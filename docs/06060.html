<html>
<head>
<title>10 TensorFlow Tricks Every ML Practitioner Must Know</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">每个ML从业者必须知道的10个张量流技巧</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/10-tensorflow-tricks-every-ml-practitioner-must-know-96b860e53c1?source=collection_archive---------30-----------------------#2020-05-17">https://towardsdatascience.com/10-tensorflow-tricks-every-ml-practitioner-must-know-96b860e53c1?source=collection_archive---------30-----------------------#2020-05-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6a8d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">为什么TensorFlow是完整的ML包</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a178f16578fbaf35db83b3bbb53122b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qo7hRVJkoYBCsZlzMFxEMQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者照片，Logo via <a class="ae ky" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a></p></figure><p id="effe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">TensorFlow 2.x在构建模型和总体TensorFlow使用方面提供了很多简单性。TF2有什么新鲜事吗？</p><ul class=""><li id="2f0b" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">使用Keras和热切的执行轻松构建模型。</li><li id="8f62" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">在任何平台上的生产中实现强大的模型部署。</li><li id="aabd" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">强大的研究实验。</li><li id="367b" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">通过清理废弃的API和减少重复来简化API。</li></ul><p id="e545" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们将探讨TF 2.0的10个特性，这些特性使TensorFlow的使用更加流畅，减少了代码行数，提高了效率，因为这些函数/类属于TensorFlow API。</p><h1 id="162d" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">第1(a)条。用于构建输入管道的tf.data API</h1><p id="e660" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">tf.data API提供了数据管道和相关操作的函数。我们可以构建管道、映射预处理函数、混洗或批处理数据集等等。</p><h2 id="be4d" class="ng mk it bd ml nh ni dn mp nj nk dp mt li nl nm mv lm nn no mx lq np nq mz nr bi translated">从张量构建管道</h2><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="5dd3" class="ng mk it nt b gy nx ny l nz oa">&gt;&gt;&gt; dataset = tf.data.Dataset.from_tensor_slices([8, 3, 0, 8, 2, 1])<br/>&gt;&gt;&gt; iter(dataset).next().numpy()<br/>8</span></pre><h2 id="ce4d" class="ng mk it bd ml nh ni dn mp nj nk dp mt li nl nm mv lm nn no mx lq np nq mz nr bi translated">分批和洗牌</h2><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="30fb" class="ng mk it nt b gy nx ny l nz oa"><strong class="nt iu"># Shuffle</strong><br/>&gt;&gt;&gt; dataset = tf.data.Dataset.from_tensor_slices([8, 3, 0, 8, 2, 1]).shuffle(6)<br/>&gt;&gt;&gt; iter(dataset).next().numpy()<br/>0</span><span id="38a5" class="ng mk it nt b gy ob ny l nz oa"><strong class="nt iu"># Batch</strong><br/>&gt;&gt;&gt; dataset = tf.data.Dataset.from_tensor_slices([8, 3, 0, 8, 2, 1]).batch(2)<br/>&gt;&gt;&gt; iter(dataset).next().numpy()<br/>array([8, 3], dtype=int32)</span><span id="a515" class="ng mk it nt b gy ob ny l nz oa"><strong class="nt iu"># Shuffle and Batch</strong><br/>&gt;&gt;&gt; dataset = tf.data.Dataset.from_tensor_slices([8, 3, 0, 8, 2, 1]).shuffle(6).batch(2)<br/>&gt;&gt;&gt; iter(dataset).next().numpy()<br/>array([3, 0], dtype=int32)</span></pre><h2 id="3de7" class="ng mk it bd ml nh ni dn mp nj nk dp mt li nl nm mv lm nn no mx lq np nq mz nr bi translated">压缩两个数据集</h2><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="6158" class="ng mk it nt b gy nx ny l nz oa">&gt;&gt;&gt; dataset0 = tf.data.Dataset.from_tensor_slices([8, 3, 0, 8, 2, 1])<br/>&gt;&gt;&gt; dataset1 = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5, 6])<br/>&gt;&gt;&gt; dataset = tf.data.Dataset.zip((dataset0, dataset1))<br/>&gt;&gt;&gt; iter(dataset).next()<br/>(&lt;tf.Tensor: shape=(), dtype=int32, numpy=8&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt;)</span></pre><h2 id="2425" class="ng mk it bd ml nh ni dn mp nj nk dp mt li nl nm mv lm nn no mx lq np nq mz nr bi translated">映射外部函数</h2><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="6b62" class="ng mk it nt b gy nx ny l nz oa">def into_2(num):<br/>     return num * 2</span><span id="4675" class="ng mk it nt b gy ob ny l nz oa">&gt;&gt;&gt; dataset = tf.data.Dataset.from_tensor_slices([8, 3, 0, 8, 2, 1]).map(into_2)<br/>&gt;&gt;&gt; iter(dataset).next().numpy()<br/>16</span></pre><h1 id="1873" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">第1款(b)项。图像数据生成器</h1><p id="c561" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">这是tensorflow.keras API最好的特性之一(在我看来)。ImageDataGenerator能够生成数据集切片，同时进行批处理和预处理，并实时增加数据<strong class="lb iu">。</strong></p><p id="b2cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">生成器允许数据流直接来自目录或数据帧。</p><blockquote class="oc od oe"><p id="adb0" class="kz la of lb b lc ld ju le lf lg jx lh og lj lk ll oh ln lo lp oi lr ls lt lu im bi translated">关于ImageDataGenerator中数据扩充的一个<strong class="lb iu">误解</strong>是，它<strong class="lb iu">向现有数据集添加更多数据</strong>。虽然这是数据扩充的实际定义，但在ImageDataGenerator中，数据集中的<strong class="lb iu">图像会在训练的不同步骤中动态转换</strong>，以便模型可以在它没有看到的有噪声的数据上进行训练。</p></blockquote><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="e323" class="ng mk it nt b gy nx ny l nz oa">train_datagen = ImageDataGenerator(<br/>        rescale=1./255,<br/>        shear_range=0.2,<br/>        zoom_range=0.2,<br/>        horizontal_flip=True<br/>)</span></pre><p id="8efb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，对所有样本进行重新缩放(用于归一化)，而其他参数用于增强。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="fb4e" class="ng mk it nt b gy nx ny l nz oa">train_generator = train_datagen.flow_from_directory(<br/>        'data/train',<br/>        target_size=(150, 150),<br/>        batch_size=32,<br/>        class_mode='binary'<br/>)</span></pre><p id="a080" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们为实时数据流指定目录。这也可以使用数据帧来完成。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="c3de" class="ng mk it nt b gy nx ny l nz oa">train_generator = flow_from_dataframe(<br/>    dataframe,<br/>    x_col='filename',<br/>    y_col='class',<br/>    class_mode='categorical',<br/>    batch_size=32<br/>)</span></pre><p id="92ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="of"> x_col </em>参数定义图像的完整路径，而<em class="of"> y_col </em>参数定义分类的标签列。</p><p id="65f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该模型可以直接由发电机供电。尽管需要指定<em class="of">每个时期的步骤数</em>参数，该参数本质上是<em class="of">样本数//批量大小。</em></p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="bb51" class="ng mk it nt b gy nx ny l nz oa">model.fit(<br/>    train_generator,<br/>    validation_data=val_generator,<br/>    epochs=EPOCHS,<br/>    steps_per_epoch=(num_samples // batch_size),<br/>    validation_steps=(num_val_samples // batch_size)<br/>)</span></pre><h1 id="9d77" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">2.用tf.image扩充数据</h1><p id="d5fc" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">数据扩充是必要的。在数据不足的情况下，对数据进行修改并将其作为一个独立的数据点，是在数据较少的情况下进行训练的一种非常有效的方法。</p><p id="7962" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">tf.image API提供了用于转换图像的工具，这些工具稍后可以用于前面讨论的tf.data API的数据扩充。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="cf85" class="ng mk it nt b gy nx ny l nz oa">flipped = tf.image.flip_left_right(image)<br/>visualise(image, flipped)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/12d8350976073a8cc0c52e432ab07a46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4r3ORe9aGUj6oZuAi3LMhA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">上述代码片段的输出</p></figure><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="78a4" class="ng mk it nt b gy nx ny l nz oa">saturated = tf.image.adjust_saturation(image, 5)<br/>visualise(image, saturated)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/fb450470f11e30ac7687aad2a1e50d40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*956iNTt7nZJqwWqGJ7rNvQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">上述代码片段的输出</p></figure><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="ae32" class="ng mk it nt b gy nx ny l nz oa">rotated = tf.image.rot90(image)<br/>visualise(image, rotated)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/9b4e287053c96bc599aef0c4d8e4d351.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*Q0vRv6oXMH55WcyQ1dMRFg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">上述代码片段的输出</p></figure><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="7824" class="ng mk it nt b gy nx ny l nz oa">cropped = tf.image.central_crop(image, central_fraction=0.5)<br/>visualise(image, cropped)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/d0216fd220d037c40f4a6090adf71834.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LQAhaU_inaWIBjruwpKEtw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">上述代码片段的输出</p></figure><h1 id="0e96" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">3.张量流数据集</h1><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="63f3" class="ng mk it nt b gy nx ny l nz oa">pip install tensorflow-datasets</span></pre><p id="70ee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是一个非常有用的库，因为它是TensorFlow从各个领域收集的非常著名的数据集的单一转储点。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="9445" class="ng mk it nt b gy nx ny l nz oa">import tensorflow_datasets as tfds</span><span id="dd39" class="ng mk it nt b gy ob ny l nz oa">mnist_data = tfds.load("mnist")<br/>mnist_train, mnist_test = mnist_data["train"], mnist_data["test"]<br/>assert isinstance(mnist_train, tf.data.Dataset)</span></pre><p id="c8ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">tensorflow-datasets中可用数据集的详细列表可在文档的<a class="ae ky" href="https://www.tensorflow.org/datasets/catalog/overview" rel="noopener ugc nofollow" target="_blank">数据集页面上找到。</a></p><blockquote class="oc od oe"><p id="3798" class="kz la of lb b lc ld ju le lf lg jx lh og lj lk ll oh ln lo lp oi lr ls lt lu im bi translated">音频、图像、图像分类、对象检测、结构化、摘要、文本、翻译、视频是tfds提供的类型。</p></blockquote><h1 id="bb6b" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">4.预训练模型下的迁移学习</h1><p id="eb28" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">迁移学习是机器学习中的新亮点，听起来很重要。训练一个已经被其他人训练过的基准模型并且拥有大量资源(例如，一个人可能负担不起的多个昂贵的GPU)是不可行和不切实际的。迁移学习解决了这个问题。一个预训练的模型可以为一个给定的用例重用，或者可以为一个不同的用例扩展。</p><p id="4341" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">TensorFlow提供了基准预训练模型，可以根据所需的使用情况轻松扩展。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="b41f" class="ng mk it nt b gy nx ny l nz oa">base_model = tf.keras.applications.MobileNetV2(<br/>    input_shape=IMG_SHAPE,<br/>    include_top=False,<br/>    weights='imagenet'<br/>)</span></pre><p id="3d46" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个<em class="of"> base_model </em>可以很容易地用附加层或者不同的模型来扩展。例如:</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="8b68" class="ng mk it nt b gy nx ny l nz oa">model = tf.keras.Sequential([<br/>    base_model,<br/>    global_average_layer,<br/>    prediction_layer<br/>])</span></pre><p id="a683" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有关tf.keras.applications下其他模型和/或模块的详细列表，请参考<a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/keras/applications" rel="noopener ugc nofollow" target="_blank">文档页面</a>。</p><h1 id="3c71" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">5.评估者</h1><blockquote class="on"><p id="6af9" class="oo op it bd oq or os ot ou ov ow lu dk translated">估计器是TensorFlow对完整模型的高级表示，它被设计为易于扩展和异步训练</p><p id="e019" class="oo op it bd oq or os ot ou ov ow lu dk translated">— <a class="ae ky" href="https://www.tensorflow.org/tutorials/estimator/premade" rel="noopener ugc nofollow" target="_blank">张量流文档</a></p></blockquote><p id="88f1" class="pw-post-body-paragraph kz la it lb b lc ox ju le lf oy jx lh li oz lk ll lm pa lo lp lq pb ls lt lu im bi translated">预制估算器提供了一个非常高层次的模型抽象，因此您可以直接专注于训练模型，而不用担心较低层次的复杂性。例如:</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="4428" class="ng mk it nt b gy nx ny l nz oa">linear_est = tf.estimator.LinearClassifier(<br/>    feature_columns=feature_columns<br/>)</span><span id="4c2d" class="ng mk it nt b gy ob ny l nz oa">linear_est.train(train_input_fn)<br/>result = linear_est.evaluate(eval_input_fn)</span></pre><p id="218c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这显示了使用tf.estimator构建和训练估计器是多么容易。估计器也可以定制。</p><p id="e292" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">TensorFlow有许多预制的估计器，包括线性回归器、BoostedTreesClassifier等。在<a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/estimator" rel="noopener ugc nofollow" target="_blank"> TensorFlow文档</a>中可以找到完整、详细的估算表。</p><h1 id="1d62" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">6.自定义图层</h1><p id="b494" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">众所周知，神经网络是多层深度网络，其中各层可以是不同的类型。张量流包含许多预定义的层(如密集，LSTM等。).但是对于更复杂的体系结构，层的逻辑要比主层复杂得多。对于这种情况，TensorFlow允许构建自定义图层。这可以通过创建tf.keras.layers.Layer类的子类来实现。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="b8a4" class="ng mk it nt b gy nx ny l nz oa">class CustomDense(tf.keras.layers.Layer):<br/>    def __init__(self, num_outputs):<br/>        super(CustomDense, self).__init__()<br/>        self.num_outputs = num_outputs<br/><br/>    def build(self, input_shape):<br/>        self.kernel = self.add_weight(<br/>            "kernel",<br/>            shape=[int(input_shape[-1]),<br/>            self.num_outputs]<br/>        )<br/><br/>    def call(self, input):<br/>        return tf.matmul(input, self.kernel)</span></pre><p id="45a5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如<a class="ae ky" href="https://www.tensorflow.org/tutorials/customization/custom_layers" rel="noopener ugc nofollow" target="_blank">文档</a>中所述，实现您自己的层的最佳方式是扩展tf.keras.Layer类并实现:</p><ol class=""><li id="69ed" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu pc mb mc md bi translated"><em class="of"> __init__ </em>，在这里可以进行所有与输入无关的初始化。</li><li id="a439" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu pc mb mc md bi translated"><em class="of">构建</em>，在这里你知道输入张量的形状，并且可以完成剩下的初始化工作。</li><li id="74f9" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu pc mb mc md bi translated"><em class="of">调用</em>，在这里进行正向计算。</li></ol><p id="309f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然内核初始化可以在<em class="of"> __init__ </em>中完成，但是在<em class="of"> build </em>中初始化被认为更好，否则，您将不得不在每个新层创建的实例上显式指定<em class="of"> input_shape </em>。</p><h1 id="c5d9" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">7.定制培训</h1><p id="dd66" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">tf.keras Sequential和Model API使得训练模型更加容易。然而，大多数时候在训练复杂模型时，使用定制损失函数。此外，模型训练也可以不同于默认值(例如，将梯度分别应用于不同的模型组件)。</p><p id="3e5c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">TensorFlow的自动微分功能有助于高效计算梯度。这些原语用于定义自定义训练循环。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="416b" class="ng mk it nt b gy nx ny l nz oa">def train(model, inputs, outputs, learning_rate):<br/>    with tf.GradientTape() as t:<br/><strong class="nt iu">        # Computing Losses from Model Prediction</strong><br/>        current_loss = loss(outputs, model(inputs))</span><span id="f0ef" class="ng mk it nt b gy ob ny l nz oa"><strong class="nt iu">    # Gradients for Trainable Variables with Obtained Losses</strong><br/>    dW, db = t.gradient(current_loss, [model.W, model.b])</span><span id="a5e1" class="ng mk it nt b gy ob ny l nz oa"><strong class="nt iu">    # Applying Gradients to Weights</strong><br/>    model.W.assign_sub(learning_rate * dW)<br/>    model.b.assign_sub(learning_rate * db)</span></pre><p id="b528" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个循环可以重复多个时期，并根据使用情况进行更加定制的设置。</p><h1 id="735e" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">8.检查站</h1><p id="fd7b" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">保存张量流模型有两种类型:</p><ol class=""><li id="64eb" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu pc mb mc md bi translated"><strong class="lb iu"> SavedModel </strong>:保存模型的完整状态以及所有参数。这与源代码无关。<code class="fe pd pe pf nt b">model.save_weights('checkpoint')</code></li><li id="36c2" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu pc mb mc md bi translated"><strong class="lb iu">检查点</strong></li></ol><p id="e82a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">检查点捕获模型使用的所有参数的精确值。用顺序API或模型API构建的模型可以简单地保存为SavedModel格式。</p><p id="8b34" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是，对于定制模型，检查点是必需的。</p><blockquote class="oc od oe"><p id="79cf" class="kz la of lb b lc ld ju le lf lg jx lh og lj lk ll oh ln lo lp oi lr ls lt lu im bi translated">检查点不包含由模型定义的计算的任何描述，因此通常仅当使用保存的参数值的源代码可用时才有用。</p></blockquote><h2 id="d6bc" class="ng mk it bd ml nh ni dn mp nj nk dp mt li nl nm mv lm nn no mx lq np nq mz nr bi translated">保存检查点</h2><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="f4a0" class="ng mk it nt b gy nx ny l nz oa">checkpoint_path = “save_path”</span><span id="7b61" class="ng mk it nt b gy ob ny l nz oa"><strong class="nt iu"># Defining a Checkpoint</strong><br/>ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)</span><span id="6888" class="ng mk it nt b gy ob ny l nz oa"><strong class="nt iu"># Creating a CheckpointManager Object</strong><br/>ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)</span><span id="eaa9" class="ng mk it nt b gy ob ny l nz oa"><strong class="nt iu"># Saving a Model</strong><br/>ckpt_manager.save()</span></pre><h2 id="7921" class="ng mk it bd ml nh ni dn mp nj nk dp mt li nl nm mv lm nn no mx lq np nq mz nr bi translated">从检查点加载</h2><p id="b3f7" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">TensorFlow通过遍历带有命名边的有向图，从正在加载的对象开始，将变量与检查点值进行匹配。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pg"><img src="../Images/c9fb7ee3e2616268c05a0bb37bda2264.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rMqi-aL9mGFFWgbk5zw6UQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">通过<a class="ae ky" href="https://www.tensorflow.org/guide/checkpoint" rel="noopener ugc nofollow" target="_blank">文档</a>恢复模型的依赖图</p></figure><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="8eb5" class="ng mk it nt b gy nx ny l nz oa">if ckpt_manager.latest_checkpoint:<br/>    ckpt.restore(ckpt_manager.latest_checkpoint)</span></pre><h1 id="56c5" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">9.Keras调谐器</h1><p id="43a3" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">这是TensorFlow中一个相当新的特性。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="87ef" class="ng mk it nt b gy nx ny l nz oa">!pip install keras-tuner</span></pre><p id="5d93" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">超参数调整或超调整是挑选定义ML模型配置的参数的过程。这些因素是特征工程和预处理后模型性能的决定因素。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="2e3a" class="ng mk it nt b gy nx ny l nz oa"><strong class="nt iu"># model_builder is a function that builds a model and returns it</strong><br/>tuner = kt.Hyperband(<br/>    model_builder,<br/>    objective='val_accuracy', <br/>    max_epochs=10,<br/>    factor=3,<br/>    directory='my_dir',<br/>    project_name='intro_to_kt'<br/>)</span></pre><p id="0060" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">除了HyperBand，BayesianOptimization和RandomSearch也可用于调优。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="3f17" class="ng mk it nt b gy nx ny l nz oa">tuner.search(<br/>    img_train, label_train, <br/>    epochs = 10, <br/>    validation_data=(img_test,label_test), <br/>    callbacks=[ClearTrainingOutput()]<br/>)<br/><strong class="nt iu"><br/># Get the optimal hyperparameters</strong><br/>best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]</span></pre><p id="623c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，我们使用最佳超参数来训练模型:</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="fd1b" class="ng mk it nt b gy nx ny l nz oa">model = tuner.hypermodel.build(best_hps)<br/>model.fit(<br/>    img_train, <br/>    label_train, <br/>    epochs=10, <br/>    validation_data=(img_test, label_test)<br/>)</span></pre><h1 id="409b" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">10.分布式培训</h1><p id="fa88" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">如果您有多个GPU，并希望通过在多个GPU上分散训练循环来优化训练，TensorFlow的各种分布式训练策略能够优化GPU的使用，并为您操纵GPU上的训练。</p><p id="5d43" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">tf.distribute.MirroredStrategy是最常用的策略。它到底是怎么工作的？<a class="ae ky" href="https://www.tensorflow.org/tutorials/distribute/custom_training" rel="noopener ugc nofollow" target="_blank">单据</a>状态:</p><ul class=""><li id="a07c" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">所有的变量和模型图都被复制到复制品上。</li><li id="6354" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">输入在副本之间均匀分布。</li><li id="fbb9" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">每个复制品计算它接收的输入的损失和梯度。</li><li id="3be6" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">通过求和，梯度在所有副本中同步。</li><li id="2eed" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">同步后，对每个副本上的变量副本进行相同的更新。</li></ul><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="7fd5" class="ng mk it nt b gy nx ny l nz oa">strategy = tf.distribute.MirroredStrategy()</span><span id="cc8e" class="ng mk it nt b gy ob ny l nz oa">with strategy.scope():<br/>    model = tf.keras.Sequential([<br/>        tf.keras.layers.Conv2D(<br/>            32, 3, activation='relu',  input_shape=(28, 28, 1)<br/>        ),<br/>        tf.keras.layers.MaxPooling2D(),<br/>        tf.keras.layers.Flatten(),<br/>        tf.keras.layers.Dense(64, activation='relu'),<br/>        tf.keras.layers.Dense(10)<br/>    ])<br/><br/>    model.compile(<br/>        loss="sparse_categorical_crossentropy",<br/>        optimizer="adam",<br/>        metrics=['accuracy']<br/>    )</span></pre><p id="e854" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于其他策略和自定义训练循环，请参考<a class="ae ky" href="https://www.tensorflow.org/tutorials/distribute/keras" rel="noopener ugc nofollow" target="_blank">文档</a>。</p><h1 id="2273" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">结论</h1><p id="6ffd" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">TensorFlow足以构建ML管道的几乎所有组件。本教程的要点是介绍TensorFlow提供的各种API以及如何使用它们的快速指南。</p><p id="ce20" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://github.com/rojagtap/tensorflow_tutorials" rel="noopener ugc nofollow" target="_blank">这里的</a>是指向GitHub代码库的链接。随便叉吧。</p><h1 id="0084" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">参考</h1><p id="b520" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">本指南中使用的代码引用自以下官方TensorFlow文档:</p><div class="ph pi gp gr pj pk"><a href="https://www.tensorflow.org/tutorials" rel="noopener  ugc nofollow" target="_blank"><div class="pl ab fo"><div class="pm ab pn cl cj po"><h2 class="bd iu gy z fp pp fr fs pq fu fw is bi translated">教程| TensorFlow核心</h2><div class="pr l"><h3 class="bd b gy z fp pp fr fs pq fu fw dk translated">完整的端到端示例，帮助ML初学者和专家了解如何使用TensorFlow。尝试谷歌教程…</h3></div><div class="ps l"><p class="bd b dl z fp pp fr fs pq fu fw dk translated">www.tensorflow.org</p></div></div><div class="pt l"><div class="pu l pv pw px pt py ks pk"/></div></div></a></div><div class="ph pi gp gr pj pk"><a href="https://www.tensorflow.org/tutorials" rel="noopener  ugc nofollow" target="_blank"><div class="pl ab fo"><div class="pm ab pn cl cj po"><h2 class="bd iu gy z fp pp fr fs pq fu fw is bi translated">教程| TensorFlow核心</h2><div class="pr l"><h3 class="bd b gy z fp pp fr fs pq fu fw dk translated">完整的端到端示例，帮助ML初学者和专家了解如何使用TensorFlow。尝试谷歌教程…</h3></div><div class="ps l"><p class="bd b dl z fp pp fr fs pq fu fw dk translated">www.tensorflow.org</p></div></div><div class="pt l"><div class="pu l pv pw px pt py ks pk"/></div></div></a></div></div></div>    
</body>
</html>