<html>
<head>
<title>How to Draw a Map using Python and Word2vec</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用 Python 和 Word2vec 绘制地图</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-draw-a-map-using-python-and-word2vec-e9627b4eae34?source=collection_archive---------27-----------------------#2020-08-27">https://towardsdatascience.com/how-to-draw-a-map-using-python-and-word2vec-e9627b4eae34?source=collection_archive---------27-----------------------#2020-08-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4a2d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">从欧洲首都的 Word2vec 向量创建的主要组件的二维可视化表示，也称为地图。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a6764b69e100ebbe9f2c0308fbf64574.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9r4RwTPjslulMIAEcia2sQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">雅各布·布朗在 Unsplash<a class="ae ky" href="https://unsplash.com/s/photos/map-of-europe?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">上的照片</a></p></figure><p id="7453" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">到目前为止，Word2vec 绝对是我在自然语言处理研究中遇到的最有趣的概念。想象一下，一种算法可以真正成功地模仿理解单词的含义及其在语言中的功能，可以沿着数百个不同的主题测量单词的接近程度，可以回答更复杂的问题，如“<em class="lv">谁对文学来说就像贝多芬对音乐来说</em>”。</p><p id="ca6d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我认为直观地表示 word2vec 向量会很有趣:本质上，我们可以获取国家或城市的向量，应用主成分分析来降低维度，并将其放在二维图表上。然后，我们可以观察我们离实际的地理地图有多近。</p><p id="f5cb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我们将:</p><ul class=""><li id="08a5" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">广义地讨论 word2vec 理论；</li><li id="296c" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">下载原始预训练向量；</li><li id="f22b" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">看看一些有趣的应用:从列表中找出奇怪的一个，或者对单词进行算术运算，比如著名的<code class="fe mk ml mm mn b">king — man + woman = queen</code>例子；</li><li id="51d1" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">看看我们仅仅基于 word2vec 向量就能多精确地画出欧洲的首都。</li></ul><p id="3853" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最初的 word2vec 研究论文和预训练模型来自 2013 年，考虑到 NLP 文献的扩展速度，它在这一点上是旧技术。更新的方法包括<a class="ae ky" href="https://nlp.stanford.edu/projects/glove/" rel="noopener ugc nofollow" target="_blank"> GloVe </a>(更快的训练，不同的算法，可以在更小的语料库上训练)和<a class="ae ky" href="https://fasttext.cc/" rel="noopener ugc nofollow" target="_blank"> fastText </a>(能够处理字符 n-grams)。我现在坚持原始算法的结果。</p><h1 id="1d31" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">快速 Word2Vec 简介</h1><p id="824d" class="pw-post-body-paragraph kz la it lb b lc ng ju le lf nh jx lh li ni lk ll lm nj lo lp lq nk ls lt lu im bi translated">自然语言处理的核心概念之一是我们如何量化单词和表达式，以便能够在模型设置中使用它们。这种语言元素到数字表示的映射被称为<a class="ae ky" href="https://en.wikipedia.org/wiki/Word_embedding" rel="noopener ugc nofollow" target="_blank">单词嵌入</a>。</p><p id="9548" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Word2vec 是一个单词嵌入过程。这个概念相对简单:它一句接一句地在语料库中循环，并符合一个模型，该模型根据来自预定义大小窗口的相邻单词来预测单词。为此，它使用神经网络，但实际上并不使用预测，一旦模型被保存，它只保存第一层的权重。在最初的模型中，我们将要使用的模型，有 300 个权重，所以每个单词都由一个 300 维的向量表示。</p><p id="420c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，两个单词不一定要彼此接近才能被视为相似。如果两个单词从未出现在同一个句子中，但它们通常被相同的单词所包围，则可以有把握地假设它们具有相似的意思。</p><p id="6d47" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">word2vec 中有两种建模方法:<em class="lv">跳跃式语法</em>和<em class="lv">连续式词汇袋</em>，这两种方法都有各自的优点，并且对某些超参数很敏感……但是你知道吗？我们不会去适应我们自己的模型，所以我不打算在这上面花更多的时间，你可以在<a class="ae ky" rel="noopener" target="_blank" href="/nlp-101-word2vec-skip-gram-and-cbow-93512ee24314">这篇文章</a>或<a class="ae ky" href="https://en.wikipedia.org/wiki/Word2vec" rel="noopener ugc nofollow" target="_blank">维基站点</a>中阅读更多关于不同方法和参数的内容。</p><p id="4286" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">自然，你得到的单词向量依赖于你训练你的模型的语料库。一般来说，你确实需要一个巨大的语料库，有在维基百科上训练过的版本，或者各种来源的新闻文章。我们将要使用的结果是在谷歌新闻上训练出来的。</p><h1 id="c7ed" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">如何下载和安装</h1><p id="f55e" class="pw-post-body-paragraph kz la it lb b lc ng ju le lf nh jx lh li ni lk ll lm nj lo lp lq nk ls lt lu im bi translated">首先，您需要下载预先训练好的 word2vec 矢量。您可以从针对不同类型文档的各种模型中进行选择。我用的是最初的模型，在谷歌新闻上受过训练，你可以从很多来源下载，只需搜索“<em class="lv">谷歌新闻向量负 300 </em>”。比如这个 GitHub 链接就是一个方便的方法:<a class="ae ky" href="https://github.com/mmihaltz/word2vec-GoogleNews-vectors" rel="noopener ugc nofollow" target="_blank">https://github.com/mmihaltz/word2vec-GoogleNews-vectors</a>。</p><p id="5b51" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，该文件有 1.66 GB，但在其辩护中，它包含了 30 亿个单词的 300 维表示。</p><p id="6e46" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当谈到在 Python 中使用 word2vec 时，同样，您有许多包可供选择，我们将使用<code class="fe mk ml mm mn b">gensim</code>库。假设您已经将文件保存在<code class="fe mk ml mm mn b">word2vec_pretrained</code>文件夹中，您可以像这样用 Python 加载它:</p><pre class="kj kk kl km gt nl mn nm nn aw no bi"><span id="9dfb" class="np mp it mn b gy nq nr l ns nt">from gensim.models.keyedvectors import KeyedVectors</span><span id="7824" class="np mp it mn b gy nu nr l ns nt">word_vectors = KeyedVectors.load_word2vec_format(\<br/>    './word2vec_pretrained/GoogleNews-vectors-negative300.bin.gz', \<br/>    binary = True, limit = 1000000)</span></pre><p id="9a18" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">limit 参数定义了你要输入多少单词，一百万对我来说已经足够了。</p><h1 id="1337" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">玩文字游戏</h1><p id="cdc3" class="pw-post-body-paragraph kz la it lb b lc ng ju le lf nh jx lh li ni lk ll lm nj lo lp lq nk ls lt lu im bi translated">现在我们已经有了 word2vec 向量，我们可以检查它的一些应用程序。</p><p id="ef3b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，你实际上可以检查任何单词的矢量表示:</p><pre class="kj kk kl km gt nl mn nm nn aw no bi"><span id="2202" class="np mp it mn b gy nq nr l ns nt">word_vectors['dog']</span></pre><p id="b1ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我们所料，结果是一个 300 维的向量，很难解释。但这是整个概念的基础，我们通过将这些向量相加和相减来对它们进行计算，然后我们计算余弦相似度来找到最匹配的单词。</p><p id="e00c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以使用<code class="fe mk ml mm mn b">most_similar</code>函数查找同义词，<code class="fe mk ml mm mn b">topn</code>参数定义了您希望列出多少个单词:</p><pre class="kj kk kl km gt nl mn nm nn aw no bi"><span id="5b5a" class="np mp it mn b gy nq nr l ns nt">word_vectors.most_similar(positive = ['nice'], topn = 5)</span></pre><p id="b039" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果是</p><pre class="kj kk kl km gt nl mn nm nn aw no bi"><span id="c79a" class="np mp it mn b gy nq nr l ns nt">[('good', 0.6836092472076416),<br/> ('lovely', 0.6676311492919922),<br/> ('neat', 0.6616737246513367),<br/> ('fantastic', 0.6569241285324097),<br/> ('wonderful', 0.6561347246170044)]</span></pre><p id="83ed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，你可能认为用类似的方法，你也可以找到反义词，你只需要输入单词'<em class="lv"> nice </em>'作为一个<code class="fe mk ml mm mn b">negative</code>，对吗？不完全是，结果是这样的:</p><pre class="kj kk kl km gt nl mn nm nn aw no bi"><span id="b948" class="np mp it mn b gy nq nr l ns nt">[('J.Gordon_###-###', 0.38660115003585815),<br/> ('M.Kenseth_###-###', 0.35581791400909424),<br/> ('D.Earnhardt_Jr._###-###', 0.34227001667022705),<br/> ('G.Biffle_###-###', 0.3420777916908264),<br/> ('HuMax_TAC_TM', 0.3141660690307617)]</span></pre><p id="7115" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些单词与单词“<em class="lv"> nice </em>”相距甚远，表明它并不总是如你所愿。</p><p id="7532" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以使用<code class="fe mk ml mm mn b">doesnt_match</code>功能找出奇数:</p><pre class="kj kk kl km gt nl mn nm nn aw no bi"><span id="ac75" class="np mp it mn b gy nq nr l ns nt">word_vectors.doesnt_match(<br/>['Hitler', 'Churchill', 'Stalin', 'Beethoven'])</span></pre><p id="c7f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">返回<code class="fe mk ml mm mn b">Beethoven</code>。我想这很方便。</p><p id="0bda" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，让我们来看几个例子，这些例子通过给算法一种错误的智能感而使它出名。如果我们想要组合字向量<code class="fe mk ml mm mn b">father</code>和<code class="fe mk ml mm mn b">woman</code>的值，但是减去分配给字向量<code class="fe mk ml mm mn b">man</code>的值:</p><pre class="kj kk kl km gt nl mn nm nn aw no bi"><span id="44e9" class="np mp it mn b gy nq nr l ns nt">word_vectors.most_similar(<br/>positive = ['father', 'woman'], negative = ['man'], topn = 1)</span></pre><p id="6495" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们得到:</p><pre class="kj kk kl km gt nl mn nm nn aw no bi"><span id="93e9" class="np mp it mn b gy nq nr l ns nt">[('mother', 0.8462507128715515)]</span></pre><p id="4182" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，要理解这个手术有点困难，我认为把这个问题表述成“<em class="lv">父亲对于男人来说，对于女人来说是什么？</em>“其实没那么有用。想象我们只有两个维度:父母和性别。单词'<em class="lv">女人</em>'可以用这个向量来表示:<code class="fe mk ml mm mn b">[0, 1]</code>，'<em class="lv">男人</em>是<code class="fe mk ml mm mn b">[0, -1]</code>，'<em class="lv">父亲</em>是<code class="fe mk ml mm mn b">[1, -1]</code>，而'<em class="lv">母亲</em>是<code class="fe mk ml mm mn b">[1, 1]</code>。现在，如果我们用向量做同样的运算，我们会得到同样的结果。当然，不同之处在于我们有 300 个维度，而不是例子中的 2 个，维度的意义几乎无法解释。</p><p id="00c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当谈到 word2vec 操作时，有一个著名的性别偏见例子，单词'<em class="lv"> doctor' </em>(我们知道，这是一个中性词)的女性版本曾经被计算为'<em class="lv"> nurse' </em>。我尝试复制它，但没有得到相同的结果:</p><pre class="kj kk kl km gt nl mn nm nn aw no bi"><span id="1e56" class="np mp it mn b gy nq nr l ns nt">word_vectors.most_similar(<br/>positive = ['doctor', 'woman'], negative = ['man'], topn = 1)<br/></span><span id="38ec" class="np mp it mn b gy nu nr l ns nt">[('gynecologist', 0.7093892097473145)]</span></pre><p id="056d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我猜是进步了吧？</p><p id="0a54" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">好了，现在我们检查了一些基本的可能性，让我们在我们的地图上工作！</p><h1 id="4d2e" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">映射函数</h1><p id="38c6" class="pw-post-body-paragraph kz la it lb b lc ng ju le lf nh jx lh li ni lk ll lm nj lo lp lq nk ls lt lu im bi translated">首先，我们需要一个我们希望我们的映射函数做什么的计划。假设我们有一个想要可视化的字符串列表和一个单词向量对象，我们想要:</p><ol class=""><li id="009d" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu nv mc md me bi translated">找到列表中每个单词的单词向量表示；</li><li id="657c" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu nv mc md me bi translated">使用主成分分析将维度减少到 2；</li><li id="c70d" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu nv mc md me bi translated">创建散点图，将单词作为标签添加到每个数据点；</li><li id="6e6f" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu nv mc md me bi translated">作为一个额外的奖励，可以通过任何维度“翻转”结果-主成分分析的向量具有任意方向，当我们绘制地理单词以更好地与现实世界的方向保持一致时，我们可能希望改变这一点。</li></ol><p id="f075" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将需要以下库:</p><pre class="kj kk kl km gt nl mn nm nn aw no bi"><span id="3e13" class="np mp it mn b gy nq nr l ns nt">import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>from sklearn.decomposition import PCA</span><span id="e094" class="np mp it mn b gy nu nr l ns nt">import adjustText</span></pre><p id="bba7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">列表中一个不常用的库是<a class="ae ky" href="https://github.com/Phlya/adjustText" rel="noopener ugc nofollow" target="_blank"> adjustText </a>，这是一个非常方便的包，它使得在散点图中编写图例变得简单，而且不会重叠。对我来说，找到这个解决方案出奇的困难，而且据我所知，在 matplotlib 或 seaborn 中没有办法做到这一点。</p><p id="cb21" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">事不宜迟，这个函数正是我们所需要的:</p><pre class="kj kk kl km gt nl mn nm nn aw no bi"><span id="e38f" class="np mp it mn b gy nq nr l ns nt">def plot_2d_representation_of_words(<br/>    word_list, <br/>    word_vectors, <br/>    flip_x_axis = False,<br/>    flip_y_axis = False,<br/>    label_x_axis = "x",<br/>    label_y_axis = "y", <br/>    label_label = "city"):<br/>    <br/>    pca = PCA(n_components = 2)<br/>    <br/>    word_plus_coordinates=[]<br/>    <br/>    for word in word_list: <br/>    <br/>        current_row = []<br/>        current_row.append(word)<br/>        current_row.extend(word_vectors[word])</span><span id="1be9" class="np mp it mn b gy nu nr l ns nt">    word_plus_coordinates.append(current_row)<br/>    <br/>    word_plus_coordinates = pd.DataFrame(word_plus_coordinates)<br/>        <br/>    coordinates_2d = pca.fit_transform(<br/>        word_plus_coordinates.iloc[:,1:300])<br/>    coordinates_2d = pd.DataFrame(<br/>        coordinates_2d, columns=[label_x_axis, label_y_axis])<br/>    coordinates_2d[label_label] = word_plus_coordinates.iloc[:,0]</span><span id="35d3" class="np mp it mn b gy nu nr l ns nt">    if flip_x_axis:<br/>        coordinates_2d[label_x_axis] = \<br/>        coordinates_2d[label_x_axis] * (-1)</span><span id="8261" class="np mp it mn b gy nu nr l ns nt">    if flip_y_axis:<br/>        coordinates_2d[label_y_axis] = \<br/>        coordinates_2d[label_y_axis] * (-1)<br/>            <br/>    plt.figure(figsize = (15,10))</span><span id="987c" class="np mp it mn b gy nu nr l ns nt">    p1=sns.scatterplot(<br/>        data=coordinates_2d, x=label_x_axis, y=label_y_axis)<br/>    <br/>    x = coordinates_2d[label_x_axis]<br/>    y = coordinates_2d[label_y_axis]<br/>    label = coordinates_2d[label_label]<br/>    <br/>    texts = [plt.text(x[i], y[i], label[i]) for i in range(len(x))]</span><span id="b28e" class="np mp it mn b gy nu nr l ns nt">    adjustText.adjust_text(texts)</span></pre><p id="d233" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在该测试功能了。我绘制了欧洲国家的首都，但是你可以使用任何列表，总统或其他历史人物的名字，汽车品牌，烹饪原料，摇滚乐队，等等，只要在<code class="fe mk ml mm mn b">word_list</code>参数中传递它。我从中得到一些乐趣，有趣的是看到集群形成并试图在两个轴后面找到一个意义。</p><p id="c4a5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想重现结果，这里有一些城市:</p><pre class="kj kk kl km gt nl mn nm nn aw no bi"><span id="56a5" class="np mp it mn b gy nq nr l ns nt">capitals = [<br/>    'Amsterdam', 'Athens', 'Belgrade', 'Berlin', 'Bern', <br/>    'Bratislava', 'Brussels', 'Bucharest', 'Budapest', <br/>    'Chisinau', 'Copenhagen','Dublin', 'Helsinki', 'Kiev',<br/>    'Lisbon', 'Ljubljana', 'London', 'Luxembourg','Madrid',<br/>    'Minsk', 'Monaco', 'Moscow', 'Nicosia', 'Nuuk', 'Oslo', <br/>    'Paris','Podgorica', 'Prague', 'Reykjavik', 'Riga', <br/>    'Rome', 'San_Marino', 'Sarajevo','Skopje', 'Sofia', <br/>    'Stockholm', 'Tallinn', 'Tirana', 'Vaduz', 'Valletta',<br/>    'Vatican', 'Vienna', 'Vilnius', 'Warsaw', 'Zagreb']</span></pre><p id="2a07" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">(安道尔的首都安道尔城不在列表中，无法找到 word2vec 识别的格式。我们会接受的。)</p><p id="550a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">假设您仍然拥有我们在上一节中创建的<code class="fe mk ml mm mn b">word_vectors</code>对象，您可以像这样调用该函数:</p><pre class="kj kk kl km gt nl mn nm nn aw no bi"><span id="3c8a" class="np mp it mn b gy nq nr l ns nt">plot_2d_representation_of_words(<br/>    word_list = capitals, <br/>    word_vectors = word_vectors, <br/>    flip_y_axis = True)</span></pre><p id="14a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">(y 轴被翻转，以便创建更类似于真实地图的表示。)</p><p id="6229" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/e7101db026010299345e51793b59194c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N_paKE0ef5RrBxnNITQyvA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Word2vec 欧洲地图</p></figure><p id="5741" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我不知道你的感受，当我第一次看到这张地图的时候，我简直不敢相信它的效果是如此之好！是的，当然，你观察的时间越长，你发现的“错误”就越多，一个不祥的结果是莫斯科并不像它应该的那样远离东方……然而，东方和西方几乎完全分开，斯堪的纳维亚和波罗的海国家很好地组合在一起，意大利周围的首都也是如此，这样的例子不胜枚举。</p><p id="3450" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">需要强调的是，这绝不意味着纯粹的地理位置，例如，雅典在西边很远，但这是有原因的。让我们回顾一下上面的地图是如何得出的，这样我们就可以充分欣赏它了:</p><ul class=""><li id="b0df" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">谷歌的一组研究人员训练了一个巨大的神经网络，它可以根据上下文预测单词；</li><li id="9b0c" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">他们将每个单词的权重保存在一个 300 维的向量表示中；</li><li id="ef5d" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">我们取了欧洲各国首都的向量。</li><li id="ab4e" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">通过主成分分析将维数降低到 2；</li><li id="a798" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">将计算出的组件放在图表上。</li></ul><p id="9afa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我觉得这很棒！</p><h1 id="9c59" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">参考</h1><p id="8171" class="pw-post-body-paragraph kz la it lb b lc ng ju le lf nh jx lh li ni lk ll lm nj lo lp lq nk ls lt lu im bi translated">霍布森、科尔和汉尼斯(2019 年)。自然语言处理实践:理解、分析和用 Python 生成文本。曼宁出版，2019。</p><div class="nx ny gp gr nz oa"><a href="https://en.wikipedia.org/wiki/Word2vec" rel="noopener  ugc nofollow" target="_blank"><div class="ob ab fo"><div class="oc ab od cl cj oe"><h2 class="bd iu gy z fp of fr fs og fu fw is bi translated">Word2vec</h2><div class="oh l"><h3 class="bd b gy z fp of fr fs og fu fw dk translated">Word2vec 是一种自然语言处理技术。word2vec 算法使用神经网络模型来学习…</h3></div><div class="oi l"><p class="bd b dl z fp of fr fs og fu fw dk translated">en.wikipedia.org</p></div></div><div class="oj l"><div class="ok l ol om on oj oo ks oa"/></div></div></a></div><div class="nx ny gp gr nz oa"><a href="https://adjusttext.readthedocs.io/en/latest/" rel="noopener  ugc nofollow" target="_blank"><div class="ob ab fo"><div class="oc ab od cl cj oe"><h2 class="bd iu gy z fp of fr fs og fu fw is bi translated">欢迎阅读 adjustText 的文档！- adjustText 0.7 文档</h2><div class="oh l"><h3 class="bd b gy z fp of fr fs og fu fw dk translated">adjustText 是一个小的库，帮助您调整 matplotlib 图上的文本位置，以删除或最小化与…的重叠</h3></div><div class="oi l"><p class="bd b dl z fp of fr fs og fu fw dk translated">adjusttext.readthedocs.io</p></div></div></div></a></div></div></div>    
</body>
</html>