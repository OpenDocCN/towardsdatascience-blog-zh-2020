<html>
<head>
<title>Active Learning Tutorial — Machine Learning with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">主动学习教程—使用 Python 进行机器学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/active-learning-5b9d0955292d?source=collection_archive---------3-----------------------#2020-05-30">https://towardsdatascience.com/active-learning-5b9d0955292d?source=collection_archive---------3-----------------------#2020-05-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="dfb5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">这是一个 Python 主动学习的教程，对概念进行了解释，并对代码中的步骤进行了详细说明</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f5982fb49e148b7e42cab41db631c67d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UVk3DCobeo6oNSvjt6bQ-A.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h2 id="c849" class="ky kz it bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">什么是主动学习？</h2><p id="9aee" class="pw-post-body-paragraph lu lv it lw b lx ly ju lz ma mb jx mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">主动学习是一种机器学习技术，其中我们使用较少的标记数据，并交互式地标记新的数据点，以提高模型的性能。</p><p id="abce" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">术语:<br/>训练数据集=标记的数据点<br/>池=未标记的数据点</p><p id="f56a" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">我们从一些带标签的数据点(训练数据集)开始。有大量未标记的数据点。这些未标记的数据点必须被标记并添加到训练数据集中以创建模型。然而，在主动学习中，我们将只标记一小部分数据点，而不是标记池中的所有数据点，但是仍然可以获得良好的性能。</p><p id="0660" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">我们创建一个模型(分类器),并根据标记的数据对其进行训练。然后，我们检查池中的所有数据点，识别分类器最不明确的点，并将这些点添加到训练数据中(我们每次可能只添加一个点)。我们重复这个过程来提高模型性能。这种技术通常在贴标成本较高时使用。</p><p id="ce88" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">我将很快在<a class="ae ms" href="https://bit.ly/ai-n-ml-youtube" rel="noopener ugc nofollow" target="_blank"> YouTube </a>上传一段视频，详细解释主动学习背后的概念。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/48dbbab6fb96d56056b3a48cf68a6a5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uG9wH0xpWt34sH2LYaoZWg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">主动学习和其他采样新数据点进行标记的方法的性能改进比较—图片由<a class="ae ms" href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fwww.groundai.com%2Fproject%2Flearning-to-sample-an-active-learning-framework%2F1&amp;psig=AOvVaw2itxPFqwYbNZCnGV_EFSpQ&amp;ust=1590952401948000&amp;source=images&amp;cd=vfe&amp;ved=0CA0QjhxqFwoTCICnqNil3OkCFQAAAAAdAAAAABAY" rel="noopener ugc nofollow" target="_blank">基金会</a>提供</p></figure></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h2 id="367d" class="ky kz it bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">主要代码</h2><p id="a94c" class="pw-post-body-paragraph lu lv it lw b lx ly ju lz ma mb jx mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">在这里，我们导入所需的库:<br/> pandas —处理数据<br/> sklearn —用于 SVM 模型<br/> numpy —用于矩阵和数组操作<br/> matplotlib.pyplot —用于图形绘制<br/> imageio —制作 gif<br/>OS—创建文件夹并检查它们的内容</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="c350" class="ky kz it nc b gy ng nh l ni nj">from sklearn.svm import SVC, LinearSVC<br/>import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>from sklearn.model_selection import train_test_split<br/>import imageio as io<br/>import os</span></pre><p id="b82e" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">这里，我们从 CSV 文件中读取数据。该数据可在<a class="ae ms" href="https://www.kaggle.com/uciml/iris" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上获得。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="e944" class="ky kz it nc b gy ng nh l ni nj">origdata = pd.read_csv("Iris.csv")<br/>origdata[:10]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/48e133c55626142e34ba945ce069020b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rOFmJmS4I02vYni48rCWwQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">单元格输出:虹膜数据集预览-作者提供的图像</p></figure><p id="c088" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">该数据集包含关于鸢尾花的 3 个<strong class="lw iu">种/亚种</strong>的数据。每个样本都有萼片的长度、萼片的宽度、花瓣的长度和花瓣的宽度，都以厘米为单位。每个样本都是这三种鸢尾中的一种——刚毛鸢尾、杂色鸢尾和海滨鸢尾。</p><p id="82cb" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">我们从数据集中选择两个属性(列)来执行主动学习。我们选择了两列，因为这样很容易将 2D 数据可视化。但是注意，只取 2 列未必比取所有列用于机器学习或主动学习更好。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="a7c5" class="ky kz it nc b gy ng nh l ni nj">k1, k2 = 'PetalLengthCm', 'PetalWidthCm'<br/>data = origdata[[k1, k2, 'Species']].copy()<br/>data[:10]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/904f8aa0e95d4079f01310034198de20.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*4i0QfRA_spQLr3qDlQzhvA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">仅包含选定列的 Iris 数据集-按作者分类的图像</p></figure><p id="ac09" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">对于训练数据，我们采用前面选择的两列。物种栏是标签。我们将标签更改为 0(鸢尾-刚毛鸢尾)、1(鸢尾-杂色)和 2(鸢尾-海滨鸢尾)。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="4028" class="ky kz it nc b gy ng nh l ni nj">X = data[[k1, k2]]<br/>y = data['Species']<br/>print('Classes:')<br/>print(y.unique(), '\n\n\n')<br/><br/>y[y=='Iris-setosa'] = 0<br/>y[y=='Iris-versicolor'] = 1<br/>y[y=='Iris-virginica'] = 2</span></pre><p id="6d33" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">输出:</p><p id="729b" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated"><code class="fe nm nn no nc b">Classes:<br/>['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']</code></p><p id="c0e7" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">我们在 2D 图上绘制了云芝和海滨锦葵的样本，云芝用红色，海滨锦葵用青色。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="b19e" class="ky kz it nc b gy ng nh l ni nj">plt.figure()<br/>setosa = y == 0<br/>versicolor = y == 1<br/>virginica = y == 2<br/><br/>plt.scatter(X[k1][versicolor], X[k2][versicolor], c='r')<br/>plt.scatter(X[k1][virginica], X[k2][virginica], c='c')<br/>plt.xlabel(k1)<br/>plt.ylabel(k2)<br/>plt.show()</span></pre><p id="80b3" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">输出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/72f7c0ad11c9aa60e3ab263de1b8ad35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*f63_0Nyayk2BlQzag7xz1Q.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">杂色-红色；Virginica-青色——作者图片</p></figure><p id="2971" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">我们丢弃鸢尾的样本。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="ad28" class="ky kz it nc b gy ng nh l ni nj">X1 = X[y != 0]<br/>y1 = y[y != 0]<br/>X1[:5]</span></pre><p id="2529" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">输出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/b96dfcd0417e9fb5083764fe0b53f8d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*9VCijHmWQz6tZsxBzJTd5g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">注意，数据帧的行从 50 开始，而不是从 0 开始。这里的索引不是从 0 开始，因为 0–49 索引行包含鸢尾花的数据，50–149 索引行包含其他两种花的数据——按作者分类的图像</p></figure><p id="a58b" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">然后，我们重置数据帧的索引。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="ff0b" class="ky kz it nc b gy ng nh l ni nj">X1 = X1.reset_index(drop=True)<br/>y1 = y1.reset_index(drop=True)<br/>y1 -= 1<br/>print(y1.unique())<br/>X1[:5]</span></pre><p id="ca61" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">输出:<br/> <code class="fe nm nn no nc b">[0 1]</code></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/3d5ef5da49e490436e8f93cd78042e71.png" data-original-src="https://miro.medium.com/v2/resize:fit:644/format:webp/1*_6hfz7ezdeVTZrutr8_w8w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">重置索引后的数据帧-作者图片</p></figure><p id="c4d8" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">我们将数据绘制在 2D 图上，并将图形保存为“main.jpg”。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="d461" class="ky kz it nc b gy ng nh l ni nj">fig = plt.figure()<br/><br/>plt.scatter(X1[k1][y1==0], X1[k2][y1==0], c='r')<br/>plt.scatter(X1[k1][y1==1], X1[k2][y1==1], c='c')<br/><br/>plt.xlabel(k1)<br/>plt.ylabel(k2)<br/>fig.savefig('main.jpg', dpi=100)<br/>plt.show()<!-- --> </span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/72f7c0ad11c9aa60e3ab263de1b8ad35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*f63_0Nyayk2BlQzag7xz1Q.jpeg"/></div></figure><p id="10a6" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">我们在全部数据上训练线性 SVM 核，以理解当使用全部数据时我们将得到的 SVM 模型。由于这是一个线性 SVM 模型，决策边界(分隔两个类别的边界)将是一条直线。我们看决策边界的斜率和截距。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="497b" class="ky kz it nc b gy ng nh l ni nj">y1 = y1.astype(dtype=np.uint8)</span><span id="af4d" class="ky kz it nc b gy ns nh l ni nj">clf0 = LinearSVC()<br/>clf0.fit(X1, y1)</span><span id="8414" class="ky kz it nc b gy ns nh l ni nj">LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,<br/>          intercept_scaling=1, loss='squared_hinge', max_iter=1000,<br/>          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,<br/>          verbose=0)</span><span id="6d24" class="ky kz it nc b gy ns nh l ni nj">print(clf0.coef_)<br/>print(clf0.intercept_)</span></pre><p id="5dbf" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">输出</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="2395" class="ky kz it nc b gy ng nh l ni nj">[[0.2801542  1.70097577]]<br/>[-4.17110884]</span></pre><p id="b931" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">这里，我们绘制了决策边界以及所有数据点。在这种情况下，决策边界是一条直线(因为模型是线性 SVM)。<code class="fe nm nn no nc b">clf0</code>是受过训练的量词(SVM)。我们从<code class="fe nm nn no nc b">clf0.coef_</code>和<code class="fe nm nn no nc b">clf0.intercept</code>得到系数。<code class="fe nm nn no nc b">a0, b0, c0</code>是线的系数(线方程:<code class="fe nm nn no nc b">a0*x + b0*y + c0 = 0; y = -(a0*x + c0)/b0</code>)。我们在这条线上得到 100 个点(<code class="fe nm nn no nc b">lx0- has the x-corrdinates; ly0- has the y-coordinates</code>)并绘制它们(一条洋红色的线)。让我们称之为<em class="nt">理想决策边界</em>(当我们使用不同种类的 SVM 核时，这可能不是所有 SVM 的理想决策边界，但是，它确实是一个好的决策边界)。<br/>然后，我们根据类别用青色和红色绘制数据集中的所有点。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="4ebe" class="ky kz it nc b gy ng nh l ni nj">xmin, xmax = X1[k1].min(), X1[k1].max()<br/>ymin, ymax = X1[k2].min(), X1[k2].max()<br/>stepx = (xmax - xmin)/99<br/>stepy = (ymax - ymin)/99</span><span id="ab7a" class="ky kz it nc b gy ns nh l ni nj">a0, b0, c0 = clf0.coef_[0, 0], clf0.coef_[0, 1], clf0.intercept_</span><span id="dbec" class="ky kz it nc b gy ns nh l ni nj"># Formula for reference<br/># a*x + b*y + c = 0<br/># y = -(a*x + c)/b<br/><br/>lx0 = [xmin + stepx * i for i in range(100)]<br/>ly0 = [-(a0*lx0[i] + c0)/b0 for i in range(100)]<br/><br/>plt.figure()<br/><br/>plt.scatter(X1[k1][y1==0], X1[k2][y1==0], c='r')<br/>plt.scatter(X1[k1][y1==1], X1[k2][y1==1], c='c')<br/><br/>plt.plot(lx0, ly0, c='m')<br/><br/>plt.xlabel(k1)<br/>plt.ylabel(k2)<br/><br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/6cbfe601f0f6d00653a6a4c2e7b429c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*FrH5-rl01kqo2Lq-5A3pQA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">紫线是 SVM 模型的决策边界。红色和青色点是两个类别。</p></figure><p id="c7ed" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">现在，我们将数据集分成两部分—池(80%)和测试(20%)。我们使用随机状态 1。数据集的分割取决于随机状态。<br/>(我做过随机状态为 1 后主动学习 5 次迭代和随机状态为 2 后主动学习算法 20 次迭代的仿真)。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="b6fa" class="ky kz it nc b gy ng nh l ni nj">X_pool, X_test, y_pool, y_test = train_test_split(X1, y1, test_size=0.2, random_state=1)<br/>X_pool, X_test, y_pool, y_test = X_pool.reset_index(drop=True), X_test.reset_index(drop=True), y_pool.reset_index(drop=True), y_test.reset_index(drop=True)<br/># random state 1 5 iterations<br/># random state 2 20 iterations</span></pre><p id="7a6e" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">让我们对两个数据点应用 SVM 的判定函数。通常，对于两类线性 SVM，决策函数为其中一类(决策边界的一侧)输出正值，为另一类(决策边界的另一侧)输出负值，并在决策边界上输出零。<br/>对于线性 SVM，决策函数的大小等于数据点到决策函数的距离。这是因为，如果一个点靠近决策边界，那么它可能是决策边界另一侧的类的异常值。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="5b0f" class="ky kz it nc b gy ng nh l ni nj">clf0.decision_function(X_pool.iloc[6:8])</span></pre><p id="b1ef" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">输出</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="e8cf" class="ky kz it nc b gy ng nh l ni nj">array([-0.55706427,  0.26340314])</span></pre><p id="423d" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">这里，我们看到决策函数对于其中一个点具有负值，对于另一个点具有正值。</p><p id="122d" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">函数<code class="fe nm nn no nc b">find_most_ambiguous</code>给出了分类器最不明确的点。对于 SVM 分类器，如果数据点更接近决策边界，并且如果数据点更远离决策边界，则不那么模糊，而不管该点在决策边界的哪一侧。因此，<code class="fe nm nn no nc b">find_most_ambiguous</code>给出了最接近决策边界的未标记点。<br/> <code class="fe nm nn no nc b">clf- classifier (trained SVM model); unknown_indexes- indexes from the dataset that are the unlabelled/unknown pool</code></p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="f2a3" class="ky kz it nc b gy ng nh l ni nj">def find_most_ambiguous(clf, unknown_indexes):<br/>    <br/>    ind = np.argmin(np.abs( <br/>        list(clf0.decision_function(X_pool.iloc[unknown_indexes]) )<br/>        ))<br/>    return unknown_indexes[ind]</span></pre><p id="2d64" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">函数<code class="fe nm nn no nc b">plot_svm</code>用于绘制以下内容:<br/> SVM 判定边界、根据分类来自列车数据的数据点以及未知样本池中的数据点。<br/> <code class="fe nm nn no nc b">clf- classifier (trained SVM model).</code> <br/> <code class="fe nm nn no nc b">train_indexes- Indexes of the dataset that are the train data points.<br/>unknown_indexes- Indexes of the dataset that are the unlabelled pool data points.<br/>title- The title of the plot.<br/>name- the name of the image file that when the plot is saved to a file.<br/>new_index- This is the index of the most ambiguous point in the unlabelled pool</code></p><p id="3f9a" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">在这个函数中，首先，我们分别从<code class="fe nm nn no nc b">train_indexes</code>和<code class="fe nm nn no nc b">unknown_indexes</code>获取列车数据(<code class="fe nm nn no nc b">X_train, y_train</code>)和未标记数据(<code class="fe nm nn no nc b">X_unk, y_unk</code>)。我们用黑色标出了池中所有未标记的点。然后，我们根据分类标签，用不同的颜色(红色和青色)绘制来自训练数据的所有点。我们从 clf.coef_ 和 clf.intercept 中得到决策边界(直线)的系数，利用这个和直线的公式，我们画出这条线(绿色虚线)。我们还有前面计算的<em class="nt">理想决策边界</em>。这条线也用洋红色标出。<br/>最后，我们绘制出<code class="fe nm nn no nc b">new_index</code>点，也就是最模糊的点(黄星)。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="824b" class="ky kz it nc b gy ng nh l ni nj">def plot_svm(clf, train_indexes, unknown_indexes, new_index = False, title = False, name = False):<br/>    X_train = X_pool.iloc[train_indexes]<br/>    y_train = y_pool.iloc[train_indexes]<br/><br/>    X_unk = X_pool.iloc[unknown_indexes]<br/><br/>    if new_index:<br/>        X_new = X_pool.iloc[new_index]<br/><br/>    a, b, c = clf.coef_[0, 0], clf.coef_[0, 1], clf.intercept_</span><span id="e0cb" class="ky kz it nc b gy ns nh l ni nj">    # Straight Line Formula<br/>    # a*x + b*y + c = 0<br/>    # y = -(a*x + c)/b<br/><br/>    lx = [xmin + stepx * i for i in range(100)]<br/>    ly = [-(a*lx[i] + c)/b for i in range(100)]<br/><br/>    fig = plt.figure(figsize=(9,6))<br/><br/>    # plt.scatter(x[k1][setosa], x[k2][setosa], c='r')<br/>    plt.scatter(X_unk[k1], X_unk[k2], c='k', marker = '.')<br/>    plt.scatter(X_train[k1][y_train==0], X_train[k2][y_train==0], c='r', marker = 'o')<br/>    plt.scatter(X_train[k1][y_train==1], X_train[k2][y_train==1], c='c', marker = 'o')<br/>    <br/><br/>    plt.plot(lx, ly, c='m')<br/>    plt.plot(lx0, ly0, '--', c='g')<br/><br/>    if new_index:<br/>        plt.scatter(X_new[k1], X_new[k2], c='y', marker="*", s=125)<br/>        plt.scatter(X_new[k1], X_new[k2], c='y', marker="*", s=125)<br/>        plt.scatter(X_new[k1], X_new[k2], c='y', marker="*", s=125)<br/>        plt.scatter(X_new[k1], X_new[k2], c='y', marker="*", s=125)<br/>        plt.scatter(X_new[k1], X_new[k2], c='y', marker="*", s=125)<br/><br/>    if title:<br/>        plt.title(title)<br/>    <br/>    plt.xlabel(k1)<br/>    plt.ylabel(k2)<br/><br/>    if name:<br/>        fig.set_size_inches((9,6))<br/>        plt.savefig(name, dpi=100)<br/><br/>    plt.show()</span></pre><p id="34f1" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">我们将集合的前 10 个指数/数据点作为初始训练数据，其余 70 个点作为未标记的样本。我们用所有未标记的样本、<em class="nt">理想决策边界</em>和 10 个训练数据点创建开始图。<br/>然后，我们在训练数据上训练一个 SVM，我们找到最不明确的点并创建一个新的图(“迭代 0”)，用这个点作为一个黄色的星，并且还绘制训练的 SVM 的决策边界。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="1224" class="ky kz it nc b gy ng nh l ni nj">train_indexes = list(range(10))<br/>unknown_indexes = list(range(10, 80))<br/>X_train = X_pool.iloc[train_indexes]<br/>y_train = y_pool.iloc[train_indexes]<br/>clf = LinearSVC()<br/>clf.fit(X_train, y_train)<br/><br/># folder = "rs1it5/"<br/>folder = "rs2it20/"<br/># folder = "rs1it20/"<br/><br/>try:<br/>    os.mkdir(folder)<br/>except:<br/>    pass<br/><br/>filenames = ["ActiveLearningTitleSlide2.jpg"] * 2<br/><br/>title = "Beginning"<br/># name = folder + ("rs1it5_0a.jpg")<br/>name = folder + ("rs2it20_0a.jpg")<br/>plot_svm(clf, train_indexes, unknown_indexes, False, title, name)<br/><br/>filenames.append(name)<br/><br/>n = find_most_ambiguous(clf, unknown_indexes)<br/>unknown_indexes.remove(n)<br/><br/>title = "Iteration 0"<br/>name = folder + ("rs1it5_0b.jpg")<br/># name = folder + ("rs2it20_0b.jpg")<br/>filenames.append(name)<br/>plot_svm(clf, train_indexes, unknown_indexes, n, title, name)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/eb0f2f775c98016df0c58bd6f4d1c5a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GvwFXmd_v2rzu5uPtItJew.jpeg"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/2c9f863589ca810cd25bd81839d87089.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g-fObNd7rsj7UMCO3s0wrw.jpeg"/></div></div></figure><p id="35c8" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">接下来，我们运行主动学习算法 5 次迭代。在每一个阶段中，我们将最模糊的点添加到训练数据中，并训练一个 SVM，在这个阶段找到最明确的点，然后创建一个图。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="d468" class="ky kz it nc b gy ng nh l ni nj">num = 5<br/># num = 20<br/>t = []<br/>for i in range(num):<br/>    <br/>    train_indexes.append(n)<br/>    X_train = X_pool.iloc[train_indexes]<br/>    y_train = y_pool.iloc[train_indexes]<br/>    clf = LinearSVC()<br/>    clf.fit(X_train, y_train)<br/>    title, name = "Iteration "+str(i+1), folder + ("rs1it5_%d.jpg" % (i+1))<br/>    # title, name = "Iteration "+str(i+1), folder + ("rs2it20_%d.jpg" % (i+1))<br/><br/>    n = find_most_ambiguous(clf, unknown_indexes)<br/>    unknown_indexes.remove(n)<br/>    plot_svm(clf, train_indexes, unknown_indexes, n, title, name)<br/>    filenames.append(name)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/6cd7c2daf6d9c8318e0cc1027e08a138.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*babY4sbiOWaDTiffoaXmKQ.jpeg"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/8a6278e545fee273c3f1f7f30623058c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7dhJFAlG9wSnN_FHjln97A.jpeg"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/c5225f54bd5e11b8259ff0cf5966e643.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WkQemcfkuuvMFMuafiKiKQ.jpeg"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/618bea0511c6d170646fc79e89eccf56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pVkxQYhplMYGtueMD7r6VA.jpeg"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/562442b2b00d68e7da5aa69895b8687c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rraA5RX9CP0hO5JStBpU5g.jpeg"/></div></div></figure><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="13a8" class="ky kz it nc b gy ng nh l ni nj">images = []<br/>for filename in filenames:<br/>    images.append(io.imread(filename))<br/>io.mimsave('rs1it5.gif', images, duration = 1)<br/># io.mimsave('rs2it20.gif', images, duration = 1)<br/># io.mimsave('rs1it20.gif', images, duration = 1)<br/>try:<br/>    os.mkdir('rs1it5')<br/>#    os.mkdir('rt2it20')<br/>except:<br/>    pass<br/>os.listdir('rs1it5')</span></pre><p id="7c6d" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">输出</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="7438" class="ky kz it nc b gy ng nh l ni nj">['ActiveLearningTitleSlide2.jpg',<br/> 'ActiveLearningTitleSlide2.jpg',<br/> 'rs1it5/rs1it5_0a.jpg',<br/> 'rs1it5/rs1it5_0b.jpg',<br/> 'rs1it5/rs1it5_1.jpg',<br/> 'rs1it5/rs1it5_2.jpg',<br/> 'rs1it5/rs1it5_3.jpg',<br/> 'rs1it5/rs1it5_4.jpg',<br/> 'rs1it5/rs1it5_5.jpg']</span></pre><p id="ab82" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">现在，我们显示 GIF 文件</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="583b" class="ky kz it nc b gy ng nh l ni nj">with open('rs1it5.gif','rb') as f:<br/>    display(Image(data=f.read(), format='gif'))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/4c6781daf44a2b046f4ec558c859e50b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*7bksSQYwbOI7SGrI_A8iyA.gif"/></div></div></figure><p id="ed1c" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">请注意，在上面的 GIF 中，随着我们添加更多的点(迭代次数)，绿线越来越接近<em class="nt">理想决策边界</em>。</p><p id="0e54" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated"><em class="nt">请注意，在上面的一些代码块和下面的代码块中，有一些带有数字 20 的注释行。这是为了运行 20 次迭代，而不是 5 次迭代。要运行它，我们必须用 5 注释所有的行，用 20 取消注释所有的行。<br/> </em>当我们运行 20 次主动学习算法的迭代时，我们得到下面的 GIF。请注意，为此，我们在将数据分为测试和池时使用了 2 作为随机状态。<br/>注意，随着下面 GIF 中迭代次数的增加，绿线越来越接近<em class="nt">理想决策边界</em>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/ae62ecda57e5ae42712531d2be292997.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*HK031F-ah-YfQCoSwGQPDw.gif"/></div></div></figure><p id="1fcf" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">注意，主动学习可以用于其他机器学习/深度学习模型(不仅仅是支持向量机)。<br/>另外，第一个<code class="fe nm nn no nc b">ActiveLearningTitleSlide2.jpg</code>是我用画图工具创建的一个简单的图像，和其他图像的长宽比一样(900x600)。</p></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h2 id="9cae" class="ky kz it bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">结论</h2><p id="5045" class="pw-post-body-paragraph lu lv it lw b lx ly ju lz ma mb jx mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">我们看到，我们已经训练了一个好的分类器，也就是说，一个分类器的性能接近用所有点训练的 SVM，尽管我们使用了非常少量的点。这就是如何使用主动学习来创建标记更少数据点的健壮模型。</p></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><p id="96a3" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">完整的代码可以在<a class="ae ms" href="https://gist.github.com/akhileshravi/198bc38d66547affa4ca0eb019c1ac13" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上获得</p><p id="8b30" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">你可以看看我的<a class="ae ms" href="https://bit.ly/ai-n-ml-youtube" rel="noopener ugc nofollow" target="_blank"> YouTube 频道</a>上解释 AI 和 ML 概念的视频。</p></div></div>    
</body>
</html>