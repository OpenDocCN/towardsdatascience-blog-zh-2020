<html>
<head>
<title>Linear Regression and its assumptions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归及其假设</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/linear-regression-and-its-assumptions-ef6e8db4904d?source=collection_archive---------9-----------------------#2020-01-24">https://towardsdatascience.com/linear-regression-and-its-assumptions-ef6e8db4904d?source=collection_archive---------9-----------------------#2020-01-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/0f322b45b27f07b9cb4bff544364969a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*btTIPVcQGCINIk_ItuCLTw.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">来源:stocksnap.io</p></figure><div class=""/><div class=""><h2 id="0224" class="pw-subtitle-paragraph kf jh ji bd b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw dk translated">举例说明了线性回归的假设，如共线性、多元正态性、自相关、同异方差</h2></div><p id="a650" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">上周，我在帮助我的朋友准备一个数据科学家职位的面试。我在网上搜索了相关问题，发现问题“<strong class="kz jj">数据科学涉及的假设有哪些？“T1”在我的搜索中出现得非常频繁。尽管大多数博客都提供了这个问题的答案，但细节仍然缺失。我研究了基本假设，并希望与您分享我的发现。首先，我会简单地告诉你这些假设，然后举例说明。</strong></p><p id="528f" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">线性回归模型的<strong class="kz jj">基本假设</strong>如下:</p><ul class=""><li id="5ab0" class="lt lu ji kz b la lb ld le lg lv lk lw lo lx ls ly lz ma mb bi translated">自变量(X)和因变量(y)之间存在<strong class="kz jj">线性关系</strong></li><li id="6a87" class="lt lu ji kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated">不同特征之间很少或没有多重共线性</li><li id="3544" class="lt lu ji kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated">残差应呈正态分布(<strong class="kz jj">多变量正态性</strong>)</li><li id="7e49" class="lt lu ji kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated">残基之间很少或没有自相关</li><li id="b406" class="lt lu ji kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated"><strong class="kz jj">误差的同方差</strong></li></ul><p id="b073" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">现在，让我们来看看如何验证一个假设，以及在假设不成立的情况下应该做些什么。让我们逐一关注这些要点。我们将获取一个包含不同葡萄酒特征的数据集。该数据集已被数据科学家同事用于多个示例，并由UCI机器学习知识库公开提供(<a class="ae mh" href="https://archive.ics.uci.edu/ml/datasets/Wine+Quality" rel="noopener ugc nofollow" target="_blank"> Wine_quality data </a>或来自<a class="ae mh" href="https://drive.google.com/file/d/195gkZ5cTZL11L308MHc7EyBbAoiB4xqf/view" rel="noopener ugc nofollow" target="_blank">此处</a>的CSV文件)。我将使用的另一个数据集是温度数据集(可从<a class="ae mh" href="https://drive.google.com/file/d/1fiHg5DyvQeRC4SyhsVnje5dhJNyVWpO1/view" rel="noopener ugc nofollow" target="_blank">此处</a>获得)。我在纳格什·辛格·肖汉的一篇文章中偶然发现了这些数据集。我会建议你下载数据，用它来寻找行数，列数，是否有NaN值的行等。熊猫是一个阅读CSV和处理数据的非常好的工具。如果您不熟悉熊猫，请尝试使用以下方式阅读该文件:</p><figure class="mj mk ml mm gt iv gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/ba7cc647bcfa5397c47ac450db87e5d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*GmENtYICfY13Uo7OyqIDJA.png"/></div></figure><p id="f5a8" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">现在可以用，dataset . head()/dataset . tail()/dataset . describe等来玩数据了。</p><ol class=""><li id="d3fe" class="lt lu ji kz b la lb ld le lg lv lk lw lo lx ls mn lz ma mb bi translated"><strong class="kz jj">线性关系</strong></li></ol><p id="f94f" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">自变量和因变量之间应该存在线性关系。这很容易用散点图来验证。我将使用温度数据集来显示线性关系。您可以绘制Tmax vrs T_min(或T_avg vrs T_min ),如图1所示。如果你已经处理过数据，你可能已经观察到有一个月列，因此我们甚至可以根据月份标记(颜色代码)散点图，只是为了看看不同月份的温度是否有明显的区别(图1b)。</p><figure class="mj mk ml mm gt iv gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/530f206a2dbc50c5036e590d73c448ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*-zh3t_u7ywzDbcwWh_FcGg.png"/></div></figure><p id="8505" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">输出应该类似于:</p><figure class="mj mk ml mm gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mp"><img src="../Images/e26811cf04113be8472725a2efac86cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sSAxRJdAJjNzpfsvb60HzA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图1</p></figure><p id="d837" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">这里可以观察到T_max和T_min遵循线性趋势。你可以想象一条直线穿过数据。因此，我们已经确保我们的数据遵循第一个假设。</p><p id="ccaa" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">如果数据不是线性的呢？</p><ul class=""><li id="f5c4" class="lt lu ji kz b la lb ld le lg lv lk lw lo lx ls ly lz ma mb bi translated">也许用线性模型拟合数据是一个<strong class="kz jj">错误的想法</strong>。它可能更适合多项式模型(非线性回归)。</li><li id="0e85" class="lt lu ji kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated"><strong class="kz jj">数据转换</strong>，如果y似乎是x的指数，那么在y和log(x)之间画一条曲线怎么样(或者y对x的平方)。现在你可以对这些数据进行线性回归。但是你为什么要这么做呢？因为你(我也是)比非线性回归更懂线性回归。我们已经为线性回归、假设验证等建立了许多工具，这些工具对于非线性回归可能并不容易获得。此外，一旦你拟合了y和变换后的x之间的线性回归，就不难回到原来的y对x的关系。</li></ul><p id="3e44" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated"><strong class="kz jj"> 2。不同特征之间没有多重共线性</strong></p><p id="5f32" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated"><strong class="kz jj">为什么‘无多重共线性’</strong>？</p><p id="7e4f" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">当我们进行线性回归分析时，我们在寻找y = mx + c类型的解，其中c是截距，m是斜率。“m”的值决定了将x改变1时y将改变多少。对于多元线性回归，同样的关系适用于以下等式:y = m1x1 +m2x2 +m3x3 … + c。理想情况下，m1表示y在改变x1时会改变多少，但如果x1的改变会改变x2或x3呢？在这种情况下，y和m1(或m2、m3等)之间的关系将非常复杂。</p><p id="f86c" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated"><strong class="kz jj">如何检查‘多重共线性’</strong>？</p><p id="7e79" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">Seaborn提供了一个pairplot函数，它可以绘制变量之间的属性。这些图是散点图，我们需要看看这些属性是否呈现线性关系。这是可视化和感受不同属性的线性关系的最简单的工具，但只有当涉及的要素数量限制在10-12个时才是好的。在下一节中，我们将讨论如果涉及到更多的特性该怎么办。让我们先画出我们的配对图。为此，我将使用Wine_quality数据，因为它具有高度相关的特性(图2)。</p><figure class="mj mk ml mm gt iv gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/750ae4e9d804eff8eca82d3953bfe454.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*tGlgsjUtMMvP4X0B7rUFjw.png"/></div></figure><p id="d945" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">输出应该是11x11的图形，如下所示:</p><figure class="mj mk ml mm gt iv gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/a1332c8486620d5bc03bc4abfb899c26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*oijJUQA_g-YtxBG6skIzHA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图2</p></figure><p id="6867" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">如果你观察像<em class="ms"> pH值</em>和<em class="ms">固定酸度</em>显示线性相关性(具有负协方差)。如果你观察完整的情节，你会发现</p><ul class=""><li id="153c" class="lt lu ji kz b la lb ld le lg lv lk lw lo lx ls ly lz ma mb bi translated"><em class="ms">固定酸度</em>与<em class="ms">柠檬酸</em>、<em class="ms">密度</em>和<em class="ms">酸度</em>相关</li><li id="1a09" class="lt lu ji kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated"><em class="ms">挥发性酸度</em>与<em class="ms">柠檬酸</em>相关</li></ul><p id="48a7" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">我让你去寻找其他的共线性关系。让我们<strong class="kz jj">绕道了解一下这种共线性的原因</strong>。如果你还记得你的高中化学，pH值被定义为</p><blockquote class="mt mu mv"><p id="4cc7" class="kx ky ms kz b la lb kj lc ld le km lf mw lh li lj mx ll lm ln my lp lq lr ls im bi translated">pH =-log[H+]=-log(酸的浓度)</p></blockquote><p id="d207" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">由此很直观的得出pH值和柠檬酸或挥发酸度是负相关的。</p><p id="4c50" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">本练习还提供了一个<strong class="kz jj">关于数据的领域知识如何帮助更有效地处理数据的示例</strong>。大概这就是数据科学对所有科学领域的科学家开放的原因。</p><p id="c926" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">不同特征的共线程度如何？</p><p id="9d9d" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">在上一节中，我们绘制了不同的要素，以检查它们是否共线。在本节中，我们将回答什么是共线性的度量？</p><p id="65e5" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">我们可以测量相关性(<strong class="kz jj">注意“相关性”</strong>不是<strong class="kz jj">“共线性”</strong>)，如果两个特征之间的绝对相关性很高，我们可以说这两个特征是共线的。为了测量不同特征之间的相关性，我们使用相关矩阵/热图。为了绘制热图，我们可以使用seaborn的热图函数(图3)。</p><figure class="mj mk ml mm gt iv gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/72611c34963bef1b9eac1b0765de6ae8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*G8UGXY_-gNlksanx7UAnjQ.png"/></div></figure><p id="3963" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">输出应为彩色编码矩阵，并在网格中标注相关性:</p><figure class="mj mk ml mm gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi na"><img src="../Images/a0677834e49d846e93b21817ecc064ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sIuJzVeZ06r2jILi183hgQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图3</p></figure><p id="e564" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">现在，根据您的统计知识，您可以决定一个阈值，如0.4或0.5，如果相关性大于此阈值，则认为是一个问题。与其在这里给出一个明确的答案，我不如向你提一个问题。这个相关阈值的理想值应该是多少？现在，假设您的数据集包含10，000个示例(或行),如果数据集包含100，000个或1000个示例，您会改变答案吗？也许你可以在评论中给出你的答案。</p><p id="095a" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated"><strong class="kz jj">相关性高怎么办</strong>？</p><p id="d9ca" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">假设您已经列出了不同特征之间的共线关系。现在怎么办？首先要考虑的是一个特性是否可以被删除。如果两个特征直接相关，例如酸度和pH值，我会毫不犹豫地删除其中一个。因为pH只不过是酸量的负对数。这就像在两个不同的尺度上拥有相同的信息。但更大的问题是:</p><ul class=""><li id="99a0" class="lt lu ji kz b la lb ld le lg lv lk lw lo lx ls ly lz ma mb bi translated">哪个功能可以去除pH值或酸量？</li><li id="31fe" class="lt lu ji kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated">接下来应该删除哪个功能？</li></ul><p id="2353" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">这个我没有明确的答案。我所学的是计算方差通货膨胀系数VIF。它被定义为公差的倒数，而公差是1- R2。虽然我将讨论VIF，但通常有以下方法可用于处理共线性:</p><p id="3397" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">a)贪婪淘汰</p><p id="f833" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">b)递归特征消除</p><p id="9378" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">c)套索正则化(L1正则化)</p><p id="a5ec" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">d)主成分分析</p><p id="2b97" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">我们将使用VIF值来查找应该首先消除的要素。然后，我们将重新计算VIF，以检查是否有任何其他功能需要消除。如果我们在相关标度上工作，不同变量之间的相关性在消除前后不会改变。VIF给出了这个优势来衡量淘汰的效果。我们使用statsmodels，oulier_influence模块来计算VIF。此模型要求我们在模型中添加一个常量变量来计算VIF，因此在代码中我们使用“add_constant(X)”,其中X是包含所有要素的数据集(质量列被删除，因为它包含目标值)。</p><figure class="mj mk ml mm gt iv gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/60d06aecb071a23ea3702d1fcd8c1a9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/format:webp/1*BhdjbDRR_OeP1gINxHf6-w.png"/></div></figure><p id="63b1" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">我采用的方法是消除具有最高VIF的要素，然后重新计算VIF。如果VIF值大于10，则移除VIF次高的要素，否则我们将不再处理多重共线性。</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><p id="14ad" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">为了检验其他假设，我们需要进行线性回归。我已经使用scikit学习线性回归模块来做同样的事情。我们将模型分为测试和训练模型，使用训练数据拟合模型，并使用测试数据进行预测。</p><figure class="mj mk ml mm gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nj"><img src="../Images/ef0a240448130a65225abb0f0d343887.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cVc1NuesCWm9BPg9XWtS2g.png"/></div></div></figure></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><p id="9eaf" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated"><strong class="kz jj"> 3。</strong> <strong class="kz jj">多元常态</strong></p><p id="60dc" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">残差应该是正态分布的。这一点可以通过绘制QQ图很容易地检查出来。我们将使用statsmodels，qqplot来绘制它。我们首先导入qqplot属性，然后向它提供残差值。我们得到的Q-Q图如图4所示。</p><figure class="mj mk ml mm gt iv gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/a0164645b97a67e3ac87a56f377d0e63.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*9D-2aJl8k35hQ8zciedZsw.png"/></div></figure><figure class="mj mk ml mm gt iv gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/f108e40cc299332dee52fdfd4ced8dc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1106/format:webp/1*UXF61Om9-JrFQIETcXW3EA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图4</p></figure><p id="11cb" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">理想情况下，它应该是一条直线。这种模式表明我们的模型有严重的问题。我们不能依赖这个回归模型。让我们检查一下其他假设是否成立。</p><p id="72f8" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated"><strong class="kz jj"> 4。无自相关</strong></p><p id="1674" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">Durbin Watson的d检验可以帮助我们分析残基之间是否存在任何自相关。既然网上有很多关于这个测试的资料，我就给你提供另一种方式。在图5中显示了每个属性的残基图，以检查残基是否显示任何相关性。在下面的代码中，dataset2是X_test的pandas数据帧。</p><figure class="mj mk ml mm gt iv gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/a193cad770b949c04b59d15fdb6a1e2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*JWwfHCOsQyy-jncVtZQ8KA.png"/></div></figure><p id="cd53" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">输出将是一系列图(测试数据集的1个图/列)</p><figure class="mj mk ml mm gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mi"><img src="../Images/0308772a028b8e856ab4110d4e49b7b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*vosYaJO8DPNNSZifrQsAig.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图5</p></figure><p id="4339" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">图5显示了数据是如何在没有任何特定模式的情况下很好地分布的，从而验证了残留物没有自相关。我们需要在所有的图中验证这一点(X轴是特征，所以有多少个特征就有多少个图)。</p><p id="f5c9" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated"><strong class="kz jj"> 5。同质性</strong></p><p id="d592" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">用拟合线绘制误差散点图将显示残留物是否与该线形成任何模式。如果是，那么数据不是异方差的或者数据是异方差的。而如果散点图不形成任何模式，并且随机分布在拟合线周围，则残差是均方的。</p><p id="5f02" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">为了绘制关于拟合线的残差(y _ test-y _ pred ),可以写出拟合线的方程(通过使用*。coeff_和*。拦截)。使用此等式获得y值，但将这些y值绘制在X轴上，因为我们想要绘制关于拟合线的残差(X轴应该是拟合线)。现在可以观察到残留物的模式。下面是相同的代码:</p><figure class="mj mk ml mm gt iv gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/076813fe5a52d4ac517bf98d200af8f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*tqsS7GjFMWCJxU1lQYXyLQ.png"/></div></figure><p id="bf0f" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">如果您是python新手，并且希望远离编写代码，您可以使用<em class="ms"> yellowbrick regressor </em>的“Redidualsplot”模块来执行相同的任务。在这里，您只需要适应测试和训练数据，其余的将由模型本身完成。在这里，我使用scikit learn的LinearRegression()模型，您可以选择使用不同的模型。</p><figure class="mj mk ml mm gt iv gh gi paragraph-image"><div class="gh gi no"><img src="../Images/ce2c516d91c6f3933483ffc70e2b4a6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:826/format:webp/1*9uel_STn5PXhTpeW9U09Gg.png"/></div></figure><p id="b73f" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">无论如何，使用上述任何一种方法都会得到相同的结果，如图6所示。</p><figure class="mj mk ml mm gt iv gh gi paragraph-image"><div class="gh gi np"><img src="../Images/1c9ee6802226ab0511cda2c7d0ea447b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1258/format:webp/1*o_ZB56AEOJV0JqptPrOF-g.png"/></div></figure><p id="f45d" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">这里的残留物显示了一个清晰的模式，表明我们的模型有问题。</p><p id="306c" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">因此，我们的模型无法支持多元正态性和同方差假设(分别见图4和图6)。这表明，要么数据不适合线性回归，要么给定的特征不能基于给定的特征真正预测葡萄酒的质量。但这是展示线性回归基本假设的一个很好的练习。如果你对这个问题有更好的解决办法，请告诉我。</p><p id="0bf1" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">欢迎建设性的批评/建议。</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><p id="04c3" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">本主题的其他好读物:</p><ol class=""><li id="9bc8" class="lt lu ji kz b la lb ld le lg lv lk lw lo lx ls mn lz ma mb bi translated">如何在python上检查你的线性回归模型的质量？<a class="ae mh" href="https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Regression/Regression_Diagnostics.ipynb" rel="noopener ugc nofollow" target="_blank">链接</a></li><li id="08ed" class="lt lu ji kz b la mc ld md lg me lk mf lo mg ls mn lz ma mb bi translated">线性回归算法的假设。<a class="ae mh" rel="noopener" target="_blank" href="/assumptions-of-linear-regression-algorithm-ed9ea32224e1">链接</a></li></ol></div></div>    
</body>
</html>