# 不怕机器学习——如何用不到 10 行代码对文本进行分类

> 原文：<https://towardsdatascience.com/no-fear-of-machine-learning-classify-your-textual-data-in-less-than-10-lines-of-code-2360d5cec798?source=collection_archive---------34----------------------->

## 文本数据的机器学习导论

![](img/d7fd6d9a80a985a39e782052463c0728.png)

图片来自 [Pixaby](https://pixabay.com)

这篇文章建立在我前两篇文章的基础上，在那两篇文章中，我分享了一些关于如何[开始使用 Python(或 R)](/how-to-get-started-with-data-analysis-and-data-science-in-python-and-r-a-pragmatic-approach-a6ff498dec61) 进行数据分析的技巧，并解释了一些关于 Python 中文本分析的[基本概念。在这篇文章中，我想更进一步，谈谈如何在机器学习的帮助下开始文本分类。](/getting-started-with-text-analysis-in-python-ca13590eb4f7)

写这篇文章背后的动机和之前的一样:因为有足够多的人受困于对给定任务来说不是最佳的工具，例如使用 MS Excel 进行文本分析。我想鼓励人们使用 Python，不要害怕编程，尽可能多地自动化他们的工作。

说到自动化，在我的上一篇文章中，我介绍了一些如何从文本数据中提取信息的方法，以铁路事故报告为例。我展示了如何从数据集中提取最常见的词(以获得数据的整体概念)，如何查找特定的词，如“损害”或“危险材料”，以记录损害是否发生，以及如何在正则表达式的帮助下提取损害的成本，而不是必须阅读每个事件文本。

但是，要找的词太多怎么办？以犯罪报告为例，如果您对未成年人是否参与其中感兴趣，该怎么办？你可以用很多不同的词来描述未成年人:*未成年人、未成年人、青年、少年、少年、青春期*等。记住所有这些单词将是相当乏味的。但是，如果您已经标记了过去的数据，有一个简单的解决方案。假设您有一个手动标记的以前犯罪报告的数据集，您可以训练一个分类器，该分类器可以学习标记的犯罪报告的模式，并将它们与标签进行匹配(是否涉及未成年人，此人是否喝醉，等等)。如果您得到一批新的未标记的犯罪报告，您可以对新数据运行分类器，并自动标记报告，而不必阅读它们。听起来很棒，不是吗？如果我告诉你这只用 7 行代码就可以完成，会怎么样？令人震惊，我知道。

在这篇文章中，我将回顾机器学习和自然语言处理(NLP)中的一些主要概念，并链接文章以供进一步阅读。需要一些文本预处理的知识，比如停用词移除和词条满足，我在我的[上一篇文章](/getting-started-with-text-analysis-in-python-ca13590eb4f7)中描述过。然后，我将展示一个真实世界的例子，使用我在最近的博士研究中获得的数据集，如何训练一个分类器。

# 分类问题

分类的任务是识别一个新观察值属于哪一组类别。一个简单的例子是将电子邮件分类为垃圾邮件和垃圾邮件(二进制分类)。如果你有两个以上的类别，这就是所谓的多类分类。有几种流行的分类算法，我不会深入讨论，但邀请您查看提供的链接并进行自己的研究:

*   逻辑回归(查看此[视频](https://www.youtube.com/watch?v=yIYKR4sgzI8&vl=en)和此[文章](/understanding-logistic-regression-9b02c2aec102)获得详细解释)
*   k-最近邻(KNN) ( [视频](https://www.youtube.com/watch?v=HVXime0nQeI)，[文章](/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761))
*   支持向量机(SVM) ( [视频](https://www.youtube.com/watch?v=efR1C6CvhmE)，[文章](https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-theory-f0812effc72))
*   朴素贝叶斯([视频](https://www.youtube.com/watch?v=O2L2Uv9pdDA)，[文章](https://medium.com/analytics-vidhya/naive-bayes-classifier-for-text-classification-556fabaf252b))
*   决策树([视频](https://www.youtube.com/watch?v=7VeUPuFGJHk)，[文章](https://medium.com/@chiragsehra42/decision-trees-explained-easily-28f23241248))
*   神经网络([视频](https://www.youtube.com/watch?v=aircAruvnKk)，[文章](/first-neural-network-for-beginners-explained-with-code-4cfd37e06eaf))

# 培训和测试数据

当您收到一封新邮件时，发件人不会将该邮件标记为“垃圾邮件”或“垃圾邮件”。您的电子邮件提供商必须将收到的电子邮件标记为垃圾邮件并将其发送到您的收件箱，或者标记为垃圾邮件并将其发送到垃圾邮件文件夹。为了告诉你的分类器(机器学习模型)在现实世界中工作得有多好，你在开发期间将你的数据分成[个训练集和](https://www.quora.com/In-machine-learning-what-s-the-purpose-of-splitting-data-up-into-test-sets-and-training-sets)个测试集。

假设你有 1000 封邮件被标记为垃圾邮件。如果您使用全部数据训练您的分类器，您就没有数据来判断您的分类器有多准确，因为您没有模型没有看到的任何电子邮件示例。因此，您希望将一些电子邮件排除在训练集之外，让经过训练的模型预测这些被排除的电子邮件的标签(测试集)。通过将预测的标签与实际标签进行比较，您将能够知道您的模型对新数据的概括程度，以及它在现实世界中的表现。

# 以计算机可读格式(数字)表示文本

好了，现在你有了你的数据，你已经把它分成了训练集和测试集，让我们开始训练分类器，不是吗？假设我们正在处理文本数据，我们还需要做一件事。如果我们处理的是数字数据，我们可以将这些数字直接输入分类器。但是计算机不理解文本。文本必须被转换成数字，这被称为*文本矢量化*。做这件事有几种方法，但我只讲一种。查看这些文章，进一步了解 [tf-idf](https://medium.com/acing-ai/what-is-tf-idf-in-feature-engineering-7f1ba81982bd) 和[单词嵌入](/introduction-to-word-embedding-and-word2vec-652d0c2060fa)。

一种流行且简单的利用文本数据进行特征提取的方法被称为文本的词袋模型。让我们以下面这句话为例:

> 苹果很好，但梨也很好，不过，有时我想吃桔子，有时我想吃香蕉

这句引语被用作我们的词汇。这个句子包含 17 个不同的单词。下面三个句子可以用我们的词汇表示为向量:

*   *《我喜欢苹果》*
    【1，0，0，0，0，0，0，0，1，0，1，0，0，0，0，0，0】
*   *“香蕉很棒。香蕉很牛逼，*
    【0，2，1，0，0，0，0，0，0，0，0，0，0，2】
    或者
    【0，1，1，0，0，0，0，0，0，0，0，0，0，1】如果你不在乎一个词出现的频率。
*   *《她吃猕猴桃》*
    【0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0

下面你可以看到表格形式的句子向量。

你可以看到我们计算了词汇中的每个单词在句子的向量表示中出现的频率。不在我们初始词汇表中的单词当然是不知道的，因此最后一句话只包含零。现在你应该能够看到分类器在预测句子的标签时是如何识别模式的。想象一个包含关于不同水果的句子的训练集。在向量表示中，谈论苹果的句子在索引 1 处的值将大于 0，而在向量表示中，谈论香蕉的句子在索引 17 处的值将大于 0。

# **测量精度**

太好了，现在我们已经训练了我们的分类器，我们怎么知道它有多准确呢？这取决于你的数据类型。衡量分类器准确性的最简单方法是将测试集上的预测与实际标签进行比较。如果分类器获得 80/100 的正确率，则准确率为 80%。然而，有几件事需要考虑。我不会讲太多细节，但我会举一个例子来证明我的观点:假设你有一个关于信用欺诈的[数据集](https://www.kaggle.com/mlg-ulb/creditcardfraud)。该数据集包含信用卡交易，并显示两天内发生的交易，其中 284，807 笔交易中有 492 笔欺诈。您可以看到数据集高度不平衡，欺诈仅占所有交易的 0.172%。你可以给所有的交易分配“非欺诈”，并获得 99.98%的准确率！这听起来很棒，但完全忽略了检测欺诈的要点，因为我们准确地识别出了 0%的欺诈案例。

这里有一篇[文章](/various-ways-to-evaluate-a-machine-learning-models-performance-230449055f15)，解释了评估机器学习模型的不同方法。这里的[是另一个](https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets)，描述了如何处理不平衡数据的技术。

# 交叉验证

在介绍编码示例之前，我还想介绍一个概念，那就是交叉验证。有许多很棒的[视频](https://www.youtube.com/watch?v=fSytzGwwBVw)和[文章](/cross-validation-explained-evaluating-estimator-performance-e51e5430ff85)解释了交叉验证，所以，我将再次从准确性评估的角度快速介绍一下。交叉验证通常用于避免模型对训练数据的[过拟合和](/what-are-overfitting-and-underfitting-in-machine-learning-a96b30864690)欠拟合。这是机器学习中的一个重要概念，所以我邀请你仔细阅读。

当将您的数据分成训练集和测试集时，如果您幸运地使用了测试集，并且模型在测试集上的性能高估了您的模型在现实生活中的性能，该怎么办？或者相反，如果你运气不好，你的模型在真实世界的数据上可能比在测试集上表现得更好。因此，为了更全面地了解您的模型的准确性，有必要执行几次不同的训练和测试分割，并对每次迭代获得的不同准确性进行平均。

# 对人们对潜在新冠肺炎疫苗的担忧进行分类。

最初，我想使用来自英国广播公司的公共数据集，该数据集由 2225 篇文章组成，每篇文章都标有 5 个类别:商业、娱乐、政治、体育或技术，并训练一个可以预测新闻文章类别的分类器。然而，通常流行的数据集给你很高的准确性分数，而不必对数据做太多的预处理。笔记本可以在[这里](https://github.com/lisanka93/intro_ML_textdata/blob/master/BBC%20dataset%20and%20COVID-19%20vaccine%20concerns%20text%20classification.ipynb)找到，在这里我演示了不需要对文本数据做任何事情就可以获得 97%的准确率。这很好，但不幸的是，对于现实生活中的大多数问题，这并不奏效。

所以，我使用了我自己的小数据集，这是我在最近的博士研究中收集的。一旦我写完论文，我会把它链接到这里。我收集了一些反对研发新冠肺炎疫苗的人的意见。我部分自动地标记了数据，部分手动地标记了论点所针对的“关注”。毫不奇怪，最普遍的担忧是疫苗的潜在副作用，其次是对政府缺乏信任，以及担心疫苗开发速度过快导致测试不足。

我使用 Python 和 [scikit-learn](https://scikit-learn.org) 库来完成这个任务。Scikit-learn 可以为您做很多繁重的工作，正如本文标题中所述，它允许您用少至 7 行的代码为文本数据编写分类器。所以，我们开始吧！

读入数据后，这是一个 CSV 文件，包含 2 列、参数和指定的关注点，我首先对数据进行预处理。我在我的[上一篇文章中描述了预处理方法。](/getting-started-with-text-analysis-in-python-ca13590eb4f7)我将包含预处理参数的新列添加到数据框中，并将使用预处理参数来训练分类器。

我将参数和它们的标签按 80:20 的比例分为训练集和测试集。Scikit-learn 有一个 [train_test_split 函数](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)，它也可以为你对数据进行分层和洗牌。

接下来，我实例化一个 CountVectoriser，将参数转换成稀疏向量，如上所述。然后，我调用 *fit()* 函数从测试集中的参数中学习词汇，之后，我对参数调用 *transform()* 函数，将每个参数编码为一个向量(scikit-learn 提供了一个同时执行这两个步骤的函数)。现在注意，我只对测试参数调用了 *transform()* 。为什么？因为我不想从测试参数中学习词汇，也不想在分类器中引入偏见。

最后，我实例化了一个多项式朴素贝叶斯，将其拟合到训练参数上，在测试参数上对其进行测试，并打印出准确度分数。差不多 74%。但是如果我们使用交叉验证呢？那么准确率下降到 67%。所以我们只是幸运地拥有随机状态产生的测试数据。随机状态确保您生成的分割是可重复的。

出于好奇，我打印出[笔记本](https://github.com/lisanka93/intro_ML_textdata/blob/master/BBC%20dataset%20and%20COVID-19%20vaccine%20concerns%20text%20classification.ipynb)中的预测，并检查分类器出错的参数，我们可以看到，最令人担忧的“副作用”是错误标记的参数。这是有道理的，因为数据集是不平衡的，而且解决副作用的论点是第二大最受关注的问题，即缺乏政府信任的两倍多。因此，将副作用指定为一个关注点比指定另一个关注点更有可能是正确的。我已经尝试过欠采样，并放弃了一些副作用的论点，但结果并不太好。我鼓励你尝试一下。

我又编写了几个分类器，我们可以看到它们的准确率都在 70%左右。我设法用支持向量机把它提高到 74%,并去掉了大约 30 个副作用参数。我还使用 tensorflow 编写了一个神经网络，这超出了本文的范围，它将准确性提高了近 10%。

我希望这篇文章为您提供了开始对文本数据进行机器学习的必要资源。请随意使用[笔记本](https://github.com/lisanka93/intro_ML_textdata/blob/master/BBC%20dataset%20and%20COVID-19%20vaccine%20concerns%20text%20classification.ipynb)中的任何代码，我鼓励你尝试不同的预处理方法、分类算法、文本矢量，当然还有数据集。