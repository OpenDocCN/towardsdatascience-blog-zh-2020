<html>
<head>
<title>Machine Learning: Improving Classification accuracy on MNIST using Data Augmentation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习:使用数据扩充提高MNIST的分类精度</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/improving-accuracy-on-mnist-using-data-augmentation-b5c38eb5a903?source=collection_archive---------9-----------------------#2020-05-06">https://towardsdatascience.com/improving-accuracy-on-mnist-using-data-augmentation-b5c38eb5a903?source=collection_archive---------9-----------------------#2020-05-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a55f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">增加训练数据集的简单方法</h2></div><p id="723a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> MNIST </strong>数据集有被称为<strong class="kh ir">你好世界</strong>的图像分类。每个机器学习工程师迟早都会处理这个数据集。</p><h1 id="af86" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated"><strong class="ak">数据集</strong></h1><p id="90d6" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">MNIST是一组手写数字的小图像。请看下图，其中有一些例子。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ly"><img src="../Images/56af7eec864f293bd444e66497c9ea5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LyRlX__08q40UJohhJG9Ow.png"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">MNIST数据集</p></figure><blockquote class="mo mp mq"><p id="ce62" class="kf kg mr kh b ki kj jr kk kl km ju kn ms kp kq kr mt kt ku kv mu kx ky kz la ij bi translated">共有<strong class="kh ir">70000张图像</strong>，每张图像有<strong class="kh ir"> 784个特征</strong>。这是因为每幅图像都是28 x 28像素，每个特征代表一个像素的强度，从0到255。</p></blockquote><p id="46df" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有许多分类算法(SGD，SVM，RandomForest等)可以在这个数据集上训练，包括深度学习算法(CNN)。</p><h1 id="9e47" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">培训和评估</h1><p id="2756" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">我们以<strong class="kh ir"> RandomForest </strong>分类器为例，在上面的数据集上对其进行训练，并进行评估。</p><figure class="lz ma mb mc gt md"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="d845" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在<strong class="kh ir">测试集</strong>上评估或建模后，我们得到的准确度分数是<strong class="kh ir"> 0.9705 </strong></p><h1 id="a369" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">我们能提高准确性吗？</h1><p id="9059" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">我们可以通过<strong class="kh ir">调整算法的超参数</strong>或者尝试<strong class="kh ir">不同的算法</strong>来改进。但是我们能对数据集做些什么吗？</p><p id="5e81" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">是的，我们可以！(是的，我们也会打败新冠肺炎)</p><p id="8ac3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有时算法需要更多的数据集来提高预测功能，我们可以使用相同的数据集本身来扩展数据集。</p><h2 id="898c" class="mx lc iq bd ld my mz dn lh na nb dp ll ko nc nd ln ks ne nf lp kw ng nh lr ni bi translated">如何扩展数据集？</h2><p id="278b" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">正如我们之前所讨论的，数据集的每个实例只不过是(<em class="mr"> 784 </em>)个像素值的向量。(这实际上是一个代表<em class="mr"> 28x28 </em>图像)</p><p id="3700" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我们把图像向两边移动两个像素会怎么样？请看下面的例子。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi nj"><img src="../Images/6c359a420e720efb3b4f891439ce88de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7Qxxye_xfKnMKUqVlD0M1g.png"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">增强图像</p></figure><p id="a67c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些图像会聚在一起，对吗？如果我们生成这样的图像，并将其添加到我们的训练集中，然后再次训练模型，会怎么样呢？我们可能会得到更准确的预测。</p><h2 id="78fc" class="mx lc iq bd ld my mz dn lh na nb dp ll ko nc nd ln ks ne nf lp kw ng nh lr ni bi translated">履行</h2><p id="8f4b" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">我们可以编写一个方法，按照给定的顺序在四个方向上移动图像。</p><p id="8d76" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将把图像向四个方向移动一个像素，并从一幅图像中再生成四幅图像。结果数据集现在将包含<strong class="kh ir"> <em class="mr"> 3，00，000张</em> </strong>图像(<em class="mr"> 60000 x 5 </em>)。</p><figure class="lz ma mb mc gt md"><div class="bz fp l di"><div class="mv mw l"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">我们可以为每一次移位增加<strong class="ak"> 60，000 </strong>个实例。</p></figure><p id="194a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们在这个新数据集上训练模型并进行评估。</p><figure class="lz ma mb mc gt md"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="4158" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">瞧啊。！！精度得分现在是<strong class="kh ir"> <em class="mr"> 0.9803 </em> </strong>。</p><p id="aa1d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将精度提高了<strong class="kh ir"> <em class="mr"> ~0.01% </em> </strong>。这太棒了。</p><h2 id="8a6e" class="mx lc iq bd ld my mz dn lh na nb dp ll ko nc nd ln ks ne nf lp kw ng nh lr ni bi translated">结论</h2><ul class=""><li id="dd13" class="nk nl iq kh b ki lt kl lu ko nm ks nn kw no la np nq nr ns bi translated">我们已经从现有的数据集扩展了我们的数据集，使用“<strong class="kh ir">数据扩充</strong>”技术，通过简单地改变像素顺序。</li><li id="87b6" class="nk nl iq kh b ki nt kl nu ko nv ks nw kw nx la np nq nr ns bi translated">在这个更大的数据集上进行训练，我们的准确率提高了0.01%</li></ul><p id="bf55" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请在下面的GitHub位置找到完整的代码</p><div class="ny nz gp gr oa ob"><a href="https://github.com/akashp1712/ml-akash/tree/master/Articles/data-augmentation" rel="noopener  ugc nofollow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd ir gy z fp og fr fs oh fu fw ip bi translated">阿卡什1712/毫升-阿卡什</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">机器学习的注释和代码:https://akashp1712.github.io/ml-akash-阿卡什1712/ml-阿卡什</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">github.com</p></div></div><div class="ok l"><div class="ol l om on oo ok op mi ob"/></div></div></a></div><h1 id="dd64" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">更多想法？</h1><ul class=""><li id="4294" class="nk nl iq kh b ki lt kl lu ko nm ks nn kw no la np nq nr ns bi translated">你能增加更多的数据集吗？(<strong class="kh ir">提示</strong>:对角移动图像)</li><li id="650b" class="nk nl iq kh b ki nt kl nu ko nv ks nw kw nx la np nq nr ns bi translated">尝试其他算法，而不是随机森林，比如<strong class="kh ir"> KNeighborsClassifier </strong>或<strong class="kh ir"> SVM </strong></li></ul><blockquote class="oq"><p id="f22f" class="or os iq bd ot ou ov ow ox oy oz la dk translated">当你纠结于一个问题的时候，就是你理解它的时候——埃隆·马斯克</p></blockquote></div></div>    
</body>
</html>