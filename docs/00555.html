<html>
<head>
<title>Billion Dollar Data Science</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">十亿美元的数据科学</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/billion-dollar-data-science-ea586c621590?source=collection_archive---------15-----------------------#2020-01-16">https://towardsdatascience.com/billion-dollar-data-science-ea586c621590?source=collection_archive---------15-----------------------#2020-01-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d784" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何防止高风险数据科学应用中代价高昂的失败</h2></div><p id="b689" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">预测智能手机计划的客户流失的内在风险与为一万亿美元的抵押贷款支持证券定价或为自动驾驶汽车检测人行横道上的行人是不同的。在第一种情况下，一个错误的决定有机会成本，在第二种情况下，它会导致金融危机，在第三种情况下，有人可能会受伤或死亡。作为数据科学家，我们经常谈论模型选择、超参数优化和性能指标，但很少谈论应用的严肃性会如何影响我们的工作。从事金融行业十年后，我发现有5个问题是模型失败的最常见根源。了解它们是什么以及如何处理它们<strong class="kk iu">可能会帮助你避免在数据科学中犯下十亿美元的错误。</strong></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/359c9d13f3630b3ce3deb50d3683453a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-wMotkBtOyEG7s3K"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">照片由<a class="ae le" href="https://unsplash.com/@timbatec?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">佩皮·斯托扬诺夫斯基</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><h1 id="8f86" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">风险和可逆性</h1><p id="2132" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">有两个概念对于很好地评估一个模型将如何用于决策是至关重要的:风险和可逆性。第一个概念，风险，更直观。衡量风险的最佳方式因每个决策而异，但它总是关于理解正确决策的回报和错误决策的代价。第二个概念，可逆性，是关于一个不正确的决定在事实发生后是否可以被改变。决策几乎永远不会完全可逆，因为通常会产生一些成本，即使是损失的时间或受损的声誉等非金钱成本，但错误可以逆转或减轻的程度会改变糟糕选择的实际成本。</p><p id="f67f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当我在《纽约时报》从事评论审核工作时，机器学习模型的错误成本是明确而有限的。一个读者会发布算法漏掉的淫秽评论，其他读者会向我们的评论审核专家团队报告，评论会被删除。即使在系统故障的情况下，也需要不到24小时来检测故障，并修复机器学习系统或暂时使整个系统离线。错误决策造成的风险很低，因为出现淫秽评论的可能性和显示淫秽评论的成本都很低。模型决策也是可逆的，因为版主可以在评论显示后将其删除。在这种情况下，数据科学家应该自由地快速行动，打破常规。通过模型的快速迭代进行学习和实验的好处超过了部署前的仔细验证和检查。</p><p id="9abe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在为信用卡建立风险模型时，人们面临的情况是完全不同的。今天部署的模型出现严重问题的第一个明显迹象可能不会在6个月内出现。某些类型的模型故障可能需要2到3年才能显现出来。当问题变得明显时——为时已晚，损害已经造成。在这里，每个错误的决策都是低风险的，因为与投资组合的规模相比，损失是很小的。但是每个决定都是不可逆的，在反馈回路闭合之前，总成本变得很高。如果失败足够严重，剩下要做的就是看着亏损滚滚而来，直到你慢慢地(或者可能很快地)倒闭。投资者失去了他们的钱，数据科学团队让每个人都失业，公司变成了一个恐怖的故事，就像<a class="ae le" href="https://en.wikipedia.org/wiki/Long-Term_Capital_Management" rel="noopener ugc nofollow" target="_blank">长期资本管理</a>一样，讲述了当你在公司给书呆子太多权力时会发生什么。</p><p id="2669" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">决策中风险的一般概念在<a class="ae le" href="http://individual.utoronto.ca/michael_miller/courses/sv_f17/documents/rudner_1953.pdf" rel="noopener ugc nofollow" target="_blank">用于假设检验的科学哲学</a>中早已得到认可。虽然应用0.95的显著性水平被灌输给每个Stats 101学生，但要求对网站上按钮的颜色进行A/B测试的信心水平也是同样荒谬的，因为只要求医生给有风险的药物注射这样的信心水平是可怕的。尽管如此，在某些时候，科学家必须对什么样的显著性水平是合适的做出判断。</p><p id="be79" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">类似地，当我们构建一个模型时，我们必须对如何平衡方法的便利性和严谨性做出判断。当一个模型是高风险决策的主要输入时，我们应该如何加强我们的方法以最小化模型失败的机会？</p><p id="d4e2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">没有通用的方法来保证模型的性能，但是在模型可能失败的无数方式中——这里是我在构建或审查模型时试图意识到的5种失败模式。</p><h1 id="d534" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">模型失败的五大原因</h1><h1 id="d58c" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">1.选择偏差</h1><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi ms"><img src="../Images/c2e61e398fedd4ac142423f35844a03f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LTtiWm5v0yEol2Lb"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">micha Parzuchowski在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="06f3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">建模中最常见，也是最容易被忽视的问题之一是选择偏差。选择偏差的定义因领域而异，但大致上我指的是以非随机方式收集训练数据并偏离预期应用的任何过程。大多数实际问题在某种程度上都存在选择偏差。</p><p id="055e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">假设我们想要预测某人的汽车售价。选择偏差的一个温和的例子是，大部分数据是关于轿车的，只有一些数据是关于卡车和SUV的。基于该数据集建立的模型可能对轿车比对SUV更准确，但价值、里程和年龄之间的基本关系应该成立，并给出良好的预测。一种更严重的选择偏差是，只根据美国汽车的数据建立一个模型，并将其应用于日本制造商的汽车。这种差异很容易被忽略，但日本汽车有更好的记录和可靠性的声誉，所以价格不会随着年龄或里程快速下降。</p><p id="18e2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了避免被选择偏差绊倒，在建立模型之前，最好养成问两个问题的习惯:</p><ol class=""><li id="d180" class="mt mu it kk b kl km ko kp kr mv kv mw kz mx ld my mz na nb bi translated">数据收集的选择过程是怎样的？</li><li id="3a18" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">模型是否会有与训练集在重要方面不同的操作条件？</li></ol><p id="16ce" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">问题#1是最重要的，因为如果我们不理解选择过程，我们就不能对我们的模型或数据进行调整。理想的情况是只研究像物理科学中的问题，其中每个观察单位都是相同的(例如电子或细菌)，所有感兴趣的变量都是独立操纵的，以使因果推断变得容易，并确保模型将完美地推广到整个群体。但是对于行业应用，数据收集很少归数据科学家所有，<a class="ae le" href="https://leon.bottou.org/slides/2challenges/2challenges.pdf" rel="noopener ugc nofollow" target="_blank">它可能不符合模型的操作条件</a>，并且数据收集很少仅用于科学研究的目的。由于来自物理科学的数据往往是例外，而不是数据科学从业者的规则，所以可以问的好问题包括:</p><ul class=""><li id="8b93" class="mt mu it kk b kl km ko kp kr mv kv mw kz mx ld nh mz na nb bi translated">什么过程将数据从更广泛的人群中提取到样本中？</li><li id="d3a2" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld nh mz na nb bi translated">选择过程如何影响样本数据？(例如，用于分类的标签比率的变化，或者特征分布的支持)</li><li id="dad6" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld nh mz na nb bi translated">时间的流逝是否带来了潜在的影响？</li></ul><p id="2bbc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于我们关于选择偏差的第二个问题，如果训练数据的选择过程与应用有意义的不同，第一步是尝试量化这种差异。在无监督学习或迁移学习问题的情况下，我们仍然可以以单变量方式(这更容易)或联合分布(这更难)来评估特征分布的差异。对于监督学习问题，我们还可以比较样本数据和应用之间的目标差异或预测器和目标之间的关系。</p><p id="1d9e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当我们想要对P(Y | X)建模并且X的分布有变化时，在协变量移位的大标题下有许多技术，并且，利用相对灵活的模型，对协变量移位进行调整是容易处理的。当P(Y)变化时(先验概率变化)，校准通常是一个简单的解决方法。当一个数据选择过程(无论该过程是已知的、潜在的还是由于不稳定的环境)改变了我们所了解的X和Y之间的关系(概念转变)时，通常没有聪明的算法方法来逃避只有可用数据的问题。在这种情况下，有5种明智的方法:</p><ol class=""><li id="a52d" class="mt mu it kk b kl km ko kp kr mv kv mw kz mx ld my mz na nb bi translated"><strong class="kk iu">使用护栏</strong>:约束模型允许操作的空间。这可能很简单，比如对单个要素的值进行硬切割，也可能更复杂，比如在样本数据的联合分布密度较低的地方不做决策。这种技术的一个例子是当<a class="ae le" href="https://www.investopedia.com/terms/f/flash-crash.asp" rel="noopener ugc nofollow" target="_blank">市场在不到10分钟内下跌超过10%时，停止模型交易。</a></li><li id="bc97" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated"><strong class="kk iu">收集更多数据</strong>:改变选择过程，最好是通过实验，直接解决选择偏差。</li><li id="c5e9" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated"><strong class="kk iu">渐进式探索</strong>:使用分层抽样或主动学习等技术(通常受预算限制)来更新模型，并在“实时”环境中高效学习。</li><li id="d494" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated"><strong class="kk iu">使用预测区间</strong>:对于监督学习，当有可能生成准确的预测区间时，有时调整决策过程以使用预测区间而不是点估计就足够了。</li><li id="5bc1" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated"><strong class="kk iu">建立一个因果模型</strong>:这是最难也是最不实用的方法，但是<a class="ae le" href="https://leon.bottou.org/slides/invariances/invariances.pdf" rel="noopener ugc nofollow" target="_blank">识别因果关系解决了许多选择偏差产生的问题</a>，当<a class="ae le" href="https://ftp.cs.ucla.edu/pub/stat_ser/r350.pdf" rel="noopener ugc nofollow" target="_blank">有可能识别它们的时候</a>。</li></ol><p id="2512" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">大多数实际应用都存在某种程度的选择偏差。最重要的是理解它，以便有意识地决定偏差带来的风险，以及如何在模型的构建或应用中减轻风险。</p><h1 id="7bba" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">2.操作化</h1><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi ni"><img src="../Images/4774b4737738beb7a2c761b74c75b31c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*P0s3cEnELiQ5IuSC"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">照片由<a class="ae le" href="https://unsplash.com/@chne_?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Tachina Lee </a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="dee2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">可操作化的概念是如何将一个模糊的、真实的目标变成一个可量化的问题。一个简单的例子就是“吸烟致癌”的假设。即使有了这样一个直观的想法，我们仍然需要决定如何量化假设。例如，我们是否应该将“吸烟”的定义局限于烟草？如果是，一个人要抽多少或多长时间才有资格成为“烟民”？我们对癌症的定义是否仅限于肺癌？诸如此类。</p><p id="f9c6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让数据科学的可操作性变得棘手的是，错误往往不在于数据或算法，而在于我们自己。我们从技术训练中获得的素质经常引导我们去熟悉和舒适的方法，即使它们可能不是解决问题的正确选择。有时候最重要的问题也是最不明显的。要设置一个新问题，有两个背景问题需要仔细考虑:</p><p id="e8e3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">把这个问题框定为数据科学问题到底合适不合适？</strong></p><p id="6d37" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在工业界，非科学的、昂贵的或不可行的问题总是被提出来。在试图回答迈克尔·乔丹或勒布朗·詹姆斯是否是有史以来最伟大的篮球运动员之前，问问这个问题是否值得回答，如果值得，数据科学是获得答案的正确途径吗？</p><p id="20a3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">可以用什么方法学<em class="nj"/>来设计这个问题？</strong></p><p id="5e91" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们都倾向于默认使用我们最熟悉的工具和技术，这可能是一个错误。身份盗窃问题就是一个很好的例子。将问题设计成分类问题和异常检测问题可以得到更好的结果。当数据是相关的，或者我们需要进行因果推断时，我们必须处理这些问题，即使大多数技术不能保证这一点。问题应该决定方法，而不是相反。</p><p id="0f4e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一旦解决了背景问题，我们就可以评估更明显的技术主题:</p><p id="177a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">分解</strong> —问题是否应该<a class="ae le" href="https://arxiv.org/pdf/1905.01772.pdf" rel="noopener ugc nofollow" target="_blank">分解成零件</a>？尽管端到端学习对于复杂的问题来说可能很有吸引力，正如吴恩达在“机器学习的渴望”一章中就端到端学习的利弊<a class="ae le" href="https://d2wvfoqc9gyqzf.cloudfront.net/content/uploads/2018/09/Ng-MLY01-13.pdf" rel="noopener ugc nofollow" target="_blank">指出的那样</a>它可能需要更多的数据，并且更难分析和改进。</p><p id="1739" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">特性</strong> —基于对领域的了解，是否存在所有相关的度量？潜在特征在多大程度上可能产生影响？无关数据被排除了吗？如果与人打交道，这些数据会导致不公平或歧视性的待遇吗？</p><p id="b91c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">目标</strong> —目标是否最接近预期结果？无论是多臂强盗还是分类器，选择对看起来接近人的概念建模，如收入和利润，可以对模型产生巨大的影响。</p><p id="5467" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">目标函数</strong> —目标函数是否用正确的约束优化了正确的权衡？尽管最小化RMSE或对数损失的想法在监督学习中普遍存在，但可能有更合适的方法(例如，不同的损失函数、成本敏感的机器学习、结构化预测、多目标优化)。</p><p id="9ce9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">性能评估</strong> —即使在对监督学习问题的损失函数进行了大量考虑的理想情况下，优化的函数也很少是手边的实际问题。这仍然是一种简化，对于高风险模型更是如此，在高风险模型中，问题的某些方面可能存在难以量化的限制，如可解释性、计算复杂性或与其他系统的交互。高风险模型的最终评估必须超越简单的汇总统计，并尽可能根据预期用途进行评估。</p><p id="6788" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">操作化是任何数据科学问题中最具挑战性的部分之一，因为它将该领域中一些最巧妙和技术性的方面联系在一起。即使有领域知识，也很难对一个问题提出一个好的概念表示。为这一概念提出实证测量和数学表述，如果不是更难的话，至少也是同样困难的。好消息是，当一个问题被正确操作时——其他一切都变得容易多了。</p><h1 id="6a85" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">3.黑箱滥用</h1><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi nk"><img src="../Images/86591a42784612db1f34d90c59689769.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ifq5l1XL1qanV0dB"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">阿里·沙阿·拉哈尼在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="ddf6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">高风险问题不同于低风险问题的一个方面是，我们几乎总是想要一些证据，证明模型使用信息的方式与我们对现实的理解一致。虽然“白盒”模型经常被提议作为“黑盒”模型的替代方案，如神经网络或集成方法来提供证据，但现实是线性或逻辑回归模型<a class="ae le" href="https://www.stat.cmu.edu/~cshalizi/350/lectures/17/lecture-17.pdf" rel="noopener ugc nofollow" target="_blank">不容易解释大多数现实世界的问题</a>，并且需要更多的工作来实现类似水平的预测准确性。当复杂模型失败时，问题几乎从来都不是模型的灵活性，而是将输入数据、算法或模型对输入数据的使用视为黑盒的某种滥用。</p><p id="ca81" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于一个高风险的决策来说，忠实——一个模型的概括能力——甚至比准确性更重要。对于任何高风险模型，谨慎的做法是:</p><p id="50dc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">理解算法</strong> —这看似显而易见，但却是许多失败的根源。每个算法都有优点、缺点和假设。无论是特征的规模还是数据的维度，对算法局限性的实际工作知识与合理的理论理解一样重要。</p><p id="2205" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">了解特征</strong>-即使在学习特征表示是建模任务的一部分的情况下，了解输入数据是什么以及如何使用它也是至关重要的。两个很好的例子说明了这一点的重要性:</p><ol class=""><li id="24b2" class="mt mu it kk b kl km ko kp kr mv kv mw kz mx ld my mz na nb bi translated"><a class="ae le" href="https://www.cs.umb.edu/~ding/history/470_670_fall_2011/papers/cs670_Tran_PreferredPaper_LeakingInDataMining.pdf" rel="noopener ugc nofollow" target="_blank">泄漏</a> —除了在某个特征与目标有着滑稽的强关联的情况下，泄漏需要人为干预来防止。</li><li id="fc3d" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated"><a class="ae le" href="https://arxiv.org/pdf/1908.09635.pdf" rel="noopener ugc nofollow" target="_blank">歧视</a> —导致不公平待遇的数据(如种族主义、性别歧视等。)对人来说可能是显而易见的，但在模型优化中却不明显。甚至像一份好的清单这样简单的事情<a class="ae le" href="https://github.com/drivendataorg/deon" rel="noopener ugc nofollow" target="_blank">也可以成为从数据或模型中承认歧视的起点。</a></li></ol><p id="b970" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">理解模型如何使用特性</strong>:有各种各样的方法来评估一个模型，甚至是一个“黑盒”模型，如何使用数据。对于稀疏数据，手动检查每个特征是不可行的，但利用特征重要性的指数衰减或问题中的特殊结构(如生物信息学中的<a class="ae le" href="https://media.springernature.com/full/springer-static/image/art%3A10.1186%2F1471-2105-15-S6-S4/MediaObjects/12859_2014_Article_6393_Fig5_HTML.jpg" rel="noopener ugc nofollow" target="_blank">双聚类</a>)仍然可以证明模型中的原则驱动因素在概念上是正确的，即使在具有大量竞争因素的高维空间中的行为难以理解。</p><p id="a835" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">尊重数据集偏差的影响</strong>-对超参数优化的短视关注可能会使我们相信模型性能已经得到改善，即使<a class="ae le" href="http://www.wisdom.weizmann.ac.il/~vision/courses/2010_2/papers/datasets.pdf" rel="noopener ugc nofollow" target="_blank">跨数据集泛化</a>或对超时维持的泛化很差。对运行条件变化具有鲁棒性的模型可能更适合高风险应用。</p><p id="2da7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当然，有时不理解一个模型是如何工作的，理解一个模型是如何崩溃的就足够了——我们将在关于错误分析的第5章中讨论。</p><h1 id="a958" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">4.部署</h1><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi nl"><img src="../Images/5fafa5d7d42e37f65ef898b96aaca43f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EESlTV_VvpqrichZ"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">凯文·杰瑞特在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="d2a6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">即使是在正确的数据上以正确的方式构建的模型仍然面临着部署的障碍。为了使模型有用，模型的输出必须走出实验室，回到现实世界。<a class="ae le" href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43146.pdf" rel="noopener ugc nofollow" target="_blank">机器学习:技术债务的高息信用卡</a>是关于机器学习系统的软件工程最佳实践的权威参考，我强烈推荐它，因此我将特别关注部署高风险应用程序的一些实际考虑</p><h2 id="f78a" class="nm lw it bd lx nn no dn mb np nq dp mf kr nr ns mh kv nt nu mj kz nv nw ml nx bi translated">匹配环境</h2><p id="395e" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">开发环境和预期应用程序的硬件差异往往是最难处理的，尤其是在浮点运算存在差异的情况下。幸运的是，我们大多数人只需要关心软件层，虚拟机和容器让生活变得更加轻松。无论采用哪种方法，环境细节都需要匹配:操作系统、语言和软件包版本等。都需要排队。模型的单元测试和集成测试经常会错过边缘情况，这些情况可能是由在两个独特的环境中执行的具有细微差别的相同的全功能代码行引入的。</p><h2 id="8f5c" class="nm lw it bd lx nn no dn mb np nq dp mf kr nr ns mh kv nt nu mj kz nv nw ml nx bi translated">序列化</h2><p id="c303" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">为了存储、共享或复制一个模型，需要将它序列化到持久存储中。不幸的是，对于许多实际应用来说，模型序列化仍然具有挑战性。原生序列化格式，如Python中的<a class="ae le" href="https://docs.python.org/3/library/pickle.html" rel="noopener ugc nofollow" target="_blank"> pickle </a>或R中的<a class="ae le" href="https://stat.ethz.ch/R-manual/R-devel/library/base/html/readRDS.html" rel="noopener ugc nofollow" target="_blank"> rds </a>，以及工具特定的序列化格式，如<a class="ae le" href="https://www.tensorflow.org/guide/saved_model" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>或<a class="ae le" href="https://spark.apache.org/mllib/" rel="noopener ugc nofollow" target="_blank"> mllib </a>中的格式，都很方便，但几乎总是会产生问题。安全性可能是一个问题，随着模型的老化，重新创建正确的执行环境可能是困难的或不可取的，并且可能没有简单的方法将模型分发到不同的平台。虽然<a class="ae le" href="http://dmg.org/pmml/v4-3/GeneralStructure.html" rel="noopener ugc nofollow" target="_blank"> PMML </a>是行业标准的序列化格式，因为它是独立于语言和平台的，但它也有缺点。PMML强调的是便携性，而不是性能；此外，只有有限数量的模型类型可用，并且将格式扩展到新类型的模型或转换是一项不小的工作量。<a class="ae le" href="https://onnx.ai/" rel="noopener ugc nofollow" target="_blank"> ONNX </a>和<a class="ae le" href="https://github.com/onnx/onnxmltools" rel="noopener ugc nofollow" target="_blank">on XML</a>已经开始弥合深度学习模型和标准机器学习模型的序列化格式之间的差距，但仍在积极开发中。因为序列化很少有一个显而易见的答案，所以最终，存储模型及其训练参数的数据总是一个好习惯，以便在必要时可以从头重新创建它。</p><h1 id="9528" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">特征</h1><p id="434f" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">根据我的经验，特性导致的失败比模型部署的任何其他方面都要多。</p><h2 id="2cfa" class="nm lw it bd lx nn no dn mb np nq dp mf kr nr ns mh kv nt nu mj kz nv nw ml nx bi translated">翻译错误</h2><p id="5529" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">特性工程经常发生在与<em class="nj">生产</em>环境不完全匹配的<em class="nj">开发</em>环境中。有时，开发中编写的特性甚至必须翻译成不同的编程语言才能用于生产。将功能转换到生产环境中可能会出现错误。尽管编写所有特性的生产实现并通过生产系统提取它们用于开发，但由于时间和现有系统的限制，这通常是不可行的。通常，我们所能做的最好的事情是在共享数据集上测试生产实现和开发实现，并要求匹配达到浮点精度。</p><h2 id="a8a9" class="nm lw it bd lx nn no dn mb np nq dp mf kr nr ns mh kv nt nu mj kz nv nw ml nx bi translated">所有权</h2><p id="5d7a" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">不管数据是来自传感器还是ORM，建模者很少拥有或维护数据的创建。除了我们在“黑盒滥用”一节中讨论的泄漏概念之外，这一挑战还会以几种不同的方式出现:</p><ul class=""><li id="6460" class="mt mu it kk b kl km ko kp kr mv kv mw kz mx ld nh mz na nb bi translated"><strong class="kk iu">漂移</strong>:即使当一个特性的计算和一个模型之间有一个明确的依赖关系时，由于大多数软件系统中存在的耦合程度，特性的分布也会随时间漂移。即使计算本身不变，它也依赖于输入，而输入又具有依赖性。一个很好的默认假设是，代码库的正常开发和与之交互的真实世界过程最终会导致不可接受的偏差。</li><li id="52f2" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld nh mz na nb bi translated"><strong class="kk iu">修复“损坏的”功能</strong>:虽然漂移会导致模型慢慢退化，但有一个棘手的维护问题会导致功能立即损坏。有时，模型具有被精确实现的特性，但是具有明显的计算错误——例如，将整数视为字符串或除以零。然后，作为正常维护的一部分，特征计算被某个人改变，该人认为他们正在修复一个bug——但是无意中破坏了模型。即使基于改进的计算来重新训练模型可能是理想的，但模型的性能保证是基于原始特征计算的，并且会有所不同(可能更差)，因为其参数是基于该计算的。</li></ul><h2 id="1cf3" class="nm lw it bd lx nn no dn mb np nq dp mf kr nr ns mh kv nt nu mj kz nv nw ml nx bi translated">复杂性</h2><p id="e2e8" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">复杂性带来的挑战是邪恶的，因为它很难定义，也很难衡量。随着模型复杂性的增加，即参数、功能和依赖性越多，或者透明度越低，或者对硬件(无论是CPU、GPU、RAM还是内存)的要求越高，部署和维护就越困难。</p><p id="a5bb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正如Leon Bottou在他关于<a class="ae le" href="https://leon.bottou.org/slides/2challenges/2challenges.pdf" rel="noopener ugc nofollow" target="_blank">的演讲中解释的，机器学习的两大挑战</a>，管理复杂性的另一个方面是不能孤立地考虑模型。一个模型在一个动态的生态系统中运行，特别是对于现代企业，一个模型可能会受到其他模型的决策或输出的影响。</p><p id="077c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们追溯到开始这一切的竞赛，100万美元的网飞奖，<a class="ae le" href="https://www.wired.com/2012/04/netflix-prize-costs/" rel="noopener ugc nofollow" target="_blank">获胜的算法从未实现过</a>，因为性能优势与复杂性不相称。在部署新的champion模型之前，应始终将性能优势与更简单的替代方案进行权衡，尤其是在下行风险可能远远超过性能提升的高风险应用中。</p><p id="f2a9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与“选择偏差”、“可操作化”或“黑盒滥用”等主要与设计和创建有关的章节不同，关于部署的好消息是，只要我们在编写测试和创建监控时牢记这些问题，我们就可以开发出避免这些问题的明确方法。</p><h1 id="3e1b" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">5.误差分析</h1><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi ny"><img src="../Images/b613316cb27ecd470f5f07da60da386e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XshscmK86DHRvUd8"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">斯蒂芬·道森在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="109d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所有模型都失败了。所有的模型都是现实的一个脆弱的简化版本。无论一个模型有多聪明或多精确，它都有缺陷。但是，如果我们能够预测一个模型将如何执行，并了解一个模型将如何失败，我们就可以安全地使用它。</p><p id="be8d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">即使我们为正确的决策做了很好的优化工作，我们对它的评估仍然是一种简化。构建champion模型后，我们可以执行错误分析，以几种不同的方式审核模型的性能，这在培训阶段可能会不方便。</p><blockquote class="nz"><p id="99fc" class="oa ob it bd oc od oe of og oh oi ld dk translated">“所有的模型都是错误的，但有些是有用的”——乔治·博克斯</p></blockquote><h2 id="a8dc" class="nm lw it bd lx nn oj dn mb np ok dp mf kr ol ns mh kv om nu mj kz on nw ml nx bi translated">基准</h2><p id="9b0b" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">如果可能的话，最好用已知性能良好的“黄金标准”模型来评估新模型。虽然每个人都习惯于在培训/测试中对照“冠军”来评估新的“挑战者”模型，但值得注意的是，因为我们在错误分析中的目标是寻找重要的缺陷，所以有时最好是对照最健壮、最稳定的模型来评估挑战者模型，而不是最佳表现的冠军。</p><p id="e336" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">更经常被忽视的是，在没有明显的冠军或黄金标准可供比较的情况下该怎么做。在这种情况下，仍然有几个选择。一种是纯粹为了比较而创建一个更简单的模型。例如，如果你已经建立了一个GAM，把它与相同数据上的逻辑回归模型进行比较。如果有足够的数据，并且关系是非线性的，那么GAM应该在任何地方都优于逻辑回归。同样的类比适用于任何问题——如果你将<a class="ae le" href="https://arxiv.org/pdf/1810.04805.pdf" rel="noopener ugc nofollow" target="_blank">伯特</a>应用于你的NLP问题，而它并没有表现出一袋单词的方法，那就有问题了。</p><p id="1fda" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当时间或其他约束阻止一个简单的模型成为一个现实的选择时，我们可以退回到随机数生成——这可能是一个<em class="nj">令人惊讶的</em>有效的现实检查。众所周知，人类不善于识别“随机”是什么样子，数据科学家也不例外。将随机的统一特征注入到数据集中，或者通过从参数与目标匹配的分布中抽取随机数来模拟“模型”,至少可以显示出纯粹由于偶然而可能发生的情况。</p><h2 id="0634" class="nm lw it bd lx nn no dn mb np nq dp mf kr nr ns mh kv nt nu mj kz nv nw ml nx bi translated">残差</h2><p id="b8a3" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">称残差分析是一门失传的艺术是不正确的，因为统计学家还没有忘记它。也就是说，没有受过正规统计学培训的从业者往往没有充分利用它，我得到的印象是，大多数人认为残差分析只对线性模型有用。虽然<a class="ae le" href="https://christophm.github.io/interpretable-ml-book/agnostic.html" rel="noopener ugc nofollow" target="_blank"> PDP、ICE和SHAP图</a>都是解释模型和检查模型如何使用特性的好方法，但要了解模型哪里出错了——没有什么比查看残差的<a class="ae le" href="http://uc-r.github.io/dalex" rel="noopener ugc nofollow" target="_blank">更好的了。不是所有的残差都是相等的，尤其是当时间是一个问题的相关维度时。幸运的话，检查残差可以建议改变特征表示、模型类型或集成模型的机会。在最坏的情况下，残差分析可以证明模型的整体指标没有隐藏残差上的恶劣行为，其中一小部分大残差被小的平均残差抵消。</a></p><h2 id="38b4" class="nm lw it bd lx nn no dn mb np nq dp mf kr nr ns mh kv nt nu mj kz nv nw ml nx bi translated">成分</h2><p id="752d" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">有时候，将机器学习系统分解成组件来分析性能，这在事后才显而易见。回到我们最初的例子，自动驾驶汽车的行人检测可能会在许多方面出错。模型可能擅长检测图像中的人，但不擅长检测场景中的位置。或者它可能对接近任何一种“条纹”图案的人来说太合适了，不管是条纹人行横道还是条纹衬衫。预测信用卡违约风险也是如此。预测2年期的违约概率包含许多因素。一个模型可能只是非常擅长预测前6个月或12个月的短期风险，之后也不会比随机风险更好。将一个系统分解成几个组成部分来测量哪里出现了错误，这有助于我们理解它是如何工作的，哪里出了故障。</p><p id="96b9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与残差一样，成分分析的主题是检测意外错误。如果我们在构建模型的一开始就预料到某些组件将更难建模，我们可能会以不同的方式塑造我们的训练集，添加功能以避免矛盾的关系，或者创建子模型。事实是，我们最初的假设是，我们可以测量或优化的许多东西根本不重要。即使对于我们非常关心准确性和可靠性的模型或机器学习系统，对每个假设进行建模和测试也是不现实的。通常，事后检查性能是否符合预期以及错误是否是随机的要比事先为所有可能性做好准备容易得多。</p><h1 id="2575" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi ni"><img src="../Images/8d3c5afd378f5584bcc32ed280e60d60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*opJh1HHGjHrPw4af"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated"><a class="ae le" href="https://unsplash.com/@jeremythomasphoto?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">杰瑞米·托马斯</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="bb33" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">大多数模型不需要三级审问。有些是。在准备构建任何模型时，考虑模型将用于的决策的风险和可逆性总是谨慎的。如果一个模型将被用于做出高风险、不可逆转的决策——作为科学家，我们应该增强我们的怀疑精神和方法的严谨性。不幸的是，这5个模型失败的常见原因并没有涵盖所有可能的失败模式。但它们确实是一个健康的提醒，帮助任何从业者避免可预防的错误…甚至可能是十亿美元的错误。</p></div></div>    
</body>
</html>