<html>
<head>
<title>A Practical Guide to DBSCAN Method</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">DBSCAN方法实用指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-practical-guide-to-dbscan-method-d4ec5ab2bc99?source=collection_archive---------11-----------------------#2020-04-25">https://towardsdatascience.com/a-practical-guide-to-dbscan-method-d4ec5ab2bc99?source=collection_archive---------11-----------------------#2020-04-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5e11" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">流行的聚类方法DBSCAN的综合指南</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4dd49e4feb2023e7ae37752937785768.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yBJp5sOdknwFanHyx2KDgw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="ky">检索2020年4月19日，来自</em><a class="ae kz" href="https://www.irishtimes.com/life-and-style/health-family/rejection-of-an-individual-by-a-group-is-the-worst-kind-of-bullying-1.3441864" rel="noopener ugc nofollow" target="_blank"><em class="ky"/></a><a class="ae kz" href="https://gdoria.com/Exploring-the-Doc2Vec-and-Creating-a-Map-of-Video-Games.html" rel="noopener ugc nofollow" target="_blank"><em class="ky">【gloria.com】</em></a></p></figure><p id="a4e3" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">当我在处理我的第一个数据科学任务时，我想使用DBSCAN(带噪声的基于密度的应用程序空间聚类)进行聚类，我多次搜索以下问题的答案:</p><ul class=""><li id="80f1" class="lw lx it lc b ld le lg lh lj ly ln lz lr ma lv mb mc md me bi translated">如何选择DBSCAN参数？</li><li id="88e0" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">DBSCAN如何工作？</li><li id="3362" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">DBSCAN如何选择哪个点将属于哪个集群？</li><li id="81b7" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">为什么用DBSCAN而不用K-means？</li></ul><p id="c99c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">当然，要找到所有这些问题以及更多问题的答案并不困难。然而，可能很难找到一篇总结所有这些和许多其他基本问题的文章。此外，你可能会感到惊讶，但一些重要的问题没有这样容易得到的答案。</p><blockquote class="mk"><p id="6cd7" class="ml mm it bd mn mo mp mq mr ms mt lv dk translated">我的目标是编写一个指南，总结DBSCAN方法，回答所有这些问题以及更多问题。我发现DBSCAN算法不如K-means和层次聚类等其他流行的聚类方法直观，所以我将使用许多示例，并且我保证在本文结束时，您会理解这种方法。</p></blockquote></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h1 id="72dc" class="nb nc it bd nd ne nf ng nh ni nj nk nl jz nm ka nn kc no kd np kf nq kg nr ns bi translated">基于密度的聚类的动机</h1><p id="e74e" class="pw-post-body-paragraph la lb it lc b ld nt ju lf lg nu jx li lj nv ll lm ln nw lp lq lr nx lt lu lv im bi translated">两种流行的聚类方法是:分区和层次方法。</p><p id="76f4" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">划分方法</strong>将数据集划分为k(方法的主输入)个组(簇)。分区迭代过程将数据集中的每个点或对象(从现在起我将把它称为点)分配给它所属的组。将点分配到组中后，通过取组中所有点的平均值来计算组的平均值(质心)。最广为人知的划分方法是<a class="ae kz" href="https://www.youtube.com/watch?v=4b5d3muPQmA" rel="noopener ugc nofollow" target="_blank"> K-means </a>。分区方法有一些明显的缺点:您应该预先知道要将数据库分成多少个组(K值)。另一个重要的缺点是K-means在发现非凸/非球形的簇时表现不佳(图1)。此外，K-means对噪声数据很敏感。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/ceadf573b424aabaf311709f8301cd35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*i-tY7X87AX2YGB7S13PTIA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图1-K-means不能识别的聚类形状。检索自<a class="ae kz" href="https://slideplayer.com/slide/4706420/" rel="noopener ugc nofollow" target="_blank">数据挖掘简介</a>(谭，Steinbach，Kumar，2004)</p></figure><p id="8427" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">分层方法</strong>使用特殊的树(树状图)为数据创建一个分层的可视化表示。<a class="ae kz" href="https://www.youtube.com/watch?v=7xHsRkOdVwo" rel="noopener ugc nofollow" target="_blank">凝聚层次聚类法</a>始于其聚类中的每个点，在每一步中，它将相似或接近的聚类合并为一个聚类。在最后一步中，所有点都在同一个簇中。与K-means相反，您不需要决定应该有多少个聚类，但它也有一些严重的缺点:它不适合大数据集，计算复杂性高，您需要选择影响聚类结果的合并聚类的度量(链接)。此外，每个度量都有其缺点:对噪声敏感，难以处理簇密度的严重差异，以及对簇的形状和大小敏感。</p><p id="162d" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">正如我们所看到的，划分和分级方法的主要缺点是:处理噪声，并且在寻找非球形的簇时得到不好的结果。</p><blockquote class="mk"><p id="a6e7" class="ml mm it bd mn mo mp mq mr ms mt lv dk translated">DBSCAN聚类方法能够表示任意形状的聚类并处理噪声。</p></blockquote><figure class="nz oa ob oc od kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/94e5b9dea026fcb1892041e42d591133.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*zeMlnUQNBN2LjdfkKDMZ0A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图2-任意形状的簇，例如“S”形和椭圆形簇。检索自<a class="ae kz" href="http://myweb.sabanciuniv.edu/rdehkharghani/files/2016/02/The-Morgan-Kaufmann-Series-in-Data-Management-Systems-Jiawei-Han-Micheline-Kamber-Jian-Pei-Data-Mining.-Concepts-and-Techniques-3rd-Edition-Morgan-Kaufmann-2011.pdf" rel="noopener ugc nofollow" target="_blank">数据挖掘:概念与技术</a> s(韩，Peri，Kamner，2011)。</p></figure></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h1 id="e489" class="nb nc it bd nd ne nf ng nh ni nj nk nl jz nm ka nn kc no kd np kf nq kg nr ns bi translated">DBSCAN直觉</h1><p id="9c3e" class="pw-post-body-paragraph la lb it lc b ld nt ju lf lg nu jx li lj nv ll lm ln nw lp lq lr nx lt lu lv im bi translated">让我们想象一个有很多居民和游客的大城市。想象一下，在不远的地方有一个小村庄。如果我们带一个外星人去两个地方，尽管它们离得很近，他也能很容易地分辨出它们是完全不同的地方。是的，景色、面积、建筑和其他许多方面都完全不同。但是有一个方面与我们的案例相关——地方的密度。城市很拥挤，有很多当地人和游客，而村庄很小，人少得多。</p><blockquote class="mk"><p id="c12e" class="ml mm it bd mn mo mp mq mr ms mt lv dk translated">根据密度来区分点组是DBSCAN的主要思想。</p></blockquote></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h1 id="22f5" class="nb nc it bd nd ne nf ng nh ni nj nk nl jz nm ka nn kc no kd np kf nq kg nr ns bi translated">DBSCAN概念</h1><blockquote class="mk"><p id="647f" class="ml mm it bd mn mo mp mq mr ms mt lv dk translated">DBSCAN将具有密集邻域的点组合成簇。</p></blockquote><p id="0879" class="pw-post-body-paragraph la lb it lc b ld oe ju lf lg of jx li lj og ll lm ln oh lp lq lr oi lt lu lv im bi translated">如果一个点附近有许多其他相邻点，则该点将被认为是拥挤的。DBSCAN找到这些拥挤的点，并将它们和它们的邻居放在一个簇中。</p><p id="8f79" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">DBSCAN有两个主要参数-</p><ul class=""><li id="e1d6" class="lw lx it lc b ld le lg lh lj ly ln lz lr ma lv mb mc md me bi translated"><strong class="lc iu"> ε </strong>(或eps或epsilon)——定义每个邻域的大小和边界。ε(必须大于0)是半径。点x的邻域称为x的ε-邻域，是围绕点x的半径为ε的圆/球。</li></ul><p id="b8ea" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">一些书籍和文章将x的ε-邻域描述为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/8b03d3607ff2f7a52e93cf37ec11d79f.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*Ir5fLs5b3RsRoajRnwrWJg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">从<a class="ae kz" href="https://books.google.com/books?hl=en&amp;lr=&amp;id=Gh9GAwAAQBAJ&amp;oi=fnd&amp;pg=PR9&amp;ots=JmG7PES-qp&amp;sig=-pYKMgBCYkCp5x6yDqQutHnekEs" rel="noopener ugc nofollow" target="_blank">数据挖掘和分析中检索的公式。基本概念和算法(扎基，梅拉，梅拉，2014年</a></p></figure><p id="821b" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在图3中，我们可以看到不同大小的ε如何定义x的ε-邻域。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/d8a733c7f8aec4c900b3ad6ff79c5919.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*ounZBlLn5G9_X8HSN288Yw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图3 —我们可以看到ε大小如何影响x的ε邻域的大小。</p></figure><p id="1cfa" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">现在，您可能会问自己，为什么它是基于密度的集群？一个非常密集的邻域和一个稀疏的邻域会被认为是两个不同的邻域(图4)，然后被分成两个不同的簇吗？</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/7ea64efc1597c8c209f3d17b1e7e5b66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*hlUYIBZ6sbncKVDYtkLqlQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图4 —密集邻域和稀疏邻域。</p></figure><p id="518e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">点x和它的邻居会在一个邻域内，而y和它的几个邻居会在另一个邻域内。然而，最终，点x和它的邻居可能会在一个聚类中，而点y和它的邻居会被认为是异常值或噪声。这是因为y的ε-邻域不够稠密。邻域包含的点越多，密度就越大。</p><blockquote class="mk"><p id="6fbb" class="ml mm it bd mn mo mp mq mr ms mt lv dk translated">如何定义一个邻域是否足够密集？为此，DBSCAN使用MinPts参数。</p></blockquote><p id="eb75" class="pw-post-body-paragraph la lb it lc b ld oe ju lf lg of jx li lj og ll lm ln oh lp lq lr oi lt lu lv im bi translated"><strong class="lc iu"> MinPts — </strong>密度阈值。如果一个邻域至少包含MinPts个点，它将被视为一个密集区域。或者，如果一个点的ε-邻域中至少有MinPts个点的值，则该点将被认为是稠密的。这些密集的点被称为<strong class="lc iu">核心点</strong>。</p><p id="c89e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">让我们再次检查图4，如果MinPts参数是3，点x将是核心点，因为它的ε-邻域的大小是9，并且它大于3。点y不会是核心点，因为它的ε-邻域包含两个点。</p><p id="109a" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">* <em class="ol">点x的ε-邻域内的点数包含x本身。</em></p><p id="44a4" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">一个边界点</strong>有包含少于MinPts个点的ε-邻域(所以它不是一个核心点)，但它属于另一个核心点的ε-邻域。</p><p id="eeba" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">如果一个点不是核心点，也不是边界点，那么它就是一个<strong class="lc iu">噪声点</strong>或者一个离群点。</p><p id="e19f" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在图5中我们可以看到点<strong class="lc iu"> </strong> x是一个核心点，因为在其ε-邻域中它有超过11个点。点y不是核心点，因为它的ε-邻域中的点少于11个，但是因为它属于点x的ε-邻域，并且点x是核心点，点y是边界点。我们很容易看出z点不是核心点。它属于y点的ε-邻域，而y点不是核心点，因此z点是一个噪声点。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/5837528cc1ccc86feb6c30aebfdfa296.png" data-original-src="https://miro.medium.com/v2/resize:fit:644/format:webp/1*eb-_ArjU-66N-zBYY6w8Ag.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图5-在这个图中我们可以看到三种类型的点:x是核心点，y是边界点，z是噪声点。</p></figure><blockquote class="mk"><p id="c5b1" class="ml mm it bd mn mo on oo op oq or lv dk translated">既然我们看到核心点和边界点将在一个集群中，那么DBSCAN如何知道哪个点去哪个集群呢？为了回答这个问题，我们需要定义一些定义:</p></blockquote><p id="2a5c" class="pw-post-body-paragraph la lb it lc b ld oe ju lf lg of jx li lj og ll lm ln oh lp lq lr oi lt lu lv im bi translated"><strong class="lc iu">直接</strong> <strong class="lc iu">密度可达— </strong>点y是从点x直接密度可达的，如果:</p><ul class=""><li id="1050" class="lw lx it lc b ld le lg lh lj ly ln lz lr ma lv mb mc md me bi translated">点y属于点x的ε-邻域</li><li id="731e" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">点x是一个核心点。</li></ul><p id="f1e1" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在图5中，点y是从点x可直接密度到达的点。注意，点x不是从点y可直接密度到达的点，因为点y不是核心点。</p><p id="e15d" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">密度可达— </strong>点y是从点x可达的密度，如果在点x和点y之间有一条点的路径，其中路径中的每一个点都可以从前一个点直接到达。这意味着路径上的所有点都是核心点，除了y点。我们可以在图6中看到一个例子。</p><p id="ef37" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">据<a class="ae kz" href="https://en.wikipedia.org/wiki/DBSCAN" rel="noopener ugc nofollow" target="_blank">维基百科</a>:</p><blockquote class="os ot ou"><p id="6f14" class="la lb ol lc b ld le ju lf lg lh jx li ov lk ll lm ow lo lp lq ox ls lt lu lv im bi translated"><em class="it">如果有一条路径</em> P₁ <em class="it">，</em> P₂ <em class="it"> …，</em> Pₙ <em class="it">与</em> P₁ <em class="it"> = p，</em> Pₙ <em class="it"> = q，则从核心点p到点q是可达的，这条路径上的所有点都是核心点，除了点q可能例外</em></p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/662a5b07c68df1b75b4f0f00a5ffeaa1.png" data-original-src="https://miro.medium.com/v2/resize:fit:650/format:webp/1*8a64OpD-Qj9suq_tVF-7HQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图6-点y是从点x可达到的密度。点y是边界点，点:x、z和p是核心点。</p></figure><p id="b920" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">密度连通- </strong>一个点x与一个点y是密度连通的，如果有一个点o使得x和y都是密度可达的。通过这种方式，DBSCAN在密集区域中连接核心对象和它们的邻居。我们可以在图7中看到一个例子。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/6b38b81f5f3c5b025ff3286d6b590e3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*alHJdfV4g_kQpKPpRgAtsA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图7-点x和点y是从点o密度可达的。因此，点x是密度连接到点y的。图从<a class="ae kz" href="https://www.dbs.ifi.lmu.de/Lehre/KDD/SS16/skript/4_Clustering.pdf" rel="noopener ugc nofollow" target="_blank">数据库中的知识发现(Seidl，2016) </a>检索并由我编辑。</p></figure><p id="3fe8" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">基于密度的聚类:</strong>聚类C是一个非空的点组，给定:</p><ul class=""><li id="be8c" class="lw lx it lc b ld le lg lh lj ly ln lz lr ma lv mb mc md me bi translated">点x在C中，y是从x密度可达的，在这种情况下，y将在C中</li><li id="1d24" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">C中的所有点都是密度相关的</li></ul><p id="8e6b" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在图6中，点x、y、z、p和y将在同一个群中。</p></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h1 id="1930" class="nb nc it bd nd ne nf ng nh ni nj nk nl jz nm ka nn kc no kd np kf nq kg nr ns bi translated">DBSCAN算法</h1><p id="376e" class="pw-post-body-paragraph la lb it lc b ld nt ju lf lg nu jx li lj nv ll lm ln nw lp lq lr nx lt lu lv im bi translated"><em class="ol">输入:</em></p><ul class=""><li id="c1e9" class="lw lx it lc b ld le lg lh lj ly ln lz lr ma lv mb mc md me bi translated"><em class="ol"> D —具有n个点的数据集</em></li><li id="6f82" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated"><em class="ol">min pts——</em>邻域密度阈值</li><li id="c281" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">ε-邻域半径</li></ul><p id="cce7" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">方法:</p><p id="c6d5" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">1)我们将数据中的所有点标记为未访问。</p><p id="94a3" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">2)我们随机选择一个未访问的点进行访问，并将其标记为已访问。姑且称之为‘p’吧。</p><p id="7cb8" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">3)我们检查p的ε-邻域是否至少有MinPts个点。</p><p id="8cc0" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">如果‘p’在其ε-邻域中没有足够的点(图8)，我们将其标记为噪声，并继续执行步骤4。</p><p id="3b94" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><em class="ol">*注意，在稍后的迭代中，在步骤3.d中，该点可能被包括在一个聚类中。</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/4702b2a49506668ba3e14292365c934b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*lB-4gjIAwdNFmSkliLsLIw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图8-点“p”将被视为噪声，因为其ε-邻域包含的点少于MinPts点。</p></figure><p id="f632" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">如果点‘p’在其ε-邻域内有足够多的点(图9 ),我们继续步骤3.a</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/144738b280fc57762f81de3b88ffba85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*EIOR3qPPUxHwX574oazqOw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图9—‘p’<strong class="bd pa"/>在它的ε-邻域中有超过个MinPts</p></figure><p id="f8ac" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">3.a)我们将创建一个新的集群C，并将“p”添加到该集群中。</p><p id="e738" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">3.b)我们将给p的ε-邻域取一个新名字——N(图10)。n将包括这些点:{a，b，c，d，e，f，g，h，i}</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/a7c0c21152c137c035121f9e76607c67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*0ovFK-KO53UtWGEMYgcuiQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图10-我们将赋予p的ε-邻域一个新的名字-N. <em class="ky">图8-10检索于2020年4月19日，来自</em> <a class="ae kz" href="https://www.irishtimes.com/life-and-style/health-family/rejection-of-an-individual-by-a-group-is-the-worst-kind-of-bullying-1.3441864" rel="noopener ugc nofollow" target="_blank"> <em class="ky">爱尔兰时报</em> </a> <em class="ky">，</em>由我编辑</p></figure><p id="a0e2" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">3.c)我们将对n中的每个点执行以下步骤。第一个点是“a”。如果“a”未被访问，我们将执行步骤3.c.1和3.c.2。否则，我们将继续执行步骤3.d。</p><p id="205e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">3.c.1)我们将点‘a’<strong class="lc iu"/>标记为已访问。</p><p id="e380" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">3.c.2)我们将检查点‘a’在其ε-邻域中是否至少有MinPts。如果是这样，我们将把这些点加到N上。例如，如果‘a’的ε-邻域包括点{j，k，l}并且MinPts是3，则新的N将包括点:{a，b，c，d，e，f，g，h，I，j，k，l }。但是，如果‘a’的ε-邻域仅包括点{j}，N将保持不变。</p><p id="6b2f" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">3.d)如果点‘a’不属于任何聚类，我们将把它添加到聚类C，现在聚类C将包括点‘a’和‘p’。</p><p id="0633" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">3.e)我们将移动到N中的下一个点(点‘b’)并返回到步骤3.c。在检查了N中的所有点之后，我们将完成重复步骤3.c-3.e。记住，N可能随时更新(步骤3.c.2) <strong class="lc iu">。</strong></p><p id="7f0c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">4.我们已经完成了p。我们将返回到步骤2，访问下一个未访问的点，并重复这些步骤。当访问完数据集中的所有点时，我们就结束了。</p><p id="03c3" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">算法的一个例子-</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/174c35e32aae3f17dd22c02f7f5198ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1350/0*PQTm0HWuxQHuxHyl.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图11。检索于2020年4月19日，来自<a class="ae kz" rel="noopener" target="_blank" href="/the-5-clustering-algorithms-data-scientists-need-to-know-a36d136ef68">走向数据科学(Seif，2018) </a></p></figure><p id="768a" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><em class="ol">我推荐查一下</em> <a class="ae kz" href="https://dbs.ifi.uni-heidelberg.de/files/Team/eschubert/lectures/KDDClusterAnalysis17-screen.pdf#page=214" rel="noopener ugc nofollow" target="_blank"> <em class="ol">这个</em> </a> <em class="ol"> DBSCAN玩具例子(舒伯特，2018) </em></p></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h1 id="d4f8" class="nb nc it bd nd ne nf ng nh ni nj nk nl jz nm ka nn kc no kd np kf nq kg nr ns bi translated">MinPts和ε怎么选？</h1><p id="e097" class="pw-post-body-paragraph la lb it lc b ld nt ju lf lg nu jx li lj nv ll lm ln nw lp lq lr nx lt lu lv im bi translated">这是一个价值百万的问题。首先，我将定义一些术语:</p><p id="7591" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">函数k-distance(p) </strong>:点p到其K最近邻的距离(用户选择K值)。例如，如果用户选择k值为4(图12)，那么从点p到4最近邻的距离就是从p到它的4最近邻的距离。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/b3fc9425a5d4042e480753975f037b31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*OPFxvZkrGjrZyY0oi3OZxg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图12- k距离。检索自<a class="ae kz" href="https://www.dbs.ifi.lmu.de/Lehre/KDD/SS16/skript/4_Clustering.pdf" rel="noopener ugc nofollow" target="_blank">数据库中的知识发现(Seidl，2016) </a></p></figure><p id="942e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu"> K距离图</strong>:所有物体的K距离，按降序排列。也称为排序k线图。</p><h2 id="a3b0" class="pc nc it bd nd pd pe dn nh pf pg dp nl lj ph pi nn ln pj pk np lr pl pm nr pn bi translated">参数估计</h2><p id="107c" class="pw-post-body-paragraph la lb it lc b ld nt ju lf lg nu jx li lj nv ll lm ln nw lp lq lr nx lt lu lv im bi translated">如果ε值很小，许多点可能会被视为异常值，因为它们不是核心点或边界点(ε邻域将非常小)。较大的ε值可能会导致大量的点位于同一个聚类中。</p><p id="e2ab" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">如前所述，DBSCAN的主要优势之一是它可以检测噪声。根据舒伯特、桑德等人在2017年进行的一项<a class="ae kz" href="https://dl.acm.org/doi/pdf/10.1145/3068335" rel="noopener ugc nofollow" target="_blank">研究</a>，理想的噪音量通常在1%到30%之间。该研究的另一个启示是，如果一个聚类包含数据集的许多(20%-50%)点，则表明您应该为ε选择一个较小的值，或者尝试另一种聚类方法。</p><blockquote class="mk"><p id="58de" class="ml mm it bd mn mo mp mq mr ms mt lv dk translated">一般情况下，ε应选择尽可能小的。</p></blockquote><p id="0f32" class="pw-post-body-paragraph la lb it lc b ld oe ju lf lg of jx li lj og ll lm ln oh lp lq lr oi lt lu lv im bi translated">根据DBSCAN算法的<a class="ae kz" href="https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">发起人</a>(Ester，Kriegel，Sander和Xu，1996)，我们可以使用这种启发式算法来找到ε和MinPts:</p><p id="dd54" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">对于给定的k，我们建立排序的k-dist图。阈值点是排序的k-dist图的第一个“谷”中的第一个点。阈值的k-dist值将是ε值。研究表明，对于k &gt; 4的k-dist图与4-dist图没有显著不同，并且它们需要相当多的计算。因此，对于所有数据库(对于二维数据)，他们通过将参数MinPts设置为4来消除该参数。阈值点的4-dist值用作DBSCAN的ε值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/a579e6e218891ec17d1084818a6eb53a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*zviJVN_hWgd2H5xUhsh56A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图13 — K分布图(对于k=4) ( <a class="ae kz" href="https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"> Ester，Kriegel，Sander和Xu，1996) </a></p></figure><p id="37e9" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">如果不希望MinPts值为4，可以决定MinPts = k+1。选择k的一个启发式方法是将k设为2∫维数-1 <a class="ae kz" href="https://s3.amazonaws.com/academia.edu.documents/49949929/a_3A100974521941920161028-6495-1racv9j.pdf?response-content-disposition=inline%3B%20filename%3DDensity-Based_Clustering_in_Spatial_Data.pdf&amp;X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=ASIATUSBJ6BAG3OEV5TH%2F20200420%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20200420T102132Z&amp;X-Amz-Expires=3600&amp;X-Amz-Security-Token=IQoJb3JpZ2luX2VjEOr%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIH0BDQ%2Bu4%2B4Gn2EYyNJb7mXMz9ICyY6nGWlN1AGAqwiAAiEAq7WYBwhWCSfMR%2Fk2y7EBKCuUGdZKVVCNxWEJafNNneMqtAMIEhAAGgwyNTAzMTg4MTEyMDAiDDVqaIEkFqUHl40KKSqRA0ibNBxUVWpXyxUnNcrD1QJ5vkKZjbPCPJDOhOdWbkcHXzSgkrlUPWYznXPIKCYtum2gQnN4dCfzihWiYaaQdfdRZIw6z1wm38GPDolFJU5gdZtX2y5bFSg9v3H1BSjD6kBf3UHTmbv3ebD3zQAbqkJ2jZPd2VfRUNbSObOhS3N2PU7m2Y5YYfEdDh7yyq9GUGeVFRaNQqFsQDyW5viARJJtpnzJtSiKd3uuZyZ7FJNUQnyHprLI8tV0BrzfQuXS50TL9KkgCmDyihWWiSPYJEP5EerVURa5FwdySl2bpHx7kH4GyPE0fFwCvTnkPxh1pFpmSIdoL0713IFyruacO3aBxg5N9H3rUO8gCDuFMsHu%2Fmp363H2bfVJbR1DZemYj7%2BiSy0DP8stII%2FYz1I8CZ2fdj4CNZvUQVj%2FkxCKGp72HccgptUDuqk9MYpdMDMxRZpuTXEBAWSNXcw5beDExvY3qmerbz6M1j6RYM4vxBtNkD95S9xCrBPX6CPI2ronZC68fbXoUYxmicjGR509yFo4MLzL9fQFOusBcr%2BPj%2FTtuyXCgwsSWKTTb9CutvWs7Qm1UtEBAhKNY4bM1fvgXNfedXe7nIUrHx3TcBTQc%2Bc1GhuH89OCBapsUUaUwZs8TamygNpwxObOIrFYKbjVryH5%2BemUJFUcUCu45IxD2%2BdW1A2yNykqDMff7lgg1hliHxIoDoecU36sAKPdjTE55O8gyD4cU3OP%2F6LBfT0y2kUzXttM%2BYmDsU9lIiHOQXYB52KsYF%2FJNiIprxM2g4RZwM92EPVBN9pNwNj5aOKKAZ4nsXHmncw60aSrGgowcQNckTbTuOg1PaGaUrTCJwmmiv%2F0dRvwCQ%3D%3D&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=b02ed8e6de1a562c2ff34a9971cbd06dc6c161c47af5c4e728c68c4b9fda8e83" rel="noopener ugc nofollow" target="_blank"> (Sander，Ester等人，1998)。</a></p><p id="8338" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">另一种选择MinPts值的启发式方法是</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi po"><img src="../Images/acef5a94d55e35ba6a5e11336349a4d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*TcyGiOxo6ykPMyfUaqV5PA.png"/></div></figure><p id="0da0" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">其中，Pᵢ是点I的ε-邻域中的点数，n是数据集中的点数。对于ε的每个不同值，我们将得到相应的MinPts值(<a class="ae kz" href="http://ijiset.com/v1s4/IJISET_V1_I4_48.pdf" rel="noopener ugc nofollow" target="_blank">萨万特，2014) </a>。</p><p id="9276" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在下一个例子中(图15 ),我们:</p><ol class=""><li id="0228" class="lw lx it lc b ld le lg lh lj ly ln lz lr ma lv pp mc md me bi translated">选择K =3。</li><li id="eb64" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv pp mc md me bi translated">计算每个点的第三近邻距离。例如，对于点n，这个距离稍大于5。</li><li id="d527" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv pp mc md me bi translated">对距离进行排序(图15中的柱状图是在我们对所有的点距离进行排序之后)。</li><li id="8d74" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv pp mc md me bi translated">选择ε为第一个膝盖的值，所以ε ≈ 2.5。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/432451de38c0d1007c9bdca235b39afd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*Go5jLkjC2RgNMGwhKO9J5w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图14-使用k线图选择参数。检索自埃里希·舒伯特2018年出版的<a class="ae kz" href="https://dbs.ifi.uni-heidelberg.de/files/Team/eschubert/lectures/KDDClusterAnalysis17-screen.pdf" rel="noopener ugc nofollow" target="_blank">数据库中的知识发现</a>。由我编辑</p></figure></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h1 id="42dc" class="nb nc it bd nd ne nf ng nh ni nj nk nl jz nm ka nn kc no kd np kf nq kg nr ns bi translated">计算的复杂性</h1><p id="11f2" class="pw-post-body-paragraph la lb it lc b ld nt ju lf lg nu jx li lj nv ll lm ln nw lp lq lr nx lt lu lv im bi translated">如前所述，DBSCAN检查数据中每个点的ε-邻域。检查它需要O(n)。</p><blockquote class="mk"><p id="d13f" class="ml mm it bd mn mo mp mq mr ms mt lv dk translated">因此，在最坏的情况下，DBSCAN的总复杂度是O(n)。</p></blockquote><p id="af66" class="pw-post-body-paragraph la lb it lc b ld oe ju lf lg of jx li lj og ll lm ln oh lp lq lr oi lt lu lv im bi translated">在某些情况下，复杂度可以降低到O(nlogn)。</p></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h1 id="4f42" class="nb nc it bd nd ne nf ng nh ni nj nk nl jz nm ka nn kc no kd np kf nq kg nr ns bi translated">DBSCAN PROS</h1><ul class=""><li id="69e4" class="lw lx it lc b ld nt lg nu lj pq ln pr lr ps lv mb mc md me bi translated">识别随机形状的簇</li><li id="8952" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">不需要事先知道数据中的聚类数(与K-means相反)</li><li id="13de" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">处理噪音</li></ul><h1 id="af4b" class="nb nc it bd nd ne pt ng nh ni pu nk nl jz pv ka nn kc pw kd np kf px kg nr ns bi translated">DBSCAN</h1><ul class=""><li id="613b" class="lw lx it lc b ld nt lg nu lj pq ln pr lr ps lv mb mc md me bi translated">具有不同密度的数据集是有问题的</li><li id="1c89" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">输入参数(ε和MinPts)可能难以确定</li><li id="d9dd" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">计算复杂度——当维数很高时，计算复杂度为O(n)</li></ul></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h1 id="2c7f" class="nb nc it bd nd ne nf ng nh ni nj nk nl jz nm ka nn kc no kd np kf nq kg nr ns bi translated">摘要</h1><blockquote class="mk"><p id="1684" class="ml mm it bd mn mo mp mq mr ms mt lv dk translated">DBSCAN是一种基于密度的聚类方法，可以发现非球形的聚类。</p></blockquote><p id="8843" class="pw-post-body-paragraph la lb it lc b ld oe ju lf lg of jx li lj og ll lm ln oh lp lq lr oi lt lu lv im bi translated">它的主要参数是ε和Minpts。ε是邻域(一组相互靠近的点)的半径。如果邻域将至少包括MinPts，则它将被视为密集区域，并将成为聚类的一部分。</p><p id="2bbb" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">有许多选择参数的方法。一种流行的启发式方法是选择一个k值并构建一个排序的k-dist图。阈值点是排序的k-dist图的第一个“谷”中的第一个点。阈值的k-dist值将是ε值<strong class="lc iu">。</strong>min pts值将是k+1的值。您可以选择4作为K和MinPts值的默认值。</p><p id="54ec" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">DBSCAN的主要优点是不需要预先知道簇的数量，它可以识别随机形状的簇。主要缺点是计算复杂度高，需要为ε和MinPts选择好的值，以及处理不同密度的数据集。</p></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h1 id="c542" class="nb nc it bd nd ne nf ng nh ni nj nk nl jz nm ka nn kc no kd np kf nq kg nr ns bi translated">参考</h1><ol class=""><li id="8d54" class="lw lx it lc b ld nt lg nu lj pq ln pr lr ps lv pp mc md me bi translated"><a class="ae kz" href="https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">艾斯特，m .，克里格尔，H. P .，桑德，j .，&amp;徐，X. (1996年8月)。一种基于密度的发现带噪声的大型空间数据库中聚类的算法。在<em class="ol"> Kdd </em>(第96卷，№34，第226–231页)。</a></li><li id="a47b" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv pp mc md me bi translated"><a class="ae kz" href="http://myweb.sabanciuniv.edu/rdehkharghani/files/2016/02/The-Morgan-Kaufmann-Series-in-Data-Management-Systems-Jiawei-Han-Micheline-Kamber-Jian-Pei-Data-Mining.-Concepts-and-Techniques-3rd-Edition-Morgan-Kaufmann-2011.pdf" rel="noopener ugc nofollow" target="_blank">韩，j .，Kamber，m .，T13裴，J. (2011)。数据挖掘概念和技术第三版。摩根·考夫曼。</a></li><li id="c40a" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv pp mc md me bi translated"><a class="ae kz" href="https://en.wikipedia.org/wiki/DBSCAN" rel="noopener ugc nofollow" target="_blank"> DBSCAN。(2020).于2020年4月8日从https://en.wikipedia.org/wiki/DBSCAN检索</a></li><li id="c971" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv pp mc md me bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/how-dbscan-works-and-why-should-i-use-it-443b4a191c80">普拉多，K. (2017)。DBSCAN如何工作，为什么要使用它？。检索于2020年3月11日，来自https://towards data science . com/how-DBS can-works-and-why-should-I-use-it-443 B4 a191c 80</a></li><li id="3f97" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv pp mc md me bi translated">萨万特，K. (2014年)。确定DBSCAN参数的自适应方法。<em class="ol">国际创新科学杂志，工程&amp;技术</em>，<em class="ol"> 1 </em> (4)，329–334页。</li><li id="1851" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv pp mc md me bi translated"><a class="ae kz" href="https://s3.amazonaws.com/academia.edu.documents/49949929/a_3A100974521941920161028-6495-1racv9j.pdf?response-content-disposition=inline%3B%20filename%3DDensity-Based_Clustering_in_Spatial_Data.pdf&amp;X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=ASIATUSBJ6BAG3OEV5TH%2F20200420%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20200420T102132Z&amp;X-Amz-Expires=3600&amp;X-Amz-Security-Token=IQoJb3JpZ2luX2VjEOr%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIH0BDQ%2Bu4%2B4Gn2EYyNJb7mXMz9ICyY6nGWlN1AGAqwiAAiEAq7WYBwhWCSfMR%2Fk2y7EBKCuUGdZKVVCNxWEJafNNneMqtAMIEhAAGgwyNTAzMTg4MTEyMDAiDDVqaIEkFqUHl40KKSqRA0ibNBxUVWpXyxUnNcrD1QJ5vkKZjbPCPJDOhOdWbkcHXzSgkrlUPWYznXPIKCYtum2gQnN4dCfzihWiYaaQdfdRZIw6z1wm38GPDolFJU5gdZtX2y5bFSg9v3H1BSjD6kBf3UHTmbv3ebD3zQAbqkJ2jZPd2VfRUNbSObOhS3N2PU7m2Y5YYfEdDh7yyq9GUGeVFRaNQqFsQDyW5viARJJtpnzJtSiKd3uuZyZ7FJNUQnyHprLI8tV0BrzfQuXS50TL9KkgCmDyihWWiSPYJEP5EerVURa5FwdySl2bpHx7kH4GyPE0fFwCvTnkPxh1pFpmSIdoL0713IFyruacO3aBxg5N9H3rUO8gCDuFMsHu%2Fmp363H2bfVJbR1DZemYj7%2BiSy0DP8stII%2FYz1I8CZ2fdj4CNZvUQVj%2FkxCKGp72HccgptUDuqk9MYpdMDMxRZpuTXEBAWSNXcw5beDExvY3qmerbz6M1j6RYM4vxBtNkD95S9xCrBPX6CPI2ronZC68fbXoUYxmicjGR509yFo4MLzL9fQFOusBcr%2BPj%2FTtuyXCgwsSWKTTb9CutvWs7Qm1UtEBAhKNY4bM1fvgXNfedXe7nIUrHx3TcBTQc%2Bc1GhuH89OCBapsUUaUwZs8TamygNpwxObOIrFYKbjVryH5%2BemUJFUcUCu45IxD2%2BdW1A2yNykqDMff7lgg1hliHxIoDoecU36sAKPdjTE55O8gyD4cU3OP%2F6LBfT0y2kUzXttM%2BYmDsU9lIiHOQXYB52KsYF%2FJNiIprxM2g4RZwM92EPVBN9pNwNj5aOKKAZ4nsXHmncw60aSrGgowcQNckTbTuOg1PaGaUrTCJwmmiv%2F0dRvwCQ%3D%3D&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=b02ed8e6de1a562c2ff34a9971cbd06dc6c161c47af5c4e728c68c4b9fda8e83" rel="noopener ugc nofollow" target="_blank">桑德，j .，埃斯特，m .，克里格尔，H. P .，T23徐，X. (1998)。空间数据库中基于密度的聚类:gdbscan算法及其应用。<em class="ol">数据挖掘与知识发现</em>，<em class="ol"> 2 </em> (2)，169–194。</a></li><li id="ba86" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv pp mc md me bi translated"><a class="ae kz" href="https://www.dbs.ifi.lmu.de/Lehre/KDD/SS16/skript/4_Clustering.pdf" rel="noopener ugc nofollow" target="_blank">塞德尔，T. (2016)。<em class="ol">数据库中的知识发现——第4章:聚类</em>。介绍，路德维希-马克西米利安-慕尼黑大学。</a></li><li id="4fb8" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv pp mc md me bi translated"><a class="ae kz" href="https://dl.acm.org/doi/pdf/10.1145/3068335" rel="noopener ugc nofollow" target="_blank">舒伯特，e，桑德，j，埃斯特，m，克里格尔，h . p .&amp;徐，X. (2017)。DBSCAN重温，重温:为什么和如何你应该(仍然)使用DBSCAN。<em class="ol">美国计算机学会数据库系统汇刊(TODS) </em>，<em class="ol"> 42 </em> (3)，1–21。</a></li><li id="8fa8" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv pp mc md me bi translated">拉夫桑贾尼、扎拉·阿斯加里·瓦尔扎内·纳西贝·埃马米·楚坎托。层次聚类算法综述。数学和计算机科学杂志，229–240页。</li><li id="43ae" class="lw lx it lc b ld mf lg mg lj mh ln mi lr mj lv pp mc md me bi translated"><a class="ae kz" href="https://books.google.co.il/books?hl=en&amp;lr=&amp;id=Gh9GAwAAQBAJ&amp;oi=fnd&amp;pg=PR9&amp;ots=JmG7PES-qp&amp;sig=-pYKMgBCYkCp5x6yDqQutHnekEs&amp;redir_esc=y#v=onepage&amp;q&amp;f=false" rel="noopener ugc nofollow" target="_blank">m . j .扎基，&amp;w .梅拉(2014)。<em class="ol">数据挖掘和分析:基本概念和算法</em>。剑桥大学出版社。</a></li></ol></div></div>    
</body>
</html>