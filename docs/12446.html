<html>
<head>
<title>DBSCAN with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Python 的 DBSCAN</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/dbscan-with-python-743162371dca?source=collection_archive---------10-----------------------#2020-08-27">https://towardsdatascience.com/dbscan-with-python-743162371dca?source=collection_archive---------10-----------------------#2020-08-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="5f4f" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">包含 GitHub repo 的链接</h2><div class=""/><div class=""><h2 id="c3a5" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">带噪声应用的基于密度的空间聚类初学者指南(带示例)</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/8a331f99f7cd417d5b8978f00a3e67d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1K5tsxPDxQuM9YVN6FcBVQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">KMeans 在处理任意形状的簇时有困难。图片由 Mikio Harman 提供</p></figure><p id="a3a7" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi ma translated">聚类是一种无监督的学习技术，它在数据中寻找模式，而不需要被明确告知要寻找什么模式。</p><p id="bcf4" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">DBSCAN 通过测量每个点之间的距离来做到这一点，如果足够多的点足够靠近，那么 DBSCAN 会将其分类为一个新的聚类。</p><p id="6135" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">如上所示，在测试数据中有两个不同的集群。另一种流行的聚类技术 KMeans 无法准确地对这些数据进行聚类，因为当 k=2 时，<a class="ae mj" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html" rel="noopener ugc nofollow" target="_blank"> KMeans </a>在聚类之间创建了一个线性可分的边界。</p><p id="2e37" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">DBSCAN 根据两个参数定义聚类:Epsilon 和 Min_Points</p><blockquote class="mk ml mm"><p id="b126" class="le lf mn lg b lh li ka lj lk ll kd lm mo lo lp lq mp ls lt lu mq lw lx ly lz ij bi translated"><strong class="lg ja">ε</strong>—一个点到另一个点的最大距离被认为是邻居。</p><p id="f2b3" class="le lf mn lg b lh li ka lj lk ll kd lm mo lo lp lq mp ls lt lu mq lw lx ly lz ij bi translated"><strong class="lg ja"> Min_Points </strong> —在ε的范围内被认为是一个聚类所需的点数。</p></blockquote><h2 id="5f6d" class="mr ms iq bd mt mu mv dn mw mx my dp mz ln na nb nc lr nd ne nf lv ng nh ni iw bi translated">DBSCAN 的优势</h2><p id="6cf9" class="pw-post-body-paragraph le lf iq lg b lh nj ka lj lk nk kd lm ln nl lp lq lr nm lt lu lv nn lx ly lz ij bi translated"><strong class="lg ja">确定输入参数需要最少的领域知识。</strong></p><p id="a8cc" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">其他聚类算法，如 KMeans，要求用户知道数据中存在多少个聚类。</p><p id="c74d" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">DBSCAN 不要求找到多少个聚类，而是要求用户输入每个数据点可以被认为是一个聚类的一部分的最大距离，以及形成一个聚类需要多少个数据点。</p><p id="8c07" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">它能发现任何形状的星团。</p><p id="b819" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">由于 DBSCAN 基于 epsilon 和每个点的邻居数量来创建聚类，因此它可以找到任何形状的聚类。当集群具有相同的密度(点之间的距离)时，DBSCAN 工作得最好。当存在不同密度的簇时，这会使 DBSCAN 难以识别簇。</p><h2 id="ee76" class="mr ms iq bd mt mu mv dn mw mx my dp mz ln na nb nc lr nd ne nf lv ng nh ni iw bi translated">跟着走！</h2><p id="f93a" class="pw-post-body-paragraph le lf iq lg b lh nj ka lj lk nk kd lm ln nl lp lq lr nm lt lu lv nn lx ly lz ij bi translated"><a class="ae mj" href="https://colab.research.google.com/drive/1rCQl2sc5wEGKx0CgG-hW_Dg959qT3qct?usp=sharing" rel="noopener ugc nofollow" target="_blank">点击此处</a>打开实现 Scikit 的 Google Colab 笔记本——从头开始学习 DBSCAN 和 DBSCAN2。如果你想了解更多关于引擎盖下发生的事情，请继续阅读。</p><pre class="kp kq kr ks gt no np nq nr aw ns bi"><span id="b4cd" class="mr ms iq np b gy nt nu l nv nw"><strong class="np ja"># Download the test package</strong><br/>pip install -i <a class="ae mj" href="https://test.pypi.org/simple/" rel="noopener ugc nofollow" target="_blank">https://test.pypi.org/simple/</a> dbscan2==0.0.3</span><span id="0c84" class="mr ms iq np b gy nx nu l nv nw"><strong class="np ja"># Import it!</strong><br/>from dbscan2 import dbscan2</span><span id="2867" class="mr ms iq np b gy nx nu l nv nw"><strong class="np ja"># If you would like to plot the results import the following</strong><br/>from sklearn.datasets import make_moons<br/>import pandas as pd</span></pre><p id="f3fe" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">为了从头开始理解和实现 DBSCAN，我们需要知道 DBSCAN 是如何对数据进行聚类的。除了ε点和最小点，还有三个基本术语需要理解:</p><blockquote class="mk ml mm"><p id="e233" class="le lf mn lg b lh li ka lj lk ll kd lm mo lo lp lq mp ls lt lu mq lw lx ly lz ij bi translated"><strong class="lg ja">噪声</strong> —这是一个在 epsilon 内没有足够的邻居来成为聚类的一部分(包括其自身)的点。</p><p id="a3d2" class="le lf mn lg b lh li ka lj lk ll kd lm mo lo lp lq mp ls lt lu mq lw lx ly lz ij bi translated"><strong class="lg ja">边界点</strong> —这是一个在ε内有邻居但没有足够邻居成为核心点的点。这些点构成了群集的边缘。</p><p id="d510" class="le lf mn lg b lh li ka lj lk ll kd lm mo lo lp lq mp ls lt lu mq lw lx ly lz ij bi translated"><strong class="lg ja">核心点</strong>——具有 epsilon(包括其自身)内所需最小点数的点。这些点连同边界点将形成一个簇。</p></blockquote><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ny"><img src="../Images/6bf100d111a8a45dc43b3b0a934a933c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PenJiBtSaeDZD9P9XhLBmA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图片由 Mikio Harman 提供</p></figure><p id="e105" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们将使用一个类来实现 DBSCAN，并将其命名为 dbscan2。它将有两个主要方法:拟合和预测。</p><p id="62a0" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><code class="fe nz oa ob np b"><strong class="lg ja">def __init__()</strong></code></p><p id="5c12" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">将使用标准化的两个特征数组ε和创建聚类所需的点数来初始化该类。它还将用一个簇标签和一个噪声标签来初始化。</p><pre class="kp kq kr ks gt no np nq nr aw ns bi"><span id="fc97" class="mr ms iq np b gy nt nu l nv nw">class dbscan2():<br/>    def __init__(self,df, epsilon=1, min_points=5):<br/>        self.df = np.array(df)<br/>        self.epsilon = epsilon<br/>        self.min_points = min_points<br/>        self.cluster_label = 0<br/>        self.noise = 0</span></pre><p id="7c4c" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">助手功能</strong></p><p id="34bd" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们将使用欧几里得距离来度量每个点之间的距离。欧几里德距离将测量从一对坐标到另一对坐标的普通直线距离。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/37743aa902392158019b3f86526004a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*pa_-xlpNYQBO8gIvmj-atA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图片来自<a class="ae mj" href="https://en.wikipedia.org/wiki/Euclidean_distance" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></figure><pre class="kp kq kr ks gt no np nq nr aw ns bi"><span id="23f1" class="mr ms iq np b gy nt nu l nv nw">def dist(self, point1, point2):<br/>    """Euclid distance function"""<br/>    x1 = point1[0]<br/>    x2 = point2[0]<br/>    y1 = point1[1]<br/>    y2 = point2[1]</span><span id="a340" class="mr ms iq np b gy nx nu l nv nw"># create the points<br/>    p1 = (x1 - x2)**2<br/>    p2 = (y1 - y2)**2<br/>    return np.sqrt(p1 + p2)</span></pre><p id="c431" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们需要的另一个助手函数叫做<code class="fe nz oa ob np b">rangeQuery</code>。该函数将帮助我们找出每个点在ε内有多少个邻居。</p><pre class="kp kq kr ks gt no np nq nr aw ns bi"><span id="a76f" class="mr ms iq np b gy nt nu l nv nw">def rangeQuery(self, x):<br/>    """Query database against x and return all points that are &lt;= <br/>    epsilon"""</span><span id="0130" class="mr ms iq np b gy nx nu l nv nw">neighbors = []</span><span id="891d" class="mr ms iq np b gy nx nu l nv nw">for y in range(len(self.df)):<br/>        q = self.df[y, :2]</span><span id="8638" class="mr ms iq np b gy nx nu l nv nw"><strong class="np ja"># If the distance is &lt;= than epsilon then append to <br/>          neighbors list</strong><br/>        if self.dist(x, q) &lt;= self.epsilon:<br/>            neighbors.append(y)</span><span id="5e0c" class="mr ms iq np b gy nx nu l nv nw">return neighbors</span></pre><p id="a59d" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><code class="fe nz oa ob np b"><strong class="lg ja">def fit():</strong></code></p><p id="1c59" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们的拟合函数将遍历整个数据集，并确定数据集中每个点有多少个邻居。</p><p id="4afa" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">如果单个点没有足够的邻居(<code class="fe nz oa ob np b">neighbors &lt; min_points</code>，那么它将被标记为噪声。</p><p id="5392" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">如果一个点有足够多的邻居(<code class="fe nz oa ob np b">neighbors ≥ min_points</code>)，那么该点将被分配一个新的聚类标签，并且它的所有邻居也将被赋予相同的标签。fit 函数将进入一个 while 循环，将所有的邻居添加到一个<code class="fe nz oa ob np b">Queue</code>中，以便它们可以与新发现的邻居的邻居一起被正确地标记为新聚类的一部分。</p><p id="d1ff" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这个过程将继续，直到算法已经检查了所有点。</p><p id="a9a6" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><code class="fe nz oa ob np b"><strong class="lg ja">def predict():</strong></code></p><p id="4779" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">进行预测时，算法将使用<code class="fe nz oa ob np b">rangeQuery</code>识别新输入点是否有任何邻居。如果是，那么新点将被预测为具有与其邻居相同的标签。</p><p id="17bf" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">这是我们最终完成的类的样子</strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="f89d" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">与 Scikit-Learn 版本相比如何？</strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi of"><img src="../Images/74acbb578ac0f3d5292a32a4d00079d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A9GpgWyR0lJj8QUHUERnaA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图片由 Mikio Harman 提供</p></figure><p id="6d9c" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">正如所料，我们从头开始的实现最终得到了与 Scikit-Learn 版本相同的结果。我们的 DBSCAN 版本需要更长的时间，我仍然会使用 Scikit-Learns 版本，但是希望从头开始实现该算法可以帮助您更好地理解如何使用 DBSCAN 找到任意的簇形状。</p><p id="0954" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">找到博客的代码</strong> <a class="ae mj" href="https://github.com/mpHarm88/projects/blob/master/dbscan/notebooks/dbscan.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="lg ja">这里</strong> </a></p><h2 id="65b5" class="mr ms iq bd mt mu mv dn mw mx my dp mz ln na nb nc lr nd ne nf lv ng nh ni iw bi translated">参考</h2><p id="fd30" class="pw-post-body-paragraph le lf iq lg b lh nj ka lj lk nk kd lm ln nl lp lq lr nm lt lu lv nn lx ly lz ij bi translated"><a class="ae mj" href="https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf" rel="noopener ugc nofollow" target="_blank">一种基于密度的算法，用于在带有噪声的大型空间数据库中发现聚类</a></p><p id="7682" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><a class="ae mj" href="https://en.wikipedia.org/wiki/DBSCAN" rel="noopener ugc nofollow" target="_blank">数据库扫描</a></p><p id="f1f7" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><a class="ae mj" href="https://en.wikipedia.org/wiki/Euclidean_distance" rel="noopener ugc nofollow" target="_blank">欧几里德距离</a></p></div></div>    
</body>
</html>