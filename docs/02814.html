<html>
<head>
<title>Build your Data Pipeline on Kubernetes using Kubeflow Pipelines SDK and Argo Workflows</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Kubeflow Pipelines SDK和Argo工作流在Kubernetes上构建您的数据管道</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/build-your-data-pipeline-on-kubernetes-using-kubeflow-pipelines-sdk-and-argo-eef69a80237c?source=collection_archive---------14-----------------------#2020-03-18">https://towardsdatascience.com/build-your-data-pipeline-on-kubernetes-using-kubeflow-pipelines-sdk-and-argo-eef69a80237c?source=collection_archive---------14-----------------------#2020-03-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8bf4" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">运行K8本地数据管道</h2></div><h1 id="9b3e" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">良好数据管道的重要性</h1><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi la"><img src="../Images/9713c4a9a9c44aee274b182c72684a8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WHwsBZuh2OYK7m_y.png"/></div></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">在构建你的机器学习管道的元素上花了多少精力？参考“机器学习系统中隐藏的技术债务”——斯卡利等人。</p></figure><p id="804f" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">对于那些没有看过上图的人，我强烈推荐阅读论文<a class="ae mm" href="https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf" rel="noopener ugc nofollow" target="_blank">“机器学习系统中隐藏的技术债务”</a>。它涵盖了构建机器学习系统的最佳实践。本文中有一节是关于ML系统反模式和管道丛林的:</p><blockquote class="mn mo mp"><p id="9ba2" class="lq lr mq ls b lt lu ju lv lw lx jx ly mr ma mb mc ms me mf mg mt mi mj mk ml im bi translated"><strong class="ls iu">管道丛林</strong>。作为胶水代码的特例，管道丛林经常出现在数据准备中。随着新信号的识别和新信息源的增加，这些可以有机地发展。如果不小心的话，以ML友好格式准备数据的结果系统可能会变成一个由抓取、连接和采样步骤组成的丛林，通常还会有中间文件输出。管理这些管道、检测错误和从故障中恢复都是困难和昂贵的。</p></blockquote><h1 id="8004" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">如何避开管道丛林</h1><p id="46a5" class="pw-post-body-paragraph lq lr it ls b lt mu ju lv lw mv jx ly lz mw mb mc md mx mf mg mh my mj mk ml im bi translated">使用工作流引擎。</p><p id="b204" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">有许多工作流引擎可以帮助管道编排和构建ETL。我不会深入讨论每个框架的利弊，因为那将需要一个完全不同的博客帖子，实际上，我不认为有一个明确的赢家。</p><p id="6ea5" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">这篇博文的目的是向你展示如何使用<a class="ae mm" href="https://www.kubeflow.org/docs/pipelines/sdk/sdk-overview/" rel="noopener ugc nofollow" target="_blank"> Kubeflow Pipelines SDK </a>来运行<a class="ae mm" href="https://github.com/argoproj/argo" rel="noopener ugc nofollow" target="_blank"> Argo工作流</a>。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/a80aaf72de125613318f278be48ccb66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*BabQarZZ3nTjW2K1onpWlQ.png"/></div></figure><h1 id="2e49" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">为什么选择Argo工作流？</h1><p id="e39e" class="pw-post-body-paragraph lq lr it ls b lt mu ju lv lw mv jx ly lz mw mb mc md mx mf mg mh my mj mk ml im bi translated">简单的答案是，它是云原生的，这意味着如果您已经有一个Kubernetes集群在运行，<a class="ae mm" href="https://argoproj.github.io/projects/argo" rel="noopener ugc nofollow" target="_blank"> Argo </a>被实现为<a class="ae mm" href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/" rel="noopener ugc nofollow" target="_blank"> Kubernetes CRD </a>并允许您在集群上原生运行管道。有了Argo，每个任务都在一个pod中执行，你可以像一个<a class="ae mm" href="https://en.wikipedia.org/wiki/Directed_acyclic_graph" rel="noopener ugc nofollow" target="_blank"> DAG </a>一样轻松地执行多个任务。它包含许多重要的特性，如在任务间传递工件、参数化、调度<a class="ae mm" href="https://argoproj.github.io/projects/argo/" rel="noopener ugc nofollow" target="_blank">和更多</a>。</p><h1 id="e38e" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">如何运行Argo工作流？</h1><p id="3c96" class="pw-post-body-paragraph lq lr it ls b lt mu ju lv lw mv jx ly lz mw mb mc md mx mf mg mh my mj mk ml im bi translated">运行Argo工作流的方法是使用YAML配置文件。<br/>下面是一个运行简单的“hello world”任务的示例，该任务运行python docker图像并打印“hello world”。</p><pre class="lb lc ld le gt na nb nc nd aw ne bi"><span id="ddde" class="nf kj it nb b gy ng nh l ni nj">apiVersion: argoproj.io/v1alpha1<br/>kind: Workflow                     # new type of k8s spec<br/>metadata:<br/>  generateName: hello-world-       # name of the workflow spec<br/>  namespace: default<br/>spec:<br/>  entrypoint: hello-world-template # invoke the template<br/>  templates:<br/>  - name: hello-world-template     # name of the template<br/>    container:<br/>      image: python:latest<br/>      command: ["python","-c"]<br/>      args: ["print('hello world')"]</span></pre><p id="ea4d" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">Argo工作流引擎的用户界面具有以下功能:</p><ul class=""><li id="9bee" class="nk nl it ls b lt lu lw lx lz nm md nn mh no ml np nq nr ns bi translated">监控和运行Argo工作流</li><li id="05f2" class="nk nl it ls b lt nt lw nu lz nv md nw mh nx ml np nq nr ns bi translated">查看容器日志、环境变量、任务参数和输出</li><li id="11d8" class="nk nl it ls b lt nt lw nu lz nv md nw mh nx ml np nq nr ns bi translated">查看和运行cron工作流</li></ul><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi ny"><img src="../Images/a964a61cd876d7321415f087360e9227.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DeM_KM8GIgTAxHJURP8UiQ.png"/></div></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">Argo工作流用户界面</p></figure><h1 id="80b2" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">那么我们为什么需要Kubeflow Pipelines SDK呢？</h1><p id="c452" class="pw-post-body-paragraph lq lr it ls b lt mu ju lv lw mv jx ly lz mw mb mc md mx mf mg mh my mj mk ml im bi translated">YAML有它的局限性，特别是当你想运行有许多任务的管道和进行快速迭代的时候。出于这个原因，目前正在构建各种Argo SDKs，这些SDK将使您能够以编程方式在Python中定义Argo工作流，并将您的代码转换为Argo YAML规范。</p><p id="776a" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">最成熟的SDK之一是在<a class="ae mm" href="https://www.kubeflow.org/" rel="noopener ugc nofollow" target="_blank"> Kubeflow </a>项目下构建的。Kubeflow是一个开放的、社区驱动的项目，使得在<a class="ae mm" href="https://kubernetes.io/" rel="noopener ugc nofollow" target="_blank"> Kubernetes </a>上部署和管理ML栈变得容易。包括谷歌、思科、IBM、微软、红帽、亚马逊网络服务和阿里巴巴在内的公司都在生产中使用它。它有一个松散耦合的微服务架构。</p><p id="825c" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">其中一个服务是<a class="ae mm" href="https://www.kubeflow.org/docs/pipelines/overview/pipelines-overview/" rel="noopener ugc nofollow" target="_blank"> Kubeflow Pipelines </a> (KFP)，这是一个基于Docker容器构建和部署可移植、可扩展的机器学习(ML)工作流的平台。它有一个用户界面，用于管理和跟踪实验、作业和运行。</p><p id="447b" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">阿尔戈工作流和KFP之间有细微的区别。Argo是KFP背后的工作流引擎，而KFP主要用于与ML相关的应用。</p><blockquote class="nz"><p id="4f17" class="oa ob it bd oc od oe of og oh oi ml dk translated">与Argo不同，ML相关的用法一直是Kubeflow管道的唯一焦点；它不是针对其他数据处理任务的。</p></blockquote><p id="16f1" class="pw-post-body-paragraph lq lr it ls b lt oj ju lv lw ok jx ly lz ol mb mc md om mf mg mh on mj mk ml im bi translated"><strong class="ls iu">ML相关用法在哪里开始和结束？</strong> <em class="mq"> <br/> </em>我发现Argo对于像数据摄取和一般数据处理管道这样的任务来说更自然，这些任务并不意味着以运行ML实验来结束。</p><p id="9c66" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">由于Argo是KFP背后的工作流引擎，<strong class="ls iu">我们可以使用KFP python SDK来定义python中的Argo工作流</strong>。<a class="ae mm" href="https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.html" rel="noopener ugc nofollow" target="_blank"> KFP SDK </a>提供了一组Python包，您可以使用它们来指定和运行您的工作流。这些管道将按照阿尔戈YAML规范进行编译。只需用<code class="fe oo op oq nb b">pip install kfp</code>安装包即可使用。</p><h1 id="fd94" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">工作流程示例</h1><p id="9dea" class="pw-post-body-paragraph lq lr it ls b lt mu ju lv lw mv jx ly lz mw mb mc md mx mf mg mh my mj mk ml im bi translated">在下面的例子中，我将向您展示如何用KFP python SDK编写一个简单的管道。管道将接收一个参数，运行for-each循环，并在任务之间传输数据(大多数数据处理管道的一般构造块)。它是使用KFP python SDK编写的，将被编译成阿尔戈YAML配置。</p><pre class="lb lc ld le gt na nb nc nd aw ne bi"><span id="7c7f" class="nf kj it nb b gy ng nh l ni nj">import kfp</span><span id="57e9" class="nf kj it nb b gy or nh l ni nj">@kfp.components.func_to_container_op<br/>def print_func(param: int):<br/>  print(str(param))</span><span id="0ba3" class="nf kj it nb b gy or nh l ni nj">@kfp.components.func_to_container_op<br/>def list_func(param: int) -&gt; list:<br/>  return list(range(param))</span><span id="8cde" class="nf kj it nb b gy or nh l ni nj">@kfp.dsl.pipeline(name='pipeline')<br/>def pipeline(param: int):<br/>  list_func_op = list_func(param)<br/>  with kfp.dsl.ParallelFor(list_func_op.output) as param:<br/>    print_func(param)</span><span id="7d35" class="nf kj it nb b gy or nh l ni nj">if __name__ == '__main__':<br/>  workflow_dict = kfp.compiler.Compiler()._create_workflow(pipeline)<br/>  workflow_dict['metadata']['namespace'] = "default"<br/>  del workflow_dict['spec']['serviceAccountName']<br/>  kfp.compiler.Compiler._write_workflow(workflow_dict, 'pipe.yaml')</span></pre><p id="7978" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">让我们解释一下脚本的不同部分</p><pre class="lb lc ld le gt na nb nc nd aw ne bi"><span id="f41c" class="nf kj it nb b gy ng nh l ni nj">@kfp.components.func_to_container_op<br/>def print_func(param: int):<br/>  print(str(param))</span><span id="5b4d" class="nf kj it nb b gy or nh l ni nj">@kfp.components.func_to_container_op<br/>def list_func(param: int) -&gt; list:<br/>  return list(range(param))</span></pre><p id="cd80" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">用<code class="fe oo op oq nb b">@func_to_container_op</code> decorator包装python函数(任务)会将函数转换成<em class="mq">任务组件</em>并返回一个任务(ContainerOp)工厂。该任务将在Docker容器内部运行(默认图像是<em class="mq">tensor flow/tensor flow:1 . 13 . 2-py3</em>)。也可以改变<a class="ae mm" href="https://kubeflow-pipelines.readthedocs.io/en/latest/_modules/kfp/components/_python_op.html#func_to_container_op" rel="noopener ugc nofollow" target="_blank">基本图像</a>。</p><pre class="lb lc ld le gt na nb nc nd aw ne bi"><span id="95b9" class="nf kj it nb b gy ng nh l ni nj">@kfp.dsl.pipeline(name='pipeline')<br/>def pipeline(param: int):<br/>  list_func_op = list_func(param)<br/>  with kfp.dsl.ParallelFor(list_func_op.output) as param:<br/>    print_func(param)</span></pre><p id="07fb" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">用一个<code class="fe oo op oq nb b">@dsl.pipeline</code>装饰器包装你的函数会将函数转换成一个<em class="mq">管道组件</em>，它描述了<em class="mq">任务组件</em>如何相互交互。任务之间有许多不同的交互方式(Dag、loops、conditions等)。</p><p id="dab3" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">在上面的例子中，管道接收一个参数，该参数将指定要运行的子任务的数量。<code class="fe oo op oq nb b"><em class="mq">list_func_op </em></code>是一个运行<code class="fe oo op oq nb b"><em class="mq">list_func</em></code>的容器组件，对于<code class="fe oo op oq nb b"><em class="mq">list_func </em></code>返回的列表中的每一项，KFP将启动另一个运行<code class="fe oo op oq nb b"><em class="mq">print_func</em> </code>的容器，并将相关列表项作为参数。每个任务将在Kubernetes pods上并行运行。</p><p id="e0ea" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">眼尖的读者可能会问:“不同的任务之间是如何传输数据的？”。要做到这一点，你需要为Argo(例如S3或GCS)配置一个<em class="mq">工件库</em>  <em class="mq"> </em>。您还可以使用<code class="fe oo op oq nb b">kfp.dsl.ArtifactLocation.</code>为每个管道配置不同的工件存储库。在我们的例子中，KFP通过用JSON序列化程序包装我们的函数来保存和加载数据，JSON序列化程序将数据保存到工件存储中。</p><p id="f2ac" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">最终线路将编译管道并输出阿尔戈YAML。</p><pre class="lb lc ld le gt na nb nc nd aw ne bi"><span id="9a89" class="nf kj it nb b gy ng nh l ni nj">workflow_dict = kfp.compiler.Compiler()._create_workflow(pipeline)</span><span id="3398" class="nf kj it nb b gy or nh l ni nj"># The following lines are needed to adapt kfp to argo yaml<br/>workflow_dict['metadata']['namespace'] = "default"<br/>del workflow_dict['spec']['serviceAccountName']</span><span id="932e" class="nf kj it nb b gy or nh l ni nj"># Save yaml output<br/>kfp.compiler.Compiler._write_workflow(workflow_dict, 'pipe.yaml')</span></pre><p id="f377" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">一旦你得到了YAML，你就可以使用Argo命令行界面运行它:</p><pre class="lb lc ld le gt na nb nc nd aw ne bi"><span id="fc65" class="nf kj it nb b gy ng nh l ni nj">argo submit --watch pipe.yaml -p param=<strong class="nb iu">5</strong></span></pre><p id="1695" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">最后，这是它在Argo UI中的样子:</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi os"><img src="../Images/38318c15d235aef2d301a2ff0e72a239.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k_Z9nFdQUOsMXeNZcTJY7A.png"/></div></div></figure><p id="fdbb" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">您可以在以下要点中查看完整的管道脚本，包括工件配置:</p><figure class="lb lc ld le gt lf"><div class="bz fp l di"><div class="ot ou l"/></div></figure></div><div class="ab cl ov ow hx ox" role="separator"><span class="oy bw bk oz pa pb"/><span class="oy bw bk oz pa pb"/><span class="oy bw bk oz pa"/></div><div class="im in io ip iq"><h2 id="d60e" class="nf kj it bd kk pc pd dn ko pe pf dp ks lz pg ph ku md pi pj kw mh pk pl ky pm bi translated">如果你喜欢这篇文章，请随时在推特上关注我</h2></div></div>    
</body>
</html>