<html>
<head>
<title>Problem: Overfitting, Solution: Regularization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">问题:过度拟合，解决方案:正则化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/problem-overfitting-solution-regularization-b466d3d1f4da?source=collection_archive---------21-----------------------#2020-03-25">https://towardsdatascience.com/problem-overfitting-solution-regularization-b466d3d1f4da?source=collection_archive---------21-----------------------#2020-03-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="3db7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">什么使模型过度拟合，我们如何解决这个问题</p><p id="f45f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们都有这样的朋友，他们讲述的故事极其详细。当你问他们最近看的一部电影时，你可能不仅会知道这部电影，还会知道电影院卖爆米花的那个人的手表。另一方面，我们有沉默寡言的朋友，他们只会告诉你这部电影是“好”还是“坏”。</p><p id="68a1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">就细节的数量而言，过度适应和欠适应与那些不同类型的朋友相似。过度拟合的机器学习模型试图提取训练数据的细节，而欠拟合的模型过于笼统，往往会错过训练数据中的重要趋势。</p><p id="e21e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一个更像机器学习的例子是预测图像中的对象。假设我们正在尝试构建一个模型来预测图像中的西红柿:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/7241c9a6465eeb0d57c98c8408dafea6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7WsAuDxSRjTAV2fS_idhdA.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">照片由<a class="ae le" href="https://unsplash.com/@sooong?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Soya Soong </a>在<a class="ae le" href="https://unsplash.com/s/photos/tomato?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><ul class=""><li id="6b3c" class="lf lg it js b jt ju jx jy kb lh kf li kj lj kn lk ll lm ln bi translated">模型A:红色，圆形，顶部是绿色的星形，有一些水滴</li><li id="9068" class="lf lg it js b jt lo jx lp kb lq kf lr kj ls kn lk ll lm ln bi translated">B型:红色，圆形</li></ul><p id="c1f9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">A型的问题是，并不是所有的番茄上都有水滴。这个模型太具体了，很可能会挑湿番茄。它不能很好地推广到所有的番茄。它会寻找水滴，所以无法预测图像中的干番茄。是<strong class="js iu">过拟合</strong>。</p><p id="0158" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">另一方面，B型认为所有红色圆形的东西都是番茄，这是不正确的。该模型过于一般化，不能检测番茄的关键特征。是<strong class="js iu">欠配合</strong>。</p><p id="12a3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这些例子并不完全是机器学习模型如何学习和预测的，而是给出了过度拟合和欠拟合的概述。在这篇文章中，我将详细介绍以下概念:</p><ul class=""><li id="11b4" class="lf lg it js b jt ju jx jy kb lh kf li kj lj kn lk ll lm ln bi translated">偏差和方差</li><li id="bc13" class="lf lg it js b jt lo jx lp kb lq kf lr kj ls kn lk ll lm ln bi translated">过度拟合和欠拟合</li><li id="cacf" class="lf lg it js b jt lo jx lp kb lq kf lr kj ls kn lk ll lm ln bi translated">正规化</li></ul><h1 id="7a06" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated"><strong class="ak">偏差和方差</strong></h1><p id="fc4c" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">偏差和方差对于理解过度拟合和欠拟合是至关重要的。</p><p id="e6bb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">偏差</strong>衡量平均预测值与实际值的差距。如果我们试图用一个非常简单的模型来模拟一个复杂的关系，就会产生偏差。高偏差模型的预测非常相似。由于它对数据内的变化不敏感，因此该模型在训练数据和测试数据(以前未见过的数据)上的准确性都很低。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/17f76c3c8c41918f72168a54a1775a59.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*_LxWcLLRL3MCeiZEsvNsRQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">高偏差模型</p></figure><p id="925c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">蓝点是训练集中的观察值，红线是我们的有偏模型，它不关心观察值的两个特征内的波动，并进行相同的预测。</p><p id="d3bd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">方差</strong>是偏差的反义词，对数据内的变化敏感。具有高方差的模型对训练数据中甚至很小的变化都非常敏感。它试图捕捉每一个小细节，因此训练数据的微小变化也会改变模型。具有高方差的模型也倾向于捕捉数据中的噪声。异常值将在模型的范围内。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/abf36c18ec655e425dbd7fc1782aaa53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*Hv3I38wo7b1ML3NYhy5ckA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">高方差模型</p></figure><p id="486e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如您所见，该模型试图根据数据中的所有变化进行调整。具有高方差的模型的预测被广泛传播。很明显，该模型在训练集上有很高的准确率。然而，它在新的、以前看不到的观测中表现不佳。</p><p id="7031" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">机器学习模型是为以前看不到的观察结果而建立的，因此方差很大的模型是不可接受的。我们也永远不能依赖高偏差的模型。因此，找到偏差和方差之间的界限是至关重要的。偏差和方差之间总是有一个权衡。我们很容易找到一个高偏差低方差或者低偏差高方差的模型。然而，你的模型的成功取决于在偏差和方差之间找到最优的方法。例如，下面的模型似乎很适合。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi my"><img src="../Images/87730cb4d413aad0b2e46c03df9a4ab4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*XCUlCIAFlxc2RAy6Tvc0xw.png"/></div></figure><h1 id="a4ea" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated"><strong class="ak">过拟合和欠拟合</strong></h1><ul class=""><li id="5538" class="lf lg it js b jt mr jx ms kb mz kf na kj nb kn lk ll lm ln bi translated">具有高偏差的模型往往会欠拟合。</li><li id="5a71" class="lf lg it js b jt lo jx lp kb lq kf lr kj ls kn lk ll lm ln bi translated">方差高的模型往往会过度拟合。</li></ul><p id="515a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当模型试图很好地拟合训练数据，以至于不能推广到新的观察结果时，就会出现过度拟合。广义模型在新的观察上表现得更好。如果一个模型比需要的更复杂，我们很可能会过度拟合。欠拟合模型不能很好地推广到训练和测试数据集。</p><p id="7576" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在监督学习任务中，我们可以通过比较训练和测试数据集上的模型精度来检测过拟合。如果训练数据集(模型看到的观察值)数据集的精度远远高于测试数据集(看不到的观察值)的精度，则模型过度拟合。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/b2108fde3dc7beb4539a8ab929ee71ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*c4IggG2pAHpkU2rQe3zw7g.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">损失表示实际价值和我们的预测之间的差异</p></figure><p id="c847" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">损失与实际目标值和预测值之间的差异成比例。监督学习模型执行多次迭代，通过更新特征权重来最小化这种损失。然而，在某个点之后，模型在测试和训练数据上表现不同。损失在训练数据上持续减少，但是在某个点之后在测试数据上开始增加。检测这一点对于创建出色的机器学习模型至关重要。</p><p id="76f5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">过度拟合是机器学习模型的一系列问题，但我们如何防止模型过度拟合？答案是正规化。</p><h1 id="45ab" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated"><strong class="ak">正规化</strong></h1><p id="6c8d" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">过度拟合的主要原因是使模型比必要的更复杂。如果我们找到降低复杂度的方法，那么过拟合问题就解决了。</p><blockquote class="nd ne nf"><p id="14ab" class="jq jr ng js b jt ju jv jw jx jy jz ka nh kc kd ke ni kg kh ki nj kk kl km kn im bi translated">正则化不利于复杂的模型。</p></blockquote><p id="e62e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">正则化增加了对模型中较高项的惩罚，从而控制了模型的复杂性。如果增加一个正则项，该模型试图最小化损失和模型的复杂性。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nk"><img src="../Images/216a7904bf4ffcf412edd4d85ff608ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pLa3VJA4CTArP4d3pxWUqg.png"/></div></div></figure><blockquote class="nd ne nf"><p id="4b15" class="jq jr ng js b jt ju jv jw jx jy jz ka nh kc kd ke ni kg kh ki nj kk kl km kn im bi translated">正则化减少了方差，但不会导致偏差显著增加。</p></blockquote><p id="df3a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">两种常见的正则化方法是L1正则化和L2正则化。模型的复杂性取决于:</p><ul class=""><li id="0383" class="lf lg it js b jt ju jx jy kb lh kf li kj lj kn lk ll lm ln bi translated">特征总数(由L1正则化处理)，或</li><li id="ebee" class="lf lg it js b jt lo jx lp kb lq kf lr kj ls kn lk ll lm ln bi translated">特征的权重(由L2正则化处理)</li></ul><p id="5de4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> L1正规化</strong></p><p id="dcde" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">它也被称为稀疏正则化。顾名思义，它用于处理稀疏向量。如果我们有高维特征向量空间，模型就变得很难处理。</p><p id="383d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">L1正则化强制无信息特征的权重为零。L1正则化的作用类似于在每次迭代中从权重中减去少量的力，从而最终使权重为零。</p><blockquote class="nd ne nf"><p id="0f07" class="jq jr ng js b jt ju jv jw jx jy jz ka nh kc kd ke ni kg kh ki nj kk kl km kn im bi translated">L1正则化惩罚|权重|。</p></blockquote><p id="bf1d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> L2正规化</strong></p><p id="1b00" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为简单起见，它也被称为正则化。如果我们把模型的复杂度作为权重的函数，那么特征的复杂度与它的权重的绝对值成正比。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/3881b7d334c36f8b25815d0fe867286e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/format:webp/1*3-IjCqWL5Fcjk9qe_N8_uA.png"/></div></figure><p id="3b93" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">L2正则化迫使权重趋向于零，但并不使它们完全为零。L2正则化就像在每次迭代中去除一小部分权重的力。因此，权重永远不会等于零。</p><blockquote class="nd ne nf"><p id="e0e9" class="jq jr ng js b jt ju jv jw jx jy jz ka nh kc kd ke ni kg kh ki nj kk kl km kn im bi translated">L2正则化惩罚(权重)</p></blockquote><p id="6c38" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">有一个额外的参数来调整L2正则化项，称为<strong class="js iu">正则化率(λ)。</strong>正则化率是一个标量并乘以L2正则化项。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/e805ad8c2ace88fdb8298ebab9e9baf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*yb43BGhZ4g6fNrGYA7FGuQ.png"/></div></figure><blockquote class="nd ne nf"><p id="cd6c" class="jq jr ng js b jt ju jv jw jx jy jz ka nh kc kd ke ni kg kh ki nj kk kl km kn im bi translated"><strong class="js iu">注意:</strong>选择λ的最佳值很重要。L2正则化的目标是简单。然而，如果lambda太高，模型就会变得太简单，从而可能会不足。另一方面，如果λ太低，调节的效果变得可以忽略不计，模型可能会过拟合。如果lambda设置为零，那么正则化将被完全移除(过度拟合的高风险！).</p></blockquote><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nn"><img src="../Images/8fe1eb5be953327052c7952fb6622a4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GMrxAtjCsW319xo3bT3m7w.png"/></div></div></figure><blockquote class="nd ne nf"><p id="3f91" class="jq jr ng js b jt ju jv jw jx jy jz ka nh kc kd ke ni kg kh ki nj kk kl km kn im bi translated"><strong class="js iu">注:</strong> <strong class="js iu">岭回归</strong>使用L2正则化，而<strong class="js iu">拉索回归</strong>使用L1正则化。<strong class="js iu">弹性网回归</strong>结合了L1和L2正则化。</p></blockquote><h1 id="2231" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated"><strong class="ak">结论</strong></h1><p id="4075" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">过度拟合是机器学习模型的一个关键问题，需要小心处理。我们使用我们已经知道的数据建立机器学习模型，但在新的、以前看不见的数据上尝试或测试它们。我们希望模型了解训练数据中的趋势，但同时不希望模型过于关注训练数据。模型的成功取决于在过度拟合和欠拟合之间找到最佳点。</p></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><p id="a329" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">感谢您的阅读。如果您有任何反馈，请告诉我。</p></div></div>    
</body>
</html>