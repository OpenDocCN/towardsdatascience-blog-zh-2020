<html>
<head>
<title>Mixed precision training for tf.keras models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">tf.keras模型的混合精度训练</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/mixed-precision-training-for-tf-keras-models-4fb7500fd37a?source=collection_archive---------53-----------------------#2020-05-02">https://towardsdatascience.com/mixed-precision-training-for-tf-keras-models-4fb7500fd37a?source=collection_archive---------53-----------------------#2020-05-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="ae0c" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/production-ml" rel="noopener" target="_blank">生产中的机器学习</a></h2><div class=""/><div class=""><h2 id="9229" class="pw-subtitle-paragraph kd jc it bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">了解如何为<code class="fe jz ka kb kc b">tf.keras</code>模型整合混合精度训练，以加快模型训练时间。</h2></div><p id="5bc2" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><a class="ae lr" href="https://app.wandb.ai/sayakpaul/mixed-precision-tf-keras" rel="noopener ugc nofollow" target="_blank">探索为文章</a>进行的实验的交互式仪表板。</p><p id="cf15" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在本文中，我们将了解如何将混合精度(MP)训练整合到您的tf.keras训练工作流中。混合精度训练是NVIDIA在<a class="ae lr" href="https://arxiv.org/abs/1710.03740" rel="noopener ugc nofollow" target="_blank">本文</a>中提出的。它让我们能够以更快的速度训练大型神经网络，而网络性能的下降为零或非常小。这是我们将要报道的-</p><ul class=""><li id="eba3" class="lt lu it kx b ky kz lb lc le lv li lw lm lx lq ly lz ma mb bi translated">为tf.keras模型合并混合精度训练的几个选项</li><li id="b37c" class="lt lu it kx b ky mc lb md le me li mf lm mg lq ly lz ma mb bi translated">执行混合精度训练时要记住的事项</li><li id="cb9e" class="lt lu it kx b ky mc lb md le me li mf lm mg lq ly lz ma mb bi translated">这些选项的实践示例</li><li id="cc67" class="lt lu it kx b ky mc lb md le me li mf lm mg lq ly lz ma mb bi translated">使用权重和偏差(W&amp;B)来比较不同混合精度训练实验的结果</li></ul><p id="d5ce" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">如果你想了解混合精确训练的细节，我强烈推荐以下资源:</p><ul class=""><li id="f383" class="lt lu it kx b ky kz lb lc le lv li lw lm lx lq ly lz ma mb bi translated">Sylvian Gugger的<a class="ae lr" href="https://forums.fast.ai/t/mixed-precision-training/20720" rel="noopener ugc nofollow" target="_blank">混合精确训练</a></li><li id="11a4" class="lt lu it kx b ky mc lb md le me li mf lm mg lq ly lz ma mb bi translated"><a class="ae lr" href="https://drive.google.com/open?id=1dVkpmttGWf49_3wk0PSY97Wgqfc4TEJczzwEtsbmzXQ" rel="noopener ugc nofollow" target="_blank">本期PyCon SG 2019教程</a>作者Timothy Liu</li><li id="8827" class="lt lu it kx b ky mc lb md le me li mf lm mg lq ly lz ma mb bi translated"><a class="ae lr" href="https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html" rel="noopener ugc nofollow" target="_blank">英伟达的混合精度训练</a></li></ul><p id="c3d0" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们开始吧！</p><blockquote class="mh mi mj"><p id="07b3" class="kv kw ls kx b ky kz kh la lb lc kk ld mk lf lg lh ml lj lk ll mm ln lo lp lq im bi translated">点击查看代码<a class="ae lr" href="https://github.com/sayakpaul/Mixed-Precision-Training-in-tf.keras-2.0/" rel="noopener ugc nofollow" target="_blank">。</a></p></blockquote><h1 id="72a3" class="mn mo it bd mp mq mr ms mt mu mv mw mx km my kn mz kp na kq nb ks nc kt nd ne bi translated">在<code class="fe jz ka kb kc b">tf.keras</code> (TensorFlow 2)中加入混合精度训练</h1><p id="23c8" class="pw-post-body-paragraph kv kw it kx b ky nf kh la lb ng kk ld le nh lg lh li ni lk ll lm nj lo lp lq im bi translated">TensorFlow 2.0提供以下选项，帮助您轻松整合混合精度训练-</p><ul class=""><li id="0c69" class="lt lu it kx b ky kz lb lc le lv li lw lm lx lq ly lz ma mb bi translated"><a class="ae lr" href="https://www.tensorflow.org/api_docs/python/tf/train/experimental/enable_mixed_precision_graph_rewrite" rel="noopener ugc nofollow" target="_blank">TF . train . experimental . enable _ mixed _ precision _ graph _ rewrite</a></li><li id="7d01" class="lt lu it kx b ky mc lb md le me li mf lm mg lq ly lz ma mb bi translated"><a class="ae lr" href="https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/experimental/LossScaleOptimizer" rel="noopener ugc nofollow" target="_blank">TF . keras . mixed _ precision . experimental . losscale optimizer</a></li><li id="9430" class="lt lu it kx b ky mc lb md le me li mf lm mg lq ly lz ma mb bi translated"><a class="ae lr" href="https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/experimental/set_policy" rel="noopener ugc nofollow" target="_blank">TF . keras . mixed _ precision . experimental . set _ policy</a></li></ul><p id="51a2" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">根据我的经验，我发现后两种方法更有效。然而，为了激活混合精度训练，需要一些配置。我们将在后面的章节中看到它们。但在此之前，让我们讨论一些使用混合精度训练时要记住的要点。</p><h1 id="60ef" class="mn mo it bd mp mq mr ms mt mu mv mw mx km my kn mz kp na kq nb ks nc kt nd ne bi translated">使用MP训练时要记住的事项</h1><p id="1fc6" class="pw-post-body-paragraph kv kw it kx b ky nf kh la lb ng kk ld le nh lg lh li ni lk ll lm nj lo lp lq im bi translated">请注意，您无法通过现成的MP培训获得显著的绩效提升。使用MP训练时，我们需要记住一些要点-</p><ul class=""><li id="9f0d" class="lt lu it kx b ky kz lb lc le lv li lw lm lx lq ly lz ma mb bi translated">例如，MP培训仅<em class="ls">在NVIDIA GPUs的Volta一代、特斯拉V100、特斯拉T4上受支持。</em></li><li id="e2db" class="lt lu it kx b ky mc lb md le me li mf lm mg lq ly lz ma mb bi translated">为了能够从MP培训中获得最大收益，您应该将它与大型网络变压器、ResNet50等一起使用。网络的架构(即网络包含的层、激活的种类)在这里扮演着重要的角色。我无法在VGG16这样的网络上获得任何性能提升。</li><li id="af5c" class="lt lu it kx b ky mc lb md le me li mf lm mg lq ly lz ma mb bi translated">维度(批次、通道、图像大小、密集节点)应该是8的倍数。</li><li id="6166" class="lt lu it kx b ky mc lb md le me li mf lm mg lq ly lz ma mb bi translated">使用计算机视觉模型时，使用分辨率越高的图像越好。</li></ul><h1 id="8b1a" class="mn mo it bd mp mq mr ms mt mu mv mw mx km my kn mz kp na kq nb ks nc kt nd ne bi translated">使用tf.keras进行混合精确训练</h1><p id="4187" class="pw-post-body-paragraph kv kw it kx b ky nf kh la lb ng kk ld le nh lg lh li ni lk ll lm nj lo lp lq im bi translated">在本节中，我们将看到一些使用<code class="fe jz ka kb kc b">tf.keras</code>进行混合精确训练的实践例子。正如我在开始提到的，你可以在<a class="ae lr" href="https://github.com/sayakpaul/Mixed-Precision-Training-in-tf.keras-2.0" rel="noopener ugc nofollow" target="_blank">这个报告</a>中找到完整的实验。</p><h2 id="0841" class="nk mo it bd mp nl nm dn mt nn no dp mx le np nq mz li nr ns nb lm nt nu nd iz bi translated">数据集简介</h2><p id="4910" class="pw-post-body-paragraph kv kw it kx b ky nf kh la lb ng kk ld le nh lg lh li ni lk ll lm nj lo lp lq im bi translated">我的实验数据来自于Vidhya Hackathon的分析。给你一组像下面这样的图片，你需要预测给定船只的类别-</p><figure class="nw nx ny nz gt oa gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi nv"><img src="../Images/d98b114e33f96d1727f30369d0c77ae0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*nRRhiQtkylhnwkbu.png"/></div></div><p class="oh oi gj gh gi oj ok bd b be z dk translated">先睹为快</p></figure><p id="292f" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">图像的‍The标签被给出如下编码</p><figure class="nw nx ny nz gt oa"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="abf9" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">训练集中有6252个图像，测试集中有2680个图像。不幸的是，测试集中的图像完全没有标记(在黑客马拉松中应该如此)。在实验中，我只使用了6252张图片。</p><p id="4f7f" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">数据集的格式如下-</p><figure class="nw nx ny nz gt oa"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="8860" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">其中，<code class="fe jz ka kb kc b">train.csv</code>和<code class="fe jz ka kb kc b">test</code> _ApKoW4T.csv分别包含训练图像和测试图像的名称。</p><p id="98d4" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">现在我们已经对数据集有了一个大致的介绍，我们可以继续探索实际操作的例子。</p><h2 id="a3de" class="nk mo it bd mp nl nm dn mt nn no dp mx le np nq mz li nr ns nb lm nt nu nd iz bi translated">为MP培训设置明确的策略</h2><p id="fde3" class="pw-post-body-paragraph kv kw it kx b ky nf kh la lb ng kk ld le nh lg lh li ni lk ll lm nj lo lp lq im bi translated"><code class="fe jz ka kb kc b">tf.keras.mixed_precision.experimental.set_policy </code>允许我们设置网络各层的默认策略。这里的策略是指特定层的<code class="fe jz ka kb kc b">dtype</code>。有多种方法可以在tf.keras中为层设置策略-</p><ul class=""><li id="469d" class="lt lu it kx b ky kz lb lc le lv li lw lm lx lq ly lz ma mb bi translated">如果在定义网络之前指定了<code class="fe jz ka kb kc b">tf.keras.mixed_precision.experimental.set_policy("mixed_float16")</code>，网络各层的默认策略将是<code class="fe jz ka kb kc b">mixed_float16</code>，即网络中的所有计算将在<code class="fe jz ka kb kc b">float16</code>进行，而参数将在<code class="fe jz ka kb kc b">float32</code>进行。然而，请记住，包含softmax激活函数的层的计算应在<code class="fe jz ka kb kc b">float32</code>中完成，以避免数值不稳定。</li><li id="fb1b" class="lt lu it kx b ky mc lb md le me li mf lm mg lq ly lz ma mb bi translated">除了设置层的默认策略之外，您还可以做一些更具体的事情，比如</li></ul><figure class="nw nx ny nz gt oa"><div class="bz fp l di"><div class="ol om l"/></div><p class="oh oi gj gh gi oj ok bd b be z dk translated">代码取自<a class="ae lr" href="https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/experimental/Policy#how_to_use_mixed_precision_in_layers_with_policies" rel="noopener ugc nofollow" target="_blank">本例</a></p></figure><p id="797b" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">现在，为了能够使用混合精度的策略，您需要启用XLA编译器(XLA编译器的介绍可以在这里<a class="ae lr" href="https://docs.google.com/presentation/d/1F7hBey7m7bKSmLB4-Ipe9KvZl--TkaJGi69wRzzpAGM/edit?usp=sharing" rel="noopener ugc nofollow" target="_blank">找到</a>)，就像这样— <code class="fe jz ka kb kc b">tf.config.optimizer.set_jit(True)</code>。注意，这应该在每个会话的基础上完成，也就是说，如果你计划使用XLA编译器(在大多数情况下你真的应该)你需要为每个新的会话启用它。</p><p id="d2ed" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在开始实验之前清除任何现有的会话也是一个好主意，以防止不可预见的问题-</p><figure class="nw nx ny nz gt oa"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="b3b8" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">启用XLA编译器后，我们设置各层的默认策略，如下所示— <code class="fe jz ka kb kc b">tf.keras.mixed_precision.experimental.set_policy(‘mixed_float16’)</code>。我们现在可以定义我们的模型-</p><figure class="nw nx ny nz gt oa"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="8ed0" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们在预训练的ResNet50网络上添加了一个(多)分类头。<strong class="kx jd">注意模型的输入应该在</strong>T9。还有，看看密层的<code class="fe jz ka kb kc b">dtype</code>。现在，当我在我的GCP笔记本电脑实例(由特斯拉T4组成)上用上述数据训练网络时，我得到了以下结果</p><figure class="nw nx ny nz gt oa"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="6fab" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">作为健全性检查，我在没有混合精度配置的情况下训练了相同的网络<em class="ls">，我得到了以下结果</em></p><figure class="nw nx ny nz gt oa"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="3ffb" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">你可以看到训练时间的提高！让我们来看一些最重要的指标:</p><figure class="nw nx ny nz gt oa gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi on"><img src="../Images/b02a6f7318f502604be072680adde7ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RsaixfmxH4uvSW6BGBPfIw.png"/></div></div><p class="oh oi gj gh gi oj ok bd b be z dk translated">图表可用<a class="ae lr" href="https://app.wandb.ai/sayakpaul/mixed-precision-tf-keras/runs?workspace=user-sayakpaul" rel="noopener ugc nofollow" target="_blank">此处</a></p></figure><p id="4c57" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">上面的一组图表为我们提供了关于以下指标的信息，这些指标也来自不同的实验(您可以通过一点努力看到实验的名称)</p><ul class=""><li id="9d5c" class="lt lu it kx b ky kz lb lc le lv li lw lm lx lq ly lz ma mb bi translated">准确(性)</li><li id="6c9d" class="lt lu it kx b ky mc lb md le me li mf lm mg lq ly lz ma mb bi translated">失败</li><li id="c9bf" class="lt lu it kx b ky mc lb md le me li mf lm mg lq ly lz ma mb bi translated">训练时间</li></ul><p id="5176" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">可以清楚地看到，混合精度训练确实允许更快地训练我们的网络，而没有任何性能损失。请注意，默认情况下，W &amp; B不会跟踪“<strong class="kx jd"> training_time </strong>”，但它就像下面的代码块一样简单:</p><figure class="nw nx ny nz gt oa"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="1356" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">你可以记录很多其他的东西，比如表格，图片，音频等等。如果您有兴趣探索这一领域，请点击此处查看文档<a class="ae lr" href="https://docs.wandb.com/library/python/log" rel="noopener ugc nofollow" target="_blank"/>。W &amp; B也允许我们用神奇的命令%%wandb在我们的Jupyter笔记本中生成上面的图(在这里阅读更多<a class="ae lr" href="https://docs.wandb.com/library/integrations/jupyter" rel="noopener ugc nofollow" target="_blank"/>)但是我喜欢将这些图与我的笔记本分开。</p><p id="8090" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">此外，我使用您在<a class="ae lr" href="https://app.wandb.ai/sayakpaul/mixed-precision-tf-keras/runs" rel="noopener ugc nofollow" target="_blank">跑步页面</a>上获得的“添加可视化”按钮创建了以下散点图，以捕捉“训练时间与损失”的趋势。</p><figure class="nw nx ny nz gt oa gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi oo"><img src="../Images/6f89f04243a46dda0904fceea21029ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FtHkf14rt-pUv8s8.png"/></div></div><p class="oh oi gj gh gi oj ok bd b be z dk translated">图表可用<a class="ae lr" href="https://app.wandb.ai/sayakpaul/mixed-precision-tf-keras/runs?workspace=user-sayakpaul" rel="noopener ugc nofollow" target="_blank">此处</a></p></figure><p id="8651" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">创建散点图是一件简单的事情<a class="ae lr" href="https://www.dropbox.com/s/awdlo24s2pmm0f0/mixed-precision-tf-keras%20_%20W%26B.mp4?dl=0" rel="noopener ugc nofollow" target="_blank">几个击键</a>你就可以轻松完成。</p><p id="6c93" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">如您所料，该图也是交互式的。</p><p id="19b3" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">现在让我们探讨一下<code class="fe jz ka kb kc b">tf.keras</code>中进行MP训练的第二种选择。</p><h2 id="52b7" class="nk mo it bd mp nl nm dn mt nn no dp mx le np nq mz li nr ns nb lm nt nu nd iz bi translated">MP培训的损失比例</h2><p id="cda7" class="pw-post-body-paragraph kv kw it kx b ky nf kh la lb ng kk ld le nh lg lh li ni lk ll lm nj lo lp lq im bi translated">损失缩放在MP训练中是一个重要的概念，因为它防止了在计算中可能发生的降低精度的数值下溢。为了能够使用<code class="fe jz ka kb kc b">tf.keras.mixed_precision.experimental.LossScaleOptimizer</code>，你需要通过<code class="fe jz ka kb kc b">tf.config.optimizer.set_experimental_options({“auto_mixed_precision”: True})</code>启用混合精度，同时启用XLA编译器。确保回顾<a class="ae lr" href="https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/experimental/LossScaleOptimizer" rel="noopener ugc nofollow" target="_blank">一些重要的事情</a>如果你在定制训练循环中使用损失比例，你可能需要遵循。我们可以使用上一节中看到的相同模型，为了插入损耗比例，我们将执行以下操作-</p><figure class="nw nx ny nz gt oa"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="738f" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">就是这样！在这种情况下，您应该可以获得与策略类似的性能。</p><h1 id="f9f8" class="mn mo it bd mp mq mr ms mt mu mv mw mx km my kn mz kp na kq nb ks nc kt nd ne bi translated">比较我们实验的权重和偏差(W&amp;B)</h1><p id="8f24" class="pw-post-body-paragraph kv kw it kx b ky nf kh la lb ng kk ld le nh lg lh li ni lk ll lm nj lo lp lq im bi translated">混合精度不仅能提高训练速度，还能减少模型的内存占用。因为你没有完全使用双精度或者单精度<em class="ls"/>。但这可能不是那么明显，因为我们在这里处理的数据较少。如果是一个更大的数据集(例如，500 MB的数据集)，差异会非常明显。但是从总体上看你的机器学习模型的内存占用总是非常实用的。W &amp; B让这一点变得非常容易想象。在我的<a class="ae lr" href="https://app.wandb.ai/sayakpaul/mixed-precision-tf-keras" rel="noopener ugc nofollow" target="_blank">项目页面</a>，对于像<a class="ae lr" href="https://app.wandb.ai/sayakpaul/mixed-precision-tf-keras/runs/q3jyari7/" rel="noopener ugc nofollow" target="_blank">这种</a>的单独运行，你会得到一个名为<a class="ae lr" href="https://app.wandb.ai/sayakpaul/mixed-precision-tf-keras/runs/q3jyari7/system" rel="noopener ugc nofollow" target="_blank">系统</a>的标签。它为你提供了一系列信息，比如-</p><figure class="nw nx ny nz gt oa gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi op"><img src="../Images/2a5aeab6148a27f585ff4725af247f07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_loAbDuQA8Ykogps.png"/></div></div><p class="oh oi gj gh gi oj ok bd b be z dk translated">图表可用<a class="ae lr" href="https://app.wandb.ai/sayakpaul/mixed-precision-tf-keras/runs?workspace=user-sayakpaul" rel="noopener ugc nofollow" target="_blank">此处</a></p></figure><p id="371f" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">除了上述与您的系统相关的指标，您还可以在底部获得关于<em class="ls"> GPU内存使用</em>的信息。在我的实验中，我使用了TensorFlow的数据API，它允许与数据加载、预处理等相关的计算。要在您的GPU上执行(如果可用)。这真正将tf.data与ImageDataGenerator等其他替代产品区分开来，因为它不支持GPU计算。您可以使用GPU内存使用情况的图表进行这种比较。</p><p id="4cd1" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">下图显示了不同实验中的GPU使用情况-</p><figure class="nw nx ny nz gt oa gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi oq"><img src="../Images/c2f38e1b690a2b3304a1cabab15a0d55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*g2TD6qeo_8XzC2Fl.png"/></div></div></figure><p id="6617" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">正如你所看到的，不同风格的混合精度训练在GPU使用方面往往遵循相似的模式。当我不使用混合精度时，GPU实际上得到了更好的利用。这可能会提示开发人员进一步钻研，找出提高GPU利用率的方法。但是在GPU利用率和模型性能之间总是有一个折衷，并且它会随着项目的不同而变化。</p><p id="5605" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">以下是一些综合图表，代表了所有必要的实验材料-</p><figure class="nw nx ny nz gt oa gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi or"><img src="../Images/ce0ce4c9bd9de1e205b2b4a5d8023501.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UBnTTqBE1yrykvmU.png"/></div></div><p class="oh oi gj gh gi oj ok bd b be z dk translated">可用图表<a class="ae lr" href="https://app.wandb.ai/sayakpaul/mixed-precision-tf-keras/runs?workspace=user-sayakpaul" rel="noopener ugc nofollow" target="_blank">此处</a></p></figure><p id="71ce" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">图表的图例是不同的运行(一次运行=一个实验)。使用混合精度训练时，打开XLA编译器非常重要。从上图可以看出，在没有XLA编译器的情况下，如果使用混合精度训练，模型训练将更加耗时。</p><p id="6ef1" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">作为一名机器学习实践者，你将被期望更多地关心像这样的方面。</p><p id="9e4e" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">对于每一次不同的跑步，我们都有一个<a class="ae lr" href="https://app.wandb.ai/sayakpaul/mixed-precision-tf-keras/runs/dd2orq1s/logs" rel="noopener ugc nofollow" target="_blank">专用的日志页面</a>，在那里我们可以获得本地的训练日志</p><figure class="nw nx ny nz gt oa gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi os"><img src="../Images/678d25c4b2aaf360bfc1574dcb8aa71b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lOwXZRhVStXhT6ZM.png"/></div></div><p class="oh oi gj gh gi oj ok bd b be z dk translated">可用日志<a class="ae lr" href="https://app.wandb.ai/sayakpaul/mixed-precision-tf-keras/runs/dd2orq1s/logs?workspace=user-sayakpaul" rel="noopener ugc nofollow" target="_blank">此处</a></p></figure><h1 id="95a0" class="mn mo it bd mp mq mr ms mt mu mv mw mx km my kn mz kp na kq nb ks nc kt nd ne bi translated">谢谢大家！</h1><p id="5e8e" class="pw-post-body-paragraph kv kw it kx b ky nf kh la lb ng kk ld le nh lg lh li ni lk ll lm nj lo lp lq im bi translated">谢谢你陪我到最后。我希望您能从这篇文章中受益，并将混合精度训练融入到您自己的实验中。别忘了让我知道结果！</p><p id="fba1" class="pw-post-body-paragraph kv kw it kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我要感谢W&amp;B团队的Lavanya，她仔细审阅了代码和文章本身。她的反馈非常有帮助。</p></div></div>    
</body>
</html>