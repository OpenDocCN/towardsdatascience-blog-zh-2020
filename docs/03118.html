<html>
<head>
<title>(In-depth) Machine Learning Image Classification With TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用张量流的(深入)机器学习图像分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/in-depth-machine-learning-image-classification-with-tensorflow-2-0-a76526b32af8?source=collection_archive---------7-----------------------#2020-03-25">https://towardsdatascience.com/in-depth-machine-learning-image-classification-with-tensorflow-2-0-a76526b32af8?source=collection_archive---------7-----------------------#2020-03-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8a1e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">理解实现用于图像分类的神经网络的过程。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/19c8a5b44a71e34067567568f59a2445.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zPlqJOZ5PCg8oPBm3FwjHw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Arif Riyanto 在<a class="ae ky" href="https://unsplash.com/s/photos/machine-learning?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="899e" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="209d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi mn translated"><span class="l mo mp mq bm mr ms mt mu mv di"> T </span>这将是一篇很长的文章，因为我将详细讨论实现图像分类神经网络所必需的组件和过程。</p><p id="6eb3" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">随意休息一下，甚至直接跳到有代码的部分。</p><p id="987b" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">本文旨在介绍实际的实现技巧，并解释机器学习开发中涉及的术语和术语。</p><p id="2664" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">本文内容面向初学者和中级机器学习从业者。</p><h2 id="9ebd" class="nb la it bd lb nc nd dn lf ne nf dp lj ma ng nh ll me ni nj ln mi nk nl lp nm bi translated">在页面底部有一个链接，指向本文中介绍的代码的笔记本。</h2><p id="9b6b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">享受吧。</p></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h1 id="af3f" class="kz la it bd lb lc nu le lf lg nv li lj jz nw ka ll kc nx kd ln kf ny kg lp lq bi translated">目标</h1><p id="dc08" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">神经网络解决各种各样的任务，例如分类、回归等等。</p><p id="1dec" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">本文研究了开发一个简单的用于图像分类的神经网络的过程。</p><p id="5ea5" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">将对以下内容进行探讨:</p><ol class=""><li id="091b" class="nz oa it lt b lu mw lx mx ma ob me oc mi od mm oe of og oh bi translated"><strong class="lt iu">图像分类和其他术语的定义</strong></li><li id="7133" class="nz oa it lt b lu oi lx oj ma ok me ol mi om mm oe of og oh bi translated"><strong class="lt iu">机器学习中的理论和概念(多层感知器)</strong></li><li id="30b1" class="nz oa it lt b lu oi lx oj ma ok me ol mi om mm oe of og oh bi translated"><strong class="lt iu">如何利用TensorFlow、Keras等工具和库</strong></li><li id="7c97" class="nz oa it lt b lu oi lx oj ma ok me ol mi om mm oe of og oh bi translated"><strong class="lt iu">如何建立、训练和评估神经网络</strong></li></ol></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h1 id="1bef" class="kz la it bd lb lc nu le lf lg nv li lj jz nw ka ll kc nx kd ln kf ny kg lp lq bi translated">图像分类</h1><p id="f311" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">图像分类是与多标签分配相关联的任务。</p><p id="e913" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">它包括从图像中提取信息，然后将提取的信息与一个或多个类别标签相关联。机器学习领域中的图像分类可以作为监督学习任务来处理。</p></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><p id="7866" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated"><em class="on">但在我们进一步深入之前，需要理解一些基本术语以及所使用的工具和库，以正确理解实施细节</em></p></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h1 id="59f8" class="kz la it bd lb lc nu le lf lg nv li lj jz nw ka ll kc nx kd ln kf ny kg lp lq bi translated">感知器</h1><p id="0f97" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">感知器是人工神经网络的基本组成部分，由弗兰克·罗森布拉特于1958年发明。感知器利用基于阈值逻辑单元的操作。</p><p id="40ab" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">感知器可以以单层格式堆叠，这能够解决线性函数。多层感知器能够解决更复杂的功能，并具有更大的处理能力。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/1cc0e4b9782c3bfde576d8a3d0e26cd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IIoIzzVwEKRVuYj3oyGgmA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://missinglink.ai/" rel="noopener ugc nofollow" target="_blank">感知器图片来自missinglink.ai </a></p></figure></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h1 id="c5d8" class="kz la it bd lb lc nu le lf lg nv li lj jz nw ka ll kc nx kd ln kf ny kg lp lq bi translated">MLP</h1><p id="22f1" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">多层感知器(MLP)是几层感知器一个接一个地连续堆叠。MLP由一个输入层、一个或多个称为隐藏层的TLU层以及一个称为输出层的最终层组成。</p></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h1 id="fe34" class="kz la it bd lb lc nu le lf lg nv li lj jz nw ka ll kc nx kd ln kf ny kg lp lq bi translated">工具和库</h1><ul class=""><li id="6d4d" class="nz oa it lt b lu lv lx ly ma op me oq mi or mm os of og oh bi translated"><a class="ae ky" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> TensorFlow </strong> </a>:机器学习模型实现、训练、部署的开源平台。</li><li id="5078" class="nz oa it lt b lu oi lx oj ma ok me ol mi om mm os of og oh bi translated"><a class="ae ky" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> Keras </strong> </a>:一个开源库，用于实现运行在CPU和GPU上的神经网络架构。</li><li id="88e2" class="nz oa it lt b lu oi lx oj ma ok me ol mi om mm os of og oh bi translated"><a class="ae ky" href="https://pandas.pydata.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">熊猫</strong> </a>:数据分析修改库。</li><li id="0c84" class="nz oa it lt b lu oi lx oj ma ok me ol mi om mm os of og oh bi translated"><a class="ae ky" href="https://matplotlib.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> Matplotlib </strong> </a>:用于在Python中创建可视化绘图的工具，如图表、图形等</li><li id="51bc" class="nz oa it lt b lu oi lx oj ma ok me ol mi om mm os of og oh bi translated"><a class="ae ky" href="https://numpy.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> Numpy </strong> </a>:实现数组数据结构的多种数学计算和运算。</li></ul><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="42a2" class="nb la it ou b gy oy oz l pa pb">import tensorflow as tf<br/>from tensorflow import keras<br/>import matplotlib.pyplot as plt<br/>import pandas as pd<br/>import numpy as np<br/>import os<br/>import time</span></pre></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h1 id="8990" class="kz la it bd lb lc nu le lf lg nv li lj jz nw ka ll kc nx kd ln kf ny kg lp lq bi translated">资料组</h1><p id="b190" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">时尚-MNIST数据集由源自Zalando图像目录的服装图像(t恤、裤子、连衣裙等)组成。Zalando是一家成立于2008年的欧洲电子商务公司。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/6e19adb109fbc49d615e88ef78702aab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bJO8xSnH0uZFWWlDsg02ng.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">时尚-MNIST类和相关图像的例子</p></figure><p id="4353" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">Zalando的研究人员创建了包含70，000幅服装图像的时尚MNIST数据集。更具体地说，它包含60，000个训练样本和10，000个测试样本，这些样本都是尺寸为28×28的灰度图像，分为10类。</p><p id="3041" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">这些类别对应于图像中出现的服装项目。例如，一个踝靴的图像对应于数字标签“9”。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/7520f5e2a467f963874a068232a086f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*ASBL6bFOdz1KWLAgfKwsvw.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">时尚MNIST数据集分布的可视化</p></figure></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h1 id="38fd" class="kz la it bd lb lc nu le lf lg nv li lj jz nw ka ll kc nx kd ln kf ny kg lp lq bi translated">数据集分区</h1><p id="560f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">对于这个特定的分类任务，使用了55，000幅训练图像、10，000幅测试图像和5，000幅验证图像。</p><ul class=""><li id="44d4" class="nz oa it lt b lu mw lx mx ma ob me oc mi od mm os of og oh bi translated">训练数据集:这是我们用来直接训练神经网络的数据集组。训练数据是指在训练期间暴露给神经网络的数据集分区。</li><li id="05d8" class="nz oa it lt b lu oi lx oj ma ok me ol mi om mm os of og oh bi translated">验证数据集:这组数据集在训练期间被用来评估网络在各种迭代中的性能。</li><li id="be15" class="nz oa it lt b lu oi lx oj ma ok me ol mi om mm os of og oh bi translated">测试数据集:数据集的这一部分在训练阶段完成后评估我们网络的性能。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/ed93980b6f390c50cd922fd8db3aba3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DpqQGMpsWFchL_uMzHT5_g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据集分区的图示</p></figure><p id="81e7" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">Keras图书馆有一套易于使用的数据集。</p><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="9f74" class="nb la it ou b gy oy oz l pa pb">fashion_mnist = keras.datasets.fashion_mnist<br/>(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()</span></pre><p id="900c" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">60，000张28x28尺寸的训练图像</p><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="57e7" class="nb la it ou b gy oy oz l pa pb">train_images.shape<br/>&gt;&gt; (60000, 28, 28)</span></pre><p id="7ca9" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">60，000个训练标签，每个标签对应于一件衣服，例如，标签9对应于踝靴</p><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="62e4" class="nb la it ou b gy oy oz l pa pb">train_labels.shape<br/>&gt;&gt; (60000,)</span><span id="8bb9" class="nb la it ou b gy pf oz l pa pb">train_labels[0]<br/>&gt;&gt; 9</span></pre></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h1 id="7231" class="kz la it bd lb lc nu le lf lg nv li lj jz nw ka ll kc nx kd ln kf ny kg lp lq bi translated">可视化和预处理数据</h1><p id="fe11" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在我们继续之前，我们必须将训练图像像素值标准化为范围0和1内的值。这是通过将训练和测试图像中的每个像素值除以255来实现的。</p><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="6717" class="nb la it ou b gy oy oz l pa pb">train_images = train_images / 255.0<br/>test_images = test_images / 255.0</span></pre><p id="188c" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">以下是fashionMNIST数据集中的图像对应的类名。</p><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="cb32" class="nb la it ou b gy oy oz l pa pb">class_names = ["T-shirt/top", "Trouser", "Pullover", "Dress", "Coat", "Sandal", "Shirt", "Sneaker", "Bag", "Ankle boot"]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/6e19adb109fbc49d615e88ef78702aab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bJO8xSnH0uZFWWlDsg02ng.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">时尚-MNIST类和相关图像的例子</p></figure><p id="f28c" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">可视化数据集</p><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="223e" class="nb la it ou b gy oy oz l pa pb">plt.figure(figsize=(10,10))<br/>for i in range(20):<br/>    plt.subplot(5,4, i+1)<br/>    plt.xticks([])<br/>    plt.imshow(train_images[i])<br/>    plt.xlabel(class_names[train_labels[i]])<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/72a2e519fe1c9a2c4a57072ec64d06bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*VKnp67B7m5dyml7htm8Tpg.png"/></div></figure><p id="c524" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">数据集的验证分区是从训练数据集导出的。5000张图像和标签将用于验证目的。</p><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="7514" class="nb la it ou b gy oy oz l pa pb">validation_images = train_images[:5000]<br/>validation_labels = train_labels[:5000]</span></pre><p id="cea5" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">以下是用特定索引位置标识的相应服装名称的示例。</p><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="378b" class="nb la it ou b gy oy oz l pa pb">class_names[train_labels[2]]<br/>&gt;&gt; 'T-shirt/top'</span></pre></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h1 id="f90b" class="kz la it bd lb lc nu le lf lg nv li lj jz nw ka ll kc nx kd ln kf ny kg lp lq bi translated">构建模型</h1><p id="976e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Keras提供了实现分类模型所需的工具。Keras提出了一种顺序API，用于将神经网络的层堆叠在彼此之上。</p><p id="c2a2" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">分类网络是一个浅网络，具有3个隐藏层、一个输入层和一个输出层。使用“Flatten”构造函数构建输入层，该构造函数将输入形状作为其参数，在本例中为[28，28]。</p><p id="ed4a" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">每个图像输入数据被转换或展平成1D阵列。密集层有确定数量的神经元/单元，单元的数量作为第一个参数传入。每个密集层还具有第二个自变量，该自变量接受要在每个层中使用的激活函数。</p><p id="00b1" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">前三层使用ReLU激活功能，而最后一层使用softmax激活。</p><h2 id="0054" class="nb la it bd lb nc nd dn lf ne nf dp lj ma ng nh ll me ni nj ln mi nk nl lp nm bi translated">定义</h2><ul class=""><li id="7358" class="nz oa it lt b lu lv lx ly ma op me oq mi or mm os of og oh bi translated"><strong class="lt iu">激活函数</strong>:将神经元的结果或信号转化为归一化输出的数学运算。激活函数是在网络中引入非线性的神经网络的组成部分。激活函数的引入使得神经网络具有更强的表达能力和解决复杂的函数。</li><li id="718b" class="nz oa it lt b lu oi lx oj ma ok me ol mi om mm os of og oh bi translated"><strong class="lt iu"> ReLU激活</strong>:代表‘整流线性单元’<em class="on">(y = max(0，x)) </em>。这是一种激活函数，可以转换神经元的值结果。ReLU对来自神经元的值施加的变换由公式y=max(0，x)表示。ReLU激活函数将来自神经元的任何负值钳制为0，而正值保持不变。这种数学变换的结果被用作当前层的输出，并作为下一层的输入。</li><li id="adf6" class="nz oa it lt b lu oi lx oj ma ok me ol mi om mm os of og oh bi translated"><strong class="lt iu"> Softmax </strong>:激活函数，用于导出输入向量中一组数字的概率分布。softmax激活函数的输出是一个向量，其中它的一组值表示一个类/事件发生的概率。向量中的值加起来都是1。</li></ul><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="7e1a" class="nb la it ou b gy oy oz l pa pb"># Classification MLP(Multilayer perceptron) with two hidden layers<br/>model = keras.models.Sequential([<br/>    keras.layers.Flatten(input_shape=[28,28]),<br/>    keras.layers.Dense(500, activation=keras.activations.relu),<br/>    keras.layers.Dense(250, activation=keras.activations.relu),<br/>    keras.layers.Dense(100, activation=keras.activations.relu),<br/>    keras.layers.Dense(10, activation=keras.activations.softmax)<br/>])</span></pre><p id="4e67" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">通过调用我们的模型上可用的'<em class="on"> summary </em>'方法，可以获得上面实现的模型的可视化统计摘要。通过调用summary方法，我们获得了关于模型属性的信息，例如层、层类型、形状、模型中的权重数以及层。</p><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="e9cd" class="nb la it ou b gy oy oz l pa pb">model.summary()</span></pre><p id="c6b8" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">提供了以下输出</p><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="e5ca" class="nb la it ou b gy oy oz l pa pb">Model: "sequential"<br/>_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>flatten (Flatten)            (None, 784)               0         <br/>_________________________________________________________________<br/>dense (Dense)                (None, 500)               392500    <br/>_________________________________________________________________<br/>dense_1 (Dense)              (None, 250)               125250    <br/>_________________________________________________________________<br/>dense_2 (Dense)              (None, 100)               25100     <br/>_________________________________________________________________<br/>dense_3 (Dense)              (None, 10)                1010      <br/>=================================================================<br/>Total params: 543,860<br/>Trainable params: 543,860<br/>Non-trainable params: 0</span></pre></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><p id="cc31" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">模型中的每一层都是一些感知器，每一层都有一组属性权重和偏差。</p><p id="872e" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">模型的权重随机初始化。使用glorot统一初始化器初始化网络中的权重值，该初始化器被证明是Keras中密集层的默认初始化器。</p><ul class=""><li id="bb8c" class="nz oa it lt b lu mw lx mx ma ob me oc mi od mm os of og oh bi translated"><strong class="lt iu"> Glorot uniform initializer </strong>:一种神经网络的权重初始化方法，用作解决神经网络内不稳定梯度的解决方案。网络中的权重由某个范围内的值分布初始化，这些值的平均值等于零且方差恒定。分布的最大值是范围的正值，最小值是范围的负值。范围=[值，-值]</li></ul><p id="7269" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">用于确定分布范围的值来自以下公式:</p><p id="b3ca" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated"><em class="on">值= sqrt(6 /扇入+扇出)</em></p><p id="0747" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">‘fan _ in’是输入到层的数字。</p><p id="071f" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">“扇出”是层内神经元的数量。</p><p id="be88" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">官方研究<a class="ae ky" href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>中提供了更多信息。</p><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="cc94" class="nb la it ou b gy oy oz l pa pb">first_hidden_layer = model.layers[1]<br/>weights, biases = first_hidden_layer.weights<br/>print(weights)<br/>print('_____________')<br/>print('_____________')<br/>print(biases)</span></pre><h1 id="d53b" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">训练模型</h1><h2 id="10ac" class="nb la it bd lb nc nd dn lf ne nf dp lj ma ng nh ll me ni nj ln mi nk nl lp nm bi translated">汇编</h2><p id="ed71" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Keras通过我们之前实例化的模型对象提供了'<em class="on"> compile' </em>方法。compile函数支持我们在幕后实现的模型的实际构建，该模型具有一些额外的特征，如损失函数、优化器和指标。</p><p id="3138" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">为了训练网络，我们利用损失函数来计算网络提供的预测值和训练数据的实际值之间的差异。</p><p id="6ed0" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">伴随着优化算法的损失值促进了对网络内的权重进行的改变的数量。支持因素，如动量和学习率时间表，通过使损失值尽可能接近零，提供了使网络训练收敛的理想环境。</p><h2 id="b04d" class="nb la it bd lb nc nd dn lf ne nf dp lj ma ng nh ll me ni nj ln mi nk nl lp nm bi translated">定义</h2><ul class=""><li id="40ff" class="nz oa it lt b lu lv lx ly ma op me oq mi or mm os of og oh bi translated"><strong class="lt iu">学习率</strong>是神经网络不可或缺的组成部分，因为它是一个因子值，决定了网络权重值的更新水平。</li></ul><p id="41e1" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">在可视化练习中，要求解的函数可以描述为n维参数空间中的双曲线。</p><p id="2a78" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">学习率是影响当前参数值朝向局部/全局最小值的步长的分量；因此，学习速率直接影响训练期间网络的收敛速率。如果学习率太小，网络可能需要几次迭代和历元才能收敛。另一方面，如果学习率太高，就有超过最小值的风险，因此我们的训练不会收敛。选择合适的学习速度可能是一项耗时的工作。</p><ul class=""><li id="f583" class="nz oa it lt b lu mw lx mx ma ob me oc mi od mm os of og oh bi translated"><strong class="lt iu">学习率时间表</strong>:在神经网络的训练过程中可以使用恒定的学习率，但这会增加达到最佳神经网络性能所需的训练量。通过利用学习速率表，我们在训练期间引入学习速率的适时减少或增加，以达到神经网络的最佳训练结果。</li><li id="2247" class="nz oa it lt b lu oi lx oj ma ok me ol mi om mm os of og oh bi translated"><strong class="lt iu">学习率衰减:</strong>学习率衰减减少了梯度下降过程中向局部最小值移动的步长的振荡。通过将学习率降低到与训练开始时使用的学习率值相比更小的值，我们可以将网络导向在最小值附近的更小范围内振荡的解。</li><li id="8abf" class="nz oa it lt b lu oi lx oj ma ok me ol mi om mm os of og oh bi translated"><strong class="lt iu">损失函数</strong>:这是一种量化机器学习模型表现“有多好”的方法。量化是基于一组输入的输出(成本)，这些输入被称为参数值。参数值用于估计预测，而“损失”是预测值和实际值之间的差异。</li><li id="ff52" class="nz oa it lt b lu oi lx oj ma ok me ol mi om mm os of og oh bi translated"><strong class="lt iu">优化器</strong>:神经网络中的优化器是一种算法实现，它通过最小化损失函数提供的损失值来促进神经网络中的梯度下降过程。为了最小化损耗，适当地选择网络内的权重值是至关重要的。</li></ul><p id="4551" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated"><strong class="lt iu">优化算法示例:</strong></p><ul class=""><li id="8e77" class="nz oa it lt b lu mw lx mx ma ob me oc mi od mm os of og oh bi translated">随机梯度下降</li><li id="7a38" class="nz oa it lt b lu oi lx oj ma ok me ol mi om mm os of og oh bi translated">小批量梯度下降</li><li id="eca6" class="nz oa it lt b lu oi lx oj ma ok me ol mi om mm os of og oh bi translated">内斯特罗夫加速梯度</li></ul><p id="6573" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">有关梯度下降的详情，请参阅以下文章:</p><div class="ph pi gp gr pj pk"><a rel="noopener follow" target="_blank" href="/understanding-gradient-descent-and-its-variants-cf0df5c45478"><div class="pl ab fo"><div class="pm ab pn cl cj po"><h2 class="bd iu gy z fp pp fr fs pq fu fw is bi translated">理解梯度下降及其变体</h2><div class="pr l"><h3 class="bd b gy z fp pp fr fs pq fu fw dk translated">简要了解机器学习模型中的学习过程是如何得到优化支持的…</h3></div><div class="ps l"><p class="bd b dl z fp pp fr fs pq fu fw dk translated">towardsdatascience.com</p></div></div><div class="pt l"><div class="pu l pv pw px pt py ks pk"/></div></div></a></div><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="38bc" class="nb la it ou b gy oy oz l pa pb">sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)<br/>model.compile(loss="sparse_categorical_crossentropy", optimizer=sgd, metrics=["accuracy"])</span></pre></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><p id="84e5" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated"><strong class="lt iu"> TensorBoard </strong>提供对每个时期训练中发生的事件的可视化洞察。</p><p id="ff6b" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">TensorBoard提供的训练可视化存储在“runs”文件夹目录中。我们创建一个函数来生成一个文件夹目录，并通过时间戳来标识每个日志。</p><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="69f5" class="nb la it ou b gy oy oz l pa pb">root_logdir = os.path.join(os.curdir, "runs")</span><span id="32fe" class="nb la it ou b gy pf oz l pa pb">def get_run_logdir():<br/>    run_id = time.strftime("run_%Y_%m_%d-%H_%M_%S")<br/>    return os.path.join(root_logdir, run_id)</span><span id="181f" class="nb la it ou b gy pf oz l pa pb">run_logdir = get_run_logdir()<br/>tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)</span></pre><p id="a539" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">模型的功能API ' <em class="on"> fit </em>'方法提供了训练实现的网络的工具。</p><p id="0cd5" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">将特定参数传递给fit函数:</p><ul class=""><li id="1f31" class="nz oa it lt b lu mw lx mx ma ob me oc mi od mm os of og oh bi translated">我们可以指定用于训练的训练数据</li><li id="d000" class="nz oa it lt b lu oi lx oj ma ok me ol mi om mm os of og oh bi translated">我们要训练网络的纪元数</li><li id="2a89" class="nz oa it lt b lu oi lx oj ma ok me ol mi om mm os of og oh bi translated">以及用于在对看不见的数据进行训练期间验证网络性能的验证数据集。</li></ul><p id="2ad9" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">我们还将利用“回调”参数，在本例中，它调用创建的TensorBoard回调。</p><p id="7ed0" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">训练类神经网路时，Keras中的预设批次大小是32。该网络总共被训练60个时期。利用<a class="ae ky" href="https://en.wikipedia.org/wiki/Early_stopping" rel="noopener ugc nofollow" target="_blank">提前停止</a>，一旦在3个时期后记录到验证损失没有改善，则停止训练。尽早停止可以节省您的时间，尤其是在您的网络开始超载并停止收敛的情况下。</p><p id="c54c" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">总之，我们最多训练60个时期的模型，其中我们在每个时期通过网络以32(批次大小)的批次前馈我们的所有训练数据。</p><p id="8b44" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">在看到32个训练图像和标签后，我们的网络的权重参数进行了更新。</p><p id="b083" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">“fit”方法采用官方<a class="ae ky" href="https://keras.io/models/model/#fit" rel="noopener ugc nofollow" target="_blank"> Keras文档</a>中的附加参数。</p><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="2df7" class="nb la it ou b gy oy oz l pa pb">early_stopping_cb = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')<br/>model.fit(train_images, train_labels, epochs=60, validation_data=(validation_images, validation_labels), callbacks=[tensorboard_cb, early_stopping_cb])</span></pre><p id="e57d" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">要运行TensorBoard，请在您的终端中输入下面的命令，然后导航到localhost:6006。</p><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="ecd3" class="nb la it ou b gy oy oz l pa pb">tensorboard --logdir=runs</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pz"><img src="../Images/fc1fd1db7ae03a8515d5ebf43176b58b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pUfMEY46_QCF_DhAFGP85w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自TensorBoard的训练快照</p></figure><h1 id="d765" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">估价</h1><p id="ec04" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">评估一个模型需要通过网络数据进行前馈，这些数据在训练期间还没有暴露给网络。</p><p id="db46" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">在实际使用之前对模型进行评估是一个很好的指标，可以观察模型对未知数据的概括能力。</p><p id="5b9e" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">有了评估结果，您可以决定微调网络超参数，或者在观察测试数据集评估的准确性后进入生产阶段。</p><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="1a6d" class="nb la it ou b gy oy oz l pa pb">model.evaluate(test_images, test_labels)<br/>&gt;&gt; 10000/10000 [==============================] - 1s 74us/sample - loss: 0.3942 - accuracy: 0.8934<br/>[0.3942159619651735, 0.8934]</span></pre></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h1 id="8a6c" class="kz la it bd lb lc nu le lf lg nv li lj jz nw ka ll kc nx kd ln kf ny kg lp lq bi translated">预言</h1><p id="358f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">为了用训练好的模型进行预测，来自我们的测试数据集的5幅图像被用来模拟基于真实生活场景的测试。</p><p id="5e7f" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">通过使用通过我们的训练模型可用的“预测”方法，我们可以将一批实际测试图像传递给我们的模型，并提取每个图像的概率向量。</p><p id="001c" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">概率向量包含10个元素，并且向量中的每个元素对应于来自先前定义的10件服装类别的类别出现的可能性。</p><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="52aa" class="nb la it ou b gy oy oz l pa pb">practical_test_images =  test_images[:10]<br/>prediction_probabilites = model.predict(practical_test_images)<br/>prediction_probabilites</span></pre><p id="02db" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">我们可以创建一个函数来循环遍历每个向量，并获得最高的置信度得分，这对应于我们的模型预测图像所属的类别。</p><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="6dd6" class="nb la it ou b gy oy oz l pa pb">def derive_predicted_classes(prediction_probabilites):<br/>    batch_prediction = []<br/>    for vector in prediction_probabilites:<br/>        batch_prediction.append(np.argmax(vector))<br/>    return batch_prediction</span><span id="a1ca" class="nb la it ou b gy pf oz l pa pb">model_prediction = derive_predicted_classes(prediction_probabilites)<br/>model_prediction<br/>&gt;&gt; [9, 2, 1, 1, 6, 1, 4, 6, 5, 7]</span></pre><p id="0e7b" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">我们可以利用的另一种方法是利用'<em class="on"> predit_classes </em>'方法来获得每个图像对应的类。</p><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="735c" class="nb la it ou b gy oy oz l pa pb">model_prediction = model.predict_classes(practical_test_images)<br/>model_prediction</span></pre><p id="88cb" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">'<em class="on"> predict_classes </em>'方法提供了一个一维向量或一个包含每个图像对应的类的数组。</p><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="f39a" class="nb la it ou b gy oy oz l pa pb">np.array(class_names)[model_prediction]<br/>&gt;&gt;array(['Ankle boot', 'Pullover', 'Trouser', 'Trouser', 'Shirt', 'Trouser',<br/>       'Coat', 'Shirt', 'Sandal', 'Sneaker'], dtype='&lt;U11')</span></pre><p id="e448" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">让我们将practical_test_images中的图像和模型中的预测类可视化。</p><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="d5a2" class="nb la it ou b gy oy oz l pa pb"># Visualise the prediction result<br/>plt.figure(figsize=(10,10))<br/>for i in range(len(practical_test_images)):<br/>    plt.subplot(5,5, i+1)<br/>    plt.xticks([])<br/>    plt.yticks([])<br/>    plt.grid(False)<br/>    plt.imshow(practical_test_images[i])<br/>    plt.xlabel(class_names[model_prediction[i]])<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/e600de68e6cb336b483ca2068a59a1eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*PNsmKBNl61570iiEupkGDA.png"/></div></figure></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h1 id="15fd" class="kz la it bd lb lc nu le lf lg nv li lj jz nw ka ll kc nx kd ln kf ny kg lp lq bi translated">保存模型</h1><p id="5b95" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">最后一步是保存我们的模型以备将来使用。<br/>保存一个经过训练的张量流模型包括调用模型本身的“保存”功能。</p><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="507f" class="nb la it ou b gy oy oz l pa pb">model.save("image_classification_model.h5")</span></pre><p id="b6b3" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">通过调用Keras.models API提供的“load_model”函数，可以使用保存的模型。</p><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="2da7" class="nb la it ou b gy oy oz l pa pb">loaded_model = keras.models.load_model("image_classification_model.h5")<br/>predictions = loaded_model.predict_classes(practical_test_images)<br/>print(predictions)<br/>print(np.array(class_names)[predictions])</span><span id="f751" class="nb la it ou b gy pf oz l pa pb">&gt;&gt;[9 2 1 1 6 1 4 6 5 7]<br/>['Ankle boot' 'Pullover' 'Trouser' 'Trouser' 'Shirt' 'Trouser' 'Coat'<br/> 'Shirt' 'Sandal' 'Sneaker']</span></pre></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h1 id="206a" class="kz la it bd lb lc nu le lf lg nv li lj jz nw ka ll kc nx kd ln kf ny kg lp lq bi translated">结论</h1><p id="c979" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><em class="on">本部分包含会员链接。</em></p><p id="9a34" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated"><strong class="lt iu">通过这篇文章，我们做到了以下几点:</strong></p><ul class=""><li id="882b" class="nz oa it lt b lu mw lx mx ma ob me oc mi od mm os of og oh bi translated"><strong class="lt iu">实现了一个模型</strong></li><li id="83ee" class="nz oa it lt b lu oi lx oj ma ok me ol mi om mm os of og oh bi translated"><strong class="lt iu">训练了一个模特</strong></li><li id="0628" class="nz oa it lt b lu oi lx oj ma ok me ol mi om mm os of og oh bi translated"><strong class="lt iu">评估模型</strong></li><li id="29d6" class="nz oa it lt b lu oi lx oj ma ok me ol mi om mm os of og oh bi translated"><strong class="lt iu">保存了一个模型</strong></li></ul><p id="473b" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">从这里开始，您可以探索更多可以实现的神经网络架构，或者深入TensorFlow和Keras库。</p><p id="c1bc" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated"><strong class="lt iu">下面是一个GitHub知识库的链接，其中包含了本文中的所有代码。</strong></p><div class="ph pi gp gr pj pk"><a href="https://github.com/RichmondAlake/tensorflow_2_tutorials/blob/master/02_image_classification_fashionmnist.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="pl ab fo"><div class="pm ab pn cl cj po"><h2 class="bd iu gy z fp pp fr fs pq fu fw is bi translated">Richmond alake/tensor flow _ 2 _教程</h2><div class="pr l"><h3 class="bd b gy z fp pp fr fs pq fu fw dk translated">permalink dissolve GitHub是4000多万开发人员的家园，他们一起工作来托管和审查代码，管理…</h3></div><div class="ps l"><p class="bd b dl z fp pp fr fs pq fu fw dk translated">github.com</p></div></div><div class="pt l"><div class="qa l pv pw px pt py ks pk"/></div></div></a></div><p id="25ed" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">为了更好地理解实用的机器学习，下面还有一本我极力推荐的书。许多读者可能会熟悉这本书或它以前的版本</p><p id="e006" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated"><a class="ae ky" href="https://amzn.to/2wvuowj" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">用Scikit-Learn、Keras &amp; TensorFlow </strong> </a>进行动手机器学习</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qb"><img src="../Images/d7ea4744a9cec1e6875246411fb4f84e.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/0*ci5fG_lP75nyLjd8.jpg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">动手机器学习</p></figure><h1 id="8693" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">希望这篇文章对你有用。</h1><p id="7a94" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">要联系我或找到更多类似本文的内容，请执行以下操作:</p><ol class=""><li id="1011" class="nz oa it lt b lu mw lx mx ma ob me oc mi od mm oe of og oh bi translated">订阅我的<a class="ae ky" href="https://www.youtube.com/channel/UCNNYpuGCrihz_YsEpZjo8TA" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> YouTube频道</strong> </a>即将发布的视频内容<a class="ae ky" href="https://www.youtube.com/channel/UCNNYpuGCrihz_YsEpZjo8TA" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">这里</strong> </a></li><li id="f8dd" class="nz oa it lt b lu oi lx oj ma ok me ol mi om mm oe of og oh bi translated">跟我上<a class="ae ky" href="https://medium.com/@richmond.alake" rel="noopener"> <strong class="lt iu">中</strong> </a></li><li id="3e35" class="nz oa it lt b lu oi lx oj ma ok me ol mi om mm oe of og oh bi translated">通过<a class="ae ky" href="https://www.linkedin.com/in/richmondalake/" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> LinkedIn </strong> </a>联系我</li></ol></div></div>    
</body>
</html>