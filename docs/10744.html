<html>
<head>
<title>Beginner’s Guide to NVIDIA NeMo</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NVIDIA NeMo 入门指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/beginners-guide-to-nvidia-nemo-e5512862cd8e?source=collection_archive---------34-----------------------#2020-07-27">https://towardsdatascience.com/beginners-guide-to-nvidia-nemo-e5512862cd8e?source=collection_archive---------34-----------------------#2020-07-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="57c4" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">开发和训练语音和语言模型的工具包</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b648dc68463cdc5ecdbaef19803f089f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v66oVuRAxwXbDzyoPvcGJQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">戴维·克洛德在<a class="ae ky" href="https://unsplash.com/s/photos/nemo?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="6524" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇文章让你一瞥 NVIDIA NeMo 背后的基本概念。当涉及到为对话式人工智能建立你自己的艺术模型时，它是一个非常强大的工具包。供您参考，一个典型的对话式 AI 管道由以下领域组成:</p><ol class=""><li id="d2ed" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">自动语音识别(ASR)</li><li id="323f" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">自然语言处理</li><li id="66e0" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">文本到语音(TTS)</li></ol><p id="8d1e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您正在寻找一个成熟的工具包来训练或微调这些领域的模型，您可能想看看 NeMo。它允许研究人员和模型开发人员使用称为<strong class="lb iu">神经模块(NeMo) </strong>的可重用组件来构建他们自己的神经网络架构。基于<a class="ae ky" href="https://github.com/NVIDIA/NeMo" rel="noopener ugc nofollow" target="_blank">官方文档</a>，神经模块为</p><blockquote class="mj mk ml"><p id="eaf5" class="kz la mm lb b lc ld ju le lf lg jx lh mn lj lk ll mo ln lo lp mp lr ls lt lu im bi translated">“……采用<em class="it">类型的</em>输入并产生<em class="it">类型的</em>输出的神经网络概念模块。这种模块通常代表数据层、编码器、解码器、语言模型、损失函数或组合激活的方法。”</p></blockquote><p id="787a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">NeMo 的一个主要优点是，它可以用于训练新模型或在现有的预训练模型上执行迁移学习。最重要的是，在<a class="ae ky" href="https://nvda.ws/3hDVQKv" rel="noopener ugc nofollow" target="_blank"> NVIDIA GPU Cloud (NGC) </a>有相当多的预训练模型可供您使用。在撰写本文时，GPU 加速的云平台具有以下预训练模型:</p><h2 id="1a7d" class="mq mr it bd ms mt mu dn mv mw mx dp my li mz na nb lm nc nd ne lq nf ng nh ni bi translated">自动语音识别(Automatic Speech Recognition)</h2><ul class=""><li id="c65b" class="lv lw it lb b lc nj lf nk li nl lm nm lq nn lu no mb mc md bi translated">碧玉 10x5  — Librispeech</li><li id="3da1" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated"><a class="ae ky" href="https://nvda.ws/3jVCClA" rel="noopener ugc nofollow" target="_blank">多数据集 Jasper 10x5 </a> — LibriSpeech、Mozilla Common Voice、WSJ、Fisher 和 Switchboard</li><li id="3d8e" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated"><a class="ae ky" href="https://nvda.ws/2CW5Dg5" rel="noopener ugc nofollow" target="_blank">AI-shell 2 Jasper 10x 5</a>—AI-shell 2 普通话</li><li id="964f" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated"><a class="ae ky" href="https://nvda.ws/39zNssC" rel="noopener ugc nofollow" target="_blank">夸兹涅特</a>——速度扰动下的自由探索</li><li id="fdd2" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated">QuartzNetLibrispeechMCV—Librispeech，Mozilla common voice</li><li id="97d1" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated"><a class="ae ky" href="https://nvda.ws/2EqtfKl" rel="noopener ugc nofollow" target="_blank">多数据集 Quartznet </a> — LibriSpeech、Mozilla Common Voice、WSJ、Fisher 和 Switchboard</li><li id="cb1b" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated"><a class="ae ky" href="https://nvda.ws/2P3BIoR" rel="noopener ugc nofollow" target="_blank">WSJ-Quartznet</a>——华尔街日报、Librispeech、Mozilla common voice</li><li id="2a39" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated"><a class="ae ky" href="https://nvda.ws/39zV5zh" rel="noopener ugc nofollow" target="_blank">AI-shell 2 Quartznet</a>—AI-shell 2 普通话</li></ul><h2 id="6e07" class="mq mr it bd ms mt mu dn mv mw mx dp my li mz na nb lm nc nd ne lq nf ng nh ni bi translated">自然语言处理</h2><ul class=""><li id="8db1" class="lv lw it lb b lc nj lf nk li nl lm nm lq nn lu no mb mc md bi translated"><a class="ae ky" href="https://nvda.ws/3hGJtNB" rel="noopener ugc nofollow" target="_blank">bertalgeuncased</a>—使用 BERT Large 对序列长度为 512 的未分类维基百科和图书语料库进行分类</li><li id="04ed" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated"><a class="ae ky" href="https://nvda.ws/2Df8DnS" rel="noopener ugc nofollow" target="_blank"> BertBaseCased </a> —使用 BERT Base 对序列长度为 512 的维基百科和图书语料库进行装箱</li><li id="4b43" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated"><a class="ae ky" href="https://nvda.ws/32VyCLM" rel="noopener ugc nofollow" target="_blank"> BertBaseUncased </a> —使用 BERT Base 对序列长度为 512 的维基百科和图书语料库进行脱壳</li><li id="f2ba" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated"><a class="ae ky" href="https://nvda.ws/32Z6EP7" rel="noopener ugc nofollow" target="_blank">变压器-大</a> — WikiText-2</li></ul><h2 id="770b" class="mq mr it bd ms mt mu dn mv mw mx dp my li mz na nb lm nc nd ne lq nf ng nh ni bi translated">自文本至语音的转换</h2><ul class=""><li id="5302" class="lv lw it lb b lc nj lf nk li nl lm nm lq nn lu no mb mc md bi translated"><a class="ae ky" href="https://nvda.ws/2P23rGk" rel="noopener ugc nofollow" target="_blank"> Tacotron2 </a> — LJSpeech</li><li id="6adb" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated"><a class="ae ky" href="https://nvda.ws/331eRlO" rel="noopener ugc nofollow" target="_blank">波辉</a> — LJSpeech</li></ul></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h1 id="fa8c" class="nw mr it bd ms nx ny nz mv oa ob oc my jz od ka nb kc oe kd ne kf of kg nh og bi translated">设置</h1><p id="6e29" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li oh lk ll lm oi lo lp lq oj ls lt lu im bi translated">确保您满足以下要求:</p><ul class=""><li id="48e9" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu no mb mc md bi translated">Python 3.6 或 3.7</li><li id="e55a" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated">PyTorch 1.4。*支持 GPU</li><li id="5c9a" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated">NVIDIA APEX(可选)</li></ul><p id="23a3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">供您参考，NVIDIA APEX 是一个实用程序，有助于简化 Pytorch 中的混合精度和分布式培训。这不是必需的，但它有助于提高性能和训练时间。如果您打算使用 NVIDIA APEX，强烈建议使用 Linux 操作系统，因为对 Windows 的支持仍处于实验阶段。</p><p id="ab77" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您使用 docker，安装非常简单。</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="91fa" class="mq mr it ol b gy op oq l or os">docker run --runtime=nvidia -it --rm -v --shm-size=16g -p 8888:8888 -p 6006:6006 --ulimit memlock=-1 --ulimit stack=67108864 nvcr.io/nvidia/nemo:v0.11</span></pre><p id="3823" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你已经注册了 NVIDIA <a class="ae ky" href="https://nvda.ws/3f50Lm1" rel="noopener ugc nofollow" target="_blank"> NGC PyTorch 容器</a>，一个接一个地执行下面的命令。</p><p id="ba7b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">拉码头工人</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="c6dc" class="mq mr it ol b gy op oq l or os">docker pull nvcr.io/nvidia/pytorch:20.01-py3</span></pre><p id="8a16" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">运行以下命令</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="4991" class="mq mr it ol b gy op oq l or os">docker run --gpus all -it --rm -v &lt;nemo_github_folder&gt;:/NeMo  --shm-size=8g -p 8888:8888 -p 6006:6006 --ulimit memlock=-1 --ulimit  stack=67108864 nvcr.io/nvidia/pytorch:20.01-py3</span></pre><p id="5cf1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下步骤是安装其余部分的继续。如果您在本地运行它或者通过 Google Colab 运行它，您应该从这里开始安装。运行以下命令安装必要的依赖项。</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="5211" class="mq mr it ol b gy op oq l or os">apt-get update &amp;&amp; apt-get install -y libsndfile1 ffmpeg &amp;&amp; pip install Cython</span></pre><p id="b83b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦你完成了，下一步是<code class="fe ot ou ov ol b">pip install</code> NeMo 模块取决于你的用例。如果您使用它来训练新模型，请运行以下命令</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="e9bd" class="mq mr it ol b gy op oq l or os">pip install nemo_toolkit</span></pre><p id="024e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">获得自动语音识别集合附带的 NeMo</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="7ddc" class="mq mr it ol b gy op oq l or os">pip install nemo_toolkit[asr]</span></pre><p id="68ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">NeMo 和自然语言处理集合可以通过</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="30d7" class="mq mr it ol b gy op oq l or os">pip install nemo_toolkit[nlp]</span></pre><p id="1f68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要安装 NeMo 和文本到语音集合，请运行以下命令</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="4586" class="mq mr it ol b gy op oq l or os">pip install nemo_toolkit[tts]</span></pre><p id="a668" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您正在寻找包含所有集合的完整安装，您可以通过</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="6424" class="mq mr it ol b gy op oq l or os">pip install nemo_toolkit[all]</span></pre></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h1 id="d20f" class="nw mr it bd ms nx ny nz mv oa ob oc my jz od ka nb kc oe kd ne kf of kg nh og bi translated">程序设计模型</h1><p id="6bb7" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li oh lk ll lm oi lo lp lq oj ls lt lu im bi translated">基于 NeMo API 的每个应用程序通常使用以下工作流程:</p><ol class=""><li id="c7a6" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">神经调节因子和必要神经调节因子的产生</li><li id="28b1" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">定义神经模块的有向无环图(DAG)</li><li id="a2da" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">号召“行动”,如训练</li></ol><p id="f070" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">需要注意的一点是，NeMo 遵循<strong class="lb iu">懒惰执行</strong>模型。这意味着在调用推理之前或训练之后，不会执行任何实际的计算。</p></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h1 id="8b67" class="nw mr it bd ms nx ny nz mv oa ob oc my jz od ka nb kc oe kd ne kf of kg nh og bi translated">神经类型</h1><p id="0a7a" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li oh lk ll lm oi lo lp lq oj ls lt lu im bi translated">NeMo 中每个神经模块的所有输入和输出端口都是类型化的。它们是用 Python 类 NeuralType 和从 ElementType、AxisType 和 AxisKindAbstract 派生的辅助类实现的。神经类型由以下数据组成:</p><ul class=""><li id="c96e" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu no mb mc md bi translated"><code class="fe ot ou ov ol b">axes</code> —表示改变特定轴的含义(批次、时间)</li><li id="cb9f" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated"><code class="fe ot ou ov ol b">elements_type</code> —表示激活中存储内容的语义和属性(音频信号、文本嵌入、逻辑)</li></ul><h2 id="9809" class="mq mr it bd ms mt mu dn mv mw mx dp my li mz na nb lm nc nd ne lq nf ng nh ni bi translated">初始化</h2><p id="4c05" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li oh lk ll lm oi lo lp lq oj ls lt lu im bi translated">实例化主要是在模块的<code class="fe ot ou ov ol b">input_ports</code>和<code class="fe ot ou ov ol b">output_ports</code>属性中完成的。你可以如下实例化一个<code class="fe ot ou ov ol b">Neural Type</code></p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="85b3" class="mq mr it ol b gy op oq l or os">axes: Optional[Tuple] = None, elements_type: ElementType = VoidType(), optional=False</span></pre><p id="ba8b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看下面的(音频)数据层输出端口示例。</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="9bbf" class="mq mr it ol b gy op oq l or os">{<br/>    'audio_signal': NeuralType(('B', 'T'), AudioSignal(freq=self._sample_rate)),<br/>    'a_sig_length': NeuralType(tuple('B'), LengthsType()),<br/>    'transcripts': NeuralType(('B', 'T'), LabelsType()),<br/>    'transcript_length': NeuralType(tuple('B'), LengthsType()),<br/>}</span></pre><ul class=""><li id="8e5c" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu no mb mc md bi translated"><code class="fe ot ou ov ol b">B</code> —代表 AxisKind。一批</li><li id="c9d2" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated"><code class="fe ot ou ov ol b">T </code> —代表 AxisKind。时间</li><li id="be7a" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated"><code class="fe ot ou ov ol b">D</code> —代表 AxisKind。尺寸</li></ul><h2 id="d085" class="mq mr it bd ms mt mu dn mv mw mx dp my li mz na nb lm nc nd ne lq nf ng nh ni bi translated">比较</h2><p id="3494" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li oh lk ll lm oi lo lp lq oj ls lt lu im bi translated">您可以通过<code class="fe ot ou ov ol b">compare()</code>功能比较两个<code class="fe ot ou ov ol b">NeuralType</code>。它将返回一个<code class="fe ot ou ov ol b">NeuralTypeComparisonResult</code>,传达如下意思</p><ul class=""><li id="b0c3" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu no mb mc md bi translated"><strong class="lb iu">相同</strong> = 0</li><li id="46c2" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated"><strong class="lb iu">减去</strong> = 1 (A 为 B)</li><li id="7363" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated"><strong class="lb iu">大于</strong> = 2 (B 是 A)</li><li id="0b10" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated"><strong class="lb iu">尺寸不兼容</strong> = 3(尺寸不兼容。调整连接器大小可能会修复不兼容性)</li><li id="bbed" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated"><strong class="lb iu"> TRANSPOSE_SAME </strong> = 4(数据格式不兼容，但列表和张量之间的转置和/或转换会使它们相同)</li><li id="25e7" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated"><strong class="lb iu">CONTAINER _ SIZE _ MISMATCH</strong>= 5(A 和 B 包含不同数量的元素)</li><li id="eb42" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated"><strong class="lb iu">不相容</strong> = 6 (A 和 B 不相容)</li><li id="8525" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated"><strong class="lb iu">SAME _ TYPE _ INCOMPATIBLE _ PARAMS</strong>= 7(A 和 B 属于同一类型，但参数化不同)</li></ul><p id="f14a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们转到下一节，深入探讨示例。</p></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h1 id="666d" class="nw mr it bd ms nx ny nz mv oa ob oc my jz od ka nb kc oe kd ne kf of kg nh og bi translated">例子</h1><h2 id="a999" class="mq mr it bd ms mt mu dn mv mw mx dp my li mz na nb lm nc nd ne lq nf ng nh ni bi translated">基本示例</h2><p id="2c5c" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li oh lk ll lm oi lo lp lq oj ls lt lu im bi translated">让我们看看下面的例子，它建立了一个模型，学习 y=sin(x)的泰勒系数。</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="cd4e" class="mq mr it ol b gy op oq l or os">import nemo<br/><br/># instantiate Neural Factory with supported backend<br/>nf = nemo.core.NeuralModuleFactory()<br/><br/># instantiate necessary neural modules<br/># RealFunctionDataLayer defaults to f=torch.sin, sampling from x=[-4, 4]<br/>dl = nemo.tutorials.RealFunctionDataLayer(<br/>    n=10000, batch_size=128)<br/>fx = nemo.tutorials.TaylorNet(dim=4)<br/>loss = nemo.tutorials.MSELoss()<br/><br/># describe activation's flow<br/>x, y = dl()<br/>p = fx(x=x)<br/>lss = loss(predictions=p, target=y)<br/><br/># SimpleLossLoggerCallback will print loss values to console.<br/>callback = nemo.core.SimpleLossLoggerCallback(<br/>    tensors=[lss],<br/>    print_func=lambda x: logging.info(f'Train Loss: {str(x[0].item())}'))<br/><br/># Invoke "train" action<br/>nf.train([lss], callbacks=[callback],<br/>         optimization_params={"num_epochs": 3, "lr": 0.0003},<br/>         optimizer="sgd")</span></pre><h2 id="ba1c" class="mq mr it bd ms mt mu dn mv mw mx dp my li mz na nb lm nc nd ne lq nf ng nh ni bi translated">自动语音识别(Automatic Speech Recognition)</h2><p id="9391" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li oh lk ll lm oi lo lp lq oj ls lt lu im bi translated">查看以下笔记本，开始您的语音识别项目:</p><ul class=""><li id="07f0" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu no mb mc md bi translated"><a class="ae ky" href="https://github.com/NVIDIA/NeMo/blob/master/examples/asr/notebooks/1_ASR_tutorial_using_NeMo.ipynb" rel="noopener ugc nofollow" target="_blank">端到端自动语音识别简介</a></li><li id="4dcc" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated"><a class="ae ky" href="https://github.com/NVIDIA/NeMo/blob/master/examples/asr/notebooks/2_Online_ASR_Microphone_Demo.ipynb" rel="noopener ugc nofollow" target="_blank">NeMo 中麦克风流的自动语音识别</a></li><li id="ba95" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated"><a class="ae ky" href="https://github.com/NVIDIA/NeMo/blob/master/examples/asr/notebooks/3_Speech_Commands_using_NeMo.ipynb" rel="noopener ugc nofollow" target="_blank">基于 QuartzNet 模型的语音命令识别</a></li></ul><h2 id="f3ed" class="mq mr it bd ms mt mu dn mv mw mx dp my li mz na nb lm nc nd ne lq nf ng nh ni bi translated">自然语言处理</h2><p id="0f9c" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li oh lk ll lm oi lo lp lq oj ls lt lu im bi translated">使用 NeMO 进行自然语言处理任务的笔记本集合:</p><ul class=""><li id="644b" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu no mb mc md bi translated"><a class="ae ky" href="https://github.com/NVIDIA/NeMo/blob/master/examples/nlp/language_modeling/BERTPretrainingTutorial.ipynb" rel="noopener ugc nofollow" target="_blank">伯特预训</a></li><li id="7cdc" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated"><a class="ae ky" href="https://github.com/NVIDIA/NeMo/blob/master/examples/nlp/biobert_notebooks/biobert_qa.ipynb" rel="noopener ugc nofollow" target="_blank">用于问答的生物机器人</a></li><li id="5569" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated"><a class="ae ky" href="https://github.com/NVIDIA/NeMo/blob/master/examples/nlp/biobert_notebooks/biobert_ner.ipynb" rel="noopener ugc nofollow" target="_blank">用于命名实体识别的 BioBERT】</a></li><li id="3b85" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu no mb mc md bi translated"><a class="ae ky" href="https://github.com/NVIDIA/NeMo/blob/master/examples/nlp/biobert_notebooks/biobert_re.ipynb" rel="noopener ugc nofollow" target="_blank">用于关系提取的 BioBERT</a></li></ul><h2 id="fa71" class="mq mr it bd ms mt mu dn mv mw mx dp my li mz na nb lm nc nd ne lq nf ng nh ni bi translated">自文本至语音的转换</h2><p id="3e5d" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li oh lk ll lm oi lo lp lq oj ls lt lu im bi translated">使用 NeMo 执行文本到语音转换任务的笔记本示例:</p><ul class=""><li id="4d68" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu no mb mc md bi translated"><a class="ae ky" href="https://github.com/NVIDIA/NeMo/blob/master/examples/tts/notebooks/1_Tacotron_inference.ipynb" rel="noopener ugc nofollow" target="_blank"> Tacotron + WaveGlow 生成音频</a></li></ul></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h1 id="8d68" class="nw mr it bd ms nx ny nz mv oa ob oc my jz od ka nb kc oe kd ne kf of kg nh og bi translated">结论</h1><p id="4b9e" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li oh lk ll lm oi lo lp lq oj ls lt lu im bi translated">让我们回顾一下今天所学的内容。</p><p id="11cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们首先简要介绍了 NVIDIA NeMo toolkit。此外，我们接触了一些预先训练好的模型，这些模型在<a class="ae ky" href="https://nvda.ws/3hDVQKv" rel="noopener ugc nofollow" target="_blank"> NVIDIA GPU Cloud (NGC) </a>很容易获得。</p><p id="1010" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们通过 docker 或使用 pip install 的本地安装来安装工具包。</p><p id="944f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们深入探讨了构成 NeMo 背后的基本概念的编程模型和神经类型。</p><p id="da0a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们测试了几个自动语音识别、自然语言处理和文本到语音转换任务的例子。</p><p id="03bc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢你阅读这篇文章。希望在下一篇文章中再见到你！</p></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h1 id="74d6" class="nw mr it bd ms nx ny nz mv oa ob oc my jz od ka nb kc oe kd ne kf of kg nh og bi translated">参考</h1><ol class=""><li id="b94e" class="lv lw it lb b lc nj lf nk li nl lm nm lq nn lu ma mb mc md bi translated"><a class="ae ky" href="https://github.com/NVIDIA/NeMo" rel="noopener ugc nofollow" target="_blank">英伟达 NeMo Github </a></li><li id="3292" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://docs.nvidia.com/deeplearning/nemo/neural_mod_bp_guide/" rel="noopener ugc nofollow" target="_blank">英伟达 NeMo 文档</a></li><li id="b589" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://github.com/NVIDIA/NeMo/tree/master/examples" rel="noopener ugc nofollow" target="_blank">英伟达尼莫的例子</a></li></ol></div></div>    
</body>
</html>