# 如何从假设到生产测试你的 ML 模型

> 原文：<https://towardsdatascience.com/how-to-test-your-ml-models-from-hypothesis-to-production-7553430382a9?source=collection_archive---------19----------------------->

## 从第一个假设到生产中的 A/B 测试，我个人的模型测试和评估的最佳实践。

![](img/8593d96de3fa46d6e33bd7180e149ebb.png)

维克多·加西亚在 [Unsplash](https://unsplash.com/s/photos/pipeline?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上拍摄的照片

数据科学团队的目标通常是生成预测模型(分类器、回归器等)，然后用于改进公司的产品。

**但是我们怎么知道新的模型会比现在的好呢？**

带有适当对照组和随机排列测试的 A/B 测试可能会给我们一个很好的理解。问题是许多公司负担不起在真实场景中测试模型的费用。想象一下，如果特斯拉将在你身上 A/B 测试他们的新自动驾驶仪，你的车将与一个较弱的模型在一组。即使我们不谈论人们的生活，公司也可能经常经历表现不佳的模型带来的负面影响。

为了尽量减少负面影响，我更喜欢对 A/B 测试的模型候选人充满信心。当然，我们永远不会有 100%的信心，但这里的 4 个步骤测试我通常会在我工作的团队中实施。每一步都会增加我们对模型质量的信心。

# 4 步模型测试:

## 1.地方发展

模型开发通常可以从假设开始，比如说

*“如果我们使用随机森林模型作为我们的分类器会怎么样？”*

然后，一些团队成员会将这个想法作为他下周工作的任务。此时，您可能已经有了一个可用来训练和测试模型的标注数据集。因此，在时间序列数据的情况下，正确分割数据以进行交叉验证或回溯测试将是该研究人员的责任。

因此，这些数据科学家们利用该模型得出结论，交叉验证给他的平均准确率为 95%，而当前的基线模型在同一数据集上的准确率为 93%。优秀的数据科学家不会停留在这些数字上，他们会进行排列测试并计算 p 值，以了解这种准确性差异是否会因数据变化而随机出现。

提示:使用排列测试或其他你认为更适合你的特殊情况的统计测试。p 值不是“银弹”,但总是考虑获得更好性能的随机机会是有用的。

因此，我们的数据科学家得出结论，差异具有统计学意义。太好了！这意味着我们有所发现。数据科学家为管道准备了一个模型，推送他的代码，并提出拉取请求。

## 2.CI/CD 中的测试

我建议您实施的 ML 模型测试的第二步是作为 CI/CD 的一部分进行测试。有许多不同的方法可以实现这一点，它们都取决于您当前的架构，但主要思想是这样的:

*   CI/CD 环境可以访问一些样本外数据集，而数据科学团队中的任何人都无法访问这些数据集。
*   新的模型总是以同样的方式自动测试，作者不能影响它。
*   自动计算指标。将它们显示在仪表板上是一个好主意，团队中的每个人都可以看到它。
*   在成功测试的基础上，可以接受新模型的拉式请求，以加入开发分支，并进行下一步。

您需要确保样本外数据集具有代表性，并且能够提供可靠的评估。围绕 CI/CD 测试举行一些仪式也是一个好主意，这样您的团队就不会花一整天的时间来破解样本外数据，尝试不同的东西，并调整他的模型以在这个特定数据上获得更好的性能。

在我的团队中，只有当一个人向其他团队成员证明本地研究的正确性时，这种测试才是可能的。我们还有一个监控系统，所有的队友和产品经理都会收到一封电子邮件，里面有测试结果。因此，当任何人试图滥用这种测试时，这是显而易见的。

## 3.阶段测试/影子测试

下一步是在类似生产的环境中测试您的模型。例如，我们将在阶段服务器上部署开发分支，并使其在与生产管道完全相同的数据上运行，唯一的区别是最终用户不会看到开发分支的结果，结果将存储在数据库中。在进行这样的实验之前，有几个问题需要回答，但最主要的是:

“我什么时候停止那个实验？”

类似于 A/B 测试，要回答这个问题，您需要计算出您期望获得的效果大小和统计功效。

为了对模型质量做出最后的结论，我建议你使用一个统计测试来保护你自己不被随机性所充斥，但是记住它不是 100%可靠的。

## 4.A/B 测试

上面的 3 个步骤将会让你对你的新模型充满信心。在某些情况下，A/B 测试是不可能的，因此您可以停止影子测试，一些公司可以同时试验许多不同的模型，在这种情况下，影子测试可能是不必要的，在对样本外数据模型进行测试后，可以作为 A/B 测试的一部分进行测试。

# 结论

数据科学通常很棘手，在模型开发过程中有许多事情会误导您。

*   永远不要 100%相信你的模型表现，使用贝叶斯思维。
*   如果您是经理/团队领导/数据科学家，请不要犹豫质疑您的团队成员报告的模型性能
*   使用统计测试来比较模型性能

## 感谢阅读！你如何在你的团队中处理模型测试？