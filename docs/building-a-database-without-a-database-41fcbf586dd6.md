# æ„å»ºæ•°æ®åº“â€”æ²¡æœ‰æ•°æ®åº“

> åŸæ–‡ï¼š<https://towardsdatascience.com/building-a-database-without-a-database-41fcbf586dd6?source=collection_archive---------28----------------------->

## æ„å»º pythonic æ•°æ®åº“ç±»æ¥è·å–ã€æ¸…ç†ã€è½¬æ¢ã€åˆå¹¶å’Œæ ‡è®°æ•°æ®â€”â€”æ‰€æœ‰è¿™äº›éƒ½ä¸éœ€è¦æ•°æ®åº“

æœºå™¨å­¦ä¹ å®è·µè€…å’Œæ•°æ®å·¥ç¨‹å¸ˆéƒ½å¾ˆæ¸…æ¥šæ•°æ®æ¥æºã€æ”¶é›†ã€æ¸…ç†ã€è½¬æ¢ã€åˆå¹¶å’Œæ ‡è®°çš„å¯é‡å¤æ€§ã€‚è¿™äº›æ´»åŠ¨çš„ç›®çš„æ˜¯ä¸ºç®€åŒ–ã€æ¢ç´¢æ€§åˆ†ææˆ–å»ºæ¨¡å‡†å¤‡æ•°æ®ã€‚ä¾‹å¦‚ï¼Œ [scikit-learn](https://scikit-learn.org/) é€šè¿‡å®ƒä»¬çš„ [Pipeline](https://scikit-learn.org/stable/modules/compose.html) ç±»åœ¨æŠ½è±¡æ•°æ®ç®¡é“æ–¹é¢åšå¾—éå¸¸å‡ºè‰²ã€‚å°½ç®¡å¦‚æ­¤ï¼Œä»å¤šä¸ªæ¥æºæå–æ•°æ®çš„é—®é¢˜ä»ç„¶å­˜åœ¨ï¼Œå› ä¸ºæ²¡æœ‰å¤šå°‘ç®€å•çš„æŠ½è±¡ä½¿æ•°æ®äº‰è®ºè€…çš„ç”Ÿæ´»æ›´å®¹æ˜“ã€‚

![](img/761677ee6f22c8145dc77ba28ff64590.png)

Python æ•°æ®åº“ç±»|ğŸ“¸ç”±[æˆ‘](https://www.linkedin.com/in/dylancunningham/)

**é—®é¢˜é™ˆè¿°:**ä¸åŒçš„æ•°æ®æ˜¯ä¸åŒçš„ï¼Œåˆå¹¶èµ·æ¥å¾ˆéº»çƒ¦ã€‚

**è§£å†³æ–¹æ¡ˆ:**å¼€å‘ä¸€ä¸ª pythonic æ•°æ®åº“æŠ½è±¡ï¼Œä»¥ä¸€ç§æ˜“äºä½¿ç”¨ã€å¥å£®ä¸”ç”Ÿäº§å°±ç»ªçš„æ–¹å¼åˆå¹¶æ‚¨çš„æ•°æ®ã€‚

## ç›®å½•

1.  æŠ½è±¡
2.  æ•°æ®åº“â€”æ²¡æœ‰æ•°æ®åº“â€”æŠ½è±¡
3.  ä»‹ç» Python æ•°æ®åº“æŠ½è±¡
4.  å¦‚ä½•

## å…³é”®æ¦‚å¿µ

æŠ½è±¡ä½¿å¾—ç¼–ç¨‹ç”Ÿæ´»æ›´å®¹æ˜“ç®¡ç†ã€‚ä¸€ä¸ªæ•°æ®åº“â€”â€”æ²¡æœ‰æ•°æ®åº“â€”â€”æŠ½è±¡å°†ä½¿æ‚¨çš„æ•°æ®äº‰è®ºç”Ÿæ´»æ›´åŠ èˆ’é€‚ï¼Œå¹¶ä¸”å°†æ˜¯æ‚¨çš„ç”Ÿäº§ç®¡é“çš„ä¸€ä¸ªå¥å£®çš„è¡¥å……ã€‚

# 1.æŠ½è±¡

ä¸ºäº†ä¸é‡å¤ç½‘ä¸Šçš„æ–‡ç« ï¼Œæˆ‘å°†ä¸è§£é‡ŠæŠ½è±¡ï¼Œä½†è¿™é‡Œæœ‰ä¸¤ä¸ªå‚è€ƒ:

*   [å…³é”®æ¦‚å¿µ:æŠ½è±¡](https://medium.com/@mattburgess/critical-concept-abstraction-ba9e9c0f225e)(é€šè¿‡åª’ä»‹)
*   "[é¢å‘åˆå­¦è€…çš„ OOP æ¦‚å¿µ:ä»€ä¹ˆæ˜¯æŠ½è±¡ï¼Ÿ](https://stackify.com/oop-concept-abstraction/)(é€šè¿‡ Stackify)

> æŠ½è±¡è¢«å®šä¹‰ä¸ºä½äºæ›´å¤æ‚çš„äº‹ç‰©ä¹‹ä¸Šï¼Œå¹¶ä½¿å…¶å¯¹ç”¨æˆ·æ›´ç®€å•çš„äº‹ç‰©ã€‚â€”é©¬ç‰¹Â·ä¼¯å‰æ–¯åœ¨ã€Šæ‰¹åˆ¤çš„æ¦‚å¿µ:æŠ½è±¡ã€‹ä¸­

# 2.æ•°æ®åº“â€”æ²¡æœ‰æ•°æ®åº“â€”æŠ½è±¡

æ²¡æœ‰æ•°æ®åº“çš„æ•°æ®åº“æŠ½è±¡(æˆ‘ç§°ä¹‹ä¸ºæ•°æ®åº“æŠ½è±¡ï¼›ä¸è¦ä¸ SQL æ•°æ®åº“æ··æ·†)è‡³å°‘æœ‰å››ä¸ªç”¨é€”:

*   æ‚¨åªéœ€è¦ç¼–å†™ä¸€æ¬¡æ•°æ®äº‰è®ºä»£ç 
*   ç”Ÿäº§ä¸€ä¸ª ML æ¨¡å‹æ˜¯éå¸¸å®¹æ˜“çš„
*   æ‚¨ä¸éœ€è¦æ•°æ®å­˜å‚¨
*   äº‰è®ºæ“ä½œçš„é¡ºåºè¢«ä¿ç•™å¹¶ä¸”æ˜¯çµæ´»çš„ã€‚

![](img/cf6fc7774fbc8dec49ce832335288451.png)

Python æ•°æ®åº“æŠ½è±¡å›¾|ğŸ“¸ç”±[æˆ‘](https://www.linkedin.com/in/dylancunningham/)

## **ä½ åªéœ€è¦å†™ä¸€æ¬¡æ•°æ®è§’åŠ›ä»£ç ã€‚**

å¦‚æœæœ‰è¶³å¤Ÿçš„è¿œè§ï¼Œæ•°æ®åº“æŠ½è±¡å°†æŠ½è±¡å‡ºé‡å¤è¿›è¡Œæ‰€æœ‰äº‰è®ºæ“ä½œçš„éœ€è¦ã€‚æŒ‘æˆ˜æ˜¯ä½¿æŠ½è±¡è¶³å¤Ÿå¥½ï¼Œä»¥å…è®¸ç”¨æˆ·ä»¥å¥å£®å’Œæ˜“äºä½¿ç”¨çš„æ–¹å¼çµæ´»åœ°åº”ç”¨ä»–ä»¬å–œæ¬¢çš„ä»»ä½•æ“ä½œã€‚

ä¸‹é¢æ˜¯ä¼—æ‰€å‘¨çŸ¥çš„æ•°æ®äº‰è®ºæ“ä½œçš„ä¸€ä¸ªä¸å…¨é¢çš„åˆ—è¡¨:æŸ¥è¯¢ã€æ’åºã€è½¬æ¢ã€å¡«å……ç©ºå€¼å’Œåˆå¹¶ã€‚ä¸ºæ¯ä¸€ä¸ªå®éªŒå’Œ/æˆ–æ¯ä¸€ä¸ªç”Ÿäº§æ¨¡å‹ç¼–å†™ä»£ç æ¥å®Œæˆè¿™äº›æ“ä½œ(ç”šè‡³æ›´å¤š)æ˜¯å¾ˆéš¾çš„ã€‚

## ç”Ÿäº§ä¸€ä¸ª ML æ¨¡å‹æ˜¯éå¸¸å®¹æ˜“çš„ã€‚

ML ç®¡é“çš„æœ€ç»ˆç›®æ ‡æ˜¯åšå‡ºé¢„æµ‹(ä¾‹å¦‚ï¼Œå¯¹äºå¤§å¤šæ•° ML ä»»åŠ¡)ã€‚æ•°æ®ç§‘å­¦å®¶é¢ä¸´çš„ä¸€ä¸ªé—®é¢˜æ˜¯å¯é‡å¤æ€§ã€‚å½“æ•°æ®ç§‘å­¦å®¶å¤„äºè¯•éªŒé˜¶æ®µæ—¶ï¼Œä»–ä»¬ä¼šåº”ç”¨å„ç§å„æ ·çš„äº‰è®ºæ“ä½œæ¥æµ‹è¯•å“ªä¸ªæ˜¯æœ€ä½³çš„ã€‚å°†æœ€ä½³æ“ä½œè½¬ç§»åˆ°ç”Ÿäº§åœºæ™¯å¹¶ä¸æ€»æ˜¯å®¹æ˜“çš„ã€‚

æ•°æ®åº“æŠ½è±¡å°†å…è®¸ç§‘å­¦å®¶ä»¥å¯é‡å¤çš„æ–¹å¼è½»æ¾åœ°ä»å®éªŒé˜¶æ®µè¿‡æ¸¡åˆ°ç”Ÿäº§é˜¶æ®µï¼Œç„¶åå†è¿”å›ã€‚

## **ä½ ä¸éœ€è¦æ•°æ®å­˜å‚¨ã€‚**

æ•°æ®åº“æŠ½è±¡ä¸éœ€è¦æœ¬åœ°æˆ–åŸºäºäº‘çš„æ•°æ®å­˜å‚¨ï¼Œä½†æ˜¯æ‚¨å¯èƒ½å¸Œæœ›æˆäºˆç”¨æˆ·è¿™ç§èƒ½åŠ›ã€‚åœ¨æˆ‘çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä¸æƒ³ç®¡ç†æ•°æ®åº“ã€‚æˆ‘åªæ˜¯æ„å»ºä¸ web APIsã€ç½‘é¡µç­‰äº¤äº’çš„åŠŸèƒ½ã€‚

> ä»–ä»¬çš„æ•°æ®åº“æ˜¯æˆ‘çš„æ•°æ®åº“ï¼Œä½†ä»–ä»¬çš„æ•°æ®åº“é—®é¢˜ä¸æ˜¯æˆ‘çš„é—®é¢˜ã€‚

æ³¨æ„:è¿™ç§æŠ½è±¡çš„ä¸€ä¸ªé™åˆ¶æ˜¯æŸ¥è¯¢é€Ÿåº¦ã€‚å¦‚æœæ‚¨ç®¡ç†è‡ªå·±çš„æ•°æ®åº“ï¼Œæ‚¨å¯èƒ½ä¼šæé«˜æŸ¥è¯¢çš„æ€§èƒ½ã€‚

## **è§’åŠ›ä½œæˆ˜çš„ç§©åºè¢«ä¿ç•™äº†ä¸‹æ¥ï¼Œè€Œä¸”å¾ˆçµæ´»ã€‚**

è¿™ä¸ªç›®çš„å¾ˆé‡è¦ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªè€ƒè™‘ä¸å‘¨çš„é—®é¢˜ã€‚æŠŠæ“ä½œçš„é¡ºåºç•™ç»™ç”¨æˆ·è‡ªå·±å»ç†è§£å’Œè®°å¿†æ˜¯ä¸€ä¸ªè¿‡åˆ†çš„è¦æ±‚ã€‚è§£å†³æ–¹æ¡ˆæ˜¯æ„å»ºä¸€æ¬¡â€”â€”å°†æ“ä½œçš„é€»è¾‘å’Œé¡ºåºè®°å½•ä¸‹æ¥å¹¶æ„å»ºä¸€æ¬¡â€”â€”ç„¶åå°±ä¸å¿…å†æ„å»ºä¸€æ¬¡äº†ã€‚

æ“ä½œé¡ºåºå¤±è´¥ç¤ºä¾‹:ä¸‹é¢çš„æŠ˜çº¿å›¾æ˜¾ç¤ºï¼Œå¦‚æœæ‚¨å¯¹å·²ç»å‘å‰å¡«å……çš„ä»·æ ¼åºåˆ—è®¡ç®—ç§»åŠ¨å¹³å‡ï¼Œé‚£ä¹ˆæ‚¨çš„ç»“æœå°†ä¼šæ»åã€‚æ»åçš„ä¿¡æ¯æ˜¯ä¸ç†æƒ³çš„ã€‚å¯¹äºè¿™äº›äº‰è®ºä¸ä¼‘çš„ä»»åŠ¡ï¼Œæ­£ç¡®çš„æ“ä½œé¡ºåºæ˜¯åœ¨è·¨æ—¥æœŸå±•å¼€ç³»åˆ—ä¹‹å‰è®¡ç®—ç§»åŠ¨å¹³å‡å€¼ï¼Œåˆå¹¶åˆ°ä¸»æ•°æ®é›†ï¼Œç„¶åå‘å‰å¡«å……ã€‚

![](img/8c60f55da13ced10327238d6f404a266.png)

ğŸ“¸ç”±[æˆ‘](https://www.linkedin.com/in/dylancunningham/)

# 3.ä»‹ç» Python æ•°æ®åº“æŠ½è±¡

ä¸‹é¢çš„æ•°æ®åº“æŠ½è±¡æ˜¯ä»¥ç”Ÿäº§å°±ç»ªçš„æ–¹å¼åˆå¹¶ã€è½¬æ¢å’Œåˆå¹¶æ•°æ®çš„å¼ºå¤§è€Œå¥å£®çš„æ–¹æ³•ã€‚å®ƒæ˜¯ç”Ÿäº§ç®¡é“çš„ç¬¬ä¸€æ­¥(è§ä¸Šå›¾)ã€‚äº‹å®ä¸Šï¼Œæ‚¨å¯èƒ½ä¼šä»¥æŸç§æ–¹å¼åˆ›æ–°å’Œåˆå¹¶ scikit-learn ç®¡é“åŠŸèƒ½ã€‚ä¸€ç§å¯èƒ½æ˜¯åˆ›å»ºä¸€ä¸ªåä¸º MyPipeline çš„æ–°ç±»ï¼Œç¡®ä¿ç»§æ‰¿æ‚¨çš„æ•°æ®åº“ç±»ã€‚ç„¶åï¼Œæ‚¨çš„æœåŠ¡ã€lambda æˆ–è„šæœ¬å¯ä»¥ä½¿ç”¨æ‚¨éœ€è¦çš„æ‰€æœ‰åŠŸèƒ½æ¥è°ƒç”¨ MyPipelineã€‚

ä½ ä¼šæ³¨æ„åˆ°æˆ‘æ²¡æœ‰ä¸ºä½ åšæ‰€æœ‰çš„å·¥ä½œã€‚è¿™ç§æŠ½è±¡ 25%é›†ä¸­åœ¨é‡‘èé¢†åŸŸã€‚å”¯ä¸€çš„æ•°æ®æºæ˜¯[ç¾Šé©¼](https://alpaca.markets/)(æˆ‘åªå±•ç¤ºæˆ‘çš„ç±»å¦‚ä½•ä¸ç¾Šé©¼äº¤äº’ï¼Œå› ä¸ºä»–ä»¬çš„ API å¾ˆç®€å•ï¼Œæˆ‘çš„ç›®çš„æ˜¯æ•™ä½ å¦‚ä½•é’“é±¼ï¼Œè€Œä¸æ˜¯ç»™ä½ ä¸€ä¸ªè£…æ»¡é±¼çš„æ•°æ®åº“)ã€‚ä½ å¯èƒ½æƒ³è¦/éœ€è¦æ›´å¤šçš„æ•°æ®æ¥æºã€‚æ­¤å¤–ï¼Œæˆ‘çš„ä»£ç å‡è®¾è¢«äº‰è®ºçš„æ•°æ®æ˜¯æ—¶é—´åºåˆ—æ•°æ®ã€‚å…¶ä½™ 75%çš„ä»£ç é€šå¸¸å·²ç»å‡†å¤‡å¥½ä¾›æ‚¨å¤åˆ¶ã€ç²˜è´´å’Œå¼€ç®±å³ç”¨ã€‚æˆ‘å»ºè®®æ‚¨æ ¹æ®è‡ªå·±çš„éœ€è¦ä¿®æ”¹è¿™æ®µä»£ç ã€‚

# 4.å¦‚ä½•

åœ¨æˆ‘ä»¬è¿›å…¥æ‰€æœ‰ä»£ç ä¹‹å‰ï¼Œæˆ‘æƒ³å‘æ‚¨å±•ç¤ºä¸€ä¸ªç”¨æˆ·æˆ–ç³»ç»Ÿå¦‚ä½•ä¸è¿™ä¸ªæ•°æ®åº“ç±»äº¤äº’ã€‚

```
dct = # shown later

database = Database(dct).build()
```

ç®€å•å§ï¼Ÿ

> *è¯·æ³¨æ„ï¼Œæˆ‘å°†å¸¦æ‚¨å›é¡¾æ•°æ®åº“è¯¾ç¨‹ã€‚ä¾‹å¦‚ï¼Œåœ¨æˆ‘è§£é‡Š*æ„å»º*æ–¹æ³•ä¹‹å‰ï¼Œæˆ‘è§£é‡Šä¸€ä¸‹*ç‰¹æ€§*å’Œ*ç›®æ ‡*æ–¹æ³•ï¼Œå½“*æ„å»º*æ–¹æ³•ä½¿ç”¨*ç‰¹æ€§*å’Œ*ç›®æ ‡*æ–¹æ³•æ—¶ã€‚*

## åˆå§‹åŒ–

***é¦–å…ˆ*** ï¼Œæˆ‘ä»¬åˆ›å»ºè‡ªå·±çš„ç±»å¯¹è±¡ï¼Œå¹¶ä¸ºç”¨æˆ·æä¾›ä¸€ç§ä¸æˆ‘ä»¬çš„æŠ½è±¡è½»æ¾äº¤äº’çš„æ–¹å¼:é€šè¿‡ *__init__* æ–¹æ³•ã€‚

```
class Database:
    final_dataset = None
    data_cache_ = {
        'alpaca': {},
    }

    def __init__(self, dct: dict, jobs: int=1):
        *"""
        Initialize

        :param dct: user parameters
        :param jobs: number of processes
        """* self.dct = dct
        self.jobs = jobs
        self.config = dct

        self.date_dataset = pd.DataFrame(
            index=pd.date_range(
                start=self.config.get(
                    'globals', {}).setdefault(
                    'start_date', '2010-01-01'),
                end=self.config.get(
                    'globals').setdefault(
                    'end_date', str(datetime.now().date() \
                                    - timedelta(days=252 / 4))),
                name='Date'))

    def cache_data(self, source: str, key: str, json_data: dict):
        *"""
        Cache unique raw data

        :param source: data source (e.g., alpaca)
        :param key: unique identifier of raw data
        :param json_data: response from data request
        """* _ = self.data_cache_.get(source).setdefault(key, json_data)
```

è¿™é‡Œï¼Œæˆ‘ä»¬å¸Œæœ›ç”¨æˆ·ä¼ å…¥ä¸€ä¸ªå­—å…¸(å¦‚æœéœ€è¦ï¼Œæ‚¨å¯ä»¥æ„å»ºè‡ªå·±çš„ç±»ï¼Œå…è®¸ç”¨æˆ·ä»¥å­—ç¬¦ä¸²å½¢å¼æŒ‡å®šå­˜å‚¨ json æ–‡ä»¶çš„æ–‡ä»¶è·¯å¾„),æŒ‡å®šæ‰€éœ€æ•°æ®çš„ä½ç½®ã€å¦‚ä½•è·å–æ•°æ®ã€åº”ç”¨ä»€ä¹ˆè½¬æ¢ã€ç”¨ä»€ä¹ˆå‘½åæ•°æ®ç­‰ã€‚è¿™æ˜¯ç”¨æˆ·éœ€è¦çš„ä¸€åˆ‡ã€‚

åœ¨æˆ‘ä»¬äº†è§£ç”¨æˆ·è¯å…¸çš„å¤–è§‚ä¹‹å‰ï¼Œè¿™é‡Œæœ‰ä¸€äº›åç»­è¦ç‚¹:

1.  æ•°æ®ç¼“å­˜:ç”±äºæˆ‘ä»¬ä¸ä¾èµ–äºæ•°æ®å­˜å‚¨ï¼Œå¦‚æœæˆ‘ä»¬è¦æŸ¥è¯¢æ•°æ®å¹¶å¯¹ç›¸åŒçš„æ•°æ®åº”ç”¨ä¸åŒçš„æ“ä½œï¼Œé‚£ä¹ˆæˆ‘ä»¬å¸Œæœ›ç¼“å­˜åŸå§‹æ•°æ®ï¼Œè¿™æ ·æˆ‘ä»¬å°±ä¸ä¼šå¤šæ¬¡æŸ¥è¯¢ç›¸åŒçš„æ•°æ®ã€‚ç¼“å­˜åŸå§‹æ•°æ®å°†åŠ å¿«ä½ çš„å·¥ä½œã€‚
2.  å¤šå¤„ç†å¼•æ“:ç”¨æˆ·å¯ä»¥æŒ‡å®šè¿è¡Œä½œä¸šçš„ä½œä¸šæˆ–è¿›ç¨‹çš„æ•°é‡ã€‚ä½ æ‰€éœ€è¦çš„æ˜¯ä¸€ä¸ªå¤šé‡å¤„ç†å¼•æ“ã€‚(å¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äºå¦‚ä½•è®¾ç½®ä½ çš„å¼•æ“çš„çŸ¥è¯†ï¼Œæˆ‘å°†å¾ˆå¿«å†™ä¸€ç¯‡å…³äºé©¬ç§‘æ–¯Â·æ´›ä½©å…¹Â·å¾·Â·æ™®æ‹‰å¤šåœ¨ä»–çš„ä¸€æœ¬ä¹¦ä¸­è°ˆåˆ°çš„å¼•æ“çš„æ–‡ç« ï¼Œ[è¿™é‡Œ](https://www.amazon.com/Advances-Financial-Machine-Learning-Marcos/dp/1119482089)ã€‚)
3.  æ ·æœ¬å¤–(OOS)æ•°æ®:æˆ‘å†™è¿™ä¸ªç±»çš„æ–¹å¼æœ‰ä¸€äº›ç»†å¾®å·®åˆ«ã€‚ä¾‹å¦‚ï¼Œæˆ‘ç”¨é‡‘èæœºå™¨å­¦ä¹ çš„è§†è§’å†™äº†è¿™ä¸ªç±»ã€‚åœ¨é‡‘èæœºå™¨å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬çš„æ•°æ®ä¸€èˆ¬æ˜¯æ—¶é—´/ä»·æ ¼åºåˆ—æ•°æ®ã€‚æ‰€ä»¥ï¼Œæˆ‘æŠŠæœ€åçš„ 252/4=63 å¤©ç•™ä½œçº¸ä¸Šäº¤æ˜“ã€‚è¯¥è®ºæ–‡æ•°æ®é›†è¢«è®¤ä¸ºæ˜¯æ ·æœ¬å¤–çš„ã€‚(æœ€åï¼Œæˆ‘å¾—åˆ°äº†è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•å’Œ OOS æ•°æ®é›†ã€‚)

## ç”¨æˆ·äº¤äº’

***ç¬¬äºŒä¸ª*** ï¼Œè¿™ä¸ªç±»æä¾›äº†è¶³å¤Ÿæœ‰ç”¨çš„ç»“æ„ï¼Œè€Œä¸”ä¹Ÿå¾ˆçµæ´»ã€‚åœ¨æˆ‘çš„ä¾‹å­ä¸­ï¼Œç”¨æˆ·äº¤äº’éå¸¸å†—é•¿ã€‚æˆ‘å¸Œæœ›ç”¨æˆ·äº¤äº’æ¸…æ™°æ— è¯¯ã€‚æˆ‘è¿˜å¸Œæœ›ç”¨æˆ·èƒ½å¤Ÿè½»æ¾åœ°æŠ¬èµ·å’Œç§»åŠ¨ã€‚ä¸ºæ­¤ï¼Œæ•°æ®åº“ç±»éœ€è¦ä¸€ä¸ªåŒ…å«ä¸åŒçº§åˆ«çš„*é”®:å€¼*å¯¹çš„å­—å…¸ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚

ç¬¬ä¸€çº§é”®æ˜¯*å…¨å±€*ã€*ç›®æ ‡*å’Œ*ç‰¹å¾*ã€‚Globals ç”¨äºæŒ‡å®šæ•´ä¸ªæ•°æ®é›†çº§åˆ«çš„å‚æ•°ã€‚Target ç”¨äºæŒ‡å®šåº”è¯¥ä¸ºç›®æ ‡ä½¿ç”¨ä»€ä¹ˆæ•°æ®ï¼Œä»¥åŠåº”è¯¥åº”ç”¨ä»€ä¹ˆæ ‡è®°æŠ€æœ¯(å³è½¬æ¢)ã€‚ç‰¹å¾ç”¨äºæŒ‡å®šå“ªäº›æ•°æ®åº”è¯¥ç”¨ä½œå»ºæ¨¡çš„ç‰¹å¾ã€‚

ç¬¬äºŒå±‚çš„*é”®:å€¼*å¯¹éœ€è¦å…³äºæ•°æ®æºã€å‚æ•°(kwargs)ã€ä»æºè¿”å›çš„æ•°æ®çš„åç§°ã€è¦åˆ é™¤çš„ç‰¹æ€§(ä¸éœ€è¦ï¼Œå–å†³äºæºè¾“å‡º)ä»¥åŠæ•°æ®ç±»å‹çš„ä¿¡æ¯ã€‚

ç¬¬ä¸‰å±‚çš„ *key: value* å¯¹å…è®¸å¯¹åº•å±‚æ•°æ®è¿›è¡Œè½¬æ¢ã€‚è¿™äº›å˜æ¢ä»¥ä¸€ç§æ˜“äºç†è§£çš„æ–¹å¼é€ä¸€åº”ç”¨äºæ¯ä¸ªå•ç‹¬çš„ç‰¹å¾ã€‚

```
dct = {
    "globals": {
        "start_date": "2010-01-01"
    },
    "target": {
        "source": "alpaca",
        "kwargs": {
            "timeframe": "day",
            "symbols": "AAPL",
            "limit": "0",
            "start": "2000-01-01"},
        "clean": {
            "names": [
                "open",
                "high",
                "low",
                "target",
                "volume"
            ],
            "drop": [
                "open",
                "high",
                "low",
                "volume"
            ],
            "types": [
                "float"
            ]
        },
        "transformations": [
            {
                "function": "trend_scanning_label",
                "kwargs": {
                    "name": "target"
                }
            }
        ]
    },
    "features": [
        {
            "source": "alpaca",
            "kwargs": {
                "timeframe": "day",
                "symbols": "AAPL",
                "limit": "0",
                "start": "2000-01-01"
            },
            "clean": {
                "names": [
                    "open",
                    "high",
                    "low",
                    "close",
                    "volume"
                ],
                "drop": [
                    "open",
                    "high",
                    "low",
                    "volume"
                ],
                "types": [
                    "float"
                ],
            },
            "transformations": [
                {
                    "function": "rsi",
                    "kwargs": {
                        "days": 14
                    }
                }
            ]
        }
    ]
}
```

## è¦æ±‚

***ç¬¬ä¸‰ä¸ª*** ï¼Œbelow æ–¹æ³•è¯·æ±‚æ•°æ®ï¼Œä¸è€ƒè™‘ APIã€‚è¿™ä¸ªæ–¹æ³•å°† urlã€headers å’Œ kwargs ä½œä¸ºå‚æ•°ã€‚æ•°æ®ä»¥å­—å…¸çš„å½¢å¼è¿”å›ï¼Œç¨åè¿›è¡Œå¤„ç†ã€‚

```
@staticmethod
def request_data(base_url: str, headers: dict=None, **kwargs):
    *"""
    Request data through web api

    :param base_url: data source base url
    :param headers: headers to pass through requests
    :param kwargs: params to pass through requests
    """* if headers is None:
        response = requests.get(base_url, params=kwargs)
    else:
        response = requests.get(
            base_url, params=kwargs, headers=headers)
    return response.json()
```

## å‡€åŒ–

***ç¬¬å››ä¸ª*** ï¼Œä¸‹é¢çš„æ–¹æ³•æ ¹æ®ä¸Šé¢ç”¨æˆ·å­—å…¸ä¸­çš„ clean é”®æ¸…æ´—æ•°æ®é›†ã€‚ä¼ é€’ç»™è¯¥æ–¹æ³•çš„æ•°æ®å°†æ˜¯æ¥è‡ª request_data æ–¹æ³•(å¦‚ä¸Š)çš„ç»“æœï¼Œä½œä¸º pandas æ•°æ®å¸§ã€‚ä¹‹æ‰€ä»¥æœ‰å‚æ•° date_int_sï¼Œæ˜¯å› ä¸ºæœ‰äº›æ—¥æœŸæ—¶é—´æ•°æ®æœ‰ç§’ï¼Œæœ‰æ—¶æ²¡æœ‰(é»˜è®¤å€¼è®¾ç½®ä¸º False)ã€‚

ç‰¹å¾è¢«å‘½åã€‚åˆ—è¢«åˆ é™¤ã€‚æ•°æ®ç±»å‹å·²è®¾ç½®ã€‚ç´¢å¼•å·²æ’åºã€‚

```
@staticmethod
def _clean_dataset(
        dataset: pd.DataFrame, dct: dict, date_int_s: bool=False):
    *"""
    Clean dataset

    :param dataset: dataframe needing cleaned
    :param dct: clean dict with names, drop, and types keys
    :param date_int_s: make True if date is an integer with seconds
    """* dataset.columns = ['DateTime'] + dct.get('clean').get('names')
    dataset.drop(
        dct.get('clean').get('drop', []), axis=1, inplace=True)
    if date_int_s:
        dataset = dataset.assign(
            DateTime=pd.to_datetime(
                dataset.DateTime, unit='s').dt.date)
    else:
        dataset = dataset.assign(
            DateTime=pd.to_datetime(dataset.DateTime).dt.date)
    dataset.set_index('DateTime', inplace=True)
    names = [name for name in dct.get('clean').get(
        'names') if name not in dct.get('clean').get('drop', [])]
    dataset = dataset.astype({
        name: dtype for name, dtype in zip(names, dct.get(
            'clean').get('types'))})
    return dataset.sort_index(ascending=True)
```

## æ•°æ®æº

***ç¬¬äº”ä¸ª*** ï¼Œæˆ‘ä»¬éœ€è¦æ•°æ®æ¥æºã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä½¿ç”¨äº†ä¸€ä¸ªæºï¼ŒAlpacaï¼Œä½†æ˜¯ï¼Œæ­£å¦‚æˆ‘å‰é¢æåˆ°çš„ï¼Œä½ çš„æºæ–¹æ³•å¯ä»¥æ˜¯ä»»ä½•ç§ç±»çš„:Web APIsï¼Œç½‘é¡µï¼ŒS3ï¼ŒSQL Serverï¼ŒCSVï¼Œä½ èƒ½æƒ³åˆ°çš„ã€‚

è®©æˆ‘ä»¬ä¸è¦è§¦åŠè¿™äº›æ–¹æ³•çš„æ‰€æœ‰ç»†èŠ‚ï¼Œä½†è¿™é‡Œæœ‰ä¸€äº›è¦ç‚¹:

1.  å¤šé‡å¤„ç†:æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥ä¸å¤šé‡å¤„ç†å¼•æ“äº¤äº’ã€‚
2.  ç¬¬ä¸‰æ–¹è½¯ä»¶åŒ…:æˆ‘ä¸å–œæ¬¢ä¾èµ–ç¬¬ä¸‰æ–¹è½¯ä»¶åŒ…ï¼Œé™¤éå®ƒä»¬éå¸¸æœ‰ç”¨ã€‚numpy ã€[ç†ŠçŒ«](https://pandas.pydata.org/)å’Œ [scikit-learn](https://scikit-learn.org/stable/) æ˜¯éå¸¸æœ‰ç”¨çš„ç¬¬ä¸‰æ–¹è½¯ä»¶åŒ…çš„ä¾‹å­ã€‚æœ‰é’ˆå¯¹ç¾Šé©¼çš„ API çš„åŒ…ï¼Œä½†æ˜¯ä»–ä»¬çš„ web API è¶³å¤Ÿç®€å•ã€‚
3.  æ­¥éª¤:ä½¿æˆä¸ºæŸ¥è¯¢å’Œç¼“å­˜çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œè®¾ç½®å¤´å’Œ kwargsï¼Œä»æ•°æ®è¯·æ±‚ä¸­æŸ¥è¯¢å¹¶è·å–å­—å…¸ï¼Œç¼“å­˜ä»¥å¤‡å°†æ¥ä½¿ç”¨ï¼Œä½¿ç”¨å¤šé‡å¤„ç†åœ¨æ•°æ®å¸§ä¸­å¿«é€Ÿåˆ›å»ºæ•°æ®è¡Œï¼Œç„¶åæ¸…ç†æ•°æ®å¸§ã€‚

```
@staticmethod
def _mp_alpaca(molecule):
    out = []
    for tickerset in molecule:
        for bar in tickerset[list(tickerset.keys())[0]]:
            out.append([bar.get('t'), bar.get('o'), bar.get('h'),
                        bar.get('l'), bar.get('c'), bar.get('v')])
    return out

def alpaca(self, dct: dict):
    *"""
    Get data using Alpaca's web api

    :param dct: dict of config source info
    """* key = str(sorted([(key, value) for key, value in dct.get(
        'kwargs').items()]))
    headers = {
        'APCA-API-KEY-ID': os.environ['APCA_API_KEY_ID'],
        'APCA-API-SECRET-KEY': os.environ['APCA_API_SECRET_KEY']
    }
    timeframe = dct.get('kwargs').get('timeframe')
    kwargs = {key: value for key, value in dct.get(
        'kwargs').items() if key != 'timeframe'}

    if self.data_cache_.get('alpaca').get(key, False):
        json_data = self.data_cache_.get('alpaca').get(key)
    else:
        base_url = 'https://data.alpaca.markets'
        json_data = self.request_data(
            base_url=F'{base_url}/v1/bars/{timeframe}',
            headers=headers, **kwargs)
        self.cache_data(
            source='alpaca', key=key, json_data=json_data)

    tickersets = [{ticker: barsets}
                  for ticker, barsets in json_data.items()]
    out = mp_pandas_obj(
        func=self._mp_alpaca, pd_obj=('molecule', tickersets),
        num_threads=1)
    dataset = pd.DataFrame.from_records(sum(out, []))
    dataset = self._clean_dataset(
        dataset=dataset, dct=dct, date_int_s=True)
    return dataset
```

æ³¨æ„:ç¡®ä¿æ‚¨çš„ç¯å¢ƒå˜é‡ä¸­æœ‰ APCA API å¯†é’¥ ID å’Œ APCA API å¯†é’¥ã€‚æ‚¨å¯ä»¥ä»æ‚¨çš„å¸æˆ·ä¸­è·å–å®ƒä»¬ã€‚

## è½¬æ¢

***ç¬¬å…­ä¸ª*** ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ–¹æ³•æ¥è½¬æ¢æˆ‘ä»¬æ¥æºçš„æ•°æ®ï¼›æˆ‘ä»¬å¸Œæœ›ä»¥æŸç§æ–¹å¼æ„å»ºå®ƒï¼Œä»¥ä¾¿ä»ç”¨æˆ·é‚£é‡ŒæŠ½è±¡å‡ºä»£ç å’Œäº‰è®ºä»»åŠ¡çš„åºåˆ—ï¼Œä½¿å®ƒçµæ´»ï¼Œå¹¶ä½¿å®ƒå¥å£®ã€‚

ä¸‹é¢çš„è½¬æ¢æ–¹æ³•é‡‡ç”¨ä¸€ä¸ªæ•°æ®å¸§å’Œä¸€ä¸ªè¦åº”ç”¨çš„è½¬æ¢åˆ—è¡¨ã€‚è¾“å‡ºæ˜¯ä¸€ä¸ªè½¬æ¢åçš„è¦ç´ ï¼Œè¯¥è¦ç´ è¢«åˆå¹¶å¹¶æ­£å‘å¡«å……åˆ°æ—¥æœŸæ—¥æœŸé›†ä¸­ã€‚å¦‚ä¸Šæ‰€è¿°ï¼Œè¿™ä¸ªé¡ºåºæ˜¯å…³é”®ã€‚ç¨åï¼Œæ‚¨å°†çœ‹åˆ°è¿™ä¸ªæ–°è½¬æ¢çš„ç‰¹æ€§æ˜¯å¦‚ä½•åˆå¹¶åˆ°æˆ‘ä»¬çš„ç›®æ ‡ç³»åˆ—ä¸­çš„ã€‚

```
def transform(
        self, dataset: pd.DataFrame, transformation_lst: list):
    *"""
    Apply transformations to dataset

    :param dataset: dataframe needing transformed
    :param transformation_lst: list of dicts of transformations
    """* for transformation_dct in transformation_lst:
        if '.' in transformation_dct.get('function'):
            function = globals()[transformation_dct.get(
                'function').split('.')[0]]
            for notation_part in transformation_dct.get(
                    'function').split('.')[1:]:
                function = getattr(function, notation_part)
        else:
            function = globals()[
                transformation_dct.get('function')]
        if transformation_dct.get('kwargs', False):
            if transformation_dct.get('kwargs').get(
                    'other', False) and \
                    isinstance(transformation_dct.get('kwargs').get(
                        'other', 1), dict):
                sub_query_dct = transformation_dct.get(
                    'kwargs').get('other')
                dataset0 = self._get_data(dct=sub_query_dct)
                if sub_query_dct.get('transformations', False):
                    dataset0 = self.transform(
                        dataset=dataset0,
                        transformation_lst=sub_query_dct.get(
                            'transformations'))
                    dataset0 = self.date_dataset.copy().merge(
                        dataset0, how='left', left_index=True,
                        right_index=True).ffill()
                else:
                    dataset0 = self.date_dataset.copy().merge(
                        dataset0, how='left', left_index=True,
                        right_index=True).ffill()
                dataset = self.date_dataset.copy().merge(
                    dataset, how='left', left_index=True,
                    right_index=True).ffill()
                dataset = function(dataset, dataset0)
                continue
            else:
                dataset = function(
                    dataset, **transformation_dct.get('kwargs'))
        else:
            dataset = function(dataset)
        dataset = self.date_dataset.copy().merge(
            dataset, how='left', left_index=True, right_index=True)
    return dataset
```

## ç›®æ ‡

**ç¬¬ä¸ƒä¸ª**ï¼Œä¸‹é¢çš„å‡½æ•°é‡‡ç”¨ç¬¬ä¸€çº§çš„*é”®:å€¼*å¯¹ï¼Œç§°ä¸ºç›®æ ‡ï¼Œè¯·æ±‚æ•°æ®å¹¶è½¬æ¢å®ƒï¼Œæˆ–è€…ç®€å•åœ°å°†æ•°æ®åˆå¹¶åˆ°ä¸€ä¸ªæ—¥æœŸæ•°æ®é›†ã€‚

```
def target(self, transform: bool=True):
    *"""
    Make target dataset* *:param transform: False if using self.target standalone
    """* target_dct = self.config.get('target')
    dataset = getattr(self, target_dct.get('source'))(target_dct)
    if transform and target_dct.get('transformations', False):
        dataset = self.transform(
            dataset=dataset, 
            transformation_lst=target_dct.get('transformations'))
    else:
        dataset = self.date_dataset.copy().merge(
            dataset, how='left', left_index=True, right_index=True)
    return dataset
```

## æ£€ç´¢æ•°æ®

**ç¬¬å…«ä¸ª**ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ£€ç´¢æ•°æ®çš„å‡½æ•°ã€‚

```
def _get_data(self, dct: dict):
    function = getattr(self, dct.get('source'))
    dataset = function(dct)
    return dataset
```

## ç‰¹å¾

**ç¬¬ä¹ä¸ª**ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ç§å¿«é€Ÿè·å–ç‰¹æ€§å¹¶è½¬æ¢å®ƒä»¬çš„æ–¹æ³•:ä¸‹é¢çš„æ–¹æ³•ã€‚

ç±»ä¼¼äºæˆ‘ä»¬å¦‚ä½•åˆ›å»ºä¸€ä¸ªä¸æˆ‘ä»¬çš„å¤šå¤„ç†å¼•æ“äº¤äº’çš„æ–¹æ³•ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªç”¨äºå¤šå¤„ç†ç‰¹å¾çš„æ£€ç´¢å’Œè½¬æ¢çš„æ–¹æ³•ã€‚ä¸€æ—¦å®Œæˆï¼Œæœ€ç»ˆçš„ç»“æœæ˜¯ä¸€ä¸ªæ•°æ®é›†ï¼Œå°†æ‰€æœ‰æ­£ç¡®çš„äº‰è®ºå’Œè½¬æ¢æŠ€æœ¯åº”ç”¨-åœ¨ä»–ä»¬é€‚å½“çš„é¡ºåºã€‚

```
def _mp_features(self, molecule):
    out = []
    for feature_dct in molecule:
        dataset = self._get_data(dct=feature_dct)
        if feature_dct.get('transformations', False):
            dataset = self.transform(
                dataset=dataset,
                transformation_lst=feature_dct.get(
                    'transformations'))
        else:
            dataset = self.date_dataset.copy().merge(
                dataset, how='left', left_index=True, 
                right_index=True)
        out.append(dataset)
    return out@property
def features(self):
    *"""
    Makes features dataset
    """* if self.config.get('features', False):
        features_lst = self.config.get('features')
        try:
            out = mp_pandas_obj(
                func=self._mp_features,
                pd_obj=('molecule', features_lst),
                num_threads=self.jobs)
        except AssertionError:
            out = mp_pandas_obj(
                func=self._mp_features,
                pd_obj=('molecule', features_lst), num_threads=1)
        dataset = pd.concat(sum(out, []), axis=1)
        dataset = self.date_dataset.copy().merge(
            dataset, how='left', left_index=True, right_index=True)
    else:
        raise Exception('you need features in your dct file')
    return dataset
```

## å»ºè®¾

ç¬¬åä¸ªï¼Œæœ€åæˆ‘ä»¬æ¥çœ‹æœ€é‡è¦çš„æ–¹æ³•:è®©å®ƒä»¬éƒ½æ´»èµ·æ¥çš„æ–¹æ³•ã€‚è¿™æ˜¯ç”¨æˆ·è°ƒç”¨æ¥å¯åŠ¨æ„å»ºè¿‡ç¨‹çš„æ–¹æ³•ã€‚

è¯¥æ–¹æ³•ç®€å•åœ°åˆ›å»ºäº† final_datasetï¼Œè¯¥æ•°æ®é›†åŒ…æ‹¬è½¬æ¢åçš„ç›®æ ‡å’Œè½¬æ¢åçš„ç‰¹å¾ã€‚å¦‚æœç”¨æˆ·åœ¨å…¶å­—å…¸ä¸­æ²¡æœ‰æŒ‡å®šç›®æ ‡ï¼Œåˆ™åªæœ‰å˜æ¢åçš„è¦ç´ å°†æ„æˆ final_datasetã€‚

```
def build(self):
    *"""
    Build dataset
    """* if self.config.get('target', False) and self.config.get(
            'target', False):
        self.final_dataset = self.target.copy(), how='left',
            left_index=True, right_index=True).merge(
            self.features.copy(), how='left', left_index=True,
            right_index=True)
        self.final_dataset = self.final_dataset.ffill().loc[
            self.investment.dropna().index]
    # only make features dataset
    else:
        self.final_dataset = self.features.ffill()
    return self
```

## ç»“è®º

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºå¹¶è¯æ˜äº†äº‰è®ºä»»åŠ¡æœ‰ä¸€ä¸ªé€‚å½“çš„æ“ä½œé¡ºåºã€‚æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªç±»æ¥æŠ½è±¡ç”¨æˆ·è‡ªå·±åº”ç”¨è¿™äº›æ“ä½œçš„éœ€æ±‚ï¼›æˆ‘ä»¬ä»¥ä¸€ç§æ–°é¢–çš„æ–¹å¼åšåˆ°äº†è¿™ä¸€ç‚¹ã€‚

æˆ‘å¸Œæœ›ä½ å–œæ¬¢ï¼Œæˆ‘ä¼šå–œæ¬¢ä½ çš„åé¦ˆ/æŒ‘æˆ˜ã€‚

## åç»­æ­¥éª¤

1.  é”™è¯¯å¤„ç†:å¦‚æœä½ æƒ³åŠ å¼ºç”¨æˆ·é€šè¿‡ä½ çš„æŠ½è±¡æ‰€ä¼ é€’çš„å­—å…¸çš„ç»“æ„ï¼Œé‚£ä¹ˆä½ å°†æƒ³å¢åŠ å¥½çš„é”™è¯¯å¤„ç†å’Œå¯è§£é‡Šçš„é”™è¯¯æ¶ˆæ¯æ¥å¸®åŠ©ä½ çš„ç”¨æˆ·ã€‚æœ‰è®¸å¤šé”™è¯¯å¤„ç†å°†ä½¿ç”¨æˆ·çš„ç”Ÿæ´»æ›´å®¹æ˜“ã€‚
2.  ä½ åº”è¯¥æœ‰ä¸€ä¸ª[æŠ½è±¡](https://docs.python.org/3/library/abc.html)ç±»æ¥æ‰§è¡ŒæŸäº›æ–¹æ³•ã€‚æˆ‘è®¤ä¸ºè¿™ä¸ªæ•°æ®åº“ç±»æ˜¯ä¸€ä¸ªâ€œåŸºç±»â€ï¼Œå› ä¸ºå…¶ä»–æŠ½è±¡å¯ä»¥å¾ˆå®¹æ˜“åœ°ç»§æ‰¿è¿™ä¸ªç±»ã€‚ä¾‹å¦‚ï¼Œåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ç®€è¦è§£é‡Šäº†ä¸€ç§å°†æ•°æ®åº“ç±»çš„åŠŸèƒ½æ‰©å±•åˆ° MyPipeline ç±»çš„æ–¹æ³•ã€‚

## æŠŠæ‰€æœ‰çš„æ”¾åœ¨ä¸€èµ·

## å‚è€ƒ

[1] M. Lopez de Pradoï¼Œé‡‘èæœºå™¨å­¦ä¹ çš„è¿›å±•(2018)ï¼Œå¨åˆ©