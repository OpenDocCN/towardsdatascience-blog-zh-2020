<html>
<head>
<title>Hardware for Deep Learning: Know Your Options</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习的硬件:了解你的选择</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-hardware-know-your-options-9e95026b5d5e?source=collection_archive---------1-----------------------#2020-03-02">https://towardsdatascience.com/deep-learning-hardware-know-your-options-9e95026b5d5e?source=collection_archive---------1-----------------------#2020-03-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="4c5d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在部署神经网络时，GPU(图形处理单元)之外还有<strong class="js iu">选项，即<strong class="js iu"> FPGA </strong>(现场可编程门阵列)。在深入研究FPGAs及其实现之前，最好先了解一下GPU架构，以及为什么GPU是神经网络的主要组成部分。</strong></p><p id="ebec" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Tensorflow等流行的库使用CUDA(计算统一设备架构)在GPU上处理数据，利用它们的<strong class="js iu">并行计算能力</strong>。这项工作被称为GPGPU(通用GPU)编程。它已经适应了需要至少数千次算术运算的深度学习模型。</p><p id="4396" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如下所示，深度卷积神经网络要求滤波器在像素区域上滑动，同时在每次迭代时输出加权和。对于每一层，这一过程重复数千次，不同的过滤器大小相同。从逻辑上讲，<strong class="js iu">深度模型计算量变大</strong>，GPU派上了用场。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/9307c6806fc83587eb69139408ee802e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S1VkwFVyezhgAyhmMKwhzA.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:Hinton G.E .等人通过<a class="ae le" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" rel="noopener ugc nofollow" target="_blank">研究论文</a>；第一层包含253，440个权重，因此至少有那么多计算</p></figure><p id="9499" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Tensorflow可以构建在CUDA的基础上，<strong class="js iu">这使得最终用户无需实施并行代码和理解其芯片的架构</strong>。它的便利性和高度优化使它非常适合广泛使用。</p><p id="3463" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">FPGAs早期没有提供这样一个方便的解决方案，使用它们需要对硬件如何工作有深入的理解。但是最近的进展使它们变得更容易接近，以后还会有更多的进展。</p><h1 id="52a6" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">概观</h1><p id="3f47" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">本文的内容假设对不同的硬件模型如何工作知之甚少或一无所知。它包括以下内容:</p><ul class=""><li id="d058" class="mi mj it js b jt ju jx jy kb mk kf ml kj mm kn mn mo mp mq bi translated">GPU、CPU和CUDA</li><li id="86b9" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">FPGAs的优势与设计</li><li id="0fa1" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">HDL作为一种FPGA部署方法</li><li id="b45e" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">HLS作为一种FPGA部署方法</li><li id="d4d0" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">使用LeFlow的FPGA部署</li><li id="6192" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">LeFlow的优化特性</li></ul><h1 id="aeb0" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">为什么GPU有时候比CPU好？</h1><p id="ec90" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated"><strong class="js iu">CPU</strong>(中央处理器)<strong class="js iu">设计用于串行操作</strong>并支持高级逻辑。这反映在他们的设计中，包含<strong class="js iu">更少的内核</strong>和更多的高速缓存以快速获取复杂的指令。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/13d5a4933ccdc7659da5cd6d4551933c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/format:webp/1*89II2mpB6XFzjlk6YZo-7g.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">资料来源:Elkaduwe等人。via <a class="ae le" href="https://www.researchgate.net/publication/270222593_To_Use_or_Not_to_Use_Graphics_Processing_Units_for_Pattern_Matching_Algorithms" rel="noopener ugc nofollow" target="_blank">研究论文</a>；一个字母决定一切</p></figure><p id="4c39" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">GPU、</strong>拥有<strong class="js iu">数百个更小的内核</strong>用于简单计算，因此与CPU相比具有更高的吞吐量。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mx"><img src="../Images/2d765c4e02a0ad96e0f6aa975fdb5b0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sEdIXrj-QYVeL8sKXo0cWw.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:<a class="ae le" href="https://github.com/Ashwins9001/Cuda_Examples/blob/master/julia_set.cu" rel="noopener ugc nofollow" target="_blank">自我</a>；<strong class="bd my">内核&lt; &lt; &lt;网格，1 &gt; &gt; &gt; () </strong>符号表示并行进程运行的数量，等于变量网格的大小。运行名为<strong class="bd my">内核</strong>的函数。</p></figure><p id="fed5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">CUDA通过将GPU的众多内核抽象成块来访问它们。每个块包含多达512个可访问的线程，可能有65 535个块能够同时运行。每个线程执行一个短程序，问题是它可以与其他线程并行运行。<strong class="js iu"> Tensorflow </strong>利用这种模式来提高处理能力，通常<strong class="js iu">会同时运行数百到数千个线程</strong>。</p><p id="5d92" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要了解更多关于使用CUDA的信息，请访问Nvidia的开发者博客 或查阅《CUDA示例<a class="ae le" href="https://developer.nvidia.com/cuda-example" rel="noopener ugc nofollow" target="_blank"><em class="mz"/></a>》一书。</p><h1 id="2c52" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">神经网络硬件</h1><p id="730d" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">Tensorflow分为两个部分:库和运行时。</p><p id="ab72" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">库是计算图(神经网络)的创建，运行时是它在某个硬件平台上的执行。</p><p id="78dd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">首选平台是GPU，但也有一个替代方案:FPGAs。</p><h1 id="dcbd" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">为什么要用FPGAs？</h1><p id="c586" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">FPGAs可以产生具有数千个存储单元的电路来进行计算，因此它们的工作方式类似于CUDA中的GPU及其线程。FPGAs具有自适应架构，支持额外优化以提高吞吐量。因此，可能的计算量使FPGAs成为GPU的可行解决方案。</p><p id="e2d3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">相比之下，FPGAs功耗较低，最适合嵌入式应用。它们也是汽车ADAS(高级驾驶辅助系统)等安全关键操作的公认标准。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi na"><img src="../Images/1e51a23d43fc50477e3d67e8573c52c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7Ye7LB8QNu0xY4UNj2CrPA.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:福特汽车公司via <a class="ae le" href="https://commons.wikimedia.org/wiki/File:Collision_Warning_Brake_Support.jpg" rel="noopener ugc nofollow" target="_blank">维基媒体</a>(CC)；FPGAs安全关键任务的理想应用:碰撞报警系统</p></figure><p id="a0cc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">此外，FPGAs可以实现自定义数据类型，而GPU受到架构的限制。随着神经网络以多种方式转变并延伸到更多行业，FPGAs提供的自适应能力非常有用。</p><h1 id="5c4d" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">现在你一定想知道，什么是FPGAs？</h1><p id="d65c" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">FPGA(现场可编程门阵列)是一种可定制的硬件设备。它可以被认为是浮动逻辑门的<strong class="js iu">海洋。一个设计师走过来，用一种<strong class="js iu">硬件描述语言</strong> (HDL)，比如Verilog或VHDL，写下一个程序。该程序规定了连接方式以及如何使用数字元件实现连接。HDL的另一个词是<strong class="js iu"> RTL </strong>(寄存器传输级)语言。</strong></p><p id="3f63" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">FPGAs很容易被发现，找一个超大的Arduino。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/41286a6ebdcda431579de3dfd30a8200.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*vpha8pVU4fVtuzpSgueNJA.jpeg"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:保罗马蒂亚斯via <a class="ae le" href="https://commons.wikimedia.org/wiki/File:ALTERA_DE2_FPGA_Board.jpg" rel="noopener ugc nofollow" target="_blank">维基媒体</a>(CC)；altera DE2–115板，可使用的众多FPGAs之一</p></figure><p id="8849" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">开玩笑，它们有各种形状和大小。</p><p id="5c4b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用类似于编译器的软件，HDL被合成(找出使用什么门)，然后被路由(将部件连接在一起)以形成优化的数字电路。这些工具(HDL、综合、路由、时序分析、测试)都包含在一个软件套件中，有些包括Xilinx设计工具和Quartus Prime。</p><p id="db28" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">目前，模型使用GPU进行训练，但随后<strong class="js iu">部署在FPGA上进行实时处理</strong>。</p><h1 id="6461" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated"><strong class="ak">那我们为什么不用FPGAs来代替呢？</strong></h1><p id="23fd" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">对于FPGAs来说，棘手的部分是实现用Python等高级语言编写的ML框架。<strong class="js iu"> HDL本身并不是一个编程平台</strong>，它是用来定义硬件组件(如寄存器和计数器)的代码。一些HDL语言包括:Verilog，VHDL。</p><p id="88a0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下面显示的是用于创建串行位检测器的一些代码片段。</p><p id="9a09" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你不熟悉它，试着猜猜它是做什么的。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nc nd l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:Self</p></figure><p id="b91d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">完成了吗？即使你盯着它看一会儿，它也不明显。</p><p id="6123" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">大多数情况下，FSM(有限状态机)用于<strong class="js iu">将任务分解成具有输入相关转换的状态</strong>。所有这些都是在编程之前完成的，以确定每个时钟周期电路将如何工作。然后这个图，如下所示，被转换成HDL代码块。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ne"><img src="../Images/89e43421f9c531601075984d81fc49f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eUja2Iit4YjlZX2Jmh_tEw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:Maggyero via <a class="ae le" href="https://commons.wikimedia.org/wiki/File:Finite-state_machine_state-diagram.png" rel="noopener ugc nofollow" target="_blank">维基媒体</a>(CC)；可能的FSM图</p></figure><p id="b41b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">回到主题:主要的一点是，没有直接的翻译将Python中的一个循环转换成Verilog中的一束电线。</p><p id="631d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">考虑到设计的复杂性，很难对其进行进一步的优化调试。没有像CUDA中那样的抽象来简化过程，在CUDA中可以选择和修改线程。</p><h1 id="4312" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">那么我们应该坚持使用GPU吗？</h1><blockquote class="nf"><p id="868c" class="ng nh it bd ni nj nk nl nm nn no kn dk translated">不，FPGAs并非一无是处。</p></blockquote><p id="72cd" class="pw-post-body-paragraph jq jr it js b jt np jv jw jx nq jz ka kb nr kd ke kf ns kh ki kj nt kl km kn im bi translated">解决编程问题的一种方法是使用<strong class="js iu"> HLS </strong>(高级综合)工具，如<strong class="js iu"> LegUp </strong>来在Verilog中生成程序进行部署。HLS工具允许设计者<strong class="js iu">避免从头开始编写HDL</strong>，而是使用更加<strong class="js iu">直观的算法式</strong>编程语言<strong class="js iu"/>(C)。</p><p id="4d33" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">HLS工具<strong class="js iu">抽象出硬件级设计；</strong>类似于模型运行时CUDA如何自动设置并发块和线程。</p><p id="dcb4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">HLS工具需要<strong class="js iu"> C </strong>代码作为<strong class="js iu">输入</strong>，该输入将<strong class="js iu">映射</strong>到<strong class="js iu"> LLVM IR </strong>(中间表示)以供执行。这些工具用于将程序描述转换成硬件实现。</p><p id="6be9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">它们在FPGA设计中的作用如下所示。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nu"><img src="../Images/648a6bd3a144db0359303a6ec8fb492f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h7V319nk404WRu99VUDz2g.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:Greg S. via <a class="ae le" href="https://slideplayer.com/slide/8711464/" rel="noopener ugc nofollow" target="_blank">佛罗里达大学幻灯片</a>；<strong class="bd my"> HLS </strong>工具<strong class="bd my">产生HDL </strong>，允许<strong class="bd my">寄存器传输(RT)合成</strong>成数字电路，最终部署在FPGA上</p></figure><h1 id="10c3" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">关于LLVM IRs的更多信息</h1><p id="3b1f" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated"><strong class="js iu"> LLVM </strong>不是首字母缩写，是<strong class="js iu">构造</strong> <strong class="js iu">类汇编指令</strong> (IRs)的<strong class="js iu">库</strong>。这些程序对于HLS工具来说更容易处理，并可用于为FPGA创建可综合的代码。</p><p id="be50" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> IRs </strong>用于<strong class="js iu">以<strong class="js iu">通用格式</strong>描述源代码</strong>，允许各种程序使用。</p><p id="d787" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要了解更多关于LLVM和IRs的信息，请参考<a class="ae le" href="https://llvm.org/devmtg/2017-06/1-Davis-Chisnall-LLVM-2017.pdf" rel="noopener ugc nofollow" target="_blank"><em class="mz">Chisnall博士的幻灯片</em> </a>。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nv"><img src="../Images/2bb8488c014656923dde00e3ed901021.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MlfFYFMirJcWdtdkL5_8Lg.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:戴维斯·奇斯纳尔博士via <a class="ae le" href="https://llvm.org/devmtg/2017-06/1-Davis-Chisnall-LLVM-2017.pdf" rel="noopener ugc nofollow" target="_blank">讲稿</a>；从LLVM IR到x86架构汇编指令的转换，显然两种格式非常相似<strong class="bd my">证明IR的适应性</strong></p></figure><h1 id="509a" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">回到FPGAs的问题</h1><p id="d831" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">主要的问题是将程序和为Python编写的库转换成C语言，以便HLS工具运行。目前C语言不支持Tensorflow，所以这个解决方案非常困难。显然，布局和创建硬件的<strong class="js iu">要求是在深度学习中使用FPGAs的一大障碍</strong>。</p><h1 id="fd7b" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">我们的英雄勒弗洛</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/42663538914daebd91ed50fb3b9e7be9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*anJYoKXEmXzj5CXIDWCVaA.jpeg"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:Daniel H.N .等人通过<a class="ae le" href="https://arxiv.org/ftp/arxiv/papers/1807/1807.05317.pdf" rel="noopener ugc nofollow" target="_blank">研究论文</a>；<strong class="bd my"> LeFlow pipeline </strong>显示它是LLVM IR和HLS之间的中介</p></figure><p id="19da" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae le" href="https://arxiv.org/ftp/arxiv/papers/1807/1807.05317.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="mz"> LeFlow Toolkit </em> </a>允许工程师使用Python设计、训练和测试他们的模型，然后将其直接部署到FPGA中使用。<strong class="js iu"> LeFlow </strong>通过允许<strong class="js iu"> HLS </strong>工具与<strong class="js iu"> Python </strong>和<strong class="js iu"> Tensorflow </strong>兼容<strong class="js iu">来简化设计过程，充当<strong class="js iu">适配器</strong>。</strong></p><p id="62d3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">该软件由不列颠哥伦比亚大学ECE(电气和计算机工程)系的研究人员T21设计，他们是丹尼尔·h·诺罗尼亚和史蒂文J.E威尔逊。</p><p id="03a2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">以下部分详细介绍了LeFlow如何与Tensorflow和FPGA集成，如果您只对<strong class="js iu"/><strong class="js iu"/>实现中的<strong class="js iu"> </strong>感兴趣，请跳过<strong class="js iu"> </strong>到:<strong class="js iu"> </strong> <em class="mz">调优时间</em>。</p><h1 id="3acf" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">LeFlow工具包如何与Tensorflow一起工作</h1><p id="4205" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">为Tensorflow <strong class="js iu">设计的XLA(加速线性代数)编译器输出</strong>一个LLVM IR。LeFlow <strong class="js iu">重组</strong>IR和<strong class="js iu">优化</strong>与HLS工具配合使用。</p><p id="2435" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在此基础上，HLS工具完成了将IR转换为部署到FPGAs上的程序的所有工作，如<em class="mz">部分所述:我们应该坚持使用GPU吗？</em></p><h1 id="0272" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">勒弗洛投入产出模型</h1><p id="be77" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">LeFlow将IR作为输入。算法1是Tensorflow加载两个浮点数的IR。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/1255f51d96e771f74c302117bca58cc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*yV8q7qKPOwitxgYozq4xow.jpeg"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:Daniel H.N .等人通过<a class="ae le" href="https://arxiv.org/ftp/arxiv/papers/1807/1807.05317.pdf" rel="noopener ugc nofollow" target="_blank">研究论文</a>；输入到LeFlow，需要重组。获取指向每个float的元素指针(第5、6行)，解引用它们并加载(第7、8行)。</p></figure><p id="6ea0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这个节目很难跟上，而且看起来很乱。勒弗洛会把它清理干净，然后换掉。</p><p id="54bb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">它的目标是创建全局变量，然后<strong class="js iu">将它们映射为硬件接口</strong>的输入和输出。下图概述了LeFlow重新格式化并将IR通过LegUp后的合成电路。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/15b017ed23c227283c06f6e1a524142b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*UX3WLPRWORRaZ09T4oY9oQ.jpeg"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:Daniel H.N .等人通过<a class="ae le" href="https://arxiv.org/ftp/arxiv/papers/1807/1807.05317.pdf" rel="noopener ugc nofollow" target="_blank">研究论文</a>；硬件实施所需的变量和设置由LegUp、LeFlow生产，必须易于识别变量</p></figure><p id="1d25" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">显然，<strong class="js iu">硬件接口</strong>需要<strong class="js iu">额外的</strong>模块和信号，如时钟、复位、内存和内存控制器。<strong class="js iu"> LegUp </strong>处理这些部件的<strong class="js iu">创建</strong>，包括时钟的计时规范。</p><h1 id="c321" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">转换IR以实现最佳执行</h1><p id="e4b4" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">LeFlow为FPGA寄存器设置了一个可变负载。这允许变量访问，以及当高级代码改变时<strong class="js iu">自动电路修改</strong>。<strong class="js iu">变化</strong>主要在<strong class="js iu">线1、6、7 </strong>明显。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/e9a65d525ca8867297d62c15f312417c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*tfS7hUQn6pS7NXbtseJfNg.jpeg"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:Daniel H.N .等人通过<a class="ae le" href="https://arxiv.org/ftp/arxiv/papers/1807/1807.05317.pdf" rel="noopener ugc nofollow" target="_blank">研究论文</a>；<strong class="bd my">重组LLVM IR </strong>，为HLS合成做准备</p></figure><p id="2ffc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如算法2的改进IR所示，LeFlow完成了它的工作，剩下的由HLS工具处理！</p><h1 id="4b36" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">调音时间！</h1><p id="12b2" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">LeFlow的一个有趣的特性是可以更换硬件。LeFlow提供了<strong class="js iu">展开和内存分区</strong>参数，这些参数在正确使用时<strong class="js iu">会加速计算</strong>。这与FPGAs固有的低延迟相结合，使它们能够以极高的效率工作。</p><p id="91a2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最棒的是，这些参数可以在Python中指定，指令可以直接传递到电路级。</p><h1 id="c6f6" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">展开还是不展开</h1><p id="3afc" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">展开用于循环，是一种小心的平衡行为。想法是在每次迭代中进行多次计算(或复制)并采取更大的步骤。</p><p id="48c3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这看起来与常规的for循环相同，但在硬件级别添加了更多组件，以在每个时钟周期(或循环迭代)执行更多计算。有关展开的更多信息，请参见<a class="ae le" href="http://www.keil.com/support/man/docs/armcc/armcc_chr1359124222660.htm" rel="noopener ugc nofollow" target="_blank"> <em class="mz"> Keil的用户指南</em> </a>。</p><pre class="kp kq kr ks gt nz oa ob oc aw od bi"><span id="f217" class="oe lg it oa b gy of og l oh oi">int sum = 0;</span><span id="1001" class="oe lg it oa b gy oj og l oh oi">for(int i = 0; i &lt; 10; i+=2)</span><span id="75a8" class="oe lg it oa b gy oj og l oh oi">     sum += a[i]; sum += a[i+1];</span></pre><p id="5e59" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从上面看，我们可以展开两倍，这意味着一次进行两次迭代，循环增加两步。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/024f952d144966b6237d8f9293284425.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*KNwuTnKuPnO6JFzbdr6kcQ.jpeg"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:Daniel H.N .等人通过<a class="ae le" href="https://arxiv.org/ftp/arxiv/papers/1807/1807.05317.pdf" rel="noopener ugc nofollow" target="_blank">研究论文</a>；<strong class="bd my">将32×32输入图像上的3×3卷积的简化循环</strong>展开为5个32×32输出</p></figure><p id="8a72" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这利用了<strong class="js iu"> FPGA的并行性，工作起来更像GPU </strong>，显然每个示例的周期减少了13%。</p><p id="7527" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请记住，额外添加的硬件可能会导致效率低下或尺寸受限。</p><h1 id="b0c9" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">用内存分区分割它</h1><p id="12b9" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">LeFlow管道中使用的HLS需要一个双端口RAM(随机存取存储器)来存储值。</p><p id="fbad" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是有问题的，因为RAM被设计成存储大量数据，但代价是非常慢。从其中提取值可能需要十倍的时钟周期。</p><p id="0eab" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">幸运的是，FPGAs包含许多其他独立的存储单元，因此<strong class="js iu"> LeFlow可以将其数据划分到多个唯一的存储点</strong>。在某种意义上，这类似于在处理器中添加更多的内核。它<strong class="js iu">通过允许更多的指令同时执行来减少时钟周期</strong>。</p><p id="f802" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">假设任务是将两个大小为8的数组的元素相乘。在<a class="ae le" href="https://www.youtube.com/watch?v=JkbgMnL4xO0" rel="noopener ugc nofollow" target="_blank">并行计算</a>中，任务被分成组同时执行。<strong class="js iu">循环分解</strong>意味着某一组步骤同时重复。</p><p id="59d5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用内存分区可以提高FPGAs的运行效率。以下计划已经运行了八个时钟周期。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/1dc04b6d36477c96bee4a1eb3fd220b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*ApPIsOj8ojrbUCP298lZ0g.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:Daniel H.N .等人通过<a class="ae le" href="https://arxiv.org/ftp/arxiv/papers/1807/1807.05317.pdf" rel="noopener ugc nofollow" target="_blank">研究论文</a>；<strong class="bd my">加载两个数组的时钟周期分解</strong></p></figure><p id="1e61" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在(a)中，没有内存分区，所以每个周期从每个数组中<strong class="js iu">加载、相乘并存储一个元素。该过程继续，并花费<strong class="js iu">八个周期</strong>直到完成。</strong></p><p id="e278" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在(b)中，数组被循环划分到两个独立的存储器中。<strong class="js iu">每个数组</strong>中的两个元素在每个周期被加载、相乘并存储。较大的块表示进程同时发生，尽管是在硬件的不同部分。这将其减少到六个周期<strong class="js iu">。</strong></p><p id="cefa" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在c)中，数组被循环划分到四个独立的存储器中，并且减少到<strong class="js iu">五个周期。每个周期加载、相乘并存储来自每个数组的四个元素</strong>。</p><h1 id="736d" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">在Python中使用LeFlow</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi om"><img src="../Images/099a9170e5fc727615af955c7900e575.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0NGZZVWmPjmE4t3YjxgiMw.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:Daniel H.N .等人通过<a class="ae le" href="https://arxiv.org/ftp/arxiv/papers/1807/1807.05317.pdf" rel="noopener ugc nofollow" target="_blank">研究论文</a>；<strong class="bd my">实现一个CNN </strong>。输入被分配为单个32×32图像(第4行)，并且网络输出五个图像(每个图像应用了3×3滤波器；第5行)。</p></figure><p id="b043" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一旦LeFlow设置正确，它只需运行一个设备选择行，无需任何额外的配置(如展开):</p><pre class="kp kq kr ks gt nz oa ob oc aw od bi"><span id="c635" class="oe lg it oa b gy of og l oh oi">with tf.device("device:XLA_CPU:0")</span></pre><p id="e84d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">它表示XLA编译器将用于生成LLVM并启动LeFlow转换过程。</p><h1 id="17c0" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">尝试一下！</h1><p id="2d17" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">现在你是了解LeFlow工作原理的专家，也许FPGAs适合你。</p><p id="64a3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在<a class="ae le" href="https://github.com/danielholanda/LeFlow" rel="noopener ugc nofollow" target="_blank"> Github </a>上有很多LeFlow及其具体安装的例子。丹尼尔·霍兰达(合著者之一)有关于 <a class="ae le" href="https://github.com/danielholanda/LeFlow/tree/master/examples/classificationMNIST" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu"> MNIST数字识别</strong> </a>的<strong class="js iu">源代码，所以拿起FPGA试一试吧！</strong></p></div></div>    
</body>
</html>