<html>
<head>
<title>Analysis of Duterte’s Speeches using NLP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">杜特尔特演讲的自然语言处理分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/duterte-speech-analysis-f9e13f695558?source=collection_archive---------47-----------------------#2020-05-13">https://towardsdatascience.com/duterte-speech-analysis-f9e13f695558?source=collection_archive---------47-----------------------#2020-05-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="65fc" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">第一部分:搜集杜特尔特总统的演讲</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/7174b2056e4f0765553437465361dc86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ChgxfIHryY4BcW2Bbp3_Cg.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">罗德里戈·杜特尔特总统。照片由<a class="ae kv" href="https://www.pexels.com/@denniz-futalan-339724" rel="noopener ugc nofollow" target="_blank">丹尼兹·福塔兰</a>在<a class="ae kv" href="https://www.pexels.com/photo/rodrigo-duterte-on-stage-1394506/" rel="noopener ugc nofollow" target="_blank">像素</a>上拍摄</p></figure><p id="d7cf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">鉴于不同国家新冠肺炎的现状，各国政府加紧解决疫情问题的紧迫性进一步提高。菲律宾的情况也没有什么不同，因为罗德里戈·杜特尔特总统向菲律宾人民发表新闻发布会的频率已经上升。这启发了我去做一个个人项目，用自然语言处理(NLP)来分析他多年来的演讲。</p><p id="01b8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当然，在我分析他的演讲之前，我需要先实际收集它们。这是杜特尔特演讲分析的<strong class="ky ir"> Part 1 </strong>，将重点刮杜特尔特的演讲。本系列的后续文章将集中使用NLP来分析它们。对于我编写的代码，请查看我的<a class="ae kv" href="https://github.com/daniddelrio/duterte-speech-analysis" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>——尽管我承认我的代码在这里有点乱——如果你有任何意见或建议，请留下。最后，我还将更新我的自述文件，说明如何运行Python程序。</p><p id="98dd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对我来说幸运的是，该国的总统通信运营办公室(PCOO)在他们的网站上发布了他的演讲<a class="ae kv" href="https://pcoo.gov.ph/presidential-speech/" rel="noopener ugc nofollow" target="_blank">，至少到某一点为止(页面显示它有31页，但如果你浏览超过某一页码，它会返回一个“找不到页面”的错误)。因此，我收集的演讲仅从2020年到2018年。</a></p><p id="9a91" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于演讲的抓取，我主要使用了<code class="fe ls lt lu lv b">BeautifulSoup4</code>和<code class="fe ls lt lu lv b">requests</code> Python库，同时还使用了<code class="fe ls lt lu lv b">pandas</code>来构建数据集，<code class="fe ls lt lu lv b">python-dotenv</code>用于环境变量，以及一些用于从pdf中提取文本的库。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lw"><img src="../Images/e2c92fc35ec36daaf22243cbcf0ee255.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rnnenh425z05cm3AZmYPMA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">好喝的汤。由<a class="ae kv" href="https://www.pexels.com/@foodie-factor-162291" rel="noopener ugc nofollow" target="_blank">美食因素</a>在<a class="ae kv" href="https://www.pexels.com/photo/appetizer-bowl-bread-breakfast-539451/" rel="noopener ugc nofollow" target="_blank">像素</a>上拍摄的照片</p></figure></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><h2 id="72ee" class="me mf iq bd mg mh mi dn mj mk ml dp mm lf mn mo mp lj mq mr ms ln mt mu mv mw bi translated">抓取PCOO网站</h2><p id="4cbb" class="pw-post-body-paragraph kw kx iq ky b kz mx jr lb lc my ju le lf mz lh li lj na ll lm ln nb lp lq lr ij bi translated">最初，当我试图使用<code class="fe ls lt lu lv b">requests</code>库向PCOO网站发出GET请求时，由于某种原因，我一直收到一个连接错误。经过进一步的研究，我发现这是因为一些网站，包括PCOO的，普遍<em class="nc">不喜欢</em>机器人爬满它们。你可以通过访问他们的<a class="ae kv" href="http://www.gov.ph/robots.txt" rel="noopener ugc nofollow" target="_blank"> robots.txt </a>看到这一点，显示了以下针对<em class="nc">禁用</em>机器人的设置。</p><pre class="kg kh ki kj gt nd lv ne nf aw ng bi"><span id="0831" class="me mf iq lv b gy nh ni l nj nk">User-Agent: *<br/>Disallow:</span></pre><p id="c7cf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，我不得不执行几个额外的步骤，作为克服针对<em class="nc">机器人</em>的设置的措施，以及为了<a class="ae kv" href="https://www.scrapehero.com/how-to-prevent-getting-blacklisted-while-scraping/" rel="noopener ugc nofollow" target="_blank">防止我的IP地址被列入黑名单</a>的预防措施。首先，我必须将我的<em class="nc">机器人程序</em>伪装成人类，方法是<strong class="ky ir">为我的每个请求附加一个</strong> <a class="ae kv" href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/User-Agent" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">用户代理</strong> </a>，我将它存储在我的<code class="fe ls lt lu lv b">.env</code>文件中(因此我安装了<code class="fe ls lt lu lv b">python-dotenv</code>)。其次，如果一个IP地址以极快的速度向一个网站发出GET请求，那就太明显了，所以我使用<code class="fe ls lt lu lv b">time.sleep</code>将每个请求分散15秒，让它看起来更人性化。不可否认，这增加了刮擦时间，但是稍后我会解释我是如何大大加速这个过程的。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nl nm l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Python刮刀的主程序。这个主程序以每页的速度进行抓取。</p></figure><p id="6eea" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面的片段显示了在<code class="fe ls lt lu lv b">01_scraper.py</code>文件中找到的主程序的一部分，它抓取了网站每页的演讲。每页包含20篇演讲，在我的程序中，我将其中的每一篇都称为<code class="fe ls lt lu lv b">row</code>。每篇演讲都会将你带到演讲详情页面(<a class="ae kv" href="https://pcoo.gov.ph/presidential-speech/talk-to-the-people-of-president-rodrigo-roa-duterte-on-coronavirus-disease-2020-covid-19/" rel="noopener ugc nofollow" target="_blank">示例</a>)，其中包含音频、完整的文字记录，可能还有新闻发布会的视频。完整的文稿会将您重定向到一个PDF格式的演讲文稿(<a class="ae kv" href="https://pcoo.gov.ph/presidential-speech/talk-to-the-people-of-president-rodrigo-roa-duterte-on-coronavirus-disease-2020-covid-19/" rel="noopener ugc nofollow" target="_blank">示例</a>)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nn"><img src="../Images/90a7d5d11ddccedcebdfe105eae106ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RWcHdF_NvxH2qySGG6Ledg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://pcoo.gov.ph/presidential-speech/" rel="noopener ugc nofollow" target="_blank"> PCOO网站</a>发言截图</p></figure><p id="c4f3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我在我的<code class="fe ls lt lu lv b">scraper_functions.py</code>中创建了一个名为<code class="fe ls lt lu lv b">extract_page</code>的函数，它使用上述过程处理每一行，并返回一个包含标题、演讲日期和提取文本的字典。</p><p id="48e5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下一个问题是，我如何从pdf中提取文本？</p><h2 id="f3f2" class="me mf iq bd mg mh mi dn mj mk ml dp mm lf mn mo mp lj mq mr ms ln mt mu mv mw bi translated">PDF提取:使用哪个库？</h2><p id="4d60" class="pw-post-body-paragraph kw kx iq ky b kz mx jr lb lc my ju le lf mz lh li lj na ll lm ln nb lp lq lr ij bi translated">如果我想尝试更多的PDF库，为了减少抓取时间，我将PDF保存在我的存储库中。这样，我就不用再费力地浏览PCOO网站了。之后，我找到了四个用于从pdf中提取文本的Python库:</p><ol class=""><li id="6f96" class="no np iq ky b kz la lc ld lf nq lj nr ln ns lr nt nu nv nw bi translated"><a class="ae kv" href="https://pythonhosted.org/PyPDF2/" rel="noopener ugc nofollow" target="_blank"> PyPDF2 </a></li><li id="11c9" class="no np iq ky b kz nx lc ny lf nz lj oa ln ob lr nt nu nv nw bi translated"><a class="ae kv" href="https://github.com/TakesxiSximada/slate3k" rel="noopener ugc nofollow" target="_blank"> slate3k </a></li><li id="dfc4" class="no np iq ky b kz nx lc ny lf nz lj oa ln ob lr nt nu nv nw bi translated"><a class="ae kv" href="https://github.com/chrismattmann/tika-python" rel="noopener ugc nofollow" target="_blank">蒂卡</a></li><li id="05e7" class="no np iq ky b kz nx lc ny lf nz lj oa ln ob lr nt nu nv nw bi translated"><a class="ae kv" href="https://github.com/jsvine/pdfplumber" rel="noopener ugc nofollow" target="_blank">pdf木材</a></li></ol><p id="9863" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最初，我用的是<code class="fe ls lt lu lv b">PyPDF2</code>，但对于一些演讲，它只能提取空的新行，所以它会以类似<code class="fe ls lt lu lv b">\n\n\n\n\n\n\n\n</code>的东西结束。因此，我使用regex为创建了一个函数来检查提取的文本是否返回一个没有单词的字符串。如果函数返回了<code class="fe ls lt lu lv b">True</code>，那么我使用<code class="fe ls lt lu lv b">slate3k</code>来提取该语音。尽管如此，这个图书馆有时还是会有错误的结果，比如完全遗漏了演讲的某些部分，并且奇怪地将一些演讲的文本中的每个字母隔开。尽管如此，我还是使用<code class="fe ls lt lu lv b">PyPDF2</code>和<code class="fe ls lt lu lv b">slate3k</code>将所有结果编译成一个<code class="fe ls lt lu lv b">csv</code>。</p><p id="86ce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我试用了<code class="fe ls lt lu lv b">tika</code>，因为我在试图分析时，对之前的结果太失望了，它的效果<em class="nc">非常好</em>。事实上太漂亮了，以至于我没有机会试用<code class="fe ls lt lu lv b">PDFPlumber</code>(所以如果你以前用过它，一定要让我知道它是否有同样的功能！).在提取所有内容时没有发现错误，所以使用这个库的过程非常顺利。我已经决定在我的分析中使用<code class="fe ls lt lu lv b">tika</code>结果，而不是其他三个包。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nl nm l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">从pdf中提取文本的功能</p></figure><h2 id="0afe" class="me mf iq bd mg mh mi dn mj mk ml dp mm lf mn mo mp lj mq mr ms ln mt mu mv mw bi translated">多重处理</h2><p id="5365" class="pw-post-body-paragraph kw kx iq ky b kz mx jr lb lc my ju le lf mz lh li lj na ll lm ln nb lp lq lr ij bi translated">我在上面提到过，每个演讲有两个抓取阶段:演讲详情页面和PDF文稿页面，总计每个演讲超过30秒的抓取。鉴于每页有20篇演讲稿，我们要花10多分钟(加上另外15秒来抓取页面本身)才能提取一页中的所有演讲稿。大约有21个有效页面，所以理论上总共需要210分钟或者大约3.5小时来提取它们。然而，实际上我花了大约一周的时间来完成刮擦，因为在使用<code class="fe ls lt lu lv b">PyPDF2</code>和<code class="fe ls lt lu lv b">slate3k</code>时出现了许多错误。</p><p id="7f6b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这让我探索<a class="ae kv" href="https://docs.python.org/3/library/multiprocessing.html" rel="noopener ugc nofollow" target="_blank">多重处理</a>来加速整个过程，而不是使用<code class="fe ls lt lu lv b">tika</code>作为我的PDF提取器，并且它工作<em class="nc">奇迹</em>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nl nm l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">多重处理程序</p></figure><p id="8a2d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于我在第一次试运行时无法在本地保存pdf，我不得不重新开始整个抓取过程。但是有了多重处理，我可以让多个工作人员同时处理同一组数据(在这种情况下，每页20篇演讲)，而不是必须依次处理每篇演讲。</p><p id="d25e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用代表工作进程池的<code class="fe ls lt lu lv b">Pool</code>对象，我能够将数据(每页20行数据)映射到工作进程，工作进程同时运行<code class="fe ls lt lu lv b">extract_page</code>功能。在所有的工作完成之后，由函数返回的20个字典的列表被附加到正在工作的<code class="fe ls lt lu lv b">pandas</code>数据帧中。我还包含了一个文本文件，用于记录我处理的每个演讲(我在第一次试运行时也是这样做的)。</p><p id="c364" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我用我的<code class="fe ls lt lu lv b">scrape_logs.txt</code>比较了第一次和第二次试运行时抓取一整页所用的总时间，差异<strong class="ky ir">明显</strong>。对于第一次试运行，完成一个完整的页面需要13-20分钟，而我的第二次涉及多处理的试运行只需要4-5分钟。这也要感谢<code class="fe ls lt lu lv b">tika</code>库的顺利运行，我在提取文本时没有遇到任何错误(尽管我确实遇到了这个与多重处理相关的奇怪的递归限制错误，我通过添加<code class="fe ls lt lu lv b">sys.recursionlimit(10000)</code>纠正了这个错误)。总的来说，多重处理试运行只持续了大约1.5小时！</p><p id="4f21" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我对PDF提取本身也很满意，看到使用<code class="fe ls lt lu lv b">tika</code>获得的文本中只有微不足道的错误。因此，我选择不再继续进行<code class="fe ls lt lu lv b">PDFPlumber</code>了。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/3c9c3f7f798ab3638b70f07876ce970e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AoylKnODcnQquvLBkSORlA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">工人的效率！由<a class="ae kv" href="https://www.pexels.com/@fauxels" rel="noopener ugc nofollow" target="_blank">山</a>在<a class="ae kv" href="https://www.pexels.com/photo/photo-of-people-leaning-on-wooden-table-3183183/" rel="noopener ugc nofollow" target="_blank">山</a>拍摄的照片</p></figure></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><p id="cb69" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">总的来说，我成功地抓取了PCOO网站，以便收集杜特尔特的演讲，并将它们汇编成一个<code class="fe ls lt lu lv b">csv</code>文件，通过整合多重处理进一步加快了整个过程。</p><p id="8ac3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于第2部分(可能还有第3部分)，我将尝试分析我使用NLTK和TF-IDF/N-gram等NLP工具收集的数据。同样，请随意浏览我的<a class="ae kv" href="https://github.com/daniddelrio/duterte-speech-analysis" rel="noopener ugc nofollow" target="_blank"> Github库</a>，如果您有任何意见或建议，请在下面留下！我将非常感激。</p></div></div>    
</body>
</html>