# 帮助你赢得面试的 15 个数据科学和统计问题！

> 原文：<https://towardsdatascience.com/top-15-data-science-statistics-questions-to-help-ace-your-interview-c86da6a954fe?source=collection_archive---------32----------------------->

## 有答案的问题

![](img/36b97ab87a61d9ce3b2da359cc0773de.png)

丹尼尔·麦卡洛在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

今天，数据科学已经成为世界上最热门和最受欢迎的职业之一。数百万人，包括新生和有经验的专业人士，都在努力获得数据科学行业所需的技能。我从数据科学和统计学中收集了一系列问题，这些问题可能会对面试有所帮助。
*注意——这不是一份详尽的问题清单，也不适用于所有人，但它将与 83%的申请人相关。*

# **一般问题**

# 在数据科学项目中，您会遵循哪些不同的步骤？

一般来说，所有数据科学项目都有相同的工作流程
***加载*** *—* 使用适当的命令在 R、Python、SAS(或任何其他语言)上加载给定的数据集。
***检查原始数据*** —使用散列表计算/平均值/模式检查加载的数据集的准确性/一致性，以确保数据已正确加载。
***清理*** —对数据集进行缺失值插补、离群点检测等。 ***预处理方法***——如检查独立变量之间的相关性、处理分类变量、创建新的合成变量、合并外部数据(如果存在)。
***预建模步骤***——包括在训练/测试/验证分割中划分数据，创建一个精度指标，变量缩减技术(主成分、逐步回归等)。
***模型创建*** —创建不同的统计和数据科学模型，如线性、逻辑、随机森林、gbm、神经网络等，并测试它们的准确性。 ***部署*** 服务器上的模型。

始终确保与客户/业务团队进行健康的讨论，以便他们的所有期望都符合上述模型。

# 有监督和无监督模型有什么区别？

监督模型是那些根据标记数据训练的模型，即我们有一个或多个*自变量(x)* 和一个*因变量(y)。*如此创建的训练模型将有助于根据未知或*独立变量(x)的未来值预测*因变量(y)。* 无监督模型是那些没有经过标记数据训练的模型，即我们只有一个或多个*自变量(x)，但没有*因变量(y)。*在这样的方法中，你允许算法本身发现数据中隐藏的模式。

# 什么是回归？

它是一种确定两个或多个变量之间统计关系的技术，其中因变量的变化与一个或多个自变量的变化相关联，并取决于一个或多个自变量的变化。
例如:线性回归、逻辑回归

# 什么是集群？

聚类是一项任务，通过该任务，计算机算法将观察结果分成不同数量的组，使得一个组中的观察结果比其他组中的观察结果更加相似
例如:K 均值、DBSCAN、LOCi

# 数据清理问题

# **有哪些不同的数据插补方法，我们为什么要这样做？**

如果数据中有缺失值，计算机算法无法计算并抛出错误。一些插补方法有:
连续数据——用平均值代替缺失值
分类数据——用模式
代替缺失值。其他几种插补方法有——正向插补、线性回归、随机森林的 missforest 技术、MICE 等。

# 为什么我们需要测试异常值？

异常值的出现有几个原因——坏数据、一次性案例、实验误差等。一般来说，它们并不重要，可能会降低模型的准确性或给出不准确的结果，或者两者兼而有之。但是有时候它们非常重要，可以用来发现异常。尤其有助于信用卡、保险索赔等欺诈检测。

# 预处理问题

# 什么是相关性，它与回归有什么不同？

相关性是确定两个变量的相互关系或关联的统计度量。*相关系数*表示两个变量一起移动的程度。
回归描述了自变量与因变量在数字上的关系。*回归表示已知自变量(x)的单位变化对因变量(y)的影响*

# 什么是分类变量，我们如何处理它们？

分类变量是那些只能取有限数量的值的变量。像国家这样的变量会有一组确定的值，如印度、美国、韩国、泰国等。分类变量可以有两种类型
*序数* —变量的值以某种形式排序。例如:考试成绩可以有一组有限的值，如 A、B、C、D 等，并且可以排序，即 A>B>C>D
名义值——变量具有未排序的值。例:上面提到的国家例子。

有序的分类变量通常可以直接用于建模过程中，但这不适用于名义变量。有多种方法处理它，但最简单和最常用的方法是创建*虚拟变量或零热编码*变量，并将它们用作建模变量

# 建模前问题

# 为什么我们要在训练测试中分割数据？

训练测试有助于模型不对给定的数据进行概括或过度拟合，并有助于在现实世界中表现良好。因此，该模型在训练数据集上被训练，并被用于在看不见的测试数据集上评分和检查准确性。

# 什么是 R-Square，它与调整的 R-Square 有何不同？

R-Square 确定*因变量(y)* 的总变化中有多少是由*自变量(x)* 的变化解释的。(您对直线或曲线的拟合程度如何)。
调整后的 R-square 是 R-square 的修改版本，已针对模型中的预测器数量进行了调整。如果我们在模型中加入无关紧要的变量，调整后的 r 平方将会减少。如果我们增加重要的变量，调整后的 r 平方将会增加

# 偏倚和方差的区别？

*偏差*是模型的平均预测值与我们试图预测的正确值之间的差异。具有高偏差的模型很少关注训练数据，并且过度简化了模型。它导致训练和测试数据的高误差(*欠拟合* )
方差是给定数据点或告诉我们数据分布的值的模型预测的可变性。高方差模型非常重视训练数据，不会对以前没有见过的数据进行归纳。这种模型在训练数据上表现很好，但是在测试数据上有很高的错误率(*过拟合*)

# 通俗地说什么是决策树？

决策树是使用分支方法来说明决策的每一个可能结果的图形。决策规则通常采用 if-then-else 语句的形式。树越深，规则越复杂，模型越合适

# 建模问题

# 套索和岭回归有什么区别？

套索和岭回归是不同类型的正则化技术，有助于减少过度拟合。这是通过在损失函数中添加另一个最小化元素来实现的，该元素被称为罚函数。
在*岭回归(L2)* 中，惩罚是系数的平方和。因此，它有助于降低一个不重要变量的系数值。
而在*拉索(L1)回归*中，惩罚是系数的绝对值之和。因此，它不仅有助于降低系数值，还有助于减少变量。

# 装袋(随机森林)和助推 *(GBM)有什么区别？*

bagging 和 boosting 都是建立在决策树上的集成技术，但是:
*Bagging:* 模型是在从训练数据中随机选择的多个数据子集上训练的。最后，对不同的树进行平均预测(回归)/最高频率(分类)。可能会导致高偏差和低方差。 *Boosting:* 逐步或顺序训练模型。早期模型相对简单，而以下模型分析前一个模型的误差，并尝试拟合残差。可能导致低偏差和高方差

# 有哪些不同的准确性指标？

*对于回归模型:*
MAPE =(y-yhat)/y
RMSE = sqrt((y-yhat)/n)
调整后的 R 平方

*对于分类模型:*
准确率= TP+TN/TP+FP+FN+TN
精度= TP/TP+FP
召回/灵敏度= TP/TP+FN
特异性= TN/TN+FP
F1 得分= 2*(召回*精度)/(召回+精度)
Gini = 2*AUC -1
ROC 曲线