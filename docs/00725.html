<html>
<head>
<title>Deep Learning for Time Series Classification (InceptionTime)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">时间序列分类的深度学习(InceptionTime)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-for-time-series-classification-inceptiontime-245703f422db?source=collection_archive---------1-----------------------#2020-01-21">https://towardsdatascience.com/deep-learning-for-time-series-classification-inceptiontime-245703f422db?source=collection_archive---------1-----------------------#2020-01-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="491e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用于时间序列分类的新深度学习(类GoogleNet)模型。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/5361830c89a741fe0e3c1af4b6f892b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yi4LbmlBTc8JiTdjsNtfXA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图InceptionTime的初始模块。</p></figure><h1 id="353e" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">索引</h1><ol class=""><li id="ff85" class="lq lr it ls b lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">动机</li><li id="5e62" class="lq lr it ls b lt mi lv mj lx mk lz ml mb mm md me mf mg mh bi translated">用于时间序列分类的机器学习</li><li id="fbee" class="lq lr it ls b lt mi lv mj lx mk lz ml mb mm md me mf mg mh bi translated">时间序列分类的最佳深度学习实践:InceptionTime</li><li id="8d5f" class="lq lr it ls b lt mi lv mj lx mk lz ml mb mm md me mf mg mh bi translated">了解初始时间</li><li id="c43e" class="lq lr it ls b lt mi lv mj lx mk lz ml mb mm md me mf mg mh bi translated">结论</li></ol><h1 id="cd9a" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated"><strong class="ak"> 1。动机</strong></h1><p id="1db1" class="pw-post-body-paragraph mn mo it ls b lt lu ju mp lv lw jx mq lx mr ms mt lz mu mv mw mb mx my mz md im bi translated">时间序列数据一直是金融服务的主要兴趣，现在随着实时应用的兴起，零售和编程广告等其他领域正在将注意力转向时间序列数据驱动的应用。在过去几年中，云服务的几个主要参与者，如Apache Kafka和Apache Spark，已经发布了处理时间序列数据的新产品。因此，理解机器学习(ML)在这个新兴领域中的作用和潜力是非常有趣的。</p><p id="be53" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">在这篇文章中，我通过跟踪[ <a class="ae nf" href="https://arxiv.org/abs/1809.04356" rel="noopener ugc nofollow" target="_blank"> 2 </a>作者的一系列出版物，讨论了关于深度学习的时间序列分类(TSC)的(非常)最新发现。</p><h1 id="c089" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated"><strong class="ak"> 2。</strong>用于时间序列分类的机器学习</h1><p id="0f60" class="pw-post-body-paragraph mn mo it ls b lt lu ju mp lv lw jx mq lx mr ms mt lz mu mv mw mb mx my mz md im bi translated"><strong class="ls iu">定义问题:</strong></p><p id="4aef" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">TSC是ML对学习如何给时间序列分配标签感兴趣的领域。更具体地说，我们对训练ML模型感兴趣，当输入一系列按时间顺序索引的数据点(例如，金融资产的历史数据)时，它输出标签(例如，资产的行业部门)。</p><p id="78a2" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">更正式的说法是，让【t8(x，y)】成为<em class="ng"> </em>一个训练实例，带有<em class="ng"> T </em>观察值<em class="ng"> (X，… ,Xᵀ)≡ X </em>(时间序列)和一个离散类变量<em class="ng"> y </em>，它取<em class="ng"> k </em>个可能值(标签)。一个数据集<em class="ng"> S </em>就是一组<em class="ng"> n </em>这样的训练实例:<em class="ng"> S= </em> <em class="ng"> { (X₍₁₎，y₍₁₎)，…，(X₍ n₎，y₍ n₎)) } </em>。对时间序列数据进行分类的任务包括在<em class="ng"> S </em>上学习分类器，以便从可能的输入空间<em class="ng"> {X} </em>映射到标签<em class="ng"> {y，…，yᵏ} </em>上的概率分布。</p><p id="0dc4" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">我们真的需要DL吗？</p><p id="3449" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">提醒我们自己DL只不过是一套解决问题的工具，这一点很重要，尽管DL可能非常强大，但这并不意味着我们应该盲目地将DL技术应用于每一个问题。毕竟，训练和调整神经网络可能非常耗时，所以测试其他ML模型的性能，然后寻找任何潜在的缺点总是一个好的做法。</p><p id="cc8a" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">通常，问题的性质是由数据本身决定的；在我们的例子中，选择处理和分类时间序列的方式高度依赖于数据的长度和统计。也就是说，让我们运行一个快速量纲分析来估计我们问题的复杂性。</p><p id="ef54" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">假设我们希望为我们的TSC问题学习一个最近邻分类器(这在文献中很常见)。现在给定一个长度为<em class="ng"> T </em>的<em class="ng"> n </em>时间序列的数据集，我们必须为<em class="ng"> ⁿC₂=n(n-1)/2 </em>唯一对计算某种距离度量。此外，为了找到两个时间序列<em class="ng"> X₍₁₎ </em>和<em class="ng"> X₍₂₎ </em>之间的“最佳距离”，我们必须为每一对唯一的训练实例计算<em class="ng"> T×T </em>逐点距离矩阵<em class="ng">mʲᵏ=</em>(<em class="ng">x₍₁₎ʲ-x₍₂₎ᵏ)</em>，然后寻找优化我们的目标函数的路径。正如在[ <a class="ae nf" href="https://arxiv.org/pdf/1602.01711.pdf" rel="noopener ugc nofollow" target="_blank"> 3 </a>中所解释的，文献中有几种针对这种设置的优化算法，它们都具有复杂度<em class="ng"> O(n ⋅ Tᶜ) </em>，其中<em class="ng"> c=3或4 </em>。显然，<strong class="ls iu">时间序列的长度真的会损害计算速度。然而，对于某些类型的数据，这个问题可以在不挖掘复杂的机器学习模型(如深度神经网络)的情况下得到缓解。</strong></p><p id="498b" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">在信号处理中，通过将信号分解成一系列“基本”信号来分析复杂信号，称为<em class="ng">傅立叶模式</em>。例如，下面的方波可以用三个不同频率的正弦信号<em class="ng"> (f₁、f₂、f₃)=(ω、3ω、5ω) </em>来近似，对于某个恒定角频率<em class="ng"> ω </em>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/5f920732cc999f6e9e244f6f33332ee0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oRF5Muygj0RbJ_IPjUcDdg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图2:方波的傅立叶级数展开(红线)。这里我只介绍前三种模式(蓝色虚线)和它们的加法(绿线)。希望不难看出，通过增加下一个模式，级数很快收敛到方波。</p></figure><p id="2c3a" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">通过对这些信号进行线性求和，我们可以重建原始信号:</p><p id="a115" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated"><em class="ng">方波(t)= w⋅sin(f₁t)+w⋅sin(f₂t)+w⋅sin(f₃t)+…</em></p><p id="a9d4" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">其中系数<em class="ng"> (W，W，W ) = (1，1/3，1/5) </em>指定每个模式对方波贡献的<em class="ng">权重</em>。</p><p id="0f19" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">现在考虑一个数据集，在该数据集内，最初由一系列<em class="ng"> T </em>时间有序数据点表示的任何时间序列也可以由三个基本频率模式所跨越的空间中的权重向量来表示:</p><p id="eae8" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated"><em class="ng"> X=(X，…，Xᵀ ) </em> → <em class="ng"> W </em> = <em class="ng"> (W，w，w，…)。</em></p><p id="c00d" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">从我们的时间序列数据的“时间”表示到“频率”表示被称为<em class="ng">傅立叶变换</em>，虽然傅立叶空间在理论上是无限维的(而不是三维的)，但我们可以应用各种近似技术将傅立叶级数截断到有限维。最重要的是，<strong class="ls iu">我们可以将时间序列数据的<em class="ng"> T </em>维表示减少到多个维度(在傅立叶空间)，这使得我们的分类问题在计算上是可跟踪的</strong>。总的来说，我们可以在数据预处理阶段应用傅立叶变换，以将输入时间序列转换成权重向量，然后继续构建我们的分类模型(例如，1-最近邻分类器)。使用这种“行为良好”的时间序列，我们可以在不使用DL的情况下实现高性能。</p><p id="702e" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">现在，前述处理方法<strong class="ls iu">假设</strong>任何输入信号都可以用基本(谐波)函数的傅立叶级数来近似。然而，许多现实世界的时间序列数据是如此嘈杂(如金融数据)，不允许这样一个优雅的分解(或任何形式的数学预处理)。正是针对这种类型的数据，DL前来救援:<strong class="ls iu">在处理非结构化噪声数据时，让模型自己学习如何处理时间序列数据是一个更有前途的解决方案。</strong></p><h1 id="4810" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated"><strong class="ak"> 3。TSC的最佳DL实践:开始时间</strong></h1><p id="1630" class="pw-post-body-paragraph mn mo it ls b lt lu ju mp lv lw jx mq lx mr ms mt lz mu mv mw mb mx my mz md im bi translated">迄今为止，TSC有两种最先进的DL型号。最古老的模型称为HIVE-COTE [ <a class="ae nf" href="https://core.ac.uk/download/pdf/77027925.pdf" rel="noopener ugc nofollow" target="_blank"> 4 </a> ]，它基于最近邻算法和动态时间弯曲相似性度量。尽管该算法在基准数据集[ <a class="ae nf" href="https://www.cs.ucr.edu/~eamonn/time_series_data/" rel="noopener ugc nofollow" target="_blank"> 5 </a> ]上取得了优异的性能，但其时间复杂度为<em class="ng"> O(n ⋅ T ⁴) </em>。最近[ <a class="ae nf" href="https://arxiv.org/abs/1909.04939" rel="noopener ugc nofollow" target="_blank"> 6 </a> ]的作者介绍了一种深度卷积神经网络(CNN)，称为InceptionTime，它不仅比HIVE-COTE的精度更高，而且速度也快得多。InceptionTime的高精度及其可扩展性使其成为产品开发的完美候选！</p><p id="d5c1" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">为此，让我们介绍一下InceptionTime最重要的组件，以及这些组件是如何在Keras中实现的。</p><p id="60ed" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated"><strong class="ls iu"> 3.1输入层</strong></p><p id="22c9" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">一般来说，时间序列<em class="ng"> X </em>的每个数据观测值<em class="ng"> Xʲ (j=1，…，T) </em>可以是一个或多个数据测量值的列表，即<em class="ng"> Xʲ = ( X₁ʲ，…，X_m ʲ ) </em>对于<em class="ng"> m </em>数据测量值，都是在第<em class="ng"> j </em>时刻进行的。例如，一个质点在三维空间中运动的速度由三个空间分量组成:<strong class="ls iu"> <em class="ng"> V </em> </strong> <em class="ng"> =(V₁，V₂，V₃) </em>。跟踪粒子的速度达<em class="ng"> T </em>秒，每秒一次观测，相当于收集一系列数据:(<strong class="ls iu"> <em class="ng"> V </em> </strong> <em class="ng">，…，</em><strong class="ls iu"><em class="ng">v</em></strong><em class="ng">ᵀ)。</em></p><p id="bfbf" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated"><strong class="ls iu">定义1: </strong>安<em class="ng">米</em>-维<em class="ng">多元</em>时间序列【MTS】<em class="ng">x =(</em><strong class="ls iu"><em class="ng">x</em></strong><em class="ng">，…，</em><strong class="ls iu"><em class="ng">x</em></strong><em class="ng">【ᵀ】</em>由<em class="ng"> T </em>有序元素<strong class="ls iu"> <em class="ng"> X </em> </strong> <em class="ng"/></p><p id="15f1" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated"><strong class="ls iu">定义二:</strong>一个长度为<em class="ng"> T的单变量<em class="ng">时间序列<em class="ng"> X </em>简单来说就是一个<em class="ng"> m=1 </em>的MTS，即<strong class="ls iu"><em class="ng">x</em></strong><em class="ng">ʲ</em>→<em class="ng">xʲ</em>∈ℝ和<em class="ng"> X</em></em></em></p><p id="f1c9" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">就像在图像分类问题中一样，我们可以将输入MTS视为一个形状数组(<em class="ng"> 1，T，m) </em>，其中<em class="ng"> m </em>表示通道的数量(深度)。事实上，抑制输入的宽度并直接使用<em class="ng"> input_shape = (T，m)是很方便的。</em></p><p id="12fd" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated"><strong class="ls iu"> 3.2初始模块</strong></p><p id="4662" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">InceptionTime的主要构件是<em class="ng">初始模块</em>，如下图所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/2e94e0b407ef869fcb17172080812a3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QCeZup5dSkAtd3JvJeDa2Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图InceptionTime的初始模块。框中的第一个数字表示内核大小，而第二个数字表示步幅大小。“(S)”指定填充类型，即“相同”。</p></figure><p id="f13e" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">这包括以下几层:</p><ul class=""><li id="05f0" class="lq lr it ls b lt na lv nb lx nj lz nk mb nl md nm mf mg mh bi translated">一个<em class="ng">瓶颈层</em>，用于减少输入的维度(即深度)。这减少了计算成本和参数数量，加快了训练速度，提高了泛化能力。</li><li id="79f0" class="lq lr it ls b lt mi lv mj lx mk lz ml mb mm md nm mf mg mh bi translated">瓶颈的输出被馈送到核大小为10、20和40的三个<em class="ng">一维卷积层</em>。</li><li id="cedc" class="lq lr it ls b lt mi lv mj lx mk lz ml mb mm md nm mf mg mh bi translated">初始模块的输入也通过大小为3的<em class="ng">最大池层</em>，并依次通过<em class="ng">瓶颈层</em>。</li><li id="7c5e" class="lq lr it ls b lt mi lv mj lx mk lz ml mb mm md nm mf mg mh bi translated">最后一层是<em class="ng">深度级联层</em>，其中步骤2的四个卷积层的输出沿着深度维度被级联。</li></ul><p id="94c7" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">所有层(不包括连接层)都有<em class="ng">步距</em> 1和【相同】<em class="ng">填充</em>。此外，所有的卷积层都有32个T4过滤器。</p><p id="4476" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated"><strong class="ls iu"> Keras实现</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/e061d274c38d9738488c43f974e294ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jyTLN-rZj0cD4B3Ou7vgTw.png"/></div></div></figure><p id="8c91" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated"><strong class="ls iu"> 3.3盗梦空间网络</strong></p><p id="5aa4" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">InceptionTime的网络架构与GoogleNet的[ <a class="ae nf" href="https://arxiv.org/pdf/1409.4842.pdf" rel="noopener ugc nofollow" target="_blank"> 7 </a> ]高度相似。具体而言，该网络由一系列初始模块组成，其后是一个全局平均池层和一个具有softmax激活功能的密集层。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/036928219ed83bd3c2df6758c77d2ac6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fjSunNoM0mnX8oK_FYONmA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图4:用于时间序列分类的初始网络。</p></figure><p id="ad28" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">然而，InceptionTime在其网络层中引入了一个额外的元素:<em class="ng">剩余连接</em>在每三个初始模块中。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/8fb70bdbb44c963a868f212d78390000.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*KUod6aCTJ1zx6D5q7y1B2Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图5:初始网络中的剩余连接。</p></figure><p id="701a" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated"><strong class="ls iu"> Keras实施</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/b18dd634e2592c60b6e8ac25588ae16d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i8ecKdAPXQiO-bfPs4NwPQ.png"/></div></div></figure><p id="8a4d" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated"><strong class="ls iu"> 3.4初始时间:用于TSC的神经网络集成</strong></p><p id="e4f1" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">正如[ <a class="ae nf" href="https://arxiv.org/abs/1909.04939" rel="noopener ugc nofollow" target="_blank"> 6 </a> ]中所解释的，事实证明，单个初始网络在准确性方面表现出很大的差异。这可能是因为与随机权重初始化以及随机优化过程本身相关联的可变性。为了克服这种不稳定性，提出的最先进的InceptionTime模型实际上是由5个初始网络组成的<strong class="ls iu">，每个预测都被赋予一个均匀的权重(有关TSC的深度神经网络集成的更多信息，请参见[ <a class="ae nf" href="https://arxiv.org/abs/1903.06602" rel="noopener ugc nofollow" target="_blank"> 8 </a>)。模型的完整实现可以在<a class="ae nf" href="https://github.com/hfawaz/InceptionTime" rel="noopener ugc nofollow" target="_blank"> <strong class="ls iu"> Github </strong> </a>上找到。</strong></p><h1 id="634c" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated"><strong class="ak"> 4。了解开始时间</strong></h1><p id="3650" class="pw-post-body-paragraph mn mo it ls b lt lu ju mp lv lw jx mq lx mr ms mt lz mu mv mw mb mx my mz md im bi translated">正如前面提到的，InceptionTime主要是受计算机视觉问题的CNN的启发，因此，我们希望我们的模型以类似的方式学习功能。例如，在图像分类中，底层的神经元学习识别低级(局部)特征，如线条，而高层的神经元学习检测高级(全局)特征，如形状(如眼睛)。同样，我们期望InceptionTime的底层神经元能够捕捉到一个时间序列的局部结构，比如直线和曲线，顶层神经元能够识别各种形状模式，比如“山谷”和“山丘”。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/18eb54190d303d83eda54c5c2447711f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5NoKcfsUuch8ojfmdl0OZw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图6:过滤器中神经元的感受野。</p></figure><p id="9d11" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">神经元所依赖的输入信号区域被称为该特定神经元的<strong class="ls iu">感受野</strong>。在物体识别中，更大的感受野用于捕捉更多的上下文。因此，在处理非常长的时间序列数据时，选择更大的感受域是很自然的，这样我们的认知时间将学会检测更大的模式。</p><h1 id="a33d" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">5.结论</h1><p id="6c26" class="pw-post-body-paragraph mn mo it ls b lt lu ju mp lv lw jx mq lx mr ms mt lz mu mv mw mb mx my mz md im bi translated">TSC的一个重要方面是时间序列的长度，因为这可能会降低训练速度。虽然有各种数学处理方案可以用来解决这样的问题，但InceptionTime是TSC的主要算法，特别是对于长时间的噪声时间序列数据。</p><p id="0367" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">InceptionTime是一组CNN，它学习识别时间序列数据集中的局部和全局形状模式(即低级和高级特征)。不同的实验<a class="ae nf" href="https://arxiv.org/abs/1909.04939" rel="noopener ugc nofollow" target="_blank"> 6 </a>表明<strong class="ls iu"> InceptionTime的时间复杂度与训练集大小和时间序列长度</strong>均呈线性增长，即<em class="ng"> O(n ⋅ T)！</em>总的来说，InceptionTime将TSC问题与图像分类问题放在了同一立足点上，因此探索其在工业领域的不同应用是令人兴奋的。</p><p id="21ae" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">在接下来的一篇文章中，我将讨论我如何使用InceptionTime根据不同的属性(如行业/类别、位置和绩效)对金融资产进行分类和聚类。</p><h1 id="7dc2" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">参考</h1><p id="426d" class="pw-post-body-paragraph mn mo it ls b lt lu ju mp lv lw jx mq lx mr ms mt lz mu mv mw mb mx my mz md im bi translated">[ <a class="ae nf" href="https://apps.dtic.mil/docs/citations/ADA164453" rel="noopener ugc nofollow" target="_blank"> 1 </a> ] <em class="ng">通过错误传播学习内部表示</em></p><p id="8a00" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated"><a class="ae nf" href="https://arxiv.org/abs/1809.04356" rel="noopener ugc nofollow" target="_blank">2</a><em class="ng">时间序列分类的深度学习:综述</em></p><p id="e55c" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">[ <a class="ae nf" href="https://arxiv.org/pdf/1602.01711.pdf" rel="noopener ugc nofollow" target="_blank"> 3 </a> ] <em class="ng">伟大的时间序列分类烘焙:对最近提出的算法的实验评估。扩展版</em></p><p id="1cd6" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">[ <a class="ae nf" href="https://core.ac.uk/download/pdf/77027925.pdf" rel="noopener ugc nofollow" target="_blank"> 4 </a> ] <em class="ng"> HIVE-COTE:用于时间序列分类的基于变换的集成的层次投票集合</em></p><p id="8e33" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">【<a class="ae nf" href="https://www.cs.ucr.edu/~eamonn/time_series_data/" rel="noopener ugc nofollow" target="_blank">5</a>】<em class="ng">UCR时间序列分类存档</em></p><p id="7d8b" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">[ <a class="ae nf" href="https://arxiv.org/abs/1909.04939" rel="noopener ugc nofollow" target="_blank"> 6 </a> ] <em class="ng">开始时间:寻找AlexNet进行时间序列分类</em></p><p id="92e3" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">[ <a class="ae nf" href="https://arxiv.org/pdf/1409.4842.pdf" rel="noopener ugc nofollow" target="_blank"> 7 </a> ] <em class="ng">用卷积更深入(GoogleNet) </em></p><p id="cb95" class="pw-post-body-paragraph mn mo it ls b lt na ju mp lv nb jx mq lx nc ms mt lz nd mv mw mb ne my mz md im bi translated">[ <a class="ae nf" href="https://arxiv.org/abs/1903.06602" rel="noopener ugc nofollow" target="_blank"> 8 </a> ] <em class="ng">用于时间序列分类的深度神经网络集成</em></p></div></div>    
</body>
</html>