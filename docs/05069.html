<html>
<head>
<title>Day 122 of #NLP365: NLP Papers Summary — Applying BERT to Document Retrieval with Birch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">#NLP365的第122天:NLP论文摘要——将BERT应用于Birch的文献检索</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/day-122-of-nlp365-nlp-papers-summary-applying-bert-to-document-retrieval-with-birch-766eaeac17ab?source=collection_archive---------47-----------------------#2020-05-01">https://towardsdatascience.com/day-122-of-nlp365-nlp-papers-summary-applying-bert-to-document-retrieval-with-birch-766eaeac17ab?source=collection_archive---------47-----------------------#2020-05-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div class="gh gi ir"><img src="../Images/fbe3831891625ccfa7a5401ede20b085.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NAmWzzuXHoD6w2K9Yp9p9Q.jpeg"/></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">阅读和理解研究论文就像拼凑一个未解之谜。汉斯-彼得·高斯特在<a class="ae jc" href="https://unsplash.com/s/photos/research-papers?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片。</p></figure><h2 id="fe83" class="jd je jf bd b dl jg jh ji jj jk jl dk jm translated" aria-label="kicker paragraph"><a class="ae ep" href="https://medium.com/towards-data-science/inside-ai/home" rel="noopener">内线艾</a> <a class="ae ep" href="http://towardsdatascience.com/tagged/nlp365" rel="noopener" target="_blank"> NLP365 </a></h2><div class=""/><div class=""><h2 id="ff04" class="pw-subtitle-paragraph kl jo jf bd b km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc dk translated">NLP论文摘要是我总结NLP研究论文要点的系列文章</h2></div><p id="a8d2" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">项目#NLP365 (+1)是我在2020年每天记录我的NLP学习旅程的地方。在这里，你可以随意查看我在过去的262天里学到了什么。在本文的最后，你可以找到以前的论文摘要，按自然语言处理领域分类:)</p><p id="f42f" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">今天的NLP论文是<strong class="lf jp"> <em class="lz">用Birch </em> </strong>将BERT应用于文档检索。以下是研究论文的要点。</p></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><h1 id="20ff" class="mh mi jf bd mj mk ml mm mn mo mp mq mr ku ms kv mt kx mu ky mv la mw lb mx my bi translated">目标和贡献</h1><p id="28b3" class="pw-post-body-paragraph ld le jf lf b lg mz kp li lj na ks ll lm nb lo lp lq nc ls lt lu nd lw lx ly im bi translated">Birch，一个使用BERT进行文档检索的建议系统。它与Anserini信息检索工具包集成，为大型文档集带来完整的端到端文档检索。</p><p id="4a77" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">文档检索是给定一个大的文档集合，系统应该根据用户的查询返回一组排序的文档。Lucene(以及Solr和Elasticsearch)是业界构建搜索引擎的主要平台。然而，当涉及到连接NLP和IR时，存在一个技术挑战，Lucene是用Java实现的，然而，大多数深度学习技术是用Python和C++后端实现的。</p><h1 id="3f66" class="mh mi jf bd mj mk ne mm mn mo nf mq mr ku ng kv mt kx nh ky mv la ni lb mx my bi translated">桦树</h1><figure class="nk nl nm nn gt iv gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/62ff6b23908d94db69015226b38e5b44.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/0*WxbmSpRpvGAAED5B.png"/></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">桦树的建筑[1]</p></figure><p id="84a8" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">Birch的建筑由两个阶段组成:</p><ol class=""><li id="9ac6" class="no np jf lf b lg lh lj lk lm nq lq nr lu ns ly nt nu nv nw bi translated">使用Anserini进行检索</li><li id="ca87" class="no np jf lf b lg nx lj ny lm nz lq oa lu ob ly nt nu nv nw bi translated">使用基于BERT的模型进行重新排序</li></ol><p id="bd01" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">Python是代码入口点，它使用Pyjnuis库访问Java类与Anserini集成。总的来说，Python是主要的开发语言，连接到Java虚拟机(JVM)后端进行检索。</p><p id="202f" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们针对文本的相关性分类对BERT进行了微调。给定文档D和查询Q，我们将它们连接成以下文本序列:[CLS] + Q + [SEP] + D + [SEP]。对于每个小批量，我们将序列填充到N个令牌，其中N是批量中的最大长度令牌。像往常一样，[CLS]令牌被输入到一个单层神经网络中。一个问题是，BERT不是为长文档推理而设计的，所以我们决定在每个文档的句子级别进行推理，并聚合句子级别的推理来对文档进行排序。先前的工作发现，文档中的最佳得分句子提供了文档相关性的良好代理。</p><h1 id="5eec" class="mh mi jf bd mj mk ne mm mn mo nf mq mr ku ng kv mt kx nh ky mv la ni lb mx my bi translated">检索结果</h1><p id="be5f" class="pw-post-body-paragraph ld le jf lf b lg mz kp li lj na ks ll lm nb lo lp lq nc ls lt lu nd lw lx ly im bi translated">有两个评估数据集:TREC 2011-2014微博轨迹和TREC 2004健壮轨迹。对于微博轨迹，Birch应用于一组推文。使用查询可能性和RM3相关反馈来检索初始候选集(大约100个)，使用BERT来推断整个候选文档(因为它很短，BERT可以覆盖整个文档，而不是句子级的聚合)。结果如下所示。检索的两个常见评估指标是平均精度(AP)和排名30的精度(P@30)。如图所示，Birch在基线和高级神经模型的基础上每年都有很大的进步。</p><figure class="nk nl nm nn gt iv gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/12f70b555600d62c9db47b79cfd84b7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/0*pDhitxY9eUcJ14PD.png"/></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">结果在TREC微博上追踪报道[1]</p></figure><p id="8600" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">健壮跟踪器由用于文档检索任务的新闻专线文章组成。这个数据集的另一个挑战是没有足够的数据来微调我们的BERT模型，因为相关性标签是在文档级别。先前工作的令人惊讶的发现是，尽管两个数据集在不同的领域，但用微博轨迹微调的BERT模型在新闻专线文章排名方面工作得很好。BERT能够学习在不同领域的句子级别上建立相关性模型，这已被证明对新闻专线文章的排名是有用的。对于稳健的跟踪，我们用MARCO女士和微博数据对BERT进行了微调，结果如下所示。我们将BERT的分数与文档分数(BM25 + RM3)结合起来。1-3指的是将前1-3个句子的得分相加。总的来说，结果表明我们可以通过预测句子级别的相关性来准确地对文档进行排序。</p><figure class="nk nl nm nn gt iv gh gi paragraph-image"><div class="gh gi od"><img src="../Images/9971c73ff862194367ad5771af923402.png" data-original-src="https://miro.medium.com/v2/resize:fit:650/format:webp/0*PHvzLZd8kX90lJZp.png"/></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">Robust04的结果[1]</p></figure><h1 id="cf35" class="mh mi jf bd mj mk ne mm mn mo nf mq mr ku ng kv mt kx nh ky mv la ni lb mx my bi translated">结论和未来工作</h1><p id="e42a" class="pw-post-body-paragraph ld le jf lf b lg mz kp li lj na ks ll lm nb lo lp lq nc ls lt lu nd lw lx ly im bi translated">通过句子级推理和分数聚合，该系统架构使用BERT对文档进行排序。我们已经成功地将PyTorch与Java虚拟机后端集成在一起，允许研究人员在他们熟悉的环境中进行代码开发。</p><h2 id="0050" class="oe mi jf bd mj of og dn mn oh oi dp mr lm oj ok mt lq ol om mv lu on oo mx jl bi translated">来源:</h2><p id="6807" class="pw-post-body-paragraph ld le jf lf b lg mz kp li lj na ks ll lm nb lo lp lq nc ls lt lu nd lw lx ly im bi translated">[1]，张志安，王，杨，张，林，2019年11月.BERT在birch文献检索中的应用。在<em class="lz">2019自然语言处理经验方法会议暨第九届国际自然语言处理联合会议(EMNLP-IJCNLP)论文集:系统演示</em>(第19–24页)。</p><p id="381e" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><em class="lz">原载于2020年5月1日</em><a class="ae jc" href="https://ryanong.co.uk/2020/05/01/day-122-nlp-papers-summary-applying-bert-to-document-retrieval-with-birch/" rel="noopener ugc nofollow" target="_blank"><em class="lz">【https://ryanong.co.uk】</em></a><em class="lz">。</em></p></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><h1 id="7349" class="mh mi jf bd mj mk ml mm mn mo mp mq mr ku ms kv mt kx mu ky mv la mw lb mx my bi translated">特征提取/基于特征的情感分析</h1><ul class=""><li id="d60c" class="no np jf lf b lg mz lj na lm op lq oq lu or ly os nu nv nw bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-102-of-nlp365-nlp-papers-summary-implicit-and-explicit-aspect-extraction-in-financial-bdf00a66db41">https://towards data science . com/day-102-of-NLP 365-NLP-papers-summary-implicit-and-explicit-aspect-extraction-in-financial-BDF 00 a 66 db 41</a></li><li id="eef4" class="no np jf lf b lg nx lj ny lm nz lq oa lu ob ly os nu nv nw bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-103-nlp-research-papers-utilizing-bert-for-aspect-based-sentiment-analysis-via-constructing-38ab3e1630a3">https://towards data science . com/day-103-NLP-research-papers-utilizing-Bert-for-aspect-based-sense-analysis-via-construction-38ab 3e 1630 a3</a></li><li id="ddc5" class="no np jf lf b lg nx lj ny lm nz lq oa lu ob ly os nu nv nw bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-104-of-nlp365-nlp-papers-summary-sentihood-targeted-aspect-based-sentiment-analysis-f24a2ec1ca32">https://towards data science . com/day-104-of-NLP 365-NLP-papers-summary-senthious-targeted-aspect-based-sensitive-analysis-f 24 a2 EC 1 ca 32</a></li><li id="7c15" class="no np jf lf b lg nx lj ny lm nz lq oa lu ob ly os nu nv nw bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-105-of-nlp365-nlp-papers-summary-aspect-level-sentiment-classification-with-3a3539be6ae8">https://towards data science . com/day-105-of-NLP 365-NLP-papers-summary-aspect-level-sensation-class ification-with-3a 3539 be 6 AE 8</a></li><li id="8a96" class="no np jf lf b lg nx lj ny lm nz lq oa lu ob ly os nu nv nw bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-106-of-nlp365-nlp-papers-summary-an-unsupervised-neural-attention-model-for-aspect-b874d007b6d0">https://towards data science . com/day-106-of-NLP 365-NLP-papers-summary-an-unsupervised-neural-attention-model-for-aspect-b 874d 007 b 6d 0</a></li><li id="961b" class="no np jf lf b lg nx lj ny lm nz lq oa lu ob ly os nu nv nw bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-110-of-nlp365-nlp-papers-summary-double-embeddings-and-cnn-based-sequence-labelling-for-b8a958f3bddd">https://towards data science . com/day-110-of-NLP 365-NLP-papers-summary-double-embedding-and-CNN-based-sequence-labeling-for-b8a 958 F3 bddd</a></li><li id="32e2" class="no np jf lf b lg nx lj ny lm nz lq oa lu ob ly os nu nv nw bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-112-of-nlp365-nlp-papers-summary-a-challenge-dataset-and-effective-models-for-aspect-based-35b7a5e245b5">https://towards data science . com/day-112-of-NLP 365-NLP-papers-summary-a-challenge-dataset-and-effective-models-for-aspect-based-35b 7 a5 e 245 b5</a></li></ul><h1 id="7332" class="mh mi jf bd mj mk ne mm mn mo nf mq mr ku ng kv mt kx nh ky mv la ni lb mx my bi translated">总结</h1><ul class=""><li id="e1b0" class="no np jf lf b lg mz lj na lm op lq oq lu or ly os nu nv nw bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-107-of-nlp365-nlp-papers-summary-make-lead-bias-in-your-favor-a-simple-and-effective-4c52b1a569b8">https://towards data science . com/day-107-of-NLP 365-NLP-papers-summary-make-lead-bias-in-your-favor-a-simple-effective-4c 52 B1 a 569 b 8</a></li><li id="c21e" class="no np jf lf b lg nx lj ny lm nz lq oa lu ob ly os nu nv nw bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-109-of-nlp365-nlp-papers-summary-studying-summarization-evaluation-metrics-in-the-619f5acb1b27">https://towards data science . com/day-109-of-NLP 365-NLP-papers-summary-studing-summary-evaluation-metrics-in-the-619 F5 acb1 b 27</a></li><li id="815c" class="no np jf lf b lg nx lj ny lm nz lq oa lu ob ly os nu nv nw bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-113-of-nlp365-nlp-papers-summary-on-extractive-and-abstractive-neural-document-87168b7e90bc">https://towards data science . com/day-113-of-NLP 365-NLP-papers-summary-on-extractive-and-abstract-neural-document-87168 b 7 e 90 BC</a></li><li id="79ba" class="no np jf lf b lg nx lj ny lm nz lq oa lu ob ly os nu nv nw bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-116-of-nlp365-nlp-papers-summary-data-driven-summarization-of-scientific-articles-3fba016c733b">https://towards data science . com/day-116-of-NLP 365-NLP-papers-summary-data-driven-summary-of-scientific-articles-3 FBA 016 c 733 b</a></li><li id="388a" class="no np jf lf b lg nx lj ny lm nz lq oa lu ob ly os nu nv nw bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-117-of-nlp365-nlp-papers-summary-abstract-text-summarization-a-low-resource-challenge-61ae6cdf32f">https://towards data science . com/day-117-of-NLP 365-NLP-papers-summary-abstract-text-summary-a-low-resource-challenge-61a E6 CDF 32 f</a></li><li id="a03a" class="no np jf lf b lg nx lj ny lm nz lq oa lu ob ly os nu nv nw bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-118-of-nlp365-nlp-papers-summary-extractive-summarization-of-long-documents-by-combining-aea118a5eb3f">https://towards data science . com/day-118-of-NLP 365-NLP-papers-summary-extractive-summary-of-long-documents-by-combining-AEA 118 a5 eb3f</a></li><li id="1088" class="no np jf lf b lg nx lj ny lm nz lq oa lu ob ly os nu nv nw bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-120-of-nlp365-nlp-papers-summary-a-simple-theoretical-model-of-importance-for-summarization-843ddbbcb9b">https://towards data science . com/day-120-of-NLP 365-NLP-papers-summary-a-simple-theory-model-of-importance-for-summary-843 ddbcb 9b</a></li><li id="f5a7" class="no np jf lf b lg nx lj ny lm nz lq oa lu ob ly os nu nv nw bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-121-of-nlp365-nlp-papers-summary-concept-pointer-network-for-abstractive-summarization-cd55e577f6de">https://towards data science . com/day-121-of-NLP 365-NLP-papers-summary-concept-pointer-network-for-abstract-summary-cd55e 577 F6 de</a></li></ul><h1 id="249f" class="mh mi jf bd mj mk ne mm mn mo nf mq mr ku ng kv mt kx nh ky mv la ni lb mx my bi translated">其他人</h1><ul class=""><li id="eb3f" class="no np jf lf b lg mz lj na lm op lq oq lu or ly os nu nv nw bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-108-of-nlp365-nlp-papers-summary-simple-bert-models-for-relation-extraction-and-semantic-98f7698184d7">https://towards data science . com/day-108-of-NLP 365-NLP-papers-summary-simple-Bert-models-for-relation-extraction-and-semantic-98f 7698184 D7</a></li><li id="2d14" class="no np jf lf b lg nx lj ny lm nz lq oa lu ob ly os nu nv nw bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-111-of-nlp365-nlp-papers-summary-the-risk-of-racial-bias-in-hate-speech-detection-bff7f5f20ce5">https://towards data science . com/day-111-of-NLP 365-NLP-papers-summary-the-risk-of-race-of-bias-in-hate-speech-detection-BFF 7 F5 f 20 ce 5</a></li><li id="ac91" class="no np jf lf b lg nx lj ny lm nz lq oa lu ob ly os nu nv nw bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-115-of-nlp365-nlp-papers-summary-scibert-a-pretrained-language-model-for-scientific-text-185785598e33">https://towards data science . com/day-115-of-NLP 365-NLP-papers-summary-scibert-a-pre trained-language-model-for-scientific-text-185785598 e33</a></li><li id="843e" class="no np jf lf b lg nx lj ny lm nz lq oa lu ob ly os nu nv nw bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-119-nlp-papers-summary-an-argument-annotated-corpus-of-scientific-publications-d7b9e2ea1097">https://towards data science . com/day-119-NLP-papers-summary-an-argument-annoted-corpus-of-scientific-publications-d 7 b 9 e 2e ea 1097</a></li></ul></div></div>    
</body>
</html>