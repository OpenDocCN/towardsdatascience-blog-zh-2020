<html>
<head>
<title>Automated Data Collection From Yahoo Finance With Selenium, Pygsheets</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Selenium、Pygsheets 从 Yahoo Finance 自动收集数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/automated-data-collection-from-yahoo-finance-with-selenium-pygsheets-126539999d72?source=collection_archive---------24-----------------------#2020-01-31">https://towardsdatascience.com/automated-data-collection-from-yahoo-finance-with-selenium-pygsheets-126539999d72?source=collection_archive---------24-----------------------#2020-01-31</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/ea2b6e5bc0faced91fe61bab51c21f1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VFmq4UFVi2jPxL0XtVgOtA@2x.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">Alexandre Debiève 在<a class="ae jd" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片。</p></figure><div class=""/><div class=""><h2 id="43e3" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">将数据收集掌握在自己手中的简单方法</h2></div></div><div class="ab cl kv kw hu kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="ij ik il im in"><blockquote class="lc ld le"><p id="ced2" class="lf lg lh li b lj lk kh ll lm ln kk lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">最近，我一直在学习技术交易，以及算法如何帮助投资者做出高效和有效的决策。鉴于人工智能和机器学习在金融领域日益突出，我认为值得研究学生和年轻专业人士如何参与进来。在接下来的文章中，我将概述我在获取数据、清理数据和在 Google Sheets 中托管数据时采取的最初步骤。</p></blockquote></div><div class="ab cl kv kw hu kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="ij ik il im in"><h1 id="b46e" class="mc md jg bd me mf mg mh mi mj mk ml mm km mn kn mo kp mp kq mq ks mr kt ms mt bi translated">概观</h1><p id="3041" class="pw-post-body-paragraph lf lg jg li b lj mu kh ll lm mv kk lo mw mx lr ls my mz lv lw na nb lz ma mb ij bi translated">在这个项目的最初步骤中，我想找到一种方法来自动收集历史数据，确保它清晰易懂，并将其附加到 google 工作表中。由于我正在收集 50 只股票的数据，我知道我不想手动点击雅虎财经，改变日期范围过滤器，并下载数据 50 次。为了实现自动化，我决定使用 Selenium (webdriver、Keys 和 By)、Pandas 和 time 库。<em class="lh"> Yfinance </em>是一个允许与雅虎财经轻松互动的 API，但我认为自己尝试自动化数据收集将是一个有趣而富有挑战性的项目。</p><h1 id="2c5a" class="mc md jg bd me mf nc mh mi mj nd ml mm km ne kn mo kp nf kq mq ks ng kt ms mt bi translated">第一步</h1><p id="4b82" class="pw-post-body-paragraph lf lg jg li b lj mu kh ll lm mv kk lo mw mx lr ls my mz lv lw na nb lz ma mb ij bi translated">首先，我必须决定要收集哪些股票的数据。为了做到这一点，我利用了我的<a class="ae jd" href="http://www.robinhood.com" rel="noopener ugc nofollow" target="_blank"> Robinhood </a>账户中的“观察列表”。在过去的两年里，我花了一些空闲时间交易、研究和测试某些策略。在整个过程中，我收集了有价值的反馈，帮助我了解了股票市场中什么可行(什么不可行)的开端。下面是我的股票代码清单的代码片段:</p><figure class="ni nj nk nl gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nh"><img src="../Images/09f880aebf95fa2b6ad02eb556b65ba4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0V0lGw2NntbgHYPbjT2w7g.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">有了这个列表，我将能够使用股票代码在雅虎财经上搜索正确的股票，获取其历史数据，然后将其下载到我的电脑上。</p></figure><h1 id="c39c" class="mc md jg bd me mf nc mh mi mj nd ml mm km ne kn mo kp nf kq mq ks ng kt ms mt bi translated">第二步</h1><p id="92fc" class="pw-post-body-paragraph lf lg jg li b lj mu kh ll lm mv kk lo mw mx lr ls my mz lv lw na nb lz ma mb ij bi translated">我决定使用一个“while”循环来遍历列表中的每个值。在这个循环中，我将执行三个步骤:</p><ol class=""><li id="0ca9" class="nm nn jg li b lj lk lm ln mw no my np na nq mb nr ns nt nu bi translated"><strong class="li jh">首先</strong>，我将设置我的 web 驱动程序，并利用 selenium 抓取雅虎财经搜索栏，搜索正确的股票代码。在整个过程中，我将利用<strong class="li jh"> time.sleep() </strong>来说明缓慢的 WiFi 和/或需要一段时间才能在浏览器中编译的进程。下面的代码片段突出了我用来完成第 1 部分的代码:</li></ol><figure class="ni nj nk nl gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nv"><img src="../Images/d83bf50ef9752c5fc0574fe4882b6289.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BkRBMxhwZXChgnuNt75bCg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">构建自动化数据收集算法的第一部分</p></figure><p id="21a2" class="pw-post-body-paragraph lf lg jg li b lj lk kh ll lm ln kk lo mw lq lr ls my lu lv lw na ly lz ma mb ij bi translated">2.<strong class="li jh">第二个</strong>，我会切换到“历史数据”标签页。然后，我将单击日期范围过滤器，将其切换到 5 年，并单击“完成”和“应用”span 元素以应用更改。</p><figure class="ni nj nk nl gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nw"><img src="../Images/2482be4137ee6070069e0b5b3df71bb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y8qEb2AomEWHem8DrdYhAw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">构建自动化数据收集算法的第二部分</p></figure><p id="e468" class="pw-post-body-paragraph lf lg jg li b lj lk kh ll lm ln kk lo mw lq lr ls my lu lv lw na ly lz ma mb ij bi translated">3.<strong class="li jh">最后，</strong>我将单击“下载数据”span 元素，等待 15 秒钟，让文件完全下载到我的计算机上，然后关闭我的 web 驱动程序。在这之后，我将“I”加 1，继续到列表中的下一个索引。这个循环将一直持续到我列表中的最后一只股票。</p><figure class="ni nj nk nl gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nx"><img src="../Images/ba5d04381c585a9595af6d1d28727fd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5UhY6VXDz7qhM3mE1gH4_g.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">构建自动化数据收集算法的第三部分</p></figure><h1 id="d970" class="mc md jg bd me mf nc mh mi mj nd ml mm km ne kn mo kp nf kq mq ks ng kt ms mt bi translated">第三步</h1><p id="3510" class="pw-post-body-paragraph lf lg jg li b lj mu kh ll lm mv kk lo mw mx lr ls my mz lv lw na nb lz ma mb ij bi translated">在使用<a class="ae jd" href="https://pygsheets.readthedocs.io/en/stable/#" rel="noopener ugc nofollow" target="_blank"> pygsheets </a>将这些 CSV 文件读入 google sheets 后，我们有了一个如下所示的数据集:</p><div class="ip iq gp gr ir ny"><a href="https://docs.google.com/spreadsheets/d/1VJbaZoem-XFa_uboQfJHVvx64ryOseM0sJvWN7PJXB0/edit?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="nz ab fo"><div class="oa ab ob cl cj oc"><h2 class="bd jh gy z fp od fr fs oe fu fw jf bi translated">股票</h2><div class="of l"><h3 class="bd b gy z fp od fr fs oe fu fw dk translated">TSLA 日期，开盘，盘高，盘低，收盘，调整收盘，成交量 2020-01-03，440.5，454，436.920013，443.01001，443.01777774856</h3></div><div class="og l"><p class="bd b dl z fp od fr fs oe fu fw dk translated">docs.google.com</p></div></div><div class="oh l"><div class="oi l oj ok ol oh om ix ny"/></div></div></a></div><p id="7f21" class="pw-post-body-paragraph lf lg jg li b lj lk kh ll lm ln kk lo mw lq lr ls my lu lv lw na ly lz ma mb ij bi translated">这个数据集的维度可以用我们 Jupyter 笔记本中的几行代码来验证:</p><figure class="ni nj nk nl gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi on"><img src="../Images/3546f7ec13170b038fc97ce1690050c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7zc0q-MVa8VauYfdaIqDmQ.png"/></div></div></figure><p id="9774" class="pw-post-body-paragraph lf lg jg li b lj lk kh ll lm ln kk lo mw lq lr ls my lu lv lw na ly lz ma mb ij bi translated">虽然为我们的股票列表收集了 5 年的历史数据，但我将在下一篇文章中更进一步(我将编写一个 python 脚本，每天运行它来自动收集数据)。</p></div><div class="ab cl kv kw hu kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="ij ik il im in"><p id="65d0" class="pw-post-body-paragraph lf lg jg li b lj lk kh ll lm ln kk lo mw lq lr ls my lu lv lw na ly lz ma mb ij bi translated">**补充说明:使用 selenium 有一种更简单的方法，通过用股票符号格式化 url 来直接进入历史数据页面。我还将在下一篇文章中介绍这一点(我决定不在本文中使用它，因为纯粹是为了挑战用 selenium 一页一页地浏览网站。**</p></div></div>    
</body>
</html>