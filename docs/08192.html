<html>
<head>
<title>Understanding Parameter Sharing (or weights replication) Within Convolutional Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解卷积神经网络中的参数共享(或权重复制)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-parameter-sharing-or-weights-replication-within-convolutional-neural-networks-cc26db7b645a?source=collection_archive---------4-----------------------#2020-06-16">https://towardsdatascience.com/understanding-parameter-sharing-or-weights-replication-within-convolutional-neural-networks-cc26db7b645a?source=collection_archive---------4-----------------------#2020-06-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="3ebf" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">技术和解释</h2><div class=""/><div class=""><h2 id="ea8a" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">参数共享或权重复制是深度学习研究中可以忽略的主题领域。理解这个简单的概念有助于更广泛地理解卷积神经网络的内部结构。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/dff5e8c0978f8f0c795af218ee1bffd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M-79Q9XHQqjxjPm9GW9IHA.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">亨特·哈里特在<a class="ae lh" href="/s/photos/machine-learning?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="96f7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">卷积神经网络(CNN)具有能够对通过网络馈送的图像的仿射变换保持不变的特性。这提供了识别图像中偏移、倾斜或轻微扭曲的图案的能力。</p><p id="fecb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">由于 CNN 架构的三个主要属性，引入了仿射不变性的这些特征。</p><ol class=""><li id="744a" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated"><a class="ae lh" rel="noopener" target="_blank" href="/understand-local-receptive-fields-in-convolutional-neural-networks-f26d700be16c">局部感受野</a></li><li id="2b0b" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated"><strong class="lk jd">共享权重(参数共享)</strong></li><li id="ff11" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">空间子采样</li></ol><p id="41db" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在本文中，我们将探索<strong class="lk jd">共享权重</strong>并理解它们的目的以及它们在 CNN 架构中的优势。</p><blockquote class="ms"><p id="324f" class="mt mu it bd mv mw mx my mz na nb md dk translated">这篇文章面向所有水平的练习机器学习或更具体地说深度学习的个人。</p></blockquote><h1 id="7c2a" class="nc nd it bd ne nf ng nh ni nj nk nl nm ki nn kj no kl np km nq ko nr kp ns nt bi translated">介绍</h1><p id="2731" class="pw-post-body-paragraph li lj it lk b ll nu kd ln lo nv kg lq lr nw lt lu lv nx lx ly lz ny mb mc md im bi translated">让我们首先在脑海中创建一个 CNN 中单个卷积层的图示。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nz"><img src="../Images/34c6a67f148cb770f2acc5478d4c26c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6h_0SQxFEFBV6NW1_ogPSg.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">由<a class="ae lh" href="https://unsplash.com/@herfrenchness?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Clarisse Croset </a>在<a class="ae lh" href="/s/photos/machine-learning?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="5b18" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">CNN 中的卷积层(<em class="oa"> conv 层</em>)包含一组单元，也可以称为神经元。</p><p id="3de2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">conv 层还包括层内的几个过滤器，这是一个预定义的超参数。</p><p id="bee7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">层内的过滤器的数量指示由 conv 层创建的作为下一层的输入的激活/特征地图的输出体积的深度维度。</p><p id="679d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些过滤器中的每一个都具有设定的宽度和高度，其对应于该层中单个单元的局部感受野。作用于输入数据的过滤器产生卷积层的输出，即特征图。</p><p id="6bb6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在 CNN 的训练阶段，滤波器内的权重值是可学习的。卷积层的输出维度具有深度分量，如果我们划分输出的每个片段，我们将获得特征图的 2D 平面。在单个 2D 平面上使用的滤波器包含由在同一平面上使用的所有滤波器共享的权重。</p><p id="db19" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这样做的好处是，我们可以在输入数据的其他部分保持在输入数据的一部分中使用的相同特征检测器。</p><p id="625b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">卷积层的输出是一组特征图，其中每个特征图是单元内的固定权重参数和输入数据之间的卷积运算的结果。</p><p id="d070" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">卷积神经网络层的一个基本特征是其特征图能够反映对通过输入层输入的输入图像进行的任何仿射变换。</p><p id="aaf3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，对输入数据进行的任何移动、倾斜或定向，要素地图都会提供一个输出，该输出会根据输入数据所受的量进行移动、倾斜或定向。</p></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><h1 id="3ea2" class="nc nd it bd ne nf oi nh ni nj oj nl nm ki ok kj no kl ol km nq ko om kp ns nt bi translated">将理论付诸实践</h1><p id="d111" class="pw-post-body-paragraph li lj it lk b ll nu kd ln lo nv kg lq lr nw lt lu lv nx lx ly lz ny mb mc md im bi translated">本节的目标是揭示卷积神经网络中出现的权重共享的好处。</p><p id="a50e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将在两种流行的 CNN 架构的第一卷积层中，推导出不具有权重共享和具有权重共享的可训练权重的数量:<a class="ae lh" href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf" rel="noopener ugc nofollow" target="_blank"> LeNet </a>和<a class="ae lh" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" rel="noopener ugc nofollow" target="_blank"> AlexNet </a>。</p><h2 id="2a72" class="on nd it bd ne oo op dn ni oq or dp nm lr os ot no lv ou ov nq lz ow ox ns iz bi translated">下面是要采取的步骤:</h2><ol class=""><li id="be96" class="me mf it lk b ll nu lo nv lr oy lv oz lz pa md mj mk ml mm bi translated"><strong class="lk jd">获得 conv 图层的输出宽度</strong></li></ol><p id="d47c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">(输入大小宽度—滤波器大小+(2 *填充)/步距)+ 1 =卷积层的输出宽度</p><p id="5774" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">2.<strong class="lk jd">计算 conv 层内神经元/单元的数量</strong></p><p id="b877" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">3.<strong class="lk jd">计算不带权重分配的训练参数(包括偏差)的数量</strong></p><p id="0c17" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">4.<strong class="lk jd">计算权重分配的训练参数数量(包括偏差)</strong></p><blockquote class="pb pc pd"><p id="2f7a" class="li lj oa lk b ll lm kd ln lo lp kg lq pe ls lt lu pf lw lx ly pg ma mb mc md im bi translated">下表描述了来自 AlexNet 和 LeNet CNN 架构的信息将用于导出卷积层内的训练参数/权重的数量。</p></blockquote><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ph"><img src="../Images/b46cff52859384fa8f2ee126bf466534.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oW8gp8HQlDT0tOnT60jx8Q.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">显示 CNN 架构的不完整属性的表格</p></figure><h2 id="2533" class="on nd it bd ne oo op dn ni oq or dp nm lr os ot no lv ou ov nq lz ow ox ns iz bi translated">AlexNet</h2><ol class=""><li id="5280" class="me mf it lk b ll nu lo nv lr oy lv oz lz pa md mj mk ml mm bi translated"><strong class="lk jd">conv 图层输出宽度:</strong></li></ol><p id="508d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="oa">=((227–11)/4)+1</em></p><p id="f847" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="oa">=</em><strong class="lk jd"><em class="oa">55</em></strong><em class="oa">(conv 图层输出宽度)</em></p><p id="5190" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">2.<strong class="lk jd">conv 层内神经元/单位的数量</strong></p><p id="59b4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="oa"> =输出高度*输出宽度*特征地图数量</em></p><p id="87ab" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="oa"> = 55x55x96 (conv 输出音量)</em></p><p id="e510" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="oa">=</em><strong class="lk jd"><em class="oa">29.04 万辆</em> </strong></p><p id="5d71" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">3.<strong class="lk jd">conv 层内训练参数或权重的数量(无权重分配)</strong></p><p id="0d67" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="oa">= 290400 *(11 * 11 * 3)+1 偏置)</em></p><p id="d75c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="oa">=‭</em><strong class="lk jd"><em class="oa">105,415,600‬</em></strong></p><p id="f8bb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">4.<strong class="lk jd">具有重量共享的训练参数或重量的数量(具有重量共享)</strong></p><p id="be31" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="oa">= 96 *(11 * 11 * 3)+1 偏置)</em></p><h2 id="b02f" class="on nd it bd ne oo op dn ni oq or dp nm lr os ot no lv ou ov nq lz ow ox ns iz bi translated">= 34，944 重量</h2><h2 id="aef7" class="on nd it bd ne oo op dn ni oq or dp nm lr os ot no lv ou ov nq lz ow ox ns iz bi translated">LeNet</h2><ol class=""><li id="f4c4" class="me mf it lk b ll nu lo nv lr oy lv oz lz pa md mj mk ml mm bi translated"><strong class="lk jd">conv 图层输出宽度:</strong></li></ol><p id="f2a2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="oa">=((28–5)/1)+1</em></p><p id="9205" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="oa">=</em><strong class="lk jd"><em class="oa">24</em></strong><em class="oa">(conv 图层输出宽度)</em></p><p id="d449" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">2.<strong class="lk jd">conv 层内神经元/单元的数量</strong></p><p id="e0a5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="oa"> =输出高度*输出宽度*特征地图数量</em></p><p id="3078" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="oa"> = 24x24x6 (conv 输出音量)</em></p><p id="7245" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="oa"> = </em> <strong class="lk jd"> <em class="oa">三千四百五十六台</em> </strong></p><p id="3866" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">3.<strong class="lk jd">conv 层内的训练参数或权重的数量(没有权重共享)</strong></p><p id="c54a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="oa">= 3456 *(5 * 5 * 1)+1 偏差)</em></p><p id="e6dd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="oa">=‭</em><strong class="lk jd"><em class="oa">89,856‬</em></strong></p><p id="b35c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">4.<strong class="lk jd">具有重量共享的训练参数或重量的数量(具有重量共享)</strong></p><p id="3cf9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="oa">= 6 *(5 * 5 * 1)+1 偏置)</em></p><h2 id="6900" class="on nd it bd ne oo op dn ni oq or dp nm lr os ot no lv ou ov nq lz ow ox ns iz bi translated">= 156 重量</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pi"><img src="../Images/1639e0b2dd958745f48f06e080191673.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jSWQPjQ6YuL5Zn3zaS8xxA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">显示 CNN 架构完整属性的表格</p></figure></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><h1 id="dab2" class="nc nd it bd ne nf oi nh ni nj oj nl nm ki ok kj no kl ol km nq ko om kp ns nt bi translated">让我们一起来。</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pj"><img src="../Images/6b6cb332f4f5e1b18e3b34352c11f2ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MAYvQkafAsbLpBeWA2wVwg.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">克林特·王茂林在<a class="ae lh" href="/s/photos/connection?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="04a4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">很明显，通过参数共享，我们可以减少 conv 层中的权重数量。</p><p id="533b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">参数共享用于网络内的所有 conv 层。</p><p id="1379" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">参数共享减少了训练时间；这是减少反向传播期间必须发生的权重更新次数的直接优点。</p><p id="f88e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">重申参数共享发生在从过滤器和来自 conv 层中的平面内的单元的输入数据之间的卷积结果生成特征图时。该层平面内的所有单元共享相同的权重；因此，它被称为权重/参数共享。</p></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><h1 id="4cf2" class="nc nd it bd ne nf oi nh ni nj oj nl nm ki ok kj no kl ol km nq ko om kp ns nt bi translated">我希望这篇文章对你有用。</h1><p id="4987" class="pw-post-body-paragraph li lj it lk b ll nu kd ln lo nv kg lq lr nw lt lu lv nx lx ly lz ny mb mc md im bi translated">要联系我或找到更多类似本文的内容，请执行以下操作:</p><ol class=""><li id="f43a" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">订阅我的<a class="ae lh" href="https://www.youtube.com/channel/UCNNYpuGCrihz_YsEpZjo8TA" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd"> YouTube 频道</strong> </a>即将上线的视频内容<a class="ae lh" href="https://www.youtube.com/channel/UCNNYpuGCrihz_YsEpZjo8TA" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd">这里</strong> </a></li><li id="d701" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">跟我上<a class="ae lh" href="https://medium.com/@richmond.alake" rel="noopener"> <strong class="lk jd">中</strong> </a></li><li id="7e2f" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">通过<a class="ae lh" href="https://www.linkedin.com/in/richmondalake/" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd"> LinkedIn </strong> </a>联系我</li></ol></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><div class="ks kt ku kv gt pk"><a rel="noopener follow" target="_blank" href="/understand-local-receptive-fields-in-convolutional-neural-networks-f26d700be16c"><div class="pl ab fo"><div class="pm ab pn cl cj po"><h2 class="bd jd gy z fp pp fr fs pq fu fw jc bi translated">理解卷积神经网络中的局部感受野</h2><div class="pr l"><h3 class="bd b gy z fp pp fr fs pq fu fw dk translated">想过为什么卷积神经网络中的所有神经元都没有连接起来吗？</h3></div><div class="ps l"><p class="bd b dl z fp pp fr fs pq fu fw dk translated">towardsdatascience.com</p></div></div><div class="pt l"><div class="pu l pv pw px pt py lb pk"/></div></div></a></div><div class="pz qa gp gr qb pk"><a rel="noopener follow" target="_blank" href="/what-a-masters-in-machine-learning-wont-teach-you-b84e5aac8837"><div class="pl ab fo"><div class="pm ab pn cl cj po"><h2 class="bd jd gy z fp pp fr fs pq fu fw jc bi translated">机器学习硕士(不会)教你什么</h2><div class="pr l"><h3 class="bd b gy z fp pp fr fs pq fu fw dk translated">关于攻读机器学习高级学位的常见误解</h3></div><div class="ps l"><p class="bd b dl z fp pp fr fs pq fu fw dk translated">towardsdatascience.com</p></div></div><div class="pt l"><div class="qc l pv pw px pt py lb pk"/></div></div></a></div></div></div>    
</body>
</html>