<html>
<head>
<title>Search COVID papers with Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用深度学习搜索COVID论文</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/search-in-covid-papers-with-deep-learning-a3c14a61f501?source=collection_archive---------48-----------------------#2020-04-27">https://towardsdatascience.com/search-in-covid-papers-with-deep-learning-a3c14a61f501?source=collection_archive---------48-----------------------#2020-04-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0c9b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated"><em class="ki">一个</em>语义<em class="ki">浏览器使用深度学习和弹性搜索来搜索COVID论文</em></h2></div><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi kj"><img src="../Images/d58bf6097d752b267d728d4fcfcac381.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rGzaywXfT2t2t-t8"/></div></div></figure><p id="95f8" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">今天，我们将使用深度学习建立一个语义浏览器，在超过5万篇关于最近新冠肺炎病的论文中进行搜索。</p><p id="1507" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">所有代码都在我的GitHub <a class="ae lr" href="https://github.com/FrancescoSaverioZuppichini/Search-COVID-papers-with-Deep-Learning" rel="noopener ugc nofollow" target="_blank"> repo </a>上。而这篇文章的现场版是<a class="ae lr" href="https://github.com/FrancescoSaverioZuppichini/Search-COVID-papers-with-Deep-Learning/blob/develop/tutorial.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a></p><p id="1445" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">其核心思想是将每篇论文编码成一个表示其语义内容的向量，然后使用查询和所有编码文档之间的余弦相似性进行搜索。这与图像浏览器(例如Google Images)搜索相似图像的过程相同。</p><p id="f54c" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">因此，我们的难题由三部分组成:数据、从论文到向量的映射以及搜索方法。</p><p id="d969" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">大部分工作都是基于这个项目，在这个项目中，我和来自意大利的里雅斯特大学的学生一起工作。此处有现场演示<a class="ae lr" href="http://covidbrowser.areasciencepark.it/" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="59f6" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们开始吧！</p><h1 id="f65e" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">数据</h1><p id="abc1" class="pw-post-body-paragraph kv kw it kx b ky mk ju la lb ml jx ld le mm lg lh li mn lk ll lm mo lo lp lq im bi translated">一切从数据开始。我们将使用来自Kaggle的数据集。由白宫和领先研究团体联盟准备的超过57，000篇学术文章的列表。实际上，我们唯一需要的文件是包含论文信息和摘要全文的<code class="fe mp mq mr ms b">metadata.csv</code>。您需要将文件存储在<code class="fe mp mq mr ms b">./dataset</code>中。</p><p id="95eb" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">让我们来看看</p><pre class="kk kl km kn gt mt ms mu mv aw mw bi"><span id="0119" class="mx lt it ms b gy my mz l na nb">import pandas as pd</span><span id="a00b" class="mx lt it ms b gy nc mz l na nb">df = pd.read_csv('./dataset/metadata.csv')</span><span id="f98c" class="mx lt it ms b gy nc mz l na nb">df.head(5)</span></pre><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi nd"><img src="../Images/8c53887c44ce34f97dc059370821dd23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*oDGR1uvVOO4jqaJJ"/></div></div></figure><p id="dedc" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">如你所见，我们有很多信息。我们显然对文本栏感兴趣。和熊猫一起工作并不理想，所以让我们创造一个<code class="fe mp mq mr ms b">Dataset</code>。这将允许我们稍后创建一个<code class="fe mp mq mr ms b">DataLoader</code>来执行分批编码。如果你不熟悉Pytorch数据加载生态系统，你可以在这里阅读更多关于<a class="ae lr" href="https://pytorch.org/tutorials/beginner/data_loading_tutorial.html" rel="noopener ugc nofollow" target="_blank">的内容</a></p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ne"><img src="../Images/78845f975723fedbef0f5aba3bbea194.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*amePkoNGTMf6jv4jVc7cDA.png"/></div></div></figure><p id="708a" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">按照顺序，我子类化了<code class="fe mp mq mr ms b">torch.utils.data.Dataset</code>来创建一个定制数据集。数据集需要一个dataframe作为输入，我们只保留了感兴趣的列。然后，我们删除了一些行，其中的<code class="fe mp mq mr ms b">abstract</code>和<code class="fe mp mq mr ms b">title</code>列分别与<code class="fe mp mq mr ms b">FILTER_TITLE</code>和<code class="fe mp mq mr ms b">FILTER_ABSTRACT</code>中的一个“垃圾”单词相匹配。这样做是因为文章以自动的方式被废弃，并且许多文章有不相关的条目而不是标题/摘要信息。</p><p id="2c77" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">数据集返回一个字典，因为PyTorch不支持<code class="fe mp mq mr ms b">pd.DataFrame</code>类型。为了给我们的搜索引擎更多的上下文，我们将<code class="fe mp mq mr ms b">title</code>和<code class="fe mp mq mr ms b">abstract</code>合并在一起，结果存储在<code class="fe mp mq mr ms b">title_abstract</code>键中。</p><p id="71af" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们现在可以调用数据集，看看是否一切都是正确的</p><pre class="kk kl km kn gt mt ms mu mv aw mw bi"><span id="47ba" class="mx lt it ms b gy my mz l na nb">ds = CovidPapersDataset.from_path('./dataset/metadata.csv')</span><span id="a0ff" class="mx lt it ms b gy nc mz l na nb">ds[0]['title']</span></pre><p id="43db" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">输出:</p><p id="d3c9" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><code class="fe mp mq mr ms b">'Sequence requirements for RNA strand transfer during nidovirus discontinuous subgenomic RNA synthesis'</code></p><h1 id="7158" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">把…嵌入</h1><p id="ee2c" class="pw-post-body-paragraph kv kw it kx b ky mk ju la lb ml jx ld le mm lg lh li mn lk ll lm mo lo lp lq im bi translated">我们现在需要一种方法从每个数据点创建一个向量(<em class="nf">嵌入</em>)。我们定义了一个类<code class="fe mp mq mr ms b">Embedder</code>，它使用<a class="ae lr" href="https://github.com/UKPLab/sentence-transformers" rel="noopener ugc nofollow" target="_blank"> sentence_transformers </a>库从<a class="ae lr" href="https://github.com/huggingface/transformers" rel="noopener ugc nofollow" target="_blank"> HuggingFace的</a> <code class="fe mp mq mr ms b"><a class="ae lr" href="https://github.com/huggingface/transformers" rel="noopener ugc nofollow" target="_blank">transformers</a></code>中自动加载一个模型。</p><p id="8dc4" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">选择的模型是<a class="ae lr" href="https://huggingface.co/gsarti/biobert-nli" rel="noopener ugc nofollow" target="_blank">gsarti/BioBERT-nli</a>a<a class="ae lr" href="https://github.com/dmis-lab/biobert" rel="noopener ugc nofollow" target="_blank">BioBERT</a>模型，在<a class="ae lr" href="https://nlp.stanford.edu/projects/snli/" rel="noopener ugc nofollow" target="_blank"> SNLI </a>和<a class="ae lr" href="https://www.nyu.edu/projects/bowman/multinli/" rel="noopener ugc nofollow" target="_blank"> MultiNLI </a>上进行微调，以产生<a class="ae lr" href="https://www.aclweb.org/anthology/D17-1070/" rel="noopener ugc nofollow" target="_blank">通用句子嵌入</a>。Gabriele Sarti 进行了微调，复制它的代码可从<a class="ae lr" href="https://github.com/gsarti/covid-papers-browser/blob/master/scripts/finetune_nli.py" rel="noopener ugc nofollow" target="_blank">这里</a>获得。</p><p id="c0fd" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">BioBERT特别适合我们的数据集，因为它最初是在生物医学科学出版物上训练的。因此，考虑到与我们的数据的相似性，它应该创建更好的上下文感知嵌入。</p><p id="c1fe" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在幕后，模型首先将输入字符串标记化，然后为每个标记创建一个向量。因此，如果我们在一篇论文中有<code class="fe mp mq mr ms b">N</code>个标记，我们将得到一个<code class="fe mp mq mr ms b">[N, 768]</code>向量(注意，一个标记通常对应一个单词片段，在这里阅读更多关于标记化策略<a class="ae lr" href="https://www.thoughtvector.io/blog/subword-tokenization/" rel="noopener ugc nofollow" target="_blank"/>。因此，如果两篇论文有不同的字数，我们将有两个不同的第一维向量。这是一个问题，因为我们需要将它们与搜索进行比较。</p><p id="0421" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">为了获得每篇论文的固定嵌入，我们应用平均池。这种方法计算每个单词的平均值，并输出一个固定大小的dims向量<code class="fe mp mq mr ms b">[1, 768]</code></p><p id="8ca9" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">所以，让我们编写一个<code class="fe mp mq mr ms b">Embedder</code>类</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ne"><img src="../Images/96bcbb9eafa6549bcc62ba2e3c861177.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*55GPSuS2iFCN2uu5_wmChQ.png"/></div></div></figure><p id="4bbb" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们可以在数据点上尝试我们的嵌入器</p><pre class="kk kl km kn gt mt ms mu mv aw mw bi"><span id="1a6b" class="mx lt it ms b gy my mz l na nb">embedder = Embedder()</span><span id="cabf" class="mx lt it ms b gy nc mz l na nb">emb = embedder(ds[0]['title_abstract'])</span><span id="6a02" class="mx lt it ms b gy nc mz l na nb">emb[0].shape // (768,)</span></pre><p id="bd25" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">瞧啊！我们对一篇论文进行了编码。</p><h1 id="d04f" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">搜索</h1><p id="f967" class="pw-post-body-paragraph kv kw it kx b ky mk ju la lb ml jx ld le mm lg lh li mn lk ll lm mo lo lp lq im bi translated">好的，我们知道如何嵌入每篇论文，但是我们如何使用查询来搜索数据呢？假设我们已经嵌入了<strong class="kx iu">所有</strong>论文，我们也可以<strong class="kx iu">嵌入查询</strong>并计算查询和所有嵌入之间的余弦相似性。然后，我们可以显示按距离(分数)排序的结果。直觉上，它们在嵌入空间中离查询越近，它们共享的上下文相似性就越大。</p><p id="3a78" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">但是，怎么做呢？首先，我们需要一种适当的方法来管理数据，并足够快地运行余弦相似性。幸运的是，弹性搜索来救援！</p><h1 id="67ca" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">弹性搜索</h1><p id="d352" class="pw-post-body-paragraph kv kw it kx b ky mk ju la lb ml jx ld le mm lg lh li mn lk ll lm mo lo lp lq im bi translated"><a class="ae lr" href="https://www.elastic.co/" rel="noopener ugc nofollow" target="_blank">弹性搜索</a>是一个目标只有一个的数据库，是的你猜对了:搜索。我们将首先在elastic中存储所有嵌入，然后使用它的API来执行搜索。如果你像我一样懒，你可以用docker 安装弹性搜索</p><pre class="kk kl km kn gt mt ms mu mv aw mw bi"><span id="92bb" class="mx lt it ms b gy my mz l na nb">docker pull docker.elastic.co/elasticsearch/elasticsearch:7.6.2<br/>docker run -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" docker.elastic.co/elasticsearch/elasticsearch:7.6.2</span></pre><p id="c868" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">完美。下一步是在弹性搜索中存储嵌入和论文信息。这是一个非常简单的过程。我们需要创建一个<code class="fe mp mq mr ms b">index</code>(一个新的数据库)，然后为每篇论文建立一个条目。</p><p id="561f" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">为了创建一个<code class="fe mp mq mr ms b">index</code>，我们需要为elastic描述我们希望存储的内容。在我们的案例中:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ng"><img src="../Images/a0761b72c201f305fa8445d583c6ada2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZaWaHxyGWVg9l9dMgBQleA.png"/></div></div></figure><p id="a3f8" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">你可以在弹性搜索<a class="ae lr" href="https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-create-index.html" rel="noopener ugc nofollow" target="_blank">文档</a>上阅读更多关于索引创建的内容。最后一个条目将<code class="fe mp mq mr ms b">embed</code>字段定义为带有<code class="fe mp mq mr ms b">768</code>的密集向量。这确实是我们的嵌入。为了方便起见，我将配置存储在一个<code class="fe mp mq mr ms b">.json</code>文件中，并创建了一个名为<code class="fe mp mq mr ms b">ElasticSearchProvider</code>的类来处理存储过程。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ne"><img src="../Images/fa988a2daff6d64bf8da2d599374dde3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IUiPfuQNYmPXynWp3LdZDQ.png"/></div></div></figure><p id="55b3" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">大部分工作都是在<code class="fe mp mq mr ms b">create_and_bulk_documents</code>完成的，在那里我们每次只解构一个条目，并添加两个弹性搜索参数。</p><p id="b42e" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">不幸的是，弹性搜索无法序列化<code class="fe mp mq mr ms b">numpy</code>数组。所以我们需要为我们的数据创建一个适配器。该类将纸张数据和嵌入作为输入，并“调整”它们以在我们的<code class="fe mp mq mr ms b">ElasticSearchProvider</code>中工作。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ng"><img src="../Images/2ebc378c2298d7d5aaece3e94a91c560.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nfOukLU3ZDOKegRMZ-mn7g.png"/></div></div></figure><p id="5e57" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">好了，我们一切就绪。一种表示数据的方法，一种将数据编码成向量的方法和一种存储结果的方法。让我们把所有的东西都包起来，把所有的文件都编码。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ne"><img src="../Images/2d14e3d035e5c8dac8c91ca042224932.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NjTm3z8nVLvKJ-3PzZLe4A.png"/></div></div></figure><p id="8f5d" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">这里有两个技巧，首先，我们使用<code class="fe mp mq mr ms b">torch.utils.data.DataLoader</code>创建一个批处理式迭代器。总的来说，将数据成批地而不是作为一个单独的点提供给模型可以提高性能(在我的例子中是x100)。其次，我们替换<code class="fe mp mq mr ms b">DataLoader</code>构造函数中的<code class="fe mp mq mr ms b">collate_fn</code>参数。这是因为，默认情况下，Pytorch会尝试将我们所有的数据转换成一个<code class="fe mp mq mr ms b">torch.Tensor</code>，但是它无法转换字符串。通过这样做，我们只返回一个字典数组，即来自<code class="fe mp mq mr ms b">CovidPapersDataset</code>的输出。所以，<code class="fe mp mq mr ms b">batch</code>是一个长度为<code class="fe mp mq mr ms b">batch_size</code>的字典列表。我们做完后(1080ti上~7m)，可以看一下<code class="fe mp mq mr ms b"><a class="ae lr" href="http://localhost:9200/covid/_search?pretty=true&amp;q=*:*." rel="noopener ugc nofollow" target="_blank">http://localhost:9200/covid/_search?pretty=true&amp;q=*:*</a></code> <a class="ae lr" href="http://localhost:9200/covid/_search?pretty=true&amp;q=*:*." rel="noopener ugc nofollow" target="_blank">。</a></p><p id="8521" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">如果一切正常，您应该会看到弹性搜索显示我们的数据</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi nh"><img src="../Images/185d9397155714a2b47c4638863dd99f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HDAa7YRrQT6eB-AC"/></div></div></figure><h1 id="60b5" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">进行查询</h1><p id="ba3e" class="pw-post-body-paragraph kv kw it kx b ky mk ju la lb ml jx ld le mm lg lh li mn lk ll lm mo lo lp lq im bi translated">我们差不多完成了。拼图的最后一块是在数据库中搜索的方法。弹性搜索可以在所有文档中的一个输入向量和目标向量场之间执行余弦相似性。语法非常简单:</p><pre class="kk kl km kn gt mt ms mu mv aw mw bi"><span id="b61c" class="mx lt it ms b gy my mz l na nb">{<br/>    "query": {<br/>        "match_all": {}<br/>    },<br/>    "script": {<br/>        "source":<br/>        "cosineSimilarity(params.query_vector, doc['embed']) + 1.0",<br/>        "params": {<br/>            "query_vector": vector<br/>        }<br/>    }<br/>}</span></pre><p id="e704" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">其中<code class="fe mp mq mr ms b">vector</code>是我们的输入。因此，我们创建了一个类，它将一个向量作为输入，并显示查询的所有结果</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ng"><img src="../Images/4d99e617b2620dc3a0e0735413798a99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vmFYbYAEwFt-WnVkrmuaSg.png"/></div></div></figure><p id="a18e" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">让我们看看第一个结果(我已经复制并粘贴了第一篇匹配论文的摘要)</p><pre class="kk kl km kn gt mt ms mu mv aw mw bi"><span id="456e" class="mx lt it ms b gy my mz l na nb">es_search = ElasticSearcher()<br/>es_search(embedder(['Effect of the virus on pregnant women'])[0].tolist())</span></pre><p id="9758" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><em class="nf">作为应对新发感染的公共卫生专业人员，需要特别关注</em><strong class="kx iu"><em class="nf"/></strong><em class="nf">孕妇及其后代。孕妇可能更容易感染新出现的感染，或受到更严重的影响。新的母体感染对胚胎或胎儿的影响很难预测。一些推荐用于预防或治疗的药物可能会伤害胚胎或胎儿。我们讨论了应对孕妇中新出现的感染的挑战，并提出了克服这些挑战的策略。</em></p><p id="db75" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">成功了！我还创建了一个命令行，用户可以在其中输入查询。最后的结果是:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ni"><img src="../Images/2ea4198afd8cb9e5d6e5093041d85818.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3x315Pdvnj7_O4hj"/></div></div></figure><h1 id="3ee8" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">更多查询</h1><p id="6e12" class="pw-post-body-paragraph kv kw it kx b ky mk ju la lb ml jx ld le mm lg lh li mn lk ll lm mo lo lp lq im bi translated">最后可以提一个问题，找感兴趣的论文。从经验上看，越详细的查询效果越好，因为它们提供了更多的上下文。</p><p id="e703" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">例如，我们可能想知道<em class="nf">氯喹对新冠肺炎</em>有什么效果。结果是</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi nj"><img src="../Images/5144caac7214226192f75d7b4902111b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lAHXotFa3DZG7ZUg"/></div></div></figure><p id="6dce" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">或者<em class="nf">新冠肺炎如何与ACE2受体结合？</em></p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi nk"><img src="../Images/0556794a34ce020fc3c8a7a6ad53149d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*j4WFrVOQTFQAXpUG"/></div></div></figure><p id="a230" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">搜索引擎似乎工作良好，但它并不完美，在本教程的下一部分，我们将努力提高其准确性。</p><h1 id="d92a" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">结论</h1><p id="69aa" class="pw-post-body-paragraph kv kw it kx b ky mk ju la lb ml jx ld le mm lg lh li mn lk ll lm mo lo lp lq im bi translated">在这个项目中，我们建立了一个语义浏览器来搜索超过5万篇新冠肺炎论文。我和的里雅斯特大学的学生合作的最初项目是这里的<a class="ae lr" href="https://github.com/gsarti/covid-papers-browser" rel="noopener ugc nofollow" target="_blank"/>。这里<a class="ae lr" href="http://covidbrowser.areasciencepark.it/" rel="noopener ugc nofollow" target="_blank">有现场演示</a></p><p id="5cec" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">你也可以使用命令行程序，你需要按照<a class="ae lr" href="https://github.com/FrancescoSaverioZuppichini/Search-COVID-papers-with-Deep-Learning/blob/develop/README.md" rel="noopener ugc nofollow" target="_blank">这里</a>的指示。</p><h2 id="0a59" class="mx lt it bd lu nl nm dn ly nn no dp mc le np nq me li nr ns mg lm nt nu mi nv bi translated">承认</h2><p id="3282" class="pw-post-body-paragraph kv kw it kx b ky mk ju la lb ml jx ld le mm lg lh li mn lk ll lm mo lo lp lq im bi translated">我要感谢<a class="ae lr" href="https://www.linkedin.com/in/gabrielesarti/" rel="noopener ugc nofollow" target="_blank"> Gabriele Sarti </a>对我撰写本文的帮助，<a class="ae lr" href="https://www.linkedin.com/in/marco-franzon/" rel="noopener ugc nofollow" target="_blank"> Marco Franzon </a>和<a class="ae lr" href="https://www.linkedin.com/in/tommaso-rodani-471a43b8/" rel="noopener ugc nofollow" target="_blank"> Tommaso Rodani </a>对我在弹性搜索实现中的支持。</p><p id="a821" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">感谢您的阅读</p><p id="b86f" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">注意安全，</p><p id="2411" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">弗朗西斯科·萨维里奥·祖皮奇尼</p></div></div>    
</body>
</html>