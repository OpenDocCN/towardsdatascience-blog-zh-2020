<html>
<head>
<title>Object (Drones) Detection: Step-by-Step Guide on Mask R-CNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">物体(无人机)探测:掩模 R-CNN 的逐步指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/object-drones-detection-step-by-step-guide-on-mask-r-cnn-7bec0fb09a1?source=collection_archive---------13-----------------------#2020-04-14">https://towardsdatascience.com/object-drones-detection-step-by-step-guide-on-mask-r-cnn-7bec0fb09a1?source=collection_archive---------13-----------------------#2020-04-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/c1baec6b5c4b77f2dd7172cb42c11fc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Ma-n_NWMjih_mkLO"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">米格尔·Á·安赫尔·埃尔南德斯在<a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="7bf9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对象检测是一类计算机视觉，用于识别和定位图像中的对象。存在许多检测算法，这里的<a class="ae kf" href="https://medium.com/analytics-vidhya/beginners-guide-to-object-detection-algorithms-6620fb31c375" rel="noopener">是对它们的一个很好的总结。</a></p><p id="f934" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">掩模 R-CNN 是对象检测的扩展，因为它为图像中检测到的每个对象生成边界框和分段掩模。我最近不得不训练一个 Mask R-CNN 模型，并在尝试在我的自定义数据集上训练时遇到了一些障碍。即使有来自<a class="ae kf" href="https://github.com/matterport/Mask_RCNN/blob/master/samples/shapes/train_shapes.ipynb" rel="noopener ugc nofollow" target="_blank"> matterport </a>的样品笔记本，由于兼容性和数据问题，实现也不是那么简单。因此，我决定写这篇关于使用 Mask R-CNN 训练自定义数据集的指南，并希望它能帮助你们简化这个过程。</p></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><figure class="lm ln lo lp gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ll"><img src="../Images/c373734b758ec913139d62a005165942.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n2HrWrg7lqu12Pqt6cv8pw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated"><a class="ae kf" href="https://github.com/matterport/Mask_RCNN" rel="noopener ugc nofollow" target="_blank">https://github.com/matterport/Mask_RCNN</a></p></figure><p id="9718" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于本指南，我选择使用无人机数据集，您可以在这里下载<a class="ae kf" href="https://md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com/zcsj2g2m4c-4.zip" rel="noopener ugc nofollow" target="_blank"/>。</p><h2 id="9d46" class="lq lr it bd ls lt lu dn lv lw lx dp ly kr lz ma mb kv mc md me kz mf mg mh mi bi translated">首先—库和包</h2><p id="3281" class="pw-post-body-paragraph kg kh it ki b kj mj kl km kn mk kp kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">该算法的主要软件包是 mrcnn。从下载并导入库到您的环境中开始。</p><pre class="lm ln lo lp gt mo mp mq mr aw ms bi"><span id="02f2" class="lq lr it mp b gy mt mu l mv mw">!pip install mrcnn</span><span id="1779" class="lq lr it mp b gy mx mu l mv mw">from mrcnn.config import Config<br/>from mrcnn import utils<br/>import mrcnn.model as modellib<br/>from mrcnn import visualize<br/>from mrcnn.model import log</span></pre><p id="21c3" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当我们到达那里时，我将解释每个导入的类。现在，只需要知道这些是我们需要的导入语句。</p><p id="d375" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">至于 TensorFlow，mrcnn 尚未与 TensorFlow 2.0 兼容，所以请确保您恢复到 TensorFlow 1.x。因为我是在 Colab 上开发的，所以我将使用 magic 函数恢复到 TensorFlow 1.x。</p><pre class="lm ln lo lp gt mo mp mq mr aw ms bi"><span id="88f0" class="lq lr it mp b gy mt mu l mv mw">%tensorflow_version 1.x<br/>import tensorflow as tf</span></pre><p id="9662" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我没看错，在 TensorFlow 2.0 中 tf.random_shuffle 被重命名为 tf.random.shuffle，导致了不兼容问题。通过更改 mrcnn 代码中的 shuffle 函数，您可能能够使用 TensorFlow 2.0。</p><p id="c2d9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我也不得不把我的 Keras 恢复到以前的版本，但是我不记得原因了。只是把它放在那里，以防你遇到一些错误，由于 Keras。</p><pre class="lm ln lo lp gt mo mp mq mr aw ms bi"><span id="78bb" class="lq lr it mp b gy mt mu l mv mw">!pip install keras==2.2.5</span></pre><h2 id="e5a8" class="lq lr it bd ls lt lu dn lv lw lx dp ly kr lz ma mb kv mc md me kz mf mg mh mi bi translated">预处理</h2><p id="0560" class="pw-post-body-paragraph kg kh it ki b kj mj kl km kn mk kp kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">mrcnn 包在其接受的数据格式方面相当灵活。因此，由于它的简单性，我将处理成 NumPy 数组。</p><p id="2196" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在此之前，我意识到视频 17_295 和视频 19_1900 不能被 cv2 正常读取。因此，我过滤掉这些图像，并创建了一个文件名列表。</p><pre class="lm ln lo lp gt mo mp mq mr aw ms bi"><span id="5ff1" class="lq lr it mp b gy mt mu l mv mw">dir = "Database1/"</span><span id="ecc3" class="lq lr it mp b gy mx mu l mv mw"># filter out image that cant be read<br/>prob_list = ['video17_295','video19_1900'] # cant read format<br/>txt_list = [f for f in os.listdir(dir) if f.endswith(".txt") and f[:-4] not in prob_list]<br/>file_list = set([re.match("\w+(?=.)",f)[0] for f in txt_list])</span><span id="4d00" class="lq lr it mp b gy mx mu l mv mw"># create data list as tuple of (jpeg,txt)<br/>data_list = []<br/>for f in file_list:<br/>    data_list.append((f+".JPEG",f+".txt"))</span></pre><p id="6453" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来要做的事情很少；</p><ol class=""><li id="ed40" class="my mz it ki b kj kk kn ko kr na kv nb kz nc ld nd ne nf ng bi translated">检查标签是否存在(一些图像不包含无人机)</li><li id="eb27" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated">读取和处理图像</li><li id="ac14" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated">读取并处理边界框的坐标</li><li id="a385" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated">出于可视化目的，绘制边界框</li></ol><pre class="lm ln lo lp gt mo mp mq mr aw ms bi"><span id="78f3" class="lq lr it mp b gy mt mu l mv mw">X,y = [], []<br/>img_box = []<br/>DIMENSION = 128 # set low resolution to decrease training time</span><span id="a15f" class="lq lr it mp b gy mx mu l mv mw">for i in range(len(data_list)):<br/>    # get bounding box and check if label exist<br/>    with open(dir+data_list[i][1],"rb") as f:<br/>    box = f.read().split()<br/>    if len(box) != 5: <br/>        continue # skip data if does not contain label</span><span id="e4aa" class="lq lr it mp b gy mx mu l mv mw">box = [float(s) for s in box[1:]]</span><span id="c5bc" class="lq lr it mp b gy mx mu l mv mw"># read image</span><span id="40a8" class="lq lr it mp b gy mx mu l mv mw">img = cv2.imread(dir+data_list[i][0])<br/>    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)</span><span id="24c2" class="lq lr it mp b gy mx mu l mv mw"># resize img to 128 x 128<br/>    img = cv2.resize(img, (DIMENSION,DIMENSION), interpolation= cv2.INTER_LINEAR)</span><span id="21f6" class="lq lr it mp b gy mx mu l mv mw"># draw bounding box (for visualization purposes)<br/>    resize1, resize2 = img.shape[0]/DIMENSION, img.shape[1]/DIMENSION<br/>    p1,p2,p3,p4 = int(box[0]*img.shape[1]*resize2), int(box[1]*img.shape[0]*resize1) ,int(box[2]*img.shape[1]*resize2) ,int(box[3]*img.shape[0]*resize1)</span><span id="7146" class="lq lr it mp b gy mx mu l mv mw">ymin, ymax, xmin, xmax = p2-p4//2, p2+p4//2, p1-p3//2, p1+p3//2</span><span id="51ca" class="lq lr it mp b gy mx mu l mv mw">draw = cv2.rectangle(img.copy(),(xmax,ymax),(xmin,ymin),color=(255,255,0),thickness =1)</span><span id="a74d" class="lq lr it mp b gy mx mu l mv mw"># store data if range of y is at least 20 pixels (remove data with small drones)<br/>    if ymax - ymin &gt;=20:<br/>        X.append(img)<br/>        y.append([ymin, ymax, xmin, xmax])<br/>        img_box.append(draw)</span><span id="eff5" class="lq lr it mp b gy mx mu l mv mw"># convert to numpy arrays</span><span id="6fbf" class="lq lr it mp b gy mx mu l mv mw">X = np.array(X).astype(np.uint8)<br/>y = np.array(y)<br/>img_box = np.array(img_box)</span></pre><p id="7328" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在转换为 NumPy 数组之前，我获取了数据集的一个子群体，以减少训练时间。如果你有计算能力，可以忽略它。</p><p id="1eb8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里有一些样本图像。</p><figure class="lm ln lo lp gt ju gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/47ddd3a54b18f50a34b3baf6320bc855.png" data-original-src="https://miro.medium.com/v2/resize:fit:854/format:webp/1*eowOUsf9xgHSfOqFnfM80g.png"/></div></figure><h2 id="4204" class="lq lr it bd ls lt lu dn lv lw lx dp ly kr lz ma mb kv mc md me kz mf mg mh mi bi translated">MRCNN —处理</h2><p id="c900" class="pw-post-body-paragraph kg kh it ki b kj mj kl km kn mk kp kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">现在来看看 mrcnn 本身，我们需要在训练过程之前定义一个 mrcnn 数据集类。这个数据集类提供图像的信息，例如图像所属的类以及图像中对象的位置。我们之前导入的 mrcnn.utils 包含这个数据集类。</p><p id="4730" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是事情变得有点棘手的地方，需要对<a class="ae kf" href="https://github.com/matterport/Mask_RCNN/blob/master/mrcnn/utils.py" rel="noopener ugc nofollow" target="_blank">源代码</a>进行一些解读。</p><p id="0bc1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这些是你需要修改的函数；</p><ol class=""><li id="130a" class="my mz it ki b kj kk kn ko kr na kv nb kz nc ld nd ne nf ng bi translated">add_class，它决定了模型的类的数量</li><li id="9d58" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated">add_image，您可以在其中定义 image_id 和图像路径(如果适用)</li><li id="bb60" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated">load_image，加载图像数据的地方</li><li id="d681" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated">load_mask，它获取关于图像的遮罩/边界框的信息</li></ol><pre class="lm ln lo lp gt mo mp mq mr aw ms bi"><span id="b9a9" class="lq lr it mp b gy mt mu l mv mw"># define drones dataset using mrcnn utils class</span><span id="cd60" class="lq lr it mp b gy mx mu l mv mw">class DronesDataset(utils.Dataset):<br/>    def __init__(self,X,y): # init with numpy X,y<br/>        self.X = X<br/>        self.y = y<br/>        super().__init__()</span><span id="b9ba" class="lq lr it mp b gy mx mu l mv mw">def load_dataset(self):<br/>        self.add_class("dataset",1,"drones") # only 1 class, drones<br/>        for i in range(len(self.X)):<br/>            self.add_image("dataset",i,path=None)</span><span id="82f1" class="lq lr it mp b gy mx mu l mv mw">def load_image(self,image_id):<br/>        image = self.X[image_id] # where image_id is index of X<br/>        return image</span><span id="d9a8" class="lq lr it mp b gy mx mu l mv mw">def load_mask(self,image_id):<br/>    # get details of image<br/>    info = self.image_info[image_id]<br/>    #create one array for all masks, each on a different channel<br/>    masks = np.zeros([128, 128, len(self.X)], dtype='uint8')</span><span id="728b" class="lq lr it mp b gy mx mu l mv mw">class_ids = []<br/>    for i in range(len(self.y)):<br/>        box = self.y[info["id"]]<br/>        row_s, row_e = box[0], box[1]<br/>        col_s, col_e = box[2], box[3]<br/>        masks[row_s:row_e, col_s:col_e, i] = 1 # create mask with similar boundaries as bounding box<br/>        class_ids.append(1)</span><span id="0579" class="lq lr it mp b gy mx mu l mv mw">return masks, np.array(class_ids).astype(np.uint8)</span></pre><p id="c594" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因为我们努力将图像格式化成 NumPy 数组，所以我们可以简单地用数组初始化 Dataset 类，并通过索引数组来加载图像和边界框。</p><p id="8453" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来做一个传统方式的火车测试，</p><pre class="lm ln lo lp gt mo mp mq mr aw ms bi"><span id="f943" class="lq lr it mp b gy mt mu l mv mw"># train test split 80:20</span><span id="624d" class="lq lr it mp b gy mx mu l mv mw">np.random.seed(42) # for reproducibility<br/>p = np.random.permutation(len(X))<br/>X = X[p].copy()<br/>y = y[p].copy()</span><span id="02b1" class="lq lr it mp b gy mx mu l mv mw">split = int(0.8 * len(X))</span><span id="c15e" class="lq lr it mp b gy mx mu l mv mw">X_train = X[:split]<br/>y_train = y[:split]</span><span id="b04f" class="lq lr it mp b gy mx mu l mv mw">X_val = X[split:]<br/>y_val = y[split:]</span></pre><p id="9da0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在将数据加载到数据集类中。</p><pre class="lm ln lo lp gt mo mp mq mr aw ms bi"><span id="5ac1" class="lq lr it mp b gy mt mu l mv mw"># load dataset into mrcnn dataset class</span><span id="676b" class="lq lr it mp b gy mx mu l mv mw">train_dataset = DronesDataset(X_train,y_train)<br/>train_dataset.load_dataset()<br/>train_dataset.prepare()</span><span id="1b52" class="lq lr it mp b gy mx mu l mv mw">val_dataset = DronesDataset(X_val,y_val)<br/>val_dataset.load_dataset()<br/>val_dataset.prepare()</span></pre><p id="1f06" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">prepare()函数使用 image_ids 和 class_ids 信息为 mrcnn 模型准备数据，</p><p id="9217" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来是我们从 mrcnn 导入的 config 类的修改。Config 类决定了训练中使用的变量，应该根据数据集进行调整。以下这些变量并不详尽，您可以参考<a class="ae kf" href="https://github.com/matterport/Mask_RCNN/blob/master/mrcnn/config.py" rel="noopener ugc nofollow" target="_blank">文档</a>获得完整列表。</p><pre class="lm ln lo lp gt mo mp mq mr aw ms bi"><span id="8538" class="lq lr it mp b gy mt mu l mv mw">class DronesConfig(Config):<br/>    # Give the configuration a recognizable name<br/>    NAME = "drones"</span><span id="db42" class="lq lr it mp b gy mx mu l mv mw"># Train on 1 GPU and 2 images per GPU.<br/>    GPU_COUNT = 1<br/>    IMAGES_PER_GPU = 2</span><span id="1810" class="lq lr it mp b gy mx mu l mv mw"># Number of classes (including background)<br/>    NUM_CLASSES = 1+1  # background + drones</span><span id="9f7a" class="lq lr it mp b gy mx mu l mv mw"># Use small images for faster training. <br/>    IMAGE_MIN_DIM = 128<br/>    IMAGE_MAX_DIM = 128</span><span id="a8fe" class="lq lr it mp b gy mx mu l mv mw"># Reduce training ROIs per image because the images are small and have few objects.<br/>    TRAIN_ROIS_PER_IMAGE = 20</span><span id="4403" class="lq lr it mp b gy mx mu l mv mw"># Use smaller anchors because our image and objects are small<br/>    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels</span><span id="c0bf" class="lq lr it mp b gy mx mu l mv mw"># set appropriate step per epoch and validation step<br/>    STEPS_PER_EPOCH = len(X_train)//(GPU_COUNT*IMAGES_PER_GPU)<br/>    VALIDATION_STEPS = len(X_val)//(GPU_COUNT*IMAGES_PER_GPU)</span><span id="c826" class="lq lr it mp b gy mx mu l mv mw"># Skip detections with &lt; 70% confidence<br/>    DETECTION_MIN_CONFIDENCE = 0.7</span><span id="ea57" class="lq lr it mp b gy mx mu l mv mw">config = DronesConfig()<br/>config.display()</span></pre><p id="69a5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">根据您的计算能力，您可能需要相应地调整这些变量。否则，你将面临卡在“Epoch 1”而没有给出错误信息的问题。甚至有一个<a class="ae kf" href="https://github.com/matterport/Mask_RCNN/issues/287" rel="noopener ugc nofollow" target="_blank"> GitHub 问题</a>针对这个问题提出，并提出了许多解决方案。如果这种情况发生在你身上，一定要检查一下，并测试其中的一些建议。</p><h2 id="d28f" class="lq lr it bd ls lt lu dn lv lw lx dp ly kr lz ma mb kv mc md me kz mf mg mh mi bi translated">MRCNN —培训</h2><p id="afa0" class="pw-post-body-paragraph kg kh it ki b kj mj kl km kn mk kp kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">mrcnn 已经在<a class="ae kf" href="http://cocodataset.org/#home" rel="noopener ugc nofollow" target="_blank"> COCO </a>和 I <a class="ae kf" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> mageNet </a>数据集上进行了训练。为了将这些预先训练好的权重用于迁移学习，我们需要将其下载到我们的环境中(记得首先定义您的 ROOT_DIR)。</p><pre class="lm ln lo lp gt mo mp mq mr aw ms bi"><span id="b935" class="lq lr it mp b gy mt mu l mv mw"><em class="nn"># Local path to trained weights file</em><br/>COCO_MODEL_PATH = os.path.join(ROOT_DIR, "mask_rcnn_coco.h5")</span><span id="6f71" class="lq lr it mp b gy mx mu l mv mw"><em class="nn"># Download COCO trained weights from Releases if needed</em><br/><strong class="mp iu">if</strong> <strong class="mp iu">not</strong> os.path.exists(COCO_MODEL_PATH):<br/>    utils.download_trained_weights(COCO_MODEL_PATH)</span></pre><p id="e77d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">创建模型并以预训练的权重开始。</p><pre class="lm ln lo lp gt mo mp mq mr aw ms bi"><span id="db50" class="lq lr it mp b gy mt mu l mv mw"># Create model in training mode using gpu</span><span id="f495" class="lq lr it mp b gy mx mu l mv mw">with tf.device("/gpu:0"):<br/>    model = modellib.MaskRCNN(mode="training", config=config,model_dir=MODEL_DIR)</span><span id="1db7" class="lq lr it mp b gy mx mu l mv mw"><em class="nn"># Which weights to start with?</em><br/>init_with = "imagenet"  <em class="nn"># imagenet, coco</em></span><span id="fdef" class="lq lr it mp b gy mx mu l mv mw"><strong class="mp iu">if</strong> init_with == "imagenet":<br/>    model.load_weights(model.get_imagenet_weights(), by_name=<strong class="mp iu">True</strong>)<br/><strong class="mp iu">elif</strong> init_with == "coco":<br/>    <em class="nn"># Load weights trained on MS COCO, but skip layers that</em><br/>    <em class="nn"># are different due to the different number of classes</em><br/>    <em class="nn"># See README for instructions to download the COCO weights</em><br/>    model.load_weights(COCO_MODEL_PATH, by_name=<strong class="mp iu">True</strong>,exclude=["mrcnn_class_logits", "mrcnn_bbox_fc", "mrcnn_bbox", "mrcnn_mask"])</span></pre><p id="9889" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，我们可以开始实际训练了。</p><pre class="lm ln lo lp gt mo mp mq mr aw ms bi"><span id="a259" class="lq lr it mp b gy mt mu l mv mw">model.train(train_dataset, val_dataset,learning_rate=config.LEARNING_RATE,epochs=5,layers='heads') # unfreeze head and just train on last layer</span></pre><p id="8c3f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于本练习，我将只训练最后一层来检测我们数据集中的无人机。如果时间允许，您还应该通过训练所有前面的层来微调您的模型。</p><pre class="lm ln lo lp gt mo mp mq mr aw ms bi"><span id="ee59" class="lq lr it mp b gy mt mu l mv mw">model.train(train_dataset, val_dataset, <br/>            learning_rate=config.LEARNING_RATE / 10,<br/>            epochs=2, <br/>            layers="all")</span></pre><p id="7bfb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你已经完成了 mrcnn 模型的训练。您可以用这两行代码保存模型的权重。</p><pre class="lm ln lo lp gt mo mp mq mr aw ms bi"><span id="803c" class="lq lr it mp b gy mt mu l mv mw"># save weights<br/>model_path = os.path.join(MODEL_DIR, "mask_rcnn_drones.h5")<br/>model.keras_model.save_weights(model_path)</span></pre><h2 id="8d0c" class="lq lr it bd ls lt lu dn lv lw lx dp ly kr lz ma mb kv mc md me kz mf mg mh mi bi translated">MRCNN —推理</h2><p id="c8ed" class="pw-post-body-paragraph kg kh it ki b kj mj kl km kn mk kp kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">要对其他图像进行推理，您需要创建一个带有自定义配置的新推理模型。</p><pre class="lm ln lo lp gt mo mp mq mr aw ms bi"><span id="2efd" class="lq lr it mp b gy mt mu l mv mw"># make inference</span><span id="bfa8" class="lq lr it mp b gy mx mu l mv mw">class InferenceConfig(DronesConfig):<br/>    GPU_COUNT = 1<br/>    IMAGES_PER_GPU = 1</span><span id="b60f" class="lq lr it mp b gy mx mu l mv mw">inference_config = InferenceConfig()</span><span id="5817" class="lq lr it mp b gy mx mu l mv mw"># Recreate the model in inference mode<br/>model = modellib.MaskRCNN(mode="inference",config=inference_config, model_dir=MODEL_DIR)</span><span id="2093" class="lq lr it mp b gy mx mu l mv mw"># Load trained weights</span><span id="c23c" class="lq lr it mp b gy mx mu l mv mw">model_path = os.path.join(MODEL_DIR, "mask_rcnn_drones.h5")<br/>model.load_weights(model_path, by_name=True)</span></pre><p id="abb8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">mrcnn 的 visualize 类在这里派上了用场。</p><pre class="lm ln lo lp gt mo mp mq mr aw ms bi"><span id="7c60" class="lq lr it mp b gy mt mu l mv mw">def get_ax(rows=1, cols=1, size=8):<br/>    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))</span><span id="6721" class="lq lr it mp b gy mx mu l mv mw">return ax</span><span id="6b24" class="lq lr it mp b gy mx mu l mv mw"># Test on a random image<br/>image_id = random.choice(val_dataset.image_ids)<br/>original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\<br/>modellib.load_image_gt(val_dataset, inference_config,image_id, use_mini_mask=False)</span><span id="3035" class="lq lr it mp b gy mx mu l mv mw">results = model.detect([original_image], verbose=1)<br/>r = results[0]</span><span id="3139" class="lq lr it mp b gy mx mu l mv mw">visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'],val_dataset.class_names, r['scores'], ax=get_ax())</span></pre><figure class="lm ln lo lp gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi no"><img src="../Images/489a4623ada373dfe0982f8391f87176.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VerTWOEbtVRQPKM4cFcwaQ.png"/></div></div></figure></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><p id="b1f4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">恭喜你，你已经用自定义数据集训练了一个 mrcnn 模型。拍拍自己的背，因为这不是一件容易的事。如您所见，掩蔽对我们的数据集来说并不完美，因为我们没有掩蔽数据。在这样的模型上测试一下，你会得到更好的结果。</p><p id="272a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">快乐学习。</p></div></div>    
</body>
</html>