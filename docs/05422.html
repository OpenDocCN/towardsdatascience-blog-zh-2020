<html>
<head>
<title>Full stack PyTorch Crowd Size Estimator</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">全栈 PyTorch 人群规模估计量</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deploy-a-crowd-size-estimator-with-pytorch-size-ai-580903a101a5?source=collection_archive---------24-----------------------#2020-05-07">https://towardsdatascience.com/deploy-a-crowd-size-estimator-with-pytorch-size-ai-580903a101a5?source=collection_archive---------24-----------------------#2020-05-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ae72" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">查理·麦基，杰森·戴尔和但丁·德鲁卡</h2></div><h2 id="f797" class="ki kj it bd kk kl km dn kn ko kp dp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">演示</h2><p id="fdce" class="pw-post-body-paragraph le lf it lg b lh li ju lj lk ll jx lm kr ln lo lp kv lq lr ls kz lt lu lv lw im bi translated">请尝试我们的人群规模估计器的演示:<a class="ae lx" href="https://app3-qrhrzckmpq-ue.a.run.app" rel="noopener ugc nofollow" target="_blank">https://app 3-qhrzckmpq-UE . a . run . app</a></p><p id="d4b7" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">你可以从 ShanghaiTech 数据集中选择一些图片，也可以上传自己的图片。如果你选择上传自己的图像，它必须是 JPG/JPEG 格式，并且小于 100KB。</p><p id="87c3" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">您可以按如下方式检查图像尺寸:</p><p id="648e" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">计算机:</p><ul class=""><li id="a709" class="md me it lg b lh ly lk lz kr mf kv mg kz mh lw mi mj mk ml bi translated">窗口:资源管理器→选择图像(窗口底部)。</li><li id="1edb" class="md me it lg b lh mm lk mn kr mo kv mp kz mq lw mi mj mk ml bi translated">Mac:按住 Control 键并点击→“获取信息”→“大小”</li></ul><p id="0044" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">手机:</p><ul class=""><li id="84df" class="md me it lg b lh ly lk lz kr mf kv mg kz mh lw mi mj mk ml bi translated">iPhone:确保图像不是截图，然后你可以“选择大小”的图像(屏幕底部)。选择“小”并上传。</li><li id="bdf2" class="md me it lg b lh mm lk mn kr mo kv mp kz mq lw mi mj mk ml bi translated">安卓:看看这篇博文，<a class="ae lx" href="https://www.quora.com/How-do-I-reduce-the-size-of-photos-in-Android" rel="noopener ugc nofollow" target="_blank">https://www . quora . com/How-do-I-reduce-the-size-of-photos-in-Android</a></li></ul><h2 id="89a3" class="ki kj it bd kk kl km dn kn ko kp dp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">介绍</h2><p id="5281" class="pw-post-body-paragraph le lf it lg b lh li ju lj lk ll jx lm kr ln lo lp kv lq lr ls kz lt lu lv lw im bi translated">在这篇文章中，我将解释我的<a class="ae lx" href="https://www.facebook.com/westernuai/" rel="noopener ugc nofollow" target="_blank">西部人工智能</a>项目团队如何开发一个 web 应用程序来估计给定图像中人群的大小。</p><p id="3bc5" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">我们从 2019 年 9 月开始的目标是部署一个可以预测人群规模的机器学习模型。我们实现了我们的目标，并能够在由女王人工智能中心主办的加拿大人工智能本科生会议上展示我们的项目。</p><p id="7932" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">人群规模估计是机器学习社区中的一个热门话题。它有多种应用，包括人群控制、客户管理和城市规划。我们的模型可以应用于学校环境，测量课堂出勤率或建筑物占用率。</p><h2 id="3b49" class="ki kj it bd kk kl km dn kn ko kp dp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">最终产品</h2><div class="mr ms mt mu gt ab cb"><figure class="mv mw mx my mz na nb paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><img src="../Images/7ff8f5a82644f7b8447ffaaab2e61c09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/1*ZAM5nYmfMaicCK5Zyw2xkw.png"/></div></figure><figure class="mv mw ni my mz na nb paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><img src="../Images/f2dc8a2cf27ed412f4a402673cf7559a.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*ANCDskBdeZD5ktV5LFhvSg.png"/></div></figure></div><p id="b14d" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">上图是我们部署的 web 应用程序。web 主机从用户那里获取 JPG 格式的本地图像，然后估计人群的大小(人数)。</p><h2 id="4af2" class="ki kj it bd kk kl km dn kn ko kp dp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">目的</h2><p id="3942" class="pw-post-body-paragraph le lf it lg b lh li ju lj lk ll jx lm kr ln lo lp kv lq lr ls kz lt lu lv lw im bi translated">这篇文章的目的是:</p><ul class=""><li id="bf07" class="md me it lg b lh ly lk lz kr mf kv mg kz mh lw mi mj mk ml bi translated">展示我们的项目:尺寸。人工智能</li><li id="d6aa" class="md me it lg b lh mm lk mn kr mo kv mp kz mq lw mi mj mk ml bi translated">深入了解当今的人群识别和机器学习</li><li id="44ce" class="md me it lg b lh mm lk mn kr mo kv mp kz mq lw mi mj mk ml bi translated">提供部署机器学习模型的教程</li></ul><h2 id="ed06" class="ki kj it bd kk kl km dn kn ko kp dp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">议程</h2><p id="f300" class="pw-post-body-paragraph le lf it lg b lh li ju lj lk ll jx lm kr ln lo lp kv lq lr ls kz lt lu lv lw im bi translated">这篇文章的结构如下:</p><ul class=""><li id="5584" class="md me it lg b lh ly lk lz kr mf kv mg kz mh lw mi mj mk ml bi translated">机器学习、计算机视觉和人群规模估计简介</li><li id="dd8d" class="md me it lg b lh mm lk mn kr mo kv mp kz mq lw mi mj mk ml bi translated">当前人群规模估计方法</li><li id="d602" class="md me it lg b lh mm lk mn kr mo kv mp kz mq lw mi mj mk ml bi translated">我们的方法:CSRNet</li><li id="9a20" class="md me it lg b lh mm lk mn kr mo kv mp kz mq lw mi mj mk ml bi translated">培训、测试和验证(Google Colab/Python3)</li><li id="7a59" class="md me it lg b lh mm lk mn kr mo kv mp kz mq lw mi mj mk ml bi translated">部署(Flask/Google 云)</li><li id="2f64" class="md me it lg b lh mm lk mn kr mo kv mp kz mq lw mi mj mk ml bi translated">下一步、来源和西方人工智能</li></ul><h2 id="90a6" class="ki kj it bd kk kl km dn kn ko kp dp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">机器学习、计算机视觉和人群规模估计的介绍</h2><p id="0887" class="pw-post-body-paragraph le lf it lg b lh li ju lj lk ll jx lm kr ln lo lp kv lq lr ls kz lt lu lv lw im bi translated"><strong class="lg iu">人工智能(AI)和机器学习(ML) </strong>含义不同。机器学习是一种人工智能，涉及统计分析和问题分类。流行的机器学习应用包括自然语言处理(NLP)和计算机视觉(CV)。这些应用程序由机器学习算法驱动，包括 K 近邻(kNN)、回归和神经网络。</p><p id="8cea" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">让我们关注神经网络。神经网络是由我们大脑的结构松散地启发的。在大脑中有一个神经元网络，每个神经元存储一些信息。神经元通过轴突相互连接，轴突可以在神经元之间传递信号。在人工神经网络中，神经元由组织成层的节点表示。</p><figure class="mr ms mt mu gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi nj"><img src="../Images/623c0bf22256e09754a0831c7e6a6036.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g-MWJr9Z3mQw0t15fEmgWQ.png"/></div></div><p class="nk nl gj gh gi nm nn bd b be z dk translated">来自:s . Logan:<a class="ae lx" href="https://becominghuman.ai/understanding-the-structure-of-neural-networks-1fa5bd17fef0" rel="noopener ugc nofollow" target="_blank">“理解神经网络的结构”</a></p></figure><p id="bfd6" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">第一层节点可以采用某种形式的输入，每一层的处理都将有助于对输入进行分类。最后一层表示容易解释的输出。</p><p id="95e3" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated"><em class="no">例子</em>:计算机想要确定一幅图像中包含一只狗还是一只猫。图像将被分解成像素，每个像素将由一个 RGB 比例值(0–255)表示。RGB 值是第一层节点的输入。之后的每一层可以代表图像内的某种类型的特征检测；眼睛的重叠，头的大小与耳朵的大小的比较…等等。最后一层节点汇总了前几层的所有信息并做出决策。</p><p id="3a62" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">机器学习的“学习”部分，包括迭代通过许多标记有元数据的例子，这些元数据已经被人类分类。神经网络经历反向传播过程，其中网络的误差被最小化。对于提供的每个示例，网络将进行预测，然后用提供的元数据验证其预测，并得出误差成本(预测-实际)。反向传播的目标是通过调整网络来最小化这种误差。</p><p id="70d4" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">这背后的数学比我刚才解释的更复杂。如果你仍然感兴趣，可以看看 Jayson(项目经理)，<a class="ae lx" href="https://github.com/jaysondale/Simple-Classifier/blob/master/Intro%20to%20NN%20(1).pdf" rel="noopener ugc nofollow" target="_blank">神经网络的简单分类器介绍。</a></p><h2 id="f38b" class="ki kj it bd kk kl km dn kn ko kp dp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated"><strong class="ak">人群规模估计</strong></h2><p id="045d" class="pw-post-body-paragraph le lf it lg b lh li ju lj lk ll jx lm kr ln lo lp kv lq lr ls kz lt lu lv lw im bi translated">人群规模估计使用神经网络对人群中的人进行分类，然后合计检测到的人数。目前有三种人群规模估计方法:检测、回归和密度。</p><ul class=""><li id="377f" class="md me it lg b lh ly lk lz kr mf kv mg kz mh lw mi mj mk ml bi translated"><strong class="lg iu">检测</strong>:专注于物体检测；识别人的特征(例如:头、肩、身体等)。这种方法通常对人数较少的人群更准确。</li><li id="4497" class="md me it lg b lh mm lk mn kr mo kv mp kz mq lw mi mj mk ml bi translated"><strong class="lg iu">回归</strong>:使用一个人更广泛的特征，把更多的注意力放在边缘细节上。当面对更密集的人群时，这优于检测模型。</li><li id="c76e" class="md me it lg b lh mm lk mn kr mo kv mp kz mq lw mi mj mk ml bi translated"><strong class="lg iu">密度</strong>:(见下面的密度图示例)密度图不是聚焦于单个人，而是追踪人群。这是对密集人群最准确的方法，也是我们选择的模型 CSRNet 使用的方法。</li></ul><div class="mr ms mt mu gt ab cb"><figure class="mv mw np my mz na nb paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><img src="../Images/15ee613c473b5e205966ef49b546457a.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*XUiXKN0pEqaYW0ytr3UJig.png"/></div></figure><figure class="mv mw nq my mz na nb paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><img src="../Images/b37d093e60ca53f8d3675019671a3cc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*D2NgJDx7SINjuRXf7WOD8g.png"/></div><p class="nk nl gj gh gi nm nn bd b be z dk nr di ns nt translated">密度图(右)</p></figure></div><h2 id="7b8b" class="ki kj it bd kk kl km dn kn ko kp dp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">CSRNet</h2><p id="dc7c" class="pw-post-body-paragraph le lf it lg b lh li ju lj lk ll jx lm kr ln lo lp kv lq lr ls kz lt lu lv lw im bi translated"><strong class="lg iu">拥挤场景识别网络(CSRNet) </strong>是由伊利诺伊大学厄巴纳-香槟分校的计算机科学家在 2018 年提出的人群规模估计模型。</p><p id="3bf2" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">CSRNet 利用 VGG-16 图像分类网络作为前端部分，因为它具有灵活有效的架构。VGG-16 使用各种激活功能(用于提取层间节点输出)和其他超参数(层/节点配置)，包括 ReLU 和 SoftMax。ReLU 是机器学习中的标准，意思是校正的线性单元。SoftMax 不太常见，但值得注意。SoftMax 的目标是把数字变成概率，把分类两极分化。这在最后一层的影像分类中非常有用，因为它为任何分类场景提供了概率。由于我们的目标是输出一个密度图，而不是一个热分类，CSRNet 的后端结构用更多的卷积层取代了全连接和 SoftMax 层。</p><figure class="mr ms mt mu gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi nu"><img src="../Images/8f3288b2eac7f0c388a6c05fe0dcdefd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EZVNbkM5E9wNgvZgn14JEQ.png"/></div></div><p class="nk nl gj gh gi nm nn bd b be z dk translated">VGG-16 结构</p></figure><p id="2eed" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated"><strong class="lg iu">扩展内核:</strong>在后端，使用扩展卷积层来代替最大池，以便保持输出维度并增加感受域。膨胀核是一个标准的卷积核，由一个膨胀因子分散(见下文)。膨胀的核不会降低图像质量，这一点很重要，因为密度图的尺寸越大，我们的估计就越准确。</p><p id="b9b0" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">膨胀的卷积有助于生成我们的密度图:</p><div class="mr ms mt mu gt ab cb"><figure class="mv mw nv my mz na nb paragraph-image"><img src="../Images/438214532140d5c91164b3f21864305c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/0*E0ukZEsrp78ZeKbC"/></figure><figure class="mv mw nw my mz na nb paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><img src="../Images/72c1468414ae62248d7a273e816f269d.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/0*YOkQ4h5ZbDxNU61-"/></div><p class="nk nl gj gh gi nm nn bd b be z dk nx di ny nt translated">增大膨胀系数:1 → 2 → 3</p></figure></div><p id="8de3" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated"><strong class="lg iu">结果</strong> : CSRNet 取得了比其他流行的人群规模估计网络更好的 MAE 和 MSE 结果。</p><figure class="mr ms mt mu gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi nz"><img src="../Images/243c0c87123c1fed000c59e9415d8fbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C8_cZ_8bCgqDY3mNM-elZw.png"/></div></div><p class="nk nl gj gh gi nm nn bd b be z dk translated"><a class="ae lx" href="https://arxiv.org/pdf/1802.10062.pdf" rel="noopener ugc nofollow" target="_blank"> CSRNet </a></p></figure><p id="2366" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">对于更多的上下文<strong class="lg iu">，</strong> MAE 是平均绝对误差。平均绝对误差是每个训练图像的绝对误差的平均值。MSE <strong class="lg iu"> </strong>是均方误差。MSE 不同于 MAE，因为它更强调大误差。</p><figure class="mr ms mt mu gt mw gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/c147e3175c6647d1ebe736ee94ba7d61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*YzlYGDeifBSVzch7aAUu-Q.png"/></div></figure><h2 id="bb2d" class="ki kj it bd kk kl km dn kn ko kp dp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">培训、测试和验证(Google Colab/Python3)</h2><p id="cbd3" class="pw-post-body-paragraph le lf it lg b lh li ju lj lk ll jx lm kr ln lo lp kv lq lr ls kz lt lu lv lw im bi translated">既然女王的学生都走了——我们来编码吧！我们使用了来自 Analytics Vidhya 的教程:<a class="ae lx" href="https://www.analyticsvidhya.com/blog/2019/02/building-crowd-counting-model-python/" rel="noopener ugc nofollow" target="_blank">构建你自己的人群计数模型</a>。我们将所有的预处理、训练、测试和验证脚本存储在一个 Google Drive 文件夹中。在 Google Drive 中，我们能够使用 Google Colab 笔记本来创建和共享我们的模型。在某些情况下，所有脚本都是用 Python 3 或 Python 2 编写和编译的。为了训练我们的模型，我们还安装了 CUDA GPU。</p><p id="0373" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">我们使用了<a class="ae lx" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zhang_Single-Image_Crowd_Counting_CVPR_2016_paper.pdf" rel="noopener ugc nofollow" target="_blank">上海科技馆</a>的数据集，因为它具有摄像机视角的广度、人群规模的多样性以及大量的注释数据。该数据集包含近 1200 张图片和超过 330，000 个带注释的头像。</p><p id="6181" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">Google Drive 中的培训和测试的最终目标是生成我们经过培训的模型。PT 文件(PyTorch 文件)，我们可以上传到我们的前端界面。为了达到这个目标，我们必须编译并运行:</p><ul class=""><li id="18c8" class="md me it lg b lh ly lk lz kr mf kv mg kz mh lw mi mj mk ml bi translated">地面真实生产脚本</li><li id="93e5" class="md me it lg b lh mm lk mn kr mo kv mp kz mq lw mi mj mk ml bi translated">培训脚本</li><li id="5295" class="md me it lg b lh mm lk mn kr mo kv mp kz mq lw mi mj mk ml bi translated">验证脚本</li></ul><p id="c5f8" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated"><strong class="lg iu">地面实况生成脚本:</strong>该脚本的目的是将数据集提供的地面实况转换成可用于训练的密度图。</p><p id="7c92" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">下面你可以看到一个输出的例子。将地面实况转换成密度图。</p><div class="mr ms mt mu gt ab cb"><figure class="mv mw ob my mz na nb paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><img src="../Images/ec7479d37fbe947d388015e665b443e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*2OqwiOM907oIPh4skz2ldQ.png"/></div></figure><figure class="mv mw oc my mz na nb paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><img src="../Images/be8d2657cb2f990804d5b312be7a07fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*zmvZJIVrIsxrsAT36AKT1Q.png"/></div></figure></div><p id="747d" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">显示密度图中的原始预测计数:</p><pre class="mr ms mt mu gt od oe of og aw oh bi"><span id="40e4" class="ki kj it oe b gy oi oj l ok ol">np.sum(groundtruth) # Output -&gt; 166.15</span></pre><p id="3da7" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated"><strong class="lg iu">训练脚本:</strong>训练脚本遍历我们所有的训练数据集图像，并提高每个历元之间的准确性(历元是对数据的一次迭代)。</p><p id="bd44" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">使用我们的第一个数据集运行训练脚本的示例代码:</p><pre class="mr ms mt mu gt od oe of og aw oh bi"><span id="51ea" class="ki kj it oe b gy oi oj l ok ol">root = "/content/gdrive/My Drive/Western AI - Intro to Computer Vision Project/CSRNet Crowd Counting Model/Data/"</span><span id="6a9c" class="ki kj it oe b gy om oj l ok ol">!python2 '/content/gdrive/My Drive/Western AI - Intro to Computer Vision Project/CSRNet Crowd Counting Model/train.py' '/content/gdrive/My Drive/Western AI - Intro to Computer Vision Project/CSRNet Crowd Counting Model/part_A_train.json' '/content/gdrive/My Drive/Western AI - Intro to Computer Vision Project/CSRNet Crowd Counting Model/part_A_test.json' 0 0</span></pre><p id="eb1f" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">以下是其中一个训练时期(第 15 个)的快照:</p><figure class="mr ms mt mu gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi on"><img src="../Images/507286f24693a7b5fca7f0796d9afd28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zXwLFIlWQLreFQ0zVbx1rQ.png"/></div></div></figure><p id="9e40" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">在时间和资源允许的情况下，我们能够为 100 个完整的时期训练我们的模型。在监控训练时，我们注意到 MAE 在每个时期都有轻微的改善。如果你看上面的输出，第 15 个纪元的 MAE 是 70.621。这意味着平均误差是 70.621 人(+/-)。第一纪元的 MAE 是 250，所以我们取得了一些进展。根据数据集的大小(1200 张图片)和每个人群的总规模(330，000 人)，每个人群中平均有 275 人。考虑到大规模的人群，我们的误差是令人满意的。</p><p id="2d5e" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated"><strong class="lg iu">验证脚本:</strong>该脚本采用我们训练过的模型，并确定每个测试示例的平均误差和百分比误差。(注意:这是验证脚本的抽象版本)</p><pre class="mr ms mt mu gt od oe of og aw oh bi"><span id="1724" class="ki kj it oe b gy oi oj l ok ol">checkpoint = torch.load('/content/gdrive/My Drive/Western AI - Intro to Computer Vision Project/CSRNet Crowd Counting Model/model.pt')</span><span id="cc22" class="ki kj it oe b gy om oj l ok ol">model.load_state_dict(checkpoint['state_dict'])</span><span id="735d" class="ki kj it oe b gy om oj l ok ol">import numpy as np<br/>mae = []<br/>for i in xrange(len(img_paths)):</span><span id="2e89" class="ki kj it oe b gy om oj l ok ol">    ...</span><span id="dcd3" class="ki kj it oe b gy om oj l ok ol">    mae.append(abs(np.sum(groundtruth)))<br/>    print i, mae[i]</span></pre><p id="c35e" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">结果各不相同，但最终测试的平均平均误差为 90.19。这与来自训练脚本的 MAE 值有很好的相关性，并且不表明我们的训练集有任何显著的过拟合/欠拟合。以下是一些结果的片段:</p><div class="mr ms mt mu gt ab cb"><figure class="mv mw oo my mz na nb paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><img src="../Images/f7139e5577a9ba5eeeb86f621ce9a3aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:614/format:webp/1*8e6XMmsel6k7sYnZ3W_vAA.png"/></div></figure><figure class="mv mw op my mz na nb paragraph-image"><img src="../Images/d6f4e25caee605ea44dd22c6cb220c8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:712/format:webp/1*C5i7sBwthA94i-O9-51LgQ.png"/></figure><figure class="mv mw oq my mz na nb paragraph-image"><img src="../Images/1cfd89530df513c64effc71273a090ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:656/format:webp/1*0N5fD9A3N3dsvQEOg7PMGg.png"/></figure></div><p id="8c91" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">我们运行了这个验证脚本的一个类似变体，它给出了我们的模型误差/准确性。上述 MAE 值对应于 15.3%的总测试误差(两个测试集:A 和 B)。这意味着我们的模型有 84.7%的准确率。</p><p id="abd7" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated"><strong class="lg iu"> Model.pt: </strong>经过训练和测试后，我们将模型导出到一个. pt 文件(PyTorch ),可以部署到 Flask 上。model.pt 文件包含存储在大规模字典对象中的所有网络参数和权重。</p><figure class="mr ms mt mu gt mw gh gi paragraph-image"><div class="gh gi or"><img src="../Images/daa38ed451ef6cfb74193e95a9428015.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*RAcE77TzKBOivS1XRboeQw.png"/></div></figure><h2 id="4e60" class="ki kj it bd kk kl km dn kn ko kp dp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated"><strong class="ak">调配(烧瓶)</strong></h2><p id="2c9c" class="pw-post-body-paragraph le lf it lg b lh li ju lj lk ll jx lm kr ln lo lp kv lq lr ls kz lt lu lv lw im bi translated">您可以在这里查看我们的 Flask 部署的 GitHub 库:<a class="ae lx" href="https://github.com/jaysondale/Size.AI-Deployment" rel="noopener ugc nofollow" target="_blank">https://github.com/jaysondale/Size.AI-Deployment</a></p><p id="7da0" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">Flask 是一个 Python web 框架，采用易于扩展的理念(<a class="ae lx" href="https://www.fullstackpython.com/flask.html" rel="noopener ugc nofollow" target="_blank">https://www.fullstackpython.com/flask.html</a>)构建。启动您自己的 web 应用程序就像运行具有以下结构的“app . py”Python 文件一样简单:</p><pre class="mr ms mt mu gt od oe of og aw oh bi"><span id="624c" class="ki kj it oe b gy oi oj l ok ol">from flask import Flask<br/>app = Flask(__name__)<br/><br/>@app.route('/')<br/>def hello_world():<br/>    return 'Hello, World!'<br/><br/>if __name__ == '__main__':<br/>    app.run()</span></pre><p id="a4cc" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">在我们的部署框架中，有 5 个关键组件<strong class="lg iu"> : </strong></p><ul class=""><li id="ac6d" class="md me it lg b lh ly lk lz kr mf kv mg kz mh lw mi mj mk ml bi translated">App—启动我们的本地主机端口 5000</li><li id="c870" class="md me it lg b lh mm lk mn kr mo kv mp kz mq lw mi mj mk ml bi translated">推论——初始化我们的模型并做出预测</li><li id="3dda" class="md me it lg b lh mm lk mn kr mo kv mp kz mq lw mi mj mk ml bi translated">commons—引用我们的模型文件</li><li id="a2d5" class="md me it lg b lh mm lk mn kr mo kv mp kz mq lw mi mj mk ml bi translated">Model.pt —我们训练过的模型</li><li id="edde" class="md me it lg b lh mm lk mn kr mo kv mp kz mq lw mi mj mk ml bi translated">模板—包含索引和结果模板(渲染结果页面)</li></ul><figure class="mr ms mt mu gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi os"><img src="../Images/3c230157c548b185b96c94040f5079a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sZchqwlaCT139pkQALaTxw.png"/></div></div></figure><figure class="mr ms mt mu gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi ot"><img src="../Images/f3d2236ced096a20accd9b59e791fe8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5-eIb6gPajP1Qm1nU_nDog.png"/></div></div><p class="nk nl gj gh gi nm nn bd b be z dk translated">在 Cameo 系统建模器中设计的 UML</p></figure><p id="631e" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated"><strong class="lg iu">App(' App . py '):</strong>hello _ world 函数(如上)返回要在 web app 中显示的内容和功能。在我们的例子中，我们需要接受来自用户的图像并返回一个预测。当处理用户输入时，我们需要使用 HTTP 方法。“GET”呈现我们想要的模板，“POST”注册可以执行操作(上传文件)的用户。在这里，您可以看到“app.py”文件中的“上传文件”功能:</p><pre class="mr ms mt mu gt od oe of og aw oh bi"><span id="b89b" class="ki kj it oe b gy oi oj l ok ol">def <strong class="oe iu">upload_file()</strong>:<br/>    if request.method == 'POST':<br/>       absolute_path = os.path.abspath("../")<br/>       if 'file' not in request.files:<br/>          return redirect(request.url)<br/>       file = request.files['file']<br/>       if not file:<br/>          return<br/>       print("GETTING PREDICTION")<br/>       filename = secure_filename(file.filename)<br/>       file.save(os.path.join(app.config['UPLOAD_FOLDER'],filename))<br/>       prediction = <strong class="oe iu">get_prediction</strong>(file) <br/>       return <strong class="oe iu">render_template</strong>('result.html', Prediction=prediction,        File=filename) <br/>       return render_template('index.html')</span></pre><p id="ab68" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated"><strong class="lg iu">推论(' inference.py'): </strong>初始化我们的模型，并从中获得一个预测。应用程序脚本从用户处发送了一个文件作为参数。get_prediction 函数将图像发送到模型并输出结果:</p><pre class="mr ms mt mu gt od oe of og aw oh bi"><span id="299d" class="ki kj it oe b gy oi oj l ok ol">model = get_model() <strong class="oe iu"># initialize model</strong></span><span id="fe09" class="ki kj it oe b gy om oj l ok ol">def get_prediction(file): <br/>    img = transform(Image.open(file).convert('RGB')).cpu() <br/>    output = model(img.unsqueeze(0))<br/>    prediction=int(output.detach().cpu().sum().numpy()) <strong class="oe iu"># prediction</strong><br/>    print("Predicted Count: ",int(output.detach().cpu().sum().numpy())) <br/>    return prediction</span></pre><p id="b5da" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated"><strong class="lg iu"> Commons ('commons.py'): </strong>引用我们的 model.pt 文件。我们从 PyTorch 导入并初始化 CSRNet，然后加载我们的状态字典(来自训练的权重和偏差):</p><pre class="mr ms mt mu gt od oe of og aw oh bi"><span id="ff60" class="ki kj it oe b gy oi oj l ok ol">def get_model():<br/>    model = CSRNet() <strong class="oe iu"># original CSRNet</strong><br/>    model.load_state_dict( torch.load('/Users/charliemackie/CSRNET_DEPLOYMENT/SIZE.AI/Pytorch/model (2).pt', map_location='cpu')) <strong class="oe iu"># local reference to model.pt</strong><br/>    model.eval()<br/>    return model</span></pre><p id="1c16" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">'/Users/charliemackie/CSR net _ DEPLOYMENT/SIZE。AI/Pytorch/model (2)。“pt”是保存在我们的项目目录中的<strong class="lg iu"> Model.pt </strong>的路径。</p><p id="1f28" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">模板:有我们的自定义 HTML 和 CSS 模板，将显示我们的用户界面。这些文件结合了文本标签、按钮和标题。最重要的部分是显示我们的预测，它嵌入在文本正文中，如下所示:</p><pre class="mr ms mt mu gt od oe of og aw oh bi"><span id="22cb" class="ki kj it oe b gy oi oj l ok ol">&lt;h2 class="h5 mb-3 font-weight-normal"&gt;&lt;i&gt;<strong class="oe iu">{{Prediction}}</strong>&lt;/i&gt;&lt;/h2&gt;</span></pre><p id="239f" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">所有这些组件一起工作，我们有我们的功能烧瓶应用程序！</p><h2 id="5261" class="ki kj it bd kk kl km dn kn ko kp dp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated"><strong class="ak">部署(谷歌云)</strong></h2><p id="fc2b" class="pw-post-body-paragraph le lf it lg b lh li ju lj lk ll jx lm kr ln lo lp kv lq lr ls kz lt lu lv lw im bi translated">我们的部署过程利用了谷歌云的三个核心特性:云存储、构建和运行。创建基于云的 web 系统的第一步是将我们的 flask 应用程序容器化，这意味着它将包含在任何给定的计算机系统上运行的所有要求和命令。运行时，云平台被编程为监听 IP 地址为 0.0.0.0:8080 的特定网络端口。这个 IP 和端口被直接硬编码到 flask 应用程序中。将以下文件添加到 flask 应用程序目录中，以完成容器化过程:</p><p id="6852" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated"><strong class="lg iu">需求</strong>(“Requirements . txt”):这个文件包含应用程序运行所需的所有 python 模块。</p><p id="f59c" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">Docker(“Docker file”):这个文件包含一系列启动 flask 应用程序的 CLI 命令。</p><p id="a3d6" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">Dockerfile 文件内容:</p><pre class="mr ms mt mu gt od oe of og aw oh bi"><span id="cda3" class="ki kj it oe b gy oi oj l ok ol">FROM python:3<br/>RUN apt-get update -y<br/>RUN apt-get install -y python-pip python-dev build-essential<br/>COPY . /app<br/>WORKDIR /app<br/>RUN pip install -r requirements.txt<br/>ENTRYPOINT [“python”]<br/>CMD [“app.py”]</span></pre><p id="8d8a" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated"><strong class="lg iu">YAML</strong>(“Cloud build . YAML”):这个文件与 Google Cloud 命令行界面(CLI)一起使用，并提供额外的构建参数(这包括构建目的地)。</p><p id="52f9" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">Yaml 文件内容:</p><pre class="mr ms mt mu gt od oe of og aw oh bi"><span id="b742" class="ki kj it oe b gy oi oj l ok ol">steps:<br/>- name: ‘gcr.io/cloud-builders/docker’<br/>args: [‘build’, ‘-t’, ‘gcr.io/size-ai/app’, ‘.’]<br/>- name: ‘gcr.io/cloud-builders/docker’<br/>args: [‘push’, ‘gcr.io/size-ai/app’]<br/>images: [‘gcr.io/size-ai/app’]</span></pre><p id="46b4" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">一旦添加了这些文件，容器化的应用程序需要被压缩并上传到 Google 云存储中，以便在 web 服务中使用。一旦上传，Google Cloud Build 将遵循 cloudbuild.yaml 提供的步骤，并构建一个基于云的应用程序，该应用程序将准备好进行部署。在 size-deployment 目录中执行了以下命令来完成这两项任务。</p><pre class="mr ms mt mu gt od oe of og aw oh bi"><span id="7447" class="ki kj it oe b gy oi oj l ok ol">$ gcloud builds submit</span></pre><p id="48f5" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">默认情况下，gcloud 接口会查找“cloudbuild.yaml”并完成上传和构建过程。一旦构建完成，就会在 Google Cloud Run 中创建一个 web 服务来托管容器化的应用程序。在配置服务时，我们使用了 2gb 和 900 秒的最大内存和超时余量，让用户有机会上传最高质量的图像。一旦选择了构建版本，我们的应用程序就成功地部署在 Google Cloud 上了！</p><p id="66fa" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">Google Cloud dashboard(下图)让我们可以分析许多有用的指标，包括:请求计数、请求延迟、容器 CPU 利用率和容器内存利用率。通过“请求计数”指标，我们可以查看已经运行的应用程序的每个实例。</p><figure class="mr ms mt mu gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi ou"><img src="../Images/fb2cf6165c4bf0c99ed047c6c39a9fdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GzEBO7tILlEHMbVUrpGp-Q.png"/></div></div></figure><h2 id="41e4" class="ki kj it bd kk kl km dn kn ko kp dp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">下一步，西方人工智能和来源</h2><p id="6435" class="pw-post-body-paragraph le lf it lg b lh li ju lj lk ll jx lm kr ln lo lp kv lq lr ls kz lt lu lv lw im bi translated"><strong class="lg iu">下一步:</strong></p><ul class=""><li id="368f" class="md me it lg b lh ly lk lz kr mf kv mg kz mh lw mi mj mk ml bi translated">调整超参数<em class="no"> : </em>我们希望尝试调整网络以获得更好的结果。超参数可能意味着层数、层大小或激活函数。目前，我们运行现成的 VGG-16/CSRNet 结构——有许多修改的可能性。我们强调的一些领域包括调整学习率和/或在增强型 GPU 上使用更长的训练时间。我们想在不久的将来在对数尺度上测试不同的学习速度。</li><li id="9203" class="md me it lg b lh mm lk mn kr mo kv mp kz mq lw mi mj mk ml bi translated">优化器选择:我们的模型目前使用随机梯度下降(SGD)优化器。这意味着小批量大小为 1，并且在每个训练示例之后执行梯度下降。我们已经讨论了用 Adam 优化器或 RMSprop 进行试验。一旦我们实现了一个新的优化器，我们将有更多的超参数需要优化，包括调整我们的学习率。</li><li id="2db6" class="md me it lg b lh mm lk mn kr mo kv mp kz mq lw mi mj mk ml bi translated">大规模部署:由于模型的大小，我们的 web 应用程序目前是有限的。一个潜在的解决方案是使用迁移学习来训练更有效的模型版本。我们受到了 Geoffrey Hinton 的启发，他在 CUCAI re: Transfer Learning 上向我们展示了开发轻量级 ML 模型的方法。如果我们做到了这一点，我们可以考虑发布一款 IOS 应用。</li></ul><p id="9415" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated"><strong class="lg iu">西方艾:</strong></p><blockquote class="ov ow ox"><p id="dda2" class="le lf no lg b lh ly ju lj lk lz jx lm oy ma lo lp oz mb lr ls pa mc lu lv lw im bi translated">Western AI 是西部大学第一个由学生领导的组织，旨在为校园人工智能创建一个社区。这意味着我们正在为有兴趣接触人工智能的学生建立一个基础，让他们相互认识，学习真正的技能，并培养对理解人工智能在各种行业和经济中的全球影响的重要性的认识。</p><p id="705b" class="le lf no lg b lh ly ju lj lk lz jx lm oy ma lo lp oz mb lr ls pa mc lu lv lw im bi translated">仅在大学学生会(USC)批准运营的第一年，我们就正式吸纳了 170 多名学生成员，并与众多教授、行业专家和其他学生组织合作，在令人印象深刻的短时间内创建了一个非常强大的社区。我们相信有这么大的发展空间，有无数的机会。</p></blockquote><p id="4578" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated"><strong class="lg iu">来源:</strong></p><p id="2aee" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">CSRNet 的 Vidhya 实施:</p><div class="pb pc gp gr pd pe"><a href="https://www.analyticsvidhya.com/blog/2019/02/building-crowd-counting-model-python/" rel="noopener  ugc nofollow" target="_blank"><div class="pf ab fo"><div class="pg ab ph cl cj pi"><h2 class="bd iu gy z fp pj fr fs pk fu fw is bi translated">这是破纪录的人群！一个必读的教程来建立你的第一个人群计数模型，使用…</h2><div class="pl l"><h3 class="bd b gy z fp pj fr fs pk fu fw dk translated">人工智能和机器学习将在未来十年成为我们最大的帮手！今天早上，我在…</h3></div><div class="pm l"><p class="bd b dl z fp pj fr fs pk fu fw dk translated">www.analyticsvidhya.com</p></div></div><div class="pn l"><div class="po l pp pq pr pn ps ng pe"/></div></div></a></div><p id="eac9" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">烧瓶中的 PyTorch:</p><div class="pb pc gp gr pd pe"><a href="https://github.com/avinassh/pytorch-flask-api-heroku" rel="noopener  ugc nofollow" target="_blank"><div class="pf ab fo"><div class="pg ab ph cl cj pi"><h2 class="bd iu gy z fp pj fr fs pk fu fw is bi translated">阿维纳什/皮托赫-烧瓶-api-heroku</h2><div class="pl l"><h3 class="bd b gy z fp pj fr fs pk fu fw dk translated">点击这里查看演示。如果你想检查一个超级简单的 API 服务器，那么检查这个 repo。从…安装它们</h3></div><div class="pm l"><p class="bd b dl z fp pj fr fs pk fu fw dk translated">github.com</p></div></div><div class="pn l"><div class="pt l pp pq pr pn ps ng pe"/></div></div></a></div><p id="b1a0" class="pw-post-body-paragraph le lf it lg b lh ly ju lj lk lz jx lm kr ma lo lp kv mb lr ls kz mc lu lv lw im bi translated">CSRNet 原始论文:</p><div class="pb pc gp gr pd pe"><a href="https://arxiv.org/abs/1802.10062" rel="noopener  ugc nofollow" target="_blank"><div class="pf ab fo"><div class="pg ab ph cl cj pi"><h2 class="bd iu gy z fp pj fr fs pk fu fw is bi translated">CSRNet:用于理解高度拥挤场景的扩展卷积神经网络</h2><div class="pl l"><h3 class="bd b gy z fp pj fr fs pk fu fw dk translated">我们提出了一个用于拥挤场景识别的网络，称为 CSRNet，以提供数据驱动和深度学习的方法…</h3></div><div class="pm l"><p class="bd b dl z fp pj fr fs pk fu fw dk translated">arxiv.org</p></div></div></div></a></div></div><div class="ab cl pu pv hx pw" role="separator"><span class="px bw bk py pz qa"/><span class="px bw bk py pz qa"/><span class="px bw bk py pz"/></div><div class="im in io ip iq"><h2 id="d27f" class="ki kj it bd kk kl km dn kn ko kp dp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">非常感谢我的西部人工智能团队:安迪·马夫鲁迪斯，萨姆·韦勒，帕拉斯·阿胡贾，丹特·德卢卡和杰森·戴尔。</h2><h2 id="2659" class="ki kj it bd kk kl km dn kn ko kp dp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">如有任何问题或意见，请随时联系杰森或我。</h2><h2 id="2626" class="ki kj it bd kk kl km dn kn ko kp dp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated"><strong class="ak">邮箱:Cmacki43@uwo.ca，Jdale29@uwo.ca </strong></h2><h2 id="e574" class="ki kj it bd kk kl km dn kn ko kp dp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">领英:【https://www.linkedin.com/in/charlie-mackie-749ba314b/<a class="ae lx" href="https://www.linkedin.com/in/jaysondale/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/jaysondale/</a>T4</h2></div></div>    
</body>
</html>