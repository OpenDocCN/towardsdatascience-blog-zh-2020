<html>
<head>
<title>Intuitive CNN Creation for Fashion Image Multi-class Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于时尚图像多类分类的直观 CNN 创建</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/intuitively-create-cnn-for-fashion-image-multi-class-classification-6e31421d5227?source=collection_archive---------24-----------------------#2020-04-23">https://towardsdatascience.com/intuitively-create-cnn-for-fashion-image-multi-class-classification-6e31421d5227?source=collection_archive---------24-----------------------#2020-04-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1457" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">服装图像分类中使用 Keras 的卷积神经网络创建的分步走查</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/031530a8f5ec725b5cb5606ec5e7b198.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*Ygc6MMK6uQqcpYFU4n3lTg.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">Img 改编自 Pixabay 通过<a class="ae ku" href="https://pixabay.com/photos/woman-umbrella-floating-jumping-1245817/" rel="noopener ugc nofollow" target="_blank">链接</a></p></figure><p id="44b5" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在之前的<a class="ae ku" href="https://medium.com/@vistaxjtu/cnn-classification-a-cat-or-a-dog-568e6a135602" rel="noopener">文章</a>中，我创建了一个卷积神经网络(CNN)用于二值图像分类。在本文中，我将为零售营销行业创建另一个 CNN。<strong class="kx iu">本文的独特之处在于:不同格式的输入数据需要不同的数据处理方法，不同的 CNN 架构支持多类分类。</strong>它被分成 6 部分。</p><ol class=""><li id="d89e" class="lr ls it kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated">问题陈述</li><li id="54ad" class="lr ls it kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">数据处理</li><li id="1427" class="lr ls it kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">模型结构</li><li id="c893" class="lr ls it kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">模型编译</li><li id="e86e" class="lr ls it kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">模型拟合</li><li id="eb3b" class="lr ls it kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">模型评估</li></ol><p id="4577" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">让我们开始旅程吧🏃‍♀️🏃‍♂️.</p><ol class=""><li id="8085" class="lr ls it kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated"><strong class="kx iu">问题陈述</strong></li></ol><p id="909b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们得到了一组来自零售业的图片。任务是创建一个 CNN 模型来预测一个时尚形象的标签:0 为 t 恤；1 作为裤子；2 作为套头衫；3 作为着装；4 作为外套；5 作为凉鞋；6 as 衬衫；7 作为球鞋；8 as 包；9 作为踝靴。</p><p id="c8fa" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">2.<strong class="kx iu">数据处理</strong></p><p id="dd05" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们使用的数据是具有 70，000 幅图像的 Fashion MINST 数据集，其中 60，000 幅用于训练集，10，000 幅用于测试集。所有图像都是灰度，高 28 像素，宽 28 像素。每个像素代表像素的暗度，范围从 0(黑色)到 255(白色)。</p><p id="7d38" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">图 1 是训练数据的一个片段。请注意，代表图像的每一行都有一个关联的标签和 784 像素值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/aa7abb527009a5e66903169ba9869a26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*ASZO6ME4Fdqzv7ISYLSjqQ.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图 1 训练数据片段</p></figure><p id="945d" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">首先，读入训练和测试数据，将<em class="mg">数据帧</em>类型转换为<em class="mg"> NumPy 数组</em>。</p><pre class="kj kk kl km gt mh mi mj mk aw ml bi"><span id="67ec" class="mm mn it mi b gy mo mp l mq mr">fashion_train_df = pd.read_csv(‘fashion-mnist_train.csv’,sep=’,’)<br/>fashion_test_df = pd.read_csv(‘fashion-mnist_test.csv’, sep = ‘,’)<br/>training = np.array(fashion_train_df, dtype = ‘float32’)<br/>testing = np.array(fashion_test_df, dtype=’float32')</span></pre><p id="78b2" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">如果您想以彩色或灰度模式查看图像，请尝试以下方式:</p><pre class="kj kk kl km gt mh mi mj mk aw ml bi"><span id="0e7b" class="mm mn it mi b gy mo mp l mq mr">i = random.randint(1,60000) <br/>plt.imshow( training[i,1:].reshape((28,28)) ) <br/>plt.imshow( training[i,1:].reshape((28,28)) , cmap = ‘gray’) </span></pre><p id="cece" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">接下来，在 0 和 1 之间缩放独立变量，即像素。</p><pre class="kj kk kl km gt mh mi mj mk aw ml bi"><span id="03cc" class="mm mn it mi b gy mo mp l mq mr">X_train = training[:,1:]/255<br/>y_train = training[:,0]<br/>X_test = testing[:,1:]/255<br/>y_test = testing[:,0]</span></pre><p id="bded" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">然后，将训练数据分成训练集和验证集，验证占 20%。通过验证集，将评估模型对新数据进行概括预测的能力。</p><pre class="kj kk kl km gt mh mi mj mk aw ml bi"><span id="9b89" class="mm mn it mi b gy mo mp l mq mr">X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size = 0.2, random_state = 12345)</span></pre><p id="d3ff" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">最后，我们需要重塑<em class="mg"> X_train </em>，<em class="mg"> X_validate </em>，<em class="mg"> X_test </em>。这是一个临界点。<em class="mg"> Keras </em>只接受 CNN 特殊形状的输入数据，即(批量大小，像素宽度，像素高度，颜色通道数)。因此，</p><pre class="kj kk kl km gt mh mi mj mk aw ml bi"><span id="d6c3" class="mm mn it mi b gy mo mp l mq mr">X_train = X_train.reshape((-1, 28, 28, 1))<br/>X_test = X_test.reshape(X_test.shape[0], *(28, 28, 1))<br/>X_validate = X_validate.reshape(X_validate.shape[0], *(28, 28, 1))</span></pre><p id="cea2" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">请注意，有两种方法用于重塑上述数据，达到了相同的目的。<strong class="kx iu">第一种方法为<em class="mg"> Numpy </em>设置第一维度进行推断，第二种方法用*定义第一维度。</strong></p><p id="7410" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">太好了，现在数据已经准备好训练模型了😎。</p><p id="4dbb" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">3.<strong class="kx iu">模型建立</strong></p><blockquote class="ms mt mu"><p id="cc34" class="kv kw mg kx b ky kz ju la lb lc jx ld mv lf lg lh mw lj lk ll mx ln lo lp lq im bi translated">一般来说，建立一个 CNN 需要 4 个步骤:卷积、最大池化、扁平化和完全连接。在这里，我们将建立一个有两个卷积层的 CNN 模型。</p></blockquote><p id="8c71" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">3.1 卷积</p><blockquote class="ms mt mu"><p id="5b0b" class="kv kw mg kx b ky kz ju la lb lc jx ld mv lf lg lh mw lj lk ll mx ln lo lp lq im bi translated">从根本上说，CNN 是基于卷积的。简而言之，卷积使用一个核矩阵来扫描给定的图像，并应用滤镜来获得某种效果，如模糊和锐化。在 CNN 中，核用于特征提取，以选择图像中最重要的像素，同时保持像素之间的空间关系。</p></blockquote><p id="254d" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">如果你想要一个详细的概念解释，请点击查看上一篇文章<a class="ae ku" href="https://medium.com/p/568e6a135602/edit" rel="noopener">。请随意探索这个神奇的</a><a class="ae ku" href="https://setosa.io/ev/image-kernels/" rel="noopener ugc nofollow" target="_blank">网站</a>来可视化卷积如何工作。另一个很棒的 T4 网站是瑞尔森大学的。它直观、互动地展示了 CNN 是如何工作的。</p><p id="0c81" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">具体来说，</p><pre class="kj kk kl km gt mh mi mj mk aw ml bi"><span id="db59" class="mm mn it mi b gy mo mp l mq mr">classifier = Sequential()<br/>classifier.add(Conv2D(64,3, 3, input_shape = (28,28,1), activation=’relu’))</span></pre><p id="4a2a" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">注意，<em class="mg"> </em>特征检测器的数量<em class="mg"> n </em>设置为 64，特征检测器为 3×3 阵列。<em class="mg"> input_shape </em>是我们通过卷积对其应用特征检测器的输入图像的形状。我们设置为<em class="mg"> (28，28，1)。</em>这里，1 是灰度图像的通道数，28x28 是每个通道中的图像尺寸。这需要与<em class="mg"> X_train </em>、<em class="mg"> X_test </em>、<em class="mg"> X_validate </em>的形状相同。</p><p id="8a91" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">最后一个参数是激活函数。我们使用<strong class="kx iu"> <em class="mg"> ReLU </em> </strong>去除特征图中的负像素值。这是因为根据卷积中使用的参数，我们可能会在特征图中获得负像素。移除负像素增加了非线性分类问题的非线性。</p><p id="b2ac" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">3.2 最大池化</p><blockquote class="ms mt mu"><p id="3816" class="kv kw mg kx b ky kz ju la lb lc jx ld mv lf lg lh mw lj lk ll mx ln lo lp lq im bi translated">最大池化是通过滑动表格并取表格中的最大值来减小卷积产生的特征图的大小。最终，它的目标是在不丢失图像中的关键特征和空间结构信息的情况下，减少完全连接层中的节点数量。</p></blockquote><p id="67f5" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">具体来说，我们使用<em class="mg"> MaxPooling2D() </em>函数来添加池层。一般来说，我们使用 2x2 的表格进行合并。</p><pre class="kj kk kl km gt mh mi mj mk aw ml bi"><span id="6df7" class="mm mn it mi b gy mo mp l mq mr">classifier.add(MaxPooling2D(pool_size = (2, 2)))</span></pre><p id="d46c" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">3.3 辍学</p><p id="f6ad" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">辍学是过度拟合的解决方案。辍学是怎么回事🤔？在每次训练迭代期间，一些神经元被随机禁用，以防止它们过于依赖彼此。通过覆盖这些神经元，神经网络每次都保留不同的架构，帮助神经网络学习数据的独立相关性。这可以防止神经元过度学习。</p><p id="c129" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">具体来说，</p><pre class="kj kk kl km gt mh mi mj mk aw ml bi"><span id="bab0" class="mm mn it mi b gy mo mp l mq mr">classifier.add(Dropout(0.25))</span></pre><p id="9715" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">注意，我们在每次迭代中将 25%的神经元设置为禁用。</p><p id="8908" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">3.4 卷积和最大池化</p><p id="c5cf" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">基于之前的实验，添加第二层用于卷积和最大池以提高模型性能。</p><pre class="kj kk kl km gt mh mi mj mk aw ml bi"><span id="9ef4" class="mm mn it mi b gy mo mp l mq mr">classifier.add(Conv2D(32,3, 3, activation=’relu’))<br/>classifier.add(MaxPooling2D(pool_size = (2, 2)))</span></pre><p id="7697" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">3.5 扁平化</p><blockquote class="ms mt mu"><p id="c40a" class="kv kw mg kx b ky kz ju la lb lc jx ld mv lf lg lh mw lj lk ll mx ln lo lp lq im bi translated">展平是将所有缩减后的特征地图汇集成一个矢量，作为完全连接图层的输入。</p></blockquote><p id="b935" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">具体来说，</p><pre class="kj kk kl km gt mh mi mj mk aw ml bi"><span id="6781" class="mm mn it mi b gy mo mp l mq mr">classifier.add(Flatten())</span></pre><p id="3752" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">3.6 完全连接</p><p id="d1f0" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">通过以上操作，我们将输入图像转换为一维向量。现在让我们使用这个向量作为输入来构建一个分类器。具体来说，</p><pre class="kj kk kl km gt mh mi mj mk aw ml bi"><span id="66d6" class="mm mn it mi b gy mo mp l mq mr">classifier.add(Dense(output_dim = 32, activation = ‘relu’))<br/>classifier.add(Dense(output_dim = 10, activation = ‘sigmoid’))</span></pre><p id="99ab" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">注意，对于第一隐藏层，作为隐藏层中的节点数的<em class="mg"> output_dim </em>被设置为 32。请随意尝试更多。使用<strong class="kx iu"> <em class="mg"> ReLU </em> </strong>作为激活功能。</p><p id="f545" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">完成后，祝贺你完成了模型制作。图 2 是我们构建的🎉🎉。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi my"><img src="../Images/64a9163e8ecf052a548d35411c4916d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*8nXOkOfmXufkk1bJTnQnhg.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图 2 CNN 架构图(作者创建的 Img)</p></figure><p id="0433" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">4.<strong class="kx iu">模型编译</strong></p><p id="932c" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">添加完所有图层后，让我们为训练配置 CNN。要做的一个重要决定是损失函数。至于建议，如果一个样本可以有多个类或者标签，使用<strong class="kx iu"><em class="mg">categorial _ cross entropy</em></strong>。如果类是互斥的(例如，当每个样本恰好属于一个类时)，使用<strong class="kx iu"><em class="mg">sparse _ category _ cross entropy</em></strong>。这里用后者。</p><pre class="kj kk kl km gt mh mi mj mk aw ml bi"><span id="d1c8" class="mm mn it mi b gy mo mp l mq mr">classifier.compile(loss =’sparse_categorical_crossentropy’, optimizer=Adam(lr=0.001), metrics =[‘accuracy’])</span></pre><p id="61b8" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">5.<strong class="kx iu">模型拟合</strong></p><p id="173e" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们根据数据对模型进行 50 次迭代训练。该模型每 512 个样本更新其梯度。使用(<em class="mg"> X_validate </em>，<em class="mg"> y_validate </em>)评估模型损耗和精度。</p><pre class="kj kk kl km gt mh mi mj mk aw ml bi"><span id="976f" class="mm mn it mi b gy mo mp l mq mr">epochs = 50<br/>history = classifier.fit(X_train, y_train, batch_size = 512, nb_epoch = epochs, verbose = 1, validation_data = (X_validate, y_validate))</span></pre><p id="7a1b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">最终我们得到了一个训练精度为<strong class="kx iu"> 92% </strong>和测试精度为<strong class="kx iu"> 90% ✨✨ </strong></p><p id="2af7" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">6.<strong class="kx iu">模型评估</strong></p><p id="33d0" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">现在，让我们在测试集上评估模型。具体来说，</p><pre class="kj kk kl km gt mh mi mj mk aw ml bi"><span id="d971" class="mm mn it mi b gy mo mp l mq mr">evaluation = classifier.evaluate(X_test, y_test)</span></pre><p id="23a8" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们获得了一个<strong class="kx iu"> 90% </strong>的测试准确率！如果你想知道如何计算精度，请阅读这篇<a class="ae ku" href="https://medium.com/@vistaxjtu/intuitively-explain-accuracy-precision-recall-and-f1-777563342aca" rel="noopener">文章</a>。</p><p id="b02a" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">下面的图 3 显示了图像的预测标签和真实标签的视图。这个模型似乎不擅长区分套头衫(2)、衬衫(6)和外套(4)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/91bf1ae098fe3fb4073a3539fee2a975.png" data-original-src="https://miro.medium.com/v2/resize:fit:846/format:webp/1*IJaS7Xmco2ndO9PghqB2GA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图 3 预测和真实类别比较</p></figure><p id="e288" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">如果你想用更多的数据训练模型，可以随意探索这个<a class="ae ku" href="http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html" rel="noopener ugc nofollow" target="_blank">链接</a>。如果你想查一个零售业数据科学创新的真实案例，可以查这个<a class="ae ku" href="https://vue.ai/" rel="noopener ugc nofollow" target="_blank">页面</a>。</p><p id="0509" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">太好了！如果你觉得这篇文章有帮助，请随意点击👏s！如果需要源代码或者更多 CNN 用例，请访问我的</strong> <a class="ae ku" href="https://github.com/luke4u/CNN-Image-Classification" rel="noopener ugc nofollow" target="_blank"> <strong class="kx iu"> Github </strong> </a> <strong class="kx iu">页面🤞🤞。</strong></p></div></div>    
</body>
</html>