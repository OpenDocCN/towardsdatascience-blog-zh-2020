<html>
<head>
<title>Newbie’s Guide to Study Reinforcement Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">新手学习强化学习指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/newbies-guide-to-study-reinforcement-learning-8b9002eff643?source=collection_archive---------4-----------------------#2020-01-30">https://towardsdatascience.com/newbies-guide-to-study-reinforcement-learning-8b9002eff643?source=collection_archive---------4-----------------------#2020-01-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="52fe" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在强化学习领域迈出小步</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/63260ecf5cc83a1cc867357fa21dff18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jWWcwjbhnS2Q8kVFAtVN3w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">本指南中介绍的入门资源包</p></figure><p id="e420" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果计量付费墙困扰着你，请点击<a class="ae lu" rel="noopener" target="_blank" href="/newbies-guide-to-study-reinforcement-learning-8b9002eff643?source=friends_link&amp;sk=40504079487b82552aa921d7cfe2c38a">此链接</a>。</p><p id="675f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你想知道我的深度学习之路，可以看看我在<a class="ae lu" rel="noopener" target="_blank" href="/newbies-guide-to-deep-learning-6bf601c5a98e">新手深度学习指南</a>上的文章。</p><p id="f907" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我在这里要谈的不是强化学习，而是如何研究强化学习，我采取了哪些步骤，以及我在学习过程中发现哪些是有帮助的。如果你发现一些有用的东西，请在评论中告诉我。如果您有其他想要推荐的路径，请将它们留在评论中让其他人看到(我会在适当的地方编辑、添加和更新文本)。和平的人们！</p><h2 id="9e73" class="lv lw it bd lx ly lz dn ma mb mc dp md lh me mf mg ll mh mi mj lp mk ml mm mn bi translated">阻止信息泛滥</h2><p id="144f" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">强化学习有相当多的概念需要你去思考。看到RL技术的完整分类后，你的脑袋会转得更快。一旦你开始阅读所有最酷和最新的研究，以及它们让事情运转的技巧和细节，事情就会变得更加复杂。但是看那些OpenAI机器人玩DoTA太酷了，你可能会想学习它的所有技术和技巧，并建立自己的机器人。首先，停在那里。暂时忘记如何实现自己版本的OpenAI Five。你最终可能会回到起点；也就是说，永远离开RL，却发现自己在三个月后试图重新学习。</p><p id="2f23" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你需要从大量的教程(<a class="ae lu" href="https://medium.com/arkflections/tutorial-syndrome-821588bd2fc8" rel="noopener">我的两分钱教程</a>)和YouTube视频中抽身出来，告诉他们你可以用20行代码在5分钟内编写出“一些棒极了的RL东西”之类的东西。因为他们都没教你什么！是的，什么都没有(除了git克隆和/或复制代码)。一旦你足够努力地去弄清楚价值迭代是如何工作的，并意识到这个想法如此简单，但对于一个简单的玩具例子来说却非常有效，你就会知道知识的真正味道。这就是你学习的方式，也是你在这条学习道路上前进的方式。</p><h2 id="daac" class="lv lw it bd lx ly lz dn ma mb mc dp md lh me mf mg ll mh mi mj lp mk ml mm mn bi translated">在线课程</h2><p id="f982" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">所以，让我们理清思路，重新开始，让自己保持冷静，参加Coursera 的<a class="ae lu" href="https://www.coursera.org/learn/practical-rl/" rel="noopener ugc nofollow" target="_blank">实用强化学习课程。本课程将不是在公园散步，但挑战是锻炼你的大脑和质疑自己是否完全掌握了核心概念。它从非常基本的</a><a class="ae lu" href="https://www.coursera.org/lecture/practical-rl/crossentropy-method-TAT8g" rel="noopener ugc nofollow" target="_blank">交叉熵方法</a>开始，逐渐发展到策略迭代、值迭代、Q学习和SARSA。课程的后半部分包括:深度Q网络和演员-评论家算法。这门课程的一个好处是，你不需要担心繁重的计算资源，因为你可以在Coursera或<a class="ae lu" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"> Google Colab </a>的Jupyter笔记本上完成作业(他们有在Colab上设置的说明)，甚至可以在你自己的机器上用你最喜欢的IDE完成。就个人而言，我更喜欢在我的本地IDE中编写代码，因为我拥有所有的调试工具。事实上，我甚至会引导您在IDE中运行和调试代码，因为您需要理解OpenAI gym对象实际包含的内容(使用print语句并不理想)。否则，你会觉得事情是在黑盒子里，尽管它们不是。查看OpenAI文档，感受特定的环境并愉快地开始调试(是的，当我进行调试会话时，我非常高兴；不确定你会有什么感觉)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/c814a7066004006f261fddf350d42b84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X3IKAwYSlfD4wIx7elikdg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">当你学习新概念时，你的IDE和调试器是你最好的朋友。我发现Jupyter笔记本在跳跃、查找文档和调试时非常笨重。但那是我个人的看法。</p></figure><p id="8bb7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是课程视频会变得非常乏味，你不想吸收任何东西。如果是这种情况，停止视频，直接开始编程作业。我有时发现这真的很有帮助，因为它给了我一个更好的动机，为什么我应该学习课程视频喋喋不休的内容。结合阅读我将在下面提到的教科书。</p><h2 id="82ff" class="lv lw it bd lx ly lz dn ma mb mc dp md lh me mf mg ll mh mi mj lp mk ml mm mn bi translated">身边放一本教科书(这会给你很大帮助！)</h2><p id="862f" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">课本很无聊。我明白了。但有时，他们是那些能在网上文章的海洋中给你一些安慰的人。我在强化学习方面的首选教材是<a class="ae lu" href="https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf" rel="noopener ugc nofollow" target="_blank">萨顿和巴尔托的《强化学习:导论</a>。如果你曾经搜索过强化学习教材，这不会让你感到惊讶，而且它是大多数大学课程的首选教材。</p><p id="d8ab" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">萨顿和巴尔托写了这么好的教科书，真是太棒了。我发现阅读和查找我想知道的东西是一件非常愉快的事情。事实上，我甚至强烈推荐你阅读教材的第一章，对强化学习有一个非常温和的介绍。我发现它比任何其他在线教程或媒体帖子都好。</p><p id="5c39" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这本教材的另一个真正的好处是，即使在学习Coursera课程时，我有时也会发现阅读教材比课程视频本身对我的帮助更大。这有点奇怪，因为大多数时候情况正好相反。所以，我所做的就是在课本和课程视频之间来来回回，填补我的知识空白。然后，我尝试编程作业，以真正检查我是否理解算法的技术细节。</p><h2 id="787b" class="lv lw it bd lx ly lz dn ma mb mc dp md lh me mf mg ll mh mi mj lp mk ml mm mn bi translated">通过编码学习，而不仅仅是通过阅读</h2><p id="7a11" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">当我开始进入强化学习的世界时，我总是对“价值函数”、“Q值”、“最优策略”和“策略”之间的联系感到困惑。相信我，在你实施并使用这些概念来训练你的特工之后，这些概念就会变得一清二楚。阅读文本，观看课程视频，实现功能，运行，调试，重复。</p><h2 id="809a" class="lv lw it bd lx ly lz dn ma mb mc dp md lh me mf mg ll mh mi mj lp mk ml mm mn bi translated">四处玩耍</h2><p id="3338" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">当你在学习Coursera课程的时候(最好是在你完成了课程的第三周，并且对Q-Learning有所了解之后)，看看<a class="ae lu" href="https://www.youtube.com/watch?v=zR11FLZ-O9M" rel="noopener ugc nofollow" target="_blank"> Lex Fridman关于深度强化学习的讲座</a>。这不是技术性的，但现在，你会对幻灯片中的Q-learning部分有更好的理解。关于强化学习的事情是，如果你在需要知道某些概念的时候用谷歌搜索它们，你会暂时记住这些知识，但如果你对这些概念背后的作用没有深刻的理解，你将永远感到困惑。这也是我建议你在充分理解基本概念后去查阅那些讲座的原因之一。然后，试用<a class="ae lu" href="https://selfdrivingcars.mit.edu/deeptraffic/" rel="noopener ugc nofollow" target="_blank">深度流量</a>。有几个参数可供选择，如果你不确定这些参数的含义，查看<a class="ae lu" href="https://selfdrivingcars.mit.edu/deeptraffic-documentation/" rel="noopener ugc nofollow" target="_blank">的文档</a>并阅读<a class="ae lu" href="https://arxiv.org/abs/1801.02805" rel="noopener ugc nofollow" target="_blank">论文</a>以更好地了解为什么某些参数会有帮助。然后，去试试Karpathy的<a class="ae lu" href="https://cs.stanford.edu/people/karpathy/convnetjs/demo/rldemo.html" rel="noopener ugc nofollow" target="_blank">深度Q-Learning Demo </a>。现在，您应该非常熟悉各种超参数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/83a33a9160180cc8a51c5c73ef9ef34e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DltZCEv7hjD5ul3pYLHywQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">尝试几个随机参数并得到好的结果是有趣的，但是不要忘记了解你的变化背后的“为什么”。[ <a class="ae lu" href="https://selfdrivingcars.mit.edu/deeptraffic/" rel="noopener ugc nofollow" target="_blank">深度交通</a></p></figure><h2 id="64b7" class="lv lw it bd lx ly lz dn ma mb mc dp md lh me mf mg ll mh mi mj lp mk ml mm mn bi translated">参数是脆弱的，但首先检查错别字！</h2><p id="9cf2" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">当你开始研究强化学习问题时，你会开始意识到这些参数是多么脆弱。将您的epsilon调整到一个特定的数字，以便在您的代理开始开发之前进行足够的探索，这与为您的DQN网络建立一个具有确切参数的确切架构一样重要。所有这些都会让您认为，如果您的代理没有做好工作，您就没有将所有这些讨厌的超参数调得足够好。但是通常情况下，您可能在代码中的某个地方有一个打字错误。在更新Q值时，您可能错误地传递了当前状态，而不是下一个状态。所以，在你花一整天的时间调优一个参数而没有得到任何好的结果之前，一定要先检查你的代码。</p><h2 id="bb03" class="lv lw it bd lx ly lz dn ma mb mc dp md lh me mf mg ll mh mi mj lp mk ml mm mn bi translated">走向广阔</h2><p id="b135" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">一旦你很好地掌握了基本的强化学习概念，就开始跟随<a class="ae lu" href="http://rail.eecs.berkeley.edu/deeprlcourse/" rel="noopener ugc nofollow" target="_blank">加州大学伯克利分校深度强化学习课程</a>的讲座和<a class="ae lu" href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" rel="noopener ugc nofollow" target="_blank">大卫·西尔弗关于强化学习的讲座</a>。这有助于重申你所学到的东西，并确保你仍然可以跟上，尽管在符号等方面有细微的变化(我们在机器学习文献中也看到了很多；人们使用稍微不同的符号只是为了让你更困惑！).</p><p id="f8c9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">既然你对强化学习的基础有了很好的理解，你应该开始阅读<a class="ae lu" href="https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf" rel="noopener ugc nofollow" target="_blank">关于DQN的开创性论文</a>。如果你只理解深度学习部分而不理解强化学习部分，直接进入深度强化学习是不可取的。这是那些非常精通深度学习但不知道强化学习是什么的人的一个主要谬误。</p><p id="15ca" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">配备了基本的强化学习知识，就可以开始阅读各种深度强化学习论文(并开始实施)。你在某些概念上会有一些知识缺口，但你应该已经有了工具箱中的核心概念，学习额外的技术不再那么困难。我个人的技巧是使用思维导图软件来绘制概念和论文(描述于<a class="ae lu" rel="noopener" target="_blank" href="/newbies-guide-to-deep-learning-6bf601c5a98e">新手深度学习指南</a>)。</p><p id="6254" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其他资源</p><ul class=""><li id="bcbd" class="mv mw it la b lb lc le lf lh mx ll my lp mz lt na nb nc nd bi translated"><a class="ae lu" href="https://spinningup.openai.com/" rel="noopener ugc nofollow" target="_blank"> OpenAI旋转起来</a></li><li id="3ad8" class="mv mw it la b lb ne le nf lh ng ll nh lp ni lt na nb nc nd bi translated"><a class="ae lu" href="https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html" rel="noopener ugc nofollow" target="_blank">Lilian Weng对RL的精彩介绍</a></li></ul></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><p id="b277" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="nq">不管怎样，伙计们，我希望这篇指南能给你足够的动力，让你真正认真对待强化学习，让你从永无止境的YouTubing和在线阅读教程的循环中解脱出来。</em></p></div></div>    
</body>
</html>