<html>
<head>
<title>The enigma of Adjusted R Squared in regression analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">回归分析中的调整 R 平方之谜</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-enigma-of-adjusted-r-squared-57b01edac9f?source=collection_archive---------24-----------------------#2020-08-11">https://towardsdatascience.com/the-enigma-of-adjusted-r-squared-57b01edac9f?source=collection_archive---------24-----------------------#2020-08-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="664c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在数据科学家中，调整后的 R 平方比 R 平方的可信度背后的真正煽动</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/b53c7e535540aee861a7c33146365625.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Rv4aXGJMSZzHC8We"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">马库斯·斯皮斯克在<a class="ae kv" href="https://unsplash.com/s/photos/accuracy?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><blockquote class="kw kx ky"><p id="96b0" class="kz la lb lc b ld le jr lf lg lh ju li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ir">“真理不在于细节的精确；而是传达一个正确的印象。”</strong></p><p id="bef4" class="kz la lb lc b ld le jr lf lg lh ju li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="lc ir">亨利·阿福德</strong></p></blockquote><h2 id="ee38" class="lw lx iq bd ly lz ma dn mb mc md dp me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">介绍</h2><p id="4f29" class="pw-post-body-paragraph kz la iq lc b ld ms jr lf lg mt ju li mf mu ll lm mj mv lp lq mn mw lt lu lv ij bi translated">回归分析是最基本但最重要的机器学习技术之一，它仍然占主导地位，并为行业中的许多高级研究开辟了道路。虽然有一些先进的回归技术已经用于预测连续变量，如 bagging、boosting、support vectors 等，但如果数据在多维空间中表现为直线形式，线性回归原理仍然是大多数研究人员的首选。线性回归模型最广泛使用的评估指标之一是<strong class="lc ir"> R 的平方</strong>又名<strong class="lc ir">决定系数</strong>。r 的平方被认为是一个<strong class="lc ir">拟合优度</strong>度量，在大多数情况下范围在 0 到 1 之间。R 平方值越高，模型的一致性和预测能力越高。</p><p id="b506" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">但与机器学习中的大多数其他评估指标一样，R 平方也有一些限制，这使得它有时通过用极高的值表示一个贫乏的模型来给出不精确的指示。在本文中，我们将讨论 R 平方的计算过程、其局限性，以及如何使用一种称为调整后 R 平方的高级评估指标来克服这些局限性。</p><h2 id="591c" class="lw lx iq bd ly lz ma dn mb mc md dp me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">目录</h2><ol class=""><li id="18ff" class="mx my iq lc b ld ms lg mt mf mz mj na mn nb lv nc nd ne nf bi translated">回归分析中 R 平方的直观性</li><li id="17ce" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv nc nd ne nf bi translated">R 平方的极限</li><li id="f912" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv nc nd ne nf bi translated">调整后的 R 平方的重要性</li></ol><h2 id="34bf" class="lw lx iq bd ly lz ma dn mb mc md dp me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">回归分析中 R 平方的直观性</h2><p id="426d" class="pw-post-body-paragraph kz la iq lc b ld ms jr lf lg mt ju li mf mu ll lm mj mv lp lq mn mw lt lu lv ij bi translated">我们将从一个示例用例开始。假设我们有一个机器学习问题，使用一个人的体重、父亲的身高和母亲的身高作为自变量来预测他/她的身高。</p><p id="f1b9" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">我们有以下研究数据-</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/e8a0221645be976dd147f084a423d884.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cPdltFHM6QNKqG6Pw-jxPA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">回归分析的输入数据(在 MS Excel 上显示)</p></figure><p id="24d8" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">这里，我们的目标变量是身高，预测变量是-</p><ol class=""><li id="87db" class="mx my iq lc b ld le lg lh mf nm mj nn mn no lv nc nd ne nf bi translated">父亲的身高(厘米)</li><li id="da35" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv nc nd ne nf bi translated">母亲的身高(厘米)</li><li id="e777" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv nc nd ne nf bi translated">人的重量(千克)</li></ol><p id="2e88" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">从数据中可以清楚地看出，预测变量和目标变量之间存在线性关系。因此，使用多元线性回归算法来构建模型以服务于我们的预测目的是一种典型的想法。</p><p id="274b" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">让我们假设我们有一个 0.7 的训练比，我们认为前 7 个记录是训练数据，其余的 3 个记录是测试数据。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/f0eae4c40055ed23e7f5894b6f237204.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K-5GS15z1IQmFasFRI_2nQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">培训数据(在 MS Excel 上显示)</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi np"><img src="../Images/9c2df7fc71b14fc48e022539d9c445a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vZ3Nwql2MihCOsXUcEBHcg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">测试数据(在 MS Excel 上显示)</p></figure><p id="cf5f" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">我们完成了线性回归模型，现在，我们需要评估我们的模型，以了解我们的预测与现实的接近程度。</p><p id="a807" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">接下来是 R 平方，这是衡量预测强度和接近程度的最流行的性能评估指标之一。</p><p id="f03c" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated"><strong class="lc ir"> R 的平方= 1- (SSR/SST) </strong></p><p id="aa0d" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">在哪里，</p><p id="6da3" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated"><strong class="lc ir"> SSR =残差平方和</strong></p><p id="74df" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated"><strong class="lc ir"> SST =总和的平方和</strong></p><p id="f162" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">考虑我们对测试数据的预测如下-</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/0917e2eed4701971c002d8d880b4ccf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gCC9-2-UUnurFb72L6pVyg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">带有预测结果的测试数据(在 MS Excel 上显示)</p></figure><p id="0652" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">让我们使用 sklearn 库计算我们模型的 R 平方(之后我们将讨论其数学推导的深入直觉)</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="b9e5" class="lw lx iq ns b gy nw nx l ny nz">#Import necessary packages and libraries<br/>import numpy as np  <br/>import pandas as pd<br/>from sklearn.linear_model import LinearRegression</span><span id="ed3b" class="lw lx iq ns b gy oa nx l ny nz">#Create input data as a dictionary<br/>input_dict = <br/>{<br/>"PersonId": [1,2,3,4,5,6,7,8,9,10],<br/>"Father's height" [136.5,149.8,174.07,168.05,185.8,170.45,180.75,148.15,154.46,158.11],<br/>"Mother's height" : [126.5,143.8,167.07,165.05,182.8,160.45,170.75,140.25,148.46,147.11],<br/>"Weight" : [50,60,79,85,60,65,75,55,62,67] ,<br/>"Person's Height":  [116.5,139.8,184.07,198.05,145.8,160.45,180.75,128.15,144.46,156.11]}</span><span id="22b4" class="lw lx iq ns b gy oa nx l ny nz">#Convert dictionary into a pandas dataframe<br/>data = pd.DataFrame(input_dict)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/708d864cf0c6322f7cd725c978bdafe2.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/format:webp/1*A1MgUGmvkWrZGrszNNjzAw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">用于回归分析的熊猫数据框格式的输入数据(在 Jupyter 笔记本上显示)</p></figure><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="0985" class="lw lx iq ns b gy nw nx l ny nz">#Split the data into train data and test data<br/>X_train = data.head(7)<br/>X_test = data.tail(3)</span><span id="3d8d" class="lw lx iq ns b gy oa nx l ny nz">#Remove UniqueId and target variable<br/>del X_train["PersonId"]<br/>del X_train["Person's Height"]</span><span id="c969" class="lw lx iq ns b gy oa nx l ny nz">#Remove UniqueId and target variable<br/>del X_test["PersonId"]<br/>del X_test["Person's Height"]</span><span id="0ebb" class="lw lx iq ns b gy oa nx l ny nz">y_train = data.head(7)<br/>y_test = data.tail(3)</span><span id="e3b7" class="lw lx iq ns b gy oa nx l ny nz">#Remove UniqueId and predictor variables<br/>del y_train["PersonId"]<br/>del y_train["Father's height"]<br/>del y_train["Mother's height"]<br/>del y_train["Weight"]</span><span id="bbfd" class="lw lx iq ns b gy oa nx l ny nz">#Remove UniqueId and predictor variables<br/>del y_test["PersonId"]<br/>del y_test["Father's height"]<br/>del y_test["Mother's height"]<br/>del y_test["Weight"]</span><span id="c5b4" class="lw lx iq ns b gy oa nx l ny nz">#Perform linear regression using sklearn library<br/>regressor = LinearRegression()<br/>regressor.fit(X_train,y_train)        <br/>predictions = regressor.predict(X_test)</span><span id="5c71" class="lw lx iq ns b gy oa nx l ny nz">#sklearn's inbuilt method for computing the RSquared of the model<br/>rsquared = regressor.score(X_test, y_test)</span><span id="3f66" class="lw lx iq ns b gy oa nx l ny nz">#Predictions of testdata<br/>print(predictions)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/7daf42c048bb735507c7bb5447c24312.png" data-original-src="https://miro.medium.com/v2/resize:fit:280/format:webp/1*bCKD_zCiaWNsVHuqgHCgcg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">测试数据的预测值(在 Jupyter 笔记本上显示)</p></figure><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="823c" class="lw lx iq ns b gy nw nx l ny nz">#R Sqaured of the model<br/>print(rsquared)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi od"><img src="../Images/ba4da7e4c97d6abf3d1d7b88f090a9a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:290/format:webp/1*g17oCt4YuNPcTDJC3pR9dQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">模型的 r 平方值(在 Jupyter 笔记本上显示)</p></figure><p id="ca67" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">这里，R 的平方= 0.963。根据这一指标的特征，这看起来是一个非常好的值。</p><p id="1499" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">但是，这是否足以证实关于该模型预测能力的信心呢？</p><p id="5ab0" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">号码</p><p id="3cea" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">让我们检查一下这个模型调整后的 R 的平方</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="8b51" class="lw lx iq ns b gy nw nx l ny nz">#Adjusted RSquared of the model<br/>n=len(data) #number of records<br/>p=len(data.columns)-2 #number of features .i.e. columns excluding uniqueId and target variable<br/>adjr= 1-(1-score)*(n-1)/(n-p-1)<br/>print(adjr)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/932a7667233e56bb9e685ecf897939d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:350/format:webp/1*KKYQ2mMG_O-qLfkzgh9Z_A.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">模型的调整 R 平方(在 Jupyter 笔记本上有插图)</p></figure><p id="1aae" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">哎呀！！！它小于 R 的平方。此外，从 R 的平方(0.963)到调整后的 R 的平方(0.945)，置信度下降了大约 2%。</p><ol class=""><li id="0698" class="mx my iq lc b ld le lg lh mf nm mj nn mn no lv nc nd ne nf bi translated"><strong class="lc ir">为什么调整后的 R 平方会下降？</strong></li><li id="0e9f" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv nc nd ne nf bi translated"><strong class="lc ir">这种差异所传达的真实直观意义是什么？</strong></li><li id="0a6b" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv nc nd ne nf bi translated"><strong class="lc ir">它将如何反映在实时用例中？</strong></li><li id="886e" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv nc nd ne nf bi translated"><strong class="lc ir">R 的平方是否总是属于 0 到 1 之间的某个值或者有什么我们经常遗漏的例外情况？</strong></li></ol><p id="1ecd" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">让我们知道答案…</p><h2 id="a162" class="lw lx iq bd ly lz ma dn mb mc md dp me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">R 平方的极限</h2><p id="9080" class="pw-post-body-paragraph kz la iq lc b ld ms jr lf lg mt ju li mf mu ll lm mj mv lp lq mn mw lt lu lv ij bi translated"><strong class="lc ir"> R 的平方= 1- (SSR/SST) </strong></p><p id="bf90" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">这里，SST 代表总和的平方和，它只表示“<strong class="lc ir">预测点与目标变量的平均值相差多少</strong>”。均值在这里不过是一条回归线。</p><p id="71c0" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated"><strong class="lc ir"> SST = Sum(平方(每个数据点——目标变量的平均值))</strong></p><p id="20ad" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">数学上，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi of"><img src="../Images/4135aef913811177f9c5efb87c7b74fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*4u2pVDYgkfrZyDlJbFViyg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在 MS Word 上显示</p></figure><p id="ebed" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">在哪里，</p><p id="85e7" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">n =观察次数</p><p id="1781" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">y =目标变量的观察值</p><p id="246c" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">y̅ =目标变量的平均值</p><p id="238e" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">举个例子，</p><p id="585e" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">如果我们想建立一个回归模型，以体重作为独立变量来预测一个人的身高，那么一个不需要太多努力的可能预测就是计算属于我们样本的所有人的平均身高，并将其视为预测值。下图中的红线显示了属于我们样本的所有人的平均身高。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/c617c9240b3dc46834041181304a1792.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/0*J2uaExFFs9UWN5VG"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在 MS Paint 上显示</p></figure><p id="2a07" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">现在来看 SSR，</p><p id="2927" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">SSR 代表残差平方和。这个残差是从我们用数学方法(线性回归、贝叶斯回归、多项式回归或任何其他方法)构建的模型中计算出来的。如果我们使用复杂的方法，而不是简单的方法，比如均值，那么我们的准确度就会提高。</p><p id="6eb5" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated"><strong class="lc ir"> SSR = Sum(平方(每个数据点—回归线中每个对应的数据点))</strong></p><p id="7b43" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">数学上，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/4b0f7133fa363e2d068d1ef74fb33cd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*TAIGzDR-6ypHl4HYC0RbwA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在 MS Word 上显示</p></figure><p id="59d2" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">在哪里，</p><p id="0216" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">n =观察次数</p><p id="d657" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">y =目标变量的观察值</p><p id="5f9d" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">ŷ =目标变量的预测值</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/4a6dd8dbe67bc442eeb33667caa917f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/0*J7LOP4xPhAkDQyGU"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在 MS Paint 上显示</p></figure><p id="c06c" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">在上图中，让我们假设蓝线表示通过高级数学分析的复杂模型的预测。我们可以看到它比红线有更高的精度。</p><p id="0a0a" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">现在来看公式，</p><p id="0219" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated"><strong class="lc ir"> R 的平方= 1- (SSR/SST) </strong></p><p id="00ff" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">这里，</p><ul class=""><li id="8d45" class="mx my iq lc b ld le lg lh mf nm mj nn mn no lv oj nd ne nf bi translated"><strong class="lc ir"> SST 会是一个很大的数字，因为它是一个很差的型号(红线)。</strong></li><li id="4481" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv oj nd ne nf bi translated"><strong class="lc ir"> SSR 将是一个小数字，因为它是我们经过大量数学分析后开发的最佳模型(蓝线)。</strong></li><li id="5cbc" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv oj nd ne nf bi translated"><strong class="lc ir">所以，SSR/SST 会是一个很小的数(每当 SSR 降低的时候就会变得很小)。</strong></li><li id="0883" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv oj nd ne nf bi translated"><strong class="lc ir">所以，1- (SSR/SST)会是一个很大的数字。</strong></li><li id="672c" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv oj nd ne nf bi translated"><strong class="lc ir">所以我们可以推断，每当 R 的平方变高，就说明模型太好了。</strong></li></ul><p id="38a6" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">这是一种一般情况，但在存在多个独立变量的许多情况下，这是不适用的。在这个例子中，我们只有一个自变量和一个目标变量，但在实际情况下，我们将有 100 个自变量作为一个因变量。实际问题是，在 100 个独立变量中</p><ul class=""><li id="02ea" class="mx my iq lc b ld le lg lh mf nm mj nn mn no lv oj nd ne nf bi translated"><strong class="lc ir">有些变量会与目标变量有很高的相关性。</strong></li><li id="dca6" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv oj nd ne nf bi translated"><strong class="lc ir">有些变量与目标变量的相关性很小。</strong></li><li id="83ed" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv oj nd ne nf bi translated"><strong class="lc ir">此外，一些独立变量根本不相关。</strong></li></ul><p id="9bad" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">如果没有相关性，那么发生的是<strong class="lc ir">——“我们的模型将自动尝试建立因变量和自变量之间的关系，并继续进行数学计算，假设研究人员已经消除了不想要的自变量。”</strong></p><p id="b68f" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">举个例子，</p><p id="0e4c" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">为了预测一个人的身高，我们将有以下自变量</p><ul class=""><li id="7330" class="mx my iq lc b ld le lg lh mf nm mj nn mn no lv oj nd ne nf bi translated"><strong class="lc ir">权重(高相关性)</strong></li><li id="1469" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv oj nd ne nf bi translated"><strong class="lc ir">电话号码(无关联)</strong></li><li id="43c4" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv oj nd ne nf bi translated"><strong class="lc ir">位置(低相关性)</strong></li><li id="a24d" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv oj nd ne nf bi translated"><strong class="lc ir">年龄(高相关性)</strong></li><li id="85e2" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv oj nd ne nf bi translated"><strong class="lc ir">性别(低相关性)</strong></li></ul><p id="ede3" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">在这里，只有体重和年龄足以建立一个精确的模型，但该模型将假设电话号码也会影响身高，并在多维空间中表示它。当通过这 5 个独立变量构建回归平面时，<strong class="lc ir">的梯度、截距、成本和残差</strong>将自动调整以提高精确度。当精度得到人为提高时，显然 R 的平方也会增加。</p><p id="bd6f" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">在这种情况下，回归平面将接触多维空间中原始数据点的所有边缘。这将使 SSR 成为一个非常小的数字，最终将使 R 的平方成为一个非常大的数字，但是当引入测试数据时，这样的模型将悲惨地失败。</p><p id="95a9" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">这就是为什么高 R 平方值不能保证精确模型的原因。</p><h2 id="0da4" class="lw lx iq bd ly lz ma dn mb mc md dp me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">调整后的 R 平方的重要性</h2><p id="ae57" class="pw-post-body-paragraph kz la iq lc b ld ms jr lf lg mt ju li mf mu ll lm mj mv lp lq mn mw lt lu lv ij bi translated">为了克服上面提到的挑战，我们有一个额外的指标叫做<strong class="lc ir">调整的 R 平方</strong>。</p><p id="8607" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated"><strong class="lc ir">调整后的 R 平方= 1—[(1—R 平方)* (n-1) ) / (n-p-1) ] </strong></p><p id="ece0" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">在哪里，</p><ul class=""><li id="d944" class="mx my iq lc b ld le lg lh mf nm mj nn mn no lv oj nd ne nf bi translated"><strong class="lc ir"> p =自变量的数量。</strong></li><li id="b904" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv oj nd ne nf bi translated"><strong class="lc ir"> n =数据集中的记录数。</strong></li></ul><p id="06fc" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">对于一个简单的表示，我们可以这样重写上面的公式</p><p id="21d4" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated"><strong class="lc ir">调整后的 R 平方= 1 — (A * B) </strong></p><p id="f02c" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">在哪里，</p><ul class=""><li id="eb3e" class="mx my iq lc b ld le lg lh mf nm mj nn mn no lv oj nd ne nf bi translated"><strong class="lc ir"> A = 1 — R 的平方</strong></li><li id="aea7" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv oj nd ne nf bi translated"><strong class="lc ir"> B = (n-1) / (n-p-1) </strong></li></ul><p id="024a" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">从上面的公式，我们可以冲动地考虑以下推论——</p><ul class=""><li id="298f" class="mx my iq lc b ld le lg lh mf nm mj nn mn no lv oj nd ne nf bi translated"><strong class="lc ir">当预测变量的数量增加时，会降低 b 的整体值。</strong></li><li id="8424" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv oj nd ne nf bi translated"><strong class="lc ir">当 R 的平方值增加时，它将减少 a 的整个值。</strong></li><li id="ff2c" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv oj nd ne nf bi translated">因此，从技术上讲，如果 R 的平方很高或者预测变量的数量很高，那么 A 和 B 的值都会受到惩罚。</li><li id="f9ac" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv oj nd ne nf bi translated">如果我们把 A 和 B 相乘，那么它将是一个小得多的数。</li><li id="ff49" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv oj nd ne nf bi translated">如果我们从 1 中减去 A 和 B 的乘积，那么它肯定小于 1，除非 p = 1。</li><li id="0eef" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv oj nd ne nf bi translated"><strong class="lc ir">不仅 R 平方和经调整的 R 平方之间的差异，而且经调整的 R 平方本身的值都可以被认为是代替 R 平方的限制的拟合优度度量，用于评估模型的设想一致性。</strong></li></ul><p id="331e" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">总的来说，当自变量的数量增加时，它会惩罚公式，所以总价值会下降。受自变量增加的影响最小。因此，调整后的 R 平方将比 R 平方更准确地指示模型的性能。</p><h2 id="b6e9" class="lw lx iq bd ly lz ma dn mb mc md dp me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">R 的平方可以是负数吗？</h2><p id="f1df" class="pw-post-body-paragraph kz la iq lc b ld ms jr lf lg mt ju li mf mu ll lm mj mv lp lq mn mw lt lu lv ij bi translated">是的。在一些罕见的情况下，它也可以是负值。</p><p id="0d64" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">因为，R 的平方= 1 — ( SSR / SST)</p><p id="3032" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">它是基于这样的假设计算的，即目标的平均线是 y 轴的垂直线，是模型在最大风险情况下可能具有的最差拟合。SST 是这条平均线和原始数据点之间的平方差。类似地，SSR 是预测数据点(通过模型平面)和原始数据点之间的平方差。</p><p id="5e0c" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">SSR/SST 给出了一个比率，该比率表明，<strong class="lc ir">“相对于 SST，SSR 如何最差？”</strong>。如果你的模型能在某种程度上建造出一架相对较好的飞机，那么在 99%的情况下，SSR &lt; SST。如果你把它代入方程，它最终会使 R 的平方为正。</p><p id="5d2a" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">但是如果 SSR &gt;SST 呢？这意味着你的回归平面比均值线(SST)差。在这种情况下，R 的平方将是负的。但这种情况只发生在 1%或更少的病例中。</p><h2 id="73ba" class="lw lx iq bd ly lz ma dn mb mc md dp me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">结论</h2><p id="eed1" class="pw-post-body-paragraph kz la iq lc b ld ms jr lf lg mt ju li mf mu ll lm mj mv lp lq mn mw lt lu lv ij bi translated">尽管 R 平方是一种众所周知的、被广泛接受的性能评估方法，但在一些不属于它的范围的情况下，它的推理传递能力有所下降。然而，要接受的是，没有一根魔棒可以 100%完全代表回归模型的固有倾向。调整后的 R 平方是这样一个指标，它可以在很大程度上适应 R 平方的局限性，并且仍然是全球数据科学家青睐的主要原因。</p><p id="13fb" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">尽管这不在本文的讨论范围内，但请看看我们在回归和预测中通常使用的其他一些性能评估指标<a class="ae kv" href="https://medium.com/@sanjayjsw05/time-series-analysis-complete-tutorial-for-beginners-part-4-afea36da7ac6" rel="noopener"> <strong class="lc ir">这里</strong> </a> <strong class="lc ir"> </strong>像 MAE、MSE、RMSE、MAPE 等。除了我们到目前为止在这里讨论的内容之外，它将给你一个处理连续变量的模型评估的更先天的视角。</p><p id="aa8e" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">我希望现在你对 R 平方和调整后 R 平方的原理和推导，以及如何在正确的位置和正确的时间实现它们有了直观的理解。</p><p id="4e4f" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated">您可以通过以下平台与我联系-</p><ol class=""><li id="4584" class="mx my iq lc b ld le lg lh mf nm mj nn mn no lv nc nd ne nf bi translated"><a class="ae kv" href="https://www.quora.com/profile/Sanjay-Kumar-563?q=sanjay%20kumar" rel="noopener ugc nofollow" target="_blank"> Quora </a></li><li id="40de" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv nc nd ne nf bi translated"><a class="ae kv" href="https://www.linkedin.com/in/sanjay-nandakumar-8278229b/" rel="noopener ugc nofollow" target="_blank">领英</a></li><li id="8307" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv nc nd ne nf bi translated">Gmail—sanjayjsw05@gmail.com</li></ol><h2 id="582e" class="lw lx iq bd ly lz ma dn mb mc md dp me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">参考</h2><ol class=""><li id="165c" class="mx my iq lc b ld ms lg mt mf mz mj na mn nb lv nc nd ne nf bi translated">Sougata Deb，<strong class="lc ir"> </strong> <a class="ae kv" href="https://link.springer.com/chapter/10.1007%2F978-3-319-48517-1_12" rel="noopener ugc nofollow" target="_blank"> <strong class="lc ir">一种新的稳健 R 平方测度及其在线性回归中的应用</strong></a><strong class="lc ir"><em class="lb"/></strong>(2016)</li><li id="30e7" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv nc nd ne nf bi translated">Kazhurio Ohtani 和 Hisashi Tanizaki，<a class="ae kv" href="http://www2.econ.osaka-u.ac.jp/~tanizaki/cv/papers/dist_r2.pdf" rel="noopener ugc nofollow" target="_blank"><strong class="lc ir">R2 和调整后的 R2 在线性回归模型中的精确分布，带有多元误差项<em class="lb"> </em> </strong> </a> (2004 年)</li><li id="c0ed" class="mx my iq lc b ld ng lg nh mf ni mj nj mn nk lv nc nd ne nf bi translated">Carrodus，M.L .和 Giles，D.E.A .，<a class="ae kv" href="https://www.sciencedirect.com/science/article/abs/pii/016517659290021P" rel="noopener ugc nofollow" target="_blank"> <strong class="lc ir">回归扰动自相关时 R2 的精确分布</strong> </a>，《经济学快报》，38，375–380(1992)</li></ol><p id="e5f4" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mf lk ll lm mj lo lp lq mn ls lt lu lv ij bi translated"><strong class="lc ir">感谢阅读！！！</strong></p></div></div>    
</body>
</html>