<html>
<head>
<title>Oversampling and Undersampling</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">过采样和欠采样</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/oversampling-and-undersampling-5e2bbaf56dcf?source=collection_archive---------1-----------------------#2020-09-10">https://towardsdatascience.com/oversampling-and-undersampling-5e2bbaf56dcf?source=collection_archive---------1-----------------------#2020-09-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e347" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一种不平衡分类技术</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/40d0fd0e2e9a557256e67ad3b537634a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_ONKGIky1GvS60y_"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@morningbrew?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">晨酿</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><h2 id="e626" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated"><span class="l lv lw lx bm ly lz ma mb mc di">我</span>简介</h2><p id="e499" class="pw-post-body-paragraph md me it mf b mg mh ju mi mj mk jx ml li mm mn mo lm mp mq mr lq ms mt mu mv im bi mw translated">不平衡分类问题是当我们的训练数据的类别分布存在严重偏斜时我们所面临的问题。好吧，偏斜可能不是非常严重(它可以变化)，但我们将不平衡分类识别为一个问题的原因是因为它可以影响我们的机器学习算法的性能。</p><p id="ed49" class="pw-post-body-paragraph md me it mf b mg mx ju mi mj my jx ml li mz mn mo lm na mq mr lq nb mt mu mv im bi translated">不平衡可能影响我们的机器学习算法的一种方式是当我们的算法完全忽略少数类时。这之所以是一个问题，是因为少数民族阶层通常是我们最感兴趣的阶层。例如，当构建一个分类器来根据各种观察结果对欺诈性和非欺诈性交易进行分类时，数据中的非欺诈性交易可能比欺诈性交易多，我的意思是想一想，如果我们有等量的欺诈性交易和非欺诈性交易，这将非常令人担忧。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/73cea4e36d23de4f6f032900b8f56bce.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*emgamRvmZiswj9AYoycEFQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 1:欺诈检测问题的类别分布示例</p></figure><p id="578e" class="pw-post-body-paragraph md me it mf b mg mx ju mi mj my jx ml li mz mn mo lm na mq mr lq nb mt mu mv im bi translated">应对这一挑战的方法是<em class="nd">随机抽样。</em>执行随机重采样有两种主要方式，各有利弊:</p><p id="d6d0" class="pw-post-body-paragraph md me it mf b mg mx ju mi mj my jx ml li mz mn mo lm na mq mr lq nb mt mu mv im bi translated"><strong class="mf iu">过采样</strong> —从少数类中复制样本</p><p id="a2a5" class="pw-post-body-paragraph md me it mf b mg mx ju mi mj my jx ml li mz mn mo lm na mq mr lq nb mt mu mv im bi translated"><strong class="mf iu">欠采样</strong> —从多数类中删除样本。</p><p id="563f" class="pw-post-body-paragraph md me it mf b mg mx ju mi mj my jx ml li mz mn mo lm na mq mr lq nb mt mu mv im bi translated">换句话说，过采样和欠采样都涉及引入一种偏向，从一个类别中选择比另一个类别更多的样本，以补偿数据中已经存在的不平衡，或者如果采取纯粹随机的样本，可能会出现的不平衡(来源:<a class="ae ky" href="https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis" rel="noopener ugc nofollow" target="_blank">维基百科</a>)。</p><p id="d41d" class="pw-post-body-paragraph md me it mf b mg mx ju mi mj my jx ml li mz mn mo lm na mq mr lq nb mt mu mv im bi translated">我们将随机抽样定义为一种幼稚的技术，因为在执行时，它不假设任何数据。它涉及创建我们数据的新转换版本，其中有一个新的类分布，以减少数据对我们机器学习算法的影响。</p><blockquote class="ne nf ng"><p id="4df1" class="md me nd mf b mg mx ju mi mj my jx ml nh mz mn mo ni na mq mr nj nb mt mu mv im bi translated"><strong class="mf iu">注意</strong>:我们称随机重采样为幼稚，因为在执行时，它不对数据做任何假设。</p></blockquote></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><p id="4034" class="pw-post-body-paragraph md me it mf b mg mx ju mi mj my jx ml li mz mn mo lm na mq mr lq nb mt mu mv im bi translated">在本文中，我们将利用 2014 年启动的<code class="fe nr ns nt nu b">imbalanced-learn</code>框架，主要关注 SMOTE(另一种不平衡数据技术)的实施。多年来，已经实现了额外的过采样和欠采样方法，并使该框架与流行的机器学习框架<code class="fe nr ns nt nu b">scikit-learn</code>兼容。访问<a class="ae ky" href="https://imbalanced-learn.readthedocs.io/en/stable/about.html" rel="noopener ugc nofollow" target="_blank">不平衡学习</a>获取安装指南和完整文档。</p><pre class="kj kk kl km gt nv nu nw nx aw ny bi"><span id="da3d" class="kz la it nu b gy nz oa l ob oc">from sklearn.datasets import make_classification<br/>from imblearn.over_sampling import RandomOverSampler<br/>from imblearn.under_sampling import RandomUnderSampler<br/>from collections import Counter</span><span id="1120" class="kz la it nu b gy od oa l ob oc"># defining the dataset<br/>X, y = make_classification(n_samples= 10000, weights=[.99])</span><span id="26e9" class="kz la it nu b gy od oa l ob oc"># class distribution<br/><strong class="nu iu">print</strong>(Counter(y))</span><span id="467a" class="kz la it nu b gy od oa l ob oc">Counter({0: 9844, 1: 156})</span></pre><p id="b25c" class="pw-post-body-paragraph md me it mf b mg mx ju mi mj my jx ml li mz mn mo lm na mq mr lq nb mt mu mv im bi translated">完整的代码你可以访问我的<a class="ae ky" href="https://github.com/kurtispykes/demo/blob/master/notebook/kpy_random_sampling_example.ipynb" rel="noopener ugc nofollow" target="_blank"> Github </a>。</p><div class="oe of gp gr og oh"><a href="https://github.com/kurtispykes/demo/blob/master/notebook/kpy_random_sampling_example.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd iu gy z fp om fr fs on fu fw is bi translated">kurtispykes/演示</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">permalink dissolve GitHub 是超过 5000 万开发人员的家园，他们一起工作来托管和审查代码，管理…</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">github.com</p></div></div><div class="oq l"><div class="or l os ot ou oq ov ks oh"/></div></div></a></div></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h2 id="3016" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">随机过采样</h2><p id="118d" class="pw-post-body-paragraph md me it mf b mg mh ju mi mj mk jx ml li mm mn mo lm mp mq mr lq ms mt mu mv im bi translated">随机过采样包括用替换从少数类中选择随机样本，并用该样本的多个副本补充训练数据，因此单个样本可能被选择多次。</p><blockquote class="ow"><p id="9be4" class="ox oy it bd oz pa pb pc pd pe pf mv dk translated">随机过采样可能增加过拟合发生的可能性，因为它精确复制了少数类的例子。以这种方式，举例来说，一个符号分类器可能构建表面上准确的规则，但实际上覆盖了一个复制的例子。”—第 83 页，<a class="ae ky" href="https://www.amazon.co.uk/Learning-Imbalanced-Data-Alberto-Fern%C3%A1ndez/dp/3319980734" rel="noopener ugc nofollow" target="_blank">从不平衡数据集学习</a>，2018。</p></blockquote><p id="d62b" class="pw-post-body-paragraph md me it mf b mg pg ju mi mj ph jx ml li pi mn mo lm pj mq mr lq pk mt mu mv im bi translated">对于受偏斜分布影响的机器学习算法，如人工神经网络和<a class="ae ky" rel="noopener" target="_blank" href="/algorithms-from-scratch-support-vector-machine-6f5eb72fce10">支持向量机</a>，这是一种非常有效的技术。然而，在许多情况下建议调整目标类分布，因为为严重不平衡的数据集寻求平衡分布会导致算法过度适应少数类，从而导致我们的泛化错误增加。</p><p id="aeab" class="pw-post-body-paragraph md me it mf b mg mx ju mi mj my jx ml li mz mn mo lm na mq mr lq nb mt mu mv im bi translated">我们应该意识到的另一件事是计算成本的增加。当我们训练模型时，增加少数类中的示例数量(特别是对于严重偏斜的数据集)可能会导致计算量增加，并且考虑到模型多次看到相同的示例，这不是一件好事。</p><p id="39e2" class="pw-post-body-paragraph md me it mf b mg mx ju mi mj my jx ml li mz mn mo lm na mq mr lq nb mt mu mv im bi translated">尽管如此，过采样是一个相当不错的解决方案，应该进行测试。下面是我们如何用 Python 实现它…</p><pre class="kj kk kl km gt nv nu nw nx aw ny bi"><span id="4c0c" class="kz la it nu b gy nz oa l ob oc"># instantiating the random over sampler <br/>ros = RandomOverSampler()<br/># resampling X, y<br/>X_ros, y_ros = ros.fit_resample(X, y)</span><span id="1c33" class="kz la it nu b gy od oa l ob oc"># new class distribution <br/><strong class="nu iu">print</strong>(Counter(y_ros))</span><span id="790f" class="kz la it nu b gy od oa l ob oc">Counter({0: 9844, 1: 9844})</span></pre></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h2 id="375c" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">随机欠采样</h2><p id="2493" class="pw-post-body-paragraph md me it mf b mg mh ju mi mj mk jx ml li mm mn mo lm mp mq mr lq ms mt mu mv im bi translated">随机欠采样与随机过采样相反。该方法试图从多数类中随机选择和移除样本，从而减少变换数据中多数类中的样本数量。</p><blockquote class="ow"><p id="fa4c" class="ox oy it bd oz pa pb pc pd pe pf mv dk translated">“在(潜在的)随机欠采样中，大量数据被丢弃。[……]这可能是一个很大的问题，因为这些数据的丢失会使少数和多数实例之间的决策界限更难了解，从而导致分类性能的损失。”——第 45 页，<a class="ae ky" href="https://www.amazon.co.uk/Imbalanced-Learning-Foundations-Algorithms-Applications/dp/1118074629" rel="noopener ugc nofollow" target="_blank">不平衡学习:基础、算法和应用</a>，2013 年</p></blockquote><p id="35a0" class="pw-post-body-paragraph md me it mf b mg pg ju mi mj ph jx ml li pi mn mo lm pj mq mr lq pk mt mu mv im bi translated">欠采样的结果是在多数类中具有较少样本的变换数据集——可以重复该过程，直到每个类中的样本数量相等。</p><p id="d767" class="pw-post-body-paragraph md me it mf b mg mx ju mi mj my jx ml li mz mn mo lm na mq mr lq nb mt mu mv im bi translated">尽管存在严重的不平衡，但在少数类有足够数量的例子的情况下，使用这种方法是有效的。另一方面，考虑有价值的信息被删除的可能性总是很重要的，因为我们随机地将它们从我们的数据集中删除，因为我们没有办法检测或保存在多数类中信息丰富的例子。</p><p id="12c4" class="pw-post-body-paragraph md me it mf b mg mx ju mi mj my jx ml li mz mn mo lm na mq mr lq nb mt mu mv im bi translated">为了更好地理解这个方法，这里有一个 python 实现…</p><pre class="kj kk kl km gt nv nu nw nx aw ny bi"><span id="d395" class="kz la it nu b gy nz oa l ob oc"># instantiating the random undersampler<br/>rus = RandomUnderSampler() <br/># resampling X, y<br/>X_rus, y_rus = rus.fit_resample(X, y)</span><span id="252e" class="kz la it nu b gy od oa l ob oc"># new class distribution<br/>print(Counter(y_rus))</span><span id="ce99" class="kz la it nu b gy od oa l ob oc">Counter({0: 156, 1: 156})</span></pre></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h2 id="1a52" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">结合两种随机抽样技术</h2><p id="6f79" class="pw-post-body-paragraph md me it mf b mg mh ju mi mj mk jx ml li mm mn mo lm mp mq mr lq ms mt mu mv im bi translated">与单独执行的方法相比，结合使用两种随机采样方法有时可以提高整体性能。</p><p id="2cb0" class="pw-post-body-paragraph md me it mf b mg mx ju mi mj my jx ml li mz mn mo lm na mq mr lq nb mt mu mv im bi translated">其概念是，我们可以对少数类应用适度的过采样，这改善了对少数类示例的偏差，同时我们还对多数类执行适度的欠采样，以减少对多数类示例的偏差。</p><p id="be1b" class="pw-post-body-paragraph md me it mf b mg mx ju mi mj my jx ml li mz mn mo lm na mq mr lq nb mt mu mv im bi translated">为了在 Python 中实现这一点，利用<code class="fe nr ns nt nu b">imbalanced-learn</code>框架，我们可以在过采样和欠采样技术中使用<code class="fe nr ns nt nu b">sampling_strategy</code>属性。</p><pre class="kj kk kl km gt nv nu nw nx aw ny bi"><span id="a487" class="kz la it nu b gy nz oa l ob oc"># instantiating over and under sampler<br/>over = RandomOverSampler(sampling_strategy=0.5)<br/>under = RandomUnderSampler(sampling_strategy=0.8)</span><span id="615b" class="kz la it nu b gy od oa l ob oc"># first performing oversampling to minority class<br/>X_over, y_over = over.fit_resample(X, y)<br/><strong class="nu iu">print</strong>(f"Oversampled: {Counter(y_over)}")</span><span id="64f4" class="kz la it nu b gy od oa l ob oc">Oversampled: Counter({0: 9844, 1: 4922})</span><span id="1f6f" class="kz la it nu b gy od oa l ob oc"># now to comine under sampling <br/>X_combined_sampling, y_combined_sampling = under.fit_resample(X_over, y_over)<br/><strong class="nu iu">print</strong>(f"Combined Random Sampling: {Counter(y_combined_sampling)}")</span><span id="e6d3" class="kz la it nu b gy od oa l ob oc">Combined Random Sampling: Counter({0: 6152, 1: 4922})</span></pre></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h2 id="dfa8" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">包裹</h2><p id="bb9e" class="pw-post-body-paragraph md me it mf b mg mh ju mi mj mk jx ml li mm mn mo lm mp mq mr lq ms mt mu mv im bi translated">在本指南中，我们讨论了不平衡分类的过采样和欠采样。在许多情况下，我们可能会遇到不平衡的数据集，应用随机抽样可以为我们提供一个非常好的模型来克服训练中的这个问题，并仍然保持一个可以很好地推广到新示例的模型。</p><p id="4b2d" class="pw-post-body-paragraph md me it mf b mg mx ju mi mj my jx ml li mz mn mo lm na mq mr lq nb mt mu mv im bi translated">让我们继续 LinkedIn 上的对话…</p><div class="oe of gp gr og oh"><a href="https://www.linkedin.com/in/kurtispykes/" rel="noopener  ugc nofollow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd iu gy z fp om fr fs on fu fw is bi translated">Kurtis Pykes -人工智能作家-走向数据科学| LinkedIn</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">在世界上最大的职业社区 LinkedIn 上查看 Kurtis Pykes 的个人资料。Kurtis 有两个工作列在他们的…</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">www.linkedin.com</p></div></div><div class="oq l"><div class="pl l os ot ou oq ov ks oh"/></div></div></a></div></div></div>    
</body>
</html>