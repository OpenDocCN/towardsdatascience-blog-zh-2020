<html>
<head>
<title>Dimensionality Reduction: PCA versus Autoencoders</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">降维:PCA 与自动编码器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/dimensionality-reduction-pca-versus-autoencoders-338fcaf3297d?source=collection_archive---------9-----------------------#2020-06-18">https://towardsdatascience.com/dimensionality-reduction-pca-versus-autoencoders-338fcaf3297d?source=collection_archive---------9-----------------------#2020-06-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c6f1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">主成分分析和自动编码器降维的比较</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/2685cffad2dfe066e7e13e9cdf2d583f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*eAkxzAlqaNRrmDEx"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由<a class="ae ky" href="https://unsplash.com/@billy_huy" rel="noopener ugc nofollow" target="_blank">比利·胡恩</a>在<a class="ae ky" href="https://images.unsplash.com/photo-1496715976403-7e36dc43f17b?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=1950&amp;q=80" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="36b0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Dimensionality_reduction" rel="noopener ugc nofollow" target="_blank">降维</a>是一种减少特征空间的技术，以获得稳定且统计上合理的机器学习模型，避免<a class="ae ky" href="https://en.wikipedia.org/wiki/Curse_of_dimensionality" rel="noopener ugc nofollow" target="_blank">维数灾难</a>。降维主要有两种方法:<a class="ae ky" href="https://en.wikipedia.org/wiki/Feature_selection" rel="noopener ugc nofollow" target="_blank">特征选择</a>和<a class="ae ky" href="https://en.wikipedia.org/wiki/Feature_extraction" rel="noopener ugc nofollow" target="_blank">特征变换</a>。</p><p id="d8ea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Feature_selection" rel="noopener ugc nofollow" target="_blank">特征选择</a>方法试图对重要特征进行子集划分，并移除共线或不太重要的特征。你可以在这里读到更多。</p><p id="7b62" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Feature_extraction" rel="noopener ugc nofollow" target="_blank">特征转换</a>也称为特征提取，试图将高维数据投影到较低的维度。一些特征变换技术有<a class="ae ky" href="https://en.wikipedia.org/wiki/Principal_component_analysis" rel="noopener ugc nofollow" target="_blank"> PCA </a>，<a class="ae ky" href="https://en.wikipedia.org/wiki/Matrix_decomposition" rel="noopener ugc nofollow" target="_blank">矩阵分解</a>，<a class="ae ky" href="https://en.wikipedia.org/wiki/Autoencoder" rel="noopener ugc nofollow" target="_blank">自动编码器</a>，<a class="ae ky" href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding" rel="noopener ugc nofollow" target="_blank"> t-Sne </a>，<a class="ae ky" href="https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction#Uniform_manifold_approximation_and_projection" rel="noopener ugc nofollow" target="_blank"> UMAP </a>等。</p><p id="2042" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过这篇博文，我打算深入研究 PCA 和自动编码器。我们将看到这两种技术的优点和缺点，并通过一个有趣的例子来清楚地理解它。该解决方案的完整源代码可以在<a class="ae ky" href="https://github.com/samread81/PCA-versus-AE" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="e6a7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">你也可以在 Youtube 上找到我关于同一主题的视频。</em></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lw lx l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我在 Youtube 上的同主题视频</p></figure><h1 id="c93b" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">主成分分析</h1><p id="21b5" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li ms lk ll lm mt lo lp lq mu ls lt lu im bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Principal_component_analysis" rel="noopener ugc nofollow" target="_blank">主成分分析</a>是一种<a class="ae ky" href="https://en.wikipedia.org/wiki/Unsupervised_learning" rel="noopener ugc nofollow" target="_blank">无监督技术</a>，将原始数据向高方差方向投影。这些高方差方向<a class="ae ky" href="https://en.wikipedia.org/wiki/Orthogonality" rel="noopener ugc nofollow" target="_blank">彼此正交</a>，导致投影数据中的相关性<a class="ae ky" href="https://en.wikipedia.org/wiki/Correlation_and_dependence" rel="noopener ugc nofollow" target="_blank">非常低或几乎接近 0</a>。这些功能转换是线性的，其方法是:</p><p id="5f0a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">第一步:</em> </strong>计算 n 维组成的<a class="ae ky" href="https://en.wikipedia.org/wiki/Correlation_and_dependence#Correlation_matrices" rel="noopener ugc nofollow" target="_blank">相关矩阵</a>数据。相关矩阵的形状为 n*n。</p><p id="bb28" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">第二步:</em> </strong>计算这个矩阵的<a class="ae ky" href="https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors" rel="noopener ugc nofollow" target="_blank">特征向量和特征值</a>。</p><p id="2142" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">第三步:</em> </strong>取特征值最高的前 k 个特征向量。</p><p id="d205" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">第四步:</em> </strong>将原始数据集投影到这 k 个特征向量中，得到 k 维，其中 k ≤ n。</p><h1 id="1151" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">自动编码器</h1><p id="6faa" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li ms lk ll lm mt lo lp lq mu ls lt lu im bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Autoencoder" rel="noopener ugc nofollow" target="_blank"> Autoencoder </a>是一个无监督的<a class="ae ky" href="https://en.wikipedia.org/wiki/Artificial_neural_network" rel="noopener ugc nofollow" target="_blank">人工神经网络</a>，它将数据压缩到较低的维度，然后将输入重构回来。Autoencoder 通过更多地关注重要特征来消除噪声和冗余，从而在较低的维度中找到数据的表示。它基于编码器-解码器架构，其中编码器将高维数据编码为低维数据，解码器获取低维数据并尝试重建原始高维数据。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mv"><img src="../Images/6f3cdf3f011be0477bc909548030ebb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*wDgeaksTnEdja-xC.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">基本自动编码器的模式:<a class="ae ky" href="https://en.wikipedia.org/wiki/Autoencoder#/media/File:Autoencoder_schema.png" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/f73f19541ab2827f0142535d8ba9b026.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/0*BfGx9Pk2mf78GOfj.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">深度自动编码器的模式:<a class="ae ky" href="https://en.wikipedia.org/wiki/File:Autoencoder_structure.png" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></figure><p id="5caf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在上图中，X 是输入数据，z 是输入 X 的低维表示，X '是重构的输入数据。根据对<a class="ae ky" href="https://en.wikipedia.org/wiki/Activation_function" rel="noopener ugc nofollow" target="_blank">激活功能</a>的选择，较高维度到较低维度的映射可以是线性的或非线性的。</p><h1 id="e1a7" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">比较:PCA 与自动编码器</h1><ol class=""><li id="92a5" class="mx my it lb b lc mq lf mr li mz lm na lq nb lu nc nd ne nf bi translated">PCA 是数据的线性变换，而 AE 可以是线性的或非线性的，这取决于激活函数的选择。</li><li id="1ec7" class="mx my it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">PCA 非常快，因为存在可以快速计算它的算法，而 AE 通过梯度下降训练，并且相对较慢。</li><li id="d36a" class="mx my it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">PCA 将数据投影到彼此正交的维度中，导致投影数据中的相关性非常低或接近零。PCA 得到正交子空间，因为特征向量(数据投影到其上)来自应用于协方差矩阵(对称半正定)的特征分解，并且在这种情况下，特征分解产生正交特征向量。AE 转换数据不能保证这一点，因为它的训练方式仅仅是为了最小化重建损失。</li><li id="4b70" class="mx my it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">PCA 是输入空间到最大变化方向的简单线性变换，而 AE 是更复杂的技术，可以模拟相对复杂的关系和非线性。</li><li id="f906" class="mx my it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">一个经验法则可能是数据的大小。对于小数据集使用 PCA，对于相对较大的数据集使用 AE。</li><li id="198b" class="mx my it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">PCA 超参数是“k ”,即投影数据的正交维数，而对于 AE，它是神经网络的架构。</li><li id="be2b" class="mx my it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">具有单层和线性激活的 AE 具有与 PCA 相似的性能。称为深度自动编码器的具有多层和非激活功能的 AE 易于过拟合，并且可以通过规范化和仔细设计来控制。请参考下面两篇博客来了解更多。</li></ol><div class="nl nm gp gr nn no"><a href="https://blog.keras.io/building-autoencoders-in-keras.html" rel="noopener  ugc nofollow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd iu gy z fp nt fr fs nu fu fw is bi translated">在 Keras 中构建自动编码器</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">在本教程中，我们将回答一些关于自动编码器的常见问题，我们将涵盖代码的例子…</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">blog.keras.io</p></div></div><div class="nx l"><div class="ny l nz oa ob nx oc ks no"/></div></div></a></div><div class="nl nm gp gr nn no"><a href="https://iq.opengenus.org/types-of-autoencoder/" rel="noopener  ugc nofollow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd iu gy z fp nt fr fs nu fu fw is bi translated">不同类型的自动编码器</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">阅读时间:30 分钟自动编码器是一种人工神经网络，用于学习有效的数据编码</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">iq.opengenus.org</p></div></div><div class="nx l"><div class="od l nz oa ob nx oc ks no"/></div></div></a></div><h1 id="d3d7" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">图像数据示例:了解 PCA 和自动编码器</h1><p id="1b1e" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li ms lk ll lm mt lo lp lq mu ls lt lu im bi translated">让我们以下图为例，用这两种方法进行降维。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/4647890def1aaa50d4ec2beef1099d46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ouE2f3FMRiAFBM9YGKqdEQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://iq.opengenus.org/types-of-autoencoder/" rel="noopener ugc nofollow" target="_blank">图像来源</a></p></figure><p id="e3dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这幅图像的尺寸是 360 * 460。从另一个角度来看，它是一个包含 360 个数据点和 460 个特征/维度的数据集。</p><p id="7de9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将尝试将维数从 460 减少到 10%，即 46 维，首先使用 PCA，然后使用 AE。再来看看重构和其他属性的区别。</p><h2 id="5201" class="of lz it bd ma og oh dn me oi oj dp mi li ok ol mk lm om on mm lq oo op mo oq bi translated">使用主成分分析进行降维</h2><pre class="kj kk kl km gt or os ot ou aw ov bi"><span id="6515" class="of lz it os b gy ow ox l oy oz">pct_reduction = 0.10<br/>reduced_pixel  = int( pct_reduction* original_dimensions[1])</span><span id="6f6a" class="of lz it os b gy pa ox l oy oz">#Applying PCA<br/>pca = PCA(n_components=reduced_pixel)<br/>pca.fit(image_matrix)</span><span id="0574" class="of lz it os b gy pa ox l oy oz">#Transforming the input matrix<br/>X_transformed = pca.transform(image_matrix)<br/>print("Original Input dimesnions {}".format(original_dimensions))<br/>print("New Reduced dimensions {}".format(X_transformed.shape))</span></pre><p id="9f99" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出</p><pre class="kj kk kl km gt or os ot ou aw ov bi"><span id="ed73" class="of lz it os b gy ow ox l oy oz">Original Input dimesnions (360, 460)<br/>New Reduced dimensions (360, 46)</span></pre><p id="e3a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们检查来自 PCA 的新变换特征的相关性。</p><pre class="kj kk kl km gt or os ot ou aw ov bi"><span id="71fd" class="of lz it os b gy ow ox l oy oz">df_pca = pd.DataFrame(data = X_transformed,columns=list(range(X_transformed.shape[1])))</span><span id="5867" class="of lz it os b gy pa ox l oy oz">figure = plt.figure(figsize=(10,6))<br/>corrMatrix = df_pca.corr()<br/>sns.heatmap(corrMatrix, annot=False)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/31bbcf448da984d13425f870ef710373.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IttKjViWKUcq5SCU0ypqLQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">变换特征的相关矩阵:PCA</p></figure><p id="cba5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">相关矩阵显示新的变换特征彼此不相关，相关度为 0。原因是在 PCA 中将数据投影到正交维度中。</p><p id="74de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们将尝试仅通过来自我们可用的缩减特征空间的信息来重建原始数据。</p><pre class="kj kk kl km gt or os ot ou aw ov bi"><span id="84f3" class="of lz it os b gy ow ox l oy oz">reconstructed_matrix = pca.inverse_transform(X_transformed)<br/>reconstructed_image_pca = Image.fromarray(np.uint8(reconstructed_matrix))<br/>plt.figure(figsize=(8,12))<br/>plt.imshow(reconstructed_image_pca,cmap = plt.cm.gray)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/d5361ecba672b990fb195f7bcecb94a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nDQI5GYmi43yMFSbrQdPNQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">重建图像:主成分分析</p></figure><p id="5014" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">计算重建图像的<a class="ae ky" href="https://en.wikipedia.org/wiki/Root-mean-square_deviation" rel="noopener ugc nofollow" target="_blank"> RMSE </a></p><pre class="kj kk kl km gt or os ot ou aw ov bi"><span id="022a" class="of lz it os b gy ow ox l oy oz">def my_rmse(np_arr1,np_arr2):<br/>    dim = np_arr1.shape<br/>    tot_loss = 0<br/>    for i in range(dim[0]):<br/>        for j in range(dim[1]):<br/>            tot_loss += math.pow((np_arr1[i,j] - np_arr2[i,j]),2)<br/>    return round(math.sqrt(tot_loss/(dim[0]* dim[1]*1.0)),2)</span><span id="26fe" class="of lz it os b gy pa ox l oy oz">error_pca = my_rmse(image_matrix,reconstructed_matrix)</span></pre><p id="593c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">RMSE 是 11.84(越低越好)。</p><blockquote class="pd pe pf"><p id="9752" class="kz la lv lb b lc ld ju le lf lg jx lh pg lj lk ll ph ln lo lp pi lr ls lt lu im bi translated">如果原始图像和重建图像之间没有差异，RMSE 将为 0。如果使用大约 120 个来自 PCA 的维度，则 RMSE 接近于 0。</p></blockquote><h2 id="9e5f" class="of lz it bd ma og oh dn me oi oj dp mi li ok ol mk lm om on mm lq oo op mo oq bi translated">使用具有线性激活的单层自动编码器进行降维</h2><pre class="kj kk kl km gt or os ot ou aw ov bi"><span id="7df4" class="of lz it os b gy ow ox l oy oz"># Standarise the Data<br/>X_org = image_matrix.copy()<br/>sc = StandardScaler()<br/>X = sc.fit_transform(X_org)</span><span id="2b24" class="of lz it os b gy pa ox l oy oz"># this is the size of our encoded representations<br/>encoding_dim = reduced_pixel </span><span id="343b" class="of lz it os b gy pa ox l oy oz"># this is our input placeholder<br/>input_img = Input(shape=(img.width,))</span><span id="fc2b" class="of lz it os b gy pa ox l oy oz"># "encoded" is the encoded representation of the input<br/>encoded = Dense(encoding_dim, activation='linear')(input_img)</span><span id="d054" class="of lz it os b gy pa ox l oy oz"># "decoded" is the lossy reconstruction of the input<br/>decoded = Dense(img.width, activation=None)(encoded)</span><span id="9523" class="of lz it os b gy pa ox l oy oz"># this model maps an input to its reconstruction<br/>autoencoder = Model(input_img, decoded)</span><span id="256a" class="of lz it os b gy pa ox l oy oz">#Encoder<br/>encoder = Model(input_img, encoded)</span><span id="e06b" class="of lz it os b gy pa ox l oy oz"># create a placeholder for an encoded (32-dimensional) input<br/>encoded_input = Input(shape=(encoding_dim,))</span><span id="69bb" class="of lz it os b gy pa ox l oy oz"># retrieve the last layer of the autoencoder model<br/>decoder_layer = autoencoder.layers[-1]</span><span id="24fc" class="of lz it os b gy pa ox l oy oz"># create the decoder model<br/>decoder = Model(encoded_input, decoder_layer(encoded_input))</span><span id="8d21" class="of lz it os b gy pa ox l oy oz">autoencoder.compile(optimizer='adadelta', loss='mean_squared_error')</span><span id="e873" class="of lz it os b gy pa ox l oy oz">autoencoder.fit(X, X,<br/>                epochs=500,<br/>                batch_size=16,<br/>                shuffle=True)</span><span id="fd43" class="of lz it os b gy pa ox l oy oz">encoded_imgs = encoder.predict(X)<br/>decoded_imgs = decoder.predict(encoded_imgs)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/e6b5f7ff907541d94c8917da8e597ecf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RTXube8V4SScxNku1K2Yxg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模型架构/摘要</p></figure><p id="84fd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们检查从 AE 出来的新变换特征的相关性。</p><pre class="kj kk kl km gt or os ot ou aw ov bi"><span id="b7c2" class="of lz it os b gy ow ox l oy oz">df_ae = pd.DataFrame(data = encoded_imgs,columns=list(range(encoded_imgs.shape[1])))<br/>figure = plt.figure(figsize=(10,6))<br/>corrMatrix = df_ae.corr()<br/>sns.heatmap(corrMatrix, annot=False)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pk"><img src="../Images/16fa76b09a036f0ba6d6362ed0fd22fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z2-AvV_mkX5n3N_bPEUzxg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">变换特征的相关矩阵:AE</p></figure><p id="1e83" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">相关矩阵显示新的变换特征在某种程度上是相关的。皮尔逊相关因子偏离 0 很多。AE 训练的原因仅仅是为了最小化重建损失。</p><p id="ad40" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们将尝试仅通过我们可用的缩减的特征空间来重建回原始数据。</p><pre class="kj kk kl km gt or os ot ou aw ov bi"><span id="2a01" class="of lz it os b gy ow ox l oy oz">X_decoded_ae = sc.inverse_transform(decoded_imgs)</span><span id="4c23" class="of lz it os b gy pa ox l oy oz">reconstructed_image_ae = Image.fromarray(np.uint8(X_decoded_ae))<br/>plt.figure(figsize=(8,12))<br/>plt.imshow(reconstructed_image_ae,cmap = plt.cm.gray)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/34d3211b0bc5e950f090309f7eae6f3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M70AmfVHfapmFzojGYK7yg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">重建图像:声发射</p></figure><p id="2036" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">计算重建图像的<a class="ae ky" href="https://en.wikipedia.org/wiki/Root-mean-square_deviation" rel="noopener ugc nofollow" target="_blank"> RMSE </a>。</p><pre class="kj kk kl km gt or os ot ou aw ov bi"><span id="ad38" class="of lz it os b gy ow ox l oy oz">error_ae = my_rmse(image_matrix,X_decoded_ae)</span></pre><blockquote class="pd pe pf"><p id="61be" class="kz la lv lb b lc ld ju le lf lg jx lh pg lj lk ll ph ln lo lp pi lr ls lt lu im bi translated">RMSE 是 12.15。接近 PCA 的 RMSE 11.84。具有单层和线性激活的自动编码器的性能类似于 PCA。</p></blockquote><h2 id="e730" class="of lz it bd ma og oh dn me oi oj dp mi li ok ol mk lm om on mm lq oo op mo oq bi translated">使用具有非线性激活的三层自动编码器进行降维</h2><pre class="kj kk kl km gt or os ot ou aw ov bi"><span id="80c6" class="of lz it os b gy ow ox l oy oz">input_img = Input(shape=(img.width,))<br/>encoded1 = Dense(128, activation='relu')(input_img)<br/>encoded2 = Dense(reduced_pixel, activation='relu')(encoded1)<br/>decoded1 = Dense(128, activation='relu')(encoded2)<br/>decoded2 = Dense(img.width, activation=None)(decoded1)</span><span id="66e3" class="of lz it os b gy pa ox l oy oz">autoencoder = Model(input_img, decoded2)<br/>autoencoder.compile(optimizer='adadelta', loss='mean_squared_error')</span><span id="4331" class="of lz it os b gy pa ox l oy oz">autoencoder.fit(X,X,<br/>                epochs=500,<br/>                batch_size=16,<br/>                shuffle=True)<br/># Encoder<br/>encoder = Model(input_img, encoded2)<br/># Decoder<br/>decoder = Model(input_img, decoded2)</span><span id="c80c" class="of lz it os b gy pa ox l oy oz">encoded_imgs = encoder.predict(X)<br/>decoded_imgs = decoder.predict(X)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pl"><img src="../Images/c51c10a217e3b88c4f48a8043e104133.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tvEQpy8VJQbr3L73F6NpoQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模型架构/摘要</p></figure><p id="fb1c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们将尝试仅通过我们可用的缩减的特征空间来重建回原始数据。</p><pre class="kj kk kl km gt or os ot ou aw ov bi"><span id="707c" class="of lz it os b gy ow ox l oy oz">X_decoded_deep_ae = sc.inverse_transform(decoded_imgs)</span><span id="faec" class="of lz it os b gy pa ox l oy oz">reconstructed_image_deep_ae = Image.fromarray(np.uint8(X_decoded_deep_ae))<br/>plt.figure(figsize=(8,12))<br/>plt.imshow(reconstructed_image_deep_ae,cmap = plt.cm.gray)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pm"><img src="../Images/a5662d10336c1c1f04b1692b0e3af922.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SlmBXcoiWMz68Q9CJ_LRLw.png"/></div></div></figure><p id="d3c5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">计算重建图像的<a class="ae ky" href="https://en.wikipedia.org/wiki/Root-mean-square_deviation" rel="noopener ugc nofollow" target="_blank"> RMSE </a>。</p><pre class="kj kk kl km gt or os ot ou aw ov bi"><span id="5247" class="of lz it os b gy ow ox l oy oz">error_dae = my_rmse(image_matrix,X_decoded_deep_ae)</span></pre><p id="70af" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">RMSE 是 8.57。相对于 PCA 的增益是 28 %,同时减少了相同数量的维数。</p><blockquote class="pn"><p id="daff" class="po pp it bd pq pr ps pt pu pv pw lu dk translated">具有非线性激活的额外层的 Autoencoder 能够更好地捕捉图像中的非线性。与 PCA 相比，它能够更好地捕捉复杂的模式以及像素值的突然变化。尽管它伴随着相对较高的培训时间和资源的成本。</p></blockquote><h1 id="91a7" class="ly lz it bd ma mb mc md me mf mg mh mi jz px ka mk kc py kd mm kf pz kg mo mp bi translated">结论</h1><p id="a4f2" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li ms lk ll lm mt lo lp lq mu ls lt lu im bi translated">通过这篇博文，我们深入研究了 PCA 和自动编码器。我们也看到了这两种技术的优缺点。这些概念在图像数据集上进行了尝试，其中具有额外非线性激活层的自动编码器优于 PCA，尽管代价是更高的训练时间和资源。该解决方案的完整源代码可以在<a class="ae ky" href="https://github.com/samread81/PCA-versus-AE" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><blockquote class="pn"><p id="1d78" class="po pp it bd pq pr ps pt pu pv pw lu dk translated">如果你有任何疑问，请联系我。我很想知道你是否面临过高维度的问题，以及你尝试了哪些方法来克服它。</p></blockquote><p id="7675" class="pw-post-body-paragraph kz la it lb b lc qa ju le lf qb jx lh li qc lk ll lm qd lo lp lq qe ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">我的 Youtube 频道更多内容:</em> </strong></p><div class="nl nm gp gr nn no"><a href="https://www.youtube.com/channel/UCg0PxC9ThQrbD9nM_FU1vWA" rel="noopener  ugc nofollow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd iu gy z fp nt fr fs nu fu fw is bi translated">阿布舍克·蒙戈利</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">嗨，伙计们，欢迎来到频道。该频道旨在涵盖各种主题，从机器学习，数据科学…</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">www.youtube.com</p></div></div><div class="nx l"><div class="qf l nz oa ob nx oc ks no"/></div></div></a></div><blockquote class="pd pe pf"><p id="fc22" class="kz la lv lb b lc ld ju le lf lg jx lh pg lj lk ll ph ln lo lp pi lr ls lt lu im bi translated"><strong class="lb iu"> <em class="it">关于作者-: </em> </strong></p><p id="c80d" class="kz la lv lb b lc ld ju le lf lg jx lh pg lj lk ll ph ln lo lp pi lr ls lt lu im bi translated">Abhishek Mungoli 是一位经验丰富的数据科学家，拥有 ML 领域的经验和计算机科学背景，跨越多个领域并具有解决问题的思维方式。擅长各种机器学习和零售业特有的优化问题。热衷于大规模实现机器学习模型，并通过博客、讲座、聚会和论文等方式分享知识。</p><p id="6624" class="kz la lv lb b lc ld ju le lf lg jx lh pg lj lk ll ph ln lo lp pi lr ls lt lu im bi translated">我的动机总是把最困难的事情简化成最简单的版本。我喜欢解决问题、数据科学、产品开发和扩展解决方案。我喜欢在闲暇时间探索新的地方和健身。关注我的<a class="ae ky" href="https://medium.com/@mungoliabhishek81" rel="noopener"> <strong class="lb iu">中</strong> </a>、<strong class="lb iu"/><a class="ae ky" href="https://www.linkedin.com/in/abhishek-mungoli-39048355/" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">Linkedin</strong></a><strong class="lb iu"/>或<strong class="lb iu"/><a class="ae ky" href="https://www.instagram.com/simplyspartanx/" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">insta gram</strong></a><strong class="lb iu"/>并查看我的<a class="ae ky" href="https://medium.com/@mungoliabhishek81" rel="noopener">以前的帖子</a>。我欢迎反馈和建设性的批评。我的一些博客-</p></blockquote><ul class=""><li id="2922" class="mx my it lb b lc ld lf lg li qg lm qh lq qi lu qj nd ne nf bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/experience-the-power-of-the-genetic-algorithm-4030adf0383f">体验遗传算法的威力</a></li><li id="1f3c" class="mx my it lb b lc ng lf nh li ni lm nj lq nk lu qj nd ne nf bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/5-mistakes-every-data-scientist-should-avoid-bcc8142d7693">每个数据科学家都应该避免的 5 个错误</a></li><li id="97e8" class="mx my it lb b lc ng lf nh li ni lm nj lq nk lu qj nd ne nf bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/decomposing-a-time-series-in-a-simple-and-intuitive-way-19d3213c420b?source=---------7------------------">以简单&amp;直观的方式分解时间序列</a></li><li id="d8ba" class="mx my it lb b lc ng lf nh li ni lm nj lq nk lu qj nd ne nf bi translated"><a class="ae ky" href="https://medium.com/walmartlabs/how-gpu-computing-literally-saved-me-at-work-fc1dc70f48b6" rel="noopener">GPU 计算如何在工作中拯救了我？</a></li><li id="ce93" class="mx my it lb b lc ng lf nh li ni lm nj lq nk lu qj nd ne nf bi translated">信息论&amp; KL 分歧<a class="ae ky" rel="noopener" target="_blank" href="/part-i-a-new-tool-to-your-toolkit-kl-divergence-5b887b5b420e">第一部分</a>和<a class="ae ky" rel="noopener" target="_blank" href="/part-2-a-new-tool-to-your-toolkit-kl-divergence-736c134baa3d">第二部分</a></li><li id="0628" class="mx my it lb b lc ng lf nh li ni lm nj lq nk lu qj nd ne nf bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/process-wikipedia-using-apache-spark-to-create-spicy-hot-datasets-1a59720e6e25">使用 Apache Spark 处理维基百科，创建热点数据集</a></li><li id="d601" class="mx my it lb b lc ng lf nh li ni lm nj lq nk lu qj nd ne nf bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/a-semi-supervised-embedding-based-fuzzy-clustering-b2023c0fde7c">一种基于半监督嵌入的模糊聚类</a></li><li id="d014" class="mx my it lb b lc ng lf nh li ni lm nj lq nk lu qj nd ne nf bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/compare-which-machine-learning-model-performs-better-4912b2ed597d">比较哪个机器学习模型表现更好</a></li><li id="c51b" class="mx my it lb b lc ng lf nh li ni lm nj lq nk lu qj nd ne nf bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/analyzing-fitbit-data-to-demystify-bodily-pattern-changes-amid-pandemic-lockdown-5b0188fec0f0">分析 Fitbit 数据，揭开疫情封锁期间身体模式变化的神秘面纱</a></li><li id="dadc" class="mx my it lb b lc ng lf nh li ni lm nj lq nk lu qj nd ne nf bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/myths-and-reality-around-correlation-9b359456d8e1">神话与现实围绕关联</a></li><li id="070c" class="mx my it lb b lc ng lf nh li ni lm nj lq nk lu qj nd ne nf bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/a-guide-to-becoming-business-oriented-data-scientist-51da5c829ffa">成为面向业务的数据科学家指南</a></li></ul></div></div>    
</body>
</html>