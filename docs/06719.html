<html>
<head>
<title>EfficientNet should be the goto pre-trained model or…</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">EfficientNet应该是goto预训练模型或…</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/efficientnet-should-be-the-goto-pre-trained-model-or-38f719cbfe60?source=collection_archive---------36-----------------------#2020-05-26">https://towardsdatascience.com/efficientnet-should-be-the-goto-pre-trained-model-or-38f719cbfe60?source=collection_archive---------36-----------------------#2020-05-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a423" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">比较不同预训练模型的时间和准确性，并最终创建一个集成来提高结果。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/2da3e663e8f47a04426805a3f93b5a66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3gEMVXobSJ4kbW34"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">乔恩·泰森在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="f18c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一周前我还没有听说过这个术语，现在我认为EfficientNet是最好的预训练模型。在他们的<a class="ae ky" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank">论文</a>中，他们已经展示了它的艺术状态，所以让我们来测试一下，当你为一个模型选择一个主干时，它是否应该是你的选择。我将把它的性能与广泛使用的MobileNet、Inception和Xception进行比较，比较的基础是每个时期训练和执行推理所用的时间，当然还有准确性。我决定用一场<a class="ae ky" href="https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition" rel="noopener ugc nofollow" target="_blank">狗对猫</a>的Kaggle比赛来做我的裁判，让一切都脱离我的掌控。在我们开始模型和比较之前，如果你想了解更多关于什么是EfficientNet和它的所有八个模型的架构，你可以先阅读我以前的文章。</p><div class="lv lw gp gr lx ly"><a rel="noopener follow" target="_blank" href="/complete-architectural-details-of-all-efficientnet-models-5fd5b736142"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">所有高效网络模型的完整架构细节</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">让我们深入了解所有不同高效网络模型的体系结构细节，并找出它们的不同之处…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm ks ly"/></div></div></a></div><h1 id="7102" class="mn mo it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated">目录</h1><ol class=""><li id="3757" class="nf ng it lb b lc nh lf ni li nj lm nk lq nl lu nm nn no np bi translated">要求</li><li id="390a" class="nf ng it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated">加载数据集</li><li id="2f81" class="nf ng it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated">模型</li><li id="441f" class="nf ng it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated">结果</li></ol><ul class=""><li id="6e93" class="nf ng it lb b lc ld lf lg li nv lm nw lq nx lu ny nn no np bi translated">训练时间</li><li id="fc44" class="nf ng it lb b lc nq lf nr li ns lm nt lq nu lu ny nn no np bi translated">推理时间</li><li id="93f3" class="nf ng it lb b lc nq lf nr li ns lm nt lq nu lu ny nn no np bi translated">测试集上的性能</li></ul><p id="be1d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">5.全体</p></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><h1 id="6a57" class="mn mo it bd mp mq og ms mt mu oh mw mx jz oi ka mz kc oj kd nb kf ok kg nd ne bi translated">要求</h1><p id="fef8" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li ol lk ll lm om lo lp lq on ls lt lu im bi translated">您将需要TensorFlow-Nightly，因为EfficientNet的稳定版本和Kaggle目前不支持下载数据集和提交结果。我将使用Google Colab，所以如果你想编码，打开笔记本，不要忘记连接到GPU。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="ccb4" class="ot mo it op b gy ou ov l ow ox">!pip install tf-nightly-gpu<br/>!pip install -q kaggle</span></pre><p id="2748" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您将需要生成一个Kaggle的API密钥。程序如<a class="ae ky" href="https://adityashrm21.github.io/Setting-Up-Kaggle/" rel="noopener ugc nofollow" target="_blank">所示，此处为</a>。执行下面给出的代码来完成设置。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="7013" class="ot mo it op b gy ou ov l ow ox">! mkdir ~/.kaggle<br/>! cp kaggle.json ~/.kaggle/<br/>! chmod 600 ~/.kaggle/kaggle.json</span></pre><h1 id="86ce" class="mn mo it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated">加载数据集</h1><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="d006" class="ot mo it op b gy ou ov l ow ox">! kaggle competitions download -c 'dogs-vs-cats-redux-kernels-edition'<br/>! mkdir train<br/>! unzip train.zip -d train<br/>! mkdir test<br/>! unzip test.zip -d testimport ostrain_dir = os.path.join('/content/train', 'train')<br/>test_dir = os.path.join('/content/test', 'test')</span></pre><p id="cd50" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我使用了一个定制的数据生成器来批量加载图像，并定义了几个图像增强函数。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="dd7d" class="ot mo it op b gy ou ov l ow ox">def data_gen(img_names, bat ch_size):<br/>    c = 0<br/>    n = os.listdir(img_names) #List of training images<br/>    random.shuffle(n)while (True):<br/>        img = np.zeros((batch_size, 224, 224, 3)).astype('float')<br/>        labels = []for i in range(c, c+batch_size):<br/>            train_img = cv2.imread(os.path.join(train_dir, n[i]))<br/>            train_img =  cv2.resize(train_img, (224, 224))<br/>            train_img = train_img/255.if random.random() &lt; 0.25:<br/>                train_img = cv2.flip(train_img, 1)<br/>            rno = random.random()<br/>            if rno &lt; 0.1:<br/>                train_img = train_img[:196, :196, :]<br/>            elif rno &lt; 0.2:<br/>                train_img = train_img[28:, 28:, :]<br/>            elif rno &lt; 0.3:<br/>                train_img = train_img[28:, :196, :]<br/>            elif rno &lt; 0.4:<br/>                train_img = train_img[:196, 28:, :]<br/>            elif rno &lt; 0.5:<br/>                train_img = train_img[28:196, 28:196, :]<br/>            if rno &lt; 0.5:<br/>                train_img = cv2.resize(train_img, (224, 224), cv2.INTER_CUBIC)img[i-c] = train_img<br/>            if len(re.findall('dog', n[i])) == 1:<br/>                labels.append(1)<br/>            else:<br/>                labels.append(0)labels = np.array(labels)<br/>        c+=batch_size<br/>        if(c+batch_size&gt;=len(n)):<br/>            c=0<br/>            random.shuffle(n)<br/>        yield img, labelstrain_gen = data_gen(train_dir, batch_size)</span></pre><p id="75bd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您想了解如何创建更多的图像增强功能，请参考本文。</p><div class="lv lw gp gr lx ly"><a rel="noopener follow" target="_blank" href="/complete-image-augmentation-in-opencv-31a6b02694f5"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">OpenCV中的完整图像增强</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">这是一篇详尽的文章，通过使用OpenCV的自定义数据生成器，涵盖了所有的图像增强功能。</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mh l"><div class="oy l mj mk ml mh mm ks ly"/></div></div></a></div><h1 id="cec1" class="mn mo it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated">模型</h1><p id="52a0" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li ol lk ll lm om lo lp lq on ls lt lu im bi translated">我们将创建一个非常基本的模型，即加载预训练的网络，将其层设置为可训练，添加一个全局平均池层和一个密集层。所有的层都被设置为可训练的，这样即使有些层在这里被冻结了，也要花最长的时间来训练。他们将接受10个纪元的训练。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="4d9d" class="ot mo it op b gy ou ov l ow ox">def create_model(base_model):<br/>    base_model.trainable = True<br/>    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)<br/>    prediction_layer = tf.keras.layers.Dense(1, activation='sigmoid')(global_average_layer)<br/>    model = tf.keras.models.Model(inputs=base_model.input, outputs=prediction_layer)<br/>    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=["accuracy", "mse"])<br/>    return modeldef fit_model(model):<br/>    model.fit(train_gen, batch_size=batch_size, steps_per_epoch=25000 // batch_size, epochs=epochs)IMG_SHAPE = (224, 224, 3)<br/>model_mob = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights="imagenet")<br/>model_inc = tf.keras.applications.InceptionV3(input_shape=IMG_SHAPE, include_top=False, weights="imagenet")<br/>model_xcep = tf.keras.applications.Xception(input_shape=IMG_SHAPE, include_top=False, weights="imagenet")<br/>model_B0 = tf.keras.applications.EfficientNetB0(input_shape=IMG_SHAPE, include_top=False, weights="imagenet")<br/>model_B1 = tf.keras.applications.EfficientNetB1(input_shape=IMG_SHAPE, include_top=False, weights="imagenet")<br/>model_B2 = tf.keras.applications.EfficientNetB2(input_shape=IMG_SHAPE, include_top=False, weights="imagenet")<br/>model_B3 = tf.keras.applications.EfficientNetB3(input_shape=IMG_SHAPE, include_top=False, weights="imagenet")<br/>model_B4 = tf.keras.applications.EfficientNetB4(input_shape=IMG_SHAPE, include_top=False, weights="imagenet")<br/>model_B5 = tf.keras.applications.EfficientNetB5(input_shape=IMG_SHAPE, include_top=False, weights="imagenet")fit_model(model_mob)<br/>fit_model(model_inc)<br/>fit_model(model_xcep)<br/>fit_model(model_B0)<br/>fit_model(model_B1)<br/>fit_model(model_B2)<br/>fit_model(model_B3)<br/>fit_model(model_B4)<br/>fit_model(model_B5)</span></pre><h1 id="ee27" class="mn mo it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated">结果</h1><p id="02f8" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li ol lk ll lm om lo lp lq on ls lt lu im bi translated">啊终于到了真相大白的时刻了。你一直在等待的部分。</p><h1 id="b114" class="mn mo it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated">训练时间</h1><p id="516a" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li ol lk ll lm om lo lp lq on ls lt lu im bi translated">记录下训练时每个时期所用的时间，如下所示。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="ad76" class="ot mo it op b gy ou ov l ow ox">+-----------------+-------------------------+<br/>|      Model      | Time per epoch (in sec) |<br/>+-----------------+-------------------------+<br/>| MobileNetV2     |                     250 |<br/>| InceptionV3     |                     400 |<br/>| Xception        |                     900 |<br/>| EfficientNet-B0 |                     179 |<br/>| EfficientNet-B1 |                     250 |<br/>| EfficientNet-B2 |                     257 |<br/>| EfficientNet-B3 |                     315 |<br/>| EfficientNet-B4 |                     388 |<br/>| EfficientNet-B5 |                     500 |<br/>+-----------------+-------------------------+</span></pre><p id="9e8b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">(最后两个EfficientNets在Colab上抛出内存错误，我无法训练它们。如果你想创建这样的表格，你可以使用<a class="ae ky" href="https://ozh.github.io/ascii-tables/" rel="noopener ugc nofollow" target="_blank">这个</a>。)EfficientNet-B0轻松击败所有人，Xception是最慢的。</p><h1 id="d9a8" class="mn mo it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated">推理时间</h1><p id="27f3" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li ol lk ll lm om lo lp lq on ls lt lu im bi translated">为了避免差异，我加载了一个测试图像，并测量了预测它的总时间100次，取其平均值。结果如下。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="3f40" class="ot mo it op b gy ou ov l ow ox">+-----------------+-------------------------+<br/>|      Model      | Time per epoch (in sec) |<br/>+-----------------+-------------------------+<br/>| MobileNetV2     |                   0.034 |<br/>| InceptionV3     |                   0.049 |<br/>| Xception        |                   0.038 |<br/>| EfficientNet-B0 |                   0.041 |<br/>| EfficientNet-B1 |                   0.048 |<br/>| EfficientNet-B2 |                   0.049 |<br/>| EfficientNet-B3 |                   0.054 |<br/>| EfficientNet-B4 |                   0.061 |<br/>| EfficientNet-B5 |                   0.070 |<br/>+-----------------+-------------------------+</span></pre><p id="30b3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，这是个惊喜！我曾觉得训练时间会指示推理时间，但一点也不。MobileNet这次拿了蛋糕，紧随其后的是花了最多时间训练的Xception。效率网模型中的时间随着代的增加而增加，这是随着参数数量的增加而预期的。</p><h1 id="2092" class="mn mo it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated">准确(性)</h1><p id="8aec" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li ol lk ll lm om lo lp lq on ls lt lu im bi translated">我选择不包含验证集，这样在Kaggle上提交CSV文件后会有惊喜。使用的度量标准是<a class="ae ky" href="https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/overview/evaluation" rel="noopener ugc nofollow" target="_blank">测井损失</a>。它的价值越低越好。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/d68f3a29c0e098027748199a548b3761.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/0*6FoQdce0FfVemV8X.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="http://wiki.fast.ai/index.php/Log_Loss" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="84a0" class="ot mo it op b gy ou ov l ow ox">+-----------------+----------+<br/>|      Model      | Log loss |<br/>+-----------------+----------+<br/>| MobileNetV2     |    0.238 |<br/>| InceptionV3     |    0.168 |<br/>| Xception        |    0.111 |<br/>| EfficientNet-B0 |    0.205 |<br/>| EfficientNet-B1 |    0.160 |<br/>| EfficientNet-B2 |    0.122 |<br/>| EfficientNet-B3 |    0.137 |<br/>| EfficientNet-B4 |    0.126 |<br/>| EfficientNet-B5 |    0.125 |<br/>+-----------------+----------+</span></pre><p id="579c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例外表现最好！！紧随其后的是其他EfficientNet模型，除了EfficientNet-B0，它真正的比较对象是MobileNetV2，它名列前茅。EfficientNet-B0可能是移动模型的有趣选择🤔。这些结果表明，深度学习仍然像彩票一样，任何人都可以表现得更好(在可比模型中表现良好)。</p><h1 id="4c5b" class="mn mo it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated">全体</h1><p id="4edf" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li ol lk ll lm om lo lp lq on ls lt lu im bi translated">当我知道EfficientNet有8个模型时，我想为它创建一个整体模型，看看效果如何。我们将制作两个集合模型，一个包含MobileNet、Inception和Xception，另一个包含6个EfficientNet模型。我们将创建的集合将使用ANN来组合这些模型。我已经写了一篇关于如何做到这一点的文章，所以如果你想了解它是如何做到的，请参考。</p><div class="lv lw gp gr lx ly"><a rel="noopener follow" target="_blank" href="/destroy-image-classification-by-ensemble-of-pre-trained-models-f287513b7687"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">基于预训练模型集成的破坏性图像分类</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">通过制作预训练网络的集成堆叠集成模型，如…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mh l"><div class="pa l mj mk ml mh mm ks ly"/></div></div></a></div><p id="c7ea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在为集合模型创建数据生成器而不是产生四维(批量大小、图像高度、图像宽度、通道)的NumPy数组时，我们在列表中传递它的次数作为模型的数量。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="4962" class="ot mo it op b gy ou ov l ow ox">img = np.zeros((batch_size, 224, 224, 3)).astype('float')<br/># looping and adding images to img<br/>img = [img]*no_of_models_in_ensemble</span></pre><p id="7151" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在加载所有的模型放入集合中，冻结它们的权重，改变层的名称，这样没有两层有相同的名称，添加一些密集的层来创建一个人工神经网络，这就完成了。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="2a06" class="ot mo it op b gy ou ov l ow ox">def ensemble_model(models):<br/>    for i, model in enumerate(models):<br/>        for layer in model.layers:<br/>            layer.trainable = False<br/>            layer._name = 'ensemble_' + str(i+1) + '_' + layer.name<br/>    ensemble_visible = [model.input for model in models]<br/>    ensemble_outputs = [model.output for model in models]<br/>    merge = tf.keras.layers.concatenate(ensemble_outputs)<br/>    merge = tf.keras.layers.Dense(32, activation='relu')(merge)<br/>    merge = tf.keras.layers.Dense(8, activation='relu')(merge)<br/>    output = tf.keras.layers.Dense(1, activation='sigmoid')(merge)<br/>    model = tf.keras.models.Model(inputs=ensemble_visible, outputs=output)<br/>    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=["accuracy"])<br/>    return model</span></pre><p id="773c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">两个集合模型都被训练10个时期，并且它们的对数损失值是:</p><ul class=""><li id="4190" class="nf ng it lb b lc ld lf lg li nv lm nw lq nx lu ny nn no np bi translated">MobileNet、Inception和异常集合:0.104</li><li id="c72b" class="nf ng it lb b lc nq lf nr li ns lm nt lq nu lu ny nn no np bi translated">有效净系综:0.078</li></ul><p id="27ae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第一个集合模型确实有所改进，但没有那么多。然而，有效网络集合有了很大的提高。</p></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><p id="a140" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">比较所有这些结果，我们可以看到，我们不能抹杀其他模型相比，有效的网络和提高分数的竞争集成是一条路要走。</p></div></div>    
</body>
</html>