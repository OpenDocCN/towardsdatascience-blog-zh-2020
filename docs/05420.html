<html>
<head>
<title>Convolutional Neural Networks(CNN’s) — A practical perspective</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络(CNN)——实用的观点</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/convolutional-neural-networks-cnns-a-practical-perspective-c7b3b2091aa8?source=collection_archive---------22-----------------------#2020-05-07">https://towardsdatascience.com/convolutional-neural-networks-cnns-a-practical-perspective-c7b3b2091aa8?source=collection_archive---------22-----------------------#2020-05-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5b6c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">深入了解卷积神经网络的主要操作，并使用Mel光谱图和迁移学习对心跳进行分类。</h2></div></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/7a24f2d4d4911d33fa6677228427c506.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4nIWOYH1I7rWrw_s"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">弗兰基·查马基在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="42ae" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">大家好，</p><p id="d66e" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">希望每个人都平安无事。在这篇博客中，我们将探讨CNN的一些图像分类概念，这些概念经常被初学者(包括我在内)忽略或误解。这个博客要求读者对CNN的工作有一些基本的了解。然而，我们将涵盖CNN的重要方面，然后再深入到高级主题。</p><p id="973c" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在这之后，我们将研究一种称为迁移学习的机器学习技术，以及它如何在深度学习框架上用较少的数据训练模型。我们将在Resnet34架构之上训练一个图像分类模型，使用包含以音频形式数字记录的人类心跳的数据。wav)文件。在这个过程中，我们将使用一个流行的python音频库Librosa将这些音频文件转换成光谱图，从而将它们转换成图像。最后，我们将使用流行的误差度量来检验该模型，并检查其性能。</p><h1 id="0cb9" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">CNN的图像分类:</h1><p id="b7d8" class="pw-post-body-paragraph lg lh it li b lj mu ju ll lm mv jx lo lp mw lr ls lt mx lv lw lx my lz ma mb im bi translated">具有1次以上卷积运算的神经网络称为卷积神经网络(CNN)。CNN的输入包含图像，每个像素中的数值沿着宽度、高度和深度(通道)在空间上排列。总体架构的目标是通过从这些空间排列的数值中学习来获得属于某一类的图像的概率分数。在这个过程中，我们对这些数值执行诸如汇集和卷积之类的操作，以沿着深度挤压和拉伸它们。</p><p id="7d5e" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">图像通常包含三层，即RGB(红、绿、蓝)。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/e763b80e3908109e001c16789bff0ba4.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*peZsS2BvVkEvGnKhaPzQiQ.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">图片由<a class="ae lf" href="https://blog.datawow.io/@punyawiwat2" rel="noopener ugc nofollow" target="_blank"> Purit Punyawiwat </a>提供，来源:<a class="ae lf" href="https://blog.datawow.io/interns-explain-cnn-8a669d053f8b" rel="noopener ugc nofollow" target="_blank"> Datawow </a></p></figure><h1 id="9389" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated"><strong class="ak">CNN的主要操作</strong></h1><p id="3c93" class="pw-post-body-paragraph lg lh it li b lj mu ju ll lm mv jx lo lp mw lr ls lt mx lv lw lx my lz ma mb im bi translated"><strong class="li iu">卷积运算</strong></p><p id="a600" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">卷积运算(<em class="na"> w.x+b) </em>应用于输入体积中所有不同的空间位置。使用更多数量的卷积运算有助于学习特定的形状，即使它在图像中的位置发生了变化。</p><p id="914b" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">例子:通常云出现在风景图片的顶部。如果一个反转的图像被输入CNN，更多的卷积运算可以确保模型识别云的部分，即使它是反转的。</p><p id="36ac" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">数学表达式:<strong class="li iu"><em class="na">x _ new = w . x+b</em></strong><em class="na"/>其中<em class="na"> w </em>是滤波器/内核，<em class="na"> b </em>是偏差，<em class="na"> x </em>是隐藏层输出的一部分。对于应用于不同隐藏层的每个卷积运算，w<em class="na">和b</em>都是不同的。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nb"><img src="../Images/2fca8f070440d75596e5e009d008b6d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*HTBusYCR3hEvH_uzioSQrQ.gif"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">卷积运算(来源:第22讲-EECS251，inst.eecs.berkley.edu)</p></figure><p id="c0b5" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">联营</strong></p><p id="76cf" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">汇集减少了每个激活图(卷积运算后的输出)的空间维度，同时聚集了局部化的空间信息。池化有助于沿着高度和宽度挤压隐藏层的输出。如果我们考虑非重叠子区域内的最大值，那么它被称为最大池。最大池也增加了模型的非线性。</p><p id="6471" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">激活功能</strong></p><p id="211a" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">对于CNN而言，ReLU是优选的激活函数，因为与其他激活函数如tanh和sigmoid相比，它具有简单的可微性和快速性。ReLU通常跟在卷积运算之后。</p><p id="6ba8" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">让我们检查一下计算每个激活函数的梯度所用的时间:</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nc nd l"/></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ne"><img src="../Images/4eaef2ce9f6a4f96ee5e65a863d29889.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MN2b9DV4nz_jInhSYbfm_g.jpeg"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">每个模型生成其导数所用的时间</p></figure><p id="a6e0" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">从上表可以看出，与其他激活函数相比，ReLU计算其导数所需的时间要少得多。</p><p id="acf3" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">有时，当图像的边缘构成可能有助于训练模型的重要方面时，填充也用于这些操作之间。它还可以用于抑制由于汇集等操作而导致的高度和宽度方向的收缩。</p><p id="6a58" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">一般来说，隐藏层的<strong class="li iu">深度</strong>比<strong class="li iu">高</strong>，因为卷积运算中使用的<strong class="li iu">数量的滤波器</strong>比<strong class="li iu">高</strong>数量。随着每个过滤器学习新的特征或新的形状，过滤器的数量保持较高。</p><p id="b65a" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">示例:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nf"><img src="../Images/922fecc6a6c62519ffe70ff1a160d992.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jyG82s-FLiM1-TsJiUxA_g.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">多滤镜卷积运算，源码:<a class="ae lf" href="https://indoml.com/2018/03/07/student-notes-convolutional-neural-networks-cnn-introduction/" rel="noopener ugc nofollow" target="_blank"> Indoml </a></p></figure><p id="84ba" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这里，我们使用了两个滤波器来执行卷积运算，并且输出的深度也是2。假设，如果我们使用3个过滤器/内核，一个内核可能会学习识别垂直边缘，因为初始层不能学习大于过滤器大小(此处为3*3)的特征。第二滤波器可以学习识别水平边缘，第三滤波器可以学习识别图像中的弯曲边缘。</p><p id="c896" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">反向传播</strong></p><p id="f8b4" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">使用反向传播来更新每个卷积运算的权重(w)。<strong class="li iu">反向传播</strong>涉及梯度的计算，这反过来帮助w达到错误率(或任何其他损失度量)非常小的理想状态。在Pytorch中，使用torch.backward函数执行反向传播。从数学上来说，我们可以说这个函数类似于J.v操作，其中J是雅可比矩阵，v是损耗w.r.t下一层的梯度。雅可比矩阵由偏导数组成，可以认为是局部梯度。</p><p id="0507" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">对于一个函数，y = f(x)其中y和x是向量，J.v是</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ng"><img src="../Images/5df4279160f9b0d2fa4f7df52ad49f30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tJNcZ_wnKIX95xd3rvOKog.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">图片来源:Pytorch.org<a class="ae lf" href="https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html" rel="noopener ugc nofollow" target="_blank"/></p></figure><p id="242c" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">其中<strong class="li iu"> <em class="na"> l </em> </strong>为损失函数。</p><p id="8c46" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">批量归一化</strong></p><p id="f18b" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">执行批量标准化(BN)是为了解决内部协变量移位(ICF)的问题。由于每次操作中权重的分布不同，隐藏层需要更多的时间来适应这些变化。批量标准化技术使得由神经网络<strong class="li iu">学习的较深层的权重较少依赖于在较浅层学习的权重</strong>，从而避免ICF。</p><p id="b614" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">它在隐藏层输出的<strong class="li iu">像素级</strong>执行。下图是批量大小= 3，隐藏层大小为4*4的示例。最初，批处理规范化据说是在应用ReLU(激活函数)之前<strong class="li iu">执行的，但是后来的结果发现，当它在激活步骤之后执行时，模型执行得更好。</strong></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nh"><img src="../Images/7eac7a01780155b1baa926cbb2c52145.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*shoO6s1vjwt7251yT5TIMg.jpeg"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">图片由<a class="ae lf" href="https://towardsdatascience.com/@aqeel.anwar" rel="noopener" target="_blank"> Aqeel Anwar </a>提供，来源:<a class="ae lf" rel="noopener" target="_blank" href="/difference-between-local-response-normalization-and-batch-normalization-272308c034ac">走向数据科学</a></p></figure><p id="ad87" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">Pytorch，在训练期间，一批隐藏层保持运行其计算的平均值和方差的估计，这些估计稍后在该特定层中的评估/测试期间用于归一化。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/a296b5e99d28c90c7552b05897064f62.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*HVzsviKvlD9ei3Aoqbr9jg.jpeg"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">批量标准化，来源:<a class="ae lf" href="https://pytorch.org/docs/stable/nn.html" rel="noopener ugc nofollow" target="_blank"> Pytorch文档</a></p></figure><p id="efbf" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">默认情况下，γ <em class="na"> </em>的元素设置为1，β的元素设置为0</p><p id="9b23" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">正规化</strong></p><p id="dcc4" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">引入正则化是为了检查权重矩阵(w)中的元素，并避免 <strong class="li iu">过拟合</strong>。通常，我们在CNN中执行L2正则化。<strong class="li iu">丢弃</strong>也有助于正则化隐藏层的输出，只需以一定的概率p丢弃一些完全连接的层连接。Pytorch通过在一个隐藏层中批量随机分配零到整个通道来实现这一点。</p><p id="a307" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">小批量</strong></p><p id="4d07" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">一组图像(批次)(通常是2的幂，如8、16、32)通过使用GPU的能力在这些图像上独立但并行地运行模型而被传递到架构中。小批量有助于我们最大限度地减少更新权重向量的次数，而不会影响结果。微型批处理有助于实现更快的收敛。</p><p id="c3b9" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">小批量梯度下降</strong></p><p id="df9e" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">使用小批量梯度下降在每次批量后更新重量向量。我们取像素级的所有梯度的<strong class="li iu">平均值，并将其从权重向量中减去，以在每个时期后得到更新的权重向量。</strong></p><p id="088b" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">也有一些梯度优化技术，使这一进程更快。<strong class="li iu"> ADAM </strong>就是一种常用的梯度下降优化技术。这里，我们将使用ADAM优化技术(尽管在下面的代码中没有具体提到)。</p><h1 id="2ab1" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated"><strong class="ak">迁移学习</strong></h1><p id="04ca" class="pw-post-body-paragraph lg lh it li b lj mu ju ll lm mv jx lo lp mw lr ls lt mx lv lw lx my lz ma mb im bi translated">迁移学习是一种机器学习技术，其中模型使用在大型数据集上训练的预训练参数/权重。<strong class="li iu"> </strong>迁移学习减少了收集更多数据的需求，有助于在小数据集上运行深度学习模型。</p><p id="09de" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">如前所述，CNN的初始层擅长捕捉简单和通用的特征(如边缘、曲线等)。)而更深层次的则擅长复杂特征。因此，只训练较深层的参数(权重)而不更新其他层的参数更有意义。我们将在ResNet-34模型上使用这种技术，并检查其性能。</p><p id="736c" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu"> ResNet-34架构:</strong></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nj"><img src="../Images/b447d5706f15923fa438bae220d3c616.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KSUB5LgmDu0QnlLso5214w.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">图片来自<a class="ae lf" href="http://euler.stat.yale.edu/~tba3/stat665/lectures/lec18/img/resNet.jpg" rel="noopener ugc nofollow" target="_blank">euler.stat.yale.edu</a></p></figure><p id="7cde" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">了解数据:</strong></p><p id="da7a" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">给定的数据包含313个音频文件的数字记录的人类心跳。wav格式。set_b.csv文件中提供了这些音频文件的标签。为了使用CNN的，我们必须将这些音频文件转换成图像格式。</p><p id="d0b0" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">应用于音频信号的傅立叶变换将信号从时域转换到频域。频谱图是应用傅立叶变换后信号的直观表示。Mel光谱图是以Mel标度为y轴的光谱图。</p><p id="bb79" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">音频文件:</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nk nd l"/></div></figure><p id="6fb0" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">以上音频文件的Mel声谱图表示:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/cf15edd60d2bc855e67d898ffbc35cb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*bZjQOx82hBbKZ0QOeQX89Q.jpeg"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">梅尔光谱图</p></figure><p id="beb8" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">代码:</strong></p><blockquote class="nm nn no"><p id="0a9b" class="lg lh na li b lj lk ju ll lm ln jx lo np lq lr ls nq lu lv lw nr ly lz ma mb im bi translated">为此任务导入必要的模块</p></blockquote><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nc nd l"/></div></figure><blockquote class="nm nn no"><p id="86ec" class="lg lh na li b lj lk ju ll lm ln jx lo np lq lr ls nq lu lv lw nr ly lz ma mb im bi translated">创建一个python函数，该函数创建每个音频文件的mel-spectrogram，并将其保存在一个目录中</p></blockquote><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nc nd l"/></div></figure><blockquote class="nm nn no"><p id="6eee" class="lg lh na li b lj lk ju ll lm ln jx lo np lq lr ls nq lu lv lw nr ly lz ma mb im bi translated">查看标签数据</p></blockquote><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nc nd l"/></div></figure><blockquote class="nm nn no"><p id="56b3" class="lg lh na li b lj lk ju ll lm ln jx lo np lq lr ls nq lu lv lw nr ly lz ma mb im bi translated">准备用于分类的数据，并将每个图像转换为512*512。数据以70:30的比例分为训练和验证。批处理大小4用于在GPU中并行化任务。</p></blockquote><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nc nd l"/></div></figure><blockquote class="nm nn no"><p id="df99" class="lg lh na li b lj lk ju ll lm ln jx lo np lq lr ls nq lu lv lw nr ly lz ma mb im bi translated">选择要使用的架构</p></blockquote><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nc nd l"/></div></figure><blockquote class="nm nn no"><p id="1f61" class="lg lh na li b lj lk ju ll lm ln jx lo np lq lr ls nq lu lv lw nr ly lz ma mb im bi translated">定义模型并将“错误率”设置为错误度量。'误差_率'是(<strong class="li iu"><em class="it">1-精度)</em> </strong></p></blockquote><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nc nd l"/></div></figure><blockquote class="nm nn no"><p id="ceb0" class="lg lh na li b lj lk ju ll lm ln jx lo np lq lr ls nq lu lv lw nr ly lz ma mb im bi translated">为我们的模型选择正确的学习率</p></blockquote><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nc nd l"/></div></figure><blockquote class="nm nn no"><p id="5b22" class="lg lh na li b lj lk ju ll lm ln jx lo np lq lr ls nq lu lv lw nr ly lz ma mb im bi translated">在选择了正确的学习速率后，我们可以选择使用learn.freeze()命令使用预训练的参数/权重来训练模型</p></blockquote><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nc nd l"/></div></figure><blockquote class="nm nn no"><p id="9c36" class="lg lh na li b lj lk ju ll lm ln jx lo np lq lr ls nq lu lv lw nr ly lz ma mb im bi translated">使用循环学习率更新模型5次(即，5个时期)</p></blockquote><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nc nd l"/></div></figure><blockquote class="nm nn no"><p id="d9d4" class="lg lh na li b lj lk ju ll lm ln jx lo np lq lr ls nq lu lv lw nr ly lz ma mb im bi translated">一批已验证集合的结果。在这一批中，我们所有的预测都是正确的。</p></blockquote><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nc nd l"/></div></figure><blockquote class="nm nn no"><p id="1035" class="lg lh na li b lj lk ju ll lm ln jx lo np lq lr ls nq lu lv lw nr ly lz ma mb im bi translated">绘制混淆矩阵</p></blockquote><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nc nd l"/></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/e9024ce655fa2415127c7349a52d0b40.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*WzIShhuMiKb-5Fx_HMw0Ig.jpeg"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">最终预测的混淆矩阵</p></figure><p id="dfbf" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我们的模型在识别杂音和正常心跳方面表现非常好。模型的最终<strong class="li iu">精度</strong>大约为<strong class="li iu"> 70% </strong>(对角线元素的总和/混淆矩阵中所有元素的总和)<strong class="li iu"> </strong>，这在这种情况下非常好，因为给定的数据在某些情况下是不平衡的和有噪声的。你可以在这里找到完整的代码<a class="ae lf" href="https://github.com/pawanreddy-u/Heartbeat-Classification/blob/master/Heartbeats.ipynb" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="928a" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">结论:</strong></p><p id="11a8" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在这篇博客中，我们已经学习了卷积神经网络(CNN)的构建模块的实际方面以及为什么使用它们。我们使用这些概念并建立了一个图像分类模型，将Mel频谱图分为3类(杂音、期前收缩和正常)。最后，我们用混淆矩阵对性能进行了分析。</p><p id="4e62" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">如果你发现这个博客有任何帮助，请分享并在这里鼓掌。它鼓励我写更多这样的博客。</p><p id="890c" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">谢谢大家！！！</p></div></div>    
</body>
</html>