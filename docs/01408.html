<html>
<head>
<title>Logistic Regression Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">逻辑回归解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/logistic-regression-explained-9ee73cede081?source=collection_archive---------0-----------------------#2020-02-08">https://towardsdatascience.com/logistic-regression-explained-9ee73cede081?source=collection_archive---------0-----------------------#2020-02-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1618" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">[ —逻辑回归简单解释— ]</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/cc455da2b67b2a2fd1f8387c50362ba0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QY3CSyA4BzAU6sEPFwp9ZQ.png"/></div></div></figure><p id="d848" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这篇文章中，我将简单地解释逻辑回归。这可以被认为是一种逻辑回归，然而，我从来没有真正喜欢这个表达。</p><p id="6343" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><em class="lq">在我们开始之前，这里有一些额外的资源可以让你的机器学习事业突飞猛进:</em></p><pre class="kj kk kl km gt lr ls lt lu aw lv bi"><span id="e4df" class="lw lx it ls b gy ly lz l ma mb"><em class="lq">Awesome Machine Learning Resources:</em></span><span id="5cc1" class="lw lx it ls b gy mc lz l ma mb"><em class="lq">- For </em><strong class="ls iu"><em class="lq">learning resources</em></strong><em class="lq"> go to </em><a class="ae md" href="https://howtolearnmachinelearning.com/books/machine-learning-books/" rel="noopener ugc nofollow" target="_blank"><strong class="ls iu"><em class="lq">How to Learn Machine Learning</em></strong></a><em class="lq">! <br/>- For </em><strong class="ls iu"><em class="lq">professional</em></strong><em class="lq"> </em><strong class="ls iu"><em class="lq">resources</em></strong><em class="lq"> (jobs, events, skill tests) go to </em><a class="ae md" href="https://aigents.co/" rel="noopener ugc nofollow" target="_blank"><strong class="ls iu"><em class="lq">AIgents.co — A career community for Data Scientists &amp; Machine Learning Engineers</em></strong></a><strong class="ls iu"><em class="lq">.<br/></em></strong></span></pre><div class="me mf gp gr mg mh"><a href="https://z-ai.medium.com/subscribe" rel="noopener follow" target="_blank"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd iu gy z fp mm fr fs mn fu fw is bi translated">订阅我的专属列表！</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">订阅我的专属列表！并获取您喜爱的所有新鲜文章&lt;3! By signing up, you will create a Medium…</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">z-ai.medium.com</p></div></div><div class="mq l"><div class="mr l ms mt mu mq mv ks mh"/></div></div></a></div><p id="5cf5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Lets get to it and learn it all about Logistic Regression.</p><h1 id="44ec" class="mw lx it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">Logistic Regression Explained for Beginners</h1><p id="14db" class="pw-post-body-paragraph ku kv it kw b kx nn ju kz la no jx lc ld np lf lg lh nq lj lk ll nr ln lo lp im bi translated">In the Machine Learning world, <strong class="kw iu">逻辑回归</strong>是一种<strong class="kw iu">参数分类模型，</strong>尽管其名称中有单词'<em class="lq">回归</em> ' <strong class="kw iu"> </strong>。</p><p id="f1ae" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这意味着逻辑回归模型是具有某个固定数量的参数的模型，这些参数取决于输入特征的数量，并且它们输出分类预测，例如植物是否属于某个物种。</p><p id="4cad" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在现实中，逻辑回归背后的理论与线性回归非常相似，所以如果你不知道什么是线性回归，花5分钟阅读这个超级简单的指南:</p><div class="me mf gp gr mg mh"><a rel="noopener follow" target="_blank" href="/linear-regression-explained-d0a1068accb9"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd iu gy z fp mm fr fs mn fu fw is bi translated">线性回归解释</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">[ —线性回归简单解释— ]</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">towardsdatascience.com</p></div></div><div class="mq l"><div class="ns l ms mt mu mq mv ks mh"/></div></div></a></div><p id="dd94" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在逻辑回归中，我们不像线性回归那样直接用直线拟合数据。相反，我们拟合一条S形曲线，称为<strong class="kw iu"><em class="lq">S形</em> </strong>，来拟合我们的观察结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/d6c769d469e4c27eed35e9d2f5734486.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*44qV8LhNzE5hPnta2PaaHw.png"/></div></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">符合某些数据的Sigmoid函数</p></figure><p id="a899" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们仔细检查一下这个数字。</p><p id="95f8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">首先</strong>，就像我们之前说的，Logistic回归模型是分类模型；特别是二元分类模型(它们只能用于区分两种不同的类别——比如一个人是否肥胖或体重不足，或者一所房子根据其大小是大是小)。<strong class="kw iu">这意味着我们的数据有两种观察值</strong>(类别1和类别2观察值)，就像我们在图中可以观察到的一样。</p><p id="001f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> <em class="lq">注:</em> </strong> <em class="lq">这是逻辑回归的一个非常简单的例子，在实践中更困难的问题可以使用这些模型来解决，使用广泛的特性而不仅仅是单一的一个。</em></p><p id="fac9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">其次</strong>，我们可以看到，Y轴从0到1。这是因为<em class="lq"> sigmoid </em>函数总是将这两个值作为最大值和最小值，这非常符合我们将样本分为两个不同类别的目标。通过计算X的<em class="lq"> sigmoid </em>函数(这是输入特征的加权和，就像线性回归中一样)，<strong class="kw iu">我们得到属于两个类别之一的观察值的概率</strong> ( <em class="lq">在0和1之间，显然是</em>)。</p><p id="eb60" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><em class="lq">s形函数</em>的公式如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/1c62536deb531ecbf90f40b8e19133b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/0*59BSXTBcxZcZGtVT"/></div></figure><p id="4bf3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果我们想预测一个人是否肥胖或没有给出他们的体重，我们将首先计算他们体重的加权和(抱歉，词汇冗余)，然后将其输入到<em class="lq"> sigmoid </em>函数中:</p><h2 id="bb48" class="lw lx it bd mx nz oa dn nb ob oc dp nf ld od oe nh lh of og nj ll oh oi nl oj bi translated">1)计算输入的加权和</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/4ca23ae9fa6b643eefbea358ea753b76.png" data-original-src="https://miro.medium.com/v2/resize:fit:492/0*vq7V-FuK9EirWDeN"/></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">输入要素的加权总和(本例中为要素)</p></figure><h2 id="766a" class="lw lx it bd mx nz oa dn nb ob oc dp nf ld od oe nh lh of og nj ll oh oi nl oj bi translated">2)计算肥胖的概率</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/a60a8f7df89b26c8998afeeaa5c8acfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:898/0*p5Yczl6itusXkxN8"/></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">使用sigmoid方程进行计算</p></figure><p id="6761" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">好吧，这看起来很酷，但这难道不是一个机器学习模型吗？<em class="lq"> </em> <strong class="kw iu"> <em class="lq">我们如何训练它？</em> </strong>这个问题问得好。有多种方法来训练逻辑回归模型(将S形线拟合到我们的数据)。我们可以使用类似<strong class="kw iu"> <em class="lq">梯度下降</em> </strong>的迭代优化算法来计算模型的参数(权重)，或者我们可以使用类似<strong class="kw iu"> <em class="lq">最大似然</em> </strong>的概率方法。</p><p id="823c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你不知道这些是什么，梯度下降在<a class="ae md" rel="noopener" target="_blank" href="/linear-regression-explained-d0a1068accb9">线性回归文章</a>中有解释，关于机器学习的最大可能性的解释可以在这里找到:</p><div class="me mf gp gr mg mh"><a rel="noopener follow" target="_blank" href="/probability-learning-iii-maximum-likelihood-e78d5ebea80c"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd iu gy z fp mm fr fs mn fu fw is bi translated">概率学习III:最大似然</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">我们成为概率大师的又一步…</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">towardsdatascience.com</p></div></div><div class="mq l"><div class="om l ms mt mu mq mv ks mh"/></div></div></a></div><p id="ff49" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">一旦我们使用了这些方法中的一种来训练我们的模型，我们就可以做一些预测了。让我们来看一个示例，演示如何训练逻辑回归模型并使用它来进行预测:</p><ol class=""><li id="78f2" class="on oo it kw b kx ky la lb ld op lh oq ll or lp os ot ou ov bi translated"><strong class="kw iu">首先，</strong>我们将<strong class="kw iu">收集一个数据集</strong>，该数据集包含已被诊断为肥胖和未被诊断为肥胖的患者，以及他们相应的体重。</li><li id="c0e4" class="on oo it kw b kx ow la ox ld oy lh oz ll pa lp os ot ou ov bi translated"><strong class="kw iu">在此</strong>之后，我们将<strong class="kw iu">训练我们的模型</strong>，将我们的S形线与数据拟合，并获得模型的参数。使用最大似然法进行训练后，我们得到了以下参数:</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/fc414fda5771894ebd6837063cad8802.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*sGI7P3PLzVcwWkLTE5Q7mg.png"/></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">X的参数和方程</p></figure><p id="b3f4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">3.<strong class="kw iu">现在</strong>，我们准备<strong class="kw iu">做一些预测</strong>:假设我们有两个病人；一个120斤，一个60斤。让我们看看将这些数字代入模型后会发生什么:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/d8f3c1a58bc62dffb27a415520d0aa7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/1*fCwfXTnE55D_MJWNqhkegQ.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/2ce387dd76413c2846bc50c341e7363d.png" data-original-src="https://miro.medium.com/v2/resize:fit:878/format:webp/1*dwEPZB0Y6wKBvVNoQTLy6A.png"/></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">在给定患者体重的情况下，使用拟合模型预测肥胖的结果</p></figure><p id="f912" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可以看到，第一个病人(60公斤)肥胖的概率非常低，然而，第二个病人(120公斤)肥胖的概率非常高。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/641f1554495b457437b3f1741b65e1a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UYlAenPep0fmJamioIWTBw.png"/></div></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">前面例子的逻辑回归结果。</p></figure><p id="8c90" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在上图中，我们可以看到逻辑回归模型给出的结果。现在，给定任何患者的体重，我们可以计算他们肥胖的概率，并给我们的医生一个快速的第一轮信息！</p><div class="me mf gp gr mg mh"><a href="https://z-ai.medium.com/subscribe" rel="noopener follow" target="_blank"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd iu gy z fp mm fr fs mn fu fw is bi translated">订阅我的专属列表！</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">订阅我的专属列表！并获取所有你喜爱的新鲜文章&lt;3! By signing up, you will create a Medium…</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">z-ai.medium.com</p></div></div><div class="mq l"><div class="mr l ms mt mu mq mv ks mh"/></div></div></a></div><h1 id="9f04" class="mw lx it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">Conclusion and Other resources</h1><p id="fb86" class="pw-post-body-paragraph ku kv it kw b kx nn ju kz la no jx lc ld np lf lg lh nq lj lk ll nr ln lo lp im bi translated"><em class="lq">逻辑回归是最简单的机器学习模型之一。它们容易理解，可解释，并且能给出相当好的结果。这篇文章的目标是为不是机器学习从业者的人提供一种以非数学方式理解逻辑回归的简单方法，所以如果你想更深入，或者正在寻找更深刻的数学解释，看看下面的视频，它很好地解释了我们在这篇文章中提到的一切。</em></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf pg l"/></div></figure><p id="5689" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><em class="lq">关于机器学习和数据科学的更多资源，请查看以下资源库:</em> <a class="ae md" href="https://howtolearnmachinelearning.com/books/machine-learning-books/" rel="noopener ugc nofollow" target="_blank"> <em class="lq">如何学习机器学习</em> </a> <em class="lq">！有关职业资源(工作、事件、技能测试)，请访问</em><a class="ae md" href="https://aigents.co/" rel="noopener ugc nofollow" target="_blank"><em class="lq">AIgents.co——数据科学家的职业社区&amp;机器学习工程师</em> </a> <em class="lq">。</em></p><p id="35f4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">牛逼的逻辑回归！</p><p id="e9c0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><em class="lq">此外，为了更深入地研究逻辑回归和机器学习，可以看看下面文章中描述的书:</em></p><div class="me mf gp gr mg mh"><a rel="noopener follow" target="_blank" href="/the-book-to-really-start-you-on-machine-learning-47632059fd0e"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd iu gy z fp mm fr fs mn fu fw is bi translated">让你真正开始机器学习的书</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">让你的机器学习知识更上一层楼</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">towardsdatascience.com</p></div></div><div class="mq l"><div class="ph l ms mt mu mq mv ks mh"/></div></div></a></div></div></div>    
</body>
</html>