<html>
<head>
<title>How Do RCNs Learn?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">rcn如何学习？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-do-rcns-learn-1b65561f2e38?source=collection_archive---------37-----------------------#2020-02-02">https://towardsdatascience.com/how-do-rcns-learn-1b65561f2e38?source=collection_archive---------37-----------------------#2020-02-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="0903" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">皇家护理学院</h2><div class=""/><div class=""><h2 id="06ea" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">用匹配追踪代替梯度下降</h2></div><p id="07d0" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">科学进步一次一个葬礼。马克斯·普朗克的这些话是杰弗里·辛顿在被要求评论反向传播在未来的作用时使用的话，反向传播是他共同发明的算法[1]。为了发展人工智能，检查人类大脑的灵感是很自然的，Vicarious在他们的递归皮层网络(RCNs)工作中就是这样做的[2]。本专栏文章探讨了rcn的不同方面，在本文中，我们探讨了它们的学习机制。</p><p id="c197" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="lk">本文假设了解ConvNets和RCNs的结构，并倾向于了解RCNs的推理机制。可以从[2]或者我以前的文章(</em> <a class="ae ll" href="https://medium.com/@iahmedmaher/understanding-rcns-structure-ec4b51b9c257" rel="noopener"> <em class="lk">结构</em> </a> <em class="lk">，</em> <a class="ae ll" href="https://medium.com/@iahmedmaher/understanding-the-inference-mechanism-of-rcns-ba1f00416b63" rel="noopener"> <em class="lk">推论</em> </a> <em class="lk">)中了解RCNs。</em></p><p id="4fcc" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在rcn中有两件事情需要学习，功能节点的通道以及它们到其下一层的布线，以及池层中的横向连接。</p><h1 id="0373" class="lm ln iq bd lo lp lq lr ls lt lu lv lw kf lx kg ly ki lz kj ma kl mb km mc md bi translated">特征学习</h1><h2 id="ea0e" class="me ln iq bd lo mf mg dn ls mh mi dp lw kx mj mk ly lb ml mm ma lf mn mo mc iw bi translated">特征到底是什么？</h2><p id="f211" class="pw-post-body-paragraph ko kp iq kq b kr mp ka kt ku mq kd kw kx mr kz la lb ms ld le lf mt lh li lj ij bi translated">在我们深入研究特征学习机制之前，让我们回顾一下rcn甚至ConvNets中特征的用途。分层视觉模型中给定层上的特征仅仅是考虑到它们在空间中的排列而对其下一层中的特征进行分组。在ConvNets中，特征映射中的一个单元指示在该特定元素周围的局部窗口中存在多少特定的较低级特征分组。在rcn中，通道(相当于ConvNet特征图中的单元)不是实数，而是二进制值，表示特定特征的存在与否。</p><p id="5d1b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">但是，我们应该关注什么样的低层特性分组呢？假设我们位于某个中间层，其下的要素图层在多个方向上检测曲线段。如果我们想识别英语中的字符，我们是否应该有一个特征来表示一组形成花、星或圆的曲线段的存在？这个问题的答案是这个特征将在多大程度上帮助模型解释它通常会<em class="lk">遇到的关于其他候选特征的图像。所以，在英语OCR的情况下，一个圆比一朵花或一颗星更有用，这基本上是RCNs的学习算法的本质。</em></p><p id="bfd4" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在rcn中，我们只需要学习中间层和最顶层的特性，因为最底层具有硬编码的特性，即补丁描述符。对于中间层，算法逐层进行。在每一层，该算法在每次迭代中迭代添加单个特征，直到它找不到任何有用的特征来添加。让我们考虑在图1所示的特征层之上学习一个特征层。为简单起见，所示的层将被称为层A，而它上面的层将被称为层b。</p><figure class="mv mw mx my gt mz gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi mu"><img src="../Images/274efba682cf4e387c818b31cade9c2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d0_4y6lwlu43XirHShNnWw.png"/></div></div><p class="ng nh gj gh gi ni nj bd b be z dk translated">图1:对于给定的图像，运行前向传递和稀疏化步骤后的活动特征。所有显示的层已经经历了学习。为简明起见，较低层显示为长方体。其上的图层是具有8个颜色编码通道的要素图层(即黄色通道表示在其坐标处存在弯曲的左线段)。抱歉，看起来不专业，但它让事情更清楚。</p></figure><h2 id="ddbf" class="me ln iq bd lo mf mg dn ls mh mi dp lw kx mj mk ly lb ml mm ma lf mn mo mc iw bi translated">中间层特征学习</h2><p id="bdcd" class="pw-post-body-paragraph ko kp iq kq b kr mp ka kt ku mq kd kw kx mr kz la lb ms ld le lf mt lh li lj ij bi translated">在第一次迭代中，该算法从训练数据集中选取一幅随机图像，并向前传递到层A。然后，我们应用一个稀疏化步骤，使我们获得层A的最有可能解释该层输入图像的特征。请记住，正向传递产生来自所有通道的信念传播消息，但不会告诉我们哪些功能应该激活，哪些不应该激活。如您在图1中所见，该图层中将有许多活动要素，其中一些组重复出现，如表示圆的组和表示长直线段的组。然而，在层B，图像是完全无法解释的，因为在这一层还没有通道。该算法基于一些试探法来挑选一些候选分组，例如活动通道彼此靠近以及其中具有大量子特征的分组。对于每个候选分组，该算法计算其在训练数据集中的使用频率，并挑选最常使用的分组，该分组满足我们之前关于应该学习哪些特征的推理。</p><p id="983d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在图1中，可以看到对应于一个圆的层A的红、黄、绿和蓝通道的特定方向出现了两次。因此，我们假设它选择了这组子特征，并将其作为b层的特征添加。在下一次迭代中，该算法选择了另一个随机图像。现在，它的所有圆将在层B通过稀疏化步骤解释，就像我们在层A所做的那样，但是所有长线段不会，所以这次的算法可能会选择长线段的分组，因为它是英文字母中的常见特征，并继续下一次迭代，以此类推。</p><p id="6dec" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我想在这里提到，所有这些都依赖于稀疏编码的思想，其中我刚才提到的算法是字典学习算法匹配追踪，但作者添加了轻微的修改。</p><p id="056a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">您可能已经注意到，所有中间层都不需要标签，这是rcn的一个很好的特性。在许多任务中，作者使用SHREC 3D数据集的10，000张图像训练中间层，然后在其他数据集上使用这些学习到的层，这有点像迁移学习。您可以在图2中看到实际RCN的中间层学会表示哪些通道。</p><figure class="mv mw mx my gt mz gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi nk"><img src="../Images/ef4bb1856a143b71a21bc5e75df9fe4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3BVj528aPxPiYbLp4orssA.png"/></div></div><p class="ng nh gj gh gi ni nj bd b be z dk translated">图2:中间层RCN的学习特征。图片摘自[2]的补充材料文档。</p></figure><h2 id="dc92" class="me ln iq bd lo mf mg dn ls mh mi dp lw kx mj mk ly lb ml mm ma lf mn mo mc iw bi translated">最顶层特征学习</h2><p id="bfee" class="pw-post-body-paragraph ko kp iq kq b kr mp ka kt ku mq kd kw kx mr kz la lb ms ld le lf mt lh li lj ij bi translated">最顶层是一个特例。它是使用一个带标签的图像集学习的，我们希望最终对它的图像进行分类。对于每个标记的图像，创建新的分类器特征。因此，对于同一个类，我们实际上可能在最顶层有多个通道。这看起来很昂贵，但是rcn是数据高效的，所以它首先不需要大量带标签的图像。我们在上一段中描述的学习算法将被修改，以便允许我们刚才提到的最顶层上的约束，这些约束很简单，不值得一提。</p><h2 id="2031" class="me ln iq bd lo mf mg dn ls mh mi dp lw kx mj mk ly lb ml mm ma lf mn mo mc iw bi translated">横向联系学习</h2><p id="2d46" class="pw-post-body-paragraph ko kp iq kq b kr mp ka kt ku mq kd kw kx mr kz la lb ms ld le lf mt lh li lj ij bi translated">不幸的是，这篇论文及其附带的补充文档没有提到关于如何学习池层的横向连接的很多细节，并且其算法也没有出现在他们发布的代码库中。他们提到的主要问题是，他们是从输入图像中对象的轮廓连通性中学习的。</p><p id="98e3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">本文到此为止。如果你想了解更多关于RCNs的知识，你可以查看它的论文[2]和补充材料文档，或者你可以阅读<a class="ae ll" href="https://medium.com/@iahmedmaher/examining-the-performance-of-rcns-on-popular-datasets-1d6a2a8852c1" rel="noopener">我的关于在不同数据集上应用RCNs的结果的文章</a>。</p></div><div class="ab cl nl nm hu nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="ij ik il im in"><h1 id="ba9f" class="lm ln iq bd lo lp ns lr ls lt nt lv lw kf nu kg ly ki nv kj ma kl nw km mc md bi translated">参考资料:</h1><p id="e841" class="pw-post-body-paragraph ko kp iq kq b kr mp ka kt ku mq kd kw kx mr kz la lb ms ld le lf mt lh li lj ij bi translated">[1] <a class="ae ll" href="https://www.axios.com/artificial-intelligence-pioneer-says-we-need-to-start-over-1513305524-f619efbd-9db0-4947-a9b2-7a4c310a28fe.html" rel="noopener ugc nofollow" target="_blank"> S. LeVine，人工智能先驱说我们需要重新开始(2017)，Axios。</a></p><p id="385c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">[2] <a class="ae ll" href="https://science.sciencemag.org/content/358/6368/eaag2612.full?ijkey=DmvGldXIEXVoQ&amp;keytype=ref&amp;siteid=sci" rel="noopener ugc nofollow" target="_blank"> D. George，W. Lehrach，K. Kansky等，一种以高数据效率训练并打破基于文本的验证码的生成视觉模型(2017)，科学杂志(第358卷—第6368期)。</a></p></div></div>    
</body>
</html>