<html>
<head>
<title>How to Install easily Spark for Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何为 Python 轻松安装 Spark</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-install-easily-spark-for-python-d7ca6f5e729c?source=collection_archive---------30-----------------------#2020-07-21">https://towardsdatascience.com/how-to-install-easily-spark-for-python-d7ca6f5e729c?source=collection_archive---------30-----------------------#2020-07-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9358" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">分三步在 Windows 10 上安装 PySpark</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/48d0a3b4697ca58bc35a393b8e8fe2f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_M_usADKAMZST6uHcHYQ4w.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">费德里科·贝卡里在<a class="ae ky" href="https://unsplash.com/s/photos/connection?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="d564" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">简介</strong></p><p id="0eb2" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">当我们处理大数据时，我们需要更多的计算能力，这可以通过多台计算机的分布式系统来实现。此外，为了有效地融入大数据生态系统，我们还需要一个集群计算框架，允许我们在大型数据集上快速执行处理任务。</p><p id="ffda" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">两个最著名的集群计算框架是 Hadoop 和 Spark，它们都是免费开源的。</p><p id="72e2" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">如果要比较 Apache Spark 和 Hadoop，可以说 Spark 在内存上快 100 倍，在磁盘上快 10 倍。</p><p id="9aef" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">对于 on-perm 安装，Hadoop 需要更多的磁盘内存，Spark 需要更多的 RAM，这意味着建立一个集群可能非常昂贵。</p><p id="0409" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">今天，我们可以通过 AWS 和 Azure 提供的云计算服务来解决这个问题。如果您有兴趣了解更多关于它们的信息，特别是像云数据仓库这样的主题，让我向您推荐我的文章，您可以在这里找到<a class="ae ky" rel="noopener" target="_blank" href="/overview-of-the-top-2-cloud-data-warehouses-amazon-redshift-azure-sql-dwh-6ff42fc26052?source=friends_link&amp;sk=feab4fd5644c93dce74ab559271b4a17"/>。</p><p id="01da" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">相反，在本文中，我将向您展示如何安装名为 Pyspark 的 Spark Python API。在 Windows 10 上安装 Pyspark 需要遵循一些不同的步骤，有时我们会忘记这些步骤。所以，通过这篇文章，我希望给你一个有用的指南，让你毫无问题地安装 Pyspark。</p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="9a66" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">第一部分:检查您的 Java 版本并下载 Apache Spark </strong></p><p id="d0c1" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我假设你的电脑上至少有 Python 版本。</p><p id="550b" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">所以，要运行 Spark，我们首先需要安装的是 Java。建议有 Java 8 或者 Java 1.8。</p><p id="2eab" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">因此，打开命令提示符，用下面的命令控制 Java 的版本。如果你有老版本，可以在这里下载<a class="ae ky" href="https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html" rel="noopener ugc nofollow" target="_blank">。</a></p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="2a1c" class="mh mi it md b gy mj mk l ml mm">Java -version</span></pre><p id="53be" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">出局:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/c63bccb13b927df0ca7ba207a8a34da7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1058/format:webp/1*bOCz6jlbaRgMc7nACvLtiw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="d863" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">现在，我们必须下载 Spark，您可以在这里轻松找到<a class="ae ky" href="http://spark.apache.org/downloads.html" rel="noopener ugc nofollow" target="_blank"/>。以下框架显示了您在站点中看到的步骤。</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="390e" class="mh mi it md b gy mj mk l ml mm">Download Apache Spark</span><span id="8455" class="mh mi it md b gy mo mk l ml mm">1. Choose a Spark release: 3.0.0(Jun 18 2020)--selected</span><span id="8df6" class="mh mi it md b gy mo mk l ml mm">2. Choose a package type: Pre-built for Apache Hadoop 2.7 --selected</span><span id="ea99" class="mh mi it md b gy mo mk l ml mm">3. Download Spark: <a class="ae ky" href="https://www.apache.org/dyn/closer.lua/spark/spark-3.0.0/spark-3.0.0-bin-hadoop2.7.tgz" rel="noopener ugc nofollow" target="_blank">spark-3.0.0-bin-hadoop2.7.tgz</a></span></pre><p id="6e7b" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">上面你可以观察到我如何设置我的 Spark 版本。我选择了最近的 Spark 版本和 Apache Hadoop 2.7 的预构建包。</p><p id="31d7" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">然后在第三步中，我们可以通过点击链接来下载我们的 Spark 版本，这将打开另一个网页，在该网页中，您必须点击建议的第一个下载版本。</p><p id="9f4a" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">下载完成后，将压缩文件解压到名为<strong class="li iu"> spark </strong>的文件夹中。<strong class="li iu"> </strong>记住这个文件夹的路径将在下一部分使用。</p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="8dcb" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">第二部分:下载 winutils.exe 并设置您的环境</strong></p><p id="ecdd" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">第二步是下载<strong class="li iu">winutils.exe</strong>你可以在这里<a class="ae ky" href="https://github.com/steveloughran/winutils" rel="noopener ugc nofollow" target="_blank">找到</a>。我的情况是选择了 hadoop-3.0.0 的版本，我<a class="ae ky" href="https://github.com/steveloughran/winutils/blob/master/hadoop-3.0.0/bin/winutils.exe" rel="noopener ugc nofollow" target="_blank">下载了</a>。你可以创建一个名为<strong class="li iu"> winutils </strong>的文件夹并把它放在那里。</p><p id="3c0e" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">现在，是时候建立我们的环境了。首先要做的是进入 windows 搜索栏，输入<strong class="li iu">“编辑系统环境变量”</strong>。</p><p id="1387" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">去点击<strong class="li iu">环境变量。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/09e6d5af0e493e0097186c93f1a54bc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/1*MCd0I9dMmZGBT_caplqnDQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="109f" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">当你将在<strong class="li iu">系统变量</strong>的组中，创建三个名为<strong class="li iu"> HADOOP_HOME </strong>、<strong class="li iu"> SPARK_HOME </strong>和<strong class="li iu"> JAVA_HOME </strong>的变量。</p><ul class=""><li id="dada" class="mq mr it li b lj lk lm ln lp ms lt mt lx mu mb mv mw mx my bi translated">在<strong class="li iu">HADOOP _ HOME</strong>→放之前创建的位置<strong class="li iu"> wintulis 文件夹</strong>的路径。</li><li id="f5b9" class="mq mr it li b lj mz lm na lp nb lt nc lx nd mb mv mw mx my bi translated">在<strong class="li iu">SPARK _ HOME</strong>→放入你之前创建的<strong class="li iu"> spark 文件夹</strong>的位置路径。</li><li id="4b78" class="mq mr it li b lj mz lm na lp nb lt nc lx nd mb mv mw mx my bi translated">在<strong class="li iu"> JAVA_HOME </strong>中→放入你的 JAVA 程序的位置路径。</li></ul><p id="58df" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在下图中，你可以看到如何设置你的变量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/117f17a8cff81e617120c6b1319c163e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*pZ84IsH_Fdx22rIMi4e8EQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/39c120ac07c04a4f607c1c483ce767fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*KHsfB1uClFxURaNyE3LOiQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="85e4" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">然后在变量<strong class="li iu">路径</strong>下面可以看到，我们可以添加以下两条路径:</p><ul class=""><li id="9ce7" class="mq mr it li b lj lk lm ln lp ms lt mt lx mu mb mv mw mx my bi translated"><strong class="li iu"> %SPARK_HOME%\bin </strong></li><li id="59d0" class="mq mr it li b lj mz lm na lp nb lt nc lx nd mb mv mw mx my bi translated"><strong class="li iu"> %JAVA_HOME%\bin </strong></li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/55c698bdb826a7af99aa7fb551d16081.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/format:webp/1*DYtU6R82xexIEBwSHDFgnA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="b8cf" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">第三部分:在你的蟒蛇身上运行它，飞到朱庇特</strong></p><p id="638f" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">现在您可以打开 Anaconda 提示符，将目录更改为<strong class="li iu"> SPARK_HOME </strong>目录，并键入<strong class="li iu"> bin\pyspark。</strong></p><p id="342a" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">出局:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/cb6beb759d6829b0161ad2bc7bbf8ae5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/1*DSmkF-nEKdTDMXse0lUvJQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="da95" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">所以，你准备飞往 Jupyter，用下面的代码尝试 Pyspark。如果没有错误，这意味着您的 Pyspark 已经正确安装。</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="d6b9" class="mh mi it md b gy mj mk l ml mm">import findspark<br/><br/>findspark.init()</span></pre></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="efb0" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">结论</strong></p><p id="2d6b" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">现在您已经有了 Pyspark，您可以开始通过进行一些数据操作来学习和练习它是如何工作的。如果你在安装上有困难，请随时联系我。</p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="3d52" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我发出一份期刊简讯。如果你想加入，请点击此链接报名。</p><p id="8970" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">除了我的<strong class="li iu">简讯</strong>，还可以在我的电报群<a class="ae ky" href="https://t.me/DataScienceForBeginners" rel="noopener ugc nofollow" target="_blank"> <strong class="li iu">数据科学初学者</strong> </a> <strong class="li iu">中取得联系。</strong></p></div></div>    
</body>
</html>