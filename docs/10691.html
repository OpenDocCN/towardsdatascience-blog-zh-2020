<html>
<head>
<title>DeepStyle (Part 2 ): The Fashion GAN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">时尚的甘(下)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deepstyle-part-2-4ca2ae822ba0?source=collection_archive---------26-----------------------#2020-07-26">https://towardsdatascience.com/deepstyle-part-2-4ca2ae822ba0?source=collection_archive---------26-----------------------#2020-07-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5511" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">构建 DCGAN 以生成逼真的高级时尚服装</h2></div><p id="84c4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您还没有阅读第 1 部分，请先阅读它，因为本文假设您已经阅读了第 1 部分。</p><div class="lf lg gp gr lh li"><a rel="noopener follow" target="_blank" href="/deepstyle-f8557ab9e7b"><div class="lj ab fo"><div class="lk ab ll cl cj lm"><h2 class="bd iu gy z fp ln fr fs lo fu fw is bi translated">DeepStyle:使用最先进的深度学习生成现实的高级时装服装和…</h2><div class="lp l"><h3 class="bd b gy z fp ln fr fs lo fu fw dk translated">提供论文和 Github 代码</h3></div><div class="lq l"><p class="bd b dl z fp ln fr fs lo fu fw dk translated">towardsdatascience.com</p></div></div><div class="lr l"><div class="ls l lt lu lv lr lw lx li"/></div></div></a></div><p id="bb8f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在假设您已经阅读了第 1 部分，让我们继续。</p><h2 id="75da" class="ly lz it bd ma mb mc dn md me mf dp mg kr mh mi mj kv mk ml mm kz mn mo mp mq bi translated">在 Pinterest 数据库和 Crop 上运行更快的 R-CNN</h2><p id="f480" class="pw-post-body-paragraph ki kj it kk b kl mr ju kn ko ms jx kq kr mt kt ku kv mu kx ky kz mv lb lc ld im bi translated">在收集了 Pinterest 数据库之后，现在我们可以使用我们之前训练的更快的 R-CNN 对这些图像进行推理。但在我们这样做之前，我们需要首先添加功能，我们将<strong class="kk iu">裁剪检测到的对象并保存结果图像</strong>，因为该功能不是开箱即用的。你可以去这个项目的<a class="ae le" href="https://github.com/itsuncheng/DeepStyle" rel="noopener ugc nofollow" target="_blank"> github repo 下载<code class="fe mw mx my mz b">vis.py</code>来完成。然后，导航到<code class="fe mw mx my mz b">detectron/utils</code>，用下载的版本替换现有的<code class="fe mw mx my mz b">vis.py</code>。新的<code class="fe mw mx my mz b">vis.py</code>与已经提供的相同，但有一个主要的不同——裁剪检测到的对象并将其保存在一个目录中。</a></p><figure class="na nb nc nd gt ne"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="ed09" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">添加的代码预测检测到的对象的类别，如果类别是“Full ”,即全身衣服，那么它将裁剪图像并将其保存在指定的目录中。我们只保存全身服装，因为我们希望能够生成全身服装，而不仅仅是简单的衬衫或裙子。</p><p id="16c8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">经过微小的修改后，我们就可以在 Pinterest 数据集上运行我们的模型了！我们可以在之前通过以下方式训练的更快的 R-CNN 上运行推理:</p><pre class="na nb nc nd gt nh mz ni nj aw nk bi"><span id="31c9" class="ly lz it mz b gy nl nm l nn no">python tools/infer.py \<br/>   --im [path/to/image.jpg] \<br/>   --rpn-pkl [path/to/rpn/model.pkl] \<br/>   --rpn-cfg <!-- -->configs/12_2017_baselines/e2e_faster_rcnn_R-50-FPN_1x.yaml<!-- --> \<br/>   --output-dir [path/to/output/dir]</span></pre><p id="6726" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><code class="fe mw mx my mz b">[path/to/image.jpg]</code>是我们存储 Pinterest 图像的目录，<code class="fe mw mx my mz b">--rpn-pkl</code>是我们之前保存模型<code class="fe mw mx my mz b">.pkl</code>文件的地方，<code class="fe mw mx my mz b">--rpn-cfg</code>是我们存储配置文件的地方，最后，<code class="fe mw mx my mz b">--output-dir</code>是我们想要保存预测的地方。然而，这个<code class="fe mw mx my mz b">--output-dir</code>并不重要，因为它将包含带有预测的未剪裁图像。我们要寻找的是我们在<code class="fe mw mx my mz b">vis.py</code>中指定的目录，因为那是保存裁剪图像的地方。</p><figure class="na nb nc nd gt ne gh gi paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><div class="gh gi np"><img src="../Images/05eec5cebac124d70d62d17d96ed5004.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SvGevfoQsXU_-3LiT0J-Ow.png"/></div></div><p class="nv nw gj gh gi nx ny bd b be z dk translated">包围盒预测(<a class="ae le" href="https://pixabay.com/photos/fashion-show-fashion-catwalk-model-1746596/" rel="noopener ugc nofollow" target="_blank">左源</a>、<a class="ae le" href="https://pixabay.com/photos/fashion-show-fashion-catwalk-model-1746610/" rel="noopener ugc nofollow" target="_blank">中间源</a>、<a class="ae le" href="https://pixabay.com/photos/fashion-show-fashion-catwalk-model-1746592/" rel="noopener ugc nofollow" target="_blank">右源</a>)</p></figure><p id="ba0e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在对模型进行推断之后，我们应该得到以服装为中心的裁剪图像，并且模型以及背景大部分被移除。即使仍然有一些噪音，我们已经足够好了。</p><figure class="na nb nc nd gt ne gh gi paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><div class="gh gi nz"><img src="../Images/3691815a42148ab2dc7a70ee21b50ae6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2NDQsRAX209h8TQvlfAYSA.png"/></div></div><p class="nv nw gj gh gi nx ny bd b be z dk translated">将裁剪后的图像传递给时尚 GAN ( <a class="ae le" href="https://pixabay.com/photos/fashion-show-fashion-catwalk-model-1746610/" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><h2 id="ce7c" class="ly lz it bd ma mb mc dn md me mf dp mg kr mh mi mj kv mk ml mm kz mn mo mp mq bi translated">第 6 步将预测和图像传递给 DCGAN 进行生成</h2><figure class="na nb nc nd gt ne gh gi paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><div class="gh gi oa"><img src="../Images/3941c9fd58c007f61cd6056bee21becb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2-DBAZkDLBOR06V9"/></div></div><p class="nv nw gj gh gi nx ny bd b be z dk translated">DCGAN 架构(<a class="ae le" href="https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="8e96" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们终于有了高质量的服装图像，我们可以开始构建 DCGAN 模型了！</p><p id="1301" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="ob">注意:代码基于 Pytorch 的官方 DCGAN 教程，您可以从这里的</em> <a class="ae le" href="https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html" rel="noopener ugc nofollow" target="_blank"> <em class="ob">访问</em> </a> <em class="ob">。代码就不解释太详细了，更详细的解释可以参考教程。</em></p><p id="b0bc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们开始吧。首先，我们必须导入所有必需的库:</p><figure class="na nb nc nd gt ne"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="510c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来，我们设置稍后需要的所有变量:</p><figure class="na nb nc nd gt ne"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="af1c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">设置完变量后，我们现在创建数据集和数据加载器，稍后我们将把它们输入到模型中。我们调整图像的大小，将它们居中裁剪到所需的图像大小，并使它们正常化。我们的图像尺寸设置为 64，因为较小的尺寸通常更一致。</p><figure class="na nb nc nd gt ne"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="8e56" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们还绘制了一些训练图像来可视化:</p><figure class="na nb nc nd gt ne gh gi paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><div class="gh gi oa"><img src="../Images/6c25801a784091a56bf84ad8aed246ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8k_uaU6cjJ2LM3ojr0OyLQ.png"/></div></div><p class="nv nw gj gh gi nx ny bd b be z dk translated">样本训练图像</p></figure><p id="081f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">之后，我们定义了生成器上的权重初始化和待构建的鉴别器:</p><figure class="na nb nc nd gt ne"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="a10c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们制造发电机:</p><figure class="na nb nc nd gt ne"><div class="bz fp l di"><div class="nf ng l"/></div></figure><figure class="na nb nc nd gt ne gh gi paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><div class="gh gi oc"><img src="../Images/f79e5090d42e3c42ded1f13b97ef1757.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zD33XzTns79vCkGF7AyXOA.png"/></div></div><p class="nv nw gj gh gi nx ny bd b be z dk translated">发电机架构</p></figure><p id="3944" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">还有鉴别器！</p><figure class="na nb nc nd gt ne"><div class="bz fp l di"><div class="nf ng l"/></div></figure><figure class="na nb nc nd gt ne gh gi paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><div class="gh gi od"><img src="../Images/0de3f1f33e73faadbe2e106965b606ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dwoM9KEQVepATF21NrhLhA.png"/></div></div><p class="nv nw gj gh gi nx ny bd b be z dk translated">鉴别器架构</p></figure><p id="f499" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后我们定义培训流程。我们使用 BCELoss 函数，因为鉴别器的工作是识别图像是真是假。我们为生成器和鉴别器设置了 Adam 优化器。然后，我们逐批更新两个网络:</p><figure class="na nb nc nd gt ne"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="1f63" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这将开始培训过程。输出是:</p><figure class="na nb nc nd gt ne gh gi paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><div class="gh gi oe"><img src="../Images/a352f8c0c5a5fbced7a5f8b12f7acd7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*euoWwPzolT9ayE7XQkOR3A.png"/></div></div><p class="nv nw gj gh gi nx ny bd b be z dk translated">培训产出</p></figure><p id="7158" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">培训过程需要一段时间。训练后，我们可以绘制训练期间的发生器和鉴频器损耗:</p><figure class="na nb nc nd gt ne"><div class="bz fp l di"><div class="nf ng l"/></div></figure><figure class="na nb nc nd gt ne gh gi paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><div class="gh gi of"><img src="../Images/056669155bc1c68d584b00f1d77d35ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a36Pjm58HO0bbJ450LawYQ.png"/></div></div><p class="nv nw gj gh gi nx ny bd b be z dk translated">生成器和鉴别器训练损失与迭代</p></figure><p id="8c45" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">完成所有这些工作后，这是最后一步——将图像保存到本地硬盘:</p><figure class="na nb nc nd gt ne"><div class="bz fp l di"><div class="nf ng l"/></div></figure><h1 id="19a1" class="og lz it bd ma oh oi oj md ok ol om mg jz on ka mj kc oo kd mm kf op kg mp oq bi translated">结果</h1><p id="57e2" class="pw-post-body-paragraph ki kj it kk b kl mr ju kn ko ms jx kq kr mt kt ku kv mu kx ky kz mv lb lc ld im bi translated">最后，伙计们，在所有这些工作之后！<strong class="kk iu">我们将看到生成的结果</strong>:</p><figure class="na nb nc nd gt ne gh gi paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><div class="gh gi or"><img src="../Images/f509b23215c375b72ac60121c021f7c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*JN7UPRiRPFjiItGU"/></div></div><p class="nv nw gj gh gi nx ny bd b be z dk translated">DCGAN 生成的图像！</p></figure><p id="40fe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，我们可以并排绘制并比较数据集的真实图像和生成的图像。</p><figure class="na nb nc nd gt ne"><div class="bz fp l di"><div class="nf ng l"/></div></figure><figure class="na nb nc nd gt ne gh gi paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><div class="gh gi os"><img src="../Images/be6ac6f842d3788cd687e5a307ecec3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gle59dT66PCmCch1GFo2Dg.png"/></div></div><p class="nv nw gj gh gi nx ny bd b be z dk translated">真实服装和生成的服装的并排比较</p></figure><p id="512b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">不错吧？假图像与真实图像相差不远。<strong class="kk iu">事实上，有些在我眼里看起来相当时尚</strong>😁。</p><p id="93f7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">就是这样，伙计们！希望你们都喜欢我的文章，并希望再次见到你。同样，本文中显示的全部代码以及我写的<a class="ae le" href="https://github.com/itsuncheng/DeepStyle/blob/master/full_paper.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>可以在<a class="ae le" href="https://github.com/itsuncheng/DeepStyle" rel="noopener ugc nofollow" target="_blank">我的 github repo </a>中获得！如果你喜欢我的内容，请在 Medium 上关注我，我会定期发布关于深度学习的话题！</p><h1 id="ba88" class="og lz it bd ma oh oi oj md ok ol om mg jz on ka mj kc oo kd mm kf op kg mp oq bi translated">参考</h1><div class="lf lg gp gr lh li"><a href="https://github.com/facebookresearch/Detectron" rel="noopener  ugc nofollow" target="_blank"><div class="lj ab fo"><div class="lk ab ll cl cj lm"><h2 class="bd iu gy z fp ln fr fs lo fu fw is bi translated">Facebook 研究/检测</h2><div class="lp l"><h3 class="bd b gy z fp ln fr fs lo fu fw dk translated">Detectron 已被弃用。请参阅 detectron2，这是 PyTorch 中 detectron 的全新重写版本。侦探是脸书·艾…</h3></div><div class="lq l"><p class="bd b dl z fp ln fr fs lo fu fw dk translated">github.com</p></div></div><div class="lr l"><div class="ot l lt lu lv lr lw lx li"/></div></div></a></div><div class="lf lg gp gr lh li"><a href="https://arxiv.org/abs/1506.01497" rel="noopener  ugc nofollow" target="_blank"><div class="lj ab fo"><div class="lk ab ll cl cj lm"><h2 class="bd iu gy z fp ln fr fs lo fu fw is bi translated">更快的 R-CNN:用区域提议网络实现实时目标检测</h2><div class="lp l"><h3 class="bd b gy z fp ln fr fs lo fu fw dk translated">最先进的目标检测网络依靠区域提议算法来假设目标位置…</h3></div><div class="lq l"><p class="bd b dl z fp ln fr fs lo fu fw dk translated">arxiv.org</p></div></div></div></a></div><div class="lf lg gp gr lh li"><a href="http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html" rel="noopener  ugc nofollow" target="_blank"><div class="lj ab fo"><div class="lk ab ll cl cj lm"><h2 class="bd iu gy z fp ln fr fs lo fu fw is bi translated">深度时尚数据库</h2><div class="lp l"><h3 class="bd b gy z fp ln fr fs lo fu fw dk translated">我们贡献了 DeepFashion 数据库，一个大规模的服装数据库，它有几个吸引人的特性:首先…</h3></div><div class="lq l"><p class="bd b dl z fp ln fr fs lo fu fw dk translated">mmlab.ie.cuhk.edu.hk</p></div></div><div class="lr l"><div class="ou l lt lu lv lr lw lx li"/></div></div></a></div><div class="lf lg gp gr lh li"><a href="https://cocodataset.org/#home" rel="noopener  ugc nofollow" target="_blank"><div class="lj ab fo"><div class="lk ab ll cl cj lm"><h2 class="bd iu gy z fp ln fr fs lo fu fw is bi translated">COCO -上下文中的常见对象</h2><div class="lp l"><h3 class="bd b gy z fp ln fr fs lo fu fw dk translated">编辑描述</h3></div><div class="lq l"><p class="bd b dl z fp ln fr fs lo fu fw dk translated">cocodataset.org</p></div></div><div class="lr l"><div class="ov l lt lu lv lr lw lx li"/></div></div></a></div><div class="lf lg gp gr lh li"><a href="https://arxiv.org/abs/1511.06434" rel="noopener  ugc nofollow" target="_blank"><div class="lj ab fo"><div class="lk ab ll cl cj lm"><h2 class="bd iu gy z fp ln fr fs lo fu fw is bi translated">深度卷积生成对抗网络的无监督表示学习</h2><div class="lp l"><h3 class="bd b gy z fp ln fr fs lo fu fw dk translated">近年来，卷积网络的监督学习(CNN)在计算机视觉领域得到了广泛应用…</h3></div><div class="lq l"><p class="bd b dl z fp ln fr fs lo fu fw dk translated">arxiv.org</p></div></div></div></a></div><div class="lf lg gp gr lh li"><a href="https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html" rel="noopener  ugc nofollow" target="_blank"><div class="lj ab fo"><div class="lk ab ll cl cj lm"><h2 class="bd iu gy z fp ln fr fs lo fu fw is bi translated">DCGAN 教程- PyTorch 教程 1.5.1 文档</h2><div class="lp l"><h3 class="bd b gy z fp ln fr fs lo fu fw dk translated">本教程将通过一个例子对 DCGANs 进行介绍。我们将训练一个生成性的对抗网络…</h3></div><div class="lq l"><p class="bd b dl z fp ln fr fs lo fu fw dk translated">pytorch.org</p></div></div></div></a></div></div></div>    
</body>
</html>