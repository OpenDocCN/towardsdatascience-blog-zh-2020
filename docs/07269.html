<html>
<head>
<title>Using a Neural Network to Predict Voter Preferences</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用神经网络来预测选民的偏好</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-a-neural-network-to-predict-voter-preferences-ccb9122a6df1?source=collection_archive---------44-----------------------#2020-06-02">https://towardsdatascience.com/using-a-neural-network-to-predict-voter-preferences-ccb9122a6df1?source=collection_archive---------44-----------------------#2020-06-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/75d0b5a8ac58048c0be2dee5953b919e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EYH52eXcAk3NHTVkqU0VwQ.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">由<a class="ae kc" href="https://unsplash.com/@element5digital?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">元素 5 数码</a>在<a class="ae kc" href="https://unsplash.com/s/photos/election?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="c309" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">随着总统选举的临近，政治分析师、预测者和其他利益相关方正在努力对选举结果做出最佳估计。传统上，民意调查被用来衡量政治候选人的受欢迎程度，但计算能力的提高和强大统计方法的发展为他们提供了一个有趣的替代选择。开始预测选举的一个好地方是首先预测选民的政治偏好。这就是我们将要做的。</p><p id="62a0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本文中，我们将在 R 中构建一个简单的神经网络来预测美国选民的偏好。</p><p id="de7a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将使用 Keras 来实现这一点，这是一个令人惊叹的开源 API，它允许您以简单而强大的方式运行神经网络模型。虽然它是在 Python 中本地运行的，但是 RStudio 已经开发了一个允许与 r 无缝集成的包。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><p id="a8ab" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我们开始之前，请确保您已经安装了以下 R 包，因为我们将使用它们来执行我们的预测:</p><pre class="li lj lk ll gt lm ln lo lp aw lq bi"><span id="2995" class="lr ls iq ln b gy lt lu l lv lw">install.packages("keras")<br/>install.packages("tidyr")<br/>install.packages("ggplot2")<br/>install.packages("dplyr")<br/>install.packages("fastDummies")</span></pre><p id="1d67" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">数据</strong></p><p id="691a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">用于训练神经网络的数据来自 2018 年合作国会选举研究，由 YouGov 管理。它由 Kuriwaki (2018)编制，并从哈佛数据节中提取。您可以在中下载这些数据。Rds 文件格式为 2006–2018 年<a class="ae kc" href="https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi%3A10.7910/DVN/II2DB6" rel="noopener ugc nofollow" target="_blank">此处</a>。</p><p id="250f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">假设您下载了文件并将其放在工作目录中，我们可以继续导入数据并查看其结构:</p><pre class="li lj lk ll gt lm ln lo lp aw lq bi"><span id="7f35" class="lr ls iq ln b gy lt lu l lv lw">d &lt;- readRDS("cumulative_2006_2018.Rds")<br/>dim(d)</span><span id="3542" class="lr ls iq ln b gy lx lu l lv lw">[1] 452755     73</span></pre><p id="7eb5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe ly lz ma ln b">d</code>是具有 452，755 行(观察值)和 73 列(特征)的数据帧。这些特征包括地理、人口和经济变量，以及其他有趣的变量，如政治认可和新闻兴趣水平。当然，它们也包括每个个人的总统投票选择。这最后一个变量将是我们的因变量，例如，我们将使用我们的模型预测什么。最后，在前面提到的数据集源链接中提供了每个变量的详细解释。</p><p id="d668" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于我们有 2006 年至 2008 年的数据，让我们过滤<code class="fe ly lz ma ln b">d</code>以仅选择 2018 年(最近一次调查的年份)的回答:</p><pre class="li lj lk ll gt lm ln lo lp aw lq bi"><span id="078b" class="lr ls iq ln b gy lt lu l lv lw">dd &lt;- d %&gt;%<br/>  filter(year == 2018)</span></pre><p id="ab29" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，让我们只选择我们的模型感兴趣的变量，并排除丢失的值:</p><pre class="li lj lk ll gt lm ln lo lp aw lq bi"><span id="f9c9" class="lr ls iq ln b gy lt lu l lv lw">dd &lt;- dd %&gt;%<br/>  select(st, dist, cong, # geography<br/>         gender, birthyr, age, educ, <br/>         race, faminc, marstat, # demographics<br/>         newsint, # news interest<br/>         approval_pres, # approval<br/>         ideo5, # ideology<br/>         voted_pres_16 # presidential vote<br/>  )<br/>dd &lt;- dd[complete.cases(dd),]</span></pre><p id="5b80" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该数据框如下所示:</p><figure class="li lj lk ll gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mb"><img src="../Images/9931bd492b6ea1c0064742b6c77f41cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V5CjvTp42QzsQlvagHNnvw.png"/></div></div></figure><p id="af1c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下表列出了各类选民偏好的受访者人数(变量<code class="fe ly lz ma ln b">voted_pres_16</code>)。可以看出，大约 88%的受访者投票给唐纳德·特朗普或希拉里·克林顿，9.91%的人投票给另一位候选人，大约 1.3%的人没有透露他们的偏好或没有投票。</p><figure class="li lj lk ll gt jr gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/48d879a789c44fb0ccb8330911317015.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*pVLBIUOw_EnErrgDhdRppQ.png"/></div></figure><p id="a1a8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">回到我们的数据集<code class="fe ly lz ma ln b">dd</code>，排除变量<code class="fe ly lz ma ln b">age</code>，我们所有的特征都是分类的。因此，我们需要一次性将这些变量编码成虚拟变量。有很多包和函数可以做到这一点，但是这里我们将使用<code class="fe ly lz ma ln b">fastDummies</code>包中的函数<code class="fe ly lz ma ln b">dummy_cols</code>。</p><pre class="li lj lk ll gt lm ln lo lp aw lq bi"><span id="1ea7" class="lr ls iq ln b gy lt lu l lv lw">cat_vars &lt;- colnames(dd)<br/>cat_vars &lt;- cat_vars[!cat_vars %in% c("age","voted_pres_16")]<br/>all_data &lt;- dummy_cols(dd,<br/>                 select_columns = cat_vars,<br/>                 remove_first_dummy = TRUE,<br/>                 remove_selected_columns = TRUE)</span></pre><p id="a549" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们还将我们的因变量<code class="fe ly lz ma ln b">voted_pres_16</code>转换为每个候选项的整数(从零开始)的数字向量，并从我们的数据帧中移除变量<code class="fe ly lz ma ln b">voted_pres_16</code>:</p><pre class="li lj lk ll gt lm ln lo lp aw lq bi"><span id="52aa" class="lr ls iq ln b gy lt lu l lv lw">all_labels &lt;- dd$voted_pres_16 %&gt;%<br/>  as.factor() %&gt;%<br/>  unclass() - 1</span><span id="4161" class="lr ls iq ln b gy lx lu l lv lw">all_data &lt;- all_data %&gt;%<br/>  select(-voted_pres_16) %&gt;%<br/>  as.matrix()</span></pre><p id="d08a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，我们将我们的数据分成一个训练集(90%)和一个测试集(10%)，这样在我们训练完我们的模型后，我们可以在“新”数据上测试它的性能。</p><pre class="li lj lk ll gt lm ln lo lp aw lq bi"><span id="9d7f" class="lr ls iq ln b gy lt lu l lv lw">party_levels &lt;- levels(all_labels)<br/>elems &lt;- sample(1:nrow(all_data),<br/>                round(0.1*nrow(all_data)),<br/>                replace = F)</span><span id="e9d1" class="lr ls iq ln b gy lx lu l lv lw"># training data<br/>train_data &lt;- all_data[-elems,]<br/>train_labels &lt;- all_labels[-elems]</span><span id="5644" class="lr ls iq ln b gy lx lu l lv lw">levels(train_labels) &lt;- levels(all_labels)</span><span id="a18f" class="lr ls iq ln b gy lx lu l lv lw"># test data<br/>test_data &lt;- all_data[elems,]<br/>test_labels &lt;- all_labels[elems]</span><span id="f02f" class="lr ls iq ln b gy lx lu l lv lw">levels(test_labels) &lt;- party_levels</span></pre><p id="b9aa" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">建立模型</strong></p><p id="476e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们手头的问题被建模为分类问题，其中表 1 中的每个候选代表一个分类类别(总共 5 个类别)。输入层被格式化，使得 148 个解释变量中的每一个都馈入输入层的一个神经元。这些神经元然后连接到隐藏层中的其他神经元。在这个例子中，我们为隐藏层使用了 100 个神经元。最后，输出层有 5 个单元，每个类别一个。图 1 包含了这个神经网络的图形描述。</p><figure class="li lj lk ll gt jr gh gi paragraph-image"><div class="gh gi md"><img src="../Images/d5f12f07275904426a1dbc7117b0479e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/1*WkrCMzk69cWhnOvHUEhLVQ.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图一。我们神经网络的代表</p></figure><p id="a5d4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，我们定义我们的模型:</p><pre class="li lj lk ll gt lm ln lo lp aw lq bi"><span id="ec50" class="lr ls iq ln b gy lt lu l lv lw"># Define model<br/>model &lt;- keras_model_sequential()<br/>model %&gt;%<br/>  layer_dense(units = 100, activation = "relu",<br/>              input_shape = dim(train_data)[2]) %&gt;%<br/>  layer_dense(units = length(party_levels), activation = 'softmax') </span></pre><p id="40fb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第一阶段(输入到隐藏层)的激活函数是整流线性单位，或 ReLu，而第二阶段(隐藏到输出层)的激活函数是 softmax。</p><p id="5365" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在开始编译和训练模型。我们将在这里使用的优化算法是<em class="me"> adam </em>，这是一种自适应优化算法，通常用于训练深度神经网络。使用的损失函数是<em class="me">稀疏分类交叉熵。</em>最后，我们将为模型获取大约 20%的训练数据，以迭代计算验证误差。</p><pre class="li lj lk ll gt lm ln lo lp aw lq bi"><span id="87e8" class="lr ls iq ln b gy lt lu l lv lw">###### Compile the model ######<br/>model %&gt;% compile(<br/>  optimizer = 'adam', <br/>  loss = 'sparse_categorical_crossentropy',<br/>  metrics = c('accuracy')<br/>)</span><span id="3217" class="lr ls iq ln b gy lx lu l lv lw">###### Train the Model #####<br/>early_stop &lt;- callback_early_stopping(monitor = "val_loss", <br/>                                      patience = 20)</span><span id="8504" class="lr ls iq ln b gy lx lu l lv lw">model %&gt;% fit(train_data, <br/>              train_labels,<br/>              validation_split = 1/5,<br/>              callbacks = list(early_stop),<br/>              epochs = 500)</span></pre><p id="220f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上述算法将适合我们的神经网络 500 个时期，如果测试模型性能在 20 个连续时期内没有增加，它将在此之前停止。</p><p id="f62e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">车型性能</strong></p><p id="7be6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">训练完我们的模型后，我们希望通过预测和查看模型性能，使用我们的测试数据对其进行评估:</p><pre class="li lj lk ll gt lm ln lo lp aw lq bi"><span id="1753" class="lr ls iq ln b gy lt lu l lv lw">###### Evaluate Model ######<br/>score &lt;- model %&gt;% evaluate(test_data, test_labels, verbose = 0)</span><span id="7971" class="lr ls iq ln b gy lx lu l lv lw">cat('Test loss:', score$loss, "\n")<br/>cat('Test accuracy:', score$acc, "\n")</span></pre><figure class="li lj lk ll gt jr gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/c5aca98b5e7c5d9d6b161b7f88fe2ad3.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*9B92e_tXAApREw0mmX4HbA.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">模型性能</p></figure><p id="912d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">测试损耗和准确度分别为 0.4882 和 0.8461！还不错！</p><p id="13c7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">尽管如此，我们现在想看看我们的模型失败了。图 2 详细展示了该模型的性能。</p><figure class="li lj lk ll gt jr gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/a4d9ac10a6b5f2854352db04f061d4af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*fn7YmCx0v2vhUCYyFUxwEQ.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图二。混淆矩阵</p></figure><p id="1a34" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上面的图像包含了我们模型性能的混淆矩阵。正确的分类率(对角线上的高精度和非对角线上的低值)显示为绿色，而不正确的分类率(对角线上的低值和非对角线上的高值)显示为红色。</p><p id="a2ba" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对混淆矩阵的仔细观察表明，该模型没有对“没有投票”和“不确定/不记得”的类别做出正确的预测。这是因为相对于其他类别而言，属于这些类别的意见数量较少:回答“没有投票”或“不确定/不记得”的受访者数量分别仅占总样本的 0.86%和 0.43%(表 1)。因此，为了准确地预测这些类别，需要更多的信息:为了知道回答者<em class="me">是否没有投票给</em>或者他们<em class="me">是否不记得他们投票给了</em>，仅仅知道投票者的政治和意识形态偏好是不够的。</p><p id="282e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，似乎令人惊讶的是，该模型在将投票者分配到“其他”类别时表现非常差(非常差的 14.1%的准确率)。由于所有观测值中约有 9.91%属于这一类(见表 1)，情况尤其如此。尽管如此，重要的是要注意到这一类别包括非常多样化的总统候选人，如加里·约翰逊(自由党)和吉尔·斯坦(绿党)。这些候选人有着不同的政治意识形态，代表着选民偏好和人口统计数据的混杂。因此，我们可能会认为，实际上可以预期，该模型无法准确预测任何属于这一类别的总统候选人的选票。</p><p id="5d8a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以，我们建立了一个预测选民偏好的模型。我们如何预测选举的结果？</p><p id="1607" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是一个非常困难的任务，超出了本文的范围，但一个好的开始是用民意调查数据训练我们在这里开发的模型，并使用来自选民名册的数据来预测给定州或整个美国人口的政治偏好。</p><p id="ffb8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我希望你喜欢这篇文章，如果你喜欢，请告诉我！</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><p id="d488" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Kuriwaki，Shiro，2018，“累积 CCES 共同内容(2006–2018)”，【https://doi.org/10.7910/DVN/II2DB6】T4，哈佛数据节，V4</p></div></div>    
</body>
</html>