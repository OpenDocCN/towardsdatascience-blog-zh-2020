<html>
<head>
<title>Submitted Solution for Kaggle COVID-19 Open Research Dataset Challenge (CORD-19)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卡格尔·新冠肺炎公开研究数据集挑战赛(CORD-19)提交的解决方案</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/submitted-solution-for-kaggle-covid-19-open-research-dataset-challenge-cord-19-138eced43985?source=collection_archive---------49-----------------------#2020-07-13">https://towardsdatascience.com/submitted-solution-for-kaggle-covid-19-open-research-dataset-challenge-cord-19-138eced43985?source=collection_archive---------49-----------------------#2020-07-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="1647" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这篇文章描述了为 Kaggle CORD-19 竞赛提交的解决方案。</p><p id="1050" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae kl" href="http://towardsdatascience.com/" rel="noopener" target="_blank"> <em class="km">迈向数据科学</em> </a> <em class="km">是一份以研究数据科学和机器学习为主的媒体刊物。我们不是健康专家，这篇文章的观点不应被解释为专业建议。</em></p><h1 id="aea9" class="kn ko iq bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk bi translated">CORD-19 竞赛说明</h1><p id="f8d4" class="pw-post-body-paragraph jn jo iq jp b jq ll js jt ju lm jw jx jy ln ka kb kc lo ke kf kg lp ki kj kk ij bi translated">2020 年 3 月 17 日，随着全球新冠肺炎封锁的开始，Kaggle 宣布与艾伦人工智能研究所合作举办<a class="ae kl" href="https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge" rel="noopener ugc nofollow" target="_blank">新冠肺炎开放研究数据集挑战赛(CORD-19) </a>比赛，并与 Chan Zuckerberg Initiative、乔治敦大学安全和新兴技术中心、微软研究院、IBM 和国家医学图书馆-国家卫生研究院合作，并与白宫科技政策办公室协调。</p><h2 id="4d87" class="lq ko iq bd kp lr ls dn kt lt lu dp kx jy lv lw lb kc lx ly lf kg lz ma lj mb bi translated">CORD-19 数据集</h2><p id="df31" class="pw-post-body-paragraph jn jo iq jp b jq ll js jt ju lm jw jx jy ln ka kb kc lo ke kf kg lp ki kj kk ij bi translated">CORD-19 数据集是一个开放的资源，包含超过 167，000 篇关于新冠肺炎、新型冠状病毒和相关冠状病毒的学术文章(随着时间的推移逐渐增加)，由上述六位合作者创建。这些文章代表了迄今为止可用于数据挖掘的最广泛的机器可读冠状病毒文献集合。由于冠状病毒文献的快速增加，对这些方法的需求越来越迫切，使得医学界难以跟上。数据集也可以在<a class="ae kl" href="https://pages.semanticscholar.org/coronavirus-research" rel="noopener ugc nofollow" target="_blank">语义学者</a>上找到。</p><p id="9fa1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">竞赛的目的是为世界人工智能专家和 NLP 社区提供一个机会，开发文本和数据挖掘工具，帮助医疗界找到高优先级科学问题的答案，并将这些内容的见解联系起来，以支持全球范围内正在进行的新冠肺炎响应工作。</p><p id="f05e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">比赛分两轮进行，最初的关键问题列表选自 NASEM 的 SCIED(国家科学院、工程和医学委员会关于新出现的传染病和 21 世纪健康威胁的常务委员会)<a class="ae kl" href="https://www.nationalacademies.org/event/03-11-2020/standing-committee-on-emerging-infectious-diseases-and-21st-century-health-threats-virtual-meeting-1" rel="noopener ugc nofollow" target="_blank">研究主题</a>和世界卫生组织为新冠肺炎制定的<a class="ae kl" href="https://www.who.int/blueprint/priority-diseases/key-action/Global_Research_Forum_FINAL_VERSION_for_web_14_feb_2020.pdf?ua=1" rel="noopener ugc nofollow" target="_blank">研发蓝图</a>。</p><p id="fea5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第一轮截止日期为 2020 年 4 月 16 日，包括以下主题的 9 项任务:</p><ol class=""><li id="e208" class="mc md iq jp b jq jr ju jv jy me kc mf kg mg kk mh mi mj mk bi translated">关于传播、潜伏期和环境稳定性，我们知道些什么？</li><li id="ba5a" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated">我们对新冠肺炎风险因素了解多少？</li><li id="7e90" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated">我们对疫苗和疗法了解多少？</li><li id="a5ad" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated">我们对病毒遗传学、起源和进化了解多少？</li><li id="8dfb" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated">关于医疗保健已经发表了什么？</li><li id="a436" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated">关于伦理和社会科学的考虑已经发表了什么</li><li id="07f4" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated">我们对非药物干预了解多少？</li><li id="ea82" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated">我们对诊断和监控了解多少？</li><li id="369c" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated">关于信息共享和跨部门协作，已经发表了哪些内容？</li></ol><p id="b86e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第二轮截止日期为 2020 年 6 月 16 日，包括以下主题的 8 项任务:</p><ol class=""><li id="80d4" class="mc md iq jp b jq jr ju jv jy me kc mf kg mg kk mh mi mj mk bi translated">创建处理与新冠肺炎相关的因素的汇总表</li><li id="6fe9" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated">创建治疗、干预和临床研究的汇总表</li><li id="f005" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated">创建汇总表，说明与新冠肺炎相关的风险因素</li><li id="b1da" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated">创建用于新冠肺炎诊断的汇总表(提交的解决方案)</li><li id="688c" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated">创建与新冠肺炎相关的材料研究汇总表</li><li id="55f8" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated">创建汇总表，说明与新冠肺炎相关的模型和未决问题</li><li id="c114" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated">创建处理与新冠肺炎相关的人口研究的汇总表</li><li id="e1c7" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated">创建处理与新冠肺炎相关的患者描述的汇总表</li></ol></div><div class="ab cl mq mr hu ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="ij ik il im in"><h1 id="bd13" class="kn ko iq bd kp kq mx ks kt ku my kw kx ky mz la lb lc na le lf lg nb li lj lk bi translated">已提交的诊断类别解决方案:</h1><p id="7d60" class="pw-post-body-paragraph jn jo iq jp b jq ll js jt ju lm jw jx jy ln ka kb kc lo ke kf kg lp ki kj kk ij bi translated">在第一轮中，大多数提交的文章展示了分析和分类文章类型和摘要内容的各种解决方案。第 2 轮的任务主要集中在 NLP 的“信息提取”技术上，这意味着解决方案必须回答特定的问题或检索与 COVID 相关的特定搜索查询的相关信息。参与者被要求提供 CSV 格式的文章汇总表，并保存到 Kaggle 笔记本的输出文件夹中。的。CSV 文件应包含符合表格格式的汇总表，表格格式在标题为<code class="fe nc nd ne nf b">target_table</code>的文件夹中有描述和演示。我提交的材料涉及任务 4，新冠肺炎的诊断。</p><p id="5334" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了完成上述任务，我决定从文章的<strong class="jp ir">正文</strong>中提取相关信息，而不是摘要，因为这种信息可能不会在那个级别提供，而且许多文章没有摘要。</p><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/31a3886b06cb69d79d5c3e42d78565c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:718/format:webp/1*0Pqyit-D3Q3v2u2w8N3s3A.png"/></div><p class="no np gj gh gi nq nr bd b be z dk translated"><strong class="bd ns">图 1:1000 篇净身文章的文字分布</strong></p></figure><p id="23a7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然而，从正文中提取相关信息的挑战是从提供的文章正文中找到包含相关信息的正确的文本片段。图 1 显示了 1000 篇文章的单词分布，这些文章的正文被清除了停用词。超过 95%的文章平均包含 5000 个单词。因此，找到每篇文章中最相似的句子是至关重要的。</p><p id="53fb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，我分三个阶段设计了一个解决方案(见图 2):</p><ul class=""><li id="0e2f" class="mc md iq jp b jq jr ju jv jy me kc mf kg mg kk nt mi mj mk bi translated"><strong class="jp ir">阶段 1 </strong>加载数据并预处理两个数据集的句子:诊断任务和 Kaggle 文章。</li><li id="fa42" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk nt mi mj mk bi translated"><strong class="jp ir">第二阶段</strong>计算任务句和文章正文句的 Word2Vec 句子相似度，选出排名靠前的句子。</li><li id="4166" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk nt mi mj mk bi translated"><strong class="jp ir">阶段 3 </strong>对排名靠前的句子应用 BERT 预训练问答模型，以找到汇总表查询的准确答案。</li></ul><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi nu"><img src="../Images/195660ce32a8ee3f99e4c870c9fed70f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AkmC68SC6exIosAGGbl-HQ.png"/></div></div><p class="no np gj gh gi nq nr bd b be z dk translated">图 2:提交的解决方案概述(3 个阶段)</p></figure><h2 id="f7f9" class="lq ko iq bd kp lr ls dn kt lt lu dp kx jy lv lw lb kc lx ly lf kg lz ma lj mb bi translated"><strong class="ak">环境设置:</strong></h2><p id="af32" class="pw-post-body-paragraph jn jo iq jp b jq ll js jt ju lm jw jx jy ln ka kb kc lo ke kf kg lp ki kj kk ij bi translated">Kaggle 为参与者提供了一个 jupyter 笔记本电脑环境，容量为 10 个 CPU，1 个 GPU，最大 5 GB 磁盘和 16 GB RAM。为了参加竞赛，你需要公开你的私人笔记本。为了这次提交，我在 Kaggle notebook 中开发了我的代码，这些代码可以在我的公共<a class="ae kl" href="https://github.com/LidaGh/Submitted_Kaggle_CORD_19_Word2Vec_BERT_QA_Diagnostics_Task" rel="noopener ugc nofollow" target="_blank"> github </a>库中找到。</p><p id="f94b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="km">然而，由于在 Kaggle 笔记本上安装变压器的容量问题，我不得不在 azure data science Linux 虚拟机上运行部分代码。</em></p><h2 id="2ed2" class="lq ko iq bd kp lr ls dn kt lt lu dp kx jy lv lw lb kc lx ly lf kg lz ma lj mb bi translated">阶段 1:数据加载和预处理:</h2><p id="7ccd" class="pw-post-body-paragraph jn jo iq jp b jq ll js jt ju lm jw jx jy ln ka kb kc lo ke kf kg lp ki kj kk ij bi translated">与数据集相关联的元数据如下:</p><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi nz"><img src="../Images/404478ef33e4926ae59273d13b031057.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4CndUoOHzTFS_GOp1ham6A.png"/></div></div></figure><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oa"><img src="../Images/0fa1ead961634de9b89d8b1a8a90870a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Viv8FDfeDNKRNWKcoJ4Nqw.png"/></div></div></figure><p id="c96e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意，在撰写这篇博客时，上面的数字与实际的数据集并不匹配。</p><p id="6e74" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从 Kaggle 输入目录加载数据后，生成一个字典来提取结合元数据和 json 文件内容的汇总表所需的列，如下所示:</p><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi ob"><img src="../Images/9cc9aa8abf969aecfd0ade6eef24d67d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CMamo285MG8joIhVELG4hw.png"/></div></div></figure><p id="811d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">准备 Kaggle 数据集:</strong></p><p id="d216" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦所有的数据都被加载，我在第二阶段和第三阶段将数据二次抽样到“paper_id”、“abstract”和“body”中。然后，最终结果在“paper_id”上与原始数据集合并。</p><p id="4dec" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">开发了一系列函数来实现预处理步骤:</p><ul class=""><li id="d0a7" class="mc md iq jp b jq jr ju jv jy me kc mf kg mg kk nt mi mj mk bi translated">使用 NLTK 英语标记器将文章的正文分成句子，该标记器通过应用词性标记来识别句子。</li><li id="3223" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk nt mi mj mk bi translated">小写所有的单词</li><li id="e9ab" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk nt mi mj mk bi translated">去掉标点符号</li><li id="f28c" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk nt mi mj mk bi translated">标记所有的句子</li></ul><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oc"><img src="../Images/ce8a58f5e91da15dd500597e15669c41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Paz7fdjTimJ_akGoQ1kW-w.png"/></div></div></figure><p id="0ceb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Kaggle 数据集的第一阶段的结果是句子及其干净标记的熊猫数据框架。</p><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi od"><img src="../Images/d681ec829c43cbbeafcc6f2ab03c5cd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*218smDGvpFoZOcebzJYbhg.png"/></div></div></figure><p id="e7a0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">准备任务数据集:</strong></p><p id="9909" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如前所述，对于 CORD-19 Kaggle 提交，选择了第 2 轮的任务 4，并准备了以下数据集:</p><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oe"><img src="../Images/cbe6666822048ce6f2bc37082972fe52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SDVlk8x-2f0EAh4_svyfQA.png"/></div></div></figure><h2 id="c23c" class="lq ko iq bd kp lr ls dn kt lt lu dp kx jy lv lw lb kc lx ly lf kg lz ma lj mb bi translated">阶段 2:应用句子相似度</h2><p id="bbda" class="pw-post-body-paragraph jn jo iq jp b jq ll js jt ju lm jw jx jy ln ka kb kc lo ke kf kg lp ki kj kk ij bi translated">在这个阶段，我在 Kaggle 的句子和任务数据集之间应用了句子相似性技术，如下所示。</p><p id="e725" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">句子相似度</strong>或<strong class="jp ir">语义文本相似度</strong>是衡量两段文本有多相似，或者它们表达相同意思的程度。相关任务包括释义或重复识别、搜索和匹配应用程序。用于文本相似性的常用方法从<strong class="jp ir">简单的词向量</strong>点积到<strong class="jp ir">成对分类</strong>，以及最近的<strong class="jp ir">深度神经网络</strong>。</p><p id="009b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">句子相似度通常通过以下两个步骤计算:</p><ol class=""><li id="d480" class="mc md iq jp b jq jr ju jv jy me kc mf kg mg kk mh mi mj mk bi translated">获得句子的嵌入</li><li id="e672" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated">取它们之间的余弦相似度如下图所示:</li></ol><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi of"><img src="../Images/5f83fd7330e339eb885bcd905d80eed6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cBLomt7la5i2yREwVH9_kw.png"/></div></div><p class="no np gj gh gi nq nr bd b be z dk translated">图 3: <a class="ae kl" href="https://tfhub.dev/google/universal-sentence-encoder/4" rel="noopener ugc nofollow" target="_blank">资料来源:通用语句编码器</a></p></figure><p id="06b5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> Word2vec </strong>是一个用于从文本中学习单词嵌入的预测模型，由 Google research 于 2013 年推出<a class="ae kl" href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="df11" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">简而言之，<strong class="jp ir">单词嵌入</strong>是将单词表示成向量的一种方式，即语料库中有共同上下文的单词在向量空间中会靠得很近，如男-女、国王-王后等。</p><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi og"><img src="../Images/70acedde766255842350113467c63b64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sXNXYfAqfLUeiDXPCo130w.png"/></div></div><p class="no np gj gh gi nq nr bd b be z dk translated">图 4: <a class="ae kl" href="https://www.tensorflow.org/images/linear-relationships.png" rel="noopener ugc nofollow" target="_blank">来源:可视化单词向量</a></p></figure><p id="c853" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有两种不同的模型架构可用于产生 word2vec 嵌入:<strong class="jp ir">连续词袋(CBOW) </strong>或<strong class="jp ir">连续跳格。</strong>前者使用周围单词的窗口(“上下文”)来预测当前单词，而后者使用当前单词来预测周围的上下文单词。更多关于 word2vec 的详细信息，请参见 word2vec 上的本<a class="ae kl" href="https://www.guru99.com/word-embedding-word2vec.html#3" rel="noopener ugc nofollow" target="_blank">教程</a>和本<a class="ae kl" href="https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/" rel="noopener ugc nofollow" target="_blank">博客</a>。</p><p id="6276" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我使用了<strong class="jp ir">预训练的 word2vec 单词嵌入。</strong>这些嵌入在谷歌新闻语料库上进行训练，并为 300 万个英语单词提供 300 维嵌入(向量)。参见此<a class="ae kl" href="https://code.google.com/archive/p/word2vec/" rel="noopener ugc nofollow" target="_blank">链接</a>了解嵌入的原始位置。</p><p id="eea5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> Doc2vec </strong>是 word2vec 的扩展，它产生文档的嵌入。这里，“文档”指的是由多个记号/单词组成的更大的块。对于这个解决方案，我还应用了 doc2vec，其中的文档是实际的句子。然而，word2vec 的结果比第 3 阶段稍好，因此，这个解决方案只关注 Word2Vec。</p><p id="6361" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">TF-IDF 或术语频率-逆文档频率是一种加权方案，旨在衡量一个单词在更广泛的语料库(整个文章正文)中对文档(或 Kaggle 文章的句子)的重要性。权重“与单词在文档中出现的次数成比例增加，但被单词在语料库中的频率抵消”(<a class="ae kl" href="http://www.tfidf.com/" rel="noopener ugc nofollow" target="_blank">教程链接</a>)。</p><p id="b1c1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于语料库 cc 中句子<strong class="jp ir"><em class="km">【s】</em></strong>中的术语<strong class="jp ir"> <em class="km"> t </em> </strong>，则 TF-IDF 权重为:</p><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/32b5c5f31abe06744b56888f8eac2407.png" data-original-src="https://miro.medium.com/v2/resize:fit:274/format:webp/1*FliBWtmdYlpuErXfhT4MfA.png"/></div><p class="no np gj gh gi nq nr bd b be z dk translated"><a class="ae kl" href="https://github.com/LidaGh/nlp-1/blob/master/examples/sentence_similarity/baseline_deep_dive.ipynb" rel="noopener ugc nofollow" target="_blank"> TF-IDF 重量(来源)</a></p></figure><p id="b3b8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中:</p><p id="241d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> TFt，s</strong>= term<strong class="jp ir">t</strong>出现在句子<strong class="jp ir"> s </strong> <br/> <strong class="jp ir"> dft </strong> =包含 term <strong class="jp ir"> t </strong> <br/> <strong class="jp ir"> N </strong>的句子数量=语料库的大小。</p><p id="4565" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">余弦相似度</strong>是向量之间常见的相似度度量。直观地，它测量任意两个向量之间的角度余弦。对于向量<strong class="jp ir"> a </strong>和<strong class="jp ir"> b </strong>，余弦相似度为:</p><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/e8782f5f482313ee8a2ef95b6593fdda.png" data-original-src="https://miro.medium.com/v2/resize:fit:388/format:webp/1*-rwrcu5hzWgMQ40hVGbrUw.png"/></div><p class="no np gj gh gi nq nr bd b be z dk translated"><a class="ae kl" href="https://github.com/microsoft/nlp-recipes" rel="noopener ugc nofollow" target="_blank">计算余弦相似度(来源)</a></p></figure><p id="1c8a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我计算了所有单词嵌入的 TF-IDF 加权平均值以及 Kaggle 数据集和任务数据集的每个句子之间的余弦相似度，并找到了每篇文章中排名最高的句子。代码的更多细节可以在<a class="ae kl" href="https://github.com/LidaGh/Submitted_Kaggle_CORD_19_Word2Vec_BERT_QA_Diagnostics_Task" rel="noopener ugc nofollow" target="_blank"> github </a>上找到，第二阶段的成果如下。</p><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi oj"><img src="../Images/4f97720a2ed69b1778abd0a5b61cee73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lQpyrLoL12D8nMBvm_9VXA.png"/></div></div></figure><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi ok"><img src="../Images/8a91e82d328325e69da4a97f60b714c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KEq-4rzqXeBlcW0yQb-VMw.png"/></div></div></figure><p id="a638" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">例如，为一篇文章提取的与任务 4 中的诊断句子相似的排名前十的句子是:</p><pre class="nh ni nj nk gt ol nf om on aw oo bi"><span id="a91e" class="lq ko iq nf b gy op oq l or os">['In addition to the poorly understood but well observed advantageous nature of narrow sutures on the prevention of abdominal incisional hernias, studies assessing for this type of suture and comparing it with other suturing techniques also carry a number of limitations, which may limit the generalizability of their results.',<br/> 'Participants will be randomly assigned to their treatment arms in a 1:1 ratio, according to a computer generated schedule, stratified by type of surgery (vascular or non-vascular), using permuted blocks of variable sizes.',<br/> 'Their results showed a lower incidence of wound infections, dehiscence, and incisional hernias with their new fascial closure technique as compared to the conventional one.',<br/> 'In addition, several studies showed that the clinical detection of ventral abdominal incisional hernias is a simple, rapid, radiation-free, and cost-effective method to rely on .',<br/> 'Nevertheless, major studies such as the STITCH trial relied on physical examination as the primary means of detecting incisional hernias  .',<br/> 'We will use the chi-square or Fisher exact test if the expected count of any of the outcomes is less than 5 per cell for analysis of the incidence of dichotomous outcomes (fascia dehiscence, incisional hernia, wound seroma, wound infection, and intervention for wound complications).',<br/> 'To that effect, the modality for the detection of incisional hernias remains subjective to the experience of the physician or investigator.',<br/> 'Investigating the prevention of incisional hernias using different suturing techniques requires adequate detection of this complication as a prerequisite.',<br/> 'On the other hand, some studies showed that ultrasound can be a superior modality for incisional hernia detection with a sensitivity ranging between 70 and 98% and a specificity between 88 and 100%    .']</span></pre><h2 id="8545" class="lq ko iq bd kp lr ls dn kt lt lu dp kx jy lv lw lb kc lx ly lf kg lz ma lj mb bi translated">阶段 3:使用微调过的 BERT 应用问题回答</h2><p id="e1af" class="pw-post-body-paragraph jn jo iq jp b jq ll js jt ju lm jw jx jy ln ka kb kc lo ke kf kg lp ki kj kk ij bi translated">阶段 1 和阶段 2 的结果是类似于 Kaggle 任务的句子。在第 3 阶段，我使用如下微调的 BERT 应用了问答技术。</p><p id="8da2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">问题回答</strong>是一项经典的自然语言处理任务，包括确定回答用户“问题”的相关“答案”(从提供的段落中摘录的文本片段)。这项任务是机器理解的一个子集，或者测量机器理解一段文本的程度。[ <a class="ae kl" href="https://render.githubusercontent.com/view/ipynb?commit=a5cd2303187239799ae0b1597a7c16eb99a97108&amp;enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6d6963726f736f66742f6e6c702d726563697065732f613563643233303331383732333937393961653062313539376137633136656239396139373130382f6578616d706c65732f7175657374696f6e5f616e73776572696e672f707265747261696e65642d424552542d53517541442d646565702d646976652d616d6c2e6970796e62&amp;nwo=microsoft%2Fnlp-recipes&amp;path=examples%2Fquestion_answering%2Fpretrained-BERT-SQuAD-deep-dive-aml.ipynb&amp;repository_id=179728393&amp;repository_type=Repository#References" rel="noopener ugc nofollow" target="_blank"> 1 </a></p><p id="25c4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> BERT </strong>(来自变形金刚的双向编码器表示)是谷歌在 2019 年推出的预训练语言模型<a class="ae kl" href="https://arxiv.org/abs/1810.04805" rel="noopener ugc nofollow" target="_blank">，在各种各样的 NLP 任务中呈现最先进的结果，包括问答(SQuAD v1.1)、自然语言推理(MNLI)、文本分类、名称实体识别等。，只需对特定于任务的数据集进行几次微调。BERT 的关键技术创新是应用了</a><a class="ae kl" href="https://github.com/huggingface/transformers/" rel="noopener ugc nofollow" target="_blank"> Transformer </a>的双向训练，这是一种流行的注意力模型，用于学习文本中单词(或子单词)之间的上下文关系。[ <a class="ae kl" href="https://render.githubusercontent.com/view/ipynb?commit=a5cd2303187239799ae0b1597a7c16eb99a97108&amp;enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6d6963726f736f66742f6e6c702d726563697065732f613563643233303331383732333937393961653062313539376137633136656239396139373130382f6578616d706c65732f7175657374696f6e5f616e73776572696e672f707265747261696e65642d424552542d53517541442d646565702d646976652d616d6c2e6970796e62&amp;nwo=microsoft%2Fnlp-recipes&amp;path=examples%2Fquestion_answering%2Fpretrained-BERT-SQuAD-deep-dive-aml.ipynb&amp;repository_id=179728393&amp;repository_type=Repository#References" rel="noopener ugc nofollow" target="_blank"> 1 </a></p><p id="df36" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">SQuAD( <a class="ae kl" href="https://rajpurkar.github.io/SQuAD-explorer/" rel="noopener ugc nofollow" target="_blank">斯坦福问答数据集</a>)是一个阅读理解数据集，由人群工作者就一组维基百科文章提出的问题组成，其中每个问题的答案都是相应阅读文章的一段文字或跨度，或者问题可能无法回答。“SQuAD 1.1 是 SQuAD 数据集的上一版本，包含 500+篇文章的 100，000+个问答对”。<a class="ae kl" href="https://render.githubusercontent.com/view/ipynb?commit=a5cd2303187239799ae0b1597a7c16eb99a97108&amp;enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6d6963726f736f66742f6e6c702d726563697065732f613563643233303331383732333937393961653062313539376137633136656239396139373130382f6578616d706c65732f7175657374696f6e5f616e73776572696e672f707265747261696e65642d424552542d53517541442d646565702d646976652d616d6c2e6970796e62&amp;nwo=microsoft%2Fnlp-recipes&amp;path=examples%2Fquestion_answering%2Fpretrained-BERT-SQuAD-deep-dive-aml.ipynb&amp;repository_id=179728393&amp;repository_type=Repository#References" rel="noopener ugc nofollow" target="_blank">【2】</a></p><p id="b812" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">如何针对问答任务微调 BERT:</strong>下图显示了如何针对问答任务微调 BERT。BERT 将问题-段落对插入到班数据集中作为输入，<code class="fe nc nd ne nf b">[SEP]</code>表示是用于分隔问题/答案的特殊分隔符。在输出层，它输出<code class="fe nc nd ne nf b">Start/End</code>来表示段落中的答案。</p><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi ot"><img src="../Images/63766daeaca81bfe67b889713275b7d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HwokNIPrxLQdpjHAjoWEdw.png"/></div></div><p class="no np gj gh gi nq nr bd b be z dk translated">图 5:为 QA 微调 BERT(<a class="ae kl" href="https://render.githubusercontent.com/view/ipynb?commit=a5cd2303187239799ae0b1597a7c16eb99a97108&amp;enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6d6963726f736f66742f6e6c702d726563697065732f613563643233303331383732333937393961653062313539376137633136656239396139373130382f6578616d706c65732f7175657374696f6e5f616e73776572696e672f707265747261696e65642d424552542d53517541442d646565702d646976652d616d6c2e6970796e62&amp;nwo=microsoft%2Fnlp-recipes&amp;path=examples%2Fquestion_answering%2Fpretrained-BERT-SQuAD-deep-dive-aml.ipynb&amp;repository_id=179728393&amp;repository_type=Repository#References" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="acb0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里有一个很棒的关于微调 BERT <a class="ae kl" href="https://mccormickml.com/2020/03/10/question-answering-with-a-fine-tuned-BERT/" rel="noopener ugc nofollow" target="_blank">的问答教程。为了节省这篇文章的时间和空间，我跳过描述每个步骤。更多细节可以在我的</a><a class="ae kl" href="https://github.com/LidaGh/Submitted_Kaggle_CORD_19_Word2Vec_BERT_QA_Diagnostics_Task" rel="noopener ugc nofollow" target="_blank"> github </a>上找到。</p><p id="0861" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">注意:</strong>安装变形金刚库需要相当大的内存。在这个阶段，我不能使用 Kaggle 笔记本，第二阶段的结果保存在一个 csv 文件中，第三阶段是在<strong class="jp ir"> Linux 虚拟机上开发的，使用标准 NC6、6 个 vCPUs 和 56GB RAM。</strong></p><p id="547e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用了以下 BERT 预训练模型:</p><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi ou"><img src="../Images/7099742845ef45851fbe893882be9c1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tyh8rqmbZ-iPHUayHBZvAA.png"/></div></div></figure><p id="576c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">阶段 3 的结果是与诊断任务相关的问题的答案。对于此特定任务，文章摘要表格应遵循表格格式:<code class="fe nc nd ne nf b">Group 6 - Diagnostics</code>。<code class="fe nc nd ne nf b">Publication date Study-type Study Link Journal Study Type Detection Method Sample Obtained Sample Measure of Evidence Speed of assay FDA approval Added on DOI CORD_UID</code></p><p id="0dc4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，提出了以下问题:</p><blockquote class="ov ow ox"><p id="8cc7" class="jn jo km jp b jq jr js jt ju jv jw jx oy jz ka kb oz kd ke kf pa kh ki kj kk ij bi translated">学习类型是什么？</p><p id="c711" class="jn jo km jp b jq jr js jt ju jv jw jx oy jz ka kb oz kd ke kf pa kh ki kj kk ij bi translated">用什么检测方法？</p><p id="11af" class="jn jo km jp b jq jr js jt ju jv jw jx oy jz ka kb oz kd ke kf pa kh ki kj kk ij bi translated">样本量是多少？</p><p id="5255" class="jn jo km jp b jq jr js jt ju jv jw jx oy jz ka kb oz kd ke kf pa kh ki kj kk ij bi translated">获得了什么样本？</p><p id="639f" class="jn jo km jp b jq jr js jt ju jv jw jx oy jz ka kb oz kd ke kf pa kh ki kj kk ij bi translated">证据的衡量标准是什么？</p><p id="caaa" class="jn jo km jp b jq jr js jt ju jv jw jx oy jz ka kb oz kd ke kf pa kh ki kj kk ij bi translated">化验的速度是多少？</p><p id="9f2b" class="jn jo km jp b jq jr js jt ju jv jw jx oy jz ka kb oz kd ke kf pa kh ki kj kk ij bi translated">是 FDA 批准的吗？</p></blockquote><h2 id="fd9a" class="lq ko iq bd kp lr ls dn kt lt lu dp kx jy lv lw lb kc lx ly lf kg lz ma lj mb bi translated">结果</h2><p id="fb8d" class="pw-post-body-paragraph jn jo iq jp b jq ll js jt ju lm jw jx jy ln ka kb kc lo ke kf kg lp ki kj kk ij bi translated">图 6 显示了 20 个样本的结果。我已经删除了表格中的一些内容，以适应这一页。</p><figure class="nh ni nj nk gt nl gh gi paragraph-image"><div role="button" tabindex="0" class="nv nw di nx bf ny"><div class="gh gi pb"><img src="../Images/9c54df87f2acd836415586b7e39fd2a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7KCkCQaCMNmte__31M9NFA.png"/></div></div><p class="no np gj gh gi nq nr bd b be z dk translated">图 6:最终结果(20 个样本)</p></figure><p id="9679" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些结果表明，该解决方案可有效检测特定信息，如<strong class="jp ir">方法类型</strong> : <em class="km"> pcr、胸部 x 射线、蛋白质印迹</em>、<strong class="jp ir">获得的样本</strong> : <em class="km">血液、纯化病毒、vp1 基因</em>，以及数字数据，如<strong class="jp ir">样本量</strong> : <em class="km"> 25 gl，2 周或更长时间，&gt; 400，000 名成人</em>、<strong class="jp ir">分析速度:<strong class="jp ir">该解决方案还显示了提取背景信息的有希望的结果，如 s <strong class="jp ir">研究类型</strong> : <em class="km">观察、调查和报告、行为实验</em>，<strong class="jp ir"> fda 批准:</strong> <em class="km">机构伦理研究委员会，FDA 已批准使用普瑞巴林 fibr，美国 FDA 批准。</em>对于<strong class="jp ir">证据度量</strong>的情况，提取了精确公式<em class="km"> (ρ ( τ，x p ( τ ) ) </em>以及概念证据:<em class="km">更快的实验室和数据分析周转、表面等离子体共振(spr)分析、图论和最小生成树(mst)。</em></strong></strong></p><h1 id="632b" class="kn ko iq bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk bi translated">结论和未来工作:</h1><p id="499f" class="pw-post-body-paragraph jn jo iq jp b jq ll js jt ju lm jw jx jy ln ka kb kc lo ke kf kg lp ki kj kk ij bi translated">这篇文章描述了为 Kaggle 竞赛(CORD-19)第 2 轮诊断任务提交的解决方案(链接到<a class="ae kl" href="https://github.com/LidaGh/Submitted_Kaggle_CORD_19_Word2Vec_BERT_QA_Diagnostics_Task/blob/master/Github_Word2Vec_BERT_QA_Diagnostics_Task_CORD_19.ipynb" rel="noopener ugc nofollow" target="_blank"> github </a>)。该解决方案在两个数据集的数据预处理的 3 个阶段(图 2)中实现:诊断任务和 Kaggle，计算任务句子和文章正文句子之间的单词嵌入和 Word2Vec 句子相似性，并选择排名靠前的句子，最后对排名靠前的句子应用 BERT 预训练的 QA 模型，以找到汇总表的准确答案。</p><p id="4a2b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">结果(图 6)表明，该解决方案可以有效地检测特定信息、数字数据以及从文章正文中提取上下文信息。</p><p id="2229" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于未来的工作，作者计划通过应用其他知识提取方法来继续这项研究，包括:<a class="ae kl" href="https://covid19search.azurewebsites.net/" rel="noopener ugc nofollow" target="_blank">微软新冠肺炎 Azure 认知搜索</a>，它对由<a class="ae kl" href="https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/how-tos/text-analytics-for-health?tabs=ner" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir"> Azure 健康文本分析</strong> </a>和<a class="ae kl" href="https://docs.microsoft.com/en-us/azure/search/search-what-is-azure-search" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir"> Azure 认知搜索</strong> </a> <strong class="jp ir">支持的相同 CORD-19 数据集进行分类。</strong></p></div></div>    
</body>
</html>