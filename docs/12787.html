<html>
<head>
<title>Machine Learning &amp; Image to Audio Captioning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习&amp;图像到音频字幕</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-image-to-audio-captioning-964dc0f63df9?source=collection_archive---------40-----------------------#2020-09-02">https://towardsdatascience.com/machine-learning-image-to-audio-captioning-964dc0f63df9?source=collection_archive---------40-----------------------#2020-09-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/8459d4398aa4684bdf292bba5154dc35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*798Ftr2USxK3-W_R"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">杰森·罗斯韦尔在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><div class=""><h2 id="829c" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">关于机器学习如何用于将图像直接翻译成语音的简要文献综述。</h2></div><p id="15d5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">机器学习已经扩展到许多不同的领域和学科。尝试新的领域是成长和学习新事物的最好方式。以下是研究人员如何应用机器学习直接从图像中生成音频描述的总结。</p><h1 id="3599" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated"><a class="ae jd" href="http://www.cs.cmu.edu/~awb/papers/hasegawajohnson17icnlssp.pdf" rel="noopener ugc nofollow" target="_blank">图像 2 语音:自动生成图像的音频描述</a></h1><p id="22ad" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">研究人员在不使用文本作为中间形式的情况下为图像生成音频字幕。</p><blockquote class="mo mp mq"><p id="3cb9" class="kv kw mr kx b ky kz kh la lb lc kk ld ms lf lg lh mt lj lk ll mu ln lo lp lq ij bi translated">Clustergen、VGG16、LSTM、MSCOCO、语音-COCO、XNMT、Flickr、Flickr-Audio</p></blockquote><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mv"><img src="../Images/6f6796cdc0e6c28b6cada6d442c08aa8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jp-tyS3XNGil1L0H"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">丹尼尔·山特维克在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h2 id="af2c" class="na ls jg bd lt nb nc dn lx nd ne dp mb le nf ng md li nh ni mf lm nj nk mh nl bi translated">摘要和导言</h2><p id="49f4" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">研究人员提出了人工智能的一个新领域，图像 2speech。他们将主要任务定义为:</p><blockquote class="mo mp mq"><p id="4c57" class="kv kw mr kx b ky kz kh la lb lc kk ld ms lf lg lh mt lj lk ll mu ln lo lp lq ij bi translated">" Image2Speech 系统应该直接生成图像的语音描述，而不需要首先生成文本."</p></blockquote><p id="ef7c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">以前，image2speech 问题被分解为两个步骤:image2txt，然后 txt2speech。但是，一些语言没有书面形式(例如阿尔及利亚语、摩洛哥语、黎凡特语、各种阿拉伯语等)，因此传统的 img 2 语音翻译不适用于这些语言。</p><h2 id="13d9" class="na ls jg bd lt nb nc dn lx nd ne dp mb le nf ng md li nh ni mf lm nj nk mh nl bi translated">方法</h2><p id="7bc2" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">研究人员使用标准的开源库、软件和数据来开发他们的模型。图一。展示了这些技术是如何相互关联的。</p><ol class=""><li id="5e5b" class="nm nn jg kx b ky kz lb lc le no li np lm nq lq nr ns nt nu bi translated"><a class="ae jd" rel="noopener" target="_blank" href="/step-by-step-vgg16-implementation-in-keras-for-beginners-a833c686ae6c"> VGG16 </a>(从图像中提取 CNN 特征)</li><li id="ed0b" class="nm nn jg kx b ky nv lb nw le nx li ny lm nz lq nr ns nt nu bi translated"><a class="ae jd" href="https://github.com/neulab/xnmt" rel="noopener ugc nofollow" target="_blank"> XNMT </a>(从 CNN 特征生成语音单元)</li><li id="4fbd" class="nm nn jg kx b ky nv lb nw le nx li ny lm nz lq nr ns nt nu bi translated"><a class="ae jd" href="https://www.cs.cmu.edu/~awb/papers/is2006/IS061394.PDF" rel="noopener ugc nofollow" target="_blank"> ClusterGen </a>(将语音单元转换成音频)</li><li id="5077" class="nm nn jg kx b ky nv lb nw le nx li ny lm nz lq nr ns nt nu bi translated"><a class="ae jd" href="https://kaldi-asr.org/doc/about.html" rel="noopener ugc nofollow" target="_blank"> Kaldi </a>和<a class="ae jd" href="https://github.com/srvk/eesen" rel="noopener ugc nofollow" target="_blank"> Eesen </a>(自动语音识别，将音频翻译成语音单元)</li><li id="4e92" class="nm nn jg kx b ky nv lb nw le nx li ny lm nz lq nr ns nt nu bi translated"><a class="ae jd" href="https://www.kaggle.com/hsankesara/flickr-image-dataset" rel="noopener ugc nofollow" target="_blank"> Flickr 图像数据集</a>和<a class="ae jd" href="https://groups.csail.mit.edu/sls/downloads/flickraudio/" rel="noopener ugc nofollow" target="_blank"> Flickr 音频</a></li><li id="de05" class="nm nn jg kx b ky nv lb nw le nx li ny lm nz lq nr ns nt nu bi translated"><a class="ae jd" href="https://arxiv.org/abs/1405.0312" rel="noopener ugc nofollow" target="_blank"> MSCOCO </a>和<a class="ae jd" href="https://arxiv.org/abs/1707.08435" rel="noopener ugc nofollow" target="_blank">演讲-COCO </a></li></ol><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oa"><img src="../Images/08f2b25e6adb07550aff778bf517e828.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NbYchyromVetG4CkCF5T1A.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图一。图像速度的实验方法。来源:作者</p></figure><p id="26f8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">Image2Speech 系统由三个独立的网络组成(VGG16、XNMT 和 Clustergen)。整个网络根据图像和音频描述对进行训练。</p><p id="cb52" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">作者使用 VGG16 提取图像特征，然后 XNMT 将这些图像特征转化为语音单元，最后 Clustergen 将语音单元转化为音频。</p><blockquote class="mo mp mq"><p id="a9e7" class="kv kw mr kx b ky kz kh la lb lc kk ld ms lf lg lh mt lj lk ll mu ln lo lp lq ij bi translated">" XNMT(可扩展机器翻译工具包)专门用于训练序列对序列神经网络."</p></blockquote><h1 id="4215" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">数据</h1><p id="96f8" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">数据来自两个不同的来源。它们都有一个图像数据集(Flickr 和 MSCOCO)和一个音频数据集(Flickr-Audio 和 SPEECH-MSCOCO)。因此，每个图像都伴随有文本字幕和该文本字幕的音频朗读。</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/610629256b4637b3a19ea9fbabeb08a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*LO2YGullmHu-iFUtVWL_EA.jpeg"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">示例图像 1000268201。来源:<a class="ae jd" href="https://www.kaggle.com/hsankesara/flickr-image-dataset" rel="noopener ugc nofollow" target="_blank">公共领域</a></p></figure><p id="b085" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">上图的字幕是由亚马逊土耳其机械公司的工人制作的:</p><ol class=""><li id="a255" class="nm nn jg kx b ky kz lb lc le no li np lm nq lq nr ns nt nu bi translated">一个穿着粉色连衣裙的孩子正在入口通道爬上一组楼梯。</li><li id="abed" class="nm nn jg kx b ky nv lb nw le nx li ny lm nz lq nr ns nt nu bi translated">一个女孩走进一栋木制建筑。</li><li id="292a" class="nm nn jg kx b ky nv lb nw le nx li ny lm nz lq nr ns nt nu bi translated">一个小女孩爬进木制玩具屋。</li><li id="067d" class="nm nn jg kx b ky nv lb nw le nx li ny lm nz lq nr ns nt nu bi translated">一个小女孩爬楼梯去她的玩具屋</li><li id="94b3" class="nm nn jg kx b ky nv lb nw le nx li ny lm nz lq nr ns nt nu bi translated">一个穿着粉色连衣裙的小女孩走进了一个小木屋。</li></ol><p id="052f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">MSCOCO 是最大的 image2txt 和 text2speech 数据集。它是如此之大，以至于研究人员在训练过程中无法将它全部包含进来。</p><h1 id="e670" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">结果</h1><p id="8e4d" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">在所有模型被训练之后，它们实现了 78.8%的电话错误率。作者将此描述为:</p><blockquote class="mo mp mq"><p id="14d6" class="kv kw mr kx b ky kz kh la lb lc kk ld ms lf lg lh mt lj lk ll mu ln lo lp lq ij bi translated">“不是完全自然的，而是由可理解的单词组成的可理解的句子”</p></blockquote><h1 id="735a" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">结论</h1><p id="adcf" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">作者定义了一个新的人工智能领域，比传统的 image2speech 更具挑战性和限制性。在没有任何中间文本的情况下，从图像生成语音是新应用的独特问题。在本文中，作者提出了第一个此类模型，并希望鼓励其他人继续构建更有趣的模型。</p><h1 id="e714" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">机器学习和更多</h1><div class="ip iq gp gr ir oc"><a rel="noopener follow" target="_blank" href="/machine-learning-hearing-loss-d60dab084e3f"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd jh gy z fp oh fr fs oi fu fw jf bi translated">机器学习和听力损失</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">关于机器学习如何使听力损失者受益的简要文献综述。</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ol l"><div class="om l on oo op ol oq ix oc"/></div></div></a></div><h1 id="4e46" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">参考文件</h1><blockquote class="mo mp mq"><p id="2e1f" class="kv kw mr kx b ky kz kh la lb lc kk ld ms lf lg lh mt lj lk ll mu ln lo lp lq ij bi translated">Mark Hasegawa-Johnson，Alan Black，Lucas Ondel，Odette Scharenborg，Francesco Ciannella，《图像 2speech:自动生成图像的音频描述》，载于 inter speach(2020)<a class="ae jd" href="http://www.cs.cmu.edu/~awb/papers/hasegawajohnson17icnlssp.pdf" rel="noopener ugc nofollow" target="_blank">http://www . cs . CMU . edu/~ awb/papers/Hasegawa Johnsons 17 icnlssp . pdf</a></p></blockquote></div></div>    
</body>
</html>