<html>
<head>
<title>Should I Stay or Should I Go</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我应该留下还是离开</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/should-i-stay-or-should-i-go-463c6a976db3?source=collection_archive---------37-----------------------#2020-03-25">https://towardsdatascience.com/should-i-stay-or-should-i-go-463c6a976db3?source=collection_archive---------37-----------------------#2020-03-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8ff7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">困境是一个强化学习代理，米克·琼斯，甚至蜘蛛侠的斗争。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/bbad1a62e0ef55e1b79faf6057dfb91d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CQXzmS6ekG5tBrRKJRA8kA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由<a class="ae ky" href="https://pixabay.com/users/DanaTentis-2743349/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2003647" rel="noopener ugc nofollow" target="_blank"> DanaTentis </a>来自<a class="ae ky" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2003647" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><blockquote class="kz"><p id="19a4" class="la lb it bd lc ld le lf lg lh li lj dk translated">我应该留下还是现在就走？<br/>如果我走了，会有麻烦<br/>，如果我留下，会有双倍的麻烦<br/>，所以你必须让我知道<br/>我应该留下还是离开？——<a class="ae ky" href="https://www.youtube.com/watch?v=BN1WwnEDWAM" rel="noopener ugc nofollow" target="_blank">冲突</a></p></blockquote><p id="c5d5" class="pw-post-body-paragraph lk ll it lm b ln lo ju lp lq lr jx ls lt lu lv lw lx ly lz ma mb mc md me lj im bi translated">我们不都有这种感觉吗？对目前的工作不满意，但新工作薪水更低。不确定是投资股市还是理财平台？甚至蜘蛛侠也不得不在拯救玛丽·简和拯救缆车上的人之间做出选择。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="4dd4" class="pw-post-body-paragraph lk ll it lm b ln mh ju lp lq mi jx ls lt mj lv lw lx mk lz ma mb ml md me lj im bi translated">困境是一种发生在头脑中的斗争。它是关于必须在两个或更多的选择中做出选择，在这些选择中，结果都是有利的或不利的。做出正确的选择可能会带来积极的结果，而做出错误的决定会让你付出代价。</p><p id="ca30" class="pw-post-body-paragraph lk ll it lm b ln mh ju lp lq mi jx ls lt mj lv lw lx mk lz ma mb ml md me lj im bi translated">在强化学习中，<a class="ae ky" rel="noopener" target="_blank" href="/reinforcement-learning-value-function-57b04e911152?source=friends_link&amp;sk=fe8b20f046c2c67a1941bb896e1a3658">机器学习代理</a>也面临两难，在探索和利用之间选择。在培训过程中，代理必须:</p><ul class=""><li id="b6bc" class="mm mn it lm b ln mh lq mi lt mo lx mp mb mq lj mr ms mt mu bi translated">选择一些熟悉的东西，最大化获得奖励的机会</li><li id="3ace" class="mm mn it lm b ln mv lq mw lt mx lx my mb mz lj mr ms mt mu bi translated">选择一些新的可能(也可能不会)导致未来做出更好决定的东西</li></ul><h1 id="341b" class="na nb it bd nc nd ne nf ng nh ni nj nk jz nl ka nm kc nn kd no kf np kg nq nr bi translated">在探索和开发之间取得平衡</h1><p id="b223" class="pw-post-body-paragraph lk ll it lm b ln ns ju lp lq nt jx ls lt nu lv lw lx nv lz ma mb nw md me lj im bi translated">找到探索(未知领域)和利用(现有知识)之间的平衡是训练一个成功的强化学习代理的关键。未知需要被发现来扩展现有的知识。已知的需要被开发，以产生回报。</p><p id="faec" class="pw-post-body-paragraph lk ll it lm b ln mh ju lp lq mi jx ls lt mj lv lw lx mk lz ma mb ml md me lj im bi translated">这意味着，有时你不得不故意决定不选择你认为对获取新信息最有益的行动。尽管有时这意味着在探索的过程中最终会做出一些糟糕的决定。但与此同时，你想通过<em class="nx">利用</em>你所知道的最有效的方法来最大化你的回报。</p><p id="f2de" class="pw-post-body-paragraph lk ll it lm b ln mh ju lp lq mi jx ls lt mj lv lw lx mk lz ma mb ml md me lj im bi translated">那么，我们如何在充分探索未知和利用最佳行动之间取得平衡呢？</p><ul class=""><li id="7010" class="mm mn it lm b ln mh lq mi lt mo lx mp mb mq lj mr ms mt mu bi translated">充分的初步探索，以便确定最佳方案</li><li id="f8de" class="mm mn it lm b ln mv lq mw lt mx lx my mb mz lj mr ms mt mu bi translated">利用最佳选择使总回报最大化</li><li id="d015" class="mm mn it lm b ln mv lq mw lt mx lx my mb mz lj mr ms mt mu bi translated">继续留出一个小概率来试验次优和未开发的选项，以防它们在未来提供更好的回报</li><li id="cb1b" class="mm mn it lm b ln mv lq mw lt mx lx my mb mz lj mr ms mt mu bi translated">如果这些实验选项表现良好，算法必须更新并开始选择这个选项</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/29bc9c1c65ebe278638b4ce4664b6133.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/0*q270CrZLxQi3CPx_.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">有时候探索会让我们付出代价。红迪网</p></figure><h1 id="4451" class="na nb it bd nc nd ne nf ng nh ni nj nk jz nl ka nm kc nn kd no kf np kg nq nr bi translated">ε贪婪</h1><p id="933b" class="pw-post-body-paragraph lk ll it lm b ln ns ju lp lq nt jx ls lt nu lv lw lx nv lz ma mb nw md me lj im bi translated">在强化学习中，我们可以决定一个智能体要花多少时间去探索。这是通过调整ε-greedy 参数来实现的，其范围从 0 到 1。</p><p id="120c" class="pw-post-body-paragraph lk ll it lm b ln mh ju lp lq mi jx ls lt mj lv lw lx mk lz ma mb ml md me lj im bi translated">如果我们设置 0.1ε-greedy，该算法将在 10%的时间内探索，在 90%的时间内利用最佳选项。在大多数情况下，ε-贪婪参数值通常设置在 5%到 10%之间。</p><h2 id="070b" class="nz nb it bd nc oa ob dn ng oc od dp nk lt oe of nm lx og oh no mb oi oj nq ok bi translated">使用井字游戏代理评估不同的 greedy</h2><p id="a8db" class="pw-post-body-paragraph lk ll it lm b ln ns ju lp lq nt jx ls lt nu lv lw lx nv lz ma mb nw md me lj im bi translated">我开发了一个<a class="ae ky" href="https://jinglescode.github.io/reinforcement-learning-tic-tac-toe/" rel="noopener ugc nofollow" target="_blank">井字游戏</a>，代理可以通过互相对战来学习游戏。首先，让我向你介绍我们的代理人，他们是代理人 X 和代理人 o。代理人 X 总是先走，这意味着代理人 X 有优势。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/bc14fd1e14e658346a2f2665b6bbba86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GTD6JO5aV0Egj0bHSFLdmA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://jinglescode.github.io/reinforcement-learning-tic-tac-toe/" rel="noopener ugc nofollow" target="_blank">你可以和我的井字游戏代理</a>对战</p></figure><p id="d7db" class="pw-post-body-paragraph lk ll it lm b ln mh ju lp lq mi jx ls lt mj lv lw lx mk lz ma mb ml md me lj im bi translated"><strong class="lm iu">实验一。为了找出这个游戏中每个代理最合适的ε贪婪值，我将测试不同的ε贪婪值。我会初始化代理 X 探索 1% (eps 0.01)的时间，双方代理对战 10000 场，我会记录代理 X 获胜的次数。然后我会增加到探索，重复测试，直到 X 特工 100%的时间探索(eps 1.0)。</strong></p><p id="ba7c" class="pw-post-body-paragraph lk ll it lm b ln mh ju lp lq mi jx ls lt mj lv lw lx mk lz ma mb ml md me lj im bi translated">代理 X 的结果(从 1%到 100%的探索)。vs 特工 O (eps 0.05)。蓝线代表代理 X 在不同探索率下赢得的游戏数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/a39d92a7de0ac76c597ad39c6cdadebc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*b0tJsIu0nr1JnJg4.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代理 X 在不同的ε贪婪值上赢得的游戏数(10，000 个中的一个)</p></figure><p id="322f" class="pw-post-body-paragraph lk ll it lm b ln mh ju lp lq mi jx ls lt mj lv lw lx mk lz ma mb ml md me lj im bi translated">这说明探索率越高，X 特工胜率下降。当 X 特工探索 5%的时间时，它达到了赢得 9268 场比赛的顶峰。代理人 O 也开始赢得更多的游戏，因为代理人 X 探索超过 50%的时间。</p><blockquote class="kz"><p id="ecad" class="la lb it bd lc ld on oo op oq or lj dk translated">5%的探索率是赢得大多数游戏的最佳选择</p></blockquote><p id="1806" class="pw-post-body-paragraph lk ll it lm b ln lo ju lp lq lr jx ls lt lu lv lw lx ly lz ma mb mc md me lj im bi translated"><strong class="lm iu">实验二。让我们看看如果我们用一个最优的 5%ε贪婪初始化代理 X，代理 O 会怎么样。蓝线代表 O 探员赢的游戏数。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/d8b15ff6e097500120a5c66523af92d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*RDcIKCeFhAlHk1zW.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代理 O 在不同ε-贪婪值下赢得的游戏数</p></figure><p id="c30b" class="pw-post-body-paragraph lk ll it lm b ln mh ju lp lq mi jx ls lt mj lv lw lx mk lz ma mb ml md me lj im bi translated">好吧，特工 O 任何勘探率都没有胜算；它在学会游戏之前就已经输了大部分游戏。</p><p id="86df" class="pw-post-body-paragraph lk ll it lm b ln mh ju lp lq mi jx ls lt mj lv lw lx mk lz ma mb ml md me lj im bi translated"><strong class="lm iu">实验三。</strong>让我们将代理 X 的 greedy 调整为 100%，这意味着代理 X 将一直玩随机动作。蓝线代表代理人 O 赢了随机代理人 x 的游戏次数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/2d3c0dccfbe3fbe05bd37aacb7168718.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Y8sLLD2ndHCvfU3K.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代理 O 在不同ε-贪婪值上赢得的游戏数，其中代理 X 随机参与</p></figure><p id="c649" class="pw-post-body-paragraph lk ll it lm b ln mh ju lp lq mi jx ls lt mj lv lw lx mk lz ma mb ml md me lj im bi translated">代理人 O 在 30%勘探率后开始损失更多。</p><h1 id="63cb" class="na nb it bd nc nd ne nf ng nh ni nj nk jz nl ka nm kc nn kd no kf np kg nq nr bi translated">尝试演示</h1><p id="19dd" class="pw-post-body-paragraph lk ll it lm b ln ns ju lp lq nt jx ls lt nu lv lw lx nv lz ma mb nw md me lj im bi translated"><a class="ae ky" href="https://jinglescode.github.io/reinforcement-learning-tic-tac-toe/" rel="noopener ugc nofollow" target="_blank">探索在线演示</a>，在井字游戏中挑战我们的强化代理。您可以调整参数来训练不同的代理。</p><p id="d8b8" class="pw-post-body-paragraph lk ll it lm b ln mh ju lp lq mi jx ls lt mj lv lw lx mk lz ma mb ml md me lj im bi translated">了解井字游戏代理如何学习:</p><div class="ot ou gp gr ov ow"><a rel="noopener follow" target="_blank" href="/reinforcement-learning-value-function-57b04e911152"><div class="ox ab fo"><div class="oy ab oz cl cj pa"><h2 class="bd iu gy z fp pb fr fs pc fu fw is bi translated">强化学习价值函数</h2><div class="pd l"><h3 class="bd b gy z fp pb fr fs pc fu fw dk translated">代理使用价值函数学习井字游戏的强化学习算法——带网络演示</h3></div><div class="pe l"><p class="bd b dl z fp pb fr fs pc fu fw dk translated">towardsdatascience.com</p></div></div><div class="pf l"><div class="pg l ph pi pj pf pk ks ow"/></div></div></a></div><p id="d5e1" class="pw-post-body-paragraph lk ll it lm b ln mh ju lp lq mi jx ls lt mj lv lw lx mk lz ma mb ml md me lj im bi translated">如果您喜欢在线演示，您可能也会喜欢这个:</p><div class="ot ou gp gr ov ow"><a rel="noopener follow" target="_blank" href="/time-series-forecasting-with-tensorflow-js-1efd48ff2201"><div class="ox ab fo"><div class="oy ab oz cl cj pa"><h2 class="bd iu gy z fp pb fr fs pc fu fw is bi translated">使用 TensorFlow.js 进行时间序列预测</h2><div class="pd l"><h3 class="bd b gy z fp pb fr fs pc fu fw dk translated">从在线 API 中提取股票价格，并使用 RNN 和 LSTM 以及 TensorFlow.js 进行预测(包括演示和代码)</h3></div><div class="pe l"><p class="bd b dl z fp pb fr fs pc fu fw dk translated">towardsdatascience.com</p></div></div><div class="pf l"><div class="pl l ph pi pj pf pk ks ow"/></div></div></a></div></div><div class="ab cl pm pn hx po" role="separator"><span class="pp bw bk pq pr ps"/><span class="pp bw bk pq pr ps"/><span class="pp bw bk pq pr"/></div><div class="im in io ip iq"><div class="kj kk kl km gt ab cb"><figure class="pt kn pu pv pw px py paragraph-image"><a href="https://jinglescode.github.io/"><img src="../Images/e6191b77eb1b195de751fecf706289ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*fPTPd_WxZ4Ey7iOVElxwJQ.png"/></a></figure><figure class="pt kn pu pv pw px py paragraph-image"><a href="https://towardsdatascience.com/@jinglesnote"><img src="../Images/7c898af9285ccd6872db2ff2f21ce5d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*airGp_q6AXwaoL1LYXwYeQ.png"/></a></figure><figure class="pt kn pu pv pw px py paragraph-image"><a href="https://jingles.substack.com/subscribe"><img src="../Images/d370b96eace4b03cb3c36039b70735d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*ESxUX6V6tAqj_2ZFSr-pUw.png"/></a></figure></div></div><div class="ab cl pm pn hx po" role="separator"><span class="pp bw bk pq pr ps"/><span class="pp bw bk pq pr ps"/><span class="pp bw bk pq pr"/></div><div class="im in io ip iq"><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mf mg l"/></div></figure></div></div>    
</body>
</html>