# ML impossible:使用 Vaex 和 Scikit-Learn 在 5 分钟内在您的笔记本电脑上训练 10 亿个样本

> 原文：<https://towardsdatascience.com/ml-impossible-train-a-1-billion-sample-model-in-20-minutes-with-vaex-and-scikit-learn-on-your-9e2968e6f385?source=collection_archive---------1----------------------->

![](img/602e022059cafe4b37ab90da6e08670a.png)

汤姆·克鲁斯尝试在没有 Vaex 的情况下进行机器学习。(版权所有:派拉蒙影业)

## 让您的笔记本电脑感觉像一台超级计算机。

“数据是新的石油。”不管你是否同意这种说法，收集和利用数据的竞赛已经持续了一段时间。事实上，今天的科技巨头有一个共同点，就是他们有能力充分利用他们收集的大量数据。他们有知识、人力和资源来分析数十亿个数据点，大规模训练和部署各种机器学习模型，然后影响我们星球上无数的人。

创建一个简单的机器学习服务也不是一件小事。即使我们忽略数据收集和扩充步骤，我们仍然需要理解数据，适当地清理数据，创建有意义的特征，然后训练和调整模型。接下来是一系列的验证步骤，有望更好地理解数据和模型。重复这个过程，直到模型满足业务目标，然后投入生产。然而，在实践中，这一过程可能会无限期地继续下去。

想象一下，我们有一个包含超过*10 亿*个样本的数据集，我们需要用它来训练一个机器学习模型。由于数量庞大，探索这样的数据集已经变得棘手，而重复清洗、预处理和训练步骤成为一项艰巨的任务。诸如此类的挑战通常通过分布式或云计算来解决。虽然这是当今的标准方法，但与在本地机器上工作相比，它可能非常昂贵、耗时，而且不太方便。

在这篇文章中，我将展示任何人如何以快速有效的方式在十亿个样本上训练机器学习模型。您的笔记本电脑就是您需要的所有基础设施。只要确保它插上电源就行了。

## 问题:预测出租车行程持续时间

例如，假设我们想帮助一家出租车公司预测在纽约市的行程需要多长时间。我们将使用纽约市出租车数据集，其中包含 2009 年至 2015 年间由可识别的黄色出租车进行的超过*10 亿次*出租车旅行的信息。原始数据由纽约市出租车豪华轿车委员会(TLC)提供，可以从他们的网站(T3)上下载(T2)。*如果你只是对作为本文基础的 Jupyter 笔记本感兴趣，你可以* [*点击这里*](https://nbviewer.jupyter.org/github/vaexio/vaex-examples/blob/master/medium-nyc-taxi-data-ml/vaex-taxi-ml-article.ipynb) *。*

## 使用 Vaex 进行数据准备

为了操作大量数据，我们将使用 [Vaex](https://github.com/vaexio/vaex) ，一个 Python [开源数据帧库](/vaex-out-of-core-dataframes-for-python-and-fast-visualization-12c102db044a)。利用内存映射、延迟评估和高效的核外算法等概念，Vaex 可以轻松处理那些太大而无法放入 RAM 的数据集。

让我们从打开数据开始。为了方便起见，我将 7 年的出租车数据合并到一个文件中。即使文件在磁盘上大于 100GB，用 Vaex 打开它也是即时的:

![](img/0139632b3d4b578ec45090668d4f52d2.png)

打开一个内存映射文件是即时的(119 毫秒！)与 [Vaex](https://github.com/vaexio/vaex) 。如果你本地没有，你可以从 AWS 上下载。

检查数据也一样快。由于数据是内存映射的，Vaex 立即知道在哪里查找，只读取需要的部分。对于如下所示的简单预览，只从磁盘中读取前 5 行和后 5 行。

![](img/fcfa0db578bc458e344034061487501a.png)

出租车数据集的预览。实际上只有前 5 行和后 5 行是从磁盘中读取的。

使用 Vaex 处理纽约出租车数据集相当简单，尽管它的磁盘容量超过 100GB，包含超过 11 亿条记录。[本文](/how-to-analyse-100s-of-gbs-of-data-on-your-laptop-with-python-f83363dda94)回顾了 Vaex 的基础知识，并对这个完全相同的数据集进行了探索性的数据分析。

在开始之前，让我们将数据分成一个训练集和一个测试集。我们将按年份进行划分，这样 2015 年进行的旅行将构成测试集，而在此之前的所有旅行将构成训练集。数据集是按年份排序的，因此我们可以通过对数据帧进行切片来进行拆分。

![](img/3fe1cd16182b2a7f9a7754ae4cd4b8bf.png)

创建训练集和测试集。Vaex 数据帧的切片不会复制数据，而只会创建一个引用。

请注意，执行上述代码单元不会产生数据的内存副本。对 Vaex 数据帧进行切片会产生浅拷贝，该浅拷贝仅引用原始数据的适当部分。

## 数据争论

这个练习的目的是预测出租车旅行的可能持续时间。一次旅行的持续时间在数据集中并不容易获得，但是从接送的时间戳来计算是微不足道的。

![](img/2bddb54e93cc37e8b22541df1d647e5a.png)

从现有列创建新列不需要额外的内存，而且是即时的。

在上面的代码示例中计算行程距离会产生一个虚拟列。创建这样的列不消耗内存，因为它们只存储定义它们的表达式，并且只在必要时才进行计算。

现在，让我们从训练集中过滤出异常值和错误的数据样本。本文中的探索性数据分析可以作为如何做到这一点的指南，因此如果您想了解这些过滤选择背后的基本原理，请查看。

![](img/b60491831b07456397e617eeaa1466e2.png)

过滤出 Vaex 数据帧只需几秒钟，不需要额外的内存，即使它有数十亿行。

过滤背后的主要思想是移除异常值和可能的错误数据输入，因此模型不会被少数异常样本“分散”注意力。应用所有过滤器后，训练集“仅”包括 812，816，595 次出租车旅行。

在这个阶段，我们可以开始设计一些有意义的特性。因为所有的特性都是虚拟列，所以我们不需要关心内存的使用，因此可以自由地进行实验和创新。让我们从提取拾取时间戳的几个特征开始。

![](img/7cc4a40508b5f28ed7c6e04658772a4b.png)

从提货日期和时间中提取一些有用的特征。

现在，让我们创建几个计算要求更高的特性。其中之一是上下车点之间的距离，我们称之为“弧距”。第二个特征是出租车行程的方向角，即出租车是否从其起点向其目的地正北方或西北方行进的指示。

![](img/8b36f9bdbbb2f032e90b1c63e5f02f52.png)

通过 [Numba](http://numba.pydata.org/) 或 [CUDA](https://developer.nvidia.com/cuda-zone) 的即时编译可以加速计算要求高的表达式的评估。

注意函数调用末尾的`.jit_numba`方法。通过 [Numba](http://numba.pydata.org/) 进行实时编译，可以加速计算开销很大的表达式的求值。如果你的机器配备了更新的 NVIDIA 显卡，你可以通过调用`.jit_cuda`方法使用 [CUDA](https://developer.nvidia.com/cuda-zone) 来获得额外的提升。通过在一些表达式上使用`.jit_numba`,在其他表达式上使用`.jit_cuda`,您可以同时利用 CPU 和 GPU 来获得最高性能。

## 数据转换(vaex.ml)

在我们将数据传递给任何模型之前，我们需要确保它被适当地转换，以便充分利用它。Vaex 包含了`vaex.ml`包，它实现了各种常见的数据转换，比如 PCA、分类编码器和数字定标器。所有的转换都用熟悉的 [scikit-learn](https://scikit-learn.org/stable/) API 调用，在核外并行执行。

让我们把重点放在接送地点。在美国的许多城市，街道形成网格状。这在曼哈顿地区清晰可见。提高模型性能的一个想法是在装载和卸载位置应用一组 [PCA](https://en.wikipedia.org/wiki/Principal_component_analysis) 变换。这将导致由许多上下车点跟踪的街道与自然地理轴(经度和纬度)对齐，而不是与它们成一个角度。

![](img/b3de37a7e039bfc963b0bf8934467c1d.png)

使用 vaex.ml，在近 10 亿个样本上安装几个 PCA 变压器大约需要半分钟。

注意，当使用`vaex.ml`时，将整个数据帧传递给转换器的`.fit`、`.transform`或`.fit_transform`方法，而转换所应用的特性是在实例化转换器时指定的。最重要的是，`.transform`方法返回 DataFrame 的浅层副本，其中转换的结果以虚拟列的形式存储。这使我们很容易看到 PCA 变换的结果。

![](img/594e6e8bbc9d240771d56d8124e68db1.png)

将原始位置与 PCA 变换后的上下车位置进行比较。

让我们将注意力转移到我们之前定义的“提货时间”、“提货日”和“提货月”特性上。这些特征的关键属性是它们在本质上是周期性的，即一月与二月和十二月一样接近。因此，我们将使用在`vaex.ml`中实现的`CycleTransformer`，它本质上将每个特征视为极坐标(ρ=1，φ)中单位圆内的角度φ。然后，变换器计算半径ρ的 *𝑥* 和 *𝑦* 投影，从而为每个特征获得两个新分量。这个技巧完美地保留了不同值之间的相对距离，因为它只是一个坐标变换。你可以在[这篇文章](http://blog.davidkaleko.com/feature-engineering-cyclical-features.html)中读到更多关于这种方法的内容。

![](img/1b13a3030e22c05e6f75ed7f7ebe19b0.png)

使用 vaex.ml.CycleTransformer 对循环特征进行编码可以完美地保留不同值之间的相对距离。

我们将同样的技巧应用于方向角，因为它也是一个循环特征。让我们画出从“pickup_time”列*、*中得到的特性，以说服我们自己这些转换是有意义的。

![](img/10f90833c283fd7ce6537ba8558f1cb0.png)![](img/826c0dcfd56b673f8578d6a5c6e0d021.png)

“拾取时间”特征的 *𝑥* 和 *𝑦* 投影的密度图。

我们看到变换后的特征产生了一个完美的单位圆。请注意，与普通挂钟不同，所有 24 小时都显示在圆圈上。比如“午夜”有坐标 *(x，y) = (1，0)，*“6 点”在 *(x，y) = (0，1)，*而“正午”在 *(x，y) = (-1，0)。*

最后，我们只有一个连续的特征，“弧距离”，我们没有注意到。我们将简单地对其应用标准缩放。

![](img/2a6b8fea553452fe436a826991930d16.png)

使用 vaex.ml 对连续要素进行标准比例变换。

现在我们已经完成了所有的预处理任务，我们可以创建一个最终的特征列表，用于训练模型。

![](img/65d1354af0b1824c45b84b73a6249cb4.png)

用于训练模型的特征子集。

## 训练模型:[Vaex](https://github.com/vaexio/vaex)+[sci kit-learn](https://scikit-learn.org/stable/)

在这个阶段，我们为模型训练阶段做好了准备。虽然`vaex.ml`还没有实现任何预测模型，但它确实提供了 Python 生态系统中几个流行的机器学习库的接口，如 [scikit-learn](https://scikit-learn.org/stable/) 和 [xgboost](https://xgboost.readthedocs.io/en/latest/) 。通过 Vaex 使用这些模型的好处是，在进行数据清理、特征工程和预处理时不会浪费任何内存，从而最大限度地利用 RAM 来训练模型。

对于目前的问题，如果我们要实现我们打算用于培训的所有功能，我们仍然需要比典型的笔记本电脑或台式电脑上可用的内存多得多的内存。为了避免这个问题，我们将使用通过 scikit-learn 获得的`[SGDRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html)`。`SGDRegressor`属于 scikit 中的预测模型家族——了解除了通常的`.fit`之外，还实现了一个`.partial_fit`方法。这使得模型可以在批量数据上进行训练，本质上使其脱离核心。

使用在`vaex.ml`中实现的包装器，可以轻松地从 Vaex 数据帧向 scikit-learn 模型发送批量数据。使用非常简单。首先实例化 scikit-learn 中的`SGDRegressor`,同时以标准方式设置其参数。然后实例化在`vaex.ml`中实现的`IncrementalPredictor`，同时提供主模型、特性名称列表、目标列的名称和批处理大小。原则上，任何模型都可以使用，只要它有一个`.partial_fit`方法并遵循 scikit-learn API 约定。通过批量大小，可以控制 RAM 的使用。可选地，还可以指定时期的数量，即，每个批次中的数据被模型看到多少次，以及是否应该被混洗。最后，我们在`IncrementalPredictor`实例上调用`.fit`方法，在这里我们传递训练集数据帧。

![](img/9aa8456878e2b64ebdbd01c81a5c83fd.png)

使用 [Vaex](https://github.com/vaexio/vaex) 和 [scikit-learn](https://scikit-learn.org/stable/) 在大约 10 亿个样本上训练一个模型既简单又快速。

非常值得注意的是，Vaex + scikit-learn 组合导致我的笔记本电脑(MacBook Pro 15”，2018，2.6GHz 英特尔酷睿 i7，32GB RAM)的总训练时间仅为 7 分钟。这包括对所用的 14 个特征进行动态评估，所有这些特征都是虚拟色谱柱，以及训练 scikit-learn 模型。此外，使用上面显示的一组参数，RAM 的使用从来没有超过 4 GB，这给我留下了足够的空间来运行 Slack。

上面显示的完全相同的设置也由 [Maarten Breddels](https://medium.com/u/b8a6decc0862?source=post_page-----9e2968e6f385--------------------------------) 在他的联想 Thinkpad X1 Extreme 笔记本电脑(英特尔酷睿 i7–8750h，32GB RAM)上运行，培训阶段花费了**不到 5 分钟！**

![](img/27f588e16656f353088e3381e25329a9.png)

在运行 Linux 的 Lenovo Thinkpad X1 Extreme 笔记本电脑(英特尔酷睿 i7–8750h，32GB RAM)上训练 SGDRegressor 不到 5 分钟。

`IncrementalPredictor`不仅仅是一个将 Vaex 数据帧传递给 scikit-learn 模型的便利类。它还是一个`vaex.ml`转换器，这意味着`.transform`方法返回一个包含模型预测的数据帧的浅层副本作为虚拟列。这是在`vaex.ml`中实现的任何模型包装器的情况。这不仅不需要额外的内存，而且还可以非常方便地对结果进行后处理，甚至进行集成，以及计算各种性能指标和诊断图，稍后我们将会看到。

![](img/abfe8044104a9f08a207c38e86a954a5.png)

vaex.ml 中的所有模型包装器都是变形金刚。

最后，让我们将预测限制在模型训练数据的范围内。这样做是为了防止对一些奇异的特征值组合进行不实际或不切实际的持续时间估计。因此，让我们将任何小于 3 分钟的预测设置为 3，将任何大于 25 分钟的预测设置为 25。

![](img/46f5d89e14e24cbafd76c21030859843.png)

vaex.ml 模型包装器的输出是一个虚拟列，这使得后处理变得容易，或者用于创建诊断图或计算指标。

## 管道呢？

既然模型已经训练好了，我们想知道它在测试集上的表现如何。您可能已经注意到，与其他库不同，我们没有显式地创建一个管道来传播所有的数据清理和转换步骤。事实上，在 Vaex 中，当用户对数据进行探索和转换时，管道会自动创建。每个 Vaex 数据帧包含一个*状态*，它是一个可序列化的对象，包含应用于它的所有转换:过滤、创建新的虚拟列、列转换)。

回想一下，我们创建的所有特征，连同 PCA 变换的输出、缩放和预测模型输出，包括对预测的最终修补，都是虚拟列，因此存储在训练数据帧的状态中。因此，为了计算测试集上的预测，我们所需要做的就是将该状态应用于该测试集数据帧，并且所有的转换将被自动传播。

![](img/dc85aa1653395b1872d6748029c99856.png)

将来自训练的状态应用到测试集导致过滤器和虚拟列的自动传播。

状态也可以被序列化并从磁盘中读取，这大大简化了模型部署的任务。

![](img/a303cab7d717e2700450bbcdedd491e8.png)

Vaex 数据帧的状态很容易序列化并从磁盘中读取。这在部署模型时非常有用。

## 模型诊断

既然行程持续时间预测对于训练集和测试集都是可用的，那么让我们来计算一些性能指标。由于这是一个回归问题，我们将计算平均绝对误差和均方误差。

![](img/65e0f837d752e2f4b5d7a0fb44782df5.png)

计算训练集和测试集的绝对误差和均方差。

请注意，上图中显示的 4 个统计数据的计算花费了大约 4.5 分钟。考虑到计算需要评估所有特征，然后传递到模型以获得预测，这是非常令人印象深刻的，并且这是对训练集和测试集之间的超过 10 亿个样本进行的，超过两次。

在测试集上评估的平均绝对误差刚好超过 3.5 分钟。这是否是一个可以接受的错误，你也许应该咨询一下纽约市的出租车常客或出租车司机。我们不应该从表面上接受这样的统计数据，因此让我们创建两个诊断图。让我们画出实际行程持续时间与估计行程持续时间的分布，以及预测持续时间的绝对误差。

![](img/5402e9a5e1559c1935006dd684738597.png)

左图:测试集的实际行程持续时间与估计行程持续时间的密度图。右图:测试集的预测持续时间的绝对误差。

虽然我们看到实际和估计的出行持续时间之间有很强的相关性，但上图的左图也显示了模型估计值系统地偏向更高的值。一个潜在的原因是训练特征和目标变量的非高斯分布。也可能有一些异常值会对模型性能产生负面影响，尽管之前进行了过滤。另一方面，在估算出租车行程持续时间时，或许有点悲观也没那么糟糕。

右边的面板显示了每个绝对误差箱的跳闸次数。事实上，测试集中 77%的行程持续时间的绝对误差小于 5 分钟。虽然目前的模式可能是一个很好的起点，但仍有很大的改进空间。好消息是，有了 Vaex，我们有了一个工具，可以让我们发挥创造力，以令人难以置信的高效方式尝试许多功能和预处理组合。

说到模型，`SGDRegressor`的训练实例作为`IncrementalPredictor`的属性是很容易得到的。可以很容易地访问它，并且我们可以使用它来检查用于训练模型的特征的相对重要性。

![](img/7664c2e1e4e5cfaeba83ee52232bcfe3.png)![](img/ce81b5d59d58476d9532ee5c6e45944b.png)

用于定型模型的功能的相对重要性。

## 生产呢？

想象一下，我们设法消除了模型中的所有怪癖，并且在彻底验证之后，它已经准备好投入生产了。原则上，使用 Vaex 很容易做到这一点。所需要的只是将状态存储在生产环境中。然后，该状态可以很容易地应用于输入的 Vaex 数据帧，并且预测将很容易获得。

回想一下，状态不仅会记住所有创建的虚拟列，还会记住应用了哪些过滤器。因此，如果要查询某个样本的预测，而该样本是训练集的一部分时会被过滤掉，则在预测时也会被过滤掉，因此该样本会“消失”。实际上，样本不可能就这样丢失，许多生产案例要求我们总是返回至少某种预测，不管查询是什么。

为了克服这个障碍，我们可以利用这样一个事实，即在 Vaex 中，过滤后的数据帧实际上仍然包含所有的数据，加上一个定义哪些行被过滤掉，哪些行被保留的表达式。在其他常见的库中，比如 Numpy 和 Pandas，我们只能过滤掉更多的行，而在 Vaex 中，我们实际上可以通过在过滤器中使用“or”操作符来取回行。

让我们为我们的问题实现这个想法。我们将名为“生产”的变量添加到训练数据帧中，并将其值设置为`False`。然后，我们添加一个额外的过滤器，在这种情况下，它只是变量的值。然而，现在我们使用“or”而不是默认的“and”操作符，这种操作符在类似于`df3 = df2[df2.x < 5]`的情况下使用。想法很简单:如果最后一个过滤器被设置为`False`，它将不会对任何其他过滤器产生影响，因为它的操作模式是“或”。然而，如果它被设置为`True`，这可以通过修改“生产”变量的值来实现，它将使所有其他过滤器无效，因此任何数据点都可以通过。

![](img/40cc70010d3565e7a1ddeee6b827cd50.png)

如何借助 Vaex 数据帧中的变量启用或禁用过滤器的示例。

上面的代码块显示了我们如何包含和修改“production”变量，以便在需要时禁用过滤器。我们可以很容易地确认，在这种情况下，测试数据帧包含的样本数与我们执行训练/测试分割时一样多，并且对每个样本都有预测。在这种情况下，计算平均绝对误差给出了 13 分钟的较高结果，这并不奇怪，因为该模型没有经过良好的训练，无法为现在是测试集一部分的许多异常值或错误样本提供预测。

## 我们对未来的愿景

我希望我设法向您展示了使用 [Vaex](https://github.com/vaexio/vaex) 创建机器学习管道是多么容易和方便，即使训练数据超过 10 亿个样本，并占用超过 100 GB 的磁盘空间。我相信你会发现更多创造性的方法来使用 [Vaex](https://github.com/vaexio/vaex) 来改进本文中提出的模型，以及为各种其他问题和用例创建许多新的模型。

我们, [Vaex](https://github.com/vaexio/vaex) 团队相信，在未来，数据科学和机器学习可以通过免费和开源的工具方便高效地下载，即使是“大”数据。我们的目标是让 Vaex 更好地与 Python 数据科学堆栈的支柱相集成，并在[将 Vaex 和 scikit-learn 更紧密地结合在一起](https://github.com/scikit-learn/scikit-learn/pull/14963)方面投入了相当大的努力。敬请期待，肯定还有更精彩的东西往这边来！

数据科学快乐！