# 为我蹒跚学步的孩子制作一个播放视频的机器人

> 原文：<https://towardsdatascience.com/building-a-bot-that-plays-videos-for-my-toddler-597330d0005e?source=collection_archive---------17----------------------->

## 使用一个物体检测人工智能模型、一个游戏引擎、一个亚马逊 Polly 和一个在英伟达(NVIDIA)Jetson Nano 上运行的 Selenium automation 框架来构建 Qrio，这是一个可以说话、识别玩具并在 YouTube 上播放相关视频的机器人。

![](img/bac5e238645e18d87a90e55cec48361f.png)

我和我妻子有一个超级好奇的 21 个月大的男孩，名叫德歇。虽然他还不会说话，但他真的很喜欢指着东西让我们告诉他是什么。它可以是他最喜欢的书里的一张动物图片，他卡片上的一张汽车图片，或者只是一个玩具。我喜欢和他一起做这项活动，最近我一直在给他看描绘老虎、海豚、火车和其他有趣事物的视频。他真的很喜欢看一只真正的老虎如何走路、吼叫和社交，我认为这对他的认知发展有好处。

![](img/7c47c52970762a83b2be37291601d52b.png)

德协指着一个飞机的机翼，一条鲸鱼和一个拉面！

有一天，我想到给他造一个机器人，可以和他一起玩这个指点游戏。不要误解我的意思，我们的目标不是取代我们，而是补充我们，让他尽早接触技术。

# 概念

经过一段时间的头脑风暴，我清楚地知道我想要建造什么。这是一个有着狗的外形的聊天机器人，狗是德西最喜欢的动物。她的名字叫 Qrio，是“问题”和“好奇”两个词的混合。在我为他买玩具的一年半时间里，我观察了他一直玩的玩具和不玩的玩具，我发现玩具越能模仿他能与之建立联系的生物(在这种情况下是一只狗)，它成功的机会就越高。

为了最大限度地提高凝聚力，Qrio 以我们已故的爱犬百事可乐为模型，德克斯特在第一年就与百事可乐建立了关系。

![](img/a517cbcf1f4ff9c3457e9e2a76982475.png)

百事和 Qrio

Qrio 将能够看到 Dexie 走过，并对他说:‘嗨，Dexie！你想过来给我看看你的玩具吗？接下来，当德茜拿起一个飞机玩具给她看时，她会继续说‘嘿，那是一架飞机。‘我给你放一段关于飞机的视频’，然后找一段飞机视频给他播放。

# 研究

为了实现上述目标，Qrio 需要具备以下模块:

*   **视线**。Qrio 必须确认 Dexie 和他携带的玩具。为此，我需要一个连接到人工智能系统的摄像头，以检测德歇和他的玩具的存在和位置。需要建立一个经过训练可以识别人脸和玩具的物体检测人工智能模型，该模型将在连接到摄像头的 GPU 驱动的设备上运行。
*   **视觉存在**——以虚拟狗的形式出现，它将与德歇互动。它将由显示在显示器上的虚拟木偶系统驱动。
*   **语音**，这样 Qrio 就可以和他打招呼，让他拿起一个玩具，说出玩具的名字等等，这需要一个文本到语音的技术，显然还需要一个扬声器。
*   **视频搜索和播放**，这样 Qrio 就可以在 YouTube 上搜索并播放一个相关的视频。这将由自动化工具驱动。
*   **所有组件的协调者**。

经过一番认真的研究，我列出了运行该系统所需的硬件清单。

*   **NVIDIA Jetson Nano**(150 澳元)。这是一个微小的 GPU 驱动的嵌入式设备，将运行所有模块(特别是对象检测人工智能模型)。这是一个完美的工作设备，因为它可以通过一个简单的 HDMI 端口支持视频和音频输出，并且它有一个以太网端口，方便互联网接入。你甚至可以插入鼠标和键盘，在设备上进行开发和调试，因为它有一个功能齐全的 Ubuntu 18.04 操作系统。
*   **电视**(带 HDMI 输入和内置扬声器)(150 澳元)。这样 Dexie 就可以看到 Qrio，听到她在说什么，还可以播放 YouTube 视频。
*   **相机——索尼 IMX219** ($AUD 35)。这是一个令人敬畏的微型 800 万像素摄像头，使 Qrio 能够识别 Dexie 和他的玩具。画质超赞，价格惊人的便宜。

![](img/63155f9e624aa2e3c594e1b2744adcf5.png)

NVIDIA Jetson Nano 和索尼 IMX219 摄像头

# 履行

有了一个可靠的计划，我开始完成我的使命。

**建筑景观**

首先，需要开发和训练一个对象检测组件来识别特定的人脸和玩具。请记住，NVIDIA Jetson Nano 的 GPU 不如 1080Ti 等桌面级 GPU 卡强大，因此选择一种在准确性和性能之间取得良好平衡的对象检测模型架构至关重要。首先，我决定了我能接受的最低每秒帧数(FPS)。然后，我逆向工作，寻找可以在 Jetson Nano 上提供这种 FPS 的模型。我选择了 8 FPS，实际上，当视频处理、文本到语音、虚拟木偶戏渲染等同时运行时，它将下降到大约 5 FPS。每秒少于 5 次检测将显著降低获得高质量捕捉的机会，在高质量捕捉中，Dexie 的脸和他的玩具清晰可见。获胜的模型架构是[ssdlitemobilentv 2](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md)，它运行在 TensorFlow 1.8 [对象检测](https://github.com/tensorflow/models/tree/master/research/object_detection) API 上。

我只用了四个类来训练这个模型:一张人脸和三个 Dexie 的玩具(飞机、火车和熊猫)。所有训练集图像(每类 150 个图像)都是从使用同一台索尼 IMX219 摄像机记录的视频文件中生成的。为了最大限度地提高检测精度，并确保照明和背景是一致的，它们是在我将运行该系统的同一个客厅中拍摄的。这三个玩具都是从视频中手动、费力地贴上标签的。然而，为了保持理智，我使用了 [Amazon Rekognition](https://aws.amazon.com/rekognition/) ，这是一种现成的对象检测云服务，可以自动标记所有人脸。

![](img/f845096fabe973c2c34b7e831f591fbd.png)![](img/51d8875f79c0efd4d8ba78b7c1c66137.png)![](img/c6352f669ab70c48a85f56e6caf76104.png)

人脸和玩具检测训练装置

视频录制是使用 GStreamer 完成的，通过执行下面的命令就可以轻松完成。以低 FPS 录制会导致最终视频中出现明显的运动模糊，并产生低质量的训练集。因此，我将录制帧速率设置为 120 FPS，稍后使用视频编辑工具对其进行向下采样。记录尺寸设置为 720x540，这已经足够了，因为我们的对象检测模型只能在 300x300 像素上运行，任何更大的图像在训练和推断期间都会自动调整为 300x300 像素。

```
*gst-launch-1.0 nvarguscamerasrc num-buffers=120000 ! 'video/x-raw(memory:NVMM),width=720, height=540, framerate=120/1, format=NV12' ! omxh264enc  ! qtmux ! filesink location=out.mp4 -e*
```

我使用了 [EVA](https://github.com/Ericsson/eva) ，一个伟大的免费物体检测标签工具，你可以安装在本地，并可以导入一个视频文件作为图像源。

训练在五个小时内完成，使用的是在实现 mAP=0.8 的 P3.2XLarge (Pascal V100)上运行的 [AWS EC2 深度学习 AMI](https://aws.amazon.com/machine-learning/amis) 。Mean Average Precision (mAP)是一种用于评估对象检测性能的指标，通过计算在各种 iOU 阈值上平均的精度/召回曲线下的面积来进行。这需要一个完整的博客帖子来解释，所以我会简单地让你看一下[物体检测博客](https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173)的地图。否则，你只需要相信我，0.8 的贴图已经很好了，而且还可以通过聚合几帧的检测来进一步改进。

![](img/d293c18e092b54c99f6aa94509c94ee6.png)![](img/1d6c000f948b778f79cb7aca38480630.png)

培训统计

一旦你刷新了设备，在 NVIDIA Jetson Nano 上部署和运行这个模型是非常简单的(按照步骤[这里](https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit))，因为它运行的是全功能的 Ubuntu 18.04。我的意思是你可以安装 Tensorflow，Object Detection API 和所有的 Python 依赖项，就像在你的笔记本电脑或 PC 上一样。我使用 Tensorflow 1.8 是因为在写这篇博客的时候，由于缺少 contrib 依赖项，Tensorflow 2.0 不支持对象检测 API。

GStreamer 和 OpenCV 框架用于连接到摄像机并从摄像机获取视频。从那里，我们只需要将捕获的图像直接传递给我们的对象检测模型。请看这里的代码示例[。](https://github.com/msubzero2000/Qrio-public/blob/master/misc/objectDetectionOnJetsonNano.py)

我设法让物体检测以 10 FPS 的速度运行，这超过了我的最低要求 8 FPS——并且具有相当好的检测精度！

![](img/088325ac02b171f4b8d6654f2138f47d.png)

目标检测结果

**建立视觉存在**

获得正确的视觉呈现组件至关重要。Qrio 必须有吸引力，更重要的是，看起来足够像一只真实的，活着的狗，让 Dexie 想和她一起玩。她的眼睛需要能够直视德谢的脸，无论他在哪里。像一只正常的狗一样，当她不与德西互动时，她需要通过摇尾巴，移动头部和随意看方向来坐立不安。作为一名 3D 动画程序员，我在一家专门从事面部动画和虚拟木偶戏的电影特效公司工作了五年，在这五年的美好时光中，我学到了如此宝贵的技能，对此我感激不尽。我现在需要的只是一个游戏引擎！

几个小时的挖掘让我找到了这个叫做 arcade 的可怕的 Python 框架，它拥有我需要的一切。嗯……差不多，我稍后会讲到这个。它支持游戏动画循环，能够渲染/显示带有旋转和缩放的精灵(PNG 透明图像)。由于该框架基于 OpenGL，NVIDIA Jetson Nano 的速度性能应该非常出色，因为它将进行 GPU 加速。

![](img/d473a5e15dc37d806846c4f910b498a2.png)

街机 python 游戏引擎

为了让 Qrio 身体的各个部分(耳朵、眼球、眉毛、头和尾巴)既能独立运动又能作为一个群体运动，需要将单独的精灵组装起来(例如，移动头部也会移动耳朵、眉毛和眼球)。我需要建立一个骨骼动画系统(SAS ),它允许你将几个物体以层次关系连接在一起(例如，头部是身体的孩子，而耳朵、眼睛和眉毛是头部的孩子)。因此，当您对一个对象应用变换(旋转、平移或缩放)时，它也会影响它的所有子对象。

大多数游戏角色，人类，动物，怪物，就像下面动画中的一样，都是用 SAS 制作的。

![](img/5531fcb59e67e959792e155e222b1744.png)

全身骨骼动画系统

大多数游戏引擎原生支持 SAS 然而，街机没有。由于我找不到替代框架，我决定从头实现 SAS 功能，这实际上并不难。我需要做的第一件事是建立一个存储所有精灵(耳朵、头、眉毛等)的树形数据结构。)并根据它们的关系连接它们的关节。接下来是构建一个 SAS 分层转换函数。这涉及到一点三角学和矩阵。如果你热衷于了解数学细节，你可以在这个[博客](https://cseweb.ucsd.edu/classes/sp16/cse169-a/readings/2-Skeleton.html)中阅读。

下图展示了 Qrio 的 SAS。第一幅图像显示了如何使用精灵来定义每个身体部位，这些部位是按层次组合的，如下一幅图像所示。每个身体部位也将有一个定义为旋转中心的关节。最右边的图像显示了围绕其关节应用于右耳的变换(旋转),并且没有其他身体部位受到影响，因为右耳没有任何子体。下图描绘了围绕其关节应用于头部的旋转，它影响了眉毛、眼球和耳朵。注意标记显示右耳也相应地绕着头部关节旋转。

![](img/8f44105e6fecb517b999e43b2c723797.png)

Qrio 的骨骼动画系统

为了完成视觉呈现模块，我需要建立的下一个东西是一个坐立不安的动画系统，它是基于一个简单的[关键帧动画](https://www.tutorialspoint.com/computer_graphics/computer_animation.htm)。关键帧动画允许您通过提供对象的初始和最终变换(位置、缩放和旋转)以及动画的持续时间来设置对象(如头部)的动画。系统对从初始值到最终值的变换进行插值。接下来，我定义了几个坐立不安的动画，比如耳朵的上下运动，头尾的旋转，眼球和眉毛的运动。每一个小动作都用随机选取的值(旋转/平移)、持续时间和频率使相应的对象从一个变换到下一个变换产生动画，以便看起来更自然。

我花了几个小时调整坐立不安的动画参数，最终得到我想要的结果。

![](img/dd7a16c3dc7c6325ddf742dfb4df8ba8.png)

Qrio 的坐立不安动画系统

最后，我添加了一种方法来按需覆盖眼球和眉毛的位置，方法是手动提供它们的位置，这是头部跟踪逻辑在稍后阶段跟随 Dexie 的脸的位置所需要的。

**大厦演讲**

随着她的视力和视觉呈现模块的完成，她接下来需要的是语言能力。经过几个小时的研究，我能找到的最好的免费离线文本语音转换应用是 [pyttsx3](https://pypi.org/project/pyttsx3/) 。该引擎支持一些驱动程序，但 Ubuntu 上唯一可用的驱动程序是 espeak，它的语音质量最糟糕。这听起来像已故的斯蒂芬·霍金的轮椅(无意冒犯)。Dexie 目前正处于重复我们说的每一句话的阶段，我最不希望他学会那样说话。查看以下内容，做自己的评判。

ubuntu OS 上的 pyttsx3、espeak 驱动程序产生的音频质量不佳

放弃线下发行后，我开始寻找线上发行。我登陆了[亚马逊波利](https://aws.amazon.com/polly/)。玩了几分钟后，我完全被迷住了。语音质量提高了 100 倍，没有明显的延迟，尽管它需要通过互联网进行 API 调用，以生成并从云中下载结果音频文件。这最初是我主要关心的问题。生成 7 秒钟的音频文件只需要 200 毫秒。我知道这不是一个免费的解决方案。然而，它可以被大量缓存，因为 Qrio 最多只需要说出 50 个不同的句子，我们只需要支付 50 次亚马逊 Polly 呼叫(0.08 美分)。耶！！！

![](img/30d8157a86905dcd68ff6344f4594d19.png)

亚马逊波利

**建立视频搜索和播放**

正如我们之前讨论的，Qrio 需要能够在 YouTube 上搜索和播放特定的视频。最好的方法是使用自动化测试套件，它可以控制 web 浏览器在 YouTube 中执行搜索，并播放搜索结果中的视频。在这里，Selenium 自动化框架来拯救我们了！

![](img/77703a99917845c7205bc228636f9219.png)

Selenium 自动化框架

这是一个 QA 通常用来测试网站的工具。它允许您编写脚本来自动完成诸如在文本字段中键入内容、按下按钮等操作。你可以猜到，我将使用它来导航到 YouTube 网站，输入像 panda 这样的搜索词，然后自动点击搜索结果中的第一个视频，并按下全屏按钮以全屏播放它。首先，您需要为 Selenium 安装一个 Chromium-chrome 驱动程序，以便能够通过执行下面的 apt-get install 命令来控制 Chromium web 浏览器(Ubuntu 18.04 附带的原生浏览器)。

```
sudo apt-get install chromium-chromedriver
```

然后，您可以使用针对 Selenium 的 [python 绑定](https://pypi.org/project/selenium/)，从您的 Python 代码中以编程方式执行 Selenium 脚本。为了确保播放的视频对孩子是安全的，我用 YouTubeKids.com 而不是普通的 YouTube。这带来了一点复杂，因为每次 Selenium 启动时，您都必须通过一系列步骤来证明您是家长。然而，我设法编写了一个 Selenium 脚本，它可以自动完成这些步骤，并且只需要执行一次。

你可以在这里看到代码。

**构建协调器**

该模块充当协调器，将所有其他模块粘合在一起。协调器的一个关键部分是跟踪游戏当前状态的状态机。为什么我们需要一个状态机？以便我们在接收到相同的事件时可以根据我们当前所处的状态做出不同的决定。例如，如果之前 Qrio 还没有看到 Dexie，看到一个飞机玩具本身不应该触发播放 YouTube 视频的调用，因为它可能是玩具飞机就在沙发上的情况。在播放完飞机视频后看到一个飞机玩具应该会让 Qrio 说‘嘿，我们以前玩过飞机。“你为什么不给我带点别的东西来，”这样，我们可以避免让 Qrio 一遍又一遍地播放相同的视频，如果 Dexie 在它之前被识别并且视频播放被触发后继续持有飞机的话。

有四种主要状态——**空闲**、**占用**、**obec 识别**和**播放视频**——如下面的状态图所示。当系统处于除**播放视频**之外的任何状态时，它会定期调用坐立不安动画系统来制作 Qrio 坐立不安的动画，并与视觉模块核对以获取所有可识别物体的位置。系统从**空闲**状态启动，如果检测到 Dexie 至少 0.5 秒(以减少错误检测)，它将调用语音模块，说类似“嗨 Dexie，你想过来玩吗？”并将游戏状态设置为**参与**状态。

![](img/ceee89b1545f8cc8f8e8ef4889f04cc6.png)

Qrio 全状态机图

此外，如果在我们处于**参与**模式时，可以看到一个熊猫玩具，Qrio 会说‘嗨，Dexie。我想那是一只熊猫，将进入**物体识别**模式。如果熊猫玩具在另外两秒钟内仍然可见，Qrio 将切换到**播放视频**状态，将说“让我给你播放一段关于熊猫的视频”，并将调用视频搜索和播放模块来搜索熊猫视频并播放它。然而，如果我们最近播放了一段关于熊猫的视频，它会说‘嘿，我们以前和熊猫玩过。为什么不给我带点别的？视频将只全屏播放 45 秒，而视线和坐立不安动画系统暂停，以集中 CPU 资源播放流畅的视频。视频播放完成后，浏览器窗口隐藏，视线和坐立不安动画系统恢复。当 Dexie 在接合模式下 10 秒钟不可见时，协调器将重置状态为**空闲**。

您还可以看到，除了**播放视频**之外，在任何状态下，当面部可见时，都会调用头部跟踪模块，以使 Qrio 的眼球跟随面部边界框的中心点。

# 设置和校准

一切准备就绪后，我在客厅安装了系统，进行最后的校准和测试。

![](img/9403596eed0f6dd57adf7294b338ce59.png)![](img/ff3023f9cc9850c1561ce66eccde0c47.png)

Qrio 系统设置

初始化时，系统会顺利通过 YouTubeKids 的母授权。我看到 Qrio 的眼睛快速地跟随我的脸，这表明物体检测和头部跟踪逻辑工作得非常好。我注意到 NVIDIA Jetson Nano 已经被推到了极限，RAM 运行得非常低，设备变得非常热。这是完全可以理解的，因为它正在运行一个重型人工智能模型，仍然需要实时渲染游戏引擎，控制 Selenium 浏览器和解码视频。然而，整个系统似乎运行得很好，游戏引擎显示的基准为 5 FPS。

我现在需要的就是找个合适的时机把 Qrio 给 Dexie 看！

Qrio 系统校准和测试

# 表演时间

第一次看到 Qrio 的时候，是看着德谢的无价时刻。他好奇地冲向她，而 Qrio 在叫他，他站着不动，只是不相信地盯着她看了几秒钟。突然，他咯咯地笑了起来……我才知道我成功地通过了第一次测试——男孩和机器人的成功结合！

![](img/b1fa2536f73499ccebb008558bc54345.png)![](img/6c1e3cd76c10ed7470c6fb2326c8a4e3.png)![](img/f1da421c46aff5f31fb705b39d9c0919.png)

德歇第一次见到 Qrio

为了让他更加熟悉和舒适，我让他做任何他想做的事情，没有任何指导。他走向她，看着她坐立不安，摸着电视(以为他真的在摸她)，甚至叫她“小狗”。

接下来是关键时刻——测试实际的游戏玩法。举个例子，我让他看我给 Qrio 展示他的飞机玩具，她完美地认出了它，并说，“嘿，我想这是一架飞机。让我给你放一段关于飞机的录像。德协看到飞机视频开始播放的时候超级兴奋！

视频播放完一次，我把一个熊猫玩具递给了德协。他模仿我，把熊猫玩具给 Qrio 看，她再次搜索并播放了一段合适的视频！你可以在下面的视频中观看整个经历。

德西第一次看到并和 Qrio 一起玩

# 学习和未来改进

系统还不完善。尽管它在 80%的时间里能够识别玩具并播放正确的视频，但它仍然会时不时地失败——这没什么。最重要的是，我学到了很多关于什么可行，什么不可行，为下次类似的项目做准备。

**相机的 FOV**

大多数故障发生在 Dexie 站得离电视太近时，这超出了摄像机的可视范围。如下图所示，相机有一个 77 度的 FOV，放置在距离电视中等距离的位置，但不是很近(红色圆圈标记的区域)。同样的问题也发生在垂直覆盖中，当他坐在地板上时，摄像机看不到他举得很低的玩具。降低相机的焦距可以解决这个问题，但会带来相反的问题，即当他站在相机附近时，看不到他的脸。

![](img/6ba86440a48d6860697e509fe0df5317.png)

Qrio 的摄像头的水平盲点

![](img/5615cc5fb2a9a5d2801ce201a2bdde05.png)

Qrio 的相机的垂直盲点

解决这个问题的办法可能是买一台 FOV 更宽(120 度)的新相机，这样它可以覆盖更多的区域。然而，由于透镜失真，FOV 边缘周围的检测精度可能下降。

**可回放性**

到目前为止，Qrio sight 模块只对三个玩具进行了训练，并且总是为同一个玩具播放相同的视频。这只够娱乐德歇五分钟，直到他厌烦为止。因此，它具有低的可重复因子。我计划在未来增加对更多玩具的支持——如果我能鼓起勇气手动标记数以千计的额外图片的话。还可以添加一个随机化，从找到的前五个视频中随机选择，而不是总是选择第一个。

**更快的 FPS**

另一个需要改进的地方是游戏的 FPS。当视频搜索和播放模块执行 Selenium 脚本来控制 chromium 浏览器时，游戏以大约 5 FPS 的速度运行，偶尔会出现短暂的冻结和较长的冻结。你可能已经在上面的演示视频中发现了这一点。一个冻结的游戏引擎意味着 Qrio 停止移动，这不是那么好看。一个想法是将对象检测移到一个单独的线程中，这样它可以并发运行，而不会阻塞游戏引擎。同样的处理也可以应用于视频搜索和播放模块。然而，我们需要测试 OpenCV 和 Selenium 是否乐意在单独的线程上运行。除此之外，我还想测试一款更强大的设备，比如 NVIDIA Jetson NX T1，它可能更适合这种规模的项目。

就这样，伙计们！我希望你喜欢阅读我的令人兴奋的周末计划，就像我喜欢与你分享它一样。

完整的源代码可以在[这里](https://github.com/msubzero2000/Qrio-public/tree/master/qrio)找到。