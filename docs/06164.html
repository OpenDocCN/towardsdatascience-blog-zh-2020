<html>
<head>
<title>Implementing Autoencoders in the Fastai Library</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 Fastai 库中实现自动编码器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/autoencoders-in-the-fastai-library-fa288e1f899a?source=collection_archive---------68-----------------------#2020-05-18">https://towardsdatascience.com/autoencoders-in-the-fastai-library-fa288e1f899a?source=collection_archive---------68-----------------------#2020-05-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="1c27" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在 fastai 中实现自动编码器的分步指南。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/b30857e6290a443b253e4d52a1636886.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/1*1sfunl2TIRyaoKcQIEviPA.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">自动编码器架构。使用<a class="ae kr" href="https://alexlenail.me/NN-SVG/LeNet.html" rel="noopener ugc nofollow" target="_blank"> NN-SVG </a>制作的图像。</p></figure><h1 id="1a58" class="ks kt iq bd ku kv kw kx ky kz la lb lc jw ld jx le jz lf ka lg kc lh kd li lj bi translated">介绍</h1><p id="8b31" class="pw-post-body-paragraph lk ll iq lm b ln lo jr lp lq lr ju ls lt lu lv lw lx ly lz ma mb mc md me mf ij bi translated"><a class="ae kr" href="https://docs.fast.ai/index.html" rel="noopener ugc nofollow" target="_blank"> fastai </a>是一个深度学习库，它使用现代最佳实践来简化训练神经网络[1]。虽然 fastai 为用户提供了一个高级别的神经网络 API，但它旨在允许研究人员和用户轻松混合低级别的方法，同时仍然使整个训练过程变得简单易行。</p><p id="2c84" class="pw-post-body-paragraph lk ll iq lm b ln mg jr lp lq mh ju ls lt mi lv lw lx mj lz ma mb mk md me mf ij bi translated">这篇文章将讲述如何在 fastai 中设置一个自动编码器。这将通过创建一个基本的 autoencoder 模型，在 fastai 中设置数据，最后将所有这些放到一个学习者模型中。</p><p id="0ab2" class="pw-post-body-paragraph lk ll iq lm b ln mg jr lp lq mh ju ls lt mi lv lw lx mj lz ma mb mk md me mf ij bi translated"><em class="ml">注意:假设对 fastai 和 PyTorch 有基本的了解。</em></p><h1 id="7814" class="ks kt iq bd ku kv kw kx ky kz la lb lc jw ld jx le jz lf ka lg kc lh kd li lj bi translated">履行</h1><h2 id="26ab" class="mm kt iq bd ku mn mo dn ky mp mq dp lc lt mr ms le lx mt mu lg mb mv mw li mx bi translated">设置数据</h2><p id="0789" class="pw-post-body-paragraph lk ll iq lm b ln lo jr lp lq lr ju ls lt lu lv lw lx ly lz ma mb mc md me mf ij bi translated">自动编码器是一种神经网络，它通过架构中的某种瓶颈来学习重新创建输入。为此，我们需要一个输入和输出相等的 fastai 数据束。</p><p id="a95d" class="pw-post-body-paragraph lk ll iq lm b ln mg jr lp lq mh ju ls lt mi lv lw lx mj lz ma mb mk md me mf ij bi translated">在这里，我将给出一个使用图像数据实现这一点的示例，但是，还有一个更通用的示例，可以使用相应笔记本电脑上的任何可用阵列<a class="ae kr" href="https://github.com/henriwoodcock/blog-post-codes/blob/master/autoencoders-in-fastai/autoencoders-in-fastai.ipynb" rel="noopener ugc nofollow" target="_blank">在这里</a>。</p><p id="47e5" class="pw-post-body-paragraph lk ll iq lm b ln mg jr lp lq mh ju ls lt mi lv lw lx mj lz ma mb mk md me mf ij bi translated">导入数据集的代码如下:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="743f" class="mm kt iq mz b gy nd ne l nf ng">from fastai import *<br/>from fastai.vision import *</span><span id="2752" class="mm kt iq mz b gy nh ne l nf ng">size = 32<br/>batchsize = 32<br/>tfms = get_transforms(do_flip = True)<br/>src = (ImageImageList.from_folder(image_path).label_from_func(lambda x: x))<br/>data = (src.transform(tfms, size=size, tfm_y=True)<br/> .databunch(bs=batchsize)<br/> .normalize(imagenet_stats, do_y = False))</span></pre><p id="a949" class="pw-post-body-paragraph lk ll iq lm b ln mg jr lp lq mh ju ls lt mi lv lw lx mj lz ma mb mk md me mf ij bi translated">这与为分类器设置数据分组的两个区别是:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="7663" class="mm kt iq mz b gy nd ne l nf ng">ImageImageList()</span></pre><p id="133c" class="pw-post-body-paragraph lk ll iq lm b ln mg jr lp lq mh ju ls lt mi lv lw lx mj lz ma mb mk md me mf ij bi translated"><code class="fe ni nj nk mz b">ImageImageList</code>是一个内置的 fastai 列表，它将输入和输出数据都设置为图像。使用这种方法，我们仍然可以像使用<code class="fe ni nj nk mz b">show_batch</code>一样使用<strong class="lm ir">内置的 fastai 函数</strong>。</p><p id="cb5e" class="pw-post-body-paragraph lk ll iq lm b ln mg jr lp lq mh ju ls lt mi lv lw lx mj lz ma mb mk md me mf ij bi translated">第二个区别是标签的设置方式:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="a1b5" class="mm kt iq mz b gy nd ne l nf ng">label_from_func(lambda x: x)</span></pre><p id="7159" class="pw-post-body-paragraph lk ll iq lm b ln mg jr lp lq mh ju ls lt mi lv lw lx mj lz ma mb mk md me mf ij bi translated">这允许用户从定义的功能中设置标签。这里我们使用一个输出输入的函数。</p><p id="258d" class="pw-post-body-paragraph lk ll iq lm b ln mg jr lp lq mh ju ls lt mi lv lw lx mj lz ma mb mk md me mf ij bi translated">现在有了这些，我们可以运行:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="7e16" class="mm kt iq mz b gy nd ne l nf ng">data</span></pre><p id="bcb9" class="pw-post-body-paragraph lk ll iq lm b ln mg jr lp lq mh ju ls lt mi lv lw lx mj lz ma mb mk md me mf ij bi translated">哪些输出:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="52b3" class="mm kt iq mz b gy nd ne l nf ng">ImageDataBunch;</span><span id="9d80" class="mm kt iq mz b gy nh ne l nf ng">Train: LabelList (4800 items)<br/>x: ImageImageList<br/>Image (3, 32, 32),Image (3, 32, 32),Image (3, 32, 32),Image (3, 32, 32),Image (3, 32, 32)<br/>y: ImageList<br/>Image (3, 32, 32),Image (3, 32, 32),Image (3, 32, 32),Image (3, 32, 32),Image (3, 32, 32)<br/>Path: autoencoders-in-fastai/data;</span><span id="31da" class="mm kt iq mz b gy nh ne l nf ng">Valid: LabelList (1200 items)<br/>x: ImageImageList<br/>Image (3, 32, 32),Image (3, 32, 32),Image (3, 32, 32),Image (3, 32, 32),Image (3, 32, 32)<br/>y: ImageList<br/>Image (3, 32, 32),Image (3, 32, 32),Image (3, 32, 32),Image (3, 32, 32),Image (3, 32, 32)<br/>Path: autoencoders-in-fastai/data;</span><span id="3a66" class="mm kt iq mz b gy nh ne l nf ng">Test: None</span></pre><p id="6e9e" class="pw-post-body-paragraph lk ll iq lm b ln mg jr lp lq mh ju ls lt mi lv lw lx mj lz ma mb mk md me mf ij bi translated">运行 show_batch 给出:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="0179" class="mm kt iq mz b gy nd ne l nf ng">data.show_batch(rows = 1)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/97368709f62dfa444b1ded2484bd0e9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*CmVH0YXeik0rWKs8_R1Dsg.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated"><code class="fe ni nj nk mz b">data.show_batch(rows = 1) </code>输出。从<a class="ae kr" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> CIFAR10 数据集</a>中获取的图像。</p></figure><h2 id="eed0" class="mm kt iq bd ku mn mo dn ky mp mq dp lc lt mr ms le lx mt mu lg mb mv mw li mx bi translated">创建模型</h2><p id="b573" class="pw-post-body-paragraph lk ll iq lm b ln lo jr lp lq lr ju ls lt lu lv lw lx ly lz ma mb mc md me mf ij bi translated">我们现在需要创建一个自动编码器模型。这是通过创建 PyTorch 模块来实现的。下面是从<a class="ae kr" href="https://github.com/jellycsc/PyTorch-CIFAR-10-autoencoder/blob/master/main.py" rel="noopener ugc nofollow" target="_blank">这里</a>截取的一个基本例子。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="024d" class="mm kt iq mz b gy nd ne l nf ng">from torch import nn</span><span id="3cbf" class="mm kt iq mz b gy nh ne l nf ng">class Autoencoder(nn.Module):<br/>    def __init__(self):<br/>        super(Autoencoder, self).__init__()<br/>        # Input size: [batch, 3, 32, 32]<br/>        # Output size: [batch, 3, 32, 32]<br/>        self.encoder = nn.Sequential(<br/>            nn.Conv2d(3,12,4,stride=2,padding=1),<br/>            nn.ReLU(),<br/>            nn.Conv2d(12,24,4,stride=2,padding=1),<br/>            nn.ReLU(),<br/>            nn.Conv2d(24,48,4,stride=2,padding=1),<br/>            nn.ReLU(),<br/>            )<br/>        self.decoder = nn.Sequential(<br/>            nn.ConvTranspose2d(48,24,4,stride=2,padding=1),<br/>            nn.ReLU(),<br/>            nn.ConvTranspose2d(24,12,4,stride=2,padding=1),<br/>            nn.ReLU(),<br/>            nn.ConvTranspose2d(12,3,4,stride=2,padding=1),<br/>            nn.Sigmoid(),<br/>            )</span><span id="963a" class="mm kt iq mz b gy nh ne l nf ng">    def encode(self, x): return self.encoder(x)</span><span id="5d94" class="mm kt iq mz b gy nh ne l nf ng">    def decode(self, x): return self.decoder(x)</span><span id="0234" class="mm kt iq mz b gy nh ne l nf ng">    def forward(self, x):<br/>        encoded = self.encoder(x)<br/>        decoded = self.decoder(encoded)<br/>        return decoded</span></pre><h2 id="54f6" class="mm kt iq bd ku mn mo dn ky mp mq dp lc lt mr ms le lx mt mu lg mb mv mw li mx bi translated">创造快速学习者</h2><p id="ae88" class="pw-post-body-paragraph lk ll iq lm b ln lo jr lp lq lr ju ls lt lu lv lw lx ly lz ma mb mc md me mf ij bi translated">现在我们把所有这些放入一个快速学习器中。为此，你需要定义一个损失函数，在这个例子中，我将使用<em class="ml"> MSE 损失</em>。</p><p id="ae65" class="pw-post-body-paragraph lk ll iq lm b ln mg jr lp lq mh ju ls lt mi lv lw lx mj lz ma mb mk md me mf ij bi translated">为了实现这一点，我们首先创建一个 autoencoder 实例，如下所示:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="2acd" class="mm kt iq mz b gy nd ne l nf ng">autoencoder = Autoencoder()</span></pre><p id="0548" class="pw-post-body-paragraph lk ll iq lm b ln mg jr lp lq mh ju ls lt mi lv lw lx mj lz ma mb mk md me mf ij bi translated">然后我们把这个放入一个快速学习者中:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="b896" class="mm kt iq mz b gy nd ne l nf ng">import torch.nn.functional as F</span><span id="96fd" class="mm kt iq mz b gy nh ne l nf ng">learn = Learner(data, autoencoder, loss_func = F.mse_loss)</span></pre><p id="8a37" class="pw-post-body-paragraph lk ll iq lm b ln mg jr lp lq mh ju ls lt mi lv lw lx mj lz ma mb mk md me mf ij bi translated">现在我们已经做到了这一点，我们可以轻松地利用 fastai 中包含的所有最佳培训实践，如<code class="fe ni nj nk mz b">lr_find</code>和<code class="fe ni nj nk mz b">fit_one_cycle</code>。</p><h2 id="69fd" class="mm kt iq bd ku mn mo dn ky mp mq dp lc lt mr ms le lx mt mu lg mb mv mw li mx bi translated">培养</h2><p id="f7f6" class="pw-post-body-paragraph lk ll iq lm b ln lo jr lp lq lr ju ls lt lu lv lw lx ly lz ma mb mc md me mf ij bi translated">fastai 中实现的所有技术现在都可以在您的自定义 autoencoder 上使用。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="3e36" class="mm kt iq mz b gy nd ne l nf ng">learn.lr_find()<br/>learn.fit_one_cycle()</span></pre><h2 id="548d" class="mm kt iq bd ku mn mo dn ky mp mq dp lc lt mr ms le lx mt mu lg mb mv mw li mx bi translated">示例结果</h2><p id="357f" class="pw-post-body-paragraph lk ll iq lm b ln lo jr lp lq lr ju ls lt lu lv lw lx ly lz ma mb mc md me mf ij bi translated">使用 fastai 库，我在<a class="ae kr" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> CIFAR10 </a>的一个子集上训练了 10 个历元，使用<code class="fe ni nj nk mz b">lr_find</code>找到了一个最佳学习率和<code class="fe ni nj nk mz b">fit_one_cycle</code>，并取得了以下结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi nm"><img src="../Images/13065a79e4656e02cc72637d0987aa01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kn2-8ctPCpnZLJPaQBk5DQ.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">使用 fastai 文库的 10 个时期的结果。</p></figure><h1 id="376a" class="ks kt iq bd ku kv kw kx ky kz la lb lc jw ld jx le jz lf ka lg kc lh kd li lj bi translated">结论</h1><p id="7f5b" class="pw-post-body-paragraph lk ll iq lm b ln lo jr lp lq lr ju ls lt lu lv lw lx ly lz ma mb mc md me mf ij bi translated">在这里，我简单介绍了如何在 fastai 中实现自动编码器，您可以在这里找到笔记本<a class="ae kr" href="https://github.com/henriwoodcock/blog-post-codes/blob/master/autoencoders-in-fastai/autoencoders-in-fastai.ipynb" rel="noopener ugc nofollow" target="_blank">和</a>，其中包括所有代码以及如何为通用数组数据集实现它。一旦自动编码器经过训练，还有关于如何使用<em class="ml">编码器</em>和<em class="ml">解码器</em>部件的信息。</p><p id="b20e" class="pw-post-body-paragraph lk ll iq lm b ln mg jr lp lq mh ju ls lt mi lv lw lx mj lz ma mb mk md me mf ij bi translated">我在这里展示的 autoencoder 模型是一个非常简单的模型，有许多改进可以提及的是特征丢失、上采样而不是转置卷积以及最后的像素混洗。我发现这些在我自己的工作中非常有效。</p></div><div class="ab cl nr ns hu nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="ij ik il im in"><h1 id="a3b3" class="ks kt iq bd ku kv ny kx ky kz nz lb lc jw oa jx le jz ob ka lg kc oc kd li lj bi translated">参考</h1><p id="4587" class="pw-post-body-paragraph lk ll iq lm b ln lo jr lp lq lr ju ls lt lu lv lw lx ly lz ma mb mc md me mf ij bi translated">[1]杰瑞米·霍华德和西尔万·古格。_fastai:深度学习的分层 API。arXiv。https://arxiv.org/abs/2002.04688。2020.</p></div></div>    
</body>
</html>