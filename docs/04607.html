<html>
<head>
<title>Recommendation System Series Part 5: The 5 Variants of Multi-Layer Perceptron for Collaborative Filtering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">推荐系统系列之五:用于协同过滤的多层感知器的5种变体</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/recsys-series-part-5-neural-matrix-factorization-for-collaborative-filtering-a0aebfe15883?source=collection_archive---------15-----------------------#2020-04-24">https://towardsdatascience.com/recsys-series-part-5-neural-matrix-factorization-for-collaborative-filtering-a0aebfe15883?source=collection_archive---------15-----------------------#2020-04-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="5f4a" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">RecSys系列</h2><div class=""/><div class=""><h2 id="820a" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">将神经架构引入建议</h2></div><p id="1bb6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja"> <em class="lk">更新:</em> </strong> <em class="lk">本文是我探索学术界和工业界推荐系统系列文章的一部分。查看完整系列:</em> <a class="ae ll" rel="noopener" target="_blank" href="/recommendation-system-series-part-1-an-executive-guide-to-building-recommendation-system-608f83e2630a"> <em class="lk">第一部分</em> </a> <em class="lk">，</em> <a class="ae ll" rel="noopener" target="_blank" href="/recommendation-system-series-part-2-the-10-categories-of-deep-recommendation-systems-that-189d60287b58"> <em class="lk">第二部分</em> </a> <em class="lk">，</em> <a class="ae ll" rel="noopener" target="_blank" href="/recommendation-system-series-part-3-the-6-research-directions-of-deep-recommendation-systems-that-3a328d264fb7"> <em class="lk">第三部分</em> </a> <em class="lk">，</em> <a class="ae ll" rel="noopener" target="_blank" href="/recsys-series-part-4-the-7-variants-of-matrix-factorization-for-collaborative-filtering-368754e4fab5"> <em class="lk">第四部分</em> </a> <em class="lk">，</em> <a class="ae ll" rel="noopener" target="_blank" href="/recsys-series-part-5-neural-matrix-factorization-for-collaborative-filtering-a0aebfe15883"> <em class="lk">第五部分</em> </a> <em class="lk">和</em> <a class="ae ll" rel="noopener" target="_blank" href="/recommendation-system-series-part-6-the-6-variants-of-autoencoders-for-collaborative-filtering-bd7b9eae2ec7"/></p><p id="c576" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">协同过滤算法是推荐系统应用中最常用的算法。由于互联网的使用和产生的大量信息，用户找到他们的偏好变成了一项非常乏味的任务。用户对项目的偏好以评分矩阵的形式表示，用于建立用户和项目之间的关系，以找到用户的相关项目。因此，目前的协同过滤算法面临着大数据集和评分矩阵稀疏的问题。</p><p id="4c33" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在各种协同过滤技术中，<a class="ae ll" rel="noopener" target="_blank" href="/recsys-series-part-4-the-7-variants-of-matrix-factorization-for-collaborative-filtering-368754e4fab5">矩阵分解</a>是最流行的一种，它将用户和项目投影到一个共享的潜在空间，用一个潜在特征向量来表示一个用户或一个项目。之后，用户对一个项目的交互被建模为他们潜在向量的内积。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lm"><img src="../Images/bf7a9cb23d0d0eaef7c7c94bc73a2833.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hEdT52pNv-uIWhLmM5ka7A.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated"><em class="mc">Kiran Shivlingkar—Spotify发现算法如何工作(</em><a class="ae ll" href="https://blog.prototypr.io/how-spotify-discovery-algorithm-works-fae8f63466ab" rel="noopener" target="_blank"><em class="mc">https://blog . prototypr . io/How-Spotify-Discovery-Algorithm-Works-fae8f 63466 ab</em></a><em class="mc">)</em></p></figure><p id="7df2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">尽管矩阵分解对于协同过滤是有效的，但是众所周知，它的性能会受到交互作用函数的简单选择的阻碍:内积。例如，对于对显式反馈的评级预测的任务，众所周知，矩阵分解模型的性能可以通过将用户和项目偏好项合并到交互函数中来提高。虽然对于内积运算符来说，这似乎只是一个微不足道的调整，但它指出了设计一个更好的、专用的交互函数来建模用户和项目之间的潜在功能交互的积极效果。简单地线性组合潜在特征的乘积的内积可能不足以捕获用户交互数据的复杂结构。</p><p id="fe7b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在这篇文章和接下来的文章中，我将介绍推荐系统的创建和训练，因为我目前正在做这个主题的硕士论文。</p><ul class=""><li id="a435" class="md me iq kq b kr ks ku kv kx mf lb mg lf mh lj mi mj mk ml bi translated"><a class="ae ll" rel="noopener" target="_blank" href="/recommendation-system-series-part-1-an-executive-guide-to-building-recommendation-system-608f83e2630a">第1部分</a>提供了推荐系统的高级概述，它们是如何构建的，以及它们如何用于改善各行业的业务。</li><li id="1645" class="md me iq kq b kr mm ku mn kx mo lb mp lf mq lj mi mj mk ml bi translated"><a class="ae ll" rel="noopener" target="_blank" href="/recommendation-system-series-part-2-the-10-categories-of-deep-recommendation-systems-that-189d60287b58">第2部分</a>提供了关于这些模型的优势和应用场景的正在进行的研究计划的仔细回顾。</li><li id="6493" class="md me iq kq b kr mm ku mn kx mo lb mp lf mq lj mi mj mk ml bi translated"><a class="ae ll" rel="noopener" target="_blank" href="/recommendation-system-series-part-3-the-6-research-directions-of-deep-recommendation-systems-that-3a328d264fb7">第3部分</a>提供了几个可能与推荐系统学者社区相关的研究方向。</li><li id="5dfe" class="md me iq kq b kr mm ku mn kx mo lb mp lf mq lj mi mj mk ml bi translated"><a class="ae ll" rel="noopener" target="_blank" href="/recsys-series-part-4-the-7-variants-of-matrix-factorization-for-collaborative-filtering-368754e4fab5">第4部分</a>提供了可以构建的矩阵分解的7种变体的本质数学细节:从使用巧妙的侧面特征到应用贝叶斯方法。</li></ul><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi mr"><img src="../Images/eefa44fb1f4f4e980233b35a6a697e7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lrj-BgrJWKUuIUQu8ZFDCg.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated"><em class="mc">阿汉·莫汉提— MLP真实世界银行数据模型(</em><a class="ae ll" href="https://becominghuman.ai/multi-layer-perceptron-mlp-models-on-real-world-banking-data-f6dd3d7e998f" rel="noopener ugc nofollow" target="_blank"><em class="mc">https://becoming human . ai/multi-layer-perceptron-MLP-Models-on-Real-World-Banking-Data-f6dd 3d 7 e 998 f</em></a><em class="mc">)</em></p></figure><p id="a1ba" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在第5部分中，我探索了使用<strong class="kq ja">多层感知器</strong>进行协同过滤。多层感知器是一种前馈神经网络，在输入层和输出层之间有多个隐藏层。它可以解释为非线性变换的堆叠层，用于学习等级要素制图表达。这是一个简洁但实用的网络，可以将任何可测量的函数逼近到任何期望的精确度(这种现象被称为<strong class="kq ja">通用逼近定理</strong>)。因此，它是许多高级方法的基础，并被广泛应用于许多领域。</p><p id="4fee" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">更具体地说，我将浏览5篇将多层感知器整合到推荐框架中的论文。</p><h1 id="0881" class="ms mt iq bd mu mv mw mx my mz na nb nc kf nd kg ne ki nf kj ng kl nh km ni nj bi translated">1 —广泛而深入的学习</h1><p id="7023" class="pw-post-body-paragraph ko kp iq kq b kr nk ka kt ku nl kd kw kx nm kz la lb nn ld le lf no lh li lj ij bi translated">记忆和归纳对于推荐系统都是至关重要的。谷歌的论文“<a class="ae ll" href="https://arxiv.org/pdf/1606.07792.pdf" rel="noopener ugc nofollow" target="_blank">推荐系统的广泛和深度学习</a>”(2016)提出了一个结合广泛线性模型和深度神经网络的优势的框架，以解决这两个问题。该框架已经在大规模商业应用商店Google Play的推荐系统上进行了生产和评估。</p><p id="c581" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如下图所示，<strong class="kq ja">宽学习</strong>组件是一个单层感知器，可以使用叉积特征变换有效记忆稀疏特征交互。<strong class="kq ja">深度学习</strong>组件是一个多层感知器，可以通过低维嵌入归纳到以前看不到的特征交互。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi np"><img src="../Images/5151573ce3222149fa74023857fcabb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sseHpVu9c1BcMLcgTY2tkA.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated"><em class="mc">Google Inc .—&amp;深度学习推荐系统(</em><a class="ae ll" href="https://arxiv.org/pdf/1606.07792.pdf" rel="noopener ugc nofollow" target="_blank"><em class="mc">https://arxiv.org/pdf/1606.07792.pdf</em></a><em class="mc">)</em></p></figure><p id="d550" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">从数学上来说，广泛学习被定义为:</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/c681cff243e1484c359e3754c1fbf3c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:530/format:webp/1*ZEr1d88hZ1uhBUXHEwcBEw.png"/></div></figure><p id="3d1f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">其中y是预测值，x是特征向量，W是模型参数向量，b是偏差。特征集包括原始输入和转换输入(通过叉积转换来获取特征之间的相关性)。</p><p id="604c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在深度学习组件中，每个隐藏层执行以下计算:</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/3451f54e262d190edb554a6e6e256369.png" data-original-src="https://miro.medium.com/v2/resize:fit:742/format:webp/1*MKGeXWitcxPceRdOWSeGRg.png"/></div></figure><p id="1fdb" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">其中l是层数，f是激活函数，a_l是激活向量，b_l是偏差向量，W_l是第l层的模型权重向量。</p><p id="c844" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">通过融合这些模型来获得广泛和深度的学习模型:</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi ns"><img src="../Images/1741e1d636b6023f66ed683c0de9f361.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zFZvCeFvn6cZN2T2P7HqbQ.png"/></div></div></figure><p id="47f7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">其中Y是二进制类标签，W_{wide}是所有宽模型权重的向量，W_{deep}是应用于最终激活a_{last}的权重的向量，b是偏差项。</p><p id="1ed6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们看看这在代码中是什么样子的:</p><figure class="ln lo lp lq gt lr"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="db13" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这种方法的完整PyTorch实现可以在这里查看:<a class="ae ll" href="https://github.com/khanhnamle1994/transfer-rec/tree/master/Multilayer-Perceptron-Experiments/Wide-and-Deep-PyTorch" rel="noopener ugc nofollow" target="_blank">https://github . com/khanhnamle 1994/transfer-rec/tree/master/multi layer-Perceptron-Experiments/Wide-and-Deep-py torch</a>。</p><h1 id="b7f1" class="ms mt iq bd mu mv mw mx my mz na nb nc kf nd kg ne ki nf kj ng kl nh km ni nj bi translated">2-深度因子分解机器</h1><p id="451e" class="pw-post-body-paragraph ko kp iq kq b kr nk ka kt ku nl kd kw kx nm kz la lb nn ld le lf no lh li lj ij bi translated">作为宽深度学习方法的扩展，由Huifeng Guo等人提出的“<a class="ae ll" href="https://arxiv.org/pdf/1703.04247.pdf" rel="noopener ugc nofollow" target="_blank"> DeepFM:一个基于因子分解机的神经网络用于CTR预测</a>”(2017)是一个端到端的模型，无缝集成了<strong class="kq ja">因子分解机</strong>(宽组件)和<strong class="kq ja">多层感知器</strong>(深度组件)。与宽和深模型相比，DeepFM不需要繁琐的特征工程。</p><p id="08ed" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如下图所示，因式分解机器利用加法和内积运算来捕获特征之间的线性和成对交互。多层感知器利用非线性激活和深层结构来模拟高阶交互。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/aa721942fd8b0f135038ff7ab9fd1848.png" data-original-src="https://miro.medium.com/v2/resize:fit:890/format:webp/1*MbGYi2awAntyVYW0JPNNJA.png"/></div><p class="ly lz gj gh gi ma mb bd b be z dk translated"><em class="mc">郭慧峰等——DeepFM:一种基于因子分解机器的CTR预测神经网络(</em><a class="ae ll" href="https://arxiv.org/pdf/1703.04247.pdf" rel="noopener ugc nofollow" target="_blank"><em class="mc">)</em></a><em class="mc">)</em></p></figure><p id="0b55" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">从数学上来说，DeepFM的输入是一个m-fields数据，由(u，I)对组成，它们是用户和项目的身份和特征，以及一个表示用户点击行为的二进制标签y(y = 1表示用户点击了项目，否则y = 0)。这里的任务是建立一个预测模型，以估计用户在给定的上下文中点击特定应用程序的概率。</p><p id="6c17" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">对于任何特定的特征I，标量w_i用于衡量其一阶重要性，潜在向量V_i用于衡量其与其他特征的相互作用的影响。将V_i馈入宽分量以模拟二阶特征相互作用，馈入深分量以模拟高阶特征相互作用。包括w_i、V_i和网络参数在内的所有参数被联合训练用于组合预测模型:</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/923ed0819e4b19951871755607b27ce4.png" data-original-src="https://miro.medium.com/v2/resize:fit:824/format:webp/1*8YgAjeMUgUgTqO21yD2iaQ.png"/></div></figure><p id="ae6c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">其中y_hat是预测的CTR(在0和1之间)，y_{FM}是宽因式分解机组件的输出，y_{DNN}是多层感知器组件的输出。</p><p id="d873" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在宽分量中，除了特征之间的线性(一阶)交互之外，因子分解机器将成对(二阶)特征交互建模为各个特征潜在向量的内积。当数据集稀疏时，这有助于非常有效地捕捉二阶特征交互。因式分解机的输出是一个加法单元和几个内积单元的和:</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi nx"><img src="../Images/c4caa121720cb915ab76f5b4e2b1eb78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c4pH-Wi5TKNgV0eIwUNyDQ.png"/></div></div></figure><p id="ced0" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">对于给定的特征I和j，加法单位(第一项)反映一阶特征的重要性，内积单位(第二项)表示二阶特征相互作用的影响。</p><p id="a090" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在深层组件中，多层感知器的输出如下所示:</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/df9327b4299c596ebe049a28757d195c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*-z2UiFD57Y3cwoEC75lgpg.png"/></div></figure><p id="5df2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">其中|H|是隐藏层的数量，a是嵌入层的向量输出，W是模型权重的向量，b是偏差单元的向量。</p><p id="a6aa" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们看看这在代码中是什么样子的:</p><figure class="ln lo lp lq gt lr"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="1cc5" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这种方法的完整PyTorch实现可以在这里查看:<a class="ae ll" href="https://github.com/khanhnamle1994/transfer-rec/tree/master/Multilayer-Perceptron-Experiments/DeepFM-PyTorch" rel="noopener ugc nofollow" target="_blank">https://github . com/khanhnamle 1994/transfer-rec/tree/master/multi layer-Perceptron-Experiments/DeepFM-py torch</a>。</p><h1 id="4d13" class="ms mt iq bd mu mv mw mx my mz na nb nc kf nd kg ne ki nf kj ng kl nh km ni nj bi translated">3-极端深度因式分解机器</h1><p id="8860" class="pw-post-body-paragraph ko kp iq kq b kr nk ka kt ku nl kd kw kx nm kz la lb nn ld le lf no lh li lj ij bi translated">作为深度因子分解机的扩展，简训廉等人的《<a class="ae ll" href="https://arxiv.org/pdf/1803.05170.pdf" rel="noopener ugc nofollow" target="_blank"> xDeepFM:结合显式和隐式特征交互的推荐系统</a>》(2018)可以对显式和隐式特征交互进行联合建模。<strong class="kq ja">显式</strong>高阶特征交互通过<strong class="kq ja">压缩交互网络</strong> k学习，而<strong class="kq ja">隐式</strong>高阶特征违反通过多层<strong class="kq ja">感知器</strong>学习。该模型也不需要人工特征工程，并且将数据科学家从繁琐的特征搜索工作中解放出来。</p><p id="b03a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">压缩交互网络的设计考虑了以下因素:</p><ol class=""><li id="0e0e" class="md me iq kq b kr ks ku kv kx mf lb mg lf mh lj nz mj mk ml bi translated">交互应用于向量级，而不是位级。</li><li id="827c" class="md me iq kq b kr mm ku mn kx mo lb mp lf mq lj nz mj mk ml bi translated">高阶特征相互作用被明确地测量。</li><li id="2263" class="md me iq kq b kr mm ku mn kx mo lb mp lf mq lj nz mj mk ml bi translated">网络的复杂性不会随着相互作用的程度呈指数增长。</li></ol><p id="0ef7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">压缩交互网络的结构非常类似于递归神经网络，其中下一个隐藏层的输出依赖于最后一个隐藏层和附加输入。各层嵌入向量的结构保持现状；因此，相互作用应用于向量水平。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi oa"><img src="../Images/b71d762ddbd3e1dec3a5c3d7fa34cb58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tTg9m6XwlHNENLfVTrPu-w.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated"><em class="mc">简训廉等——xDeepFM:结合显式和隐式特征交互的推荐系统(</em><a class="ae ll" href="https://arxiv.org/pdf/1803.05170.pdf" rel="noopener ugc nofollow" target="_blank"><em class="mc">)</em></a><em class="mc">)</em></p></figure><ul class=""><li id="778b" class="md me iq kq b kr ks ku kv kx mf lb mg lf mh lj mi mj mk ml bi translated">看上面的图4a，中间张量Z^{k+1}是沿着隐藏层x^k和原始特征矩阵x⁰.的每个嵌入维度的外积计算每个隐藏层x^k的过程与计算机视觉中众所周知的卷积神经网络有很强的联系。在这里，Z^{k+1}可以被视为一种特殊类型的图像，而W^{k，h}是一个过滤器。</li><li id="ac79" class="md me iq kq b kr mm ku mn kx mo lb mp lf mq lj mi mj mk ml bi translated">如图4b所示，作者沿着嵌入维度将过滤器滑过Z^{k+1}，得到了一个隐藏向量x^{k+1}——这在计算机视觉中通常被称为特征图。因此，x^k是H_k个不同特征地图的集合。</li><li id="62e7" class="md me iq kq b kr mm ku mn kx mo lb mp lf mq lj mi mj mk ml bi translated">图4c提供了压缩交互网络架构的概述。设T表示网络的深度。X^k的每个隐藏层都与输出单元有联系。作者在隐藏层的每个特征图上应用和池，并为第k个隐藏层获得长度为H_k的池向量p^k。隐藏层的所有池向量在连接到输出单元之前被连接:p+ = [p，p，…，p^T]</li></ul><p id="0a5e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">xDeepFM通过广度和深度学习框架将上述压缩的交互网络与简单的多层感知器相结合。一方面，该模型既包括低阶特征交互，也包括高阶特征交互；另一方面，它还包含隐式和显式的特征交互。这里显示了架构。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi ob"><img src="../Images/e04ddc657f7b79bce4afb9b91fb4b3ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ILllpalSLYzevkxnx1W5gQ.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated"><em class="mc">简训廉等xDeepFM:结合显式和隐式特征交互的推荐系统(</em><a class="ae ll" href="https://arxiv.org/pdf/1803.05170.pdf" rel="noopener ugc nofollow" target="_blank"><em class="mc"/></a><em class="mc">)</em></p></figure><p id="a07e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">从数学上来说，产生的输出单位是:</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi oc"><img src="../Images/9c84452c261d90f5605bb7e7465c7619.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nCtIJ8aCDtGqSN41bqupLw.png"/></div></div></figure><p id="cf57" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">其中a是原始特征的向量，x_{mlp}是普通多层感知器的输出向量，p+是交叉交互网络的输出向量。w和b是可学习的参数，分别是权重和偏差。</p><p id="06ab" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们看看这在代码中是什么样子的:</p><figure class="ln lo lp lq gt lr"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="5d0f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这种方法的完整PyTorch实现可以在这里查看:<a class="ae ll" href="https://github.com/khanhnamle1994/transfer-rec/tree/master/Multilayer-Perceptron-Experiments/xDeepFM-PyTorch" rel="noopener ugc nofollow" target="_blank">https://github . com/khanhnamle 1994/transfer-rec/tree/master/multi layer-Perceptron-Experiments/xDeepFM-py torch</a></p><h1 id="c357" class="ms mt iq bd mu mv mw mx my mz na nb nc kf nd kg ne ki nf kj ng kl nh km ni nj bi translated">4-神经分解机器</h1><p id="6b5a" class="pw-post-body-paragraph ko kp iq kq b kr nk ka kt ku nl kd kw kx nm kz la lb nn ld le lf no lh li lj ij bi translated">另一个无缝集成因子分解机器和多层感知机的并行工作是Xiangnan He和Tat-Seng Chua的“<a class="ae ll" href="https://arxiv.org/pdf/1708.05027.pdf" rel="noopener ugc nofollow" target="_blank">用于稀疏预测分析的神经因子分解机器</a>”(2017)。该模型将线性因式分解机器的有效性与非线性神经网络的强大表示能力结合起来，用于稀疏预测分析。</p><p id="b743" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如下所示，其架构的关键是一种称为<strong class="kq ja">双线性交互池</strong>的操作，它允许神经网络模型在较低级别学习更多信息的功能交互。通过在双线性交互层上堆叠非线性层，作者能够深化浅层线性因式分解机，有效地建模高阶和非线性特征交互，以提高因式分解机的表达能力。与简单连接或平均低层嵌入向量的传统深度学习方法相比，双线性交互池的这种使用编码了更多信息的特征交互，极大地促进了后续“深度”层学习有意义的信息。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi od"><img src="../Images/0350b043aa075c2dcdb0cef0fdcd2200.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vRQm_b9VkGbEt7xGC8Mrwg.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">【https://arxiv.org/pdf/1708.05027.pdf】<em class="mc"/></p></figure><p id="a85d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们深入研究神经分解机器模型的数学。给定稀疏向量x作为输入，模型估计目标为:</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/06024c4f9858efcb1d52c69e9624eed6.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*KqyKC8FB0UNSXzVyu_t7wA.png"/></div></figure><p id="d86b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">其中第一项模拟特征数据的全局偏差，第二项模拟特征权重的全局偏差，第三项f(x)是模拟特征交互的多层感知器(如图2所示)。f(x)的设计由这些层组件组成:</p><h2 id="b644" class="of mt iq bd mu og oh dn my oi oj dp nc kx ok ol ne lb om on ng lf oo op ni iw bi translated">嵌入层</h2><p id="3695" class="pw-post-body-paragraph ko kp iq kq b kr nk ka kt ku nl kd kw kx nm kz la lb nn ld le lf no lh li lj ij bi translated">这是一个完全连通的图层，将每个要素投影到密集矢量表示中。设v_i为第I个特征的嵌入向量。然后在嵌入步骤之后，作者获得一组嵌入向量来表示输入特征向量x。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/cdb09ebff97b423e895816d0e472200f.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*yXP-dEunysAAX5TKvKyicg.png"/></div></figure><p id="e23e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">由于x的可能的稀疏表示，作者仅包括非零特征的嵌入向量，其中x_i不等于0。</p><h2 id="e81c" class="of mt iq bd mu og oh dn my oi oj dp nc kx ok ol ne lb om on ng lf oo op ni iw bi translated">双线性相互作用层</h2><p id="a6d8" class="pw-post-body-paragraph ko kp iq kq b kr nk ka kt ku nl kd kw kx nm kz la lb nn ld le lf no lh li lj ij bi translated">然后，嵌入集V_x被馈送到双线性交互层，双线性交互层是将一组嵌入向量转换成一个向量的汇集操作:</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi or"><img src="../Images/b831d7dcda645381ca625a5813fd214e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*uwBZHOhOwS5eNp8PppYgmg.png"/></div></figure><p id="0eea" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">其中v_i.x_j表示两个向量v_i和x_j的按元素的乘积，该汇集的输出是k维向量，其编码嵌入空间中特征之间的二阶交互。</p><h2 id="ee0c" class="of mt iq bd mu og oh dn my oi oj dp nc kx ok ol ne lb om on ng lf oo op ni iw bi translated">隐藏层</h2><p id="04bd" class="pw-post-body-paragraph ko kp iq kq b kr nk ka kt ku nl kd kw kx nm kz la lb nn ld le lf no lh li lj ij bi translated">双线性交互池层之上是一堆完全连接的层，这些层能够学习要素之间的高阶交互。这些隐藏层的定义是:</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi os"><img src="../Images/b1cd749fe0c85338ffa754f91521df46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*BoDgzsqGPrb5h229PBNYLA.png"/></div></figure><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/c9f48b192b74c0fde2a535ee2f88aa74.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*PSm3_mm6_UVPrIyjf_cvdQ.png"/></div></figure><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/67843849ab300ffa8dd79d98fdde7255.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*KiMXWqbhmKCF6VfIjRrQtA.png"/></div></figure><p id="a73d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">其中L是隐藏层数；W_L、b_L和activation_L分别对应于第L层的权重矩阵、偏置向量和激活函数。激活函数的选择可以是sigmoid、tanh或ReLU，以非线性地学习高阶特征交互。</p><h2 id="2d33" class="of mt iq bd mu og oh dn my oi oj dp nc kx ok ol ne lb om on ng lf oo op ni iw bi translated">预测层</h2><p id="0f57" class="pw-post-body-paragraph ko kp iq kq b kr nk ka kt ku nl kd kw kx nm kz la lb nn ld le lf no lh li lj ij bi translated">最后，最后一个隐藏层z_L的输出向量被转换成最终预测分数:</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/ad3d60d4e285b06ca7492f215c631aa5.png" data-original-src="https://miro.medium.com/v2/resize:fit:442/format:webp/1*ZIczdhClab-mlaGnZSjAwA.png"/></div></figure><p id="3075" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">其中h^T表示预测层的神经元权重。</p><p id="e19f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们看看这在代码中是什么样子的:</p><figure class="ln lo lp lq gt lr"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="1432" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这种方法的完整PyTorch实现可以在这里查看:<a class="ae ll" href="https://github.com/khanhnamle1994/transfer-rec/tree/master/Multilayer-Perceptron-Experiments/Neural-FM-PyTorch" rel="noopener ugc nofollow" target="_blank">https://github . com/khanhnamle 1994/transfer-rec/tree/master/multi layer-Perceptron-Experiments/Neural-FM-py torch</a></p><h1 id="801a" class="ms mt iq bd mu mv mw mx my mz na nb nc kf nd kg ne ki nf kj ng kl nh km ni nj bi translated">5 —神经协同过滤</h1><p id="42f6" class="pw-post-body-paragraph ko kp iq kq b kr nk ka kt ku nl kd kw kx nm kz la lb nn ld le lf no lh li lj ij bi translated">向南和等人的论文“<a class="ae ll" href="https://www.comp.nus.edu.sg/~xiangnan/papers/ncf.pdf" rel="noopener ugc nofollow" target="_blank">神经协同过滤</a>”(2018)将多层感知器用于从数据中学习交互函数的应用又推进了一步。这里注意，他们也是上面提到的神经因子分解机器论文的同一作者。他们形式化了一种协作过滤的建模方法，这种方法专注于<strong class="kq ja">隐式反馈</strong>，它通过观看视频、购买产品和点击商品等行为间接反映用户的偏好。与评分和评论等显性反馈相比，隐性反馈可以被自动跟踪，因此对于内容提供商来说，收集隐性反馈要自然得多。然而，利用它更具挑战性，因为没有观察到用户满意度，并且存在负面反馈的固有稀缺性。</p><p id="3b47" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">用于模拟用户隐式反馈的用户-项目交互值y_ui可以是1或0。值1指示在用户u和项目I之间存在交互，但是这并不意味着u喜欢I。这在从隐式数据中学习时提出了挑战，因为它仅提供关于用户偏好的噪声信号。虽然观察到的条目至少反映了用户对项目的兴趣，但未观察到的条目可能只是缺失的数据，并且负面反馈自然很少。</p><p id="d1d2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">作者采用多层表示来建模用户-项目交互y_ui，如下所示，其中一层的输出作为下一层的输入。</p><ul class=""><li id="352a" class="md me iq kq b kr ks ku kv kx mf lb mg lf mh lj mi mj mk ml bi translated">底部的<strong class="kq ja">输入层</strong>由2个描述用户u和物品I的特征向量组成，可以定制以支持用户和物品的广泛建模。特别地，本文仅使用用户和物品的身份作为输入特征，通过一键编码将其转换为二值化的稀疏向量。有了这样一个输入的通用特征表示，通过使用内容特征来表示用户和项目，可以很容易地调整这个框架来解决冷启动问题。</li><li id="df6d" class="md me iq kq b kr mm ku mn kx mo lb mp lf mq lj mi mj mk ml bi translated">在输入层之上是<strong class="kq ja">嵌入层</strong>——一个将稀疏表示投影到密集向量的全连接层。在潜在因素模型的上下文中，所获得的用户/项目嵌入可以被视为用户/项目的潜在向量。</li><li id="c821" class="md me iq kq b kr mm ku mn kx mo lb mp lf mq lj mi mj mk ml bi translated">用户嵌入和项目嵌入然后被馈送到多层神经架构(称为<strong class="kq ja">神经协同过滤层</strong>)以将潜在向量映射到预测分数。神经协同过滤层的每一层都可以被定制以发现用户-项目交互的特定潜在结构。最后一个隐藏层X的尺寸决定了模型的能力。</li><li id="6041" class="md me iq kq b kr mm ku mn kx mo lb mp lf mq lj mi mj mk ml bi translated">最终的<strong class="kq ja">输出层</strong>为预测得分y-hat_ui，通过最小化y-hat_ui与其目标值y_ui之间的逐点损失来进行训练。</li></ul><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi ow"><img src="../Images/a6bfb1d7b6d2c255e5678671b81d8fc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tyV5hx3AmVxqAyC1tBZ1wQ.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">【https://www.comp.nus.edu.sg/~xiangnan/papers/ncf.pdf】<em class="mc">)</em></p></figure><p id="0b27" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">上述框架可以用下面的评分函数来概括:</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/6316e18267d55c36da82899ae3df95b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/1*1VGTA67IjpoXV-bbsXfRlg.png"/></div></figure><p id="e429" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">其中y-hat_ui是交互y_ui的预测得分，θ表示模型参数。f是将模型参数映射到预测得分的多层感知器。更具体地，P <strong class="kq ja"> </strong>是用户的潜在因素矩阵，Q <strong class="kq ja"> </strong>是项目的潜在因素矩阵，v_u^U是与用户特征相关联的辅助信息，而v_i^I是与项目特征相关联的辅助信息。</p><p id="b7c2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">本文认为，传统的矩阵分解可以看作是神经协同过滤的一个特例。因此，将矩阵分解的神经解释与多层感知器相结合以形成更通用的模型是方便的，该模型利用矩阵分解的线性和多层感知器的非线性来提高推荐质量。</p><p id="a8b4" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们看看这在代码中是什么样子的:</p><figure class="ln lo lp lq gt lr"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="6fed" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这种方法的完整PyTorch实现可以在这里查看:<a class="ae ll" href="https://github.com/khanhnamle1994/transfer-rec/tree/master/Multilayer-Perceptron-Experiments/Neural-CF-PyTorch-Version2" rel="noopener ugc nofollow" target="_blank">https://github . com/khanhnamle 1994/transfer-rec/tree/master/multi layer-Perceptron-Experiments/Neural-CF-py torch-version 2</a>。</p><h1 id="9e96" class="ms mt iq bd mu mv mw mx my mz na nb nc kf nd kg ne ki nf kj ng kl nh km ni nj bi translated">模型评估</h1><p id="e98d" class="pw-post-body-paragraph ko kp iq kq b kr nk ka kt ku nl kd kw kx nm kz la lb nn ld le lf no lh li lj ij bi translated">你可以查看我在这个知识库中构建的所有五个基于多层感知器的推荐模型:<a class="ae ll" href="https://github.com/khanhnamle1994/transfer-rec/tree/master/Multilayer-Perceptron-Experiments" rel="noopener ugc nofollow" target="_blank">https://github . com/khanhnamle 1994/transfer-rec/tree/master/Multilayer-Perceptron-Experiments</a>。</p><ul class=""><li id="6a0b" class="md me iq kq b kr ks ku kv kx mf lb mg lf mh lj mi mj mk ml bi translated">数据集是<a class="ae ll" href="https://github.com/khanhnamle1994/transfer-rec/tree/master/ml-1m" rel="noopener ugc nofollow" target="_blank"> MovieLens 1M </a>，类似于我在<a class="ae ll" rel="noopener" target="_blank" href="/recsys-series-part-4-the-7-variants-of-matrix-factorization-for-collaborative-filtering-368754e4fab5">上一篇文章</a>中的矩阵分解实验。目标是预测用户对特定电影的评分——评分范围为1到5。</li><li id="577c" class="md me iq kq b kr mm ku mn kx mo lb mp lf mq lj mi mj mk ml bi translated">唯一的区别是，为了使用基于因式分解机器的模型来预测点击率，我使用了<strong class="kq ja">二进制评级</strong>。小于等于3的评级被视为0，大于3的评级被视为1。</li><li id="8bbf" class="md me iq kq b kr mm ku mn kx mo lb mp lf mq lj mi mj mk ml bi translated">因此，考虑到这是一个二元分类问题(而不是像上次一样的RMSE)，评估度量是<strong class="kq ja"> AUC </strong>。</li><li id="18d7" class="md me iq kq b kr mm ku mn kx mo lb mp lf mq lj mi mj mk ml bi translated">所有模型都经过100个时期的训练，结果在<a class="ae ll" href="https://app.wandb.ai/khanhnamle1994/multi_layer_perceptron_collaborative_filtering" rel="noopener ugc nofollow" target="_blank"> <strong class="kq ja">权重和偏差</strong> </a>中捕获。对于那些不熟悉的人来说，这是一个出色的工具，它将所有模型超参数和输出指标存储在一个地方，以跟踪实验并毫不费力地再现结果。</li></ul><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi oy"><img src="../Images/b52423338b9d6e638c89c4f00bc92e12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WD3l5ovXVbL4QFRRMjJJgQ.png"/></div></div></figure><p id="78a2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">结果表位于自述文件的底部，正如您从重量和偏差仪表盘可视化中看到的:</p><ul class=""><li id="8307" class="md me iq kq b kr ks ku kv kx mf lb mg lf mh lj mi mj mk ml bi translated">广度和深度学习模型在测试和验证集上都具有最好的AUC结果。</li><li id="b341" class="md me iq kq b kr mm ku mn kx mo lb mp lf mq lj mi mj mk ml bi translated">另一方面，极深因式分解机分别具有最低的AUC。</li><li id="2d80" class="md me iq kq b kr mm ku mn kx mo lb mp lf mq lj mi mj mk ml bi translated">神经协同过滤运行速度最快，极深因式分解机运行速度最慢。</li></ul><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/8b0091f2fba5170d380aaca9ff7780e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*x9YNGOkFklG_XP50Ql7djQ.png"/></div></figure><h1 id="e3d8" class="ms mt iq bd mu mv mw mx my mz na nb nc kf nd kg ne ki nf kj ng kl nh km ni nj bi translated">结论</h1><p id="e60b" class="pw-post-body-paragraph ko kp iq kq b kr nk ka kt ku nl kd kw kx nm kz la lb nn ld le lf no lh li lj ij bi translated">在这篇文章中，我讨论了多层感知器的直观含义及其在协同过滤中的应用。我还浏览了使用MLP作为推荐框架的5篇不同的论文:(1)广泛和深度学习，(2)深度因子分解机，(3)极端深度因子分解机，(4)神经因子分解机，以及(5)神经协同过滤。这些模型补充了主流的浅层协同过滤模型，从而为基于深度学习的推荐开辟了一条新的研究途径。</p><p id="fae3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">请继续关注本系列未来的博文，它们超越了区分模型，进入了协同过滤的生成模型领域。</p><p id="90b2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="lk">现在开始阅读</em> <a class="ae ll" rel="noopener" target="_blank" href="/recommendation-system-series-part-6-the-6-variants-of-autoencoders-for-collaborative-filtering-bd7b9eae2ec7"> <em class="lk">推荐系统系列第六部</em> </a> <em class="lk">！</em></p><h1 id="6569" class="ms mt iq bd mu mv mw mx my mz na nb nc kf nd kg ne ki nf kj ng kl nh km ni nj bi translated">参考</h1><ul class=""><li id="be47" class="md me iq kq b kr nk ku nl kx pa lb pb lf pc lj mi mj mk ml bi translated"><a class="ae ll" href="https://arxiv.org/pdf/1606.07792.pdf" rel="noopener ugc nofollow" target="_blank"><em class="lk"/></a>针对推荐系统的宽深度学习。Cheng-Tze Cheng、Levent Koc、Jeremiah Harmsen、Tal Shaked、Tushar Chandra、Hrishi Aradhye、Glen Anderson、Greg Corrado、、Mustafa Ispir、Rohan Anil、Zakaria Haque、Hong、Jain、和Hemal Shah。2016年6月</li><li id="04a7" class="md me iq kq b kr mm ku mn kx mo lb mp lf mq lj mi mj mk ml bi translated"><a class="ae ll" href="https://arxiv.org/pdf/1703.04247.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="lk"> DeepFM:基于因子分解机的神经网络，用于CTR预测</em> </a>。郭慧峰，唐瑞明，叶云明，，何秀强。2017年3月。</li><li id="bb7f" class="md me iq kq b kr mm ku mn kx mo lb mp lf mq lj mi mj mk ml bi translated"><a class="ae ll" href="https://www.comp.nus.edu.sg/~xiangnan/papers/ncf.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="lk">神经协同过滤</em> </a> <em class="lk">。</em>何湘南，廖，汉王张，聂，，蔡达生。2017年8月</li><li id="e88c" class="md me iq kq b kr mm ku mn kx mo lb mp lf mq lj mi mj mk ml bi translated"><a class="ae ll" href="https://arxiv.org/pdf/1708.05027.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="lk">用于稀疏预测分析的神经分解机</em> </a>。何湘南和蔡达生。2017年8月</li><li id="a707" class="md me iq kq b kr mm ku mn kx mo lb mp lf mq lj mi mj mk ml bi translated"><a class="ae ll" href="https://arxiv.org/pdf/1803.05170.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="lk"> xDeepFM:结合显式和隐式特征交互的推荐系统</em> </a>。连建勋、周小欢、张辅政、陈忠霞、谢星和。2018年5月</li></ul></div><div class="ab cl pd pe hu pf" role="separator"><span class="pg bw bk ph pi pj"/><span class="pg bw bk ph pi pj"/><span class="pg bw bk ph pi"/></div><div class="ij ik il im in"><p id="6ca4" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="lk">如果你想关注我在推荐系统、深度学习和数据科学新闻方面的工作，你可以查看我的</em> <a class="ae ll" href="https://medium.com/@james_aka_yale" rel="noopener"> <em class="lk">中的</em> </a> <em class="lk">和</em><a class="ae ll" href="https://github.com/khanhnamle1994" rel="noopener ugc nofollow" target="_blank"><em class="lk">GitHub</em></a><em class="lk">，以及在</em><a class="ae ll" href="https://jameskle.com/" rel="noopener ugc nofollow" target="_blank"><em class="lk">https://jameskle.com/</em></a><em class="lk">的其他项目。你也可以在</em> <a class="ae ll" href="https://twitter.com/le_james94" rel="noopener ugc nofollow" target="_blank"> <em class="lk">推特</em> </a> <em class="lk">，</em> <a class="ae ll" href="mailto:khanhle.1013@gmail.com" rel="noopener ugc nofollow" target="_blank"> <em class="lk">直接发邮件给我</em> </a> <em class="lk">，或者</em> <a class="ae ll" href="http://www.linkedin.com/in/khanhnamle94" rel="noopener ugc nofollow" target="_blank"> <em class="lk">在LinkedIn上找我</em> </a> <em class="lk">。</em> <a class="ae ll" href="http://eepurl.com/deWjzb" rel="noopener ugc nofollow" target="_blank"> <em class="lk">注册我的简讯</em> </a> <em class="lk">就在你的收件箱里接收我对机器学习研究和行业的最新想法吧！</em></p></div></div>    
</body>
</html>