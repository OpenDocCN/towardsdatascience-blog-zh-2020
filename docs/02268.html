<html>
<head>
<title>How To Find Decision Tree Depth via Cross-Validation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何通过交叉验证找到决策树深度</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-find-decision-tree-depth-via-cross-validation-2bf143f0f3d6?source=collection_archive---------6-----------------------#2020-03-04">https://towardsdatascience.com/how-to-find-decision-tree-depth-via-cross-validation-2bf143f0f3d6?source=collection_archive---------6-----------------------#2020-03-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4fe8" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">消化偏差-方差权衡、过拟合、欠拟合、K 倍交叉验证背后的直觉。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/882c983de207aa64dfe5de02b362a709.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0hPTClxhk3aHcgWvOf4M2Q.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">RegalShave 在<a class="ae ky" href="https://pixabay.com/photos/oak-tree-tree-huge-old-charleston-2018822/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>拍摄的照片</p></figure><h1 id="8ddf" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">什么是决策树？</h1><p id="32f4" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">假设我们有一组经度和纬度坐标，对应于两种类型的区域:植被和非植被。我们可以建立一个逻辑回归模型，能够将任何坐标分类为植被或非植被。<strong class="lt iu">如下图所示，当类别在特征空间</strong>中很好地分离时，用于分类的逻辑回归工作得最好。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/5afddaafd84cac705650b01c7ec74659.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*Jjq_4x1G4BbCnxIHOAXP9g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">资料来源:哈佛大学 P. Protopapas 教授的讲稿</p></figure><p id="0d47" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">现在，让我们设想一种情况，植被分布在几个地区。如下图所示，现在解释非线性决策边界就不那么简单了。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/1bba67b7780f7496b388909abe05d15e.png" data-original-src="https://miro.medium.com/v2/resize:fit:748/format:webp/1*-W7HOfNfWk5BeXgF5jao6g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">资料来源:哈佛大学 P. Protopapas 教授的讲稿</p></figure><p id="efff" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">事实证明，在这种情况下，一个简单的流程图可以被公式化为用于分类的数学模型。它们的优势是可以被人类理解。我们用一个简单的例子来说明这些<strong class="lt iu">决策树</strong>是如何工作的，在这个例子中，一种水果应该被识别为柠檬或橙子。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/d5a1825200fc07f608c721bb3305f771.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sLKdGqGJU9Bay1i2y-91Bg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">资料来源:哈佛大学 P. Protopapas 教授的讲稿</p></figure><h1 id="79e6" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">如何训练决策树？</h1><p id="4154" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">为任何给定的训练数据集学习最小的决策树是一项困难的任务。在每个节点中，<strong class="lt iu">我们需要选择分裂</strong>的最佳预测值，<strong class="lt iu">需要选择分裂</strong>的最佳阈值。在前面的示例中，我们首先通过查看水果的宽度并使用阈值 6.5 厘米来决定。我们也可以从水果的高度开始，或者为宽度选择不同的阈值。我们的选择对树的区域形状有影响。</p><p id="67e6" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">理想情况下，随着分裂次数的增加，这些区域应该逐渐变得更纯。每个区域应该专门针对一个类(柠檬或橙)。通常通过测量<strong class="lt iu">分类误差</strong>来评估这种分割的质量。也可以使用所谓的<strong class="lt iu">基尼指数</strong>来评估该区域的纯度。或者，区域的<strong class="lt iu">熵</strong>可以告诉杂质的级别。</p><h1 id="c590" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">什么是偏差-方差权衡？</h1><p id="c9b7" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在训练期间，该树将继续增长，直到每个区域恰好包含一个训练点(100%训练准确度)。这产生了一个完整的分类树，该分类树分割训练数据，直到每个树叶包含单个观察值。换句话说，整个树会过度适应训练数据。</p><h2 id="dbe1" class="mv la it bd lb mw mx dn lf my mz dp lj ma na nb ll me nc nd ln mi ne nf lp ng bi translated">过度拟合</h2><p id="d361" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><strong class="lt iu">过拟合的树将实现训练观察的完美分类，并且偏差(误差)将为 0 </strong>。然而，这样的树会非常敏感，因为训练观察的微小变化会导致预测的类别发生很大变化，这意味着<strong class="lt iu">模型方差会非常高</strong>。这个模型不能很好地概括看不见的数据。</p><h1 id="a636" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">权衡取舍</h1><p id="f47c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">为了防止过拟合的发生，<strong class="lt iu">我们需要定义一个停止条件</strong>。低深度的树不能捕捉分隔类的非线性边界。通过减少树的深度，我们增加了 biais(训练的误分类误差),但是我们也减少了方差。<strong class="lt iu">偏差-方差权衡寻求偏差和方差之间的折衷，这里使用交叉验证。</strong></p><h1 id="1398" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">什么是交叉验证？</h1><p id="cc1f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">适当的深度可以通过交叉验证在保留的数据集上评估树来确定。通过多次对数据进行重新采样，将分为训练折叠和验证折叠，在训练折叠上拟合不同大小的树，并查看验证折叠上的分类精度，我们能够找到树的深度，这提供了最佳的偏差-方差权衡。这种树不能完美地预测训练集(可接受的偏差)，但是如果我们稍微改变训练集(可接受的方差)，它的性能将大致相同。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/bcf3ff6ff6c100b13605bd21083affd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L90fdYb2oT0BOP2CCMSIbg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://scikit-learn.org/stable/modules/cross_validation.html" rel="noopener ugc nofollow" target="_blank">来源</a>—Scikit-learn.org</p></figure><h1 id="7ea6" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">通过 K-fold 交叉验证找到最佳深度</h1><p id="2f8f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">诀窍是选择一系列树深度进行评估，并使用 K 倍交叉验证绘制每个深度的估计性能+/- 2 标准偏差。我们提供了一个 Python 代码，可以在任何情况下使用，在这种情况下，您需要调整给定预测张量 X 和标签 y 的决策树。该代码包括图中的训练集性能，同时缩放 y 轴以关注交叉验证性能。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ni nj l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/5db4226d0020db101be8caa23d6a1f0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tkeHqY42uNgHwd-e6iCrCA.png"/></div></div></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ni nj l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/a33fa2e6928c755af22e5820344d645f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*84vw11HyiS5NirLNB9tagA.png"/></div></div></figure><p id="147b" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">该方法选择树深度 5，因为它使用大小为 5 的交叉验证折叠来实现对训练数据的最佳平均准确度。准确度置信区间的下限足够高，使得该值有意义。当更多的节点被添加到树中时，很明显，交叉验证的准确性向零变化。</p><p id="5957" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">深度为 20 的树在训练集上实现了完美的准确度(100%)，这意味着树的每一片叶子恰好包含一个样本，并且该样本的类别将是预测。深度为 20 的树过度适合训练集。</p><p id="947b" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">我们通过交叉验证选择的树深度 5 有助于我们避免过度拟合，并提供了一个更好的机会来重现准确性，并根据测试数据概括模型，如下所示。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ni nj l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/4174600b8fba61f2cfe9a0311384a78d.png" data-original-src="https://miro.medium.com/v2/resize:fit:526/format:webp/1*vJctbJkQcATAlB0rnXVBIQ.png"/></div></figure><h1 id="23cd" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">结论</h1><p id="93d0" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">本文中的想法是使用 K-fold 交叉验证和搜索算法。搜索的输入是超参数网格，这是在训练模型之前选择的参数。在我们的例子中，这是一个简单的潜在树深度范围。</p><p id="d45c" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">我们提供了易于复制的 Python 代码，不仅可以用于调整决策树，还可以用于一般的模型选择任务。其他方法包括<a class="ae ky" href="https://mlfromscratch.com/nested-cross-validation-python-code" rel="noopener ugc nofollow" target="_blank">嵌套交叉验证</a>。</p><p id="6e65" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">感谢<a class="ae ky" href="https://medium.com/@annebonner" rel="noopener"> Anne Bonner </a>和<a class="ae ky" href="https://medium.com/@angelamarieteng" rel="noopener"> Amber Teng </a>来自《走向数据科学》的编辑评论。</p></div></div>    
</body>
</html>