<html>
<head>
<title>Neural Structured Learning &amp; Adversarial Regularization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经结构化学习和对抗正则化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/neural-structured-learning-adversarial-regularization-378523dace08?source=collection_archive---------33-----------------------#2020-09-07">https://towardsdatascience.com/neural-structured-learning-adversarial-regularization-378523dace08?source=collection_archive---------33-----------------------#2020-09-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a814" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">张量流中用对立正则化提高分类模型的鲁棒性</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/db7950838512f6bd40b98a0aca201744.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*PGTvYzYzF8ilO6oCxbtzYg.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">作者拥有的图像</p></figure><h1 id="2022" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">介绍</h1><p id="7faf" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">正如我们许多人无疑都知道的那样，计算机视觉领域取得的不变进展已经在多个学科领域取得了一些令人难以置信的成就，从<a class="ae mf" href="https://inews.co.uk/news/deepmind-google-ai-predict-eye-conditions-threatening-sight-429071" rel="noopener ugc nofollow" target="_blank">医疗保健</a>和自动驾驶汽车，到气候研究和游戏，不一而足。</p><p id="6384" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">从最先进的液氮冷却硬件形式的<a class="ae mf" href="https://cloud.google.com/tpu/docs/tpus" rel="noopener ugc nofollow" target="_blank">张量处理单元(TPU) </a>到日益复杂的数百万参数深度卷积网络，如<a class="ae mf" href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43022.pdf" rel="noopener ugc nofollow" target="_blank"> GoogLeNet </a>、<a class="ae mf" href="https://en.wikipedia.org/wiki/AlexNet" rel="noopener ugc nofollow" target="_blank"> AlexNet </a>这种技术的能力继续打破以前无法逾越的障碍。</p><h2 id="2aec" class="ml ks iq bd kt mm mn dn kx mo mp dp lb ls mq mr ld lw ms mt lf ma mu mv lh mw bi translated">对抗性脆弱性</h2><p id="b98f" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">尽管取得了这些令人难以置信的成就，但事实证明，即使是最熟练的模型也不是绝对可靠的。多项研究表明，这些模型对<strong class="ll ir">输入数据结构</strong>中的微小变化非常敏感。最初是在谷歌和纽约大学的联合研究论文的发现中:<a class="ae mf" href="http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42503.pdf" rel="noopener ugc nofollow" target="_blank">“神经网络的有趣特性，2014”</a>模型易受对立例子影响的主题现在被认为是如此重要的主题，以至于现在存在解决它的<a class="ae mf" href="https://ai.googleblog.com/2018/09/introducing-unrestricted-adversarial.html" rel="noopener ugc nofollow" target="_blank">竞赛</a>。</p><p id="76e7" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">这些错误的存在提出了各种各样的关于样本外泛化的问题，以及如何使用这样的例子来滥用已部署的系统。</p><h1 id="9feb" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">神经结构化学习</h1><p id="29a7" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">在某些应用中，这些误差可能不是有意产生的，而且，它们可能是由于人为误差或仅仅是由于输入不稳定而产生的。在采矿业，计算机视觉有无数非常有用的应用，例如，从流式处理工厂传送带图像以预测矿石纯度，到使用卫星图像检测商品库存水平和非法运输/采矿。</p><p id="557a" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">我们经常会发现，由于相机未对准、振动或可能导致错误分类的非常独特的样本外示例，此类图像数据在收集过程中遭到破坏。</p><p id="5e69" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated"><strong class="ll ir">为了克服诸如此类的例子，并总体上改进我们的模型以对抗损坏或扰乱的数据，我们可以采用一种形式的</strong> <a class="ae mf" href="https://github.com/tensorflow/neural-structured-learning" rel="noopener ugc nofollow" target="_blank"> <strong class="ll ir">神经结构化学习</strong> </a> <strong class="ll ir">称为</strong> <a class="ae mf" href="https://www.tensorflow.org/neural_structured_learning/api_docs/python/nsl/keras/AdversarialRegularization" rel="noopener ugc nofollow" target="_blank"> <strong class="ll ir">对抗正则化</strong> </a> <strong class="ll ir">。</strong></p><p id="e777" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">神经结构化学习(NSL) <strong class="ll ir"> </strong>是一个相对较新的开源框架，由 TensorFlow 的优秀人员开发，用于使用结构化信号训练深度神经网络(与传统的单一样本相反)。NSL 实现了<a class="ae mf" href="https://ai.google/research/pubs/pub46568.pdf" rel="noopener ugc nofollow" target="_blank">神经图形学习</a>，其中使用<a class="ae mf" href="https://en.wikipedia.org/wiki/Graph_database" rel="noopener ugc nofollow" target="_blank">图形</a>(见下图)训练神经网络，图形携带关于目标(节点)的信息和通过节点边缘连接的其他节点中的相邻信息。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi mx"><img src="../Images/ffec4c12f956ac650fd81a0a3cf20d7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AuC-ZlRwuV3-obQj0Pk1uA.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated"><a class="ae mf" href="https://blog.tensorflow.org/2019/09/introducing-neural-structured-learning.html" rel="noopener ugc nofollow" target="_blank">图片来自 TensorFlow 博客:在 TensorFlow 中引入神经结构化学习，2019 </a></p></figure><p id="2cde" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">这样，这允许训练模型通过以下方式同时利用标记和未标记的数据:</p><ol class=""><li id="5129" class="nc nd iq ll b lm mg lp mh ls ne lw nf ma ng me nh ni nj nk bi translated">在标记数据上训练模型(任何监督学习问题中的标准程序)；</li><li id="6f4c" class="nc nd iq ll b lm nl lp nm ls nn lw no ma np me nh ni nj nk bi translated">偏置网络以学习图上相邻节点的相似隐藏表示(相对于输入数据标签)</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi nq"><img src="../Images/81797544051b99d80b863317dd1d5da6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pawtkw3G3u1jrHHFogi1fw.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated"><a class="ae mf" href="https://blog.tensorflow.org/2019/09/introducing-neural-structured-learning.html" rel="noopener ugc nofollow" target="_blank">图片来自 TensorFlow 博客:神经结构化学习，对抗性例子，2019 </a>。</p></figure><p id="6057" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">与第二点一致，我们可以在上述表达式中观察到经验损失(即监督损失)和<strong class="ll ir">邻居损失的最小化。</strong>在上面的例子中，这被计算为目标隐藏层内的计算的权重向量与输入、<em class="nr"> X、</em>和添加了某种程度的噪声的相同输入之间的距离度量(即，L1、L2 距离)的点积:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/a021dc599b25f3944205c88bf896a16f.png" data-original-src="https://miro.medium.com/v2/resize:fit:390/format:webp/1*HlqDz6YppaRHoYFYBJp1mg.png"/></div></figure><p id="9ab8" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">典型地，通过计算输出相对于输入的梯度 x_i，然后最大化损失来创建对立的例子。例如，如果您有一个对吉娃娃和松饼进行分类的模型，并且您希望创建对立的示例，您可以将一个 128 x 128 像素的吉娃娃图像输入到您的网络中，根据输入计算损失的梯度(128 x 128 张量)，然后将负梯度(扰动)添加到您的图像中，直到网络将图像分类为松饼。通过使用正确的标签再次对这些生成的图像进行训练，网络变得对噪声/干扰更加鲁棒。</p><h1 id="1ba0" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">为什么用 NSL？</h1><ul class=""><li id="60be" class="nc nd iq ll b lm ln lp lq ls nt lw nu ma nv me nw ni nj nk bi translated"><strong class="ll ir">更高的精度</strong>:样本间的结构化信号可以提供在特征输入中并不总是可用的信息。</li><li id="1459" class="nc nd iq ll b lm nl lp nm ls nn lw no ma np me nw ni nj nk bi translated"><strong class="ll ir">更强的鲁棒性</strong>:用对立的例子训练的模型<a class="ae mf" href="https://arxiv.org/abs/1807.06732" rel="noopener ugc nofollow" target="_blank">在对抗为误导模型的预测或分类而设计的对立扰动方面</a>明显更强。</li><li id="7bc3" class="nc nd iq ll b lm nl lp nm ls nn lw no ma np me nw ni nj nk bi translated"><strong class="ll ir">需要更少的标记数据</strong> : NSL 使神经网络能够利用标记和未标记的数据，迫使网络学习类似的“邻近样本”的隐藏表示，这些样本可能有也可能没有标记。</li></ul><h1 id="26f2" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">对抗性规则</h1><p id="cce6" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">如果没有这样明确的结构作为输入，我们能做什么？</p><p id="cdc7" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">关于 TensorFlows 神经结构化学习库，<em class="nr">特别有用的是提供了一些方法，使用户能够通过对抗扰动，从原始输入数据中动态构建<em class="nr">诱导的</em>对抗示例作为隐式结构。NSL 的这种一般化被称为<strong class="ll ir">对抗正则化，</strong>在这种情况下，对抗示例被构造成在训练期间有意混淆模型，从而产生对小输入扰动具有鲁棒性的模型。</em></p><h1 id="3ae2" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">实践中的对抗性规范</h1><p id="db02" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">在下面的例子中，我们将比较基线图像分类模型(特别是卷积神经网络)与利用对抗正则化的变体的性能。不幸的是，我们无法在上述任何采矿数据上演示 AR 的使用，因为这是专有的。</p><p id="3454" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">相反，我们将对在著名的图像分类数据集— <a class="ae mf" href="https://www.tensorflow.org/datasets/catalog/beans" rel="noopener ugc nofollow" target="_blank"> Beans </a>上训练的两个模型进行分析。我们将比较基线模型的结果，与一个经过对抗性例子训练的结果，以充分理解对抗性规则对每个模型的能力和性能的影响。</p><p id="cb40" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">包含本文所用代码的 Colab 笔记本可以在<a class="ae mf" href="https://github.com/cmp1/computer_vision_neural_structured_learning/tree/master" rel="noopener ugc nofollow" target="_blank">这里</a>找到。一个优秀的教程，这篇文章的灵感和一些代码的来源，可以在<a class="ae mf" href="https://www.tensorflow.org/neural_structured_learning/tutorials/adversarial_keras_cnn_mnist#conclusion" rel="noopener ugc nofollow" target="_blank"> TensorFlow NSL 页面</a>上找到。</p><p id="7dfc" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">在开始之前，我们必须先安装 TensorFlow 的神经结构学习包:</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="a5d6" class="ml ks iq ny b gy oc od l oe of">!pip install neural_structured_learning</span></pre><h2 id="4e31" class="ml ks iq bd kt mm mn dn kx mo mp dp lb ls mq mr ld lw ms mt lf ma mu mv lh mw bi translated">进口</h2><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="abe2" class="ml ks iq ny b gy oc od l oe of">import matplotlib.image as mpimg<br/>import matplotlib.pyplot as plt<br/>import numpy as np<br/>import keras_preprocessing<br/>import neural_structured_learning as nsl<br/>import tensorflow as tf<br/>import tensorflow_datasets.public_api as tfds</span><span id="d5bf" class="ml ks iq ny b gy og od l oe of">from tensorflow.keras import models<br/>from keras_preprocessing import image<br/>from keras_preprocessing.image import ImageDataGenerator</span></pre><h2 id="f9d2" class="ml ks iq bd kt mm mn dn kx mo mp dp lb ls mq mr ld lw ms mt lf ma mu mv lh mw bi translated">加载和检查图像数据</h2><p id="c3bf" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">TensorFlow 在其<a class="ae mf" href="https://www.tensorflow.org/datasets" rel="noopener ugc nofollow" target="_blank"> TensorFlow 数据集</a>集合中托管了许多著名的数据集。</p><p id="fa43" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">我们可以使用<code class="fe oh oi oj ny b">tfds.load()</code>方法加载我们想要训练模型的 Beans 数据集，该方法执行两个操作:</p><ol class=""><li id="3a16" class="nc nd iq ll b lm mg lp mh ls ne lw nf ma ng me nh ni nj nk bi translated">下载数据集并将其保存为<code class="fe oh oi oj ny b"><a class="ae mf" href="https://www.tensorflow.org/tutorials/load_data/tfrecord" rel="noopener ugc nofollow" target="_blank">tfrecord</a></code>文件。</li><li id="04fe" class="nc nd iq ll b lm nl lp nm ls nn lw no ma np me nh ni nj nk bi translated">加载<code class="fe oh oi oj ny b">tfrecord</code>文件并返回<code class="fe oh oi oj ny b"><a class="ae mf" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset" rel="noopener ugc nofollow" target="_blank">tf.data.Dataset</a></code>的实例</li></ol><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="6038" class="ml ks iq ny b gy oc od l oe of"># load dataset<br/>dataset = 'beans' #@param</span><span id="84e2" class="ml ks iq ny b gy og od l oe of">dataset = tfds.load(dataset, shuffle_files=True)<br/>train, test = dataset['train'], dataset['test']</span><span id="9218" class="ml ks iq ny b gy og od l oe of">IMAGE_INPUT_NAME = 'image'<br/>LABEL_INPUT_NAME = 'label'</span></pre><p id="1749" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">在执行任何图像缩放或图像增强/扰动之前，我们可以检查数据集中的图像样本，以了解卷积层可能作为特征提取的各种结构和组成，并了解数据集中各种类之间的差异:</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="d04b" class="ml ks iq ny b gy oc od l oe of"># Get random batch<br/>raw_images = train.take(10)</span><span id="e21c" class="ml ks iq ny b gy og od l oe of"># Tensor to np format<br/>raw_images = [item['image'] for item in<br/>raw_images.as_numpy_iterator()]</span><span id="f7b6" class="ml ks iq ny b gy og od l oe of"># Plot batch<br/>fig = plt.gcf()<br/>fig.set_size_inches(10, 10)<br/>for i, img in enumerate(raw_images):<br/>  sp = plt.subplot(2, 5, i+1)<br/>  sp.axis('Off')<br/>  plt.imshow(img)</span><span id="1540" class="ml ks iq ny b gy og od l oe of">plt.show()</span></pre><p id="7aaf" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">默认情况下，<code class="fe oh oi oj ny b"><a class="ae mf" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset" rel="noopener ugc nofollow" target="_blank">tf.data.Dataset</a></code>对象包含一个由<code class="fe oh oi oj ny b"><a class="ae mf" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" rel="noopener ugc nofollow" target="_blank">tf.Tensor</a></code>组成的<code class="fe oh oi oj ny b">dict</code>，我们可以通过在我们的列表理解中调用<code class="fe oh oi oj ny b">raw_images</code>上的<code class="fe oh oi oj ny b">.as_numpy_iterator()</code>来迭代这批图像(tf.data.Dataset 键值)。该方法返回一个生成器，该生成器将数据集的批处理元素从<code class="fe oh oi oj ny b">tf.Tensor</code>格式转换为<code class="fe oh oi oj ny b">np.array</code>格式。然后，我们可以绘制生成的一批图像:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/ef44ae801bd71b391a93ce6da4827b95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*_pZxLQXIxzFSJykZvyTcHg.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">由作者生成的图像:“豆”数据集中的 10 个训练图像的样本批次，描绘了 3 个不同的类别:“健康”、“豆锈病”和“角斑病”</p></figure><h2 id="0295" class="ml ks iq bd kt mm mn dn kx mo mp dp lb ls mq mr ld lw ms mt lf ma mu mv lh mw bi translated">预处理</h2><p id="da75" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">我们对图像数据执行简单的缩放操作，将输入映射到 0 和 1 之间的浮点张量(Beans 数据集是 500 x 500 x 3 图像的集合)。有益的是，TDFS 数据集将<a class="ae mf" href="https://www.tensorflow.org/datasets/catalog/beans" rel="noopener ugc nofollow" target="_blank">要素属性</a>存储为字典:</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="c194" class="ml ks iq ny b gy oc od l oe of">FeaturesDict({<br/>    'image': Image(shape=(500, 500, 3), dtype=tf.uint8),<br/>    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),<br/>})</span></pre><p id="1e96" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">因此，我们可以访问各个图像及其标签，并使用我们的训练和测试<code class="fe oh oi oj ny b">tf.Dataset</code>实例的<code class="fe oh oi oj ny b">.map()</code>属性就地执行这些预处理操作<strong class="ll ir">:</strong></p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="996e" class="ml ks iq ny b gy oc od l oe of">def normalize(features):<br/>  """Scale images to within 0-1 bound based on max image size."""<br/>  features[IMAGE_INPUT_NAME] = tf.cast(<br/>    features[IMAGE_INPUT_NAME], <br/>    dtype=tf.float32) / 500.0)<br/>  return features</span><span id="4556" class="ml ks iq ny b gy og od l oe of">def examples_to_tuples(features):<br/>  return features[IMAGE_INPUT_NAME], features[LABEL_INPUT_NAME]</span><span id="338d" class="ml ks iq ny b gy og od l oe of">def examples_to_dict(image, label):<br/>  return {IMAGE_INPUT_NAME: image, LABEL_INPUT_NAME: label}</span><span id="8c06" class="ml ks iq ny b gy og od l oe of"># Define train set, preprocess. (Note: inputs shuffled on load)<br/>train_dataset = train.map(normalize)<br/>                     .batch(28)<br/>                     .map(examples_to_tuples)</span><span id="9a85" class="ml ks iq ny b gy og od l oe of">test_dataset = test.map(normalize)<br/>                   .batch(28)<br/>                   .map(examples_to_tuples)</span></pre><p id="a083" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">功能<code class="fe oh oi oj ny b">examples_to_dict</code>将在稍后解释。</p><h2 id="ecaf" class="ml ks iq bd kt mm mn dn kx mo mp dp lb ls mq mr ld lw ms mt lf ma mu mv lh mw bi translated">基线模型</h2><p id="ea3d" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">然后，我们构建一个简单的基线卷积神经网络模型，并使其适合我们的图像数据:</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="6b8f" class="ml ks iq ny b gy oc od l oe of">def conv_nn_model(img_input_shape: tuple) -&gt; tf.keras.Model():<br/>  """Simple Conv2D Neural Network.<br/>    Args:<br/>      img_input_shape: An (mxnxo) tuple defining the input image   <br/>      shape.<br/>    Returns:<br/>      model: An instance of tf.keras.Model.<br/>  """<br/>  model = tf.keras.models.Sequential([<br/>      tf.keras.layers.Conv2D(16, (3,3), activation='relu',   <br/>          input_shape=input_shape),<br/>      tf.keras.layers.MaxPooling2D(2, 2),<br/>      tf.keras.layers.Conv2D(32, (3,3), activation='relu'),<br/>      tf.keras.layers.MaxPooling2D(2,2),<br/>      tf.keras.layers.Conv2D(32, (3,3), activation='relu'),<br/>      tf.keras.layers.MaxPooling2D(2,2),<br/>      tf.keras.layers.Flatten(),<br/>      tf.keras.layers.Dense(64, activation='relu'),<br/>      # Note to adjust output layer for number of classes<br/>      tf.keras.layers.Dense(3, activation='softmax')])<br/>  return model</span><span id="9de4" class="ml ks iq ny b gy og od l oe of"># Beans dataset img dims (pixel x pixel x bytes)<br/>input_shape = (500, 500, 3)</span><span id="7fbe" class="ml ks iq ny b gy og od l oe of"># Establish baseline<br/>baseline_model = conv_nn_model(input_shape)<br/>baseline_model.summary()</span><span id="0ef6" class="ml ks iq ny b gy og od l oe of">baseline_model.compile(<br/>    optimizer='adam',<br/>    loss='sparse_categorical_crossentropy',<br/>    metrics=['acc'])</span><span id="4f89" class="ml ks iq ny b gy og od l oe of">baseline_history = baseline_model.fit(<br/>    train_dataset,<br/>    epochs=5)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/4b63e4700c644f4279efd2f11fb80307.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_pYuIJdAax8Xj1fOwl6Qgg.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">我们的基准 Conv2D 模型架构</p></figure><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="1bbb" class="ml ks iq ny b gy oc od l oe of">results = baseline_model.evaluate(test_dataset)<br/>print(f'Baseline Accuracy: {results[1]}')</span><span id="62c9" class="ml ks iq ny b gy og od l oe of">3/3 [==============================] - 0s 72ms/step - loss: 0.1047 - acc: 0.8934 <br/>Baseline Accuracy: 0.8934375</span></pre><p id="8aee" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">我们可以看到，我们的基线模型在测试数据集上表现良好，达到了 89%的准确率。</p><h2 id="f04f" class="ml ks iq bd kt mm mn dn kx mo mp dp lb ls mq mr ld lw ms mt lf ma mu mv lh mw bi translated">对抗正则化模型</h2><p id="2dc5" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">我们现在将检查该模型如何针对包括对立干扰示例的测试集执行，并将其与在包括所述示例的数据集上训练的模型进行比较。我们首先创建另一个卷积神经网络模型，只是这一次我们将把对抗性训练纳入其训练目标。</p><p id="f8c1" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">接下来，使用 TensorFlow 的 NSL 框架，我们用 NSL 的助手函数<code class="fe oh oi oj ny b"><a class="ae mf" href="https://www.tensorflow.org/neural_structured_learning/api_docs/python/nsl/configs/make_adv_reg_config" rel="noopener ugc nofollow" target="_blank">nsl.configs.make_adv_reg_config</a></code>定义一个配置对象:</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="fa22" class="ml ks iq ny b gy oc od l oe of">#@title ADV Regularization Config</span><span id="05af" class="ml ks iq ny b gy og od l oe of"># Create new CNN model instance<br/>base_adv_model = conv_nn_model(input_shape)</span><span id="9693" class="ml ks iq ny b gy og od l oe of"># Create AR config object <br/>adv_reg_config = nsl.configs.make_adv_reg_config(<br/>    multiplier=0.2,<br/>    adv_step_size=0.2,<br/>    adv_grad_norm='infinity')</span><span id="64fb" class="ml ks iq ny b gy og od l oe of"># Model wrapper <br/>adv_reg_model = nsl.keras.AdversarialRegularization(<br/>    base_adv_model,<br/>    label_keys=[LABEL_INPUT_NAME],<br/>    adv_config=adv_config)</span></pre><p id="58e3" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">我们可以注意到，这个函数要求我们设置许多超参数。其中一些不需要明确的值，其他的需要我们的输入:</p><ul class=""><li id="f384" class="nc nd iq ll b lm mg lp mh ls ne lw nf ma ng me nw ni nj nk bi translated"><code class="fe oh oi oj ny b"><strong class="ll ir">multiplier</strong></code>:训练中对抗性损失相对于标签损失的权重，w.r.t 我们 AR 模型的目标函数。我们应用 0.2 作为正则化权重。</li><li id="ddea" class="nc nd iq ll b lm nl lp nm ls nn lw no ma np me nw ni nj nk bi translated"><code class="fe oh oi oj ny b"><strong class="ll ir">adv_step_size</strong></code>:训练中要应用的对抗性扰动的程度/幅度。</li><li id="eba0" class="nc nd iq ll b lm nl lp nm ls nn lw no ma np me nw ni nj nk bi translated"><code class="fe oh oi oj ny b"><strong class="ll ir">adv_grad_norm</strong></code>:归一化梯度的张量范数(L1 或 L2)，即对抗性扰动幅度的测量。默认为 L2。</li></ul><p id="8210" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">然后，我们可以使用<code class="fe oh oi oj ny b">nsl.keras.AdversarialRegularization</code>函数包装我们新创建的模型，这将把我们之前使用<code class="fe oh oi oj ny b">adv_reg_config</code>对象配置的对抗性正则化添加到我们基本模型的训练目标(要最小化的损失函数)中。</p><p id="8a1a" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated"><strong class="ll ir">在这个阶段</strong>需要注意的重要一点是，我们的模型<em class="nr">期望它的输入是特性名称到特性值的字典映射</em>。可以看到，当我们实例化我们的对抗性模型时，我们必须将<code class="fe oh oi oj ny b">label_keys</code>作为参数传入。这使得我们的模型能够区分<strong class="ll ir">输入数据</strong>和<strong class="ll ir">目标数据</strong>。这里，我们可以使用我们的<code class="fe oh oi oj ny b">examples_to_dict</code>函数，并将其映射到我们的训练和测试数据集:</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="43e8" class="ml ks iq ny b gy oc od l oe of">train_set_for_adv_model = train_dataset.map(convert_to_dictionaries)<br/>test_set_for_adv_model = test_dataset.map(convert_to_dictionaries)</span></pre><p id="0faf" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">然后，我们正常编译、拟合和评估我们的对抗性正则化模型:</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="2099" class="ml ks iq ny b gy oc od l oe of">4/4 [==============================] - 0s 76ms/step - loss: 0.1015 - sparse_categorical_crossentropy: 0.1858 - sparse_categorical_accuracy: 0.8656 - scaled_adversarial_loss: 0.1057  accuracy: 0.911625</span></pre><p id="e703" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">类似地，我们的对抗性正则化模型很好地推广到我们的测试数据集，达到了与我们的<code class="fe oh oi oj ny b">baseline_model</code>相似的精度(0.91%)。</p><h2 id="feeb" class="ml ks iq bd kt mm mn dn kx mo mp dp lb ls mq mr ld lw ms mt lf ma mu mv lh mw bi translated">针对不利扰动数据的评估</h2><p id="76e0" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">现在是有趣的部分。</p><p id="fcaa" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">就像我们在测试集上评估一个训练过的模型的能力一样，我们将在我们的两个模型上执行相同的操作。然而，在这种情况下，我们将比较我们的两个模型；基线 CNN，以及已经针对包含<em class="nr">对抗性扰动示例</em>的测试数据集对对抗性扰动输入数据进行训练的变体。</p><p id="7cff" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">为了生成上述示例，我们必须首先创建一个参考模型，其配置(损耗、指标和校准/学习权重)将用于生成扰动示例。为此，我们再次用<code class="fe oh oi oj ny b">nsl.keras.AdversarialRegularization</code>函数包装我们的性能基线模型并编译它。<strong class="ll ir">请注意，我们并未将该模型应用于我们的数据集，我们希望保留与基础模型相同的学习权重</strong>):</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="ddef" class="ml ks iq ny b gy oc od l oe of"># Wrap baseline model<br/>reference_model = nsl.keras.AdversarialRegularization(<br/>    baseline_model,<br/>    label_keys=[LABEL_INPUT_NAME],<br/>    adv_config=adv_reg_config)</span><span id="b34b" class="ml ks iq ny b gy og od l oe of">reference_model.compile(<br/>    optimizer='adam',<br/>    loss='sparse_categorical_crossentropy',<br/>    metrics=['acc']</span><span id="97e6" class="ml ks iq ny b gy og od l oe of">models_to_eval = {<br/>    'base': baseline_model,<br/>    'adv-regularized': adv_reg_model.base_model}</span><span id="4a8d" class="ml ks iq ny b gy og od l oe of">metrics = {<br/>    name: tf.keras.metrics.SparseCategoricalAccuracy()<br/>    for name in models_to_eval.keys()}</span></pre><p id="ad53" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">如果此时你和我一样，喜欢理解这些事情背后的逻辑，你可以在这里找到包含对抗性正则化类<a class="ae mf" href="https://github.com/tensorflow/neural-structured-learning/blob/v1.3.1/neural_structured_learning/keras/adversarial_regularization.py#L695-L747" rel="noopener ugc nofollow" target="_blank">的<strong class="ll ir">源代码</strong></a>。</p><p id="433c" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">然后我们存储我们的两个模型；字典中的基线和对抗性正则化变量，随后在我们的测试数据集的每一批上循环(成批评估是对抗性正则化模型的一个要求)。</p><p id="cc00" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">使用我们新包装的<code class="fe oh oi oj ny b">reference_model</code>的<code class="fe oh oi oj ny b">.perturb_on_batch()</code>方法，我们可以生成与我们的<code class="fe oh oi oj ny b">adv_reg_config</code>对象一致的对抗性扰动批处理，并在其上评估我们的两个模型的性能:</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="125e" class="ml ks iq ny b gy oc od l oe of">labels, y_preds = [], []</span><span id="c020" class="ml ks iq ny b gy og od l oe of"># Generate perturbed batches, <br/>for batch in test_set_for_adv_model:<br/>  perturbed_batch = reference_model.perturb_on_batch(batch)<br/>  perturbed_batch[IMAGE_INPUT_NAME] = tf.clip_by_value(<br/>      perturbed_batch[IMAGE_INPUT_NAME], 0.0, 1.0)<br/>  # drop label from batch<br/>  y = perturbed_batch.pop(LABEL_INPUT_NAME)<br/>  y_preds.append({})<br/>  for name, model in models_to_eval.items():<br/>    y_pred = model(perturbed_batch)<br/>    metrics[name](y, y_pred)<br/>    predictions[-1][name] = tf.argmax(y_pred, axis=-1).numpy()</span><span id="b8a4" class="ml ks iq ny b gy og od l oe of">for name, metric in metrics.items():<br/>  print(f'{name} model accuracy: {metric.result().numpy()}')</span><span id="60cb" class="ml ks iq ny b gy og od l oe of">&gt;&gt; base model accuracy: 0.2201466 adv-regularized model accuracy: 0.8203125</span></pre><h2 id="4bc6" class="ml ks iq bd kt mm mn dn kx mo mp dp lb ls mq mr ld lw ms mt lf ma mu mv lh mw bi translated">结果</h2><p id="46af" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">相对于 adv_reg_model，我们的基线模型在对抗扰动数据上的性能<strong class="ll ir"><em class="nr"/></strong>显著降低，对抗学习在提高模型稳健性上的有效性立即变得明显。</p><p id="8118" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">我们的基线模型的性能下降了<strong class="ll ir"> 69% </strong>相比于我们的对抗性正则化模型，只实现了 14%的性能下降。</p><p id="f3f9" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">借助 Kera 的 Layers API，我们可以通过可视化卷积层来了解扰动前后提取的特征，从而检查恶意扰动数据对基线模型的影响:</p><h2 id="f96e" class="ml ks iq bd kt mm mn dn kx mo mp dp lb ls mq mr ld lw ms mt lf ma mu mv lh mw bi translated">扰动前</h2><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="e633" class="ml ks iq ny b gy oc od l oe of"># Random img &amp; conv layer idxs<br/>IDX_IMAGE_1=2<br/>IDX_IMAGE_2=5<br/>IDX_IMAGE_3=10<br/>CONVOLUTION_NUMBER = 10</span><span id="7e08" class="ml ks iq ny b gy og od l oe of"># Get baseline_model layers <br/>layer_outputs = [layer.output for layer in baseline_model.layers]<br/>activation_model = tf.keras.models.Model(<br/>    inputs =baseline_model.input, <br/>    outputs = layer_outputs)</span><span id="b1a1" class="ml ks iq ny b gy og od l oe of"># Plot img at specified conv<br/>f, axarr = plt.subplots(3,2, figsize=(8, 8))<br/>for x in range(0, 2):<br/>  f1 = activation_model.predict(test_images[IDX_IMAGE_1].reshape(<br/>      1, 500, 500, 3))[x]<br/>  axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER],cmap='inferno')<br/>  axarr[0,x].grid(False)<br/>  f2 = activation_model.predict(test_images[IDX_IMAGE_2].reshape(<br/>      1,500, 500, 3))[x]<br/>  axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER],cmap='inferno')<br/>  axarr[1,x].grid(False)<br/>  f3 = activation_model.predict(test_images[IDX_IMAGE_3].reshape(<br/>      1, 500, 500, 3))[x]<br/>  axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER],cmap='inferno')<br/>  axarr[2,x].grid(False)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/db7950838512f6bd40b98a0aca201744.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*PGTvYzYzF8ilO6oCxbtzYg.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">由作者生成的图像:给定卷积层的中间图像表示</p></figure><p id="8990" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">我们可以在上面的图像中观察到，我们的基线模型似乎已经确定了定义每个类别的相关区别特征:角叶锈病、健康叶锈病和豆状叶锈病，通过不同的颜色梯度变得可见。</p><h2 id="342c" class="ml ks iq bd kt mm mn dn kx mo mp dp lb ls mq mr ld lw ms mt lf ma mu mv lh mw bi translated">扰动后</h2><p id="5a66" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">现在，我们可以检查基线模型在扰动数据中识别的特征:</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="2fd9" class="ml ks iq ny b gy oc od l oe of"># Pertubed test data<br/>perturbed_images = []<br/>for batch in test_set_for_adv_model:<br/>  perturbed_batch = reference_model.perturb_on_batch(batch)<br/>  perturbed_batch[IMAGE_INPUT_NAME] = tf.clip_by_value(<br/>  perturbed_batch[IMAGE_INPUT_NAME], 0.0, 1.0)<br/>  perturbed_images.append(perturbed_batch)</span><span id="36ce" class="ml ks iq ny b gy og od l oe of"># Get images<br/>pt_img = [item['image'] for item in perturbed_images]</span><span id="17d0" class="ml ks iq ny b gy og od l oe of">IDX_IMAGE_1=0<br/>IDX_IMAGE_2=1<br/>IDX_IMAGE_3=2<br/>CONVOLUTION_NUMBER = 11</span><span id="f5bf" class="ml ks iq ny b gy og od l oe of">base_mod_layer_out = [layer.output for layer in baseline_model.layers]</span><span id="84fe" class="ml ks iq ny b gy og od l oe of">base_mod_activ = tf.keras.models.Model(<br/>  inputs = baseline_model.input,<br/>  outputs = base_mod_layer_out)</span><span id="0b84" class="ml ks iq ny b gy og od l oe of">f1 = base_mod_activ.predict(pt_img[IDX_IMAGE_1].numpy())[x]<br/>f2 = base_mod_activ.predict(pt_img[IDX_IMAGE_2].numpy())[x]<br/>f3 = base_mod_activ.predict(pt_img[IDX_IMAGE_3].numpy())[x]</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi om"><img src="../Images/ca59c57a748bf0d0f667fff91a264305.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t0jMQ5T4qFsEHC6iXPsP9w.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">作者生成的图像:中间图像表示；敌对扰乱数据。</p></figure><p id="4d4b" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">正如我们在上面的表示中所观察到的，网络很难表示每幅图像中的原始像素，并且由于扰动而变得更加抽象。在最右边的图像中，似乎网络成功地保留了代表‘角叶锈病’的特征，但是叶子的基本结构大部分丢失了。当然，这只是我们未经调整的网络中的一个卷积层，但它仍然是一个可信的演示，说明了一个以前熟练的模型是如何被敌对的输入数据推翻的。</p><h1 id="d125" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">结论</h1><p id="95f7" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">在本文中，我们研究了如何使用对抗正则化显著提高卷积神经网络模型在对抗扰动数据上的鲁棒性和泛化性能。此外，我们还探索了:</p><ul class=""><li id="6f1a" class="nc nd iq ll b lm mg lp mh ls ne lw nf ma ng me nw ni nj nk bi translated">如何在 Keras 模型中添加对抗性规则？</li><li id="8e8f" class="nc nd iq ll b lm nl lp nm ls nn lw no ma np me nw ni nj nk bi translated">如何将一个对抗性的规范化模型与一个基线性能模型进行比较？</li><li id="2fe5" class="nc nd iq ll b lm nl lp nm ls nn lw no ma np me nw ni nj nk bi translated">如何通过可视化中间层来检查敌对扰动数据对传统训练模型的影响。</li></ul><p id="ed4b" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">如果您发现错误或有任何建设性的批评/构建，请评论。</p><p id="dc0f" class="pw-post-body-paragraph lj lk iq ll b lm mg jr lo lp mh ju lr ls mi lu lv lw mj ly lz ma mk mc md me ij bi translated">感谢您的阅读。</p><h1 id="2826" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">参考</h1><ul class=""><li id="dc02" class="nc nd iq ll b lm ln lp lq ls nt lw nu ma nv me nw ni nj nk bi translated"><a class="ae mf" href="http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42503.pdf" rel="noopener ugc nofollow" target="_blank">谷歌公司，NYU，2014 年，神经网络的有趣特性</a></li><li id="04f0" class="nc nd iq ll b lm nl lp nm ls nn lw no ma np me nw ni nj nk bi translated"><a class="ae mf" href="https://blog.tensorflow.org/2019/09/introducing-neural-structured-learning.html" rel="noopener ugc nofollow" target="_blank"> TensorFlow 博客，2019，神经结构化学习</a></li><li id="2547" class="nc nd iq ll b lm nl lp nm ls nn lw no ma np me nw ni nj nk bi translated"><a class="ae mf" href="https://arxiv.org/abs/1807.06732" rel="noopener ugc nofollow" target="_blank"> Gilmer 等人，2018 年，激励对抗性例子研究的游戏规则。</a></li></ul></div></div>    
</body>
</html>