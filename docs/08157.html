<html>
<head>
<title>Convolutional Neural Networks with TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">张量流卷积神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/convolutional-neural-networks-with-tensorflow-8c980d206330?source=collection_archive---------66-----------------------#2020-06-15">https://towardsdatascience.com/convolutional-neural-networks-with-tensorflow-8c980d206330?source=collection_archive---------66-----------------------#2020-06-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/850262146bf8e098e9c9fc3c30e96cca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qWvYScZmIplZkbTF9w_Y8Q.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">尼克·希利尔在<a class="ae jg" href="https://unsplash.com/s/photos/numbers?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><div class=""><h2 id="5c81" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">实现 LeNet 5 架构来对 MNIST 数据集上的数字进行分类。</h2></div><p id="9056" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi lu translated"><span class="l lv lw lx bm ly lz ma mb mc di">这个世界充满了非结构化数据，而不是结构化数据。它包括图像、文本、图表等等。这些数据很难分析，直到深度学习再次开始存在。深度学习是机器学习的一个分支，它受到大脑工作机制的启发，特别是对神经元的影响。人工神经元结合在一起形成一种叫做神经网络的东西。</span></p><p id="13e8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">深度学习取得了有影响力的进展，尤其是在图像数据上。图像数据非常复杂，因为它没有表格格式，而且有大量的参数，尤其是像素。假设当你使用 SVM 和逻辑回归等机器学习模型时，你想预测哪个图像代表猫，哪个图像代表狗，你必须自己确定猫和狗的区别。</p><p id="211e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">区分猫和狗的特征是什么？嗯，你可以通过它的鼻子、眼睛、耳朵等等来说。要捕捉这些特征，您可以使用卷积运算来捕捉这些特征。但是如果要提取特征，就存在一些问题。而是这些图像彼此之间的形式不同。因此，我们应该有一种方法，可以自己学习从图像中提取特征的参数。</p><p id="d58f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们必须处理两个任务，提取特征和预测图像。我们可以使用卷积神经网络(CNN)来解决我们的问题。</p><p id="9b75" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">与传统的机器学习相比，它的特别之处在于它可以捕捉数据的非线性。像支持向量机(SVM)和逻辑回归这样的算法仅从数据中估计线性函数来将它们分类。另一方面，由于激活函数，神经网络可以估计一个非线性函数，该函数将数据划分到它们的类别中。</p><p id="9895" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">神经网络如此强大的另一个原因是，该模型可以自己设计特征，并且由于反向传播的能力，它可以学习捕捉特征并正确预测数据。因此，神经网络是从非结构化数据中发现知识的完美模型。</p><p id="d76b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">本文将通过 Yann LeCun 的 LeNet 5 架构(第一个 CNN 架构)向您展示如何使用卷积神经网络解决图像分类问题。然后，我们将使用 Python 中的 TensorFlow 库实现它。本文的目标将是这样的，</p><ul class=""><li id="e501" class="md me jj la b lb lc le lf lh mf ll mg lp mh lt mi mj mk ml bi translated"><strong class="la jk">了解卷积神经网络的构建模块，</strong></li><li id="f678" class="md me jj la b lb mm le mn lh mo ll mp lp mq lt mi mj mk ml bi translated"><strong class="la jk">了解 CNN 架构，尤其是 LeNet 5 架构，最后</strong></li><li id="2ab3" class="md me jj la b lb mm le mn lh mo ll mp lp mq lt mi mj mk ml bi translated"><strong class="la jk">可以用 Python 中的 TensorFlow 实现架构</strong></li></ul></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="71f8" class="my mz jj bd na nb nc nd ne nf ng nh ni kp nj kq nk ks nl kt nm kv nn kw no np bi translated"><strong class="ak">基本面</strong></h1><p id="6f8a" class="pw-post-body-paragraph ky kz jj la b lb nq kk ld le nr kn lg lh ns lj lk ll nt ln lo lp nu lr ls lt im bi translated">在我们开始实施之前，为了确保您不会感到困惑，我将向您展示卷积神经网络的基础知识。它由卷积层、子采样(池化)层和全连接层组成。</p><h2 id="034e" class="nv mz jj bd na nw nx dn ne ny nz dp ni lh oa ob nk ll oc od nm lp oe of no og bi translated"><strong class="ak">卷积层</strong></h2><figure class="oi oj ok ol gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oh"><img src="../Images/8c857149ce9e026d05b1761477458103.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*auR2-uuekbC5UYtJ"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">摘自<a class="ae jg" href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks" rel="noopener ugc nofollow" target="_blank">斯坦福 CS230 课程备忘单</a></p></figure><p id="1b1b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">卷积层是使用卷积过滤器捕捉图像特征的层。如前所述，卷积是一种用给定的过滤器计算像素的操作，通过逐元素相乘，然后将它们作为一个数字相加。</p><p id="5869" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">过滤器将减少数据的维度，但维度的数量会随着时间的推移而增加。如果我们想保持图像的尺寸，我们可以设置填充。填充在图像的边界添加缺失的像素。因此，它将具有与前一个相同的维度。</p><p id="b7c9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">或者在做卷积的时候想避免像素重叠，可以用 stride。步幅是一种操作，其中卷积过程将随着其给定的数字而跳跃。利用这一点，它可以按照给定的数目跳几级。</p><p id="1734" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该图层将学习适合数据的参数，因此可以准确预测图像。此外，因为它希望捕捉图像的非线性，该层包含一个名为整流线性单元(ReLU)的激活，它将负值设置为 0，否则将是值本身。因此，通过使用这一层，我们不必手动提取特征。</p><h2 id="498f" class="nv mz jj bd na nw nx dn ne ny nz dp ni lh oa ob nk ll oc od nm lp oe of no og bi translated"><strong class="ak">汇集层</strong></h2><figure class="oi oj ok ol gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi om"><img src="../Images/c12461eb3c9982e9960fb57d1c3be039.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*CdAfjJ6m1NJl2bzM.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">来自<a class="ae jg" href="https://www.geeksforgeeks.org/cnn-introduction-to-pooling-layer/" rel="noopener ugc nofollow" target="_blank"> GeeksForGeeks </a></p></figure><p id="80e7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">池层基本上是一个降低数据维度的层。该层的机制类似于卷积层，只是它不应用任何滤镜。池层的例子是最大池层。它将取图像对应的每个区域的最大值，正如我们可以看到上面的图像。通过获取图像每个区域的最大值，图层可用于汇总图像。</p><h2 id="5534" class="nv mz jj bd na nw nx dn ne ny nz dp ni lh oa ob nk ll oc od nm lp oe of no og bi translated"><strong class="ak">全连接层</strong></h2><p id="0c4e" class="pw-post-body-paragraph ky kz jj la b lb nq kk ld le nr kn lg lh ns lj lk ll nt ln lo lp nu lr ls lt im bi translated">在卷积和池层之后，现在图像进入完全连接的层。该图层将处理预测结果。它类似于人工神经网络(ANN)图层，因为它包含节点，对于预测已缩减像素采样的图像非常有用，并且其特征已经被检索。该机制也类似于人工神经网络，但它增加了卷积层，以自动进行特征提取。</p></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="81b8" class="my mz jj bd na nb nc nd ne nf ng nh ni kp nj kq nk ks nl kt nm kv nn kw no np bi translated"><strong class="ak"> LeNet 5 架构</strong></h1><p id="5020" class="pw-post-body-paragraph ky kz jj la b lb nq kk ld le nr kn lg lh ns lj lk ll nt ln lo lp nu lr ls lt im bi translated">在我们知道 CNN 的构建模块之后，我们如何实现它呢？我们可以参考现有的对它的研究，可以用它的架构作为我们的参考来构建自己的 CNN 模型。对于本文，我们将使用现有的第一个 CNN 架构。它来自 Yann LeCun 和他的团队在 1998 年发表的一篇名为“基于梯度的学习应用于文档识别”的论文。他们提出了一个名为 LeNet 5 的架构。它看起来像这样，</p><figure class="oi oj ok ol gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi on"><img src="../Images/f784fd750f88b654c3ec4ffb63b93ece.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yhB9rDp2fPnsbOxZ_X5sKQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">摘自 Yann LeCun 关于 LeNet 5 的论文</p></figure><p id="7ea1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一般来说，架构由几层组成。流程看起来像这样，</p><blockquote class="oo op oq"><p id="768c" class="ky kz or la b lb lc kk ld le lf kn lg os li lj lk ot lm ln lo ou lq lr ls lt im bi translated">Conv = &gt;池=&gt; Conv = &gt;池= &gt;全连接层= &gt;输出</p></blockquote><p id="d83b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">它将执行两个常规步骤。它们是特征提取(Conv = &gt;池序列)和用于预测值的全连接层。如果我们观察细节，每一层至少重复两次。这就是为什么它被称为深度学习，因为它比现有的机器学习模型更深入地学习数据。</p><p id="a87a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在我们了解架构之后，我们可以直接进入实现。为了实现这一点，我们将使用 TensorFlow 及其 Keras API 来实现。我们将使用来自 Keras 的高级 API，因此您可以更容易地实现模型，而不是使用低级 API。</p></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="457a" class="my mz jj bd na nb nc nd ne nf ng nh ni kp nj kq nk ks nl kt nm kv nn kw no np bi translated">行动（或活动、袭击）计划</h1><p id="c854" class="pw-post-body-paragraph ky kz jj la b lb nq kk ld le nr kn lg lh ns lj lk ll nt ln lo lp nu lr ls lt im bi translated">在我们实现这一点之前，我将向您概述一下我们将如何使用 TensorFlow 实现这一架构，</p><ol class=""><li id="ea11" class="md me jj la b lb lc le lf lh mf ll mg lp mh lt ov mj mk ml bi translated">准备数据</li><li id="857f" class="md me jj la b lb mm le mn lh mo ll mp lp mq lt ov mj mk ml bi translated">构建模型并设置优化器</li><li id="2e5e" class="md me jj la b lb mm le mn lh mo ll mp lp mq lt ov mj mk ml bi translated">拟合模型并用数据验证集进行验证</li></ol></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="d323" class="my mz jj bd na nb nc nd ne nf ng nh ni kp nj kq nk ks nl kt nm kv nn kw no np bi translated">实施</h1><h2 id="8b19" class="nv mz jj bd na nw nx dn ne ny nz dp ni lh oa ob nk ll oc od nm lp oe of no og bi translated">准备数据</h2><p id="ff36" class="pw-post-body-paragraph ky kz jj la b lb nq kk ld le nr kn lg lh ns lj lk ll nt ln lo lp nu lr ls lt im bi translated">在我们实现模型之前，我们必须准备数据。首先，我们将导入数据。它的来源是 Kaggle 上的数字识别竞赛。它由 60000 行组成。然后，它分成 42000 个观察值用于训练数据，其余的用于模型的测试数据。在我们导入数据后，数据最初看起来是这样的，</p><figure class="oi oj ok ol gt iv gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/583a25c20fbd053b135919918b573875.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*B4cJQaIZy1Av_R0p-UMy2w.png"/></div></figure><p id="4752" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">数据集仍为表格格式。列表示标签和对应于图像的像素。因此，我们必须重塑数据集。但在此之前，请确保首先对图像进行归一化，然后对数据集进行整形。最后，我们将训练数据分成两部分，模型的训练和验证数据集。</p><p id="7fe3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这样做的代码看起来像这样，</p><pre class="oi oj ok ol gt ox oy oz pa aw pb bi"><span id="841b" class="nv mz jj oy b gy pc pd l pe pf"><strong class="oy jk"># Import The Libraries</strong><br/>import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import tensorflow as tf<br/>from tensorflow.keras import layers, models<br/>from sklearn.model_selection import train_test_split</span><span id="b260" class="nv mz jj oy b gy pg pd l pe pf"><strong class="oy jk"># Import The Dataset</strong><br/>train = pd.read_csv('../input/digit-recognizer/train.csv')<br/>test = pd.read_csv('../input/digit-recognizer/test.csv')</span><span id="a48b" class="nv mz jj oy b gy pg pd l pe pf"><strong class="oy jk"># Prepare the training set</strong><br/>train_image = train.drop('label', axis=1)<br/>train_label = train['label']</span><span id="2cc9" class="nv mz jj oy b gy pg pd l pe pf"><strong class="oy jk"># Normalize the data</strong><br/>train_image = train_image / 255.0<br/>test_image = test / 255.0</span><span id="ad10" class="nv mz jj oy b gy pg pd l pe pf"><strong class="oy jk"># Reshaping the image</strong><br/>train_image = train_image.values.reshape(-1, 28, 28, 1)<br/>test_image = test_image.values.reshape(-1, 28, 28, 1)</span><span id="935f" class="nv mz jj oy b gy pg pd l pe pf"><strong class="oy jk"># Split into training and validation dataset</strong><br/>X_train, X_val, y_train, y_val = train_test_split(train_image, train_label, test_size=0.1, random_state=42)</span></pre><p id="cd88" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于数据的预览，它看起来像这样，</p><figure class="oi oj ok ol gt iv gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/a7000eaeb265788766a6d495bc8a2623.png" data-original-src="https://miro.medium.com/v2/resize:fit:648/format:webp/1*n5m0N1hJFvZ4fuW78UyqnQ.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图像的预览</p></figure><h2 id="2489" class="nv mz jj bd na nw nx dn ne ny nz dp ni lh oa ob nk ll oc od nm lp oe of no og bi translated">建立模型</h2><p id="b022" class="pw-post-body-paragraph ky kz jj la b lb nq kk ld le nr kn lg lh ns lj lk ll nt ln lo lp nu lr ls lt im bi translated">准备好数据后，我们就可以建立模型了。我们将基于架构构建模型，并使用我们的数据集进行调整，因为数据与原始纸张的维度不同，即 28 x 28 x 1。正如我们之前所说的，模型的流程看起来像这样，</p><blockquote class="oo op oq"><p id="9d12" class="ky kz or la b lb lc kk ld le lf kn lg os li lj lk ot lm ln lo ou lq lr ls lt im bi translated">Conv = &gt;池=&gt; Conv = &gt;池= &gt;完全连接</p></blockquote><p id="b26f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是构建它的代码，</p><pre class="oi oj ok ol gt ox oy oz pa aw pb bi"><span id="92d2" class="nv mz jj oy b gy pc pd l pe pf">model = models.Sequential()<br/><strong class="oy jk"># Feature Extraction Section (The Convolution and The Pooling Layer)</strong><br/>model.add(layers.Conv2D(filters=6, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)))<br/>model.add(layers.AveragePooling2D())<br/>model.add(layers.Conv2D(filters=16, kernel_size=(5, 5), activation='relu'))<br/>model.add(layers.AveragePooling2D())<br/><strong class="oy jk"># Reshape the image into one-dimensional vector</strong><br/>model.add(layers.Flatten())<br/><strong class="oy jk"># Classification Section (The Fully Connected Layer)</strong><br/>model.add(layers.Dense(120, activation='relu'))<br/>model.add(layers.Dense(84, activation='relu'))<br/>model.add(layers.Dense(10, activation='softmax'))<br/><strong class="oy jk"># Show summary of the model</strong><br/>model.summary()</span></pre><p id="f914" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在我们建立模型之后，摘要将会是这样的，</p><figure class="oi oj ok ol gt iv gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/7f7adbf1b7cc9243400ce992e3066c3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*CXJ_j7owjgmgwxvWSTtAKA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">模型的总结</p></figure><p id="6614" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如我们所看到的，我们可以看到图像的尺寸减少了，但过滤器的数量增加了。在我们提取特征后，我们将图像整形为一维向量来预测它。此外，我们可以看到，除了池层之外，每一层都有一定数量的参数。在这种情况下，模型要学习 44426 层。该模型将学习这些参数，以实现预测图像的更高精度。</p><p id="c41b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了适应和优化这个模型，代码应该是这样的，</p><pre class="oi oj ok ol gt ox oy oz pa aw pb bi"><span id="e2f9" class="nv mz jj oy b gy pc pd l pe pf"><strong class="oy jk"># Compile The Model</strong><br/>model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])</span><span id="de45" class="nv mz jj oy b gy pg pd l pe pf"><strong class="oy jk"># Fit And Evaluate The Model Using Validation Dataset</strong><br/>history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))</span><span id="3252" class="nv mz jj oy b gy pg pd l pe pf"><strong class="oy jk"># Evaluate The Model Using Plot<br/></strong>plt.plot(history.history['accuracy'], label='accuracy')<br/>plt.plot(history.history['val_accuracy'], label = 'val_accuracy')<br/>plt.xlabel('Epoch')<br/>plt.ylabel('Accuracy')<br/>plt.ylim([0.95, 1])<br/>plt.legend(loc='lower right')</span></pre><p id="4b62" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">之后，模型拟合数据，并根据历元数重复几次。为了评价，模型达到这样的精度，</p><figure class="oi oj ok ol gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pj"><img src="../Images/43fbc8afb230cda8b58c4b9d48bc2dfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l72niEwYlyuK5MhPvzgDHQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">拟合过程</p></figure><figure class="oi oj ok ol gt iv gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/e15ab27f2eeec2f7f939a378940e77d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*0BSKqcbAAE5jxD3gqjAs5A.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">带精度结果的历元线图</p></figure><p id="8145" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如我们可以看到的，我们得出的结论是，5 的历元数比任何历元数都要稍好一些。因此，我们可以只使用 5 个时期来建立模型，并且我们可以使用它来预测值。</p></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="bf7b" class="my mz jj bd na nb nc nd ne nf ng nh ni kp nj kq nk ks nl kt nm kv nn kw no np bi translated">最终想法</h1><p id="faf3" class="pw-post-body-paragraph ky kz jj la b lb nq kk ld le nr kn lg lh ns lj lk ll nt ln lo lp nu lr ls lt im bi translated">我们已经使用 LeNet 5 架构在 MNIST 数据集上建立了模型。我们模型的精确度已经很高了，但我们还可以进一步改进模型。为了改进模型，我们可以增加数据，微调模型，添加更多的过滤器和模型的深度，等等。</p><p id="731d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">存在许多 CNN 架构，例如 VGG-16、ResNet、AlexNet 等等。我必须告诉你这只是开始。关于计算机视觉，我们可以学到很多东西。我希望这篇文章将是你开始计算机视觉之旅的一个很好的开端，我也希望你可以使用 CNN 或其他方式开发一个很好的应用程序。</p></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h2 id="f467" class="nv mz jj bd na nw nx dn ne ny nz dp ni lh oa ob nk ll oc od nm lp oe of no og bi translated">参考</h2><p id="5ff7" class="pw-post-body-paragraph ky kz jj la b lb nq kk ld le nr kn lg lh ns lj lk ll nt ln lo lp nu lr ls lt im bi translated">[1]马丁·阿巴迪等人。艾尔。<em class="or"> TensorFlow:异构系统上的大规模机器学习</em> (2015)。tensorflow.org 提供的软件。<br/> [2]扬·勒存等。艾尔。<em class="or">基于梯度的学习应用于文档识别。</em>IEEE 会报，第 86 卷，第 11 期，第 2278-2324 页，1998 年 11 月，doi: 10.1109/5.726791。<br/> [3] Yann LeCun 等。艾尔。<em class="or">深度学习</em> (2015)。《自然》, 521(7553)，第 436-444 页。</p></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h2 id="510d" class="nv mz jj bd na nw nx dn ne ny nz dp ni lh oa ob nk ll oc od nm lp oe of no og bi translated">感谢您阅读我的文章，您也可以在下面查看我以前的文章:</h2><div class="is it gp gr iu pl"><a rel="noopener follow" target="_blank" href="/time-series-forecasting-with-arima-model-in-r-77f4e2ae7abb"><div class="pm ab fo"><div class="pn ab po cl cj pp"><h2 class="bd jk gy z fp pq fr fs pr fu fw ji bi translated">R 中 ARIMA 模型的时间序列预测</h2><div class="ps l"><h3 class="bd b gy z fp pq fr fs pr fu fw dk translated">从勘探到预测 1970 年至 2015 年的二氧化碳排放数据。</h3></div><div class="pt l"><p class="bd b dl z fp pq fr fs pr fu fw dk translated">towardsdatascience.com</p></div></div><div class="pu l"><div class="pv l pw px py pu pz ja pl"/></div></div></a></div><div class="is it gp gr iu pl"><a rel="noopener follow" target="_blank" href="/introduction-to-time-series-analysis-with-r-a2f97650baa3"><div class="pm ab fo"><div class="pn ab po cl cj pp"><h2 class="bd jk gy z fp pq fr fs pr fu fw ji bi translated">R 时间序列分析导论</h2><div class="ps l"><h3 class="bd b gy z fp pq fr fs pr fu fw dk translated">从探索，到预测。使用印度尼西亚 2002 年 12 月至 2020 年 4 月的消费者价格指数(CPI)数据</h3></div><div class="pt l"><p class="bd b dl z fp pq fr fs pr fu fw dk translated">towardsdatascience.com</p></div></div><div class="pu l"><div class="qa l pw px py pu pz ja pl"/></div></div></a></div><div class="is it gp gr iu pl"><a rel="noopener follow" target="_blank" href="/data-science-and-competitive-programming-2887300207c0"><div class="pm ab fo"><div class="pn ab po cl cj pp"><h2 class="bd jk gy z fp pq fr fs pr fu fw ji bi translated">数据科学和竞争性编程</h2><div class="ps l"><h3 class="bd b gy z fp pq fr fs pr fu fw dk translated">他们在解决问题，但方法不同。</h3></div><div class="pt l"><p class="bd b dl z fp pq fr fs pr fu fw dk translated">towardsdatascience.com</p></div></div><div class="pu l"><div class="qb l pw px py pu pz ja pl"/></div></div></a></div></div></div>    
</body>
</html>