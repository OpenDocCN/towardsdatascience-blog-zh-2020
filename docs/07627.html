<html>
<head>
<title>Make computations on large cross joined Spark DataFrames faster</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">加快大型交叉连接火花数据帧的计算速度</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/make-computations-on-large-cross-joined-spark-dataframes-faster-6cc36e61a222?source=collection_archive---------24-----------------------#2020-06-08">https://towardsdatascience.com/make-computations-on-large-cross-joined-spark-dataframes-faster-6cc36e61a222?source=collection_archive---------24-----------------------#2020-06-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5663" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">减少输入数据帧上的分区数量，以加快交叉连接数据帧的计算速度。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/96b81eb54b4f916d810c8e7b1b5e5e49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bJEJyrSPeJeRcg6W"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@saffu?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">萨夫</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="4d25" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Spark </a>将数据分割成分区，并在这些分区上并行执行任务，使您的计算并行运行。分区的数量对Spark计算的运行时间有直接影响。<br/><br/>Spark计算通常涉及交叉连接两个Spark <a class="ae kv" href="https://spark.apache.org/docs/latest/sql-programming-guide.html#datasets-and-dataframes" rel="noopener ugc nofollow" target="_blank">数据帧</a>，即创建一个新的数据帧，包含两个输入数据帧中每一行的组合。当交叉连接大型数据帧时，Spark会成倍增加输入数据帧的分区数量。这可能导致交叉连接数据帧中的分区数量显著增加。因此，由于管理分区上许多小任务的额外开销，在该数据帧上运行计算会非常慢。<br/><br/> <br/>让我们考虑两个场景来理解交叉连接数据帧时分区是如何工作的:</p><h2 id="6129" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">场景1:较小的数据帧</h2><p id="aaa1" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">如果输入数据帧的大小较小，那么交叉连接数据帧的分区数将等于输入数据帧的分区数。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="48a3" class="ls lt iq mr b gy mv mw l mx my">scala&gt; val xDF = (1 to 1000).toList.toDF("x")<br/>scala&gt; xDF.rdd.partitions.size<br/>res11: Int = 2</span><span id="cc38" class="ls lt iq mr b gy mz mw l mx my">scala&gt; val yDF = (1 to 1000).toList.toDF("y")<br/>scala&gt; yDF.rdd.partitions.size<br/>res12: Int = 2</span><span id="afec" class="ls lt iq mr b gy mz mw l mx my">scala&gt; val crossJoinDF = xDF.crossJoin(yDF)<br/>scala&gt; crossJoinDF.rdd.partitions.size<br/>res13: Int = 2</span></pre><p id="7ec4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这种情况下，<br/>xDF的分区= = yDF的分区= = crossJoinDF的分区<br/> <br/>如果输入数据帧的分区，即xDF或yDF不相等，那么交叉连接的数据帧的分区将等于输入数据帧之一。</p><h2 id="e453" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">场景2:更大的数据框架</h2><p id="0c12" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">如果我们增加输入数据帧的数据大小，交叉连接数据帧上的分区行为会发生变化。<br/>在以下示例中，我将输入数据帧中的行数从1000增加到1，000，000</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="796d" class="ls lt iq mr b gy mv mw l mx my">scala&gt; val xDF = (1 to 1000000).toList.toDF("x")<br/>scala&gt; xDF.rdd.partitions.size<br/>res15: Int = 2</span><span id="195e" class="ls lt iq mr b gy mz mw l mx my">scala&gt; val yDF = (1 to 1000000).toList.toDF("y")<br/>scala&gt; yDF.rdd.partitions.size<br/>res16: Int = 2</span><span id="3f4d" class="ls lt iq mr b gy mz mw l mx my">scala&gt; val crossJoinDF = xDF.crossJoin(yDF)<br/>scala&gt; crossJoinDF.rdd.partitions.size<br/>res17: Int = 4</span></pre><p id="a1c2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这种情况下，交叉连接的数据帧的分区大小等于输入数据帧分区<br/> <br/>的乘积crossJoinDF =(xDF的分区)yDF的分区)。<br/> <br/>如果您的输入数据帧有更多的列或更大的数据类型，您也能够在只有几千行的数据帧上复制这种行为。<br/> <br/>一个数据帧的确切分区数量因硬件而异，但交叉连接大型数据帧时分区的交叉乘法在所有类型的硬件上都是一致的。</p><h1 id="d9dc" class="na lt iq bd lu nb nc nd lx ne nf ng ma jw nh jx md jz ni ka mg kc nj kd mj nk bi translated">那么，如果Spark将大输入数据帧的分区相乘来为交叉连接的数据帧创建分区，会有什么问题呢？</h1><p id="3b8c" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">如果您的输入数据帧包含几百个分区(大约100个)，这是处理大数据时的典型情况，那么交叉连接的数据帧将包含大约10，000个分区。<br/> <br/>数据帧分区的数量对计算的运行时间有影响:</p><ul class=""><li id="85d1" class="nl nm iq ky b kz la lc ld lf nn lj no ln np lr nq nr ns nt bi translated">如果分区太少，您的计算将无法利用集群中所有可用的并行性。</li><li id="aed5" class="nl nm iq ky b kz nu lc nv lf nw lj nx ln ny lr nq nr ns nt bi translated">如果你有太多的分区，在管理许多小任务时会有过多的开销，使得你的计算运行起来非常慢。</li></ul><p id="934a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">交叉连接具有不到100个分区的大型数据帧属于后一种情况，这会导致数据帧具有10，000个数量级的太多分区。这使得对交叉连接数据帧的任何操作都非常慢。在具有大量分区的交叉连接数据帧上运行操作时，您可能会遇到以下异常:</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="01cb" class="ls lt iq mr b gy mv mw l mx my">org.apache.spark.SparkException Job aborted due to stage failure: <br/>Total size of serialized results of 147936 tasks (1024.0 MB) is bigger than <br/>spark.driver.maxResultSize (1024.0 MB)</span></pre><p id="4f15" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是因为Spark将每个任务的状态数据发送回驱动程序。由于有许多分区(或任务)，这些数据经常会超过默认的1024 MB的限制。<br/> <br/>增加Spark配置<em class="nz">Spark . driver . max resultsize</em>的值将使您的计算运行时不会抛出上述异常，但不会使它更快。大量分区的固有问题仍然存在。</p><h1 id="bfbc" class="na lt iq bd lu nb nc nd lx ne nf ng ma jw nh jx md jz ni ka mg kc nj kd mj nk bi translated">你如何使计算更快？</h1><p id="23bc" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">要加快计算速度，请在交叉连接之前减少输入数据帧的分区数量，以便交叉连接后的数据帧不会有太多分区。<br/> <br/>作为一个真实世界的例子，我需要交叉连接两个数据帧df1和df2，以计算两个数据帧的行的每个组合之间的余弦相似性。两个数据帧都由文本和长度为500的双精度数组组成，表示文本嵌入。数据帧df1由大约60，000行组成，数据帧df2由130，000行组成。使用40名<a class="ae kv" href="https://docs.aws.amazon.com/glue/latest/dg/add-job.html" rel="noopener ugc nofollow" target="_blank"> G.1X </a>型工人在<a class="ae kv" href="https://aws.amazon.com/glue/" rel="noopener ugc nofollow" target="_blank"> AWS胶水</a>上对交叉连接的数据帧进行连续计数需要大约6个小时。在交叉连接之前将df1和df2重新划分为更少的分区，将交叉连接数据帧的计算时间减少到40分钟！<br/> <br/>为了便于说明，我将从df1和df2数据帧中抽取少量样本。将包含17，000行和200个分区的df1与包含15，000行和200个分区的df2交叉连接，可创建包含40，000个分区的交叉连接数据帧。对交叉连接的数据帧进行计数需要285，163，427，988 ns，即4.75分钟。</p><blockquote class="oa ob oc"><p id="2651" class="kw kx nz ky b kz la jr lb lc ld ju le od lg lh li oe lk ll lm of lo lp lq lr ij bi translated"><em class="iq">以下代码是在AWS Glue上执行的，有40名G1类型的工人。x使用Spark 2.4 </em></p></blockquote><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="3dda" class="ls lt iq mr b gy mv mw l mx my">scala&gt; df1.count()<br/>res73: Long = 17000</span><span id="30c6" class="ls lt iq mr b gy mz mw l mx my">scala&gt; df1.show(4)<br/>+---------------------------+--------------------+<br/>|                       text|      text_embedding|<br/>+---------------------------+--------------------+<br/>|eiffel tower location      |[0.4, 0.02, 0.1, ...|<br/>|pounds kilogram conversion |[0.01, 0.2, 0.1, ...|<br/>|capital of spain           |[0.05, 0.2, 0.2, ...|<br/>|mount everest height       |[0.07, 0.1, 0.1, ...|<br/>+---------------------------+--------------------+</span><span id="554b" class="ls lt iq mr b gy mz mw l mx my">scala&gt; df1.rdd.partitions.size<br/>res74: Int = 200</span><span id="a176" class="ls lt iq mr b gy mz mw l mx my">scala&gt; df2.count()<br/>res75: Long = 15000</span><span id="eed4" class="ls lt iq mr b gy mz mw l mx my">scala&gt; df2.rdd.partitions.size<br/>res76: Int = 200</span><span id="6a4e" class="ls lt iq mr b gy mz mw l mx my">scala&gt; df2.show(4)<br/>+------------------------------+--------------------+<br/>|                          text|      text_embedding|<br/>+------------------------------+--------------------+<br/>|where is eiffel tower located |[0.3, 0.01, 0.1, ...|<br/>|how many pounds in a kilogram |[0.02, 0.2, 0.1, ...|<br/>|what is the capital of spain  |[0.03, 0.2, 0.2, ...|<br/>|how tall is mount everest     |[0.06, 0.1, 0.1, ...|<br/>+------------------------------+--------------------+</span><span id="897c" class="ls lt iq mr b gy mz mw l mx my">scala&gt; val finalDF = df1.crossJoin(df2)</span><span id="f225" class="ls lt iq mr b gy mz mw l mx my">scala&gt; finalDF.rdd.partitions.size <br/>res77: Int = 40000</span><span id="64a7" class="ls lt iq mr b gy mz mw l mx my">scala&gt; time {finalDF.count()}<br/>Elapsed time: 285163427988ns<br/>res78: Long = 255000000</span></pre><p id="c761" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们在执行交叉连接之前将df1和df2上的分区数量减少到40，那么在交叉连接的数据帧上运行计数的时间将减少到47，178，149，994 ns，即47秒！我们选择了40个分区来利用40个工作集群中所有可用的并行性。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="7148" class="ls lt iq mr b gy mv mw l mx my">scala&gt; val df1 = df1.repartition(40)<br/>scala&gt; df1.rdd.partitions.size <br/>res80: Int = 40</span><span id="82dd" class="ls lt iq mr b gy mz mw l mx my">scala&gt; val df2 = df2.repartition(40)<br/>scala&gt; df2.rdd.partitions.size <br/>res81: Int = 40</span><span id="5eca" class="ls lt iq mr b gy mz mw l mx my">scala&gt; val finalDF = df1.crossJoin(df2)<br/>scala&gt; finalDF.rdd.partitions.size <br/>res82: Int = 1600</span><span id="19b2" class="ls lt iq mr b gy mz mw l mx my">scala&gt; time {finalDF.count()}<br/>Elapsed time: 47178149994ns<br/>res86: Long = 255000000</span></pre><p id="3bcf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在交叉连接数据帧之前减少分区数量，可以将计算交叉连接数据帧的时间减少6倍！</p><h1 id="63c6" class="na lt iq bd lu nb nc nd lx ne nf ng ma jw nh jx md jz ni ka mg kc nj kd mj nk bi translated">外卖</h1><p id="487e" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">下次在执行交叉连接后发现Spark计算变慢时，一定要检查交叉连接数据帧上的分区数量。如果分区太多，请减少输入数据帧上的分区数量，以加快对结果交叉连接数据帧的操作。</p></div></div>    
</body>
</html>