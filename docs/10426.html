<html>
<head>
<title>House Prices Prediction Using Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于深度学习的房价预测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/house-prices-prediction-using-deep-learning-dea265cc3154?source=collection_archive---------3-----------------------#2020-07-22">https://towardsdatascience.com/house-prices-prediction-using-deep-learning-dea265cc3154?source=collection_archive---------3-----------------------#2020-07-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="13e5" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">Keras 回归与多元线性回归</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/e67b869cb04007e784a408b0f7945edc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o1QnTHtiBsQa6xuwTQLT8A.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由佛罗里达州 KW insta gram 上的@ <a class="ae kv" href="https://www.instagram.com/p/B-2gBVqhuME/?utm_source=ig_web_copy_link" rel="noopener ugc nofollow" target="_blank"> Kusseyl </a>拍摄</p></figure><p id="5412" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本教程中，我们将创建一个模型来预测房价🏡基于不同市场的各种因素。</p><h1 id="57d2" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">问题陈述</h1><p id="ab19" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">这一统计分析的目的是帮助我们理解房屋特征之间的关系，以及如何使用这些变量来预测房价。</p><h1 id="cd33" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">目标</h1><ul class=""><li id="38a1" class="mp mq iq ky b kz mk lc ml lf mr lj ms ln mt lr mu mv mw mx bi translated">预测房价</li><li id="92bd" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">在最小化预测和实际评级之间的差异方面使用两种不同的模型</li></ul><p id="a3e2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">所用数据:</strong><a class="ae kv" href="https://www.kaggle.com/harlfoxem/housesalesprediction" rel="noopener ugc nofollow" target="_blank">ka ggle-KC _ house Dataset</a><br/><strong class="ky ir">GitHub:</strong>你可以在这里找到我的源代码<a class="ae kv" href="https://github.com/mahsamir/CaseStudy-KerasRegression" rel="noopener ugc nofollow" target="_blank"/></p></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="368d" class="ls lt iq bd lu lv nk lx ly lz nl mb mc jw nm jx me jz nn ka mg kc no kd mi mj bi translated">步骤 1:探索性数据分析(EDA)</h1><p id="dcdd" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">首先，让我们导入数据，看看我们正在处理哪种数据:</p><pre class="kg kh ki kj gt np nq nr ns aw nt bi"><span id="a667" class="nu lt iq nq b gy nv nw l nx ny"><strong class="nq ir">#import required libraries<br/></strong>import pandas as pd<br/>import numpy as np<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt</span><span id="af6d" class="nu lt iq nq b gy nz nw l nx ny"><strong class="nq ir">#import Data<br/></strong>Data = pd.read_csv('kc_house_data.csv')<br/>Data.head(5).T</span><span id="6a8d" class="nu lt iq nq b gy nz nw l nx ny"><strong class="nq ir">#get some information about our Data-Set<br/></strong>Data.info()<br/>Data.describe().transpose()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/cf845c18ee334af78096e9f245e65460.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*un2MVx-5yHJvChFWoHvpgw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">我们数据集的前 5 条记录</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/1f8fda225be74ceb5cb263981ab2fed4.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*Qm27s9tFefKbzBjDcdP6Tw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">关于数据集的信息，你的变量是哪种数据类型</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/b582524c12630222fe830c074a509573.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ULPxj4J4EQUSeXmcHrFlcw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">数据集的统计摘要</p></figure><p id="19d1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">已提供以下功能:<em class="od"><br/></em><strong class="ky ir"><em class="od">日期:</em> </strong> <em class="od">房屋出售日期<br/> </em> ✔️ <strong class="ky ir"> <em class="od">价格:</em> </strong> <em class="od">价格为预测目标<br/> </em> ✔️ <strong class="ky ir"> <em class="od">卧室:</em> </strong> <em class="od">卧室/房屋数量<br/> </em> ✔️ <strong class="ky ir"> <em class="od">卫生间:</em> </strong> <em class="od">卫生间数量 拍品镜头<br/> </em> ✔️ <strong class="ky ir"> <em class="od">楼层:</em> </strong> <em class="od">房屋总层数<br/> </em> ✔️ <strong class="ky ir"> <em class="od">滨水:</em> </strong> <em class="od">可以看到滨水景观的房屋<br/></em><strong class="ky ir"><em class="od">查看:</em> </strong> <em class="od">已查看<br/> </em> ✔️ <strong class="ky ir"> <em class="od"> 根据景县分级系统<br/></em>✔️<strong class="ky ir"><em class="od">sqft _ above:</em></strong><em class="od">房屋面积(不含地下室)<br/></em>✔️<strong class="ky ir"><em class="od">sqft _ base:</em></strong><em class="od">地下室面积<br/></em>✔️<strong class="ky ir"><em class="od">yr _ build:</em></strong><em class="od">建造年份<br/> 【T10 坐标<br/> </em> ✔️ <strong class="ky ir"> <em class="od">长:</em> </strong> <em class="od">经度坐标<br/></em>✔️<strong class="ky ir"><em class="od">sqft _ living 15:</em></strong><em class="od">客厅面积 2015 年(暗示—部分装修)<br/></em>✔️<strong class="ky ir"><em class="od">sqft _ lot 15:</em></strong></strong></p></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><p id="82e7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们绘制几个特征，以便更好地理解数据</p><pre class="kg kh ki kj gt np nq nr ns aw nt bi"><span id="91b5" class="nu lt iq nq b gy nv nw l nx ny"><strong class="nq ir">#visualizing house prices</strong><br/>fig = plt.figure(figsize=(10,7))<br/>fig.add_subplot(2,1,1)<br/>sns.distplot(Data['price'])<br/>fig.add_subplot(2,1,2)<br/>sns.boxplot(Data['price'])<br/>plt.tight_layout()</span><span id="63a4" class="nu lt iq nq b gy nz nw l nx ny"><strong class="nq ir">#visualizing square footage of (home,lot,above and basement)</strong><em class="od"><br/></em>fig = plt.figure(figsize=(16,5))<br/>fig.add_subplot(2,2,1)<br/>sns.scatterplot(Data['sqft_above'], Data['price'])<br/>fig.add_subplot(2,2,2)<br/>sns.scatterplot(Data['sqft_lot'],Data['price'])<br/>fig.add_subplot(2,2,3)<br/>sns.scatterplot(Data['sqft_living'],Data['price'])<br/>fig.add_subplot(2,2,4)<br/>sns.scatterplot(Data['sqft_basement'],Data['price'])</span><span id="eadc" class="nu lt iq nq b gy nz nw l nx ny"><strong class="nq ir">#visualizing bedrooms,bathrooms,floors,grade<br/></strong>fig = plt.figure(figsize=(15,7))<br/>fig.add_subplot(2,2,1)<br/>sns.countplot(Data['bedrooms'])<br/>fig.add_subplot(2,2,2)<br/>sns.countplot(Data['floors'])<br/>fig.add_subplot(2,2,3)<br/>sns.countplot(Data['bathrooms'])<br/>fig.add_subplot(2,2,4)<br/>sns.countplot(Data['grade'])<br/>plt.tight_layout()</span></pre><p id="235b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">通过价格分布图，我们可以看到大多数价格在 0 到 100 万之间，只有少数异常值接近 800 万(豪宅😉).在我们的分析中去掉那些异常值是有意义的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/0479909b936f1a93beecad4aac5f14c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ifthlzoLkm220KoUG1dl7w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">房价预测</p></figure><p id="750b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">快速浏览不同特征分布与房价的关系是非常有用的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi of"><img src="../Images/4c44b419f8602533d92f88fd44087e58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CPm9URj3e-z3P6A-eFpqNQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">散点图——平方英尺(住宅、地段、楼上和地下室)</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi og"><img src="../Images/9b30be011ac49062da86273784818406.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5C_H9dqs70yrP7EgkeohQg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">计数图—卧室、浴室、地板、等级</p></figure><p id="0246" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这里，我将日期列分解为年和月，以查看房价是如何变化的。</p><pre class="kg kh ki kj gt np nq nr ns aw nt bi"><span id="9895" class="nu lt iq nq b gy nv nw l nx ny"><strong class="nq ir">#let's break date to years, months<br/></strong>Data['date'] = pd.to_datetime(Data['date'])<br/>Data['month'] = Data['date'].apply(lambda date:date.month)<br/>Data['year'] = Data['date'].apply(lambda date:date.year)</span><span id="7e81" class="nu lt iq nq b gy nz nw l nx ny"><strong class="nq ir">#data visualization house price vs months and years</strong><br/>fig = plt.figure(figsize=(16,5))<br/>fig.add_subplot(1,2,1)<br/>Data.groupby('month').mean()['price'].plot()<br/>fig.add_subplot(1,2,2)<br/>Data.groupby('year').mean()['price'].plot()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oh"><img src="../Images/1249e52c797f1449a6c21ab4730e0b13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RJaKJvu_Cxfddo1BA28JPg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">房价与月份和年份</p></figure><p id="6f69" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们检查一下是否有空数据，并删除一些我们不需要的列(这个数据集没有一些丢失的值)</p><pre class="kg kh ki kj gt np nq nr ns aw nt bi"><span id="56a1" class="nu lt iq nq b gy nv nw l nx ny"><strong class="nq ir"># check if there are any Null values</strong><br/>Data.isnull().sum()</span><span id="d098" class="nu lt iq nq b gy nz nw l nx ny"><strong class="nq ir"># drop some unnecessary columns<br/></strong>Data = Data.drop('date',axis=1)<br/>Data = Data.drop('id',axis=1)<br/>Data = Data.drop('zipcode',axis=1)</span></pre></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="d5d9" class="ls lt iq bd lu lv nk lx ly lz nl mb mc jw nm jx me jz nn ka mg kc no kd mi mj bi translated">步骤 2:数据集准备(拆分和缩放)</h1><p id="2086" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">数据分为<code class="fe oi oj ok nq b">Train</code>组和<code class="fe oi oj ok nq b">Test</code>组。我们使用<code class="fe oi oj ok nq b">Train</code>集合让算法学习数据的行为，然后在<code class="fe oi oj ok nq b">Test</code>集合上检查我们的模型的准确性。</p><ul class=""><li id="40cb" class="mp mq iq ky b kz la lc ld lf ol lj om ln on lr mu mv mw mx bi translated">特性(<code class="fe oi oj ok nq b">X</code>):插入到我们的模型中的列将用于进行预测。</li><li id="83d0" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">预测(<code class="fe oi oj ok nq b">y</code>):特征预测的目标变量</li></ul><pre class="kg kh ki kj gt np nq nr ns aw nt bi"><span id="54aa" class="nu lt iq nq b gy nv nw l nx ny">X = Data.drop('price',axis =1).values<br/>y = Data['price'].values</span><span id="3869" class="nu lt iq nq b gy nz nw l nx ny"><strong class="nq ir">#splitting Train and Test <br/></strong>from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101)</span></pre><p id="0aa6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">特征缩放将帮助我们从相同的镜头(相同的比例)看到所有的变量，它还将帮助我们的模型学习得更快。</p><pre class="kg kh ki kj gt np nq nr ns aw nt bi"><span id="3f6f" class="nu lt iq nq b gy nv nw l nx ny"><strong class="nq ir">#standardization scaler - fit&amp;transform on train, fit only on test<br/></strong>from sklearn.preprocessing import StandardScaler<br/>s_scaler = StandardScaler()<br/>X_train = s_scaler.fit_transform(X_train.astype(np.float))<br/>X_test = s_scaler.transform(X_test.astype(np.float))</span></pre></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="8610" class="ls lt iq bd lu lv nk lx ly lz nl mb mc jw nm jx me jz nn ka mg kc no kd mi mj bi translated">步骤 3:模型选择和评估</h1><h1 id="df04" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">💡<strong class="ak">模型 1: </strong>多元线性回归</h1><p id="cdb1" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">多元线性回归是简单线性回归的延伸(此处阅读更多<a class="ae kv" href="https://medium.com/swlh/linear-regression-lab-for-dummies-in-python-a16cf2b93957" rel="noopener"/>)并假设因变量<code class="fe oi oj ok nq b">Y</code>和自变量<code class="fe oi oj ok nq b">X</code>之间存在线性关系</p><p id="08c0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们在回归模型中总结训练过程:</p><pre class="kg kh ki kj gt np nq nr ns aw nt bi"><span id="b3ac" class="nu lt iq nq b gy nv nw l nx ny"><strong class="nq ir"># Multiple Liner Regression<br/></strong>from sklearn.linear_model import LinearRegression<br/>regressor = LinearRegression()  <br/>regressor.fit(X_train, y_train)</span><span id="e334" class="nu lt iq nq b gy nz nw l nx ny"><strong class="nq ir">#evaluate the model (intercept and slope)<br/></strong>print(regressor.intercept_)<br/>print(regressor.coef_)</span><span id="7a87" class="nu lt iq nq b gy nz nw l nx ny"><strong class="nq ir">#predicting the test set result</strong><br/>y_pred = regressor.predict(X_test)</span><span id="025a" class="nu lt iq nq b gy nz nw l nx ny"><strong class="nq ir">#put results as a DataFrame</strong><br/>coeff_df = pd.DataFrame(regressor.coef_, Data.drop('price',axis =1).columns, columns=['Coefficient']) <br/>coeff_df</span></pre><p id="092d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">通过可视化残差，我们可以看到正态分布(证明与因变量具有线性关系)</p><pre class="kg kh ki kj gt np nq nr ns aw nt bi"><span id="8288" class="nu lt iq nq b gy nv nw l nx ny"><strong class="nq ir"># visualizing residuals<br/></strong>fig = plt.figure(figsize=(10,5))<br/>residuals = (y_test- y_pred)<br/>sns.distplot(residuals)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/c9a2eefa99bde1f279da1d26bbd053d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*KSqdppRyj1PnKLQ-23yMuw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">剩余可视化</p></figure><p id="aabf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们比较实际产量和预测值，以衡量我们的预测与实际房价有多远。</p><pre class="kg kh ki kj gt np nq nr ns aw nt bi"><span id="4a98" class="nu lt iq nq b gy nv nw l nx ny"><strong class="nq ir">#compare actual output values with predicted values</strong><br/>y_pred = regressor.predict(X_test)<br/>df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})<br/>df1 = df.head(10)<br/>df1</span><span id="794f" class="nu lt iq nq b gy nz nw l nx ny"><strong class="nq ir"># evaluate the performance of the algorithm (MAE - MSE - RMSE)<br/></strong>from sklearn import metrics</span><span id="4cfa" class="nu lt iq nq b gy nz nw l nx ny">print('MAE:', metrics.mean_absolute_error(y_test, y_pred))  <br/>print('MSE:', metrics.mean_squared_error(y_test, y_pred))  <br/>print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))</span><span id="8199" class="nu lt iq nq b gy nz nw l nx ny">print('VarScore:',metrics.explained_variance_score(y_test,y_pred))</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi op"><img src="../Images/34b63a57a89f919b75627caf161f9595.png" data-original-src="https://miro.medium.com/v2/resize:fit:1324/format:webp/1*_ORN2DJUDx4t1NFycz8yYg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">多元线性回归结果</p></figure></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="b4d0" class="ls lt iq bd lu lv nk lx ly lz nl mb mc jw nm jx me jz nn ka mg kc no kd mi mj bi translated">💡模型 2: Keras 回归</h1><p id="33ed" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">让我们为回归问题创建一个基线神经网络模型。从所有需要的函数和对象开始。</p><pre class="kg kh ki kj gt np nq nr ns aw nt bi"><span id="c768" class="nu lt iq nq b gy nv nw l nx ny"><strong class="nq ir"># Creating a Neural Network Model<br/></strong>from tensorflow.keras.models import Sequential<br/>from tensorflow.keras.layers import Dense, Activation<br/>from tensorflow.keras.optimizers import Adam</span></pre><p id="0024" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于我们有 19 个特征，让我们插入 19 个神经元作为开始，4 个隐藏层和 1 个输出层由于预测房价。</p><p id="d5ab" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，ADAM 优化算法用于优化损失函数(均方误差)</p><pre class="kg kh ki kj gt np nq nr ns aw nt bi"><span id="7fe8" class="nu lt iq nq b gy nv nw l nx ny"><strong class="nq ir"># having 19 neuron is based on the number of available features<br/></strong>model = Sequential()<br/>model.add(Dense(19,activation='relu'))<br/>model.add(Dense(19,activation='relu'))<br/>model.add(Dense(19,activation='relu'))<br/>model.add(Dense(19,activation='relu'))<br/>model.add(Dense(1))</span><span id="d621" class="nu lt iq nq b gy nz nw l nx ny">model.compile(optimizer='Adam',loss='mes')</span></pre><p id="50b0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们对模型进行 400 个历元的训练，每次都在历史对象中记录训练和验证精度。为了跟踪模型在每个时期的表现，模型将在训练和测试数据中运行，同时计算损失函数。</p><pre class="kg kh ki kj gt np nq nr ns aw nt bi"><span id="c1ba" class="nu lt iq nq b gy nv nw l nx ny">model.fit(x=X_train,y=y_train,<br/>          validation_data=(X_test,y_test),<br/>          batch_size=128,epochs=400)</span><span id="0312" class="nu lt iq nq b gy nz nw l nx ny">model.summary()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/3a94d7eb618de62b78c8423ba4c89f7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/1*3cTjQ7V9ixNVEQyYpHO5Lw.png"/></div></figure><pre class="kg kh ki kj gt np nq nr ns aw nt bi"><span id="f545" class="nu lt iq nq b gy nv nw l nx ny">loss_df = pd.DataFrame(model.history.history)<br/>loss_df.plot(figsize=(12,8))</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi or"><img src="../Images/138daf4959437c5fb73f2af20afb4092.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2iFNylZi7lSI-R4XuNvCcQ.png"/></div></div></figure></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="48ca" class="ls lt iq bd lu lv nk lx ly lz nl mb mc jw nm jx me jz nn ka mg kc no kd mi mj bi translated">测试数据评估</h1><pre class="kg kh ki kj gt np nq nr ns aw nt bi"><span id="3ef3" class="nu lt iq nq b gy nv nw l nx ny">y_pred = model.predict(X_test)</span><span id="4624" class="nu lt iq nq b gy nz nw l nx ny">from sklearn import metrics</span><span id="bc6f" class="nu lt iq nq b gy nz nw l nx ny">print('MAE:', metrics.mean_absolute_error(y_test, y_pred))  <br/>print('MSE:', metrics.mean_squared_error(y_test, y_pred))  <br/>print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))</span><span id="fa3b" class="nu lt iq nq b gy nz nw l nx ny">print('VarScore:',metrics.explained_variance_score(y_test,y_pred))</span><span id="0a20" class="nu lt iq nq b gy nz nw l nx ny"><strong class="nq ir"># Visualizing Our predictions<br/></strong>fig = plt.figure(figsize=(10,5))<br/>plt.scatter(y_test,y_pred)<br/><strong class="nq ir"># Perfect predictions<br/></strong>plt.plot(y_test,y_test,'r')</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi os"><img src="../Images/c88f05a882dedcd8bde405ff576e108e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*9nJDK0WVdXMA9AO24PoCXw.png"/></div></div></figure><pre class="kg kh ki kj gt np nq nr ns aw nt bi"><span id="b5d8" class="nu lt iq nq b gy nv nw l nx ny"><strong class="nq ir"># visualizing residuals<br/></strong>fig = plt.figure(figsize=(10,5))<br/>residuals = (y_test- y_pred)<br/>sns.distplot(residuals)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/ccfa70b8406c25b1084fda0f56bf51c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*F4-ovkiL1jZ5TgxTZ8rAxg.png"/></div></figure><h1 id="c480" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">Keras 回归 vs 多元线性回归！</h1><p id="c967" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我们成功了！💪<br/>我们用两种不同的 ML 模型算法预测了房价。</p><p id="cd66" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的<strong class="ky ir">多元线性回归</strong>的得分在 69%左右，所以这个模型还有改进的空间。然后我们用<strong class="ky ir"> Keras 回归模型</strong>得到了约 81%的准确率。<br/>另外，请注意，Keras 回归模型的 RMSE(损失函数)较低，这表明我们的预测更接近实际评级价格。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/6dec11542b36c22f35e06deb868f32ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*AFgjhAE8ud8TwD_5kqsDOQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">结果:喀拉斯区。vs 多个线性稳压器。</p></figure><p id="512c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">毫无疑问，这个分数可以通过特征选择或使用其他回归模型来提高。</p><p id="2da7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">感谢您的阅读🤓。再次反馈总是受欢迎的！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/5752c5da744c2897e8c79719cf133d57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*Q_7_8NnFPLJxbmocNnqz2Q.png"/></div></figure></div></div>    
</body>
</html>