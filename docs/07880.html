<html>
<head>
<title>Transfer Learning with PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 PyTorch 迁移学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/transfer-learning-with-pytorch-95dd5dca82a?source=collection_archive---------41-----------------------#2020-06-11">https://towardsdatascience.com/transfer-learning-with-pytorch-95dd5dca82a?source=collection_archive---------41-----------------------#2020-06-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="daf0" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">以及为什么您不应该从头开始编写 CNN 架构</h2></div><p id="c64e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如今，训练深度学习模型，尤其是与图像识别相关的模型，是一项非常简单的任务。有很多原因可以解释为什么你不应该过分强调架构，主要是有人已经为你做了这一步。至于其他的，你得继续读下去。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/4574255ff96301295023ed8d44d560e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UBaMToSOyXJhHzuM"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">由<a class="ae lu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae lu" href="https://unsplash.com/@drmakete?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> drmakete 实验室</a>拍摄的照片</p></figure><p id="842a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">源代码:</strong> <a class="ae lu" href="https://colab.research.google.com/drive/1ItUWnucWWg4Enxz6Xjz4Eb52Kpj1f3HA?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Colab 笔记本</a></p><p id="78c1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如今，作为一名工程师，你唯一应该关注的是<strong class="kk iu">数据准备</strong>——在深度学习的世界中，这个术语概括了数据收集、加载、规范化和扩充的过程。</p><p id="fc0e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">今天的议程很简单——解释什么是迁移学习以及如何使用它，然后是模型培训的实际示例，包括有无预培训架构。</p><p id="73e9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">听起来很简单，所以让我们直入主题吧！</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="43c6" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">数据集下载和基本准备</h1><p id="83ea" class="pw-post-body-paragraph ki kj it kk b kl mu ju kn ko mv jx kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">先说进口。这里我们有常见的嫌疑人，如<em class="mz"> Numpy </em>、<em class="mz"> Pandas </em>和<em class="mz"> Matplotlib </em>，但也有我们最喜欢的深度学习库——<em class="mz">py torch</em>——以及它所提供的一切。</p><pre class="lf lg lh li gt na nb nc nd aw ne bi"><span id="f5e0" class="nf md it nb b gy ng nh l ni nj">import os<br/>import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>from datetime import datetime</span><span id="c0de" class="nf md it nb b gy nk nh l ni nj">import torch<br/>import torch.nn as nn<br/>import torch.nn.functional as F<br/>from torch.utils.data import DataLoader<br/>from torchvision.utils import make_grid<br/>from torchvision import models, transforms, datasets</span></pre><p id="fd31" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们正在用<strong class="kk iu"> Colab </strong>或者更准确地说是 Colab Pro 编写这段代码，所以我们将利用 GPU 的能力进行训练。如果您不知道 Colab 是什么，或者想知道升级到 Pro 版本是否值得，请随时查看这些文章:</p><div class="nl nm gp gr nn no"><a rel="noopener follow" target="_blank" href="/google-colab-how-does-it-compare-to-a-gpu-enabled-laptop-851c1e0a2ca9"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd iu gy z fp nt fr fs nu fu fw is bi translated">Google Colab:它与支持 GPU 的笔记本电脑相比如何？</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">Colab 简介、运行时、性能比较…以及疑难解答</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">towardsdatascience.com</p></div></div><div class="nx l"><div class="ny l nz oa ob nx oc lo no"/></div></div></a></div><div class="nl nm gp gr nn no"><a rel="noopener follow" target="_blank" href="/colab-pro-is-it-worth-the-money-32a1744f42a8"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd iu gy z fp nt fr fs nu fu fw is bi translated">Colab Pro:物有所值吗？</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">10 美元有多大作用？我们做了测试。你做阅读。</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">towardsdatascience.com</p></div></div><div class="nx l"><div class="od l nz oa ob nx oc lo no"/></div></div></a></div><p id="9673" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因为我们是在 GPU 上训练，而这可能不适合你，所以我们需要一个健壮的方法来处理这个问题。这里有一个标准方法:</p><pre class="lf lg lh li gt na nb nc nd aw ne bi"><span id="72f3" class="nf md it nb b gy ng nh l ni nj">device = torch.device(‘cuda:0’ if torch.cuda.is_available() else ‘cpu’)<br/>device</span><span id="80ef" class="nf md it nb b gy nk nh l ni nj"><strong class="nb iu">&gt;&gt;&gt; device(type=’cuda’, index=0)</strong></span></pre><p id="bed8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你正在进行 cpu 方面的培训，它应该会显示类似于<strong class="kk iu"> type='cpu' </strong>的内容，但是因为 Colab 是免费的，所以没有必要这样做。</p><p id="fb50" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在进入<strong class="kk iu">数据集</strong>。为此，我们将使用<a class="ae lu" href="http://files.fast.ai/data/dogscats.zip" rel="noopener ugc nofollow" target="_blank">狗或猫</a>数据集。它有大量不同大小的图像，我们将在后面处理。现在我们需要下载并解压它。方法如下:</p><pre class="lf lg lh li gt na nb nc nd aw ne bi"><span id="27c9" class="nf md it nb b gy ng nh l ni nj">%mkdir data<br/>%cd /content/data/<br/>!wget <a class="ae lu" href="http://files.fast.ai/data/dogscats.zip" rel="noopener ugc nofollow" target="_blank">http://files.fast.ai/data/dogscats.zip</a></span><span id="2e72" class="nf md it nb b gy nk nh l ni nj">!unzip dogscats.zip</span></pre><p id="33e5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">大约一分钟后，根据你的网速，数据集就可以使用了。现在，我们可以将它声明为一个数据目录——这不是必需的，但会节省我们一点时间。</p><pre class="lf lg lh li gt na nb nc nd aw ne bi"><span id="a673" class="nf md it nb b gy ng nh l ni nj">DIR_DATA = ‘/content/data/dogscats/’</span></pre><h2 id="7a3c" class="nf md it bd me oe of dn mi og oh dp mm kr oi oj mo kv ok ol mq kz om on ms oo bi translated">数据准备</h2><p id="f7d5" class="pw-post-body-paragraph ki kj it kk b kl mu ju kn ko mv jx kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">第一部分的第一部分现在完成了。接下来，我们必须对训练和验证子集应用一些转换，然后用<strong class="kk iu"> DataLoaders </strong>加载转换后的数据。以下是我们应用的转换:</p><ul class=""><li id="82bb" class="op oq it kk b kl km ko kp kr or kv os kz ot ld ou ov ow ox bi translated">随机旋转</li><li id="cd9c" class="op oq it kk b kl oy ko oz kr pa kv pb kz pc ld ou ov ow ox bi translated">随机水平翻转</li><li id="237e" class="op oq it kk b kl oy ko oz kr pa kv pb kz pc ld ou ov ow ox bi translated">调整到 224x224 大小—预训练体系结构需要</li><li id="8341" class="op oq it kk b kl oy ko oz kr pa kv pb kz pc ld ou ov ow ox bi translated">转换为张量</li><li id="e7cd" class="op oq it kk b kl oy ko oz kr pa kv pb kz pc ld ou ov ow ox bi translated">正常化</li></ul><p id="2c4c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">代码如下:</p><pre class="lf lg lh li gt na nb nc nd aw ne bi"><span id="5eac" class="nf md it nb b gy ng nh l ni nj">train_transforms = transforms.Compose([<br/>    transforms.RandomRotation(10),<br/>    transforms.RandomHorizontalFlip(p=0.5),<br/>    transforms.Resize(224),<br/>    transforms.CenterCrop((224, 224)),<br/>    transforms.ToTensor(), <br/>    transforms.Normalize(<br/>        mean=[0.485, 0.456, 0.406],<br/>        std=[0.229, 0.224, 0.225]<br/>    )<br/>])</span><span id="be46" class="nf md it nb b gy nk nh l ni nj">valid_transforms = transforms.Compose([<br/>    transforms.Resize(224),<br/>    transforms.CenterCrop((224, 224)),<br/>    transforms.ToTensor(),<br/>    transforms.Normalize(<br/>        mean=[0.485, 0.456, 0.406],<br/>        std=[0.229, 0.224, 0.225]<br/>    )<br/>])</span></pre><p id="e71b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们用数据加载器加载数据。这一步也很简单，您可能很熟悉:</p><pre class="lf lg lh li gt na nb nc nd aw ne bi"><span id="aabd" class="nf md it nb b gy ng nh l ni nj">train_data = datasets.ImageFolder(os.path.join(DIR_DATA, ‘train’), transform=train_transforms)<br/>valid_data = datasets.ImageFolder(os.path.join(DIR_DATA, ‘valid’), transform=valid_transforms)</span><span id="eefe" class="nf md it nb b gy nk nh l ni nj">torch.manual_seed(42)<br/>train_loader = DataLoader(train_data, batch_size=64, shuffle=True)<br/>valid_loader = DataLoader(valid_data, batch_size=64, shuffle=False)</span><span id="472a" class="nf md it nb b gy nk nh l ni nj">class_names = train_data.classes<br/>class_names</span><span id="cc4e" class="nf md it nb b gy nk nh l ni nj"><strong class="nb iu">&gt;&gt;&gt; ['cats', 'dogs']</strong></span></pre><p id="f993" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们现在对单个批次进行逆归一化并将其可视化，我们会得到这样的结果:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi pd"><img src="../Images/6c27d5d8e134ff389d7717370461ba78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8VbqfUOzhUI6ICyBPDbL2A.png"/></div></div></figure><p id="7a98" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">快速看一下上面的图像，就可以看出我们的转换工作符合预期。</p><p id="7c70" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">数据准备部分现在已经完成，在下一部分，我们将声明一个定制的 CNN 架构，训练它，并评估性能。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="21f1" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">定制建筑 CNN</h1><p id="4914" class="pw-post-body-paragraph ki kj it kk b kl mu ju kn ko mv jx kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">对于这一部分，我们想做一些非常简单的事情——3 个卷积层，每个卷积层后面是 max-pooling 和 ReLU，然后是一个完全连接的层和一个输出层。</p><p id="acd3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是这个架构的代码:</p><pre class="lf lg lh li gt na nb nc nd aw ne bi"><span id="315f" class="nf md it nb b gy ng nh l ni nj">class CustomCNN(nn.Module):<br/>    def __init__(self):<br/>        super().__init__()<br/>        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1)<br/>        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1)<br/>        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1)<br/>        self.fc1 = nn.Linear(in_features=26*26*64, out_features=128)<br/>        self.out = nn.Linear(in_features=128, out_features=2)</span><span id="05a0" class="nf md it nb b gy nk nh l ni nj">    def forward(self, x):<br/>        x = F.relu(self.conv1(x))<br/>        x = F.max_pool2d(x, kernel_size=2, stride=2)<br/>        x = F.relu(self.conv2(x))<br/>        x = F.max_pool2d(x, kernel_size=2, stride=2)<br/>        x = F.relu(self.conv3(x))<br/>        x = F.max_pool2d(x, kernel_size=2, stride=2)<br/>        x = x.view(-1, 26*26*64)<br/>        x = F.relu(self.fc1(x))<br/>        x = F.dropout(x, p=0.2)<br/>        x = self.out(x)<br/>        return F.log_softmax(x, dim=1)</span><span id="7f74" class="nf md it nb b gy nk nh l ni nj">torch.manual_seed(42)<br/>model = CustomCNN()<br/>model.to(device)</span></pre><p id="fb1f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这里，我们可以定义一个优化器和标准，并准备好进行培训:</p><pre class="lf lg lh li gt na nb nc nd aw ne bi"><span id="a694" class="nf md it nb b gy ng nh l ni nj">custom_criterion = nn.CrossEntropyLoss()<br/>custom_optimizer = torch.optim.Adam(model.parameters(), lr=0.001)</span></pre><p id="69c7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因为你可以访问<a class="ae lu" href="https://colab.research.google.com/drive/1ItUWnucWWg4Enxz6Xjz4Eb52Kpj1f3HA?usp=sharing" rel="noopener ugc nofollow" target="_blank">源代码、</a>和<strong class="kk iu"> train_model </strong>函数太长了，我们决定不把它放在这里。因此，如果您继续学习，请参考源代码。我们将为 10 个时期训练模型:</p><pre class="lf lg lh li gt na nb nc nd aw ne bi"><span id="7ee8" class="nf md it nb b gy ng nh l ni nj">custom_model_trained = train_model(<br/>    train_loader=train_loader,<br/>    test_loader=valid_loader,<br/>    model=model,<br/>    criterion=custom_criterion,<br/>    optimizer=custom_optimizer,<br/>    epochs=10<br/>)</span></pre><p id="c55c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一段时间后，获得的结果如下:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi pe"><img src="../Images/f97a14b1a767c2561a8b7638b3b205d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h2WRT8Ct14gULnPA2a6Ckg.png"/></div></div></figure><p id="e4f3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">无论如何，结果并不可怕，但我们如何才能做得更好？转学为救。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="8855" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">迁移学习法</h1><p id="4c8e" class="pw-post-body-paragraph ki kj it kk b kl mu ju kn ko mv jx kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">你可以很容易地在网上找到正式的定义。对我们来说，迁移学习意味着下载一个预制的架构，它是在 1M 以上的图像上训练的，并调整输出层，以便它可以根据你的需要分类许多类别。</p><p id="40bc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因为我们这里只有猫和狗，所以我们需要将这个数字修改为 2。</p><p id="d305" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，我们将下载预训练版本的<a class="ae lu" href="https://en.wikipedia.org/wiki/Residual_neural_network" rel="noopener ugc nofollow" target="_blank"> ResNet101 </a>架构，并使其参数不可训练——因为网络已经训练好了:</p><pre class="lf lg lh li gt na nb nc nd aw ne bi"><span id="7e78" class="nf md it nb b gy ng nh l ni nj">pretrained_model = models.resnet101(pretrained=True)</span><span id="61e4" class="nf md it nb b gy nk nh l ni nj">for param in pretrained_model.parameters():<br/>    param.requires_grad = False</span></pre><p id="044d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">太好了！让我们看看输出图层是什么样子的:</p><pre class="lf lg lh li gt na nb nc nd aw ne bi"><span id="ebbd" class="nf md it nb b gy ng nh l ni nj">pretrained_model.fc</span><span id="542f" class="nf md it nb b gy nk nh l ni nj"><strong class="nb iu">&gt;&gt;&gt; Linear(in_features=2048, out_features=1000, bias=True)</strong></span></pre><p id="f0b3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以这个架构默认有 1000 个可能的类，但是我们只需要两个——一个用于猫，一个用于狗。以下是调整方法:</p><pre class="lf lg lh li gt na nb nc nd aw ne bi"><span id="6302" class="nf md it nb b gy ng nh l ni nj">pretrained_model.fc = nn.Sequential(<br/>    nn.Linear(2048, 1000),<br/>    nn.ReLU(),<br/>    nn.Dropout(0.5),<br/>    nn.Linear(1000, 2),<br/>    nn.LogSoftmax(dim=1)<br/>)</span><span id="0768" class="nf md it nb b gy nk nh l ni nj">pretrained_model.to(device)</span></pre><p id="1b1f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是我们要做的。</p><p id="fc4f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们仍然需要定义一个优化器和一个标准，但是你知道怎么做:</p><pre class="lf lg lh li gt na nb nc nd aw ne bi"><span id="ebf9" class="nf md it nb b gy ng nh l ni nj">pretrained_criterion = nn.CrossEntropyLoss()<br/>pretrained_optimizer = torch.optim.Adam(pretrained_model.fc.parameters(), lr=0.001)</span></pre><p id="9377" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">训练过程与定制架构相同，但是我们不需要这么多的纪元，因为我们已经知道权重和偏差的正确值。</p><pre class="lf lg lh li gt na nb nc nd aw ne bi"><span id="84ad" class="nf md it nb b gy ng nh l ni nj">pretrained_model_trained = train_model(<br/>    train_loader=train_loader,<br/>    test_loader=valid_loader,<br/>    model=pretrained_model,<br/>    criterion=pretrained_criterion,<br/>    optimizer=pretrained_optimizer,<br/>    epochs=1<br/>)</span></pre><p id="0791" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一段时间后，获得的结果如下:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi pe"><img src="../Images/023e7ced2d3f7498b6a477ad0d21c715.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6DiVLhjzjISJQBlRWpQm_g.png"/></div></div></figure><p id="b56c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">多神奇啊？不仅准确度提高了，而且我们还通过不训练太多纪元节省了大量时间。</p><p id="58ee" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在你知道迁移学习能做什么，以及如何和为什么使用它。让我们在下一部分总结一下。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="33f3" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">结论</h1><p id="e59f" class="pw-post-body-paragraph ki kj it kk b kl mu ju kn ko mv jx kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">这就是 PyTorch 最简单的迁移学习指南。当然，如果网络更深，定制模型的结果可能会更好，但这不是重点。重点是，没有必要强调多少层是足够的，以及最佳超参数值是多少。至少在大多数情况下是这样。</p><p id="49e3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请务必尝试不同的架构，并随时在下面的评论部分告诉我们结果。</p><p id="f10e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢阅读。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="7269" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mz">喜欢这篇文章吗？成为</em> <a class="ae lu" href="https://medium.com/@radecicdario/membership" rel="noopener"> <em class="mz">中等会员</em> </a> <em class="mz">继续无限制学习。如果你使用下面的链接，我会收到你的一部分会员费，不需要你额外付费。</em></p><div class="nl nm gp gr nn no"><a href="https://medium.com/@radecicdario/membership" rel="noopener follow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd iu gy z fp nt fr fs nu fu fw is bi translated">通过我的推荐链接加入 Medium-Dario rade ci</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">medium.com</p></div></div><div class="nx l"><div class="pf l nz oa ob nx oc lo no"/></div></div></a></div></div></div>    
</body>
</html>