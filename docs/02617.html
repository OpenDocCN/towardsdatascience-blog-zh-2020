<html>
<head>
<title>Using Snorkel For Multi-Label Annotation.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用通气管进行多标签标注。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-snorkel-for-multi-label-annotation-cc2aa217986a?source=collection_archive---------13-----------------------#2020-03-13">https://towardsdatascience.com/using-snorkel-for-multi-label-annotation-cc2aa217986a?source=collection_archive---------13-----------------------#2020-03-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9889" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何使用浮潜的多类实现来创建多标签</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/d8ae9bfdc7e34f7d386e42006efa2602.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/0*ZtVCOooN2oZdFN8o.jpg"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">hazy research @<a class="ae ku" href="http://snorkel.org" rel="noopener ugc nofollow" target="_blank">Snorkel.org</a>的浮潜</p></figure><p id="2f10" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">sculpt是一个很好的小软件包，它允许我们使用标签函数(LFs ),简单如启发式或关键字，复杂如算法和人工注释器，以便创建一个标签数据集，用于训练分类器。</p><blockquote class="lr ls lt"><p id="f2a3" class="kv kw lu kx b ky kz ju la lb lc jx ld lv lf lg lh lw lj lk ll lx ln lo lp lq im bi translated">“通气管是一个系统，用于以编程方式<em class="it"/>建立和管理训练数据集<strong class="kx iu">，而无需手动标记</strong>。在snuck中，用户可以在几小时或几天内开发大型训练数据集，而不是在几周或几个月内手工标记它们。”—<a class="ae ku" href="https://www.snorkel.org/get-started/" rel="noopener ugc nofollow" target="_blank">Snorkel.org</a></p></blockquote><h2 id="f029" class="ly lz it bd ma mb mc dn md me mf dp mg le mh mi mj li mk ml mm lm mn mo mp mq bi translated">动机</h2><p id="3cda" class="pw-post-body-paragraph kv kw it kx b ky mr ju la lb ms jx ld le mt lg lh li mu lk ll lm mv lo lp lq im bi translated">使用通气管来创建多标签的动机很简单。通气管允许我们使用简单的试探法或关键字来创建一个监督数据集。当我们需要理解为什么一个样本被分配到一个特定的类别时，使用它作为一个标记算法允许一定程度的清晰度。你也可以想到这样一个场景，你创建了一个启发式的多标签算法，分配稀疏数量的多标签；当您的产品或功能需要大量的多标签，以便为您的客户提供更高的价值。</p><h2 id="ec0c" class="ly lz it bd ma mb mc dn md me mf dp mg le mh mi mj li mk ml mm lm mn mo mp mq bi translated">通气管</h2><p id="d1d3" class="pw-post-body-paragraph kv kw it kx b ky mr ju la lb ms jx ld le mt lg lh li mu lk ll lm mv lo lp lq im bi translated">值得注意的是，在整个过程中，我们实际上是在创建两个分类器，第一个使用的是sauce的<em class="lu"> MajorityLabelVoter </em>或<em class="lu"> LabelModel，</em>前者为我们提供了一个多数票作为基线，后者为我们提供了secret-sauce模型，后者是为了训练一个机器或深度学习(MLDL)算法，因为我们不想依赖我们创建的标签函数。我们希望训练一个不局限于我们的关键字、正则表达式等的分类器。我们想要一个比我们给它的更一般化的分类器。理想情况下，它会发现，例如，我们在标记过程中没有考虑到的标记与我们的最终标记之间的相关性。</p><h2 id="df59" class="ly lz it bd ma mb mc dn md me mf dp mg le mh mi mj li mk ml mm lm mn mo mp mq bi translated">使用多级通气管</h2><p id="2510" class="pw-post-body-paragraph kv kw it kx b ky mr ju la lb ms jx ld le mt lg lh li mu lk ll lm mv lo lp lq im bi translated">首先，我们需要了解如何使用通气管。考虑一个情感分类任务和下面的句子:1。“蛋糕尝起来真难吃”，2。“奶油真好”&amp; 3。“这食物是公平的”。这些句子分别是否定句、肯定句和中性句。因此，我们将创建几个相应地分配标签的逻辑框架。</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="b118" class="ly lz it mx b gy nb nc l nd ne">from snorkel.labeling import labeling_function<br/><br/>@labeling_function()<br/>def lf_keyword_good(x):<br/>    return POSITIVE if "good" in x.text.lower() else ABSTAIN<br/><br/>@labeling_function()<br/>def lf_keyword_bad(x):<br/>    return NEGATIVE if "bad" in x.text.lower() else ABSTAIN</span><span id="e738" class="ly lz it mx b gy nf nc l nd ne">@labeling_function()<br/>def lf_keyword_fair(x):<br/>    return NEUTRAL if "<!-- -->fair<!-- -->" in x.text.lower() else ABSTAIN</span></pre><p id="223e" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">剩下的过程很简单，一旦你有了很多LFs，你就可以把它们用在你的<em class="lu">熊猫身上。DataFrame </em>训练其中一个模型，即<em class="lu"> MajorityLabelVoter </em>或<em class="lu"> LabelModel。</em></p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="af10" class="ly lz it mx b gy nb nc l nd ne">from snorkel.labeling import LabelModel, PandasLFApplier<br/><br/># Define the set of labeling functions (LFs)<br/>lfs = [lf_keyword_bad, lf_keyword_good, lf_keyword_fair]<br/><br/># Apply the LFs to the unlabeled training data<br/>applier = PandasLFApplier(lfs)<br/>L_train = applier.apply(df_train)<br/><br/># Train the label model and compute the training labels<br/>label_model = LabelModel(cardinality=3, verbose=True)<br/>label_model.fit(L_train, n_epochs=500, log_freq=50)<br/>df_train["label"] = label_model.predict(L=L_train, tie_break_policy="abstain")</span></pre><p id="89f1" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><em class="lu"> df_train["label"] </em>也将包含弃权标签，因此为了进一步训练我们的二级分类器，我们必须将它们过滤掉。</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="ae30" class="ly lz it mx b gy nb nc l nd ne">df_train = df_train[df_train.label != ABSTAIN]</span></pre><p id="21b4" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">同样，在过滤的数据集上训练二级分类器(在本例中为随机森林)的目的是“<strong class="kx iu">推广到标注函数和</strong>T0的覆盖范围之外</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="8dd6" class="ly lz it mx b gy nb nc l nd ne"><strong class="mx iu">from</strong> <strong class="mx iu">sklearn.ensemble</strong> <strong class="mx iu">import</strong> RandomForestClassifier<br/><br/>clf = RandomForestClassifier()<br/>clf.fit(<!-- -->df_train.drop(['label'],axis=1)<!-- -->, <!-- -->df_train["label"]<!-- -->)</span></pre><h2 id="819f" class="ly lz it bd ma mb mc dn md me mf dp mg le mh mi mj li mk ml mm lm mn mo mp mq bi translated">将通气管用于多标签</h2><p id="5617" class="pw-post-body-paragraph kv kw it kx b ky mr ju la lb ms jx ld le mt lg lh li mu lk ll lm mv lo lp lq im bi translated">通气管只能作为多类贴标机开箱使用。要将其用于多标签，您可以执行以下三种方法之一:</p><ol class=""><li id="ec5c" class="nj nk it kx b ky kz lb lc le nl li nm lm nn lq no np nq nr bi translated">使用<em class="lu"> MajorityLabelVoter的</em> predict_proba()并分配所有“概率”≥ 0的类。即第一个和最后一个[0.5，0，0.5]。我们可以把它想象成一个样本，它存在于两个聚类中，或者来自两个类别的两个关键词，这允许一个样本具有多个标签。例如，“汉堡包有好有坏”。</li><li id="70c9" class="nj nk it kx b ky ns lb nt le nu li nv lm nw lq no np nq nr bi translated">使用<em class="lu"> LabelModel的</em> predict_proba，分配所有概率高于“拐点”的类。可以用<a class="ae ku" href="https://pypi.org/project/kneed/" rel="noopener ugc nofollow" target="_blank"> Kneed </a>算出来。本质上，我们的概率是softmax，只有少数人会得到高值。请注意，根据我的实证测试，MajorityLabelVoter的概率值与LabelModel的概率值之间有很高的相关性，即前者是一个“硬”softmax，而后者是你对softmax的预期。即[0.5，0，0.5]对[0.45，0.06，0.49]。</li><li id="d1ea" class="nj nk it kx b ky ns lb nt le nu li nv lm nw lq no np nq nr bi translated">使用<em class="lu"> MajorityLabelVoter </em>或<em class="lu"> LabelModel </em>训练“一对所有”模型，并根据预测分配多标签。请注意，在考虑放弃标签时，您需要考虑一个策略。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/0a080dc531afb3cd9f3f728a55545411.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*pDgOpMzED1c-4uWGQqwChA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">最高概率的图示。</p></figure><h2 id="0cc4" class="ly lz it bd ma mb mc dn md me mf dp mg le mh mi mj li mk ml mm lm mn mo mp mq bi translated">实践中的多标签</h2><p id="36cc" class="pw-post-body-paragraph kv kw it kx b ky mr ju la lb ms jx ld le mt lg lh li mu lk ll lm mv lo lp lq im bi translated">因为“1”和“2”给出了相似的输出，并且从“1”获得多标签的计算更简单，所以我选择基于1分配多标签。</p><p id="eef4" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">请注意，当一个模型分配一个弃权标签时，它不能决定谁是赢家。我们在predict_proba()的输出中观察到了这种行为。比如考虑下面这个概率向量:[1.0，0，0]，这里的赢家是第一类。现在，考虑下面的向量:[0.5，0，0.5]，我们看到这不是一个明确的赢家，因此，浮潜将分配一个弃权标签。</p><p id="3302" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">当我们为每个具有非零概率的类分配一个标签时，我们实际上消除了所有的放弃标签，标记了所有的数据集，并为每个样本分配了许多多标签。</p><p id="6af6" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">以下代码使用了一个<em class="lu"> MajorityLabelVoter </em>分类器，并根据所有分数高于零的类分配标签。就这么简单:)。</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="e17b" class="ly lz it mx b gy nb nc l nd ne">from snorkel.labeling import MajorityLabelVoter<br/>from sklearn.preprocessing import MultiLabelBinarizer</span><span id="a233" class="ly lz it mx b gy nf nc l nd ne">Y = [['POSITIVE', 'NEGATIVE', 'NEUTRAL']]</span><span id="df20" class="ly lz it mx b gy nf nc l nd ne"># fit a MultiLabelBinarizer<br/>mlb = MultiLabelBinarizer()<br/>mlb.fit_transform(Y)</span><span id="4e28" class="ly lz it mx b gy nf nc l nd ne"># create a majority vote model and predict<br/>majority_model = MajorityLabelVoter(cardinality=3)<br/>predictions = majority_model.predict_proba(L=L_test)</span><span id="1e8c" class="ly lz it mx b gy nf nc l nd ne">df_multilabel = pd.DataFrame()<br/>df_multilabel['predict_proba'] = predictions.tolist()</span><span id="93c5" class="ly lz it mx b gy nf nc l nd ne"># get all the non zero indices which are the multi labels<br/>df_multilabel['multi_labels'] = df_multilabel['predict_proba'].apply(lambda x: np.nonzero(x)[0])<br/>    <br/>#transform to mlb for classification report<br/>df_multilabel['mlb_pred'] = df_multilabel['multi_labels'].apply(lambda x: mlb.transform([x])[0])</span><span id="5336" class="ly lz it mx b gy nf nc l nd ne">print(df_multilabel.head())</span><span id="5a10" class="ly lz it mx b gy nf nc l nd ne">#convert to str in order to see how many multi labels did we gain<br/>multi_label_string = df_multilabel.multi_labels.apply(lambda x: ", ".join(le.inverse_transform(x)))<br/>print(multi_label_string.value_counts()[:50])</span><span id="d461" class="ly lz it mx b gy nf nc l nd ne"># print some metrics using classification report <br/>y_pred = df_multilabel.mlb_pred.apply(lambda x: list(x)).to_numpy().tolist()<br/>y_true = mlb.transform(Y.values).tolist()</span><span id="4058" class="ly lz it mx b gy nf nc l nd ne">print(classification_report(y_true, y_pred, target_names = mlb.classes_))</span></pre><p id="ed57" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">就这样，您已经为每个样本创建了多个标签。请记住，由于这种使用浮潜的方法论，在标记策略方面非常贪婪，您可能会得到一个非常面向回忆的模型。你的经历会有所不同。</p></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><p id="70d1" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">Ori Cohen博士拥有计算机科学博士学位，主要研究机器学习。他是TLV新遗迹公司的首席数据科学家，从事AIOps领域的机器和深度学习研究。</p></div></div>    
</body>
</html>