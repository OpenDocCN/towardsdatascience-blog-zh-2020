<html>
<head>
<title>DeepAnT — Unsupervised Anomaly Detection for Time Series</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">DeepAnT——时间序列的无监督异常检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deepant-unsupervised-anomaly-detection-for-time-series-97c5308546ea?source=collection_archive---------24-----------------------#2020-07-27">https://towardsdatascience.com/deepant-unsupervised-anomaly-detection-for-time-series-97c5308546ea?source=collection_archive---------24-----------------------#2020-07-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b24a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">只有当你有大海捞针的方法时，才能观察到图案的美！</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/68d4ed94be6f9502029dbe1884d2a607.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*X6jc5NtMK6OWW03_"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">丹尼尔·塔夫乔德在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h2 id="99bc" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">什么是异常现象，我为什么要担心？</h2><p id="f24a" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi mo translated"><span class="l mp mq mr bm ms mt mu mv mw di">“一个</span>异常值”或“异常值”是样本空间中那些异常的数据点，或<em class="mx">超出趋势</em>。现在，问题是，“你如何定义异常或异常的东西？”<br/>答:数学上，不在<strong class="lx iu">相同趋势</strong>中的数据点与其邻域中的数据点相同。</p><p id="3859" class="pw-post-body-paragraph lv lw it lx b ly my ju ma mb mz jx md li na mf mg lm nb mi mj lq nc ml mm mn im bi translated">作为业务伙伴或技术专家，在日常工作中从大量数据中发现异常模式。在这里，我们将讨论一种能够以接近实时的格式检测数据中所有(<em class="mx">几乎</em>)异常的方法。</p></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><p id="2dc2" class="pw-post-body-paragraph lv lw it lx b ly my ju ma mb mz jx md li na mf mg lm nb mi mj lq nc ml mm mn im bi translated">在本文中，我们将尝试学习如何从数据中检测<em class="mx">异常</em>而无需事先训练模型，因为你无法根据数据训练模型，而我们对此一无所知！<br/>这就是<strong class="lx iu">无监督学习</strong>的想法出现的地方。<br/>选择<strong class="lx iu">时间序列</strong>数据的原因是，它们是最常见的真实世界数据之一，我们作为数据科学家进行分析。</p><p id="a57d" class="pw-post-body-paragraph lv lw it lx b ly my ju ma mb mz jx md li na mf mg lm nb mi mj lq nc ml mm mn im bi translated">来到模型——“<strong class="lx iu">DeepAnT”</strong>是一个无监督的基于时间的异常检测模型，它由卷积神经网络层组成。在检测时间序列数据中的各种异常时，它确实工作得很好。但这可能需要注意检测噪声，这可以通过调整超参数来处理，如内核大小、<em class="mx">回看</em>、<em class="mx">时间序列窗口大小</em>、隐藏层中的单元等等。</p></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><p id="8eda" class="pw-post-body-paragraph lv lw it lx b ly my ju ma mb mz jx md li na mf mg lm nb mi mj lq nc ml mm mn im bi translated">代码和数据的链接在这里的<a class="ae ky" href="https://github.com/bmonikraj/medium-ds-unsupervised-anomaly-detection-deepant-lstmae" rel="noopener ugc nofollow" target="_blank"> Github </a>链接中提供—</p><div class="nk nl gp gr nm nn"><a href="https://github.com/bmonikraj/medium-ds-unsupervised-anomaly-detection-deepant-lstmae" rel="noopener  ugc nofollow" target="_blank"><div class="no ab fo"><div class="np ab nq cl cj nr"><h2 class="bd iu gy z fp ns fr fs nt fu fw is bi translated">bmonikraj/medium-ds-unsupervised-异常检测-deepant-lstmae</h2><div class="nu l"><h3 class="bd b gy z fp ns fr fs nt fu fw dk translated">使用 DeepAnT 和 LSTM 自动编码器数据描述的无监督异常检测的基于深度学习的技术…</h3></div><div class="nv l"><p class="bd b dl z fp ns fr fs nt fu fw dk translated">github.com</p></div></div><div class="nw l"><div class="nx l ny nz oa nw ob ks nn"/></div></div></a></div><p id="e048" class="pw-post-body-paragraph lv lw it lx b ly my ju ma mb mz jx md li na mf mg lm nb mi mj lq nc ml mm mn im bi translated">数据中的特征数= 27(包括'时间戳'特征)<br/>数据特征类型=数值</p><p id="08f0" class="pw-post-body-paragraph lv lw it lx b ly my ju ma mb mz jx md li na mf mg lm nb mi mj lq nc ml mm mn im bi translated">现在我们知道了数据，让我们进入代码库，解决我们遇到的问题。<br/>问题描述:-我们有大约 80 年的加拿大气候数据(数据频率=每天)，我们想从气候数据中识别异常。</p></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><pre class="kj kk kl km gt oc od oe of aw og bi"><span id="9f6e" class="kz la it od b gy oh oi l oj ok">import numpy as np<br/>import pandas as pd<br/>import torch<br/>from sklearn.preprocessing import MinMaxScaler<br/>import time<br/>import datetime<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>import os<br/><br/>data_file = ""<br/>MODEL_SELECTED = "deepant" <em class="mx"># Possible Values ['deepant', 'lstmae']</em><br/>LOOKBACK_SIZE = 10<br/>for dirname, _, filenames <strong class="od iu">in</strong> os.walk('/kaggle/input'):<br/>    for filename <strong class="od iu">in</strong> filenames:<br/>        data_file = os.path.join(dirname, filename)</span></pre><p id="5451" class="pw-post-body-paragraph lv lw it lx b ly my ju ma mb mz jx md li na mf mg lm nb mi mj lq nc ml mm mn im bi mo translated">模块被导入，文件被加载到 Kaggle 内核的环境中。</p></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><pre class="kj kk kl km gt oc od oe of aw og bi"><span id="4261" class="kz la it od b gy oh oi l oj ok">def read_modulate_data(data_file):<br/>    <em class="mx">"""</em><br/><em class="mx">        Data ingestion : Function to read and formulate the data</em><br/><em class="mx">    """</em><br/>    data = pd.read_csv(data_file)<br/>    data.fillna(data.mean(), inplace=True)<br/>    df = data.copy()<br/>    data.set_index("LOCAL_DATE", inplace=True)<br/>    data.index = pd.to_datetime(data.index)<br/>    return data, df</span></pre><p id="a8ac" class="pw-post-body-paragraph lv lw it lx b ly my ju ma mb mz jx md li na mf mg lm nb mi mj lq nc ml mm mn im bi mo translated"><span class="l mp mq mr bm ms mt mu mv mw di">在上面的</span>代码片段中，我们从文件中读取数据，该文件存在于环境中。<br/>读取后，我们将索引数据转换为<em class="mx">时间戳</em>。<br/>将时间戳作为数据索引的主要动机是，如果需要，通过数据帧图和重采样进行更好的分析。</p></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><pre class="kj kk kl km gt oc od oe of aw og bi"><span id="32d8" class="kz la it od b gy oh oi l oj ok">def data_pre_processing(df):<br/>    <em class="mx">"""</em><br/><em class="mx">        Data pre-processing : Function to create data for Model</em><br/><em class="mx">    """</em><br/>    try:<br/>        scaled_data = MinMaxScaler(feature_range = (0, 1))<br/>        data_scaled_ = scaled_data.fit_transform(df)<br/>        df.loc[:,:] = data_scaled_<br/>        _data_ = df.to_numpy(copy=True)<br/>        X = np.zeros(shape=(df.shape[0]-LOOKBACK_SIZE,LOOKBACK_SIZE,df.shape[1]))<br/>        Y = np.zeros(shape=(df.shape[0]-LOOKBACK_SIZE,df.shape[1]))<br/>        timesteps = []<br/>        for i <strong class="od iu">in</strong> range(LOOKBACK_SIZE-1, df.shape[0]-1):<br/>            timesteps.append(df.index[i])<br/>            Y[i-LOOKBACK_SIZE+1] = _data_[i+1]<br/>            for j <strong class="od iu">in</strong> range(i-LOOKBACK_SIZE+1, i+1):<br/>                X[i-LOOKBACK_SIZE+1][LOOKBACK_SIZE-1-i+j] = _data_[j]<br/>        return X,Y,timesteps<br/>    except <strong class="od iu">Exception</strong> as e:<br/>        print("Error while performing data pre-processing : <strong class="od iu">{0}</strong>".format(e))<br/>        return None, None, None</span></pre><p id="6684" class="pw-post-body-paragraph lv lw it lx b ly my ju ma mb mz jx md li na mf mg lm nb mi mj lq nc ml mm mn im bi translated">在这里，我们在<code class="fe ol om on od b">[0,1]</code>的范围内对数据进行标准化，然后通过将“时间步长”作为一个维度纳入图片来修改数据集。<br/>想法是将维度数据集从<code class="fe ol om on od b">[Batch Size, Features]</code>转换到<code class="fe ol om on od b">[Batch Size, Lookback Size, Features]</code></p></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><pre class="kj kk kl km gt oc od oe of aw og bi"><span id="4b1a" class="kz la it od b gy oh oi l oj ok">class <strong class="od iu">DeepAnT</strong>(torch.nn.Module):<br/>    <em class="mx">"""</em><br/><em class="mx">        Model : Class for DeepAnT model</em><br/><em class="mx">    """</em><br/>    def __init__(self, LOOKBACK_SIZE, DIMENSION):<br/>        super(DeepAnT, self).__init__()<br/>        self.conv1d_1_layer = torch.nn.Conv1d(in_channels=LOOKBACK_SIZE, out_channels=16, kernel_size=3)<br/>        self.relu_1_layer = torch.nn.ReLU()<br/>        self.maxpooling_1_layer = torch.nn.MaxPool1d(kernel_size=2)<br/>        self.conv1d_2_layer = torch.nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3)<br/>        self.relu_2_layer = torch.nn.ReLU()<br/>        self.maxpooling_2_layer = torch.nn.MaxPool1d(kernel_size=2)<br/>        self.flatten_layer = torch.nn.Flatten()<br/>        self.dense_1_layer = torch.nn.Linear(80, 40)<br/>        self.relu_3_layer = torch.nn.ReLU()<br/>        self.dropout_layer = torch.nn.Dropout(p=0.25)<br/>        self.dense_2_layer = torch.nn.Linear(40, DIMENSION)<br/>        <br/>    def forward(self, x):<br/>        x = self.conv1d_1_layer(x)<br/>        x = self.relu_1_layer(x)<br/>        x = self.maxpooling_1_layer(x)<br/>        x = self.conv1d_2_layer(x)<br/>        x = self.relu_2_layer(x)<br/>        x = self.maxpooling_2_layer(x)<br/>        x = self.flatten_layer(x)<br/>        x = self.dense_1_layer(x)<br/>        x = self.relu_3_layer(x)<br/>        x = self.dropout_layer(x)<br/>        return self.dense_2_layer(x)</span></pre><p id="2f6d" class="pw-post-body-paragraph lv lw it lx b ly my ju ma mb mz jx md li na mf mg lm nb mi mj lq nc ml mm mn im bi mo translated"><span class="l mp mq mr bm ms mt mu mv mw di">我们</span>正在创建模型 DeepAnT 架构(关于论文的更多信息可以在 IEEE 的链接— <a class="ae ky" href="https://ieeexplore.ieee.org/abstract/document/8581424" rel="noopener ugc nofollow" target="_blank">研究论文中找到)。<br/>它包含两层卷积层，在确定数据时间模式中的异常时非常有效。<br/>可以根据数据进一步调整内核大小和过滤器数量，以实现更好的性能。</a></p><p id="5450" class="pw-post-body-paragraph lv lw it lx b ly my ju ma mb mz jx md li na mf mg lm nb mi mj lq nc ml mm mn im bi translated">让我们来看看模型架构，以便更好地直观理解—</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/a1f4a1883c01ec4d664ab0bbf20964cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*s3DcZoG3hA6YoWZ-oSaGFw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由 Mohsin Munir、Shoaib Ahmed Siddhiqui、Andreas Dengel 和 Sheraz Ahmed 撰写的 IEEE 论文中的 DeepAnT 模型架构</p></figure></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><pre class="kj kk kl km gt oc od oe of aw og bi"><span id="a58d" class="kz la it od b gy oh oi l oj ok">def make_train_step(model, loss_fn, optimizer):<br/>    <em class="mx">"""</em><br/><em class="mx">        Computation : Function to make batch size data iterator</em><br/><em class="mx">    """</em><br/>    def train_step(x, y):<br/>        model.train()<br/>        yhat = model(x)<br/>        loss = loss_fn(y, yhat)<br/>        loss.backward()<br/>        optimizer.step()<br/>        optimizer.zero_grad()<br/>        return loss.item()<br/>    return train_step</span></pre><p id="389a" class="pw-post-body-paragraph lv lw it lx b ly my ju ma mb mz jx md li na mf mg lm nb mi mj lq nc ml mm mn im bi translated">功能<code class="fe ol om on od b">make_train_step</code>是创建迭代器，它可以向计算模型提供小批量的数据。</p><p id="3eea" class="pw-post-body-paragraph lv lw it lx b ly my ju ma mb mz jx md li na mf mg lm nb mi mj lq nc ml mm mn im bi translated">MSE 损失函数传递给 make_train_step 函数，Adam 优化器用于多个历元后的损失函数优化和收敛。</p></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><pre class="kj kk kl km gt oc od oe of aw og bi"><span id="5ee5" class="kz la it od b gy oh oi l oj ok">def compute(X,Y):<br/>    <em class="mx">"""</em><br/><em class="mx">        Computation : Find Anomaly using model based computation </em><br/><em class="mx">    """</em><br/>    if str(MODEL_SELECTED) == "deepant":<br/>        model = DeepAnT(10,26)<br/>        criterion = torch.nn.MSELoss(reduction='mean')<br/>        optimizer = torch.optim.Adam(list(model.parameters()), lr=1e-5)<br/>        train_data = torch.utils.data.TensorDataset(torch.tensor(X.astype(np.float32)), torch.tensor(Y.astype(np.float32)))<br/>        train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=32, shuffle=False)<br/>        train_step = make_train_step(model, criterion, optimizer)<br/>        for epoch <strong class="od iu">in</strong> range(30):<br/>            loss_sum = 0.0<br/>            ctr = 0<br/>            for x_batch, y_batch <strong class="od iu">in</strong> train_loader:<br/>                loss_train = train_step(x_batch, y_batch)<br/>                loss_sum += loss_train<br/>                ctr += 1<br/>            print("Training Loss: <strong class="od iu">{0}</strong> - Epoch: <strong class="od iu">{1}</strong>".format(float(loss_sum/ctr), epoch+1))<br/>        hypothesis = model(torch.tensor(X.astype(np.float32))).detach().numpy()<br/>        loss = np.linalg.norm(hypothesis - Y, axis=1)<br/>        return loss.reshape(len(loss),1)<br/>    else:<br/>        print("Selection of Model is not in the set")<br/>        return None</span></pre><p id="9efb" class="pw-post-body-paragraph lv lw it lx b ly my ju ma mb mz jx md li na mf mg lm nb mi mj lq nc ml mm mn im bi mo translated">最后一步是通过数据运行模型(批量)。我们使用 MSE 损失函数和 Adam 优化器，并在 30 个时期内运行。<br/>此后，我们生成假设并计算损失，即数据集中给定的各个时间戳的异常置信度得分。</p></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h2 id="d8ab" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">形象化</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/8ac830b47226eb00b38db0963ee9fcc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*h8PKqKiSN3rpboGe.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">异常置信度得分的频率分布|作者图片</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/c53b7c56f8ebefb744c6d429c31163d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FbpsZ9EadTkF5GxQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">异常可信度分数与时间戳(freq="daily") |作者图片</p></figure><p id="bb4c" class="pw-post-body-paragraph lv lw it lx b ly my ju ma mb mz jx md li na mf mg lm nb mi mj lq nc ml mm mn im bi translated">看上面的两个图，我们可以得出结论，异常置信度得分大于 1.2 的时间戳是那些可以被视为潜在异常的时间戳，并且可以通过分析采取进一步的行动:)</p></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><ul class=""><li id="2753" class="oq or it lx b ly my mb mz li os lm ot lq ou mn ov ow ox oy bi translated">DeepAnT 是一种适用于基于时间序列的异常检测的体系结构模型。</li><li id="222c" class="oq or it lx b ly oz mb pa li pb lm pc lq pd mn ov ow ox oy bi translated">用于类似问题的其他架构有:LSTM 自动编码器、具有时间信息的 kNN 聚类。</li><li id="f022" class="oq or it lx b ly oz mb pa li pb lm pc lq pd mn ov ow ox oy bi translated">时间序列数据，在需要实时分析的情况下，应该考虑数据流。</li></ul></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><p id="ab23" class="pw-post-body-paragraph lv lw it lx b ly my ju ma mb mz jx md li na mf mg lm nb mi mj lq nc ml mm mn im bi translated">对于想直接在 Kaggle 内核上运行的:)</p><div class="nk nl gp gr nm nn"><a href="https://www.kaggle.com/bmonikraj/unsupervised-timeseries-anomaly-detection/notebook" rel="noopener  ugc nofollow" target="_blank"><div class="no ab fo"><div class="np ab nq cl cj nr"><h2 class="bd iu gy z fp ns fr fs nt fu fw is bi translated">无监督时间序列异常检测</h2><div class="nu l"><h3 class="bd b gy z fp ns fr fs nt fu fw dk translated">使用 Kaggle 笔记本探索和运行机器学习代码|使用加拿大 80 年的气候数据</h3></div><div class="nv l"><p class="bd b dl z fp ns fr fs nt fu fw dk translated">www.kaggle.com</p></div></div><div class="nw l"><div class="pe l ny nz oa nw ob ks nn"/></div></div></a></div><p id="4174" class="pw-post-body-paragraph lv lw it lx b ly my ju ma mb mz jx md li na mf mg lm nb mi mj lq nc ml mm mn im bi translated">如有任何疑问，请通过<a class="ae ky" href="mailto:bmonikraj@gmail.com" rel="noopener ugc nofollow" target="_blank">bmonikraj@gmail.com</a>联系我本人</p></div></div>    
</body>
</html>