<html>
<head>
<title>NeurIPS 2019 Highlights</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NeurIPS 2019 亮点</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/neurips-2019-highlights-part-1-cc4acc46f8c2?source=collection_archive---------21-----------------------#2020-01-07">https://towardsdatascience.com/neurips-2019-highlights-part-1-cc4acc46f8c2?source=collection_archive---------21-----------------------#2020-01-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="df90" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">我在最大的机器学习大会上学到的总结。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/11122375705075b71fa07a0b144442ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v6ATDuYRcMKxEGsN4iI6qg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">温哥华会议中心海滨景色[图片由本人拍摄]</p></figure><p id="0ba8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">NeurIPS 2019 有 13000 名参与者，1428 篇被接受的论文(来自 6743 篇提交的论文)，58 场研讨会，16K 页的会议记录，是我参加过的最具影响力也是最有成效的会议之一。主席们在“<a class="ae lu" href="https://medium.com/@NeurIPSConf/what-we-learned-from-neurips-2019-data-111ab996462c" rel="noopener">我们从 NeurIPS 2019 数据</a>中学到了什么”上展示了一份精彩的会议数据分析。</p><p id="bd59" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">考虑到会议的规模，要涵盖所有的曲目、演讲和海报几乎是不可能的。在这篇文章(以及后续文章)中，我将从我个人的角度提供一些大会的亮点。</p><h1 id="344c" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">1.专题讲座:</h1><p id="0553" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">Yoshua Bengio | <a class="ae lu" href="https://slideslive.com/38921750/from-system-1-deep-learning-to-system-2-deep-learning" rel="noopener ugc nofollow" target="_blank"> <em class="ms">从系统 1 深度学习到系统 2 深度学习</em> </a> <br/> Vivienne Sze | <a class="ae lu" href="https://slideslive.com/38921492/efficient-processing-of-deep-neural-network-from-algorithms-to-hardware-architectures" rel="noopener ugc nofollow" target="_blank"> <em class="ms">深度神经网络的高效处理:从算法到硬件架构</em></a><br/>Celeste Kidd |<a class="ae lu" href="https://slideslive.com/38921495/how-to-know" rel="noopener ugc nofollow" target="_blank"><em class="ms">如何知道</em></a><br/>Mohammad emti yaz Khan |<a class="ae lu" href="https://slideslive.com/38921489/deep-learning-with-bayesian-principles" rel="noopener ugc nofollow" target="_blank"><em class="ms">深度学习与贝叶斯原理</em></a><br/>Blaise Aguera y Arcas |<a class="ae lu" href="https://slideslive.com/38921748/social-intelligence" rel="noopener ugc nofollow" target="_blank"/></p><p id="0347" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae lu" href="https://slideslive.com/38921750/from-system-1-deep-learning-to-system-2-deep-learning" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu">从系统 1 深度学习到系统 2 深度学习</strong> </a> <strong class="la iu"> </strong> ( <a class="ae lu" href="https://drive.google.com/file/d/1zbe_N8TmAEvPiKXmn6yZlRkFehsAUS8Z/view" rel="noopener ugc nofollow" target="_blank">幻灯片</a> ): Yoshua Bengio 的演讲是大会最受欢迎的主题演讲。Yoshua 对深度学习的现状及其未来提供了一个奇妙的见解。受《思考<a class="ae lu" href="https://www.amazon.com/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374533555" rel="noopener ugc nofollow" target="_blank"> <em class="ms">、快与慢</em> </a> <em class="ms">，</em>这本书的启发，他提出了一条从深度学习擅长的<em class="ms">系统 1 </em>(直觉、快速无意识非语言、习惯性决策/推理)到其未来的<em class="ms">系统 2 </em>(缓慢、逻辑、顺序、有意识、语言、算法、决策)的路径。他将<em class="ms">意识</em>(以及<a class="ae lu" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank"> <em class="ms">注意力</em> </a>作为其关键成分)作为<em class="ms">系统 2 </em>的基础，以<a class="ae lu" href="https://arxiv.org/abs/1709.08568" rel="noopener ugc nofollow" target="_blank">稀疏因子图作为意识先验</a>，以<a class="ae lu" href="https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html" rel="noopener ugc nofollow" target="_blank">元学习</a>作为理论框架，将深度学习从系统 1 扩展到系统 2。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/bab2ce7645822d96034edacfba4281e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XcXAvXOBia1cg9WgpwwewA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">系统 1 与系统 2 学习[图片取自 Yoshua Bengio 的<a class="ae lu" href="https://drive.google.com/file/d/1zbe_N8TmAEvPiKXmn6yZlRkFehsAUS8Z/view" rel="noopener ugc nofollow" target="_blank">幻灯片</a></p></figure><p id="9b23" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae lu" href="https://slideslive.com/38921489/deep-learning-with-bayesian-principles" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu">深度学习与贝叶斯原理</strong> </a> <strong class="la iu"> ( </strong> <a class="ae lu" href="https://emtiyaz.github.io/papers/neurips_tutorial.pdf" rel="noopener ugc nofollow" target="_blank">幻灯片</a> <strong class="la iu"> ): </strong> <em class="ms">深度学习</em>和<em class="ms">贝叶斯学习</em>被认为是两个完全不同的领域，经常在互补的设置中使用。Emtiyaz Khan 在他的演讲中介绍了现代贝叶斯原理来弥合这一差距，通过结合它们的优势来解决具有挑战性的现实世界问题。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/876e5ef0ed5ef93da516e2e1b0e2410c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LfvK93rIgN20tOX01Raw7g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">贝叶斯 vs 深度学习[图片取自<a class="ae lu" href="https://emtiyaz.github.io/papers/neurips_tutorial.pdf" rel="noopener ugc nofollow" target="_blank">https://emtiyaz.github.io/papers/neurips_tutorial.pdf</a></p></figure><p id="8461" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以使用贝叶斯原则作为一般原则，通过计算后验近似来设计、改进和推广一系列学习算法。我们可以将现有的算法(例如 Adam optimizer)作为特例，或者设计新的深度学习算法，用于不确定性估计、小数据集上的推广和终身学习。训练贝叶斯神经网络特别是后验近似仍然是一个具有挑战性和计算昂贵的问题。因此，可以使用近似方法，如<em class="ms">变分推论</em> (VI)。</p><p id="1c25" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">进一步阅读可以参考论文“<a class="ae lu" href="https://arxiv.org/abs/1906.02506" rel="noopener ugc nofollow" target="_blank">实用深度学习与贝叶斯原理</a>”、“<a class="ae lu" href="https://arxiv.org/pdf/1807.04489.pdf" rel="noopener ugc nofollow" target="_blank">变分推理的自然梯度下降</a>”、“<a class="ae lu" href="https://nips.cc/Conferences/2019/Schedule?showParentSession=15542" rel="noopener ugc nofollow" target="_blank">概率方法—变分推理</a>”。PyTorch 实现也是一个即插即用的优化器。</p><h1 id="afed" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">2.趋势:</h1><p id="0799" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">下图显示了 NeurIPS 2019 所有已接受论文标题的最常用标记(单词)的<a class="ae lu" href="https://www.wordclouds.com/" rel="noopener ugc nofollow" target="_blank">单词云</a>(经过一些预处理，如删除自定义停用词，如“neural”&amp;“network”)。获取标题和令牌频率的代码可以在<a class="ae lu" href="https://github.com/alirezadir/neurips-analysis/tree/master/notebooks" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mv"><img src="../Images/2816500a7194c15b511ad3d10b8f7999.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*be50kG9WKgUhOQ9-BaTCcw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">论文标题中最常见标记的词云和频率图—neur IPS 2019[源代码可在此处获得<a class="ae lu" href="https://github.com/alirezadir/neurips-analysis/tree/master/notebooks" rel="noopener ugc nofollow" target="_blank"/></p></figure><p id="215c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最常用的 10 个词如下:<em class="ms">优化、强化、对抗、图、高效、随机、最优、生成、贝叶斯</em>。我对以下关键词进行了进一步分析:<em class="ms">优化、强化学习、对抗、图形、生成和贝叶斯神经网络</em>(代码可在此处找到<a class="ae lu" href="https://github.com/alirezadir/neurips-analysis/tree/master/notebooks" rel="noopener ugc nofollow" target="_blank"/>)，发现了一些有趣的结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mw"><img src="../Images/260029be5c15dea414027ac2c720d893.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4QKm-k_T9u2YNvlw9k2_EQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按主题分类的论文标题中最常见标记的词云—neur IPS 2019[源代码可在此处获得<a class="ae lu" href="https://github.com/alirezadir/neurips-analysis/tree/master/notebooks" rel="noopener ugc nofollow" target="_blank"/></p></figure><p id="91bc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从我的角度来看(基于会议出席人数和上述数据)，以下主题是会议的趋势:</p><ul class=""><li id="0b9f" class="mx my it la b lb lc le lf lh mz ll na lp nb lt nc nd ne nf bi translated"><strong class="la iu">强化学习</strong> : RL 仍然是人工智能会议中最热门的话题之一。彼得·阿比尔等人的<a class="ae lu" href="https://sites.google.com/view/deep-rl-workshop-neurips-2019/home" rel="noopener ugc nofollow" target="_blank">深度强化学习工作坊</a>。艾尔。Katja Hofmann 的教程<a class="ae lu" href="https://slideslive.com/38921493/reinforcement-learning-past-present-and-future-perspectives" rel="noopener ugc nofollow" target="_blank">强化学习:过去、现在和未来的观点</a> ( <a class="ae lu" href="https://www.microsoft.com/en-us/research/uploads/prod/2019/11/2019-12-09-Hofmann-NeurIPS-tutorial_no-video.pdf" rel="noopener ugc nofollow" target="_blank">幻灯片</a>)是今年 Neurips 最受欢迎的课程之一。最近受到很多关注的一个非常有趣的话题是<strong class="la iu"> <em class="ms">多智能体 RL (MARL) </em> </strong> <em class="ms">，</em>在复杂的环境中，多个智能体相互竞争和/或协调以实现一个目标。<em class="ms"> </em> The Nature paper，<a class="ae lu" href="https://www.nature.com/articles/s41586-019-1724-z" rel="noopener ugc nofollow" target="_blank"> <em class="ms">星际争霸 2 中的特级大师级使用多智能体强化学习</em> </a>，是 DRL 工作坊的重头戏。Katja Hofmann 在她的演讲中概述了我们目前所处的位置，以及对未来研究和 RL 实际应用的关键机会的展望。关于 MARL 的介绍可以在这篇<a class="ae lu" rel="noopener" target="_blank" href="/modern-game-theory-and-multi-agent-reinforcement-learning-systems-e8c936d6de42">博客文章</a>中找到，关于这个主题的论文的完整列表可以在<a class="ae lu" href="https://github.com/LantaoYu/MARL-Papers" rel="noopener ugc nofollow" target="_blank">蓝涛宇的报告</a>中找到。</li><li id="cbd4" class="mx my it la b lb ng le nh lh ni ll nj lp nk lt nc nd ne nf bi translated"><strong class="la iu">对抗网络</strong>:gan 为知识获取提供了一个很好的机制，然而，它们也可以被用作<a class="ae lu" href="https://arxiv.org/abs/1312.6199" rel="noopener ugc nofollow" target="_blank">对抗例子</a>来产生对 DNN 模型的攻击(例如，来自攻击者的<a class="ae lu" href="https://openai.com/blog/adversarial-example-research/" rel="noopener ugc nofollow" target="_blank">对抗输入</a>可以在训练图像中引起难以察觉的变化来欺骗分类模型)。评估深度学习模型针对这种攻击的<em class="ms"> </em> <strong class="la iu"> <em class="ms">对抗性</em> </strong> <em class="ms"> </em> <strong class="la iu"> <em class="ms">健壮性</em> </strong>一直是 OpenAI、Google 和 IBM 等 AI 巨头(例如 IBM 的<a class="ae lu" href="https://github.com/IBM/adversarial-robustness-toolbox" rel="noopener ugc nofollow" target="_blank">对抗性健壮性工具箱</a>)的优先事项，并且不出所料是该领域的主导话题。</li><li id="7dfc" class="mx my it la b lb ng le nh lh ni ll nj lp nk lt nc nd ne nf bi translated">【<strong class="la iu">新增</strong><strong class="la iu">贝叶斯深度学习</strong>:请参考第一节<a class="ae lu" href="https://slideslive.com/38921489/deep-learning-with-bayesian-principles" rel="noopener ugc nofollow" target="_blank"> <em class="ms">深度学习与贝叶斯原理</em> </a> <em class="ms"> </em>。</li><li id="935b" class="mx my it la b lb ng le nh lh ni ll nj lp nk lt nc nd ne nf bi translated">【<strong class="la iu">新</strong>】<strong class="la iu">图形神经网络</strong>:在这次 NeurIPS 大会上，图形几乎无处不在。图是非常强大的非欧几里得数据结构，可以表示对象之间的复杂关系和相互依赖性。因此，大量应用(如社交网络、物理科学、化学、电子商务、知识库、推荐系统和组合问题)中的数据可以用图来表示。图的<em class="ms">不规则结构</em>(可变大小和节点的无序邻居集)使得对它们执行诸如卷积的操作具有挑战性。因此，人们对<em class="ms">图形神经网络(GNNs) </em>算法越来越感兴趣，以便<em class="ms"> </em>推广深度学习方法，如针对图形数据的 CNN、RNNs 和自动编码器<em class="ms"> </em>。gnn 可以分为四类:<em class="ms">递归图神经网络、卷积图神经网络(cgnn)、图自动编码器和时空图神经网络</em>，目前 cgnn 的权重最大。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/ab49d2cd92e3e3ccbf96ed72e2807949.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EVyIQ5ji0fR07-ZtwGAleA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">左边的 2D 卷积与右边的图卷积(节点的邻居是无序的，大小可变)的比较[图片取自本文<a class="ae lu" href="https://arxiv.org/pdf/1901.00596.pdf" rel="noopener ugc nofollow" target="_blank"/>]。</p></figure><p id="2a6f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要了解更多关于 GNNs 的知识，可以看看<a class="ae lu" rel="noopener" target="_blank" href="/a-gentle-introduction-to-graph-neural-network-basics-deepwalk-and-graphsage-db5d540d50b3">关于图神经网络的温和介绍</a>的帖子或者下面的调查论文:<br/><a class="ae lu" href="https://arxiv.org/abs/1901.00596" rel="noopener ugc nofollow" target="_blank">关于图神经网络的全面调查</a>、<br/><a class="ae lu" href="http://snap.stanford.edu/proj/embeddings-www/files/nrltutorial-part2-gnns.pdf" rel="noopener ugc nofollow" target="_blank">Stanford SNAP 的图神经网络教程</a>和<br/><a class="ae lu" href="https://arxiv.org/pdf/1812.08434.pdf" rel="noopener ugc nofollow" target="_blank">图神经网络:方法和应用回顾</a>。<br/>在<a class="ae lu" href="https://github.com/thunlp/GNNPapers" rel="noopener ugc nofollow" target="_blank">本次回购</a>中还收集了一份不错的 GNN 论文清单。图不仅可以用作数据结构，还可以表示神经网络的输出，例如，任何联合分布都可以表示为因子图，正如 Yoshua Bengio 在他的特邀演讲中所指出的。</p><h1 id="4c3a" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">3.新方向奖:</h1><p id="14f4" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">杰出新方向论文奖授予了 Vaishnavh Nagarajan 和 j .济科·科尔特的<a class="ae lu" href="https://arxiv.org/abs/1902.04742" rel="noopener ugc nofollow" target="_blank">统一收敛可能无法解释深度学习中的泛化</a>(<a class="ae lu" href="https://www.cs.cmu.edu/~vaishnan/talks/neurips19_uc_slides.pdf" rel="noopener ugc nofollow" target="_blank">幻灯片</a>，<a class="ae lu" href="https://locuslab.github.io/2019-07-09-uniform-convergence/" rel="noopener ugc nofollow" target="_blank">博客</a>，<a class="ae lu" href="https://github.com/locuslab/uniform-convergence-NeurIPS19" rel="noopener ugc nofollow" target="_blank">代码</a>)。</p><p id="17e0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">深度学习理论中最大的公开挑战之一是泛化难题，因为深度网络模型(与经典学习理论相反)尽管存在严重的过度参数化，但仍能很好地泛化。为了解释这种反直觉的行为，理论工作试图推导出深度网络的<em class="ms">泛化差距</em>(模型在训练数据和来自同一分布的未看到的数据上的表现之间的差距)的上限。这项工作退一步说，追求一致收敛为基础的界限可能不会真正导致我们对这个难题的完整解决方案。特别地，它表明 1)理论泛化界限随着训练集大小而增长(而经验差距减小)，以及 2)任何类型的一致收敛界限将被证明无法解释深度学习中某些情况下的泛化。</p><h1 id="ce9f" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">4.车间</h1><p id="98ed" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">在为期 3 天的 54 场研讨会中，以下是最受与会者欢迎的研讨会:</p><p id="1689" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae lu" href="https://sites.google.com/view/deep-rl-workshop-neurips-2019/home" rel="noopener ugc nofollow" target="_blank">深度强化学习</a><br/><a class="ae lu" href="https://grlearning.github.io/" rel="noopener ugc nofollow" target="_blank">图形表征学习</a><br/><a class="ae lu" href="http://metalearning.ml/2019/" rel="noopener ugc nofollow" target="_blank">元学习</a> ( <a class="ae lu" href="https://david-abel.github.io/notes/neurips_2019.pdf" rel="noopener ugc nofollow" target="_blank">大卫·阿贝尔笔记</a>，第 4 节，对本次工作坊有个牛逼的总结)<br/><a class="ae lu" href="http://bayesiandeeplearning.org/" rel="noopener ugc nofollow" target="_blank">贝叶斯深度学习</a><br/><a class="ae lu" href="https://sites.google.com/view/biologicalandartificialrl/" rel="noopener ugc nofollow" target="_blank">生物和人工强化学习</a><br/><a class="ae lu" href="https://www.climatechange.ai/NeurIPS2019_workshop.html" rel="noopener ugc nofollow" target="_blank">用 ML 应对气候变化</a> <br/>以及对<em class="ms">对话式 AI 感兴趣的人</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/d641e15a5b02a1a3ca30cdde8478afc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xa3c-JMC93vOth37tanEPA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">关于<a class="ae lu" href="https://www.climatechange.ai/NeurIPS2019_workshop.html" rel="noopener ugc nofollow" target="_blank">与 ML 一起应对气候变化的研讨会</a>[图片来自<a class="ae lu" href="https://twitter.com/PaulWSave/status/1205932047232929792?s=20" rel="noopener ugc nofollow" target="_blank"> Paul Save 的推特</a> ]</p></figure><h1 id="a20d" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">5.民众</h1><p id="678b" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">在会议期间的 28 个演示中，以下是我个人最喜欢的(有些偏向 NLP):<br/><a class="ae lu" href="http://exbert.net/" rel="noopener ugc nofollow" target="_blank">ex BERT</a>:一个解释 BERT 的学习表示的可视化分析工具<br/><a class="ae lu" href="https://streamlit.io/" rel="noopener ugc nofollow" target="_blank">Streamlit</a>， 机器学习工具的新应用程序框架<br/><a class="ae lu" href="https://allennlp.org/interpret" rel="noopener ugc nofollow" target="_blank">allenlp 解释器</a>:解释 NLP 模型的预测<br/><a class="ae lu" href="http://word-game-ui-dev.mybluemix.net/play-guesser" rel="noopener ugc nofollow" target="_blank">密码</a>:人类和人工智能代理之间的合作猜字游戏<br/>趣味演示:<a class="ae lu" href="https://www.youtube.com/watch?v=gqs2bSrFM4o" rel="noopener ugc nofollow" target="_blank"> <em class="ms">机器人辅助梳头</em> </a>、<a class="ae lu" href="http://smc2019.uma.es/articles/D1/D1_02_SMC2019_paper.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="ms">旋律吃角子老虎机</em> </a>互动音乐系统、<a class="ae lu" href="https://twitter.com/twentybn/status/1204859719007002625" rel="noopener ugc nofollow" target="_blank"> <em class="ms">与人工智能化身的一对一健身训练 </em></a></p><h1 id="91f2" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">6.社区、社交和聚会:</h1><p id="10df" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">NeurIPS 2019 强调多样性和包容性。有 15 次正式的社交聚会把有共同兴趣的人聚集在一起。此外，与会者通过大会的官方移动应用程序(Whova)交流了大量信息。例如，有超过 300 个聚会由参与者组织和(几乎)无数的主题讨论！！</p><h2 id="6271" class="nn lw it bd lx no np dn mb nq nr dp mf lh ns nt mh ll nu nv mj lp nw nx ml ny bi translated">AI 名人:</h2><p id="5b28" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">看到一些人工智能名人并与他们交谈是非常令人兴奋的，因为他们非常热情和谦逊:)</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/c5ba232f2913266528dcdf4a4b7c271f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WdY3deK0u5oN7kR9jSPkKw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我和艾名人[图片由我自己]</p></figure><h1 id="3935" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">8.其他摘要:</h1><p id="cea3" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">奇普·胡延的惊人之帖:<a class="ae lu" href="https://huyenchip.com/2019/12/18/key-trends-neurips-2019.html?utm_campaign=NLP%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank">来自 NeurIPS 2019 的关键趋势</a> <br/>大卫·阿贝尔的牛逼<a class="ae lu" href="https://david-abel.github.io/notes/neurips_2019.pdf" rel="noopener ugc nofollow" target="_blank"> NeurIPS 2019 笔记</a> (70 页)<br/>罗伯特·兰格的优美<a class="ae lu" href="https://github.com/RobertTLange/conference-school-notes/blob/master/2019-12-NeuRIPS/NeurIPS_1_compressed.pdf?utm_campaign=NLP%20News&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank">手记</a></p><h1 id="3c0e" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">9.相关链接</h1><ul class=""><li id="5250" class="mx my it la b lb mn le mo lh oa ll ob lp oc lt nc nd ne nf bi translated"><a class="ae lu" href="https://papers.nips.cc/book/advances-in-neural-information-processing-systems-32-2019" rel="noopener ugc nofollow" target="_blank">neur IPS 2019 被接受论文的完整列表</a></li><li id="3bba" class="mx my it la b lb ng le nh lh ni ll nj lp nk lt nc nd ne nf bi translated"><a class="ae lu" href="https://slideslive.com/neurips" rel="noopener ugc nofollow" target="_blank"> NeurIPS 2019 实录会谈</a></li><li id="0aee" class="mx my it la b lb ng le nh lh ni ll nj lp nk lt nc nd ne nf bi translated"><a class="ae lu" href="https://medium.com/@NeurIPSConf/what-we-learned-from-neurips-2019-data-111ab996462c" rel="noopener">我们从 NeurIPS 2019 数据中学到了什么</a></li><li id="7845" class="mx my it la b lb ng le nh lh ni ll nj lp nk lt nc nd ne nf bi translated"><a class="ae lu" href="https://medium.com/syncedreview/neurips-2019-the-numbers-c1808fba9480" rel="noopener"> NeurIPS 2019 |数字</a></li><li id="354f" class="mx my it la b lb ng le nh lh ni ll nj lp nk lt nc nd ne nf bi translated"><a class="ae lu" href="https://medium.com/syncedreview/neurips-2019-roundup-outstanding-papers-featured-talks-facts-and-figures-94aab6cfb8ce" rel="noopener"> NeurIPS 2019 综述:杰出论文、专题演讲、事实和数字</a></li><li id="5b29" class="mx my it la b lb ng le nh lh ni ll nj lp nk lt nc nd ne nf bi translated"><a class="ae lu" href="https://drive.google.com/file/d/1xdf3ia2VocviPR0q1uwH49h33bVVlNmp/view" rel="noopener ugc nofollow" target="_blank">深度 RL 工作坊论文</a></li></ul></div></div>    
</body>
</html>