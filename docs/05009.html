<html>
<head>
<title>Image Classification using CNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于 CNN 的图像分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-classification-cnn-cf53e5e5c176?source=collection_archive---------41-----------------------#2020-04-30">https://towardsdatascience.com/image-classification-cnn-cf53e5e5c176?source=collection_archive---------41-----------------------#2020-04-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0251" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated"><strong class="ak">使用 CNN 和代码</strong>对漫威字符进行分类</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d257e32a4d266a4370209a3a47e52f5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B_29ydtxizKwjjWEbt1vXA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据集中使用的漫威人物(来源:<a class="ae ky" href="https://www.instagram.com/marvel.fans.united/" rel="noopener ugc nofollow" target="_blank"> Instagram </a>，作者创建的拼贴)</p></figure><h1 id="89a5" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">我们怎么看？</h1><p id="40dd" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在深入探讨<strong class="lt iu">背后的技术细节之前，让我们先来谈谈生物。他们是如何识别和感知图像的。我们每秒钟看到多幅图像，我们能够处理它，我们能够在未来识别它。所有这一切都归功于<strong class="lt iu">人脑</strong>，世界上最强大的机器。让我们来谈谈我们是如何感知图像的，以便更好地理解<strong class="lt iu"> CNN </strong>。看看下面的图片</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/c9b182a576294348af78426197c8e328.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/1*0LbeeUVZs-WfNyU2-BElMA.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://in.pinterest.com/pin/61783826116053603/" rel="noopener ugc nofollow" target="_blank"> Pinterest </a></p></figure><p id="4e64" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">我们可以看到两幅图像</p><ul class=""><li id="9bb4" class="mt mu it lt b lu mo lx mp ma mv me mw mi mx mm my mz na nb bi translated">右脸的男人</li><li id="af49" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm my mz na nb bi translated">一个面向我们的男人</li></ul><p id="d753" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">基于我们对图像的聚焦我们看到不同的视图，我们的大脑太强大了，它自动识别模式并帮助我们识别物体。这是 CNN 背后的基本原理，它搜索模式并区分图像。</p><div class="kj kk kl km gt ab cb"><figure class="nh kn ni nj nk nl nm paragraph-image"><img src="../Images/ba7119417c200521433ecf722eb3ecf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:320/format:webp/1*5iPDtmN0sA7AnbLqC71XlQ.jpeg"/></figure><figure class="nh kn ni nj nk nl nm paragraph-image"><img src="../Images/3158c0cf732528a1a7ba06964960d41a.png" data-original-src="https://miro.medium.com/v2/resize:fit:320/format:webp/1*5ylBJ0z1IQ4t8-7wHfqvWA.jpeg"/><p class="ku kv gj gh gi kw kx bd b be z dk nn di no np translated">狮子狗(图片来源:Fredrik hlander 在<a class="ae ky" href="https://unsplash.com/s/photos/poodle?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄)狮子(图片来源:Arleen wiese 在<a class="ae ky" href="https://unsplash.com/s/photos/lion?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄)</p></figure></div><p id="301e" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">考虑上面的图像，我们能够通过观察一些模式来识别 A 和 B。我们能够做到这一点是因为我们在过去看到过这些图像，我们的大脑观察到了其中的一些模式，这有助于我们区分它们。如果我们问一个孩子或一个一生中从未见过狮子或狗的人。他能对上述图像进行分类吗？肯定<strong class="lt iu">没有</strong>。</p><p id="4031" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">上图不仅适用于<strong class="lt iu"> CNN </strong>也普遍适用于<strong class="lt iu">机器学习</strong>。让我们关注 CNN，因为这篇文章就是关于它的。我们向<strong class="lt iu"> CNN </strong>发送一堆图像进行训练，<strong class="lt iu"> CNN </strong>在其中寻找与人类相似的模式，因此当我们要求 CNN 识别这些图像时，它将能够识别其中的<strong class="lt iu">模式</strong>。因此，如果我们将图像发送给未经训练的 CNN，它也会像人类一样失败。</p><h1 id="13a8" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">CNN 步行道:</h1><p id="bbd5" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">如何让机器读取图像？是困扰我们大多数人的常见问题，这是<strong class="lt iu">图像处理的第一步。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/1856a183a65b575cc7b73f473818eba6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SXlVj7EDehN3Ex-KdfnQyA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" rel="noopener" target="_blank" href="/everything-you-ever-wanted-to-know-about-computer-vision-heres-a-look-why-it-s-so-awesome-e8a58dfb641e">计算机视觉如何工作。在最左边我们有一个图像，像素值是根据亮度分配的</a></p></figure><p id="fdcc" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">机器通过<strong class="lt iu">像素值读取图像。</strong>每幅图像都是像素值的组合，改变像素值会改变图像。这些像素值在输入 CNN 之前必须经过处理。像素值的数量取决于图像的大小，因此如果图像的大小太大，又会出现问题。一个完全连接的网络会将二维像素阵列展平为一维阵列，并根据像素值识别图像。</p><h1 id="7e22" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">卷积层:</h1><p id="1aa3" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">卷积层与汇集来拯救我们。它从图像中提取某些特征并缩小图像的尺寸。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/9619d00e1a23cca1064039ffc32f2a1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*60uqHq7wJ2Mbg0uP4SRgvg.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">一个过滤器在没有填充的二维图像上的卷积(来源:Pinterest </p></figure><p id="c6b4" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">我们把 6*6 矩阵的图像转换成 3*3 矩阵。我们的权重初始化为 3*3 矩阵。加权矩阵穿过我们图像，并产生 3*3 矩阵的卷积输出。权重覆盖我们的图像中的所有像素值至少一次，并且执行逐元素乘法。</p><p id="1989" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">当您查看元素乘法以获得卷积层时，另一个问题出现了，边缘处的像素值仅被覆盖一次。借助<strong class="lt iu">衬垫</strong>可以解决这个问题。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/150a600ffbbb7b6f3f76d0b8b7755966.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*O06nY1U7zoP4vE5AZEnxKA.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="http://www.michaelfxu.com/neural%20networks%20series/neural-networks-pt3-cnn/" rel="noopener ugc nofollow" target="_blank">2D 图像上的滤波器与填充的卷积</a></p></figure><p id="5477" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">当我们应用填充时，图像的大小保持不变。类似于<a class="ae ky" href="https://en.wikipedia.org/wiki/Multilayer_perceptron" rel="noopener ugc nofollow" target="_blank"><strong class="lt iu">【MLP】</strong></a><strong class="lt iu"/>学习权重，即最小化<strong class="lt iu">损失函数</strong>或帮助模型正确预测图像。我们不会在实际应用中只使用一个滤镜，滤镜数量的使用会影响<strong class="lt iu">旋绕层</strong>的深度。卷积输出的深度取决于我们使用的<strong class="lt iu">滤波器</strong>的数量。</p><h1 id="ca7e" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated"><strong class="ak">彩色图像的卷积层:</strong></h1><p id="3b7a" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">每幅彩色图像都可以用红色<strong class="lt iu">、蓝色</strong>和绿色<strong class="lt iu">的组合来表示。我们把它分成三层，并遵循同样的程序应用于灰度图像的情况。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/f92c45c5dbbe87410d078d3c5a03bc00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*D9swJVEhR0Ytq5lxzvr3tA.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" rel="noopener" target="_blank" href="/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53">用 3x3x3 内核对彩色图像矩阵进行卷积运算</a></p></figure><h1 id="b3c1" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated"><strong class="ak">汇集层:</strong></h1><p id="f7ad" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">池化的唯一目的是减小图像的大小。<strong class="lt iu">大多数情况下首选最大池</strong>。池在每个层上独立运行，因此卷积层的深度保持不变。您可以观察到我们一次应用两个<strong class="lt iu">步长</strong>。尺寸随着<strong class="lt iu">步数</strong>的增加而减小。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi gj"><img src="../Images/5b68cec644588cf86ab8bae268796260.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*WvHC5bKyrHa7Wm3ca-pXtg.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Gif 由<a class="ae ky" href="https://developers.google.com/machine-learning/practica/image-classification/convolutional-neural-networks" rel="noopener ugc nofollow" target="_blank">谷歌开发者</a></p></figure><h1 id="b0ed" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated"><strong class="ak">输出层:</strong></h1><p id="0180" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们的最终目标是预测一幅图像是否属于某个特定的类别。但是卷积层给了我们一个 3 D 激活图，使用卷积层不容易获得输出类，所以我们需要将其展平以产生所需数量的输出类。进行前向和反向传播以减少损耗。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/180e3047f024100ee1559ba1a3f649cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HcqCUAcTLqdVUHYXNeI5_A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://www.researchgate.net/figure/Example-CNN-architecture_fig3_322957424" rel="noopener ugc nofollow" target="_blank">研究门</a></p></figure><p id="37e6" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">正如我们可以观察到的，我们在开始时应用<strong class="lt iu">卷积</strong>以从中提取有用的特征，随后是<strong class="lt iu">最大汇集</strong>以减小图像的大小，随后是<strong class="lt iu">展平</strong>，最后输出预测图像属于特定类别的概率。</p><h1 id="c962" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated"><strong class="ak">使用 CNN 对图像进行分类:(代码)</strong></h1><p id="e654" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">五个漫威角色被选中，分别是黑寡妇、钢铁侠、雷神、美国队长和绿巨人。按照<strong class="lt iu"> 70: 30 </strong>的比例划分训练和测试装置，并观察性能。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/e5b1a83acf913eaf22d07cb55987813d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*9hs41FxiQnBI0-yT0nMbLw.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">钢铁侠(来源:<a class="ae ky" href="https://in.pinterest.com/pin/AYIgZDx6HmT1VOIiLXVWR6p1f9eEVX1ZTjCn8_PcAAeEZtG6PH_HmUg/" rel="noopener ugc nofollow" target="_blank"> Pinterest </a></p></figure><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="e29c" class="ob la it nx b gy oc od l oe of">from zipfile import ZipFile<br/>filename= "marvel.zip"<br/>with ZipFile(filename,'r')as zip:<br/>zip.extractall()</span></pre><p id="4803" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">您可以忽略前三个块，因为它处理图像加载和导入依赖项。由 5 个漫威角色组成的 zip 文件在上面的代码块中被加载和提取。</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="b535" class="ob la it nx b gy oc od l oe of">#Importing<br/>import os<br/>import numpy as np<br/>import glob<br/>import shutil<br/>import matplotlib.pyplot as plt<br/>import tensorflow as tf<br/>from tensorflow.keras.models import Sequential<br/>from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D<br/>from tensorflow.keras.preprocessing.image import ImageDataGenerator<br/>base_dir = os.path.join(os.path.dirname(filename), 'marvel')</span></pre><p id="23e7" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">所有必需的依赖项都会被导入，如果在导入这些依赖项时出现错误，您必须安装它。使用 pip 安装(Jupyter 笔记本)</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="4e80" class="ob la it nx b gy oc od l oe of"># Accessing the images and setting 0.7 of images for training and the rest for testing</span><span id="bd02" class="ob la it nx b gy og od l oe of">classes=['Black Widow','Captain America','Hulk','Iron Man','Thor']<br/>for m in classes:<br/>img_path = os.path.join(base_dir, m)<br/>images = glob.glob(img_path + '/*.jpg')<br/>num_train = int(round(len(images)*0.7))<br/>train, val = images[:num_train], images[num_train:]</span><span id="7f84" class="ob la it nx b gy og od l oe of"># Creating separate directories for training data</span><span id="b037" class="ob la it nx b gy og od l oe of">for t in train:<br/>if not os.path.exists(os.path.join(base_dir, 'train', m)):<br/>os.makedirs(os.path.join(base_dir, 'train', m))<br/>shutil.move(t, os.path.join(base_dir, 'train', m))</span><span id="25a7" class="ob la it nx b gy og od l oe of"># Creating separate directories for validating data</span><span id="5ad3" class="ob la it nx b gy og od l oe of">for v in val:<br/>if not os.path.exists(os.path.join(base_dir, 'val', m)):<br/>os.makedirs(os.path.join(base_dir, 'val', m))<br/>shutil.move(v, os.path.join(base_dir, 'val', m))</span></pre><p id="756c" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">在上面的代码块中，为训练和验证数据创建了单独的目录。训练和验证数据按照<strong class="lt iu"> 70:30 </strong>的比例分割。所有的图像扩展名都被转换成<strong class="lt iu"> jpg </strong>。</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="bd42" class="ob la it nx b gy oc od l oe of">train_dir = os.path.join(base_dir, 'train')<br/>val_dir = os.path.join(base_dir, 'val')</span></pre><p id="9748" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">为培训和验证创建了两个目录。</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="2a93" class="ob la it nx b gy oc od l oe of"># Setting batch size and a constant image shape</span><span id="8a17" class="ob la it nx b gy og od l oe of">batch_size = 130</span><span id="1ed4" class="ob la it nx b gy og od l oe of">IMG_SHAPE = 150</span><span id="ae8f" class="ob la it nx b gy og od l oe of"># Rescaling the images so all the values lie between 0 and 1 and applying horizontal flip and training the data</span><span id="eb38" class="ob la it nx b gy og od l oe of">image_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)</span><span id="9387" class="ob la it nx b gy og od l oe of">train_data_gen = image_gen.flow_from_directory(</span><span id="6725" class="ob la it nx b gy og od l oe of">batch_size=batch_size,</span><span id="c3a5" class="ob la it nx b gy og od l oe of">directory=train_dir,</span><span id="2879" class="ob la it nx b gy og od l oe of">shuffle=True,</span><span id="35d3" class="ob la it nx b gy og od l oe of">target_size=(IMG_SHAPE,IMG_SHAPE)</span><span id="9a1f" class="ob la it nx b gy og od l oe of">)</span><span id="9768" class="ob la it nx b gy og od l oe of"># Rescaling the images so all the values lie between 0 and 1 and rotating and training the data</span><span id="8b25" class="ob la it nx b gy og od l oe of">image_gen = ImageDataGenerator(rescale=1./255, rotation_range=45)</span><span id="888c" class="ob la it nx b gy og od l oe of">train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,</span><span id="1013" class="ob la it nx b gy og od l oe of">directory=train_dir,</span><span id="6ed9" class="ob la it nx b gy og od l oe of">shuffle=True,</span><span id="9439" class="ob la it nx b gy og od l oe of">target_size=(IMG_SHAPE, IMG_SHAPE))</span><span id="1032" class="ob la it nx b gy og od l oe of">#Rescaling and zooming the data</span><span id="fc4d" class="ob la it nx b gy og od l oe of">image_gen_train = ImageDataGenerator(</span><span id="3ab3" class="ob la it nx b gy og od l oe of">rescale=1./255,</span><span id="212e" class="ob la it nx b gy og od l oe of">rotation_range=45,</span><span id="36ab" class="ob la it nx b gy og od l oe of">width_shift_range=.15,</span><span id="88cc" class="ob la it nx b gy og od l oe of">height_shift_range=.15,</span><span id="fa6b" class="ob la it nx b gy og od l oe of">horizontal_flip=True,</span><span id="29e1" class="ob la it nx b gy og od l oe of">zoom_range=0.5</span><span id="bc5e" class="ob la it nx b gy og od l oe of">)</span><span id="4288" class="ob la it nx b gy og od l oe of">train_data_gen = image_gen_train.flow_from_directory(</span><span id="f9e8" class="ob la it nx b gy og od l oe of">batch_size=batch_size,</span><span id="14e9" class="ob la it nx b gy og od l oe of">directory=train_dir,</span><span id="c38b" class="ob la it nx b gy og od l oe of">shuffle=True,</span><span id="dd91" class="ob la it nx b gy og od l oe of">target_size=(IMG_SHAPE,IMG_SHAPE),</span><span id="451d" class="ob la it nx b gy og od l oe of">class_mode='sparse'</span><span id="3d72" class="ob la it nx b gy og od l oe of">)</span></pre><p id="eae4" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">由于收集的图像大小不同，因此对图像进行<strong class="lt iu">调整</strong>大小。选择 150 * 150 的图像尺寸。图像的像素值范围从<strong class="lt iu"> 0 到 255，</strong>为了提供更好的结果，像素值被<strong class="lt iu">重新缩放</strong>，因此所有值都位于 0 和 1 之间。不同的技术如<strong class="lt iu">水平翻转</strong>、<strong class="lt iu">缩放</strong>、<strong class="lt iu">旋转</strong>都是在现有的一组图像上进行<strong class="lt iu"> </strong>。</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="f55b" class="ob la it nx b gy oc od l oe of">image_gen_val = ImageDataGenerator(rescale=1./255)</span><span id="e193" class="ob la it nx b gy og od l oe of">val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,</span><span id="47fe" class="ob la it nx b gy og od l oe of">directory=val_dir,</span><span id="180a" class="ob la it nx b gy og od l oe of">target_size=(IMG_SHAPE, IMG_SHAPE),</span><span id="2474" class="ob la it nx b gy og od l oe of">class_mode='sparse')</span><span id="2ed8" class="ob la it nx b gy og od l oe of">model = Sequential()</span><span id="05cb" class="ob la it nx b gy og od l oe of">model.add(Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_SHAPE,IMG_SHAPE, 3)))</span><span id="8a4b" class="ob la it nx b gy og od l oe of">model.add(MaxPooling2D(pool_size=(2, 2)))</span><span id="1e7a" class="ob la it nx b gy og od l oe of">model.add(Conv2D(32, 3, padding='same', activation='relu'))</span><span id="6b38" class="ob la it nx b gy og od l oe of">model.add(MaxPooling2D(pool_size=(2, 2)))</span><span id="0237" class="ob la it nx b gy og od l oe of">model.add(Conv2D(64, 3, padding='same', activation='relu'))</span><span id="6aa2" class="ob la it nx b gy og od l oe of">model.add(MaxPooling2D(pool_size=(2, 2)))</span><span id="c8b5" class="ob la it nx b gy og od l oe of"># Adding dropout to turn down some neurons</span><span id="a4ce" class="ob la it nx b gy og od l oe of">model.add(Flatten())</span><span id="48be" class="ob la it nx b gy og od l oe of">model.add(Dropout(0.2))</span><span id="5dcc" class="ob la it nx b gy og od l oe of">model.add(Dense(512, activation='relu'))</span><span id="e916" class="ob la it nx b gy og od l oe of">model.add(Dropout(0.2))</span><span id="0d00" class="ob la it nx b gy og od l oe of">model.add(Dense(5, activation='softmax'))</span></pre><p id="b865" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">卷积和最大池应用于数据集，在将其发送到输出层之前，模型被<strong class="lt iu">展平</strong>。剔除用于防止图像的<strong class="lt iu">过拟合</strong>。</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="c47f" class="ob la it nx b gy oc od l oe of">model.compile(optimizer='adam',</span><span id="21df" class="ob la it nx b gy og od l oe of">loss='sparse_categorical_crossentropy',</span><span id="f42b" class="ob la it nx b gy og od l oe of">metrics=['accuracy'])</span><span id="d527" class="ob la it nx b gy og od l oe of">epochs = 120</span><span id="748c" class="ob la it nx b gy og od l oe of">history = model.fit_generator(</span><span id="5634" class="ob la it nx b gy og od l oe of">train_data_gen,</span><span id="6a10" class="ob la it nx b gy og od l oe of">steps_per_epoch=int(np.ceil(train_data_gen.n / float(batch_size))),</span><span id="8de7" class="ob la it nx b gy og od l oe of">epochs=epochs,</span><span id="b10f" class="ob la it nx b gy og od l oe of">validation_data=val_data_gen,</span><span id="d004" class="ob la it nx b gy og od l oe of">validation_steps=int(np.ceil(val_data_gen.n / float(batch_size)))</span><span id="46f3" class="ob la it nx b gy og od l oe of">)</span></pre><p id="e0cd" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">模型<strong class="lt iu">编译</strong>观察性能。您可以使用<strong class="lt iu">超参数</strong>来获得最佳结果。</p><p id="6f7c" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">github(代码)的链接附在下面</p><div class="oh oi gp gr oj ok"><a href="https://github.com/VishnuBhaarath/Computervisionprojects/blob/master/Imageclassification.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd iu gy z fp op fr fs oq fu fw is bi translated">VishnuBhaarath/计算机视觉项目</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">permalink dissolve GitHub 是 4000 多万开发人员的家园，他们一起工作来托管和审查代码，管理…</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">github.com</p></div></div><div class="ot l"><div class="ou l ov ow ox ot oy ks ok"/></div></div></a></div></div></div>    
</body>
</html>