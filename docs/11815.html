<html>
<head>
<title>Digging deep into YOLO V3 - A hands-on guide Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深入了解 YOLO V3 -动手指南第 1 部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/digging-deep-into-yolo-v3-a-hands-on-guide-part-1-78681f2c7e29?source=collection_archive---------4-----------------------#2020-08-16">https://towardsdatascience.com/digging-deep-into-yolo-v3-a-hands-on-guide-part-1-78681f2c7e29?source=collection_archive---------4-----------------------#2020-08-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="1941" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">深度学习/实时对象检测</h2><div class=""/><div class=""><h2 id="48cc" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">让我们熟悉 YOLO v3 模型的尝试</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/0be191cfc59361be75d976212955e1aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*nFAPHBLrSGU9ZGV-.jpg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">https://www . good fon . com/wallpaper/zhivotnoe-gry Zun-zveriok-belka-priroda-mokh-voda-vodopoi . html</p></figure><p id="ac19" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">人工智能领域在过去几年里发生了巨大的变化，产生了许多新技术。计算机视觉就是这样一个领域，它的目的是训练机器阅读和解释视觉世界。</p><p id="a0a2" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">计算机视觉处理许多具有挑战性的用例，从图像分类到人脸识别。我今天要解决的一个挑战就是<em class="ma">物体检测</em>。</p><h1 id="19a4" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">什么是物体检测？</h1><p id="21fc" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">对象检测是一种包含两项任务的技术，即<em class="ma">对象分类</em>和<em class="ma">对象定位</em>。它是一个被训练来检测多类对象的存在和位置的模型。这可以用于静态图像，甚至实时视频。</p><h1 id="e41c" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">物体检测是如何工作的？</h1><p id="492b" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">对象检测定位对象并将其分类为不同的类别，并通过在其周围绘制边界框来对其进行定位。对象检测有许多使用案例。例如，自动驾驶汽车需要能够在驾驶时识别道路上的其他物体。阅读 X 射线的 AI 放射科医生需要能够定位病变(异常组织)。为了解决这些用例，许多最先进的算法被用于检测对象，例如 R-CNN、快速 R-CNN、更快 R-CNN、掩蔽 R-CNN、SSD、YOLO 等。但是我对今天的 YOLO 特别感兴趣。</p><p id="d85b" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">YOLO(你只看一次)被认为是最强大的对象检测算法之一。由约瑟夫·雷德蒙、桑托什·迪夫瓦拉、罗斯·吉斯克和阿里·法尔哈迪(2015)发明，迄今为止它已经有 4 个不同的版本，YOLO V4 是 2020 年 4 月发布的最新版本，但在这篇文章中，我们将重点关注 YOLOv3，并试图了解围绕它的所有宣传。除了 YOLO v3，我们还将使用最新版本的 Tensorflow，即谷歌在 2019 年 9 月发布的 TF 2.0。</p><h1 id="88c5" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">这个帖子是给谁的？</h1><p id="e79f" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">由于被隔离，这些天我有额外的时间，我决定使用 YOLO V3 探索对象检测，并在跳到最新的 YOLO 版本之前了解它的动态。我看到了很多文章，但大多数都解释了这个非常复杂的 YOLO v3 模型的高级架构和直接实现，这让我感到困惑。我在寻找更多的东西，并决定要理解每一行代码以及后台发生的事情。我偶然看到了伊桑·颜佳·李、阿尤什·卡图里亚和拉赫马德·萨德里的精彩文章，这些文章帮助我更好地理解了。还有什么比试着向别人解释更好的方法来确保我真的理解了某事，因此我写了这篇文章。</p><p id="8dac" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这篇文章是我对 YOLO V3 的理解，一个复杂的算法，一个用简单的语言表达的天真的尝试。</p><h1 id="50b7" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">先决条件</h1><p id="cf6f" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">这篇文章假设你是:</p><p id="7768" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja"> </strong>熟悉 Python 3</p><p id="c65a" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">很了解<a class="ae my" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>库</p><p id="9559" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">对卷积神经网络(CNN)和对象检测有基本的了解。</p><p id="4eca" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">对<a class="ae my" href="https://www.streamlit.io/" rel="noopener ugc nofollow" target="_blank"> Streamlit </a>有一个基本的了解，以及它是用来做什么的。</p><h1 id="335e" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">本教程的关键要点</h1><p id="5baf" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">本教程分为<strong class="lg ja"> <em class="ma">两个</em> </strong>部分。</p><p id="d577" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja"> <em class="ma">第 1 部分</em> </strong>解释了理解 YOLO v3 如何工作的架构和关键概念。</p><p id="3a38" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja"> <em class="ma">第 2 部分</em> </strong>从理解配置文件到能够创建用户界面以从用户处获取输入图像并在其上执行对象检测，开始着手实施该算法。</p><p id="4a7e" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">让我们首先了解一下 YOLO 是什么。</p><h1 id="bdab" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">YOLO——你只能看一次</h1><p id="0871" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">许多对象检测模型多次接收和处理图像，以便能够检测图像中存在的所有对象。但是 YOLO，顾名思义，只看物体一次。它对整个图像应用单次向前传递，并预测边界框及其类别概率。这使得 YOLO 成为超快速实时对象检测算法。</p><p id="946f" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">太多行话了，嗯？让我们一步步来理解。</p><h1 id="eb2a" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">YOLO V3</h1><p id="29b2" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">Yolo V3 是对前两个 Yolo 版本的改进，前两个版本更强大，但比前两个版本稍慢。该模型具有多尺度检测、更强的特征提取网络和损失函数的一些变化。</p><h2 id="6467" class="mz mc iq bd md na nb dn mh nc nd dp ml ln ne nf mn lr ng nh mp lv ni nj mr iw bi translated">网络体系结构</h2><p id="5586" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">为了在高层次上理解网络架构，我们将整个架构分为两大部分:<strong class="lg ja"> <em class="ma">特征提取器</em>和<em class="ma">特征检测器(多尺度检测器)</em> </strong>。图像首先被提供给特征提取器，该特征提取器提取特征嵌入，然后被传递给网络的特征检测器部分，该特征检测器部分吐出处理后的图像，该图像具有围绕检测到的类别的边界框。</p><p id="394d" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">让我们稍微深入一下这些组件。</p><h2 id="290c" class="mz mc iq bd md na nb dn mh nc nd dp ml ln ne nf mn lr ng nh mp lv ni nj mr iw bi translated">特征提取器</h2><p id="605d" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">以前的 YOLO 版本使用 Darknet-19(用 C 和 CUDA 编写的定制神经网络架构)作为特征提取器，顾名思义，它有 19 层。YOLO v2 在 Darknet-19 的基础上又增加了 11 层，使其架构达到 30 层。尽管如此，该算法在检测小对象时仍然面临着挑战，因为对输入图像进行了下采样，丢失了细粒度的特征。</p><p id="c4ff" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">YOLO V3 提出了一个更好的架构，其中使用的特征提取器是 YOLO v2、Darknet-53(在 ImageNet 上训练的网络)和残差网络(ResNet)的混合。该网络使用 53 个卷积层(因此被命名为 Darknet-53)，其中该网络由<strong class="lg ja">个连续的 3×3 和 1×1 卷积层</strong>构建，后跟一个<strong class="lg ja">跳过连接</strong>(由 ResNet 引入，以帮助激活通过更深的层传播，而不会出现梯度递减)。</p><p id="ba71" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">53 层暗网再叠加 53 层用于探测头，使得 YOLO v3 总共是一个<strong class="lg ja"> 106 层全卷积底层架构</strong>。从而导致大的架构，尽管与 YOLO v2 相比，使其稍慢，但同时提高了精度。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nk"><img src="../Images/67f8567275d2c20c98e6a96d4e14a486.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-Whes2CytS_v22Wx1LZ6RA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">这张图片是取自<a class="ae my" href="https://arxiv.org/pdf/1804.02767.pdf" rel="noopener ugc nofollow" target="_blank"> YOLOv3 的 darknet-53 架构:一个增量改进</a></p></figure><p id="2170" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">如果目标是像在 ImageNet 中那样执行分类，那么将添加平均池层、1000 个完全连接的层和 SoftMax 激活函数，如图所示，但是在我们的示例中，我们希望检测类和位置，因此我们将在提取器上附加一个检测头。探测头是多尺度探测头，因此，我们也需要在多个尺度上提取特征。</p><p id="00c0" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">一旦我们熟悉了高层架构，我们将在下一节更深入地了解这些层是如何工作的。</p><p id="b9f7" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">为了形象化多尺度提取器的样子，我举了一个 416x416 的图像的例子。层的跨度定义为<strong class="lg ja">比率，通过该比率对输入进行下采样，</strong>，因此在我们的情况下，三个比例将是<strong class="lg ja"> 52x52、26x26、</strong>和<strong class="lg ja"> 13x13 </strong>，其中 13x13 将用于较大的对象，26x26 和 52x52 将用于中等和较小的对象。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nl"><img src="../Images/9c17d197f8faa1c578eaadac14f1144d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zXBb8YHNxhK-TjSK1pnpgQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">416x416 图像的多尺度特征提取器</p></figure><h1 id="4695" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">多尺度检测器</h1><p id="9a76" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">YOLO v3 模型的一个重要特征是其多尺度检测器，这意味着对全卷积网络的最终输出的检测是通过在三个不同位置对三个不同大小的特征映射应用 1x1 检测核来完成的。内核的形状是<strong class="lg ja"><em class="ma">1</em>x<em class="ma">1</em>x<em class="ma">(B *(5+C))。</em> </strong></p><h1 id="3ba4" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">完整的网络架构</h1><p id="858f" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">Ayoosh Kathuria 制作了一个非常精细的图表，完美地解释了 YOLO v3 的完整架构(结合了提取器和检测器)。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nm"><img src="../Images/3971eb258a10908809ec69cf5da71f33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*DvRGcggiSgGlekij.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图来自<a class="ae my" rel="noopener" target="_blank" href="/yolo-v3-object-detection-53fb7d3bfe6b">https://towards data science . com/yolo-v3-object-detection-53 FB 7d 3 bfe 6 b</a></p></figure><p id="f4ca" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">如上图所示，我们以 416x416 的图像为例，进行检测的三个比例分别为第 82 层、第 94 层和第 106 层。</p><p id="1185" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">对于第一次检测，前 81 层被下采样，使得第 81 层具有 32 的跨距(如前所述，层的跨距被定义为对输入进行下采样的<strong class="lg ja">比率)</strong>，产生我们的大小为 13×13 的第一特征图，并且第一次检测是用 1×1 内核进行的，产生我们的大小为 13×13×255 的检测 3D 张量。</p><p id="5391" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">对于第二次检测，在向上采样到 26×26 的维度之前，第 79 层向前经过卷积层。该特征图然后与来自层 61 的特征图深度连接以形成新的特征图，该新的特征图在 1x1 卷积层的帮助下进一步与第 61 层融合。第二检测层在第 94 层，具有大小为 26×26×255 的 3D 张量。</p><p id="c077" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">对于最终(第三)检测层，遵循与第二检测相同的过程，其中第 91 层的特征图在与来自第 36 层的特征图深度连接和融合之前经历卷积层。在第 106 层使用大小为 52×52×255 的特征图进行最终检测。</p><p id="5c91" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">多尺度探测器用于确保小物体也能被探测到，这与 YOLO v2 不同，后者一直受到批评。与先前层连接的上采样层最终保留了有助于检测小对象的细粒度特征。</p><p id="843b" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">下一节将详细描述这个内核在我们的模型中的样子。</p></div><div class="ab cl nn no hu np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="ij ik il im in"><h1 id="a0ab" class="mb mc iq bd md me nu mg mh mi nv mk ml kf nw kg mn ki nx kj mp kl ny km mr ms bi translated">YOLO v3 的工作</h1><p id="88c8" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">YOLO v3 网络旨在预测每个对象的<strong class="lg ja"><em class="ma"/></strong><em class="ma">(候选对象的感兴趣区域)</em>以及该对象所属类别的<strong class="lg ja"> <em class="ma">概率</em> </strong>。</p><p id="dcca" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">为此，该模型将每个输入图像分成一个由单元组成的<em class="ma"> S </em> x <em class="ma"> S </em>网格，每个网格预测中心落在网格单元内的对象的<em class="ma"> B </em>边界框和<em class="ma"> C </em>类别概率。该论文指出，每个包围盒可以专门用于检测某一种对象。</p><p id="11dc" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">边界框<strong class="lg ja"><em class="ma">【B】</em></strong>与正在使用的<strong class="lg ja"> <em class="ma">锚点</em> </strong>的数量相关联。每个包围盒都有<strong class="lg ja"> 5+C </strong>属性，其中<strong class="lg ja">‘5’</strong>是指五个包围盒属性(例如:中心坐标(bx，by)、高度(bh)、宽度(bw)和置信度得分)<strong class="lg ja"> C </strong>是类的数量。</p><p id="8bad" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们将此图像传递到正向卷积网络的输出是一个三维张量，因为我们正在处理一个<em class="ma"> S </em> x <em class="ma"> S </em>图像。输出看起来像[ <strong class="lg ja"> <em class="ma"> S，S，B*(5+C) </em> </strong> ]。</p><p id="cdec" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">让我们用一个例子来更好地理解这一点。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nz"><img src="../Images/13d147f06b85ae2cddc60b88783a524e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vPkSlucTm2tZtTd8ID8RAw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图片来自<a class="ae my" href="https://machinelearningspace.com/yolov3-tensorflow-2-part-1/#nms-unique" rel="noopener ugc nofollow" target="_blank">https://machine learning space . com/yolo v3-tensor flow-2-part-1/# NMS-unique</a></p></figure><p id="b1de" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在上面的例子中，我们看到我们的输入图像被分成 13×13 个网格单元。现在，让我们来理解只取一个网格单元会发生什么。</p><p id="7804" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">由于 YOLO v3 的多尺度检测特征，在三个不同的地方应用三个不同大小的检测核，因此有 3 个盒子(即<em class="ma"> B=3 </em>)。YOLO v3 在具有 80 个对象类别或类的 COCO 数据集上被训练，因此<em class="ma"> C=80 </em>。</p><p id="3be3" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">因此，输出是前面提到的具有维度(13，13，3*(80+5))的 3d 张量。</p><h1 id="2069" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">锚箱</h1><p id="fa01" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">在检测物体的早期，科学家使用滑动窗口的概念，并在每个窗口上运行图像分类算法。很快他们意识到这没有意义，而且效率很低，所以他们转而使用 ConvNets，在一个镜头中运行整个图像。由于 ConvNet 输出特征值的方阵(例如 YOLO 的 13x13 或 26x26)，因此<strong class="lg ja">“网格”</strong>的概念出现了。我们将正方形特征矩阵定义为一个<em class="ma">网格</em>，但是当要检测的对象不是正方形时，真正的问题就来了。这些物体可以是任何形状(大部分是矩形)。因此，<strong class="lg ja">锚箱</strong>开始被使用。</p><p id="a667" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">锚定框是预定义的具有纵横比设置的框。甚至在训练之前，通过在整个数据集上运行<em class="ma"> K-means 聚类</em>来预先定义这些纵横比。这些锚定框锚定到网格单元并共享同一个质心。YOLO v3 每个检测秤使用<strong class="lg ja"> 3 个锚箱，总共<strong class="lg ja"> 9 个锚箱。</strong></strong></p><h1 id="78fc" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">非最大抑制</h1><p id="ae0f" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">在单次向前传递后，由于质心是相同的，预测的输出可能会有多个相同对象的边界框，但我们只需要一个最适合所有对象的边界框。</p><p id="af34" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">为此，我们可以使用一种称为非最大值抑制(NMS)的方法，该方法基本上在这些检测之后清除。我们可以定义一个特定的阈值作为这个 NMS 方法的约束，其中它将忽略置信度低于所述阈值的所有其他边界框，从而消除一些。但是这并不能消除所有的置信度，因此 NMS 的下一步将被执行，即按照降序排列包围盒的所有置信度，并选择得分最高的一个作为最适合该对象的置信度。然后，我们找到所有其他与具有最大置信度的边界框具有高并集交集(IOU)的框，并消除所有这些框。</p><p id="803b" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">现在我们已经知道了 YOLO v3 中使用的所有术语和架构，在下一部分<strong class="lg ja"> <em class="ma">(第 2 部分)</em> </strong>中，我们将深入研究实现。</p><p id="fb35" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">由于这是我第一次尝试写一篇中型文章，并试图阐明我的想法，我很乐意听到反馈的改进建议。</p><p id="a174" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja"> <em class="ma">第二部即将上映……</em></strong></p><h1 id="953f" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">参考</h1><ol class=""><li id="8683" class="oa ob iq lg b lh mt lk mu ln oc lr od lv oe lz of og oh oi bi translated">约洛夫 3:增量改进<a class="ae my" href="https://arxiv.org/pdf/1804.02767.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1804.02767.pdf</a></li><li id="a855" class="oa ob iq lg b lh oj lk ok ln ol lr om lv on lz of og oh oi bi translated"><a class="ae my" href="https://towardsdatascience.com/@ethanyanjiali?source=post_page-----9e3d2666280e----------------------" rel="noopener" target="_blank">伊桑李</a><a class="ae my" rel="noopener" target="_blank" href="/dive-really-deep-into-yolo-v3-a-beginners-guide-9e3d2666280e">https://towards data science . com/dive-really-deep-into-yolo-v3-a-初学者指南-9e3d2666280e </a></li><li id="b8c2" class="oa ob iq lg b lh oj lk ok ln ol lr om lv on lz of og oh oi bi translated"><a class="ae my" href="https://towardsdatascience.com/@ayoosh?source=post_page-----53fb7d3bfe6b----------------------" rel="noopener" target="_blank">Ayoosh Kathuria</a><a class="ae my" rel="noopener" target="_blank" href="/yolo-v3-object-detection-53fb7d3bfe6b">https://towardsdatascience . com/yolo-v3-object-detection-53 FB 7d 3 bfe 6 b</a></li><li id="c27d" class="oa ob iq lg b lh oj lk ok ln ol lr om lv on lz of og oh oi bi translated">rahmad Sadli<a class="ae my" href="https://mc.ai/the-beginners-guide-to-implementing-yolo-v3-in-tensorflow-2-0-part-1/" rel="noopener ugc nofollow" target="_blank">https://MC . ai/the-初学者-实施指南-yolo-v3-in-tensor flow-2-0-part-1/</a></li><li id="862b" class="oa ob iq lg b lh oj lk ok ln ol lr om lv on lz of og oh oi bi translated"><a class="ae my" href="https://machinelearningmastery.com/object-recognition-with-deep-learning/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/object-recognition-with-deep-learning/</a></li></ol></div></div>    
</body>
</html>