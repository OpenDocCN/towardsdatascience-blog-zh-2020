<html>
<head>
<title>AI for Textiles — Convolutional Neural Network Based Fabric Structure Classifier</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">纺织品人工智能——基于卷积神经网络的织物结构分类器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ai-for-textiles-convolutional-neural-network-based-fabric-structure-classifier-c0db5433501d?source=collection_archive---------25-----------------------#2020-05-16">https://towardsdatascience.com/ai-for-textiles-convolutional-neural-network-based-fabric-structure-classifier-c0db5433501d?source=collection_archive---------25-----------------------#2020-05-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/318d0718c85a1db5bce3bd89172cc9a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zyhAbLGe-LTVwWw11wLXyQ.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">来源:<a class="ae kf" href="https://pixabay.com/users/AllNikArt-65709/" rel="noopener ugc nofollow" target="_blank"> AllNikArt </a>，via <a class="ae kf" href="https://pixabay.com/en/labrador-breed-dogs-animal-animals-805838/" rel="noopener ugc nofollow" target="_blank"> pixabay </a></p></figure><p id="c0b4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi le translated"><span class="l lf lg lh bm li lj lk ll lm di"> T </span>如今，深度学习被广泛用于各种人工智能应用，包括面部识别、自然语言处理等。在纺织工程领域也有可能找到深度学习的许多应用，计算机视觉已经在这种背景下广泛使用。本文描述了开发卷积神经网络用于从织物表面的输入图像识别织物结构的方法。开发的模型能够成功地区分针织物和机织物结构。</p><p id="a077" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于针织和机织结构的结构差异，它们很容易区分。针织物的线圈结构和机织物上交织的经纱和纬纱使得这两种结构易于识别。如果通过显示一组标记的针织和机织织物图像，可以训练神经网络来学习织物结构固有的这些特征，那么神经网络将能够正确地区分针织和机织织物图像，这是它以前从未见过的。为了实现这一点，决定使用卷积神经网络(CNN)架构，因为CNN能够有效地从图像中提取特征。</p><p id="d8bd" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该模型是使用python和TensorFlow框架以及Keras API开发的。为了获得用于训练神经网络的数据集，使用了在<a class="ae kf" href="https://ibug.doc.ic.ac.uk/resources/fabrics/" rel="noopener ugc nofollow" target="_blank"><em class="ln">【https://ibug.doc.ic.ac.uk/resources/fabrics/】</em></a>上可用的图像的开源数据库，该数据库最初是为一项研究而准备的(<em class="ln"> C. Kampouris，S. Zafeiriou，A. Ghosh，S. Malassiotis，</em> <a class="ae kf" href="https://ibug.doc.ic.ac.uk/media/uploads/documents/1119.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="ln">使用微观几何和反射率的细粒度材料分类</em> </a> <em class="ln">，第14届欧洲计算机视觉会议，阿姆斯特丹，2016年</em>)。该原始数据集中的织物图像根据材料类型(即尼龙、聚酯、棉等)进行标记。).因此，在训练之前，从该原始数据集中选择总共4300幅图像，并根据织物结构(即，针织和机织)对其进行人工标记。在4300幅图像中，4200幅用作训练数据，而剩余的100幅用作验证数据。(尽管验证数据集太小，但大多数图像用于训练以避免过度拟合)。训练和验证数据集都由相同数量的针织和机织织物图像组成。</p><p id="69b2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最初，决定使用迁移学习技术。因此，使用VGG16架构(<a class="ae kf" href="https://arxiv.org/abs/1409.1556" rel="noopener ugc nofollow" target="_blank"><em class="ln">https://arxiv.org/abs/1409.1556</em></a>)和预训练的权重。只有最终输出层被更改为具有两个单元的softmax层。使用迁移学习，训练最终输出层，保持其他层的权重不变，经过100个历元后，训练和验证准确率分别达到88%和83%。</p><p id="b996" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了改进模型，原始VGG16架构的最后三个密集层被移除，并由几个稍微修改的密集层取代。使用迁移学习，这些新增加的层被训练，同时保持其余层的权重不变。该模型最高训练准确率达到99.81%，验证准确率达到91%。该模型现在明显过度适合训练数据。</p><p id="a63d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了克服过拟合问题，再次训练模型的最终密集层，在最后两个密集层之间添加一个丢弃层，并增加数据。然而，在20个时期之后，该模型达到了84.55%的训练准确度和84%的验证准确度，并且似乎没有进一步改善。过拟合问题被克服了，但是现在模型有很高的偏差。</p><p id="b688" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，决定训练整个模型，而不是使用迁移学习。然而，由于可用的训练数据量有限，因此决定降低原始VGG16架构的复杂性。因此，移除了原始VGG16架构的第五个卷积块，并添加了一个平均池层，之后是两个密集层。为了避免过度拟合，数据增强使用了几种增强技术，如旋转、垂直翻转、缩放和不同的亮度水平(<a class="ae kf" href="https://keras.io/api/preprocessing/image/" rel="noopener ugc nofollow" target="_blank"><em class="ln">【https://keras.io/api/preprocessing/image/】</em></a>)。输入图像的旋转是重要的，因为它允许模型识别针织物图像的纵行和机织织物图像中的经纱和纬纱，由于捕获图像时发生的变化，它们在不同的方向上取向。放大图像使模型能够清楚地识别针织物的线圈结构和机织物的交织图案。</p><figure class="lp lq lr ls gt ju gh gi paragraph-image"><div class="gh gi lo"><img src="../Images/ff3e0597ccc480ced7fbcaf2afa5206e.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*Or32JTBXaSGDyys1VhFaeQ.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">模型摘要</p></figure><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="7d00" class="ly lz it lu b gy ma mb l mc md">import numpy as np;<br/>import keras;<br/>from keras.layers import AveragePooling2D;<br/>from keras. layers.core import Dense, Flatten;<br/>from keras.optimizers import Adam;<br/>from keras.metrics import binary_crossentropy;<br/>from keras.preprocessing.image import ImageDataGenerator;<br/>from keras.models import Model;<br/>from keras.applications import imagenet_utils;<br/>from keras.callbacks import ModelCheckpoint;</span><span id="2c57" class="ly lz it lu b gy me mb l mc md">train_data_path = '/content/drive/My Drive/fabric_data/Train';<br/>test_data_path = '/content/drive/My Drive/fabric_data/Test';</span><span id="aff0" class="ly lz it lu b gy me mb l mc md">train_data = ImageDataGenerator(rescale = 1.0/255, <br/>                                rotation_range = 180, <br/>                                vertical_flip = True, <br/>                                horizontal_flip = True, <br/>                                brightness_range = [0.5, 1.5], <br/>                                zoom_range = [1, 1.5]);</span><span id="d5a6" class="ly lz it lu b gy me mb l mc md">train_generator = train_data.flow_from_directory(directory = train_data_path, <br/>target_size = (224,224), <br/>classes = ['Woven','Knitted'], <br/>batch_size = 70, <br/>shuffle = True);</span><span id="7e0c" class="ly lz it lu b gy me mb l mc md">test_data = ImageDataGenerator(rescale = 1.0/255);</span><span id="7977" class="ly lz it lu b gy me mb l mc md">test_generator = test_data.flow_from_directory(directory = test_data_path, target_size = (224,224), classes = ['Woven', 'Knitted'], batch_size = 50, shuffle = False);</span><span id="5d07" class="ly lz it lu b gy me mb l mc md">vgg16_model = keras.applications.VGG16();<br/>x = vgg16_model.layers[-9].output;</span><span id="e297" class="ly lz it lu b gy me mb l mc md">x = AveragePooling2D(pool_size = (2,2))(x);<br/>x = Flatten(name="flatten")(x);<br/>x = Dense(128, activation = 'relu')(x);<br/>x = Dense(2, activation = 'softmax')(x);</span><span id="e729" class="ly lz it lu b gy me mb l mc md">model = Model(inputs = vgg16_model.input, outputs = x);</span><span id="f210" class="ly lz it lu b gy me mb l mc md">model.compile(optimizer = Adam(lr=0.00001, clipvalue = 0.5, clipnorm = 1), loss = 'binary_crossentropy', metrics = ['accuracy']);</span><span id="58b7" class="ly lz it lu b gy me mb l mc md">print("\nTraining.....");</span><span id="9109" class="ly lz it lu b gy me mb l mc md">checkpoint = ModelCheckpoint(filepath = '/content/drive/My Drive/new_fab_model.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max');</span><span id="29b3" class="ly lz it lu b gy me mb l mc md">history = model.fit_generator(generator = train_generator, <br/>                              steps_per_epoch = 60, <br/>                              validation_data = test_generator, <br/>                              validation_steps = 2, <br/>                              epochs = 250, <br/>                              verbose = 1, <br/>                              callbacks = [checkpoint]);</span></pre><p id="cd94" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用Adam优化器以0.00001的学习率从头开始训练整个模型。经过50个时期的训练，该模型达到了98%的训练准确率和97%的验证准确率。</p><figure class="lp lq lr ls gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mf"><img src="../Images/1426a287d482d9fb7c232b9f92fa01fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*43jXqSikO3QJxYjol01PPw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">达到培训和验证的准确性</p></figure><p id="2dc6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于使用的验证数据集太小(只有100个图像)，为了进一步验证模型在现实世界中的性能，使用训练的模型测试了不同的100个织物图像的集合。该模型正确预测了其中的97幅图像。这个新测试样本的意义在于，图像是从与原始训练和验证数据完全不同的分布中获取的。一组图像是从互联网上下载的(3D针织物图像)。使用扫描仪扫描另一组图像，图像被放大50%，裁剪并调整为224x224像素，以输入神经网络。使用光度立体传感器捕获原始训练和验证数据集的织物图像(<em class="ln"> C. Kampouris，S. Zafeiriou，A. Ghosh，S. Malassiotis，</em> <a class="ae kf" href="https://ibug.doc.ic.ac.uk/media/uploads/documents/1119.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="ln">使用微观几何和反射率的细粒度材料分类</em> </a> <em class="ln">，第14届欧洲计算机视觉会议，阿姆斯特丹，2016) </em>。</p><figure class="lp lq lr ls gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mg"><img src="../Images/a7b8738fc92a53aff465131cf0b47b96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XHo2wacECfPALwPhCYGTsA.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">由训练模型预测的织物结构</p></figure><p id="b24d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">应该注意的是，模型的训练数据仅由纬编针织物组成。只有单面针织结构的技术正面图像可用，不包括3D针织结构。然而，经过训练的模型能够正确预测3D缆线编织结构，并且它也正确预测一些单面针织物的技术背面图像。训练集中的大多数织物图像由平纹和斜纹结构组成。</p><p id="a65c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">被训练的模型的中间激活被可视化以理解卷积如何从织物图像中学习特征。针织织物图像作为输入输入到模型中，相应的层激活如下所示。请注意，这里只显示了几层的一些卷积。</p><figure class="lp lq lr ls gt ju gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/bf6d9793cb50fd440bedb21900129811.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*fgxlcnogu_riHAyw1AD_bQ.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">输入图像(作者提供的照片)</p></figure><figure class="lp lq lr ls gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mi"><img src="../Images/781f86ad429c81ac55330ca705da03c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cLCVcRHL-HzpBwn5uZIBag.png"/></div></div></figure><figure class="lp lq lr ls gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mj"><img src="../Images/32990065b1ce91da4ac6dee15395e0b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*85rFWo_WqWeR77E81KIBjg.png"/></div></div></figure><figure class="lp lq lr ls gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mk"><img src="../Images/302eb84c00f1d7f691c60fe09a9dc1fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M56gyT5tCnhaW8sjVlWKkw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">对应于输入图像的模型的层激活(仅示出了来自一组选定层的一些卷积)</p></figure><p id="d066" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">模型的初始层似乎在识别图像的最基本特征，例如水平和垂直边缘。一些盘旋已经确定了针织物表面纵行的边缘。在中间层，卷积开始提取更精细的细节，如针织线圈的形状，最大汇集层突出了这些特征。最深层的激活很难从视觉上解释，因为根据模型在训练中所学的，它们正在编码特定于织物结构的信息。</p><p id="7d8e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">应该注意的是，该模型仅用于学术目的。该模型只能区分两种主要的织物结构(即针织和机织)。区分几种织物结构变化(如单面针织物、罗纹织物和联锁织物)将是一项更有趣的任务，但由于无法获得此类不同类型织物结构的大型数据集，该模型仅限于区分针织和机织织物结构。然而，有了足够的数据，也可以训练一个模型来完成这样的任务。还应该注意，通过使用不同的神经网络结构和更多的数据，有可能进一步改进该模型。</p></div></div>    
</body>
</html>