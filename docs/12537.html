<html>
<head>
<title>NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NeRF:将场景表示为用于视图合成的神经辐射场</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/nerf-representing-scenes-as-neural-radiance-fields-for-view-synthesis-ef1e8cebace4?source=collection_archive---------14-----------------------#2020-08-29">https://towardsdatascience.com/nerf-representing-scenes-as-neural-radiance-fields-for-view-synthesis-ef1e8cebace4?source=collection_archive---------14-----------------------#2020-08-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9017" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">ECCV-2020 口头论文评论</h2></div><p id="aa55" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从 2D 图像绘制三维模型是计算机视觉领域的一个挑战性问题。即使我们对每个图像都有摄像机位置监控，以前的 3D 渲染模型也不足以在实践中使用。在 ECCV 被选为口头论文的 NeRF 提出了一种最先进的方法，该方法利用 2D 图像及其相应的相机位置来构建 3D 模型。</p><figure class="lb lc ld le gt lf"><div class="bz fp l di"><div class="lg lh l"/></div><p class="li lj gj gh gi lk ll bd b be z dk translated">视频 1。NeRF 作者的官方视频，经常被作者推荐观看。</p></figure><h1 id="b56b" class="lm ln iq bd lo lp lq lr ls lt lu lv lw jw lx jx ly jz lz ka ma kc mb kd mc md bi translated">术语</h1><ol class=""><li id="bfe5" class="me mf iq kh b ki mg kl mh ko mi ks mj kw mk la ml mm mn mo bi translated"><strong class="kh ir">射线</strong>:从摄像机中心连接的线，由摄像机位置参数决定，在特定方向上，由摄像机角度参数决定。</li><li id="d9d1" class="me mf iq kh b ki mp kl mq ko mr ks ms kw mt la ml mm mn mo bi translated"><strong class="kh ir">颜色</strong>:每个 3D 体所具有的 RGB 值。</li><li id="39a5" class="me mf iq kh b ki mp kl mq ko mr ks ms kw mt la ml mm mn mo bi translated"><strong class="kh ir">体积密度</strong>:决定它对最终色彩决定的影响程度。</li><li id="1fab" class="me mf iq kh b ki mp kl mq ko mr ks ms kw mt la ml mm mn mo bi translated"><strong class="kh ir">光线颜色</strong>:我们跟随光线时可以观察到的 RGB 值。公式 1 给出了正式定义。</li></ol><h1 id="5a51" class="lm ln iq bd lo lp lq lr ls lt lu lv lw jw lx jx ly jz lz ka ma kc mb kd mc md bi translated">什么是 NeRF？</h1><p id="792a" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mu kq kr ks mv ku kv kw mw ky kz la ij bi translated">NeRF 是第一篇介绍神经场景表示的论文。它有利于渲染真实物体的高分辨率真实感新视图。本文的主要思想是预测沿光线的颜色值和不透明度值，这由五个外部相机参数(3 个相机位置，两个相机角度)确定。</p><p id="b3cc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最终，使用估计的颜色和不透明度，NeRF 确定光线的预期颜色(等式 1)。对于实际实施，NeRF 将整数近似为有限和(等式 2)，称为<strong class="kh ir">分层采样</strong>。实验中的样本数为 64，128，256。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi mx"><img src="../Images/ea7eb30387505804bce001acdeb8bb4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gtPuY_sS3J8zIU6mj_gSyA.png"/></div></div><p class="li lj gj gh gi lk ll bd b be z dk translated">等式 1。输入光线的预期颜色。</p></figure><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi ne"><img src="../Images/fb4c5e541de07c693f2f5cb29c717f48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zC2rAuyRIHivjwrcS1-gjg.png"/></div></div><p class="li lj gj gh gi lk ll bd b be z dk translated">等式 2。方程式 1 的近似值。</p></figure><p id="1ed1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">NeRF 架构不需要保留每个特性；因此，NeRF 是由 MLP 而不是 CNN 组成的。它还使用两种技术来提高其性能:<strong class="kh ir">位置编码</strong>和<strong class="kh ir">分层体积采样</strong>。</p><h1 id="d6a5" class="lm ln iq bd lo lp lq lr ls lt lu lv lw jw lx jx ly jz lz ka ma kc mb kd mc md bi translated">位置编码</h1><p id="393f" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mu kq kr ks mv ku kv kw mw ky kz la ij bi translated">NeRF 没有使用五个简单的相机参数，而是使用位置编码，这种编码经常在 NLP(自然语言处理)中使用。在颜色和几何图形的高频变化中，使用简单输入通常表现不佳。位置编码便于网络通过容易地将输入映射到更高维空间来优化参数。<strong class="kh ir"> NeRF 表明，使用高频函数映射原始输入能够更好地拟合包含高频变化的数据。</strong>消融研究是这一论点的证据(表 1)。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi nf"><img src="../Images/42bfc8349b42feda4f9e6a545ad5ff0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DADqjLIHJAsE8u3WPx2TAA.png"/></div></div><p class="li lj gj gh gi lk ll bd b be z dk translated">等式 3。位置编码。</p></figure><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi ng"><img src="../Images/1fd9990632e59a3a0ace63c7cad303cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q3fLvJFfoUdtVhsXeeTNXw.png"/></div></div><p class="li lj gj gh gi lk ll bd b be z dk translated">图一。NeRF 的整体架构，它使用位置编码而不是简单的输入。</p></figure><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi nh"><img src="../Images/b2e9bdbd65dc4f38765fe35378936196.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bcHd7RtWi_w5TBvTa4VWNA.png"/></div></div><p class="li lj gj gh gi lk ll bd b be z dk translated">表 1。位置编码的效果。使用位置编码提高了每个指标的性能。</p></figure><h1 id="8d97" class="lm ln iq bd lo lp lq lr ls lt lu lv lw jw lx jx ly jz lz ka ma kc mb kd mc md bi translated">分层体积取样</h1><p id="ce86" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mu kq kr ks mv ku kv kw mw ky kz la ij bi translated">NeRF 提出了一个层次结构。整个网络架构由两个网络组成:一个是<strong class="kh ir">粗网</strong>，另一个是<strong class="kh ir">细网</strong>。</p><p id="4383" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">粗糙网络使用 N_c 个采样点来评估光线的预期颜色。顾名思义，它首先从粗采样开始优化。等式 4 是粗略网络的正式定义。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi ni"><img src="../Images/032d7371e91e479ecfb1290db2d7ac31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7gjVrg4RQf5MYl4FSdPuCA.png"/></div></div><p class="li lj gj gh gi lk ll bd b be z dk translated">等式 4。粗糙网络</p></figure><p id="95a8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">精细网络使用 N_c + N_f = N 个采样点来评估光线的预期颜色。这个等式与等式 2 相同。表 2 显示了关于等级结构影响的消融研究。然而，依我拙见，表 2 中的(4)和(7)之间的比较并不公平。是因为(4)和(7)之间的 N_c + N_f 不一样。如果(4)中的 N_f 值是 192(=128 + 64)，这可能是一个更公平的比较。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi nj"><img src="../Images/ac2cabda3bcc968055bda60bfb4cf3d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B3nLlBMQA9rqjMIcDB-rcA.png"/></div></div><p class="li lj gj gh gi lk ll bd b be z dk translated">表二。等级结构效应的烧蚀研究。</p></figure><h1 id="2e24" class="lm ln iq bd lo lp lq lr ls lt lu lv lw jw lx jx ly jz lz ka ma kc mb kd mc md bi translated">损失函数</h1><p id="14fe" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mu kq kr ks mv ku kv kw mw ky kz la ij bi translated">该网络的最终目标是正确预测光线的预期颜色值。由于我们可以使用地面真实 3D 模型来估计地面真实光线颜色，因此我们可以使用具有 RGB 值的 L2 距离作为损失。好在每一步都是可微的；因此，我们可以通过光线的预测 RGB 值来优化网络。</p><p id="1467" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作者设计损失函数以实现两个目标。</p><ol class=""><li id="2142" class="me mf iq kh b ki kj kl km ko nk ks nl kw nm la ml mm mn mo bi translated">很好地优化了粗网络。</li><li id="f82f" class="me mf iq kh b ki mp kl mq ko mr ks ms kw mt la ml mm mn mo bi translated">好好优化精细网络。</li></ol><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi nn"><img src="../Images/1ab0ced3e90de236e5c99e97d0642798.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RnNCluIz_RbyjvU57QdE2w.png"/></div></div><p class="li lj gj gh gi lk ll bd b be z dk translated">等式 5。损失函数</p></figure><h1 id="8654" class="lm ln iq bd lo lp lq lr ls lt lu lv lw jw lx jx ly jz lz ka ma kc mb kd mc md bi translated">结果</h1><h2 id="7c03" class="no ln iq bd lo np nq dn ls nr ns dp lw ko nt nu ly ks nv nw ma kw nx ny mc nz bi translated">-评估指标</h2><p id="5300" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mu kq kr ks mv ku kv kw mw ky kz la ij bi translated"><strong class="kh ir"> PSNR </strong>(峰值信噪比):PSNR 越高，MSE 越低。较低的 MSE 意味着地面真实图像和渲染图像之间的差异较小。因此，PSNR 越高，模型越好。</p><p id="7081" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> SSIM </strong>(结构相似度指标):<strong class="kh ir"> </strong>检查与地面真实图像模型的结构相似度。SSIM 越高，模型越好。</p><p id="200f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> LPIPS </strong>(学习感知图像块相似度):确定与感知视图的相似度；使用 VGGNet。LPIPS 越低，型号越好。</p><h2 id="e4ea" class="no ln iq bd lo np nq dn ls nr ns dp lw ko nt nu ly ks nv nw ma kw nx ny mc nz bi translated">-实验结果(定量结果)</h2><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi oa"><img src="../Images/becfd5f7873ec955317b2185374687ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6ty_MGp1UpvrbL0FKqgY6g.png"/></div></div><p class="li lj gj gh gi lk ll bd b be z dk translated">表二。实验结果</p></figure><p id="ee98" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">NeRF 在所有任务中都实现了一流的性能。</p><h2 id="1f36" class="no ln iq bd lo np nq dn ls nr ns dp lw ko nt nu ly ks nv nw ma kw nx ny mc nz bi translated">-可视化(定性结果)</h2><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi ob"><img src="../Images/7b4b7a84365ba8ef5e27919e6a3edd00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f6mPVNufLsMvGmsOnMsM-A.png"/></div></div><p class="li lj gj gh gi lk ll bd b be z dk translated">图二。用可比较的模型可视化 NeRF。</p></figure><ul class=""><li id="cfdc" class="me mf iq kh b ki kj kl km ko nk ks nl kw nm la oc mm mn mo bi translated">NeRF 还解决了<strong class="kh ir">视图依赖问题</strong>模型根据视图有不同的颜色。如图 3 所示，与其他模型不同，NeRF 架构会自动学习视图相关的颜色值。</li></ul><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi od"><img src="../Images/dbcb461682bd62c29cd11ce986ee02df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*19-wNDTanAZMSdXuEAgE2A.png"/></div></div><p class="li lj gj gh gi lk ll bd b be z dk translated">图 3。NeRF 的视图相关结果。</p></figure><h1 id="a6d0" class="lm ln iq bd lo lp lq lr ls lt lu lv lw jw lx jx ly jz lz ka ma kc mb kd mc md bi translated">结论</h1><p id="3254" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mu kq kr ks mv ku kv kw mw ky kz la ij bi translated">NeRF 证明，将场景表示为 5D 神经辐射场比以前占主导地位的训练深度卷积网络输出离散体素表示的方法产生更好的渲染。作者期望 NeRF 模型可以用不同的结构进一步优化。此外，NeRF 的可解释性不如以前的方法，如体素和网格。</p><p id="cb09" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">论文链接:<a class="ae oe" href="https://arxiv.org/abs/2003.08934" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2003.08934</a></p><p id="3251" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">NeRF 官方链接:【https://www.matthewtancik.com/nerf T2】</p><p id="ce2a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">随时联系我！" jeongyw12382@postech.ac.kr "</p></div></div>    
</body>
</html>