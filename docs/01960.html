<html>
<head>
<title>Turn Yourself Invisible Using Python And OpenCV</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python和OpenCV让自己隐形</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/turn-yourself-invisible-using-python-and-opencv-3a66dfa8af80?source=collection_archive---------16-----------------------#2020-02-24">https://towardsdatascience.com/turn-yourself-invisible-using-python-and-opencv-3a66dfa8af80?source=collection_archive---------16-----------------------#2020-02-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jq jr js jt"><div class="bz fp l di"><div class="ju jv l"/></div></figure><blockquote class="jw jx jy"><p id="9dc6" class="jz ka kb kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx im bi translated">将一个人从背景中移除的确是一项有趣又尴尬的任务。在本指南中，我想一步一步地展示如何使用OpenCV和Python从直播流中删除一个人。</p></blockquote><figure class="kz la lb lc gt jt gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi ky"><img src="../Images/2b6c2dc70d36126ba340f909f029e27c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fyHedFMitJ-5ZKG5BkFgmQ.jpeg"/></div></div><p class="lj lk gj gh gi ll lm bd b be z dk translated">照片由阿索格蒂在unsplash.com拍摄</p></figure><p id="ad99" class="pw-post-body-paragraph jz ka it kc b kd ke kf kg kh ki kj kk ln km kn ko lo kq kr ks lp ku kv kw kx im bi translated">几天前，在浏览黑客新闻时，我对谷歌工程师杰森·梅斯的<a class="ae lq" href="https://github.com/jasonmayes/Real-Time-Person-Removal" rel="noopener ugc nofollow" target="_blank">T3项目印象深刻。从我第一次看到这个项目的那一刻起，我就决定一定要(至少尝试)复制它。然而，由于我的随身工具主要是R和Python，所以我决定用后者来实现它。</a></p><h2 id="12a8" class="lr ls it bd lt lu lv dn lw lx ly dp lz ln ma mb mc lo md me mf lp mg mh mi mj bi translated">你需要什么:</h2><ul class=""><li id="d7ae" class="mk ml it kc b kd mm kh mn ln mo lo mp lp mq kx mr ms mt mu bi translated">Python 3.x.x(我用的是Python 3.7.4)</li><li id="e50a" class="mk ml it kc b kd mv kh mw ln mx lo my lp mz kx mr ms mt mu bi translated">OpenCV(我使用的是版本4.1.2)</li></ul><figure class="kz la lb lc gt jt gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi na"><img src="../Images/7b6d528f38eaf626806138c634878cd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XuwvJKmwOihCWDSsuHrohQ.png"/></div></div><p class="lj lk gj gh gi ll lm bd b be z dk translated">本项目中描述的不同阶段的分解。</p></figure><h2 id="ceac" class="lr ls it bd lt lu lv dn lw lx ly dp lz ln ma mb mc lo md me mf lp mg mh mi mj bi translated">头脑风暴:</h2><p id="57c6" class="pw-post-body-paragraph jz ka it kc b kd mm kf kg kh mn kj kk ln nb kn ko lo nc kr ks lp nd kv kw kx im bi translated">在做了一些头脑风暴后，我意识到，要从稳定的图像中删除一个对象，我很可能需要一个锚点作为起点，然后复制粘贴每一帧，就像一个遮罩一样，应用于包含一个人的每一个后续帧。</p><p id="c25c" class="pw-post-body-paragraph jz ka it kc b kd ke kf kg kh ki kj kk ln km kn ko lo kq kr ks lp ku kv kw kx im bi translated">然后我想，如果我有我想要隐藏的区域的坐标，我可以简单地从锚帧复制它，并在我想要隐藏对象的当前帧上替换它。</p><figure class="kz la lb lc gt jt gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi ne"><img src="../Images/9e1b01d9ee160a036a109f0d7438bd34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FmJedcATc-yERuNUYp6jFQ.png"/></div></div><p class="lj lk gj gh gi ll lm bd b be z dk translated">一个我被检测到的帧的例子。</p></figure><p id="9f96" class="pw-post-body-paragraph jz ka it kc b kd ke kf kg kh ki kj kk ln km kn ko lo kq kr ks lp ku kv kw kx im bi translated">要解决的第二个问题是找到一种方法来检测我想要移除的感兴趣的对象。幸运的是，OpenCV提供了一种简单的方法:基于支持向量机的梯度方向直方图检测器。这是一个必去的人探测器，不是最快的，不是最准确的，也不是最好的，但它就是工作。</p><h2 id="bc76" class="lr ls it bd lt lu lv dn lw lx ly dp lz ln ma mb mc lo md me mf lp mg mh mi mj bi translated">工作流程:</h2><p id="85a6" class="pw-post-body-paragraph jz ka it kc b kd mm kf kg kh mn kj kk ln nb kn ko lo nc kr ks lp nd kv kw kx im bi translated">因此，在头脑风暴之后，我决定坚持以下工作流程:</p><ul class=""><li id="8820" class="mk ml it kc b kd ke kh ki ln nf lo ng lp nh kx mr ms mt mu bi translated">实例化<code class="fe ni nj nk nl b">HOGDescriptor</code></li><li id="a225" class="mk ml it kc b kd mv kh mw ln mx lo my lp mz kx mr ms mt mu bi translated">获取视频的第一帧以用作遮罩</li><li id="34bf" class="mk ml it kc b kd mv kh mw ln mx lo my lp mz kx mr ms mt mu bi translated">迭代每一帧，对于每个检测到的人，用第一帧中相应的“空”区域替换该区域</li><li id="be4c" class="mk ml it kc b kd mv kh mw ln mx lo my lp mz kx mr ms mt mu bi translated">保存输出</li></ul><h2 id="fe12" class="lr ls it bd lt lu lv dn lw lx ly dp lz ln ma mb mc lo md me mf lp mg mh mi mj bi translated">代码:</h2><p id="991d" class="pw-post-body-paragraph jz ka it kc b kd mm kf kg kh mn kj kk ln nb kn ko lo nc kr ks lp nd kv kw kx im bi translated">按照之前描述的工作流程，我在我的<a class="ae lq" href="https://github.com/robertosannazzaro/person-removal-detectron2" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>下找到了下面的代码。</p><h2 id="8504" class="lr ls it bd lt lu lv dn lw lx ly dp lz ln ma mb mc lo md me mf lp mg mh mi mj bi translated">来测试一下吧！</h2><figure class="kz la lb lc gt jt gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/abab61d4bacb0700db8f4ee7cb86e956.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*miJYBDtp0Gtivn-auABpuQ.gif"/></div><p class="lj lk gj gh gi ll lm bd b be z dk translated">像老板一样。把手放在口袋里，然后消失！</p></figure><p id="6239" class="pw-post-body-paragraph jz ka it kc b kd ke kf kg kh ki kj kk ln km kn ko lo kq kr ks lp ku kv kw kx im bi translated">然而，引用埃隆·马斯克的话:</p><blockquote class="jw jx jy"><p id="2cc2" class="jz ka kb kc b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx im bi translated">“仍有改进的空间”</p></blockquote><figure class="kz la lb lc gt jt gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi nn"><img src="../Images/b8fbca2f093f377e334726dd5a19b0c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8VkogdEOK_5SqXecSYbdzg.png"/></div></div><p class="lj lk gj gh gi ll lm bd b be z dk translated">实际上没有这么精确，尤其是当我靠近镜头的时候。</p></figure><p id="21aa" class="pw-post-body-paragraph jz ka it kc b kd ke kf kg kh ki kj kk ln km kn ko lo kq kr ks lp ku kv kw kx im bi translated">测试完这段代码后，我意识到我可能是在正确的道路上，但是，检测不够精确，整个输出看起来有问题且不稳定。</p><p id="fd62" class="pw-post-body-paragraph jz ka it kc b kd ke kf kg kh ki kj kk ln km kn ko lo kq kr ks lp ku kv kw kx im bi translated">所以我意识到我需要找到一种方法来改进它:用第一帧替换每个检测到的人似乎是一个好方法，所以我可能需要找到一种更好的方法来检测物体，<strong class="kc iu">一个更好的模型！</strong></p><p id="4f0f" class="pw-post-body-paragraph jz ka it kc b kd ke kf kg kh ki kj kk ln km kn ko lo kq kr ks lp ku kv kw kx im bi translated">我记得不久前我写了一篇<a class="ae lq" rel="noopener" target="_blank" href="/a-beginners-guide-to-object-detection-and-computer-vision-with-facebook-s-detectron2-700b6273390e">简短指南</a>关于如何开始使用脸书的Detectron2模型，那么为什么不实现它而不是HOG检测器呢？</p><h2 id="3d8d" class="lr ls it bd lt lu lv dn lw lx ly dp lz ln ma mb mc lo md me mf lp mg mh mi mj bi translated">改进之处:</h2><p id="85ad" class="pw-post-body-paragraph jz ka it kc b kd mm kf kg kh mn kj kk ln nb kn ko lo nc kr ks lp nd kv kw kx im bi translated">在<a class="ae lq" href="https://github.com/facebookresearch/detectron2/tree/master/configs/COCO-InstanceSegmentation" rel="noopener ugc nofollow" target="_blank"> COCO的模型动物园</a>上搜索我发现了一个实例分割模型，每张图片的推理时间为0.07秒，这是最快的可用模型之一(可能不是最准确的)。然后我决定使用它。</p><p id="1898" class="pw-post-body-paragraph jz ka it kc b kd ke kf kg kh ki kj kk ln km kn ko lo kq kr ks lp ku kv kw kx im bi translated">要在我的管道中插入一个定制模型，必须安装所有必需的依赖项，如<code class="fe ni nj nk nl b">pytorch</code>、<code class="fe ni nj nk nl b">torchvision</code>和<code class="fe ni nj nk nl b">detectron2</code>:</p><pre class="kz la lb lc gt no nl np nq aw nr bi"><span id="dbb3" class="lr ls it nl b gy ns nt l nu nv"># install dependencies:</span><span id="d036" class="lr ls it nl b gy nw nt l nu nv">!pip install -U torch==1.4+cu100 torchvision==0.5+cu100 -f <a class="ae lq" href="https://download.pytorch.org/whl/torch_stable.html" rel="noopener ugc nofollow" target="_blank">https://download.pytorch.org/whl/torch_stable.html</a></span><span id="0088" class="lr ls it nl b gy nw nt l nu nv">!pip install cython pyyaml==5.1</span><span id="f8ae" class="lr ls it nl b gy nw nt l nu nv">!pip install -U ‘git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'</span><span id="8b9f" class="lr ls it nl b gy nw nt l nu nv">import torch, torchvision</span></pre><p id="a610" class="pw-post-body-paragraph jz ka it kc b kd ke kf kg kh ki kj kk ln km kn ko lo kq kr ks lp ku kv kw kx im bi translated">以下代码和指令是在Google Colab实例上测试的，做出这一选择是为了让这个实验更容易复制，而不会有缺少依赖、版本冲突和所有经常发生的无聊事情。</p><p id="260b" class="pw-post-body-paragraph jz ka it kc b kd ke kf kg kh ki kj kk ln km kn ko lo kq kr ks lp ku kv kw kx im bi translated">然后我们需要安装检测器2:</p><pre class="kz la lb lc gt no nl np nq aw nr bi"><span id="b690" class="lr ls it nl b gy ns nt l nu nv"># install detectron2:</span><span id="7328" class="lr ls it nl b gy nw nt l nu nv">!git clone <a class="ae lq" href="https://github.com/facebookresearch/detectron2" rel="noopener ugc nofollow" target="_blank">https://github.com/facebookresearch/detectron2</a> detectron2_repo</span><span id="cc4c" class="lr ls it nl b gy nw nt l nu nv">!pip install -e detectron2_repo</span></pre><p id="96d6" class="pw-post-body-paragraph jz ka it kc b kd ke kf kg kh ki kj kk ln km kn ko lo kq kr ks lp ku kv kw kx im bi translated">现在我们可以导入所有需要的库并加载模型(完整代码请参考<a class="ae lq" href="https://colab.research.google.com/drive/12cFu78sYG6Hl-kpmSEI3axuw4KhUe_RY" rel="noopener ugc nofollow" target="_blank"> Google Colab笔记本</a>或<a class="ae lq" href="https://github.com/robertosannazzaro/person-removal-detectron2" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>):</p><pre class="kz la lb lc gt no nl np nq aw nr bi"><span id="53c0" class="lr ls it nl b gy ns nt l nu nv">cfg = get_cfg()</span><span id="ea5a" class="lr ls it nl b gy nw nt l nu nv">cfg.merge_from_file(model_zoo.get_config_file(“COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_1x.yaml”))</span><span id="b691" class="lr ls it nl b gy nw nt l nu nv">cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5 # set threshold for this model</span><span id="f335" class="lr ls it nl b gy nw nt l nu nv">cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(“COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_1x.yaml”)</span><span id="669c" class="lr ls it nl b gy nw nt l nu nv">predictor = DefaultPredictor(cfg)</span></pre><p id="6dd5" class="pw-post-body-paragraph jz ka it kc b kd ke kf kg kh ki kj kk ln km kn ko lo kq kr ks lp ku kv kw kx im bi translated">不可能使用我们的<code class="fe ni nj nk nl b">predictor</code>来推断类，<code class="fe ni nj nk nl b">predictor</code>返回一个需要转换成<code class="fe ni nj nk nl b">numpy</code>数组的张量数组，然后可以像我之前做的一样迭代它:</p><pre class="kz la lb lc gt no nl np nq aw nr bi"><span id="6544" class="lr ls it nl b gy ns nt l nu nv">outputs = predictor(frame)</span><span id="8c9a" class="lr ls it nl b gy nw nt l nu nv">outputs = outputs[“instances”].pred_boxes<br/>.to(‘cpu’)<br/>.tensor<br/>.numpy()<br/>.astype(int)</span></pre><p id="461b" class="pw-post-body-paragraph jz ka it kc b kd ke kf kg kh ki kj kk ln km kn ko lo kq kr ks lp ku kv kw kx im bi translated">让我们来看看最终结果:</p><figure class="kz la lb lc gt jt gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/327ca150406f7bca797c61edb60e32b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*rqzva5Qjx7_Nr8es5jipfQ.gif"/></div><p class="lj lk gj gh gi ll lm bd b be z dk translated">探测器2与全息探测器</p></figure><p id="ce97" class="pw-post-body-paragraph jz ka it kc b kd ke kf kg kh ki kj kk ln km kn ko lo kq kr ks lp ku kv kw kx im bi translated">从gif中可以观察到Detectron2如何更准确地检测到一个人，然而，需要指出的是，当然，它需要一些更“深入”的配置(依赖关系有时是一种斗争)。但是，最后的结果自己说话！</p><h2 id="a8a8" class="lr ls it bd lt lu lv dn lw lx ly dp lz ln ma mb mc lo md me mf lp mg mh mi mj bi translated">几个最后的考虑:</h2><p id="93a3" class="pw-post-body-paragraph jz ka it kc b kd mm kf kg kh mn kj kk ln nb kn ko lo nc kr ks lp nd kv kw kx im bi translated">尽管最终获得的结果相当令人惊讶，但总有改进的余地。仔细观察我身后的滑雪者，可以发现当我从他们面前经过时，面具使他们自己消失了(这种现象被称为遮挡)。此外，当前帧上的“切割”矩形之间的插值非常明显。为了解决这两个问题，能够执行<a class="ae lq" href="https://github.com/facebookresearch/detectron2" rel="noopener ugc nofollow" target="_blank">全景分割</a>的模型可能会有所帮助。</p></div><div class="ab cl nx ny hx nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="im in io ip iq"><h2 id="7bd9" class="lr ls it bd lt lu lv dn lw lx ly dp lz ln ma mb mc lo md me mf lp mg mh mi mj bi translated">最后的对比视频:</h2><figure class="kz la lb lc gt jt"><div class="bz fp l di"><div class="oe jv l"/></div></figure></div><div class="ab cl nx ny hx nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="im in io ip iq"><pre class="kz la lb lc gt no nl np nq aw nr bi"><span id="a698" class="lr ls it nl b gy ns nt l nu nv"><strong class="nl iu">I have a newsletter 📩.</strong></span><span id="9ae7" class="lr ls it nl b gy nw nt l nu nv">Every week I’ll send you a brief findings of articles, links, tutorials, and cool things that caught my attention. If tis sounds cool to you subscribe.</span><span id="16f2" class="lr ls it nl b gy nw nt l nu nv"><em class="kb">That means </em><strong class="nl iu"><em class="kb">a lot</em></strong><em class="kb"> for me.</em></span></pre><div class="of og gp gr oh oi"><a href="https://relentless-creator-2481.ck.page/68d9def351" rel="noopener  ugc nofollow" target="_blank"><div class="oj ab fo"><div class="ok ab ol cl cj om"><h2 class="bd iu gy z fp on fr fs oo fu fw is bi translated">米尔斯形式</h2><div class="op l"><h3 class="bd b gy z fp on fr fs oo fu fw dk translated">编辑描述</h3></div><div class="oq l"><p class="bd b dl z fp on fr fs oo fu fw dk translated">无情-创造者-2481.ck.page</p></div></div></div></a></div></div></div>    
</body>
</html>