<html>
<head>
<title>Kubernetes and Amazon SageMaker for machine learning — best of both worlds</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Kubernetes 和亚马逊 SageMaker 的机器学习——两全其美</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/kubernetes-and-amazon-sagemaker-for-machine-learning-best-of-both-worlds-part-1-37580689a92f?source=collection_archive---------11-----------------------#2020-03-03">https://towardsdatascience.com/kubernetes-and-amazon-sagemaker-for-machine-learning-best-of-both-worlds-part-1-37580689a92f?source=collection_archive---------11-----------------------#2020-03-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3f8c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用 Amazon SageMaker 为机器学习工作负载扩展 Kubernetes 集群的容量和功能</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c987f77efea2ae5ae73b128e863ac03c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*iX8mhoiOSjihYpAU"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Kubernetes 和亚马逊 SageMaker——两全其美</p></figure><p id="15a3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你是一个经常训练和部署机器学习模型的团队的一员，你可能有一个集群设置来帮助协调和管理你的机器学习工作负载。你使用 Kubernetes(和 KubeFlow)或亚马逊 SageMaker 的机会。</p><p id="0bd4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">到目前为止，你必须选择你的编排系统，并坚持下去。您要么(1)根据数据科学团队的预期工作负载调配 Kubernetes 集群，要么(2)完全由 Amazon SageMaker 管理，根据需要自动调配和拆除资源。</p><p id="bfdb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果能两全其美岂不是很好？</p><ul class=""><li id="cae8" class="lu lv it la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">使用 Kubernetes 管理您的工作流，并使用 Amazon SageMaker 获得大规模分布式培训的爆发容量？</li><li id="1c13" class="lu lv it la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">用 Kubeflow Jupyter 笔记本开发算法和模型，用亚马逊 SageMaker 大规模运行超参数实验？</li><li id="36b0" class="lu lv it la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">使用 Kubeflow 训练模型，并托管一个推理端点 Amazon SageMaker，可以弹性扩展到数百万用户？</li></ul><p id="3026" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">有了针对 Kubernetes  的亚马逊 SageMaker 运营商，你就可以做到这一点！您可以使用它来训练机器学习模型，优化超参数，运行批量转换作业，并使用 Amazon SageMaker 设置推理端点，而无需离开您的 Kubernetes 集群。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mj"><img src="../Images/8340e38ad54018ea47b23553c3104b7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EtviqsXJZWc6FaMyaw-Vyg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用 Amazon SageMaker Operators for Kubernetes 来运行培训作业、模型调优作业、批量转换作业，并使用 Kubernetes 配置文件和 kubectl 在 Amazon sage maker 上设置推理端点</p></figure><p id="8017" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">用于 Kubernetes 的 Amazon SageMaker Operators 是 Kubernetes 中的一个<a class="ae mi" href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/" rel="noopener ugc nofollow" target="_blank">定制资源</a>，它支持使用 Kubernetes CLI 和配置文件调用 Amazon SageMaker 功能。事实上，Kubernetes 的许多核心功能都是作为定制资源构建的，这种模块化使得 Kubernetes 非常具有可扩展性。对于 Kubernetes 用户来说，Amazon SageMaker Operators 使您能够以一种一致的方式与 Kubernetes 和 Amazon SageMaker 进行交互。</p><p id="8388" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这篇博文中，我将概述 Amazon sage maker Operators for Kubernetes，为什么它很重要，以及常见的使用模式，以便您可以决定这是否适合您。这篇博文中引用的所有代码、配置文件和演示 Jupyter 笔记本都可以在 GitHub 上获得:</p><blockquote class="mk ml mm"><p id="9083" class="ky kz mn la b lb lc ju ld le lf jx lg mo li lj lk mp lm ln lo mq lq lr ls lt im bi translated"><a class="ae mi" href="https://github.com/shashankprasanna/kubernetes-sagemaker-demos.git" rel="noopener ugc nofollow" target="_blank">https://github . com/shashankprasanna/kubernetes-sage maker-demos . git</a></p></blockquote><p id="d8b3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要深入了解如何使用 Amazon SageMaker Operators for Kubernetes 实现分布式培训、模型调优和模型托管示例，请查看随附的帖子:</p><blockquote class="mk ml mm"><p id="387d" class="ky kz mn la b lb lc ju ld le lf jx lg mo li lj lk mp lm ln lo mq lq lr ls lt im bi translated"><a class="ae mi" href="https://medium.com/p/kubernetes-and-amazon-sagemaker-for-machine-learning-distributed-training-hyperparameter-tuning-187c821e25b4?source=email-e0c596ca35b5--writer.postDistributed&amp;sk=482ac690fe10d9273a2b2d1219cc47d3" rel="noopener">用于 Kubernetes 的 Amazon SageMaker 运营商——分布式培训、超参数调整和模型托管的示例</a></p></blockquote><h1 id="19ea" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated">云中的一对</h1><p id="580a" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">Kubernetes 和 Kubeflow 项目享有强大的用户社区，是机器学习领域发展最快的开源项目之一。只要您拥有设置、管理和排除 Kubernetes 集群故障的内部专业知识，您就可以获得作为数据科学家或机器学习研究人员所需的一切——Jupyter 笔记本和对 KubeFlow 分布式培训的支持，KubeFlow 和 Katib 的超参数调整，以及 KFServing 的轻松推理部署。作为 Kubernetes 用户，您可以完全灵活地选择在哪里运行它(本地或云)，以及在什么系统上运行它。这也意味着您要负责保持群集的高利用率，以降低运营成本，鉴于突发性或峰值机器学习工作负载的性质，这可能是一项挑战。</p><p id="5866" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">亚马逊 SageMaker 采取了不同的方法。首先，它为机器学习工作流程的几乎每个部分提供了一套完全托管的服务，从数据标记、托管 Jupyter 笔记本开发环境、使用后自动供应和拆除的托管培训集群、超参数优化、托管模型托管服务等等。作为 Amazon SageMaker 用户，您不必关注基础设施管理和集群利用率之类的事情。</p><p id="fd6c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">作为一名机器学习实践者，你应该能够利用两者的优势。例如，您应该能够将持续运行的(或多或少)固定容量自我管理的 Kubernetes 基础架构与按需、完全管理的弹性 Amazon SageMaker 基础架构配对，后者仅在您需要时供应。这是一个强大的想法——数据科学家团队可以让他们的想法自由驰骋，随心所欲地进行实验，而不受现有 Kubernetes 设置的限制。</p><p id="959b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您现在已经可以做到这一点，但是必须在这两个系统之间来回切换。有了 Amazon sage maker Operators for Kubernetes，您现在无需离开您可能已经熟悉的 Kubernetes 环境就可以做到这一点。</p><h1 id="d20c" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated">场景和用例</h1><p id="7c14" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">借助 Amazon SageMaker Operators for Kubernetes，您可以将单节点培训、分布式或多节点培训、大规模超参数调整和托管推理部署等工作负载卸载到 Amazon sage maker 的完全托管基础设施中。因此，问题就变成了，什么时候把工作负载转移到 Amazon SageMaker 上比在 Kubernetes 集群上运行更有意义？</p><p id="426b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们通过几个假设的场景来探讨这个问题。</p><h2 id="1892" class="no ms it bd mt np nq dn mx nr ns dp nb lh nt nu nd ll nv nw nf lp nx ny nh nz bi translated">场景#1 —大规模培训能力过剩</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/3c990ae95bd3240020fc007bea8c8b51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L-Hk7CRNKFePqkMex6XUaw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用 Amazon sage maker Operators for Kubernetes 通过 kubectl 提交培训工作。Amazon SageMaker 提供所需的容量并运行培训作业。</p></figure><p id="f381" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">假设您目前正在本地数据中心或使用亚马逊 EKS 的 AWS 上运行 Kubernetes 集群。在设置时，您根据当时的工作负载对数据中心的 CPU、GPU 和存储数量进行了预算和选择。现在，您的团队已经壮大，或者您拥有更多数据，需要更多计算能力。如果您有 128 个 GPU，您可以在一天内完成一个机器学习训练实验的快速截止日期，但在您的 Kubernetes 集群上，他们都在忙于其他项目。你只需要短时间的额外突发容量。</p><p id="d02f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你的选择是</p><ol class=""><li id="f431" class="lu lv it la b lb lc le lf lh lw ll lx lp ly lt ob ma mb mc bi translated">扩展您现有的 Kubernetes 集群并添加所需的资源</li><li id="1af5" class="lu lv it la b lb md le me lh mf ll mg lp mh lt ob ma mb mc bi translated">使用所需的资源启动另一个 Kubernetes 集群</li><li id="3209" class="lu lv it la b lb md le me lh mf ll mg lp mh lt ob ma mb mc bi translated">使用 Amazon SageMaker 进行按需供应</li></ol><p id="9dae" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">(1)和(2)是您没有参与的额外基础设施工作。(3)是一个很好的选择，但是要求您离开您熟悉的 Kubernetes 环境，并且它没有集成到您已经设置的任何 CI/CD 自动化中。</p><p id="c773" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">还有第四种选择。使用 Amazon SageMaker Operators for Kubernetes 通过<code class="fe oc od oe of b">kubectl</code>提交 Amazon sage maker 作业，就像提交其他 Kubernetes 作业一样。在后台，将自动为您提供一个 Amazon SageMaker 托管集群，其中包含指定数量的实例。然后，培训作业将在 Amazon SageMaker 管理的集群上执行，一旦培训完成，该集群将自动关闭，您将看到培训的确切持续时间，这是您将支付的费用。</p><h2 id="e98b" class="no ms it bd mt np nq dn mx nr ns dp nb lh nt nu nd ll nv nw nf lp nx ny nh nz bi translated">场景#2 —托管可伸缩的推理端点</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/34fdbd54636e7ed66ef2fd7bfff388ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eA7ZglmZDBW-usTBUKg0Aw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用 Amazon sage maker Operators for Kubernetes 通过 kubectl 托管推理端点。Amazon SageMaker 提供所需的实例并运行模型服务器。</p></figure><p id="111e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们考虑另一种情况。您拥有针对 Kubernetes 的培训、验证和部署的 CI/CD 自动化设置。您使用 Kubernetes 托管的模型由您的客户通过终端、移动应用程序或网站使用。该模型托管在 GPU 实例上，因为延迟和性能对于您的客户体验至关重要。您希望释放 GPU 资源用于培训，并且需要能够自动扩展和执行实时模型监控。Amazon SageMaker 主机服务已经提供了这些功能，但是您希望在不中断现有 CI/CD 工作流的情况下利用这些功能。使用 Amazon SageMaker Operators for Kubernetes，您可以直接从 Kubernetes 部署一个经过训练的模型，以同样的声明方式使用 YAML 的配置文件，它可以轻松集成到您现有的设置中，并且仍然允许您获得 Amazon sage maker 托管的好处。</p><p id="96e2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在让我们来看看 Kubernetes 和 Amazon SageMaker 一起使用的一些常见使用模式。</p><h2 id="73f8" class="no ms it bd mt np nq dn mx nr ns dp nb lh nt nu nd ll nv nw nf lp nx ny nh nz bi translated">使用案例#1 —利用 TensorFlow、PyTorch、MXNet 和其他框架进行分布式培训</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/0d6ba051da6425ce78e2d8ab22112591.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wbF9rHTWkBDgj7ZA"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">工作流程:用户上传培训代码到亚马逊 S3。Amazon SageMaker 下载训练代码，拉出指定的框架容器，并在其中运行训练脚本。用户不必处理构建和推动容器。</p></figure><p id="36e8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">借助分布式多节点训练，您可以通过在多个 GPU 之间分配工作负载来大幅减少训练模型的时间。当 Kubernetes 集群中的 GPU 容量不足时，可以配置一个分布式培训作业，在 Amazon SageMaker 管理的集群上运行。除了快速访问 AWS 上的多余容量之外，您还可以获得 Amazon SageMaker 的其他好处，如利用 Spot Instance 大幅降低培训成本的能力，在 AWS 控制台上或使用 AWS CLI 监控和跟踪培训工作的能力，以及通过几次点击托管培训模型的能力。</p><p id="cbd6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果您正在使用广泛使用的框架，如 TensorFlow、PyTorch、MXNet、XGboost 等，您所要做的就是将您的培训脚本作为 tar.gz 文件上传到亚马逊 S3，并通过在 YAML 编写的 Kubernetes 配置文件向亚马逊 SageMaker 提交培训作业。看看 GitHub 存储库中的示例代码和配置文件。以下是您需要做出的更改，以便通过 Kubernetes 的 kubectl 提交您的 Amazon SageMaker 培训工作</p><p id="2cf9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面是这篇博文的<a class="ae mi" href="https://github.com/shashankprasanna/kubernetes-sagemaker-demos" rel="noopener ugc nofollow" target="_blank"> GitHub 资源库中的<code class="fe oc od oe of b"><a class="ae mi" href="https://github.com/shashankprasanna/kubernetes-sagemaker-demos/blob/master/1-tf-dist-training-training-script/k8s-sm-dist-training-script.yaml" rel="noopener ugc nofollow" target="_blank">k8s-sm-dist-training-script.y</a>aml</code>文件摘录。</a></p><pre class="kj kk kl km gt oh of oi oj aw ok bi"><span id="175c" class="no ms it of b gy ol om l on oo">apiVersion: sagemaker.aws.amazon.com/v1<br/>kind: TrainingJob<br/>metadata:<br/>  name: k8s-sm-dist-training-script <br/>spec:<br/>    hyperParameters:<br/>        - name: learning-rate<br/>          value: "0.001"<br/>        - name: batch-size<br/>          value: "256"<br/>…<br/>        - name: sagemaker_program<br/>          value: 'cifar10-multi-gpu-horovod-sagemaker.py'<br/>        - name: sagemaker_submit_directory<br/>          value: 's3://sagemaker-jobs/training-scripts/sourcedir.tar.gz'<br/>...<br/>    algorithmSpecification:<br/>        trainingImage: 763104351884.dkr.ecr.us-west-2.amazonaws.com/tensorflow-training:1.15.2-gpu-py27-cu100-ubuntu18.04<br/>        trainingInputMode: File<br/>...<br/>    resourceConfig:<br/>        instanceCount: 128<br/>        instanceType: "ml.p3.2xlarge"<br/>        volumeSizeInGB: 50<br/>...</span></pre><p id="a8a2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这读起来像任何其他 Kubernetes 配置写在 YAML。对于培训工作，你会注意到顶部的<code class="fe oc od oe of b">kind: TrainingJob</code></p><p id="9eef" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">以下是几个关键部分，您可以在其中指定培训工作的各个方面:</p><ul class=""><li id="bb1b" class="lu lv it la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated"><code class="fe oc od oe of b"><strong class="la iu">hyperParameters</strong></code> —这些在 YAML 规范中指定，因此您可以通过更改和提交培训作业来自动运行不同的实验</li><li id="f700" class="lu lv it la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><code class="fe oc od oe of b"><strong class="la iu">sagemaker_submit_directory</strong></code> —您上传培训脚本的 S3 地点。与使用 Kubernetes 提交培训相比，这是独一无二的，因为您不必构建自定义容器！Amazon SageMaker 会自动将您的培训脚本下载到现有的 TensorFlow 容器中，然后为您运行培训。没有乱搞 Docker 文件和自定义容器。</li><li id="5cba" class="lu lv it la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><code class="fe oc od oe of b"><strong class="la iu">resourceConfig</strong></code> —您需要多少个什么类型的实例。该配置将要求 128 个 V100 GPUs 来运行分布式培训。</li><li id="9829" class="lu lv it la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><code class="fe oc od oe of b"><strong class="la iu">trainingImage</strong></code> — <a class="ae mi" href="https://docs.aws.amazon.com/deep-learning-containers/latest/devguide/deep-learning-containers-images.html" rel="noopener ugc nofollow" target="_blank">从预先构建的容器中挑选</a>用于 TensorFlow、PyTorch、MXNet，用于训练或推理，用于 Python2 或 Python 3，用于 CPU 或 GPU。</li></ul><p id="f4c5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">像提交任何其他 Kubernetes 配置文件一样提交作业。</p><pre class="kj kk kl km gt oh of oi oj aw ok bi"><span id="0052" class="no ms it of b gy ol om l on oo">kubectl apply -f k8s-sm-dist-training-script.yaml</span></pre><h2 id="9e62" class="no ms it bd mt np nq dn mx nr ns dp nb lh nt nu nd ll nv nw nf lp nx ny nh nz bi translated">用例 2 —使用定制容器的分布式培训</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/893c79024d5ffa11a4153f94657044c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-SzcJ6jJtJWrCQrU"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">工作流:用户在本地构建一个自定义容器，并将其推送到 Amazon ECR。Amazon SageMaker 提取定制容器，并在完全管理的训练集群上运行它。</p></figure><p id="40de" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果您正在使用定制的专有算法并构建自己的 Docker 容器，那么您更愿意指定容器映像，而不是 TensorFlow、PyTorch、MXNet 等框架培训脚本。与用例 1 不同，您必须经历额外的步骤，首先在本地构建一个自定义 docker 容器，并将其推送到 Amazon Elastic Container Registry(ECR ),并在 trainingImage 下指定其 URI。如果您没有需要构建定制容器的定制算法，我推荐使用用例 1 中的方法。</p><pre class="kj kk kl km gt oh of oi oj aw ok bi"><span id="3c29" class="no ms it of b gy ol om l on oo">apiVersion: sagemaker.aws.amazon.com/v1<br/>kind: TrainingJob<br/>metadata:<br/>  name: k8s-sm-dist-custom-container <br/>spec:<br/>    hyperParameters:<br/>        - name: learning-rate<br/>          value: "0.001"<br/>        - name: weight-decay<br/>          value: "0.0002"<br/>...<br/>    algorithmSpecification:<br/>        trainingImage: &lt;ACCOUNT_ID&gt;.dkr.ecr.us-west-2.amazonaws.com/&lt;IMAGE&gt;:latest<br/>        trainingInputMode: File<br/>        metricDefinitions: <br/>         - name: val_acc<br/>         - regex: 'val_acc: ([0-9\\.]+)'</span></pre><p id="020f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">GitHub 存储库中的代码也包括重复这些步骤的 Jupyter 笔记本。</p><p id="37d1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">提交作业:</p><pre class="kj kk kl km gt oh of oi oj aw ok bi"><span id="27f0" class="no ms it of b gy ol om l on oo">kubectl apply -f k8s-sm-dist-custom-container.yaml</span></pre><h2 id="81ae" class="no ms it bd mt np nq dn mx nr ns dp nb lh nt nu nd ll nv nw nf lp nx ny nh nz bi translated">用例 3——大规模超参数优化</h2><p id="b013" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">机器学习模型的超参数是在训练阶段没有优化或学习的选项。Amazon SageMaker 提供超参数优化功能，并实现贝叶斯和随机搜索。这与 KubeFlow 的 Katib 项目所提供的功能没有什么不同。要在 Amazon SageMaker 上运行大规模的超参数调优作业，需要创建一个 Kubernetes 配置文件。这里您将指定超参数范围，而不是固定的超参数。这指示亚马逊 SageMaker 尝试不同的选项，以达到最佳模式。maxNumberOfTrainingJobs 指定您希望使用不同超参数组合运行的作业总数，maxParallelTrainingJobs 指定您希望在任何给定时间对多少个实例运行此操作。</p><pre class="kj kk kl km gt oh of oi oj aw ok bi"><span id="fb67" class="no ms it of b gy ol om l on oo">apiVersion: sagemaker.aws.amazon.com/v1<br/>kind: HyperparameterTuningJob<br/>metadata:<br/>    name: k8s-sm-hyperopt-training-script <br/>spec:<br/>    hyperParameterTuningJobConfig:<br/>        resourceLimits:<br/>            maxNumberOfTrainingJobs: 32<br/>            maxParallelTrainingJobs: 8<br/>        strategy: "Bayesian"<br/>        trainingJobEarlyStoppingType: Auto<br/>        hyperParameterTuningJobObjective:<br/>            type: Maximize<br/>            metricName: 'val_acc'<br/>        parameterRanges:<br/>            continuousParameterRanges:<br/>            - name: learning-rate<br/>              minValue: '0.0001'<br/>              maxValue: '0.1'<br/>              scalingType: Logarithmic<br/>...<br/>            categoricalParameterRanges:<br/>            - name: optimizer<br/>              values:<br/>              - 'sgd'<br/>              - 'adam'<br/>...</span></pre><p id="19c6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">提交作业:</p><pre class="kj kk kl km gt oh of oi oj aw ok bi"><span id="7cfc" class="no ms it of b gy ol om l on oo">kubectl apply -f k8s-sm-dist-custom-container.yaml</span></pre><h2 id="aca4" class="no ms it bd mt np nq dn mx nr ns dp nb lh nt nu nd ll nv nw nf lp nx ny nh nz bi translated">用例 4——用 BYO 模型托管一个推理端点</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/aa8d369f5e656f60c22854593500f2a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*opWIiGEBFY-zYqsJ"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">工作流程:用户上传一个训练有素的模型作为 tar.gz 文件到亚马逊 S3。如果模型是使用亚马逊 SageMaker 训练的，那么 model.tar.gz 将已经在亚马逊 S3 上可用。Amazon SageMaker 下载模型文件，提取服务容器，并在完全托管的实例上托管端点。</p></figure><p id="fb27" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一旦模型经过训练，您就可以使用 Amazon SageMaker 托管来托管它，而不是在您的 Kubernetes 集群上托管它。使用 Amazon SageMaker，您可以利用额外的功能和节省成本的特性进行推理部署。要进行部署，您需要创建一个配置文件:HostingDeployment。在这里，您将指定实例的类型，如果您托管多个模型，则提供 A/B 测试的权重，以及经过训练的模型在亚马逊 S3 上的位置，如下所示。</p><pre class="kj kk kl km gt oh of oi oj aw ok bi"><span id="5a78" class="no ms it of b gy ol om l on oo">apiVersion: sagemaker.aws.amazon.com/v1<br/>kind: HostingDeployment<br/>metadata:<br/>  name: k8s-sm-inference-host-endpoint <br/>spec:<br/>    region: us-west-2<br/>    productionVariants:<br/>        - variantName: AllTraffic<br/>          modelName: tf-cifar10-resnet-model<br/>          initialInstanceCount: 1<br/>          instanceType: ml.c5.large<br/>          initialVariantWeight: 1<br/>    models:<br/>        - name: tf-cifar10-resnet-model<br/>          executionRoleArn: arn:aws:iam::&lt;ACCOUNT_ID&gt;:role/service-role/AmazonSageMaker-ExecutionRole-20190820T113591 <br/>          containers:<br/>              - containerHostname: tensorflow<br/>                modelDataUrl: s3://sagemaker-jobs/trained-tf-model/model.tar.gz<br/>                image: 763104351884.dkr.ecr.us-west-2.amazonaws.com/tensorflow-inference:1.15.2-cpu-py36-ubuntu18.04</span></pre><h1 id="950f" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated">准备实施！</h1><p id="8096" class="pw-post-body-paragraph ky kz it la b lb nj ju ld le nk jx lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">在这篇文章中，我简要介绍了 Amazon sage maker Operator for Kubernetes，以及如何在现有的 Kubernetes 集群中使用它。我展示了 2 个场景和 4 个不同的用例来利用 Amazon SageMaker 的优势，而无需离开您的 Kubernetes 环境。</p><p id="8a07" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">关于如何实现这篇博文中给出的例子的分步说明，请查看这篇附带的文章:</p><blockquote class="mk ml mm"><p id="dee8" class="ky kz mn la b lb lc ju ld le lf jx lg mo li lj lk mp lm ln lo mq lq lr ls lt im bi translated"><a class="ae mi" href="https://medium.com/p/kubernetes-and-amazon-sagemaker-for-machine-learning-distributed-training-hyperparameter-tuning-187c821e25b4?source=email-e0c596ca35b5--writer.postDistributed&amp;sk=482ac690fe10d9273a2b2d1219cc47d3" rel="noopener"> <em class="it">用于 Kubernetes 的 Amazon SageMaker 运营商——分布式培训、超参数调整和模型托管的示例</em> </a></p></blockquote><p id="5eb5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要运行这些示例，请前往 GitHub:<br/><a class="ae mi" href="https://github.com/shashankprasanna/kubernetes-sagemaker-demos.git" rel="noopener ugc nofollow" target="_blank">https://GitHub . com/shashankprasanna/kubernetes-sage maker-demos . git</a></p><p id="6dd2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你有问题，请在 twitter (@shshnkp)、LinkedIn 联系我或者在下面留言。</p></div></div>    
</body>
</html>