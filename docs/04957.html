<html>
<head>
<title>Analyzing the Coronavirus outbreak in France and South Korea</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">法国和韩国冠状病毒疫情分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/analyzing-the-coronavirus-outbreak-in-france-and-south-korea-8f467ef385de?source=collection_archive---------56-----------------------#2020-04-29">https://towardsdatascience.com/analyzing-the-coronavirus-outbreak-in-france-and-south-korea-8f467ef385de?source=collection_archive---------56-----------------------#2020-04-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/9041c5a1f34b410e4a8f6486d10b597a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l1c_p6KjbNYMKJ9zNGzIVg.jpeg"/></div></div></figure><div class=""/><p id="3119" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们目前正在经历新型冠状病毒的负面影响。这种病毒迅速改变了我们的生活，并让我们许多人对即将发生的事情感到困惑和恐惧。</p><p id="f0be" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">作为工程师和数据科学家，我们希望帮助理解海量的可用数据。我们认为，我们有责任分享我们的见解，以便集体找到解决办法，防止疾病进一步爆发。</p><p id="8cda" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">本文的重点是分析这种疾病最初在法国和韩国的传播。我们的分析涵盖了截至2020年3月12日收集的所有数据。多亏了我们的数据科学家蜜琪拉·皮萨尼的工作，它才得以整合。</p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="b924" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf"> <em class="lg">编者按:</em> </strong> <em class="lg"> </em> <a class="ae lh" href="http://towardsdatascience.com/" rel="noopener" target="_blank"> <em class="lg">走向数据科学</em> </a> <em class="lg">是一份以数据科学和机器学习研究为主的中型刊物。我们不是健康专家或流行病学家，本文的观点不应被解释为专业建议。想了解更多关于疫情冠状病毒的信息，可以点击</em> <a class="ae lh" href="https://www.who.int/emergencies/diseases/novel-coronavirus-2019/situation-reports" rel="noopener ugc nofollow" target="_blank"> <em class="lg">这里</em> </a> <em class="lg">。</em></p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h2 id="305d" class="li lj je bd lk ll lm dn ln lo lp dp lq km lr ls lt kq lu lv lw ku lx ly lz ma bi translated">我们的数据来源</h2><p id="785d" class="pw-post-body-paragraph kb kc je kd b ke mb kg kh ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky im bi translated">Kaggle为数据科学家提供不同的数据集。它们可以用来练习和解决机器学习问题。</p><p id="50f2" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">以下链接包含来自世界各国的最新数据集，提供了感染冠状病毒的患者的统计数据:</p><ul class=""><li id="f89d" class="mg mh je kd b ke kf ki kj km mi kq mj ku mk ky ml mm mn mo bi translated"><a class="ae lh" href="https://www.kaggle.com/kimjihoo/coronavirusdataset" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/kimjihoo/coronavirusdataset</a></li><li id="f3d1" class="mg mh je kd b ke mp ki mq km mr kq ms ku mt ky ml mm mn mo bi translated"><a class="ae lh" href="https://www.kaggle.com/lperez/coronavirus-france-dataset" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/lperez/coronavirus-france-dataset</a></li><li id="f64e" class="mg mh je kd b ke mp ki mq km mr kq ms ku mt ky ml mm mn mo bi translated"><a class="ae lh" href="https://www.kaggle.com/imdevskp/corona-virus-report#covid_19_clean_complete.csv" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/imdevskp/corona-virus-report # covid _ 19 _ clean _ complete . CSV</a></li><li id="e341" class="mg mh je kd b ke mp ki mq km mr kq ms ku mt ky ml mm mn mo bi translated"><a class="ae lh" href="https://www.kaggle.com/sudalairajkumar/covid19-in-italy" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/sudalairajkumar/covid19-in-italy</a></li></ul><p id="f417" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">更多信息资源可以在这里找到。</p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="889b" class="mu lj je bd lk mv mw mx ln my mz na lq nb nc nd lt ne nf ng lw nh ni nj lz nk bi translated">问题</h1><p id="b7c5" class="pw-post-body-paragraph kb kc je kd b ke mb kg kh ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky im bi translated">此时此刻，科学界的问题远多于答案。提出问题很容易，但大多数答案都需要等待。</p><p id="47e4" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们可以很容易地编造其中的一些，比如:</p><ul class=""><li id="1f06" class="mg mh je kd b ke kf ki kj km mi kq mj ku mk ky ml mm mn mo bi translated">数据中是否有某种模式，第一次感染是如何发生的？有容易识别的集群吗？</li><li id="a815" class="mg mh je kd b ke mp ki mq km mr kq ms ku mt ky ml mm mn mo bi translated">阳性病例和死亡病例的比例是多少？</li><li id="1a2e" class="mg mh je kd b ke mp ki mq km mr kq ms ku mt ky ml mm mn mo bi translated">我们能预测未来的阳性病例吗？</li><li id="e132" class="mg mh je kd b ke mp ki mq km mr kq ms ku mt ky ml mm mn mo bi translated">病毒轨迹是怎样的？随着时间的推移，病毒是如何传播的？</li></ul><p id="9faa" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如前所述，在本文中，我们将探讨该病毒最初是如何在法国和韩国传播的，并通过聚类分析对两者进行比较。</p><p id="bb64" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">聚类分析的任务是对一组对象进行分组，使同一组(称为聚类)中的对象比其他组(聚类)中的对象更相似(在某种意义上)。</p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="8fde" class="mu lj je bd lk mv mw mx ln my mz na lq nb nc nd lt ne nf ng lw nh ni nj lz nk bi translated">步骤1 —我们的数据集</h1><p id="b4ad" class="pw-post-body-paragraph kb kc je kd b ke mb kg kh ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky im bi translated">有两个数据集分别包含法国和韩国的类似信息。所以，我们的想法是合并这些数据集，看看我们是否能找到有意义的聚类。<br/>我们可以在这里找到数据的链接:</p><ul class=""><li id="05c9" class="mg mh je kd b ke kf ki kj km mi kq mj ku mk ky ml mm mn mo bi translated">法兰西🇫🇷:<a class="ae lh" href="https://www.kaggle.com/lperez/coronavirus-france-dataset" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/lperez/coronavirus-france-dataset</a></li><li id="b801" class="mg mh je kd b ke mp ki mq km mr kq ms ku mt ky ml mm mn mo bi translated">南韩🇰🇷:<a class="ae lh" href="https://www.kaggle.com/kimjihoo/coronavirusdataset" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/kimjihoo/coronavirusdataset</a></li></ul><p id="7cfe" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">让我们首先对我们将在这里使用的库进行一些初始设置。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="6df3" class="li lj je nq b gy nu nv l nw nx">import pandas as pd<br/>import numpy as np<br/>import random<br/>from sklearn import preprocessing<br/>from sklearn.cluster import KMeans<br/>import matplotlib.pyplot as plt<br/>from kneed import KneeLocator<br/>from matplotlib import cm<br/>from mpl_toolkits.mplot3d import Axes3D</span></pre><p id="a3d5" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我推荐你看看这篇关于熊猫图书馆和数据清理的文章。</p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="30db" class="mu lj je bd lk mv mw mx ln my mz na lq nb nc nd lt ne nf ng lw nh ni nj lz nk bi translated">步骤2 —检查数据质量</h1><p id="b0c6" class="pw-post-body-paragraph kb kc je kd b ke mb kg kh ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky im bi translated">在深入挖掘之前，我们必须探索我们的数据集，看看它看起来像什么，以及我们希望如何开始我们的分析。</p><p id="d2e4" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">首先，我们将检查空值。我们将加载两个数据集，并查看找到多少空(NA)值。</p><p id="be13" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf"> <em class="lg"> NA </em> </strong> <em class="lg">值对应缺失或空信息。</em></p><p id="9970" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">根据我们的发现，我们可能需要为每个特定的列做出一些决定，以便为分析准备数据。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="98ff" class="li lj je nq b gy nu nv l nw nx">def load_data(data_path):<br/>    <!-- -->df = pd.read_csv(data_path + '/patient.csv')<br/>    <!-- -->df['released_date'] = pd.to_datetime(df['released_date'])<br/>    <!-- -->df['confirmed_date'] = pd.to_datetime(df['confirmed_date'])<br/>    <!-- -->df['month'] = df['confirmed_date'].dt.month<br/>    <!-- -->df['day'] = df['confirmed_date'].dt.day<br/>    <!-- -->return df</span><span id="1e62" class="li lj je nq b gy ny nv l nw nx">df_france = load_data('coronavirusdataset_france')<br/>df_france.isnull().sum()</span></pre><p id="54b6" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们会得到:</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="e0b2" class="li lj je nq b gy nu nv l nw nx">id                  2067<br/>sex                 1851<br/>birth_year          1936<br/>country                1<br/>region                 1<br/>department          195<br/>city                1804<br/>group               1905<br/>infection_reason    1906<br/>infection_order     2068<br/>infected_by         2056<br/>contact_number      2073<br/>confirmed_date         4<br/>released_date       2064<br/>deceased_date       2048<br/>status              1481<br/>health              1849<br/>source               199<br/>comments            1637<br/>month                  4<br/>day                    4<br/>dtype: int64</span></pre><p id="3cef" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">接下来，我们将检查韩国。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="481f" class="li lj je nq b gy nu nv l nw nx">df_south_korea = load_data('coronavirusdataset_south_korea')<br/>df_south_korea.isnull().sum()</span></pre><p id="9399" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们发现以下数据</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="43d7" class="li lj je nq b gy nu nv l nw nx">patient_id             0<br/>sex                 7190<br/>birth_year          7203<br/>country                0<br/>region              7432<br/>disease             7841<br/>group               7783<br/>infection_reason    7715<br/>infection_order     7833<br/>infected_by         7799<br/>contact_number      7816<br/>confirmed_date         0<br/>released_date       7813<br/>deceased_date       7833<br/>state                  0<br/>month                  0<br/>day                    0<br/>dtype: int64</span></pre></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="feae" class="mu lj je bd lk mv mw mx ln my mz na lq nb nc nd lt ne nf ng lw nh ni nj lz nk bi translated">步骤3-解决缺失值</h1><p id="482d" class="pw-post-body-paragraph kb kc je kd b ke mb kg kh ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky im bi translated">为了只保留必要的数据，应该删除一些列，比如department、comments和health，因为它们对于这个特定的分析并不重要。</p><p id="116f" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们将填充出生年份的缺失值。这个过程被称为数据插补。</p><p id="2ec1" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">通过使用出生日期，我们可以创建年龄变量，将其减去实际日期。缺失的信息将用从分布中抽取的随机数来填充。考虑到每个国家的人口统计数据，可以填写与人口年龄分布相关的信息:</p><ul class=""><li id="70d1" class="mg mh je kd b ke kf ki kj km mi kq mj ku mk ky ml mm mn mo bi translated">法兰西🇫🇷: <a class="ae lh" href="https://www.indexmundi.com/south_korea/demographics_profile.html" rel="noopener ugc nofollow" target="_blank">人口统计</a></li><li id="0d26" class="mg mh je kd b ke mp ki mq km mr kq ms ku mt ky ml mm mn mo bi translated">南韩🇰🇷: <a class="ae lh" href="https://www.indexmundi.com/south_korea/demographics_profile.html" rel="noopener ugc nofollow" target="_blank">人口统计</a></li></ul><p id="a86e" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">创建“simulate_age”函数是为了根据可用数据模拟人口年龄。在这种情况下，有了每个年龄的范围和占总人口的百分比，我们可以使用均匀分布来模拟每个范围的年龄分布。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="048f" class="li lj je nq b gy nu nv l nw nx">df_france.drop(['departement','region','comments', 'id', 'infected_by','health','city','source'],axis=1,inplace=True)</span><span id="c010" class="li lj je nq b gy ny nv l nw nx">df_south_korea.drop(['region','disease','patient_id','infected_by'], axis=1, inplace=True)</span><span id="b882" class="li lj je nq b gy ny nv l nw nx">def simulate_age(ranges, percents, total_pop):<br/>    simulated_pop = np.array(0)<br/>    for (low, high), percent in zip(ranges, percents):<br/>        simulated_pop = np.append(simulated_pop, <br/>                  np.random.randint(low=low, high=high, size=int(total_pop*percent/100)))<br/>return simulated_pop</span><span id="4710" class="li lj je nq b gy ny nv l nw nx"><em class="lg">#France</em><br/>france_population = 67364357<br/>'''<br/>0-14 years: 18.48% <br/>15-24 years: 11.8% <br/>25-54 years: 37.48% <br/>55-64 years: 12.42%<br/>65 years and over: 19.82%<br/>'''<br/>ranges = [(0,14),(15,24),(25,54),(55,64),(65,90)]<br/>percents = [18.48,11.8,37.48,12.42,19.82]<br/>france_simulated_pop = simulate_age(ranges, percents, france_population) f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))<br/>ax1.hist(france_simulated_pop,bins=20, color='mediumaquamarine', edgecolor='k', alpha=0.5)ax1.set_title('France - Simulated age distribution')</span><span id="c05e" class="li lj je nq b gy ny nv l nw nx">#South Korea<br/>south_korea_population = 51418097<br/>'''<br/>0-14 years: 13.03% <br/>15-24 years: 12.19%<br/>25-54 years: 45.13%<br/>55-64 years: 15.09% <br/>65 years and over: 14.55% <br/>'''<br/>percents = [13.03,12.19,45.13,15.09,14.55]<br/>south_korea_simulated_pop = simulate_age(ranges, percents, south_korea_population)<br/>ax2.hist(south_korea_simulated_pop,bins=20, color='mediumaquamarine', edgecolor='k', alpha=0.5)<br/>ax2.set_title('South Korea - Simulated age distribution')</span><span id="322d" class="li lj je nq b gy ny nv l nw nx">plt.show()</span></pre><figure class="nl nm nn no gt iv gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/8827752c8ba99ef8a5adccd3ee625657.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/0*5GILY5_dPrxyFvi-"/></div></figure><p id="e997" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在，我们可以在数据框中创建一个年龄列，并用从我们刚刚模拟的分布中选择的随机值填充缺失值。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="0f13" class="li lj je nq b gy nu nv l nw nx">import math<br/>actual_year = pd.to_datetime('today').year</span><span id="7690" class="li lj je nq b gy ny nv l nw nx">def calculate_age(x):<br/>    if math.isnan(x):<br/>        return x<br/>    else:return int(actual_year - x)</span><span id="68a2" class="li lj je nq b gy ny nv l nw nx">#France<br/>df_france['age'] = df_france['birth_year'].apply(calculate_age)<br/>df_france.fillna({'age':int(random.choice(france_simulated_pop))}, inplace=True)<br/>df_france.drop(['birth_year'], axis=1, inplace=True)</span><span id="7f12" class="li lj je nq b gy ny nv l nw nx">#South Korea<br/>df_south_korea['age'] = df_south_korea['birth_year'].apply(calculate_age)<br/>df_south_korea.fillna({'age':int(random.choice(south_korea_simulated_pop))}, inplace=True)<br/>df_south_korea.drop(['birth_year'], axis=1, inplace=True)</span></pre><p id="03eb" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">对于缺失的性别值，我们可以根据每个人群的性别比例，用一个概率值来画一个随机数。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="486f" class="li lj je nq b gy nu nv l nw nx">'''<br/>Considering m as men and w as women. <br/>m/w=ratio -&gt; m=ration*w<br/>m+w=total_pop<br/>'''<br/>def calculate_values(ratio, total_pop):<br/>    w = (france_population/(1+ratio))/total_pop<br/>    m = 1 - w<br/>    return (w,m)</span><span id="03c6" class="li lj je nq b gy ny nv l nw nx"># 0 (woman) and 1 (man) with the calculated probabilities<br/># France<br/># total population: 0.96 male(s)/female (2018 est.)</span><span id="d9c6" class="li lj je nq b gy ny nv l nw nx">w,m = calculate_values(0.96, france_population)<br/>df_france['sex'] = df_france['sex'].str.lower()<br/>df_france["sex"].replace({"male\xa0?": "male"}, inplace=True)<br/>df_france.fillna({'sex': np.random.choice(['female','male'],p=[w,m])}, inplace=True)</span><span id="1953" class="li lj je nq b gy ny nv l nw nx"># South Korea<br/># total population: 1 male(s)/female (2018 est.)</span><span id="714b" class="li lj je nq b gy ny nv l nw nx">w,m = calculate_values(1, south_korea_population)<br/>df_south_korea['sex'] = df_south_korea['sex'].str.lower()<br/>df_south_korea["sex"].replace({"male\xa0?": "male"}, inplace=True)<br/>df_south_korea.fillna({'sex': np.random.choice(['female','male'],p=[w,m])}, inplace=True)</span><span id="9ad4" class="li lj je nq b gy ny nv l nw nx"># France<br/># total population: 0.96 male(s)/female (2018 est.)</span><span id="0ae3" class="li lj je nq b gy ny nv l nw nx">w,m = calculate_values(0.96, france_population)<br/>df_france['sex'] = df_france['sex'].str.lower()<br/>df_france["sex"].replace({"male\xa0?": "male"}, inplace=True)<br/>df_france.fillna({'sex': np.random.choice(['female','male'],p=[w,m])}, inplace=True)</span><span id="1fa8" class="li lj je nq b gy ny nv l nw nx"># South Korea<br/># total population: 1 male(s)/female (2018 est.)</span><span id="0c5a" class="li lj je nq b gy ny nv l nw nx">w,m = calculate_values(1, south_korea_population)<br/>df_south_korea['sex'] = df_south_korea['sex'].str.lower()<br/>df_south_korea['sex'].replace({"male\xa0?": "male"}, inplace=True)<br/>df_south_korea.fillna({'sex': np.random.choice(['female','male'],p=[w,m])}, inplace=True)</span></pre><p id="ce5c" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">由于法国数据集的status列和韩国数据集的state列具有相同的含义，我们可以重命名其中一个数据集的列，并将值更新为相同的类别。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="dcae" class="li lj je nq b gy nu nv l nw nx">df_france.rename({'status':'state'}, axis=1, inplace=True)<br/>df_france['state'] = df_france['state'].apply(lambda x: 'isolated' if (x=='hospital' or x=='home isolation') else x)</span></pre><p id="39b8" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">此外:</p><ul class=""><li id="ff27" class="mg mh je kd b ke kf ki kj km mi kq mj ku mk ky ml mm mn mo bi translated">国家变量的空值将分别用法国或韩国填充。</li><li id="ea4d" class="mg mh je kd b ke mp ki mq km mr kq ms ku mt ky ml mm mn mo bi translated">将为感染原因、组、状态变量创建一个新类别“未知”</li><li id="bbba" class="mg mh je kd b ke mp ki mq km mr kq ms ku mt ky ml mm mn mo bi translated">为infection_order添加了一个新类别，代码为0</li><li id="1194" class="mg mh je kd b ke mp ki mq km mr kq ms ku mt ky ml mm mn mo bi translated">联系号码的空值将用0填充</li></ul><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="5ed7" class="li lj je nq b gy nu nv l nw nx">df_france.fillna({'country':'France','infection_reason':'Unknown','group':'Unknown', 'state':'Unknown','infection_order':0, 'contact_number':0} , inplace=True)</span><span id="69a7" class="li lj je nq b gy ny nv l nw nx">df_south_korea.fillna({'infection_reason':'Unknown','group':'Unknown', 'infection_order':0, 'contact_number':0, 'state':'Unknown'} , inplace=True)</span></pre><p id="6181" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在，让我们检查一下是否还有需要解决的缺失值。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="eeff" class="li lj je nq b gy nu nv l nw nx">df_france.isnull().sum()</span><span id="036f" class="li lj je nq b gy ny nv l nw nx">sex                    0<br/>country                0<br/>group                  0<br/>infection_reason       0<br/>infection_order        0<br/>contact_number         0<br/>confirmed_date         4<br/>released_date       2064<br/>deceased_date       2048<br/>state                  0<br/>month                  4<br/>day                    4<br/>age                    0<br/>dtype: int64<br/></span><span id="ab29" class="li lj je nq b gy ny nv l nw nx">df_south_korea.isnull().sum()</span><span id="cd8d" class="li lj je nq b gy ny nv l nw nx">sex                    0<br/>country                0<br/>group                  0<br/>infection_reason       0<br/>infection_order        0<br/>contact_number         0<br/>confirmed_date         0<br/>released_date       7813<br/>deceased_date       7833<br/>state                  0<br/>month                  0<br/>day                    0<br/>age                    0<br/>dtype: int64</span></pre><p id="071d" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">干得好！我们剩下的不多了。现在我们需要解析released_date和dead _ date空值。</p><ul class=""><li id="e4e3" class="mg mh je kd b ke kf ki kj km mi kq mj ku mk ky ml mm mn mo bi translated">如果released_date为空，则意味着此人仍携带病毒。</li><li id="9cf3" class="mg mh je kd b ke mp ki mq km mr kq ms ku mt ky ml mm mn mo bi translated">如果dead _ date为空，则表示此人没有死亡。</li></ul><p id="e5ec" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们可以计算感染持续时间(以天为单位)并去除其他3个变量。此外，我们希望将death _ date转换为一个二进制列，指示该人是否已经死亡。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="9db2" class="li lj je nq b gy nu nv l nw nx">df_france['released_date'] = df_france[['released_date','deceased_date']].fillna(df_france['deceased_date'])<br/>df_france['released_date'] = df_france[['released_date']].fillna(pd.to_datetime('today'))<br/>df_france['infection_duration'] = pd.to_datetime(df_france['released_date']).sub(df_france['confirmed_date'], axis=0)</span><span id="511e" class="li lj je nq b gy ny nv l nw nx">df_france = df_france[df_france['infection_duration'].dt.days&gt;=0]<br/>df_france['infection_duration'] = df_france['infection_duration'].dt.days<br/>df_france.drop(['released_date','confirmed_date','deceased_date'], axis=1, inplace=True)<br/>df_south_korea['released_date'] = df_south_korea[['released_date','deceased_date']].fillna(df_south_korea['deceased_date'])<br/>df_south_korea['released_date'] = df_south_korea[['released_date']].fillna(pd.to_datetime('today'))</span><span id="a0c5" class="li lj je nq b gy ny nv l nw nx">df_south_korea['infection_duration'] = pd.to_datetime(df_south_korea['released_date']).sub(df_south_korea['confirmed_date'], axis=0)<br/>df_south_korea = df_south_korea[df_south_korea['infection_duration'].dt.days&gt;=0]</span><span id="5b05" class="li lj je nq b gy ny nv l nw nx">df_south_korea['infection_duration'] = df_south_korea['infection_duration'].dt.days</span><span id="fd17" class="li lj je nq b gy ny nv l nw nx">df_france.columns<br/>Index(['sex', 'country', 'group', 'infection_reason',<br/>'infection_order','contact_number', 'state', 'month', <br/>'day', 'age', 'infection_duration'], dtype='object')</span><span id="453b" class="li lj je nq b gy ny nv l nw nx">df_south_korea.columns<br/>Index(['sex', 'country', 'group', 'infection_reason',<br/>'infection_order', 'contact_number', 'state', 'month', <br/>'day', 'age', 'infection_duration'], dtype='object')</span></pre></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="b5d7" class="mu lj je bd lk mv mw mx ln my mz na lq nb nc nd lt ne nf ng lw nh ni nj lz nk bi translated">步骤4 —数据融合</h1><p id="2966" class="pw-post-body-paragraph kb kc je kd b ke mb kg kh ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky im bi translated">最后，我们准备将两个数据集放在一起，开始我们的分析。</p><p id="cda0" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">最后，我们准备将两个数据集放在一起，开始我们的分析。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="d21c" class="li lj je nq b gy nu nv l nw nx">df = df_france.append(df_south_korea, sort=False)<br/>df.isnull().sum()</span><span id="4a26" class="li lj je nq b gy ny nv l nw nx">sex                   0<br/>country               0<br/>group                 0<br/>infection_reason      0<br/>infection_order       0<br/>contact_number        0<br/>state                 0<br/>month                 0<br/>day                   0<br/>age                   0<br/>infection_duration    0<br/>dtype: int64</span></pre><h1 id="8113" class="mu lj je bd lk mv oa mx ln my ob na lq nb oc nd lt ne od ng lw nh oe nj lz nk bi translated">虚拟编码</h1><p id="a0d8" class="pw-post-body-paragraph kb kc je kd b ke mb kg kh ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky im bi translated">模型的输入必须是数值。因此，我们必须将分类变量转换成数字。由于类别没有顺序，我们将把每个类别值转换成一个二进制列(0或1值)。这种技术被称为虚拟编码。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="3cba" class="li lj je nq b gy nu nv l nw nx">df = pd.concat([df, pd.get_dummies(df['sex'])], axis=1)<br/>df = pd.concat([df, pd.get_dummies(df['country'])], axis=1)<br/>df = pd.concat([df, pd.get_dummies(df['state'], drop_first=True)], axis=1)<br/>df = pd.concat([df, pd.get_dummies(df['infection_reason'], drop_first=True)], axis=1)<br/>df = pd.concat([df, pd.get_dummies(df['group'], drop_first=True)], axis=1)</span></pre><h1 id="b792" class="mu lj je bd lk mv oa mx ln my ob na lq nb oc nd lt ne od ng lw nh oe nj lz nk bi translated">降维</h1><p id="9923" class="pw-post-body-paragraph kb kc je kd b ke mb kg kh ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky im bi translated">当我们应用哑编码时，我们最终会有更多的变量，因为每个类别都被转换成一个列。</p><p id="5c45" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">因为我们有太多的变量，所以很难在聚类中找到模式。首先，我们可以通过分组相似的类别来减少分类变量的数量。第二，我们可以应用降维技术来减少输入变量的数量，使模型更容易解释。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="c0f7" class="li lj je nq b gy nu nv l nw nx">df = df_france.append(df_south_korea, sort=False)</span></pre><p id="4cd2" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">Transform infection_reason:我们将列出这个变量所有可能的值，并对它们进行分组。之后，我们会将类似的原因分组，并将其转换为虚拟变量。最后，我们将删除原来的列。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="54de" class="li lj je nq b gy nu nv l nw nx">df.infection_reason.unique()</span><span id="de29" class="li lj je nq b gy ny nv l nw nx">array(['visit to Italy', 'contact with patient', 'visit to Mulhouse religious gathering', 'Unknown', 'contact with person who visited Italy', 'visit to Egypt', 'unknown', 'Visit to Venice, Italy', 'contact with patient in Auray', 'visit to Mulhouse', 'visit to Milan', 'Italian', 'visit to Lombardy', 'parishioner', 'Creil military base\xa0?', 'visit to Senegal', 'visit to Alsace', 'visit in Lombardy', 'visit to Bretagne', 'Visit in Italy', 'In contact with someone contamitaminated in Oise', 'Religious Meeting in Mulhouse', 'work in a medical environment ', 'Visit family in Oise', 'health professional', 'visit to Wuhan', 'contact with patient in Japan', 'residence in Wuhan', 'visit to Thailand', 'contact with patient in Singapore', 'visit to China', 'visit to Daegu', 'pilgrimage to Israel', 'contact with patient in Daegu', 'visit to Vietnam', 'visit to Japan', 'visit to ooo'], dtype=object)</span><span id="5110" class="li lj je nq b gy ny nv l nw nx">def transform_reason(value):<br/>    if ('religious' in value or 'parishioner' in value):<br/>        return 'religious'<br/>    elif ('visit' in value or 'residence' in value):<br/>        return 'visit'<br/>    elif ('contact' in value):<br/>        return 'contact'<br/>    elif ('medical' in value or 'health professional' in value):<br/>        return 'medical'<br/>    elif ('militar' in value):<br/>        return 'militar'<br/>    elif ('italian' in value):<br/>        return 'italian'<br/>    elif ('pilgrimage' in value):<br/>        return 'pilgrimage'<br/>    else:<br/>        return 'unknown'</span><span id="512f" class="li lj je nq b gy ny nv l nw nx">df['infection_reason'] = df['infection_reason'].str.lower()<br/>df['infection_reason'] = df['infection_reason'].apply(transform_reason)  <br/>df = pd.concat([df, pd.get_dummies(df['infection_reason'], prefix='infection_reason', prefix_sep='_')], axis=1)<br/>df.drop(['infection_reason_unknown'], axis=1, inplace=True)</span></pre><p id="8713" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">此外,“group”变量提供了与infection_reson类似的信息。我们可以很容易地移除它。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="9a70" class="li lj je nq b gy nu nv l nw nx">df.drop(['group'], axis=1, inplace=True)</span></pre><p id="f488" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在，我们可以将其他分类变量转换成虚拟变量:国家、州和性别。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="80c8" class="li lj je nq b gy nu nv l nw nx">df = pd.concat([df, pd.get_dummies(df['country'])], axis=1)<br/>df = pd.concat([df, pd.get_dummies(df['state'], prefix='state', prefix_sep='_')], axis=1)<br/>df = pd.concat([df, pd.get_dummies(df['sex'])], axis=1)</span></pre><h1 id="d452" class="mu lj je bd lk mv oa mx ln my ob na lq nb oc nd lt ne od ng lw nh oe nj lz nk bi translated">主成分分析</h1><p id="a48e" class="pw-post-body-paragraph kb kc je kd b ke mb kg kh ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky im bi translated">现在，我们将为一项非常强大的技术准备数据:主成分分析(PCA)。</p><p id="c424" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这种技术找到解释数据的原始变量的线性组合。主要目标是通过寻找新的变量“组件”来减少变量的数量。它基于正交向量，这使得这些分量不相关。</p><p id="abee" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们需要定义哪些变量是输入，并删除我们从中创建虚拟变量的变量(它们是多余的)。</p><p id="0a27" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">此外，有必要将我们的数据标准化，为此我们使用StandardScaler。标准化数据意味着将所有变量放在同一尺度上，以避免累积的数值误差。只有这样，我们才能比较数据点之间的距离。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="2210" class="li lj je nq b gy nu nv l nw nx">features = df.drop(['country','state','sex','infection_reason'], axis=1)<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.decomposition import PCA<br/>x = StandardScaler().fit_transform(features.values)<br/>pca = PCA(random_state=20)<br/>pca.fit(x)</span><span id="00d9" class="li lj je nq b gy ny nv l nw nx"><br/>PCA(copy=True, iterated_power='auto', n_components=None, random_state=20, svd_solver='auto', tol=0.0, whiten=False)</span></pre><p id="e017" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">为了确定组件的数量，我们需要查看每个组件的解释方差。<br/>以解释最大方差的方式计算组件。例如，我们将添加组件，直到达到解释的方差的定义阈值。典型地，阈值在0.7和0.9之间。这意味着它解释了70%到90%的差异。</p><p id="5c78" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在这种情况下，我们将选择0.8作为阈值。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="9dd8" class="li lj je nq b gy nu nv l nw nx"># determine number of components with threshold=0.8</span><span id="e1f4" class="li lj je nq b gy ny nv l nw nx">n_components=np.where(np.cumsum(pca.explained_variance_ratio_)&gt;0.8)[0][0]+1</span><span id="d10e" class="li lj je nq b gy ny nv l nw nx"># explained variance<br/>v = round(np.cumsum(pca.explained_variance_ratio_)[n_components-1]*100,1)<br/>print(f'It is needed {n_components} components to explain {v}% variance of the data')</span></pre><p id="dcdb" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们需要12个分量来解释数据的83.1%的方差</p><p id="00ee" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在我们有了一些组件，我们可以计算这些新变量的值。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="7908" class="li lj je nq b gy nu nv l nw nx">pca = PCA(n_components=n_components, random_state=20)<br/>pcs = pca.fit(x)<br/>components_name = list(range(0, n_components))<br/>components_name = list(map(lambda x: 'PC' + str(x), components_name))<br/>pd.DataFrame(data=pcs.components_, columns = features.columns, index=components_name)</span></pre><figure class="nl nm nn no gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi of"><img src="../Images/4150a90d49478c3a35790e537b47dfc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*j1rtLkmktbhWcWNp"/></div></div></figure><p id="b3d8" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们可以用一个矩阵来显示每个变量对每个组成部分的重要性。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="74ef" class="li lj je nq b gy nu nv l nw nx">components_range = np.arange(1, n_components+1, 1)<br/>components_names = list(map(lambda x: 'PC' + str(x), components_range))<br/>plt.matshow(pcs.components_,cmap='viridis')<br/>plt.yticks(range(0,n_components), components_names,fontsize=10)<br/>plt.colorbar()<br/>plt.xticks(range(0,len(features.columns)),features.columns,rotation=90,ha='left')</span><span id="9400" class="li lj je nq b gy ny nv l nw nx">plt.show()</span></pre><figure class="nl nm nn no gt iv gh gi paragraph-image"><div class="gh gi og"><img src="../Images/6a351097be88aae7bbd237636f818924.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/0*zrBYTd5aivAsRoWe"/></div></figure><p id="9172" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">变量的值越高，意味着主成分的影响越大。较低的值意味着对主成分的负面影响。<br/>因此，根据热图，主成分分析的一种可能解释是:</p><ul class=""><li id="d28b" class="mg mh je kd b ke kf ki kj km mi kq mj ku mk ky ml mm mn mo bi translated">PC1:男性不是孤立的，也不是朝鲜人</li><li id="9656" class="mg mh je kd b ke mp ki mq km mr kq ms ku mt ky ml mm mn mo bi translated">PC2:第一个月</li><li id="d400" class="mg mh je kd b ke mp ki mq km mr kq ms ku mt ky ml mm mn mo bi translated">PC3:国家释放</li><li id="9821" class="mg mh je kd b ke mp ki mq km mr kq ms ku mt ky ml mm mn mo bi translated">PC4:状态死者</li><li id="fdb2" class="mg mh je kd b ke mp ki mq km mr kq ms ku mt ky ml mm mn mo bi translated">PC5:感染原因宗教</li><li id="bc10" class="mg mh je kd b ke mp ki mq km mr kq ms ku mt ky ml mm mn mo bi translated">PC6:感染原因访问</li><li id="4581" class="mg mh je kd b ke mp ki mq km mr kq ms ku mt ky ml mm mn mo bi translated">PC7:感染原因意大利语</li><li id="c440" class="mg mh je kd b ke mp ki mq km mr kq ms ku mt ky ml mm mn mo bi translated">PC8:感染原因军事</li><li id="0270" class="mg mh je kd b ke mp ki mq km mr kq ms ku mt ky ml mm mn mo bi translated">PC9:感染原因医疗</li><li id="e41f" class="mg mh je kd b ke mp ki mq km mr kq ms ku mt ky ml mm mn mo bi translated">PC10:感染原因朝圣</li><li id="e0ba" class="mg mh je kd b ke mp ki mq km mr kq ms ku mt ky ml mm mn mo bi translated">PC11:高感染顺序</li><li id="a8f2" class="mg mh je kd b ke mp ki mq km mr kq ms ku mt ky ml mm mn mo bi translated">PC12:来自蒙古国</li></ul></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="ce74" class="mu lj je bd lk mv mw mx ln my mz na lq nb nc nd lt ne nf ng lw nh ni nj lz nk bi translated">步骤5 — K均值聚类</h1><p id="005a" class="pw-post-body-paragraph kb kc je kd b ke mb kg kh ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky im bi translated">K-means试图将数据分成k个组，其中一个组的元素彼此接近。该方法基于数据点之间的距离。<br/>因此，目标是最小化点到质心的距离。质心是每个簇/组的“中间”点。</p><p id="f8b5" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">该算法从随机选择的质心开始，在每次迭代中，它重新计算质心的位置。</p><p id="fc7d" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">为了确定k，即组的数量，我们使用了一个图来显示数据相对于分类数量的失真。这种方法被称为肘测试。失真被定义为到聚类中心的平均距离。扭曲开始以线性方式减少的点是肘部，这表示最佳的群集数量。这意味着添加另一个集群不会改变太多的失真。</p><p id="fa42" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">让我们根据主成分得分创建一个数据框架，并将其用于聚类分析。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="62d1" class="li lj je nq b gy nu nv l nw nx">pca_df = pd.DataFrame(data = pca.fit_transform(x), columns = components_names)<br/>pca_df.head()</span></pre><figure class="nl nm nn no gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi of"><img src="../Images/aaa6dae370329ea426afc3e23e14267e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*A-QNpvZG34MQP5AN"/></div></div></figure><p id="ba57" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">使用弯头测试来确定最佳聚类数。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="75fd" class="li lj je nq b gy nu nv l nw nx">def elbow_test(df, n_init, max_clusters, max_iter):<br/>    distortions = []<br/>    for i in range(1, max_clusters):<br/>        km = KMeans(<br/>            n_clusters=i, init='random',<br/>            n_init=n_init, max_iter=max_iter,<br/>            tol=1e-04, random_state=20<br/>        )<br/>        km.fit(df)<br/>        distortions.append(km.inertia_)<br/>plt.plot(range(1, max_clusters), distortions, marker='o')<br/>    plt.xlabel('Number of clusters')<br/>    plt.ylabel('Distortion')<br/>    plt.show()</span><span id="048a" class="li lj je nq b gy ny nv l nw nx">kn = KneeLocator(<br/>        range(1, max_clusters),<br/>        distortions,<br/>        curve='convex',<br/>        direction='decreasing',<br/>        interp_method='interp1d',<br/>    )<br/>    return kn.knee</span><span id="189f" class="li lj je nq b gy ny nv l nw nx">n_clusters = elbow_test(pca_df, 10, 20, 300)<br/>print(f'the optimal number of clusters is {n_clusters}')</span></pre><figure class="nl nm nn no gt iv gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/3e19226ed83300faff00a4561ec0de15.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/0*54YuCqmsF1mJ70XC"/></div></figure><p id="bc53" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">根据我们的分析，最佳的聚类数是4</p><p id="1372" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们将知道用四个集群运行K-means算法，看看我们会发现什么！</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="7765" class="li lj je nq b gy nu nv l nw nx">km = KMeans(n_clusters=n_clusters, random_state=20)<br/>y = km.fit_predict(pca_df)<br/>idx = np.argsort(km.cluster_centers_.sum(axis=1))<br/>lut = np.zeros_like(idx)<br/>lut[idx] = np.arange(n_clusters)<br/>pca_df['cluster'] = lut[km.labels_]<br/>df['cluster'] = lut[km.labels_]</span></pre><p id="9e2e" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们可以用下面的代码保存/加载我们的模型:</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="71b7" class="li lj je nq b gy nu nv l nw nx">import pickle   <br/>pickle.dump(km, open('kmeans_model.sav', 'wb'))</span><span id="ec13" class="li lj je nq b gy ny nv l nw nx"># Load<br/>km = pickle.load(open('kmeans_model.sav', 'rb'))</span><span id="ba72" class="li lj je nq b gy ny nv l nw nx">pca_df[pca_df['cluster']==3]</span></pre><figure class="nl nm nn no gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi of"><img src="../Images/29f890f93c30c2979bf620899cea1782.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*A3Sf5bzeBkamVJ-w"/></div></div></figure><p id="d4ef" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们可以看到PC7值很高。它对应于感染原因“意大利语”。我们可以通过查看实际数据来证实这一点:</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="f6d6" class="li lj je nq b gy nu nv l nw nx">df[df['cluster']==3]</span></pre><figure class="nl nm nn no gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi of"><img src="../Images/ae545da7716536f97bbfffc5d1331467.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vf9h_m8fxirF7rDn"/></div></div></figure><p id="ecf3" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">以下函数将绘制我们的数据。</p><p id="296c" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">第一个是散点图，用于比较两个主成分，并查看它们之间的聚类分布情况。第二个创建了一个3d图来比较由聚类着色的三个主成分。</p><p id="d9de" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这些图表将帮助我们确定聚类的含义。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="5ca2" class="li lj je nq b gy nu nv l nw nx">def draw_scatter(df, col_1, col_2, cluster_column, num_clusters, title):<br/>    fig = plt.figure(figsize=(10,10))<br/>    ax = fig.add_subplot(111)<br/>    ax.set_title(title)<br/>    ax.set_xlabel(col_1)<br/>    ax.set_ylabel(col_2)<br/>    labels = list(range(0,num_clusters))<br/>    colors = plt.cm.Spectral(np.linspace(0, 1, num_clusters))<br/>    axs = []<br/>    for i in labels:<br/>        axs.append(ax.scatter(df[df[cluster_column]==i][col_1], df[df[cluster_column]==i][col_2], cmap=colors[I]))</span><span id="84cb" class="li lj je nq b gy ny nv l nw nx">ax.legend(axs, labels, loc='center', bbox_to_anchor=(0.92, 0.84), ncol=1)<br/>    plt.show()</span><span id="8e0f" class="li lj je nq b gy ny nv l nw nx">def create_3d_scatter(df, col_1, col_2, col_3, cluster_column, num_clusters, title):<br/>    fig = plt.figure()<br/>    ax = fig.add_subplot(111, projection='3d')<br/>    ax.set_title(title)<br/>    ax.set_xlabel(col_1)<br/>    ax.set_ylabel(col_2)<br/>    ax.set_zlabel(col_3, rotation=90)<br/>    labels = list(range(0,num_clusters))<br/>    colors = plt.cm.Spectral(np.linspace(0, 1, num_clusters))<br/>    axs = []<br/>    for i in labels:<br/>        d = df[df[cluster_column]==i]<br/>        axs.append(ax.scatter(d[col_1], d[col_2], d[col_3], cmap=colors[i]))<br/>    ax.legend(axs, labels, bbox_to_anchor=(0.2, 0.5), ncol=1)<br/>    ax.set_xticklabels([])<br/>    ax.set_yticklabels([])<br/>    ax.set_zticklabels([])<br/>    plt.show()</span><span id="5ae0" class="li lj je nq b gy ny nv l nw nx">create_3d_scatter(pca_df, 'PC1', 'PC2', 'PC3', 'cluster', n_clusters, '')</span></pre><figure class="nl nm nn no gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oi"><img src="../Images/18b12f047e277369fc4924468cdc21b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/0*Z6WQDu67jVGW6geN"/></div></div></figure><p id="e537" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们可以看到，一些集群是根据前两个主成分分布的。此外，PC3似乎对团簇的分离没有太大的影响。</p><p id="55f2" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在此表中，我们可以看到每个组件的值如何影响分类的意义。</p><figure class="nl nm nn no gt iv gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/f5a07962adba864b5f0c39ba81d808bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/0*YpjlxTmGOJHF9d12"/></div></figure><p id="0797" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">让我们画出PC1和PC2上的群集，以便更清楚地验证这一假设。</p><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="2db1" class="li lj je nq b gy nu nv l nw nx">draw_scatter(pca_df, 'PC1', 'PC2', 'cluster', n_clusters, 'Clusters - PC1/PC2')</span></pre><figure class="nl nm nn no gt iv gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/6fe3b74c883fe3f126dbc0494d25f71a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/0*H-zKixzWPyhxfZQh"/></div></figure><pre class="nl nm nn no gt np nq nr ns aw nt bi"><span id="ad5f" class="li lj je nq b gy nu nv l nw nx">draw_scatter(pca_df, 'PC1', 'PC3', 'cluster', n_clusters, 'Clusters - PC1/PC3')</span></pre><figure class="nl nm nn no gt iv gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/d8cc814a9189fd265ac371e1acd345e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/0*zNZORSDgFkGCKzYe"/></div></figure><p id="32e9" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">请记住，主要组件的含义定义如下:</p><ul class=""><li id="b9f8" class="mg mh je kd b ke kf ki kj km mi kq mj ku mk ky ml mm mn mo bi translated">PC1:不是孤立的，也不是韩国人</li><li id="0e8f" class="mg mh je kd b ke mp ki mq km mr kq ms ku mt ky ml mm mn mo bi translated">PC2:第一个月</li><li id="d010" class="mg mh je kd b ke mp ki mq km mr kq ms ku mt ky ml mm mn mo bi translated">PC3:国家释放</li></ul><p id="666e" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">因此，从图表中我们可以得出结论:</p><figure class="nl nm nn no gt iv gh gi paragraph-image"><div class="gh gi om"><img src="../Images/435f83ba255198470fc1357c46c195a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/0*7CXWT3i6jpMVlehj"/></div></figure><h1 id="881e" class="mu lj je bd lk mv oa mx ln my ob na lq nb oc nd lt ne od ng lw nh oe nj lz nk bi translated">结论</h1><p id="c695" class="pw-post-body-paragraph kb kc je kd b ke mb kg kh ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky im bi translated">聚类分析包括将对象放入独立的组(簇)，相似的对象放在同一个组中。物体之间的相似性是基于它们之间的距离，彼此靠近的物体有一些共同点。因此，接近的对象属于同一个集群。</p><p id="82c7" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在这种情况下，通过K-means发现的聚类显示，这些病例按照患者中的某些特征进行分组。这些特征集中在性别、感染原因、国家和月份等变量上。根据这些变量的值，数据点分布在聚类中。</p><p id="3dfd" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">聚类是具有相似特征的患者组。</p><p id="ae1c" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们发现的集群是:</p><figure class="nl nm nn no gt iv gh gi paragraph-image"><div class="gh gi on"><img src="../Images/6f8778785a5fcaaafad6fd7640676e15.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/0*aiszdTXf3pYSeaZj"/></div></figure><p id="f157" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">聚类0将3月份感染病毒的韩国女性患者分组。聚类1包含来自韩国但在其他月份感染病毒的另一组妇女。聚类2指的是来自法国的男性，聚类3将因为与来自意大利的人接触而感染病毒的患者分组。</p><p id="e99d" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">做这样的分析让我们对疫情有了更清晰的认识。尽管冠状病毒很快就脱离了我们的控制，但我们相信，随着更多数据的可用，我们可以做好准备，以便能够在未来做出更好的应对。</p></div></div>    
</body>
</html>