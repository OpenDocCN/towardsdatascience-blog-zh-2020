<html>
<head>
<title>Statistical pitfalls in data science</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据科学中的统计陷阱</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/statistical-pitfalls-in-data-science-ad76e8ec0584?source=collection_archive---------35-----------------------#2020-06-01">https://towardsdatascience.com/statistical-pitfalls-in-data-science-ad76e8ec0584?source=collection_archive---------35-----------------------#2020-06-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a745" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">刻板结果如何改变人们头脑中的数据分布</h2></div><p id="d953" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有很多方法可以从给定的数据集中推断出大量不同的结果，但是也有无限多的方法可以从中得出错误的结论。谬误可以定义为不准确或错误推理的产物，通常导致人们从给出的数据中获得不正确的结果。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/9fb39695feef15792669e9d87e689b3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z4zM4gSN1Pw-N8eJIaCEBw.jpeg"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">照片由<a class="ae lu" href="https://unsplash.com/s/photos/brain?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae lu" href="https://unsplash.com/@tjeff514719?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Tayla Jeffs </a>拍摄</p></figure><p id="c803" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">好的一面是，由于长期以来许多人都犯过这些错误，而且这些错误的结果在各个领域都有记载，因此识别和解释这些统计谬误就变得更加容易了。以下是数据科学家应该避免陷入的一些统计陷阱。</p><h2 id="95e9" class="lv lw it bd lx ly lz dn ma mb mc dp md kr me mf mg kv mh mi mj kz mk ml mm mn bi translated">樱桃采摘</h2><p id="3c75" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">这可能是最明显和最简单的谬误，也是我们大多数人以前肯定做过的事情。摘樱桃的直觉很简单:<strong class="kk iu">故意选择数据点来帮助支持一个特定的假设，以其他拒绝该命题的数据点为代价。</strong></p><blockquote class="mt"><p id="7d73" class="mu mv it bd mw mx my mz na nb nc ld dk translated">摘樱桃降低了实验发现的可信度，因为它只显示了画面的一面</p></blockquote><p id="0a6c" class="pw-post-body-paragraph ki kj it kk b kl nd ju kn ko ne jx kq kr nf kt ku kv ng kx ky kz nh lb lc ld im bi translated">摘樱桃不仅是对公众的不诚实和误导，也降低了实验发现的可信度，因为它本质上只显示了画面的一面，遮蔽了所有负面的方面。这会让一个实验看起来完全成功，但实际上并非如此。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ni"><img src="../Images/872bdbe24b5417adb42934be42adad1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*HE3ZLbCRZJYl08SgPYWL0Q.gif"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">精选数据与所有数据— <a class="ae lu" href="https://en.wikipedia.org/wiki/Cherry_picking" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="9e2d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">避免摘樱桃最简单的方法就是不摘！本质上，采摘樱桃是从业者有意为之，因此不是偶然的。在整理数据的过程中，为了进一步避免摘樱桃的可能性，人们应该使用来自大量不同背景的数据(尽可能地)来限制通常伴随有限视角而来的偏见。</p><h2 id="100a" class="lv lw it bd lx ly lz dn ma mb mc dp md kr me mf mg kv mh mi mj kz mk ml mm mn bi translated">数据挖掘</h2><p id="8776" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">大多数人(尤其是那些不熟悉数据科学细微差别的人)认为数据分析意味着从各种数据中挑选出明显的相关性。这并不完全正确，因为数据分析通常需要逻辑推理来解释为什么存在某种相关性。如果没有一个合理的解释，仍然存在着机会相关性的可能性。进行实验的传统方法是定义一个假设，然后检查数据来证明它。相比之下，数据挖掘是一种实践，即<strong class="kk iu">做出符合假设的偶然关联，而不对关联的原因提供任何逻辑见解</strong>。</p><blockquote class="mt"><p id="ac54" class="mu mv it bd mw mx my mz na nb nc ld dk translated">数据挖掘有时被描述为从数据集中寻找比它实际包含的更多的信息</p></blockquote><p id="edc3" class="pw-post-body-paragraph ki kj it kk b kl nd ju kn ko ne jx kq kr nf kt ku kv ng kx ky kz nh lb lc ld im bi translated">数据挖掘的一个分支是<strong class="kk iu">假因果关系</strong>，关于相关性的错误假设可能导致研究的最终失败。通常，两个事物之间的相关性会诱使我们相信一个事物导致了另一个事物，或者是由另一个事物导致的。然而，通常是巧合或其他外部因素导致一种或两种效应发生。数据科学家必须始终挖掘比表面上看起来更深的东西，超越简单的相关性，以收集证据来支持研究假设。</p><blockquote class="mt"><p id="e349" class="mu mv it bd mw mx my mz na nb nc ld dk translated">相关性并不意味着因果关系</p></blockquote><h2 id="51cf" class="lv lw it bd lx ly nj dn ma mb nk dp md kr nl mf mg kv nm mi mj kz nn ml mm mn bi translated">过度拟合</h2><p id="afed" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">过度拟合是大多数机器学习和数据科学从业者都很熟悉的一个术语。过度拟合是指<strong class="kk iu">创建一个极其复杂的模型的过程，该模型过度适应数据集，并且在一般化的数据上表现不佳。</strong></p><p id="81cd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">用机器学习的术语来说，当一个模型在训练集上表现得非常好，但在测试数据集上却不能给出类似的结果时，就会发生过度拟合。John Langford 给出了实践中最常见的过度拟合类型的全面描述，以及帮助避免它们的技术<a class="ae lu" href="https://hunch.net/?p=22" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi no"><img src="../Images/d35ec692ca798117f01c6c4d3a4b9552.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*NJnMs89pwUO9ZjORpXBohA.jpeg"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">数据过度拟合— <a class="ae lu" href="https://commons.wikimedia.org/wiki/File:Overfitted_Data.png" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="14ec" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">大多数数据科学家构建基于数学的模型来理解数据点之间的潜在关系和相关性。一个足够复杂的模型倾向于完美地拟合所提供的数据，给出高精度和最小的损失。也就是说，复杂的模型通常是脆弱的，当提供其他数据时会崩溃。简单模型通常更稳健，更善于根据给定数据进行预测。</p><h2 id="47f2" class="lv lw it bd lx ly lz dn ma mb mc dp md kr me mf mg kv mh mi mj kz mk ml mm mn bi translated">辛普森悖论</h2><p id="ef1c" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">辛普森悖论是一个很好的例子，它强调了在整理和实验数据时对真实世界良好直觉的需要。数据科学家需要认识并接受这样一个事实，即大多数数据是一个更大、更复杂的领域的有限表示。辛普森悖论展示了试图从单一角度看待复杂情况而将其过于简单化的危险。</p><p id="e32f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">辛普森悖论是以统计学家爱德华·休·辛普森的名字命名的，他在 1951 年的一篇技术论文中描述了以他名字命名的统计现象。陈述起来很简单，但对于没有接受过统计培训的受众来说，这往往是一个困惑的原因——当数据被分组时出现的趋势或结果，当数据被组合时，这种趋势或结果会逆转或消失。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi np"><img src="../Images/1133738347246616b8c207428cc46bc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*1r_s5QKOk2LRFjazaXghgA.gif"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">当数据按特定类别分组时，总体趋势发生逆转— <a class="ae lu" href="https://commons.wikimedia.org/wiki/File:Simpsons_paradox_-_animation.gif" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="85c2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一个简单的例子可以很好地解释辛普森悖论。假设我们选取了板球比赛中两个击球手 A 和 B 的击球得分。在我们收集的数据中，A 总体上比 B 得分更多。但是，如果我们查看 A 和 B 的终身统计数据，就会发现 B 比 A 得分更多。</p><p id="2058" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">辛普森悖论，在某些方面，可以认为是无意的摘樱桃。这通常是由分布中的一个变量引起的，这个变量被恰当地命名为<em class="nq">潜伏变量</em>，它将数据分割成多个独立的分布，而且它们通常很难识别。</p><blockquote class="mt"><p id="6a67" class="mu mv it bd mw mx my mz na nb nc ld dk translated">我们需要知道我们在寻找什么，并恰当地选择最佳的数据观点，给观众一个公正和完整的事实陈述</p></blockquote><p id="7162" class="pw-post-body-paragraph ki kj it kk b kl nd ju kn ko ne jx kq kr nf kt ku kv ng kx ky kz nh lb lc ld im bi translated">为了避免陷入辛普森悖论，数据科学家必须了解他们的数据，并对围绕和影响数据的一般因素有一个基本的概念。基于所有这些情况，应该以这样的方式收集和查看数据，即结果不仅美化假设(摘樱桃)，而且如果从独立的角度来看也不会改变。</p><h2 id="2f6d" class="lv lw it bd lx ly lz dn ma mb mc dp md kr me mf mg kv mh mi mj kz mk ml mm mn bi translated">生存偏差</h2><p id="cbc6" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">算法偏差最近获得了很多关注，并成为一个热门话题。然而，统计偏差和统计本身一样古老。生存偏差可以最好地描述为<strong class="kk iu">从不完整数据中得出结论</strong>。这些在使数据分析不准确方面起着至关重要的作用。</p><p id="e334" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当数据集中提供的数据先前已经经过过滤过程时，会出现生存偏差。这会导致错误的推论，并会影响大量的分析。意识到偏差通常在数据科学领域非常重要，因为人类倾向于研究成功的结果并从中得出推论，而忽略伴随的失败。</p><blockquote class="mt"><p id="29fd" class="mu mv it bd mw mx my mz na nb nc ld dk translated">只看成功的首席执行官，我们看不到完整的数据集，包括不成功的首席执行官和地球上可能碰巧早餐吃燕麦片的其他人</p></blockquote><p id="cf04" class="pw-post-body-paragraph ki kj it kk b kl nd ju kn ko ne jx kq kr nf kt ku kv ng kx ky kz nh lb lc ld im bi translated">由于生存偏差来自不完整的数据集和研究输入，数据科学家可以应用一些技术来避免生存偏差，同时从数据中进行推断。这些包括但不限于多个数据输入、假想场景、对数据的上下文理解以及测试时增加的数据。</p><h2 id="0095" class="lv lw it bd lx ly lz dn ma mb mc dp md kr me mf mg kv mh mi mj kz mk ml mm mn bi translated">赌徒谬误</h2><p id="3352" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">赌徒谬误是人类思维倾向于从数据中的常规相关性得出推论的另一个例子。赌徒谬误指出<strong class="kk iu">因为某件事最近发生得更频繁，所以现在不太可能发生(反之亦然)</strong>。然而，这在现实生活中并不成立。例如，如果一枚硬币连续 3 次正面朝上，人们会认为<em class="nq">不可能连续 4 次正面朝上</em>。然而，这是错误的，因为硬币仍然有相同的概率正面或反面落地。</p><p id="cfca" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">同样的事情也发生在数据上。当多个数据点开始显示类似的未解释的相关性或矛盾时，数据科学家通常倾向于依靠<em class="nq">直觉</em>，而不是逻辑解释和公式，这往往会在推断推论时导致灾难性的后果。</p><blockquote class="mt"><p id="541d" class="mu mv it bd mw mx my mz na nb nc ld dk translated">当从数据中得出推论时，人们倾向于根据以前的经验凭直觉，而不是逻辑解释</p></blockquote><p id="f6c1" class="pw-post-body-paragraph ki kj it kk b kl nd ju kn ko ne jx kq kr nf kt ku kv ng kx ky kz nh lb lc ld im bi translated">理解“赌徒谬误”需要两个关键点:大数定律及其与回归均值的关系。大数定律表明，多次执行完全相同的实验的所有结果的平均值应该接近期望值，并且期望值和原始值之间的差异将与所进行的实验次数成正比。</p><p id="ef49" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">向均值回归的概念还引入了<strong class="kk iu">回归谬误</strong>，该谬误假设当某件事情发生时，它异常地好或坏，随着时间的推移，它会回复到平均值。这种谬误经常被用来为研究或模型预测中产生的异常值寻找解释。</p></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><blockquote class="mt"><p id="73b7" class="mu mv it bd mw mx my mz na nb nc ld dk translated">避免一个错误是朝着正确方向迈出的一步。避免谬误是迈向更好推论的一步。</p></blockquote></div></div>    
</body>
</html>