<html>
<head>
<title>Scraping 1000’s of News Articles using 10 simple steps</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用10个简单的步骤搜集1000篇新闻文章</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/scraping-1000s-of-news-articles-using-10-simple-steps-d57636a49755?source=collection_archive---------0-----------------------#2020-06-22">https://towardsdatascience.com/scraping-1000s-of-news-articles-using-10-simple-steps-d57636a49755?source=collection_archive---------0-----------------------#2020-06-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8f10" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如果你遵循这10个简单的步骤，使用python进行网络抓取是非常简单的。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6633e6a7cb005bd5ef7b34d5bb70f6f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*__fCMPzS-15OrfzeXyIOXA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">迈克尔·波德格在<a class="ae ky" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="fcb8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">网页抓取系列:使用Python和软件</strong></p><p id="1fed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> Part-1: </strong> <a class="ae ky" href="https://medium.com/@TechyKajal/scraping-1000s-of-news-articles-using-10-simple-steps-d57636a49755" rel="noopener">不使用软件抓取网页:Python </a></p><p id="5508" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">第二部分:</strong> <a class="ae ky" href="https://medium.com/@TechyKajal/dataset-creation-for-beginners-using-software-4795ee119f6d" rel="noopener">利用软件抓取网页:octoporse</a></p><p id="5bda" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">目录</strong></p><p id="18de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 1。</strong>简介</p><p id="2b49" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 1.1 </strong>为什么写这篇文章？</p><p id="ea63" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">谁应该阅读这篇文章？</p><p id="f612" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 2。</strong>概述</p><p id="c66e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 2.1 </strong>网页设计和HTML简介</p><p id="fb3e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 2.2 </strong>使用PYTHON中的BeautifulSoup进行网页抓取</p><p id="1a7f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 3。</strong>建议&amp;结论</p><p id="1ba4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 3.1 </strong>完整代码</p><h1 id="f7ac" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">介绍</h1><h1 id="d91f" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">为什么是这篇文章？</h1><p id="5b0a" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">这篇文章的目的是使用Python从不同的网站收集新闻文章。一般来说，网络搜集包括访问大量网站并从这些网站收集数据。然而，我们可以限制自己从单一来源收集大量信息，并将其用作数据集。</p><blockquote class="ms mt mu"><p id="2846" class="kz la mv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated">网络抓取是一种用于从网站提取大量数据的技术，通过这种技术，数据被提取并以表格(电子表格)格式保存到您计算机中的本地文件或数据库中。</p></blockquote><p id="c1e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，当我在<strong class="lb iu">假新闻检测系统</strong>上进行我的机器学习项目时，我有动力去做网络搜集。每当我们开始一个机器学习项目时，我们首先需要的是一个数据集。虽然您可以在网上找到许多包含各种信息的数据集，但有时您希望自己提取数据并开始自己的调查。我需要一个数据集，但我无法根据需要在任何地方找到它。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mz na l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">资料来源:giphy.com</p></figure><p id="4891" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，这促使我相应地为我的项目制作我自己的数据集。这就是我如何从零开始做我的项目。我的项目基本上是基于将不同的新闻文章分为两大类<strong class="lb iu">假的</strong> &amp; <strong class="lb iu">真的</strong>。</p><h2 id="b7db" class="nb lw it bd lx nc nd dn mb ne nf dp mf li ng nh mh lm ni nj mj lq nk nl ml nm bi translated">假新闻数据集</h2><p id="2f74" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">对于这个项目，第一个任务是获得一个已经标记有“<em class="mv">假</em>的数据集，因此这可以通过从一些经过验证的&amp;认证新闻网站抓取数据来实现，我们可以依赖这些数据来获取新闻文章的事实，而获得真正的“<em class="mv">假新闻</em>确实是一个非常困难的任务。<br/> <strong class="lb iu"> <em class="mv">我浏览这些新闻网站来获取我的假新闻数据集</em> </strong></p><ul class=""><li id="3cc4" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">Boom Live</li><li id="08b0" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">Snopes</li><li id="b4c1" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">政治事实</li><li id="2a0c" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">所有方面</li></ul><p id="0896" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是老实说，我最终还是从一个网站上搜集数据，即Politifact。 <br/>有很强的理由这样做，当你浏览上面列出的链接时，你会得出结论，我们需要一个已经标记了类别的数据集，即“<strong class="lb iu">假的</strong>”，但我们也不希望我们的新闻文章以这样的形式修改。我们希望提取一篇原始新闻文章，其中没有任何指定数据集中给定新闻文章是否“虚假”的关键字。<br/>因此，例如，如果您通过链接“BoomLive.in ”,您会发现指定“FAKE”的新闻文章并不是其实际形式，而是根据事实核查小组的一些分析进行了修改。因此，这种在ML模型训练中修改过的文本每次都会给我们一个有偏见的结果，而我们使用这种数据集制作的模型将导致一个哑模型，它只能预测带有关键字的新闻文章，如“假的”，“做了吗？”，“是吗？”并且在新的测试数据集上不会有很好的表现。<br/>这就是为什么我们使用<strong class="lb iu"> Politifact </strong>来搜集我们的“假新闻数据集”。</p><h2 id="8e7b" class="nb lw it bd lx nc nd dn mb ne nf dp mf li ng nh mh lm ni nj mj lq nk nl ml nm bi translated">真实新闻数据集</h2><p id="6e39" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">第二项任务是创建一个"<strong class="lb iu">真实新闻</strong>"数据集，因此，如果您从诸如" TOI "、"今日印度"、" TheHindu" &amp;等如此之多的可信或经过验证的新闻网站上搜集新闻文章，这是很容易的……因此，我们可以相信这些网站列出的是事实/实际数据，即使不是，我们也会假设它们是真实的，并相应地训练我们的模型。<br/>但是对于我的项目，我只从一个网站(即Politifact.com)抓取<strong class="lb iu">真实</strong>和<strong class="lb iu">虚假</strong>的数据，因为我从它那里得到了我所需要的，而且当我们使用python抓取数据时，建议一次只使用一个网站。虽然您可以通过运行一个外部for循环在一个模块中抓取特定网站的多个页面。</p><h1 id="a98d" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">世卫组织应该读读这篇文章？</h1><p id="eacc" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">无论谁在从事需要收集成千上万数据的项目，这篇文章绝对适合你😃。不管你是否有编程背景，因为很多时候，除了来自不同背景的程序员之外，其他人也需要数据来完成他们的项目、调查或其他任何目的。</p><p id="023f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是非程序员发现理解任何编程语言都很困难，所以我将通过介绍一些软件让他们也能轻松地放弃，他们可以轻松地从这些软件中抓取大量的任何类型的数据。</p><p id="d025" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然使用python抓取并不困难，如果你在阅读这篇博客的时候跟着我的话😎，你唯一需要关注的是网页的HTML源代码。一旦你能够理解网页是如何用HTML编写的，并且能够识别你感兴趣的属性和元素，你就可以抓取任何网站。</p><p id="08f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于非程序员来说，如果你想用python做网页抓取，只需要主要关注HTML代码，python的语法并没有那么难理解，它只是一些你需要记住和理解的库、函数和关键字。所以我试着用透明的方式解释每一步，我希望在这个系列的最后，你将能够了解不同类型的网页布局。</p></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><h1 id="22ce" class="lv lw it bd lx ly oi ma mb mc oj me mf jz ok ka mh kc ol kd mj kf om kg ml mm bi translated">概观</h1><p id="9d85" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">这篇文章涵盖了第一部分:<strong class="lb iu">使用PYTHON的新闻文章web抓取。</strong>我们将创建一个脚本，从不同的报纸中抓取最新的新闻文章并存储文本，然后将这些文本输入到模型中，以获得对其类别的预测。</p><h1 id="0c0c" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">网页设计和HTML简介:</h1><p id="060c" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">如果我们希望能够从网站中提取新闻文章(或者，事实上，任何其他类型的文本)，第一步就是要知道网站是如何工作的。</p><p id="767d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mv">我们将通过一个例子来理解这一点:</em></p><p id="9c69" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我们将一个URL插入网络浏览器(如Google Chrome、Firefox等)并访问它时，我们看到的是三种技术的结合:</p><p id="0e39" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> HTML(超文本标记语言):</strong>它是给网站添加内容的标准语言。它允许我们在网站上插入文本、图片和其他东西。一句话，HTML定义了互联网上每个网页的内容。</p><p id="048d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">CSS(层叠样式表):这种语言允许我们设置网站的视觉设计。这意味着它决定了网页的风格/外观，包括颜色、布局和字体。</p><p id="ec52" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> JavaScript: </strong> JavaScript是一种动态的计算机编程语言。它允许我们使内容和风格交互&amp;提供了客户端脚本和用户之间的动态接口。</p><p id="f333" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意这三种都是编程语言。它们将允许我们创建和操作网页设计的每一个方面。</p><p id="35c9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们用一个例子来说明这些概念。当我们访问Politifact页面时，我们会看到以下内容:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/c82bffdd205ebe71e092c73f5c6782aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hoFhcwDgBOwT67YYMyfIRQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">截图来自Politifact网站</p></figure><p id="f38f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们禁用了<strong class="lb iu"> JavaScript </strong>，我们将无法再使用此弹出窗口，正如您所见，我们现在看不到视频弹出窗口:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/c11f58ca47522f81188750493b9f918b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j1oNYcaCtHzOUanRqF-lGA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">截图来自Politifact网站</p></figure><p id="166c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们在inspect窗口中使用ctrl+F找到CSS 元素，然后将其从网页中删除，我们将会看到如下内容:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/b3768f6a82dc712ea80646589bb5984c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*lXYcNnN7Opww5O-xGsy0HA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">截图来自Politifact网站</p></figure><p id="95a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以，现在，我会问你一个问题。</p><blockquote class="ms mt mu"><p id="1a09" class="kz la mv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated"><strong class="lb iu"><em class="it"/>如果想通过抓取网页内容，需要从哪里查找？</strong><em class="it"/></p></blockquote><p id="9aa6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以，在这一点上，我希望你们都清楚我们需要搜集什么样的源代码。是的，你是绝对正确的，如果你正在考虑HTML的话😎</p><p id="d615" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以，执行web抓取方法之前的最后一步是理解HTML语言。</p><p id="d103" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> HTML </strong></p><p id="e564" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> HTML </strong>语言是一种<em class="mv">超文本标记语言</em>，它定义了网页的内容，由元素和属性构成，为了抓取数据，你应该熟悉检查那些元素。</p><ul class=""><li id="89d2" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">一个元素可以是一个标题、段落、分部、锚定标签等等…</li><li id="cc66" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">一个属性可以是标题是粗体字母。<br/>这些标签用开始符号<code class="fe oq or os ot b">&lt;tag&gt;</code>和结束符号<code class="fe oq or os ot b">&lt;/tag&gt;</code> <br/>表示，</li></ul><p id="f2de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe oq or os ot b">&lt;p&gt;This is paragraph.&lt;/p&gt;<br/>&lt;h1&gt;&lt;b&gt;This is heading one in bold letters&lt;/b&gt;&lt;/h1&gt;</code></p><h1 id="d75c" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">使用PYTHON中的BeautifulSoup进行网页抓取</h1><p id="a42f" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">说够了，给我看看代码。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/5e1e0750a738b167b0f0f74ec8cef732.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/0*gR0AHtedrifUw8ZJ.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">资料来源:giphy.com</p></figure><h2 id="59fb" class="nb lw it bd lx nc nd dn mb ne nf dp mf li ng nh mh lm ni nj mj lq nk nl ml nm bi translated">步骤1:安装软件包</h2><p id="8a3b" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我们将首先开始安装必要的软件包:</p><p id="6bb7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">1.<code class="fe oq or os ot b">beautifulsoup4</code> <br/>要安装它，请在您的python发行版中键入以下代码。</p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="e899" class="nb lw it ot b gy oz pa l pb pc">! pip install beautifulsoup4</span></pre><blockquote class="ms mt mu"><p id="690f" class="kz la mv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated"><em class="it">bs4包下的BeautifulSoup是一个库，用于以一种非常简单方便的方式将HTML &amp; XML文档解析为python，并通过使用标签和属性来识别元素来访问元素。</em></p></blockquote><p id="e93f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它非常容易使用，但非常强大的软件包提取任何类型的数据从互联网上只有5-6行。</p><p id="b9af" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.<code class="fe oq or os ot b">requests</code></p><p id="d69a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要安装它，请在IDE中使用以下命令，或者在命令外壳中使用不带感叹号的命令。</p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="a6e2" class="nb lw it ot b gy oz pa l pb pc">! pip install requests</span></pre><blockquote class="ms mt mu"><p id="ec00" class="kz la mv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated">为了给BeautifulSoup提供任何页面的HTML代码，我们需要请求模块。</p></blockquote><p id="614a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3.<code class="fe oq or os ot b">urllib</code> <br/>要安装它，使用以下命令:</p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="4e47" class="nb lw it ot b gy oz pa l pb pc">! pip install urllib</span></pre><blockquote class="ms mt mu"><p id="8070" class="kz la mv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated"><em class="it"> urllib模块是python的URL处理模块。它用于获取URL(统一资源定位符)</em></p></blockquote><p id="abc0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然，在这里我们使用这个模块是为了不同的目的，来调用像这样的库:</p><ul class=""><li id="eb39" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">time(使用它我们可以调用sleep()函数来延迟或暂停执行给定的秒数。</li><li id="32b4" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">sys(此处用于获取异常信息，如错误类型、错误对象、关于错误的信息。</li></ul><h2 id="d6e1" class="nb lw it bd lx nc nd dn mb ne nf dp mf li ng nh mh lm ni nj mj lq nk nl ml nm bi translated">步骤2:导入库</h2><p id="af5a" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">现在我们将导入所有需要的库:<br/> 1。<code class="fe oq or os ot b">BeautifulSoup</code> <br/>要导入它，在您的IDE上使用以下命令</p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="4301" class="nb lw it ot b gy oz pa l pb pc">from bs4 import BeautifulSoup</span></pre><blockquote class="ms mt mu"><p id="64b2" class="kz la mv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated">这个库帮助我们获得我们想要处理的任何页面的HTML结构，并提供访问特定元素和提取相关信息的功能。</p></blockquote><p id="d3f1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.<code class="fe oq or os ot b">urllib</code> <br/>要导入它，键入以下命令</p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="2bbe" class="nb lw it ot b gy oz pa l pb pc">import urllib.request,sys,time</span></pre><ul class=""><li id="02e5" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">urllib.request:它有助于定义帮助打开URL的函数和类</li><li id="5a77" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">urllib.sys:它的函数和类帮助我们检索异常信息。</li><li id="82c1" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">urllib.time : Python有一个名为time的模块，它提供了几个有用的函数来处理与时间相关的任务。其中最受欢迎的功能之一就是sleep()。</li></ul><p id="5567" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3.<code class="fe oq or os ot b">requests</code> <br/>要导入它，只需在本库关键字前键入import即可。</p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="19b3" class="nb lw it ot b gy oz pa l pb pc">import requests</span></pre><blockquote class="ms mt mu"><p id="7d41" class="kz la mv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated"><em class="it">该模块允许我们使用python向web服务器发送HTTP请求。(HTTP消息由从客户端到服务器的请求和从服务器到客户端的响应组成。)</em></p></blockquote><p id="c40e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">4.<code class="fe oq or os ot b">pandas</code></p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="d64c" class="nb lw it ot b gy oz pa l pb pc">import pandas as pd</span></pre><blockquote class="ms mt mu"><p id="8671" class="kz la mv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated"><em class="it">这是一个高级数据操作工具，我们需要它来可视化我们的结构化抓取数据。</em></p></blockquote><p id="82c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将使用这个库来制作DataFrame(这个库的关键数据结构)。数据帧允许我们存储和操作观察行和变量列中的表格数据。</p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="da48" class="nb lw it ot b gy oz pa l pb pc">import urllib.request,sys,time<br/>from bs4 import BeautifulSoup<br/>import requests<br/>import pandas as pd</span></pre><h2 id="6a04" class="nb lw it bd lx nc nd dn mb ne nf dp mf li ng nh mh lm ni nj mj lq nk nl ml nm bi translated">第三步:提出简单的请求</h2><p id="2049" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">通过<code class="fe oq or os ot b">request</code>模块，我们可以获取HTML内容并存储到<code class="fe oq or os ot b">page</code>变量中。<br/>发出一个简单的get请求(只是获取一个页面)</p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="c7ed" class="nb lw it ot b gy oz pa l pb pc">#url of the page that we want to Scarpe<br/>#+str() is used to convert int datatype of the page no. and concatenate that to a URL for pagination purposes.</span><span id="d738" class="nb lw it ot b gy pd pa l pb pc">URL = 'https://www.politifact.com/factchecks/list/?page='+str(page)</span><span id="992e" class="nb lw it ot b gy pd pa l pb pc">#Use the browser to get the URL. This is a suspicious command that might blow up.</span><span id="09d8" class="nb lw it ot b gy pd pa l pb pc">page = requests.get(url)</span></pre><blockquote class="ms mt mu"><p id="5c24" class="kz la mv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated"><em class="it">既然，</em> <code class="fe oq or os ot b"><em class="it">requests.get(url)</em></code> <em class="it">是一个可疑的命令，可能会抛出一个异常，我们就在try-except block中调用它</em></p></blockquote><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="a094" class="nb lw it ot b gy oz pa l pb pc">try:<br/>     # this might throw an exception if something goes wrong.<br/>     page=requests.get(url) </span><span id="1d97" class="nb lw it ot b gy pd pa l pb pc">     # this describes what to do if an exception is thrown <br/>except Exception as e:    <br/>    <br/>    # get the exception information<br/>    error_type, error_obj, error_info = sys.exc_info()      <br/>    <br/>    #print the link that cause the problem<br/>    print ('ERROR FOR LINK:',url)<br/>    <br/>    #print error info and line that threw the exception                          <br/>    print (error_type, 'Line:', error_info.tb_lineno)<br/>    <br/>    continue</span></pre><p id="4809" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">出于分页的目的，我们还将使用外部for循环。</p><h2 id="e2bf" class="nb lw it bd lx nc nd dn mb ne nf dp mf li ng nh mh lm ni nj mj lq nk nl ml nm bi translated">步骤4:检查响应对象</h2><p id="6e41" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">一、看服务器发回什么响应码(对<br/>检测4XX或5XX错误有用。</p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="e143" class="nb lw it ot b gy oz pa l pb pc">page.status_code</span></pre><p id="e9b0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">输出:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/5b157f7c99259a6dc526fc85b197d47f.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/1*TqevY6vYbhd__eQlMktYrA.png"/></div></figure><p id="76dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">HTTP 200 OK成功状态响应代码表示请求已经成功。</p><p id="ac68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">二。以文本形式访问完整的响应(在一个大字符串中获取页面的HTML)</p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="d0f0" class="nb lw it ot b gy oz pa l pb pc">page.text</span></pre><p id="626b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">输出:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/4ce82ea248e443d9b629ffac82ed663d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/1*foS38y9Ld53klywgHLTPuw.png"/></div></figure><p id="0cdd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它将以Unicode返回响应对象的HTML内容。<br/> <strong class="lb iu">备选:</strong></p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="4129" class="nb lw it ot b gy oz pa l pb pc">page.content</span></pre><p id="04f0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">输出:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/70182ac3ebd1339e0adfd7147a3809e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*B8PzDcuqn690HQLEUHfb4w.png"/></div></figure><p id="0fa6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">输出:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/a64a094992c2d9379405d15d65a3a7dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*CdskXwTjrEPkrFaXDUi21Q.png"/></div></figure><p id="f552" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，它将以字节为单位返回响应的内容。</p><p id="8f9c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">三。在响应中查找特定的文本子字符串。</p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="0ce4" class="nb lw it ot b gy oz pa l pb pc">if "Politifact" in page.text:<br/>         print("Yes, Scarpe it")</span></pre><p id="021e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">四。检查响应的内容类型(查看是否得到了HTML、<br/> JSON、XML等)</p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="25fb" class="nb lw it ot b gy oz pa l pb pc">print (page.headers.get("content-type", "unknown"))</span></pre><p id="3967" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">输出:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/6f28c141179fc80544215998059ef768.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/1*lpMFqba2WNfmiYeBCeQHWQ.png"/></div></figure><h2 id="44d9" class="nb lw it bd lx nc nd dn mb ne nf dp mf li ng nh mh lm ni nj mj lq nk nl ml nm bi translated">步骤5:延迟请求时间</h2><p id="60dd" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">接下来使用时间模块，我们可以调用值为2秒的sleep(2)函数。这里，它向web服务器发送请求的时间延迟了2秒。</p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="20bb" class="nb lw it ot b gy oz pa l pb pc">time.sleep(2)</span></pre><blockquote class="ms mt mu"><p id="c106" class="kz la mv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated"><em class="it">sleep()函数在给定的秒数内暂停当前线程的执行。</em></p></blockquote><h2 id="9ae8" class="nb lw it bd lx nc nd dn mb ne nf dp mf li ng nh mh lm ni nj mj lq nk nl ml nm bi translated">步骤6:从HTML中提取内容</h2><p id="9018" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">现在您已经发出了HTTP请求并获得了一些HTML内容，是时候解析它了，这样您就可以提取您正在寻找的值。</p><p id="6f60" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> A)使用正则表达式</strong> <br/>完全不建议使用正则表达式来查找HTML内容。</p><p id="9e01" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是，正则表达式对于查找特定的字符串模式仍然很有用，比如价格、电子邮件地址或电话号码。</p><p id="f4a5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对响应文本运行正则表达式，以查找特定的字符串模式:</p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="7a18" class="nb lw it ot b gy oz pa l pb pc">import re  # put this at the top of the file<br/>...<br/>print(re.findall(r'\$[0-9,.]+', page.text))</span></pre><p id="d5ae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">输出:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/f9e98d2884bee8827e2a20d3cb3067b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:486/format:webp/1*_tyBbK798SgRbsYVB7tw1g.png"/></div></figure><p id="6a12" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> B)使用BeautifulSoup的对象汤</strong> <br/> Beautiful Soup是一个用于从HTML和XML文件中提取数据的Python库。它与您喜欢的解析器一起工作，提供导航、搜索和修改解析树的惯用方式。它通常可以为程序员节省数小时或数天的工作</p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="c0f7" class="nb lw it ot b gy oz pa l pb pc">soup = BeautifulSoup(page.text, "html.parser")</span></pre><p id="6a64" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面列出的命令将查找所有具有特定属性“o-listicle__item”的标签，例如<code class="fe oq or os ot b">&lt;li&gt;</code></p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="c759" class="nb lw it ot b gy oz pa l pb pc">links=soup.find_all('li',attrs={'class':'o-listicle__item'})</span></pre><p id="dd96" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">检查网页</strong> <br/>为了能够理解上面的代码，你需要检查网页&amp;请跟着做:<br/> 1)转到上面列出的URL<br/>2)按ctrl+shift+I检查它。<br/> 3)这是你的“检查窗口”的样子:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/99a9d136d17a43b8ec4c955bc8c7b0a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*tuJmM3Gr4co2jTtVYoPBQQ.png"/></div></figure><ul class=""><li id="da81" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">按ctrl+shift+C选择页面中的元素进行检查，或者转到“检查”窗口标题中最左边的箭头。</li></ul><p id="34c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">4)用于在检查窗口中获取上述特定元素和属性</p><ul class=""><li id="4578" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">首先，尝试进入网页的每个部分，并在inspect窗口中查看变化，您将很容易理解网页如何工作，以及哪个元素是什么，哪个特定属性对网页有贡献。</li><li id="cb18" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">完成上述步骤后，现在我假设你能理解上述元素<code class="fe oq or os ot b">&lt;li&gt;</code>及其属性的工作原理。</li><li id="d590" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">因为我需要某篇文章的新闻部分，所以我通过选择inspect窗口中的inspect元素选项转到该文章部分，它将在网页上突出显示该文章部分，并在Inspect窗口中突出显示其HTML源代码。瞧啊。✨</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pl"><img src="../Images/65b228c5bc33440689eef5764bd60ea1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gtWbvj4y1M7v4Nfo_uknog.png"/></div></div></figure><blockquote class="ms mt mu"><p id="e702" class="kz la mv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated"><em class="it">你能在你的机器上找到相同的标签吗？</em></p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/400b69ca73d2e67da5e198cde83ba558.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*XaMcQoILM5h5fj2D95pKCw.png"/></div></figure><p id="62a5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果是的话，你已经完全理解了我在代码中使用的所有HTML标签。</p><p id="44e7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">继续我的代码:😅</p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="2d24" class="nb lw it ot b gy oz pa l pb pc">print(len(links))</span></pre><blockquote class="ms mt mu"><p id="564e" class="kz la mv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated">这个命令将帮助你检查给定页面上有多少新闻文章。<br/>相应地帮助你理解，为了提取大量数据，你需要对你的循环进行分页到什么级别。</p></blockquote><h2 id="d4f3" class="nb lw it bd lx nc nd dn mb ne nf dp mf li ng nh mh lm ni nj mj lq nk nl ml nm bi translated">步骤7:查找元素和属性</h2><ul class=""><li id="be62" class="nn no it lb b lc mn lf mo li pn lm po lq pp lu ns nt nu nv bi translated">查找页面上的所有锚标签(如果您正在构建一个爬虫，并且需要找到下一个要访问的页面，这很有用)</li></ul><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="d38e" class="nb lw it ot b gy oz pa l pb pc">links = soup.find_all("a")</span></pre><ul class=""><li id="5dd5" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">它将在<code class="fe oq or os ot b">&lt;li&gt;</code>标签下找到一个div标签，其中div标签应该包含列出的或特定的属性值。这里的“j”是一个iterable变量，它对给定页面上列出的所有新闻文章的响应对象“Links”进行迭代。</li></ul><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="398e" class="nb lw it ot b gy oz pa l pb pc">Statement = j.find("div",attrs={'class':'m-statement__quote'})</span></pre><ul class=""><li id="7215" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">text.strip()函数将返回包含在该标记中的文本，并从文本字符串对象中去除任何类型的额外空格，' \n '，' \t '。</li></ul><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="11b7" class="nb lw it ot b gy oz pa l pb pc">Statement = j.find("div",attrs={'class':'m- <br/>   statement__quote'}).text.strip()</span></pre><blockquote class="ms mt mu"><p id="fd63" class="kz la mv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated"><em class="it">好极了！🌟我们已经刮出了第一个属性，即数据集的语句</em></p></blockquote><ul class=""><li id="5371" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">在同一个division部分，它将寻找锚标记并返回超文本链接的值。同样，strip()函数用于组织我们的值，以便我们的CSV文件看起来不错。</li></ul><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="3eeb" class="nb lw it ot b gy oz pa l pb pc">Link=j.find("div",attrs={'class':'m-statement__quote'}).find('a')['href'].strip()</span></pre><ul class=""><li id="413a" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">要获取日期属性，您需要先检查网页，因为它包含一个字符串。所以在没有指定索引的情况下调用文本函数，你会得到类似这样的结果</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pq"><img src="../Images/be29c3149586eaba987be941ff15b149.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*_AUeKTN_hHEu0O5-9yIXHw.png"/></div></figure><ul class=""><li id="0e89" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">但是除了日期之外，我们不需要文本，所以我使用索引。尽管您可以稍后使用一些正则表达式组合来清理您的属性。“footer”是包含所需文本的元素。</li></ul><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="ea73" class="nb lw it ot b gy oz pa l pb pc">Date = j.find('div',attrs={'class':'m-statement__body'}).find('footer').text[-14:-1].strip()</span></pre><ul class=""><li id="f93e" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">在这里，除了get()之外，我做了和以前一样的事情，get()提取传递的属性(即title)的内容</li></ul><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="c631" class="nb lw it ot b gy oz pa l pb pc">Source = j.find('div', attrs={'class':'m-statement__author'}).find('a').get('title').strip()</span></pre><ul class=""><li id="2d27" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">因为，对于我的项目，我需要一个没有被改变的数据集，而且，我需要知道成千上万的文章，哪篇文章属于我的训练数据的哪个类别。没有人可以手动操作。所以，在这个网站上，我确实找到了已经贴有标签的文章，但是文本是不可检索的，因为它包含在图像中。对于这种特定的任务，您可以使用get()来有效地检索特定的文本。这里，我将' alt '作为属性传递给get()，它包含我们的标签文本。</li></ul><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="10c7" class="nb lw it ot b gy oz pa l pb pc">Label = j.find('div', attrs ={'class':'m-statement__content'}).find('img',attrs={'class':'c-image__original'}).get('alt').strip()</span></pre><p id="b202" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在下面的代码行中，我将所有的概念放在一起，并尝试获取数据集的五个不同属性的详细信息。</p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="f993" class="nb lw it ot b gy oz pa l pb pc">for j in links:<br/>        Statement = j.find("div",attrs={'class':'m-statement__quote'}).text.strip()<br/>        Link=st.find('a')['href'].strip()<br/>        Date = j.find('div',attrs={'class':'m-statement__body'}).find('footer').text[-14:-1].strip()<br/>        Source = j.find('div', attrs={'class':'m-statement__author'}).find('a').get('title').strip()<br/>        Label = j.find('div', attrs ={'class':'m-statement__content'}).find('img',attrs={'class':'c-image__original'}).get('alt').strip()<br/>        frame.append([Statement,Link,Date,Source,Label])<br/>upperframe.extend(frame)</span></pre><h2 id="35e4" class="nb lw it bd lx nc nd dn mb ne nf dp mf li ng nh mh lm ni nj mj lq nk nl ml nm bi translated">步骤8:制作数据集</h2><p id="9f05" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">将每个属性值附加到每个文章的空列表“框架”中</p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="eb3e" class="nb lw it ot b gy oz pa l pb pc">frame.append([Statement,Link,Date,Source,Label])</span></pre><p id="5ee4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，将此列表扩展为每页的空列表“upperframe”。</p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="272a" class="nb lw it ot b gy oz pa l pb pc">upperframe.extend(frame)</span></pre><h2 id="4bed" class="nb lw it bd lx nc nd dn mb ne nf dp mf li ng nh mh lm ni nj mj lq nk nl ml nm bi translated">步骤9:可视化数据集</h2><p id="07dd" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">如果你想在木星上可视化你的数据，你可以使用pandas DataFrame来实现。</p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="379f" class="nb lw it ot b gy oz pa l pb pc">data=pd.DataFrame(upperframe, columns=['Statement','Link','Date','Source','Label'])<br/>data.head()</span></pre><h2 id="ce00" class="nb lw it bd lx nc nd dn mb ne nf dp mf li ng nh mh lm ni nj mj lq nk nl ml nm bi translated">步骤10:制作CSV文件并保存到你的机器上</h2><p id="0911" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated"><strong class="lb iu"> A)打开&amp;写入文件</strong>T5】下面的命令将帮助你编写CSV文件，并将其保存到你的机器上保存你的python文件的同一个目录下</p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="13d5" class="nb lw it ot b gy oz pa l pb pc">filename="NEWS.csv"<br/>    f=open(filename,"w")<br/>    headers="Statement,Link,Date, Source, Label\n"<br/>    f.write(headers)<br/>    ....<br/>        f.write(Statement.replace(",","^")+","+Link+",<br/>"+Date.replace(",","^")+","+Source.replace(",","^")+","+Label.replace(",","^")+"\n")</span></pre><p id="ad2e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这一行将把每个属性写到一个文件中，用'^'.替换所有的'，'</p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="c0ea" class="nb lw it ot b gy oz pa l pb pc">f.write(Statement.replace(",","^")+","+Link+","+Date.replace(",","^")+","+Source.replace(",","^")+","+Label.replace(",","^")+"\n")</span></pre><p id="ced0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，当您在命令shell上运行这个文件时，它会在您的。py文件目录。打开它时，如果你在抓取时没有使用strip()，你可能会看到奇怪的数据。所以不要用strip()检查它，如果你不用'，'替换'^'，它看起来也会很奇怪。<br/>所以，用这些简单的步骤替换它:</p><ul class=""><li id="a7ba" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">打开您的excel文件(。csv文件)</li><li id="5509" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">按ctrl+H(将出现一个弹出窗口，询问“查找内容并替换为”)</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/d85b342aa14c2cbdb4e5eb5e9b87021d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*eqPATRKQwOHUWkab70BUqg.png"/></div></figure><ul class=""><li id="1575" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu ns nt nu nv bi translated">给'<strong class="lb iu"/>'取值给'<strong class="lb iu">找什么</strong>字段，给'<strong class="lb iu">中的'<strong class="lb iu">，</strong>'取值替换为</strong>'字段。</li><li id="cc18" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">按全部替换</li><li id="8eb4" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu ns nt nu nv bi translated">点击关闭&amp;哇哦！😍您已经完成了让数据集保持完美形式的工作。不要忘记在完成两个for循环后用下面的命令关闭文件，</li></ul><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="0d25" class="nb lw it ot b gy oz pa l pb pc">f.close()</span></pre><p id="9069" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果已经使用文件写入方法创建了数据集，则反复运行相同的代码可能会引发错误。</p><p id="9d94" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> B)使用to_csv() </strong> <br/>将数据帧转换为csv文件因此，除了这种冗长的方法，您可以选择另一种方法:to_csv()也用于将数据帧转换为csv文件，并且还提供一个属性来指定路径。</p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="a105" class="nb lw it ot b gy oz pa l pb pc">path = 'C:\\Users\\Kajal\\Desktop\\KAJAL\\Project\\Datasets\\'<br/>data.to_csv(path+'NEWS.csv')</span></pre><p id="ae9e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了避免歧义并允许代码的可移植性，您可以使用:</p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="610b" class="nb lw it ot b gy oz pa l pb pc">import os<br/>data.to_csv(os.path.join(path,r'NEWS.csv'))</span></pre><p id="bda4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这将正确地将您的CSV名称附加到您的目标路径。</p></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><h1 id="8c6b" class="lv lw it bd lx ly oi ma mb mc oj me mf jz ok ka mh kc ol kd mj kf om kg ml mm bi translated">建议和结论</h1><p id="07ca" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">虽然我建议使用第一种方法，即打开文件，写入文件，然后关闭文件，但我知道实现起来有点冗长和俗气，但至少它不会像to_csv方法那样给你提供模糊的数据。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ps"><img src="../Images/d3f1ee7ce0dcaaeeea19a1be062c16a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:178/format:webp/1*3LB5V5rAZFsT_sr6RFebhg.png"/></div></div></figure><p id="f10b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请看上图，它是如何提取语句属性的不明确数据的。<br/>因此，与其花费数小时手动清理数据，我建议多写几行第一种方法中指定的代码。现在，你已经完成了。✌️</p><blockquote class="ms mt mu"><p id="0834" class="kz la mv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated"><strong class="lb iu"> <em class="it">重要提示:</em> </strong> <em class="it">如果您尝试复制粘贴我的源代码来抓取不同的网站&amp;运行它，它可能会抛出一个错误。事实上，它肯定会抛出一个错误，因为每个网页的布局是不同的&amp;为此，你需要做出相应的改变。</em></p></blockquote><h1 id="44a6" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">完整代码</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pt na l"/></div></figure><p id="e163" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">数据集:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pu"><img src="../Images/8409167108a03421a122863ab0be7d39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G6NXa9gkYXGQhnsXn9GZmA.png"/></div></div></figure></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><p id="2cb5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇文章是网络搜集系列的第一部分，对于那些没有技术背景的人来说，可以在这里阅读这个系列的第二部分<a class="ae ky" href="https://medium.com/@TechyKajal/dataset-creation-for-beginners-using-software-4795ee119f6d" rel="noopener">。</a></p><p id="f368" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以，如果我的博客帖子对你有所帮助，而你此刻觉得很慷慨，请不要犹豫，请给我买杯咖啡。☕😍</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><a href="https://www.buymeacoffee.com/techykajal"><div class="gh gi pv"><img src="../Images/d0d4f4d264b3d53ab60b92ba81600f19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xpxVFhGlTQmm57O_jswZ-Q.png"/></div></a></figure><p id="b0c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">是的，点击我。</p><pre class="kj kk kl km gt ov ot ow ox aw oy bi"><span id="f9f8" class="nb lw it ot b gy oz pa l pb pc">And yes, buying me a coffee <strong class="ot iu">(and lots of it if you are feeling extra generous)</strong> goes a long way in ensuring that I keep producing content every day in the years to come.</span></pre><p id="28a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望你会觉得有用，喜欢我的文章。😇请随时分享你的想法，如果你有任何疑问，请打电话给我。您可以通过以下方式联系我:</p><ol class=""><li id="9ef4" class="nn no it lb b lc ld lf lg li np lm nq lq nr lu pw nt nu nv bi translated">订阅我的<a class="ae ky" href="https://www.youtube.com/channel/UCdwAaZMWiRmvIBIT96ApVjw" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> YouTube频道</strong> </a>视频内容即将上线<a class="ae ky" href="https://www.youtube.com/channel/UCdwAaZMWiRmvIBIT96ApVjw" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">这里</strong> </a></li><li id="b854" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu pw nt nu nv bi translated">跟我上<a class="ae ky" href="https://medium.com/@TechyKajal" rel="noopener"> <strong class="lb iu">中</strong> </a></li><li id="a9fa" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu pw nt nu nv bi translated">在<a class="ae ky" href="http://www.linkedin.com/in/techykajal" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> LinkedIn </strong> </a>上连接并联系我</li><li id="8d33" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu pw nt nu nv bi translated">跟随我的博客之旅:-【https://kajalyadav.com/】<strong class="lb iu"/></li><li id="bb03" class="nn no it lb b lc nw lf nx li ny lm nz lq oa lu pw nt nu nv bi translated">成为会员:-<a class="ae ky" href="https://techykajal.medium.com/membership" rel="noopener"><strong class="lb iu">https://techykajal.medium.com/membership</strong></a></li></ol></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><p id="1ea3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">查看我的其他博客:</p><div class="px py gp gr pz qa"><a rel="noopener follow" target="_blank" href="/8-ml-ai-projects-to-make-your-portfolio-stand-out-bfc5be94e063"><div class="qb ab fo"><div class="qc ab qd cl cj qe"><h2 class="bd iu gy z fp qf fr fs qg fu fw is bi translated">8 ML/AI项目，让您的投资组合脱颖而出</h2><div class="qh l"><h3 class="bd b gy z fp qf fr fs qg fu fw dk translated">有趣的项目想法与源代码和参考文章，也附上一些研究论文。</h3></div><div class="qi l"><p class="bd b dl z fp qf fr fs qg fu fw dk translated">towardsdatascience.com</p></div></div><div class="qj l"><div class="qk l ql qm qn qj qo ks qa"/></div></div></a></div><div class="px py gp gr pz qa"><a href="https://medium.com/datadriveninvestor/predicting-us-presidential-election-using-twitter-sentiment-analysis-with-python-8affe9e9b8f" rel="noopener follow" target="_blank"><div class="qb ab fo"><div class="qc ab qd cl cj qe"><h2 class="bd iu gy z fp qf fr fs qg fu fw is bi translated">基于Python的推特情感分析预测美国总统大选</h2><div class="qh l"><h3 class="bd b gy z fp qf fr fs qg fu fw dk translated">修订数据科学基础的有趣项目，从数据集创建到数据分析再到数据可视化</h3></div><div class="qi l"><p class="bd b dl z fp qf fr fs qg fu fw dk translated">medium.com</p></div></div><div class="qj l"><div class="qp l ql qm qn qj qo ks qa"/></div></div></a></div></div></div>    
</body>
</html>