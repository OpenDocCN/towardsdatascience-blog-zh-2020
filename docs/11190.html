<html>
<head>
<title>Image Labelling Using Facebook’s Detectron🤖🤖</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用脸书探测器的图像标记🤖🤖</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-labelling-using-facebooks-detectron-4931e30c4d0c?source=collection_archive---------55-----------------------#2020-08-03">https://towardsdatascience.com/image-labelling-using-facebooks-detectron-4931e30c4d0c?source=collection_archive---------55-----------------------#2020-08-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="490b" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">你好，脸书探测器世界</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/89bcca6a02842c04503dcc98e88ab45c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9ARB5EorvQR4RSQm3AuKQA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Canva.com 地平线|免费媒体许可证</p></figure><p id="27c4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">训练一个模型从头开始检测文本可能是一项非常困难和令人沮丧的任务。传统的方法是使用具有特征金字塔网络的 R-CNN 或者使用像 YOLO 这样的算法。</p><p id="6931" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果你不知道这两种方法背后的数学和逻辑，那么这两种方法都很难实现。</p><p id="0d92" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由脸书人工智能研究团队开发的 Detectron 2 是一个基于 mask-r-CNN 基准的最新目标检测模型。它的动力来自 Pytorch 深度学习框架。主要功能包括</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lr"><img src="../Images/bce2f1908b447ea91fc21ff5503bc7ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fFMFIBx3zOfGstx0_asJcA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae ls" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Kirillov_Panoptic_Segmentation_CVPR_2019_paper.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><ol class=""><li id="03b7" class="lt lu iq kx b ky kz lb lc le lv li lw lm lx lq ly lz ma mb bi translated"><a class="ae ls" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Kirillov_Panoptic_Segmentation_CVPR_2019_paper.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ir">全景分割</strong></a>:FAIR 的另一个产品，是一种将语义分割(给每个像素分配一个类标签)和实例分割(检测和分割每个对象实例)这两种典型的不同任务统一起来的分割类型。</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mc"><img src="../Images/07f4243bdfe58c0f9991430e3161e11d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HT4v6r3FKB9xr7hJ_QrcsA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae ls" href="https://github.com/facebookresearch/Detectron" rel="noopener ugc nofollow" target="_blank"> FAIR GITHUB </a></p></figure><p id="5b21" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">2.<strong class="kx ir">密集姿态</strong>:用于将 RGB 图像的所有人体像素映射到人体的 3D 表面。这是由咖啡 2 驱动的。</p><p id="b492" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">“这种模式旨在通过提供快速培训和解决公司在从研究走向生产时面临的问题来推进物体检测”</p><h1 id="c461" class="md me iq bd mf mg mh mi mj mk ml mm mn jw mo jx mp jz mq ka mr kc ms kd mt mu bi translated">我们开始吧！</h1><p id="b089" class="pw-post-body-paragraph kv kw iq kx b ky mv jr la lb mw ju ld le mx lg lh li my lk ll lm mz lo lp lq ij bi translated">Detectron 2 可以使用 Google Colab Notebook 实现对象检测。我们选择 Google Colab 而不是本地系统，以利用 GPU 进行更快的训练。</p><h1 id="cdee" class="md me iq bd mf mg mh mi mj mk ml mm mn jw mo jx mp jz mq ka mr kc ms kd mt mu bi translated"><strong class="ak">步骤 1:安装并导入 Detectron 2 </strong></h1><p id="19f5" class="pw-post-body-paragraph kv kw iq kx b ky mv jr la lb mw ju ld le mx lg lh li my lk ll lm mz lo lp lq ij bi translated">我们将在 google colab 上编写这些代码，或者您可以在这里  <em class="na">获得整个笔记本<a class="ae ls" href="https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5#scrollTo=b-i4hmGYk1dL" rel="noopener ugc nofollow" target="_blank"> <em class="na">。</em></a></em></p><p id="770d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了开始，我们将安装一些依赖项，如 COCO API，CUDA(获取关于 GPU 的信息)，Tourch Visison</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="7987" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">导入实用程序和公共库</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><h1 id="6d5d" class="md me iq bd mf mg mh mi mj mk ml mm mn jw mo jx mp jz mq ka mr kc ms kd mt mu bi translated">步骤 2:运行预训练的检测器 2 模型</h1><p id="f4cb" class="pw-post-body-paragraph kv kw iq kx b ky mv jr la lb mw ju ld le mx lg lh li my lk ll lm mz lo lp lq ij bi translated">我们将使用来自 COCO 数据集的图像，并将运行一个预训练的模型，如果你想在客户数据集上运行这个模型，请参见<a class="ae ls" href="https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="589a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在 COCO 的图像上运行模型的代码:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><blockquote class="nd ne nf"><p id="2373" class="kv kw na kx b ky kz jr la lb lc ju ld ng lf lg lh nh lj lk ll ni ln lo lp lq ij bi translated">你已经成功地用 detectron 实现了你的第一个项目。</p></blockquote><h1 id="0a8c" class="md me iq bd mf mg mh mi mj mk ml mm mn jw mo jx mp jz mq ka mr kc ms kd mt mu bi translated">结果:可视化前后</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/c1f2beb066d3be059eecea37daa88f0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*0WekZZ8Xo5AxRdHDiReopA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">下面列出了来源。</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/2b7d9525d950a4c6c794c54226edee1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8uDI2Y0Ve3VNiQffXYB0OQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae ls" href="https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5#scrollTo=dq9GY37ml1kr" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><h2 id="fc0e" class="nl me iq bd mf nm nn dn mj no np dp mn le nq nr mp li ns nt mr lm nu nv mt nw bi translated">资源:</h2><ol class=""><li id="6a97" class="lt lu iq kx b ky mv lb mw le nx li ny lm nz lq ly lz ma mb bi translated"><a class="ae ls" href="https://github.com/facebookresearch/Detectron" rel="noopener ugc nofollow" target="_blank">脸书探测仪人工智能研究页面</a></li><li id="c7ed" class="lt lu iq kx b ky oa lb ob le oc li od lm oe lq ly lz ma mb bi translated"><a class="ae ls" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Kirillov_Panoptic_Segmentation_CVPR_2019_paper.pdf" rel="noopener ugc nofollow" target="_blank">论文讲解全景分割</a></li></ol></div></div>    
</body>
</html>