<html>
<head>
<title>Live Video Streaming Using Multiple Smartphones With ImageZMQ</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用带有ImageZMQ的多部智能手机进行实时视频流传输</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/live-video-streaming-using-multiple-smartphones-with-imagezmq-e260bd081224?source=collection_archive---------19-----------------------#2020-04-24">https://towardsdatascience.com/live-video-streaming-using-multiple-smartphones-with-imagezmq-e260bd081224?source=collection_archive---------19-----------------------#2020-04-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f99a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">将您的旧智能手机回收到实时视频流网络中！</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/016e982560ded567367d3b4181681f79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Uam0eS_qVRNwOeaj"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@steve_j?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">斯蒂夫·约翰森</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><h1 id="a9e0" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="a332" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">最近，我一直在钻研计算机视觉。我对活体对象检测和对象跟踪特别感兴趣。然而，我意识到我需要我自己的现场视频流来测试我的项目。</p><p id="02ab" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">第一个问题是，我没有任何外部网络摄像头可用。我有一台内置网络摄像头的笔记本电脑，但由于其尺寸和功耗的原因，将笔记本电脑设置为仅使用网络摄像头并不太实际。然而，我确实有相当多的备用智能手机，我不再使用了。</p><p id="9195" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">第二个问题是，我还需要一些东西，允许我通过网络将帧发送到远程服务器，那里有足够的处理能力来对每个视频流运行机器学习算法。这是一个重要的问题。我的笔记本电脑远远不够强大，无法在多个流上运行YOLO和深度排序之类的东西。</p><blockquote class="ms mt mu"><p id="a5d2" class="lr ls mv lt b lu mn ju lw lx mo jx lz mw mp mc md mx mq mg mh my mr mk ml mm im bi translated">我可以用我的旧智能手机建立一个简单的相机网络吗？</p></blockquote><p id="eb6e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">起初，我使用IP camera应用程序和OpenCV成功地从一台设备通过网络传输视频。然而，当我尝试从多台设备上流式传输时，事情很快变得一团糟。还有性能问题，因为我没有异步处理帧。</p><p id="35ba" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在与OpenCV斗争了一段时间后，我偶然发现了一个由<a class="mz na ep" href="https://medium.com/u/1fb3f201026a?source=post_page-----e260bd081224--------------------------------" rel="noopener" target="_blank">杰夫·巴斯</a>为Python开发的惊人的库，名为<a class="ae ky" href="https://github.com/jeffbass/imagezmq" rel="noopener ugc nofollow" target="_blank"> ImageZMQ </a>。它允许你用几行代码创建一个视频流网络！它被设计成运行在覆盆子馅饼上，但是我没有任何可用的。相反，我用我的笔记本电脑处理并通过网络发送智能手机上的帧。ImageZMQ还显著提高了我的流性能。</p><p id="3aff" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果你想开始研究计算机视觉，或者想回收你的旧智能手机来建立一个监控系统，我会说这是一个很好的起点。</p><h2 id="6d2d" class="nb la it bd lb nc nd dn lf ne nf dp lj ma ng nh ll me ni nj ln mi nk nl lp nm bi translated">为什么选择ImageZMQ？</h2><p id="1ed0" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">顾名思义，ImageZMQ使用名为<strong class="lt iu"> ZeroMQ </strong>的无代理异步消息传递库。</p><p id="1b53" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">当涉及到实时视频流时，我们理想地想要尽可能低的延迟。异步处理允许我们实现更好的帧速率和延迟。对于较大的摄像机网络来说尤其如此。</p><p id="e7c6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">也是无经纪的。这意味着运行的进程更少，并消除了代理瓶颈的可能性。这对于实时视频流尤为重要，因为我们需要高吞吐量和低延迟性能。</p><h2 id="3d77" class="nb la it bd lb nc nd dn lf ne nf dp lj ma ng nh ll me ni nj ln mi nk nl lp nm bi translated">网络结构</h2><p id="a64a" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><a class="mz na ep" href="https://medium.com/u/2b8f8f0c68a1?source=post_page-----e260bd081224--------------------------------" rel="noopener" target="_blank"> Adrian Rosebrock </a>发表了一篇<a class="ae ky" href="https://www.pyimagesearch.com/2019/04/15/live-video-streaming-over-network-with-opencv-and-imagezmq/" rel="noopener ugc nofollow" target="_blank">精彩文章</a>，深入介绍了如何使用配有Pi摄像头模块的Raspberry Pis建立一个带运动检测的监控网络。这对我来说是多余的，正如我之前所说的，我没有这些可用的。</p><p id="5026" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">相反，我使用了一些旧的智能手机，每部手机上都安装了IP摄像头应用程序。我把智能手机传到我的笔记本电脑上，在那里它们通过网络被重定向到一个中央服务器。如果你碰巧有一些覆盆子酱，那么我建议你先看阿德里安指南，而不是我的。</p><p id="afa0" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">要做到这一点，我们需要设置多个客户机和一个服务器，作为中央处理中心。我们还需要在每部智能手机上安装一个IP摄像头应用程序。需要说明的是，我所有的智能手机都使用Android操作系统。如果你也在使用Android，那么Google Play商店里有很多IP摄像头。就我个人而言，我一直在使用<a class="ae ky" href="https://play.google.com/store/apps/details?id=com.pas.webcam&amp;hl=en_GB" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> IP网络摄像头</strong> </a>，它提供了一些有用的视频设置。但我相信其他IP摄像头应用程序的工作方式也大致相同。</p><p id="0d1e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">继续之前，请确保Python环境中安装了以下库:</p><ul class=""><li id="486d" class="nn no it lt b lu mn lx mo ma np me nq mi nr mm ns nt nu nv bi translated"><code class="fe nw nx ny nz b"><strong class="lt iu">imutils</strong></code> <strong class="lt iu">，</strong></li><li id="0df4" class="nn no it lt b lu oa lx ob ma oc me od mi oe mm ns nt nu nv bi translated"><code class="fe nw nx ny nz b"><strong class="lt iu">opencv-python</strong></code> <strong class="lt iu">，</strong></li><li id="6a11" class="nn no it lt b lu oa lx ob ma oc me od mi oe mm ns nt nu nv bi translated"><code class="fe nw nx ny nz b"><strong class="lt iu">socket</strong></code>，</li><li id="db1d" class="nn no it lt b lu oa lx ob ma oc me od mi oe mm ns nt nu nv bi translated">当然还有<code class="fe nw nx ny nz b"><strong class="lt iu">imagezmq</strong></code>。</li></ul><p id="4bdd" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了防止这些库出现任何问题，我使用Python 3.6。我建议使用与我相同或更高版本的Python。</p></div><div class="ab cl of og hx oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="im in io ip iq"><h1 id="25e2" class="kz la it bd lb lc om le lf lg on li lj jz oo ka ll kc op kd ln kf oq kg lp lq bi translated">服务器端</h1><p id="b429" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">设置服务器来接收输入帧非常简单。如果您有使用OpenCV的经验，它应该看起来很熟悉。</p><h2 id="9250" class="nb la it bd lb nc nd dn lf ne nf dp lj ma ng nh ll me ni nj ln mi nk nl lp nm bi translated">图像中心</h2><p id="c5dd" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">首先，我们需要导入OpenCV和ImageZMQ。注意，当我们安装<code class="fe nw nx ny nz b">opencv-python</code>时，我们将其导入为<code class="fe nw nx ny nz b">cv2</code>。然后，我们需要使用ImageZMQ的<code class="fe nw nx ny nz b">ImageHub</code>创建一个图像处理中心，它将接收和处理来自每个流的传入帧，这可以在一行中完成。</p><pre class="kj kk kl km gt or nz os ot aw ou bi"><span id="6892" class="nb la it nz b gy ov ow l ox oy">import cv2<br/>import imagezmq</span><span id="2b92" class="nb la it nz b gy oz ow l ox oy">image_hub = imagezmq.ImageHub()</span></pre><p id="b177" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><code class="fe nw nx ny nz b">ImageHub()</code>有两个额外的参数，您可以在其中使用。第一个参数是<code class="fe nw nx ny nz b">open_port</code>，默认情况下在端口5555接受任何传入的TCP流量。第二个参数是<code class="fe nw nx ny nz b">REQ_REP</code>，代表请求-回复，默认为<code class="fe nw nx ny nz b">True</code>。这是一种ZeroMQ模式，在发送下一帧之前，客户端发送的每一帧都必须等待服务器的回复。如果我们将此设置为<code class="fe nw nx ny nz b">False</code>，那么模式将改为发布-订阅模式。</p><p id="62ad" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">对于我们的场景，我们希望有一台服务器来处理多个客户端发送给它的视频帧。发布-订阅模式要求每个客户机本身也是一个服务器，主处理中心订阅这些服务器中的每一个。这需要预先知道每个流的地址，所以这不是我们想要做的最实际的事情。因此，我们保留默认值并保持不变。</p><p id="b242" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">然而，Jeff已经很好地解释了使用发布-订阅模式的好处。如果您有兴趣学习更多关于ZeroMQ模式的知识，那么我建议您阅读一下。</p><h2 id="0234" class="nb la it bd lb nc nd dn lf ne nf dp lj ma ng nh ll me ni nj ln mi nk nl lp nm bi translated">显示帧</h2><p id="a06d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">下一步是创建一个循环，从每个流中提取每一帧，并相应地显示它们。这可以通过使用while循环和OpenCV的<code class="fe nw nx ny nz b">imshow()</code>方法来完成，如下所示。</p><pre class="kj kk kl km gt or nz os ot aw ou bi"><span id="8cfd" class="nb la it nz b gy ov ow l ox oy">while True:  <br/>    cam_id, frame = image_hub.recv_image()<br/><br/>    cv2.imshow(cam_id, frame)  <br/><br/>    cv2.waitKey(1)<br/><br/>    image_hub.send_reply(b'OK')</span></pre><p id="4dd0" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们使用<code class="fe nw nx ny nz b">recv_image()</code>对输入流进行解包，以获得每个视频流的帧以及每个摄像机设备的名称。</p><p id="9945" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了显示每个摄像机的帧，我们使用<code class="fe nw nx ny nz b">cv2.imshow()</code>。最好的部分是，这种方法将自动分离和显示每个视频流的帧！然后我们需要<code class="fe nw nx ny nz b">cv2.waitKey(1)</code>来允许每一帧在1ms后刷新。</p><p id="f919" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">最后，由于我们使用的是请求-回复模式，我们需要向客户端发送一条OK消息，让他们知道服务器已经成功接收并处理了该帧。然后，客户端将知道继续向服务器发送帧。</p></div><div class="ab cl of og hx oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="im in io ip iq"><h1 id="40dc" class="kz la it bd lb lc om le lf lg on li lj jz oo ka ll kc op kd ln kf oq kg lp lq bi translated">客户端</h1><p id="3b0e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">每个客户端的代码也非常简单。我们需要知道的唯一事情是，要向服务器发送帧，我们需要用正确的流路径和服务器地址配置每个客户端。</p><h2 id="d95a" class="nb la it bd lb nc nd dn lf ne nf dp lj ma ng nh ll me ni nj ln mi nk nl lp nm bi translated">设置流</h2><p id="536b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">对于客户端，我们需要从imutils导入ImageZMQ、socket和<code class="fe nw nx ny nz b">VideoStream()</code>方法。然后，我们使用<code class="fe nw nx ny nz b">VideoStream()</code>从我们的相机捕捉帧。我们<em class="mv">本可以</em>使用OpenCV的<code class="fe nw nx ny nz b">VideoCapture() </code>来代替，但是imutil的<code class="fe nw nx ny nz b">VideoStream()</code>将<code class="fe nw nx ny nz b">picamera</code>模块与OpenCV结合起来，万一我们将来决定使用Raspberry Pis，这是一个很好的选择。</p><pre class="kj kk kl km gt or nz os ot aw ou bi"><span id="5ae4" class="nb la it nz b gy ov ow l ox oy">from imutils.video import VideoStream<br/>import imagezmq<br/>import socket</span><span id="3bef" class="nb la it nz b gy oz ow l ox oy"># change this to your stream address<br/>path = "rtsp://192.168.1.70:8080//h264_ulaw.sdp"</span><span id="fba5" class="nb la it nz b gy oz ow l ox oy">cap = VideoStream(path)</span></pre><p id="4d11" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><code class="fe nw nx ny nz b">path</code>应该是一个来自你的IP摄像头应用程序的链接。你可以通过打开智能手机上的应用程序很容易地找到这一点。</p><p id="58c9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">请注意，如果您通过路由器进行流式传输，地址可能会改变。你需要在路由器内给设备一个静态IP地址，否则如果你再次运行代码，它会中断你的数据流。</p><p id="0048" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">然后，我们需要使用ImageZMQ创建一个图像发送器，并为我们的相机命名。我们现在可以开始了。</p><pre class="kj kk kl km gt or nz os ot aw ou bi"><span id="37f2" class="nb la it nz b gy ov ow l ox oy"># change this to your server address<br/>sender = imagezmq.ImageSender(connect_to='tcp://localhost:5555') <br/><br/>cam_id = socket.gethostname()</span><span id="e989" class="nb la it nz b gy oz ow l ox oy">stream = cap.start()</span></pre><p id="9a8d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><code class="fe nw nx ny nz b">ImageSender()</code>也有<code class="fe nw nx ny nz b">REQ_REP</code>参数，但是如前所述，我们将其保留为<code class="fe nw nx ny nz b">True</code>的默认值。我们只需要指定将帧发送到的服务器地址。在本例中，我在端口5555使用了localhost，因为我是从同一台机器上流式传输的。例如，如果我们将数据流传输到云中的一个服务器，那么我们将用该机器的IP地址替换localhost。这是假设服务器通过打开正确的端口(默认情况下是端口5555)来允许流量。</p><p id="56c4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们还使用<code class="fe nw nx ny nz b">socket.gethostname()</code>来获取我们正在传输的设备的名称。如果我们使用Raspberry Pis，那么这是一种自动获取每个设备名称的简单方法。如果您只有几个设备，那么您可以手动将<code class="fe nw nx ny nz b">cam_id</code>更改为简单的数字。</p><h2 id="61e9" class="nb la it bd lb nc nd dn lf ne nf dp lj ma ng nh ll me ni nj ln mi nk nl lp nm bi translated">发送帧</h2><p id="b2cc" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">为了发送帧，我们再次需要一个循环，从视频流中读取帧，然后使用前面的<code class="fe nw nx ny nz b">ImageSender()</code>发送它们。</p><pre class="kj kk kl km gt or nz os ot aw ou bi"><span id="6cd1" class="nb la it nz b gy ov ow l ox oy">while True:<br/>    frame = stream.read()<br/>    sender.send_image(cam_id, frame)</span></pre><p id="8010" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">…我们完成了！现在我们需要做的就是为每个设备创建一个客户端脚本，并确保为每个设备正确配置了<code class="fe nw nx ny nz b">path</code>和<code class="fe nw nx ny nz b">cam_id</code>变量。</p></div><div class="ab cl of og hx oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="im in io ip iq"><h1 id="0a21" class="kz la it bd lb lc om le lf lg on li lj jz oo ka ll kc op kd ln kf oq kg lp lq bi translated">把所有东西放在一起</h1><p id="3107" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">一旦每个设备都准备好自己的客户端脚本和IP摄像机运行，确保流路径和服务器地址是正确的，然后启动服务器。只有服务器启动并运行后，设备才能开始发送帧。运行每个客户端，你应该能够看到每个单独的视频流出现在服务器端！</p></div></div>    
</body>
</html>