<html>
<head>
<title>MapReduce</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">MapReduce</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/simplifying-the-mapreduce-framework-20915f13ebd3?source=collection_archive---------45-----------------------#2020-05-29">https://towardsdatascience.com/simplifying-the-mapreduce-framework-20915f13ebd3?source=collection_archive---------45-----------------------#2020-05-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2e28" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">简化 MapReduce 框架</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/b48699ba0fa3d349d437df9b13f4edc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_phBzciHREC7bW8Nikaj-Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Apache Hadoop MapReduce 架构</p></figure><p id="4dfb" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi lr translated">在 2003 年，Google 提出了一个迷人的框架，通过他们革命性的白皮书“MapReduce:大型集群上的简化数据处理”，在分布于多个节点的大型数据集上实现并行处理。</p><p id="20d6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，MapReduce (MR)是 Hadoop 的主要处理框架，跨多个应用程序使用，如 Sqoop、Pig、Hive 等。</p><h2 id="963b" class="ma mb iq bd mc md me dn mf mg mh dp mi le mj mk ml li mm mn mo lm mp mq mr ms bi translated">数据存储在 HDFS</h2><p id="525b" class="pw-post-body-paragraph kv kw iq kx b ky mt jr la lb mu ju ld le mv lg lh li mw lk ll lm mx lo lp lq ij bi translated">如果你是 HDFS (Hadoop 分布式文件系统)的新手，或者想要复习一下，我建议你看看我的<a class="ae my" rel="noopener" target="_blank" href="/hadoop-distributed-file-system-b09946738555">综合指南</a>。否则，继续阅读。</p><p id="e2a4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在上面的流程图中，我们在 HDFS 存储了一个大的 csv 文件。我们的复制系数(RF)为 2，数据块大小为 128 MB，有 2 个数据节点。因此，B1、B3、B3、B4 等，每个大小为 128 MB，放置在两个数据节点中，如上面的流程图所示。</p><blockquote class="mz"><p id="99e8" class="na nb iq bd nc nd ne nf ng nh ni lq dk translated">Hadoop 与传统客户端-服务器架构的不同之处在于，数据位于静态位置，而作业/流程移动到数据所在的位置。这显著提高了性能。</p></blockquote><p id="ab16" class="pw-post-body-paragraph kv kw iq kx b ky nj jr la lb nk ju ld le nl lg lh li nm lk ll lm nn lo lp lq ij bi translated">想想看，数据的大小通常是 GB 到 PBs，而作业/进程只有几 MB。因此，通过网络将数据转移到作业/流程中非常昂贵，但是通过网络将作业/流程转移到存储数据的地方非常便宜。这就是 HDFS 建筑的美。</p><h2 id="c38d" class="ma mb iq bd mc md me dn mf mg mh dp mi le mj mk ml li mm mn mo lm mp mq mr ms bi translated">制图人</h2><p id="4d65" class="pw-post-body-paragraph kv kw iq kx b ky mt jr la lb mu ju ld le mv lg lh li mw lk ll lm mx lo lp lq ij bi translated">从本质上讲，谷歌的人认为数据处理的大多数用例都适合 Map + Reduce 任务。我认为大约 90%的任务都适合这种形式。</p><p id="d864" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">那么，什么是映射器呢？映射器只是一个函数，它接受一个键、值(k，v)对，对其进行处理并返回一个(k，v)对。下面是它的编程方式:</p><pre class="kg kh ki kj gt no np nq nr aw ns bi"><span id="51e7" class="ma mb iq np b gy nt nu l nv nw">map(in_key, in_value) -&gt; list(intermediate_key, intermediate_value)</span></pre><p id="f0aa" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">工作开始:地图 0%减少 0% </strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/89facc845c9bf0e8a17f5e87c3b13599.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3gueHiPod67p5TQhX5SSzA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">制图人</p></figure><ol class=""><li id="68f0" class="ny nz iq kx b ky kz lb lc le oa li ob lm oc lq od oe of og bi translated"><strong class="kx ir">输入格式— </strong>指向 HDFS 文件块位置的指针。这些数据仍然没有被加载到内存中，目前按原样放在 HDFS 上。在我们的例子中，节点 1 的输入格式中的指针指向块 1 和块 2。类似地，在节点 2 中，它指向块 3 和块 4。</li><li id="c9c0" class="ny nz iq kx b ky oh lb oi le oj li ok lm ol lq od oe of og bi translated"><strong class="kx ir"> Split — </strong>此时，文件实际上被加载到内存中。拆分的数量等于该节点中的块数。拆分器和 RecordReader 一起工作。</li><li id="7377" class="ny nz iq kx b ky oh lb oi le oj li ok lm ol lq od oe of og bi translated"><strong class="kx ir"> RR 或 RecordReader — </strong>我肯定您想知道如何将一个简单的文件转换成(k，v)对。嗯，谷歌在他们的白皮书中提到，大部分处理是通过抽象完成的，这很好！记录阅读器只是为我们将数据处理成(k，v)对。此外，有多种方法可以实现这一点。更多细节见下文。</li><li id="0b0a" class="ny nz iq kx b ky oh lb oi le oj li ok lm ol lq od oe of og bi translated"><strong class="kx ir"> Map — </strong>最后，我们到达“Map”函数，在这里进行实际的处理。无论您希望函数执行什么逻辑，这里都是它发生的地方。发布此消息后，最终得到的(k，v)对再次被卸载到 HDFS，reducer 任务开始。</li></ol><p id="3fe6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">工作状态:地图 100%减少 0% </strong></p><h2 id="1a48" class="ma mb iq bd mc md me dn mf mg mh dp mi le mj mk ml li mm mn mo lm mp mq mr ms bi translated">还原剂</h2><p id="dce3" class="pw-post-body-paragraph kv kw iq kx b ky mt jr la lb mu ju ld le mv lg lh li mw lk ll lm mx lo lp lq ij bi translated">一个 reducer，就像一个 mapper，也是一个函数，它接受一个(k，v)对，处理它并返回一个(k，v)对。以下是图示:</p><pre class="kg kh ki kj gt no np nq nr aw ns bi"><span id="5ebd" class="ma mb iq np b gy nt nu l nv nw">reduce(intermediate_key, list(intermediate_value) -&gt; list(out_key, out_value)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi om"><img src="../Images/6b74b4cb1935c53c98d1baeb6a7050a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rjoGQQt0swL4CjyzinldFQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">还原剂</p></figure><ol class=""><li id="0287" class="ny nz iq kx b ky kz lb lc le oa li ob lm oc lq od oe of og bi translated"><strong class="kx ir">分割器— </strong>中间(k，v)对再次被原样加载到内存中。并且使用这些中间键，将一个<em class="on">分组函数</em>应用于数据集。我们将在下一节的例子中更好地理解这一点。如果你觉得幸运的话——这里有一个<a class="ae my" href="https://acadgild.com/blog/mapreduce-custom-partitioner" rel="noopener ugc nofollow" target="_blank">定制分区</a>。</li><li id="f729" class="ny nz iq kx b ky oh lb oi le oj li ok lm ol lq od oe of og bi translated"><strong class="kx ir"> Shuffle — </strong>这是跨节点的分组。基本上，公共键现在在节点间“混洗”。</li><li id="d3c4" class="ny nz iq kx b ky oh lb oi le oj li ok lm ol lq od oe of og bi translated"><strong class="kx ir">排序— </strong>数据现在根据关键字排序。</li><li id="f7df" class="ny nz iq kx b ky oh lb oi le oj li ok lm ol lq od oe of og bi translated"><strong class="kx ir"> Reduce — </strong>最后，我们到达“Reduce”函数，在这里进行数据的实际聚合。无论您希望该函数执行什么样的聚合，这里都是它发生的地方。</li><li id="dd51" class="ny nz iq kx b ky oh lb oi le oj li ok lm ol lq od oe of og bi translated"><strong class="kx ir">输出格式— </strong>最终得到的(k，v)对通过 RecordWriter (RW —更多细节见下文)再次卸载到 HDFS，作业完成。</li></ol><p id="0baf" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">工作状态:地图 100%缩小 100% </strong></p></div><div class="ab cl oo op hu oq" role="separator"><span class="or bw bk os ot ou"/><span class="or bw bk os ot ou"/><span class="or bw bk os ot"/></div><div class="ij ik il im in"><h2 id="94fc" class="ma mb iq bd mc md me dn mf mg mh dp mi le mj mk ml li mm mn mo lm mp mq mr ms bi translated">用一个简单的例子把它们放在一起</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ov"><img src="../Images/2eb1ac74603d76cb6caa1221ca4e401a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*k43qY_Bsw5X0QNhy"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae my" href="https://unsplash.com/@andreasdress?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">德乐思教授</a>在<a class="ae my" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="64b4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">假设你是特斯拉汽车公司的首席执行官埃隆·马斯克。你得到了以下特斯拉汽车一年来的全球销量数据(百万辆)。很自然，你很高兴，你抽了一些，然后马上在推特上说:</p><blockquote class="mz"><p id="3687" class="na nb iq bd nc nd ne nf ng nh ni lq dk translated">特斯拉的股价在我看来太高了</p></blockquote><p id="7b70" class="pw-post-body-paragraph kv kw iq kx b ky nj jr la lb nk ju ld le nl lg lh li nm lk ll lm nn lo lp lq ij bi translated">好吧，那是个错误。那你哭还是不哭。反正我跑题了。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ow ox l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">特斯拉汽车销售数据集(百万)</p></figure><p id="7c1d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这些数据现在在 HDFS 被分成几个数据块，平均分布在两个数据节点中(根据 RF)。这是两个区块(B1 和 B3)的样子:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ow ox l"/></div></figure><p id="6804" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">映射器输出</strong>:</p><pre class="kg kh ki kj gt no np nq nr aw ns bi"><span id="c7ec" class="ma mb iq np b gy nt nu l nv nw"><strong class="np ir">Country,Sales(M)</strong><br/>USA,1<br/>Russia,1<br/>UK,1<br/>France,1<br/>China,1<br/>Russia,1<br/>UK,1<br/>France,1<br/>China,1<br/>USA,1</span><span id="f0b7" class="ma mb iq np b gy oy nu l nv nw"><strong class="np ir">Country,Sales(M)<br/></strong>UK,1<br/>USA,1<br/>China,1<br/>UK,1<br/>USA,1<br/>China,1<br/>UK,1<br/>USA,1<br/>China,1<br/>UK,1</span></pre><p id="582b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">输出到 HDFS —生成 2 个文件</p><p id="2b3b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">减速器</strong>:</p><pre class="kg kh ki kj gt no np nq nr aw ns bi"><span id="53db" class="ma mb iq np b gy nt nu l nv nw"><strong class="np ir">Country,Sales(M): Partition<br/></strong>USA,1<br/>USA,1<br/>Russia,1<br/>Russia,1<br/>UK,1<br/>UK,1<br/>France,1<br/>France,1<br/>China,1<br/>China,1</span><span id="bb4b" class="ma mb iq np b gy oy nu l nv nw"><strong class="np ir">Country,Sales(M)</strong>: <strong class="np ir">Partition<br/></strong>UK,1<br/>UK,1<br/>UK,1<br/>UK,1<br/>USA,1<br/>USA,1<br/>USA,1<br/>China,1<br/>China,1<br/>China,1</span><span id="25f1" class="ma mb iq np b gy oy nu l nv nw"><strong class="np ir">Country,Sales(M)</strong>: <strong class="np ir">Shuffle<br/></strong>Russia,1<br/>Russia,1<br/>France,1<br/>France,1</span><span id="a60d" class="ma mb iq np b gy oy nu l nv nw"><strong class="np ir">Country,Sales(M)</strong>: <strong class="np ir">Shuffle<br/></strong>USA,1<br/>USA,1<br/>USA,1<br/>USA,1<br/>USA,1<br/>UK,1<br/>UK,1<br/>UK,1<br/>UK,1<br/>UK,1<br/>UK,1<br/>China,1<br/>China,1<br/>China,1<br/>China,1<br/>China,1</span><span id="da8b" class="ma mb iq np b gy oy nu l nv nw"><strong class="np ir">Country,Sales(M)</strong>: <strong class="np ir">Sort<br/></strong>France,1<br/>France,1<br/>Russia,1<br/>Russia,1</span><span id="d116" class="ma mb iq np b gy oy nu l nv nw"><strong class="np ir">Country,Sales(M)</strong>: <strong class="np ir">Sort<br/></strong>China,1<br/>China,1<br/>China,1<br/>China,1<br/>China,1<br/>USA,1<br/>USA,1<br/>USA,1<br/>USA,1<br/>USA,1<br/>UK,1<br/>UK,1<br/>UK,1<br/>UK,1<br/>UK,1<br/>UK,1</span><span id="6a51" class="ma mb iq np b gy oy nu l nv nw"><strong class="np ir">Country,Sales(M)</strong>: <strong class="np ir">Reduce<br/></strong>France,2<br/>Russia,2</span><span id="d796" class="ma mb iq np b gy oy nu l nv nw"><strong class="np ir">Country,Sales(M)</strong>: <strong class="np ir">Reduce<br/></strong>China,5<br/>USA,5<br/>UK,6</span></pre><p id="204e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">输出到 HDFS —生成 2 个文件。大概就是这样。有问题吗？不要犹豫地问。</p></div><div class="ab cl oo op hu oq" role="separator"><span class="or bw bk os ot ou"/><span class="or bw bk os ot ou"/><span class="or bw bk os ot"/></div><div class="ij ik il im in"><h2 id="c26b" class="ma mb iq bd mc md me dn mf mg mh dp mi le mj mk ml li mm mn mo lm mp mq mr ms bi translated">记录阅读器</h2><p id="0a39" class="pw-post-body-paragraph kv kw iq kx b ky mt jr la lb mu ju ld le mv lg lh li mw lk ll lm mx lo lp lq ij bi translated">以下方法可用于将数据转换成(K，V)对:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ow ox l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">RecordReaderInputFormat</p></figure><h2 id="40cb" class="ma mb iq bd mc md me dn mf mg mh dp mi le mj mk ml li mm mn mo lm mp mq mr ms bi translated">记录器(RW)</h2><p id="8ce6" class="pw-post-body-paragraph kv kw iq kx b ky mt jr la lb mu ju ld le mv lg lh li mw lk ll lm mx lo lp lq ij bi translated">以下方法可用于将(K，V)对转换为输出数据:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ow ox l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">RecordWriterOutputFormat</p></figure></div><div class="ab cl oo op hu oq" role="separator"><span class="or bw bk os ot ou"/><span class="or bw bk os ot ou"/><span class="or bw bk os ot"/></div><div class="ij ik il im in"><h1 id="5111" class="oz mb iq bd mc pa pb pc mf pd pe pf mi jw pg jx ml jz ph ka mo kc pi kd mr pj bi translated">优步模式</h1><p id="2bb8" class="pw-post-body-paragraph kv kw iq kx b ky mt jr la lb mu ju ld le mv lg lh li mw lk ll lm mx lo lp lq ij bi translated">摘自我的 Apache Sqoop 帖子(脚注中的链接):</p><blockquote class="pk pl pm"><p id="54d1" class="kv kw on kx b ky kz jr la lb lc ju ld pn lf lg lh po lj lk ll pp ln lo lp lq ij bi translated">MapReduce 作业的 Mapper 和 Reducer 任务由<a class="ae my" rel="noopener" target="_blank" href="/apache-yarn-zookeeper-61e17a958215"> YARN </a>的资源管理器(RM)在分布于几个节点的两个独立容器中运行。但是，如果您的数据集很小，或者您的作业包含小型制图工具任务，或者您的作业仅包含一个缩减器任务，我们可以将优步模式设置为 TRUE。这迫使 RM 在一个容器或 JVM 中顺序运行 mapper 和 reducer 任务，从而减少了启动新容器和跨多个节点为一个小任务建立网络的开销。工作完成得更快。</p></blockquote></div><div class="ab cl oo op hu oq" role="separator"><span class="or bw bk os ot ou"/><span class="or bw bk os ot ou"/><span class="or bw bk os ot"/></div><div class="ij ik il im in"><p id="eec3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">参考资料:</p><p id="804e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[1] J. Dean，S. Ghemawat (2003)，<a class="ae my" href="https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf" rel="noopener ugc nofollow" target="_blank"> MapReduce:大型集群上的简化数据处理</a>，Google</p><p id="76ef" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[1.1] J. Dean，S. Ghemawat (2003)，<a class="ae my" href="https://research.google.com/archive/mapreduce-osdi04-slides/index.html" rel="noopener ugc nofollow" target="_blank"> HTML 幻灯片— MapReduce:大型集群上的简化数据处理</a>，Google</p><p id="8dd5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[2] Manjunath (2016)，<a class="ae my" href="https://acadgild.com/blog/mapreduce-custom-partitioner" rel="noopener ugc nofollow" target="_blank"> MapReduce 自定义分区器</a>，Acadgild</p><p id="48be" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[3] C. Chaudhari，<a class="ae my" href="https://community.cloudera.com/t5/Support-Questions/What-is-Uber-mode/td-p/211160" rel="noopener ugc nofollow" target="_blank">什么是优步模式？</a> (2018)，Cloudera 社区</p><p id="c3f1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[4] <a class="ae my" href="https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html" rel="noopener ugc nofollow" target="_blank"> MapReduce 教程</a> (2019)，Apache Hadoop MapReduce 客户端，ASF</p></div><div class="ab cl oo op hu oq" role="separator"><span class="or bw bk os ot ou"/><span class="or bw bk os ot ou"/><span class="or bw bk os ot"/></div><div class="ij ik il im in"><div class="kg kh ki kj gt pq"><a rel="noopener follow" target="_blank" href="/apache-flume-71ed475eee6d"><div class="pr ab fo"><div class="ps ab pt cl cj pu"><h2 class="bd ir gy z fp pv fr fs pw fu fw ip bi translated">阿帕奇水槽</h2><div class="px l"><h3 class="bd b gy z fp pv fr fs pw fu fw dk translated">使用 Apache Flume 将非结构化数据涓滴输入 HDFS</h3></div><div class="py l"><p class="bd b dl z fp pv fr fs pw fu fw dk translated">towardsdatascience.com</p></div></div><div class="pz l"><div class="qa l qb qc qd pz qe kp pq"/></div></div></a></div><div class="qf qg gp gr qh pq"><a rel="noopener follow" target="_blank" href="/apache-sqoop-1113ce453639"><div class="pr ab fo"><div class="ps ab pt cl cj pu"><h2 class="bd ir gy z fp pv fr fs pw fu fw ip bi translated">Apache Sqoop</h2><div class="px l"><h3 class="bd b gy z fp pv fr fs pw fu fw dk translated">RDBMS 到 HDFS 并返回</h3></div><div class="py l"><p class="bd b dl z fp pv fr fs pw fu fw dk translated">towardsdatascience.com</p></div></div><div class="pz l"><div class="qi l qb qc qd pz qe kp pq"/></div></div></a></div><div class="qf qg gp gr qh pq"><a href="https://medium.com/@prathamesh.nimkar/big-data-analytics-using-the-hadoop-ecosystem-411d629084d3" rel="noopener follow" target="_blank"><div class="pr ab fo"><div class="ps ab pt cl cj pu"><h2 class="bd ir gy z fp pv fr fs pw fu fw ip bi translated">使用 Hadoop 生态系统的大数据分析渠道</h2><div class="px l"><h3 class="bd b gy z fp pv fr fs pw fu fw dk translated">登录页面</h3></div><div class="py l"><p class="bd b dl z fp pv fr fs pw fu fw dk translated">medium.com</p></div></div><div class="pz l"><div class="qj l qb qc qd pz qe kp pq"/></div></div></a></div></div></div>    
</body>
</html>