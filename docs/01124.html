<html>
<head>
<title>Topic Modeling Tutorial with Latent Dirichlet Allocation (LDA)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用潜在狄利克雷分配(LDA)的主题建模教程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/topic-modeling-with-latent-dirichlet-allocation-by-example-3b22cd10c835?source=collection_archive---------9-----------------------#2020-02-01">https://towardsdatascience.com/topic-modeling-with-latent-dirichlet-allocation-by-example-3b22cd10c835?source=collection_archive---------9-----------------------#2020-02-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="dfba" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">这是一本实用指南，包含经过实践检验的Python代码。找到人们在推特上谈论的内容。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/85d755589b3ee9f8f837d4c5fb8e47ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/0*U90la28EHpwkWPcY.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">来源:杰夫·克拉克的在线推特话题浏览器生成的图片</p></figure><p id="c9db" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">对内容好奇？感觉迷失在无数的帖子、推文、评论、文章、页面、文档中？寻找人们写的东西？你并不孤单。</p><p id="2d61" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在本教程中，我提供了一个实用的指南，其中包含经过实践检验的Python代码，用于发现文本或文档集合中出现的抽象主题。</p><p id="5a0c" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们将对一组推文应用潜在狄利克雷分配(LDA ),并将它们分成主题。我们开始吧！</p><h1 id="5a36" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">推特数据</h1><p id="cf0d" class="pw-post-body-paragraph kv kw it kx b ky mj ju la lb mk jx ld le ml lg lh li mm lk ll lm mn lo lp lq im bi translated">我们将处理来自@realDonaldTrump推特账户的推文。该数据集包含该账户自2009年5月4日以来的所有推文。</p><p id="0ff4" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">数据集来自http://www.trumptwitterarchive.com/archive<a class="ae ku" href="http://www.trumptwitterarchive.com/archive" rel="noopener ugc nofollow" target="_blank"/>。下面是原始档案的摘录。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mo mp l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi mq"><img src="../Images/4f689c72533890ec48e11f35265367b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UxsRwC9ZPFf4NBBJpxA8Cg.png"/></div></div></figure><h1 id="2f47" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">数据预处理</h1><p id="2e66" class="pw-post-body-paragraph kv kw it kx b ky mj ju la lb mk jx ld le ml lg lh li mm lk ll lm mn lo lp lq im bi translated">对文本进行预处理是很重要的，因为语言在各个层面都是模糊的:词汇、短语、语义。我们将推文全部小写，并删除了<strong class="kx iu">的停用词</strong>。它们是常用词，不会给推文增加重要意义。以下是自然语言工具包(NLTK)中的停用词示例。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mo mp l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/043c31e17944d04086e3b50ae72d94db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/1*SJ54o-Pb7A1mWyEZWuvd-Q.png"/></div></figure><p id="c2ae" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">鉴于推文的性质，我们要小心使用标点符号和术语，如<strong class="kx iu"> RT </strong>(用于转发推文)和<strong class="kx iu"> VIA </strong>(用于提及原作者)，它们不在默认的英语停用词表中。我们还想删除推文末尾的网址。</p><p id="01cb" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们也<strong class="kx iu">标记</strong>我们的推文。<strong class="kx iu"> </strong>记号化器的工作原理类似于正则表达式，用于将tweets分成单词列表。下面我们提供了预处理推文的完整代码。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mo mp l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi mw"><img src="../Images/b815c4ada55d84a7879cde999d0e6673.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dsk1xxtcL74zryLda_ZDXg.png"/></div></div></figure><h1 id="22d8" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">一袋单词</h1><p id="2f93" class="pw-post-body-paragraph kv kw it kx b ky mj ju la lb mk jx ld le ml lg lh li mm lk ll lm mn lo lp lq im bi translated">当我们对文本分类感兴趣时，根据主题分类，我们通常不想看单词的顺序模式。相反，我们会将文本表示为一个单词包，就好像它是一组无序的单词，同时忽略它们在文本中的原始位置，只保留它们的频率。你可以在我们下面的文章中了解更多关于自然语言处理的知识。</p><div class="mx my gp gr mz na"><a rel="noopener follow" target="_blank" href="/representing-text-in-natural-language-processing-1eead30e57d8"><div class="nb ab fo"><div class="nc ab nd cl cj ne"><h2 class="bd iu gy z fp nf fr fs ng fu fw is bi translated">自然语言处理中的文本表示</h2><div class="nh l"><h3 class="bd b gy z fp nf fr fs ng fu fw dk translated">理解书面单词:温习Word2vec、GloVe、TF-IDF、单词袋、N-grams、1-hot编码…</h3></div><div class="ni l"><p class="bd b dl z fp nf fr fs ng fu fw dk translated">towardsdatascience.com</p></div></div><div class="nj l"><div class="nk l nl nm nn nj no ko na"/></div></div></a></div><p id="69b1" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">最常见的单词及其计数如下。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mo mp l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/16ab895e3c4ed6ef4df1dd13c8b0e197.png" data-original-src="https://miro.medium.com/v2/resize:fit:328/format:webp/1*6dltZJhI15VVk7JhR4X9Bw.png"/></div></figure><h1 id="8e19" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">寻找主题的数量</h1><p id="0093" class="pw-post-body-paragraph kv kw it kx b ky mj ju la lb mk jx ld le ml lg lh li mm lk ll lm mn lo lp lq im bi translated"><strong class="kx iu">潜在狄利克雷分配(LDA) </strong>是从词袋计数到更低维度的主题空间的概率变换。推文被视为主题的分布。反过来，主题由词汇表中所有单词的分布来表示。但是我们不知道语料库中出现的主题数量以及属于每个主题的tweets。使用LDA，我们希望将tweets到主题的分配视为一个随机变量，它是根据手头的数据估计的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi nq"><img src="../Images/4b881dfc039fc9fc5d587f988d035933.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s5ornZrlCWPQh8Q1toHEjg.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">来源:马克·格利克曼(哈佛大学IACS分校)</p></figure><p id="7d54" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">为LDA寻找合适数量的主题是一门艺术。<strong class="kx iu">主题连贯</strong>技术通常比困惑技术更受青睐。对于连贯性，我们通过测量高得分单词之间的语义相似度来量化主题的连贯性。这就引出了更人性化的话题。该技术选择每个主题中出现频率最高的单词。然后，它计算并汇总每个单词的所有成对得分(UMass ),以计算特定主题的一致性得分。</p><p id="c9d4" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">下面，我们将一系列用不同数量的主题训练的模型的每个主题的平均一致性分数可视化。平均分稳定的主题数量，是我们正在寻找的最佳点。因此，我们对主题数量的最佳猜测是6个左右。我们应该考虑到，通常情况下，包含非常短的文档(在我们的例子中是tweets)的语料库比包含较长文档的语料库更难应用于连贯模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mo mp l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/caae6becd3289422d892a9addf9989bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*cPIfTpxB8w3mxAlpciWlsQ.png"/></div></figure><h1 id="1b10" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">运行LDA</h1><p id="fcfa" class="pw-post-body-paragraph kv kw it kx b ky mj ju la lb mk jx ld le ml lg lh li mm lk ll lm mn lo lp lq im bi translated">现在，我们可以使用通过上述分析找到的最优值对文本运行LDA。LDA是一种生成方法，其中对于每个主题，模型模拟单词出现的概率以及主题在文档中的概率。每个主题的前10个单词如下所示。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mo mp l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi ns"><img src="../Images/7354d853af29d906f6748dcb3afdfa8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xNi4Ffihw7v06OlAdmY-IQ.png"/></div></div></figure><p id="0cee" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">虽然题目的合理性值得怀疑，但我们可以看到下面有意义的匹配。主题0涉及中国、朝鲜和美国领导人之间的会晤。话题1似乎与联邦调查局对俄罗斯干涉上届总统选举的调查有关。话题4好像是关于边境安全和修建边境墙的。</p><h1 id="f103" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">结论</h1><p id="5e5d" class="pw-post-body-paragraph kv kw it kx b ky mj ju la lb mk jx ld le ml lg lh li mm lk ll lm mn lo lp lq im bi translated">我们展示了统计建模如何帮助发现人们在推特上谈论什么。本文提供的代码可以推广到许多其他任务，旨在发现文档集合中出现的抽象主题。</p><h2 id="9bba" class="nt ls it bd lt nu nv dn lx nw nx dp mb le ny nz md li oa ob mf lm oc od mh oe bi translated">一些参考资料:</h2><p id="fe49" class="pw-post-body-paragraph kv kw it kx b ky mj ju la lb mk jx ld le ml lg lh li mm lk ll lm mn lo lp lq im bi translated">D.布莱，阿宁和乔丹。潜在狄利克雷分配。机器学习研究杂志，3:993–1022，2003年1月。d .布雷和j .拉弗蒂。主题模型。编辑，文本挖掘:理论与应用。泰勒和弗朗西斯，2009年。<br/> B .陈，x .陈，andW。邢。学习分析和知识会议的“Twitter考古学”。《第五届学习分析和知识国际会议论文集》(第340-349页)。纽约州纽约市，2015年。</p><p id="ba0d" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">感谢您的阅读。期待您的反馈或问题。</p></div></div>    
</body>
</html>