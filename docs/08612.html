<html>
<head>
<title>Use SHAP loss values to debug/monitor your model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用SHAP损耗值来调试/监控您的模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/use-shap-loss-values-to-debug-monitor-your-model-83f7808af40f?source=collection_archive---------32-----------------------#2020-06-22">https://towardsdatascience.com/use-shap-loss-values-to-debug-monitor-your-model-83f7808af40f?source=collection_archive---------32-----------------------#2020-06-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="b587" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">你应该如何理解和使用SHAP损失值</h2></div><p id="affe" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">近年来，负责任的人工智能一直是一个非常热门的话题。问责制和可解释性现在成为机器学习模型的必要组成部分，特别是当模型做出将影响人们生活的决策时，例如医疗诊断和金融服务。这是机器学习的一个非常大的主题，许多正在进行的工作都致力于各个方面。您可以查看关于这个主题的更多资源[1]。在这篇文章中，我将重点介绍<a class="ae lb" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank">SHAP</a>(SHapley Additive explaining)，这是最受欢迎的可解释性包之一，因为它的通用性(局部/全局可解释性；模型特定/不可知)和来自博弈论的坚实理论基础。您可以找到许多帖子和教程来了解SHAP如何帮助您了解您的ML模型如何工作，即您的每个要素如何对模型预测做出贡献。然而，在这篇文章中，我将谈论许多人可能不太熟悉的SHAP损失值。我将通过一个例子来介绍一些关键概念。我也分享一下我的一些想法。</p><p id="0c8b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，你可能想要检查由SHAP软件包提供的<a class="ae lb" href="https://github.com/slundberg/shap/blob/master/notebooks/tree_explainer/Explaining%20the%20Loss%20of%20a%20Model.ipynb" rel="noopener ugc nofollow" target="_blank">例子</a>。有两个重要的注意事项:</p><ul class=""><li id="c44b" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">shap loss值将向您显示每个要素如何影响logloss值与预期值的比值。注意，在这篇文章中，当我说损失值时，它指的是logloss，因为我们将研究分类问题)</li></ul><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ll"><img src="../Images/d5ab54c1c42e00e1edf68392d2ad4de2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hRVvBOloozyUQvxUm5HIXQ.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">就像预测的SHAP值一样，SHAP损失值表示每个要素对对数损失的影响。预期值是依赖于标签的基线值。当数据实例为真时，通过将所有实例的标签设置为真来计算预期值(当数据实例为假时，设置为假)</p></figure><ul class=""><li id="da72" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">你应该使用“介入”方法来计算SHAP损失值</li></ul><p id="331f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本质上，这意味着在整合缺失的特性时，应该使用边际分布而不是条件分布。实现边缘分布的方法是用来自背景数据集中的值来分配缺少的特征。</p><p id="b824" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用“介入式”(即边缘分布)或“tree_path_dependent”(即条件分布)是一个重要的细微差别(参见SHAP包中的<a class="ae lb" href="https://github.com/slundberg/shap/blob/fc30c661339e89e0132f5f89e5385e3681090e1f/shap/explainers/tree.py#L39" rel="noopener ugc nofollow" target="_blank"> docstring </a>)，值得进一步讨论。但我不想一开始就让你困惑。你只需要知道，在通常的做法中，TreeShap计算Shap值的速度非常快，因为它利用了来自模型的树结构的条件分布，但条件分布的使用会引入因果关系的问题[2]。</p><h1 id="6b39" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">训练XGBoost分类器</h1><p id="9cae" class="pw-post-body-paragraph kf kg iq kh b ki mt jr kk kl mu ju kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">这篇文章中的例子是从SHAP包中的<a class="ae lb" href="https://github.com/slundberg/shap/blob/master/notebooks/tree_explainer/Census%20income%20classification%20with%20XGBoost.ipynb" rel="noopener ugc nofollow" target="_blank">教程例子</a>修改而来的，你可以在这里找到完整的代码和笔记本<a class="ae lb" href="https://github.com/Chancylin/shap_loss" rel="noopener ugc nofollow" target="_blank">。我首先训练了一个XGBoost分类器。数据集</a>使用12个特征来预测一个人的年收入是否超过5万英镑。</p><pre class="lm ln lo lp gt my mz na nb aw nc bi"><span id="015a" class="nd mc iq mz b gy ne nf l ng nh">['Age', 'Workclass', 'Education-Num', 'Marital Status', 'Occupation', 'Relationship', 'Race', 'Sex', 'Capital Gain', 'Capital Loss', 'Hours per week', 'Country']</span></pre><p id="bdf0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您可以使用SHAP软件包来计算shap值。力图将为您提供局部可解释性，以了解这些特性如何对感兴趣的实例的<strong class="kh ir">模型预测</strong>有所贡献(图1)。汇总图将给出全局可解释性(图2)。你可以查看Jupyter笔记本的第一部分。没有什么新的，只是SHAP的常见用法，所以我将把细节留给你，并跳转到第2部分，<strong class="kh ir"> shap值的模型损失</strong>。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ni"><img src="../Images/b4b0b747d7943324f1b522ea79bbf445.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E20JclnUiDHpdVgGAmtoAg.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">图一。力图显示了每个特征如何将模型输出从基础值推至模型输出。请注意，输出是在对数优势比空间中。</p></figure><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nj"><img src="../Images/cdfb88fc1faf46b1c16c2d9411ba4781.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PMFNZo1qlL0DHMIezllmYw.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">图二。SHAP摘要图给出了全局可解释性。量值大的要素意味着它对预测有更重要的影响。</p></figure><h1 id="9359" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">解释模型的对数损失</h1><p id="abc9" class="pw-post-body-paragraph kf kg iq kh b ki mt jr kk kl mu ju kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">现在对模型损失的贡献更感兴趣，所以我们需要计算shap损失值。在某种意义上，这类似于残差分析。代码片段如下。请注意，您需要</p><ul class=""><li id="558b" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">提供背景数据，因为我们使用“介入”方法。并且计算成本可能是昂贵的。所以你要提供一个合理大小的背景数据(这里我用100)。</li><li id="13ca" class="lc ld iq kh b ki nk kl nl ko nm ks nn kw no la lh li lj lk bi translated">现在model_output是“log_loss”。</li></ul><pre class="lm ln lo lp gt my mz na nb aw nc bi"><span id="6f46" class="nd mc iq mz b gy ne nf l ng nh"># subsample to provide the background data (stratified by the target variable)</span><span id="222f" class="nd mc iq mz b gy np nf l ng nh">X_subsample = subsample_data(X, y)</span><span id="11fe" class="nd mc iq mz b gy np nf l ng nh">explainer_bg_100 = shap.TreeExplainer(model, X_subsample, <br/>                                feature_perturbation="interventional", <br/>                                      model_output="log_loss")</span><span id="0085" class="nd mc iq mz b gy np nf l ng nh">shap_values_logloss_all = explainer_bg_100.shap_values(X, y)</span></pre><p id="d1a9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">力图</strong></p><p id="ada5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，数据实例的预测图具有与图2类似的解释，但是是根据测井曲线损失而不是预测。图3给出了成功的预测(基础事实为真，预测为真)，而图4给出了错误的预测(基础事实为真，预测为假)。您可以看到蓝色的要素如何试图减少基本值的对数损失，而红色的要素会增加对数损失。值得注意的是，模型损失的基础值(期望值)取决于标签(对/错)，因此它是一个函数而不是一个数字。期望值的计算是通过首先将所有数据标签设置为真(或假)，然后计算平均日志损失，对此您可以在笔记本上查看更多详细信息。我不知道这样计算基值是否有特别的原因，但毕竟基值只是作为一个参考值，所以我认为这应该没有太大关系。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nq"><img src="../Images/a7e118527a939c67877663271089650b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LM8jOFgk1i_BE3PCAFGH3g.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">图3。对于数据实例，地面真值为真，模式预测为真。</p></figure><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nr"><img src="../Images/3c17cc0c6a9a8e0518c39ef7aef37201.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p3rlLkl2ez2AdRgnhV5xtQ.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">图4。对于数据实例，地面真值为真，模式预测为假。</p></figure><p id="24ea" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">概要图</strong></p><p id="934d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">类似地，我们有模型对数损失的汇总图(图5)。这将告诉您特征如何影响模型对数损失(计算基于绝对平均值)。贡献较大的功能意味着它对模型损失的贡献很大，可能会增加某些数据实例的对数损失或减少其他数据实例的对数损失。因此，这里的摘要图应该显示与图2中shap值的顶部特征的一致性。但是我们可以看到排名顺序有点不同。虽然“关系”仍然是最重要的，但“年龄”、“教育程度”、“资本收益”、“每周工作时间”、“职业”的顺序不同。并且图5中的“资本收益”比图2中的“资本收益”具有相对较大的贡献。这表明“资本收益”在减少测井损失中起着重要作用，而相对而言，与“关系”相比，模型进行预测可能并不那么重要。值得注意的是，应谨慎解释图5中的摘要图，因为图5中的条形图是基于绝对平均值计算的，这意味着在对某个特征的重要性进行排序时，会考虑降低对数损失和增加对数损失的影响。简单地说，大量的(绝对)贡献不一定意味着一个特性是“好”的特性。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ns"><img src="../Images/b134518cbb90d63be874433118701c58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HFAg1aRBHj07ywoRuk9iBA.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">图5。类似于图2，但基于模型对数损失。</p></figure><p id="54cb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当然，您可以使用散点图而不是柱状图来查看详细的分布，以便更深入地进行模型调试(例如，提高模型性能)。我研究的另一种方法是将形状损失值分解为负分量(图6)和正分量(图7)。就模型调试而言，您希望获得更大的负值，并减少所有功能的正值，因为您希望所有功能都减少最终的模型logloss。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nt"><img src="../Images/3d97573d06f081567d5fd3c8f5037e05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6ZABoTMU_fujUJKDqnuUxA.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">图6。每个要素的所有负形状损失值的总和。</p></figure><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nu"><img src="../Images/bac54f6961623c1f4ad27b49bce50461.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8hqE6t9bNR43SE49Py7szQ.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">图7。每个要素的所有正形状损失值的总和。</p></figure><h2 id="57f0" class="nd mc iq bd md nv nw dn mh nx ny dp ml ko nz oa mn ks ob oc mp kw od oe mr of bi translated">监控图</h2><p id="f445" class="pw-post-body-paragraph kf kg iq kh b ki mt jr kk kl mu ju kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">现在我们到了最有趣的部分:使用shap损失值来监控您的模型。模型漂移和数据漂移是现实世界中的问题，您的模型会退化并导致不可靠/不准确的预测。但这些通常都是悄无声息地发生的，很难找出根本原因。在SHAP作者最近的一篇论文[3]中，他们使用shap损失值来监控模型的健康状况。这个想法很吸引人，我希望在这方面做更多的探索。请注意，<a class="ae lb" href="https://github.com/slundberg/shap/blob/master/shap/plots/monitoring.py" rel="noopener ugc nofollow" target="_blank"> API </a>是可用的，但似乎正在开发中。</p><p id="2ab9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，我们需要计算训练数据和测试数据的形状损失值。在监控环境中，您需要计算来自不同时间快照的数据集的shap丢失值。您可能还记得，我们在本节开始时已经这样做了。但是请注意，我们使用从整个数据集采样的背景数据。出于监控的基本原理，通过使用来自训练数据集和测试数据集的背景数据，分别计算训练数据集和测试数据集的shap损失值更有意义。代码片段如下:</p><pre class="lm ln lo lp gt my mz na nb aw nc bi"><span id="3cbb" class="nd mc iq mz b gy ne nf l ng nh"># shap loss values for training data<br/>X_train_subsample = subsample_data(X=X_train, y=y_train)</span><span id="743c" class="nd mc iq mz b gy np nf l ng nh">explainer_train_bg_100 = shap.TreeExplainer(model, X_train_subsample, <br/>                                            feature_perturbation="interventional", model_output="log_loss")</span><span id="1278" class="nd mc iq mz b gy np nf l ng nh">shap_values_logloss_train = explainer_train_bg_100.shap_values(X_train, y_train)</span><span id="dc2a" class="nd mc iq mz b gy np nf l ng nh"># shap loss values for test data<br/>X_test_subsample = subsample_data(X=X_test, y=y_test)</span><span id="51cc" class="nd mc iq mz b gy np nf l ng nh">explainer_test_bg_100 = shap.TreeExplainer(model, X_test_subsample, <br/>                                           feature_perturbation="interventional", model_output="log_loss")</span><span id="0216" class="nd mc iq mz b gy np nf l ng nh">shap_values_logloss_test = explainer_test_bg_100.shap_values(X_test, y_test)</span></pre><p id="cf29" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">顶部特征的监控图如图8所示。首先，所有数据实例将按索引排序。这里我们假设指数表示时间的演变(沿着轴从左到右)。在这个玩具示例中，我们没有来自不同时间快照的数据，因此我们简单地将训练数据视为当前数据，将测试数据视为我们想要监控的未来数据。</p><p id="5cba" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">根据SHAP帕克凯奇目前的实施情况，理解这些监测地块有几个要点。为了查看shap损失值是否具有时间一致性，将重复进行t检验来比较两个数据样本。当前的实现使用50个数据点的增量来分割数据。这意味着，第一个t检验将比较数据[0: 50]和数据[50:]；第二个将比较数据[0: 100]和数据[100:]，依此类推。如果p值小于0.05/n_features，t检验将失败。换句话说，它使用95%的置信度，并应用了Bonferroni校正。如果t检验失败，将绘制一条垂直虚线来指示位置。有点令人惊讶的是，我们看到监控图显示了[“关系”、“教育数量”、“资本收益”]的shap损失值的不一致性，当我们输入测试数据的时间快照时就会发生这种情况(图8)。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi og"><img src="../Images/3026134df7b84aaadfd8b430602b037d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*YMoH7FK_c5Nus2ApQj8RpA.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">图8。监控顶部特征的图。训练数据集和测试数据集被连接以模拟来自不同时间快照的数据。请注意，测试数据从索引26047开始。</p></figure><p id="a6eb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我不太清楚使用50个数据点增量的原因。而在这个例子中，由于我们知道[0:26048]是训练数据，[-6513:]是测试数据。我将增量修改为6500，看看它是否会给出不同的结果。但是当比较测试数据时，监测图仍然显示相同的不一致性(即，t-测试的失败)(图9)。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/f1d991251118453cda9e4032d4ed6a75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*E0BA3OD2t6bgqAnPQ-ff6w.png"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">图9。监控顶部特征的图。类似于图8，但是现在我们使用6500个数据点的增量。目的是将测试数据与训练数据的最后一个“时间段”直接进行比较。</p></figure><p id="05ef" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，我觉得直接对训练数据和测试数据进行t检验是个不错的主意。这再次验证了训练数据集和测试数据集之间的形状损失值不一致的结论。</p><pre class="lm ln lo lp gt my mz na nb aw nc bi"><span id="7f89" class="nd mc iq mz b gy ne nf l ng nh"># t-test for top features (assume equal variance)<br/>t-test for feature:  Relationship , p value:  2.9102249320497517e-06<br/>t-test for feature:  Age , p value:  0.22246187841821208<br/>t-test for feature:  Education-Num , p value:  4.169244713493427e-06<br/>t-test for feature:  Capital Gain , p value:  1.0471308847541212e-27</span><span id="681a" class="nd mc iq mz b gy np nf l ng nh"># t-test for top features (unequal variance, i.e., Welch’s t-test,)<br/>t-test for feature:  Relationship , p value:  1.427849321056383e-05<br/>t-test for feature:  Age , p value:  0.2367209506867293<br/>t-test for feature:  Education-Num , p value:  3.3161498092593535e-06<br/>t-test for feature:  Capital Gain , p value:  1.697971581168647e-24</span></pre><p id="180f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">训练数据和测试数据之间的shap损失值的不一致实际上是非常意外的，并且可能是麻烦的。请记住，我们只是从整个数据集使用训练/测试分割，因此有很好的理由相信训练数据集和测试数据集在数据分布或shap损失值贡献方面应该是一致的。无论如何，这只是一个简单的实验，需要进行更多的调查才能得出确切的结论。但我认为，SHAP软件包表明监控功能只是初步的，可能有一些原因，例如:</p><ul class=""><li id="8b33" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">在我看来，使用50个数据点的增量是任意的；</li><li id="279f" class="lc ld iq kh b ki nk kl nl ko nm ks nn kw no la lh li lj lk bi translated">t-test看起来非常敏感，可能会发出许多错误警报。</li></ul><p id="f2e2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">另一个有趣的讨论点是背景数据的使用。注意，对于监测图，使用不同的背景数据(来自训练数据集/测试数据集的子样本)计算训练数据集和测试数据集的shap损失值。由于计算shap损失值的“介入”方法非常昂贵，我只尝试了100个数据实例大小的子样本数据。这可能会产生shap损失值的高方差结果。也许大规模的背景数据将减少方差，并给出监测地块中形状损失值的一致性。当我使用相同的背景数据(来自整个数据集的子样本)时，监测图中不会出现不一致。所以你如何选择背景数据很重要！</p><h1 id="9aad" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">结论和讨论</h1><p id="fed7" class="pw-post-body-paragraph kf kg iq kh b ki mt jr kk kl mu ju kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">希望这篇帖子能给你有用的介绍shap损失值。通过调查shap损失值，可以更好地调试ML模型。它也可以是一种有用的方法来监控您的ML模型的模型漂移和数据漂移，这在社区中仍然是一个非常大的挑战。但是请注意它的局限性:为了使用shap损失值进行监控，您需要了解新数据的真实情况，这通常只能在一段时间后才能获得。此外，不幸的是，这一功能仍在开发中，使用t-test的适当性需要进一步证明。</p><p id="ceb0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后但同样重要的是，通过边际分布或条件分布计算shap值(TreeShap)可以给出不同的结果(见等式)。条件分布的使用会引入因果关系的问题，而边际分布会给模型提供不太可能的数据点[4]。对于使用哪一个，取决于什么场景，似乎没有一致的意见[2，5]。这篇论文[6]对这个话题有一些有趣的评论，我想在这里引用一下:</p><blockquote class="oi oj ok"><p id="3bd3" class="kf kg ol kh b ki kj jr kk kl km ju kn om kp kq kr on kt ku kv oo kx ky kz la ij bi translated">一般来说，用户是否应该用不属于原始训练分布的输入来呈现他们的模型是一个正在进行的辩论的主题。</p><p id="e3a3" class="kf kg ol kh b ki kj jr kk kl km ju kn om kp kq kr on kt ku kv oo kx ky kz la ij bi">….</p><p id="25c9" class="kf kg ol kh b ki kj jr kk kl km ju kn om kp kq kr on kt ku kv oo kx ky kz la ij bi translated">这个问题适合于一个更大的讨论，即你的归因方法是否应该“忠于模型”或“忠于数据”，这已经在最近的几篇文章中讨论过了。</p></blockquote><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi op"><img src="../Images/9ae4571028c160588cd91d19670aaa0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ujL32eGCxAOtwA2tlM2Ilw.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">说明如何使用边际分布和条件分布来整合缺失值(即缺失特征)。这里X1是呈现特征，而X2、X3是缺席特征。转载自[2]。</p></figure><p id="697f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">谢谢你的时间。并且不要犹豫留下任何评论和讨论！</p><p id="bd69" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本帖中的所有情节都是作者使用SHAP软件包创作的。如果你认为你的任何作品没有被恰当地引用，请告诉我。</p><p id="5ae7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[1] <a class="ae lb" href="https://jphall663.github.io/GWU_rml/" rel="noopener ugc nofollow" target="_blank">负责任机器学习简介</a></p><p id="22fb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[2] Janzing，d .，Minorics，l .，&amp; Blö baum，P. (2019年)。可解释人工智能中的特征相关性量化:一个因果关系问题。<a class="ae lb" href="https://arxiv.org/abs/1910.13413" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1910.13413</a></p><p id="57e8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[3] Lundberg，S.M .，Erion，g .，Chen，h .，DeGrave，a .，Prutkin，J.M .，Nair，b .，Katz，r .，Himmelfarb，j .，Bansal，n .和Lee，S.I. (2020)。用可解释的人工智能对树木从局部解释到全局理解。<em class="ol">自然机器智能</em>，<em class="ol"> 2 </em> (1)，2522–5839。</p><p id="8f44" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[4]<a class="ae lb" href="https://christophm.github.io/interpretable-ml-book/shap.html" rel="noopener ugc nofollow" target="_blank">https://christophm . github . io/interpretable-ml-book/shap . html</a></p><p id="27dd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[5]m . Sundararajan和a . naj mi(2019年)。用于模型解释的多个Shapley值。<a class="ae lb" href="https://arxiv.org/abs/1908.08474" rel="noopener ugc nofollow" target="_blank"> <em class="ol"> arXiv预印本arXiv:1908.08474 </em> </a>。</p><p id="03f1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[6] Sturmfels，p .，Lundberg，s .，和Lee，S. I. (2020年)。<a class="ae lb" href="https://distill.pub/2020/attribution-baselines/" rel="noopener ugc nofollow" target="_blank">可视化特性属性基线的影响</a>。<em class="ol">提取</em>，<em class="ol"> 5 </em> (1)，e22。</p></div></div>    
</body>
</html>