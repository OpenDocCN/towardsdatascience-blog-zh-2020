<html>
<head>
<title>Deploying an AI Edge App using OpenVINO</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 OpenVINO 部署 AI Edge 应用程序</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deploying-an-ai-edge-app-using-openvino-aa84e87c4577?source=collection_archive---------27-----------------------#2020-08-14">https://towardsdatascience.com/deploying-an-ai-edge-app-using-openvino-aa84e87c4577?source=collection_archive---------27-----------------------#2020-08-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="325b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我之前的文章中，我已经讨论了 OpenVINO 工具包的<a class="ae ko" href="https://medium.com/swlh/introduction-to-intel-openvino-toolkit-5f98dbb30ffb" rel="noopener">基础，OpenVINO 的</a><a class="ae ko" href="https://medium.com/analytics-vidhya/intel-openvino-model-optimizer-e381affa458c" rel="noopener">模型优化器</a>和<a class="ae ko" href="https://medium.com/analytics-vidhya/intel-openvino-inference-engine-7ba5076dc6e0" rel="noopener">推理机</a>。在这篇文章中，我们将探索:-</p><ul class=""><li id="6294" class="kp kq it js b jt ju jx jy kb kr kf ks kj kt kn ku kv kw kx bi translated">计算机视觉模型的类型。</li><li id="d183" class="kp kq it js b jt ky jx kz kb la kf lb kj lc kn ku kv kw kx bi translated">OpenVINO 的预训练模型。</li><li id="cd87" class="kp kq it js b jt ky jx kz kb la kf lb kj lc kn ku kv kw kx bi translated">下载预先训练好的模型。</li><li id="fb25" class="kp kq it js b jt ky jx kz kb la kf lb kj lc kn ku kv kw kx bi translated">使用预先训练的模型部署 Edge 应用程序。</li></ul><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ld"><img src="../Images/ad9f3f76c38ecba6596bff9f80ed8ec1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*3xvR3pvDfUao7R2lxC8TKw.jpeg"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">图片:<a class="ae ko" href="https://image.freepik.com/free-photo/planting-seed-grow-step-concept-garden-sunlight-agriculture-idea_34152-1873.jpg" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><h1 id="5918" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">计算机视觉模型的类型</h1><p id="0fd1" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">有不同类型的计算机视觉模型用于各种目的。但是三个主要的计算机视觉模型是:-</p><ul class=""><li id="c927" class="kp kq it js b jt ju jx jy kb kr kf ks kj kt kn ku kv kw kx bi translated">分类</li><li id="fa78" class="kp kq it js b jt ky jx kz kb la kf lb kj lc kn ku kv kw kx bi translated">目标检测</li><li id="f85f" class="kp kq it js b jt ky jx kz kb la kf lb kj lc kn ku kv kw kx bi translated">分割</li></ul><p id="25b0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">分类模型识别给定图像或图像中对象的“类别”。分类可以是二元的，即“是”或“否”,或者成千上万的类别，如人、苹果、汽车、猫等..有几种分类模型，如 ResNet、DenseNet、Inception 等..</p><p id="80b2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对象检测模型用于确定图像中存在的对象，并且经常在检测到的对象周围绘制边界框。它们还使用分类来识别边界框内对象的类别。您还可以设置边界框的阈值，以便拒绝低阈值检测。RCNN、Fast-RCNN、YOLO 等。是对象检测模型的一些例子。</p><p id="3cf8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">分割模型在给定图像中执行逐像素分类。有两种不同类型的分段-语义分段和实例分段。在语义分割中，属于同一类的所有对象被认为是相同的，而在实例分割中，每个对象被认为是不同的，即使它属于同一类。例如，如果在一幅图像中有五个人，语义分割模型将把他们都视为相同，而在实例分割模型中，他们都将被不同地对待。优信网、DRN 等..</p><h1 id="130c" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">OpenVINO 中的预训练模型</h1><p id="e08c" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">预训练模型，顾名思义，是已经被训练得具有高精度甚至尖端精度的模型。训练深度学习模型需要大量的时间和计算能力。虽然，创建自己的模型并通过微调超参数(隐藏层数、学习率、激活函数等)来训练它是令人兴奋的。)以达到更高的精度。但是，这需要几个小时的工作。</p><p id="14c1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过使用预先训练的模型，我们避免了大规模数据收集和长时间高成本培训的需要。了解如何预处理输入和处理网络输出后，您可以将这些内容直接插入到您自己的应用程序中。</p><p id="e1a6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">OpenVINO 在<a class="ae ko" href="https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/pretrained-models.html" rel="noopener ugc nofollow" target="_blank">模型动物园</a>里有很多预先训练好的模型。模型动物园有自由模型集和公共模型集，自由模型集包含已转换为中间表示的预训练模型。xml 和。bin)使用模型优化器。这些模型可以直接用于推理机。公共模型集包含预先训练的模型，但是这些模型不会被转换为中间表示。</p><h1 id="aadf" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">下载预先训练的模型</h1><p id="b180" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">在本文中，我将从开放模型动物园加载“车辆-属性-识别-障碍-0039”模型。</p><p id="38be" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要下载预先训练的模型，请遵循以下步骤(在命令提示符/终端中键入命令):-</p><ol class=""><li id="c9e0" class="kp kq it js b jt ju jx jy kb kr kf ks kj kt kn mw kv kw kx bi translated">导航到模型下载器目录</li></ol><p id="ad79" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于 Linux:-</p><pre class="le lf lg lh gt mx my mz na aw nb bi"><span id="fbcc" class="nc lu it my b gy nd ne l nf ng">cd /opt/intel/openvino/deployment_tools/open_model_zoo/tools/model_downloader</span></pre><p id="0c1f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于 Windows:-</p><pre class="le lf lg lh gt mx my mz na aw nb bi"><span id="2a7d" class="nc lu it my b gy nd ne l nf ng">cd C:/Program Files (x86)/IntelSWTools/openvino<!-- -->deployment_tools/open_model_zoo/tools/model_downloader</span></pre><p id="0c69" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我在上面的命令中使用了默认的安装目录，如果您的安装目录不同，那么请导航到适当的目录。</p><p id="0ae3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">2.运行下载程序. py</p><p id="7eea" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下载器 Python 文件需要一些参数，您可以使用“-h”参数来查看可用的参数。</p><pre class="le lf lg lh gt mx my mz na aw nb bi"><span id="85cd" class="nc lu it my b gy nd ne l nf ng">python downloader.py -h</span></pre><p id="84da" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们下载模型，</p><pre class="le lf lg lh gt mx my mz na aw nb bi"><span id="1e77" class="nc lu it my b gy nd ne l nf ng">python downloader.py --name vehicle-attributes-recognition-barrier-0039 --precisions -FP32 --output_dir /home/pretrained_models</span></pre><ul class=""><li id="386c" class="kp kq it js b jt ju jx jy kb kr kf ks kj kt kn ku kv kw kx bi translated"><strong class="js iu"> —名称</strong> →型号名称。</li><li id="611f" class="kp kq it js b jt ky jx kz kb la kf lb kj lc kn ku kv kw kx bi translated"><strong class="js iu"> —精度</strong> →型号精度(FP16、FP32 或 INT8)。</li><li id="201a" class="kp kq it js b jt ky jx kz kb la kf lb kj lc kn ku kv kw kx bi translated"><strong class="js iu"> — output_dir </strong> →保存模型的路径。</li></ul><p id="d973" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">成功下载模型后，导航到下载模型的路径，您将找到。xml“和”。bin "文件的模型。</p><p id="2203" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请参考<a class="ae ko" href="https://docs.openvinotoolkit.org/latest/omz_models_intel_vehicle_attributes_recognition_barrier_0039_description_vehicle_attributes_recognition_barrier_0039.html#inputs" rel="noopener ugc nofollow" target="_blank">文档</a>以了解关于该模型的更多细节(输入和输出)。</p><h1 id="ebea" class="lt lu it bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">部署边缘应用</h1><p id="4d2a" class="pw-post-body-paragraph jq jr it js b jt mr jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">现在，由于我们已经下载了预训练模型，让我们在 Edge 应用程序中部署它。</p><p id="b9b2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们创建一个文件“inference.py”来定义和使用推理引擎。在我的<a class="ae ko" href="https://medium.com/analytics-vidhya/intel-openvino-inference-engine-7ba5076dc6e0" rel="noopener">上一篇文章</a>中，关于推理引擎，我已经使用了不同的函数，但是这里我将定义一个类。</p><pre class="le lf lg lh gt mx my mz na aw nb bi"><span id="f9af" class="nc lu it my b gy nd ne l nf ng">from openvino.inference_engine import IENetwork, IECore</span><span id="8c77" class="nc lu it my b gy nh ne l nf ng"><strong class="my iu">class </strong>Network:<br/>    <strong class="my iu">def </strong>__init__(self):<br/>        self.plugin = None<br/>        self.network = None<br/>        self.input_blob = None<br/>        self.exec_network = None<br/>        self.infer_request = None</span><span id="57da" class="nc lu it my b gy nh ne l nf ng"><strong class="my iu">    def </strong>load_model(self):<br/>        self.plugin = IECore()<br/>        self.network = IENetwork(model='path_to_xml', weights='path_to_bin')<br/>        <br/>        ### Defining CPU Extension path<br/>        CPU_EXT_PATH=      "/opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/ libcpu_extension_sse4.so"   </span><span id="feba" class="nc lu it my b gy nh ne l nf ng">        ### Adding CPU Extension<br/>        plugin.add_extension(CPU_EXT_PATH,"CPU")</span><span id="c207" class="nc lu it my b gy nh ne l nf ng">        ### Get the supported layers of the network<br/>        supported_layers = plugin.query_network(network=network, device_name="CPU")    </span><span id="9374" class="nc lu it my b gy nh ne l nf ng">        ### Finding unsupported layers<br/>        unsupported_layers = [l <strong class="my iu">for</strong> l <strong class="my iu">in</strong> network.layers.keys() <strong class="my iu">if</strong> l <strong class="my iu">not</strong> <strong class="my iu">in</strong> supported_layers]    </span><span id="090f" class="nc lu it my b gy nh ne l nf ng">        ### Checking for unsupported layers<br/>        <strong class="my iu">if</strong> len(unsupported_layers) != 0:<br/>            print("Unsupported layers found")<br/>            print(unsupported_layers)<br/>            exit(1)</span><span id="afc3" class="nc lu it my b gy nh ne l nf ng">        ### Loading the network<br/>        self.exec_network =             self.plugin.load_network(self.network,"CPU")</span><span id="1093" class="nc lu it my b gy nh ne l nf ng">        self.input_blob  = next(iter(self.network.inputs))<br/>        print("MODEL LOADED SUCCESSFULLY!!!)</span><span id="3d42" class="nc lu it my b gy nh ne l nf ng"><strong class="my iu">    def </strong>get_input_shape(self):<br/>        return self.network.inputs[self.input_blob].shape</span><span id="421e" class="nc lu it my b gy nh ne l nf ng"><strong class="my iu">    def </strong>synchronous_inference(self,image):  <br/>        self.exec_network.infer({self.input_blob: image})</span><span id="b156" class="nc lu it my b gy nh ne l nf ng"><strong class="my iu">    def </strong>extract_output(self):<br/>        return self.exec_network.requests[0].outputs</span></pre><p id="0f92" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">别糊涂了！我会解释每一个功能。</p><ul class=""><li id="660d" class="kp kq it js b jt ju jx jy kb kr kf ks kj kt kn ku kv kw kx bi translated"><strong class="js iu"> __init__(self): </strong></li></ul><p id="eb75" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">它是类网络的构造器，在那里我初始化了类的数据成员。</p><ul class=""><li id="2ffe" class="kp kq it js b jt ju jx jy kb kr kf ks kj kt kn ku kv kw kx bi translated"><strong class="js iu"> load_model(self): </strong></li></ul><p id="b438" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">顾名思义，它用于加载模型(预训练)，在这个函数中我们:-</p><p id="85c7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">▹声明了一个 iecore 对象。</p><p id="eb41" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">▹声明了一个 ienetwork 对象。</p><p id="fb8d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">▹加载了模型 xml 和 bin 文件。</p><p id="4106" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">▹检查了不受支持的层</p><p id="8280" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">▹在 iecore 对象中加载 ienetwork 对象。</p><ul class=""><li id="0668" class="kp kq it js b jt ju jx jy kb kr kf ks kj kt kn ku kv kw kx bi translated"><strong class="js iu">获取 _ 输入 _ 形状(自身):</strong></li></ul><p id="e1e5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">返回模型所需的输入形状</p><ul class=""><li id="0f1d" class="kp kq it js b jt ju jx jy kb kr kf ks kj kt kn ku kv kw kx bi translated"><strong class="js iu">同步 _ 推论(自我，形象):</strong></li></ul><p id="b76a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对输入图像执行同步推理</p><ul class=""><li id="71b0" class="kp kq it js b jt ju jx jy kb kr kf ks kj kt kn ku kv kw kx bi translated"><strong class="js iu">提取 _ 输出(自我):</strong></li></ul><p id="1933" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">推理完成后返回模型的输出。</p><p id="a54d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这就是“推论. py”，现在让我们创建一个文件“main.py”。</p><pre class="le lf lg lh gt mx my mz na aw nb bi"><span id="6c0a" class="nc lu it my b gy nd ne l nf ng">import cv2<br/>import numpy as np<br/>from inference import Network<br/></span><span id="cae4" class="nc lu it my b gy nh ne l nf ng">def preprocessing(image,height,width):</span><span id="5673" class="nc lu it my b gy nh ne l nf ng">    ### Resize the Image<br/>    image = cv2.resize(image,(width,height))</span><span id="f1a5" class="nc lu it my b gy nh ne l nf ng">    ### Add color channel first<br/>    image = image.transpose((2,0,1))</span><span id="d0d7" class="nc lu it my b gy nh ne l nf ng">    ### Add Batch Size<br/>    image  = np.reshape((image,(1,3,height,width))<br/>    return image</span></pre><ol class=""><li id="0860" class="kp kq it js b jt ju jx jy kb kr kf ks kj kt kn mw kv kw kx bi translated">使用 OpenCV 的 resize()调整图像大小时，应该先给出宽度，再给出高度。</li><li id="ed48" class="kp kq it js b jt ky jx kz kb la kf lb kj lc kn mw kv kw kx bi translated">根据<a class="ae ko" href="https://docs.openvinotoolkit.org/latest/omz_models_intel_vehicle_attributes_recognition_barrier_0039_description_vehicle_attributes_recognition_barrier_0039.html#inputs" rel="noopener ugc nofollow" target="_blank">文档</a>，模型首先读取通道，然后读取图像尺寸，但是 OpenCV 首先读取图像尺寸，然后读取通道，所以我使用了 transpose()，首先带来颜色通道。</li><li id="b29a" class="kp kq it js b jt ky jx kz kb la kf lb kj lc kn mw kv kw kx bi translated">该模型将输入作为(batch_size，color_channels，height，width ),因此我们对图像进行整形，以给出为 1 的“batch_size”。</li></ol><pre class="le lf lg lh gt mx my mz na aw nb bi"><span id="fb9e" class="nc lu it my b gy nd ne l nf ng">def main():<br/>    ### Read the image<br/>    image = cv2.imread('path_to_image')</span><span id="a9eb" class="nc lu it my b gy nh ne l nf ng">    ### Declare a Network Object<br/>    plugin = Network()</span><span id="933a" class="nc lu it my b gy nh ne l nf ng">    ### Input shape required by model<br/>    input_shape = plugin.get_input_shape()</span><span id="94b7" class="nc lu it my b gy nh ne l nf ng">    height = input_shape[2]<br/>    width = input_shape[3]</span><span id="2328" class="nc lu it my b gy nh ne l nf ng">    ### Preprocess the input    <br/>    p_image = preprocessing(image,height,width)</span><span id="6070" class="nc lu it my b gy nh ne l nf ng">    ### Perform Synchronous Inference<br/>    plugin.synchronous_inference(p_image)</span><span id="0edc" class="nc lu it my b gy nh ne l nf ng">    ### Extract the output<br/>    results = plugin.extract_output()</span></pre><p id="f36c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">根据文档，模型的输出(结果)是一个字典，其中包含以下信息</p><ol class=""><li id="0feb" class="kp kq it js b jt ju jx jy kb kr kf ks kj kt kn mw kv kw kx bi translated">“颜色”，形状:[1，7，1，1] —七种颜色类别的 Softmax 输出[白色、灰色、黄色、红色、绿色、蓝色、黑色]</li><li id="6fa3" class="kp kq it js b jt ky jx kz kb la kf lb kj lc kn mw kv kw kx bi translated">“类型”，形状:[1，4，1，1] —跨四个类型类别[轿车、公共汽车、卡车、货车]的 Softmax 输出</li></ol><p id="9cb4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">由于它是 softmax 输出，我们需要将最大值的索引与颜色和类型进行映射。</p><pre class="le lf lg lh gt mx my mz na aw nb bi"><span id="86e2" class="nc lu it my b gy nd ne l nf ng">    color = ['white','grey','yellow','red','green','blue','black']<br/>    vehicle = ['car','bus','truck','van']</span><span id="e55c" class="nc lu it my b gy nh ne l nf ng">    ### Finding out the color and type<br/>    result_color = str(color[np.argmax(results['color'])])<br/>    result_type = str(vehicle[np.argmax(results['type'])])</span><span id="70c2" class="nc lu it my b gy nh ne l nf ng">### Add details to image<br/>    font = cv2.FONT_HERSHEY_SIMPLEX<br/>    font_scale = 1<br/>    col = (0, 255,0) #BGR<br/>    thickness = 2    <br/>    color_text= 'color: '+result_color<br/>    type_text = 'vehicle: '+result_type<br/>    cv2.putText(image,color_text,(50,50), font, font_scale, col, thickness, cv2.LINE_AA)<br/>    cv2.putText(image,type_text,(50,75), font, font_scale, col, thickness, cv2.LINE_AA)</span><span id="e273" class="nc lu it my b gy nh ne l nf ng">    ### Save the image<br/>    cv2.imwrite('path/vehicle.png',image)</span><span id="6553" class="nc lu it my b gy nh ne l nf ng">if __name__=="__main__":<br/>    main()</span></pre><p id="7ebd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我尝试了两辆车，得到了以下输出:-</p><div class="le lf lg lh gt ab cb"><figure class="ni li nj nk nl nm nn paragraph-image"><img src="../Images/3e367c4811a2ee37df7079ea095bdca7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*vecGCj5sakOeFk-E90g4eQ.png"/></figure><figure class="ni li nj nk nl nm nn paragraph-image"><img src="../Images/4dfbe1b59ab479c17a3ae3def590188e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Q17VQChRNagygDvyQsbIUQ.png"/><p class="lp lq gj gh gi lr ls bd b be z dk no di np nq translated">来源:作者</p></figure></div><p id="ca99" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">好了，大家都到齐了。我希望现在你已经对如何使用 OpenVINO 部署 AI edge 应用程序有了正确的理解。OpenVINO 为多种应用提供了各种预训练模型。尝试实现 OpenVINO <a class="ae ko" href="https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/pretrained-models.html" rel="noopener ugc nofollow" target="_blank"> model zoo </a>中可用的不同预训练模型，并创建自己的 edge 应用程序。非常感谢您阅读我的文章。</p></div></div>    
</body>
</html>