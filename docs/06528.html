<html>
<head>
<title>Complete Architectural Details of all EfficientNet Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">所有高效网络模型的完整架构细节</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/complete-architectural-details-of-all-efficientnet-models-5fd5b736142?source=collection_archive---------0-----------------------#2020-05-24">https://towardsdatascience.com/complete-architectural-details-of-all-efficientnet-models-5fd5b736142?source=collection_archive---------0-----------------------#2020-05-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="47a8" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">让我们深入探究所有不同高效网络模型的架构细节，并找出它们之间的不同之处。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/8a8c345ed8b87a3020d62c9a489fcf1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*34PlrpddgachPgag"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">乔尔·菲利普在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="6925" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我在一次 Kaggle 竞赛中翻阅笔记本，发现几乎每个人都在使用 EfficientNet 作为他们的主干网，这是我之前从未听说过的。它是由谷歌人工智能在这篇<a class="ae ky" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank">论文</a>中介绍的，他们试图提出一种如其名称所示更有效的方法，同时改善艺术效果的状态。一般来说，模型做得太宽、太深，或者分辨率太高。增加这些特征最初有助于模型，但是它很快饱和，并且所制作的模型只是具有更多的参数，因此效率不高。在 EfficientNet 中，它们以更有原则的方式进行扩展，即逐渐增加所有内容。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/4c30134440e059fd889b3983d0984fab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FJos7uXvl-uLDpSQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://arxiv.org/pdf/1905.11946v3.pdf" rel="noopener ugc nofollow" target="_blank">模型缩放。(a)是一个基线网络示例；(b)-(d)是仅增加网络宽度、深度或分辨率的一个维度的传统缩放。(e)是我们提出的复合缩放方法，它以固定的比例统一缩放所有三个维度。</a></p></figure><p id="bd93" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不明白发生了什么？别担心，一旦你看到这个建筑，你就会明白的。但首先，让我们看看他们用这个得到的结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/c1b78a1c8bf8694dde6517c6feaed142.png" data-original-src="https://miro.medium.com/v2/resize:fit:1324/format:webp/0*09AED_CjE-PUFxKC.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://arxiv.org/pdf/1905.11946v3.pdf" rel="noopener ugc nofollow" target="_blank">模型尺寸与 ImageNet 精度</a></p></figure><p id="568f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于参数数量少得多，模型系列是有效的，并且还提供了更好的结果。现在我们已经看到了为什么这些可能成为标准的预训练模型，但是缺少了一些东西。我记得<a class="lx ly ep" href="https://medium.com/u/c2958659896a?source=post_page-----5fd5b736142--------------------------------" rel="noopener" target="_blank">莱米·卡里姆</a>的一篇文章，他展示了预训练模型的架构，这对我理解它们和创建类似的架构帮助很大。</p><div class="lz ma gp gr mb mc"><a rel="noopener follow" target="_blank" href="/illustrated-10-cnn-architectures-95d78ace614d"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd iu gy z fp mh fr fs mi fu fw is bi translated">插图:10 个 CNN 架构</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">普通卷积神经网络的编译可视化</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ml l"><div class="mm l mn mo mp ml mq ks mc"/></div></div></a></div><p id="8b7b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于我在网上找不到这样的一个，我决定理解它并为你们所有人创建一个。</p><h1 id="2f1d" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated">共有的事物</h1><p id="6f90" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">首先，任何网络都是它的主干，然后开始所有的架构实验，这在所有八个模型和最终层中都很常见。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/68145ce61955cc4b578c04b5c99424d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*93Ahac6GAA04fnpVPcKZBg.png"/></div></div></figure><p id="44a5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此后，它们中的每一个都包含 7 个块。这些模块还包含不同数量的子模块，随着我们从效率 0 提高到效率 7，子模块的数量也会增加。要查看 Colab 中模型的层，请编写以下代码:</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="8e2b" class="nu ms it nq b gy nv nw l nx ny">!pip install tf-nightly-gpu</span><span id="c618" class="nu ms it nq b gy nz nw l nx ny">import tensorflow as tf</span><span id="c52b" class="nu ms it nq b gy nz nw l nx ny">IMG_SHAPE = (224, 224, 3)<br/>model0 = tf.keras.applications.EfficientNetB0(input_shape=IMG_SHAPE, include_top=False, weights="imagenet")</span><span id="1492" class="nu ms it nq b gy nz nw l nx ny">tf.keras.utils.plot_model(model0) # to draw and visualize<br/>model0.summary() # to see the list of layers and parameters</span></pre><p id="4d33" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你计算一下 EfficientNet-B0 中的总层数，总数是 237，而在 EfficientNet-B7 中，总数是 813！！但是不要担心，所有这些层都可以由下面显示的 5 个模块和上面的茎制成。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/166b30c1e995d6eca4718f88178071eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cwMpOJNhwOeosjwW-usYvA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我们将使用 5 个模块来构建架构。</p></figure><ul class=""><li id="3609" class="ob oc it lb b lc ld lf lg li od lm oe lq of lu og oh oi oj bi translated"><strong class="lb iu">模块 1 </strong> —用作子模块的起点。</li><li id="4f19" class="ob oc it lb b lc ok lf ol li om lm on lq oo lu og oh oi oj bi translated"><strong class="lb iu">模块 2 </strong> —该模块用作除第一个模块之外的所有 7 个主模块的第一个子模块的起点。</li><li id="be7f" class="ob oc it lb b lc ok lf ol li om lm on lq oo lu og oh oi oj bi translated"><strong class="lb iu">模块 3 </strong> —该模块作为跳接连接至所有子模块。</li><li id="1e81" class="ob oc it lb b lc ok lf ol li om lm on lq oo lu og oh oi oj bi translated"><strong class="lb iu">模块 4 </strong> —用于组合第一个子块中的跳跃连接。</li><li id="dc5d" class="ob oc it lb b lc ok lf ol li om lm on lq oo lu og oh oi oj bi translated"><strong class="lb iu">模块 5 </strong> —每个子模块以跳接方式连接到其前一个子模块，并使用该模块进行组合。</li></ul><p id="28ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些模块被进一步组合以形成子块，这些子块将以某种方式在块中使用。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/511f63d7422f1ea707d78d11b8b4819f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*snN5M6WXlqHVFAwi17H9Mw.png"/></div></div></figure><ul class=""><li id="a603" class="ob oc it lb b lc ld lf lg li od lm oe lq of lu og oh oi oj bi translated"><strong class="lb iu">子块 1 </strong> —仅用作第一个块中的第一个子块。</li><li id="d8d6" class="ob oc it lb b lc ok lf ol li om lm on lq oo lu og oh oi oj bi translated"><strong class="lb iu">子块 2 </strong> —它被用作所有其它块中的第一个子块。</li><li id="d6f3" class="ob oc it lb b lc ok lf ol li om lm on lq oo lu og oh oi oj bi translated"><strong class="lb iu">子块 3 </strong> —用于所有块中除第一个以外的任何子块。</li></ul></div><div class="ab cl oq or hx os" role="separator"><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov"/></div><div class="im in io ip iq"><p id="ac0c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">到目前为止，我们已经指定了将被组合以创建高效网络模型的所有内容，所以让我们开始吧。</p><h2 id="a1b3" class="nu ms it bd mt ox oy dn mx oz pa dp nb li pb pc nd lm pd pe nf lq pf pg nh ph bi translated">EfficientNet-B0</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pi"><img src="../Images/6c9d48b68eeb18ec4b3beb18e9df22c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rnhgFRXetwD8PvxhZIpwIA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">高效网络架构-B0。(x2 表示括号内的模块重复两次)</p></figure><h2 id="c08a" class="nu ms it bd mt ox oy dn mx oz pa dp nb li pb pc nd lm pd pe nf lq pf pg nh ph bi translated">效率网络-B1</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/3517a145d07ea050126b10d0cbefcf77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vm_lmc2p9S8GJmtP2tSfDw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">高效网络架构-B1</p></figure><h2 id="ca7b" class="nu ms it bd mt ox oy dn mx oz pa dp nb li pb pc nd lm pd pe nf lq pf pg nh ph bi translated">B2 效率网</h2><p id="4aee" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">其架构与上述模型相同，它们之间的唯一区别是特征图(通道)的数量不同，这增加了参数的数量。</p><h2 id="8e16" class="nu ms it bd mt ox oy dn mx oz pa dp nb li pb pc nd lm pd pe nf lq pf pg nh ph bi translated">B3 效率网</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pk"><img src="../Images/322a8ce4f20c8f4d27ff4cb8e8b2a423.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8oE4jOMfOXeEzgsHjSB5ww.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">高效网络架构-B3</p></figure><h2 id="0284" class="nu ms it bd mt ox oy dn mx oz pa dp nb li pb pc nd lm pd pe nf lq pf pg nh ph bi translated">高效网络-B4</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pl"><img src="../Images/83fe56ad5f83620da20303ce94a13c8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4-w-cb0WpFb4pBdf6ZCA7w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">高效网络架构-B4</p></figure><h2 id="3d33" class="nu ms it bd mt ox oy dn mx oz pa dp nb li pb pc nd lm pd pe nf lq pf pg nh ph bi translated">高效网络-B5</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pm"><img src="../Images/09fb03de26e8cc578de0d5f190d3b9c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6vH0nsxj0_-kHxF09tPFlg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">高效网络 B5 的架构</p></figure><h2 id="2220" class="nu ms it bd mt ox oy dn mx oz pa dp nb li pb pc nd lm pd pe nf lq pf pg nh ph bi translated">B6 效率网</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/3c739140ef8dcd88aea475a47a7c4e0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2OXrqNg_7CMuNFg2T6eRUA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">B6 高效网络的架构</p></figure><h2 id="00aa" class="nu ms it bd mt ox oy dn mx oz pa dp nb li pb pc nd lm pd pe nf lq pf pg nh ph bi translated">B7 效率网</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pn"><img src="../Images/9a1985a86be5db4b776cd6136bcccb82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9LkWH_LUPi5QD1k-QcUA2g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">B7 高效网络的架构</p></figure></div><div class="ab cl oq or hx os" role="separator"><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov"/></div><div class="im in io ip iq"><p id="ebce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">很容易看出所有模型之间的差异，他们逐渐增加了子块的数量。如果你理解这些架构，我会鼓励你选择任何一个模型，打印出它的概要，并浏览一遍以更彻底地了解它。下表显示了卷积运算的内核大小以及 EfficientNet-B0 中的分辨率、通道和层。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi po"><img src="../Images/28e1c4b800529866b977d2fdfa7f8df4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WP4AKPg1QsrMCKKO.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://arxiv.org/pdf/1905.11946v3.pdf" rel="noopener ugc nofollow" target="_blank">内核大小、分辨率、通道和层数信息。</a></p></figure><p id="ddf4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此表包含在原始文件中。这个决议对整个家庭来说是一样的。我不知道内核大小是变化还是保持不变，所以如果有人知道，请回复。层数已经在上面的图中示出。频道数量各不相同，它是根据从每个型号的摘要中看到的信息计算出来的，如下所示(<em class="pp">)如果您使用的是移动设备，则需要在横向模式下查看</em>。)</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="8c38" class="nu ms it nq b gy nv nw l nx ny">╔═══════╦══════╦══════╦══════╦══════╦══════╦══════╦══════╗<br/>║ Stage ║  B1  ║  B2  ║  B3  ║  B4  ║  B5  ║  B6  ║  B7  ║<br/>╠═══════╬══════╬══════╬══════╬══════╬══════╬══════╬══════╣<br/>║     1 ║   32 ║   32 ║   40 ║   48 ║   48 ║   56 ║   64 ║<br/>║     2 ║   16 ║   16 ║   24 ║   24 ║   24 ║   32 ║   32 ║<br/>║     3 ║   24 ║   24 ║   32 ║   32 ║   40 ║   40 ║   48 ║<br/>║     4 ║   40 ║   48 ║   48 ║   56 ║   64 ║   72 ║   80 ║<br/>║     5 ║   80 ║   88 ║   96 ║  112 ║  128 ║  144 ║  160 ║<br/>║     6 ║  112 ║  120 ║  136 ║  160 ║  176 ║  200 ║  224 ║<br/>║     7 ║  192 ║  208 ║  232 ║  272 ║  304 ║  344 ║  384 ║<br/>║     8 ║  320 ║  352 ║  384 ║  448 ║  512 ║  576 ║  640 ║<br/>║     9 ║ 1280 ║ 1408 ║ 1536 ║ 1792 ║ 2048 ║ 2304 ║ 2560 ║<br/>╚═══════╩══════╩══════╩══════╩══════╩══════╩══════╩══════╝</span></pre><p id="38ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Medium 没有任何制作表格的格式，所以如果你想创建如上的表格，你可以从这个<a class="ae ky" href="https://ozh.github.io/ascii-tables/" rel="noopener ugc nofollow" target="_blank">站点</a>创建 ASCII 表格。</p></div><div class="ab cl oq or hx os" role="separator"><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov"/></div><div class="im in io ip iq"><p id="181d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在结束之前，我再次附上了其研究论文中的另一张图片，该图片显示了其相对于其他先进技术的性能，并且还减少了所需的参数数量和触发器数量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pq"><img src="../Images/a5866ecb5856034e389e1c78c1ed15ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PTmdERX7H11aYT2P2gjJSQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://arxiv.org/pdf/1905.11946v3.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="f7c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您想创建像这样的高级 CNN 架构，或者在理解所使用的任何层或术语方面有问题，请不要担心，我已经写了一篇文章来解决这些问题。</p><div class="lz ma gp gr mb mc"><a rel="noopener follow" target="_blank" href="/beyond-the-standard-cnn-in-tensorflow-2-a7562d25ca2d"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd iu gy z fp mh fr fs mi fu fw is bi translated">超越 Tensorflow 2 中的标准 CNN</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">使用复杂的架构生成更深层次的模型，并了解不同的层，从而使模型更好。</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ml l"><div class="pr l mn mo mp ml mq ks mc"/></div></div></a></div><p id="6791" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你想看看 EfficientNet 如何在 Kaggle 挑战赛上与模特们一较高下吗，你可以看看这篇文章。</p><div class="lz ma gp gr mb mc"><a rel="noopener follow" target="_blank" href="/efficientnet-should-be-the-goto-pre-trained-model-or-38f719cbfe60"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd iu gy z fp mh fr fs mi fu fw is bi translated">EfficientNet 应该是 goto 预训练模型或…</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">比较不同预训练模型的时间和准确性，并最终创建一个集成来提高结果。</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ml l"><div class="ps l mn mo mp ml mq ks mc"/></div></div></a></div></div></div>    
</body>
</html>