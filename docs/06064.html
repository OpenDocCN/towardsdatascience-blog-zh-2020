<html>
<head>
<title>Linear Classification in Pytorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pytorch中的线性分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/linear-classification-in-pytorch-9d8a8f8ff264?source=collection_archive---------34-----------------------#2020-05-17">https://towardsdatascience.com/linear-classification-in-pytorch-9d8a8f8ff264?source=collection_archive---------34-----------------------#2020-05-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c328" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">利用二元分类法检测乳腺癌</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/42fb6916486810e24a60ab0ca0dfd42e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*i47HbuYFI1JBMXPe"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@nci?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">国家癌症研究所</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="9901" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇中型文章将探索<strong class="lb iu"> Pytorch </strong>库以及如何实现线性分类算法。我们将在经典且易于理解的数据集上应用该算法。在本文中，您将更加熟悉Pytorch的基础知识。之后，你应该准备好深入更高级的问题(例如时间序列)。</p><p id="fb4e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">文章的结构如下:</p><ul class=""><li id="f138" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">加载数据集</li><li id="dc8f" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">拆分数据</li><li id="3214" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">预处理数据</li><li id="6ff0" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">创建模型</li><li id="ca29" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">全梯度下降</li><li id="67d9" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">模型评估</li></ul></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h2 id="5ceb" class="mq mr it bd ms mt mu dn mv mw mx dp my li mz na nb lm nc nd ne lq nf ng nh ni bi translated">加载数据集</h2><p id="989d" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">将使用的数据集是乳腺癌威斯康辛数据集，它非常适合演示二元分类。</p><p id="a130" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">问题很简单。科学家们收集了患有(恶性)或没有(良性)乳腺癌的患者的特征。我们的工作是辨别是非。这可以帮助医生在日常工作中处理数据。乳腺癌作为一个例子的原因是因为它的相关性。2018年，据估计全球有627，000名女性死于乳腺癌[ <a class="ae ky" href="https://www.who.int/cancer/prevention/diagnosis-screening/breast-cancer/en/" rel="noopener ugc nofollow" target="_blank">世卫组织</a>，2020]。</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="e62c" class="mq mr it np b gy nt nu l nv nw">from sklearn.datasets import load_breast_cancer</span><span id="4b2d" class="mq mr it np b gy nx nu l nv nw">data = load_breast_cancer()<br/>X, Y = data.data, data.target</span></pre><p id="844b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在该数据集中，有30个特征(例如，平均半径、平均纹理)。</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="83dd" class="mq mr it np b gy nt nu l nv nw">print(data.feature_names)</span><span id="d9b4" class="mq mr it np b gy nx nu l nv nw">['mean radius' 'mean texture' 'mean perimeter' 'mean area'  'mean smoothness' 'mean compactness' 'mean concavity'  'mean concave points' 'mean symmetry' 'mean fractal dimension'  'radius error' 'texture error' 'perimeter error' 'area error'  'smoothness error' 'compactness error' 'concavity error'  'concave points error' 'symmetry error' 'fractal dimension error'  'worst radius' 'worst texture' 'worst perimeter' 'worst area'  'worst smoothness' 'worst compactness' 'worst concavity'  'worst concave points' 'worst symmetry' 'worst fractal dimension']</span></pre><p id="7455" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">目标映射很简单。这些特征表明你患有恶性或良性肿瘤。大多数肿瘤是良性的，这意味着它们不是癌性的，不会杀死你。</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="eb6c" class="mq mr it np b gy nt nu l nv nw">print(data.target_names)</span><span id="f09c" class="mq mr it np b gy nx nu l nv nw">['malignant' 'benign']</span></pre></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h2 id="8d19" class="mq mr it bd ms mt mu dn mv mw mx dp my li mz na nb lm nc nd ne lq nf ng nh ni bi translated">拆分数据</h2><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="b125" class="mq mr it np b gy nt nu l nv nw">from sklearn.model_selection import train_test_split</span><span id="482b" class="mq mr it np b gy nx nu l nv nw">X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)</span></pre><p id="c6c0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，使用训练数据创建模型，然后使用测试数据进行测试。如果你熟悉这个领域，这应该是一个惊喜。因此，上面的代码使用<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html" rel="noopener ugc nofollow" target="_blank"> sklearn </a>将数据分成随机的训练和测试子集。一行代码，但是非常重要。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h2 id="bd42" class="mq mr it bd ms mt mu dn mv mw mx dp my li mz na nb lm nc nd ne lq nf ng nh ni bi translated">预处理数据</h2><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="349e" class="mq mr it np b gy nt nu l nv nw">from sklearn.preprocessing import StandardScaler</span><span id="91f9" class="mq mr it np b gy nx nu l nv nw">scaler = StandardScaler()<br/>X_train = scaler.fit_transform(X_train)<br/>X_test = scaler.transform(X_test)</span></pre><p id="925b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了获得更好的结果，一点缩放是很重要的。我们不希望一个特性支配另一个特性。我们能做的是确保数据被很好地分配。这里没有什么新东西，如果你不熟悉标准化功能，机器学习课程可能会有所帮助(例如<a class="ae ky" href="https://www.deeplearning.ai/" rel="noopener ugc nofollow" target="_blank"> deeplearning.ai </a>)。</p><p id="6eeb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以自己做，但为什么要重新发明轮子呢？对于这个任务，可以使用sklearn的<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html" rel="noopener ugc nofollow" target="_blank"> StandardScaler </a>。这是一个微妙的细节，但以与训练集相同的方式扩展测试集是很重要的。因为训练集比测试集大得多，而且两者都是随机选择的，所以它应该是对实际分布的更好估计。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h2 id="0398" class="mq mr it bd ms mt mu dn mv mw mx dp my li mz na nb lm nc nd ne lq nf ng nh ni bi translated">创建模型</h2><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="57fb" class="mq mr it np b gy nt nu l nv nw">class BinaryClassification(torch.nn.Module):</span><span id="09d7" class="mq mr it np b gy nx nu l nv nw">def __init__(self, input_dimension):<br/>        super().__init__()<br/>        self.linear = torch.nn.Linear(input_dimension, 1)</span><span id="1e23" class="mq mr it np b gy nx nu l nv nw">def forward(self, input_dimension):<br/>        return self.linear(input_dimension)</span><span id="2f22" class="mq mr it np b gy nx nu l nv nw">_, input_dimension = X_train.shape<br/>model = BinaryClassification(input_dimension)</span></pre><p id="b89e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感兴趣的模型是一个非常简单的线性模型。在示例中，它展示了如何创建自己的Pytorch“模块”,但是您也可以使用一行程序来完成。同样的事情也可以这样做。因此，如果您更喜欢这样，请随意使用一行程序。但是，本文意在告知。在Pytorch中创建一个定制的神经网络就是这么容易。</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="85f7" class="mq mr it np b gy nt nu l nv nw">model = torch.nn.Linear(input_dimension, 1)</span></pre><p id="54dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">还有一点你可能已经注意到了，我们没有使用sigmoid激活函数，但这是可以解释的。不使用与sigmoid函数结合的二进制交叉熵损失函数，这里更倾向于使用具有logits损失的函数的<a class="ae ky" href="https://pytorch.org/cppdocs/api/structtorch_1_1nn_1_1_b_c_e_with_logits_loss_impl.html#structtorch_1_1nn_1_1_b_c_e_with_logits_loss_impl" rel="noopener ugc nofollow" target="_blank">二进制交叉熵。后者在数值上更稳定，从而导致更好的结果。</a></p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="a2e7" class="mq mr it np b gy nt nu l nv nw">def configure_loss_function():<br/>    return torch.nn.BCEWithLogitsLoss()</span><span id="47d3" class="mq mr it np b gy nx nu l nv nw">def configure_optimizer(model):<br/>    return torch.optim.Adam(model.parameters())</span></pre><p id="afbb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，使用了Adam优化器。可能有更好的优化算法，但它的表现相当好。还不需要用别人做实验。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h2 id="b6b5" class="mq mr it bd ms mt mu dn mv mw mx dp my li mz na nb lm nc nd ne lq nf ng nh ni bi translated">模型评估</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">二元分类示例</p></figure><p id="97a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">剩下的代码只是一个完整的梯度下降循环以及训练和测试精度的计算。在每个时期都会发生以下步骤:</p><ul class=""><li id="267d" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">向前通过二进制分类模型。</li><li id="ae0f" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">损失函数测量BCEWithLogits损失。</li><li id="83fe" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">损耗的梯度被重置为零。</li><li id="d85e" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">损失函数向后传播(计算损失的梯度)。</li><li id="7816" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">Adam optimizer朝着“正确”的方向前进。</li></ul><p id="a781" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此时不给出完整的代码是愚蠢的。你可以自己随意摆弄算法和数据集。</p><p id="d2ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">提示</strong>:使用谷歌Colab，它就像类固醇上的木星笔记本——也非常容易上手。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="2fc0" class="oa mr it bd ms ob oc od mv oe of og my jz oh ka nb kc oi kd ne kf oj kg nh ok bi translated">结论</h1><p id="038c" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">二进制分类算法的结果在训练集和测试集上都有大约98%的准确率——很神奇，不是吗？这也不需要太多的努力。如果你对这篇文章有任何改进，请在下面的评论中告诉我。这将有助于我和未来的读者，提前谢谢你。</p></div></div>    
</body>
</html>