<html>
<head>
<title>Object Detection on Newspaper images using YoloV3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于 YoloV3 的报纸图像目标检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/object-detection-on-newspaper-images-using-yolov3-85acfa563080?source=collection_archive---------16-----------------------#2020-07-05">https://towardsdatascience.com/object-detection-on-newspaper-images-using-yolov3-85acfa563080?source=collection_archive---------16-----------------------#2020-07-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="0d57" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">为更好的 OCR 制作自定义 YoloV3 模型</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/effac392da2f6d4f4c45756d1906415c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X98JKdKDCjFAR-Q107QQeA.jpeg"/></div></div></figure><blockquote class="kr ks kt"><p id="7ff9" class="ku kv kw kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">当我在报纸图像上尝试光学字符识别时，我意识到大多数文档都有章节，并且文本不一定跨越页面的整个水平空间。</p><p id="2b84" class="ku kv kw kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">即使宇宙魔方能够辨认出文本，它也是乱糟糟的。为了解决这个问题，该模型应该能够识别文档中的部分，并在其周围绘制一个边界框，并执行 OCR。就在这个时候，我想到了在这样的图像上应用 Yolo 物体检测。</p></blockquote><h2 id="fbb3" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">YoloV3 简介</h2><p id="90fc" class="pw-post-body-paragraph ku kv iq kx b ky mn jr la lb mo ju ld ma mp lg lh me mq lk ll mi mr lo lp lq ij bi translated">YOLOv3 速度极快，精度极高。在 mAP 中，测得 5 IOU YOLOv3 与焦点损耗相当，但速度快 4 倍左右。此外，你可以简单地通过改变模型的大小在速度和准确性之间进行权衡，不需要重新训练！</p><h1 id="db1b" class="ms ls iq bd lt mt mu mv lw mw mx my lz jw mz jx md jz na ka mh kc nb kd ml nc bi translated">创建数据集</h1><p id="8059" class="pw-post-body-paragraph ku kv iq kx b ky mn jr la lb mo ju ld ma mp lg lh me mq lk ll mi mr lo lp lq ij bi translated">首先，我需要一个标记图像的数据集来训练 Yolo 模型，但没有可用的数据集，所以我决定自己制作一个。找到了一个用<strong class="kx ir"> Python </strong>写的优秀工具，按照 Yolo 格式<a class="ae nd" href="https://github.com/tzutalin/labelImg" rel="noopener ugc nofollow" target="_blank">T3】链接 T5】给图片加标签。经过几个小时的鼠标点击、绘制边框和手工标记报纸图片，我最终得到了一个包含 4 个类的图片数据集</a></p><ul class=""><li id="9d10" class="ne nf iq kx b ky kz lb lc ma ng me nh mi ni lq nj nk nl nm bi translated">头条新闻</li><li id="4500" class="ne nf iq kx b ky nn lb no ma np me nq mi nr lq nj nk nl nm bi translated">标志；徽标</li><li id="8420" class="ne nf iq kx b ky nn lb no ma np me nq mi nr lq nj nk nl nm bi translated">图像</li><li id="f439" class="ne nf iq kx b ky nn lb no ma np me nq mi nr lq nj nk nl nm bi translated">文本</li></ul><p id="db9a" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld ma lf lg lh me lj lk ll mi ln lo lp lq ij bi translated">我已经将数据集上传到 Kaggle 和 Github 上，供任何人进一步使用。(下面的链接)</p><h2 id="3f5a" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">数据集文件结构</h2><pre class="kg kh ki kj gt ns nt nu nv aw nw bi"><span id="7266" class="lr ls iq nt b gy nx ny l nz oa">.<br/>├── custom.names<br/>├── detector.data<br/>├── images<br/>│   ├── 001.jpg<br/>│   ├── 002.jpg<br/>│   ├── 003.jpeg<br/>│   ├── 100.jpg <br/>|   .....<br/>│   ├── 101.JPG<br/>├── labels<br/>│   ├── 001.txt<br/>│   ├── 002.txt<br/>│   ├── 101.txt<br/>├── newspaper-yolo.cfg<br/>├── test.txt<br/>└── train.txt</span></pre><h1 id="59e5" class="ms ls iq bd lt mt mu mv lw mw mx my lz jw mz jx md jz na ka mh kc nb kd ml nc bi translated">培养</h1><p id="e818" class="pw-post-body-paragraph ku kv iq kx b ky mn jr la lb mo ju ld ma mp lg lh me mq lk ll mi mr lo lp lq ij bi translated">我们将使用的模型架构被称为 YOLOv3，或者你只看一次，由 Joseph Redmon 编写。这种特定的模型是一次性学习器，这意味着每幅图像只通过网络一次来进行预测，这使得该架构的性能非常高，在预测视频馈送时每秒可查看高达 60 帧。从根本上说，YOLO 把一幅图像分成几个子部分，并对每个子部分进行卷积，然后汇集起来进行预测。这里有一个关于 YOLO 的深度潜水推荐<a class="ae nd" href="http://datahacker.rs/yolov3-tensorflow/" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="b526" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld ma lf lg lh me lj lk ll mi ln lo lp lq ij bi translated">现在，即使我们在自定义数据集上训练我们的模型，使用另一个已经训练好的模型的权重作为起点仍然是有利的。想象一下，我们想要尽可能快地爬上一座山，而不是完全从零开始创建我们自己的路径，我们将从假设别人的路径比我们随机尝试猜测曲折路径更快开始。</p><p id="6d6c" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld ma lf lg lh me lj lk ll mi ln lo lp lq ij bi translated">为了给我们的模型计算提供动力，我们将使用 Google Colab，它提供免费的 GPU 计算资源(在浏览器打开的情况下长达 24 小时)。</p><p id="2df1" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld ma lf lg lh me lj lk ll mi ln lo lp lq ij bi translated">从克隆约瑟夫·雷德蒙的 Github 回购开始。这提供了动态训练对象检测模型所需的大部分工具。</p><pre class="kg kh ki kj gt ns nt nu nv aw nw bi"><span id="0f44" class="lr ls iq nt b gy nx ny l nz oa">git clone <a class="ae nd" href="https://github.com/pjreddie/darknet" rel="noopener ugc nofollow" target="_blank">https://github.com/pjreddie/darkne</a>t</span></pre><p id="02fb" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld ma lf lg lh me lj lk ll mi ln lo lp lq ij bi translated">编辑 yolo-v3.cfg 文件，根据您的要求进行配置</p><p id="1b89" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld ma lf lg lh me lj lk ll mi ln lo lp lq ij bi translated">你需要在第一行输入你的班级号，<code class="fe ob oc od nt b">train.txt</code>和<code class="fe ob oc od nt b">test.txt</code>路径在第二和第三行，<code class="fe ob oc od nt b">object.names</code>路径在第四行。</p><p id="38c4" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld ma lf lg lh me lj lk ll mi ln lo lp lq ij bi translated">现在你需要编辑<code class="fe ob oc od nt b"><strong class="kx ir">*.cfg</strong></code>文件。默认情况下，每个 YOLO 层有 255 个输出:每个锚点 85 个输出[4 个框坐标+ 1 个对象置信度+ 80 个类别置信度]，乘以 3 个锚点。</p><p id="6ba7" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld ma lf lg lh me lj lk ll mi ln lo lp lq ij bi translated">在我们的例子中，我们只使用了四个类，然后我们需要编辑过滤器。您可以将过滤器减少到<code class="fe ob oc od nt b">filters=[4 + 1 + n] * 3</code>，其中<code class="fe ob oc od nt b">n</code>是您的类计数。这种修改应该在三个 YOLO 层的每一层之前进行。此外，修改<code class="fe ob oc od nt b">classes=80</code>到<code class="fe ob oc od nt b">classes=n</code>在每个 YOLO 层，其中<code class="fe ob oc od nt b">n</code>是你的类计数。</p><p id="5abc" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld ma lf lg lh me lj lk ll mi ln lo lp lq ij bi translated">我更改了第<strong class="kx ir"> 6 </strong>和<strong class="kx ir"> 7 </strong>行中的批量和细分。然后是行号<strong class="kx ir"> 610 </strong>(类=4)和<strong class="kx ir"> 603 </strong>(过滤器=27)，然后是行号<strong class="kx ir"> 689 </strong> &amp; <strong class="kx ir"> 696 </strong>，最后是行号<strong class="kx ir">776</strong>&amp;783。如果您使用 tiny-yolo，行号会有所不同。</p><pre class="kg kh ki kj gt ns nt nu nv aw nw bi"><span id="d1f7" class="lr ls iq nt b gy nx ny l nz oa">[yolo]<br/>mask = 0,1,2<br/>anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326<br/>classes=4<br/>num=9<br/>jitter=.3<br/>ignore_thresh = .7<br/>truth_thresh = 1<br/>random=1</span></pre><p id="e40b" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld ma lf lg lh me lj lk ll mi ln lo lp lq ij bi translated">将 num classes 更改为您想要检测的类的数量，我们就可以开始训练了。</p><pre class="kg kh ki kj gt ns nt nu nv aw nw bi"><span id="986c" class="lr ls iq nt b gy nx ny l nz oa"># Start Training </span><span id="a4bf" class="lr ls iq nt b gy oe ny l nz oa">./darknet detector train custom_data/detector.data custom_data/newspaper-yolo.cfg -dont_show</span></pre><p id="5bc6" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld ma lf lg lh me lj lk ll mi ln lo lp lq ij bi translated">在数千行控制台输出和几个小时后…</p></div><div class="ab cl of og hu oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="ij ik il im in"><h1 id="34b7" class="ms ls iq bd lt mt om mv lw mw on my lz jw oo jx md jz op ka mh kc oq kd ml nc bi translated"><strong class="ak">结果</strong></h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/effac392da2f6d4f4c45756d1906415c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X98JKdKDCjFAR-Q107QQeA.jpeg"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi or"><img src="../Images/591a72431c6a7c4c46bfcd601a74970d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-qja367LABIs6dTJmImOGg.jpeg"/></div></div></figure><p id="817c" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld ma lf lg lh me lj lk ll mi ln lo lp lq ij bi translated">在图像增强的帮助下，经过 2 小时训练的 32 幅图像的小数据集能够产生 98%以上置信度的结果。考虑到报纸是非常复杂的文档，需要适应大量的内容，这个模型表现得非常好。类似的模型可以被训练用于各种任务，如验证 Id，验证物理表单，转换手写笔记等等！</p><p id="ce10" class="pw-post-body-paragraph ku kv iq kx b ky kz jr la lb lc ju ld ma lf lg lh me lj lk ll mi ln lo lp lq ij bi translated">如果你喜欢我做的，请随意鼓掌！(你可以顺便做 50 次)</p><h1 id="0f9a" class="ms ls iq bd lt mt mu mv lw mw mx my lz jw mz jx md jz na ka mh kc nb kd ml nc bi translated"><strong class="ak">源代码和数据集链接</strong></h1><div class="os ot gp gr ou ov"><a href="https://github.com/imvab/news-yolo" rel="noopener  ugc nofollow" target="_blank"><div class="ow ab fo"><div class="ox ab oy cl cj oz"><h2 class="bd ir gy z fp pa fr fs pb fu fw ip bi translated">imvab/news-yolo</h2><div class="pc l"><h3 class="bd b gy z fp pa fr fs pb fu fw dk translated">报纸图像中的目标检测。在 GitHub 上创建一个帐户，为 imvab/news-yolo 的发展做出贡献。</h3></div><div class="pd l"><p class="bd b dl z fp pa fr fs pb fu fw dk translated">github.com</p></div></div><div class="pe l"><div class="pf l pg ph pi pe pj kp ov"/></div></div></a></div><div class="os ot gp gr ou ov"><a href="https://www.kaggle.com/immvab/document-object-detection" rel="noopener  ugc nofollow" target="_blank"><div class="ow ab fo"><div class="ox ab oy cl cj oz"><h2 class="bd ir gy z fp pa fr fs pb fu fw ip bi translated">文档对象检测</h2><div class="pc l"><h3 class="bd b gy z fp pa fr fs pb fu fw dk translated">用于文本图像上目标检测的标记图像。</h3></div><div class="pd l"><p class="bd b dl z fp pa fr fs pb fu fw dk translated">www.kaggle.com</p></div></div><div class="pe l"><div class="pk l pg ph pi pe pj kp ov"/></div></div></a></div><h1 id="d9cb" class="ms ls iq bd lt mt mu mv lw mw mx my lz jw mz jx md jz na ka mh kc nb kd ml nc bi translated">在 LinkedIn 和 Github 上与我联系</h1><div class="os ot gp gr ou ov"><a href="https://in.linkedin.com/in/vaibhav-birla-960412b7" rel="noopener  ugc nofollow" target="_blank"><div class="ow ab fo"><div class="ox ab oy cl cj oz"><h2 class="bd ir gy z fp pa fr fs pb fu fw ip bi translated">vaibhav Birla-Techno India Salt Lake-Kolkata，西孟加拉邦，印度| LinkedIn</h2><div class="pc l"><h3 class="bd b gy z fp pa fr fs pb fu fw dk translated">在世界上最大的职业社区 LinkedIn 上查看 Vaibhav Birla 的个人资料。Vaibhav 的教育列在…</h3></div><div class="pd l"><p class="bd b dl z fp pa fr fs pb fu fw dk translated">in.linkedin.com</p></div></div><div class="pe l"><div class="pl l pg ph pi pe pj kp ov"/></div></div></a></div><div class="os ot gp gr ou ov"><a href="https://github.com/imvab" rel="noopener  ugc nofollow" target="_blank"><div class="ow ab fo"><div class="ox ab oy cl cj oz"><h2 class="bd ir gy z fp pa fr fs pb fu fw ip bi translated">imvab -概述</h2><div class="pc l"><h3 class="bd b gy z fp pa fr fs pb fu fw dk translated">在 GitHub 上注册你自己的个人资料，这是托管代码、管理项目和构建软件的最佳地方…</h3></div><div class="pd l"><p class="bd b dl z fp pa fr fs pb fu fw dk translated">github.com</p></div></div><div class="pe l"><div class="pm l pg ph pi pe pj kp ov"/></div></div></a></div></div></div>    
</body>
</html>