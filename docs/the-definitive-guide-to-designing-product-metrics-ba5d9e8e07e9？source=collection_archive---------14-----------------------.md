# 设计产品指标的权威指南

> 原文：<https://towardsdatascience.com/the-definitive-guide-to-designing-product-metrics-ba5d9e8e07e9?source=collection_archive---------14----------------------->

## 讨论精确度和召回指标、指标设计访谈和指标生命周期

作者扎卡里·托马斯([zthomas.nc@gmail.com](mailto:zthomas.nc@gmail.com)，[推特](https://twitter.com/zach_i_thomas)，[领英](https://www.linkedin.com/in/thomaszi/))

![](img/04a4056bef0797e77e594c276f033804.png)

斯蒂芬·道森在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

(这篇文章最初是作为一个妙语文档写成的[)](https://quip.com/edU3AgdiNOo1)

# 背景

如果你有一个技术产品，你也会想要它的度量标准。这是 Reddit 的联合创始人[在这段视频中给出的建议:](https://youtu.be/6IFR3WYSBFM?t=973)在开始一个产品时，你会想要跟踪*一些东西*及其趋势，以避免数据债务。科技公司的产品和工程团队现在认为这是传统智慧。产品的成功和质量取决于验证它的指标。不去衡量就无法提高。

看新闻，看电影，比如《社会困境》，科技行业和社会似乎有一个广泛的愿望，那就是超越仅仅使用参与度作为成功的衡量标准。也就是说，令人惊讶的是，我遇到的讨论如何*设计*一个好的指标的平易近人的在线资源很少。这非常令人惊讶，因为这是数据科学团队的核心职责之一！该指南旨在填补这一空白。

# 两桶指标:精确度和召回率

在我们设计新的指标之前，我们应该了解现有的指标已经测量了什么。就个人而言，我发现将度量标准分成两大类很有帮助:*精度*和*召回*。

分析师可以将现有的指标分为这两个类别，并为新的指标找到要解决的度量差距。或者，这个框架可以帮助将提议的新指标放在现有指标中。第一个召回指标可能比第十个精度指标更有影响力，反之亦然。

# 精确度指标🎯

**精度度量**测量产品当前迭代的使用和反馈。这些指标通常来自产品日志。团队使用它们来衡量增长和优化特性。事实上，我可以说绝大多数分析师使用和设计的度量标准本质上都是精确的。

例子包括:

*   **DAU、MAU 和其他使用指标**:了解产品及其功能的总使用量和参与度是产品分析团队的核心任务
*   *阅读更多:*参见 Y Combinator 的[关键指标指南](https://www.ycombinator.com/library/1y-key-metrics)的“广告”部分的非收入指标
*   **CSAT 和其他以产品为中心的调查指标**:类似 CSAT 的指标(用 1 到 5 的等级对功能或产品进行评级，通过自由形式的回答询问原因)侧重于收集关于产品当前状态的反馈
*   *阅读更多*:这篇 [GetFeedback 文章](https://www.getfeedback.com/resources/csat/customer-satisfaction-score-csat-complete-guide/)概述了计算 CSAT 和不同行业基准的两种方法
*   **延迟指标:**延迟指标衡量产品加载时间和基础设施性能
*   *阅读更多*:产品分析师团队通常不会处理延迟指标，但是非常成熟的产品可能希望了解延迟与产品增长和满意度之间的关系。特雷诺·斯洛斯、努卡拉和劳写的这篇关于谷歌如何看待基础设施指标的文章可能会在这方面提供一些思路

# 召回指标📚

**召回指标**根据基本事实跟踪产品性能。如果精度指标衡量增长和优化现有功能，召回指标有助于衡量产品质量和推动新功能开发。与精度指标不同，召回指标可能不仅仅需要产品日志来衡量。由团队进行的用户调查或数据标记可以作为召回指标的数据输入。有时，用户体验研究团队将拥有基于调查的召回指标，而不是数据科学团队，后者往往更关注基于日志的指标。

例子包括:

*   净推介值(NPS) :可以说，最著名的召回指标是 NPS，因为客户对产品的忠诚度是可能的替代品的函数
*   *阅读更多信息*:此[指标概述](https://www.qualtrics.com/experience-management/customer/net-promoter-score/)除了指标的计算之外，还包括 NPS 跟进问题的提示
*   **推荐系统或搜索系统的召回**:召回指标衡量推荐或搜索系统的结果是否真正满足了最终用户的意图
*   *阅读更多:*正如[的第 21 张幻灯片所示，你可以使用实际的用户喜欢/点击作为回忆分级的基础](https://courses.cs.washington.edu/courses/cse416/18sp/slides/L13_matrix-factorization.pdf)
*   *注意:*这种方法可能会夸大召回分数，因为它排除了潜在的喜欢，这些喜欢甚至不是产品的选项。例如，如果用户搜索一个产品，但根本没有看到它被列出来，召回指标应该理想地惩罚一个电子商务产品的推荐🤯。如果人们基于用户意图对推荐系统输出的样本进行人工评分，团队可以产生高覆盖率的召回指标。分析师的输入或指导有助于减少这些人工贴标过程中的偏差
*   **竞争分析指标**:对于有强大竞争对手的产品，分析师可以设计产品偏好、质量或任务完成指标来比较不同时期的产品
*   *阅读更多*:这篇[博文](https://www.idownloadblog.com/2018/07/25/siri-digital-assistants-survey/)描述了 Loup Ventures 如何向 Siri、Google Assistant 和 Alexa 询问同样的 800 个查询，并根据响应正确性和查询理解程度对每个查询进行评分。三个月后，他们重复了这个实验，看看每种产品在同一组查询中提高了多少

# 指标生命周期

既然我们已经建立了存在哪种度量，那么让我们深入到创建、报告和可能终止度量的过程中。

# 新的指标来自哪里？👶

总体而言，产品方向和市场、产品或客户成熟度的变化会推动对新指标的需求。更具体地说，新的指标可以来自:

*   **建立用户漏斗或发展现有漏斗**:新产品将从其用户获取和参与漏斗中获得其初始指标集
*   *阅读更多内容*:我见过的设计用户参与度漏斗及其相关指标的最佳教程是来自 [Udacity 的 A/B 测试课程的第 3 课](https://www.udacity.com/course/ab-testing--ud257)
*   **当前指标对功能发布没有反应**:新功能可能不再显示产品漏斗指标的统计和实际改进。这可能发生在一个产品饱和的市场，或者当产品变得足够复杂的时候。在这种情况下，分析师团队可能需要设计新的、更具可操作性的指标
*   *阅读更多信息*:在[设计和评估指标](https://medium.com/@seanjtaylor/designing-and-evaluating-metrics-5902ad6873bf)的因果接近度部分，Sean Taylor 描述了产品和工程团队应该如何通过特性发布来影响指标的驱动因素。缺少该属性的度量是不可操作的
*   **用户投诉或显著损失**:反复的负面用户或客户反馈以及媒体和市场分析师的评论可能会推动注重质量的指标的创建
*   *阅读更多内容*:如[中所述，这项新的美国案例研究](https://www.newamerica.org/oti/reports/why-am-i-seeing-this/case-study-youtube/#a-technical-overview-of-youtubes-recommendation-system)(见脚注 82-89 周围的文字)从 2016 年左右开始，Youtube 开始通过用户调查来衡量视频满意度，以更好地优化 Youtube 关于用户幸福和满意度的建议，而不是观看时间
*   **领导的指示+年度计划:**更实际的情况是，分析师团队经常在年度计划期间投资新的指标，以使指标与下一年的产品或公司战略保持一致

# 提出一种新的度量标准:访谈框架和古德哈特定律📝

一旦分析师团队确定了对新指标的需求，分析师就开始指标设计工作。数据科学团队希望这些分析师通过在实验和性能跟踪中使用提议的指标的潜在二阶效应进行推理

数据科学家访谈通常会围绕这一推理过程提出案例研究问题。根据我的经验，面试官要么会要求应聘者设计一个衡量标准，要么会提出一个衡量标准，并要求应聘者对其进行评估。以下是解决这些问题的框架:

*   🤔**提出澄清性问题，以理解数据输入**:确保你和面试官在哪些用户行为或其他数据输入会影响指标上保持一致。例如，在社交媒体产品上滚动、点赞、链接共享、状态发布、发送消息等。所有这些都可以作为专注于参与度的成功衡量标准吗
*   *提示:*由于数据输入是特定于产品的，我建议研究一下你的面试官会问到的产品，并创建一个关于你可以想象公司团队使用的指标的备忘单
*   例如，注释[“对于像 Lyft 或优步这样的公司来说，最重要的拼车指标是什么？”](https://www.quora.com/What-are-the-most-important-ride-sharing-metrics-for-a-company-like-Lyft-or-Uber)及其相关问题可以帮助您熟悉拼车指标及其输入
*   实际试用一个产品并理解它的机制和特性也是有帮助的——令人惊讶的是很多候选人没有这样做！
*   🤝**就该指标应衡量的行为或属性达成一致:**向面试官重复问题，并询问边缘案例。例如，如果一个电子商务平台的访问者要求定义一个对成功客户帐户进行分类的指标，那么可能值得询问团队是否期望该指标将一个具有高交易量但低 NPS 且不断下降的帐户分类为成功的
*   🧑‍🎓**提出指标:**我的建议是尽量简单，让后续问题帮助你决定是否需要让你的指标更复杂
*   *提示:*如果是顶线指标，面试官可能会跟进你的指标应该是什么时间粒度。例如，每天、每周或每月的活跃用户？
*   **⬇️讨论该指标会阻止哪些行为**:如果用户最终只是做了该指标衡量的事情，并停止了产品上的其他行为，会发生什么？回答这个假设性的问题会引出一个指标的二阶效应
*   *举例*:你提议将滚动作为基于订阅源的社交媒体产品的成功衡量标准。如果用户最终只在产品上滚动，这将使减少滚动的行为(如发帖、评论和点击链接)的使用为零。团队对激励这一结果满意吗？
*   **🚧讨论产品团队如何人为增加(“黑掉”)指标:**古德哈特定律指出，当人们知道他们的绩效是基于某个指标的[时，他们会调整自己的行为以优化该指标。在技术产品的背景下，产品经理、设计师和工程师可能会开始改变产品，以增加成功指标，尽管存在负面的权衡](/unintended-consequences-and-goodharts-law-68d60a94705c)
*   *举例*:你提议将滚动作为基于订阅源的社交媒体产品的成功衡量标准。这个指标激励设计者把内容块做得很长，或者把默认文本做得很大，以迫使用户滚动更多。该指标还激励产品经理和工程师创建有助于启动内容农场和传播其内容的功能和算法，以便用户有更多的项目可以滚动浏览。这些变化一起降低了产品的质量，但也增加了用户的滚动
*   **🏆🙅‍♂️讨论了哪些相关属性没有用度量标准**来衡量:不幸的是，简单明了的度量标准不会立刻衡量所有相关属性或用户行为。你应该向面试官概述你的衡量标准没有衡量的相关属性。你应该仍然能够论证你提出的度量标准与那些相关的属性相关，或者你是否需要为它们设计一个新的度量标准
*   *举例*:如果面试官让你为支付平台选择一个单一的成功指标，你可以说完成的交易效果最好，并且与其他重要指标相关，如 CSAT 和处理的总支付，即使完成的交易并不直接衡量这些属性

这个框架包含了我在公制设计面试中的经验。在接下来的部分中，我将讨论更多关于在分析师团队中经验地验证一个提议的度量标准，以及获得涉众的认同。

# 通过实验和分析验证新的度量标准📈

提出指标后，下一步是完成数据和实验分析，证明指标的行为符合预期且可行。验证指标需要几个步骤:

*   (如果相关)显示不同阈值的指标分布:如果指标基于阈值，则显示不同的阈值可能值如何影响指标的分布
*   *举例*:如果我们将流失阈值设置为 7 天、14 天、21 天或 28 天，流失指标会将百分之多少的用户归类为流失用户？实际显示每个值的分布，作为选择特定值的解释的一部分
*   **与相关现有指标的相关性分析**:展示相关性对于注重质量的新指标或现有指标的改进特别有用
*   *举例:*在拼车应用程序上，我预计随着乘车过程中增加的停车次数增加，用户满意度会下降或持平。相反，如果新的满意度随着停靠次数的增加而增加，那么这可能意味着日志问题，或者需要进行单独的调查来了解这种用户行为，因为这是违反直觉的
*   **精确/召回基本事实**:如果分析师使用调查或用户研究作为验证这些标签的基本事实，他们可以使描述某些行为为“好”、“坏”或“质量”的指标更有意义
*   *示例:*基于日志的数据分析，业务应用程序的产品分析师可能会建议将“良好的工作流完成”定义为点击次数不超过 3 次。为了令人信服地证明 3 次或更少的点击是“好的”,分析师还可以收集用户对不同工作流长度的满意度调查响应，并测量所提议的指标相对于调查响应的精确度和召回率
*   **通过实验进行的敏感性分析**:如果产品团队认为将持续推动度量标准的新特性没有改变度量标准，那么该度量标准可能不像设计的那样可操作。[设计和评估指标](https://medium.com/@seanjtaylor/designing-and-evaluating-metrics-5902ad6873bf)的指标生命周期部分的“验证”和“实验”要点描述了分析师如何使用保存的历史实验数据来显示一个新指标是否具有实验可以测量的实际的和统计上显著的效果

# 获得利益相关方对新指标的认可🤹

在验证流程的某个阶段，数据科学团队需要向工程和产品团队展示新指标及其行为，以获得认同和反馈，从而用作产品成功指标。

指标验证是数据分析的一种形式，所以我会记住 Roger Peng 关于这个主题的[建议](https://simplystatistics.org/2018/04/17/what-is-a-successful-data-analysis/):*如果数据分析的受众接受结果，那么数据分析就是成功的。*确保产品和工程团队的直觉检查通过了这个提议的指标和与之相关的分析。

# 监控和报告度量🗓️📊

在涉众批准之后，您的度量应该准备好进行记录了！用数据交流、可视化和讲述故事是一个可以写满一整本书的主题。也就是说，这里有一些可能有用的提示:

***公制格式和通信***

*   使用 7 天滚动平均值来说明影响大多数产品的日常指标的工作日/周末变化
*   团队通常建议基于调查或 95%置信区间的采样日志来报告指标
*   就如何沟通基于百分比的指标的变化与您的团队保持一致——它总是[很快变得令人困惑](https://www.tribtoday.com/news/latest-news/2020/08/tue-1121-a-m-fda-chief-apologizes-for-overstating-plasma-effect-on-virus/)

***仪表盘***

*   工程师和分析师都可以轻松地启动仪表板，因此风险承担者可能很难知道哪些仪表板最适合回答他们的问题。在大型技术公司，数据科学团队将在特定网站/应用程序上创建他们自己的“可信”仪表板集，产品领导层将这些仪表板视为真理
*   这是一个简单的建议，但是我喜欢 Eric Mayefsky 在这篇博文中所说的话——实际看看你创建的仪表板！使用它们来激发更深入的数据调查。*“泡在数据里。不要把你创建的仪表盘和报告当成是别人的产品——定期花时间，最好是每天都花时间，只是随便逛逛"*

***季度/预定指标评审***

*   除了实验报告之外，与工程和产品领导一起进行预定的指标审查和趋势分析，可以在更大的组织中推动指标影响
*   需要回答的常见问题包括指标变化归因于新功能/客户或外部影响、指标值与预测的比较、深入探究指标下降或未达到目标的原因、群组分析等。

# 日落度量🌅

根据我的经验，分析师很少反对指标。相反，数据工程团队和代码管理推动了度量标准的贬值。

数据团队试图优化计算核心指标所需的时间，通常是每天一次。他们的日常工作需要计算的指标越多，这些工作运行的时间就越长，工作失败的可能性就越大。这些工程团队有动机停止计算分析师和产品团队既不监控也不会发现有用的指标。

不重要的或未采用的度量在他们离开团队后可能缺少所有者，并且在很长一段时间没有更新后没有人要求记录。数据工程团队有反对这些无主度量的余地。

# 总结一下:公制设计清单📋

所以你有它！我们已经讨论过…

*   🎯📚两桶指标:精确度和召回率
*   👶新指标的来源和原因
*   📝如何思考指标的二阶效应(以及这个问题如何出现在面试中)
*   📈通过相关性和敏感性分析验证指标
*   🗓️📊指标监控和报告技巧
*   🌅公制日落发生的原因和方式

一如既往，我认为这是一个活的文档，我欢迎反馈——如果你有任何想法，请随时给我发邮件到 zthomas.nc @ gmail 或 LinkedIn[上！谢了。](https://www.linkedin.com/in/thomaszi/)