<html>
<head>
<title>Twitter JSON data processing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Twitter JSON 数据处理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/twitter-json-data-processing-3f353a5deac4?source=collection_archive---------7-----------------------#2020-07-04">https://towardsdatascience.com/twitter-json-data-processing-3f353a5deac4?source=collection_archive---------7-----------------------#2020-07-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3bd1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用 python 库清理和润色用于社交媒体分析的推文数据帧。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/e1927918cbb6d5c984959ea19028e192.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mz7r2-lL12zthjbE"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com/@ravinepz?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">拉维·夏尔马</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><p id="a4d3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated">witter 允许使用用于访问 Twitter API 的 Python 库 tweepy 来收集 tweepy。在这里，我不打算给出如何收集 tweet 的教程，因为已经有一些好的评论了(看看下面的参考资料)，而是给你一个完整的例子，说明如何处理 tweet 对象，以便建立一个干净的数据框架，我们可以在这个框架上进行社交媒体分析。</p><p id="2bd0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">TL；TR: </strong>在这个过程中，我们将展平 Twitter JSON，在几个选项(主推、转发、引用等)中选择文本对象。)，清理它们(删除非字母字符)，翻译非英语推文，计算文本的情感，以及关联给定用户定义的位置或自动地理定位的位置。</p><p id="a720" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">要使用的库:</strong> <a class="ae ky" href="https://pandas.pydata.org" rel="noopener ugc nofollow" target="_blank">熊猫</a><a class="ae ky" href="https://pypi.org/project/country-converter/" rel="noopener ugc nofollow" target="_blank">国家转换器</a><a class="ae ky" href="https://geopy.readthedocs.io/en/stable/#" rel="noopener ugc nofollow" target="_blank">GeoPy</a><a class="ae ky" href="https://spacy.io" rel="noopener ugc nofollow" target="_blank">spaCy</a><a class="ae ky" href="https://pypi.org/project/googletrans/" rel="noopener ugc nofollow" target="_blank">Google trans</a><a class="ae ky" href="https://www.nltk.org" rel="noopener ugc nofollow" target="_blank">NLTK</a>。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="bb95" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">每个<a class="ae ky" href="https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object" rel="noopener ugc nofollow" target="_blank"> <em class="ml"> tweet 对象</em> </a>以 JSON 格式出现，<em class="ml">混合了“根级”属性和子对象(用</em> <code class="fe mm mn mo mp b"><em class="ml">{}</em></code> <em class="ml">符号表示)</em>。Twitter 开发者页面给出了以下例子:</p><pre class="kj kk kl km gt mq mp mr ms aw mt bi"><span id="d5b5" class="mu mv it mp b gy mw mx l my mz">{<br/> "created_at": "Wed Oct 10 20:19:24 +0000 2018",<br/> "id": 1050118621198921728,<br/> "id_str": "1050118621198921728",<br/> "text": "To make room for more expression, we will now count all emojis as equal—including those with gender‍‍‍ ‍‍and skin t… https://t.co/MkGjXf9aXm",<br/> "user": {},  <br/> "entities": {}<br/>}</span></pre><p id="9cf1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当然，这只是组成每条推文的庞大字典中的一小部分。另一个流行的例子是这个<a class="ae ky" href="http://www.slaw.ca/wp-content/uploads/2011/11/map-of-a-tweet-copy.pdf" rel="noopener ugc nofollow" target="_blank"> Twitter 状态对象图</a>。</p><p id="a4b3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于大多数类型的分析，我们肯定需要属性，如 tweet 文本、用户屏幕名称或 tweet 位置。不幸的是，正如您所看到的，这些属性没有一个清晰的格式，相反，它们分布在 JSON 的各个层次上——例如，tweet 位置坐标位于</p><pre class="kj kk kl km gt mq mp mr ms aw mt bi"><span id="d3d5" class="mu mv it mp b gy mw mx l my mz">tweet_object['place']['bounding_box']['coordinates']</span></pre><p id="5ddd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正是由于这一事实，收集的推文需要一个大的清理和转换过程，这就是这篇文章的目的。</p><h2 id="3c1c" class="mu mv it bd na nb nc dn nd ne nf dp ng li nh ni nj lm nk nl nm lq nn no np nq bi translated">推特数据</h2><p id="80cc" class="pw-post-body-paragraph kz la it lb b lc nr ju le lf ns jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi lv translated"><span class="l lw lx ly bm lz ma mb mc md di">我</span>最近进行了一个<a class="ae ky" href="https://en.wikipedia.org/wiki/Language_localisation" rel="noopener ugc nofollow" target="_blank">语言本地化</a>项目，我需要在 Twitter 上做一个社交媒体分析。为此，我在几天的时间里收集了<strong class="lb iu"> 52830 条</strong>包含以下关键词的推文:<strong class="lb iu"> '#FIFA20' </strong>，'<strong class="lb iu"> #FIFA21' </strong>，<strong class="lb iu"> 'FIFA20' </strong>，<strong class="lb iu"> 'FIFA21' </strong>，<strong class="lb iu"> 'FIFA 20' </strong>，<strong class="lb iu"> 'FIFA 21' </strong>和<strong class="lb iu">' # easporter 然后，为了对它们进行正确的分析，我必须事先清理每个 tweet 对象，这样我才能得出有意义的结论。</strong></p><p id="5c10" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于该项目的性质，我主要感兴趣的是关于推文位置的数据(国家和坐标)，英文版本文本的情感，以及推文使用的语言。加工步骤的目标是完善和发现这些属性。您可以在以下存储库中找到该项目的详细信息:</p><div class="nw nx gp gr ny nz"><a href="https://github.com/hectoramirez/Language-localization_FIFA" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd iu gy z fp oe fr fs of fu fw is bi translated">hectoramirez/语言-本地化 _FIFA</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">这是一个端到端的项目，我们的目标是执行国际足联视频游戏的语言本地化，只有公众…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">github.com</p></div></div><div class="oi l"><div class="oj l ok ol om oi on ks nz"/></div></div></a></div><p id="b440" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们用这个数据集来举例说明 tweets 处理的步骤！</p><h1 id="11d2" class="oo mv it bd na op oq or nd os ot ou ng jz ov ka nj kc ow kd nm kf ox kg np oy bi translated">处理 JSON</h1><p id="9c41" class="pw-post-body-paragraph kz la it lb b lc nr ju le lf ns jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">正如我们看到的，在包含文本数据的<a class="ae ky" href="https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object" rel="noopener ugc nofollow" target="_blank"> Twitter JSON </a>中有多个字段。在典型的 tweet 中，有 tweet 文本、用户描述和用户位置。在超过 140 个字符的 tweet 中，还有扩展 tweet 子 JSON。在引用的推文中，有原始推文和引用推文的评论。</p><p id="9111" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了大规模分析 tweet，我们需要将 tweet JSON 扁平化为一个层次。这将允许我们以数据帧格式存储推文。为此，我们将定义函数<code class="fe mm mn mo mp b">flatten_tweets()</code>，该函数将接受几个关于文本和位置的字段(该字段存储在<code class="fe mm mn mo mp b">place</code>中)。看一看:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="c293" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，您可能想要研究所有的文本字段(主字段、转发字段或引用字段)，但是，为了简单起见，这里我只保留一个文本字段。为此，我们现在定义一个函数<code class="fe mm mn mo mp b">select_text(tweets)</code>来选择主要文本，无论该推文是主要推文还是转发推文，我们决定删除引用的文本，因为它通常是重复的，可能没有信息。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="3e9e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在构建数据框。请注意，我们选择了与社交媒体分析相关的主要列(字段)。这包括 tweet 语言、<code class="fe mm mn mo mp b">lang</code>和由用户手动设置的<code class="fe mm mn mo mp b">user-location</code>。我们还保留了<code class="fe mm mn mo mp b">place</code>中的<code class="fe mm mn mo mp b">country</code>、<code class="fe mm mn mo mp b">country_code</code>和<code class="fe mm mn mo mp b">coordinates</code>字段。当推文被地理标记时，这些字段就会出现，并且通常包含在不到 10%的推文中。以下代码块构建了数据帧:</p><pre class="kj kk kl km gt mq mp mr ms aw mt bi"><span id="2a0c" class="mu mv it mp b gy mw mx l my mz"><strong class="mp iu">import</strong> <strong class="mp iu">pandas</strong> <strong class="mp iu">as</strong> <strong class="mp iu">pd</strong><br/><br/><em class="ml"># flatten tweets</em><br/>tweets = flatten_tweets(tweets_data)<br/><br/><em class="ml"># select text</em><br/>tweets = select_text(tweets)<br/>columns = ['text', 'lang', 'user-location', 'place-country', <br/>           'place-country_code', 'location-coordinates', <br/>           'user-screen_name']<br/><br/><em class="ml"># Create a DataFrame from `tweets`</em><br/>df_tweets = pd.DataFrame(tweets, columns=columns)</span><span id="63a8" class="mu mv it mp b gy pb mx l my mz"><em class="ml"># replaces NaNs by Nones</em><br/>df_tweets.where(pd.notnull(df_tweets), <strong class="mp iu">None</strong>, inplace=<strong class="mp iu">True</strong>)</span></pre><p id="5e8e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据帧的头部看起来像这样:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/1caffdac6adc47e3bf68e2ec17e833fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vnbcrRKwkxsYs5gdi0XLDA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">df_tweets.head()</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/eb2e90d61d6dcaeab0faebf9cde22bcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7x_ZBgi1uItHBaoFEkwPyA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">df_tweets.info()</p></figure><p id="81cf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，几乎只有一半的推文包含手动设置的用户位置字段，甚至 1%的推文都没有地理标记，<em class="ml">即</em>，它们没有提供<em class="ml">位置</em>字段。这凸显了收集尽可能多的推文的重要性！</p><p id="e912" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在下文中，我们感兴趣的是清理和抛光每个 dataframe 列。</p><h1 id="03e4" class="oo mv it bd na op oq or nd os ot ou ng jz ov ka nj kc ow kd nm kf ox kg np oy bi translated">语言</h1><p id="e119" class="pw-post-body-paragraph kz la it lb b lc nr ju le lf ns jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">在流程的这一部分，我们将用语言标准名称替换<code class="fe mm mn mo mp b">lang</code>中的语言代码。如文档中所述:</p><blockquote class="pe pf pg"><p id="4724" class="kz la ml lb b lc ld ju le lf lg jx lh ph lj lk ll pi ln lo lp pj lr ls lt lu im bi translated">如果存在，[ <code class="fe mm mn mo mp b">lang</code> ]表示与机器检测到的 Tweet 文本语言相对应的 BCP 47 语言标识符，如果没有检测到语言，则为<code class="fe mm mn mo mp b"><em class="it">und</em></code>。</p></blockquote><p id="e8da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们使用<a class="ae ky" href="https://github.com/annexare/Countries/tree/master/data" rel="noopener ugc nofollow" target="_blank">这个库</a>中的辅助<code class="fe mm mn mo mp b">languages.json</code>文件来执行这个步骤。该文件将语言代码映射到语言标准名称。下面的代码将完成这个任务:</p><pre class="kj kk kl km gt mq mp mr ms aw mt bi"><span id="8704" class="mu mv it mp b gy mw mx l my mz"><strong class="mp iu">with</strong> open('languages.json', 'r', encoding='utf-8') <strong class="mp iu">as</strong> json_file:<br/>    languages_dict = json.load(json_file)</span><span id="3ed4" class="mu mv it mp b gy pb mx l my mz">names = []<br/><strong class="mp iu">for</strong> idx, row <strong class="mp iu">in</strong> df_tweets.iterrows():<br/>    lang = row['lang']<br/>    <strong class="mp iu">if</strong> lang == 'und':<br/>        names.append(<strong class="mp iu">None</strong>)<br/>    <strong class="mp iu">elif</strong> lang == 'in':<br/>        name = languages_dict['id']['name']<br/>        names.append(name)<br/>    <strong class="mp iu">elif</strong> lang == 'iw':<br/>        name = languages_dict['he']['name']<br/>        names.append(name)<br/>    <strong class="mp iu">else</strong>:<br/>        name = languages_dict[lang]['name']<br/>        names.append(name)<br/><br/>df_tweets['language'] = names<br/>df_tweets.drop(['lang'], axis=1, inplace=<strong class="mp iu">True</strong>)</span></pre><h1 id="df55" class="oo mv it bd na op oq or nd os ot ou ng jz ov ka nj kc ow kd nm kf ox kg np oy bi translated">位置</h1><p id="e980" class="pw-post-body-paragraph kz la it lb b lc nr ju le lf ns jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">现在我们开始处理位置。我们将首先处理<code class="fe mm mn mo mp b">place</code>字段，然后处理<code class="fe mm mn mo mp b">user-location</code>字段。</p><h2 id="df8b" class="mu mv it bd na nb nc dn nd ne nf dp ng li nh ni nj lm nk nl nm lq nn no np nq bi translated">地方</h2><p id="35cd" class="pw-post-body-paragraph kz la it lb b lc nr ju le lf ns jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">很明显,<code class="fe mm mn mo mp b">place</code>对象中的数据比<code class="fe mm mn mo mp b">user-location</code>更可靠。因此，虽然它构成了我们推文的 0.91%，但我们会照顾它。首先，<code class="fe mm mn mo mp b">place-country_code</code>中的国家代码以 ISO 2 形式出现，为此我们将使用<a class="ae ky" href="https://github.com/konstantinstadler/country_converter" rel="noopener ugc nofollow" target="_blank">国家转换器</a>将其转换为 ISO 3 形式。然后，我们将执行同样的操作，将<code class="fe mm mn mo mp b">place-country</code>名称改为标准的简称。这是有利的，因为，例如，<strong class="lb iu"> Plotly 地图使用 ISO 3 代码来定位国家。</strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><h2 id="a3b9" class="mu mv it bd na nb nc dn nd ne nf dp ng li nh ni nj lm nk nl nm lq nn no np nq bi translated">用户位置</h2><p id="b885" class="pw-post-body-paragraph kz la it lb b lc nr ju le lf ns jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">在这里，我们将手动设置的<code class="fe mm mn mo mp b">user-locations</code>翻译成国家名称和代码——这涉及到对用户的信任。我们使用<a class="ae ky" href="https://geopy.readthedocs.io/en/latest/#" rel="noopener ugc nofollow" target="_blank"> GeoPy </a>库来识别一个位置(可能是一个地址)并为其分配一个国家。同样，我们使用<code class="fe mm mn mo mp b">country_converter</code>来查找 ISO 3 表格中的国家代码。</p><p id="7582" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">提醒一句</strong> : GeoPy 连接到一个 API，不幸的是，每次调用几乎要花一秒钟。这使得计算~ 50 K tweets 的过程相当慢。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="ed6f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">注意:</strong> <a class="ae ky" href="https://tqdm.github.io" rel="noopener ugc nofollow" target="_blank"> tqdm </a>是一个 python 库，对 pandas 有很好的实现，在代码运行时输出进度条。这会让你的生活更轻松！</p><p id="c7ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们将<code class="fe mm mn mo mp b">place-country</code>和<code class="fe mm mn mo mp b">user-country</code>列减少为一列，当前者存在时保留前者，否则保留后者。我们对<em class="ml">代码</em>列进行同样的操作:</p><pre class="kj kk kl km gt mq mp mr ms aw mt bi"><span id="052e" class="mu mv it mp b gy mw mx l my mz">countries, codes = [], []<br/><strong class="mp iu">for</strong> idx, row <strong class="mp iu">in</strong> df_tweets.iterrows():<br/>    <strong class="mp iu">if</strong> row['place-country_code'] <strong class="mp iu">is</strong> <strong class="mp iu">None</strong>:<br/>        country = row['user-country']<br/>        code = row['user-country_code']<br/>        countries.append(country)<br/>        codes.append(code)<br/>    <strong class="mp iu">else</strong> :<br/>        countries.append(row['place-country'])<br/>        codes.append(row['place-country_code'])<br/><br/>df_tweets['location'] = countries<br/>df_tweets['location_code'] = codes<br/><br/><em class="ml"># drop old columns</em><br/>df_tweets.drop(columns=['place-country', 'place-country_code', <br/>                 'user-country', 'user-country_code'], inplace=<strong class="mp iu">True</strong>)</span></pre><p id="0104" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此时，我们的数据集如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pk"><img src="../Images/97c198724360693985a67290c1d667f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TZuEgkrs4er_G4WmIMa2gw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">df_tweets.head()</p></figure><h1 id="86a8" class="oo mv it bd na op oq or nd os ot ou ng jz ov ka nj kc ow kd nm kf ox kg np oy bi translated">文本清理</h1><p id="a00a" class="pw-post-body-paragraph kz la it lb b lc nr ju le lf ns jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">现在是处理推文文本的时候了。这将涉及删除非字母字符和翻译非英语推文。然而，我们将保留这两个选项，并实际使用带有表情符号和其他字符的文本进行分析，因为我们的情感分析器可以很好地处理它们。</p><p id="f2a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要删除非字母字符，我们使用<a class="ae ky" href="https://spacy.io/" rel="noopener ugc nofollow" target="_blank"> spaCy </a>，因为它非常简单，我们不需要指定正则表达式。请记住，下面的代码块删除了带有撇号的表情符号和单词，如“我是”、“你们都是”、“不要”等。</p><pre class="kj kk kl km gt mq mp mr ms aw mt bi"><span id="e99a" class="mu mv it mp b gy mw mx l my mz"><strong class="mp iu">import</strong> <strong class="mp iu">spacy</strong><br/><br/>nlp = spacy.load('en_core_web_sm')<br/><br/><strong class="mp iu">def</strong> cleaner(string):<br/>    <br/>    <em class="ml"># Generate list of tokens</em><br/>    doc = nlp(string)<br/>    lemmas = [token.lemma_ <strong class="mp iu">for</strong> token <strong class="mp iu">in</strong> doc]</span><span id="14c6" class="mu mv it mp b gy pb mx l my mz">    <em class="ml"># Remove tokens that are not alphabetic </em><br/>    a_lemmas = [lemma <strong class="mp iu">for</strong> lemma <strong class="mp iu">in</strong> lemmas <strong class="mp iu">if</strong> lemma.isalpha() <br/>                 <strong class="mp iu">or </strong>lemma == '-PRON-'] </span><span id="5bd7" class="mu mv it mp b gy pb mx l my mz">    <em class="ml"># Print string after text cleaning</em><br/>    <strong class="mp iu">return</strong> ' '.join(a_lemmas)<br/><br/>df_tweets['text_cleaned'] = \<br/>                   df_tweets['text'].progress_apply(cleaner)</span></pre><h2 id="89bc" class="mu mv it bd na nb nc dn nd ne nf dp ng li nh ni nj lm nk nl nm lq nn no np nq bi translated">翻译</h2><p id="fc90" class="pw-post-body-paragraph kz la it lb b lc nr ju le lf ns jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">为了<strong class="lb iu">翻译</strong>非英语推文，我们使用<a class="ae ky" href="https://pypi.org/project/googletrans/" rel="noopener ugc nofollow" target="_blank"> googletrans </a>，作为 GeoPy，它连接到它的 API，然而它要快得多。</p><p id="44a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">另一个警告:</strong>存在一个讨论过的记录不良的错误，<em class="ml">例如</em>，这里:<a class="ae ky" href="https://stackoverflow.com/questions/49497391/googletrans-api-error-expecting-value-line-1-column-1-char-0" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/49497391/Google trans-API-error-expecting-value-line-1-column-1-char-0</a>，它会断开您的连接并阻止您的 IP。为了避免这个错误，我使用<code class="fe mm mn mo mp b">np.array_split()</code>将数据帧分成几个块，在一个循环中一次处理一个块。通过这样做，错误不会发生，但是我仍然将每个块的翻译保存到一个<code class="fe mm mn mo mp b">csv</code>中，这样如果在任何迭代中出错，我可以只重新计算一个块。我每次都会实例化<code class="fe mm mn mo mp b">Translator()</code>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="207f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们将原始的、未经处理的英文文本添加到<code class="fe mm mn mo mp b">text_english</code>:</p><pre class="kj kk kl km gt mq mp mr ms aw mt bi"><span id="9b77" class="mu mv it mp b gy mw mx l my mz"><em class="ml"># replaces NaNs by Nones</em><br/>df_english.where(pd.notnull(df_english), <strong class="mp iu">None</strong>, inplace=<strong class="mp iu">True</strong>)<br/><br/><em class="ml"># add original English tweets to text_english by replacing Nones</em><br/>texts = []<br/><strong class="mp iu">for</strong> idx, row <strong class="mp iu">in</strong> df_english.iterrows():<br/>    <strong class="mp iu">if</strong> row['text_english'] <strong class="mp iu">is</strong> <strong class="mp iu">None</strong>:<br/>        text = row['text']<br/>        texts.append(text)<br/>    <strong class="mp iu">else</strong> :<br/>        texts.append(row['text_english'])<br/><br/>df_english['text_english'] = texts</span></pre><p id="d94e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此时，数据帧看起来像这样:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pl"><img src="../Images/7dc7e4f715e3487cb8092b6b0c7a3fd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fm09SX0yMaNyStAchZblbg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">df_english.head()</p></figure><h1 id="8be2" class="oo mv it bd na op oq or nd os ot ou ng jz ov ka nj kc ow kd nm kf ox kg np oy bi translated">情感分析</h1><p id="2cc3" class="pw-post-body-paragraph kz la it lb b lc nr ju le lf ns jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">我们最终计算每条推文的情感。为此，我们使用<code class="fe mm mn mo mp b">nltk.sentiment.vader</code>库中<a class="ae ky" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> NLTK </a>的<code class="fe mm mn mo mp b">SentimentIntensityAnalyzer</code>对象。</p><blockquote class="pe pf pg"><p id="9e88" class="kz la ml lb b lc ld ju le lf lg jx lh ph lj lk ll pi ln lo lp pj lr ls lt lu im bi translated">VADER (Valence Aware 字典和情感推理器)是一个基于词典和规则的情感分析工具，专门针对社交媒体中表达的情感。<em class="it"/><a class="ae ky" href="https://medium.com/analytics-vidhya/simplifying-social-media-sentiment-analysis-using-vader-in-python-f9e6ec6fc52f" rel="noopener">T22【参。】 </a></p></blockquote><p id="ec15" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个库使用起来非常简单，如你所见:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="ea7f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，<code class="fe mm mn mo mp b">polarity_score</code>输出文本为负、中性或正的概率以及一个复合分数。然后，我们提取后者并将分数附加到数据帧中。</p><h1 id="e202" class="oo mv it bd na op oq or nd os ot ou ng jz ov ka nj kc ow kd nm kf ox kg np oy bi translated">结束</h1><p id="f411" class="pw-post-body-paragraph kz la it lb b lc nr ju le lf ns jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">为了便于展示，我们对各列进行了重新排序。</p><pre class="kj kk kl km gt mq mp mr ms aw mt bi"><span id="3363" class="mu mv it mp b gy mw mx l my mz">cols_order = ['text', 'language', 'location', 'location_code', <br/>              'location-coordinates', 'sentiment', 'text_english', <br/>              'text_cleaned', 'user-screen_name']</span><span id="cfa5" class="mu mv it mp b gy pb mx l my mz">df_final = df_sentiment[cols_order]</span></pre><p id="44c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最终数据集应该如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pm"><img src="../Images/240ff0121597b437c8a14507ad0c9bfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WUmrLuIrcU7377n3YN1mug.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">df_final.head()</p></figure><h1 id="b30f" class="oo mv it bd na op oq or nd os ot ou ng jz ov ka nj kc ow kd nm kf ox kg np oy bi translated">附加:一个简单的分析</h1><p id="ae51" class="pw-post-body-paragraph kz la it lb b lc nr ju le lf ns jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">为了举例说明可以用这个数据集做什么，让我们按国家建立一个平均推文情绪得分的可视化:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="c7b6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，我们使用了一个国家/语言数据框架，它可以在<a class="ae ky" href="https://github.com/hectoramirez/Language-localization_FIFA/blob/master/Countries/countries_lang_full.csv" rel="noopener ugc nofollow" target="_blank">这个库</a>中找到。上面的代码输出以下 Plotly 地图:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pn pa l"/></div></figure><p id="ab2f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这张世界地图看起来不太乐观😕</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="ca8f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">这篇文章中使用的全部代码可以在我的知识库中找到:</strong></p><div class="nw nx gp gr ny nz"><a href="https://github.com/hectoramirez/Language-localization_FIFA/blob/master/Tweets%20processing%20and%20sentiment.py" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd iu gy z fp oe fr fs of fu fw is bi translated">hectoramirez/语言-本地化 _FIFA</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">EA Sports 的 FIFA 本地化端到端研究。通过以下方式为 hectoramirez/Language-localization _ FIFA 的发展做出贡献…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">github.com</p></div></div><div class="oi l"><div class="po l ok ol om oi on ks nz"/></div></div></a></div><h2 id="28af" class="mu mv it bd na nb nc dn nd ne nf dp ng li nh ni nj lm nk nl nm lq nn no np nq bi translated">关于作者</h2><p id="7d7a" class="pw-post-body-paragraph kz la it lb b lc nr ju le lf ns jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">我最近获得了物理学博士学位，目前正在进入数据科学领域。<strong class="lb iu">非常感谢对这篇文章的任何评论和/或建议。</strong>另外，看看我的其他故事:</p><div class="nw nx gp gr ny nz"><a rel="noopener follow" target="_blank" href="/your-live-covid-19-tracker-with-airflow-and-github-pages-658c3e048304"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd iu gy z fp oe fr fs of fu fw is bi translated">您的实时新冠肺炎跟踪与气流和 GitHub 网页</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">加载数据，用散景制作出色的可视化效果，将它们放在 GitHub Pages 网站上，让气流自动流动…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">towardsdatascience.com</p></div></div><div class="oi l"><div class="pp l ok ol om oi on ks nz"/></div></div></a></div><p id="c807" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，请随时在 LinkedIn 与我联系:</p><div class="nw nx gp gr ny nz"><a href="https://www.linkedin.com/in/harr/" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd iu gy z fp oe fr fs of fu fw is bi translated">héctor ramírez-西班牙巴伦西亚地区|职业简介| LinkedIn</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">我最近获得了物理学博士学位，专攻实验数据分析和数学建模。我领导了…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">www.linkedin.com</p></div></div><div class="oi l"><div class="pq l ok ol om oi on ks nz"/></div></div></a></div><h1 id="f6c1" class="oo mv it bd na op oq or nd os ot ou ng jz ov ka nj kc ow kd nm kf ox kg np oy bi translated">参考</h1><p id="7db4" class="pw-post-body-paragraph kz la it lb b lc nr ju le lf ns jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">Datacamp 用 Python 分析社交媒体数据:</p><div class="nw nx gp gr ny nz"><a href="https://learn.datacamp.com/courses/analyzing-social-media-data-in-python" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd iu gy z fp oe fr fs of fu fw is bi translated">签到</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">登录 DataCamp 帐户</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">learn.datacamp.com</p></div></div><div class="oi l"><div class="pr l ok ol om oi on ks nz"/></div></div></a></div><div class="nw nx gp gr ny nz"><a rel="noopener follow" target="_blank" href="/my-first-twitter-app-1115a327349e"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd iu gy z fp oe fr fs of fu fw is bi translated">我的第一个 Twitter 应用</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">如何使用 Python 和 Tweepy 创建自己的数据集</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">towardsdatascience.com</p></div></div><div class="oi l"><div class="ps l ok ol om oi on ks nz"/></div></div></a></div><div class="nw nx gp gr ny nz"><a rel="noopener follow" target="_blank" href="/tweepy-for-beginners-24baf21f2c25"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd iu gy z fp oe fr fs of fu fw is bi translated">适合初学者的 Tweepy</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">使用 Twitter 的 API 建立你自己的数据集</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">towardsdatascience.com</p></div></div><div class="oi l"><div class="pt l ok ol om oi on ks nz"/></div></div></a></div><div class="nw nx gp gr ny nz"><a rel="noopener follow" target="_blank" href="/how-to-access-twitters-api-using-tweepy-5a13a206683b"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd iu gy z fp oe fr fs of fu fw is bi translated">如何使用 Tweepy 访问 Twitter 的 API</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">使用易于使用的 Python 库获得大型 Twitter 数据集的分步指南(包含代码和技巧)</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">towardsdatascience.com</p></div></div><div class="oi l"><div class="pu l ok ol om oi on ks nz"/></div></div></a></div><div class="nw nx gp gr ny nz"><a href="https://medium.com/@leowgriffin/scraping-tweets-with-tweepy-python-59413046e788" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd iu gy z fp oe fr fs of fu fw is bi translated">用 Tweepy Python 抓取推文</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">这是一个使用 Python 库 Tweepy 抓取 Twitter tweets 的逐步指南。</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="pv l ok ol om oi on ks nz"/></div></div></a></div></div></div>    
</body>
</html>