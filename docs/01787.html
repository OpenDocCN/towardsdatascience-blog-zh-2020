<html>
<head>
<title>API Crawls: Respecting Rate Limits</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">API爬网:遵守速率限制</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/api-crawls-respecting-rate-limits-30cc0f76ca98?source=collection_archive---------33-----------------------#2020-02-18">https://towardsdatascience.com/api-crawls-respecting-rate-limits-30cc0f76ca98?source=collection_archive---------33-----------------------#2020-02-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="1f7e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">这叫爬行是有原因的。</h2></div><p id="7f97" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">任何通过网络API公开信息的人都有可能对API客户端实施速率限制。这降低了<a class="ae lb" href="https://en.wikipedia.org/wiki/Denial-of-service_attack" rel="noopener ugc nofollow" target="_blank">拒绝服务攻击</a>的风险，帮助API提供商控制和预测他们的基础设施成本，并限制API故障的严重性。</p><p id="29e4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">爬行通常可以，跑步通常不行。怎么爬得快？</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lc"><img src="../Images/2738df412989da24f740d3ecf3c83b66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c7YDCzf09agmDq6HIeQzdw.jpeg"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">由<a class="ae lb" href="https://unsplash.com/@vidarnm?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">维达尔·诺德里-马西森</a>在<a class="ae lb" href="https://unsplash.com/s/photos/spider?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="822b" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">第一步:了解自己的极限</h1><p id="d900" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">一些API使得调用者很容易检查他们的速率限制。GitHub API是我最喜欢的例子。它<a class="ae lb" href="https://developer.github.com/v3/#rate-limiting" rel="noopener ugc nofollow" target="_blank">在响应报头</a>中返回速率限制信息，并提供一个<a class="ae lb" href="https://developer.github.com/v3/rate_limit/" rel="noopener ugc nofollow" target="_blank"> <em class="mp"> /rate_limit </em>端点</a>，该端点不计入调用者的速率限制。</p><p id="b752" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于其他API，您负责跟踪自己的使用情况。通读API文档，注意您将访问的端点上的速率限制。</p><p id="3f7f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，知道你将如何被处罚超过率限制。搜索谷歌太快会屏蔽超过24小时。太快抓取GitHub通常会锁定你最多一个小时。</p><h1 id="092f" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">第二步:预算</h1><p id="15b3" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">确定爬网中将涉及多少个进程，计算每个进程在爬网的单个步骤中将进行的速率受限API调用的数量，并确定每个进程的预算。</p><p id="2d10" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有几种方法可以强制执行预算:</p><ol class=""><li id="9b2b" class="mq mr iq kh b ki kj kl km ko ms ks mt kw mu la mv mw mx my bi translated">让你的爬虫知道速率限制。生成每个crawler进程，其速率限制与相对于其群组中其余crawler的爬行量成比例。当您可以在开始爬网之前轻松地将输入划分到各个爬网程序时，这种方法非常有效。</li><li id="20ff" class="mq mr iq kh b ki mz kl na ko nb ks nc kw nd la mv mw mx my bi translated">使用速率受限队列将作业提供给crawler进程。如果每个爬行器进程的输入都是在爬行过程中动态生成的，那么这样做效果很好。</li><li id="6914" class="mq mr iq kh b ki mz kl na ko nb ks nc kw nd la mv mw mx my bi translated">在出站代理中强制实施速率限制。像<em class="mp"> nginx </em>这样的代理提供了现成的功能。<a class="ae lb" href="https://www.monterail.com/blog/2011/outbound-api-rate-limits-the-nginx-way" rel="noopener ugc nofollow" target="_blank">下面是一个如何使用<em class="mp"> nginx </em>来限制API请求的例子。</a></li></ol><p id="e8eb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">无论你选择做什么，做一些算术，确保不超出你的预算。</p><h1 id="829a" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">第三步:当风险很高时，增加一个关闭开关</h1><p id="0d39" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">有时，超出速率限制的成本高得惊人。如果API在您的应用程序中提供了一个关键功能，或者如果它的定价在无法承受的上层，就会发生这种情况。如果是这种情况，实现一个kill switch，如果你太接近你的速率限制，它会关闭你所有的爬虫。</p><h1 id="beba" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">第四步:当风险很低时，慢慢后退</h1><p id="5958" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">如果超过API速率限制不是世界末日，你的爬虫应该简单地重试他们的API调用，增加尝试之间的时间间隔，直到达到一定的尝试次数。这种技术的名称是<em class="mp">后退重试</em>。补偿通常是指数的，这意味着每次失败的尝试，API调用之间的时间间隔都会被放大一个固定的倍数<em class="mp"> r &gt; 1 </em>。这篇AWS文章是一个很好的战略指南。</p><p id="b6a2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些是需要遵循的简单准则，遵循它们将使您轻松地将API抓取扩展到笔记本电脑之外。祝你好运，爬虫伙伴！</p><p id="0449" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mp"> Neeraj Kashyap(跟我上</em><a class="ae lb" href="https://twitter.com/zomglings" rel="noopener ugc nofollow" target="_blank"><em class="mp">Twitter</em></a><em class="mp">和上</em><a class="ae lb" href="https://github.com/nkashy1" rel="noopener ugc nofollow" target="_blank"><em class="mp">GitHub</em></a><em class="mp">)</em></p></div></div>    
</body>
</html>