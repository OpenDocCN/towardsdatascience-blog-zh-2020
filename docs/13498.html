<html>
<head>
<title>Machine Learning with Koalas and Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用考拉和火花进行机器学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/koalas-ml-4807f2c56e98?source=collection_archive---------20-----------------------#2020-09-16">https://towardsdatascience.com/koalas-ml-4807f2c56e98?source=collection_archive---------20-----------------------#2020-09-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="d071" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">实用指南</h2><div class=""/><div class=""><h2 id="db7d" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">有火花后端的熊猫</h2></div><p id="2edc" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi ln translated">andas 被认为是用 python 编写的事实上的数据分析库。大多数数据科学家或机器学习工程师在转到其他库之前都是从 Pandas 和 Numpy 开始的。没有一次可以围绕使用 Pandas 作为标准数据处理库展开辩论。使用 Pandas 有很多好处，但是 Pandas API 适应分布式处理的一个关键瓶颈是。像摩丁和达斯克这样的解决方案在一定程度上解决了这个问题。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/a516a75189393f5c9e14ea658e97d534.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*J1_7FeFoehrse5UyXmSTPw.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated">作者使用 Canva.com 的图片</p></figure><p id="b165" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">说到使用分布式处理框架，Spark 是专业人员和大型数据处理中心事实上的选择。最近，Databricks 的团队开源了一个名为<a class="ae mi" href="https://koalas.readthedocs.io/en/latest/?badge=latest" rel="noopener ugc nofollow" target="_blank">考拉</a>的库，用 spark 后端实现了熊猫 API。这个库正在积极开发中，覆盖了超过 60%的熊猫 API。要阅读更多关于使用考拉的内容，请参考我之前的文章<a class="ae mi" href="https://medium.com/analytics-vidhya/spark-ifying-pandas-databricks-koalas-with-google-colab-93028890db5" rel="noopener">激发熊猫的火花:数据布里克的考拉与谷歌实验室</a>。</p><p id="f2f5" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在本教程中，我将带领您使用 Koalas 和 PySpark 执行探索性数据分析，并使用 Spark 分布式框架构建回归模型。在处理大型数据集时，使用考拉而不是熊猫 API 有很多好处。一些关键点是</p><ol class=""><li id="73e7" class="mj mk it kt b ku kv kx ky la ml le mm li mn lm mo mp mq mr bi translated">大数据处理变得简单</li><li id="b665" class="mj mk it kt b ku ms kx mt la mu le mv li mw lm mo mp mq mr bi translated">从熊猫到考拉的快速转变</li><li id="1ab0" class="mj mk it kt b ku ms kx mt la mu le mv li mw lm mo mp mq mr bi translated">与 PySpark 无缝集成</li></ol><p id="6f85" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">本教程的目标是利用 Spark 后端，使用考拉完成一个完整的机器学习开发周期。工作中的谷歌合作实验室将被嵌入。</p><h1 id="fcfc" class="mx my it bd mz na nb nc nd ne nf ng nh ki ni kj nj kl nk km nl ko nm kp nn no bi translated">在 Google 联合实验室中设置 Spark 3.0.1</h1><p id="2358" class="pw-post-body-paragraph kr ks it kt b ku np kd kw kx nq kg kz la nr lc ld le ns lg lh li nt lk ll lm im bi translated">作为第一步，我用 spark 安装配置 google colab 运行时。详细内容，读者可以在 Google Colab  om medium 阅读我的文章<a class="ae mi" href="https://medium.com/analytics-vidhya/getting-started-spark3-0-0-with-google-colab-9796d350d78" rel="noopener">入门 Spark 3.0.0。</a></p><p id="dcce" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们将安装以下程序</p><ul class=""><li id="1463" class="mj mk it kt b ku kv kx ky la ml le mm li mn lm nu mp mq mr bi translated">Java 8</li><li id="b43a" class="mj mk it kt b ku ms kx mt la mu le mv li mw lm nu mp mq mr bi translated">火花-3.0.1</li><li id="e5fd" class="mj mk it kt b ku ms kx mt la mu le mv li mw lm nu mp mq mr bi translated">Hadoop3.2</li><li id="f3fa" class="mj mk it kt b ku ms kx mt la mu le mv li mw lm nu mp mq mr bi translated"><a class="ae mi" href="https://github.com/minrk/findspark" rel="noopener ugc nofollow" target="_blank"> Findspark </a></li></ul><p id="0def" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">您可以使用下面的命令集安装最新版本的 Spark。</p><pre class="lx ly lz ma gt nv nw nx ny aw nz bi"><span id="493e" class="oa my it nw b gy ob oc l od oe"># Run below commands<br/>!apt-get install openjdk-8-jdk-headless -qq &gt; /dev/null<br/>!wget -q http://apache.osuosl.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz<br/>!tar xf spark-3.0.1-bin-hadoop3.2.tgz<br/>!pip install -q findspark</span></pre><h2 id="b9cb" class="oa my it bd mz of og dn nd oh oi dp nh la oj ok nj le ol om nl li on oo nn iz bi translated">环境变量</h2><p id="e94c" class="pw-post-body-paragraph kr ks it kt b ku np kd kw kx nq kg kz la nr lc ld le ns lg lh li nt lk ll lm im bi translated">安装完 spark 和 Java 之后，设置安装 Spark 和 Java 的环境变量。</p><pre class="lx ly lz ma gt nv nw nx ny aw nz bi"><span id="74ce" class="oa my it nw b gy ob oc l od oe">import os<br/>os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"<br/>os.environ["SPARK_HOME"] = "/content/spark-3.0.1-bin-hadoop3.2"</span></pre><h2 id="c81d" class="oa my it bd mz of og dn nd oh oi dp nh la oj ok nj le ol om nl li on oo nn iz bi translated">火花安装试验</h2><p id="13f3" class="pw-post-body-paragraph kr ks it kt b ku np kd kw kx nq kg kz la nr lc ld le ns lg lh li nt lk ll lm im bi translated">让我们在 google colab 环境中测试 spark 的安装。</p><pre class="lx ly lz ma gt nv nw nx ny aw nz bi"><span id="7a07" class="oa my it nw b gy ob oc l od oe">import findspark<br/>findspark.init()<br/><br/>from pyspark.sql import SparkSession<br/><br/>spark = SparkSession.builder.master("local[*]").getOrCreate()<br/># Test the spark <br/>df = spark.createDataFrame([{"hello": "world"} for x in range(1000)])<br/><br/>df.show(3, False)</span><span id="e4e1" class="oa my it nw b gy op oc l od oe">/content/spark-3.0.1-bin-hadoop3.2/python/pyspark/sql/session.py:381: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead<br/>  warnings.warn("inferring schema from dict is deprecated,"<br/><br/><br/>+-----+<br/>|hello|<br/>+-----+<br/>|world|<br/>|world|<br/>|world|<br/>+-----+<br/>only showing top 3 rows</span></pre><h2 id="7280" class="oa my it bd mz of og dn nd oh oi dp nh la oj ok nj le ol om nl li on oo nn iz bi translated">安装考拉</h2><p id="c35a" class="pw-post-body-paragraph kr ks it kt b ku np kd kw kx nq kg kz la nr lc ld le ns lg lh li nt lk ll lm im bi translated">在安装 spark 并确保它正常工作后，我们现在可以使用 pip 安装 databrick 的考拉了。</p><pre class="lx ly lz ma gt nv nw nx ny aw nz bi"><span id="8d0e" class="oa my it nw b gy ob oc l od oe">! pip install koalas</span><span id="d4dd" class="oa my it nw b gy op oc l od oe">Requirement already satisfied: koalas in /usr/local/lib/python3.6/dist-packages (1.2.0)<br/>Requirement already satisfied: numpy&lt;1.19.0,&gt;=1.14 in /usr/local/lib/python3.6/dist-packages (from koalas) (1.18.5)<br/>Requirement already satisfied: matplotlib&lt;3.3.0,&gt;=3.0.0 in /usr/local/lib/python3.6/dist-packages (from koalas) (3.2.2)<br/>Requirement already satisfied: pyarrow&gt;=0.10 in /usr/local/lib/python3.6/dist-packages (from koalas) (0.14.1)<br/>Requirement already satisfied: pandas&lt;1.1.0,&gt;=0.23.2 in /usr/local/lib/python3.6/dist-packages (from koalas) (1.0.5)<br/>Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib&lt;3.3.0,&gt;=3.0.0-&gt;koalas) (2.4.7)<br/>Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib&lt;3.3.0,&gt;=3.0.0-&gt;koalas) (0.10.0)<br/>Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib&lt;3.3.0,&gt;=3.0.0-&gt;koalas) (1.2.0)<br/>Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib&lt;3.3.0,&gt;=3.0.0-&gt;koalas) (2.8.1)<br/>Requirement already satisfied: six&gt;=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pyarrow&gt;=0.10-&gt;koalas) (1.15.0)<br/>Requirement already satisfied: pytz&gt;=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas&lt;1.1.0,&gt;=0.23.2-&gt;koalas) (2018.9)<br/>Requirement already satisfied: pyarrow in /usr/local/lib/python3.6/dist-packages (0.14.1)<br/>Requirement already satisfied: numpy&gt;=1.14 in /usr/local/lib/python3.6/dist-packages (from pyarrow) (1.18.5)<br/>Requirement already satisfied: six&gt;=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pyarrow) (1.15.0)</span><span id="eee3" class="oa my it nw b gy op oc l od oe"># Install compatible version of pyarrow<br/>! pip install pyarrow</span><span id="bf61" class="oa my it nw b gy op oc l od oe">import seaborn as sns</span><span id="262c" class="oa my it nw b gy op oc l od oe">/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.<br/>  import pandas.util.testing as tm</span><span id="3006" class="oa my it nw b gy op oc l od oe">import databricks.koalas as ks</span></pre><h1 id="a52b" class="mx my it bd mz na nb nc nd ne nf ng nh ki ni kj nj kl nk km nl ko nm kp nn no bi translated">机器学习开发周期</h1><p id="e759" class="pw-post-body-paragraph kr ks it kt b ku np kd kw kx nq kg kz la nr lc ld le ns lg lh li nt lk ll lm im bi translated">开发机器学习模型的标准做法是执行探索性数据分析，执行特征工程，并建立模型。我将试着用考拉来接触上述观点的基础。我相信大多数 ML 工程师/科学家都使用 Pandas API 来执行 EDA 和特征工程。我演示了如何使用考拉来完成这项工作，并使用 PySpark 来构建模型。</p><p id="242e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我将使用<a class="ae mi" href="https://archive.ics.uci.edu/ml/datasets/combined+cycle+power+plant" rel="noopener ugc nofollow" target="_blank">联合循环发电厂</a>数据集来预测每小时净电力输出(EP)。我已经把数据上传到我的 GitHub 上，这样用户就可以重现结果了。</p><h2 id="da1b" class="oa my it bd mz of og dn nd oh oi dp nh la oj ok nj le ol om nl li on oo nn iz bi translated">使用考拉进行探索性数据分析</h2><p id="3b28" class="pw-post-body-paragraph kr ks it kt b ku np kd kw kx nq kg kz la nr lc ld le ns lg lh li nt lk ll lm im bi translated">作为第一步，我想使用考拉 API 探索给定的数据、它的分布和依赖性。我将包括一个简单的例子来演示这个想法，用户可以针对手头的问题扩展它。</p><p id="d045" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">下载数据并保存在本地</p><pre class="lx ly lz ma gt nv nw nx ny aw nz bi"><span id="ee41" class="oa my it nw b gy ob oc l od oe"># Downloading the clustering dataset<br/>!wget -q 'https://raw.githubusercontent.com/amjadraza/blogs-data/master/spark_ml/ccpp.csv'</span></pre><p id="c4de" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">使用考拉<code class="fe oq or os nw b">read_csv</code>方法读取数据。要阅读更多关于 API 的内容，请关注<a class="ae mi" href="https://koalas.readthedocs.io/en/latest/?badge=latest" rel="noopener ugc nofollow" target="_blank">考拉官方文档</a></p><pre class="lx ly lz ma gt nv nw nx ny aw nz bi"><span id="6f94" class="oa my it nw b gy ob oc l od oe"># Read the iris data<br/>kdf_ccpp = ks.read_csv("ccpp.csv")</span><span id="955e" class="oa my it nw b gy op oc l od oe">kdf_ccpp.columns</span><span id="98d8" class="oa my it nw b gy op oc l od oe">Index(['AT', 'V', 'AP', 'RH', 'PE'], dtype='object')</span><span id="288d" class="oa my it nw b gy op oc l od oe">kdf_ccpp.head()</span></pre><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="ab gu cl ot"><img src="../Images/ba257500ad0b7b68a9a6db5857db703b.png" data-original-src="https://miro.medium.com/v2/format:webp/1*WZWY_O3oA2jmCiVBwng24Q.png"/></div></figure><p id="b22f" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">就像熊猫一样，考拉也有绘制数据以理解变量的功能。在下面的例子中，我绘制了原始数据和它的平滑版本。这个例子演示了<code class="fe oq or os nw b">plot</code>和<code class="fe oq or os nw b">rolling</code>窗口方法的使用</p><pre class="lx ly lz ma gt nv nw nx ny aw nz bi"><span id="739a" class="oa my it nw b gy ob oc l od oe">kdf_ccpp['AT'].plot(figsize=(12,6))<br/>kdf_ccpp['AT'].rolling(window=20).mean().plot()<br/>kdf_ccpp['AT'].rolling(window=200).mean().plot()</span><span id="71ac" class="oa my it nw b gy op oc l od oe">&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f9992f63320&gt;</span></pre><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="ab gu cl ot"><img src="../Images/4d66e2f23f924815439842671fce4cbc.png" data-original-src="https://miro.medium.com/v2/format:webp/1*4mNwPElpnuh3UjJcjEfSiQ.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated">作者图片:更平滑版本的 AT 特性图</p></figure><p id="6dce" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">就像上面的绘图一样，用户可以绘制所有的列。参见下面的命令</p><pre class="lx ly lz ma gt nv nw nx ny aw nz bi"><span id="7bd3" class="oa my it nw b gy ob oc l od oe">kdf_ccpp.plot(figsize=(12,6))</span><span id="acc3" class="oa my it nw b gy op oc l od oe">&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f9993b7e668&gt;</span></pre><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="ab gu cl ot"><img src="../Images/9cf6f2712c00c2d000715bbb847ba670.png" data-original-src="https://miro.medium.com/v2/format:webp/1*VytR2NFcPShwB53HbEx6kw.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated">作者图像:原始数据图</p></figure><p id="88d4" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">使用 20 个数据点的移动平均值绘制所有列。</p><pre class="lx ly lz ma gt nv nw nx ny aw nz bi"><span id="bb3a" class="oa my it nw b gy ob oc l od oe">kdf_ccpp.rolling(window=20).mean().plot(figsize=(12,6))</span><span id="9a50" class="oa my it nw b gy op oc l od oe">&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f99939bd358&gt;</span></pre><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="ab gu cl ot"><img src="../Images/85c08370c3dc0a8de74e68069d3d9236.png" data-original-src="https://miro.medium.com/v2/format:webp/1*1onFBo40v0EG6JnkRp9dxg.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated">作者图片:平滑数据图</p></figure><p id="8658" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">下面的命令演示了<code class="fe oq or os nw b">describe</code>的使用，这是一种类似于 Pandas API 中的方法。</p><pre class="lx ly lz ma gt nv nw nx ny aw nz bi"><span id="49e4" class="oa my it nw b gy ob oc l od oe">kdf_ccpp.describe()</span></pre><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="ab gu cl ot"><img src="../Images/e1e2c4f1d7b558c502b3e3bffce979da.png" data-original-src="https://miro.medium.com/v2/format:webp/1*x-GsBrx5kNOfiauF_wYqdA.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated">作者图片</p></figure><h2 id="fb19" class="oa my it bd mz of og dn nd oh oi dp nh la oj ok nj le ol om nl li on oo nn iz bi translated">特征工程</h2><p id="4c63" class="pw-post-body-paragraph kr ks it kt b ku np kd kw kx nq kg kz la nr lc ld le ns lg lh li nt lk ll lm im bi translated">特征工程步骤通常与 EDA 结合在一起。用户准备特性的目的是获得最具预测性和分布良好的特性集。在本文中，我将演示如何使用考拉来执行特征工程。</p><p id="98bc" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">为了理解不同变量之间的关系，<code class="fe oq or os nw b">paiprplot</code>函数<code class="fe oq or os nw b">seaborn</code>被广泛使用。使用 below 命令绘制数据集中变量的 pairplot。由于 Seaborn 不支持考拉数据帧，用户必须在调用 pairplot 之前将其转换为熊猫数据帧。</p><pre class="lx ly lz ma gt nv nw nx ny aw nz bi"><span id="7e5d" class="oa my it nw b gy ob oc l od oe">sns.pairplot(kdf_ccpp.to_pandas())</span><span id="ff74" class="oa my it nw b gy op oc l od oe">&lt;seaborn.axisgrid.PairGrid at 0x7f99989459e8&gt;</span></pre><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="ab gu cl ot"><img src="../Images/09ef89dfc76b8ebc339c0e9af0e8b7e5.png" data-original-src="https://miro.medium.com/v2/format:webp/1*kz3aDWgFK98NZ77BLr754Q.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated">作者提供的图片:原始要素和目标的配对图</p></figure><p id="ff0a" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">通过查看上图，我们可以看到很多离群值，对于一些变量与目标的关系并不清楚。为了去除异常值，最简单的解决方案是计算移动平均值，我用考拉来演示。</p><pre class="lx ly lz ma gt nv nw nx ny aw nz bi"><span id="0b52" class="oa my it nw b gy ob oc l od oe">sns.pairplot(kdf_ccpp.rolling(window=20).mean().to_pandas())</span><span id="6ab7" class="oa my it nw b gy op oc l od oe">&lt;seaborn.axisgrid.PairGrid at 0x7f9993a5ada0&gt;</span></pre><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="ab gu cl ot"><img src="../Images/e7b6b8297b37e5a740878b6bfe1f3176.png" data-original-src="https://miro.medium.com/v2/format:webp/1*Ac1jkePCTAVcXdFWQ1MLbQ.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated">作者提供的图像:平滑特征和目标的配对图</p></figure><p id="37c2" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">看起来 20 天移动平均线与目标变量有更好的关系，因此使用 20 天平均线更有意义。</p><h2 id="ef32" class="oa my it bd mz of og dn nd oh oi dp nh la oj ok nj le ol om nl li on oo nn iz bi translated">使用 PySpark 建模</h2><p id="65e2" class="pw-post-body-paragraph kr ks it kt b ku np kd kw kx nq kg kz la nr lc ld le ns lg lh li nt lk ll lm im bi translated">一旦 EDA 和特性工程完成，就该建立预测模型了。使用考拉数据框架的好处之一是用户可以无缝地创建 Spark 数据框架。在下一节中，我将演示如何使用 PySpark API 来构建和训练梯度推进机器(GBM)。</p><pre class="lx ly lz ma gt nv nw nx ny aw nz bi"><span id="9856" class="oa my it nw b gy ob oc l od oe"># Create the moving average features<br/>kdf = kdf_ccpp.rolling(window=20, min_periods=1).mean()</span><span id="ffb6" class="oa my it nw b gy op oc l od oe"># Convert the Koalas DataFrame into Spark DataFrame<br/>sdf = kdf.to_spark()</span><span id="e04b" class="oa my it nw b gy op oc l od oe">sdf.show(5,False)</span><span id="4799" class="oa my it nw b gy op oc l od oe">+------------------+------+------------------+-----------------+-----------------+<br/>|AT                |V     |AP                |RH               |PE               |<br/>+------------------+------+------------------+-----------------+-----------------+<br/>|14.96             |41.76 |1024.07           |73.17            |463.26           |<br/>|20.07             |52.36 |1022.055          |66.125           |453.815          |<br/>|15.083333333333334|48.04 |1018.7566666666667|74.79666666666667|465.3966666666667|<br/>|16.5275           |50.36 |1016.6275         |75.2575          |460.6675         |<br/>|15.386000000000001|47.788|1015.1479999999999|79.53            |463.314          |<br/>+------------------+------+------------------+-----------------+-----------------+<br/>only showing top 5 rows</span></pre><p id="8884" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">现在，使用 PySpark API 构建模型。关于使用 PySpark 构建模型的更多细节，请参考我的文章<a class="ae mi" rel="noopener" target="_blank" href="/machine-learning-with-spark-f1dbc1363986">使用 Spark 进行机器学习</a>。</p><pre class="lx ly lz ma gt nv nw nx ny aw nz bi"><span id="41d7" class="oa my it nw b gy ob oc l od oe">from pyspark.ml.regression import LinearRegression<br/>from pyspark.ml.feature import VectorAssembler<br/>from pyspark.ml.evaluation import RegressionEvaluator<br/>from pyspark.ml.regression import GBTRegressor</span></pre><p id="d295" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">准备与 PySpark 型号兼容的功能</p><pre class="lx ly lz ma gt nv nw nx ny aw nz bi"><span id="71da" class="oa my it nw b gy ob oc l od oe"># Create the feature column using VectorAssembler class<br/>vectorAssembler = VectorAssembler(inputCols =["AT", "V", "AP", "RH"], outputCol = "features")<br/>vpp_sdf = vectorAssembler.transform(sdf)</span><span id="047d" class="oa my it nw b gy op oc l od oe">vpp_sdf.show(2, False)</span><span id="ecf5" class="oa my it nw b gy op oc l od oe">+-----+-----+--------+------+-------+-----------------------------+<br/>|AT   |V    |AP      |RH    |PE     |features                     |<br/>+-----+-----+--------+------+-------+-----------------------------+<br/>|14.96|41.76|1024.07 |73.17 |463.26 |[14.96,41.76,1024.07,73.17]  |<br/>|20.07|52.36|1022.055|66.125|453.815|[20.07,52.36,1022.055,66.125]|<br/>+-----+-----+--------+------+-------+-----------------------------+<br/>only showing top 2 rows</span></pre><p id="8030" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">创建 tarin 并测试拆分</p><pre class="lx ly lz ma gt nv nw nx ny aw nz bi"><span id="149b" class="oa my it nw b gy ob oc l od oe"># Define train and test data split<br/>splits = vpp_sdf.randomSplit([0.7,0.3])<br/>train_df = splits[0]<br/>test_df = splits[1]</span></pre><p id="3341" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">建立和训练模型</p><pre class="lx ly lz ma gt nv nw nx ny aw nz bi"><span id="fc8f" class="oa my it nw b gy ob oc l od oe"># Define the GBT Model<br/>gbt = GBTRegressor(featuresCol="features", labelCol="PE")<br/>gbt_model = gbt.fit(train_df)<br/>gbt_predictions = gbt_model.transform(test_df)</span></pre><p id="a829" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">评估模型准确性</p><pre class="lx ly lz ma gt nv nw nx ny aw nz bi"><span id="e1dc" class="oa my it nw b gy ob oc l od oe"># Evaluate the GBT Model<br/>gbt_evaluator = RegressionEvaluator(labelCol="PE", predictionCol="prediction", metricName="rmse")<br/>gbt_rmse = gbt_evaluator.evaluate(gbt_predictions)<br/>print("The RMSE of GBT Tree regression Model is {}".format(gbt_rmse))</span><span id="7b3f" class="oa my it nw b gy op oc l od oe">The RMSE of GBT Tree regression Model is 1.077464978110743</span></pre><p id="5401" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">将预测转换回考拉数据框架</p><pre class="lx ly lz ma gt nv nw nx ny aw nz bi"><span id="5243" class="oa my it nw b gy ob oc l od oe">kdf_predictions = ks.DataFrame(gbt_predictions)</span><span id="613c" class="oa my it nw b gy op oc l od oe">kdf_predictions.head()</span></pre><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="ab gu cl ot"><img src="../Images/fa4760889f2b41b9192747480a453580.png" data-original-src="https://miro.medium.com/v2/format:webp/1*xJYLG_isv4k_HbLSreoTng.png"/></div></figure><p id="f5ba" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">让我们从模型中画出实际值和预测值。</p><pre class="lx ly lz ma gt nv nw nx ny aw nz bi"><span id="24ec" class="oa my it nw b gy ob oc l od oe">kdf_predictions[['PE', 'prediction']].plot(figsize=(12,8))</span><span id="d659" class="oa my it nw b gy op oc l od oe">&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f9992ba4828&gt;<!-- --> </span></pre><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="ab gu cl ot"><img src="../Images/678828a5410462290bb015aafa46c351.png" data-original-src="https://miro.medium.com/v2/format:webp/1*1PpOkWS25x6-gWvsTnp0Ww.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated">作者图片:实际 PE 与预测 PE 图</p></figure><h1 id="40f8" class="mx my it bd mz na nb nc nd ne nf ng nh ki ni kj nj kl nk km nl ko nm kp nn no bi translated">一个有效的 Google Colab</h1><p id="ccf7" class="pw-post-body-paragraph kr ks it kt b ku np kd kw kx nq kg kz la nr lc ld le ns lg lh li nt lk ll lm im bi translated">下面是工作谷歌 colab 笔记本重新创建教程。试试看，在可能的情况下，在目前用考拉代替熊猫的基础上开发机器学习算法。</p><figure class="lx ly lz ma gt mb"><div class="bz fp l di"><div class="ou ov l"/></div></figure><h1 id="d5f0" class="mx my it bd mz na nb nc nd ne nf ng nh ki ni kj nj kl nk km nl ko nm kp nn no bi translated">结论</h1><p id="03b5" class="pw-post-body-paragraph kr ks it kt b ku np kd kw kx nq kg kz la nr lc ld le ns lg lh li nt lk ll lm im bi translated">在本教程中，我演示了使用考拉来执行探索性数据分析和特征工程。对于熊猫用户来说，使用 Spark 后端进行分布式计算的好处是，切换到考拉是直接的。在讨论的要点下面</p><ul class=""><li id="5505" class="mj mk it kt b ku kv kx ky la ml le mm li mn lm nu mp mq mr bi translated">考拉过去常常表演 EDA</li><li id="38ff" class="mj mk it kt b ku ms kx mt la mu le mv li mw lm nu mp mq mr bi translated">使用考拉的特征工程</li><li id="aec7" class="mj mk it kt b ku ms kx mt la mu le mv li mw lm nu mp mq mr bi translated">PySpark 与考拉的整合</li></ul><h1 id="4a16" class="mx my it bd mz na nb nc nd ne nf ng nh ki ni kj nj kl nk km nl ko nm kp nn no bi translated">参考资料/阅读/链接</h1><ol class=""><li id="2d58" class="mj mk it kt b ku np kx nq la ow le ox li oy lm mo mp mq mr bi translated">【https://spark.apache.org/docs/latest/ml-features.html T2】号</li><li id="e457" class="mj mk it kt b ku ms kx mt la mu le mv li mw lm mo mp mq mr bi translated">【https://koalas.readthedocs.io/en/latest/?badge=latest T4】</li><li id="76b8" class="mj mk it kt b ku ms kx mt la mu le mv li mw lm mo mp mq mr bi translated"><a class="ae mi" rel="noopener" target="_blank" href="/machine-learning-with-spark-f1dbc1363986">https://towards data science . com/machine-learning-with-spark-f1dbc 1363986</a></li><li id="4c37" class="mj mk it kt b ku ms kx mt la mu le mv li mw lm mo mp mq mr bi translated"><a class="ae mi" href="https://medium.com/analytics-vidhya/getting-started-spark3-0-0-with-google-colab-9796d350d78" rel="noopener">https://medium . com/analytics-vid hya/getting-started-spark 3-0-0-with-Google-colab-9796d 350d 78</a></li><li id="de19" class="mj mk it kt b ku ms kx mt la mu le mv li mw lm mo mp mq mr bi translated"><a class="ae mi" href="https://medium.com/analytics-vidhya/spark-ifying-pandas-databricks-koalas-with-google-colab-93028890db5" rel="noopener">https://medium . com/analytics-vid hya/spark-ifying-pandas-data bricks-koala-with-Google-colab-93028890 db5</a></li></ol></div></div>    
</body>
</html>