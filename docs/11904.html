<html>
<head>
<title>Trading Sentiment: NLP &amp; Sentiment Scoring the Spot Copper Market</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">交易情绪:NLP 和情绪给现货铜市场打分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/spot-vs-sentiment-nlp-sentiment-scoring-in-the-spot-copper-market-492456b031b0?source=collection_archive---------48-----------------------#2020-08-17">https://towardsdatascience.com/spot-vs-sentiment-nlp-sentiment-scoring-in-the-spot-copper-market-492456b031b0?source=collection_archive---------48-----------------------#2020-08-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a814" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">NLTK、Gensim 和 VADER 在金融出版物推文中搜索 Alpha</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/9f0b3ef59627aacd9a09843537840ac8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YkGWZo6LTQslvB4Gz0FfHQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">每日复合情绪得分与铜现货价格，美元/盎司。</p></figure><p id="37df" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> <em class="lr">注来自《走向数据科学》的编辑:</em> </strong> <em class="lr">虽然我们允许独立作者根据我们的</em> <a class="ae ls" rel="noopener" target="_blank" href="/questions-96667b06af5"> <em class="lr">规则和指导方针</em> </a> <em class="lr">发表文章，但我们不认可每个作者的贡献。你不应该在没有寻求专业建议的情况下依赖一个作者的作品。详见我们的</em> <a class="ae ls" rel="noopener" target="_blank" href="/readers-terms-b5d780a700a4"> <em class="lr">读者术语</em> </a> <em class="lr">。</em></p><h1 id="a478" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">介绍</h1><p id="fe61" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi mq translated">继铁和铝之后，铜是世界消耗最多的金属之一。铜是一种用途极其广泛的金属，其导电性和导热性、抗菌性和耐腐蚀性使其广泛应用于大多数经济部门。从电力基础设施、住宅和工厂到电子产品和医疗设备，全球经济对铜的依赖程度如此之深，以至于有时被称为“<a class="ae ls" href="https://www.investopedia.com/terms/d/doctor-copper.asp" rel="noopener ugc nofollow" target="_blank">铜博士</a>”，市场和大宗商品分析师也经常这样称呼铜，因为这种金属能够评估全球经济健康状况和活动。</p><p id="ddbf" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">从交易的角度来看，铜的定价是由金属交易所的供需动态决定的，特别是伦敦金属交易所(LME)和芝加哥商品交易所。然而，铜的交易价格受到无数因素的影响，其中许多因素很难同时衡量:</p><ul class=""><li id="2485" class="mz na iq kx b ky kz lb lc le nb li nc lm nd lq ne nf ng nh bi translated">全球经济增长(GDP)</li><li id="b095" class="mz na iq kx b ky ni lb nj le nk li nl lm nm lq ne nf ng nh bi translated">新兴市场经济体</li><li id="aca8" class="mz na iq kx b ky ni lb nj le nk li nl lm nm lq ne nf ng nh bi translated">中国经济(<a class="ae ls" href="https://asia.nikkei.com/Business/Markets/Commodities/Dr.-Copper-misdiagnoses-the-global-economy" rel="noopener ugc nofollow" target="_blank">中国占全球铜需求的一半</a></li><li id="2312" class="mz na iq kx b ky ni lb nj le nk li nl lm nm lq ne nf ng nh bi translated">铜矿生产国的政治和环境不稳定</li><li id="9223" class="mz na iq kx b ky ni lb nj le nk li nl lm nm lq ne nf ng nh bi translated">美国房地产市场</li><li id="b29c" class="mz na iq kx b ky ni lb nj le nk li nl lm nm lq ne nf ng nh bi translated">贸易制裁和关税</li><li id="a0c6" class="mz na iq kx b ky ni lb nj le nk li nl lm nm lq ne nf ng nh bi translated">很多很多其他人。</li></ul><p id="ac07" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">除了上述基本面因素，铜价还可能受到对冲基金、投资机构、<a class="ae ls" href="https://agmetalminer.com/2014/06/11/what-chinas-shadow-financing-market-aluminum-copper-collateral-means-for-metals-markets/" rel="noopener ugc nofollow" target="_blank">保税金属</a>，甚至国内交易的人为影响。从系统交易的角度来看，当我们想要开发一个预测模型时，这是一个非常具有挑战性的情况。</p><p id="e116" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然而，就以<strong class="kx ir">新闻</strong>形式公布的事件而言，短期机会可能存在。在整个美中贸易战期间，铜的现货和远期价格一直受到<a class="ae ls" href="https://www.kitco.com/news/2020-07-15/METALS-Copper-slips-on-profit-taking-triggered-by-U-S-China-tensions.html" rel="noopener ugc nofollow" target="_blank">的冲击，并且像所有市场一样，对重大消息几乎立即做出反应。</a></p><p id="03f4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果发现得足够早，基于 NLP 的系统交易模型可以通过将公告解析为令牌向量，评估潜在情绪，并随后在预期的(如果适用)价格变动之前建仓，或者在价格变动期间建仓，以期利用潜在的修正来利用这些短期价格变动。</p><h1 id="79c9" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">问题</h1><p id="cc84" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">在本文中，我们将从各种金融新闻出版物 Twitter feeds 中抓取历史(和当前)推文。然后，我们将分析这些数据，以了解每条推文背后的潜在情绪，得出情绪得分，并考察这一得分与过去五年铜现货价格之间的相关性。</p><p id="0156" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将涵盖:</p><ol class=""><li id="3341" class="mz na iq kx b ky kz lb lc le nb li nc lm nd lq nn nf ng nh bi translated"><strong class="kx ir">如何用<a class="ae ls" href="https://pypi.org/project/GetOldTweets3/" rel="noopener ugc nofollow" target="_blank"> GetOldTweets3 </a>获取历史推文</strong>。</li><li id="443e" class="mz na iq kx b ky ni lb nj le nk li nl lm nm lq nn nf ng nh bi translated"><strong class="kx ir">基本探索性数据分析</strong> (EDA)技术与我们的 Twitter 数据。</li><li id="09b8" class="mz na iq kx b ky ni lb nj le nk li nl lm nm lq nn nf ng nh bi translated"><strong class="kx ir">文本数据预处理技术</strong>(停用词、标记化、n 元语法、词干化&amp;词条化等)。</li><li id="1247" class="mz na iq kx b ky ni lb nj le nk li nl lm nm lq nn nf ng nh bi translated"><a class="ae ls" href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ir">潜在狄利克雷分配</strong> </a>到模型&amp;使用<a class="ae ls" href="https://pypi.org/project/gensim/" rel="noopener ugc nofollow" target="_blank">GenSim</a>&amp;<a class="ae ls" href="https://pypi.org/project/pyLDAvis/" rel="noopener ugc nofollow" target="_blank">NLTK pyl Davis 探索主题和内容在我们的 Twitter 数据中的分布。</a></li><li id="2a0a" class="mz na iq kx b ky ni lb nj le nk li nl lm nm lq nn nf ng nh bi translated"><strong class="kx ir">情感评分</strong>使用<a class="ae ls" href="https://www.nltk.org/_modules/nltk/sentiment/vader.html" rel="noopener ugc nofollow" target="_blank"> NLTK 价觉词典和<strong class="kx ir">情感</strong>推理机(VADER)。</a></li></ol><p id="02cc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们不会在这项工作的基础上开发和测试一个成熟的交易策略，其语义超出了本文的范围。此外，本文旨在展示数据科学家可以用来从文本数据中提取有用信号的各种技术。</p><h1 id="744d" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">现货铜 NLP 策略模型</h1><p id="c413" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">让我们从获取数据开始。</p><h2 id="c8b7" class="no lu iq bd lv np nq dn lz nr ns dp md le nt nu mf li nv nw mh lm nx ny mj nz bi translated">现货价格数据</h2><p id="ccd5" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">我们将从获取现货铜价数据开始。我们选择使用铜的现货价格，而不是铜的远期合约(以今天商定的价格在商定的固定未来日期买卖固定数量金属的协议)的原因是现货价格对市场事件最具反应性——它是立即完成商品交易的报价(T2)。通常，我们会使用彭博终端来获取这些数据，但是，我们可以从<a class="ae ls" href="https://markets.businessinsider.com/commodities/copper-price" rel="noopener ugc nofollow" target="_blank">商业内幕</a>免费获得历史现货铜数据:</p><pre class="kg kh ki kj gt oa ob oc od aw oe bi"><span id="5c38" class="no lu iq ob b gy of og l oh oi"># Imports<br/>import glob<br/>import GetOldTweets3 as got<br/>import gensim as gs<br/>import os<br/>import keras<br/>import matplotlib.pyplot as plt<br/>import numpy as np<br/>import nltk<br/>import pandas as pd<br/>import pyLDAvis.gensim<br/>import re<br/>import seaborn as sns</span><span id="556f" class="no lu iq ob b gy oj og l oh oi">from keras.preprocessing.text import Tokenizer<br/>from nltk.stem import *<br/>from nltk.util import ngrams<br/>from nltk.corpus import stopwords<br/>from nltk.tokenize import TweetTokenizer<br/>from nltk.sentiment.vader import SentimentIntensityAnalyzer<br/>from sklearn.feature_extraction.text import CountVectorizer<br/>from tensorflow.keras.preprocessing.sequence import pad_sequences</span><span id="40e1" class="no lu iq ob b gy oj og l oh oi"># Get Cu Spot<br/>prices_df = pd.read_csv(<br/>    '/content/Copper_120115_073120',<br/>    parse_dates=True,<br/>    index_col='Date'<br/>)<br/># To lower case<br/>cu_df.columns = cu_df.columns.str.lower()</span><span id="a893" class="no lu iq ob b gy oj og l oh oi">#Plt close price<br/>cu_df['close'].plot(figsize=(16,4))<br/>plt.ylabel('Spot, $/Oz')<br/>plt.title('Cu Spot Close Price, $/Oz')<br/>plt.legend()<br/>plt.grid()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ok"><img src="../Images/e71a32845acff7c6891e3f865da08511.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hNdODLUUSKGd8kcMli62sQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">现货铜，收盘价，2015 年 1 月 1 日至 2020 年 7 月 1 日，美元/公吨</p></figure><p id="8fd5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">虽然我们的价格数据看起来不错，但需要注意的是，我们正在考虑<strong class="kx ir">每日价格</strong>数据。因此，我们将自己限制在一个可能会丢失信息的时间范围内——市场对新闻事件的任何反应都可能在几分钟内发生，很可能是在新闻发布后的<em class="lr">秒</em>内。理想情况下，我们会使用 1-5 分钟的棒线，但是对于本文的目的来说，这样就可以了。</p><h2 id="f283" class="no lu iq bd lv np nq dn lz nr ns dp md le nt nu mf li nv nw mh lm nx ny mj nz bi translated">推特数据</h2><p id="93d9" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">我们将使用一个名为<a class="ae ls" href="https://pypi.org/project/GetOldTweets3/" rel="noopener ugc nofollow" target="_blank"><strong class="kx ir">getoldtweets 3</strong></a><strong class="kx ir">(GOT)的库来提取我们的历史 tweet 数据。</strong>与官方的<a class="ae ls" href="https://developer.twitter.com/en/docs" rel="noopener ugc nofollow" target="_blank"> Twitter API </a>不同，GOT3 允许用户访问 Twitter 数据的大量历史记录。给定一个属于金融新闻媒体的 Twitter 句柄列表和一些相关的关键字，我们可以定义我们想要获取数据的搜索参数(<strong class="kx ir">注意:</strong>出于格式原因，我在下面发布了执行此操作所需逻辑的截图，而不是代码片段):</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ol"><img src="../Images/b532166284449c06131479af9c931b8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j1OMA8ZNQ7mkKAc4BhUndw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">使用搜索参数获取指定句柄的历史 twitter 数据</p></figure><p id="4c9d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">方法<code class="fe om on oo ob b">.setQuerySearch()</code>接受单个搜索查询，因此我们无法根据多个搜索标准提取 tweets。我们可以使用循环很容易地解决这个限制。例如，可以简单地为一个唯一查询的每次执行分配变量名，即“现货铜”、“铜价”等，但是对于本文的目的，我们可以满足于单个查询:</p><pre class="kg kh ki kj gt oa ob oc od aw oe bi"><span id="b50a" class="no lu iq ob b gy of og l oh oi"># Define handles<br/>commodity_sources = ['reuters','wsj','financialtimes', 'bloomberg']</span><span id="791c" class="no lu iq ob b gy oj og l oh oi"># Query <br/>search_terms = 'spot copper'</span><span id="eab6" class="no lu iq ob b gy oj og l oh oi"># Get twitter data<br/>tweets_df = get_tweets(<br/>  commodity_sources,<br/>  search_term = search_terms,<br/>  top_only = False,<br/>  start_date = '2015-01-01',<br/>  end_date = '2020-01-01'<br/>).sort_values('date', ascending=False).set_index('date')</span><span id="4da0" class="no lu iq ob b gy oj og l oh oi">tweets_df.head(10)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi op"><img src="../Images/c2651ecc03ce774598f2ca34472f0b78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VT7qPNPSiJmP3HTjSRxhgw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Twitter 历史数据</p></figure><p id="6fc6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">到目前为止一切顺利。</p><p id="8d8a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们现在需要处理这些文本数据，以使其能够为我们的主题和情感模型所解释。</p><h2 id="a548" class="no lu iq bd lv np nq dn lz nr ns dp md le nt nu mf li nv nw mh lm nx ny mj nz bi translated">预处理和探索性数据分析</h2><p id="95c3" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">自然语言应用程序的文本数据预处理需要仔细考虑。从丢失的角度来看，从文本数据组成一个数字向量可能是具有挑战性的，当执行看似基本的任务时，如删除停用词，有价值的信息和主题上下文很容易丢失，我们将在下面看到。</p><p id="a3ec" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">首先，让我们删除标签和 URL 形式的冗余信息，即</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oq"><img src="../Images/566d6120fcf3d9658d5c7d6f148aa133.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zlb-OdXMABqi6fcPcyOPAw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来自媒体的推文通常包含句柄标签、标签和文章链接，所有这些都需要删除。</p></figure><p id="b4c8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们定义了几个单行的<a class="ae ls" href="https://docs.python.org/3/tutorial/controlflow.html" rel="noopener ugc nofollow" target="_blank"><strong class="kx ir"/></a>函数，这些函数使用<a class="ae ls" href="https://docs.python.org/2/library/re.html" rel="noopener ugc nofollow" target="_blank">正则表达式</a>来删除匹配我们想要删除的表达式的字母和字符:</p><pre class="kg kh ki kj gt oa ob oc od aw oe bi"><span id="3650" class="no lu iq ob b gy of og l oh oi">#@title Strip chars &amp; urls<br/>remove_handles = lambda x: re.sub(‘@[^\s]+’,’’, x)<br/>remove_urls = lambda x: re.sub(‘http[^\s]+’,’’, x)<br/>remove_hashtags = lambda x: re.sub('#[^\s]*','',x)</span><span id="01c7" class="no lu iq ob b gy oj og l oh oi">tweets_df[‘text’] = tweets_df[‘text’].apply(remove_handles)<br/>tweets_df[‘text’] = tweets_df[‘text’].apply(remove_urls)<br/>tweets_df[‘text’] = tweets_df[‘text’].apply(remove_hashtags)</span></pre><p id="52aa" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">接下来，我们通过检查 tweet 的组成对我们的 twitter 数据进行一些基本分析，例如单个 tweet 的长度(每条 tweet 的字数)、字符数等。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi or"><img src="../Images/2ed9cc31774f72b87942075b1b41eb0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*thlhCgMcYu8OkGIHHOUjqQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">基本文本 EDA —单词和字符频率分布</p></figure><h2 id="7cc3" class="no lu iq bd lv np nq dn lz nr ns dp md le nt nu mf li nv nw mh lm nx ny mj nz bi translated">停止言语</h2><p id="2e89" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">显而易见，每条推文的平均长度相对较短(准确地说是 10.3 个单词)。这些信息表明，如果我们考虑潜在的信息损失，以计算复杂性和内存开销为代价，过滤停用词可能<strong class="kx ir">而不是</strong>是一个好主意。</p><p id="4192" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最初，这个实验使用 NLTK 非常方便的停用词标准列表，从 Tweets 中删除所有停用词:</p><pre class="kg kh ki kj gt oa ob oc od aw oe bi"><span id="606f" class="no lu iq ob b gy of og l oh oi"># Standard tweet sw<br/>stop_words_nltk = set(stopwords.words('english'))</span><span id="c456" class="no lu iq ob b gy oj og l oh oi"># custom stop words<br/>stop_words = get_top_ngram(tweets_df['text'], 1)<br/>stop_words_split = [<br/>    w[0] for w in stop_words<br/>    if w[0] not in [<br/>        'price', 'prices',<br/>        'china', 'copper',<br/>        'spot', 'other_stop_words_etc'<br/>    ] # Keep SW with hypothesised importance<br/>]</span><span id="2df3" class="no lu iq ob b gy oj og l oh oi">stop_words_all = list(stop_words_nltk) + stop_words_split</span></pre><p id="8f72" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然而，这种行为导致了许多错误分类的推文(从情感分数的角度来看),这支持了信息丢失的概念，因此最好避免。</p><p id="80f9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这一点上，当涉及到处理 Twitter 数据时，非常值得强调 NLTK 的<em class="lr">优秀的</em>库。它提供了一套全面的工具和功能来帮助解析社交媒体输出，包括表情符号解释！。你可以在 Twitter data <a class="ae ls" href="http://www.nltk.org/howto/twitter.html" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ir">这里</strong> </a>找到一个真正有用的入门和使用 NLTK 的指南。</p><h2 id="d725" class="no lu iq bd lv np nq dn lz nr ns dp md le nt nu mf li nv nw mh lm nx ny mj nz bi translated">N-grams</h2><p id="c44b" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">下一步是考虑词序。当我们将一系列符号矢量化成一个单词包(BOW——下一段将详细介绍)时，我们失去了这些单词在 tweet 中的顺序所固有的上下文和含义。我们可以通过检查最常见的<a class="ae ls" href="https://en.wikipedia.org/wiki/N-gram" rel="noopener ugc nofollow" target="_blank"> n-grams </a>来尝试理解词序在我们的 tweets 数据框架中的重要性。</p><p id="859d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">正如我们在上面的初步分析中观察到的，一条给定推文的平均长度只有 10 个词。根据这些信息，一条推文中词语的<strong class="kx ir">顺序，特别是确保我们保留这种顺序中固有的上下文和含义，对于生成准确的情感评分<strong class="kx ir">至关重要</strong>。我们可以将记号的概念扩展到包括多单词记号，即<strong class="kx ir"> n-grams </strong>，以便保留单词排序中的含义。</strong></p><p id="ac89" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">NLTK 有一个非常方便(也非常高效)的 n 元语法标记器:<code class="fe om on oo ob b">from nltk.util import ngram</code>。n-gram 函数返回一个生成器，该生成器以元组的形式生成前“n”个 n-gram。然而，我们有兴趣探索这些 n 元语法在第一个实例中实际上是什么，所以将利用 Scikit-learn 的<a class="ae ls" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer.fit_transform" rel="noopener ugc nofollow" target="_blank">计数矢量器</a>来解析我们的 tweet 数据:</p><pre class="kg kh ki kj gt oa ob oc od aw oe bi"><span id="dc2e" class="no lu iq ob b gy of og l oh oi">def get_ngrams(doc, n=None):<br/>  """<br/>  Get matrix of individual token counts for a given text document.<br/>    Args:<br/>      corpus: String, the text document to be vectorized into its  constituent tokens.<br/>    n: Int, the number of contiguous words (n-grams) to return.      <br/>    Returns:<br/>      word_counts: A list of word:word frequency tuples.<br/>  """<br/>  # Instantiate CountVectorizer class<br/>  vectorizer = CountVectorizer(ngram_range=<br/>  (n,n)).fit(doc)<br/>  bag_of_words = vectorizer.transform(doc)<br/>  sum_of_words = bag_of_words.sum(axis=0)<br/>  # Get word frequencies<br/>  word_counts = [(word, sum_of_words[0, index])<br/>      for word, index in vectorizer.vocabulary_.items()<br/>  ]<br/>  word_counts = sorted(word_counts, key=lambda x:x[1], reverse=True)<br/>  return word_counts</span><span id="6b31" class="no lu iq ob b gy oj og l oh oi"># Get n-grams<br/>top_bigrams = get_ngrams(tweets_df['text'], 2)[:20]<br/>top_trigrams = get_ngrams(tweets_df['text'], 3)[:20]</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi os"><img src="../Images/74a93783814dc7c3fc702d72a6535107.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cf2PLMvUk-ccCJrJcwpc7Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">连续词频(n 元语法)。</p></figure><p id="8516" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在检查我们的 n-gram 图时，我们可以看到，除了少数例外，基于 NLP 的预测模型将从我们的 n-gram 特征中学习到更多。例如，该模型将能够正确地将“铜价”解释为铜的实物价格的参考，或者将“中国贸易”解释为中国的贸易，而不是解释单个单词的含义。</p><h2 id="5af9" class="no lu iq bd lv np nq dn lz nr ns dp md le nt nu mf li nv nw mh lm nx ny mj nz bi translated">记号化和词条化。</h2><p id="a304" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">我们的下一步是标记我们的 tweets，以便在我们的 LDA 主题模型中使用。我们将开发一个功能，对我们的 tweets 进行必要的分段(分词器的工作)和词汇化。</p><p id="3955" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将使用 NLTK 的<a class="ae ls" href="https://www.nltk.org/api/nltk.tokenize.html" rel="noopener ugc nofollow" target="_blank"><strong class="kx ir">tweet tokenizer</strong></a>来执行我们的推文的标记化，这是专门为解析推文和理解它们相对于这个社交媒体平台的语义而开发的。</p><p id="ba60" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">鉴于每条推文相对简短的性质，降维对我们的模型来说并不是一个紧迫的问题。考虑到这一点，在试图消除单词的复数形式与所有格形式之间的细微意义差异时，不对我们的数据执行任何词干操作是合理的。</p><p id="aa78" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">相反，我们将实现一个词条整理器，<a class="ae ls" href="https://www.nltk.org/_modules/nltk/stem/wordnet.html" rel="noopener ugc nofollow" target="_blank"><strong class="kx ir">WordNetLemmatizer</strong></a>，对我们的 tweet 数据中的词进行规范化。对于我们的应用程序来说，lemma tion 可以说比词干提取更准确，因为它考虑了单词的<strong class="kx ir">含义</strong>。WordNetLemmatizer 还可以帮助提高我们的主题模型的准确性，因为它利用了词性(POS)标记。一个单词的词性标记表明了它在句子语法中的作用，例如区分名词词性和形容词词性，如“铜”和“铜的价格”。</p><p id="9c16" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="lr">注意:您必须在 WordNetLemmatizer 中手动配置 POS 标签。如果没有 POS 标签，它会认为你输入的所有东西都是名词。</em></p><pre class="kg kh ki kj gt oa ob oc od aw oe bi"><span id="1ecf" class="no lu iq ob b gy of og l oh oi">def preprocess_tweet(df: pd.DataFrame, stop_words: None):<br/>  """<br/>  Tokenize and Lemmatize raw tweets in a given DataFrame.<br/>    Args:<br/>      df: A Pandas DataFrame of raw tweets indexed by index of type       DateTime.<br/>      stop_words: Optional. A list of Strings containing stop words         to be removed.<br/>    Returns:<br/>      processed_tweets: A list of preprocessed tokens of type          String.<br/>  """<br/>  processed_tweets = []<br/>  tokenizer = TweetTokenizer()<br/>  lemmatizer = WordNetLemmatizer()<br/>  for text in df['text']:<br/>    words = [w for w in tokenizer.tokenize(text) if (w not in    stop_words)]<br/>    words = [lemmatizer.lemmatize(w) for w in words if len(w) &gt; 2]    </span><span id="c4fc" class="no lu iq ob b gy oj og l oh oi">    processed_tweets.append(words)<br/>    return processed_tweets</span><span id="c1d3" class="no lu iq ob b gy oj og l oh oi"># Tokenize &amp; normalise tweets<br/>tweets_preprocessed = preprocess_tweet(tweets_df, stop_words_all)</span></pre><p id="2539" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了演示上述函数的效用，我们还将一个<strong class="kx ir">停用词列表</strong>传递到函数中。</p><h2 id="0a2c" class="no lu iq bd lv np nq dn lz nr ns dp md le nt nu mf li nv nw mh lm nx ny mj nz bi translated">矢量化和连续词汇袋</h2><p id="3863" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">我们现在需要使用一种称为单词的 B<strong class="kx ir">ag(BOW)的文档表示方法，将我们的标记化 tweets 转换为向量。</strong>为了执行这个映射，我们将使用<a class="ae ls" href="https://radimrehurek.com/gensim/corpora/dictionary.html" rel="noopener ugc nofollow" target="_blank"> Gensim 的字典类</a>:</p><pre class="kg kh ki kj gt oa ob oc od aw oe bi"><span id="bf9d" class="no lu iq ob b gy of og l oh oi">tweets_dict = gs.corpora.Dictionary(tweets_preprocessed)</span></pre><p id="7515" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">通过将处理过的 tweets 列表作为参数传递，Gensim 的字典为每个唯一的规范化单词创建了一个唯一的整数 id 映射(类似于<a class="ae ls" href="https://en.wikipedia.org/wiki/Hash_table" rel="noopener ugc nofollow" target="_blank">哈希映射</a>)。我们可以通过调用 tweets_dict 上的<code class="fe om on oo ob b">.token2id()</code>来查看 word: id 映射。然后，我们计算每个不同单词的出现次数，将单词转换为其整数单词 id，并将结果作为稀疏向量返回:</p><pre class="kg kh ki kj gt oa ob oc od aw oe bi"><span id="8164" class="no lu iq ob b gy of og l oh oi">cbow_tweets = [tweets_dict.doc2bow(doc) for doc in tweets_preprocessed]</span></pre><h2 id="2249" class="no lu iq bd lv np nq dn lz nr ns dp md le nt nu mf li nv nw mh lm nx ny mj nz bi translated">LDA 主题建模</h2><p id="decd" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">现在是有趣的部分。</p><p id="b0ad" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">开发基于 NLP 的交易策略的前提是了解我们提取的数据是否包含与铜价相关的主题/信号，更重要的是，它是否包含我们可能交易的信息。</p><p id="44cd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这要求我们检查和评估各种主题以及在我们的数据中代表这些主题的单词。垃圾进，垃圾出。</p><p id="1557" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了探索我们的 tweet 语料库中的各种主题(以及所述主题的主题)，我们将使用 Gensim 的<a class="ae ls" href="https://radimrehurek.com/gensim/models/ldamodel.html#gensim.models.ldamodel.LdaModel" rel="noopener ugc nofollow" target="_blank">潜在狄利克雷分配</a>模型。LDA 是一种生成概率模型，适用于文本等离散数据的集合。LDA 的功能相当于一个分层贝叶斯模型，其中集合中的每个项目都被建模为一组底层主题的有限混合。反过来，每个主题都被建模为一组潜在主题概率的无限混合物(<a class="ae ls" href="https://ai.stanford.edu/~ang/papers/jair03-lda.pdf" rel="noopener ugc nofollow" target="_blank"> Blei，ng 等人，2003 </a>)。</p><p id="b905" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将新矢量化的推文<code class="fe om on oo ob b">cbow_tweets</code>和将每个单词映射到 id 的字典<code class="fe om on oo ob b">tweets_dict</code>传递给 Gensim 的 LDA 模型类:</p><pre class="kg kh ki kj gt oa ob oc od aw oe bi"><span id="e698" class="no lu iq ob b gy of og l oh oi"># Instantiate model <br/>model = gs.models.LdaMulticore(<br/>  cbow_tweets,<br/>  num_topics = 4,<br/>  id2word = tweets_dict,<br/>  passes = 10,<br/>  workers = 2)</span><span id="4157" class="no lu iq ob b gy oj og l oh oi"># Display topics <br/>model.show_topics()</span></pre><p id="a8e2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">您可以看到，我们需要通过<code class="fe om on oo ob b">num_topics</code>超参数提供数据集内主题数量的估计值。据我所知，有两种方法可以确定主题的最佳数量:</p><ol class=""><li id="f3b0" class="mz na iq kx b ky kz lb lc le nb li nc lm nd lq nn nf ng nh bi translated">建立多个 LDA 模型，用<strong class="kx ir"> </strong> <a class="ae ls" href="https://radimrehurek.com/gensim/models/coherencemodel.html" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ir">相干模型</strong> </a> <strong class="kx ir">计算它们的<strong class="kx ir">相干得分</strong>。</strong></li><li id="87ed" class="mz na iq kx b ky ni lb nj le nk li nl lm nm lq nn nf ng nh bi translated">领域专长和直觉。</li></ol><p id="7a0b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">从交易的角度来看，这是领域知识和市场专业知识可以帮助的地方。我们希望我们的 Twitter 数据中的主题，记住它们是金融新闻出版物的产品，主要集中在以下主题:</p><ul class=""><li id="f259" class="mz na iq kx b ky kz lb lc le nb li nc lm nd lq ne nf ng nh bi translated"><strong class="kx ir">铜价(自然上涨)</strong></li><li id="cf20" class="mz na iq kx b ky ni lb nj le nk li nl lm nm lq ne nf ng nh bi translated"><strong class="kx ir">美中贸易战</strong></li><li id="1937" class="mz na iq kx b ky ni lb nj le nk li nl lm nm lq ne nf ng nh bi translated"><strong class="kx ir">美国总统唐纳德·特朗普</strong></li><li id="7a65" class="mz na iq kx b ky ni lb nj le nk li nl lm nm lq ne nf ng nh bi translated"><strong class="kx ir">主要铜矿商</strong></li><li id="4e81" class="mz na iq kx b ky ni lb nj le nk li nl lm nm lq ne nf ng nh bi translated"><strong class="kx ir">宏观经济公告</strong></li><li id="6efa" class="mz na iq kx b ky ni lb nj le nk li nl lm nm lq ne nf ng nh bi translated"><strong class="kx ir">当地生产国国内/政治动乱</strong></li></ul><p id="f98f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">除此之外，在确定这个超参数时，应该使用自己的判断。</p><p id="4720" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">值得一提的是，其他超参数的整个<strong class="kx ir">主机</strong>存在。这种灵活性使得 Gensim 的 LDA 模型极其强大。例如，作为贝叶斯模型，如果我们对主题/单词概率有“先验”的信念，我们的 LDA 模型允许我们通过<code class="fe om on oo ob b">init_dir_prior</code>方法，或者类似地通过<code class="fe om on oo ob b">eta</code>超参数，为狄利克雷分布编码这些先验。</p><p id="e837" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">回到我们的模型，你会注意到我们使用了 Gensim 的多核版本<code class="fe om on oo ob b">LdaModel</code>，它允许更快的实现(多核机器的操作并行化):</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ot"><img src="../Images/5f7e652ff4bf9175a8b456e26d48010d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EME77pNqcubvxvYc5iIYIQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">LDA 模型 show_topics()输出:注意编号为 0-4 的主题，其中包含单词及其相关权重，即它们对主题的贡献大小。</p></figure><p id="d5b2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">粗略地检查一下我们模型中的主题，会发现我们既有相关的数据，而且我们的 LDA 模型在对所述主题建模方面做得很好。</p><p id="f592" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了了解主题及其关键字的分布，我们将使用 pyLDAvis，它启动了一个交互式小部件，非常适合在 Jupyter/Colab 笔记本中使用:</p><pre class="kg kh ki kj gt oa ob oc od aw oe bi"><span id="3e30" class="no lu iq ob b gy of og l oh oi">pyLDAvis.enable_notebook()<br/>topic_vis = pyLDAvis.gensim.prepare(model, cbow_tweets, tweets_dict)<br/>topic_vis</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ou"><img src="../Images/eaf808d3751915e5ffb032ff4ce6d593.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AOFyZlF_ldA4Kf8hd9kn5w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">LDA 模型——Twitter 新闻数据，话题分布。</p></figure><h2 id="d37e" class="no lu iq bd lv np nq dn lz nr ns dp md le nt nu mf li nv nw mh lm nx ny mj nz bi translated">LDA 模型结果</h2><p id="adfb" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">在检查产生的主题图时，我们可以看到我们的 LDA 模型在捕捉 Twitter 数据中的突出主题及其组成词方面做得很好。</p><p id="8dc0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">什么构成了健壮的主题模型？</strong></p><p id="1c17" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一个好的主题模型通常展示大的、不同的主题(圆圈),没有重叠。所述圆圈的面积与语料库(即我们的 Twitter 数据)中“N”个总标记中的主题比例成比例。每个主题圆的中心在两个维度上设置:PC1 和 PC2，它们之间的距离由在主题间距离矩阵上运行的降维模型(准确地说是多维标度)的输出来设置。pyLDAvis 主题视觉背后的数学细节的完整解释可以在<a class="ae ls" href="https://cran.r-project.org/web/packages/LDAvis/vignettes/details.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="4722" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">解读我们的结果</strong></p><p id="46c9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在记住<strong class="kx ir">而不是</strong>忽略我们试图解决的问题的同时，具体来说，了解我们的推文数据中是否有任何<strong class="kx ir">有用的信号</strong>可能影响铜的现货价格，我们必须进行定性评估。</p><p id="c7cc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">详细检查各个主题，我们可以看到一组有希望的结果，特别是出现在各个主题中的热门词汇，它们在很大程度上符合我们上面预期的主题标准:</p><p id="0b0f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">题目编号:</strong></p><ol class=""><li id="4be6" class="mz na iq kx b ky kz lb lc le nb li nc lm nd lq nn nf ng nh bi translated"><strong class="kx ir">铜矿开采&amp;铜出口国</strong></li></ol><p id="54bb" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">热门词汇包括主要铜矿商(必和必拓、安托法加斯塔、英美资源集团和力拓)，以及主要铜出口国，即秘鲁、智利、蒙古等。</p><p id="2ad2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">2.<strong class="kx ir">中国贸易&amp;制造业活动</strong></p><p id="f0a0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">热门词汇包括“铜”、“铜价”、“中国”、“自由港”和“上海”。</p><p id="be5f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">3.<strong class="kx ir">美中贸易战</strong></p><p id="3e40" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">热门词汇包括“铜”、“价格”、“中国”、“特朗普”、“美元”和“美联储”，但也有一些不常见的术语，如“智利”和“视频”。</p><p id="112a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">基于上述结果，我们决定继续我们的 NLP 交易策略，因为我们的 twitter 数据展示了足够多的与铜现货价格相关的信息。更重要的是，我们可以确信我们的 Twitter 数据与铜价的<em class="lr">相关性</em>——我们的 LDA 模型发现的主题符合我们对数据中应该出现的<strong class="kx ir"> <em class="lr">预期主题</em> </strong> <em class="lr"> </em>的看法。</p><h2 id="89d6" class="no lu iq bd lv np nq dn lz nr ns dp md le nt nu mf li nv nw mh lm nx ny mj nz bi translated">验证 LDA 模型</h2><p id="185b" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">作为数据科学家，我们知道我们必须验证任何模型的完整性和稳健性。我们的 LDA 模型也不例外。我们可以通过检查模型的一致性(如上所述)来做到这一点。通俗地说，连贯性衡量的是一个主题内单词之间的相对距离。关于数学背后的数学细节精确地说<em class="lr"/>这个分数是如何计算的可以在这篇<a class="ae ls" href="http://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ir">论文</strong> </a> <strong class="kx ir">中找到。为了简洁起见，我省略了重复各种表达。</strong></p><p id="433c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一般来说，介于 0.55 和 0.70 之间的分数表示一个熟练的主题模型:</p><pre class="kg kh ki kj gt oa ob oc od aw oe bi"><span id="c5c0" class="no lu iq ob b gy of og l oh oi"># Compute Coherence Score<br/>coherence_model = gs.models.CoherenceModel(<br/>    model=model,<br/>    texts=tweets_preprocessed,<br/>    dictionary=tweets_dict,<br/>    coherence='c_v')</span><span id="9d0e" class="no lu iq ob b gy oj og l oh oi">coherence_score = coherence_model.get_coherence()<br/>print(f'Coherence Score: {coherence_score}')</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/a3934df54f2aed442af2ca8667f98ab2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*xi-TdsuiLqnhY3t2KHskGQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">基于确认度量‘c _ v’(与 UMass 相反)，计算我们的 LDA 模型的一致性分数。</p></figure><p id="2a4c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在 0.0639 的一致性分数下，我们可以合理地确信我们的 LDA 模型已经在正确数量的主题上被训练，并且在每个主题中的高分单词之间保持足够程度的语义相似性。</p><p id="6eb7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们对分数测量的选择，在上述一致性模型逻辑的签名中可以观察到，是由<a class="ae ls" href="http://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf" rel="noopener ugc nofollow" target="_blank"> Roder，Both &amp; Hindeburg </a>的论文中的结果激发的。您可以看到，我们已经选择根据<code class="fe om on oo ob b">coherence = 'c_v</code>度量对我们的模型进行评分，而不是使用<em class="lr">‘u _ mass’，‘c _ v’，‘c _ UCI’。</em>等。发现“c_v”分数测量返回优于其他测量的结果，特别是在小词集的情况下，限定了我们的选择。</p><h2 id="f060" class="no lu iq bd lv np nq dn lz nr ns dp md le nt nu mf li nv nw mh lm nx ny mj nz bi translated">情感得分:VADER</h2><p id="f6e6" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">在对我们的 twitter 数据包含足够相关的信息以潜在地预测短期铜价走势感到满意后，我们继续进入我们问题的<a class="ae ls" href="https://en.wikipedia.org/wiki/Sentiment_analysis" rel="noopener ugc nofollow" target="_blank"><strong class="kx ir"/></a><strong class="kx ir"/>部分<strong class="kx ir"> </strong>。</p><p id="40d9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将使用 NLTK 的 Valence Aware 字典和情感推理器(VADER)来分析我们的推文，并根据每条推文中每个词的潜在强度总和，生成一个介于-1 和 1 之间的情感得分。</p><p id="a67d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">不管我们在 NLP 模型中使用单个标记、ngrams、词干还是词条，基本上，我们 tweet 数据中的每个标记都包含一些信息。可能这些信息中最重要的部分是单词的<em class="lr">情感。</em></p><p id="429b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">VADER 是一个受欢迎的启发式的、基于规则的(由人类创作的)情感分析模型，由<a class="ae ls" href="https://www.nltk.org/_modules/nltk/sentiment/vader.html" rel="noopener ugc nofollow" target="_blank">休顿和</a>吉尔伯特开发。它在社交媒体文本上使用特别准确(并且是专门为此应用程序设计的)。因此，在我们的项目中使用它似乎是合理的。</p><p id="ed7b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">VADER 的实现非常简单:</p><pre class="kg kh ki kj gt oa ob oc od aw oe bi"><span id="539a" class="no lu iq ob b gy of og l oh oi"># Instantiate SIA class<br/>analyser = SentimentIntensityAnalyzer()</span><span id="5ea7" class="no lu iq ob b gy oj og l oh oi">sentiment_score = []</span><span id="643c" class="no lu iq ob b gy oj og l oh oi">for tweet in tweets_df[‘text’]:<br/>  sentiment_score.append(analyser.polarity_scores(tweet))</span></pre><p id="b48f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><code class="fe om on oo ob b">SentimentIntensityAnalyzer</code>包含一个令牌和它们各自分数的字典。然后，我们为 tweets 数据框架中的每条 tweets 生成一个情感分数，并访问由 VADER 模型生成的四个独立分数部分的结果(一个字典对象):</p><ul class=""><li id="f70c" class="mz na iq kx b ky kz lb lc le nb li nc lm nd lq ne nf ng nh bi translated">文本的否定比例</li><li id="04f6" class="mz na iq kx b ky ni lb nj le nk li nl lm nm lq ne nf ng nh bi translated">正文的正面比例</li><li id="ef0b" class="mz na iq kx b ky ni lb nj le nk li nl lm nm lq ne nf ng nh bi translated">文本的中性比例&amp;</li><li id="68a1" class="mz na iq kx b ky ni lb nj le nk li nl lm nm lq ne nf ng nh bi translated">上述情绪极性的综合强度，即“复合”得分</li></ul><pre class="kg kh ki kj gt oa ob oc od aw oe bi"><span id="9c8e" class="no lu iq ob b gy of og l oh oi">#@title Extract Sentiment Score Elements</span><span id="9eb4" class="no lu iq ob b gy oj og l oh oi">sentiment_prop_negative = []<br/>sentiment_prop_positive = []<br/>sentiment_prop_neutral = []<br/>sentiment_score_compound = []</span><span id="b05b" class="no lu iq ob b gy oj og l oh oi">for item in sentiment_score:<br/>  sentiment_prop_negative.append(item['neg'])<br/>  sentiment_prop_positive.append(item['neu'])<br/>  sentiment_prop_neutral.append(item['pos'])<br/>  sentiment_score_compound.append(item['compound'])</span><span id="cd15" class="no lu iq ob b gy oj og l oh oi"># Append to tweets DataFrame<br/>tweets_df['sentiment_prop_negative'] = sentiment_prop_negative<br/>tweets_df['sentiment_prop_positive'] = sentiment_prop_positive<br/>tweets_df['sentiment_prop_neutral'] = sentiment_prop_neutral<br/>tweets_df['sentiment_score_compound'] = sentiment_score_compound</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ow"><img src="../Images/807d4ee723ec8e83f9a91e2cd2d30e3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nmYW4wj4Fo4QC9UxTJUvmA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">推文数据情绪得分:负面，正面，复合，每日。</p></figure><p id="3f3e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在绘制了各种成分的滚动分数、负分数、正分数和复合分数(我们不考虑中性分数)之后，我们可以进行一些观察:</p><ul class=""><li id="7fae" class="mz na iq kx b ky kz lb lc le nb li nc lm nd lq ne nf ng nh bi translated">显然，情感得分非常嘈杂/不稳定——我们的 Twitter 数据可能只包含冗余信息，少数信息会导致得分大幅飙升。然而，这就是信号发现的本质——我们只需要那一条显著的信息。</li><li id="ccc2" class="mz na iq kx b ky ni lb nj le nk li nl lm nm lq ne nf ng nh bi translated">我们的 Twitter 数据看起来主要是正面的:平均负面得分是 0.09，而平均正面得分是 0.83。</li></ul><h2 id="c73f" class="no lu iq bd lv np nq dn lz nr ns dp md le nt nu mf li nv nw mh lm nx ny mj nz bi translated">情绪得分与铜现货价格</h2><p id="06ae" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">现在我们必须评估我们的努力是否得到了回报:<strong class="kx ir">我们的情绪得分是否能预测铜的现货价格！</strong></p><p id="e495" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">乍一看，现货价格和我们的综合得分之间似乎没有任何关联:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ox"><img src="../Images/f4065962b1b66868d3d66c299c5ec9bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tkU2Y6ECuiMKy12XJBpPvA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">复合情绪得分 vs 现货铜($/Mt)，每日。</p></figure><p id="5599" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然而，当我们应用经典的平滑技术并计算我们情绪得分的滚动平均值时，我们看到了一个不同的画面:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oy"><img src="../Images/026f5cbb56f877baf0e2c732202c4f04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S7xktMdPWX2zHPcpXECz0A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">滚动 21d 平均复合情绪得分与现货铜(美元/公吨)，每日。</p></figure><p id="0c91" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这现在看起来更有希望。除了 2017 年 1 月至 8 月期间，我们可以很容易地观察到我们的 21 天滚动平均复合得分和铜现货价格之间近乎对称的反比关系。</p><h1 id="ed22" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">结论</h1><p id="e06d" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">在这种情况下，我们停下来考虑我们可用的选项，即我们希望我们的模型如何处理和分类一段文本数据中的潜在情绪，以及关键的是，模型将如何根据其交易决策对这种分类采取行动。</p><p id="8a82" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">与<a class="ae ls" href="https://en.wikipedia.org/wiki/Occam%27s_razor" rel="noopener ugc nofollow" target="_blank">奥卡姆剃刀</a>原则一致，我们实现了一个开箱即用的解决方案来分析 twitter 数据中的潜在情绪。除了探索一些著名的 EDA 和预处理技术作为先决条件，我们还使用了<a class="ae ls" href="https://www.nltk.org/_modules/nltk/sentiment/vader.html" rel="noopener ugc nofollow" target="_blank"> NLTK 的 Valence Aware 字典和<strong class="kx ir">情绪</strong> Reasoner (VADER) </a>，为每条推文生成相关的情绪得分，并检查了所述得分与简单的相应铜现货价格运动的相关性。</p><p id="da66" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有趣的是，我们观察到滚动复合情绪得分和铜价之间存在相关性。当然，这并不意味着因果关系。此外，它可能只是新闻数据跟踪铜价，而我们的推文数据只是报告其走势。尽管如此，仍有进一步工作的余地。</p><h1 id="c978" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">观察、批评和进一步分析</h1><p id="0143" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">事实上，系统交易策略的设计需要更多的数学和分析的严谨性，以及大量的专业知识。人们通常会投入大量时间来设计一个合适的标签，最好地包含信号和价格运动的幅度(如果有的话！)在所述信号中发现，尽管对信号本身进行了彻底的研究。</p><p id="ba11" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">关于我们的问题，存在大量非常有趣的进一步工作和分析的空间:</p><ol class=""><li id="0510" class="mz na iq kx b ky kz lb lc le nb li nc lm nd lq nn nf ng nh bi translated"><strong class="kx ir">神经网络嵌入:</strong>作为一个例子，为了更好地理解一个 NLP 模型和一个相关的标签(或多个标签)是如何做出交易决策的，我们可以用<a class="ae ls" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding" rel="noopener ugc nofollow" target="_blank">嵌入层</a>来训练一个神经网络。然后，我们可以检查经过训练的嵌入层，以了解模型如何根据具有类似编码和标签的层来处理层中的各种标记。然后，我们可以可视化模型如何根据单词对我们希望预测的类别的影响对单词进行分组，即 0 表示负价格变动，1 表示正价格变动。例如，TensorFlow 的嵌入投影仪是可视化此类嵌入的无价工具:</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oz"><img src="../Images/c4d7251c28d4b4d1c0ea4193b5da1aee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XTLxZ5KPnsVD4wUPmUCnBw.png"/></div></div></figure><p id="72f3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> 2。多项式朴素贝叶斯</strong></p><p id="c83d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们使用 VADER 来解析和解释我们的 Twitter 数据的潜在情绪，它做了合理的工作。然而，使用 VADER 的缺点是<strong class="kx ir">它不会考虑文档中的所有单词，实际上只有大约 7500 个。</strong>鉴于商品交易及其相关术语的复杂性，我们可能会遗漏重要信息。</p><p id="c678" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">作为替代，我们可以使用朴素贝叶斯分类器来寻找预测我们目标的关键词集，无论是铜价本身还是情绪得分。</p><p id="e832" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> 3 </strong>。<strong class="kx ir">日内数据</strong></p><p id="b5c2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由于引言中提到的原因，在设计 NLP 交易策略模型时，几乎所有情况下的日内数据都是必须的。当试图利用基于新闻/事件的价格变动时，时间和交易执行是非常重要的。</p><p id="40f1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">感谢你花时间阅读我的文章，我希望你觉得有趣。</p><p id="6285" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">请不要客气，我非常欢迎评论和建设性的批评。</p><h1 id="4075" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">参考</h1><ol class=""><li id="b829" class="mz na iq kx b ky ml lb mm le pa li pb lm pc lq nn nf ng nh bi translated"><a class="ae ls" href="https://www.nltk.org/_modules/nltk/sentiment/vader.html" rel="noopener ugc nofollow" target="_blank">休顿，C.J. &amp;吉伯特，E.E. (2014)。VADER:基于规则的社交媒体文本情感分析的简约模型。第八届网络日志和社交媒体国际会议。密歇根州安阿伯，2014 年 6 月。</a></li><li id="b0be" class="mz na iq kx b ky ni lb nj le nk li nl lm nm lq nn nf ng nh bi translated">莱恩、霍华德、哈普克(2019):自然语言处理在行动。</li><li id="64e5" class="mz na iq kx b ky ni lb nj le nk li nl lm nm lq nn nf ng nh bi translated"><a class="ae ls" href="https://moneyweek.com/516039/the-cycles-in-the-metals-market-when-will-zinc-and-copper-shine" rel="noopener ugc nofollow" target="_blank"> Moneyweek (2019):金属市场的周期:锌&amp;铜什么时候发光</a>。</li><li id="26be" class="mz na iq kx b ky ni lb nj le nk li nl lm nm lq nn nf ng nh bi translated"><a class="ae ls" href="https://asia.nikkei.com/Business/Markets/Commodities/Dr.-Copper-misdiagnoses-the-global-economy" rel="noopener ugc nofollow" target="_blank">《日经亚洲评论》(2020):《铜博士》误诊了全球经济</a>。</li><li id="3d5e" class="mz na iq kx b ky ni lb nj le nk li nl lm nm lq nn nf ng nh bi translated"><a class="ae ls" href="https://www.kitco.com/news/2020-07-15/METALS-Copper-slips-on-profit-taking-triggered-by-U-S-China-tensions.html" rel="noopener ugc nofollow" target="_blank"> Kitco 2020:美中紧张局势引发的获利回吐导致铜价下跌。</a></li><li id="c3e0" class="mz na iq kx b ky ni lb nj le nk li nl lm nm lq nn nf ng nh bi translated"><a class="ae ls" href="https://agmetalminer.com/2014/06/11/what-chinas-shadow-financing-market-aluminum-copper-collateral-means-for-metals-markets/" rel="noopener ugc nofollow" target="_blank"> Metal Miner，(2020):中国影子金属融资对市场意味着什么</a>。</li></ol></div></div>    
</body>
</html>