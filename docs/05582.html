<html>
<head>
<title>Cyclic Generative Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">循环生成网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/cyclic-generative-networks-cyclegans-9b9526b2731c?source=collection_archive---------24-----------------------#2020-05-10">https://towardsdatascience.com/cyclic-generative-networks-cyclegans-9b9526b2731c?source=collection_archive---------24-----------------------#2020-05-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="910d" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://medium.com/tag/gans-explained" rel="noopener">生成网络解释</a></h2><div class=""/><div class=""><h2 id="4dce" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">“其他人在他们的智慧的帮助下，将一个黄色的点变成了太阳”——巴勃罗·毕加索</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/2c8d7d2cd5d117cf524b08911ccc696b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*tQZZsDZyehZg6UQgFaseUA.gif"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">将马的原始镜头转换为斑马的循环生成网络。</p></figure><p id="4807" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><em class="md">本文旨在解释循环gan的内部工作原理，以及它们如何应用于解决现实世界的任务。</em></p><h2 id="c477" class="me mf it bd mg mh mi dn mj mk ml dp mm lq mn mo mp lu mq mr ms ly mt mu mv iz bi translated">介绍</h2><p id="f600" class="pw-post-body-paragraph lh li it lj b lk mw kd lm ln mx kg lp lq my ls lt lu mz lw lx ly na ma mb mc im bi nb translated"><span class="l nc nd ne bm nf ng nh ni nj di"> C </span>循环生成对抗网络(简称<strong class="lj jd">cycle gans</strong>)【1】是强大的计算机算法，具有改善数字生态系统的潜力。它们能够将信息从一种表示转换成另一种表示。例如，当给定一幅图像时，他们可以模糊它，给它着色(例如，如果它原本是黑色的&amp;白色的)，提高它的清晰度，或者填补缺失的空白。</p><p id="b8b1" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">它们比你传统的设计/生产/写作平台更强大。因为<strong class="lj jd">cycle gan</strong>是机器学习算法，它们原则上可以学习实现任何想要的转换。相反，传统的转换软件(如Photoshop)通常是硬编码的，用于执行特定的任务。此外，<strong class="lj jd"> CycleGans </strong>可以实现比现有软件更高的性能，因为它们可以从数据中学习，并随着数据的收集而改进。</p><p id="df40" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">了解不同层次的CycleGans的工作方式和能力令人兴奋，并提供了人工智能如何以前所未有的方式影响我们日常生活的见解。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nk nl l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">CycleGAN基于3d草图渲染手绘图像</p></figure><h2 id="90e4" class="me mf it bd mg mh mi dn mj mk ml dp mm lq mn mo mp lu mq mr ms ly mt mu mv iz bi translated">生成网络</h2><p id="7d3c" class="pw-post-body-paragraph lh li it lj b lk mw kd lm ln mx kg lp lq my ls lt lu mz lw lx ly na ma mb mc im bi translated">在谈论CycleGans之前，我们先简单讨论一下正则生成对抗网络。</p><p id="33ec" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">生成对抗网络(简称GANs)[2]是能够创建数据的<a class="ae nm" href="https://en.wikipedia.org/wiki/Machine_learning" rel="noopener ugc nofollow" target="_blank">机器学习算法</a>。当他们得到图像、声音或文本等信息时，他们会学习产生新的看起来/听起来相似的输出。例如:给定一组人脸图像，算法可以<em class="md">自学</em> ( <em class="md">训练</em>，用机器学习的行话来说)人脸长什么样，并且能够创造新的人脸。<strong class="lj jd">我鼓励你看一看</strong> <a class="ae nm" href="https://medium.com/ai-society/gans-from-scratch-1-a-deep-introduction-with-code-in-pytorch-and-tensorflow-cb03cdcdba0f" rel="noopener"> <strong class="lj jd">这篇文章</strong> </a> <strong class="lj jd">，我在其中旨在解释GANs </strong>的基本面。</p><p id="d954" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">环状GANs是传统GANs的特殊变体。他们还可以创建新的数据样本，但他们是通过转换输入样本来实现的，而不是从头开始创建输出。换句话说，他们学习转换来自两个数据源的数据；为该算法提供数据集的科学家或开发人员可以选择这些分布。在两个数据源是狗的图片和猫的图片的情况下，该算法能够有效地将猫的图像转换成狗的图像，反之亦然。</p><h1 id="85ae" class="nn mf it bd mg no np nq mj nr ns nt mm ki nu kj mp kl nv km ms ko nw kp mv nx bi translated">他们是怎么做到的？</h1><h2 id="b6d2" class="me mf it bd mg mh mi dn mj mk ml dp mm lq mn mo mp lu mq mr ms ly mt mu mv iz bi translated">什么是CycleGan？</h2><p id="de11" class="pw-post-body-paragraph lh li it lj b lk mw kd lm ln mx kg lp lq my ls lt lu mz lw lx ly na ma mb mc im bi translated">CycleGan是学习两个域之间的两个数据转换函数的神经网络。其中之一就是转型<code class="fe ny nz oa ob b"><strong class="lj jd">G</strong>(x)</code>。它将给定的样本<code class="fe ny nz oa ob b">x ∈ X</code>转换成域<code class="fe ny nz oa ob b">Y</code>的元素。第二个是<code class="fe ny nz oa ob b"><strong class="lj jd">F</strong>(y)</code>，将样本元素<code class="fe ny nz oa ob b">y ∈ Y</code>转换成域<code class="fe ny nz oa ob b">X</code> <em class="md">的元素。</em></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/f2ee8ecbb4e33e8c83dfd74db350e0bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/format:webp/1*f8x4_vYxMo1hZ9ZbSXu6rA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">变换函数F和g的定义。</p></figure><h2 id="3061" class="me mf it bd mg mh mi dn mj mk ml dp mm lq mn mo mp lu mq mr ms ly mt mu mv iz bi translated">两个甘，一个辛克莱甘</h2><p id="9311" class="pw-post-body-paragraph lh li it lj b lk mw kd lm ln mx kg lp lq my ls lt lu mz lw lx ly na ma mb mc im bi translated"><em class="md">考虑阅读</em> <a class="ae nm" href="https://medium.com/ai-society/gans-from-scratch-1-a-deep-introduction-with-code-in-pytorch-and-tensorflow-cb03cdcdba0f#0f72" rel="noopener"> <em class="md">这篇文章</em> </a> <em class="md">了解更多关于甘斯</em>的内容</p><p id="2556" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了学习<code class="fe ny nz oa ob b"><strong class="lj jd">F</strong></code>和<code class="fe ny nz oa ob b"><strong class="lj jd">G</strong></code>，使用了两个传统的甘。每个GAN内部都有一个<strong class="lj jd">发生器</strong>网络，学习如何根据需要转换数据。GAN的第一个生成器学习计算<code class="fe ny nz oa ob b"><strong class="lj jd">F</strong></code>，GAN的第二个生成器学习计算<code class="fe ny nz oa ob b"><strong class="lj jd">G</strong></code>。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi od"><img src="../Images/4b420bb0e05ccd4bcb19140ca6233d2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*zbDZm4Rs7y7acU2rs-VCjg.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">生成函数G和f的定义。</p></figure><p id="65ac" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">此外，每个发生器都与一个鉴别器相关联，该鉴别器学习区分真实数据<code class="fe ny nz oa ob b">y</code>和合成数据<code class="fe ny nz oa ob b"><strong class="lj jd">G</strong>(x)</code>。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/1feb769d21b6c93b72e1ca28fd30aff5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*zFEqALkAM34_ZMeOToNRgg.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">生成函数G和f的定义。</p></figure><p id="46fc" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">因此，CycleGAN由学习变换函数<code class="fe ny nz oa ob b"><strong class="lj jd">F</strong></code>和<code class="fe ny nz oa ob b"><strong class="lj jd">G</strong></code>的两个发生器和两个鉴别器组成。该结构显示在下图中:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi of"><img src="../Images/00bdf8fc39c61408b512fe70ea93c78c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZubXhJYyqvNFmtwY8ZyvEA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">CycleGan表示法。它由两个甘组成，甘学习两种转化。</p></figure><h2 id="6ff6" class="me mf it bd mg mh mi dn mj mk ml dp mm lq mn mo mp lu mq mr ms ly mt mu mv iz bi translated">单GAN损耗</h2><p id="153d" class="pw-post-body-paragraph lh li it lj b lk mw kd lm ln mx kg lp lq my ls lt lu mz lw lx ly na ma mb mc im bi translated">每个GAN发生器将通过最小化损耗来学习其相应的变换函数(或者<code class="fe ny nz oa ob b"><strong class="lj jd">F</strong></code>或者<code class="fe ny nz oa ob b"><strong class="lj jd">G</strong></code>)。通过测量生成的数据与目标数据的不同程度(例如，生成的猫图像与真实的猫图像相比的不同程度)来计算发生器损耗。差距越大，发生器将受到的惩罚越高。</p><p id="8b3e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">鉴别器损耗也用于训练鉴别器，使其善于区分真实数据和合成数据。</p><p id="0cb2" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">当这两个代理设置在一起时，它们将相互改进。生成器将被训练来欺骗鉴别器，而鉴别器将被训练来更好地从合成数据中区分真实数据。因此，生成器将变得非常擅长创建/转换所需的数据(学习所需的转换，例如<code class="fe ny nz oa ob b"><strong class="lj jd">F</strong></code> <strong class="lj jd"> </strong>)。</p><p id="5905" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">总的来说，GAN损耗如下:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi og"><img src="../Images/8ce4d5050bad5b9d59e1825e14833df7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*265YPQDBPSc0QaQO3voU0Q.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">单个GAN损耗的定义。d是鉴别器功能，G是发生器功能。</p></figure><p id="79f7" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">第二个发生器-鉴别器对也有类似的损耗:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oh"><img src="../Images/3dc815ba22052792da0bcc741d240712.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aJI8h8kpCO4wuQ89hnoKBw.png"/></div></div></figure><p id="5e5b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">作为学习所需转换<code class="fe ny nz oa ob b"><strong class="lj jd">F</strong></code>和<code class="fe ny nz oa ob b"><strong class="lj jd">G</strong></code>的一种方式，CycleGAN将尝试最小化两个GAN损耗的总和。</p><h2 id="1175" class="me mf it bd mg mh mi dn mj mk ml dp mm lq mn mo mp lu mq mr ms ly mt mu mv iz bi translated">循环转换一致性</h2><p id="8e52" class="pw-post-body-paragraph lh li it lj b lk mw kd lm ln mx kg lp lq my ls lt lu mz lw lx ly na ma mb mc im bi translated">理想情况下，我们希望我们的CycleGAN学习周期一致的转换函数<code class="fe ny nz oa ob b"><strong class="lj jd">F</strong></code>和<code class="fe ny nz oa ob b"><strong class="lj jd">G</strong></code>。这意味着，给定一个输入<code class="fe ny nz oa ob b">x</code>，我们希望来回转换<code class="fe ny nz oa ob b"><strong class="lj jd">F(G(</strong>x<strong class="lj jd">))= </strong>x'</code>准确地输出原始输入<code class="fe ny nz oa ob b">x</code>。理论上这应该是可能的，因为在输入端<code class="fe ny nz oa ob b">x</code>应用<code class="fe ny nz oa ob b"><strong class="lj jd">G</strong></code>将在<code class="fe ny nz oa ob b">Y</code>域输出一个值，在输入端<code class="fe ny nz oa ob b">y</code>应用<code class="fe ny nz oa ob b"><strong class="lj jd">F</strong></code>将在<code class="fe ny nz oa ob b">X</code>域输出一个值。</p><p id="6c8a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">循环一致性减少了这些网络可以学习的可能映射集，并迫使<code class="fe ny nz oa ob b"><strong class="lj jd">F</strong></code>和<code class="fe ny nz oa ob b"><strong class="lj jd">G</strong></code>成为相反的变换。想象一下，学会的函数<code class="fe ny nz oa ob b"><strong class="lj jd">F</strong></code>通过修改自己的<em class="md">耳朵</em>将猫的图片转化为狗的图片，而<code class="fe ny nz oa ob b"><strong class="lj jd">G</strong></code> <strong class="lj jd"> </strong>通过修改自己的<em class="md">鼻子</em>学会将狗的图片转化为猫的图片。虽然这些转换可以达到目标，但是它们并不协调，因为它们对数据应用了不同的更改。使用周期一致性迫使<code class="fe ny nz oa ob b"><strong class="lj jd">F</strong></code>和<code class="fe ny nz oa ob b"><strong class="lj jd">G</strong></code>彼此相反。这样猫的图片会通过修改耳朵转化为狗的图片，狗的图片会通过反过来修改耳朵转化为猫的图片。如果这两个函数是循环一致的，那么它们也是更有意义的映射。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oi"><img src="../Images/20bf10fa4d660c24b2439d5feb8bbab4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JSD9trMVg0CbSY1cGll1FA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">左:输入x的循环一致性损失的直观表示。右:输入y的循环一致性损失的直观表示。</p></figure><p id="e2a5" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">仅使用GAN损耗训练CycleGAN并不能保证保持<strong class="lj jd">周期一致性</strong>。因此，额外的<strong class="lj jd">周期一致性损失</strong>被用于实施该属性。这种损失被定义为输入值<code class="fe ny nz oa ob b">x</code>与其前向周期预测值<code class="fe ny nz oa ob b"><strong class="lj jd">F</strong>(<strong class="lj jd">G</strong>(x))</code>之间的绝对值差(<a class="ae nm" href="https://en.wikipedia.org/wiki/Uniform_norm" rel="noopener ugc nofollow" target="_blank"> L1范数</a>)，以及输入值<code class="fe ny nz oa ob b">y</code>与其前向周期预测值<code class="fe ny nz oa ob b"><strong class="lj jd">G</strong>(<strong class="lj jd">F</strong>(y))</code>。差异越大，预测值与原始输入值的差距就越大。理想情况下，我们的网络会将这种损失降至最低。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oh"><img src="../Images/e9320ed28cef8980d6b5f2ab557ffa02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wnwr_QV6M-7hLLB0Pa-Blw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">循环一致性损失的定义。相当于上图中的可视化表示。</p></figure><h2 id="467a" class="me mf it bd mg mh mi dn mj mk ml dp mm lq mn mo mp lu mq mr ms ly mt mu mv iz bi translated">完全损失</h2><p id="24ee" class="pw-post-body-paragraph lh li it lj b lk mw kd lm ln mx kg lp lq my ls lt lu mz lw lx ly na ma mb mc im bi translated">用于训练网络的完整周期Gan损耗定义为两个GAN损耗和周期一致性损耗之和。</p><p id="e13d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">加权因子<strong class="lj jd"> ƛ </strong>(名为λ)用于控制周期一致性损失在全部损失中的权重。与其他损失相比，权重越高，减少循环一致性损失就越相关。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oj"><img src="../Images/443c129fbe205ea2c633b34b33b62a51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*ATHeB8kavpkRups9MBT0OQ.gif"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">完全损失的定义</p></figure><p id="911f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">被优化以最小化该函数的CycleGANs将能够学习期望的变换<code class="fe ny nz oa ob b">F</code>和<code class="fe ny nz oa ob b">G</code>。机器学习培训的细节将留到我的后续文章中。</p><h1 id="5640" class="nn mf it bd mg no np nq mj nr ns nt mm ki nu kj mp kl nv km ms ko nw kp mv nx bi translated">结果</h1><p id="550a" class="pw-post-body-paragraph lh li it lj b lk mw kd lm ln mx kg lp lq my ls lt lu mz lw lx ly na ma mb mc im bi translated">CycleGans已经在几个任务的完成情况上进行了测试，并且已经能够成功地解决它们。这些任务的几个例子是:</p><h2 id="89b4" class="me mf it bd mg mh mi dn mj mk ml dp mm lq mn mo mp lu mq mr ms ly mt mu mv iz bi translated"><strong class="ak">图像变换</strong></h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ok"><img src="../Images/3c0d4dee23ecb7572d9df5429a38950a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*VYEez1K8BM4DAATU.jpg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">输入:鲜花原图。输出:应用了焦点和效果的改进的花卉图片。</p></figure><p id="4e97" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">照片增强:<em class="md"> </em> </strong> CycleGans经过训练，可以生成专业的花卉照片，具有几个级别的聚焦和模糊，以及任何照片编辑工具。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ol"><img src="../Images/43c4c5c6bfe7a0469aec2338383de26d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fEnlUj97GgkR_mFd.jpg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">输入:风景图片。输出:相同的风景，不同风格的艺术品。</p></figure><p id="956b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">图像风格转换:</strong> CycleGans被训练来转换图片和艺术品的风格，例如，他们已经能够将照片转换成相同风景的梵高风格的画作。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi om"><img src="../Images/f01f17f9c899aad5b7e2695bb7529510.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A8FhY2uIKbBAoycbHNxqrQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">风景图片从冬天变成了夏天。</p></figure><p id="237c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">季节转换:</strong>与风格转换类似，CycleGANs已用于转换拍摄照片的季节。这里的结果令人惊讶，因为许多图像看起来像真实的照片。</p><h2 id="bf8e" class="me mf it bd mg mh mi dn mj mk ml dp mm lq mn mo mp lu mq mr ms ly mt mu mv iz bi translated">音频转换</h2><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="c959" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">音乐类型转换:</strong>苏黎世ETH大学的研究人员已经能够训练CycleGANs人将古典流行音乐类型的歌曲转换成古典音乐作品[4]。</p><p id="8b80" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">语音转换:</strong>日本NTT通信科学实验室的研究人员展示了令人印象深刻的结果，他们使用CycleGANs在不同性别的说话者之间转换语音注册表[5]。</p><p id="827b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这部作品的音频样本可以在<a class="ae nm" href="http://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/cyclegan-vc2/index.html" rel="noopener ugc nofollow" target="_blank">他们的网站</a>找到。</p><h2 id="0915" class="me mf it bd mg mh mi dn mj mk ml dp mm lq mn mo mp lu mq mr ms ly mt mu mv iz bi translated">其他人</h2><p id="da42" class="pw-post-body-paragraph lh li it lj b lk mw kd lm ln mx kg lp lq my ls lt lu mz lw lx ly na ma mb mc im bi translated">CycleGan paper官方网站<a class="ae nm" href="https://junyanz.github.io/CycleGAN/" rel="noopener ugc nofollow" target="_blank">提供了在互联网不同地方发现的其他CycleGan用例的图库。我希望这些有趣的例子能鼓励您进一步了解CycleGans，并提出更多有用和有趣的应用。</a></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi on"><img src="../Images/f5bd824a1813939b6edc880c20fa3ba0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nalmMcts-Y52HP0XAaH2og.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">CycleGan使用的图库可以在<a class="ae nm" href="https://junyanz.github.io/CycleGAN/" rel="noopener ugc nofollow" target="_blank">这个网站</a>找到。</p></figure><h1 id="0e96" class="nn mf it bd mg no np nq mj nr ns nt mm ki nu kj mp kl nv km ms ko nw kp mv nx bi translated">CycleGan问题</h1><p id="7db5" class="pw-post-body-paragraph lh li it lj b lk mw kd lm ln mx kg lp lq my ls lt lu mz lw lx ly na ma mb mc im bi translated">尽管CycleGANs在上述许多任务中取得了明显的成功，但仍显示出100%的成功率。以下是他们目前的一些陷阱:</p><ol class=""><li id="f593" class="oo op it lj b lk ll ln lo lq oq lu or ly os mc ot ou ov ow bi translated">当CycleGans输入的数据来自他们接受训练的数据时，可能会产生意想不到的结果(见下图)。</li><li id="2945" class="oo op it lj b lk ox ln oy lq oz lu pa ly pb mc ot ou ov ow bi translated">需要几何变化而不是颜色或对比度的任务对输入的影响很小。</li></ol><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pc"><img src="../Images/3403a23bfd5bf05cf8a2ebd3689b3058.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_53XiVo6TECL6eDx1L6PqA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">用于变换马和斑马图像的CycleGan没有人类的输入，因此它可以生成任意的变换。</p></figure><p id="331a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">进一步的研究可能侧重于改进这些领域的工作。一些策略包括使用更广泛和更多样化的数据集，以及使用半监督学习方法。</p><h1 id="2ecf" class="nn mf it bd mg no np nq mj nr ns nt mm ki nu kj mp kl nv km ms ko nw kp mv nx bi translated">最后的话</h1><p id="5e88" class="pw-post-body-paragraph lh li it lj b lk mw kd lm ln mx kg lp lq my ls lt lu mz lw lx ly na ma mb mc im bi translated">我要感谢并祝贺来自加州大学伯克利分校人工智能研究实验室的朱俊彦、朴泰成、菲利普·伊索拉和阿列克谢·a·埃夫罗斯为CycleGans所做的工作。在<a class="ae nm" href="https://junyanz.github.io/CycleGAN/." rel="noopener ugc nofollow" target="_blank">他们的网站</a>你会找到更多与项目相关的信息。</p><p id="888b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我鼓励你去看看<a class="ae nm" href="http://github.com/diegoalejogm/gans" rel="noopener ugc nofollow" target="_blank">我的GANs库</a>，在那里你会发现不同类型的GANs在Python中的实现，以及一个正在从头开始在PyTorch和TensorFlow中的CycleGan实现。我将通过媒体发布一个教程，一旦我完成了。</p><p id="1529" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">感谢阅读这篇文章直到最后。我希望你在学习这个主题的过程中获得了乐趣，我将在下一期节目中与你见面。🎊</p><h1 id="c039" class="nn mf it bd mg no np nq mj nr ns nt mm ki nu kj mp kl nv km ms ko nw kp mv nx bi translated">参考</h1><p id="1ea0" class="pw-post-body-paragraph lh li it lj b lk mw kd lm ln mx kg lp lq my ls lt lu mz lw lx ly na ma mb mc im bi translated"><em class="md">【1】</em><a class="ae nm" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhu%2C+J" rel="noopener ugc nofollow" target="_blank"><em class="md">【朱俊彦】</em></a><em class="md"/><a class="ae nm" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Park%2C+T" rel="noopener ugc nofollow" target="_blank"><em class="md">朴泰成</em></a><em class="md"/><a class="ae nm" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Isola%2C+P" rel="noopener ugc nofollow" target="_blank"><em class="md">菲力普·伊索拉</em></a><em class="md"/><a class="ae nm" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Efros%2C+A+A" rel="noopener ugc nofollow" target="_blank"><em class="md">阿列克谢·阿弗罗斯</em> </a> <em class="md">、不成对的图像到图像翻译使用循环一致的对抗网络、</em><a class="ae nm" href="https://arxiv.org/abs/1703.10593" rel="noopener ugc nofollow" target="_blank"/><a class="ae nm" href="https://arxiv.org/abs/1703.10593" rel="noopener ugc nofollow" target="_blank"/></p><p id="c4e7" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><em class="md">【2】伊恩·j·古德菲勒、让·普盖-阿巴迪、迈赫迪·米尔扎、徐炳、大卫·沃德-法利、谢尔吉尔·奥泽尔、亚伦·库维尔、约舒阿·本吉奥，《生成性对抗性网络》，2014年，</em><a class="ae nm" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank"><em class="md">【https://arxiv.org/abs/1406.2661</em></a></p><p id="a6ab" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><em class="md">【3】</em><a class="ae nm" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karras%2C+T" rel="noopener ugc nofollow" target="_blank"><em class="md">泰罗卡拉斯</em></a><em class="md"/><a class="ae nm" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Laine%2C+S" rel="noopener ugc nofollow" target="_blank"><em class="md">萨穆利莱恩</em></a><em class="md"/><a class="ae nm" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aittala%2C+M" rel="noopener ugc nofollow" target="_blank"><em class="md">米卡艾塔拉</em></a><em class="md"/><a class="ae nm" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hellsten%2C+J" rel="noopener ugc nofollow" target="_blank"><em class="md">简内赫尔斯滕</em></a><em class="md"/><a class="ae nm" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lehtinen%2C+J" rel="noopener ugc nofollow" target="_blank"><em class="md">贾科莱蒂宁</em> </a> <em class="md"/></p><p id="fce4" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">【4】<a class="ae nm" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Brunner%2C+G" rel="noopener ugc nofollow" target="_blank"><em class="md">吉诺·布鲁纳</em></a><em class="md"/><a class="ae nm" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Y" rel="noopener ugc nofollow" target="_blank"><em class="md">【王】</em></a><em class="md"/><a class="ae nm" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wattenhofer%2C+R" rel="noopener ugc nofollow" target="_blank"><em class="md">罗杰·瓦滕霍夫</em></a><em class="md"/><a class="ae nm" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+S" rel="noopener ugc nofollow" target="_blank"><em class="md">苏穆·赵</em> </a> <em class="md">【象征性音乐流派转移用CycleGAN、</em></p><p id="8dd3" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><em class="md"/><a class="ae nm" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kaneko%2C+T" rel="noopener ugc nofollow" target="_blank"><em class="md">金子拓广</em></a><em class="md"/><a class="ae nm" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kameoka%2C+H" rel="noopener ugc nofollow" target="_blank"><em class="md">龟冈博和</em></a><em class="md"/><a class="ae nm" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tanaka%2C+K" rel="noopener ugc nofollow" target="_blank"><em class="md">田中寇</em></a><em class="md"/><a class="ae nm" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hojo%2C+N" rel="noopener ugc nofollow" target="_blank"><em class="md">信厚北藏</em> </a> <em class="md">。CycleGAN-VC2:改进的基于CycleGAN的非并行语音转换，</em><a class="ae nm" href="https://arxiv.org/abs/1904.04631" rel="noopener ugc nofollow" target="_blank"><em class="md">https://arxiv.org/abs/1904.04631</em></a></p></div></div>    
</body>
</html>