# 是什么让光变轻

> 原文：<https://towardsdatascience.com/what-makes-lightgbm-light-8eb4dc258046?source=collection_archive---------36----------------------->

## 速度很重要。

![](img/24672830e55e3633c3c302deab689fed.png)

照片由 [Shiro hatori](https://unsplash.com/@shiroscope?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 在 [Unsplash](https://unsplash.com/s/photos/fast?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上拍摄

梯度增强决策树(GBDT)是一种性能非常好的算法，它已经成为许多先进算法的基础，如 XGBoost、LightGBM 和 CatBoost。

在这篇文章中，我们将关注是什么让 LightGBM 变得又轻又快。LightGBM 是由微软的研究人员创建的，旨在建立一个比其他正在使用的 GDBT 更有效的实现。

让我们先简要讨论一下 GBDT 算法是如何工作的。我们将关注 LightGBM 的特别之处。

梯度提升意味着以这样一种方式顺序地组合弱学习器，即每个新学习器都符合来自前一步骤的残差。因此，每个新的学习者都会改进整个模型。最终的模型汇总了每一步的结果，从而形成了一个强学习者。在 GBDT 的例子中，弱学习者是决策树。

GBDT 的弱学习器决策树通过基于特征值分割观察值(即数据实例)来学习。该算法寻找将导致最高信息增益的最佳分割。

事实证明，寻找最佳分裂是决策树学习过程中最耗时的部分。GBDT 的先前实现使用预先排序或基于直方图的算法来寻找最佳分割。

*   预先排序:特征值预先排序，并评估所有可能的分割点。
*   基于直方图:连续特征被分成离散的箱，并创建特征直方图。

基于直方图的算法比预先排序的算法更有效。随着数据集在观测值和要素方面的增大，这两种方法的速度都会变慢。

LightGBM 从基于直方图的算法开始，因为它是更有效的算法。

基于直方图的算法的问题是扫描所有数据实例以找到关于信息增益的最佳分割。对每个特征都这样做。因此，基于直方图的算法的复杂性取决于数据实例和特征的数量。

为了解决这个问题，LightGBM 使用了两种技术:

*   梯度单侧采样
*   EFB(独家功能捆绑)

下面我们来详细介绍一下这些技术的作用，以及它们是如何让 LightGBM 变得“轻”的。

# 梯度单侧采样

扫描所有数据实例以找到最佳分割是一种蛮力，这肯定不是最佳的。我们需要找到一种方法，以某种方式根据信息增益对数据实例进行采样。

一种方法是根据权重对数据进行采样。但是，它不适用于 GBDT，因为在 GBDT 没有样品重量。

GOSS 采用的解决方案是使用梯度对数据进行采样。梯度告诉我们:

*   小梯度:该算法已经在这种情况下进行了训练，与此相关的误差很小。
*   大梯度:与该实例相关的误差很大，因此它将提供更多的信息增益。

梯度小的数据实例提供不了多少东西。因此，我们可以排除梯度小的实例，只关注梯度大的实例。但是，在这种情况下，数据分布将会改变。我们不希望这样，因为这将对学习模型的准确性产生负面影响。

GOSS 提供了一种基于梯度的数据采样方法，同时考虑了数据分布。

选择具有较大梯度的数据实例。从具有较小梯度的剩余数据实例中，仅选择随机样本。小梯度的随机样本乘以一个常数以保持数据分布。

如您所见，只对数据集的一部分进行了采样。这就是该算法被称为“单侧采样”的原因。

GOSS 最终实现的是，模型的重点倾向于导致更多损失(即训练不足)的数据实例，而不会对数据分布产生太大影响。

# EFB(独家功能捆绑)

简而言之，EFB 以一种新特征携带组合特征的信息的方式组合稀疏特征。

具有大量要素的数据集可能具有高稀疏性(即大量零值)。稀疏特征通常是互斥的，这意味着它们不会同时具有非零值。

例如，在典型的稀疏特征空间中，一行可能仅在一列中具有非零值(例如，编码文本数据)。

EFB 是一种使用贪婪算法将这些互斥特征组合(或捆绑)成单个特征(例如，互斥特征束)并因此降低维度的技术。

EFB 减少了 GDBT 的训练时间，而不太影响准确性，因为创建特征直方图的复杂性现在与束的数量而不是特征的数量成比例(束的数量远小于特征的数量)。

EFB 面临的挑战之一是找到最佳捆绑包。微软的研究人员设计了一种算法，将捆绑问题转化为图形着色问题。

在图着色问题中，将特征作为顶点，在不互斥的特征之间添加边。然后，使用贪婪算法来产生束。

更进一步，该算法还允许捆绑很少同时具有非零值(即几乎互斥)的特征。这意味着牺牲少量信息来加快训练速度。

捆绑的特性需要以智能的方式创建。考虑一组 3 个特性。捆绑特性的值应该能够为我们提供前 3 个特性的值。LightGBM 利用基于直方图的算法创建的离散箱。

包中特性的唯一值放在不同的容器中。这是通过向原始特征值添加偏移来实现的。

戈斯和 EFB 都让 LightGBM 快速运行，同时保持相当高的精确度。在一个典型的现实生活中，我们可能有大型数据集，所以效率和准确性一样重要。

感谢您的阅读。如果您有任何反馈，请告诉我。