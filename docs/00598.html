<html>
<head>
<title>Extracting the author of news stories with DOM-based segmentation and BERT</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于 DOM 分割和 BERT 的新闻故事作者抽取</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/extracting-the-author-of-news-stories-with-dom-based-segmentation-and-bert-69225ea0e5c2?source=collection_archive---------22-----------------------#2020-01-17">https://towardsdatascience.com/extracting-the-author-of-news-stories-with-dom-based-segmentation-and-bert-69225ea0e5c2?source=collection_archive---------22-----------------------#2020-01-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="c238" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何利用 Web2Text 的 HTML 特征生成框架和 HuggingFace Transformers 进行海量内容提取</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/8b17456c317ea797e0af593ac630716d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0LZYPmYpo2Zz-0HZzjonJQ.png"/></div></div></figure><p id="356b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">获得大量新闻故事的作者是令人生畏的。网页有不同的格式，一个完美的解决方案应该在所有情况下，当可用时，识别作者的全名。作者的名字有时会出现在标题的正下方，但有时会出现在文章的下方，或者几乎完全隐藏在不同的栏目中。作者的名字可能出现在<strong class="kt ir">的任何一种语言</strong>中，可能有也可能没有助词在里面，比如英语介词<strong class="kt ir"> <em class="ln"> by </em> </strong>。在某些情况下，有一个以上的作者，名字用<strong class="kt ir">逗号- </strong>或<strong class="kt ir"> <em class="ln">和- </em> </strong>分隔。</p><blockquote class="lo lp lq"><p id="3ead" class="kr ks ln kt b ku kv jr kw kx ky ju kz lr lb lc ld ls lf lg lh lt lj lk ll lm ij bi translated">基于<strong class="kt ir">试探法的解析器，</strong>也就是说，使用正则表达式和 bash 脚本来处理条件，在很多情况下都可以很好地工作。然而，一个好的解决方案应该推广到看不见的格式。例如，一些文章在文档中有给定名称的列表(链接到网站上的其他文章或其他元素)，这可能会产生歧义。</p></blockquote><p id="ca7e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">众所周知，分类器非常适合内容提取任务，因为它们可以查看多个上下文和布局特征。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lu"><img src="../Images/e248ac410c703968739e06cf23af614c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XDWgjDa-wYRJ7ZGimenu0A.png"/></div></div><p class="lv lw gj gh gi lx ly bd b be z dk translated">这篇来自<strong class="bd lz">卫报</strong>的文章在左栏有作者。字符串<strong class="bd lz">在巴黎</strong>指的是记者写文章的地点，而不是名字的一部分。</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ma"><img src="../Images/effd4fe2a45b2f8b7834d30555fffdb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*agaOxJaEY9TaUfdcUnpZ2A.png"/></div></div><p class="lv lw gj gh gi lx ly bd b be z dk translated">瑞典小报<strong class="bd lz"> Aftonbladet </strong>上的一篇新闻文章，通讯作者在左边。瑞典语中，<strong class="bd lz"> av </strong>放在作者姓名前，类似于英语中的 by<strong class="bd lz">。注意到第二列有一些名字(<strong class="bd lz">哈里王子</strong>、<strong class="bd lz">梅根汗·马克尔</strong>等等。)，这可能会被误认为是文章的作者。这个标题也包含了一个名字(<strong class="bd lz"> Prins Phillip </strong>)，同样不是作者。</strong></p></figure><h1 id="7ba7" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">获取培训示例</h1><p id="6b67" class="pw-post-body-paragraph kr ks iq kt b ku mt jr kw kx mu ju kz la mv lc ld le mw lg lh li mx lk ll lm ij bi translated">我使用了 Andrew Thompson 的<a class="ae my" href="https://www.kaggle.com/snapcrack/all-the-news" rel="noopener ugc nofollow" target="_blank">All News</a>数据集(其中有来自 15 家美国出版物的 73，000 篇文章，带有 URL 和作者)。新闻文章的时间跨度为 2015 年至 2017 年。<a class="ae my" href="https://archive.org/" rel="noopener ugc nofollow" target="_blank">Archive.org</a>以其原始格式存储了大约 27000 篇新闻文章，其他的都在他们原来的新闻网站上。抓取所有链接大概花了三天时间(4.1 GB 压缩数据)。</p><p id="bff8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">因为报纸每隔一段时间就会改变他们的网站结构，所以语料库涵盖的不同案例的数量是未知的(但可以说是很少的)。收集和手动标记其他新闻渠道的更多培训示例以涵盖更多案例应该相当容易。</p><h1 id="b8b3" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">概观</h1><p id="b82b" class="pw-post-body-paragraph kr ks iq kt b ku mt jr kw kx mu ju kz la mv lc ld le mw lg lh li mx lk ll lm ij bi translated">流水线包含三个步骤:一个<strong class="kt ir">预处理器</strong>，一个<strong class="kt ir">分类器</strong>，以及<strong class="kt ir">命名实体识别</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mz"><img src="../Images/3d5490932e45b8f9dab8e6cbb589c1ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZLDgm1m45ptxp05ElDDWqw.png"/></div></div><p class="lv lw gj gh gi lx ly bd b be z dk translated">端到端作者提取器管道</p></figure><h1 id="c3d1" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">预处理程序</h1><p id="c418" class="pw-post-body-paragraph kr ks iq kt b ku mt jr kw kx mu ju kz la mv lc ld le mw lg lh li mx lk ll lm ij bi translated">我使用了论文<a class="ae my" href="https://arxiv.org/pdf/1801.02607.pdf" rel="noopener ugc nofollow" target="_blank">web 2 text:Deep Structured Boilerplate Removal</a>(<a class="ae my" href="https://github.com/dalab/web2text" rel="noopener ugc nofollow" target="_blank">Github repo</a>)中的预处理器。</p><blockquote class="lo lp lq"><p id="183d" class="kr ks ln kt b ku kv jr kw kx ky ju kz lr lb lc ld ls lf lg lh lt lj lk ll lm ij bi translated">Web2Text 可以为兼容和不兼容的 HTML 构建一个 DOM 树。它有逻辑来清理已知包含非信息数据的 DOM 节点，向下遍历 DOM 树并折叠单个子节点及其各自的子节点。</p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi na"><img src="../Images/61bf10803f0587608b08e309a06e7110.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Jdq5vEJk1swfOQCcGU5Eg.png"/></div></div><p class="lv lw gj gh gi lx ly bd b be z dk translated">(来源:Web2Text)</p></figure><p id="bee9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">该模型的训练示例是 HTML 文件的 DOM 节点。每个 HTML 文件平均有 138 个 DOM 节点。因此，该数据集总共包含 m = 73K * 138 = 101M 个训练示例。平均而言，代码需要 127 毫秒将每个 HTML 文件转换为 CSV 特征表示文件，其中每行代表一个特征，每列是一个 DOM 节点(运行在 1.7GHz 双核 i7 和 8GB DDR3 内存上)。</p><p id="e2b8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">主类<code class="fe nb nc nd ne b">ExtractPageFeatures</code>将一个原始 HTML 文件作为输入，并生成一个 CSV 文件，该文件具有去除样板文件的功能。我修改了这段代码，并创建了更适合作者提取任务的新特性。编译 Scala 项目后，您可以在任何 HTML 文件上运行:</p><pre class="kg kh ki kj gt nf ne ng nh aw ni bi"><span id="5531" class="nj mc iq ne b gy nk nl l nm nn">&gt; ./extract_page_features.sh  &lt;input_html_file&gt;</span></pre><p id="c356" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们以数据集中的一个文本为例:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/9c2cc5ef8614f14022ae82ccba373368.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vn1N-ilnmUlY9wZoTJ37jA.png"/></div></div></figure><p id="518a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">算法通过路由<code class="fe nb nc nd ne b">header -&gt; div -&gt; div -&gt; h2 / a</code>到达令牌<em class="ln">政治</em> (8 个字符)。注意<code class="fe nb nc nd ne b">&lt;h2&gt;</code>和<code class="fe nb nc nd ne b">&lt;a&gt;</code>是如何折叠成一片叶子的。</p><p id="cda6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">对于每个折叠的 DOM (CDOM)节点，Web2Text 构建一个特征向量:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi np"><img src="../Images/ca8c29e524308123f369ed702c6e5fb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*T0GYTdYsQKI0jZtKO_0-4w.gif"/></div></div><p class="lv lw gj gh gi lx ly bd b be z dk translated">Web2Text 允许您将 CDOM 树输出到 HTML 文件中，以便您可以看到每个节点的特征。</p></figure><p id="ea9f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Web2Text 附带了一组 128 个预定义的特性:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/ad71a2d590afc259827227a71904d948.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fuQ9gsv73XnKejTa9bvArQ.png"/></div></div><p class="lv lw gj gh gi lx ly bd b be z dk translated">Web2Text 的开箱即用特性(来源:Web2Text)</p></figure><p id="da53" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">功能存在于以下级别:</p><ul class=""><li id="d0b1" class="nr ns iq kt b ku kv kx ky la nt le nu li nv lm nw nx ny nz bi translated">叶子</li><li id="779d" class="nr ns iq kt b ku oa kx ob la oc le od li oe lm nw nx ny nz bi translated">父母</li><li id="dc65" class="nr ns iq kt b ku oa kx ob la oc le od li oe lm nw nx ny nz bi translated">祖父或祖母</li><li id="fc59" class="nr ns iq kt b ku oa kx ob la oc le od li oe lm nw nx ny nz bi translated">根</li></ul><p id="1973" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">预处理器使用<strong class="kt ir"><em class="ln"/></strong>对后代特征进行求和(对整数)，或者使用<strong class="kt ir"> <em class="ln">或</em> </strong>(对布尔值)来计算祖先级特征(父级、祖父级或根级)。例如，如果有两个兄弟节点，一个有电子邮件地址，另一个没有，预处理器会将公共父节点标记为包含电子邮件。</p><p id="e47c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在作者提取任务中使用祖先级别的数据捕获功能非常方便，因为在许多新闻网站中，作者姓名和出版日期(有时还有作者的社交媒体资料)被小方框包围。该信息可以帮助分类器学习识别哪些块包含作者。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi of"><img src="../Images/13a99aa3d205de16e8e48779ab883510.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZKDiUMs0TOLuS4JQQ2rfog.png"/></div></div><p class="lv lw gj gh gi lx ly bd b be z dk translated">在这个来自纽约时报的例子中，预处理器将包含作者的节点标记为在祖先层有一个 T21 日期字段。</p></figure><h2 id="4b38" class="nj mc iq bd md og oh dn mh oi oj dp ml la ok ol mn le om on mp li oo op mr oq bi translated">特征工程</h2><p id="0cb4" class="pw-post-body-paragraph kr ks iq kt b ku mt jr kw kx mu ju kz la mv lc ld le mw lg lh li mx lk ll lm ij bi translated">作者提取任务用一些额外的特性扩展了 Web2Text(出于性能原因，仅当<code class="fe nb nc nd ne b">2&lt;=nWords&lt;=5</code>时才运行检查):</p><ul class=""><li id="69b9" class="nr ns iq kt b ku kv kx ky la nt le nu li nv lm nw nx ny nz bi translated"><code class="fe nb nc nd ne b">contains_popular_name</code>:如果 CDOM 节点包含 1880-2008 年期间美国每年 1000 个最常见婴儿名字的<a class="ae my" href="https://github.com/hadley/data-baby-names" rel="noopener ugc nofollow" target="_blank">数据集</a>中的一个名字，则为真。在任何一年，它涵盖了美国 80%的男孩和 67%的女孩的名字(68k 的重复数据删除记录)。(注意:这一部分使用了字符串比较。这个特性的一个更好的解决方案将涉及单词嵌入或者可能是 BERT 或它的后继者)。</li><li id="3967" class="nr ns iq kt b ku oa kx ob la oc le od li oe lm nw nx ny nz bi translated"><code class="fe nb nc nd ne b">contains_author_particle</code>:如果 CDOM 节点包含粒子<em class="ln"> by </em>或<em class="ln"> and，则为真。</em></li><li id="56f7" class="nr ns iq kt b ku oa kx ob la oc le od li oe lm nw nx ny nz bi translated"><code class="fe nb nc nd ne b">contains_author_url</code>:如果节点包含格式为<code class="fe nb nc nd ne b">http[s]://[something]/author/[something</code>的 URL，则为真。许多报纸都包含一个链接，链接到一个包含作者传记的页面，或者一个包含同一作者的其他文章的页面，并带有这种格式的链接。</li></ul><p id="ec72" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我很兴奋地得知我可以使用 Web2Text 的一些标准特性来捕获与我的任务相关的信息:</p><ul class=""><li id="dd81" class="nr ns iq kt b ku kv kx ky la nt le nu li nv lm nw nx ny nz bi translated"><code class="fe nb nc nd ne b">contains_two_capitalized_words</code>:包含至少两个大写单词(<em class="ln">无名氏</em>、<em class="ln">无名氏</em> ) (Web2Text 的特性<code class="fe nb nc nd ne b">b20</code>、<code class="fe nb nc nd ne b">b21</code>、<code class="fe nb nc nd ne b">b22</code>)</li><li id="4dcc" class="nr ns iq kt b ku oa kx ob la oc le od li oe lm nw nx ny nz bi translated"><code class="fe nb nc nd ne b">at_least_two_words</code>:包含至少两个单词(由 Web2Text 特征<code class="fe nb nc nd ne b">b5</code>捕获)</li><li id="fd5a" class="nr ns iq kt b ku oa kx ob la oc le od li oe lm nw nx ny nz bi translated"><code class="fe nb nc nd ne b">contains_date</code>:合理距离内的节点包含日期。这是由父级或祖父级的<code class="fe nb nc nd ne b">contains_year</code>特性(<code class="fe nb nc nd ne b">b19</code>)捕获的。</li></ul><p id="c2b8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">扩展该模型的一些非常有趣的特性是:</p><ul class=""><li id="a133" class="nr ns iq kt b ku kv kx ky la nt le nu li nv lm nw nx ny nz bi translated">呈现的 HTML 字体大小</li><li id="8ce7" class="nr ns iq kt b ku oa kx ob la oc le od li oe lm nw nx ny nz bi translated">祖先节点包含到社交媒体的链接</li><li id="f862" class="nr ns iq kt b ku oa kx ob la oc le od li oe lm nw nx ny nz bi translated"><code class="fe nb nc nd ne b">number_of_sibling_nodes</code>:同胞 CDOM 叶数。捕捉名称可以是链接列表的一部分的事实，如前面看到的 Aftonbladet 的例子。</li><li id="5d4b" class="nr ns iq kt b ku oa kx ob la oc le od li oe lm nw nx ny nz bi translated">确定文章使用的语言，因为该模型依赖于大写字母、英语日期格式和一系列英语名字。</li></ul><h1 id="cd5f" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">分类</h1><p id="8e48" class="pw-post-body-paragraph kr ks iq kt b ku mt jr kw kx mu ju kz la mv lc ld le mw lg lh li mx lk ll lm ij bi translated">Web2Text 的架构使用卷积神经网络，然后是隐藏马尔可夫模型，分别计算块和相邻块对上的一元和成对势。然而，在我们的例子中，我们希望每页最多找到一个包含作者姓名的块，所以我将这个问题构建为一个包含两个类的二进制分类器:<code class="fe nb nc nd ne b">{contains_author, not_contains_author}</code>，并选择了最小化二进制交叉熵损失的块。实际模型是一个简单的<strong class="kt ir">神经网络</strong> (1 个隐含层；140 个隐藏单元)</p><h1 id="42a1" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">分类结果</h1><h2 id="9997" class="nj mc iq bd md og oh dn mh oi oj dp ml la ok ol mn le om on mp li oo op mr oq bi translated">超参数</h2><p id="c35f" class="pw-post-body-paragraph kr ks iq kt b ku mt jr kw kx mu ju kz la mv lc ld le mw lg lh li mx lk ll lm ij bi translated"><strong class="kt ir">分析的 HTML 文件数量:</strong>15000【717414<strong class="kt ir">训练示例(DOM 节点)</strong>；<strong class="kt ir">历元:</strong>50；<strong class="kt ir">批量大小:</strong> 50 档；<strong class="kt ir">学习率:</strong>0.0001；<strong class="kt ir">辍学率:</strong>0.2；<strong class="kt ir">培训/开发/测试分割</strong> : 60%/20%/20%。</p><h2 id="4fc7" class="nj mc iq bd md og oh dn mh oi oj dp ml la ok ol mn le om on mp li oo op mr oq bi translated">关键指标</h2><p id="03f6" class="pw-post-body-paragraph kr ks iq kt b ku mt jr kw kx mu ju kz la mv lc ld le mw lg lh li mx lk ll lm ij bi translated"><strong class="kt ir">准确率:</strong>99.93%；<strong class="kt ir">精度:</strong>91.30%；<strong class="kt ir">召回:</strong>95.40%；<strong class="kt ir">F1-得分:</strong> 93.31%。</p><p id="8734" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">培训时间:</strong> 8.3 小时</p><h2 id="5b70" class="nj mc iq bd md og oh dn mh oi oj dp ml la ok ol mn le om on mp li oo op mr oq bi translated">混淆矩阵</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi or"><img src="../Images/63c2e11be90eb0d388d10135e17045b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*n4DmcLkdKNkFdAfY0eVJTA.png"/></div></figure><p id="2d93" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在<code class="fe nb nc nd ne b">/public/trained_model_all_the_news/</code>，训练模型的权重存储在我们的存储库中。</p><h1 id="fddd" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">推理</h1><p id="1d23" class="pw-post-body-paragraph kr ks iq kt b ku mt jr kw kx mu ju kz la mv lc ld le mw lg lh li mx lk ll lm ij bi translated">该模型在推理期间执行两个步骤:</p><p id="6c40" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">1.-对 HTML 文档运行<strong class="kt ir">训练好的神经网络</strong>，选择代价最小的 DOM 块。</p><p id="4d95" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">2.-运行一个<strong class="kt ir"> BERT 命名实体识别器</strong>，从块中提取所有人名。这个模型使用 HuggingFace Transformer 对<strong class="kt ir"> BERT (Large，cased)</strong><a class="ae my" href="https://huggingface.co/bert-large-cased-finetuned-conll03-english" rel="noopener ugc nofollow" target="_blank"><strong class="kt ir">链接到模型</strong> </a> <strong class="kt ir"> </strong>的实现，并将一个句子中的每个标记标记为属于四种类型:<em class="ln"> Person </em>、<em class="ln"> MISC </em>、<em class="ln"> Organization </em>和<em class="ln"> Location </em>，使用标准的<a class="ae my" href="https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)" rel="noopener ugc nofollow" target="_blank"> IOB 格式</a>。对于作者提取任务，只有人名(<code class="fe nb nc nd ne b">PER</code>标签)是相关的。该模型使用用于命名实体识别的标准数据集<strong class="kt ir"> CoNLL-2003 </strong> ⁵数据集进行微调。</p><p id="80a1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最后，您可以运行以下命令来预测新闻文章的作者姓名:</p><pre class="kg kh ki kj gt nf ne ng nh aw ni bi"><span id="e4d7" class="nj mc iq ne b gy nk nl l nm nn">&gt; ./inference_from_url.sh <a class="ae my" href="https://www.theguardian.com/us-news/2016/jul/13/alton-sterling-son-cameron-protesters-baton-rouge" rel="noopener ugc nofollow" target="_blank">https://www.theguardian.com/us-news/2016/jul/13/alton-sterling-son-cameron-protesters-baton-rouge</a></span><span id="f05d" class="nj mc iq ne b gy os nl l nm nn">The Author Name is: Jessica Glenza.</span></pre></div><div class="ab cl ot ou hu ov" role="separator"><span class="ow bw bk ox oy oz"/><span class="ow bw bk ox oy oz"/><span class="ow bw bk ox oy"/></div><div class="ij ik il im in"><h1 id="2720" class="mb mc iq bd md me pa mg mh mi pb mk ml jw pc jx mn jz pd ka mp kc pe kd mr ms bi translated">贮藏室ˌ仓库</h1><p id="9041" class="pw-post-body-paragraph kr ks iq kt b ku mt jr kw kx mu ju kz la mv lc ld le mw lg lh li mx lk ll lm ij bi translated"><a class="ae my" href="https://github.com/canetcesc/AuthorExtractor" rel="noopener ugc nofollow" target="_blank">https://github.com/canetcesc/AuthorExtractor</a></p><h1 id="52dd" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">参考</h1><p id="c791" class="pw-post-body-paragraph kr ks iq kt b ku mt jr kw kx mu ju kz la mv lc ld le mw lg lh li mx lk ll lm ij bi translated">[1]沃格尔斯、加内亚和埃克霍夫。"<a class="ae my" href="https://arxiv.org/abs/1801.02607" rel="noopener ugc nofollow" target="_blank"> Web2text:深度结构化样板去除</a>(2018)<em class="ln">欧洲信息检索会议</em>。斯普林格，查姆。</p><p id="0456" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">[2]周和马舒克。"<a class="ae my" href="https://pdfs.semanticscholar.org/a355/13ebc494326f7ba0141b718b08cbb3a7dff7.pdf" rel="noopener ugc nofollow" target="_blank">通过机器学习进行网页内容抽取</a>(2014)<em class="ln">斯坦福大学</em>。</p><p id="c469" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">[3]姚和左。<a class="ae my" href="http://cs229.stanford.edu/proj2013/YaoZuo-AMachineLearningApproachToWebpageContentExtraction.pdf" rel="noopener ugc nofollow" target="_blank">网页内容提取的一种机器学习方法</a>(2013)S<em class="ln">坦福德大学</em>。</p><p id="f896" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">[4] J. Devlin、M.W. Chang、K. Lee 和 K. Toutanova。"<a class="ae my" href="https://arxiv.org/abs/1810.04805" rel="noopener ugc nofollow" target="_blank"> Bert:用于语言理解的深度双向变换器的预训练</a>(2018)<em class="ln">arXiv 预印本 arXiv:1810.04805 </em>。</p><p id="5110" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">[5]桑和德默德。<a class="ae my" href="https://arxiv.org/abs/cs/0306050" rel="noopener ugc nofollow" target="_blank">CoNLL-2003 共享任务介绍:独立于语言的命名实体识别</a>(2003)<em class="ln">arXiv 预印本 cs/0306050 </em>。</p><h1 id="ee60" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">感谢</h1><p id="55f5" class="pw-post-body-paragraph kr ks iq kt b ku mt jr kw kx mu ju kz la mv lc ld le mw lg lh li mx lk ll lm ij bi translated">非常感谢<a class="ae my" href="http://hypefactors.com" rel="noopener ugc nofollow" target="_blank">催眠师</a>为这篇文章提供了想法。Hypefactors 是一个面向媒体专业人士的平台，其管道中的一个组件是识别每天数百万篇新闻文章的作者。这篇文章是由他们的真实业务需求所激发的，尽管实现可能有所不同。</p><p id="b3b5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">剪贴画由<a class="ae my" href="http://www.freepik.com" rel="noopener ugc nofollow" target="_blank">工作室</a>提供。</p></div></div>    
</body>
</html>