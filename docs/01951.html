<html>
<head>
<title>Realtime video object detection on Raspberry Pi</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Raspberry Pi上的实时视频对象检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-stream-video-with-real-time-object-detection-on-raspberry-pi-f6503c46c7f9?source=collection_archive---------7-----------------------#2020-02-24">https://towardsdatascience.com/how-to-stream-video-with-real-time-object-detection-on-raspberry-pi-f6503c46c7f9?source=collection_archive---------7-----------------------#2020-02-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f14c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用OpenCV、专用硬件和云技术实现快速检测</h2></div><p id="7e19" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最近，一段来自特斯拉autopilot view的视频出现在互联网上，并非常受欢迎。我对一个类似的视频流(带有检测到的物体)很感兴趣，这个演示最终让我做了一些工作。</p><p id="8d25" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">唯一的问题是我想从Raspberry Pi流视频，但总的来说，它不够强大，无法执行这样的任务。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/d134df747959a40a41812684bde89842.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nLNYaOes_DUcuBI1G15c4A.jpeg"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">检测到物体的图像</p></figure><h2 id="ebef" class="lu lv it bd lw lx ly dn lz ma mb dp mc kr md me mf kv mg mh mi kz mj mk ml mm bi translated">树莓上的OpenCV</h2><p id="8395" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">最直接的实现是通过OpenCV-DNN在Raspberry Pi上运行一个检测器。</p><p id="bad9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">OpenCV-DNN支持多种网络和格式，但我以前用的是Google 的<a class="ae ms" href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_11_06_2017.tar.gz" rel="noopener ugc nofollow" target="_blank">MobileSSD(11 _ 06 _ 2017版本，最新的不兼容OpenCV 4.2)。</a></p><p id="f2be" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，读取类名并加载模型:</p><pre class="lf lg lh li gt mt mu mv mw aw mx bi"><span id="4011" class="lu lv it mu b gy my mz l na nb">tf_labels.initLabels(dnn_conf.DNN_LABELS_PATH)</span><span id="8d4e" class="lu lv it mu b gy nc mz l na nb">net = cv.dnn.readNetFromTensorflow(dnn_conf.DNN_PATH,         dnn_conf.DNN_TXT_PATH)</span></pre><p id="fc8d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后对一个图像运行推理:def推理(img):<br/>net . set input(cv . dnn . blobfromimage(img，1.0/127.5，(300，300)，(127.5，127.5，127.5)，swapRB=True，crop = False))<br/>return net . forward()</p><p id="6472" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个操作在树莓上需要1.7秒。例如，我的漂亮的旧笔记本电脑在0.2秒内完成同样的工作。</p><p id="a3c7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">将输出张量转换为人类友好的JSON:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/d134df747959a40a41812684bde89842.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nLNYaOes_DUcuBI1G15c4A.jpeg"/></div></div></figure><pre class="lf lg lh li gt mt mu mv mw aw mx bi"><span id="67b5" class="lu lv it mu b gy my mz l na nb">def build_detection(data, thr, rows, cols):    <br/>    ret = []     <br/>    for detection in data[0,0,:,:]:         <br/>        score = float(detection[2])         <br/>        if score &gt; thr:             <br/>            cls = int(detection[1])             <br/>            a = {"class" : cls, "name" : tf_labels.getLabel(cls),  "score" : score}             <br/>            a["x"] = int(detection[3] * cols)             <br/>            a["y"] = int(detection[4] * rows)<br/>            a["w"] = int(detection[5] * cols ) - a["x"]                        a["h"] = int(detection[6] * rows) - a["y"]             <br/>            ret.append(a)     <br/>    return ret</span></pre><p id="7222" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">考虑到测量，很明显原生树莓性能(1.7秒)对于任何视频都是不够的。</p><p id="170e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但是让Raspberry与笔记本电脑配合使用应该会提高处理帧的整体能力。</p><h2 id="fc2a" class="lu lv it bd lw lx ly dn lz ma mb dp mc kr md me mf kv mg mh mi kz mj mk ml mm bi translated">笔记本电脑原型</h2><p id="3e59" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">现在用一个REST接口把检测器包起来。</p><p id="00fa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为此，我通常使用烧瓶。获得<a class="ae ms" href="https://github.com/tprlab/docker-detect/blob/master/detect-app/app.py" rel="noopener ugc nofollow" target="_blank">服务</a>有两个切入点:</p><ul class=""><li id="6281" class="nd ne it kk b kl km ko kp kr nf kv ng kz nh ld ni nj nk nl bi translated">第一个返回JSON中的检测</li><li id="b093" class="nd ne it kk b kl nm ko nn kr no kv np kz nq ld ni nj nk nl bi translated">第二个返回带有检测到的矩形和标签的图像</li></ul><p id="31d5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第二种方法给出了检测结果，简单明了:</p><pre class="lf lg lh li gt mt mu mv mw aw mx bi"><span id="c86e" class="lu lv it mu b gy my mz l na nb">curl -X POST -F "file=@pic.jpg" <a class="ae ms" href="http://192.168.1.243/" rel="noopener ugc nofollow" target="_blank">h</a>ost:80/ddetect --output a.jpg</span></pre><h2 id="f001" class="lu lv it bd lw lx ly dn lz ma mb dp mc kr md me mf kv mg mh mi kz mj mk ml mm bi translated">码头工人</h2><p id="4758" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">我们想要一个可扩展和可移植的解决方案，然后将服务打包到docker映像中。</p><p id="72dd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">选择Debian Stretch + Python作为基础映像，保留与Raspbian类似的堆栈。</p><p id="c4f2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">需要设置flask，protobuf，requests，opencv_python，从GitHub下载移动SSD和服务器代码。</p><pre class="lf lg lh li gt mt mu mv mw aw mx bi"><span id="202f" class="lu lv it mu b gy my mz l na nb">FROM python:3.7-stretch</span><span id="77bc" class="lu lv it mu b gy nc mz l na nb">RUN pip3 install flask<br/>RUN pip3 install protobuf<br/>RUN pip3 install requests<br/>RUN pip3 install opencv_python</span><span id="ca8c" class="lu lv it mu b gy nc mz l na nb">ADD <a class="ae ms" href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_11_06_2017.tar.gz" rel="noopener ugc nofollow" target="_blank">http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_11_06_2017.tar.gz</a> /<br/>RUN tar -xvf /ssd_mobilenet_v1_coco_11_06_2017.tar.gz</span><span id="2e74" class="lu lv it mu b gy nc mz l na nb">ADD <a class="ae ms" href="https://github.com/tprlab/docker-detect/archive/master.zip" rel="noopener ugc nofollow" target="_blank">https://github.com/tprlab/docker-detect/archive/master.zip</a> /<br/>RUN unzip /master.zip</span><span id="88ee" class="lu lv it mu b gy nc mz l na nb">EXPOSE 80</span><span id="1903" class="lu lv it mu b gy nc mz l na nb">CMD ["python3", "/docker-detect-master/detect-app/app.py"]</span></pre><p id="1f10" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了与第三方提供商一起使用该图像，需要将其发布到一些公共docker注册表上。</p><p id="0851" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我决定用传统的方式使用Docker Hub。</p><ul class=""><li id="ca40" class="nd ne it kk b kl km ko kp kr nf kv ng kz nh ld ni nj nk nl bi translated">创建一个帐户</li><li id="7941" class="nd ne it kk b kl nm ko nn kr no kv np kz nq ld ni nj nk nl bi translated">使用DockerHub: <strong class="kk iu"> docker登录</strong>授权本地docker</li><li id="b3fa" class="nd ne it kk b kl nm ko nn kr no kv np kz nq ld ni nj nk nl bi translated">给图像命名:<strong class="kk iu"> docker标签&lt;local _ image _ name&gt;TPR lab/opencv-detect-SSD</strong></li><li id="acf7" class="nd ne it kk b kl nm ko nn kr no kv np kz nq ld ni nj nk nl bi translated">上传图片:<strong class="kk iu"> docker推送tprlab/opencv-detect-ssd </strong></li></ul><p id="dfb4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，该映像可以用于许多容器提供商，如Google Cloud、Microsoft Azure、Amazon Web Services、Digital Ocean、Heroku等。</p><h2 id="e73e" class="lu lv it bd lw lx ly dn lz ma mb dp mc kr md me mf kv mg mh mi kz mj mk ml mm bi translated">录像</h2><p id="cc6d" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">使用<a class="ae ms" href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html" rel="noopener ugc nofollow" target="_blank"> OpenCV示例，</a>制作一个基本服务器:</p><pre class="lf lg lh li gt mt mu mv mw aw mx bi"><span id="73bb" class="lu lv it mu b gy my mz l na nb">def handle_frame(frame):<br/>    return detect.detect_draw_img(frame)<br/>       <br/>def generate():<br/>    while True:<br/>        rc, frame = vs.read()<br/>        outFrame = handle_frame(frame)<br/>        if outFrame is None:<br/>            (rc, outFrame) = cv.imencode(".jpg", frame)<br/>        yield(b'--frame\r\n' b'Content-Type: image/jpeg\r\n\r\n' + bytearray(outFrame) + b'\r\n')</span><span id="3801" class="lu lv it mu b gy nc mz l na nb"><a class="ae ms" href="http://twitter.com/app" rel="noopener ugc nofollow" target="_blank">@app</a>.route("/stream")<br/>def video_feed():<br/>    return Response(generate(), mimetype = "multipart/x-mixed-replace; boundary=frame")</span></pre><p id="11e6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">随着docker部署在笔记本电脑上，视频以慢动作播放。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/4721dfd5a03bcb43eeeb293775ae1eee.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/1*6o9h6Q6SF3DHbUu0_CTg2A.gif"/></div></figure><h2 id="ccec" class="lu lv it bd lw lx ly dn lz ma mb dp mc kr md me mf kv mg mh mi kz mj mk ml mm bi translated">谷歌云</h2><p id="61e4" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">到目前为止，单个码头工人是不够的。让它伸缩——在这种情况下，我们将能够同时处理多个帧。</p><p id="2e59" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我选择GCloud作为Kubernetes的服务提供商，并在5个实例中运行<a class="ae ms" href="https://hub.docker.com/r/tprlab/opencv-detect-ssd" rel="noopener ugc nofollow" target="_blank">我的映像</a>。</p><p id="3570" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">服务器代码变得更加复杂:</p><pre class="lf lg lh li gt mt mu mv mw aw mx bi"><span id="a840" class="lu lv it mu b gy my mz l na nb">def generate():<br/>    while True:<br/>        rc, frame = vs.read()<br/>        if frame is not None:<br/>            future = executor.submit(handle_frame, (frame.copy()))<br/>            Q.append(future)<br/>keep_polling = len(Q) &gt; 0<br/>        while(keep_polling):            <br/>            top = Q[0]<br/>            if top.done():<br/>                outFrame = top.result()<br/>                Q.popleft()<br/>                if outFrame:<br/>                    print("Frame", datetime.datetime.now())<br/>                    yield(b'--frame\r\n' b'Content-Type: image/jpeg\r\n\r\n' + bytearray(outFrame) + b'\r\n')<br/>                keep_polling = len(Q) &gt; 0<br/>            else:<br/>                keep_polling = len(Q) &gt;= M</span></pre><p id="8285" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这种方法有助于以大约10 fps的速度传输检测到的视频。</p><p id="827d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">还有提高速度的空间——只需在我们的Kubernetes集群中添加更多节点。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/23a4b97fdf6c6db7d516f60f5415549e.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/1*ekiVCrIXrRWR9NX4KilqGw.gif"/></div></figure><h2 id="012e" class="lu lv it bd lw lx ly dn lz ma mb dp mc kr md me mf kv mg mh mi kz mj mk ml mm bi translated">英特尔神经计算棒</h2><p id="1051" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">在进行了远程检测实验后，我决定尝试本地硬件解决方案。</p><p id="c7e5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我有一台英特尔NCS，已经在<a class="ae ms" rel="noopener" target="_blank" href="/robot-tank-with-raspberry-pi-and-intel-neural-computer-stick-2-77263ca7a1c7">类似任务</a>中使用过。</p><p id="d848" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以我把MobileSSD转换成OpenVino格式，用NCS检测器运行视频流。</p><p id="e1e8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">NCS很好地完成了这项工作——FPS略高于10，优于5节点Kubernetes集群。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/4198149d5560033a6e2287b848611012.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/1*kLPowrRfQgK-GeKCZ6Ikfg.gif"/></div></figure><h2 id="d590" class="lu lv it bd lw lx ly dn lz ma mb dp mc kr md me mf kv mg mh mi kz mj mk ml mm bi translated">结论</h2><p id="fe0c" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">最终，使用外部电源进行接近实时的检测被证明是可能的。</p><p id="d4cf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用NCS是最简单(也是最便宜)的方法——一次性购买，用最简单的代码工作很长时间。</p><p id="5b45" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">docker方式更复杂，但也更具可伸缩性、可移植性和可重用性。</p><h2 id="25e7" class="lu lv it bd lw lx ly dn lz ma mb dp mc kr md me mf kv mg mh mi kz mj mk ml mm bi translated">链接</h2><ul class=""><li id="3d99" class="nd ne it kk b kl mn ko mo kr ns kv nt kz nu ld ni nj nk nl bi translated">带有docker文件和源代码的<a class="ae ms" href="https://github.com/tprlab/docker-detect" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a></li><li id="90f4" class="nd ne it kk b kl nm ko nn kr no kv np kz nq ld ni nj nk nl bi translated">Docker Hub上准备就绪的<a class="ae ms" href="https://hub.docker.com/r/tprlab/opencv-detect-ssd" rel="noopener ugc nofollow" target="_blank"> docker图像</a></li></ul></div></div>    
</body>
</html>