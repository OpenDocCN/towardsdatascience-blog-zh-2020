<html>
<head>
<title>Natural Language Processing with Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Spark 自然语言处理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/natural-language-processing-with-spark-9efef3564270?source=collection_archive---------23-----------------------#2020-01-06">https://towardsdatascience.com/natural-language-processing-with-spark-9efef3564270?source=collection_archive---------23-----------------------#2020-01-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0325" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">利用 PySpark MLlib 对灾难推文进行分类(文本分类)</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9f919cc5f5a04aa2033287e7e682bdef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jKnN5UioFBompgcF"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">西蒙·马辛格在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="7b93" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是一个关于使用 PySpark 开发预测机器学习模型的介绍性教程。我将展示自然语言处理(NLP)的基础，同时利用 Spark 的强大功能。我们会用 PySpark 这是一个用于 Spark 的 Python API。本教程的数据集来自于<em class="lv"/><a class="ae ky" href="https://www.kaggle.com/c/nlp-getting-started" rel="noopener ugc nofollow" target="_blank">【NLP with Disaster Tweets】ka ggle 竞赛。</a>GitHub 上有完整的代码。</p><p id="b8d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些数据由推文组成，我们的任务是预测哪些推文与灾难有关。这可以改善几个相关方的响应时间，例如警察部队、消防队或新闻机构等。我们将通过建立预测机器学习模型来执行文本分类，这是 NLP 的一个类别。下面的算法可以帮助你在文本分析或自然语言处理中得到启发，并且有很多应用。</p><blockquote class="lw lx ly"><p id="e56f" class="kz la lv lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">文本分类是根据文本的内容给文本分配标签或类别的过程。它是自然语言处理的基本任务之一，具有广泛的应用，如情感分析、主题标注、垃圾邮件检测和意图检测。—来自<a class="ae ky" href="https://monkeylearn.com/text-classification/" rel="noopener ugc nofollow" target="_blank"> Monkeylearn </a></p></blockquote><p id="6795" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们马上开始研究数据吧。为此，我们需要了解一下<a class="ae ky" href="https://spark.apache.org/docs/latest/sql-programming-guide.html" rel="noopener ugc nofollow" target="_blank">火花数据帧</a>。现在，我们需要在 Python 中启动一个 Spark 会话来使用 Spark。我们使用以下命令启动会话，appName 参数，即“nlp”在这种情况下可以由用户选择。</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="dbb0" class="mh mi it md b gy mj mk l ml mm">spark = SparkSession.builder.appName('nlp').getOrCreate()</span></pre><p id="d523" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦我们开始 Spark 会话，我们将使用' spark.read.csv '函数加载数据。将数据文件加载到工作空间后，我们需要对文本数据进行预处理。数据帧的头部如下图所示。我们将处理<em class="lv">‘文本’</em>字段，以预测<em class="lv">‘目标’</em>字段。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mn"><img src="../Images/53743c47b6fe872c178aab1a41ad2124.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Mqj5nZgax8oOTG0OsPKpg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">推文数据的最高记录</p></figure><h2 id="b95f" class="mh mi it bd mo mp mq dn mr ms mt dp mu li mv mw mx lm my mz na lq nb nc nd ne bi translated">数据预处理(提取特征)</h2><p id="75a5" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">以下工作流详细介绍了从数据中提取要素的过程。每个阶段的描述都跟在图像后面。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/0894c31bd33085be330bfb4b587fcd08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qh9CnIYv2m858snlxCeN1Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">用于特征提取的数据处理工作流程</p></figure><p id="7f02" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 1)删除空值:</strong>我们删除文本中所有具有<em class="lv"> null/na </em>值的记录。为此，我们可以使用 dropna()函数。</p><p id="593c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 2)从推文中删除数字:</strong>我们使用<a class="ae ky" href="https://en.wikipedia.org/wiki/Regular_expression" rel="noopener ugc nofollow" target="_blank">正则表达式(regex) </a>操作符来进一步清理文本数据。下面的代码删除文本中的所有数字。我们正在处理单词而不是数字来识别灾难推文。</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="56d0" class="mh mi it md b gy mj mk l ml mm">regexp_replace(col(‘text’), ‘\d+’, ‘’)</span></pre><p id="9a6f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 3)分离单词:</strong>然后我们将推文分解成单个单词进行分析。为此，我们使用<a class="ae ky" href="https://spark.apache.org/docs/latest/ml-features#tokenizer" rel="noopener ugc nofollow" target="_blank"> RegexTokenizer() </a>。</p><p id="bc25" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 4)删除停用词:</strong>我们使用<a class="ae ky" href="https://spark.apache.org/docs/2.2.0/ml-features.html#stopwordsremover" rel="noopener ugc nofollow" target="_blank">py spark . ml 库中的【stopwodsmover()</a>函数从分离的词中删除停用词。一些停用词的例子有:I，the，a，has，等等。从这些例子中你可以注意到，这些单词没有携带太多的信息，因此我们从分析中去除了它们。</p><p id="1844" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 5)创建 features 列:</strong>在从数据中删除不重要的单词后，我们使用<a class="ae ky" href="https://spark.apache.org/docs/2.2.0/ml-features.html#countvectorizer" rel="noopener ugc nofollow" target="_blank"> CountVectorizer() </a>函数。该函数将单词转换为数字向量，以便能够将其输入到机器学习模型中。</p><p id="d836" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们的数据可以输入预测模型了。完成上述过程后的数据是这样的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/d14ca83b5e19b13ee64d3d6c53568fc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZOuLNDBVFiyfJjZOA-7dpg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">清洗和特征提取后的最终数据帧</p></figure><p id="6098" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我解释一下上面数据框架中的所有字段；我们从<em class="lv">‘文本’</em>字段开始。执行上述工作流程的前 3 个步骤后，<em class="lv">【单词】</em>会显示分离的单词。<em class="lv">‘filtered’</em>栏显示按照第 4 步所述移除停用词后的单词。完成步骤 5 后，<em class="lv">‘特征’</em>字段是数值向量字段，这是我们将用于训练机器学习模型的字段。<em class="lv">‘目标’</em>字段是我们的预测变量，它显示推文是否与灾难有关。</p><h1 id="c92d" class="nm mi it bd mo nn no np mr nq nr ns mu jz nt ka mx kc nu kd na kf nv kg nd nw bi translated">机器学习模型</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/0a61337f7ada58250360ad604c153ca1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eXtaLIwko2ZpXUjbdDdeaw.png"/></div></div></figure><p id="b4e9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将从前面的过程中获得的数据分成<em class="lv">训练</em>和<em class="lv">验证。</em>我们使用<em class="lv">训练</em>数据帧来训练机器学习模型，使用<em class="lv">验证</em>数据帧来验证它们对未知数据的准确性。验证分类模型有几个标准，我们将使用 ROC 和准确性进行分析。验证后，我们将对<em class="lv">测试</em>数据进行预测。</p><p id="ba88" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我将举例说明一些常见的<a class="ae ky" href="https://en.wikipedia.org/wiki/Statistical_classification" rel="noopener ugc nofollow" target="_blank">分类机器学习算法。</a>我假设你熟悉这些算法，我会尽量不要用这些算法来烦你。</p><h2 id="6690" class="mh mi it bd mo mp mq dn mr ms mt dp mu li mv mw mx lm my mz na lq nb nc nd ne bi translated">朴素贝叶斯</h2><p id="9771" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">朴素贝叶斯模型是最常用的文本分类算法之一。朴素贝叶斯算法假设所有的预测变量都是相互独立的。简而言之，它假设某个特定要素的存在与数据中的任何其他要素无关。这个假设在现实生活中并不总是正确的，然而，它在文本分类中是有意义的。以下代码用于使用 PySpark 对朴素贝叶斯模型进行定型和验证。</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="a850" class="mh mi it md b gy mj mk l ml mm">from pyspark.ml.classification import NaiveBayes<br/>from pyspark.ml.evaluation import MulticlassClassificationEvaluator</span><span id="55b1" class="mh mi it md b gy ny mk l ml mm">## Fitting the model<br/>nb = NaiveBayes(modelType="multinomial",labelCol="label", featuresCol="features")<br/>nbModel = nb.fit(train)<br/>nb_predictions = nbModel.transform(validate)</span><span id="c97f" class="mh mi it md b gy ny mk l ml mm">## Evaluating the model<br/>evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")<br/>nb_accuracy = evaluator.evaluate(nb_predictions)<br/>print("Accuracy of NaiveBayes is = %g"% (nb_accuracy))</span><span id="4294" class="mh mi it md b gy ny mk l ml mm">#Accuracy of NaiveBayes is = 0.803448</span></pre><h2 id="55f5" class="mh mi it bd mo mp mq dn mr ms mt dp mu li mv mw mx lm my mz na lq nb nc nd ne bi translated">逻辑回归</h2><p id="28ee" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">它是回归的一种变体，使用逻辑函数<a class="ae ky" href="https://en.wikipedia.org/wiki/Logistic_function" rel="noopener ugc nofollow" target="_blank">为二元结果变量建模。下面的代码演示了如何定型和验证逻辑回归。</a></p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="f9a4" class="mh mi it md b gy mj mk l ml mm">from pyspark.ml.classification import LogisticRegression</span><span id="4915" class="mh mi it md b gy ny mk l ml mm">## Fitting the model<br/>lr = LogisticRegression(featuresCol = 'features', labelCol = 'target', maxIter=10)<br/>lrModel = lr.fit(train)<br/>lrPreds = lrModel.transform(validate)</span><span id="0f36" class="mh mi it md b gy ny mk l ml mm">## Evaluating the model<br/>evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")<br/>lr_accuracy = evaluator.evaluate(lrPreds)<br/>print("Accuracy of Logistic Regression is = %g"% (lr_accuracy))</span><span id="4222" class="mh mi it md b gy ny mk l ml mm">#Accuracy of Logistic Regression is = 0.768276</span></pre><h2 id="24ca" class="mh mi it bd mo mp mq dn mr ms mt dp mu li mv mw mx lm my mz na lq nb nc nd ne bi translated">决策树</h2><p id="4de6" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">决策树本质上是基于试图学习其关于结果变量的行为的列来分割数据集，即，我们将预测器空间分割成简单的区域。Will Koehrsen 的这篇文章有助于详细理解决策树和随机森林。我们可以使用下面的代码来训练和验证决策树。</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="761c" class="mh mi it md b gy mj mk l ml mm">from pyspark.ml.classification import DecisionTreeClassifier</span><span id="7f8b" class="mh mi it md b gy ny mk l ml mm">## Fitting the model<br/>dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'target', maxDepth = 3)<br/>dtModel = dt.fit(train)<br/>dtPreds = dtModel.transform(validate)</span><span id="874c" class="mh mi it md b gy ny mk l ml mm">## Evaluating the model<br/>evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")<br/>dt_accuracy = evaluator.evaluate(dtPreds)<br/>print("Accuracy of Decision Trees is = %g"% (dt_accuracy))</span><span id="3ba8" class="mh mi it md b gy ny mk l ml mm">#Accuracy of Decision Trees is = 0.651034</span></pre><h2 id="1336" class="mh mi it bd mo mp mq dn mr ms mt dp mu li mv mw mx lm my mz na lq nb nc nd ne bi translated">随机森林</h2><p id="80ce" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">随机森林是一种集合机器学习方法。它们使用自举技术，从根本上说是众多弱学习者的组合，特别是决策树。查看以下代码，了解如何在 spark 中实现随机森林。</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="3bee" class="mh mi it md b gy mj mk l ml mm">from pyspark.ml.classification import RandomForestClassifier</span><span id="8e8a" class="mh mi it md b gy ny mk l ml mm">## Fitting the model<br/>rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'target')<br/>rfModel = rf.fit(train)<br/>rfPreds = rfModel.transform(validate)</span><span id="6d1f" class="mh mi it md b gy ny mk l ml mm">## Evaluating the model<br/>evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")<br/>rf_accuracy = evaluator.evaluate(rfPreds)<br/>print("Accuracy of Random Forests is = %g"% (rf_accuracy))</span><span id="cb1e" class="mh mi it md b gy ny mk l ml mm">#Accuracy of Random Forests is = 0.581379</span></pre><h2 id="726b" class="mh mi it bd mo mp mq dn mr ms mt dp mu li mv mw mx lm my mz na lq nb nc nd ne bi translated">梯度推进树</h2><p id="b896" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">梯度推进树是一种类似于随机森林的集成方法。构建树的方法不同于随机森林；由梯度推进树建立的每个新树试图纠正由前一个树产生的错误。我们使用来自<em class="lv">py spark . ml . class ification</em>库中的 GBTClassifier 来训练和验证数据。</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="77a2" class="mh mi it md b gy mj mk l ml mm">from pyspark.ml.classification import GBTClassifier</span><span id="5f96" class="mh mi it md b gy ny mk l ml mm">## Fitting the model<br/>gbt = GBTClassifier(maxIter=10)<br/>gbtModel = gbt.fit(train)<br/>gbtPreds = gbtModel.transform(validate)</span><span id="cef5" class="mh mi it md b gy ny mk l ml mm">## Evaluating the model<br/>evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")<br/>gb_accuracy = evaluator.evaluate(gbtPreds)<br/>print("Accuracy of GBT is = %g"% (gb_accuracy))</span><span id="c0a9" class="mh mi it md b gy ny mk l ml mm">#Accuracy of GBT is = 0.681379</span></pre><h2 id="d485" class="mh mi it bd mo mp mq dn mr ms mt dp mu li mv mw mx lm my mz na lq nb nc nd ne bi translated">根据测试数据进行预测</h2><p id="fa4c" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">既然我们已经训练并验证了几个模型，我们就可以对看不见的测试数据进行预测了。我们可以根据所有可用的训练数据重新训练模型，然后进行预测。下面的代码演示了如何使用梯度推进模型进行预测。但是，您可以对任何训练过的模型重复同样的操作，并且使用其他模型进行预测的完整代码可以在<a class="ae ky" href="https://github.com/SurajMalpani/NLP-using-Spark" rel="noopener ugc nofollow" target="_blank"> Github 上找到。</a></p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="fc72" class="mh mi it md b gy mj mk l ml mm">## Fitting the model<br/>gbt = GBTClassifier(maxIter=10)<br/>gbtModel = gbt.fit(trainData)</span><span id="5117" class="mh mi it md b gy ny mk l ml mm">## Make predictions<br/>gbtPreds = gbtModel.transform(testData)<br/>gbtPreds.select('id','prediction').show(5)</span><span id="30c6" class="mh mi it md b gy ny mk l ml mm">+---+----------+<br/>| id|prediction|<br/>+---+----------+<br/>|  0|       0.0|<br/>|  2|       0.0|<br/>|  3|       1.0|<br/>|  9|       0.0|<br/>| 11|       0.0|<br/>+---+----------+<br/>only showing top 5 rows</span></pre><p id="ea9a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦你做出了预测，你就可以将数据帧转换成 CSV 格式并提交给比赛。您现在已经准备好使用 Spark 来开发机器学习模型。文本分类有无数的应用，例如识别垃圾邮件、标记网站/产品内容等。并且上述算法适用于所有这样的任务。希望你觉得这很有用，并让我知道你的想法。快乐学习！</p></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><p id="c4cb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢您的阅读。我希望这对你有所帮助。如果你有任何建议，请在评论区添加。请随时通过我的<a class="ae ky" href="https://surajmalpani.github.io/" rel="noopener ugc nofollow" target="_blank">网站</a>或<a class="ae ky" href="https://www.linkedin.com/in/suraj-malpani/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>与我联系。</p><h2 id="06ae" class="mh mi it bd mo mp mq dn mr ms mt dp mu li mv mw mx lm my mz na lq nb nc nd ne bi translated">参考资料:</h2><ol class=""><li id="6de1" class="og oh it lb b lc nf lf ng li oi lm oj lq ok lu ol om on oo bi translated">Spark 文档:<a class="ae ky" href="https://spark.apache.org/docs/2.2.0/ml-classification-regression.html" rel="noopener ugc nofollow" target="_blank">https://spark . Apache . org/docs/2 . 2 . 0/ml-classification-regression . html</a></li><li id="d356" class="og oh it lb b lc op lf oq li or lm os lq ot lu ol om on oo bi translated"><a class="ae ky" href="https://monkeylearn.com/text-classification/" rel="noopener ugc nofollow" target="_blank">https://monkeylearn.com/text-classification/</a></li><li id="8df4" class="og oh it lb b lc op lf oq li or lm os lq ot lu ol om on oo bi translated">Kaggle 笔记本:<a class="ae ky" href="https://www.kaggle.com/palmer0/binary-classification-with-pyspark-and-mllib" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/palmero/binary-class ification-with-py spark-and-ml lib</a></li><li id="4307" class="og oh it lb b lc op lf oq li or lm os lq ot lu ol om on oo bi translated">Github 笔记本:<a class="ae ky" href="https://github.com/lp-dataninja/SparkML/blob/master/pyspark-nlp-kaggle.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/LP-data ninja/spark ml/blob/master/py spark-NLP-ka ggle . ipynb</a></li></ol></div></div>    
</body>
</html>