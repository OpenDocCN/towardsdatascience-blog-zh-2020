<html>
<head>
<title>Learning from Imbalanced Datasets</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从不平衡数据集中学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/learning-from-imbalanced-datasets-b601a1f1e154?source=collection_archive---------29-----------------------#2020-03-09">https://towardsdatascience.com/learning-from-imbalanced-datasets-b601a1f1e154?source=collection_archive---------29-----------------------#2020-03-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b466" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">不平衡类是机器学习分类中的一个常见问题，其中每个类中的观察值比例不成比例。在本文中，我们提供了处理不平衡数据集的指南。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/caae1114df8aab9f16bac6e77a9eecb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-yAsC-YHy9aOcxt3XUuvfA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@eduardoequis?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">艾德亚多·桑奇兹</a>在<a class="ae ky" href="https://unsplash.com/s/photos/unbalanced?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="a4ff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据科学家经常面临处理不平衡数据集的需求。事实上，不平衡类是机器学习分类中的一个常见问题，其中每个类中的观察值比例不成比例。</p><p id="dd04" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">阶层失衡可以在许多领域找到，包括广告技术、医疗诊断、垃圾邮件过滤和欺诈检测。但大多数机器学习算法在每类样本数量大致相等的情况下工作得最好。这是因为大多数算法都是为了最大限度地提高精度和减少误差而设计的。</p><p id="a659" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们提供了处理不平衡数据集的指南。但是在做我们推荐的任何事情之前，你应该首先确定你是否能<strong class="lb iu">收集更多的数据</strong>。获取更多的欠采样类总是最好的解决方案。</p><p id="4680" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在你收集了尽可能多的数据之后，处理不平衡的数据集包括选择三件事:<strong class="lb iu">正确的度量标准</strong>，使用什么样的<strong class="lb iu">重采样方法</strong>，以及<strong class="lb iu">正确的建模框架</strong>一旦你预处理了你的数据。‍</p><p id="2ce4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">选择正确的指标</strong></p><blockquote class="lv lw lx"><p id="1b48" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">准确性悖论是一个矛盾的发现，即在预测分析中进行分类时，准确性不是预测模型的一个好指标。这是因为一个简单的模型可能有很高的精确度，但是太粗糙而没有用。例如，如果女性对男性的发生率占主导地位，在 99%的病例中被发现，那么预测每个病例都是女性的准确率将为 99%。<a class="ae ky" href="https://en.wikipedia.org/wiki/Accuracy_paradox" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></blockquote><p id="3d86" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">仔细观察这种自相矛盾的行为会发现两种类型的错误分类:假阳性和假阴性。在一个涉及火灾警报的例子中，假阳性将包括在没有火灾时预测有火灾(预测阳性)；假阴性是错误地预测没有火灾(预测阴性)，而实际上有火灾。在准确性悖论的情况下，我们可以看到，我们所有的错误都是预测肯定的(意味着有火灾)而不是火灾，因为我们所做的所有预测都不是火灾。这给我们留下了和负面观察一样多的假阴性。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/97bef7e8d47d87624f6485a5a5e76ac0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/0*KEKYiI6_TDDcpz0r.jpg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者照片</p></figure><p id="512a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了更仔细地检查我们在假阳性和假阴性方面准确或不准确的地方，我们需要查看密切相关的指标精度和召回。为了全面评估一个模型的有效性，你必须同时检查<strong class="lb iu">精度</strong>和<strong class="lb iu">召回</strong>。精确度和召回率是可选的性能指标:</p><ul class=""><li id="4bb6" class="md me it lb b lc ld lf lg li mf lm mg lq mh lu mi mj mk ml bi translated"><strong class="lb iu">精度</strong>:实际上有多少比例的肯定识别是正确的？</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/2daf9657b0ec6a27be7d5386e2b95c84.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/0*3NLPdEHd5bRhXcFY.png"/></div></figure><ul class=""><li id="e702" class="md me it lb b lc ld lf lg li mf lm mg lq mh lu mi mj mk ml bi translated"><strong class="lb iu">回忆:</strong>正确识别实际阳性的比例是多少？</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/2250079665970732ef8e56028ae1a65c.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/0*B5aKvXcFLItRIgYW.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mn"><img src="../Images/125707a048360e3ee960df3d7126ab88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*P5pKudmqUBgHfY6U.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://en.wikipedia.org/wiki/File:Precisionrecall.svg" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></figure><p id="dfb1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不幸的是，精确和回忆天生就是矛盾的。也就是说，提高精度通常会降低召回率，反之亦然。精确和召回的重要性取决于问题的商业逻辑。例如，在火灾警报的情况下，我们想要捕捉所有的火灾，即使代价是每隔一段时间触发一次假警报。这意味着回忆比精确更重要。</p><p id="ed78" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，在 YouTube 推荐中可以看到相反的情况。由于推荐一些你可能不喜欢的东西并没有真正的伤害，所以错误的否定很容易被忽视。与此同时，推荐你不知道并且可能喜欢的东西的好处超过了你仅仅跳过视频的风险。</p><p id="aacc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了全面了解您的预测的假阳性和假阴性图，我们建议在混淆矩阵的框架中查看您的模型的分数。</p><p id="7c31" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，如果你的目标是选择一个指标，而不是同时处理两个指标，你可能要考虑 F1 的分数。F1 分数是精确度和召回率的调和平均值，其中 F1 分数在 1 时达到其最佳值(完美的精确度和召回率),在 0 时最差。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/a1a33390fd153e519300c90b12c9dddc.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/0*pQHU1VQJ1O0Pu0p5.png"/></div></figure><p id="374a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">重采样方法</strong></p><p id="fe5c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据科学家有多种重采样方法可供选择，每种方法都有各自的优缺点。在这里，我们将重点关注行业中使用的一些更流行的方法。由于不同的建模任务可能需要不同的重采样方法，我们建议您尝试几种方法，以探索哪种方法最适合您的特定问题。</p><ul class=""><li id="86ac" class="md me it lb b lc ld lf lg li mf lm mg lq mh lu mi mj mk ml bi translated"><strong class="lb iu">随机欠采样<br/> </strong>在随机欠采样中，你从过表示类中选择随机观察值。这应该作为更复杂的建模工作的基线。请注意，随着代表过多和代表不足的标签之间的比率增加，这种方法可能会产生越来越大的偏差。偏差是由于如果不平衡太大，随机样本可能不会从特征空间的整个区域采样。举个例子，假设某个游戏 app 里的标签是购买者，我们有三十六万非购买者。除此之外，数据中的每一行都表示用户的年龄和性别。如果我们以 1:1 的比例进行抽样，我们可能不会对特定年龄以下的女性用户的负面标签进行抽样，或者由于样本量较小，我们的样本通常不代表被抽样的人群。这可能会导致某些特征在预测标注时显得比实际更有影响力。</li><li id="97e1" class="md me it lb b lc mp lf mq li mr lm ms lq mt lu mi mj mk ml bi translated"><strong class="lb iu">随机过采样<br/> </strong>在随机过采样中，从代表性不足的类别中复制随机观察值。在随机欠采样的情况下，这种采样方法可以用作更复杂建模工作的基线。注意，在尝试过采样技术之前，你应该<strong class="lb iu">总是</strong>分成“测试”和“训练”组<em class="ly">。分割数据之前的过采样可以允许在“测试”和“训练”集中出现完全相同的观察结果。此外，由于阳性标签被重复多次，因此在使用随机过采样时，模型过拟合训练数据是非常常见的。</em></li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/1a833990f3d79bed26b50e5a6ccfedf3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3omFd4BG3ubWnIIS.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者照片</p></figure><ul class=""><li id="dbe1" class="md me it lb b lc ld lf lg li mf lm mg lq mh lu mi mj mk ml bi translated"><strong class="lb iu">聚类质心<br/> </strong>在这种重采样方法中，将一些聚类算法应用于数据，将每个数据点分配给一个聚类，并按等于该聚类大小的比例按聚类执行欠采样。这旨在解决特征空间中的区域在随机下采样中可能不被表示的问题。如果回到用户年龄和性别的例子，聚类模型会根据特征空间确定数据中有 K 个聚类；一群可能是老年女性，另一群可能是年轻男性，等等。然后，将根据每个聚类在数据中的大小按比例进行采样，而不是统一从整个数据集中进行采样。因此，向下采样的数据必然会更准确地代表真实群体(我们从中采样的群体)。</li></ul><p id="e755" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> SMOTE(合成少数民族过采样算法)<br/> </strong>这种重采样方法沿着观察值和其最近的少数民族邻居之间的线生成新的少数民族类样本。这种方法的一个优点是，它允许您避免过拟合，过拟合是在随机过采样中添加少数实例的精确副本时发生的。这种方法有助于强调存在大比例阳性标记的区域，而不是过度拟合可能无法概括的单个阳性观察。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/7be609f285ddc797fed258c9b16e4965.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/format:webp/0*U7gHvBaflbB8hIpx.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://www.datasciencecentral.com/profiles/blogs/handling-imbalanced-data-sets-in-supervised-learning-using-family" rel="noopener ugc nofollow" target="_blank"> Rohit Walimbe </a>通过<a class="ae ky" href="http://datasciencecentral.com" rel="noopener ugc nofollow" target="_blank">数据科学中心</a>拍摄</p></figure><p id="85f6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">‍ <strong class="lb iu">选择正确的建模框架<br/> </strong>每当你遇到机器学习问题时，尝试各种算法是一个很好的经验法则。当您处理不平衡的数据集时，这样做尤其有益。</p><p id="a076" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">决策树通常在不平衡数据上表现良好。他们通过学习“如果/否则”问题的层次结构来最小化数据中的熵。</p><p id="cadc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">某些模型允许您为损失函数分配权重，以便处理数据集由大小不等的类组成的类。在 scikit-learn 框架中，这通常被称为“class_weights ”,它通常包含一个字典，定义每个类应该受到多少惩罚。这个参数也存在于 XGBoost 框架中，它被称为“scale_pos_weight”</p><p id="303e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">无论您选择什么样的建模框架，我们建议从阅读文档开始，并检查模型是否支持针对不平衡数据情况的某种损失函数惩罚。</p><p id="58cc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">结论</strong></p><p id="3763" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我们提到的，不平衡数据是一个常见的问题。不要让它吓倒你。虽然处理不平衡的数据的确具有挑战性，但是只要你按照我们在这里提供的指导方针仔细计划，这也是可行的。</p><p id="91e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你应该总是从小事做起。仔细阅读一种方法，确保你确切地知道在引擎盖下发生了什么。如果你发现一种方法给你带来了价值，你可以通过尝试同一系列的不同方法来进一步调整它。</p><p id="3e7e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另外，<strong class="lb iu">尊重基线</strong>。将你所做的一切与一个简单的基线进行比较，以确保你没有浪费时间，并且通过对你的数据实施这些方法，你实际上已经足够移动指针了。我们建议最简单和最强的基线是随机过采样和随机欠采样。</p><p id="fc48" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，<strong class="lb iu">使用外部库</strong>。正如数据科学中 99%的情况一样，你不是第一个遇到你所面临的问题的人！寻找能够解决你正在处理的问题的开源库。如果 python 是您数据科学的首选武器(应该是！)，我们推荐不平衡学习(下面的链接)。</p><p id="43cb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">有用的资源</strong></p><p id="bcf1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是一些资源，可进一步帮助您找到处理不平衡数据集的方法:</p><ul class=""><li id="763c" class="md me it lb b lc ld lf lg li mf lm mg lq mh lu mi mj mk ml bi translated">Bigabid 数据科学家 Ido Zehori 发表了一篇关于不平衡数据集的演讲— <a class="ae ky" href="https://youtu.be/P0YN5-PFOU0" rel="noopener ugc nofollow" target="_blank">这里</a>。</li><li id="c633" class="md me it lb b lc mp lf mq li mr lm ms lq mt lu mi mj mk ml bi translated">上图<a class="ae ky" href="https://docs.google.com/presentation/d/1ef97mUt38OAV4rZMqFXdu0DsKcw-eokyoF7RTzuYXGo/edit?usp=sharing" rel="noopener ugc nofollow" target="_blank">的演讲——这里是</a>。</li><li id="9008" class="md me it lb b lc mp lf mq li mr lm ms lq mt lu mi mj mk ml bi translated">不平衡-学习 python 包— <a class="ae ky" href="https://github.com/scikit-learn-contrib/imbalanced-learn" rel="noopener ugc nofollow" target="_blank">此处</a>。</li><li id="8f4b" class="md me it lb b lc mp lf mq li mr lm ms lq mt lu mi mj mk ml bi translated">推荐论文:<br/> <a class="ae ky" href="http://link.springer.com/chapter/10.1007/978-0-387-09823-4_45" rel="noopener ugc nofollow" target="_blank">不平衡数据集的数据挖掘:综述<br/> </a> <a class="ae ky" href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5128907" rel="noopener ugc nofollow" target="_blank">从不平衡数据中学习</a></li><li id="5c6f" class="md me it lb b lc mp lf mq li mr lm ms lq mt lu mi mj mk ml bi translated"><strong class="lb iu">这篇博文最初是为</strong> <a class="ae ky" href="https://www.bigabid.com/blog" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> Bigabid 博客</strong> </a> <strong class="lb iu">而写的，可在</strong> <a class="ae ky" href="https://www.bigabid.com/blog/data-learning-from-imbalanced-datasets" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">这里</strong> </a>找到</li></ul></div></div>    
</body>
</html>