<html>
<head>
<title>Federated Learning: A Step by Step Implementation in Tensorflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">联合学习:Tensorflow 中的逐步实现</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/federated-learning-a-step-by-step-implementation-in-tensorflow-aac568283399?source=collection_archive---------2-----------------------#2020-04-10">https://towardsdatascience.com/federated-learning-a-step-by-step-implementation-in-tensorflow-aac568283399?source=collection_archive---------2-----------------------#2020-04-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="844f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">通过代码理解联邦学习</h2></div><p id="4e3a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本教程中，我实现了联邦学习(FL)的构建模块，并在 MNIST 数字数据集上从头开始训练了一个。在此之前，我简要介绍了这个主题，以便将代码中的要点讲清楚。如果这是你第一次学习 FL，我相信你会受益于我最近在 LinkedIn 上发表的关于这项技术的 <a class="ae lf" href="https://www.linkedin.com/pulse/federated-learning-why-what-how-saheed-tijani" rel="noopener ugc nofollow" target="_blank"> <em class="le">介绍文章</em> </a> <em class="le">。</em></p><h2 id="d1a7" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">介绍</h2><p id="8b8a" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">高质量的数据像孤岛一样存在于全球各地的手机和个人电脑等边缘设备上，并受到严格的隐私保护法的保护。联合学习提供了一种将机器学习模型连接到这些脱节数据的聪明方法，而不管它们在哪里，更重要的是，不违反隐私法律。FL 不是根据经验法则将数据带到模型中进行训练，而是将模型带到数据中。所需要的只是托管数据的设备将其自身提交给联合过程的灵活性。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi me"><img src="../Images/c43dae0792955a9472697802f14c4b53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PmWHMpjKOtxjXa5yTgb93g.jpeg"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">高质量数据的孤岛。照片由<a class="ae lf" href="https://unsplash.com/@andrzejsuwara?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Andrzej Suwara </a>在<a class="ae lf" href="https://unsplash.com/s/photos/multiple-islands?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="396b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">FL 架构的基本形式是由一个位于其中心并协调培训活动的管理者或服务器组成。客户端主要是边缘设备，数量可能高达数百万。这些设备在每个训练迭代中至少与服务器通信两次。首先，它们每个都从服务器接收当前全局模型的权重，根据它们的每个本地数据对其进行训练，以生成更新的参数，然后将这些参数上传回服务器进行聚合。这种通信循环一直持续到达到预设的纪元编号或精度条件。在联邦平均算法中，聚合仅仅意味着平均操作。这就是 FL 模特训练的全部内容。我希望您抓住了这个过程中最突出的一点——我们现在交流模型权重，而不是移动原始数据。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi mu"><img src="../Images/cb5fac2803e4abc13c96562b7b4a7029.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XPGv1Gmf_b30VZu4dbjLog.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">联合学习布局。<a class="ae lf" href="https://blog.ml.cmu.edu/2019/11/12/federated-learning-challenges-methods-and-future-directions/" rel="noopener ugc nofollow" target="_blank">图像参考</a></p></figure><p id="e086" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们清楚了什么是 FL 以及它是如何工作的，让我们继续在 Tensorflow 中从头构建一个，并在 Kaggle 的<a class="ae lf" href="https://www.kaggle.com/scolianni/mnistasjpg" rel="noopener ugc nofollow" target="_blank"> MNIST 数据集上训练它。请注意，本教程仅用于说明。我们既不会深入研究 FL 中服务器-客户端通信如何工作的细节，也不会深入研究安全聚合的基础知识。由于这是一个模拟，客户端将仅仅由数据分片来表示，并且所有本地模型将在同一台机器上被训练。这里是我的 GitHub 库</a>中的本教程完整代码的链接。不能再拖延了，让我们开始吧。</p><h2 id="3108" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated"><strong class="ak">导入所有相关包</strong></h2><p id="f8c0" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">不要担心，我将在实例化它们各自的对象时提供每个导入模块的细节。</p><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="mv mw l"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">导入所有相关模块</p></figure><h2 id="51b9" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">读取和预处理 MNIST 数据集</h2><p id="488a" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">我在这里使用的是来自<a class="ae lf" href="https://www.kaggle.com/scolianni/mnistasjpg" rel="noopener ugc nofollow" target="_blank">的 MNIST 数据集的 jpeg 版本</a>。它由 42000 个数字图像组成，每个类别保存在单独的文件夹中。我将使用这段代码片段将数据加载到内存中，并保留 10%的数据用于稍后测试训练好的全局模型。</p><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="mv mw l"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">读取和处理 MNIST 数字数据</p></figure><p id="31c2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在第 9 行，每个图像将作为灰度级从磁盘中读取，然后变平。扁平化步骤非常重要，因为我们稍后将使用 MLP 网络架构。为了获得图像的类标签，我们在第 11 行拆分它的路径字符串。希望你注意到我们还在第 13 行将图像缩放到[0，1]来减弱不同像素亮度的影响。</p><h2 id="8b7e" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">创建训练测试分割</h2><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="mv mw l"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">创建训练/测试数据分割</p></figure><p id="6485" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个片段中有几个步骤。我们应用了前面代码块中定义的 load 函数来获取图像列表(现在在 numpy 数组中)和标签列表。之后，我们使用 sklearn 的<code class="fe mx my mz na b">LabelBinarizer</code>对象对标签进行热编码。接下来，数字 1 的标签不再是数字 1，而是现在的形式<code class="fe mx my mz na b">[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</code>。有了这种标签风格，我们将能够使用 Tensorflow 中的<code class="fe mx my mz na b">cross-entropy</code>损失作为我们模型的损失函数。或者，我可以让标签保持原样，而使用<code class="fe mx my mz na b">sparse-categorical-entropy</code>损失。最后，我使用 sklearn 的<code class="fe mx my mz na b">train_test_split</code>对象将数据拆分成比率为<code class="fe mx my mz na b">9:1</code>的训练/测试。</p><h2 id="f046" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">作为数据碎片的联邦成员(客户机)</h2><p id="0076" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">在 FL 的实际实现中，每个联邦成员都有自己的独立数据。请记住，FL 的目的是将模型传递给数据，而不是相反。这里的碎片创建步骤只发生在实验中。我将把训练集分成 10 份，每个客户一份。我写了一个名为<code class="fe mx my mz na b">create_clients</code>的函数来实现这个。</p><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="mv mw l"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">将客户端创建为数据碎片</p></figure><p id="94c3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在第 13 行，我使用前缀(<code class="fe mx my mz na b">initials</code>)创建了一个客户端名称列表。在第 16–20 行，我压缩了数据和标签列表，然后随机化了结果元组列表。最后，我在第 21 行根据期望的客户端数量(<code class="fe mx my mz na b">num_clients</code>)从元组列表中创建了碎片。在第 26 行，返回了一个字典，其中包含每个客户机的名称作为键，数据份额作为值。现在，让我们将这个函数应用于我们的训练数据集。</p><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="mv mw l"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">客户字典</p></figure><h2 id="3ece" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">处理和批量处理客户和测试数据</h2><p id="19b8" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">接下来就是把每一个客户端的数据处理成 tensorflow 数据集，进行批量处理。为了简化这个步骤并避免重复，我将这个过程封装到一个名为<code class="fe mx my mz na b">batch_data</code>的小函数中。</p><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="mv mw l"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">为培训准备客户数据的功能</p></figure><p id="d089" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我相信您还记得，每个客户端数据集都是从<code class="fe mx my mz na b">create_clients</code>出来的(数据，标签)元组列表。在上面的第 9 行，我将元组分成单独的数据和标签列表。然后，我从这些列表中创建了一个混洗和批处理的 tensorflow 数据集对象。</p><p id="7245" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在应用下面的函数时，我也将处理测试集，并把它放在一边以备后用。</p><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="mv mw l"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">为培训准备每个客户端数据</p></figure><h2 id="b25b" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">创建多层感知器(MLP)模型</h2><p id="9bbe" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">我在介绍部分没有提到的一点是，FL 最适合参数化学习——所有类型的神经网络。机器学习技术，如 KNN 或 it likes，只是在学习时存储训练数据，可能不会从第一语言中受益。我正在创建一个 3 层 MLP 作为我们分类任务的模型。我希望你还记得我们之前导入的那些 Keras 模块，这是它们适合的地方。</p><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="mv mw l"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">建筑模型:MLP</p></figure><p id="6135" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了构建一个新的模型，将调用<code class="fe mx my mz na b">build</code>方法。它需要输入数据的形状和类的数量作为参数。对于 MNIST，形状参数将是<code class="fe mx my mz na b">28*28*1 = 784,</code>，而类的数量将是 10。</p><p id="c9f8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在是时候定义一个<code class="fe mx my mz na b">optimizer</code>、<code class="fe mx my mz na b">loss</code>函数和<code class="fe mx my mz na b">metrics</code>来编译我们的模型了。</p><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="mv mw l"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">清除优化器、损失函数和度量</p></figure><p id="840c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">SGD 是我的默认优化器，除非我有理由不使用它。损失函数是<code class="fe mx my mz na b">categorical_crossentropy. </code>，最后，我将使用的度量是<code class="fe mx my mz na b">accuracy</code>。但是在衰变的论点中有些东西看起来很奇怪。什么是<code class="fe mx my mz na b">comms_round</code>？这只是我在训练期间将运行的全局纪元(聚合)的数量。因此，不是像你可能熟悉的那样，学习率相对于局部时期的数量而衰减，这里我想相对于全局聚集的数量而衰减。这显然是一个超参数选择的选择，但我发现它在实验中工作得很好。我还发现了一份学术报告，其中这种设置也有效[1]。</p><h2 id="15d1" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">模型聚合(联合平均)</h2><p id="bf52" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">到目前为止，我所做的一切都非常符合深度学习管道的标准。当然，数据分区或客户机创建位除外。我现在将转移到联邦平均(FL 的标准算法)，这是本教程的全部内容。我使用的数据是水平分区的，因此我将简单地进行组件式参数平均，这将根据每个参与客户端贡献的数据点的比例进行加权。这是我使用的联邦平均方程，它是联邦学习的先驱作品之一[2]。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/dca6eb5b0e9997fffa40cdafd57451fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*Obl9KaXxW1Gt8ha55w0paQ.png"/></div></figure><p id="eca6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">不要让方程中复杂的数学符号欺骗了你，这是一个非常简单的计算。在右边，我们根据他们训练时记录的每个数据点的体重值来估计每个客户的体重参数。在左侧，我们对这些参数中的每一个进行了缩放，并对所有组件进行了求和。</p><p id="e435" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面我将这个过程封装成三个简单的函数。</p><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="mv mw l"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">实现 FedAvg</p></figure><p id="111f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">(1) <code class="fe mx my mz na b">weight_scalling_factor </code>计算一个客户端的本地训练数据占所有客户端持有的整体训练数据的比例。首先，我们获得客户端的批量大小，并使用它来计算数据点的数量。然后，我们在第 6 行获得了总体的全局训练数据大小。最后，我们在第 9 行计算了比例因子的分数。这肯定不是现实世界应用中的方法。训练数据将是不连续的，因此没有一个客户端能够正确地估计组合集的数量。在这种情况下，在每个本地训练步骤之后，当用新参数更新服务器时，每个客户端将被期望指示它们训练的数据点的数量。</p><p id="a043" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">(2) <code class="fe mx my mz na b">scale_model_weights</code>根据在(1)中计算的缩放因子的值，缩放每个局部模型的权重</p><p id="92c9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">(3) <code class="fe mx my mz na b">sum_scaled_weights</code>将所有客户的加权求和。</p><h2 id="56b5" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">联合模型训练</h2><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="mv mw l"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">外语训练逻辑</p></figure><p id="3254" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">训练逻辑有两个主要循环，外部循环用于全局迭代，内部循环用于遍历客户端的本地训练。还有一个隐含的第三个问题，它考虑了本地纪元，将由我们的<code class="fe mx my mz na b">model.fit</code>方法中的纪元参数来处理。</p><p id="6630" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">开始时，我构建了输入形状为(784)的全局模型，类的数量为 10 —第 2-3 行。然后，我进入了外部循环。首先在第 9 行获得全局模型的初始化<code class="fe mx my mz na b">weights</code>。第 15 行和第 16 行打乱了客户机的字典顺序，以确保随机性。从那里，我开始迭代客户培训。</p><p id="c0cd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于每个客户端，我创建了一个新的模型对象，编译它，并将其初始化权重设置为全局模型的当前参数——第 20–27 行。然后，本地模型(客户端)被训练一个时期。训练之后，新的权重被缩放并附加到第 35 行的<code class="fe mx my mz na b">scaled_local_weight_list</code>上。当地培训到此为止。</p><p id="2f58" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">回到第 41 行的外循环，我总结了所有缩放的局部训练权重(当然是按组件),并将全局模型更新为这个新的集合。这结束了一个完整的全球训练时代。</p><p id="cc62" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">按照<code class="fe mx my mz na b">comms_round</code>的规定，我运行了 100 个全局训练循环，并在第 48 行测试了经过训练的全局模型，每次通信后都是我们的测试数据。下面是测试逻辑的片段:</p><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="mv mw l"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">测试逻辑</p></figure><h2 id="9e8c" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">结果</h2><p id="7f1d" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">有 10 个客户端，每个客户端在 100 轮全局通信的基础上运行 1 个本地纪元，以下是截断的测试结果:</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/576930b4988511d098e03d42d391c1e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*Hiz5FH6dJgRbJPN7rFaVbw.png"/></div></figure><h2 id="8243" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">新加坡元与联邦平均</h2><p id="8be9" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">是的，我们的 FL 模型结果非常好，经过 100 轮沟通后，测试准确率达到 96.5%。但是它与在相同数据集上训练的标准 SGD 模型相比如何呢？为了找出答案，我将根据组合的训练数据训练一个单一的 3 层 MLP 模型(而不是像我们在 FL 中那样训练 10 个)。请记住，组合数据是我们在分区之前的训练数据。</p><p id="84cb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了确保公平竞争，我将保留除批量之外的所有用于 FL 培训的超级参数。我们 SGD 的批量将是 320，而不是 32。通过这种设置，我们确信 SGD 模型在每个时期看到的训练样本的数量与全局模型在 FL 中每个通信回合看到的完全相同。</p><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="mv mw l"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">SGD 培训</p></figure><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi nd"><img src="../Images/33fa42b506bf4dafe41944e68626d15e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1158/format:webp/1*Fge0ALQEQZrWCdhPgLoBEw.png"/></div></div></figure><p id="6497" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是了，SGD 模型在 100 个时期后的测试准确率为 94.5%。在这个数据集上，FL 的表现比 SGD 稍好，这难道不令人惊讶吗？不过，我警告你不要对此过于兴奋。这种结果在现实世界中不太可能出现。耶！客户端持有的真实世界的联邦数据大多是非独立且同分布的(IID)。</p><p id="5fc4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">例如，我们可以通过构建上面的客户端碎片来复制这个场景，使每个客户端碎片都包含来自单个类的图像—例如，client_1 只包含数字 1 的图像，client_2 只包含数字 2 的图像，依此类推。这种安排会导致 FL 模型的性能显著下降。我将此作为一个练习留给读者去尝试。同时，这里有一段代码，您可以用它来以非 IID 的方式分割任何分类数据。</p><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="mv mw l"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">创造非 IID 碎片</p></figure><h2 id="606a" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">结论</h2><p id="934d" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">通过本文，我介绍了联邦学习的概念，并带您了解了它的基本形式的 tensorflow 实现。我鼓励你查看我最近在 LinkedIn 上的文章，这里是对这项技术更广泛的介绍，特别是如果你不清楚它的工作原理，或者想了解更多关于如何应用它的信息。对于想要更深入研究这个主题的研究人员来说，有许多关于 arxiv.org/csT2【FL】的期刊，主要是推动其实施并解决其众多挑战。</p><h2 id="22c9" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">参考</h2><p id="d91b" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">[1]使用非 IID 数据的联合学习，赵月等人，arXiv: 1806.00582v1，2018 年 6 月 2 日</p><p id="b430" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[2]从分散数据中进行深度网络的通信高效学习，H. Brendan McMahan 等人，arXiv:1602.05629v3 [cs .2017 年 2 月 28 日</p><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="mv mw l"/></div></figure><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="mv mw l"/></div></figure></div></div>    
</body>
</html>