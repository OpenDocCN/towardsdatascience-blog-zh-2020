<html>
<head>
<title>Building Linear Regression (Least Squares) with Linear Algebra</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用线性代数构建线性回归(最小二乘法)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-linear-regression-least-squares-with-linear-algebra-2adf071dd5dd?source=collection_archive---------7-----------------------#2020-07-30">https://towardsdatascience.com/building-linear-regression-least-squares-with-linear-algebra-2adf071dd5dd?source=collection_archive---------7-----------------------#2020-07-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9ae8" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用 excel 或 numpy 解决线性回归问题的全线性代数方法。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/d0c5bafb2a6826a52fb1834c5dbf6434.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rxMofhj9hoF0Ji3T"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">迪米特里·卡拉斯泰列夫在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="ee71" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有了 python 和 R 中大量复杂的包供我们使用，我们不太可能在每次必须拟合大量数据点时都要经历算法背后的数学运算。但是，有时学习数学并手动从头开始求解算法是很有用的，这样我们就能够直观地了解它是如何在后台完成的。在我为<a class="ae kv" href="https://www.isb.edu/en/study-isb/advanced-management-programmes/ampba.html" rel="noopener ugc nofollow" target="_blank"> ISB-CBA </a>的课程工作中，有一堂统计学课涉及使用线性代数在 excel 上用矩阵乘法求解多元线性回归的截距、系数和 R 平方值。在此之前，我一直使用 python 中的<em class="ls"> statmodel OLS </em>或 R 上的<em class="ls"> lm() </em>命令来获取截距和系数，看一眼 R 平方值就知道它有多好。</p><p id="7ba5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">自从我的课程结束后，我早就忘记了如何使用 excel 解决这个问题，所以我想重温一下这些概念，并写下这篇文章，以便对其他人也有用。</p><blockquote class="lt lu lv"><p id="5e8a" class="kw kx ls ky b kz la jr lb lc ld ju le lw lg lh li lx lk ll lm ly lo lp lq lr ij bi translated">我在我的 K <a class="ae kv" href="https://www.kaggle.com/gireeshs/diy-build-linear-regression-with-linear-algebra#Part-3:-Multiple-linear-regression" rel="noopener ugc nofollow" target="_blank"> aggle 笔记本上使用 numpy 完成了这篇文章。如果你觉得这篇文章有用，请查看我的笔记本并投赞成票！</a></p></blockquote></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><h1 id="ac78" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">使用矩阵乘法求解线性回归的数学基础</h1><p id="ac69" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">让我们从一个简单的线性回归开始。我们想通过一组数据点找到最佳拟合线:(x1，y1)，(x2，y2)，……(xn，yn)。但是最适合是什么意思呢？</p><p id="28bb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们能找到一条穿过所有可能数据点的直线的斜率和截距，那么这条直线就是最佳拟合直线。但是在大多数情况下，这样的线是不存在的！所以我们决心找到一条线，使得当从数据点到回归线平行于 y 轴画一条连接线时，测量每个数据点的误差，所有这些误差的总和应该是最小的。简单，嗯？</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/67dbbdd03007607746441eda54dcd647.png" data-original-src="https://miro.medium.com/v2/resize:fit:748/format:webp/1*8ASUA-1sN5NJ8jitj3VmZQ.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/d424118031252989467078460f076de0.png" data-original-src="https://miro.medium.com/v2/resize:fit:546/format:webp/1*umIRzupw0uVIizV0zquRVw.png"/></div></figure><p id="f99e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在图中，错误分别用红、蓝、绿、黄和紫线表示。为了将此公式化为矩阵求解问题，考虑下面给出的线性方程，其中β0 是截距，β是斜率。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/d06db4dbe14b801a14bc29466785dc66.png" data-original-src="https://miro.medium.com/v2/resize:fit:320/format:webp/1*8SYieaxjk97scXFFD-rVlw.png"/></div></figure><p id="56e1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了简化这种表示法，我们将把β0 加到β向量上。这是通过在 X 矩阵中添加一个额外的 1 列，并在 Beta 向量中添加一个额外的变量来实现的。因此，矩阵形式将为:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/ab04e28051a597ec926fc229267d832a.png" data-original-src="https://miro.medium.com/v2/resize:fit:470/format:webp/1*-WrH6s43sOI4zVPMFyb4UA.png"/></div></figure><p id="7f29" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">那么最小二乘矩阵问题就是:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/422d3ce4e1564dce979164745e4dbe4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:610/format:webp/1*NuPg6ncwm2ceLqeplZLodQ.png"/></div></figure><p id="c9ce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们考虑我们的初始方程:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/6f3aee7dae45f6c18f0da4274b4c31eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:208/format:webp/1*_fPkZ77CTRnR7wtwG-AtLQ.png"/></div></figure><p id="1db7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">两边乘以 X _ 转置矩阵:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nj"><img src="../Images/890604a0b903ee7b013612ca13ef318b.png" data-original-src="https://miro.medium.com/v2/resize:fit:328/format:webp/1*3Nd0n8IRJatxtMAEm3_fZg.png"/></div></div></figure><p id="cc78" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/daf2c9b870a25d862705e599ec956761.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*OmWhv8UfxLsUysuExlvBCg.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/1d34166ef1c095f88d40db1e96d9da7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*1gDZQtWCF0to4iMzIrW64g.png"/></div></figure><p id="3591" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">那是一大堆方程式。但是当我们用下面一个简单的案例来解决它时，它就足够简单了。</p></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><h1 id="1358" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">一个玩具简单线性回归问题的求解</h1><p id="8d32" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">为简单起见，我们将从一个简单的线性回归问题开始，它有 4 个数据点(1，1)，(2，3)，(3，3)和(4，5)。X = [1，2，3，4]，y = [1，3，3，5]。当我们转换成如上所述的矩阵形式时，我们得到:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/46ba0046aeba42257312c27bd52cc8e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:430/format:webp/1*ZPtGeGo60509A-5TbdEjwA.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nn"><img src="../Images/92cd43d249349841e817f0a62b2e9a43.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*nvF6JUo6bMeGxBbYbYymwg.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/980d48f4da3b5fa6b21ee13d660cfe96.png" data-original-src="https://miro.medium.com/v2/resize:fit:594/format:webp/1*byUKF2r9DdTJWdF10l-_Jg.png"/></div></figure><p id="2da8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面是实现这个简单解决方案的 numpy 代码:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="np nq l"/></div></figure></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><h1 id="eb35" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">多元线性回归</h1><p id="4cbc" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">多元线性回归的求解也非常类似于简单线性回归，我们遵循 6 个步骤:</p><ol class=""><li id="5bd4" class="nr ns iq ky b kz la lc ld lf nt lj nu ln nv lr nw nx ny nz bi translated">为 X 矩阵中的截距添加一个从全 1 开始的新列</li><li id="bd8e" class="nr ns iq ky b kz oa lc ob lf oc lj od ln oe lr nw nx ny nz bi translated">取 X 矩阵的转置</li><li id="3050" class="nr ns iq ky b kz oa lc ob lf oc lj od ln oe lr nw nx ny nz bi translated">乘以 X 转置矩阵和 X 矩阵</li><li id="8ae7" class="nr ns iq ky b kz oa lc ob lf oc lj od ln oe lr nw nx ny nz bi translated">求这个矩阵的逆矩阵</li><li id="294b" class="nr ns iq ky b kz oa lc ob lf oc lj od ln oe lr nw nx ny nz bi translated">将 X 转置与 y 矩阵相乘</li><li id="e8fa" class="nr ns iq ky b kz oa lc ob lf oc lj od ln oe lr nw nx ny nz bi translated">将两个矩阵相乘，找出截距和系数</li></ol><p id="3d58" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了解决多元线性回归问题，我从 kaggle 获取了一个数据集，其中包含英国二手车销售价格。</p><p id="7f37" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我在 excel 中手工计算了所有的计算。我已经从大众数据集中取出了前 300 行，并且只取出了其中的数字变量。回归得出的 r 平方得分为 0.77。</p><div class="of og gp gr oh oi"><a href="https://docs.google.com/spreadsheets/d/10zoOfiQLryz0Y7T1Zbd1grvOSdDGEgEEyECZ5sVyKJ8/edit#gid=212170771" rel="noopener  ugc nofollow" target="_blank"><div class="oj ab fo"><div class="ok ab ol cl cj om"><h2 class="bd ir gy z fp on fr fs oo fu fw ip bi translated">大众 _ 回归</h2><div class="op l"><h3 class="bd b gy z fp on fr fs oo fu fw dk translated">数据年份，里程，税，mpg，发动机尺寸，价格 2019，13904，145，49.6，225000 2019，4562，145，49.6，226883…</h3></div><div class="oq l"><p class="bd b dl z fp on fr fs oo fu fw dk translated">docs.google.com</p></div></div><div class="or l"><div class="os l ot ou ov or ow kp oi"/></div></div></a></div><p id="a13a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我敦促你下载 excel 工作簿，并按照计算(谷歌表的新数学字体格式不好。可以下载在 MS excel 上查看，可读性更好)。在“解释”表中，我用矩阵乘以 X_Transpose 和 X。这包含了我们计算模型参数(如 R 平方值)所需的所有信息。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ox"><img src="../Images/e37f46beda749dcb47493ecaf243cf2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vxyVfsrO5t5d0vS9pPhWQg.png"/></div></div></figure><p id="4e9c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请参考 kaggle 笔记本的第三节这里:<a class="ae kv" href="https://www.kaggle.com/gireeshs/diy-build-linear-regression-with-linear-algebra#Part-3:-Multiple-linear-regression" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/gireeshs/DIY-build-linear-regression-with-linear-algebra # Part-3:-Multiple-linear-regression</a>在这里我用矩阵乘法解决了这个问题。</p></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><h1 id="2436" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">参考资料:</h1><ol class=""><li id="311c" class="nr ns iq ky b kz my lc mz lf oy lj oz ln pa lr nw nx ny nz bi translated">【https://www.youtube.com/watch?v=Lx6CfgKVIuE T4】</li><li id="4ede" class="nr ns iq ky b kz oa lc ob lf oc lj od ln oe lr nw nx ny nz bi translated">完整的商业统计手册</li><li id="93a3" class="nr ns iq ky b kz oa lc ob lf oc lj od ln oe lr nw nx ny nz bi translated">我的课程工作为<a class="ae kv" href="https://www.isb.edu/en/study-isb/advanced-management-programmes/ampba.html" rel="noopener ugc nofollow" target="_blank"> ISB CBA </a></li></ol><p id="69aa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">图像:</strong></p><p id="3386" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">【http://onlinestatbook.com/2/regression/intro.html T2】号</p></div></div>    
</body>
</html>