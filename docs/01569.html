<html>
<head>
<title>Imbalanced Classes: Predicting Hotel Cancellations with Support Vector Machines</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不平衡类:用支持向量机预测酒店取消</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/svms-random-forests-and-unbalanced-datasets-predicting-hotel-cancellations-2b983c2c5731?source=collection_archive---------17-----------------------#2020-02-12">https://towardsdatascience.com/svms-random-forests-and-unbalanced-datasets-predicting-hotel-cancellations-2b983c2c5731?source=collection_archive---------17-----------------------#2020-02-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="360e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">当试图构建分类算法时，人们必须经常应对不平衡数据集的问题。</h2></div><p id="00d2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">不平衡数据集</strong>是指类别之间的样本大小不相等，这会导致分类器的预测出现重大偏差。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/6ab4830bbe7f134595a20dbdae3b13e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HB_CBf8eckZwumz6VC0pVg.jpeg"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">来源:照片由<a class="ae lu" href="https://pixabay.com/users/antranias-50356/" rel="noopener ugc nofollow" target="_blank"> Antranias </a>从<a class="ae lu" href="https://pixabay.com/photos/see-saw-swing-swing-device-rock-240650/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>拍摄。</p></figure><p id="71c9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这个特定的例子中(可从下面的参考资料部分获得)，支持向量机(SVM)分类模型用于根据取消风险对酒店预订客户进行分类，即如果模型预测客户将取消预订，则为<strong class="kk iu"> 1 </strong>，如果客户将坚持预订，则为<strong class="kk iu"> 0 </strong>。</p><p id="040e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">H1数据集用于训练和验证模型，而来自结果模型的预测则使用H2数据进行测试。</p><p id="3180" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这个特定的数据集中，非抵消类(0)的样本大小明显大于抵消类(1)。在前面的例子中，这是通过删除大量的<strong class="kk iu"> 0 </strong>条目来处理的，以便在两个类之间具有相等的样本大小。但是，这不一定是最佳方法，因为在此过程中会丢弃许多数据点。</p><p id="1057" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">相反，SVM模型可以被修改，以惩罚对小类的错误预测。让我们看看这是如何影响分析的。</p><p id="a449" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用树外分类器和向前向后特征选择方法进行分析时，所识别的特征如下:</p><ul class=""><li id="4844" class="lv lw it kk b kl km ko kp kr lx kv ly kz lz ld ma mb mc md bi translated">研制周期</li><li id="7600" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">原产国</li><li id="f18f" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">细分市场</li><li id="96d9" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">存款类型</li><li id="691d" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">客户类型</li><li id="ff03" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">所需的停车位</li><li id="6b16" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">到达日期:年</li><li id="8494" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">抵达日期:月</li><li id="8bce" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">到达日期:周数</li><li id="2a90" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">到达日期:当月的某一天</li></ul><h1 id="7f57" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">什么是SVM？</h1><p id="d889" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">SVM是一种监督学习模型，可用于分类和回归任务。</p><p id="b2de" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当定义两个类之间的决策限制时，SVM模型提供了对每个训练点的重要性的评估。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/9c06cd34d7778c3fdbe4e5de9850a3bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/0*nRsSU4G73N9x1Ze9.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">来源:图片由作者创建</p></figure><p id="2181" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">位于两个类别之间的决策边界上的少数训练点被称为支持向量。</p><h1 id="7a62" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">精确度与召回率和f1分数</h1><p id="c8b0" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">当比较准确度分数时，我们看到在每个混淆矩阵中都提供了大量的读数。</p><p id="314d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，在<strong class="kk iu">精度</strong>和<strong class="kk iu">召回</strong>之间存在一个特别重要的区别。</p><pre class="lf lg lh li gt nh ni nj nk aw nl bi"><span id="8f96" class="nm mk it ni b gy nn no l np nq">Precision = ((True Positive)/(True Positive + False Positive))</span><span id="79b0" class="nm mk it ni b gy nr no l np nq">Recall = ((True Positive)/(True Positive + False Negative))</span></pre><p id="af62" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这两个读数经常相互矛盾，也就是说，通常不可能在不降低召回率的情况下提高精确度，反之亦然。</p><p id="491c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对理想指标的评估很大程度上取决于所分析的具体数据。例如，癌症检测筛查出现假阴性(即表明患者没有患癌症，而事实上他们患有癌症)是一大禁忌。在这种情况下，召回是理想的衡量标准。</p><p id="0f57" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，对于电子邮件，人们可能更喜欢避免误报，例如，将一封重要的电子邮件发送到垃圾邮件文件夹，而实际上它是合法的。</p><p id="b2a2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">f1分数在设计一个更通用的分数时考虑了精确度和召回率。</p><p id="969a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">哪个因素对预测酒店取消更重要？</p><p id="fbf1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从酒店的角度来看，他们可能希望更准确地识别出最终会取消预订的客户，这使得酒店能够更好地分配房间和资源。确定不打算取消预订的客户不一定会增加酒店分析的价值，因为酒店知道，无论如何，很大一部分客户最终都会坚持预订。</p><h1 id="331c" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">SVM和不平衡数据集</h1><p id="33cf" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">上面概述的相关特征包括在内，用于确定客户是否将取消他们的预订。</p><pre class="lf lg lh li gt nh ni nj nk aw nl bi"><span id="3ffa" class="nm mk it ni b gy nn no l np nq">y1 = y<br/>x1 = np.column_stack((leadtime,countrycat,marketsegmentcat,deposittypecat,customertypecat,rcps,arrivaldateyear,arrivaldatemonthcat,arrivaldateweekno,arrivaldatedayofmonth))<br/>x1 = sm.add_constant(x1, prepend=True)</span></pre><p id="564c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，数据被分为训练数据和验证数据:</p><pre class="lf lg lh li gt nh ni nj nk aw nl bi"><span id="69f4" class="nm mk it ni b gy nn no l np nq">x1_train, x1_val, y1_train, y1_val = train_test_split(x1, y1, random_state=0)</span></pre><p id="8767" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">可以将“平衡的”类别权重添加到SVM配置中，这对于次要类别(在这种情况下，取消类别)上的错误分类增加了更大的惩罚。</p><pre class="lf lg lh li gt nh ni nj nk aw nl bi"><span id="139d" class="nm mk it ni b gy nn no l np nq">from sklearn import svm<br/>clf = svm.SVC(gamma='scale', <br/>            class_weight='balanced')<br/>clf.fit(x1_train, y1_train)  <br/>prclf = clf.predict(x1_val)<br/>prclf</span></pre><p id="5984" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是该模型在验证集上的分类性能:</p><pre class="lf lg lh li gt nh ni nj nk aw nl bi"><span id="7e5b" class="nm mk it ni b gy nn no l np nq">[[5142 2124]<br/> [ 865 1884]]<br/>              precision    recall  f1-score   support</span><span id="d97d" class="nm mk it ni b gy nr no l np nq">           0       0.86      0.71      0.77      7266<br/>           1       0.47      0.69      0.56      2749</span><span id="7773" class="nm mk it ni b gy nr no l np nq">    accuracy                           0.70     10015<br/>   macro avg       0.66      0.70      0.67     10015<br/>weighted avg       0.75      0.70      0.72     10015</span></pre><p id="eb5a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第一类的回忆率为69%，而f1分数的准确率为70%。现在，让我们在H2(测试集)上测试预测性能。</p><pre class="lf lg lh li gt nh ni nj nk aw nl bi"><span id="6864" class="nm mk it ni b gy nn no l np nq">[[25217 21011]<br/> [ 8436 24666]]<br/>              precision    recall  f1-score   support</span><span id="ab4e" class="nm mk it ni b gy nr no l np nq">           0       0.75      0.55      0.63     46228<br/>           1       0.54      0.75      0.63     33102</span><span id="8529" class="nm mk it ni b gy nr no l np nq">    accuracy                           0.63     79330<br/>   macro avg       0.64      0.65      0.63     79330<br/>weighted avg       0.66      0.63      0.63     79330</span></pre><p id="90eb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们看到，1类的召回率现在达到了75%，而f1分数的准确率达到了63%。值得注意的是，我们可以看到测试集上的f1分数较低，但召回率现在高于验证集。</p><p id="2da0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这方面，如果假设在这种情况下假阳性比假阴性更可容忍，那么人们可以认为该模型在此基础上表现得相当好。</p><h1 id="dc59" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">结论</h1><p id="c2b2" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">在这个例子中，我们看到了如何使用支持向量机来处理不平衡的数据集，以及如何解释混淆矩阵以提高分类的准确性。</p><p id="e85a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以在这里找到原始文章<a class="ae lu" href="https://www.michael-grogan.com/articles/hotel-cancellations-svm" rel="noopener ugc nofollow" target="_blank">，以及本例中所示的数据集和笔记本的相关存储库的链接。</a></p><p id="6470" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="ns">免责声明:本文是在“原样”的基础上编写的，没有担保。本文旨在提供数据科学概念的概述，不应以任何方式解释为专业建议。</em></p><h1 id="7ed2" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">参考</h1><ul class=""><li id="4554" class="lv lw it kk b kl nb ko nc kr nt kv nu kz nv ld ma mb mc md bi translated"><a class="ae lu" href="https://www.sciencedirect.com/science/article/pii/S2352340918315191" rel="noopener ugc nofollow" target="_blank">安东尼奥、阿尔梅迪亚和努内斯(2019)。酒店预订需求数据集</a></li><li id="530d" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated"><a class="ae lu" href="https://elitedatascience.com/imbalanced-classes" rel="noopener ugc nofollow" target="_blank">精英数据科学:如何处理机器学习中的不平衡类</a></li></ul></div></div>    
</body>
</html>