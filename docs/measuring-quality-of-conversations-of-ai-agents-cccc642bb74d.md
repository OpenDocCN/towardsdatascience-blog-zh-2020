# 测量人工智能代理的对话质量

> 原文：<https://towardsdatascience.com/measuring-quality-of-conversations-of-ai-agents-cccc642bb74d?source=collection_archive---------29----------------------->

人工智能(AI)代理无处不在。它们嵌入在你的智能手机(苹果 Siri，谷歌助手)中，它们在你的智能家居设备(亚马逊 Alexa，谷歌 home)中，你可能在与一家公司的客户服务部门交谈时与一些互动，它们嵌入在你访问的许多网站的聊天小工具中；你可能不止一次在与那个代理人交流时感到沮丧。但是为什么还是会这样呢？

![](img/3fa3cdbba6c2a5e8f9d642caea7a8680.png)

来源:[麻省理工科技评论](https://www.google.com/url?sa=i&source=images&cd=&cad=rja&uact=8&ved=2ahUKEwjuutyVw6rnAhWlhHIEHeGlBv0QjB16BAgBEAM&url=https%3A%2F%2Fwww.technologyreview.com%2Fs%2F601279%2Fhow-to-prevent-a-plague-of-dumb-chatbots%2F&psig=AOvVaw0bBnI2bwHsPt-GOxxS_FfQ&ust=1580446206395644)

这种情况仍然发生有许多技术和数据相关的原因，我们现在不会深入探讨，但对改进人工智能代理至关重要的一个主题是**测量**。如果无法衡量，如何改进？

人工智能社区内部普遍存在测量和评估——毕竟他们是科学家，科学家需要证据来证明一些事情。但是如果测量标准不能准确描述实际问题呢？

AI 智能体从出现之日起就被测量过。被广泛接受的用来衡量人工智能代理质量的指标是真正重要的指标。其中一些测量如下:

*   **理解**:机器学习的一个领域叫做自然语言理解，完全是让计算机理解用户在说什么。一些常用的指标是[精度、回忆](https://en.wikipedia.org/wiki/Precision_and_recall)、 [F1](https://en.wikipedia.org/wiki/F1_score) 和 [ROC 曲线](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)来确定计算机理解用户的准确程度。这是一个好的开始，但并不完整。这只是衡量对话的一方(理解用户说了什么)，而不是衡量双方的对话(对话)。
*   **满意度**:另一种测量技术是直接询问用户对响应和/或体验的满意度。一个常用的衡量标准是[客户满意度(CSAT)](https://www.callcentrehelper.com/how-to-calculate-customer-satisfaction-csat-109557.htm) 。这一指标可能不准确，因为用户在回答调查时可能会考虑回答对他们的影响，而不是回答本身。例如，如果在 10 次令人沮丧的互动后，一个人工智能代理告诉我，我中了彩票，见鬼，是的，他们得到了 10/10 的分数。另一方面，如果一个人工智能代理告诉我，我已经超过了我的手机计划的数据限制，我很可能不会得到很好的分数。

正如你所看到的，在能够衡量人工智能代理的对话质量方面一直存在差距——直到本周。

本周早些时候，谷歌大脑团队发布了他们的[研究](https://ai.googleblog.com/2020/01/towards-conversational-agent-that-can.html)，名为“迈向一个可以聊……任何事情的对话代理”，他们发布了一个聊天机器人 *Meena* ，它比其他开放域聊天机器人表现更好。虽然 Meena 产生了令人印象深刻的结果，但我发现更有趣的是谷歌如何测量结果。

谷歌推出了**敏感度和特异性平均值(SSA)** ，它从用户的角度(理应如此)衡量对话。

敏感性和特异性平均(SSA)指标是由 Google 开发的，因为现有的指标很复杂，并且没有在评论者中产生一致的结果。SSA 很简单，通过解决对话的两个基本问题“有意义吗”和“这具体吗”，可以产生更一致的结果。它是这样工作的:

*   **明智的**:要求人类评估者判断计算机的反应是否有意义。如果有任何令人困惑、不合逻辑、断章取义或事实不正确的地方，回答将被标记为“没有意义”——否则，它将被标记为“有意义”，并根据下一个标准进行评估；
*   **Specific** :一旦人类评估者认为某个响应“有意义”，他们就会被要求判断该响应是否特定于给定的上下文。例如，如果用户说“我饿了”,而计算机回复“好的，酷”,则该响应不是特定的，因为相同的响应可以用于许多其他上下文。如果电脑回复“我也是，我们点些吃的吧”，那么这个回复就是具体的。

在评估了数百次对话和数千次来回互动后，可以通过查看标记为“合理”的响应比例和标记为“具体”的响应比例来确定 SSA 分数；这两者的平均值得出 SSA 分数。SSA 提供了对对话质量的更好理解，同时作为一种度量标准简单而优雅。

我已经在人工智能(AI)领域工作了很多年，去年专门构建了对话式 AI 代理。我以前就考虑过这个差距，因为我们现有的测量过程似乎不完整和/或不确定。我知道必须有一个好的方法来衡量整体的对话，但我一直没有找到什么东西。敏感度和特异性平均值(SSA)是一个优雅的指标，在保持简单的同时衡量正确的事情。有希望的是，随着 SSA 在学术界和商业应用中被更广泛地采用，我们将会看到用户与计算机对话的质量有所提高。

对人工智能系统的测量有更多的想法吗？在 [*Twitter*](https://twitter.com/AbhiMathur_) *或*[*LinkedIn*](https://www.linkedin.com/in/abhishek89/)*上打我。*

阿布舍克