<html>
<head>
<title>Deep Learning in Healthcare — X-Ray Imaging (Part 5-Data Augmentation and Image Normalization)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">医疗保健中的深度学习——X 射线成像(第 5 部分——数据扩充和图像标准化)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-in-healthcare-x-ray-imaging-part-5-data-augmentation-and-image-normalization-1ead1c02cfe3?source=collection_archive---------25-----------------------#2020-07-29">https://towardsdatascience.com/deep-learning-in-healthcare-x-ray-imaging-part-5-data-augmentation-and-image-normalization-1ead1c02cfe3?source=collection_archive---------25-----------------------#2020-07-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0043" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">这是深度学习在 X 射线成像上的应用的第 5 部分。这里的重点是实现数据扩充的各种方法。</h2></div><p id="86fc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们在上一部分—第四部分—<a class="ae le" rel="noopener" target="_blank" href="/deep-learning-in-healthcare-x-ray-imaging-part-4-the-class-imbalance-problem-364eff4d47bb">https://towards data science . com/deep-learning-in-health care-x-ray-imaging-Part-4-the-Class-distribution-Problem-364 eff 4d 47 bb</a>中看到了如何解决<strong class="kk iu">阶层失衡问题</strong>。在本节中，我们将重点关注图像规范化和数据扩充。</p></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><p id="ac50" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在解决了类不平衡问题之后，接下来我们来看看如何提高神经网络的性能并使其更快。在训练数据的三个类中，我们已经有了相似数量的图像— 1。正常(无感染)，2。细菌性肺炎，3。病毒性肺炎。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi lm"><img src="../Images/274757b55f1e1c953ef38c0d16d61a23.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*VXr3r0ism1-RdpZn9fv4Yw.jpeg"/></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">每一类中图片数量的条形图——图片来自第四部分(来源:图片由作者创建)</p></figure><p id="9c4c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">图像缩放/归一化:</strong></p><p id="baf6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当所有特征都在同一尺度上时，神经网络工作得最好。类似地，当特征<strong class="kk iu">以平均值零为中心，标准偏差为 1</strong>时，梯度下降等优化算法工作得非常好，即数据具有标准正态分布的属性。</p><p id="e0ee" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这可以通过如下所示的几种方式来实现。</p><p id="b4c0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">案例 1:不推荐</p><pre class="ln lo lp lq gt ly lz ma mb aw mc bi"><span id="16f8" class="md me it lz b gy mf mg l mh mi">scaled_dataset = (dataset - dataset_mean) / dataset_std_deviation<br/><br/>train, test = split(scaled_dataset)</span></pre><p id="4ba2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">整个数据集被缩放，然后分成训练集和测试集。</p><p id="47c5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">案例 2:不推荐</p><pre class="ln lo lp lq gt ly lz ma mb aw mc bi"><span id="259c" class="md me it lz b gy mf mg l mh mi">train, test = split(dataset)<br/><br/>scaled_train =  (train - train_mean) / train_std_deviation<br/><br/>scaled_test = (test - test_mean) / test_std_deviation</span></pre><p id="f0aa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">数据集被分成训练集和测试集，然后分别对训练集和测试集进行缩放。</p><p id="976b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">案例三:推荐</strong></p><pre class="ln lo lp lq gt ly lz ma mb aw mc bi"><span id="8390" class="md me it lz b gy mf mg l mh mi">train, test = split(dataset)</span><span id="635d" class="md me it lz b gy mj mg l mh mi">scaled_train =  (train - train_mean) / train_std_deviation<br/><br/>scaled_test = (test - train_mean) / train_std_deviation</span></pre><p id="c0d6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">数据集被分成训练集和测试集。然后对训练图像进行缩放。为了缩放测试图像，我们使用训练集的平均值和标准偏差，而不是测试图像的平均值和标准偏差。</p><p id="c216" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用训练集的均值和标准差来衡量测试集可能看起来很奇怪，但是<strong class="kk iu">案例 3 是遵循</strong>的最佳方法。原因是:</p><p id="572d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">测试数据是模型的“看不见的数据”,我们使用测试数据来检查模型在看不见的数据下的表现，也就是说，它给出了一个很好的估计，即模型是否可以在现实世界中使用。</p><p id="0875" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，在真实的场景中，我们可能没有一批测试图像来测试我们的模型，而是只有一个图像。在这种情况下，不可能在单个图像上计算平均值和标准偏差。此外，在多个图像的情况下，知道每批测试数据的平均值将有效地给我们的模型带来优势，并且我们不希望模型具有关于测试数据的任何信息。</p><p id="5450" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，解决这个问题的最佳方式是使用案例 3，并使用从训练集计算的统计数据来规范化传入的测试数据。然后，我们将使用这些统计数据来转换我们的测试数据和以后的任何数据。</p></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><h1 id="4e4c" class="mk me it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated"><strong class="ak">数据扩充:</strong></h1><blockquote class="nb nc nd"><p id="a3d4" class="ki kj ne kk b kl km ju kn ko kp jx kq nf ks kt ku ng kw kx ky nh la lb lc ld im bi translated">数据扩充是一种策略，使从业者能够显著增加可用于训练模型的数据的多样性，而无需实际收集新数据。[1]</p></blockquote><p id="d3f9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在第 4 部分(<a class="ae le" rel="noopener" target="_blank" href="/deep-learning-in-healthcare-x-ray-imaging-part-4-the-class-imbalance-problem-364eff4d47bb">https://towards data science . com/deep-learning-in-health care-x-ray-imaging-part-4-the-class-unbalancy-problem-364 eff 4d 47 bb</a>)中，我们已经看到了如何通过使用数据增强来创建人工图像。我们使用 OpenCV 来旋转、平移、翻转和模糊图像。在这里，我们研究如何在 Keras 中进行数据扩充。</p><p id="a24b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">数据增强的优势:</strong></p><ol class=""><li id="c442" class="ni nj it kk b kl km ko kp kr nk kv nl kz nm ld nn no np nq bi translated">改进模型结果</li><li id="4531" class="ni nj it kk b kl nr ko ns kr nt kv nu kz nv ld nn no np nq bi translated">防止过度拟合</li></ol><p id="25f7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了实现这一点，我们将使用 Keras 框架中的<strong class="kk iu"> ImageDataGenerator </strong>类。ImageDataGenerator 通过实时数据扩充帮助生成批量张量图像数据。也就是说，它可以执行所有这些操作:</p><ol class=""><li id="d710" class="ni nj it kk b kl km ko kp kr nk kv nl kz nm ld nn no np nq bi translated">生成数据框中指定的批量图像。</li><li id="58b9" class="ni nj it kk b kl nr ko ns kr nt kv nu kz nv ld nn no np nq bi translated">允许基本的数据扩充技术，如翻转、缩放、缩放、旋转等。</li><li id="e5c5" class="ni nj it kk b kl nr ko ns kr nt kv nu kz nv ld nn no np nq bi translated">转换每批中的值，使它们的平均值为 1，标准偏差为 1。这通过标准化输入分布来帮助模型训练。</li><li id="5c19" class="ni nj it kk b kl nr ko ns kr nt kv nu kz nv ld nn no np nq bi translated">它还通过在所有通道上重复图像中的值，将单通道 X 射线图像(灰度)转换为三通道格式。我们需要这样做，因为我们稍后将用来训练模型的预训练模型需要三通道输入。</li></ol><p id="36ea" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">实现 ImageDataGenerator:</p><p id="9f46" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面的代码是第 3 部分和第 4 部分代码的延续:</p><p id="fdaa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第三部分链接—<a class="ae le" rel="noopener" target="_blank" href="/deep-learning-in-healthcare-x-ray-imaging-part-3-analyzing-images-using-python-915a98fbf14c">https://towards data science . com/deep-learning-in-health care-x-ray-imaging-part-3-analyzing-images-using-python-915 a 98 fbf 14 c</a></p><p id="8c91" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第四部分链接—<a class="ae le" rel="noopener" target="_blank" href="/deep-learning-in-healthcare-x-ray-imaging-part-4-the-class-imbalance-problem-364eff4d47bb">https://towards data science . com/deep-learning-in-health care-x-ray-imaging-part-4-the-class-unbalancy-problem-364 eff 4d 47 bb</a></p><pre class="ln lo lp lq gt ly lz ma mb aw mc bi"><span id="20f4" class="md me it lz b gy mf mg l mh mi"><strong class="lz iu">def</strong> get_train_generator(X_train,y_train, batch_size = 32, shuffle = <strong class="lz iu">True</strong>, seed = 1):<br/>      <br/>    print("getting train generator...") <br/>    <em class="ne"># normalize and augment images</em><br/>    image_generator = ImageDataGenerator(<br/>        samplewise_center=<strong class="lz iu">True</strong>,<br/>        samplewise_std_normalization= <strong class="lz iu">True</strong>,<br/>        rotation_range = 15,<br/>        width_shift_range=0.2,<br/>        height_shift_range=0.2,<br/>        shear_range=0.2,<br/>        zoom_range=0.2,<br/>        fill_mode="nearest",<br/>        cval=0.0,<br/>        rescale = 0.2)<br/>    <br/>    generator = image_generator.flow(<br/>            X_train,<br/>            y=y_train,<br/>            shuffle=shuffle,<br/>            batch_size=batch_size,<br/>            seed=seed<br/>            )<br/>    <br/>    <strong class="lz iu">return</strong> generator</span></pre><p id="059b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上面的代码片段为训练集实现了 ImageDataGenerator。ImageDataGenerator 成批接受图像。这里，批量大小设置为 32，因此它将一次生成 32 个图像。</p><pre class="ln lo lp lq gt ly lz ma mb aw mc bi"><span id="1265" class="md me it lz b gy mf mg l mh mi">samplewise_center=<strong class="lz iu">True</strong>,<br/>samplewise_std_normalization= <strong class="lz iu">True</strong></span></pre><p id="b6be" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这实现了图像标准化。它<strong class="kk iu">将图像像素居中到平均值 0，标准偏差为 1。</strong></p><p id="a6d6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是 Keras 在不需要使用任何公式的情况下进行图像规范化/标准化/缩放的方式。</p></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><p id="b1d4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">可视化 ImageDataGenerator 如何工作:</strong></p><p id="becd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通过一张猫的图片，我们可以看到 ImageDataGenerator 中的各种增强功能是如何工作的</p><pre class="ln lo lp lq gt ly lz ma mb aw mc bi"><span id="62ff" class="md me it lz b gy mf mg l mh mi">#importing the necessary libraries</span><span id="56bf" class="md me it lz b gy mj mg l mh mi"><strong class="lz iu">import</strong> <strong class="lz iu">cv2</strong> <strong class="lz iu">as</strong> <strong class="lz iu">cv</strong><br/><strong class="lz iu">import</strong> <strong class="lz iu">numpy</strong> <strong class="lz iu">as</strong> <strong class="lz iu">np</strong><br/><strong class="lz iu">import</strong> <strong class="lz iu">matplotlib.pyplot</strong> <strong class="lz iu">as</strong> <strong class="lz iu">plt</strong><br/><br/><strong class="lz iu">from</strong> <strong class="lz iu">tensorflow.keras.preprocessing.image</strong> <strong class="lz iu">import</strong> load_img<br/><strong class="lz iu">from</strong> <strong class="lz iu">tensorflow.keras.preprocessing.image</strong> <strong class="lz iu">import</strong> img_to_array<br/><strong class="lz iu">from</strong> <strong class="lz iu">tensorflow.keras.preprocessing.image</strong> <strong class="lz iu">import</strong> ImageDataGenerator</span><span id="15fe" class="md me it lz b gy mj mg l mh mi">#define a function to display 9 augmented images</span><span id="64d6" class="md me it lz b gy mj mg l mh mi"><strong class="lz iu">def</strong> show_image(iterator):<br/><br/>    <em class="ne"># generate samples and plot</em><br/>    <strong class="lz iu">for</strong> i <strong class="lz iu">in</strong> range(9):<br/>        plt.subplot(330 + 1 + i)<br/>        batch = iterator.next()<br/>        image = batch[0].astype('uint8')<br/>        plt.imshow(image)<br/>    plt.show()</span><span id="ba4e" class="md me it lz b gy mj mg l mh mi">#load and display the original image</span><span id="1115" class="md me it lz b gy mj mg l mh mi">img = load_img('cat.jpg') <br/>plt.imshow (img) <br/>data = img_to_array(img) <br/>samples = np.expand_dims(data, 0)</span></pre><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/d21ffa4abae8e3e4b3160421744195e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/format:webp/1*AoSu5_5xtMyobGQlZC_scg.png"/></div></figure><pre class="ln lo lp lq gt ly lz ma mb aw mc bi"><span id="2a9e" class="md me it lz b gy mf mg l mh mi"><strong class="lz iu"><em class="ne"># height_shift_range</em></strong></span><span id="cf04" class="md me it lz b gy mj mg l mh mi">datagen = ImageDataGenerator(height_shift_range=0.5)<br/>iterator = datagen.flow(samples, batch_size=1)<br/><br/>show_image(iterator)</span></pre><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ny nz di oa bf ob"><div class="gh gi nx"><img src="../Images/10a7ce0abb8897f787efa7ebbd6c5ce8.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*a_zVPCHeP7t-AzFVvT76Xw.png"/></div></div></figure><pre class="ln lo lp lq gt ly lz ma mb aw mc bi"><span id="88e9" class="md me it lz b gy mf mg l mh mi"><strong class="lz iu"><em class="ne"># width_shift_range</em></strong></span><span id="dc6b" class="md me it lz b gy mj mg l mh mi">datagen = ImageDataGenerator(width_shift_range=0.5)<br/>iterator = datagen.flow(samples, batch_size=1)<br/><br/>show_image(iterator)</span></pre><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/dd7a7b3edb785320404e39e3fabec75c.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*MRMCTP53ztGAlcKx5KZtVg.png"/></div></figure><pre class="ln lo lp lq gt ly lz ma mb aw mc bi"><span id="4fce" class="md me it lz b gy mf mg l mh mi"><strong class="lz iu"><em class="ne"># rotation_range</em> </strong></span><span id="9f6a" class="md me it lz b gy mj mg l mh mi">datagen = ImageDataGenerator(rotation_range = 50)<br/>iterator = datagen.flow(samples, batch_size=1)<br/><br/>show_image(iterator)</span></pre><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi od"><img src="../Images/d209453420a4369ca26cd9e34f331ff6.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*zeuNxI_OxZXsxQInTpAmZg.png"/></div></figure><pre class="ln lo lp lq gt ly lz ma mb aw mc bi"><span id="9e06" class="md me it lz b gy mf mg l mh mi"><strong class="lz iu"><em class="ne"># shear_range</em> </strong></span><span id="52f0" class="md me it lz b gy mj mg l mh mi">datagen = ImageDataGenerator(shear_range = 50)<br/>iterator = datagen.flow(samples, batch_size=1)<br/><br/>show_image(iterator)</span></pre><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/1f83be47794293438a0af4f62fdc78b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*f_oYddFrbU7XzXpMnbLqKg.png"/></div></figure><pre class="ln lo lp lq gt ly lz ma mb aw mc bi"><span id="e29b" class="md me it lz b gy mf mg l mh mi"><strong class="lz iu"><em class="ne"># brightness_range</em> </strong></span><span id="a5d5" class="md me it lz b gy mj mg l mh mi">datagen = ImageDataGenerator(brightness_range = [0.3,1.9])<br/>iterator = datagen.flow(samples, batch_size=1)<br/><br/>show_image(iterator)</span></pre><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/fadc8d81a16fa2ef47dd390624fb5501.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*VA8bKTFXw9nX1Sl9RgSHbQ.png"/></div></figure><pre class="ln lo lp lq gt ly lz ma mb aw mc bi"><span id="8bfb" class="md me it lz b gy mf mg l mh mi"><strong class="lz iu"><em class="ne"># zoom_range</em></strong></span><span id="03c5" class="md me it lz b gy mj mg l mh mi">datagen = ImageDataGenerator(zoom_range = [0.5,1.5])<br/>iterator = datagen.flow(samples, batch_size=1)<br/><br/>show_image(iterator)</span></pre><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi of"><img src="../Images/953e15e7c64d6aa957d91e6598a2fcf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*SvApJTKxhgcbzFh9rNdHFQ.png"/></div></figure><pre class="ln lo lp lq gt ly lz ma mb aw mc bi"><span id="530f" class="md me it lz b gy mf mg l mh mi"><strong class="lz iu"><em class="ne"># flip</em></strong></span><span id="58d1" class="md me it lz b gy mj mg l mh mi">datagen =ImageDataGenerator(horizontal_flip=<strong class="lz iu">True</strong>,vertical_flip=<strong class="lz iu">True</strong>)<br/>iterator = datagen.flow(samples, batch_size=1)<br/><br/>show_image(iterator)</span></pre><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ny nz di oa bf ob"><div class="gh gi og"><img src="../Images/cca7e6a9d653680910cc48b8bbba9328.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/1*tRcMmxs70h2NxfIYzvArxQ.png"/></div></div></figure><p id="b866" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从图片来看，我相信 ImgaeDataGenerator 中每个函数的作用是可以理解的。更多详情请访问以下链接—【https://keras.io/api/preprocessing/image/ T2】。</p></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><p id="e0a1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">回到 X 射线图像，我们已经看到了如何在训练集上实现 ImageDataGenerator。但是我们不应该直接在测试集上实现，就像在<strong class="kk iu">案例 3 的图像缩放/归一化</strong>中看到的那样(如上所述)。因此，我们为测试和验证集构建了一个单独的生成器。</p><pre class="ln lo lp lq gt ly lz ma mb aw mc bi"><span id="0e55" class="md me it lz b gy mf mg l mh mi"><strong class="lz iu">def</strong> get_test_val_generator(X_train,y_train,X_test,y_test,X_val,y_val,<br/>                      batch_size=32, seed=1, sample_size=100):<br/>    <br/>    raw_train_generator = ImageDataGenerator().flow(<br/>        X_train,y_train, <br/>        batch_size=sample_size, <br/>        shuffle=<strong class="lz iu">False</strong>)<br/>    <br/>    <em class="ne"># get data sample</em><br/>    batch = raw_train_generator.next()<br/>    data_sample = batch[0]<br/><br/>    <em class="ne"># use sample to fit mean and std for test set generator</em><br/>    image_generator = ImageDataGenerator(<br/>        featurewise_center=<strong class="lz iu">True</strong>,<br/>        featurewise_std_normalization= <strong class="lz iu">True</strong>)<br/>    <br/>    <em class="ne"># fit generator to sample from training data</em><br/>    image_generator.fit(data_sample)<br/>    <br/>    <em class="ne"># get test generator</em><br/>    test_generator = image_generator.flow(<br/>            X_test,<br/>            y=y_test,<br/>            batch_size=batch_size,<br/>            shuffle=<strong class="lz iu">False</strong>,<br/>            seed=seed)<br/>    <br/>    <em class="ne">#get validation generator</em><br/>    val_generator = image_generator.flow(<br/>            X_val,<br/>            y=y_val,<br/>            batch_size=batch_size,<br/>            shuffle=<strong class="lz iu">False</strong>,<br/>            seed=seed)<br/>    <br/>    <strong class="lz iu">return</strong> test_generator,val_generator</span></pre><p id="2255" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这个实现中，我们使用训练集的统计数据，并将其应用于测试和验证集。理想情况下，我们希望使用整个训练集来计算样本均值和标准差。<br/>然而，由于这非常大，这将非常耗时。<br/>因此，我们随机抽取数据集样本(在本例中为 100 张图像),并计算样本均值和样本标准差。</p><p id="d189" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来，我们创建训练、测试和验证生成器。</p><pre class="ln lo lp lq gt ly lz ma mb aw mc bi"><span id="02f7" class="md me it lz b gy mf mg l mh mi"><strong class="lz iu"><em class="ne">#create the train, test and validation generator</em> </strong> </span><span id="942e" class="md me it lz b gy mj mg l mh mi">train_generator = get_train_generator(X_train,y_train) </span><span id="9798" class="md me it lz b gy mj mg l mh mi">test_generator,valid_generator = get_test_val_generator(X_train,y_train,X_test,y_test,X_val,y_val)</span></pre><p id="09fb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在生成器被创建之后，我们可视化一些来自训练和测试生成器的图像，看看它们看起来如何。</p><pre class="ln lo lp lq gt ly lz ma mb aw mc bi"><span id="9d80" class="md me it lz b gy mf mg l mh mi"><strong class="lz iu"><em class="ne"># Displays 9 generated train_generator images </em></strong><br/><br/>print('Display Random Images')<br/><br/><em class="ne"># Adjust the size of your images</em><br/>plt.figure(figsize=(20,10))<br/><br/><strong class="lz iu">for</strong> i <strong class="lz iu">in</strong> range(12):<br/>    num = random.randint(1,30)<br/>    plt.subplot(3,4, i + 1)<br/>    <br/>    x,y = train_generator.__getitem__(num)<br/>    <br/>    plt.imshow(x[num],cmap='gray')<br/>    plt.axis('off')<br/>    <br/><em class="ne"># Adjust subplot parameters to give specified padding</em><br/>plt.tight_layout()</span></pre><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ny nz di oa bf ob"><div class="gh gi oh"><img src="../Images/2622a55510962b94c282daf8c18f62cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KSZiQx4adG2snGouhSaTCA.png"/></div></div></figure><pre class="ln lo lp lq gt ly lz ma mb aw mc bi"><span id="5bc4" class="md me it lz b gy mf mg l mh mi"><strong class="lz iu"><em class="ne"># Displays 9 generated test_generator images </em> </strong> </span><span id="d2a1" class="md me it lz b gy mj mg l mh mi">print('Display Random Images')  </span><span id="3235" class="md me it lz b gy mj mg l mh mi"><em class="ne"># Adjust the size of your images</em> </span><span id="9ab9" class="md me it lz b gy mj mg l mh mi">plt.figure(figsize=(20,10))  <br/>   <strong class="lz iu">for</strong> i <strong class="lz iu">in</strong> range(12):     <br/>   num = random.randint(1,17)     <br/>   plt.subplot(3,4, i + 1)          <br/>   x,y = test_generator.__getitem__(num)<br/>   plt.imshow(x[num],cmap='gray')     <br/>   plt.axis('off')    <br/>  <br/><em class="ne"># Adjust subplot parameters to give specified padding</em> plt.tight_layout()</span></pre><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ny nz di oa bf ob"><div class="gh gi oi"><img src="../Images/d99d24ab18c2d119b9cd880b3ed91d18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iZBSVuiJl_1KfL4hkM-MIw.png"/></div></div></figure><p id="483a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们看到图像现在在训练和测试生成器中都被归一化了，但是我们仅在训练生成器上应用了增强，因为神经网络仅在训练图像上训练，并且我们不想干扰测试或验证图像。</p></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><p id="c8e7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">图像被标准化和增强，现在可以输入神经网络。在下一部分中，我们将设计一个神经网络，看看它在将 X 射线图像适当分类到所有三个类别中的效果如何。在后面的部分，我们还将看到如何使用迁移学习进一步改善这些结果。</p></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><p id="f4ec" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">参考资料:</p><ol class=""><li id="cf36" class="ni nj it kk b kl km ko kp kr nk kv nl kz nm ld nn no np nq bi translated"><a class="ae le" href="https://bair.berkeley.edu/blog/2019/06/07/data_aug/#:~:text=Data%20augmentation%20is%20a%20strategy,to%20train%20large%20neural%20networks." rel="noopener ugc nofollow" target="_blank">https://bair.berkeley.edu/blog/2019/06/07/data_aug</a></li></ol></div></div>    
</body>
</html>