<html>
<head>
<title>Text classification with feature selection using Naive Bayes likelihoods</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用朴素贝叶斯似然的特征选择的文本分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/nlp-with-naive-bayes-feature-selection-in-python-15c4d327aad5?source=collection_archive---------34-----------------------#2020-05-02">https://towardsdatascience.com/nlp-with-naive-bayes-feature-selection-in-python-15c4d327aad5?source=collection_archive---------34-----------------------#2020-05-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4102" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用 Python 和一个小型说明性数据集的教程</h2></div><p id="6861" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本文中，我将讨论如何使用朴素贝叶斯似然法来确定重要的特征，即 P(feature | class)。</p><p id="7d9e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">假设我们有一个文本分类任务，作为第一步，我们将把单词标记化和词条化成特征。接下来的问题是，在分类任务中，哪些特征具有最强的预测能力。</p><p id="566d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了简单起见，我们将考虑这个人工玩具天气数据集，其中的特征包括九个与天气相关的英语术语，因变量使用一些未指定的标准来指示天气是否“适合”。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lb"><img src="../Images/356a00ab3c17c619a8a9c7bbcec5c63e.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*En2ycBhj10o0uzc1n4BsZA.png"/></div></figure><p id="1355" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为这只是一个说明性的研究，所以我不想分成训练集和测试集。对全部特征集运行朴素贝叶斯分类会得到以下结果:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lj"><img src="../Images/fcb6ceb6c5579dc7edbf87550f1177cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*GSDfaSkr9edzyA0vkXkG8Q.png"/></div></figure><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lk"><img src="../Images/dbfc4a48f6b0e9eb3b0fa818dd6f9f7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2_k2hwKIwaGgm7Tynf6y3A.png"/></div></div></figure><p id="9249" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，计算要素可能性 p(要素|类)得出:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lp"><img src="../Images/a90aacaff0732656ae9840c12c770258.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*FWxrjo_FA0Mcm0SzHlxBrw.png"/></div></figure><p id="5447" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这里，我按照两个类之间可能性的绝对差异进行排序。你可以看到,<em class="lq">多风</em>的特征最能说明问题:在不适宜的天气(0.27)发生的频率是适宜天气(0.09)的三倍。<em class="lq">无风</em>和<em class="lq">温和</em>特征具有高度预测性，仅在合适的天气中被提及。而特征<em class="lq">多云</em>根本没有预测能力，在合适和不合适的天气中同样可能发生。</p><p id="9196" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我将重新运行仅具有前三个特征的朴素贝叶斯分类:<em class="lq">多风</em>、<em class="lq">平静</em> &amp; <em class="lq">温和</em>:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/6947801bb07e2911fa21b839e1f78546.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*wwvBzHpxntpZm3miQ0YQ_A.png"/></div></figure><p id="226d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可以看到准确率提高了 11 个百分点。</p><p id="27cd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">另请注意，重要的是，由于我们将特征集从九个减少到三个，朴素贝叶斯分类器使用的特征可能性也发生了变化:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi ls"><img src="../Images/870c55f728b1c457ab1c4aa80e25d15e.png" data-original-src="https://miro.medium.com/v2/resize:fit:834/format:webp/1*9JchoGYGfZiglc17nouE2g.png"/></div></figure><p id="b4f4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">实际值与预测值的比较:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/36c49b146379adf183c9bfabd7906a78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*ZQeRuR2QegBDJuxymw7MXg.png"/></div></figure><p id="3bbc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">总之，基于条件似然概率区分能力的特征选择可以提高查准率和查全率。</p><p id="715e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当然，数据集非常简单，结果可能会有所不同。在我的下一篇博文中，我将尝试将这种方法应用于更大的 tweets 语料库。</p><h1 id="d8f6" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">Python 代码</h1><p id="11fd" class="pw-post-body-paragraph kf kg iq kh b ki mm jr kk kl mn ju kn ko mo kq kr ks mp ku kv kw mq ky kz la ij bi translated">我现在将强调实现的一些特性。完整的 Python 代码在这里:<a class="ae mr" href="https://github.com/benlaird/tweet_sentiment/blob/master/feature_selection.py" rel="noopener ugc nofollow" target="_blank">https://github . com/benlaird/tweet _ 情操/blob/master/feature _ selection . py</a></p><p id="08cd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">函数<em class="lq">compute _ relative _ freq _ df</em>使用相对频率计算可能性:</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="5c22" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">内置 Python 函数 SelectKBest 调用的可调用函数:</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="6bb6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我使用的管道:</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="ms mt l"/></div></figure></div></div>    
</body>
</html>