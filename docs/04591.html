<html>
<head>
<title>Day 114 of #NLP365: NLP Papers Summary — A Summarization System for Scientific Documents</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">#NLP365的第114天:NLP论文摘要——科学文献的摘要系统</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/day-114-of-nlp365-nlp-papers-summary-a-summarization-system-for-scientific-documents-aebdc6e081f8?source=collection_archive---------40-----------------------#2020-04-23">https://towardsdatascience.com/day-114-of-nlp365-nlp-papers-summary-a-summarization-system-for-scientific-documents-aebdc6e081f8?source=collection_archive---------40-----------------------#2020-04-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div class="gh gi ir"><img src="../Images/fbe3831891625ccfa7a5401ede20b085.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NAmWzzuXHoD6w2K9Yp9p9Q.jpeg"/></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">阅读和理解研究论文就像拼凑一个未解之谜。汉斯-彼得·高斯特在<a class="ae jc" href="https://unsplash.com/s/photos/research-papers?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片。</p></figure><h2 id="7781" class="jd je jf bd b dl jg jh ji jj jk jl dk jm translated" aria-label="kicker paragraph"><a class="ae ep" href="https://medium.com/towards-data-science/inside-ai/home" rel="noopener">内线艾</a> <a class="ae ep" href="http://towardsdatascience.com/tagged/nlp365" rel="noopener" target="_blank"> NLP365 </a></h2><div class=""/><div class=""><h2 id="a61f" class="pw-subtitle-paragraph kl jo jf bd b km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc dk translated">NLP论文摘要是我总结NLP研究论文要点的系列文章</h2></div><p id="183c" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">项目#NLP365 (+1)是我在2020年每天记录我的NLP学习旅程的地方。在这里，你可以随意查看我在过去的257天里学到了什么。在本文的最后，你可以找到以前的论文摘要，按自然语言处理领域分类:)</p><p id="fe79" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">今天的NLP论文是<strong class="lf jp"> <em class="lz">一个科学文献的摘要系统</em> </strong>。以下是研究论文的要点。</p></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><h1 id="9c4f" class="mh mi jf bd mj mk ml mm mn mo mp mq mr ku ms kv mt kx mu ky mv la mw lb mx my bi translated">目标和贡献</h1><p id="64fb" class="pw-post-body-paragraph ld le jf lf b lg mz kp li lj na ks ll lm nb lo lp lq nc ls lt lu nd lw lx ly im bi translated">用于总结计算机科学研究论文的IBM Science Summariser。该系统可以识别不同的场景，例如科学文档的发现、探索和理解。提议的系统以两种方式总结研究论文:自由文本查询或通过选择分类值，如科学任务、数据集等。提议的系统吸收了270，000篇论文。</p><p id="3c7f" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">IBM Science Summariser生成关注用户查询的摘要(以查询为中心的摘要)。它独立地总结了论文的各个部分，允许用户只关注相关的部分。这允许用户的查询和论文中的各种实体之间的交互。</p><p id="d869" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">下图展示了IBM Science Summariser的用户界面。用户提出他们的查询(或使用元数据字段上的过滤器)。然后，相关论文连同总结结果一起返回。每个部分都清楚地显示，实体精确地突出显示。</p><figure class="nf ng nh ni gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi ne"><img src="../Images/8c7c7179d4f59afd4329d542c86b81e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*Ru5mzQy1onLyEurpRpZglQ.png"/></div></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">IBM Science Summariser的用户界面[1]</p></figure><h1 id="3617" class="mh mi jf bd mj mk nn mm mn mo no mq mr ku np kv mt kx nq ky mv la nr lb mx my bi translated">科学文章的总结——什么，为什么，如何？</h1><p id="83d9" class="pw-post-body-paragraph ld le jf lf b lg mz kp li lj na ks ll lm nb lo lp lq nc ls lt lu nd lw lx ly im bi translated">科学论文的摘要系统由什么组成？</p><ol class=""><li id="d182" class="ns nt jf lf b lg lh lj lk lm nu lq nv lu nw ly nx ny nz oa bi translated">提取结构</li><li id="82ab" class="ns nt jf lf b lg ob lj oc lm od lq oe lu of ly nx ny nz oa bi translated">从PDF中提取表格和图表</li><li id="d9c9" class="ns nt jf lf b lg ob lj oc lm od lq oe lu of ly nx ny nz oa bi translated">识别重要的实体</li><li id="c41e" class="ns nt jf lf b lg ob lj oc lm od lq oe lu of ly nx ny nz oa bi translated">生成有用的摘要</li></ol><h2 id="06b7" class="og mi jf bd mj oh oi dn mn oj ok dp mr lm ol om mt lq on oo mv lu op oq mx jl bi translated">为什么需要这样做？</h2><p id="a422" class="pw-post-body-paragraph ld le jf lf b lg mz kp li lj na ks ll lm nb lo lp lq nc ls lt lu nd lw lx ly im bi translated">以下是学术研究人员的痛点:</p><ol class=""><li id="5c0e" class="ns nt jf lf b lg lh lj lk lm nu lq nv lu nw ly nx ny nz oa bi translated">及时了解当前工作</li><li id="a404" class="ns nt jf lf b lg ob lj oc lm od lq oe lu of ly nx ny nz oa bi translated">准备研究项目/拨款申请</li><li id="390c" class="ns nt jf lf b lg ob lj oc lm od lq oe lu of ly nx ny nz oa bi translated">写论文时准备相关作品</li><li id="ee77" class="ns nt jf lf b lg ob lj oc lm od lq oe lu of ly nx ny nz oa bi translated">检验一个想法的新颖性</li></ol><p id="9f3f" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">第一个痛点往往发生在每天/每周，信息过载，大量时间花在阅读论文上。难点2-4很重要，但不太常见。</p><h2 id="18f6" class="og mi jf bd mj oh oi dn mn oj ok dp mr lm ol om mt lq on oo mv lu op oq mx jl bi translated">研究人员如何搜索和阅读研究论文？</h2><ol class=""><li id="0da4" class="ns nt jf lf b lg mz lj na lm or lq os lu ot ly nx ny nz oa bi translated">研究人员通过关键词、实体(如任务名称、数据集名称或模型等)或引文进行搜索。例如，“班的最先进的结果”</li><li id="9de4" class="ns nt jf lf b lg ob lj oc lm od lq oe lu of ly nx ny nz oa bi translated">阅读标题-&gt;摘要。然而，研究人员提到，摘要的信息量不足以确定相关性</li></ol><h1 id="728e" class="mh mi jf bd mj mk nn mm mn mo no mq mr ku np kv mt kx nq ky mv la nr lb mx my bi translated">系统概况</h1><figure class="nf ng nh ni gt iv gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/7bfd9964005dda47f25c86dcbfcf9f9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:878/format:webp/0*NsdTNHODfDRQWhcc.png"/></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">IBM科学摘要的总体框架[1]</p></figure><p id="b52e" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">该系统(如上图)有两个组件:</p><ol class=""><li id="5970" class="ns nt jf lf b lg lh lj lk lm nu lq nv lu nw ly nx ny nz oa bi translated">摄取管道和搜索引擎(Elasticsearch)</li><li id="87dc" class="ns nt jf lf b lg ob lj oc lm od lq oe lu of ly nx ny nz oa bi translated">总结</li></ol><h2 id="160d" class="og mi jf bd mj oh oi dn mn oj ok dp mr lm ol om mt lq on oo mv lu op oq mx jl bi translated">摄入管道</h2><p id="101b" class="pw-post-body-paragraph ld le jf lf b lg mz kp li lj na ks ll lm nb lo lp lq nc ls lt lu nd lw lx ly im bi translated">该系统包含来自arXiv和ACL的270，000篇论文。管道由3个主要步骤组成:</p><ol class=""><li id="de54" class="ns nt jf lf b lg lh lj lk lm nu lq nv lu nw ly nx ny nz oa bi translated">提取论文的正文、表格和图表</li><li id="bed2" class="ns nt jf lf b lg ob lj oc lm od lq oe lu of ly nx ny nz oa bi translated">使用注释和实体丰富元数据</li><li id="786e" class="ns nt jf lf b lg ob lj oc lm od lq oe lu of ly nx ny nz oa bi translated">实体提取</li></ol><p id="9bc1" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">该系统使用Science-Parse提取PDF文本、表格和图表。Science-Parse支持将图形和表格提取到图像文件(及其标题文本)中。检测文本段落中的图表引用。我们还提取了任务、数据集和指标。输出以JSON格式返回。Elasticsearch用于索引论文，我们索引其标题、摘要文本、章节文本和一些元数据。</p><p id="610c" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">该系统有三种类型的实体:任务、数据集和指标。实现了基于字典和基于学习的方法。基于字典的是使用paperswithcode网站手工创建的。为了涵盖所有不断发展的主题，我们采用了基于学习的方法来分析整篇论文，以提取三种类型的实体。这被视为一个文本蕴涵任务，其中论文内容是文本和目标任务-数据集-指标(TDM)三元组作为假设。这种方法迫使模型学习文本和三元组之间的相似性模式。总体而言，该系统已经索引了来自整个语料库的872个任务、345个数据集和62个指标。</p><h2 id="20f9" class="og mi jf bd mj oh oi dn mn oj ok dp mr lm ol om mt lq on oo mv lu op oq mx jl bi translated">总结</h2><p id="4263" class="pw-post-body-paragraph ld le jf lf b lg mz kp li lj na ks ll lm nb lo lp lq nc ls lt lu nd lw lx ly im bi translated">摘要可以是通用的，也可以是针对查询的。各节之间的语言可能有很大的不同，因此各节被独立地总结，然后这些基于节的总结被组合在一起成为一个总结。摘要的输入是查询(可选)、实体和搜索引擎返回的相关论文。总结分为多个步骤:</p><ol class=""><li id="e810" class="ns nt jf lf b lg lh lj lk lm nu lq nv lu nw ly nx ny nz oa bi translated">查询处理</li><li id="46ed" class="ns nt jf lf b lg ob lj oc lm od lq oe lu of ly nx ny nz oa bi translated">预处理</li><li id="96a3" class="ns nt jf lf b lg ob lj oc lm od lq oe lu of ly nx ny nz oa bi translated">总结</li></ol><p id="dfae" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如果给出查询Q，它可以非常精确，也可以非常详细。如果它简短而精确，我们将使用查询扩展来扩展它，查询扩展将Q转换为100个单字项(通过分析从Q返回的顶级论文获得)。如果Q是verbose，则使用定点加权模式对查询词进行排序。如果没有问题，论文的关键短语被用作查询的代理。</p><p id="220e" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在预处理方面，我们执行句子标记化、单词标记化、小写和停用词的去除。每个句子然后被转换成单字母和双字母BoW表示。</p><p id="ea16" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在摘要方面，我们使用了SOTA无监督的、提取的、查询聚焦的摘要算法。该算法接受论文部分、查询Q、期望的摘要长度(10个句子)和一组链接到查询的实体。生成的摘要是通过非监督优化方案从论文部分选择的句子的子集。这句话的选择是提出了一个多标准优化问题，其中几个总结质量目标的考虑。这些汇总质量是:</p><ol class=""><li id="8570" class="ns nt jf lf b lg lh lj lk lm nu lq nv lu nw ly nx ny nz oa bi translated"><em class="lz">查询显著度</em>。摘要是否包含许多与查询相关的术语(余弦相似度)？</li><li id="7d2c" class="ns nt jf lf b lg ob lj oc lm od lq oe lu of ly nx ny nz oa bi translated"><em class="lz">实体覆盖</em>。摘要中包含的实体与我们的实体集匹配吗？</li><li id="3dbe" class="ns nt jf lf b lg ob lj oc lm od lq oe lu of ly nx ny nz oa bi translated"><em class="lz">文字报道</em>。总结涵盖了论文部分的多少内容？</li><li id="2708" class="ns nt jf lf b lg ob lj oc lm od lq oe lu of ly nx ny nz oa bi translated"><em class="lz">句子长度</em>。我们希望摘要偏向于更长的句子，这样会提供更多的信息。</li></ol><h1 id="0bd2" class="mh mi jf bd mj mk nn mm mn mo no mq mr ku np kv mt kx nq ky mv la nr lb mx my bi translated">人类评估</h1><h2 id="8df7" class="og mi jf bd mj oh oi dn mn oj ok dp mr lm ol om mt lq on oo mv lu op oq mx jl bi translated">评估设置</h2><p id="2df5" class="pw-post-body-paragraph ld le jf lf b lg mz kp li lj na ks ll lm nb lo lp lq nc ls lt lu nd lw lx ly im bi translated">我们接触了12位作者，请他们评价他们合著的两篇论文的摘要。这样我们总共有24篇论文。对于每篇论文，我们生成两种类型的摘要:基于章节的摘要和与章节无关的摘要(将论文内容视为平面文本)。这是为了让我们评估部门总结的好处。这使我们总共有48个摘要需要评估。</p><p id="88ad" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">作者需要对每个摘要执行3项任务:</p><ol class=""><li id="7626" class="ns nt jf lf b lg lh lj lk lm nu lq nv lu nw ly nx ny nz oa bi translated">对于每个句子，确定该句子是否应该作为摘要的一部分(精度的二进制度量)</li><li id="c985" class="ns nt jf lf b lg ob lj oc lm od lq oe lu of ly nx ny nz oa bi translated">总结中涵盖论文各部分的程度(回忆的衡量标准，1-5分，3分为好)</li><li id="71d8" class="ns nt jf lf b lg ob lj oc lm od lq oe lu of ly nx ny nz oa bi translated">评估摘要的整体质量(1-5分，3分为好)</li></ol><h2 id="9a75" class="og mi jf bd mj oh oi dn mn oj ok dp mr lm ol om mt lq on oo mv lu op oq mx jl bi translated">结果</h2><p id="086b" class="pw-post-body-paragraph ld le jf lf b lg mz kp li lj na ks ll lm nb lo lp lq nc ls lt lu nd lw lx ly im bi translated">结果如下图所示。在任务2中，68%的论文以章节为基础的总结得分较高。基于章节的摘要的平均分数是3.32，这突出了基于章节的摘要的质量。</p><figure class="nf ng nh ni gt iv gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/10b6a9330c87b500b0d0f6fe6dfc102b.png" data-original-src="https://miro.medium.com/v2/resize:fit:690/format:webp/1*g6ukByeQErAg_iL-TmVe8Q.png"/></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">总结结果——不可知部分与基于部分的对比[1]</p></figure><h1 id="495f" class="mh mi jf bd mj mk nn mm mn mo no mq mr ku np kv mt kx nq ky mv la nr lb mx my bi translated">结论和未来工作</h1><p id="d3af" class="pw-post-body-paragraph ld le jf lf b lg mz kp li lj na ks ll lm nb lo lp lq nc ls lt lu nd lw lx ly im bi translated">作为未来的工作，IBM Science Summariser计划增加对更多实体的支持，并吸收更多的论文。正在进行更多的定性研究，以评估其使用情况和摘要质量，包括摘要的自动评价。</p><h2 id="6791" class="og mi jf bd mj oh oi dn mn oj ok dp mr lm ol om mt lq on oo mv lu op oq mx jl bi translated">来源:</h2><p id="ae9c" class="pw-post-body-paragraph ld le jf lf b lg mz kp li lj na ks ll lm nb lo lp lq nc ls lt lu nd lw lx ly im bi translated">[1] Erera，s .，shmu Eli-朔伊尔，m .，Feigenblat，g .，Nakash，O.P .，Boni，o .，Roitman，h .，Cohen，d .，Weiner，b .，Mass，y .，Rivlin，o .和Lev，g .，2019 .科学文献摘要系统。<em class="lz"> arXiv预印本arXiv:1908.11152 </em>。</p><p id="2fff" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><em class="lz">原载于2020年4月23日https://ryanong.co.uk</em><a class="ae jc" href="https://ryanong.co.uk/2020/04/23/day-114-nlp-papers-summary-a-summarization-system-for-scientific-documents/" rel="noopener ugc nofollow" target="_blank"><em class="lz"/></a><em class="lz">。</em></p></div><div class="ab cl ma mb hx mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="im in io ip iq"><h1 id="2232" class="mh mi jf bd mj mk ml mm mn mo mp mq mr ku ms kv mt kx mu ky mv la mw lb mx my bi translated">特征提取/基于特征的情感分析</h1><ul class=""><li id="16b6" class="ns nt jf lf b lg mz lj na lm or lq os lu ot ly ow ny nz oa bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-102-of-nlp365-nlp-papers-summary-implicit-and-explicit-aspect-extraction-in-financial-bdf00a66db41">https://towards data science . com/day-102-of-NLP 365-NLP-papers-summary-implicit-and-explicit-aspect-extraction-in-financial-BDF 00 a 66 db 41</a></li><li id="bcf3" class="ns nt jf lf b lg ob lj oc lm od lq oe lu of ly ow ny nz oa bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-103-nlp-research-papers-utilizing-bert-for-aspect-based-sentiment-analysis-via-constructing-38ab3e1630a3">https://towards data science . com/day-103-NLP-research-papers-utilizing-Bert-for-aspect-based-sense-analysis-via-construction-38ab 3e 1630 a3</a></li><li id="0ad6" class="ns nt jf lf b lg ob lj oc lm od lq oe lu of ly ow ny nz oa bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-104-of-nlp365-nlp-papers-summary-sentihood-targeted-aspect-based-sentiment-analysis-f24a2ec1ca32">https://towards data science . com/day-104-of-NLP 365-NLP-papers-summary-senthious-targeted-aspect-based-sensitive-analysis-f 24 a2 EC 1 ca 32</a></li><li id="e5e4" class="ns nt jf lf b lg ob lj oc lm od lq oe lu of ly ow ny nz oa bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-105-of-nlp365-nlp-papers-summary-aspect-level-sentiment-classification-with-3a3539be6ae8">https://towards data science . com/day-105-of-NLP 365-NLP-papers-summary-aspect-level-sensation-class ification-with-3a 3539 be 6 AE 8</a></li><li id="8622" class="ns nt jf lf b lg ob lj oc lm od lq oe lu of ly ow ny nz oa bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-106-of-nlp365-nlp-papers-summary-an-unsupervised-neural-attention-model-for-aspect-b874d007b6d0">https://towards data science . com/day-106-of-NLP 365-NLP-papers-summary-an-unsupervised-neural-attention-model-for-aspect-b 874d 007 b 6d 0</a></li><li id="c90f" class="ns nt jf lf b lg ob lj oc lm od lq oe lu of ly ow ny nz oa bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-110-of-nlp365-nlp-papers-summary-double-embeddings-and-cnn-based-sequence-labelling-for-b8a958f3bddd">https://towardsdatascience . com/day-110-of-NLP 365-NLP-papers-summary-double-embedding-and-CNN-based-sequence-labeling-for-b8a 958 F3 bddd</a></li><li id="2bbf" class="ns nt jf lf b lg ob lj oc lm od lq oe lu of ly ow ny nz oa bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-112-of-nlp365-nlp-papers-summary-a-challenge-dataset-and-effective-models-for-aspect-based-35b7a5e245b5">https://towards data science . com/day-112-of-NLP 365-NLP-papers-summary-a-challenge-dataset-and-effective-models-for-aspect-based-35b 7 a5 e 245 b5</a></li></ul><h1 id="2c1b" class="mh mi jf bd mj mk nn mm mn mo no mq mr ku np kv mt kx nq ky mv la nr lb mx my bi translated">总结</h1><ul class=""><li id="1069" class="ns nt jf lf b lg mz lj na lm or lq os lu ot ly ow ny nz oa bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-107-of-nlp365-nlp-papers-summary-make-lead-bias-in-your-favor-a-simple-and-effective-4c52b1a569b8">https://towards data science . com/day-107-of-NLP 365-NLP-papers-summary-make-lead-bias-in-your-favor-a-simple-effective-4c 52 B1 a 569 b 8</a></li><li id="ff87" class="ns nt jf lf b lg ob lj oc lm od lq oe lu of ly ow ny nz oa bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-109-of-nlp365-nlp-papers-summary-studying-summarization-evaluation-metrics-in-the-619f5acb1b27">https://towards data science . com/day-109-of-NLP 365-NLP-papers-summary-studing-summary-evaluation-metrics-in-the-619 F5 acb1b 27</a></li><li id="90ba" class="ns nt jf lf b lg ob lj oc lm od lq oe lu of ly ow ny nz oa bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-113-of-nlp365-nlp-papers-summary-on-extractive-and-abstractive-neural-document-87168b7e90bc">https://towards data science . com/day-113-of-NLP 365-NLP-papers-summary-on-extractive-and-abstract-neural-document-87168 b 7 e 90 BC</a></li></ul><h1 id="e98b" class="mh mi jf bd mj mk nn mm mn mo no mq mr ku np kv mt kx nq ky mv la nr lb mx my bi translated">其他人</h1><ul class=""><li id="95da" class="ns nt jf lf b lg mz lj na lm or lq os lu ot ly ow ny nz oa bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-108-of-nlp365-nlp-papers-summary-simple-bert-models-for-relation-extraction-and-semantic-98f7698184d7">https://towards data science . com/day-108-of-NLP 365-NLP-papers-summary-simple-Bert-models-for-relation-extraction-and-semantic-98f 7698184 D7</a></li><li id="9b95" class="ns nt jf lf b lg ob lj oc lm od lq oe lu of ly ow ny nz oa bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/day-111-of-nlp365-nlp-papers-summary-the-risk-of-racial-bias-in-hate-speech-detection-bff7f5f20ce5">https://towards data science . com/day-111-of-NLP 365-NLP-papers-summary-the-risk-of-race-of-bias-in-hate-speech-detection-BFF 7 F5 f 20 ce 5</a></li></ul></div></div>    
</body>
</html>