<html>
<head>
<title>Data Transformation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据转换</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data-transformation-e7b3b4268151?source=collection_archive---------31-----------------------#2020-08-18">https://towardsdatascience.com/data-transformation-e7b3b4268151?source=collection_archive---------31-----------------------#2020-08-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="2c2f" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">📈Python for finance 系列</h2><div class=""/><div class=""><h2 id="f72e" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">如何将现代机器学习应用于体积扩散分析(VSA)</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/c276200c7e5ec74675a94025295bc861.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z2JkqA9n7NUjpjoqEnHzBA.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae lh" href="https://unsplash.com/@jeremythomasphoto?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">杰瑞米·托马斯</a>在<a class="ae lh" href="https://unsplash.com/s/photos/leaves-wallpaper?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="eb93" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">警告</strong>:这里没有神奇的公式<em class="me">或圣杯，尽管一个新的世界可能会为你打开大门。</em></p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h2 id="2dee" class="mm mn it bd mo mp mq dn mr ms mt dp mu lr mv mw mx lv my mz na lz nb nc nd iz bi translated">📈Python For Finance 系列</h2><ol class=""><li id="b687" class="ne nf it lk b ll ng lo nh lr ni lv nj lz nk md nl nm nn no bi translated"><a class="ae lh" href="https://medium.com/python-in-plain-english/identifying-outliers-part-one-c0a31d9faefa" rel="noopener">识别异常值</a></li><li id="9376" class="ne nf it lk b ll np lo nq lr nr lv ns lz nt md nl nm nn no bi translated"><a class="ae lh" href="https://medium.com/better-programming/identifying-outliers-part-two-4c00b2523362" rel="noopener">识别异常值—第二部分</a></li><li id="62cb" class="ne nf it lk b ll np lo nq lr nr lv ns lz nt md nl nm nn no bi translated"><a class="ae lh" href="https://medium.com/swlh/identifying-outliers-part-three-257b09f5940b" rel="noopener">识别异常值—第三部分</a></li><li id="58d2" class="ne nf it lk b ll np lo nq lr nr lv ns lz nt md nl nm nn no bi translated"><a class="ae lh" rel="noopener" target="_blank" href="/data-whispering-eebb77a422da">程式化的事实</a></li><li id="53ed" class="ne nf it lk b ll np lo nq lr nr lv ns lz nt md nl nm nn no bi translated"><a class="ae lh" href="https://medium.com/@kegui/feature-engineering-feature-selection-8c1d57af18d2" rel="noopener">特征工程&amp;特征选择</a></li><li id="eae1" class="ne nf it lk b ll np lo nq lr nr lv ns lz nt md nl nm nn no bi translated"><a class="ae lh" rel="noopener" target="_blank" href="/data-transformation-e7b3b4268151">数据转换</a></li><li id="2d00" class="ne nf it lk b ll np lo nq lr nr lv ns lz nt md nl nm nn no bi translated"><a class="ae lh" href="https://medium.com/swlh/fractionally-differentiated-features-9c1947ed2b55" rel="noopener">细微差别特征</a></li><li id="6243" class="ne nf it lk b ll np lo nq lr nr lv ns lz nt md nl nm nn no bi translated"><a class="ae lh" rel="noopener" target="_blank" href="/the-triple-barrier-method-251268419dcd">数据标签</a></li><li id="3abf" class="ne nf it lk b ll np lo nq lr nr lv ns lz nt md nl nm nn no bi translated"><a class="ae lh" rel="noopener" target="_blank" href="/meta-labeling-and-stacking-f17a7f9804ec">元标签和堆叠</a></li></ol></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="3dc2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在预览文章中，我简要介绍了体积扩散分析(VSA)。在我们完成特征工程和特征选择后，我立即注意到两件事，第一件是数据集中有异常值，第二件是分布不接近正态分布。通过使用这里描述的<a class="ae lh" href="https://medium.com/python-in-plain-english/identifying-outliers-part-one-c0a31d9faefa" rel="noopener"/>、这里描述的<a class="ae lh" href="https://medium.com/@kegui/identifying-outliers-part-two-4c00b2523362" rel="noopener"/>和这里描述的<a class="ae lh" href="https://medium.com/swlh/identifying-outliers-part-three-257b09f5940b" rel="noopener"/>的方法，我去除了大部分的异常值。现在是时候面对更大的问题了，常态。</p><p id="984e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">有许多方法可以传输数据。众所周知的一个例子是<a class="ae lh" href="https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/" rel="noopener ugc nofollow" target="_blank">一键编码</a>，更好的例子是自然语言处理(NLP)中的<a class="ae lh" href="https://en.wikipedia.org/wiki/Word_embedding" rel="noopener ugc nofollow" target="_blank">单词嵌入</a>。考虑到使用深度学习的一个优势是，它完全自动化了过去机器学习工作流程中最关键的步骤:特征工程。在后面的文章进入深度学习之前，我们先来看看一些简单的转移数据的方法，看看能否让它更接近正态分布。</p><p id="5749" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这篇文章中，我想尝试几件事。第一种是将所有特征转换成简单的百分比变化。第二个是做百分位数排名。最后，我将向您展示，如果我只选择所有数据的符号，会发生什么。像 Z-score 这样的方法，是深度学习中的标准预处理，我宁愿暂时不做。</p><h1 id="a0f4" class="nu mn it bd mo nv nw nx mr ny nz oa mu ki ob kj mx kl oc km na ko od kp nd oe bi translated">1.数据准备</h1><p id="9b72" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr of lt lu lv og lx ly lz oh mb mc md im bi translated">为了一致性，在所有的<a class="ae lh" href="https://medium.com/swlh/identifying-outliers-part-three-257b09f5940b" rel="noopener">📈Python for finance 系列</a>，我会尽量重用相同的数据。关于数据准备的更多细节可以在<a class="ae lh" href="https://medium.com/python-in-plain-english/identifying-outliers-part-one-c0a31d9faefa" rel="noopener">这里</a>，这里<a class="ae lh" href="https://medium.com/@kegui/identifying-outliers-part-two-4c00b2523362" rel="noopener">这里</a>和<a class="ae lh" href="https://medium.com/swlh/identifying-outliers-part-three-257b09f5940b" rel="noopener">这里</a>找到，或者你可以参考我之前的<a class="ae lh" href="https://medium.com/@kegui/feature-engineering-feature-selection-8c1d57af18d2" rel="noopener">文章</a>。或者，如果你愿意，你可以忽略下面的所有代码，使用你手头上任何干净的数据，这不会影响我们将要一起做的事情。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="f88f" class="mm mn it oj b gy on oo l op oq">#import all the libraries<br/>import pandas as pd<br/>import numpy as np<br/>import seaborn as sns <br/>import yfinance as yf  #the stock data from Yahoo Finance<br/>import matplotlib.pyplot as plt #set the parameters for plotting<br/>plt.style.use('seaborn')<br/>plt.rcParams['figure.dpi'] = 300</span><span id="8503" class="mm mn it oj b gy or oo l op oq">#define a function to get data<br/>def get_data(symbols, begin_date=None,end_date=None):<br/>    df = yf.download('AAPL', start = '2000-01-01',<br/>                     auto_adjust=True,#only download adjusted data<br/>                     end= '2010-12-31') <br/>    #my convention: always lowercase<br/>    df.columns = ['open','high','low',<br/>                  'close','volume'] <br/>    <br/>    return df</span><span id="e885" class="mm mn it oj b gy or oo l op oq">prices = get_data('AAPL', '2000-01-01', '2010-12-31')</span><span id="87b5" class="mm mn it oj b gy or oo l op oq">#create some features<br/>def create_HLCV(i):<br/>#as we don't care open that much, that leaves volume, <br/>#high,low and close <br/>    df = pd.DataFrame(index=prices.index)<br/>    df[f'high_{i}D'] = prices.high.rolling(i).max()<br/>    df[f'low_{i}D'] = prices.low.rolling(i).min()<br/>    df[f'close_{i}D'] = prices.close.rolling(i).\<br/>                        apply(lambda x:x[-1]) <br/>    # close_2D = close as rolling backwards means today is <br/>    # literly the last day of the rolling window.<br/>    df[f'volume_{i}D'] = prices.volume.rolling(i).sum()<br/>    <br/>    return df</span><span id="a173" class="mm mn it oj b gy or oo l op oq"># create features at different rolling windows<br/>def create_features_and_outcomes(i):<br/>    df = create_HLCV(i)<br/>    high = df[f'high_{i}D']<br/>    low = df[f'low_{i}D']<br/>    close = df[f'close_{i}D']<br/>    volume = df[f'volume_{i}D']<br/>    <br/>    features = pd.DataFrame(index=prices.index)<br/>    outcomes = pd.DataFrame(index=prices.index)<br/>    <br/>    #as we already considered the different time span, <br/>    #here only day of simple percentage change used.<br/>   <br/>    features[f'volume_{i}D'] = volume.pct_change()<br/>    features[f'price_spread_{i}D'] = (high - low).pct_change()<br/>    #aligne the close location with the stock price change<br/>    features[f'close_loc_{i}D'] = ((close - low) / \<br/>                             (high -   low)).pct_change()</span><span id="b31c" class="mm mn it oj b gy or oo l op oq">    #the future outcome is what we are going to predict<br/>    outcomes[f'close_change_{i}D'] = close.pct_change(-i)<br/>       <br/>    return features, outcomes</span><span id="5158" class="mm mn it oj b gy or oo l op oq">def create_bunch_of_features_and_outcomes():<br/>    '''<br/>    the timespan that i would like to explore <br/>    are 1, 2, 3 days and 1 week, 1 month, 2 month, 3 month<br/>    which roughly are [1,2,3,5,20,40,60]<br/>    '''<br/>    days = [1,2,3,5,20,40,60]<br/>    bunch_of_features = pd.DataFrame(index=prices.index)<br/>    bunch_of_outcomes = pd.DataFrame(index=prices.index)<br/>    <br/>    for day in days:<br/>        f,o = create_features_and_outcomes(day)<br/>        bunch_of_features = bunch_of_features.join(f)<br/>        bunch_of_outcomes = bunch_of_outcomes .join(o)<br/>        <br/>    return bunch_of_features, bunch_of_outcomes</span><span id="9cfa" class="mm mn it oj b gy or oo l op oq">bunch_of_features, bunch_of_outcomes = create_bunch_of_features_and_outcomes()</span><span id="5792" class="mm mn it oj b gy or oo l op oq">#define the method to identify outliers<br/>def get_outliers(df, i=4): <br/>    #i is number of sigma, which define the boundary along mean<br/>    outliers = pd.DataFrame()<br/>    stats = df.describe()<br/>    <br/>    for col in df.columns:<br/>        mu = stats.loc['mean', col]<br/>        sigma = stats.loc['std', col]<br/>        condition = (df[col] &gt; mu + sigma * i) | \<br/>                  (df[col] &lt; mu -   sigma * i) <br/>        outliers[f'{col}_outliers'] = df[col][condition]<br/>    <br/>    return outliers</span><span id="96e0" class="mm mn it oj b gy or oo l op oq">#remove all the outliers<br/>features_outcomes = bunch_of_features.join(bunch_of_outcomes)<br/>outliers = get_outliers(features_outcomes, i=1)</span><span id="19ad" class="mm mn it oj b gy or oo l op oq">features_outcomes_rmv_outliers = features_outcomes.drop(index = outliers.index).dropna()</span><span id="b623" class="mm mn it oj b gy or oo l op oq">features = features_outcomes_rmv_outliers[bunch_of_features.columns]<br/>outcomes = features_outcomes_rmv_outliers[bunch_of_outcomes.columns]<br/>features.info(), outcomes.info()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi os"><img src="../Images/27903ffff3bb6e8342604005c12809f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:706/format:webp/1*TS0S3pRnVvGmJ07YS3z2FQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">要素数据集的信息</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/b536e721faabf7e33b8e97f5ab6ff72b.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*CWfwN1fVpSH8Ki0DFhw8yA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">结果数据集信息</p></figure><p id="f240" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最后，我们将具有基于不同时间尺度的量差分析(VSA)的基本四个特征，如下所列，即 1 天、2 天、3 天、一周、一个月、2 个月和 3 个月。</p><ul class=""><li id="be30" class="ne nf it lk b ll lm lo lp lr ou lv ov lz ow md ox nm nn no bi translated">音量:非常直接</li><li id="b243" class="ne nf it lk b ll np lo nq lr nr lv ns lz nt md ox nm nn no bi translated">范围/价差:最高价和收盘价之间的差异</li><li id="847c" class="ne nf it lk b ll np lo nq lr nr lv ns lz nt md ox nm nn no bi translated">收盘价相对于区间:收盘价是接近价格柱的顶部还是底部？</li><li id="c7b4" class="ne nf it lk b ll np lo nq lr nr lv ns lz nt md ox nm nn no bi translated">股票价格的变化:非常直接</li></ul><h1 id="bad5" class="nu mn it bd mo nv nw nx mr ny nz oa mu ki ob kj mx kl oc km na ko od kp nd oe bi translated">2.百分比回报</h1><p id="735e" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr of lt lu lv og lx ly lz oh mb mc md im bi translated">我知道上面有很多代码。我们通过下面的函数将所有特征转换成简单的百分比变化。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="0131" class="mm mn it oj b gy on oo l op oq">def create_features_and_outcomes(i):<br/>    df = create_HLCV(i)<br/>    high = df[f'high_{i}D']<br/>    low = df[f'low_{i}D']<br/>    close = df[f'close_{i}D']<br/>    volume = df[f'volume_{i}D']<br/>    <br/>    features = pd.DataFrame(index=prices.index)<br/>    outcomes = pd.DataFrame(index=prices.index)<br/>    <br/>    #as we already considered the different time span, <br/>    #here only 1 day of simple percentage change used.<br/>   <br/>    features[f'volume_{i}D'] = volume.pct_change()<br/>    features[f'price_spread_{i}D'] = (high - low).pct_change()<br/>    #aligne the close location with the stock price change<br/>    features[f'close_loc_{i}D'] = ((close - low) / \<br/>    (high -    low)).pct_change()</span><span id="0486" class="mm mn it oj b gy or oo l op oq">#the future outcome is what we are going to predict<br/>    outcomes[f'close_change_{i}D'] = close.pct_change(-i)<br/>       <br/>    return features, outcomes</span></pre><p id="6ba1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，让我们用聚类图来看看它们的相关性。Seaborn 的<code class="fe oy oz pa oj b"> clustermap()</code>层次聚类算法展示了一种将最密切相关的特征分组的好方法。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="1fd4" class="mm mn it oj b gy on oo l op oq">corr_features = features.corr().sort_index()<br/>sns.clustermap(corr_features, cmap='coolwarm', linewidth=1);</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/f34519f18e1e8cff5a1ef6f9afef6822.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*KQ2QWmvBsDZ6iAutCfaSqg.png"/></div></figure><p id="8f48" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">基于此聚类图，为了最大限度地减少所选要素中的要素重叠量，我将移除那些与其他要素紧密配对且与结果目标相关性较小的要素。从上面的聚类图中，很容易发现[40D，60D]和[2D，3D]上的特征是成对出现的。为了了解这些特征与结果之间的关系，我们先来看看结果之间的关系。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="bd58" class="mm mn it oj b gy on oo l op oq">corr_outcomes = outcomes.corr()<br/>sns.clustermap(corr_outcomes, cmap='coolwarm', linewidth=2);</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/281625fcbd78c14547538a63f822b8c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1324/format:webp/1*ilDBNYnz6ipCudH93nDsEQ.png"/></div></figure><p id="bd43" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">从上到下，20 天、40 天和 60 天的价格百分比变化被分组在一起，2 天、3 天和 5 天也是如此。然而，一天的股价百分比变化相对独立于这两组。如果我们选择第二天的价格百分比变化作为结果目标，让我们看看这些特性是如何与之相关的。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="8d01" class="mm mn it oj b gy on oo l op oq">corr_features_outcomes = features.corrwith(outcomes. \<br/>                                close_change_1D).sort_values()<br/>corr_features_outcomes.dropna(inplace=True)<br/>corr_features_outcomes.plot(kind='barh',title = 'Strength of Correlation');</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/328be316ac3efffc4f3ce4af96563987.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*PUl8KwOenqTyrZtdl_mrNw.png"/></div></figure><p id="660d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">相关系数太小，无法得出可靠的结论。我会期望最近的数据具有更强的相关性，但这里的情况并非如此。</p><p id="04c2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">双人情节怎么样？我们只选择那些基于 1 天时间尺度的特征作为演示。与此同时，我将<code class="fe oy oz pa oj b">close_change_1D</code>转换为基于它是负数还是正数的符号，以增加绘图的额外维度。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="ce6e" class="mm mn it oj b gy on oo l op oq">selected_features_1D_list = ['volume_1D', 'price_spread_1D', 'close_loc_1D', 'close_change_1D']<br/>features_outcomes_rmv_outliers['sign_of_close'] = features_outcomes_rmv_outliers['close_change_1D']. \<br/>                                                  apply(np.sign)</span><span id="f821" class="mm mn it oj b gy or oo l op oq">sns.pairplot(features_outcomes_rmv_outliers, <br/>             vars=selected_features_1D_list,<br/>             diag_kind='kde',<br/>             palette='husl', hue='sign_of_close',<br/>             markers = ['*', '&lt;', '+'], <br/>             plot_kws={'alpha':0.3});</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/e2481d015ee12c67417815251e794219.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*FSuaaTc6t4b80cEViy2piA.png"/></div></figure><p id="d284" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">配对图建立在两个基本图形上，直方图和散点图。对角线上的直方图允许我们看到单个变量的分布，而上下三角形上的散点图显示了两个变量之间的关系(或缺乏关系)。从上面的图中，我们可以看到，随着交易量的增加，价差越来越大。大部分价格变动位于狭窄的价差，换句话说，更大的价差并不总是伴随着更大的价格波动。无论是低交易量还是高交易量都会导致几乎所有规模的价格变动。我们可以把所有这些结论应用到上涨和下跌的日子里。</p><p id="07be" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">您也可以使用接近的酒吧位置，以增加更多的维度，简单地应用</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="39b7" class="mm mn it oj b gy on oo l op oq">features[‘sign_of_close_loc’] = np.where( \<br/> features[‘close_loc_1D’] &gt; 0.5, \<br/> 1, -1)</span></pre><p id="e325" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">看有多少棒线的收盘价高于 0.5 或低于 0.5。</p><p id="d1fc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在 pair 图中，我不喜欢的一点是所有的图都浓缩了<code class="fe oy oz pa oj b">close_loc_1D</code>,看起来像离群值仍然存在，即使我知道我使用了一个标准偏差作为边界，这是一个非常低的阈值，338 个离群值被删除。我意识到因为 close 的位置已经是百分比变化了，在上面再加一个百分比变化没有太大意义。让我们改变它。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="f95d" class="mm mn it oj b gy on oo l op oq">def create_features_and_outcomes(i):<br/>    df = create_HLCV(i)<br/>    high = df[f'high_{i}D']<br/>    low = df[f'low_{i}D']<br/>    close = df[f'close_{i}D']<br/>    volume = df[f'volume_{i}D']<br/>    <br/>    features = pd.DataFrame(index=prices.index)<br/>    outcomes = pd.DataFrame(index=prices.index)<br/>    <br/>    #as we already considered the different time span, <br/>    #simple percentage change of 1 day used here.<br/>    <br/>    features[f'volume_{i}D'] = volume.pct_change()<br/>    features[f'price_spread_{i}D'] = (high - low).pct_change()<br/>    #remove pct_change() here<br/>    features[f'close_loc_{i}D'] = ((close - low) / (high - low))<br/>    #predict the future with -i<br/>    outcomes[f'close_change_{i}D'] = close.pct_change(-i)<br/>       <br/>    return features, outcomes</span></pre><p id="3341" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">去掉了<code class="fe oy oz pa oj b">pct_change()</code>，让我们看看现在的星团图是什么样子。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="2bc9" class="mm mn it oj b gy on oo l op oq">corr_features = features.corr().sort_index()<br/>sns.clustermap(corr_features, cmap='coolwarm', linewidth=1);</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/3e7b636c0cb18988e6ffaf0ee233f843.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*TjtZXx6Safa1GfEgluJFzg.png"/></div></figure><p id="9085" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">聚类图现在更有意义了。所有四个基本特征都有非常相似的模式。[40D，60D]，[2D，3D]配对在一起。</p><p id="a527" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">以及与结果相关的特征。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="e430" class="mm mn it oj b gy on oo l op oq">corr_features_outcomes.plot(kind='barh',title = 'Strength of Correlation');</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/7126498c87557aceed901ca593b525f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*9zBhntl0lW12veJmvw0jsw.png"/></div></figure><p id="5165" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">长期时间尺度特征与股票价格回报的相关性较弱，而近期事件对价格回报的影响更大。</p><p id="19a3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">通过去掉<code class="fe oy oz pa oj b">close_loc_1D</code>的<code class="fe oy oz pa oj b">pct_change()</code>，最大的区别在于<code class="fe oy oz pa oj b">pairplot()</code>。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/13d8baf95038efeb5c12329c5521feee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*Osw1uLgi24KiKi6uFI_Vkw.png"/></div></figure><p id="197a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最后，<code class="fe oy oz pa oj b">close_loc_1D</code>变量在正确的范围内绘图。这说明我们应该小心过度设计。它可能会导致一个完全意想不到的方式。</p><h1 id="9877" class="nu mn it bd mo nv nw nx mr ny nz oa mu ki ob kj mx kl oc km na ko od kp nd oe bi translated">3.百分位数排名</h1><p id="53ca" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr of lt lu lv og lx ly lz oh mb mc md im bi translated">根据维基百科，百分位排名是</p><blockquote class="ph pi pj"><p id="8f72" class="li lj me lk b ll lm kd ln lo lp kg lq pk ls lt lu pl lw lx ly pm ma mb mc md im bi translated">分数的百分位数等级是分数在其频率分布中等于或低于它的百分比。例如，一个测试分数大于参加测试的人的分数的 75%被认为是在第<strong class="lk jd">75</strong>百分位，其中 75 是百分位等级。</p></blockquote><p id="c9f8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">以下示例返回与过去 60 天期间相比，每个值的交易量的百分比等级(从 0.00 到 1.00)。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="9c04" class="mm mn it oj b gy on oo l op oq">roll_rank = lambda x: pd.Series(x).rank(pct=True)[-1]<br/># you only pick the first value [0]<br/># of the 60 windows rank if you rolling forward.<br/># if you rolling backward, we should pick last one,[-1].</span><span id="9151" class="mm mn it oj b gy or oo l op oq">features_rank = features.rolling(60, min_periods=60). \<br/>                apply(roll_rank).dropna()<br/>outcomes_rank = outcomes.rolling(60, min_periods=60). \<br/>                apply(roll_rank).dropna()</span></pre></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h2 id="26a2" class="mm mn it bd mo mp mq dn mr ms mt dp mu lr mv mw mx lv my mz na lz nb nc nd iz bi translated">✍Tip！</h2><p id="65f0" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr of lt lu lv og lx ly lz oh mb mc md im bi translated">熊猫<code class="fe oy oz pa oj b">rolling()</code>，默认情况下，结果设置为窗口的右边缘。这意味着该窗口是向后看的窗口，从过去滚动到当前时间戳。这就是为什么对于那个窗口帧中的<code class="fe oy oz pa oj b">rank()</code>，我们选择最后一个值<code class="fe oy oz pa oj b">[-1]</code>。</p><p id="6d0c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">更多关于<code class="fe oy oz pa oj b">rolling()</code>的信息，请查看<a class="ae lh" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rolling.html" rel="noopener ugc nofollow" target="_blank">官方文档。</a></p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="3d4b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">首先，我们快速浏览一下结果的聚类图。它几乎等同于顺序不同的百分比变化。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="b00b" class="mm mn it oj b gy on oo l op oq">corr_outcomes_rank = outcomes_rank.corr().sort_index()<br/>sns.clustermap(corr_outcomes_rank, cmap='coolwarm', linewidth=2);</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/48d35e7f8a8dac184f9b1000c6cc7ae0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*rCb4WHPodFcYDt96kjBzKQ.png"/></div></figure><p id="5999" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">同样的模式也适用于要素的聚类图。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="3889" class="mm mn it oj b gy on oo l op oq">corr_features_rank = features_rank.corr().sort_index()<br/>sns.clustermap(corr_features_rank, cmap='coolwarm', linewidth=2);</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/3ad5b56fb81cdfa58b135dcf596db657.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*iN_K5kk1ktEmedBEZkTbOQ.png"/></div></figure><p id="64ba" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">即使使用不同的方法，</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="eb3f" class="mm mn it oj b gy on oo l op oq"># using 'ward' method<br/>corr_features_rank = features_rank.corr().sort_index()<br/>sns.clustermap(corr_features_rank, cmap='coolwarm', linewidth=2, method='ward');</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/82f913b587971c8af8ebe1204139725a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1324/format:webp/1*alqXy0_42G4gyUSe1Pq4eQ.png"/></div></figure><p id="843c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当然，特征和结果的相关性也是一样的。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="949c" class="mm mn it oj b gy on oo l op oq">corr_features_outcomes_rank = features_rank.corrwith( \<br/>                              outcomes_rank. \<br/>                              close_change_1D).sort_values()</span><span id="16f1" class="mm mn it oj b gy or oo l op oq">corr_features_outcomes_rank</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/1d4862580c67c53c56647633c443f4c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:388/format:webp/1*9Ysdcz7l_WhtP1Dng1LhXw.png"/></div></figure><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="abf0" class="mm mn it oj b gy on oo l op oq">corr_features_outcomes_rank.plot(kind='barh',title = 'Strength of Correlation');</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/c3e589099bd1637641c80391d2b83d84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*bERtiy9pIEAYhRCJU32VfA.png"/></div></figure><p id="2de9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最后，你可能会猜到结对图也是一样的。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="c908" class="mm mn it oj b gy on oo l op oq">selected_features_1D_list = ['volume_1D', 'price_spread_1D', 'close_loc_1D', 'close_change_1D']<br/>features_outcomes_rank['sign_of_close'] = features_outcomes_rmv_outliers['close_change_1D']. \<br/>                                                  apply(np.sign)</span><span id="d2b6" class="mm mn it oj b gy or oo l op oq">sns.pairplot(features_outcomes_rank, <br/>             vars=selected_features_1D_list,<br/>             diag_kind='kde',<br/>             palette='husl', hue='sign_of_close',<br/>             markers = ['*', '&lt;', '+'], <br/>             plot_kws={'alpha':0.3});</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/a995ceb902f83d46eb0358f047fbad0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*wwP3jx4D_RMEEAXnTIDc3g.png"/></div></figure><p id="d68b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因为我们在集合窗口中使用了百分位等级(从 0.00 到 1.00)，所以斑点均匀地分布在所有特征上。与未经变换的相同数据相比，所有特征的分布或多或少接近正态分布。</p><h1 id="dac7" class="nu mn it bd mo nv nw nx mr ny nz oa mu ki ob kj mx kl oc km na ko od kp nd oe bi translated">4.签署</h1><p id="5e15" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr of lt lu lv og lx ly lz oh mb mc md im bi translated">最后同样重要的是，我想删除所有的数据颗粒，看看这些功能在这种情况下是如何关联的。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="2a63" class="mm mn it oj b gy on oo l op oq">features_sign = features.apply(np.sign)<br/>outcomes_sign = outcomes.apply(np.sign)</span></pre><p id="f7a6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然后再次计算相关系数。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="dc9d" class="mm mn it oj b gy on oo l op oq">corr_features_outcomes_sign = features_sign.corrwith(<br/>                              outcomes_sign. \<br/>                              close_change_1D).sort_values(ascending=False)</span><span id="c199" class="mm mn it oj b gy or oo l op oq">corr_features_outcomes_sign</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi po"><img src="../Images/92ea7f6b46e407d42a27aedb0bd6b028.png" data-original-src="https://miro.medium.com/v2/resize:fit:392/format:webp/1*S2g14xnZcfS78f8r3mEStg.png"/></div></figure><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="5bbd" class="mm mn it oj b gy on oo l op oq">corr_features_outcomes_sign.plot(kind='barh',title = 'Strength of Correlation');</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/a9295335c2f39ca727d2573caa9fcdca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1324/format:webp/1*NrPdE2NK42gn5ENi7-eVow.png"/></div></figure><p id="ad8d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在看来有点怪，像<code class="fe oy oz pa oj b">volume_1D</code>和<code class="fe oy oz pa oj b">price_spread_1D</code>和现在的胜负相关性很弱。</p><p id="db0e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">幸运的是，聚类图基本保持不变。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="b248" class="mm mn it oj b gy on oo l op oq">corr_features_sign = features_sign.corr().sort_index()<br/>sns.clustermap(corr_features_sign, cmap='coolwarm', linewidth=2);</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/f68380e79984c1181eadb7388a09b527.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*oZmWhTiV2k1WoEZZRojJUw.png"/></div></figure><p id="9b64" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">结果之间的关系也是如此。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="6441" class="mm mn it oj b gy on oo l op oq">corr_outcomes_sign = outcomes_sign.corr().sort_index()<br/>sns.clustermap(corr_outcomes_sign, cmap='coolwarm', linewidth=2);</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/a08e554127ca43ee367433c862437faf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*Ca40vkj7Pnd7DO9uSy-v0A.png"/></div></figure><p id="0c72" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">至于 pair plot，由于所有数据都被转移到-1 或 1，它没有显示任何有意义的东西。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/f23616dba66588f12eb1b07be342ceca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*rSWmysj03xn_4Fa3Z9Fe4A.png"/></div></figure><p id="e626" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">有时对数据进行“标准化”或“规范化”是至关重要的，这样我们才能在不同尺度的特征之间进行公平的比较。我很想用 Z-score 来标准化数据集。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pq"><img src="../Images/ec8907ad6a787573e799e4772c1f078a.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/format:webp/1*RS4ke_qE-GIelCSsw3Hm6A.png"/></div></figure><p id="4565" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Z 得分的公式需要平均值和标准差，通过计算整个数据集的这两个参数，我们有机会看到未来。当然，我们可以再次利用滚动窗口。但一般来说，人们会在将数据注入模型之前对其进行标准化。</p><p id="9054" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">总之，通过利用 3 种不同的数据转换方法，现在我们很有信心可以选择最相关的特性并丢弃那些大量的特性，因为所有 3 种方法几乎共享相同的模式。</p><h1 id="967f" class="nu mn it bd mo nv nw nx mr ny nz oa mu ki ob kj mx kl oc km na ko od kp nd oe bi translated">5.平稳和正态性检验</h1><p id="476d" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr of lt lu lv og lx ly lz oh mb mc md im bi translated">最后一个问题转换后的数据能通过平稳性/正态性检验吗？这里，我将使用<a class="ae lh" href="https://en.wikipedia.org/wiki/Augmented_Dickey%E2%80%93Fuller_test" rel="noopener ugc nofollow" target="_blank">扩展的 Dickey-Fuller 检验</a>，这是一种叫做<a class="ae lh" href="https://en.wikipedia.org/wiki/Unit_root_test" rel="noopener ugc nofollow" target="_blank">单位根检验</a>的统计检验。同时，我还想看看偏斜度和峰度。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="4d47" class="mm mn it oj b gy on oo l op oq">import statsmodels.api as sm<br/>import scipy.stats as scs<br/><br/>p_val = lambda s: sm.tsa.stattools.adfuller(s)[1]</span><span id="6b9c" class="mm mn it oj b gy or oo l op oq">def build_stats(df):<br/>    stats = pd.DataFrame({'skew':scs.skew(df),<br/>                 'skew_test':scs.skewtest(df)[1],<br/>                 'kurtosis': scs.kurtosis(df),<br/>                 'kurtosis_test' : scs.kurtosistest(df)[1],<br/>                 'normal_test' : scs.normaltest(df)[1]},<br/>                  index = df.columns)<br/>    return stats</span></pre><p id="6719" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">检验的零假设是时间序列可以用一个单位根来表示，它不是平稳的(具有一些依赖于时间的结构)。另一个假设(拒绝零假设)是时间序列是平稳的。</p><ul class=""><li id="56c8" class="ne nf it lk b ll lm lo lp lr ou lv ov lz ow md ox nm nn no bi translated"><strong class="lk jd">零假设(H0) </strong>:如果没有被拒绝，说明时间序列有单位根，意味着它是非平稳的。它有一些依赖于时间的结构。</li><li id="ae50" class="ne nf it lk b ll np lo nq lr nr lv ns lz nt md ox nm nn no bi translated"><strong class="lk jd">备选假设(H1) </strong>:拒绝零假设；这表明时间序列没有单位根，这意味着它是平稳的。它没有依赖于时间的结构。</li></ul><p id="ac87" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">以下是来自<a class="ae lh" href="https://en.wikipedia.org/wiki/Augmented_Dickey%E2%80%93Fuller_test" rel="noopener ugc nofollow" target="_blank">增强迪基-富勒测试</a>的结果:</p><p id="ae0b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于功能和结果:</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="f24b" class="mm mn it oj b gy on oo l op oq">features_p_val = features.apply(p_val)<br/>outcomes_p_val = outcomes.apply(p_val)<br/>outcomes_p_val,features_p_val</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/4245f9f2d643c40ba73f34906cd14fc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:434/format:webp/1*WgnAsZ_4CxbKWTI6Iir_bA.png"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/d478fdaebab286f3a011ea41f0a765c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:432/format:webp/1*xUSwcKsqyKn8X1X70cmfSA.png"/></div></figure><p id="8c91" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">测试可以通过<em class="me"> p </em>值来解释。低于阈值的<em class="me">p</em>-值(如 5%或 1%)表明我们拒绝零假设(平稳)，否则，高于阈值的<em class="me">p</em>-值表明我们不能拒绝零假设(非平稳)。</p><ul class=""><li id="43ac" class="ne nf it lk b ll lm lo lp lr ou lv ov lz ow md ox nm nn no bi translated"><strong class="lk jd"><em class="me">p</em>-值&gt; 0.05 </strong>:不能拒绝零假设(H0)，数据有单位根，非平稳。</li><li id="0efa" class="ne nf it lk b ll np lo nq lr nr lv ns lz nt md ox nm nn no bi translated"><strong class="lk jd"><em class="me">p</em>-值&lt; = 0.05 </strong>:拒绝零假设(H0)，数据没有单位根，是平稳的。</li></ul><p id="65e5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">从这个测试中，我们可以看到所有的结果都远低于 5%，这表明我们可以拒绝零假设，所有转换的数据都是平稳的。</p><p id="2bb4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">接下来，我们来测试正态性。</p><pre class="ks kt ku kv gt oi oj ok ol aw om bi"><span id="3b13" class="mm mn it oj b gy on oo l op oq">build_stats(features_outcomes_rmv_outliers)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pt"><img src="../Images/9677f0b330ba4f97286b3b00d585cf4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:954/format:webp/1*GCNBGkI5XqUcwgS3vijVFg.png"/></div></figure><p id="0735" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于正态分布的数据，偏斜度应该大约为零。对于单峰连续分布，大于零的偏斜值意味着分布的右尾有更多的权重，反之亦然。</p><p id="eb02" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><code class="fe oy oz pa oj b">scs.skewtest()</code>检验样本总体的偏斜度与相应正态分布的偏斜度相同的原假设。由于所有的数字都低于 5%的阈值，我们不得不拒绝零假设，并说偏斜度不符合正态分布。同样的事情去<code class="fe oy oz pa oj b">scs.kurtosistest()</code>。</p><p id="a783" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><code class="fe oy oz pa oj b">scs.normaltest()</code>检验样本来自正态分布的原假设。它基于 D'Agostino 和 Pearson 的测试，结合了偏斜度和峰度，以产生一个正态性的综合测试。同样，所有数字都低于 5%阈值。我们必须拒绝零假设，并说由百分比变化转换的数据不是正态分布。</p><p id="cd12" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们可以对通过百分比排名和签名转换的数据进行同样的测试。我不想让事情变得更复杂，把人们吓跑。在这篇文章太长之前，我最好在这里结束。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="6811" class="nu mn it bd mo nv pu nx mr ny pv oa mu ki pw kj mx kl px km na ko py kp nd oe bi translated">参考</h1><ol class=""><li id="5a8b" class="ne nf it lk b ll ng lo nh lr ni lv nj lz nk md nl nm nn no bi translated">麦金农，J.G. 1994。单位根和协整检验的近似渐近分布函数。《商业与经济统计杂志》12，167–76。</li><li id="d06d" class="ne nf it lk b ll np lo nq lr nr lv ns lz nt md nl nm nn no bi translated">达戈斯蒂诺，R. B. (1971)，“中等和大样本量的正态性综合检验”，《生物计量学》，58，341–348</li><li id="5fb4" class="ne nf it lk b ll np lo nq lr nr lv ns lz nt md nl nm nn no bi translated">达戈斯蒂诺，r .和皮尔逊，E. S. (1973)，“偏离正态性的检验”，《生物计量学》，60，613–622</li></ol></div></div>    
</body>
</html>