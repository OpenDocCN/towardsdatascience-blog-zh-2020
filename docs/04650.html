<html>
<head>
<title>What is a GPU and do you need one in Deep Learning?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">什么是GPU，深度学习需要GPU吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-is-a-gpu-and-do-you-need-one-in-deep-learning-718b9597aa0d?source=collection_archive---------1-----------------------#2020-04-25">https://towardsdatascience.com/what-is-a-gpu-and-do-you-need-one-in-deep-learning-718b9597aa0d?source=collection_archive---------1-----------------------#2020-04-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/3eb50bb3f7c538d99d58c5da927f8f5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ugfDFEAZuHuVzMTL"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">穆基尔·梅农在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><div class=""/><div class=""><h2 id="4e44" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">在深度学习中，大家似乎都推荐用GPU。它是什么，没有它你能做什么，它到底是给谁的？</h2></div><p id="e26d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">任何试图大规模提高训练模型性能的数据科学家或机器学习爱好者都会在某个时候遇到上限，并开始经历不同程度的处理延迟。当数据集变大时，使用较小的训练集需要几分钟的任务现在可能需要更多的时间，在某些情况下需要几周。</p><p id="ca85" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是什么是GPU呢？它们与CPU相比如何？我的深度学习项目需要一个吗？</p><p id="40ca" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你曾经问过自己这些问题，请继续读下去…</p><blockquote class="lu lv lw"><p id="661e" class="ky kz lx la b lb lc kk ld le lf kn lg ly li lj lk lz lm ln lo ma lq lr ls lt im bi translated">我最近开源了我的计算机视觉库，它利用GPU进行动态图像和视频处理。我会留下Github回购的链接，以防你感兴趣:)</p></blockquote><div class="is it gp gr iu mb"><a href="https://github.com/jasmcaus/caer" rel="noopener  ugc nofollow" target="_blank"><div class="mc ab fo"><div class="md ab me cl cj mf"><h2 class="bd jk gy z fp mg fr fs mh fu fw ji bi translated">贾斯考斯/卡尔</h2><div class="mi l"><h3 class="bd b gy z fp mg fr fs mh fu fw dk translated">用于高性能人工智能研究的轻量级计算机视觉库。Caer包含强大的图像和视频处理操作…</h3></div><div class="mj l"><p class="bd b dl z fp mg fr fs mh fu fw dk translated">github.com</p></div></div><div class="mk l"><div class="ml l mm mn mo mk mp ja mb"/></div></div></a></div></div><div class="ab cl mq mr hx ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="im in io ip iq"><p id="d847" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">任何数据科学家或机器学习爱好者都会听说，深度学习需要<em class="lx">很多</em>硬件，至少在他们的一生中会听到一次。一些人在他们的笔记本电脑上训练简单的深度学习模型几天(通常没有GPU)，这导致了一种印象，即深度学习需要大系统来运行执行。</p><p id="1b53" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这创造了一个围绕深度学习的神话，为初学者制造了一个路障。</p><p id="1bed" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在过去的几年里，我参考的每本书的作者总是提到以下几点:</p><blockquote class="mx"><p id="e722" class="my mz jj bd na nb nc nd ne nf ng lt dk translated">深度学习需要大量的计算能力来运行。</p></blockquote><p id="292b" class="pw-post-body-paragraph ky kz jj la b lb nh kk ld le ni kn lg lh nj lj lk ll nk ln lo lp nl lr ls lt im bi translated">但是我没有数据中心可供我使用，当我在一台相当大的笔记本电脑上构建我的第一个深度学习模型时，我知道这个共识要么是错误的，要么是用一些真理描绘的。</p><blockquote class="mx"><p id="c5f9" class="my mz jj bd na nb nc nd ne nf ng lt dk translated">你不必接管谷歌就能成为深度学习专家。</p></blockquote><h1 id="199b" class="nm nn jj bd no np nq nr ns nt nu nv nw kp nx kq ny ks nz kt oa kv ob kw oc od bi translated">为什么深度学习需要更多的硬件？</h1><p id="649e" class="pw-post-body-paragraph ky kz jj la b lb oe kk ld le of kn lg lh og lj lk ll oh ln lo lp oi lr ls lt im bi translated">对于任何神经网络来说，深度学习模型的<strong class="la jk">训练阶段</strong>是资源最密集的任务</p><p id="c626" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在训练过程中，神经网络接收输入，然后使用在训练过程中调整的<em class="lx">权重</em>在隐藏层进行处理，然后模型给出预测。调整权重以找到模式，从而做出更好的预测。</p><p id="dca9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这两种操作本质上都是矩阵乘法<em class="lx"/>。简单的矩阵乘法可以用下图来表示</p><figure class="ok ol om on gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oj"><img src="../Images/2366d2eabe3640f2524437bd9e116d87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FlJ_ZPMSlpCdeuAYzC0gPw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">来源:jeremyjordan.me</p></figure><p id="c03f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在一个神经网络中，我们可以将第一个数组的<em class="lx">输入</em>到神经网络，而第二个数组形成它的<em class="lx">权重。</em></p><p id="7a0c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">很简单，对吧？</p><p id="69ab" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">是的，如果你的神经网络有大约10，100甚至100，000个参数。计算机仍然能够在几分钟内，甚至最多几个小时内处理这个问题。</p><p id="4900" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是如果你的神经网络有<a class="ae jg" href="https://www.popsci.com/science/article/2013-06/stanfords-artificial-neural-network-biggest-ever/" rel="noopener ugc nofollow" target="_blank">超过100亿个参数</a>呢？使用传统方法训练这种系统需要<em class="lx">年</em>。你的电脑可能在你完成十分之一之前就放弃了。</p><blockquote class="lu lv lw"><p id="b14e" class="ky kz lx la b lb lc kk ld le lf kn lg ly li lj lk lz lm ln lo ma lq lr ls lt im bi translated">“一个神经网络接受搜索输入，并从1亿个输出或产品中进行预测，通常每个产品会有大约2000个参数。所以你把它们相乘，神经网络的最后一层现在是2000亿个参数。我没有做过任何复杂的事情。我说的是一个非常非常死简单的神经网络模型。”—莱斯大学的一名博士生</p></blockquote><h1 id="1109" class="nm nn jj bd no np nq nr ns nt nu nv nw kp oo kq ny ks op kt oa kv oq kw oc od bi translated">让深度学习模型训练得更快</h1><p id="7e61" class="pw-post-body-paragraph ky kz jj la b lb oe kk ld le of kn lg lh og lj lk ll oh ln lo lp oi lr ls lt im bi translated">深度学习模型可以通过简单地在<em class="lx">同时</em>运行所有操作而不是一个接一个地运行来更快地训练。</p><p id="d0ac" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可以通过使用一个<strong class="la jk"> GPU </strong>来训练你的模型来实现。</p><blockquote class="mx"><p id="d94a" class="my mz jj bd na nb nc nd ne nf ng lt dk translated">GPU(图形处理单元)是具有专用存储器的专用处理器，其通常执行渲染图形所需的浮点操作</p></blockquote><p id="1e96" class="pw-post-body-paragraph ky kz jj la b lb nh kk ld le ni kn lg lh nj lj lk ll nk ln lo lp nl lr ls lt im bi translated">换句话说，它是一个用于大量图形和数学计算的单芯片处理器，可以为其他任务释放CPU周期。</p><blockquote class="lu lv lw"><p id="131d" class="ky kz lx la b lb lc kk ld le lf kn lg ly li lj lk lz lm ln lo ma lq lr ls lt im bi translated">GPU和CPU之间的主要区别是，与CPU相比，GPU在算术逻辑单元上投入更多的晶体管，而在缓存和流控制上投入更少的晶体管。</p></blockquote><p id="26ee" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">虽然CPU主要适用于需要<em class="lx">解析</em>或<em class="lx">解释</em>代码中复杂逻辑的问题，但GPU是为计算机游戏的专用图形渲染工具而设计的，后来得到了增强，以加速其他几何计算(例如，将多边形或垂直旋转到不同的坐标系，如3D)。</p><p id="79b4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">GPU比CPU小，但往往比后者有更多的<em class="lx">逻辑</em>核心(算术逻辑单元或alu、控制单元和内存缓存)。</p><figure class="ok ol om on gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi or"><img src="../Images/621b9bdea548d336d7d960ce88a1578e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1TJ6wZR_ojRGSE3GKw4UBg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">来源:fast.ai</p></figure><p id="f7eb" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在上面的图表中，您可以看到GPU(红色/绿色)理论上可以完成CPU(蓝色)的10-15倍操作。这种加速在实践中也非常适用。</p><blockquote class="lu lv lw"><p id="3520" class="ky kz lx la b lb lc kk ld le lf kn lg ly li lj lk lz lm ln lo ma lq lr ls lt im bi translated">如果你把CPU看成一辆玛莎拉蒂，GPU可以看成一辆大卡车。</p><p id="6386" class="ky kz lx la b lb lc kk ld le lf kn lg ly li lj lk lz lm ln lo ma lq lr ls lt im bi translated">CPU(玛莎拉蒂)可以快速读取RAM中的少量包(3 -4名乘客)，而GPU(卡车)速度较慢，但可以一次读取大量内存(约20名乘客)。</p></blockquote><p id="f413" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该视频进一步概述了这一概念:</p><figure class="ok ol om on gt iv"><div class="bz fp l di"><div class="os ot l"/></div></figure><h1 id="458e" class="nm nn jj bd no np nq nr ns nt nu nv nw kp oo kq ny ks op kt oa kv oq kw oc od bi translated">为什么选择GPU进行深度学习</h1><p id="5f74" class="pw-post-body-paragraph ky kz jj la b lb oe kk ld le of kn lg lh og lj lk ll oh ln lo lp oi lr ls lt im bi translated">GPU针对训练人工智能和深度学习模型进行了优化，因为它们可以<em class="lx">同时处理多个计算</em>。</p><p id="529a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">它们拥有大量内核，可以更好地计算多个并行进程。此外，深度学习中的计算需要处理大量数据——这使得GPU的内存带宽最合适。</p><p id="6b52" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">有几个<strong class="la jk">决定参数</strong>决定使用CPU还是GPU来训练深度学习模型:</p><h2 id="3e39" class="ou nn jj bd no ov ow dn ns ox oy dp nw lh oz pa ny ll pb pc oa lp pd pe oc pf bi translated">内存带宽:</h2><p id="1707" class="pw-post-body-paragraph ky kz jj la b lb oe kk ld le of kn lg lh og lj lk ll oh ln lo lp oi lr ls lt im bi translated">带宽是GPU比CPU计算速度更快的主要原因之一。对于大型数据集，CPU在训练模型时会占用大量内存。</p><p id="87f6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">计算巨大而复杂的任务占用了CPU中大量的时钟周期——CPU按顺序<em class="lx">处理任务</em>,并且拥有比它的对手GPU更少的内核数量。</p><p id="f6de" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">另一方面，独立的GPU配备了专用的VRAM(视频RAM)内存。因此，CPU的内存可以用于其他任务。</p><figure class="ok ol om on gt iv gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/a50f26f33ed7eaa753dbfe0c4e93963b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ttCX7SD4cn1FqQoM.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">一段时间内CPU和GPU带宽的比较</p></figure><h2 id="e223" class="ou nn jj bd no ov ow dn ns ox oy dp nw lh oz pa ny ll pb pc oa lp pd pe oc pf bi translated">数据集大小</h2><p id="9355" class="pw-post-body-paragraph ky kz jj la b lb oe kk ld le of kn lg lh og lj lk ll oh ln lo lp oi lr ls lt im bi translated">在深度学习中训练模型需要大型数据集，因此在内存方面需要大量的计算操作。为了高效地计算数据，GPU是最佳选择。计算量越大，GPU相对于CPU的优势就越大。</p><h2 id="b326" class="ou nn jj bd no ov ow dn ns ox oy dp nw lh oz pa ny ll pb pc oa lp pd pe oc pf bi translated">最佳化</h2><p id="b26a" class="pw-post-body-paragraph ky kz jj la b lb oe kk ld le of kn lg lh og lj lk ll oh ln lo lp oi lr ls lt im bi translated">在CPU中优化任务要容易得多。CPU核虽然少，但比成千上万的GPU核更强大。</p><p id="2a68" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">每个CPU内核可以执行不同的指令(MIMD架构)，而GPU内核通常由32个内核组成，在给定时间并行执行相同的指令(SIMD架构)。</p><p id="5b6e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">考虑到所需要的努力，密集神经网络中的并行化是非常困难的。因此，复杂的优化技术在GPU中比在CPU中更难实现。</p></div><div class="ab cl mq mr hx ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="im in io ip iq"><figure class="ok ol om on gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ph"><img src="../Images/a94a7aa0331110f3718b9719af780cd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ggebkv6aIvXON-cI"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">照片由<a class="ae jg" href="https://unsplash.com/@agkdesign?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">亚历山大·奈特</a>在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="bf83" class="nm nn jj bd no np nq nr ns nt nu nv nw kp oo kq ny ks op kt oa kv oq kw oc od bi translated">该不该用GPU？</h1><p id="b47e" class="pw-post-body-paragraph ky kz jj la b lb oe kk ld le of kn lg lh og lj lk ll oh ln lo lp oi lr ls lt im bi translated">与任何数据科学项目一样，这取决于具体情况。在速度、可靠性和成本之间需要权衡考虑:</p><ol class=""><li id="aa1c" class="pi pj jj la b lb lc le lf lh pk ll pl lp pm lt pn po pp pq bi translated">如果你的神经网络规模相对<strong class="la jk">小</strong>，没有GPU也可以凑合</li><li id="992f" class="pi pj jj la b lb pr le ps lh pt ll pu lp pv lt pn po pp pq bi translated">如果你的神经网络涉及<strong class="la jk">成吨的计算</strong>涉及成千上万的参数，你可能要考虑投资一个GPU</li></ol><blockquote class="mx"><p id="758f" class="my mz jj bd na nb pw px py pz qa lt dk translated">一般来说，对于快速机器学习来说，GPU是一个更安全的赌注，因为在其核心，数据科学模型训练由简单的矩阵数学计算组成，如果并行执行计算，其速度可能会大大提高。</p></blockquote><p id="b77e" class="pw-post-body-paragraph ky kz jj la b lb nh kk ld le ni kn lg lh nj lj lk ll nk ln lo lp nl lr ls lt im bi translated">参见Reddit上关于深度学习投资的<a class="ae jg" href="https://www.reddit.com/r/MachineLearning/comments/b95182/d_which_gpus_to_get_for_deep_learning_my/" rel="noopener ugc nofollow" target="_blank">最佳GPU的帖子</a></p><h2 id="9fdf" class="ou nn jj bd no ov ow dn ns ox oy dp nw lh oz pa ny ll pb pc oa lp pd pe oc pf bi translated">云GPU实例</h2><p id="5e2e" class="pw-post-body-paragraph ky kz jj la b lb oe kk ld le of kn lg lh og lj lk ll oh ln lo lp oi lr ls lt im bi translated">你也应该给云GPU一个思路。如果你不想买一堆昂贵的GPU，你可以通过云托管公司按需利用GPU。它们将使您无需配置硬件，最重要的是，它们并不昂贵，在您使用它时，成本可以低至每小时0.25美元。</p><blockquote class="lu lv lw"><p id="f8d5" class="ky kz lx la b lb lc kk ld le lf kn lg ly li lj lk lz lm ln lo ma lq lr ls lt im bi translated"><strong class="la jk">一旦你完成了，记得关闭你的云实例。</strong></p></blockquote><p id="d349" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你将租用国外的计算机/服务器，而不是自己运行。仅仅关闭你的浏览器或你的电脑是不够的，这些只会切断你的设备和这个远程服务器之间的连接，而不是关闭你为之付费的东西。否则，你将为它运行的所有时间付费，并得到一个讨厌的账单！</p></div><div class="ab cl mq mr hx ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="im in io ip iq"><p id="f2b0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">CPU最擅长顺序处理单个更复杂的计算，而GPU更擅长并行处理多个但更简单的计算。</p><p id="cc26" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">GPU计算实例的成本通常是CPU计算实例的2-3倍，因此除非您在基于GPU的培训模型中看到2-3倍的性能提升，否则我会建议使用CPU。</p></div><div class="ab cl mq mr hx ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="im in io ip iq"><p id="449f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一如既往，非常感谢您的阅读！请告诉我你的想法或者希望我接下来在评论中写些什么。我也乐于接受批评！</p><p id="4674" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下期帖子再见！😄</p></div></div>    
</body>
</html>