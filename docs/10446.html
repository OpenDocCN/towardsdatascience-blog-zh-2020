<html>
<head>
<title>Complete Guide to Linear Regression in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python 线性回归完全指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/complete-guide-to-linear-regression-in-python-d95175447255?source=collection_archive---------23-----------------------#2020-07-22">https://towardsdatascience.com/complete-guide-to-linear-regression-in-python-d95175447255?source=collection_archive---------23-----------------------#2020-07-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2819" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在本文中，我们将使用 sklearn 在波士顿房价数据集上理解和实现线性回归</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d7189cc20f34c098636e311b01b9aa97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*buSE4eExZVMcsoAK"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Emil Widlund 在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="67ae" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">什么是线性回归？</h1><p id="7647" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><strong class="lt iu">线性回归</strong>是一种有监督的机器学习算法。它根据给定的<strong class="lt iu">因变量(x) </strong>预测<strong class="lt iu">自变量(y) </strong>之间的<strong class="lt iu">线性关系。使得<strong class="lt iu">自变量(y) </strong>具有<strong class="lt iu">最低成本</strong>。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/548a3910ee665a2451dfb1840232ee4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*OYs7-QeBzwWmfVh3nFBPEw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">应用于数据的线性回归，作者提供照片</p></figure><h1 id="63cb" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">线性回归工作</h1><p id="5c89" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">为了解释<strong class="lt iu">线性回归</strong>的工作原理，我们首先必须假设我们有一些数据，当我们在<strong class="lt iu">散点图</strong>上绘制这些数据时，我们会得到一个类似这样的图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/9c5f5acb6cc662a1feb45fede5e30450.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*uD5IbcFdBu5U9ph6aUpg_w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据散点图，作者照片</p></figure><p id="15f7" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">现在，如果我们将<strong class="lt iu">线性回归</strong>应用于它，那么它将计算数据之间的<strong class="lt iu">关系/线</strong>，使得<strong class="lt iu">线</strong>是距离数据中的所有点<strong class="lt iu">最近的<strong class="lt iu">。换句话说，它会计算出<strong class="lt iu">温度(x) </strong>和<strong class="lt iu">冰淇淋(y) </strong>销量之间的<strong class="lt iu">关系，并告诉我们在什么<strong class="lt iu">温度</strong>下<strong class="lt iu">销量</strong>会大于<strong class="lt iu">销量</strong>以及在什么<strong class="lt iu">温度</strong>下<strong class="lt iu">销量</strong>会小于<strong class="lt iu">。</strong></strong></strong></strong></p><p id="cd74" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated"><strong class="lt iu"> <em class="mu">我们如何找到我们数据之间的这条线/关系？</em>T51】</strong></p><p id="e580" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">现在，在我们深入探讨这个问题之前，我们应该先了解一些<strong class="lt iu">术语</strong>。</p><ul class=""><li id="c68e" class="mv mw it lt b lu mp lx mq ma mx me my mi mz mm na nb nc nd bi translated"><strong class="lt iu">假设表示</strong></li><li id="a4a6" class="mv mw it lt b lu ne lx nf ma ng me nh mi ni mm na nb nc nd bi translated"><strong class="lt iu">成本函数</strong></li><li id="0e22" class="mv mw it lt b lu ne lx nf ma ng me nh mi ni mm na nb nc nd bi translated"><strong class="lt iu">梯度下降</strong></li></ul><h1 id="815f" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">假设表示</h1><p id="ae06" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><strong class="lt iu">假设表示</strong>是我们的<strong class="lt iu">线</strong>的方程，我们用来表示给定的<strong class="lt iu">数据</strong>之间的<strong class="lt iu">关系</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/62daa34ff3465ebf8eb4167973c6f2f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/format:webp/0*E4LgcnWZEeLU-9MB.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">假设表示公式，作者照片</p></figure><p id="79bf" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">现在，这个<strong class="lt iu">方程</strong>一开始可能会令人困惑，有些人可能很难把它想象成直线的<strong class="lt iu">方程。但是如果我们考虑直线</strong>的<strong class="lt iu">方程，那就是<strong class="lt iu"> y = mx + c </strong>。</strong></p><p id="7c94" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">在线的方程中，<strong class="lt iu"> m </strong>对应的是<strong class="lt iu">斜率</strong>，<strong class="lt iu"> x </strong>是具有某值的<strong class="lt iu">变量</strong> <strong class="lt iu">，<strong class="lt iu"> c </strong>是一个<strong class="lt iu">常数</strong>。<br/>在假设表示中，<strong class="lt iu"> θ1 </strong>对应<strong class="lt iu">斜率</strong>，<strong class="lt iu"> x </strong>为具有某值</strong>的<strong class="lt iu">变量，<strong class="lt iu"> θ0 </strong>为<strong class="lt iu">常数</strong>。</strong></p><p id="283c" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">所以这里的<strong class="lt iu"> θ0 </strong> &amp; <strong class="lt iu"> θ1 </strong>都是<strong class="lt iu">的参数</strong>，它们的<strong class="lt iu">初始值</strong>是我们手动设置的<strong class="lt iu"/>，但之后又进一步修改为<strong class="lt iu">线</strong>在<strong class="lt iu">数据</strong>中完美设置。</p><h1 id="d500" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">价值函数</h1><p id="b47c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">现在，每当我们第一次绘制数据和计算<strong class="lt iu">线/关系</strong>时，我们都必须选择一些<strong class="lt iu">参数</strong>，如那条线的起点<strong class="lt iu"/><strong class="lt iu">和线的斜率</strong>。因此，首先，我们不知道任何这些东西的值，我们假设两个<strong class="lt iu">参数</strong>的值，然后对我们的<strong class="lt iu">数据</strong>应用<strong class="lt iu">成本函数</strong>来检查<strong class="lt iu">误差(点和我们的线的距离 b/w)</strong>。</p><p id="abd8" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">现在首先我会给你看我们的<strong class="lt iu">成本函数</strong>的数学版本，然后我会在下面解释它。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/b498dabdd033369ae1049451f89f6653.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*8dP9eDjZGwohxVLG.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">平方误差成本函数，作者照片</p></figure><p id="0299" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated"><strong class="lt iu"> <em class="mu">重要符号:</em> </strong></p><ul class=""><li id="aa4e" class="mv mw it lt b lu mp lx mq ma mx me my mi mz mm na nb nc nd bi translated"><strong class="lt iu"> m </strong>代表<strong class="lt iu">训练样本总数</strong></li><li id="49f0" class="mv mw it lt b lu ne lx nf ma ng me nh mi ni mm na nb nc nd bi translated"><strong class="lt iu"> x(i) </strong>代表<strong class="lt iu">输入变量</strong> (x(1)表示第一个训练示例)</li><li id="9235" class="mv mw it lt b lu ne lx nf ma ng me nh mi ni mm na nb nc nd bi translated"><strong class="lt iu"> y(i) </strong>代表<strong class="lt iu">输出变量</strong></li></ul><p id="4f41" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">所以在这个<strong class="lt iu">成本函数</strong>中，<strong class="lt iu">(hθ(x)-y)</strong>项用我们的<strong class="lt iu">给定值</strong> <strong class="lt iu"> (y) </strong>减去<strong class="lt iu">预测值</strong> ( <strong class="lt iu"> x) </strong>，这样我们就找到了我们的<strong class="lt iu">线</strong>和<strong class="lt iu">给定点</strong>之间的<strong class="lt iu">误差(距离)</strong>。然后我们取答案的<strong class="lt iu">平方</strong>，以防<strong class="lt iu">得到的值</strong>是一个<strong class="lt iu">负数</strong>。之后，我们<strong class="lt iu">对所有<strong class="lt iu">训练示例</strong>和<strong class="lt iu">求和</strong>并将</strong>乘以<strong class="lt iu"> 1/2m </strong>，取<strong class="lt iu">平均值</strong>作为我们<strong class="lt iu">训练示例误差。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/6b0a10a33e17097ffa08183a0ed24d72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o9wQqS813Ppfqd3MEQwX0w.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我们的假设和给定数据之间的误差，<a class="ae ky" href="https://medium.com/@ahmadbinshafiq/linear-regression-simplified-for-beginners-dcd3afe0b23f" rel="noopener">中等</a></p></figure><p id="a7ac" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated"><strong class="lt iu"> <em class="mu">【细化 1 / 2m(可选)</em> </strong></p><p id="5637" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">现在，我们在这里看到的是这个等式被乘以<strong class="lt iu"> 1/2m </strong>。这里的<strong class="lt iu"> m </strong>是取我们误差的<strong class="lt iu">均值/平均值</strong>，这里的<strong class="lt iu"> 2 </strong>是因为当我们取<strong class="lt iu">成本函数</strong>的<strong class="lt iu">导数</strong>时，在<strong class="lt iu">更新</strong>时使用<strong class="lt iu">参数</strong>在<strong class="lt iu">坡度下降</strong>时，即<strong class="lt iu"> 2 </strong>在<strong class="lt iu">功率<strong class="lt iu"/></strong></p><h1 id="8114" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">梯度下降</h1><p id="1b76" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">现在，当我们对<strong class="lt iu">成本函数</strong> &amp; <strong class="lt iu">假设表象</strong>有了更好的理解，由此我们走向第三项，<strong class="lt iu">梯度下降</strong>。</p><p id="e759" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">所以，现在我们已经成功地实现了<strong class="lt iu">成本函数</strong>，并且得到了一些<strong class="lt iu">成本(误差)&gt; &gt; 0 </strong>。为了减少这个<strong class="lt iu">成本(误差)</strong>我们应用<strong class="lt iu">梯度下降，</strong>其中我们<strong class="lt iu">更新<strong class="lt iu">参数θ0 </strong> &amp; <strong class="lt iu"> θ1 </strong>的值，并且保持<strong class="lt iu">更新</strong>它们，直到我们的<strong class="lt iu">成本(误差)</strong>几乎等于<strong class="lt iu"> 0 </strong>。因此，<strong class="lt iu">梯度下降</strong>的数学公式如下</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/dab83a426ba9a1d80ce0285872927888.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/0*jTrM-AfW7Q7X04DN.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">梯度下降公式，<a class="ae ky" href="https://medium.com/@ahmadbinshafiq/linear-regression-simplified-for-beginners-dcd3afe0b23f" rel="noopener">中等</a></p></figure><p id="d8f9" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated"><strong class="lt iu"> <em class="mu">重要符号:</em> </strong></p><ul class=""><li id="6d71" class="mv mw it lt b lu mp lx mq ma mx me my mi mz mm na nb nc nd bi translated"><strong class="lt iu"> m </strong>代表<strong class="lt iu">训练样本总数</strong></li><li id="0060" class="mv mw it lt b lu ne lx nf ma ng me nh mi ni mm na nb nc nd bi translated"><strong class="lt iu"> α </strong>代表<strong class="lt iu">α</strong>也叫<strong class="lt iu">学习率</strong></li><li id="7a01" class="mv mw it lt b lu ne lx nf ma ng me nh mi ni mm na nb nc nd bi translated"><strong class="lt iu"> x(i) </strong>代表<strong class="lt iu">输入变量</strong> (x(1)表示第一个训练样本)</li><li id="afe8" class="mv mw it lt b lu ne lx nf ma ng me nh mi ni mm na nb nc nd bi translated"><strong class="lt iu"> y(i) </strong>代表<strong class="lt iu">输出变量</strong></li></ul><p id="933d" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">好了，现在深入这个公式，我们可以看到<strong class="lt iu"> θ0 </strong> &amp; <strong class="lt iu"> θ1 </strong>在不断变化，直到<strong class="lt iu">成本函数</strong>达到其<strong class="lt iu">最小值</strong>。它的意思是，我们将继续<strong class="lt iu">改变<strong class="lt iu"> θ0 </strong> &amp; <strong class="lt iu"> θ1 </strong>的值，直到我们的<strong class="lt iu">参数</strong>达到<strong class="lt iu">值</strong>，其中 c <strong class="lt iu"> ost(误差)</strong>将是最小的<strong class="lt iu"/>。</strong></p><p id="4035" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">现在，如果你看到我们在<strong class="lt iu"> α </strong>之后有一个类似于<strong class="lt iu">成本函数</strong>的等式，那是因为<strong class="lt iu">梯度下降</strong>是<strong class="lt iu">成本函数</strong>的<strong class="lt iu">导数</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/ca4b61435c551fa67c0bd1fda401366c.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/0*QgBl0CY9oWXGDGQA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">突出成本函数的导数，<a class="ae ky" href="https://medium.com/@ahmadbinshafiq/linear-regression-simplified-for-beginners-dcd3afe0b23f" rel="noopener">中</a></p></figure><p id="f412" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">这里我们将我们的<strong class="lt iu">成本函数的导数</strong> <strong class="lt iu">(平方误差成本函数)</strong>乘以<strong class="lt iu"> α </strong>，<strong class="lt iu">从当时的<strong class="lt iu"> θ </strong>的当前值中减去</strong>α，得到一个新值<strong class="lt iu"> theta (θ) </strong>。</p><p id="422e" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated"><strong class="lt iu"> <em class="mu">选择α的值</em> </strong></p><p id="1a82" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">我们总是选择<strong class="lt iu"> α </strong>的一个非常小的<strong class="lt iu">值</strong>，因为每次迭代后<strong class="lt iu"> θ </strong>值的<strong class="lt iu">变化</strong>取决于<strong class="lt iu"> α </strong>的值(如等式所示)。因此，通过选择<strong class="lt iu"> α </strong>的<strong class="lt iu">非常小的值</strong>，我们的<strong class="lt iu">假设</strong>采取<strong class="lt iu">非常小的步骤</strong>并达到其<strong class="lt iu">最低成本</strong>。通过使用大值的<strong class="lt iu"> α </strong>，我们可能开始采取<strong class="lt iu">大的步骤</strong>，并且可能<strong class="lt iu">错过</strong>全局最小值，其中我们的<strong class="lt iu">成本(误差)</strong>将是<strong class="lt iu">最低的</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/cc67f9e5c78aab6d525fe8bb6991c67b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hNKBeT8OmZ7N7sSVS17Emw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用小值的<strong class="bd no"> α </strong>与使用大值的<strong class="bd no"> α，</strong>作者照片</p></figure><p id="2ef5" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated"><strong class="lt iu"> <em class="mu">澄清第二方程中的 x</em></strong></p><p id="49ed" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">现在有些人可能会奇怪，在第二个<strong class="lt iu">方程</strong>中，一个额外的<strong class="lt iu"> x(i) </strong>正被<strong class="lt iu">乘以我们的<strong class="lt iu">方程</strong>，而在第一个<strong class="lt iu">方程</strong>中什么也没有。这里有一个<strong class="lt iu"> x(0) </strong>，是用<strong class="lt iu">乘以</strong>得到的<strong class="lt iu">等式</strong>，但是我们没有写下来，因为这是<strong class="lt iu">偏差</strong>，并且总是等于<strong class="lt iu"> 1。</strong></strong></p><p id="7439" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated"><strong class="lt iu"> <em class="mu">梯度下降作业</em> </strong></p><p id="43d2" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">现在<strong class="lt iu">梯度下降</strong>所做的是它采取<strong class="lt iu">小婴儿步骤</strong>并且在每个<strong class="lt iu">步骤</strong>中，它<strong class="lt iu">将<strong class="lt iu">假设(线)</strong>向<strong class="lt iu">位置</strong>收敛</strong>，在那里我们的<strong class="lt iu">成本(误差)</strong>将会是<strong class="lt iu">最小</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/12237b8e3a762016a4b0c5e4cb9f5664.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*c9B_RbVU5UFjNqR_.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">假设收敛到全局最小值，图像来自<a class="ae ky" href="https://medium.com/@ahmadbinshafiq/linear-regression-simplified-for-beginners-dcd3afe0b23f" rel="noopener">介质</a></p></figure><p id="c73c" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">从<a class="ae ky" rel="noopener" target="_blank" href="/machine-learning-fundamentals-via-linear-regression-41a5d11f5220"> <strong class="lt iu">这里</strong> </a> <strong class="lt iu">阅读更多关于<strong class="lt iu">成本函数</strong>和<strong class="lt iu">梯度下降</strong>。</strong></p><h2 id="a6d0" class="nq la it bd lb nr ns dn lf nt nu dp lj ma nv nw ll me nx ny ln mi nz oa lp ob bi translated">应用线性回归的步骤:</h2><p id="cb31" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">现在我们对<strong class="lt iu">假设表示</strong>、<strong class="lt iu">成本函数、</strong>和<strong class="lt iu">梯度下降</strong>有了很好的理解。因此，让我们将<strong class="lt iu">线性回归</strong>应用于我们的数据集。</p><p id="ee0d" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated"><strong class="lt iu">线性回归</strong>可应用于以下步骤:</p><ol class=""><li id="3c48" class="mv mw it lt b lu mp lx mq ma mx me my mi mz mm oc nb nc nd bi translated">绘制我们的数据(x，y)。</li><li id="4ef9" class="mv mw it lt b lu ne lx nf ma ng me nh mi ni mm oc nb nc nd bi translated">取随机值<strong class="lt iu"> θ0 </strong> &amp; <strong class="lt iu"> θ1 </strong>并初始化我们的<strong class="lt iu">假设</strong>。</li><li id="9d40" class="mv mw it lt b lu ne lx nf ma ng me nh mi ni mm oc nb nc nd bi translated">在我们的<strong class="lt iu">假设</strong>上应用<strong class="lt iu">成本函数</strong>，并计算其<strong class="lt iu">成本</strong>。</li><li id="6d28" class="mv mw it lt b lu ne lx nf ma ng me nh mi ni mm oc nb nc nd bi translated">如果我们的<strong class="lt iu">花费&gt; &gt; 0 </strong>，那么应用<strong class="lt iu">梯度下降</strong>和<strong class="lt iu">更新</strong>我们的<strong class="lt iu">参数θ0 </strong> &amp; <strong class="lt iu"> θ1 </strong>的<strong class="lt iu">值。</strong></li><li id="d630" class="mv mw it lt b lu ne lx nf ma ng me nh mi ni mm oc nb nc nd bi translated">继续计算<strong class="lt iu">第 3 步</strong>和<strong class="lt iu">第 4 步</strong>，直到我们的<strong class="lt iu">成本</strong>接近等于 0 或<strong class="lt iu">最小</strong>。</li><li id="1a4a" class="mv mw it lt b lu ne lx nf ma ng me nh mi ni mm oc nb nc nd bi translated">如果我们的<strong class="lt iu">成本</strong>已经达到它的<strong class="lt iu">全局最小值</strong>，那么我们停止应用<strong class="lt iu">成本函数</strong>和<strong class="lt iu">梯度下降</strong>，现在我们已经成功地训练了我们的<strong class="lt iu">算法</strong>来预测我们的数据之间正确的<strong class="lt iu">关系</strong>。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/054355ecc3b36cc27e08eb13626fa19c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/0*oks-R7whafJQBKJ5.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">对我们的数据集应用线性回归</p></figure></div><div class="ab cl oe of hx og" role="separator"><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj"/></div><div class="im in io ip iq"><p id="c007" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">现在，当我们很好地理解了<strong class="lt iu">线性回归</strong>的工作原理后，让我们使用<strong class="lt iu"> Python 的</strong>著名的<strong class="lt iu">机器学习库</strong>、<strong class="lt iu"> Scikit-learn </strong>将其应用于一个数据集。</p><h1 id="3b66" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">什么是 Scikit-learn？</h1><p id="9849" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><strong class="lt iu"> Scikit-learn </strong>(又称<strong class="lt iu"> sklearn </strong>)是一个针对 Python 的机器学习库。它包括各种<strong class="lt iu">分类</strong>、<strong class="lt iu">回归、</strong>和<strong class="lt iu">聚类算法</strong>以及<strong class="lt iu">支持向量机(SVM) </strong>、<strong class="lt iu">随机森林</strong>、<strong class="lt iu">梯度提升</strong>、<strong class="lt iu">、<em class="mu"> k </em> -means </strong>和<strong class="lt iu"> DBSCAN </strong>，并且被设计为与类似<strong class="lt iu">的 Python 库一起工作</strong></p><h1 id="b2ae" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">使用 Sklearn 进行线性回归</h1><p id="2e47" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><strong class="lt iu">线性回归</strong>是一种非常直接且易于使用的<strong class="lt iu">算法</strong>。特别是在这个<strong class="lt iu"> Scikit learn </strong>库的帮助下，它的实现和使用变得相当容易。现在，我们开始使用<strong class="lt iu"> Sklearn </strong>。</p><p id="e9f2" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">首先我们需要一些数据对其应用<strong class="lt iu">线性回归</strong>。因此，我们将使用来自<strong class="lt iu"> sklearn </strong>的<strong class="lt iu">波士顿房价数据集</strong>。</p><p id="1526" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated"><strong class="lt iu"> <em class="mu">在 Python 中导入波士顿数据集</em> </strong></p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="5955" class="nq la it om b gy oq or l os ot">from sklearn.datasets import load_boston<br/>boston = load_boston()</span></pre><p id="6abe" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated"><strong class="lt iu"> <em class="mu">在 Python 中导入其他库</em> </strong></p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="396c" class="nq la it om b gy oq or l os ot">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span></pre><p id="1cf5" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated"><strong class="lt iu"> <em class="mu">检查内容我们的数据集</em> </strong></p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="cb03" class="nq la it om b gy oq or l os ot">print(boston.keys())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/57246b94e202b6d47bd824fc4958a0b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/format:webp/1*11TtWEFNOQWo3legAqn71w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">打印输出(波士顿['target'])代码</p></figure><p id="df79" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">这些键中的每一个都包含了大量的信息和数据。</p><ul class=""><li id="84c0" class="mv mw it lt b lu mp lx mq ma mx me my mi mz mm na nb nc nd bi translated">'<strong class="lt iu"> data </strong>'键包含我们将提供给模型的数据，它也可以被假定为输入(x)变量。可以使用<code class="fe ov ow ox om b">boston.data</code>代码进行访问。</li><li id="e4c5" class="mv mw it lt b lu ne lx nf ma ng me nh mi ni mm na nb nc nd bi translated">'<strong class="lt iu"> target </strong>'键包含我们的模型应该预测的输出数据(y)。可以使用<code class="fe ov ow ox om b">boston.target</code>代码访问它。</li><li id="1ddb" class="mv mw it lt b lu ne lx nf ma ng me nh mi ni mm na nb nc nd bi translated">'<strong class="lt iu"> feature_names </strong>'键包含我们的数据的列/特征的名称。也可以使用<code class="fe ov ow ox om b">boston.feature_names</code>代码访问它们。</li><li id="db30" class="mv mw it lt b lu ne lx nf ma ng me nh mi ni mm na nb nc nd bi translated">'<strong class="lt iu"> DESCR </strong>'键将为我们提供关于数据集的所有信息，其中的列数，甚至每一列的细节/描述。我们可以使用<code class="fe ov ow ox om b">print(boston['DESCR'])</code>代码获取这些信息。</li><li id="c41d" class="mv mw it lt b lu ne lx nf ma ng me nh mi ni mm na nb nc nd bi translated">“<strong class="lt iu">文件名</strong>键给了我们这个(波士顿房价)文件的位置。我们可以使用<code class="fe ov ow ox om b">print(boston['filename'])</code>代码获得位置。</li></ul><p id="0ce1" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated"><strong class="lt iu"> <em class="mu">创建数据帧</em> </strong></p><p id="23a5" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">现在，为了向前推进并以一种有组织的和可行的方式查看我们的数据，我们将使用<strong class="lt iu"> Pandas </strong>创建一个数据框。</p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="f146" class="nq la it om b gy oq or l os ot">bostondf = pd.DataFrame(boston.data, columns=boston.feature_names)</span></pre><p id="1615" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">在我们的数据框架被创建并且我们的数据被组织之后。我们使用<code class="fe ov ow ox om b">bostondf.head()</code>检查数据集的头部。这为我们提供了数据集的整体清晰度/图像。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/280c31dd74debe9471794cfddb3a0cf7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*5-83-RpIoWljLyHeC-AyGg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我们数据框的头</p></figure><p id="77c5" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">现在，如果我们不明白每一列代表什么，我们可以使用我们之前讨论过的<code class="fe ov ow ox om b">print(boston['DESCR'])</code>代码来检查每一列的细节。</p><p id="da42" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">现在，在对我们的数据做了一些<strong class="lt iu">特征工程</strong>之后，当我们觉得我们的数据现在是可以传递给我们的模型的正确格式时，我们就向我们的下一步前进。<br/> <strong class="lt iu">注意:我不是在这个数据集上做特征工程。</strong></p><p id="afe9" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated"><strong class="lt iu"> <em class="mu">将我们的数据集分割成训练、测试值</em> </strong></p><p id="bc27" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">现在，当我们的数据准备好传递给我们的模型时，我们的第一步是将数据集分成两组，即<strong class="lt iu">训练集</strong>和<strong class="lt iu">测试集</strong>。</p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="9039" class="nq la it om b gy oq or l os ot">from sklearn.model_selection import train_test_split<br/>X = bostondf<br/>y = boston['target']<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)</span></pre><p id="ba22" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">这里，<code class="fe ov ow ox om b">X = bostondf</code>中的<strong class="lt iu"> X </strong>包含所有的<strong class="lt iu">特征/输入数据(x) </strong>，我们提供给我们的模型<strong class="lt iu">来预测</strong>的<strong class="lt iu">房价(y)</strong>,<code class="fe ov ow ox om b">y = boston['target']</code>中的<strong class="lt iu"> y </strong>包含<strong class="lt iu">房价</strong>。所以现在我们数据的<strong class="lt iu"> 67% </strong>属于<strong class="lt iu"> training_set </strong>而<strong class="lt iu">的 33% </strong>属于<strong class="lt iu"> test_set </strong>因为<strong class="lt iu"> test_size </strong>被设置为<strong class="lt iu"> 0.33 </strong>。</p><p id="7f89" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated"><strong class="lt iu"> <em class="mu">导入线性回归()</em> </strong></p><p id="25aa" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">在成功地将我们的数据分成测试和训练集之后，我们将使用<strong class="lt iu"> sklearn </strong>和<code class="fe ov ow ox om b"><strong class="lt iu">fit</strong></code> <strong class="lt iu"> </strong>将<strong class="lt iu">线性回归</strong>导入到我们的模型中，然后我们将<strong class="lt iu">预测</strong>我们的模型从我们的训练数据中学习得有多好。</p><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="aac5" class="nq la it om b gy oq or l os ot">from sklearn.linear_model import LinearRegression<br/>lr = LinearRegression()<br/>lr.fit(X_train, y_train)<br/>lr.score(X_test, y_test)</span></pre><p id="a7bd" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">好了，我们在这两个步骤中所做的是，我们导入了<strong class="lt iu"> LinearRegression( ) </strong>类，并创建了一个名为<strong class="lt iu"> lr </strong>的<strong class="lt iu"> LinearRegression </strong>对象。然后我们<strong class="lt iu">将</strong>我们的训练数据<code class="fe ov ow ox om b">lr.fit(X_train, y_train)</code>拟合到模型中，为其提供<strong class="lt iu">输入特征(X_train) </strong>和<strong class="lt iu">输出值(y_train) </strong>。在模型根据我们的训练数据对<strong class="lt iu">进行了</strong>训练之后，我们使用<code class="fe ov ow ox om b">lr.score(X_test, y_test)*100</code>代码来检查我们的模型与我们的训练数据的拟合程度。它会根据<strong class="lt iu"> X_test </strong>中提供的<strong class="lt iu">特征</strong>来<strong class="lt iu">预测</strong>房屋的<strong class="lt iu">价格，然后将这些价格与<strong class="lt iu"> y_test </strong>中给出的实际价格进行交叉核对。然后它会给我们一个 1-100 之间的浮点值，告诉我们模型的精度。</strong></p><p id="37de" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">该模型的<strong class="lt iu">精度</strong>为<strong class="lt iu"> 72.45 %。</strong></p><p id="74e5" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated"><strong class="lt iu"> <em class="mu">重要提示</em> </strong></p><p id="277d" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">现在，在检查了<strong class="lt iu">精度</strong>之后，如果我们的<strong class="lt iu">精度</strong>看起来不是很<strong class="lt iu">激励</strong>，我们应该继续到我们对我们的<strong class="lt iu">数据集</strong>进行<strong class="lt iu">特征工程</strong>的部分，并做一些<strong class="lt iu">更多的特征工程</strong>。这肯定会提高<strong class="lt iu">的结果。</strong></p><p id="2be3" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated"><strong class="lt iu">恭喜！</strong>我们已经在<strong class="lt iu">波士顿房价数据集上成功训练了我们的<strong class="lt iu">线性回归</strong>模型。</strong></p><h2 id="ce46" class="nq la it bd lb nr ns dn lf nt nu dp lj ma nv nw ll me nx ny ln mi nz oa lp ob bi translated">学习成果</h2><p id="cf97" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">到目前为止，我们已经了解了什么是<strong class="lt iu">假设表示</strong>、<strong class="lt iu">代价函数</strong>、<strong class="lt iu">梯度下降</strong>以及它们是如何工作的。此外，我们还学习了如何从<strong class="lt iu"> scratch </strong>在<strong class="lt iu">数据集</strong>上实现<strong class="lt iu">线性回归</strong>，以及如何使用<strong class="lt iu"> Python </strong>著名的<strong class="lt iu">机器学习库</strong>即<strong class="lt iu"> Scikit-learn 构建<strong class="lt iu">机器学习模型</strong>。</strong></p><p id="a129" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma mr mc md me ms mg mh mi mt mk ml mm im bi translated">到目前为止，我们已经了解了什么是<strong class="lt iu">假设表示</strong>、<strong class="lt iu">成本函数</strong>、<strong class="lt iu">梯度下降</strong>以及它们是如何工作的。此外，我们还学习了如何从<strong class="lt iu"> scratch </strong>在<strong class="lt iu">数据集</strong>上实现<strong class="lt iu">线性回归</strong>，以及如何使用<strong class="lt iu"> Python </strong>著名的<strong class="lt iu">机器学习库</strong>即<strong class="lt iu"> Scikit-learn 构建<strong class="lt iu">机器学习模型</strong>。</strong></p></div></div>    
</body>
</html>