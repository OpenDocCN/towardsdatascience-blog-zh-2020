<html>
<head>
<title>Visualizing Change in Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">可视化神经网络的变化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/visualizing-change-in-neural-networks-eea86529a9f3?source=collection_archive---------36-----------------------#2020-06-19">https://towardsdatascience.com/visualizing-change-in-neural-networks-eea86529a9f3?source=collection_archive---------36-----------------------#2020-06-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="dd40" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">评估神经网络在针对新任务进行微调时的特征可视化变化的实验</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/471c6bba156edef09ae6643715a54766.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D6cLbQlvdc8hGp9D_2-kUw.png"/></div></div></figure><p id="4f94" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">深度神经网络以其强大的能力吸引了世界，但它们在很大程度上是作为黑盒模型运行的。为了帮助解决这个谜，<em class="lq">特征可视化</em>已经成为一种强大的工具，用于查看神经网络的“引擎盖”以可视化它们所学习的东西。</p><p id="209b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在本文中，我们将探索如何可视化神经网络学习检测的内容，以及当我们微调网络以执行新任务时，这些学习到的工件如何变化。此外，该项目基于 tensorflow <a class="ae lr" href="https://github.com/tensorflow/lucid" rel="noopener ugc nofollow" target="_blank"> lucid </a>库提供了特征可视化的 pytorch 实现。</p><p id="4ae2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在我们开始之前，你可以在 Github 上找到这个项目<a class="ae lr" href="https://github.com/martin-chobanyan/transfer-visualization" rel="noopener ugc nofollow" target="_blank">的代码。</a></p><h1 id="244a" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">什么是微调？</h1><p id="11cb" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">微调是使预先训练的神经网络适应新任务的过程。微调时，网络的参数用从原始任务中学习到的值进行初始化。假设任务相对相似，通过利用从原始任务中学到的知识，微调有助于网络在新任务上实现更高的准确性。当原始任务有更大更丰富的数据集时，这种技术特别有用。</p><p id="501a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这个项目使用的架构是 ResNet-50 [2]，一个深度卷积网络，有五十层。对于最初的任务，这个网络已经被训练成在 ImageNet 上进行分类，ImageNet 是一个包含跨越一千个不同类别(包括动物、植物、车辆和物体)的数百万张图像的数据集。</p><p id="ba5b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这个项目中，我们将探索当网络在<a class="ae lr" href="http://vision.stanford.edu/aditya86/ImageNetDogs/" rel="noopener ugc nofollow" target="_blank">斯坦福狗数据集</a>【3】上进行微调时，预训练网络对输入图像的内部表示的变化。该数据集包含大约 20，000 张 120 个品种的狗的图片。通过标准的微调方法和均匀的训练测试分割，在这个新的数据集上获得了 80%的分类准确度分数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/8819733cddd2aa611dc3ada42d62741d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*VzT4_XUbcBpy0HkDzNDJGQ.png"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated"><strong class="bd mu">图一。</strong>来自斯坦福狗数据集的示例图像</p></figure><h1 id="8bd1" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">什么是特征可视化？</h1><p id="d950" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">神经网络中的每个组件学习检测输入图像中的各种特征。例如，狗分类器中的特定神经元在遇到吻状特征时可能会释放大量激活(输出值)。</p><p id="c710" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><em class="lq">特征可视化</em>是一种优化输入图像的技术，以便在预训练神经网络的特定组件中产生大量激活。与常见的深度学习范例相反，该过程不更新网络的参数。相反，它冻结预训练的网络并更新图像中的像素，使得网络的组件被高度激活。</p><p id="7601" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下面的<strong class="kw iu">图 2 </strong>给出了特征可视化的总图。特征可视化使用梯度上升来<em class="lq">最大化</em>网络中目标组件的激活值。输入图像从随机初始化所有像素开始。随着算法的迭代，图像开始更接近组件已经学会检测的特征。</p><p id="aaab" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">另外，请注意目标组件如何来自网络中的任何地方。特别是在这个项目中，我们可视化了 ResNet-50 的最后四个瓶颈层中每个特征图的平均值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mv"><img src="../Images/270943f5077490793bc8f9a8c2100b23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UlTMHNgpl8_2G7Pn"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated"><strong class="bd mu">图二。</strong>特征可视化算法概述</p></figure><p id="9d36" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">回到狗鼻子的例子，如果将特征可视化应用于特定神经元的输出，我们会期望得到的图像是模型可以预期的最“看起来像鼻子”的输入。这意味着(如果神经元只检测狗的鼻子),得到的图像将充满各种形状和大小的鼻子。</p><p id="dcbe" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这种技术有助于了解网络的不同组件已经学会检测什么。<strong class="kw iu">下图 3 </strong>显示了 ImageNet 预训练 ResNet-50 模型中三个不同通道的功能可视化。请注意，对于模型中更深的层，特征会更加复杂。例如，在左图中，唯一可见的特征似乎是某种类似毛皮的纹理。然而，在右边，我们可以看到狗和蛇头纠缠在一起的图像。这表明网络中的这个特定通道已经学会了在输入图像中检测狗和蛇。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mw"><img src="../Images/54c8c528f90d4bac47fbf9c9d57ed719.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4T-_FgvHXKBPPJEJ"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated"><strong class="bd mu">图三。</strong>分别从层 1-瓶颈 1、层 2-瓶颈 3 和层 3-瓶颈 5 中的三个不同通道进行特征可视化。</p></figure><p id="7e18" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">要了解更多关于特性可视化及其在这个项目中的具体实现，请参见这篇优秀的文章。</p><h1 id="45d3" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">比较特征可视化</h1><p id="2d12" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">既然我们已经讨论了潜在的想法，让我们看看如何在神经网络中可视化这种变化。回想一下，有两个网络需要考虑:</p><ul class=""><li id="8db7" class="mx my it kw b kx ky la lb ld mz lh na ll nb lp nc nd ne nf bi translated">在 ImageNet 上预先训练的<strong class="kw iu">基础网络</strong></li><li id="f7f7" class="mx my it kw b kx ng la nh ld ni lh nj ll nk lp nc nd ne nf bi translated"><strong class="kw iu">狗网络</strong>是在狗数据集上微调的基础网络</li></ul><p id="17ea" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在微调过程中，只允许训练体系结构中的四个组件(不包括全连接层):</p><ul class=""><li id="8d38" class="mx my it kw b kx ky la lb ld mz lh na ll nb lp nc nd ne nf bi translated">第 3 层，瓶颈 5</li><li id="7f03" class="mx my it kw b kx ng la nh ld ni lh nj ll nk lp nc nd ne nf bi translated">第 4 层，瓶颈 0</li><li id="5e8c" class="mx my it kw b kx ng la nh ld ni lh nj ll nk lp nc nd ne nf bi translated">第 4 层，瓶颈 1</li><li id="9349" class="mx my it kw b kx ng la nh ld ni lh nj ll nk lp nc nd ne nf bi translated">第 4 层，瓶颈 2</li></ul><p id="7e42" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，我们将只为这四个层中的通道创建特征可视化。目标是比较两个网络中匹配组件的特征可视化。例如，层 3-瓶颈 5 中的第一通道的特征可视化在基础网络和狗网络之间如何变化？直觉上，我们应该期待后一个网络的许多特征更像“狗”(例如，更像皮毛的纹理)。</p><p id="ce18" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这种分析的一个假设是，随着我们深入网络，特征可视化将变得越来越不同。这是基于这样的观察，即更深的层通常代表更复杂的特征(见<strong class="kw iu">图 3 </strong>)。另一种看待这一点的方式是，网络中的早期层代表更基本的特征，这些特征在计算机视觉任务中是通用的(因此在训练期间不太可能被改变)。</p><h1 id="83a2" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">自动化图像比较</h1><p id="4132" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">手动比较特征可视化是不方便的。目标层上有数千个通道。更不用说，这将在比较中引入人为偏见，因为一个人对哪些图像不同的看法是主观的。相反，我们必须定义两幅图像之间的相似性度量。</p><p id="77af" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">当我们通过神经网络输入图像时，图像在每一层中的隐藏状态都是丰富的潜在向量表示。如果我们使用图像的这种矢量表示，我们可以使用<a class="ae lr" href="https://en.wikipedia.org/wiki/Cosine_similarity" rel="noopener ugc nofollow" target="_blank">余弦相似度</a>来判断两个矢量彼此有多相似。</p><p id="abb5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">对于每一对特征可视化，我们通过基本网络分别馈送它们，并在完全连接的层之前检索它们的隐藏矢量表示(嵌入)。然后，我们将两个可视化之间的相似性度量定义为它们各自嵌入的余弦相似性。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/b583904b1d46c841ede1ea53e5d2bf15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MQqs_fj0s5JRhiftrOxA9w.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated"><strong class="bd mu">图四。</strong>余弦相似性度量的概述。层 4-瓶颈 2 之后的全局平均池产生 2048 维向量。</p></figure><h1 id="7952" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">功能:ImageNet →狗</h1><p id="c3ee" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">在我们进行比较之前，需要注意的是，一些通道未能优化其特征可视化，导致无特征的灰度图像。有趣的是，这种模式在基础网络中的任何特征可视化中都没有出现。不太清楚为什么这些通道未能优化。在任何情况下，由于那些有缺陷的可视化缺乏任何可比较的特征，它们被丢弃了(更多细节见附录)。</p><p id="67a0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在<strong class="kw iu">图 5 </strong>中，我们可以看到基础网络和狗网络之间的第 3 层瓶颈 5 中最不同和最相似的前 3 个通道。在大多数不同的通道中，在通道 667 和 675 中的狗网络的特征可视化中清楚地出现了毛皮状纹理。尽管 963 频道也有明显的变化，但那里的新功能在视觉上并不能解释为“像狗一样”。不足为奇的是，实际上在前 3 个最相似的通道中没有可检测到的变化，因为相同的模式在每个图像对中重复。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/d8c4ee51bb59e3ca76dc89343de9ed55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Co_KSLc5DuK6CBkgzybPaw.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated"><strong class="bd mu">图五。</strong>分别列出第 3 层-瓶颈 5 中最不同和最相似的 3 个特征可视化。</p></figure><p id="2df0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">移动到<strong class="kw iu">图 6 </strong>的下一层，前 3 个最不同的特征可视化的变化有点难以解读。狗网络中的通道 503 的可视化似乎包含散布在图像上的几个类似狗的特征，包括眼睛、鼻子和嘴。频道 1904 很有趣，因为可视化看起来几乎像植物，这可能是数据集的副产品，因为许多狗的图像是在户外拍摄的。</p><p id="b430" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">同样值得注意的是，该层的前 3 个最相似通道中的可视化对彼此之间的差异比前一层中的可视化对更多。有趣的是，它们都在图像上共享类似特定符号/字符的覆盖纹理(这可能有助于放大以获得更好的视图)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/651b8eb89c0dad246fc480b866a6f1c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4CXESgt1Yo7MUjN7Qd50_g.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated"><strong class="bd mu">图 5。</strong>分别列出第 4 层-瓶颈 0 中最不同和最相似的 3 个特征可视化。</p></figure><p id="1a06" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在<strong class="kw iu">图 7 的下一层中，</strong>前 3 个最不同的通道中的可视化开始代表更完整的狗的图片。例如，在频道 700 和 899 中，特征似乎分别类似于哈巴狗和伯恩山犬的头部。有趣的是，最相似的通道再次包含类似字符的纹理。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/e64c633cedc879b7229bd1c55c14087d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u1XFNVpkvj9yG3egxAYYyg.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated"><strong class="bd mu">图 7。</strong>第 4 层-瓶颈 1 中最不同和最相似的 3 个特征可视化。</p></figure><p id="009c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">下面的图 8 </strong>描绘了最终层中前 3 个最不同和最相似的通道。前 3 个最不同的频道中的频道 707 和 442 再次在可视化中展示更完整的狗特征，例如头。</p><p id="9fc0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这一层中，甚至前 3 个最相似频道中的频道 1485 和 31 也在其狗网络的可视化中展示了类似狗的特征。这些通道还包含前两层示例中讨论的特定纹理。另一方面，通道 952 不包含该纹理，并且其图案在其对于基础和狗网络的可视化中保持一致。这可能会突出我们的余弦相似性度量中的缺陷，因为它忽略了关于通道 1485 和 31 的新狗特征的图像中的明显变化。出于某种原因，相似性度量更关注它们的纹理，而不是它们的新内容。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/84dd392f225a8df72baacd6b8ee76518.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vnk3RV1HJXA9qGp98QfQMQ.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated"><strong class="bd mu">图 8。</strong>分别列出第 4 层-瓶颈 2 中最不同和最相似的 3 个特征可视化。</p></figure><h1 id="054e" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">表征层之间的差异</h1><p id="ea87" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">已经可视化了目标层内特征<em class="lq">的变化，现在让我们评估层</em>之间的变化<em class="lq">的程度。<strong class="kw iu">图 9 </strong>以箱线图的形式展示了四个目标层内余弦相似性的分布。除了最后一层(第 4 层-瓶颈 2)，随着我们深入网络，余弦相似性分布有明显的下降趋势。这表明，平均而言，对于更深的层，基本网络和狗网络的特征可视化之间存在更多差异(这与我们之前的假设一致)。</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/3d9edd69f2c52a587c763acdb84e39df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fpbJ_7zJKukZ_rrq9zrabg.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated"><strong class="bd mu">图九。</strong>每个目标层的基本网络和 dog 网络特征可视化之间的平均余弦相似性分布的箱线图。</p></figure><p id="37c3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有趣的是，最后一层偏离了这种模式，并且与前一层具有几乎相同的中值余弦相似性。这种偏差更有可能是使用要素可视化作为比较手段的误导效果，而不是最终图层变化较小的迹象。</p><p id="6bee" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了理解这一点，让我们再看几个第 4 层瓶颈 2 的特征可视化(仅使用前 3 个极端可能不是一个好的表示)。<strong class="kw iu">下图 10 </strong>显示了该层中三个不同通道的特征可视化的变化。这一层的可视化似乎更加复杂，许多表现出来的特征相互纠缠在一起。在所有三个例子中，我们可以看到新的类似狗的特征出现在狗网络的可视化中。然而，由于其他可视化特征的丰富性，这些新的类似狗的特征不像前面图层中的可视化特征那样突出。</p><p id="f391" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">假设这种模式在最终层的可视化中是常见的，这可以解释为什么层 4-瓶颈 2 的平均余弦相似性不低于层 4-瓶颈 1 的平均余弦相似性。与直觉相反，最终层中特征可视化的更高复杂性和丰富性可能会“淹没”新狗特征引入的变化。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/0072e39b5c2a8c604295cc79f442f4d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*7MFse0rNwAMJMm7BTJzOjA.png"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated"><strong class="bd mu">图 10。</strong>基础网络和 dog 网络的第 4 层瓶颈 2 的三个示例特征可视化。</p></figure><h1 id="3ae4" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">结论</h1><p id="0a9a" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">在这个项目中，我们可视化了神经网络的检测特征如何随着网络向新任务的微调而变化。我们将 ImageNet 预训练的 ResNet-50 模型微调到一个更小的狗品种图像数据集。正如所料，新的类似狗的特征出现在微调网络的可视化中，尤其是在更深的层中。根据我们的相似性度量，网络中的最后一层打破了这种模式，突出了使用特征可视化来评估网络中的变化的潜在缺陷或困难。</p><p id="0e2e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">考虑到这一点，让我们讨论一下这个项目的其他一些细微差别:</p><ul class=""><li id="97d2" class="mx my it kw b kx ky la lb ld mz lh na ll nb lp nc nd ne nf bi translated"><strong class="kw iu">特征可视化提供了对网络的有限一瞥</strong>:特征可视化创建了一个图像，它最大化地激活了网络中的一个组件。然而，生成的图像只捕捉到每个组件学习检测的少量特征。这就是为什么更深层的特征可视化看起来如此混乱和纠结的原因(很难将所有潜在的特征都压缩到一张图像中！)</li><li id="0036" class="mx my it kw b kx ng la nh ld ni lh nj ll nk lp nc nd ne nf bi translated"><strong class="kw iu">可能会有一个更好的特征可视化配置</strong>:这个项目中的结果是使用一个单一的配置生成的，它为每个层产生了良好的结果，但是可能有不同的设置会产生更好的可视化效果。</li><li id="4a6e" class="mx my it kw b kx ng la nh ld ni lh nj ll nk lp nc nd ne nf bi translated">这个项目中的相似性度量是一个黑盒:余弦相似性本身并不是一个黑盒。然而，由于其输入是深层网络中的隐藏表示，我们对图像中的相似性度量究竟比较什么的理解有限。这解释了为什么我们的度量突出显示为最相似的几个通道包含相同的特定<strong class="kw iu"> </strong>纹理。</li></ul><h1 id="d508" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">附录</h1><h2 id="1d73" class="ns lt it bd lu nt nu dn ly nv nw dp mc ld nx ny me lh nz oa mg ll ob oc mi od bi translated"><strong class="ak">斯坦福汽车数据集</strong></h2><p id="2354" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">在这个项目中还执行了第二个微调任务。和以前一样，基本网络是在 ImageNet 上预先训练的 ResNet-50。第二个数据集是<a class="ae lr" href="https://ai.stanford.edu/~jkrause/cars/car_dataset.html" rel="noopener ugc nofollow" target="_blank">斯坦福汽车数据集</a> [4]，其中包含 196 种不同车型的约 16，000 张汽车图像。使用标准的微调方法，在这个新数据集上实现了 70%的分类准确率。</p><p id="b752" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然而，由于生成的要素可视化中的变化缺乏可解释性，该数据集不包括在讨论中。尽管这些变化是显而易见的，相似性分布的箱线图也遵循了狗网络中的模式，但新特征并不十分“像汽车”。这可能是由于更困难的微调任务(如在结果的准确度分数中明显的)或者可能是由于识别狗特征比识别汽车特征更好的人类偏见。</p><h2 id="e9f3" class="ns lt it bd lu nt nu dn ly nv nw dp mc ld nx ny me lh nz oa mg ll ob oc mi od bi translated"><strong class="ak">移除故障特征可视化</strong></h2><p id="6166" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">由于特征可视化是一个优化问题，并且每一层仅使用一种配置，因此一些通道未能优化，这导致了灰色图像。<strong class="kw iu">图 11 </strong>显示了每一层的灰度图像数量(第三层-瓶颈 5 没有)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/3b805ccdbe0a68f3296d6d1514ecc890.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/0*z4D-ArHvT1WPQkv0"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated"><strong class="bd mu">图 11。</strong>每层中错误可视化的数量</p></figure><p id="515b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了识别和去除这些灰度图像，必须定义一个评分函数。第一步是创建每个图像的灰度版本(这可以使用 Pillow python 库来完成)。然后，计算图像的原始 RGB 版本和灰度版本之间的平方误差。灰色特征可视化与其灰度版本非常相似，导致误差更小(<strong class="kw iu">图 12 </strong>)。事实上，绘制分类错误显示了错误的灰色特征可视化和正常特征可视化之间的大尖峰。剩下的就是移除落在该尖峰左侧的特征可视化(<strong class="kw iu">图 13 </strong>)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/2e0a1da602238da1afa6c02470106274.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/1*X3C9BhU8kFNXoyGSaR5EGg.png"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated"><strong class="bd mu">图 12。</strong>灰度图像评分功能概述。在这个例子中，主要是灰色的有缺陷的可视化将具有比原始图像更低的平方误差。</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/2c9e6fbfc19f1709a9a6c2e78eb8c4cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*buYjyfosF0YYB6M4naACUQ.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated"><strong class="bd mu">图 13。</strong>在误差值的巨大尖峰之前，故障通道可以被识别为簇。</p></figure><h2 id="f92b" class="ns lt it bd lu nt nu dn ly nv nw dp mc ld nx ny me lh nz oa mg ll ob oc mi od bi translated"><strong class="ak">克矩阵距离</strong></h2><p id="9d86" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">在试验特征可视化之间的相似性度量时，基于 Gram 矩阵定义了一个度量。Gram 矩阵是在神经风格转移[1]中引入的，是一种捕捉图像中纹理信息的技术。然后，克矩阵距离被定义为比较中第一和第二图像的克矩阵之间的平方误差。</p><p id="4c7c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这种想法背后的直觉是，可视化中的特征通常会在整个图像中重复出现(有一些变化)。比较特征可视化之间的纹理信息是有意义的，因为它总结了图像中的局部结构，而不考虑它们的位置。</p><p id="07cc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然而，基于视觉检查，该度量不如余弦相似性表现得好。一个原因是网络中不同层之间的 Gram 矩阵距离变化很大，很难将它们组合成一个度量。</p><h1 id="8e60" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">参考</h1><ol class=""><li id="798d" class="mx my it kw b kx mk la ml ld oh lh oi ll oj lp ok nd ne nf bi translated">Gatys，l .，Ecker，a .，&amp; Bethge，M. (2016 年)。《艺术风格的神经算法》。视觉杂志，16(12)，326。doi: 10.1167/16.12.326</li><li id="0f80" class="mx my it kw b kx ng la nh ld ni lh nj ll nk lp ok nd ne nf bi translated">何刚，张，任，孙，“深度残差学习在图像识别中的应用”。2016 年在 CVPR</li><li id="4007" class="mx my it kw b kx ng la nh ld ni lh nj ll nk lp ok nd ne nf bi translated">科斯拉(a .)，贾亚德瓦普拉卡什(n .)，姚(b)和(l .),“用于细粒度图像分类的新型数据集”。2011 年 IEEE 计算机视觉和模式识别会议(CVPR)，第一届细粒度视觉分类研讨会。</li><li id="1d76" class="mx my it kw b kx ng la nh ld ni lh nj ll nk lp ok nd ne nf bi translated">j .克劳斯，m .斯塔克，邓杰，飞飞，l .〈精细分类的三维对象表示〉。第四届 IEEE 表示和识别研讨会，ICCV 2013 (3dRR-13)。澳大利亚悉尼。2013 年 12 月 8 日。</li><li id="7157" class="mx my it kw b kx ng la nh ld ni lh nj ll nk lp ok nd ne nf bi translated">Olah，c .，Mordvintsevm A .，和 Schubert，L. 2017。“特征可视化”。蒸馏。<a class="ae lr" href="https://distill.pub/2017/feature-visualization" rel="noopener ugc nofollow" target="_blank">https://distill.pub/2017/feature-visualization</a></li></ol></div></div>    
</body>
</html>