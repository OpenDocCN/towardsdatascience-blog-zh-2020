<html>
<head>
<title>Hierarchical Clustering: Agglomerative and Divisive — Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">等级聚类:凝聚和分裂——解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/hierarchical-clustering-agglomerative-and-divisive-explained-342e6b20d710?source=collection_archive---------4-----------------------#2020-08-02">https://towardsdatascience.com/hierarchical-clustering-agglomerative-and-divisive-explained-342e6b20d710?source=collection_archive---------4-----------------------#2020-08-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="447d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">聚集和分裂聚类算法及其实现综述</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/00244e4f11f445ee528bce49915fdb01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KplGwejxlwRdEAfG"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">卢卡斯·布拉塞克在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="61a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">层次聚类是一种聚类分析方法，用于将相似的数据点聚类在一起。分层聚类遵循自顶向下或自底向上的聚类方法。</p><h1 id="c41e" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">什么是集群？</h1><p id="ed6e" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">聚类是一种无监督的机器学习技术，它将群体分成几个聚类，使得同一聚类中的数据点更相似，而不同聚类中的数据点不相似。</p><ul class=""><li id="e03e" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated">同一簇中的点彼此更接近。</li><li id="c422" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">不同簇中的点相距很远。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/bc39ae2fc286e384aab80536f5cb30d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:712/format:webp/0*0OharQES2IT2svnq.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，样本二维数据集</p></figure><p id="169a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在上面的二维数据集样本中，可以看到数据集形成了 3 个相距很远的聚类，并且同一聚类中的点彼此靠近。</p><p id="1cb3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">除了层次聚类之外，还有几种聚类算法，如 k-Means 聚类、DBSCAN 等。阅读下面的文章，了解什么是 k-means 聚类以及如何实现它。</p><div class="nh ni gp gr nj nk"><a rel="noopener follow" target="_blank" href="/understanding-k-means-k-means-and-k-medoids-clustering-algorithms-ad9c9fbf47ca"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd iu gy z fp np fr fs nq fu fw is bi translated">了解 K-means、K-means++和 K-medoids 聚类算法</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">了解 K-means、K-means++和 K-Medoids 聚类算法及其关系的概述。这篇文章…</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">towardsdatascience.com</p></div></div><div class="nt l"><div class="nu l nv nw nx nt ny ks nk"/></div></div></a></div><p id="b2cc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，您可以了解层次集群及其类型。</p><p id="b5e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有两种类型的层次聚类方法:</p><ol class=""><li id="bbf4" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu nz my mz na bi translated">分裂聚类</li><li id="f9de" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu nz my mz na bi translated">凝聚聚类</li></ol><h1 id="96fa" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">分裂聚类:</h1><p id="e7a0" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">分裂聚类算法是一种自上而下的聚类方法，最初，数据集中的所有点都属于一个聚类，并且当一个聚类在层次结构中向下移动时，会递归地执行分裂。</p><h2 id="cad8" class="oa lw it bd lx ob oc dn mb od oe dp mf li of og mh lm oh oi mj lq oj ok ml ol bi translated">分裂聚类的步骤:</h2><ol class=""><li id="2a67" class="ms mt it lb b lc mn lf mo li om lm on lq oo lu nz my mz na bi translated">最初，数据集中的所有点都属于一个单独的聚类。</li><li id="9cb5" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu nz my mz na bi translated">将集群划分为两个最不相似的集群</li><li id="001c" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu nz my mz na bi translated">递归地进行以形成新的聚类，直到获得期望数量的聚类。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/7b7d389755defc2032eab151c5951113.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9-ay426PC9zXWglD7LRNoQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片作者)，<strong class="bd oq">第一张图片:</strong>所有的数据点都属于一个聚类，<strong class="bd oq">第二张图片:</strong> 1 个聚类从前一个单个聚类中分离出来，<strong class="bd oq">第三张图片:</strong>再有 1 个聚类从前一组聚类中分离出来。</p></figure><p id="01c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在上面的样本数据集中，观察到有 3 个彼此相距很远的聚类。所以我们在得到 3 个集群后就停止了。</p><p id="f449" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">即使开始进一步分离更多的簇，下面是获得的结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/fa4eea0cc664453925d39a961eb5800d.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*VLN53TWU-nJBB10mCu_ixg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，样本数据集分为 4 个聚类</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/da27bd9d0d40cad3473d17799998e733.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*xwhqz6pcHxF-zX1mOSWDKw.png"/></div></figure><h2 id="b11d" class="oa lw it bd lx ob oc dn mb od oe dp mf li of og mh lm oh oi mj lq oj ok ml ol bi translated">如何选择拆分哪个集群？</h2><p id="cbb7" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">检查每个分类的误差平方和，并选择具有最大值的分类。在下面的二维数据集中，当前，数据点被分成 2 个聚类，为了进一步将其分成第 3 个聚类，找出红色聚类和蓝色聚类中每个点的误差平方和(SSE)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/95a544484a01b55f08380f2237ea06fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*59Tt8AYi6UN3Rcxd4IuW7A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，样本数据集分为 2 个聚类</p></figure><p id="22e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">具有最大 SSE 值的聚类被分成 2 个聚类，从而形成新的聚类。在上面的图像中，可以观察到红色星团有较大的 SSE，因此它被分成两个星团，总共形成三个星团。</p><h2 id="97d0" class="oa lw it bd lx ob oc dn mb od oe dp mf li of og mh lm oh oi mj lq oj ok ml ol bi translated">如何拆分上面选择的集群？</h2><p id="263f" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">一旦我们决定了分割哪个集群，那么问题就出现了，如何将选择的集群分割成两个集群。一种方法是使用<a class="ae ky" href="https://en.wikipedia.org/wiki/Ward%27s_method" rel="noopener ugc nofollow" target="_blank">沃德标准</a>来追踪作为分割结果的 SSE 标准差异的最大减少。</p><h2 id="64c1" class="oa lw it bd lx ob oc dn mb od oe dp mf li of og mh lm oh oi mj lq oj ok ml ol bi translated">如何处理噪音或异常值？</h2><p id="c26e" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">由于离群值或噪声的存在，可能导致形成其自己的新聚类。为了处理数据集中的噪声，使用阈值来确定终止标准，这意味着不生成太小的聚类。</p></div><div class="ab cl ot ou hx ov" role="separator"><span class="ow bw bk ox oy oz"/><span class="ow bw bk ox oy oz"/><span class="ow bw bk ox oy"/></div><div class="im in io ip iq"><h1 id="89be" class="lv lw it bd lx ly pa ma mb mc pb me mf jz pc ka mh kc pd kd mj kf pe kg ml mm bi translated">凝聚聚类:</h1><p id="fc4d" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">凝聚聚类是一种自下而上的方法，最初，每个数据点都是自己的一个聚类，随着层次结构的向上移动，更多的聚类对被合并。</p><h2 id="7d7f" class="oa lw it bd lx ob oc dn mb od oe dp mf li of og mh lm oh oi mj lq oj ok ml ol bi translated">聚集聚类的步骤:</h2><ol class=""><li id="c2d0" class="ms mt it lb b lc mn lf mo li om lm on lq oo lu nz my mz na bi translated">最初，所有的数据点都是它自己的一个集群。</li><li id="d8e8" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu nz my mz na bi translated">取两个最近的集群，将它们连接起来形成一个集群。</li><li id="0565" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu nz my mz na bi translated">递归地进行第 2 步，直到获得所需的聚类数。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pf"><img src="../Images/82bed2fead9ca2816afd8507ed158384.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AM3SBvuzJ-6HVEkuNrbFZg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，<strong class="bd oq">第一张图:</strong>所有的数据点都是它自己的一个聚类，<strong class="bd oq">第二张图:</strong>两个最近的聚类(被一个黑色椭圆包围)结合在一起形成一个单独的聚类。</p></figure><p id="5018" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在上面的样本数据集中，观察到两个集群彼此相距甚远。所以我们在得到 2 个集群后就停止了。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/97b1adcb6c0f98dcb2fc8f1d74ae353c.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*sKTXIJWNwSrhbWKW4OvXTg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，样本数据集分为两个聚类</p></figure><h2 id="90c8" class="oa lw it bd lx ob oc dn mb od oe dp mf li of og mh lm oh oi mj lq oj ok ml ol bi translated">如何将两个集群连接成一个集群？</h2><p id="e97f" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">为了获得期望数量的聚类，聚类的数量需要从最初的 n 个聚类减少(n 等于数据点的总数)。通过计算两个聚类之间的相似性来组合它们。</p><p id="49e8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有一些方法用于计算两个聚类之间的相似性:</p><ul class=""><li id="bed7" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated">两个聚类中最近的两个点之间的距离。</li><li id="f5e0" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">两个集群中两个最远点之间的距离。</li><li id="1f52" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">两个聚类中所有点之间的平均距离。</li><li id="eb23" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">两个簇的质心之间的距离。</li></ul><p id="400c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">选择上述任何一种相似性度量标准都有一些优点和缺点。</p><h2 id="663b" class="oa lw it bd lx ob oc dn mb od oe dp mf li of og mh lm oh oi mj lq oj ok ml ol bi translated">实施:</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ph pi l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure></div><div class="ab cl ot ou hx ov" role="separator"><span class="ow bw bk ox oy oz"/><span class="ow bw bk ox oy oz"/><span class="ow bw bk ox oy"/></div><div class="im in io ip iq"><h1 id="f8e9" class="lv lw it bd lx ly pa ma mb mc pb me mf jz pc ka mh kc pd kd mj kf pe kg ml mm bi translated">结论:</h1><p id="b6db" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在本文中，我们讨论了凝聚和分裂层次聚类算法的深入直觉。分层算法的缺点是空间和时间复杂度大，不适用于大数据集。</p><blockquote class="pj"><p id="c626" class="pk pl it bd pm pn po pp pq pr ps lu dk translated">感谢您的阅读</p></blockquote></div></div>    
</body>
</html>