<html>
<head>
<title>The (Artificially) Intelligent Investor</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">(人工)聪明的投资者</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-artificially-intelligent-investor-379a180e199f?source=collection_archive---------60-----------------------#2020-04-20">https://towardsdatascience.com/the-artificially-intelligent-investor-379a180e199f?source=collection_archive---------60-----------------------#2020-04-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="e471" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">金融中的人工智能</h2><div class=""/><div class=""><h2 id="c446" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">使用 RNNs 生成投资建议</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/4f7391a466782a610e4c3e7b4902ad59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zrnn3q4j7GyjMuZBZXTJrw.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">马库斯·斯皮斯克在<a class="ae lh" href="https://unsplash.com/s/photos/finance?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="e127" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">莎士比亚戏剧，斯蒂芬·金的小说，甚至坎耶的歌词都曾作为生成文本的递归神经网络(RNNs)的训练数据。虽然这些项目很有趣，但我想为文本生成找到一个更实际的用途，并决定探索 RNNs 是否可以形成连贯的投资建议。在考虑了几个选项后，我选择用本杰明·格拉哈姆的《聪明的投资者 T4》来训练这个模型，这本书被沃伦·巴菲特称为“有史以来最好的投资书籍”。正如我们稍后将看到的，该模型的输出当然没有揭示击败市场的秘密，但思考人工智能是否有一天能够提供合理的财务建议仍然很有趣。</p><h1 id="48bd" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">RNNs:快速概述</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/44fd4ae2db6368e9613be6a093866da6.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*B8hYaF8datk5VY5-BdOYYw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">门控循环单元(图片来自<a class="ae lh" href="https://en.wikipedia.org/wiki/Gated_recurrent_unit" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></figure><p id="04e0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">rnn 类似于人类的学习。当人类思考时，我们并不是每秒钟都从零开始思考。例如，在句子“鲍勃打篮球”中，我们知道鲍勃是打篮球的人，因为我们在阅读句子时保留了过去单词的信息。类似地，rnn 是具有反馈回路的神经网络，这允许它们在达到最终输出之前使用过去的信息。然而，随着时间间隔的增长，RNNs 只能连接最近的信息，而不能连接更早的信息。门控递归单元(gru)是 RNNs 的改进版本，它通过一个决定传递哪些信息相关的更新门和一个决定哪些过去的信息不相关的重置门来克服短期记忆问题。关于 GRUs 的深入解释，点击<a class="ae lh" rel="noopener" target="_blank" href="/understanding-gru-networks-2ef37df6c9be">这里</a>。</p><p id="c7b9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="me">作者注:RNNs 的定义重用自我之前的文章</em> <a class="ae lh" rel="noopener" target="_blank" href="/predicting-stock-prices-using-a-keras-lstm-model-4225457f0233"> <em class="me">机器学习预测股票价格</em></a><em class="me"/></p><h1 id="89dd" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">导入/加载数据</h1><p id="f7e0" class="pw-post-body-paragraph li lj it lk b ll my kd ln lo mz kg lq lr na lt lu lv nb lx ly lz nc mb mc md im bi translated">首先，我们进行必要的导入:Tensorflow、Numpy 和 os。</p><pre class="ks kt ku kv gt nd ne nf ng aw nh bi"><span id="7e2b" class="ni mg it ne b gy nj nk l nl nm">import tensorflow as tf</span><span id="516f" class="ni mg it ne b gy nn nk l nl nm">import numpy as np</span><span id="926e" class="ni mg it ne b gy nn nk l nl nm">import os</span></pre><p id="e1de" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下一步是下载我们的数据，这是一个智能投资者的. txt 文件。我从文件中删除了前言、索引和一些图表，以帮助我们的模型生成更相关的文本。一旦我们下载了这个文件，我们看一下里面总共有多少个字符。</p><pre class="ks kt ku kv gt nd ne nf ng aw nh bi"><span id="4f45" class="ni mg it ne b gy nj nk l nl nm">from google.colab import files</span><span id="5f8f" class="ni mg it ne b gy nn nk l nl nm">files.upload()</span><span id="8def" class="ni mg it ne b gy nn nk l nl nm">text = open('The_Intelligent_Investor copy.txt', 'rb').read().decode(encoding='utf-8')</span><span id="f7bc" class="ni mg it ne b gy nn nk l nl nm">print ('Length of text: {} characters'.format(len(text)))</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi no"><img src="../Images/ec70917a47da66b6f1b8d23ca76743a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GN1qL0_hjalxRvZEdY-1Cw.png"/></div></div></figure><h1 id="432b" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">预处理</h1><p id="a69d" class="pw-post-body-paragraph li lj it lk b ll my kd ln lo mz kg lq lr na lt lu lv nb lx ly lz nc mb mc md im bi translated">让我们看看文件中有多少独特的字符。</p><pre class="ks kt ku kv gt nd ne nf ng aw nh bi"><span id="9f77" class="ni mg it ne b gy nj nk l nl nm">vocab = sorted(set(text))</span><span id="f8fc" class="ni mg it ne b gy nn nk l nl nm">print ('{} unique characters'.format(len(vocab)))</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi np"><img src="../Images/035ba71ad039b0b2978997461407429c.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*5qTkIP_CiH85Pgvk7jQ0Dw.png"/></div></figure><p id="32de" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们的模型不能理解字母，所以我们必须对文本进行矢量化。每个独特的字符被映射成一个整数，以便计算机理解，整数被映射到字符，以便我们以后可以解码计算机的输出。</p><pre class="ks kt ku kv gt nd ne nf ng aw nh bi"><span id="513a" class="ni mg it ne b gy nj nk l nl nm">#Maps characters to ints</span><span id="81bc" class="ni mg it ne b gy nn nk l nl nm">char2int = {char: num for num, char in enumerate(vocab)}</span><span id="c491" class="ni mg it ne b gy nn nk l nl nm">#Maps ints to characters</span><span id="0666" class="ni mg it ne b gy nn nk l nl nm">int2char = np.array(vocab)</span><span id="2a6e" class="ni mg it ne b gy nn nk l nl nm">#Intelligent Investor text represented as ints.</span><span id="6223" class="ni mg it ne b gy nn nk l nl nm">text_as_int = np.array([char2int[char] for char in text])</span><span id="3503" class="ni mg it ne b gy nn nk l nl nm">print(char2int)</span><span id="7ec4" class="ni mg it ne b gy nn nk l nl nm">print(int2char)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nq"><img src="../Images/9f00d3239d908d13c3ab25ac3a199529.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0LHjYBDEPp5ftMQOJ0w1JQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">字符到整数映射的示例</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nr"><img src="../Images/64850f4fcc5255fbc0696350781c3f2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BN_EwNdtbrUA8J-hQPONmA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">整数到字符映射的示例</p></figure><p id="f718" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们训练 RNN 模型的目的是教会它在给定的字符序列后预测最可能的字符。为此，我们将把文本中的输入序列分成一个示例序列和目标序列。目标序列是右移一个字符的示例序列，因此文本块必须比序列长一个字符。例如，如果我们的文本是“股票”，示例序列将是“股票”，目标序列将是“库存”。</p><pre class="ks kt ku kv gt nd ne nf ng aw nh bi"><span id="8394" class="ni mg it ne b gy nj nk l nl nm">seq_length = 100</span><span id="87b4" class="ni mg it ne b gy nn nk l nl nm">examples_per_epoch = len(text)//(seq_length+1)<br/># Create examples and targets sequences</span><span id="eae9" class="ni mg it ne b gy nn nk l nl nm">char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)</span><span id="13ab" class="ni mg it ne b gy nn nk l nl nm">sequences = char_dataset.batch(seq_length+1, drop_remainder=True)</span><span id="15e4" class="ni mg it ne b gy nn nk l nl nm">def split_input_seq(chunk):</span><span id="7ee0" class="ni mg it ne b gy nn nk l nl nm">    example_text = chunk[:-1]</span><span id="b710" class="ni mg it ne b gy nn nk l nl nm">    target_text = chunk[1:]</span><span id="3829" class="ni mg it ne b gy nn nk l nl nm">    return example_text, target_text</span><span id="3f7e" class="ni mg it ne b gy nn nk l nl nm">dataset = sequences.map(split_input_seq)</span><span id="4047" class="ni mg it ne b gy nn nk l nl nm">#look at the first example and target sequence</span><span id="4fa5" class="ni mg it ne b gy nn nk l nl nm">for example_text, target_text in  dataset.take(1):</span><span id="1287" class="ni mg it ne b gy nn nk l nl nm">    print ('Example data: ',  repr(''.join(int2char[example_text.numpy()])))</span><span id="a5ee" class="ni mg it ne b gy nn nk l nl nm">    print ('Target data:',  repr(''.join(int2char[target_text.numpy()])))</span></pre><p id="e52d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在训练我们的模型之前，我们将数据混洗并分段成批。混洗数据的目的是通过避免过度拟合来提高模型的性能，过度拟合是指模型学习训练数据过于紧密，无法很好地推广到测试集。</p><pre class="ks kt ku kv gt nd ne nf ng aw nh bi"><span id="f07e" class="ni mg it ne b gy nj nk l nl nm">batch_size = 64</span><span id="ac92" class="ni mg it ne b gy nn nk l nl nm">buffer_size = 10000</span><span id="bc59" class="ni mg it ne b gy nn nk l nl nm">dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)</span></pre><h1 id="5a00" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">构建/培训我们的模型</h1><p id="21a0" class="pw-post-body-paragraph li lj it lk b ll my kd ln lo mz kg lq lr na lt lu lv nb lx ly lz nc mb mc md im bi translated">使用为训练准备的数据，我们创建具有三层的模型。</p><ol class=""><li id="d4d3" class="ns nt it lk b ll lm lo lp lr nu lv nv lz nw md nx ny nz oa bi translated">嵌入层是我们的输入层，它将每个字符的整数表示映射为 256 维的密集向量。</li><li id="cb75" class="ns nt it lk b ll ob lo oc lr od lv oe lz of md nx ny nz oa bi translated">GRU 层是我们的隐藏层，有 1024 个 RNN 单位。</li><li id="bf73" class="ns nt it lk b ll ob lo oc lr od lv oe lz of md nx ny nz oa bi translated">Softmax 层是我们的输出层，有 109 个潜在输出(109 个唯一字符中的一个)。</li></ol><pre class="ks kt ku kv gt nd ne nf ng aw nh bi"><span id="f346" class="ni mg it ne b gy nj nk l nl nm">model = tf.keras.Sequential()</span><span id="195a" class="ni mg it ne b gy nn nk l nl nm">model.add(tf.keras.layers.Embedding(len(vocab), 256, batch_input_shape=[batch_size, None]))</span><span id="00b5" class="ni mg it ne b gy nn nk l nl nm">model.add(tf.keras.layers.GRU(1024, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'))</span><span id="d2b5" class="ni mg it ne b gy nn nk l nl nm">model.add(tf.keras.layers.Dense(len(vocab)))</span><span id="3ba5" class="ni mg it ne b gy nn nk l nl nm">#summary of our model</span><span id="da45" class="ni mg it ne b gy nn nk l nl nm">model.summary()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi og"><img src="../Images/3b130c847591d7b68738e08ae00ca58a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u8rYKzJqxWstlCG9e2OHxg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">我们模型的总结</p></figure><p id="3bd9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，我们用 Adam 优化器和稀疏分类交叉熵损失函数来编译我们的模型。</p><pre class="ks kt ku kv gt nd ne nf ng aw nh bi"><span id="d212" class="ni mg it ne b gy nj nk l nl nm">def loss(labels, logits):<br/>    return tf.keras.losses.sparse_categorical_crossentropy(labels,         logits, from_logits=True)</span><span id="9bf3" class="ni mg it ne b gy nn nk l nl nm">model.compile(optimizer='adam', loss=loss)</span></pre><p id="8f46" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在我们训练模型之前，我们确保在训练期间保存检查点。通过保存检查点，我们可以用不同的批量快速重建我们的模型，并恢复保存的权重，而不是再次训练它。</p><pre class="ks kt ku kv gt nd ne nf ng aw nh bi"><span id="3aeb" class="ni mg it ne b gy nj nk l nl nm">checkpoint_dir = './training_checkpoints'</span><span id="f9a4" class="ni mg it ne b gy nn nk l nl nm">checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt_{epoch}")</span><span id="292d" class="ni mg it ne b gy nn nk l nl nm">#Make sure the weights are saved</span><span id="10f2" class="ni mg it ne b gy nn nk l nl nm">checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(</span><span id="565f" class="ni mg it ne b gy nn nk l nl nm">filepath=checkpoint_prefix, save_weights_only=True)</span><span id="0ed1" class="ni mg it ne b gy nn nk l nl nm">history = model.fit(dataset, epochs=30, callbacks=[checkpoint_callback])</span></pre><h1 id="b7a3" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">生成文本</h1><p id="1eac" class="pw-post-body-paragraph li lj it lk b ll my kd ln lo mz kg lq lr na lt lu lv nb lx ly lz nc mb mc md im bi translated">重新构建我们的模型，并加载批量大小更改为 1 的权重，这使得预测更简单。</p><pre class="ks kt ku kv gt nd ne nf ng aw nh bi"><span id="fb03" class="ni mg it ne b gy nj nk l nl nm">model = tf.keras.Sequential()</span><span id="fad8" class="ni mg it ne b gy nn nk l nl nm">model.add(tf.keras.layers.Embedding(len(vocab), 256, batch_input_shape=[1, None]))</span><span id="17e8" class="ni mg it ne b gy nn nk l nl nm">model.add(tf.keras.layers.GRU(1024, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'))</span><span id="3140" class="ni mg it ne b gy nn nk l nl nm">model.add(tf.keras.layers.Dense(len(vocab)))</span><span id="66d4" class="ni mg it ne b gy nn nk l nl nm">#load weights from previous model</span><span id="5bc0" class="ni mg it ne b gy nn nk l nl nm">model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))</span><span id="fa83" class="ni mg it ne b gy nn nk l nl nm">model.build(tf.TensorShape([1, None]))</span><span id="cff6" class="ni mg it ne b gy nn nk l nl nm">#summary of our model</span><span id="9a1e" class="ni mg it ne b gy nn nk l nl nm">model.summary()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi og"><img src="../Images/d430f013e1100be0ea0a2fbc04b4a64b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sMlxh2qz6SLwN9VIGFWhSA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">新模型概述</p></figure><p id="2c50" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">关键时刻到了:我们的模型最终揭示了它的投资建议！温度参数影响我们接收到的输出:较低的温度导致更保守的输出，而较高的温度导致更有创造性的输出，更容易出错。我们将在下面看到这样的例子。</p><pre class="ks kt ku kv gt nd ne nf ng aw nh bi"><span id="ca75" class="ni mg it ne b gy nj nk l nl nm">#try any temperature in the range of 0.1 to 1</span><span id="809c" class="ni mg it ne b gy nn nk l nl nm">def generate_text(model, start_string, temperature):</span><span id="71f9" class="ni mg it ne b gy nn nk l nl nm">    # Number of characters to generate</span><span id="c21c" class="ni mg it ne b gy nn nk l nl nm">    num_generate = 1000</span><span id="1a38" class="ni mg it ne b gy nn nk l nl nm">    # Converting our start string to numbers (vectorizing)</span><span id="5e21" class="ni mg it ne b gy nn nk l nl nm">    input_eval = [char2int[s] for s in start_string]</span><span id="d94b" class="ni mg it ne b gy nn nk l nl nm">    input_eval = tf.expand_dims(input_eval, 0)</span><span id="eb0d" class="ni mg it ne b gy nn nk l nl nm">    # Empty string to store our results</span><span id="a37c" class="ni mg it ne b gy nn nk l nl nm">    text_generated = []</span><span id="f77f" class="ni mg it ne b gy nn nk l nl nm">    model.reset_states()</span><span id="0fea" class="ni mg it ne b gy nn nk l nl nm">    for i in range(num_generate):</span><span id="aa06" class="ni mg it ne b gy nn nk l nl nm">        predictions = model(input_eval)</span><span id="03df" class="ni mg it ne b gy nn nk l nl nm">        # remove the batch dimension</span><span id="d5cf" class="ni mg it ne b gy nn nk l nl nm">        predictions = tf.squeeze(predictions, 0)</span><span id="3e2b" class="ni mg it ne b gy nn nk l nl nm">        predictions = predictions / temperature</span><span id="b9d9" class="ni mg it ne b gy nn nk l nl nm">        predicted_id = tf.random.categorical(predictions,     <br/>        num_samples=1)[-1,0].numpy()</span><span id="980a" class="ni mg it ne b gy nn nk l nl nm">        input_eval = tf.expand_dims([predicted_id], 0)</span><span id="00af" class="ni mg it ne b gy nn nk l nl nm">        text_generated.append(int2char[predicted_id])</span><span id="694d" class="ni mg it ne b gy nn nk l nl nm">    return (start_string + ''.join(text_generated))</span><span id="e01c" class="ni mg it ne b gy nn nk l nl nm">print(generate_text(model, start_string="Advice: ", temperature=.5))</span></pre><p id="3ec0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这是我们的模型在温度为 0.1 时产生的建议。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oh"><img src="../Images/970d785308312b5aa183b5321fbc8e35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dEB9A10gXiMvvUozsWk0pQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">温度= 0.1</p></figure><p id="9a2e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">尽管这一结果与你应该遵循的任何投资建议都相去甚远，但它在模仿聪明的投资者方面做得相当不错。由于气温较低，我们的模型没有尝试创新，而是通过坚持段落格式中的标准句子来谨慎行事。让我们看看随着温度的升高，这是如何变化的。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oi"><img src="../Images/52f207d86ae296e6a9441a747783465b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h6jlJ7t2i-A0KSTrz7ebJA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">温度= 0.5</p></figure><p id="61e6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在温度为 0.5 时，我们可以开始看到输出的差异。我们的模型试图更有创造性，结果却犯了更多的错误。这方面的一个例子是在倒数第二行，括号使用不当。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oj"><img src="../Images/35f2d0b19f1366e8cb395d2fdf5e4cca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fnhps1nZHqi8frZQ82Qygw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">温度= 1</p></figure><p id="07ac" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，温度为 1 时的差异非常明显，因为我们的模型试图生成表格。然而，创造性增加的代价是输出变得很难理解。我在不同的温度下提供了更多的输出，以供参考。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oh"><img src="../Images/3150219ea2f69db93907ba14b5c0b193.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ge2OKwynchnxId_6D6WeNQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">温度= 0.1</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ok"><img src="../Images/2a4dbfa29605bd071ee539d7162e7502.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e2o2ntlZdqE_lMjFbRLeyQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">温度= 0.5</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ol"><img src="../Images/f95e29cfffc822f6dadd34f23cdd2d07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZYCcooI8WVHQOSi4RxudKA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">温度= 1</p></figure><h1 id="6b44" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">结论</h1><p id="c9dd" class="pw-post-body-paragraph li lj it lk b ll my kd ln lo mz kg lq lr na lt lu lv nb lx ly lz nc mb mc md im bi translated">正如我们所看到的，RNNs 目前还不能取代投资顾问。也就是说，这里有一些我们可以尝试改进模型输出的方法。</p><ul class=""><li id="3256" class="ns nt it lk b ll lm lo lp lr nu lv nv lz nw md om ny nz oa bi translated">增加纪元的数量</li><li id="e23c" class="ns nt it lk b ll ob lo oc lr od lv oe lz of md om ny nz oa bi translated">获得一个更好的训练数据集(当把<em class="me">这个聪明的投资者</em>从 pdf 文件转换成 txt 文件时，一些格式被弄乱了)</li><li id="bbf2" class="ns nt it lk b ll ob lo oc lr od lv oe lz of md om ny nz oa bi translated">使用 LSTM 图层代替 GRU 图层(lstm 是 RNN 的另一种改进类型)</li></ul><h1 id="6e02" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">参考</h1><p id="e2b1" class="pw-post-body-paragraph li lj it lk b ll my kd ln lo mz kg lq lr na lt lu lv nb lx ly lz nc mb mc md im bi translated">[1]谷歌团队，<a class="ae lh" href="https://www.tensorflow.org/tutorials/text/text_generation" rel="noopener ugc nofollow" target="_blank">文本生成与 RNN </a>，Tensorflow 核心</p><p id="4007" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">[2] Aurélien Géron，<a class="ae lh" href="https://github.com/ageron/handson-ml2/blob/master/16_nlp_with_rnns_and_attention.ipynb" rel="noopener ugc nofollow" target="_blank">使用 RNNs 和 Attention 进行自然语言处理</a>，使用 Scikit-Learn、Keras 和 TensorFlow 进行动手机器学习</p></div><div class="ab cl on oo hx op" role="separator"><span class="oq bw bk or os ot"/><span class="oq bw bk or os ot"/><span class="oq bw bk or os"/></div><div class="im in io ip iq"><p id="7166" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">先别走</strong>！</p><p id="5bdc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我是 Roshan，16 岁，对人工智能和金融的交叉领域充满热情。如果你对应用于金融的 RNNs 有进一步的兴趣，可以看看这篇文章:<a class="ae lh" rel="noopener" target="_blank" href="/predicting-stock-prices-using-a-keras-lstm-model-4225457f0233">https://towards data science . com/predicting-stock-prices-using-a-keras-lstm-model-4225457 f 0233</a></p><p id="43f3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在 Linkedin 上联系我:<a class="ae lh" href="https://www.linkedin.com/in/roshan-adusumilli-96b104194/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/roshan-adusumilli-96b104194/</a></p></div></div>    
</body>
</html>