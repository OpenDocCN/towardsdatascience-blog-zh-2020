<html>
<head>
<title>Understanding Trees</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解树木</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data-science-crash-course-understanding-trees-60337f605448?source=collection_archive---------70-----------------------#2020-04-26">https://towardsdatascience.com/data-science-crash-course-understanding-trees-60337f605448?source=collection_archive---------70-----------------------#2020-04-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="942f" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">数据科学速成班</h2><div class=""/><div class=""><h2 id="dc21" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">了解用于分类和回归的基于树的模型</h2></div><p id="93a7" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">本月早些时候，<a class="ae ln" href="https://medium.com/u/9ab35c11801?source=post_page-----49cfc5ed9136----------------------" rel="noopener"> Edward Qian </a>和我开始为有抱负的数据科学家编写一套综合课程，这些课程可以在我们的网站【www.dscrashcourse.com】上找到</p><p id="6303" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我将把稍加修改的课程交叉发布到 Medium 上，让更多的观众可以看到。如果你觉得这些文章很有帮助，请到网站上查看更多的课程和练习题！</p></div><div class="ab cl lo lp hx lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="im in io ip iq"><p id="7b4f" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">基于树的方法可用于回归和分类。这些算法背后的思想是将预测器空间分成多个不重叠的区域，并将新的观测值分配给它们各自的区域。这些方法也被称为<strong class="kt jd">决策树方法</strong>。</p><h1 id="fade" class="lv lw it bd lx ly lz ma mb mc md me mf ki mg kj mh kl mi km mj ko mk kp ml mm bi translated">回归决策树</h1><p id="3e04" class="pw-post-body-paragraph kr ks it kt b ku mn kd kw kx mo kg kz la mp lc ld le mq lg lh li mr lk ll lm im bi translated">在将预测空间分成<em class="ms"> n </em>个区域后，我们计算该区域中响应变量的统计量(例如，平均值)。新的预测将被放入它们各自的区域中，并且该区域的统计数据将被用作预测。</p><p id="e0d8" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们用房价的例子来说明一个例子。为了简单起见，我们假设最佳区域已经确定。房地产经纪人吉姆想尝试一种基于树的方法来预测房价。他用房子的面积和年龄作为预测指标。</p><p id="0bf2" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">Jim 的决策树将其预测器空间划分如下:</p><ul class=""><li id="8525" class="mt mu it kt b ku kv kx ky la mv le mw li mx lm my mz na nb bi translated">区域#1:面积小于 250 平方英尺，年龄小于 10 岁</li><li id="9fb1" class="mt mu it kt b ku nc kx nd la ne le nf li ng lm my mz na nb bi translated">区域#2:面积小于 250 平方英尺，年龄超过 10 年</li><li id="b684" class="mt mu it kt b ku nc kx nd la ne le nf li ng lm my mz na nb bi translated">区域#3:面积超过 250 平方英尺，年龄在 10 岁以下</li><li id="ad3f" class="mt mu it kt b ku nc kx nd la ne le nf li ng lm my mz na nb bi translated">区域#4:面积超过 250 平方英尺，年龄超过 10 年</li></ul><figure class="ni nj nk nl gt nm gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi nh"><img src="../Images/1108b283b9ee7541af771190599f7269.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JU3VIbZszDrW6fcj.png"/></div></div></figure><p id="001e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">吉姆想推断一栋新房子的价格(在图中用红色标出)。这所房子属于第四区。从训练集中观察到的区域 4 中房屋的平均价格是$125，000。因此，吉姆的模型会预测这个新房子会卖那么多。</p><h1 id="c685" class="lv lw it bd lx ly lz ma mb mc md me mf ki mg kj mh kl mi km mj ko mk kp ml mm bi translated">分类决策树</h1><p id="fdb0" class="pw-post-body-paragraph kr ks it kt b ku mn kd kw kx mo kg kz la mp lc ld le mq lg lh li mr lk ll lm im bi translated">用于分类的决策树的行为类似于回归。假设 Jim 决定使用相同的预测器(在不同的数据集上)来预测某人是否会出价购买房子。蓝色的观察值对应于那些提供报价的观察值，而红色的观察值对应于没有报价。该算法将预测器空间分成<em class="ms"> n </em>个区域，并且每个区域被映射到一个类别。</p><p id="ac57" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">Jim 的决策树将其预测器空间划分如下:</p><ul class=""><li id="be15" class="mt mu it kt b ku kv kx ky la mv le mw li mx lm my mz na nb bi translated">区域# 1:5 岁以下</li><li id="908c" class="mt mu it kt b ku nc kx nd la ne le nf li ng lm my mz na nb bi translated">区域#2:年龄超过 5 年，面积超过 250 平方英尺</li><li id="a2f4" class="mt mu it kt b ku nc kx nd la ne le nf li ng lm my mz na nb bi translated">区域#3:年龄超过 5 年，面积小于 250 平方英尺</li></ul><figure class="ni nj nk nl gt nm gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi nh"><img src="../Images/5957ab1f3712de38f652ae6ce489a9eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2wa9DZxbehT7Uxna.png"/></div></div></figure><p id="4224" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">假设算法也告诉我们，区域 2 和 3 映射到“offer”，而区域 1 映射到“no offer”。有了这些信息，我们可以预测随后的观测值将属于哪一类。</p><h1 id="084b" class="lv lw it bd lx ly lz ma mb mc md me mf ki mg kj mh kl mi km mj ko mk kp ml mm bi translated">更复杂的基于树的方法</h1><p id="3602" class="pw-post-body-paragraph kr ks it kt b ku mn kd kw kx mo kg kz la mp lc ld le mq lg lh li mr lk ll lm im bi translated">我们可以<strong class="kt jd">集成</strong>(组合)多个决策树来形成更复杂的模型。基于树的集成算法分为:</p><ul class=""><li id="ee2b" class="mt mu it kt b ku kv kx ky la mv le mw li mx lm my mz na nb bi translated"><strong class="kt jd"> Bagging </strong>(也称为<strong class="kt jd"> bootstrap aggregation </strong>):更小的数据子集是通过替换随机抽样产生的。在每个子集上训练决策树。来自每个决策树的结果被<em class="ms">平均</em>以产生最终输出。</li><li id="6364" class="mt mu it kt b ku nc kx nd la ne le nf li ng lm my mz na nb bi translated"><strong class="kt jd"> Boosting </strong>:与 Bagging 不同，在 Bagging 中每个决策树都是独立训练的，Boosting 算法中的每个学习器都是从以前的学习器中顺序学习的。</li><li id="e78b" class="mt mu it kt b ku nc kx nd la ne le nf li ng lm my mz na nb bi translated"><strong class="kt jd">堆叠</strong>:几个模型并行训练。另一个模型被训练以基于每个集合模型的预测来确定输出。这种集成技术在基于树的模型中并不常见。</li></ul><h2 id="4c20" class="nt lw it bd lx nu nv dn mb nw nx dp mf la ny nz mh le oa ob mj li oc od ml iz bi translated">装袋示例:随机森林</h2><p id="793c" class="pw-post-body-paragraph kr ks it kt b ku mn kd kw kx mo kg kz la mp lc ld le mq lg lh li mr lk ll lm im bi translated"><strong class="kt jd">随机森林</strong>是一种流行的机器学习算法，使用 bagging 集成决策树。除了随机采样每棵树的训练数据之外，随机森林还随机采样用于每棵树的特征。</p><h2 id="b8f0" class="nt lw it bd lx nu nv dn mb nw nx dp mf la ny nz mh le oa ob mj li oc od ml iz bi translated">Boosting 示例:使用决策树的 AdaBoost</h2><p id="599d" class="pw-post-body-paragraph kr ks it kt b ku mn kd kw kx mo kg kz la mp lc ld le mq lg lh li mr lk ll lm im bi translated"><strong class="kt jd"> AdaBoost </strong>是 adaptive boosting 的缩写，在迭代过程中集成决策树:我们从数据集上训练的一个决策树开始，但在每个迭代步骤中，我们重新加权数据集，以更加强调错误分类，并在这个重新加权的数据集上重新训练决策树。</p><h1 id="3ed0" class="lv lw it bd lx ly lz ma mb mc md me mf ki mg kj mh kl mi km mj ko mk kp ml mm bi translated">感谢您的阅读！</h1><p id="6e89" class="pw-post-body-paragraph kr ks it kt b ku mn kd kw kx mo kg kz la mp lc ld le mq lg lh li mr lk ll lm im bi translated">如果你喜欢这篇文章，你可能想看看我关于数据科学、数学和编程的其他文章。<a class="ae ln" href="https://medium.com/@mandygu" rel="noopener">关注我 Medium </a>上的最新更新！</p></div></div>    
</body>
</html>