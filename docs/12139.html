<html>
<head>
<title>Penalizing the Discount Factor in Reinforcement Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">强化学习中折扣因子的惩罚</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/penalizing-the-discount-factor-in-reinforcement-learning-d672e3a38ffe?source=collection_archive---------30-----------------------#2020-08-21">https://towardsdatascience.com/penalizing-the-discount-factor-in-reinforcement-learning-d672e3a38ffe?source=collection_archive---------30-----------------------#2020-08-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d241" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">强化学习领域用于许多机器人问题，具有独特的机制，奖励应该通过行动来积累。但是，这些动作之间的时间呢？</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9c02ef481a0a2158bb16e25cccdd3575.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WvMuhK30SagJNO38vWZaHA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者形象</p></figure><p id="587f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这篇文章讨论了我发现影响很大的一个关键参数:折扣因子。讨论了基于时间的惩罚以获得更好的性能，其中折扣因子被相应地修改。</p><p id="185e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我假设如果你看到这篇文章，你已经熟悉 RL 术语了。如果不是这样，那么在你继续之前，我强烈推荐这些提供了很好背景的博客:<a class="ae lu" rel="noopener" target="_blank" href="/introduction-to-various-reinforcement-learning-algorithms-i-q-learning-sarsa-dqn-ddpg-72a5e0cb6287"> Intro1 </a>和<a class="ae lu" rel="noopener" target="_blank" href="/reinforcement-learning-demystified-markov-decision-processes-part-1-bf00dda41690"> Intro2 </a>。</p><h1 id="4bee" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">折扣因子在 RL 中的作用是什么？</h1><p id="057a" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">贴现因子<strong class="la iu">𝛾</strong>是一个实值∈ [0，1]，关心代理人在过去、现在和未来获得的回报。换句话说，它将奖励与时间域联系起来。让我们来探讨以下两种情况:</p><ol class=""><li id="541e" class="ms mt it la b lb lc le lf lh mu ll mv lp mw lt mx my mz na bi translated">如果<strong class="la iu"> 𝛾 </strong> = 0，代理只关心他的第一个奖励。</li><li id="832f" class="ms mt it la b lb nb le nc lh nd ll ne lp nf lt mx my mz na bi translated">如果<strong class="la iu"> 𝛾 </strong> = 1，代理关心所有未来的奖励。</li></ol><p id="087e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一般来说，设计师应该预先定义场景情节的折扣系数。这可能会引起许多稳定性问题，并且可能在没有达到预期目标的情况下结束。然而，通过探索一些参数，许多问题可以用收敛的解决方案来解决。要进一步了解折扣系数和为机器人应用选择折扣系数的经验法则，我推荐阅读:<a class="ae lu" href="https://stats.stackexchange.com/questions/221402/understanding-the-role-of-the-discount-factor-in-reinforcement-learning" rel="noopener ugc nofollow" target="_blank"> resource3 </a>。</p><h1 id="8189" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">为什么要处罚？</h1><p id="44a5" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">一旦设计者选择了折扣因子，它对于整个场景都是统一的，这对于连续-离散问题(以及更多，但让我们专注于此)来说不是最优的情况。机器人动力学是一个连续的过程，我们通过各种嘈杂的传感器观察，并以离散的方式处理其信息(毕竟是计算机……)。因此，我们通过使用离散的工具来解决一个连续的问题。因为这涉及到数值误差。此外，各种传感器被噪声污染，增加了固有误差。最后，我们假设的动态模型(例如我们定义的状态)也受到不确定性的影响，并且包括额外的误差。</p><p id="db19" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，通过假设统一的折扣因子，我们假设这些误差源的统一行为，这些误差源是非统一行为。对这些问题的补偿可以通过惩罚折扣因子并相应地权衡所获得的回报来实现。</p><h1 id="ee9f" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">关于取样时间的处罚</h1><p id="fc8d" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">下面的例子解释了一种针对采样时间(定义为两次连续测量之间经过的时间)惩罚折扣因子的常用方法:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/adf0a2b4229cf564a88c2ea8019572e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:312/format:webp/1*ZVjzmqKf-gJi6YYogwuAIQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者形象</p></figure><p id="5f85" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">由于采样间隔很小，在极限情况下，折扣为 1(由于<a class="nh ni ep" href="https://medium.com/u/d6ea8553654c?source=post_page-----d672e3a38ffe--------------------------------" rel="noopener" target="_blank">或 Rivlin </a>的校正)，当采样间隔很大，以致两次连续测量之间经过很长时间时，采样间隔相应改变。请记住，折扣因子介于 0 和 1 之间，因此大的采样间隔转换为小的折扣因子(反之亦然)。更新折扣系数的公式只是一个演示该想法的建议，因为可以采用许多其他形式。</p><h1 id="e0c9" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">一个算法例子</h1><p id="d491" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">考虑一个算法交易场景，其中投资者(代理人)在交易市场(环境)中控制他的对冲策略(行动)，其中股票价格(状态)随时间变化。如果最近一次投资已经过去了很长时间，回报就不能保持原样，因为在此期间可能会发生很多变化。因此，修改的折扣因子可能会导致更好的性能，因为它关心事件之间经过的时间。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/af93a340ad86e4462103f4ea7f9206e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c5wPxS6ZSGrTazokN0tZBQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者形象</p></figure><p id="d26a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">就这样…希望你喜欢读这篇文章！如有任何问题/讨论，请随时联系我。</p><p id="bf9e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">巴拉克</p><p id="8230" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">www.barakor.com<a class="ae lu" href="http://www.barakor.com" rel="noopener ugc nofollow" target="_blank"/></p><p id="4f93" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">【https://www.linkedin.com/in/barakor/ T4】</p></div></div>    
</body>
</html>