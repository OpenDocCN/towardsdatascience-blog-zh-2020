# ä½¿ç”¨é€»è¾‘å›å½’é¢„æµ‹åº”ç”¨è®¢é˜…

> åŸæ–‡ï¼š<https://towardsdatascience.com/logistic-regression-how-to-on-app-behavior-data-8a95802a988f?source=collection_archive---------37----------------------->

## ä½¿ç”¨ Sklearn å¯¹åº”ç”¨ç¨‹åºè¡Œä¸ºæ•°æ®è¿›è¡ŒåŠŸèƒ½å·¥ç¨‹ã€æ•°æ®å¤„ç†å’Œé€»è¾‘å›å½’å»ºæ¨¡æ¼”ç»ƒ

![](img/7a7c7285ec75c30254be57db436f8000.png)

é€šè¿‡[é“¾æ¥](https://unsplash.com/photos/F1I4IN86NiE)æ”¹ç¼–è‡ª Unsplash çš„ Img

ä¹‹å‰çš„[æ–‡ç« ](/eda-how-to-on-app-behavior-data-77fde7384a70)æ˜¯å…³äºåŸå§‹æ•°æ®ä¸Šçš„ EDAã€‚åœ¨è¿™é‡Œï¼Œæˆ‘å°†è§£é‡Šå¦‚ä½•æ‰§è¡Œ**ç‰¹å¾å·¥ç¨‹ã€æ•°æ®å¤„ç†**ï¼Œå¹¶æœ€ç»ˆ**ä½¿ç”¨ç§»åŠ¨ app è¡Œä¸ºæ•°æ®åˆ›å»ºé€»è¾‘å›å½’æ¨¡å‹**ã€‚å®ƒåˆ†ä¸º 7 ä¸ªéƒ¨åˆ†ã€‚

1.  é—®é¢˜é™ˆè¿°
2.  ç‰¹å¾å·¥ç¨‹
3.  æ•°æ®å¤„ç†
4.  æ¨¡å‹ç»“æ„
5.  æ¨¡å‹è¯•éªŒ
6.  æ¨¡å‹éªŒè¯
7.  æ‘˜è¦

ç°åœ¨è®©æˆ‘ä»¬å¼€å§‹å§ğŸƒâ€â™€ï¸ğŸƒâ€â™‚ï¸.

1.**é—®é¢˜é™ˆè¿°**

ä¸€å®¶é‡‘èç§‘æŠ€å…¬å¸å§”æ‰˜æˆ‘ä»¬åˆ†æç§»åŠ¨åº”ç”¨è¡Œä¸ºæ•°æ®ï¼Œä»¥å¸®åŠ©å¼•å¯¼å®¢æˆ·è·å¾—ä»˜è´¹è®¢é˜…æœåŠ¡ã€‚å…·ä½“æ¥è¯´ï¼Œä»»åŠ¡æ˜¯ç¡®å®šå“ªäº›ç”¨æˆ·æœ€æœ‰å¯èƒ½ä¸æ³¨å†Œã€‚å›¾ 1 æ˜¯å…·æœ‰ ***12 åˆ—å’Œ 50ï¼Œ000 è¡Œ*** çš„åŸå§‹æ•°æ®ç‰‡æ®µã€‚

![](img/3519a1fc492229b0856be1110d31d6c9.png)

å›¾ 1 åŸå§‹æ•°æ®ç‰‡æ®µ

2.**ç‰¹å¾å·¥ç¨‹**

***ç‰¹å¾å·¥ç¨‹æ˜¯å°†åŸå§‹æ•°æ®è½¬åŒ–ä¸ºæœ€èƒ½ä»£è¡¨é—®é¢˜çš„ç‰¹å¾çš„è‰ºæœ¯ã€‚*** åªæœ‰ç”¨æ­£ç¡®çš„ç‰¹å¾å·¥ç¨‹ï¼Œæ¨¡å‹æ‰èƒ½åšå‡ºæœ€å¥½çš„é¢„æµ‹ã€‚æˆ‘ä»¬å°†ä»ä¸¤ä¸ªæ–¹é¢è¿›è¡Œç‰¹å¾å·¥ç¨‹ã€‚

2.1 å› å˜é‡å·¥ç¨‹

å› å˜é‡æ˜¯åˆ—'*å·²æ³¨å†Œ'*ã€‚ä¸' *enrolled'* å¯†åˆ‡ç›¸å…³çš„ä¸€åˆ—æ˜¯' *enrolled_date'* ã€‚åŸºæœ¬ä¸Šï¼Œç”¨æˆ·å¯ä»¥åœ¨ä»»ä½•æ—¥æœŸæŠ¥åï¼Œä»¥'*æŠ¥å'*ä¸º 1ã€‚ç”±äºå¤§å¤šæ•°åº”ç”¨ç¨‹åºåŠŸèƒ½åœ¨ç¬¬ä¸€ä¸ª 24 å°æ—¶åä¸å¯è¯•ç”¨ï¼Œæˆ‘ä»¬éœ€è¦è®¾ç½®æ³¨å†Œçš„æ—¶é—´é™åˆ¶ã€‚

ä¸ºäº†è®¾ç½®æœ‰æ•ˆçš„ç™»è®°æ—¶é—´é™åˆ¶ï¼Œæˆ‘ä»¬è®¡ç®—' *first_open 'å’Œ' enrolled_date'* ä¹‹é—´çš„æ—¶é—´å·®ï¼Œå¹¶è°ƒæŸ¥ç™»è®°åˆ†å¸ƒã€‚

ç¬¬ä¸€æ­¥æ˜¯è®¡ç®—' *first_open 'å’Œ' enrolled_date'* ä¹‹é—´çš„æ—¶å·®ã€‚å…·ä½“æ¥è¯´ï¼Œå°†' *first_open 'å’Œ' enrolled_date'* è§£æä¸º *datetime* ç±»å‹ï¼Œå¹¶ä»¥å°æ—¶ä¸ºå•ä½è®¡ç®—æ—¶å·®ã€‚

```
dataset[â€œfirst_openâ€] = [parser.parse(row_date) for row_date in dataset[â€œfirst_openâ€]]dataset[â€œenrolled_dateâ€] = [parser.parse(row_date) if isinstance(row_date, str) else row_date for row_date in dataset[â€œenrolled_dateâ€]]dataset[â€œdifferenceâ€] = (dataset.enrolled_date-dataset.first_open).astype(â€˜timedelta64[h]â€™)
```

ç¬¬äºŒæ­¥æ˜¯é€šè¿‡ç»˜åˆ¶â€œ*å·®å¼‚â€*åˆ—çš„ç›´æ–¹å›¾æ¥æŸ¥çœ‹æ³¨å†Œåˆ†å¸ƒã€‚

```
response_hist = plt.hist(dataset[â€œdifferenceâ€].dropna(), color=â€™#3F5D7Dâ€™)
plt.title(â€˜Distribution of Time-Since-Screen-Reachedâ€™)
plt.show()
```

å›¾ 2 æ˜¾ç¤ºç”¨æˆ·æ³¨å†Œé«˜åº¦é›†ä¸­åœ¨å‰ 50 ä¸ªå°æ—¶ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†å“åº”é™åˆ¶è®¾ç½®ä¸º 48 å°æ—¶ã€‚

![](img/e384fe3d52b2bec0975725bb2997a92d.png)

å›¾ 2 æ³¨å†Œåˆ†å¸ƒ

ç°åœ¨ï¼Œæœ‰äº† 48 å°æ—¶çš„ç™»è®°é™åˆ¶ï¼Œæˆ‘ä»¬å°†'T38 å·²ç™»è®°'T39 åˆ—é‡ç½®ä¸º 0ï¼Œå³æœªç™»è®°ã€‚

```
dataset.loc[dataset.difference > 48, â€˜enrolledâ€™] = 0
dataset = dataset.drop(columns=[â€˜enrolled_dateâ€™, â€˜differenceâ€™, â€˜first_openâ€™])
```

ä¸Šé¢æˆ‘ä»¬åˆ é™¤äº†*ã€æ³¨å†Œæ—¥æœŸã€‘**ã€å·®å¼‚ã€‘ã€é¦–æ¬¡å…¬å¼€ã€‘*æ ï¼Œå› ä¸ºåŸ¹è®­ä¸éœ€è¦å®ƒä»¬ã€‚

2.2 è‡ªå˜é‡å·¥ç¨‹

æ•°æ®é›†ä¸­å”¯ä¸€çš„éæ•°å­—åˆ—æ˜¯*â€˜screen _ listâ€™*ã€‚è¿™æ˜¯ä¸€ä¸ªåŒ…å«ç”¨æˆ·æŸ¥çœ‹çš„æ‰€æœ‰å±å¹•åŠŸèƒ½çš„åˆ—è¡¨ã€‚æ‰€ä»¥æˆ‘ä»¬éœ€è¦æŠŠå®ƒè½¬æ¢æˆæ•°å€¼å˜é‡ã€‚ä¸€ç§æ–¹æ³•æ˜¯å°†*â€˜screen _ listâ€™*ä¸­çš„æ¯ä¸ªå”¯ä¸€å±å¹•è½¬æ¢ä¸ºåˆ†ç±»å˜é‡ã€‚*ä½†æ˜¯ï¼Œç‹¬ç‰¹çš„å±å¹•å¤ªå¤šäº†ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†åªå…³æ³¨é‚£äº›æœ€å—æ¬¢è¿çš„å±å¹•ã€‚*å…·ä½“æ¥è¯´ï¼Œ

```
top_screens = pd.read_csv(â€˜top_screens.csvâ€™).top_screens.values
dataset[â€œscreen_listâ€] = dataset.screen_list.astype(str) + â€˜,â€™ 
for sc in top_screens:
    dataset[sc] = dataset.screen_list.str.contains(sc).astype(int)
    dataset['screen_list'] = dataset.screen_list.str.replace(sc+",", "")
```

ä¸Šé¢ï¼Œæˆ‘ä»¬ä¸ºä»£è¡¨æœ€å—æ¬¢è¿å±å¹•çš„*â€˜top _ screensâ€™*ä¸­çš„æ¯ä¸ªå±å¹•åˆ›å»ºäº†ä¸€ä¸ªåˆ—ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ª*â€˜Otherâ€™*åˆ—ï¼Œä½œä¸ºæ‰€æœ‰éæµè¡Œå±å¹•çš„æ€»å’Œã€‚

```
dataset[â€˜Otherâ€™] = dataset.screen_list.str.count(â€œ,â€)
dataset = dataset.drop(columns=[â€˜screen_listâ€™])
```

**æœ€åï¼Œå¦‚æœæˆ‘ä»¬ä»”ç»†æ£€æŸ¥åˆ—çš„åç§°ï¼Œæˆ‘ä»¬ä¼šå‘ç°è®¸å¤šåˆ—ä»£è¡¨ç›¸åŒçš„ç‰¹æ€§ã€‚**ä¾‹å¦‚ï¼Œ*ä¿å­˜ 1* ã€*ä¿å­˜ 5* æ˜¯å…³äºä¿å­˜çš„å±å¹•ï¼Œè€Œ*ä¿¡ç”¨ 1* ã€*ä¿¡ç”¨ 3* æ˜¯å…³äºä¿¡ç”¨çš„å±å¹•ã€‚æˆ‘ä»¬éœ€è¦é€šè¿‡åˆè®¡ç›¸åŒåŠŸèƒ½å±å¹•çš„æ•°é‡æ¥èšåˆç›¸åŒçš„åŠŸèƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œ

```
cm_screens = [â€œCredit1â€, â€œCredit2â€, â€œCredit3â€, â€œCredit3Containerâ€, â€œCredit3Dashboardâ€]
dataset[â€œCMCountâ€] = dataset[cm_screens].sum(axis=1)
dataset = dataset.drop(columns=cm_screens)
```

å¯¹å…¶ä»–ç‰¹å¾é‡å¤ç›¸åŒçš„æ–¹æ³•(ä¾‹å¦‚ï¼Œ*ä¿å­˜*ã€*è´·æ¬¾*ç­‰)ï¼Œæˆ‘ä»¬å¾—åˆ°äº†åŒ…å«æ‰€æœ‰æ•°å­—å˜é‡çš„æœ€ç»ˆæ•°æ®é›†ã€‚å›¾ 3 æ˜¾ç¤ºäº†æ‰€æœ‰çš„åˆ—ã€‚

![](img/a236e3541634f3054f1e318b29507873.png)

å›¾ 3 æ‰€æœ‰æ•°æ®åˆ—åç§°

æ€»ä¹‹ï¼Œæˆ‘ä»¬ä½¿ç”¨æ•°æ®æŒ–æ˜æŠ€æœ¯æ¥æç‚¼å’Œæå–æœ€èƒ½ä»£è¡¨ç§»åŠ¨åº”ç”¨ç”¨æˆ·è¡Œä¸ºçš„å±æ€§ã€‚

3.**æ•°æ®å¤„ç†**

æ•°æ®å¤„ç†åŒ…æ‹¬æ•°æ®åˆ†å‰²å’Œç‰¹å¾ç¼©æ”¾ã€‚

3.1 æ•°æ®åˆ†å‰²

ç¬¬ä¸€æ­¥æ˜¯åˆ†ç¦»è‡ªå˜é‡å’Œå› å˜é‡ã€‚å…·ä½“æ¥è¯´ï¼Œ

```
response = dataset[â€œenrolledâ€]
dataset = dataset.drop(columns=â€enrolledâ€)
```

ç¬¬äºŒæ­¥æ˜¯å°†æ•°æ®åˆ†æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚å…·ä½“æ¥è¯´ï¼Œ

```
X_train, X_test, y_train, y_test = train_test_split(dataset, response, test_size = 0.2, random_state = 0)
```

3.2 ç‰¹å¾ç¼©æ”¾

ç‰¹å¾ç¼©æ”¾æ˜¯ä¸ºäº†é¿å…ä»»ä½•å˜é‡æ”¯é…å…¶ä»–å˜é‡ï¼Œå³é‡‡ç”¨æ›´é«˜çš„æƒé‡å’Œå¯¹æ¨¡å‹å­¦ä¹ çš„å¼ºçƒˆå½±å“ã€‚è¿™é‡Œï¼Œæˆ‘ä»¬é€šè¿‡å»é™¤å¹³å‡å€¼å¹¶ç¼©æ”¾åˆ°å•ä½æ–¹å·®æ¥æ ‡å‡†åŒ–ç‰¹å¾ã€‚å…·ä½“æ¥è¯´ï¼Œ

```
from sklearn.preprocessing import StandardScaler
sc_X = StandardScaler()
X_train2 = pd.DataFrame(sc_X.fit_transform(X_train))
X_test2 = pd.DataFrame(sc_X.transform(X_test)) 
X_train2.columns = X_train.columns.values
X_test2.columns = X_test.columns.values
X_train2.index = X_train.index.values
X_test2.index = X_test.index.values
X_train = X_train2
X_test = X_test2
```

æ³¨æ„ï¼Œ *StandardScaler()* è¿”å›ä¸€ä¸ª *numpy* æ•°ç»„ï¼Œè¯¥æ•°ç»„ä¼šä¸¢å¤±åˆ—åå’Œç´¢å¼•ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å†æ¬¡å°†ç¼©æ”¾åçš„æ•°æ®è½¬æ¢ä¸º*æ•°æ®å¸§*ï¼Œä»¥ä¿ç•™è¡Œå’Œåˆ—æ ‡è¯†ç¬¦ã€‚

å¤ªå¥½äº†ã€‚æ¨¡å‹çš„æ•°æ®ç»ˆäºå‡†å¤‡å¥½äº†ã€‚å›¾ 4 æ˜¯å…·æœ‰ ***50 åˆ—å’Œ 50ï¼Œ000 è¡Œ*** çš„æœ€ç»ˆæ•°æ®çš„ç®€è¦è§†å›¾ã€‚

å›¾ 4 æœ€ç»ˆæ•°æ®çš„ç®€è¦è§†å›¾

4.**æ¨¡å‹å»ºç­‘**

è¿™é‡Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ª**é€»è¾‘å›å½’**æ¨¡å‹æ¥é¢„æµ‹ä¸€ä¸ªäºŒå…ƒå› å˜é‡ï¼Œå³æ˜¯å¦å…¥å­¦ã€‚æ ¹æ®[ç»´åŸºç™¾ç§‘](https://en.wikipedia.org/wiki/Logistic_regression)ï¼Œæ ‡ç­¾ä¸º 1 çš„æ¦‚ç‡çš„å¯¹æ•°æ˜¯ä¸€ä¸ªæˆ–å¤šä¸ªç‹¬ç«‹å˜é‡çš„çº¿æ€§ç»„åˆã€‚æœ¬è´¨ä¸Šï¼Œæˆ‘ä»¬è¯•å›¾ä¼°è®¡ä¸€ä¸ªé€»è¾‘æ¨¡å‹çš„ç³»æ•°ï¼Œå¦‚å›¾ 5 æ‰€ç¤ºã€‚

![](img/0d1ea26fc22f444e35858ebb0616b8bd.png)

å›¾ 5 é€»è¾‘å›å½’æ¨¡å‹(ä½œè€…åˆ›å»ºçš„ Img)

å…·ä½“æ¥è¯´ï¼Œ

```
from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression(random_state = 0, penalty = â€˜l1â€™)
classifier.fit(X_train, y_train)
```

æ³¨æ„æˆ‘ä»¬ä½¿ç”¨æ‹‰ç´¢(*ã€L1ã€‘*)æ­£åˆ™åŒ–æ¨¡å‹ï¼Œè€Œä¸æ˜¯æ­£æ€å›å½’æ¨¡å‹ã€‚ *L1* æ­£åˆ™åŒ–ç»™æŸå¤±å‡½æ•°å¢åŠ ä¸€ä¸ªç­‰äº ***ç³»æ•°*** å¤§å°çš„ç»å¯¹å€¼ä¹‹å’Œçš„æƒ©ç½šï¼Œå¦‚å›¾ 6 æ‰€ç¤ºã€‚

![](img/d663b1592a8a67aba752a4b04972165f.png)

å›¾ L1 æ­£åˆ™åŒ–çš„æŸå¤±å‡½æ•°(ä½œè€…åˆ›å»ºçš„ Img)

æ³¨æ„ *L1* å’Œ *L2* æ­£åˆ™åŒ–çš„åŒºåˆ«åœ¨äº *L2* ç›¸åŠ çš„æƒ©ç½šæ˜¯ ***ç³»æ•°****å¤§å°çš„å¹³æ–¹å€¼ä¹‹å’Œï¼Œå¦‚å›¾ 7 æ‰€ç¤ºã€‚*

*![](img/090617b59ea4440d3390f8c3dc42a4cb.png)*

*å›¾ 7 L2 æ­£åˆ™åŒ–æŸå¤±å‡½æ•°(ä½œè€…åˆ›å»ºçš„ Img)*

*5.**æ¨¡å‹æµ‹è¯•***

*è®­ç»ƒå¥½æ¨¡å‹åï¼Œè®©æˆ‘ä»¬åœ¨ *X_test* ä¸Šæµ‹è¯•æ¨¡å‹ã€‚*

```
*y_pred = classifier.predict(X_test)
cm = confusion_matrix(y_test, y_pred)*
```

*ä¸ºäº†æ›´å¥½åœ°å›é¡¾é¢„æµ‹ç»“æœï¼Œè®©æˆ‘ä»¬å°†å…¶ä¸å®é™…ç»“æœè¿›è¡Œæ¯”è¾ƒã€‚æ‰€ä»¥ï¼Œå…·ä½“æ¥è¯´ï¼Œ*

```
*final_results = pd.concat([y_test, test_identity],axis =1).dropna()
final_results[â€˜predicted_resultsâ€™] = y_pred
final_results[[â€˜userâ€™, â€˜enrolledâ€™,â€˜predicted_resultsâ€™]].reset_index(drop=True)*
```

*å›¾ 8 æ˜¾ç¤ºäº†å®é™…ç™»è®°çš„ç»“æœå’Œé¢„æµ‹çš„ç»“æœã€‚*

*![](img/27938b4f36a2ee6a74e75842648c51d9.png)*

*å›¾ 8 é¢„æµ‹å’Œå®é™…ç»“æœå¯¹æ¯”*

*å›¾ 9 å±•ç¤ºäº†æ··æ·†çŸ©é˜µã€‚è¿™å‘Šè¯‰æˆ‘ä»¬æµ‹è¯•ç²¾åº¦ä¸º 0.768ã€‚ä¸é”™çš„ç»“æœğŸ˜ƒã€‚å¦‚æœä½ æƒ³çŸ¥é“å¦‚ä½•è®¡ç®—ç²¾åº¦ï¼Œè¯·é˜…è¯»è¿™ç¯‡[æ–‡ç« ](https://medium.com/@vistaxjtu/intuitively-explain-accuracy-precision-recall-and-f1-777563342aca)ã€‚*

*![](img/3ede255f851f13e658a631b87d59987e.png)*

*å›¾ 9 æ··æ·†çŸ©é˜µ*

*6.**æ¨¡å‹éªŒè¯***

*æœ‰äº†ä¸Šé¢çš„æµ‹è¯•å‡†ç¡®æ€§ï¼Œä½œä¸ºä¸€ä¸ªæ•°æ®ç§‘å­¦å®¶ï¼Œä½ åº”è¯¥é—®ä¸€ä¸ªé—®é¢˜:è¿™æ˜¯æ¨¡å‹æ€§èƒ½çš„çœŸå®åæ˜ å—ğŸ¤”ï¼Ÿä¸ºäº†å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ K å€äº¤å‰éªŒè¯ã€‚*

*å…·ä½“æ¥è¯´ï¼Œå°†è®­ç»ƒæ•°æ®åˆ†æˆ 10 ä¸ªå­é›†ï¼Œä½¿ç”¨ 9 ä¸ªå­é›†æ¥è®­ç»ƒæ¨¡å‹ï¼Œå‰©ä½™çš„ç”¨äºéªŒè¯ã€‚é‡å¤è¿™ä¸ªè®­ç»ƒå’ŒéªŒè¯ 10 æ¬¡ã€‚æœ€åå¹³å‡å‡†ç¡®ç‡å’ŒæŸè€—ã€‚*

```
*accuracies = cross_val_score(estimator= classifier, X= X_train, y = y_train, cv = 10)*
```

*æˆ‘ä»¬å¾—åˆ°çš„å¹³å‡ç²¾åº¦ä¸º **0.767** ï¼Œæ ‡å‡†åå·®ä¸º **0.10** ã€‚å¾ˆå¥½ï¼Œæ¨¡å‹æ˜¾ç¤ºå‡ºå¾ˆå°çš„å·®å¼‚ï¼Œå³æ¨¡å‹å§‹ç»ˆæ˜¯å‡†ç¡®çš„ã€‚*

*7.**æ€»ç»“***

*æ¦‚æ‹¬åœ°è¯´ï¼Œæˆ‘ä»¬ç»å†äº†ç‰¹å¾å·¥ç¨‹ã€æ•°æ®å¤„ç†ã€æ¨¡å‹æ„å»ºã€æµ‹è¯•å’ŒéªŒè¯ã€‚ç‰¹å¾å·¥ç¨‹å’Œæ•°æ®å¤„ç†æ˜¯è€—æ—¶çš„ï¼Œä½†æ˜¯ä¸ºæ¨¡å‹å‡†å¤‡æ•°æ®æ˜¯æœ€é‡è¦çš„ã€‚å¦‚æœä½ æƒ³äº†è§£æ¨¡å‹ä¼˜åŒ–ï¼Œè¯·é˜…è¯»è¿™ç¯‡[æ–‡ç« ](/ann-classification-model-evaluation-and-parameter-tuning-9174fd5ad0c2)ã€‚*

***å¤ªå¥½äº†ï¼è¿™å°±æ˜¯æ‰€æœ‰çš„æ—…ç¨‹ï¼å¦‚æœæ‚¨éœ€è¦æºä»£ç ï¼Œè¯·éšæ—¶è®¿é—®æˆ‘çš„** [**Github**](https://github.com/luke4u/Customer_Behaviour_Prediction/tree/main/enrollment_prediction) **é¡µé¢ğŸ¤ğŸ¤ã€‚***