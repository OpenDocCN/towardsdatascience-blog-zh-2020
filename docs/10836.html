<html>
<head>
<title>Accelerating Spark 3.0 Google DataProc Project with NVIDIA GPUs in 6 simple steps</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 NVIDIA GPUs 通过 6 个简单的步骤加速 Spark 3.0 Google DataProc 项目</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/accelerating-spark-3-0-google-dataproc-project-with-nvidia-gpus-in-6-simple-steps-ab8c26d38957?source=collection_archive---------41-----------------------#2020-07-28">https://towardsdatascience.com/accelerating-spark-3-0-google-dataproc-project-with-nvidia-gpus-in-6-simple-steps-ab8c26d38957?source=collection_archive---------41-----------------------#2020-07-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/660cd7f6c74b315f9d2024a66bd9d3c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ijI0oQwjUWhnIjjE"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">Genessa panainite 在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><div class=""/><div class=""><h2 id="8097" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">Spark 3.0 + GPU 来了。它改变了游戏规则</h2></div><p id="7c57" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">数据探索是数据科学的关键部分。需要很长时间吗？啊。别问了。为 ML 准备数据集不仅需要理解数据集、清理和创建新特征，还需要重复执行这些步骤，直到我们有一个微调的系统。</p><p id="42d5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当我们走向更大的数据集时，<a class="ae jg" rel="noopener" target="_blank" href="/the-hitchhikers-guide-to-handle-big-data-using-spark-90b9be0fe89a"> Apache Spark </a>带来了一线希望。它为我们提供了一个可扩展的分布式内存系统来处理大数据。顺便说一句，我们还看到了像<a class="ae jg" rel="noopener" target="_blank" href="/moving-from-keras-to-pytorch-f0d4fff4ce79"> Pytorch </a>和 Tensorflow 这样的框架，它们使用数千个 GPU 核心来固有地并行化矩阵计算。</p><p id="a152" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但过去我们从未见过这两种系统协同工作。我们继续在<a class="ae jg" rel="noopener" target="_blank" href="/stop-worrying-and-create-your-deep-learning-server-in-30-minutes-bb5bd956b8de">深度学习</a>中使用 Spark 处理大数据 ETL 任务，使用 GPU 处理矩阵密集型问题。</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lu"><img src="../Images/bf576a2ecfd3f4af581b7fcf639dd290.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Itvwf4seWZJNn9-fcKyc7A.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://marketing.thepoweroftwo.solutions/acton/attachment/42621/f-0f867d92-c1d0-4112-afef-26f9cbb51499/1/-/-/-/-/NVIDIA%20&amp;%20Google%20Cloud%20Dataproc%20ebook%20July2020.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="e0a0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这就是 Spark 3.0 的由来。它为我们提供了一种将 NVIDIA GPUs 添加到 Spark 集群节点的方法。这些节点完成的工作现在可以通过使用 GPU 计算软件平台<a class="ae jg" rel="noopener" target="_blank" href="/minimal-pandas-subset-for-data-scientist-on-gpu-d9a6c7759c7f?source=post_stats_page---------------------------"> RAPIDS </a>的 CPU+GPU 并行处理。</p><blockquote class="lz"><p id="df22" class="ma mb jj bd mc md me mf mg mh mi lt dk translated">Spark + GPU + RAPIDS = Spark 3.0</p></blockquote><p id="b645" class="pw-post-body-paragraph ky kz jj la b lb mj kk ld le mk kn lg lh ml lj lk ll mm ln lo lp mn lr ls lt im bi translated">根据<a class="ae jg" href="https://www.nvidia.com/en-in/deep-learning-ai/solutions/data-science/apache-spark-3/" rel="noopener ugc nofollow" target="_blank"> NVIDIA </a>的说法，Spark 3.0 的早期采用者已经看到了其当前数据负载的显著更快的性能。这种处理时间的减少可以让数据科学家在更大的数据集上进行更多的迭代，让零售商改善他们的预测，让金融公司增强他们的信用模型，让广告技术公司提高他们预测点击率的能力。</p><p id="5505" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">兴奋不已。那么如何才能开始使用 Spark 3.0 呢？幸运的是，Google Cloud、Spark 和 NVIDIA 已经联合起来，为我们简化了集群创建过程。通过 Google Cloud 上的 Dataproc，我们可以在几分钟内拥有一个完全托管的带有 GPU 的 Apache Spark 集群。</p><p id="8a76" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk"> <em class="mo">这篇帖子是关于在 Google Cloud 上用 NVIDIA GPUs 建立自己的 Dataproc Spark 集群。</em>T3】</strong></p></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h2 id="b92b" class="mw mx jj bd my mz na dn nb nc nd dp ne lh nf ng nh ll ni nj nk lp nl nm nn no bi translated">1.创建新的 GCP 项目</h2><p id="6478" class="pw-post-body-paragraph ky kz jj la b lb np kk ld le nq kn lg lh nr lj lk ll ns ln lo lp nt lr ls lt im bi translated">在<a class="ae jg" href="https://cloud.google.com/" rel="noopener ugc nofollow" target="_blank">谷歌云平台</a>上完成初始注册后，我们可以开始一个新项目。在这里，我首先创建一个名为 dSparkDataProc 的新项目。</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nu"><img src="../Images/3e616bf2fb6792bf0e7cc1cda3037657.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IwPfzKHjJ4ONnHiBGciF2w.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">创建新项目</p></figure><h2 id="6d2e" class="mw mx jj bd my mz na dn nb nc nd dp ne lh nf ng nh ll ni nj nk lp nl nm nn no bi translated">2.在 GCP 项目中启用 API</h2><p id="e7ca" class="pw-post-body-paragraph ky kz jj la b lb np kk ld le nq kn lg lh nr lj lk ll ns ln lo lp nt lr ls lt im bi translated">一旦我们添加了这个项目，我们就可以转到我们的新项目，并通过单击右上角的“激活<strong class="la jk">云外壳</strong>按钮来启动云外壳实例。这样做将在屏幕底部打开一个终端窗口，我们可以在其中运行下一个命令来设置数据处理集群:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nv"><img src="../Images/917d30314418ae04e014355aa3979f89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*unxrAYMXzlUyHxyTVakozw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">激活<strong class="bd nw">云壳</strong>来放置你的命令</p></figure><p id="07ed" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这之后，我们将需要运行一些命令来在云 shell 中设置我们的项目。我们从在您的项目中启用 dataproc 服务开始。启用 Compute 和 Dataproc APIs 来访问 Dataproc，并启用 Storage API，因为您将需要一个 Google 云存储桶来存放您的数据。我们还设置了默认区域。这可能需要几分钟时间:</p><pre class="lv lw lx ly gt nx ny nz oa aw ob bi"><span id="61f7" class="mw mx jj ny b gy oc od l oe of">gcloud services enable compute.googleapis.com<br/>gcloud services enable dataproc.googleapis.com <br/>gcloud services enable storage-api.googleapis.com<br/>gcloud config set dataproc/region us-central1</span></pre><h2 id="c3d9" class="mw mx jj bd my mz na dn nb nc nd dp ne lh nf ng nh ll ni nj nk lp nl nm nn no bi translated">3.创建一些数据并放入 GCS 桶中</h2><p id="9d9d" class="pw-post-body-paragraph ky kz jj la b lb np kk ld le nq kn lg lh nr lj lk ll ns ln lo lp nt lr ls lt im bi translated">完成后，我们可以创建一个新的 Google 云存储桶，在那里我们将把所有数据保存在云外壳中:</p><pre class="lv lw lx ly gt nx ny nz oa aw ob bi"><span id="50f2" class="mw mx jj ny b gy oc od l oe of">#You might need to change this name as this needs to be unique across all the users<br/>export BUCKET_NAME=rahulsparktest</span><span id="11c1" class="mw mx jj ny b gy og od l oe of">#Create the Bucket<br/>gsutil mb gs://${BUCKET_NAME}</span></pre><p id="52d4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在运行 spark 集群时，我们还可以将一些数据放入桶中，以便以后运行。</p><pre class="lv lw lx ly gt nx ny nz oa aw ob bi"><span id="c906" class="mw mx jj ny b gy oc od l oe of"># Get data in cloudshell terminal<br/>git clone <a class="ae jg" href="https://github.com/caroljmcdonald/spark3-book" rel="noopener ugc nofollow" target="_blank">https://github.com/caroljmcdonald/spark3-book</a> <br/>mkdir -p ~/data/cal_housing <br/>tar -xzf spark3-book/data/cal_housing.tgz -C ~/data</span><span id="eac7" class="mw mx jj ny b gy og od l oe of"># Put data into Bucket using gsutil<br/>gsutil cp ~/data/CaliforniaHousing/cal_housing.data gs://${BUCKET_NAME}/data/cal_housing/cal_housing.csv</span></pre><h2 id="0df4" class="mw mx jj bd my mz na dn nb nc nd dp ne lh nf ng nh ll ni nj nk lp nl nm nn no bi translated">4.设置 DataProc Rapids 集群</h2><p id="2c8e" class="pw-post-body-paragraph ky kz jj la b lb np kk ld le nq kn lg lh nr lj lk ll ns ln lo lp nt lr ls lt im bi translated">为了创建一个使用 NVIDIA T4 GPU 的 DataProc RAPIDS 集群，我们需要一些初始化脚本来实例化我们的集群。这些脚本将安装 GPU 驱动程序(<a class="ae jg" href="https://raw.githubusercontent.com/GoogleCloudDataproc/initialization-actions/master/gpu/install_gpu_driver.sh" rel="noopener ugc nofollow" target="_blank"> install_gpu_driver.sh </a>)并为我们自动创建 Rapids conda 环境(<a class="ae jg" href="https://raw.githubusercontent.com/GoogleCloudDataproc/initialization-actions/master/rapids/rapids.sh" rel="noopener ugc nofollow" target="_blank"> rapids.sh </a>)。由于这些脚本处于开发阶段，所以最好的方法是从 GitHub 源代码中获取脚本。我们可以在我们的云 shell 中使用下面的命令来做到这一点，我们在其中获取初始化脚本并将它们复制到我们的 GS Bucket 中:</p><pre class="lv lw lx ly gt nx ny nz oa aw ob bi"><span id="0773" class="mw mx jj ny b gy oc od l oe of">wget <a class="ae jg" href="https://raw.githubusercontent.com/GoogleCloudDataproc/initialization-actions/master/rapids/rapids.sh" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/GoogleCloudDataproc/initialization-actions/master/rapids/rapids.sh</a><br/>wget <a class="ae jg" href="https://raw.githubusercontent.com/GoogleCloudDataproc/initialization-actions/master/gpu/install_gpu_driver.sh" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/GoogleCloudDataproc/initialization-actions/master/gpu/install_gpu_driver.sh</a></span><span id="02a6" class="mw mx jj ny b gy og od l oe of">gsutil cp rapids.sh gs://$BUCKET_NAME<br/>gsutil cp install_gpu_driver.sh gs://$BUCKET_NAME</span></pre><p id="8864" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们现在可以在云 Shell 中使用下面的命令来创建集群。在下面的命令中，我们使用一个预定义的镜像版本(2.0.0-RC2-ubuntu18)来创建我们的 dataproc 集群，它包含了 Spark 3.0 和 python 3.7。我用的是这张图片的旧版本，因为最新版本在运行 Jupyter 和 Jupyter Lab 时有一些问题。你可以在这里得到所有版本<a class="ae jg" href="https://cloud.google.com/dataproc/docs/release-notes" rel="noopener ugc nofollow" target="_blank">的列表</a>。</p><pre class="lv lw lx ly gt nx ny nz oa aw ob bi"><span id="7dfc" class="mw mx jj ny b gy oc od l oe of">CLUSTER_NAME=sparktestcluster<br/>REGION=us-central1<br/>gcloud beta dataproc clusters create ${CLUSTER_NAME} \<br/> --image-version 2.0.0-RC2-ubuntu18 \<br/> --master-machine-type n1-standard-8 \<br/> --worker-machine-type n1-highmem-32 \<br/> --worker-accelerator type=nvidia-tesla-t4,count=2 \<br/> --optional-components ANACONDA,JUPYTER,ZEPPELIN \<br/> --initialization-actions gs://$BUCKET_NAME/install_gpu_driver.sh,gs://$BUCKET_NAME/rapids.sh \<br/> --metadata rapids-runtime=SPARK \<br/> --metadata gpu-driver-provider=NVIDIA \<br/> --bucket ${BUCKET_NAME} \<br/> --subnet default \<br/> --enable-component-gateway \<br/>--properties="^#^spark:spark.task.resource.gpu.amount=0.125#spark:spark.executor.<br/>cores=8#spark:spark.task.cpus=1#spark:spark.yarn.unmanagedAM.enabled=false"</span></pre><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oh"><img src="../Images/ae095b549c2863a2a2831955a3b93256.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qAFmQrxsIPxOtUeBc3dzlw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><strong class="bd nw">集群架构</strong></p></figure><p id="5559" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们得到的 Dataproc 集群具有:</p><ul class=""><li id="c4e0" class="oi oj jj la b lb lc le lf lh ok ll ol lp om lt on oo op oq bi translated">一个 8 核主节点和两个 32 核工作节点</li><li id="019b" class="oi oj jj la b lb or le os lh ot ll ou lp ov lt on oo op oq bi translated">两个 NVIDIA T4 GPU 连接到每个工作节点</li><li id="0e88" class="oi oj jj la b lb or le os lh ot ll ou lp ov lt on oo op oq bi translated">巨蟒、朱庇特和齐柏林飞船启动</li><li id="0051" class="oi oj jj la b lb or le os lh ot ll ou lp ov lt on oo op oq bi translated">启用组件网关以访问群集上托管的 Web UIs</li><li id="b9e5" class="oi oj jj la b lb or le os lh ot ll ou lp ov lt on oo op oq bi translated">额外的火花配置调整适用于笔记本电脑环境设置使用属性标志。具体来说，我们设置<code class="fe ow ox oy ny b">spark.executor.cores=8</code>是为了提高并行性，设置<code class="fe ow ox oy ny b">spark.yarn.unmanagedAM.enabled=false</code>是因为它当前破坏了<strong class="la jk"> <em class="mo"> SparkUI </em> </strong>。</li></ul><p id="b0de" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk"> <em class="mo">故障排除:</em> </strong>如果您在执行此命令后收到有关限制的错误，您可能需要更改默认<a class="ae jg" href="https://console.cloud.google.com/iam-admin/quotas?project=sparkdataproc" rel="noopener ugc nofollow" target="_blank"> Google 控制台配额页面</a>中的一些配额。我最终改变的限制是:</p><ul class=""><li id="aabd" class="oi oj jj la b lb lc le lf lh ok ll ol lp om lt on oo op oq bi translated"><strong class="la jk">GPU(所有区域)</strong>至 12(最少 4 个)</li><li id="8450" class="oi oj jj la b lb or le os lh ot ll ou lp ov lt on oo op oq bi translated"><strong class="la jk">CPU(所有地区)</strong>到 164(最少 72 个)</li><li id="b528" class="oi oj jj la b lb or le os lh ot ll ou lp ov lt on oo op oq bi translated"><strong class="la jk">美国中部的 NVIDIA T4 GPU</strong>1 到 12(最低:4)</li><li id="ab88" class="oi oj jj la b lb or le os lh ot ll ou lp ov lt on oo op oq bi translated"><strong class="la jk">美国中央处理器</strong>1 到 164(最少 72 个)</li></ul><p id="9892" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我实际上请求了比我需要的更多的限制，因为增加限制的过程可能需要更长一点的时间，稍后我将启动一些更大的集群。</p><h2 id="1573" class="mw mx jj bd my mz na dn nb nc nd dp ne lh nf ng nh ll ni nj nk lp nl nm nn no bi translated">5.在 DataProc Rapids 集群上运行 JupyterLab</h2><p id="8605" class="pw-post-body-paragraph ky kz jj la b lb np kk ld le nq kn lg lh nr lj lk ll ns ln lo lp nt lr ls lt im bi translated">一旦您的命令成功(可能需要 10-15 分钟)，您将能够在<a class="ae jg" href="https://console.cloud.google.com/dataproc/clusters" rel="noopener ugc nofollow" target="_blank">https://console.cloud.google.com/dataproc/clusters</a>看到您的 Dataproc 集群。或者你可以在浏览器上进入谷歌云平台控制台，搜索“Dataproc”，点击“Dataproc”图标(它看起来像三个相连的圆圈)。这将引导您进入 Dataproc 集群页面。</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oz"><img src="../Images/271d9fd6cf60eb6b850cb79e836e4dfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zX2KsFGYZyHuanQtlbJOEA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">Dataproc 集群页面</p></figure><p id="cb4a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，如果你点击 sparktestcluster，然后点击“web Interfaces ”,你将能够打开一个 Web 界面(Jupyter/JupyterLab/Zeppelin)。</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pa"><img src="../Images/d587366341fe67f7d0c4c1a665335181.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EvTz4VJnDv3mRgm8oGO7Pw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">我们集群的 Web 界面页面</p></figure><p id="83fd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">打开 Jupyter Pyspark 笔记本后，如果您遵循本教程，这里有一些示例代码供您运行。在这段代码中，我们加载了一个小数据集，我们看到<code class="fe ow ox oy ny b">df.count()</code>函数运行了 252 毫秒，这对于 Spark 来说确实很快，但我稍后会发布一篇更详细的基准测试文章，敬请关注。</p><pre class="lv lw lx ly gt nx ny nz oa aw ob bi"><span id="2bc5" class="mw mx jj ny b gy oc od l oe of">file = "gs://rahulsparktest/data/cal_housing/cal_housing.csv"</span><span id="89ce" class="mw mx jj ny b gy og od l oe of">df = spark.read.load(file,format="csv", sep=",", inferSchema="true", header="false")<br/>colnames = ["longitude","latitude","medage","totalrooms","totalbdrms","population","houshlds","medincome","medhvalue"]</span><span id="c8f5" class="mw mx jj ny b gy og od l oe of">df = df.toDF(*colnames)<br/>df.count()</span></pre><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pb"><img src="../Images/38bd5997c9e69d1b123769c7259ca2b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MA24Zzmot45oiLlX7D66Jw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">是的，我们的<strong class="bd nw"> Jupyter 笔记本</strong>起作用了</p></figure><h2 id="9951" class="mw mx jj bd my mz na dn nb nc nd dp ne lh nf ng nh ll ni nj nk lp nl nm nn no bi translated">6.访问 Spark 用户界面</h2><p id="8026" class="pw-post-body-paragraph ky kz jj la b lb np kk ld le nq kn lg lh nr lj lk ll ns ln lo lp nt lr ls lt im bi translated">这一切都很好，但我面临的一个主要问题是，我无法使用笔记本中提供的链接访问 Spark UI。我发现有两种方法可以访问 Spark UI 进行调试:</p><p id="1dbf" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">答:使用网络界面选项:</strong></p><p id="76c7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以通过首先点击<strong class="la jk">网络界面</strong>上的<strong class="la jk">纱线资源管理器</strong>链接，然后点击相应页面上的应用程序主界面来访问 Spark UI:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pc"><img src="../Images/d8e14bbca77afab465154071d8126215.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qBKzS3ZDSKBDpALDN_zdbw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">点击<strong class="bd nw">跟踪界面</strong>栏中的<strong class="bd nw">应用程序主</strong>以获得 Spark 界面</p></figure><p id="a376" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后，您将到达 Spark UI 页面:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pd"><img src="../Images/c2857f877d358039d37edbc687aa1c12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_iacL93lt9Ge6T3GR7n0NQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">是啊！我们得到了 Spark UI。</p></figure><p id="b399" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">B.<strong class="la jk">使用 SSH 隧道选项:</strong></p><p id="9718" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">访问 Spark UI 的另一个选项是使用隧道。为此，您需要转到 web 界面页面并点击<em class="mo">“创建 SSH 隧道以连接到 Web 界面”。</em></p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pe"><img src="../Images/620cd07189913ca325c09a5eeda0f8f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4cAJcKc-Il-wUeBaEN0ubA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">使用 SSH 的 Spark 测试集群 Web 界面</p></figure><p id="8076" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这将给你两个你想在本地机器<strong class="la jk">而不是云 shell 上运行的命令。但是在运行它们之前，您需要将 google cloud SDK 安装到您的机器上，并为您当前的项目进行设置:</strong></p><pre class="lv lw lx ly gt nx ny nz oa aw ob bi"><span id="d4ef" class="mw mx jj ny b gy oc od l oe of">sudo snap install google-cloud-sdk --classic</span><span id="4815" class="mw mx jj ny b gy og od l oe of"># This Below command will open the browser where you can authenticate by selecting your own google account.<br/>gcloud auth login</span><span id="252b" class="mw mx jj ny b gy og od l oe of"># Set up the project as sparkdataproc (project ID)<br/>gcloud config set project sparkdataproc</span></pre><p id="171b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">完成后，我们可以简单地运行第一个命令:</p><pre class="lv lw lx ly gt nx ny nz oa aw ob bi"><span id="550b" class="mw mx jj ny b gy oc od l oe of">gcloud compute ssh sparktestcluster-m --project=sparkdataproc  --zone=us-central1-b -- -D 1080 -N</span></pre><p id="c960" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后在另一个标签/窗口中显示第二个。这个命令将打开一个新的 chrome 窗口，你可以像以前一样点击 Application Master 来访问 Spark UI。</p><pre class="lv lw lx ly gt nx ny nz oa aw ob bi"><span id="977a" class="mw mx jj ny b gy oc od l oe of">/usr/bin/google-chrome --proxy-server="socks5://localhost:1080"   --user-data-dir="/tmp/sparktestcluster-m" <a class="ae jg" href="http://sparktestcluster-m:8088" rel="noopener ugc nofollow" target="_blank">http://sparktestcluster-m:8088</a></span></pre></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><p id="1c28" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这就是设置由 GPU 加速的 Spark3.0 集群的全部内容。</p><p id="8b43" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果不算调试时间和配额增加请求，我花了大约 30 分钟来完成所有这些步骤。</p><p id="f318" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我完全被在 Spark 上使用 GPU 的概念和它开启的不同实验流所震惊。在接下来的几周里，我会做很多这样的工作，不仅是为了基准测试，也是因为它很有趣。敬请关注。</p></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="90c2" class="pf mx jj bd my pg ph pi nb pj pk pl ne kp pm kq nh ks pn kt nk kv po kw nn pp bi translated">继续学习</h1><p id="2156" class="pw-post-body-paragraph ky kz jj la b lb np kk ld le nq kn lg lh nr lj lk ll ns ln lo lp nt lr ls lt im bi translated">此外，如果你想了解更多关于 Spark 和 Spark DataFrames 的知识，我想在 Coursera 上调出 Yandex 关于<a class="ae jg" href="https://click.linksynergy.com/link?id=lVarvwc5BD0&amp;offerid=467035.11468293556&amp;type=2&amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Fbig-data-essentials" rel="noopener ugc nofollow" target="_blank">大数据基础知识的精彩课程:HDFS、MapReduce 和 Spark RDD </a>和<a class="ae jg" href="https://click.linksynergy.com/link?id=lVarvwc5BD0&amp;offerid=467035.11468293488&amp;type=2&amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Fbig-data-analysis" rel="noopener ugc nofollow" target="_blank">大数据分析:Hive、Spark SQL、DataFrames 和 GraphFrames </a>。</p><p id="c76d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我以后也会写更多这样的帖子。让我知道你对他们的看法。在<a class="ae jg" href="https://medium.com/@rahul_agarwal" rel="noopener"> <strong class="la jk">媒体</strong> </a>关注我，或者订阅我的<a class="ae jg" href="http://eepurl.com/dbQnuX" rel="noopener ugc nofollow" target="_blank"> <strong class="la jk">博客</strong> </a>了解他们。一如既往，我欢迎反馈和建设性的批评，可以通过 Twitter <a class="ae jg" href="https://twitter.com/MLWhiz" rel="noopener ugc nofollow" target="_blank"> @mlwhiz </a>联系到我。</p></div></div>    
</body>
</html>