<html>
<head>
<title>Pipeline-Oriented Data Analytics with Spark ML. Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Spark ML进行面向管道的数据分析。第二部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pipeline-oriented-data-analytics-with-spark-ml-part-2-3088d7a3c1b5?source=collection_archive---------26-----------------------#2020-02-24">https://towardsdatascience.com/pipeline-oriented-data-analytics-with-spark-ml-part-2-3088d7a3c1b5?source=collection_archive---------26-----------------------#2020-02-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/bacfb6e1484ac421d8fb4b50a7963e86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Wb69sAC3SpFRXIyYsbJrA.png"/></div></div></figure><div class=""/><p id="aa7c" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们继续探索基于Spark ML的面向管道的方法，这在之前的<a class="ae kz" href="https://medium.com/@borys.biletskyy/pipeline-oriented-data-analytics-with-spark-ml-c664befe1c2d" rel="noopener">部分</a>中有简要介绍。作为一个玩具示例，我们继续使用Kaggle <a class="ae kz" href="https://www.kaggle.com/c/nyc-taxi-trip-duration/" rel="noopener ugc nofollow" target="_blank">挑战</a>，其目标是根据接送时间、接送地理坐标、乘客数量和其他一些输入来预测出租车行程持续时间。我们的目标是在toy ( <a class="ae kz" href="https://github.com/bbiletskyy/pipeline-oriented-analytics" rel="noopener ugc nofollow" target="_blank"> github </a>)项目上展示ML管道如何通过使用数量有限的生产就绪构建模块来提高机器学习工作流的效率，这些模块足够灵活，可以由不同的工作流参与者在不同的工作流阶段应用。</p><p id="3dcd" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在我们继续之前，让我们回忆一下什么是面向管道的方法。</p><h2 id="726d" class="la lb je bd lc ld le dn lf lg lh dp li km lj lk ll kq lm ln lo ku lp lq lr ls bi translated">面向管道的数据分析</h2><p id="416e" class="pw-post-body-paragraph kb kc je kd b ke lt kg kh ki lu kk kl km lv ko kp kq lw ks kt ku lx kw kx ky im bi translated">像OOP中的对象或FP中的函数一样，管道阶段是面向管道范例的核心元素。这种范式基于两个基本原则，一个是介绍构建模块，另一个是定义构建模块的方式，这些原则是:</p><figure class="lz ma mb mc gt iv gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/39d2d53c67ba80a3049e3ee02ff65f23.png" data-original-src="https://miro.medium.com/v2/resize:fit:516/format:webp/1*oJR_2380ryfr5bf24IGOCg.png"/></div></figure><figure class="lz ma mb mc gt iv gh gi paragraph-image"><div class="gh gi md"><img src="../Images/551e3417081810581ba39b9300c52049.png" data-original-src="https://miro.medium.com/v2/resize:fit:650/format:webp/1*zHptYgV7QaXh6y5SB_D_4Q.png"/></div></figure><ol class=""><li id="2878" class="me mf je kd b ke kf ki kj km mg kq mh ku mi ky mj mk ml mm bi translated">数据操作用两种流水线阶段来描述:<strong class="kd jf"> <em class="mn">变换器</em> </strong>将数据映射到数据，以及<strong class="kd jf"> <em class="mn">估计器</em> </strong>将数据映射到<em class="mn">变换器</em>；</li><li id="ed6a" class="me mf je kd b ke mo ki mp km mq kq mr ku ms ky mj mk ml mm bi translated">管道阶段可以链接成管道，管道也是管道阶段。</li></ol><p id="fbfe" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">正如我们将看到的，这种简单的方法可以非常有表现力地描述模型生命周期各个阶段的数据操作。</p><h2 id="aef6" class="la lb je bd lc ld le dn lf lg lh dp li km lj lk ll kq lm ln lo ku lp lq lr ls bi translated"><strong class="ak">用ML流水线进行数据预处理</strong>。</h2><p id="9fba" class="pw-post-body-paragraph kb kc je kd b ke lt kg kh ki lu kk kl km lv ko kp kq lw ks kt ku lx kw kx ky im bi translated">在简介<a class="ae kz" href="https://medium.com/@borys.biletskyy/pipeline-oriented-data-analytics-with-spark-ml-c664befe1c2d" rel="noopener">部分</a>中，我们展示了当我们必须构建距离矩阵时，如何在数据预处理阶段使用ML管道。这个距离矩阵应该用于快速行程距离查找，以避免昂贵的调用非本地的Spark外部的<a class="ae kz" href="https://s2sphere.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> s2sphere </a>库。</p><p id="ae3f" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在让我们看看如何在数据预处理期间使用ML管道从距离矩阵中查找行程距离(完整的示例可在此处<a class="ae kz" href="https://github.com/bbiletskyy/pipeline-oriented-analytics/blob/master/src/pipeline_oriented_analytics/script/pre_process.py" rel="noopener ugc nofollow" target="_blank">获得</a>)。</p><figure class="lz ma mb mc gt iv"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="0d76" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这里，首先，我们选择、重命名和归一化输入数据框的列，该数据框是从csv文件加载的。然后，我们添加具有14级拾取和放下单元标记的列(级别越高，单元的面积越小)。之后，生成的像元令牌用于将输入数据框与距离矩阵连接起来，距离矩阵存储在拼花文件中。最后，我们删除一些列，并将结果保存到parquet文件中。</p><p id="9fcd" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如您所见，我们在之前的<a class="ae kz" rel="noopener" target="_blank" href="/pipeline-oriented-data-analytics-with-spark-ml-c664befe1c2d">部分</a>的矩阵生成示例中所熟悉的相同变压器被反复使用。通过重复使用变压器，我们的管道变得更加安全，因为我们使用经过测试、记录在案且可投入生产的组件。</p><h2 id="3d74" class="la lb je bd lc ld le dn lf lg lh dp li km lj lk ll kq lm ln lo ku lp lq lr ls bi translated">面向管道方法的一些应用</h2><p id="5866" class="pw-post-body-paragraph kb kc je kd b ke lt kg kh ki lu kk kl km lv ko kp kq lw ks kt ku lx kw kx ky im bi translated">在我们的例子中，我们展示了ML管道的各种应用。其中一些在之前的<a class="ae kz" rel="noopener" target="_blank" href="/pipeline-oriented-data-analytics-with-spark-ml-c664befe1c2d">部分</a>已经讨论过了。让我们简要地突出它们。</p><p id="35c5" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">数据帧扩展。</strong>面向管道的方法基于一些参与者(数据帧、管道和管道阶段)，我们不想通过添加更多参与者来使该模型变得复杂。因此一些重要的操作被实现为<code class="fe mv mw mx my b">pyspark.sql.DatFrame</code>的扩展。其中:<code class="fe mv mw mx my b">CsvDataFrame</code> —从csv文件中加载数据，<code class="fe mv mw mx my b">ParquetDataFrame</code> —从parquet文件中加载数据，<code class="fe mv mw mx my b">TempViewDataFrame</code> —使用临时视图(下面将详细介绍)。</p><p id="059f" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">日志记录、监控和其他副作用</strong>。具有副作用的ML管道在之前的<a class="ae kz" rel="noopener" target="_blank" href="/pipeline-oriented-data-analytics-with-spark-ml-c664befe1c2d">部分</a>中已经讨论过，以及一些关于其使用的问题。然而，当包装在身份转换器中时，各种副作用会非常有用。其中包括:持久性、日志记录、监控、数据验证、重新分区、检查点、缓存等。在正常情况下，它们中的每一个都会中断管道流，但是，作为管道阶段，它们自然可以用在ML管道中。在我们的例子中，我们使用<code class="fe mv mw mx my b">SaveToParquet</code>转换器来保存数据帧。</p><p id="78f7" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">超越线性</strong>。根据定义，ML流水线是线性的，流水线阶段只接受一个输入数据帧，并且只产生一个结果数据帧或变换器。在我们的例子中，通过使用数据帧作为构造函数参数，我们能够在一个单独的转换器中组合几个数据帧(一些问题在之前的<a class="ae kz" rel="noopener" target="_blank" href="/pipeline-oriented-data-analytics-with-spark-ml-c664befe1c2d">部分</a>中已经讨论过)。我们之前用的<code class="fe mv mw mx my b">Union</code>和<code class="fe mv mw mx my b">Join</code>变压器就是那种变压器。</p><p id="2a93" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">使用ML管道进行数据探索</strong>。我们看到了如何在数据预处理过程中使用面向管道的方法。尽管如此，没有什么能阻止我们在Jupyter笔记本的数据探索中使用相同的想法(这里有一些例子<a class="ae kz" href="https://github.com/bbiletskyy/pipeline-oriented-analytics/blob/master/notebooks/pre_processing.ipynb" rel="noopener ugc nofollow" target="_blank"/>)。经过大量的聚合计算后，spark数据帧可以转换为pandas数据帧，以便进一步可视化和分析。数据概要分析就是这样一种用例，尤其是在对新数据源重复执行大量标准数据质量检查时。我们可以想象变压器将数据帧映射到标准数据质量报告。它可能看起来像这样:</p><pre class="lz ma mb mc gt mz my na nb aw nc bi"><span id="a6e7" class="la lb je my b gy nd ne l nf ng">MissingValuesReport().transform(ParquetDataFrame(path, spark)) \<br/>    .toPandas().set_index(index_col).plot()</span></pre><p id="81de" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在，让我们考虑一些面向管道方法的新用例，我们还没有遇到过。</p><h2 id="7bb5" class="la lb je bd lc ld le dn lf lg lh dp li km lj lk ll kq lm ln lo ku lp lq lr ls bi translated">条件ML管道</h2><p id="59ba" class="pw-post-body-paragraph kb kc je kd b ke lt kg kh ki lu kk kl km lv ko kp kq lw ks kt ku lx kw kx ky im bi translated">有时我们不得不中断管道的自然、逻辑流程，因为我们需要在一个<em class="mn"> if-then-else </em>子句中检查某些条件。例如，机器学习有两个主要阶段:训练和预测。通常，相关的数据操作非常相似，但不完全相同。因此，将训练和预测管道放在一起以保持它们同步并避免代码重复是很方便的。</p><p id="a229" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">让我们考虑由三个步骤组成的特征提取流程:1)特征提取；2)标签提取(应该仅在训练期间发生，因为标签在预测期间不可用)；3)清理并保存。</p><p id="4c34" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在这种情况下，ML管道有助于减少代码重复。让我们首先考虑一种简单的方法，其中我们定义了对应于上述三个步骤的三个管道。稍后，当组装火车或预测主要特征工程管线的版本时，这些管线被用作管线阶段。如果标签列不可用，则在预测过程中装配特征工程管线时会省略标签提取管线。</p><figure class="lz ma mb mc gt iv"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="0bca" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">由于管道嵌套，我们设法减少了代码重复。然而，与此同时，特征工程流程的自然逻辑被分成三部分，这使得流水线定义不太容易理解。此外，一旦训练流和预测流被分离，我们需要额外注意在每次改变它们中的任何一个时保持它们的同步。</p><p id="2f54" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们能在不中断管道流的情况下达到同样的结果吗？下面的例子展示了如何在面向管道的方法中实现一个<em class="mn"> if-then-else </em>子句，并将其用于特性工程(完整的<a class="ae kz" href="https://github.com/bbiletskyy/pipeline-oriented-analytics/blob/master/src/pipeline_oriented_analytics/script/extract_features.py" rel="noopener ugc nofollow" target="_blank">例子</a>)。</p><figure class="lz ma mb mc gt iv"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="fb1b" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这里的<code class="fe mv mw mx my b"><a class="ae kz" href="https://github.com/bbiletskyy/pipeline-oriented-analytics/blob/master/src/pipeline_oriented_analytics/pipe/IF.py" rel="noopener ugc nofollow" target="_blank">IF</a></code>是一种特殊类型的流水线，在这里根据条件执行转换。条件被定义为谓词，<code class="fe mv mw mx my b"><a class="ae kz" href="https://github.com/bbiletskyy/pipeline-oriented-analytics/blob/master/src/pipeline_oriented_analytics/pipe/IF.py" rel="noopener ugc nofollow" target="_blank">IF</a> </code>接受它作为构造函数的参数。它可以是任何类型的<code class="fe mv mw mx my b">Callable[[DataFrame], bool]</code>谓词，在我们的例子中,<code class="fe mv mw mx my b">in_train_phase</code>谓词检查流程是否处于训练阶段。与前一种情况类似，这是通过检查输入数据框列中是否存在标签列<code class="fe mv mw mx my b">duration_sec</code>来实现的:</p><pre class="lz ma mb mc gt mz my na nb aw nc bi"><span id="7043" class="la lb je my b gy nd ne l nf ng">def in_training_phase(df: DataFrame) -&gt; bool:<br/>    return 'duration_sec' in df.columns</span></pre><p id="59cc" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">基于<code class="fe mv mw mx my b">IF</code>管道的实现看起来可读性更好，也更容易维护。完整的管道流是可见的，这使得管道定义更容易理解。训练流和预测流放在一起，这有助于保持它们的同步。</p><h2 id="b2af" class="la lb je bd lc ld le dn lf lg lh dp li km lj lk ll kq lm ln lo ku lp lq lr ls bi translated">作为管道变量的数据帧</h2><p id="e2b8" class="pw-post-body-paragraph kb kc je kd b ke lt kg kh ki lu kk kl km lv ko kp kq lw ks kt ku lx kw kx ky im bi translated">在某些情况下，我们需要将一个数据框与其先前的版本连接起来，只需进行几次变换。通常，这是通过引入临时变量来存储数据帧快照来实现的。但随之而来的是打破原有管道自然流动的代价。</p><p id="6be3" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">上面特性工程管道中的<code class="fe mv mw mx my b">RequestCount</code>变压器就是这样一个例子。这个转换器的目的是添加一个列，其中包含某个时间段内某个单元中的出租车请求数。让我们首先考虑一个简单的实现，其中对应的<code class="fe mv mw mx my b">_transform</code>方法如下所示。</p><figure class="lz ma mb mc gt iv"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="1701" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在这里，我们创建了几个临时的时间相关列，这些列稍后将与单元标记列一起用于分组和连接。然后，使用聚合进行分组，以计算请求数。最后，在连接中间结果之后，删除临时列。</p><p id="2999" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如果转换器添加新列而不更改现有列中的数据，则链接转换器很容易。在使用聚合进行分组的情况下，情况并非如此，因为此类操作会显著改变原始数据框的结构。</p><p id="5c9e" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">下面的例子展示了实现<code class="fe mv mw mx my b">RequestCount</code>转换器的另一种面向管道的方法。它利用Spark的临时视图来存储数据帧快照，而不是使用数据帧变量(完整的<a class="ae kz" href="https://github.com/bbiletskyy/pipeline-oriented-analytics/blob/master/src/pipeline_oriented_analytics/transformer/feature/request_count.py" rel="noopener ugc nofollow" target="_blank">示例</a>)。</p><figure class="lz ma mb mc gt iv"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="bf9c" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><code class="fe mv mw mx my b">SaveToTempView</code>副作用关联转换器将数据帧保存为Spark会话的临时视图。一种特殊类型的数据帧<code class="fe mv mw mx my b">TempViewDataFrame</code>用于从临时视图中访问数据。临时视图被另一个副作用关联变压器<code class="fe mv mw mx my b">DropTempView</code>丢弃。</p><p id="e414" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">面向管道的实现更易于维护，因为它是基于经过测试、有文档记录和生产就绪的构建块。</p><h2 id="607c" class="la lb je bd lc ld le dn lf lg lh dp li km lj lk ll kq lm ln lo ku lp lq lr ls bi translated"><strong class="ak">ML管道中的循环</strong></h2><p id="d6be" class="pw-post-body-paragraph kb kc je kd b ke lt kg kh ki lu kk kl km lv ko kp kq lw ks kt ku lx kw kx ky im bi translated">我没有机会将这个想法付诸实践，但是循环加上条件语句和管道变量为我们提供了一个非常强大的计算模型。这个模型应该有足够的表达能力来描述机器学习算法中的数据转换。机器学习方法常用作黑箱；抽象出了它们的实现细节。使用ML管道描述模型训练过程的数据操作将是很好的；这将使我们能够更容易地建立定制的机器学习方法，并为我们提供一个统一的形式，可以在机器学习工作流程的所有阶段使用。</p><h2 id="ed54" class="la lb je bd lc ld le dn lf lg lh dp li km lj lk ll kq lm ln lo ku lp lq lr ls bi translated"><strong class="ak">结论</strong></h2><p id="be51" class="pw-post-body-paragraph kb kc je kd b ke lt kg kh ki lu kk kl km lv ko kp kq lw ks kt ku lx kw kx ky im bi translated">我们在ML工作流程的不同阶段看到了面向管道方法的各种应用。这种方法通过提供一种组织、测试和维护相关数据操作的策略，可以使ML工作流开发更加有效。这对于共享公共业务领域的项目尤其有益，在这些领域中重用定制的特定于领域的管道阶段的机会更高。</p><h2 id="9245" class="la lb je bd lc ld le dn lf lg lh dp li km lj lk ll kq lm ln lo ku lp lq lr ls bi translated">参考</h2><p id="d0f2" class="pw-post-body-paragraph kb kc je kd b ke lt kg kh ki lu kk kl km lv ko kp kq lw ks kt ku lx kw kx ky im bi translated">[1] <a class="ae kz" href="https://spark.apache.org/docs/latest/ml-pipeline.html" rel="noopener ugc nofollow" target="_blank"> Spark ML管道文件</a></p><p id="a088" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">[2] Holder Karau，<a class="ae kz" href="https://www.youtube.com/watch?v=n8lIqL8w1fg" rel="noopener ugc nofollow" target="_blank">为定制车型扩展Spark ML</a>(2017)</p></div></div>    
</body>
</html>