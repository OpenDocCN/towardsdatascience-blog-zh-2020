<html>
<head>
<title>Convolutional Neural Networks’ mathematics</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络的数学</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/convolutional-neural-networks-mathematics-1beb3e6447c0?source=collection_archive---------3-----------------------#2020-02-24">https://towardsdatascience.com/convolutional-neural-networks-mathematics-1beb3e6447c0?source=collection_archive---------3-----------------------#2020-02-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/7c1b05c824ae620029bf57c6ac4ac02e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XfBJ8NEwSB_zW8Up1V71mQ.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">米盖尔·Á的照片。帕德里纳来自<a class="ae jg" href="https://www.pexels.com/fr-fr/photo/carre-cerveau-colore-couleur-19677/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">派克斯</a></p></figure><div class=""/><div class=""><h2 id="aa2d" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">卷积神经网络-第1部分:深入探究CNN的基本原理。</h2></div><p id="900a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">计算机视觉是深度学习的一个子领域，它处理所有尺度的图像。它允许计算机通过自动过程处理和理解大量图片的内容。<br/>计算机视觉背后的主要架构是卷积神经网络，它是前馈神经网络的衍生物。它的应用非常广泛，例如图像分类、物体检测、神经类型转移、人脸识别……如果你没有深度学习的一般背景，我建议你先阅读我关于前馈神经网络的<a class="ae jg" href="https://medium.com/swlh/deep-learnings-mathematics-f52b3c4d2576" rel="noopener">帖子</a>。</p><p id="3245" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">注意:因为Medium不支持LaTeX，所以数学表达式是作为图像插入的。因此，为了更好的阅读体验，我建议你关闭黑暗模式。</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="0d0f" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">目录</h1><blockquote class="mt mu mv"><p id="6507" class="ky kz mw la b lb lc kk ld le lf kn lg mx li lj lk my lm ln lo mz lq lr ls lt im bi translated"><em class="jj"> 1。过滤处理<br/> 2。定义<br/> 3。基础<br/> 4。训练CNN <br/> 5。常见架构</em></p></blockquote></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="095a" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated"><strong class="ak"> 1-过滤处理</strong></h1><p id="71de" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">图像的第一次处理是基于过滤器，例如，使用垂直边缘和水平边缘过滤器的组合来获得图像中对象的边缘。<br/>从数学上讲，垂直边缘滤波器，VEF，如果定义如下:</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nf"><img src="../Images/f15dad940e9bf732286077213fb89b19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k_aLLM_1_Uwz6Aq1ttsbUA.png"/></div></div></figure><p id="fc5c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其中HEF代表水平边缘滤波器。</p><p id="63fe" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了简单起见，我们考虑灰度6×6图像A，这是一个2D矩阵，其中每个元素的值表示相应像素中的光量。<br/>为了从该图像中提取垂直边缘，我们执行一个<strong class="la jk">卷积乘积(⋆) </strong>，它基本上是每个块中元素乘积的总和<strong class="la jk">:</strong></p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nk"><img src="../Images/a28e4712de559827b795bb119dc6f93a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CKFWAxDyPKjJBzzQTKVqYw.png"/></div></div></figure><p id="be6a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们对图像的第一个3x3块执行元素乘法，然后我们考虑右边的下一个块，并做同样的事情，直到我们覆盖了所有潜在的块。</p><p id="6701" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以把以下过程归纳为:</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nl"><img src="../Images/88e022b5d6b3a375f83b3ce112cbba36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RSlV8HIboZ99qUrHRpCUQQ.png"/></div></div></figure><p id="5e7b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">给定这个例子，我们可以考虑对<code class="fe nm nn no np b">any objective</code>使用相同的过程，其中<code class="fe nm nn no np b">filter is learned</code>由<code class="fe nm nn no np b">neural network</code>执行，如下所示:</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nf"><img src="../Images/9ac2b23258866ee6de41d88e13ab7e9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WfnfIUIo6uocAwDjupwLOQ.png"/></div></div></figure><p id="9cb3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">主要的直觉是设置一个<a class="ae jg" href="https://medium.com/swlh/deep-learnings-mathematics-f52b3c4d2576" rel="noopener">神经网络</a>，将图像作为输入，输出一个定义好的目标。使用<a class="ae jg" href="https://medium.com/swlh/deep-learnings-mathematics-f52b3c4d2576" rel="noopener">反向传播</a>学习参数。</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="caad" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">2-定义</h1><p id="f04a" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">卷积神经网络是一系列卷积和汇集层，允许从图像中提取最符合最终目标的主要特征。</p><p id="5aba" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在下一节中，我们将详细介绍每一块砖及其数学方程。</p><h2 id="4b3a" class="nq mc jj bd md nr ns dn mh nt nu dp ml lh nv nw mn ll nx ny mp lp nz oa mr ob bi translated">卷积乘积</h2><p id="8c7f" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">在我们明确定义卷积积之前，我们将首先定义一些基本操作，如填充和步长。</p><p id="b94a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">填充</strong></p><p id="5750" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如我们在使用垂直边缘滤波器的卷积产品中看到的那样，图像角落的像素(2D矩阵)比图像中间的像素使用得少，这意味着边缘的信息被丢弃了。<br/>为了解决这个问题，我们经常在图像周围添加填充，以便考虑边缘上的像素。按照惯例，我们用<code class="fe nm nn no np b">zeros</code>表示<code class="fe nm nn no np b">padde</code>，用<code class="fe nm nn no np b">p</code>表示填充参数，该参数表示添加到图像四个边中的每一个边上的元素数量。<br/>下图说明了灰度图像(2D矩阵)的填充，其中<code class="fe nm nn no np b">p=1</code>:</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oc"><img src="../Images/206325e29a20718f8af4fdaa91ff361c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9reDuDh3nXs_kJ-M4eq0Ow.png"/></div></div></figure><p id="9d3f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">跨步</strong></p><p id="8ff1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">跨距是卷积乘积中的步长。大的步幅允许缩小输出的大小，反之亦然。我们称步幅参数为<code class="fe nm nn no np b">s</code>。<br/>下图显示了带有<code class="fe nm nn no np b">s=1</code>的卷积乘积(每个块的逐元素总和):</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi od"><img src="../Images/7ac84eb1d4b963f5d97178022cd1d7c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g_RWc_Z5ws6fzdbrkOkOPw.png"/></div></div></figure><p id="ae5e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">卷积</strong></p><p id="231f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一旦我们定义了步幅和填充，我们就可以定义张量和滤波器之间的卷积积。<br/>在先前定义了2D矩阵上的卷积积(是<code class="fe nm nn no np b">element-wise product</code>的和)之后，我们现在可以正式定义体积上的卷积积。<br/>一般来说，图像在数学上可以表示为具有以下维度的张量:</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oe"><img src="../Images/d4600f9fae9e288a51aee79c1f7a9feb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ENwMvk5FdI1pJN7lZkoyKw.png"/></div></div></figure><p id="f184" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，在RGB图像的情况下，n_C=3，我们有红色、绿色和蓝色。按照惯例，我们认为滤波器<em class="mw"> K </em>为<code class="fe nm nn no np b">squared</code>并且具有表示为<em class="mw"> f，</em>的<code class="fe nm nn no np b">odd dimension</code>，这允许每个像素在滤波器中居中，从而考虑其周围的所有元素。<br/>当操作卷积乘积时，滤波器/内核<em class="mw"> K </em>必须将<code class="fe nm nn no np b">same number of channels</code>作为图像，这样我们对每个通道应用不同的滤波器。因此，过滤器的尺寸如下:</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nf"><img src="../Images/41358952458640a46ae438995355a643.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*katNKCrhEYuzOHnj3j7vHA.png"/></div></div></figure><p id="5daa" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">图像和过滤器之间的<code class="fe nm nn no np b">convolutional product</code>是一个<code class="fe nm nn no np b">2D matrix</code>，其中每个元素是立方体(过滤器)和给定图像的子立方体的元素乘法的<strong class="la jk">和，如下图所示:</strong></p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi of"><img src="../Images/25805138de8bda27578794b4a504ab97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oCW5sShGseY-VNw1IjGR3w.png"/></div></div></figure><p id="0e94" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从数学上来说，对于给定的图像和滤波器，我们有:</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi og"><img src="../Images/1cfe69fd147895459c90ec921597284f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wISYuY4fWaczdGIt6df0_Q.png"/></div></div></figure><p id="0c2d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">保持与之前相同的符号，我们有:</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oh"><img src="../Images/e3b7310a6ad44535914e14f43be3b44a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HTiiwBK3cYvNHotwoHw3pQ.png"/></div></div></figure><p id="a3e8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">统筹</strong></p><p id="60b4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">它是通过总结信息对图像的特征进行下采样的步骤。该操作通过每个通道执行，因此它只影响尺寸(n_H，n_W ),并保持n_C不变。<br/>给定一幅图像，我们滑动一个过滤器，用<code class="fe nm nn no np b">no parameters</code>来学习，按照一定的步幅，我们对选定的元素应用一个函数。我们有:</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oi"><img src="../Images/15b764538325e2515572363ecfb1c2f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RU8ziK15I5l3d4STcymZMw.png"/></div></div></figure><p id="3fe0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">按照惯例，我们考虑大小为<em class="mw"> f </em>的平方滤波器，我们通常设置<em class="mw"> f </em> =2，并考虑<em class="mw"> s </em> =2。</p><p id="1002" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们经常应用:</p><ul class=""><li id="6ca7" class="oj ok jj la b lb lc le lf lh ol ll om lp on lt oo op oq or bi translated"><code class="fe nm nn no np b">Average pooling</code>:我们对过滤器上的元素进行平均</li><li id="3798" class="oj ok jj la b lb os le ot lh ou ll ov lp ow lt oo op oq or bi translated"><code class="fe nm nn no np b">Max pooling</code>:给定过滤器中的所有元素，我们返回最大值</li></ul><p id="997b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面是一个平均池的例子:</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ox"><img src="../Images/e0ef4f988ad829f642f611a92e3e2dcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OL7kquQUgAaJmB11rxBcPg.png"/></div></div></figure></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="9b30" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">3-基础</h1><p id="10af" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">在这一节中，我们将结合上面定义的所有操作，逐层构建一个卷积神经网络。</p><h1 id="fd30" class="mb mc jj bd md me oy mg mh mi oz mk ml kp pa kq mn ks pb kt mp kv pc kw mr ms bi translated">CNN的一层</h1><p id="da93" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">卷积神经网络的每一层可以是:</p><ul class=""><li id="1e6b" class="oj ok jj la b lb lc le lf lh ol ll om lp on lt oo op oq or bi translated"><code class="fe nm nn no np b">Convolutional layer -CONV-</code>后面跟着一个<code class="fe nm nn no np b">activation function</code></li><li id="5fc4" class="oj ok jj la b lb os le ot lh ou ll ov lp ow lt oo op oq or bi translated"><code class="fe nm nn no np b">Pooling layer -POOL-</code>如上详述</li><li id="72c9" class="oj ok jj la b lb os le ot lh ou ll ov lp ow lt oo op oq or bi translated"><code class="fe nm nn no np b">Fully connected layer -FC-</code>基本上类似于前馈神经网络的层，</li></ul><p id="c2c8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可以在我之前的<a class="ae jg" href="https://medium.com/swlh/deep-learnings-mathematics-f52b3c4d2576" rel="noopener">帖子</a>中看到更多关于激活功能和完全连接层的细节。</p><h2 id="d949" class="nq mc jj bd md nr ns dn mh nt nu dp ml lh nv nw mn ll nx ny mp lp nz oa mr ob bi translated">卷积层</h2><p id="9bfd" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">正如我们之前看到的，在卷积层，我们对输入应用卷积乘积<strong class="la jk"> s </strong>，这次使用了许多滤波器，然后是激活函数ψ。</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pd"><img src="../Images/0dc19ca2293c0dd2c0f2174b237d262e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LoOgiq0flCTTePEGcfttyA.png"/></div></div></figure><p id="fac5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以在下图中总结卷积层:</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pe"><img src="../Images/40e1a0bae441fcfe315ead776d5f67b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yld1twhx2-RRir7oPafbTw.png"/></div></div></figure><h2 id="e01d" class="nq mc jj bd md nr ns dn mh nt nu dp ml lh nv nw mn ll nx ny mp lp nz oa mr ob bi translated">汇集层</h2><p id="7903" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">如前所述，池图层旨在对输入要素进行缩减采样，而不会影响通道的数量。<br/>我们考虑以下符号:</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pf"><img src="../Images/83f68357a31d11a3669232929be12e8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NHdmP6zSimB9A47-glxySQ.png"/></div></div></figure><p id="85b4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以断言:</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nf"><img src="../Images/c4936fb5a44989b2ff51929711f87db3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tRgFrYa59MBL4scrHHeYtw.png"/></div></div></figure><p id="0f8d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">池层有<code class="fe nm nn no np b">no parameters</code>要学习。</p><p id="c8d4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们在下图中总结了前面的操作:</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pg"><img src="../Images/89770bec6b4fb7280a5a54d23203e124.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3AYOdJJ6aNVuj7sGzFPbzw.png"/></div></div></figure><h2 id="5921" class="nq mc jj bd md nr ns dn mh nt nu dp ml lh nv nw mn ll nx ny mp lp nz oa mr ob bi translated">全连接层</h2><p id="2f8b" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">全连接层是有限数量的神经元，它接受一个向量的输入，并返回另一个向量。</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ph"><img src="../Images/5bb20da5813e06ef879159363364c51e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lgAm_8L7f2ve3E41S6V42A.png"/></div></div></figure><p id="d800" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们在下图中总结了完全连接的层:</p><p id="b376" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">更多细节，你可以访问我的关于前馈神经网络的<a class="ae jg" href="https://www.ismailmebsout.com/deep-learning/" rel="noopener ugc nofollow" target="_blank"> p </a>上一篇<a class="ae jg" href="https://medium.com/swlh/deep-learnings-mathematics-f52b3c4d2576" rel="noopener">文章</a>。</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pi"><img src="../Images/27997cc1e51431f7c2a57355f22a1a83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bOsh19eTl3kI6aRMoezURw.png"/></div></div></figure><h2 id="5771" class="nq mc jj bd md nr ns dn mh nt nu dp ml lh nv nw mn ll nx ny mp lp nz oa mr ob bi translated">CNN总的来说</h2><p id="9c42" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">一般来说，卷积神经网络是上述所有操作的系列，如下所示:</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pj"><img src="../Images/086ff21277ae596ba3b757fab8b64823.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uSQdT2LwPWzIXBdlHnJVMg.png"/></div></div></figure><p id="0172" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在激活函数之后重复一系列卷积之后，我们应用一个池并重复这个过程一定次数。这些操作允许从将被<code class="fe nm nn no np b">fed</code>的图像<code class="fe nm nn no np b">extract features</code>到由完全连接的层描述的<code class="fe nm nn no np b">neural network</code>，该完全连接的层也有规律地被激活功能跟随。<br/>大意是通过网络更深入时<code class="fe nm nn no np b">decrease</code> n_H &amp; n_W和<code class="fe nm nn no np b">increase</code> n_C。<br/>在3D中，卷积神经网络具有以下形状:</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pk"><img src="../Images/158e2897550258064b5422c8ea193ff2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YejW73f36BGhNGhrtbz67g.png"/></div></div></figure><h2 id="1f61" class="nq mc jj bd md nr ns dn mh nt nu dp ml lh nv nw mn ll nx ny mp lp nz oa mr ob bi translated">CNN为什么工作效率高？</h2><p id="841c" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">卷积神经网络能够实现图像处理的最新成果有两个主要原因:</p><ul class=""><li id="4095" class="oj ok jj la b lb lc le lf lh ol ll om lp on lt oo op oq or bi translated"><strong class="la jk">参数共享</strong>:卷积层中的特征检测器在图像的一部分有用，在其他部分可能有用</li><li id="0399" class="oj ok jj la b lb os le ot lh ou ll ov lp ow lt oo op oq or bi translated"><strong class="la jk">连接的稀疏性</strong>:在每一层中，每个输出值只依赖于少量的输入</li></ul></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="22ee" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">4-培训CNN</h1><p id="20e2" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">卷积神经网络是在一组标记图像上训练的。从给定的图像开始，我们通过CNN的不同层传播它，并返回所寻找的输出。<br/>在本章中，我们将介绍学习算法以及数据扩充中使用的不同技术。</p><h2 id="6972" class="nq mc jj bd md nr ns dn mh nt nu dp ml lh nv nw mn ll nx ny mp lp nz oa mr ob bi translated">数据预处理</h2><p id="e2de" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated"><strong class="la jk">数据扩充</strong>是增加给定数据集中图像数量的步骤。数据扩充中使用了许多技术，例如:</p><ul class=""><li id="bafc" class="oj ok jj la b lb lc le lf lh ol ll om lp on lt oo op oq or bi translated"><code class="fe nm nn no np b">Crooping</code></li><li id="9f9e" class="oj ok jj la b lb os le ot lh ou ll ov lp ow lt oo op oq or bi translated"><code class="fe nm nn no np b">Rotation</code></li><li id="4a00" class="oj ok jj la b lb os le ot lh ou ll ov lp ow lt oo op oq or bi translated"><code class="fe nm nn no np b">Flipping</code></li><li id="7c25" class="oj ok jj la b lb os le ot lh ou ll ov lp ow lt oo op oq or bi translated"><code class="fe nm nn no np b">Noise injection</code></li><li id="6698" class="oj ok jj la b lb os le ot lh ou ll ov lp ow lt oo op oq or bi translated"><code class="fe nm nn no np b">Color space transformation</code></li></ul><p id="db32" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">由于训练集的规模较大，它启用了<code class="fe nm nn no np b">better learning</code>，并允许算法从所讨论的对象的不同<code class="fe nm nn no np b">conditions</code>中学习。<br/>一旦数据集准备好了，我们<strong class="la jk">就像任何机器学习项目一样把它分成三个部分:</strong></p><ul class=""><li id="f0a0" class="oj ok jj la b lb lc le lf lh ol ll om lp on lt oo op oq or bi translated"><strong class="la jk">训练集</strong>:用于训练算法和构造批次</li><li id="95ee" class="oj ok jj la b lb os le ot lh ou ll ov lp ow lt oo op oq or bi translated"><strong class="la jk"> Dev set </strong>:用于微调算法，评估偏差和方差</li><li id="ccaa" class="oj ok jj la b lb os le ot lh ou ll ov lp ow lt oo op oq or bi translated"><strong class="la jk">测试集</strong>:用于概括最终算法的误差/精度</li></ul><h2 id="554d" class="nq mc jj bd md nr ns dn mh nt nu dp ml lh nv nw mn ll nx ny mp lp nz oa mr ob bi translated">学习算法</h2><p id="4ba2" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">卷积神经网络是一种专门用于图像的特殊类型的神经网络。一般来说，神经网络中的学习是在几个层中计算上面定义的参数的权重的步骤。<br/>换句话说，我们的目标是从输入图像开始，找到给出真实值的最佳预测/近似的最佳参数。<br/>为此，我们定义了一个目标函数，称为<code class="fe nm nn no np b">loss function</code>，记为<code class="fe nm nn no np b">J</code>，它量化了整个训练集的实际值和预测值之间的距离。<br/>我们通过以下两个主要步骤最小化J:</p><ul class=""><li id="2e96" class="oj ok jj la b lb lc le lf lh ol ll om lp on lt oo op oq or bi translated"><code class="fe nm nn no np b"><strong class="la jk">Forward Propagation</strong></code>:我们通过网络整体或分批传播数据，并计算这批数据的损失函数，该函数只不过是不同行的预测输出中的误差之和。</li><li id="7a8f" class="oj ok jj la b lb os le ot lh ou ll ov lp ow lt oo op oq or bi translated"><code class="fe nm nn no np b"><strong class="la jk">Backpropagation</strong></code>:包括计算成本函数相对于不同参数的梯度，然后应用下降算法更新它们。</li></ul><p id="1c23" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们多次重复相同的过程，称为<code class="fe nm nn no np b">epoch number</code>。定义架构后，学习算法编写如下:</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pl"><img src="../Images/7919eb6842fbbd16f1b8a96f48bf7757.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1AmnF78RwOvdwH8zfxEhNQ.png"/></div></div></figure><p id="c35b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">(*)成本函数评估单点的实际值和预测值之间的距离。</p><p id="8d5c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">更多的细节，你可以访问我的<a class="ae jg" href="https://www.ismailmebsout.com/deep-learning/" rel="noopener ugc nofollow" target="_blank"> p </a>上一篇<a class="ae jg" href="https://medium.com/swlh/deep-learnings-mathematics-f52b3c4d2576" rel="noopener">关于前馈神经网络的文章</a>。</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="3d66" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">5-通用架构</h1><h2 id="9273" class="nq mc jj bd md nr ns dn mh nt nu dp ml lh nv nw mn ll nx ny mp lp nz oa mr ob bi translated">雷斯内特</h2><p id="606e" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">Resnet、捷径或跳过连接是一个卷积层，它在层<em class="mw"> n </em>处考虑了层<em class="mw"> n-2 </em>。直觉来自于这样一个事实:当神经网络变得非常深入时，输出端的精度变得非常稳定，不会增加。注入前一层的残差有助于解决这个问题。<br/>让我们考虑一个残差块，当<code class="fe nm nn no np b">skip connection</code>为<code class="fe nm nn no np b">off</code>时，我们有以下等式:</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pm"><img src="../Images/dc851708c4d0532080b8478981c25765.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jcQJrr1MLJ7wdzUvr38s6Q.png"/></div></div></figure><p id="5b22" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以在下图中对残差块进行求和:</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pf"><img src="../Images/e09d4d6ece660960d58ccc1a7a6c1d7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QgU9Kc-dvzH3NiOOU8jbIg.png"/></div></div></figure><h2 id="8e0e" class="nq mc jj bd md nr ns dn mh nt nu dp ml lh nv nw mn ll nx ny mp lp nz oa mr ob bi translated">初始网络</h2><p id="5d40" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">在设计卷积神经网络时，我们经常要选择层的类型:<code class="fe nm nn no np b">CONV</code>、<code class="fe nm nn no np b">POOL</code>或<code class="fe nm nn no np b">FC</code>。初始层完成了所有的工作。所有操作的结果然后是单个块中的<code class="fe nm nn no np b">concatenated</code>,其将是下一层的输入，如下:</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pn"><img src="../Images/0de66a92e53e90cadc3671da2f972881.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*65prBVhae_m1PqyjlVDVyA.png"/></div></div></figure><p id="7806" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">需要注意的是，初始层提出了<code class="fe nm nn no np b">computational cost</code>的问题。供参考，名字<code class="fe nm nn no np b">inception</code>来源于电影！</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="d967" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">结论</h1><p id="dafd" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">在本文的第一部分中，我们已经看到了从卷积产品、池化/全连接层到训练算法的CNN基础。</p><p id="f8c8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在<a class="ae jg" rel="noopener" target="_blank" href="/object-detection-face-recognition-algorithms-146fec385205">第二部分</a>中，我们将讨论图像处理中使用的一些最著名的架构。</p><p id="aef4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">不要犹豫，检查我以前的文章处理:</p><ul class=""><li id="e696" class="oj ok jj la b lb lc le lf lh ol ll om lp on lt oo op oq or bi translated"><a class="ae jg" href="https://medium.com/p/deep-learnings-mathematics-f52b3c4d2576" rel="noopener">深度学习的数学</a></li><li id="ac55" class="oj ok jj la b lb os le ot lh ou ll ov lp ow lt oo op oq or bi translated"><a class="ae jg" href="https://medium.com/p/object-detection-face-recognition-algorithms-146fec385205" rel="noopener">物体检测&amp;人脸识别算法</a></li><li id="a63c" class="oj ok jj la b lb os le ot lh ou ll ov lp ow lt oo op oq or bi translated"><a class="ae jg" rel="noopener" target="_blank" href="/recurrent-neural-networks-b7719b362c65">递归神经网络</a></li></ul></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="fb19" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">参考</h1><ul class=""><li id="6b81" class="oj ok jj la b lb na le nb lh po ll pp lp pq lt oo op oq or bi translated"><a class="ae jg" href="https://fr.coursera.org/specializations/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习专业化</a>，Coursera，吴恩达</li><li id="971d" class="oj ok jj la b lb os le ot lh ou ll ov lp ow lt oo op oq or bi translated"><a class="ae jg" href="http://deeploria.gforge.inria.fr/cours/cours1.html#/machine-learning-introduction" rel="noopener ugc nofollow" target="_blank">机器学习</a>，洛里亚，克里斯托夫·塞里萨拉</li></ul><p id="166c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="mw">原载于2020年2月24日</em><a class="ae jg" href="https://www.ismailmebsout.com/Convolutional%20Neural%20Network%20-%20Part%201/" rel="noopener ugc nofollow" target="_blank"><em class="mw">https://www.ismailmebsout.com</em></a><em class="mw">。</em></p></div></div>    
</body>
</html>