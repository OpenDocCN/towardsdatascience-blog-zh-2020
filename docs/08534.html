<html>
<head>
<title>How YOLOv5 solved an ambiguity encountered by YOLOv3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">YOLOv5 如何解决 YOLOv3 遇到的歧义</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/indian-car-license-plate-detection-using-yolo-v5-ae2574578175?source=collection_archive---------12-----------------------#2020-06-21">https://towardsdatascience.com/indian-car-license-plate-detection-using-yolo-v5-ae2574578175?source=collection_archive---------12-----------------------#2020-06-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="f519" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" rel="noopener" target="_blank" href="https://towardsdatascience.com/data-science-in-the-real-world/home?gi=ea0e55878a54">现实世界中的数据科学</a></h2><div class=""/><div class=""><h2 id="2b71" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">使用 YOLOv5 实现稳健的印度车牌检测</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/340638ce6662deb750ba2a0cd8034296.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/1*-1D-CabftTbQpm01cp3Dpg.gif"/></div><p class="kz la gj gh gi lb lc bd b be z dk translated">我对一般交通数据的结果</p></figure><p id="4a06" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">对那些可能不知道的人来说，一个新版本的 YOLO(你只看一次)在这里，即 YOLO v5。非常感谢<a class="ae lz" href="https://www.ultralytics.com/" rel="noopener ugc nofollow" target="_blank"> Ultralytics </a>将这个库放在一起。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi ma"><img src="../Images/1a1912464b01655459b58c262e686f43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4BQ2ZXPPHuGPrmExq5FGsg.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">来源:‘【https://github.com/ultralytics/yolov5】T4</p></figure><h2 id="79a8" class="mf mg it bd mh mi mj dn mk ml mm dp mn lm mo mp mq lq mr ms mt lu mu mv mw iz bi translated">YOLOv3 的问题是</h2><p id="4ab0" class="pw-post-body-paragraph ld le it lf b lg mx kd li lj my kg ll lm mz lo lp lq na ls lt lu nb lw lx ly im bi translated">你只看一次(YOLO)是一个最先进的，实时对象检测系统。在 Pascal Titan X 上，它以 30 FPS 的速度处理图像，在 COCO test-dev 上有 57.9%的 mAP。</p><p id="7cd2" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">YOLOv3 速度极快，精度极高。在 mAP 中，测得 5 IOU YOLOv3 与焦点损耗相当，但速度快 4 倍左右。此外，你可以简单地通过改变模型的大小在速度和准确性之间进行权衡，不需要重新训练！</p><p id="a1e7" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">YOLOv3 有一个问题，尽管如此精确，但它是有偏见的。偏向于图像中对象的大小。如果在训练时遇到较大的物体，它不能完美地检测到较小尺度的相同物体。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi nc"><img src="../Images/dd6afbe056457d5d30d0087ab4232cde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p0xn8H0tYRtSG6sKVUcpyw.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">由于该模型是为较大的车牌训练的，所以它不能在这个非常小的图像中正确地检测到小的车牌</p></figure><p id="d340" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">YOLOv3 检测图像中的特征，并学习如何利用这些信息识别物体。靠近起点的层检测非常简单的特征，如边缘，而更深的层可以检测更复杂的特征，如眼睛、鼻子或整张脸。然后，它使用所有这些它已经学会的特征，做出最终的预测。这就是该系统的缺陷所在——没有在 CNN 中任何地方使用的空间，并且用于连接层的汇集功能效率低下。</p><p id="4ba2" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd"> YOLOv5 </strong></p><p id="aee5" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">YOLOv5 由三部分组成:</p><ol class=""><li id="90bb" class="nd ne it lf b lg lh lj lk lm nf lq ng lu nh ly ni nj nk nl bi translated">模型主干</li><li id="067d" class="nd ne it lf b lg nm lj nn lm no lq np lu nq ly ni nj nk nl bi translated">模型头</li><li id="0e5f" class="nd ne it lf b lg nm lj nn lm no lq np lu nq ly ni nj nk nl bi translated">模特脖子</li></ol><p id="0454" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">模型头部有助于特征提取过程。模型主干由 CSP 网络组成，有助于从通过模型头部的张量中提取基本特征。CSPNets 也支持更快的推理。来自模型主干的张量通过具有特征金字塔的模型颈部，该特征金字塔试图消除相对于对象大小的偏差。</p><p id="c638" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">要了解有关要素金字塔的更多信息，请查看</p><div class="nr ns gp gr nt nu"><a href="https://arxiv.org/abs/1612.03144" rel="noopener  ugc nofollow" target="_blank"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd jd gy z fp nz fr fs oa fu fw jc bi translated">用于目标检测的特征金字塔网络</h2><div class="ob l"><h3 class="bd b gy z fp nz fr fs oa fu fw dk translated">特征金字塔是识别系统中的基本组件，用于检测不同尺度的对象。但是最近…</h3></div><div class="oc l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">arxiv.org</p></div></div></div></a></div><p id="0b3a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">要了解更多关于 YOLOv5 的信息，请查看这个。</p><div class="nr ns gp gr nt nu"><a href="https://blog.roboflow.ai/yolov5-is-here/" rel="noopener  ugc nofollow" target="_blank"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd jd gy z fp nz fr fs oa fu fw jc bi translated">YOLOv5 来了</h2><div class="ob l"><h3 class="bd b gy z fp nz fr fs oa fu fw dk translated">CDT 月 12 日上午 8:08 更新:为了回应社区反馈，我们写了一篇更详细的帖子，比较…</h3></div><div class="oc l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">blog.roboflow.ai</p></div></div><div class="od l"><div class="oe l of og oh od oi kx nu"/></div></div></a></div><p id="4c61" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">查看 YOLO 版本 5 库，网址为</p><div class="nr ns gp gr nt nu"><a href="https://github.com/ultralytics/yolov5" rel="noopener  ugc nofollow" target="_blank"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd jd gy z fp nz fr fs oa fu fw jc bi translated">ultralytics/yolov5</h2><div class="ob l"><h3 class="bd b gy z fp nz fr fs oa fu fw dk translated">这个资源库代表了 Ultralytics 对未来对象检测方法的开源研究，并结合了我们的…</h3></div><div class="oc l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">github.com</p></div></div><div class="od l"><div class="oj l of og oh od oi kx nu"/></div></div></a></div><p id="8107" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">对于我们的用例，我在</p><div class="nr ns gp gr nt nu"><a href="https://github.com/sid0312/anpr_yolov5" rel="noopener  ugc nofollow" target="_blank"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd jd gy z fp nz fr fs oa fu fw jc bi translated">sid0312/anpr_yolov5</h2><div class="ob l"><h3 class="bd b gy z fp nz fr fs oa fu fw dk translated">这个项目是一个后续项目，参考我们的数据准备在这个链接的培训，参考这个链接给…</h3></div><div class="oc l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">github.com</p></div></div><div class="od l"><div class="ok l of og oh od oi kx nu"/></div></div></a></div><h2 id="7ea2" class="mf mg it bd mh mi mj dn mk ml mm dp mn lm mo mp mq lq mr ms mt lu mu mv mw iz bi translated">克隆存储库</h2><pre class="ks kt ku kv gt ol om on oo aw op bi"><span id="2adc" class="mf mg it om b gy oq or l os ot">git clone <a class="ae lz" href="https://github.com/sid0312/anpr_yolov5" rel="noopener ugc nofollow" target="_blank">https://github.com/sid0312/anpr_yolov5</a><br/>cd anpr_yolov5</span></pre><h2 id="59b9" class="mf mg it bd mh mi mj dn mk ml mm dp mn lm mo mp mq lq mr ms mt lu mu mv mw iz bi translated">检测车牌</h2><p id="3ade" class="pw-post-body-paragraph ld le it lf b lg mx kd li lj my kg ll lm mz lo lp lq na ls lt lu nb lw lx ly im bi translated">要检测汽车图像中的车牌，请将其保存在目录的 sample_cars 文件夹中。把它命名为 example.jpg</p><pre class="ks kt ku kv gt ol om on oo aw op bi"><span id="8620" class="mf mg it om b gy oq or l os ot">python detect.py --source sample_cars/example.jpg  --weights weights/best.pt --conf 0.4</span></pre><h2 id="9350" class="mf mg it bd mh mi mj dn mk ml mm dp mn lm mo mp mq lq mr ms mt lu mu mv mw iz bi translated">结果</h2><p id="452a" class="pw-post-body-paragraph ld le it lf b lg mx kd li lj my kg ll lm mz lo lp lq na ls lt lu nb lw lx ly im bi translated">获取推理/输出目录中的最终图像。要获得检测过程的直觉，请查看以下笔记本</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ou ov l"/></div></figure><p id="841e" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">以下是一些结果</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi ow"><img src="../Images/ddf6196f289dec7624077adb63498cac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DZBtVdOu0NBXQBMAb6wnMw.jpeg"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">验证图像的批量预测</p></figure><h2 id="3847" class="mf mg it bd mh mi mj dn mk ml mm dp mn lm mo mp mq lq mr ms mt lu mu mv mw iz bi translated">我们注意到 YOLOv5 正确地检测到了车牌，而 YOLOv3 根本没有检测到车牌</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/ef89eb0b31feb51294acc61c5574f316.png" data-original-src="https://miro.medium.com/v2/resize:fit:386/format:webp/1*grFzjUOUQzrsubneD3N2mQ.png"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi oy"><img src="../Images/23e40b1c9d6d040f2b6c5ae5f47fbac0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FB7z1tHjjiEVaA3OGDGdgQ.jpeg"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">对测试样本图像的预测</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi oz"><img src="../Images/7e9947add34c73c9e9f2822bfd513180.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mwK36lxXwkqF-ETLza0rmw.jpeg"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">测试样本图像预测</p></figure><h1 id="bcdb" class="pa mg it bd mh pb pc pd mk pe pf pg mn ki ph kj mq kl pi km mt ko pj kp mw pk bi translated">我是怎么做到的？</h1><p id="bb4d" class="pw-post-body-paragraph ld le it lf b lg mx kd li lj my kg ll lm mz lo lp lq na ls lt lu nb lw lx ly im bi translated">该存储库包括对原始 utlralytics 存储库的以下更改</p><p id="0b0b" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">已创建数据/license_plate.yaml </strong></p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ou ov l"/></div></figure><p id="3896" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">数据准备</strong></p><ul class=""><li id="3060" class="nd ne it lf b lg lh lj lk lm nf lq ng lu nh ly pl nj nk nl bi translated">步骤 1-从以下网址下载 JSON 格式的初学者数据集</li></ul><div class="nr ns gp gr nt nu"><a href="https://www.kaggle.com/dataturks/vehicle-number-plate-detection" rel="noopener  ugc nofollow" target="_blank"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd jd gy z fp nz fr fs oa fu fw jc bi translated">车辆牌照检测</h2><div class="ob l"><h3 class="bd b gy z fp nz fr fs oa fu fw dk translated">标记在车辆牌照上的包围盒</h3></div><div class="oc l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">www.kaggle.com</p></div></div><div class="od l"><div class="pm l of og oh od oi kx nu"/></div></div></a></div><p id="ad8c" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这是我们的起始数据集。将 JSON 文件上传到您的 Google Drive</p><ul class=""><li id="9526" class="nd ne it lf b lg lh lj lk lm nf lq ng lu nh ly pl nj nk nl bi translated">步骤 2——将 JSON starter 数据集转换成 YOLO 格式</li></ul><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ou ov l"/></div></figure><p id="a3e1" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">以下存储库是使用 YOLO v3 Darknet 和 Pytesseract 对印度车牌进行的端到端检测和识别。它是我们项目的先驱。这是一个有趣的个人项目本身！</p><ul class=""><li id="f6df" class="nd ne it lf b lg lh lj lk lm nf lq ng lu nh ly pl nj nk nl bi translated">创建文件夹结构</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi pn"><img src="../Images/5df774247f73be273c1bd4fd0b68ec45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GcONnXpu6BNYwcnFqszE9w.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">存储库的数据文件夹</p></figure><ul class=""><li id="5c6c" class="nd ne it lf b lg lh lj lk lm nf lq ng lu nh ly pl nj nk nl bi translated">在数据/图像文件夹中，创建两个文件夹，即 train 和 valid</li><li id="48c1" class="nd ne it lf b lg nm lj nn lm no lq np lu nq ly pl nj nk nl bi translated">训练文件夹由从步骤 2 获得的 201 个图像组成。这些是用来训练的</li><li id="972d" class="nd ne it lf b lg nm lj nn lm no lq np lu nq ly pl nj nk nl bi translated">有效文件夹由步骤 2 中获得的 36 幅图像组成，用于验证</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi po"><img src="../Images/17b1f2f72570c355326558b56ab5e1b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7CKeHRjODPHHWSlk_nQhfg.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">我的数据/图像/训练文件夹的内容</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi pp"><img src="../Images/36efa23fdb19445e51fddc436eb1924a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZP6R0WIfGEe8kufWX88a-A.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">我的数据/图像/训练/有效文件夹的内容</p></figure><p id="6e83" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">只有图像不能用于检测，因为我们需要边界框的标签和每个图像的类。</p><p id="3462" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">单个类边界框标注的 YOLO 格式如下:</p><pre class="ks kt ku kv gt ol om on oo aw op bi"><span id="446b" class="mf mg it om b gy oq or l os ot">class_number x y width height</span></pre><p id="9ce0" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">标签已经从步骤 2 中获得。</p><p id="d8ab" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">标签文件夹由训练和有效文件夹组成，分别由训练和验证图像的标签组成。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi pq"><img src="../Images/6038b4402796fc06c8f81de6e1316805.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PoKX1CsiBGZE2BB3y4ticA.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">训练图像的标签</p></figure><p id="cba2" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">标签样本</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi pr"><img src="../Images/34102902a069a0a5a6f6d6c9ad602b00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CNUnf-Lu1qWeiQFpqD0ITQ.png"/></div></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi ps"><img src="../Images/009a56fcd3d73380fcf234b2d3b5cb72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XLU2d4MZ32ap8Wlq892fYQ.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">验证图像的标签</p></figure><p id="b192" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">接下来，我们创建 data/train.txt 文件</p><p id="8fa9" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">要获取该文件的内容，只需在命令提示符或终端中编写以下内容。确保您位于 anpr_yolov5 目录中</p><pre class="ks kt ku kv gt ol om on oo aw op bi"><span id="e596" class="mf mg it om b gy oq or l os ot">D:&gt;git clone <a class="ae lz" href="https://github.com/sid0312/anpr_yolov5" rel="noopener ugc nofollow" target="_blank">https://github.com/sid0312/anpr_yolov5</a><br/>cd anpr_yolov5<br/>python<br/>&gt;&gt;import os<br/>&gt;&gt;for image in os.list('data/images/train'):<br/>     path = 'D:/anpr_yolov5/data/images/train'<br/>     print(path+'/'+image)</span></pre><p id="50ad" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">您将获得以下输出</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pt"><img src="../Images/388ed62dbc903c4810de57335e88877f.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*qzTNaIjn5imzOycVjr067g.png"/></div></figure><p id="fe2b" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">将输出复制到文件 data/train.txt 中</p><p id="acae" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">对 valid.txt 进行同样的操作</p><p id="36a2" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如果您打算在 Google Colab 上训练 Yolo v5，提交当前状态的存储库，不要复制上面的内容。提交您的存储库的当前状态并将其推送到 GitHub。</p><pre class="ks kt ku kv gt ol om on oo aw op bi"><span id="ac30" class="mf mg it om b gy oq or l os ot">git add . <br/>git commit -m"some msg"<br/>git push</span></pre><p id="8c5f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">现在按照下面的笔记本，将打印日志的内容分别复制到 data/train.txt 和 data/val.txt 文件中</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ou ov l"/></div></figure><ul class=""><li id="302a" class="nd ne it lf b lg lh lj lk lm nf lq ng lu nh ly pl nj nk nl bi translated"><strong class="lf jd">将 yolov5s.yaml 中的 nc 参数改为 1 </strong></li><li id="9cb7" class="nd ne it lf b lg nm lj nn lm no lq np lu nq ly pl nj nk nl bi translated"><strong class="lf jd">再次重复 git 添加、提交、推送过程</strong></li><li id="0c51" class="nd ne it lf b lg nm lj nn lm no lq np lu nq ly pl nj nk nl bi translated"><strong class="lf jd">查看以下笔记本了解培训流程</strong></li></ul><div class="nr ns gp gr nt nu"><a href="https://github.com/sid0312/anpr_yolov5/blob/master/yolov5_license_plate_train.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd jd gy z fp nz fr fs oa fu fw jc bi translated">sid0312/anpr_yolov5</h2><div class="ob l"><h3 class="bd b gy z fp nz fr fs oa fu fw dk translated">permalink dissolve GitHub 是超过 5000 万开发人员的家园，他们一起工作来托管和审查代码，管理…</h3></div><div class="oc l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">github.com</p></div></div><div class="od l"><div class="pu l of og oh od oi kx nu"/></div></div></a></div><p id="3a7c" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">注意:也可以使用 yolo5s.pt 砝码。我使用了随机初始化的权重，并对模型进行了 100 个时期的训练。</strong></p><h2 id="686b" class="mf mg it bd mh mi mj dn mk ml mm dp mn lm mo mp mq lq mr ms mt lu mu mv mw iz bi translated">我的一些训练日志如下</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi pv"><img src="../Images/e311aa4c58596a3a8b2279c708f93422.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b37FLoaM44BBlamTBhZ95Q.png"/></div></div></figure><h2 id="ebba" class="mf mg it bd mh mi mj dn mk ml mm dp mn lm mo mp mq lq mr ms mt lu mu mv mw iz bi translated">我们用 mAP@0.5 实现了令人敬畏的性能，达到 0.978 或 97.8%，相当令人敬畏！</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi pw"><img src="../Images/48bdf5e98dfd4097c3ab4f679d57f162.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0s3xShFcBbd0eDlS8YDmRw.png"/></div></div></figure><p id="c161" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">运行 100 个纪元后，我们得到</strong></p><p id="50fb" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">精度为 0.659 </strong></p><p id="4b60" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">召回为 0.972 </strong></p><p id="fc6a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">将@0.5 映射为 0.978 </strong></p><p id="bd2a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">以 95%的置信度将@0.5 映射为 0.471 </strong></p><h1 id="ebee" class="pa mg it bd mh pb pc pd mk pe pf pg mn ki ph kj mq kl pi km mt ko pj kp mw pk bi translated"><strong class="ak">使用的资源</strong></h1><ul class=""><li id="2940" class="nd ne it lf b lg mx lj my lm px lq py lu pz ly pl nj nk nl bi translated"><a class="ae lz" href="https://blog.roboflow.ai/" rel="noopener ugc nofollow" target="_blank">https://blog . roboflow . ai</a></li><li id="0d16" class="nd ne it lf b lg nm lj nn lm no lq np lu nq ly pl nj nk nl bi translated"><a class="ae lz" href="https://github.com/ultralyitcs/yolov5" rel="noopener ugc nofollow" target="_blank">https://github.com/ultralyitcs<strong class="lf jd">/</strong>约洛夫 5 </a></li></ul><h1 id="9dad" class="pa mg it bd mh pb pc pd mk pe pf pg mn ki ph kj mq kl pi km mt ko pj kp mw pk bi translated">相关存储库</h1><p id="d705" class="pw-post-body-paragraph ld le it lf b lg mx kd li lj my kg ll lm mz lo lp lq na ls lt lu nb lw lx ly im bi translated">如果你跳过了培训部分，直接跳到了结论，我有更多的东西给你。找到车牌的感兴趣区域后，我们可以使用 pytesseract 将其用于字符识别</p><p id="0436" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我以前为一个项目做过。您可以查看:</p><div class="nr ns gp gr nt nu"><a href="https://github.com/sid0312/ANPR" rel="noopener  ugc nofollow" target="_blank"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd jd gy z fp nz fr fs oa fu fw jc bi translated">sid0312/ANPR</h2><div class="ob l"><h3 class="bd b gy z fp nz fr fs oa fu fw dk translated">这将作为我们的初始数据集 git 克隆 https://github.com/pjreddie/darknet CD 暗网我们添加我们的处理…</h3></div><div class="oc l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">github.com</p></div></div><div class="od l"><div class="qa l of og oh od oi kx nu"/></div></div></a></div><h2 id="9ce2" class="mf mg it bd mh mi mj dn mk ml mm dp mn lm mo mp mq lq mr ms mt lu mu mv mw iz bi translated">作者推荐的博客</h2><p id="9719" class="pw-post-body-paragraph ld le it lf b lg mx kd li lj my kg ll lm mz lo lp lq na ls lt lu nb lw lx ly im bi translated">如果你想了解更多关于物体检测算法和库的知识，我强烈推荐这个由 neptune.ai 撰写的博客</p><div class="nr ns gp gr nt nu"><a href="https://neptune.ai/blog/object-detection-algorithms-and-libraries" rel="noopener  ugc nofollow" target="_blank"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd jd gy z fp nz fr fs oa fu fw jc bi translated">对象检测算法和库- neptune.ai</h2><div class="ob l"><h3 class="bd b gy z fp nz fr fs oa fu fw dk translated">对象检测在图像中找到并识别事物，这是深度学习的最大成就之一…</h3></div><div class="oc l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">海王星. ai</p></div></div><div class="od l"><div class="qb l of og oh od oi kx nu"/></div></div></a></div><h2 id="8005" class="mf mg it bd mh mi mj dn mk ml mm dp mn lm mo mp mq lq mr ms mt lu mu mv mw iz bi translated">作者说明</h2><p id="cd37" class="pw-post-body-paragraph ld le it lf b lg mx kd li lj my kg ll lm mz lo lp lq na ls lt lu nb lw lx ly im bi translated">如果你喜欢我的文章，看看这些！</p><div class="nr ns gp gr nt nu"><a rel="noopener follow" target="_blank" href="/face-detection-on-the-browser-with-tensorflow-js-27846a5fe954"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd jd gy z fp nz fr fs oa fu fw jc bi translated">使用 Tensorflow.js 优化浏览器上的人脸检测</h2><div class="ob l"><h3 class="bd b gy z fp nz fr fs oa fu fw dk translated">基于浏览器的人脸检测器正是你所需要的</h3></div><div class="oc l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">towardsdatascience.com</p></div></div><div class="od l"><div class="qc l of og oh od oi kx nu"/></div></div></a></div><div class="nr ns gp gr nt nu"><a rel="noopener follow" target="_blank" href="/segmentation-of-optical-coherence-tomography-images-with-diabetic-macular-edema-the-gluon-82093cfd8e24"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd jd gy z fp nz fr fs oa fu fw jc bi translated">基于 U-网的 OCT 图像分割</h2><div class="ob l"><h3 class="bd b gy z fp nz fr fs oa fu fw dk translated">使用 OCT 报告诊断糖尿病性黄斑水肿的深度学习方法。使用 Apache Mxnet 和…</h3></div><div class="oc l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">towardsdatascience.com</p></div></div><div class="od l"><div class="qd l of og oh od oi kx nu"/></div></div></a></div><div class="nr ns gp gr nt nu"><a rel="noopener follow" target="_blank" href="/counting-people-on-your-webcam-using-gluoncv-and-mxnet-d1a9f05c427d"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd jd gy z fp nz fr fs oa fu fw jc bi translated">使用 GluonCV 和 MxNet 计算网络摄像头上的人数</h2><div class="ob l"><h3 class="bd b gy z fp nz fr fs oa fu fw dk translated">介绍</h3></div><div class="oc l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">towardsdatascience.com</p></div></div><div class="od l"><div class="qe l of og oh od oi kx nu"/></div></div></a></div><p id="6ace" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">如果你希望在 Linkedin 上与我联系</strong>，<strong class="lf jd">这是我的简介</strong></p><div class="nr ns gp gr nt nu"><a href="https://www.linkedin.com/in/siddhant-baldota-051059180/" rel="noopener  ugc nofollow" target="_blank"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd jd gy z fp nz fr fs oa fu fw jc bi translated">Siddhant Baldota -圣地亚哥超级计算机中心研究实习生| LinkedIn</h2><div class="ob l"><h3 class="bd b gy z fp nz fr fs oa fu fw dk translated">我是一名计算机科学硕士研究生，积极致力于深度学习和计算机的应用</h3></div><div class="oc l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">www.linkedin.com</p></div></div><div class="od l"><div class="qf l of og oh od oi kx nu"/></div></div></a></div><p id="f271" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">快乐的计算机视觉和快乐的深度学习❤.</p></div></div>    
</body>
</html>