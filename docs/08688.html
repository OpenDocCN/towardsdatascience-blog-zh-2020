<html>
<head>
<title>Tuning Parameters. Here’s How.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">调整参数。以下是方法。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tuning-parameters-heres-how-39a4d1956f79?source=collection_archive---------27-----------------------#2020-06-23">https://towardsdatascience.com/tuning-parameters-heres-how-39a4d1956f79?source=collection_archive---------27-----------------------#2020-06-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="65eb" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">对你的机器学习模型有益的常见和不太常见的参数。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/3d137104ecbcf7f4508d58500771e1af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xTxsJN6f_jsHhf_KnepHcg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Gabriel Gurrola 在<a class="ae ky" href="https://unsplash.com/s/photos/tune?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a>【1】上的照片。</p></figure><h1 id="b24a" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">目录</h1><ol class=""><li id="3b7c" class="lr ls it lt b lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">介绍</li><li id="71b1" class="lr ls it lt b lu mj lw mk ly ml ma mm mc mn me mf mg mh mi bi translated">因素</li><li id="af98" class="lr ls it lt b lu mj lw mk ly ml ma mm mc mn me mf mg mh mi bi translated">例子</li><li id="8399" class="lr ls it lt b lu mj lw mk ly ml ma mm mc mn me mf mg mh mi bi translated">密码</li><li id="8f5a" class="lr ls it lt b lu mj lw mk ly ml ma mm mc mn me mf mg mh mi bi translated">摘要</li><li id="95ee" class="lr ls it lt b lu mj lw mk ly ml ma mm mc mn me mf mg mh mi bi translated">参考</li></ol><h1 id="4ebc" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="c7fc" class="pw-post-body-paragraph mo mp it lt b lu lv ju mq lw lx jx mr ly ms mt mu ma mv mw mx mc my mz na me im bi translated">参数可能令人望而生畏，令人困惑，令人不知所措。本文将概述常用机器学习算法中使用的关键参数，包括:随机森林、多项式朴素贝叶斯、逻辑回归、支持向量机和 K 近邻。还有称为超参数的特定参数，我们将在后面讨论。参数调整有利于提高模型精度，减少模型运行时间，并最终减少模型的货币支出。</p><h1 id="9fbe" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">因素</h1><p id="4374" class="pw-post-body-paragraph mo mp it lt b lu lv ju mq lw lx jx mr ly ms mt mu ma mv mw mx mc my mz na me im bi translated">来自<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" rel="noopener ugc nofollow" target="_blank">sk learn</a>【2】和其他库的每种型号都有不同的参数；但是，这些常用算法之间有相当多的重叠。开发模型时，您将拥有默认参数。调整这些有助于提高您的整体准确性。这些参数将在分类代码中找到(我将展示 Python 中的例子)，例如，假设您使用<em class="nb"> clf </em>作为分类器的别名，您可以输入这些参数并在那里更改或调整它们的值，最终更改您的模型的输出。</p><p id="7536" class="pw-post-body-paragraph mo mp it lt b lu nc ju mq lw nd jx mr ly ne mt mu ma nf mw mx mc ng mz na me im bi translated">最有效的调优方法之一是网格搜索[3]。这些参数是不同的，因为它们被认为是超参数，并且不是在估计器本身中直接学习的。在建立了上述分类器之后，您将创建一个参数网格，该网格将进行搜索以找到超参数的最大优化。请记住，这个调优过程计算量很大，如果您添加几个超参数的话，可能会非常昂贵。该模型将引用您列出的所有网格项目的组合，因此，几乎就好像您有几个模型在运行，而不是一个。</p><h1 id="054f" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">例子</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/fbcba1ce4535925c28ea1017c5f328a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k0dCl_EY3wUc1sjdBXGCaw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@grohsfabian?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Fabian Grohs </a>在<a class="ae ky" href="https://unsplash.com/s/photos/code?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a>【4】上拍摄。</p></figure><p id="80a9" class="pw-post-body-paragraph mo mp it lt b lu nc ju mq lw nd jx mr ly ne mt mu ma nf mw mx mc ng mz na me im bi translated">下面，我会把我在整个数据科学硕士期间所学的常用机器学习算法，以及我的职业生涯包括在内。虽然这些都是需要学习和练习的重要方法，但还有无数其他方法可以帮助你提高准确度。</p><blockquote class="ni"><p id="ee15" class="nj nk it bd nl nm nn no np nq nr me dk translated">这些参数不仅有助于提高准确性，而且有助于降低计算机的计算时间和工作量，因为您将降低随机森林的数量，从而降低树的最大深度，最终也将节省资金。</p></blockquote><p id="50b6" class="pw-post-body-paragraph mo mp it lt b lu ns ju mq lw nt jx mr ly nu mt mu ma nv mw mx mc nw mz na me im bi translated">下面列出的是来自 sklearn 的常见机器学习算法，其中包括几个可编辑的参数。以下是所有记录的参数及其各自的机器学习算法的链接:</p><p id="dc44" class="pw-post-body-paragraph mo mp it lt b lu nc ju mq lw nd jx mr ly ne mt mu ma nf mw mx mc ng mz na me im bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" rel="noopener ugc nofollow" target="_blank">随机森林</a></p><p id="b8db" class="pw-post-body-paragraph mo mp it lt b lu nc ju mq lw nd jx mr ly ne mt mu ma nf mw mx mc ng mz na me im bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html" rel="noopener ugc nofollow" target="_blank">多项式朴素贝叶斯</a></p><p id="2922" class="pw-post-body-paragraph mo mp it lt b lu nc ju mq lw nd jx mr ly ne mt mu ma nf mw mx mc ng mz na me im bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" rel="noopener ugc nofollow" target="_blank">逻辑回归</a></p><p id="809c" class="pw-post-body-paragraph mo mp it lt b lu nc ju mq lw nd jx mr ly ne mt mu ma nf mw mx mc ng mz na me im bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/modules/svm.html" rel="noopener ugc nofollow" target="_blank">支持向量机</a></p><p id="6d65" class="pw-post-body-paragraph mo mp it lt b lu nc ju mq lw nd jx mr ly ne mt mu ma nf mw mx mc ng mz na me im bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html" rel="noopener ugc nofollow" target="_blank">K-最近邻</a></p><p id="2f1d" class="pw-post-body-paragraph mo mp it lt b lu nc ju mq lw nd jx mr ly ne mt mu ma nf mw mx mc ng mz na me im bi translated">下面代码片段中的默认参数将在括号内——我还将给出我发现在过去有用的建议。</p><blockquote class="nx ny nz"><p id="bdd4" class="mo mp nb lt b lu nc ju mq lw nd jx mr oa ne mt mu ob nf mw mx oc ng mz na me im bi translated">随机森林</p></blockquote><pre class="kj kk kl km gt od oe of og aw oh bi"><span id="db52" class="oi la it oe b gy oj ok l ol om"><strong class="oe iu">n_estimators</strong>: number of trees in your forest (100)</span><span id="d44d" class="oi la it oe b gy on ok l ol om"><strong class="oe iu">max_depth</strong>: maximum depth of your tree (None) - recommendation, change this parameter to be an actual number because this parameter could cause overfitting from learning your traning data too well</span><span id="aefa" class="oi la it oe b gy on ok l ol om"><strong class="oe iu">min_samples_split</strong>: minimum samples required to split your node (2)</span><span id="6184" class="oi la it oe b gy on ok l ol om"><strong class="oe iu">min_samples_leaf</strong>: mimimum number of samples to be at your leaf node (1)</span><span id="fda0" class="oi la it oe b gy on ok l ol om"><strong class="oe iu">max_features</strong>: number of features used for the best split ("auto")</span><span id="ecfd" class="oi la it oe b gy on ok l ol om"><strong class="oe iu">boostrap</strong>: if you want to use boostrapped samples (True)</span><span id="5c40" class="oi la it oe b gy on ok l ol om"><strong class="oe iu">n_jobs</strong>: number of jobs in parallel run (None) - for using all processors, put -1</span><span id="eacc" class="oi la it oe b gy on ok l ol om"><strong class="oe iu">random_state</strong>: for reproducibility in controlling randomness of samples (None)</span><span id="6ce4" class="oi la it oe b gy on ok l ol om"><strong class="oe iu">verbose</strong>: text output of model in process (None)</span><span id="1e9b" class="oi la it oe b gy on ok l ol om"><strong class="oe iu">class_weight</strong>: balancing weights of features, n_samples / (n_classes * np.bincount(y)) (None) - recommendation, use 'balanced' for labels that are unbalanced</span></pre><blockquote class="nx ny nz"><p id="2086" class="mo mp nb lt b lu nc ju mq lw nd jx mr oa ne mt mu ob nf mw mx oc ng mz na me im bi translated">多项式朴素贝叶斯</p></blockquote><pre class="kj kk kl km gt od oe of og aw oh bi"><span id="03e1" class="oi la it oe b gy oj ok l ol om">parameters - </span><span id="d15d" class="oi la it oe b gy on ok l ol om"><strong class="oe iu">alpha</strong>: a paramter for smoothing (1.0)</span><span id="be4f" class="oi la it oe b gy on ok l ol om"><strong class="oe iu">class_prior</strong>: looking at the previous class probability (None) attributes -</span><span id="8fac" class="oi la it oe b gy on ok l ol om"><strong class="oe iu">feature_count</strong>: number of samples for each class or feature (number of classes, number of features)</span><span id="1236" class="oi la it oe b gy on ok l ol om"><strong class="oe iu">n_features</strong>: number of features for sample</span></pre><blockquote class="nx ny nz"><p id="3f90" class="mo mp nb lt b lu nc ju mq lw nd jx mr oa ne mt mu ob nf mw mx oc ng mz na me im bi translated">逻辑回归</p></blockquote><pre class="kj kk kl km gt od oe of og aw oh bi"><span id="9338" class="oi la it oe b gy oj ok l ol om"><strong class="oe iu">penalty</strong>: l1 or l2 (lasso or ridge), the normality of penalization (l2)</span><span id="6333" class="oi la it oe b gy on ok l ol om"><strong class="oe iu">multi_class</strong>: binary versus multiclass label data ('auto')</span></pre><blockquote class="nx ny nz"><p id="73b0" class="mo mp nb lt b lu nc ju mq lw nd jx mr oa ne mt mu ob nf mw mx oc ng mz na me im bi translated">支持向量机</p></blockquote><pre class="kj kk kl km gt od oe of og aw oh bi"><span id="5178" class="oi la it oe b gy oj ok l ol om">parameter<strong class="oe iu"> - decision_function_shape</strong>: 'ovr' or 'one-versus-rest' approach</span></pre><blockquote class="nx ny nz"><p id="7f5a" class="mo mp nb lt b lu nc ju mq lw nd jx mr oa ne mt mu ob nf mw mx oc ng mz na me im bi translated">k-最近邻</p></blockquote><pre class="kj kk kl km gt od oe of og aw oh bi"><span id="c480" class="oi la it oe b gy oj ok l ol om">parameter - <strong class="oe iu">n_neighbors</strong>: number of neighbors (5)</span></pre><h1 id="862e" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">密码</h1><p id="1ad5" class="pw-post-body-paragraph mo mp it lt b lu lv ju mq lw lx jx mr ly ms mt mu ma mv mw mx mc my mz na me im bi translated">下面是一些有用的代码，可以帮助您开始参数调整。有几个模型可以从调优中受益，业务和团队也可以从调优带来的效率中受益。下面，是模型代码，以及可用于强大优化的网格搜索代码。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oo op l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">调谐参数的位置。作者代码[5]。</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oo op l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">网格搜索示例。作者代码[6]。</p></figure><h1 id="0c89" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">摘要</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/1f5efe8cc8443040385d26ea5a0257e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zfr4G5CzLM0ZJ3jWNKsAaQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@thisisengineering?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> ThisisEngineering RAEng </a>在<a class="ae ky" href="https://unsplash.com/s/photos/person-coding?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a>【7】上拍摄。</p></figure><p id="4239" class="pw-post-body-paragraph mo mp it lt b lu nc ju mq lw nd jx mr ly ne mt mu ma nf mw mx mc ng mz na me im bi translated">现在，希望您和您的团队能够从应用当前或下一个机器学习模型的参数更改中受益。从默认参数开始，确保在开始调优之前了解每个模型的参数，以及关于这些参数定义的官方文档。虽然它们可以改善你的模型，但是参数也可以以降低你的准确性或者过度拟合你的模型的方式被调整。小心谨慎，你会发现自己拥有一个成功的、复杂的数据科学模型。</p><p id="b9b7" class="pw-post-body-paragraph mo mp it lt b lu nc ju mq lw nd jx mr ly ne mt mu ma nf mw mx mc ng mz na me im bi translated">我希望你觉得这篇文章有趣且有用。谢谢大家！</p><p id="aad2" class="pw-post-body-paragraph mo mp it lt b lu nc ju mq lw nd jx mr ly ne mt mu ma nf mw mx mc ng mz na me im bi translated">如果你想了解更多关于这些特定的机器学习算法，我写了另一篇文章，你可以在这里找到[8]:</p><div class="or os gp gr ot ou"><a rel="noopener follow" target="_blank" href="/machine-learning-algorithms-heres-the-end-to-end-a5f2f479d1ef"><div class="ov ab fo"><div class="ow ab ox cl cj oy"><h2 class="bd iu gy z fp oz fr fs pa fu fw is bi translated">机器学习算法。这里是端到端。</h2><div class="pb l"><h3 class="bd b gy z fp oz fr fs pa fu fw dk translated">通用算法的端到端运行；包括随机森林，多项式朴素贝叶斯，逻辑回归…</h3></div><div class="pc l"><p class="bd b dl z fp oz fr fs pa fu fw dk translated">towardsdatascience.com</p></div></div><div class="pd l"><div class="pe l pf pg ph pd pi ks ou"/></div></div></a></div><h1 id="9883" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">参考</h1><p id="5476" class="pw-post-body-paragraph mo mp it lt b lu lv ju mq lw lx jx mr ly ms mt mu ma mv mw mx mc my mz na me im bi translated">[1]照片由<a class="ae ky" href="https://unsplash.com/@gabrielgurrola?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Gabriel Gurrola </a>在<a class="ae ky" href="https://unsplash.com/s/photos/tune?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a>(2016)上拍摄</p><p id="3ddc" class="pw-post-body-paragraph mo mp it lt b lu nc ju mq lw nd jx mr ly ne mt mu ma nf mw mx mc ng mz na me im bi translated">[2] sklearn，<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" rel="noopener ugc nofollow" target="_blank"> sklearn.linear_model。后勤回归</a>(2007 年至 2019 年)</p><p id="6d34" class="pw-post-body-paragraph mo mp it lt b lu nc ju mq lw nd jx mr ly ne mt mu ma nf mw mx mc ng mz na me im bi translated">[3] sklearn，<a class="ae ky" href="https://scikit-learn.org/stable/modules/grid_search.html" rel="noopener ugc nofollow" target="_blank"> 3.2。调整估计器的超参数</a>(2007–2019)</p><p id="d64c" class="pw-post-body-paragraph mo mp it lt b lu nc ju mq lw nd jx mr ly ne mt mu ma nf mw mx mc ng mz na me im bi translated">[4]照片由<a class="ae ky" href="https://unsplash.com/@grohsfabian?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Fabian Grohs </a>在<a class="ae ky" href="https://unsplash.com/s/photos/code?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄，(2018)</p><p id="9591" class="pw-post-body-paragraph mo mp it lt b lu nc ju mq lw nd jx mr ly ne mt mu ma nf mw mx mc ng mz na me im bi translated">[5] M.Przybyla，<a class="ae ky" href="https://gist.github.com/mprzybyla123/461cc1513e83826f763949cf409a98d8" rel="noopener ugc nofollow" target="_blank">要点—模型</a>，(2020)</p><p id="dbf2" class="pw-post-body-paragraph mo mp it lt b lu nc ju mq lw nd jx mr ly ne mt mu ma nf mw mx mc ng mz na me im bi translated">[6] M.Przybyla，<a class="ae ky" href="https://gist.github.com/mprzybyla123/663dfc57b5cf6fcdd45b4a06ce82afb3" rel="noopener ugc nofollow" target="_blank">要点——网格搜索</a>，(2020)</p><p id="4ab0" class="pw-post-body-paragraph mo mp it lt b lu nc ju mq lw nd jx mr ly ne mt mu ma nf mw mx mc ng mz na me im bi translated">[7]照片由<a class="ae ky" href="https://unsplash.com/@thisisengineering?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">this engineering RAEng</a>在<a class="ae ky" href="https://unsplash.com/s/photos/person-coding?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a>(2020)上拍摄</p><p id="7640" class="pw-post-body-paragraph mo mp it lt b lu nc ju mq lw nd jx mr ly ne mt mu ma nf mw mx mc ng mz na me im bi translated">[8] M.Przybyla，<a class="ae ky" rel="noopener" target="_blank" href="/machine-learning-algorithms-heres-the-end-to-end-a5f2f479d1ef">机器学习算法。这里是端到端的</a>。, (2020)</p></div></div>    
</body>
</html>