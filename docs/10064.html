<html>
<head>
<title>Let's Get Artsy! Creating Custom Snapchat Filters With Neural Networks!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">让我们开始艺术吧！用神经网络创建自定义 Snapchat 过滤器！</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/lets-get-artsy-creating-custom-snapchat-filters-with-neural-networks-8b73134b6cd7?source=collection_archive---------56-----------------------#2020-07-15">https://towardsdatascience.com/lets-get-artsy-creating-custom-snapchat-filters-with-neural-networks-8b73134b6cd7?source=collection_archive---------56-----------------------#2020-07-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e786" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">利昂·a·盖茨比神经风格迁移初探</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/94e339380f131049d102f9b82aabeb83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*E8K0qMwlGbC0JHcQ"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">普里西拉·杜·普里兹在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="b6f5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">和很多人一样，我可以强烈地说，拍照不是我的强项。我学会了变得更好，并养成了一种像《我是如何遇见你母亲》中的巴尼那样的半笑。最近，我想努力变得更上镜，所以我通过我的社交媒体搜索，看看别人是如何做到的。然后我突然想到，这些照片中的大多数都经过了某种过滤，主要来自 Snapchat。这让我困惑了一段时间，直到我亲自尝试。这些滤镜又古怪又愚蠢，而且确实让我在镜头前看起来更好看！</p><p id="fc93" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">那时我就在想，“如果我们能自己制作过滤器会怎么样”？经过一些研究，我了解到 Snapchat 从许多计算机视觉技术中创建了这些增强现实过滤器。最后，经过几个小时的研究，我发现了一篇有趣的论文，名为“艺术风格的神经算法”，作者是里昂·A·盖茨比(Leon A. Gatsy)及其同事。他们使用神经网络从一张照片和一件艺术品中创建一个“风格化的图像”。然后，在突然意识到之后，我想探索一下我们是否可以使用这种技术来创建自定义过滤器，就像 Snap chat 上的过滤器一样。这是我用 Python 实现它的旅程！</p><p id="c1c6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">附注:这种技术已经成为研究的热门话题好几年了，有许多很好的在线资源和视频很好地解释了这些概念。本文主要是尽我所能提供这种技术的高层次概述。好吧，让我们开始吧！</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="fc2d" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">神经类型转移:算法</h1><p id="2105" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">那么这个算法想要完成什么呢？本质上，我们希望产生一个图像，类似于我们的内容图像(我们希望风格化的图像)，具有我们的风格图像的艺术风格。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mw"><img src="../Images/b3501ca00bc02417ef6b9a828e0dc141.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*54xB8BAbMYR0iu1SJlXyuA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图宾根斯纳卡前线梵高《星夜》风格转移的一个例子(<a class="ae kv" href="https://www.researchgate.net/publication/330383053_Automated_Deep_Photo_Style_Transfer" rel="noopener ugc nofollow" target="_blank">图片来源</a></p></figure><p id="4698" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在最初的论文中，他首先使用 VGG19 模型来实现这个结果。VGG19 是一种流行的图像识别神经网络，但我们主要关注它如何从照片中提取特征。特征提取是通过可以检测小图案的多个连续层来完成的。它最初拾取的要素非常简单，但随着更多要素图层的添加而变得更加复杂。然后，我们可以使用这些功能，重新创建我们的原始图像！</p><h2 id="423a" class="mx ma iq bd mb my mz dn mf na nb dp mj lf nc nd ml lj ne nf mn ln ng nh mp ni bi translated">内容损失</h2><p id="dfaf" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">在这一步中，我们希望或多或少地重新创建我们内容图像的本质。为了实现这一点，我们将首先创建一个充满随机噪声的图像。然后，我们将使用从我们的网络中提取的特征作为指导，将这个图像塑造成看起来像我们的内容图像。随机图像特征和内容特征之间的距离被称为我们的“内容损失”。为了获得最佳的风格化图像，我们希望通过反向传播来最小化这个损失函数。我们将最终循环这整个事情，并优化每一步，以获得一个很好的重建我们的形象。</p><pre class="kg kh ki kj gt nj nk nl nm aw nn bi"><span id="39d1" class="mx ma iq nk b gy no np l nq nr">for i in range(1,epochs+1):</span><span id="21d1" class="mx ma iq nk b gy ns np l nq nr">target_features = model_activations(target,model)</span><span id="8b29" class="mx ma iq nk b gy ns np l nq nr">content_loss = torch.mean((content_features['conv4_2']-target_features['conv4_2'])**2)</span></pre><h2 id="d85f" class="mx ma iq bd mb my mz dn mf na nb dp mj lf nc nd ml lj ne nf mn ln ng nh mp ni bi translated">风格丧失</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/fee7a02183156aae5056fc85e88c2555.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*1sYsIEGsUYter2G2saPN7w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">格拉姆矩阵方程(<a class="ae kv" href="https://en.wikipedia.org/wiki/Gramian_matrix" rel="noopener ugc nofollow" target="_blank">图像来源</a></p></figure><p id="9ecb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这一步，我们要重新创建我们的风格形象的核心艺术方向。盖茨比用一种有趣的方式解决了这个问题！我们不是将我们的风格特征与另一个图像进行比较，而是将每个特征图与其自身进行比较。我们首先将样式特征转换成一个 gram 矩阵，它基本上是一个矩阵的内积。“风格损失”基本上是模型网络中所有特征地图损失的总和。我们将做一个类似的循环过程，并优化每一步。</p><pre class="kg kh ki kj gt nj nk nl nm aw nn bi"><span id="6366" class="mx ma iq nk b gy no np l nq nr">style_loss = 0</span><span id="7bd7" class="mx ma iq nk b gy ns np l nq nr">for layer in style_wt_meas:</span><span id="634c" class="mx ma iq nk b gy ns np l nq nr">style_gram = style_grams[layer]</span><span id="dc1a" class="mx ma iq nk b gy ns np l nq nr">target_gram = target_features[layer]</span><span id="cba6" class="mx ma iq nk b gy ns np l nq nr">_,d,w,h = target_gram.shape</span><span id="ed1a" class="mx ma iq nk b gy ns np l nq nr">target_gram = gram_matrix(target_gram)</span><span id="24c5" class="mx ma iq nk b gy ns np l nq nr">style_loss += (style_wt_meas[layer]*torch.mean((target_gram-style_gram)**2))/d*w*h</span></pre><p id="55e7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们在这个过程中的最后一步是计算我们的最终损失，作为我们的内容损失和风格损失的加权和。我们还将在训练循环的每一步优化这种损失。</p><pre class="kg kh ki kj gt nj nk nl nm aw nn bi"><span id="161a" class="mx ma iq nk b gy no np l nq nr">total_loss = content_wt*content_loss + style_wt*style_loss</span></pre><h1 id="5645" class="lz ma iq bd mb mc nu me mf mg nv mi mj jw nw jx ml jz nx ka mn kc ny kd mp mq bi translated">问题和未来工作</h1><p id="5948" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">盖茨比风格转换法是此类方法中的首创，但也存在一些问题。主要的问题是它非常慢。这是因为由于优化是在训练循环中的每个周期进行的，所以算法需要一些时间来产生任何东西。其次，有时改变权重会大大破坏照片的稳定性。有一个修复方法是添加一个总损失变量，该变量与内容和样式图像的均值和方差对齐。根据我的研究，看起来神经风格转移仍然是一个热门话题，应用程序被应用于视频处理、模拟和设计。</p><p id="5098" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我在 Youtube 上使用 Ayush Chaurasia: <a class="ae kv" href="https://www.youtube.com/watch?v=K_xBhp1YsrE" rel="noopener ugc nofollow" target="_blank">艺术神经风格转移从零开始</a>来创建代码。就像我在本文开头提到的，你可以在网上找到很多很好的资源。如果你想开始解决计算机视觉问题，我认为构建神经风格转换应用程序会非常有趣和令人兴奋！所以我希望这有所帮助，如果你想继续下去，我祝你好运！</p><h1 id="19e2" class="lz ma iq bd mb mc nu me mf mg nv mi mj jw nw jx ml jz nx ka mn kc ny kd mp mq bi translated">感谢阅读！</h1><p id="37a2" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">这里有一些我拍摄的很酷的结果，我迫不及待地想看看你会创造出什么！</p><div class="kg kh ki kj gt ab cb"><figure class="nz kk oa ob oc od oe paragraph-image"><img src="../Images/1ce8210e3e5bea0c6294ba7e08c8a0f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*UxVlU0tvPWkPK-Q85R2Dwg.jpeg"/></figure><figure class="nz kk oa ob oc od oe paragraph-image"><img src="../Images/affeaafcfb0f6f5f968da4e30ca80361.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*ZTmZemVqTyJLd_DYErcbgg.jpeg"/></figure><figure class="nz kk oa ob oc od oe paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/87a74a204442eb1b93f0aa42945c01ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*b5a2oUVsa5IrwLSv-J3_6g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk of di og oh translated">金门大桥上的红云</p></figure></div><div class="ab cb"><figure class="nz kk oa ob oc od oe paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/973e73dc4b2f95c6b5c58c747572f8bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*qwVKZ3AozRgiGVev-BNoaw.jpeg"/></div></figure><figure class="nz kk oa ob oc od oe paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/99a7fb2358d8ed978251dee6773e2909.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*XVh9z7FQ3j47uFpMKlXaWQ.jpeg"/></div></figure><figure class="nz kk oa ob oc od oe paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/aabe98c62d545f643d74e6d1c15ba04d.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*mK3xB_vFNBAD37olkXfAwQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk of di og oh translated">卡丁斯基论大海龟</p></figure></div><div class="ab cb"><figure class="nz kk oi ob oc od oe paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/e11f8b8a352f8bb88c7c238fcaa1c0fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/1*r0LSwwYNkqmDZGRZrud3Lw.jpeg"/></div></figure><figure class="nz kk oj ob oc od oe paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/621e65207941f4fce4ace7f0e992844a.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*sqpZXK_OLq7eS2OlPB-WLg.jpeg"/></div></figure><figure class="nz kk ok ob oc od oe paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/a25c676e09cd5d64f5daf536abc068fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:630/format:webp/1*ewynXMKVglTll-HZY9valw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk ol di om oh translated">米开朗基罗在你的真实(我)上的绘画(风格来源:照片由<a class="ae kv" href="https://unsplash.com/@adrigeo_" rel="noopener ugc nofollow" target="_blank">阿德里安娜·吉奥</a>在<a class="ae kv" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄)</p></figure></div><p id="5594" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">完整的代码可以在我的 Google Colab 上找到:</p><div class="on oo gp gr op oq"><a href="https://colab.research.google.com/drive/1iUdLwtgV5cJZefR1j09PtpAYpcWxfZ1e" rel="noopener  ugc nofollow" target="_blank"><div class="or ab fo"><div class="os ab ot cl cj ou"><h2 class="bd ir gy z fp ov fr fs ow fu fw ip bi translated">谷歌联合实验室</h2><div class="ox l"><h3 class="bd b gy z fp ov fr fs ow fu fw dk translated">Snapchat 应用</h3></div><div class="oy l"><p class="bd b dl z fp ov fr fs ow fu fw dk translated">colab.research.google.com</p></div></div><div class="oz l"><div class="pa l pb pc pd oz pe kp oq"/></div></div></a></div><p id="36f4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以查看我的 GitHub 获取更多资源！</p><div class="on oo gp gr op oq"><a href="https://github.com/MehrabiHasan/Snapchat-App" rel="noopener  ugc nofollow" target="_blank"><div class="or ab fo"><div class="os ab ot cl cj ou"><h2 class="bd ir gy z fp ov fr fs ow fu fw ip bi translated">MehrabiHasan/Snapchat-App</h2><div class="ox l"><h3 class="bd b gy z fp ov fr fs ow fu fw dk translated">GitHub 是超过 5000 万开发人员的家园，他们一起工作来托管和审查代码、管理项目和构建…</h3></div><div class="oy l"><p class="bd b dl z fp ov fr fs ow fu fw dk translated">github.com</p></div></div><div class="oz l"><div class="pf l pb pc pd oz pe kp oq"/></div></div></a></div><h1 id="8abe" class="lz ma iq bd mb mc nu me mf mg nv mi mj jw nw jx ml jz nx ka mn kc ny kd mp mq bi translated">参考</h1><ol class=""><li id="6720" class="pg ph iq ky b kz mr lc ms lf pi lj pj ln pk lr pl pm pn po bi translated">【https://www.youtube.com/watch?v=K_xBhp1YsrE T4】</li><li id="03f8" class="pg ph iq ky b kz pp lc pq lf pr lj ps ln pt lr pl pm pn po bi translated"><a class="ae kv" href="https://www.youtube.com/watch?v=c3kL9yFGUOY" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=c3kL9yFGUOY</a></li><li id="92a1" class="pg ph iq ky b kz pp lc pq lf pr lj ps ln pt lr pl pm pn po bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/breaking-down-leon-gatys-neural-style-transfer-in-pytorch-faf9f0eb79db">https://towards data science . com/breaking-down-Leon-gatys-neural-style-transfer-in-py torch-fa F9 f 0 EB 79 db</a></li><li id="2d20" class="pg ph iq ky b kz pp lc pq lf pr lj ps ln pt lr pl pm pn po bi translated"><a class="ae kv" href="https://arxiv.org/abs/1703.06868" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1703.06868</a></li><li id="e7ad" class="pg ph iq ky b kz pp lc pq lf pr lj ps ln pt lr pl pm pn po bi translated"><a class="ae kv" href="https://arxiv.org/abs/1603.08155" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1603.08155</a></li><li id="1e11" class="pg ph iq ky b kz pp lc pq lf pr lj ps ln pt lr pl pm pn po bi translated"><a class="ae kv" href="https://arxiv.org/abs/1508.06576" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1508.06576</a></li><li id="78b7" class="pg ph iq ky b kz pp lc pq lf pr lj ps ln pt lr pl pm pn po bi translated"><a class="ae kv" href="https://github.com/reiinakano" rel="noopener ugc nofollow" target="_blank">https://github.com/reiinakano</a></li></ol></div></div>    
</body>
</html>