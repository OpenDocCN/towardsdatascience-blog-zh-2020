<html>
<head>
<title>Natural Scene Recognition Using Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习的自然场景识别</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/natural-scene-recognition-using-deep-learning-91b6ba86bad5?source=collection_archive---------35-----------------------#2020-07-28">https://towardsdatascience.com/natural-scene-recognition-using-deep-learning-91b6ba86bad5?source=collection_archive---------35-----------------------#2020-07-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8b1d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在计算机视觉中，场景识别是最具挑战性的研究领域之一。</h2></div><p id="4edc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一眼就认出环境是人类大脑最有成就的行为之一。虽然最近在对象识别任务中的巨大进步源于诸如 COCO 之类的大型数据集的可用性以及用于学习高级特征的卷积神经网络(CNN)的兴起，但是场景识别性能并没有获得同样程度的成功。</p><p id="195f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这篇博文中，我们将看到分类模型如何对一个场景的图像进行分类。对于这项任务，我们采用了<em class="lb"> Places365-Standard </em>数据集来训练模型。该数据集具有 1，803，460 个训练图像和 365 个类，每个类的图像数量从 3，068 到 5，000 不等，图像的大小为 256*256。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi lc"><img src="../Images/1447a332b86422341271a53521d30d2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1374/format:webp/1*fKeHGEcUi_bpy44zO3MhcA.png"/></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">数据集的图像</p></figure><h1 id="2d9c" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">安装和下载数据</h1><p id="d16f" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">让我们从设置 Monk 及其依赖项开始:</p><pre class="ld le lf lg gt ml mm mn mo aw mp bi"><span id="732a" class="mq lp iq mm b gy mr ms l mt mu">!git clone <a class="ae mv" href="https://github.com/Tessellate-Imaging/monk_v1.git" rel="noopener ugc nofollow" target="_blank">https://github.com/Tessellate-Imaging/monk_v1.git</a><br/><em class="lb">! cd monk_v1/installation/Linux &amp;&amp; pip install -r requirements_cu9.txt</em></span></pre><p id="4631" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">安装完依赖项后，我下载了<em class="lb">place 365-Standard</em>数据集，可以从<a class="ae mv" href="http://places2.csail.mit.edu/download.html" rel="noopener ugc nofollow" target="_blank">这里</a>下载。</p><h1 id="b34c" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">创造一个实验</h1><p id="0e60" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">我已经创建了一个实验，对于这个任务，我使用了<strong class="kh ir"> mxnet 胶子后端。</strong></p><pre class="ld le lf lg gt ml mm mn mo aw mp bi"><span id="f18b" class="mq lp iq mm b gy mr ms l mt mu">import os<br/>import sys<br/>sys.path.append("monk_v1/monk/");<br/>from gluon_prototype import prototype<br/>gtf = prototype(verbose=1);<br/>gtf.Prototype("Places_365", "Experiment");</span></pre><h1 id="0d63" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">模型选择和培训</h1><p id="5d1a" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">我尝试了各种模型，如 resnet、densenet、inception、vgg16 等等，但是只有 vgg16 比其他任何模型都具有更高的验证准确性。</p><pre class="ld le lf lg gt ml mm mn mo aw mp bi"><span id="0918" class="mq lp iq mm b gy mr ms l mt mu">gtf.Default(dataset_path="train/",<br/>            path_to_csv="labels.csv",<br/>            model_name="vgg16",<br/>            freeze_base_network=False,<br/>            num_epochs=20);</span><span id="5d6e" class="mq lp iq mm b gy mw ms l mt mu">gtf.Train();</span></pre><p id="e59b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">经过 20 个历元的训练，我得到了 65%的训练准确率和 53%的验证准确率。</p><h1 id="4845" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">预言；预测；预告</h1><pre class="ld le lf lg gt ml mm mn mo aw mp bi"><span id="aa14" class="mq lp iq mm b gy mr ms l mt mu">gtf = prototype(verbose=1);<br/>gtf.Prototype("Places_365", "Experiment", eval_infer=<strong class="mm ir">True</strong>);</span><span id="26fc" class="mq lp iq mm b gy mw ms l mt mu">img_name = "test_256/Places365_test_00208427.jpg" <br/>predictions = gtf.Infer(img_name=img_name);<br/><strong class="mm ir">from</strong> <strong class="mm ir">IPython.display</strong> <strong class="mm ir">import</strong> Image<br/>Image(filename=img_name)</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/a902827eff71badcf77223e716ab41ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:954/format:webp/1*FPlaYiY_PBxzf53Kcv6BeA.png"/></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">对测试图像的预测</p></figure><pre class="ld le lf lg gt ml mm mn mo aw mp bi"><span id="54c7" class="mq lp iq mm b gy mr ms l mt mu">img_name = "test_256/Places365_test_00151496.jpg" <br/>predictions = gtf.Infer(img_name=img_name);<br/><strong class="mm ir">from</strong> <strong class="mm ir">IPython.display</strong> <strong class="mm ir">import</strong> Image<br/>Image(filename=img_name)</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi my"><img src="../Images/7a55b3905d69614c08796ce79691c007.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/1*aPVbJAg6tFY7rUr0HjZK8w.png"/></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">对测试图像的预测</p></figure><p id="376e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在此之后，我试图找出为什么精度没有比我得到的提高更多。一些可能的原因是:</p><p id="b017" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">标签不正确:- </strong>检查训练文件夹时，有些图像的标签不正确，如 baseball_field 的图像不正确。还有很多不正确的标签。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/eab1e22e80d641dcb84855e016257608.png" data-original-src="https://miro.medium.com/v2/resize:fit:438/format:webp/1*db3NFLcytgfAnrFE5A3VQA.png"/></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">棒球场中的错误图像</p></figure><pre class="ld le lf lg gt ml mm mn mo aw mp bi"><span id="8340" class="mq lp iq mm b gy mr ms l mt mu">img=mpimg.imread(“images/train/baseball_field2469.jpg”)<br/>imgplot = plt.imshow(img)</span></pre><p id="72ff" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">不清晰的场景:- </strong>由于各种类似的类共享类似的对象，如餐厅和食堂、森林道路和田野道路，因此存在非常难以分类的不清晰图像。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/04d79e93c4c152bbcc4076831cdec929.png" data-original-src="https://miro.medium.com/v2/resize:fit:438/format:webp/1*rSS8U5BQkh2yH1-3BjzMOA.png"/></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">标签:field_road</p></figure><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi na"><img src="../Images/ff75757c38e43e649a91ac991f072789.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/format:webp/1*4E07A4egX7yHXhMIkSiF5Q.png"/></div><p class="lk ll gj gh gi lm ln bd b be z dk translated">标签:森林 _ 道路</p></figure><p id="5d8c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我们所见，很难对这两幅图像进行分类。</p><p id="83cf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">多个场景部分:- </strong>由多个场景部分组成的图像不能像海洋附近的建筑物一样归为一类。这些场景可能很难分类，需要更多的地面真实标签来描述环境。</p><p id="6ac7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">总之，这篇博文展示了我们如何使用深度学习网络来执行自然场景分类，以及为什么场景识别性能没有达到与对象识别相同的成功水平。</p><h1 id="7d37" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">参考</h1><div class="nb nc gp gr nd ne"><a href="https://github.com/shubham7169/MonkAI/blob/master/Scene%20Recognition.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="nf ab fo"><div class="ng ab nh cl cj ni"><h2 class="bd ir gy z fp nj fr fs nk fu fw ip bi translated">shubham7169/MonkAI</h2><div class="nl l"><h3 class="bd b gy z fp nj fr fs nk fu fw dk translated">permalink dissolve GitHub 是超过 5000 万开发人员的家园，他们一起工作来托管和审查代码，管理…</h3></div><div class="nm l"><p class="bd b dl z fp nj fr fs nk fu fw dk translated">github.com</p></div></div><div class="nn l"><div class="no l np nq nr nn ns li ne"/></div></div></a></div><p id="eaf9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae mv" href="http://places2.csail.mit.edu/PAMI_places.pdf" rel="noopener ugc nofollow" target="_blank">http://places2.csail.mit.edu/PAMI_places.pdf</a></p></div></div>    
</body>
</html>