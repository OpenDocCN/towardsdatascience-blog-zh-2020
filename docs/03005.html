<html>
<head>
<title>Clothes reviews analysis with NLP — Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用自然语言处理分析服装评论—第二部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/clothes-reviews-analysis-with-nlp-part-1-bfb8a3a2c4bd?source=collection_archive---------34-----------------------#2020-03-22">https://towardsdatascience.com/clothes-reviews-analysis-with-nlp-part-1-bfb8a3a2c4bd?source=collection_archive---------34-----------------------#2020-03-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/20c23efd30541cbb1b6d46647da85098.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2BgtWSN5EVGNOCI0.jpg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://www.klaviyo.com/blog/fashion-apparel-best-practices" rel="noopener ugc nofollow" target="_blank">https://www.klaviyo.com/blog/fashion-apparel-best-practices</a></p></figure><div class=""/><div class=""><h2 id="d940" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">从文本评论分析预测项目评分</h2></div><p id="7d22" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在我之前的<a class="ae jg" href="https://medium.com/@valentinaalto/clothes-reviews-analysis-with-nlp-part-1-d81bdfa14d97#d345-9525ff891c8d" rel="noopener">文章</a>中，我一直在分析网上购买女装的文字评论，以推断顾客的情绪。这个想法是调查情绪是否与购买建议一致。</p><p id="887d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，我将继续分析文本评论，但现在将重点放在评级列上，该列显示该商品的得分从1(最差)到5(最好)。</p><p id="31a6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们刷新一下我们正在谈论的数据集(你可以在<a class="ae jg" href="https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews/version/1#" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上找到它):</p><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="d950" class="md me jj lz b gy mf mg l mh mi">import pandas as pd<br/>df = pd.read_csv('Womens Clothing E-Commerce Reviews.csv')</span><span id="738b" class="md me jj lz b gy mj mg l mh mi">#data cleaning</span><span id="4473" class="md me jj lz b gy mj mg l mh mi">df.dropna(inplace=True)<br/>df.reset_index(drop=True, inplace=True)<br/>import re<br/>for i in range(len(df)):<br/>    #print(i)<br/>    df['Review Text'][i] = df['Review Text'][i].replace("'s", " is").replace("'ll", " will").replace("'ve", " have").replace("'m", " am").replace("\'", "'")<br/>    <br/>df['Review Text'][1]<br/>df = df.drop('Unnamed: 0', 1)</span><span id="a160" class="md me jj lz b gy mj mg l mh mi">#data preprocessing</span><span id="1d03" class="md me jj lz b gy mj mg l mh mi">import nltk<br/>import en_core_web_sm<br/>import spacy<br/>nlp = spacy.load("en_core_web_sm")<br/>from nltk.corpus import stopwords<br/>def lemmatization(df):<br/>    df["Lemmas"] = [" ".join([token.lemma_ if token.lemma_ != "-    <br/>    PRON-" else token.text.lower() <br/>    for sentence in nlp(speech).sents for token in sentence if <br/>    token.pos_ in {"NOUN", "VERB", "ADJ", "ADV", "X"} and  <br/>    token.is_stop == False]) for speech in df.text]<br/>    <br/>df["Lemmas"] = [" ".join([token.lemma_ if token.lemma_ != "-PRON-" <br/>                else token.text.lower() for sentence in <br/>                nlp(speech).sents for token in sentence if <br/>                token.pos_ in {"NOUN", "VERB", "ADJ", "ADV", "X"} <br/>                and token.is_stop == False]) for speech in <br/>                df['Review Text']]df.head()</span><span id="c3b0" class="md me jj lz b gy mj mg l mh mi">df.head()</span></pre><figure class="lu lv lw lx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mk"><img src="../Images/2e31b7c8eec7f9844f4141114685f233.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hSA9IgrxtcRiu9Bi.png"/></div></div></figure><p id="cb87" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">(如果您不熟悉代码，请务必查看本系列的<a class="ae jg" href="https://medium.com/@valentinaalto/clothes-reviews-analysis-with-nlp-part-1-d81bdfa14d97#d345-9525ff891c8d" rel="noopener">第1部分</a>，其中解释了代码的每个块！)</p><p id="ed72" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为此，我们将使用<a class="ae jg" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>(内嵌Tensorflow)构建一个神经网络。在开始之前，我们需要对数据集做一些进一步的预处理。事实上，由于它是一个多类分类(5个类组成评级列)，我们首先需要对该列进行一次性编码(一旦将其从整数转换为字符串):</p><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="2c3e" class="md me jj lz b gy mf mg l mh mi">from sklearn.preprocessing import MultiLabelBinarizer</span><span id="5723" class="md me jj lz b gy mj mg l mh mi">mlb = MultiLabelBinarizer()</span><span id="42c8" class="md me jj lz b gy mj mg l mh mi">df_factor = df.join(pd.DataFrame(mlb.fit_transform(df['Rating']),<br/>                          columns=mlb.classes_,<br/>                          index=df.index))<br/>df_factor.head()<br/></span></pre><figure class="lu lv lw lx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ml"><img src="../Images/732c2f78cd5b5f6317d4a5261d808862.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9d46MBQ6anSS63PsMku96A.png"/></div></div></figure><p id="5297" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">很好，现在让我们导入必要的库，并将数据集分成训练(80%)和测试(20%)集。这对于我们模型的稳健性至关重要:事实上，由于任何机器学习模型的主要目标都是对新的、前所未见的数据进行准确预测，因此根据算法在测试集而不是训练集上的性能来调整算法的参数是至关重要的，以避免过度拟合。</p><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="f599" class="md me jj lz b gy mf mg l mh mi">import tensorflow as tf<br/>from tensorflow.python.keras.models import Sequential<br/>from tensorflow.python.keras.layers import InputLayer, Input<br/>from tensorflow.python.keras.layers import Reshape, MaxPooling2D<br/>from tensorflow.python.keras.layers import Conv2D, Dense, Flatten, Activation, Dropout<br/>from tensorflow.python.keras.optimizers import SGD</span><span id="d19a" class="md me jj lz b gy mj mg l mh mi">#diseabling eager execution<br/>from tensorflow.python.framework.ops import disable_eager_execution<br/>disable_eager_execution()</span><span id="5d8c" class="md me jj lz b gy mj mg l mh mi">import pandas as pd<br/>from sklearn.model_selection import train_test_split</span><span id="fa9a" class="md me jj lz b gy mj mg l mh mi">train, test = train_test_split(df_factor, test_size=0.2)</span><span id="61f5" class="md me jj lz b gy mj mg l mh mi">vectorizer_nn = TfidfVectorizer(ngram_range = (1, 2), min_df = 0.001, max_df = 0.25, stop_words = 'english')</span><span id="cbb6" class="md me jj lz b gy mj mg l mh mi">X_train_nn = vectorizer_nn.fit_transform(train.Lemmas)<br/>X_test_nn = vectorizer_nn.transform(test.Lemmas)</span><span id="04ee" class="md me jj lz b gy mj mg l mh mi">y_train = train.drop(["Clothing ID", "Age", "Title", "Review Text", "Rating", "Recommended IND", "Lemmas", "Positive Feedback Count", "Division Name", "Department Name", "Class Name"], axis = 1)<br/>y_test = test.drop(["Clothing ID", "Age", "Title", "Review Text", "Rating", "Recommended IND", "Lemmas", "Positive Feedback Count", "Division Name", "Department Name", "Class Name"], axis = 1)</span></pre><p id="bb30" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">注意:在导入必要的模块时，我编写了“tensorflow.python.keras.models”代码，因为这是存储模块的路径。在输入之前，请确保检索TensorFlow模块的正确路径。</p><p id="9c64" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在让我们建立我们的模型。这个想法是初始化一个空模型，用Sequential()，然后添加许多隐藏层，用dropout选项来避免过度拟合，最后，用softmax函数激活层。</p><p id="4c33" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">(注:如果你有兴趣了解更多关于神经网络的参数和超参数，可以在这里阅读我以前的文章<a class="ae jg" rel="noopener" target="_blank" href="/neural-networks-parameters-hyperparameters-and-optimization-strategies-3f0842fac0a5">。)</a></p><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="3198" class="md me jj lz b gy mf mg l mh mi">model = Sequential()<br/>model.add(Dense(5000, activation='relu', input_dim = X_train_nn.shape[1]))<br/>model.add(Dropout(0.1))<br/>model.add(Dense(600, activation='relu'))<br/>model.add(Dropout(0.1))<br/>model.add(Dense(200, activation='relu'))<br/>model.add(Dropout(0.1))<br/>model.add(Dense(y_train.shape[1], activation='softmax'))</span><span id="715a" class="md me jj lz b gy mj mg l mh mi">sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)<br/>model.compile(loss='categorical_crossentropy',<br/>              optimizer=sgd,<br/>              metrics=['accuracy',])</span><span id="1184" class="md me jj lz b gy mj mg l mh mi">score = model.evaluate(X_test_nn, y_test, batch_size = 7000)<br/>score</span></pre><figure class="lu lv lw lx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mm"><img src="../Images/800005df43f1e8882c41f691857fb104.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IYByxS0QCVSN9-7B28beYw.png"/></div></div></figure><figure class="lu lv lw lx gt iv gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/d81a0db3326507fb1232440140a3ba16.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*guTF2akuYjNDP7AOEeBUeA.png"/></div></figure><p id="47c3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如你所看到的，我们最终得到了一个准确率为54.36%的模型，这并不是那么糟糕，但仍然太低，不能作为一个可靠的预测指标。我们能做得比这更好吗？好吧，如果我们让病人用我们的神经网络玩一点甜菜，我们可以尝试不同的组合，看看结果。</p><p id="d308" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">令人欣慰的是，Keras是一个强大的工具，因为它提供了一个简单的界面。我们还可以绘制培训和测试过程的历史，如下所示:</p><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="9e66" class="md me jj lz b gy mf mg l mh mi">import matplotlib.pyplot as plt</span><span id="c169" class="md me jj lz b gy mj mg l mh mi">history = model.fit(X_train_nn, y_train, validation_split=0.25, epochs = 10, batch_size = 7000, verbose=1)</span><span id="1412" class="md me jj lz b gy mj mg l mh mi"># Plot training &amp; validation accuracy values<br/>plt.plot(history.history['accuracy'])<br/>plt.plot(history.history['val_accuracy'])<br/>plt.title('Model accuracy')<br/>plt.ylabel('Accuracy')<br/>plt.xlabel('Epoch')<br/>plt.legend(['Train', 'Test'], loc='upper left')<br/>plt.show()</span><span id="952a" class="md me jj lz b gy mj mg l mh mi"># Plot training &amp; validation loss values<br/>plt.plot(history.history['loss'])<br/>plt.plot(history.history['val_loss'])<br/>plt.title('Model loss')<br/>plt.ylabel('Loss')<br/>plt.xlabel('Epoch')<br/>plt.legend(['Train', 'Test'], loc='upper left')<br/>plt.show()</span></pre><figure class="lu lv lw lx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mo"><img src="../Images/719d2568e986f5297ff3b0195cc3f559.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d-Mq_Z7UUHHjn9wmyLDAKA.png"/></div></div></figure><p id="818e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">本文并不是关于Keras的详尽指南，但它是一个例子，说明了如何轻松实现Keras模块来完成这种任务。</p><p id="7a01" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你有兴趣了解更多关于Keras和神经网络的知识，我推荐以下读物:</p><ul class=""><li id="01bd" class="mp mq jj la b lb lc le lf lh mr ll ms lp mt lt mu mv mw mx bi translated"><a class="ae jg" href="https://keras.io/getting-started/sequential-model-guide/" rel="noopener ugc nofollow" target="_blank">https://keras.io/getting-started/sequential-model-guide/</a></li><li id="a278" class="mp mq jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">https://www.tensorflow.org/api_docs/python/tf<a class="ae jg" href="https://www.tensorflow.org/api_docs/python/tf" rel="noopener ugc nofollow" target="_blank"/></li><li id="0638" class="mp mq jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">【https://pathmind.com/wiki/neural-network T4】</li><li id="34bc" class="mp mq jj la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated"><a class="ae jg" href="https://medium.com/dataseries/understanding-the-maths-behind-neural-networks-108a4ad4d4db" rel="noopener">https://medium . com/data series/understanding-the-maths-behind-neural-networks-108 a4 ad 4d db</a></li></ul></div></div>    
</body>
</html>