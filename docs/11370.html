<html>
<head>
<title>Statistics for AI (Part 2 )</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能统计学(下)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/statistics-for-ai-part-2-43d81986c87c?source=collection_archive---------51-----------------------#2020-08-06">https://towardsdatascience.com/statistics-for-ai-part-2-43d81986c87c?source=collection_archive---------51-----------------------#2020-08-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2bdc" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">构成复杂算法基础的向量和矩阵概念</h2></div><p id="ec5f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">今天我打算讨论以下主题:线性独立性、特殊矩阵和矩阵分解。</p><h1 id="2eb1" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">线性独立性</h1><p id="3ca6" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">如果这些向量中没有一个可以写成其他向量的线性组合，那么这个向量集就是线性无关的。例如，V1=(1，0)和 V2=(0，1)。在这里，V2 不能用 V1 来写。然而，V3 (3，4)是线性相关的，因为 V3 可以表示为 3V1+4V2。</p><p id="c882" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">数学上，s={V1，V2，…。，Vn}线性无关当且仅当线性组合α1V1+α2V2+…..+αnVn=0 意味着所有αi=0。</p><h1 id="1cd5" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">矩阵运算</h1><p id="506d" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">矩阵可以将一个向量转换成另一个向量。例如，V 是 Nx1 向量，w 也是 Nx1 向量。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ly"><img src="../Images/2434bd14be40ef4b69c155110b6de8df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CamRNoRYh5scdGiFeovn7A.png"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">矩阵乘法通过保持形状，图像由作者</p></figure><h1 id="bfe0" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">矩阵的迹</h1><p id="4dd0" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">矩阵的迹由其对角元素的和给出。对于矩阵 A，其迹将是行和列具有相同值的所有元素的总和。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/5dd5007bf69047b2b99dce46e12aa5b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*e_0MdPyMaXnCy--5zPsN6g.png"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">矩阵的轨迹，作者的图像</p></figure><h1 id="be98" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">一些属性</h1><ol class=""><li id="2baf" class="mp mq iq kh b ki lt kl lu ko mr ks ms kw mt la mu mv mw mx bi translated">Tr(A+B) = Tr(A)+Tr(B)</li><li id="0e39" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated">Tr(AB) = Tr(BA)</li><li id="7eea" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated">Tr(A) = Tr(A.T) (A.T 表示矩阵 A 的转置)</li></ol><h1 id="810d" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">矩阵的行列式</h1><p id="1d63" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">NxN 矩阵的拉普拉斯展开由以下公式给出:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/8a037e699a63da49e90a9b98ef10d203.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*miojYzOBFLINxzPrPhyTSg.png"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">矩阵的行列式，作者图片</p></figure><p id="8be0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">行列式实际上表示由列向量形成的体积。对于 2x2 向量，它表示面积。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/748c4bf0ddf215d3f1caa234da4a2646.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*NjLDhZilZJjk3oPbFMxNew.png"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">解释空间中的 2x2 向量，图片由作者提供</p></figure><h1 id="35de" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">矩阵的可逆性</h1><p id="26fd" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">只有当 det(A)不为 0 时，矩阵 A 的逆矩阵才有可能。请注意，这自动意味着的列必须是线性独立的。考虑下面的矩阵。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/9aa413685c16ef497c918709cde7d831.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*62HSVbGeBFZRG79nDlkqCw.png"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">矩阵 A，作者图片</p></figure><p id="b446" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，V1、V2……，Vn 是向量，如果任何向量，比如说 Vn，可以写成其余向量的线性相关向量，比如 Vn=α1V1+α2V2+…..+αn-1Vn-1 然后，我们可以做一个简单的列操作，即最后一列=最后一列- (α1V1+α2V2+…..+αn-1Vn-1)，这将产生充满零的列。这会使矩阵的行列式为 0。对于一个 2x2 矩阵，我们将有两个向量 V1 和 V2。如果 V1 和 V2 是线性相关的，像 V1=2V2，那么由这两个向量形成的面积将为零。一个聪明的说法是，这两个向量相互平行。</p><h1 id="9468" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">特殊矩阵和向量</h1><ol class=""><li id="2128" class="mp mq iq kh b ki lt kl lu ko mr ks ms kw mt la mu mv mw mx bi translated">对角矩阵:只有对角元素不为零，其余所有元素为零。如果 I 不等于 j，则 D(i，j) = 0。</li><li id="61a6" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated">对称矩阵:如果一个矩阵及其转置矩阵相等，则称该矩阵对称。</li><li id="d2da" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated">单位向量:具有单位长度的向量。向量的 2-范数是 1。</li><li id="f9a7" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated">正交向量:如果(X.T)Y = 0，则两个向量 X 和 Y 是正交的</li><li id="d21b" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated">正交矩阵:如果一个矩阵的转置等于它的逆矩阵，那么我们可以说这个矩阵是正交的。此外，所有列都是正交的。正交矩阵可用于旋转保持体积的向量。</li><li id="10c0" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated">标准正交矩阵:如果一个矩阵的逆矩阵等于它的单位行列式转置矩阵，则称这个矩阵是标准正交的。</li></ol><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/cd3c4431e6cd5cbe398ab6cb27e32e8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:594/format:webp/1*t-rIMPunhQMIxk_B7pQrKA.png"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">正交矩阵，作者图片</p></figure><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/75ac31f34bd4ce34f945bc5a009ba394.png" data-original-src="https://miro.medium.com/v2/resize:fit:834/format:webp/1*ZRSfMYdOKDFHZoudhuoQVw.png"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">正交矩阵，作者图片</p></figure><h1 id="c3fa" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">特征分解</h1><p id="0435" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">特征分解对于正方形对称矩阵非常有用。让我们看看这个术语的物理意义。</p><p id="62d0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">每一个实矩阵都可以认为是旋转和拉伸的组合。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/e2567e2cf58b07a139fafb8f2bbda7a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*5b6d7Brkek0EeJHhILa7ww.png"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">向量乘法，作者图片</p></figure><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/b6866b518247577fcc8dcf2f10a73fd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:444/format:webp/1*kF7-MqI1xTh5d7RSfI4Kbw.png"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">对向量 v 进行运算，生成向量 w，由作者生成图像</p></figure><p id="a661" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里，A 可以被认为是一个算子，它拉伸并旋转一个向量 v 以获得一个新的向量 w。矩阵的特征向量是那些只在矩阵的作用下拉伸的特殊向量。特征值是特征向量拉伸的因子。在下面的等式中，当与特征向量 a 一起操作时，向量 v 被拉伸了λ的值</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/4da18dfa758e8d8e79512a817c021f5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*J9ZUH8DbnKyqv0yoZXRPyQ.png"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">向量 v 的特征值λ，图片作者</p></figure><p id="e295" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">比如说，A 有 n 个线性无关的特征向量{V1，V2，…..，Vn}。将所有向量串联成一列，我们得到一个特征向量矩阵 V，其中 V=[V1，V2，…..，Vn】。如果我们将相应的特征值连接成一个对角矩阵，即λ<strong class="kh ir">=</strong>diag(λ1，λ2，…，λn)，我们得到 A 的特征分解(因式分解)如下:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/3d3fd1b6bc1cfe5b8466640e518eb756.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*Vx_yhfuEHhyOvYAYEzae5w.png"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">作者图像的特征分解</p></figure><p id="79a1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">实对称矩阵有实特征向量和实特征值。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/b69f5ee708bc426812ea06781fbf9e2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*Kf4wLgk7_ml1LG2D4sNdjA.png"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">实对称矩阵，图像 y 作者</p></figure><h1 id="21d1" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">二次型与正定矩阵</h1><p id="7758" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">二次型可以解释为“加权”长度。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi nn"><img src="../Images/7cc89dd6fa781ec1ffce2f8aa3744368.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pgnVsZuiBZkJYKsbSXbG-A.png"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">二次型，作者图片</p></figure><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi no"><img src="../Images/763109da0cc0d2a32992a201ea72fd2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1302/format:webp/1*NimRRTi_7AJ6IUjbY5C1zA.png"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">二次型，作者图片</p></figure><p id="5e52" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正定(PD)矩阵的所有特征值都大于零。半正定(PSD)矩阵具有大于等于零的特征值。PD 矩阵具有对于所有 X，(X.T)AX 大于 0 的性质。例如，如果 A=I 或单位矩阵，则(X.T)I(X)=(X.T)(X)大于 0。PSD 矩阵具有对于所有 X，(X.T)AX 大于等于 0 的性质。类似地，负定(ND)矩阵的所有特征值都小于零。半负定(PD)矩阵的所有特征值都小于等于零。</p><h1 id="cf47" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">奇异值分解</h1><p id="2a9c" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">如果 A 是一个 MxN 矩阵，那么</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi np"><img src="../Images/586adc50fb1a52d27d6f50c092f29db6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4KINnDzrqc6_I_q1gu4qdA.png"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">奇异值分解，作者图片</p></figure><ol class=""><li id="c9f2" class="mp mq iq kh b ki kj kl km ko nq ks nr kw ns la mu mv mw mx bi translated">u 是一个 MxM 矩阵并且是正交的</li><li id="3286" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated">v 是一个 NxN 矩阵并且是正交的</li><li id="d571" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated">d 是一个 MxN 矩阵和对角线</li><li id="0046" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated">U 的元素是 A(A.T)的特征向量，称为左奇异向量</li><li id="3c46" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated">(A.T)A 的特征向量，称为右奇异向量</li><li id="0ac4" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated">D 的非零元素是平方根(λ((A.T)(A)))，这意味着(A.T)(A)的特征值的平方根，称为奇异值</li></ol><h1 id="284e" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">结束</h1><p id="13b0" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">谢谢，请继续关注更多关于人工智能的博客。</p></div></div>    
</body>
</html>