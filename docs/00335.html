<html>
<head>
<title>Using MALLET LDA to Learn Why Players Hate Pokémon Sword /Shield</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 MALLET LDA 了解玩家讨厌神奇宝贝剑/盾的原因</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-mallet-lda-to-learn-why-players-hate-pok%C3%A9mon-sword-shield-23b12e4fc395?source=collection_archive---------23-----------------------#2020-01-10">https://towardsdatascience.com/using-mallet-lda-to-learn-why-players-hate-pok%C3%A9mon-sword-shield-23b12e4fc395?source=collection_archive---------23-----------------------#2020-01-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="c344" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">简单介绍 MALLET LDA 如何用于主题模型，解释玩家不喜欢神奇宝贝剑/盾的原因。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/81d28346914e55c2b7058b58048c860a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ffyusYFDm6xtXOyY"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae kv" href="https://unsplash.com/@16bitspixelz?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Kamil S </a>拍摄的照片</p></figure><p id="7239" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">任天堂 Switch 最新的神奇宝贝游戏大张旗鼓地推出了，承诺用令人惊叹的视觉效果和开放世界的冒险让粉丝们惊叹不已。尽管受到了评论家的赞扬，但这场比赛还是让大多数玩家失望了。在这篇文章中，我将带你了解我如何使用<a class="ae kv" href="http://mallet.cs.umass.edu/" rel="noopener ugc nofollow" target="_blank">槌潜狄利克雷分配(LDA) </a>来找出玩家不喜欢这个游戏的关键原因。</p><h2 id="1a93" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">数据收集</h2><p id="e743" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">我用 BeautifulSoup 从 Metacritic 上报废了 Pokémon <a class="ae kv" href="https://www.metacritic.com/game/switch/pokemon-sword/user-reviews" rel="noopener ugc nofollow" target="_blank">剑</a>和<a class="ae kv" href="https://www.metacritic.com/game/switch/pokemon-shield/user-reviews" rel="noopener ugc nofollow" target="_blank">盾</a>用户评论(我已经在这里详述了步骤<a class="ae kv" rel="noopener" target="_blank" href="/web-scraping-metacritic-reviews-using-beautifulsoup-63801bbe200e">)。Metacritic 评论有评级分数，表明用户对游戏的总体评价。这让我们的生活更轻松，因为我们不需要运行一个单独的情绪分析来寻找负面评论。</a></p><p id="0e7b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我总共收集了 2019 年 11 月 15 日至 28 日发布的 3，261 条用户评论。数据集包含以下特征:</p><ul class=""><li id="0629" class="mq mr iq ky b kz la lc ld lf ms lj mt ln mu lr mv mw mx my bi translated"><em class="mz">姓名</em>:审核人的用户名</li><li id="2a35" class="mq mr iq ky b kz na lc nb lf nc lj nd ln ne lr mv mw mx my bi translated"><em class="mz">日期</em>:审核日期</li><li id="c8f5" class="mq mr iq ky b kz na lc nb lf nc lj nd ln ne lr mv mw mx my bi translated"><em class="mz">评分</em>:从 0 到 10 的数字分数，给出游戏的总体评价。较高的分数意味着更积极的体验。</li><li id="9e50" class="mq mr iq ky b kz na lc nb lf nc lj nd ln ne lr mv mw mx my bi translated"><em class="mz">评审</em>:实际评审文本</li></ul><h2 id="5f26" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">包装</h2><p id="5df9" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">以下软件包用于数据清理和分析:numpy、pandas、regex、string、nltk、langdetect、sklearn、spaCy、gensim、pprint(可选)、matplotlib 和 collections。</p><p id="7728" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你还需要<a class="ae kv" href="https://radimrehurek.com/gensim/models/wrappers/ldamallet.html" rel="noopener ugc nofollow" target="_blank">安装</a> gensim 的 MALLET LDA 的包装器，如果你还没有的话。</p><p id="05e2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">导入日志记录也是可选的，但这是一个最佳实践，因为它使您能够了解模型运行时幕后发生的事情。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="9884" class="ls lt iq ng b gy nk nl l nm nn">import numpy as np <br/>import pandas as pd</span><span id="b241" class="ls lt iq ng b gy no nl l nm nn">import re <br/>import string</span><span id="0e5c" class="ls lt iq ng b gy no nl l nm nn">import nltk</span><span id="49ce" class="ls lt iq ng b gy no nl l nm nn">from langdetect import detect</span><span id="e9fd" class="ls lt iq ng b gy no nl l nm nn">from sklearn.feature_extraction.text import CountVectorizer </span><span id="a761" class="ls lt iq ng b gy no nl l nm nn">import spacy<br/>from spacy.lang.en.stop_words import STOP_WORDS</span><span id="fe2f" class="ls lt iq ng b gy no nl l nm nn">import gensim<br/>from gensim import corpora, models, matutils<br/>from gensim.models import CoherenceModel</span><span id="9c26" class="ls lt iq ng b gy no nl l nm nn">import os<br/>from gensim.models.wrappers import LdaMallet</span><span id="a385" class="ls lt iq ng b gy no nl l nm nn">mallet_path = '/Users/adelweiss/mallet-2.0.8/bin/mallet'</span><span id="c860" class="ls lt iq ng b gy no nl l nm nn">from pprint import pprint #optional</span><span id="21a1" class="ls lt iq ng b gy no nl l nm nn">import matplotlib.pyplot as plt<br/>%matplotlib inline</span><span id="2f4c" class="ls lt iq ng b gy no nl l nm nn">from collections import Counter</span><span id="816a" class="ls lt iq ng b gy no nl l nm nn">import logging #optional<br/>logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)</span></pre><h2 id="ebe3" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">特征工程</h2><ol class=""><li id="e88b" class="mq mr iq ky b kz ml lc mm lf np lj nq ln nr lr ns mw mx my bi translated">给评论贴上正面、负面或褒贬不一的标签。Metacritic 将低于 5 的分数视为负面，将 5 到 7 的分数视为混合分数，将高于 7 的分数视为正面。在下面的代码中，我定义了一个函数来根据这些规则标记评论。</li></ol><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="c909" class="ls lt iq ng b gy nk nl l nm nn">def sentiment(x):<br/>    if x &gt; 7:<br/>        return 'positive'<br/>    if x &lt; 5:<br/>        return 'negative'<br/>    else: return 'mixed'</span><span id="a7b4" class="ls lt iq ng b gy no nl l nm nn">df['sentiment'] = df['rating'].apply(lambda x:sentiment(x))</span></pre><h2 id="5d17" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">数据清理</h2><ol class=""><li id="65d5" class="mq mr iq ky b kz ml lc mm lf np lj nq ln nr lr ns mw mx my bi translated"><strong class="ky ir">删除重复的用户评论。</strong>一些用户对《神奇宝贝之剑》和《盾牌》发表了相同的评论(这是意料之中的，因为这两款游戏在内容上仅略有不同)。</li></ol><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="b1cf" class="ls lt iq ng b gy nk nl l nm nn">df.drop_duplicates(subset='name', keep = 'first', inplace = True)</span></pre><p id="b380" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">2.<strong class="ky ir">过滤掉非英文评论。</strong> <em class="mz"> </em>为了做到这一点，我使用了<em class="mz"> langdetect </em>包，它依赖于 Google 的语言检测库，支持 55 种语言。<em class="mz"> detect </em>函数读取文本输入，计算文本使用支持语言的概率，并返回概率最高的语言。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="e196" class="ls lt iq ng b gy nk nl l nm nn">def language_detection(x): <br/> result = detect(x)<br/> if result == 'en':return x <br/> else: return np.NaN <br/> <br/>df['review'] = df['review'].apply(lambda x:language_detection(x))</span></pre><p id="2a1f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">3.<strong class="ky ir">删除停用词。</strong> <em class="mz"> </em>我结合了 nltk 和 spaCy 的停用词，加入了‘游戏’、‘口袋妖怪’、‘神奇宝贝’等自定义停用词。</p><p id="b395" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在检查每个单词的评论频率后添加自定义停用词(例如，频率为 5 表示该单词出现在 5 次评论中。在第 6 步中会有更多的介绍。).自定义停用词出现在大多数评论中。它们在评论中的高频率意味着它们对主题建模没有用。因此，我在后续运行中删除了它们，以提高模型性能。</p><p id="6931" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该代码创建了一个停用词列表。这些词将在下一步从评论中删除。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="dacf" class="ls lt iq ng b gy nk nl l nm nn">nltk_stop_words = nltk.corpus.stopwords.words('english')</span><span id="118b" class="ls lt iq ng b gy no nl l nm nn">stop_words = list(STOP_WORDS)<br/>stop_words.extend(['game','pokemon','pokémon']) <br/>### these are common words that appear in almost all reviews</span><span id="a6be" class="ls lt iq ng b gy no nl l nm nn">for word in nltk_stop_words:<br/> if word in stop_words: continue<br/> else: stop_words.append(word)</span></pre><p id="6790" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">4.<strong class="ky ir">文字清理。</strong>这是主要使用正则表达式的标准文本清理步骤列表:</p><ul class=""><li id="1546" class="mq mr iq ky b kz la lc ld lf ms lj mt ln mu lr mv mw mx my bi translated">将所有单词转换成小写</li><li id="6448" class="mq mr iq ky b kz na lc nb lf nc lj nd ln ne lr mv mw mx my bi translated">从列表中删除单词(我们将使用它来删除停用词，以及出现在少于 4 条评论中的罕见单词)</li><li id="729a" class="mq mr iq ky b kz na lc nb lf nc lj nd ln ne lr mv mw mx my bi translated">删除数字</li><li id="2086" class="mq mr iq ky b kz na lc nb lf nc lj nd ln ne lr mv mw mx my bi translated">删除标点符号</li><li id="2a89" class="mq mr iq ky b kz na lc nb lf nc lj nd ln ne lr mv mw mx my bi translated">替换单词(标准化我注意到的拼写不一致，如“游戏狂”和“游戏怪胎”)</li><li id="2666" class="mq mr iq ky b kz na lc nb lf nc lj nd ln ne lr mv mw mx my bi translated">移除“\r”字符串文字</li><li id="709f" class="mq mr iq ky b kz na lc nb lf nc lj nd ln ne lr mv mw mx my bi translated">从单词中去除多余的空格(即一行中有两个空格)，这是由删除数字、标点符号和字符串文字的函数产生的</li></ul><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="a173" class="ls lt iq ng b gy nk nl l nm nn">def make_lower(text):<br/> return text.lower()</span><span id="e6d0" class="ls lt iq ng b gy no nl l nm nn">def remove_words(text,wordlist):<br/> for word in wordlist:<br/> if word in text.split():<br/>     text = re.sub(r'\b{}\b'.format(word), '', text) <br/> return text</span><span id="9b93" class="ls lt iq ng b gy no nl l nm nn">def remove_digits(text):<br/> return re.sub('\d', ' ', text)</span><span id="c9c1" class="ls lt iq ng b gy no nl l nm nn">def remove_punctuation(text):<br/> text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text) <br/> return re.sub(r'[^\w\s]', ' ', text)</span><span id="dc12" class="ls lt iq ng b gy no nl l nm nn">def strip_extraspace(text):<br/> return re.sub('\s\s+',' ', text)</span><span id="8f45" class="ls lt iq ng b gy no nl l nm nn">def replace_word(text,word,replacement):<br/> return text.replace(word,replacement)</span><span id="70ac" class="ls lt iq ng b gy no nl l nm nn">def remove_r(text):<br/> return text.replace('\r',' ')<br/>#df['review'] = df['review'].apply(lambda x:remove_punctuation(x))</span><span id="a249" class="ls lt iq ng b gy no nl l nm nn">def clean_text(text):<br/> text = make_lower(text)<br/> text = remove_punctuation(text)<br/> text = remove_digits(text)<br/> text = replace_word(text,'game freak','gamefreak') <br/> text = replace_word(text, 'game play', 'gameplay')<br/> text = remove_words(text,stop_words)<br/> text = remove_r(text)<br/> text = strip_extraspace(text)<br/> return text</span><span id="7a3a" class="ls lt iq ng b gy no nl l nm nn">df['review'] = df['review'].apply(lambda x:clean_text(x))</span></pre><p id="87d6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">5.<strong class="ky ir">词汇化</strong>。我使用 spaCy 的词类标注分类器来减少对名词和动词的评论。只使用名词和动词更容易辨别主题是关于什么的。</p><p id="14f4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面的代码遍历评论中的每个单词，并返回标记为“名词”或“动词”的单词。它会跳过已被词条化为“-PRON-”的单词(当单词是代词时，spaCy 会返回这个词)，以及停用词列表中已被词条化的单词。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="d6f9" class="ls lt iq ng b gy nk nl l nm nn">sp = spacy.load('en_core_web_sm')</span><span id="bde4" class="ls lt iq ng b gy no nl l nm nn">def lemmatize_words(text, allowed_postags=['NOUN', 'ADJ', 'VERB', ‘ADV’]):<br/> text = sp(text)<br/> lemmed_string =''<br/> for word in text:<br/>     if word.pos_ in allowed_postags:<br/>         if word.lemma_ == '-PRON-' or word.lemma_ in stop_words: <br/> ### skip words that are not in allowed postags or becomes a    stopword when lemmatised <br/>             continue <br/>         else: lemmed_string = lemmed_string+' '+word.lemma_<br/>     return lemmed_string.lstrip()</span><span id="9292" class="ls lt iq ng b gy no nl l nm nn">df['review'] = df['review'].apply(lambda x:lemmatize_words(x, allowed_postags=['NOUN', 'VERB']))</span></pre><p id="b04b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">6.<strong class="ky ir">去除生僻字。</strong>没有出现在大量评论中的罕见单词对于主题建模也是无用的。与停用词一样，我删除了它们以提高模型性能。</p><p id="f411" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这段代码计算一个单词在评论中出现的次数，并将出现次数少于 4 次的评论添加到一个列表中。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="1561" class="ls lt iq ng b gy nk nl l nm nn">word_frequency = Counter()</span><span id="0316" class="ls lt iq ng b gy no nl l nm nn">for text in df.review:<br/> text = text.split()<br/> word_frequency.update(set(text))</span><span id="1e89" class="ls lt iq ng b gy no nl l nm nn">rare_words = []</span><span id="12c2" class="ls lt iq ng b gy no nl l nm nn">for key, value in word_frequency.items():<br/> if value &lt; 4:<br/> rare_words.append(key)</span><span id="cb7d" class="ls lt iq ng b gy no nl l nm nn">df['review'] = df['review'].apply(lambda x:remove_words(x,rare_words))</span></pre><p id="57d1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">7.仅选择负面评论，并创建令牌。最后，由于我们只对负面评论感兴趣，我根据评论的情感标签过滤了评论，并应用<em class="mz"> sklearn 的计数矢量器</em>来创建单词标记。</p><p id="63c2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="mz"> CountVectorizer 的 token_pattern </em>参数指定只包含至少 3 个字符的单词。我的假设是 1 和 2 个字母的单词信息不多，对主题建模用处不大。另外，<em class="mz"> ngram_range </em>参数被设置为(1，2)以包含二元模型作为标记。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="1e17" class="ls lt iq ng b gy nk nl l nm nn">negative = df[df['sentiment']=='negative']</span><span id="c3c0" class="ls lt iq ng b gy no nl l nm nn">vectorizer = CountVectorizer(stop_words=stop_words, ngram_range = (1,2), token_pattern="\\b[a-z][a-z][a-z]+\\b") </span></pre><h2 id="2aa2" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">为 MALLET LDA 奠定基础</h2><p id="3c12" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">要使用 MALLET LDA，我们需要使用矢量器拟合和转换数据，并创建模型需要的一些变量。首先，我们将<em class="mz">计数矢量器</em>与负面评论相匹配。然后，我们创建一个文档-单词矩阵，并将其从稀疏矩阵转换为 gensim 单词语料库。接下来，我们创建<em class="mz"> word2id </em>和<em class="mz"> id2word </em>变量，将单词与其数字令牌 id 进行匹配，反之亦然，并将这些变量保存到字典中。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="19f0" class="ls lt iq ng b gy nk nl l nm nn">vectorizer.fit(negative.review)<br/>doc_word = vectorizer.transform(negative.review).transpose()</span><span id="e6b6" class="ls lt iq ng b gy no nl l nm nn">corpus = matutils.Sparse2Corpus(doc_word)</span><span id="2b86" class="ls lt iq ng b gy no nl l nm nn">word2id = dict((v, k) for v, k in vectorizer.vocabulary_.items())<br/>id2word = dict((v, k) for k, v in vectorizer.vocabulary_.items())</span><span id="091c" class="ls lt iq ng b gy no nl l nm nn">dictionary = corpora.Dictionary()<br/>dictionary.id2token = id2word<br/>dictionary.token2id = word2id</span></pre><h2 id="79b0" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">选择主题的数量</h2><p id="9f94" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">为了选择主题的数量，我们将计算每个指定数量的主题的一致性分数。</p><p id="a6b6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">连贯性分数通过检查每个主题的热门单词之间的语义相似度来评估主题的质量。分数越高，模型越好。</p><p id="969c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了计算每个模式的一致性分数，我使用了下面的代码，我在第 17 节的中找到了<a class="ae kv" href="https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#14computemodelperplexityandcoherencescore" rel="noopener ugc nofollow" target="_blank">。代码循环遍历一系列数字，代表应用于模型的主题数量，计算每个模型的一致性分数，保存分数并绘制它们。</a></p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="ddcc" class="ls lt iq ng b gy nk nl l nm nn">def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):<br/>    """<br/>    Compute c_v coherence for various number of topics<br/><br/>    Parameters:<br/>    ----------<br/>    dictionary : Gensim dictionary<br/>    corpus : Gensim corpus<br/>    texts : List of input texts<br/>    limit : Max num of topics<br/><br/>    Returns:<br/>    -------<br/>    model_list : List of LDA topic models<br/>    coherence_values : Coherence values corresponding to the LDA model with respective number of topics<br/>    """<br/>    coherence_values = []<br/>    model_list = []<br/>    for num_topics in range(start, limit, step):<br/>        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)<br/>        model_list.append(model)<br/>        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')<br/>        coherence_values.append(coherencemodel.get_coherence())<br/><br/>    return model_list, coherence_values</span><span id="30d2" class="ls lt iq ng b gy no nl l nm nn"># Can take a long time to run.<br/>model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=2, limit=40, step=6)</span><span id="2cc5" class="ls lt iq ng b gy no nl l nm nn"># Show graph<br/>limit=40; start=2; step=6;<br/>x = range(start, limit, step)<br/>plt.plot(x, coherence_values)<br/>plt.xlabel("Num Topics")<br/>plt.ylabel("Coherence score")<br/>plt.legend(("coherence_values"), loc='best')<br/>plt.show()</span></pre><p id="4576" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">根据图表，2 或 5 是可供选择的好数字，因为它们的一致性得分最高。然而，选择 2 个主题可能会过于简单，所以我们选择 5 个。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/75fef0fede92662746c21ed2c73243c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X5XwYAr5Z9ld0Om7YRngrQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">描述 MALLET LDA 在多个主题上的一致性分数的图表</p></figure><h2 id="ee8b" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">探索主题</h2><p id="ae55" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">为了查看与每个主题最相关的前 10 个单词，我们重新运行指定 5 个主题的模型，并使用<em class="mz"> show_topics。你可以使用一个简单的 print 语句来代替，但是 pprint 让事情更容易阅读。</em></p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="7ecc" class="ls lt iq ng b gy nk nl l nm nn">ldamallet = LdaMallet(mallet_path, corpus=corpus, num_topics=5, id2word=id2word, random_seed = 77)</span><span id="546a" class="ls lt iq ng b gy no nl l nm nn"># Show Topics<br/>pprint(ldamallet.show_topics(formatted=False))</span></pre><p id="9ba4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面是每个话题的热门词汇，以及我给它们的标签。大部分话题都和游戏性有关，除了最后一个。因为我们只看了负面评论，我们可以假设这些是问题领域。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/abcf2c11ad68823000446ba6bb3916bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S__4w_KXG9RzdopehVS7zg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">表格描述了每个主题的前 10 个单词，以及建议的主题标签</p></figure><p id="3acc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">检查完评论后，下面是每个主题的快速概述:</p><ul class=""><li id="f5c0" class="mq mr iq ky b kz la lc ld lf ms lj mt ln mu lr mv mw mx my bi translated"><strong class="ky ir">时间:</strong>上场时间太短。许多玩家在 10 到 25 小时内完成了游戏</li><li id="93ba" class="mq mr iq ky b kz na lc nb lf nc lj nd ln ne lr mv mw mx my bi translated">体验:故事缺乏，整体游戏太简单。此外，大肆宣传的野生区域缺乏活力，而且大多是空的。</li><li id="e014" class="mq mr iq ky b kz na lc nb lf nc lj nd ln ne lr mv mw mx my bi translated"><strong class="ky ir">视觉效果:</strong>动画、图形和模型缺乏质量和质感。对视觉效果的期望非常高，因为游戏狂认为这是从游戏中删除这么多神奇宝贝的原因。</li><li id="5779" class="mq mr iq ky b kz na lc nb lf nc lj nd ln ne lr mv mw mx my bi translated"><strong class="ky ir">内容</strong>:玩家经常将 switch 游戏与 3DS 游戏相比较，后者有更多的功能、内容和可用的神奇宝贝。</li><li id="b172" class="mq mr iq ky b kz na lc nb lf nc lj nd ln ne lr mv mw mx my bi translated">开发者:玩家们感觉被 Game Freak 背叛了，因为它并没有兑现其承诺的惊人的视觉效果。他们觉得《游戏怪胎》欺骗了他们，而且《神奇宝贝》的删减是不合理的。</li></ul><h2 id="0f89" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">结论</h2><p id="207f" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">LDA 是一种在文本中寻找主题的好方法，尤其是当它用于探索性目的时。我认为 MALLET LDA 很好地概括了为什么玩家讨厌这个游戏。我快速浏览了一下正面评论，发现了两个广泛的话题:游戏性和正面感受。也许，这可能是在 switch 上开始玩神奇宝贝的新玩家(因此使用 Let's Go 作为基准)与更习惯复杂游戏的经验丰富的玩家之间的情况。</p><p id="0f06" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">**代码可在此处找到<a class="ae kv" href="https://github.com/adelweiss/Pokemon/tree/master" rel="noopener ugc nofollow" target="_blank"/>* *</p></div></div>    
</body>
</html>