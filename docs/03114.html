<html>
<head>
<title>How to Use DBSCAN Effectively</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何有效地使用 DBSCAN</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-use-dbscan-effectively-ed212c02e62?source=collection_archive---------3-----------------------#2020-03-25">https://towardsdatascience.com/how-to-use-dbscan-effectively-ed212c02e62?source=collection_archive---------3-----------------------#2020-03-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c524" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">有效使用最常引用的聚类算法的完整指南</h2></div><p id="af73" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><a class="ae ki" href="https://dl.acm.org/doi/10.5555/3001460.3001507" rel="noopener ugc nofollow" target="_blank"> DBSCAN </a>是一个极其强大的聚类算法。首字母缩写代表<strong class="kl iu">带噪声应用的基于密度的空间聚类</strong>。顾名思义，该算法使用密度来聚集空间中的点以形成簇。该算法一旦被正确实现就可以非常快。然而，在本文中，我们更愿意讨论优化 DBSCAN 的参数，以获得比算法实现本身更好的效用。(DBSCAN 的实现非常简单。更难的部分，如果有的话，将是为邻居查找结构化数据。)</p><p id="4cf5" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">在我们开始之前，确保你手头有这些包裹。</p><pre class="lf lg lh li gt lj lk ll lm aw ln bi"><span id="f779" class="lo lp it lk b gy lq lr l ls lt">numpy<br/>sklearn<br/>matplotlib # for visualization<br/>seabron # for pretty visualizations<br/>kneed # for our computations</span></pre><h1 id="cabe" class="lu lp it bd lv lw lx ly lz ma mb mc md jz me ka mf kc mg kd mh kf mi kg mj mk bi translated">连续的例子</h1><p id="42d0" class="pw-post-body-paragraph kj kk it kl b km ml ju ko kp mm jx kr ks mn ku kv kw mo ky kz la mp lc ld le im bi translated">让我们首先创建一组数据，它可以复制一组适合我们分析的数据点。Python 对它的类库非常慷慨。为了生成数据，我们将使用<strong class="kl iu"> sci-kit learn </strong>库的<strong class="kl iu"> make blobs </strong>函数。</p><pre class="lf lg lh li gt lj lk ll lm aw ln bi"><span id="6852" class="lo lp it lk b gy lq lr l ls lt">from sklearn.datasets import make_blobs<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>import numpy as np</span><span id="91dd" class="lo lp it lk b gy mq lr l ls lt">centers = [[1, 0.5], [2, 2], [1, -1]]<br/>stds = [0.1, 0.4, 0.3]<br/>X, labels_true = make_blobs(n_samples=1000, centers=centers, cluster_std=stds, random_state=0)</span><span id="1a4a" class="lo lp it lk b gy mq lr l ls lt">fig = plt.figure(figsize=(10, 10))<br/>sns.scatterplot(X[:,0], X[:,1], hue=["cluster-{}".format(x) for x in labels_true])</span></pre><p id="5628" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">在这里，我创建了 3 个数据块。我们可以看到这些数据块的可视化，如图 1 所示。在这个例子中，我故意创建了 3 个不同密度的集群来增加集群的难度。</p><figure class="lf lg lh li gt ms gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi mr"><img src="../Images/496c7b88dcc4a01bcba5a3c655efe335.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TKTPIW8zH6ztYr_xx0beGA.png"/></div></div><p class="mz na gj gh gi nb nc bd b be z dk translated">图一。原始集群的可视化</p></figure><h1 id="ed5d" class="lu lp it bd lv lw lx ly lz ma mb mc md jz me ka mf kc mg kd mh kf mi kg mj mk bi translated">DBSCAN 及其参数</h1><p id="0d7f" class="pw-post-body-paragraph kj kk it kl b km ml ju ko kp mm jx kr ks mn ku kv kw mo ky kz la mp lc ld le im bi translated">DBSCAN 有几个参数，其中有两个非常重要。第一个是<strong class="kl iu"> <em class="nd"> eps </em> </strong>参数，另一个是<strong class="kl iu"><em class="nd">min _ points(min _ samples)</em></strong>。后者指的是将一个点视为密集区域或有效聚类所需的相邻点的数量。通常，我们将其设置为对数据集和数据中存在的维度数量有意义的值。这将决定被识别的异常值的数量。不过这个参数没有<strong class="kl iu"> <em class="nd"> eps </em> </strong>那么关键。</p><h2 id="eec8" class="lo lp it bd lv ne nf dn lz ng nh dp md ks ni nj mf kw nk nl mh la nm nn mj no bi translated">DBSCAN 的ε参数</h2><p id="b3ca" class="pw-post-body-paragraph kj kk it kl b km ml ju ko kp mm jx kr ks mn ku kv kw mo ky kz la mp lc ld le im bi translated">DBSCAN 最重要的参数可以确定为<strong class="kl iu"> <em class="nd"> eps </em> </strong>。这是一个点选择其邻居的最远距离。因此，直觉上这将决定一个点将发现多少个邻居。虽然我们可以为 min_points/min_samples 提供一个默认值，但我们不能为 eps 提供默认值。这将取决于数据本身的分布。让我们用数据集的一些猜测值进行 DBSCAN。代码和可视化(图 2 中)如下所示。</p><pre class="lf lg lh li gt lj lk ll lm aw ln bi"><span id="b6b5" class="lo lp it lk b gy lq lr l ls lt">db = DBSCAN(eps=0.5, min_samples=10).fit(X)<br/>labels = db.labels_</span><span id="28c5" class="lo lp it lk b gy mq lr l ls lt">fig = plt.figure(figsize=(10, 10))<br/>sns.scatterplot(X[:,0], X[:,1], hue=["cluster-{}".format(x) for x in labels])</span></pre><figure class="lf lg lh li gt ms gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi mr"><img src="../Images/ccc46be09de7bc4446365c1ed5bf5220.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LtxOKx0xeNiblnCuVOFJDQ.png"/></div></div><p class="mz na gj gh gi nb nc bd b be z dk translated">图二。eps=0.5 时的 DBSCAN</p></figure><h1 id="3b15" class="lu lp it bd lv lw lx ly lz ma mb mc md jz me ka mf kc mg kd mh kf mi kg mj mk bi translated">调整 EPS 参数</h1><p id="b0c6" class="pw-post-body-paragraph kj kk it kl b km ml ju ko kp mm jx kr ks mn ku kv kw mo ky kz la mp lc ld le im bi translated">从上一张图中我们可以清楚地看到，两个集群已经合并在一起。这很糟糕。这种情况会降低真实集群应用程序的召回率。我们再来试试变<strong class="kl iu"> <em class="nd"> eps </em> </strong>集群。代码和可视化效果(如图 3 所示)如下所示。</p><pre class="lf lg lh li gt lj lk ll lm aw ln bi"><span id="c7eb" class="lo lp it lk b gy lq lr l ls lt">import numpy as np<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>from sklearn.cluster import DBSCAN</span><span id="e43e" class="lo lp it lk b gy mq lr l ls lt">fig = plt.figure(figsize=(20, 10))<br/>fig.subplots_adjust(hspace=.5, wspace=.2)<br/>i = 1</span><span id="49bd" class="lo lp it lk b gy mq lr l ls lt">for x in range(10, 0, -1):<br/>    eps = 1/(11-x)<br/>    db = DBSCAN(eps=eps, min_samples=10).fit(X)<br/>    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)<br/>    core_samples_mask[db.core_sample_indices_] = True<br/>    labels = db.labels_<br/>    <br/>    print(eps)<br/>    ax = fig.add_subplot(2, 5, i)<br/>    ax.text(1, 4, "eps = {}".format(round(eps, 1)), fontsize=25, ha="center")<br/>    sns.scatterplot(X[:,0], X[:,1], hue=["cluster-{}".format(x) for x in labels])<br/>    <br/>    i += 1</span></pre><figure class="lf lg lh li gt ms gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi np"><img src="../Images/5cd32335102771b6b0e4851783760c04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zj0qAtMDenWQg2LMrJyFxw.png"/></div></div><p class="mz na gj gh gi nb nc bd b be z dk translated">图三。不同<strong class="bd nq"> <em class="nr"> eps </em> </strong>值下的 DBSCAN</p></figure><p id="6981" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">可以看到我们在<strong class="kl iu"> <em class="nd"> eps=0.1 </em> </strong>和<strong class="kl iu"> <em class="nd"> eps=0.3 </em> </strong>之间打了一个甜蜜点。<strong class="kl iu"> eps </strong>小于该值的值有太多噪声或异常值(以绿色显示)。请注意，在图像中，我通过将代码中的分母从 10 增加到 1 来减少<strong class="kl iu"> <em class="nd"> eps </em> </strong>。我们怎样才能自动做到这一点？</p><h1 id="8996" class="lu lp it bd lv lw lx ly lz ma mb mc md jz me ka mf kc mg kd mh kf mi kg mj mk bi translated">调整每股收益值的系统方法</h1><p id="2433" class="pw-post-body-paragraph kj kk it kl b km ml ju ko kp mm jx kr ks mn ku kv kw mo ky kz la mp lc ld le im bi translated">由于<strong class="kl iu"> <em class="nd"> eps </em> </strong>数字与预期发现的邻居数量成正比，我们可以使用最近邻居来对<strong class="kl iu"> <em class="nd"> eps </em> </strong>达成一个公平的估计。让我们计算一下最近的邻居。</p><pre class="lf lg lh li gt lj lk ll lm aw ln bi"><span id="00cb" class="lo lp it lk b gy lq lr l ls lt">from sklearn.neighbors import NearestNeighbors</span><span id="8c1d" class="lo lp it lk b gy mq lr l ls lt">nearest_neighbors = NearestNeighbors(n_neighbors=11)<br/>neighbors = nearest_neighbors.fit(X)<br/>distances, indices = neighbors.kneighbors(X)</span><span id="6d57" class="lo lp it lk b gy mq lr l ls lt">distances = np.sort(distances[:,10], axis=0)</span><span id="f946" class="lo lp it lk b gy mq lr l ls lt">fig = plt.figure(figsize=(5, 5))<br/>plt.plot(distances)<br/>plt.xlabel("Points")<br/>plt.ylabel("Distance")</span><span id="1d70" class="lo lp it lk b gy mq lr l ls lt">plt.savefig("Distance_curve.png", dpi=300)</span></pre><figure class="lf lg lh li gt ms gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi mr"><img src="../Images/e2a320e1f0133e501c433fc6ec9d2a58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l5Bpk-lnIYf3u2BM_Ti75w.png"/></div></div><p class="mz na gj gh gi nb nc bd b be z dk translated">第 10 个邻居的距离变化</p></figure><p id="4340" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">请注意，在最近邻计算中，点本身将作为第一个最近邻出现。所以我们寻找 11 个最近的邻居。我们对到第 10 个最近邻居<em class="nd">的距离进行排序，并绘制距离变化。我们可以看到，肘点出现在<strong class="kl iu"><em class="nd"/></strong>和<strong class="kl iu"> <em class="nd"> 0.3 </em> </strong>之间的某处。这正是我们所期待的，不是吗？考虑到我挑选 10 作为用于聚类的<strong class="kl iu"> <em class="nd"> min_samples </em> </strong>值，我选择第 10 个邻居。希望到目前为止有意义。</em></p><h1 id="afb8" class="lu lp it bd lv lw lx ly lz ma mb mc md jz me ka mf kc mg kd mh kf mi kg mj mk bi translated">检测肘点的膝盖定位器</h1><p id="8e82" class="pw-post-body-paragraph kj kk it kl b km ml ju ko kp mm jx kr ks mn ku kv kw mo ky kz la mp lc ld le im bi translated"><a class="ae ki" href="https://ieeexplore.ieee.org/author/37704602300" rel="noopener ugc nofollow" target="_blank"> Ville Satopaa </a>等人在 2011 年提交了论文“<a class="ae ki" href="https://doi.org/10.1109/ICDCSW.2011.20" rel="noopener ugc nofollow" target="_blank"> <strong class="kl iu">大海捞针:检测系统行为中的拐点</strong> </a>”。在本文中，出于检测<strong class="kl iu"> <em class="nd">肘点</em> </strong>(或<strong class="kl iu"> <em class="nd">膝点</em> </strong>)的目的，我将使用他们的 python 库<a class="ae ki" href="https://pypi.org/project/kneed/" rel="noopener ugc nofollow" target="_blank"><strong class="kl iu"><em class="nd">kneed</em></strong></a>。我们可以使用下面的代码来查找和绘制拐点。</p><pre class="lf lg lh li gt lj lk ll lm aw ln bi"><span id="ebbd" class="lo lp it lk b gy lq lr l ls lt">from kneed import KneeLocator</span><span id="0b86" class="lo lp it lk b gy mq lr l ls lt">i = np.arange(len(distances))<br/>knee = KneeLocator(i, distances, S=1, curve='convex', direction='increasing', interp_method='polynomial')</span><span id="d755" class="lo lp it lk b gy mq lr l ls lt">fig = plt.figure(figsize=(5, 5))</span><span id="6d2d" class="lo lp it lk b gy mq lr l ls lt">knee.plot_knee()<br/>plt.xlabel("Points")<br/>plt.ylabel("Distance")<br/><br/>print(distances[knee.knee])</span></pre><figure class="lf lg lh li gt ms gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi ns"><img src="../Images/ecc351bf432b5026259fbf9ada1e36fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*09FRSSndDp4ohnjhZ2UIdw.png"/></div></div><p class="mz na gj gh gi nb nc bd b be z dk translated">拐点图</p></figure><p id="117c" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">我们可以看到通过这种方法检测到的拐点在距离 0.178 处。现在我们可以用这个值作为我们的<strong class="kl iu"> <em class="nd"> eps </em> </strong>来看看我们新的集群看起来会是什么样子。</p><figure class="lf lg lh li gt ms gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi mr"><img src="../Images/b75135785c18e5dc7bd851968bff9fae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0kZQew8VPzXW49gEDxY5XQ.png"/></div></div><p class="mz na gj gh gi nb nc bd b be z dk translated">带自动检测 Eps 的 DBSCAN</p></figure><p id="5ce1" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">我们可以看到，我们对实际的聚类有一个合理的估计。这对于研究工作来说通常已经足够了。如果不存在离群点是该场景的直观假设，则可以简单地使用计算出的最近邻居来将离群点(称为<code class="fe nt nu nv lk b">cluster--1</code>)重新分配给检测到的聚类。</p><h1 id="83b3" class="lu lp it bd lv lw lx ly lz ma mb mc md jz me ka mf kc mg kd mh kf mi kg mj mk bi translated">限制</h1><p id="e914" class="pw-post-body-paragraph kj kk it kl b km ml ju ko kp mm jx kr ks mn ku kv kw mo ky kz la mp lc ld le im bi translated">这种方法有几个隐含的假设。</p><ol class=""><li id="cf70" class="nw nx it kl b km kn kp kq ks ny kw nz la oa le ob oc od oe bi translated">所有集群的密度都是相同的。</li><li id="4f79" class="nw nx it kl b km of kp og ks oh kw oi la oj le ob oc od oe bi translated">聚类大小或标准差是相同的。</li></ol><p id="71f7" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">当我们考虑用于膝部计算的相同邻居级别时，这些假设是隐含的。但是，在原始数据中，我们可以清楚地看到密度并不相同。这就是我们观察到一些异常值的主要原因，即使我们在创建斑点时使用固定的标准偏差来分布这些点。此外，修复这些问题超出了本文的范围。</p><h1 id="a62c" class="lu lp it bd lv lw lx ly lz ma mb mc md jz me ka mf kc mg kd mh kf mi kg mj mk bi translated">最后的想法</h1><p id="5d8b" class="pw-post-body-paragraph kj kk it kl b km ml ju ko kp mm jx kr ks mn ku kv kw mo ky kz la mp lc ld le im bi translated">我附上了一个 jupyter 笔记本，上面有本文中的例子使用的完整代码。您可以通过下面的链接访问该笔记本。</p><figure class="lf lg lh li gt ms"><div class="bz fp l di"><div class="ok ol l"/></div></figure><p id="2d2e" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">我希望你喜欢阅读我的文章，就像我喜欢写作一样。请在您的研究工作中尝试这些方法。这对我帮助很大。</p><p id="36b1" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">感谢阅读！</p><p id="d594" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">干杯！😊</p></div></div>    
</body>
</html>