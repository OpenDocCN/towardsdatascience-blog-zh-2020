<html>
<head>
<title>14 Lesser-Known Impressive Features of Scikit Learn Library</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Scikit 学习库的 14 个鲜为人知的令人印象深刻的特性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/14-lesser-known-impressive-features-of-scikit-learn-library-e7ea36f1149a?source=collection_archive---------38-----------------------#2020-06-21">https://towardsdatascience.com/14-lesser-known-impressive-features-of-scikit-learn-library-e7ea36f1149a?source=collection_archive---------38-----------------------#2020-06-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8d72" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">scikit 学习库中经常未知和被低估的功能示例。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f340137f0871a5c4477ff55aad1a4b30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VMtN2zDGUvh7yIhixDKiEA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://pixabay.com/illustrations/precious-diamond-jewelry-expensive-1199183/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><p id="c61a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> Scikit learn </strong>仍然是人工智能领域最受欢迎的开源和机器学习库之一。scikit-learn 库包含了很多用于机器学习和统计建模的高效工具，包括<em class="lv">分类、回归、聚类和降维。</em></p><p id="cbe6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Scikit-learn 大部分是用<strong class="lb iu"> Python </strong>编程语言编写的，一些核心算法是用<strong class="lb iu"> Cython </strong>编写的，以提高其性能。它还可以与许多其他 Python 库很好地集成，例如用于绘图的<strong class="lb iu"> matplotlib </strong>和<strong class="lb iu"> Plotly </strong>，用于数组矢量化的<strong class="lb iu"> NumPy </strong>，以及<strong class="lb iu"> pandas </strong> dataframes、<strong class="lb iu"> scipy </strong>等等。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lw"><img src="../Images/47e86c151a07bc2a90d9ef2b4d5053b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sgdaWDnqpuacF5vYRRmX_w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> scikit 学习主页</a></p></figure><p id="86cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Scikit-learn 附带了许多特性。以下是其中的几个</p><ul class=""><li id="387f" class="lx ly it lb b lc ld lf lg li lz lm ma lq mb lu mc md me mf bi translated">数据集</li><li id="280f" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">特征抽出</li><li id="d010" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">特征选择</li><li id="e472" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">参数调谐</li><li id="a574" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">使聚集</li><li id="3ed5" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">交叉验证</li><li id="f42a" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">监督模型</li><li id="79d2" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">无监督模型</li><li id="ef74" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">降维</li><li id="d220" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">集成方法</li></ul><p id="732e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Scikit learn 在其<a class="ae ky" href="https://github.com/scikit-learn/scikit-learn" rel="noopener ugc nofollow" target="_blank"> GitHub 资源库</a>上拥有超过<strong class="lb iu"> <em class="lv"> 1770 个贡献者</em> </strong>和<strong class="lb iu"> <em class="lv"> 41.2k 颗恒星</em> </strong>，这意味着许多数据科学家、机器学习工程师和研究人员依赖这个库进行机器学习项目。</p><p id="695a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我个人喜欢使用 scikit learn 库，因为它提供了极大的灵活性，并且很容易理解带有大量示例的文档。在本文中，我很高兴与您分享 scikit learn 库中您不存在的鲜为人知的令人印象深刻的特性。</p><h2 id="8a25" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">1.克隆估计量</h2><p id="bae6" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">如果您想要复制一个估计器并将其用于另一个数据集<strong class="lb iu">，克隆函数</strong>可以帮助您做到这一点。克隆函数帮助你用相同的参数构造一个新的估计量。</p><blockquote class="nj"><p id="2fa5" class="nk nl it bd nm nn no np nq nr ns lu dk translated"><em class="nt">“Clone 在不实际复制附加数据的情况下，在估算器中进行模型的深度复制。它产生了一个新的估计量，其参数与任何数据都不匹配。”- </em> <a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html#sklearn.base.clone" rel="noopener ugc nofollow" target="_blank"> <em class="nt"> scikit 学习文档</em> </a></p></blockquote><p id="7d37" class="pw-post-body-paragraph kz la it lb b lc nu ju le lf nv jx lh li nw lk ll lm nx lo lp lq ny ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">例如:</em> </strong></p><p id="9157" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们首先创建一个分类数据集和估值器。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="6643" class="ml mm it oa b gy oe of l og oh">from sklearn.linear_model import LogisticRegression<br/>from sklearn.datasets import make_classification</span><span id="1463" class="ml mm it oa b gy oi of l og oh"># create dataset`<br/>X1, y1 = make_classification(n_classes=2, n_features=5, random_state=1)</span><span id="6118" class="ml mm it oa b gy oi of l og oh"># create estimators <br/>logistic_classifier_1 = LogisticRegression()</span></pre><p id="4b18" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们将使用来自<strong class="lb iu"> sklearn.base </strong>的克隆函数来复制<strong class="lb iu"> logistic_classifier_1 </strong>模型。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="93b5" class="ml mm it oa b gy oe of l og oh">from sklearn.base import clone</span><span id="c711" class="ml mm it oa b gy oi of l og oh"># duplicae the first classifier with clone function <br/>logistic_classifier_2 = clone(logistic_classifier_1)</span><span id="b011" class="ml mm it oa b gy oi of l og oh">logistic_classifier_2</span></pre><p id="c87d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从逻辑分类器 1 克隆的名为<strong class="lb iu">的逻辑分类器 2 </strong>的新估计器的输出如下。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="c7ed" class="ml mm it oa b gy oe of l og oh">LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,<br/>                   intercept_scaling=1, l1_ratio=None, max_iter=100,<br/>                   multi_class='auto', n_jobs=None, penalty='l2',<br/>                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,<br/>                   warm_start=False)</span></pre><h2 id="5149" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">2.将评估者识别为分类器或回归器。</h2><p id="1b1f" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">如果一个模型实例用两个简单的函数<strong class="lb iu"> is_classifier </strong>和<strong class="lb iu"> is_regressor </strong>解决了 scikit-learn 库中的分类或回归任务，您就可以识别该模型实例。如果给定的估计量是分类器，is_classifier 函数返回 True，如果给定的估计量是回归量，is_regressor 函数返回 True。</p><p id="14b7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">举例:</em> </strong></p><p id="f23a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先创建两个估计器，第一个作为回归，第二个作为分类。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="4591" class="ml mm it oa b gy oe of l og oh">from sklearn.linear_model import LinearRegression<br/>from sklearn.ensemble import RandomForestClassifier</span><span id="7322" class="ml mm it oa b gy oi of l og oh"># create estimators <br/>model_1 = LinearRegression()<br/>model_2 = RandomForestClassifier()</span></pre><p id="7746" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们检查一下第一个模型是否回归。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="2d1b" class="ml mm it oa b gy oe of l og oh"># check if it regressor<br/>from sklearn.base import is_regressor</span><span id="996c" class="ml mm it oa b gy oi of l og oh">is_regressor(model_1)</span></pre><p id="b827" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出为<strong class="lb iu">真。</strong></p><p id="cd1e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们检查第二个模型是否是分类。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="a9b3" class="ml mm it oa b gy oe of l og oh"># check if it classifier <br/>from sklearn.base import is_classifier</span><span id="07af" class="ml mm it oa b gy oi of l og oh">is_classifier(model_2)</span></pre><p id="4f87" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出为<strong class="lb iu">真</strong></p><h2 id="b7c5" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">3.用 make_column_selector 选择列</h2><p id="4938" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">将<em class="lv"> make_column_selector 与</em><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_transformer.html#sklearn.compose.make_column_transformer" rel="noopener ugc nofollow" target="_blank"><em class="lv">make _ column _ transformer</em></a>配合使用，根据不同列的数据类型(整数、类别)或列名对其应用不同的预处理。</p><p id="789e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">举例:</em> </strong></p><p id="ada4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本例中，我们使用 make_column-_selector 来选择数据集中的所有对象特征，并通过使用<strong class="lb iu"> OneHotEncoder </strong>方法来转换它们。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="aa99" class="ml mm it oa b gy oe of l og oh">import numpy as np <br/>import pandas as pd<br/>from sklearn.preprocessing import StandardScaler, OneHotEncoder<br/>from sklearn.compose import make_column_transformer<br/>from sklearn.compose import make_column_selector</span><span id="3a84" class="ml mm it oa b gy oi of l og oh"># create a dataframe with different data types<br/>data = pd.DataFrame(<br/> {“gender”: [“male”, “female”, “female”, “male”],<br/> “age”: [23, 5, 11, 8]}<br/>)</span><span id="f18e" class="ml mm it oa b gy oi of l og oh"># create a column transformer with make_column_selector</span><span id="aaf1" class="ml mm it oa b gy oi of l og oh">ct = make_column_transformer(<br/> (StandardScaler(), make_column_selector(dtype_include=np.number)), # ages<br/> (OneHotEncoder(), make_column_selector(dtype_include=object)), # genders<br/>)</span><span id="075a" class="ml mm it oa b gy oi of l og oh">transformed_data = ct.fit_transform(data)</span><span id="9d73" class="ml mm it oa b gy oi of l og oh">transformed_data</span></pre><p id="43b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">转换数据的输出是:-</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="b099" class="ml mm it oa b gy oe of l og oh">array([[ 1.6464639 ,  0.        ,  1.        ],<br/>       [-0.98787834,  1.        ,  0.        ],<br/>       [-0.10976426,  1.        ,  0.        ],<br/>       [-0.5488213 ,  0.        ,  1.        ]])</span></pre><h2 id="09f7" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">4.绘制决策树</h2><p id="1cad" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">您可以使用<strong class="lb iu"> plot_tree 函数</strong>可视化决策树模型。绘图功能允许你用名为<strong class="lb iu"> feature_names 的参数添加特征名。</strong></p><p id="e76d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">示例:<br/> </em> </strong>我们首先通过使用决策树算法为虹膜数据集创建分类模型，然后绘制决策树。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="6131" class="ml mm it oa b gy oe of l og oh"># import libraries<br/>import matplotlib.pyplot as plt <br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import plot_confusion_matrix<br/>from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text <br/>from sklearn.datasets import load_iris</span><span id="ed48" class="ml mm it oa b gy oi of l og oh">#load data <br/>iris = load_iris()</span><span id="ac45" class="ml mm it oa b gy oi of l og oh"># create our instances<br/>model = DecisionTreeClassifier()</span><span id="69e2" class="ml mm it oa b gy oi of l og oh"># train test split<br/>X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state = 0)</span><span id="2956" class="ml mm it oa b gy oi of l og oh"># fit and predict<br/>model.fit(X_train, y_train)</span><span id="f796" class="ml mm it oa b gy oi of l og oh"># plot the tree<br/>plt.figure(figsize = (20, 10))<br/>plot_tree(model,feature_names=iris.feature_names, filled = True) <br/>plt.show()</span></pre><p id="42b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们通过 plot_tree 函数中的<em class="lv">模型和特征名称</em>来创建一个决策树图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/025a33543e1744998d8e08530dea4f07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IIyTtyy6g_uJYB4EFK8hCg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">决策树图</p></figure><h2 id="0032" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">5.从 Openml 获取数据集</h2><p id="38f7" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">Openml 是一个在线平台，旨在通过提供一个开放、协作、无摩擦、自动化的机器学习环境来改进开放式机器学习。</p><p id="eea3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以通过使用 scikit-learn 的<strong class="lb iu"> fetch_openml 函数</strong>从 openml 平台获取数据集。</p><p id="fbd8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">举例:</em> </strong></p><p id="5469" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用名称获取银行营销数据集。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="e4f9" class="ml mm it oa b gy oe of l og oh">from sklearn.datasets import fetch_openml</span><span id="8635" class="ml mm it oa b gy oi of l og oh">#fetch by using data name<br/>bank_marketing = fetch_openml(name=”bank-marketing”)</span><span id="8f53" class="ml mm it oa b gy oi of l og oh"># seperate independent variables and target variable <br/>x = bank_marketing.data <br/>y = bank_marketing.target</span></pre><p id="c9bb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">获取数据集的访问样本。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="93a9" class="ml mm it oa b gy oe of l og oh">x[:2]</span></pre><p id="3b98" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出是</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="6a90" class="ml mm it oa b gy oe of l og oh">array([[ 5.800e+01,  4.000e+00,  1.000e+00,  2.000e+00,  0.000e+00,<br/>         2.143e+03,  1.000e+00,  0.000e+00,  2.000e+00,  5.000e+00,<br/>         8.000e+00,  2.610e+02,  1.000e+00, -1.000e+00,  0.000e+00,<br/>         3.000e+00],<br/>       [ 4.400e+01,  9.000e+00,  2.000e+00,  1.000e+00,  0.000e+00,<br/>         2.900e+01,  1.000e+00,  0.000e+00,  2.000e+00,  5.000e+00,<br/>         8.000e+00,  1.510e+02,  1.000e+00, -1.000e+00,  0.000e+00,<br/>         3.000e+00]])</span></pre><p id="2183" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您也可以使用指定的 ID 提取数据。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="3dcb" class="ml mm it oa b gy oe of l og oh"># fetch by using id from this link <a class="ae ky" href="https://www.openml.org/d/1461" rel="noopener ugc nofollow" target="_blank">https://www.openml.org/d/1461</a><br/>bank_marketing = fetch_openml(data_id=1461)</span><span id="9853" class="ml mm it oa b gy oi of l og oh"># seperate independent variables and target variable <br/>x = bank_marketing.data <br/>y = bank_marketing.target</span></pre><p id="e064" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在上面的例子中，我们获取 ID 为<strong class="lb iu"> 1461 的数据。</strong></p><h2 id="727e" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">6.学习曲线</h2><p id="e547" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">scikit-learn 的学习曲线功能允许您确定不同训练集大小的交叉验证训练和测试分数。</p><blockquote class="ok ol om"><p id="9c08" class="kz la lv lb b lc ld ju le lf lg jx lh on lj lk ll oo ln lo lp op lr ls lt lu im bi translated"><em class="it">“交叉验证生成器在训练和测试数据中将整个数据集拆分 k 次。具有不同大小的训练集的子集将用于训练估计器，并且将计算每个训练子集大小和测试集的分数。之后，对于每个训练子集大小，将在所有 k 次运行中平均分数。”</em> <a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html#sklearn.model_selection.learning_curve" rel="noopener ugc nofollow" target="_blank"> <em class="it"> scikit 学习文档</em> </a></p></blockquote><p id="801b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">举例:</em> </strong></p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="8681" class="ml mm it oa b gy oe of l og oh">from sklearn.datasets import make_classification<br/>from sklearn.neighbors import KNeighborsClassifier<br/>from sklearn.model_selection import learning_curve</span><span id="0af7" class="ml mm it oa b gy oi of l og oh"># create dataset`<br/>X, y = make_classification(n_classes=2, n_features=10, n_samples=5000, random_state=1)</span><span id="1042" class="ml mm it oa b gy oi of l og oh"># create estimator<br/>KNN_classifier = KNeighborsClassifier()</span><span id="31e9" class="ml mm it oa b gy oi of l og oh">#<br/>train_sizes, train_scores, test_scores = learning_curve(<br/>estimator = KNN_classifier,<br/>X = X,<br/>y = y,<br/>train_sizes=np.linspace(0.1, 1.0, 5),<br/>shuffle=True, cv = 5)</span></pre><p id="f96d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">显示训练规模以生成学习曲线。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="bea6" class="ml mm it oa b gy oe of l og oh"># the train size<br/>train_sizes</span></pre><p id="e5d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出是</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="e585" class="ml mm it oa b gy oe of l og oh">array([ 400, 1300, 2200, 3100, 4000])</span></pre><p id="444d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">显示训练集的分数。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="5e4a" class="ml mm it oa b gy oe of l og oh"># Scores on training sets<br/>train_scores</span></pre><p id="977f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出是</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="d144" class="ml mm it oa b gy oe of l og oh">array([[0.895     , 0.8875    , 0.85      , 0.8675    , 0.8975    ],<br/>       [0.87384615, 0.88846154, 0.87692308, 0.88461538, 0.88230769],<br/>       [0.88818182, 0.89363636, 0.88409091, 0.89045455, 0.88863636],<br/>       [0.89354839, 0.89354839, 0.88903226, 0.88806452, 0.88387097],<br/>       [0.893     , 0.894     , 0.88825   , 0.893     , 0.88625   ]])</span></pre><p id="67af" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">显示验证分数</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="d760" class="ml mm it oa b gy oe of l og oh"># show validation scores<br/>test_scores</span></pre><p id="ffc0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出是</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="89f6" class="ml mm it oa b gy oe of l og oh">array([[0.83 , 0.812, 0.829, 0.841, 0.819],<br/>       [0.837, 0.813, 0.853, 0.848, 0.828],<br/>       [0.843, 0.823, 0.845, 0.853, 0.821],<br/>       [0.832, 0.831, 0.855, 0.857, 0.83 ],<br/>       [0.834, 0.828, 0.849, 0.86 , 0.835]])</span></pre><p id="c225" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们来找训练分和验证分的手段。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="1f02" class="ml mm it oa b gy oe of l og oh"># find the mean of training scores and validation scores </span><span id="7af8" class="ml mm it oa b gy oi of l og oh">train_scores_mean = train_scores.mean(axis = 1)<br/>print(“Training Scores mean:{}”.format(train_scores_mean))</span><span id="c7b4" class="ml mm it oa b gy oi of l og oh">test_scores_mean = test_scores.mean(axis = 1)<br/>print(“Test Scores mean:{}”.format(test_scores_mean))</span></pre><p id="8d68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出是。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="11a4" class="ml mm it oa b gy oe of l og oh">Training Scores mean:[0.8795 0.88123077 0.889 0.8896129  0.8909]<br/>Test Scores mean:[0.8262 0.8358 0.837  0.841  0.8412]</span></pre><p id="3ae5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下图展示了数据是如何被分成 k 次和 5 次交叉验证的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/50dbbc870cee85b647cd86fe1eec295f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G2fRGPHRnX8txZ3BDrEiyw.png"/></div></div></figure><p id="e1aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">了解更多查看另一个例子</em> <a class="ae ky" href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html#sphx-glr-auto-examples-model-selection-plot-learning-curve-py" rel="noopener ugc nofollow" target="_blank"> <em class="lv">这里</em> </a> <em class="lv">。</em></p><h2 id="e82c" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">7.交叉验证和预测</h2><p id="322f" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">如果您想为您的估计器同时执行交叉验证和预测，您可以使用 scikit-learn 的<strong class="lb iu"> cross_val_predict </strong>函数。</p><p id="a967" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">举例:</em> </strong></p><p id="20cc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对 iris 数据集执行 cross_val_predict。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="e63c" class="ml mm it oa b gy oe of l og oh">from sklearn import datasets, linear_model<br/>from sklearn.model_selection import cross_val_predict<br/>from sklearn.ensemble import RandomForestRegressor</span><span id="d6b4" class="ml mm it oa b gy oi of l og oh">#load dataet<br/>diabetes = datasets.load_diabetes()</span><span id="cb66" class="ml mm it oa b gy oi of l og oh">X = diabetes.data<br/>y = diabetes.target</span><span id="7a11" class="ml mm it oa b gy oi of l og oh">RF_regressor = RandomForestRegressor()</span><span id="93d1" class="ml mm it oa b gy oi of l og oh"># perfrom cross validation and prediction<br/>y_pred = cross_val_predict(estimator=RF_regressor, X= X, y=y, cv=5)</span></pre><p id="07fb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">显示前 10 个预测。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="fb04" class="ml mm it oa b gy oe of l og oh">#show prediction<br/>y_pred[:10]</span></pre><p id="b919" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出是:</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="33b9" class="ml mm it oa b gy oe of l og oh">array([225.41,  89.16, 172.4 , 164.03,  79.48, 116.87,  74.47, 157.5 ,155.99, 170.59])</span></pre><h2 id="4d00" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">8。使用 SelectFromModel 函数选择重要功能。</h2><p id="2a76" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">并非数据集中出现的所有特征都对模型性能有用，这意味着您可以通过使用<strong class="lb iu"> SelectFromModel 函数来识别和选择模型的重要特征。</strong>该函数根据重要性权重选择特征。您可以从一系列估计量中进行选择，但请记住，拟合后估计量必须具有<em class="lv"> feature_importances_ 或 coef_ attribute </em>。</p><p id="860a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">SelectFromModel 不太健壮，因为它只是根据作为参数给出的<em class="lv">阈值</em>来删除不太重要的特征。</p><p id="b48a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">示例:</strong>从包含<em class="lv"> 10 个独立特征</em>的糖尿病数据集中选择重要特征。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="2bdc" class="ml mm it oa b gy oe of l og oh">from sklearn import datasets, linear_model<br/>from sklearn.feature_selection import SelectFromModel<br/>from sklearn.linear_model import LogisticRegression</span><span id="f09e" class="ml mm it oa b gy oi of l og oh">#load dataet<br/>diabetes = datasets.load_diabetes()</span><span id="eb35" class="ml mm it oa b gy oi of l og oh">X = diabetes.data<br/>y = diabetes.target</span><span id="ddb5" class="ml mm it oa b gy oi of l og oh">lg_regressor = LogisticRegression()</span><span id="2c28" class="ml mm it oa b gy oi of l og oh"># identify and select important fatures by using SelectFromModel<br/>selector = SelectFromModel(estimator=lg_regressor).fit(X, y)</span><span id="e926" class="ml mm it oa b gy oi of l og oh">#show estimator coefficient <br/>selector.estimator_.coef_</span></pre><p id="011c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出如下。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="f4ca" class="ml mm it oa b gy oe of l og oh">array([[-0.01631211, -0.04448689, -0.01041713, ..., -0.03925967,<br/>        -0.02122777, -0.03405436],<br/>       [ 0.00188878, -0.04444519, -0.00816801, ..., -0.03918144,<br/>        -0.06436135, -0.05463903],<br/>       [-0.02699287, -0.04433151, -0.06285579, ..., -0.0756844 ,<br/>        -0.05557734, -0.06683906],<br/>       ...,<br/>       [ 0.03415162,  0.05040128,  0.11077166, ..., -0.00292399,<br/>         0.027618  ,  0.07302442],<br/>       [ 0.03416799,  0.05030017,  0.12469165, ...,  0.10747183,<br/>        -0.00019805,  0.02747969],<br/>       [-0.04907612, -0.04462806,  0.16038187, ...,  0.0340123 ,<br/>         0.02773604,  0.01114488]])</span></pre><p id="1689" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">显示用于特征选择的阈值。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="765f" class="ml mm it oa b gy oe of l og oh"># show the threshold value<br/>selector.threshold_</span></pre><p id="e3dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出是<em class="lv">12.19469668686</em></p><p id="5ff7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们可以使用选定的要素来转换数据。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="c885" class="ml mm it oa b gy oe of l og oh"><br/>transformed = selector.transform(X)<br/>transformed[:3]</span></pre><p id="f76b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出是:-</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="482a" class="ml mm it oa b gy oe of l og oh">array([[ 0.05068012,  0.06169621,  0.02187235, -0.04340085, -0.00259226,<br/>         0.01990842],<br/>       [-0.04464164, -0.05147406, -0.02632783,  0.07441156, -0.03949338,<br/>        -0.06832974],<br/>       [ 0.05068012,  0.04445121, -0.00567061, -0.03235593, -0.00259226,<br/>         0.00286377]])</span></pre><p id="35da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据集已经从<em class="lv"> 10 个特征</em>转化为<em class="lv"> 6 个重要特征</em>。</p><h2 id="f2b2" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated"><strong class="ak"> 9。功能变压器</strong></h2><p id="954e" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">应用来自<strong class="lb iu"> pandas </strong>的函数已被用于处理数据帧中从一个形状到另一个形状的数据，但如果您想在管道中使用它，则该函数没有用。<strong class="lb iu"> FunctionTransformer </strong>函数可以帮助您在管道中添加特征/变量转换。</p><p id="c835" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html#sklearn.preprocessing.FunctionTransformer" rel="noopener ugc nofollow" target="_blank"> FunctionTransformer </a>提供了其他 sklearn 估算器的一些标准方法(例如，拟合和转换)。</p><p id="ca9d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">举例:</em> </strong></p><p id="b5f1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用<strong class="lb iu"> np.log() </strong>方法将数组转换为自然对数。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="ec38" class="ml mm it oa b gy oe of l og oh">import numpy as np<br/>from sklearn.preprocessing import FunctionTransformer</span><span id="c8e5" class="ml mm it oa b gy oi of l og oh">X = np.array([[89,34,9, 1,5,87,54,22,67,44], [12, 63,67,2,9,45,81,54,22,73]])</span><span id="748a" class="ml mm it oa b gy oi of l og oh">#create FunctionTransformer<br/>log_transformer = FunctionTransformer(np.log)</span><span id="7417" class="ml mm it oa b gy oi of l og oh">#transform the data<br/>log_transformer.transform(X)</span></pre><p id="2af2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">转换后的输出。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="e071" class="ml mm it oa b gy oe of l og oh">array([[4.48863637, 3.52636052, 2.19722458, 0.        , 1.60943791,<br/>        4.46590812, 3.98898405, 3.09104245, 4.20469262, 3.78418963],<br/>       [2.48490665, 4.14313473, 4.20469262, 0.69314718, 2.19722458,<br/>        3.80666249, 4.39444915, 3.98898405, 3.09104245, 4.29045944]])</span></pre><h2 id="292f" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated"><strong class="ak"> 10。确定目标数据类型</strong></h2><p id="4a14" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">在监督机器学习任务/问题中，我们有<em class="lv">独立变量</em>和<em class="lv">目标变量。</em>您还需要知道<em class="lv">目标变量</em>的数据类型，以选择您将使用哪条路径来解决回归或分类任务的问题。您可以使用<strong class="lb iu"> type_of_target </strong>函数来检查目标变量所指示的数据类型。</p><p id="ce16" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">示例:<br/> </em> </strong>确定糖尿病数据集中目标变量的类型。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="eb12" class="ml mm it oa b gy oe of l og oh">from sklearn.utils.multiclass import type_of_target<br/>from skearn import datasets</span><span id="18a8" class="ml mm it oa b gy oi of l og oh">#load dataet<br/>diabetes = datasets.load_diabetes()</span><span id="bbb5" class="ml mm it oa b gy oi of l og oh">X = diabetes.data<br/>y = diabetes.target</span><span id="503d" class="ml mm it oa b gy oi of l og oh">type_of_target(y)</span></pre><p id="c694" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出为<strong class="lb iu"><em class="lv">‘多类’。</em> </strong></p><h2 id="fd45" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">11.添加虚拟特征</h2><p id="83e0" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">通过使用<strong class="lb iu"> add_dummy_feature </strong>功能，可以在数据中添加具有特定值的虚拟特征。</p><blockquote class="ok ol om"><p id="e18b" class="kz la lv lb b lc ld ju le lf lg jx lh on lj lk ll oo ln lo lp op lr ls lt lu im bi translated">"这对于将截取项与不能直接拟合的实现相拟合是很有用的."<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.add_dummy_feature.html#sklearn.preprocessing.add_dummy_feature" rel="noopener ugc nofollow" target="_blank"> scikit-learn 文档</a></p></blockquote><p id="1cf8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">例如:</em> </strong></p><p id="f1e7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据集对象和虚拟特征值(如 5)将通过<strong class="lb iu"> add_dummy-feature </strong>函数在我们的数据集中创建一个新的虚拟特征。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="67fc" class="ml mm it oa b gy oe of l og oh">import numpy as np <br/>from sklearn.preprocessing import add_dummy_feature</span><span id="6057" class="ml mm it oa b gy oi of l og oh">p = np.array([[89,34], [12, 63]])</span><span id="5472" class="ml mm it oa b gy oi of l og oh">add_dummy_feature(p, value=5)</span></pre><p id="a302" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的 p 数组中，每一行都将增加一个值 5。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="bcc7" class="ml mm it oa b gy oe of l og oh">array([[ 5., 89., 34.],<br/>       [ 5., 12., 63.]])</span></pre><h2 id="f7a7" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">12.使用迭代估算器估算缺失值</h2><p id="af09" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">大多数时候，我们使用简单的方法来估算数据集中的缺失值。像用于数字特征的<strong class="lb iu">均值/中值</strong>和用于分类特征的<strong class="lb iu">模式</strong>这样的方法。也可以使用<strong class="lb iu"> <em class="lv">迭代估算器</em> </strong>等高级方法。</p><p id="6d50" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过使用<em class="lv">机器学习模型</em>，例如 BayesianRidge，IterativeImputer 使用数据集中所有可用的要素来估计缺失值。这意味着带有缺失值的特征将被标记为<em class="lv">因变量</em>，其他特征将被标记为<em class="lv">自变量</em>。</p><p id="aa4a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">举例:</strong></p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="a9dc" class="ml mm it oa b gy oe of l og oh">import numpy as np<br/>from sklearn.experimental import enable_iterative_imputer <br/>from sklearn.impute import IterativeImputer</span><span id="77af" class="ml mm it oa b gy oi of l og oh"># Create dataset with missing values<br/>data = [[61, 22, 43,np.nan,67],<br/>        [np.nan, 6, 27, 8, 11],<br/>        [83, 51, np.nan, 32, 9],<br/>        [74, np.nan, 35, 26, 97],<br/>        [np.nan, 4, 13,45, 33]]</span></pre><p id="aeb6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们可以用迭代估算函数估算缺失值。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="08e6" class="ml mm it oa b gy oe of l og oh"># Impute missing values using iterative imputer<br/>iter_imp = IterativeImputer(random_state= 42)<br/>iter_imp.fit_transform(data)</span></pre><p id="465b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">没有丢失值的输出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/9e0f30a765fce9dabe54d4d62e4f6b2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/1*qkSLn6gGARvCsDUPNfAXJA.png"/></div></figure><h2 id="85f8" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">13.使用随机搜索的超参数调谐</h2><p id="9448" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">RandomizeSearchCV 函数倾向于通过随机选取一组预定的超参数分布来训练和评估一系列模型。在用不同的随机选择的超参数组合训练模型的 N 个不同版本之后，该函数挑选具有最佳参数值的模型的最成功版本。这允许您显式控制尝试的参数组合的数量。</p><p id="0488" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">示例:<br/> </strong>创建随机搜索以找到 XGBoost 算法的最佳参数，从而将虹膜分类为 3 类。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="1494" class="ml mm it oa b gy oe of l og oh">from sklearn import linear_model, datasets<br/>from sklearn.model_selection import RandomizedSearchCV<br/>from xgboost import XGBClassifier<br/>from scipy.stats import randint</span><span id="abe3" class="ml mm it oa b gy oi of l og oh"># Load data<br/>iris = datasets.load_iris()<br/>X = iris.data<br/>y = iris.target</span><span id="f510" class="ml mm it oa b gy oi of l og oh"># create model<br/>classifier = XGBClassifier()</span><span id="8969" class="ml mm it oa b gy oi of l og oh"># Create Hyperparameter Search Space<br/>param_dist = {<br/> # randomly sample numbers from 50 to 400 estimators<br/> “n_estimators”: randint(50,400),<br/> “learning_rate”: [0.01, 0.03, 0.05],<br/> “subsample”: [0.5, 0.7],<br/> “max_depth”: [3, 4, 5],<br/> “min_child_weight”: [1, 2, 3],<br/>}</span><span id="2405" class="ml mm it oa b gy oi of l og oh"># create random search</span><span id="ff7f" class="ml mm it oa b gy oi of l og oh"># Create randomized search 5-fold cross validation and 100 iterations</span><span id="c062" class="ml mm it oa b gy oi of l og oh">clf = RandomizedSearchCV(<br/> estimator=classifier,<br/> param_distributions=param_dist,<br/> random_state=1,<br/> n_iter=100,<br/> cv=5,<br/> verbose=0,<br/> n_jobs=-1,<br/>)</span><span id="a0f0" class="ml mm it oa b gy oi of l og oh"># Fit randomized search<br/>best_model = clf.fit(X, y)</span></pre><p id="e825" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">运行随机搜索后，我们可以观察最佳参数值，以提高模型性能。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="de74" class="ml mm it oa b gy oe of l og oh"># View best hyperparameters<br/>print(‘Best n_estimator:’, best_model.best_estimator_.get_params()[‘n_estimators’])<br/>print(‘Best learning_rate:’, best_model.best_estimator_.get_params()[‘learning_rate’])<br/>print(‘Best subsample:’, best_model.best_estimator_.get_params()[‘subsample’])<br/>print(‘Best max_depth:’, best_model.best_estimator_.get_params()[‘max_depth’])<br/>print(‘Best min_child_weight:’, best_model.best_estimator_.get_params()[‘min_child_weight’])</span></pre><p id="2e8d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出:</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="78e7" class="ml mm it oa b gy oe of l og oh">Best n_estimator: 259<br/>Best learning_rate: 0.03<br/>Best subsample: 0.5<br/>Best max_depth: 3<br/>Best min_child_weight: 1</span></pre><p id="5aac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有时，RandomizedSearchCV 不会提供准确的结果，因为<strong class="lb iu"> GridSearchCV，</strong>但是当您拥有大型数据集时，GridSearchCV 会大大降低计算时间，并且成本非常高。在这种情况下，建议使用随机搜索，因为您可以定义想要运行的迭代次数。</p><h2 id="aead" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">14.加载文本文件</h2><p id="6709" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">如果您想在 scikit learn 中加载文本文件，您可以使用<strong class="lb iu"> load_files 函数</strong>。load_files 将根/主文件夹中的每个文件夹视为一个类别，该文件夹中的所有文档都将被分配到相应的类别。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/1a4095000c8331cd400064f18d4fa6e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*5zlcP7z_RaT2eMryJG38Jg.png"/></div></figure><p id="b3ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">示例:<br/> </strong>从名为 news_report 的文件夹中加载数据。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="3e46" class="ml mm it oa b gy oe of l og oh">from sklearn.datasets import load_files</span><span id="1f38" class="ml mm it oa b gy oi of l og oh">news_reports = load_files(<br/> container_path=”news_report/”,<br/> description=”News reports in 2020",<br/> load_content=True,<br/>)</span></pre><p id="2c63" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从 l <strong class="lb iu"> oad_files </strong>函数中，我们在名为<strong class="lb iu"> container_path 的参数中传递了文件夹的名称。</strong></p><p id="fda8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">注意:</strong>当设置 load_content=True 时，您也可以使用' encoding '参数来指定文本的编码。</p><p id="d21d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们可以用 target_names 属性来标识目标名称。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="6ab6" class="ml mm it oa b gy oe of l og oh"># show target names <br/>news_reports.target_names</span></pre><p id="c7c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出将是。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="5f73" class="ml mm it oa b gy oe of l og oh">['business', 'healthy', 'international', 'sport']</span></pre><p id="2059" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">还可以通过使用两个名为 data 和 target 的属性来指定自变量和目标变量。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="08a1" class="ml mm it oa b gy oe of l og oh"># specify the independent variable and the target variable <br/>X = news_reports.data<br/>y = news_reports.target</span></pre><h1 id="2561" class="ot mm it bd mn ou ov ow mq ox oy oz mt jz pa ka mw kc pb kd mz kf pc kg nc pd bi translated">结论</h1><p id="ff46" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">正如我所说，scikit-learn 仍然是最受欢迎的开源和机器学习库之一，拥有所有可用的功能，您可以进行端到端的机器学习项目。您还可以在您的机器学习项目中实现本文中介绍的 scikit learn 令人印象深刻的功能。</p><p id="d79c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您想了解更多关于 scikit-learn 的信息，我推荐您参加来自<a class="ae ky" href="https://courses.analyticsvidhya.com/courses/get-started-with-scikit-learn-sklearn" rel="noopener ugc nofollow" target="_blank"> AnalyticVidhya </a>的免费在线课程</p><p id="a654" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在这里下载包含本文介绍的所有<strong class="lb iu"> 14 个特性</strong>的笔记本。</p><div class="pe pf gp gr pg ph"><a href="https://github.com/Davisy/14-Lesser-Known-Impressive-Features-in-Scikit-learn-Library" rel="noopener  ugc nofollow" target="_blank"><div class="pi ab fo"><div class="pj ab pk cl cj pl"><h2 class="bd iu gy z fp pm fr fs pn fu fw is bi translated">davisy/14-Scikit-Learn-Library 中鲜为人知但令人印象深刻的功能</h2><div class="po l"><h3 class="bd b gy z fp pm fr fs pn fu fw dk translated">scikit 学习库中经常未知和被低估的功能示例。…</h3></div><div class="pp l"><p class="bd b dl z fp pm fr fs pn fu fw dk translated">github.com</p></div></div><div class="pq l"><div class="pr l ps pt pu pq pv ks ph"/></div></div></a></div><p id="8957" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你学到了新的东西或者喜欢阅读这篇文章，请分享给其他人看。也可以随意发表评论。在那之前，下一篇文章再见！也可以通过推特<a class="ae ky" href="https://twitter.com/Davis_McDavid" rel="noopener ugc nofollow" target="_blank"> @Davis_McDavid </a>联系到我。</p><p id="2f12" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">最后一件事:</em> </strong> <em class="lv">在下面的链接里多看看类似这样的文章。</em></p><div class="pe pf gp gr pg ph"><a href="https://medium.com/analytics-vidhya/feature-selection-by-using-voting-approach-e0d1c7182a21" rel="noopener follow" target="_blank"><div class="pi ab fo"><div class="pj ab pk cl cj pl"><h2 class="bd iu gy z fp pm fr fs pn fu fw is bi translated">使用投票方法的特征选择</h2><div class="po l"><h3 class="bd b gy z fp pm fr fs pn fu fw dk translated">如何应用多种技术来选择 Xverse 包的特性？</h3></div><div class="pp l"><p class="bd b dl z fp pm fr fs pn fu fw dk translated">medium.com</p></div></div><div class="pq l"><div class="pw l ps pt pu pq pv ks ph"/></div></div></a></div><div class="pe pf gp gr pg ph"><a href="https://medium.com/analytics-vidhya/how-to-run-machine-learning-experiments-with-python-logging-module-9030fbee120e" rel="noopener follow" target="_blank"><div class="pi ab fo"><div class="pj ab pk cl cj pl"><h2 class="bd iu gy z fp pm fr fs pn fu fw is bi translated">如何用 Python 日志模块运行机器学习实验</h2><div class="po l"><h3 class="bd b gy z fp pm fr fs pn fu fw dk translated">有时候“打印”并不是一个好主意</h3></div><div class="pp l"><p class="bd b dl z fp pm fr fs pn fu fw dk translated">medium.com</p></div></div><div class="pq l"><div class="px l ps pt pu pq pv ks ph"/></div></div></a></div><div class="pe pf gp gr pg ph"><a href="https://medium.com/analytics-vidhya/how-to-write-configuration-files-in-your-machine-learning-project-47bc840acc19" rel="noopener follow" target="_blank"><div class="pi ab fo"><div class="pj ab pk cl cj pl"><h2 class="bd iu gy z fp pm fr fs pn fu fw is bi translated">如何在你的机器学习项目中写配置文件？</h2><div class="po l"><h3 class="bd b gy z fp pm fr fs pn fu fw dk translated">用配置文件管理参数和初始设置。</h3></div><div class="pp l"><p class="bd b dl z fp pm fr fs pn fu fw dk translated">medium.com</p></div></div><div class="pq l"><div class="py l ps pt pu pq pv ks ph"/></div></div></a></div></div></div>    
</body>
</html>