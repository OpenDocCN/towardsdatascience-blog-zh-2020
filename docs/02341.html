<html>
<head>
<title>To translate or not to translate, best practices in non-English sentiment analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">翻译还是不翻译，非英语情感分析的最佳实践</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/to-translate-or-not-to-translate-best-practices-in-non-english-sentiment-analysis-144a53613913?source=collection_archive---------22-----------------------#2020-03-05">https://towardsdatascience.com/to-translate-or-not-to-translate-best-practices-in-non-english-sentiment-analysis-144a53613913?source=collection_archive---------22-----------------------#2020-03-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8a5c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在本文中，在具有正/负标签的多样化的50，000个荷兰评论数据集上建立和训练递归神经网络。将性能与测试集被翻译成英语并通过预先训练的英语情感模型分类的情况进行比较。接下来，在去除停用词和不嵌入使用词的情况下测试该模型。ConceptNet Numberbatch受到更密切的关注，因为这种多语言单词嵌入优于其他单词嵌入。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/f2efd7829d4e5fa47854c461986cfb77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*8oF-K2DZoFlSrDcF5rRkSw.jpeg"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated"><a class="ae kr" href="https://commons.wikimedia.org/wiki/File:Macbeth_consulting_the_Vision_of_the_Armed_Head.jpg" rel="noopener ugc nofollow" target="_blank">图片来自维基共享资源</a></p></figure><p id="5b07" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir">总结</strong> <br/>翻译对于情感分析来说不是一个好的选择，它会导致16%的准确率下降。对于情感分析，停用词和词嵌入是有用的。事实证明，对于荷兰语自然语言处理，Conceptnet Numberbatch单词嵌入优于Word2vec/Glove。</p><p id="ded6" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir">翻译与递归神经网络<br/> </strong>在本文中，递归神经网络在独立测试集上的准确性与Textblob在该测试集的英语google翻译上的性能进行了比较。荷兰训练模型是在一个数据集上训练的，该数据集包括近50，000条对酒店、购物产品、食品和服务的各种评论，标签为正面或负面。训练后，该模型用于预测独立测试集的标签。翻译后的模型是从Textblob预训练的。Textblob是Python中广泛使用的预训练文本分析库。翻译后的模型首先翻译测试集，然后使用预训练的情感分析模型。独立测试集的结果如下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lo"><img src="../Images/b3ee2c4fe5436b583c7f1414047b5601.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Er-U_t2XAh2DcHENdx31-Q.png"/></div></div></figure><p id="3508" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">如您所见，性能降低了16%。根据斯坦福大学的研究，Textblob在母语英语测试集上的准确率约为87.5%。因此，如果翻译是完美的，Textblob模型的性能已经降低了4%左右。另外12%是因为翻译不完美。因此，在这种情况下，建议收集大量的母语数据集。</p><p id="18aa" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">但有时在小语种中，获取大数据集可能会很困难。除了英语和中文，没有很多大的标准数据集可以使用，网络内容也不太容易获得。如果你能设法得到几百个数据点(但不是10.000以上)，那么迁移学习可能是一种选择。为了在这种情况下应用迁移学习，一个带有正负标签的(大)英语数据集被翻译成荷兰语，然后被训练。然后，该模型的权重用于在荷兰数据集的一小部分(1000条评论)上进一步训练。这给出了比翻译的Textblob模型更好的结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lo"><img src="../Images/974ced093b289b9723826c44b9405a20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zfM6xYHT6MyB4BPzpCW-kA.png"/></div></div></figure><p id="3a8c" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">培训和测试中的三种方法概述:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lt"><img src="../Images/2831af0d2c76c1ff6a3972668fa9a92f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dUStm-Cb4dGwJK5GJ-xR-w.png"/></div></div></figure><p id="c725" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir">无停用词<br/> </strong>如果停用词被过滤，数据集中最常见的词是好、好吃、酒店、预订、快捷和送货。这些词有些是中性的，有些则带有感情色彩。但是，结果表明准确率下降了7%以上:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lo"><img src="../Images/7786273c783dc5da2eacb42cb09dfb36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ft1Eg5Ou1u2eS7mY_EGuZQ.png"/></div></div></figure><p id="c2ae" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">如果检查未过滤数据集中最常见的单词，可以看到前20个单词全部是停用词(这是有道理的)。性能下降变得明显。“不是”和“但是”这两个词颠倒了句子的意思。单词“too”和“also”也会改变句子的意思。如果模型不能考虑到这些词，它就不能预测一个句子/评论的反转情绪。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lu"><img src="../Images/e37224da6f78a0b0b82e74f0d23fb258.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nq1MbDFbMsHCNubPc5Ga1w.png"/></div></div></figure><p id="f984" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">所以在这种情况下，最好将停用词保留在数据集中。</p><p id="1e1a" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir">没有单词嵌入<br/> </strong>为了新鲜起见，单词嵌入是用数字(或张量)来表示单词。例如，“遛狗的人”可以表示为这样的二维单词嵌入:[1.3，-0.2] [0.4，1.1] [-0.3，0.1] [1.3，-0.2] [1.2，0.7]。因此，当像上面那样使用二维嵌入时，每个(唯一的)单词都被转换成两个数字的组合。单词嵌入工作得如此之好是因为单词的语义被捕获了。意义相同的词具有相似的张量值，与其他词群的差异也相似。如下图所示，单词嵌入的性能要高得多。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lo"><img src="../Images/dcb51699cbfc9b93f2dbc3239406cc13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nkHMc3fppZ9HEa9vXHXlyQ.png"/></div></div></figure><p id="46e0" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir">concept net number batch<br/></strong>concept net是一个多语言的单词嵌入集。ConceptNet优于其他众所周知的单词嵌入，如Word2Vec和GloVe，如下图所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lv"><img src="../Images/82618066f1c23bcb51bfd6b5318486c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FJ5Gu5MGypM3TQFYpy6Tew.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated"><a class="ae kr" href="https://github.com/commonsense/conceptnet-numberbatch" rel="noopener ugc nofollow" target="_blank"> <em class="lw">图来自ConceptNet项目</em> </a></p></figure><p id="a975" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">word embeddings文件可以在下载部分下载<a class="ae kr" href="https://github.com/commonsense/conceptnet-numberbatch" rel="noopener ugc nofollow" target="_blank">。该文件的结构如下:/c/<em class="lx">language _ code</em>/<em class="lx">word</em>0.4…0.1。例如，dog的结构如下:/c/en/dog 0.2 … 0.9。使用Numberbatch时，请确保只上传所需的语言，以减少冗余。Numberbatch的词汇量令人印象深刻，请看下面的15种顶级语言:</a></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi ly"><img src="../Images/89987523ebad7ccf6bcf4063d8148cae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-5K4oFvVvz7nDN0LfxRk1Q.png"/></div></div></figure><p id="eacf" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">那么嵌入如何寻找荷兰人呢？这些单词是用300个维度来表示的。为了将这个数字压缩到2，可以使用T-SNE算法。共测试了三大类18个单词，分别是服装类的夹克、围巾、裤子、鞋子、袜子、毛衣的荷兰语翻译(下图黄色)，动物类的虎、鹰、蜘蛛、鹰、狮子、鬣狗的荷兰语翻译(下图灰色)，君主制类的皇冠、国王、女王、王子、宫殿、加冕(下图浅蓝色)。如您所见，单词根据相似性进行聚类，这意味着单词嵌入有助于需要处理荷兰语的模型:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lz"><img src="../Images/be6c9a4dd8fc0246f8729b2edeb4be30.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*YiDiiHFbmirg_WG_-BONaA.png"/></div></div></figure><p id="3c96" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">最后，下面是一些关于如何实现Numberbatch的代码。下一节中的代码打开了Numberbatch单词嵌入(确保文件只包含您的语言部分，所以对于荷兰语是c/nl/)。它创建了一个包含所有荷兰语单词及其Numberbatch单词嵌入表示的300维字典。例如，单词dog将保存为{ 'dog': [0.2，0.1，0.5 … 0.3]}:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ma mb l"/></div></figure><p id="9ee5" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">这部分将数据集标记化。代码为每个唯一的单词分配一个数字，所有唯一的单词都被计算在内。接下来，将构建包含在训练集中出现的单词的字典，并且脚本向其添加300维嵌入:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ma mb l"/></div></figure><p id="452b" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">最后，让Keras网络的第一层成为嵌入层。这确保了输入数据句子被转换为Numberbatch张量:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ma mb l"/></div></figure></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><p id="4562" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir">结论<br/> </strong>如果你能够收集一个母语的大数据集，那么在这个数据集上训练的模型可能会给出最好的分类精度。如果你不能得到一个大的数据集，但只能得到几百个数据点，那么迁移学习仍然可以给出很好的结果。翻译数据，然后使用英语训练的模型是不推荐的，除了坏的准确性，这也将恶化您的应用程序的性能，因为数据首先需要被翻译。关于停用词和词嵌入，在这种情况下它们是有用的。Conceptnet Numberbatch是一个非常好的单词嵌入工具，用于非英语的自然语言处理任务。</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><p id="6609" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir"> Next up 2021 <br/> </strong>我要写一篇关于神经风格转移的文章。要查看文章的最终应用，请查看以下页面(荷兰语):</p><p id="a9e0" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><a class="ae kr" href="https://gan-studios.nl/ontwerpen" rel="noopener ugc nofollow" target="_blank"> Schilderij laten maken </a></p><p id="9893" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">到时候见！</p></div></div>    
</body>
</html>