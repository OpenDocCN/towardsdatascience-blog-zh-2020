<html>
<head>
<title>How to Build a DCGAN with PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用 PyTorch 构建 DCGAN</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-build-a-dcgan-with-pytorch-31bfbf2ad96a?source=collection_archive---------16-----------------------#2020-06-26">https://towardsdatascience.com/how-to-build-a-dcgan-with-pytorch-31bfbf2ad96a?source=collection_archive---------16-----------------------#2020-06-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d6c3" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">GAN 入门教程</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/cb58c8d3f87be24182f2ce117314c920.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m-JtcLBnJV2XlZY4BIzxJw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:<a class="ae ky" href="https://pixabay.com/photos/light-lamp-warm-kind-mellow-focus-4297386/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><p id="4db3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本教程中，我们将在 PyTorch 中构建一个简单的<a class="ae ky" href="https://arxiv.org/abs/1511.06434" rel="noopener ugc nofollow" target="_blank"> DCGAN </a>，并训练它生成手写数字。作为本教程的一部分，我们将讨论 PyTorch 数据加载器，以及如何使用它将真实图像数据输入 PyTorch 神经网络进行训练。PyTorch 是本教程的重点，所以我假设您熟悉 GANs 的工作方式。</p><h1 id="8218" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">要求</h1><ol class=""><li id="fb3e" class="mn mo it lb b lc mp lf mq li mr lm ms lq mt lu mu mv mw mx bi translated">Python 3.7 以上版本。再低的话，你就要重构 f 弦了。</li><li id="30a2" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu mu mv mw mx bi translated">PyTorch 1.5 不确定怎么安装？这可能会有所帮助。</li><li id="16a6" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu mu mv mw mx bi translated">Matplotlib 3.1 或更高版本</li><li id="051d" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu mu mv mw mx bi translated">大约 22 分钟。</li></ol><p id="c269" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这不是必需的，但我建议先阅读我的<a class="ae ky" rel="noopener" target="_blank" href="/pytorch-and-gans-a-micro-tutorial-804855817a6b">香草甘教程</a>；它解释了一些本教程认为理所当然的事情。我还建议你在配有 CUDA GPU 的电脑上完成本教程，或者准备一本厚厚的数独书。</p><h1 id="d0f0" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">手头的任务</h1><blockquote class="nd"><p id="2b2d" class="ne nf it bd ng nh ni nj nk nl nm lu dk translated"><em class="nn">创建一个函数 G: Z → X 其中 Z~N₁ </em> ₆ <em class="nn"> (0，1)和 X~MNIST。</em></p></blockquote><p id="38c2" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">也就是说，训练一个 GAN，它采用 16 维随机噪声并产生看起来像来自<a class="ae ky" href="https://en.wikipedia.org/wiki/MNIST_database" rel="noopener ugc nofollow" target="_blank"> MNIST </a>数据集的真实样本的图像。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/e7620493a3de60425cfd89c7d99be1f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*Ft2rLuO82eItlvJn5HOi9A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自 MNIST 数据集的数字样本(来源:<a class="ae ky" href="https://commons.wikimedia.org/wiki/File:MnistExamples.png" rel="noopener ugc nofollow" target="_blank">约瑟夫·斯特潘</a></p></figure><h1 id="dd3b" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">但是在我们开始之前…</h1><p id="0cbf" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">…让我们做一点家务。如果您还没有，请安装所需版本的 Python 和上述库。然后，创建您的项目目录。我把我的叫做<code class="fe nx ny nz oa b">DCGAN</code>。在该目录中，创建一个名为<code class="fe nx ny nz oa b">data</code>的目录。然后，导航到<a class="ae ky" href="https://github.com/myleott/mnist_png" rel="noopener ugc nofollow" target="_blank">这个 GitHub repo </a>并下载<code class="fe nx ny nz oa b">mnist_png.tar.gz</code>。这个压缩文件包含 70000 个独立的 png 文件形式的 MNIST 数据集。当然，我们可以使用 PyTorch 的内置 MNIST 数据集，但这样你就不会知道如何实际加载图像数据进行训练。解压文件并将<code class="fe nx ny nz oa b">mnist_png</code>目录放到你的<code class="fe nx ny nz oa b">data</code>目录中。创建一个名为<code class="fe nx ny nz oa b">dcgan_mnist.py</code>的文件，并将其放在您的 DCGAN 目录中。您的项目目录应该如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/e0cb515e5693f248f64c049c922f7b28.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*ikfrJldwpQ3lItLhhirgjQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我们的项目目录，包括图像文件和 Python 脚本。0/、1/等中的数千个图像文件。未示出。</p></figure><p id="f350" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，将以下内容添加到您的<code class="fe nx ny nz oa b">dcgan_mnist.py</code>脚本中:</p><pre class="kj kk kl km gt oc oa od oe aw of bi"><span id="37d3" class="og lw it oa b gy oh oi l oj ok">import os</span><span id="1609" class="og lw it oa b gy ol oi l oj ok">import torch<br/>from torch import nn<br/>from torch import optim<br/>import torchvision as tv<br/>from torchvision.datasets import ImageFolder<br/>from torch.utils.data import DataLoader</span></pre><p id="cf45" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">好了，现在我们准备开始了。</p><h1 id="c44f" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">发电机</h1><p id="8515" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">将以下内容添加到您的<code class="fe nx ny nz oa b">dcgan_mnist.py</code>脚本中:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="8a7e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">生成器继承了<code class="fe nx ny nz oa b">nn.Module</code>，它是 PyTorch 神经网络的基类。生成器有三种方法:</p><h2 id="9d6c" class="og lw it bd lx op oq dn mb or os dp mf li ot ou mh lm ov ow mj lq ox oy ml oz bi translated">发电机。__init__</h2><p id="fbb8" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">构造函数，存储实例变量并调用<code class="fe nx ny nz oa b">_init_layers</code>。这里不多说了。</p><h2 id="3532" class="og lw it bd lx op oq dn mb or os dp mf li ot ou mh lm ov ow mj lq ox oy ml oz bi translated">发电机。<code class="fe nx ny nz oa b">_init_modules</code></h2><p id="f685" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">这个方法实例化 PyTorch 模块(或者其他框架中称为“层”)。其中包括:</p><ul class=""><li id="a6ba" class="mn mo it lb b lc ld lf lg li pa lm pb lq pc lu pd mv mw mx bi translated">线性(“全连通”)模块，用于将潜在空间映射到 7<em class="om">×</em>7<em class="om">×</em>256 = 12544 维空间。正如我们将在<code class="fe nx ny nz oa b">forward</code>方法中看到的，这个 12544 长度的张量被整形为(256，7，7)“图像”张量(通道<em class="om"> × </em>高度×宽度)。在 PyTorch 中，与 TensorFlow 不同，通道出现在空间维度之前。</li><li id="d1dd" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu pd mv mw mx bi translated">一维批处理规范化模块(如果指定)。</li><li id="3761" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu pd mv mw mx bi translated">泄漏的 ReLU 模块。</li><li id="af17" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu pd mv mw mx bi translated">二维卷积层。</li><li id="2af3" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu pd mv mw mx bi translated">两个 2 维转置卷积层；这些用于放大图像。请注意，一个卷积层的输出通道是下一个卷积层的输入通道。</li><li id="6ebe" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu pd mv mw mx bi translated">两个二维批处理规范化层(如果指定)。</li><li id="6a2d" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu pd mv mw mx bi translated">一个 Tanh 模块作为输出激活。我们将重新调整我们的图像到范围[-1，1]，所以我们的发生器输出激活应该反映这一点。</li></ul><p id="1bdc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些可以在<code class="fe nx ny nz oa b">__init__</code>方法中实例化，但是我喜欢将模块实例化与构造函数分开。对于这么简单的模型来说，这是微不足道的，但是随着模型变得越来越复杂，这有助于保持代码的简单。</p><h2 id="61f8" class="og lw it bd lx op oq dn mb or os dp mf li ot ou mh lm ov ow mj lq ox oy ml oz bi translated">发电机。<code class="fe nx ny nz oa b">forward</code></h2><p id="d18c" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">这是我们的生成器用来从随机噪声中生成样本的方法。输入张量传递给第一个模块，其输出传递给下一个模块，<em class="om">的输出传递给下一个模块，依此类推。这相当简单，但我想提醒您注意两个有趣的特性:</em></p><ol class=""><li id="180f" class="mn mo it lb b lc ld lf lg li pa lm pb lq pc lu mu mv mw mx bi translated">注意线<code class="fe nx ny nz oa b">intermediate = intermediate.view((-1, 256, 7, 7))</code>。与 Keras 不同，PyTorch 不使用显式的“整形”模块；相反，我们使用 PyTorch 操作“视图”手动重塑张量。其他简单的 PyTorch 操作也可以在向前传递的过程中应用，比如将一个张量乘以 2，PyTorch 不会眨一下眼睛。</li><li id="af09" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu mu mv mw mx bi translated">注意在<code class="fe nx ny nz oa b">forward</code>方法中有多少<code class="fe nx ny nz oa b">if</code>语句。PyTorch 使用运行定义策略，这意味着计算图是在向前传递的过程中动态构建的。这使得 PyTorch 极其灵活；没有什么可以阻止你向前传球添加循环，或者随机选择几个模块中的一个来使用。</li></ol><h1 id="c5de" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">鉴别器</h1><p id="0790" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">将以下内容添加到您的<code class="fe nx ny nz oa b">dcgan_mnist.py</code>脚本中:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="c231" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我不会对这个做太多的描述，因为它和发生器非常相似，但方向相反。通读一遍，确保你明白它在做什么。</p><h1 id="eff5" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">DCGAN</h1><p id="bf9a" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">将以下内容添加到您的<code class="fe nx ny nz oa b">dcgan_mnist.py</code>脚本中:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="on oo l"/></div></figure><h2 id="09e8" class="og lw it bd lx op oq dn mb or os dp mf li ot ou mh lm ov ow mj lq ox oy ml oz bi translated">DCGAN。__init__</h2><p id="fb5b" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">让我们一行一行地检查构造函数:</p><pre class="kj kk kl km gt oc oa od oe aw of bi"><span id="9146" class="og lw it oa b gy oh oi l oj ok">self.generator = Generator(latent_dim).to(device)<br/>self.discriminator = Discriminator().to(device)</span></pre><p id="a5d9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">构造函数的前两行(非 docstring)实例化生成器和鉴别器，将它们移动到指定的设备，并将它们存储为实例变量。该设备通常是“cpu”，或者“cuda”，如果你想使用 gpu。</p><pre class="kj kk kl km gt oc oa od oe aw of bi"><span id="9156" class="og lw it oa b gy oh oi l oj ok">self.noise_fn = noise_fn</span></pre><p id="563e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们将<code class="fe nx ny nz oa b">noise_fn</code>存储为一个实例变量；<code class="fe nx ny nz oa b">noise_fn</code>是一个以整数<code class="fe nx ny nz oa b">num</code>作为输入，以 PyTorch 张量的形式返回<code class="fe nx ny nz oa b">num</code>潜在向量作为 shape (num，latent_dim)输出的函数。这个 PyTorch 张量必须在指定的设备上。</p><pre class="kj kk kl km gt oc oa od oe aw of bi"><span id="6d2a" class="og lw it oa b gy oh oi l oj ok">self.dataloader = dataloader</span></pre><p id="7cb9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将一个 torch.utils.data.DataLoader 对象 dataloader 存储为实例变量；稍后将详细介绍。</p><pre class="kj kk kl km gt oc oa od oe aw of bi"><span id="3988" class="og lw it oa b gy oh oi l oj ok">self.batch_size = batch_size<br/>self.device = device</span></pre><p id="af36" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将批次大小和设备存储为实例变量。简单。</p><pre class="kj kk kl km gt oc oa od oe aw of bi"><span id="8e3d" class="og lw it oa b gy oh oi l oj ok">self.criterion = nn.BCELoss()<br/>self.optim_d = optim.Adam(self.discriminator.parameters(), lr=lr_d, betas=(0.5, 0.999))<br/>self.optim_g = optim.Adam(self.generator.parameters(), lr=lr_g, betas=(0.5, 0.999))</span></pre><p id="bc43" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将损失函数设置为<a class="ae ky" rel="noopener" target="_blank" href="/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a">二进制交叉熵</a>，并为生成器和鉴别器实例化 Adam 优化器。PyTorch 优化器需要知道他们在优化什么。对于鉴别器，这意味着鉴别器网络内的所有可训练参数。因为我们的 Discriminator 类继承自 nn。模块中，它有<code class="fe nx ny nz oa b">parameters()</code>方法，该方法返回所有实例变量中的所有可训练参数，这些变量也是 PyTorch 模块。发电机也是如此。</p><pre class="kj kk kl km gt oc oa od oe aw of bi"><span id="3b4f" class="og lw it oa b gy oh oi l oj ok">self.target_ones = torch.ones((batch_size, 1), device=device)<br/>self.target_zeros = torch.zeros((batch_size, 1), device=device)</span></pre><p id="09c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">训练目标，设置到指定的设备。记住，鉴别器试图将真实样本分类为 1，将生成的样本分类为 0，而生成器试图让鉴别器将生成的样本错误分类为 1。我们在这里定义并存储它们，这样我们就不必在每个训练步骤中重新创建它们。</p><h2 id="a43d" class="og lw it bd lx op oq dn mb or os dp mf li ot ou mh lm ov ow mj lq ox oy ml oz bi translated">DCGAN.generate_samples</h2><p id="c9f9" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">生成样本的辅助方法。注意，使用了<code class="fe nx ny nz oa b">no_grad</code>上下文管理器，它告诉 PyTorch 不要跟踪梯度，因为这种方法不用于训练网络。还要注意，不管指定的设备是什么，返回的张量都被设置为 cpu，这是进一步使用所必需的，比如显示样本或将样本保存到磁盘。</p><h2 id="3f9b" class="og lw it bd lx op oq dn mb or os dp mf li ot ou mh lm ov ow mj lq ox oy ml oz bi translated">DCGAN.train_step_generator</h2><p id="696a" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">该方法执行生成器的一个训练步骤，并以浮点形式返回损失。让我们一步一步来:</p><pre class="kj kk kl km gt oc oa od oe aw of bi"><span id="a501" class="og lw it oa b gy oh oi l oj ok">self.generator.zero_grad()</span></pre><p id="04bb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">清除发生器的渐变。这是必要的，因为 PyTorch 自动跟踪梯度和计算网络。我们不希望一个训练步骤影响下一个。</p><pre class="kj kk kl km gt oc oa od oe aw of bi"><span id="f074" class="og lw it oa b gy oh oi l oj ok">latent_vec = self.noise_fn(self.batch_size)<br/>generated = self.generator(latent_vec)<br/>classifications = self.discriminator(generated)<br/>loss = self.criterion(classifications, self.target_ones)</span></pre><p id="5149" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">获得一批潜在向量，用它们生成样本，区分每个样本的真实程度，然后使用二进制交叉熵准则计算损失。请注意，通过将这些网络链接在一起，我们创建了一个单一的计算图，从潜在向量开始，包括发生器和鉴别器网络，并在损耗处结束。</p><pre class="kj kk kl km gt oc oa od oe aw of bi"><span id="7a1a" class="og lw it oa b gy oh oi l oj ok">loss.backward()<br/>self.optim_g.step()</span></pre><p id="9b4b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">PyTorch 的主要优点之一是它自动跟踪计算图形及其梯度。通过对损失调用<code class="fe nx ny nz oa b">backward</code>方法，PyTorch 应用反向传播并计算损失相对于计算图中每个参数的梯度。然后通过调用生成器的优化器的<code class="fe nx ny nz oa b">step</code>方法，生成器的参数(只有<em class="om">和</em>生成器的参数)在梯度的负方向上被轻微推动。</p><pre class="kj kk kl km gt oc oa od oe aw of bi"><span id="ace2" class="og lw it oa b gy oh oi l oj ok">return loss.item()</span></pre><p id="86a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们归还损失。使用<code class="fe nx ny nz oa b">item</code>方法很重要，这样我们将返回一个浮点数而不是 PyTorch 张量。如果我们返回张量，Python 垃圾收集器将无法清理底层的计算图形，我们将很快耗尽内存。</p><h2 id="9ff6" class="og lw it bd lx op oq dn mb or os dp mf li ot ou mh lm ov ow mj lq ox oy ml oz bi translated">DCGAN.train_step_discriminator</h2><p id="1d3c" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">这种方法与<code class="fe nx ny nz oa b">train_step_generator</code>非常相似，但是有两个显著的不同。首先:</p><pre class="kj kk kl km gt oc oa od oe aw of bi"><span id="3660" class="og lw it oa b gy oh oi l oj ok">with torch.no_grad():<br/>    fake_samples = self.generator(latent_vec)</span></pre><p id="716b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上下文管理器<code class="fe nx ny nz oa b">no_grad</code>在这里用来告诉 PyTorch 不要担心跟踪渐变。这是不必要的，但减少了不必要的计算。第二:</p><pre class="kj kk kl km gt oc oa od oe aw of bi"><span id="1348" class="og lw it oa b gy oh oi l oj ok">loss = (loss_real + loss_fake) / 2</span></pre><p id="42ae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这条线真的很酷。<code class="fe nx ny nz oa b">loss_real</code>是鉴别器对真实样本的损耗(并附上其计算图)，而<code class="fe nx ny nz oa b">loss_fake</code>是对假样本的损耗(及图)。PyTorch 能够使用<code class="fe nx ny nz oa b">+</code>操作符将这些组合成一个计算图。然后，我们将反向传播和参数更新应用于该组合计算图。如果你不认为这非常简单，尝试在另一个框架中重写。</p><h2 id="cad2" class="og lw it bd lx op oq dn mb or os dp mf li ot ou mh lm ov ow mj lq ox oy ml oz bi translated">DCGAN.train_epoch</h2><p id="bfea" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">该函数为一个时期训练发生器和鉴别器，这是对整个数据集的一次遍历。在短暂的迂回之后，我们将回到这个问题上。</p><h1 id="a43c" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">主要的</h1><p id="8a5d" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">将以下代码添加到您的脚本中:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="03c0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该功能构建、训练和展示 GAN。</p><pre class="kj kk kl km gt oc oa od oe aw of bi"><span id="33f8" class="og lw it oa b gy oh oi l oj ok">import matplotlib.pyplot as plt<br/>from time import time<br/>batch_size = 32<br/>epochs = 100<br/>latent_dim = 16</span></pre><p id="d3c0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">导入<code class="fe nx ny nz oa b">pyplot</code>(用于可视化生成的数字)和<code class="fe nx ny nz oa b">time</code>(用于训练计时)。将训练批次大小设置为 32，将时期数设置为 100，将潜在维度设置为 16。</p><pre class="kj kk kl km gt oc oa od oe aw of bi"><span id="be15" class="og lw it oa b gy oh oi l oj ok">device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span></pre><p id="0878" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该行检查 cuda 设备是否可用。如果是，<code class="fe nx ny nz oa b">device</code>被指定为该设备；否则，<code class="fe nx ny nz oa b">device</code>被分配 cpu。</p><pre class="kj kk kl km gt oc oa od oe aw of bi"><span id="7a18" class="og lw it oa b gy oh oi l oj ok">transform = tv.transforms.Compose([<br/>            tv.transforms.Grayscale(num_output_channels=1),<br/>            tv.transforms.ToTensor(),<br/>            tv.transforms.Normalize((0.5,), (0.5,))<br/>            ])</span></pre><p id="29ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据加载器使用这种复合转换来预处理图像。我们之前下载的 MNIST 数据集是。png 文件；当 PyTorch 从磁盘加载它们时，它们必须经过处理，以便我们的神经网络可以正确使用它们。这些转换依次为:</p><ul class=""><li id="ac72" class="mn mo it lb b lc ld lf lg li pa lm pb lq pc lu pd mv mw mx bi translated"><code class="fe nx ny nz oa b">Grayscale(num_output_channels=1)</code>:将图像转换成灰度。加载时，MNIST 数字为三通道 RGB 格式。<code class="fe nx ny nz oa b">Greyscale</code>把这三个减为一个。</li><li id="1813" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu pd mv mw mx bi translated"><code class="fe nx ny nz oa b">ToTensor()</code>:将图像转换为 PyTorch 张量，尺寸为 channels × height × width。这也会重新调整像素值，从 0 到 255 之间的整数到 0.0 到 1.0 之间的浮点数。</li><li id="d8c1" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu pd mv mw mx bi translated"><code class="fe nx ny nz oa b">Normalize((0.5,), (0.5,))</code>:从范围[0.0，1.0]到[-1.0，1.0]缩放和平移像素值。第一个参数为μ，第二个参数为σ，应用于每个像素的函数为:</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/e162ed144bd9e8ebbbec4998a0f7b010.png" data-original-src="https://miro.medium.com/v2/resize:fit:352/format:webp/1*bk-8koolNNUEgnBSw5bF9w.png"/></div></figure><p id="2363" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">μ和σ是一元组的原因是这种变换是针对每个通道应用的。到 RGB 图像的等效变换将是<code class="fe nx ny nz oa b">Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))</code></p><pre class="kj kk kl km gt oc oa od oe aw of bi"><span id="e265" class="og lw it oa b gy oh oi l oj ok">dataset = ImageFolder(<br/>            root=os.path.join("data", "mnist_png", "training"),<br/>            transform=transform<br/>            )</span></pre><p id="c511" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这里，我们通过指定它的根和要应用的转换来创建数据集。这用于创建数据加载器:</p><pre class="kj kk kl km gt oc oa od oe aw of bi"><span id="6b5d" class="og lw it oa b gy oh oi l oj ok">dataloader = DataLoader(dataset,<br/>            batch_size=batch_size,<br/>            shuffle=True,<br/>            num_workers=2<br/>            )</span></pre><p id="cc88" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">DataLoader 是一个对象，它从数据集中加载数据。在这里，我们指定我们的批处理大小，告诉数据加载器在不同的时期之间混洗数据集，并使用两个工作进程的多处理(如果您使用的是 Windows，这会导致问题，请将<code class="fe nx ny nz oa b">num_workers</code>设置为 0)。您可以遍历这个数据加载器，每次迭代都会返回一个元组，其中包含:</p><ol class=""><li id="d762" class="mn mo it lb b lc ld lf lg li pa lm pb lq pc lu mu mv mw mx bi translated">形状为(32，1，28，28)的 PyTorch 张量，对应于一批(32 个样本)灰度(1 通道)MNIST 图像(28×28 像素)。</li><li id="b37d" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu mu mv mw mx bi translated">数字 0 到 9 的形状(32)py torch 张量，对应于该图像的标签(数字)。这些类标签取自目录结构，因为所有的 0 都在目录<code class="fe nx ny nz oa b">0</code>中，所有的 1 都在<code class="fe nx ny nz oa b">1</code>中，等等。</li></ol><pre class="kj kk kl km gt oc oa od oe aw of bi"><span id="64a1" class="og lw it oa b gy oh oi l oj ok">noise_fn = lambda x: torch.rand((x, latent_dim), device=device)</span></pre><p id="04a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">产生随机正态分布噪声的函数。</p><pre class="kj kk kl km gt oc oa od oe aw of bi"><span id="f637" class="og lw it oa b gy oh oi l oj ok">gan = DCGAN(latent_dim, noise_fn, dataloader, device=device)<br/>start = time()<br/>for i in range(10):<br/>    print(f"Epoch {i+1}; Elapsed time = {int(time() - start)}s")<br/>    gan.train_epoch()</span></pre><p id="7183" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">建立和训练 GAN。</p><h2 id="efe2" class="og lw it bd lx op oq dn mb or os dp mf li ot ou mh lm ov ow mj lq ox oy ml oz bi translated">DCGAN.train_epoch，再来一遍:</h2><p id="a65c" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">既然我们已经讨论了什么是数据加载器，让我们再来看看这个。该方法非常简单明了，尽管有些冗长，但我想重点介绍两行代码:</p><pre class="kj kk kl km gt oc oa od oe aw of bi"><span id="0ff5" class="og lw it oa b gy oh oi l oj ok">for batch, (real_samples, _) in enumerate(self.dataloader):<br/>   real_samples = real_samples.to(self.device)</span></pre><p id="14e9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，我们遍历数据加载器。我们将数据加载器包装在一个枚举器中，这样我们就可以跟踪批号，但是正如您所看到的，数据加载器确实像承诺的那样返回了一个元组。我们将一批图像张量分配给<code class="fe nx ny nz oa b">real_samples</code>，并忽略标签，因为我们不需要它们。然后，在循环中，我们将<code class="fe nx ny nz oa b">real_samples</code>移动到指定的设备。模型的输入和模型本身在同一个设备上是很重要的；如果你忘记这样做，不要担心，PyTorch 一定会让你知道的！此外，不要担心数据加载器“耗尽”。一旦我们遍历了整个数据集，循环将会结束，但是如果我们再次尝试遍历它，它将会从头开始(首先洗牌，因为我们在制作数据加载器时指定了这一点)。</p><h1 id="7cab" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">让我们试着运行它？</h1><p id="4b28" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">如果复制和粘贴正确，运行脚本应该会显示几分钟的训练统计数据，然后是一些生成的数字。希望它看起来像这样:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/83340ca62217bd65620ced28cb4f1618.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*M1ea99fSMJXPMHhBSpzNdQ.png"/></div></figure><p id="88d0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果它们看起来很糟糕，你的损失暴增，试着再跑一次(甘的不稳定性是出了名的)。如果它<em class="om">仍然</em>不工作，请在下面留下评论，我们看看是否能调试它。</p><p id="a099" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">只是为了好玩，我修改了脚本，看看在每 10 个训练步骤之后，生成器能够做什么。这是结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/cf615f2788a0cf313cc6daf4bc524564.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*mVEtS64T4ShRYWSM5xZ9XQ.gif"/></div></figure><p id="f8fb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我觉得只走 1000 步就已经很不错了。这是那些训练步骤的损失，分成 10 步“时期”。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/1b00a0372761da406b07f2ecbfe4f5dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*Xz1nmGMC35WCHSFZ5eFgQw.png"/></div></figure><h1 id="2aa4" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结束语</h1><ul class=""><li id="9990" class="mn mo it lb b lc mp lf mq li mr lm ms lq mt lu pd mv mw mx bi translated">本教程中描述的 DCGAN 显然非常简单，但应该足以让您开始在 PyTorch 中实现更复杂的 GAN。</li><li id="b7f3" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu pd mv mw mx bi translated">在我制作一个教程之前，你能修改这个脚本来制作一个<a class="ae ky" href="https://arxiv.org/abs/1411.1784" rel="noopener ugc nofollow" target="_blank">条件句</a>吗？</li><li id="09ae" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu pd mv mw mx bi translated">完整的脚本可在<a class="ae ky" href="https://github.com/ConorLazarou/pytorch-generative-models/blob/master/GAN/DCGAN/dcgan_mnist.py" rel="noopener ugc nofollow" target="_blank">这里</a>获得。</li><li id="81cb" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu pd mv mw mx bi translated">所有未引用的图片都是我自己的。请随意使用它们，但请引用❤的这篇文章</li></ul><div class="pi pj gp gr pk pl"><a href="https://github.com/ConorLazarou/pytorch-generative-models/blob/master/GAN/DCGAN/dcgan_mnist.py" rel="noopener  ugc nofollow" target="_blank"><div class="pm ab fo"><div class="pn ab po cl cj pp"><h2 class="bd iu gy z fp pq fr fs pr fu fw is bi translated">ConorLazarou/py torch-生成模型</h2><div class="ps l"><h3 class="bd b gy z fp pq fr fs pr fu fw dk translated">产生 MNIST 数字的简单 DCGAN 实现。</h3></div><div class="pt l"><p class="bd b dl z fp pq fr fs pr fu fw dk translated">github.com</p></div></div><div class="pu l"><div class="pv l pw px py pu pz ks pl"/></div></div></a></div></div></div>    
</body>
</html>