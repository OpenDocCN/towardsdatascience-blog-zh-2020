# Spark vs Pandas，第 3 部分——Scala vs Python

> 原文：<https://towardsdatascience.com/spark-vs-pandas-part-3-scala-vs-python-7b267b130158?source=collection_archive---------30----------------------->

## 为什么编程语言很重要

![](img/c5b7c2736ca7d8bf85b986f34a74b4ae.png)

蒂莫西·戴克斯在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 拍摄的照片

在“熊猫 vs Spark”系列的第三部分中，我们将更仔细地看看编程语言以及选择一种语言的含义。

最初我想写一篇文章来公平地比较熊猫和火花，但它继续增长，直到我决定把它分开。这是小编的第二部。

*   [星火大战熊猫，第一部——熊猫](/spark-vs-pandas-part-1-pandas-10d768b979f5)
*   [星火大战熊猫，第二部——星火](/spark-vs-pandas-part-2-spark-c57f8ea3a781)
*   Spark vs Pandas，第 3 部分—编程语言
*   星火大战熊猫，第四部分——枪战与推荐

## 期待什么

本系列的第三部分将关注编程语言 Scala 和 Python。Spark 本身是用 Scala 编写的，绑定了 Python，而 Pandas 只适用于 Python。

# 为什么编程语言很重要

当然，编程语言起着重要的作用，尽管它们的相关性经常被误解。在简历中加入合适的编程语言可能最终会成为获得一份特定工作或项目的决定性因素之一。这是编程语言的相关性可能被误解的一个很好的例子，尤其是在数据科学的背景下。

不要误解我的意思，成为一个给定编程语言的专家要比花几周时间编写代码花费更多的时间。你不仅需要习惯语法，还需要习惯语言特有的习惯用法。这真的就像学习一门外国自然语言，需要的不仅仅是知道单词和语法(这本身已经是一项巨大的任务)。

另一方面，在某些领域，比如数据科学，方法学至少和了解特定的编程语言一样重要。我更愿意雇佣一个在使用 Python 的 R for ML 项目中有深厚知识的机器学习专家，而不是一个没有数据科学知识的 Python 专家，我打赌你们大多数人都会同意。因此，从专家的角度来看，编程语言在你的简历中并不重要(至少不应该如此——我知道它在现实中是不同的)，只要你知道在引擎盖下发生了什么，并且理解处理问题的科学方法。

但是从一个*项目的*角度来看，事情看起来完全不同:当建立一个更大的项目并开始创建实际的代码时，你最终需要考虑你*最好*想要使用哪种编程语言。而且这个决定有很多后果，你应该清楚。我将在本文中讨论其中的许多，重点关注 Scala 和 Python，它们是 Spark 和 Pandas 的自然编程语言。

# Python vs Scala

在比较 Spark 和 Pandas 时，我们还应该包括每个框架所支持的编程语言的比较。虽然 Pandas 是“只支持 Python”的，但是你可以将 Spark 与 Scala、Java、Python 和 R 一起使用，并且相应的社区正在开发更多的绑定。

因为选择一种编程语言将会有一些严重的直接和间接的影响，我想指出 Python 和 Scala 之间的一些基本差异。更详细的讨论可能会形成一篇独立的文章。我主要选择了这个比较，因为[我在开头提到的原始文章](/stop-using-pandas-and-start-using-spark-with-scala-f7364077c2e0)也建议人们应该开始使用 Scala(而不是 Python ),而我再次提出了一个更有区别的观点。

## 类型系统

让我们先来看看类型系统:两种语言都提供了一些简单的内置类型，比如整数、浮点数和字符串。Scala 中的基本类型也提供了一些特定的大小，比如 16 位整数的`Short`，64 位浮点数的`Double`。

两种语言都提供了具有继承的类，尽管许多细节确实不同。

Scala 和 Python 中的类型系统有两个主要区别:

*   虽然 Scala 是一种强类型语言(即每个变量和参数都有固定的类型，如果试图使用错误的类型，Scala 会立即抛出错误)，但 Python 是动态类型的(即单个变量或参数在技术上可以接受任何数据类型——尽管代码可能会采用特定的类型，因此在执行过程中会失败)。
*   由于 Python 的动态类型特性，某个操作的*合适类型通常只由它实现的操作决定。使用正确的基类或继承通常并不重要，重要的只是可用的方法。这种范式被称为“[鸭子分型](https://en.wikipedia.org/wiki/Duck_typing)*

这些差异有着巨大的影响，我们将在后面看到。

## 功能语言方面

虽然 Python 已经从一种简单的脚本语言发展成为一种功能齐全的编程语言，但是 Scala 作为一个研究项目，从一开始就把函数式编程语言(比如 Haskell)的一些方面与面向对象语言(比如 Java)的一些方面结合起来——这种结合是否成功，甚至是否可取，还存在一些争议。

对我来说，术语*函数式编程*指的是某种范式，即*函数不应该有副作用*(即它们不改变某些全局状态，并尊重*不变性*)。*另一方面，面向对象编程*正好相反，其中每个方法都被视为与对象*进行通信的某种方式，而对象*又会改变其状态*。将范式本身与特定的语言特性分开是很重要的——几乎任何语言都可以实现纯函数式程序，但只有一些语言会提供支持概念，而其他语言会变得复杂。*

Python 和 Scala 都支持一些函数概念，具体来说函数可以作为值和匿名函数传递( [lambda 函数](https://en.wikipedia.org/wiki/Anonymous_function))。Scala 还提供了一个丰富的集合库，它很好地支持了函数式方法，比如不变性，而 Pythons 在这一领域最好的贡献是列表理解。

## 执行模型

Python 是一种*解释的*语言，本质上意味着 Python 可以立即执行任何代码，只要它是有效的 Python 语法。不需要“构建”或“编译”步骤。这使得 Python 成为交互式工作的绝佳选择，因为 Python 可以在您键入代码时立即执行。

另一方面，Scala 是一种*编译的*语言，这意味着 *Scala 编译器*首先需要将 Scala 代码转换成所谓的用于 JVM 的 [Java 字节码](https://en.wikipedia.org/wiki/Java_bytecode)(在执行过程中，它又被翻译成本机代码)。这种三步法(编写、编译、执行)通常会使代码实验更加困难，因为周转时间更长。幸运的是，Scala 还提供了一个交互式 shell，它能够编译并立即执行你输入的代码。但是一般来说，Scala 是用来编译的。

## 学习曲线

总的来说，Python 非常容易学习——它是专门设计来强调可读性的。Pythons 的动态类型系统非常适合从未接触过编程语言的初学者。Python 非常宽容，它的语法很容易理解。

另一方面，Scala 的学习曲线要陡峭得多，而且——与 Python 相反——对于新手来说，代码很快就会变得难以阅读。尽管使用 Spark 首先只需要一小部分，但当你开始深入 Spark 并试图解决更复杂的问题时，你最终需要理解越来越多的 Scala 细节。

我发现大多数 Java 程序员在开始时在习惯 Scala 的功能方面有很大的问题，部分原因是因为非常简洁的语法。我总觉得 Scala 中的信息密度(即每个字母程序代码编码多少逻辑)比 Java 中的高得多，这种密度在开始时对大多数人的大脑来说是一种挑战，因为他们习惯了 Java 中更多的锅炉板代码，这大大降低了信息密度。

## 代码的健壮性

与静态类型语言相比，动态类型语言有一个巨大的缺点:使用错误的类型只能在运行时检测到，而不能在更早的时候(编译时)检测到。这意味着，如果在一些非常罕见的情况下用错误的数据类型调用一个函数，您可能只会在为时已晚的时候(在生产中)才注意到这一点。

相比之下，静态类型和编译语言将阻止您将损坏的代码发布到产品中。它会直接指向错误类型的用法，你必须在编译器完成它的工作之前修复它。

由于这种差异，我发现编写健壮的、生产就绪的 Python 代码比编写健壮的 Scala 代码要困难得多。当编写一个完整的*框架*或*库*供其他应用程序使用时，这就更加困难了。应用程序可能会将错误的数据类型传递给函数，但这些类型在某些情况下可能“足够好”(因为它们实现了所有必需的方法)，但在其他情况下可能会失败(因为缺少其他方法或它们的签名已被更改)。

最重要的是，用 Python 进行重构可能非常困难，因为使用不同类型或重命名方法的后果并不总是能被您的 IDE 正确检测到。

## 生态系统

如今，一门编程语言的成功不主要依赖于它的语法或概念，而是依赖于它的生态系统。这包括许多方面，如有用的库的可用性、优秀编辑器的选择、相关操作系统的支持等等。

具体来说，当今的一系列库对使用特定编程语言的主要领域有着巨大的影响。最突出的例子是 Python，其中实现了大多数最新的机器学习算法——这是 Scala 远远落后的领域，尽管像 [ScalaNLP](http://www.scalanlp.org/) 这样的项目试图改善这种情况。

虽然 Scalas boost 在过去几年中可能可以追溯到 Apache Spark 的成功，但它也用于许多需要高并发性的网络服务项目，Scalas 函数式编程特性可以为实现健壮的多线程代码提供支持。

## 结论

Scala 和 Python 都有自己的位置。特别是在数据处理领域，Python 非常适合科学工作流，在探索阶段进行许多小而快速的代码实验，以获得新的见解。

Scala 的“编写-编译-执行”工作流其静态类型系统更适合工程工作流，其中处理特定问题的知识已经存在，因此不再进行实验。

正如我在“代码的健壮性”中指出的，我更喜欢使用强类型语言来编写产品代码，除非是在一些简单的情况下，在这些情况下应用程序几乎是微不足道的。

# 生态系统的价值

在 Scala 和 Python 的比较之后，让我们回到 Pandas 和 Spark。有一个方面与编程语言高度相关，那就是生态系统。我在上面已经提到了这个方面，但是让我们更关注可以与 Pandas 和 Spark 一起使用的库。

## Python 生态系统

由于 Pandas 的核心是建立在 NumPy 数组之上的，它自然地与一个由许多数字和统计库组成的非常丰富的生态系统集成得非常好。仅举几个重要的例子:

*   [SciKit 学习](https://scikit-learn.org/)
*   [统计模型](https://www.statsmodels.org/)
*   [张量流](https://www.tensorflow.org/)
*   [Matplotlib](https://matplotlib.org/)

此外，我们还有可爱的 [Jupyter 笔记本](https://jupyter.org/)用于互动工作，作为实验驱动的探索阶段的一部分。

## Scala 生态系统

另一方面，火花生活在一个完全不同的世界。作为 JVM 世界的一员，你可以使用所有种类的 Java 库——但是大多数 Java 库的焦点是网络、web 服务和数据库。数值算法不是 Java 的核心领域。

因此，Spark 的生态系统看起来非常不同。最重要的是，有许多连接器可以将 Spark 用于各种数据库，比如通过 JDBC 连接器的关系数据库、HBase、MongoDB、Cassandra 等等。

除了连接器，Spark 已经实现了[最重要的机器学习算法](https://spark.apache.org/docs/latest/ml-guide.html)，如回归、决策树等。然后我们还有 [Breeze](https://github.com/scalanlp/breeze/) 和 [ScalaNLP](http://www.scalanlp.org/) 用于较低级别的数值算法(Spark 也不能直接扩展这些算法以在不同的机器上并行工作)。但是当您将这些库与相应的 Python 库的可能性进行比较时，您会很快发现这些库的范围要小得多。

最后，通过使用 Zeppelin 或者在 Jupyter 中使用 py Spark(Spark 的 Python 绑定),我们也可以在笔记本环境中使用 Spark。

## 结论

我们看到熊猫和星火生态系统的巨大差异。虽然 Pandas 与各种数字包有着紧密的联系，但 Spark 在统一连接各种数据源方面表现出色。

# Python vs Scala for Spark

因为 Spark 可以与 Scala 和 Python 一起使用，所以有必要更深入地研究选择合适的编程语言来使用 Spark。

我已经指出，Python 有一个更大的数字库集合，通常用于数据科学项目。虽然这已经是使用 Python 和 PySpark 而不是 Scala 和 Spark 的有力论据，但另一个有力的论据是学习 Python 的容易程度，与非平凡的 Scala 程序所需的陡峭学习曲线形成对比。更糟糕的是，Scala 代码不仅难以编写，而且难以阅读和理解。这使得 Scala 成为协作项目的一种困难语言，在协作项目中，同事甚至非程序员也需要或想要理解应用程序的逻辑细节。在数据科学环境中，这种情况很常见。

## 用于数据科学的 Python

因为有许多与数据科学相关的库可用，也因为 Python 代码的易读性，所以我总是推荐使用 PySpark 进行真正的数据科学。这也非常符合许多数据科学家的概况，他们有很强的数学背景，但往往不是编程专家(他们的工作重点在其他地方)。

通过使用 PySpark，数据科学家可以处理不再适合本地机器内存的巨大数据集，同时(在一定程度上)他们仍然可以访问所有相关的 Python 库——只要他们可以缩减采样或聚合数据，以便这些工具和库再次变得可行。

## 数据工程的 Scala

对于数据工程来说，情况有所不同。对于这些类型的任务，我强烈推荐使用 Spark 和 Scala。首先，数据工程师应该有很强的技术背景，这样使用 Scala 才是可行的。接下来可能需要一些 Spark 中没有的自定义转换。但是 Spark 是非常可扩展的，在这种情况下，使用 Scala 作为原生 Spark 编程语言真的很划算。

使用 Scala 代替 Python 不仅能提供更好的性能，还能让开发人员以比使用 Python 更多的方式扩展 Spark。使用 Scala，你甚至可以访问 Spark 的内部开发者 API(只要它们不是`private`)，而 Python 只能访问 Spark 的公共终端用户 API。

此外，我坚信在数据工程项目中,“产品质量代码”的所有方面都比在笔记本环境中执行的探索性数据分析任务重要得多。这正是像 Scala 这样的静态类型和编译语言带来巨大好处的地方。

# 结论

选择一种编程语言并不容易。你必须考虑你的需求，包括功能性的和非功能性的。虽然 Python 非常适合数据科学，但我更喜欢使用 Scala 和 Spark 进行数据工程。

下一节也是最后一节将总结所有的发现，并给出更多何时使用什么的建议。