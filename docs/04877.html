<html>
<head>
<title>Image Segmentation: Predicting Image Mask with Carvana Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">图像分割:用Carvana数据预测图像掩模</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-segmentation-predicting-image-mask-with-carvana-data-32829ca826a0?source=collection_archive---------25-----------------------#2020-04-28">https://towardsdatascience.com/image-segmentation-predicting-image-mask-with-carvana-data-32829ca826a0?source=collection_archive---------25-----------------------#2020-04-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="1c3c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">本文使用CNN和U-Net模型演示了使用Carvana数据进行图像分割的任务。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/4fe557c91594885e9a5268a30854ccf7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H548-ElGViO-DK6ZzSAFjw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">信用:<a class="ae kv" href="https://unsplash.com/@introspectivedsgn" rel="noopener ugc nofollow" target="_blank">@自省dsgn </a></p></figure><p id="0d74" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在<a class="ae kv" href="https://medium.com/analytics-vidhya/beginners-guide-on-image-classification-vgg-19-resnet-50-and-inceptionresnetv2-with-tensorflow-4909c6478941" rel="noopener">我之前的博客</a>中，我们冒险进入了图像分类领域，任务是为输入图像识别标签或类别。在我们之前的上下文中，我们对狗的照片进行了分类，人们可以了解算法识别的是哪种类型的狗。然而，假设一个人想知道狗是否由它的主人陪伴，或者在这些物体的图像和位置中是否有两只狗等等。在这种情况下，需要使用图像分割来代替。</p><p id="8693" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">想象一下，图像的每个像素都被赋予了特定的类别。以汽车图片为例，可以有三个类别:汽车、道路和背景的其余部分。这些类“告诉”计算机哪个像素属于哪个类。图像分割的任务是训练神经网络，该神经网络能够预测输入图像的逐像素类别。预测的输出被称为图像的“掩模”。该技术在物体识别、人脸识别、医学图像分析和卫星图像分析等方面都有应用。</p><p id="015e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这个项目中，我们将使用两种不同的方法训练神经网络来预测Carvana数据的图像掩模，代码库可以在这里找到<a class="ae kv" href="https://github.com/ZeeTsing/Carvana_challenge" rel="noopener ugc nofollow" target="_blank"/>。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="0115" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">#数据</strong></p><p id="da35" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://www.kaggle.com/c/carvana-image-masking-challenge/overview" rel="noopener ugc nofollow" target="_blank">数据集</a>来自Carvana的Kaggle上举办的图像屏蔽挑战。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/7e6768ce4db059a16376fac5317faf99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*S0FmXVwqpW_w1MIft_rmPA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来自数据集的样本图片。左图是原始照片，中间显示面具，右图显示原始减去背景，只保留汽车。</p></figure><p id="7b21" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">目前只有两个班级:</p><ul class=""><li id="d411" class="ma mb iq ky b kz la lc ld lf mc lj md ln me lr mf mg mh mi bi translated">类别0:背景</li><li id="c9ee" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr mf mg mh mi bi translated">类别1:前景，汽车</li></ul><p id="a7ce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每辆车都有16张不同位置的1918*1280像素的高质量照片。在列车组中，有318节车厢，总共5088幅图像；和6254辆汽车，总共100，064幅图像。我们将使用训练集来分割训练和验证数据，而模型将完全看不到测试集。</p><p id="14fd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于数据预处理，我们选择使用Keras图像处理简单地水平翻转图像。</p><p id="51f5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">#引入骰子系数</strong></p><p id="1d23" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在制定任务时，我们认识到生成图像掩模类似于一个分类任务，因为模型为每个像素预测一个类别标签。因此，用于分类任务的评估度量，例如准确性，似乎是该任务的自然选择，不是吗？然而，情况并非如此，我们需要为此任务引入一个新的指标。在这里，我将使用数据集举例说明。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/75686b028867ab1c0a2fca5efe5d7dcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*avfB9s0OgLM7qS6wBi6BAw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">真实面具</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/8f881efd416a938a1d62a316d47f6ca7.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*QEP16QsOy54XqKC8zjml9Q.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">掩模预测</p></figure><p id="dec0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">左边的图像是从训练集中随机选择的真实遮罩。黄色区域是汽车，紫色是背景。我们还观察到前景占总像素的18%，而背景占82%。一般来说，汽车(前景)只占图像总尺寸的不到20%。</p><p id="c9be" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">假设我们有一个完全紫色的遮罩预测，换句话说，它预测只有背景出现在图像中，而没有检测到前景。</p><p id="bbed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们评估准确，它给我们一个体面的82%的分数，因为背景是正确预测的。听起来很棒？</p><p id="67a7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，图像分割不仅学习图像中的内容，还学习图像中的位置。准确性作为一种衡量标准将无法捕捉“在哪里”的信息。在这种情况下，我们引入骰子系数来同时捕捉“什么”和“哪里”。</p><p id="cf63" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Dice系数逐类地度量两幅图像之间的相似性。1分表示两幅图像完全相同，0分表示完全不同。如果我们拿上面同样的例子，dice coefficient给出的分数是41%。</p><p id="e950" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">计算如下:</p><blockquote class="mq mr ms"><p id="608f" class="kw kx mt ky b kz la jr lb lc ld ju le mu lg lh li mv lk ll lm mw lo lp lq lr ij bi translated">两幅图像的总像素数合计= 200(为简单起见，我们假设每张图片是100个像素，而不是实际的像素数)</p><p id="2baa" class="kw kx mt ky b kz la jr lb lc ld ju le mu lg lh li mv lk ll lm mw lo lp lq lr ij bi translated">前景(汽车):重叠区域= 0</p><p id="030b" class="kw kx mt ky b kz la jr lb lc ld ju le mu lg lh li mv lk ll lm mw lo lp lq lr ij bi translated"><em class="iq"> (2 *重叠面积)/(总像素组合)= 0/200 = 0 </em></p><p id="5e93" class="kw kx mt ky b kz la jr lb lc ld ju le mu lg lh li mv lk ll lm mw lo lp lq lr ij bi translated">背景:重叠面积= 82</p><p id="e51e" class="kw kx mt ky b kz la jr lb lc ld ju le mu lg lh li mv lk ll lm mw lo lp lq lr ij bi translated"><em class="iq"> (2 *重叠面积)/(总像素组合)= 82*2/200 = 0.82 </em></p><p id="ee39" class="kw kx mt ky b kz la jr lb lc ld ju le mu lg lh li mv lk ll lm mw lo lp lq lr ij bi translated"><em class="iq">骰子=(前景+背景)/2 =(0%+82%)/2 =</em><strong class="ky ir"><em class="iq">41</em>%</strong></p></blockquote><p id="77ac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将使用dice系数作为主要指标来评估我们的模型性能，并将准确性作为一个指标进行监控。下面的代码片段定义了项目使用的dice系数。骰子系数可用于骰子损失，即(1-骰子系数)。平滑变量用于通过不使项接近零来帮助反向传播，并防止过拟合相对较大的值。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mx my l"/></div></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="d958" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">#型号:CNN </strong></p><p id="2174" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的第一个模型是一个简单的三层卷积模型，作为一个简单的基线。输入图片是具有3个通道的原始图片，并且为了更快的训练而调整为较小的尺寸。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="ed3e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用的损失函数是二元交叉熵，监控的度量是dice系数和准确度。</p><p id="7d59" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">#型号:U-Net </strong></p><p id="0042" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，经过一些研究，我们转向了一种叫做U-Net的模型结构。它是一种有效的图像分割模型结构。U-Net网络有两部分:编码器(下采样器)和解码器(上采样器)。它看起来像原始符号上的U形。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mz"><img src="../Images/57b55f1efce384cfeb67dcc9cdc5289e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*r_GHJWOvUL_PVGfY"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">U-Net架构</p></figure><p id="9637" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">左侧是编码器，数据被压缩成一个更小但更深的矩阵。然后，右侧使用编码器的输出以及编码器各自的输入进行解码(跳过连接)。你可以在这里了解更多关于<a class="ae kv" href="https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/" rel="noopener ugc nofollow" target="_blank">优信网的信息。</a></p><p id="8f67" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用的损失函数是二元交叉熵，监控的度量是dice系数和准确度。</p><p id="d28b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">#结果</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi na"><img src="../Images/d98277ab6b58ef040d8cf2411bd0f50f.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*rHwlOD3oNRCi9RCKoUvfRA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来自训练40个验证时期的结果</p></figure><p id="a015" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">结果表明，U-Net模型远远优于朴素模型，这是意料之中的。</p><p id="10bd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个模型对于看不见的数据也有很好的推广。下面是一些看不见的图像和它的预测遮罩。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/4c1a445dae6a543049ac480b0aabfe89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*Tz8e1pLglLususglGP9g6Q.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/591be0d6b91c9f6befe3f6270a12eb45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*TqgmpiHWeQoZVfMQcsP1eA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">具有来自U-Net模型的预测掩码的测试集图像</p></figure><p id="de20" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">#讨论</strong></p><p id="4a00" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个项目在两周内完成了，还有改进的余地。</p><p id="3afb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">选择损失函数(二元交叉熵)是为了简单和方便。它不一定是这类任务的最佳损失函数。可以考虑混合使用骰子损失和二元交叉熵或骰子损失。</p><p id="d3ef" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当我们可视化来自训练集的具有最高误差的图像时，我们意识到发现的常见问题是缺少边界线、缺少靠近阴影的部分以及缺少天线等精细细节。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nd"><img src="../Images/89fcbb15c4ae85c77632b81ef7d0c326.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*smseLDEFb-QOrgMXOQtD6w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">汽车的黑色部分与地板上的阴影混为一谈；顶部的天线丢失</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nd"><img src="../Images/c690910ebe81af96d426ac0be6b8d6f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3dmHfN7a3l2uVSpY-z_TDA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">车的边缘线没抓拍到</p></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="658f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我希望你喜欢阅读它！呆在家里，注意安全。</p></div></div>    
</body>
</html>