<html>
<head>
<title>When to Use the Kolmogorov-Smirnov Test</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">何时使用柯尔莫哥洛夫-斯米尔诺夫检验</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/when-to-use-the-kolmogorov-smirnov-test-dd0b2c8a8f61?source=collection_archive---------4-----------------------#2020-02-14">https://towardsdatascience.com/when-to-use-the-kolmogorov-smirnov-test-dd0b2c8a8f61?source=collection_archive---------4-----------------------#2020-02-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="21aa" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">理论、应用和解释</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/57d8ec615e458ccab48a27dd694a9d4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6-tGMKCT1ZA17OAT"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae ky" href="https://unsplash.com/@nerfee?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Nerfee Mirandilla </a>拍摄</p></figure><h1 id="5881" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">动机</h1><p id="b776" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">假设检验在许多应用中被使用，而且这种方法看起来很简单。然而，很多时候，我们往往会忽略潜在的假设，并需要问:我们是在拿苹果和桔子做比较吗？当数据科学家决定放弃基于缺失特征的观察时，问题也出现了。</p><p id="4901" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">假设我们有特征<code class="fe ms mt mu mv b">f1, f2,… fn</code>和一个二元目标变量<code class="fe ms mt mu mv b">y</code>。假设许多观察结果缺少一个或多个特征的信息，我们决定删除这些观察结果(行)。通过这样做，我们可能已经改变了一个特征<code class="fe ms mt mu mv b">fk</code>的分布。将这个问题公式化为一个问题:删除观测值会改变特征的分布吗？这个变化<strong class="lt iu">意义重大</strong>吗？</p><p id="e47b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在这篇文章中，我们将提出一些t检验的假设，以及Kolmogorov-Smirnov检验如何验证或否定这些假设。也就是说，尽早声明t检验和KS检验测试的是不同的东西是至关重要的。</p><p id="062f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">对于每一步，我们将介绍理论并用Python 3实现代码。如需完整示例，请随意阅读jupyter笔记本:<a class="ae ky" href="https://github.com/NadimKawwa/Statistics/blob/master/KS_Test.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/NadimKawwa/Statistics/blob/master/KS _ test . ipynb</a></p><h1 id="ebd7" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">t检验的局限性</h1><p id="989d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">有些情况下，我们应该怀疑t检验的结果。t-检验假设情况产生正常的数据，不同之处仅在于一种情况下的平均结果不同于另一种情况下的平均结果。</p><p id="a812" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">也就是说，如果我们对来自非正态分布的数据进行t检验，我们可能会增加出错的风险。根据<a class="ae ky" href="https://en.wikipedia.org/wiki/Central_limit_theorem" rel="noopener ugc nofollow" target="_blank">中心极限定理</a> (CLM)，随着对照组/治疗组变得足够大，t检验变得更加稳健。</p><p id="d5b5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">然而，在我们有足够大的样本的情况下，t检验仍然可能失败。</p><h2 id="fab4" class="mw la it bd lb mx my dn lf mz na dp lj ma nb nc ll me nd ne ln mi nf ng lp nh bi translated">具有相同平均值的小型数据集</h2><p id="39a3" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">考虑下面代码块中随机生成的两个样本:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="7094" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">两个样本都是从具有相同均值的正态分布中生成的，但是通过目测，很明显两个样本是不同的。t检验可能无法发现这种差异，并自信地说两个样本是相同的。</p><p id="68ba" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">使用<a class="ae ky" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html" rel="noopener ugc nofollow" target="_blank"> scipy.ttest.ttest_ind </a>对这些样本进行t检验，得出大于0.05的p值。因此，我们不能拒绝相同平均分的零假设。</p><h2 id="9768" class="mw la it bd lb mx my dn lf mz na dp lj ma nb nc ll me nd ne ln mi nf ng lp nh bi translated">不同均值相同分布</h2><p id="7c6f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">假设我们生成两个均值不同的小数据集，但非正态分布掩盖了差异，如下面的代码所示:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="eab6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果我们事先知道数据不是正态分布的，我们就不会一开始就使用t检验。考虑到这一点，我们引入一种方法来检查我们的观察值是否来自参考概率分布。</p><h1 id="767d" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">KS测试</h1><p id="21fa" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">KS检验是非参数和无分布的检验:它对数据的分布不做任何假设。KS检验可以用来比较一个样本和一个参考概率分布，或者比较两个样本。</p><p id="4d8b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">假设我们有我们认为来自分布p的观察值<code class="fe ms mt mu mv b">x1, x2, …xn</code>，KS检验用于评估:</p><ul class=""><li id="fa08" class="nk nl it lt b lu mn lx mo ma nm me nn mi no mm np nq nr ns bi translated">零假设:样本确实来自P</li><li id="bef2" class="nk nl it lt b lu nt lx nu ma nv me nw mi nx mm np nq nr ns bi translated">替代假设:样本不是来自P</li></ul><p id="800a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了建立KS检验的直觉，我们后退一步，考虑描述性统计。众所周知，正态分布的平均值为0，标准差为1。因此，我们预计不超过15%的数据低于平均值1个标准差以上。</p><p id="0c3a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们将使用<a class="ae ky" href="https://en.wikipedia.org/wiki/Cumulative_distribution_function" rel="noopener ugc nofollow" target="_blank">累积分布函数</a> (CDF)。更具体地说，我们将使用<a class="ae ky" href="https://en.wikipedia.org/wiki/Cumulative_distribution_function#Empirical_distribution_function" rel="noopener ugc nofollow" target="_blank">经验分布函数</a> (EDF):生成样本中点的累积分布函数的估计值。</p><p id="a937" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">CDF的用处在于它唯一地表征了概率分布。我们希望将观察数据的经验分布函数<strong class="lt iu"> F_obs </strong>与零假设相关的累积分布函数<strong class="lt iu"> F_exp </strong>进行比较。</p><h1 id="096d" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">测试样本是否属于分配</h1><p id="f1f5" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在第一个例子中，假设我们的样本来自正态分布<code class="fe ms mt mu mv b">N(0,1)</code>。我们希望将观察数据的经验分布函数与零假设相关的累积分布函数进行比较。</p><p id="f8ac" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">下面是设置这个实验的方法:</p><ul class=""><li id="8c97" class="nk nl it lt b lu mn lx mo ma nm me nn mi no mm np nq nr ns bi translated">按升序对观察值进行排序</li><li id="3ceb" class="nk nl it lt b lu nt lx nu ma nv me nw mi nx mm np nq nr ns bi translated">计算观测值的CDF</li><li id="55d8" class="nk nl it lt b lu nt lx nu ma nv me nw mi nx mm np nq nr ns bi translated">对于每个观测值，xi计算F_exp(xi) = P(Z ≤ xi)</li><li id="1653" class="nk nl it lt b lu nt lx nu ma nv me nw mi nx mm np nq nr ns bi translated">计算绝对差值</li><li id="4522" class="nk nl it lt b lu nt lx nu ma nv me nw mi nx mm np nq nr ns bi translated">记录最大差异</li><li id="11c7" class="nk nl it lt b lu nt lx nu ma nv me nw mi nx mm np nq nr ns bi translated">计算临界值</li><li id="8c65" class="nk nl it lt b lu nt lx nu ma nv me nw mi nx mm np nq nr ns bi translated">拒绝或接受零假设</li></ul><p id="8fb6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">实现相当简单:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="2c92" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">下面的图直观地展示了我们正在做的事情。观察值<code class="fe ms mt mu mv b">F_obs</code>由蓝色曲线表示，而理论值<code class="fe ms mt mu mv b">F_exp</code>由橙色曲线表示。垂直的绿线是观测值和理论值之间的差异</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/264830524ccdfbdcb1f6d8a4b1a3fc23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/1*73C9Sx1lB6NZ-E6XQPnVaQ.png"/></div></div></figure><p id="49ee" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果我们的最大差异小于<code class="fe ms mt mu mv b">D_Crit</code>,我们无法拒绝零假设。95%时的临界值近似为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/b708553eea0b5f1aac5419d1752e2768.png" data-original-src="https://miro.medium.com/v2/resize:fit:510/format:webp/1*NBTOXCr9vea96nj2yAdiZw.png"/></div></figure><p id="f7da" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">其中n是样本数。</p><h1 id="db6a" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">两个样品的KS</h1><p id="2307" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">给定两个样本<code class="fe ms mt mu mv b">x</code>和<code class="fe ms mt mu mv b">y</code>，我们希望测试它们是否来自同一个分布p。首先改变的是接近95%临界值的公式:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/4b27910bc5b5b7cd3efe74675741ba2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/1*iabjhufEXbPxr9xuo7BUoQ.png"/></div></figure><p id="9d59" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">其中<code class="fe ms mt mu mv b">n_x</code>和<code class="fe ms mt mu mv b">n_y </code>是每个样本中的观察次数。</p><p id="71a2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们将从两个分布中随机生成两个随机样本:</p><ul class=""><li id="3e8d" class="nk nl it lt b lu mn lx mo ma nm me nn mi no mm np nq nr ns bi translated">常态</li><li id="e833" class="nk nl it lt b lu nt lx nu ma nv me nw mi nx mm np nq nr ns bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Log-normal_distribution" rel="noopener ugc nofollow" target="_blank">对数正态</a></li></ul><p id="4662" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了比较这两者，我们实施了以下步骤:</p><ul class=""><li id="fb66" class="nk nl it lt b lu mn lx mo ma nm me nn mi no mm np nq nr ns bi translated">订购每个样品</li><li id="904b" class="nk nl it lt b lu nt lx nu ma nv me nw mi nx mm np nq nr ns bi translated">串联成一个排序数组</li><li id="c371" class="nk nl it lt b lu nt lx nu ma nv me nw mi nx mm np nq nr ns bi translated">计算两个样本的观测累积分布函数</li><li id="8636" class="nk nl it lt b lu nt lx nu ma nv me nw mi nx mm np nq nr ns bi translated">计算它们的最大绝对差值<code class="fe ms mt mu mv b">D_n</code></li><li id="3ba6" class="nk nl it lt b lu nt lx nu ma nv me nw mi nx mm np nq nr ns bi translated">对比<code class="fe ms mt mu mv b">D_crit</code></li></ul><p id="b9d5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在实现代码之前，我们在下面的图中展示了我们的视觉目标。查看CDF，我们可以直观地说，样本a和b不来自相同的分布。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/dda2a8dc5c350b5e3f1f5a74507234c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*90cqn9dTW-oJZpRO-TbxLQ.png"/></div></figure><p id="7ea1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在下面的代码块中，我们将实现前两步。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="1d7e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">接下来，我们利用scipy的<a class="ae ky" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.percentileofscore.html" rel="noopener ugc nofollow" target="_blank"> percentileofscore </a>来计算CDF，如下所示:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="91d6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在我们的例子<code class="fe ms mt mu mv b"> D_crit=0.408</code>中，不出所料，我们得到了<code class="fe ms mt mu mv b">D_n=0.6</code>，我们拒绝了两者来自同一分布的无效假设。</p><h1 id="2a06" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">结论</h1><p id="4293" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们使用了KS检验来比较一个样本和一个参考概率分布，或者比较两个样本。在许多日常应用中，测试用于验证假设并帮助指导决策。</p><p id="514d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了更快地实现，scipy包提供了一个针对<a class="ae ky" href="https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.kstest.html" rel="noopener ugc nofollow" target="_blank">拟合优度</a>或<a class="ae ky" href="https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.ks_2samp.html" rel="noopener ugc nofollow" target="_blank">两个样本</a>的KS测试。</p><h1 id="e1c2" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">参考</h1><p id="f03b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><strong class="lt iu">维基百科</strong>:<a class="ae ky" href="https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/wiki/Kolmogorov % E2 % 80% 93s mirnov _ test</a><a class="ae ky" href="https://en.wikipedia.org/wiki/Cumulative_distribution_function" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/wiki/Cumulative _ distribution _ function</a></p><p id="018f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">圣本笃学院和圣约翰大学</strong>:<a class="ae ky" href="http://www.physics.csbsju.edu/stats/KS-test.html" rel="noopener ugc nofollow" target="_blank">http://www.physics.csbsju.edu/stats/KS-test.html</a></p><p id="454a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">牛津大学统计系</strong>:<a class="ae ky" href="http://www.stats.ox.ac.uk/~massa/Lecture%2013.pdf" rel="noopener ugc nofollow" target="_blank">http://www.stats.ox.ac.uk/~massa/Lecture%2013.pdf</a></p></div></div>    
</body>
</html>