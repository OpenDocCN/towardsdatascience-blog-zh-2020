<html>
<head>
<title>Collaborative Filtering in Pytorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pytorch 中的协同过滤</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/collaborative-filtering-in-pytorch-6e50515f01ae?source=collection_archive---------30-----------------------#2020-07-12">https://towardsdatascience.com/collaborative-filtering-in-pytorch-6e50515f01ae?source=collection_archive---------30-----------------------#2020-07-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3a7c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">构建用于电影推荐的嵌入神经网络</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/3bcd6fd95d435a3caa2b7ff446641acd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l-RhVlSKlGQiXa4Q7lOnDg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由<a class="ae ky" href="https://unsplash.com/@hngstrm" rel="noopener ugc nofollow" target="_blank">亨利&amp;公司</a>在<a class="ae ky" href="http://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="be4c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">协同过滤是公司越来越多地使用的工具。网飞用它来推荐节目给你看。脸书用它来推荐你应该和谁交朋友。<a class="ae ky" href="https://medium.com/s/story/spotifys-discover-weekly-how-machine-learning-finds-your-new-music-19a41ab76efe" rel="noopener"> Spotify </a>用它来推荐播放列表和歌曲。它在向顾客推荐产品时非常有用。</p><p id="384b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我构建了一个嵌入的协同过滤神经网络来理解用户对某些电影的感受。由此可以推荐电影给他们看。</p><p id="9ff7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据集取自此处的<a class="ae ky" href="http://files.grouplens.org/datasets/movielens/" rel="noopener ugc nofollow" target="_blank"/>。这段代码大致基于<a class="ae ky" href="https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson4-collab.ipynb" rel="noopener ugc nofollow" target="_blank"> fastai 笔记本</a>。</p><p id="4804" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，让我们去掉烦人的复杂用户 id。我们可以用普通的旧整数来凑合。它们更容易处理。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="7910" class="ma mb it lw b gy mc md l me mf">import pandas as pd<br/>ratings = pd.read_csv('ratings.csv')<br/>movies = pd.read_csv('movies.csv')</span></pre><p id="c949" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后我们将对电影 id 做同样的事情。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="2352" class="ma mb it lw b gy mc md l me mf">u_uniq = ratings.userId.unique()<br/>user2idx = {o:i for i,o in enumerate(u_uniq)}<br/>ratings.userId = ratings.userId.apply(lambda x: user2idx[x])</span></pre><p id="a410" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们需要获得用户数量和电影数量。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="b1a7" class="ma mb it lw b gy mc md l me mf">n_users=int(ratings.userId.nunique())<br/>n_movies=int(ratings.movieId.nunique())</span></pre><p id="6114" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，让我们创建一些随机权重。我们需要打电话。这允许我们避免显式调用基类。这使得代码更易于维护。</p><p id="2d94" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些权重将在 0 和 0.05 之间均匀分布。<code class="fe mg mh mi lw b">uniform_</code>末尾的<code class="fe mg mh mi lw b">_</code>操作符表示在位操作。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mj mk l"/></div></figure><p id="d425" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们添加我们的嵌入矩阵和潜在因素。</p><p id="9353" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们正在为我们的用户 id 和电影 id 创建一个嵌入矩阵。嵌入基本上是一种数组查找。当我们将我们的一次性编码用户 id 乘以我们的权重时，大多数计算都取消了<code class="fe mg mh mi lw b">0</code> <code class="fe mg mh mi lw b">(0 * number = 0)</code>。我们只剩下权重矩阵中的某一行。这基本上就是<a class="ae ky" href="https://youtu.be/CJKnDu2dxOE?t=1625" rel="noopener ugc nofollow" target="_blank">一个数组查找</a>。</p><p id="fde8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以我们不需要矩阵乘法，也不需要独热编码数组。相反，我们可以只做一个数组查找。这<a class="ae ky" href="https://arxiv.org/pdf/1604.06737" rel="noopener ugc nofollow" target="_blank">减少了内存使用</a>并加速了神经网络。它还揭示了分类变量的内在属性。这个想法在最近的一次<a class="ae ky" href="https://www.kaggle.com/c/rossmann-store-sales" rel="noopener ugc nofollow" target="_blank"> Kaggle 比赛</a>中得到了应用<a class="ae ky" href="https://www.kaggle.com/c/rossmann-store-sales/discussion/17974" rel="noopener ugc nofollow" target="_blank">获得了第三名</a>。</p><p id="62c0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些嵌入矩阵的大小将由 n 个因子决定。这些因素决定了数据集中潜在因素的数量。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mj mk l"/></div></figure><p id="120a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">潜在因素在我们的网络中非常有用。它们减少了对特征工程的需求。比如<code class="fe mg mh mi lw b">User_id</code> <code class="fe mg mh mi lw b">554</code>喜欢<code class="fe mg mh mi lw b">Tom cruise</code><code class="fe mg mh mi lw b">Tom cruise</code>出现在一部电影里。用户<code class="fe mg mh mi lw b">554</code>可能会喜欢这部电影。出现在电影中会是一个潜在的特征。我们在培训前没有具体说明。它就这么出现了。我们很高兴它做到了。</p><p id="ee78" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们需要添加我们的<code class="fe mg mh mi lw b">forward</code>函数。</p><p id="b217" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如这个类的名字所暗示的，我们正在做嵌入矩阵的点积。</p><p id="6d08" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">给我们一个用户和电影的小批量。我们只看嵌入的分类变量。<code class="fe mg mh mi lw b">conts</code>指连续变量。</p><p id="0cb5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个小批量大小将由您设置的批量大小决定。根据这篇文章，大批量实际上会损害模型的质量。但是根据这篇论文，大批量增加了模型的质量。目前还没有达成共识。许多人都在报道<a class="ae ky" href="https://stats.stackexchange.com/questions/436878/choosing-optimal-batch-size-contradicting-results" rel="noopener ugc nofollow" target="_blank">矛盾的结果</a>。所以你可以随意选择批量大小进行实验。</p><p id="0733" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从这个迷你批处理中，我们想要在我们的嵌入矩阵中进行数组查找。</p><p id="d0fa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">允许我们进行数组查找。这种查找比一位热码编码矩阵和加权矩阵矩阵乘法计算量小。</p><p id="18c5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe mg mh mi lw b">(u*m).sum(1).view(-1, 1)</code>是用户和电影嵌入的叉积，返回一个数字。这是那部电影的预测分级。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mj mk l"/></div></figure><p id="3ada" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们需要创建一个<code class="fe mg mh mi lw b">ColumnarModelData</code>对象</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mj mk l"/></div></figure><p id="665b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">那我就设置一个乐观器。对此我将使用随机梯度下降法。<code class="fe mg mh mi lw b">optim.SGD</code>实现<a class="ae ky" href="https://pytorch.org/docs/stable/optim.html#torch.optim.SGD" rel="noopener ugc nofollow" target="_blank">随机梯度下降</a>。随机梯度下降在计算上不如梯度下降密集。这是因为当<a class="ae ky" rel="noopener" target="_blank" href="/stochastic-gradient-descent-clearly-explained-53d239905d31">选择数据点</a>计算导数时，我们引入了随机性。</p><p id="9f38" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们也可以使用<code class="fe mg mh mi lw b">optim.Adam</code>。实现<a class="ae ky" href="https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf" rel="noopener ugc nofollow" target="_blank"> rmsprop </a>和<a class="ae ky" href="https://www.youtube.com/watch?v=YU_W8PFkY2U" rel="noopener ugc nofollow" target="_blank">动量</a>。反过来，这导致了自适应的学习速率。但是<a class="ae ky" href="https://arxiv.org/abs/1705.08292" rel="noopener ugc nofollow" target="_blank">这篇</a>论文表明从 SGD 得到的解比从 Adam 得到的解更一般化。另外，反正训练也不需要那么长时间，所以 SGD 也不是个坏选择。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mj mk l"/></div></figure><p id="dd8b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后我们适合一个<code class="fe mg mh mi lw b">3</code>时代。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="ac34" class="ma mb it lw b gy mc md l me mf">fit(model, data, 3, opt, F.mse_loss)</span></pre><p id="fccb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">MSE 损失就是简单的均方误差损失。这是自动计算的。</p><p id="9ecf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Fastai 在幕后自动创建一个神经网络。您可以调用一个<code class="fe mg mh mi lw b"><a class="ae ky" href="https://docs.fast.ai/collab.html#collab_learner" rel="noopener ugc nofollow" target="_blank">collab_learner</a></code>，它会自动创建一个用于协同过滤的神经网络。Fastai 还可以通过这个协作学习器引入<a class="ae ky" href="https://dev.fast.ai/tutorial.collab#Movie-bias" rel="noopener ugc nofollow" target="_blank">偏差</a>和<a class="ae ky" href="https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf" rel="noopener ugc nofollow" target="_blank">辍学</a>。</p><p id="6d22" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">偏见是很有用的。我们需要找到用户偏见和电影偏见。用户偏见可以解释那些对每部电影都给予高评价的人。电影偏见可以解释那些倾向于给某类电影高评级的人。Fastai 自动添加偏差。</p><p id="d1c9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用 fastai，我们可以轻松创建协作学习者:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mj mk l"/></div></figure><p id="3508" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">偏见是很有用的。我们需要找到用户偏见和电影偏见。用户偏见可以解释那些对每部电影都给予高评价的人。电影偏见可以解释那些倾向于给某类电影高评级的人。Fastai 自动添加偏差。</p><p id="a567" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有趣的是，fastai 指出你应该稍微增加<code class="fe mg mh mi lw b">y_range</code><a class="ae ky" href="https://youtu.be/CJKnDu2dxOE?t=2609" rel="noopener ugc nofollow" target="_blank"/>。<a class="ae ky" href="https://en.wikipedia.org/wiki/Sigmoid_function" rel="noopener ugc nofollow" target="_blank"> sigmoid 函数</a>用于确保最终输出在<code class="fe mg mh mi lw b">y_range</code>中指定的数字之间。问题是一个 sigmoid 函数似乎。所以我们需要稍微增加我们的<code class="fe mg mh mi lw b">y_range</code>。Fastai 建议增加<code class="fe mg mh mi lw b">0.5</code>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ml"><img src="../Images/7656998f11bde4e8e8832696cd769193.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YuabQiGBA-W-5PWsojwN5A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://www.researchgate.net/profile/Knut_Kvaal/publication/239269767/figure/fig2/AS:643520205430784@1530438581076/An-illustration-of-the-signal-processing-in-a-sigmoid-function.png" rel="noopener ugc nofollow" target="_blank"> ResearchGate </a></p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mm"><img src="../Images/1c10617d4722c0f7c8e0e12d0245f14a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NvB0u1rxR4oyxrM8.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="e53e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我这里用的是建议的学习率，有少量的重量衰减。这是我发现非常有效的组合。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mn"><img src="../Images/cd1da4672312d16703c4fe2f35333182.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*J_kafj53815GSnBE.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="93a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以多训练一些</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mo"><img src="../Images/f18ff0fb4e149cffeb5b9718693d78bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*25SI4Ucqvvu3EvKi.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mp"><img src="../Images/31b12552272ebf165e1d115b4c205ba5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tBKYeD3w312tL-gq.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="93d6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们终于得到了一个<code class="fe mg mh mi lw b">0.784105</code>的 MSE。但这是一段非常颠簸的旅程。我们的损失上下波动很大。也就是说<code class="fe mg mh mi lw b">0.784105</code>实际上比<a class="ae ky" href="https://www.librec.net/release/v1.3/example.html" rel="noopener ugc nofollow" target="_blank"> LibRec 系统</a>的协同过滤得分更高。他们得到了 MSE。</p><p id="ee2a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它实际上也比 fastai 在他们的<a class="ae ky" href="https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson4-collab.ipynb" rel="noopener ugc nofollow" target="_blank">协作过滤课程</a>中创建的模型略好。他们越来越小。</p><h1 id="2add" class="mq mb it bd mr ms mt mu mv mw mx my mz jz na ka nb kc nc kd nd kf ne kg nf ng bi translated">丰富</h1><ol class=""><li id="46bd" class="nh ni it lb b lc nj lf nk li nl lm nm lq nn lu no np nq nr bi translated">我们可以通过发送一个名为<code class="fe mg mh mi lw b">emb_szs</code>的字典来调整嵌入的大小。这可能是一个需要调整的有用参数。</li><li id="5942" class="nh ni it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated">基于内容的推荐。协同过滤只是建立推荐系统的一种方法。其他方法可能更有用。基于内容的系统是我一直铭记在心的。它可以查看演员、工作人员、流派和导演等元数据来做出推荐。我认为某种<a class="ae ky" href="https://www.kaggle.com/rounakbanik/movie-recommender-systems#Movies-Recommender-System" rel="noopener ugc nofollow" target="_blank">混合</a>解决方案将是最佳的。这将结合基于内容的推荐系统和协作过滤系统。</li><li id="ef4b" class="nh ni it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated">协同过滤在很大程度上被<a class="ae ky" href="https://www.kdnuggets.com/2019/01/data-scientist-dilemma-cold-start-machine-learning.html" rel="noopener ugc nofollow" target="_blank">冷启动问题</a>所破坏。为了克服这个问题，我们可能会查看用户元数据。例如，我们可以查看诸如:性别、年龄、城市、他们访问网站的时间等。只是他们在报名表上输入的所有内容。在这些数据的基础上建立一个模型可能会很棘手，但是如果效果好的话，它可能会很有用。</li></ol></div><div class="ab cl nx ny hx nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="im in io ip iq"><p id="626e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="oe">原载于 2020 年 7 月 12 日</em><a class="ae ky" href="https://spiyer99.github.io/Recommendation-System-in-Pytorch/" rel="noopener ugc nofollow" target="_blank"><em class="oe">https://spiyer 99 . github . io</em></a><em class="oe">。</em></p></div></div>    
</body>
</html>