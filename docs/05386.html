<html>
<head>
<title>Generative Adversarial Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成对抗网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generative-adversarial-networks-bf4e809180b3?source=collection_archive---------41-----------------------#2020-05-06">https://towardsdatascience.com/generative-adversarial-networks-bf4e809180b3?source=collection_archive---------41-----------------------#2020-05-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/a10f3b4679ccc3871b71e7478743b928.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*MRS6rRq2F36-gSk-.jpg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://pixabay.com/users/comfreak-51581/" rel="noopener ugc nofollow" target="_blank">combreak</a>T3】pix abay</p></figure><div class=""/><p id="2ba5" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">生成对抗网络或简称GANs是一种神经网络，可用于生成数据，而不是试图对其进行分类。虽然有点令人不安，以下网站提供了一个令人印象深刻的例子。</p><div class="is it gp gr iu le"><a href="https://thispersondoesnotexist.com/" rel="noopener  ugc nofollow" target="_blank"><div class="lf ab fo"><div class="lg ab lh cl cj li"><h2 class="bd jk gy z fp lj fr fs lk fu fw ji bi translated">此人不存在</h2><div class="ll l"><h3 class="bd b gy z fp lj fr fs lk fu fw dk translated">此人不存在</h3></div><div class="lm l"><p class="bd b dl z fp lj fr fs lk fu fw dk translated">这个人不是Existthispersondoesnotexist.com</p></div></div><div class="ln l"><div class="lo l lp lq lr ln ls ja le"/></div></div></a></div><p id="6990" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">生成性对抗网络由两部分组成。一个学习生成似是而非的数据的<strong class="ki jk">生成器</strong>和一个学习区分生成器的假数据和真实数据的<strong class="ki jk">鉴别器</strong>。只要检测到虚假数据，鉴别器就会处罚生成器。</p><figure class="lu lv lw lx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lt"><img src="../Images/8990a0199672cbff3f934ffee7a9ce6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yfJWSydg3ofBDpN7guhBHA.png"/></div></div></figure><p id="d807" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">鉴别器和发生器的训练阶段是分开的。换句话说，生成器的权重保持固定，同时它为鉴别器提供训练样本，反之亦然。通常，我们交替训练鉴别器和生成器一个或多个时期。</p><p id="da8c" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">鉴别器训练过程与任何其他神经网络的训练过程相当。鉴别器对来自发生器的真实样本和虚假数据进行分类。鉴别器损失函数惩罚将真实实例误分类为假实例或将假实例误分类为真实实例的鉴别器，并通过反向传播更新鉴别器的权重。</p><p id="3d7f" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">类似地，发生器产生样本，然后由鉴别器分类为假的或真的。然后将结果输入损失函数，该函数因生成器未能欺骗鉴别器而对其进行惩罚，并使用反向传播来修改生成器的权重。</p><p id="7df5" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">随着生成器随着训练而改进，鉴别器的性能变得更差，因为鉴别器无法区分真假。如果生成器完全成功，那么鉴别器有50%的准确性(不比随机机会好)。后者对GAN整体的收敛提出了真正的问题。如果GAN继续训练超过鉴别器给出完全随机反馈的点，那么发生器开始训练垃圾反馈，其自身的性能可能会受到影响。</p><h1 id="7d1a" class="ly lz jj bd ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv bi translated">Python代码</h1><p id="6017" class="pw-post-body-paragraph kg kh jj ki b kj mw kl km kn mx kp kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">让我们来看看如何用Python来实现一个生成式对抗网络。首先，我们导入以下库。</p><pre class="lu lv lw lx gt nb nc nd ne aw nf bi"><span id="8352" class="ng lz jj nc b gy nh ni l nj nk">from keras.datasets import mnist<br/>from keras.layers import Input, Dense, Reshape, Flatten, Dropout<br/>from keras.layers import BatchNormalization, Activation<br/>from keras.layers.advanced_activations import LeakyReLU<br/>from keras.models import Sequential, Model<br/>from keras.optimizers import Adam<br/>import matplotlib.pyplot as plt<br/>import sys<br/>import numpy as np</span></pre><p id="787c" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将使用MNIST数据集，其中包含28×28的手写数字图像。我们用以下参数创建了一个名为<code class="fe nl nm nn nc b">GAN</code>的类。</p><pre class="lu lv lw lx gt nb nc nd ne aw nf bi"><span id="5729" class="ng lz jj nc b gy nh ni l nj nk">class GAN():<br/>    def __init__(self):<br/>        self.image_rows = 28<br/>        self.image_cols = 28<br/>        self.channels = 1<br/>        self.image_shape = (self.image_rows, self.image_cols, self.channels)<br/>        self.input_dim = 100<br/>        optimizer = Adam(0.0002, 0.5)<br/>        self.discriminator = self.build_discriminator()<br/>        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])<br/>        self.generator = self.build_generator()</span><span id="79c5" class="ng lz jj nc b gy no ni l nj nk">_in = Input(shape=(self.input_dim,))<br/>        image = self.generator(_in)</span><span id="378a" class="ng lz jj nc b gy no ni l nj nk">self.discriminator.trainable = False</span><span id="8666" class="ng lz jj nc b gy no ni l nj nk">validity = self.discriminator(image)</span><span id="5fdf" class="ng lz jj nc b gy no ni l nj nk">self.combined = Model(_in, validity)<br/>        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)</span></pre><p id="9a7d" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们定义了发电机网络。</p><pre class="lu lv lw lx gt nb nc nd ne aw nf bi"><span id="4e4c" class="ng lz jj nc b gy nh ni l nj nk">def build_generator(self):<br/>        model = Sequential()<br/>        model.add(Dense(256, input_dim=self.input_dim))<br/>        model.add(LeakyReLU(alpha=0.2))<br/>        model.add(BatchNormalization(momentum=0.8))<br/>        model.add(Dense(512))<br/>        model.add(LeakyReLU(alpha=0.2))<br/>        model.add(BatchNormalization(momentum=0.8))<br/>        model.add(Dense(1024))<br/>        model.add(LeakyReLU(alpha=0.2))<br/>        model.add(BatchNormalization(momentum=0.8))<br/>        model.add(Dense(np.prod(self.image_shape), activation='tanh'))<br/>        model.add(Reshape(self.image_shape))<br/>        model.summary()<br/>        noise = Input(shape=(self.input_dim,))<br/>        image = model(noise)<br/>        return Model(noise, image)</span></pre><p id="d011" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们定义鉴别器网络。</p><pre class="lu lv lw lx gt nb nc nd ne aw nf bi"><span id="5362" class="ng lz jj nc b gy nh ni l nj nk">def build_discriminator(self):<br/>        model = Sequential()<br/>        model.add(Flatten(input_shape=self.image_shape))<br/>        model.add(Dense(512))<br/>        model.add(LeakyReLU(alpha=0.2))<br/>        model.add(Dense(256))<br/>        model.add(LeakyReLU(alpha=0.2))<br/>        model.add(Dense(1, activation='sigmoid'))<br/>        model.summary()<br/>        image = Input(shape=self.image_shape)<br/>        validity = model(image)<br/>        return Model(image, validity)</span></pre><p id="4347" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来，我们定义一个函数来训练模型。我们首先对每个图像的像素进行归一化，使它们的范围从负到正。我们使用Numpy来创建随机噪声，它反过来被生成器用来产生假数据。除了已知为真实的样本之外，还对生成的数据训练鉴别器。最后，通过将输出与实际样本进行比较来计算发电机损耗。</p><pre class="lu lv lw lx gt nb nc nd ne aw nf bi"><span id="a36d" class="ng lz jj nc b gy nh ni l nj nk">def train(self, epochs, batch_size=128, sample_interval=50):<br/>        (X_train, _), (_, _) = mnist.load_data()<br/>        X_train = X_train / 127.5 - 1.<br/>        X_train = np.expand_dims(X_train, axis=3)<br/>        valid = np.ones((batch_size, 1))<br/>        fake = np.zeros((batch_size, 1))</span><span id="35d8" class="ng lz jj nc b gy no ni l nj nk">for epoch in range(epochs):<br/>            index = np.random.randint(0, X_train.shape[0], batch_size)<br/>            images = X_train[index]<br/>            noise = np.random.normal(0, 1, (batch_size, self.input_dim))<br/>            gen_images = self.generator.predict(noise)<br/>            d_loss_real = self.discriminator.train_on_batch(images, valid)<br/>            d_loss_fake = self.discriminator.train_on_batch(gen_images, fake)<br/>            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)</span><span id="a4c5" class="ng lz jj nc b gy no ni l nj nk">noise = np.random.normal(0, 1, (batch_size, self.input_dim))<br/>            g_loss = self.combined.train_on_batch(noise, valid)</span><span id="6853" class="ng lz jj nc b gy no ni l nj nk">print ("%d [Discriminator loss: %f, acc.: %.2f%%] [Generator loss: %f]" % (epoch, d_loss[0], 100*d_loss[1], g_loss))<br/>            if epoch % sample_interval == 0:<br/>               self.sample_images(epoch)</span></pre><p id="6164" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们定期保存输出，以便在整个训练过程中评估模型的性能。</p><pre class="lu lv lw lx gt nb nc nd ne aw nf bi"><span id="51d5" class="ng lz jj nc b gy nh ni l nj nk">def sample_images(self, epoch):<br/>        r, c = 5, 5<br/>        noise = np.random.normal(0, 1, (r * c, self.input_dim))<br/>        gen_images = self.generator.predict(noise)<br/>        gen_images = 0.5 * gen_images + 0.5<br/>        fig, axs = plt.subplots(r, c)<br/>        count = 0<br/>        for i in range(r):<br/>            for j in range(c):<br/>                axs[i,j].imshow(gen_images[count, :,:,0], cmap='gray')<br/>                axs[i,j].axis('off')<br/>                count += 1<br/>        fig.savefig("images/%d.png" % epoch)<br/>        plt.close()</span></pre><p id="08a1" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，我们创建GAN类的一个实例并训练该模型。</p><pre class="lu lv lw lx gt nb nc nd ne aw nf bi"><span id="8b35" class="ng lz jj nc b gy nh ni l nj nk">gan = GAN()<br/>gan.train(epochs=100000, batch_size=128, sample_interval=10000)</span></pre><p id="d05e" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最初，GAN的输出只是随机噪声。</p><figure class="lu lv lw lx gt iv gh gi paragraph-image"><div class="gh gi np"><img src="../Images/0c30b9a43ef93bfc20621ef2354a4e6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/0*fYd1vxeH5o91pYwz.png"/></div></figure><p id="0078" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，到最后，输出开始看起来像手写数字。</p><figure class="lu lv lw lx gt iv gh gi paragraph-image"><div class="gh gi np"><img src="../Images/40fc68b7e6f670849c248d71dbc93917.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/0*nZn7f-dE9x_2X05g.png"/></div></figure></div></div>    
</body>
</html>