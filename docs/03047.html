<html>
<head>
<title>Deploy, Monitor and Scale Machine Learning models on AWS</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 AWS 上部署、监控和扩展机器学习模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deploy-monitor-and-scale-machine-learning-models-on-aws-408dfd397422?source=collection_archive---------27-----------------------#2020-03-23">https://towardsdatascience.com/deploy-monitor-and-scale-machine-learning-models-on-aws-408dfd397422?source=collection_archive---------27-----------------------#2020-03-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ca2a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Cortex 如何帮助数据科学家将他们的机器学习模型投入生产。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f9b60fba7c82a51742d4695fa2d8a4ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lOqD_NHM7gQY9Ax9TF4wZg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">泰勒·维克在<a class="ae ky" href="https://unsplash.com/s/photos/data-center?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="341c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">部署健壮的和可扩展的机器学习解决方案仍然是一个相当手工和复杂的过程，需要大量的人工参与和努力。因此，新产品和服务需要很长时间才能上市，或者在原型状态下被放弃，从而降低了行业内的兴趣。<strong class="lb iu">那么，我们如何才能促进将机器学习模型投入生产的过程呢？</strong></p><p id="e4a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Cortex 是一个开源平台，用于将机器学习模型部署为生产 web 服务。它利用强大的 AWS 生态系统根据需要部署、监控和扩展与框架无关的模型。其主要特点可归纳如下:</p><ul class=""><li id="acb8" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu">框架无关:</strong> Cortex 支持任何一段 python 代码；TensorFlow、PyTorch、scikit-learn、XGBoost 都是由库支持的，就像任何其他 python 脚本一样。</li><li id="a79d" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">自动伸缩:</strong> Cortex 自动伸缩您的 API，以处理生产工作负载。</li><li id="d1bc" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu"> CPU / GPU 支持:</strong> Cortex 可以运行在使用 AWS IaaS 作为其底层基础设施的 CPU 或 GPU 环境上。</li><li id="ce07" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu"> Spot 实例:</strong> Cortex 支持 EC2 spot 实例以降低成本。</li><li id="ab72" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">滚动更新:</strong> Cortex 在不停机的情况下将任何更新应用于模型。</li><li id="f577" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">日志流式传输:</strong> Cortex 保存来自已部署模型的日志，并使用类似 docker 的熟悉语法将它们流式传输到您的 CLI。</li><li id="df18" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">预测监控:</strong> Cortex 监控网络指标，跟踪预测。</li><li id="6b59" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">最小配置:</strong> Cortex 部署配置被定义为一个简单的 YAML 文件。</li></ul><p id="835f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这个故事中，我们使用 Cortex 在 AWS 上部署一个图像分类模型作为 web 服务。那么，事不宜迟，我们来介绍一下 Cortex。</p><blockquote class="mj mk ml"><p id="2bdb" class="kz la mm lb b lc ld ju le lf lg jx lh mn lj lk ll mo ln lo lp mp lr ls lt lu im bi translated"><a class="ae ky" href="https://mailchi.mp/d2d2d4a109b5/learning-rate-newsletter" rel="noopener ugc nofollow" target="_blank">学习率</a>是为那些对 AI 和 MLOps 的世界感到好奇的人准备的时事通讯。你会在每周五收到我关于最新人工智能新闻和文章的更新和想法。在这里订阅<a class="ae ky" href="https://mailchi.mp/d2d2d4a109b5/learning-rate-newsletter" rel="noopener ugc nofollow" target="_blank"/>！</p></blockquote><h1 id="2357" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">将您的模型部署为 Web 服务</h1><p id="1df0" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">对于这个例子，我们使用了<a class="ae ky" href="https://pypi.org/project/fastai/" rel="noopener ugc nofollow" target="_blank"> fast.ai </a>库，并从相关<a class="ae ky" href="https://course.fast.ai/" rel="noopener ugc nofollow" target="_blank"> MOOC </a>的第一门课程中借用了 pets 分类模型。接下来的部分将介绍 Cortex 的安装和 pets 分类模型作为 web 服务的部署。</p><h2 id="6354" class="nn mr it bd ms no np dn mw nq nr dp na li ns nt nc lm nu nv ne lq nw nx ng ny bi translated">装置</h2><p id="3b03" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">如果您还没有这样做，那么您应该做的第一件事就是在 AWS 上创建一个新的用户帐户，并提供编程访问。为此，选择<code class="fe nz oa ob oc b">IAM</code>服务，然后从右侧面板选择<code class="fe nz oa ob oc b">Users</code>，最后按下<code class="fe nz oa ob oc b">Add User</code>按钮。为您的用户命名，然后选择<code class="fe nz oa ob oc b">Programmatic access</code>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/db1dd754d82d763de16a19f4719c6744.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tloBEWgAXCtQvLPZijkw_g.png"/></div></div></figure><p id="9dda" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，在<code class="fe nz oa ob oc b">Permissions</code>屏幕中选择<code class="fe nz oa ob oc b">Attach existing policies directly</code>选项卡并选择<code class="fe nz oa ob oc b">AdministratorAccess</code>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/4b989b07e1d5dacf8d2914353cd911f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hcTN15vQCWCxagY0qJjZig.png"/></div></div></figure><p id="1a7c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以将标签页留空，查看并创建您的用户。最后，记下<strong class="lb iu">访问密钥 ID </strong>和<strong class="lb iu">秘密访问密钥。</strong></p><p id="db64" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当您在 AWS 控制台上时，您还可以创建一个<code class="fe nz oa ob oc b">S3</code>桶，来存储训练好的模型和您的代码可能产生的任何其他工件。你可以给这个桶取任何你喜欢的名字，只要它是一个唯一的名字。对于这个故事，我们创建了一个名为<code class="fe nz oa ob oc b">cortex-pets-model</code>的桶。</p><p id="4be5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下一步，我们必须在系统上安装 Cortex CLI 并启动 Kubernetes 集群。要安装 Cortex CLI，请运行以下命令:</p><pre class="kj kk kl km gt of oc og oh aw oi bi"><span id="7b31" class="nn mr it oc b gy oj ok l ol om">bash -c “$(curl -sS https://raw.githubusercontent.com/cortexlabs/cortex/0.14/get-cli.sh)"</span></pre><blockquote class="mj mk ml"><p id="e338" class="kz la mm lb b lc ld ju le lf lg jx lh mn lj lk ll mo ln lo lp mp lr ls lt lu im bi translated">通过访问相应的<a class="ae ky" href="https://www.cortex.dev/" rel="noopener ugc nofollow" target="_blank">文档</a>部分，检查您是否安装了最新版本的 Cortex CLI</p></blockquote><p id="12af" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在准备设置我们的集群。使用 Cortex 创建 Kubernetes 集群很简单。只需执行下面的命令:</p><pre class="kj kk kl km gt of oc og oh aw oi bi"><span id="ad5b" class="nn mr it oc b gy oj ok l ol om">cortex cluster up</span></pre><p id="157f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Cortex 将要求您提供一些信息，例如您的 AWS 键、您想要使用的区域、您想要启动的计算实例以及它们的数量。Cortex 还会让您知道使用您选择的服务将支付多少费用。整个过程可能需要 20 分钟。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/200541e0bd6a5941828708ba587a31bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*24q9rE1QZIocM-YWlE3D3Q.png"/></div></div></figure><h2 id="2f48" class="nn mr it bd ms no np dn mw nq nr dp na li ns nt nc lm nu nv ne lq nw nx ng ny bi translated">训练您的模型</h2><p id="f9ec" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">Cortex 不关心你如何创建或训练你的模型。对于这个例子，我们使用 fast.ai 库和<a class="ae ky" href="https://www.robots.ox.ac.uk/~vgg/data/pets/" rel="noopener ugc nofollow" target="_blank">牛津-IIIT Pet 数据集</a>。该数据集包含 37 种不同品种的狗和猫。因此，我们的模型应该将每张图片分为这 37 个类别。</p><p id="382b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">创建一个<code class="fe nz oa ob oc b">trainer.py</code>文件，如下图所示。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oo op l"/></div></figure><p id="d908" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本地运行脚本，就像任何其他 python 脚本一样:<code class="fe nz oa ob oc b">python trainer.py</code>。但是，一定要提供您的 AWS 凭证和<code class="fe nz oa ob oc b">S3</code> bucket 名称。这个脚本获取数据，处理它们，符合预先训练的 ResNet 模型，并上传到<code class="fe nz oa ob oc b">S3</code>。当然，您可以扩展这个脚本，使用多种技术使模型更加准确——更复杂的架构、有区别的学习率、针对更多时期的训练——但这与我们这里的目标无关。如果您想进一步了解 ResNet 架构，请阅读下面的文章。</p><div class="oq or gp gr os ot"><a rel="noopener follow" target="_blank" href="/xresnet-from-scratch-in-pytorch-e64e309af722"><div class="ou ab fo"><div class="ov ab ow cl cj ox"><h2 class="bd iu gy z fp oy fr fs oz fu fw is bi translated">Pytorch 中从头开始的 xResNet</h2><div class="pa l"><h3 class="bd b gy z fp oy fr fs oz fu fw dk translated">从你的 ResNet 架构中挤出一点额外的东西。</h3></div><div class="pb l"><p class="bd b dl z fp oy fr fs oz fu fw dk translated">towardsdatascience.com</p></div></div><div class="pc l"><div class="pd l pe pf pg pc ph ks ot"/></div></div></a></div><h2 id="7b2c" class="nn mr it bd ms no np dn mw nq nr dp na li ns nt nc lm nu nv ne lq nw nx ng ny bi translated">部署您的模型</h2><p id="eb09" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">既然我们已经在<code class="fe nz oa ob oc b">S3</code>上训练并存储了我们的模型，下一步就是将它作为 web 服务部署到生产中。为此，我们创建一个 python 脚本，名为<code class="fe nz oa ob oc b">predictor.py</code>，如下图所示:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oo op l"/></div></figure><p id="b697" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该文件定义了一个预测器类。当它被实例化时，它从<code class="fe nz oa ob oc b">S3</code>中检索模型，将其加载到内存中，并定义一些必要的转换和参数。在推断过程中，它从给定的<code class="fe nz oa ob oc b">URL</code>中读取图像，并返回预测类的名称。预测器的接口正是如此。一个用于初始化的<code class="fe nz oa ob oc b">__init__</code>方法和一个用于接收有效载荷并返回结果的<code class="fe nz oa ob oc b">predict</code>方法。</p><p id="3fa4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">预测器脚本有两个附带文件。记录库依赖关系的<code class="fe nz oa ob oc b">requirements.txt</code>文件(如 pytorch、fastai、boto3 等。)和一个 YAML 配置文件。最低配置如下所示:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oo op l"/></div></figure><p id="f2b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这个 YAML 文件中，我们定义了运行哪个脚本进行推理，在哪个设备(例如 CPU)上运行，以及在哪里找到训练好的模型。文档中提供了更多选项。</p><p id="638a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，项目的结构应该遵循下面的层次结构。请注意，这只是最低要求，但是如果您已经为部署准备好了模型，您可以提交<code class="fe nz oa ob oc b">trainer.py</code>。</p><pre class="kj kk kl km gt of oc og oh aw oi bi"><span id="8761" class="nn mr it oc b gy oj ok l ol om">- Project name<br/>    |----trainer.py<br/>    |----predictor.py<br/>    |----requirements.txt<br/>    |----cortex.yaml</span></pre><p id="5353" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">准备就绪后，您可以简单地运行<code class="fe nz oa ob oc b">cortex deploy</code>，几秒钟后，您的新端点就可以接受请求了。执行<code class="fe nz oa ob oc b">corted get pets-classifier</code>监控端点并查看更多详细信息。</p><pre class="kj kk kl km gt of oc og oh aw oi bi"><span id="6a90" class="nn mr it oc b gy oj ok l ol om">status   up-to-date   requested   last update   avg request   2XX   <br/>live     1            1           13m           -             -</span><span id="2380" class="nn mr it oc b gy pi ok l ol om">endpoint: <a class="ae ky" href="http://a984d095c6d3a11ea83cc0acfc96419b-1937254434.us-west-2.elb.amazonaws.com/pets-classifier" rel="noopener ugc nofollow" target="_blank">http://a984d095c6d3a11ea83cc0acfc96419b-1937254434.us-west-2.elb.amazonaws.com/pets-classifier</a><br/>curl: curl <a class="ae ky" href="http://a984d095c6d3a11ea83cc0acfc96419b-1937254434.us-west-2.elb.amazonaws.com/pets-classifier?debug=true" rel="noopener ugc nofollow" target="_blank">http://a984d095c6d3a11ea83cc0acfc96419b-1937254434.us-west-2.elb.amazonaws.com/pets-classifier?debug=true</a> -X POST -H "Content-Type: application/json" -d <a class="ae ky" href="http://twitter.com/sample" rel="noopener ugc nofollow" target="_blank">@sample</a>.json</span><span id="f92b" class="nn mr it oc b gy pi ok l ol om">configuration<br/>name: pets-classifier<br/>endpoint: /pets-classifier<br/>predictor:<br/>  type: python<br/>  path: predictor.py<br/>  config:<br/>    bucket: cortex-pets-model<br/>    device: cpu<br/>    key: model.pkl<br/>compute:<br/>  cpu: 200m<br/>autoscaling:<br/>  min_replicas: 1<br/>  max_replicas: 100<br/>  init_replicas: 1<br/>  workers_per_replica: 1<br/>  threads_per_worker: 1<br/>  target_replica_concurrency: 1.0<br/>  max_replica_concurrency: 1024<br/>  window: 1m0s<br/>  downscale_stabilization_period: 5m0s<br/>  upscale_stabilization_period: 0s<br/>  max_downscale_factor: 0.5<br/>  max_upscale_factor: 10.0<br/>  downscale_tolerance: 0.1<br/>  upscale_tolerance: 0.1<br/>update_strategy:<br/>  max_surge: 25%<br/>  max_unavailable: 25%</span></pre><p id="5541" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">剩下的就是用<code class="fe nz oa ob oc b">curl</code>和一只博美犬的图像来测试它:</p><pre class="kj kk kl km gt of oc og oh aw oi bi"><span id="0073" class="nn mr it oc b gy oj ok l ol om">curl <a class="ae ky" href="http://a984d095c6d3a11ea83cc0acfc96419b-1937254434.us-west-2.elb.amazonaws.com/pets-classifier?debug=true" rel="noopener ugc nofollow" target="_blank">http://a984d095c6d3a11ea83cc0acfc96419b-1937254434.us-west-2.elb.amazonaws.com/pets-classifier</a> -X POST -H "Content-Type: application/json" -d '{"url": "<a class="ae ky" href="https://i.imgur.com/HPRQ28l.jpeg" rel="noopener ugc nofollow" target="_blank">https://i.imgur.com/HPRQ28l.jpeg</a>"}'</span></pre><h2 id="63d4" class="nn mr it bd ms no np dn mw nq nr dp na li ns nt nc lm nu nv ne lq nw nx ng ny bi translated">打扫</h2><p id="7528" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">当我们完成服务和集群时，我们应该释放资源以避免额外的成本。Cortex 让这一切变得简单:</p><pre class="kj kk kl km gt of oc og oh aw oi bi"><span id="efa2" class="nn mr it oc b gy oj ok l ol om">cortex delete pets-classifier<br/>cortex cluster down</span></pre><h1 id="dd90" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">结论</h1><p id="38da" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">在这个故事中，我们看到了如何使用 Cortex，这是一个开源平台，用于将机器学习模型部署为生产 web 服务。我们训练了一个图像分类器，将其部署在 AWS 上，监控其性能并对其进行测试。</p><p id="ae10" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于更高级的概念，如预测监控、滚动更新、集群配置、自动扩展等，请访问官方文档<a class="ae ky" href="https://www.cortex.dev/" rel="noopener ugc nofollow" target="_blank">网站</a>，以及该项目的 GitHub <a class="ae ky" href="https://github.com/cortexlabs/cortex" rel="noopener ugc nofollow" target="_blank">页面</a>。</p><blockquote class="mj mk ml"><p id="d043" class="kz la mm lb b lc ld ju le lf lg jx lh mn lj lk ll mo ln lo lp mp lr ls lt lu im bi translated"><strong class="lb iu">我叫 Dimitris Poulopoulos，是希腊比雷埃夫斯大学<em class="it"/></strong><a class="ae ky" href="https://bigdatastack.eu/" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">BigDataStack</strong></a><strong class="lb iu"><em class="it"/>的机器学习研究员和博士(c)。我曾为欧洲委员会、欧盟统计局、国际货币基金组织、欧洲中央银行、经合组织和宜家等主要客户设计和实施人工智能和软件解决方案。如果你有兴趣阅读更多关于机器学习、深度学习和数据科学的帖子，请在 twitter 上关注我的</strong><a class="ae ky" href="https://medium.com/@dpoulopoulos" rel="noopener"><strong class="lb iu"/></a><strong class="lb iu"/><a class="ae ky" href="https://www.linkedin.com/in/dpoulopoulos/" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">LinkedIn</strong></a><strong class="lb iu">或</strong><a class="ae ky" href="https://twitter.com/james2pl" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">@ james2pl</strong></a><strong class="lb iu">。</strong></p></blockquote></div></div>    
</body>
</html>