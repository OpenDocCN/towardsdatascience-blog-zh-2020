<html>
<head>
<title>A Swift Introduction To Flux For Julia (With CUDA)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Julia对Flux的快速介绍(使用CUDA)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-swift-introduction-to-flux-for-julia-with-cuda-9d87c535312c?source=collection_archive---------21-----------------------#2020-02-25">https://towardsdatascience.com/a-swift-introduction-to-flux-for-julia-with-cuda-9d87c535312c?source=collection_archive---------21-----------------------#2020-02-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="63fa" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用Flux在Julia中建立你的第一个渐变模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/e34711f397a849e3f3b98cf6abad6dd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*htR27bKR1vXpPnlonaOQlg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(src = http://fluxml.ai)</p></figure><p id="79dc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">自从经典的Mocha.jl时代以来，Julia中的机器学习已经走过了漫长的道路，对该生态系统做出贡献的最具开创性的创造之一是Flux.jl. Flux是Julia的权威梯度下降库，可以与Python的Tensorflow相提并论。Flux遵循与许多Julia包类似的概念，如Lathe.jl和DataFrames.jl，只用大约1000行代码编写，并且只依赖于Julia本身。与Tensorflow和Pytorch等解决方案相比，它们都使用各种语言，包括C++、Go和C。</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/48377835c42fb637eb686750247989c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/format:webp/1*M3xv_1TQvceL6WBqN318oQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(src = http://juliacomputing.com)</p></figure><p id="033e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Julia的一个优点是并行计算平台和多线程与语言的无缝结合。没有比这更形象化的了(明白吗？相比NVIDIA图形处理器的古老平台CUDA。Julia和您的硬件之间的紧密集成很好地延续到Flux中，使Flux和CUDA成为真正的天作之合。将机器代码中的零标志设置为一，系好安全带，因为这肯定会令人兴奋！</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="140b" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">获取数据</h1><p id="f3db" class="pw-post-body-paragraph ky kz it la b lb mu ju ld le mv jx lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated">对于我今天的样本数据，我选择了来自MLDatasets.jl的数据集，它是可爱的Julia Computing的产品，您可以使用Pkg添加它:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="f065" class="ne md it na b gy nf ng l nh ni">using Pkg;Pkg.add("MLDatasets")</span></pre><p id="bdaf" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">或者，在Pkg REPL:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="e461" class="ne md it na b gy nf ng l nh ni">bash -$ julia<br/>julia&gt; ]<br/>pkg&gt; add "MLDatasets"</span></pre><p id="3da4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我通常不从常用的包中选择数据集，但是我做了这个例外，以确保这段代码不需要任何下载就可以重现(至少不需要通过您的web浏览器)。我要使用的数据集是时尚敏斯特数据集，我们可以这样下载:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="f17b" class="ne md it na b gy nf ng l nh ni"><strong class="na iu">using</strong> MLDatasets FashionMNIST.download(i_accept_the_terms_of_use=true)<br/>train_x, train_y = FashionMNIST.traindata();  <br/>test_x,  test_y  = FashionMNIST.testdata();</span></pre><p id="3919" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您还可以选择添加一个验证集，或者用Lathe分割您自己的数据集:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="644b" class="ne md it na b gy nf ng l nh ni">using Pkg; Pkg.add("Lathe")<br/>using Lathe.preprocess: TrainTestSplit</span><span id="9a3f" class="ne md it na b gy nj ng l nh ni">using DataFrames<br/># Validation:<br/>train_x, train_y = FashionMNIST.traindata();<br/>test_x, test_y = FashionMNIST.testdata();<br/>df = DataFrame(:Feature =&gt; train_x, :Target =&gt; train_y)<br/>train, val = TrainTestSplit(df)</span><span id="8065" class="ne md it na b gy nj ng l nh ni">f = :Feature</span><span id="f882" class="ne md it na b gy nj ng l nh ni">t = :Target<br/>val_x = val[f]<br/>val_y = val[t]<br/>train_x = train[f]<br/>train_y = train[t]</span><span id="176a" class="ne md it na b gy nj ng l nh ni"># Bring your own data:<br/>using CSV<br/>df = CSV.read("data.csv")<br/>train, test = TrainTestSplit(df)</span></pre><p id="8b17" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因为我的数据集处理图像，所以我应该将数据从各自的文件格式转换成图像，我们可以这样做:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="25d4" class="ne md it na b gy nf ng l nh ni"><strong class="na iu">using</strong> ImageCore<br/>FashionMNIST.convert2image(FashionMNIST.traintensor(4))</span></pre></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="cf94" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">建模</h1><p id="0cb5" class="pw-post-body-paragraph ky kz it la b lb mu ju ld le mv jx lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated">首先，我们需要导入通量本身:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="4c11" class="ne md it na b gy nf ng l nh ni"><strong class="na iu">using</strong> Flux, Statistics <br/><strong class="na iu">using</strong> Flux: onehotbatch, onecold, crossentropy, throttle, params <strong class="na iu">using</strong> Lathe.stats: mean <br/><strong class="na iu">using</strong> Base.Iterators: partition <br/><strong class="na iu">using</strong> Random</span></pre><p id="dff1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我还直接从Flux导入了几个模块包括onehotbatch，onecold，crossentropy，throttle，params，还有从Lathe.stats导入的mean函数，从Julia的迭代器导入的partition，还有Random。所有这些都是我们可以用来制作通量模型的拼图的一部分。下一步将是构建模型链。这是Flux真正闪光的地方，因为与大多数其他机器学习库不同，Flux的渐变层使用链工作。Flux使用Julia语言中各种独特而令人敬畏的语法点的组合来创建一个非常优雅的机器学习环境，chain就是一个很好的例子。</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="e524" class="ne md it na b gy nf ng l nh ni">model() = Chain(<br/>  Conv((5, 5), 1 =&gt; 64, elu, pad=(2, 2), stride=(1, 1)),<br/>  BatchNorm(64),<br/>  MaxPool((3, 3), pad=(2, 2), stride=(2, 2)),<br/>  Dropout(0.25),<br/>  Conv((5, 5), 64 =&gt; 128, elu, pad=(2, 2), stride=(1, 1)),<br/>  BatchNorm(128),<br/>  MaxPool((2, 2), stride=(2, 2)),<br/>  Dropout(0.25),<br/>  Conv((5, 5), 128 =&gt; 256, elu, pad=(2, 2), stride=(1, 1)),<br/>  BatchNorm(256),<br/>  MaxPool((2, 2), stride=(2, 2)),<br/>  Dropout(0.25),<br/>  x -&gt; reshape(x, :, size(x, 4)),<br/>  Dense(2304, 256, elu),<br/>  Dropout(0.5),<br/>  Dense(256, 10),<br/>  softmax) |&gt; gpu</span></pre><p id="6410" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">接下来，我们需要为我们的训练数据获取N:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="cc6e" class="ne md it na b gy nf ng l nh ni">N = size(train_x)[<strong class="na iu">end</strong>]</span></pre><p id="cd72" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，我们可以使用N通过范围迭代来随机混洗和排列我们训练索引:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="3bd7" class="ne md it na b gy nf ng l nh ni">ixs = collect(1:N)<br/>shuffle!(ixs)<br/>n = Int(floor(.9 * N))</span></pre><p id="e78f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里需要注意的重要一点是，我们的数据需要存储在子数组或字典中。鉴于这将适用于字典，它很可能也适用于数据帧。将我们的数据转换成Flux批处理可以接受的格式后，我们可以像这样对数据进行批处理:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="59b6" class="ne md it na b gy nf ng l nh ni"><strong class="na iu">function</strong> make_batches(data; bs=100)<br/>    n = size(data[1])[<strong class="na iu">end</strong>]<br/>    sz = (28, 28, 1, bs)<br/>    iter = [(reshape(Float32.(data[1][:, :, i]), sz), onehotbatch(data[2][i], 0:9)) <strong class="na iu">for</strong> i <strong class="na iu">in</strong> partition(1:n, bs)] |&gt; gpu<br/><strong class="na iu">end</strong><br/><br/>train = make_batches(train)<br/>val = make_batches(val)<br/>test = make_batches(test);</span></pre><p id="5837" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，我们简单地用预期回报构建我们的模型:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="29e5" class="ne md it na b gy nf ng l nh ni">m = model()</span></pre><p id="7bff" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是输出:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="ea99" class="ne md it na b gy nf ng l nh ni"><strong class="na iu">Chain(Conv((5, 5), 1=&gt;64, elu), BatchNorm(64), MaxPool((3, 3), pad = (2, 2), stride = (2, 2)), Dropout(0.25), Conv((5, 5), 64=&gt;128, elu), BatchNorm(128), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Dropout(0.25), Conv((5, 5), 128=&gt;256, elu), BatchNorm(256), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Dropout(0.25), #9, Dense(2304, 256, elu), Dropout(0.5), Dense(256, 10), softmax)</strong></span></pre><p id="69a6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我没有为这个特定的模型进行超参数调整，所以很可能只需要一点优化就可以提高精度。</p><p id="6621" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">接下来，我们需要一个度量函数，它将允许我们的模型检测它什么时候做得好或者坏。为此，我们需要三大部分:</p><blockquote class="nk"><p id="4eac" class="nl nm it bd nn no np nq nr ns nt lt dk translated">尝试、验证、重建</p></blockquote><p id="ce06" class="pw-post-body-paragraph ky kz it la b lb nu ju ld le nv jx lg lh nw lj lk ll nx ln lo lp ny lr ls lt im bi translated">我喜欢把这种尝试称为网络学习任何东西之前的初步猜测。验证是该过程中的一个重要步骤，模型需要检测它是变得更准确了，还是变得不准确了。最后但同样重要的是，重构是一个递归过程，在这个过程中，猜测被恢复并从中学习。这是我的函数:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="b3ad" class="ne md it na b gy nf ng l nh ni"><strong class="na iu">function</strong> met(data)<br/>    <strong class="na iu">global</strong> batch_idx<br/>    acc = 0<br/>    <strong class="na iu">for</strong> batch <strong class="na iu">in</strong> data<br/>        x, y = batch<br/>        pred = m(x) .&gt; 0.5<br/>        tp = Float32(sum((pred .+ y) .== Int16(2)))<br/>        fp = Float32(sum((pred .- y) .== Int16(1)))<br/>        fn = Float32(sum((pred .- y) .== Int16(-1)))<br/>        tn = Float32(sum((pred .+ y) .== Int16(0)))<br/>        acc += (tp + tn) / (tp + tn + fp + fn)<br/>    <strong class="na iu">end</strong><br/>    acc /= length(data)<br/>    push!(eval_acc, acc)<br/>    <strong class="na iu">if</strong> batch_idx % 100 == 0<br/>        @show(batch_idx)<br/>    <strong class="na iu">end</strong><br/>    <br/>    batch_idx += 1<br/><strong class="na iu">end</strong></span></pre><p id="e3fc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后我们可以将所有这些部分插入语法表达式:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="460c" class="ne md it na b gy nf ng l nh ni">loss(x, y) = crossentropy(m(x), y)<br/>evalcb = () -&gt; met(val)</span></pre><p id="116e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后训练我们的模型！</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="ddb9" class="ne md it na b gy nf ng l nh ni">Flux.train!(loss, params(m), train, opt, cb = evalcb)</span></pre><p id="2f1f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，我们可以使用相同的度量函数来检查我们的精度:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="1e33" class="ne md it na b gy nf ng l nh ni">met(test)<br/>println("accuracy:", eval_acc[1])</span></pre><blockquote class="nk"><p id="b07e" class="nl nm it bd nn no nz oa ob oc od lt dk translated">百分之九十七的准确率！</p></blockquote><figure class="of og oh oi oj kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/4bdbd270662dc7083304fcdd5d956427.png" data-original-src="https://miro.medium.com/v2/resize:fit:1222/format:webp/1*JCj8jBjG5CIqoAM9RcWlLQ.png"/></div></div></figure><h1 id="f567" class="mc md it bd me mf ok mh mi mj ol ml mm jz om ka mo kc on kd mq kf oo kg ms mt bi translated">结论</h1><p id="9997" class="pw-post-body-paragraph ky kz it la b lb mu ju ld le mv jx lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated">Flux的语法、表达式和速度使其成为在Julia工作的数据科学家的一个非常有价值的工具。Flux在许多测试中击败了竞争对手，因为它体积小、简单、快速且有效。Flux的另一个巨大好处是模块化模型可以是什么样的，正如我通过在一个链中构建我的网络层，然后在其上传递更多内置来说明的那样。总的来说，我对Flux的发展以及Julia在机器学习和统计方面的整体发展感到兴奋。如果你对Flux感兴趣，另一个你可能感兴趣的很酷的东西是KNet，我将很快写一篇关于它的“快速介绍”!你现在可以亲自去看看Metalhead.jl，这是一个用Flux编写的图像分类器，可以适应新数据，并可回收用于任何分类用例。</p></div></div>    
</body>
</html>