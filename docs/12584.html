<html>
<head>
<title>‘Simpsonize’ Yourself using CycleGAN and PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 CycleGAN 和 PyTorch 来简化自己</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/simpsonize-yourself-using-cyclegan-and-pytorch-cea94ee199ca?source=collection_archive---------24-----------------------#2020-08-30">https://towardsdatascience.com/simpsonize-yourself-using-cyclegan-and-pytorch-cea94ee199ca?source=collection_archive---------24-----------------------#2020-08-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7c5a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用 CycleGAN 和 PyTorch 将人脸转换为 Simpsons 角色</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/a826dbe421d7f596582516428da79257.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6ttM41rkE158Ox1u8OYVmw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><div class="kg kh ki kj gt ab cb"><figure class="kv kk kw kx ky kz la paragraph-image"><img src="../Images/b4162d06662724195ff749a2f4bb2487.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*MqJY9-rS7_-RPRqV.png"/></figure><figure class="kv kk kw kx ky kz la paragraph-image"><img src="../Images/baea2b11223d9b37d90e3baf4645aaa4.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*GPwpOOa2N_pKnogq.png"/><p class="kr ks gj gh gi kt ku bd b be z dk lb di lc ld translated">作者图片</p></figure></div><p id="4f73" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">Cyclegan 是一个能够进行不成对图像到图像翻译的框架。它被应用在一些非常有趣的案例中。比如把马转换成斑马(T4)，把冬天的照片转换成夏天的照片。</p><p id="46bb" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我认为这可能适用于辛普森一家。我的灵感来自于像<a class="ae ma" href="https://turnedyellow.com/" rel="noopener ugc nofollow" target="_blank">变黄</a>和<a class="ae ma" href="https://makemeyellow.photos/" rel="noopener ugc nofollow" target="_blank"> makemeyellow </a>这样的网站。这个想法是你上传一张你的脸的照片。Cyclegan 会把它翻译成辛普森一家的角色。</p><p id="0047" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">值得注意的是<a class="ae ma" href="https://arxiv.org/pdf/1703.10593.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>明确提到大的几何变化通常是不成功的。所以这不太可能有好结果。</p><p id="022f" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">但我还是要尝试一下。</p><h1 id="5ae4" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">安装</h1><p id="7aee" class="pw-post-body-paragraph le lf iq lg b lh mt jr lj lk mu ju lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">首先我们需要安装 CycleGAN。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="0b7e" class="nd mc iq mz b gy ne nf l ng nh">!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix<br/>import os<br/>os.chdir('pytorch-CycleGAN-and-pix2pix/')<br/>!pip install -r requirements.txt</span></pre><h1 id="4b9f" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">数据集</h1><p id="d280" class="pw-post-body-paragraph le lf iq lg b lh mt jr lj lk mu ju lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">创建数据集比您最初想象的要困难。</p><p id="8498" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">为了创建这个数据集，我需要找到辛普森一家角色的特写镜头和普通人的特写镜头。</p><h1 id="b8ba" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">下载辛普森数据集</h1><p id="ec40" class="pw-post-body-paragraph le lf iq lg b lh mt jr lj lk mu ju lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">最初我的想法是从谷歌图片中抓取图片。不幸的是，要做到这一点，看起来你需要一个来自谷歌控制台的开发者密钥。</p><p id="08c5" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">所以我从 Bing 中抓取图片。</p><p id="6846" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这在一定程度上起了作用。但是花了<em class="ni">这么长时间</em>才下载完所有的图片。在我看了这些照片后，我注意到其中一些根本没有任何人脸。</p><p id="4ab5" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">谢天谢地，我在 kaggle 上偶然发现了一个数据集，里面有我需要的一切。它包含了从几季中提取的辛普森面孔。每个图像为 200x200 像素，包含一张脸。</p><p id="b37c" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">该数据集将存储在<code class="fe nj nk nl mz b">trainA</code>文件夹中。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="5195" class="nd mc iq mz b gy ne nf l ng nh">def create_training_dataset_simpson_faces(download_dir):<br/><br/>  %cd $download_dir<br/><br/>  # download dataset and unzip<br/>  !kaggle datasets download kostastokis/simpsons-faces --force<br/>  !unzip \*.zip<br/>  !rm *.zip<br/>  !cp -a $download_dir/cropped/. $download_dir<br/><br/>  # remove unnecessary folders<br/>  !rm -Rf $download_dir/cropped<br/>  !rm -Rf $download_dir/simplified<br/><br/>  # go back to orig directory<br/>  %cd /content/pytorch-CycleGAN-and-pix2pix<br/><br/>create_training_dataset_simpson_faces(TRAIN_A)</span></pre><h1 id="52a0" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">下载真实人脸数据集</h1><p id="f19f" class="pw-post-body-paragraph le lf iq lg b lh mt jr lj lk mu ju lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">为了创建真实人脸的数据集，我做了一点实验。</p><p id="a38e" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><a class="ae ma" href="https://www.youtube.com/watch?v=pctzpu_wJyE" rel="noopener ugc nofollow" target="_blank"> Will Kwan </a>最近使用<a class="ae ma" href="https://github.com/NVlabs/stylegan2" rel="noopener ugc nofollow" target="_blank"> stylegan2 </a>在他最近的一个视频中生成数据集。这对他来说似乎相当有效。所以我想我也可以做同样的事情。</p><p id="40f6" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这里有一些取自 Nvidia 的 stylegan2 github 库的人脸示例。如你所见，GAN 的输出相当逼真。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nm"><img src="../Images/46e2bd0e9a5f7148bcbec0d9912299df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*E6pJw7GKUJX7SgE5.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由<a class="ae ma" href="https://github.com/NVlabs" rel="noopener ugc nofollow" target="_blank"> NVlabs </a>在<a class="ae ma" href="https://github.com/NVlabs/stylegan2" rel="noopener ugc nofollow" target="_blank"> Github </a>上提供</p></figure><p id="4cef" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这可能比在网上搜索人脸要好得多。我可以为我的模型创建尽可能多的面。另外，我也不必下载笨重的大文件。</p><p id="a45a" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">该数据集将存储在<code class="fe nj nk nl mz b">trainB</code>文件夹中</p><h2 id="a044" class="nd mc iq bd md nn no dn mh np nq dp ml ln nr ns mn lr nt nu mp lv nv nw mr nx bi translated">创建数据集</h2><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="3eb9" class="nd mc iq mz b gy ne nf l ng nh">import matplotlib.pyplot as plt<br/>from tqdm.notebook import tqdm</span><span id="4ba9" class="nd mc iq mz b gy ny nf l ng nh"># see Github for full code: <a class="ae ma" href="https://github.com/spiyer99/spiyer99.github.io/blob/master/nbs/cyclegan_simpsonify.ipynb" rel="noopener ugc nofollow" target="_blank">https://github.com/spiyer99/spiyer99.github.io/blob/master/nbs/cyclegan_simpsonify.ipynb</a></span><span id="a192" class="nd mc iq mz b gy ny nf l ng nh">def create_training_dataset_real_faces_stylegan(download_dir):<br/><br/>  # create in batches of 100<br/>  # reduces RAM requirements<br/><br/>  counter = 0<br/>  pbar = tqdm(total = LIMIT)<br/><br/>  while counter &lt; LIMIT:<br/><br/>    seeds = np.random.randint(10000000, size=100)<br/>    imgs = generate_images_from_seeds(seeds, 0.7)<br/><br/>    for img in imgs:<br/>      img.save(download_dir/'real_face_{}.jpg'.format(counter), 'JPEG', quality=100)<br/>      counter+=1<br/>      pbar.update(1)<br/>    del imgs<br/><br/>create_training_dataset_real_faces_stylegan(TRAIN_B)</span></pre><h1 id="21ef" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">列车测试分离</h1><p id="7b39" class="pw-post-body-paragraph le lf iq lg b lh mt jr lj lk mu ju lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">接下来，我们需要将数据分为训练和测试。<code class="fe nj nk nl mz b">testB</code>将包含我们想要转换成辛普森一家角色的真实面孔。<code class="fe nj nk nl mz b">testA</code>将包含辛普森一家的人物，我们想把他们变成真人。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="afd2" class="nd mc iq mz b gy ne nf l ng nh"># move images to a new folder<br/># `images` is the existing image directory: <br/># `new_dir` is the path that the images will be moved to<br/># `files_limit` is the limit of files that will be moved<br/>def move_all_images_to_new_folder(images, new_dir, files_limit = None):<br/>  files = glob.glob(str(images/'*.*g'))<br/><br/>  if(files_limit is not None):<br/>    files = files[:files_limit]<br/><br/>  for file in files: shutil.move(file, new_dir/os.path.basename(file))<br/><br/>move_all_images_to_new_folder(TRAIN_A, new_dir = TEST_A, files_limit = int(min(LIMIT*0.1, 25)))<br/>move_all_images_to_new_folder(TRAIN_B, new_dir = TEST_B, files_limit = int(min(LIMIT*0.1, 25)))</span></pre><h1 id="d634" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">查看我们的培训和测试数据</h1><p id="e725" class="pw-post-body-paragraph le lf iq lg b lh mt jr lj lk mu ju lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">让我们看看我们正在处理的图像。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="6ead" class="nd mc iq mz b gy ne nf l ng nh">import PIL<br/>import random<br/><br/>def plot_from_image_path(path, title):<br/><br/>  all_imgs = glob.glob(str(path/'*.*g'))<br/><br/>  print(f'{len(all_imgs)} imgs in {title} directory')<br/><br/>  img_path = random.choice(all_imgs)<br/>  img = PIL.Image.open(img_path)<br/>  plt.imshow(img)<br/>  plt.title(title)<br/>  plt.show()<br/><br/>plot_from_image_path(TRAIN_A, 'TRAIN_A')<br/>plot_from_image_path(TRAIN_B, 'TRAIN_B')<br/><br/>plot_from_image_path(TEST_A, 'TEST_A')<br/>plot_from_image_path(TEST_B, 'TEST_B')</span></pre><div class="kg kh ki kj gt ab cb"><figure class="kv kk nz kx ky kz la paragraph-image"><img src="../Images/562fc1d3f91115e2dca5727b00621fd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/format:webp/0*IPkWvWBYIdRrXpXd.png"/></figure><figure class="kv kk oa kx ky kz la paragraph-image"><img src="../Images/e24f5a35e75e436f9bfed29d87876a74.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/format:webp/0*Z7qrUMIqZPZZX9c3.png"/><p class="kr ks gj gh gi kt ku bd b be z dk ob di oc ld translated">作者图片</p></figure></div><div class="ab cb"><figure class="kv kk nz kx ky kz la paragraph-image"><img src="../Images/451fe6f32fd263b23e003974f6e32e92.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/format:webp/0*eTK-17g_5zdN0e84.png"/></figure><figure class="kv kk oa kx ky kz la paragraph-image"><img src="../Images/39ee812a497fa38f3ca8f05866db658f.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/format:webp/0*lf_fYQQqAa8jtnR_.png"/><p class="kr ks gj gh gi kt ku bd b be z dk ob di oc ld translated">作者图片</p></figure></div><p id="6802" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">一切看起来都很好！</p><h1 id="e691" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">创建模型</h1><p id="28cc" class="pw-post-body-paragraph le lf iq lg b lh mt jr lj lk mu ju lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">现在我们可以创建模型了。我对现有的<a class="ae ma" href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/train.py" rel="noopener ugc nofollow" target="_blank">脚本</a>做了一些调整。</p><p id="8a9b" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">让我们创建几个助手函数。</p><p id="208e" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这些功能帮助我将保存的模型复制到我的 google drive。它还有助于测试模型并将输出图像存储到 google drive。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="458f" class="nd mc iq mz b gy ne nf l ng nh">import os<br/>from pathlib import Path<br/>from distutils.dir_util import copy_tree<br/>import matplotlib.pyplot as plt<br/>import random<br/><br/>def copy_to_drive(folder = 'cyclegan_simpsonify'):<br/><br/>  drive_folder = Path('/content/drive/My Drive/')/folder<br/><br/>  if(drive_folder.exists()):<br/>    shutil.rmtree(drive_folder)<br/><br/>  shutil.copytree('/content/pytorch-CycleGAN-and-pix2pix/checkpoints/'+NAME+'/', str(drive_folder))<br/><br/>def get_corresponding_photo(file_path):<br/>  return file_path.replace('fake', 'real')<br/><br/>def plot_results(number):<br/><br/>  for i in range(number):<br/><br/>    img_path = random.choice(glob.glob('./results/'+NAME+'/test_latest/images/*fake.*g'))<br/>    print(img_path)<br/>    img = plt.imread(img_path)<br/>    plt.imshow(img)<br/>    plt.title('fake')<br/>    plt.show()<br/><br/>    print(get_corresponding_photo(img_path))<br/>    img = plt.imread(get_corresponding_photo(img_path))<br/>    plt.imshow(img)<br/>    plt.title('real')<br/>    plt.show()<br/><br/>def get_model(src, dst):<br/><br/>  # copy across model<br/>  try:<br/>    os.remove(dst)<br/>  except:<br/>    pass<br/>  shutil.copyfile(src, dst)<br/><br/>def copy_from_drive(folder = 'cyclegan_simpsonify'):<br/><br/>  drive_folder = Path('/content/drive/My Drive/')/folder<br/><br/>  if(not Path('/content/pytorch-CycleGAN-and-pix2pix/checkpoints/').exists()): <br/>    os.mkdir('/content/pytorch-CycleGAN-and-pix2pix/checkpoints/')<br/><br/>  if(Path('/content/pytorch-CycleGAN-and-pix2pix/checkpoints/'+NAME+'/').exists()): <br/>    shutil.rmtree('/content/pytorch-CycleGAN-and-pix2pix/checkpoints/'+NAME+'/')<br/><br/>  shutil.copytree(str(drive_folder), '/content/pytorch-CycleGAN-and-pix2pix/checkpoints/'+NAME+'/')<br/><br/>def test_model (number_results = 5, direction = 'BtoA', src = None, dst = None):<br/><br/>  # delete results folder and recrete<br/>  shutil.rmtree('./results')<br/>  os.mkdir('./results')<br/><br/>  # get appropriate model<br/>  if (src is None): src = './checkpoints/'+NAME+'/latest_net_G_'+direction.split('to')[-1]+'.pth'<br/>  if (dst is None): dst = './checkpoints/'+NAME+'/latest_net_G.pth'<br/><br/>  get_model(src, dst)<br/><br/>  if (direction == 'BtoA'):<br/>    test = TEST_B<br/>  else:<br/>    test = TEST_A<br/>  <br/>  cmd = 'python test.py --dataroot '+str(test)+' --name '+str(NAME)+' --model test --no_dropout'<br/>  os.system(cmd)<br/>  plot_results(number_results)</span></pre><p id="723f" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">让我们为培训创建选项。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="7313" class="nd mc iq mz b gy ne nf l ng nh">import time<br/>from options.train_options import TrainOptions<br/>from data import create_dataset<br/>from models import create_model<br/>from util.visualizer import Visualizer<br/>import shutil<br/>import os<br/>from pathlib import Path<br/>from tqdm.notebook import tqdm<br/><br/>options_list = ['--name', NAME,\<br/>		'--dataroot', TRAIN_A.parent,\<br/>		'--batch_size', BATCH_SIZE,\<br/>		'--checkpoints_dir', './checkpoints',\<br/>		'--lr', 2e-4,\<br/>		'--n_epochs', EPOCHS,\<br/>		'--n_epochs_decay', EPOCHS//2,\<br/>		'--name', NAME]<br/><br/>opt = TrainOptions().parse(options_list)</span></pre><p id="fdc0" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">首先，我们使用前面指定的选项创建数据集。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="cdfd" class="nd mc iq mz b gy ne nf l ng nh">dataset = create_dataset(opt)<br/>dataset_size = len(dataset)<br/>print('The number of training images = %d' % dataset_size)</span></pre><p id="195f" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">然后，我们创建模型并运行 setup 调用。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="3eb2" class="nd mc iq mz b gy ne nf l ng nh">model = create_model(opt)<br/>model.setup(opt)<br/>visualizer = Visualizer(opt)<br/>total_iters = 0</span></pre><p id="44f0" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们从 A 到 b 来看生成器，命名约定和<a class="ae ma" href="https://arxiv.org/pdf/1703.10593.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>略有不同。在论文<a class="ae ma" href="https://arxiv.org/pdf/1703.10593.pdf" rel="noopener ugc nofollow" target="_blank">中</a>发电机被称为<code class="fe nj nk nl mz b">G</code>。</p><p id="a7ac" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在代码中，他们称这个映射函数为<code class="fe nj nk nl mz b">G_A</code>。意思还是一样的。</p><p id="e9e4" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">该发生器功能从<code class="fe nj nk nl mz b">A</code>映射到<code class="fe nj nk nl mz b">B</code>。</p><p id="1fc5" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在我们的例子中，它从辛普森一家映射到现实生活。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="73b6" class="nd mc iq mz b gy ne nf l ng nh">model.netG_A</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/2383f77f9162114704d1bda3413088a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kqcYFWXtqQRV1xMR.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="627b" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这里我们可以看到模型使用了<a class="ae ma" href="https://arxiv.org/pdf/1512.03385v1.pdf" rel="noopener ugc nofollow" target="_blank"> Resnets </a>。</p><p id="574d" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们有<code class="fe nj nk nl mz b">Conv2d</code>、<code class="fe nj nk nl mz b">Batchnorm</code>、<code class="fe nj nk nl mz b">ReLU</code>、<code class="fe nj nk nl mz b">InstanceNorm2d</code>和<code class="fe nj nk nl mz b">ReflectionPad2d</code>。<code class="fe nj nk nl mz b">InstanceNorm2d</code>和<code class="fe nj nk nl mz b">ReflectionPad2d</code>对我来说是新的。</p><p id="92e3" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><code class="fe nj nk nl mz b">InstanceNorm2d</code>:这与<a class="ae ma" href="https://arxiv.org/abs/1502.03167" rel="noopener ugc nofollow" target="_blank">批量定额</a>非常相似，但它一次应用于一幅图像。</p><p id="5852" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><code class="fe nj nk nl mz b">ReflectionPad2d</code>:这将使用输入边界的反射填充张量。</p><p id="5b68" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">现在我们也可以看看鉴别器。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="ea29" class="nd mc iq mz b gy ne nf l ng nh">model.netD_A</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/09ad385b41f9bf536db6664c2b6afb86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1uyeA-Tmeg3Lfsbe.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="91bd" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">鉴别器使用<code class="fe nj nk nl mz b">LeakyReLU</code>、<code class="fe nj nk nl mz b">Conv2d</code>和<code class="fe nj nk nl mz b">InstanceNorm2d</code>。</p><p id="cb02" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><code class="fe nj nk nl mz b">LeakyReLU</code>有意思。<code class="fe nj nk nl mz b">ReLU</code>是增加网络非线性的激活。但是什么是<code class="fe nj nk nl mz b">LeakyReLU</code>？</p><p id="4926" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><code class="fe nj nk nl mz b">ReLU</code>将所有负值转换为<code class="fe nj nk nl mz b">0</code>。由于<code class="fe nj nk nl mz b">0</code>的梯度是<code class="fe nj nk nl mz b">0</code>神经元达到大的负值，有效神经元抵消到<code class="fe nj nk nl mz b">0</code>。他们实际上是“死”了。这意味着你的网络最终会停止学习。</p><p id="0468" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这种效应被称为<a class="ae ma" href="https://datascience.stackexchange.com/questions/5706/what-is-the-dying-relu-problem-in-neural-networks" rel="noopener ugc nofollow" target="_blank">将死</a> <code class="fe nj nk nl mz b"><a class="ae ma" href="https://datascience.stackexchange.com/questions/5706/what-is-the-dying-relu-problem-in-neural-networks" rel="noopener ugc nofollow" target="_blank">ReLU</a></code> <a class="ae ma" href="https://datascience.stackexchange.com/questions/5706/what-is-the-dying-relu-problem-in-neural-networks" rel="noopener ugc nofollow" target="_blank">问题</a>。</p><p id="d374" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><code class="fe nj nk nl mz b">LeakyReLU</code>旨在解决这个问题。该功能如下所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/622b4368481309a8a34f1ca26382a318.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9Fr1o7p5lv2cmg33.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae ma" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>在<a class="ae ma" href="https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html" rel="noopener ugc nofollow" target="_blank"> PyTorch 文档</a>上拍摄的图像</p></figure><p id="011b" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这个函数本质上解释为:如果一个值是负的，则将其乘以<code class="fe nj nk nl mz b">negative_slope</code>，否则什么也不做。<code class="fe nj nk nl mz b">negative_slope</code>通常是<code class="fe nj nk nl mz b">0.01</code>，但是你可以变化一下。</p><p id="6197" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">所以<code class="fe nj nk nl mz b">LeakyReLU</code>大大降低了负值的幅度，而不是将它们发送给<code class="fe nj nk nl mz b">0</code>。但是这是否真的有效还没有定论。</p><h1 id="be6f" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">培养</h1><p id="d6b0" class="pw-post-body-paragraph le lf iq lg b lh mt jr lj lk mu ju lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">现在，我们可以在多个时期内训练模型。我在这里指定了<code class="fe nj nk nl mz b">10</code>纪元。</p><p id="86a3" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">以下是培训代码:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="0946" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">所有神奇的事情都发生在这里。它运行损失函数，获取梯度并更新权重。通过这样做，它优化了生成器和鉴别器。</p><p id="9fb0" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">让我们训练它！</p><h1 id="6b51" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">测试</h1><p id="8dd2" class="pw-post-body-paragraph le lf iq lg b lh mt jr lj lk mu ju lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">我让模型在<a class="ae ma" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"> google colab </a>上通宵训练，并将<code class="fe nj nk nl mz b">.pth</code>模型复制到我的 google drive 上。</p><p id="a74c" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">让我们看看输出。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="b13f" class="nd mc iq mz b gy ne nf l ng nh">test_model(10, 'BtoA')</span></pre><div class="kg kh ki kj gt ab cb"><figure class="kv kk kw kx ky kz la paragraph-image"><img src="../Images/7fb5bb05469c620b8df1adbf31c6ce2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*uEDZX3ixpiRDPrww.png"/></figure><figure class="kv kk kw kx ky kz la paragraph-image"><img src="../Images/df78ea1648758ef2fea9cfaa8121772b.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*cTQILqRKr7Z5FQw-.png"/><p class="kr ks gj gh gi kt ku bd b be z dk lb di lc ld translated">作者图片</p></figure></div><div class="ab cb"><figure class="kv kk kw kx ky kz la paragraph-image"><img src="../Images/75c090c66859cbfd2f36139faa214e79.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*BBJaNZXOV_KM81F6.png"/></figure><figure class="kv kk kw kx ky kz la paragraph-image"><img src="../Images/3c85c4ae834e0f0842f014e84108ab67.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*VusY1XBs7V2cRnFx.png"/><p class="kr ks gj gh gi kt ku bd b be z dk lb di lc ld translated">作者图片</p></figure></div><div class="ab cb"><figure class="kv kk kw kx ky kz la paragraph-image"><img src="../Images/c508899860a94c8fa63749560e6a1938.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*feRmXLPCvpotXG-6.png"/></figure><figure class="kv kk kw kx ky kz la paragraph-image"><img src="../Images/e6fe0a5f8bc6c24be957b6ff049386e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*bM8943IU-w9d6s4b.png"/><p class="kr ks gj gh gi kt ku bd b be z dk lb di lc ld translated">作者图片</p></figure></div><div class="ab cb"><figure class="kv kk kw kx ky kz la paragraph-image"><img src="../Images/832614524aa49242963926d536289f54.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*hRVnjADkdp3GReSV.png"/></figure><figure class="kv kk kw kx ky kz la paragraph-image"><img src="../Images/85a711a8bf30e3d34930f5b1786dfb5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*vkU0ROtVqQn7B3Q6.png"/><p class="kr ks gj gh gi kt ku bd b be z dk lb di lc ld translated">作者图片</p></figure></div><div class="ab cb"><figure class="kv kk kw kx ky kz la paragraph-image"><img src="../Images/7bd34bd68ac07ecfc71090e20d56b037.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/0*pSR6aYTE3vUygAzd.png"/></figure><figure class="kv kk kw kx ky kz la paragraph-image"><img src="../Images/7ce9620c82679cecc1c9f84fa477bdea.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/0*-e_C67HxCWkW_qdS.png"/><p class="kr ks gj gh gi kt ku bd b be z dk lb di lc ld translated">作者图片</p></figure></div><div class="ab cb"><figure class="kv kk kw kx ky kz la paragraph-image"><img src="../Images/1ae4aed2c15ff724f189d9cb9cf5c6fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*lrqR574qtX6KB6Jo.png"/></figure><figure class="kv kk kw kx ky kz la paragraph-image"><img src="../Images/6fb57af6ed39420c24e86bcf3bf5326c.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*ZwYWCoFNAm29tTnP.png"/><p class="kr ks gj gh gi kt ku bd b be z dk lb di lc ld translated">作者图片</p></figure></div><p id="7dfc" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这是一个好的开始。我特别喜欢这张图片:</p><div class="kg kh ki kj gt ab cb"><figure class="kv kk kw kx ky kz la paragraph-image"><img src="../Images/ccf7484fa6924411f1c887195529875a.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*TQWeiy3-0yCji8iV.png"/></figure><figure class="kv kk kw kx ky kz la paragraph-image"><img src="../Images/bfa01e79db4e663f24fe523583040ea9.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*NJcODMLcIvBIgMhh.png"/><p class="kr ks gj gh gi kt ku bd b be z dk lb di lc ld translated">作者图片</p></figure></div><p id="7cb6" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">老实说，它需要一些改进。</p><p id="5c91" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">让我们尝试运行<code class="fe nj nk nl mz b">AtoB</code>周期。所以我们要把辛普森一家的角色转换成人脸。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="13a6" class="nd mc iq mz b gy ne nf l ng nh">test_model(10, 'AtoB')</span></pre><div class="kg kh ki kj gt ab cb"><figure class="kv kk kw kx ky kz la paragraph-image"><img src="../Images/d49e7d9ada9f6b1ab63eb37c2d830e93.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*MIO0jgBFLZjx1KJ8.png"/></figure><figure class="kv kk kw kx ky kz la paragraph-image"><img src="../Images/69ee239505e968c1b9d062ed876c3fdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*eSpiv1z7K7JWM8Yi.png"/><p class="kr ks gj gh gi kt ku bd b be z dk lb di lc ld translated">作者图片</p></figure></div><div class="ab cb"><figure class="kv kk kw kx ky kz la paragraph-image"><img src="../Images/e5fdd1ed212f31a2975a5418914d394e.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*H5XZD5oujso3dWWj.png"/></figure><figure class="kv kk kw kx ky kz la paragraph-image"><img src="../Images/0ffe63350a10a61d53a69bea09f94fb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*pvTE-TUPeSQ6c-Xm.png"/><p class="kr ks gj gh gi kt ku bd b be z dk lb di lc ld translated">作者图片</p></figure></div><div class="ab cb"><figure class="kv kk kw kx ky kz la paragraph-image"><img src="../Images/02aec023301d2aadc861ab297645c9cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*idyhS5IospCwCPgW.png"/></figure><figure class="kv kk kw kx ky kz la paragraph-image"><img src="../Images/a4813547272f76b74a06896b0fbb07d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*4DtfKFvtqTTlQPHS.png"/><p class="kr ks gj gh gi kt ku bd b be z dk lb di lc ld translated">作者图片</p></figure></div><div class="ab cb"><figure class="kv kk kw kx ky kz la paragraph-image"><img src="../Images/29dee1120d065581076aca1cf2de418c.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*bptzedYot_AUVGnf.png"/></figure><figure class="kv kk kw kx ky kz la paragraph-image"><img src="../Images/d6381a2a5ca7e6896052e660269797a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*6JcoF11TdFjZJMx2.png"/><p class="kr ks gj gh gi kt ku bd b be z dk lb di lc ld translated">作者图片</p></figure></div><h1 id="2f33" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">丰富</h1><p id="4909" class="pw-post-body-paragraph le lf iq lg b lh mt jr lj lk mu ju lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">Cyclegan <a class="ae ma" href="https://junyanz.github.io/CycleGAN/" rel="noopener ugc nofollow" target="_blank">的作者指出</a>需要大的几何变化的任务不太可能成功。我刚刚证实了这一点。</p><p id="1b62" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">该网络似乎在努力应对将辛普森一家的角色转换成真人(反之亦然)所需的巨大几何变化。我不确定更多的培训能否解决这个问题。GANs 的棘手之处在于弄清楚何时停止训练。目视检查<a class="ae ma" href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/issues/166" rel="noopener ugc nofollow" target="_blank">似乎</a>是 Cyclegan 的答案。再训练几天看看会发生什么也许是值得的。</p><p id="8dd4" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">完整的 jupyter 笔记本可以在<a class="ae ma" href="https://github.com/spiyer99/spiyer99.github.io/blob/master/nbs/cyclegan_simpsonify.ipynb" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到</p></div><div class="ab cl oh oi hu oj" role="separator"><span class="ok bw bk ol om on"/><span class="ok bw bk ol om on"/><span class="ok bw bk ol om"/></div><div class="ij ik il im in"><p id="b3b6" class="pw-post-body-paragraph le lf iq lg b lh li jr lj lk ll ju lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><em class="ni">原载于 2020 年 8 月 30 日</em><a class="ae ma" href="https://spiyer99.github.io/Cyclegan-Simpsonify/" rel="noopener ugc nofollow" target="_blank"><em class="ni">https://spiyer 99 . github . io</em></a><em class="ni">。</em></p></div></div>    
</body>
</html>