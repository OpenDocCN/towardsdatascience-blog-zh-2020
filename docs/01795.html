<html>
<head>
<title>Logistic Regression — Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">逻辑回归—已解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/logistic-regression-explained-593e9ddb7c6c?source=collection_archive---------5-----------------------#2020-02-19">https://towardsdatascience.com/logistic-regression-explained-593e9ddb7c6c?source=collection_archive---------5-----------------------#2020-02-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="829e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">详细的理论解释和 scikit-learn 示例</h2></div><p id="40f4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">逻辑回归是一种监督学习算法，主要用于<strong class="kk iu">二元</strong>分类问题。虽然“回归”与“分类”相矛盾，但这里的重点是“逻辑”一词，指的是在该算法中执行分类任务的<strong class="kk iu">逻辑函数</strong>。逻辑回归是一种简单但非常有效的分类算法，因此它通常用于许多二元分类任务。客户流失、垃圾邮件、网站或广告点击预测是逻辑回归提供强大解决方案的一些领域的例子。</p><p id="e3f3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">逻辑回归的基础是逻辑函数，也称为 sigmoid 函数，它接受任何实数值并将其映射到 0 到 1 之间的值。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi le"><img src="../Images/e62a61ae01f14992a04867d6b289d3d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*d7vTi3MRm5Vx47QW9nbG-g.png"/></div></figure><p id="e96b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">逻辑回归模型将线性方程作为输入，并使用逻辑函数和对数比值来执行二元分类任务。在详细讨论逻辑回归之前，最好先回顾一下范围概率中的一些概念。</p><h1 id="e7fb" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated"><strong class="ak">概率</strong></h1><p id="69c7" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">概率衡量事件发生的可能性。例如，如果我们说“此电子邮件有 90%的可能性是垃圾邮件”:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/4f0af8023cf25e0bc112622c42b42512.png" data-original-src="https://miro.medium.com/v2/resize:fit:446/format:webp/1*_fFJxEzGcARFcgQ3xQzhjw.png"/></div></figure><p id="a6bf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> Odds </strong>是正类和负类的概率之比。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/947fae1af4e5d50bb88007fbd0949592.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/format:webp/1*Ks3oAsXqYuFDMa_Bi4zokw.png"/></div></figure><p id="2525" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">对数赔率</strong>是赔率的对数。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/391f372f094e3a55f48924c0834743cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:818/format:webp/1*Z7JnD04ZKldk55M53mp7Og.png"/></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">概率 vs 赔率 vs 对数赔率</p></figure><p id="b87e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所有这些概念本质上代表相同的度量，但方式不同。在逻辑回归的情况下，使用对数优势。我们将看到为什么对数概率在逻辑回归算法中是首选的原因。</p><p id="7834" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">概率为 0.5 意味着该电子邮件是垃圾邮件还是非垃圾邮件的几率相等。请注意，概率为 0，5 的<strong class="kk iu">对数赔率为 0 </strong>。我们将利用这一点。</p></div><div class="ab cl mq mr hx ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="im in io ip iq"><p id="6728" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们回到 sigmoid 函数，用不同的方式展示它:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi mx"><img src="../Images/8a68db75cc7030de7a0f35a43f187286.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BFxpAPDPSI5FtjHra-yTWg.png"/></div></div></figure><p id="1399" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">取两侧的自然对数:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/b6fd481270e3875d0bba9abcbb05f59d.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*dMLUOo3nnVSu1lPnu9LPiQ.png"/></div></figure><p id="e684" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在等式(1)中，我们可以使用线性等式<strong class="kk iu"> z </strong>来代替 x:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/77cf22f9056cb57d704330ed5a6e505a.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*xxGk9uGaaB22L-shpphRKQ.png"/></div></figure><p id="2859" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">那么等式(1)变成:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/088ee355dafe31d4825b76d6f7500fd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1122/format:webp/1*iGNGynnGhYA5qeAbpKnfeA.png"/></div></figure><p id="bd0d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">假设 y 是正类的概率。如果 z 是 0，那么 y 是 0，5。对于 z 的正值，y 大于 0.5，对于 z 的负值，y 小于 0.5。如果正类的概率大于 0，5(即大于 50%的几率)，我们可以预测结果为正类(1)。否则，结果是一个负类(0)。</p><p id="30ac" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意:在二进制分类中，有许多方法来表示两个类别，如正/负、1/0、真/假。</p><p id="2eda" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下表显示了一些 z 值和相应的 y(概率)值。所有实数都映射在 0 和 1 之间。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/28af06d96af36f7ca65bbdd91cbcfdbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*5raKm6lIT06qd3v53KCteg.png"/></div></figure><p id="5850" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们画出这个函数，我们将得到著名的逻辑回归 s 形图:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/92d354b4625238e4ae08ad7f0f4762a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*kdnGMCPik_GJITfPRI35DA.png"/></div></figure><p id="d037" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">分类问题归结为求解一个线性方程:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/a6bb141e84a06e3511da8041e80736f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*cVhjSy6EOqnivI27x0ypyw.png"/></div></figure><p id="c75b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">函数的参数在训练阶段用最大似然估计算法确定。然后，对于任意给定的自变量(x1，… xn)的值，可以计算出正类的概率。</p><p id="7bff" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以“原样”使用计算出的概率。例如，输出可以是电子邮件是垃圾邮件的概率是 95%,或者客户将点击该广告的概率是 70%。然而，在大多数情况下，概率被用来分类数据点。如果概率大于 50%，则预测为正类(1)。否则，预测为负类(0)。</p><p id="73c9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">到目前为止，除了一个问题，一切似乎都很好。并不总是希望为所有高于 50%的概率值选择正类。关于垃圾邮件的情况，为了将一封邮件归类为垃圾邮件，我们必须几乎确定。由于被检测为垃圾邮件的电子邮件会直接进入垃圾邮件文件夹，我们不希望用户错过重要的电子邮件。除非我们几乎确定，否则电子邮件不会被归类为垃圾邮件。另一方面，当健康相关问题的分类需要我们更加敏感时。即使我们有点怀疑一个细胞是恶性的，我们也不想错过它。因此，作为正类和负类之间的阈值的值取决于问题。好的一面是，逻辑回归允许我们调整这个阈值。</p><p id="e3e4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们设置一个高阈值(即 95%)，几乎所有我们做出的预测都是正确的。然而，我们会错过一些积极的类，并将其标记为消极的。</p><p id="78b8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们设置一个低阈值(即 30%)，我们将正确地预测几乎所有的正类。但是，我们会将一些负面类归类为正面类。</p><p id="ce76" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这两种情况都会影响我们模型的准确性。测量精度的最简单方法是:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/d48382e714be54f7c7765bcc2d2a2ce5.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*2Nc3Z_gxAqaH37BJtcIchg.png"/></div></figure><p id="9db1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，这通常不足以评估分类模型。在一些二元分类任务中，正类和负类之间存在不平衡。想想把肿瘤分为恶性和良性。数据集中的大多数目标值(肿瘤)将为 0(良性)，因为与良性肿瘤相比，恶性肿瘤非常罕见。典型集合将包括 90%以上的良性(0)类。所以如果模型不做任何计算就把所有的例子都预测为 0，准确率在 90%以上。这听起来不错，但在这种情况下没有用。因此，我们需要其他方法来评估分类模型。这些措施是<strong class="kk iu">精确</strong>和<strong class="kk iu">召回</strong>。</p><h1 id="11b4" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated"><strong class="ak">精度和召回</strong></h1><p id="e678" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">首先，我们需要定义一些术语:</p><p id="a293" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">真阳性</strong>:正确预测阳性(1)类</p><p id="bf78" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">假阳性</strong>:将阴性(0)类预测为阳性</p><p id="9244" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">真阴性</strong>:正确预测阴性(0)类</p><p id="9a81" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">假阴性</strong>:将阳性类(0)预测为阴性</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/3a08cfa49f258daee2e9400f9b5cd186.png" data-original-src="https://miro.medium.com/v2/resize:fit:1258/format:webp/1*ENmD0KD4fzuFtaHh5tPIgA.png"/></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">真实值与预测值</p></figure><p id="9957" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">需要进行 TP 或 TN 预测，因此模型旨在最大化 TP 和 TN 值。</p><p id="9dd2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> Precision </strong>衡量当预测为正时，我们的模型有多好。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/27b04a62423e76aa2047cfcf7982234f.png" data-original-src="https://miro.medium.com/v2/resize:fit:510/format:webp/1*Tab_35ofZV5IMUef2KCKig.png"/></div></figure><p id="0527" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">回忆</strong>测量我们的模型在正确预测正类方面有多好。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/7c72fc7ca053127be2e643770f56e4e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:424/format:webp/1*BNAGu2uzsgSggsvvt0aPFA.png"/></div></figure><p id="a8c2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们不能试图同时最大化精确度和召回率，因为它们之间有一个平衡。下图清楚地解释了这种权衡:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi nm"><img src="../Images/18b9e84dfe4cb67e19a867c2630dbc06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/1*q586LVJApiqX_t8UMubAGw.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">精确度和召回率之间的权衡</p></figure><p id="fbb1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这两个表中，有 8 个负(0)类和 11 个正(1)类。模型的预测以及精度和召回率根据阈值而变化。精度和召回值的计算如下:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/46da7d65c569262e588332f8a0a84a82.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*-KcXhunRxKWwEjTR_ex6Hg.png"/></div></figure><p id="2d89" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">提高精度会降低召回率，反之亦然。根据任务的不同，你的目标可以是最大限度地提高精确度或召回率。对于垃圾邮件检测模型，我们试图最大限度地提高精确度，因为我们希望在电子邮件被检测为垃圾邮件时是正确的。我们不想将一封普通的电子邮件标记为垃圾邮件(即误报)。如果假阳性低，则精度高。</p><p id="2a55" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">还有另一种将精确度和召回率结合成一个数字的方法:<strong class="kk iu"> F1_score。</strong>精度和召回率的加权平均值，计算公式如下:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi no"><img src="../Images/c88bc3847d757bf0b7922bcfd2774a88.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/format:webp/1*4C9nZyhtPO_CCF7DuW3OEg.png"/></div></figure><p id="aeba" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于类分布不均匀的问题，F1_score 是比准确性更有用的度量，因为它同时考虑了假阳性和假阴性。</p><p id="1dab" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="np">注:</em> </strong> <em class="np"> L2 正则化默认用于 logistic 回归模型(如岭回归)。正则化由 C 参数控制。由于这种正则化，对逻辑回归模型中的特征(独立变量)进行正则化非常重要。</em></p><h1 id="0985" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated"><strong class="ak"> Scikit-learn 实现</strong></h1><p id="9abd" class="pw-post-body-paragraph ki kj it kk b kl me ju kn ko mf jx kq kr mg kt ku kv mh kx ky kz mi lb lc ld im bi translated">我将使用 scikit-learn 的 datasets 模块下的一个数据集。我将导入数据集和依赖项:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/7d7e64ce1f96108d39826fe303fa6264.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*JMX8QyWutOa0OiN8cNMaWA.png"/></div></figure><p id="09f8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后加载数据集，并分成训练集和测试集:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/7e3a608634e6d562b5ea4b02b058a128.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*m4OzfwOQLasxXFSDMMn9zw.png"/></div></figure><p id="18c1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">创建一个逻辑回归对象，并为其拟合训练数据。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/d8fc4fe6201efafe6173e49ba5141cb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*SqGCeDwF5ztwaXtRl2clVg.png"/></div></figure><p id="fb52" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后预测测试数据集中的目标变量:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/0b102c7822c58bdff9f73f6fed59010b.png" data-original-src="https://miro.medium.com/v2/resize:fit:548/format:webp/1*AdHUeSHsRHj0ZheLZHG_FA.png"/></div></figure><p id="5d0c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Scikit-learn 提供了<strong class="kk iu"> classification_report </strong>函数，可以同时计算精度、召回率和 f1-score。它还在支持列中显示了积极类和消极类的数量。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/33e6eafeeef0838d177a00091e47fa90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*sr5CqzMol1lJUEjDEJogPA.png"/></div></figure><p id="cc09" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">值得注意的是，与这个非常简单的例子相比，现实生活项目中的数据准备、模型创建和评估是极其复杂和耗时的。我只是想给你展示一下模型创建的步骤。在现实生活中，你的大部分时间将花在数据清理和准备上(假设数据收集是由别人完成的)。您还需要花费大量时间对超参数模型的准确性进行多次调整和重新评估。</p></div><div class="ab cl mq mr hx ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="im in io ip iq"><p id="c3f1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢您的阅读。如果您有任何反馈，请告诉我。</p><h1 id="a886" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated"><strong class="ak">我关于机器学习算法的其他帖子</strong></h1><ul class=""><li id="baaf" class="nv nw it kk b kl me ko mf kr nx kv ny kz nz ld oa ob oc od bi translated"><a class="ae oe" rel="noopener" target="_blank" href="/naive-bayes-classifier-explained-50f9723571ed">朴素贝叶斯分类器——解释</a></li><li id="dc90" class="nv nw it kk b kl of ko og kr oh kv oi kz oj ld oa ob oc od bi translated"><a class="ae oe" rel="noopener" target="_blank" href="/support-vector-machine-explained-8d75fe8738fd">支持向量机—解释</a></li><li id="90ed" class="nv nw it kk b kl of ko og kr oh kv oi kz oj ld oa ob oc od bi translated"><a class="ae oe" rel="noopener" target="_blank" href="/decision-tree-and-random-forest-explained-8d20ddabc9dd">决策树和随机森林——解释</a></li><li id="1cb5" class="nv nw it kk b kl of ko og kr oh kv oi kz oj ld oa ob oc od bi translated"><a class="ae oe" rel="noopener" target="_blank" href="/gradient-boosted-decision-trees-explained-9259bd8205af">梯度增强决策树—解释</a></li></ul><h1 id="c623" class="lm ln it bd lo lp lq lr ls lt lu lv lw jz lx ka ly kc lz kd ma kf mb kg mc md bi translated"><strong class="ak">参考文献</strong></h1><ul class=""><li id="5d9e" class="nv nw it kk b kl me ko mf kr nx kv ny kz nz ld oa ob oc od bi translated"><a class="ae oe" href="https://developers.google.com/machine-learning/crash-course/logistic-regression/calculating-a-probability" rel="noopener ugc nofollow" target="_blank">https://developers . Google . com/machine-learning/crash-course/logistic-regression/calculating-a-probability</a></li></ul></div></div>    
</body>
</html>