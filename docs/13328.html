<html>
<head>
<title>LSTM Network and Time-Series Data to Predict Future Prices</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">LSTM 网络和时间序列数据预测未来价格</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/regression-analysis-lstm-network-to-predict-future-prices-b95dc0db6fcc?source=collection_archive---------18-----------------------#2020-09-13">https://towardsdatascience.com/regression-analysis-lstm-network-to-predict-future-prices-b95dc0db6fcc?source=collection_archive---------18-----------------------#2020-09-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="9ef0" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">加密货币和神经网络</h2><div class=""/><div class=""><h2 id="8fc1" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">使用每小时数据的神经网络和时间序列价格预测</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/2a81aa685adddae20c50dac9f1d1b2f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y-3wW71llpBQRo20U9RoQw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</p></figure><p id="233b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><a class="ae md" href="https://sarit-maitra.medium.com/membership" rel="noopener">https://sarit-maitra.medium.com/membership</a></p><p id="6eda" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> <em class="me">来自《走向数据科学》编辑的提示:</em> </strong> <em class="me">虽然我们允许独立作者根据我们的</em> <a class="ae md" rel="noopener" target="_blank" href="/questions-96667b06af5"> <em class="me">规则和指导方针</em> </a> <em class="me">发表文章，但我们不认可每个作者的贡献。你不应该在没有寻求专业建议的情况下依赖一个作者的作品。详见我们的</em> <a class="ae md" rel="noopener" target="_blank" href="/readers-terms-b5d780a700a4"> <em class="me">读者术语</em> </a> <em class="me">。</em></p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="f7e3" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi mm translated">T21:由于时间序列的高波动性以及随机运动的非线性，股票价格的预测是一项相当具有挑战性的工作。这里，我们手头的问题是一个价格预测问题，我们试图预测一个范围内定义的数值(大约从 9000 到 12500)。这个问题符合回归分析框架。我们将使用神经网络架构来尝试解决这里的问题。</p><p id="a53a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们将在这里建立一个深度神经网络，为我们做一些预测，并使用它来预测未来的价格。让我们加载每小时的频率数据。</p><h1 id="074e" class="mv mw it bd mx my mz na nb nc nd ne nf ki ng kj nh kl ni km nj ko nk kp nl nm bi translated">数据加载:</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nn"><img src="../Images/8a05caca29af02b662642bbcc38007cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JgaE2xQB5_1Jw2pEVshUGQ.png"/></div></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi no"><img src="../Images/b777ccb74ecfa2480111c381f528ddd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:474/format:webp/1*286B0QKE66voMPsVxBYVVg.png"/></div></figure><p id="0848" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们总共有 2001 个数据点用美元表示比特币。我们对预测未来日期的收盘价感兴趣。</p><p id="7929" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">当我们看到一个时间序列时，我们总是想知道当前时间步长的值是否会影响下一个时间步长。</p><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="7356" class="nu mw it nq b gy nv nw l nx ny">plt.figure(figsize = (15,5))<br/>plt.plot(btc.close)<br/>plt.title('BTC Close price (Hourly frequency)')<br/>plt.xlabel ('Date_time')<br/>plt.ylabel ('Price (US$')<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nz"><img src="../Images/4875471b64fb98ec7910f79e1e424966.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-LNRLHKJTFxiEUfL3602cA.png"/></div></div></figure><p id="13cc" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这里我们将使用 LSTM 网络，它有能力捕捉序列中的长期相关性(例如，今天的价格和两周前的价格之间的相关性)。此外，这里使用的单变量系列仅考虑该系列的接近价格。</p><p id="b8b1" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们使用 MinMax scaler 将价格数据标准化。</p><h2 id="fd16" class="nu mw it bd mx oa ob dn nb oc od dp nf lq oe of nh lu og oh nj ly oi oj nl iz bi translated"><strong class="ak">数据缩放:</strong></h2><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="7cc8" class="nu mw it nq b gy nv nw l nx ny">scaler = MinMaxScaler() <br/><br/>close_price = btc['close'].values.reshape(-1, 1) </span><span id="0780" class="nu mw it nq b gy ok nw l nx ny"># The scaler expects the data to be shaped as (x, y)<br/>scaled_close = scaler.fit_transform(close_price)<br/>scaled_close = scaled_close[~np.isnan(scaled_close)] </span><span id="099e" class="nu mw it nq b gy ok nw l nx ny"># reshaping data after removing NaNs<br/>scaled_close = scaled_close.reshape(-1, 1) <br/># reshaping data after removing NaNs</span></pre><h2 id="5094" class="nu mw it bd mx oa ob dn nb oc od dp nf lq oe of nh lu og oh nj ly oi oj nl iz bi translated">LSTM 的数据处理:</h2><p id="60a8" class="pw-post-body-paragraph lh li it lj b lk ol kd lm ln om kg lp lq on ls lt lu oo lw lx ly op ma mb mc im bi translated">LSTMs 需要三维数据形状；所以我们需要把数据拆分成:[batch_size，sequence_length，n_features]的形状。我们还想保存一些数据用于测试。</p><p id="c17e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们建立一些序列。序列的工作方式类似于向前行走验证方法，其中将定义初始序列长度，随后将向右移动一个位置以创建另一个序列。这样，重复该过程，直到使用了所有可能的位置。</p><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="561f" class="nu mw it nq b gy nv nw l nx ny">SEQ_LEN = 100 <br/># creating a sequence of 100 hours at position 0.<br/>def to_sequences(data, seq_len):<br/>d = []<br/>for index in range(len(data) - seq_len):<br/>d.append(data[index: index + seq_len])<br/>return np.array(d)<br/>def preprocess(data_raw, seq_len, train_split):<br/>data = to_sequences(data_raw, seq_len)<br/>num_train = int(train_split * data.shape[0])<br/>X_train = data[:num_train, :-1, :]<br/>y_train = data[:num_train, -1, :]</span><span id="bbde" class="nu mw it nq b gy ok nw l nx ny">X_test = data[num_train:, :-1, :]<br/>y_test = data[num_train:, -1, :]</span><span id="edab" class="nu mw it nq b gy ok nw l nx ny">return X_train, y_train, X_test, y_test</span><span id="871c" class="nu mw it nq b gy ok nw l nx ny">"""Walk forward validation: <br/>Initial SEQ_LEN is defined above, so, walk forward will be shifting one position to the right and create another sequence.<br/>The process is repeated until all possible positions are used."""</span><span id="32d1" class="nu mw it nq b gy ok nw l nx ny">X_train, y_train, X_test, y_test = preprocess(scaled_close, SEQ_LEN, train_split = 0.95) <br/># 5% of the data saved for testing.</span><span id="6c9c" class="nu mw it nq b gy ok nw l nx ny">print(X_train.shape, X_test.shape)</span><span id="d0f5" class="nu mw it nq b gy ok nw l nx ny">"""Our model will use 1805 sequences representing 99 hours of Bitcoin price changes each for training. We shall be predicting the price for 96 hours in the future"""</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/0416b771d2bfbaeb721cbdde549ce5e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:552/format:webp/1*zFAylgHoj4yoI-VoQ9SiLQ.png"/></div></figure><h2 id="73fb" class="nu mw it bd mx oa ob dn nb oc od dp nf lq oe of nh lu og oh nj ly oi oj nl iz bi translated">偏差方差:</h2><p id="af30" class="pw-post-body-paragraph lh li it lj b lk ol kd lm ln om kg lp lq on ls lt lu oo lw lx ly op ma mb mc im bi translated">如果模型在训练和测试数据集中的误差都很高，这将表明模型对两个数据集都拟合不足，并且具有很高的偏差。如果模型在训练集中具有低误差，但在测试集中具有高误差，这表示高方差，因为模型未能推广到第二组数据。</p><p id="635b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">因此，目标是生成一个在训练和测试数据集中总体误差较低的模型，并平衡正确的偏差和方差水平。</p><h1 id="069a" class="mv mw it bd mx my mz na nb nc nd ne nf ki ng kj nh kl ni km nj ko nk kp nl nm bi translated">构建 LSTM 模型:</h1><p id="9120" class="pw-post-body-paragraph lh li it lj b lk ol kd lm ln om kg lp lq on ls lt lu oo lw lx ly op ma mb mc im bi translated">我们将创建一个 3 层 LSTM 网络，使用 20%的退出率来控制训练期间的过拟合。</p><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="dc76" class="nu mw it nq b gy nv nw l nx ny">DROPOUT = 0.2 <br/># 20% Dropout is used to control over-fitting during training<br/>WINDOW_SIZE = SEQ_LEN - 1<br/>model = keras.Sequential()</span><span id="1f51" class="nu mw it nq b gy ok nw l nx ny"># Input layer<br/>model.add(Bidirectional(LSTM(WINDOW_SIZE, return_sequences=True), input_shape=(WINDOW_SIZE, X_train.shape[-1])))</span><span id="a5ce" class="nu mw it nq b gy ok nw l nx ny">"""Bidirectional RNNs allows to train on the sequence data in forward and backward direction."""</span><span id="7b01" class="nu mw it nq b gy ok nw l nx ny">model.add(Dropout(rate=DROPOUT))</span><span id="5624" class="nu mw it nq b gy ok nw l nx ny"># 1st Hidden layer<br/>model.add(Bidirectional(LSTM((WINDOW_SIZE * 2), return_sequences = True)))<br/>model.add(Dropout(rate=DROPOUT))</span><span id="df63" class="nu mw it nq b gy ok nw l nx ny"># 2nd Hidden layer<br/>model.add(Bidirectional(LSTM(WINDOW_SIZE, return_sequences=False)))</span><span id="3e22" class="nu mw it nq b gy ok nw l nx ny"># output layer<br/>model.add(Dense(units=1))</span><span id="a944" class="nu mw it nq b gy ok nw l nx ny">model.add(Activation('linear'))</span><span id="07fd" class="nu mw it nq b gy ok nw l nx ny">"""Output layer has a single neuron (predicted Bitcoin price). We use Linear activation function which activation is proportional to the input."""</span><span id="fd56" class="nu mw it nq b gy ok nw l nx ny">BATCH_SIZE = 64<br/>model.compile(loss='mean_squared_error', optimizer='adam')<br/>history = model.fit(X_train, y_train, epochs=50, batch_size=BATCH_SIZE, shuffle=False, validation_split=0.1) <br/># shuffle not advisable during training of Time Series</span></pre><p id="f166" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以在训练期间使用回调选项来防止我们的模型过度拟合；我没有使用过回叫，但在模型拟合阶段也可以使用。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi or"><img src="../Images/a55b7cf2fb96236046bf6cf49783780c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K_S5WB71SFDoHFIDwhPq7g.png"/></div></div></figure><h2 id="e74d" class="nu mw it bd mx oa ob dn nb oc od dp nf lq oe of nh lu og oh nj ly oi oj nl iz bi translated">模型评估:</h2><p id="ec56" class="pw-post-body-paragraph lh li it lj b lk ol kd lm ln om kg lp lq on ls lt lu oo lw lx ly op ma mb mc im bi translated">了解培训过程的一个简单方法是查看培训和验证损失。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi os"><img src="../Images/0cd42b382c7333ad3132d8249bc89b63.png" data-original-src="https://miro.medium.com/v2/resize:fit:904/format:webp/1*OVW0Yntz5LyKgaAGP4sl9A.png"/></div></figure><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="1218" class="nu mw it nq b gy nv nw l nx ny"># history for loss<br/>plt.figure(figsize = (10,5))<br/>plt.plot(history.history['loss'])<br/>plt.plot(history.history['val_loss'])<br/>plt.title('model loss')<br/>plt.ylabel('loss')<br/>plt.xlabel('epoch')<br/>plt.legend(['train', 'test'], loc='upper left')<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ot"><img src="../Images/faf77ce4a515a66735ca1af24bb0f789.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ikC80-tkGBeDkicBLkpm7w.png"/></div></div></figure><p id="8707" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在这里，我们可以看到训练错误和验证错误都有所改善。</p><h2 id="e0b5" class="nu mw it bd mx oa ob dn nb oc od dp nf lq oe of nh lu og oh nj ly oi oj nl iz bi translated">测试:</h2><p id="2ed4" class="pw-post-body-paragraph lh li it lj b lk ol kd lm ln om kg lp lq on ls lt lu oo lw lx ly op ma mb mc im bi translated">我们还剩下一些额外的数据用于测试。让我们使用这些数据从模型中获得预测，以验证我们的模型的拟合度。</p><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="b64e" class="nu mw it nq b gy nv nw l nx ny"># prediction on test data<br/>y_pred = model.predict(X_test) <br/># invert the test to original values<br/>y_test_inverse = DataFrame(scaler.inverse_transform(y_test)) <br/># assigning datetime<br/>y_test_inverse.index = btc.index[-len(y_test):] <br/>print('Test data:',)<br/>print(y_test_inverse.tail(3)); print();</span><span id="898d" class="nu mw it nq b gy ok nw l nx ny"># invert the prediction to understandable values<br/>y_pred_inverse = DataFrame(scaler.inverse_transform(y_pred)) <br/># assigning datetime<br/>y_pred_inverse.index = y_test_inverse.index <br/>print('Prediction data:',)<br/>print(y_pred_inverse.tail(3))</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/9e229fe6573b33f9cee34d0e56a57c8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*EziSM1RHCyd3OOO4koNg5Q.png"/></div></figure><h2 id="1ebc" class="nu mw it bd mx oa ob dn nb oc od dp nf lq oe of nh lu og oh nj ly oi oj nl iz bi translated">准确性指标:</h2><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="829e" class="nu mw it nq b gy nv nw l nx ny">print(f'MAE {mean_absolute_error(y_test, y_pred)}')<br/>print(f'MSE {mean_squared_error(y_test, y_pred)}')<br/>print(f'RMSE {np.sqrt(mean_squared_error(y_test, y_pred))}')<br/>print(f'R2 {r2_score(y_test, y_pred)}')</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ov"><img src="../Images/be68cdddba5de6dba29b564f2c8da9a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*wySVcArgoY7FY9222IIyqA.png"/></div></div></figure><p id="5cd0" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">RMSE 允许我们处罚远离平均值的分数。虽然错误分数很低，但看看 R2 分数，这里肯定有改进的空间。可以调整模型以获得更好的输出。</p><h2 id="6f46" class="nu mw it bd mx oa ob dn nb oc od dp nf lq oe of nh lu og oh nj ly oi oj nl iz bi translated">性能可视化:</h2><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="59a0" class="nu mw it nq b gy nv nw l nx ny">plt.figure(figsize = (15,5))<br/>plt.plot(y_test_inverse)<br/>plt.plot(y_pred_inverse)<br/>plt.title('Actual vs Prediction plot (Price prediction model)')<br/>plt.ylabel('price')<br/>plt.xlabel('date')<br/>plt.legend(['actual', 'prediction'], loc='upper left')<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ow"><img src="../Images/f0687cd721d981c0f15f2dfe4485baed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yHLLOR39ity0nGQL-DHVjQ.png"/></div></div></figure><p id="5434" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">看起来我们的基本和简要模型已经能够捕捉数据的一般模式。然而，它未能捕捉随机运动，这可能是一个好迹象，因为我们可以说，它概括得很好。</p><h1 id="4fec" class="mv mw it bd mx my mz na nb nc nd ne nf ki ng kj nh kl ni km nj ko nk kp nl nm bi translated">结论和未来范围:</h1><p id="64c0" class="pw-post-body-paragraph lh li it lj b lk ol kd lm ln om kg lp lq on ls lt lu oo lw lx ly op ma mb mc im bi translated">预测股票市场回报是一项具有挑战性的任务，因为股票价值不断变化，取决于形成复杂模式的多个参数。</p><p id="2e8b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">未来的方向可能是:</p><ol class=""><li id="2a9b" class="ox oy it lj b lk ll ln lo lq oz lu pa ly pb mc pc pd pe pf bi translated">分析不同加密货币之间的相关性，以及这将如何影响我们的模型的性能。</li><li id="863c" class="ox oy it lj b lk pg ln ph lq pi lu pj ly pk mc pc pd pe pf bi translated">使用技术分析添加特征以检查模型性能。</li><li id="6a08" class="ox oy it lj b lk pg ln ph lq pi lu pj ly pk mc pc pd pe pf bi translated">添加基本面分析的特征，检查这些特征如何影响模式。</li><li id="facb" class="ox oy it lj b lk pg ln ph lq pi lu pj ly pk mc pc pd pe pf bi translated">添加来自社交网络(如 twitter 和新报告)的情感分析，以检查模型性能。</li><li id="2b53" class="ox oy it lj b lk pg ln ph lq pi lu pj ly pk mc pc pd pe pf bi translated">GRU 网络也可以尝试不同的激活方式，如“软签名”来检查性能。</li></ol><p id="0781" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这种性质的多变量分析需要在特征工程、数据分析、模型训练等方面投入大量的精力和时间。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/fc0f40fa911c3fef34b1ec483c6d6de4.png" data-original-src="https://miro.medium.com/v2/resize:fit:878/format:webp/1*J7qvYXgw71whDaPmqbqjHg.png"/></div></figure><p id="c59e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">接我这里</strong><a class="ae md" href="https://www.linkedin.com/in/saritmaitra/" rel="noopener ugc nofollow" target="_blank"><strong class="lj jd"><em class="me"/></strong></a><strong class="lj jd">。</strong></p><p id="d3f9" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><em class="me">参考文献:</em></p><ol class=""><li id="7ebb" class="ox oy it lj b lk ll ln lo lq oz lu pa ly pb mc pc pd pe pf bi translated"><em class="me"> Vijh，m .，Chandola，d .，Tikkiwal，V. A .，&amp; Kumar，A. (2020)。使用机器学习技术预测股票收盘价。Procedia 计算机科学，167，599–606。</em></li><li id="7afc" class="ox oy it lj b lk pg ln ph lq pi lu pj ly pk mc pc pd pe pf bi translated">瓦内琳·瓦尔科夫(2015 年)。黑客机器学习指南</li></ol><p id="79f0" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">注意:<em class="me">此处描述的程序是实验性的，在用于任何商业目的时都应谨慎使用。所有此类使用风险自负。</em></p></div></div>    
</body>
</html>