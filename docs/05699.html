<html>
<head>
<title>Deep Learning with Julia, Flux.jl story</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">与 Julia 深度学习，Flux.jl story</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-with-julia-flux-jl-story-7544c99728ca?source=collection_archive---------17-----------------------#2020-05-12">https://towardsdatascience.com/deep-learning-with-julia-flux-jl-story-7544c99728ca?source=collection_archive---------17-----------------------#2020-05-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7346" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">步入淡水</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/337364d13203647ea57d9528276ecd67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-wRaXRzZBPJOh37p"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@tommy_c137?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">富山武广</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="ac68" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="9d94" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">数据科学领域出现了一个新的挑战者:Julia。它速度快，易于输入，有很好的文档和社区。</p><p id="517a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">但它缺乏例子和教程来学习，所以在这篇文章中，我们将建立一个经典的:MNIST 分类器使用卷积神经网络。</p><h2 id="134d" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">是给谁的？</h2><p id="5fd6" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">对于那些对深度学习略知一二，但对尝试一门新语言充满好奇的人来说，我将把重点放在对初学者更友好的风格上。我将尝试解释 Julia 语法与 Python 的不同之处。</p><h2 id="5c1e" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">我们将使用什么？</h2><p id="615a" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Flux.jl .是 Julia 主要的深度学习库之一。你可以在这里查看一些例子<a class="ae ky" href="https://github.com/FluxML/model-zoo" rel="noopener ugc nofollow" target="_blank"/>，尽管它们对初学者来说有些吓人。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/98bd97137ea5100d62908e6f1befa36b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*EfvOq4ZtD7RfV7-_.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自 flux 主页的官方 logo:<a class="ae ky" href="https://fluxml.ai/" rel="noopener ugc nofollow" target="_blank">https://fluxml.ai/</a></p></figure><h2 id="5c95" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">我为什么要在乎？</h2><p id="37ac" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">虽然 PyTorch 或 TensorFlow 已经为 Python 的深度学习提供了一个很好的生态系统，但它们大多是用 C++甚至 Cuda 编写的，以获得出色的 GPU 性能。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nf"><img src="../Images/cef079d00894eea6e8f5e91f470cd676.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hw5ZopX0QOZ8m9LOquOoKA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">PyTorch GitHub 页面的语言统计</p></figure><p id="3589" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">因此，如果你想写一些自定义代码来做一点试验，这可能会变得相当复杂<em class="ng">(尽管在其中编写生产代码可能仍然是一个更好的主意)</em>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/632414d5d471dbc174cec0bd18a7e82a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LyhaT0vAsEq4WlnOd8Comw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自 TensorFlow GitHub 页面的语言统计</p></figure><p id="a606" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">另一方面，朱莉娅从一开始就为你提供了速度。所以如果你想写一些自定义的损失函数，你可以在 Julia 中完成。将它与很少的努力结合起来，放在 GPU 上并清除源代码，即使对初学者来说，你也有相当吸引人的东西。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/efb124d3315982e26b9c2e0b9e9576ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I3OKJncoCmP5bI4yV02Zrw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Flux GitHub 页面的语言统计</p></figure></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="4e4a" class="kz la it bd lb lc nq le lf lg nr li lj jz ns ka ll kc nt kd ln kf nu kg lp lq bi translated">包和数据集</h1><p id="923b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">导入包非常简单。为了更简单的数据准备，我们将导入<strong class="lt iu">通量</strong> <em class="ng">(当然)</em><strong class="lt iu">统计</strong>和<strong class="lt iu"> MLDatasets </strong>。</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="74d5" class="ms la it nw b gy oa ob l oc od">using Flux<br/>using Flux: Data.DataLoader<br/>using Flux: onehotbatch, onecold, crossentropy<br/>using Flux: @epochs<br/>using Statistics<br/>using MLDatasets</span><span id="32c0" class="ms la it nw b gy oe ob l oc od"># Load the data<br/>x_train, y_train = MLDatasets.MNIST.traindata()<br/>x_valid, y_valid = MLDatasets.MNIST.testdata()</span><span id="d597" class="ms la it nw b gy oe ob l oc od"># Add the channel layer<br/>x_train = Flux.unsqueeze(x_train, 3)<br/>x_valid = Flux.unsqueeze(x_valid, 3)</span><span id="9632" class="ms la it nw b gy oe ob l oc od"># Encode labels<br/>y_train = onehotbatch(y_train, 0:9)<br/>y_valid = onehotbatch(y_valid, 0:9)</span><span id="9d6e" class="ms la it nw b gy oe ob l oc od"># Create the full dataset<br/>train_data = DataLoader(x_train, y_train, batchsize=128)</span></pre><p id="8a7b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><em class="ng">(亲提示:默认情况下 Julia 会打印该函数的输出。您可以抑制它，但键入“；”结束)</em></p><p id="5a05" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">Flux 将期望我们的图像数据按照 WHCN 顺序<em class="ng">(宽度，高度，#通道，批量)</em>，所以我们必须添加一个通道层。幸运的是，已经有了一个名为<code class="fe of og oh nw b">unsqueeze</code>的函数。</p><p id="4a08" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">稍后我们将使用交叉熵损失，因此我们还需要使用<code class="fe of og oh nw b">onehotbatch</code>对标签进行编码。</p><h1 id="3edc" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">模型</h1><h2 id="7fb2" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">层</h2><p id="b7bb" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们的模型将有 8 层。其中 4 个将是 Relu 的卷积，然后我们将意味着池化，展平它，最后用 softmax 填充到一个线性层中。</p><p id="57ea" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们可以使用<code class="fe of og oh nw b">Chain</code>函数将所有东西“链接”在一起</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="8d9e" class="ms la it nw b gy oa ob l oc od">model = Chain(<br/>    # 28x28 =&gt; 14x14<br/>    Conv((5, 5), 1=&gt;8, pad=2, stride=2, relu),<br/>    # 14x14 =&gt; 7x7<br/>    Conv((3, 3), 8=&gt;16, pad=1, stride=2, relu),<br/>    # 7x7 =&gt; 4x4<br/>    Conv((3, 3), 16=&gt;32, pad=1, stride=2, relu),<br/>    # 4x4 =&gt; 2x2<br/>    Conv((3, 3), 32=&gt;32, pad=1, stride=2, relu),<br/>    <br/>    # Average pooling on each width x height feature map<br/>    GlobalMeanPool(),<br/>    flatten,<br/>    <br/>    Dense(32, 10),<br/>    softmax)</span></pre><p id="d116" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">每个卷积层获取一个图像，并从中创建通道层。因此，下一个卷积层将采取一个更小的图像，其中有更多的通道。我们还在第一层应用填充，并在所有层上应用步长 2。</p><p id="2273" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果你需要复习一下下面的 gif 和这篇文章。对于内核来说，填充基本上使我们的图像更大，而 stride 定义了它需要多大的步长。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/e2b440e64b7d0781ebe5e23515a640d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/0*Yl5fULOdEgtIsc1G.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Vincent Dumoulin，Francesco vision—<a class="ae ky" href="https://arxiv.org/abs/1603.07285" rel="noopener ugc nofollow" target="_blank">深度学习卷积算法指南</a></p></figure><p id="907e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">然后是平均池层。它从卷积层获取特征图，并从每个通道获取平均值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/c6e561996210cb1c78e143bcb1df4b4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4ge5GA_awYpUPrH_oZayiQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由作者提供</p></figure><p id="a17f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">但是在我们将数据进一步输入到线性层之前，我们必须去掉称为<em class="ng">单线态</em>的 1x1 维度。这就是扁平化层的目的。</p><p id="70a6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果你想知道每一层的尺寸是如何变化的，我会在文章末尾提供一个 jupyter 笔记本的链接。</p><p id="b292" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在是我们可以将数据输入模型并获得预测的时候了。它们还没有任何用处，但这是检查我们是否做对了所有事情的好方法。要解码预测，使用<code class="fe of og oh nw b">onecold</code>函数。</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="7bc7" class="ms la it nw b gy oa ob l oc od"># Getting predictions<br/>ŷ = model(x_train)<br/># Decoding predictions<br/>ŷ = onecold(ŷ)<br/>println("Prediction of first image: $(ŷ[1])")</span></pre><h2 id="eb10" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">损失函数、优化器和指标</h2><p id="be4d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">现在是时候选择如何更新模型参数以及如何检查其性能了。</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="cc85" class="ms la it nw b gy oa ob l oc od">accuracy(ŷ, y) = mean(onecold(ŷ) .== onecold(y))<br/>loss(x, y) = Flux.crossentropy(model(x), y)</span><span id="4404" class="ms la it nw b gy oe ob l oc od"># learning rate<br/>lr = 0.1<br/>opt = Descent(lr)</span><span id="1df8" class="ms la it nw b gy oe ob l oc od">ps = Flux.params(model)</span></pre><p id="ae5d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们有标准的精度度量和通量的交叉熵损失。对于优化器，我们将选择学习率为 0.1 的简单梯度下降。当然还有更好的选择，比如<code class="fe of og oh nw b">Momentum</code>或者<code class="fe of og oh nw b">ADAM</code>，但是对于一个简单的向导来说已经足够了。</p><p id="71ee" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">例如，Flux 的分化库<em class="ng"> Zygote </em>的工作方式与 PyTorch 中使用的有些不同。它本身是值得研究的，但是现在我们只需要知道我们必须从我们的模型中获取参数。</p><p id="b6dd" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为此，我们简单地调用<code class="fe of og oh nw b">params</code>函数，将我们的模型作为输入。</p><h1 id="7a17" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">培养</h1><p id="f224" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">现在我们在等待的事情是:训练模型。</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="ecac" class="ms la it nw b gy oa ob l oc od">number_epochs = 10<br/>@epochs number_epochs Flux.train!(loss, ps, train_data, opt)</span><span id="77e1" class="ms la it nw b gy oe ob l oc od">accuracy(model(x_train), y_train)</span></pre><p id="88a3" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">就是这样。这就是训练。我们用损失、参数、数据和优化器调用<code class="fe of og oh nw b">train!</code>函数。我们使用<code class="fe of og oh nw b">@epochs</code>宏，指定我们希望它执行的次数<em class="ng">(默认情况下它只执行一次)</em>。</p><h2 id="fbde" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">现在来看看朱莉娅的更多方面。</h2><p id="dd68" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">“！”在函数名中，通常意味着函数会产生副作用或者就地执行<em class="ng">(如果在 Python 中使用 numpy)</em>。</p><p id="bc47" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">“@”位于宏之前。这是通向所谓元编程的大门。他们改变了函数的代码，所以你可以将它与 Pyton <em class="ng">中的 decorators 进行比较(尽管严格来说它们不是同一个东西)</em>。</p><h2 id="7262" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">更深入</h2><p id="e3bf" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">现在让我们自己编写训练循环。最好的一点是，如果我们比较执行这两种方法所花的时间，会发现它们实际上是相似的。</p><p id="827c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">从文档中:</p><blockquote class="ok ol om"><p id="3252" class="lr ls ng lt b lu mn ju lw lx mo jx lz on mp mc md oo mq mg mh op mr mk ml mm im bi translated"><code class="fe of og oh nw b">Flux.train!</code>函数可以非常方便，特别是对于简单的问题。回调的使用也非常灵活。但是对于一些问题来说，编写自己的定制训练循环要干净得多。</p></blockquote><p id="cf37" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">所以，我们就这么做吧。</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="22a3" class="ms la it nw b gy oa ob l oc od">for batch in train_data<br/>    <br/>    gradient = Flux.gradient(ps) do<br/>      # Remember that inside the loss() is the model<br/>      # `...` syntax is for unpacking data<br/>      training_loss = loss(batch...)<br/>      return training_loss<br/>    end<br/>    <br/>    Flux.update!(opt, ps, gradient)<br/>end</span></pre><p id="e326" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们循环训练数据集<em class="ng">(来自数据加载器)</em>。然后，我们使用<code class="fe of og oh nw b">do</code>关键字将损失计算映射到梯度函数。然后我们用优化器、参数和保存的梯度调用<code class="fe of og oh nw b">update!</code>，就完成了。</p><h2 id="5e44" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">更深</h2><p id="edcc" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">哦，你不喜欢<code class="fe of og oh nw b">update!</code>功能？没问题。让我们编写自己的循环。</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="97bd" class="ms la it nw b gy oa ob l oc od">for x in ps<br/>    x .-= lr .* gradient[x] # Update parameters<br/>end</span></pre><p id="1532" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">每个符号前的<code class="fe of og oh nw b">.</code>告诉 Julia 按元素进行操作。</p><p id="9618" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果你仔细查看 Flux 的源代码，你会发现，仅仅在两个函数中。不相信我？自己看<a class="ae ky" href="https://github.com/FluxML/Flux.jl/blob/7a32a703f0f2842dda73d4454aff5990ade365d5/src/optimise/train.jl#L6-L10" rel="noopener ugc nofollow" target="_blank">这里</a>和<a class="ae ky" href="https://github.com/FluxML/Flux.jl/blob/7a32a703f0f2842dda73d4454aff5990ade365d5/src/optimise/optimisers.jl" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="4988" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这就是朱莉娅最吸引人的地方。它会很快，并且已经为 GPU 做好了准备。厉害！</p><h2 id="93a8" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">甚至更深</h2><p id="4e4f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">想要更多吗？让我们创建一些回调。它们本质上是在训练时将被调用的函数。</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="b3cc" class="ms la it nw b gy oa ob l oc od">loss_vector = Vector{Float64}()<br/>callback() = push!(loss_vector, loss(x_train, y_train))</span><span id="4602" class="ms la it nw b gy oe ob l oc od">Flux.train!(loss, ps, train_data, opt, cb=callback)</span></pre><p id="359a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">你可以把<code class="fe of og oh nw b">push!</code>当作 numpy 的一个<code class="fe of og oh nw b">append</code>函数。</p><p id="d672" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在，我们有了一个列表，列出了每批数据之后的损失<em class="ng">(请记住，这是针对更大数据集的大量计算)</em>。</p><h1 id="d9cb" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">包扎</h1><p id="fe52" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">现在你知道如何在朱莉娅使用通量。您甚至知道如何为您的模型编写高效的定制函数。花了多长时间？不多，不是吗？</p><p id="025b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">毫无疑问，Julia 和 Flux 的时代还很早，但是如果你喜欢这种语言和这些包的编写方式，我认为值得尝试一下。</p><p id="317e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">毕竟，如果我们有一些与他人交流的经验，我们都可以用自己喜欢的语言写出更好的代码。</p><p id="71af" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">你可以在这里看到一个 jupyter 笔记本，里面有所有的代码。</p><p id="9e99" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">来和我一起在<a class="ae ky" href="https://twitter.com/Jarartur" rel="noopener ugc nofollow" target="_blank">推特</a>上闲逛吧，感谢你的阅读！</p></div></div>    
</body>
</html>