<html>
<head>
<title>How to Train A Custom Object Detection Model with YOLO v5</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用YOLO v5训练自定义对象检测模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-train-a-custom-object-detection-model-with-yolo-v5-917e9ce13208?source=collection_archive---------0-----------------------#2020-06-15">https://towardsdatascience.com/how-to-train-a-custom-object-detection-model-with-yolo-v5-917e9ce13208?source=collection_archive---------0-----------------------#2020-06-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5d2e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">注:我们这里也公布了<a class="ae kf" href="https://blog.roboflow.ai/how-to-train-yolov5-on-a-custom-dataset/" rel="noopener ugc nofollow" target="_blank">如何训练YOLOv5 </a>。在本帖中，我们将介绍如何训练<a class="ae kf" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank">新的YOLO v5模型</a>为您的定制用例识别您的定制对象。</h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi kg"><img src="../Images/63cf8a1299d3c1cd989400e8aebcd047.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*T5YHyjej1k3o8WOZeCJNsw.gif"/></div><p class="ko kp gj gh gi kq kr bd b be z dk translated">我们的模型在预设的环境下进行推理。让我们看看如何让它识别<strong class="bd ks">任何物体</strong>！</p></figure><p id="fa01" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">我们将介绍以下材料，您可以在创建对象检测模型的过程中随时加入:</p><ul class=""><li id="c2cb" class="lp lq iq kv b kw kx kz la lc lr lg ls lk lt lo lu lv lw lx bi translated"><a class="ae kf" href="https://blog.roboflow.com/the-ultimate-guide-to-object-detection/" rel="noopener ugc nofollow" target="_blank">物体检测概述</a></li><li id="f42d" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated">关于YOLO v5车型</li><li id="5cf1" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated">收集我们的训练图像</li><li id="3068" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated">注释我们的训练图像</li><li id="93bf" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated">安装YOLO版本5依赖项</li><li id="2ea0" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated">下载自定义YOLO v5对象检测数据</li><li id="0ca6" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated">定义YOLO v5模型配置和架构</li><li id="bc4a" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated">训练自定义YOLO v5检测器</li><li id="b35a" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated">评估YOLO v5的性能</li><li id="ac6b" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated">对测试图像运行YOLO v5推理</li><li id="33da" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated">导出保存的YOLO v5权重以供将来推断</li></ul><h2 id="0789" class="md me iq bd mf mg mh dn mi mj mk dp ml lc mm mn mo lg mp mq mr lk ms mt mu mv bi translated">本教程中的资源</h2><ul class=""><li id="a2ad" class="lp lq iq kv b kw mw kz mx lc my lg mz lk na lo lu lv lw lx bi translated"><a class="ae kf" href="https://colab.research.google.com/drive/1gDZ2xcTOgR39tGGs-EZ6i3RTs16wmzZQ" rel="noopener ugc nofollow" target="_blank">带有YOLOv5训练代码的Colab笔记本</a>(我建议同时打开这个)</li><li id="eae7" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated">如果你想要一个视频演示，请附上YOLOv5 YouTube视频。</li><li id="88fe" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated"><a class="ae kf" href="https://public.roboflow.ai/object-detection/bccd" rel="noopener ugc nofollow" target="_blank">公共血细胞检测数据集</a></li></ul><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi nb"><img src="../Images/d8d592d66de81536a92b5a3b1650584b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*aY1YI8kvMxGZL0mM.png"/></div></div><p class="ko kp gj gh gi kq kr bd b be z dk translated">我们的训练数据地面真相— <a class="ae kf" href="https://public.roboflow.ai/object-detection/bccd" rel="noopener ugc nofollow" target="_blank">大众BCCD </a></p></figure><h1 id="f522" class="ng me iq bd mf nh ni nj mi nk nl nm ml jw nn jx mo jz no ka mr kc np kd mu nq bi translated">目标检测综述</h1><p id="cf35" class="pw-post-body-paragraph kt ku iq kv b kw mw jr ky kz mx ju lb lc nr le lf lg ns li lj lk nt lm ln lo ij bi translated"><a class="ae kf" href="https://blog.roboflow.com/the-ultimate-guide-to-object-detection/" rel="noopener ugc nofollow" target="_blank">目标检测</a>由于其通用性，是最流行的计算机视觉模型之一。正如我在以前的文章<a class="ae kf" rel="noopener" target="_blank" href="/what-is-mean-average-precision-map-in-object-detection-8f893b48afd3">分解地图</a>中所写:</p><blockquote class="nu nv nw"><p id="ffea" class="kt ku nx kv b kw kx jr ky kz la ju lb ny ld le lf nz lh li lj oa ll lm ln lo ij bi translated"><a class="ae kf" href="https://blog.roboflow.com/the-ultimate-guide-to-object-detection/" rel="noopener ugc nofollow" target="_blank">对象检测模型</a>试图识别图像中相关对象的存在，并将这些对象分类到相关类别中。例如，在医学图像中，我们希望能够计数血液中的红细胞(RBC)、白细胞(WBC)和血小板的数量。为了自动做到这一点，我们需要训练一个对象检测模型来识别这些对象中的每一个，并正确地对它们进行分类。</p></blockquote><p id="7ea7" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">我们的对象检测器模型将把包围盒回归从连接网络的不同区域中的对象分类中分离出来。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi ob"><img src="../Images/73050a944b276d3a2b51ddd7ee147183.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6Y7__b4ZpcQfmK7IvQjqNQ.png"/></div></div><p class="ko kp gj gh gi kq kr bd b be z dk translated"><a class="ae kf" href="https://blog.roboflow.com/the-ultimate-guide-to-object-detection/" rel="noopener ugc nofollow" target="_blank">对象检测</a>首先找到相关对象周围的方框，然后将每个对象分类到相关的类别类型中</p></figure><h1 id="b08d" class="ng me iq bd mf nh ni nj mi nk nl nm ml jw nn jx mo jz no ka mr kc np kd mu nq bi translated">关于YOLOv5型号</h1><p id="9b24" class="pw-post-body-paragraph kt ku iq kv b kw mw jr ky kz mx ju lb lc nr le lf lg ns li lj lk nt lm ln lo ij bi translated">YOLOv5是YOLO系列的最新产品。YOLO最初是作为第一个将包围盒预测和对象分类结合到单个端到端可区分网络中的对象检测模型而引入的。它是在一个叫做<a class="ae kf" href="https://github.com/AlexeyAB/darknet" rel="noopener ugc nofollow" target="_blank"> Darknet </a>的框架中编写和维护的。YOLOv5是第一个用PyTorch框架编写的YOLO模型，它更加轻量级和易于使用。也就是说，YOLOv5没有对YOLOv4中的网络进行重大的架构更改，并且在公共基准COCO数据集上的表现也不如YOLOv4。</p><p id="9cee" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">我在这里向您推荐YOLOv5，因为我相信它更容易上手，并且在进入部署时可以为您提供更快的开发速度。</p><p id="568c" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">如果你想更深入地了解YOLO模型，请查看以下帖子:</p><ul class=""><li id="865a" class="lp lq iq kv b kw kx kz la lc lr lg ls lk lt lo lu lv lw lx bi translated"><a class="ae kf" href="https://blog.roboflow.ai/yolov5-improvements-and-evaluation/" rel="noopener ugc nofollow" target="_blank"> YOLOv5更新</a> —注意自从我最初写这篇文章以来，YOLOv5在短时间内有所改进——我推荐在这里阅读它们。</li><li id="c249" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated"><a class="ae kf" href="https://blog.roboflow.ai/yolov4-versus-yolov5/" rel="noopener ugc nofollow" target="_blank">比较YOLOv4和YOLOv5 </a>(适用于比较创建定制模型检测器的性能)</li><li id="8d0a" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated"><a class="ae kf" href="https://blog.roboflow.ai/a-thorough-breakdown-of-yolov4/" rel="noopener ugc nofollow" target="_blank">解释YOLOv4 </a>(解释模型架构——因为在YOLOv5中除了框架之外没什么变化)</li><li id="e359" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated"><a class="ae kf" href="https://blog.roboflow.ai/training-yolov4-on-a-custom-dataset/" rel="noopener ugc nofollow" target="_blank">如何培训YOLOv4 </a>(如果您愿意投入时间，并且您正在寻求进行学术研究或寻求尽可能构建最准确的实时检测模型，您应该使用此工具。)</li></ul><h1 id="aefc" class="ng me iq bd mf nh ni nj mi nk nl nm ml jw nn jx mo jz no ka mr kc np kd mu nq bi translated">收集我们的训练图像</h1><p id="a0bf" class="pw-post-body-paragraph kt ku iq kv b kw mw jr ky kz mx ju lb lc nr le lf lg ns li lj lk nt lm ln lo ij bi translated">为了让你的物体探测器离开地面，你需要首先收集训练图像。您需要仔细考虑您要完成的任务，并提前考虑您的模型可能会觉得困难的任务方面。我建议尽可能缩小模型必须处理的范围，以提高最终模型的准确性。</p><p id="aa29" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">在本教程中，我们将对象检测器的范围限制为只检测血液中的细胞。这是一个狭窄的领域，可用现有技术获得。</p><p id="16f8" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">首先，我建议:</p><ul class=""><li id="0290" class="lp lq iq kv b kw kx kz la lc lr lg ls lk lt lo lu lv lw lx bi translated">缩小你的任务范围，只识别<strong class="kv ir"> 10个或更少的类</strong>，收集<strong class="kv ir">50-100张图片</strong>。</li><li id="40a4" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated">尽量确保每个类中的对象数量均匀分布。</li><li id="b27f" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated">选择可区分的物体。例如，一个主要由汽车和少量吉普车组成的数据集对于你的模型来说是很难掌握的。</li></ul><p id="9d85" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">当然，如果你只是想学习新技术，你可以选择一些免费的对象检测数据集。如果你想直接跟随教程，选择BCCD。</p><h1 id="bd67" class="ng me iq bd mf nh ni nj mi nk nl nm ml jw nn jx mo jz no ka mr kc np kd mu nq bi translated">注释我们的训练图像</h1><p id="a020" class="pw-post-body-paragraph kt ku iq kv b kw mw jr ky kz mx ju lb lc nr le lf lg ns li lj lk nt lm ln lo ij bi translated">为了训练我们的对象检测器，我们需要用包围盒注释来监督它的学习。我们在希望检测器看到的每个对象周围画一个框，并用希望检测器预测的对象类别标记每个框。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi kg"><img src="../Images/d5d40b856743c4a370bd422a2f3568fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*PapX5M32FKJ16v-FU1EgXQ.gif"/></div><p class="ko kp gj gh gi kq kr bd b be z dk translated">我正在<a class="ae kf" href="https://blog.roboflow.ai/getting-started-with-cvat/" rel="noopener ugc nofollow" target="_blank"> CVAT </a>标注一个航空数据集</p></figure><p id="4e29" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">有很多贴标工具(<a class="ae kf" href="https://blog.roboflow.ai/getting-started-with-cvat/" rel="noopener ugc nofollow" target="_blank"> CVAT </a>、<a class="ae kf" href="https://blog.roboflow.ai/getting-started-with-labelimg-for-labeling-object-detection-data/" rel="noopener ugc nofollow" target="_blank"> LabelImg </a>、<a class="ae kf" href="https://blog.roboflow.com/vott/" rel="noopener ugc nofollow" target="_blank"> VoTT </a>)和大规模解决方案(scale、AWS Ground Truth、要开始使用免费的标签工具，这里有两个有用的指南:</p><ul class=""><li id="856b" class="lp lq iq kv b kw kx kz la lc lr lg ls lk lt lo lu lv lw lx bi translated"><a class="ae kf" href="https://blog.roboflow.ai/getting-started-with-cvat/" rel="noopener ugc nofollow" target="_blank"> CVAT为计算机视觉标注</a></li><li id="2efb" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated"><a class="ae kf" href="https://blog.roboflow.ai/getting-started-with-labelimg-for-labeling-object-detection-data/" rel="noopener ugc nofollow" target="_blank">用于计算机视觉标注的标签</a></li></ul><p id="46ca" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">绘制边界框时，请确保遵循最佳实践:</p><ul class=""><li id="8ae8" class="lp lq iq kv b kw kx kz la lc lr lg ls lk lt lo lu lv lw lx bi translated">在有问题的物体周围贴上标签</li><li id="114a" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated">完全标记被遮挡的对象</li><li id="14c6" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated">避免有问题的物体周围有太多的空间</li></ul></div><div class="ab cl oc od hu oe" role="separator"><span class="of bw bk og oh oi"/><span class="of bw bk og oh oi"/><span class="of bw bk og oh"/></div><div class="ij ik il im in"><p id="0860" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">好吧！现在我们已经准备了一个数据集，我们准备进入YOLOv5训练代码。请保留您的数据集，我们将很快导入它。</p><p id="7a04" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">兼开:<a class="ae kf" href="https://colab.research.google.com/drive/1gDZ2xcTOgR39tGGs-EZ6i3RTs16wmzZQ" rel="noopener ugc nofollow" target="_blank"> Colab笔记本训练YOLOv5 </a>。</p><p id="7512" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">在Google Colab中，你将获得一个免费的GPU。确保文件→在您的驱动器中保存一份副本。然后，您将能够编辑代码。</p><h1 id="ac47" class="ng me iq bd mf nh ni nj mi nk nl nm ml jw nn jx mo jz no ka mr kc np kd mu nq bi translated">安装YOLOv5环境</h1><p id="5bfc" class="pw-post-body-paragraph kt ku iq kv b kw mw jr ky kz mx ju lb lc nr le lf lg ns li lj lk nt lm ln lo ij bi translated">从YOLOv5开始，我们首先克隆YOLOv5存储库并安装依赖项。这将设置我们的编程环境，为运行对象检测训练和推理命令做好准备。</p><pre class="kh ki kj kk gt oj ok ol om aw on bi"><span id="f63b" class="md me iq ok b gy oo op l oq or">!git clone <a class="ae kf" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank">https://github.com/ultralytics/yolov5</a>  # clone repo<br/>!pip install -U -r yolov5/requirements.txt  # install dependencies</span><span id="f746" class="md me iq ok b gy os op l oq or">%cd /content/yolov5</span></pre><p id="f8c1" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">然后，我们可以看看Google Colab免费提供给我们的训练环境。</p><pre class="kh ki kj kk gt oj ok ol om aw on bi"><span id="5b2a" class="md me iq ok b gy oo op l oq or">import torch<br/>from IPython.display import Image  # for displaying images<br/>from utils.google_utils import gdrive_download  # for downloading models/datasets</span><span id="fad8" class="md me iq ok b gy os op l oq or">print('torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))</span></pre><p id="4d4f" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">很有可能你会收到一个来自Google Colab的特斯拉P100 GPU。以下是我收到的内容:</p><pre class="kh ki kj kk gt oj ok ol om aw on bi"><span id="197f" class="md me iq ok b gy oo op l oq or">torch 1.5.0+cu101 _CudaDeviceProperties(name='Tesla P100-PCIE-16GB', major=6, minor=0, total_memory=16280MB, multi_processor_count=56)</span></pre><p id="76ac" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">GPU将允许我们加快训练时间。Colab也很好，因为它预装了<code class="fe ot ou ov ok b">torch</code>和<code class="fe ot ou ov ok b">cuda</code>。如果您尝试在本地上学习本教程，可能需要额外的步骤来设置YOLOv5。</p><h1 id="4ff8" class="ng me iq bd mf nh ni nj mi nk nl nm ml jw nn jx mo jz no ka mr kc np kd mu nq bi translated">下载自定义YOLOv5对象检测数据</h1><p id="b78d" class="pw-post-body-paragraph kt ku iq kv b kw mw jr ky kz mx ju lb lc nr le lf lg ns li lj lk nt lm ln lo ij bi translated">在本教程中，我们将从<a class="ae kf" href="https://roboflow.ai" rel="noopener ugc nofollow" target="_blank"> Roboflow </a>下载<a class="ae kf" href="https://public.roboflow.ai/" rel="noopener ugc nofollow" target="_blank">yolov 5格式的自定义对象检测数据</a>。您可以跟随公共血细胞数据集或上传您自己的数据集。</p><p id="5b10" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">一旦您标记了数据，要将您的数据移动到Roboflow中，<a class="ae kf" href="https://app.roboflow.ai/" rel="noopener ugc nofollow" target="_blank">创建一个免费帐户</a>，然后您可以以任何格式拖动您的数据集:(<a class="ae kf" href="https://blog.roboflow.com/how-to-convert-annotations-from-voc-xml-to-coco-json/" rel="noopener ugc nofollow" target="_blank"> VOC XML </a>、<a class="ae kf" href="https://blog.roboflow.com/how-to-convert-annotations-from-voc-xml-to-coco-json/" rel="noopener ugc nofollow" target="_blank"> COCO JSON </a>、TensorFlow对象检测CSV等)。</p><p id="fa3d" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">上传后，您可以选择预处理和增强步骤:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi ow"><img src="../Images/e9720c4047e96143449fd4e72f9e289e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Aq9Fss8fsFxVOqeq.png"/></div></div><p class="ko kp gj gh gi kq kr bd b be z dk translated">为BCCD示例数据集选择的设置</p></figure><p id="892d" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">然后点击<code class="fe ot ou ov ok b">Generate</code>和<code class="fe ot ou ov ok b">Download</code>，就可以选择YOLOv5 PyTorch格式了。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi ox"><img src="../Images/5b91312c27cef0b7b2ea2004a698c69b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*F9tDtAqw1sy0XS1B.png"/></div></div><p class="ko kp gj gh gi kq kr bd b be z dk translated">选择“YOLO v5 PyTorch”</p></figure><p id="b423" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">出现提示时，请务必选择“显示代码片段”这将输出一个下载curl脚本，这样您就可以轻松地将数据以正确的格式导入Colab。</p><pre class="kh ki kj kk gt oj ok ol om aw on bi"><span id="e24b" class="md me iq ok b gy oo op l oq or">curl -L "<a class="ae kf" href="https://public.roboflow.ai/ds/YOUR-LINK-HERE" rel="noopener ugc nofollow" target="_blank">https://public.roboflow.ai/ds/YOUR-LINK-HERE</a>" &gt; roboflow.zip; unzip roboflow.zip; rm roboflow.zip</span></pre><p id="be7d" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">在Colab中下载…</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/5bdb3430ad55df8527f2f8e67f36c0be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/0*d4i7ueG3EUBU2Zqy.png"/></div><p class="ko kp gj gh gi kq kr bd b be z dk translated">下载YOLOv5格式的自定义对象检测数据集</p></figure><p id="c3e1" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">导出会创建一个YOLOv5。名为<code class="fe ot ou ov ok b">data.yaml</code>的yaml文件指定了一个YOLOv5 <code class="fe ot ou ov ok b">images</code>文件夹、一个YOLOv5 <code class="fe ot ou ov ok b">labels</code>文件夹的位置，以及关于我们自定义类的信息。</p><h1 id="e0e9" class="ng me iq bd mf nh ni nj mi nk nl nm ml jw nn jx mo jz no ka mr kc np kd mu nq bi translated">定义YOLOv5模型配置和架构</h1><p id="d15e" class="pw-post-body-paragraph kt ku iq kv b kw mw jr ky kz mx ju lb lc nr le lf lg ns li lj lk nt lm ln lo ij bi translated">接下来，我们为自定义对象检测器编写一个模型配置文件。对于本教程，我们选择了YOLOv5最小、最快的基本模型。您可以选择其他YOLOv5型号，包括:</p><ul class=""><li id="d84d" class="lp lq iq kv b kw kx kz la lc lr lg ls lk lt lo lu lv lw lx bi translated">YOLOv5s</li><li id="4fcf" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated">YOLOv5m</li><li id="03a2" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated">YOLOv5l</li><li id="406a" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated">YOLOv5x</li></ul><p id="e90c" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">您也可以在这一步编辑网络的结构，尽管您很少需要这样做。这里是YOLOv5模型配置文件，我们称之为<code class="fe ot ou ov ok b">custom_yolov5s.yaml</code>:</p><pre class="kh ki kj kk gt oj ok ol om aw on bi"><span id="2e6e" class="md me iq ok b gy oo op l oq or">nc: 3<br/>depth_multiple: 0.33<br/>width_multiple: 0.50</span><span id="1f57" class="md me iq ok b gy os op l oq or">anchors:<br/>  - [10,13, 16,30, 33,23] <br/>  - [30,61, 62,45, 59,119]<br/>  - [116,90, 156,198, 373,326]</span><span id="3b0b" class="md me iq ok b gy os op l oq or">backbone:<br/>  [[-1, 1, Focus, [64, 3]],<br/>   [-1, 1, Conv, [128, 3, 2]],<br/>   [-1, 3, Bottleneck, [128]],<br/>   [-1, 1, Conv, [256, 3, 2]],<br/>   [-1, 9, BottleneckCSP, [256]],<br/>   [-1, 1, Conv, [512, 3, 2]], <br/>   [-1, 9, BottleneckCSP, [512]],<br/>   [-1, 1, Conv, [1024, 3, 2]],<br/>   [-1, 1, SPP, [1024, [5, 9, 13]]],<br/>   [-1, 6, BottleneckCSP, [1024]],<br/>  ]</span><span id="6a3c" class="md me iq ok b gy os op l oq or">head:<br/>  [[-1, 3, BottleneckCSP, [1024, False]],<br/>   [-1, 1, nn.Conv2d, [na * (nc + 5), 1, 1, 0]],<br/>   [-2, 1, nn.Upsample, [None, 2, "nearest"]],<br/>   [[-1, 6], 1, Concat, [1]],<br/>   [-1, 1, Conv, [512, 1, 1]],<br/>   [-1, 3, BottleneckCSP, [512, False]],<br/>   [-1, 1, nn.Conv2d, [na * (nc + 5), 1, 1, 0]],<br/>   [-2, 1, nn.Upsample, [None, 2, "nearest"]],<br/>   [[-1, 4], 1, Concat, [1]],<br/>   [-1, 1, Conv, [256, 1, 1]],<br/>   [-1, 3, BottleneckCSP, [256, False]],<br/>   [-1, 1, nn.Conv2d, [na * (nc + 5), 1, 1, 0]],</span><span id="8f13" class="md me iq ok b gy os op l oq or">[[], 1, Detect, [nc, anchors]],<br/>  ]</span></pre><h1 id="b4f6" class="ng me iq bd mf nh ni nj mi nk nl nm ml jw nn jx mo jz no ka mr kc np kd mu nq bi translated">培训自定义YOLOv5检测器</h1><p id="8e62" class="pw-post-body-paragraph kt ku iq kv b kw mw jr ky kz mx ju lb lc nr le lf lg ns li lj lk nt lm ln lo ij bi translated">随着我们的<code class="fe ot ou ov ok b">data.yaml</code>和<code class="fe ot ou ov ok b">custom_yolov5s.yaml</code>文件准备就绪，我们可以开始训练了！</p><p id="d6fc" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">为了开始训练，我们使用以下选项运行训练命令:</p><ul class=""><li id="155e" class="lp lq iq kv b kw kx kz la lc lr lg ls lk lt lo lu lv lw lx bi translated"><strong class="kv ir"> img: </strong>定义输入图像尺寸</li><li id="a09c" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated"><strong class="kv ir">批量:</strong>确定批量大小</li><li id="702b" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated"><strong class="kv ir">时期:</strong>定义训练时期的数量。(注:通常，3000+在这里是常见的！)</li><li id="14b5" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated"><strong class="kv ir">数据:</strong>设置我们yaml文件的路径</li><li id="f699" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated"><strong class="kv ir"> cfg: </strong>指定我们的模型配置</li><li id="be25" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated"><strong class="kv ir">权重:</strong>指定权重的自定义路径。(注意:您可以从Ultralytics Google Drive <a class="ae kf" href="https://drive.google.com/open?id=1Drs_Aiu7xx6S-ix95f9kNsA6ueKRpN2J" rel="noopener ugc nofollow" target="_blank">文件夹</a>中下载权重)</li><li id="9309" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated"><strong class="kv ir">名称:</strong>结果名称</li><li id="c7b1" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated"><strong class="kv ir"> nosave: </strong>仅保存最后一个检查点</li><li id="6bce" class="lp lq iq kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated"><strong class="kv ir">缓存:</strong>缓存图像以加快训练速度</li></ul><p id="78f7" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">并运行训练命令:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi oz"><img src="../Images/b602aa643712c06dd181e933465ca30e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*bBjkBK6dxxMiueubNjHhiw.gif"/></div></div><p class="ko kp gj gh gi kq kr bd b be z dk translated">训练自定义YOLOv5检测器。它训练得很快！</p></figure><p id="bd81" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">在培训期间，您希望观察mAP@0.5，以了解您的检测器如何在您的验证集上学习检测，越高越好！—见<a class="ae kf" href="https://blog.roboflow.ai/what-is-mean-average-precision-object-detection/" rel="noopener ugc nofollow" target="_blank">分解图</a>上的这篇帖子。</p><h1 id="5e22" class="ng me iq bd mf nh ni nj mi nk nl nm ml jw nn jx mo jz no ka mr kc np kd mu nq bi translated">评估定制YOLOv5检测器的性能</h1><p id="8413" class="pw-post-body-paragraph kt ku iq kv b kw mw jr ky kz mx ju lb lc nr le lf lg ns li lj lk nt lm ln lo ij bi translated">现在我们已经完成了培训，我们可以通过查看验证指标来评估培训程序的执行情况。训练脚本将在<code class="fe ot ou ov ok b">runs</code>中删除tensorboard日志。我们在这里想象这些:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi pa"><img src="../Images/99fdffe7a57396742f56b0cf1862de33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ifcQEhHKhka5ERzt.png"/></div></div><p class="ko kp gj gh gi kq kr bd b be z dk translated">在我们的自定义数据集上可视化tensorboard结果</p></figure><p id="f571" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">如果你因为某种原因不能可视化Tensorboard，也可以用<code class="fe ot ou ov ok b">utils.plot_results</code>绘制结果并保存一个<code class="fe ot ou ov ok b">result.png</code>。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi pb"><img src="../Images/355c4d1436214dafa7fc654fad76b076.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e_KilaOC7GSvhxiClrwUVw.png"/></div></div><p class="ko kp gj gh gi kq kr bd b be z dk translated">训练图。png格式</p></figure><p id="cb3f" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">我在这里提前停止了训练。您希望在验证图达到最高点时获取训练好的模型权重。</p><h1 id="2b24" class="ng me iq bd mf nh ni nj mi nk nl nm ml jw nn jx mo jz no ka mr kc np kd mu nq bi translated">对测试图像运行YOLOv5推理</h1><p id="5994" class="pw-post-body-paragraph kt ku iq kv b kw mw jr ky kz mx ju lb lc nr le lf lg ns li lj lk nt lm ln lo ij bi translated">现在，我们采用训练好的模型，对测试图像进行推断。训练完成后，模型重量将保存在<code class="fe ot ou ov ok b">weights/</code>中。为了进行推理，我们调用这些权重以及一个指定模型置信度的<code class="fe ot ou ov ok b">conf</code>(需要的置信度越高，预测越少)，以及一个推理<code class="fe ot ou ov ok b">source</code>。<code class="fe ot ou ov ok b">source</code>可以接受一个<strong class="kv ir">目录的图像、个人图像、视频文件，以及一个设备的网络摄像头端口</strong>。为了源码，我把我们的<code class="fe ot ou ov ok b">test/*jpg</code>移到了<code class="fe ot ou ov ok b">test_infer/</code>。</p><pre class="kh ki kj kk gt oj ok ol om aw on bi"><span id="0517" class="md me iq ok b gy oo op l oq or">!python detect.py --weights weights/last_yolov5s_custom.pt --img 416 --conf 0.4 --source ../test_infer</span></pre><p id="77d8" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">推断时间极快。在我们的特斯拉P100上，<strong class="kv ir"> YOLOv5s每幅图像达到7毫秒。这对于部署到像Jetson Nano(价格仅为100美元)这样的小型GPU来说是个好兆头。</strong></p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi pc"><img src="../Images/114a019920c55c5c59c8c709b6941abc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7NdJLh0rrQ1Rflzf.png"/></div></div><p class="ko kp gj gh gi kq kr bd b be z dk translated">对出现在142 FPS(. 007s/图像)的YOLOv5s的推断</p></figure><p id="6cad" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">最后，我们在测试图像上可视化我们的检测器推理。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/b3b5baa92f5a79ad935491ebfb20f1ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/format:webp/0*XhcrzasLptcbJpqg.png"/></div><p class="ko kp gj gh gi kq kr bd b be z dk translated">YOLOv5对测试图像的推断。它还可以通过视频和网络摄像头轻松推断。</p></figure><h1 id="b813" class="ng me iq bd mf nh ni nj mi nk nl nm ml jw nn jx mo jz no ka mr kc np kd mu nq bi translated">导出保存的YOLOv5重量以供将来推断</h1><p id="22a9" class="pw-post-body-paragraph kt ku iq kv b kw mw jr ky kz mx ju lb lc nr le lf lg ns li lj lk nt lm ln lo ij bi translated">既然我们的自定义YOLOv5对象检测器已经过验证，我们可能希望将Colab中的权重用于实时计算机视觉任务。为此，我们导入一个Google Drive模块，然后将它们发送出去。</p><pre class="kh ki kj kk gt oj ok ol om aw on bi"><span id="36aa" class="md me iq ok b gy oo op l oq or">from google.colab import drive<br/>drive.mount('/content/gdrive')</span><span id="2dc0" class="md me iq ok b gy os op l oq or">%cp /content/yolov5/weights/last_yolov5s_custom.pt /content/gdrive/My\ Drive</span></pre><h1 id="ee95" class="ng me iq bd mf nh ni nj mi nk nl nm ml jw nn jx mo jz no ka mr kc np kd mu nq bi translated">结论</h1><p id="edb9" class="pw-post-body-paragraph kt ku iq kv b kw mw jr ky kz mx ju lb lc nr le lf lg ns li lj lk nt lm ln lo ij bi translated">我们希望你喜欢训练你的定制YOLO v5 <a class="ae kf" href="https://blog.roboflow.com/the-ultimate-guide-to-object-detection/" rel="noopener ugc nofollow" target="_blank">物体探测器</a>！</p><p id="709a" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">YOLO v5是轻量级的，非常容易使用。YOLO v5训练快，推理快，表现好。</p><p id="ec83" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">让我们把它拿出来！</p><p id="29a4" class="pw-post-body-paragraph kt ku iq kv b kw kx jr ky kz la ju lb lc ld le lf lg lh li lj lk ll lm ln lo ij bi translated">后续步骤:请继续关注未来的教程以及如何将您的新模型部署到生产环境中。</p></div></div>    
</body>
</html>