<html>
<head>
<title>Productive NLP Experimentation with Python using Pytorch Lightning and Torchtext</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Pytorch Lightning 和 Torchtext 对 Python 进行高效的自然语言处理实验</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/productive-nlp-experimentation-with-python-using-pytorch-lightning-and-torchtext-256a4d00a26b?source=collection_archive---------35-----------------------#2020-05-31">https://towardsdatascience.com/productive-nlp-experimentation-with-python-using-pytorch-lightning-and-torchtext-256a4d00a26b?source=collection_archive---------35-----------------------#2020-05-31</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="61f5" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何使用 Pytorch Lightning 和 Torchtext</h2></div><p id="1213" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Pytorch 是我主要的深度学习框架。然而，有些部分我觉得可以改进。Pytorch Lightning 已经回答了这个问题[1]。</p><p id="ccf9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">William Falcon 展示了 Pytorch Lightning [2]中的一些核心功能。这些功能包括构建您的代码以准备数据、进行训练、验证和测试，以及使用 Tensorboard 进行日志记录。</p><p id="22c5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">他对 Pytorch Lightning、Pytorch Ignite、fast.ai 做了客观的比较[4]。他强调指出，Ignite 并不是每个模型都有一个标准的接口，需要更多的代码来训练模型，并不直接与 Tensorboard 集成，也不像 Lightning 那样具有额外的高性能计算。而 fast.ai 比其他两个有更高的学习曲线，用例可能与 Pytorch Lightning 和 Pytorch Ignite 不同。</p><p id="8a74" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本文中，我想强调 Pytorch Lightning 提高我的工作效率的一些特性，以及如何将 Pytorch Lightning 与 Torchtext 集成。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lc"><img src="../Images/1c1467f39a5127697834af29fd368b88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IKlh7KdEwLeu0AjK"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">照片由<a class="ae lb" href="https://unsplash.com/@micahtindell?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">🏴󠁵󠁳󠁴󠁸󠁿·廷德尔</a>在<a class="ae lb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="15a8" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">为什么使用 Pytorch 闪电</h1><h2 id="2524" class="mk lt iq bd lu ml mm dn ly mn mo dp mc ko mp mq me ks mr ms mg kw mt mu mi mv bi translated">减少样板文件</h2><p id="b0b9" class="pw-post-body-paragraph kf kg iq kh b ki mw jr kk kl mx ju kn ko my kq kr ks mz ku kv kw na ky kz la ij bi translated">除非万不得已，不要再进行写作训练。您可以将您的培训定义为</p><pre class="ld le lf lg gt nb nc nd ne aw nf bi"><span id="280d" class="mk lt iq nc b gy ng nh l ni nj">from pytorch_lightning import Trainer</span><span id="1405" class="mk lt iq nc b gy nk nh l ni nj">trainer = Trainer(<br/>    gpus=1, <br/>    logger=[logger],<br/>    max_epochs=5<br/>)<br/>trainer.fit(model)</span></pre><p id="6ed6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一个<code class="fe nl nm nn nc b">Trainer</code>的工作是做你的日常训练。</p><ul class=""><li id="317d" class="no np iq kh b ki kj kl km ko nq ks nr kw ns la nt nu nv nw bi translated"><strong class="kh ir">不再有写循环。</strong>正如你所看到的，不再有通常在 pytorch 教程中看到的循环。</li><li id="3299" class="no np iq kh b ki nx kl ny ko nz ks oa kw ob la nt nu nv nw bi translated"><strong class="kh ir">不要将你的模型转换成 gpu。</strong>您不必担心忘记将您的型号转换为<code class="fe nl nm nn nc b">cuda</code>。</li><li id="4e41" class="no np iq kh b ki nx kl ny ko nz ks oa kw ob la nt nu nv nw bi translated"><strong class="kh ir">没有定制打印对您造成的损失。</strong>你看到<code class="fe nl nm nn nc b">logger</code>那里的变量了吗？你可以使用 Tensorboard 来管理你的日志，我推荐你使用它。在本地使用之前，请执行<code class="fe nl nm nn nc b">pip install tensorboard</code>。</li></ul><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi oc"><img src="../Images/6110f5a212ddb8333a2a33b49ad45bc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Co6YwacQJK3ZfoOdAuBkTA.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">Pytorch 闪电产生的张量板样本</p></figure><p id="e2b4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这个截图中，我将<code class="fe nl nm nn nc b">logger</code>变量定义为</p><pre class="ld le lf lg gt nb nc nd ne aw nf bi"><span id="7486" class="mk lt iq nc b gy ng nh l ni nj">from pytorch_lightning.loggers import TensorBoardLogger</span><span id="8bd7" class="mk lt iq nc b gy nk nh l ni nj">logger = TensorBoardLogger('tb_logs', name='my_model')</span></pre><p id="8f9f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Pytorch Lightning 会创建一个名为<code class="fe nl nm nn nc b">tb_logs</code>的日志目录，你可以参考你的 Tensorboard 的日志目录(如果你在 Jupyter notebook 之外单独运行你的 Tensorboard)。</p><pre class="ld le lf lg gt nb nc nd ne aw nf bi"><span id="db7a" class="mk lt iq nc b gy ng nh l ni nj">tensorboard --logdir tb_logs/</span></pre><h2 id="f914" class="mk lt iq bd lu ml mm dn ly mn mo dp mc ko mp mq me ks mr ms mg kw mt mu mi mv bi translated">组织代码</h2><p id="1552" class="pw-post-body-paragraph kf kg iq kh b ki mw jr kk kl mx ju kn ko my kq kr ks mz ku kv kw na ky kz la ij bi translated">除了构造函数和<code class="fe nl nm nn nc b">forward</code>之外，你还可以定义更多的函数</p><ul class=""><li id="a074" class="no np iq kh b ki kj kl km ko nq ks nr kw ns la nt nu nv nw bi translated"><code class="fe nl nm nn nc b">configure_optimizer</code>。期望从<code class="fe nl nm nn nc b">torch.optim</code>包中返回 Pytorch 优化器。</li></ul><pre class="ld le lf lg gt nb nc nd ne aw nf bi"><span id="7f9f" class="mk lt iq nc b gy ng nh l ni nj">def configure_optimizers(self):<br/>    return Adam(self.parameters(), lr=0.01)</span></pre><ul class=""><li id="b980" class="no np iq kh b ki kj kl km ko nq ks nr kw ns la nt nu nv nw bi translated"><code class="fe nl nm nn nc b">train_step</code>。给定一个批次和批次号，定义我们将如何输入到模型中。</li></ul><pre class="ld le lf lg gt nb nc nd ne aw nf bi"><span id="f6a5" class="mk lt iq nc b gy ng nh l ni nj">def training_step(self, batch, batch_idx):<br/>    x, y = batch.text[0].T, batch.label<br/>    y_hat = self(x)<br/>    loss = self.loss_function(y_hat, y)<br/>    return dict(<br/>        loss=loss,<br/>        log=dict(<br/>            train_loss=loss<br/>        )<br/>    )</span></pre><p id="69ca" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这个例子中，注意我用转置做了一点变换。在输入到模型中之前，可以进行各种转换，但是我建议您在这个函数之外进行大量的转换，这样会比较干净。</p><p id="7d65" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我还将<code class="fe nl nm nn nc b">loss_function</code>定义为模型的一部分，并使用交叉熵对其进行“硬编码”。如果你不想这样，你可以使用<code class="fe nl nm nn nc b">torch.functional as F</code>然后调用你的功能损失函数，比如<code class="fe nl nm nn nc b">F.log_softmax()</code>。你可以做的另一件事是让模型构造器接受损失函数作为参数。</p><ul class=""><li id="e5f0" class="no np iq kh b ki kj kl km ko nq ks nr kw ns la nt nu nv nw bi translated"><code class="fe nl nm nn nc b">train_dataloader</code>。定义希望如何加载培训数据加载器。</li></ul><p id="b702" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="https://pytorch.org/docs/stable/data.html" rel="noopener ugc nofollow" target="_blank"> Pytorch Dataloader </a>是一个 API，可以帮助你批处理输入。不过，据我所知，Pytorch Lightning 将运行<code class="fe nl nm nn nc b">for batch_idx, batch in enumerate(train_dataloader)</code>(不完全是这样，但类似)。这意味着你可以自由定义任何可迭代的东西。</p><ul class=""><li id="ede1" class="no np iq kh b ki kj kl km ko nq ks nr kw ns la nt nu nv nw bi translated"><code class="fe nl nm nn nc b">test_step</code>。给定一个批次和批号，定义我们如何将输入馈送到模型进行测试。值得注意的是，在这一步中，我们不需要输入损失函数，因为我们是在没有梯度的情况下运行的。</li><li id="1747" class="no np iq kh b ki nx kl ny ko nz ks oa kw ob la nt nu nv nw bi translated"><code class="fe nl nm nn nc b">test_dataloader</code>。定义您希望如何加载您的测试数据加载器</li><li id="538c" class="no np iq kh b ki nx kl ny ko nz ks oa kw ob la nt nu nv nw bi translated"><code class="fe nl nm nn nc b">test_epoch_end</code>。给定所有的测试输出，定义您想要对测试输出做的一些动作。如果您不想定义它，那么您可以定义，但是当您定义了<code class="fe nl nm nn nc b">test_step</code>和<code class="fe nl nm nn nc b">test_dataloader</code>之后，它会显示警告，因为这样您基本上对您的测试数据没有做任何事情。</li></ul><h1 id="da5d" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">使用 Pytorch Lightning 和 Torchtext</h1><p id="03fd" class="pw-post-body-paragraph kf kg iq kh b ki mw jr kk kl mx ju kn ko my kq kr ks mz ku kv kw na ky kz la ij bi translated">之前，我已经描述了我对使用 torchtext 的探索[4]。现在，我想在实验部分进一步提高我的生产力，包括培训、测试、验证、度量记录。所有这些都可以通过 Pytorch 闪电来实现。</p><p id="7feb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我将采用<strong class="kh ir"> IMDB 情感分类数据集</strong>，它已经在 Torchtext 包中可用。</p><h2 id="5e6e" class="mk lt iq bd lu ml mm dn ly mn mo dp mc ko mp mq me ks mr ms mg kw mt mu mi mv bi translated">正在加载数据集</h2><p id="1b0a" class="pw-post-body-paragraph kf kg iq kh b ki mw jr kk kl mx ju kn ko my kq kr ks mz ku kv kw na ky kz la ij bi translated">IMDB 情感分类数据集是文本分类任务，给定评论文本预测它是正面评论还是负面评论。有一个来自<a class="ae lb" href="https://pytorch.org/text/datasets.html" rel="noopener ugc nofollow" target="_blank">torch text</a>【5】的官方简短教程，然而那个教程并没有涵盖训练部分。我将使用一些教程代码，并使用 Pytorch Lightning 将它们与培训联系起来。</p><p id="8f82" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该数据集包含<strong class="kh ir"> 3 个类别:未知、阳性(标记为“阳性”)、阴性(标记为“阴性”)</strong>。因此，我们知道我们将需要定义一个可以预测 3 个类的输出。这是一个分类任务，所以我将使用交叉熵损失。</p><p id="645f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在加载数据你可以做什么</p><pre class="ld le lf lg gt nb nc nd ne aw nf bi"><span id="5f95" class="mk lt iq nc b gy ng nh l ni nj">from torchtext.data import Field <br/>from torchtext.datasets import IMDB</span><span id="cfaf" class="mk lt iq nc b gy nk nh l ni nj">text_field = Field(sequential=True, include_lengths=True, fix_length=200)<br/>label_field = Field(sequential=False)</span><span id="40f8" class="mk lt iq nc b gy nk nh l ni nj">train, test = IMDB.splits(text_field, label_field)</span></pre><p id="023b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于 IMDB 审查的长度不一致，使用<strong class="kh ir">固定长度参数将有助于填充/修剪序列数据</strong>。</p><p id="3eb0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您可以使用<code class="fe nl nm nn nc b">train.examples[i]</code>访问您的样本数据，以查看训练和测试变量中的内容。</p><h2 id="2f2a" class="mk lt iq bd lu ml mm dn ly mn mo dp mc ko mp mq me ks mr ms mg kw mt mu mi mv bi translated">构建词汇</h2><p id="ead9" class="pw-post-body-paragraph kf kg iq kh b ki mw jr kk kl mx ju kn ko my kq kr ks mz ku kv kw na ky kz la ij bi translated">预训练单词嵌入通常针对我们使用的不同数据进行训练。因此，它将使用不同的“编码”从令牌到整数，我们目前有。<code class="fe nl nm nn nc b">build_vocab</code>将使用预先训练的编码重新映射来自当前数据集(在本例中为 IMDB 数据集)的当前整数编码。例如，如果我们词汇表中的标记<code class="fe nl nm nn nc b">2</code>是<code class="fe nl nm nn nc b">eat</code>，但是<code class="fe nl nm nn nc b">eat</code>是预训练单词嵌入中的标记号<code class="fe nl nm nn nc b">15</code>，那么它将被自动映射到正确的标记号。</p><pre class="ld le lf lg gt nb nc nd ne aw nf bi"><span id="ef35" class="mk lt iq nc b gy ng nh l ni nj">from torchtext.vocab import FastText</span><span id="f3a1" class="mk lt iq nc b gy nk nh l ni nj">text_field.build_vocab(train, vectors=FastText('simple'))<br/>label_field.build_vocab(train)</span></pre><p id="25a3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">IMDB 数据集中的标签字段将采用<code class="fe nl nm nn nc b">pos</code>、<code class="fe nl nm nn nc b">neg</code>和<code class="fe nl nm nn nc b">&lt;unk&gt;</code>的形式，因此它仍然需要构建自己的 vocab，但不嵌入单词。</p><h2 id="6f3c" class="mk lt iq bd lu ml mm dn ly mn mo dp mc ko mp mq me ks mr ms mg kw mt mu mi mv bi translated">拆分并生成迭代器</h2><p id="a860" class="pw-post-body-paragraph kf kg iq kh b ki mw jr kk kl mx ju kn ko my kq kr ks mz ku kv kw na ky kz la ij bi translated">迭代器的工作方式有点像数据加载器，它有助于在一个时期内批处理和迭代数据。我们可以使用 BucketIterator 来帮助我们迭代特定数量的批处理，并将所有这些向量转换成一个设备，其中设备可以是<code class="fe nl nm nn nc b">cpu </code>或<code class="fe nl nm nn nc b">cuda</code>。</p><pre class="ld le lf lg gt nb nc nd ne aw nf bi"><span id="6129" class="mk lt iq nc b gy ng nh l ni nj">from torchtext.data import BucketIterator</span><span id="eab9" class="mk lt iq nc b gy nk nh l ni nj">device = 'cuda' if torch.cuda.is_available() else 'cpu'<br/>batch_size = 32</span><span id="bf27" class="mk lt iq nc b gy nk nh l ni nj">train_iter, test_iter = BucketIterator.splits(<br/>    (train, test), <br/>    batch_size=batch_size, <br/>    device=device<br/>)</span></pre><p id="020e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们准备定义我们的模型。</p><h2 id="aab4" class="mk lt iq bd lu ml mm dn ly mn mo dp mc ko mp mq me ks mr ms mg kw mt mu mi mv bi translated">模型定义</h2><p id="50a2" class="pw-post-body-paragraph kf kg iq kh b ki mw jr kk kl mx ju kn ko my kq kr ks mz ku kv kw na ky kz la ij bi translated">用 Pytorch Lightning 定义模型就像 William 解释的那样简单[2]。</p><ol class=""><li id="ce41" class="no np iq kh b ki kj kl km ko nq ks nr kw ns la od nu nv nw bi translated">从<code class="fe nl nm nn nc b">LightningModule</code>而不是 Pytorch 的模块加载。</li><li id="11de" class="no np iq kh b ki nx kl ny ko nz ks oa kw ob la od nu nv nw bi translated">定义构造函数并转发。</li><li id="6413" class="no np iq kh b ki nx kl ny ko nz ks oa kw ob la od nu nv nw bi translated">现在添加上一节提到的属性</li></ol><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="oe of l"/></div></figure><p id="6af9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在进行完整的训练之前，最好确保您的模型可以正确地接受传递的输入，就像这样。</p><pre class="ld le lf lg gt nb nc nd ne aw nf bi"><span id="c95a" class="mk lt iq nc b gy ng nh l ni nj">sample_batch = next(iter(train_iter))<br/>model(sample_batch.text[0].T)</span></pre><p id="47be" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我解释一下我为什么要做这些转换。</p><p id="ca7d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">迭代器中的每个批处理对象都有<code class="fe nl nm nn nc b">text </code>和<code class="fe nl nm nn nc b">label </code>字段。<code class="fe nl nm nn nc b">text</code>字段实际上是一个评论的真实单词向量和实际长度向量的元组。真实字向量的大小为<strong class="kh ir">固定长度 x 批量大小</strong>，而实际长度向量的大小为<strong class="kh ir">批量大小</strong>。为了给模型输入单词 vector，我需要:取第一个元组并旋转它，这样它将产生<strong class="kh ir">batch _ size x fixed _ length</strong>。</p><p id="7660" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在准备训练我们的模型！</p><pre class="ld le lf lg gt nb nc nd ne aw nf bi"><span id="c601" class="mk lt iq nc b gy ng nh l ni nj">from pytorch_lightning import Trainer<br/>from pytorch_lightning.loggers import TensorBoardLogger</span><span id="64a9" class="mk lt iq nc b gy nk nh l ni nj">model = MyModel(text_field.vocab.vectors)<br/>logger = TensorBoardLogger('tb_logs', name='my_model')<br/>trainer = Trainer(<br/>    gpus=1, <br/>    logger=logger,<br/>    max_epochs=3<br/>)<br/>trainer.fit(model)</span></pre><p id="eee7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">完成了！它会自动显示进度条，这样你就不用再做 tqdm 了。</p><pre class="ld le lf lg gt nb nc nd ne aw nf bi"><span id="f3ac" class="mk lt iq nc b gy ng nh l ni nj">for batch_idx, batch in tqdm(enumerate(train_loader)):</span></pre><p id="5e71" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">经过培训，您可以通过 1 行进行测试</p><pre class="ld le lf lg gt nb nc nd ne aw nf bi"><span id="1e11" class="mk lt iq nc b gy ng nh l ni nj">trainer.test()</span></pre><blockquote class="og oh oi"><p id="75fb" class="kf kg oj kh b ki kj jr kk kl km ju kn ok kp kq kr ol kt ku kv om kx ky kz la ij bi translated">如果你在想为什么这个测试方法只返回一个对象？那么你可能会想到 scikit-learn 的训练和测试分离。在 Pytorch 中，“测试”部分通常被定义为“验证”。所以你可能想定义<code class="fe nl nm nn nc b">validation_step</code>和<code class="fe nl nm nn nc b">val_dataloader</code>，而不是<code class="fe nl nm nn nc b">test_*</code>。</p></blockquote><h1 id="f781" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论</h1><p id="9504" class="pw-post-body-paragraph kf kg iq kh b ki mw jr kk kl mx ju kn ko my kq kr ks mz ku kv kw na ky kz la ij bi translated">在我看来，使用 Pytorch lightning 和 Torchtext 确实提高了我试验 NLP 深度学习模型的生产率。我认为这个库非常吸引人的一些方面是向后兼容 Pytorch，Torchtext 友好，以及利用 Tensorboard。</p><h2 id="48e5" class="mk lt iq bd lu ml mm dn ly mn mo dp mc ko mp mq me ks mr ms mg kw mt mu mi mv bi translated">向后兼容 Pytorch</h2><p id="1001" class="pw-post-body-paragraph kf kg iq kh b ki mw jr kk kl mx ju kn ko my kq kr ks mz ku kv kw na ky kz la ij bi translated">如果你犹豫不决，因为你认为使用一个新的库会是一个开销，那么不要担心！你可以先安装，用<code class="fe nl nm nn nc b">LightningModule</code>代替<code class="fe nl nm nn nc b">nn.Module</code>并编写普通的 Pytorch 代码。它仍然可以工作，因为这个库不会引起任何额外的麻烦。</p><h2 id="8327" class="mk lt iq bd lu ml mm dn ly mn mo dp mc ko mp mq me ks mr ms mg kw mt mu mi mv bi translated">友好的火炬文本</h2><p id="d42d" class="pw-post-body-paragraph kf kg iq kh b ki mw jr kk kl mx ju kn ko my kq kr ks mz ku kv kw na ky kz la ij bi translated">与 Pytorch Lightning 一起使用 Torchtext 相当容易。这两个库都运行在 Pytorch 上，并且与本机 Pytorch 有很高的兼容性。两者都有额外的特征，这些特征并不相交，而是互补的。例如，Torchtext 具有加载数据集的简单接口，如 IMDB 或 YelpReview。然后，您可以使用 Pytorch Lightning 来训练您想要定义的任何模型，并登录到 Tensorboard 或 MLFlow。</p><h2 id="411c" class="mk lt iq bd lu ml mm dn ly mn mo dp mc ko mp mq me ks mr ms mg kw mt mu mi mv bi translated">利用 Tensorboard 的使用</h2><p id="88a0" class="pw-post-body-paragraph kf kg iq kh b ki mw jr kk kl mx ju kn ko my kq kr ks mz ku kv kw na ky kz la ij bi translated">使用 Tensorboard 代替手动打印你的损失和其他指标，帮助我消除了在训练循环中打印损失时不必要的错误。它还将消除在培训结束时可视化损失与时期图的需要。</p><p id="93c1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你最好现在就在 google colab 中进行实验，这是链接</p><blockquote class="on"><p id="ebb1" class="oo op iq bd oq or os ot ou ov ow la dk translated"><a class="ae lb" href="https://colab.research.google.com/github/ariepratama/python-playground/blob/master/dl-pytorch-lightning.ipynb" rel="noopener ugc nofollow" target="_blank">Google Colab 的笔记本</a></p></blockquote><h1 id="1a8f" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw ox jx me jz oy ka mg kc oz kd mi mj bi translated">参考</h1><p id="a599" class="pw-post-body-paragraph kf kg iq kh b ki mw jr kk kl mx ju kn ko my kq kr ks mz ku kv kw na ky kz la ij bi translated">[1] Pytorch Lightning 文档。<a class="ae lb" href="https://pytorch-lightning.readthedocs.io/en/stable/introduction_guide.html" rel="noopener ugc nofollow" target="_blank">https://py torch-lightning . readthedocs . io/en/stable/introduction _ guide . html</a></p><p id="a048" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[2] Falcon，w .从 PyTorch 到 py torch Lightning——一个温和的介绍。<a class="ae lb" rel="noopener" target="_blank" href="/from-pytorch-to-pytorch-lightning-a-gentle-introduction-b371b7caaf09">https://towards data science . com/from-py torch-to-py torch-lightning-a-gentle-introduction-b 371 b 7 caaf 09</a></p><p id="adb0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[3] Falcon，w . py torch Lightning vs py torch Ignite vs fast . ai .<a class="ae lb" rel="noopener" target="_blank" href="/pytorch-lightning-vs-pytorch-ignite-vs-fast-ai-61dc7480ad8a">https://towards data science . com/py torch-Lightning-vs-py torch-Ignite-vs-fast-ai-61dc 7480 ad8a</a></p><p id="b371" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[4] Sutiono，Arie P .用 PyTorch 和 Torchtext 进行 NLP 的深度学习。<a class="ae lb" rel="noopener" target="_blank" href="/deep-learning-for-nlp-with-pytorch-and-torchtext-4f92d69052f">https://towardsdatascience . com/deep-learning-for-NLP-with-py torch-and-torch text-4f92d 69052 f</a></p><p id="deb9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[5] Torchtext 数据集文档。<a class="ae lb" href="https://pytorch.org/text/datasets.html" rel="noopener ugc nofollow" target="_blank">https://pytorch.org/text/datasets.html</a></p></div></div>    
</body>
</html>