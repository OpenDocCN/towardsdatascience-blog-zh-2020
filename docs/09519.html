<html>
<head>
<title>Try TextHero: The Absolute Simplest way to Clean and Analyze Text in Pandas</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">试试 TextHero:清理和分析 Pandas 中文本的绝对最简单的方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/try-texthero-the-absolute-simplest-way-to-clean-and-analyze-text-in-pandas-6db86ed14272?source=collection_archive---------16-----------------------#2020-07-07">https://towardsdatascience.com/try-texthero-the-absolute-simplest-way-to-clean-and-analyze-text-in-pandas-6db86ed14272?source=collection_archive---------16-----------------------#2020-07-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3b2f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">自然语言处理(NLP)让 Python 变得简单</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/2d10f0fa8af4f22ccefd0ffa4ad68490.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rFFr71R313_J39UX"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">加布里埃尔·巴西诺在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="e2db" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">简化的自然语言处理</h1><p id="d705" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我一直在寻找新的工具来帮助我简化自然语言处理管道，所以当我偶然发现一个展示 Texthero 功能的视频短片时，我知道我必须马上尝试一下。Texthero 被设计成一个 Pandas 包装器，因此它使得预处理和分析基于文本的 Pandas 系列变得前所未有的容易。我立即调出文档，打开笔记本，下载了几千条 Reddit 线程进行分析，以测试新的 lib。</p><p id="af21" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">注</strong>:text hero 库还在测试中！可能会有错误，管道可能会改变。我发现了 wordcloud 功能中的一个 bug，并报告了它。它应该在即将到来的更新中得到修复！</p><h1 id="ae93" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">Texthero 概述</h1><p id="7f06" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在处理代码时，我会更仔细地研究这些，但为了快速概述，Texthero 分为四个功能模块:</p><h2 id="4915" class="mt la it bd lb mu mv dn lf mw mx dp lj ma my mz ll me na nb ln mi nc nd lp ne bi translated"><a class="ae ky" href="https://texthero.org/docs/api-preprocessing" rel="noopener ugc nofollow" target="_blank">预处理</a></h2><p id="3365" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><em class="ms">预处理</em>模块是关于高效清理基于文本的熊猫系列。它主要是在幕后使用<a class="ae ky" href="https://docs.python.org/3/library/re.html" rel="noopener ugc nofollow" target="_blank">正则表达式(regex) </a>。</p><h2 id="18d0" class="mt la it bd lb mu mv dn lf mw mx dp lj ma my mz ll me na nb ln mi nc nd lp ne bi translated"><a class="ae ky" href="https://texthero.org/docs/api-nlp" rel="noopener ugc nofollow" target="_blank"> NLP </a></h2><p id="1562" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">NLP 模块包含一些常见的 NLP 任务，比如命名实体识别和名词块。它正在使用引擎盖下的<a class="ae ky" href="https://spacy.io/" rel="noopener ugc nofollow" target="_blank">空间</a>。</p><h2 id="8165" class="mt la it bd lb mu mv dn lf mw mx dp lj ma my mz ll me na nb ln mi nc nd lp ne bi translated"><a class="ae ky" href="https://texthero.org/docs/api-representation" rel="noopener ugc nofollow" target="_blank">代表权</a></h2><p id="a0ce" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><em class="ms">表示</em>模块用于使用不同的算法创建单词向量。它包括像主成分分析和 kMeans 这样的东西。它使用<a class="ae ky" href="https://scikit-learn.org/stable/user_guide.html" rel="noopener ugc nofollow" target="_blank"> scikit-learn for TF-IDF 和 Count </a>，并从语言模型预先计算加载嵌入。</p><h2 id="c9f8" class="mt la it bd lb mu mv dn lf mw mx dp lj ma my mz ll me na nb ln mi nc nd lp ne bi translated"><a class="ae ky" href="https://texthero.org/docs/api-visualization" rel="noopener ugc nofollow" target="_blank">可视化</a></h2><p id="3159" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><em class="ms">可视化</em>模块用于可视化散点图或生成文字云。这个模块目前只有几个功能，并在引擎盖下使用了<a class="ae ky" href="https://plotly.com/python/plotly-fundamentals/" rel="noopener ugc nofollow" target="_blank"> Plotly </a>和 WordCloud。</p><p id="e8f1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">查看文档以获得完整的特性列表！</p><div class="nf ng gp gr nh ni"><a href="https://texthero.org/" rel="noopener  ugc nofollow" target="_blank"><div class="nj ab fo"><div class="nk ab nl cl cj nm"><h2 class="bd iu gy z fp nn fr fs no fu fw is bi translated">Texthero 文本预处理，从零到英雄的表示和可视化。</h2><div class="np l"><h3 class="bd b gy z fp nn fr fs no fu fw dk translated">从零到英雄的文本预处理、表示和可视化。</h3></div><div class="nq l"><p class="bd b dl z fp nn fr fs no fu fw dk translated">从零到 hero.texthero.org 的文本预处理、表示和可视化</p></div></div><div class="nr l"><div class="ns l nt nu nv nr nw ks ni"/></div></div></a></div><h1 id="ac14" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">依赖性和数据</h1><p id="3b3e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">尽管使用 pip 安装很容易，但由于熊猫版本的问题，当我试图在我的有<a class="ae ky" href="https://github.com/nitred/airflow-pandas" rel="noopener ugc nofollow" target="_blank"> Apache Airflow </a>的环境中安装它时，我遇到了一个冲突。此外，它需要一段时间来安装在一个新的环境中，因为它在后端使用了如此多的其他库。第一次导入后，它还会下载一些额外的东西。</p><p id="c14f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">对于数据集，我使用<a class="ae ky" href="https://praw.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> PRAW </a>从<a class="ae ky" href="http://www.reddit.com" rel="noopener ugc nofollow" target="_blank"> Reddit </a>中提取数据。检查这篇文章，如果你需要一个 PRAW 复习。</p><div class="nf ng gp gr nh ni"><a rel="noopener follow" target="_blank" href="/ultimate-beginners-guide-to-collecting-text-for-natural-language-processing-nlp-with-python-256d113e6184"><div class="nj ab fo"><div class="nk ab nl cl cj nm"><h2 class="bd iu gy z fp nn fr fs no fu fw is bi translated">用 Python 收集自然语言处理(NLP)文本的入门指南</h2><div class="np l"><h3 class="bd b gy z fp nn fr fs no fu fw dk translated">通过 API 和 Web 抓取收集文本</h3></div><div class="nq l"><p class="bd b dl z fp nn fr fs no fu fw dk translated">towardsdatascience.com</p></div></div><div class="nr l"><div class="nx l nt nu nv nr nw ks ni"/></div></div></a></div><pre class="kj kk kl km gt ny nz oa ob aw oc bi"><span id="a2b2" class="mt la it nz b gy od oe l of og">!pip install texthero</span><span id="669c" class="mt la it nz b gy oh oe l of og">import praw<br/>import pandas as pd <br/>import texthero as hero</span><span id="d6a2" class="mt la it nz b gy oh oe l of og">from config import cid, csec, ua #PRAW credentials</span></pre><p id="5ef6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">注意当你第一次导入 Texthero 时，你会看到它从<a class="ae ky" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> NLTK </a>和<a class="ae ky" href="https://spacy.io/" rel="noopener ugc nofollow" target="_blank"> Spacy </a>下载了一些东西:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/1479aeaa7c6296d325e42b284f9acfaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*OoSv-4I7SCdH7-61of7sVQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">初次导入时下载 Texthero</p></figure><h2 id="a2c4" class="mt la it bd lb mu mv dn lf mw mx dp lj ma my mz ll me na nb ln mi nc nd lp ne bi translated">获取一些数据</h2><p id="3f7f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我正在从<strong class="lt iu">教学</strong>子编辑中提取数据，看看我们是否能找出任何与 COVID heavy America 秋季开学有关的主题。</p><pre class="kj kk kl km gt ny nz oa ob aw oc bi"><span id="40d2" class="mt la it nz b gy od oe l of og">#create a reddit connection<br/>reddit = praw.Reddit(client_id= cid,<br/>                     client_secret= csec,<br/>                     user_agent= ua)</span><span id="2a6f" class="mt la it nz b gy oh oe l of og">#list for df conversion<br/>posts = []</span><span id="3bac" class="mt la it nz b gy oh oe l of og">#return 1000 new posts from teaching<br/>new = reddit.subreddit('teaching').new(limit=1000)</span><span id="9027" class="mt la it nz b gy oh oe l of og">#return the important attributes<br/>for post in new:<br/>    posts.append([post.title, post.score, post.num_comments, post.selftext, post.created, post.pinned, post.total_awards_received])</span><span id="f133" class="mt la it nz b gy oh oe l of og">#create a dataframe<br/>df = pd.DataFrame(posts,columns=['title', 'score', 'comments', 'post', 'created', 'pinned', 'total awards'])</span><span id="57c3" class="mt la it nz b gy oh oe l of og">#return top 3 df rows<br/>df.head(3)</span></pre><p id="538c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu"> PRAW </strong>使得从 Reddit 提取数据并将其加载到熊猫数据框架中变得非常容易。<br/>注意我从<strong class="lt iu">教学</strong>拉了 1000 个新岗位。使用<strong class="lt iu"> df.head(3) </strong>，dataframe 的输出看起来会像这样:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/be7e750477d2111f7b39e6cf0fd06773.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G0w00WOM0pqS7LCOGIuocg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据帧的前 3 行</p></figure><h1 id="5800" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">用 Texthero 预处理</h1><p id="d56d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">texthero 库的真正卖点是它简化的预处理管道。记不住正则表达式语法？Texthero 为您报道！只需调用。<strong class="lt iu"> clean() </strong>方法并通过 dataframe 系列:</p><pre class="kj kk kl km gt ny nz oa ob aw oc bi"><span id="9908" class="mt la it nz b gy od oe l of og">df['clean_title'] = hero.clean(df['title'])</span></pre><p id="d080" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">使用 clean()时，它默认运行以下七个函数</p><ol class=""><li id="1436" class="ok ol it lt b lu mn lx mo ma om me on mi oo mm op oq or os bi translated"><code class="fe ot ou ov nz b">fillna(s)</code>用空格替换未赋值的值。</li><li id="6ef3" class="ok ol it lt b lu ow lx ox ma oy me oz mi pa mm op oq or os bi translated"><code class="fe ot ou ov nz b">lowercase(s)</code>小写所有文本。</li><li id="541a" class="ok ol it lt b lu ow lx ox ma oy me oz mi pa mm op oq or os bi translated"><code class="fe ot ou ov nz b">remove_digits()</code>删除所有数字块。</li><li id="beab" class="ok ol it lt b lu ow lx ox ma oy me oz mi pa mm op oq or os bi translated"><code class="fe ot ou ov nz b">remove_punctuation()</code>删除所有字符串.标点(！" #$% &amp; '()*+，-。/:;&lt; = &gt;？@[\]^_`{|}~).</li><li id="903f" class="ok ol it lt b lu ow lx ox ma oy me oz mi pa mm op oq or os bi translated"><code class="fe ot ou ov nz b">remove_diacritics()</code>去除琴弦上的所有重音。</li><li id="2245" class="ok ol it lt b lu ow lx ox ma oy me oz mi pa mm op oq or os bi translated"><code class="fe ot ou ov nz b">remove_stopwords()</code>删除所有停用词。</li><li id="dda0" class="ok ol it lt b lu ow lx ox ma oy me oz mi pa mm op oq or os bi translated"><code class="fe ot ou ov nz b">remove_whitespace()</code>去掉单词之间的所有空格。</li></ol></div><div class="ab cl pb pc hx pd" role="separator"><span class="pe bw bk pf pg ph"/><span class="pe bw bk pf pg ph"/><span class="pe bw bk pf pg"/></div><div class="im in io ip iq"><h2 id="d60f" class="mt la it bd lb mu mv dn lf mw mx dp lj ma my mz ll me na nb ln mi nc nd lp ne bi translated">定制清洗</h2><p id="9b2d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">如果缺省设置不能满足需要，那么创建一个定制的清理管道就非常简单了。例如，如果我想保留<a class="ae ky" href="https://en.wikipedia.org/wiki/Stop_words" rel="noopener ugc nofollow" target="_blank">停用词</a>并阻止包含的词，我可以注释掉<strong class="lt iu"> remove_stopwords </strong>并将<strong class="lt iu">text hero . preprocessing . stem()</strong>添加到管道中:</p><pre class="kj kk kl km gt ny nz oa ob aw oc bi"><span id="2337" class="mt la it nz b gy od oe l of og">from texthero import preprocessing</span><span id="dec4" class="mt la it nz b gy oh oe l of og">#create a custom cleaning pipeline<br/>custom_pipeline = [preprocessing.fillna<br/>                   , preprocessing.lowercase<br/>                   , preprocessing.remove_digits<br/>                   , preprocessing.remove_punctuation<br/>                   , preprocessing.remove_diacritics<br/>                   #, preprocessing.remove_stopwords<br/>                   , preprocessing.remove_whitespace<br/>                   , <strong class="nz iu">preprocessing.stem</strong>]</span><span id="7829" class="mt la it nz b gy oh oe l of og">#pass the custom_pipeline to the pipeline argument<br/>df['clean_title'] = hero.clean(df['title'], pipeline = custom_pipeline)</span><span id="47af" class="mt la it nz b gy oh oe l of og">df.head()</span></pre><p id="5294" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">注意<strong class="lt iu"> custom_pipeline </strong>是一个预处理函数列表。查看文档以获得预处理特性的完整列表！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pi"><img src="../Images/8da13dfc9c888953d8eee4e6c8dcce6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SutoiWA3tMoJ9CTchiXgFQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Clean_title 添加到数据帧</p></figure><h2 id="5351" class="mt la it bd lb mu mv dn lf mw mx dp lj ma my mz ll me na nb ln mi nc nd lp ne bi translated">检查热门词汇</h2><p id="ad6d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">检查顶部单词只有一行代码，这是我喜欢做的事情，看看是否有额外的单词我应该考虑添加到停用单词列表中。Texthero 还没有内置条形图，它只有散点图，所以我将使用<a class="ae ky" href="https://plotly.com/python/plotly-express/" rel="noopener ugc nofollow" target="_blank"><strong class="lt iu">Plotly express</strong></a>来可视化条形图中的顶部单词。</p><pre class="kj kk kl km gt ny nz oa ob aw oc bi"><span id="535e" class="mt la it nz b gy od oe l of og">tw = hero.visualization.top_words(df['clean_title']).head(10)</span><span id="dd50" class="mt la it nz b gy oh oe l of og">import plotly.express as px</span><span id="1b75" class="mt la it nz b gy oh oe l of og">fig = px.bar(tw)<br/>fig.show()<br/>tw.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/e0674d8c593a38efa8086df05f6227bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ppaNaHTWDUDA7-SY9dlBNw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">热门词汇图</p></figure><h2 id="8432" class="mt la it bd lb mu mv dn lf mw mx dp lj ma my mz ll me na nb ln mi nc nd lp ne bi translated">添加新的停用字词</h2><p id="a2ef" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Stemming" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> <em class="ms">词干</em> </strong> </a>这些词加上“<strong class="lt iu">’</strong>”(老师和学生之间注意一下)这些停用词应该给我更多独特的词。词干已经添加到自定义管道中，但需要添加停止词。使用两个列表上的<strong class="lt iu">联合</strong>可将停用词添加到停用词列表中:</p><pre class="kj kk kl km gt ny nz oa ob aw oc bi"><span id="5174" class="mt la it nz b gy od oe l of og">from texthero import stopwords</span><span id="dba0" class="mt la it nz b gy oh oe l of og">default_stopwords = stopwords.DEFAULT</span><span id="8219" class="mt la it nz b gy oh oe l of og">#add a list of stopwords to the stopwords<br/>custom_stopwords = default_stopwords.union(set(["'"]))</span><span id="9251" class="mt la it nz b gy oh oe l of og">#Call remove_stopwords and pass the custom_stopwords list<br/>df['clean_title'] = hero.remove_stopwords(df['clean_title'], custom_stopwords)</span></pre><p id="74d9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">注意，custom_stopwords 列表被传递到<strong class="lt iu"> hero.remove_stopwords()中。我将重新可视化它并检查结果！</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pk"><img src="../Images/e2996b5265f0ef23177c281d68adf598.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ji_gIYbzVIlmRyUBxRFVGQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">阻止结果</p></figure><p id="f03e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在使用词干和额外的停用词后，结果看起来好一点了！</p><h1 id="5c7d" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">建造管道</h1><p id="d1cc" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">感谢<a class="ae ky" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pipe.html" rel="noopener ugc nofollow" target="_blank">熊猫的<strong class="lt iu">。pipe() </strong> </a>，把 Texthero 模块组件链接在一起超级简单。为了形象化题目，我准备用<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html?highlight=pca#sklearn.decomposition.PCA" rel="noopener ugc nofollow" target="_blank"> <em class="ms">主成分分析</em> </a>来压缩向量空间。我也准备运行<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html?highlight=kmeans#sklearn.cluster.KMeans" rel="noopener ugc nofollow" target="_blank"> <em class="ms"> K-means </em> </a>聚类来增色。记住，Texthero 将一个<em class="ms">系列</em>作为输入，将<em class="ms">系列</em>作为输出，这样我可以将输出设置为 dataframe 中的一个新列。</p><pre class="kj kk kl km gt ny nz oa ob aw oc bi"><span id="f2a7" class="mt la it nz b gy od oe l of og">#Add pca value to dataframe to use as visualization coordinates<br/>df['pca'] = (<br/>            df['clean_title']<br/>            .pipe(hero.tfidf)<br/>            .pipe(hero.pca)<br/>   )</span><span id="895c" class="mt la it nz b gy oh oe l of og">#Add k-means cluster to dataframe <br/>df['kmeans'] = (<br/>            df['clean_title']<br/>            .pipe(hero.tfidf)<br/>            .pipe(hero.kmeans)<br/>   )</span><span id="c97e" class="mt la it nz b gy oh oe l of og">df.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/b0c782932a90cfc6ffd13dfb22424f77.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*4OuGLGczJQBUBYFvC8QcZQ.png"/></div></figure><p id="02b2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">只用几行代码就应用了 PCA 和 K-means 聚类！现在可以使用<strong class="lt iu"> hero.scatterplot() </strong>将数据可视化</p><pre class="kj kk kl km gt ny nz oa ob aw oc bi"><span id="8491" class="mt la it nz b gy od oe l of og">#generate scatter plot<br/>hero.scatterplot(df, 'pca', color = 'kmeans', hover_data=['title'] )</span></pre><p id="7961" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">因为它在引擎盖下使用了 Plotly，散点图就像你所期望的那样具有交互性！可以根据需要放大。现在是时候探索视觉化的结果，看看可以获得什么样的洞见了！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pm"><img src="../Images/d09d354d48508c55437cb6f2f62c1e27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cvLTeFhTOjM6wCyiHQ84kQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">标题散点图</p></figure><h1 id="5f86" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">最后的想法</h1><p id="fa14" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">虽然该库仍处于测试阶段，但我看到了 Texthero 充满希望的未来，并希望它得到应有的爱。它使得清理和准备熊猫数据框中的文本变得轻而易举。我希望增加一些可视化选项，但是散点图是一个很好的开始。如果您有兴趣了解更多关于自然语言处理的知识，请查看我的其他文章，这些文章涵盖了一些基础和高级主题。</p><div class="nf ng gp gr nh ni"><a rel="noopener follow" target="_blank" href="/the-simple-approach-to-word-embedding-for-natural-language-processing-using-python-ae028c8dbfd2"><div class="nj ab fo"><div class="nk ab nl cl cj nm"><h2 class="bd iu gy z fp nn fr fs no fu fw is bi translated">用 Python 实现自然语言处理中单词嵌入的简单方法</h2><div class="np l"><h3 class="bd b gy z fp nn fr fs no fu fw dk translated">使用 Gensim 和 Plotly 探索单词嵌入</h3></div><div class="nq l"><p class="bd b dl z fp nn fr fs no fu fw dk translated">towardsdatascience.com</p></div></div><div class="nr l"><div class="pn l nt nu nv nr nw ks ni"/></div></div></a></div><div class="nf ng gp gr nh ni"><a rel="noopener follow" target="_blank" href="/3-super-simple-projects-to-learn-natural-language-processing-using-python-8ef74c757cd9"><div class="nj ab fo"><div class="nk ab nl cl cj nm"><h2 class="bd iu gy z fp nn fr fs no fu fw is bi translated">使用 Python 学习自然语言处理的 3 个超级简单的项目</h2><div class="np l"><h3 class="bd b gy z fp nn fr fs no fu fw dk translated">单词云、垃圾邮件检测和情感分析的简单代码示例</h3></div><div class="nq l"><p class="bd b dl z fp nn fr fs no fu fw dk translated">towardsdatascience.com</p></div></div><div class="nr l"><div class="po l nt nu nv nr nw ks ni"/></div></div></a></div><div class="nf ng gp gr nh ni"><a rel="noopener follow" target="_blank" href="/using-python-to-analyze-the-brutal-lyrics-of-the-black-dahlia-murder-with-genius-api-spacy-bfc7e0e8577f"><div class="nj ab fo"><div class="nk ab nl cl cj nm"><h2 class="bd iu gy z fp nn fr fs no fu fw is bi translated">用 Python 分析《黑色大丽花谋杀案》的残暴歌词用 Genius API，SpaCy…</h2><div class="np l"><h3 class="bd b gy z fp nn fr fs no fu fw dk translated">利用自然语言处理和词性标注发现《死亡金属》中的主题</h3></div><div class="nq l"><p class="bd b dl z fp nn fr fs no fu fw dk translated">towardsdatascience.com</p></div></div><div class="nr l"><div class="pp l nt nu nv nr nw ks ni"/></div></div></a></div><h2 id="793a" class="mt la it bd lb mu mv dn lf mw mx dp lj ma my mz ll me na nb ln mi nc nd lp ne bi translated">完全码</h2><p id="8e82" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">感谢阅读。以下是完整的代码:</p><pre class="kj kk kl km gt ny nz oa ob aw oc bi"><span id="e3c7" class="mt la it nz b gy od oe l of og">#create a reddit connection<br/>reddit = praw.Reddit(client_id= cid,<br/>                     client_secret= csec,<br/>                     user_agent= ua)<br/>#list for df conversion<br/>posts = []</span><span id="8b62" class="mt la it nz b gy oh oe l of og">#return 1000 new posts from teaching<br/>new = reddit.subreddit('teaching').new(limit=1000)</span><span id="9aa2" class="mt la it nz b gy oh oe l of og">#return the important attributes<br/>for post in new:<br/>    posts.append([post.title, post.score, post.num_comments, post.selftext, post.created, post.pinned, post.total_awards_received])</span><span id="425b" class="mt la it nz b gy oh oe l of og">#create a dataframe<br/>df = pd.DataFrame(posts,columns=['title', 'score', 'comments', 'post', 'created', 'pinned', 'total awards'])</span><span id="f667" class="mt la it nz b gy oh oe l of og">#return top 3 df rows<br/>df.head(3)</span><span id="51fc" class="mt la it nz b gy oh oe l of og">from texthero import preprocessing</span><span id="59ae" class="mt la it nz b gy oh oe l of og">custom_pipeline = [preprocessing.fillna<br/>                   , preprocessing.lowercase<br/>                   , preprocessing.remove_digits<br/>                   , preprocessing.remove_punctuation<br/>                   , preprocessing.remove_diacritics<br/>                   , preprocessing.remove_stopwords<br/>                   , preprocessing.remove_whitespace<br/>                   , preprocessing.stem]</span><span id="1c85" class="mt la it nz b gy oh oe l of og">df['clean_title'] = hero.clean(df['title'], pipeline = custom_pipeline)<br/>df.head()</span><span id="3f6a" class="mt la it nz b gy oh oe l of og">from texthero import stopwords</span><span id="2f29" class="mt la it nz b gy oh oe l of og">default_stopwords = stopwords.DEFAULT<br/>custom_stopwords = default_stopwords.union(set(["'"]))</span><span id="8bfa" class="mt la it nz b gy oh oe l of og">df['clean_title'] = hero.remove_stopwords(df['clean_title'], custom_stopwords)</span><span id="9bb9" class="mt la it nz b gy oh oe l of og">hero.visualization.top_words(df['clean_title'])</span><span id="8421" class="mt la it nz b gy oh oe l of og">tw = hero.visualization.top_words(df['clean_title']).head(10)</span><span id="ea33" class="mt la it nz b gy oh oe l of og">import plotly.express as px</span><span id="1546" class="mt la it nz b gy oh oe l of og">fig = px.bar(tw)<br/>fig.show()</span><span id="09b5" class="mt la it nz b gy oh oe l of og">df['pca'] = (<br/>            df['clean_title']<br/>            .pipe(hero.tfidf)<br/>            .pipe(hero.pca)<br/>   )</span><span id="e438" class="mt la it nz b gy oh oe l of og">df['kmeans'] = (<br/>            df['clean_title']<br/>            .pipe(hero.tfidf)<br/>            .pipe(hero.kmeans)<br/>   )</span><span id="1232" class="mt la it nz b gy oh oe l of og">hero.scatterplot(df, 'pca', color = 'kmeans', hover_data=['title'] )</span></pre><h1 id="d710" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">谢谢大家！</h1><ul class=""><li id="88b4" class="ok ol it lt b lu lv lx ly ma pq me pr mi ps mm pt oq or os bi translated"><em class="ms">如果你喜欢这个，</em> <a class="ae ky" href="https://medium.com/@erickleppen" rel="noopener"> <em class="ms">跟我上媒</em> </a> <em class="ms">了解更多</em></li><li id="8803" class="ok ol it lt b lu ow lx ox ma oy me oz mi pa mm pt oq or os bi translated"><a class="ae ky" href="https://erickleppen.medium.com/membership" rel="noopener"> <em class="ms">通过订阅</em> </a>获得完全访问权限并帮助支持我的内容</li><li id="9f21" class="ok ol it lt b lu ow lx ox ma oy me oz mi pa mm pt oq or os bi translated"><em class="ms">我们连线上</em><a class="ae ky" href="https://www.linkedin.com/in/erickleppen01/" rel="noopener ugc nofollow" target="_blank"><em class="ms">LinkedIn</em></a></li><li id="9c79" class="ok ol it lt b lu ow lx ox ma oy me oz mi pa mm pt oq or os bi translated"><em class="ms">用 Python 分析数据？查看我的</em> <a class="ae ky" href="https://pythondashboards.com/" rel="noopener ugc nofollow" target="_blank"> <em class="ms">网站</em> </a></li></ul><p id="8ad1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><a class="ae ky" href="http://pythondashboards.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> —埃里克·克莱彭</strong> </a></p></div></div>    
</body>
</html>