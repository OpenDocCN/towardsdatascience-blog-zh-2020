<html>
<head>
<title>Spark Streaming for Beginners</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">面向初学者的火花流</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/spark-streaming-for-beginners-a0170113e479?source=collection_archive---------7-----------------------#2020-07-23">https://towardsdatascience.com/spark-streaming-for-beginners-a0170113e479?source=collection_archive---------7-----------------------#2020-07-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8dbf" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">对 Spark 流概念的理解和使用 Java API 对初学者的代码演示。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/0d80dd237d059863b2b147db8321da73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jVKsZjucxOyWWbEWh1I2hw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">萨法尔·萨法罗夫在 Unsplash.com<a class="ae kv" href="https://unsplash.com/photos/MSN8TFhJ0is" rel="noopener ugc nofollow" target="_blank">拍摄的照片</a></p></figure><p id="7b62" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Spark 被认为是处理大量数据的高速引擎，比 MapReduce 快 100 倍。之所以如此，是因为它使用分布式数据处理，通过这种处理，它将数据分成更小的块，以便可以跨机器并行计算数据块，从而节省时间。此外，它使用内存处理，而不是基于磁盘的处理，这使得计算速度更快。</p><p id="d8bc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Spark Streaming 是大数据生态系统中最重要的部分之一。这是一个来自 Apache Spark Foundation 的软件框架，用于管理大数据。基本上，它实时吸收来自 Twitter 等来源的数据，使用函数和算法对其进行处理，然后将其存储在数据库和其他地方。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ls"><img src="../Images/f5461b2abda79a2316c406f0dbbc102f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*UggSk-9kQfjKL5fjp4QVyA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:spark.apache.org<a class="ae kv" href="https://spark.apache.org/docs/latest/streaming-programming-guide.html" rel="noopener ugc nofollow" target="_blank"/></p></figure><h1 id="d71e" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">如何启动火花流？</h1><h2 id="277b" class="ml lu iq bd lv mm mn dn lz mo mp dp md lf mq mr mf lj ms mt mh ln mu mv mj mw bi translated">配置火花</h2><p id="02fd" class="pw-post-body-paragraph kw kx iq ky b kz mx jr lb lc my ju le lf mz lh li lj na ll lm ln nb lp lq lr ij bi translated">首先，我们配置 spark，告诉它从哪里接收数据，是从本地目录、spark 集群、mesos 集群还是 kubernetes 集群。如果你不熟悉这些术语，不要担心。基本上，这些是集群管理系统，spark 需要这些系统来处理诸如检查节点健康状况和调度作业之类的任务。如果您选择您的本地目录作为主目录，您需要从您的本地机器中指定您希望 spark 在其上运行的核心的数量。运行的内核越多，性能就越快。如果指定*，则意味着使用系统中的所有内核。然后我们指定 app name，这是我们给 spark 应用程序起的名字。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="1313" class="ml lu iq nd b gy nh ni l nj nk">SparkConf conf = new SparkConf().setAppName(“SparkApp”).setMaster(“local[*]”);</span></pre><h2 id="d6b0" class="ml lu iq bd lv mm mn dn lz mo mp dp md lf mq mr mf lj ms mt mh ln mu mv mj mw bi translated">创建流式上下文对象</h2><p id="674f" class="pw-post-body-paragraph kw kx iq ky b kz mx jr lb lc my ju le lf mz lh li lj na ll lm ln nb lp lq lr ij bi translated">然后，我们创建一个 Java 流上下文的对象，它有点像打开了流开始的大门。它提供了从输入源创建 JavaDStream 和 JavaPairDStream 的方法，我们将进一步讨论这些方法。在创建 Java 流上下文对象时，我们需要指定批处理间隔；基本上，spark streaming 将传入的数据分成几批，因此最终结果也是成批生成的。一个<strong class="ky ir">批处理间隔</strong>告诉 spark 你需要获取数据多长时间，比如如果是 1 分钟，它将获取最后 1 分钟的数据。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/f8239049263085472c1204eb5487758f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*BbR7wqfzs8pTOOSIcZ-aTg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:<a class="ae kv" href="https://spark.apache.org/docs/latest/streaming-programming-guide.html" rel="noopener ugc nofollow" target="_blank">spark.apache.org</a></p></figure><p id="4008" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以数据将开始成批地涌入一个流中，这个连续的数据流被称为<strong class="ky ir"> DStream </strong>。每一批数据流都包含可以并行处理的元素的集合，这个集合被称为<strong class="ky ir"> RDD </strong>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/50b1c97774860e363ebb616cdd92ff8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*p3U__F7ztdmvQR99Hg1-Vw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:spark.apache.org<a class="ae kv" href="https://spark.apache.org/docs/latest/streaming-programming-guide.html" rel="noopener ugc nofollow" target="_blank"/></p></figure><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="2d79" class="ml lu iq nd b gy nh ni l nj nk">JavaStreamingContext jssc = new JavaStreamingContext(conf, Durations.seconds(60));</span></pre><h1 id="adec" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">开始传输数据</h1><p id="5d77" class="pw-post-body-paragraph kw kx iq ky b kz mx jr lb lc my ju le lf mz lh li lj na ll lm ln nb lp lq lr ij bi translated">为了接收数据，流式上下文提供了从 TCP 套接字连接或作为输入源的文件流式传输数据的方法。这些源可以是像 HDFS、S3 等的源。要读取 textfiles，有 javastreamingcontext 的 textFileStream 方法。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="0f4f" class="ml lu iq nd b gy nh ni l nj nk">JavaDStream&lt;String&gt; lines = jssc.textFileStream(“C:\\Users\\HP\\Downloads\\Spark_Streams”);</span></pre><p id="14d6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是在流式上下文启动之前，您将无法读取目录中已经存在的文件，因为它只读取新创建的文件。</p><p id="6ea7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以在这里，我将通过端口 9999 通过套接字连接传输数据，并用它创建一个 java 接收器输入数据流。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="b860" class="ml lu iq nd b gy nh ni l nj nk">JavaReceiverInputDStream&lt;String&gt; lines = jssc.socketTextStream(“localhost”, 9999);</span></pre><p id="6ddb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以现在，如果你建立一个套接字连接，在终端中写一些东西，并运行 dstream，你会看到文本出现在控制台中。</p><p id="7454" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意:要启动一个 java 流上下文，我们需要告诉 spark 启动它，等待计算终止，然后停止它。我们需要通过 print()方法打印数据流。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="103f" class="ml lu iq nd b gy nh ni l nj nk">lines.print();</span><span id="168c" class="ml lu iq nd b gy nn ni l nj nk">jssc.start();</span><span id="94e2" class="ml lu iq nd b gy nn ni l nj nk">jssc.awaitTermination();</span><span id="e67c" class="ml lu iq nd b gy nn ni l nj nk">jssc.stop();</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/9e7fd37e6e94915b7c6b20314b46f3fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*JBoAPLT--UXzvvmG9FC9tQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">通过 TCP 套接字输入</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/ac7bb236e3cf06a38b0b90f3e8bfcda8.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*b8cZcUr5WKVGtVqKQ8c_FQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">控制台中的输出</p></figure><p id="a390" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，它在时间 t1 打印输出，但在时间 t2 和 t3 没有输出，因为它每分钟都获取数据。在下一个批处理间隔中，它没有接收到任何输入，所以它不打印任何东西。</p><p id="f402" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我将向您展示如何使用 lanbda 函数对这些数据流进行一些转换。</p><h1 id="c525" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">地图变换</h1><p id="cb7e" class="pw-post-body-paragraph kw kx iq ky b kz mx jr lb lc my ju le lf mz lh li lj na ll lm ln nb lp lq lr ij bi translated">地图转换应用我们在数据流上指定的函数，并为每个输入值生成一个输出值。所以它基本上将一个流转换成另一个流。就像这里，我想计算文本行的长度，所以我将使用地图转换。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="8d46" class="ml lu iq nd b gy nh ni l nj nk">JavaDStream&lt;Integer&gt; length = lines.map(x -&gt; x.length());</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/49dc7bde9d659604ef5848beaf83b9eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*mPCL13F8aLG6VPmtrDuVnw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">投入</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/e46d8faa0fe712160a1731bc799a9f5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*HJM8Sk1kZpDe1Zifx1Xa6Q.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">它计算文本行的长度</p></figure><h1 id="5263" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">平面图变换</h1><p id="0f9c" class="pw-post-body-paragraph kw kx iq ky b kz mx jr lb lc my ju le lf mz lh li lj na ll lm ln nb lp lq lr ij bi translated">FlatMap 转换将函数应用于 DStream，但可以为每个输入值生成一个或多个输出值。因此，如果我想转换 RDD，使其产生多个值，我将使用平面图转换。</p><p id="edfc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以我在这里输入了一行文字“嗨，你好吗”，我想把它分成几个单词。我用了 lambda 函数。FlatMap 转换返回任意数量的值，这取决于 rdd 和应用的函数，因此返回类型必须是值流。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="705b" class="ml lu iq nd b gy nh ni l nj nk">JavaDStream words = lines.flatMap(x -&gt; Arrays.asList(x.split(“ “)).iterator());</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/6b804e0bdf390da4179ad22b1433e4ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*nUPRpL2P8ibOsPh06d17sg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">它将这一行拆分成单词</p></figure><h1 id="acf5" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">减少变形</h1><p id="809c" class="pw-post-body-paragraph kw kx iq ky b kz mx jr lb lc my ju le lf mz lh li lj na ll lm ln nb lp lq lr ij bi translated">reduce 变换聚合每个 RDD 中的元素。它接受单元素 rdd 的两个参数并返回一个。</p><p id="e28b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里，在我们应用平面映射函数并返回单词流之后，我将应用 reduce 变换来获得每个 RDD 中长度最大的单词。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="a455" class="ml lu iq nd b gy nh ni l nj nk">JavaDStream&lt;String&gt; reduce = words.reduce((a,b) -&gt; {</span><span id="7204" class="ml lu iq nd b gy nn ni l nj nk">String max_length_word;</span><span id="dade" class="ml lu iq nd b gy nn ni l nj nk">if(a.length() &gt;= b.length()) {</span><span id="baee" class="ml lu iq nd b gy nn ni l nj nk">max_length_word = a;</span><span id="2ea4" class="ml lu iq nd b gy nn ni l nj nk">}else {</span><span id="dd50" class="ml lu iq nd b gy nn ni l nj nk">max_length_word = b;</span><span id="a04b" class="ml lu iq nd b gy nn ni l nj nk">}</span><span id="06a1" class="ml lu iq nd b gy nn ni l nj nk">return max_length_word;</span><span id="118c" class="ml lu iq nd b gy nn ni l nj nk">});</span></pre><p id="cc92" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请试着理解这段代码，它接受 String 类型的参数，其中每个 RDD 中的单词根据它们的长度进行聚合，返回长度最大的单词。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/191f967d3fa3fef858db6d5d976008b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*OylugxfeS1hDfk7Z62siVg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">投入</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/dffbcba1458e4f97c05d75cce96a7d06.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*kiY1UNcEykuodk68rUXutg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">它返回每批中最大长度的单词</p></figure><h1 id="5850" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">过滤变换</h1><p id="de6d" class="pw-post-body-paragraph kw kx iq ky b kz mx jr lb lc my ju le lf mz lh li lj na ll lm ln nb lp lq lr ij bi translated">过滤转换根据给定的函数过滤数据流。就像在平面图转换之后，假设我想从单词流中过滤出单词 hello。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="f672" class="ml lu iq nd b gy nh ni l nj nk">JavaDStream&lt;String&gt; filter = words.filter(x -&gt; !x.equals(“hello”));</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/9fa813bb02d0ec498bf6ccfa14c7515c.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*eyo0j2DKBJjER-PZYkm0Tg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">投入</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/b7bddf4c85fb57290727fb1cbc72795b.png" data-original-src="https://miro.medium.com/v2/resize:fit:534/format:webp/1*arDpNL1Z2Pxiy5udbMeqtA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">它过滤“你好”这个词</p></figure><p id="5e04" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，单词“Hello”没有被过滤，因为它包含大写字母，这是我们在代码中没有指定的。</p><h1 id="43cd" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">映射对变换</h1><p id="760e" class="pw-post-body-paragraph kw kx iq ky b kz mx jr lb lc my ju le lf mz lh li lj na ll lm ln nb lp lq lr ij bi translated">mapToPair 转换将每个输入值转换为一对值。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="5e76" class="ml lu iq nd b gy nh ni l nj nk">JavaPairDStream&lt;String, Integer&gt; pairs = filter.mapToPair(x -&gt; new Tuple2&lt;String, Integer&gt;(x, 1));</span></pre><p id="59e2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意，这里创建的对象是 JavaPairDStream 而不是 DStream，因为我们在流中返回对。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/9bf9ebf57a3bb40ba866ac662e11a431.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*L3PepcWAEGkUYbrRIaiHXg.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/6a7cb41301c353faeecfd9a8756722b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:444/format:webp/1*lKl1iDenjfJm4XMqbxdkFA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">它返回单词和整数 1</p></figure><h1 id="25b7" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">ReduceByKey 变换</h1><p id="6c66" class="pw-post-body-paragraph kw kx iq ky b kz mx jr lb lc my ju le lf mz lh li lj na ll lm ln nb lp lq lr ij bi translated">在数据流中，我们可以使用 reduceByKey 在 key 的基础上聚集 rdd 的元素。与 reduce 转换不同，它采用成对的 rdd，而不是单元素 rdd。就像这里，它采用了一个字符串和整数的元组，我们正在合计一个单词在 RDD 中出现的次数。它接受两个参数并返回一个。但是在指定调用类型时，我们没有指定 tuple <string integer="">，我们只是指定了 Integer，因为 reduce by key 本身会注意到这个键，并根据指定的函数对它进行聚合。</string></p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="f610" class="ml lu iq nd b gy nh ni l nj nk">JavaPairDStream&lt;String, Integer&gt; sum = pairs.reduceByKey((a,b) -&gt; a + b);</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/da22fc456faea196ef1c52f3c4846385.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*9WkFwTk9oprmrLSIzHq8ng.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/4991da4d4ff348f4af8381ccf4c5812d.png" data-original-src="https://miro.medium.com/v2/resize:fit:466/format:webp/1*fCUnWjFu7V9KgwZ0HASxCQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">对于每个单词，它根据单词出现的次数对整数 1 求和</p></figure><h1 id="861e" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">计数变换</h1><p id="f80f" class="pw-post-body-paragraph kw kx iq ky b kz mx jr lb lc my ju le lf mz lh li lj na ll lm ln nb lp lq lr ij bi translated">计数转换计算每个 RDD 中的元素数，并返回包含单个元素 rdd 的数据流。</p><p id="530c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在应用平面图转换后，我们想知道每个 RDD 的字数。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="ede4" class="ml lu iq nd b gy nh ni l nj nk">JavaDStream&lt;Long&gt; count = words.count();</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/6f2320db654769d3ee47212d389fa9b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*Ls6EAbnxuZT1wiZcCqR3ww.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/895300690b05644f2964432008e089e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:520/format:webp/1*kMc2F53HtyqfQsAuyKhJ_w.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">它返回文本行中的字数</p></figure><p id="a48a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以 RDD 中的单词数是 13，所以它返回 13 作为输出。这是在应用了将单词行分割成单个单词的 flatMap 之后。如果我们不拆分单词就申请，看看我们会得到什么。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi od"><img src="../Images/5c06a70350da2da9cad3d0d508e50367.png" data-original-src="https://miro.medium.com/v2/resize:fit:846/format:webp/1*Qdfrt2qqoi1GHQdolLj7pg.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/912fda4062e7d731efeac4e69ccfea43.png" data-original-src="https://miro.medium.com/v2/resize:fit:890/format:webp/1*NfIr_XnEQqZLJGyfTY1pNw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">它返回它在每批中接收的行数</p></figure><p id="e320" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于我们没有将这一行单词分割成单个的单词，spark 将整行单词视为一个单一的元素。在第一批中，它接收 3 行，因此它返回计数为 3，在接下来的批中，它接收 2 行和 6 行，因此计数分别为 3 和 6。</p><h1 id="de1c" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">计数值转换</h1><p id="928f" class="pw-post-body-paragraph kw kx iq ky b kz mx jr lb lc my ju le lf mz lh li lj na ll lm ln nb lp lq lr ij bi translated">countByValue 获取 k 类型的数据流，并计算该键在 RDD 中出现的次数，然后返回(k，Value)对的 PairedDStream。</p><p id="0998" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里，在我用 flatMap 分割了单词行之后，我应用了 countByValue 转换。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="2f50" class="ml lu iq nd b gy nh ni l nj nk">JavaPairDStream&lt;String, Long&gt; countByValue = words.countByValue();</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi of"><img src="../Images/51a256a50c26e7a5e4ef33b1f1bcbb3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:842/format:webp/1*nw3xwVJgx4F4cBmdAFjhRQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">投入</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/c412460246ac219fe6e6496eca5a7cc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:436/format:webp/1*zamyjLhcigZtQWghiZKANA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">它计算一个单词在 RDD 中出现的次数</p></figure><p id="53b0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我将向您展示我们可以在 rdd 上执行的一些操作。所以基本上我们是在包含 rdd 的数据流上应用转换，当我们指定一个转换时，我们是在那些 rdd 上应用函数。spark 提供了一些我们可以在这些 rdd 上应用的操作。</p><p id="c70d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">假设我想将应用 countByValue 后得到的键值对按降序排列。我能做的是交换那些键值对，然后排序，我会进一步展示。使用 mapToPair 转换，我在 RDDs 上使用 swap 操作来将其更改为(Long，String)对。</p><h1 id="ea5d" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">交换动作</h1><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="5377" class="ml lu iq nd b gy nh ni l nj nk">JavaPairDStream&lt;Long, String&gt; swap = countByValue.mapToPair(x -&gt; x.swap());</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/0606df54e49a0cd8eba644395bd57a24.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*0Y250TH9c8VRK1WVbmQZjw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">投入</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/73a71e84f2ef5a05f366fd9df5788c49.png" data-original-src="https://miro.medium.com/v2/resize:fit:436/format:webp/1*nFxCC_2Lz6PsJmVLYHr_mg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">交换动作交换键值对</p></figure><h1 id="c3be" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">SortByKey 操作</h1><p id="cc76" class="pw-post-body-paragraph kw kx iq ky b kz mx jr lb lc my ju le lf mz lh li lj na ll lm ln nb lp lq lr ij bi translated">现在要按降序排列这些值，我可以使用 RDD 的 sortByKey 变换。它将按照指定的布尔值按升序或降序排序。如果我们不指定布尔值，默认情况下它将按升序排序。</p><h1 id="c5d3" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">变换对变换</h1><p id="3102" class="pw-post-body-paragraph kw kx iq ky b kz mx jr lb lc my ju le lf mz lh li lj na ll lm ln nb lp lq lr ij bi translated">现在要使用 sortByKey，我将使用 transformToPair 转换。transform 函数通过对每个 RDD 应用 RDD 到 RDD 变换来返回新的数据流。这里我想返回 PairedDStream，所以我将使用 transformToPair。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="9dfe" class="ml lu iq nd b gy nh ni l nj nk">JavaPairDStream&lt;Long, String&gt; sort = swap.transformToPair(x -&gt; x.sortByKey(false));</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/b1a499304703847eb2bba27cdbad1d0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*TgaG4bbHkZ1UaG3RLWprsA.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/7052d92c656f5ed256119d7b692ae4d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:262/format:webp/1*0CkePjpvR0-6ubG1Cb--6w.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">它按降序对键进行排序</p></figure><p id="fd8d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我可以再次使用 mapToPair 交换单词对，将单词作为键，将计数作为值。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="188c" class="ml lu iq nd b gy nh ni l nj nk">JavaPairDStream&lt;String, Long&gt; swap_again = sort.mapToPair(x -&gt; x.swap());</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/0e172ebce70ab6ac4a4db310d3dae153.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*qyHzrwW5EhDZxuQeDtyYWA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">投入</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/0ec0f23092c4455d07d67e8fc2f9328f.png" data-original-src="https://miro.medium.com/v2/resize:fit:416/format:webp/1*r3ycu66yB18vCBMeGWrBTQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">它又被交换了</p></figure><p id="2f13" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是 spark 流如何工作的概述，以及我们如何将转换应用于数据流的几个例子。感谢阅读！！！有疑问可以在评论区问我。</p></div></div>    
</body>
</html>