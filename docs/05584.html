<html>
<head>
<title>SinGAN: Training GAN from a Single Image.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">SinGAN:从单个图像训练 GAN。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/singan-training-gan-from-a-single-image-cdd965af4406?source=collection_archive---------26-----------------------#2020-05-10">https://towardsdatascience.com/singan-training-gan-from-a-single-image-cdd965af4406?source=collection_archive---------26-----------------------#2020-05-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="e68b" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">生成网络解释</h2><div class=""/><div class=""><h2 id="1388" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">没有足够的数据来训练你的生成网络？辛甘是来帮忙的。</h2></div><h1 id="49c2" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">介绍</h1><p id="ae47" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated"><strong class="ll jd"> GANs </strong>是一种生成网络，可以从潜在向量(“或分布”)中生成逼真的图像。通常，GAN 由两个网络组成:生成器(G ),其目的是将潜在代码映射到图像；鉴别器(D ),其任务是评估图像是来自原始数据集(真实图像)还是由其他网络生成(虚假图像)。与鉴别器对抗，生成器试图愚弄它，从潜在向量生成新图像，因此鉴别器认为它们是真实图像。</p><p id="de92" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">而<strong class="ll jd"> SinGAN </strong>是 GAN 的变体，其中网络必须从单个自然图像中学习，这与以前版本的 GAN 形成对比，因为它们有多个真实图像来学习表示。SinGAN 是一个无条件的生成模型，它可以学习单个图像中面片的内部统计信息。正如本文的<strong class="ll jd">结果</strong>部分所示，SinGAN 在各种图像处理任务上显示了令人印象深刻的结果。</p><h1 id="e452" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">体系结构</h1><p id="f157" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">SinGAN 架构由多尺度流水线组成，其中存在一对生成器和鉴别器，学习不同尺度的表示。它们可以以由粗到细的方式进行训练，其中最低尺度的生成器和鉴别器学习背景和材料等粗糙特征，而在高尺度下，它们学习边缘和拐角等非常精细的细节。</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi mk"><img src="../Images/f8add8d5e83310e4fe71dd7700392818.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S6G3JSAmS3Z_dajl88MwXw.png"/></div></div><p class="mw mx gj gh gi my mz bd b be z dk translated">新加坡建筑</p></figure><p id="8f72" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">源图像被缩减采样到相应的大小，并与发生器的输出一起输入鉴别器。并且随机噪声连同从它们下面的发生器生成的图像一起被馈送到发生器(除了最后一个，它仅被馈送随机噪声)。</p><p id="3689" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">因为我们只处理一个源图像，所以我们将来自下采样源图像的一组补片视为我们的真实图像数据集。“您可以将 patch 视为一个滑动窗口，它悬停在图像上方并收集样本”。通常，所有大小的补丁区域保持不变，但是对于更高的网络，随着图像变得越来越大，有效的补丁大小会减小。</p><p id="e5d5" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">如果我们仔细观察发生器，随机噪声向量与从下面生成的图像(向上采样为噪声形状)连接在一起，并馈入 5 个后续卷积层，卷积层的输出再次与从下面生成的图像连接。这将输出一个新的图像，与真实图像(下采样)一起进一步发送到鉴别器进行评估。</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div class="gh gi na"><img src="../Images/ab42b6d0fe94507fff610bc1ea0a26dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/1*B7xWkk0b5YD5r6KdW79uwQ.png"/></div><p class="mw mx gj gh gi my mz bd b be z dk translated">辛甘的典型发电机</p></figure><p id="ea12" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">辛甘的典型发电机，每个区块:</p><p id="a11a" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated"><strong class="ll jd">噪点+g _ image-&gt;5x(conv)+g _ image-&gt;输出</strong>。</p><p id="fcab" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">其中 g_image 是从先前的生成器生成的图像，Conv 是<strong class="ll jd">conv(3x 3)-&gt;batch norm-&gt;LeakyReLU。</strong></p><p id="ec0b" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">对于鉴别器，生成的图像和源图像(下采样)被馈送用于评估。鉴别器由五个卷积层组成，与发生器一样，但没有级联。</p><h1 id="f73d" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">训练和损失函数</h1><p id="1fc4" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated"><strong class="ll jd">网络</strong>按顺序训练，从最低级别开始，上升到最高级别。首先训练最小尺寸的发生器和鉴别器得到粗特征，然后训练下一个尺寸的网络，依此类推。一旦每个 GAN 被训练，它就保持固定，并且所有子网 GAN 以传统(对抗)方式被训练。</p><p id="04d6" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">训练包括两个损失函数的组合。</p><ol class=""><li id="71d4" class="nb nc it ll b lm mf lp mg ls nd lw ne ma nf me ng nh ni nj bi translated"><strong class="ll jd">对抗性损失:</strong>对抗性损失用于惩罚网络，通过计算真实数据分布与生成器预测数据分布之间的距离，使预测样本分布与原始样本分布相匹配。最初的实现使用 WGAN-GP 丢失，他们发现这可以增加稳定性。这个损失在这里得到了很好的解释<a class="ae nk" href="https://machinelearningmastery.com/how-to-implement-wasserstein-loss-for-generative-adversarial-networks/" rel="noopener ugc nofollow" target="_blank">。</a></li><li id="3797" class="nb nc it ll b lm nl lp nm ls nn lw no ma np me ng nh ni nj bi translated"><strong class="ll jd">重构损失:</strong>顾名思义，重构损失是用来惩罚网络生成看起来像原始样本的样本。这种损失很重要，因为噪声矢量被输入发电机。最初的实现使用 RMSE(均方根误差)损失。</li></ol><h1 id="a1e5" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">结果</h1><p id="b1cc" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">如下图所示，第一列作为网络的输入，所有后续图像都是网络的输出。所有生成的样本都具有相同的高层次特征，如第一行是山脉、湖泊和沙子，第二行是橙色背景、鸟类和树木。尽管仅使用一幅图像作为输入，但样本显示了非常精细的细节，并且所有样本彼此之间非常不同。</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi nq"><img src="../Images/9056c3ff16919441efa63d1a87f43337.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jNPw9Oil9aWsFmmzHFgR0g.png"/></div></div><p class="mw mx gj gh gi my mz bd b be z dk translated"><a class="ae nk" href="https://github.com/tamarott/SinGAN/blob/master/imgs/teaser.PNG" rel="noopener ugc nofollow" target="_blank">资料来源:https://github.com/tamarott/SinGAN/blob/master/imgs/teaser.巴布亚新几内亚</a></p></figure><p id="4c7f" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">下图显示了一些图像处理任务的结果。第一列示出了风格转移，其中图像的属性可以被转移到视觉上不同但上下文相同的另一个图像，放大或缩小图像内的对象而不引起像素内的抖动，在背景前面添加对象，减少像素失真(超分辨率)等。</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi nr"><img src="../Images/fd05be1abe5a4ab71a0e5af45b424d96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yyHCfMnlhs-77TfYlCoa4g.png"/></div></div><p class="mw mx gj gh gi my mz bd b be z dk translated"><a class="ae nk" href="https://github.com/tamarott/SinGAN/blob/master/imgs/manipulation.PNG" rel="noopener ugc nofollow" target="_blank">来源:https://github . com/Tamar ott/SinGAN/blob/master/imgs/manipulation。巴布亚新几内亚</a></p></figure><p id="15ad" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">结果表明，一个图像足以学习属性。所有的实验表明，SinGAN 确实是一个强大的生成网络，即使给定一幅图像作为输入，它也能够很好地进行泛化。</p><h1 id="6b51" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">结论</h1><p id="57ec" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">这是对最近推出的 SinGAN 的快速而完整的介绍。我发现这个网络特别有趣，因为它能够仅使用一个源图像进行很好的归纳。如上所示，这个网络在各种图像相关的任务中表现良好，你可以看看 Github 上的实验。这个网络是用 PyTorch 实现的，可以在 GitHub 上进行实验。</p><h2 id="a978" class="ns ks it bd kt nt nu dn kx nv nw dp lb ls nx ny ld lw nz oa lf ma ob oc lh iz bi translated">参考</h2><p id="161a" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">[1]https://github.com/tamarott/SinGAN<a class="ae nk" href="https://github.com/tamarott/SinGAN" rel="noopener ugc nofollow" target="_blank"/></p><p id="7e46" class="pw-post-body-paragraph lj lk it ll b lm mf kd lo lp mg kg lr ls mh lu lv lw mi ly lz ma mj mc md me im bi translated">[2]https://arxiv.org/abs/1905.01164<a class="ae nk" href="https://arxiv.org/abs/1905.01164" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>