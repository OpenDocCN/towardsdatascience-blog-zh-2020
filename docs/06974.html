<html>
<head>
<title>Grad-CAM</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Grad-CAM</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/grad-cam-2f0c6f3807fe?source=collection_archive---------36-----------------------#2020-05-29">https://towardsdatascience.com/grad-cam-2f0c6f3807fe?source=collection_archive---------36-----------------------#2020-05-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="04fa" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">来自深层网络的视觉解释</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c81d3c3b1a4ae5f3460656a0db202008.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g26OgGzN0fjIR1tz5fhLAQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">修改自Grad-CAM论文的图1和图20</p></figure><p id="d1d0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Grad-CAM是一种用于可视化卷积神经网络模型的流行技术。Grad-CAM是特定于类别的，这意味着它可以为图像中出现的每个类别生成单独的可视化图像:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/95858e7ed7dd4f02e8d4650c948effb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:938/0*N5Lxg7IJ_7Po6f7b"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">根据Grad-CAM论文图1修改的猫和狗Grad-CAM可视化示例</p></figure><p id="d695" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Grad-CAM可用于弱监督定位，<em class="lv">即</em>使用仅在完整图像标签而非显式位置注释上训练的模型来确定特定对象的位置。</p><p id="236a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Grad-CAM还可以用于弱监督分割，其中模型预测属于特定对象的所有像素，而不需要像素级标签进行训练:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/d3ef40f66a94a14a34185d2e9bc175af.png" data-original-src="https://miro.medium.com/v2/resize:fit:604/0*5yGB-3qrAcJCHCUG"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Grad-CAM论文图4的一部分显示了通过使用Grad-CAM热图作为名为<a class="ae lx" href="https://arxiv.org/abs/1603.06098" rel="noopener ugc nofollow" target="_blank"> SEC(种子、扩展、约束)</a>的方法的种子而获得的预测摩托车和人分割遮罩</p></figure><p id="8873" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，Grad-CAM可用于更好地了解模型，例如通过提供对模型故障模式的洞察:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/5f21a0d26f1cbe09850adb60fedbb190.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/0*wQl3EJCkqY0nXK8j"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Grad-CAM论文的图6显示了模型故障示例以及Grad-CAM可视化，说明了模型做出错误预测的原因。</p></figure><p id="c5f6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这篇文章的主要参考是Grad-CAM论文的扩展版本:<a class="ae lx" href="https://arxiv.org/abs/1610.02391" rel="noopener ugc nofollow" target="_blank"> Selvaraju等人的“Grad-CAM:通过基于梯度的定位从深度网络进行可视化解释”国际计算机视觉杂志2019。</a></p><p id="9980" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Grad-CAM论文的先前版本发表在2017年国际计算机视觉大会(ICCV)上。</p><h1 id="3dca" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated"><strong class="ak">2021年更新</strong></h1><p id="3292" class="pw-post-body-paragraph ky kz it la b lb mr ju ld le ms jx lg lh mt lj lk ll mu ln lo lp mv lr ls lt im bi translated">虽然Grad-CAM的论文被引用了几千次，但最近的工作<a class="ae lx" href="https://arxiv.org/abs/2011.08891" rel="noopener ugc nofollow" target="_blank">展示了Grad-CAM的一个严重问题:有时，Grad-CAM会突出显示图像中模型实际上没有用于预测的区域。这意味着Grad-CAM是一种不可靠的模型解释方法。HiResCAM是一种新的解释方法，可以证明它保证只突出显示模型使用的位置。HiResCAM的灵感来自Grad-CAM，所以如果你理解Grad-CAM，那么</a><a class="ae lx" href="https://arxiv.org/abs/2011.08891" rel="noopener ugc nofollow" target="_blank">理解HiResCAM如何工作</a>就很简单了。</p><h1 id="a4d0" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated"><strong class="ak"> Grad-CAM作为事后关注</strong></h1><p id="a866" class="pw-post-body-paragraph ky kz it la b lb mr ju ld le ms jx lg lh mt lj lk ll mu ln lo lp mv lr ls lt im bi translated">Grad-CAM是一种事后注意力的形式，这意味着它是一种用于产生热图的方法，该热图在训练完成且参数固定后应用于已经训练的神经网络。这与可训练的注意力是不同的，可训练的注意力包括学习如何在训练期间通过学习特定的参数来产生注意力图(热图)。关于事后<em class="lv">与</em>可训练注意力的更深入讨论，见<a class="ae lx" href="https://glassboxmedicine.com/2019/08/10/learn-to-pay-attention-trainable-visual-attention-in-cnns/" rel="noopener ugc nofollow" target="_blank">这篇文章</a>。</p><h1 id="8a67" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated"><strong class="ak"> Grad-CAM作为CAM的推广</strong></h1><p id="78fa" class="pw-post-body-paragraph ky kz it la b lb mr ju ld le ms jx lg lh mt lj lk ll mu ln lo lp mv lr ls lt im bi translated">Grad-CAM不需要特定的CNN架构。Grad-CAM是CAM(类激活映射)的一种推广，是一种需要使用特定架构的方法。</p><p id="e4f6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">CAM需要一个将全局平均池(GAP)应用于最终卷积要素图的架构，然后是一个产生预测的全连接层:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/25c267f1179ce06ce205eb074ea19e08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/0*PeNRe_9F_JZJSZrz"/></div></figure><p id="de7a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在上面的草图中，正方形A1(红色)、A2(绿色)和A3(蓝色)代表CNN最后一个卷积层产生的特征图。为了使用Grad-CAM所基于的CAM方法，我们首先取每个特征图的平均值，以产生每个图的单个数字。在这个例子中，我们有3个特征地图，因此有3个数字；这3个数字在草图中显示为彩色小方块。然后，我们对这3个数字应用全连接层，以获得分类决策。对于输出类“cat”，预测将基于3个权重(w1、w2和w3)。为了制作“猫”的CAM热图，我们使用最终全连接层的“猫”权重对特征图进行加权求和:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/c94b8a84ff39983617b0896451a942b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/0*Y-kmPtPQ4e5tTQLL"/></div></figure><p id="53da" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">注意，特征图的数量不一定是三个——它可以是任意的<em class="lv"> k </em>。关于CAM如何工作的更详细的解释，请参见<a class="ae lx" href="https://glassboxmedicine.com/2019/06/11/cnn-heat-maps-class-activation-mapping-cam/" rel="noopener ugc nofollow" target="_blank">这篇文章</a>。理解CAM对于理解Grad-CAM非常重要，因为这两种方法密切相关。</p><p id="ce7b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Grad-CAM开发的部分动机是想出一种类似CAM的方法，不限制CNN架构。</p><h1 id="7841" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated">Grad-CAM概述</h1><p id="6d26" class="pw-post-body-paragraph ky kz it la b lb mr ju ld le ms jx lg lh mt lj lk ll mu ln lo lp mv lr ls lt im bi translated">Grad-CAM背后的基本思想与CAM背后的基本思想相同:我们希望利用通过卷积层保存的空间信息，以便了解输入图像的哪些部分对于分类决策是重要的。</p><p id="5585" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">与CAM类似，Grad-CAM使用CNN最后一个卷积层产生的特征图。Grad-CAM的作者认为，“我们可以预期最后的卷积层在高级语义和详细的空间信息之间具有最佳的折衷。”</p><p id="f6ab" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">以下是显示与Grad-CAM相关的神经网络模型部分的示意图:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi my"><img src="../Images/c29c0bcb222e09d7b34a89a50771c6e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_quH4ttPdnPhc5Io"/></div></div></figure><p id="58c8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">CNN由一些卷积层组成(在草图中显示为“conv”)。最终卷积层生成的特征图显示为A1、A2和A3，与CAM草图中的相同。</p><p id="3465" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">此时，对于CAM，我们需要进行全局平均池化，然后是完全连接的层。对于Grad-CAM，我们可以做任何事情——例如，多个完全连接的层——在草图中显示为“任何神经网络层”。唯一的要求是我们在A1、A2和A3之后插入的层必须是可微的，这样我们就可以得到一个梯度。最后，我们有飞机、狗、猫、人等的分类输出。</p><p id="eadd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">CAM和Grad-CAM之间的区别在于如何对特征图A1、A2和A3进行加权以生成最终热图。在CAM中，我们使用取自网络最后一个全连接层的权重对这些特征地图进行加权。在Grad-CAM中，我们使用基于梯度计算的“alpha值”对特征图进行加权。因此，Grad-CAM不需要特定的架构，因为我们可以通过任何一种我们想要的神经网络层来计算梯度。Grad-CAM中的“Grad”代表“梯度”</p><p id="528b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Grad-CAM的输出是一个“区分类别的定位图”，<em class="lv">即</em>一个热点图，其中热点部分对应于一个特定类别:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/9d2189bee44fa23acf8899acd4c2b261.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/0*UpjLqzpOkZnUnDNb"/></div></figure><p id="03d9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果有10个可能的输出类，那么对于特定的输入图像，您可以制作10个不同的Grad-CAM热图，每个类一个热图。</p><h1 id="6765" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated"><strong class="ak"> Grad-CAM详情</strong></h1><p id="637a" class="pw-post-body-paragraph ky kz it la b lb mr ju ld le ms jx lg lh mt lj lk ll mu ln lo lp mv lr ls lt im bi translated">首先，做一点注释:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/1872ee0c16435931b033cea5f5e1ef51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/0*qV0uZBUwUIHisgax"/></div></figure><p id="550e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">换句话说，在应用softmax将原始分数转换成概率之前，y^c是类<em class="lv"> c </em>的神经网络的原始输出。</p><p id="5911" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Grad-CAM应用于已完成训练的神经网络。神经网络的权重是固定的。我们将一幅图像输入网络，为选定的感兴趣类别计算该图像的Grad-CAM热图。</p><p id="40c8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Grad-CAM有三个步骤:</p><h2 id="b03a" class="nb ma it bd mb nc nd dn mf ne nf dp mj lh ng nh ml ll ni nj mn lp nk nl mp nm bi translated">步骤1:计算梯度</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/cd779bc009bc6e0472f8db0b68f42310.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/0*KeTb6R35CIKV95Oq"/></div></figure><p id="e01f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在该步骤中计算的梯度的特定值取决于选择的输入图像，因为输入图像决定了特征图A^k以及产生的最终类别分数y^c。</p><p id="d3af" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于2D输入图像，此渐变是3D的，与特征地图具有相同的形状。高度<em class="lv"> v </em>和宽度<em class="lv"> u </em>、<em class="lv">即</em>各有<em class="lv"> k </em>个特征图，这些特征图统称为形状<em class="lv"> k，v，u </em>。这意味着在步骤1中计算的梯度也将是形状[ <em class="lv"> k，v，u </em> ]。</p><p id="4bd8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在下面的草图中，<em class="lv"> k </em> =3所以有三张<em class="lv"> u </em> x <em class="lv"> v </em>特征图和三张<em class="lv"> u </em> x <em class="lv"> v </em>渐变:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/1fac00447f35e6807a8e9762ce20472a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*E20golgKRA39KikM"/></div></div></figure><h2 id="a8c5" class="nb ma it bd mb nc nd dn mf ne nf dp mj lh ng nh ml ll ni nj mn lp nk nl mp nm bi translated">步骤2:通过平均梯度计算阿尔法值</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/7c4eded84e524a1cd922132ecb24f369.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/0*fvO8nU5DtPAjg0DZ"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/8067d1080872701e3e5362b4c6bbad5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/0*KnMR9r4Ftv8FxTdZ"/></div></figure><p id="2b15" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这一步，我们计算阿尔法值。类别<em class="lv"> c </em>和特征地图<em class="lv"> k </em>的alpha值将在下一步中用作应用于特征地图A^k.的权重(在CAM中，应用于特征地图A^k的权重是最终完全连接层中的权重w_k。)</p><p id="0933" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">回想一下，我们的渐变有形状[ <em class="lv"> k，v，u </em> ]。我们对高度<em class="lv"> v </em>和宽度<em class="lv"> u </em>进行合并，因此我们最终得到的是形状为[ <em class="lv"> k，1，1 </em>的东西，或者简单点说，就是[ <em class="lv"> k </em>】。这些是我们的kα值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/94b46750ef19fd9a77355ac69d30fbc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/0*gO-xO82YCWBfsR_s"/></div></figure><h2 id="423d" class="nb ma it bd mb nc nd dn mf ne nf dp mj lh ng nh ml ll ni nj mn lp nk nl mp nm bi translated">步骤3:计算最终Grad-CAM热图</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/564e47ed1cdb66a1338e94428725a6b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/0*x4tHO-tWZGdQZ4dy"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/90553aed2c76511875f52e02934f5bd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:566/0*nWVoy5oNL7So7-E7"/></div></figure><p id="091d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们有了alpha值，我们使用每个alpha值作为相应特征图的权重，并计算特征图的加权和作为最终的Grad-CAM热图。然后我们应用一个ReLU操作，只强调正值，把所有负值都变成0。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/fae958deae2ebea101aa28ed794098ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UW821aV8np1Y8U4-"/></div></div></figure><h1 id="fb72" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated">Grad-CAM热图不会太小吗？</h1><p id="e88f" class="pw-post-body-paragraph ky kz it la b lb mr ju ld le ms jx lg lh mt lj lk ll mu ln lo lp mv lr ls lt im bi translated">Grad-CAM热图的大小为<em class="lv"> u </em> x <em class="lv"> v </em>，这是最终卷积特征图的大小:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/e27ef26e63c59fe2fc2933bb3a06b5f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/0*po_rTspA6hMUOhSO"/></div></figure><p id="8b2a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可能想知道这有什么意义，因为在大多数CNN中，最终的卷积特征在宽度和高度上都比原始输入图像小得多。</p><p id="4b2b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">事实证明，如果<em class="lv"> u </em> x <em class="lv"> v </em> Grad-CAM热图比原始输入图像尺寸小很多，也没关系。我们需要做的就是在最终可视化之前，对微小的<em class="lv"> u </em> x <em class="lv"> v </em>热图进行上采样，以匹配原始图像的大小。</p><p id="5f6c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，这是一个12 x 12的小热图:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/608e4d17391ceab895d4c97db56561af.png" data-original-src="https://miro.medium.com/v2/resize:fit:454/0*2a04IIEOhdYIMoA-"/></div></figure><p id="a230" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，这是使用Python包cv2向上采样到420 x 420的相同热图:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/641046025136b4a7949e2fa2633f36b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:472/0*9CaY4ksub-NFA8Iy"/></div></figure><p id="7a18" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">将原始小的低分辨率热图可视化并将其转换为大的高分辨率热图的代码如下:</p><pre class="kj kk kl km gt nx ny nz oa aw ob bi"><span id="b3b7" class="nb ma it ny b gy oc od l oe of">import cv2 <br/>import matplotlib <br/>import matplotlib.pyplot as plt </span><span id="3bd8" class="nb ma it ny b gy og od l oe of">small_heatmap = CalculateGradCAM(class='cat') </span><span id="6385" class="nb ma it ny b gy og od l oe of">plt.imshow(small_heatmap, cmap='rainbow') </span><span id="2dfa" class="nb ma it ny b gy og od l oe of">#Upsample the small_heatmap into a big_heatmap with cv2: <br/>big_heatmap = cv2.resize(small_heatmap, dsize=(420, 420), <br/>                         interpolation=cv2.INTER_CUBIC) </span><span id="1957" class="nb ma it ny b gy og od l oe of">plt.imshow(big_heatmap, cmap='rainbow')</span></pre><h1 id="f852" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated"><strong class="ak"> Grad-CAM实施</strong></h1><p id="2eb8" class="pw-post-body-paragraph ky kz it la b lb mr ju ld le ms jx lg lh mt lj lk ll mu ln lo lp mv lr ls lt im bi translated">Grad-CAM的Pytorch实现可从<a class="ae lx" href="https://github.com/jacobgil/pytorch-grad-cam/blob/master/README.md" rel="noopener ugc nofollow" target="_blank">这里</a>获得。</p><h1 id="5658" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated"><strong class="ak">更多Grad-CAM示例</strong></h1><p id="1f34" class="pw-post-body-paragraph ky kz it la b lb mr ju ld le ms jx lg lh mt lj lk ll mu ln lo lp mv lr ls lt im bi translated">Grad-CAM已经应用于许多研究领域，在医学图像中尤其流行。这里有几个例子:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/a07f6dc91470b46137376cd519c864eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1Q6gls8LUJmyCCnE"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae lx" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6371279/#!po=62.5000" rel="noopener ugc nofollow" target="_blank">杨等，“深度三维卷积神经网络对阿尔茨海默病分类的可视化解释”</a></p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/17c431dea16cb33f9a3d535c57e1b476.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/0*dzt4BEhWM_6mvGu_"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">上面一排是摄像头，下面一排是摄像头。<a class="ae lx" href="https://www.mdpi.com/2075-4418/9/2/38/htm" rel="noopener ugc nofollow" target="_blank"> Kim等人，“医学图像形态分类中卷积神经网络预测的视觉解释。”</a></p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/1b52762bb83298c78c0694d5c0917cb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6PD_h64Up5__O3l_"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">伍等人的Grad-CAM可视化。“CBAM:卷积块注意模块。”本文是一个可训练的注意力机制(CBAM)与可视化的事后注意力机制(Grad-CAM)相结合的例子。</p></figure><h1 id="b515" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated"><strong class="ak">2021年确定Grad-CAM的主要问题</strong></h1><p id="a548" class="pw-post-body-paragraph ky kz it la b lb mr ju ld le ms jx lg lh mt lj lk ll mu ln lo lp mv lr ls lt im bi translated">虽然Grad-CAM应该能够解释模型用于预测的图像区域，但事实证明Grad-CAM并不能保证做到这一点！简而言之，由于梯度平均步骤，Grad-CAM的热图不能反映模型的计算，因此可以突出显示不用于预测的无关区域。解决方案是HiResCAM，这是一种解释方法，它避免了Grad-CAM的梯度平均步骤，而是使用原始梯度和特征图之间的元素乘积。HiResCAM实现了与Grad-CAM相同的所有目的，其好处是HiResCAM可以保证只突出显示模型使用的区域，对于任何以一个完全连接的层结束的CNN。把Grad-CAM代码改成HiResCAM代码只需要几秒钟。关于为什么Grad-CAM有时会失败，以及HiResCAM解决方案如何工作的更多细节，请参见<a class="ae lx" href="https://arxiv.org/abs/2011.08891" rel="noopener ugc nofollow" target="_blank">这篇论文</a>。</p><h1 id="b79c" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated"><strong class="ak">制导Grad-CAM的问题</strong></h1><p id="2e95" class="pw-post-body-paragraph ky kz it la b lb mr ju ld le ms jx lg lh mt lj lk ll mu ln lo lp mv lr ls lt im bi translated">作为另一个需要注意的问题，Grad-CAM论文提到了Grad-CAM的一个变种，称为“Guided Grad-CAM”，它将Grad-CAM与另一种称为“guided backpropagation”的CNN热图可视化技术相结合。我在<a class="ae lx" href="https://glassboxmedicine.com/2019/10/12/guided-grad-cam-is-broken-sanity-checks-for-saliency-maps/" rel="noopener ugc nofollow" target="_blank">这篇文章</a>和<a class="ae lx" href="https://glassboxmedicine.com/2019/10/06/cnn-heat-maps-gradients-vs-deconvnets-vs-guided-backpropagation/" rel="noopener ugc nofollow" target="_blank">这篇文章</a>中讨论了引导反向传播。简短的总结是，Adebayo等人(T13)和Nie等人(T15)最近的工作表明，引导反向传播正在执行部分图像恢复，并像边缘检测器一样工作，而不是提供对训练模型的洞察。因此，最好不要使用导向反向传播，由此引申，这意味着最好不要使用导向Grad-CAM。</p><h1 id="f5aa" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated"><strong class="ak">总结</strong></h1><ul class=""><li id="de2c" class="ok ol it la b lb mr le ms lh om ll on lp oo lt op oq or os bi translated">Grad-CAM是一种流行的技术，用于根据特定的输入图像、经过训练的CNN和选定的感兴趣的类别来创建特定类别的热图。</li><li id="bd3a" class="ok ol it la b lb ot le ou lh ov ll ow lp ox lt op oq or os bi translated">Grad-CAM与CAM关系密切。</li><li id="b5f7" class="ok ol it la b lb ot le ou lh ov ll ow lp ox lt op oq or os bi translated">Grad-CAM可以在任何CNN架构上计算，只要层是可区分的。</li><li id="8744" class="ok ol it la b lb ot le ou lh ov ll ow lp ox lt op oq or os bi translated">Grad-CAM已经用于弱监督定位和弱监督分割。</li><li id="6de9" class="ok ol it la b lb ot le ou lh ov ll ow lp ox lt op oq or os bi translated">最近的工作发现了Grad-CAM的一个基本问题:有时Grad-CAM会突出显示模型实际上没有使用的区域。因此，对于模型解释，应使用<a class="ae lx" href="https://arxiv.org/abs/2011.08891" rel="noopener ugc nofollow" target="_blank"> HiResCAM </a>代替Grad-CAM。</li></ul></div><div class="ab cl oy oz hx pa" role="separator"><span class="pb bw bk pc pd pe"/><span class="pb bw bk pc pd pe"/><span class="pb bw bk pc pd"/></div><div class="im in io ip iq"><p id="6113" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lv">原载于2020年5月29日</em><a class="ae lx" href="https://glassboxmedicine.com/2020/05/29/grad-cam-visual-explanations-from-deep-networks/" rel="noopener ugc nofollow" target="_blank"><em class="lv"/></a><em class="lv">。</em></p></div></div>    
</body>
</html>