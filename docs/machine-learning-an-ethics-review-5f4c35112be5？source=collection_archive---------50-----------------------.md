# 机器学习——伦理评论

> 原文：<https://towardsdatascience.com/machine-learning-an-ethics-review-5f4c35112be5?source=collection_archive---------50----------------------->

![](img/0a170d0f644923b8ffece6310e19321c.png)

由 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的[üMIT Bulut](https://unsplash.com/@umit?utm_source=medium&utm_medium=referral)拍摄的照片

我正在熨斗学校完成我的数据科学项目，回顾我所做的五个项目，并考虑如果这些项目将投入生产并影响真实的人，我应该考虑哪些伦理问题。虽然机器学习伦理的介绍是 Flatron 项目的一部分，但将伦理分析整合到每个项目中超出了它的范围。

## 五项原则

我将使用弗洛里迪和考尔斯在 2019 年的论文[中提出的五项原则，这是人工智能在社会中的五项原则的统一框架](https://hdsr.mitpress.mit.edu/pub/l0jsh9d1/release/6)，对我的项目进行顶级审查。原则是*有利*、*无害*、*自治*、*正义*和*可解释*。慈善意味着“促进福祉，维护尊严，维持地球”。无罪意味着“隐私、安全和‘能力警告’”。自主指的是“我们为自己保留的决策权和我们委托给人为代理人的决策权之间的平衡”。正义意味着“促进繁荣、维护团结、避免不公平”。可解释性意味着“通过可理解性和可说明性实现其他原则”。

## 项目# 1——向新企业推荐电影类型

我的第一个项目是基于向一个虚构的新电影工作室推荐什么类型的电影。它实际上不涉及机器学习，它纯粹基于数据分析；然而，创建一个代替人类分析师做出建议的机器学习模型并不难想象，也不难实现。

对于电影工作室来说，要求机器学习模型告诉他们制作什么类型的电影，这对于五项原则来说意味着什么？在这个项目中，企业被认为是一个盈利性公司。它感兴趣的主要是经济利益，从分析来看，我推荐的类型是动画。我使用了来自电影数据库的数据，推荐什么类型的可能性是有限的。模型可以做出类似的建议，并随着数据集随时间的变化而更新其建议。随着娱乐和就业被视为商品，它可以被视为是有益的。侵犯隐私或安全的可能性似乎很小，通过自主测试将取决于实现。这个决定是由模型单独做出的，还是由一些人和模型共同做出的？如果只考虑模型，除了短期财务收益之外，可能永远不会考虑其他因素。当考虑正义时，这也将取决于实现，但是如果唯一的问题是类型，那么正义的方面将取决于模型建议的人类实现。关于可解释性，这将再次取决于模型的实现。然而，来自电影数据库的数据集是公开可用的这一事实将有助于模型的可理解性。

因为这个项目实际上没有进行机器学习，所以分析主要是推测性的，并且将取决于机器学习模型的实际实现。让我们继续下面四个使用机器学习模型的项目。

## 项目# 2——房价预测即服务

这个项目是基于一个虚构的服务，该服务将向搬到华盛顿州 King County 地区或希望搬到该地区新位置的人提供住房建议，并向企业提供类似的数据，以便他们可以做出明智的工资决定。

这个项目的机器学习方面是使用国王县房屋销售数据集的修改版本进行房价预测。

让我们开始伦理分析。我会把这个项目看作一个整体，而不仅仅是机器学习方面。出于慈善目的，可以向潜在购房者及其雇员提供的知识可以被视为通过向他们提供可能很难或很费时间来汇编的信息来促进购房者的福祉。该数据集不使用国王县尚未公开的个人信息，因此不会对人们的隐私造成损害。就自主性而言，该服务将几乎所有的自主性都给予了人类参与者。信息的消费者可以使用或不使用服务给出的建议，而不会产生任何影响。就公正而言，该服务最终可能会导致中产阶级化，并对该服务推荐的价格和便利性之间更好平衡的现有社区成员进行定价，而不考虑目前居住在那里的人。对于可解释性，我将同时考虑模型和数据集。首先，数据集是公开的。用于房价预测的模型是线性回归，其中内置了许多解释能力。它可以提供正在使用的参数列表及其对计算出的房价的重要性。

这项服务唯一潜在的道德问题是它对中产阶级化的潜在贡献。这项服务如何才能更加公正，使特定社区的住房成本不会迅速攀升？这是一个社区需要参与解决的复杂问题，但一个想法是增加服务的复杂性，以便考虑价格趋势，并阻止购房者在价格上涨过快的社区购买。

## 项目 3——坦桑尼亚水点分类

该项目旨在创建一个模型，用于预测供水点的分类，即功能性、功能性需要修复或非功能性，以便坦桑尼亚政府能够更好地利用其有限的资源，更好地为其人口提供清洁水。

这个项目看起来很有益处，它有助于为需要的人们提供干净的水。但是当把无罪和自主结合起来考虑时，就不那么明确了。不存在隐私或安全问题，但如果给予这种模式太多的自主权，可能会导致一些人永远无法获得当地供水点的服务。功能性水点的假阳性将导致那些水点被忽略。当考虑正义时，结果会是什么也不清楚。虽然拥有一个模型来确定需要访问哪些水点以获取服务可以消除人类决策过程中的偏差，但我们不知道在[源数据集](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/)中存在什么偏差(如果有的话)。检查和记录结果以及每个水点信息的人做得好吗？他们是否同样注意或准确地检查了所有的水点？是否有任何水点被故意忽略，从而被排除在模型之外？如果不知道这些问题的答案，我们就无法知道通过源数据在模型中会产生什么样的偏差。现在让我们从可解释性的角度来看模型本身。表现最好并被选择用于实现的模型是随机森林分类器，它具有有限的互操作性。它可以告诉我们哪些特征对模型整体而言是重要的，但是考虑到随机森林模型中涉及大量树木，要解释特定水点的分类并不容易。

随机森林模型缺乏真正的互操作性，并且缺乏关于训练数据集中可能嵌入哪些偏差的信息，这使我认为，如果可以找到具有可比性能的模型，应该使用更具互操作性的模型。这样就可以审核一些已知的错误分类，以了解错误发生的原因，并对模型进行改进。

## 项目 4——推特情感分析

该项目旨在建立一个情感分析模型，以帮助一家虚构的公司监控公众对其新手机的反应，并对其竞争对手进行市场研究。

它使用机器学习模型对推文的情绪进行分类，但将解释和回应留给了人类分析师和决策者。该项目的好处是，根据 Twitter 用户的反馈，该公司将提供更好的手机。没有任何非恶意，模型中没有使用私人信息，但模型是在包含 twitter 句柄的公共数据集上训练的。虽然数据集不是为这个项目创建的，但数据集的创建者应该考虑是否包含这些 twitter 句柄，他们应该对数据进行某种匿名处理。虽然这些推文是公开发布的，但它们现在有了寿命，发布推文的人不再能够控制。这个系统通过只给人类参与者建议和观察，给予他们充分的自主权。公正的问题不适用于这个项目，因为它的范围有限。用于情感分析的模型是可解释的朴素贝叶斯分类器，并且数据集是公开可用的，使得项目是可解释的。

## 项目# 5——假新闻分类

这个项目是为一家虚构的社交媒体公司创建一个模型，将发布到其平台上的新闻故事分类为*假*或*真*，以帮助他们回应公众对允许*假新闻*在其网站上扩散的指控，然后监控假新闻的发展。

该项目的好处是有可能消除或限制这个平台上的*假新闻*，这将减少人们个人或其社区成员面临的 dis 和错误信息的数量。*假新闻*被理解为对其读者或公众造成伤害，因为其意图是为了创作者或创作者支持的人或团体的利益而误导读者。在处理无罪问题时，新闻自由和言论自由就发挥了作用。在这个项目中，不会因为分类而改变或删除任何帖子，这将由人类决策者决定，但如果模型被赋予基于其分类删除帖子的自主权，则需要提出审查和偏见的问题。是什么使得*这个故事是假的？*它实际上是错误或虚假信息，还是讽刺、耸人听闻或质疑主导故事线？如所实现的，充分的自主权被给予人类决策。在考虑公正时，必须考虑模型的准确性。该模型在两个类别之间实现了 89%的准确率平衡，但是有 11%的类别被错误地分类了呢？考虑到对具有真正公共价值的新闻报道的潜在错误分类，是仅仅基于这种模式采取行动，还是删除它们会超出潜在价值？训练模型的数据集是否包含对某些类型的*假新闻*的偏见？谁来决定假新闻的真正定义，他们如何决定？这个项目使用了一个随机森林分类器，就像上面解释的那样，只能部分解释。考虑到对言论自由的高度重视，以及解释特定新闻故事的分类而不仅仅是呈现整体特征重要性的需要，使用更具可解释性的模型会更好。

这个项目提出了许多关于无罪、公正和可解释性的伦理问题，如果它被实际执行或有一个执行计划，有些问题会有答案，但还有其他问题仍然存在，值得深思。

## 结论

虽然这些项目看起来大多是道德的，但它们都提出了许多问题，需要不同程度的深入调查或反思，才能完成真正的道德分析。也就是说，我认为这对我来说是一次值得的练习，我希望对你也是如此。