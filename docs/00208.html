<html>
<head>
<title>Self-Supervised Learning and the Quest for Reducing Labeled Data in Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自我监督学习和深度学习中减少标记数据的探索</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/self-supervised-learning-and-the-quest-for-reducing-labeled-data-in-deep-learning-db59a563e25b?source=collection_archive---------8-----------------------#2020-01-07">https://towardsdatascience.com/self-supervised-learning-and-the-quest-for-reducing-labeled-data-in-deep-learning-db59a563e25b?source=collection_archive---------8-----------------------#2020-01-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d01f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">深度学习的现状以及自我监督如何可能是更健壮模型的答案</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9666635f8d9b5e3c52c3312fdf2adeac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pr-B_UeeNKcy5l98r1p9ug.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://pixabay.com/users/picjumbo_com-2130229/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=865116" rel="noopener ugc nofollow" target="_blank">来自 www.picjumbo.com 的免费库存照片</a>来自<a class="ae ky" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=865116" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><p id="d6b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated"><span class="l lw lx ly bm lz ma mb mc md di"> T </span>这里有一件事是每个深度学习实践者都同意的。</p><blockquote class="me"><p id="e39c" class="mf mg it bd mh mi mj mk ml mm mn lu dk translated">深度学习模型是数据低效的。</p></blockquote><p id="b51c" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">让我们首先考虑计算机视觉中流行的分类任务。以<a class="ae ky" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>数据库为例。它包含来自 1000 个不同类别的 130 万张图片。对于这些图像中的每一个，都有一个人注释的标签。</p><p id="9383" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ImageNet 无疑是当前深度学习复兴的垫脚石之一。其中大部分始于 2012 年的那篇(<a class="ae ky" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" rel="noopener ugc nofollow" target="_blank">krijevsky 等人</a>)论文。在这里，ConvNets 第一次大幅度击败了当前最先进的模型。在竞争对手中，它是基于 ConvNet 的单一解决方案。之后，ConvNets 变得无处不在。</p><p id="7fc9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在深度学习之前，ImageNet 挑战一直被认为是非常困难的。在主要原因中，其较大的可变性最为突出。事实上，要建立能在这么多种类的狗中通用的手工制作的特征并不容易。</p><blockquote class="me"><p id="5a73" class="mf mg it bd mh mi mj mk ml mm mn lu dk translated">然而，随着深度学习的发展，我们很快意识到，让 ImageNet 如此艰难的原因实际上是让深度学习如此有效的秘密成分。这就是丰富的数据。</p></blockquote><p id="7777" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">然而，经过多年的深度学习研究，有一点变得很清楚。<em class="mt">用于训练精确模型的大型数据库的必要性成为一个非常重要的问题</em>。当需要人工标注的数据时，这种低效率会成为一个更大的问题。</p><p id="4bf4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">而且，在当前的深度学习应用中，数据的问题无处不在。再以<a class="ae ky" href="https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii" rel="noopener ugc nofollow" target="_blank"> DeepMind 的 AlphaStar </a>模型为例。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/b719707f40cf8e9fcbb90ef1ab0e4422.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*gidYwyTpP1IbJ7VnNexLgw.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii" rel="noopener ugc nofollow" target="_blank"> AlphaStar:精通即时战略游戏星际争霸 2</a></p></figure><p id="37d6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">AlphaStar 是一个深度学习系统，使用监督和强化学习来玩星际争霸 2。在训练过程中，AlphaStar 只能看到来自游戏控制台的原始图像像素。为了训练它，DeepMind 的研究人员使用了一种分布式策略，他们可以并行训练大量的代理人。<strong class="lb iu">每个代理都经历了至少 200 年的实时星际争霸游戏(不间断)</strong>。AlphaStar 接受了与职业选手相似的训练。它在官方游戏服务器上的活跃玩家中排名超过 99.8%——这是一个巨大的成功。</p><p id="a770" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">尽管使用了所有通用技术来训练系统，但有一件事对成功构建 AlphaStar(或几乎任何其他 RL 代理)至关重要——<strong class="lb iu">数据的可用性</strong>。事实上，最好的强化学习算法需要许多(但许多)试验才能达到人类水平的性能。<strong class="lb iu">这与我们人类的学习方式完全相反。</strong></p><p id="9938" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，巨大的成功来自于有大量可用数据的受限的、定义良好的场景。看看 DeepMind 的这篇论文<a class="ae ky" href="https://arxiv.org/pdf/1710.02298.pdf" rel="noopener ugc nofollow" target="_blank">。最好的 RL 方法需要近 100 小时(1080 万帧)的不间断播放，才能达到专业人员在一套 Atari 游戏上的相同性能水平。尽管最近有所改善，但这似乎还是太多了。</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/858d73f46ee66265cd2b204f339a5e91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*375qien7h0it1VAql1WLYg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">学分:<a class="ae ky" href="https://arxiv.org/pdf/1710.02298.pdf" rel="noopener ugc nofollow" target="_blank">彩虹:结合深度强化学习的改进</a></p></figure><p id="67e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mt">要了解更多关于 AlphaStar 的信息，请看一下这个来自</em> <a class="ae ky" href="https://blog.deeplearning.ai/blog/the-batch-google-achieves-quantum-supremacy-amazon-aims-to-sway-lawmakers-ai-predicts-basketball-plays-face-detector-preserves-privacy-1-0-0-0-0" rel="noopener ugc nofollow" target="_blank"> <em class="mt">批次</em> </a> <em class="mt">的简短摘要。</em></p></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><p id="2613" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我可以用更多的例子来烦你，但是我想这两个例子说明了我想要表达的观点。</p><blockquote class="me"><p id="0b6c" class="mf mg it bd mh mi mj mk ml mm mn lu dk translated">目前的深度学习是基于大规模数据的。当它们的环境和约束得到满足时，这些系统就像魔法一样工作。然而，在一些奇怪的情况下，他们也会灾难性地失败。</p></blockquote><p id="5681" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">让我们稍微回到 ImageNet 上的分类。具体来说，该数据库估计人为错误率为 5.1% 。另一方面，目前最先进的<a class="ae ky" href="https://paperswithcode.com/sota/image-classification-on-imagenet" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">深度学习 top-5 准确率在 1.8% </strong> </a>左右。因此，人们完全可以说深度学习在这项任务上已经比人类做得更好了。但是是吗？</p><p id="94a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果是这样的话，我们如何解释这些事情？</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/4fb1de4b8d22add299623cf7ee76fbfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/0*PVczsmnFPoFZw-QU.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">学分:<a class="ae ky" href="https://openai.com/blog/adversarial-example-research/" rel="noopener ugc nofollow" target="_blank">用对抗性例子攻击机器学习</a></p></figure><p id="3380" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些例子在互联网上非常流行，被称为<a class="ae ky" href="https://openai.com/blog/adversarial-example-research/" rel="noopener ugc nofollow" target="_blank">反例</a>。我们可以认为这是一个优化任务，旨在欺骗机器学习模型。这个想法很简单:</p><blockquote class="me"><p id="732d" class="mf mg it bd mh mi mj mk ml mm mn lu dk translated">我们如何改变先前被分类为“熊猫”的图像，以便分类器认为它是“长臂猿”？</p></blockquote><p id="5fb5" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我们可以简单地认为它是精心设计的输入示例，用来欺骗 ML 模型，使其犯分类错误。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/4c2383afa823017157e269c22a58972c.png" data-original-src="https://miro.medium.com/v2/resize:fit:682/format:webp/1*BXaKVASNijJ5-bgWdtI2gQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">致谢:<a class="ae ky" href="https://arxiv.org/pdf/1710.08864.pdf" rel="noopener ugc nofollow" target="_blank">愚弄深度神经网络的一个像素攻击</a></p></figure><p id="095a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我们所看到的，优化是如此有效，以至于我们无法(用肉眼)感知真实(左)和对立(右)图像之间的差异。事实上，造成错误分类的噪声不是任何类型的已知信号。相反，它被精心设计来探索这些模型中隐藏的偏见。此外，最近的研究表明，在某些情况下，我们只需要改变<a class="ae ky" href="https://arxiv.org/pdf/1710.08864.pdf" rel="noopener ugc nofollow" target="_blank"> 1 个像素，就可以完全欺骗最好的深度学习分类器</a>。</p><p id="bafe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这一点上，我们可以看到问题开始相互叠加。我们不仅需要大量的例子来学习一项新的任务，而且我们还需要确保我们的模型学习正确的表示。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://www.youtube.com/watch?v=piYnd_wYlT8&amp;list=PL4-Hw6PNAmgc1NUCsMRbZFOChJmuDnefp&amp;index=12" rel="noopener ugc nofollow" target="_blank">用对立的例子愚弄图像识别</a></p></figure><p id="af92" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我们看到深度学习系统像那样失败时，一个有趣的讨论就来了。显然，我们人类不会轻易被这样的例子愚弄。但这是为什么呢？</p><p id="5a85" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有人可能会说，当我们需要掌握一项新任务时，我们实际上并不是从零开始学习。取而代之的是，我们使用了大量在我们的生活和经历中获得的先验知识。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/dafcd0c2d4726a6e93c043b5e45a2f1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S-uIt0UY0M7MlPkeyyfgbQ.jpeg"/></div></div></figure><p id="4be0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们了解重力及其含义。我们知道，如果我们让一枚炮弹和一根鸟毛从同一个起点落下，由于两个物体中空气阻力的不同作用，炮弹将首先到达地面。我们知道物体不应该浮在空中。我们了解世界如何运转的常识。你知道如果你的父亲有一个孩子，他或她将是你的兄弟姐妹。我们知道，如果我们在报纸上看到有人出生在 20 世纪，他/她可能已经不在人世，因为我们知道(通过观察世界)人们通常不会活超过 120 岁。</p><p id="0378" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们理解事件之间的因果关系。最令人好奇的是，我们实际上在生命的早期就学习了许多这些高层次的概念。事实上，我们只用 6 到 7 个月就学会了像重力和惯性这样的概念。这个年纪，和世界的互动几乎没有！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/a214fb0c959738960da9719c524a6714.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/0*H6sHp3EVX1RlyDvn"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">婴儿的早期概念习得。<a class="ae ky" href="https://drive.google.com/file/d/12pDCno02FJPDEBk4iGuuaj8b2rr48Hh0/view" rel="noopener ugc nofollow" target="_blank"> Yann LeCun 幻灯片</a></p></figure><p id="f715" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从这个意义上说，有人可能会说，将算法的性能与人类进行比较是不“<em class="mt">公平的”</em>。</p><p id="bc54" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在他的一次关于自我监督学习的<a class="ae ky" href="https://www.facebook.com/epflcampus/videos/1960325127394608" rel="noopener ugc nofollow" target="_blank">演讲</a>中，Yann LeCun 认为至少有三种方法可以获得知识。</p><ul class=""><li id="4b07" class="nj nk it lb b lc ld lf lg li nl lm nm lq nn lu no np nq nr bi translated">通过观察</li><li id="9417" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated">来自监督(大多来自家长和老师)</li><li id="e88d" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated">来自强化反馈</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/7b99037145d66a2426f275cae7ccedd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jTFXWwbU5VGQORf5wpgbpQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">人类通过生活获得的不同知识来源。通过观察/互动、监督和反馈来学习。</p></figure><p id="7b04" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，如果我们以人类婴儿为例，在那个年龄几乎没有互动。然而，婴儿设法建立一个直观的世界物理模型。因此，像重力这样的高级知识只能通过纯粹的观察来学习——至少，我还没有见过任何父母给 6 个月大的婴儿教物理。</p><p id="4bae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">只是在生命的后期，当我们掌握了语言并开始上学时，监督和互动(有反馈)才变得更加普遍。但更重要的是，当我们到达人生的这些阶段时，我们已经发展出一个强健的模型世界。这可能是为什么人类比现在的机器数据效率更高的主要原因之一。</p><p id="57fb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如 LeCun 所说，强化学习就像蛋糕中的樱桃。监督学习是糖衣，自我监督学习是蛋糕！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/bb30f544a0f9d05d732d0f9d7557bba6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iP84tjfdjSGfI8TorleWxw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://drive.google.com/drive/folders/0BxKBnD5y2M8NUXhZaXBCNXE4QlE" rel="noopener ugc nofollow" target="_blank"> Yann LeCun </a></p></figure><h1 id="081a" class="nz oa it bd ob oc od oe of og oh oi oj jz ok ka ol kc om kd on kf oo kg op oq bi translated">自我监督学习</h1><blockquote class="me"><p id="e479" class="mf mg it bd mh mi mj mk ml mm mn lu dk translated">在自我监督学习中，系统学习从其输入的其他部分预测其输入的一部分— <a class="ae ky" href="https://www.facebook.com/722677142/posts/10155934004262143/" rel="noopener ugc nofollow" target="_blank"> LeCun </a></p></blockquote><p id="19bd" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">自监督学习源于无监督学习。它涉及从未标记的数据中学习语义上有意义的特征。在这里，我们主要关注的是计算机视觉环境下的自我监督。</p><p id="3f24" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一般的策略是通过设计一个<em class="mt">借口</em>任务，将一个无监督的问题转化为一个有监督的任务。通常，一个<em class="mt">借口</em>任务有一个总的目标。这个想法是让网络从图像或视频中捕捉视觉特征。</p><p id="b32d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">借口任务和常见的监督问题有一些相似之处。</p><p id="4a68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们知道监督训练需要标签。反过来，这些通常是由<strong class="lb iu">人类注释者</strong>收集的。然而，在许多情况下，标签要么非常昂贵，要么不可能获得。此外，我们还知道深度学习模型天生就需要数据。其直接结果是，大规模标注数据集成为进一步发展的主要障碍之一。</p><p id="9b6b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">嗯，自我监督学习也需要标签来训练托词任务。然而，这里有一个关键的区别。用于学习借口任务的标签(或伪标签)具有不同的特征。</p><blockquote class="me"><p id="f5b7" class="mf mg it bd mh mi mj mk ml mm mn lu dk translated">事实上，对于自监督训练，伪标签仅从数据属性中单独导出。</p></blockquote><p id="d132" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">换句话说，不需要人为标注。事实上，自我学习和监督学习的主要区别在于标签的来源。</p><ul class=""><li id="41a8" class="nj nk it lb b lc ld lf lg li nl lm nm lq nn lu no np nq nr bi translated">如果标签来自人类注释者(像大多数数据集一样)，这是一个监督任务。</li><li id="1851" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated">如果标签来自数据，在这种情况下，我们可以自动生成它们，我们谈论的是自我监督学习。</li></ul><p id="2b58" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最近的研究提出了许多借口任务。一些最常见的包括:</p><ul class=""><li id="a4a2" class="nj nk it lb b lc ld lf lg li nl lm nm lq nn lu no np nq nr bi translated">旋转</li><li id="33ad" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated">七巧板</li><li id="7979" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated">图像彩色化</li><li id="31ea" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated">图像修复</li><li id="e841" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated">使用 GANs 生成图像/视频</li></ul><p id="a408" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mt">在这里</em>  <em class="mt">查看每个</em> <a class="ae ky" href="https://arxiv.org/abs/1902.06162" rel="noopener ugc nofollow" target="_blank"> <em class="mt">借口任务的概要描述。</em></a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/4e674cc02f20aaab11d49b1a5f772a06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9cYDTTe20Fa5mHCISXjLYw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">学分:<a class="ae ky" href="https://arxiv.org/abs/1902.06162" rel="noopener ugc nofollow" target="_blank">深度神经网络的自我监督视觉特征学习:综述</a></p></figure><p id="710c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在自我监督训练期间，我们挑战网络来学习<em class="mt">托词</em>任务。同样，伪标签是从数据本身自动生成的，并用作训练目标。一旦训练结束，我们通常使用学习到的视觉特征将知识转移到第二个问题——下游任务<strong class="lb iu">中。</strong></p><p id="e155" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一般来说，<em class="mt">下游任务</em>可以是任何被监督的问题。这个想法是使用自我监督的特性来提高下游任务的性能。通常，<em class="mt">下游</em>任务的数据有限，过度拟合是一个大问题。在这里，我们可以看到在大型标记数据库(如 ImageNet)上使用预训练的 ConvNets 进行普通迁移学习的相似性。但有一个关键优势。</p><blockquote class="me"><p id="ede9" class="mf mg it bd mh mi mj mk ml mm mn lu dk translated">通过自我监督训练，我们可以在难以置信的大型数据库上预先训练模型，而不用担心人类标签。</p></blockquote><p id="f3d9" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">另外，<em class="mt">托辞</em>和平时的分类任务有个茬儿区别。在纯分类中，网络学习表示，目标是在特征空间中分离类别。在自我监督学习中，<em class="mt">托辞</em>任务通常挑战网络来学习更一般的概念。</p><p id="5bf7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以图像着色<em class="mt">托辞</em>任务为例。为了在其中脱颖而出，网络必须学习解释数据集中对象的许多特征的通用特征。这些包括物体的形状，它们的一般纹理，担心光线，阴影，遮挡等。</p><p id="5de7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">简而言之，通过解决托词任务，网络将学习语义上有意义的特征，这些特征可以很容易地转移到学习新问题。<strong class="lb iu">换句话说，我们的目标是在接受监督之前从未标记的数据中学习有用的表示法</strong>。</p><h1 id="c2da" class="nz oa it bd ob oc od oe of og oh oi oj jz ok ka ol kc om kd on kf oo kg op oq bi translated">结论</h1><p id="2044" class="pw-post-body-paragraph kz la it lb b lc os ju le lf ot jx lh li ou lk ll lm ov lo lp lq ow ls lt lu im bi translated">自我监督学习允许我们在不使用大型<strong class="lb iu">注释</strong>数据库的情况下学习良好的表示。相反，我们可以使用未标记的数据(这是丰富的)并优化预定义的<em class="mt">借口</em>任务。然后，我们可以使用这些特征来学习数据稀缺的新任务。</p><p id="525e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">感谢阅读</strong>。</p></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><h1 id="31bd" class="nz oa it bd ob oc ox oe of og oy oi oj jz oz ka ol kc pa kd on kf pb kg op oq bi translated">参考</h1><ul class=""><li id="38d9" class="nj nk it lb b lc os lf ot li pc lm pd lq pe lu no np nq nr bi translated"><a class="ae ky" href="https://openai.com/blog/adversarial-example-research/" rel="noopener ugc nofollow" target="_blank">用对立的例子攻击机器学习</a></li><li id="f89c" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated"><a class="ae ky" href="https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii" rel="noopener ugc nofollow" target="_blank">阿尔法星:精通即时战略游戏星际争霸 2</a></li><li id="cd56" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated">《彩虹:结合深度强化学习的改进》<em class="mt">第三十二届 AAAI 人工智能大会</em>。2018.</li><li id="59cf" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated">景，龙龙，田英丽。"深度神经网络自监督视觉特征学习:综述."<em class="mt"> arXiv 预印本 arXiv:1902.06162 </em> (2019)。</li><li id="ddad" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated">Gidaris，Spyros，Praveer Singh 和 Nikos Komodakis。"通过预测图像旋转的无监督表示学习."<em class="mt"> arXiv 预印本 arXiv:1803.07728 </em> (2018)</li><li id="de63" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated">较少标签的高保真图像生成。<em class="mt"> arXiv 预印本 arXiv:1903.02271 </em> (2019)</li><li id="10c0" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated">苏、佳伟、达尼洛·瓦斯康塞洛斯·巴尔加斯和樱井幸一。"愚弄深度神经网络的一个像素攻击."<em class="mt"> IEEE 进化计算汇刊</em> (2019)。</li></ul></div></div>    
</body>
</html>