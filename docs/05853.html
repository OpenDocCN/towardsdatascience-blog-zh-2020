<html>
<head>
<title>K-Nearest-Neighbors in 6 steps</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">6 步 k 近邻</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/k-nearest-neighbors-in-6-steps-efbcbebce54d?source=collection_archive---------15-----------------------#2020-05-14">https://towardsdatascience.com/k-nearest-neighbors-in-6-steps-efbcbebce54d?source=collection_archive---------15-----------------------#2020-05-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a09c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用 scikit-学习 python</h2></div><p id="f134" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi lb translated">本书旨在成为一个应用指南，介绍如何利用 K 近邻(KNN)方法来解决 python 中的商业问题。KNN 最流行的用例是在分类中。有趣的是，它也适用于 KNN 回归。</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi lk"><img src="../Images/04e8e0d7ebf9d292a0dc6e00b0fd55fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*h2vjCaQRXBooD_eN"/></div></div><p class="lw lx gj gh gi ly lz bd b be z dk translated"><a class="ae ma" href="https://unsplash.com/@fabioha?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">法比奥</a>在<a class="ae ma" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h2 id="c8c2" class="mi mj iq bd mk ml mm dn mn mo mp dp mq ko mr ms mt ks mu mv mw kw mx my mz na bi translated">这个概念</h2><p id="d9bb" class="pw-post-body-paragraph kf kg iq kh b ki nb jr kk kl nc ju kn ko nd kq kr ks ne ku kv kw nf ky kz la ij bi translated">从 KNN 分类器模型的基础开始。KNN 分类器模型在 3 个主要步骤中工作，以预测前所未有的特征值(不在训练数据中)的标签。</p><ol class=""><li id="ec79" class="ng nh iq kh b ki kj kl km ko ni ks nj kw nk la nl nm nn no bi translated">它会记住整个训练测试集——特别是哪个特征产生了哪个 y 标签。</li><li id="bb00" class="ng nh iq kh b ki np kl nq ko nr ks ns kw nt la nl nm nn no bi translated">它定义了 K 个最近的最相似实例，其中 K 是用户定义的整数。对于给定的数据点，它会查看最近的要素及其各自的标注。</li><li id="7978" class="ng nh iq kh b ki np kl nq ko nr ks ns kw nt la nl nm nn no bi translated">它根据最近邻居的标签来预测新标签。通常，这是多数票。</li></ol><p id="a399" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">回到 KNN 回归:不同之处在于，KNN 回归模型从前所未有的特征值的连续分布中预测新值。从概念上讲，它如何获得预测值与 KNN 分类模型类似，只是它将采用其 K 个最近邻的平均值。</p><h1 id="1533" class="nu mj iq bd mk nv nw nx mn ny nz oa mq jw ob jx mt jz oc ka mw kc od kd mz oe bi translated">k 近邻分类器</h1><h2 id="78e6" class="mi mj iq bd mk ml mm dn mn mo mp dp mq ko mr ms mt ks mu mv mw kw mx my mz na bi translated">包裹</h2><p id="34d9" class="pw-post-body-paragraph kf kg iq kh b ki nb jr kk kl nc ju kn ko nd kq kr ks ne ku kv kw nf ky kz la ij bi translated">让我们首先导入所需的包:</p><ol class=""><li id="6c27" class="ng nh iq kh b ki kj kl km ko ni ks nj kw nk la nl nm nn no bi translated">numpy 和<em class="of">pandas</em>:python 中的数据和数组操作</li><li id="b48e" class="ng nh iq kh b ki np kl nq ko nr ks ns kw nt la nl nm nn no bi translated"><em class="of">来自<em class="of"> matplotlib 库的 pyploy 模块</em>:</em>数据可视化</li><li id="c2f2" class="ng nh iq kh b ki np kl nq ko nr ks ns kw nt la nl nm nn no bi translated"><em class="of"> sklearn 模块</em>用于创建列车测试分割，并创建 KNN 对象。</li></ol><pre class="ll lm ln lo gt og oh oi oj aw ok bi"><span id="c6e7" class="mi mj iq oh b gy ol om l on oo"># Packages<br/>%matplotlib notebook<br/>import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt</span><span id="c5a7" class="mi mj iq oh b gy op om l on oo">from sklearn.model_selection import train_test_split<br/>from sklearn.neighbors import KNeighborsClassifier<br/>from sklearn.preprocessing import MinMaxScaler</span></pre><h2 id="b4d7" class="mi mj iq bd mk ml mm dn mn mo mp dp mq ko mr ms mt ks mu mv mw kw mx my mz na bi translated">数据</h2><p id="0ffd" class="pw-post-body-paragraph kf kg iq kh b ki nb jr kk kl nc ju kn ko nd kq kr ks ne ku kv kw nf ky kz la ij bi translated">数据集有 59 行和 7 列，前 10 行如下所示。为了简单起见，我们不会使用所有的特性；我们的目的是使用<em class="of">质量</em>和<em class="of">宽度</em>来预测标签<em class="of">水果 _ 标签</em>。</p><pre class="ll lm ln lo gt og oh oi oj aw ok bi"><span id="8859" class="mi mj iq oh b gy ol om l on oo">#import data<br/>fruits = pd.read_table('readonly/fruit_data_with_colors.txt')</span><span id="df39" class="mi mj iq oh b gy op om l on oo">feature_names_fruits = ['height', 'width', 'mass', 'color_score'] #x variable names<br/>X_fruits = fruits[feature_names_fruits] #setting the col names<br/>y_fruits = fruits['fruit_label'] #setting the col names<br/>target_names_fruits = ['apple', 'mandarin', 'orange', 'lemon'] #potential classes</span><span id="9b91" class="mi mj iq oh b gy op om l on oo">fruits.head(10)</span></pre><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/239629f7f0ce20253cb4d8bc3d8570ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*cOyEtJQJ7B1lLzfHNORa6w.png"/></div><p class="lw lx gj gh gi ly lz bd b be z dk translated">水果.头(10)</p></figure><h2 id="ea30" class="mi mj iq bd mk ml mm dn mn mo mp dp mq ko mr ms mt ks mu mv mw kw mx my mz na bi translated">1.特征工程</h2><p id="8e45" class="pw-post-body-paragraph kf kg iq kh b ki nb jr kk kl nc ju kn ko nd kq kr ks ne ku kv kw nf ky kz la ij bi translated">丢弃不需要的要素和标注。您将对数据集执行的要素工程的范围在很大程度上取决于您所操作的业务环境。</p><pre class="ll lm ln lo gt og oh oi oj aw ok bi"><span id="892e" class="mi mj iq oh b gy ol om l on oo"># setting up the 2 dimensional array of height and width predictors. other x vars discarded<br/>X_fruits_2d = fruits[['height', 'width']]<br/>y_fruits_2d = fruits['fruit_label'] #labels</span></pre><h2 id="6931" class="mi mj iq bd mk ml mm dn mn mo mp dp mq ko mr ms mt ks mu mv mw kw mx my mz na bi translated">2.列车测试分离</h2><p id="c73b" class="pw-post-body-paragraph kf kg iq kh b ki nb jr kk kl nc ju kn ko nd kq kr ks ne ku kv kw nf ky kz la ij bi translated">现在，我们将使用 75/25 的训练测试拆分来拆分 59 个条目，其中 75%的数据用于训练 KNN 分类模型，剩余的 25%从模型中“隐藏”出来，用于验证结果。75/25 分割是由<em class="of"> train_test_split 执行的默认分割。</em></p><pre class="ll lm ln lo gt og oh oi oj aw ok bi"><span id="8338" class="mi mj iq oh b gy ol om l on oo">#75 / 25 train test split<br/>X_train, X_test, y_train, y_test = train_test_split(X_fruits, y_fruits, random_state=0)</span></pre><h2 id="8d61" class="mi mj iq bd mk ml mm dn mn mo mp dp mq ko mr ms mt ks mu mv mw kw mx my mz na bi translated">3.特征最小-最大缩放</h2><p id="7e55" class="pw-post-body-paragraph kf kg iq kh b ki nb jr kk kl nc ju kn ko nd kq kr ks ne ku kv kw nf ky kz la ij bi translated">查看<em class="of">质量</em>和<em class="of">宽度</em>特征，我们注意到它们都在不同的尺度上:<em class="of">质量</em>值的范围是两位数和三位数，而<em class="of">宽度</em>值的范围通常是个位数。如果值的范围太大，目标函数可能无法正常工作，因为一些特征可能会无意中对预测产生更大的影响。</p><p id="285a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最小-最大缩放是一种相对简单的方法，类似于对分布应用 Z 分数归一化。相对于要素最小值和最大值，值被重新调整到-1 和 1 之间的范围内。</p><pre class="ll lm ln lo gt og oh oi oj aw ok bi"><span id="d789" class="mi mj iq oh b gy ol om l on oo">scaler = MinMaxScaler()<br/>X_train_scaled = scaler.fit_transform(X_train)<br/># we must apply the scaling to the test set that we computed for the training set<br/>X_test_scaled = scaler.transform(X_test)</span></pre><h2 id="f99e" class="mi mj iq bd mk ml mm dn mn mo mp dp mq ko mr ms mt ks mu mv mw kw mx my mz na bi translated">4.创建适合的 KNN 对象</h2><p id="122f" class="pw-post-body-paragraph kf kg iq kh b ki nb jr kk kl nc ju kn ko nd kq kr ks ne ku kv kw nf ky kz la ij bi translated">我们可以用第一行创建一个“空的”KNN 分类器模型。此外，<em class="of">n _ neighbors</em>参数允许控制我们的‘K’值。接下来，模型将根据训练数据集中缩放后的 X 要素及其对应的 Y 标注进行拟合。</p><pre class="ll lm ln lo gt og oh oi oj aw ok bi"><span id="2bcd" class="mi mj iq oh b gy ol om l on oo">knn = KNeighborsClassifier(n_neighbors = 5) #setting up the KNN model to use 5NN<br/>knn.fit(X_train_scaled, y_train) #fitting the KNN</span></pre><h2 id="485b" class="mi mj iq bd mk ml mm dn mn mo mp dp mq ko mr ms mt ks mu mv mw kw mx my mz na bi translated">5.评估绩效</h2><p id="6ea3" class="pw-post-body-paragraph kf kg iq kh b ki nb jr kk kl nc ju kn ko nd kq kr ks ne ku kv kw nf ky kz la ij bi translated">类似于如何使用<em class="of"> R 平方</em>度量来评估简单线性模型的拟合优度，我们可以使用<em class="of"> F 值</em>来评估 KNN 分类器。<em class="of"> F 值</em>衡量模型正确预测标签的准确性。我们可以观察到，该模型在 95%的训练数据时间和 100%的保留测试数据集时间上预测标签是正确的。</p><pre class="ll lm ln lo gt og oh oi oj aw ok bi"><span id="6d44" class="mi mj iq oh b gy ol om l on oo">#Checking performance on the training set<br/>print('Accuracy of K-NN classifier on training set: {:.2f}'<br/>     .format(knn.score(X_train_scaled, y_train)))<br/>#Checking performance on the test set<br/>print('Accuracy of K-NN classifier on test set: {:.2f}'<br/>     .format(knn.score(X_test_scaled, y_test)))</span></pre><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div class="gh gi or"><img src="../Images/5ac3cd323001d4770e639bb4225a8fd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/1*sbVB8AqmsmfLt_1xFc-zLw.png"/></div></figure><h2 id="230e" class="mi mj iq bd mk ml mm dn mn mo mp dp mq ko mr ms mt ks mu mv mw kw mx my mz na bi translated">6.做一个预测</h2><p id="02ac" class="pw-post-body-paragraph kf kg iq kh b ki nb jr kk kl nc ju kn ko nd kq kr ks ne ku kv kw nf ky kz la ij bi translated">最后，我们想用这个模型来做预测。给定一个<em class="of">质量、宽度、高度和 color_score </em>分别为 5.5、2.2、10 和 0.70 的水果，这是什么水果？在适当的最小-最大缩放之后，模型预测它是普通话。</p><pre class="ll lm ln lo gt og oh oi oj aw ok bi"><span id="7769" class="mi mj iq oh b gy ol om l on oo">example_fruit = [[5.5, 2.2, 10, 0.70]]<br/>example_fruit_scaled = scaler.transform(example_fruit)<br/>#Making an prediction based on x values<br/>print('Predicted fruit type for ', example_fruit, ' is ', <br/>          target_names_fruits[knn.predict(example_fruit_scaled)[0]-1])</span></pre><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div class="gh gi os"><img src="../Images/caa483707a43d383179a71cafabb5e11.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*KwCnfVXqlh9yFOBUqWcjUQ.png"/></div></figure><h2 id="cfbf" class="mi mj iq bd mk ml mm dn mn mo mp dp mq ko mr ms mt ks mu mv mw kw mx my mz na bi translated">7.测绘</h2><p id="67f6" class="pw-post-body-paragraph kf kg iq kh b ki nb jr kk kl nc ju kn ko nd kq kr ks ne ku kv kw nf ky kz la ij bi translated">让我们看看如何使用<em class="of"> matplotlib </em>库可视化数据。我们还可以进一步检查数据集在不同 K 值下的表现。下面我绘制了 K = 1，5，11。</p><p id="245b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通常，我们可以观察到，K 值越低，训练数据的过度拟合程度越高。该模型尝试使用较低的 K 值更准确地预测每个点。结果，我们可以观察到分类区域之间的边界是锯齿状的，并且随着局部变化而剧烈变化。</p><p id="2449" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">查看 K = 11 的 KNN，我们可以看到分类区域之间的边界相对更平滑。这种 KNN 模型在捕捉全球趋势方面变得相对更好，并允许它更通用于一个持续的测试集。</p><pre class="ll lm ln lo gt og oh oi oj aw ok bi"><span id="e4e2" class="mi mj iq oh b gy ol om l on oo">from adspy_shared_utilities import plot_two_class_knn</span><span id="f0f9" class="mi mj iq oh b gy op om l on oo">X_train, X_test, y_train, y_test = train_test_split(X_C2, y_C2,<br/> random_state=0)</span><span id="f41c" class="mi mj iq oh b gy op om l on oo">plot_two_class_knn(X_train, y_train, 1, ‘uniform’, X_test, y_test)<br/>plot_two_class_knn(X_train, y_train, 5, ‘uniform’, X_test, y_test)<br/>plot_two_class_knn(X_train, y_train, 11, ‘uniform’, X_test, y_test)</span></pre><div class="ll lm ln lo gt ab cb"><figure class="ot lp ou ov ow ox oy paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/ad96c46840aec60865c9d5c6bb14ad40.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*kPd0IT2blO9_bPuE-JHwcw.png"/></div></figure><figure class="ot lp ou ov ow ox oy paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/cae6346e0f1634eaad8cef2f5bfda784.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*78XhTen0XncNEOJHSY7-dQ.png"/></div></figure><figure class="ot lp ou ov ow ox oy paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/b1c106d933711f9643008ff9e7f701d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*dYDEUEKB-jUdPS_0YJze-A.png"/></div><p class="lw lx gj gh gi ly lz bd b be z dk oz di pa pb translated">K = 1，5，11</p></figure></div></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="b0b6" class="nu mj iq bd mk nv pc nx mn ny pd oa mq jw pe jx mt jz pf ka mw kc pg kd mz oe bi translated">尾注</h1><p id="1876" class="pw-post-body-paragraph kf kg iq kh b ki nb jr kk kl nc ju kn ko nd kq kr ks ne ku kv kw nf ky kz la ij bi translated">我通过由 Coursera 主办的密歇根大学 MOOC“Python 中的应用机器学习”了解到了这一点。</p><p id="64d1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你有问题或者想讨论后新冠肺炎世界，请随时联系我，LinkedIn ！</p><p id="67d1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我希望我能够以这样或那样的方式帮助您学习数据科学方法！</p><p id="b766" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是另一篇数据科学文章！</p><div class="ph pi gp gr pj pk"><a href="https://medium.com/python-in-plain-english/linear-regressions-with-scikitlearn-a5d54efe898f" rel="noopener follow" target="_blank"><div class="pl ab fo"><div class="pm ab pn cl cj po"><h2 class="bd ir gy z fp pp fr fs pq fu fw ip bi translated">使用 scikit-learn 进行线性回归</h2><div class="pr l"><h3 class="bd b gy z fp pp fr fs pq fu fw dk translated">本文应该足以涵盖如何在 python 中运行构造一个简单的线性回归；它还将包含…</h3></div><div class="ps l"><p class="bd b dl z fp pp fr fs pq fu fw dk translated">medium.com</p></div></div><div class="pt l"><div class="pu l pv pw px pt py lu pk"/></div></div></a></div><ul class=""><li id="fa24" class="ng nh iq kh b ki kj kl km ko ni ks nj kw nk la pz nm nn no bi translated"><a class="ae ma" href="https://medium.com/tag/machine-learning" rel="noopener">机器学习</a></li><li id="b9c6" class="ng nh iq kh b ki np kl nq ko nr ks ns kw nt la pz nm nn no bi translated"><a class="ae ma" href="https://medium.com/tag/data-analysis" rel="noopener">数据分析</a></li><li id="ad5c" class="ng nh iq kh b ki np kl nq ko nr ks ns kw nt la pz nm nn no bi translated"><a class="ae ma" href="https://medium.com/tag/data-analytics" rel="noopener">数据分析</a></li></ul></div></div>    
</body>
</html>