<html>
<head>
<title>Counterfactual Explanations in Model Interpretations</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">模型解释中的反事实解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/counterfactual-explanations-in-model-interpretations-a73caec5b74b?source=collection_archive---------23-----------------------#2020-07-30">https://towardsdatascience.com/counterfactual-explanations-in-model-interpretations-a73caec5b74b?source=collection_archive---------23-----------------------#2020-07-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="702d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf">我们回顾了从模型中产生可操作的解释和见解的方法</em></h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/27696b294bebd7c12635ed04340b4855.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*q4lkuadCxopyPFGq"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">由<a class="ae kw" href="https://unsplash.com/@joelfilip?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">乔尔·菲利普</a>在<a class="ae kw" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="daee" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">对比涉及特征属性的模型解释方法<a class="ae kw" rel="noopener" target="_blank" href="/exploring-methods-for-model-agnostic-interpretation-816304cb6e71">如前一篇文章</a>中所讨论的，反事实是解释的一个有趣部分，它允许对机器学习模型进行事后解释。</p><p id="bd70" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在这篇文章中，我讨论了几种反事实解释方法的一些背景，包括那些非常注重多样性的方法以及另一种由原型引导的方法。这篇文章是对我和他人参考的概念的直觉练习。</p><p id="35c1" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">讨论的主题:</p><ul class=""><li id="5b03" class="lt lu iq kz b la lb ld le lg lv lk lw lo lx ls ly lz ma mb bi translated"><strong class="kz ir">反事实解释和基本形式</strong></li><li id="5e50" class="lt lu iq kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated"><strong class="kz ir">不同的反事实解释(骰子)</strong></li><li id="9734" class="lt lu iq kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated"><strong class="kz ir">原型引导的反事实</strong></li></ul><h1 id="fcc7" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">反事实解释和基本形式</h1><p id="5b46" class="pw-post-body-paragraph kx ky iq kz b la mz jr lc ld na ju lf lg nb li lj lk nc lm ln lo nd lq lr ls ij bi translated">在它的核心，反事实允许我们采取行动，以导致某种结果。就机器学习而言，动作是模型特征的变化，而结果是期望的目标响应。数据基本上被扰乱，直到返回对应于远离原始模型的模型预测类的新实例。因为有各种方法可以达到相同的结果，所以可能有多种反事实。</p><p id="bef2" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">一个常见的例子和用例是贷款审批。客户可能需要增加他们的收入或教育的一些数额，以批准某些类型的贷款。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi ne"><img src="../Images/37d8d1c89b5a2b693d64efc03f8ce93d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*Wf_nstxpjUWPHu8nAte0xQ.gif"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">来源:微软研究博客</p></figure><p id="e521" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">由于反事实可能性的空间相当大，评估有效性的度量标准通常分为三个主要方面:稀疏性、多样性和接近性。</p><ul class=""><li id="c713" class="lt lu iq kz b la lb ld le lg lv lk lw lo lx ls ly lz ma mb bi translated">稀疏性与需要更改以达到输出类的要素数量相关联</li><li id="8a2d" class="lt lu iq kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated">多样性处理生成的反事实之间的距离，并用于确保不同的方式改变到输出类跨度很大</li><li id="418f" class="lt lu iq kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated">接近度与输出和原始实例之间的相似性有关。从概念上讲，这是一个衡量做出改变有多容易的标准</li></ul><h2 id="f760" class="nf mi iq bd mj ng nh dn mn ni nj dp mr lg nk nl mt lk nm nn mv lo no np mx nq bi translated">基本形式</h2><p id="05ad" class="pw-post-body-paragraph kx ky iq kz b la mz jr lc ld na ju lf lg nb li lj lk nc lm ln lo nd lq lr ls ij bi translated">为了更好地理解这个主题，我们从一个标准的分类器及其反事实目标函数的修改开始</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nr"><img src="../Images/86d8dd6995d8ade9a4dc78e0cb336a78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TDqi_qOjWrSU6iLv63siGQ.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">f 是模型。xi 是最初的例子。易是最初的目标反应。p 是在损失函数上优化的权重上的正则化。“x”是反事实的例子。y 是所需的目标类。d 是距离函数。λ是平衡/正则化参数。</p></figure><p id="7ec0" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">后一个目标函数的第一项实质上引导对新输出的搜索。第二项是距离函数<em class="ns"> d </em>，它描述了原始实例和反事实之间的差异。这包括所有要素之间的距离，其中连续和分类要素以特定方式处理。这一项由中位数绝对偏差(MAD)来衡量。正则化参数<em class="ns"> λ </em>平衡了两项之间的距离。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nt"><img src="../Images/3d96606cd6115e05823b11d8bf9adbd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TgWceiG8J669Dk2OjvuSDw.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">p 是特征计数。MAD 是中位数绝对偏差。s 是特色。n 是一些数据集。</p></figure><p id="b7bf" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">MAD 值对异常值相当稳健，但对某些数据集仍有限制。下面几节提到了处理这个问题的不同方法。一种方法使用修改的 MAD 阈值，另一种方法简单地找到在扰动技术中使用 MAD 的替代方法。</p><p id="d16d" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">从这里开始，工作变成了寻找反事实的优化问题。作者提到了 ADAM，尽管也可以使用其他优化器。由于问题的非凸性质，不同的最小值被用作生成多种反事实的不同集合的方法。</p><p id="1745" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">以下章节中讨论的方法提供了一些处理目前为止所涉及的策略的替代方案，并且总体上，还提供了对反事实目标函数的一般形式的扩展和改进。</p><p id="6e86" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">下面我们来回顾一下:</p><ul class=""><li id="eef0" class="lt lu iq kz b la lb ld le lg lv lk lw lo lx ls ly lz ma mb bi translated"><strong class="kz ir">多样的反事实解释(骰子)</strong></li><li id="4cbe" class="lt lu iq kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated"><strong class="kz ir">原型引导的反事实</strong></li></ul><h1 id="d319" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">不同的反事实解释(DiCE)</h1><p id="6cd3" class="pw-post-body-paragraph kx ky iq kz b la mz jr lc ld na ju lf lg nb li lj lk nc lm ln lo nd lq lr ls ij bi translated">多样性是反事实的一个重要属性。毕竟，根据使用案例和业务需求，太少和太相似的选项可能会成为瓶颈。以贷款为例，拥有选择与你的位置、收入、职业或教育相关的变化的选择权，对客户和贷方都有好处。</p><p id="3da6" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">多样化的反事实解释方法试图提供一种平衡多样性和可行性的途径。如果没有如上所述的适当考虑稀疏性和邻近性，多样性本身可能并不总是有用的。可能有这样的情况，需要改变的特性数量可能太多，或者需要的改变太大而不可行。此外，在不提供域约束的情况下，可能存在这样的场景，其中反事实接近原始实例，但是仍然在真实世界域之外。最终，理想的选择将为个人提供不仅多样而且可行的变化，这些变化是可行的并且在他们的能力范围内。</p><p id="b812" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">作者用来提升这一属性的策略导致了多样性度量，决定性点过程(DPP ),它考虑了邻近性和约束。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nu"><img src="../Images/0826644e2faf50f8093c1dd482dd07f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K_E9UeBXnMEVIRceM5lVLw.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">k 是核矩阵。d 是距离函数。“x”是反事实的例子。</p></figure><p id="d6ea" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">耦合<em class="ns"> dpp_diversity </em>以及调整上述反事实的基本形式，我们在所有生成的反事实上建立以下优化框架:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nv"><img src="../Images/a3c8cea1cb91e5de863a249a16d815aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CbHtrlH63A_v0qtEUhJ9cg.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">x 是一个反事实。x 是原始实例。k 是反事实的总数。λ1 和λ2 是平衡参数。y 是期望的目标响应。</p></figure><p id="f70d" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">第一项和第二项类似于在基本形式中发现的那些，其中前者涉及将搜索导向期望的结果，而后者涉及反事实和原始实例之间的距离。第三项是我们刚刚引入的<em class="ns"> dpp_diversity </em>以及一个额外的平衡超参数<em class="ns"> λ </em> ₂.</p><p id="0b36" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">对于连续变量，距离函数<em class="ns"> d </em>由类似于基本形式的 MAD 引导；然而，对于分类变量，这种方法就不那么简单了(毕竟，我们如何定义像职业这样的特征中类别之间的距离呢？)这种方法更多地采用二进制类型的赋值:如果特征与原始实例匹配，则距离取为 1，否则取为 0。</p><p id="728b" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">与上一节一样，从这里开始本质上是一个优化问题，作者使用带有指定搜索参数的梯度下降。</p><h1 id="ff2e" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">原型引导的反事实</h1><p id="044c" class="pw-post-body-paragraph kx ky iq kz b la mz jr lc ld na ju lf lg nb li lj lk nc lm ln lo nd lq lr ls ij bi translated">另一种寻找可解释的反事实解释的方法涉及到类原型的指导。这样做的一个重要目的是加速反事实搜索过程。我们可以考虑在与实时决策相关的场景中对快速计算的需求。</p><p id="96a0" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">原型基本上是一个代表数据集的实例。作者通过使用 k-NN 实例与数据集的代表性部分耦合的编码器或者通过使用 k-dd 方法来选择原型。第 3.3 节提供了更多详细信息。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/2d2486a3dad0e070f495b5743b3838af.png" data-original-src="https://miro.medium.com/v2/resize:fit:898/format:webp/1*rjVyk2SjngFPf03ySDn1fA.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">为类别 I、类别数量 K 和编码器型号 ENC 定义的类别原型</p></figure><p id="3724" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在高层次上，这种方法的主要概念包括将一个额外的损失函数项整合到第一节的基本反事实方程的修改版本中，该损失函数项说明了这些原型。这为反事实搜索过程中的原型提供了指导。</p><p id="72c3" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这在计算上要求较低，尤其是在我们只能访问模型预测函数的情况下。而不是传统地仅使用与预测相关联的损失函数来偏离原始类别；该方法可以避开该项，而简单地使用对应于原型的损失函数。</p><p id="ce4c" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">正如多样化的反事实方法一样，在搜索过程中处理分类特征的想法有点模糊。第一节和第二节中介绍的方法都应用了某种类型的二进制，这里的策略稍微复杂一点，使用嵌入技术将分类变量投影到数值空间中。这是通过考虑特征之间的不相似性的度量以及它们的预测概率来实现的。附录 C 对此进行了更详细的描述。</p><p id="9133" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">再次，从这里我们可以继续优化，以产生反事实的解释。</p><p id="fa2d" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">值得注意的是，这个方法总体上提供了几个有趣的属性，以便提供快速的结果。首先，优化使用快速迭代收缩阈值算法(FISTA)作为快速收敛到结果的手段。其次，自动微分可以利用深度学习架构和权重进行显式评估。最后，如前所述，增加原型损失项可以灵活地绕过计算瓶颈。这对于黑盒用例尤其重要。</p><h1 id="1a4c" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">摘要</h1><p id="850d" class="pw-post-body-paragraph kx ky iq kz b la mz jr lc ld na ju lf lg nb li lj lk nc lm ln lo nd lq lr ls ij bi translated">总之，反事实解释可以通过允许我们改变个别实例作为达到预期结果的途径，从而为模型预测提供可操作的见解。</p><ul class=""><li id="4404" class="lt lu iq kz b la lb ld le lg lv lk lw lo lx ls ly lz ma mb bi translated">我们首先回顾了模型解释中反事实背后的一般思想及其一般形式</li><li id="2afc" class="lt lu iq kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated">然后，我们讨论在此基础上构建的扩展、修改和优化策略，探索强调多样性的方法以及原型提供的指导</li></ul><h1 id="2fdc" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">参考</h1><p id="0f83" class="pw-post-body-paragraph kx ky iq kz b la mz jr lc ld na ju lf lg nb li lj lk nc lm ln lo nd lq lr ls ij bi translated">[1]s .沃希特、b .米特斯塔特和 c .拉塞尔(2017)“不打开黑盒的反事实解释:自动化决策和 GDPR。”</p><p id="f179" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">[2] Mothilal，R. K .，Sharma A .，和 Tan，C. (2020)“通过不同的反事实解释来解释机器学习分类器。”</p><p id="3f0f" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">[3] Arnaud，V. L .和 Klaise，J. (2019)“原型指导下的可解释的反事实解释”</p></div></div>    
</body>
</html>