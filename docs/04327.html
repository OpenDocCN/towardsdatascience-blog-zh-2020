<html>
<head>
<title>TensorFlow 2.1: A How-To</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TensorFlow 2.1:操作指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tensorflow-2-1-a-how-to-a3e6400d0899?source=collection_archive---------18-----------------------#2020-04-19">https://towardsdatascience.com/tensorflow-2-1-a-how-to-a3e6400d0899?source=collection_archive---------18-----------------------#2020-04-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/35430c976d5ba2221165c7d7e18fde06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GQ-r7pPKvYA1Y9-nF4-3oA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">我们深入吧！—<a class="ae jg" href="https://www.instagram.com/Didssph/" rel="noopener ugc nofollow" target="_blank">Dids</a>的惊人画面</p></figure><div class=""/><div class=""><h2 id="91a5" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">keras模式、渴望模式和图形模式</h2></div><p id="cd79" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你和我一样，是一个正常人，你可能已经经历过有时你是如何陷入你的应用程序的开发中，以至于很难找到一个时刻停下来思考我们是否以最有效的方式做事:<em class="lu">我们是否使用了正确的工具？哪个框架最适合我的用例？这种方法可扩展吗？我们考虑到可伸缩性了吗？</em></p><p id="71e5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在AI领域更是如此。我们都知道人工智能是一个快速发展的领域。每天都有新的研究发表。正在高速开发的主要人工智能框架之间存在巨大的竞争。新的硬件架构、芯片和优化被发布以支持日益增长的人工智能应用的部署…然而，尽管有所有的华而不实，有时你需要停下来重新考虑。</p><p id="69b8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">什么时候是停下来重新考虑的好时机？只有你会知道。对我来说，这一刻是最近才到来的。自从我进入这个领域以来，我一直在工作和个人项目中使用<a class="ae jg" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>和<a class="ae jg" href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf" rel="noopener ugc nofollow" target="_blank"> Tensorflow 1.x </a> (TF1)。我完全喜欢Keras库的高级方法和Tensorlfow的低级方法，当您需要更多定制时，它们可以让您在引擎盖下进行更改。</p><p id="fd97" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">尽管我是Keras-Tensorflow婚姻的超级粉丝，但总有一个非常具体的负面因素让这对夫妇远离田园生活:<strong class="la jk">调试功能</strong>。正如你已经知道的，在Tensorflow中，有一个先定义计算图，然后编译它(或者移动到GPU)然后非常高效地运行它的范例。这种范式非常好，从技术上讲也很有意义，但是，一旦你在GPU中有了模型，就几乎不可能调试它。</p><p id="f3b5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这就是为什么在TensorFlow 2.0的alpha版本<a class="ae jg" href="https://github.com/tensorflow/tensorflow/releases/tag/v2.0.0-alpha0" rel="noopener ugc nofollow" target="_blank">发布大约一年后，我决定尝试TensorFlow 2.1(我可以从TF2.0开始，但我们都知道我们喜欢新软件)，并与您分享它的进展。</a></p><h1 id="23b5" class="lv lw jj bd lx ly lz ma mb mc md me mf kp mg kq mh ks mi kt mj kv mk kw ml mm bi translated">张量流2.1</h1><p id="756b" class="pw-post-body-paragraph ky kz jj la b lb mn kk ld le mo kn lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">令人难过的事实是，我很难弄清楚我应该如何使用这个新的TensorFlow版本，即著名的2.1稳定版本。我知道，这里有<a class="ae jg" href="https://www.tensorflow.org/tutorials" rel="noopener ugc nofollow" target="_blank">大量的教程</a>，笔记本和代码手册……然而，我发现困难并不在于编程，因为归根结底，这只是Python，而是范式的转变。简而言之:TensorFlow 2编程不同于TensorFlow 1，就像面向对象编程不同于函数式编程一样。</p><p id="5a55" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在做了一些实验后，我发现在TensorFlow 2.1中有3种建模方法:</p><ul class=""><li id="a0eb" class="ms mt jj la b lb lc le lf lh mu ll mv lp mw lt mx my mz na bi translated">Keras模式(<code class="fe nb nc nd ne b">tf.keras</code>):基于图形定义，稍后运行图形。</li><li id="4894" class="ms mt jj la b lb nf le ng lh nh ll ni lp nj lt mx my mz na bi translated">急切模式:基于定义一个迭代地执行定义一个图的所有操作。</li><li id="e161" class="ms mt jj la b lb nf le ng lh nh ll ni lp nj lt mx my mz na bi translated">图表模式(<code class="fe nb nc nd ne b">tf.function</code>):之前两种方法的混合。</li></ul><p id="5e6d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">无聊到此为止。给我看看代码！</p><h2 id="ad8f" class="nk lw jj bd lx nl nm dn mb nn no dp mf lh np nq mh ll nr ns mj lp nt nu ml nv bi translated">Keras模式</h2><figure class="nw nx ny nz gt iv"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="83fe" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是我们都习惯的标准用法。只使用普通的Keras和自定义损失函数，以平方误差损失为特征。该网络是一个3密集层深度网络。</p><pre class="nw nx ny nz gt oc ne od oe aw of bi"><span id="e909" class="nk lw jj ne b gy og oh l oi oj"># The network<br/>x = Input(shape=[20])<br/>h = Dense(units=20, activation='relu')(x)<br/>h = Dense(units=10, activation='relu')(h)<br/>y = Dense(units=1)(h)</span></pre><p id="1ef1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里的目标是教一个网络学习如何对一个20个元素的向量求和。因此，我们向网络输入一个数据集<code class="fe nb nc nd ne b">[10000 x 20]</code>，即10000个样本，每个样本有20个特征(要求和的元素)。那是在:</p><pre class="nw nx ny nz gt oc ne od oe aw of bi"><span id="53dc" class="nk lw jj ne b gy og oh l oi oj"># Training samples<br/>train_samples = tf.random.normal(shape=(10000, 20))<br/>train_targets = tf.reduce_sum(train_samples, axis=-1)<br/>test_samples = tf.random.normal(shape=(100, 20))<br/>test_targets = tf.reduce_sum(test_samples, axis=-1)</span></pre><p id="2d07" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以运行这个例子，得到通常漂亮的Keras输出:</p><pre class="nw nx ny nz gt oc ne od oe aw of bi"><span id="bf2d" class="nk lw jj ne b gy og oh l oi oj">Epoch 1/10<br/>10000/10000 [==============================] - 10s 1ms/sample - loss: 1.6754 - val_loss: 0.0481<br/>Epoch 2/10<br/>10000/10000 [==============================] - 10s 981us/sample - loss: 0.0227 - val_loss: 0.0116<br/>Epoch 3/10<br/>10000/10000 [==============================] - 10s 971us/sample - loss: 0.0101 - val_loss: 0.0070</span></pre><p id="0deb" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里发生了什么？嗯，没什么，只是一个Keras玩具的例子训练在10秒每时代(在一个英伟达GTX 1080 Ti)。编程范式呢？和之前一样，就像在TF1.x中，你定义了图形，然后你通过调用<code class="fe nb nc nd ne b">keras.models.Model.fit</code>来运行它。调试功能呢？和以前一样…没有。你甚至不能在损失函数中设置一个简单的断点。</p><p id="d518" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">运行完这段代码后，您可能会疑惑一个非常明显的问题:TensorFlow 2版本承诺的所有优秀特性都到哪里去了？你是对的。如果与Keras包的集成意味着不需要安装额外的包，那么优势是什么？</p><p id="e245" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">除此之外，还有一个更重要的问题:众所周知的调试特性在哪里？幸运的是，这是急切模式来拯救。</p><h2 id="9e7d" class="nk lw jj bd lx nl nm dn mb nn no dp mf lh np nq mh ll nr ns mj lp nt nu ml nv bi translated">渴望模式</h2><p id="9a2b" class="pw-post-body-paragraph ky kz jj la b lb mn kk ld le mo kn lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">如果我告诉你有一种方法可以交互地构建你的模型，并且可以访问运行时的所有操作，那会怎么样？— 如果你激动得发抖，这意味着你已经经历了10个纪元后随机批次运行时错误的深刻痛苦……是的，我知道，我也去过那里，我们可以在那些战斗后开始称自己为战友。</p><p id="11b4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">嗯，是的，这就是你要找的操作模式。在这种模式下，所有的张量操作都是交互式的，你可以设置一个断点并访问任何中间张量变量。然而，这种灵活性是有代价的:更显式的代码。让我们来看看:</p><figure class="nw nx ny nz gt iv"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="cd65" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">阅读完代码后，你脑海中出现的第一件事可能是:许多代码只是为了做一个<code class="fe nb nc nd ne b">model.compile</code>和一个<code class="fe nb nc nd ne b">model.fit</code>。是的，没错。但另一方面，你可以控制之前发生的一切。引擎盖下发生了什么？训练循环。</p><p id="edf1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以现在情况变了。在这种方法中，你可以从头开始设计事情如何进行。以下是您现在可以指定的内容:</p><ul class=""><li id="5109" class="ms mt jj la b lb lc le lf lh mu ll mv lp mw lt mx my mz na bi translated">度量:曾经想要测量每个样本、批次或任何其他自定义统计的结果吗？没问题，我们掩护你。现在，您可以使用传统的移动平均线或任何其他自定义指标。</li><li id="fc17" class="ms mt jj la b lb nf le ng lh nh ll ni lp nj lt mx my mz na bi translated">损失函数:曾经想做疯狂的多参数依赖损失函数？嗯，这也解决了，你可以在损失函数定义中得到所有你想要的技巧，而不用Keras用它的<code class="fe nb nc nd ne b">_standarize_user_data</code> ( <a class="ae jg" href="https://github.com/keras-team/keras/blob/f242c6421fe93468064441551cdab66e70f631d8/keras/engine/training.py#L470" rel="noopener ugc nofollow" target="_blank">链接</a>)来抱怨它</li><li id="3e2a" class="ms mt jj la b lb nf le ng lh nh ll ni lp nj lt mx my mz na bi translated">梯度:您可以访问梯度，并定义向前和向后传递的细节。是的，最后，请和我一起欢呼吧！</li></ul><p id="f298" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这些指标是用新的<code class="fe nb nc nd ne b">tf.keras.metrics</code> <a class="ae jg" href="https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Mean" rel="noopener ugc nofollow" target="_blank"> API </a>指定的。您只需获取想要的指标，定义它并像这样使用它:</p><pre class="nw nx ny nz gt oc ne od oe aw of bi"><span id="879f" class="nk lw jj ne b gy og oh l oi oj"># Getting metric instanced<br/>metric = tf.keras.metrics.Mean() </span><span id="91fc" class="nk lw jj ne b gy ok oh l oi oj"># Run your model to get the loss and update the metric<br/>loss = [...]<br/>metric(loss)</span><span id="cfd5" class="nk lw jj ne b gy ok oh l oi oj"># Print the metric <br/>print('Training Loss: %.3f' % metric.result().numpy())</span></pre><p id="5445" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">损失函数和梯度分别在正向和反向过程中计算。在这种方法中，向前传球必须由<code class="fe nb nc nd ne b">tf.GradientTape</code>记录。<code class="fe nb nc nd ne b">tf.GradientTape</code>将跟踪(或记录)前向传递中完成的所有张量操作，因此它可以计算后向传递中的梯度。换句话说:为了向后跑，你必须记住你向前走过的路。</p><pre class="nw nx ny nz gt oc ne od oe aw of bi"><span id="f1a3" class="nk lw jj ne b gy og oh l oi oj"># Forward pass: needs to be recorded by gradient tape<br/>with tf.GradientTape() as tape:<br/>    y_pred = model(x)<br/>    loss = loss_compute(y_true, y_pred)</span><span id="094a" class="nk lw jj ne b gy ok oh l oi oj"># Backward pass:<br/>gradients = tape.gradient(loss, model.trainable_weights)<br/>optimizer.apply_gradients(zip(gradients, model.trainable_weights))</span></pre><p id="35ef" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这非常简单，在向前传递中，你运行你的预测，并通过计算损失来看你做得有多好。在反向过程中，通过计算梯度来检查权重如何影响损失，然后通过更新权重(在优化器的帮助下)来尝试最小化损失。</p><p id="32f4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您还可以在代码中注意到，在每个时期结束时，会计算验证损失(通过只运行正向传递而不更新权重)。</p><p id="a514" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们看看这与之前的方法相比如何(我将输出减少了一点，这样它就可以放在这里):</p><pre class="nw nx ny nz gt oc ne od oe aw of bi"><span id="fd71" class="nk lw jj ne b gy og oh l oi oj">Epoch 1:<br/>Loss: 1.310: 100%|███████████| 10000/10000 [00:41&lt;00:00, 239.70it/s]<br/>Epoch 2:<br/>Loss: 0.018: 100%|███████████| 10000/10000 [00:41&lt;00:00, 240.21it/s]<br/>Epoch 3:<br/>Loss: 0.010: 100%|███████████| 10000/10000 [00:41&lt;00:00, 239.28it/s]</span></pre><p id="d768" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">发生了什么事？你注意到了吗？在同一台机器上，每个时期花费了41秒，即4倍的时间增量…这只是一个虚拟模型。你能想象这对一个真实的用例模型，如RetinaNet、YOLO或MaskRCNN，会有多大的影响吗？</p><p id="669c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">幸运的是，优秀的TensorFlow人员意识到了这一点，并实现了图形模式。</p><h2 id="eb9e" class="nk lw jj bd lx nl nm dn mb nn no dp mf lh np nq mh ll nr ns mj lp nt nu ml nv bi translated">图表模式</h2><p id="74fa" class="pw-post-body-paragraph ky kz jj la b lb mn kk ld le mo kn lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">图表模式(来自AutoGraph或<code class="fe nb nc nd ne b">tf.function</code>)是前两种模式的混合模式。这里的<a class="ae jg" href="https://www.tensorflow.org/guide/function#keras_and_autograph" rel="noopener ugc nofollow" target="_blank">这里的</a>和这里的<a class="ae jg" href="https://www.tensorflow.org/guide/effective_tf2#recommendations_for_idiomatic_tensorflow_20" rel="noopener ugc nofollow" target="_blank">这里的</a>你可以大致了解一下这是什么。但是我发现那些指南有点混乱，所以我用我自己的话来解释。</p><p id="4bce" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果Keras模式是关于定义图形并稍后在GPU中运行它，而eager模式是关于交互式地执行每个步骤，那么graph模式允许您像在eager模式中一样编码，但运行训练的速度几乎与在Keras模式中一样快(所以是的，在GPU中)。</p><p id="0695" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">关于eager模式的唯一变化是，在graph模式中，您将代码分解成小函数，并用<code class="fe nb nc nd ne b">@tf.function</code>对这些函数进行注释。让我们来看看事情是如何变化的:</p><figure class="nw nx ny nz gt iv"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="72aa" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在你可以看到前向和后向传递计算是如何被重构为两个用<code class="fe nb nc nd ne b">@tf.function</code>装饰器注释的函数的。</p><p id="27a1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">那么这里到底发生了什么？简单。每当你用<code class="fe nb nc nd ne b">@tf.function</code> decorator注释一个函数时，你就像Keras一样将这些操作“编译”到GPU中。因此，通过注释您的函数，您可以告诉TensorFlow在GPU中的优化图形中运行这些操作。</p><p id="4c66" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在引擎盖下，真正发生的是函数正在被<a class="ae jg" href="https://www.tensorflow.org/api_docs/python/tf/autograph" rel="noopener ugc nofollow" target="_blank">亲笔</a>、<code class="fe nb nc nd ne b">tf.autograph</code>解析。AutoGraph将获取函数输入和输出，并从它们生成一个张量流图，这意味着，它将解析操作，以将输入的输出转换为张量流图。这个生成的图形将非常高效地运行到GPU中。</p><p id="1625" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这就是为什么它是一种混合模式，因为除了用<code class="fe nb nc nd ne b">@tf.function</code>装饰器注释的操作之外，所有的操作都是交互运行的。</p><p id="482e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这也意味着你可以访问所有的变量和张量，除了用<code class="fe nb nc nd ne b">@tf.function</code>修饰的函数中的变量和张量，你只能访问它的输入和输出。这种方法建立了一种非常清晰的调试方式，在这种方式下，您可以在渴望模式下开始交互式开发，然后，当您的模型准备就绪时，使用<code class="fe nb nc nd ne b">@tf.function</code>将其推向生产性能。听起来不错吧？让我们看看进展如何:</p><pre class="nw nx ny nz gt oc ne od oe aw of bi"><span id="2ae5" class="nk lw jj ne b gy og oh l oi oj">Epoch 1:<br/>Loss: 1.438: 100%|████████████| 10000/10000 [00:16&lt;00:00, 612.3it/s]<br/>Epoch 2:<br/>Loss: 0.015: 100%|████████████| 10000/10000 [00:16&lt;00:00, 615.0it/s]<br/>Epoch 3:<br/>Loss: 0.009:  72%|████████████| 7219/10000  [00:11&lt;00:04, 635.1it/s]</span></pre><p id="722e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">嗯，一个惊人的16s/纪元。您可能认为它不如Keras模式快，但另一方面，您可以获得所有的调试功能和非常接近的性能。</p><h2 id="d186" class="nk lw jj bd lx nl nm dn mb nn no dp mf lh np nq mh ll nr ns mj lp nt nu ml nv bi translated">结论</h2><p id="d60c" class="pw-post-body-paragraph ky kz jj la b lb mn kk ld le mo kn lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">如果您一直在关注这篇文章，那么您将不会感到惊讶，所有这些最终都归结为一个非常古老的软件问题:灵活性还是效率？渴望模式还是Keras模式？为什么要和解？使用图形模式！</p><p id="942e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在我看来，TensorFlow的工作人员在为我们这些开发人员提供更多灵活性方面做得非常出色，而且没有在效率方面做出太大的牺牲。所以从我的立场来看，我只能为他们说<em class="lu"> bravo </em>。</p></div></div>    
</body>
</html>