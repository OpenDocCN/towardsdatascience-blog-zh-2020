<html>
<head>
<title>Swarm Intelligence — Swarm-Based Dimensionality Reduction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">群体智能——基于群体的降维</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/swarm-intelligence-swarm-based-dimensionality-reduction-dfb3cdc55259?source=collection_archive---------24-----------------------#2020-01-17">https://towardsdatascience.com/swarm-intelligence-swarm-based-dimensionality-reduction-dfb3cdc55259?source=collection_archive---------24-----------------------#2020-01-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="be96" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">利用群体智能优化多元数据</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/f7d735a711de0dd78057a98ba7ff4e37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zREiXGkV5Jvh0r7PV_yHqw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">一群椋鸟——由詹姆斯·温斯科特在 Unsplash 上拍摄</p></figure><p id="68df" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi ls translated"><span class="l lt lu lv bm lw lx ly lz ma di">A</span><strong class="ky ir">b</strong>——一种基于群体的降维方法，受群体智能(SI)和主成分分析(PCA)的启发。它使用粒子群优化(PSO)的矢量化实现，以提高计算效率。该模型以标准 PCA 为基准。</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h2 id="3621" class="mi mj iq bd mk ml mm dn mn mo mp dp mq lf mr ms mt lj mu mv mw ln mx my mz na bi translated">介绍</h2><p id="ec66" class="pw-post-body-paragraph kw kx iq ky b kz nb jr lb lc nc ju le lf nd lh li lj ne ll lm ln nf lp lq lr ij bi translated">这些年来，技术发生了巨大的变化，随着个人和企业越来越能够访问更高的处理和计算能力、更大的内存容量、更智能和更高效的数据存储技术等等，无论是在内部还是在云中，技术访问差距都在逐年缩小。尽管如此，数据量仍呈指数级增长，预计这一趋势在可预见的未来还将继续。因此，降低海量数据集的维度是创建更有效的机器学习模型的最重要的方面之一。</p><h2 id="185c" class="mi mj iq bd mk ml mm dn mn mo mp dp mq lf mr ms mt lj mu mv mw ln mx my mz na bi translated">降维</h2><p id="9831" class="pw-post-body-paragraph kw kx iq ky b kz nb jr lb lc nc ju le lf nd lh li lj ne ll lm ln nf lp lq lr ij bi translated">目标是产生一个具有较低维度的新数据集，而不丢失其原始特征。与 PCA 一样，我们将使用协方差矩阵来确定方差和协方差。</p><p id="c0ed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">考虑一个由<em class="ng"> N </em>个特征和<em class="ng"> M </em>个观察值组成的数据集。可以描述为一系列的<em class="ng"> N </em>维向量，表示为一个<em class="ng"> M*N </em>矩阵。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/93953577cd2532b83bcf51715cba95e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rINwkWtahKAxTUj98c-VMw.png"/></div></div></figure><p id="a56e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中<em class="ng"> i ∈ {0，…，M} </em>和<em class="ng"> j ∈ {0，…，N} </em>。X 的协方差矩阵是通过从数据中减去平均值并乘以其转置，然后除以样本数而获得的。这是至关重要的，以便不同尺度的特征被同等地解释。它由下式给出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/25b290a8f3d608301e6d2efe3c0ef07e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5jT67eQkEqeEZafTGLh8Bw.png"/></div></div></figure><p id="0456" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果已经扣除了特征的平均值，协方差矩阵可以写成:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/bb4cd0bff67848d63b6a5c7b6dc24856.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wozr5WC5NFY4l5XefFPdfg.png"/></div></div></figure><p id="ff32" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，您可能会遇到略有不同的符号版本<em class="ng"> C_x </em>，特别是我们使用行向量来表示数据，而大多数引用将数据表示为列向量，这允许点积元素。尽管如此，使用这两种方法都会得到相同的结果。</p><p id="349c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们对协方差矩阵感兴趣的原因是，它描述了数据集内的方差以及元素间的协方差。视觉上，主对角线元素保存方差，而协方差信息跨越非对角线元素。例如，给定一个具有标记为<em class="ng"> {x，y，z} </em>的特征的三维数据集，我们得到以下表示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/5160b433d77627fbd6c211f9d5f8c0da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*okrr4c-it6KDNr8uaU38tA.png"/></div></div></figure><p id="6ff6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">PCA 的目的是找到一个线性变换，给定<em class="ng"> X </em>，生成一个低维数据集<em class="ng"> Y </em>。最终，我们会寻找另一个与原始基线性相关的基，它可以更有效地表示数据。这可以表示为:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/b12a206c089e668450e9ce27bfa6e226.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jXrbbJIjf5pW4Gu-N0eEVw.png"/></div></div></figure><p id="faf3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中<em class="ng"> P </em>是线性变换矩阵。考虑到这一点，主成分分析设定了转换数据的两个主要目标，即:</p><ol class=""><li id="df05" class="nj nk iq ky b kz la lc ld lf nl lj nm ln nn lr no np nq nr bi translated">最大化方差，即所有特征样本的可变性或信号。</li><li id="a693" class="nj nk iq ky b kz ns lc nt lf nu lj nv ln nw lr no np nq nr bi translated">最小化协方差，即冗余数据，以进一步压缩数据集。</li></ol><p id="6eb2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在实践中，我们需要优化线性变换<em class="ng"> P </em>，以便产生的数据集<em class="ng"> Y </em>在强调数据信号和抑制噪声或冗余信号方面更有效地表示数据。为此，我们需要最大化主对角元素，最小化对应协方差矩阵<em class="ng"> C_y </em>的非对角元素。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/86b0b6b2dde3b79bd803031a5093e7ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z-gZlwDCRKgApCu_xTBtOA.png"/></div></div></figure><p id="0478" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在很清楚，这是一个最大化/最小化问题，非常适合优化算法，其中包括群体智能模型，我们将使用该模型将低维数据集<em class="ng"> Y </em>拟合到最佳协方差矩阵<em class="ng"> C_y </em>。</p><h2 id="8450" class="mi mj iq bd mk ml mm dn mn mo mp dp mq lf mr ms mt lj mu mv mw ln mx my mz na bi translated">基于群体的方法</h2><p id="796a" class="pw-post-body-paragraph kw kx iq ky b kz nb jr lb lc nc ju le lf nd lh li lj ne ll lm ln nf lp lq lr ij bi translated">我们将在这里使用与前面描述的相似的符号，稍作修改以适应基于群体和矢量化的计算。我们为低维数据定义了以下符号:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/5ad8976c9409ab9e8493e8841809e5c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AAnMpr5o2d2DxHVXOLsusw.png"/></div></div></figure><p id="7d71" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中<em class="ng"> X </em>是一批<em class="ng"> Np </em>输入，每个输入的尺寸为<em class="ng"> M*N </em>，如前所述。</p><p id="4da8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将<em class="ng"> Y </em>定义为一批<em class="ng"> Np </em>输出，其中每个输出的维数为 M*K，其中<em class="ng"> K∈ R 和 K &lt; N </em>，以及<em class="ng"> P </em>一批维数为<em class="ng"> N*K </em>的<em class="ng"> Np </em>变换矩阵。变换矩阵的集合是要被训练并适合解的粒子。</p><p id="ae1e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">遵循这种模式，并参考<em class="ng"> C_y </em>定义，我们得出结论，矢量化协方差矩阵<em class="ng"> C_y </em>将具有维度<em class="ng"> Np*K*K </em>。</p><p id="721f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">健身功能</strong></p><p id="3482" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">适应度函数必须反映我们数据集的准确性，尽可能多地保留原始数据特征，并消除冗余或有噪声的数据。我们将提出两种适合度评估的方法，其中一种来自文献，而另一种已被证明在 Iris 数据集上优于它，因此将被使用。</p><p id="3d28" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以将适应度定义为信噪比(SNR) [1]:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/2c9bc145c9243f013f4ab41e4d5cda23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C0cLAVCj17PeM_HMg9cNvQ.png"/></div></div></figure><p id="d88e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中<em class="ng"> σ_signal </em>表示方差，<em class="ng"> σ_noise </em>表示协方差。高<em class="ng"> SNR </em> (≫ 1)表示高精度数据，而低 SNR 表示受噪声污染的数据。请注意，本文中的适应度是一个真正的正数<em class="ng"> SNR≥0 </em>，而不是一个百分比或有界数字。为确保信号最大化(方差→+∞)且噪声抵消(协方差→0)，我们将 SNR 定义为:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/62776a47338a05cc136def106d35b110.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uQx5m3ztWGgfQi2KqjHI4A.png"/></div></div></figure><p id="529f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">通过使用上面的 SNR 定义作为我们的适应度函数，该模型将惩罚低方差和高协方差。我们使用对数标度来获得更好的适应性解释能力。</p><p id="8cf4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在 Iris 数据集预测上胜过 SNR 度量的另一种方法是通过将适应度函数视为方差和协方差的加权和:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/964bee609203e051c9a03b9ff5ac5d2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*drUMmRn0wmteNcqufHlCmQ.png"/></div></div></figure><p id="bd88" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中<em class="ng"> α_1 </em>和<em class="ng"> α_2 </em>是控制各项贡献的加权系数。例如，为了进一步优化惩罚低方差，您可以使用<em class="ng"> α_1=5 </em>和<em class="ng"> α_2=1 </em>。</p><p id="2e18" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">粒子运动</strong></p><p id="9000" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一旦评估了适应度，粒子被移动以扫描更好的解决方案，即实现更高适应度分数的解决方案。粒子运动由以下方程控制，该方程将粒子向其个人最佳值<em class="ng"> p </em>和全局最佳值<em class="ng"> g </em>的方向移动。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/ef0df22550fded9e5259aa19bcf91b1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZKSV7spfi0Y_4B-N4QFdkg.png"/></div></div></figure><p id="9729" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中<em class="ng"> v[i] </em>代表第<em class="ng"> np 个</em> <em class="ng"> N*K 个</em>维质点在<em class="ng"> i </em>时段的速度，其中<em class="ng">NP</em><em class="ng">∈{ 0；Np} </em>，<em class="ng"> v[i-1] </em>前一历元中的速度，<em class="ng">R1</em>和<em class="ng">R2</em><em class="ng">Np</em><em class="ng">N * K</em>-均匀分布随机数的维矩阵，以及最后<em class="ng"> ω </em>控制前一速度对新速度的贡献的加权系数。</p><p id="65d5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面执行了<em class="ng"> Np </em>粒子速度的矢量化计算。之后，我们在知道每个粒子的速度的情况下计算粒子的新值:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/9c500318eab8f91c7c347752074c1096.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G-n8eZaspYY2Wqg5RS1bUA.png"/></div></div></figure><p id="48e9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一旦粒子被移动，我们可以重新评估适应值，并更新个人最佳值和全局最佳值。这要重复几次，直到满足终止标准。最终的全局最佳解决方案是最佳转换矩阵，在此基础上我们可以检索原始数据集<em class="ng"> X </em>的低维表示<em class="ng"> Y </em>。</p><h2 id="f616" class="mi mj iq bd mk ml mm dn mn mo mp dp mq lf mr ms mt lj mu mv mw ln mx my mz na bi translated">绩效基准</h2><p id="f408" class="pw-post-body-paragraph kw kx iq ky b kz nb jr lb lc nc ju le lf nd lh li lj ne ll lm ln nf lp lq lr ij bi translated">我们将通过数据表达能力来评估模型。低维数据集的可表达性将根据加权方差和协方差总和来测量，但也可以根据前面描述的信噪比来测量。</p><p id="2335" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在 Iris 数据集上进行的 1000 次 SBDR 运行的样本测试，每次有 100 个时期和 40 个粒子，获得了 5.87 的平均适应度得分，而标准 PCA 获得了 1.96 的适应度得分。下图显示了 SBDR 的表现，以适应度得分表示，并与标准 PCA 并列显示。</p><p id="8a50" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，生成的数据集用于在该数据集上训练随机森林模型，并在测试集上进行预测。标准 PCA 实现了 80%的预测准确度，而 SBDR 在 1000 次运行中实现了 86.5%的平均准确度。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/91fb8017e80d0fc1566feb06c1a68eb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kr2fw_mmB-ODMtY1M9PZXg.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/5628641f47d5687ec1b2a36a07fd4959.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GlJvxsWOrendURT3DoBb5g.png"/></div></div></figure><h2 id="6d05" class="mi mj iq bd mk ml mm dn mn mo mp dp mq lf mr ms mt lj mu mv mw ln mx my mz na bi translated">结束了👋</h2><p id="5587" class="pw-post-body-paragraph kw kx iq ky b kz nb jr lb lc nc ju le lf nd lh li lj ne ll lm ln nf lp lq lr ij bi translated">如果你能走到这一步，谢谢你留下来！</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><p id="c7a3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ng"> [1] J. Shlens，2014，《主成分分析教程》</em></p><p id="b959" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ng"> [2] J .肯尼迪，r .埃伯哈特，1995，“粒子群优化”</em></p></div></div>    
</body>
</html>