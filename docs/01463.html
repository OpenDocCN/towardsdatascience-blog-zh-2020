<html>
<head>
<title>BERT: Multilabel Text Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多标签文本分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/bert-multilabel-text-classification-a7f560db34e5?source=collection_archive---------19-----------------------#2020-02-09">https://towardsdatascience.com/bert-multilabel-text-classification-a7f560db34e5?source=collection_archive---------19-----------------------#2020-02-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><h1 id="93e3" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">介绍</h1><p id="965d" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在<a class="ae lm" rel="noopener" target="_blank" href="/multi-label-text-classification-5c505fdedca8">我的上一篇文章</a>中，我介绍了各种机器学习方法，这些方法能够为单个电影描述指定一组相关的流派(请访问文章获取数据集)。分类器链模型获得了最好的 F1 值= 0.43。我要验证的想法是用 BERT 嵌入来训练神经网络。</p><p id="ba1d" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated"><a class="ae lm" href="https://github.com/google-research/bert" rel="noopener ugc nofollow" target="_blank"> BERT </a>(来自变形金刚的双向编码器表示)是由谷歌人工智能语言的研究人员开发的一个新模型。</p><p id="27c3" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">它的主要创新是将一种流行的注意力模型 Transformer 的双向训练应用于语言建模。这导致了比单向语言模型更深刻的语言上下文和流程感。</p><h1 id="dea1" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">密码</h1><p id="d77d" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><a class="ae lm" href="https://pypi.org/project/bert-serving-server/" rel="noopener ugc nofollow" target="_blank"> Bert_serving </a>支持使用 Bert 模型作为句子编码服务，用于将可变长度的句子映射到固定长度的句子。</p><p id="aafa" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">为了找到最佳的参数，我使用了<a class="ae lm" href="https://github.com/IDSIA/sacred" rel="noopener ugc nofollow" target="_blank">神圣模块</a>。神圣是一个工具，帮助您配置，组织，记录和复制实验，以便:</p><ul class=""><li id="ca02" class="ls lt it kq b kr ln kv lo kz lu ld lv lh lw ll lx ly lz ma bi translated">记录你实验的所有参数</li><li id="b82c" class="ls lt it kq b kr mb kv mc kz md ld me lh mf ll lx ly lz ma bi translated">轻松运行不同设置的实验</li><li id="53a9" class="ls lt it kq b kr mb kv mc kz md ld me lh mf ll lx ly lz ma bi translated">在数据库中保存单次运行的配置</li></ul><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="ml mm l"/></div></figure><p id="5c6f" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">修改后的参数如下:</p><ol class=""><li id="271f" class="ls lt it kq b kr ln kv lo kz lu ld lv lh lw ll mn ly lz ma bi translated"><strong class="kq iu"> max_seq_len </strong> —序列的最大长度。找到的最佳值是<strong class="kq iu"> 256 </strong>，这需要使用 GPU</li><li id="f314" class="ls lt it kq b kr mb kv mc kz md ld me lh mf ll mn ly lz ma bi translated"><strong class="kq iu"> batch_size </strong> —将通过网络传播的样本数量。选择的号码是<strong class="kq iu"> 128 </strong></li><li id="9d2c" class="ls lt it kq b kr mb kv mc kz md ld me lh mf ll mn ly lz ma bi translated"><strong class="kq iu"> gamma </strong> —聚焦损失中的聚焦参数，平滑调整简单示例向下加权的速率。焦点损失旨在通过降低内联体(简单的例子)的权重来解决类别不平衡，这样即使它们的数量很大，它们对总损失的贡献也很小。它侧重于训练一组稀疏的硬例子。在我们的例子中，伽马的最佳值是<strong class="kq iu"> 2 </strong></li></ol><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="ml mm l"/></div></figure><p id="3e8d" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">得到了 F1 = <strong class="kq iu"> 0.49 </strong></p><h1 id="6b40" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">标签共现</h1><p id="e26f" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们需要记住，在我们的数据集中有多个标签，有时一个标签表示另一个标签的出现。为了检查这种百分比依赖性，我创建了共现矩阵。例如，现在我们知道:</p><pre class="mg mh mi mj gt mo mp mq mr aw ms bi"><span id="6f20" class="mt jr it mp b gy mu mv l mw mx">Action Comedy -&gt; Action, 0.9722222222222222<br/>Action Comedy -&gt; Comedy, 0.9629629629629629<br/>Action Thrillers -&gt; Action, 0.9492537313432836<br/>Action Thrillers -&gt; Thriller, 0.9253731343283582<br/>Adventure Comedy -&gt; Comedy, 0.9101123595505618</span></pre><p id="537c" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">下图显示了前 100 个最强的依赖关系。</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi my"><img src="../Images/908350ae5121d0a8ca678fa4039f963f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VgL7xNbkAggCANIhGow6uw.png"/></div></div><p class="nf ng gj gh gi nh ni bd b be z dk translated">标签共现的路由弦</p></figure><p id="4faf" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">有了获得的知识，我们现在可以尝试修改我们的预测。经过几次尝试，我决定将结果标签的值改为 1，前提是它与指示标签的同现度大于或等于 0.9。</p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="ml mm l"/></div></figure><p id="24a3" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">更新后的 F1 成绩是<strong class="kq iu"> 0.5 </strong>，小进步。</p><h1 id="1927" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">结果</h1><p id="6c1e" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">示例结果如下所示。</p><pre class="mg mh mi mj gt mo mp mq mr aw ms bi"><span id="8b5f" class="mt jr it mp b gy mu mv l mw mx">First Platoon centers around Rock Brannigan ([[Scott Gibson  and his ragtag squad of ex-military zombie hunters trying to make a living in the desert Southwest two years after the zombie apocalypse. Along the way they encounter the grizzled Pa Jericho , and the eccentric Rex Necro .<br/><strong class="mp iu">Action, Comedy, Horror, Parody, Science Fiction</strong></span><span id="db00" class="mt jr it mp b gy nj mv l mw mx">The life of the S&amp;M-theme artist and author Seiu Ito is depicted in the film. His artistic life and Sadian philosophy, inspired by his torturing of his two wives and Tae, his favorite prostitute, are portrayed as shown in his journalistic writings. Tae is eventually driven insane due to Ito's attentions.<br/><strong class="mp iu">Drama, Japanese Movies, World cinema</strong></span></pre><h1 id="05cf" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">结论</h1><p id="197a" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">使用 BERT 嵌入技术使 F1 得分提高了 7%(总体提高了 50%)。</p><p id="2c0d" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">在未来的工作中，我认为减少标签的数量，只保留主要的标签是个好主意。由于“动作喜剧”在 100%的情况下是“动作”，在 100%的情况下是“喜剧”，也许我们真的不需要这个类别。</p><p id="1757" class="pw-post-body-paragraph ko kp it kq b kr ln kt ku kv lo kx ky kz lp lb lc ld lq lf lg lh lr lj lk ll im bi translated">感谢您的阅读。</p></div></div>    
</body>
</html>