<html>
<head>
<title>Keras 101: A simple (and interpretable) Neural Network model for House Pricing regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Keras 101:一个简单的(和可解释的)用于房价回归的神经网络模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/keras-101-a-simple-and-interpretable-neural-network-model-for-house-pricing-regression-31b1a77f05ae?source=collection_archive---------11-----------------------#2020-02-28">https://towardsdatascience.com/keras-101-a-simple-and-interpretable-neural-network-model-for-house-pricing-regression-31b1a77f05ae?source=collection_archive---------11-----------------------#2020-02-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="b0ea" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">TL；DR:使用带有神经网络的波士顿数据集预测房价，并采用 SHAP 值来解释我们的模型。完整的笔记本可以在这里找到<a class="ae ko" href="https://github.com/rodrigobressan/keras_boston_housing_price" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="b27b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在本帖中，我们将介绍一些数据探索的基础知识，并使用 Keras 构建一个模型，以帮助我们预测波士顿(MA)地区某栋房屋的销售价格。作为这个模型在现实世界中的一个应用，你可以想象成为一个真正的国家代理人，寻找一个工具来帮助你履行日常职责，至少对我来说，与直觉相比，这听起来相当不错。</p><p id="4f32" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这个练习中，我们将使用<a class="ae ko" href="https://plot.ly/python/" rel="noopener ugc nofollow" target="_blank"> Plotly </a>库，而不是老式的 matplotlib，因为它有更多的交互图，这无疑有助于理解数据。我们还将使用<a class="ae ko" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> Scikit-Learn </a>和<a class="ae ko" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>来构建模型，使用<a class="ae ko" href="https://pandas.pydata.org/" rel="noopener ugc nofollow" target="_blank"> Pandas </a>库来操作我们的数据，使用<a class="ae ko" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank"> SHAP 库</a>来为我们训练好的模型生成解释。</p><h1 id="5e86" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">导入数据集</h1><p id="629d" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">在本例中，我们将使用包含波士顿数据集的 sklearn.datasets 模块。您也可以使用 keras.datasets 模块，但是这个模块不包含要素的标签，所以我们决定使用 scikit 的模块。让我们也把它转换成熊猫的数据帧，并打印它的头部。</p><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="cf46" class="mb kq it lx b gy mc md l me mf">from sklearn.datasets import load_boston<br/>import pandas as pd</span><span id="f20f" class="mb kq it lx b gy mg md l me mf">boston_dataset = load_boston()</span><span id="5032" class="mb kq it lx b gy mg md l me mf">df = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)<br/>df['MEDV'] = boston_dataset.target</span><span id="8047" class="mb kq it lx b gy mg md l me mf">df.head(n=10)</span></pre><h1 id="788e" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">探索性数据分析</h1><p id="2cb6" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">熟悉数据集是帮助您理解数据并从结果中得出更好的结论和解释的基本步骤。</p><p id="3ec2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">首先，让我们绘制一些箱线图，这将有助于我们更好地可视化数据分布中的异常和/或异常值。如果你对什么是盒图以及它如何帮助我们更好地可视化我们的数据分布感到困惑，这里有一个来自 Ross (1977)的简短描述:</p><blockquote class="mh mi mj"><p id="7b45" class="jq jr mk js b jt ju jv jw jx jy jz ka ml kc kd ke mm kg kh ki mn kk kl km kn im bi translated"><em class="it">在描述统计学中，箱线图是一种通过四分位数以图形方式描绘数字数据组的方法。箱形图也可能有从箱形图(须状图)垂直延伸的线，表示上下四分位数之外的可变性，因此称为箱形图和箱形须状图。异常值可以绘制为单个点。</em></p></blockquote><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="4e35" class="mb kq it lx b gy mc md l me mf">from plotly.subplots import make_subplots<br/>import plotly.graph_objects as go<br/>import math</span><span id="5183" class="mb kq it lx b gy mg md l me mf">total_items = len(df.columns)<br/>items_per_row = 3<br/>total_rows = math.ceil(total_items / items_per_row)</span><span id="328e" class="mb kq it lx b gy mg md l me mf">fig = make_subplots(rows=total_rows, cols=items_per_row)</span><span id="f467" class="mb kq it lx b gy mg md l me mf">cur_row = 1<br/>cur_col = 1</span><span id="148a" class="mb kq it lx b gy mg md l me mf">for index, column in enumerate(df.columns):<br/>    fig.add_trace(go.Box(y=df[column], name=column), row=cur_row, col=cur_col)<br/>    <br/>    if cur_col % items_per_row == 0:<br/>        cur_col = 1<br/>        cur_row = cur_row + 1<br/>    else:<br/>        cur_col = cur_col + 1<br/>    </span><span id="89d2" class="mb kq it lx b gy mg md l me mf">fig.update_layout(height=1000, width=550,  showlegend=False)<br/>fig.show()<!-- --> </span></pre><p id="aef5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这将输出以下箱线图:</p><figure class="ls lt lu lv gt mp gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/2142a7715522d78a58f0ade45cd9107a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*iRszP6ShhLTVxyeP1kka7w.png"/></div></figure><p id="a729" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这些结果证实了我们最初的假设，即在一些列中有异常值。让我们为每个特征和目标变量绘制一些散点图，以及它们的截距线:</p><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="1581" class="mb kq it lx b gy mc md l me mf">from plotly.subplots import make_subplots<br/>import plotly.graph_objects as go<br/>import math<br/>import numpy as np</span><span id="a31f" class="mb kq it lx b gy mg md l me mf">total_items = len(df.columns)<br/>items_per_row = 3<br/>total_rows = math.ceil(total_items / items_per_row)</span><span id="bfe2" class="mb kq it lx b gy mg md l me mf">fig = make_subplots(rows=total_rows, cols=items_per_row, subplot_titles=df.columns)</span><span id="b530" class="mb kq it lx b gy mg md l me mf">cur_row = 1<br/>cur_col = 1</span><span id="38ff" class="mb kq it lx b gy mg md l me mf">for index, column in enumerate(df.columns):<br/>    fig.add_trace(go.Scattergl(x=df[column], <br/>                            y=df['MEDV'], <br/>                            mode="markers", <br/>                            marker=dict(size=3)), <br/>                  row=cur_row, <br/>                  col=cur_col)<br/>    <br/>    intercept = np.poly1d(np.polyfit(df[column], df['MEDV'], 1))(np.unique(df[column]))<br/>    <br/>    fig.add_trace(go.Scatter(x=np.unique(df[column]), <br/>                             y=intercept, <br/>                             line=dict(color='red', width=1)), <br/>                  row=cur_row, <br/>                  col=cur_col)<br/>    <br/>    if cur_col % items_per_row == 0:<br/>        cur_col = 1<br/>        cur_row = cur_row + 1<br/>    else:<br/>        cur_col = cur_col + 1<br/>    </span><span id="1195" class="mb kq it lx b gy mg md l me mf">fig.update_layout(height=1000, width=550, showlegend=False)<br/>fig.show()</span></pre><figure class="ls lt lu lv gt mp gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/fe85b73f59446b04d20bb814cb1bc557.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/0*0qbBir50coHukTC6.png"/></div></figure><p id="965a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从这个初步的数据探索中，我们可以得出两个主要结论:</p><ul class=""><li id="ee8a" class="ms mt it js b jt ju jx jy kb mu kf mv kj mw kn mx my mz na bi translated">RM(每所住宅的平均房间数)和 LSTAT(人口的较低地位百分比)与目标变量之间有很强的线性相关性，RM 为正相关，LSTAT 为负相关。</li><li id="f623" class="ms mt it js b jt nb jx nc kb nd kf ne kj nf kn mx my mz na bi translated">有一些包含异常值的记录，我们可以对其进行预处理，以便为我们的模型输入更多的规范化数据。</li></ul><h1 id="f685" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">数据预处理</h1><p id="9368" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">在我们进行任何数据预处理之前，将数据分成训练集和测试集是很重要的。我们不应该对我们的数据进行任何类型的预处理，而不应该忘记我们不应该将信息从我们的测试集泄露到其他的测试集中。对于这一步，我们可以使用 scikit-learn 中的<em class="mk"> train_test_split </em>方法。在这种情况下，我们将使用 70%的数据用于训练，30%的数据用于测试。我们还设置了一个 random_state 种子，以保证方法的可重复性。</p><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="d830" class="mb kq it lx b gy mc md l me mf">from sklearn.model_selection import train_test_split</span><span id="710e" class="mb kq it lx b gy mg md l me mf">X = df.loc[:, df.columns != 'MEDV']<br/>y = df.loc[:, df.columns == 'MEDV']</span><span id="32e1" class="mb kq it lx b gy mg md l me mf">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)</span></pre><p id="a034" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了向我们的神经网络提供标准化的输入，我们需要执行数据集的规范化。这可以被看作是减少可能由现有特征引起的规模差异的一个步骤。我们通过从数据中减去平均值并除以标准偏差来执行标准化。<strong class="js iu">再强调一次，为了避免测试集的任何信息泄露，这种标准化只能通过使用训练集的平均值和标准偏差来执行。</strong></p><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="5788" class="mb kq it lx b gy mc md l me mf">mean = X_train.mean(axis=0)<br/>std = X_train.std(axis=0)</span><span id="0aa3" class="mb kq it lx b gy mg md l me mf">X_train = (X_train - mean) / std<br/>X_test = (X_test - mean) / std</span></pre><h1 id="6e45" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">建立我们的模型</h1><p id="4176" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">由于该数据集中呈现的数据量很小，我们必须小心不要创建过于复杂的模型，否则会导致数据过度拟合。为此，我们将采用基于两个密集层的架构，第一个具有 128 个神经元，第二个具有 64 个神经元，两者都使用 ReLU(整流线性单元)激活功能。具有线性激活的密集层将被用作输出层。</p><p id="3073" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了让我们知道我们的模型是否正确学习，我们将使用均方误差损失函数，并且为了报告它的性能，我们将采用平均误差度量。</p><p id="5926" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过使用来自 Keras 的汇总方法，我们可以看到我们总共有 10，113 个参数，这对我们来说是可以接受的。</p><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="c2ba" class="mb kq it lx b gy mc md l me mf">from keras.models import Sequential<br/>from keras.layers import Dense</span><span id="d632" class="mb kq it lx b gy mg md l me mf">model = Sequential()</span><span id="3ad7" class="mb kq it lx b gy mg md l me mf">model.add(Dense(128, input_shape=(13, ), activation='relu', name='dense_1'))<br/>model.add(Dense(64, activation='relu', name='dense_2'))<br/>model.add(Dense(1, activation='linear', name='dense_output'))</span><span id="4dd8" class="mb kq it lx b gy mg md l me mf">model.compile(optimizer='adam', loss='mse', metrics=['mae'])<br/>model.summary()</span></pre><h1 id="0cd9" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">训练我们的模型</h1><p id="6c80" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">这一步非常简单:用我们的特征和它们的标签来拟合我们的模型，总共 100 个历元，保留 5%的样本(18 个记录)作为验证集。</p><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="a28c" class="mb kq it lx b gy mc md l me mf">history = model.fit(X_train, y_train, epochs=100, validation_split=0.05)</span></pre><p id="b548" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过绘制损失和平均误差，我们可以看到我们的模型能够学习数据中的模式，而不会发生过度拟合(如验证集曲线所示):</p><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="701e" class="mb kq it lx b gy mc md l me mf">fig = go.Figure()<br/>fig.add_trace(go.Scattergl(y=history.history['loss'],<br/>                    name='Train'))</span><span id="7c5f" class="mb kq it lx b gy mg md l me mf">fig.add_trace(go.Scattergl(y=history.history['val_loss'],<br/>                    name='Valid'))<br/></span><span id="c857" class="mb kq it lx b gy mg md l me mf">fig.update_layout(height=500, width=700,<br/>                  xaxis_title='Epoch',<br/>                  yaxis_title='Loss')</span><span id="4e60" class="mb kq it lx b gy mg md l me mf">fig.show()</span></pre><figure class="ls lt lu lv gt mp gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/dd7bb5d3bb0ff805f1151638321a5185.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*V8-A-wUMuKUya-ect28PDg.png"/></div><p class="nh ni gj gh gi nj nk bd b be z dk translated">我们训练模型的训练和验证损失。我们可以看到，我们的模型显然能够学习我们的数据模式，而不存在数据过度拟合。</p></figure><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="4713" class="mb kq it lx b gy mc md l me mf">fig = go.Figure()<br/>fig.add_trace(go.Scattergl(y=history.history['mean_absolute_error'],<br/>                    name='Train'))</span><span id="2fc7" class="mb kq it lx b gy mg md l me mf">fig.add_trace(go.Scattergl(y=history.history['val_mean_absolute_error'],<br/>                    name='Valid'))<br/></span><span id="cee2" class="mb kq it lx b gy mg md l me mf">fig.update_layout(height=500, width=700,<br/>                  xaxis_title='Epoch',<br/>                  yaxis_title='Mean Absolute Error')</span><span id="f1af" class="mb kq it lx b gy mg md l me mf">fig.show()<!-- --> </span></pre><figure class="ls lt lu lv gt mp gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/5c5d92d1df4261af6da5f56bbb2edfe3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*_dTYQPqabDeTro_di3cymQ.png"/></div><p class="nh ni gj gh gi nj nk bd b be z dk translated">训练集和验证集的训练和验证平均绝对误差(MAE)。</p></figure><h1 id="232f" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">评估我们的模型</h1><p id="bd9d" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">为了正确评估我们的模型是否能够在现实世界中工作，我们必须使用我们的测试集来评估它。下面我们通过使用 evaluate 方法以及测试集中的特性和目标来实现。</p><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="30d6" class="mb kq it lx b gy mc md l me mf">mse_nn, mae_nn = model.evaluate(X_test, y_test)</span><span id="eec8" class="mb kq it lx b gy mg md l me mf">print('Mean squared error on test data: ', mse_nn)<br/>print('Mean absolute error on test data: ', mae_nn)</span></pre><p id="6042" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这为我们提供了以下输出:</p><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="ed67" class="mb kq it lx b gy mc md l me mf">152/152 [==============================] - 0s 60us/step<br/><strong class="lx iu">Mean squared error on test data:  17.429732523466413<br/>Mean absolute error on test data:  2.6727954964888725</strong></span></pre><h1 id="8f6b" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">与传统方法的比较</h1><p id="5d6c" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">首先让我们尝试一个简单的算法，线性回归:</p><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="3072" class="mb kq it lx b gy mc md l me mf">lr_model = LinearRegression()<br/>lr_model.fit(X_train, y_train)</span><span id="80b3" class="mb kq it lx b gy mg md l me mf">y_pred_lr = lr_model.predict(X_test)<br/>mse_lr = mean_squared_error(y_test, y_pred_lr)<br/>mae_lr = mean_absolute_error(y_test, y_pred_lr)</span><span id="56cb" class="mb kq it lx b gy mg md l me mf">print('Mean squared error on test data: ', mse_lr)<br/>print('Mean absolute error on test data: ', mae_lr)</span><span id="4e49" class="mb kq it lx b gy mg md l me mf"><strong class="lx iu">Mean squared error on test data: 28.40585481050824<br/>Mean absolute error on test data: 3.6913626771162575</strong></span></pre><p id="c8a6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在使用决策树回归器:</p><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="57a5" class="mb kq it lx b gy mc md l me mf">tree = DecisionTreeRegressor()<br/>tree.fit(X_train, y_train)</span><span id="de07" class="mb kq it lx b gy mg md l me mf">y_pred_tree = tree.predict(X_test)</span><span id="722e" class="mb kq it lx b gy mg md l me mf">mse_dt = mean_squared_error(y_test, y_pred_tree)<br/>mae_dt = mean_absolute_error(y_test, y_pred_tree)</span><span id="7bcd" class="mb kq it lx b gy mg md l me mf">print('Mean squared error on test data: ', mse_dt)<br/>print('Mean absolute error on test data: ', mae_dt)</span><span id="65d8" class="mb kq it lx b gy mg md l me mf"><strong class="lx iu">Mean squared error on test data:  17.830657894736845<br/>Mean absolute error on test data:  2.755263157894737</strong></span></pre><h1 id="acdf" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">打开黑匣子(也就是解释我们的模型)</h1><p id="3883" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">有时候，对大多数人来说，一个好的结果就足够了，但是有些情况下，我们需要解释我们的模型用来执行预测的主要组件是什么。对于这个任务，我们可以依靠 SHAP 库，它允许我们很容易地创建我们的特性及其对模型输出的影响的概要。我不会深入 SHAP 的细节，但如果你有兴趣了解更多关于它是如何工作的，你可以查看他们的 github 页面或者甚至看一下他们的 T2 论文。</p><pre class="ls lt lu lv gt lw lx ly lz aw ma bi"><span id="bf8b" class="mb kq it lx b gy mc md l me mf">import shap<br/>shap.initjs()</span><span id="6078" class="mb kq it lx b gy mg md l me mf">explainer = shap.DeepExplainer(model, X_train[:100].values)<br/>shap_values = explainer.shap_values(X_test[:100].values)</span><span id="ba9f" class="mb kq it lx b gy mg md l me mf">shap.summary_plot(shap_values, X_test, plot_type='bar')</span></pre><figure class="ls lt lu lv gt mp gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/df9efc8afa06b5bc651fb37d1b2aaa6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/0*8YvgkgSbebmoAurW.png"/></div></figure><p id="be64" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从这个简单的图中，我们可以看到对模型输出有影响的主要特征是:</p><ul class=""><li id="bfd9" class="ms mt it js b jt ju jx jy kb mu kf mv kj mw kn mx my mz na bi translated">LSTAT: %人口的较低地位</li><li id="0c2e" class="ms mt it js b jt nb jx nc kb nd kf ne kj nf kn mx my mz na bi translated">RM:每个住宅的平均房间数</li><li id="ccfc" class="ms mt it js b jt nb jx nc kb nd kf ne kj nf kn mx my mz na bi translated">RAD:放射状公路可达性指数</li><li id="f91b" class="ms mt it js b jt nb jx nc kb nd kf ne kj nf kn mx my mz na bi translated">DIS:到五个波士顿就业中心的加权距离</li><li id="a9ba" class="ms mt it js b jt nb jx nc kb nd kf ne kj nf kn mx my mz na bi translated">氮氧化物:氮氧化物浓度(百万分之一)——这可能与该地区的绿化程度有关</li><li id="e3a5" class="ms mt it js b jt nb jx nc kb nd kf ne kj nf kn mx my mz na bi translated">CRIM:城镇人均犯罪率</li></ul><p id="be0c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这清楚地证实了我们最初的 EDA 分析，其中我们指出 LSTAT 和 RM 特征与模型结果高度相关。</p><h1 id="b856" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">结论</h1><p id="2aef" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">在这篇文章中，我们已经表明，通过使用神经网络，我们可以轻松地超越传统的机器学习方法。我们还表明，即使在使用更复杂的模型时，与其他技术相比，我们仍然可以通过使用 SHAP 值来解释我们的模型的结果。</p><p id="d540" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">此外，我们需要记住，所探索的数据集可能已经过时，为了更好地反映当前的情况，可以执行一些功能工程(如校正通货膨胀的价格)。</p><h2 id="c471" class="mb kq it bd kr nm nn dn kv no np dp kz kb nq nr ld kf ns nt lh kj nu nv ll nw bi translated">参考</h2><p id="d36c" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">波士顿数据集:<a class="ae ko" href="https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html" rel="noopener ugc nofollow" target="_blank">https://www . cs . Toronto . edu/~ delve/data/Boston/Boston detail . html</a></p><p id="3d70" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">剧情:<a class="ae ko" href="https://plot.ly/python/" rel="noopener ugc nofollow" target="_blank">https://plot.ly/python/</a></p><p id="d586" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">scikit learn:<a class="ae ko" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank">https://scikit-learn.org/stable/</a></p><p id="7a5a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">https://keras.io/<a class="ae ko" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"/></p><p id="776c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">熊猫:【https://pandas.pydata.org/】T4</p><p id="5db8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">https://github.com/slundberg/shap SHAP 项目页面:<a class="ae ko" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank"/></p><p id="da63" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">SHAP 论文:<a class="ae ko" href="https://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf" rel="noopener ugc nofollow" target="_blank">https://papers . nips . cc/Paper/7062-a-unified-approach-to-interpretation-model-predictions . pdf</a></p><p id="d9e4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">工程师和科学家概率统计导论。<a class="ae ko" href="https://www.amazon.com.br/dp/B007ZBZN9U/ref=dp-kindle-redirect?_encoding=UTF8&amp;btkr=1" rel="noopener ugc nofollow" target="_blank">https://www . Amazon . com . br/DP/b 007 zbzn 9 u/ref = DP-kindle-redirect？_encoding=UTF8 &amp; btkr=1 </a></p></div></div>    
</body>
</html>