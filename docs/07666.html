<html>
<head>
<title>5 Scikit-Learn Must-Know Hidden Gems</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">5 sci kit-学习必须知道的隐藏宝石</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/5-scikit-learn-must-know-hidden-gems-8249e5214a73?source=collection_archive---------63-----------------------#2020-06-08">https://towardsdatascience.com/5-scikit-learn-must-know-hidden-gems-8249e5214a73?source=collection_archive---------63-----------------------#2020-06-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/fbb0c30d637fa5910d273d494244b237.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VbB8SpL6vpoL25phfpXvdA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://pixabay.com/illustrations/precious-diamond-jewelry-expensive-1199183/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><div class=""/><div class=""><h2 id="b66e" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">数据生成器、管道、验证曲线等</h2></div><p id="5795" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">尽管 Scikit-learn 是机器学习中的一个主要部分，但许多人并不知道或没有使用该库中一些最有用的隐藏宝石。这里是 Scikit-learn 最有用的五个隐藏的宝石。</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="de00" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">数据集生成器</h1><p id="55b7" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">Scikit-learn 有大量的数据集生成器，可用于创建具有不同复杂性和形状的人工数据集。</p><p id="63af" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，<code class="fe my mz na nb b">make_blobs</code>函数创建“斑点”或数据簇，具有任意数量的样本、中心/簇和特征/维度。</p><figure class="nc nd ne nf gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="acf6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe my mz na nb b">X</code>和<code class="fe my mz na nb b">y</code>的值为:</p><figure class="nc nd ne nf gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="0c31" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当<code class="fe my mz na nb b">X</code>根据标签<code class="fe my mz na nb b">y</code>被图形化和着色时，数据的形状可以被可视化:</p><figure class="nc nd ne nf gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ni"><img src="../Images/8c8e9a91fbca77e659d22910c6fb725c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_UwJFJ2Tbb8knjTjzqg5HQ.png"/></div></div></figure><p id="8d01" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Scikit-learn 具有许多其他数据集创建功能:</p><figure class="nc nd ne nf gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nj"><img src="../Images/6e97630f543a34bea33284a9fc41dec2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4lo2d0IeQ9o6o_B7aR5x8Q.png"/></div></div></figure><ul class=""><li id="04ce" class="nk nl jj la b lb lc le lf lh nm ll nn lp no lt np nq nr ns bi translated"><code class="fe my mz na nb b">make_moons(n_samples=100, noise=0.1)</code></li><li id="4466" class="nk nl jj la b lb nt le nu lh nv ll nw lp nx lt np nq nr ns bi translated"><code class="fe my mz na nb b">make_circles(n_samples=100, noise=0.05)</code></li><li id="0cde" class="nk nl jj la b lb nt le nu lh nv ll nw lp nx lt np nq nr ns bi translated"><code class="fe my mz na nb b">make_regression(n_samples=100, n_features=1, noise=15)</code></li><li id="28de" class="nk nl jj la b lb nt le nu lh nv ll nw lp nx lt np nq nr ns bi translated"><code class="fe my mz na nb b">make_classification(n_samples=100)</code></li></ul><h1 id="7e25" class="mb mc jj bd md me ny mg mh mi nz mk ml kp oa kq mn ks ob kt mp kv oc kw mr ms bi translated">管道</h1><p id="8fce" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">管道允许将各种方法合并到一个单一的模型中。在自然语言处理(NLP)应用中尤其如此，这些应用需要需要标准化或规范化的矢量器或数据。可以通过将几个模型组合在一起来创建管道，在管道中，数据按顺序流经聚合模型。它具有标准的拟合和预测能力，使训练过程更有组织性。</p><figure class="nc nd ne nf gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="8cf1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">各种对象可以放入一个管道中:</p><ul class=""><li id="1624" class="nk nl jj la b lb lc le lf lh nm ll nn lp no lt np nq nr ns bi translated"><em class="od">估算者</em>。你有丢失的数据吗？试试简单的估算器或 KNN 估算器。</li><li id="0e25" class="nk nl jj la b lb nt le nu lh nv ll nw lp nx lt np nq nr ns bi translated"><em class="od">编码器。</em>如果您的数据是非二进制分类数据，您可能需要使用标签编码器或一次性编码器。</li><li id="a445" class="nk nl jj la b lb nt le nu lh nv ll nw lp nx lt np nq nr ns bi translated"><em class="od"> NLP 矢量器。</em>如果您正在处理 NLP 数据，请使用计数矢量器、TD-IDF 矢量器或哈希矢量器。</li><li id="1429" class="nk nl jj la b lb nt le nu lh nv ll nw lp nx lt np nq nr ns bi translated"><em class="od">数值转换</em>。尝试标准化器、规格化器和最小-最大缩放器。</li></ul><h1 id="c8bb" class="mb mc jj bd md me ny mg mh mi nz mk ml kp oa kq mn ks ob kt mp kv oc kw mr ms bi translated">网格搜索</h1><p id="1be7" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">机器学习中的一个常见任务是在模型中找到正确的参数集。通常，人们可以根据他们对任务和模型的了解进行猜测，或者通过编程找到最佳的集合。<code class="fe my mz na nb b">sklearn</code>有一个内置函数——<code class="fe my mz na nb b">GridSearchCV</code>——自动为您找到最佳参数集，以优化模型性能。</p><p id="1eec" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe my mz na nb b">GridSearchCV</code>对象接受两个参数:首先，要训练的模型对象(在这种情况下是支持向量机分类器)，其次，描述模型参数的字典。字典中的每个键都是模型中的一个参数，其中每个值都是一个相应的值列表或元组，参数可以在其中取值。</p><figure class="nc nd ne nf gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="1e40" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在网格搜索对象被拟合之后，<code class="fe my mz na nb b">best_params_</code>属性可用于输出每个模型参数的最佳性能参数值。其他模型参数包括决策树中的树深度和随机森林集合中的投票者数量。</p><h1 id="9062" class="mb mc jj bd md me ny mg mh mi nz mk ml kp oa kq mn ks ob kt mp kv oc kw mr ms bi translated">验证曲线</h1><p id="a1c8" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">为了可视化参数对模型性能的影响，使用<code class="fe my mz na nb b">sklearn</code>的<code class="fe my mz na nb b">validation_curve</code>。它接受几个参数:模型、要调整的参数、参数值的范围以及折叠次数。它类似于对一个变量的网格搜索，可以帮助更好地可视化参数变化的结果。</p><figure class="nc nd ne nf gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="b67e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe my mz na nb b">validation_curve</code>对象的输出是一个元组——一个是训练分数，另一个是测试分数。每个中的行数代表每个参数值的数组值，而数组中的每个元素代表每个<em class="od"> k </em>折叠的值。</p><p id="2f13" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当绘制结果时，参数和精度之间的关系是清楚的。</p><figure class="nc nd ne nf gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure><figure class="nc nd ne nf gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oe"><img src="../Images/5fb47d7859fa9be3b9310f360bcfec72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bOMzQbXl3Du4fNwyWUmhOQ.png"/></div></div></figure><p id="6b35" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这使我们可以直观地看到树的深度对精确度的影响。比如说。请注意，树深度为 5 或树深度为 6 时表现相当好。进一步指定树的深度会导致过度拟合，但是需要根据测试精度来评估这一点。</p><h1 id="234d" class="mb mc jj bd md me ny mg mh mi nz mk ml kp oa kq mn ks ob kt mp kv oc kw mr ms bi translated">k 倍交叉验证</h1><p id="a958" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">交叉验证是一种比标准的<code class="fe my mz na nb b">train_test_split</code>方法给出更准确结果的方法(实际上需要更少的代码！).在传统的训练-测试-拆分中，数据被随机分为训练集和测试集(通常比例为 7:3–8:2)，模型在训练集上接受训练，在测试集上进行评估，以真正衡量模型的测量能力，而不仅仅是记忆能力。但是，由于每次分割都是随机的，将数据分割十次将产生十种不同的精度。</p><p id="51bd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了解决这个问题，使用<em class="od"> k </em>个折叠的交叉验证将数据分成<em class="od"> k </em>个类别，在<em class="od"> k </em>个折叠上训练模型，并在剩余的 1 个折叠上进行测试。重复这一过程后，每个测试折叠最终覆盖整个数据集，人们会对准确性有一个更完整和诚实的看法。更好的是，不需要跟踪 x-train、x-test、y-train 和 y-test 变量。交叉验证的唯一缺点是需要更多的时间——但是更好的结果总是有更高的成本。</p><figure class="nc nd ne nf gt iv"><div class="bz fp l di"><div class="ng nh l"/></div></figure></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="679d" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">感谢阅读！</h1><p id="93db" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">希望这些 sci-kit learn 隐藏的宝石能够让你的机器学习编码更好。</p></div></div>    
</body>
</html>