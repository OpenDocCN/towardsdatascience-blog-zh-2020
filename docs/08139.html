<html>
<head>
<title>Optimize Knowledge Graph Embeddings with DGL-KE</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用DGL-柯优化知识图嵌入</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/optimize-knowledge-graph-embeddings-with-dgl-ke-1fff4ab275f2?source=collection_archive---------48-----------------------#2020-06-15">https://towardsdatascience.com/optimize-knowledge-graph-embeddings-with-dgl-ke-1fff4ab275f2?source=collection_archive---------48-----------------------#2020-06-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8c21" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解软件优化，以加速知识图嵌入的训练，并在几分钟内训练你的第一个模型与DGL柯</h2></div><p id="b526" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">作者:Cyrus Vahid，首席解决方案工程师，郑达，乔治·卡里皮斯和巴拉吉·卡马科蒂:AWS AI</p><h1 id="6a63" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">介绍</h1><p id="48b6" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">在我们的<a class="ae mb" href="https://medium.com/@bkamakot/introduction-to-knowledge-graph-embedding-with-dgl-ke-77ace6fb60ef" rel="noopener">上一篇</a>文章中，我们介绍了知识图嵌入(KGEs)的概念，以及在DGL-柯中用来生成它们的两个流行模型。这篇博客概述了DGL-克如何加速KGE的训练。我们还分享了一个读者可以在本地机器上运行的例子。</p><h1 id="9dcf" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">什么是DGL柯</h1><p id="0b1a" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">综上所述，<a class="ae mb" href="https://github.com/awslabs/dgl-ke" rel="noopener ugc nofollow" target="_blank">DGL-克</a>是一个高性能，易于使用，可扩展的工具包，用于从大型图中生成知识图嵌入。它建立在<a class="ae mb" href="https://www.dgl.ai/" rel="noopener ugc nofollow" target="_blank">深度图形库</a> (DGL)，一个实现图形神经网络(GNN)的开源库之上。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/0a2fb8bc0d33088f3b6b92098717a003.png" data-original-src="https://miro.medium.com/v2/resize:fit:1166/format:webp/1*3-UooJr-hfWWQLwFwGO6wQ.png"/></div></figure><p id="a5f6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如上图所示，<a class="ae mb" href="https://github.com/awslabs/dgl-ke" rel="noopener ugc nofollow" target="_blank">DGL-克</a>实现了一些最流行的知识嵌入模型，如TransE、TransR、RotateE、DistMulti、RESCAL和ComplEx。</p><h1 id="d95e" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">挑战</h1><p id="8c00" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">尽管有多种模型可用于生成嵌入，但是训练这些嵌入对于大型图来说要么是耗时的，要么是不可行的，原因有两个:</p><ul class=""><li id="5e35" class="mk ml it kk b kl km ko kp kr mm kv mn kz mo ld mp mq mr ms bi translated"><strong class="kk iu">大小</strong>:很多知识图有几百万个节点，几十亿条边，几万个关系。这种规模的图的训练嵌入需要的计算资源远远超过任何单个机器的能力。因此，计算必须分布在不同的设备上。这尤其困难，因为这些设备需要平衡工作负载并减少数据移动开销。</li><li id="2f77" class="mk ml it kk b kl mt ko mu kr mv kv mw kz mx ld mp mq mr ms bi translated"><strong class="kk iu">稀疏度</strong>:知识图通常有很多缺失的边，一些关系很少被观察到。这使得很难训练涉及少数关系的实体的嵌入和不经常观察的关系的嵌入。</li></ul><p id="f0cb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">本博客的其余部分将探讨DGL-柯为应对这些挑战而实施的这些优化。但是在我们探索这些优化之前，让我们回顾一下训练KGEs所需的硬件基础设施。</p><h1 id="0635" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">硬件要求</h1><p id="63d9" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">在大型图上训练KGEs需要大量的硬件资源，比如多核CPU机器、多GPU机器和机器集群。目前支持的三种主要配置是:</p><ul class=""><li id="524b" class="mk ml it kk b kl km ko kp kr mm kv mn kz mo ld mp mq mr ms bi translated">单个共享内存多核机器(<strong class="kk iu"> <em class="my">多核</em> </strong>)，其中同一机器上的几个核心用于训练。</li><li id="390b" class="mk ml it kk b kl mt ko mu kr mv kv mw kz mx ld mp mq mr ms bi translated">具有多个GPU(<strong class="kk iu"><em class="my">多GPU </em> </strong>)的单个共享内存多核机器，其中使用同一机器上的多个GPU。</li><li id="9f79" class="mk ml it kk b kl mt ko mu kr mv kv mw kz mx ld mp mq mr ms bi translated">一个多核机器集群(<strong class="kk iu"> <em class="my">分布式</em> </strong>)，其中多个共享内存多核机器CPU机器用于训练一个嵌入。</li></ul><p id="318f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae mb" href="https://github.com/awslabs/dgl-ke" rel="noopener ugc nofollow" target="_blank">DGL-科</a>为所有这些硬件配置提供统一的软件优化，以高效地培训KGE。</p><h1 id="7f63" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">KGE培训概述</h1><p id="4046" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">对于所有的硬件配置，训练过程从分割KG的预处理步骤开始，然后是小批量训练。您可以使用此<a class="ae mb" href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/" rel="noopener ugc nofollow" target="_blank">资源</a>了解更多关于小批量训练的信息。分割步骤将KG中不相交的三元组集分配给设备。小批量训练执行以下步骤:</p><ul class=""><li id="69a9" class="mk ml it kk b kl km ko kp kr mm kv mn kz mo ld mp mq mr ms bi translated">从属于某个进程的本地分区中采样三元组以形成小批量，并为正三元组构造负样本。</li><li id="4956" class="mk ml it kk b kl mt ko mu kr mv kv mw kz mx ld mp mq mr ms bi translated">从全局实体和关系嵌入张量中获取小批量中涉及的实体和关系嵌入。</li><li id="28b7" class="mk ml it kk b kl mt ko mu kr mv kv mw kz mx ld mp mq mr ms bi translated">对上一步提取的嵌入执行前向和后向传播，以计算嵌入的梯度。</li><li id="784a" class="mk ml it kk b kl mt ko mu kr mv kv mw kz mx ld mp mq mr ms bi translated">应用梯度来更新小批量中涉及的嵌入。该步骤需要应用优化算法来调整梯度，并将梯度写回全局实体和关系嵌入张量。</li></ul><p id="d82c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae mb" href="https://github.com/awslabs/dgl-ke" rel="noopener ugc nofollow" target="_blank">DGL-克</a>对每一步都进行了优化，以加速训练。</p><h1 id="02bb" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">优化数据分布</h1><p id="bc31" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">在训练过程中，每个设备上的小批量计算需要访问与KG相关联的数据——实体和关系嵌入。将这些数据放在正确的位置，并协调其访问和更新对DGL-柯的性能至关重要。</p><ul class=""><li id="084a" class="mk ml it kk b kl km ko kp kr mm kv mn kz mo ld mp mq mr ms bi translated">在多核系统中，实体和关系嵌入驻留在系统的共享内存中。所有流程都可以有效地访问它来生成小批量，读取嵌入内容，并更新它们。</li><li id="dcb5" class="mk ml it kk b kl mt ko mu kr mv kv mw kz mx ld mp mq mr ms bi translated">在多GPU系统的情况下，由于实体嵌入太大而不适合GPU内存，因此它们与知识图一起保存在多核系统的共享内存中。然而，为了减少数据传输，关系嵌入被存储在GPU存储器上。GPU进程从多核系统的共享内存中读取和更新小批量中涉及的实体嵌入。</li><li id="893d" class="mk ml it kk b kl mt ko mu kr mv kv mw kz mx ld mp mq mr ms bi translated">分布式系统上的培训是不同的，因为我们需要分割数据并最大化每台机器的数据局部性。DGL-凯通过使用最小割图分割算法来实现这一点，以平衡负载和最小化通信的方式在机器之间分割知识图。此外，它使用每台机器的KV-store服务器来存储对应于分配给它的节点的实体的嵌入。然后，训练器进程使用<em class="my">推</em>和<em class="my">拉</em> API来获取嵌入数据并将更新(渐变)发回。</li></ul><p id="231f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下图以图形方式说明了这些数据分布的执行情况。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi mz"><img src="../Images/ce32f1ebc4330b619daf5dfb7df7cd80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YR3gtOVnDbGNfXq-gUZU9A.png"/></div></div></figure><h1 id="9d99" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">负采样</h1><p id="adcb" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated"><a class="ae mb" href="https://github.com/awslabs/dgl-ke" rel="noopener ugc nofollow" target="_blank">DGL-柯</a>为每个三联体构建了大量的负样本。总是使用系统CPU执行采样。如果负样本是独立构造的，将导致跨硬件访问大量实体。为了减少数据通信，我们对一批中的边的负边进行联合采样，使得一批中被访问的实体的数量不会由于负采样而急剧增加。<br/>由于度数较高的节点需要更多的数据来发现更多的模式，我们执行与节点度数成比例的负采样。这导致产生<em class="my">硬</em>阴性样本。这些硬阴性样品通常会提高KG包埋的质量。</p><h1 id="24e6" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">分割关系</h1><p id="cf91" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">KG中的实际关系相对于批量大小的比率越大(≈1000≈1000)，关系嵌入越稀疏。<a class="ae mb" href="https://github.com/awslabs/dgl-ke" rel="noopener ugc nofollow" target="_blank">DGL-克</a>采用稀疏关系嵌入读取和更新来提高通信效率。在多GPU训练中，<a class="ae mb" href="https://github.com/awslabs/dgl-ke" rel="noopener ugc nofollow" target="_blank">DGL-克</a>将关系进行分组，将一个组分配给一个GPU，以减少CPU和GPU之间的数据通信。</p><h1 id="7cab" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">渐变更新</h1><p id="c5f6" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated"><a class="ae mb" href="https://github.com/awslabs/dgl-ke" rel="noopener ugc nofollow" target="_blank">DGL-克</a>使用CPU对小批量进行采样，并加载实体嵌入，然后将其发送到GPU进行梯度计算。一旦GPU完成了嵌入梯度的计算，它会将它们发送到CPU以更新相应的嵌入。这意味着，如果一个进程串行运行，GPU必须等待CPU创建一个小批量，并向嵌入中写入梯度。为了防止GPU闲置，<a class="ae mb" href="https://github.com/awslabs/dgl-ke" rel="noopener ugc nofollow" target="_blank">DGL-柯</a>将CPU中的小批量创建和梯度更新与GPU中的小批量计算重叠。</p><p id="239e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于关系划分，<a class="ae mb" href="https://github.com/awslabs/dgl-ke" rel="noopener ugc nofollow" target="_blank">DGL-克</a>将关系嵌入保存在GPU中，并与CPU中的实体嵌入分开更新。更新实体嵌入被卸载到每个训练者的专用过程。这种优化在<a class="ae mb" href="https://www.microsoft.com/en-us/download/details.aspx?id=52312" rel="noopener ugc nofollow" target="_blank"> Freebase数据集</a>上为许多KGE模型提供了40%的加速。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi ne"><img src="../Images/3df93691c4258fe9bb5da92ee1d07a6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qxjYETbmAZB3NA6VUdv-wg.png"/></div></div></figure><h1 id="74e5" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">训练你的第一个知识图嵌入</h1><h1 id="93ec" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">安装DGL-科</h1><p id="2d3a" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">如果您的机器上安装了<a class="ae mb" href="https://docs.conda.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> conda </a>，使用以下命令创建一个环境:</p><pre class="md me mf mg gt nf ng nh ni aw nj bi"><span id="5d67" class="nk lf it ng b gy nl nm l nn no">:~$conda create -n dgl_pytorch python==3.8</span><span id="393e" class="nk lf it ng b gy np nm l nn no">:~$conda activate dgl_pytorch</span><span id="1776" class="nk lf it ng b gy np nm l nn no">(dgl_pytorch)…:~$</span></pre><p id="5318" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在机器上安装合适版本的<a class="ae mb" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>。如果您使用的是Mac，您可以使用</p><pre class="md me mf mg gt nf ng nh ni aw nj bi"><span id="ea98" class="nk lf it ng b gy nl nm l nn no">(dgl_pytorch)…:~$conda install PyTorch torchvision -c PyTorch</span></pre><p id="ebd8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我用的是Ubuntu机器，配有4个GPU和CUDA 10.0，所以我运行的是:</p><pre class="md me mf mg gt nf ng nh ni aw nj bi"><span id="6186" class="nk lf it ng b gy nl nm l nn no">(dgl_pytorch)…:~$conda install PyTorch torchvision cudatoolkit=10 -c PyTorch`</span></pre><p id="fb60" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">测试您的安装</p><pre class="md me mf mg gt nf ng nh ni aw nj bi"><span id="e69e" class="nk lf it ng b gy nl nm l nn no">(dgl_pytorch)…:~$python — version` #should output Python 3.8.0</span><span id="e988" class="nk lf it ng b gy np nm l nn no">(dgl_pytorch)…:~$python</span><span id="754f" class="nk lf it ng b gy np nm l nn no">&gt;&gt;&gt;import torch</span><span id="3f93" class="nk lf it ng b gy np nm l nn no">torch.__version__ #outputs the version number of PyTorch you have installed. Mine is ‘1.5.0’</span><span id="888c" class="nk lf it ng b gy np nm l nn no">&gt;&gt;&gt;quit()</span></pre><p id="7ea3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">安装<a class="ae mb" href="https://www.dgl.ai/pages/start.html" rel="noopener ugc nofollow" target="_blank"> DGL </a>和<a class="ae mb" href="https://github.com/awslabs/dgl-ke" rel="noopener ugc nofollow" target="_blank"> DGL克</a>:</p><pre class="md me mf mg gt nf ng nh ni aw nj bi"><span id="2e74" class="nk lf it ng b gy nl nm l nn no">(dgl_pytorch)…:~$pip install dgl dglke</span></pre><p id="93d1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">测试您的安装</p><pre class="md me mf mg gt nf ng nh ni aw nj bi"><span id="e6f9" class="nk lf it ng b gy nl nm l nn no">(dgl_pytorch)…:~$python</span><span id="6fcc" class="nk lf it ng b gy np nm l nn no">&gt;&gt;&gt; import dgl&gt;&gt;&gt; import dglke&gt;&gt;&gt; dgl.__version__, dglke.__version__ #It should output versions of dgl and dglke respectively. Mine is: (‘0.4.3post2’, ‘0.1.0’)</span><span id="d11b" class="nk lf it ng b gy np nm l nn no">&gt;&gt;&gt;quit()</span></pre><h1 id="0a60" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">让我们做一个快速测试</h1><pre class="md me mf mg gt nf ng nh ni aw nj bi"><span id="b5b0" class="nk lf it ng b gy nl nm l nn no"># create a new workspace</span><span id="f535" class="nk lf it ng b gy np nm l nn no">(dgl_pytorch)…:~$mkdir my_task &amp;&amp; cd my_task# Train transE model on FB15k dataset</span><span id="d0fc" class="nk lf it ng b gy np nm l nn no">(dgl_pytorch)…my_task:~$DGLBACKEND=pytorch</span><span id="7eac" class="nk lf it ng b gy np nm l nn no">(dgl_pytorch)…my_task:~$dglke_train — model_name TransE_l2 — dataset FB15k — batch_size 1000 \</span><span id="ab79" class="nk lf it ng b gy np nm l nn no"> — neg_sample_size 200 — hidden_dim 400 — gamma 19.9 — lr 0.25 — max_step 500 — log_interval 100 \</span><span id="08e8" class="nk lf it ng b gy np nm l nn no"> — batch_size_eval 16 -adv — regularization_coef 1.00E-09 — test — num_thread 1 — num_proc 8</span><span id="17a0" class="nk lf it ng b gy np nm l nn no"> — — — — — — — Test result — — — — — — — </span><span id="ba86" class="nk lf it ng b gy np nm l nn no">Test average MRR : 0.47339627234644155</span><span id="ebde" class="nk lf it ng b gy np nm l nn no">Test average MR : 58.33693352067851</span><span id="a2cc" class="nk lf it ng b gy np nm l nn no">Test average HITS@1 : 0.2806791826784717</span><span id="7047" class="nk lf it ng b gy np nm l nn no">Test average HITS@3 : 0.6246889336561088</span><span id="1a32" class="nk lf it ng b gy np nm l nn no">Test average HITS@10 : 0.7729342655448528</span><span id="92a9" class="nk lf it ng b gy np nm l nn no"> — — — — — — — — — — — — — — — — — — — — -</span></pre><h1 id="fcc8" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">刚刚发生了什么？</h1><p id="ba43" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">首先，我们将<a class="ae mb" href="https://www.dgl.ai/pages/start.html" rel="noopener ugc nofollow" target="_blank"> DGL </a>的后端设置为<a class="ae mb" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>。然后，我们使用dglke-train创建了一个训练任务。这个训练任务使用带L2损耗的TransE，下载FB15k数据集。然后，我们指示模型构建k=200k=200个负样本，其中γ=400用于嵌入维度，1000用于小批量大小(batch_size 1000)，batch_size_eval=16作为用于测试的超参数。</p><h1 id="d1f0" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">下一步是什么？</h1><p id="bff3" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">了解更多关于<a class="ae mb" href="https://github.com/awslabs/dgl-ke" rel="noopener ugc nofollow" target="_blank">DGL-柯</a>和<a class="ae mb" href="https://www.dgl.ai/" rel="noopener ugc nofollow" target="_blank"> DGL </a>的信息，并继续关注更多的例子。</p></div></div>    
</body>
</html>