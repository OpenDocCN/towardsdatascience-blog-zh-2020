<html>
<head>
<title>Predicting Forest Cover Types with the Machine Learning Workflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用机器学习工作流预测森林覆盖类型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/predicting-forest-cover-types-with-the-machine-learning-workflow-1f6f049bf4df?source=collection_archive---------9-----------------------#2020-01-13">https://towardsdatascience.com/predicting-forest-cover-types-with-the-machine-learning-workflow-1f6f049bf4df?source=collection_archive---------9-----------------------#2020-01-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/101b4e173e662ce165f2bc1b967e3fb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Jijezz8NBKn_A3gA"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://unsplash.com/@nathananderson?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">内森·安德森</a>在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><h2 id="aa41" class="jh ji jj bd b dl jk jl jm jn jo jp dk jq translated" aria-label="kicker paragraph"><a class="ae ep" rel="noopener" target="_blank" href="https://towardsdatascience.com/machine-learning/home">机器学习</a></h2><div class=""/><div class=""><h2 id="5bca" class="pw-subtitle-paragraph kp js jj bd b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg dk translated">又名神奇的树:在哪里找到，如何检测它们🌲</h2></div><p id="3f6f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在本文中，我将解释如何使用端到端的工作流来处理多类分类监督机器学习(ML)问题(或项目)。</p><ul class=""><li id="44cc" class="md me jj lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated"><strong class="lj jt">监督:</strong>特征(生成预测的变量)和目标(待确定的变量)在数据集中可用。</li><li id="f90a" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated"><strong class="lj jt">多类分类:</strong>有七个离散的类别来区分目标。</li></ul><p id="faa1" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">该项目基于机器学习社区中一个著名的数据集，称为<a class="ae jg" href="https://archive.ics.uci.edu/ml/datasets/covertype" rel="noopener ugc nofollow" target="_blank">森林覆盖类型</a>，可在<a class="ae jg" href="https://archive.ics.uci.edu/ml/index.php" rel="noopener ugc nofollow" target="_blank"> UCI 机器学习知识库</a>中下载。</p><p id="4872" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">来自原始数据集的<a class="ae jg" href="https://en.wikipedia.org/wiki/Stratified_sampling" rel="noopener ugc nofollow" target="_blank">分层样本</a>用于应用工作流和独立测试集以生成最终预测，被用作 Kaggle 中初学者友好型<a class="ae jg" href="https://www.kaggle.com/c/learn-together" rel="noopener ugc nofollow" target="_blank">竞赛的一部分。</a></p><p id="f62c" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">项目(和竞赛)的目标:</strong>以最佳<a class="ae jg" href="https://miro.medium.com/max/1064/1*5XuZ_86Rfce3qyLt7XMlhw.png" rel="noopener">精度</a>预测北科罗拉多州<a class="ae jg" href="https://en.wikipedia.org/wiki/Roosevelt_National_Forest" rel="noopener ugc nofollow" target="_blank">罗斯福国家森林</a>四个不同荒野地区的七种不同覆盖类型。</p><p id="4442" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">四个荒野地区是:</p><ul class=""><li id="b26b" class="md me jj lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated">1:拉瓦</li><li id="7fc2" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">2:纽塔</li><li id="633d" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">3:科曼奇峰</li><li id="64b0" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">4: Cache la Poudre</li></ul><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mr"><img src="../Images/83b2c7c260df5013875200ecf17c39e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FdKyVG-1-9QMYPO_.jpg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">Cache la Poudre 荒野地区(<a class="ae jg" href="https://www.uncovercolorado.com/national-lands/cache-la-poudre-wilderness/" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="588e" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在<code class="fe mw mx my mz b">Cover_Type</code>栏中从 1 到 7 的七个类别，待分类:</p><ul class=""><li id="9e6f" class="md me jj lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated">1:云杉/冷杉</li><li id="034e" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">2:黑松</li><li id="7a3a" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">3:美国黄松</li><li id="f564" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">4:杨木/柳木</li><li id="9710" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">5:阿斯彭</li><li id="451e" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">6:道格拉斯冷杉</li><li id="6c0c" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">7:克鲁姆霍尔茨</li></ul><p id="a3f3" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">目标(封面类型)的名字让我想起了神奇的野兽，所以我称它们为神奇的树，以增加项目的想象力🙃。</p><p id="83a0" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">端到端机器学习工作流程步骤:</strong>为了对封面类型进行分类并回答发起的问题，在哪里找到奇异的树以及如何检测它们，将遵循以下步骤:</p><ol class=""><li id="0fc9" class="md me jj lj b lk ll ln lo lq mf lu mg ly mh mc na mj mk ml bi translated">理解、清理和格式化数据</li><li id="c2f6" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc na mj mk ml bi translated">探索性数据分析</li><li id="912b" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc na mj mk ml bi translated">特征工程和选择</li><li id="ab84" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc na mj mk ml bi translated">比较几种机器学习模型</li><li id="503b" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc na mj mk ml bi translated">对最佳模型执行超参数调整</li><li id="4373" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc na mj mk ml bi translated">解释模型结果</li><li id="49c9" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc na mj mk ml bi translated">用测试数据评估最佳模型(回答初始问题)</li><li id="2654" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc na mj mk ml bi translated">总结和结论</li></ol><p id="1402" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我将在本文中提供该项目的亮点，项目背后的全面分析和完整代码可在<a class="ae jg" href="https://www.kaggle.com/cereniyim/fantastic-trees-where-to-find-how-to-detect-them" rel="noopener ugc nofollow" target="_blank"> Kaggle 笔记本</a>和<a class="ae jg" href="https://github.com/cereniyim/Tree-Classification-ML-Model" rel="noopener ugc nofollow" target="_blank"> GitHub </a>中获得。</p><p id="e93a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">对于数据角力和可视化<a class="ae jg" href="https://numpy.org/" rel="noopener ugc nofollow" target="_blank"> numpy </a>，<a class="ae jg" href="https://pandas.pydata.org/" rel="noopener ugc nofollow" target="_blank"> pandas </a>，<a class="ae jg" href="https://matplotlib.org/" rel="noopener ugc nofollow" target="_blank"> matplotlib </a>，<a class="ae jg" href="https://seaborn.pydata.org/" rel="noopener ugc nofollow" target="_blank">seaborn</a>；为了建立机器学习模型<a class="ae jg" href="https://xgboost.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> xgboost </a>，l<a class="ae jg" href="https://lightgbm.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">right GBM</a>和<a class="ae jg" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank">scikit-learn</a>；为了执行预处理步骤，将使用<a class="ae jg" href="https://scikit-learn.org/stable/modules/preprocessing.html" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>。</p><h2 id="4036" class="nb nc jj bd nd ne nf dn ng nh ni dp nj lq nk nl nm lu nn no np ly nq nr ns jp bi translated">1.理解、清理和格式化数据</h2><p id="07e3" class="pw-post-body-paragraph lh li jj lj b lk nt kt lm ln nu kw lp lq nv ls lt lu nw lw lx ly nx ma mb mc im bi translated">让我们加载训练数据并创建<code class="fe mw mx my mz b">trees</code>数据框:</p><pre class="ms mt mu mv gt ny mz nz oa aw ob bi"><span id="5805" class="nb nc jj mz b gy oc od l oe of">trees = pd.read_csv("/kaggle/input/learn-together/train.csv")</span></pre><p id="2128" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我总是发现查看第一行和最后一行很有用:</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi og"><img src="../Images/0362eedcedbfe65c016735b1632790e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EZfm66LW49NTthKFW8xrug.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">数据集的第一列和第一行</p></figure><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oh"><img src="../Images/ddea4ae2ddd95246067c739a60d36ef6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RDXxE67Mqn3elE2SDCBs5g.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">数据集的最后一列和最后一行</p></figure><p id="9b49" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">第一个观察结果是，<code class="fe mw mx my mz b">Vertical_Distance_To_Hydrology</code>列中有一些负值。我将在<em class="oi">检查异常&amp;异常值</em>部分对此进行更详细的检查。</p><p id="4d81" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了理解<code class="fe mw mx my mz b">trees</code>数据框架，让我们看看数据类型和描述性统计。使用 pandas <code class="fe mw mx my mz b">info</code>方法，我们可以列出非空值和数据类型:</p><pre class="ms mt mu mv gt ny mz nz oa aw ob bi"><span id="8b09" class="nb nc jj mz b gy oc od l oe of"><strong class="mz jt">Data columns (total 56 columns):<br/>Id                                    15120 non-null int64<br/>Elevation                             15120 non-null int64<br/>Aspect                                15120 non-null int64<br/>Slope                                 15120 non-null int64<br/>Horizontal_Distance_To_Hydrology      15120 non-null int64<br/>Vertical_Distance_To_Hydrology        15120 non-null int64<br/>Horizontal_Distance_To_Roadways       15120 non-null int64<br/>Hillshade_9am                         15120 non-null int64<br/>Hillshade_Noon                        15120 non-null int64<br/>Hillshade_3pm                         15120 non-null int64<br/>Horizontal_Distance_To_Fire_Points    15120 non-null int64<br/>Wilderness_Area1                      15120 non-null int64<br/>Wilderness_Area2                      15120 non-null int64<br/>Wilderness_Area3                      15120 non-null int64<br/>Wilderness_Area4                      15120 non-null int64<br/>Soil_Type1                            15120 non-null int64<br/>Soil_Type2                            15120 non-null int64<br/>Soil_Type3                            15120 non-null int64<br/>Soil_Type4                            15120 non-null int64<br/>Soil_Type5                            15120 non-null int64<br/>Soil_Type6                            15120 non-null int64<br/>Soil_Type7                            15120 non-null int64<br/>Soil_Type8                            15120 non-null int64<br/>Soil_Type9                            15120 non-null int64<br/>Soil_Type10                           15120 non-null int64<br/>Soil_Type11                           15120 non-null int64<br/>Soil_Type12                           15120 non-null int64<br/>Soil_Type13                           15120 non-null int64<br/>Soil_Type14                           15120 non-null int64<br/>Soil_Type15                           15120 non-null int64<br/>Soil_Type16                           15120 non-null int64<br/>Soil_Type17                           15120 non-null int64<br/>Soil_Type18                           15120 non-null int64<br/>Soil_Type19                           15120 non-null int64<br/>Soil_Type20                           15120 non-null int64<br/>Soil_Type21                           15120 non-null int64<br/>Soil_Type22                           15120 non-null int64<br/>Soil_Type23                           15120 non-null int64<br/>Soil_Type24                           15120 non-null int64<br/>Soil_Type25                           15120 non-null int64<br/>Soil_Type26                           15120 non-null int64<br/>Soil_Type27                           15120 non-null int64<br/>Soil_Type28                           15120 non-null int64<br/>Soil_Type29                           15120 non-null int64<br/>Soil_Type30                           15120 non-null int64<br/>Soil_Type31                           15120 non-null int64<br/>Soil_Type32                           15120 non-null int64<br/>Soil_Type33                           15120 non-null int64<br/>Soil_Type34                           15120 non-null int64<br/>Soil_Type35                           15120 non-null int64<br/>Soil_Type36                           15120 non-null int64<br/>Soil_Type37                           15120 non-null int64<br/>Soil_Type38                           15120 non-null int64<br/>Soil_Type39                           15120 non-null int64<br/>Soil_Type40                           15120 non-null int64<br/>Cover_Type                            15120 non-null int64<br/>dtypes: int64(56)<br/>memory usage: 6.5 MB</strong></span></pre><p id="207b" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">用<code class="fe mw mx my mz b">describe</code>方法，我们可以观察到描述性统计:</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi og"><img src="../Images/0b165d333fdbfd415ad39da87179ea74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LI6eikWr4SNIqNeFC7TxKg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">第一列的描述性统计</p></figure><p id="fb32" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><code class="fe mw mx my mz b">info</code>法提供了一些有价值的信息:</p><ul class=""><li id="2df3" class="md me jj lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated">数据是格式化的和干净的:没有任何空值，所有要素都是数字。</li><li id="7aca" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">有<a class="ae jg" href="https://www.geeksforgeeks.org/ml-one-hot-encoding-of-datasets-in-python/" rel="noopener ugc nofollow" target="_blank">一个热编码</a>栏(在<a class="ae jg" href="https://www.kaggle.com/cereniyim/fantastic-trees-where-to-find-how-to-detect-them#2.2.-Can-one-Fantastic-Tree-belong-to-multiple-soil-types-and-wilderness-areas-?" rel="noopener ugc nofollow" target="_blank">原始笔记本</a>中验证):土壤类型和荒野面积。</li></ul><p id="269a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">检查异常&amp;异常值:</strong></p><p id="d5e8" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">观察到的第一个异常是<code class="fe mw mx my mz b">Vertical_Distance_To_Hydrology</code>列中的负值。定义是:</p><blockquote class="oj ok ol"><p id="045e" class="lh li oi lj b lk ll kt lm ln lo kw lp om lr ls lt on lv lw lx oo lz ma mb mc im bi translated">到最近地表水特征的垂直距离</p></blockquote><p id="24c1" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">通过一些研究和使用逻辑，负值表明最近的地表水低于该数据点或低于海平面。两种情况都有道理，所以我要保留负值。</p><p id="b7ae" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了帮助未来的 ML 模型掌握数据中的模式，我将搜索异常值并使用极端异常值方法来确定它们。</p><p id="7b6e" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果数据点位于第一个四分位数<a class="ae jg" href="https://en.wikipedia.org/wiki/Quartile" rel="noopener ugc nofollow" target="_blank">以下或第三个四分位数</a>以上的四分位数间距的 3 倍以上，则数据点将被删除。</p><figure class="ms mt mu mv gt iv"><div class="bz fp l di"><div class="op oq l"/></div></figure><pre class="ms mt mu mv gt ny mz nz oa aw ob bi"><span id="886b" class="nb nc jj mz b gy oc od l oe of"><em class="oi"># loop through all columns to see if there are any outliers</em><br/>for column in trees.columns:<br/>    if outlier_function(trees, column)[2] &gt; 0:<br/>        print("There are {} outliers in {}".format(outlier_function(trees, column)[2], column))</span></pre><p id="57a7" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">知道了荒野面积和土壤类型列是一次性编码的，我们就可以专注于其余部分:</p><pre class="ms mt mu mv gt ny mz nz oa aw ob bi"><span id="5e0e" class="nb nc jj mz b gy oc od l oe of"><strong class="mz jt">There are 53 outliers in Horizontal_Distance_To_Hydrology<br/>There are 49 outliers in Vertical_Distance_To_Hydrology<br/>There are 3 outliers in Horizontal_Distance_To_Roadways<br/>There are 7 outliers in Hillshade_9am<br/>There are 20 outliers in Hillshade_Noon<br/>There are 132 outliers in Horizontal_Distance_To_Fire_Points</strong></span></pre><p id="949a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">山体阴影列是特定时间阴影的 RGB 颜色表示，因此范围已经固定在 0 到 255 之间。</p><p id="466a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">考虑到<code class="fe mw mx my mz b">Horizontal_Distance_To_Firepoints</code>具有最大数量的异常值和最宽的数据范围【0，6993】，我将只删除该列中的异常值。</p><pre class="ms mt mu mv gt ny mz nz oa aw ob bi"><span id="3ff7" class="nb nc jj mz b gy oc od l oe of">trees = trees[(trees['Horizontal_Distance_To_Fire_Points'] &gt; outlier_function(trees, 'Horizontal_Distance_To_Fire_Points')[0]) &amp;<br/>              (trees['Horizontal_Distance_To_Fire_Points'] &lt; outlier_function(trees, 'Horizontal_Distance_To_Fire_Points')[1])]</span></pre><h2 id="9806" class="nb nc jj bd nd ne nf dn ng nh ni dp nj lq nk nl nm lu nn no np ly nq nr ns jp bi translated">2.探索性数据分析</h2><p id="89ac" class="pw-post-body-paragraph lh li jj lj b lk nt kt lm ln nu kw lp lq nv ls lt lu nw lw lx ly nx ma mb mc im bi translated">EDA 是该工作流中的第一步，在该步骤中，针对特征选择启动决策过程。通过观察目标的分布、特征与目标的关系以及特征之间的联系，可以获得一些有价值的见解。</p><p id="10bd" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我的偏好是从查看目标开始，然后检查特征及其与目标的关系。</p><p id="de7c" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">目标分布:</strong></p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi or"><img src="../Images/8a40bb52e0382088093737ccb3f19afd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ukdot8pg9lFTyKO2AOF7hQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">奇异的树/标签/覆盖类型的分布</p></figure><p id="c844" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">数据集具有平衡的标签，导致每个类别的封面类型数量几乎相等。当我们应用 ML 算法时，这将是一个优势，因为模型将有很好的机会学习所有类的模式，而不需要进一步的平衡策略。</p><p id="fc28" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">荒野地区——覆盖类型:</strong></p><p id="df87" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了了解这种关系，荒野区域列将被反向热编码。</p><pre class="ms mt mu mv gt ny mz nz oa aw ob bi"><span id="00c5" class="nb nc jj mz b gy oc od l oe of">trees['Wilderness_Area_Type'] = (trees.iloc[:, 11:15] == 1).idxmax(1)</span></pre><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi or"><img src="../Images/e2ae341c0d3b27ac14e3959c47453387.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H6u0Xw38fDjIRNpxcUknPg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">不同荒野地区覆盖类型的 KDE 样地</p></figure><p id="f6f6" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">荒野区域是确定<code class="fe mw mx my mz b">Cover_Type</code>的显著特征。</p><p id="d8b4" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">荒野地区—土壤类型—覆盖类型:</strong></p><p id="005a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">反向一热编码将使用以下函数应用于土壤类型列。因此，将添加一个具有 1 到 40 之间的离散数字的列<code class="fe mw mx my mz b">Soil_Type</code>。</p><figure class="ms mt mu mv gt iv"><div class="bz fp l di"><div class="op oq l"/></div></figure><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi os"><img src="../Images/bc20acc580788d2b8d08f65bd47c6fd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lrN2jOGnMjn92EAulUygLw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">不同荒野地区土壤类型和覆盖类型散点图</p></figure><p id="06d3" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">不同的荒野地区由一些特定的树木组成。有趣的是，有一种奇妙的树，棉白杨/柳树，特别喜欢生长在 Cache la Poudre(荒野区域 4)。虽然云杉/冷杉、黑松、白杨和花旗松可以在任何土壤类型中生长，但其他覆盖类型可以在特定的土壤类型中生长。</p><p id="b3e2" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">连续特征之间的关系:</strong></p><p id="9148" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">土壤类型和荒野区域列是离散的，并且都是一个分类要素的一个热编码版本。</p><p id="d8b2" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">其余要素被视为连续要素:<em class="oi">高程、坡向、坡度、水平距离水文、垂直距离水文、水平距离道路、山体阴影上午 9 点、山体阴影中午 3 点、水平距离火灾点。</em></p><p id="7538" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了用一个函数将它们可视化，将绘制 Seaborn 的<code class="fe mw mx my mz b">PairGrid</code>,以提供用不同的图调整上下对角线的灵活性:</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ot"><img src="../Images/0c3732e1f7a33a60ffa490bcd2b581a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SV5K_MtBmziUi9j2dIEpsg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">连续特征的成对网格</p></figure><p id="c3a5" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">上半部分显示了具有皮尔逊系数的 KDE 图，下半部分显示了散点图。对角线是特定特征的直方图。正如所料，山体阴影特征是<a class="ae jg" href="https://en.wikipedia.org/wiki/Multicollinearity" rel="noopener ugc nofollow" target="_blank">共线的</a>:</p><ul class=""><li id="6308" class="md me jj lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated">山体阴影中午-山体阴影下午 3 点</li><li id="658b" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">山体阴影下午 3 点—山体阴影上午 9 点</li></ul><p id="1ef4" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这些对为模型提供相同的输入，为了更好的可解释性，其中一个将在<em class="oi">特征工程&amp;选择</em>中被删除。</p><p id="30db" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">特性和目标的皮尔逊系数:</strong></p><p id="b7ca" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">作为 EDA 的最后一步，当观察特征和目标的 Pearson 系数时，只有 1%的 one-hot-encoded 土壤类型列在确定<code class="fe mw mx my mz b">Cover_Type</code>时是有效的(本文未显示，但在笔记本<a class="ae jg" href="https://www.kaggle.com/cereniyim/fantastic-trees-where-to-find-how-to-detect-them#2.8.-Pearson-Coefficients-of-all-features" rel="noopener ugc nofollow" target="_blank">这里</a>)。因此，它们将被排除，皮尔逊系数将被重新使用连续特征、一个热编码的荒野区域、<code class="fe mw mx my mz b">Soil_Type</code>和<code class="fe mw mx my mz b">Cover_Type</code>。</p><pre class="ms mt mu mv gt ny mz nz oa aw ob bi"><span id="c0dc" class="nb nc jj mz b gy oc od l oe of">continuous_variables = trees.columns[1:11].tolist()</span><span id="4298" class="nb nc jj mz b gy ou od l oe of">wilderness_areas = sorted(trees['Wilderness_Area_Type'].value_counts().index.tolist())</span><span id="b06d" class="nb nc jj mz b gy ou od l oe of">all_features_w_label = continuous_variables + wilderness_areas + ["Soil_Type"] + ["Cover_Type"]</span><span id="ccb0" class="nb nc jj mz b gy ou od l oe of">trees_w_numeric_soil = trees[all_features_w_label]</span></pre><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ov"><img src="../Images/80dbde3fc9d5f11b710bee1a1a78c2f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R_BYSaSEDVBllPTorL451g.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">cover_type 数据集的皮尔逊系数热图</p></figure><p id="7bff" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">深色代表强烈的相关性。不幸的是，最后一列由浅色组成，导致特征相对于目标的弱皮尔逊系数，在[-0.22，0.12]的范围内。</p><p id="04c6" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">用<a class="ae jg" href="https://www.geeksforgeeks.org/ml-label-encoding-of-datasets-in-python/" rel="noopener ugc nofollow" target="_blank">标签编码的</a> <code class="fe mw mx my mz b">Soil_Type</code>列与<code class="fe mw mx my mz b">Cover_Type</code>有更强的相关性。</p><p id="0ce7" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><code class="fe mw mx my mz b">Hillshade_9am</code>在确定<code class="fe mw mx my mz b">Cover_Type</code>时最不重要。因此，它将在下一节中被删除。</p><h2 id="3ae3" class="nb nc jj bd nd ne nf dn ng nh ni dp nj lq nk nl nm lu nn no np ly nq nr ns jp bi translated">3.特征工程和选择</h2><p id="db38" class="pw-post-body-paragraph lh li jj lj b lk nt kt lm ln nu kw lp lq nv ls lt lu nw lw lx ly nx ma mb mc im bi translated">在已有特征的基础上提取新特征，用一些<a class="ae jg" href="https://scikit-learn.org/stable/modules/feature_selection.html" rel="noopener ugc nofollow" target="_blank">方法和算法</a>消除特征，称为特征工程&amp;选择。</p><p id="b914" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">水文要素有水平距离和垂直距离，两者的<a class="ae jg" href="https://en.wikipedia.org/wiki/Euclidean_distance" rel="noopener ugc nofollow" target="_blank">欧几里德距离</a>相加闪烁。</p><pre class="ms mt mu mv gt ny mz nz oa aw ob bi"><span id="bdb1" class="nb nc jj mz b gy oc od l oe of">trees_w_numeric_soil['Euclidian_Distance_To_Hydrology'] = (trees_w_numeric_soil['Horizontal_Distance_To_Hydrology']**2 +                                                        trees_w_numeric_soil['Vertical_Distance_To_Hydrology']**2)**0.5</span></pre><p id="e146" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">此外，添加数字特征的线性组合是特征工程中的常见做法。对于一些数字特征，两个变量的平均值相加:</p><pre class="ms mt mu mv gt ny mz nz oa aw ob bi"><span id="361e" class="nb nc jj mz b gy oc od l oe of">trees_w_numeric_soil['Mean_Elevation_Vertical_Distance_Hydrology'] = (trees_w_numeric_soil['Elevation'] +                                                               trees_w_numeric_soil['Vertical_Distance_To_Hydrology'])/2</span><span id="0375" class="nb nc jj mz b gy ou od l oe of">trees_w_numeric_soil['Mean_Distance_Hydrology_Firepoints'] = (trees_w_numeric_soil['Horizontal_Distance_To_Hydrology'] +                   trees_w_numeric_soil['Horizontal_Distance_To_Fire_Points'])/2</span><span id="74a8" class="nb nc jj mz b gy ou od l oe of">trees_w_numeric_soil['Mean_Distance_Hydrology_Roadways'] = (trees_w_numeric_soil['Horizontal_Distance_To_Hydrology'] +                                                   trees_w_numeric_soil['Horizontal_Distance_To_Roadways'])/2</span><span id="4fc3" class="nb nc jj mz b gy ou od l oe of">trees_w_numeric_soil['Mean_Distance_Firepoints_Roadways'] = (trees_w_numeric_soil['Horizontal_Distance_To_Fire_Points'] +                              trees_w_numeric_soil['Horizontal_Distance_To_Roadways'])/2</span></pre><p id="3f6b" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">另一种常见的做法是对数字特征执行对数和平方根变换。再添加 5 个特征后，对正特征应用平方根变换:</p><pre class="ms mt mu mv gt ny mz nz oa aw ob bi"><span id="8701" class="nb nc jj mz b gy oc od l oe of">for col <strong class="mz jt">in</strong> trees_w_numeric_soil.columns:<br/>    if trees_w_numeric_soil[col].min() &gt;= 0:<br/>        if col == 'Cover_Type':<br/>            next<br/>        else:<br/>            trees_w_numeric_soil['sqrt' + col] = np.sqrt(trees_w_numeric_soil[col])</span></pre><p id="14e7" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在重新访问皮尔逊系数之后，如果新添加的特征显示出与目标更强的相关性，则保留该新添加的特征，而丢弃原始特征。此外，<code class="fe mw mx my mz b">Hillshade_9am</code>因与<code class="fe mw mx my mz b">Hillshade_3pm</code>密切相关而被剔除。</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ow"><img src="../Images/8a548ca0fd3e84733de06209a4ccc55c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A0RiYK5njqIWeubdWItPGg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">特征工程后的皮尔逊系数</p></figure><p id="77aa" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">最后的特点是:</p><pre class="ms mt mu mv gt ny mz nz oa aw ob bi"><span id="6a1a" class="nb nc jj mz b gy oc od l oe of"><em class="oi"># final list of features</em><br/>transformed_features = ['sqrtHorizontal_Distance_To_Hydrology', 'sqrtMean_Distance_Hydrology_Roadways', 'sqrtEuclidian_Distance_To_Hydrology', <br/>'Mean_Elevation_Vertical_Distance_Hydrology', 'Mean_Distance_Firepoints_Roadways', 'Mean_Distance_Hydrology_Firepoints']</span><span id="a0aa" class="nb nc jj mz b gy ou od l oe of">all_features =  (['Elevation', 'Aspect', 'Slope', 'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', <br/>'Hillshade_Noon', 'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points' ] + <br/>wilderness_areas + ['Soil_Type'] + transformed_features)</span><span id="73a4" class="nb nc jj mz b gy ou od l oe of">trees_training = trees_w_numeric_soil[all_features]<br/>labels_training = trees_w_numeric_soil["Cover_Type"].as_matrix()</span></pre><p id="ef35" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了比较 ML 模型并建立基线，<code class="fe mw mx my mz b">trees_training</code>和<code class="fe mw mx my mz b">labels_training</code>数据帧被分成训练集和验证集。</p><pre class="ms mt mu mv gt ny mz nz oa aw ob bi"><span id="ebc0" class="nb nc jj mz b gy oc od l oe of">X_train, X_valid, y_train, y_valid = train_test_split(trees_training, labels_training, test_size=0.2, random_state=1)</span></pre><ul class=""><li id="13d2" class="md me jj lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated">训练集用作输入，以便机器学习模型可以捕捉特征中的模式，并利用它们来区分目标。</li><li id="766c" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">验证集用于评估 ML 模型的性能，并量化其将模式归纳到新数据集的能力。</li></ul><p id="e7a2" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">创建基线度量:</strong></p><p id="7e52" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在深入研究 ML 分类算法之前，我将计算一个常识基线。常识基线可以定义为了解该领域的人如何在不使用任何 ML 技巧的情况下解决问题。它可以用人类的直觉以及一个虚拟或简单的算法来计算，只需要几行代码。</p><p id="7bb8" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我将使用 scikit-learn 库中的一个虚拟算法。使用该算法，我将建立一个具有准确性的基线度量，即所有覆盖类型中正确预测的覆盖类型的百分比。准确性是本次竞赛的评估标准，将在整个项目中使用，记住它<a class="ae jg" href="https://medium.com/techspace-usict/measuring-just-accuracy-is-not-enough-in-machine-learning-a-better-technique-is-required-e7199ac36856" rel="noopener">对于某些分类问题来说不是最有效的标准</a>。</p><p id="960a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">基线指标在某种程度上很重要，如果机器学习模型不能击败人的简单直观预测或算法的猜测，那么原始问题需要重新考虑或训练数据需要重新构建。</p><pre class="ms mt mu mv gt ny mz nz oa aw ob bi"><span id="d5fa" class="nb nc jj mz b gy oc od l oe of"><em class="oi"># Create dummy classifer</em><br/>dummy = DummyClassifier(strategy='stratified', random_state=1)</span><span id="0646" class="nb nc jj mz b gy ou od l oe of"><em class="oi"># train the model</em><br/>dummy.fit(X_train, y_train)</span><span id="458d" class="nb nc jj mz b gy ou od l oe of"><em class="oi"># Get accuracy score</em><br/>baseline_accuracy = dummy.score(X_valid, y_valid)<br/>print("Our dummy algorithm classified {:0.2f} of the of the trees correctly".format(baseline_accuracy))<br/><strong class="mz jt">Our dummy algorithm classified 0.14 of the of the trees correctly</strong></span></pre><p id="24a5" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">现在，我期望以下 ML 模型击败 0.14 的准确度分数！</p><h2 id="7abb" class="nb nc jj bd nd ne nf dn ng nh ni dp nj lq nk nl nm lu nn no np ly nq nr ns jp bi translated">4.比较几种机器学习模型</h2><p id="8b28" class="pw-post-body-paragraph lh li jj lj b lk nt kt lm ln nu kw lp lq nv ls lt lu nw lw lx ly nx ma mb mc im bi translated">有时很难知道哪种机器学习模型将有效地解决给定的问题。所以，我总是尝试几种机器学习模型。</p><p id="15f9" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">一项<a class="ae jg" href="https://pdfs.semanticscholar.org/7944/be8a9d4209bea4fcea210eacc6be95681b2f.pdf?_ga=2.122963467.1406864965.1578477399-206203046.1578477399" rel="noopener ugc nofollow" target="_blank">研究</a>显示，基于树和基于距离的算法在分析的 165 个数据集上优于其他最大似然算法。</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ox"><img src="../Images/9491d4f5ea5b98edea0eea9946ac5477.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*MQYO-UVsymJPebDS.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">机器学习算法性能比较(<a class="ae jg" href="https://www.semanticscholar.org/paper/Data-driven-advice-for-applying-machine-learning-to-Olson-Cava/1279fe26020af034fd6f16b04a1c23427c127db3/figure/3" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="d265" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我将比较一个基于距离的算法和四个基于树的算法的准确性。</p><p id="b889" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">基于距离:</p><ul class=""><li id="d624" class="md me jj lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated">k-最近邻分类器(使用<a class="ae jg" href="https://en.wikipedia.org/wiki/Euclidean_distance" rel="noopener ugc nofollow" target="_blank">欧几里德距离</a>来聚类标签；之前需要进行规范化，并在原始笔记本中的处应用<a class="ae jg" href="https://www.kaggle.com/cereniyim/fantastic-trees-where-to-find-how-to-detect-them#4.1.-Z-Score-normalization-for-K-Nearest-Neighbors-and-LightGBM" rel="noopener ugc nofollow" target="_blank">。)</a></li></ul><p id="1958" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">基于树:</p><ul class=""><li id="0769" class="md me jj lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated">l<a class="ae jg" href="https://lightgbm.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">light GBM</a>库中的 light Gradient Boosting Machine(light GBM)分类器</li><li id="cea0" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">来自<a class="ae jg" href="https://xgboost.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> xgboost </a>库的额外梯度增强(XGBoost)分类器</li><li id="b402" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">来自<a class="ae jg" href="https://scikit-learn.org/stable/modules/ensemble.html#forests-of-randomized-trees" rel="noopener ugc nofollow" target="_blank"> scikit-learn 库的随机森林分类器</a></li><li id="56e4" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated">来自<a class="ae jg" href="https://scikit-learn.org/stable/modules/ensemble.html#forests-of-randomized-trees" rel="noopener ugc nofollow" target="_blank"> scikit-learn 库</a>的额外树(随机森林)分类器</li></ul><p id="7a51" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">(型号后面的代码是<a class="ae jg" href="https://www.kaggle.com/cereniyim/fantastic-trees-where-to-find-how-to-detect-them#4.2.-Build-models" rel="noopener ugc nofollow" target="_blank">这里是</a>。)</p><p id="805c" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">与研究结果不同，额外树分类器优于其他分类器。所有模型都优于基线度量，表明机器学习适用于森林覆盖类型的分类。</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oy"><img src="../Images/b278ad97feea562ae7fbbec6765312d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*919FyjnenJNYQh_boCzvRw.png"/></div></div></figure><p id="6c9f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们最好的模型，额外树分类器，是一个基于集合树的模型。<a class="ae jg" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html" rel="noopener ugc nofollow" target="_blank">sci kit-learn 库中的定义</a>如下:</p><blockquote class="oj ok ol"><p id="e6ed" class="lh li oi lj b lk ll kt lm ln lo kw lp om lr ls lt on lv lw lx oo lz ma mb mc im bi translated">该类实现了一个元估计器，它在数据集的各个子样本上拟合多个随机决策树(也称为额外树),并使用平均来提高预测精度和控制过度拟合。</p></blockquote><p id="74c4" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">与随机森林算法的主要区别在于:</p><ol class=""><li id="774a" class="md me jj lj b lk ll ln lo lq mf lu mg ly mh mc na mj mk ml bi translated">不是为节点中的特征寻找最有区别的分裂值，而是完全随机地选择分裂作为阈值。</li><li id="8dfc" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc na mj mk ml bi translated">子样本取自整个训练集，而不是训练集的<a class="ae jg" href="https://machinelearningmastery.com/a-gentle-introduction-to-the-bootstrap-method/" rel="noopener ugc nofollow" target="_blank">引导</a>样本。</li></ol><p id="3c54" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">因此，该算法对于过拟合变得更加鲁棒。</p><h2 id="5499" class="nb nc jj bd nd ne nf dn ng nh ni dp nj lq nk nl nm lu nn no np ly nq nr ns jp bi translated">5.对最佳模型执行超参数调整</h2><p id="00d8" class="pw-post-body-paragraph lh li jj lj b lk nt kt lm ln nu kw lp lq nv ls lt lu nw lw lx ly nx ma mb mc im bi translated">寻找模型参数的最佳组合被称为超参数调整，它可以极大地提高模型的性能。我将使用交叉验证的随机搜索算法进行超参数调整:</p><ul class=""><li id="283e" class="md me jj lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated"><strong class="lj jt">随机搜索:</strong>在一个范围内定义一组 ML 模型的参数，并输入到<a class="ae jg" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html" rel="noopener ugc nofollow" target="_blank"> sklearn 的</a>T0。该算法随机选择一些参数组合，并将定义的<code class="fe mw mx my mz b">score</code>(精确度，对于这个问题)与迭代进行比较。可以用参数<code class="fe mw mx my mz b">n_iter</code>控制随机搜索运行时间和迭代次数。</li><li id="a2f9" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated"><strong class="lj jt"> K-Fold 交叉验证:</strong>一种用于评估超参数在整个数据集上的性能的方法。(目测此处<a class="ae jg" href="https://scikit-learn.org/stable/_images/grid_search_cross_validation.png" rel="noopener ugc nofollow" target="_blank">为</a>)。不是将数据集分成训练集和验证集的两个静态子集，而是对于给定的 K，数据集被均等地划分，并且随着迭代，不同的 K-1 个子集被训练，并且用不同的子集测试模型。</li></ul><p id="d65b" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">使用以下一组参数和 5 重交叉验证，<code class="fe mw mx my mz b">RandomizedSearchCV</code>将寻找最佳组合:</p><pre class="ms mt mu mv gt ny mz nz oa aw ob bi"><span id="3efc" class="nb nc jj mz b gy oc od l oe of"><em class="oi"># The number of trees in the forest algorithm, default value is 100.</em><br/>n_estimators = [50, 100, 300, 500, 1000]<br/><br/><em class="oi"># The minimum number of samples required to split an internal node, default value is 2.</em><br/>min_samples_split = [2, 3, 5, 7, 9]<br/><br/><em class="oi"># The minimum number of samples required to be at a leaf node, default value is 1.</em><br/>min_samples_leaf = [1, 2, 4, 6, 8]<br/><br/><em class="oi"># The number of features to consider when looking for the best split, default value is auto.</em><br/>max_features = ['auto', 'sqrt', 'log2', None] <br/><br/><em class="oi"># Define the grid of hyperparameters to search</em><br/>hyperparameter_grid = {'n_estimators': n_estimators,<br/>                       'min_samples_leaf': min_samples_leaf,<br/>                       'min_samples_split': min_samples_split,<br/>                       'max_features': max_features}</span><span id="eaa7" class="nb nc jj mz b gy ou od l oe of"><em class="oi"># create model</em><br/>best_model = ExtraTreesClassifier(random_state=42)<br/><br/><em class="oi"># create Randomized search object</em><br/>random_cv = RandomizedSearchCV(estimator=best_model,                          param_distributions=hyperparameter_grid,<br/>                               cv=5, n_iter=20, <br/>                               scoring = 'accuracy',<br/>                               n_jobs = -1, verbose = 1, <br/>                               return_train_score = True, <br/>                               random_state=42)</span><span id="6037" class="nb nc jj mz b gy ou od l oe of"><em class="oi"># Fit on the all training data using random search object</em><br/>random_cv.fit(trees_training, labels_training)<br/>random_cv.best_estimator_</span></pre><p id="8a10" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">以下是参数的最佳组合:</p><ul class=""><li id="77c1" class="md me jj lj b lk ll ln lo lq mf lu mg ly mh mc mi mj mk ml bi translated"><code class="fe mw mx my mz b">n_estimators</code> = 300</li><li id="9297" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated"><code class="fe mw mx my mz b">max_features</code> =无</li><li id="729e" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated"><code class="fe mw mx my mz b">min_samples_leaf</code> = 1</li><li id="dcec" class="md me jj lj b lk mm ln mn lq mo lu mp ly mq mc mi mj mk ml bi translated"><code class="fe mw mx my mz b">min_samples_split</code> = 2</li></ul><p id="4a9d" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">当我将它们输入额外的树分类器时:</p><pre class="ms mt mu mv gt ny mz nz oa aw ob bi"><span id="0b34" class="nb nc jj mz b gy oc od l oe of"><strong class="mz jt">Accuracy score in the previous extra random forests model: 0.8659106070713809<br/>Accuracy score after hyperparameter tuning: 0.885923949299533</strong></span></pre><p id="26fe" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">导致精确度增加 2 个点。</p><p id="35bb" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">另一种搜索方法是<code class="fe mw mx my mz b">GridSearchCV</code>，与<code class="fe mw mx my mz b">RandomizedSearchCV</code>相反，搜索是在给定参数的每一个组合上进行的。(此处<a class="ae jg" href="https://www.kaggle.com/cereniyim/fantastic-trees-where-to-find-how-to-detect-them#5.1.2.-Possible-further-improvements-with-the-GridSearch" rel="noopener ugc nofollow" target="_blank">应用和讨论【原笔记本</a>)</p><h2 id="8002" class="nb nc jj bd nd ne nf dn ng nh ni dp nj lq nk nl nm lu nn no np ly nq nr ns jp bi translated">6.解释模型结果</h2><p id="f288" class="pw-post-body-paragraph lh li jj lj b lk nt kt lm ln nu kw lp lq nv ls lt lu nw lw lx ly nx ma mb mc im bi translated"><strong class="lj jt">混乱矩阵:</strong></p><p id="8cb6" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">可视化分类模型结果的最常见方法之一是混淆矩阵。</p><p id="ad7c" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">奇异树混淆矩阵将是一个 7x7 矩阵。我将使用标准化的混淆矩阵，因此在该特定类别的所有猜测中，正确猜到的实际封面类型的百分比将出现在矩阵的对角线上。</p><p id="926d" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">非对角线元素将显示模型错误标记的元素。混淆矩阵对角线上的百分比越高、颜色越深越好，表明有许多正确的预测。</p><p id="0376" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我将使用 scikit 中的<a class="ae jg" href="https://scikit-learn.org/0.22/auto_examples/model_selection/plot_confusion_matrix.html" rel="noopener ugc nofollow" target="_blank">函数</a>——学习绘制它:</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oz"><img src="../Images/df6833f8dac828a83941ceb941b121b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BKm1gKTbLwLqMSbtYAR72A.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">超参数调整的超随机森林分类器的混淆矩阵</p></figure><p id="0543" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">该模型很好地检测了美国黄松、三叶杨/柳树、白杨、花旗松、克拉姆霍尔茨等奇异的树木，但似乎对检测云杉/冷杉和黑松(覆盖类型 1 和 2)有些混淆。</p><p id="1781" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">特征重要性:</strong></p><p id="1028" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">另一种方法是查看具有<code class="fe mw mx my mz b">feature_importances_</code>的特征重要性:一个介于 0 和 1 之间的数字，显示每个特征对预测的贡献。数字越高，说明贡献越大。</p><p id="ce69" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">利用当前选择的功能、额外的树分类器和参数，前 10 个功能是:</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pa"><img src="../Images/7b09eff5fbc4ba173890320c40f4b996.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rcoBkbkZAV27MVwB1Wvvew.png"/></div></div></figure><p id="7c81" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">其中 5 个是在本项目范围内创建的。这个列表强调了特征工程和选择的重要性。</p><h2 id="a1f7" class="nb nc jj bd nd ne nf dn ng nh ni dp nj lq nk nl nm lu nn no np ly nq nr ns jp bi translated">7.用测试数据评估最佳模型(回答初始问题)</h2><p id="5f4d" class="pw-post-body-paragraph lh li jj lj b lk nt kt lm ln nu kw lp lq nv ls lt lu nw lw lx ly nx ma mb mc im bi translated"><strong class="lj jt">如何检测奇异的树(生成最终预测):</strong></p><p id="a1fb" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">Kaggle 为比赛提供单独的训练和测试设备。直到现在，我都在训练台上工作。尽管如此，测试集用于最终预测，所以我将测试集和训练集<a class="ae jg" href="https://www.kaggle.com/cereniyim/fantastic-trees-where-to-find-how-to-detect-them#6.1.-Align-test-set-with-the-training-set" rel="noopener ugc nofollow" target="_blank">在这里</a>对齐，并将其输入超参数调整的额外树分类器</p><blockquote class="pb"><p id="5d37" class="pc pd jj bd pe pf pg ph pi pj pk mc dk translated"><strong class="ak">成功检测奇异树，准确率 78%。</strong></p></blockquote><p id="3e08" class="pw-post-body-paragraph lh li jj lj b lk pl kt lm ln pm kw lp lq pn ls lt lu po lw lx ly pp ma mb mc im bi translated"><strong class="lj jt">哪里可以找到神奇的树:</strong></p><p id="10ae" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">云杉/冷杉、Lodgepole Pine 和 Krummholz 喜欢在 Rawah、Neota 和 Comanche Peak 荒野地区出没。</p><p id="59e0" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">Cache la Poudre 荒野区是种植黄松和棉白杨/柳树的最佳地点。</p><p id="9cfd" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果你看到一个白杨，怀疑你是在 Rawah 或 Comanche。</p><p id="ca7d" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">花旗松是一种容易相处的物种，适合任何荒野地区。</p><h2 id="4201" class="nb nc jj bd nd ne nf dn ng nh ni dp nj lq nk nl nm lu nn no np ly nq nr ns jp bi translated">8.总结和结论</h2><p id="a67e" class="pw-post-body-paragraph lh li jj lj b lk nt kt lm ln nu kw lp lq nv ls lt lu nw lw lx ly nx ma mb mc im bi translated">在本文中，我重点介绍了端到端的机器学习工作流在有监督的多类分类问题中的应用。我从使用 EDA 理解和可视化数据开始，并形成了对 cover 类型数据集的见解。利用 EDA 的输出，我进行了特征工程，在其中我转换、添加和删除了特征。</p><p id="8987" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">额外树分类器很好地匹配了这个分类问题的准确性度量。随着超参数的调整，通过调整<code class="fe mw mx my mz b">n_estimators</code>参数，模型的准确度分数增加了 2 个点。解释模型结果显示了最重要的特征以及如何进一步提高准确性(通过更好地区分封面类型 1 和 2)。</p></div><div class="ab cl pq pr hx ps" role="separator"><span class="pt bw bk pu pv pw"/><span class="pt bw bk pu pv pw"/><span class="pt bw bk pu pv"/></div><div class="im in io ip iq"><p id="ff0a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">项目背后的综合代码:</strong></p><p id="253d" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">【https://github.com/cereniyim/Tree-Classification-ML-Model】Github 回购:T4</p><p id="aca2" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt"> Kaggle 笔记本:</strong><a class="ae jg" href="https://www.kaggle.com/cereniyim/fantastic-trees-where-to-find-how-to-detect-them/notebook" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/cereniyim/fantastic-trees-where-to-find-how-detect-them/Notebook</a></p></div><div class="ab cl pq pr hx ps" role="separator"><span class="pt bw bk pu pv pw"/><span class="pt bw bk pu pv pw"/><span class="pt bw bk pu pv"/></div><div class="im in io ip iq"><p id="4e1f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">感谢阅读，这种端到端的工作流程可以应用于任何机器学习问题，我鼓励你去尝试一下！</p><p id="6b77" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">对于任何问题、评论或建设性反馈，您可以通过回复联系我，<a class="ae jg" href="https://twitter.com/cereniyim" rel="noopener ugc nofollow" target="_blank"> Twitter </a>或<a class="ae jg" href="https://www.linkedin.com/in/ceren-iyim" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>！</p></div></div>    
</body>
</html>