<html>
<head>
<title>Clustering Algorithm. Part 2.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">聚类算法。第二部分。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/clustering-algorithm-part-2-57907f5c0437?source=collection_archive---------51-----------------------#2020-07-06">https://towardsdatascience.com/clustering-algorithm-part-2-57907f5c0437?source=collection_archive---------51-----------------------#2020-07-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/dcff785e315820afb95e1ff3c1b3d09a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7Qxmslu2XIXyMTD1L7cFYA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">奥拉·米先科在<a class="ae jg" href="https://unsplash.com/s/photos/circles?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><div class=""/><div class=""><h2 id="f307" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">更快、更聪明、更快乐…</h2></div><p id="3805" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lu">扩展我之前的帖子并尝试解决这个问题，这个问题对于大多数传统的聚类算法来说太难了。</em></p><p id="4966" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这篇文章在很大程度上遵循了我上一篇文章的思路，你可以在下面找到:</p><div class="is it gp gr iu lv"><a rel="noopener follow" target="_blank" href="/a-fresh-look-at-clustering-algorithms-c3c4caa1a691"><div class="lw ab fo"><div class="lx ab ly cl cj lz"><h2 class="bd jk gy z fp ma fr fs mb fu fw ji bi translated">重新审视聚类算法</h2><div class="mc l"><h3 class="bd b gy z fp ma fr fs mb fu fw dk translated">深入研究一种新的聚类识别方法。</h3></div><div class="md l"><p class="bd b dl z fp ma fr fs mb fu fw dk translated">towardsdatascience.com</p></div></div><div class="me l"><div class="mf l mg mh mi me mj ja lv"/></div></div></a></div><p id="bd3c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我在这里尝试做的是概括它(一点)，加速它(很多！)并将其应用于一个数据集，该数据集会使大多数其他聚类算法脱轨。我还将强调这一过程中的一些挑战，并介绍一种新的预分析方法，它应该有助于选择问题的参数，以获得最佳结果。</p><p id="192d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">系好安全带。这将是一段颠簸的旅程。</p><p id="8dc8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">优化部分本身并不新鲜——我将在这里浏览一下，因为你可能会发现它很有用，并强调从经验中吸取的一些教训。如果您对此不感兴趣(或者如果您是专家)，请直接跳到下一节，深入了解真正擅长颠覆经典聚类算法的数据集。在上一篇文章中，我对我的方法进行基准测试的九个算法都失败了。每一个。单身。一个。</p><h2 id="5ce7" class="mk ml jj bd mm mn mo dn mp mq mr dp ms lh mt mu mv ll mw mx my lp mz na nb nc bi translated">优化代码</h2><p id="dd3c" class="pw-post-body-paragraph ky kz jj la b lb nd kk ld le ne kn lg lh nf lj lk ll ng ln lo lp nh lr ls lt im bi translated">当我开始查看一个相当复杂和庞大的数据集时，对算法性能的真正测试开始了。这个数据集是伦敦市中心一平方公里的栅格文件表示，显示了不到 250 座(可识别的)建筑物。每个坐标有 4 个 ln 值，这给我的笔记本电脑带来了很大的压力，计算时间为 5 小时 47 分钟。一点都不好。不得不说，这个算法在这个阶段对于一个蛮力方法来说有点痛苦，所以我需要做一些改进。目前的版本能够在 4 分 40 秒内完成同样的计算。同样的笔记本电脑，没有并行化，只是改进了算法。</p><p id="4580" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">那么大部分的性能提升来自哪里呢？</p><p id="f16e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该算法的核心是一个基本的 BFS 实现——在我们空间的图形表示中计算不相连的树。它遵循几个简单的步骤:</p><ol class=""><li id="79fa" class="ni nj jj la b lb lc le lf lh nk ll nl lp nm lt nn no np nq bi translated">选择我们想要检查的节点的 id(在这个阶段任何 id 都可以)。</li><li id="473f" class="ni nj jj la b lb nr le ns lh nt ll nu lp nv lt nn no np nq bi translated">识别它的邻居，并检查它们是否属于阈值以上的节点集。</li><li id="46fe" class="ni nj jj la b lb nr le ns lh nt ll nu lp nv lt nn no np nq bi translated">将邻居添加到“检查”列表中。</li><li id="ab88" class="ni nj jj la b lb nr le ns lh nt ll nu lp nv lt nn no np nq bi translated">将当前节点标记为已访问。</li><li id="3f63" class="ni nj jj la b lb nr le ns lh nt ll nu lp nv lt nn no np nq bi translated">更新 id 列表(删除所有“已访问”和“待检查”列表元素)</li><li id="2786" class="ni nj jj la b lb nr le ns lh nt ll nu lp nv lt nn no np nq bi translated">从“检查”列表中选择任意节点，并重复步骤 1-4。</li></ol><p id="527e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们这样做，直到“tocheck”列表为空，将所有“已访问”添加到集群字典，然后转到列表中的下一个 id(再次执行步骤 1)。</p><p id="36bc" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">第一个主要的胜利来自于间歇性地去除了列表和 numpy 数组的使用，并且不得不从一个转换到另一个。当处理 4000 个点的数据集时，这并不是一个大问题，当处理 4，000，000 个点的数据集时，这就成了一个大问题。</p><p id="86a5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以我从中得到的主要教训是——<strong class="la jk">尽量避免类型转换</strong>，至少在有潜在瓶颈的代码部分。这一变化导致了计算时间从<strong class="la jk">的 5 小时 47 分下降到 29 分 37 秒。</strong></p><p id="1f59" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">第二个胜利来自于认识到，即使字典是处理图/树结构的一个相当明显和直观的选择，但在现实中它们是不必要的和耗费资源的。至少在这个算法的框架内。这都是因为我需要一个简单的 id 来处理每个单元格，并且需要一个简单的方法来识别最近的邻居。</p><p id="4b23" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你参考我以前的文章中的原始算法的主要步骤——我们采用一个包含所有输入参数的 numpy 数组，为了维护和计数所有的单元格，我们从它们中创建一个字符串 id，然后使用它作为检查一切的密钥。放弃字典也允许我们完全放弃对这些索引的需求。这实际上使整个算法更加通用，因为例如，如果我们想处理 word2vec 的文本表示，我们将得到 300 个维度，因为每个文本块(或单个单词)都由一个 300 长的浮点向量表示。现在想象一下，我们必须对每个维度进行 10 次以上的划分，然后将它们全部粘合到一个字符串 id 中。我们将以一个 600 字符长的字符串来表示每个观察结果。不太好。事实证明，我们可以通过使用原始的 numpy 数组、屏蔽和索引来完成整个计算和循环路径。这一变化带来了另一个重大胜利——从 29 分 37 秒缩短到不到 7 分钟。</p><p id="1055" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最终的改进来自于一个非常小的变化，但仍然很重要。树计数过程的一部分涉及使用屏蔽来选择最近的邻居，然后将它们从仍然需要检查的元素数组中移除。这意味着同一个面具被使用了几次。只需将它传递到变量中，然后在多个需要的地方使用该变量，而不是在运行中进行计算，就又获得了 2 分钟的胜利，使最终执行时间达到 4 分 47 秒。</p><p id="5f22" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们需要做的另一个重要改变是积分归属。我将再次向您推荐上一篇文章的内容，但简单地说，我们只使用通过阈值的细胞来构建我们的树结构。这意味着，一旦我们确定了我们的聚类，我们就剩下一大堆没有分配给任何聚类的点。一方面，我们可以让它们保持原样。另一方面，在某些情况下，我们希望将整个数据集划分到围绕集群创建的组中。在我以前的文章中，我通过识别每个聚类的质心，然后比较每个点到每个质心的距离，然后将其分配给最近的一个质心。这在大多数情况下都很好，我们看到结果非常接近 KMeans 算法获得的结果。然而，有一整类问题，这种方法是行不通的。出于这个原因，我们将转移到一个不同的方法，这是不太依赖于质心。具体来说，我们将查看到最近的标记邻居的距离。也就是说，我们将测量到每个聚类中所有已识别点的距离，看哪一个是最近的，然后分配给最近的一个。</p><p id="6907" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所有的函数，包括两种属性方法都在本文的最后。</p><p id="5179" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这意味着我们已经准备好解决我们原始 blobs 的一个更复杂的问题:</p><h2 id="7dc6" class="mk ml jj bd mm mn mo dn mp mq mr dp ms lh mt mu mv ll mw mx my lp mz na nb nc bi translated">聚类算法禁区</h2><p id="b170" class="pw-post-body-paragraph ky kz jj la b lb nd kk ld le ne kn lg lh nf lj lk ll ng ln lo lp nh lr ls lt im bi translated">剧透警告——不再是了:)。</p><p id="3d6d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">经典数据集是简单的同心圆，它几乎颠覆了所有经典聚类算法。事实上，它是存在非线性边界的任何东西，所以在某种程度上，栅格文件簇识别已经是一个有效的例子。同心圆为我们提供了一个很好的简单示例，它还允许我们突出显示建筑物数据集因其规则模式而不会有的一些细微差别。但是我在这里跳向前。让我们从生成数据集开始，快速看一下标准算法是如何制作的。</p><p id="bd39" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们首先加载需要的库:</p><pre class="nw nx ny nz gt oa ob oc od aw oe bi"><span id="48f6" class="mk ml jj ob b gy of og l oh oi">%matplotlib inline<br/>import numpy as np<br/>import pandas as pd<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>pd.plotting.backend='seaborn'<br/>from IPython.display import clear_output<br/>import time</span></pre><p id="fa8d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">注意，我们不再需要最新实现的 itertools</p><p id="019e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">生成数据集:</p><pre class="nw nx ny nz gt oa ob oc od aw oe bi"><span id="27b9" class="mk ml jj ob b gy of og l oh oi">N=4000 #number of observations</span><span id="d7aa" class="mk ml jj ob b gy oj og l oh oi">r = np.random.random(N) * 0.1 + 1<br/>theta = np.random.random(N) * 2 * np.pi<br/>x = r * np.cos(theta) + 5<br/>y = r * np.sin(theta) + 5</span><span id="13f6" class="mk ml jj ob b gy oj og l oh oi">r = np.random.random(N) * 0.1 + 0.5<br/>theta = np.random.random(N) * 2 * np.pi<br/>x1=r * np.cos(theta) + 5<br/>y1 = r * np.sin(theta) + 5</span><span id="153f" class="mk ml jj ob b gy oj og l oh oi">r = np.random.random(N) * 0.1<br/>theta = np.random.random(N) * 2 * np.pi<br/>x2 = r * np.cos(theta) + 5<br/>y2 = r * np.sin(theta) + 5</span><span id="45e2" class="mk ml jj ob b gy oj og l oh oi">r = np.random.random(N) * 0.1<br/>theta = np.random.random(N) * 2 * np.pi<br/>x3 = r * np.cos(theta) + 5.8<br/>y3=r * np.sin(theta) + 5</span></pre><p id="e539" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以我们正在创建两个圆形斑点和两个同心圆。</p><p id="1cd7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们快速浏览一下:</p><pre class="nw nx ny nz gt oa ob oc od aw oe bi"><span id="13ed" class="mk ml jj ob b gy of og l oh oi">plt.figure(figsize=(10,10))<br/>plt.scatter(x, y)<br/>plt.scatter(x1, y1)<br/>plt.scatter(x2, y2)<br/>plt.scatter(x3, y3)</span></pre><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/bc3e7ac9b67938578335f005f842a0ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*YbWnt4pk7Xs9Qy8Z_hz_xg.png"/></div></figure><p id="d854" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">还要注意，外圆有相当多的不规则。这可能会给我们带来一些问题(剧透——会的)。</p><p id="8cf9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，让我们将所有这些组合成一个数据集并进行归一化:</p><pre class="nw nx ny nz gt oa ob oc od aw oe bi"><span id="fa56" class="mk ml jj ob b gy of og l oh oi">ttf_circles = pd.DataFrame(<br/>    {<br/>        'x':np.concatenate([x, x1, x2, x3]),<br/>        'y':np.concatenate([y, y1, y2, y3])<br/>    }<br/>)<br/>ttf_norm = ttf_circles.copy()<br/>ttf_norm['x'] = (<br/>    ttf_norm['x'] - np.min(ttf_norm.x)<br/>) / (<br/>    np.max(ttf_norm.x) - np.min(ttf_norm.x)<br/>)<br/>ttf_norm['y'] = (<br/>    ttf_norm['y'] - np.min(ttf_norm.y)<br/>) / (<br/>    np.max(ttf_norm.y) - np.min(ttf_norm.y)<br/>)</span></pre><p id="cfea" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">快速浏览一下:</p><pre class="nw nx ny nz gt oa ob oc od aw oe bi"><span id="72c4" class="mk ml jj ob b gy of og l oh oi">ttf_norm.plot(x='x', y='y', kind='scatter', figsize=(10,10))</span></pre><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/4cefb9b86426058d1bc80bd98a7d63be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*usOfnxG6Ae85w5NNAxRqYQ.png"/></div></figure><p id="1727" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您可以直接看到为什么这会给基于质心的归因带来问题。我们的三个星团的质心在同一个地方！</p><p id="758b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们首先来看看标准的、现成的方法是如何处理这个问题的。</p><pre class="nw nx ny nz gt oa ob oc od aw oe bi"><span id="edbc" class="mk ml jj ob b gy of og l oh oi">import sklearn<br/>from sklearn.cluster import AffinityPropagation, AgglomerativeClustering, Birch<br/>from sklearn.cluster import DBSCAN, KMeans, MiniBatchKMeans, MeanShift<br/>from sklearn.cluster import SpectralClustering<br/>from sklearn.mixture import GaussianMixture</span></pre><ol class=""><li id="9162" class="ni nj jj la b lb lc le lf lh nk ll nl lp nm lt nn no np nq bi translated">亲和力传播</li></ol><pre class="nw nx ny nz gt oa ob oc od aw oe bi"><span id="492b" class="mk ml jj ob b gy of og l oh oi">X = np.array(ttf_norm[['x','y']].values)<br/>model = AffinityPropagation(damping=0.9)</span></pre></div><div class="ab cl om on hx oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="im in io ip iq"><pre class="oa ob oc od aw oe bi"><span id="44ae" class="mk ml jj ob b gy ot ou ov ow ox og l oh oi">%%time<br/>model.fit(X)<br/>ttf_norm['Affinity'] = model.predict(X) + 1</span></pre><p id="7750" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">出局:</p><pre class="nw nx ny nz gt oa ob oc od aw oe bi"><span id="a3a4" class="mk ml jj ob b gy of og l oh oi">CPU times: user 9min 18s, sys: 22.7 s, total: 9min 40s<br/>Wall time: 9min 55s</span></pre><p id="427f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">并绘制结果:</p><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oy"><img src="../Images/be027d7a03553db669ee6fd6ba441d98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7HvmcoR27UE7ZQj_90E0HA.png"/></div></div></figure><p id="ba27" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">哎唷…我的意思是——它很有色彩……但是完全没用。</p><p id="e634" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">#失败！</p><p id="1c6d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其他方法的代码是相同的，所以我只展示结果。</p><p id="6498" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">2.结块的</p><pre class="nw nx ny nz gt oa ob oc od aw oe bi"><span id="7f58" class="mk ml jj ob b gy of og l oh oi">CPU times: user 8.2 s, sys: 804 ms, total: 9 s<br/>Wall time: 9.04 s</span></pre><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oy"><img src="../Images/319e0a4051aff636488b8f7a558c98ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J6ODXk_nGkVKRJ4pZFOYHg.png"/></div></div></figure><p id="7427" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们有正确数量的集群(因为我们告诉它要寻找多少！)，只是不是我们要找的人…</p><p id="2bd5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">#失败！</p><p id="7d2a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">3.桦树</p><pre class="nw nx ny nz gt oa ob oc od aw oe bi"><span id="2501" class="mk ml jj ob b gy of og l oh oi">CPU times: user 827 ms, sys: 50.7 ms, total: 877 ms<br/>Wall time: 752 ms</span></pre><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oy"><img src="../Images/6f70bbdc3c35bc7584d9c9eb7f418daf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zd74tpyx-38DMTI-bkIRXg.png"/></div></div></figure><p id="be4b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">与#2 相同。相同的结论:</p><p id="385f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">#失败！</p><p id="2373" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">4.基于密度的噪声应用空间聚类</p><pre class="nw nx ny nz gt oa ob oc od aw oe bi"><span id="3fbd" class="mk ml jj ob b gy of og l oh oi">CPU times: user 382 ms, sys: 370 ms, total: 752 ms<br/>Wall time: 865 ms</span></pre><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oy"><img src="../Images/e03b5ff8f758da92fa793cfa954e4b40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7U3ibXQGJZkPqC2AEuT8FA.png"/></div></div></figure><p id="dd74" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">的确非常丰富多彩…只是对我们完全没用。</p><p id="de5e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">#失败！</p><p id="70dd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">5.KMeans</p><pre class="nw nx ny nz gt oa ob oc od aw oe bi"><span id="a0f4" class="mk ml jj ob b gy of og l oh oi">CPU times: user 662 ms, sys: 57.3 ms, total: 719 ms<br/>Wall time: 366 ms</span></pre><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oy"><img src="../Images/d4f47f435d0044451199dfa5bb63274b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r0XeITTIiLwM7iKP4RUIJw.png"/></div></div></figure><p id="abec" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">好吧，你明白了。让我们直接跳到高斯混合。这是我希望会比其他的好一点的一个，但是，唉，在 164 毫秒内，它达到了:</p><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oy"><img src="../Images/057fc25ec7fd4654e691e224d94931d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e1uOgiOhqbKfo8ogQ7uwbA.png"/></div></div></figure><p id="d9fc" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">好，那么我们的密度树算法呢？请击鼓…</p><p id="cec8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">计算我们的部门数量:</p><pre class="nw nx ny nz gt oa ob oc od aw oe bi"><span id="5611" class="mk ml jj ob b gy of og l oh oi">D = int(np.sqrt(len(ttf_norm)))<br/>D</span></pre><p id="8b86" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">出局:126</p><p id="c362" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该模型运行时间为 374 毫秒，这已经足够了。然而，我们发现…</p><p id="a888" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">44 簇！</p><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oy"><img src="../Images/f0296fab4997c8de930c7fe40baf0864.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YelNHg1om6cDA_CGMimUzg.png"/></div></div></figure><p id="050b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">#失败！</p><p id="e0c3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">或者是？或者说我们能做点什么吗？</p><p id="7482" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">事实上，如果我们仔细观察，这就是正在发生的事情:我们被问题的规模绊倒了。记得我提到过数据中的条纹会给我们带来一些问题。这就是了。我们正在识别由数据稀疏引起的数据中的不规则性。我们可能已经预料到了，因为我们已经尽我们的临界参数所允许的那样细化了。</p><p id="4b5c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，有没有一种方法可以确定(最好是一种自动化的方法)我们需要进行多少次划分才能得到我们想要的聚类类型。所以对于这样的问题，确定一组参数，让我们得到最细粒度和最小粒度的结果。</p><p id="bd76" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">事实证明——确实有。</p><p id="2a30" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请记住，我们将所有东西都分割成单元，并计算落入每个单元的观察值的数量，以构建我们的聚类。我们可以看看这些划分是多么有效，我们的观察结果是如何被打包到我们的单位细胞中的。所以我们要看的是，有超过 10 个观察值的单胞，与只有一个观察值或根本没有观察值的单胞数量的比率。选择 10 有些武断，用这个数字来看看什么效果最好可能是有意义的，到目前为止，它对我测试的所有问题都足够好了。</p><p id="2102" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们将浏览多个部门，看看该比例如何变化:</p><pre class="nw nx ny nz gt oa ob oc od aw oe bi"><span id="62bc" class="mk ml jj ob b gy of og l oh oi">prop=[]<br/>for d in range(1, 500):<br/>    Xint = (X * d).astype(int)<br/>    unique, counts = np.unique(Xint, axis=0, return_counts=True)<br/>    prop.append(<br/>        len(<br/>            counts[counts &gt; 10]<br/>        )/(<br/>            len(<br/>                counts[counts == 1]<br/>            ) + len(Xint) - len(unique)<br/>        )<br/>    )</span></pre><p id="e3dd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我在这里使用列表来收集结果，我很抱歉。这一点是快速的，但是的，真的应该翻译成 numpy。</p><p id="8667" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们画出这个:</p><pre class="nw nx ny nz gt oa ob oc od aw oe bi"><span id="249d" class="mk ml jj ob b gy of og l oh oi">plt.figure(figsize=(12, 8))<br/>plt.plot(list(range(1, 500)), prop)</span></pre><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oz"><img src="../Images/0c62fa41011688567a5b6648148f3c82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mA2gDr5jYsYHOrm7U5i9Fg.png"/></div></div></figure><p id="3cb7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">啊哈！我们有两个峰值。一个 50 左右，一个 200 左右。确切的数字并不重要，我们想知道大概的数字。</p><p id="16a0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">只是检查一下:</p><pre class="nw nx ny nz gt oa ob oc od aw oe bi"><span id="077a" class="mk ml jj ob b gy of og l oh oi">np.argmax(prop)</span></pre><p id="1db2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">出局:49</p><p id="40db" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">够近了。</p><p id="97c5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这意味着我们有两个最佳区域。如果我们想尽可能地细化并识别我们观察到的所有聚集点，我们会选择 200。如果我们想要一个更广阔的画面，我们用 49。</p><p id="53ae" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然而，这还不完全是结束。我们还想确保我们的宽容也符合我们的意图。对于更广阔的前景，我们希望非常低，否则我们有被过度排斥小数量的单位细胞产生的额外缺口绊倒的风险。对于更详细的前景，我们希望精确，所以我们可能希望使用更高的数字。这部分，暂时来说，还是不够规定性。也许转换到精确计数而不是百分位数会使它更简单。在我的待办事项/实验清单上。</p><p id="df22" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">好的，那么如果我们用 50 个除法和第 10 个百分位数会发生什么？</p><pre class="nw nx ny nz gt oa ob oc od aw oe bi"><span id="50ef" class="mk ml jj ob b gy of og l oh oi">%%time<br/>D = 49<br/>tolerance = 10<br/>ttf_norm['density_trees'] = density_trees_fit_nn(np.array(ttf_norm[['x','y']].values), D, tolerance)</span></pre><p id="305c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">出局:</p><pre class="nw nx ny nz gt oa ob oc od aw oe bi"><span id="d2fb" class="mk ml jj ob b gy of og l oh oi">Processed 100.00% ids<br/>4 clusters found<br/>CPU times: user 76.7 ms, sys: 8.56 ms, total: 85.3 ms<br/>Wall time: 80.7 ms</span></pre><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oy"><img src="../Images/939f6e05cec5821c9e52ac77551f2317.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lW3PPAAKs-iqmFIdVPTMdA.png"/></div></div></figure><p id="4463" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">砰的一声。！！</p><h2 id="4f38" class="mk ml jj bd mm mn mo dn mp mq mr dp ms lh mt mu mv ll mw mx my lp mz na nb nc bi translated">其他器械包的临界分割值</h2><p id="3764" class="pw-post-body-paragraph ky kz jj la b lb nd kk ld le ne kn lg lh nf lj lk ll ng ln lo lp nh lr ls lt im bi translated">看一下不同场景下的临界分割值图是有意义的，这样可以获得更多的直觉。</p><p id="3b88" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，如果我们通过在外环生成更多的数据点来增加外环的密度，会发生什么？理论上，随着我们逐渐填充更多的空间，这应该会使那里的迷你星团不那么明显。</p><p id="71d7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们看看会发生什么:</p><pre class="nw nx ny nz gt oa ob oc od aw oe bi"><span id="46a3" class="mk ml jj ob b gy of og l oh oi">N=4000 #numbner of observations</span><span id="d548" class="mk ml jj ob b gy oj og l oh oi">r = np.random.random(N * 4) * 0.1 + 1<br/>theta = np.random.random(N * 4) * 2 * np.pi<br/>x = r * np.cos(theta) + 5<br/>y = r * np.sin(theta) + 5</span><span id="69d6" class="mk ml jj ob b gy oj og l oh oi">r = np.random.random(N) * 0.1 + 0.5<br/>theta = np.random.random(N) * 2 * np.pi<br/>x1=r * np.cos(theta) + 5<br/>y1 = r * np.sin(theta) + 5</span><span id="ca06" class="mk ml jj ob b gy oj og l oh oi">r = np.random.random(N) * 0.1<br/>theta = np.random.random(N) * 2 * np.pi<br/>x2 = r * np.cos(theta) + 5<br/>y2 = r * np.sin(theta) + 5</span><span id="79eb" class="mk ml jj ob b gy oj og l oh oi">r = np.random.random(N) * 0.1<br/>theta = np.random.random(N) * 2 * np.pi<br/>x3 = r * np.cos(theta) + 5.8<br/>y3=r * np.sin(theta) + 5</span><span id="d73c" class="mk ml jj ob b gy oj og l oh oi">ttf_circles = pd.DataFrame(<br/>    {<br/>        'x':np.concatenate([x, x1, x2, x3]),<br/>        'y':np.concatenate([y, y1, y2, y3])<br/>    }<br/>)</span><span id="7a01" class="mk ml jj ob b gy oj og l oh oi">ttf_norm = ttf_circles.copy()<br/>ttf_norm['x'] = (<br/>    ttf_norm['x'] - np.min(ttf_norm.x)<br/>) / (<br/>    np.max(ttf_norm.x) - np.min(ttf_norm.x)<br/>)<br/>ttf_norm['y'] = (<br/>    ttf_norm['y'] - np.min(ttf_norm.y)<br/>) / (<br/>    np.max(ttf_norm.y) - np.min(ttf_norm.y)<br/>)</span></pre><p id="73c8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">好吧，很多代码。本质上，这与我们开始时所做的是一样的，但是当我们生成第一个圆时，我们将点数乘以 4。所以我们会有 4 倍多的观测值。</p><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/5eba7d74422dbc7c4bdc6ab404ac9942.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*ACFxODgBVuw2VpY040HL_Q.png"/></div></figure><p id="9d73" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你看现在外环光滑多了…</p><p id="cf33" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">临界分裂图变成了:</p><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oz"><img src="../Images/00eb33c4e2a772f94955102283dcf09c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QUxcN499NeIyTJ6ZVpF9Mw.png"/></div></div></figure><p id="d5e2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以峰值现在移到了右边，max 现在是 86。第二个峰值仍然存在，在 200 左右，但不那么明显了。我们添加的观察越多，它就越不明显，最终会完全消失。</p><p id="4d29" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们也来看看我们在上一篇文章中看到的四个 blobs:</p><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/5af67585873f636af658f5005d5d834c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*3Ovj6RyeJghJrNa8How9Xw.png"/></div></figure><p id="da7e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">和临界分裂图:</p><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oz"><img src="../Images/c292536ce20692195a065a0da8e04523.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B2nDBklmxakn347J2bIcLQ.png"/></div></div></figure><p id="4587" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Max 在这里不太明显，实际的绝对最大值是 45，但我们可能可以达到 80。事实上，在文章中我们使用了临界值 63，这显然已经足够好了。</p><p id="c6eb" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后是栅格文件数据集。伦敦市中心的像素化建筑:</p><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pa"><img src="../Images/70cea99b0a37474d861cbd283e18838a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bE5UH6o-ajcaxmlSoUJcIw.png"/></div></div></figure><p id="45aa" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因为我们有 4mln 个点，所以计算这个需要一点时间，但是我们可以增加步长使它更容易，所以我显示的结果是使用步长 10:</p><figure class="nw nx ny nz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pb"><img src="../Images/608b7a4b5abcab8053ef837ce0594c91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7w5m43KpYOcKFnj75fzKvg.png"/></div></div></figure><p id="8e53" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个恰好很好很简单，临界除法参数恰好在 525 左右。我们在文章中使用了 501，这是我凭直觉得出的，而不是根据严格的计算得出的。现在，在我们开始之前，我们有了一个非常简单的方法来确定我们问题的正确粒度。</p><p id="420e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这种方法的好处是——现在我们可以测试数据中的条纹，并在试图找到正确的建模方法之前理解比例和联系。我们可以对任意数量的变量这样做。潜在地，这是非常强大的，可以节省很多时间。</p><p id="b607" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如我所承诺的，我在这里附上所有的主要功能。请随意使用和改进这些。如果你有一个有趣的项目/数据集，你想使用它，并希望我的投入-请让我知道，我不能保证我会接受它，但我会努力。如果你自己在用，请友好地引用这篇文章。谢谢！快乐聚类！</p><figure class="nw nx ny nz gt iv"><div class="bz fp l di"><div class="pc pd l"/></div></figure></div></div>    
</body>
</html>