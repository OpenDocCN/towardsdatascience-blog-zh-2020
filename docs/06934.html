<html>
<head>
<title>Saving Jakarta Flood Data for a Rainy Day</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">保存雅加达洪水数据以备不时之需</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/saving-jakarta-flood-data-for-a-rainy-day-d44695e487d6?source=collection_archive---------85-----------------------#2020-05-28">https://towardsdatascience.com/saving-jakarta-flood-data-for-a-rainy-day-d44695e487d6?source=collection_archive---------85-----------------------#2020-05-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6d3e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">Python 如何帮助清理混乱的数据集，以便对未来的洪水监测进行潜在的改进</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/d07c0df4b07664307fd36cc247d6d77b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CUH2Lz3647oJ9_7s"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/@yakimadesign?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">乔丹·罗兰</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="da58" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">新的一年新的开始。嗯，对雅加达来说不是，它很快将成为印度尼西亚的非首都城市。当我们通常在那天晚上燃放烟花庆祝时，雅加达的人们却在忙着游泳。不过，方式不对。这场洪水破坏了雅加达的庆祝活动，而这几乎是一个传统。到 2020 年 2 月底，已经发生了 6 次。<strong class="ky ir"> <em class="ls">六</em> </strong> <em class="ls">。</em></p><p id="2931" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">关于洪水灾害数据，雅加达政府已经与 petabencana.id 和灾害对策机构(BPBD 雅加达)合作，通过他们的官员或 petabencana.id 平台内的社区来监控洪水事件。最终产品将在一个名为<a class="ae kv" href="https://jakartasatu.jakarta.go.id/portal/apps/webappviewer/index.html?id=ee9940006aae4a268716c11abf64565b" rel="noopener ugc nofollow" target="_blank"> Jakarta Satu </a>的平台上展示。最热门的产品是洪水地图，从 2020 年 1 月 1 日开始。问题是，给出的数据有多好？嗯，我不抱太大希望。我去过那里。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lt"><img src="../Images/e4ac9ca0cb8faefc77bad68eca9906dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AW3Suta7AxY8MStWBC8o-g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">雅加达 Satu 平台，显示 2020 年 1 月 1 日的洪水事件</p></figure><p id="aa90" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">雅加达的洪水数据有点问题。好吧，这里没有糖衣。太可怕了。从平台上看，这张地图显然很漂亮，但在它背后？相反，这是一项有些草率的工作。尽管有一些有价值的信息，但数据管理从一开始就没有真正计划好，尤其是在 1 月 2 日更新之后。</p><p id="1738" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">洪水测绘数据可通过<a class="ae kv" href="https://jakartasatu.jakarta.go.id/server/rest/services" rel="noopener ugc nofollow" target="_blank">中的 REST 服务获得，此处为</a>。此处的目的是将自 1 月 1 日以来发生的许多洪水事件的数据合并，并将其整理成更整洁、更易读的数据。数据管理是使用本笔记本中的 Pandas 和 Geopandas 完成的。</p><h1 id="bcf5" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">1.数据和信息管理</h1><h2 id="b8c9" class="mm lv iq bd lw mn mo dn ma mp mq dp me lf mr ms mg lj mt mu mi ln mv mw mk mx bi translated">初始条件</h2><p id="aac8" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">第一批数据和其他数据明显不一致。原始数据(1 月 1 日)仅关注洪水分类，用数字表示严重程度(1 表示低，5 表示非常高)。与此同时，1 月 3 日和其他日期的数据发生了重大变化，变得更加详细。意图是好的。但是，仍然有许多缺失值和空白列。</p><p id="23cc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">1 月 1 日有史以来第一次洪水列单:</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="c4dc" class="mm lv iq ne b gy ni nj l nk nl">[‘OBJECTID_1’, ‘OBJECTID’, ‘KAB_NAME’, ‘KEC_NAME’, ‘KEL_NAME’, ‘RW’, ‘ID’, ‘KETERANGAN’, ‘GENANGAN’, ‘TINGGI’, ‘FLOOD’, ‘F01012020’, ‘SHAPE.AREA’, ‘SHAPE.LEN’, ‘geometry’]</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lt"><img src="../Images/d83f375dbf69162ccb83ce0a3cc98696.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xdFcf1Qkq8m44E2I4cXDGg.png"/></div></div></figure><p id="ea79" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">次日至最近(1 月 3 日-1 月 7 日)的栏目列表:</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="505c" class="mm lv iq ne b gy ni nj l nk nl">[‘OBJECTID_1’, ‘OBJECTID’, ‘KAB_NAME’, ‘KEC_NAME’, ‘KEL_NAME’, ‘RW’, ‘ID’, ‘KETERANGAN’, ‘GENANGAN’, ‘TINGGI’, ‘FLOOD’, ‘F01012020’, ‘KECAMATAN’, ‘KELURAHAN’, ‘ID_RW’, ‘KEL_DAN_RW’, ‘RW_1’, ‘RT’, ‘JUMLAH_TER’, ‘JUMLAH_T_1’, ‘JUMLAH_T_2’, ‘JUMLAH_T_3’, ‘JUMLAH_T_4’, ‘JUMLAH_T_5’, ‘JUMLAH_PEN’, ‘JUMLAH_P_1’, ‘LOKASI_PEN’, ‘MULAI’, ‘KONDISI_AW’, ‘KETINGGIAN’, ‘KETERANG_1’, ‘WAKTU_SURU’, ‘PENANGANAN’, ‘PENANGAN_1’, ‘PENANGAN_2’, ‘PENANGAN_3’, ‘BANTUAN’, ‘TINGGI_MAX’, ‘Shape__Are’, ‘Shape__Len’, ‘geometry’]</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nm"><img src="../Images/731084d7059e4d13e1d042481fff82a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cCDz6k_2BRGWOx0bc9tMSA.png"/></div></div></figure><h2 id="df73" class="mm lv iq bd lw mn mo dn ma mp mq dp me lf mr ms mg lj mt mu mi ln mv mw mk mx bi translated">提高可读性</h2><p id="bd6a" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">因此，为了整理出 1 月 1 日洪水的全面信息，必须提高可读性。以下是我目前所知道的，并相应地重新命名:</p><p id="87e6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls"> Kab_name to ID 栏</em> : <em class="ls">行政</em> <em class="ls">信息| mulai:洪水监测时间| keterang_1:可能的洪水原因| kondisi_aw:初始条件| f 010102020:1 月 1 日洪水| tinggi:洪水深度| keting gi:洪水严重程度指数|tinggi_max:最大深度</em></p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="61ef" class="mm lv iq ne b gy ni nj l nk nl"># Get the only valuable column for the analysis<br/>flood_period_one = flood_0301_1800[[‘KAB_NAME’, ‘KEC_NAME’, ‘KEL_NAME’, ‘RW’, ‘RT’, ‘ID’, ‘MULAI’, ‘KETERANG_1’, ‘KONDISI_AW’, ‘F01012020’, ‘TINGGI’, ‘KETINGGIAN’, ‘TINGGI_MAX’, ‘geometry’]]</span><span id="efc9" class="mm lv iq ne b gy nn nj l nk nl"># Rename them with proper naming to improve readability<br/>flood_period_one.columns = [‘KAB_NAME’, ‘KEC_NAME’, ‘KEL_NAME’, ‘RW’, ‘RT’, ‘ID’, ‘START_TIME’, ‘CAUSE’, ‘INITIAL_CONDITION’, ‘FLOOD_CLASS_0101’, ‘FLOOD_CLASS_0301_1800’, ‘DEPTH_0301_1800’, ‘MAX_DEPTH_0301_1800’, ‘geometry’]</span></pre><h2 id="6754" class="mm lv iq bd lw mn mo dn ma mp mq dp me lf mr ms mg lj mt mu mi ln mv mw mk mx bi translated">合并数据帧</h2><p id="d2a0" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">后来，洪水泛滥被证明持续到 1 月 7 日左右。为了给出一个更广阔的视角，我将它们结合起来(从 1 月 3 日午夜到 1 月 7 日晚上)来看洪水每天的发展，从最高到最低的状态。将它们组合在一起的关键在于“ID”列。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="06f8" class="mm lv iq ne b gy ni nj l nk nl"># List of data that need to merge<br/>flood_event = [flood_0301_2400, flood_0401_0600, flood_0401_1200, flood_0401_1800, flood_0401_2400,flood_0501_0600, flood_0501_1200, flood_0501_1800, flood_0501_2400,flood_0601_1800, flood_0601_2400,flood_0701_1800]</span><span id="f8d9" class="mm lv iq ne b gy nn nj l nk nl">#Join all the dataframe<br/>from functools import partial, reduce<br/>flood_merge = partial(pd.merge, on=['ID'], how='left')<br/>flood_result = reduce(flood_merge, flood_event)</span></pre><p id="88f2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了简化必要的数据，我将数据整理成关于洪水深度的具体数据。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="a44e" class="mm lv iq ne b gy ni nj l nk nl"># Take the ID before filtering commenced<br/>flood_ID= flood_result[['ID']].copy()</span><span id="4346" class="mm lv iq ne b gy nn nj l nk nl"># Filtering the column list with Regex to ease up the job<br/>flood_nextday = flood_result.filter(like=’TINGGI’,axis=1).copy()</span><span id="63ea" class="mm lv iq ne b gy nn nj l nk nl">#Rename the column list<br/>flood_nextday.columns = [‘FLOOD_CLASS_0301_2400’, ‘DEPTH_0301_2400’, ‘MAX_DEPTH_0301_2400’,‘........', ‘FLOOD_CLASS_0701_1800’, ‘DEPTH_0701_1800’, ‘MAX_DEPTH_0701_1800’]</span><span id="1a5a" class="mm lv iq ne b gy nn nj l nk nl"># Then join them together with concat()<br/>flood_join  = pd.concat([flood_ID, flood_nextday], axis=1).reindex(flood_result.index)</span></pre><p id="4788" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，我们用这个把它们粘在一起。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="a847" class="mm lv iq ne b gy ni nj l nk nl"># Merge from the first our clean dataframe called period_one<br/>flood_1Jan = flood_period_one.merge(flood_join, how=’left’, on=’ID’)</span><span id="920e" class="mm lv iq ne b gy nn nj l nk nl"># Move the geometry to the first column index<br/>flood_1Jan = flood_1Jan[[col for col in flood_1Jan.columns if col != 'geometry' ] + ['geometry']]</span><span id="a180" class="mm lv iq ne b gy nn nj l nk nl">#Show the result<br/>flood_1Jan.sort_values(by='FLOOD_CLASS_0101', ascending=False).head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/0711e9a5ba6efab29886d832440fa8b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_bNvNM98NY7qH7HV8CPLbQ.png"/></div></div></figure><p id="c1e2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是，有许多关于内容和缺失数据的担忧，因此需要采取进一步的行动来实现近乎完美。</p><h2 id="de49" class="mm lv iq bd lw mn mo dn ma mp mq dp me lf mr ms mg lj mt mu mi ln mv mw mk mx bi translated">洪水可能原因</h2><p id="df6f" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">该信息还包括导致该事件的可能因素的原因。尽管有这样的意图，但数据提供得并不好，缺少很多值。这些信息几乎包含了这样的文字，例如:'<strong class="ky ir">Penyebab:Lua pan Kali Krukut</strong>'表示洪水来自 kru Kut 海峡。所以我只打算删除文本‘Penyebab’(cause)，因为它与进一步的处理无关。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="0259" class="mm lv iq ne b gy ni nj l nk nl">flood_1Jan[‘CAUSE’] = flood_1Jan[‘CAUSE’].str[10:]</span></pre><h2 id="9be3" class="mm lv iq bd lw mn mo dn ma mp mq dp me lf mr ms mg lj mt mu mi ln mv mw mk mx bi translated">日期和时间</h2><p id="a2b2" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">洪水监测时间在 START_TIME 列中给出。但是，该列是在字符串列上形成的。我建议这应该是一个日期时间对象。大部分初始数据看起来是这样的。</p><blockquote class="np nq nr"><p id="65a2" class="kw kx ls ky b kz la jr lb lc ld ju le ns lg lh li nt lk ll lm nu lo lp lq lr ij bi translated">拉布，2020 年 1 月 1 日，普库尔 05:00 WIB</p></blockquote><p id="52c2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们需要消除日名(拉布/星期三)、普库尔(时间)和 WIB(当地时间)</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="8595" class="mm lv iq ne b gy ni nj l nk nl">#Split between the comma and whitespace<br/>date_split = flood_1Jan[‘START_TIME’].str.split(‘, ‘ , expand = True)</span><span id="bee1" class="mm lv iq ne b gy nn nj l nk nl">#Get the index 1 column which consist of date (1 Januari 2020) and map in dictionary.<br/>date_split[1] = date_split[1].map({’01 Januari 2020': ‘01–01–2020’, ’02 Januari 2020': ‘02–01–2020’})<br/>date = date_split[1]</span><span id="c21b" class="mm lv iq ne b gy nn nj l nk nl">#Assign the time data from index 2 of data split and split again then replace the '.' with ':' <br/>time = date_split[2].str.split(‘ ‘ , expand = True)<br/>time = time[1].str.replace(‘.’, ‘:’)</span></pre><p id="c18b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，用<strong class="ky ir">转换成 DateTime 对象。strptime </strong></p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="a7c9" class="mm lv iq ne b gy ni nj l nk nl">from datetime import datetime<br/>date_time = date + ‘, ‘+ time<br/>date_time = date_time.astype(str)<br/>flood_1Jan[‘START_TIME’].update(date_time)<br/>flood_1Jan[‘START_TIME’] = flood_1Jan[‘START_TIME’].apply(lambda x: datetime.strptime(x,’%d-%m-%Y, %H:%M’ if x != ‘nan’ else x))</span></pre><h1 id="7aad" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">2.错误的管理数据</h1><p id="5064" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">使用的管理数据是不同的。1 月份的洪水数据使用的是 2013 年数据的底图，而 2 月份的数据使用的是 2019 年的最新数据。这是相当独特的，因为这是一个提供准确性的问题。2013 年的数据在某些时候很麻烦。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="3478" class="mm lv iq ne b gy ni nj l nk nl">ax = boundaries_january.plot(figsize=(15,15), facecolor=’none’, edgecolor=’red’)<br/>boundaries_february.plot(ax=ax, facecolor=’none’, edgecolor=’black’)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/a5cede697e1cfaffc1b0d77fbf3e686a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UXqAY4VAyae0QUCUbtTocA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">基于 2013 年(红色)和 2019 年(黑色)的行政空间数据使用不当</p></figure><p id="d9f2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">是的，他们对自己的产品感到困惑。是的，还在学习… </p><p id="eda2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，为了解决这个问题，我需要在这两个数据之间匹配相似的数字。我最大的猜测是 ID 栏。但不幸的是，事实并非如此。ID 已经完全用不同的编码改变了。所以，目前，我只是让它保持原样。也许在本文的下一部分。</p><h1 id="cef4" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">3.空白和缺失数据</h1><p id="434e" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">有一些关于不同位置的深度范围的信息。虽然我认为这可能会造成一些混乱和无用的由于广泛的差距范围。例如，<em class="ls">10–150cm</em>在这种情况下没有发现帮助。但是在某些情况下可能会有帮助，所以我决定稍微整理一下数据。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="d92e" class="mm lv iq ne b gy ni nj l nk nl"># The flood depth range located on column started with 'DEPTH_' so just use filter</span><span id="b3ab" class="mm lv iq ne b gy nn nj l nk nl">depth = list(flood_1Jan.filter(regex=’^DEPTH’,axis=1))<br/>depth.append('INITIAL_CONDITION')</span><span id="6136" class="mm lv iq ne b gy nn nj l nk nl">#Replace certain text to maintain similarity between the data</span><span id="90d8" class="mm lv iq ne b gy nn nj l nk nl">for depth_range in depth:<br/>flood_1Jan[depth_range] = flood_1Jan[depth_range].str.replace(‘ cm’, ‘’)<br/>flood_1Jan[depth_range] = flood_1Jan[depth_range].str.replace(‘s.d’, ‘s/d’)<br/>flood_1Jan[depth_range] = flood_1Jan[depth_range].str.replace(‘s/d’, ‘-’)</span></pre><p id="fbf2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，flood 类列需要转换为数字，并将零值替换为 NaN。稍后，它将对时间序列分析有用。相信我。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="a539" class="mm lv iq ne b gy ni nj l nk nl">flood_class = list(flood_1Jan.filter(regex=’^FLOOD’,axis=1))</span><span id="faf3" class="mm lv iq ne b gy nn nj l nk nl">for floods in flood_class:<br/>flood_1Jan[floods] = pd.to_numeric(flood_1Jan[floods])<br/>flood_1Jan[floods] = flood_1Jan[floods].replace(0, np.nan)</span></pre><p id="dce2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，除 1 月 1 日洪水数据(F0101)外，其他数据没有最大深度值，仅给出了洪水等级。在我们之前的行动之后，洪水的深度范围大部分应该是这样的:<strong class="ky ir">‘10–150’。</strong>因此，我利用数据的长度捕捉到了最大值。这是因为有些数据的数量是固定的。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="7729" class="mm lv iq ne b gy ni nj l nk nl"># Get the maximum depth of 1st January flood and convert to numeric<br/>add_max_depth_0101 = flood_1Jan[‘INITIAL_CONDITION’].apply(lambda x: x.split(‘-’)[-1] if len(x) &gt; 3 else x)<br/>flood_1Jan[‘MAX_DEPTH_0101’] = pd.to_numeric(flood_1Jan[‘MAX_DEPTH_0101’])</span><span id="460f" class="mm lv iq ne b gy nn nj l nk nl"># Change column position<br/>flood_1Jan.insert(10, ‘MAX_DEPTH_0101’, add_max_depth_0101)</span></pre><p id="17cd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，我用 1 月 1 日数据中使用的大部分类别范围来映射字典。这是根据一个已经填写好的值做出的假设。但是，它考虑许多方面来提供一条尽可能准确的信息。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="70a7" class="mm lv iq ne b gy ni nj l nk nl">class_dict = {5: 200, 4: 150, 3: 80, 2: 40, 1: 20}</span><span id="7013" class="mm lv iq ne b gy nn nj l nk nl">flood_1Jan[‘MAX_DEPTH_0101’] = flood_1Jan[‘MAX_DEPTH_0101’].fillna(flood_1Jan[‘FLOOD_CLASS_0101’])</span><span id="7f08" class="mm lv iq ne b gy nn nj l nk nl">flood_1Jan[‘MAX_DEPTH_0101’] = flood_1Jan[‘MAX_DEPTH_0101’].map(class_dict).fillna(flood_1Jan[‘MAX_DEPTH_0101’])</span></pre><h1 id="7101" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">4.错误的分类</h1><p id="c957" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">所使用的分类不时会有所不同。例如，在同一个地方，洪水深度为 150 厘米。然而，从 1 月 1 日起使用的分类是 4 级，而 1 月 3 日的数据显示是 5 级。这里发生了一些不一致。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/80486a29693147e74e68dfe5d2ecacff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VmNv9JUnnb2ksCVSJ_joeQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">洪水事件之间不一致的分类</p></figure><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="a33a" class="mm lv iq ne b gy ni nj l nk nl">flood_1Jan[‘MAX_DEPTH_0101’] = flood_1Jan[‘MAX_DEPTH_0101’].fillna(flood_1Jan[‘FLOOD_CLASS_0101’])</span><span id="4824" class="mm lv iq ne b gy nn nj l nk nl">flood_1Jan[‘MAX_DEPTH_0101’] = flood_1Jan[‘MAX_DEPTH_0101’].map(class_dict).fillna(flood_1Jan[‘MAX_DEPTH_0101’])</span></pre><p id="bee5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">根据 2020 年 1 月 3 日及其他日期的数据分类，最好遵循这种方法。分类是这样的:</p><blockquote class="nx"><p id="4d3a" class="ny nz iq bd oa ob oc od oe of og lr dk translated">11-30 厘米的 1 级&lt;10 cm<br/>2 级<br/>31-70 厘米的 3 级<br/>71-150 厘米的 4 级<br/>150 厘米的 5 级&gt;</p></blockquote><p id="3ce8" class="pw-post-body-paragraph kw kx iq ky b kz oh jr lb lc oi ju le lf oj lh li lj ok ll lm ln ol lp lq lr ij bi translated">为了从数据中重新分类所有的洪水分类，我做了这个魔术。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="06e4" class="mm lv iq ne b gy ni nj l nk nl">verify_flood = [<br/>(flood_1Jan[‘MAX_DEPTH_0101’] &gt;= 150),<br/>(flood_1Jan[‘MAX_DEPTH_0101’] &lt; 150) &amp; (flood_1Jan[‘MAX_DEPTH_0101’] &gt;= 80),<br/>(flood_1Jan[‘MAX_DEPTH_0101’] &lt; 80) &amp; (flood_1Jan[‘MAX_DEPTH_0101’] &gt;= 40),<br/>flood_1Jan[‘MAX_DEPTH_0101’] &lt; 40) &amp; (flood_1Jan[‘MAX_DEPTH_0101’] &gt;= 20),<br/>(flood_1Jan[‘MAX_DEPTH_0101’] &lt; 20),<br/>]</span><span id="39af" class="mm lv iq ne b gy nn nj l nk nl">classifications = [5,4,3,2,1]</span><span id="a880" class="mm lv iq ne b gy nn nj l nk nl">flood_1Jan[‘FLOOD_CLASS_0101’] = np.select(verify_flood, classifications, default=np.nan)</span></pre><p id="c38e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">问题解决了。数据现在可以交付了。</p><h1 id="be77" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">结论</h1><p id="1314" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">大多数政府数据在数据准备和管理方面都很糟糕，没有未来的考虑。我知道在这些数据中可以利用很多东西，如果这些数据能够以良好的方式得到充分的处理，这些东西可能会在以后被证明是有益的。这就是我这么做的原因。</p><p id="e009" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你知道吗，这个工作最终会有回报的。这只是第一次互动。这是接下来将要发生的剧透。这是雅加达洪水分析和可视化的下一步。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi om"><img src="../Images/1da47b26fb26e71dd438ba30b361ef7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*-jGPvqmcCS7qIYjW7Sntkw.gif"/></div></div></figure></div></div>    
</body>
</html>