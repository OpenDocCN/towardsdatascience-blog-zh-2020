<html>
<head>
<title>Address class imbalance easily with Pytorch Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Pytorch 第 2 部分轻松解决班级失衡问题</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/address-class-imbalance-easily-with-pytorch-bb540497d2a6?source=collection_archive---------23-----------------------#2020-05-11">https://towardsdatascience.com/address-class-imbalance-easily-with-pytorch-bb540497d2a6?source=collection_archive---------23-----------------------#2020-05-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/6fa3ee2c6b63debc87ba751ac130288e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pW84zlcvFTFfx18BdvbqNA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">使用 Pytorch 对同一棵向日葵进行过采样？图片来源于<a class="ae jd" href="https://www.flickr.com/photos/jerseyjj/21039413358/" rel="noopener ugc nofollow" target="_blank">杰弗里·约翰逊</a>。</p></figure><div class=""/><p id="ea0c" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">了解 Pytorch 的<em class="lb">称重随机取样器</em></p><p id="c948" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi lc translated"><span class="l ld le lf bm lg lh li lj lk di">在</span>之前的<a class="ae jd" rel="noopener" target="_blank" href="/address-class-imbalance-easily-with-pytorch-e2d4fa208627?source=your_stories_page---------------------------">文章</a>中，我们看到了如何通过<em class="lb">加权随机采样器</em>进行过采样来解决类不平衡问题。实际上，这降低了过度拟合的风险。在本文中，<strong class="kf jh">我们将展示<em class="lb"> WeightedRandomSampler </em>是如何实现的，并给用户一些直觉。</strong>我们首先给出一个应用简单统计的例子，然后我们从数学上处理一个更一般的场景。我们的目标是理解我们如何从每个类中得到相同数量的观察结果，即使它们是不平衡的。</p><p id="a223" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">没有比不明白我们用什么更糟糕的了，对吗？🤗</p><blockquote class="ll lm ln"><p id="2c9e" class="kd ke lb kf b kg kh ki kj kk kl km kn lo kp kq kr lp kt ku kv lq kx ky kz la ij bi translated"><strong class="kf jh">注</strong>。如果你喜欢这篇文章，一定要关注我。很多人喜欢我的文章，请关注我以示支持，这真的很有帮助！🤗</p></blockquote><figure class="ls lt lu lv gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lr"><img src="../Images/10f6c0a6ff6c79277f713af7983e9c62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7Fn-StCbimSzUfYsH236RQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">我们数据集的 10 个批次中的类分布。红色表示辅修课，蓝色表示主修课。我们使用 WeightedRandomSampler 从左边不平衡的数据集到右边更平衡的数据集。</p></figure><p id="d9e3" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在让我们看看 Pytorch 中实现的<em class="lb"> WeightedRandomSampler </em>的源代码。我们将学习一些理论来理解代码，然后看一个简单的例子来很好地理解实现。</p><p id="d1e3" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Pytorch 的<a class="ae jd" href="https://pytorch.org/docs/stable/_modules/torch/utils/data/sampler.html#WeightedRandomSampler" rel="noopener ugc nofollow" target="_blank">源代码</a>中，关键函数如下:</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/bc54f2204ee4f83eeb631b666ceba3bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:902/format:webp/1*kZN1_FDsyLNX0rg1bFe-Wg.png"/></div></figure><figure class="ls lt lu lv gt is gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/5b78077cd605a626de4f0173a35e37de.png" data-original-src="https://miro.medium.com/v2/resize:fit:902/format:webp/1*yx5b3m-pwFcvvLNOAGEo8w.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">在 WeightedRandomSampler 类中，关键函数是 call <strong class="bd lx"> __iter__ </strong>。</p></figure><blockquote class="ll lm ln"><p id="1c6d" class="kd ke lb kf b kg kh ki kj kk kl km kn lo kp kq kr lp kt ku kv lq kx ky kz la ij bi translated"><strong class="kf jh">一个关键思路:</strong>从有控制参数的多项式分布中提取。</p></blockquote><p id="c8bb" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Pytorch 使用具有给定参数的多项式分布，即<strong class="kf jh">权重</strong>、样本数量 s 的<strong class="kf jh">以及我们是否使用<strong class="kf jh">替换</strong>进行采样。</strong></p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/0918cfd5f225f8eb45891e95bc3f4938.png" data-original-src="https://miro.medium.com/v2/resize:fit:902/format:webp/1*BS3wm6ZwlEgB7Of1_zNLdA.png"/></div></figure><p id="e787" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Pytorch 引入的关键思想是从点集的多项式分布中提取。每个点被赋予一个给定的采样概率。这种概率由其具有给定权重参数的类来定义。</p><h2 id="560c" class="ly lz jg bd ma mb mc dn md me mf dp mg ko mh mi mj ks mk ml mm kw mn mo mp mq bi translated">一个简单的例子:</h2><p id="0271" class="pw-post-body-paragraph kd ke jg kf b kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">让我们假设我们的数据点按如下方式排序:</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/4b07c330a07fa96c5d597925c06c9b43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*o7p5JSNfsa7nO4AMfdNM1g.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">左边是 100 个观察值，中间是它们的类别分布，右边是 WeightedRandomSampler 分配的权重参数。蓝色代表大类，红色代表小类。</p></figure><p id="4a44" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以控制权重，以便给予次要类别更多权重:</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/1d67fb6808e45d6da1114172a4ae4fbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:328/format:webp/1*oFfwnBsd3t2VGuCsryzakQ.png"/></div></figure><p id="f762" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，我们绘制一个带有受控参数的多项式分布。每个参数定义了一个给定观察值的绘制概率。事实上，我们是从一组观察值的多项式分布中得出的。</p><p id="8a9c" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里，我们将权重参数设置如下:</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div class="gh gi my"><img src="../Images/11bffe1d8884c7327a6c0ed7fe701435.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*k22iU_8fwgZhvc7FFLmbvg.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">将 WeightedRandomSampler 中的权重设置为每个类别分布的经验先验的倒数。</p></figure><p id="fb8a" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">概率可以通过使用类似于<strong class="kf jh"> softmax </strong>函数的简单标准化权重向量来找到。例如，可以执行以下操作:</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/04da6893899475a14ef705a8b0c912f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*-MJlWtgE15XMdNJXE2XsKg.png"/></div></figure><blockquote class="ll lm ln"><p id="d06c" class="kd ke lb kf b kg kh ki kj kk kl km kn lo kp kq kr lp kt ku kv lq kx ky kz la ij bi translated"><strong class="kf jh">重要提示</strong>:我们需要对 N 个观测值进行归一化处理。目标是得到一个元素之和等于 1 的向量。这不是通过权重向量实现的，因此标准化是必要的。</p></blockquote><figure class="ls lt lu lv gt is gh gi paragraph-image"><div class="gh gi na"><img src="../Images/eafe3a2a66050f24580e73fa8d5c9e70.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*SvIbze4uiNmBGAPKDefIPg.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">从权重向量(左边)到概率向量(右边)。蓝色代表大类，红色代表小类。</p></figure><p id="8428" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们能否从数学上展示，在抽取 100 个随机样本后，我们如何从 c0 中抽取 50 个观察值，从 c1 中抽取 50 个观察值？</p><p id="69e7" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">设一个随机变量描述 c1 中采样 m 个点后的观测数，这里设为 100。</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nb"><img src="../Images/8c1ac44abf0ac3ea1e002e3e5620cc1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WqbDzCWHsRZgrBqe4_GwIQ.png"/></div></div></figure><p id="c4f7" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nc"><img src="../Images/c95eccb4e18ca3101f6692ce3dd908db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cXQVwxZiqeDjGc0sqLvnWg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">利用期望的线性度，我们可以在小类 c1 的点集上得到一个线性方程。</p></figure><p id="3c32" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们知道，从一个多项分布中，<strong class="kf jh">在采样 m 次</strong>后，我们可以将期望值表示如下:</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/b92eb85f5935ed7751212a09c9e8443f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*DBdV-UiuCPsXnFqPyOgeAQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">采样一个点 xi 有一个由多项式分布<strong class="bd lx">多项式</strong>(【x1，...，x90，x91，..，x100]，[p0，…，p0，p1，..p1])。</p></figure><p id="8956" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于位置[91，100]中的所有观察值，我们说它们属于 c1 类:</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ne"><img src="../Images/cd496b680831e7f29686079a1f010b2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*biHCqRIkTqccxVyf6HiUcQ.png"/></div></div></figure><p id="4ca0" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">结果，从辅修课 c1 中抽取的<strong class="kf jh">期望点数(最初包含 10 个点)现在是 50 个</strong>。类似地，主要类别 c0 的预期观测值数量如下:</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nf"><img src="../Images/7b9eafb4a9a9fca7cf696e4d148566c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xU3rXUonhTdCN5EUkYb9FA.png"/></div></div></figure><p id="f1a7" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从类别 c1 中提取的<strong class="kf jh">预期观察值数量也在 50 左右。</strong></p><h2 id="8052" class="ly lz jg bd ma mb mc dn md me mf dp mg ko mh mi mj ks mk ml mm kw mn mo mp mq bi translated"><strong class="ak">更严谨，更通用:</strong></h2><p id="26ec" class="pw-post-body-paragraph kd ke jg kf b kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">在这一节中，我们试图更加概括。然而，为了简单起见，我们假设我们处理的二元问题只有两个类 c0 和 c1。</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/078c0c71f54f097ee3fc280df4fdda2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/1*aTYLS-lkqiFkiN7ge7bY7Q.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">蓝色代表大类，红色代表小类。</p></figure><p id="0942" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在有 N 个观察值，使得:</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/51051859aef83cf794fcb6fa69e32632.png" data-original-src="https://miro.medium.com/v2/resize:fit:408/format:webp/1*XBI8Z2El5h8T10vlEskJ-w.png"/></div></figure><p id="4007" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们需要像前面的例子一样建立概率。这次，我们有:</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/ea05da4195014f008668ccdcfb3f70d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:548/format:webp/1*q013-NUZOmrVJl2Dk8ah5A.png"/></div></figure><p id="6cb2" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们要<strong class="kf jh">生成从整组点 X 上的多项式分布中采样的 m 个点</strong>:<strong class="kf jh">多项式</strong> (X，[p0...，p0，p1，..p1])。</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/5d913ef2c3c77ad2fa79eb1886c691df.png" data-original-src="https://miro.medium.com/v2/resize:fit:568/format:webp/1*W3M-NbCtaNQg_9cNgBPknw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">我们从数据 x 中生成 m 个样本。</p></figure><p id="cf4d" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们定义一个随机变量来描述一个点是否来自类 c0:</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/0360232add2d53d12d42fbd7b1155ea9.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*WPqSdaaOV6jxzGIKZ5T0Gw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">描述抽样观测值是否属于 C0 类的随机变量。</p></figure><p id="fbf8" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，我们可以很容易地表达这样的随机变量的期望值:</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nl"><img src="../Images/eec6c3b74461e58f822922af06933541.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*3pOVt9qR6dIUiBTxqTbWRQ.png"/></div></div></figure><p id="cf27" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在让我们描述随机变量，它给出了从 c0 类中采样的点的总数:</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nh"><img src="../Images/8c9e08aee26199e0ada299615d4e8ff7.png" data-original-src="https://miro.medium.com/v2/resize:fit:408/format:webp/1*6go1Hxnf4-6WsLUsR7XZ1g.png"/></div></div></figure><p id="ae4d" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，我们可以计算 m 次后从类 c0 采样的元素的预期数量:</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nm"><img src="../Images/6a696f05ee473bf6d39480d0801868c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*USh6iegXvf0xsb8qQjzFYQ.png"/></div></div></figure><p id="ceb2" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们之前已经了解了如何在<em class="lb">加权随机采样器</em>中设置权重:</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/9801c7b43bac7d314c146c62565c9ca2.png" data-original-src="https://miro.medium.com/v2/resize:fit:396/format:webp/1*MS16I17D5iPT1IRoMqGjGw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">将 WeightedRandomSampler 中的权重设置为每个类别分布的经验先验的倒数。</p></figure><p id="ea83" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们可以有一个更简单的表达式来表示在 m 次之后从类 c0 <strong class="kf jh">中采样的元素的预期数量:</strong></p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div class="gh gi no"><img src="../Images/3c79c3f5175529c5d1644e3d42fc8327.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*meGm5oG3PzIqLuiUL4Fc4w.png"/></div></figure><p id="2282" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这意味着我们期望正好一半的采样观察值来自 minor 类。我们从数学上解决了类别不平衡问题，证明了我们可以从次要类别中采样与主要类别完全相同数量的观察值。</p><h2 id="8a9b" class="ly lz jg bd ma mb mc dn md me mf dp mg ko mh mi mj ks mk ml mm kw mn mo mp mq bi translated">贝叶斯理论的进一步发展:</h2><p id="9216" class="pw-post-body-paragraph kd ke jg kf b kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">给每个类增加权重相当于<a class="ae jd" href="https://en.wikipedia.org/wiki/Bayes%27_theorem" rel="noopener ugc nofollow" target="_blank">贝叶斯</a>方法。我们调整了优先等级，给了次要等级更多的权重。这种等价性通过以下关系式得到强调:</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi np"><img src="../Images/2b76cd3d3dbce9ef9b57a7e236d33cd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nMviIoHw6dJHczGKh4AbTA.png"/></div></div></figure><p id="0961" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">事实上，我们可以将我们的抽样方法建立在贝叶斯理论的基础上，我们引入了一个叫做先验的新元素。该过程是顺序采样:</p><ul class=""><li id="d0d4" class="nq nr jg kf b kg kh kk kl ko ns ks nt kw nu la nv nw nx ny bi translated"><strong class="kf jh">第一步</strong>:抛一枚概率为 p(c0)的非公平硬币，得到小类 c0，概率为 p(c1)得到大类 c1。</li><li id="b2e5" class="nq nr jg kf b kg nz kk oa ko ob ks oc kw od la nv nw nx ny bi translated"><strong class="kf jh">第 2 步:</strong>从上一步中抽取的类中，对一个观察值进行统一采样:</li></ul><figure class="ls lt lu lv gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oe"><img src="../Images/bedceaf032075ba0a5ddbcf1190cd207.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OhrLd4FUTwM_HnGAdB176Q.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">顺序抽样的第二步，我们从第一步确定的固定先验类别中抽取一个点。</p></figure><h2 id="83fa" class="ly lz jg bd ma mb mc dn md me mf dp mg ko mh mi mj ks mk ml mm kw mn mo mp mq bi translated">结论</h2><p id="8271" class="pw-post-body-paragraph kd ke jg kf b kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">总之，通过使用带有多项式分布的<em class="lb">加权随机抽样器</em>,我们期望从每一类中得到相同数量的观察值。</p><p id="0cb3" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">关键思想在于在一组观察值上构建多项式分布，其中每个观察值表现为其自己的类，具有受控的被抽取概率。</p><h2 id="cf0f" class="ly lz jg bd ma mb mc dn md me mf dp mg ko mh mi mj ks mk ml mm kw mn mo mp mq bi translated">贡献者:</h2><figure class="ls lt lu lv gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi of"><img src="../Images/6f2d7fac6e9bebd13824efcc2f886bf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:472/format:webp/1*_PxYGjy-XXO0Qin6VA7s3w.png"/></div></div></figure><p id="77f0" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae jd" href="https://www.linkedin.com/in/souhail-asmi-2a24b6118/" rel="noopener ugc nofollow" target="_blank">索海尔</a>。洛桑联邦理工学院应用数学专业硕士研究生。</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div class="gh gi og"><img src="../Images/625763ea7c9e00e9d10eab744841d7fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/format:webp/1*Yxr1i2rJN0v3HEP4hC7MOA.jpeg"/></div></figure><p id="6c3c" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae jd" href="https://www.linkedin.com/in/mastafa-foufa-666a1a109/" rel="noopener ugc nofollow" target="_blank">马斯塔法</a>。之前是微软的数据科学家实习生和瑞典皇家理工学院的机器学习学生。</p></div></div>    
</body>
</html>