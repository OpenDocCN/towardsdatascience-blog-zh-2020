<html>
<head>
<title>A Brief Tour of Scikit-learn (Sklearn)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Scikit-learn (Sklearn)简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-brief-tour-of-scikit-learn-sklearn-6e829a9db2fd?source=collection_archive---------23-----------------------#2020-01-28">https://towardsdatascience.com/a-brief-tour-of-scikit-learn-sklearn-6e829a9db2fd?source=collection_archive---------23-----------------------#2020-01-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d16c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Sklearn 简介</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/5f9603ee6a2a44fbcc78936acd4e0774.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W-JDUtlTmCGJaK5l4OF51A.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://www.pexels.com/@quang-nguyen-vinh-222549" rel="noopener ugc nofollow" target="_blank">阮光</a>在<a class="ae ky" href="https://www.pexels.com/photo/people-riding-a-boat-2161449/" rel="noopener ugc nofollow" target="_blank">拍摄</a></p></figure><p id="1958" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于机器学习来说，Python 和 R 是当今应用最广泛的编程语言。Scikit-learn 是一个 python 库，它提供了数据读取、数据准备、回归、分类、无监督聚类等方法。在本帖中，我们将回顾一些构建回归模型的基本方法。该软件包的文档内容丰富，是每位数据科学家的绝佳资源。你可以在这里找到文档<a class="ae ky" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="44a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们开始吧！</p><p id="f687" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">数据准备</strong></p><p id="4d1f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于我们的回归问题，我们将使用天气数据，这些数据可以在<a class="ae ky" href="https://www.kaggle.com/rtatman/datasets-for-regression-analysis" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="2743" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，让我们导入数据并打印前五行:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="83c8" class="ma mb it lw b gy mc md l me mf">import pandas as pd <br/>df = pd.read_csv("weatherHistory.csv")<br/>print(df.head())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/0f103b9b65f64d8b5f640fa332e2df62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*UyVD08MK7wx_NhcZJYYRIA.png"/></div></figure><p id="057d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，让我们将日期列转换成熊猫日期时间对象，并创建年、月和日列:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="75a2" class="ma mb it lw b gy mc md l me mf">df['Formatted Date'] = pd.to_datetime(df['Formatted Date'],  utc=True,)<br/>df['year'] = df['Formatted Date'].dt.year<br/>df['month'] = df['Formatted Date'].dt.month<br/>df['day'] = df['Formatted Date'].dt.day</span></pre><p id="d7d3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们再次打印前五行，以验证新列的创建:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="0ebf" class="ma mb it lw b gy mc md l me mf">print(df.head())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/d0af4efd24317c7144dca760c67c5c97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/1*ftlXmMMXOfOjZqovyqkpbA.png"/></div></figure><p id="c678" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们定义我们的输入和目标变量。我们将使用湿度、年、月、日、压力、能见度和风向来预测温度:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="9089" class="ma mb it lw b gy mc md l me mf">import numpy as np<br/>X = np.array(df[[ 'Humidity', 'year', 'month', 'day', 'Pressure (millibars)', 'Visibility (km)', 'Wind Bearing (degrees)']])<br/>y = np.array(df['Temperature (C)'])</span></pre><p id="f350" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们将分割数据用于训练和测试:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="d340" class="ma mb it lw b gy mc md l me mf">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)</span></pre><p id="71f9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们所有必要的变量都定义好了。让我们建立一些模型！</p><p id="dc24" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">线性回归</strong></p><p id="a7ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">先说线性回归。线性回归拟合带有系数的线性函数，使得目标和预测之间的残差平方和最小。</p><p id="15dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们导入线性回归包如下:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="dbb6" class="ma mb it lw b gy mc md l me mf">from sklearn.linear_model import LinearRegression</span></pre><p id="04c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们用来评估模型性能的误差指标是均方误差(MSE)。MSE 由以下等式定义:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/3ae63d7234e6ab5adb6ad918805b0984.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/1*D-7K2fUG8Ev3iA_81svXjw.gif"/></div></figure><p id="c034" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，y 是实际值，y-波形符是预测值。</p><p id="c389" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们定义一个线性回归对象，拟合我们的模型，并评估性能:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="028f" class="ma mb it lw b gy mc md l me mf">reg = LinearRegression()<br/>reg.fit(X_train, y_train)<br/>y_pred = reg.predict(X_test)</span><span id="961e" class="ma mb it lw b gy mj md l me mf">from sklearn import metrics<br/>print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mk"><img src="../Images/bdccfc7a1b288e884fe6c319d6d6520c.png" data-original-src="https://miro.medium.com/v2/resize:fit:546/format:webp/1*g32_gW-7h2ZCvxoJ8K1JRw.png"/></div></div></figure><p id="88a8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">表演不是很好。这仅仅意味着输入和目标之间的关系不是线性的。此外，探索性数据分析(EDA)可以进一步通知智能特征选择和工程，这可以提高性能。</p><p id="e250" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">随机森林</strong></p><p id="63f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们来看看随机森林。随机森林是一种基于树的方法，它集成了多个单独的决策树。</p><p id="215a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们导入 RandomForestRegressor 包，如下所示:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="6385" class="ma mb it lw b gy mc md l me mf">from sklearn.ensemble import RandomForestRegressor</span></pre><p id="f482" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们定义一个随机森林回归对象，拟合我们的模型，并评估性能:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="9c83" class="ma mb it lw b gy mc md l me mf">reg_rf = RandomForestRegressor()<br/>reg_rf.fit(X_train, y_train)<br/>y_pred = reg_rf.predict(X_test)</span><span id="daa2" class="ma mb it lw b gy mj md l me mf">from sklearn import metrics<br/>print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/fdb0abac25832bd6da4868e7725e4711.png" data-original-src="https://miro.medium.com/v2/resize:fit:548/format:webp/1*lcI-p8A_1dGvixRSkbue4Q.png"/></div></figure><p id="c2e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到随机森林的性能比线性回归好得多。</p><p id="46bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还可以打印特征重要性。这使我们能够了解哪些变量对温度预测最为重要:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="015a" class="ma mb it lw b gy mc md l me mf">feature_df = pd.DataFrame({'Importance':reg_rf.feature_importances_, 'Features': [ 'Humidity', 'year', 'month', 'day', 'Pressure (millibars)', 'Visibility (km)', 'Wind Bearing (degrees)'] })<br/>print(feature_df)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/250d7e78967b40aa54348105c405c4de.png" data-original-src="https://miro.medium.com/v2/resize:fit:546/format:webp/1*dxeNbwh7yC7qzNSuCDw6RA.png"/></div></figure><p id="44d1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到月份具有最高的重要性，这是有道理的。</p><p id="d8ee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我想指出的是，通过不传递任何参数，比如 max_depth 和 n_estimators，我选择了默认的随机森林值(n_estimators = 10 和 max_depth = 10)。我们可以通过优化随机森林中的参数来进一步提高性能。这可以手动完成，也可以使用网格搜索技术自动完成。我将把参数优化的问题留给另一篇文章。</p><p id="b8de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">支持向量机</strong></p><p id="4472" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我要讨论的下一个方法叫做支持向量回归。这是支持向量机(SVM)的扩展。支持向量机在高维特征空间中构造一组超平面，可用于回归和分类问题。</p><p id="dd56" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们导入 SVR 包，如下所示:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="30fd" class="ma mb it lw b gy mc md l me mf">from sklearn.svm import SVR</span></pre><p id="2e96" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于 SVR 的训练速度很慢，我将只选择前 100 条记录进行训练和测试。请随意在完整的数据集上进行训练和测试，以便更好地比较不同型号之间的性能。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="62e6" class="ma mb it lw b gy mc md l me mf">df = df.head(100)</span></pre><p id="cc67" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们定义一个支持向量回归对象，拟合我们的模型，并评估性能:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="29e2" class="ma mb it lw b gy mc md l me mf">reg_svr = SVR()<br/>reg_svr.fit(X_train, y_train)<br/>y_pred = reg_svr.predict(X_test)</span><span id="4db7" class="ma mb it lw b gy mj md l me mf">from sklearn import metrics<br/>print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mm"><img src="../Images/8fc2aeb1a442b75492aedde1fdfe7a79.png" data-original-src="https://miro.medium.com/v2/resize:fit:558/format:webp/1*4V-kqhVzZj7_KfVsyC2izg.png"/></div></div></figure><p id="f7e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们看到支持向量回归比线性回归表现更好，但比随机森林差。同样，这种比较并不完全合适，因为我们没有使用完整的数据集进行训练。</p><p id="9ca5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">类似于随机森林示例，可以优化支持向量机参数，使得误差最小化。</p><p id="d0eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"><em class="mn">K</em>-最近邻居</strong></p><p id="9e00" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我将讨论的最后一种方法是<em class="mn"> k- </em>最近邻回归法。k-最近邻使用欧几里德距离计算，其中预测是 k<em class="mn">最近邻的平均值。</em></p><p id="f2d5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们导入 KNeighborsRegressor 包，如下所示:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="483e" class="ma mb it lw b gy mc md l me mf">from sklearn.neighbors import KNeighborsRegressor</span></pre><p id="48ff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们定义一个<em class="mn"> k- </em>最近邻回归对象，拟合我们的模型，并评估性能:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="a880" class="ma mb it lw b gy mc md l me mf">reg_knn = KNeighborsRegressor()<br/>reg_knn.fit(X_train, y_train)<br/>y_pred = reg_knn.predict(X_test)<br/>from sklearn import metrics<br/>print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/45b29ac3b10fce9356822049f32f163b.png" data-original-src="https://miro.medium.com/v2/resize:fit:554/format:webp/1*wvNfzw9wBS6KSod4ty9Hsg.png"/></div></figure><p id="6ff8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们看到<em class="mn"> k- </em>最近邻算法在全数据集上训练时优于线性回归。</p><p id="71f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">结论</strong></p><p id="e489" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我将在这里停下来，但是您可以随意选择模型特性，看看是否可以改进其中一些模型的性能。</p><p id="8857" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">概括地说，我简要介绍了 python 机器学习库。我讲述了如何定义模型对象、使模型适合数据，以及使用线性回归、随机森林、支持向量机和最近邻模型来预测输出。此外，通过探索这些不同类型的模型，我们能够窥视机器学习库的内部。请注意我们在库中使用的四个模块:</p><ol class=""><li id="0ed2" class="mp mq it lb b lc ld lf lg li mr lm ms lq mt lu mu mv mw mx bi translated">线性模型</li><li id="6fab" class="mp mq it lb b lc my lf mz li na lm nb lq nc lu mu mv mw mx bi translated">全体</li><li id="ac58" class="mp mq it lb b lc my lf mz li na lm nb lq nc lu mu mv mw mx bi translated">SVM</li><li id="6d0c" class="mp mq it lb b lc my lf mz li na lm nb lq nc lu mu mv mw mx bi translated">邻居</li></ol><p id="b9c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然我们只看了回归方法，但是每个模块都有额外的分类方法。在另一篇文章中，我将概述 python 机器学习库中最常见的一些分类方法。</p><p id="3b7f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望这篇文章是有益的。这篇文章的代码可以在 GitHub 上找到。感谢阅读，机器学习快乐！</p></div></div>    
</body>
</html>