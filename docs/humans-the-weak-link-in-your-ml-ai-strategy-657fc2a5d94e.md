# 人类——你的人工智能战略中的薄弱环节？

> 原文：<https://towardsdatascience.com/humans-the-weak-link-in-your-ml-ai-strategy-657fc2a5d94e?source=collection_archive---------85----------------------->

![](img/4a7c56ff6767d282b3d8a3a83a3621fe.png)

## 在许多情况下，需要部署机器学习来增强人类的决策，而不是使其自动化。您如何解释这种对数据产品成功的依赖？

AI 承诺了很多事情。

其中之一是有可能降低人类从事某些类型工作(如分析)所需的 LOE。事实上，它不仅减少了它，而且它还可以远远超过这一点，实现人类无法做到的分析类型。

如果您的团队能够找到这些统计模式，您就可以优化支出、节省运营成本、检测异常、注入智能、知道向谁推销最新的小部件，等等。统计数据。数据。分析。工装。要做到这一点，需要大量预算、大量数据争论和基础设施。

打鼹鼠。

问题是，你可以把所有的技术都做对(假设你不只是用 ML 代码把你的数据或组织中现有的偏见和问题编成代码)，但是如果技术要求人类正确地用它做决策，并把它集成到业务中，你仍然会失败。

许多地方还没有准备好完全自动化，将人类从所有的决策中移除。甚至中央情报局现在也专注于用机器学习来增加决策，而不是用 ML 来自动化一切。

所以我们又回到了人类是技术成功的一个变量——一个很大的变量。AI 或者其他。

仅仅因为你可以建模并不意味着你应该这样做，或者如果你这样做，它将保证组织将释放承诺的价值——因为仍然有人类参与的部分。

这一部分可能不在您的技术清单中，但如果您将人的因素视为 it 投资的一部分，它可能应该在。

设计让我们问，人类会使用它吗？信任它？看重吗？明白吗？他们有动力吗？如果这是错误的，他们个人(或他们关心的外部社区)会付出什么代价？

最后一英里——人类参与的地方——可能是你的人工智能下沉或游动的地方。

那么，在你的人工智能战略中，500 万美元、5000 万美元或 5 亿美元中，有多少将用于确保系统中人的部分不会崩溃，即使技术部分没有问题？

Git 上没有神奇的数据或包可以帮你做到这一点，但是好的设计可能会有所帮助。

***

*如果你是一名数据科学、分析或技术产品负责人，正在寻找如何用你的数据创建有用、可用的决策支持应用程序的一步一步的过程，我的研讨会——*[*设计以人为中心的数据产品*](https://designingforanalytics.com/seminar)*——将教你可以立即应用到工作中的技能，以便你的数据* ***输出*** *开始产生业务* ***成果*** *。*

[*照片由托马斯·斯蒂芬在 Unsplash 上拍摄*](https://unsplash.com/@thomasstephan)