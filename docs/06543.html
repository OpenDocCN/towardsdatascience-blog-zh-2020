<html>
<head>
<title>Pointer Networks for Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习的指针网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-pointer-networks-81fbbc1ddbc8?source=collection_archive---------15-----------------------#2020-05-24">https://towardsdatascience.com/understanding-pointer-networks-81fbbc1ddbc8?source=collection_archive---------15-----------------------#2020-05-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="3d98" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这篇文章讨论了Oriol Vinyals，Meire Fortunato和Navdeep Jaitly的<strong class="js iu">“指针网络”</strong>。这项工作提出了一种生成可变大小输出序列的神经架构，该输出序列是输入序列的标记/索引序列。因为输出序列的长度取决于输入序列的大小，所以它不能由基于RNN的序列到序列模型和神经图灵机来解决。指针生成器网络被应用于解决各种组合优化和组合搜索问题，例如著名的平面旅行商问题(TSP)、Delaunay三角剖分、凸包问题和排序变长序列。指针网络现在还被应用于文本摘要问题，以从文档中提取句子，如在<strong class="js iu">“具有强化选择句子重写的快速抽象摘要”</strong>中由延-陈春和莫希特·班萨尔所提到的。这些网络很好地概括了序列长度，超出了网络的训练。</p><p id="e73f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">指针网络可以说是由<strong class="js iu"> Bahdanau et al. 2015 </strong>的注意机制衍生而来。为了理解指针网络，让我们首先理解序列对序列模型，基于注意力的模型序列对序列模型，然后最后是指针网络。</p><h1 id="6c7a" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">基于RNN的序列间模型:</h1><p id="b4b7" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">在序列到序列模型中，我们使用两个rnn(LSTM/GRU ),一个编码器编码输入序列，另一个供解码器产生输出序列。考虑一个具有四个点(P1、P2、P3和P4)的凸包的例子，如下图所示。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/5b7840d0c6b8de1d20252346daccb83d.png" data-original-src="https://miro.medium.com/v2/resize:fit:526/format:webp/1*6JABqBMTsN_1MPVj9QydcA.png"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">{图1}:基于编码器(蓝色)、解码器(紫色)的序列对序列模型，用于具有四个点的凸包问题</p></figure><p id="90d9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在该图中，带有输入序列(<em class="md">、【易】)</em>的蓝色方框代表编码器，紫色方框代表解码器。编码器的最后一个隐藏状态输出和“→”开始令牌被馈送到解码器模型的第一个时间步长。然后，对于下一个时间步长，来自前一个时间步长的输出连同上一个时间步长的隐藏状态一起被馈送，以产生当前时间步长的输出。在这种情况下，时间步长T0的输出["1"]，作为输入提供给下一个时间步长，以产生输出["4"]。从图中我们可以看到，输出序列完成的凸包将是["1 "，" 4 "，" 2 "，" 1"]。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi me"><img src="../Images/8f5cf2857ace9d4ba0a7cda6f383613d.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/format:webp/1*SnGJb-BJBpXEM7PvHs_ZCw.png"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">{方程1}:参数模型的条件概率方程(RNN)</p></figure><p id="c708" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在上面的等式中，Pi={P1，P2…Pn}是“n”个向量的序列，Ci={C1，C2…Cn}是从1到n的索引序列。在上面的图1中，“n”将是4。</p><p id="ca44" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如等式1所示，RNN (LSTM/GRU)可用于模拟条件概率函数。RNN在每个时间步长“I”被馈送Pi，直到到达序列的结尾，其由“←”结束标记。</p><p id="b359" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这种类型的序列模型中，我们需要为序列的“n”长度的不同值训练单独的模型。</p><h1 id="3880" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">注意力网络</h1><p id="a767" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">上面介绍的标准序列到序列模型通过采用上一时间步的隐藏状态，使用输入序列的固定表示来生成输出序列。固定描述限制了可以流经生成解码器RNN模型的信息量和计算量。因此，为了解决这个问题，Bahdanau et al. 2015提出了注意力网络。在基于注意力的顺序模型中，通过给输入标记赋予权重，在解码器的每个时间步长形成上下文向量。通过将注意力权重乘以每个输入标记的隐藏状态表示并对它们求和来计算该上下文向量。有几种方法来计算注意力权重，如训练神经网络来并行计算序列到序列模型、点积和缩放点积的这些权重。</p><p id="083c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们将编码器隐藏状态表示为(e1，e2，e3 …，en)并将解码器隐藏状态表示为(d1，d2，d3 …)。，dn)。时间步长“I”的上下文向量的计算如下式2所示。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/a76ffc3f6b5539eabde8ce531c6130b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:566/format:webp/1*0AukTEHwxLDtGhQTM93J3g.png"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">{等式2}:上下文向量计算</p></figure><p id="d02c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这里，softmax函数将长度为“n”的输入序列上的向量“u”归一化为输入序列的注意力权重。注意力权重乘以每个编码器隐藏状态“e”并求和以形成上下文向量。</p><p id="308b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">关于注意力模型的更多细节可以从这篇博文中找到。</p><div class="mg mh gp gr mi mj"><a rel="noopener follow" target="_blank" href="/attention-networks-c735befb5e9f"><div class="mk ab fo"><div class="ml ab mm cl cj mn"><h2 class="bd iu gy z fp mo fr fs mp fu fw is bi translated">注意力网络</h2><div class="mq l"><h3 class="bd b gy z fp mo fr fs mp fu fw dk translated">它们是自然语言处理、机器翻译和大多数最新技术(SOTA)领域的最新发展</h3></div><div class="mr l"><p class="bd b dl z fp mo fr fs mp fu fw dk translated">towardsdatascience.com</p></div></div><div class="ms l"><div class="mt l mu mv mw ms mx lx mj"/></div></div></a></div><p id="5ec2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在大多数顺序模型上，该模型的性能明显优于普通的顺序对顺序模型。但是它不适用于输出字典大小依赖于输入的问题。</p><h1 id="e05d" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">指针网络</h1><p id="5356" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">指针网络可以被认为是注意力模型的简单扩展(而不是缩减)。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi my"><img src="../Images/aa3cc6811cd416b683c911520f4913e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:520/format:webp/1*0coYGuIKGFpgrXIw6pYnMA.png"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">{图2}:图1中凸包问题的指针网络解。</p></figure><p id="1af9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在每个解码器时间步骤中，生成网络产生一个向量，该向量调制输入上基于内容的注意力权重。这些权重是通过采用字典大小等于输入序列长度的softmax运算来计算的。</p><p id="f8ee" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在指针网络中，这些注意力权重/掩码不再用于计算下一时间步的上下文向量。这些权重被认为是指向输入序列的指针。具有最高权重的输入时间步长被认为是该解码器时间步长的输出。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/86db225f0cd5f82d5433bf8924c1cd78.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*yfj_IOo9VVCIQPExQvoV2g.png"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">{方程式3}:指针计算</p></figure><p id="dd79" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从等式3可以看出，对“u”的softmax运算不再用于计算上下文向量，以作为信息馈送给当前的解码器步骤。softmax操作的输出指向具有最大值的输入令牌。</p><p id="5289" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">考虑解码器步骤的第一步的输出是“1 ”,如图2所示。然后，对于下一个时间步长，输入[<em class="md">X1，Y1</em>]的相应输入令牌表示连同先前时间步长的解码器隐藏状态表示被馈送到网络，以计算当前时间步长的隐藏状态表示。当前步骤的输出是“4”，因此[ <em class="md"> X4，Y4 </em>进入下一步骤的输入。</p><p id="e187" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">应该理解，简单的RNN序列到序列模型可以通过训练直接指向输入目标索引来解决这个问题。然而，根据推论，这种解决方案并不考虑输出映射回输入索引的约束。如果没有这些限制，在更长的序列中，预测必然会变得模糊。</p><h1 id="c011" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">指针网络的应用</h1><h2 id="e889" class="na kp it bd kq nb nc dn ku nd ne dp ky kb nf ng lc kf nh ni lg kj nj nk lk nl bi translated">1)文本摘要</h2><p id="1b9c" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">从实验中可以看出，结合了抽象和提取方法的研究论文比只使用一种方法训练的论文给出了更好的总结结果。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/6627c5e4a3f13cd680387cbf1193e364.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*s72uzAyQ-Rd6w-be3DBbFw.png"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">[图3]:使用抽取和抽象的文本摘要。(论文最后引用。)</p></figure><p id="37ee" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">图3显示了通过结合提取代理和抽象的文本摘要算法的结构图。提取器使用指针网络从文档的完整句子集中提取一系列独特的句子。</p><h2 id="748d" class="na kp it bd kq nb nc dn ku nd ne dp ky kb nf ng lc kf nh ni lg kj nj nk lk nl bi translated">2)凸包问题</h2><p id="5fa3" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">在计算几何中，寻找有限数量的点的凸包是一项众所周知的任务，并且有几种精确的解决方案可用。为了使用完全数据驱动的方法来解决这个问题，实验发现指针网络比传统的RNN模型给出更好的结果。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/bd9769b470a4e940bbeceb507dfc7c08.png" data-original-src="https://miro.medium.com/v2/resize:fit:538/format:webp/1*D5ub95lJ57fLEwxV8WqKaQ.png"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">[图4]:凸包</p></figure><p id="bd6d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在图4中，点序列P[2，4，3，5，6，7，2]代表凸包的边界。指针网络以P[1，2，3…10]为输入，Cp[2，4，3，5，6，7，2]为输出进行训练。由于输出指向输入序列的索引，指针网络模型提供了比其他神经网络模型更好的结果。</p><h2 id="f22c" class="na kp it bd kq nb nc dn ku nd ne dp ky kb nf ng lc kf nh ni lg kj nj nk lk nl bi translated">3) Delaunay三角剖分</h2><p id="e9a5" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">平面上P个点集的Delaunay三角剖分是这样一种三角剖分，使得每个三角形的每个外接圆都是空的；即在其内部没有来自P的点。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi no"><img src="../Images/b4e8fde3f9bcc8a792635e143cba6fa6.png" data-original-src="https://miro.medium.com/v2/resize:fit:568/format:webp/1*Lp9KfSPw2-eyLqGc04LdYg.png"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">[图5]: Delaunay三角剖分</p></figure><p id="e68d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在上面的图5中，每组三个点[(1，2，4)，(1，4，5)，(1，3，5)，(1，2，3)]代表点集P1的三角剖分集。序列的顺序在这里并不重要；它只是按字典顺序写的。指针网络可以在这里被训练，因为我们知道索引的输入和输出序列。</p><h2 id="4c5e" class="na kp it bd kq nb nc dn ku nd ne dp ky kb nf ng lc kf nh ni lg kj nj nk lk nl bi translated">4)旅行商问题</h2><p id="c28f" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">TSP出现在理论计算机科学的许多领域，并且是用于微芯片设计或DNA测序的关键算法。琐碎的TSP问题是寻找恰好访问每个城市一次并返回起点的最短可能路线。假设两个城市之间的距离在每个相反的方向上是相同的。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi np"><img src="../Images/a72aa7cbe297863937cd2a6fb3d2cea3.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/format:webp/1*nj7qh8zs0JZSzVL2jPGrrg.png"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">[图6]:旅行推销员问题</p></figure><p id="e455" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">输入-输出对具有与凸包问题类似的格式。在一个平面中有“n”个不同的城市或点，我们必须在最短的时间内到达每个城镇。输入序列将是杂乱的“n”个点，没有任何顺序，输出序列将是相同点的有序序列，表示在最短时间内行驶。可以通过取“n”的不同值的输入和输出来训练指针网络。还发现指针网络甚至对于它没有训练过的“n”的那些值也能很好地推广。</p><h1 id="482e" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">引文</h1><p id="7334" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">Oriol Vinyals，Meire Fortunato和Navdeep Jaitly的指针网络</p><p id="0a02" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">由延-陈春和莫希特·班萨尔用加强选择句子重写的快速摘要</p><h1 id="1a33" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">有用的链接</h1><div class="mg mh gp gr mi mj"><a href="https://github.com/devsisters/pointer-network-tensorflow" rel="noopener  ugc nofollow" target="_blank"><div class="mk ab fo"><div class="ml ab mm cl cj mn"><h2 class="bd iu gy z fp mo fr fs mp fu fw is bi translated">dev sisters/指针-网络-张量流</h2><div class="mq l"><h3 class="bd b gy z fp mo fr fs mp fu fw dk translated">指针网络的张量流实现。支持多线程数据管道，以减少I/O延迟。训练一个…</h3></div><div class="mr l"><p class="bd b dl z fp mo fr fs mp fu fw dk translated">github.com</p></div></div><div class="ms l"><div class="nq l mu mv mw ms mx lx mj"/></div></div></a></div><div class="mg mh gp gr mi mj"><a href="https://github.com/shirgur/PointerNet" rel="noopener  ugc nofollow" target="_blank"><div class="mk ab fo"><div class="ml ab mm cl cj mn"><h2 class="bd iu gy z fp mo fr fs mp fu fw is bi translated">shirgur/PointerNet</h2><div class="mq l"><h3 class="bd b gy z fp mo fr fs mp fu fw dk translated">指针网络的Pytorch实现。通过在…上创建帐户，为shirgur/PointerNet的发展做出贡献</h3></div><div class="mr l"><p class="bd b dl z fp mo fr fs mp fu fw dk translated">github.com</p></div></div><div class="ms l"><div class="nr l mu mv mw ms mx lx mj"/></div></div></a></div><div class="mg mh gp gr mi mj"><a href="https://github.com/ChenRocks/fast_abs_rl" rel="noopener  ugc nofollow" target="_blank"><div class="mk ab fo"><div class="ml ab mm cl cj mn"><h2 class="bd iu gy z fp mo fr fs mp fu fw is bi translated">ChenRocks/fast_abs_rl</h2><div class="mq l"><h3 class="bd b gy z fp mo fr fs mp fu fw dk translated">这个存储库包含我们的ACL 2018论文的代码:具有增强选择的快速抽象概括…</h3></div><div class="mr l"><p class="bd b dl z fp mo fr fs mp fu fw dk translated">github.com</p></div></div><div class="ms l"><div class="ns l mu mv mw ms mx lx mj"/></div></div></a></div></div></div>    
</body>
</html>