<html>
<head>
<title>Deep Learning method for object detection: R-CNN explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">物体检测的深度学习方法:R-CNN 解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-method-for-object-detection-r-cnn-explained-ecdadd751d22?source=collection_archive---------6-----------------------#2020-08-04">https://towardsdatascience.com/deep-learning-method-for-object-detection-r-cnn-explained-ecdadd751d22?source=collection_archive---------6-----------------------#2020-08-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b987" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">R-CNN 目标检测算法，从原始论文一步一步讲解</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/55e0fbaab9970792e64e704d1e660db3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IrptRDRG8IL9o-55BKjbLA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:Matthijs Hollemans 的博客</p></figure><h1 id="34c3" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="4e64" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">CNN 已经被广泛用于图像分类。但是检测图像中的对象并在它们周围绘制边界框是一个很难解决的问题。为了解决这个问题，2014 年发表了 R-CNN 算法。在 R-CNN 之后，它的许多变体如<a class="ae ky" href="https://arxiv.org/abs/1504.08083" rel="noopener ugc nofollow" target="_blank"> Fast-R-CNN </a>、<a class="ae ky" href="https://arxiv.org/abs/1506.01497" rel="noopener ugc nofollow" target="_blank">Fast-R-CNN</a>和<a class="ae ky" href="https://arxiv.org/abs/1703.06870" rel="noopener ugc nofollow" target="_blank"> Mask-R-CNN </a>出现了，它们即兴完成了对象检测的任务。要了解最新的 R-CNN 变种，对 R-CNN 有一个清晰的认识是很重要的。一旦理解了这一点，那么所有其他的变化就很容易理解了。</p><p id="de82" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这篇文章将假设读者熟悉 SVM，使用 CNN 和线性回归的图像分类。</p><h1 id="2456" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">概观</h1><p id="55d7" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><a class="ae ky" href="https://arxiv.org/abs/1311.2524" rel="noopener ugc nofollow" target="_blank"> R-CNN 论文</a>【1】发表于 2014 年。这是第一篇表明 CNN 可以在对象检测中产生高性能的论文。该算法以下列方式进行对象检测:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/3f3fa0df6e3415fecc40ae14101c8bf6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*AuW0BzXYipTYm4z1PuknBA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://arxiv.org/abs/1311.2524" rel="noopener ugc nofollow" target="_blank">原创论文</a></p></figure><ol class=""><li id="3930" class="mt mu it lt b lu mn lx mo ma mv me mw mi mx mm my mz na nb bi translated">该方法将图像作为输入，并从图像中提取大约 2000 个区域提议(上图中的步骤 2)。</li><li id="9d46" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm my mz na nb bi translated">然后，每个区域提议被扭曲(整形)成固定大小，作为 CNN 的输入。</li><li id="d747" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm my mz na nb bi translated">CNN 为每个区域提议提取一个固定长度的特征向量(上图中的步骤 3)。</li><li id="cfa2" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm my mz na nb bi translated">这些特征用于使用类别特定的线性 SVM 对区域方案进行分类(上图中的步骤 4)。</li><li id="7f85" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm my mz na nb bi translated">使用边界框回归来细化边界框，使得对象被该框正确地捕捉。</li></ol><p id="56b1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在这篇文章将深入解释模型如何被训练以及它如何预测边界框的细节。</p><h1 id="fa2f" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">计算区域建议</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/24a67c1ff3e2b011200ceb8803d773dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*myaOs8QpNuO5Wv2j-ob-vw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">地区提案|来源:作者图片</p></figure><p id="179b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">区域建议是可能包含对象的边界框。这些由 4 个数字(x，y，h，w)的元组表示。(x，y)是边界框中心的坐标,( h，w)分别是边界框的高度和宽度。这些区域建议由一种叫做<a class="ae ky" href="https://www.geeksforgeeks.org/selective-search-for-object-detection-r-cnn/" rel="noopener ugc nofollow" target="_blank">选择性搜索</a>【2】的算法计算。对于一幅图像，提取大约 2000 个区域提议。</p><h1 id="f0cc" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">训练 CNN 特征提取器；</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/3d7054fb901cf921c3f24dd64acdbbf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dbRlfW9r5ExSpMdI_roVfw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">基于 CNN(VGG 16 台)的特征提取器|来源:<a class="ae ky" href="https://www.pinterest.ca/pin/834854849655070162/?autologin=true" rel="noopener ugc nofollow" target="_blank"> Pinterest </a> |由作者编辑</p></figure><p id="ad7a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">预训练网络:</strong>为了训练 CNN 进行特征提取，像 VGG-16 这样的架构用来自<a class="ae ky" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> imagenet </a>数据的预训练权重初始化。具有 1000 个类别的输出层被切断。因此，当一个区域提议图像(扭曲到 224x224 大小)被传递到网络时，我们得到一个 4096 维的特征向量，如上图所示。这样，每个区域提议由 4096 维特征向量表示。</p><p id="bfea" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">下一步是用区域建议图像微调网络的权重。为了理解这一点，我们将引入一个称为交集/并集或 IoU 得分的新指标。</p><h2 id="e517" class="nj la it bd lb nk nl dn lf nm nn dp lj ma no np ll me nq nr ln mi ns nt lp nu bi translated">并集上的交集</h2><p id="d15f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">为了衡量分类模型的性能，我们通常使用准确度、召回率、精确度等指标。但是如何衡量物体检测的性能。在对象检测中，我们必须评估两件事:</p><ol class=""><li id="9084" class="mt mu it lt b lu mn lx mo ma mv me mw mi mx mm my mz na nb bi translated">边界框在图像中定位对象的能力。换句话说，预测的边界框有多接近地面真实。</li><li id="b2a4" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm my mz na nb bi translated">边界框是否正确分类了被包围的对象</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/4b358ab05c263900982cdb4f564f79b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*W2TbelE05W4qGXC5X-7O9g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/" rel="noopener ugc nofollow" target="_blank">阿德里安·罗斯布鲁克的博客</a></p></figure><p id="9847" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">IoU 分数衡量预测框与实际情况的接近程度。它是地面真实值和预测框的公共面积与这两个框所包围的总面积的比率。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/58fffd34fed251923e619fedc77431c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jq7BIXlq4bheXgIXNexzdg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://apple.github.io/turicreate/docs/userguide/object_detection/advanced-usage.html" rel="noopener ugc nofollow" target="_blank"> Gitbook </a></p></figure><p id="fe24" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在最左边的图像中，可以看到预测框不接近真实情况，因此 IoU 得分仅为 35%,而在最右边的图像中，预测框与真实情况框完全重叠，因此获得了 95%的非常高的值。IoU 值从 0 到 1 不等。</p><p id="5848" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">微调网络:</strong>为了微调模型，用 N+1 个类(softmax 层)替换具有 1000 个类的输出层，模型的其余部分保持不变。n 是对象被分类的不同类别的数量，加上背景类别的 1。</p><p id="dcb5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">接下来，微调需要数据。IoU &gt; 50%的区域提案被视为该目标的积极类别，其余被视为背景。在上面的球图像中，IoU 分数为 35%的区域提案将被标记为背景，而其余的方框将被标记为球。这些图像(区域提议)被扭曲(调整大小)到与 CNN 兼容的尺寸，在 VGG 16 的情况下是 224x224。使用这些图像，网络的权重被微调。</p><h1 id="8c18" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">特定于培训班的 SVM</h1><p id="5225" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">一旦获得了每个区域建议的 4096 维特征，下一个任务是为每个类别训练一个二元 SVM。例如，如果检测模型要检测三个不同的对象——猫、狗和人，那么需要为每个类训练三个 SVM。</p><p id="f4bb" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">数据准备:</strong>属于特定类别的所有对象提议被分离。该类别的手动标记的地面实况图像被认为是正类别，而对于该类别具有 IoU &lt; 30%的对象提议被认为是负类别。对每个类别做同样的事情，并且训练 N 个 SVM 模型以将每个区域提议分类成 N 个类别。</p><h1 id="30db" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">包围盒回归</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/65e24d582cd5c1093d73761bf3abdcd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*X5cCfojWHH6gB4Ez5gvLTg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://blog.mystart.com/my-white-cat-hd-wallpapers-new-tab-theme/" rel="noopener ugc nofollow" target="_blank">我的起点网站</a> |作者编辑</p></figure><p id="3119" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">由选择性搜索[2]算法预测的区域提议边界框可能无法捕获整个对象。为了微调预测的边界框，使用边界框回归。</p><p id="e70c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">通过选择性搜索[2]算法考虑地面真实区域建议 G 和预测区域建议 P。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/82da493f3c6fe63af20a52be5cf89102.png" data-original-src="https://miro.medium.com/v2/resize:fit:478/format:webp/1*biI7gJimTMDgy-mZkMbOgQ.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/4d4212f28c20f89a611e08d1e9f6f4bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:450/format:webp/1*8HwiOggGo4lu7VYVuVnhuw.png"/></div></figure><p id="4210" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了使 G 比例不变的预测，进行以下变换，使得回归的目标是<em class="nz"> t. </em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/fa87c65b2993704d4fa4a102134006f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:436/format:webp/1*x39wotV0gToBFNAXm8SWqw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">转换方程</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/92543856f92eb27b0fb330cb002accad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*biog9tPLbyaEczjEjSRFMg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://www.pinterest.ca/pin/834854849655070162/?autologin=true" rel="noopener ugc nofollow" target="_blank"> Pinterest </a> |作者编辑</p></figure><p id="47ff" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">回归模型的输入是来自 CNN 的最后一个池层的特征。我们每类训练 4 个回归模型，目标为<em class="nz"> t </em>，输入特征为 CNN 的最后一个池层特征，以学习回归参数 w。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/32409cbcd2252994ea124312a1dd25d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:354/format:webp/1*P4DIt9JIvRwNP14EFkIPgg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">回归方程式</p></figure><p id="6ddb" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这里*是(x，y，w，h)的占位符，phi(P)是对应于方案 P 的最后一个池化图层要素。因此，要预测地面实况 G，我们可以使用回归方程根据区域方案 P 计算 t，然后将 t 和 P 的值代入变换方程以获得 G。</p><h1 id="fdb8" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">预言；预测；预告</h1><p id="fd5d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">一旦 R-CNN 的不同部分被训练，接下来的部分是进行对象检测。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/f7962db4485ed616d98efebf7b43cc11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rAmUVKG8CWTnOEofxv-gTw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:作者图片</p></figure><ol class=""><li id="22cf" class="mt mu it lt b lu mn lx mo ma mv me mw mi mx mm my mz na nb bi translated">拍摄输入图像，并使用选择性搜索[2]算法，为图像获得大约 2000 个区域提议。</li><li id="8565" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm my mz na nb bi translated">每个区域建议图像被扭曲成 224x224 的固定大小。</li><li id="6327" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm my mz na nb bi translated">这些区域提议图像然后被传递到训练的 CNN 以获得所有 2000 个区域提议的 4096 维特征向量，这导致 2000×4096 维矩阵。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/e127100fa1b1ea04384503d73c2129fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_VjSlcGZZCKDS60GUFeAGQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:作者图片</p></figure><p id="ec79" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">3.每个区域的提案都使用每个类别的 SVM 进行分类。通常对于 N 个类，SVM 权重(4096 维)以矩阵的形式堆叠，并与特征矩阵相乘。这将产生一个矩阵，该矩阵为区域提案所属的每个类别分配一个分数。</p><p id="1f1e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">4.该建议被分配到得分最高的类别。因此，图像中的所有 2000 个区域提议或边界框都标有类别标签。</p><p id="fae2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">5.在那些众多的边界框中，许多是多余的和重叠的边界框，需要被移除。为了实现这一点，使用了非最大抑制算法。</p><p id="38c6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">非最大抑制算法:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/cd8678186f7857dacd4c9396bd68603d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*sw0GLpIY6n7sEW6gXJplOQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://medium.com/@yusuken/object-detction-1-nms-ed00d16fdcf9" rel="noopener">非最大压制博客</a></p></figure><p id="2af8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">非最大抑制是一种贪婪算法。它一次只对一个类有效。对于一个特定的类，它选择使用 SVM 获得最高分数的盒子。然后，它计算属于该类的所有其他边界框的 IoU 分数。IoU 分数大于 70%的框被移除。换句话说，具有非常高重叠的边界框被移除。然后选择下一个最高得分框，依此类推，直到该类别的所有重叠边界框都被移除。对所有的类都这样做，以获得如上所示的结果。</p><p id="ad72" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">6.一旦获得标记的边界框，下一个任务是使用回归来微调框的位置。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/9322834183529ba3948d7594abd6f0b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vp-cjbGf6ololi3eGDolBA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">通过回归微调区域建议|来源:作者图片</p></figure><p id="8e6a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在训练期间，为每个类训练 4 个回归模型。因此，对于特定的包围盒，区域建议图像通过 CNN 以获得要传递给回归模型的特征 P。回归模型输出比例不变的坐标(dx(P)，dy(P)，dw(P)，dh(P))。这些坐标与区域建议坐标(Px，Py，Pw，Ph)相结合，使用以下公式获得调整后的最终坐标(Gx，Gy，Gw，Gh)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/dea5c0707fe7689ceb976dd0a20c05ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:474/format:webp/1*kBaLyz5DRPGQ07_RtIlZ1w.png"/></div></figure><h1 id="71fd" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">原始论文的结果</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/343aa6cfeeb5dca92c728acb6ad2b9bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OvmL2PqSaQvRfiIk7oCODw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">R-CNN 物体探测结果|来源:<a class="ae ky" href="https://arxiv.org/abs/1311.2524" rel="noopener ugc nofollow" target="_blank">原创论文</a></p></figure><h1 id="17db" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">结论</h1><p id="8f33" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">R-CNN 虽然擅长检测对象，但也有不足之处。</p><ol class=""><li id="68c5" class="mt mu it lt b lu mn lx mo ma mv me mw mi mx mm my mz na nb bi translated">这种算法很慢，在图像上执行对象检测大约需要 47 秒。</li><li id="d043" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm my mz na nb bi translated">训练不是一步到位的。不同的部分有不同的模式，这使得培训过程非常耗时。</li></ol><p id="3151" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这些缺点在 R-CNN 后来的改进中得到解决，这些改进是 Fast-RCNN、Fast-RCNN 和 Mask-RCNN。对 R-CNN 有很好的理解，有助于轻松直观地理解 R-CNN 的其他变种。</p><h1 id="a093" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">参考</h1><ol class=""><li id="d390" class="mt mu it lt b lu lv lx ly ma oj me ok mi ol mm my mz na nb bi translated">R.吉希克、j .多纳休、t .达雷尔和 j .马利克。丰富的特征层次，用于精确的对象检测和语义分割。2014 年在 CVPR。</li><li id="978e" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm my mz na nb bi translated">Uijlings，Jasper &amp; Sande，K. &amp; Gevers，T. &amp; Smeulders，Arnold。(2013).物体识别的选择性搜索。国际计算机视觉杂志。104.154–171.10.1007/s 11263–013–0620–5。</li></ol></div></div>    
</body>
</html>