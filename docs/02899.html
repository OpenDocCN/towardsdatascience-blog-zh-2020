<html>
<head>
<title>Gini Impurity Measure – a simple explanation using python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基尼不纯度测量——使用 python 的简单解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/gini-impurity-measure-dbd3878ead33?source=collection_archive---------3-----------------------#2020-03-20">https://towardsdatascience.com/gini-impurity-measure-dbd3878ead33?source=collection_archive---------3-----------------------#2020-03-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="c80d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用 python 的直观解释</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/63586bf507aee2564ac49c7dec0d0983.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*PiapUx5kuAEAfFCQCGylsw.png"/></div></figure><h1 id="e274" class="kn ko iq bd kp kq kr ks kt ku kv kw kx jw ky jx kz jz la ka lb kc lc kd ld le bi translated">介绍</h1><p id="efd5" class="pw-post-body-paragraph lf lg iq lh b li lj jr lk ll lm ju ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">Gini 杂质度量是决策树算法中使用的方法之一，用于决定从根节点开始的最佳分裂以及后续分裂。</p><p id="21d0" class="pw-post-body-paragraph lf lg iq lh b li mb jr lk ll mc ju ln lo md lq lr ls me lu lv lw mf ly lz ma ij bi translated">(在继续之前，您可能想回顾一下<a class="ae mg" href="https://medium.com/@StevenLoaiza/making-decisions-with-trees-559c8db5af59" rel="noopener">用树做决策</a></p><p id="ea3c" class="pw-post-body-paragraph lf lg iq lh b li mb jr lk ll mc ju ln lo md lq lr ls me lu lv lw mf ly lz ma ij bi translated">将它放入上下文中，决策树试图创建连续的问题，以便将数据划分为更小的组。一旦划分完成，就在该终端节点做出预测决策(基于频率)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/5f35ea872af90a3a5a58b3530203110c.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*JDlJsxwBUFkAqYJBgHjHrw.png"/></div></figure><p id="8262" class="pw-post-body-paragraph lf lg iq lh b li mb jr lk ll mc ju ln lo md lq lr ls me lu lv lw mf ly lz ma ij bi translated">假设我们有一个观察列表，表明一个人是否决定呆在家里不工作。我们还有两个特征，即他们是否生病和他们的体温。</p><p id="4687" class="pw-post-body-paragraph lf lg iq lh b li mb jr lk ll mc ju ln lo md lq lr ls me lu lv lw mf ly lz ma ij bi translated">我们需要选择哪个特征，情绪还是温度，来分割数据。基尼系数将帮助我们做出这个决定。</p><p id="7b77" class="pw-post-body-paragraph lf lg iq lh b li mb jr lk ll mc ju ln lo md lq lr ls me lu lv lw mf ly lz ma ij bi translated"><strong class="lh ir"> Def: </strong>基尼系数告诉我们一个观察值被错误分类的概率是多少。</p><p id="1789" class="pw-post-body-paragraph lf lg iq lh b li mb jr lk ll mc ju ln lo md lq lr ls me lu lv lw mf ly lz ma ij bi translated">请注意，基尼系数越低，分割越好。换句话说，错误分类的可能性越低。</p><h1 id="b893" class="kn ko iq bd kp kq kr ks kt ku kv kw kx jw ky jx kz jz la ka lb kc lc kd ld le bi translated">形式定义</h1><p id="ec1c" class="pw-post-body-paragraph lf lg iq lh b li lj jr lk ll lm ju ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">下图是两类问题。我们将在后面将其概括为两个以上的组。</p><p id="4211" class="pw-post-body-paragraph lf lg iq lh b li mb jr lk ll mc ju ln lo md lq lr ls me lu lv lw mf ly lz ma ij bi translated">让<strong class="lh ir"> Ginx </strong>代表基尼指数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/a22451163aee6c0e2b546964e177d47d.png" data-original-src="https://miro.medium.com/v2/resize:fit:536/format:webp/1*z13XNqontu5-igtccnVXhQ.png"/></div></figure><p id="40a3" class="pw-post-body-paragraph lf lg iq lh b li mb jr lk ll mc ju ln lo md lq lr ls me lu lv lw mf ly lz ma ij bi translated">其中 p1、p2 分别是 1、2 类概率。</p><p id="d1f1" class="pw-post-body-paragraph lf lg iq lh b li mb jr lk ll mc ju ln lo md lq lr ls me lu lv lw mf ly lz ma ij bi translated"><strong class="lh ir">注</strong> : p1 + p2 =1</p><p id="018d" class="pw-post-body-paragraph lf lg iq lh b li mb jr lk ll mc ju ln lo md lq lr ls me lu lv lw mf ly lz ma ij bi translated">这还没有完成。上面的等式将给出子分割的基尼系数，但是我们想知道整个分割的基尼系数(因为数据将被分割为左右两部分)。因此，我们需要相应地权衡它们。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/e31ebd3afca55511417babab02510a65.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*Om7699X9wqjLm1HupV15yA.png"/></div></figure><p id="4c60" class="pw-post-body-paragraph lf lg iq lh b li mb jr lk ll mc ju ln lo md lq lr ls me lu lv lw mf ly lz ma ij bi translated">其中，P_L 是向左分流的比例，p_L1 类似于左分流的 P1(P _ R 也是如此)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mk ml l"/></div></figure><p id="31c2" class="pw-post-body-paragraph lf lg iq lh b li mb jr lk ll mc ju ln lo md lq lr ls me lu lv lw mf ly lz ma ij bi translated">我们有一个零的下限和一个半的上限。杂质测量值越低，分离越好。</p><p id="ffc8" class="pw-post-body-paragraph lf lg iq lh b li mb jr lk ll mc ju ln lo md lq lr ls me lu lv lw mf ly lz ma ij bi translated">如果你看一下图表，你会注意到杂质测量值越低越好。当观察值为 1 类的概率为零(一直到图表的左侧)时，这意味着它将始终为 2 类，杂质测量值为零。当观察值为 1 类的概率为 100%时，在另一端也会发生同样的事情。</p><h1 id="c995" class="kn ko iq bd kp kq kr ks kt ku kv kw kx jw ky jx kz jz la ka lb kc lc kd ld le bi translated">例子</h1><p id="2ce1" class="pw-post-body-paragraph lf lg iq lh b li lj jr lk ll lm ju ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们回到上面的例子，在两个特性上分开。</p><h2 id="6705" class="mm ko iq bd kp mn mo dn kt mp mq dp kx lo mr ms kz ls mt mu lb lw mv mw ld mx bi translated">情绪</h2><p id="af3d" class="pw-post-body-paragraph lf lg iq lh b li lj jr lk ll lm ju ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">病态基尼杂质= 2 * (2/3) * (1/3) = 0.444</p><p id="20f3" class="pw-post-body-paragraph lf lg iq lh b li mb jr lk ll mc ju ln lo md lq lr ls me lu lv lw mf ly lz ma ij bi translated">NotSick 基尼杂质= 2 * (3/5) * (2/5) = 0.48</p><p id="0cc6" class="pw-post-body-paragraph lf lg iq lh b li mb jr lk ll mc ju ln lo md lq lr ls me lu lv lw mf ly lz ma ij bi translated">加权基尼系数= (3/8) * <em class="my">西基尼+ (5/8)非西基尼= 0.4665 </em></p><h2 id="59e0" class="mm ko iq bd kp mn mo dn kt mp mq dp kx lo mr ms kz ls mt mu lb lw mv mw ld mx bi translated">温度</h2><p id="6784" class="pw-post-body-paragraph lf lg iq lh b li lj jr lk ll lm ju ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们将温度的阈值硬编码为 Temp ≥ 100。</p><p id="d5d1" class="pw-post-body-paragraph lf lg iq lh b li mb jr lk ll mc ju ln lo md lq lr ls me lu lv lw mf ly lz ma ij bi translated">杂质温度= 2 * (3/4) * (1/4) = 0.375</p><p id="8b7d" class="pw-post-body-paragraph lf lg iq lh b li mb jr lk ll mc ju ln lo md lq lr ls me lu lv lw mf ly lz ma ij bi translated">杂质下温度= 2 * (3/4) * (1/4) = 0.375</p><p id="8da5" class="pw-post-body-paragraph lf lg iq lh b li mb jr lk ll mc ju ln lo md lq lr ls me lu lv lw mf ly lz ma ij bi translated">加权基尼系数=(4/8)*<em class="my">TempOverGini</em>+(4/8)*<em class="my">TempUnderGini</em>= 0.375</p><p id="863b" class="pw-post-body-paragraph lf lg iq lh b li mb jr lk ll mc ju ln lo md lq lr ls me lu lv lw mf ly lz ma ij bi translated">我们可以看到，温度的基尼系数较低。因此，我们会选择在温度上进行分割，因为它对观察结果进行错误分类的可能性最低。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mk ml l"/></div></figure><p id="14de" class="pw-post-body-paragraph lf lg iq lh b li mb jr lk ll mc ju ln lo md lq lr ls me lu lv lw mf ly lz ma ij bi translated">我们将验证我们的函数确实返回了上面的值。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mk ml l"/></div></figure><h1 id="edf4" class="kn ko iq bd kp kq kr ks kt ku kv kw kx jw ky jx kz jz la ka lb kc lc kd ld le bi translated">结论</h1><p id="f7f6" class="pw-post-body-paragraph lf lg iq lh b li lj jr lk ll lm ju ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们已经完成了基尼系数的引入。我希望这个简短的解释能让你了解决策树是如何决定分割数据的。</p><p id="5c8f" class="pw-post-body-paragraph lf lg iq lh b li mb jr lk ll mc ju ln lo md lq lr ls me lu lv lw mf ly lz ma ij bi translated">请记住，这不是唯一使用的方法，它将取决于您使用的软件包。</p><p id="ff30" class="pw-post-body-paragraph lf lg iq lh b li mb jr lk ll mc ju ln lo md lq lr ls me lu lv lw mf ly lz ma ij bi translated">感谢您的阅读！</p><h1 id="f978" class="kn ko iq bd kp kq kr ks kt ku kv kw kx jw ky jx kz jz la ka lb kc lc kd ld le bi translated">附录</h1><p id="876d" class="pw-post-body-paragraph lf lg iq lh b li lj jr lk ll lm ju ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ir">基尼不纯的概括</strong></p><p id="a05d" class="pw-post-body-paragraph lf lg iq lh b li mb jr lk ll mc ju ln lo md lq lr ls me lu lv lw mf ly lz ma ij bi translated">假设我们有(<em class="my"> n) </em>个不同的类。那么基尼公式将是:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/8ca1d495b0f9720daf8197aecae95a8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/1*R715LfIHMHxNMCcMyb7WAA.png"/></div></figure></div></div>    
</body>
</html>