<html>
<head>
<title>Handwritten Khmer Digit Recognition</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">手写高棉数字识别</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/handwritten-khmer-digit-recognition-860edf06cd57?source=collection_archive---------43-----------------------#2020-06-20">https://towardsdatascience.com/handwritten-khmer-digit-recognition-860edf06cd57?source=collection_archive---------43-----------------------#2020-06-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5d4e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">线性判别分析方法</h2></div><h1 id="d556" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">手写识别</h1><p id="8991" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">手写识别是将给定的手写模式分类成组(类别)的任务。有许多方法可以实现这项任务，从传统的机器学习方法到深度学习，如卷积神经网络(CNN)。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi lw"><img src="../Images/e2bdc11437e4653b0810d40a3815e83d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hVdoiW35FXUE-fZ0HI30Tw.jpeg"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">图1手写数字识别示例</p></figure><p id="c873" class="pw-post-body-paragraph la lb it lc b ld mm ju lf lg mn jx li lj mo ll lm ln mp lp lq lr mq lt lu lv im bi translated">本文介绍一种简单的模式识别方法——高斯极大似然估计线性判别分析。我们以手写高棉数字识别任务为例。</p><h1 id="f9ea" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">高棉数字</h1><p id="11b2" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">高棉语是柬埔寨的官方语言。大约有1600万人说这种语言，主要分布在柬埔寨以及越南和泰国的部分地区。在高棉语中，图2所示的一组数字用于数字系统。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/cb63e736cd86ec9d7f52d1149507883e.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*T-iyJnqMqC58bNpJFiO6ow.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">图2高棉数字</p></figure><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/3090e120f638fedbd315b5eaf78ca45c.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*VTgs6Ut7lZlF0EoWOyguiw.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">图3手写高棉数字</p></figure><h1 id="e2be" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">线性判别分析(LDA)</h1><p id="0d05" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">假设我们有模式x及其类别y的样本，{(x_i，y_i)} (i=1，…，n)，其中n是训练样本的数量。设n_y是y范畴中模式的个数。</p><p id="ecd2" class="pw-post-body-paragraph la lb it lc b ld mm ju lf lg mn jx li lj mo ll lm ln mp lp lq lr mq lt lu lv im bi translated">为了定义给定模式x的相应类别，我们选择具有最大后验概率值p(y|x)的y。这里p(y|x)是给定x的y的一个条件概率，这个判定规则叫做最大后验概率规则。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/bbb37312edfea662b7cf50d00df6a181.png" data-original-src="https://miro.medium.com/v2/resize:fit:584/format:webp/0*zJmuOXwrUaHyDkLT.png"/></div></figure><p id="49d0" class="pw-post-body-paragraph la lb it lc b ld mm ju lf lg mn jx li lj mo ll lm ln mp lp lq lr mq lt lu lv im bi translated">根据贝叶斯理论，后验概率可以通过下式计算</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/24785333c65732a62f093463bee0cf7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:702/format:webp/0*2S1nn9zvD1aTlKdH.png"/></div></figure><p id="c551" class="pw-post-body-paragraph la lb it lc b ld mm ju lf lg mn jx li lj mo ll lm ln mp lp lq lr mq lt lu lv im bi translated">在上面的表达式中，p(x)不依赖于y。因此，我们可以忽略分母。</p><p id="a815" class="pw-post-body-paragraph la lb it lc b ld mm ju lf lg mn jx li lj mo ll lm ln mp lp lq lr mq lt lu lv im bi translated">现在我们需要估计p(y)和p(x|y)。对于y，由于它是一个离散的概率变量(y是一个类别)，我们可以简单地用y类别中模式的个数与样本总数的比值来估计它的概率。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/95e93c1638b6fbca3e3ccdf17b65a4f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:402/format:webp/1*na6evA7w0ugG0kbjzeBH0g.png"/></div></figure><p id="6385" class="pw-post-body-paragraph la lb it lc b ld mm ju lf lg mn jx li lj mo ll lm ln mp lp lq lr mq lt lu lv im bi translated">x是一个连续的概率变量，我们不能直接应用于y的方法。这里，我们将介绍一种参数化方法。</p><p id="c96f" class="pw-post-body-paragraph la lb it lc b ld mm ju lf lg mn jx li lj mo ll lm ln mp lp lq lr mq lt lu lv im bi translated">假设模式x由高斯分布独立且同分布，我们将对高斯模型应用最大似然估计来估计其参数并计算条件概率p(x|y)。</p><p id="1fe2" class="pw-post-body-paragraph la lb it lc b ld mm ju lf lg mn jx li lj mo ll lm ln mp lp lq lr mq lt lu lv im bi translated">通常，具有d维高斯分布的x的高斯模型由下式给出</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/ff891887956e29f257e5902dc2ce9e75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/0*eslX76skRWQsr-15.png"/></div></figure><p id="3b4b" class="pw-post-body-paragraph la lb it lc b ld mm ju lf lg mn jx li lj mo ll lm ln mp lp lq lr mq lt lu lv im bi translated">使用最大似然估计，高斯模型参数的估计为</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/0322cea71a0cf921d906c2d2ad4de8d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/0*sqK1VILW5KxNTiSe.png"/></div></figure><p id="f549" class="pw-post-body-paragraph la lb it lc b ld mm ju lf lg mn jx li lj mo ll lm ln mp lp lq lr mq lt lu lv im bi translated">现在，p(x|y)的估计值可以通过下式计算</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi my"><img src="../Images/c98769eeffb91050cad1b30ed081e267.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/0*QdHB9kPHMntWVqgi.png"/></div></figure><p id="bfa9" class="pw-post-body-paragraph la lb it lc b ld mm ju lf lg mn jx li lj mo ll lm ln mp lp lq lr mq lt lu lv im bi translated">将估计的p(x|y)和p(y)代入p(y|x)表达式，我们可以得到给定模式x的类别y的后验概率，然而，为了使它更简单，我们在下面的计算中使用了对数函数。因为对数函数是单调递增的，所以与p(y|x)的关系没有区别。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/6389db8f7968af15101a6a3fcf047adf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/0*u8qo8NWN9YnGZ7XD.png"/></div></figure><p id="8da7" class="pw-post-body-paragraph la lb it lc b ld mm ju lf lg mn jx li lj mo ll lm ln mp lp lq lr mq lt lu lv im bi translated">为了简化这个对数后验概率，在线性判别分析中，我们做如下假设:每一类的方差-协方差矩阵相等。在这种情况下，常见的方差-协方差矩阵为</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi na"><img src="../Images/3c9be92becd379f8438441f90b6818cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:418/format:webp/0*FJLF4PCrgCRRNX9v.png"/></div></figure><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/624908a6dba3f069007a4801d8c2847c.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/0*zxvBVwrywS7H5pCt.png"/></div></figure><p id="eb07" class="pw-post-body-paragraph la lb it lc b ld mm ju lf lg mn jx li lj mo ll lm ln mp lp lq lr mq lt lu lv im bi translated">log p(y|x)是</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/15f56b1fc70d8854d54de16b14b77bcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/0*cnQq6sv7KV2pC8KQ.png"/></div></figure><p id="e8bf" class="pw-post-body-paragraph la lb it lc b ld mm ju lf lg mn jx li lj mo ll lm ln mp lp lq lr mq lt lu lv im bi translated">因此，给定模式x的类别y可以通过选择其log p(y|x)在所有类别中保持最大值的y来预测。</p><h1 id="d420" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">资料组</h1><p id="7911" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">现在让我们将这种LDA方法应用于手写高棉数字识别。</p><p id="009f" class="pw-post-body-paragraph la lb it lc b ld mm ju lf lg mn jx li lj mo ll lm ln mp lp lq lr mq lt lu lv im bi translated">在这种情况下，手写数字的数字图像是模式x，而<br/>0–9是类别y。我们使用1500个64x64灰度图像作为数据集。我们将这个数据集分成1200个用于训练数据，300个用于测试数据。</p><p id="5737" class="pw-post-body-paragraph la lb it lc b ld mm ju lf lg mn jx li lj mo ll lm ln mp lp lq lr mq lt lu lv im bi translated">对于模式x，我们简单地将64x64灰度图像整形为4096维向量。因此，我们将LDA应用于具有4096维高斯分布的高斯模型。</p><h1 id="c212" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">用Python实现</h1><h2 id="051a" class="nd kj it bd kk ne nf dn ko ng nh dp ks lj ni nj ku ln nk nl kw lr nm nn ky no bi translated">o将数据集分成训练集和测试集</h2><pre class="lx ly lz ma gt np nq nr ns aw nt bi"><span id="313c" class="nd kj it nq b gy nu nv l nw nx">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)</span></pre><h2 id="b5e5" class="nd kj it bd kk ne nf dn ko ng nh dp ks lj ni nj ku ln nk nl kw lr nm nn ky no bi translated">o估计模型的参数(训练)</h2><pre class="lx ly lz ma gt np nq nr ns aw nt bi"><span id="15bf" class="nd kj it nq b gy nu nv l nw nx">means = np.zeros((10, nD*nD))<br/>cov = np.zeros((nD*nD, nD*nD))<br/>count = [sum(map(lambda x : x == i, y_train)) for i in range(0,10)]</span><span id="f1b5" class="nd kj it nq b gy ny nv l nw nx">for i in range(10):<br/>    cov_array = []<br/>    for j in range(len(y_train)):<br/>        if int(y_train[j]) == i:<br/>            means[i] = means[i] + X_train[j]<br/>            cov_array.append(X_train[j])<br/>            <br/>    cov = cov + np.cov(np.array(cov_array).T) * (count[i]/len(y_train))</span><span id="048f" class="nd kj it nq b gy ny nv l nw nx">means = means / len(y_train)<br/>inv_cov = np.linalg.inv(cov + 0.00001*np.eye(nD*nD))</span></pre><h2 id="7293" class="nd kj it bd kk ne nf dn ko ng nh dp ks lj ni nj ku ln nk nl kw lr nm nn ky no bi translated">o评估</h2><pre class="lx ly lz ma gt np nq nr ns aw nt bi"><span id="aeb8" class="nd kj it nq b gy nu nv l nw nx">ans = np.zeros((10, 10),dtype='int')<br/>total = 0<br/>errors = []</span><span id="b598" class="nd kj it nq b gy ny nv l nw nx">for i in range(10):<br/>    for j in range(len(y_test)):<br/>        if int(y_test[j]) == i:<br/>            p = np.zeros(10)<br/>            for k in range(len(p)):<br/>                p[k] = np.dot(np.dot(means[k].T, inv_cov), X_test[j]) - (np.dot(np.dot(means[k].T, inv_cov), means[k])) / 2 + np.log(count[i])</span><span id="2553" class="nd kj it nq b gy ny nv l nw nx">m = p.argmax()<br/>            if m!=y_test[j]:<br/>                errors.append((j,m))<br/>            ans[m][int(y_test[j])] = int(ans[m][int(y_test[j])] + 1)</span></pre><h2 id="4cc5" class="nd kj it bd kk ne nf dn ko ng nh dp ks lj ni nj ku ln nk nl kw lr nm nn ky no bi translated">密码</h2><p id="9460" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><a class="ae nz" href="https://github.com/loem-ms/PatternRecognition.git" rel="noopener ugc nofollow" target="_blank">https://github.com/loem-ms/PatternRecognition.git</a></p><h1 id="73ea" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">结果和讨论</h1><h2 id="975d" class="nd kj it bd kk ne nf dn ko ng nh dp ks lj ni nj ku ln nk nl kw lr nm nn ky no bi translated">o混淆矩阵</h2><pre class="lx ly lz ma gt np nq nr ns aw nt bi"><span id="40c7" class="nd kj it nq b gy nu nv l nw nx">    <strong class="nq iu">0   1   2   3   4   5   6   7   8   9</strong><br/><strong class="nq iu">0</strong>  28   0   0   0   0   0   0   0   0   0<br/><strong class="nq iu">1</strong>   2  27   0   0   0   0   0   0   0   0<br/><strong class="nq iu">2</strong>   0   0  37   0   0   0   0   0   0   0<br/><strong class="nq iu">3</strong>   0   0   0  29   0   0   0   0   0   0<br/><strong class="nq iu">4</strong>   0   0   0   0  33   0   0   0   1   0<br/><strong class="nq iu">5</strong>   0   0   0   0   0  25   0   0   0   0<br/><strong class="nq iu">6</strong>   0   0   0   0   0   0  26   0   0   0<br/><strong class="nq iu">7</strong>   0   0   0   0   0   0   0  28   0   0<br/><strong class="nq iu">8</strong>   0   0   0   0   0   0   0   0  38   0<br/><strong class="nq iu">9</strong>   0   0   0   0   0   0   0   0   0  26</span></pre><h2 id="9aea" class="nd kj it bd kk ne nf dn ko ng nh dp ks lj ni nj ku ln nk nl kw lr nm nn ky no bi translated">o测试准确度</h2><pre class="lx ly lz ma gt np nq nr ns aw nt bi"><span id="5478" class="nd kj it nq b gy nu nv l nw nx">0.99</span></pre><p id="2f8a" class="pw-post-body-paragraph la lb it lc b ld mm ju lf lg mn jx li lj mo ll lm ln mp lp lq lr mq lt lu lv im bi translated">有用！</p><h2 id="7d8e" class="nd kj it bd kk ne nf dn ko ng nh dp ks lj ni nj ku ln nk nl kw lr nm nn ky no bi translated">o错误案例</h2><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/4433f982168123990def06ec3e22d81b.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*3ylIXQ1C9FixYWnGIwAD7g.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">类别:១；预测:០</p></figure><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/8135f3b03f193f030da60b6f28859595.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*6aBtov2u2lH0Uuft-D2TOg.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">类别:៤；预测:៨</p></figure><p id="3b47" class="pw-post-body-paragraph la lb it lc b ld mm ju lf lg mn jx li lj mo ll lm ln mp lp lq lr mq lt lu lv im bi translated">与其他基于深度学习的方法中的黑盒概念不同，使用LDA，我们可以简单地理解使用数据的统计特征的学习过程。</p><p id="5022" class="pw-post-body-paragraph la lb it lc b ld mm ju lf lg mn jx li lj mo ll lm ln mp lp lq lr mq lt lu lv im bi translated">然而，由于它是基于线性的模型，在某些情况下，它不能被线性判别函数识别，性能将明显下降。</p><p id="a44a" class="pw-post-body-paragraph la lb it lc b ld mm ju lf lg mn jx li lj mo ll lm ln mp lp lq lr mq lt lu lv im bi translated">另一个问题是输入模式x的维数。在本例中，我们使用4096维向量(64x64)作为输入，估计模型参数需要7.17秒(注意PC)。当将输入图像增加到128x128时，这意味着使用16384维向量作为输入，这需要470.80秒。增加输入向量的维数导致在计算方差-协方差矩阵的逆矩阵时的巨大时间复杂度。</p></div></div>    
</body>
</html>