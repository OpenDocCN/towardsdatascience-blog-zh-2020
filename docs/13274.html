<html>
<head>
<title>The Beauty of Bayesian Optimization, Explained in Simple Terms</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">贝叶斯优化的美妙之处，用简单的术语解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-beauty-of-bayesian-optimization-explained-in-simple-terms-81f3ee13b10f?source=collection_archive---------2-----------------------#2020-09-12">https://towardsdatascience.com/the-beauty-of-bayesian-optimization-explained-in-simple-terms-81f3ee13b10f?source=collection_archive---------2-----------------------#2020-09-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/22059a16b93fdc35e849ed2f1302df46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2VEofdAC1EdNBx5t"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">来源:<a class="ae jg" href="https://unsplash.com/photos/eZQ4gogZeOA" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><div class=""/><div class=""><h2 id="0d0e" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">巧妙算法背后的直觉</h2></div><p id="f2c2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里有一个函数:<em class="lu"> f </em> ( <em class="lu"> x </em>)。计算起来很贵，不一定是一个<a class="ae jg" href="https://en.wikipedia.org/wiki/Closed-form_expression#Analytic_expression" rel="noopener ugc nofollow" target="_blank">解析表达式</a>，也不知道它的导数。</p><p id="47d8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你的任务是:找到全局最小值。</p><p id="ca84" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这肯定是一项困难的任务，比机器学习中的其他优化问题更困难。例如，梯度下降法<a class="ae jg" href="https://medium.com/analytics-vidhya/the-engine-of-the-neural-network-the-backpropagation-equation-cf2dd1be2477" rel="noopener">可以访问函数的导数</a>，并利用数学捷径来加快表达式求值。</p><p id="d4a4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">或者，在一些优化场景中，函数的评估成本很低。如果我们可以在几秒钟内获得数百个输入变量<em class="lu"> x </em>的结果，那么可以使用简单的网格搜索，并获得良好的结果。</p><p id="7313" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">或者，可以使用一整套<a class="ae jg" href="https://medium.com/analytics-vidhya/the-fascinating-no-gradient-approach-to-neural-net-optimization-abb287f88c97" rel="noopener">非常规非梯度优化方法</a>，如粒子群集或模拟退火。</p><p id="ea05" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">可惜现在的任务没有这些奢侈品。我们的优化受到几个方面的限制，特别是:</p><ul class=""><li id="1904" class="lv lw jj la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated">算起来很贵。理想情况下，我们应该能够对函数进行足够的查询，以便从本质上复制它，但是我们的优化方法必须在有限的输入采样下工作。</li><li id="92f7" class="lv lw jj la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">导数未知。这就是为什么<a class="ae jg" rel="noopener" target="_blank" href="/a-quick-guide-to-neural-network-optimizers-with-applications-in-keras-e4635dd1cca4">梯度下降及其风格</a>仍然是深度学习最受欢迎的方法，有时也是其他机器学习算法中最受欢迎的方法。知道导数给了优化器方向感——我们没有这个。</li><li id="ee80" class="lv lw jj la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">我们需要找到全局最小值，即使对于像梯度下降这样复杂的方法，这也是一个困难的任务。我们的模型需要某种机制来避免陷入局部最小值。</li></ul><p id="7181" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">解决方案:贝叶斯优化，它提供了一个优雅的框架来处理类似于所描述的场景的问题，以最少的步骤找到全局最小值。</p><p id="1fde" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们构造一个函数<em class="lu"> c </em> ( <em class="lu"> x </em>)的假设例子，或者给定一些输入的模型的成本<em class="lu"> x </em>。当然，函数的样子对优化器来说是隐藏的；这就是<em class="lu"> c </em> ( <em class="lu"> x </em>)的真实形状。这在行话中被称为“目标函数”。</p><figure class="mk ml mm mn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mj"><img src="../Images/50349c01f5197e210fffc62083db5c31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5ImfZRh-R8vbrZzM7EC7Xg.png"/></div></div></figure><p id="6981" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">贝叶斯优化通过一种称为代理优化的方法来完成这项任务。对于上下文，代理母亲是同意为另一个人生育孩子的女性——在上下文中，代理函数是目标函数的近似。</p><p id="c6de" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">基于采样点形成代理函数。</p><figure class="mk ml mm mn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mo"><img src="../Images/e4ddc22673a333bbf05103d5610db247.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*01OV9s_DYaK8k-cwa0bk3A.png"/></div></div></figure><p id="f9eb" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">基于代理函数，我们可以识别哪些点是有希望的最小值。我们决定从这些有希望的区域中采样更多的样本，并相应地更新代理函数。</p><figure class="mk ml mm mn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mp"><img src="../Images/25efa4530c6a651e4cd41f9cee2c823b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*31TpvO5XO_VGaZG0m3FgVg.png"/></div></div></figure><p id="5a35" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">每次迭代，我们继续查看当前的代理函数，通过采样了解更多感兴趣的领域，并更新函数。注意，替代函数将以评估成本低得多的方式进行数学表达(例如，<code class="fe mq mr ms mt b"><em class="lu">y</em>=<em class="lu">x</em></code>是更高成本函数的近似值，<code class="fe mq mr ms mt b"><em class="lu">y=</em>arcsin((1-cos²<em class="lu">x</em>)/sin <em class="lu">x</em>)</code>在一定范围内)。</p><p id="5a18" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">经过一定次数的迭代后，我们注定会达到一个全局最小值，除非函数的形状非常<em class="lu">怪异(因为它有很大且疯狂的上下波动),这时应该问一个比优化更好的问题:你的数据有什么问题？</em></p><p id="58c3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">花点时间惊叹这种方法的美妙之处。它不对函数做任何假设(除了它首先是可优化的)，不需要关于导数的信息，并且能够通过巧妙使用不断更新的近似函数来使用常识推理。我们最初的目标函数的昂贵的评价根本不是问题。</p><p id="ac2b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是一种基于代理的优化方法。那么到底是什么让它成为贝叶斯的呢？</p><p id="bcd3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae jg" rel="noopener" target="_blank" href="/the-most-fundamental-and-controversial-debate-in-statistics-and-data-science-e8dd1bad737a?source=your_stories_page---------------------------">贝叶斯统计</a>和建模的本质是根据新信息更新先前(先前)的信念，以产生更新的后验(“后”)信念。这正是代理优化在这种情况下所做的，所以它可以通过贝叶斯系统、<a class="ae jg" rel="noopener" target="_blank" href="/bayes-theorem-is-actually-an-intuitive-fraction-5f2803998006?source=your_stories_page---------------------------">公式</a>和想法来最好地表示。</p><p id="24cf" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们更仔细地看看代理函数，它通常由高斯过程表示，可以认为是掷骰子，返回符合给定数据点(如 sin、log)的函数，而不是数字 1 到 6。该过程返回几个函数，这些函数都带有概率。</p><figure class="mk ml mm mn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mu"><img src="../Images/821f1b661e2d7d281892243a6c7ceea5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*09NmB3U7dZ8bvU81.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">左图:四个数据点的几个高斯过程生成函数。右图:聚合的函数。来源:<a class="ae jg" rel="noopener" target="_blank" href="/an-intuitive-guide-to-gaussian-processes-ec2f0b45c71d">奥斯卡 Knagg </a>，图片免费分享。</p></figure><p id="bd26" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae jg" rel="noopener" target="_blank" href="/an-intuitive-guide-to-gaussian-processes-ec2f0b45c71d">Oscar Knagg 的这篇文章</a>对 GPs 如何工作给出了很好的直觉。</p><p id="bdc7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">有一个很好的理由为什么高斯过程，而不是一些其他的曲线拟合方法，被用来模拟代理函数:它是贝叶斯本质。GP 是一个概率分布，就像一个事件的最终结果的分布(例如，1/2 的机会掷硬币)，但是在所有可能的函数上。</p><p id="9b78" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，我们可以将当前数据集定义为 40%可由函数<em class="lu"> a </em> ( <em class="lu"> x </em>)表示，10%可由函数<em class="lu"> b </em> ( <em class="lu"> x </em>)表示，等等。通过将替代函数表示为概率分布，它可以通过固有的概率贝叶斯过程用新信息更新。也许当引入新信息时，函数<em class="lu"> a </em> ( <em class="lu"> x </em>)只能表示 20%的数据。这些变化由<a class="ae jg" rel="noopener" target="_blank" href="/bayes-theorem-is-actually-an-intuitive-fraction-5f2803998006">贝叶斯公式</a>控制。</p><p id="82a0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">比方说，用多项式回归拟合新的数据点，这将是困难的，甚至是不可能的。</p><p id="f2bd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">代理函数——表示为概率分布，先验——用“获取函数”更新。在探索和开发的权衡中，该功能负责驱动新的测试点的提议:</p><ul class=""><li id="0333" class="lv lw jj la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated"><em class="lu">利用</em>寻求在替代模型预测有良好目标的地方进行采样。这是利用已知的有希望的地点。然而，如果我们已经对某个区域进行了足够的探索，那么继续利用已知的信息将会收效甚微。</li><li id="21b8" class="lv lw jj la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated"><em class="lu">勘探</em>寻求在不确定性高的地方取样。这确保了空间中没有一个主要区域是未被探索的——全局最小值可能碰巧就在那里。</li></ul><p id="5ffe" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">鼓励过多开发和过少探索的获取函数将导致模型只停留在它首先找到的最小值(通常是局部的——“只去有光的地方”)。首先，一个鼓励对立面的获取函数不会停留在局部或全局的最小值。在微妙的平衡中产生好的结果。</p><p id="951b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">获取函数，我们将把它表示为<em class="lu"> a </em> ( <em class="lu"> x </em>)，必须同时考虑开采和勘探。常见的获取函数包括预期改善和最大改善概率，所有这些都是在给定先验信息(高斯过程)的情况下，测量特定输入在未来可能产生回报的概率。</p><p id="f2e0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们把这些碎片拼在一起。贝叶斯优化可以这样执行:</p><ol class=""><li id="6a17" class="lv lw jj la b lb lc le lf lh lx ll ly lp lz lt mv mb mc md bi translated">初始化高斯过程“代理函数”先验分布。</li><li id="df56" class="lv lw jj la b lb me le mf lh mg ll mh lp mi lt mv mb mc md bi translated">选择几个数据点<em class="lu"> x </em>，使得对当前先验分布进行操作的采集函数<em class="lu"> a </em> ( <em class="lu"> x </em>)最大化。</li><li id="c225" class="lv lw jj la b lb me le mf lh mg ll mh lp mi lt mv mb mc md bi translated">评估目标成本函数<em class="lu"> c </em> ( <em class="lu"> x </em>)中的数据点<em class="lu"> x </em>并获得结果，<em class="lu"> y </em>。</li><li id="3337" class="lv lw jj la b lb me le mf lh mg ll mh lp mi lt mv mb mc md bi translated">用新数据更新高斯过程先验分布以产生后验分布(它将成为下一步中的先验)。</li><li id="a94d" class="lv lw jj la b lb me le mf lh mg ll mh lp mi lt mv mb mc md bi translated">重复步骤 2–5，进行多次迭代。</li><li id="cc4e" class="lv lw jj la b lb me le mf lh mg ll mh lp mi lt mv mb mc md bi translated">解释当前的高斯过程分布(这样做很便宜)以找到全局最小值。</li></ol><p id="a35c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">贝叶斯优化就是把概率的想法放在代理优化的想法后面。这两个想法的结合创造了一个具有许多应用的强大系统，从<a class="ae jg" href="https://link.springer.com/article/10.1007/s12247-019-09382-8" rel="noopener ugc nofollow" target="_blank">药物产品开发</a>到<a class="ae jg" href="https://www.youtube.com/watch?v=yeDGP5yKzf8" rel="noopener ugc nofollow" target="_blank">自动驾驶汽车</a>。</p><p id="7b94" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然而，在机器学习中最常见的是，<a class="ae jg" rel="noopener" target="_blank" href="/4-python-automl-libraries-every-data-scientist-should-know-680ff5d6ad08">贝叶斯优化用于超参数优化</a>。例如，如果我们正在训练一个梯度推进分类器，有几十个参数，从学习率到最大深度到最小杂质分裂值。在这种情况下，<em class="lu"> x </em>表示模型的超参数，<em class="lu"> c </em> ( <em class="lu"> x </em>)表示模型的性能，给定超参数<em class="lu"> x. </em></p><p id="e645" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用贝叶斯优化的主要动机是在评估输出非常昂贵的情况下。首先，需要用这些参数构建一个完整的树集合，其次，它们需要运行几次预测，这对集合来说是昂贵的。</p><p id="970d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">可以说，对于给定的一组参数，神经网络评估损失更快:简单地重复矩阵乘法，这非常快，尤其是在专用硬件上。这是使用梯度下降的原因之一，梯度下降会进行重复查询以了解它的去向。</p><p id="ee52" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">总而言之:</p><ul class=""><li id="fc32" class="lv lw jj la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated">代理优化使用代理或近似函数，通过采样来估计目标函数。</li><li id="5784" class="lv lw jj la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">贝叶斯优化通过将代理函数表示为概率分布，将代理优化置于概率框架中，概率分布可以根据新信息进行更新。</li><li id="c1a3" class="lv lw jj la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">获取函数用于评估探索空间中某一点将产生“良好”回报的概率，给出当前已知的先验知识，平衡探索与开发。</li><li id="9d6f" class="lv lw jj la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">当目标函数的评估成本很高时，主要使用贝叶斯优化，通常用于超参数调整。(这个有很多像 HyperOpt 这样的库。)</li></ul><p id="575b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">感谢阅读！</p><div class="is it gp gr iu mw"><a rel="noopener follow" target="_blank" href="/monte-carlo-methods-made-simple-91758ba58dde"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd jk gy z fp nb fr fs nc fu fw ji bi translated">蒙特卡罗方法，变得简单</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">用混乱来寻找清晰</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">towardsdatascience.com</p></div></div><div class="nf l"><div class="ng l nh ni nj nf nk ja mw"/></div></div></a></div><p id="464e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lu">除非另有说明，所有图片均由作者创作。</em></p></div></div>    
</body>
</html>