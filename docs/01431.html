<html>
<head>
<title>Working with Unbalanced Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用不平衡的数据集</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/working-with-unbalanced-dataset-8405465630d7?source=collection_archive---------23-----------------------#2020-02-08">https://towardsdatascience.com/working-with-unbalanced-dataset-8405465630d7?source=collection_archive---------23-----------------------#2020-02-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="206c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">SMOTE 简介</h2></div><p id="3fd6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在建立机器学习模型时会遇到的一个典型问题是处理不平衡的数据集，其中感兴趣的标签非常少，即欺诈检测。在有偏见的数据集上直接应用机器学习模型可能会在少数标签的预测方面得到不好的结果。原因很简单，因为模型很少看到小类的训练样本，当然，当看不见的数据点出现时，它很难区分它们。</p><p id="82fe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了解决由不平衡数据集引入的问题，需要更多次类的数据点。除了通用方法，如上采样和下采样，SMOTE 可能是一个更聪明的选择，因为它通过简单地重复现有的数据点来生成数据点。在本帖中，让我们走进 SMOTE 的逻辑，通过直观地看到样本生成来更好地理解。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi le"><img src="../Images/f7fb24006c49ad36246cf90936f263d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*hBGFqMcg_VoViuuvgCIngw.jpeg"/></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">来源:<a class="ae lq" href="https://www.nexsoftsys.com/articles/what-is-imbalanced-data.html" rel="noopener ugc nofollow" target="_blank">https://www . nexsoftsys . com/articles/what-is-unbalanced-data . html</a></p></figure></div><div class="ab cl lr ls hx lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="im in io ip iq"><h1 id="8df8" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">SMOTE 的想法</h1><p id="503e" class="pw-post-body-paragraph ki kj it kk b kl mq ju kn ko mr jx kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">SMOTE，也称为合成少数过采样技术，顾名思义，是一种对少数类进行过采样的技术。它遵循以下步骤:</p><ol class=""><li id="1640" class="mv mw it kk b kl km ko kp kr mx kv my kz mz ld na nb nc nd bi translated">对于每个少数类，找到它的 k-最近邻</li><li id="6e81" class="mv mw it kk b kl ne ko nf kr ng kv nh kz ni ld na nb nc nd bi translated">从它的一个邻居中选择，并在邻居和原始点之间画一条线</li><li id="086b" class="mv mw it kk b kl ne ko nf kr ng kv nh kz ni ld na nb nc nd bi translated">在直线上随机选择一个点(相当于选择一个介于 0 和 1 之间的比率参数，并应用该比率来获得两点之间的一个点)</li><li id="1727" class="mv mw it kk b kl ne ko nf kr ng kv nh kz ni ld na nb nc nd bi translated">重复操作，直到达到预期的样本数量</li></ol><p id="963f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以逻辑基本上是线性的，<strong class="kk iu">所有生成的样本实际上都是现有样本的线性组合。</strong></p><h1 id="927b" class="ly lz it bd ma mb nj md me mf nk mh mi jz nl ka mk kc nm kd mm kf nn kg mo mp bi translated">示范</h1><p id="6a44" class="pw-post-body-paragraph ki kj it kk b kl mq ju kn ko mr jx kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">为了清楚地了解这些点是如何产生的，让我们用一个例子来形象化这个过程。</p><p id="9556" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，让我们创建一个不平衡的数据集:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="a2ba" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">看起来像是:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/a3f8381a2a1687a2bb0407047df19925.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*3L0Eo1AAMBUvqe8mO9JkwA.png"/></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">不平衡数据集</p></figure><p id="1b58" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中标签 0 的红点是少数。</p><p id="9033" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了使用 SMOTE 进行上采样，我们可以使用现有的 python 包<a class="ae lq" href="https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html" rel="noopener ugc nofollow" target="_blank">这里是</a>:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="7fc6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中<code class="fe nr ns nt nu b">k_neighbors</code>是上面描述的要选择的邻居的数量，并且<code class="fe nr ns nt nu b">sampling_strategy = 0.2</code>告诉算法将少数标签采样到<code class="fe nr ns nt nu b">0.2 x 90 = 18</code>。</p><p id="84f8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们将生成的点可视化，</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="no np l"/></div></figure><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/562b47fafe7b5502de14450c85142822.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*0-6PCs6lsXc6NKmnCJcuNg.png"/></div></figure><p id="b256" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">橙色的点是合成的。你可以注意到，所有这些点实际上都位于原始点的直线之间。更清晰的演示可能是这样的:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="nw nx di ny bf nz"><div class="gh gi nv"><img src="../Images/f8b17ae75baf03b344a58b398f2cf9dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m1pmL4jkEzdv4dw_cZPxjw.png"/></div></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">来源:<a class="ae lq" href="http://rikunert.com/SMOTE_explained" rel="noopener ugc nofollow" target="_blank">http://rikunert.com/SMOTE_explained</a></p></figure><p id="8a1b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上图显示，所有合成实例都是现有实例的线性组合(此处<a class="ae lq" href="https://github.com/MJeremy2017/Machine-Learning-Models/tree/master/SMOTE" rel="noopener ugc nofollow" target="_blank">代码为</a>)。</p><p id="7bec" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后说一下 SMOTE 的一些缺点。首先，最初的 SMOTE 不支持分类特征。如您所见，合成数据是由原始数据的线性组合生成的，因此分类特征不适合这种情况。这里讨论<a class="ae lq" href="https://stackoverflow.com/questions/47655813/oversampling-smote-for-binary-and-categorical-data-in-python" rel="noopener ugc nofollow" target="_blank">类似的问答</a>。第二，小类可能不是简单的线性组合，在这种情况下，SMOTE 对预测没有帮助。</p><p id="6381" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">参考:</p><p id="0c40" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[1]http://rikunert.com/SMOTE_explained<a class="ae lq" href="http://rikunert.com/SMOTE_explained" rel="noopener ugc nofollow" target="_blank"/></p><p id="1a31" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[2]<a class="ae lq" href="https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis#SMOTE" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/wiki/over sampling _ and _ under sampling _ in _ data _ analysis # SMOTE</a></p></div></div>    
</body>
</html>