<html>
<head>
<title>NLP: Building Text Cleanup and PreProcessing Pipeline</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP:构建文本清理和预处理管道</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/nlp-building-text-cleanup-and-preprocessing-pipeline-eba4095245a0?source=collection_archive---------8-----------------------#2020-04-05">https://towardsdatascience.com/nlp-building-text-cleanup-and-preprocessing-pipeline-eba4095245a0?source=collection_archive---------8-----------------------#2020-04-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/44ddce069f4e85dd4482c4758306ab41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Tq5XKahZyvcwArjU"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">马克·拉斯姆森在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><div class=""/><p id="6af3" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">自然语言处理，简称NLP，是研究语言学和人类语言的机器学习/人工智能的子领域。NLP处理计算机和人类语言之间的交互。换句话说，它使计算机能够理解人类语言，并对计算机进行编程，处理和分析大量的自然语言数据。</p><p id="ef7f" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但在计算机程序能够理解和解释人类语言之前，大量的预处理工作都是在幕后进行的。你有没有想过情感分析、文本分类、推文分析等等的幕后发生了什么？？由于预处理，程序可以很容易地将语言或文本转换成更易于吸收的形式，以便机器学习算法可以更好地执行。</p><p id="b028" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这些最常用于情感分析、反馈分类、翻译、摘要等。在许多情况下，预处理步骤提高了算法的准确性。通常，输入数据以自然形式呈现，即文本、句子、评论、段落、推文等格式。在这种输入可以被传递给机器学习算法之前，它需要一些清理或预处理，以便算法可以专注于主要/重要的单词，而不是增加最小价值或没有价值的单词。<br/>说够了，让我们深入探讨NLP预处理技术。在这个例子中，我使用python作为编程语言。</p><h1 id="5f14" class="le lf jj bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated"><strong class="ak">移除HTML标签</strong></h1><p id="89db" class="pw-post-body-paragraph kg kh jj ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">通常，非结构化的文本包含许多噪音，尤其是当您使用web或屏幕抓取等技术时。HTML标签通常是对理解和分析文本没有太大价值的组件之一，因此应该删除。我们将使用<em class="mh"> BeautifulSoup </em>库来清理HTML标签。</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="8c80" class="mr lf jj mn b gy ms mt l mu mv"># imports<br/>from bs4 import BeautifulSoup</span><span id="ed9f" class="mr lf jj mn b gy mw mt l mu mv"># function to remove HTML tags<br/>def remove_html_tags(text):<br/>    return BeautifulSoup(text, 'html.parser').get_text()</span><span id="aa9f" class="mr lf jj mn b gy mw mt l mu mv"># call function<br/>remove_html_tags( ‘&lt;html&gt; \<br/> &lt;h1&gt;Article Heading&lt;/h1&gt; \<br/> &lt;p&gt;First sentence of some important article. And another one. And then the last one&lt;/p&gt;&lt;/html&gt;’)</span></pre><p id="87f9" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mh">输出:</em></p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="84ec" class="mr lf jj mn b gy ms mt l mu mv">' Article Heading First sentence of some important article. And another one. And then the last one'</span></pre><h1 id="518b" class="le lf jj bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">删除重音字符</h1><p id="dc14" class="pw-post-body-paragraph kg kh jj ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">重音字符是重要的元素，用于在发音或理解过程中表示对特定单词的强调。在某些情况下，重音符号还可以澄清单词的意思，如果没有重音符号，单词的意思可能会有所不同。虽然它们在英语中的使用很有限，但是你很有可能在自由文本语料库中遇到带重音的字符/字母。诸如简历、咖啡、测试、离婚、协调、曝光、latt等词。</p><p id="fa39" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">口音可能是由某人的键盘默认设置或打字风格引起的。处理带重音的字符变得更加重要，尤其是如果你只想分析英语的话。因此，我们需要确保这些字符被转换并标准化为ASCII字符。一个简单的例子——把é转换成e。</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="18ea" class="mr lf jj mn b gy ms mt l mu mv"># imports<br/>import unicodedata</span><span id="a20c" class="mr lf jj mn b gy mw mt l mu mv"># function to remove accented characters<br/>def remove_accented_chars(text):<br/>    new_text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')<br/>    return new_text</span><span id="04b2" class="mr lf jj mn b gy mw mt l mu mv"># call function<br/>remove_accented_chars('Sómě Áccěntěd těxt. Some words such as résumé, café, prótest, divorcé, coördinate, exposé, latté.')</span></pre><p id="5ca5" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mh">输出:</em></p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="6088" class="mr lf jj mn b gy ms mt l mu mv">'Some Accented text. Some words such as resume, cafe, protest, divorce, coordinate, expose, latte.'</span></pre><h1 id="1301" class="le lf jj bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">扩张收缩</h1><p id="cd46" class="pw-post-body-paragraph kg kh jj ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">缩写是单词或音节的缩写。它们是通过从单词中去掉特定的一个或多个字母而产生的。通常不止一个单词组合成一个缩略词。在书写中，撇号被用来表示遗漏字母的位置。在英语语言/文本中，缩写经常以书面或口头形式存在。</p><p id="68f9" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在很多编辑都会默认诱导收缩。比如说<em class="mh">不要</em>要<em class="mh">不要，我要</em>要<em class="mh">我要，你要</em>要<em class="mh">你要</em>。将每个缩写转换为其扩展的原始形式有助于文本标准化。</p><p id="ac36" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了消除缩写，我利用了缩写库中可用的一组标准缩写。</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="e830" class="mr lf jj mn b gy ms mt l mu mv"># imports<br/>from contractions import CONTRACTION_MAP # from contractions.py<br/>import re </span><span id="a089" class="mr lf jj mn b gy mw mt l mu mv"># function to expand contractions<br/>def expand_contractions(text, map=CONTRACTION_MAP):<br/>    pattern = re.compile('({})'.format('|'.join(map.keys())), flags=re.IGNORECASE|re.DOTALL)<br/>    def get_match(contraction):<br/>        match = contraction.group(0)<br/>        first_char = match[0]<br/>        expanded = map.get(match) if map.get(match) else map.get(match.lower())<br/>        expanded = first_char+expanded[1:]<br/>        return expanded </span><span id="e610" class="mr lf jj mn b gy mw mt l mu mv">    new_text = pattern.sub(get_match, text)<br/>    new_text = re.sub("'", "", new_text)<br/>    return new_text</span><span id="a6d3" class="mr lf jj mn b gy mw mt l mu mv"># call function <br/>expand_contractions(“Y’all i’d contractions you’re expanded don’t think.”)</span></pre><p id="279e" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mh">输出:</em></p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="fed1" class="mr lf jj mn b gy ms mt l mu mv">'You all i would contractions you are expanded do not think.'</span></pre><p id="2cfc" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">另一种方式可以是:</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="677e" class="mr lf jj mn b gy ms mt l mu mv"># imports<br/>from pycontractions import Contractions<br/>cont = Contractions(kv_model=model)<br/>cont.load_models()</span><span id="b605" class="mr lf jj mn b gy mw mt l mu mv"># function to expand contractions<br/>def expand_contractions(text):<br/>    text = list(cont.expand_texts([text], precise=True))[0]<br/>    return text</span></pre><h1 id="ca4e" class="le lf jj bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">删除特殊字符</h1><p id="09dc" class="pw-post-body-paragraph kg kh jj ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">众所周知，特殊字符是非字母数字字符。这些字符最常见于评论、参考文献、货币数字等。这些字符对文本理解没有任何价值，而且会给算法带来干扰。幸运的是，正则表达式(<em class="mh"> regex </em>)可以用来去掉这些字符和数字。</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="49ab" class="mr lf jj mn b gy ms mt l mu mv"># imports<br/>import re</span><span id="4cde" class="mr lf jj mn b gy mw mt l mu mv"># function to remove special characters<br/>def remove_special_characters(text):<br/>    # define the pattern to keep<br/>    pat = r'[^a-zA-z0-9.,!?/:;\"\'\s]' <br/>    return re.sub(pat, '', text)<br/> <br/># call function<br/>remove_special_characters(“007 Not sure@ if this % was #fun! 558923 What do# you think** of it.? $500USD!”)</span></pre><p id="b7f2" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mh">输出:</em></p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="0e72" class="mr lf jj mn b gy ms mt l mu mv">'007 Not sure if this  was fun! 558923 What do you think of it.? 500USD!'</span></pre><h1 id="a5ff" class="le lf jj bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">移除数字</h1><p id="7e5b" class="pw-post-body-paragraph kg kh jj ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">正如您在上面看到的，文本被保留了下来。但是有时这些可能不是必需的。由于我们处理的是文本，所以数字可能不会给文本处理增加多少信息。所以，数字可以从文本中删除。我们可以使用正则表达式(<em class="mh"> regex </em>)来去掉数字。这一步可以与上一步结合，一步完成。</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="e19e" class="mr lf jj mn b gy ms mt l mu mv"># imports<br/>import re</span><span id="eb0d" class="mr lf jj mn b gy mw mt l mu mv"># function to remove numbers<br/>def remove_numbers(text):<br/>    # define the pattern to keep<br/>    pattern = r'[^a-zA-z.,!?/:;\"\'\s]' <br/>    return re.sub(pattern, '', text)<br/> <br/># call function<br/>remove_numbers(“007 Not sure@ if this % was #fun! 558923 What do# you think** of it.? $500USD!”)</span></pre><p id="5282" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mh">输出:</em></p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="db5a" class="mr lf jj mn b gy ms mt l mu mv">' Not sure if this  was fun!  What do you think of it.? USD!'</span></pre><h1 id="4543" class="le lf jj bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">删除标点符号</h1><p id="fa99" class="pw-post-body-paragraph kg kh jj ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">这可以通过删除特殊字符的步骤来实现。去掉标点符号相当容易。这可以通过使用字符串、标点符号和保留列表中没有的内容来实现。</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="a4e6" class="mr lf jj mn b gy ms mt l mu mv"># imports<br/>import string</span><span id="6102" class="mr lf jj mn b gy mw mt l mu mv"># function to remove punctuation<br/>def remove_punctuation(text):<br/>    text = ''.join([c for c in text if c not in string.punctuation])<br/>    return text</span><span id="d73c" class="mr lf jj mn b gy mw mt l mu mv"># call function<br/>remove_punctuation('Article: <a class="ae jg" href="http://twitter.com/First" rel="noopener ugc nofollow" target="_blank">@First</a> sentence of some, {important} article having lot of ~ punctuations. And another one;!')</span></pre><p id="2543" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mh">输出:</em></p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="be00" class="mr lf jj mn b gy ms mt l mu mv">'Article First sentence of some important article having lot of  punctuations And another one'</span></pre><h1 id="cef6" class="le lf jj bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">堵塞物</h1><p id="7795" class="pw-post-body-paragraph kg kh jj ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">词干化是将词尾变化/派生的单词简化为词干、词根或词根形式的过程。词干不必与原词相同。有许多方法来执行词干提取，如查找表、后缀剥离算法等。这些主要依赖于从单词的末尾截掉<em class="mh">s、【es】、【ed】、【ing】、【ly】</em>等，有时这种转换是不可取的。但是尽管如此，词干帮助我们标准化文本。</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="6067" class="mr lf jj mn b gy ms mt l mu mv"># imports<br/>import nltk</span><span id="d738" class="mr lf jj mn b gy mw mt l mu mv"># function for stemming<br/>def get_stem(text):<br/>    stemmer = nltk.porter.PorterStemmer()<br/>    text = ' '.join([stemmer.stem(word) for word in text.split()])<br/>    return text</span><span id="befa" class="mr lf jj mn b gy mw mt l mu mv"># call function<br/>get_stem("we are eating and swimming ; we have been eating and swimming ; he eats and swims ; he ate and swam ")</span></pre><p id="399d" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mh">输出:</em></p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="ba96" class="mr lf jj mn b gy ms mt l mu mv">'we are eat and swim ; we have been eat and swim ; he eat and swim ; he ate and swam'</span></pre><h1 id="c3b3" class="le lf jj bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">词汇化</h1><p id="4227" class="pw-post-body-paragraph kg kh jj ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">虽然词干化和词元化都生成词根形式的词形变化/所需单词，但词元化是词干化的高级形式。词干化可能不会产生实际的单词，而词汇化会通过使用词汇进行适当的转换，通常旨在仅删除屈折词尾，并返回单词的基本形式或词典形式，这就是所谓的词汇。</p><p id="8018" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在使用词干化之前，我们应该意识到它比词干化慢得多，所以在选择词干化或词干化之前，应该考虑性能。</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="7420" class="mr lf jj mn b gy ms mt l mu mv"># imports<br/>import spacy<br/>nlp = spacy.load('en',parse=True,tag=True, entity=True)</span><span id="249e" class="mr lf jj mn b gy mw mt l mu mv"># function to remove special characters<br/>def get_lem(text):<br/>    text = nlp(text)<br/>    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])<br/>    return text</span><span id="e5c8" class="mr lf jj mn b gy mw mt l mu mv"># call function<br/>get_lem("we are eating and swimming ; we have been eating and swimming ; he eats and swims ; he ate and swam ")</span></pre><p id="bede" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mh">输出:</em></p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="a570" class="mr lf jj mn b gy ms mt l mu mv">'we be eat and swim ; we have be eat and swim ; he eat and swim ; he eat and swam'</span></pre><h1 id="34a7" class="le lf jj bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">删除停用词</h1><p id="8127" class="pw-post-body-paragraph kg kh jj ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">停用词经常被添加到句子中以使其语法正确，例如，<em class="mh"> a、is、an、the和</em>等词。这些停用词不太重要，在公开文本、文章、评论等中随处可见。这些应该被删除，以便机器学习算法可以更好地专注于定义文本含义/想法的单词。我们使用来自<em class="mh"> nltk.corpus </em>的列表，并且可以根据手头的情况通过添加或删除自定义单词来进一步增强该列表。</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="3e2b" class="mr lf jj mn b gy ms mt l mu mv"># imports<br/>import nltk<br/>from nltk.tokenize import ToktokTokenizer<br/>tokenizer = ToktokTokenizer()<br/>stopword_list = nltk.corpus.stopwords.words('english')<br/># custom: removing words from list<br/>stopword_list.remove('not')</span><span id="5fcb" class="mr lf jj mn b gy mw mt l mu mv"># function to remove stopwords<br/>def remove_stopwords(text):<br/>    # convert sentence into token of words<br/>    tokens = tokenizer.tokenize(text)<br/>    tokens = [token.strip() for token in tokens]<br/>    # check in lowercase <br/>    t = [token for token in tokens if token.lower() not in stopword_list]<br/>    text = ' '.join(t)    <br/>    return text</span><span id="9fb4" class="mr lf jj mn b gy mw mt l mu mv"># call function<br/>remove_stopwords("i am myself you the stopwords list and this article is not should removed")</span></pre><p id="e7fe" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">输出:</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="b84f" class="mr lf jj mn b gy ms mt l mu mv">'stopwords list article not removed'</span></pre><h1 id="b4b6" class="le lf jj bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">删除多余的空格和制表符</h1><p id="3fbf" class="pw-post-body-paragraph kg kh jj ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">额外的空格和制表符不会给文本处理添加任何信息。处理这些应该相当容易。</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="6f69" class="mr lf jj mn b gy ms mt l mu mv"># imports<br/>import re</span><span id="84a4" class="mr lf jj mn b gy mw mt l mu mv"># function to remove special characters<br/>def remove_extra_whitespace_tabs(text):<br/>    #pattern = r'^\s+$|\s+$'<br/>    pattern = r'^\s*|\s\s*'<br/>    return re.sub(pattern, ' ', text).strip()</span><span id="327e" class="mr lf jj mn b gy mw mt l mu mv"># call function<br/>remove_extra_whitespace_tabs('  This web line  has \t some extra  \t   tabs and whitespaces  ')</span></pre><p id="aacf" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">输出:</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="c021" class="mr lf jj mn b gy ms mt l mu mv">'This web line has some extra tabs and whitespaces'</span></pre><h1 id="95cd" class="le lf jj bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">小写字母</h1><p id="f354" class="pw-post-body-paragraph kg kh jj ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">使用lower函数可以将大小写改为小写。</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="4df1" class="mr lf jj mn b gy ms mt l mu mv"># function to remove special characters<br/>def to_lowercase(text):<br/>    return text.lower()</span><span id="474f" class="mr lf jj mn b gy mw mt l mu mv"># call function<br/>to_lowercase('ConVert THIS string to LOWER cASe.')</span></pre><p id="cb99" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">输出:</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="5aba" class="mr lf jj mn b gy ms mt l mu mv">'convert this string to lower case.'</span></pre><h1 id="d832" class="le lf jj bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">结论</h1><p id="f4f9" class="pw-post-body-paragraph kg kh jj ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">这些步骤中的一些可以合并在一个步骤中。此外，请注意，根据上下文和要求，其中一些可能不是必需的。此外，我们可以定义一个新的函数来封装所有上述预处理函数，以形成一个文本规范化器管道。这些步骤应该能让您很好地了解如何构建清理和预处理策略。经过这些预处理步骤后，文本集就可以用于NLP算法，如<em class="mh"> Word2Vec、GloVe </em>等。这些预处理步骤肯定会提高模型的准确性。</p><p id="66f9" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">希望你喜欢这篇文章，如果是的话，请在评论中说出来。如果你想分享关于任何方法的任何建议，请在评论中畅所欲言，我会马上回复。</p></div></div>    
</body>
</html>