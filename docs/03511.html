<html>
<head>
<title>Hyperparameter Analysis for Classification of Retinal OCT Images</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于视网膜 OCT 图像分类的超参数分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/hyperparameter-analysis-for-classification-of-retinal-oct-images-94254f67d914?source=collection_archive---------50-----------------------#2020-04-02">https://towardsdatascience.com/hyperparameter-analysis-for-classification-of-retinal-oct-images-94254f67d914?source=collection_archive---------50-----------------------#2020-04-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9b63" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">通过使用 Monk，一个低代码深度学习工具和计算机视觉的统一包装器，使您的分类模型更好</h2></div><p id="f544" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">超参数是在系统的训练过程之前指定的预定义参数。这些参数通常包括时期数、学习率和优化器等。它们识别机器学习模型的整体属性，并且可以被调整以控制机器学习算法的行为。</p><p id="7d29" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此很容易猜测，设置最佳超参数意味着从您的模型中获得最大收益。通常，超参数优化涉及独立的过程，如 GridSearchCV 和 RandomizedSearchCV。在这里，我将向您展示优化超参数的最简单方法，使用 Monk 库中的内置函数。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi le"><img src="../Images/3414584194c68f0aab05b69d85980ca5.png" data-original-src="https://miro.medium.com/v2/resize:fit:348/format:webp/0*L89VaHIwePOkAb3z.png"/></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">CNV 受影响的眼睛的十月</p></figure><p id="b7fb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">视网膜光学相干断层扫描(OCT)是一种用于捕捉活着的患者的视网膜的高分辨率横截面的成像技术，并且这些图像的分析和解释占用了大量时间。我们的工作是将这些 OCT 图像分类为正常或 3 种疾病类型之一，即玻璃疣、CNV 或 DME。</p></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h1 id="7296" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">目录</h1><ol class=""><li id="76df" class="mp mq it kk b kl mr ko ms kr mt kv mu kz mv ld mw mx my mz bi translated"><strong class="kk iu">安装</strong></li><li id="4412" class="mp mq it kk b kl na ko nb kr nc kv nd kz ne ld mw mx my mz bi translated"><strong class="kk iu">建立模型</strong></li><li id="1c44" class="mp mq it kk b kl na ko nb kr nc kv nd kz ne ld mw mx my mz bi translated"><strong class="kk iu">超参数分析</strong></li><li id="6edc" class="mp mq it kk b kl na ko nb kr nc kv nd kz ne ld mw mx my mz bi translated"><strong class="kk iu">验证和推理</strong></li></ol></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h1 id="f3d0" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">装置</h1><p id="3361" class="pw-post-body-paragraph ki kj it kk b kl mr ju kn ko ms jx kq kr nf kt ku kv ng kx ky kz nh lb lc ld im bi translated">安装 Monk，一个低代码深度学习工具，也是计算机视觉的统一包装器。</p><p id="756d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">注意<em class="ni"> : </em> </strong> <em class="ni">我将在 Kaggle 上运行我的笔记本，我将使用的数据集是</em><a class="ae nj" href="https://www.kaggle.com/paultimothymooney/kermany2018" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/paultimothymooney/kermany2018</a><em class="ni">因此我将安装来自 Monk 的 Kaggle 需求。如果您希望在启用 CUDA 的系统上运行它，那么您应该安装 cu9 需求或 cu10 需求</em></p><pre class="lf lg lh li gt nk nl nm nn aw no bi"><span id="5965" class="np ly it nl b gy nq nr l ns nt"><em class="ni"># Cloning the monk repository</em><br/>$ git clone <a class="ae nj" href="https://github.com/Tessellate-Imaging/monk_v1.git" rel="noopener ugc nofollow" target="_blank">https://github.com/Tessellate-Imaging/monk_v1.git</a><em class="ni"> </em></span><span id="abe9" class="np ly it nl b gy nu nr l ns nt"><em class="ni"># Installing the dependencies for Kaggle required by Monk</em><br/>$ pip install -r monk_v1/installation/Misc/requirements_kaggle.txt</span></pre><p id="f684" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您想在自己的系统上运行它，请将第二行替换为，</p><pre class="lf lg lh li gt nk nl nm nn aw no bi"><span id="ed5f" class="np ly it nl b gy nq nr l ns nt"><em class="ni"># Installing the dependencies for CUDA 9 required by Monk</em><br/>$ pip install -r monk_v1/installation/Linux/requirements_cu9.txt</span><span id="f72b" class="np ly it nl b gy nu nr l ns nt"><em class="ni"># Installing the dependencies for CUDA 10 required by Monk</em><br/>$ pip install -r monk_v1/installation/Linux/requirements_cu10.txt</span></pre></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h1 id="dad6" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">建立模型</h1><p id="4be9" class="pw-post-body-paragraph ki kj it kk b kl mr ju kn ko ms jx kq kr nf kt ku kv ng kx ky kz nh lb lc ld im bi translated">首先，我们将为我们的模型选择后端，在这种情况下，我将使用 MXNet 后端，</p><pre class="lf lg lh li gt nk nl nm nn aw no bi"><span id="4676" class="np ly it nl b gy nq nr l ns nt">$ from gluon_prototype import prototype</span></pre><p id="14d9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，我们继续为我们的培训、测试和验证数据集定义路径。在我的例子中，它们在我的 Kaggle 工作目录中，在你的例子中，只需将路径粘贴到数据集中相应的文件夹中。</p><p id="33bd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们需要初始化我们的 Monk 原型，它将为项目建立一个工作目录</p><pre class="lf lg lh li gt nk nl nm nn aw no bi"><span id="d0e0" class="np ly it nl b gy nq nr l ns nt">$ gtf = prototype(verbose=1)<br/>$ gtf.Prototype("Retina-OCT", "Hyperparameter-Analyser")</span></pre><p id="86bb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在可以用期望的基本模型、时期数和训练数据的位置来设置原型</p><pre class="lf lg lh li gt nk nl nm nn aw no bi"><span id="3f6b" class="np ly it nl b gy nq nr l ns nt">$ gtf.Default(dataset_path=train_path,<br/>           model_name="densenet121",<br/>           freeze_base_network=False,<br/>           num_epochs=5)</span></pre><p id="1aff" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">总之，设置的代码应该如下所示</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nv nw l"/></div></figure><div class="lf lg lh li gt ab cb"><figure class="nx lj ny nz oa ob oc paragraph-image"><img src="../Images/1dcefe7b0aee5105daaaeaf8305e2175.png" data-original-src="https://miro.medium.com/v2/resize:fit:368/format:webp/0*QKJkySqswPTn6Ar_.png"/></figure><figure class="nx lj od nz oa ob oc paragraph-image"><img src="../Images/6e37afa238e573ee9dc4c53c09600855.png" data-original-src="https://miro.medium.com/v2/resize:fit:370/format:webp/0*8MEY2HNlQ0jbBK7d.png"/><p class="lm ln gj gh gi lo lp bd b be z dk oe di of og translated"><strong class="bd oh">正常眼的 OCT 对比 DME 患眼的 OCT</strong></p></figure></div></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h1 id="a71c" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">超参数分析</h1><p id="a323" class="pw-post-body-paragraph ki kj it kk b kl mr ju kn ko ms jx kq kr nf kt ku kv ng kx ky kz nh lb lc ld im bi translated">转到主要焦点，优化我们模型的超参数。调整超参数对模型的性能有明显的影响，因此优化是必要的。</p><p id="66f5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将使用 Monk 的内置超参数分析仪，这使我们的工作变得非常容易。首先，给分析项目起一个名字，并定义您想要分析的所有超参数。</p><p id="dd70" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在 Monk 的内置超参数分析器中，您可以选择分析以下超参数:</p><ol class=""><li id="5f75" class="mp mq it kk b kl km ko kp kr oi kv oj kz ok ld mw mx my mz bi translated"><strong class="kk iu">学习率</strong> : <em class="ni">控制模型适应问题的速度</em></li><li id="2dcc" class="mp mq it kk b kl na ko nb kr nc kv nd kz ne ld mw mx my mz bi translated"><strong class="kk iu">批量</strong> : <em class="ni">指训练</em>的一次迭代中抽取的样本数</li><li id="1fdb" class="mp mq it kk b kl na ko nb kr nc kv nd kz ne ld mw mx my mz bi translated"><strong class="kk iu">优化器</strong> : <em class="ni">更新权重参数以最小化损失函数</em></li></ol><p id="f5c1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您还可以分析历元数、输入大小和基础模型。</p><pre class="lf lg lh li gt nk nl nm nn aw no bi"><span id="783d" class="np ly it nl b gy nq nr l ns nt"># Analysis Project Name</span><span id="1972" class="np ly it nl b gy nu nr l ns nt">$ analysis_name = "analyse_hyperparameters"<br/>$ lrs = [0.1, 0.05, 0.01, 0.005, 0.0001] # learning rates<br/>$ batch_sizes = [2, 4, 8, 12] # Batch sizes<br/>$ models = [["densenet121", False, True], ["densenet169", False, True], ["densenet201", False, True]] # models<br/>$ optimizers = ["sgd", "adam", "adagrad"] # optimizers<br/>$ epochs=10 # number of epochs<br/>$ percent_data=5 # percent of data to use</span></pre><p id="74b2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要分析每个超参数，使用内置函数开始分析，并输入与该超参数对应的列表。因此，如果您从学习率的分析开始，输入将是学习率列表<em class="ni"> lrs </em></p><pre class="lf lg lh li gt nk nl nm nn aw no bi"><span id="383a" class="np ly it nl b gy nq nr l ns nt"><em class="ni"># Analysis of learning rates</em><br/>$ analysis = gtf.Analyse_Learning_Rates(analysis_name,lrs,<br/>           percent_data,num_epochs=epochs, state="keep_none")</span></pre><p id="c1ad" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以为了分析所有的超参数</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nv nw l"/></div></figure></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h1 id="905d" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">验证和推理</h1><p id="ba2e" class="pw-post-body-paragraph ki kj it kk b kl mr ju kn ko ms jx kq kr nf kt ku kv ng kx ky kz nh lb lc ld im bi translated">现在我们的模型已经完全优化了，我们可以用它来验证和推断我们的验证和测试数据集。</p><p id="3505" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当然，在这之前，我们需要训练我们的模型。Monk 中的训练过程再简单不过了，它只是一行代码。</p><pre class="lf lg lh li gt nk nl nm nn aw no bi"><span id="1e89" class="np ly it nl b gy nq nr l ns nt">$ gtf.Train()</span></pre><p id="5a90" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在等待该培训完成后，我们可以继续获取该模型的准确性。因此，我们再次初始化我们的原型，但是这次用<em class="ni"> infer-eval </em>标志为真，这样模型就处于预测模式。</p><pre class="lf lg lh li gt nk nl nm nn aw no bi"><span id="c7bf" class="np ly it nl b gy nq nr l ns nt"># Set flag eval_infer as True <br/>$ gtf = prototype(verbose=1)<br/>$ gtf.Prototype("Retina-OCT","Hyperparameter-Analyser", <br/>              eval_infer = True)</span></pre><p id="68c9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">加载验证数据集，对整个数据集运行预测并显示结果</p><pre class="lf lg lh li gt nk nl nm nn aw no bi"><span id="4838" class="np ly it nl b gy nq nr l ns nt"># Load the validation dataset <br/>$ gtf.Dataset_Params(dataset_path=val_path)<br/>$ gtf.Dataset()# Run validation<br/>$ accuracy, class_based_accuracy = gtf.Evaluate()</span></pre><p id="a889" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，我们将对测试图像运行一个样本推断，然后对整个测试数据集进行预测</p><pre class="lf lg lh li gt nk nl nm nn aw no bi"><span id="08a8" class="np ly it nl b gy nq nr l ns nt"># Running sample inference</span><span id="200f" class="np ly it nl b gy nu nr l ns nt">$ img_name = test_path +"/DRUSEN/DRUSEN-1786810-3.jpeg"<br/>$ predictions = gtf.Infer(img_name=img_name)#Display <br/>$ from IPython.display import Image<br/>$ Image(filename=img_name)# Load the test dataset<br/>$ gtf.Dataset_Params(dataset_path=test_path)<br/>$ gtf.Dataset()# Run inference on test data<br/>$ accuracy, class_based_accuracy = gtf.Evaluate()</span></pre><p id="8f55" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">推断和验证的完整代码看起来有点像这样</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nv nw l"/></div></figure></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h1 id="2239" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">结果</h1><p id="71d8" class="pw-post-body-paragraph ki kj it kk b kl mr ju kn ko ms jx kq kr nf kt ku kv ng kx ky kz nh lb lc ld im bi translated">优化后的模型给出了惊人的结果，在验证数据集上的准确率为<em class="ni"> 100% </em>！</p><pre class="lf lg lh li gt nk nl nm nn aw no bi"><span id="7e80" class="np ly it nl b gy nq nr l ns nt">Result<br/>        class based accuracies<br/>            0. CNV - 100.0 %<br/>            1. DME - 100.0 %<br/>            2. DRUSEN - 100.0 %<br/>            3. NORMAL - 100.0 %<br/>        total images:            32<br/>        num correct predictions: 32<br/>        Average accuracy (%):    100.0</span></pre><p id="7499" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是一个关于测试图像的示例推断，</p><pre class="lf lg lh li gt nk nl nm nn aw no bi"><span id="11b0" class="np ly it nl b gy nq nr l ns nt">Prediction<br/>    Image name:         ../input/kermany2018/OCT2017 /test/DRUSEN/DRUSEN-1786810-3.jpeg<br/>    Predicted class:      DRUSEN<br/>    Predicted score:      5.612982273101807</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/c9322ac094b8e9bbeef83ed162a467aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/0*ASfcQuYQIZvpj_0z.jpeg"/></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">玻璃疣受累眼的 OCT</p></figure><p id="eeb7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在测试数据集上给出了 99.17% 的准确率。</p></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><p id="2459" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可以在<a class="ae nj" href="https://www.kaggle.com/synysterjeet/retinal-oct-classification-using-monkai/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上找到完整的笔记本</p><p id="ba80" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果有任何问题，可以联系<a class="ae nj" href="https://www.linkedin.com/in/abhishek-kumar-annamraju/" rel="noopener ugc nofollow" target="_blank"> Abhishek </a>和<a class="ae nj" href="https://www.linkedin.com/in/akashdeepsingh01/" rel="noopener ugc nofollow" target="_blank"> Akash </a>。请随意联系他们。</p><p id="808b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我是<a class="ae nj" href="https://github.com/Tessellate-Imaging/Monk_Object_Detection" rel="noopener ugc nofollow" target="_blank"> Monk </a> Libraries 的开源贡献者。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="on oo di op bf oq"><div class="gh gi om"><img src="../Images/7cd253680907bb6fb5f4a4ab701c7dc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3fphGyOfYCVcw8lbSewUJw.jpeg"/></div></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">由<a class="ae nj" href="https://unsplash.com/s/photos/eye?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae nj" href="https://unsplash.com/@v2osk?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> v2osk </a>拍摄的照片</p></figure></div></div>    
</body>
</html>