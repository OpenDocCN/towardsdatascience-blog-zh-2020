# åˆ©ç”¨æœºå™¨å­¦ä¹ é¢„æµ‹é»„é‡‘ä»·æ ¼

> åŸæ–‡ï¼š<https://towardsdatascience.com/machine-learning-to-predict-gold-price-returns-4bdb0506b132?source=collection_archive---------11----------------------->

## [é»„é‡‘é¢„æµ‹](https://towardsdatascience.com/tagged/gold-price-prediction)

## ç”¨ PyCaret é¢„æµ‹é»„é‡‘ä»·æ ¼

# ä»‹ç»

åå¤šå¹´æ¥ï¼Œæˆ‘ä¸€ç›´æ˜¯é‡‘èå¸‚åœºçš„å­¦ç”Ÿï¼Œä¸€ç›´åœ¨ç ”ç©¶ä¸åŒçš„èµ„äº§ç±»åˆ«åŠå…¶åœ¨ä¸åŒç»æµæ¡ä»¶ä¸‹çš„è¡Œä¸ºã€‚å¾ˆéš¾æ‰¾åˆ°æ¯”é»„é‡‘æ›´å…·ä¸¤æåˆ†åŒ–çš„èµ„äº§ç±»åˆ«ã€‚æœ‰å–œæ¬¢å®ƒçš„äººï¼Œä¹Ÿæœ‰è®¨åŒå®ƒçš„äººï¼Œæ›´å¤šçš„æ—¶å€™ï¼Œä»–ä»¬æ°¸è¿œåœç•™åœ¨åŒä¸€ä¸ªé˜µè¥ã€‚ç”±äºé»„é‡‘æœ¬èº«æ²¡æœ‰ä»€ä¹ˆåŸºæœ¬é¢(è¿™åˆæ˜¯ä¸€ä¸ªä¸¤æåˆ†åŒ–çš„æ¥æº)ï¼Œåœ¨è¿™ä¸ªå¤šéƒ¨åˆ†ç³»åˆ—ä¸­ï¼Œæˆ‘å°†å°è¯•ä½¿ç”¨å‡ ç§æœºå™¨å­¦ä¹ æŠ€æœ¯æ¥é¢„æµ‹é»„é‡‘ä»·æ ¼å›æŠ¥ã€‚ä»¥ä¸‹æ˜¯æˆ‘(ç›®å‰)å¯¹è¯¥ç³»åˆ—çš„è®¾æƒ³:

***ç¬¬ä¸€éƒ¨åˆ†:ç¡®å®šæ–¹æ³•ï¼Œæ”¶é›†å’Œå‡†å¤‡æ•°æ®***

***ç¬¬äºŒéƒ¨åˆ†:ä½¿ç”¨ PyCaret*** çš„å›å½’å»ºæ¨¡

***ç¬¬ä¸‰éƒ¨åˆ†:ä½¿ç”¨ PyCaret*** åˆ†ç±»å»ºæ¨¡

***ç¬¬å››éƒ¨åˆ†:æ—¶é—´åºåˆ—å»ºæ¨¡ä½¿ç”¨ Prophet(è„¸ä¹¦)***

***ç¬¬äº”éƒ¨åˆ†:è¯„ä¼°æ–¹æ³•æ•´åˆ***

> â€œè¯·æ³¨æ„ï¼Œåœ¨ä¸€ä¸ªç«äº‰æå…¶æ¿€çƒˆçš„å¸‚åœºä¸­ï¼Œé»„é‡‘æ˜¯ä¸€ç§äº¤æ˜“éå¸¸å¹¿æ³›çš„èµ„äº§ã€‚é•¿æœŸä»ä»»ä½•ç­–ç•¥ä¸­æŒç»­èµšé’±æ˜¯æå…¶å›°éš¾çš„ï¼Œå¦‚æœä¸æ˜¯ä¸å¯èƒ½çš„è¯ã€‚è¿™ç¯‡æ–‡ç« åªæ˜¯åˆ†äº«æˆ‘çš„ç»éªŒï¼Œè€Œä¸æ˜¯æŠ•èµ„æˆ–äº¤æ˜“çš„å¤„æ–¹æˆ–å€¡å¯¼ã€‚ç„¶è€Œï¼Œå¯¹äºåƒæˆ‘è¿™æ ·çš„è¯¥é¢†åŸŸçš„å­¦ç”Ÿæ¥è¯´ï¼Œè¿™ä¸ªæƒ³æ³•å¯ä»¥é€šè¿‡ä¸ªäººåŠªåŠ›æ‰©å±•å’Œå‘å±•æˆäº¤æ˜“ç®—æ³•ã€‚â€

# èƒŒæ™¯

å‡ ä¸ªä¸–çºªä»¥æ¥ï¼Œé»„é‡‘ä¸€ç›´æ˜¯äººç±»æœ€åˆçš„ä»·å€¼å‚¨å­˜æ‰‹æ®µå’Œäº¤æ˜“åª’ä»‹ï¼Œç›´åˆ°å‡ ä¸ªä¸–çºªå‰çº¸å¸å–ä»£äº†é»„é‡‘ã€‚ç„¶è€Œï¼Œç›´åˆ° 1971 å¹´å¸ƒé›·é¡¿æ£®æ—åå®šè¢«åºŸé™¤ï¼Œä¸–ç•Œè´§å¸æˆä¸ºçœŸæ­£çš„â€²ğ¹ğ‘–ğ‘ğ‘¡â€²è´§å¸ä¹‹å‰ï¼Œå¤§å¤šæ•°å¯æŒç»­çš„çº¸å¸éƒ½æ˜¯ç”±é»„é‡‘æ”¯æŒçš„ã€‚

ç„¶è€Œï¼Œé»„é‡‘ä¸ä»…ä½œä¸ºç å®çš„é¦–é€‰é‡‘å±ï¼Œè€Œä¸”ä½œä¸ºä»·å€¼å‚¨å­˜æ‰‹æ®µå’Œå¤šæ ·åŒ–æŠ•èµ„ç»„åˆä¸­é€šå¸¸å¯å–çš„ä¸€éƒ¨åˆ†ï¼Œç»§ç»­å¼•èµ·äººä»¬çš„å…´è¶£ï¼Œå› ä¸ºå®ƒå¾€å¾€æ˜¯ä¸€ç§æœ‰æ•ˆçš„é€šèƒ€å¯¹å†²å’Œç»æµç»å†è‰°éš¾æ—¶æœŸçš„é¿é£æ¸¯ã€‚

# æ–¹æ³•

åœ¨è¿™ä¸ªç³»åˆ—ä¸­ï¼Œæˆ‘ä»¬å°†é‡‡ç”¨ä¸åŒçš„æ–¹æ³•æ¥é¢„æµ‹é»„é‡‘ä»·æ ¼çš„å›æŠ¥ï¼Œä½¿ç”¨**æœºå™¨å­¦ä¹ **æ­£å¦‚å¼•è¨€éƒ¨åˆ†æ‰€å¼ºè°ƒçš„

é¦–å…ˆï¼Œæˆ‘ä»¬å°†èµ°å›å½’è·¯çº¿æ¥é¢„æµ‹æœªæ¥ 2 å‘¨å’Œ 3 å‘¨çš„é»„é‡‘å›æŠ¥ã€‚æˆ‘ä»¬å°†é€šè¿‡ä½¿ç”¨ä¸åŒå·¥å…·çš„å†å²å›æŠ¥æ¥å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘è®¤ä¸ºè¿™å°†å½±å“é»„é‡‘çš„å‰æ™¯ã€‚æ ¹æœ¬åŸå› æ˜¯ï¼Œæˆ‘å°†é»„é‡‘ç§°ä¸ºä¸€ç§â€œååŠ¨â€èµ„äº§ã€‚å®ƒå‡ ä¹æ²¡æœ‰è‡ªå·±çš„åŸºæœ¬é¢ï¼Œä»·æ ¼çš„å˜åŠ¨é€šå¸¸æ˜¯æŠ•èµ„è€…å¦‚ä½•çœ‹å¾…å…¶ä»–èµ„äº§ç±»åˆ«(è‚¡ç¥¨ã€å¤§å®—å•†å“ç­‰)çš„è¡ç”Ÿå“ã€‚).

# å¯¼å…¥æ•°æ®

åœ¨æœ¬æ¬¡å’Œåç»­ç»ƒä¹ ä¸­ï¼Œæˆ‘ä»¬å°†éœ€è¦è¿‡å» 10 å¹´ä¸­å‡ ç§å·¥å…·çš„æ”¶ç›˜ä»·ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å„ç§ä»˜è´¹èµ„æº(è·¯é€ç¤¾ã€å½­åš)å’Œå…è´¹èµ„æº(IEXã€Quandlã€Yahoofinanceã€è°·æ­Œè´¢ç»)æ¥å¯¼å…¥æ•°æ®ã€‚ç”±äºè¿™ä¸ªé¡¹ç›®éœ€è¦ä¸åŒç±»å‹çš„èµ„äº§ç±»åˆ«(è‚¡ç¥¨ã€å•†å“ã€å€ºåŠ¡å’Œè´µé‡‘å±)ï¼Œæˆ‘å‘ç°**'**[***Yahoo financials***](https://pypi.org/project/yahoofinancials/)**'**è½¯ä»¶åŒ…éå¸¸æœ‰ç”¨ä¸”ç®€å•æ˜äº†ã€‚

```
***#Importing Libraries***
import pandas as pd
from datetime import datetime
import matplotlib.pyplot as plt
from yahoofinancials import YahooFinancials
```

æˆ‘å‡†å¤‡äº†ä¸€ä»½éœ€è¦å¯¼å…¥æ•°æ®çš„ä»ªå™¨æ¸…å•ã€‚***Yahoo financials***åŒ…éœ€è¦ Yahoo è‚¡ç¥¨ä»£ç ã€‚è¯¥åˆ—è¡¨åŒ…å«è‚¡ç¥¨ä»£å·åŠå…¶è¯´æ˜ã€‚åŒ…å«åˆ—è¡¨çš„ excel æ–‡ä»¶å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/Riazone/Gold-Return-Prediction/blob/master/Ticker%20List.xlsx)æ‰¾åˆ°ï¼Œæ–‡ä»¶åä¸ºâ€œTicker Listâ€ã€‚æˆ‘ä»¬å¯¼å…¥è¯¥æ–‡ä»¶ï¼Œå¹¶å°†è‚¡ç¥¨ä»£ç å’Œåç§°æå–ä¸ºå•ç‹¬çš„åˆ—è¡¨ã€‚( [*è§ç¬”è®°æœ¬*](https://github.com/Riazone/Gold-Return-Prediction/blob/master/Regression/Gold%20Prediction%20Experiment%20%20Regression-%20PyCaret.ipynb) )

```
ticker_details = pd.read_excel(â€œTicker List.xlsxâ€)
ticker = ticker_details['Ticker'].to_list()
names = ticker_details['Description'].to_list()
ticker_details.head(20)
```

![](img/c920231ca90a3548577ea2fce8aef876.png)

æœ‰äº†åˆ—è¡¨åï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰éœ€è¦å¯¼å…¥æ•°æ®çš„æ—¥æœŸèŒƒå›´ã€‚æˆ‘é€‰æ‹©çš„æœŸé™æ˜¯ 2010 å¹´ 1 æœˆè‡³ 2020 å¹´ 3 æœˆ 1 æ—¥ã€‚æˆ‘ä¹‹æ‰€ä»¥æ²¡æœ‰æå–ä¹‹å‰çš„æ•°æ®ï¼Œæ˜¯å› ä¸º 2008-09 å¹´çš„**å…¨çƒé‡‘èå±æœº(GFC)** æå¤§åœ°æ”¹å˜äº†ç»æµå’Œå¸‚åœºæ ¼å±€ã€‚é‚£æ®µæ—¶æœŸä¹‹å‰çš„å…³ç³»ç°åœ¨å¯èƒ½æ²¡é‚£ä¹ˆé‡è¦äº†ã€‚

æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæ—¥æœŸèŒƒå›´ï¼Œå¹¶å°†å…¶å†™å…¥ä¸€ä¸ªåä¸º ***values*** çš„ç©ºæ•°æ®å¸§ï¼Œæˆ‘ä»¬å°†ä» yahoofinancials ä¸­æå–å¹¶ç²˜è´´æ•°æ®ã€‚

```
***#Creating Date Range and adding them to values table***
end_date= â€œ2020â€“03â€“01â€
start_date = â€œ2010â€“01â€“01â€
date_range = pd.bdate_range(start=start_date,end=end_date)
values = pd.DataFrame({ â€˜Dateâ€™: date_range})
values[â€˜Dateâ€™]= pd.to_datetime(values[â€˜Dateâ€™])
```

ä¸€æ—¦æˆ‘ä»¬åœ¨ dataframe ä¸­æœ‰äº†æ—¥æœŸèŒƒå›´ï¼Œæˆ‘ä»¬å°±éœ€è¦ä½¿ç”¨ ticker ç¬¦å·ä» API ä¸­æå–æ•°æ®ã€‚ ***yahoofinancials*** ä»¥ JSON æ ¼å¼è¿”å›è¾“å‡ºã€‚ä¸‹é¢çš„ä»£ç å¾ªç¯éå†è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œåªæå–æ‰€æœ‰å†å²æ—¥æœŸçš„æ”¶ç›˜ä»·ï¼Œå¹¶å°†å®ƒä»¬æ·»åŠ åˆ°åœ¨æ—¥æœŸä¸Šæ°´å¹³åˆå¹¶çš„ dataframe ä¸­ã€‚é‰´äºè¿™äº›èµ„äº§ç±»åˆ«å¯èƒ½æœ‰ä¸åŒçš„åœ°åŒºå’Œäº¤æ˜“å‡æœŸï¼Œæ¯æ¬¡æ•°æ®æå–çš„æ—¥æœŸèŒƒå›´å¯èƒ½ä¸ç›¸åŒã€‚é€šè¿‡åˆå¹¶ï¼Œæˆ‘ä»¬æœ€ç»ˆä¼šæœ‰å‡ ä¸ª *NAs* ï¼Œç¨åæˆ‘ä»¬å°†*å¡«å……*ã€‚

```
***#Extracting Data from Yahoo Finance and Adding them to Values table using date as key*** for i in ticker:
 raw_data = YahooFinancials(i)
 raw_data = raw_data.get_historical_price_data(start_date, end_date, â€œdailyâ€)
 df = pd.DataFrame(raw_data[i][â€˜pricesâ€™])[[â€˜formatted_dateâ€™,â€™adjcloseâ€™]]
 df.columns = [â€˜Date1â€™,i]
 df[â€˜Date1â€™]= pd.to_datetime(df[â€˜Date1â€™])
 values = values.merge(df,how=â€™leftâ€™,left_on=â€™Dateâ€™,right_on=â€™Date1')
 values = values.drop(labels=â€™Date1',axis=1)***#Renaming columns to represent instrument names rather than their ticker codes for ease of readability***
names.insert(0,â€™Dateâ€™)
values.columns = names
print(values.shape)
print(values.isna().sum()) ***#Front filling the NaN values in the data set***
values = values.fillna(method="ffill",axis=0)
values = values.fillna(method="bfill",axis=0)
values.isna().sum()***# Coercing numeric type to all columns except Date***
cols=values.columns.drop('Date')
values[cols] = values[cols].apply(pd.to_numeric,errors='coerce').round(decimals=1)
values.tail()
```

![](img/062f5bf33aa745965aa55dea1e5413f7.png)

å€¼è¡¨çš„å°¾éƒ¨

# å‡†å¤‡æ•°æ®

åœ¨ä¸Šè¿°æ–¹æ³•ä¸­ï¼Œæˆ‘ä»¬å¼ºè°ƒäº†æˆ‘ä»¬å°†ä½¿ç”¨ä¸Šå¸‚å·¥å…·çš„æ»åå›æŠ¥æ¥é¢„æµ‹é»„é‡‘çš„æœªæ¥å›æŠ¥ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ç»§ç»­è®¡ç®—æ‰€æœ‰å·¥å…·çš„çŸ­æœŸå†å²å›æŠ¥å’Œå°‘æ•°é€‰å®šå·¥å…·çš„é•¿æœŸå†å²å›æŠ¥ã€‚

å…¶èƒŒåçš„åŸºæœ¬æ€æƒ³æ˜¯ï¼Œå¦‚æœæŸé¡¹èµ„äº§è¡¨ç°ä¼˜å¼‚æˆ–è¡¨ç°ä¸ä½³ï¼ŒæŠ•èµ„ç»„åˆé‡æ–°å¹³è¡¡çš„å¯èƒ½æ€§æ›´å¤§ï¼Œè¿™å°†å½±å“æœªæ¥å…¶ä»–èµ„äº§ç±»åˆ«çš„å›æŠ¥ã€‚å¦‚æœè‚¡ç¥¨å¸‚åœº(æ¯”å¦‚è¯´ S & P500)åœ¨è¿‡å»çš„ 6 ä¸ªæœˆä¸­è¡¨ç°å‡ºæƒŠäººçš„å›æŠ¥ï¼Œèµ„äº§ç»ç†å¯èƒ½ä¼šå¸Œæœ›è®°å½•åˆ©æ¶¦ï¼Œå¹¶åˆ†é…ä¸€äº›èµ„é‡‘åˆ°è´µé‡‘å±ä¸Šï¼Œä¸ºè‚¡ç¥¨å¸‚åœºçš„è°ƒæ•´åšå‡†å¤‡ã€‚ä¸‹å›¾æ˜¾ç¤ºäº†åœ¨ä¸åŒçš„å¸‚åœºæ¡ä»¶ä¸‹ï¼Œé»„é‡‘å’Œæ ‡æ™® 500 ä¹‹é—´çš„ä»·æ ¼å˜åŠ¨å’Œç›¸å…³æ€§ã€‚

![](img/7abd1b20cfb2730cb210b4cfe090a7c1.png)![](img/1241094ec01d835c56eed66bcf7067da.png)

èµ„æ–™æ¥æº:å½­åšã€ICE åŸºå‡†ç®¡ç†æœºæ„ã€ä¸–ç•Œé»„é‡‘åä¼šã€‚[é“¾æ¥](https://www.gold.org/goldhub/research/relevance-of-gold-as-a-strategic-asset-2019)

ä»ä¸Šé¢æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå½“ S&P500 å‡ºç°æç«¯çš„è´Ÿå‘è¿åŠ¨æ—¶ï¼Œé»„é‡‘è¡¨ç°å‡ºè´Ÿç›¸å…³æ€§ã€‚æœ€è¿‘è‚¡å¸‚çš„å¤§å¹…ä¸‹è·Œä¹Ÿå‡¸æ˜¾äº†ç±»ä¼¼çš„å…³ç³»ï¼Œå½“é‡‘ä»·å› é¢„æœŸä¸‹è·Œè€Œä¸Šæ¶¨æ—¶ï¼Œå¹´åˆè‡³ä»Šé‡‘ä»·ä¸Šæ¶¨äº† 11%ï¼Œè€Œ S&P500 å¹´åˆè‡³ä»Šä¸‹è·Œäº† 11%ã€‚

ç„¶è€Œï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æœºå™¨å­¦ä¹ æ¥è¯„ä¼°å‡è®¾ã€‚æ‚¨å¯ä»¥ç›´æ¥ä»æˆ‘çš„ [git-hub repo](https://github.com/Riazone/Gold-Return-Prediction/blob/master/Training%20Data_Values.csv) ä¸‹è½½æ–‡ä»¶åä¸ºâ€˜Training Data _ Valuesâ€™çš„æ•°å€¼æ•°æ®

```
imp = [â€˜Goldâ€™,â€™Silverâ€™, â€˜Crude Oilâ€™, â€˜S&P500â€™,â€™MSCI EM ETFâ€™]***# Calculating Short term -Historical Returns***
change_days = [1,3,5,14,21]data = pd.DataFrame(data=values[â€˜Dateâ€™])
for i in change_days:
 print(data.shape)
 x= values[cols].pct_change(periods=i).add_suffix(â€œ-T-â€+str(i))
 data=pd.concat(objs=(data,x),axis=1)
 x=[]
print(data.shape)***# Calculating Long term Historical Returns***
change_days = [60,90,180,250]for i in change_days:
 print(data.shape)
 x= values[imp].pct_change(periods=i).add_suffix(â€œ-T-â€+str(i))
 data=pd.concat(objs=(data,x),axis=1)
 x=[]
print(data.shape)
```

é™¤äº†æ»åå›æŠ¥ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥çœ‹åˆ°ä¸åŒçª—å£çš„å½“å‰é‡‘ä»·ç¦»å…¶ç§»åŠ¨å¹³å‡çº¿æœ‰å¤šè¿œã€‚è¿™æ˜¯æŠ€æœ¯åˆ†æä¸­éå¸¸å¸¸ç”¨çš„æŒ‡æ ‡ï¼Œç§»åŠ¨å¹³å‡çº¿ä¸ºèµ„äº§ä»·æ ¼æä¾›æ”¯æ’‘å’Œé˜»åŠ›ã€‚æˆ‘ä»¬ä½¿ç”¨ç®€å•ç§»åŠ¨å¹³å‡çº¿å’ŒæŒ‡æ•°ç§»åŠ¨å¹³å‡çº¿çš„ç»„åˆã€‚ç„¶åï¼Œæˆ‘ä»¬å°†è¿™äº›ç§»åŠ¨å¹³å‡å€¼æ·»åŠ åˆ°ç°æœ‰çš„ç‰¹å¾ç©ºé—´ã€‚

```
***#Calculating Moving averages for Gold***
moving_avg = pd.DataFrame(values[â€˜Dateâ€™],columns=[â€˜Dateâ€™])
moving_avg[â€˜Dateâ€™]=pd.to_datetime(moving_avg[â€˜Dateâ€™],format=â€™%Y-%b-%dâ€™)
***#Adding Simple Moving Average***
moving_avg[â€˜Gold/15SMAâ€™] = (values[â€˜Goldâ€™]/(values[â€˜Goldâ€™].rolling(window=15).mean()))-1
moving_avg[â€˜Gold/30SMAâ€™] = (values[â€˜Goldâ€™]/(values[â€˜Goldâ€™].rolling(window=30).mean()))-1
moving_avg[â€˜Gold/60SMAâ€™] = (values[â€˜Goldâ€™]/(values[â€˜Goldâ€™].rolling(window=60).mean()))-1
moving_avg[â€˜Gold/90SMAâ€™] = (values[â€˜Goldâ€™]/(values[â€˜Goldâ€™].rolling(window=90).mean()))-1
moving_avg[â€˜Gold/180SMAâ€™] = (values[â€˜Goldâ€™]/(values[â€˜Goldâ€™].rolling(window=180).mean()))-1***#Adding Exponential Moving Average*** moving_avg[â€˜Gold/90EMAâ€™] = (values[â€˜Goldâ€™]/(values[â€˜Goldâ€™].ewm(span=90,adjust=True,ignore_na=True).mean()))-1
moving_avg[â€˜Gold/180EMAâ€™] = (values[â€˜Goldâ€™]/(values[â€˜Goldâ€™].ewm(span=180,adjust=True,ignore_na=True).mean()))-1
moving_avg = moving_avg.dropna(axis=0)
print(moving_avg.shape)
moving_avg.head(20)
```

![](img/a8a242b98b0ac7b771f1406f652a1e2e.png)

ç§»åŠ¨å¹³å‡æ•°æ®å¸§çš„è¾“å‡º

```
***#Merging Moving Average values to the feature space***
data[â€˜Dateâ€™]=pd.to_datetime(data[â€˜Dateâ€™],format=â€™%Y-%b-%dâ€™)
data = pd.merge(left=data,right=moving_avg,how=â€™leftâ€™,on=â€™Dateâ€™)
print(data.shape)
data.isna().sum()
```

è¿™éƒ½æ˜¯å…³äºç‰¹æ€§çš„ã€‚ç°åœ¨æˆ‘ä»¬éœ€è¦åˆ›å»ºç›®æ ‡ï¼Œä¹Ÿå°±æ˜¯æˆ‘ä»¬æƒ³è¦é¢„æµ‹çš„ã€‚å› ä¸ºæˆ‘ä»¬åœ¨é¢„æµ‹å›æŠ¥ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦é€‰æ‹©ä¸€ä¸ªæˆ‘ä»¬éœ€è¦é¢„æµ‹å›æŠ¥çš„æ—¶é—´èŒƒå›´ã€‚æˆ‘é€‰æ‹©äº† 14 å¤©å’Œ 22 å¤©çš„æ—¶é—´èŒƒå›´ï¼Œå› ä¸ºå…¶ä»–æ›´å°çš„æ—¶é—´èŒƒå›´å¾€å¾€éå¸¸ä¸ç¨³å®šï¼Œç¼ºä¹é¢„æµ‹èƒ½åŠ›ã€‚ç„¶è€Œï¼Œä½ ä¹Ÿå¯ä»¥å°è¯•å…¶ä»–çš„åœ°å¹³çº¿ã€‚

```
***#Calculating forward returns for Target***
y = pd.DataFrame(data=values[â€˜Dateâ€™])
y[â€˜Gold-T+14â€™]=values[â€œGoldâ€].pct_change(periods=-14)
y[â€˜Gold-T+22â€™]=values[â€œGoldâ€].pct_change(periods=-22)
print(y.shape)
y.isna().sum()***# Removing NAs***

data = data[data[â€˜Gold-T-250â€™].notna()]
y = y[y[â€˜Gold-T+22â€™].notna()]***#Adding Target Variables***
data = pd.merge(left=data,right=y,how=â€™innerâ€™,on=â€™Dateâ€™,suffixes=(False,False))
print(data.shape)
```

ç°åœ¨æˆ‘ä»¬æœ‰äº†å®Œæ•´çš„æ•°æ®é›†ï¼Œå¯ä»¥å¼€å§‹å»ºæ¨¡äº†ã€‚åœ¨ä¸‹ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æå…¶åˆ›æ–°å’Œé«˜æ•ˆçš„ PyCaret åº“æ¥è¯•éªŒä¸åŒçš„ç®—æ³•ã€‚æˆ‘è¿˜å°†å±•ç¤ºå¦‚ä½•åˆ›å»ºä¸€ä¸ªç®¡é“æ¥ä¸æ–­å¯¼å…¥æ–°æ•°æ®ï¼Œä»¥ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ç”Ÿæˆé¢„æµ‹ã€‚

# åˆ©ç”¨æœºå™¨å­¦ä¹ é¢„æµ‹é»„é‡‘ä»·æ ¼

## ä½¿ç”¨ PyCaret çš„ç¬¬äºŒéƒ¨åˆ†å›å½’å»ºæ¨¡

åœ¨ç¬¬ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†ä»å¼€æºå…è´¹ API å¯¼å…¥æ•°æ®ï¼Œå¹¶ä»¥ä¸€ç§é€‚åˆæˆ‘ä»¬é¢„æœŸçš„æœºå™¨å­¦ä¹ ç»ƒä¹ çš„æ–¹å¼å‡†å¤‡å®ƒã€‚æ‚¨å¯ä»¥å‚è€ƒç¬¬ä¸€éƒ¨åˆ†çš„ä»£ç ï¼Œæˆ–è€…ä» [github repo](https://github.com/Riazone/Gold-Return-Prediction/blob/master/Training%20Data.csv) å¯¼å…¥æ–‡ä»¶åä¸ºâ€œTraining Dataâ€çš„æœ€ç»ˆæ•°æ®é›†ã€‚

PyCaret æ˜¯ Python ä¸­çš„ä¸€ä¸ªå¼€æºæœºå™¨å­¦ä¹ åº“ï¼Œå¯ä»¥åœ¨ä»»ä½•ç¬”è®°æœ¬ç¯å¢ƒä¸­ä½¿ç”¨ï¼Œå¹¶å¤§å¤§å‡å°‘äº†ç¼–ç å·¥ä½œï¼Œä½¿è¿‡ç¨‹å˜å¾—éå¸¸é«˜æ•ˆã€‚åœ¨ä¸‹é¢çš„éƒ¨åˆ†æˆ‘ä»¬å°†çœ‹åˆ°*[***py caret***](https://pycaret.org/)å¦‚ä½•ä¸ºä»»ä½•æœºå™¨å­¦ä¹ å®éªŒå¢å‹ã€‚é¦–å…ˆï¼Œæ‚¨éœ€è¦ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£… PyCaret:*

```
*!pip install pycaret*
```

## *22 å¤©æ¨¡å‹*

*æˆ‘ä»¬ä»¥ 22 å¤©ä¸ºç›®æ ‡ã€‚è¿™æ„å‘³ç€ï¼Œæ ¹æ®å†å²æ•°æ®ï¼Œæˆ‘ä»¬å°†å°è¯•é¢„æµ‹æœªæ¥ä¸‰å‘¨çš„é»„é‡‘å›æŠ¥ã€‚*

```
****#If you are importing downloaded dataset***
data = pd.read_csv("Training Data.csv")from pycaret.regression import ****#We have two target columns. We will remove the T+14 day Target*** data_22= data.drop(['Gold-T+14'],axis=1)*
```

***è®¾ç½®***

*è¦åœ¨ PyCaret ä¸­å¼€å§‹ä»»ä½•å»ºæ¨¡ç»ƒä¹ ï¼Œç¬¬ä¸€æ­¥æ˜¯â€œè®¾ç½®â€åŠŸèƒ½ã€‚è¿™é‡Œçš„å¼ºåˆ¶å˜é‡æ˜¯æ•°æ®é›†å’Œæ•°æ®é›†ä¸­çš„ç›®æ ‡æ ‡ç­¾ã€‚æ‰€æœ‰åŸºæœ¬å’Œå¿…è¦çš„æ•°æ®è½¬æ¢ï¼Œå¦‚ä¸¢å¼ƒ idã€ä¸€æ¬¡æ€§ç¼–ç åˆ†ç±»å› å­å’Œç¼ºå¤±å€¼æ’è¡¥ï¼Œéƒ½åœ¨åå°è‡ªåŠ¨è¿›è¡Œã€‚PyCaret è¿˜æä¾›äº† 20 å¤šä¸ªé¢„å¤„ç†é€‰é¡¹ã€‚å¯¹äºè¿™ä¸ªä¾‹å­ï¼Œæˆ‘ä»¬å°†åœ¨è®¾ç½®ä¸­ä½¿ç”¨åŸºç¡€çŸ¥è¯†ï¼Œå¹¶åœ¨åé¢çš„å®éªŒä¸­å°è¯•ä¸åŒçš„é¢„å¤„ç†æŠ€æœ¯ã€‚*

```
*a=setup(data_22,target='Gold-T+22',
        ignore_features=['Date'],session_id=11,
        silent=True,profile=False);*
```

*åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼Œæ•°æ®é›†ä½œä¸ºâ€œdata_22â€ä¼ é€’ï¼Œç›®æ ‡æŒ‡å‘æ ‡è®°ä¸ºâ€œGold-T+22â€çš„åˆ—ã€‚æˆ‘ç‰¹åˆ«æåˆ°è¦å¿½ç•¥â€œæ—¥æœŸâ€åˆ—ï¼Œä»¥é˜²æ­¢ PyCaret åœ¨æ—¥æœŸåˆ—ä¸Šåˆ›å»ºåŸºäºæ—¶é—´çš„åŠŸèƒ½ï¼Œè¿™åœ¨å…¶ä»–æƒ…å†µä¸‹å¯èƒ½éå¸¸æœ‰ç”¨ï¼Œä½†æˆ‘ä»¬ç°åœ¨ä¸è¯„ä¼°è¿™ä¸€ç‚¹ã€‚å¦‚æœæ‚¨æƒ³æŸ¥çœ‹å˜é‡ä¹‹é—´çš„åˆ†å¸ƒå’Œç›¸å…³æ€§ï¼Œæ‚¨å¯ä»¥ä¿ç•™å‚æ•°â€œprofile=Trueâ€ï¼Œå®ƒæ˜¾ç¤ºä¸€ä¸ª panda profiler è¾“å‡ºã€‚æˆ‘ç‰¹æ„æä¾›äº†â€˜session _ id = 11 â€™,ä»¥ä¾¿èƒ½å¤Ÿé‡æ–°åˆ›å»ºç»“æœã€‚*

***é­”æ³•å‘½ä»¤....*compare _ models()****

*ä¸‹ä¸€æ­¥ï¼Œæˆ‘å°†ä½¿ç”¨ PyCaret çš„ä¸€ä¸ªæˆ‘æœ€å–œæ¬¢çš„ç‰¹æ€§ï¼Œå®ƒå°†æ•°ç™¾è¡Œä»£ç ç¼©å‡ä¸ºä¸¤ä¸ªå­—â€”â€”â€œcompare _ modelsâ€ã€‚è¯¥å‡½æ•°ä½¿ç”¨æ‰€æœ‰ç®—æ³•(ç›®å‰æœ‰ 25 ç§)å¹¶ä½¿å®ƒä»¬é€‚åˆæ•°æ®ï¼Œè¿è¡Œ 10 é‡äº¤å‰éªŒè¯ï¼Œå¹¶ä¸ºæ¯ä¸ªæ¨¡å‹æä¾› 6 ä¸ªè¯„ä¼°æŒ‡æ ‡ã€‚æ‰€æœ‰è¿™äº›åªç”¨ä¸¤ä¸ªå­—ã€‚ä¸ºäº†èŠ‚çœæ—¶é—´ï¼Œå‡½æ•°ä¸­è¿˜å¯ä»¥ä½¿ç”¨å¦å¤–ä¸¤ä¸ªå‚æ•°:*

***a. turbo=False** â€”é»˜è®¤ä¸ºçœŸã€‚å½“ turbo=True æ—¶ï¼Œæ¯”è¾ƒæ¨¡å‹ä¸ä¼šè¯„ä¼°ä¸€äº›æ›´æ˜‚è´µçš„ç®—æ³•ï¼Œå³æ ¸è„Š(kr)ã€è‡ªåŠ¨ç›¸å…³æ€§ç¡®å®š(ard)å’Œå¤šå±‚æ„ŸçŸ¥å™¨(mlp)*

***b .é»‘åå•** â€”åœ¨è¿™é‡Œï¼Œå¯ä»¥ä¼ é€’ç®—æ³•ç¼©å†™çš„åˆ—è¡¨(å‚è§ docstring ),è¿™æ˜¯ä¼—æ‰€å‘¨çŸ¥çš„è€—æ—¶æ›´é•¿ä¸”æ€§èƒ½æ”¹å–„å¾ˆå°çš„æ–¹æ³•ã€‚ä¸‹é¢ï¼Œæˆ‘å·²ç»æŠŠå°¼å°”æ£®å›å½’å™¨(tr)åˆ—å…¥äº†é»‘åå•*

```
*compare_models(blacklist=['tr'],turbo=True)*
```

*![](img/d0162a42a31060ea5467a491e2deb486.png)*

*æ¯”è¾ƒæ¨¡å‹çš„è¾“å‡º*

*è¿™é‡Œæˆ‘ä»¬å°†ä½¿ç”¨ R å¹³æ–¹(R2)ä½œä¸ºåº¦é‡æ ‡å‡†ã€‚æˆ‘ä»¬çœ‹åˆ° ETã€Catboost å’Œ KNN æ˜¯å‰ä¸‰åçš„æ¨¡å‹ã€‚ä¸‹ä¸€æ­¥ï¼Œæˆ‘ä»¬å°†è°ƒæ•´ä¸‰ä¸ªæ¨¡å‹çš„è¶…å‚æ•°ã€‚*

***è°ƒæ•´æ¨¡å‹è¶…å‚æ•°***

*PyCaret ä¸ºæ¯ä¸ªç®—æ³•éƒ½é¢„å®šä¹‰äº†ä¸€ä¸ªç½‘æ ¼ï¼Œå¹¶ä¸” ***tune_model()*** å‡½æ•°ä½¿ç”¨éšæœºç½‘æ ¼æœç´¢æ¥æŸ¥æ‰¾ä¼˜åŒ–æŒ‡æ ‡é€‰æ‹©çš„å‚æ•°é›†(æ­¤å¤„ä¸º Rsquare ),å¹¶æ˜¾ç¤ºä¼˜åŒ–æ¨¡å‹çš„äº¤å‰éªŒè¯åˆ†æ•°ã€‚å®ƒä¸æ¥å—ç»è¿‡è®­ç»ƒçš„æ¨¡å‹ï¼Œå¹¶ä¸”éœ€è¦ä½œä¸ºå­—ç¬¦ä¸²ä¼ é€’çš„ä¼°è®¡é‡çš„ç¼©å†™ã€‚æˆ‘ä»¬å°†è°ƒæ•´é¢å¤–æ ‘(et)ã€K æœ€è¿‘é‚»(knn)å’Œ CatBoost (catboost)å›å½’å™¨ã€‚*

```
*et_tuned = tune_model(â€˜etâ€™)*
```

*![](img/20a519e288010c98fdede54b8cc6fa45.png)*

```
*catb_tuned = tune_model(â€˜catboostâ€™)*
```

*![](img/10b1b9287a528fe802ea76cd83c2e551.png)*

```
*knn_tuned = tune_model(â€˜knnâ€™,n_iter=150)*#I have increased the iteration in knn because increasing iterations have shown to perform better for knn rather than other models in question without significantly increasing the training time.**
```

*![](img/550777fdfa0d9c00ebf91952543aef33.png)*

*ä¸Šé¢æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œknn çš„ R2 åœ¨è°ƒä¼˜åå¤§å¹…æå‡è‡³ 87.86%ï¼Œè¿œé«˜äºè°ƒä¼˜åæ²¡æœ‰æå‡çš„ et å’Œ catboostã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºç½‘æ ¼æœç´¢è¿‡ç¨‹ä¸­çš„éšæœºåŒ–ã€‚åœ¨ä¸€äº›éå¸¸é«˜çš„è¿­ä»£æ¬¡æ•°ä¸‹ï¼Œå®ƒä»¬å¯èƒ½ä¼šæ”¹è¿›ã€‚*

*æˆ‘è¿˜ä¼šåˆ›å»ºä¸€ä¸ªåŸºæœ¬çš„é¢å¤–æ ‘(et)æ¨¡å‹ï¼Œå› ä¸ºå®ƒçš„åŸå§‹æ€§èƒ½(è°ƒä¼˜å‰)éå¸¸æ¥è¿‘è°ƒä¼˜åçš„ knnã€‚æˆ‘ä»¬å°†ä½¿ç”¨ PyCaret ä¸­çš„***create _ model()***å‡½æ•°æ¥åˆ›å»ºæ¨¡å‹ã€‚*

```
*et = create_model(â€˜etâ€™)*
```

***è¯„ä¼°æ¨¡å‹***

*å¯¹è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œä¸€äº›æ¨¡å‹è¯Šæ–­æ˜¯å¾ˆé‡è¦çš„ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ PyCaret ä¸­çš„ ***evaluate_model()*** å‡½æ•°æ¥æŸ¥çœ‹ç»˜å›¾é›†å’Œå…¶ä»–è¯Šæ–­ä¿¡æ¯ã€‚å®ƒæ¥å—ç»è¿‡è®­ç»ƒçš„æ¨¡å‹ï¼Œä»¥è¿”å›æ¨¡å‹è¯Šæ–­å›¾å’Œæ¨¡å‹å®šä¹‰çš„é€‰æ‹©ã€‚æˆ‘ä»¬å°†å¯¹æˆ‘ä»¬çš„ä¸¤ä¸ªé¡¶çº§æ¨¡å‹è¿›è¡Œæ¨¡å‹è¯Šæ–­ï¼Œå³ knn_tuned å’Œ etã€‚*

*![](img/5e80629540849143383600b07560080e.png)*

*åº“å…‹è·ç¦»å›¾ knn_tuned*

*ä¸Šé¢ï¼Œæˆ‘ä»¬å¯ä»¥æ¸…æ¥šåœ°çœ‹åˆ°ï¼Œåœ¨å‰ 500 ä¸ªè§‚å¯Ÿå€¼ä¸­ï¼Œæœ‰è®¸å¤šå¼‚å¸¸å€¼ï¼Œå®ƒä»¬ä¸ä»…å½±å“æ¨¡å‹æ€§èƒ½ï¼Œè¿˜å¯èƒ½å½±å“æœªæ¥çš„æ¨¡å‹æ³›åŒ–ã€‚å› æ­¤ï¼Œå»é™¤è¿™äº›å¼‚å¸¸å€¼å¯èƒ½æ˜¯å€¼å¾—çš„ã€‚ä½†åœ¨æ­¤ä¹‹å‰ï¼Œæˆ‘ä»¬å°†é€šè¿‡ et æ¥äº†è§£ç‰¹å¾é‡è¦æ€§(knn ä¸æä¾›ç‰¹å¾é‡è¦æ€§)*

*![](img/70d15f5fbcd14dd4e70bea960f4a6d8a.png)*

*æˆ‘ä»¬è®¤ä¸ºï¼Œç™½é“¶å’Œæ–°å…´å¸‚åœº ETF çš„å›æŠ¥ç‡å…·æœ‰æœ€é«˜çš„ç‰¹å¾é‡è¦æ€§ï¼Œçªæ˜¾å‡ºç™½é“¶å’Œé»„é‡‘é€šå¸¸æˆå¯¹æ³¢åŠ¨ï¼Œè€ŒæŠ•èµ„ç»„åˆé…ç½®ç¡®å®åœ¨æ–°å…´å¸‚åœºè‚¡ç¥¨å’Œé»„é‡‘ä¹‹é—´è½¬ç§»ã€‚*

***å»é™¤å¼‚å¸¸å€¼***

*è¦ç§»é™¤å¼‚å¸¸å€¼ï¼Œæˆ‘ä»¬éœ€è¦å›åˆ°è®¾ç½®é˜¶æ®µï¼Œä½¿ç”¨ PyCaret å†…ç½®çš„å¼‚å¸¸å€¼ç§»é™¤å™¨ï¼Œå¹¶å†æ¬¡åˆ›å»ºæ¨¡å‹ä»¥æŸ¥çœ‹å½±å“ã€‚*

```
*b=setup(data_22,target=â€™Gold-T+22', ignore_features=[â€˜Dateâ€™], session_id=11,silent=True,profile=False,remove_outliers=True);*
```

*å¦‚æœ***' remove _ outliers '***å‚æ•°è®¾ç½®ä¸º trueï¼ŒPyCaret ä½¿ç”¨å¥‡å¼‚å€¼åˆ†è§£(SVD)æŠ€æœ¯åˆ é™¤é€šè¿‡ PCA çº¿æ€§é™ç»´è¯†åˆ«çš„ç¦»ç¾¤å€¼ã€‚é»˜è®¤æ‚è´¨æ°´å¹³ä¸º 5%ã€‚è¿™æ„å‘³ç€å®ƒå°†åˆ é™¤ 5%çš„è§‚å¯Ÿå€¼ï¼Œå®ƒè®¤ä¸ºæ˜¯ç¦»ç¾¤å€¼ã€‚*

*ç§»é™¤å¼‚å¸¸å€¼åï¼Œæˆ‘ä»¬å†æ¬¡è¿è¡Œæˆ‘ä»¬çš„é¡¶çº§æ¨¡å‹ï¼Œçœ‹çœ‹æ˜¯å¦æœ‰ä»»ä½•æ€§èƒ½æ”¹è¿›ï¼Œæ˜¾ç„¶æœ‰ã€‚*

*![](img/e2b319c4ecb20a52299f97941c9345b5.png)**![](img/49c4937fe38f3fca54eebb6b37e052d4.png)

å‰”é™¤å¼‚å¸¸å€¼åçš„ et å’Œ knn_tuned ç»“æœ* 

*æˆ‘ä»¬çœ‹åˆ° et çš„æ€§èƒ½ä» 85.43%æé«˜åˆ° 86.16%ï¼Œknn_tuned çš„æ€§èƒ½ä» 87.86%æé«˜åˆ° 88.3%ã€‚è¤¶çš±é—´çš„æ ‡å‡†å·®ä¹Ÿæœ‰æ‰€é™ä½ã€‚*

***é›†åˆæ¨¡å‹***

*æˆ‘ä»¬è¿˜å¯ä»¥å°è¯•çœ‹çœ‹ bagging/boosting æ˜¯å¦å¯ä»¥æé«˜æ¨¡å‹æ€§èƒ½ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ PyCaret ä¸­çš„***ensemble _ model()***å‡½æ•°ï¼Œé€šè¿‡ä¸‹é¢çš„ä»£ç å¿«é€ŸæŸ¥çœ‹é›†æˆæ–¹æ³•å¦‚ä½•æ”¹å–„ç»“æœ:*

```
*et_bagged = ensemble_model(et,method=â€™Baggingâ€™)
knn_tuned_bagged = ensemble_model(knn_tuned, method='Bagging')*
```

*ä¸Šè¿°ä»£ç å°†æ˜¾ç¤ºç±»ä¼¼çš„äº¤å‰éªŒè¯åˆ†æ•°ï¼Œä½†æ²¡æœ‰æ˜¾ç¤ºå‡ºå¤ªå¤§çš„æ”¹è¿›ã€‚å›è´­ä¸­çš„ç¬”è®°æœ¬é“¾æ¥å¯ä»¥çœ‹åˆ°ç»“æœã€‚*

***æ··åˆæ¨¡å‹***

*æˆ‘ä»¬å¯ä»¥æ··åˆå‰ 2 ä¸ªæ¨¡å‹(et å’Œ knn_tuned)æ¥çœ‹çœ‹æ··åˆæ¨¡å‹æ˜¯å¦å¯ä»¥è¡¨ç°å¾—æ›´å¥½ã€‚äººä»¬ç»å¸¸çœ‹åˆ°ï¼Œæ··åˆæ¨¡å‹ç»å¸¸å­¦ä¹ ä¸åŒçš„æ¨¡å¼ï¼Œå¹¶ä¸”å®ƒä»¬ä¸€èµ·å…·æœ‰æ›´å¥½çš„é¢„æµ‹èƒ½åŠ›ã€‚ä¸ºæ­¤æˆ‘å°†ä½¿ç”¨ PyCaret çš„***blend _ models()***å‡½æ•°ã€‚å®ƒæ¥å—ä¸€ä¸ªè®­ç»ƒæ¨¡å‹åˆ—è¡¨ï¼Œå¹¶è¿”å›ä¸€ä¸ªæ··åˆæ¨¡å‹å’Œ 10 å€äº¤å‰éªŒè¯åˆ†æ•°ã€‚*

```
*blend_knn_et = blend_models(estimator_list=[knn_tuned,et])*
```

*![](img/5e76bdf4a7d4c7f58bba6b7f493ea683.png)*

*æ··åˆæ¨¡å‹çš„ç»“æœ*

*åœ¨ä¸Šè¡¨ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°æ··åˆçš„ ***knn_tuned*** å’Œ ***et*** è¿”å›æ¯”ä¸¤è€…æ›´å¥½åœ°è¡¨ç¤º R2ã€‚ä¸ ***knn_tuned*** ç›¸æ¯”ï¼ŒR2 çš„å¹³å‡ R2 å¢åŠ äº† 1.9%ï¼Œæ ‡å‡†å·®å‡å°‘äº† 1.9%ï¼Œè¿™æ„å‘³ç€è·¨è¤¶çš±çš„æ€§èƒ½æ›´å¥½ã€æ›´ä¸€è‡´ã€‚*

*90.2%çš„å¹³å‡ R2 æ„å‘³ç€æˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿä»æˆ‘ä»¬æä¾›çš„ç‰¹å¾ä¸­æ•æ‰å¹³å‡ 90.2%çš„é»„é‡‘å›æŠ¥å˜åŒ–ã€‚*

***å †å æ¨¡å‹***

*è™½ç„¶æ··åˆæ¨¡å‹çš„ç»“æœå¾ˆå¥½ï¼Œä½†æˆ‘æƒ³çœ‹çœ‹æ˜¯å¦æœ‰å¯èƒ½ä»æ•°æ®ä¸­æå–æ›´å¤šçš„ R2 åŸºç‚¹ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†å»ºç«‹ä¸€ä¸ªå¤šå±‚æ¬¡çš„æ¨¡å‹å †æ ˆã€‚è¿™ä¸åŒäºæ··åˆï¼Œå› ä¸ºæ¨¡å‹å±‚æ˜¯æŒ‰é¡ºåºå †å çš„ï¼Œå› æ­¤ä¸€å±‚ä¸­æ¨¡å‹çš„é¢„æµ‹å°†ä¸åŸå§‹è¦ç´ ä¸€èµ·ä¼ é€’åˆ°æ¨¡å‹çš„ä¸‹ä¸€å±‚(å¦‚æœ restack = True)ã€‚ä¸€ç»„æ¨¡å‹çš„é¢„æµ‹æå¤§åœ°å¸®åŠ©äº†åç»­æ¨¡å‹çš„é¢„æµ‹ã€‚é“¾çš„æœ«ç«¯æ˜¯å…ƒæ¨¡å‹(é»˜è®¤æ˜¯çº¿æ€§çš„)ã€‚PyCaret guide æœ‰æ›´å¤šå…³äº[ä¸»é¢˜](https://pycaret.org/stack-models/)çš„ç»†èŠ‚ã€‚åœ¨ç¬”è®°æœ¬ä¸­ï¼Œæˆ‘å°è¯•äº†å‡ ç§æ¶æ„ã€‚ä¸‹é¢å±•ç¤ºçš„æ˜¯æ€§èƒ½æœ€ä½³çš„äº§å“:*

```
*stack2 = create_stacknet(estimator_list=[[catb,et,knn_tuned],[blend_knn_et]], restack=True)*
```

*![](img/4aebda0982ceeb32ea77bcf8ff799654.png)*

*å †å  2 çš„ç»“æœ(å¤šå±‚å †å )*

*æ­£å¦‚æˆ‘ä»¬åœ¨ä¸Šé¢çœ‹åˆ°çš„ï¼Œ ***stack2*** æ¨¡å‹æ¯” ***blend_knn_et*** æœ‰ 1%çš„ R2ï¼Œæˆ‘ä»¬å°†é€‰æ‹© ***stack2*** ä½œä¸ºæœ€ä½³æ¨¡å‹ï¼Œå¹¶ä¿å­˜å®ƒç”¨äºé¢„æµ‹ã€‚*

***ä¿å­˜æ¨¡å¼***

*ä¸€æ—¦æ¨¡å‹å®šå‹ï¼Œæˆ‘ä»¬éœ€è¦ä¿å­˜æ¨¡å‹ï¼Œä»¥ä¾¿åœ¨æ–°æ•°æ®ä¸Šä½¿ç”¨å®ƒæ¥è¿›è¡Œé¢„æµ‹ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ save_model()æ¥å®ç°ã€‚è¿™ä¼šå°†æ¨¡å‹ä¿å­˜åœ¨å½“å‰ç›®å½•æˆ–ä»»ä½•å·²å®šä¹‰çš„è·¯å¾„ä¸­ã€‚ä¸‹é¢çš„ä»£ç å°†æ¨¡å‹å’Œé¢„å¤„ç†ç®¡é“ä¿å­˜ä¸ºåç§°***ã€22 å¤©å›å½’å™¨ã€‘****

```
*save_model(model=stack2, model_name=â€™22Day Regressorâ€™)*
```

***å¯¹æ–°æ•°æ®è¿›è¡Œé¢„æµ‹***

*ä¸€æ—¦æˆ‘ä»¬ä¿å­˜äº†æˆ‘ä»¬çš„æ¨¡å‹ï¼Œæˆ‘ä»¬å°†å¸Œæœ›åœ¨æ–°æ•°æ®åˆ°è¾¾æ—¶å¯¹å…¶è¿›è¡Œé¢„æµ‹ã€‚æˆ‘ä»¬å¯ä»¥ä¾é  yahoofinancials è½¯ä»¶åŒ…æ¥ç»™å‡ºæ‰€æœ‰å·¥å…·çš„æ”¶ç›˜ä»·ï¼Œä½†æ˜¯ï¼Œæˆ‘ä»¬éœ€è¦å†æ¬¡å‡†å¤‡æ–°çš„æ•°æ®ï¼Œä»¥ä¾¿èƒ½å¤Ÿä½¿ç”¨è¯¥æ¨¡å‹ã€‚è¿™äº›æ­¥éª¤ä¸æˆ‘ä»¬åœ¨å‡†å¤‡åŸ¹è®­æ•°æ®æ—¶æ‰€åšçš„ç±»ä¼¼ï¼Œå”¯ä¸€çš„åŒºåˆ«æ˜¯æˆ‘ä»¬å°†å¯¼å…¥æœ€æ–°çš„æ•°æ®ï¼Œå¹¶ä¸”æˆ‘ä»¬ä¸ä¼šåˆ›å»ºæ ‡ç­¾(æˆ‘ä»¬ä¸èƒ½åˆ›å»ºæ ‡ç­¾ï¼Œå› ä¸ºæˆ‘ä»¬æ²¡æœ‰æœªæ¥çš„ä»·æ ¼)ã€‚ä¸‹é¢çš„ä»£ç  chuck åº”è¯¥å¯¼å…¥å¹¶è°ƒæ•´æ•°æ®ï¼Œä½¿å…¶ä¸ºé¢„æµ‹åšå¥½å‡†å¤‡ã€‚*

```
****#Importing Libraries***
import pandas as pd
from datetime import datetime
import matplotlib.pyplot as plt
from yahoofinancials import YahooFinancialsticker_details = pd.read_excel("Ticker List.xlsx")
ticker = ticker_details['Ticker'].to_list()
names = ticker_details['Description'].to_list()***#Preparing Date Range***
end_date= datetime.strftime(datetime.today(),'%Y-%m-%d')
start_date = "2019-01-01"
date_range = pd.bdate_range(start=start_date,end=end_date)
values = pd.DataFrame({ 'Date': date_range})
values['Date']= pd.to_datetime(values['Date'])***#Extracting Data from Yahoo Finance and Adding them to Values table using date as key***
for i in ticker:
    raw_data = YahooFinancials(i)
    raw_data = raw_data.get_historical_price_data(start_date, end_date, "daily")
    df = pd.DataFrame(raw_data[i]['prices'])[['formatted_date','adjclose']]
    df.columns = ['Date1',i]
    df['Date1']= pd.to_datetime(df['Date1'])
    values = values.merge(df,how='left',left_on='Date',right_on='Date1')
    values = values.drop(labels='Date1',axis=1)***#Renaming columns to represent instrument names rather than their ticker codes for ease of readability***
names.insert(0,'Date')
values.columns = names***#Front filling the NaN values in the data set***
values = values.fillna(method="ffill",axis=0)
values = values.fillna(method="bfill",axis=0)***# Co-ercing numeric type to all columns except Date***
cols=values.columns.drop('Date')
values[cols] = values[cols].apply(pd.to_numeric,errors='coerce').round(decimals=1)
imp = ['Gold','Silver', 'Crude Oil', 'S&P500','MSCI EM ETF']***# Calculating Short term -Historical Returns***
change_days = [1,3,5,14,21]data = pd.DataFrame(data=values['Date'])
for i in change_days:
    x= values[cols].pct_change(periods=i).add_suffix("-T-"+str(i))
    data=pd.concat(objs=(data,x),axis=1)
    x=[]***# Calculating Long term Historical Returns***
change_days = [60,90,180,250]for i in change_days:
    x= values[imp].pct_change(periods=i).add_suffix("-T-"+str(i))
    data=pd.concat(objs=(data,x),axis=1)
    x=[]***#Calculating Moving averages for Gold***
moving_avg = pd.DataFrame(values['Date'],columns=['Date'])
moving_avg['Date']=pd.to_datetime(moving_avg['Date'],format='%Y-%b-%d')
moving_avg['Gold/15SMA'] = (values['Gold']/(values['Gold'].rolling(window=15).mean()))-1
moving_avg['Gold/30SMA'] = (values['Gold']/(values['Gold'].rolling(window=30).mean()))-1
moving_avg['Gold/60SMA'] = (values['Gold']/(values['Gold'].rolling(window=60).mean()))-1
moving_avg['Gold/90SMA'] = (values['Gold']/(values['Gold'].rolling(window=90).mean()))-1
moving_avg['Gold/180SMA'] = (values['Gold']/(values['Gold'].rolling(window=180).mean()))-1
moving_avg['Gold/90EMA'] = (values['Gold']/(values['Gold'].ewm(span=90,adjust=True,ignore_na=True).mean()))-1
moving_avg['Gold/180EMA'] = (values['Gold']/(values['Gold'].ewm(span=180,adjust=True,ignore_na=True).mean()))-1
moving_avg = moving_avg.dropna(axis=0)***#Merging Moving Average values to the feature space***data['Date']=pd.to_datetime(data['Date'],format='%Y-%b-%d')
data = pd.merge(left=data,right=moving_avg,how='left',on='Date')
data = data[data['Gold-T-250'].notna()]
prediction_data = data.copy()*
```

*å‡†å¤‡å¥½æ•°æ®åï¼Œæˆ‘ä»¬éœ€è¦åŠ è½½æ¨¡å‹å¹¶è¿›è¡Œé¢„æµ‹ã€‚ä¸ºäº†åŠ è½½æ¨¡å‹ï¼Œæˆ‘ä»¬å°†å†æ¬¡ä½¿ç”¨ PyCaret çš„å›å½’æ¨¡å—ã€‚ä¸‹é¢çš„ä»£ç å°†åŠ è½½æ¨¡å‹ï¼Œå¯¹æ–°æ•°æ®è¿›è¡Œé¢„æµ‹ï¼Œå¹¶ä½¿ç”¨æ•°æ®é›†ä¸­æ¯ä¸ªæ—¥æœŸçš„å†å²ä»·æ ¼ã€é¢„è®¡å›æŠ¥å’Œ 3 å‘¨å†…çš„é¢„æµ‹ä»·æ ¼ã€‚*

```
*from pycaret.regression import ****#Loading the stored model*** regressor_22 = load_model("22Day Regressor");***#Making Predictions*** predicted_return_22 = predict_model(regressor_22,data=prediction_data)
predicted_return_22=predicted_return_22[['Date','Label']]
predicted_return_22.columns = ['Date','Return_22']***#Adding return Predictions to Gold Values***
predicted_values = values[['Date','Gold']]
predicted_values = predicted_values.tail(len(predicted_return_22))
predicted_values = pd.merge(left=predicted_values,right=predicted_return_22,on=['Date'],how='inner')
predicted_values['Gold-T+22']=(predicted_values['Gold']*(1+predicted_values['Return_22'])).round(decimals =1)***#Adding T+22 Date*** from datetime import datetime, timedeltapredicted_values['Date-T+22'] = predicted_values['Date']+timedelta(days = 22)
predicted_values.tail()*
```

*![](img/03c371b9281ddfe68e734623e2c60138.png)*

*ä¸Šè¡¨è¾“å‡ºæ˜¾ç¤ºï¼Œé»„é‡‘åœ¨ 2020 å¹´ 4 æœˆ 17 æ—¥çš„æ”¶ç›˜ä»·ä¸º 1ï¼Œ694.5 ç¾å…ƒï¼Œæ¨¡å‹é¢„æµ‹åœ¨æ¥ä¸‹æ¥çš„ 22 å¤©å†…ï¼Œå›æŠ¥å°†ä¸º-2.3%ï¼Œå¯¼è‡´ 2020 å¹´ 5 æœˆ 9 æ—¥çš„ä»·æ ¼ç›®æ ‡ä¸º 1ï¼Œ655 ç¾å…ƒã€‚æˆ‘ä¸ºé¢„æµ‹å»ºç«‹äº†ä¸€ä¸ªå•ç‹¬çš„ç¬”è®°æœ¬ï¼Œæ ‡é¢˜ä¸º ***â€œé»„é‡‘é¢„æµ‹æ–°æ•°æ®â€”å›å½’â€*** ï¼Œå¯ä»¥åœ¨å›è´­[è¿™é‡Œ](https://github.com/Riazone/Gold-Return-Prediction/blob/master/Regression/Gold%20Prediction%20New%20Data%20-%20Regression.ipynb)æ‰¾åˆ°ã€‚*

*æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç›¸åŒçš„æ¦‚å¿µå’ŒæŠ€æœ¯æ¥é¢„æµ‹ T+14 å¤©ã€‚ä»£ç å’Œè¾“å‡ºå¯ä»¥åœ¨ Jupyter ç¬”è®°æœ¬æ ‡é¢˜ ***â€œé»„é‡‘é¢„æµ‹å®éªŒå›å½’â€”py caretâ€***ä¸­æ‰¾åˆ°ï¼Œåœ¨ repo [è¿™é‡Œ](https://github.com/Riazone/Gold-Return-Prediction/blob/master/Regression/Gold%20Prediction%20Experiment%20%20Regression-%20PyCaret.ipynb)ã€‚*

# *é‡è¦é“¾æ¥*

****é“¾æ¥ç¬¬ä¸‰éƒ¨åˆ†â€”*** [***é¢„æµ‹é‡‘ä»·æš´è·Œ***](/predicting-crashes-in-gold-prices-using-machine-learning-5769f548496)*

****é“¾æ¥åˆ°*** [***Github èµ„æºåº“***](https://github.com/Riazone/Gold-Return-Prediction)*

****å…³æ³¨æˆ‘ä¸Š***[***LinkedIn***](https://www.linkedin.com/in/riazuddin-mohammad/)*

****æŒ‡å—***[***py caret***](https://pycaret.org/guide/)*