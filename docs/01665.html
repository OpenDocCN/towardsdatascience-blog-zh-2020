<html>
<head>
<title>Elevate Your Webscraping With Splinter</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Splinter提升你的网络抓取</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/elevate-your-webscraping-with-splinter-a926eee7f7d9?source=collection_archive---------10-----------------------#2020-02-15">https://towardsdatascience.com/elevate-your-webscraping-with-splinter-a926eee7f7d9?source=collection_archive---------10-----------------------#2020-02-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="5b3c" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/on-target" rel="noopener" target="_blank">按目标</a></h2><div class=""/><div class=""><h2 id="234e" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">通过自动化与网页的交互，从您的抓取中获得更好的数据</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/bf19f573bdab691692bd5d73573feb8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sr5NZFmv6Ps7XdINcjRKSQ.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图像-像素</p></figure><p id="f69d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在以前的博客中，我使用两个包的组合探索了网络抓取的基础；<em class="md">请求</em>，它获取一个网站的HTML和<em class="md"> BeautifulSoup4 </em>，它解释那个HTML。</p><div class="me mf gp gr mg mh"><a rel="noopener follow" target="_blank" href="/soup-of-the-day-97d71e6c07ec"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd jd gy z fp mm fr fs mn fu fw jc bi translated">今日汤</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">美汤网刮——初学者指南</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">towardsdatascience.com</p></div></div><div class="mq l"><div class="mr l ms mt mu mq mv lb mh"/></div></div></a></div><p id="48ce" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这些包很好地介绍了webscraping，但是Requests有局限性，尤其是当您想要抓取的站点需要大量用户交互时。</p><p id="88b8" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">提醒一下——Requests是一个Python包，它将URL作为参数，并在第一次跟踪该URL时返回立即可用的HTML。因此，如果你的目标网站只是在特定的交互之后才加载内容(比如滚动到页面底部或者点击一个按钮)，那么请求就不是一个合适的解决方案。</p><p id="fc76" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">对于我在我的目标系列<a class="ae mw" href="https://towardsdatascience.com/tagged/on-target" rel="noopener" target="_blank">中记录的</a><a class="ae mw" rel="noopener" target="_blank" href="/how-to-moneyball-soccer-46b589429748"> FPL项目</a>，我需要从英超联赛网站的<a class="ae mw" href="https://www.premierleague.com/match/46862" rel="noopener ugc nofollow" target="_blank">结果页面</a>中收集比赛数据。这些对请求提出了一些挑战。例如，我想要每个比赛页面上的“阵容”和“统计”标签中的数据，但是，这些数据不会加载新网页。相反，它们触发JavaScript事件，在同一个页面中加载新的HTML。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi mx"><img src="../Images/6b8aa8d936fa8ad358178ad777f0bad3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aT-eTqAGR64b3kqzzo-vPg.png"/></div></div></figure><p id="cbda" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我还想抓取比赛评论，可以通过向下滚动页面进入…</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi my"><img src="../Images/d7e1888353f3fa88567a6f7ef20ec38b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qOKwO9jHlWZhSOlrlenAnA.png"/></div></div></figure><p id="19b6" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">…但只有当用户继续向下滚动时才会完全加载(类似于脸书和Reddit等“无限滚动”网站)。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/baeb4e5a48d6b230b49e810ca20271c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*iFymqb8A-vBKq4_sjF12gA.png"/></div></figure><h1 id="4932" class="na nb it bd nc nd ne nf ng nh ni nj nk ki nl kj nm kl nn km no ko np kp nq nr bi translated">用碎片刮擦</h1><p id="a2bb" class="pw-post-body-paragraph lh li it lj b lk ns kd lm ln nt kg lp lq nu ls lt lu nv lw lx ly nw ma mb mc im bi translated">我们可以使用一个名为<a class="ae mw" href="https://splinter.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> Splinter </a>的Python包来代替请求抓取。Splinter是其他浏览器自动化工具之上的一个抽象层，比如<a class="ae mw" href="http://seleniumhq.org" rel="noopener ugc nofollow" target="_blank"> Selenium，</a>它保持了良好的用户友好性。此外，一旦我们用Splinter抓取了HTML，BeautifulSoup4可以从其中提取数据，就像我们使用请求一样。</p><p id="6101" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">首先，我们需要为我们想要使用的浏览器下载合适的浏览器“驱动程序”。对于Firefox来说，这意味着使用Mozilla的<a class="ae mw" href="https://github.com/mozilla/geckodriver/releases" rel="noopener ugc nofollow" target="_blank"> geckodriver </a>(注意——Splinter默认使用Firefox)。如果你用的是Chrome，那么你需要<a class="ae mw" href="https://chromedriver.chromium.org/" rel="noopener ugc nofollow" target="_blank"> chromedriver </a>。</p><p id="582b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">您还需要使用您机器的终端pip安装selenium(完整的细节包含在<a class="ae mw" href="https://splinter.readthedocs.io/en/latest/drivers/chrome.html" rel="noopener ugc nofollow" target="_blank"> Splinter文档</a>中):</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="927d" class="oc nb it ny b gy od oe l of og">$ [sudo] pip install selenium</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/51b769bbe6321a165e761413f7928d3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:432/format:webp/1*nadxuZHo3pQS-fH6VMtSyQ.png"/></div></figure><p id="8d1a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">同样值得注意的是，驱动文件本身(即geckodriver或chromedriver)需要包含在您的repo的根目录中(这在Splinter或Firefox文档中都不是一个明显的要求！)</p><p id="f08b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">Splinter的工作原理是实例化一个“浏览器”对象(如果你愿意，它会在你的桌面上启动一个新的浏览器窗口)。然后，我们可以在Jupyter Notebook上运行方法，与浏览器进行交互。</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="7e7d" class="oc nb it ny b gy od oe l of og">from splinter import Browser</span><span id="4cbf" class="oc nb it ny b gy oi oe l of og"><strong class="ny jd"><em class="md">#State the location of your driver</em></strong><br/>executable_path = {"executable_path": "/Users/Callum/Downloads/geckodriver"}</span><span id="7d51" class="oc nb it ny b gy oi oe l of og"><strong class="ny jd"><em class="md">#Instantiate a browser object as follows...<br/>#Pass 'headless=False' to make Firefox launch a visible window<br/></em></strong>browser = Browser("firefox", **executable_path, headless=False)</span></pre><p id="888f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这将启动一个空的浏览器窗口。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl oj"><img src="../Images/0ec665f7373b5125d3916e4788d12812.png" data-original-src="https://miro.medium.com/v2/format:webp/1*JpyY8F-sBIbGkwbbA4rCrg.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">注意橙色条纹的地址栏，它告诉我们它是由我们的Python文件控制的</p></figure><p id="7a88" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们现在可以用一些Python命令来控制这个浏览器。首先，让它访问一个网页…</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="9c7e" class="oc nb it ny b gy od oe l of og">match_url = 'https://www.premierleague.com/match/46862'</span><span id="f422" class="oc nb it ny b gy oi oe l of og">browser.visit(match_url)</span></pre><p id="bbfd" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">查看我们桌面上的浏览器窗口，我们可以看到这已经工作了！</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ok"><img src="../Images/1b97eed76438e37696df3bc950354242.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IpPSkVNbz9GSsNiWbHTeRg.png"/></div></div></figure><h1 id="525d" class="na nb it bd nc nd ne nf ng nh ni nj nk ki nl kj nm kl nn km no ko np kp nq nr bi translated">与元素交互</h1><p id="b9a3" class="pw-post-body-paragraph lh li it lj b lk ns kd lm ln nt kg lp lq nu ls lt lu nv lw lx ly nw ma mb mc im bi translated">现在我们已经加载了网站，让我们来解决请求无法处理的两个问题。首先，我们想点击“阵容”和“统计”标签。</p><p id="b660" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为此，我们首先需要了解这些元素在HTML中是如何被引用的。右键单击按钮，并选择“检查元素”。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ol"><img src="../Images/fc9a26c10659ec0c153be8f9db755e99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J5P233gPyjF_oCPxz0Gcfw.png"/></div></div></figure><p id="5f24" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以在检查器中找到合适的HTML。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi om"><img src="../Images/4f9996ecb666008001f78d3453bdcc9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*VEs02RQDskM1NYB1kuRH-w.png"/></div></figure><p id="e325" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">所以按钮是一个有序列表元素<li>，带有类“matchcentresquantlabelcontainer”。</li></p><p id="9f30" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">Splinter可以用。find_by_tag()方法。然后我们可以用<a class="ae mw" href="https://splinter.readthedocs.io/en/latest/mouse-interaction.html#click" rel="noopener ugc nofollow" target="_blank">点击这个按钮。点击()</a>方法。</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="a648" class="oc nb it ny b gy od oe l of og">target = ‘li[class=”matchCentreSquadLabelContainer”]’</span><span id="cec3" class="oc nb it ny b gy oi oe l of og">browser.find_by_tag(target).click()</span></pre><p id="7c8b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">注意Splinter可以使用六种不同的东西来查找元素。这些在这里有完整的文档<a class="ae mw" href="https://splinter.readthedocs.io/en/latest/finding.html" rel="noopener ugc nofollow" target="_blank">，但是包括通过元素ID、CSS或值进行查找的选项。</a></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi on"><img src="../Images/6b60382a7da3e1e22f453d46264170a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7V_uQYQnbIoTbzKVfT-5mQ.png"/></div></div></figure><p id="4ad8" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">现在浏览器已经‘点击’了我们想要的标签，我们可以使用BeautifulSoup4来获取和存储HTML。</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="18b5" class="oc nb it ny b gy od oe l of og">from bs4 import BeautifulSoup<br/>html = BeautifulSoup(browser.html, 'html.parser')</span></pre><p id="fe62" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">然后，我们可以使用我之前的博客<a class="ae mw" rel="noopener" target="_blank" href="/soup-of-the-day-97d71e6c07ec">中记录的相同技术提取我们想要的文本信息。</a></p><p id="44ed" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">当然，如果我们还想单击“Stats”选项卡，我们会执行相同的过程—使用Inspect Element工具检查该选项卡是如何被调用的，然后在使用BeautifulSoup提取HTML之前，在. find_by_tag()方法中传递它。</p><h1 id="08d1" class="na nb it bd nc nd ne nf ng nh ni nj nk ki nl kj nm kl nn km no ko np kp nq nr bi translated">解决无限滚动问题</h1><p id="1a5b" class="pw-post-body-paragraph lh li it lj b lk ns kd lm ln nt kg lp lq nu ls lt lu nv lw lx ly nw ma mb mc im bi translated">虽然Splinter的Browser类没有内置的“滚动”方法，但它有一个更强大的功能让我们可以做到这一点——也就是说，我们可以使用<a class="ae mw" href="https://splinter.readthedocs.io/en/latest/api/driver-and-element-api.html#splinter.driver.DriverAPI.execute_script" rel="noopener ugc nofollow" target="_blank">。execute_script()方法</a>运行JavaScript。</p><p id="3d63" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了让浏览器滚动到当前加载页面的底部，我们使用了<a class="ae mw" href="https://www.w3schools.com/jsref/met_win_scrollto.asp" rel="noopener ugc nofollow" target="_blank"> JavaScript scrollTo()方法</a>。它将<em class="md"> x </em>和<em class="md"> y </em>位置作为它的参数，所以为了到达页面的末尾，我们将‘document . body . scroll height’作为<em class="md"> y </em>位置(我们不需要改变<em class="md"> x </em>位置，因为我们只是在垂直方向上滚动)。</p><p id="2b0b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">因此，我们运行:</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="161c" class="oc nb it ny b gy od oe l of og">browser.execute_script("window.scrollTo(0, document.body.scrollHeight);")</span></pre><p id="0d29" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">可能的情况是，在我们需要的所有东西加载之前，我们需要继续滚动。由于不同的比赛会有不同数量的事件，我们将需要在每一页上做不同数量的滚动。因此，我们需要某种条件来告诉我们的代码停止滚动。</p><p id="663b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">令人高兴的是，英超网站上的评论总是以“阵容公布，球员热身”这句话开始。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/3eef31ff9bc5edc475edce8462160067.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/1*cyscFdI_Hm5tIiHIKaTHbw.png"/></div></figure><p id="0627" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">因此，如果我们抓取的HTML包含这个短语，那么我们知道我们已经得到了我们需要的所有评论，我们可以停止滚动。这是一个适合“while循环”的任务。</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="6492" class="oc nb it ny b gy od oe l of og"><strong class="ny jd"><em class="md">#Declare the JavaScript that scrolls to the end of the page...</em></strong><br/>scrollJS = "window.scrollTo(0, document.body.scrollHeight);"</span><span id="41d1" class="oc nb it ny b gy oi oe l of og"><strong class="ny jd"><em class="md">#...and a variable that signifies the loop's end-condition</em></strong><br/>condition = "Lineups are announced and players are warming up."</span><span id="8804" class="oc nb it ny b gy oi oe l of og"><strong class="ny jd"><em class="md">#Instantiate a 'first_content' variable (an empty string for now)<br/></em></strong>first_content = ""</span><span id="71eb" class="oc nb it ny b gy oi oe l of og"><strong class="ny jd"><em class="md">#Create a while loop that runs when 'first content'<br/>#is not equal to our break condition</em></strong><br/>while first_content != condition:</span><span id="8367" class="oc nb it ny b gy oi oe l of og"><strong class="ny jd"><em class="md">    #Scroll to the bottom of the page</em></strong><br/>    browser.execute_script(scrollJS)</span><span id="5037" class="oc nb it ny b gy oi oe l of og"><strong class="ny jd"><em class="md">    #Use BS4 to get the HTML</em></strong><br/>    soup = BeautifulSoup(browser.html, 'html.parser')</span><span id="a608" class="oc nb it ny b gy oi oe l of og">    <strong class="ny jd"><em class="md">#Store the first line of commentary displayed on the page as-is</em></strong><br/>    first_content = soup.findAll('div',class_="innerContent")[-1].get_text()</span><span id="5262" class="oc nb it ny b gy oi oe l of og"><strong class="ny jd">    #Scroll down again, and run the loop again if we<br/>    #haven't reached the line "Lineups are announced..."</strong><br/>    browser.execute_script(scrollJS)</span><span id="4d97" class="oc nb it ny b gy oi oe l of og"><strong class="ny jd"><em class="md">#Store the soup that, thanks to the while loop, will<br/>#definitely contain all of the commentary</em></strong><br/>HTML = soup</span></pre><p id="a1ee" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">然后，我们可以重构上面的所有内容，创建一个函数来接收匹配的URL，并返回来自比赛评论的所有HTML，以及来自阵容和统计选项卡的数据。因此，我们可以自动抓取本赛季到目前为止的所有比赛页面。当然，我们如何组织、存储和操纵这些数据完全是另一项任务(事实上，也是另一篇即将发表的博客的主题)。</p><p id="3153" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">值得一提的是，就Splinter的功能而言，这只是冰山一角。其他有趣的使用案例包括:</p><ul class=""><li id="12a9" class="op oq it lj b lk ll ln lo lq or lu os ly ot mc ou ov ow ox bi translated"><a class="ae mw" href="https://splinter.readthedocs.io/en/latest/elements-in-the-page.html#interacting-with-forms" rel="noopener ugc nofollow" target="_blank">输入文本字段</a></li><li id="14a2" class="op oq it lj b lk oy ln oz lq pa lu pb ly pc mc ou ov ow ox bi translated"><a class="ae mw" href="https://splinter.readthedocs.io/en/latest/cookies.html" rel="noopener ugc nofollow" target="_blank">操作cookie</a></li><li id="3317" class="op oq it lj b lk oy ln oz lq pa lu pb ly pc mc ou ov ow ox bi translated"><a class="ae mw" href="https://splinter.readthedocs.io/en/latest/screenshot.html" rel="noopener ugc nofollow" target="_blank">截图</a></li><li id="1d94" class="op oq it lj b lk oy ln oz lq pa lu pb ly pc mc ou ov ow ox bi translated"><a class="ae mw" href="https://splinter.readthedocs.io/en/latest/mouse-interaction.html#drag-and-drop" rel="noopener ugc nofollow" target="_blank">拖放元素</a></li><li id="adce" class="op oq it lj b lk oy ln oz lq pa lu pb ly pc mc ou ov ow ox bi translated">当然，你可以用标准JavaScript做任何事情。</li></ul><p id="4419" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">无论如何，Splinter是一个很棒的小Python包，它将帮助你把你的网络抓取提升到一个新的水平！试一试，看看你有什么想法。</p></div><div class="ab cl pd pe hx pf" role="separator"><span class="pg bw bk ph pi pj"/><span class="pg bw bk ph pi pj"/><span class="pg bw bk ph pi"/></div><div class="im in io ip iq"><blockquote class="pk pl pm"><p id="cafd" class="lh li md lj b lk ll kd lm ln lo kg lp pn lr ls lt po lv lw lx pp lz ma mb mc im bi translated">这是我的博客系列“目标”中的最新一篇文章，在这篇文章中，我将尝试构建一个“摇钱树”梦幻英超联赛的模型。我很乐意听到关于这个博客的任何评论，或者这篇文章涉及的任何概念。欢迎在下面留言，或者通过<a class="ae mw" href="https://www.linkedin.com/in/callum-ballard/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>联系我。</p></blockquote></div></div>    
</body>
</html>