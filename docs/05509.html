<html>
<head>
<title>Intuitive understanding of Eigenvectors: Key to PCA</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">对特征向量的直观理解:PCA 的关键</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/intuitive-understanding-of-eigenvectors-key-to-pca-a30a261c80de?source=collection_archive---------19-----------------------#2020-05-09">https://towardsdatascience.com/intuitive-understanding-of-eigenvectors-key-to-pca-a30a261c80de?source=collection_archive---------19-----------------------#2020-05-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/></div><div class="ab cl jn jo hu jp" role="separator"><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js"/></div><div class="ij ik il im in"><p id="8c25" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">真正理解主成分分析(PCA)需要对线性代数背后的概念，尤其是特征向量有一个清晰的理解。有许多文章解释了 PCA 及其重要性，尽管我发现有一些文章解释了 PCA 背后的直觉。</p><p id="5e9b" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">这篇文章的目的是给特征向量一个直观的理解，使你更好地理解主成分分析。PCA 算法的步骤不是本文的重点。</p><p id="bf13" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">首先，我想从可视化线性代数的一些基本概念开始。</p><h2 id="e8d3" class="ks kt iq bd ku kv kw dn kx ky kz dp la kf lb lc ld kj le lf lg kn lh li lj lk bi translated"><strong class="ak">线性变换</strong></h2><p id="2fa4" class="pw-post-body-paragraph ju jv iq jw b jx ll jz ka kb lm kd ke kf ln kh ki kj lo kl km kn lp kp kq kr ij bi translated">矩阵在线性空间中被称为函数或“变换”——这意味着，在线性空间中对向量进行变换后，保持了<em class="lq">线性度</em>。参考下面的例子-</p><p id="4e18" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在图中，我们看到一个向量<em class="lq">a =【2 ^ 2】</em>在乘以矩阵 b 后，被转换成向量<em class="lq">【4 ^ 2】</em></p><div class="lr ls lt lu gt ab cb"><figure class="lv lw lx ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><img src="../Images/c354304b4b2d8bd239e6a0645419d252.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*VyaY85vPcvWNhHDBZnj7oA.png"/></div></figure><figure class="lv lw mi ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><img src="../Images/b7ca5f0399910175b45fda8b8b94fab2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*CqasOcrUe01Um6jLxSKvUw.png"/></div><p class="mj mk gj gh gi ml mm bd b be z dk mn di mo mp translated">图 1(左)显示了变换前的矢量“a ”,图 2 显示了被矩阵 B“变换”后的矢量“a”</p></figure></div><h2 id="752c" class="ks kt iq bd ku kv kw dn kx ky kz dp la kf lb lc ld kj le lf lg kn lh li lj lk bi translated"><strong class="ak">基础变更</strong></h2><p id="bcfa" class="pw-post-body-paragraph ju jv iq jw b jx ll jz ka kb lm kd ke kf ln kh ki kj lo kl km kn lp kp kq kr ij bi translated">在标准坐标系中，单位矢量<em class="lq"> i 和 j </em>被认为是“基”矢量。这些标准基向量成为测量我们系统的一种方式。</p><p id="dc6c" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">但是，如果我们想改变基本向量，因为我们的数据在不同的系统中可能看起来更好呢？</p><p id="8f92" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">例如，如果我们在二维空间中有一些数据点。</p><figure class="lr ls lt lu gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi mq"><img src="../Images/ce8581821312d8d34449d07bc9a7e078.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0cBKuOGl8k2slYbf5Z_lnQ.png"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">二维平面中的分散数据</p></figure><p id="bd54" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">这个视图告诉我们一些关于数据的信息，但是如果我们旋转坐标轴，我们可以得到一个更清晰的视图。</p><p id="1b18" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">新轴以数据的平均值为中心。这种旋转使我们更容易测量数据的<em class="lq">分布</em>或<em class="lq">方差</em>。它还清楚地显示了存在两个不同的数据组。</p><figure class="lr ls lt lu gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi mr"><img src="../Images/989e3a86ca5bd3f44b99dfeee5a196d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dpHZAuUEcNxk_aCejYByOQ.png"/></div></div></figure><p id="872b" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">那么，我们如何着手改变基础呢？—线性变换。</p><p id="0b0b" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">矩阵乘法只不过是把当前坐标系的基变换成矩阵定义的新坐标系。矩阵的列向量给出了新基向量的位置。</p><p id="152c" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">以前面的线性变换为例，我们将向量<em class="lq"> a </em>乘以矩阵<em class="lq"> B </em>，我们找到了向量<em class="lq"> a </em>在矩阵 B 的基本向量所跨越的新坐标系中的位置。参见下图。</p><div class="lr ls lt lu gt ab cb"><figure class="lv lw ms ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><img src="../Images/c71c03807de234c342c24802ecf73890.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*VyaY85vPcvWNhHDBZnj7oA.png"/></div></figure><figure class="lv lw mt ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><img src="../Images/c29dca66733cb8aef878a9156c43015f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*7cHKHhtg5QZQ46IGoxfG-Q.png"/></div><p class="mj mk gj gh gi ml mm bd b be z dk mu di mv mp translated">图 1(左)显示了标准坐标系中的矢量 a。图 2(右)显示了放置在矩阵 B 给出的新坐标系中的矢量 a</p></figure></div><p id="52ea" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">如果我们想“回到”原来的坐标系，我们只需将“新向量”乘以基矩阵变化的倒数<em class="lq"> B </em>。</p><p id="7019" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">因此，将矢量<em class="lq">【4 ^ 2】</em>乘以<em class="lq"> B </em>的逆<em class="lq"> </em>，就得到矢量<em class="lq">【2 ^ 2】</em>。</p><h2 id="1803" class="ks kt iq bd ku kv kw dn kx ky kz dp la kf lb lc ld kj le lf lg kn lh li lj lk bi translated"><strong class="ak">特征向量和特征值</strong></h2><p id="5acd" class="pw-post-body-paragraph ju jv iq jw b jx ll jz ka kb lm kd ke kf ln kh ki kj lo kl km kn lp kp kq kr ij bi translated">特征向量和特征值如何适应所有这些？</p><p id="189e" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在线性变换期间，可能存在一些保持在它们的原始跨度上的向量，并且仅被缩放或收缩。换句话说，它们的方向保持<em class="lq">不变</em>。数学上，它被表达为—</p><figure class="lr ls lt lu gt lw gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/2b57ecd9474a09c0100ea4663cad54a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:298/format:webp/1*c0sNiNOCMlZ2x73VmR3lTw.png"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">由变换 A 给出的特征向量 x 的表达式</p></figure><p id="43fe" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">λ是与特征向量<em class="lq"> x </em>相关联的特征值，矩阵 A 被称为应用于向量<em class="lq"> x </em>的变换。</p><figure class="lr ls lt lu gt lw gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/286b10f2963575732a68b1c638714f64.png" data-original-src="https://miro.medium.com/v2/resize:fit:342/format:webp/1*1Vb9un7gCFz1Ml1POrcQEg.png"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">表示为变换函数的特征向量</p></figure><p id="f074" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">从几何学上讲，我们可以用下面的方式来形象化它</p><figure class="lr ls lt lu gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi my"><img src="../Images/5995707ba63f4169e06a5116e3175a64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bOrROp502V4QF9_pZcsFvQ.png"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">向量 x 上的变换导致将其拉伸 2 倍(请注意，方向或跨度没有变化)</p></figure><p id="a24d" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">这里，对向量<em class="lq"> x </em>的变换将它拉伸到两倍的长度。因此，与该变换相关的特征值是 2。负特征值与<em class="lq">翻转</em>向量或反转向量方向相关。</p><h2 id="0be2" class="ks kt iq bd ku kv kw dn kx ky kz dp la kf lb lc ld kj le lf lg kn lh li lj lk bi translated">是什么让它们如此有用？</h2><p id="3b72" class="pw-post-body-paragraph ju jv iq jw b jx ll jz ka kb lm kd ke kf ln kh ki kj lo kl km kn lp kp kq kr ij bi translated">由特征向量给出的坐标系被称为<em class="lq">特征基，</em>它可以写成对角矩阵，因为它将每个基向量缩放了某个值。</p><figure class="lr ls lt lu gt lw gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/12ca2e540122e8bd91fcea64e30832fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*hneqXRiufBOk6ZfvvnJN9A.png"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">具有 N 个特征向量的对角矩阵</p></figure><p id="6b36" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">对角矩阵使计算变得非常容易。考虑将矩阵提升到 100 的幂，在非对角矩阵的情况下，这将成为一项艰巨的任务。在对角矩阵的情况下，计算相当简单。</p><figure class="lr ls lt lu gt lw gh gi paragraph-image"><div class="gh gi na"><img src="../Images/97c1afed6561097d91a170e80303fbce.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*MWDmqI_LE23GfC5x_XeC7Q.png"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">对角矩阵使计算更容易</p></figure><p id="f2d4" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">根据 PCA </strong></p><p id="ce02" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">PCA 的目标是<em class="lq">最小化冗余</em>和<em class="lq">最大化方差</em>以更好地表达数据。这是通过找到与数据点的协方差矩阵相关联的特征向量来实现的。然后将数据投影到由这些特征向量构成的新坐标系上。要进一步了解 PCA，请查阅参考文献[1]和[2]。</p><p id="e1ec" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我希望这能作为对特征向量的直观理解，并帮助你更好地理解 PCA 算法。</p><p id="a4e0" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">参考文献</strong>—</p><p id="183b" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">所有的图表都是用-<a class="ae nb" href="https://www.desmos.com/geometry/355373dbed" rel="noopener ugc nofollow" target="_blank">https://www.desmos.com/</a>制作的</p><ol class=""><li id="9bdd" class="nc nd iq jw b jx jy kb kc kf ne kj nf kn ng kr nh ni nj nk bi translated">PCA 教程—<a class="ae nb" href="https://arxiv.org/pdf/1404.1100.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1404.1100.pdf</a></li><li id="ad7e" class="nc nd iq jw b jx nl kb nm kf nn kj no kn np kr nh ni nj nk bi translated"><a class="ae nb" href="http://www.math.union.edu/~jaureguj/PCA.pdf" rel="noopener ugc nofollow" target="_blank">http://www.math.union.edu/~jaureguj/PCA.pdf</a></li><li id="5694" class="nc nd iq jw b jx nl kb nm kf nn kj no kn np kr nh ni nj nk bi translated"><a class="ae nb" href="https://www.khanacademy.org/math/linear-algebra/alternate-bases/eigen-everything/v/linear-algebra-showing-that-an-eigenbasis-makes-for-good-coordinate-systems" rel="noopener ugc nofollow" target="_blank">https://www.khanacademy.org/math/linear-algebra/</a></li><li id="e107" class="nc nd iq jw b jx nl kb nm kf nn kj no kn np kr nh ni nj nk bi translated">关于线性代数的精彩系列 3 blue 1 brown—【https://www.youtube.com/watch?v=fNk_zzaMoSs】T2&amp;list = plzhqobowt qd D3 mizm 2 xvfitgf 8 he _ ab&amp;index = 1</li></ol></div></div>    
</body>
</html>