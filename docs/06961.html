<html>
<head>
<title>Which Mask Are You Wearing? Face Mask Type Detection with TensorFlow and Raspberry Pi</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你戴的是哪个面具？基于张量流和树莓 Pi 的人脸类型检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/which-mask-are-you-wearing-face-mask-type-detection-with-tensorflow-and-raspberry-pi-1c7004641f1?source=collection_archive---------23-----------------------#2020-05-29">https://towardsdatascience.com/which-mask-are-you-wearing-face-mask-type-detection-with-tensorflow-and-raspberry-pi-1c7004641f1?source=collection_archive---------23-----------------------#2020-05-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/9d727ba5f2c5d3ae2968957ff0b87d0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/1*7JutDm_XnT6dYJte0zRCOg.gif"/></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">使用右下角显示的 Raspberry Pi 4 进行实时人脸检测。(图片由作者提供)</p></figure><p id="6813" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我如何使用 TensorFlow 和 Raspberry Pi 构建一个实时面罩类型检测器来判断一个人是否戴着面罩以及他们戴的是什么类型的面罩</p><p id="4ef3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我使用的代码和 Google Colab 笔记本在 GitHub 上有<a class="ae kz" href="https://github.com/wangyifan411/Face-Mask-Type-Detector" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="e220" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">动机</h1><p id="805e" class="pw-post-body-paragraph kb kc it kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">强制戴口罩的规定在世界各地的公共场合变得越来越普遍。越来越多的科学证据支持戴口罩对减少病毒传播的有效性[ <a class="ae kz" href="https://science.sciencemag.org/content/early/2020/05/27/science.abc6197?utm_campaign=SciMag&amp;utm_source=JHubbard&amp;utm_medium=Facebook" rel="noopener ugc nofollow" target="_blank"> 2 </a>、<a class="ae kz" href="https://www.preprints.org/manuscript/202004.0203/v1?fbclid=IwAR0XQTr11EM2n3xGsxmR1FGLNnjYLZgaysxyVMgRQOjkgRdT7knoGPir4NE" rel="noopener ugc nofollow" target="_blank"> 3 </a> ]。然而，我们也看到了一些对口罩的反弹，给执行规则的人带来了危险。在美国的一些地方，他们经常是商店的雇员，和其他人一样容易受到伤害。那么我们能让 AI 派上用场吗？</p><p id="dd52" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这激发了这项工作，以开发一个深度学习模型，该模型可以检测一个人是否戴着面罩，以及这个人戴着什么类型的面罩。口罩的类型与口罩的有效性有关[ <a class="ae kz" href="https://www.nytimes.com/interactive/2020/health/coronavirus-best-face-masks.html" rel="noopener ugc nofollow" target="_blank"> 4 </a> ]。该模型有可能被部署在当地超市或学校建筑中，以控制自动门，该自动门只对戴口罩的人开放。</p><p id="0475" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">当我完成 Coursera 上的<a class="ae kz" href="https://www.coursera.org/specializations/deep-learning" rel="noopener ugc nofollow" target="_blank">深度学习专业时，我认为这是一个获得一些深度学习项目实践经验的绝佳机会，人脸面具检测是一个非常相关的话题。这篇文章主要关注从数据收集到建模训练(使用 TensorFlow 对象检测 API 和 Google Colab)以及在移动设备上部署(一个 Raspberry Pi 4)的开发流程。这不是一个循序渐进的教程，但我可以给你指出有用的资源，并提供一些设计自己的项目的技巧。</a></p><h1 id="2835" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated"><strong class="ak">数据收集</strong></h1><p id="0c19" class="pw-post-body-paragraph kb kc it kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">这是一个重要但经常被忽视的步骤。俗话说“垃圾进，垃圾出”，用于训练的数据应该与目标具有相似的分布，即<strong class="kd iu">网络摄像头</strong>捕捉到的真实生活中带面具和不带面具的人脸。来自视频源的图像通常受相机质量和不同光线设置的影响。因此，我们的数据集不仅在不同性别、年龄组、种族、戴眼镜和不戴眼镜的人脸方面，而且在图像背景方面都应该是多样化的。</p><p id="8825" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我决定用自制布套、外科口罩、n95 口罩和无口罩 4 个类(口罩类型)来训练模型。相应的标签有:</p><ul class=""><li id="8471" class="md me it kd b ke kf ki kj km mf kq mg ku mh ky mi mj mk ml bi translated">自制的</li><li id="eee0" class="md me it kd b ke mm ki mn km mo kq mp ku mq ky mi mj mk ml bi translated">外科的</li><li id="0e71" class="md me it kd b ke mm ki mn km mo kq mp ku mq ky mi mj mk ml bi translated">n95</li><li id="8b93" class="md me it kd b ke mm ki mn km mo kq mp ku mq ky mi mj mk ml bi translated">空的</li></ul><p id="671e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这些图片是从 Google images 和 Upslash 上收集的。我发现批量下载图片的 chrome 插件<a class="ae kz" href="https://chrome.google.com/webstore/detail/fatkun-batch-download-ima/nnjjahlikiabnchcpehcpkdeckfgnohf?hl=en" rel="noopener ugc nofollow" target="_blank"> Fatkun </a>非常有用。但是，应该仔细选择图像，以确保数据集的质量和多样性。对于多少张图片才算足够，没有很好答案。对于一个小模型，我试着为每个类保存大约 200 张图片，它们应该代表模型可能遇到的子类。示例如下所示:</p><ul class=""><li id="1e4e" class="md me it kd b ke kf ki kj km mf kq mg ku mh ky mi mj mk ml bi translated">自制的</li></ul><figure class="ms mt mu mv gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi mr"><img src="../Images/c2902c0ae245e4fc09a567713a9ee2b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RG0-ke_sJlHyAdnPmbRDlw.png"/></div></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">自制面具，包括布面具或覆盖物。请注意，有些口罩覆盖整个颈部。(图片来自 Upslash。从左至右依次为<a class="ae kz" href="https://unsplash.com/@sharonmccutcheon" rel="noopener ugc nofollow" target="_blank">莎朗·麦卡琴</a>、<a class="ae kz" href="https://unsplash.com/photos/bEDh-PxXZ0c" rel="noopener ugc nofollow" target="_blank">来源</a>；<a class="ae kz" href="https://unsplash.com/@lgnwvr" rel="noopener ugc nofollow" target="_blank">洛根·韦弗</a>，<a class="ae kz" href="https://unsplash.com/photos/qQ_MidV6yfs" rel="noopener ugc nofollow" target="_blank">来源</a>；<a class="ae kz" href="https://unsplash.com/@zvessels55" rel="noopener ugc nofollow" target="_blank">札克血管</a>，<a class="ae kz" href="https://unsplash.com/photos/NuK_3ds2lWs" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><ul class=""><li id="4997" class="md me it kd b ke kf ki kj km mf kq mg ku mh ky mi mj mk ml bi translated">外科的</li></ul><figure class="ms mt mu mv gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi mr"><img src="../Images/00a8fd7ec671dce02b515f906c6fa4f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YGm4Gwib6sDGOyxr1VdLyw.png"/></div></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">不同颜色的外科口罩。(图片来自 Upslash。从左至右依次为<a class="ae kz" href="https://unsplash.com/@hikeshaw" rel="noopener ugc nofollow" target="_blank"> H 肖</a>、<a class="ae kz" href="https://unsplash.com/photos/XeylIhk5lDU" rel="noopener ugc nofollow" target="_blank">来源</a>；<a class="ae kz" href="https://unsplash.com/@enginakyurt" rel="noopener ugc nofollow" target="_blank"> engin akyurt </a>，<a class="ae kz" href="https://unsplash.com/photos/AS-ksEGPa2c" rel="noopener ugc nofollow" target="_blank">来源</a>；<a class="ae kz" href="https://unsplash.com/@julianwan" rel="noopener ugc nofollow" target="_blank">朱里安万</a>，<a class="ae kz" href="https://unsplash.com/photos/DWaC44FUV5o" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><ul class=""><li id="f193" class="md me it kd b ke kf ki kj km mf kq mg ku mh ky mi mj mk ml bi translated">n95</li></ul><figure class="ms mt mu mv gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi mr"><img src="../Images/0976534bee0189a82384893cd0f1e4c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OSeVf1z6vUERY2H8D-l2LA.png"/></div></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">不同形状和颜色的 N95 口罩。肖像和侧面都包括在内。(图片来自 Upslash。从左至右依次为<a class="ae kz" href="https://unsplash.com/@agiantexplorer" rel="noopener ugc nofollow" target="_blank">汉德罗沙曼</a>、<a class="ae kz" href="https://unsplash.com/photos/b2iQ-ukXlpo" rel="noopener ugc nofollow" target="_blank">来源</a>；<a class="ae kz" href="https://unsplash.com/@duongdaihiep123" rel="noopener ugc nofollow" target="_blank"> Hiep Duong </a>，<a class="ae kz" href="https://unsplash.com/photos/YLwzxM8Ssgs" rel="noopener ugc nofollow" target="_blank">来源</a>；<a class="ae kz" href="https://unsplash.com/@ashkfor121" rel="noopener ugc nofollow" target="_blank">阿什坎·弗鲁扎尼</a>，<a class="ae kz" href="https://unsplash.com/photos/IXSgwfBGnCg" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><ul class=""><li id="abde" class="md me it kd b ke kf ki kj km mf kq mg ku mh ky mi mj mk ml bi translated">空的</li></ul><figure class="ms mt mu mv gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi mr"><img src="../Images/5592231e82bb44e0f00729cc837e8894.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ToPWPjGfKzCXejdK_gvf4g.png"/></div></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">不同性别，不同年龄段，不同种族，不同背景的裸照。(图片来自 Upslash。从左至右由<a class="ae kz" href="https://unsplash.com/@hoppingfrogstudios" rel="noopener ugc nofollow" target="_blank">大卫托德麦卡蒂</a>、<a class="ae kz" href="https://unsplash.com/photos/40Qn27ZVuH0" rel="noopener ugc nofollow" target="_blank">来源</a>；<a class="ae kz" href="https://unsplash.com/@miracletwentyone" rel="noopener ugc nofollow" target="_blank">约瑟夫·冈萨雷斯</a>，<a class="ae kz" href="https://unsplash.com/photos/iFgRcqHznqg" rel="noopener ugc nofollow" target="_blank">来源</a>；<a class="ae kz" href="https://unsplash.com/@timmossholder" rel="noopener ugc nofollow" target="_blank">蒂姆·莫斯霍尔德</a>，<a class="ae kz" href="https://unsplash.com/@timmossholder" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="c55f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">每节课我分别收集了 247，197，184，255 张图片，总共用了~5 个小时，期间我见过那么多带面具的脸。不幸的是，戴着外科口罩和 n95 口罩的人的照片很难找到，尤其是在 3 月(疫情早期)，我在搜索他们的时候。这些图像大多来自东亚国家或卫生工作者的库存照片。</p><h1 id="0a38" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">建模培训</h1><p id="4faf" class="pw-post-body-paragraph kb kc it kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">我用我的 Windows 10 笔记本电脑进行了数据预处理、测试，并将模型转换为 TensorFlow lite 版本。对于模型训练，我用的是 Google Colab 配合 Google 提供的免费 GPU。</p><p id="e077" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">使用<a class="ae kz" href="https://github.com/tensorflow/models/tree/master/research/object_detection" rel="noopener ugc nofollow" target="_blank"> TensorFlow 对象检测 API </a>训练对象检测模型可分为以下主要步骤:</p><ol class=""><li id="3051" class="md me it kd b ke kf ki kj km mf kq mg ku mh ky na mj mk ml bi translated">设置 TensorFlow 环境和工作空间</li></ol><p id="f30b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这一步可能很棘手，因为对象检测 API 还不可用于最新的 TensorFlow 版本 2.x，因此需要 TensorFlow 1.x。如果您想在本地 PC 上利用 CUDA 内核进行加速，可以使用 TensorFlow 的 GPU 版本。我发现这两个教程非常有用:</p><div class="nb nc gp gr nd ne"><a href="https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/index.html" rel="noopener  ugc nofollow" target="_blank"><div class="nf ab fo"><div class="ng ab nh cl cj ni"><h2 class="bd iu gy z fp nj fr fs nk fu fw is bi translated">TensorFlow 对象检测 API 教程- TensorFlow 对象检测 API 教程文档</h2><div class="nl l"><h3 class="bd b gy z fp nj fr fs nk fu fw dk translated">重要说明:本教程适用于 TensorFlow 1.14，它(在撰写本教程时)是最新的…</h3></div><div class="nm l"><p class="bd b dl z fp nj fr fs nk fu fw dk translated">tensor flow-object-detection-API-tutorial . readthedocs . io</p></div></div></div></a></div><div class="nb nc gp gr nd ne"><a href="https://pythonprogramming.net/introduction-use-tensorflow-object-detection-api-tutorial/" rel="noopener  ugc nofollow" target="_blank"><div class="nf ab fo"><div class="ng ab nh cl cj ni"><h2 class="bd iu gy z fp nj fr fs nk fu fw is bi translated">Python 编程教程</h2><div class="nl l"><h3 class="bd b gy z fp nj fr fs nk fu fw dk translated">大家好，欢迎收看关于 TensorFlow 对象检测 API 的迷你系列和介绍。该 API 可用于…</h3></div><div class="nm l"><p class="bd b dl z fp nj fr fs nk fu fw dk translated">pythonprogramming.net</p></div></div><div class="nn l"><div class="no l np nq nr nn ns jv ne"/></div></div></a></div><p id="4dca" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">Stackoverflow 上的一些搜索可以修复 bug，帮助你让 TensorFlow 运行起来。在 conda 环境中工作可以节省很多管理混乱的依赖关系的工作。另外，在安装特定版本的 Python、TensorFlow 或 CUDA 之前，不要忘记检查<a class="ae kz" href="https://www.tensorflow.org/install/source_windows#tested_build_configurations" rel="noopener ugc nofollow" target="_blank">配置兼容性</a>。</p><figure class="ms mt mu mv gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi nt"><img src="../Images/d41aef573b9e32089180763cef9e2bf6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KI0s0lVz-i9rPsvIT6_3PA.png"/></div></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">TensorFlow GPU、Python 和 CUDA 的兼容配置(图片来自<a class="ae kz" href="https://www.tensorflow.org/install/source_windows#tested_build_configurations" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>)</p></figure><p id="1bcc" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我的笔记本电脑和 Google Drive 上的工作区都有以下目录结构:</p><pre class="ms mt mu mv gt nu nv nw nx aw ny bi"><span id="a452" class="nz lb it nv b gy oa ob l oc od">TensorFlow<br/>├─ models<br/>│   ├─ official<br/>│   ├─ research<br/>│   ├─ samples<br/>│   └─ tutorials<br/>└─ workspace<br/>    ├─ preprocessing<br/>    ├─ annotations<br/>    ├─ images<br/>    │   ├─ test<br/>    │   └─ train<br/>    ├─ pre-trained-model<br/>    ├─ training<br/>    └─ trained-inference-graphs<br/>       ├─ output_inference_graph_mobile.pb<br/>       └─ TFLite_model</span></pre><p id="f332" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">2.预处理用于训练的图像</p><p id="b244" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">首先，图像需要标注标签。你可能会注意到，上面的一些图像有不止一个人戴着口罩，一些图像有复杂的背景。在这些面具周围放置锚框有助于模型通过关注框内的局部区域并提取特定特征来更快地学习。这个过程相当乏味，我花了大约 4 个小时来标记大约 800 张图片，并且我使用了一个叫做<a class="ae kz" href="https://github.com/tzutalin/labelImg" rel="noopener ugc nofollow" target="_blank"> LabelImg </a>的 Python 包。本质上，我所做的是在人们的面具周围画出方框(如果他们没有戴面具，在他们眼睛下方和脖子上方的区域)，并将每个方框与一个标签相关联。</p><p id="cda4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">接下来，数据集以 9 比 1 的比例分成训练集和测试集。我没有设置验证集，因为这只是一个原型模型，但在机器学习中这样做总是一个好的做法。</p><p id="46c3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">3.创建标注图和张量流记录</p><p id="3be4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">TensorFlow 读入保存在<code class="fe oe of og nv b">label_map.pbtxt</code>中的标签映射，这是类标签到整数值的映射。在这种情况下，该文件类似于:</p><pre class="ms mt mu mv gt nu nv nw nx aw ny bi"><span id="6148" class="nz lb it nv b gy oa ob l oc od">item {<br/>    id: 1<br/>    name: 'homemade'<br/>}</span><span id="d5a1" class="nz lb it nv b gy oh ob l oc od">item {<br/>    id: 2<br/>    name: 'surgical'<br/>}</span><span id="2f99" class="nz lb it nv b gy oh ob l oc od">item {<br/>    id: 3<br/>    name: 'n95'<br/>}</span><span id="ddf0" class="nz lb it nv b gy oh ob l oc od">item {<br/>    id: 4<br/>    name: 'bare'<br/>}</span></pre><p id="7fb3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">注释需要转换为 TFRecord 文件，如<code class="fe oe of og nv b">test.record</code>和<code class="fe oe of og nv b">train.record</code>。</p><p id="9ac6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">4.选择模型并开始训练</p><p id="dbf6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">深度学习模型有数百万个参数，从头开始训练它们通常需要大量数据，而我们这里没有这些数据。一种有用的技术是转移学习，它采用在其他图像集上训练的预训练模型，并在新的任务中重用它(<a class="ae kz" href="https://www.tensorflow.org/tutorials/images/transfer_learning" rel="noopener ugc nofollow" target="_blank">这里显示的一个例子</a>)。大多数参数是固定的，而顶层中的一些参数针对新任务进行了微调。</p><p id="16b0" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">因为我想在计算能力有限的移动设备上使用该模型，所以速度是重中之重。在<a class="ae kz" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md" rel="noopener ugc nofollow" target="_blank"> TensorFlow 的检测模型 zoo </a>的表格中可以找到一组预先训练好的模型。我选择了一个轻量级的型号，<code class="fe oe of og nv b">ssd_mobilenet_v2_coco</code> [ <a class="ae kz" href="https://arxiv.org/abs/1512.02325" rel="noopener ugc nofollow" target="_blank"> 5 </a> ]，来平衡速度和精度之间的权衡。</p><p id="6808" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我试着在我的笔记本电脑和谷歌实验室上训练这个模型。如果你没有超快的 GPU，我肯定会推荐你使用 Colab。在我的笔记本电脑上用 GeForce MX250 GPU 训练这样一个小模型大约 20K 步需要大约 10 个小时，在 Colab 上需要大约 2 个小时。速度提高了 5 倍，同时我可以在笔记本电脑上做其他事情。用于培训的 Colab 笔记本可以在<a class="ae kz" href="https://github.com/wangyifan411/Face-Mask-Type-Detector" rel="noopener ugc nofollow" target="_blank">这个 GitHub 库</a>上找到。</p><p id="85d5" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">关于 TensorFlow 的一个很酷的事情是，你可以在训练期间使用 TensorBoard 监控指标(损失和准确性)。正如你所看到的，损失逐渐减少并趋于平稳，我决定不再等待，并在 20K 步后停止训练。另一个很酷的特点是你可以随时从你停止的地方继续训练。</p><figure class="ms mt mu mv gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi oi"><img src="../Images/fd79ed0d9e774fd30392f5f645981734.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cX2FYgUhXSyQF711yyNG1w.png"/></div></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">TensorBoard 示例。(图片由作者提供)</p></figure><p id="d48c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">5.导出模型并测试它</p><p id="f6a1" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">该模型被导出到冻结的推理图中。可以通过运行<code class="fe oe of og nv b">model_test_webcam.py</code>来测试。</p><p id="28aa" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">最初，我没有包括无面具(裸露)脸的类，因为我认为模型不会在脸上画锚框，这表明这个人没有戴面具。结果证明我错了。它没有学习裸露面部的任何特征，并将一张脸识别为自制的面具。因此，我用一个新的类和裸面数据集重新训练了模型。我从这个过程中学到的是数据集设计的重要性，模型只能学习你让它学习的东西。最初快速建立模型，然后迭代也是明智的。</p><figure class="ms mt mu mv gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi oj"><img src="../Images/bc2dc92fc2ef278ffcbcb68a03c8fa59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZSb_MJb08sVuCNTo3EJg4w.png"/></div></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">没有“裸”类的初始模型的分类结果。(图片由作者提供)</p></figure><p id="061c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我在来自互联网(不在训练/测试集中)和一个朋友的更多图片上验证了新模型。现在它可以识别裸露的面孔了！</p><figure class="ms mt mu mv gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi mr"><img src="../Images/705d803ffdf1d7fcf7bde643d2f50b4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*64EPCytY66sso1aNtQkSiw.png"/></div></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">来自 Upslash 的用于模型验证的图像。(在最上面一行，从左至右，图片由<a class="ae kz" href="https://unsplash.com/@nataliacsb" rel="noopener ugc nofollow" target="_blank">娜塔莉亚·巴罗斯</a>、<a class="ae kz" href="https://unsplash.com/photos/3TnUCHoqMHM" rel="noopener ugc nofollow" target="_blank">来源</a>；<a class="ae kz" href="https://unsplash.com/@miracletwentyone" rel="noopener ugc nofollow" target="_blank"> </a> <a class="ae kz" href="https://unsplash.com/@pressfeatures" rel="noopener ugc nofollow" target="_blank">按下特征</a>，<a class="ae kz" href="https://unsplash.com/photos/S_8rGErVlH4" rel="noopener ugc nofollow" target="_blank">来源</a>；<a class="ae kz" href="https://unsplash.com/@simmerdownjpg" rel="noopener ugc nofollow" target="_blank">杰克逊煨</a>，<a class="ae kz" href="https://unsplash.com/photos/eOmWOSclN8E" rel="noopener ugc nofollow" target="_blank">来源</a>。在最下面一行，从左到右，图片由<a class="ae kz" href="https://unsplash.com/@hikeshaw" rel="noopener ugc nofollow" target="_blank"> H Shaw </a>、<a class="ae kz" href="https://unsplash.com/photos/UhOIDLhhIcI" rel="noopener ugc nofollow" target="_blank">source</a>；<a class="ae kz" href="https://unsplash.com/@miracletwentyone" rel="noopener ugc nofollow" target="_blank"> </a> <a class="ae kz" href="https://unsplash.com/@nate_dumlao" rel="noopener ugc nofollow" target="_blank">内森·杜姆劳</a><a class="ae kz" href="https://unsplash.com/photos/JhrY9cwogzo" rel="noopener ugc nofollow" target="_blank">出处</a>；<a class="ae kz" href="https://unsplash.com/@brianisalive" rel="noopener ugc nofollow" target="_blank">布莱恩·万根海姆</a>，<a class="ae kz" href="https://unsplash.com/photos/wCqiHkjX1ZU" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><figure class="ms mt mu mv gt ju gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/7eb1fa252560663f0aed7257399c88d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*Ztskz6YFXnZ4RvOGD3AI8Q.png"/></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">和一个朋友在弱光下测试。所有口罩都贴上了正确的标签！(图片由作者提供)</p></figure><p id="9646" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">6.将模型导出到 Raspberry Pi</p><figure class="ms mt mu mv gt ju gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/65a2afbdee1ab1028ac3ff4003715e68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/1*j07istJdCWNPjvAYlf9_Ig.png"/></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">Raspberry Pi 4 和一个摄像头模块(图片由<a class="ae kz" href="http://www.raspberrypi.org" rel="noopener ugc nofollow" target="_blank"> Raspberrypi </a>拍摄，来源:<a class="ae kz" href="https://www.raspberrypi.org/products/raspberry-pi-4-model-b/" rel="noopener ugc nofollow" target="_blank"> pi 4 </a>，<a class="ae kz" href="https://www.raspberrypi.org/products/camera-module-v2/" rel="noopener ugc nofollow" target="_blank">摄像头模块 v2 </a></p></figure><p id="4369" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">Raspberry Pi 是一款信用卡大小的迷你电脑，价格非常实惠(第四代售价约 35 美元)。有了 TensorFlow 的支持，它是部署模型的完美移动设备。除了树莓派，相机模块(约 30 美元)需要单独购买。</p><p id="962a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">出于计算速度和隐私的原因，<a class="ae kz" href="https://www.tensorflow.org/lite/guide" rel="noopener ugc nofollow" target="_blank"> TensorFlow Lite 模型</a>需要用于移动设备，如 Raspberry Pi。本教程介绍了如何在 Window PC 上将经过训练的张量流推理图转换为精简模型，并在 Raspberry Pi 上运行:</p><div class="nb nc gp gr nd ne"><a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi" rel="noopener  ugc nofollow" target="_blank"><div class="nf ab fo"><div class="ng ab nh cl cj ni"><h2 class="bd iu gy z fp nj fr fs nk fu fw is bi translated">edjee electronics/tensor flow-Lite-Android-and-Raspberry-Pi 上的对象检测</h2><div class="nl l"><h3 class="bd b gy z fp nj fr fs nk fu fw dk translated">本指南展示了如何训练 TensorFlow Lite 对象检测模型，并在 Android、Raspberry Pi 和</h3></div><div class="nm l"><p class="bd b dl z fp nj fr fs nk fu fw dk translated">github.com</p></div></div><div class="nn l"><div class="om l np nq nr nn ns jv ne"/></div></div></a></div><p id="dc3e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">最后，是玩模型的时候了！</p><p id="2006" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">最后的结果显示在开始的 GIF 和下面的图片中。整体模型性能似乎很好。然而，即使我选择了轻型 SSD Mobilenet，每秒 2.5 帧(FPS)也不算太差，但也不是很快。通过选择固态硬盘或量化模型，可以进一步加速。</p><figure class="ms mt mu mv gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi mr"><img src="../Images/c38dabc7186bd7dfd61b93ef4b50bb53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JxBWvGatJpEEMMos3zO-yA.png"/></div></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">树莓派相机的测试图像。(图片由作者提供)</p></figure><h1 id="8265" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">结论和要点</h1><p id="280a" class="pw-post-body-paragraph kb kc it kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">在我自己建立了一个对象检测模型之后，我发现构建一个深度学习项目绝对不仅仅是参数调整和设计神经网络架构。</p><p id="00e9" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">最乏味和耗时的部分是收集和预处理数据。设置 TensorFlow 环境也很棘手，随着 TensorFlow 变得更加自动化，这一问题有望在不久的将来得到解决。主要要点是:</p><ul class=""><li id="9af6" class="md me it kd b ke kf ki kj km mf kq mg ku mh ky mi mj mk ml bi translated">现实生活中的数据是复杂的。我们应该选择每个班级的代表形象</li><li id="4ce3" class="md me it kd b ke mm ki mn km mo kq mp ku mq ky mi mj mk ml bi translated">当我们有一个小的数据集时，迁移学习是有用的</li><li id="5b7c" class="md me it kd b ke mm ki mn km mo kq mp ku mq ky mi mj mk ml bi translated">我们应该坚持快速原型化和迭代改进模型的指导方针</li><li id="3b49" class="md me it kd b ke mm ki mn km mo kq mp ku mq ky mi mj mk ml bi translated">最后，毫无疑问，在公共场所戴口罩，不管是哪种口罩</li></ul><p id="5ab2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">感谢阅读，保持健康！</p><h1 id="6a09" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">参考</h1><p id="8ae5" class="pw-post-body-paragraph kb kc it kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">[1] <a class="ae kz" href="https://www.npr.org/sections/coronavirus-live-updates/2020/05/28/864241210/no-mask-no-entry-cuomo-says-as-he-allows-businesses-to-insist-on-face-coverings" rel="noopener ugc nofollow" target="_blank">沙佩尔，B. (2020 年 5 月 28 日)。“不戴口罩——禁止入内，”科莫说，他允许商家坚持戴口罩。<em class="on">NPR</em>T11】</a></p><p id="ce10" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">[2] <a class="ae kz" href="https://science.sciencemag.org/content/early/2020/05/27/science.abc6197?utm_campaign=SciMag&amp;utm_source=JHubbard&amp;utm_medium=Facebook" rel="noopener ugc nofollow" target="_blank"> Prather，A. K .等人(2020 年 5 月 27 日)。减少新型冠状病毒的传播。<em class="on">理科</em> </a></p><p id="6b41" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">[3]霍华德，j；黄；李；Tufekci，z；兹迪马尔诉；范德韦斯特休伊曾；冯·代尔夫特；价格，A 弗里德曼；唐；唐五世；沃森；Bax，C.E 谢赫河；Questier，f；埃尔南德斯博士；褚来福；拉米雷斯；《反对新冠肺炎的面具:证据回顾》。<em class="on">预印本</em> <strong class="kd iu"> 2020 </strong>，202004 02 03(doi:10.20944/Preprints 202004.0203 . v1)。</p><p id="9eb2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">[4] <a class="ae kz" href="https://www.nytimes.com/interactive/2020/health/coronavirus-best-face-masks.html" rel="noopener ugc nofollow" target="_blank">帕克-波普等人(2020 年 4 月 17 日)。冠状病毒:你应该戴哪种口罩？。<em class="on">《纽约时报》</em> </a></p><p id="1826" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">[5] <a class="ae kz" href="https://arxiv.org/abs/1512.02325" rel="noopener ugc nofollow" target="_blank">刘，w，安盖洛夫，d，尔汉，d，塞格迪，c，里德，s，傅，C. Y，&amp;伯格，A. C. SSD:单次多盒探测器。arXiv 2016。<em class="on"> arXiv 预印本 arXiv:1512.02325 </em>。</a></p></div></div>    
</body>
</html>