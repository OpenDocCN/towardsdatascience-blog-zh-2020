<html>
<head>
<title>Sentiment Analysis and Product Recommendation on Amazon’s Electronics Dataset Reviews - Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">亚马逊电子数据集评论的情感分析和产品推荐——第二部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/sentiment-analysis-and-product-recommendation-on-amazons-electronics-dataset-reviews-part-2-de71649de42b?source=collection_archive---------22-----------------------#2020-05-23">https://towardsdatascience.com/sentiment-analysis-and-product-recommendation-on-amazons-electronics-dataset-reviews-part-2-de71649de42b?source=collection_archive---------22-----------------------#2020-05-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="db23" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">第2部分:情感分析和产品推荐</h2></div><h1 id="c383" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">情感分析</h1><p id="6124" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi lw translated">机器学习模型以数值作为输入。评论是由句子组成的，所以为了从数据中提取模式；我们需要找到一种方法，以机器学习算法可以理解的方式来表示它，即作为一系列数字。</p><h1 id="545a" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">特征抽出</h1><p id="aed4" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">特征工程是使用数据的领域知识来创建使机器学习算法工作的特征的过程。要素本质上通常是数字，可以是绝对数值或分类要素，可以使用一种称为“一键编码”的过程将这些要素编码为列表中每个类别的二进制要素。提取和选择特征的过程既是艺术又是科学，这个过程称为特征提取或特征工程。</p><p id="bfa7" class="pw-post-body-paragraph la lb it lc b ld mf ju lf lg mg jx li lj mh ll lm ln mi lp lq lr mj lt lu lv im bi translated">作为其中的一部分，单词包模型、TF-IDF、哈希矢量器、Word2Vec以及将最常见的单词添加到停用词列表、SMOTE、PCA和截断SVD技术作为特征工程和选择的一部分添加到以下部分中的分类模型中。</p><h1 id="8c96" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">数据预处理</h1><p id="cd2c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">出于计算方面的考虑，2010年早些时候评论的good_rating_class_reviews超过150个单词的功能被删除。最终的数据集由15000个观察值组成。从数据集中，“干净文本”和“评级类别”分别被视为“X”(特征)和“Y”(变量)。数据集被分成75%作为训练，25%作为测试。</p><h1 id="ad39" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">机器学习模型</h1><p id="0621" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">该模型需要根据从亚马逊购买耳机的客户撰写的评论来预测情绪。这是一个有监督的二元分类问题。Python的Scikit库被用来解决这个问题。实现了以下机器学习算法。</p><h2 id="54a8" class="mk kj it bd kk ml mm dn ko mn mo dp ks lj mp mq ku ln mr ms kw lr mt mu ky mv bi translated"><strong class="ak">逻辑回归</strong></h2><p id="e9ae" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">逻辑回归，尽管它的名字，是一个线性模型的分类，而不是回归。逻辑回归在文献中也称为logit回归、最大熵分类(MaxEnt)或对数线性分类器。在这个模型中，描述单个试验的可能结果的概率使用逻辑函数建模。</p><h2 id="1c22" class="mk kj it bd kk ml mm dn ko mn mo dp ks lj mp mq ku ln mr ms kw lr mt mu ky mv bi translated"><strong class="ak">朴素贝叶斯</strong></h2><p id="48ea" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">朴素贝叶斯为多项式分布数据实现了朴素贝叶斯算法，并且是文本分类中使用的两种经典朴素贝叶斯变体之一(其中数据通常表示为词向量计数)。该算法是流行的朴素贝叶斯算法的一个特例，它专门用于我们有两个以上类的预测和分类任务。</p><h2 id="7b2e" class="mk kj it bd kk ml mm dn ko mn mo dp ks lj mp mq ku ln mr ms kw lr mt mu ky mv bi translated"><strong class="ak">随机森林分类器</strong></h2><p id="b546" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">随机森林是一种元估计器，它在数据集的各个子样本上拟合多个决策树分类器，并使用平均来提高预测精度和控制过拟合。子样本大小始终与原始输入样本大小相同，但如果bootstrap=True(默认)，则使用替换来绘制样本。</p><h2 id="9c04" class="mk kj it bd kk ml mm dn ko mn mo dp ks lj mp mq ku ln mr ms kw lr mt mu ky mv bi translated"><strong class="ak"> XGBoost分类器</strong></h2><p id="ccb3" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">XGBoost的意思是极端的梯度增强。XGBoost是一个基于决策树的集成机器学习算法，它使用了一个<a class="ae mw" href="https://en.wikipedia.org/wiki/Gradient_boosting?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">梯度推进</a>框架。在涉及非结构化数据(图像、文本等)的预测问题中。)人工神经网络往往优于所有其他算法或框架。然而，当涉及到中小型结构化/表格数据时，基于决策树的算法目前被认为是同类最佳的。</p><h2 id="6b40" class="mk kj it bd kk ml mm dn ko mn mo dp ks lj mp mq ku ln mr ms kw lr mt mu ky mv bi translated"><strong class="ak"> CatBoost分类器</strong></h2><p id="b4ee" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">CatBoost是一种在决策树上进行梯度提升的算法。“CatBoost”名字来源于两个词“Category”和“Boosting”。该库适用于多种类别的数据，如音频、文本、图像，包括历史数据。</p><h1 id="0392" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">评估指标</h1><p id="9391" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">由于我们的案例中存在数据不平衡，因此必须使用适当的度量来评估分类器的性能，以便考虑类别分布并更多地关注少数类别。基于这一思想，使用f1分数作为我的评估标准，f1分数是精确度和召回率的调和平均值。</p><p id="d130" class="pw-post-body-paragraph la lb it lc b ld mf ju lf lg mg jx li lj mh ll lm ln mi lp lq lr mj lt lu lv im bi translated">理解我们的模型产生的错误类型是很重要的。可视化信息的一个好方法是使用混淆矩阵，它将我们的模型做出的预测与真实标签进行比较。考虑到这一点，除了我们的评估指标(f1分数)之外，还使用了混淆矩阵。</p><h1 id="51e4" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">建模</h1><p id="6ca8" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">由于评论的等级不是正态分布的，等级1-2被归类为“差”，等级3-4-5被归类为“好”。在特征选择方面，使用了最小/最大方向图、主成分分析和奇异值分解的单词出现阈值。对于特征工程，将计数矢量器、TF-IDF、散列矢量器和Word2Vec应用于文本数据，以便将文本文档集合转化为数字特征向量。</p><h2 id="c626" class="mk kj it bd kk ml mm dn ko mn mo dp ks lj mp mq ku ln mr ms kw lr mt mu ky mv bi translated"><strong class="ak">袋字模型</strong></h2><p id="402c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">单词袋模型可能是从文本文档中提取特征的最简单也是最强大的技术之一。这种特定的策略(标记化、计数和规范化)被称为单词袋或“n-grams袋”表示法。该模型的本质是将文本文档转换成向量，使得每个文档都被转换成表示该特定文档的文档向量空间中存在的所有不同单词的频率的向量。下图显示<strong class="lc iu">逻辑回归以0.896267胜出。</strong></p><figure class="my mz na nb gt nc gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/9849df980cceaadeedff09e1e1aa76de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/0*jRtw3HAD51mc-8Sj"/></div></figure><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi nf"><img src="../Images/2a936da09b9d89575406a2c16bd40a1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DTqaQ0ual-iL0WDq"/></div></div><p class="nk nl gj gh gi nm nn bd b be z dk translated">F1平均分数</p></figure><h2 id="84a4" class="mk kj it bd kk ml mm dn ko mn mo dp ks lj mp mq ku ln mr ms kw lr mt mu ky mv bi translated"><strong class="ak"> TF-IDF型号</strong></h2><p id="d6a6" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">TF-IDF代表术语频率-逆文档频率，这是两个指标的组合:术语频率和逆文档频率。为了更多地关注有意义的单词，TF-IDF得分(术语频率-逆文档频率)被用于我们的单词袋模型之上。TF-IDF根据单词在我们的数据集中的稀有程度来衡量单词，忽略那些过于频繁并且只会增加噪音的单词。-IDF的工作方式是通过为这些常用词分配较低的权重来惩罚它们，同时对出现在特定文档的子集中的词给予重视。下图显示<strong class="lc iu"> CatBoosting以0.896533分胜出。</strong></p><figure class="my mz na nb gt nc gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/4ac6ebc9bc58a93383d689c525820c17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/0*L_2uuH183PtKrmkQ"/></div></figure><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi nf"><img src="../Images/ec2cbbdaeff6432108b6b80652d5803c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0reS8EsEK8rpqEC2"/></div></div><p class="nk nl gj gh gi nm nn bd b be z dk translated">F1平均分数</p></figure><h2 id="44f7" class="mk kj it bd kk ml mm dn ko mn mo dp ks lj mp mq ku ln mr ms kw lr mt mu ky mv bi translated"><strong class="ak">哈希矢量器</strong></h2><p id="13dc" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">哈希矢量器被设计成尽可能地节省内存。矢量器不是将记号存储为字符串，而是应用哈希技巧将它们编码为数字索引。这种方法的缺点是，一旦矢量化，就无法再检索要素的名称。下图显示<strong class="lc iu"> CatBoosting以0.894133分胜出。</strong></p><figure class="my mz na nb gt nc gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/b890478d14c5eddc50d8500538a26b7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/0*RyxRWTt4pCF1wWgH"/></div></figure><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi nf"><img src="../Images/c98d27ecf92b745ba546f09d10b291aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*pxKmyi4kJcYNPTNl"/></div></div><p class="nk nl gj gh gi nm nn bd b be z dk translated">F1平均分数</p></figure><h2 id="11af" class="mk kj it bd kk ml mm dn ko mn mo dp ks lj mp mq ku ln mr ms kw lr mt mu ky mv bi translated"><strong class="ak">将最常用和最不常用的词添加到停用词表(计数矢量器)</strong></h2><p id="8b42" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">因为在不同的类中没有太多不同的词，所以应用添加到停用词列表和模型中的最常见和最不常见的70个词，以便查看评估度量中的任何变化。下图显示<strong class="lc iu"> CatBoosting </strong> <strong class="lc iu">以0.890133分</strong>胜出。将最常用和最不常用的单词添加到停用词表中对模型的性能没有影响。</p><figure class="my mz na nb gt nc gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/e0b07ab7d2eae7f2acc69d349ec41dca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/0*xVI7MO54t_2QtP00"/></div></figure><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi nf"><img src="../Images/ee4503b0b089120d8a228bad90b41ff3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ImFvI55f3qDa0RaH"/></div></div><p class="nk nl gj gh gi nm nn bd b be z dk translated">F1平均分数</p></figure><h2 id="261f" class="mk kj it bd kk ml mm dn ko mn mo dp ks lj mp mq ku ln mr ms kw lr mt mu ky mv bi translated"><strong class="ak">应用Word2Vec和简单神经网络</strong></h2><p id="9313" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们使用Word2Vec创建了单词向量，该模型有26548个唯一的单词，其中每个单词的向量长度为100。然后我们在一个简单的神经网络中使用这些密集的向量——单词嵌入——来进行预测。在训练和验证准确度图中，模型在第一个时期后开始过度拟合。这个简单神经网络的精度是0.7992。</p><figure class="my mz na nb gt nc gh gi paragraph-image"><div class="gh gi no"><img src="../Images/e3f2eb62e64539551069eb38f47f7e1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/0*e3jIabskXJZjsryD"/></div></figure><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi np"><img src="../Images/f8643de1dd2308702e28f783e16fc6aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7nyjXF1DVKYlg3mL"/></div></div></figure><p id="4f06" class="pw-post-body-paragraph la lb it lc b ld mf ju lf lg mg jx li lj mh ll lm ln mi lp lq lr mj lt lu lv im bi translated">上面给出了在用t-SNE将感兴趣的单词和它们的相似单词的维数减少到2-D空间之后，使用它们的嵌入向量对它们进行可视化。也可以查看基于gensim模型的类似单词。</p><h1 id="c5ea" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">产品推荐</h1><p id="ad66" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">直到最近，人们通常倾向于购买朋友或信任的人推荐给他们的产品。这曾经是对产品有任何疑问时的主要购买方法。但随着数字时代的到来，这个圈子已经扩大到包括利用某种推荐引擎的在线网站。</p><p id="d0d3" class="pw-post-body-paragraph la lb it lc b ld mf ju lf lg mg jx li lj mh ll lm ln mi lp lq lr mj lt lu lv im bi translated">推荐引擎使用不同的算法过滤数据，并向用户推荐最相关的项目。它首先捕捉客户过去的行为，并在此基础上推荐用户可能会购买的产品。</p><p id="8915" class="pw-post-body-paragraph la lb it lc b ld mf ju lf lg mg jx li lj mh ll lm ln mi lp lq lr mj lt lu lv im bi translated">如果我们能够根据客户的需求和兴趣向他们推荐一些商品，这将对用户体验产生积极的影响，并导致频繁的访问。因此，现在的企业正在通过研究用户过去的行为来构建智能的推荐引擎。使用项目-项目协同过滤。</p><h1 id="2e18" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">数据处理</h1><p id="f652" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在<strong class="lc iu"> </strong>将<strong class="lc iu"> </strong>电子评级数据集与产品元数据合并后，空值将从数据集中删除。总特征是7530925。最终数据集如下所示。</p><figure class="my mz na nb gt nc gh gi paragraph-image"><div class="gh gi no"><img src="../Images/a63f0d01b50e7a2d027d9c6c9b5d6b49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/0*4Vhul7nNIDWN3QGB"/></div><p class="nk nl gj gh gi nm nn bd b be z dk translated">产品推荐的最终数据集</p></figure><h1 id="6375" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">项目-项目协同过滤</h1><p id="c586" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">当用户数量多于推荐的项目时，这种协作过滤是有用的。用户数(4053964)大于项目数(469625)。</p><p id="3abf" class="pw-post-body-paragraph la lb it lc b ld mf ju lf lg mg jx li lj mh ll lm ln mi lp lq lr mj lt lu lv im bi translated">在该过滤中，计算每个项目对之间的相似度，并基于该相似度推荐用户过去喜欢的相似项目。采用“项目用户”评级的加权总和。基于项目的过滤过程如下所示。</p><figure class="my mz na nb gt nc gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/efc503d661c26dfd4938f8a8ea168eef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*ckn019UDEvRTYtyhi-H9Xw.jpeg"/></div><p class="nk nl gj gh gi nm nn bd b be z dk translated">作者绘图。来自Unsplash的免费图片</p></figure><h2 id="cd8b" class="mk kj it bd kk ml mm dn ko mn mo dp ks lj mp mq ku ln mr ms kw lr mt mu ky mv bi translated"><strong class="ak">用户评分总和排名前十的热门产品</strong></h2><figure class="my mz na nb gt nc gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/d9bb9e19d3175e9f1bd2fe28c6cd09b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/0*Oeoys0NjXh8MwG1f"/></div><p class="nk nl gj gh gi nm nn bd b be z dk translated">按用户评分总和列出的十大热门产品</p></figure><h2 id="7977" class="mk kj it bd kk ml mm dn ko mn mo dp ks lj mp mq ku ln mr ms kw lr mt mu ky mv bi translated"><strong class="ak">产品推荐</strong></h2><figure class="my mz na nb gt nc gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/0e20464753052e35c38459d45e8d1678.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/0*n4lptY2lThlZ7vWm"/></div><p class="nk nl gj gh gi nm nn bd b be z dk translated">产品推荐</p></figure><h1 id="9b01" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">结论</h1><p id="0d4b" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">使用计数向量、TF-IDF、散列向量、Word2Vec、分类模型和简单神经网络，并向CountVect添加最常用和最不常用的词，来预测基于顾客留下的评论的评级分数。从分析中发现，具有TF-IDF的CatBoosting得分为0.890586)或具有计数矢量化的Logistic回归(f1得分为0.899891)是最佳模型。将最常用和最不常用的单词添加到停用词表中并不会对模型的性能产生影响。</p><h1 id="4f42" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated"><strong class="ak">代码:</strong></h1><p id="f246" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">情感分析:</p><p id="63a5" class="pw-post-body-paragraph la lb it lc b ld mf ju lf lg mg jx li lj mh ll lm ln mi lp lq lr mj lt lu lv im bi translated"><a class="ae mw" href="https://github.com/umaraju18/Capstone_project_2/blob/master/code/Amazon_headphones_Sentiment_Analysis_CV_IF_IDF_HASH.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/umar aju 18/Capstone _ project _ 2/blob/master/code/Amazon _ headphones _ Analysis _ CV _ IF _ IDF _ hash . ipynb</a></p><p id="955c" class="pw-post-body-paragraph la lb it lc b ld mf ju lf lg mg jx li lj mh ll lm ln mi lp lq lr mj lt lu lv im bi translated"><a class="ae mw" href="https://github.com/umaraju18/Capstone_project_2/blob/master/code/Amazon_headphones_wordvec.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/umar aju 18/Capstone _ project _ 2/blob/master/code/Amazon _ headphones _ word vec . ipynb</a></p><p id="428f" class="pw-post-body-paragraph la lb it lc b ld mf ju lf lg mg jx li lj mh ll lm ln mi lp lq lr mj lt lu lv im bi translated">推荐系统:</p><p id="595e" class="pw-post-body-paragraph la lb it lc b ld mf ju lf lg mg jx li lj mh ll lm ln mi lp lq lr mj lt lu lv im bi translated"><a class="ae mw" href="https://github.com/umaraju18/Capstone_project_2/blob/master/code/amazon_electronics_recommendation.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/umar aju 18/Capstone _ project _ 2/blob/master/code/Amazon _ electronics _ recommendation . ipyn</a>b</p><h2 id="52d4" class="mk kj it bd kk ml mm dn ko mn mo dp ks lj mp mq ku ln mr ms kw lr mt mu ky mv bi translated"><a class="ae mw" href="https://medium.com/@umacivil2003/sentiment-analysis-and-product-recommendation-on-amazons-electronics-dataset-reviews-part-1-6b340de660c2" rel="noopener">第一部分:探索性数据分析</a></h2></div></div>    
</body>
</html>