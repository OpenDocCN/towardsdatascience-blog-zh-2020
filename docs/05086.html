<html>
<head>
<title>An Intuitive Explanation of Field Aware Factorization Machines</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">场感知因式分解机的直观解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-intuitive-explanation-of-field-aware-factorization-machines-a8fee92ce29f?source=collection_archive---------10-----------------------#2020-05-02">https://towardsdatascience.com/an-intuitive-explanation-of-field-aware-factorization-machines-a8fee92ce29f?source=collection_archive---------10-----------------------#2020-05-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2b22" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">从 LM 到 Poly2 到 MF 到 FM 到 FFM</h2></div><p id="e37f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在推荐系统中，场感知因子分解机器(FFM)特别有用，因为它们能够处理具有许多分类特征的大型稀疏数据集。</p><p id="b189" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了理解 FFM 是如何产生的，让我们明确一些基础知识，理解为什么 FFM 是好的，它们有什么好处。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/0f6df571f661cfb066d694bb73745f26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*WV07o82C9fNT6iPA2EXw3A.gif"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">由作者改编(文章底部的原始照片)</p></figure><h2 id="7c5d" class="lu lv it bd lw lx ly dn lz ma mb dp mc kr md me mf kv mg mh mi kz mj mk ml mm bi translated">线性回归</h2><p id="4f51" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">当我们试图对因变量和一个或多个自变量之间的关系建模时，我们能想到的最简单的模型是线性回归模型。</p><p id="1fbf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">例如，为了预测用户对某部电影的评价，我们可以使用许多不同的特征作为预测指标。然而，为了简单起见，让我们假设两个变量——性别(<code class="fe ms mt mu mv b">x1</code>)和电影的类型(<code class="fe ms mt mu mv b">x2</code>)。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/04f78f65d72bc3574576f4fd09182c27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*v3qFGoz71HoOFj-jbvHKfw.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">作者照片</p></figure><p id="b506" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这种情况下，我们将以下面的等式结束(假设没有偏差，并假设对分类变量进行了一些编码):</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/c4b6037272b2815296695333b0ac7e04.png" data-original-src="https://miro.medium.com/v2/resize:fit:706/format:webp/1*iGXJrGlt0J8GV7SX6fmb_Q.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">作者照片</p></figure><p id="0c00" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后我们将求解权重<code class="fe ms mt mu mv b">w1</code>和<code class="fe ms mt mu mv b">w2</code>。自然，线性回归不会表现得很好，因为它试图学习每个变量的平均行为，并且没有考虑这些变量之间相互作用的可能性(即，它不能学习<code class="fe ms mt mu mv b">x1</code>可能与<code class="fe ms mt mu mv b">x2</code>具有相关性)。</p><h2 id="3418" class="lu lv it bd lw lx ly dn lz ma mb dp mc kr md me mf kv mg mh mi kz mj mk ml mm bi translated">Poly2</h2><p id="2eff" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">为了模拟这些相互作用，我们引入下一个最简单的模型——poly 2。代替上面的等式，我们为每个<strong class="kk iu"> <em class="my">特征对</em> </strong>添加一个交互项。这给了我们:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/e371ddbd1748256fcfcb22aa7daf4c79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*aU6NxxYJwDPU9vOKQIqmJQ.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">作者照片</p></figure><p id="c0b1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，很明显，这种方法有一些主要的缺点。首先，<strong class="kk iu">非常少的<em class="my">交互将具有不可靠的预测</em></strong>，其次，<strong class="kk iu">看不见的交互(即<em class="my">零</em>交互)将具有微不足道的预测</strong>。</p><p id="23f8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">例如，在 10000 个示例的训练集中，如果我们只有 2 个男性观看惊悚电影的示例，我们对男性观看惊悚电影的未来预测将仅基于这 2 个训练示例(即，交互项的权重由 2 个数据点确定)。此外，如果我们的训练集没有女性观看科幻电影的例子(如上表所示)，对这些电影做出的预测将是琐碎而无意义的。</p><h2 id="bbc7" class="lu lv it bd lw lx ly dn lz ma mb dp mc kr md me mf kv mg mh mi kz mj mk ml mm bi translated"><strong class="ak">矩阵分解</strong></h2><p id="ec92" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">在 MF 中，我们通常以稍微不同的方式表示数据。我们希望捕捉到<em class="my">用户</em>和<em class="my">物品</em>之间的互动，而不是将每个变量编码为男性或女性，或者使用电影的类型。让我们看看我们的新数据:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi na"><img src="../Images/4df6122f19c73e652a7f12f91d6f497b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*jSafYxsHvOPpW5F7K_5Usg.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">作者照片</p></figure><p id="dcae" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在上图中，用户位于行中，而项目位于列中。给定的<em class="my">用户-项目</em>交互的正值是用户对该电影的评价(<em class="my">注意，值也可以是二进制的，如下图所示，以表示观看或未观看</em>)。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/9c6aefd8a7806242e016efabf42cb53e.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*hnP8w97Q611jen8MgnQt9A.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">作者照片</p></figure><p id="000e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">给定上面的<em class="my">用户-物品</em>矩阵<strong class="kk iu"><em class="my">R</em></strong>[<em class="my">M</em>x<em class="my">N</em>】,目标是近似两个矩阵——一个用户潜在矩阵<strong class="kk iu">P</strong>[<em class="my">M</em>x<em class="my">k</em>和一个物品潜在矩阵<strong class="kk iu">Q</strong>[<em class="my">N</em>x<em class="my">k</em>，其中更稳健的 MF 方法是加权 MF，其中非相互作用值用零填充，然后使用加权交替最小二乘(WALS)或随机梯度下降(SGD)进行优化，将(观察和未观察条目的)误差平方和作为损失函数。通常添加一个超参数来加权来自未观察条目的误差，因为由于稀疏性，它们往往更多。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nc"><img src="../Images/7c21227353763ba81d57047a29e45a9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rGPqWm0akqQjR4vZ"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">来源:<a class="ae nd" href="https://developers.google.com/machine-learning/recommendation" rel="noopener ugc nofollow" target="_blank">谷歌的推荐系统课程</a></p></figure><p id="00dd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">MF 如何改进线性回归和 Poly2？</strong></p><p id="42c0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">MF 本质上是一个潜在因子模型，这意味着它可以将一个非常稀疏(和高维)的矩阵表示为两个维度低得多的矩阵。在高层次上，人们可以想象它与主成分分析(PCA)类似，我们试图在<em class="my"> k </em>成分中捕获尽可能多的方差。</p><blockquote class="ne nf ng"><p id="6584" class="ki kj my kk b kl km ju kn ko kp jx kq nh ks kt ku ni kw kx ky nj la lb lc ld im bi translated"><strong class="kk iu">注:</strong>潜在向量的概念与向量嵌入同义，其思想是从高维空间中学习一种紧凑的表示。</p></blockquote><p id="cd4f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">MF 的一个缺点是它只是一个矩阵分解框架。因此，我们只能将矩阵表示为一个<em class="my">用户条目</em>矩阵，而不能包含诸如电影类型、语言等辅助特性。因式分解过程必须从现有的相互作用中学习所有这些。因此，因式分解机作为 MF 的改进版本被引入。</p><p id="4cc5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">(<em class="my">由于本文关注的是 FFM，我就不深究 MF 的更多细节了。为了了解更多，我强烈推荐</em> <a class="ae nd" href="https://developers.google.com/machine-learning/recommendation" rel="noopener ugc nofollow" target="_blank"> <em class="my">谷歌的推荐系统入门课程</em> </a> <em class="my">。</em>)</p><h2 id="703a" class="lu lv it bd lw lx ly dn lz ma mb dp mc kr md me mf kv mg mh mi kz mj mk ml mm bi translated">因子分解机器(FM)</h2><p id="d422" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">如前所述，FM 是 MF 的改进版本。更具体地说，FM 是一种更一般化的预测器，如支持向量机(SVM)，但能够在稀疏性下估计可靠的参数[2]。简单来说，<strong class="kk iu"> FM 公式化为线性模型，特征之间的相互作用作为附加参数(特征)</strong>。这些特征交互是在它们的潜在空间表示中完成的，而不是在它们的平面格式中。它在数学上表示为:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nk"><img src="../Images/44f9e6cf4d8eed640aa6d375e83f2aa8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4I3KXP8a4VFTL9n-bzSgSQ.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">作者照片</p></figure><p id="8640" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如上所述，我们可以将上面的等式分解为两部分——左边的一个<em class="my">线性回归</em>模型和右边的一个等价的<em class="my">矩阵分解</em>。</p><p id="d465" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">与 Poly2 相比，交互的捕获有何不同？</strong></p><p id="72ad" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上面等式的右边可能会把人吓跑，因为它看起来很吓人。为了更容易理解，让我们来看看如何表示我们在 MF 中看到的<em class="my">用户条目</em>矩阵。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nl"><img src="../Images/84c85c3554e9b91e48b02e501bc48629.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QMTYo7IjZOYS3LW2boSZJw.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">作者照片</p></figure><p id="f6ce" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，我们希望将<em class="my">用户-项目</em>交互表示为一个 hot 编码向量，其中转换后的每一行都只有<strong class="kk iu">一个活动用户和项目</strong>。然后，我们可以添加辅助特征(例如，用户评价的其他电影、评价的最后一部电影、他消费该电影的时间等)作为一次性编码或归一化向量。</p><p id="1c51" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一般来说，因式分解机器能够估计稀疏设置中的相互作用，因为它们通过因式分解打破了相互作用参数的独立性(使用<code class="fe ms mt mu mv b">&lt;v_i, v_j&gt;</code>中表示的潜在向量)。这意味着一个交互的数据也有助于估计相关交互的参数(类似于矩阵分解和协同过滤的思想)。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nm"><img src="../Images/74598ece09356be944d8ef60b69fffda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EUMAB7qmX0R4C-eGU1coFw.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">来源:<a class="ae nd" rel="noopener" target="_blank" href="/thrive-and-blossom-in-the-mud-fm-model-for-recommendation-system-1-95707839e235">媒体文章</a>作者:迈克尔·魏</p></figure><p id="715c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与 Poly2 相比，FM 中每个相互作用的权重使用两个潜在向量的内积来估计。这意味着，即使在训练集中<code class="fe ms mt mu mv b">x_i</code>和<code class="fe ms mt mu mv b">x_j</code>之间没有交互，FM 也能够概括这种交互，因为它已经在训练期间创建了嵌入(如在 MF 示例中，我们获得了两个潜在矩阵)。在 Poly2 中，这是不可能的，因为模型没有看到这种特殊的相互作用。注意，在 FM 中，有一个额外的超参数<em class="my"> k — </em>所使用的潜在特征的数量(如上图所示)。</p><p id="bc99" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果调频已经可以概括得这么好，f FM 如何超越调频？</p><h2 id="e0b0" class="lu lv it bd lw lx ly dn lz ma mb dp mc kr md me mf kv mg mh mi kz mj mk ml mm bi translated">场感知因式分解机(FFM)</h2><p id="8d28" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">在深入研究 FFM 之前，注意术语上的差异是至关重要的:自变量如<em class="my">流派</em>和<em class="my">性别</em>现在将被称为<strong class="kk iu">字段</strong>。每个字段的分类值将被称为<strong class="kk iu">特征</strong>。比如<em class="my">男</em>、<em class="my">女</em>、动作、<em class="my">言情</em>等都是特色。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nn"><img src="../Images/a25b4ca2d1ef7e68aaff2dc33565e86b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QGsszzBG0y6rV2P5d-RbIg.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">作者照片</p></figure><p id="3eb4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在 FM 中，每个特征只有一个潜在向量来学习所有<em class="my">其他</em>特征的潜在效果[1]。例如，如果我们有 3 个字段<em class="my">性别</em>、<em class="my">流派</em>和<em class="my">国家</em>，我们将 FM 下的交互计算为:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi no"><img src="../Images/c7531a594ead1cb7e7f6a6c53747e4e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QLtTA5e0AWW9se5vSYO_DQ.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">作者照片</p></figure><p id="a7bc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以上表第一行为例，用<em class="my">男</em>的潜在向量来学习<em class="my">动作</em>T0<em class="my">北美</em>T1】的潜在效果。然而，<em class="my">动作</em>属于<em class="my">流派</em>领域，而<em class="my">北美</em>属于<em class="my">地区</em>领域，然而我们使用相同的潜在向量来表示<em class="my">男性</em>。</p><p id="ea40" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">FFM 将这种单一的表现方式分解成多个潜在向量——每个向量代表一个场。这样做背后的直觉是，<code class="fe ms mt mu mv b">&lt;v_male, v_action&gt;</code>和<code class="fe ms mt mu mv b">&lt;v_male, v_northamerica&gt;</code>的潜在向量可能非常不同，我们希望更准确地捕捉它们。FFM 领导下的互动将如下:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi np"><img src="../Images/efa2df6318859f407c348155239ef921.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OzJqqUowaaelxGSYAQqeFw.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">作者照片</p></figure><p id="7f55" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了了解<code class="fe ms mt mu mv b">&lt;v_male, v_action&gt;</code>的潜在效果，我们使用<code class="fe ms mt mu mv b">v_male,genre</code>，因为我们想要将潜在向量专门用于<em class="my">类别</em>字段。同样，我们使用<code class="fe ms mt mu mv b">v_action,gender</code>是因为我们想要捕获专门针对<em class="my">性别</em>字段<em class="my">的潜在向量。</em></p><p id="c10e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">什么时候我们应该使用 FFM 而不是调频？</p><p id="4b49" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">比较 FFM 和 FM，FFM 为每个<em class="my">特征</em>学习多个潜在向量，而 FM 为每个<em class="my">特征</em>学习一个潜在向量。人们可以把前者解释为试图在更细粒度的层次上表现相互作用。因此，表示这种颗粒相互作用所需的潜在特征<em class="my"> k </em>的数量较少，即 FFM 中的<em class="my"> k </em>、FM 中的&lt; &lt; <em class="my"> k </em>。</p><p id="a5a6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在 FFM 的官方论文中，经验证明，对于具有许多分类特征的大型稀疏数据集，FFM 表现更好。相反，对于小而密集的数据集或数值数据集，FFM 可能不如 FM 有效。FFM 还容易在训练数据集上过度拟合，因此应该使用独立的验证集，并在损失增加时使用早期停止。</p><h2 id="ac0a" class="lu lv it bd lw lx ly dn lz ma mb dp mc kr md me mf kv mg mh mi kz mj mk ml mm bi translated">摘要</h2><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/fffa6529294c25a53e8f5b13f98d125e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*r8y-tb4zHYdAP5FAiLHtpw.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">作者照片</p></figure><p id="4906" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">希望这对那些探索 FFM 或 FM 在稀疏矩阵监督学习应用中的使用或探索推荐系统的人有所帮助。:)欢迎随时留言评论！</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nr"><img src="../Images/b9c2ffee99008c621ef575f5d97c1f79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8nnpmF6tBTskE64PHMs6UA.jpeg"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">来源:<a class="ae nd" href="https://www.shutterstock.com/image-vector/theory-evolution-man-human-development-monkey-1022560147" rel="noopener ugc nofollow" target="_blank"> UncleLeo </a> /Shutterstock</p></figure></div><div class="ab cl ns nt hx nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="im in io ip iq"><p id="a06a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="my">支持我！</em> </strong> —如果你喜欢我的内容并且<em class="my">没有</em>订阅 Medium，请考虑支持我并通过我在这里的推荐链接<a class="ae nd" href="https://davidcjw.medium.com/membership" rel="noopener">订阅</a> ( <em class="my">注意:你的一部分会员费将作为推荐费</em>分摊给我)。</p><h2 id="b4e4" class="lu lv it bd lw lx ly dn lz ma mb dp mc kr md me mf kv mg mh mi kz mj mk ml mm bi translated">参考资料:</h2><p id="8a56" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">[1] <a class="ae nd" href="https://dl.acm.org/doi/10.1145/2959100.2959134" rel="noopener ugc nofollow" target="_blank">用于 CTR 预测的场感知因式分解机</a></p><p id="3156" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[2] <a class="ae nd" href="https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf" rel="noopener ugc nofollow" target="_blank">因式分解机</a></p><p id="b18c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[3] <a class="ae nd" href="https://developers.google.com/machine-learning/recommendation" rel="noopener ugc nofollow" target="_blank">谷歌的推荐系统课程</a></p><p id="bccc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[4] <a class="ae nd" rel="noopener" target="_blank" href="/thrive-and-blossom-in-the-mud-fm-model-for-recommendation-system-1-95707839e235">在深度学习中茁壮成长:推荐系统的 FM 模型(上)</a></p></div></div>    
</body>
</html>