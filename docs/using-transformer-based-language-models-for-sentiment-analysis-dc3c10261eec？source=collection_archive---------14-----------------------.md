# 使用基于转换器的语言模型进行情感分析

> 原文：<https://towardsdatascience.com/using-transformer-based-language-models-for-sentiment-analysis-dc3c10261eec?source=collection_archive---------14----------------------->

![](img/b289edf54dcdd32c86d25377606c57f4.png)

来源: [shutterstock](https://www.shutterstock.com/de/image-photo/kiev-ukraine-may-29-2019-new-1410410843)

## 如何轻松击败最先进的情感模型

情感分析对许多企业来说是有用的，有助于评估客户对公司或特定产品的情绪。它的任务是根据文本的极性对文本进行分类，即识别作者对主题的感觉是积极的、消极的还是中性的。

为了能够大规模地自动进行情感分析，我们需要在带注释的数据集上训练模型。本文将展示如何通过使用开源框架 [FARM](https://github.com/deepset-ai/FARM) 以快速简单的方式将最先进的 transformer 模型应用于情感分析，从而大幅超越当前的基准测试(提高约 5 个百分点)。

# 数据集

如前所述，我们需要带注释的数据来监督训练一个模型。为此，我使用了两个共享任务的数据集: [SemEval 2017](http://alt.qcri.org/semeval2017/) 和 [Germeval 2017](https://sites.google.com/view/germeval2017-absa/home) 。
seme val 数据集由英语推文组成，而 GermEval 数据集包含来自不同社交媒体和网络来源的关于 *Deutsche Bahn* (德国铁路公司)的德语文本。两个数据集合的文本根据其极性(即正、负或中性)进行标记。

# 用 FARM 微调变压器模型

当涉及不同的 NLP 任务时，如文本分类、命名实体识别和问答，像 BERT 这样的 Transformer 模型是当前最先进的。有多种不同的预训练模型。对于 Germeval 2017 数据集，使用了 deepset 的 [GermanBERT](https://deepset.ai/german-bert) ，因为它在一系列任务中表现出了强大的性能。
然而，对于 SemEval-2017 数据集，由于训练数据由英语文本组成，但结果模型的目的是评估德国客户对文本的情感，因此尝试了零镜头学习方法，因此需要多语言模型。为此，使用了 XLM-罗伯塔-拉奇，它受过 100 种不同语言的训练。如果你想更多地了解 XLM-罗伯塔，我强烈推荐这篇博客文章。

由于预训练模型仅被训练来捕捉对语言的一般理解，而不是特定下游 NLP 任务的细微差别，所以我们需要使这些模型适应我们的特定目的。为了实现这一点，使用了用于调整表示模型(FARM) 的[框架。FARM 允许轻松调整变压器模型以适应不同的 NLP 任务。为了实现构建一个可靠的情感分类器的目标，我遵循了 FARM 的](https://github.com/deepset-ai/FARM) [doc_classification 示例](https://github.com/deepset-ai/FARM/blob/master/examples/doc_classification.py)。下面的代码片段展示了我如何通过几个步骤使 GermanBERT 适应情感分析的任务:

## 数据处理

为了能够加载训练实例，数据集需要在 csv 文件中，其中每一行都由训练示例及其标签组成。`TextClassificationProcessor`加载并转换数据，以便建模组件可以使用它。为此，我们需要指定可能的标签集、包含训练集和测试集的数据目录，以及包含每个训练实例的标签的列的名称。这里，我们还必须指出我们的模型中使用的最大序列长度。
转换后的数据随后被传递到`DataSilo`。其目的是存储数据，并逐批提供给模型。因此，必须在这一步指定批量大小。

## 建模

下一步是定义模型架构。首先，我们需要决定我们想要微调的语言模型。在这种情况下，我们使用`bert-base-german-cased`。然后，我们必须为我们的特定任务选择正确的预测头。因为我们想使用离散值根据文本的情感对文本进行分类，所以我们需要选择一个`TextClassificationHead`。最后一步是在语言模型上堆叠预测头，这是由`AdaptiveModel`完成的。

## 培养

既然已经加载了数据并且定义了模型架构，我们就可以开始训练模型了。首先，我们必须初始化一个优化器。在这里，我们设置学习率和我们想要训练模型的时期数。不仅初始化一个优化器，而且初始化一个学习率调度器。默认情况下，所有训练步骤的前 10%是学习率的线性热身。
最后，我们可以将所有组件输入到`Trainer`，开始训练并保存生成的模型以备后用。在 Germeval-17 数据集上微调 GermanBERT 在 Tesla V100 16GB GPU 上耗时不到 16 分钟；根据 SemEval-17 的数据调整 XLM-罗伯塔需要 28 分多一点的时间。

# 结果

对于 Germeval 2017 共享任务，使用微观平均 F1 分数评估提交模型的性能。提供了两个不同的测试集:一个包含与训练数据集相同时期的 tweet(同步测试集)，另一个测试集包含稍后时期的 tweet(历时测试集)。
最佳提交(Naderalvojoud et al. 2017)在共时测试集上取得了 74.9%的微观平均 F1 分，在历时测试集上取得了 73.6%的微观平均 F1 分。使用 GermanBERT 和 FARM 训练的模型比这些分数高出 5%以上，在同步测试集上实现了 80.1%的微观平均 F1 分数，在历时测试集上实现了 80.2%的微观平均 F1 分数。

Germeval-2017 数据集的评估结果

然而，对 SemEval 2017 共享任务的提交的性能是通过宏观平均召回来评估的。在那里，最佳提交(placend 2017，Baziotis 等人 2017)实现了 68.1%的宏观平均召回率。同样，使用 XLM-罗伯塔-大型和农场训练的模型比这些提交的模型高出 5%以上，实现了 73.6%的宏观平均召回率。

SemEval-2017 数据集的评估结果

因为使用 XLM-罗伯塔而不是单语模型的原因是将该模型应用于德国数据，所以也在 Germeval-17 测试集上评估了 XLM-罗伯塔情感模型。这里，我们在同步测试集和历时测试集上分别获得了 59.1%和 57.5%的微观平均 F1 值。这一表现比分数分别为 65.6%和 67.2%的基本多数类基线差。出现这种情况的一个原因可能是两个数据集的类别分布差异很大。虽然 Germeval 数据集中的大多数实例被标记为*中性*，几乎没有包含正面情绪的案例，但 SemEval 数据集中的大多数类别是*正面*。
另一个问题可能是两个数据集包含主题不同的文本。Germeval 数据集就其主题而言非常有限，主要包含来自不同社交媒体和网络来源的关于德国铁路公司的文本。相反，SemEval 数据集不受主题限制。

Germeval-2017 和 SemEval-2017 数据集的类别分布

所有上述结果都是使用以下超参数获得的:

用于训练模型的超参数

# 结论

这篇博客文章展示了我们如何使用 transformer 模型来训练我们自己的情感模型。我们看到，在框架农场的帮助下，可以轻松地对预训练模型进行微调，我们甚至能够击败不同共享任务的排行榜。如果你有兴趣亲自尝试一下 GermanBERT 情绪模型，你可以通过 [huggingface 的模型中心](https://huggingface.co/deepset/bert-base-german-cased-sentiment-Germeval17)访问它。