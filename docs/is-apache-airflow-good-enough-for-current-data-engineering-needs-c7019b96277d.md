# Apache Airflow 是否足以满足当前的数据工程需求？

> 原文：<https://towardsdatascience.com/is-apache-airflow-good-enough-for-current-data-engineering-needs-c7019b96277d?source=collection_archive---------4----------------------->

## Apache Airflow 作为 ETL 和数据科学的工作流管理平台的利与弊，以及由此衍生的 Airflow 可能是好选择或坏选择的用例

![](img/503d1f03b80079ef1406195f923ef5a5.png)

克里斯·利维拉尼在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

不久前，如果你问任何数据工程师或数据科学家，他们使用什么工具来编排和调度他们的数据管道，默认的答案可能是 Apache Airflow。尽管气流可以解决许多当前的数据工程问题，但我认为对于一些 ETL &数据科学用例来说，它可能不是最佳选择。

在这篇文章中，我将讨论我在过去两年中使用气流的利弊，并从中得出气流仍然是一个很好的选择的用例。我希望在本文结束时，您将能够确定它是否适合您的 ETL &数据科学需求。

# 气流的优势是什么？

## 社区

不可否认，阿帕奇气流有一个惊人的社区。有大量的个人在使用 Airflow 并为这个开源项目做出贡献。如果您想解决一个特定的数据工程问题，那么社区中可能有人已经解决了这个问题，并在线分享了他们的解决方案，甚至将他们的实现贡献给了代码库。

## 对气流进行战略押注的公司

许多公司决定投资 Apache Airflow 并支持其发展，其中包括:

*   谷歌凭借其云作曲家 GCP 服务，
*   **天文学家**为在 Kubernetes 上部署气流提供企业支持，
*   **Polidea** 拥有许多 PMC 成员，为代码库做出了巨大贡献
*   **GoDataDriven** 提供阿帕奇气流训练。

来自这些公司的支持确保有人全职工作来进一步改进软件，从而保证长期的稳定性、支持和培训。

## 计算机编程语言

在 Python 代码中定义工作流的可能性非常有用，因为它允许您将几乎任何自定义工作流逻辑合并到您的编排系统中。

## 展开性

气流允许您通过以下方式扩展功能:

*   使用[插件](https://airflow.apache.org/docs/stable/plugins.html)例如。要在 UI 中添加额外的菜单项，
*   添加自定义操作符或在现有操作符的基础上构建。

## 广泛的运营商

如果你看看 Airflow Github 库中可用的操作符的数量，你会发现 Airflow 支持广泛的**到外部系统**的连接器。这意味着，在许多情况下，您会发现代码模板可以用来与各种数据库、执行引擎和云提供商进行交互，而不必自己实现代码。

> *外部系统的连接器数量表明，气流可以用作“粘合剂”，将来自许多不同来源的数据结合在一起。*

# 气流的弱点是什么？

从上面列出的优势列表中，您可以看到，总的来说，从将许多外部系统捆绑在一起的角度来看，Airflow 是数据工程**的一个**伟大产品**。社区投入了大量的工作来构建广泛的特性和连接器。然而，它有几个弱点阻止我真正喜欢使用它。其中一些问题可能会在未来的版本中得到解决，所以我在撰写本文时讨论这些问题。**

## 数据管道没有版本控制

如今，当我们有了版本控制系统和存储在 Docker 注册表中的不同版本的 Docker 映像时，我们认为版本化是理所当然的——这是一个应该存在的基本功能，毫无疑问。但是，气流还是没有。如果您从 DAG 代码中删除一个任务并重新部署它，您将**丢失与该任务相关的元数据**。

## 对新用户来说不直观

我用了足够长的时间来理解它的内部结构，甚至通过编写定制组件来扩展它的功能。然而，**向一组以前从未使用过 Airflow 的数据工程师**教授如何使用它**被证明是耗时的**，因为人们需要学习一种全新的“语法”。一些数据工程师认为整个体验**不直观**。

一个突出的例子与**的调度**有关:许多人(包括在内的*我)发现，Airflow 在调度间隔的*结束*时开始调度任务，这非常令人困惑。这意味着调度间隔不会立即开始，而是仅在`execution_date`达到`start_date` + `schedule_interval`时开始。这似乎适用于每晚只运行一次的批处理 ETL 作业，但是对于每 10 分钟运行一次的作业，当不熟悉该工具的新用户使用它时，它会相当混乱，并且可能导致意外的错误，特别是如果没有正确使用 *catchup* 选项的话。*

## 从一开始就配置过载+难以在本地使用

为了在本地计算机上开始使用 Airflow，不熟悉该工具的数据专业人员需要学习:

*   内置于产品中的**调度逻辑****——比如提到的与开始日期、执行日期、调度间隔、赶上进度相关的细微差别**
*   一整套**概念和配置细节—** 操作符与任务、执行器、Dag、默认参数、airflow.cfg、airflow 元数据 DB、部署 Dag 的主目录等等)。

另外，如果你是一个 **Windows 用户**，你真的**不能在本地使用这个工具**，除非你使用 docker-compose 文件，这些文件甚至不是官方 Airflow 库的一部分——许多人使用 [puckel/docker-airflow](https://github.com/puckel/docker-airflow) 设置。这都是可行的，但我希望它会更直观，更容易为新用户。

我知道 Airflow 在过去的几个月里发布了一个官方的 docker 映像，但仍然缺少一个官方的`docker-compose`文件，新用户(*特别是 Windows 用户*)可以在其中获得完整的基本设置，以及一个元数据数据库容器和一个绑定挂载，以便将他们的 Dag 复制到容器中。一个官方的`docker-compose`文件对于能够在 Windows 上本地运行 Airflow 非常有帮助。

如果你使用天文学家付费版本的气流，你可以使用 [astro CLI](https://github.com/astronomer/astro-cli) ，这在一定程度上缓解了局部测试的问题。

## 为生产设置气流架构并不容易

为了获得生产就绪的设置，您实际上有两种选择:

1.  **Celery Executor:** 如果您选择这个选项，您需要了解 Celery 如何工作+您需要熟悉 RabbitMQ 或 Redis 作为您的消息代理，以便设置和维护可以执行您的气流管道的工作队列。据我所知，没有直接来自 Airflow 的官方教程或部署方法来使这一扩展过程对用户来说更容易。我个人是从[这篇博客文章](https://www.cloudwalker.io/2019/09/30/airflow-scale-out-with-redis-and-celery/)中学到的。)。总的来说，我希望这个设置对用户来说更容易，或者至少 Airflow 会提供一些关于如何正确设置的官方文档。
2.  **Kubernetes Executor:** 与芹菜相比，这个 Executor 相对较新，但是它允许您利用 Kubernetes 的力量自动缩放您的工人(*甚至减少到零！*)并以健壮的方式管理所有 Python 包的依赖关系，因为所有东西都必须被容器化才能在 Kubernetes 上工作。然而，在这方面，我也没有在官方文档中找到关于如何正确设置和维护它的支持。

我在为我工作的公司在 AWS 上设置气流的经验是，你可以:

*   雇佣一些外部顾问为你做这件事
*   从谷歌( *Cloud Composer* )或天文学家. io 获得一个**付费版本**
*   或者你可以**试错**，交叉手指希望它不会断。

**总体而言，Airflow 的架构包括许多组件，例如:**

*   调度程序，
*   网络服务器，
*   元数据数据库，
*   工作节点，
*   遗嘱执行人，
*   消息经纪人+芹菜+花如果选择芹菜执行者，
*   可能是一些共享卷，例如 AWS EFS，用于工作节点之间的公共 DAGs 存储，
*   正确设置`airflow.cfg`中的值
*   配置日志存储。S3 +理想的一些生命周期策略，通常情况下，你不需要查看非常旧的日志和支付存储费用
*   为用户界面注册域
*   添加一些**监控**来防止您的元数据数据库和工作节点超出它们的计算能力和存储
*   为 UI +数据库用户管理添加一些 **Auth 层**用于访问元数据数据库。

> *这些是* ***许多组件来维护*** *和* ***以确保它们都很好地一起工作，*** *而且似乎开源版本的 Airflow 并没有让这个设置对用户来说很容易。*

从我到目前为止的经验来看，如果你想在生产中使用 Airflow(*特别是如果你使用 AWS 或 Azure 而不是 GCP* )，选择[天文学家](https://www.astronomer.io/)似乎是最简单的选择，因为你在上面添加了许多功能，例如监控你的节点、将日志拉到一个中心位置、授权层(*和与活动目录的集成*)、支持、SLA 和天文学家团队将至少维护上面列出的一些组件。

## 任务之间缺乏数据共享鼓励了非原子任务

目前，除了使用 XComs 之外，还没有自然的“Pythonic 式”方法在 Airflow 中的任务之间共享数据，XComs 被设计为仅共享少量元数据(*路线图中有计划引入功能性 Dag，因此数据共享在未来可能会以某种方式变得更好*)。

任务意味着数据管道中基本的*原子*工作单元。因为在气流中的任务之间没有**共享数据的简单方法，而不是任务是*原子的*，即只负责一件事情(*例如。仅提取数据*，人们通常倾向于使用整个脚本作为*任务*，例如一个脚本执行整个 ETL ( *由 BashOprator ex 触发。" python stage _ AdWords _ ETL . py "*)，这反过来使得维护更加困难，因为您需要调试整个脚本(*完整 ETL* )，而不是一个小的原子任务(*例如。仅“提取”部分*)。**

> 如果你的任务是**而不是**原子的，当它失败时，你不能仅仅重试 ETL 的**加载**部分——你需要重试**整个 ETL** 。

## 调度程序成为瓶颈

如果你以前使用过 Airflow，你可能已经经历过在 UI 中点击 *Trigger DAG* 按钮后，你需要等待相当长的时间才能看到任务真正开始运行。

调度器通常需要几分钟才能调度任务，并由工作进程执行，至少今年早些时候我使用部署在 EC2 上的 Airflow 时是这样。Airflow 的社区正在致力于改进调度程序，所以我希望它在下一个版本中会有更高的性能，但是在撰写本文时，这个瓶颈阻止了将 Airflow 应用到延迟不可接受或不可取的用例中。

# 气流仍然是一个好选择的使用案例

在本文中，我多次强调，当 Airflow 只需要调度以下任务时，它就能很好地工作:

*   运行在 Spark、Hadoop、Druid 等外部系统上，或者 AWS Sagemaker、AWS ECS 或 AWS Batch 等一些外部云服务上，
*   向某个内存数据库提交 SQL 代码。

> *Airflow 被* ***设计成*** *不直接在 Airflow 内部执行任何工作流，而只是对它们进行调度，并让* **保持在外部系统** *内执行。*

这意味着，如果您的任务是提交 Spark 作业并将数据存储在 Hadoop 集群上，或者在 Snowflake 中执行一些 SQL 转换，或者触发 SageMaker 培训作业，那么 Airflow 仍然是一个不错的选择。

举个例子:想象一家公司，数据工程师在 Pentaho 数据集成中创建 ETL 作业，他们使用`CeleryExecutor`在 AWS EC2 实例上编排`BashOperator`任务。那些任务*没有被停靠*，任务只是调度**一个 bash 命令在一个特定的服务器上运行**。气流在这个用例中运行良好。

如果您在工作流系统中需要做的只是向外部系统提交一些 bash 命令，并且您实际的**数据流**是在 Spark、SageMaker 中定义的，或者如上面的例子，在 Pentaho 数据集成中，Airflow 应该非常适合您，因为**数据依赖关系**是由那些外部系统管理的，而 Airflow 只需要管理任务之间的**状态依赖关系**。如果您使用一些内存数据库，如雪花、Exasol 或 SAP Hana，*实际工作在这些数据库中执行*，您的工作流编排系统只需向其提交查询即可。

# 气流不是好选择的使用案例

> *如果您希望您的* ***工作流系统*** *与您的* ***执行层*** *紧密合作，并且能够在 Python 代码内的任务之间传递数据，那么在这种情况下，气流可能不是最好的选择。*

Airflow 只能通过 XComs 传递任务之间的**状态依赖**(*加上可能的一些元数据)，而不能传递**数据依赖**。这意味着，如果您主要用 Python 构建工作流，并且您有许多数据科学用例，这些用例本质上严重依赖于任务间的数据共享，那么其他工具，如 [Prefect](https://www.prefect.io/) 会更适合您。*

在这些使用案例中，Prefect 是比 Airflow 更好的选择:

*   如果需要在任务间**共享数据**
*   如果您需要对数据管道进行版本控制，那么 Airflow 不支持这一点
*   如果你想用 Dask 对你的 Python 代码进行**并行化，提督支持 [Dask 分布式](http://distributed.dask.org/en/latest/)开箱即用**
*   如果需要运行**动态参数化数据管道**
*   如果 Airflow 的**调度器延迟**不为您的工作负载所接受，
*   如果您想在**本地测试工作流代码时获得无缝体验**
*   最后，如果你喜欢一个**更容易和更灵活的执行层**而不是维护前面提到的所有气流组件，你可以选择完美云。您可以在本文中找到一种可能的设置方法:

[](/distributed-data-pipelines-made-easy-with-aws-eks-and-prefect-106984923b30) [## AWS EKS 和提督使分布式数据管道变得简单

### 如何在几分钟内建立一个分布式云工作流程编排系统，并专注于提供价值，而不是…

towardsdatascience.com](/distributed-data-pipelines-made-easy-with-aws-eks-and-prefect-106984923b30) 

# 结论

在本文中，我们讨论了 Apache Airflow 作为 ETL 和数据科学的工作流编排解决方案的优缺点。在分析了它的优势和劣势之后，我们可以推断，只要它用于其设计目的，即仅编排在 Apache Spark、Hadoop、Druid、云服务等外部系统上执行的工作，或者在向 Snowflake、Exasol 或 Redshift 等高性能分布式数据库提交 SQL 代码时，它就是一个不错的选择。

然而，air flow**并不是为直接执行您的数据管道***而设计的，所以如果您的 ETL &数据科学代码需要在任务之间传递数据，需要动态和参数化，需要并行运行，或者需要更灵活和低延迟的调度程序，那么您可能会更喜欢其他工具，如 Prefect。*

*感谢您的阅读！*