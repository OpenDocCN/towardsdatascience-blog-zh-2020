<html>
<head>
<title>Word Embeddings and Embedding Projector of TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TensorFlow的单词嵌入和嵌入投影</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/word-embeddings-and-embedding-projector-of-tensorflow-c946b98c9b3f?source=collection_archive---------48-----------------------#2020-05-24">https://towardsdatascience.com/word-embeddings-and-embedding-projector-of-tensorflow-c946b98c9b3f?source=collection_archive---------48-----------------------#2020-05-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b36e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">理论解释和实例。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/1ede52152456e1ab793bfe0ad0955494.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WTt3WXi7tiwjjfo0Scdvgg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">罗斯·乔伊纳在<a class="ae ky" href="https://unsplash.com/s/photos/similar?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="f42a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">单词嵌入是一种在词汇表中表示单词(即记号)的技术。它被认为是自然语言处理中最有用和最重要的概念之一。</p><p id="5686" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我将介绍单词嵌入的概念以及它在NLP中的作用。然后，我们将通过一个实例来理解使用TensorFlow的<strong class="lb iu">嵌入式投影仪</strong>的概念。</p><p id="1488" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">单词嵌入是指在n维向量空间中用向量表示一个单词。考虑一个包含10000个单词的词汇表。在传统的数字编码中，单词用从1到10000的数字来表示。这种方法的缺点是，我们无法捕捉到任何关于单词含义的信息，因为数字是在不考虑单词含义的情况下分配给单词的。</p><p id="c8e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们使用16维的单词嵌入，那么每个单词都用一个16维的向量表示。单词嵌入的主要优点是共享相似上下文的单词可以在向量空间中彼此接近地表示。因此，向量承载了一个词的语义。假设我们正在尝试对客户评论进行情感分析。如果我们使用单词嵌入来表示评论中的单词，与积极意义相关的单词会指出一种特定的方式。同样，具有消极意义的单词很可能与具有积极意义的单词指向不同的方向。</p><p id="6274" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一个非常著名的带有单词嵌入思想的类比是国王-王后的例子。它基于“国王”、“王后”、“男人”和“女人”这些词的矢量表示。如果我们从国王中减去男人，然后加上女人，我们将得到一个非常接近女王的向量:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/894ca9a3beac6c1d18173061ee60bd24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AJ2WL_EMYFCocyGgAyjN7w.png"/></div></div></figure><p id="87c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有不同的方法来衡量向量的相似性。最常见的方法之一是<strong class="lb iu">余弦相似度</strong>，它是两个向量之间角度的余弦。与欧几里德距离不同，余弦相似性在测量相似性时不考虑向量的大小。因此，余弦相似性关注向量的方向，而不是长度。</p><p id="a552" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">想想“令人兴奋”、“无聊”、“激动人心”和“无聊”这些词。在二维向量空间中，这些单词的向量可能看起来像:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/56b2e8fbf56b3a846f883dc1c369e2fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/1*_kA8p3VGcTZoGYDb1Xn1yQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">二维空间中的单词嵌入</p></figure><p id="15e7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随着向量之间的角度减小，角度的余弦增加，因此余弦相似性增加。如果两个向量位于同一方向(它们之间的角度为零)，余弦相似度为1。另一方面，如果两个向量指向相反的方向(它们之间的角度为180°)，余弦相似度为-1。</p><p id="09b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我们使用单词嵌入时，该模型了解到激动人心和激动人心比激动人心和无聊更有可能共享相同的上下文。如果我们用整数来表示单词，模型就不知道这些单词的上下文。</p><p id="86c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有不同的方法来创建单词嵌入，如Word2Vec、GloVe或神经网络的嵌入层。单词嵌入的另一个优点是，我们可以在模型中使用预先训练的嵌入。例如，Word2Vec和GloVe嵌入对公众开放，可以用于自然语言处理任务。我们也可以选择使用神经网络中的嵌入层来训练我们自己的嵌入。例如，我们可以在<strong class="lb iu"> Keras </strong>的序列模型中添加<strong class="lb iu">嵌入</strong>层。请注意，需要大量数据来训练嵌入层，以实现高性能。</p><p id="9b61" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们用4个单词举的例子非常简单，但是抓住了单词嵌入背后的思想和动机。为了可视化和检查更复杂的例子，我们可以使用TensorFlow的嵌入式投影仪。</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="9f76" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated"><strong class="ak">嵌入投影仪</strong></h1><p id="a9ff" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated"><a class="ae ky" href="https://projector.tensorflow.org/" rel="noopener ugc nofollow" target="_blank">嵌入投影仪</a>是理解单词嵌入的神奇工具。它允许你加载你自己的嵌入和可视化，以及分析一些预先训练的模型。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/bd6934dddfd4e0d7d63fe691c21b8310.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*vcVgEcxAksGZcQUs0kftdg.png"/></div></div></figure><p id="2584" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我选择了一个预先训练好的嵌入，这是Word2Vec 10K，但你可以使用<strong class="lb iu"> load </strong>选项随意上传你自己的嵌入。TensorFlow有一个关于单词嵌入的信息丰富的教程<a class="ae ky" href="https://www.tensorflow.org/tutorials/text/word_embeddings" rel="noopener ugc nofollow" target="_blank">也解释了如何将数据加载到嵌入投影仪。</a></p><p id="175f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们回到Word2Vec 10K的例子，它包括200个维度中的10000个点。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nc"><img src="../Images/f0a2863426eab62db9cc75e80ac980a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*18LAD97QfdICKmy2gHQGAA.png"/></div></div></figure><p id="12d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这张图片说明不了什么，但是你可以移动它来看不同的单词。上图中的每个点代表一个单词。如果你点击一个点，它会显示这个单词和附近的单词。例如，我点击了代表单词“own”的点:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/f86e8095830f6ce492a191ff7582c103.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sJ-ju1x8PUoMvNuoPdnFNQ.png"/></div></div></figure><p id="9750" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">投影仪显示“own”在文本和包含最近点的列表中出现的次数。与“own”最接近的点是“their ”,这是有意义的，因为这些词很可能像在“their own”中一样一起出现。</p><p id="7757" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们选择了一个特定的单词后，我们可以分离出一定数量的相关单词。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/66f414cf38c76e915f9f921fa59632f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pw7eBDA9HX4jq5fjNPdzlw.png"/></div></div></figure><p id="613a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我选取了“爷爷”这个词，隔离出101个词。它返回了一个不太密集的视图，这使得可视化分析嵌入更容易。</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><p id="213e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">词嵌入被认为是自然语言处理中最重要的思想之一，它使自然语言处理的研究者和实践者在完成复杂的任务上迈出了一大步。</p><p id="39eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢您的阅读。如果您有任何反馈，请告诉我。</p></div></div>    
</body>
</html>