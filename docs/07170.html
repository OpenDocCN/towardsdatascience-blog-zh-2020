<html>
<head>
<title>Introduction to Bayesian Inference</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">贝叶斯推理简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introduction-to-bayesian-inference-18e55311a261?source=collection_archive---------33-----------------------#2020-06-01">https://towardsdatascience.com/introduction-to-bayesian-inference-18e55311a261?source=collection_archive---------33-----------------------#2020-06-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6c93" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">用一些理论和一步一步的例子来说明基础——疾病的诊断和参数估计</h2></div><h1 id="1358" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">动机</h1><p id="2e7f" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">想象一下下面的场景:你开着救护车去医院，必须在路线A和b之间做出选择，为了救你的病人，你需要在15分钟内到达。如果我们估算A路线需要12分钟，B路线需要10分钟，你会选择哪个？B路线似乎更快，为什么不呢？</p><p id="f58a" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">目前提供的信息包括路线A和B的点估计。现在，让我们添加关于每个预测的不确定性的信息:路线A需要12分钟1分钟，而路线B需要10分钟6分钟。</p><p id="472c" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">现在看来，路线B的预测明显更加不确定，最终可能会超过15分钟的限制。在这里加入关于不确定性的信息，可以让我们改变决策，从走B路线到走a路线。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ly"><img src="../Images/f2e1e8e400a81ca2195260898fd2e20d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0paBWnh2hkiW_2pT"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">马克·克鲁兹在<a class="ae mo" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="4032" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated"><em class="mp">鸣谢:之前的例子是根据我在哥伦比亚大学</em><strong class="kz ir"><em class="mp">Tamara Broderick</em></strong><em class="mp">的</em> <a class="ae mo" href="http://statisticalml.stat.columbia.edu/event/sampling-variational-inference-and-related-topics/" rel="noopener ugc nofollow" target="_blank"> <em class="mp">教程中的记忆。与这个例子相关的工作可以在[1]中找到。</em></a></p><p id="1c75" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">更广泛地说，考虑以下情况:</p><ul class=""><li id="db27" class="mq mr iq kz b la lt ld lu lg ms lk mt lo mu ls mv mw mx my bi translated">我们想要估计一个没有固定值的量，相反，它可以在不同的值之间变化</li><li id="5455" class="mq mr iq kz b la mz ld na lg nb lk nc lo nd ls mv mw mx my bi translated">不管真实值是否固定，我们都想知道我们估计的不确定性</li></ul><p id="b072" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">救护车的例子旨在说明第二种情况。对于第一种情况，我们可以快速浏览一下诺贝尔经济学奖得主克里斯托弗·西姆斯的工作。我将简单地引用他的学生<strong class="kz ir">渡边俊昭</strong> :</p><blockquote class="ne nf ng"><p id="14b3" class="kx ky mp kz b la lt jr lc ld lu ju lf nh lv li lj ni lw lm ln nj lx lq lr ls ij bi translated">我曾经问过克里斯，为什么他喜欢贝叶斯方法。他以卢卡斯评论作为回答，该评论认为，当政府和央行政策改变时，模型参数也会改变，因此它们不应被视为常数，而应被视为随机变量。</p></blockquote><p id="b092" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">对于这两种情况，贝叶斯推理可以用来将我们感兴趣的变量建模为一个整体分布，而不是一个唯一的值或点估计。</p><h1 id="8e68" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">介绍</h1><p id="7ee1" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">贝叶斯推理的核心是贝叶斯法则:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/587d2a35c3c8724f12b934ab64051c5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1058/format:webp/1*7TEsUMm7Y2QJDM-DpMANtw@2x.png"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">贝叶斯法则</p></figure><p id="d8fd" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">给定条件概率的定义，这个规则可能看起来非常明显并且几乎是多余的，尽管它的使用不是立即清楚的:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/2b5d9484ab6901515ed698b8b30501fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*AQs5DqkjIlpySaSaSANfgQ@2x.png"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">条件概率定义</p></figure><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi nm"><img src="../Images/4939e4988a008f2da1714e2fa52383a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kKIhQfhgBe_ftlZm2CCaVg@2x.png"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">贝叶斯规则的推导</p></figure><p id="a3be" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated"><strong class="kz ir">朱迪亚·珀尔</strong>是这样描述的，在<em class="mp">的《何以见得》</em>【2】:</p><blockquote class="ne nf ng"><p id="00bf" class="kx ky mp kz b la lt jr lc ld lu ju lf nh lv li lj ni lw lm ln nj lx lq lr ls ij bi translated">(……)贝叶斯规则在形式上是他的条件概率定义的基本结果。但从认识论上来说，它远非初等。事实上，它作为一种规范性规则，根据证据更新信念。</p></blockquote><p id="b93c" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">的确，这个看似简单的概念受到了极大的关注。它的一些实际结果在于允许反转条件概率[从P(B|A)到P(A|B)]，并且随着我们观察B的更多样本，更新我们对A可以取的值(即它的分布)的信念。</p><p id="5dc2" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">在我们深入例子之前，让我们先给贝叶斯法则的组成部分命名:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/7e232f4b48632a417ebe7d36cdbe9e1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*cW4KR5NbRWYBqzF8n2uEog@2x.png"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">又是贝叶斯法则</p></figure><p id="bb5c" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">让我们简单讨论一下每个组件的含义。希望下一节中的例子能让这些定义更加清晰。</p><p id="8bb9" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">假设我们有兴趣了解A，但只能观察B:</p><ul class=""><li id="8008" class="mq mr iq kz b la lt ld lu lg ms lk mt lo mu ls mv mw mx my bi translated">之前的<strong class="kz ir"><em class="mp"/></strong>是我们在观察b的任何值之前，对“A取每个可能值的可能性”的信念。换句话说，我们必须选择一个分布而不是A，我们有机会结合专家知识(我们有先验的<em class="mp"/>)，或者如果我们一无所知，可以简单地选择均匀分布。</li><li id="9d62" class="mq mr iq kz b la mz ld na lg nb lk nc lo nd ls mv mw mx my bi translated"><strong class="kz ir"> <em class="mp">似然</em> </strong>表示“对于A的每个可能值，B可以取的所有值的分布是什么”。于是我们定义了B上的一组分布，一个分布对应A的每个值，更具体地说，每个分布P(B|A= <em class="mp"> a </em>)是我们假设A等于某个值<em class="mp"> a </em>后B的条件分布。</li><li id="a781" class="mq mr iq kz b la mz ld na lg nb lk nc lo nd ls mv mw mx my bi translated"><strong class="kz ir"> <em class="mp">证据</em> </strong>是我们观察到的东西的总体概率(我们观察到B，可以看作A的证据)。一旦我们有了先验和似然性，就可以通过对A的所有可能值求和来计算，如下所示。这个量可能很难计算，需要近似计算技术，如蒙特卡罗或变分推断。</li></ul><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi no"><img src="../Images/71a6b36de0dc2496b1ae0c5088c04d9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PChA1hpmvnExxORKi-5ubg@2x.png"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">证据的计算(使用全概率法则)。如果A是连续的，求和就被一个积分代替。</p></figure><ul class=""><li id="f797" class="mq mr iq kz b la lt ld lu lg ms lk mt lo mu ls mv mw mx my bi translated"><strong class="kz ir"> <em class="mp">后验</em> </strong>，这是我们在考虑了新观察到的证据b之后，对A的分布的新信念[通常与我们先前的信念P(A)不同]。</li></ul><p id="ea76" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">此外，我们可以将分数<em class="mp">似然</em> / <em class="mp">证据</em>表示为<strong class="kz ir">似然比</strong>。</p><p id="0af6" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">注意，我们可以认为<em class="mp">先验</em>和<em class="mp">似然函数</em>都是固定的，即它们是在我们开始观察b的样本之前选择的假设。在这种情况下，<em class="mp">证据</em>和<em class="mp">后验</em>是我们的假设+观察的结果。</p><p id="6ef8" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">下面两个例子对我了解这些概念是如何实现的非常重要。</p><h1 id="9c6a" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">示例1 —疾病和测试</h1><p id="5f5f" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><em class="mp">功劳:下面这个例子的灵感来源于</em> <strong class="kz ir"> <em class="mp">朱迪亚珍珠</em> </strong> <em class="mp">的《何以见得》</em>【2】<em class="mp">。</em></p><p id="d9b6" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">假设我们想要估计患疾病D的概率，给定我们的测试t的结果。如果我们知道10%的人口患有D，我们可以将其纳入我们的<strong class="kz ir">先验</strong>(如果我们知道患者的详细信息，我们可以使用更好地代表她的人口子集):</p><ul class=""><li id="9af1" class="mq mr iq kz b la lt ld lu lg ms lk mt lo mu ls mv mw mx my bi translated">P(D=1)=0.1</li><li id="f0ea" class="mq mr iq kz b la mz ld na lg nb lk nc lo nd ls mv mw mx my bi translated">P(D=0)=0.9</li></ul><p id="950d" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">注意，D只能取两个值(0或1——健康或生病),但是在其他问题中，我们的变量可以接受更多的离散值，甚至是连续值。</p><p id="606e" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">从历史数据中，我们还知道测试的可靠性——我们知道当患者患有糖尿病时测试失败的可能性，以及当患者没有糖尿病时。这将构成我们的<strong class="kz ir">可能性函数:</strong></p><ul class=""><li id="f103" class="mq mr iq kz b la lt ld lu lg ms lk mt lo mu ls mv mw mx my bi translated">p(T = 1 | D = 1)= 0.75；P(T=0|D=1)=0.25</li><li id="9eed" class="mq mr iq kz b la mz ld na lg nb lk nc lo nd ls mv mw mx my bi translated">p(T = 1 | D = 0)= 0.2；P(T=0|D=0)=0.8</li></ul><p id="5c8a" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">这样，对于d的每个值，我们在T上有一个条件分布。</p><p id="ebde" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">正如您所看到的，我们假设已知疾病的真实情况，知道测试正确的概率— P(T|D)，但是我们感兴趣的是相反的情况[已知测试结果，患疾病的概率— P(D|T)]。这说明了能够反转条件概率的重要性，贝叶斯法则允许:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi np"><img src="../Images/73dfc227db6b8f33f4c8b526785a6ee6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*P84TYJ1v6ZE6HB35iS0RwQ@2x.png"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">疾病/测试示例中的贝叶斯规则</p></figure><p id="4f43" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">假设我们做了一个测试，给出了一个肯定的结果T=1。我们现在希望计算<strong class="kz ir">后验概率</strong>，即给定新信息后我们患病的更新概率。我们可以先计算一下<strong class="kz ir">证据</strong>:</p><ul class=""><li id="714c" class="mq mr iq kz b la lt ld lu lg ms lk mt lo mu ls mv mw mx my bi translated">P(T = 1)= P(T = 1 | D = 1)* P(D = 1)+P(T = 1 | D = 0)* P(D = 0)= 0.75 * 0.1+0.2 * 0.9 = 0.255</li></ul><p id="12f8" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">为了输出D上的更新分布，现在让我们计算D可以假设的每个值:</p><ul class=""><li id="8010" class="mq mr iq kz b la lt ld lu lg ms lk mt lo mu ls mv mw mx my bi translated">P(D = 1 | T = 1)= P(T = 1 | D = 1)* P(D = 1)/P(T = 1)= 0.75 * 0.1/0.255 = 0.29</li><li id="ecf4" class="mq mr iq kz b la mz ld na lg nb lk nc lo nd ls mv mw mx my bi translated">P(D = 0 | T = 1)= P(T = 1 | D = 0)* P(D = 0)/P(T = 1)= 0.2 * 0.9/0.255 = 0.71</li></ul><p id="8566" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">自然，第二步在这里是多余的，但是在其他设置中，D可以取2个以上的值。我们更新的分布表明，在得到阳性测试后，P(D=1)从10%增加到29%。如果我们要进行第二次测试，我们可以使用这个新的分布作为输入，而不是原来的先验P(D)。如果新的测试再次为正(T=1)，我们可以重复这个计算，进一步将P(D=1)增加到60%:</p><ul class=""><li id="6688" class="mq mr iq kz b la lt ld lu lg ms lk mt lo mu ls mv mw mx my bi translated">P(T=1)=0.75*0.29+0.2*0.71=0.36</li><li id="464d" class="mq mr iq kz b la mz ld na lg nb lk nc lo nd ls mv mw mx my bi translated">P(D = 1 | T = 1)= P(T = 1 | D = 1)* P(D = 1)/P(T = 1)= 0.75 * 0.29/0.36 = 0.6</li></ul><p id="af28" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">现在观察前面提到的<em class="mp">似然比</em> ( <em class="mp">似然</em> / <em class="mp">证据</em>)的含义也很有意思。这是我们之前的信念会增加或减少的比例。</p><p id="7a62" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">希望这有助于理解更新信念时贝叶斯规则的机制。然而，对我来说，当谈论一个模型的参数时(例如克里斯托弗·西姆斯(Christopher Sims)对经济建模的研究，或许多机器学习应用)，理解会发生什么似乎还不够。</p><h1 id="57fa" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">示例2 —二项式建模</h1><p id="6dea" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">转到一个更抽象的领域，贝叶斯规则可以用来估计模型参数的分布。例如，克里斯托弗·西姆斯(Christopher Sims)利用贝叶斯法则建立了一个政府和政策会发生变化的经济模型。在这种情况下，如果我们用一个分布来描述一个模型参数，我们可以比使用一个单一的值更精确地解释这种变化。</p><p id="a8d7" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated"><em class="mp">鸣谢:下面这个例子部分灵感来自于</em><strong class="kz ir"><em class="mp">Antonio salmerón</em></strong><em class="mp">在</em> <a class="ae mo" href="https://probabilistic.ai/" rel="noopener ugc nofollow" target="_blank"> <em class="mp">的概率讲座。艾暑期学校</em> </a> <em class="mp"> ( </em> <a class="ae mo" href="https://github.com/probabilisticai/probai-2019/blob/master/day1/introduction_to_probabilistic_modelling.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="mp">幻灯片</em> </a> <em class="mp">，</em> <a class="ae mo" href="https://www.youtube.com/watch?v=rvB-VVgot2A" rel="noopener ugc nofollow" target="_blank"> <em class="mp">视频</em> </a> <em class="mp"> ) </em></p><p id="f7b5" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">我们有一个二项式分布，代表20个二元实验的结果，每个实验都有成功的概率<em class="mp"> p </em>(比如说，20次有偏硬币的投掷)。正如你可能猜到的，我们感兴趣的是从观测值<em class="mp"> x </em>中估计参数<em class="mp"> p </em>(用<em class="mp"> p </em>表示硬币有多偏向)。在这种情况下，我们考虑对<em class="mp"> x </em>的一次观察，它告诉我们20次独立实验中有多少次观察成功——我们从掷硬币中得到了多少次反面。</p><p id="6ef3" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">对<em class="mp"> x </em>的一次观察可以有0到20次成功之间的任何值。使用二项式分布的定义，我们可以构建21个不同的<em class="mp">似然函数</em> P( <em class="mp"> x </em> | <em class="mp"> p </em>)，每个函数对应一个<em class="mp"> x: </em>的值</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi nq"><img src="../Images/cb209c379170e13dafed4c98371557e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M-gAGL5pTW8C9V68mtpXqw.png"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">给定x=2，4，10或15，参数p的似然函数。用<a class="ae mo" href="https://www.wolfram.com/mathematica/" rel="noopener ugc nofollow" target="_blank"> 2020 Wolfram Mathematica </a>生成</p></figure><p id="ad4d" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">每条曲线的面积总和不需要等于1，就像前面的例子P(T = 1 | D = 1)+P(T = 1 | D = 0)= 0.75+0.2≠1一样。这些曲线不是概率分布，因为对于P( <em class="mp"> x </em> |p)，我们固定<em class="mp"> x </em>并改变<em class="mp"> p </em>。如果我们固定<em class="mp"> p </em>(例如<em class="mp"> p </em> =0.3)而改变<em class="mp"> x </em>，那么这些值的总和必须为1:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi nq"><img src="../Images/2aab039cad68faf2bc381a3cbe8c8514.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bZhudCveqjYXA31wEO5_kA.png"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">变量x的概率函数，给定p=0.3。你可以在<a class="ae mo" href="https://www.wolframalpha.com/input/?i=DiscretePlot%5Bcombination%2820%2Cx%29*%280.3%29%5Ex*%281-0.3%29%5E%2820-x%29%2C+x%2C+0%2C+20%5D" rel="noopener ugc nofollow" target="_blank">这个链接</a>中更改剧情。2020 Wolfram Alpha LLC</p></figure><p id="e368" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">为了提供额外的直觉，让我们把函数P( <em class="mp"> x </em> | <em class="mp"> p </em>)看作有两个输入参数:<em class="mp"> x </em>和<em class="mp"> p </em>。如果我们允许两者同时变化，它看起来是这样的:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi nr"><img src="../Images/e123b97e845f14f0e16d2b02b5a300a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PZNMJlHVzK6hd4zXOI-brg.png"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">P(x|p)对于x和P的所有值。在橙色中，我们看到P(x|p)与平面p=0.3的交点。用<a class="ae mo" href="https://www.wolfram.com/mathematica/" rel="noopener ugc nofollow" target="_blank"> 2020 Wolfram Mathematica </a>生成</p></figure><p id="8a46" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">如果我们将<em class="mp"> x </em>固定为一个观察值，我们就有了一个似然函数(我们沿着<em class="mp"> x </em>轴对这个3D图进行切片，获得1条蓝色曲线)，如果我们固定<em class="mp"> p </em>我们就有了一个概率分布(我们沿着<em class="mp"> p </em>轴对其进行切片，获得一条类似橙色的曲线)。在我们观察到<em class="mp"> x </em>之后，我们固定该值，并获得相应的似然函数，以便与贝叶斯规则一起使用。</p><p id="d5da" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">好了，在观察了<em class="mp"> x </em>之后，我们几乎拥有了更新我们对<em class="mp"> p </em>值的信念所需的一切！继续之前，请注意以下几点:</p><ul class=""><li id="6599" class="mq mr iq kz b la lt ld lu lg ms lk mt lo mu ls mv mw mx my bi translated">使用频率方法，我们现在可以通过简单地选择最大化被观察的<em class="mp"> x </em>的似然函数的<em class="mp"> p </em>来获得<em class="mp"> p </em>的一个点估计。</li><li id="d21c" class="mq mr iq kz b la mz ld na lg nb lk nc lo nd ls mv mw mx my bi translated">这个例子可能比前一个更复杂。原因是我们的未观察变量从离散的(疾病=健康或患病)变成了连续的(p =到1之间的任何值)。出于这个原因，我们不能像我们在前面的例子中所做的那样[对于D的每个值，P(T =正| D)]枚举出P<em class="mp">P</em>的每个可能值的可能性。我们可以得到<em class="mp"> p </em>的任何特定值的可能性，但不能列出它们，因为在0和1之间有无限可能的值！</li><li id="4af8" class="mq mr iq kz b la mz ld na lg nb lk nc lo nd ls mv mw mx my bi translated">在完成一个推断步骤后，我们也无法枚举所有<em class="mp"> p </em>的后验概率，原因相同【以前P(D | T =正)表示D =健康，D =患病，但现在<em class="mp"> p </em>在后验P( <em class="mp"> p </em> | <em class="mp"> x </em>)中取很多值】。</li><li id="501f" class="mq mr iq kz b la mz ld na lg nb lk nc lo nd ls mv mw mx my bi translated">我们观察到的变量仍然是离散的，但它从两个可能的值(测试结果T = 0或1)增加到21个(观察到的成功数<em class="mp"> x </em> = 0，1，2，…，20)。这也使得观想有点困难。在其他设置中，<em class="mp"> x </em>甚至可以是连续的。</li><li id="0abc" class="mq mr iq kz b la mz ld na lg nb lk nc lo nd ls mv mw mx my bi translated">关于<em class="mp">可能性</em>这个词的一个随机事实是:拉丁语使用一个更加精确的术语——葡萄牙语中的<em class="mp">verosimilhana</em>。它的唯一含义是“某物与真理多么相似”。在每一种语言中，所选择的术语都避免使用<em class="mp">概率</em>，因为其值的总和可能不是1。</li></ul><p id="3dbf" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">最后，如果我们假设对于<em class="mp"> p </em>在0–1之间的均匀先验，在观察到新的样本<em class="mp"> x </em>后，我们就拥有了更新我们对<em class="mp"> p </em>的信念所需的一切。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ns"><img src="../Images/6d1369f76596dedcc457f5ef73931fd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y1hsnUebRyVeP4xISbQOTg.png"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">贝叶斯法则的组成部分，当对系统的参数θ建模时给定观测值<em class="nt"> x [ </em> <a class="ae mo" href="https://github.com/probabilisticai/probai-2019/blob/master/day1/introduction_to_probabilistic_modelling.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="nt">安东尼奥·萨尔梅龙</em></a><em class="nt"/></p></figure><p id="9126" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">在这种特殊情况下(<em class="mp">二项式似然</em>与<em class="mp">均匀先验</em>)后验<em class="mp">很容易计算，从而得到快速准确的结果。然而，如果我们假设其他种类的<em class="mp">似然函数</em>和<em class="mp">先验</em>，我们可能需要借助其他技术来计算我们的<em class="mp">后验</em>，例如变分推断。</em></p><p id="4565" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">关于这个例子的一些最后说明:</p><ul class=""><li id="4d7f" class="mq mr iq kz b la lt ld lu lg ms lk mt lo mu ls mv mw mx my bi translated">如果我们只想从贝叶斯规则中获得点估计，我们可以忽略分母的计算(<em class="mp">证据</em>)而不改变结果——我们可以简单地最大化分子。这叫做<strong class="kz ir">最大后验概率(MAP) </strong>。</li><li id="f420" class="mq mr iq kz b la mz ld na lg nb lk nc lo nd ls mv mw mx my bi translated">除了忽略分母，我们在寻找点估计时也可以忽略前面的<em class="mp"/>。这可以改变结果(与MAP相比)，并且对应于频率主义方法— <strong class="kz ir">最大似然估计(MLE) </strong>。</li></ul></div><div class="ab cl nu nv hu nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="ij ik il im in"><p id="316d" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">在这篇文章中，我试图激发贝叶斯推理的使用，并阐明它的基本思想。对我来说，最令人困惑的部分是理解什么是必须先验提供的。除了在之前的<em class="mp">之外，必须事先提供<em class="mp">似然函数</em>，但是这可能意味着非常不同的事情，比较起来很有趣:</em></p><ul class=""><li id="bc25" class="mq mr iq kz b la lt ld lu lg ms lk mt lo mu ls mv mw mx my bi translated">在疾病/测试示例中，当评估各种患者(患病/健康)时，我们使用测试失败的固定概率作为可能性函数。这个概率以前是已知的(可能来自历史数据)。</li><li id="dc00" class="mq mr iq kz b la mz ld na lg nb lk nc lo nd ls mv mw mx my bi translated">在二项式示例中，先前的知识相当于假设可能性表现为20个独立实验的二项式。21个可能的似然函数中的每一个(类似于2种病人)都可以基于这一假设导出。</li></ul><p id="c028" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">[1] D. Woodard，G. Nogin，P. Koch，D. Racz，M. Goldszmidt和E. Horvitz，使用移动电话GPS数据预测旅行时间可靠性(2017)，运输研究C部分:新兴技术</p><p id="35fe" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">[2] J. Pearl和D. Mackenzie，《为什么之书》(2018)，基础图书公司。</p></div></div>    
</body>
</html>