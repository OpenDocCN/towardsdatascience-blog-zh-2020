<html>
<head>
<title>Churn Prediction: A Case study of Sparkify using Apache Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">流失预测:使用Apache Spark的Sparkify案例研究</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/churn-prediction-a-case-study-of-sparkify-using-apache-spark-e67722a84de?source=collection_archive---------46-----------------------#2020-04-30">https://towardsdatascience.com/churn-prediction-a-case-study-of-sparkify-using-apache-spark-e67722a84de?source=collection_archive---------46-----------------------#2020-04-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="96f6" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">音乐流媒体平台用户的大数据建模</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/afafd72758a4e617e410f47205bb23ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*r6JaOrTgLDxZvhMg5s0Cuw.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated"><strong class="bd kr">Soure:</strong><a class="ae ks" href="https://aws.amazon.com/big-data/what-is-spark/" rel="noopener ugc nofollow" target="_blank">T3】AWST5】</a></p></figure><h2 id="199c" class="kt ku iq bd kv kw kx dn ky kz la dp lb lc ld le lf lg lh li lj lk ll lm ln lo bi translated">简介:</h2><p id="156c" class="pw-post-body-paragraph lp lq iq lr b ls lt jr lu lv lw ju lx lc ly lz ma lg mb mc md lk me mf mg mh ij bi translated">当前席卷各行业的数字化浪潮导致了数据的爆炸，因为信息正通过各种方式被利用。这一点，加上社交媒体的出现，极大地鼓励了对人工智能的倾向和匹配。<a class="ae ks" href="https://www.forbes.com/sites/charlestowersclark/2019/02/15/big-data-iot-and-ai-part-one-three-sides-of-the-same-coin/#280ccae369da" rel="noopener ugc nofollow" target="_blank">这种倾向建立在从海量数据中获得洞察力的能力上</a>这些数据有时是实时获得的，同时为依赖这些数据的产品提供动力。Apache Hadoop和Spark 正在支持处理这种大数据的技术<a class="ae ks" href="https://www.datamation.com/big-data/big-data-technologies.html" rel="noopener ugc nofollow" target="_blank">。一台计算机无法处理如此大规模的数据集，需要使用计算平台(如亚马逊网络服务(AWS)、微软Azure、IBM Watson和谷歌云)在线托管多台计算机。这就引出了本文的目标，它将应用大数据技术(Spark)并在AWS上运行，以分析12 GB大小的大数据。这里的数据集来自一个名为“Sparkify”的伪音乐流媒体服务的Udacity。一些用户在作为付费用户使用该服务一段时间后，最终取消了他们的订阅。因此，目标是能够预测此类用户的流失，此处定义为当用户在“取消确认”页面中被跟踪时，使用用户使用平台时测量的不同特征。</a></p><h2 id="abbc" class="kt ku iq bd kv kw kx dn ky kz la dp lb lc ld le lf lg lh li lj lk ll lm ln lo bi translated">业务和数据理解:</h2><p id="2623" class="pw-post-body-paragraph lp lq iq lr b ls lt jr lu lv lw ju lx lc ly lz ma lg mb mc md lk me mf mg mh ij bi translated">使用探索性数据分析(EDA)，可以了解不同用户在决定取消订阅之前的行为。有些事实是惊人的，而有些是清晰的。</p><p id="0961" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">1.<strong class="lr ir"> <em class="mn"> Length: </em> </strong>每个用户花在流媒体歌曲上的平均时间长度的合计长度。这表明没有取消用户具有稍高的歌曲平均长度。</p><p id="668d" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">2.<strong class="lr ir"> <em class="mn">点赞:</em> </strong>通过每个用户竖起大拇指的总计数来聚集点赞显示，与后来取消的用户相比，没有取消的用户更倾向于对歌曲竖起大拇指。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/e8e2e7905f490a6fab5fa0cc1aa7a58d.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/format:webp/1*E_aOEY8W3ycH8XTuhSjE9w.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated"><strong class="bd kr">图一。两个用户组在其他事件中的点赞百分比</strong></p></figure><p id="6083" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">3.<strong class="lr ir"> <em class="mn">不喜欢:</em> </strong>按每个用户的page -thumbs_down总数合计不喜欢。与后来取消的用户相比，没有取消的用户不太喜欢歌曲。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/4e0fce08d2f393fe9493e2764a49e297.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*AAkOGMYOO7xpAMfQ1hUOtg.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated"><strong class="bd kr">图二。两组用户对其他事件的不喜欢百分比</strong></p></figure><p id="eecd" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">4.<strong class="lr ir"> <em class="mn">新增好友:</em> </strong>按每个用户页面新增好友总数合计新增好友。与后来取消的用户相比，没有取消的用户更倾向于添加朋友(通过“添加朋友页面”与所有其他页面的百分比来衡量)。</p><p id="88ff" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">5.<strong class="lr ir"><em class="mn">Playlist_adds:</em></strong>按每个用户添加到播放列表的页面总数合计“Playlist _ adds”，显示与后来取消的用户相比，未取消的用户在“add_playlist”页面中出现的百分比更高。</p><p id="7dd2" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">6.<strong class="lr ir"> <em class="mn">降级:</em> </strong>按页面总计数累计降级-每个用户降级，已知未取消的用户在“降级”页面中出现的百分比比后来取消的用户低。</p><p id="4a24" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">7.<strong class="lr ir"> <em class="mn">已升级:</em> </strong>根据每个用户的页面升级总数进行升级，已知未取消的用户比后来取消的用户具有更高的升级百分比。</p><p id="7b07" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">8.<strong class="lr ir"> <em class="mn"> NumSongs: </em> </strong>通过每个用户的歌曲总数来聚集歌曲，已知没有取消的用户与后来取消的用户相比具有更高的歌曲平均数。“NextSong”页面类似于播放长度不是None的有效播放，这应该是歌曲计数的同义词，如果包括在内，不会给模型增加额外的好处。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/0a508d42a6164375ae0a2c77a05383d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*c2nl-OnNux2JJ3S23TVkhw.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated"><strong class="bd kr">图三。流失用户更多地使用GET方法。</strong></p></figure><p id="aa3f" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">9.<strong class="lr ir"> <em class="mn"> Method_PUT: </em> </strong>按每个用户使用Put方法的次数汇总Put方法。这是因为用户可能使用了不止一种方法，因此，将其设置为简单分类将不会清楚地反映此功能的效果</p><p id="5fc6" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">10.<strong class="lr ir"> <em class="mn"> Method_GET: </em> </strong>按每个用户使用Get方法的次数来聚合Get方法。与PUT方法的逻辑相同</p><p id="fcd5" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">11.<strong class="lr ir"> <em class="mn">性别:</em> </strong>根据性别对用户进行分组，因为没有用户拥有一个以上的性别。因此，性别是一个纯粹的分类特征。</p><p id="63a5" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">12.<strong class="lr ir"> <em class="mn">【状态_307: </em> </strong>按每个用户使用状态307的次数汇总状态。这是因为某些用户使用了不止一种类型状态</p><p id="34da" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">13.<strong class="lr ir"> <em class="mn">状态_200: </em> </strong>状态由每个用户使用状态的次数200来汇总。</p><p id="bfbd" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">14.<strong class="lr ir"> <em class="mn">【状态_404: </em> </strong>通过每个用户使用状态404来流传送歌曲的次数来聚集状态。</p><p id="931f" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">15.<strong class="lr ir"><em class="mn">Level _ payed:</em></strong>根据每个用户使用付费级别播放歌曲的次数来汇总级别。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/000b2d32e10cc82e807d737d470c1369.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*p0xQSFo6FSwYbogTl712wQ.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated"><strong class="bd kr">图4。流失用户更多地作为免费用户流入</strong></p></figure><p id="08fd" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated"><strong class="lr ir">16<em class="mn">。Level_free: </em> </strong>根据每个用户使用免费级别播放歌曲的次数来汇总状态。</p><p id="3410" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">17.<strong class="lr ir"> <em class="mn">注销:</em> </strong>汇总每个用户注销的总次数。这表明取消的用户经常被发现已经注销。</p><h2 id="523c" class="kt ku iq bd kv kw kx dn ky kz la dp lb lc ld le lf lg lh li lj lk ll lm ln lo bi translated">特征工程:</h2><p id="4767" class="pw-post-body-paragraph lp lq iq lr b ls lt jr lu lv lw ju lx lc ly lz ma lg mb mc md lk me mf mg mh ij bi translated">这显然是任何机器学习中最重要的部分之一，因为无论你在这里做什么，都将决定你的模型能够在多大程度上对用户行为进行分类。对于这个项目，从对数据集(EDA)的探索性分析中获得了一些见解，以了解就其对因变量(此处为标签列)的影响而言可能重复的特征。一些列具有不特定于用户的子特征，因此给定用户可能具有不止一个这样的特征。每个用户使用的级别就是一个例子。有时，可能会发现用户使用了免费级别，后来又使用了付费级别。因为，在这种情况下，它们被设计成计数、总和或平均值的集合，这取决于哪个更有意义。另一方面，有些列是纯分类列，如性别。对于这些，简单的编码(使用字符串索引器)就可以了。其他列是可以使用每个用户的总和来设计的某些变量，例如每个用户的收听时长。在所有情况下，都要避免特征的重复，或者用两个特征来解释相似的事件。显示了一个列有所有所需特征的数据框:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><div class="gh gi mr"><img src="../Images/5c282f286288013e6c6c8e5891ac07ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5-yeORnuV7QYIJxI12KO2w.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated"><strong class="bd kr">图5:简要查看用于建模的特征数据框架</strong></p></figure><p id="9233" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated"><strong class="lr ir"> <em class="mn">空元素:</em> </strong></p><p id="a326" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">因为有些用户没有某些特性的值，所以它们被捕获为NULL。实际上，考虑到使用了聚合，这些空元素是零值。因此，对于所有列，这些空元素都被替换为零。</p><p id="6daa" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated"><strong class="lr ir"> <em class="mn">缩放:</em> </strong></p><p id="7b90" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">数据集中所有要素的值的范围显示出相当大的差异。因此，对于某些机器学习模型，如逻辑回归，它们需要被缩放。为了找到最合适的定标器，通过绘制所有列的直方图来检查所有特征的分布。这表明偏离了正态分布，在一些特征中存在异常值。因此，选择了MinMaxScaler而不是标准Scaler。</p><p id="56ac" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated"><strong class="lr ir"> <em class="mn">降维:</em>T9】</strong></p><p id="3d16" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">使用主成分分析(PCA)，可以减少为预测而设计的特征，以提高模型的性能，同时加速预测。一项旨在了解不同要素在解释数据集中的差异方面所起作用的测试显示，前10个要素解释了数据集中99.9%的差异。因此，预测中使用了前10个特征。</p><h2 id="7ace" class="kt ku iq bd kv kw kx dn ky kz la dp lb lc ld le lf lg lh li lj lk ll lm ln lo bi translated">建模:</h2><p id="5802" class="pw-post-body-paragraph lp lq iq lr b ls lt jr lu lv lw ju lx lc ly lz ma lg mb mc md lk me mf mg mh ij bi translated">首先在sparkify数据集上尝试了三种不同的机器学习模型，看看哪一种能给出更好的预测。F1分数被用作决定性指标。F1定义为精确度和召回率的调和平均值。请记住，精度是对所有肯定预测的真实肯定的度量，而召回是对所有肯定标签的真实肯定预测的度量。因此，F1-score用于捕捉模型在其预测中区分两个类别的程度，同时量化正电子的预测(此处定义为流失或标签== 1)。这与准确性相反，准确性将不会捕捉对将取消其订阅的用户做出的预测有多好。由于这是一个简单的二进制分类问题，即“流失”(标签1)或“不流失”(标签0 ),因此使用multiclassclarticationevaluator作为评估器。</p><p id="4f5a" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated"><strong class="lr ir"> <em class="mn">将数据分成训练集和测试集:</em> </strong></p><p id="258e" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">数据集按照0.75/0.25的顺序分成两部分，训练集具有较大的份额。对于每种机器学习技术，训练集用于拟合/建立模型，而建立的模型应用于测试集以研究性能</p><p id="c537" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated"><strong class="lr ir"> <em class="mn">基线模型:</em> </strong></p><p id="168d" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">构建了一个基线模型，用作衡量要在数据集上测试的其他机器学习模型的性能的起点。作为一个典型的二元分类问题，首先想到的模型是逻辑回归模型。使用大多数默认参数，除了定义的<code class="fe mw mx my mz b">elasticNetParam</code>、<code class="fe mw mx my mz b">maxIter</code>和<code class="fe mw mx my mz b">regParam</code>:</p><p id="ed25" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated"><code class="fe mw mx my mz b">regParam</code> = [0.3] <br/> <code class="fe mw mx my mz b">elasticNetParam</code> = [0.8]</p><p id="8c82" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated"><code class="fe mw mx my mz b">maxIter</code> = [10]</p><p id="3df3" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">逻辑回归分析的准确率和F1值分别为82%和72%。查看所有对流失用户的预测{1}可以发现，它未能成功预测测试集中的流失。</p><p id="8f48" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated"><strong class="lr ir"> <em class="mn">随机森林分类器:</em> </strong></p><p id="a8fb" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">Spark的分类模块有一个随机森林分类器的实现，它是树和集成分类器的成员。作为被吹捧为分类任务中性能最好的算法之一，这也进行了实验。超级参数针对树的数量<code class="fe mw mx my mz b">numTree</code>和树构建的最大深度进行了调整，以使用折叠数量<code class="fe mw mx my mz b">numFold</code>等于3的交叉验证技术来尝试<code class="fe mw mx my mz b">maxDepth</code>。。此参数网格设置为:</p><p id="017f" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated"><code class="fe mw mx my mz b">numTree</code>:【3，5，8，10，12，15】</p><p id="f44d" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated"><code class="fe mw mx my mz b">maxDepth:</code> [4，8]</p><p id="b5d2" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">交叉验证后，表现最好的模型的<code class="fe mw mx my mz b">numTree</code>为8，而<code class="fe mw mx my mz b">maxDepth</code>为4。这一最佳表现用于在测试集上进行预测，结果显示<strong class="lr ir"><em class="mn">F1-得分</em> </strong>为0.73。该模型能够预测一个正确的流失用户。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi na"><img src="../Images/17fb03bae2374615853c06294cbd7ed3.png" data-original-src="https://miro.medium.com/v2/resize:fit:890/format:webp/1*ysoXKpuYpKd5MYZSf9sJNQ.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">使用RandomForest进行流失预测</p></figure><p id="315d" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated"><strong class="lr ir"> <em class="mn">决策树分类器:</em> </strong></p><p id="3eaa" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">假设我们有一个少于200行的数据框架可用于训练，我认为在预测用户流失时应用一个不太复杂的树技术是明智的，特别是使用<strong class="lr ir"><em class="mn">RandomForestClassifier的不太好的性能。</em> </strong>超参数针对树的数量<code class="fe mw mx my mz b">maxBins</code>和<code class="fe mw mx my mz b">maxDepth</code>进行了调整。使用的参数网格是:</p><p id="7184" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated"><code class="fe mw mx my mz b">maxBins</code>:[2，10，32]</p><p id="428f" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated"><code class="fe mw mx my mz b">maxDepth:</code>【1，2，3】</p><p id="7644" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">交叉验证的最佳表现模型是3个模型中的<code class="fe mw mx my mz b">maxDepth</code>和32个模型中的<code class="fe mw mx my mz b">maxBins</code>。当该模型应用于测试集时，性能显示出0.86 (86%)的<strong class="lr ir"><em class="mn"/></strong>，0.85 (85%)的<strong class="lr ir"><em class="mn"/></strong>，0.4 (40%)的<strong class="lr ir"><em class="mn"/></strong>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/05009d7bc7d3734359b2fe70af364a19.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*0rKzMBK6zmS96Pupdq0kIA.png"/></div></figure><p id="7d81" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">另一种机器学习算法<strong class="lr ir"> <em class="mn">梯度推进树</em> </strong>也被测试，以查看是否可以在预测方面有所改进。与<strong class="lr ir"> <em class="mn">决策树分类器</em> </strong>相比，这种技术显示出较高的<em class="mn">召回率</em>为60%，但较低的<em class="mn"> F1得分</em>为大约82%。</p><h2 id="e8ff" class="kt ku iq bd kv kw kx dn ky kz la dp lb lc ld le lf lg lh li lj lk ll lm ln lo bi translated">结论:</h2><p id="38d8" class="pw-post-body-paragraph lp lq iq lr b ls lt jr lu lv lw ju lx lc ly lz ma lg mb mc md lk me mf mg mh ij bi translated">该项目利用了了解Sparkify音乐流媒体平台上用户行为的机会。利用<strong class="lr ir"><em class="mn">RandomForestClassifier</em></strong><strong class="lr ir"><em class="mn">decisiontreeclassifier</em></strong>等机器学习模型，可以预测订阅平台的用户可能的离开/取消。由于用户标签中存在巨大的不平衡，这两者对所用数据集的测试集进行预测的能力受到了阻碍。该数据集主要具有未取消的用户，比例为173/52，只留下很少的数据集用于训练。这使得预测可能的流失更加困难。</p><p id="7e7b" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">然而，<strong class="lr ir"> <em class="mn">决策树分类器</em> </strong>表现更好，其<strong class="lr ir"> <em class="mn"> F1得分</em> </strong>为0.76，而<strong class="lr ir"> <em class="mn">随机森林分类器</em> </strong>的<strong class="lr ir"> <em class="mn"> F1得分</em> </strong>为0.73，基准模型使用<strong class="lr ir"> <em class="mn">逻辑回归</em> </strong>显示<strong class="lr ir"> <em class="mn"> F1进一步提高性能的步骤包括添加新功能，如<em class="mn">注销</em>和<em class="mn">长度</em>从总和变为每个用户的平均值，然后使用PCA将功能减少到10个最重要的功能(解释了99.9%以上的差异)，性能在结果(指标)和训练数据集的速度上都有显著提高。这使得<strong class="lr ir"> <em class="mn">决策树</em> </strong>的F1分数从76%提高到了85%左右，同时召回率从20%提高到了40%。另一个提高性能的尝试包括测试另一个机器学习模型——<strong class="lr ir"><em class="mn">梯度提升树</em> </strong>，它看到了大约82%的F1分数和60%的召回率。</em></strong></p><p id="a6e5" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">这种改进很好，使我的最佳模型对可能流失的预测达到60%——考虑到数据集中的不平衡，这个值足够大，不能称之为猜测。</p><p id="17a2" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">此外，由于这种不平衡，有人试图通过SMOTE采样来增加流失用户的数量，改编自<a class="ae ks" href="https://github.com/Angkirat/Smote-for-Spark/blob/master/PythonCode.py" rel="noopener ugc nofollow" target="_blank"> github </a>的代码。然而，这种尝试并没有产生结果的改善。</p><h2 id="1d07" class="kt ku iq bd kv kw kx dn ky kz la dp lb lc ld le lf lg lh li lj lk ll lm ln lo bi translated">建议:</h2><p id="056c" class="pw-post-body-paragraph lp lq iq lr b ls lt jr lu lv lw ju lx lc ly lz ma lg mb mc md lk me mf mg mh ij bi translated">进一步的工作应该包括测试其他机器学习算法，如NaiveBayes。此外，通过对标签进行加权来增加数据集的另一种尝试，以便给予流失用户比非<br/>流失用户更高的权重，可以帮助减轻数据集中不平衡的影响。最后，仍然可以设计更多的特征，同时仍然利用PCA将特征的数量减少到最多10个。</p><p id="b3ed" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated"><strong class="lr ir"> <em class="mn">参考文献:</em> </strong></p><p id="1090" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated"><a class="ae ks" href="https://github.com/Angkirat/Smote-for-Spark/blob/master/PythonCode.py" rel="noopener ugc nofollow" target="_blank">https://github . com/Angkirat/Smote-for-Spark/blob/master/python code . py</a>。<br/><br/><a class="ae ks" href="https://medium.com/@sajad1009/credit-card-fraud-detection-with-spark-and-python-high-accuracy-27a8ba8ed32" rel="noopener">https://medium . com/@ sajad 1009/credit-card-fraud-detection-with-spark-and-python-high-accuracy-27 A8 ba 8 ed 32</a><br/><br/><a class="ae ks" href="https://www.researchgate.net/post/How_to_determine_the_number_of_trees_to_be_generated_in_Random_Forest_algorithm" rel="noopener ugc nofollow" target="_blank">https://www . research gate . net/post/How _ to _ determine _ the _ number _ of _ trees _ to _ be _ generated _ in _ Random _ Forest _ algorithm</a></p><p id="dffa" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated"><em class="mn">源代码可以在我的GitHub资源库</em> <a class="ae ks" href="https://github.com/cjayidoko/UDACITY_DSND" rel="noopener ugc nofollow" target="_blank"> <strong class="lr ir"> <em class="mn">这里</em> </strong> </a></p><p id="8e00" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">我欢迎所有读者的评论和改进建议。在引用时，可以自由使用本书的内容和成果。</p><p id="25cb" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated"><strong class="lr ir">连接:</strong></p><p id="2301" class="pw-post-body-paragraph lp lq iq lr b ls mi jr lu lv mj ju lx lc mk lz ma lg ml mc md lk mm mf mg mh ij bi translated">LinkedIn:<a class="ae ks" href="https://www.linkedin.com/in/chijioke-idoko-b14135a4/" rel="noopener ugc nofollow" target="_blank">Chijioke Idoko</a></p></div></div>    
</body>
</html>