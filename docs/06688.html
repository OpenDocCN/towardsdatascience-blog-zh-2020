<html>
<head>
<title>Image Enhancement Techniques using OpenCV and Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于OpenCV和Python的图像增强技术</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-enhancement-techniques-using-opencv-and-python-9191d5c30d45?source=collection_archive---------5-----------------------#2020-05-26">https://towardsdatascience.com/image-enhancement-techniques-using-opencv-and-python-9191d5c30d45?source=collection_archive---------5-----------------------#2020-05-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/16d976247d140f278b577fe335526871.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sZ7lkLGFaok46ZjMv7-Yow.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">作者图片</p></figure><p id="8c72" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在这篇博文中，我将展示如何使用图像处理技术从低分辨率/模糊图像/低对比度图像中提高质量并提取有意义的信息。</p><p id="91d2" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">让我们开始这个过程:</p><p id="7a5d" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我有一个在传送带上运行的从仓库中取出的液化石油气钢瓶的样本图像。我的目的是找出石油气瓶的批号，以便我可以更新有多少石油气瓶已经过质量检查。</p><p id="2979" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">步骤1:导入必要的库</p><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="7c5f" class="lm ln it li b gy lo lp l lq lr"><strong class="li iu">import </strong>cv2<br/><strong class="li iu">import </strong>numpy <strong class="li iu">as </strong>np<br/><strong class="li iu">import </strong>matplotlib.pyplot <strong class="li iu">as </strong>plt</span></pre><p id="dcae" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">步骤2:加载图像并显示示例图像。</p><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="9697" class="lm ln it li b gy lo lp l lq lr">img= cv2.imread(<strong class="li iu">'cylinder1.png'</strong>)<br/>img1=cv2.imread(<strong class="li iu">'cylinder.png'</strong>)<br/>images=np.concatenate(img(img,img1),axis=1)<br/>cv2.imshow(<strong class="li iu">"Images"</strong>,images)<br/>cv2.waitKey(0)<br/>cv2.destroyAllWindows()</span></pre><figure class="ld le lf lg gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ls"><img src="../Images/7764cb0226b731bcfc09bb39c77fff4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dtUwKZ1XjqGKmYvIB5C3qA.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">作者提供的(a)批次-D26 (b)批次C27的液化石油气钢瓶图片</p></figure><p id="683d" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">正如你所看到的，图像的对比度很差。我们几乎认不出批号。这是雷电条件不合适的仓库常见的问题。进一步将讨论对比度受限的自适应直方图均衡化，并尝试在数据集上实验不同的算法。</p><p id="e962" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">步骤3:将图像转换成灰度图像</p><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="1779" class="lm ln it li b gy lo lp l lq lr">gray_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)<br/>gray_img1=cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)</span></pre><p id="bb4d" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">步骤4:现在我们找出灰度图像的直方图，并寻找强度的分布。</p><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="dcc2" class="lm ln it li b gy lo lp l lq lr">hist=cv2.calcHist(gray_img,[0],<strong class="li iu">None</strong>,[256],[0,256])<br/>hist1=cv2.calcHist(gray_img1,[0],<strong class="li iu">None</strong>,[256],[0,256])<br/>plt.subplot(121)<br/>plt.title(<strong class="li iu">"Image1"</strong>)<br/>plt.xlabel(<strong class="li iu">'bins'</strong>)<br/>plt.ylabel(<strong class="li iu">"No of pixels"</strong>)<br/>plt.plot(hist)<br/>plt.subplot(122)<br/>plt.title(<strong class="li iu">"Image2"</strong>)<br/>plt.xlabel(<strong class="li iu">'bins'</strong>)<br/>plt.ylabel(<strong class="li iu">"No of pixels"</strong>)<br/>plt.plot(hist1)<br/>plt.show()</span></pre><figure class="ld le lf lg gt ju gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/7fc85099d6c6efbbe7f10b73b0f45188.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*WYwC27XxMtkWdgyA4XYdoQ.png"/></div></figure><p id="5b9c" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">步骤5:现在我们将使用cv2.equalizeHist()函数来均衡给定灰度图像的对比度。cv2.equalizeHist()函数使亮度正常化，同时增加对比度。</p><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="9385" class="lm ln it li b gy lo lp l lq lr">gray_img_eqhist=cv2.equalizeHist(gray_img)<br/>gray_img1_eqhist=cv2.equalizeHist(gray_img1)<br/>hist=cv2.calcHist(gray_img_eqhist,[0],<strong class="li iu">None</strong>,[256],[0,256])<br/>hist1=cv2.calcHist(gray_img1_eqhist,[0],<strong class="li iu">None</strong>,[256],[0,256])<br/>plt.subplot(121)<br/>plt.plot(hist)<br/>plt.subplot(122)<br/>plt.plot(hist1)<br/>plt.show()</span></pre><figure class="ld le lf lg gt ju gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/e404b40a6339ecaeac227e3f0f3d886c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*vYP4yUgY7EfMkU_Int21DA.png"/></div></figure><p id="cd13" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">步骤6:显示灰度直方图均衡化的图像</p><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="9e6d" class="lm ln it li b gy lo lp l lq lr">eqhist_images=np.concatenate((gray_img_eqhist,gray_img1_eqhist),axis=1)<br/>cv2.imshow(<strong class="li iu">"Images"</strong>,eqhist_images)<br/>cv2.waitKey(0)<br/>cv2.destroyAllWindows()</span></pre><figure class="ld le lf lg gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/6cd855d16d3e4e583189f3c8985e00b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I3xrbNbIAd5cwoNfKYSNtA.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">灰度直方图均衡化</p></figure><p id="bc01" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">让我们进一步深入了解CLAHE</p><p id="af25" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">第七步:</p><p id="399a" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">对比度受限的自适应直方图均衡化</p><p id="cfb7" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">该算法可用于提高图像的对比度。该算法通过创建图像的几个直方图来工作，并使用所有这些直方图来重新分配图像的亮度。CLAHE可以应用于灰度图像和彩色图像。有两个参数需要调整。</p><ol class=""><li id="0e38" class="lv lw it kh b ki kj km kn kq lx ku ly ky lz lc ma mb mc md bi translated">设定对比度限制阈值的限幅限制。默认值为40</li><li id="a913" class="lv lw it kh b ki me km mf kq mg ku mh ky mi lc ma mb mc md bi translated">tileGridsize设置行和列中标题的数量。在应用cla时，图像被分成称为图块(8*8)的小块，以便执行计算。</li></ol><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="6a02" class="lm ln it li b gy lo lp l lq lr">clahe=cv2.createCLAHE(clipLimit=40)<br/>gray_img_clahe=clahe.apply(gray_img_eqhist)<br/>gray_img1_clahe=clahe.apply(gray_img1_eqhist)<br/>images=np.concatenate((gray_img_clahe,gray_img1_clahe),axis=1)<br/>cv2.imshow(<strong class="li iu">"Images"</strong>,images)<br/>cv2.waitKey(0)<br/>cv2.destroyAllWindows()</span></pre><figure class="ld le lf lg gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/a341ac2cb3ea9f9b9e9c545f0e47e5ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sv-YMsOMebWonEY3vORfjw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">克拉赫</p></figure><p id="dea7" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">第八步:</p><p id="69c3" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">阈值技术</p><p id="6966" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">阈值化是一种简单而有效的方法，用于将图像分割成前景和背景。最简单的阈值处理方法是，如果像素强度小于某个预定义的常数(阈值)，则用黑色像素替换源图像中的每个像素，如果像素强度大于阈值，则用白色像素替换。不同类型的阈值是:-</p><p id="3cd9" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">cv2。THRESH_BINARY</p><p id="a347" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">cv2。阈值_二进制_INV</p><p id="7de4" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">cv2。TRUNC阈值</p><p id="ef72" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">cv2。阈值为零</p><p id="4be4" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">cv2。THRESH_TOZERO_INV</p><p id="9eb2" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">cv2。OTSU阈值</p><p id="39ce" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">cv2。阈值三角形</p><p id="4060" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">尝试更改阈值和max_val以获得不同的结果。</p><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="b027" class="lm ln it li b gy lo lp l lq lr">th=80<br/>max_val=255<br/>ret, o1 = cv2.threshold(gray_img_clahe, th, max_val, cv2.THRESH_BINARY)<br/>cv2.putText(o1,<strong class="li iu">"Thresh_Binary"</strong>,(40,100),cv2.FONT_HERSHEY_SIMPLEX,2,(255,255,255),3,cv2.LINE_AA)<br/>ret, o2 = cv2.threshold(gray_img_clahe, th, max_val, cv2.THRESH_BINARY_INV)<br/>cv2.putText(o2,<strong class="li iu">"Thresh_Binary_inv"</strong>,(40,100),cv2.FONT_HERSHEY_SIMPLEX,2,(255,255,255),3,cv2.LINE_AA)<br/>ret, o3 = cv2.threshold(gray_img_clahe, th, max_val, cv2.THRESH_TOZERO)<br/>cv2.putText(o3,<strong class="li iu">"Thresh_Tozero"</strong>,(40,100),cv2.FONT_HERSHEY_SIMPLEX,2,(255,255,255),3,cv2.LINE_AA)<br/>ret, o4 = cv2.threshold(gray_img_clahe, th, max_val, cv2.THRESH_TOZERO_INV)<br/>cv2.putText(o4,<strong class="li iu">"Thresh_Tozero_inv"</strong>,(40,100),cv2.FONT_HERSHEY_SIMPLEX,2,(255,255,255),3,cv2.LINE_AA)<br/>ret, o5 = cv2.threshold(gray_img_clahe, th, max_val, cv2.THRESH_TRUNC)<br/>cv2.putText(o5,<strong class="li iu">"Thresh_trunc"</strong>,(40,100),cv2.FONT_HERSHEY_SIMPLEX,2,(255,255,255),3,cv2.LINE_AA)<br/>ret ,o6=  cv2.threshold(gray_img_clahe, th, max_val,  cv2.THRESH_OTSU)<br/>cv2.putText(o6,<strong class="li iu">"Thresh_OSTU"</strong>,(40,100),cv2.FONT_HERSHEY_SIMPLEX,2,(255,255,255),3,cv2.LINE_AA)<br/><br/>final=np.concatenate((o1,o2,o3),axis=1)<br/>final1=np.concatenate((o4,o5,o6),axis=1)<br/><br/>cv2.imwrite(<strong class="li iu">"Image1.jpg"</strong>,final)<br/>cv2.imwrite(<strong class="li iu">"Image2.jpg"</strong>,final1)</span></pre><figure class="ld le lf lg gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mj"><img src="../Images/2e3b7f32c5dd6205d42018bd121a2861.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WY6Ok5AgqIm22VmGjrKTPw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">Thresh_Binary_inv，Thresh_Binary_inv，Thresh_Tozero</p></figure><figure class="ld le lf lg gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mk"><img src="../Images/91a0a7d3b619154d8b6d99aeea799e5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6irE70hpdyy7534Lmgfp5Q.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">Thresh_Tozero_inv，Thresh_trunc，Thresh_OSTU</p></figure><p id="24b7" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">步骤9:自适应阈值</p><p id="2720" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在上一节中，我们已经使用全局阈值应用了cv2.threshold()。正如我们所看到的，由于图像不同区域的光照条件不同，获得的结果不是很好。在这些情况下，您可以尝试自适应阈值处理。在OpenCV中，自适应阈值处理由函数<strong class="kh iu"> cv2.adapativeThreshold() </strong>执行</p><p id="81eb" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">该功能将自适应阈值应用于src阵列(8位单通道图像)。maxValue参数设置满足条件的dst图像中的像素值。adaptiveMethod参数设置要使用的自适应阈值算法。</p><p id="54a0" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">cv2。ADAPTIVE _ THRESH _ MEAN _ C:T(x，y)阈值计算为(x，y)的blockSize x blockSize邻域的<strong class="kh iu">均值</strong>减去C参数。<br/> cv2。ADAPTIVE _ THRESH _ GAUSSIAN _ C:T(x，y)阈值计算为(x，y)的blockSize x blockSize邻域的<strong class="kh iu">加权和</strong>减去C参数。</p><p id="d909" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">blockSize参数设置用于计算像素阈值的邻域的大小，它可以取值3、5、7…等等。</p><p id="7a36" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">C参数只是从平均值或加权平均值中减去的常数(取决于adaptive method参数设置的自适应方法)。通常，该值为正值，但也可以为零或负值。</p><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="0b6f" class="lm ln it li b gy lo lp l lq lr">gray_image = cv2.imread(<strong class="li iu">'cylinder1.png'</strong>,0)<br/>gray_image1 = cv2.imread(<strong class="li iu">'cylinder.png'</strong>,0)<br/>thresh1 = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)<br/>thresh2 = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 31, 3)<br/>thresh3 = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 13, 5)<br/>thresh4 = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 4)<br/>thresh11 = cv2.adaptiveThreshold(gray_image1, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)<br/>thresh21 = cv2.adaptiveThreshold(gray_image1, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 31, 5)<br/>thresh31 = cv2.adaptiveThreshold(gray_image1, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 21,5 )<br/>thresh41 = cv2.adaptiveThreshold(gray_image1, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 5)<br/><br/>final=np.concatenate((thresh1,thresh2,thresh3,thresh4),axis=1)<br/>final1=np.concatenate((thresh11,thresh21,thresh31,thresh41),axis=1)<br/>cv2.imwrite(<strong class="li iu">'rect.jpg'</strong>,final)<br/>cv2.imwrite(<strong class="li iu">'rect1.jpg'</strong>,final1)</span></pre><figure class="ld le lf lg gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ml"><img src="../Images/32f7c1e16e17e2cf7ac0727cf6b79979.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2zTJx1xHRQONuKgcTeWIIg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">自适应阈值</p></figure><figure class="ld le lf lg gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mm"><img src="../Images/ace71a976130f4dcf05c4c3e1355a02e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UCGyC45DGoEOaDkKC7JlIg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">自适应阈值</p></figure><p id="aa10" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">第十步:</p><p id="3cd5" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">OTSU二值化</p><p id="b7c9" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">Otsu的二值化算法，这是一种处理双峰图像的好方法。双峰图像可以通过包含两个峰值的直方图来表征。Otsu的算法通过最大化两类像素之间的方差来自动计算分离两个峰值的最佳阈值。等效地，最佳阈值使类内方差最小化。Otsu的二值化算法是一种统计方法，因为它依赖于从直方图中获得的统计信息(例如，平均值、方差或熵)</p><pre class="ld le lf lg gt lh li lj lk aw ll bi"><span id="f1a3" class="lm ln it li b gy lo lp l lq lr">gray_image = cv2.imread(<strong class="li iu">'cylinder1.png'</strong>,0)<br/>gray_image1 = cv2.imread(<strong class="li iu">'cylinder.png'</strong>,0)<br/>ret,thresh1 = cv2.threshold(gray_image,0, 255,  cv2.THRESH_BINARY+cv2.THRESH_OTSU)<br/>ret,thresh2 = cv2.threshold(gray_image1,0, 255,  cv2.THRESH_BINARY+cv2.THRESH_OTSU)<br/><br/>cv2.imwrite(<strong class="li iu">'rect.jpeg'</strong>,np.concatenate((thresh1,thresh2),axis=1))</span></pre><figure class="ld le lf lg gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mn"><img src="../Images/38969ef72cd6761bba8f968d34624944.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J-FcU2skZQNgTr4W1R2oAw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">OTSU二值化</p></figure><p id="16ea" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">现在，我们已经从低对比度图像中清楚地识别出批号。希望你觉得这篇博客内容丰富且有趣。</p><p id="30b7" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">谢谢大家！！</p><p id="ec1f" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">请继续关注我的下一篇博客…</p><p id="1c03" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">你可以通过下面的链接访问我以前的博客</p><p id="7bc2" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在我的Youtube频道上关注我</p><p id="9f2a" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><a class="ae mo" href="https://www.youtube.com/channel/UCSp0BoeXI_EK2W0GzG7TxEw" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/channel/UCSp0BoeXI_EK2W0GzG7TxEw</a></p><p id="2ad4" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在此与我联系:</p><p id="1c14" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">领英:<a class="ae mo" href="https://www.linkedin.com/in/ashishban..." rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/ashishban...</a></p><p id="1759" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">github:<a class="ae mo" href="https://github.com/Ashishb21" rel="noopener ugc nofollow" target="_blank">https://github.com/Ashishb21</a></p><p id="bba4" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">中:<a class="ae mo" href="https://medium.com/@ashishb21" rel="noopener">https://medium.com/@ashishb21</a></p><p id="3561" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">网址:<a class="ae mo" href="http://techplanetai.com/" rel="noopener ugc nofollow" target="_blank">http://techplanetai.com/</a></p><p id="50bc" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">电子邮件:techplanetai@gmail.com ashishb21@gmail.com</p><p id="793e" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">关注我的Youtube频道，观看与技术相关的视频</p><p id="d1b0" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">https://www.youtube.com/channel/UCSp0BoeXI_EK2W0GzG7TxEw<a class="ae mo" href="https://www.youtube.com/channel/UCSp0BoeXI_EK2W0GzG7TxEw" rel="noopener ugc nofollow" target="_blank"/></p><div class="mp mq gp gr mr ms"><a rel="noopener follow" target="_blank" href="/building-python-source-with-opencv-and-opencv-contrib-ba95d709eb"><div class="mt ab fo"><div class="mu ab mv cl cj mw"><h2 class="bd iu gy z fp mx fr fs my fu fw is bi translated">用OpenCV和OpenCV Contrib构建Python源代码</h2><div class="mz l"><h3 class="bd b gy z fp mx fr fs my fu fw dk translated">从源代码在Ubuntu 14.0 LTS上安装Python 3.7</h3></div><div class="na l"><p class="bd b dl z fp mx fr fs my fu fw dk translated">towardsdatascience.com</p></div></div><div class="nb l"><div class="nc l nd ne nf nb ng jz ms"/></div></div></a></div><div class="mp mq gp gr mr ms"><a rel="noopener follow" target="_blank" href="/indian-actors-classification-using-deep-neural-networks-8552573f39aa"><div class="mt ab fo"><div class="mu ab mv cl cj mw"><h2 class="bd iu gy z fp mx fr fs my fu fw is bi translated">使用深度神经网络的印度演员分类</h2><div class="mz l"><h3 class="bd b gy z fp mx fr fs my fu fw dk translated">如果你需要使用深度网络对你最喜欢的演员进行分类，该怎么办？</h3></div><div class="na l"><p class="bd b dl z fp mx fr fs my fu fw dk translated">towardsdatascience.com</p></div></div><div class="nb l"><div class="nh l nd ne nf nb ng jz ms"/></div></div></a></div></div></div>    
</body>
</html>