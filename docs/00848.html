<html>
<head>
<title>Face Recognition on Jetson Nano using TensorRT</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于TensorRT的Jetson Nano人脸识别</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/face-recognition-using-tensorrt-on-jetson-nano-set-up-in-less-than-5min-7c00bf730085?source=collection_archive---------6-----------------------#2020-01-24">https://towardsdatascience.com/face-recognition-using-tensorrt-on-jetson-nano-set-up-in-less-than-5min-7c00bf730085?source=collection_archive---------6-----------------------#2020-01-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2281" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">Jetson Nano上FP16 precision中的mtCNN和Google FaceNet</h2></div><p id="3aeb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">说到<em class="lb">人脸识别</em>有很多选项可以选择。虽然大多数都是基于云的，但我决定构建一个基于硬件的人脸识别系统，它不需要互联网连接，这使得它对机器人、嵌入式系统和汽车应用特别有吸引力。</p><p id="f106" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> → </strong> <a class="ae lc" href="https://github.com/nwesem/mtcnn_facenet_cpp_tensorRT" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">链接到Github库</strong> </a></p><h1 id="5018" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">更新</h1><p id="bac6" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">存储库已更新(2020年9月18日)，现在一切都可以与Jetpack 4.4、Cuda 10.2、cudnn 8.0、TensorRT 7.x和OpenCV 4.1.1兼容。</p><h1 id="f403" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">NVIDIA Jetson Nano</h1><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi ma"><img src="../Images/264a78637e6d00869e686b53514c54ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1D5y5AbgTmmHJc6lHNbBfw.jpeg"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">来源:<a class="ae lc" href="https://developer.nvidia.com/embedded/jetson-nano-developer-kit" rel="noopener ugc nofollow" target="_blank">https://developer . NVIDIA . com/embedded/jetson-nano-developer-kit</a></p></figure><p id="f54f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">NVIDIA Jetson Nano是一款面向计算密集型嵌入式应用的单板计算机，包括一个128核Maxwell GPU和一个四核ARM A57 64位CPU。此外，单板计算机非常适合计算机视觉领域 <strong class="kh ir">神经网络的<strong class="kh ir">部署</strong>，因为它以5–10W的功耗提供472 GFLOPS的FP16计算性能<a class="ae lc" href="https://elinux.org/Jetson_Nano" rel="noopener ugc nofollow" target="_blank">来源</a>。有许多教程可以确保轻松开始使用Jetson平台，例如<a class="ae lc" href="https://github.com/dusty-nv/jetson-inference" rel="noopener ugc nofollow" target="_blank"> Hello AI-World教程</a>或<a class="ae lc" href="https://github.com/NVIDIA-AI-IOT/jetbot" rel="noopener ugc nofollow" target="_blank"> Jetbot </a>，这是一个基于Jetson Nano的小型DIY机器人。</strong></p><h1 id="e9f9" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">NVIDIA TensorRT</h1><p id="bc3b" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">TensorRT通过合并层和张量，为特定GPU选择最佳内核，并在保持精度的同时降低矩阵乘法的精度(FP16，INT8)，实现了在您最喜欢的ML框架(TensorFlow，Keras，PyTorch等)中训练的优化机器学习模型。注意，对于INT8精度，需要额外的校准步骤来保持精度。由于这显著(至少在大多数情况下)减少了推理时间并提高了资源效率，因此这是在机器人、嵌入式系统(使用GPU)、自动驾驶和数据中心部署机器学习模型的最终步骤。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi ma"><img src="../Images/3729691a04de41014bd151c485bde8fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*asvCqn1JXuzL0dDaqDTVkw.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">来源:<a class="ae lc" href="https://developer.nvidia.com/tensorrt" rel="noopener ugc nofollow" target="_blank">https://developer.nvidia.com/tensorrt</a></p></figure><p id="8734" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">FP16是什么意思？也被称为<strong class="kh ir">半精度</strong>。大多数框架中的机器学习模型使用32位精度进行训练。在FP16的情况下，经过训练的模型的精度会降低16位，或者对于NVIDIA Jetson AGX Xavier，您甚至可以将模型转换为int 8(8位)。根据NVIDIA的推断，经过训练的模型的时间可以加快100多倍。</p><h1 id="1a87" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">mtCNN</h1><p id="d1bf" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated"><a class="ae lc" href="https://arxiv.org/pdf/1604.02878.pdf" rel="noopener ugc nofollow" target="_blank">多任务级联卷积网络</a> (mtCNN)是一种基于深度学习的人脸和地标检测方法，对头部姿势、光照和遮挡不变。在保持实时能力的同时，通过由粗到细的三阶段过程来计算面部和标志位置，这在面部识别场景中尤其重要。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/c77c594faf5478c7b76bef917d97565c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1122/format:webp/1*h6J5uRb9wQAi6BDhiqsjAw.jpeg"/></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">使用mtCNN进行人脸和地标检测(<a class="ae lc" href="https://pypi.org/project/mtcnn/" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><h1 id="ab28" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">谷歌脸谱网</h1><p id="6af1" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated"><a class="ae lc" href="https://arxiv.org/pdf/1503.03832.pdf" rel="noopener ugc nofollow" target="_blank">谷歌的FaceNet </a>是一个深度卷积网络，将160x160 RGB图像中的人脸嵌入到128维的潜在空间中，并允许对嵌入的人脸进行特征匹配。通过在数据库中保存人脸的嵌入，您可以执行特征匹配，这允许识别人脸，因为当前可见人脸嵌入的欧几里德距离将比其他嵌入更接近已知嵌入。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi mr"><img src="../Images/35c118788a128133817a6149b880c9d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jxXjI7ahtXOt2vh55q8bGA.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">(<a class="ae lc" rel="noopener" target="_blank" href="/a-facenet-style-approach-to-facial-recognition-dc0944efe8d1">来源</a>)</p></figure><h1 id="aedc" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">设置和代码</h1><p id="a7a7" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">由于Jetpack附带了Cuda、CudNN、TensorRT和OpenCV，因此这个项目的设置和构建不到5分钟。所以，不要害怕尝试它</p><p id="f33e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> → </strong> <a class="ae lc" href="https://github.com/nwesem/mtcnn_facenet_cpp_tensorRT" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">链接到Github仓库</strong> </a></p><p id="f3cd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">据我所知，这是TensorRT中第一个结合了mtCNN和Google FaceNet的开源cpp实现，我邀请您合作，从效率和功能方面改进该实现。</p><p id="acab" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个项目的设置包括:<br/> - Jetson Nano开发工具包<br/> - Raspberry Pi Camera v2(或Jetson Nano支持的任何USB相机)<br/> - <em class="lb">可选:</em> PWM风扇，用于CPU和GPU的适当冷却<br/> - <em class="lb">可选</em>:相机的某种相机支架</p><h1 id="a7f5" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">表演</h1><p id="aa93" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">最后，这是Jetson Nano在640x480 (480p)中的人脸识别性能的概述:使用mtCNN进行人脸检测的<br/>~ 60毫秒+/- 20毫秒<br/>~ 22毫秒+/-2毫秒用于facenet推理</p></div></div>    
</body>
</html>