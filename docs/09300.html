<html>
<head>
<title>What makes Logistic Regression a Classification Algorithm?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">是什么让逻辑回归成为一种分类算法？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-makes-logistic-regression-a-classification-algorithm-35018497b63f?source=collection_archive---------20-----------------------#2020-07-03">https://towardsdatascience.com/what-makes-logistic-regression-a-classification-algorithm-35018497b63f?source=collection_archive---------20-----------------------#2020-07-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="d32f" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">进入现实世界</h2><div class=""/><div class=""><h2 id="0e07" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">对数优势，基线的逻辑回归解释。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/55ddceb70cef8424dd044785ba663fcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KE_Ccr6hyC_ZK0Or1kfhiQ.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">凯勒·琼斯在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片——已编辑</p></figure><blockquote class="li"><p id="21d2" class="lj lk it bd ll lm ln lo lp lq lr ls dk translated">逻辑回归是一个<a class="ae lh" href="https://en.wikipedia.org/wiki/Statistical_model" rel="noopener ugc nofollow" target="_blank">统计模型</a>，其基本形式使用一个<a class="ae lh" href="https://en.wikipedia.org/wiki/Logistic_function" rel="noopener ugc nofollow" target="_blank">逻辑函数</a>来模拟一个<a class="ae lh" href="https://en.wikipedia.org/wiki/Binary_variable" rel="noopener ugc nofollow" target="_blank">二元</a> <a class="ae lh" href="https://en.wikipedia.org/wiki/Dependent_variable" rel="noopener ugc nofollow" target="_blank">因变量</a>，尽管存在许多更复杂的<a class="ae lh" href="https://en.wikipedia.org/wiki/Logistic_regression#Extensions" rel="noopener ugc nofollow" target="_blank">扩展</a>。<br/> —维基百科。</p></blockquote><p id="25f1" class="pw-post-body-paragraph lt lu it lv b lw lx kd ly lz ma kg mb mc md me mf mg mh mi mj mk ml mm mn ls im bi translated"><em class="mo"> —所有图像(情节)均由作者生成和修改。</em></p><p id="65b1" class="pw-post-body-paragraph lt lu it lv b lw mp kd ly lz mq kg mb mc mr me mf mg ms mi mj mk mt mm mn ls im bi translated">很可能，对于每一个数据从业者来说，<strong class="lv jd"> <em class="mo">线性回归</em> </strong>恰好是实现机器学习的起点，在这里你了解到<em class="mo">为给定的独立规则集</em>预言一个连续值。</p><h2 id="2490" class="mu mv it bd mw mx my dn mz na nb dp nc mc nd ne nf mg ng nh ni mk nj nk nl iz bi translated">为什么是逻辑的，不是线性的？</h2><p id="73e4" class="pw-post-body-paragraph lt lu it lv b lw nm kd ly lz nn kg mb mc no me mf mg np mi mj mk nq mm mn ls im bi translated">让我们从最基本的一个开始，在<strong class="lv jd"><em class="mo"/></strong>二元分类中，模型应该能够预测因变量为两个可能类之一，可能是<em class="mo"> 0 或 1 </em>。如果我们考虑使用<em class="mo">线性回归</em>，我们可以预测给定规则集的值作为模型的输入，但它将预测连续值，如 0.03、+1.2、-0.9 等。这不适于将其归类到两类中的一类，也不适于将其识别为预测一类的概率值。</p><p id="328a" class="pw-post-body-paragraph lt lu it lv b lw mp kd ly lz mq kg mb mc mr me mf mg ms mi mj mk mt mm mn ls im bi translated"><strong class="lv jd"> <em class="mo">例如</em> </strong>当我们要预测一个网站是否是恶意的当 URL 的长度作为一个特征给定时，响应变量有两个值，良性和恶意。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/af18685d47ed05678f858f12a2d1db32.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*8BI-dKPeDGVbpEOp9lac-A.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">分类数据的线性回归—按作者</p></figure><p id="6d60" class="pw-post-body-paragraph lt lu it lv b lw mp kd ly lz mq kg mb mc mr me mf mg ms mi mj mk mt mm mn ls im bi translated">如果我们试图将线性回归模型拟合到二元分类问题，模型拟合将是一条直线，并且可以看出为什么它不适合使用相同的直线。</p><p id="4b22" class="pw-post-body-paragraph lt lu it lv b lw mp kd ly lz mq kg mb mc mr me mf mg ms mi mj mk mt mm mn ls im bi translated">为了克服这个问题，我们使用了一个<strong class="lv jd"> <em class="mo"> sigmoid 函数</em> </strong>，它试图用指数曲线拟合数据来建立一个好的模型。</p><h1 id="5a35" class="ns mv it bd mw nt nu nv mz nw nx ny nc ki nz kj nf kl oa km ni ko ob kp nl oc bi translated">Logistic/Sigmoid 函数</h1><p id="d6e1" class="pw-post-body-paragraph lt lu it lv b lw nm kd ly lz nn kg mb mc no me mf mg np mi mj mk nq mm mn ls im bi translated">逻辑回归可以用<em class="mo">逻辑函数</em>来解释，也称为<em class="mo"> Sigmoid 函数</em>，它接受任何实际输入<em class="mo"> x </em>，并输出 0 和 1 之间的概率值，该概率值定义为:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi od"><img src="../Images/74e2816203c512469ebd7ae79cd5cc21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*l87rHpJLM_u7k-LInW-jYQ.png"/></div></figure><p id="2eb2" class="pw-post-body-paragraph lt lu it lv b lw mp kd ly lz mq kg mb mc mr me mf mg ms mi mj mk mt mm mn ls im bi translated">使用上述逻辑函数的模型拟合可以如下所示:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oe"><img src="../Images/9bea99b7989bb785e287baf5744ce723.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XisqJi764DTxragiRFexSQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">分类数据的逻辑回归—按作者</p></figure><p id="2db3" class="pw-post-body-paragraph lt lu it lv b lw mp kd ly lz mq kg mb mc mr me mf mg ms mi mj mk mt mm mn ls im bi translated">此外，对于任何给定的自变量 t，让我们将其视为单变量回归模型中的线性函数，其中<em class="mo"> β0 </em>是截距，<em class="mo"> β1 </em>是斜率，由下式给出:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi of"><img src="../Images/b27bc66c7f0e3772b463d742acb956a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/1*K28CcLhFka4iOz3JO0NOUg.png"/></div></figure><p id="0d63" class="pw-post-body-paragraph lt lu it lv b lw mp kd ly lz mq kg mb mc mr me mf mg ms mi mj mk mt mm mn ls im bi translated">输出 0 和 1 之间的值的通用逻辑函数<em class="mo"> p </em>将变成，</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi og"><img src="../Images/b8cd50a35ca4ef4862b145a80d057da2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*c5vPslbYETp28VpmYRvPVA.png"/></div></figure><p id="c919" class="pw-post-body-paragraph lt lu it lv b lw mp kd ly lz mq kg mb mc mr me mf mg ms mi mj mk mt mm mn ls im bi translated">我们可以看到，可分为两类的数据可以使用逻辑函数对线性函数中的给定变量进行建模。但是输入变量 x 和输出概率之间的关系不容易用 sigmoid 函数来解释，我们现在引入了<strong class="lv jd"><em class="mo">Logit</em></strong>(log-odds)函数，使得该模型可以用线性方式来解释。</p><h1 id="8aa3" class="ns mv it bd mw nt nu nv mz nw nx ny nc ki nz kj nf kl oa km ni ko ob kp nl oc bi translated">对数概率函数</h1><p id="7a83" class="pw-post-body-paragraph lt lu it lv b lw nm kd ly lz nn kg mb mc no me mf mg np mi mj mk nq mm mn ls im bi translated">对数赔率函数<em class="mo">也称为赔率的自然对数</em>，是标准逻辑函数的逆函数，可以定义并进一步简化为:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oh"><img src="../Images/dc3544d2889cdc43c90dc6945d337b03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kv33IT2dtfjRPG1xcSAAvA.png"/></div></div></figure><p id="9de8" class="pw-post-body-paragraph lt lu it lv b lw mp kd ly lz mq kg mb mc mr me mf mg ms mi mj mk mt mm mn ls im bi translated">在上述等式中，术语如下:</p><ul class=""><li id="c145" class="oi oj it lv b lw mp lz mq mc ok mg ol mk om ls on oo op oq bi translated"><em class="mo"> g </em>是<a class="ae lh" href="https://en.wikipedia.org/wiki/Logit" rel="noopener ugc nofollow" target="_blank"> logit </a>功能。对于<em class="mo"> g(p(x)) </em>的等式表明 logit 等价于线性回归表达式</li><li id="4901" class="oi oj it lv b lw or lz os mc ot mg ou mk ov ls on oo op oq bi translated"><em class="mo"> ln </em>表示<a class="ae lh" href="https://en.wikipedia.org/wiki/Natural_logarithm" rel="noopener ugc nofollow" target="_blank">自然对数</a></li><li id="d50a" class="oi oj it lv b lw or lz os mc ot mg ou mk ov ls on oo op oq bi translated"><em class="mo"> p(x) </em>是因变量落入两类 0 或 1 之一的概率，给定预测值的某种线性组合</li><li id="d136" class="oi oj it lv b lw or lz os mc ot mg ou mk ov ls on oo op oq bi translated"><em class="mo"> β0 </em>是线性回归方程的<a class="ae lh" href="https://en.wikipedia.org/wiki/Y-intercept" rel="noopener ugc nofollow" target="_blank">截距</a></li><li id="593e" class="oi oj it lv b lw or lz os mc ot mg ou mk ov ls on oo op oq bi translated"><em class="mo"> β1 </em>是回归系数乘以预测值</li></ul><p id="d96f" class="pw-post-body-paragraph lt lu it lv b lw mp kd ly lz mq kg mb mc mr me mf mg ms mi mj mk mt mm mn ls im bi translated">通过进一步简化上述方程并对两边进行指数运算，我们可以推导出概率与线性模型之间的关系如下:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/1c17cc772adaa3c07717638a9f35b70b.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/format:webp/1*a1wdaYLavV_K3VSqQPMIKg.png"/></div></figure><p id="e445" class="pw-post-body-paragraph lt lu it lv b lw mp kd ly lz mq kg mb mc mr me mf mg ms mi mj mk mt mm mn ls im bi translated">左项称为<strong class="lv jd"> <em class="mo">赔率</em> </strong>，定义为等价于线性回归表达式的指数函数。在两边都有<em class="mo"> ln </em>(对数基数 e)的情况下，我们可以将对数优势和独立变量<em class="mo"> x </em>之间的关系解释为线性。</p><h2 id="a2e9" class="mu mv it bd mw mx my dn mz na nb dp nc mc nd ne nf mg ng nh ni mk nj nk nl iz bi translated">为什么要回归？</h2><p id="4ff7" class="pw-post-body-paragraph lt lu it lv b lw nm kd ly lz nn kg mb mc no me mf mg np mi mj mk nq mm mn ls im bi translated">概率<em class="mo"> p(x) </em>随变量 x 的变化不能直接理解，因为它是由 sigmoid 函数定义的。但是通过上面的表达式，我们可以解释变量 x 的对数几率的变化是关于变量<em class="mo"> x </em>本身的线性变化。具有线性方程对数优势图可以被看作是，</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/cb3dbed17b20e9acfb97f73d57567208.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*7ETm9YJTSixm_Y7ovZrD7w.jpeg"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">对数优势与独立变量 x——作者</p></figure><p id="c216" class="pw-post-body-paragraph lt lu it lv b lw mp kd ly lz mq kg mb mc mr me mf mg ms mi mj mk mt mm mn ls im bi translated">因变量的概率结果表明，线性回归表达式的值可以从负无穷大变化到正无穷大，然而，在用 sigmoid 函数进行变换之后，所得的概率表达式<em class="mo"> p(x) </em>的范围在 0 和 1 之间，即 0 &lt; p &lt; 1。因此，这就是<strong class="lv jd">使逻辑回归成为回归分类算法的原因</strong>，它根据决策边界将线性回归的值分类到特定类别。</p><h1 id="c358" class="ns mv it bd mw nt nu nv mz nw nx ny nc ki nz kj nf kl oa km ni ko ob kp nl oc bi translated">判别边界</h1><p id="b54d" class="pw-post-body-paragraph lt lu it lv b lw nm kd ly lz nn kg mb mc no me mf mg np mi mj mk nq mm mn ls im bi translated">决策边界被定义为一个<em class="mo">阈值</em>值，它帮助我们将 sigmoid 函数给出的预测概率值分类到一个特定的类别中，积极的或消极的。</p><h2 id="7e25" class="mu mv it bd mw mx my dn mz na nb dp nc mc nd ne nf mg ng nh ni mk nj nk nl iz bi translated">线性决策边界</h2><p id="7abf" class="pw-post-body-paragraph lt lu it lv b lw nm kd ly lz nn kg mb mc no me mf mg np mi mj mk nq mm mn ls im bi translated">当两个或多个类别可以线性分离时，</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oy"><img src="../Images/424d5389174da3c31a122786f183fdd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UEMtd_lo2ve5M1jTYVg4DQ.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">线性决策边界—作者</p></figure><h2 id="ac9a" class="mu mv it bd mw mx my dn mz na nb dp nc mc nd ne nf mg ng nh ni mk nj nk nl iz bi translated">非线性边界</h2><p id="9baf" class="pw-post-body-paragraph lt lu it lv b lw nm kd ly lz nn kg mb mc no me mf mg np mi mj mk nq mm mn ls im bi translated">当两个或多个类别不能线性分离时，</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oz"><img src="../Images/6cd611dc6694d56c6dbbb0a11cf57bc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RggWqrx86u_4JhUY1zHznw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">非线性决策边界—作者</p></figure><h1 id="672c" class="ns mv it bd mw nt nu nv mz nw nx ny nc ki nz kj nf kl oa km ni ko ob kp nl oc bi translated">多类分类</h1><p id="a8f3" class="pw-post-body-paragraph lt lu it lv b lw nm kd ly lz nn kg mb mc no me mf mg np mi mj mk nq mm mn ls im bi translated"><a class="ae lh" href="https://en.wikipedia.org/wiki/Multiclass_classification" rel="noopener ugc nofollow" target="_blank">多类</a>和二元逻辑回归背后的基本直觉是一样的。但是，对于一个多类分类问题，我们遵循一个<a class="ae lh" href="https://houxianxu.github.io/implementation/One-vs-All-LogisticRegression.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lv jd"> <em class="mo">一个 v/s 全部分类</em> </strong> </a>。如果该模型有多个独立变量，则传统方程被修改为:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pa"><img src="../Images/a49c35fbcd94d617e85214b8bc03f629.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7uXOwzakASQcTZ3SLMer9Q.png"/></div></div></figure><p id="e059" class="pw-post-body-paragraph lt lu it lv b lw mp kd ly lz mq kg mb mc mr me mf mg ms mi mj mk mt mm mn ls im bi translated">这里，对数优势可定义为当线性回归变为使用<em class="mo"> m </em>个外植体的多元回归时，与存在的多个独立变量线性相关。</p><p id="8a66" class="pw-post-body-paragraph lt lu it lv b lw mp kd ly lz mq kg mb mc mr me mf mg ms mi mj mk mt mm mn ls im bi translated">如果我们必须预测天气是晴天、雨天还是刮风，我们正在处理一个多方面的问题。我们把这个问题转化为三个二元分类问题，即是否晴天、是否下雨和是否刮风。我们对输入要素独立运行所有三个分类<em class="mo"/>，概率值相对于其他分类最大的分类成为解决方案。</p><h1 id="4f47" class="ns mv it bd mw nt nu nv mz nw nx ny nc ki nz kj nf kl oa km ni ko ob kp nl oc bi translated">结论</h1><p id="c46b" class="pw-post-body-paragraph lt lu it lv b lw nm kd ly lz nn kg mb mc no me mf mg np mi mj mk nq mm mn ls im bi translated"><em class="mo">逻辑回归是最简单的机器学习模型之一。它们容易理解，可解释，并且能给出相当好的结果。每一个使用逻辑回归的从业者都必须知道对数概率，这是这种学习算法背后的主要概念。考虑到业务需求和关于模型如何在模型中使用不同独立变量的解释，逻辑回归非常容易解释。这篇文章旨在提供一种简单的方法来理解回归背后的思想和逻辑回归提供的透明性。</em></p></div><div class="ab cl pb pc hx pd" role="separator"><span class="pe bw bk pf pg ph"/><span class="pe bw bk pf pg ph"/><span class="pe bw bk pf pg"/></div><div class="im in io ip iq"><p id="d454" class="pw-post-body-paragraph lt lu it lv b lw mp kd ly lz mq kg mb mc mr me mf mg ms mi mj mk mt mm mn ls im bi translated">感谢阅读。你可以在这里找到我的其他<a class="ae lh" href="https://towardsdatascience.com/@imsparsh" rel="noopener" target="_blank">机器学习相关的帖子</a>。</p><p id="4c35" class="pw-post-body-paragraph lt lu it lv b lw mp kd ly lz mq kg mb mc mr me mf mg ms mi mj mk mt mm mn ls im bi translated">希望这篇帖子有用。我感谢反馈和建设性的批评。如果你想谈论这篇文章或其他相关话题，你可以在这里或在<a class="ae lh" href="https://www.linkedin.com/in/imsparsh/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>给我发短信。</p><div class="pi pj gp gr pk pl"><a rel="noopener follow" target="_blank" href="/insightful-loan-default-analysis-in-lending-credit-risk-model-b16bbfc94a2f"><div class="pm ab fo"><div class="pn ab po cl cj pp"><h2 class="bd jd gy z fp pq fr fs pr fu fw jc bi translated">贷款信用风险模型中的贷款违约分析</h2><div class="ps l"><h3 class="bd b gy z fp pq fr fs pr fu fw dk translated">探索和分析贷款违约背后的驱动因素，即，使贷款审批流程风险…</h3></div><div class="pt l"><p class="bd b dl z fp pq fr fs pr fu fw dk translated">towardsdatascience.com</p></div></div><div class="pu l"><div class="pv l pw px py pu pz lb pl"/></div></div></a></div></div></div>    
</body>
</html>