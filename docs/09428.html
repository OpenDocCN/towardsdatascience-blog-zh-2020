<html>
<head>
<title>10 Minutes to Building a CNN Binary Image Classifier in TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 10 分钟在 TensorFlow 中构建 CNN 二值图像分类器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/10-minutes-to-building-a-cnn-binary-image-classifier-in-tensorflow-4e216b2034aa?source=collection_archive---------3-----------------------#2020-07-06">https://towardsdatascience.com/10-minutes-to-building-a-cnn-binary-image-classifier-in-tensorflow-4e216b2034aa?source=collection_archive---------3-----------------------#2020-07-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/73fb8336aa779f390689391c783c6685.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*97AYQlupYStkcHSJ"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">照片由<a class="ae jd" href="https://unsplash.com/@karaeads?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Kara Eads </a>在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><div class=""/><div class=""><h2 id="af7b" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">如何在 TensorFlow/Keras 中使用卷积神经网络层构建二值图像分类器</h2></div><p id="981b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这是对计算机视觉的简短介绍，即如何在 TensorFlow/Keras 中使用卷积神经网络层构建二值图像分类器，主要面向新用户。这份简单易懂的教程分为 3 个部分:</p><ol class=""><li id="fdb5" class="lr ls jg kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated">数据</li><li id="4f1b" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">模型架构</li><li id="45a3" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">准确性、ROC 曲线和 AUC</li></ol><p id="e10d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">要求:没事！按照本教程，你所需要的就是这个包含数据和代码的<a class="ae jd" href="https://colab.research.google.com/drive/1nseete5huZlWM7Ak0qL-T75Dbk0mdr-Z?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Google Colab 笔记本</a>。Google Colab 允许您在浏览器中编写和运行 Python 代码，无需任何设置，并且包括免费的 GPU 访问！</p><h1 id="3fde" class="mf mg jg bd mh mi mj mk ml mm mn mo mp km mq kn mr kp ms kq mt ks mu kt mv mw bi translated">1.数据</h1><p id="b5ac" class="pw-post-body-paragraph kv kw jg kx b ky mx kh la lb my kk ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">我们将建立一个蒲公英和草的图像分类器。我已经使用 Google Images 中的图片创建了一个小的图片数据集，您可以在本教程的前 8 个单元格中下载并解析它。</p><p id="70a2" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这 8 行结束时，可视化图像数据集的样本将如下所示:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nc"><img src="../Images/e7a94798816fd3e76c66fefde0f22c84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k79tPkr1PppKp2yuoD-VvA.png"/></div></div></figure><p id="7a89" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">请注意，数据集中的一些图像并不是草地或蒲公英的完美代表。为了简单起见，让我们把它做好，然后继续讨论如何轻松地创建我们的训练和验证数据集。</p><p id="aa0c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们之前获取的数据被分成两个文件夹，<code class="fe nh ni nj nk b">train</code>和<code class="fe nh ni nj nk b">valid</code>。在这些文件夹中，<code class="fe nh ni nj nk b">dandelion</code>和<code class="fe nh ni nj nk b">grass</code>文件夹包含每个班级的图像。为了创建数据集，让我们使用<code class="fe nh ni nj nk b">keras.preprocessing.image.ImageDataGenerator</code>类来创建我们的训练和验证数据集，并规范化我们的数据。这个类所做的是创建一个数据集，并自动为我们做标记，允许我们只用一行就创建一个数据集！</p><h1 id="63f4" class="mf mg jg bd mh mi mj mk ml mm mn mo mp km mq kn mr kp ms kq mt ks mu kt mv mw bi translated">2.模型架构</h1><p id="3363" class="pw-post-body-paragraph kv kw jg kx b ky mx kh la lb my kk ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">在本节开始，我们首先导入 TensorFlow。</p><p id="6590" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们然后添加我们的 CNN 层。我们将首先添加一个卷积 2D 层，有 16 个过滤器，一个 3x3 的内核，输入尺寸为我们的图像尺寸，200x200x3，激活为 ReLU。</p><pre class="nd ne nf ng gt nl nk nm nn aw no bi"><span id="3f54" class="np mg jg nk b gy nq nr l ns nt">tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(200, 200, 3))</span></pre><p id="3b08" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">之后，我们将添加一个最大池层，将图像尺寸减半，因此在这一层之后，输出将是 100x100x3。</p><pre class="nd ne nf ng gt nl nk nm nn aw no bi"><span id="5b6c" class="np mg jg nk b gy nq nr l ns nt">tf.keras.layers.MaxPooling2D(2, 2)</span></pre><p id="c2f2" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将这些层中的 5 层堆叠在一起，随后 CNN 会添加更多的过滤器。</p><p id="5750" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最后，我们将使 CNN 层的输出变平，将其输入到一个全连接层，然后输入到一个 sigmoid 层进行二进制分类。</p><p id="5669" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这是我们建立的模型:</p><pre class="nd ne nf ng gt nl nk nm nn aw no bi"><span id="6663" class="np mg jg nk b gy nq nr l ns nt">model = tf.keras.models.Sequential([</span><span id="4ba8" class="np mg jg nk b gy nu nr l ns nt"># Note the input shape is the desired size of the image 200x200 with 3 bytes color</span><span id="6533" class="np mg jg nk b gy nu nr l ns nt"># This is the first convolution</span><span id="d366" class="np mg jg nk b gy nu nr l ns nt">tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(200, 200, 3)),</span><span id="df6e" class="np mg jg nk b gy nu nr l ns nt">tf.keras.layers.MaxPooling2D(2, 2),</span><span id="2e60" class="np mg jg nk b gy nu nr l ns nt"># The second convolution</span><span id="b28c" class="np mg jg nk b gy nu nr l ns nt">tf.keras.layers.Conv2D(32, (3,3), activation='relu'),</span><span id="60ba" class="np mg jg nk b gy nu nr l ns nt">tf.keras.layers.MaxPooling2D(2,2),</span><span id="d39d" class="np mg jg nk b gy nu nr l ns nt"># The third convolution</span><span id="0b58" class="np mg jg nk b gy nu nr l ns nt">tf.keras.layers.Conv2D(64, (3,3), activation='relu'),</span><span id="02c8" class="np mg jg nk b gy nu nr l ns nt">tf.keras.layers.MaxPooling2D(2,2),</span><span id="a26b" class="np mg jg nk b gy nu nr l ns nt"># The fourth convolution</span><span id="02e4" class="np mg jg nk b gy nu nr l ns nt">tf.keras.layers.Conv2D(64, (3,3), activation='relu'),</span><span id="2cad" class="np mg jg nk b gy nu nr l ns nt">tf.keras.layers.MaxPooling2D(2,2),</span><span id="14de" class="np mg jg nk b gy nu nr l ns nt"># # The fifth convolution</span><span id="25e3" class="np mg jg nk b gy nu nr l ns nt">tf.keras.layers.Conv2D(64, (3,3), activation='relu'),</span><span id="69fd" class="np mg jg nk b gy nu nr l ns nt">tf.keras.layers.MaxPooling2D(2,2),</span><span id="e386" class="np mg jg nk b gy nu nr l ns nt"># Flatten the results to feed into a DNN</span><span id="fc6d" class="np mg jg nk b gy nu nr l ns nt">tf.keras.layers.Flatten(),</span><span id="7d77" class="np mg jg nk b gy nu nr l ns nt"># 512 neuron hidden layer</span><span id="9f8b" class="np mg jg nk b gy nu nr l ns nt">tf.keras.layers.Dense(512, activation='relu'),</span><span id="7681" class="np mg jg nk b gy nu nr l ns nt"># Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('dandelions') and 1 for the other ('grass')</span><span id="5666" class="np mg jg nk b gy nu nr l ns nt">tf.keras.layers.Dense(1, activation='sigmoid')</span></pre><p id="ae5c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们来看看我们构建的模型的摘要:</p><pre class="nd ne nf ng gt nl nk nm nn aw no bi"><span id="2bf7" class="np mg jg nk b gy nq nr l ns nt">Model: "sequential" _________________________________________________________________ Layer (type)                 Output Shape              Param #    ================================================================= conv2d (Conv2D)              (None, 198, 198, 16)      448        _________________________________________________________________ max_pooling2d (MaxPooling2D) (None, 99, 99, 16)        0          _________________________________________________________________ conv2d_1 (Conv2D)            (None, 97, 97, 32)        4640       _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 48, 48, 32)        0          _________________________________________________________________ conv2d_2 (Conv2D)            (None, 46, 46, 64)        18496      _________________________________________________________________ max_pooling2d_2 (MaxPooling2 (None, 23, 23, 64)        0          _________________________________________________________________ conv2d_3 (Conv2D)            (None, 21, 21, 64)        36928      _________________________________________________________________ max_pooling2d_3 (MaxPooling2 (None, 10, 10, 64)        0          _________________________________________________________________ conv2d_4 (Conv2D)            (None, 8, 8, 64)          36928      _________________________________________________________________ max_pooling2d_4 (MaxPooling2 (None, 4, 4, 64)          0          _________________________________________________________________ flatten (Flatten)            (None, 1024)              0          _________________________________________________________________ dense (Dense)                (None, 512)               524800     _________________________________________________________________ dense_1 (Dense)              (None, 1)                 513        ================================================================= Total params: 622,753 Trainable params: 622,753 Non-trainable params: 0</span></pre><p id="9e59" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">接下来，我们将配置模型训练的规范。我们将用<code class="fe nh ni nj nk b">binary_crossentropy</code>损失来训练我们的模型。我们将使用<code class="fe nh ni nj nk b">RMSProp</code>优化器。<a class="ae jd" href="https://wikipedia.org/wiki/Stochastic_gradient_descent#RMSProp" rel="noopener ugc nofollow" target="_blank"> RMSProp </a>是一个明智的优化算法，因为它为我们自动化了学习率调整(或者，我们也可以使用<a class="ae jd" href="https://wikipedia.org/wiki/Stochastic_gradient_descent#Adam" rel="noopener ugc nofollow" target="_blank"> Adam </a>或<a class="ae jd" href="https://developers.google.com/machine-learning/glossary/#AdaGrad" rel="noopener ugc nofollow" target="_blank"> Adagrad </a>获得类似的结果)。我们将增加<code class="fe nh ni nj nk b">metrics</code>的准确性，这样模型将在训练过程中监控准确性。</p><pre class="nd ne nf ng gt nl nk nm nn aw no bi"><span id="42b2" class="np mg jg nk b gy nq nr l ns nt">model.compile(loss='binary_crossentropy',</span><span id="ad27" class="np mg jg nk b gy nu nr l ns nt">optimizer=RMSprop(lr=0.001),</span><span id="3720" class="np mg jg nk b gy nu nr l ns nt">metrics='accuracy')</span></pre><p id="6570" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们训练 15 个纪元:</p><pre class="nd ne nf ng gt nl nk nm nn aw no bi"><span id="2328" class="np mg jg nk b gy nq nr l ns nt">history = model.fit(train_generator,</span><span id="b9ca" class="np mg jg nk b gy nu nr l ns nt">steps_per_epoch=8,</span><span id="cb49" class="np mg jg nk b gy nu nr l ns nt">epochs=15,</span><span id="4f19" class="np mg jg nk b gy nu nr l ns nt">verbose=1,</span><span id="47c3" class="np mg jg nk b gy nu nr l ns nt">validation_data = validation_generator,</span><span id="3c0d" class="np mg jg nk b gy nu nr l ns nt">validation_steps=8)</span></pre><h1 id="45e3" class="mf mg jg bd mh mi mj mk ml mm mn mo mp km mq kn mr kp ms kq mt ks mu kt mv mw bi translated">3.准确性、ROC 曲线和 AUC</h1><p id="6585" class="pw-post-body-paragraph kv kw jg kx b ky mx kh la lb my kk ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">让我们评估一下我们模型的准确性:</p><pre class="nd ne nf ng gt nl nk nm nn aw no bi"><span id="b330" class="np mg jg nk b gy nq nr l ns nt">model.evaluate(validation_generator)</span></pre><p id="272b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，让我们计算我们的 ROC 曲线并绘制它。</p><p id="86fa" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">首先，让我们对我们的验证集进行预测。当使用生成器进行预测时，我们必须首先关闭 shuffle(正如我们在创建 validation_generator 时所做的那样)并重置生成器:</p><pre class="nd ne nf ng gt nl nk nm nn aw no bi"><span id="5513" class="np mg jg nk b gy nq nr l ns nt">STEP_SIZE_TEST=validation_generator.n//validation_generator.batch_size</span><span id="cc3f" class="np mg jg nk b gy nu nr l ns nt">validation_generator.reset()</span><span id="a823" class="np mg jg nk b gy nu nr l ns nt">preds = model.predict(validation_generator,</span><span id="2744" class="np mg jg nk b gy nu nr l ns nt">verbose=1)</span></pre><p id="d379" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了创建 ROC 曲线和 AUC，我们需要计算假阳性率和真阳性率:</p><pre class="nd ne nf ng gt nl nk nm nn aw no bi"><span id="f0cb" class="np mg jg nk b gy nq nr l ns nt">fpr, tpr, _ = roc_curve(validation_generator.classes, preds)</span><span id="f9a8" class="np mg jg nk b gy nu nr l ns nt">roc_auc = auc(fpr, tpr)</span><span id="343f" class="np mg jg nk b gy nu nr l ns nt">plt.figure()</span><span id="dbdc" class="np mg jg nk b gy nu nr l ns nt">lw = 2</span><span id="7515" class="np mg jg nk b gy nu nr l ns nt">plt.plot(fpr, tpr, color='darkorange',</span><span id="27b4" class="np mg jg nk b gy nu nr l ns nt">lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)</span><span id="5421" class="np mg jg nk b gy nu nr l ns nt">plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')</span><span id="1f82" class="np mg jg nk b gy nu nr l ns nt">plt.xlim([0.0, 1.0])</span><span id="75aa" class="np mg jg nk b gy nu nr l ns nt">plt.ylim([0.0, 1.05])</span><span id="5f84" class="np mg jg nk b gy nu nr l ns nt">plt.xlabel('False Positive Rate')</span><span id="e9f4" class="np mg jg nk b gy nu nr l ns nt">plt.ylabel('True Positive Rate')</span><span id="d25b" class="np mg jg nk b gy nu nr l ns nt">plt.title('Receiver operating characteristic example')</span><span id="6595" class="np mg jg nk b gy nu nr l ns nt">plt.legend(loc="lower right")</span><span id="2383" class="np mg jg nk b gy nu nr l ns nt">plt.show()</span></pre><figure class="nd ne nf ng gt is gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/e44c2b54a76fa0ecd09af97cedcfd22f.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*Q5zfM6BUv888TjV1dkdPtg.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">我们模型的 ROC 曲线</p></figure><p id="d423" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">ROC 曲线是绘制真阳性率(TPR)对假阳性率(FPR)的概率曲线。</p><p id="d2ce" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">类似地，AUC(曲线下面积)如上面的图例所示，测量我们的模型在多大程度上能够区分我们的两个类别，蒲公英和草。它还用于比较不同的模型，我将在未来的教程中介绍如何使用全连接层构建图像分类器，以及如何使用 ResNet 进行迁移学习。</p><p id="6105" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最后，在笔记本的最后，你将有机会对你自己的图像进行预测！</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/cdc4ae564f0b8c8f8501e250b0ee2835.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*RSjs8YwQGs7qU7YcwUGxzg.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">你现在可以在你自己的图像上做预测</p></figure><p id="affa" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我希望这给你一个温和的介绍，建立一个简单的使用 CNN 层的二值图像分类器。如果你对类似的简单易懂的教程感兴趣，请看看我的其他故事！</p></div></div>    
</body>
</html>