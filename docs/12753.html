<html>
<head>
<title>5 Derivatives to Excel in Your Machine Learning Interview</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在你的机器学习面试中脱颖而出的 5 个衍生物</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/5-derivatives-to-excel-in-your-machine-learning-interview-25601c3ba9fc?source=collection_archive---------6-----------------------#2020-09-02">https://towardsdatascience.com/5-derivatives-to-excel-in-your-machine-learning-interview-25601c3ba9fc?source=collection_archive---------6-----------------------#2020-09-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="fb7c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">机器学习背后的微积分:回顾导数，梯度，雅可比和海森</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6393753eb0ed88544f443ee0b8669fc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LLv7maGgPx69NMvE_EDCvw.jpeg"/></div></div></figure><p id="b846" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">就业市场对机器学习工程师及其对数学的深刻理解存在整体怀疑。事实是，所有机器学习算法本质上都是数学框架——支持向量机被表述为对偶优化问题，主成分分析被表述为光谱分解滤波，或者神经网络被表述为连续非线性函数的组合——只有彻底的数学理解才能让你真正掌握它们。</p><p id="399c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">各种 Python 库有助于将高级算法用于简单的步骤，<em class="lq">例如，</em> Scikit-learn 库包含 KNN、K-means、决策树等。，或 Keras，让您无需了解 CNN 或 rnn 背后的细节就可以构建神经网络架构。然而，成为一名优秀的机器学习工程师需要的远不止这些，这些职位的面试通常会包括一些问题，例如，从零开始实现 KNN 或决策树，或者推导线性回归或 softmax 反向传播方程的矩阵闭式解。</p><p id="b8cc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这篇文章中，我们将回顾微积分的一些基本概念，例如一维和多维函数的导数，包括<strong class="kw iu">梯度、</strong>T4】雅可比和海森，让你开始准备面试，同时帮助你建立一个良好的基础，成功地深入探索机器学习背后的数学，特别是神经网络。</p><p id="9b98" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这些概念将用 5 个衍生产品的例子来说明，这些例子是你面试时绝对应该随身携带的:</p><ol class=""><li id="1782" class="lr ls it kw b kx ky la lb ld lt lh lu ll lv lp lw lx ly lz bi translated">复合指数函数的导数— <strong class="kw iu"> </strong> <em class="lq"> f(x)= eˣ </em></li><li id="2f3a" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">变基变指数函数的导数— <em class="lq"> f(x)= xˣ </em></li><li id="871b" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">多维输入函数的梯度— <em class="lq"> f(x，y，z) = 2ˣʸ+zcos(x) </em></li><li id="680d" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">多维函数的雅可比矩阵— <em class="lq"> f(x，y) = [2x，x √y] </em></li><li id="0e8b" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">多维输入函数的 hessian—<em class="lq">f(x，y) = x y </em></li></ol><h1 id="9d59" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">导数 1:复合指数函数</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/60be7eb9e18210887bdbc50053e2d650.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/0*d7j9q7TT0bSrwu_j.png"/></div></figure><p id="b1df" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">指数函数是一个非常基础、常见和有用的例子。它是一个严格的正函数，<em class="lq">即ℝ的 eˣ &gt; 0 </em>，需要记住的一个重要性质是<em class="lq"> e⁰ = 1。</em>另外，你要记住指数是对数函数的倒数。这也是最容易求导的函数之一，因为它的导数就是指数本身，<em class="lq">即(eˣ)' = eˣ.)</em>当指数与另一个函数结合时，导数变得更加复杂。在这种情况下，我们使用<strong class="kw iu">链式法则</strong>公式，即<em class="lq"> f(g(x)) </em>的导数等于<em class="lq"> f'(g(x))⋅g'(x) </em>，<em class="lq">即</em>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi my"><img src="../Images/be599dc8f5fd4cf1d6c05d96d7396aa5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VMSM63Vsrn2n90C-Hi3Acg.png"/></div></div></figure><p id="94bd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">应用链式法则，我们可以计算出<em class="lq"> f(x)= eˣ的导数。</em>我们先求出<em class="lq"> g(x)=x 的导数，即 g(x)'=2x。我们还知道，ˣ)'=eˣ.</em>将这些<em class="lq"> </em>相乘得到两个中间结果，我们得到</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/b1ef0b24eda0575cd3c5ff1705ca4950.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3oyOzikhaINGmzTl.png"/></div></div></figure><p id="03f1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是一个非常简单的例子，乍一看似乎微不足道，但它经常被面试官作为热身问题来问。如果你有一段时间没有看到衍生品，确保你能迅速对这些简单的问题做出反应，因为虽然这不会给你这份工作，但在这样一个基本问题上的失败肯定会让你失去这份工作！</p><h1 id="e07f" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">导数 2。变基变指数函数</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/3973bc5477ca8677f79d1266e22784ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/0*wX2tAVpkrW2X95dT.png"/></div></figure><p id="01b2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这个功能在面试中是一个经典，尤其是在金融/量化行业，这里对数学技能的测试甚至比科技公司的机器学习职位更深入。这有时会让受访者脱离他们的舒适区，但实际上，这个问题最难的部分是能够正确地开始。</p><p id="0b0f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">当处理这种指数形式的函数时，要认识到的最重要的事情是，第一，指数和对数之间的反比关系，第二，每个指数函数都可以改写为自然指数函数的形式</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/2563ebf9aaaada6531765cd838b9971b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MNYhhaeGB2dyumVeRGZDmQ.png"/></div></div></figure><p id="29e1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在我们讨论 f(x) = xˣ的例子之前，让我们用一个更简单的函数 f(x) = 2ˣ.来演示这个性质我们首先使用上面的等式将 2 <em class="lq"> ˣ </em>重写为<em class="lq"> exp(xln(2)) </em>，随后应用链式法则来推导合成。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nc"><img src="../Images/302c6f7c926ec4068229fbb5152ad6a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NO3J6QH4jAHu9DXt.png"/></div></div></figure><p id="4f99" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">回到最初的函数<em class="lq"> f(x)=xˣ </em>，一旦你将函数改写为<em class="lq"> f(x)=exp(x ln x) </em>，导数的计算就变得相对简单，唯一可能困难的部分是链式法则步骤。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/23eefea8cc8c0c9acebde7ac1d13a92c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*emLcl97DFZh2Vd88.png"/></div></div></figure><p id="83c4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">注意，这里我们对指数<em class="lq"> xln(x) </em>使用了乘积法则<em class="lq">(uv)’= u’v+uv’</em>。</p><p id="ef33" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这个函数通常在没有任何函数域信息的情况下被调用。如果你的面试官没有默认指定领域，他可能是在测试你的数学敏锐度。这就是问题的欺骗性所在。在不具体说明域的情况下，似乎为正值和负值都定义了<em class="lq"> xˣ </em>。但对于负数<em class="lq"> x </em>，<em class="lq"> e.g.(-0.9)^(-0.9) </em>，结果是一个复数，具体为<em class="lq">-1.05–0.34 I</em>。一种可能的解决方法是将函数的定义域定义为ℤ⁻∪ℝ⁺0(进一步讨论见<a class="ae ne" href="https://math.stackexchange.com/questions/1551470/domain-of-xx" rel="noopener ugc nofollow" target="_blank">这里的</a>)，但是这对于负值仍然是不可微的。因此，为了正确定义<em class="lq"> xˣ </em>的导数，我们需要将定义域限制为严格的正值。我们排除 0 是因为对于定义在 0 中的导数，我们需要左边的极限导数(对于负值限制在 0 中)等于右边的极限导数(对于正值限制在 0 中)，这是一个在这种情况下被打破的条件。自左极限</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nf"><img src="../Images/640b9bd032ef15c8e958e7c2adf2a07f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jmg0_0Xv2CJSeYKpE5ur4w.png"/></div></div></figure><p id="c0ed" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">未定义，函数在 0 中不可微，因此函数的定义域仅限于正值。</p><p id="5460" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在我们进入下一部分之前，我留给你这个函数的一个稍微高级一点的版本来测试你的理解:<em class="lq"> f(x) = xˣ </em>。如果您理解了第一个示例背后的逻辑和步骤，添加额外的指数应该不会造成任何困难，并且您应该得出以下结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/2f3fa1200a190cbf48a273aab348eae8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bmMPjocUc9LL9PO-.png"/></div></div></figure><h1 id="ac7b" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">导数 3:多维输入函数的梯度</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/f16bfcb20b26abc74aa4458cc03b8987.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*87PTv0ygJ47t_1aV.png"/></div></div></figure><p id="2c80" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">到目前为止，一阶和二阶导数部分讨论的函数都是从ℝ到ℝ的映射，<em class="lq">即</em>函数的定义域和值域都是实数。但是机器学习本质上是矢量的，函数是多维的。这种多维性的一个很好的例子是输入大小为<em class="lq"> m </em>和输出大小为<em class="lq"> k 的神经网络层，即 f(x) = g(Wᵀx + b，</em>其中<em class="lq"> </em>是线性映射<em class="lq"> Wᵀx ( </em>具有权重矩阵<em class="lq"> W </em>和输入向量<em class="lq"> x </em>)和非线性映射<em class="lq"> g </em>(激活函数)的元素式组合。在一般情况下，这也可以看作是从ℝᵐ到ℝᵏ.的映射</p><p id="2902" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在<em class="lq"> k=1 的具体情况下，</em>的导数称为<strong class="kw iu">梯度</strong> <em class="lq">。</em>现在让我们计算以下三维函数的导数，该函数将ℝ <em class="lq"> </em>映射到ℝ:<em class="lq"/></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/ba809ebb90796ece491ae987077222cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_81mDqpljbCKGHH3S_oZ1A.png"/></div></div></figure><p id="4772" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你可以把<em class="lq"> f </em>想象成一个把大小为 3 的向量映射到大小为 1 的向量的函数。</p><p id="fac3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">多维输入函数的导数被称为<strong class="kw iu">梯度</strong>，用符号<em class="lq"> nabla </em>(倒置<em class="lq"> delta </em> ): ∇.表示<em class="lq"> </em>将ℝⁿ映射到ℝ的函数<em class="lq"> g </em>的梯度是<em class="lq"> g </em>的一组<em class="lq"> n </em>偏导数，其中每个偏导数是<em class="lq"> n </em>变量的函数。因此，如果 g 是从ℝⁿ到ℝ的映射，那么它的梯度∇g 就是从ℝⁿ到ℝⁿ.的映射</p><p id="1012" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了求我们函数<em class="lq"> f(x，y，z) = 2ˣʸ + zcos(x) </em>的梯度，我们构造了一个偏导数的向量<em class="lq"> ∂f/∂x，</em>∂f/∂y，<em class="lq"> ∂f/∂z </em>，得到如下结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/29d84546e90ff9813195f96ea0fbbb8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FYdpwnSz77hpx7uH.png"/></div></div></figure><p id="0f82" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">注意，这是一个类似于前一节的例子，我们使用等价关系<em class="lq"> 2ˣʸ=exp(xy ln(2))。</em></p><p id="6b97" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">总之，对于将ℝ <em class="lq"> </em>映射到ℝ<em class="lq"/>的多维函数，导数是将ℝ映射到ℝ的梯度<em class="lq"> ∇ f，</em>。</p><p id="d50e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在ℝᵐ到ℝᵏ的映射的一般形式中，其中将ℝᵐ映射到ℝᵏ的多维函数的导数是雅可比矩阵(而不是梯度向量)。让我们在下一节对此进行研究。</p><h1 id="36bb" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">导数 4。多维输入输出函数的雅可比矩阵</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/aba2fb5b283e914ffb1d93b1f6373d56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*TYW5sNA9byu2pUfU.png"/></div></div></figure><p id="cb68" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">从上一节我们知道，映射ℝᵐ到ℝ的函数的导数是映射ℝᵐ到ℝᵐ.的梯度但是对于输出域也是多维的情况，<em class="lq">即</em>对于<em class="lq"> k &gt; 1 </em>从ℝᵐ到ℝᵏ的映射呢？</p><p id="b129" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这种情况下，导数称为<strong class="kw iu">雅可比矩阵</strong>。我们可以简单地将梯度视为雅可比矩阵的一种特殊情况，其维数为<em class="lq"> m </em> x <em class="lq"> 1 </em>，其中<em class="lq"> m </em>等于变量的数量。函数<em class="lq"> g </em>映射ℝᵐ到ℝᵏ的雅可比矩阵<em class="lq"> J(g) </em>就是ℝᵐ到ℝᵏ*ᵐ.的映射这意味着输出域的尺寸为<em class="lq"> k </em> x <em class="lq"> m </em>，<em class="lq">即</em>是一个形状为<em class="lq"> k </em> x <em class="lq"> m </em>的矩阵。换句话说，<em class="lq"> J(g) </em>的每一行<em class="lq"> i </em>代表<em class="lq"> g. </em>的每个子功能<em class="lq"> gᵢ </em>的梯度<em class="lq"> ∇ gᵢ </em></p><p id="cd41" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们推导上面定义的函数<em class="lq"> f(x，y) = [2x，x √y] </em>映射<em class="lq"> </em> ℝ到ℝ，因此输入和输出域都是多维的。在这种特殊情况下，由于平方根函数不是为负值定义的，我们需要将<em class="lq"> y </em>的域限制在ℝ⁺.我们的输出雅可比矩阵的第一行将是函数 1 的导数，<em class="lq"> i.e.∇ 2x，</em>，第二行是函数 2 的导数，<em class="lq">，即</em> <em class="lq"> ∇ x √y. </em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/bec27fcdabf01c45a955a5ef61b92532.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*e8birBpC_t28qa8C.png"/></div></div></figure><p id="b265" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在深度学习中，雅可比矩阵特别令人感兴趣的一个例子是可解释性领域(例如，参见<a class="ae ne" href="https://arxiv.org/abs/1812.01029" rel="noopener ugc nofollow" target="_blank">基于敏感性的神经网络解释</a>)，该领域旨在理解神经网络的行为，并分析神经网络输出层对输入的敏感性。雅可比矩阵有助于研究输入空间的变化对输出的影响。这可以类似地应用于理解神经网络中中间层的概念。</p><p id="379f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">总之，记住梯度是一个<em class="lq">标量</em>相对于一个<em class="lq">向量</em>的导数，雅可比是一个<em class="lq">向量</em>相对于另一个<em class="lq">向量</em>的导数。</p><h1 id="caaf" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">导数 5。多维输入函数的 Hessian</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/a1673a225a5aaaaf605eb102b5bdb615.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/0*5zHo6cXPgd3Dengj.png"/></div></figure><p id="a0dc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">到目前为止，我们的讨论只集中在一阶导数上，但是在神经网络中我们经常会谈到多维函数的高阶导数。一个特殊情况是二阶导数，也称为<strong class="kw iu">海森矩阵</strong>，并表示为<em class="lq"> H(f) </em>或<em class="lq"> ∇(纳布拉平方)。从ℝⁿ到ℝ的映射是从ℝⁿ到ℝⁿ*ⁿ.的映射</em></p><p id="6290" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们分析一下，在输出领域，我们是如何从ℝ走向ℝⁿ*ⁿ的。一阶导数，<em class="lq">即</em>梯度<em class="lq"> ∇g，</em>是从ℝⁿ到ℝⁿ的映射，其导数是雅可比矩阵。因此，每个子函数<em class="lq"> ∇gᵢ </em>的推导导致ℝⁿ到ℝⁿ的映射，具有<em class="lq"> n 个</em>这样的函数。你可以这样想，就好像导出梯度向量的每个元素展开成一个向量，从而成为向量的向量，<em class="lq">即</em>一个矩阵。</p><p id="3673" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了计算 Hessian，我们需要计算所谓的<em class="lq">交叉导数，t </em>也就是，首先相对于<em class="lq"> x </em>求导，然后相对于<em class="lq"> y </em>求导，反之亦然。有人可能会问，我们取交叉导数的顺序是否重要；换句话说，海森矩阵是否对称。在函数<em class="lq"> f </em>是𝒞的情况下，<em class="lq">即</em>两次连续可微，<em class="lq">施瓦兹定理</em>陈述交叉导数相等，因此海森矩阵是对称的。一些不连续但可微的函数不满足交叉导数相等。</p><p id="8c34" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">构造函数的 Hessian 等价于求标量值函数的二阶偏导数。对于特定示例<em class="lq"> f(x，y) = x y </em>，计算产生以下结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/3599f3f46a25cacf9fee4911e266b6b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tmagpwbvPmFfm65D.png"/></div></div></figure><p id="a0e9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你可以看到交叉导数<em class="lq"> 6xy </em>实际上是相等的。我们首先针对<em class="lq"> x </em>进行推导，得到<em class="lq"> 2xy、</em>，然后再针对<em class="lq"> y、</em>得到<em class="lq"> 6xy。</em>对角元素是简单的<em class="lq">fᵢ</em>，用于<em class="lq">x</em>或<em class="lq">y</em>的每个一维子功能</p><p id="d973" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">一个扩展将是讨论多维函数的二阶导数将ℝᵐ映射到ℝᵏ的情况，这可以直观地视为二阶雅可比。这是从ℝᵐ到ℝᵏ*ᵐ*ᵐ的映射，<em class="lq">即</em>一个 3D 张量。类似于 Hessian，为了找到 Jacobian 的梯度(第二次微分)，我们对<em class="lq"> k </em> x <em class="lq"> m </em>矩阵的每个元素进行微分，得到一个向量矩阵，<em class="lq">即</em>一个张量。虽然不太可能要求您手动进行此类计算，但了解多维函数的高阶导数非常重要。</p><h1 id="1535" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">结论</h1><p id="962b" class="pw-post-body-paragraph ku kv it kw b kx no ju kz la np jx lc ld nq lf lg lh nr lj lk ll ns ln lo lp im bi translated">在本文中，我们回顾了机器学习背后的重要微积分基础。我们用一维和多维函数的例子演示了它们，讨论了梯度、雅可比和海森。这篇综述是对可能的面试概念的彻底演练，也是对机器学习背后的微积分相关知识的概述。</p></div></div>    
</body>
</html>