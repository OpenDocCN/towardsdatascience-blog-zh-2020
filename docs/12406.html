<html>
<head>
<title>Got data? How I taught myself how to scrape websites in a few hours (and you can, too)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">有数据吗？我如何在几个小时内自学如何浏览网站(你也可以)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/got-data-how-i-taught-myself-how-to-scrape-websites-in-a-few-hours-and-you-can-too-2fe19889d6b0?source=collection_archive---------26-----------------------#2020-08-26">https://towardsdatascience.com/got-data-how-i-taught-myself-how-to-scrape-websites-in-a-few-hours-and-you-can-too-2fe19889d6b0?source=collection_archive---------26-----------------------#2020-08-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="89c2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">找不到任何有趣的、高质量的数据集？生成你自己的数据集出奇的容易——下面是方法(包括<a class="ae ki" href="https://github.com/databyjp/beginner_scraping" rel="noopener ugc nofollow" target="_blank">代码</a>)。</h2></div><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi kj"><img src="../Images/14ef49b4287e2686206c8bccb4b79719.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j97LYz8zdbgHkurb-oYNCg.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">从网站到数据和信息:网站:<a class="ae ki" href="https://scrapethissite.com/pages/" rel="noopener ugc nofollow" target="_blank">抓取本网站</a></p></figure><p id="8210" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我有一个可耻的秘密。它影响了数据科学社区中数量惊人的人。我懒得面对这个问题，也懒得正面解决它。</p><p id="45e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我不知道如何收集数据。</p><p id="dd59" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">大多数时候，这并没有影响我的生活——我可以访问数据集，或者其他人已经为我的需要开发了定制的抓取器/API。</p><p id="523a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但我偶尔会浏览一个网站，希望我能获得一些有趣的原始数据来做一些严肃的分析。</p><p id="9040" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">嗯，不会再有了。</p><p id="26ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最近，我自学了如何用 Python 结合使用<a class="ae ki" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank"> BeautifulSoup </a>、<a class="ae ki" href="https://requests.readthedocs.io/en/master/" rel="noopener ugc nofollow" target="_blank"> requests </a>和<a class="ae ki" href="https://docs.python.org/3/library/re.html" rel="noopener ugc nofollow" target="_blank">正则表达式</a>来抓取网站。</p><blockquote class="lv"><p id="d211" class="lw lx it bd ly lz ma mb mc md me lu dk translated">我有一个可耻的秘密…我不知道如何收集数据。</p></blockquote><p id="cc9c" class="pw-post-body-paragraph kz la it lb b lc mf ju le lf mg jx lh li mh lk ll lm mi lo lp lq mj ls lt lu im bi translated">整个过程比我想象的要简单得多，因此我能够制作自己的数据集。</p><p id="129f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以在这里，我想分享我的经验，这样你也可以自己做。与我的其他文章一样，我在这里的<a class="ae ki" href="https://github.com/databyjp/beginner_scraping" rel="noopener ugc nofollow" target="_blank"> git repo 中包含了完整的代码</a>，因此您可以按照自己的目的使用或修改代码。</p><h1 id="3484" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">在开始之前</h1><h2 id="dfb0" class="nc ml it bd mm nd ne dn mq nf ng dp mu li nh ni mw lm nj nk my lq nl nm na nn bi translated">包装</h2><p id="3562" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">我假设您熟悉 python。即使你相对较新，这个教程也不应该太难。</p><p id="adf1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你需要<code class="fe nt nu nv nw b">BeautifulSoup</code>、<code class="fe nt nu nv nw b">requests</code>和<code class="fe nt nu nv nw b">pandas</code>。用<code class="fe nt nu nv nw b">pip install [PACKAGE_NAME]</code>安装每个(在您的虚拟环境中)。</p><p id="0689" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在这里找到我的代码:<a class="ae ki" href="https://github.com/databyjp/beginner_scraping" rel="noopener ugc nofollow" target="_blank">https://github.com/databyjp/beginner_scraping</a></p><h1 id="5e0d" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">让我们制作一个数据集</h1><p id="5c80" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">一旦我们学会了如何收集数据，这种技能几乎可以应用于任何网站。但重要的是要把基本面搞对；所以让我们从容易的地方开始，同时反映现实世界。</p><p id="24c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你们很多人都知道我是一个体育迷——所以让我们从搜集我们的数字数据开始吧，这些数据将从<a class="ae ki" href="https://scrapethissite.com/faq/" rel="noopener ugc nofollow" target="_blank">ScrapeThisSite.com</a>那里获得。</p><p id="8162" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">顾名思义，这个网站是用来练习刮痧的。假设数据在表中，也很容易检查数据是否被正确抓取。</p><h2 id="64ef" class="nc ml it bd mm nd ne dn mq nf ng dp mu li nh ni mw lm nj nk my lq nl nm na nn bi translated">获取原始数据</h2><p id="4fd1" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">在我们做任何事情之前，我们需要原始数据。这就是<code class="fe nt nu nv nw b">requests</code>库的用武之地。获取数据很简单，只需如下代码行:</p><pre class="kk kl km kn gt nx nw ny nz aw oa bi"><span id="8314" class="nc ml it nw b gy ob oc l od oe"><em class="of">import </em>requests<br/>page = requests.get("https://scrapethissite.com/pages/forms/")</span></pre><p id="ce2e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">获得网页的副本是如此容易。要检查页面是否已正确加载，请尝试:</p><pre class="kk kl km kn gt nx nw ny nz aw oa bi"><span id="d34c" class="nc ml it nw b gy ob oc l od oe"><em class="of">assert </em>page.status_code == 200</span></pre><p id="080f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你没有得到一个错误，这应该意味着该页面已被正确下载。那有多好？现在到了肉的问题；从我们的页面获取数据。</p><h2 id="6d96" class="nc ml it bd mm nd ne dn mq nf ng dp mu li nh ni mw lm nj nk my lq nl nm na nn bi translated">进入你的元素</h2><p id="2000" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">要抓取一个网站，我们需要确定网站的哪一部分包含了我们想要的信息。尽管这在视觉上很容易，但在代码中却很难做到。</p><p id="6de7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这项任务中，您最好的朋友是浏览器上的“检查元素”按钮。有不同的方法来处理要抓取的元素，但这是次要的。首先，您需要识别被抓取的数据。</p><p id="f64d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，让我们说，我想刮这一页。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi og"><img src="../Images/91998442eaf189b6835602f2a5f570b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IO5PLlO_e0s-5BkVhY6Kgg.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">我们的第一桌给刮了(<a class="ae ki" href="https://scrapethissite.com/pages/forms/" rel="noopener ugc nofollow" target="_blank">https://scrapethissite.com/pages/forms/</a>)</p></figure><p id="2059" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们继续之前，先看一下底层代码。这是它的一个小样本。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oh"><img src="../Images/f419f9d5ae2d8325158bd38490272899.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dMvh2ROmp5e4M6M8wQkTgQ.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">页面的源代码</p></figure><p id="d21c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">鉴于它是为学习刮擦的人设计的，阅读起来并不困难。尽管如此，将你在这里看到的与你所看到的渲染关联起来还是很痛苦。</p><p id="0c1f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您应该做的是突出显示页面上的相关元素，右键单击并选择“检查元素”。这将显示一个类似于下图的布局，尽管会因浏览器而异。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oi"><img src="../Images/6c312cd4fa86aedb3e14422073f4e67f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LK3u01DKABTTjZqHL6-8ew.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">“检查元素”按钮—您的新好朋友</p></figure><p id="feab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将要调出的代码是<a class="ae ki" href="https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model/Introduction" rel="noopener ugc nofollow" target="_blank"> DOM(文档对象模型)</a>。不用太专业，这允许代码与呈现的最终结果相匹配。</p><p id="fffd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我强烈推荐滚动浏览这里的各种元素，选择它们，并大致观察 DOM 的结构。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oi"><img src="../Images/07a0410c6ddc94a8ac9942acce639265.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Qc_ImmSH4VgCPTYLqnfvw.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">探索你的王国</p></figure><p id="f2a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">更具体地说，让我们看看我们将做什么来刮出显示如下会议排名的表。</p><h2 id="3d20" class="nc ml it bd mm nd ne dn mq nf ng dp mu li nh ni mw lm nj nk my lq nl nm na nn bi translated">小步前进——收集一份数据</h2><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oi"><img src="../Images/df2c6881cacebe9572df53292fdd0bbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nuqQ5n9JLOaYmOR_lwGqvg.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">使用“检查元素”按钮</p></figure><p id="cec1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对元素的检查表明，我们希望获得该表的内容。尽管它没有唯一的 id，但它确实驻留在一个具有<code class="fe nt nu nv nw b">id</code>值<code class="fe nt nu nv nw b">hockey</code>的<code class="fe nt nu nv nw b">section</code>中。</p><p id="095f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">BeautifulSoup 发现所有这些都很容易，参数<code class="fe nt nu nv nw b">id</code>可以被传递(html 中的<code class="fe nt nu nv nw b">id</code>值是唯一的)，或者只是标签的一个默认参数。</p><p id="e1c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以通过以下方式找到所有这些:</p><pre class="kk kl km kn gt nx nw ny nz aw oa bi"><span id="53e5" class="nc ml it nw b gy ob oc l od oe">div = soup.find(id="hockey")  # Find the right div<br/>table = div.find("table")</span></pre><p id="8970" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以通过运行以下命令来验证该 div 中只有一个表:</p><pre class="kk kl km kn gt nx nw ny nz aw oa bi"><span id="19f1" class="nc ml it nw b gy ob oc l od oe">assert len(soup.find_all("table")) == 1</span></pre><p id="0de4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们注意到该表包括标题行<code class="fe nt nu nv nw b">&lt;th&gt;</code>和数据行<code class="fe nt nu nv nw b">&lt;tr&gt;</code>。让我们只抓取这些行——我们还注意到这里的每个数据行都有一个值为<code class="fe nt nu nv nw b">team</code>的<code class="fe nt nu nv nw b">class</code>属性，所以让我们也按照这个属性进行过滤。这可以通过将它们作为字典传递来实现，允许我们根据人们定义的任何自定义属性进行过滤！</p><pre class="kk kl km kn gt nx nw ny nz aw oa bi"><span id="37bd" class="nc ml it nw b gy ob oc l od oe">team_elm = table.find("tr", attrs={"class": "team"})</span></pre><p id="a91c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">收集的元素如下所示:</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="6e39" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们想从这些乱七八糟的东西中提取出球队的名字呢？</p><p id="c460" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我看到 name 列由它的<code class="fe nt nu nv nw b">class</code>属性标记，所以我可以通过它的标签(<code class="fe nt nu nv nw b">td</code>)和属性找到该列。</p><pre class="kk kl km kn gt nx nw ny nz aw oa bi"><span id="7ce7" class="nc ml it nw b gy ob oc l od oe">team_name = team_elm.find("td", attrs={"class": "name"}).text</span></pre><p id="bb1d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是由于结果包含大量空白:</p><pre class="kk kl km kn gt nx nw ny nz aw oa bi"><span id="606b" class="nc ml it nw b gy ob oc l od oe">&gt;&gt;&gt; team_name<br/>'\n                            Boston Bruins\n                        '</span></pre><p id="fd07" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是正则表达式的工作！</p><pre class="kk kl km kn gt nx nw ny nz aw oa bi"><span id="d63f" class="nc ml it nw b gy ob oc l od oe">team_name = re.sub(r"^\s+|\s+$", "", team_name)</span></pre><p id="5063" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你不确定这是怎么回事，那么<a class="ae ki" href="https://docs.python.org/3/library/re.html" rel="noopener ugc nofollow" target="_blank">正则表达式</a>将字符串的开头<code class="fe nt nu nv nw b">^</code>空格<code class="fe nt nu nv nw b">\s+</code>或字符串的结尾<code class="fe nt nu nv nw b">|</code>空格不替换任何内容。如果可能会超过多行，您可以添加一个<code class="fe nt nu nv nw b">re.M</code>标志。</p><p id="826d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">太棒了。现在，我们如何扩展它来收集整个表呢？</p><h2 id="ca08" class="nc ml it bd mm nd ne dn mq nf ng dp mu li nh ni mw lm nj nk my lq nl nm na nn bi translated">变得舒适—抓取整个数据表</h2><p id="85dd" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">为此，我们将像以前一样识别表，隔离每一行数据，然后遍历该行以收集数据元素。</p><p id="c2ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在查看元素时(参见下面的屏幕显示)，我注意到每一列都有一个带有不同<code class="fe nt nu nv nw b">data-stat</code>属性的<code class="fe nt nu nv nw b">&lt;td&gt;</code>标记，例如“wins”、“loss”、“win_loss_pct”等。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oi"><img src="../Images/bf0db3de601ed7462486582a9ba3c638.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tFHN912wDCK-h9nZ6GvKFQ.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">调查每个要刮除的列</p></figure><p id="1c48" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以对它们进行硬编码，并手动遍历它们。但是，更有趣的方法是实际获取一行，并生成这些列属性的列表，如下所示。</p><pre class="kk kl km kn gt nx nw ny nz aw oa bi"><span id="d66d" class="nc ml it nw b gy ob oc l od oe">stat_keys = [col.attrs["class"][0] for col in data_rows[0].find_all("td")]</span></pre><p id="c99d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这为我们提供了一个值列表:</p><pre class="kk kl km kn gt nx nw ny nz aw oa bi"><span id="fe8c" class="nc ml it nw b gy ob oc l od oe">['name', 'year', 'wins', 'losses', 'ot-losses', 'pct', 'gf', 'ga', 'diff']</span></pre><p id="ca6f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用这个代码片段，我们只需编写几行代码来执行获取数据的任务。在较高层次上，代码循环遍历行，确保该行不是标题行，循环遍历列，将数据收集到一个字典中，并将其整理到一个列表中。</p><p id="47c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">整个结果数据然后被放入熊猫数据框架。</p><p id="6e49" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这应该是相对清楚的，但如果这没有什么意义，那也没关系。相反，看看下面的代码。实际代码非常简洁，几乎比我的描述还要短！</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="oj ok l"/></div></figure><h2 id="5105" class="nc ml it bd mm nd ne dn mq nf ng dp mu li nh ni mw lm nj nk my lq nl nm na nn bi translated">重复该任务—抓取多个页面</h2><p id="9d50" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">让我们通过从多个页面抓取数据来总结这一点。你可能已经注意到了底部各个页面的链接。</p><p id="f444" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">再一次，看看这个元素——根据我们的发现，我们可以决定我们的策略。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oi"><img src="../Images/45a924a3572f6ec0a7b4a545700c0df4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bcrVYbYG-U4dfqIbwTVGEg.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">检查底部分页栏</p></figure><p id="76ed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以用多种方法中的一种来处理这个问题，但是这一次，我们将抓取这里的每个链接，然后抓取每个结果页面。</p><p id="b921" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我选择的方法是用 class 属性值为<code class="fe nt nu nv nw b">pagination</code>的<code class="fe nt nu nv nw b">ul</code>标记元素。然后，我找到每个<code class="fe nt nu nv nw b">li</code>元素，获取 href 目标(即链接)，然后通过一个集合转换它以删除任何重复的内容。</p><pre class="kk kl km kn gt nx nw ny nz aw oa bi"><span id="8972" class="nc ml it nw b gy ob oc l od oe">pagination = soup.find("ul", attrs={"class": "pagination"})<br/>link_elms = pagination.find_all("li")<br/>links = [link_elm.find("a").attrs["href"] for link_elm in link_elms]<br/>links = list(set(links))</span></pre><p id="2923" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">直截了当，不是吗？</p><p id="5c3f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在需要做的就是创建一个函数来概括我们抓取上面页面的任务，并连接每个页面返回的结果。</p><pre class="kk kl km kn gt nx nw ny nz aw oa bi"><span id="5dc8" class="nc ml it nw b gy ob oc l od oe">temp_dfs = list()<br/>for link in links:<br/>    tmp_df = scrape_this(uri=link)<br/>    temp_dfs.append(tmp_df)<br/>hockey_team_df = pd.concat(temp_dfs, axis=0).reset_index(drop=True)</span></pre><p id="0770" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了更好地衡量，我们可以对结果进行排序，并将它们保存为一个文件:</p><pre class="kk kl km kn gt nx nw ny nz aw oa bi"><span id="0f89" class="nc ml it nw b gy ob oc l od oe">hockey_team_df.sort_values(["year", "name"], inplace=True)<br/>hockey_team_df.to_csv("hockey_team_df.csv")</span></pre><p id="cb46" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">综上所述，我们得到:</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="cff0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就是这样！只需几行代码，我们就可以从这个网站上收集几十年的数据来生成我们自己的数据集。</p><p id="514f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">只是为了检查一下，让我们用<a class="ae ki" href="https://github.com/plotly/plotly.py" rel="noopener ugc nofollow" target="_blank">和</a>绘制一些数据，看看胜率和一些不同指标之间的相关性。需要注意的一点是，在操作下载的页面之前，我们需要转换数据帧中的数据类型！</p><p id="903a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为什么？嗯，你可能已经知道了——或多或少所有的网站数据都是以文本形式呈现的。文本，即使是数字，也不能被操纵。因此，举例来说，需要对成功进行操作，以便:</p><pre class="kk kl km kn gt nx nw ny nz aw oa bi"><span id="4856" class="nc ml it nw b gy ob oc l od oe">hockey_team_df.wins = hockey_team_df.wins.astype(int)</span></pre><p id="4f54" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一些可视化库会在内部进行这种转换，但是如果你在 pandas 中操作数据，你肯定需要这样做。</p><p id="5f90" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">(这里我不会展示完整的代码，但它在我的<a class="ae ki" href="https://github.com/databyjp/beginner_scraping" rel="noopener ugc nofollow" target="_blank">GitHub repo</a>—<code class="fe nt nu nv nw b">scraper_mult_pages.py</code>文件中。)</p><p id="5a8e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是一张图表，对比了本赛季的胜率和进球数:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ol"><img src="../Images/906203a981f66bedd8de389e7e2f03a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F6ruESPy6avuFP2foAvSsg.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">关联得分目标与获胜百分比</p></figure><p id="2970" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这并不可怕，但看起来没有那么大的相关性。允许进球(对手进球)呢？</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi om"><img src="../Images/03f3600ba50ecb374c1580569ab7dc0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cXRvn-3I83a6hsjZRPDHAQ.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">关联允许的目标与成功百分比</p></figure><p id="674c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">那更好！也许防守确实能赢得冠军/比赛。我们可以将这两者结合起来看目标差异:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi on"><img src="../Images/828deef2f0a57edd5fc410c8b23e5255.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2UYNBdiXZKON0DAvbRnWHQ.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">将目标差异与成功百分比相关联</p></figure><p id="24c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">哇哦。如果我自己这么说，这有什么关系。</p><p id="1c4d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这不是很棒吗？嗯，我觉得是。你可能对这些<em class="of">特定的</em>数据不感兴趣，但关键是——你现在也拥有了所有你需要的工具来获取你感兴趣的数据。</p><p id="7b9e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望那是有用的。我很高兴我费心去学习如何做到这一点。</p><p id="db93" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当你认真对待它的时候，你会发现还有很多事情要做——使用像<a class="ae ki" href="https://github.com/SeleniumHQ/selenium" rel="noopener ugc nofollow" target="_blank"> selenium </a>这样的包对某些网站来说可能是必要的，而像<a class="ae ki" href="https://github.com/scrapy/scrapy" rel="noopener ugc nofollow" target="_blank"> scrapy </a>这样功能更全面的框架可能会为你的大项目节省时间。但是通过采用这些技术，我们已经可以做很多事情了。</p><p id="c3f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">来吧——试试看！</p><p id="26f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有一点要注意:我用过的这个网站明确允许抓取，但不是每个人都允许。网络抓取一直是一个有点争议的话题，最近的一个案例甚至上了法庭。一如既往，明智并尊重他人的网站和潜在的知识产权。</p><p id="54c8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在这里了解更多:<a class="ae ki" href="https://www.scraperapi.com/blog/is-web-scraping-legal/" rel="noopener ugc nofollow" target="_blank">https://www.scraperapi.com/blog/is-web-scraping-legal/</a></p></div><div class="ab cl oo op hx oq" role="separator"><span class="or bw bk os ot ou"/><span class="or bw bk os ot ou"/><span class="or bw bk os ot"/></div><div class="im in io ip iq"><p id="e679" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是在你离开之前——如果你喜欢这个，请在 twitte 上打个招呼/关注，或者关注这里的更新。ICYMI:我也写过这篇关于可视化隐藏信息的文章，以 NBA 助攻数据为例:</p><div class="ov ow gp gr ox oy"><a rel="noopener follow" target="_blank" href="/how-to-visualize-hidden-relationships-in-data-with-python-analysing-nba-assists-e480de59db50"><div class="oz ab fo"><div class="pa ab pb cl cj pc"><h2 class="bd iu gy z fp pd fr fs pe fu fw is bi translated">如何用 Python 可视化数据中的隐藏关系 NBA 助攻分析</h2><div class="pf l"><h3 class="bd b gy z fp pd fr fs pe fu fw dk translated">使用交互式快照、气泡图和桑基图操纵和可视化数据，使用 Plotly(代码和数据…</h3></div><div class="pg l"><p class="bd b dl z fp pd fr fs pe fu fw dk translated">towardsdatascience.com</p></div></div><div class="ph l"><div class="pi l pj pk pl ph pm kt oy"/></div></div></a></div><p id="5c81" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最近，这个展示了我在互联网上发现的一些令人惊叹的数据科学投资组合。</p><div class="ov ow gp gr ox oy"><a rel="noopener follow" target="_blank" href="/these-data-science-portfolios-will-awe-and-inspire-you-mid-2020-edition-728e1021f60"><div class="oz ab fo"><div class="pa ab pb cl cj pc"><h2 class="bd iu gy z fp pd fr fs pe fu fw is bi translated">这些数据科学产品组合将让您惊叹不已并深受启发(2020 年中期版)</h2><div class="pf l"><h3 class="bd b gy z fp pd fr fs pe fu fw dk translated">使用这些来改进您自己的数据科学产品组合，学习新技能或发现新的有趣项目。</h3></div><div class="pg l"><p class="bd b dl z fp pd fr fs pe fu fw dk translated">towardsdatascience.com</p></div></div><div class="ph l"><div class="pn l pj pk pl ph pm kt oy"/></div></div></a></div></div></div>    
</body>
</html>