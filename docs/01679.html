<html>
<head>
<title>Building custom-trained object detection models in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python构建定制的对象检测模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/build-a-custom-trained-object-detection-model-with-5-lines-of-code-713ba7f6c0fb?source=collection_archive---------2-----------------------#2020-02-16">https://towardsdatascience.com/build-a-custom-trained-object-detection-model-with-5-lines-of-code-713ba7f6c0fb?source=collection_archive---------2-----------------------#2020-02-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4b0c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用Detecto简化计算机视觉，Detecto是构建在PyTorch之上的Python包</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/97a6d9cf374915bcd397e8913de4883b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*lEBypTDf_jVLd4jcEBydTA.gif"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">本教程的最终结果！</p></figure><p id="b1ea" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如今，机器学习和计算机视觉都很热门。我们都看过关于自动驾驶汽车和面部识别的新闻，并且可能会想象构建我们自己的计算机视觉模型有多酷。然而，想要打入这个领域并不容易，尤其是没有很强的数学背景。如果您只想尝试一些小东西，像PyTorch和TensorFlow这样的库可能会很难学。</p><p id="f482" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在本教程中，我将向任何人介绍一种简单的方法，只需几行代码就可以构建功能齐全的对象检测模型。更具体地说，我们将使用<a class="ae lq" href="https://github.com/alankbi/detecto" rel="noopener ugc nofollow" target="_blank"> Detecto </a>，这是一个构建在PyTorch之上的Python包，它使这个过程变得简单，并对所有级别的程序员开放。</p><div class="lr ls gp gr lt lu"><a href="https://github.com/alankbi/detecto" rel="noopener  ugc nofollow" target="_blank"><div class="lv ab fo"><div class="lw ab lx cl cj ly"><h2 class="bd iu gy z fp lz fr fs ma fu fw is bi translated">alankbi/detecto</h2><div class="mb l"><h3 class="bd b gy z fp lz fr fs ma fu fw dk translated">Detecto是一个Python包，它允许你用…</h3></div><div class="mc l"><p class="bd b dl z fp lz fr fs ma fu fw dk translated">github.com</p></div></div></div></a></div><h1 id="1224" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated"><strong class="ak">快速简单的例子</strong></h1><p id="1194" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">为了演示使用Detecto有多简单，让我们加载一个预先训练好的模型，并对下图进行推理:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/c74ee5321eb11d5a93f9f7e9a894af95.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*kBY4rJ58qq1m5ZdqRu2tVA.jpeg"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">来源:<a class="ae lq" href="https://en.wikipedia.org/wiki/Apples_and_oranges" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></figure><p id="8805" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">首先，使用pip下载Detecto包:</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="2faf" class="ng me it nc b gy nh ni l nj nk">pip3 install detecto</span></pre><p id="ae89" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然后，将上面的图像保存为“fruit.jpg ”,并在与图像相同的文件夹中创建一个Python文件。在Python文件中，编写以下5行代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="7bdc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">运行此文件后(如果您的计算机上没有支持CUDA的GPU，可能需要几秒钟；稍后将详细介绍)，您应该会看到类似于下图的内容:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi nn"><img src="../Images/589ba1a7834af77913c04eddabbb1d13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X7r74bUJGoAstrTfv839Hw.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">从原始图像中裁剪以获得更好的视觉效果</p></figure><p id="3987" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">厉害！我们只用了5行代码就做到了这一切。以下是我们在每个案例中所做的:</p><ol class=""><li id="b1d4" class="ns nt it kw b kx ky la lb ld nu lh nv ll nw lp nx ny nz oa bi translated">进口探测器模块</li><li id="8981" class="ns nt it kw b kx ob la oc ld od lh oe ll of lp nx ny nz oa bi translated">读入图像</li><li id="c74f" class="ns nt it kw b kx ob la oc ld od lh oe ll of lp nx ny nz oa bi translated">初始化预训练模型</li><li id="40da" class="ns nt it kw b kx ob la oc ld od lh oe ll of lp nx ny nz oa bi translated">在我们的图像上生成了顶部预测</li><li id="745b" class="ns nt it kw b kx ob la oc ld od lh oe ll of lp nx ny nz oa bi translated">绘制了我们的预测</li></ol><p id="9625" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Detecto使用PyTorch的模型动物园中速度更快的R-CNN ResNet-50 FPN ，它能够检测大约80种不同的对象，如动物、车辆、厨房用具等。然而，如果你想检测自定义对象，如可口可乐与百事可乐罐，或斑马与长颈鹿？</p><p id="124c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">您会很高兴地知道，在自定义数据集上训练Detecto模型也同样容易；同样，您所需要的只是5行代码，以及一个现有的数据集或一些花在标记图像上的时间。</p><h1 id="b117" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated"><strong class="ak">构建自定义数据集</strong></h1><p id="f61b" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">在本教程中，我们将从头开始构建自己的数据集。我建议你也这样做，但如果你想跳过这一步，你可以在这里下载一个样本数据集<a class="ae lq" href="https://github.com/alankbi/detecto/blob/master/docs/_static/dog_dataset.zip" rel="noopener ugc nofollow" target="_blank">(修改自斯坦福的</a><a class="ae lq" href="http://vision.stanford.edu/aditya86/ImageNetDogs/main.html" rel="noopener ugc nofollow" target="_blank">狗数据集</a>)。</p><p id="25ed" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">对于我们的数据集，我们将训练我们的模型来检测来自<a class="ae lq" href="https://robonation.org/programs/robosub/" rel="noopener ugc nofollow" target="_blank"> RoboSub </a>比赛的水下外星人、蝙蝠和女巫，如下所示:</p><div class="kj kk kl km gt ab cb"><figure class="og kn oh oi oj ok ol paragraph-image"><img src="../Images/5b93fe1d99cc5ae9d0235435aa2d4b1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/1*2MPpMorMf58wSYAvA9f_ww.png"/></figure><figure class="og kn om oi oj ok ol paragraph-image"><img src="../Images/16facbc07c7019c9d2695b429da420c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:432/format:webp/1*RE_G6aM9JxGtt_QiUc4KRg.png"/><p class="kq kr gj gh gi ks kt bd b be z dk on di oo op translated">外星人、蝙蝠和女巫(从左到右)</p></figure></div><p id="f2fe" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">理想情况下，每个类至少需要100张图片。好的一面是你可以在每张图像中有多个物体，所以如果每张图像包含你想要检测的每一类物体，理论上你可以得到总共100张图像。此外，如果您有视频素材，Detecto可以轻松地将该素材分割成图像，然后用于数据集:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="63fa" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">上面的代码取“video.mp4”中的每第4帧，并将其作为JPEG文件保存在“frames”文件夹中。</p><p id="5c31" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">生成训练数据集后，您应该有一个类似于以下内容的文件夹:</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="bd4e" class="ng me it nc b gy nh ni l nj nk">images/<br/>|   image0.jpg<br/>|   image1.jpg<br/>|   image2.jpg<br/>|   ...</span></pre><p id="8e41" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果您愿意，还可以有第二个包含一组验证图像的文件夹。</p><p id="b771" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在到了耗时的部分:贴标签。Detecto支持PASCAL VOC格式，在这种格式中，XML文件包含图像中每个对象的标签和位置数据。要创建这些XML文件，您可以使用如下的开源工具:</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="f14a" class="ng me it nc b gy nh ni l nj nk">pip3 install labelImg    # Download LabelImg using pip<br/>labelImg                 # Launch the application</span></pre><p id="f8b3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">您现在应该会看到一个弹出窗口。在左侧，单击“打开目录”按钮，并选择要标记的图像文件夹。如果一切正常，您应该会看到类似这样的内容:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi oq"><img src="../Images/cd4ca24f73326cd8b334bc71000a8077.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4GsMFraX0Rw3xfbw_CSIog.png"/></div></div></figure><p id="535e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">要绘制边界框，请点按左侧菜单栏中的图标(或使用键盘快捷键“w”)。然后，您可以在对象周围拖出一个框，并写入/选择一个标签:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi oq"><img src="../Images/221fbd2a5e3963ad72b613be0a8ca31b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*roovFEPxV9ZLP89buw2Eqg.png"/></div></div></figure><p id="7831" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">当您完成标记图像时，使用CTRL+S或CMD+S来保存您的XML文件(为了简单和快速，您可以只使用它们自动填充的默认文件位置和名称)。要标记下一幅图像，请点按“下一幅图像”(或使用键盘快捷键“d”)。</p><p id="005a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">完成整个数据集后，您的文件夹应该如下所示:</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="30bb" class="ng me it nc b gy nh ni l nj nk">images/<br/>|   image0.jpg<br/>|   image0.xml<br/>|   image1.jpg<br/>|   image1.xml<br/>|   ...</span></pre><p id="7d43" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们几乎准备好开始训练我们的对象检测模型了！</p><h1 id="9947" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated"><strong class="ak">访问GPU </strong></h1><p id="0a5f" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">首先，检查你的电脑是否有支持CUDA的GPU 。由于深度学习使用大量的处理能力，在典型的CPU上进行训练可能会非常慢。值得庆幸的是，大多数现代深度学习框架，如PyTorch和Tensorflow，都可以在GPU上运行，从而使事情变得更快。确保您已经下载了PyTorch(如果您安装了Detecto，应该已经有了)，然后运行下面两行代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="cb93" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果打印出来是真的，太好了！你可以跳到下一部分。如果打印错误，不要担心。按照以下步骤创建一个<a class="ae lq" href="https://colab.research.google.com/notebooks/intro.ipynb" rel="noopener ugc nofollow" target="_blank">谷歌合作实验室</a>笔记本，这是一个带有免费可用GPU的在线编码环境。对于本教程，您将只是在Google Drive文件夹中工作，而不是在您的计算机上。</p><ol class=""><li id="9c5d" class="ns nt it kw b kx ky la lb ld nu lh nv ll nw lp nx ny nz oa bi translated">登录<a class="ae lq" href="http://drive.google.com/" rel="noopener ugc nofollow" target="_blank"> Google Drive </a></li><li id="0b00" class="ns nt it kw b kx ob la oc ld od lh oe ll of lp nx ny nz oa bi translated">创建一个名为“检测教程”的文件夹，并导航到这个文件夹</li><li id="b98d" class="ns nt it kw b kx ob la oc ld od lh oe ll of lp nx ny nz oa bi translated">将您的训练图像(和/或验证图像)上传到此文件夹</li><li id="2b41" class="ns nt it kw b kx ob la oc ld od lh oe ll of lp nx ny nz oa bi translated">右键单击，转到“更多”，然后单击“谷歌合作实验室”:</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi or"><img src="../Images/ff4209de0a9505dd607d4effa127d109.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JEfvvA3FjZAIBMdEhTUuiA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">创建您的Google Colab笔记本</p></figure><p id="3365" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">您现在应该会看到这样的界面:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi oq"><img src="../Images/afaeb5058ecc8ebec0358e62f77dcbd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zoUrUuHCtZNaDvf3T6hLpA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">Google Colab笔记本环境。点击了解更多关于环境的信息<a class="ae lq" href="https://colab.research.google.com/notebooks/intro.ipynb" rel="noopener ugc nofollow" target="_blank">。</a></p></figure><p id="226d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">5.给你的笔记本起个名字，然后进入编辑-&gt;笔记本设置-&gt;硬件加速器，选择GPU</p><p id="9fbc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">6.键入以下代码以“挂载”您的驱动器，将目录更改为当前文件夹，并安装Detecto:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="8f37" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了确保一切正常，您可以创建一个新的代码单元并键入<code class="fe os ot ou nc b">!ls</code>来检查您是否在正确的目录中。</p><h1 id="03de" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated"><strong class="ak">训练一个定制模型</strong></h1><p id="a2e3" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">最后，我们现在可以在自定义数据集上训练模型了！正如所承诺的，这是容易的部分。它只需要4行代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="1b4d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们再次分解我们对每行代码所做的工作:</p><ol class=""><li id="6f68" class="ns nt it kw b kx ky la lb ld nu lh nv ll nw lp nx ny nz oa bi translated">进口探测器模块</li><li id="3cf0" class="ns nt it kw b kx ob la oc ld od lh oe ll of lp nx ny nz oa bi translated">从“images”文件夹创建了一个数据集(包含我们的JPEG和XML文件)</li><li id="2865" class="ns nt it kw b kx ob la oc ld od lh oe ll of lp nx ny nz oa bi translated">初始化一个模型来检测我们的自定义对象(外星人、蝙蝠和女巫)</li><li id="f8d7" class="ns nt it kw b kx ob la oc ld od lh oe ll of lp nx ny nz oa bi translated">在数据集上训练我们的模型</li></ol><p id="b689" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">根据数据集的大小，这可能需要10分钟到1个多小时的时间，因此请确保您的程序在完成上述语句后不会立即退出(即，您使用的是Jupyter/Colab笔记本，它在活动时会保留状态)。</p><h1 id="a408" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated"><strong class="ak">使用训练好的模型</strong></h1><p id="1a03" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">现在你有了一个训练好的模型，让我们在一些图像上测试它。要从文件路径中读取图像，可以使用<code class="fe os ot ou nc b">detecto.utils</code>模块中的<code class="fe os ot ou nc b">read_image</code>函数(也可以使用上面创建的<a class="ae lq" href="https://detecto.readthedocs.io/en/latest/api/core.html#detecto.core.Dataset" rel="noopener ugc nofollow" target="_blank">数据集</a>中的图像):</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="ecf5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如您所见，模型的<code class="fe os ot ou nc b">predict</code>方法返回一个由3个元素组成的元组:标签、框和分数。在上面的例子中，模型预测到一个外星人(<code class="fe os ot ou nc b">labels[0]</code>)在坐标【569，204，1003，658】(<code class="fe os ot ou nc b">boxes[0]</code>)处，置信度为0.995 ( <code class="fe os ot ou nc b">scores[0]</code>)。</p><p id="c6b0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">根据这些预测，我们可以使用<code class="fe os ot ou nc b">detecto.visualize</code>模块绘制结果。例如:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="1a34" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">使用您收到的图像和预测运行上面的代码，应该会产生如下所示的结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi ov"><img src="../Images/3d4df33761a3d4b57412aa8cc2fb4c41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P_vrib61htSkGiv-j4S7xw.png"/></div></div></figure><p id="d756" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果您有视频，您可以在其上运行对象检测:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="d2c2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这将接收一个名为“input.mp4”的视频文件，并生成一个包含给定模型预测的“output.avi”文件。如果你用<a class="ae lq" href="https://www.videolan.org/vlc/index.html" rel="noopener ugc nofollow" target="_blank"> VLC </a>或其他视频播放器打开这个文件，你应该会看到一些有希望的结果！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/97a6d9cf374915bcd397e8913de4883b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*lEBypTDf_jVLd4jcEBydTA.gif"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">视频检测器产生的输出短片</p></figure><p id="f833" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最后，您可以从文件中保存和加载模型，允许您保存您的进度并在以后返回:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nl nm l"/></div></figure><h1 id="5896" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">高级用法</h1><p id="5718" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">你会很高兴地知道Detecto不仅仅局限于5行代码。比方说，这个模型没有你希望的那么好。我们可以通过用<a class="ae lq" href="https://pytorch.org/docs/stable/torchvision/transforms.html" rel="noopener ugc nofollow" target="_blank"> torchvision transforms </a>扩充我们的数据集并定义一个定制的<a class="ae lq" href="https://detecto.readthedocs.io/en/latest/api/core.html#detecto.core.DataLoader" rel="noopener ugc nofollow" target="_blank"> DataLoader </a>来提高它的性能:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="0c95" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这段代码对数据集中的图像应用随机水平翻转和饱和度效果，增加了数据的多样性。然后我们用<code class="fe os ot ou nc b">batch_size=2</code>定义一个DataLoader对象；我们将把它传递给<code class="fe os ot ou nc b">model.fit</code>而不是数据集，告诉我们的模型分批训练2张图像，而不是默认的1张。</p><p id="172f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果您之前创建了一个单独的验证数据集，现在是在培训期间加载它的时候了。通过提供一个验证数据集，<code class="fe os ot ou nc b">fit</code>方法返回每个时期的损失列表，如果是<code class="fe os ot ou nc b">verbose=True</code>，那么它也会在训练过程中打印出来。下面的代码块演示了这一点，并自定义了其他几个培训参数:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="13aa" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">所得到的损失图应该或多或少地减少:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi ow"><img src="../Images/0f981619029387b5d26b39b84ff13bf7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iZO-boBv5SAkX_pWChQKbA.png"/></div></div></figure><p id="c568" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了更加灵活和控制你的模型，你可以完全绕过Detecto<code class="fe os ot ou nc b">model.get_internal_model</code>方法返回所使用的底层torchvision模型，您可以随意修改。</p><h1 id="20d6" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">结论</h1><p id="85eb" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">在本教程中，我们展示了计算机视觉和物体检测并不具有挑战性。你需要的只是一点时间和耐心来创建一个带标签的数据集。</p><p id="53e8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果您有兴趣进一步探索，请查看GitHub 上的<a class="ae lq" href="https://github.com/alankbi/detecto" rel="noopener ugc nofollow" target="_blank"> Detecto或访问</a><a class="ae lq" href="https://detecto.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">文档</a>以获得更多教程和用例！</p><div class="lr ls gp gr lt lu"><a href="https://github.com/alankbi/detecto" rel="noopener  ugc nofollow" target="_blank"><div class="lv ab fo"><div class="lw ab lx cl cj ly"><h2 class="bd iu gy z fp lz fr fs ma fu fw is bi translated">alankbi/detecto</h2><div class="mb l"><h3 class="bd b gy z fp lz fr fs ma fu fw dk translated">Detecto是一个Python包，它允许你用…</h3></div><div class="mc l"><p class="bd b dl z fp lz fr fs ma fu fw dk translated">github.com</p></div></div></div></a></div></div></div>    
</body>
</html>