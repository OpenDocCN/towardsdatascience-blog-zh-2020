<html>
<head>
<title>Complete Guide to Clustering Techniques</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">聚类技术完全指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/beginners-guide-to-clustering-techniques-164d6ad5dbb?source=collection_archive---------49-----------------------#2020-07-27">https://towardsdatascience.com/beginners-guide-to-clustering-techniques-164d6ad5dbb?source=collection_archive---------49-----------------------#2020-07-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/a48cdefb6d1449265cec3ebcab592b4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bIMxTdc4O8W6e9V-"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">照片由<a class="ae kf" href="https://unsplash.com/@plqml?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> @plqml // felipe pelaquim </a>在<a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="6817" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了成为 Kaggle 上的大师，我从一个简单的数据挖掘算法开始发布笔记本。我要解释的第一个算法是聚类。</p><p id="61ca" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae kf" href="https://www.kaggle.com/gireeshs/complete-guide-to-clustering-techniques" rel="noopener ugc nofollow" target="_blank"> <strong class="ki iu">链接到 Kaggle 笔记本</strong> </a> <strong class="ki iu">。如果你喜欢这个帖子，请给我的 kaggle 笔记本投票。</strong></p><h1 id="af28" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">介绍</h1><p id="885d" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">聚类是一种无监督的学习技术，您可以获取整个数据集，并在数据集中找到“相似实体的组”。因此，数据集中没有标签。</p><p id="4e20" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这有助于将非常大的数据集组织成有意义的聚类，从而有助于采取行动。例如，将超过 100 万条记录的整个客户群划分为高价值客户、低价值客户等等。</p><p id="82f5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">聚类通常倾向于回答什么问题？</strong></p><ul class=""><li id="d188" class="mh mi it ki b kj kk kn ko kr mj kv mk kz ml ld mm mn mo mp bi translated">网络上有哪些类型的页面？</li><li id="bdc3" class="mh mi it ki b kj mq kn mr kr ms kv mt kz mu ld mm mn mo mp bi translated">我的市场中有哪些类型的客户？</li><li id="33b7" class="mh mi it ki b kj mq kn mr kr ms kv mt kz mu ld mm mn mo mp bi translated">社交网络上有哪些类型的人？</li><li id="49cc" class="mh mi it ki b kj mq kn mr kr ms kv mt kz mu ld mm mn mo mp bi translated">我收件箱中的<strong class="ki iu">电子邮件类型</strong>？</li><li id="7f48" class="mh mi it ki b kj mq kn mr kr ms kv mt kz mu ld mm mn mo mp bi translated"><strong class="ki iu">基因的种类</strong>人类的基因组有哪些？</li></ul><p id="f3c4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">从聚类到分类</strong></p><p id="7924" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">聚类是所有分类问题的基础。最初，假设我们在一个新的社交媒体平台上有大量未分组的用户。我们肯定知道，社交媒体中的用户数量不会等于群组数量，而且它将是合理有限的。尽管每个用户可能有细微的差别，但他们可以合理地分组。当我们知道这些用户属于哪个组时，这些分组的每一个聚类都成为类。</p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="bc2d" class="le lf it bd lg lh nc lj lk ll nd ln lo lp ne lr ls lt nf lv lw lx ng lz ma mb bi translated">划分聚类</h1><p id="926a" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">在开始聚类之前，如果我们假设数据将落入 x 个聚类中，然后将数据划分到这些数量的聚类中，这就称为分区聚类。在分区聚类中执行聚类之前，聚类的数量是已知的。k-Means 是一种流行的划分聚类技术，其中数据被划分为 k 个唯一的聚类。</p><p id="8124" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">k-均值聚类</strong></p><figure class="ni nj nk nl gt ju gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/f8def7a62b3bdb892329f2482ca56d88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/0*v-xmWmVJDkFbqNrf.gif"/></div></figure><ul class=""><li id="6a46" class="mh mi it ki b kj kk kn ko kr mj kv mk kz ml ld mm mn mo mp bi translated">设数据点 X = {x1，x2，x3，… xn}为需要聚类成 K 个簇的 N 个数据点。</li><li id="5e54" class="mh mi it ki b kj mq kn mr kr ms kv mt kz mu ld mm mn mo mp bi translated">K 介于 1 和 N 之间，其中 if: <br/> - K = 1 那么整个数据就是单个聚类，整个数据的均值就是我们要寻找的聚类中心。<br/> - K =N，那么每个数据单独代表一个单独的聚类。<br/>通常 K 介于 1 和 n 之间</li></ul><p id="eb21" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">作为优化问题的公式</strong></p><p id="69ee" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">设 M = {m1，m2，m3，… mk}为 K 个聚类的聚类均值。每一个 m 都代表我们正在寻找的单个集群。<br/>目标函数是我们为每个聚类找到这样的表示，它最好地逼近数据并且逼近的误差最小。</p><p id="387f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们试图最小化的目标函数是每个数据点与其代表点之间距离的平方和。</p><p id="1819" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">使用 SKLearn 实现 k-Means</strong></p><figure class="ni nj nk nl gt ju"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="bfa4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但是 5 个集群足够好吗？</p><p id="1e09" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如上所述，在这种情况下，我们需要准确地指定我们要寻找多少个集群。群集的数量很难直观地猜测。只有对数据了如指掌，才能凭直觉猜测。</p><p id="d28e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">集群数量的解决方案</strong></p><p id="0077" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们使用不同数量的聚类运行 k-Means 算法，并通过绘制来自 sklearn 的惯性参数来绘制拟合优度，该参数给出了样本到其最近聚类中心的平方距离之和。</p><figure class="ni nj nk nl gt ju"><div class="bz fp l di"><div class="nm nn l"/></div></figure><figure class="ni nj nk nl gt ju gh gi paragraph-image"><div class="gh gi no"><img src="../Images/76a7b5708bb46f12e0a6f94e6cca8c46.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/0*DUwJ84Rara-x5LkN.png"/></div></figure><p id="0374" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">k 均值聚类的局限性</strong></p><p id="7e6d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">k-Means 聚类只能分离线性聚类边界，这意味着它将无法识别复杂得多的决策边界。</p><p id="d0e1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这可以通过在 sklearn 上制作 moons 数据集来解释，如下所示:</p><figure class="ni nj nk nl gt ju gh gi paragraph-image"><div class="gh gi np"><img src="../Images/ac7a88a05106bb111f94ab3e5ee666c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/0*1NUOhdXfeSm17bMJ.png"/></div></figure><p id="71e0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个问题的答案可以在了解层次聚类中找到。</p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="ca66" class="le lf it bd lg lh nc lj lk ll nd ln lo lp ne lr ls lt nf lv lw lx ng lz ma mb bi translated">分层聚类</h1><p id="d068" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">自然界是由等级制度组成的，就像食物链、组织结构、物种的生物分类等等。自底向上的层次聚类也称为聚集聚类。</p><p id="2687" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">聚集聚类中的关键超参数称为连锁。这是两个集群之间的距离。它类似于用于 k-均值聚类的聚类均值 M。它可以用多种方式表示:</p><ul class=""><li id="c549" class="mh mi it ki b kj kk kn ko kr mj kv mk kz ml ld mm mn mo mp bi translated">单链:两个簇之间最近的两个点之间的距离。</li><li id="e2fa" class="mh mi it ki b kj mq kn mr kr ms kv mt kz mu ld mm mn mo mp bi translated">完全连锁:两个集群之间两个最远点之间的距离。</li><li id="1175" class="mh mi it ki b kj mq kn mr kr ms kv mt kz mu ld mm mn mo mp bi translated">平均连锁:介于单一连锁和完全连锁之间。取所有点对之间的平均值。这对于噪声是鲁棒的。</li></ul><p id="2f13" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">使用 SKLearn 实现聚集聚类</strong></p><figure class="ni nj nk nl gt ju"><div class="bz fp l di"><div class="nm nn l"/></div></figure><figure class="ni nj nk nl gt ju gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/add70a41db423a9905e64ab513cff7a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/0*kuSS8CjZ4Ie5urrM.png"/></div></figure><p id="2dcb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于同一个月球数据集，我们现在可以看到，通过聚集聚类，单个链接，我们可以得到很好的聚类。</p><figure class="ni nj nk nl gt ju gh gi paragraph-image"><div class="gh gi np"><img src="../Images/3f8e720e083d19c890d6c004ae38f706.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/0*MNlTfSfZVf_lkx4U.png"/></div></figure></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="61f5" class="le lf it bd lg lh nc lj lk ll nd ln lo lp ne lr ls lt nf lv lw lx ng lz ma mb bi translated">谱聚类</h1><p id="04b3" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">处理相似度图，其中每个节点代表一个实体和边上的权重。考虑类似于一个图的结构，其中所有节点通过由权重构成的边连接到所有其他节点。如果我们想把它分成两个簇，显然我们想去掉权重最低的边。</p><p id="6802" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">使用 SKLearn 实现谱聚类</strong></p><figure class="ni nj nk nl gt ju"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="f0fe" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">人造卫星将如下所示:</p><figure class="ni nj nk nl gt ju gh gi paragraph-image"><div class="gh gi np"><img src="../Images/cad5d5281728f33a58e41a04778b3f3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/0*qvbSH6M8N4vcNL3O.png"/></div></figure></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="47b1" class="le lf it bd lg lh nc lj lk ll nd ln lo lp ne lr ls lt nf lv lw lx ng lz ma mb bi translated">比较和对比不同的聚类技术</h1><figure class="ni nj nk nl gt ju gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/d5f47e3f0664669e4a24dcc16459f065.png" data-original-src="https://miro.medium.com/v2/resize:fit:1330/format:webp/1*zK1HmvQASxAuZ3vb9o-LbA.png"/></div></figure><figure class="ni nj nk nl gt ju gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/370b266d9847702994852038c02eb8c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1302/format:webp/0*hSeVmXoG9KciuUDL.png"/></div></figure></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><p id="2f2e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我对聚类技术的解释到此结束。我欢迎您的反馈和建议。</p><p id="edcc" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae kf" href="https://www.kaggle.com/gireeshs/complete-guide-to-clustering-techniques" rel="noopener ugc nofollow" target="_blank">如果你觉得这个帖子有用，请在 kaggle 上投票支持我的笔记本！</a></p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><p id="c0ba" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">参考文献:</strong></p><p id="7b66" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae kf" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . cluster . k means . html # sk learn . cluster . k means</a><br/><a class="ae kf" href="https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_iris.html#sphx-glr-auto-examples-cluster-plot-cluster-iris-py" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/auto _ examples/cluster/plot _ cluster _ iris . html # sphx-glr-auto-examples-cluster-plot-cluster-iris-py</a><br/><a class="ae kf" href="https://greyatom.com/programs/learn-data-science-online-with-projects/learn" rel="noopener ugc nofollow" target="_blank">https://grey atom . com/programs/learn-data-science-online-with</a></p><p id="0908" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">图片来自:</strong></p><p id="b893" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae kf" href="https://www.mygreatlearning.com/blog/clustering-algorithms-in-machine-learning/" rel="noopener ugc nofollow" target="_blank">https://www . mygreatlearning . com/blog/clustering-algorithms-in-machine-learning/</a><br/>T3】https://commons . wikimedia . org/wiki/File:K-means _ convergence . gif<br/><a class="ae kf" href="https://www.solver.com/xlminer/help/hierarchical-clustering-intro" rel="noopener ugc nofollow" target="_blank">https://www . solver . com/XL miner/help/hierarchical-clustering-intro</a><br/><a class="ae kf" rel="noopener" target="_blank" href="/spectral-clustering-aba2640c0d5b">https://towardsdatascience . com/spectral-clustering-ABA 2640 d5b</a></p></div></div>    
</body>
</html>