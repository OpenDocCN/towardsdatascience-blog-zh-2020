<html>
<head>
<title>Classification of Common Fruits Using Neural Networks (PyTorch)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于神经网络(PyTorch)的常见水果分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/classification-of-fruit-images-using-neural-networks-pytorch-1d34d49342c7?source=collection_archive---------32-----------------------#2020-06-29">https://towardsdatascience.com/classification-of-fruit-images-using-neural-networks-pytorch-1d34d49342c7?source=collection_archive---------32-----------------------#2020-06-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/d5656f4181d9183a79ccec51fd657554.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ArgXpBRmZr8TzA_9"/></div></div></figure><div class=""/><div class=""><h2 id="b6b1" class="pw-subtitle-paragraph kb jd je bd b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks dk translated">一本关于神经网络实现高准确率的易读指南</h2></div><p id="c198" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi lp translated"><span class="l lq lr ls bm lt lu lv lw lx di">目的:寻找一种对水果 360 幅图像分类准确率最高的神经网络模型。</span></p><ol class=""><li id="5785" class="ly lz je kv b kw kx kz la lc ma lg mb lk mc lo md me mf mg bi translated">深度前馈</li><li id="f02c" class="ly lz je kv b kw mh kz mi lc mj lg mk lk ml lo md me mf mg bi translated">卷积神经网络</li><li id="017e" class="ly lz je kv b kw mh kz mi lc mj lg mk lk ml lo md me mf mg bi translated">残差神经网络(ResNet9)</li></ol><p id="c399" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">数据来源:【https://www.kaggle.com/moltean/fruits T4】</p><p id="fd3a" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">全码笔记本:<a class="ae mm" href="https://jovian.ai/limyingying2000-qat/fruitsfinal" rel="noopener ugc nofollow" target="_blank">https://jovian.ml/limyingying2000/fruitsfinal</a></p><h1 id="1764" class="mn mo je bd mp mq mr ms mt mu mv mw mx kk my kl mz kn na ko nb kq nc kr nd ne bi translated"><span class="l lq lr ls bm lt lu lv lw lx di"> D </span>数据准备</h1><p id="a396" class="pw-post-body-paragraph kt ku je kv b kw nf kf ky kz ng ki lb lc nh le lf lg ni li lj lk nj lm ln lo im bi translated"><strong class="kv jf">首先，让我们了解一下我们的数据集！</strong></p><p id="b492" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">Kaggle Fruits 360 数据集由 131 种不同类型的水果和蔬菜的 90483 张图像组成。</p><p id="f965" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">首先，我们导入数据和所需的库来运行我们的代码。</p><pre class="nk nl nm nn gt no np nq nr aw ns bi"><span id="e7e8" class="nt mo je np b gy nu nv l nw nx">import torch<br/>import os<br/>import jovian<br/>import torchvision<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import torch.nn as nn<br/>import torchvision.models as models<br/>import torch.nn.functional as F<br/>from torchvision.datasets import ImageFolder<br/>from torchvision.transforms import ToTensor<br/>from torchvision.utils import make_grid<br/>from torch.utils.data.dataloader import DataLoader<br/>from torch.utils.data import random_split<br/>import torchvision.models as models<br/>%matplotlib inline</span></pre><figure class="nk nl nm nn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ny"><img src="../Images/8cc145cf3c27a8901a8970c0f5f809f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*v8gB6gFZtlyICQi3GeHRdw.png"/></div></div><p class="nz oa gj gh gi ob oc bd b be z dk translated">每种水果都有其独特的文件夹，由 jpg 图像组成。</p></figure><p id="56fa" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">使用<em class="od"> matplotlib </em>库显示彩色图像:</p><pre class="nk nl nm nn gt no np nq nr aw ns bi"><span id="fb0e" class="nt mo je np b gy nu nv l nw nx">import matplotlib.pyplot as plt<br/><br/>def <strong class="np jf">show_example</strong>(img, label):<br/>    print('Label: ', dataset.classes[label], "("+str(label)+")")<br/>    plt.imshow(img.permute(1, 2, 0))</span></pre><figure class="nk nl nm nn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oe"><img src="../Images/23dad8286f4898037ec5b26e119800c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9SSFgAcXyT3APVtjRRO7Eg.png"/></div></div><p class="nz oa gj gh gi ob oc bd b be z dk translated">数据集[5000]是一个苹果蛇果</p></figure><p id="e218" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">由于我们使用的是<em class="od"> PyTorch </em>，我们必须使用<code class="fe of og oh np b">ToTensor</code>将上面的像素图像转换成张量:</p><pre class="nk nl nm nn gt no np nq nr aw ns bi"><span id="781a" class="nt mo je np b gy nu nv l nw nx">dataset = ImageFolder(data_dir + '/Training', transform=ToTensor())<br/>img, label = dataset[0]<br/>print(img.shape, label) <br/>img</span></pre><figure class="nk nl nm nn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oi"><img src="../Images/50a30191744ccc99588ae9f7b7d952dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BDyead64G9eLZCbaqxNP1A.png"/></div></div><p class="nz oa gj gh gi ob oc bd b be z dk translated">图像转换成张量的一个例子</p></figure><p id="c2d3" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">有 3 个通道(红、绿、蓝)，100*100 图像尺寸。每个值代表相对于通道颜色的颜色强度。</p><p id="9353" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><strong class="kv jf">训练和验证数据集</strong></p><p id="221c" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">接下来，我们将随机分割数据以获得 3 组数据:</p><ol class=""><li id="efa6" class="ly lz je kv b kw kx kz la lc ma lg mb lk mc lo md me mf mg bi translated">训练集:训练模型</li><li id="a5c0" class="ly lz je kv b kw mh kz mi lc mj lg mk lk ml lo md me mf mg bi translated">验证集:评估模型</li><li id="5fc9" class="ly lz je kv b kw mh kz mi lc mj lg mk lk ml lo md me mf mg bi translated">测试集:报告模型的最终准确性</li></ol><p id="45d8" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">训练数据集的大小:57，692</p><p id="5eb1" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">验证数据集的大小:10，000</p><p id="641f" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">测试数据集的大小:22，688</p><p id="8fd9" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><strong class="kv jf">分批培训</strong></p><p id="3c7d" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">因为我们总共有 57，692 个训练图像，所以在使用<code class="fe of og oh np b"><em class="od">DataLoader</em></code>训练我们的模型之前，我们应该将我们的图像分成更小的批次。使用较小的数据集可以减少内存空间，从而提高训练速度。</p><p id="c05f" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">对于我们的数据集，我们将使用 128 的批量大小。</p><figure class="nk nl nm nn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oj"><img src="../Images/fef6845be1f00c7a1d53c2dedb88c009.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Zp8qc3ZvGTzC7_r5ZFsWA.png"/></div></div><p class="nz oa gj gh gi ob oc bd b be z dk translated">在训练批次中随机分配 128 个图像</p></figure><p id="4fda" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">现在，我们将开始设计我们的模型。</p></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><h1 id="3957" class="mn mo je bd mp mq or ms mt mu os mw mx kk ot kl mz kn ou ko nb kq ov kr nd ne bi translated">1.深度前馈</h1><p id="4857" class="pw-post-body-paragraph kt ku je kv b kw nf kf ky kz ng ki lb lc nh le lf lg ni li lj lk nj lm ln lo im bi translated"><strong class="kv jf">超参数:</strong></p><p id="98e0" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">架构:“5 层(2000，1000，500，250，131)”</p><p id="475b" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">学习率:[0.01，0.001]</p><p id="5161" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">历元数:[10，10]</p><p id="c5f5" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">优化函数:随机梯度下降(SGD)</p><p id="2a2a" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><strong class="kv jf">用 5 层架构训练模型:</strong></p><pre class="nk nl nm nn gt no np nq nr aw ns bi"><span id="24fa" class="nt mo je np b gy nu nv l nw nx">class <strong class="np jf">FruitsModelFF</strong>(ImageClassificationBase):<br/>    def <strong class="np jf">__init__</strong>(self):<br/>        super().__init__()<br/>        self.linear1= nn.Linear(input_size, 2000)<br/>        self.linear2= nn.Linear(2000, 1000)<br/>        self.linear3= nn.Linear(1000,500)<br/>        self.linear4= nn.Linear(500,250)<br/>        self.linear5= nn.Linear(250, output_size)<br/>        <br/>    def <strong class="np jf">forward</strong>(self, xb):<br/>        <em class="od"># Flatten images into vectors</em><br/>        out = xb.view(xb.size(0), -1)<br/>        <em class="od"># Apply layers &amp; activation functions </em><br/>        out= self.linear1(out)<br/>        out=F.relu(out)  <br/>        out=self.linear2(out)<br/>        out=F.relu(out)  <br/>        out=self.linear3(out)<br/>        out=F.relu(out)  <br/>        out=self.linear4(out)<br/>        out=F.relu(out)  <br/>        out=self.linear5(out)<br/>        return out</span></pre><p id="566b" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi lp translated">训练前，验证准确率为:<strong class="kv jf"> 0.52734% </strong></p><figure class="nk nl nm nn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ow"><img src="../Images/5a4be8a2719157f4e6e1cba5c27f0379.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P6SfC3ryva57zjdzmbvWfA.png"/></div></div></figure><figure class="nk nl nm nn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ow"><img src="../Images/a069b0fae15ce0fb0670081f19c0351c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uENzKbQzgM5RbUfChvPmNw.png"/></div></div></figure><p id="2852" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi lp translated"><span class="l lq lr ls bm lt lu lv lw lx di"> A </span>在以[0.01，0.001]的学习速率训练了总共 20 个周期后，验证准确率在大约<strong class="kv jf"> 96.84% </strong>处达到平稳状态。这与最初的 0.52734%相比是一个巨大的跳跃。</p><h1 id="365a" class="mn mo je bd mp mq mr ms mt mu mv mw mx kk my kl mz kn na ko nb kq nc kr nd ne bi translated">最后，让我们用测试数据集来测试我们训练好的模型！</h1><pre class="nk nl nm nn gt no np nq nr aw ns bi"><span id="3582" class="nt mo je np b gy nu nv l nw nx">img, label = test[8000]<br/>plt.imshow(img.permute(1, 2, 0))<br/>print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))</span></pre><figure class="nk nl nm nn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ox"><img src="../Images/7cf61b18fa2a480c5a84fc1784af4001.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j4fdMfMtV_-khtePT2rnTA.png"/></div></div></figure><pre class="nk nl nm nn gt no np nq nr aw ns bi"><span id="0520" class="nt mo je np b gy nu nv l nw nx">img, label = test[1002]<br/>plt.imshow(img.permute(1, 2, 0))<br/>print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))</span></pre><figure class="nk nl nm nn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ox"><img src="../Images/f59352fdbf7942f26d2ac20cedf39790.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b7ZPIOu_xJ6QqmLOE5g_4w.png"/></div></div></figure><pre class="nk nl nm nn gt no np nq nr aw ns bi"><span id="a5b1" class="nt mo je np b gy nu nv l nw nx">img, label = test[0]<br/>plt.imshow(img.permute(1, 2, 0))<br/>print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))</span></pre><figure class="nk nl nm nn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ox"><img src="../Images/3fb4e33c1e4b5eb3f8fff3cb69ec9541.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-QbQitEM0y1k1RK5RXW0GA.png"/></div></div></figure><p id="405e" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我们训练的模型正确地预测了上述所有结果。</p><pre class="nk nl nm nn gt no np nq nr aw ns bi"><span id="7838" class="nt mo je np b gy nu nv l nw nx"><strong class="np jf">Final test accuracy: 86.209%</strong></span></pre><p id="863e" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">为了进一步提高我们的测试精度，我们将使用卷积神经网络，它通常比前馈神经网络性能更好。</p><blockquote class="oy oz pa"><p id="b03b" class="kt ku od kv b kw kx kf ky kz la ki lb pb ld le lf pc lh li lj pd ll lm ln lo im bi translated">原因:</p><p id="7fab" class="kt ku od kv b kw kx kf ky kz la ki lb pb ld le lf pc lh li lj pd ll lm ln lo im bi translated"><a class="ae mm" rel="noopener" target="_blank" href="/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53">通过应用相关过滤器，ConvNet 能够<strong class="kv jf">成功捕捉图像中的空间和时间相关性</strong>。由于所涉及的参数数量的减少和权重的可重用性，该架构对图像数据集执行更好的拟合。换句话说，可以训练网络更好地理解图像的复杂程度。</a></p></blockquote><p id="2b31" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">简而言之，CNN 非常适合计算密集型的大尺寸图像:</p><ol class=""><li id="d9ad" class="ly lz je kv b kw kx kz la lc ma lg mb lk mc lo md me mf mg bi translated">需要更少的参数</li><li id="b7ac" class="ly lz je kv b kw mh kz mi lc mj lg mk lk ml lo md me mf mg bi translated">形成连接的稀疏性</li><li id="4b0c" class="ly lz je kv b kw mh kz mi lc mj lg mk lk ml lo md me mf mg bi translated">能够检测相似的模式，并在图像的不同部分应用学到的特征</li></ol><h1 id="8721" class="mn mo je bd mp mq mr ms mt mu mv mw mx kk my kl mz kn na ko nb kq nc kr nd ne bi translated"><strong class="ak"> 2。简单卷积神经网络(CNN) </strong></h1><p id="e2de" class="pw-post-body-paragraph kt ku je kv b kw nf kf ky kz ng ki lb lc nh le lf lg ni li lj lk nj lm ln lo im bi translated"><strong class="kv jf">CNN 功能简介:</strong></p><figure class="nk nl nm nn gt iv gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/bc46fe100c0b9fc24dc056bc53b2829a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/0*liDYplB-Bn7QnB50.gif"/></div><p class="nz oa gj gh gi ob oc bd b be z dk translated"><a class="ae mm" rel="noopener" target="_blank" href="/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1"> 5*5 图像尺寸，3*3 内核尺寸，3*3 输出尺寸</a></p></figure><p id="61ea" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">内核上的权重首先被随机初始化为:</p><p id="95d1" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><code class="fe of og oh np b">[0, 1, 2]<br/> [2, 2, 0]<br/> [0, 1, 2]</code></p><p id="8d96" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我们的示例图像如下所示:</p><p id="acba" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><code class="fe of og oh np b">[3, 3, 2, 1, 0]<br/> [0, 0, 1, 3, 1] <br/> [3, 1, 2, 2, 3] <br/> [2, 0, 0, 2, 2] <br/> [2, 0, 0, 0, 1]</code></p><p id="6514" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">当我们对样本图像应用内核时，输出将是:</p><p id="7c03" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><code class="fe of og oh np b">[12., 12., 17.]<br/>[10., 17., 19.]<br/>[ 9., 6., 14.]</code></p><p id="3524" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><strong class="kv jf">申请:</strong></p><figure class="nk nl nm nn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pf"><img src="../Images/cba638f57b2c220ca555fc26554f4db5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LMND6LUpI_eBLbz1C3y9Kg.png"/></div></div></figure><p id="28d9" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">输出= 2 * 0+2 * 1+3 * 2+0 * 2+2 * 2+2 * 0+0 * 0+0 * 1+1 * 2 = 14</p><p id="94b0" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">对样本图像上内核的每次移动重复计算输出，以获得新的输出大小。</p><pre class="nk nl nm nn gt no np nq nr aw ns bi"><span id="8cba" class="nt mo je np b gy nu nv l nw nx">def <strong class="np jf">apply_kernel</strong>(image, kernel):<br/>    ri, ci = image.shape       <em class="od"># image dimensions</em><br/>    rk, ck = kernel.shape      <em class="od"># kernel dimensions</em><br/>    ro, co = ri-rk+1, ci-ck+1  <em class="od"># output dimensions</em><br/>    output = torch.zeros([ro, co])<br/>    for i in range(ro): <br/>        for j in range(co):<br/>            output[i,j] = torch.sum(image[i:i+rk,j:j+ck] * kernel)<br/>    return output</span></pre><p id="a728" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">此外，我们通过应用最大池层来逐渐减小每个卷积层的输出张量的大小。</p><figure class="nk nl nm nn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pf"><img src="../Images/cd5e708353516a6087d17fed17a58bf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vLaMNVVMHxx7vwpc4lFXFA.png"/></div></div><p class="nz oa gj gh gi ob oc bd b be z dk translated"><a class="ae mm" rel="noopener" target="_blank" href="/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1">最大池可视化</a></p></figure><p id="a351" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">如上所述，卷积层增加了通道，而最大池层减少了图像大小。</p><figure class="nk nl nm nn gt iv gh gi paragraph-image"><div class="ab gu cl pg"><img src="../Images/5fda1dcba94efa203608f6bec0bad445.png" data-original-src="https://miro.medium.com/v2/format:webp/0*B32xL6pGF6LPF5cI.jpeg"/></div><p class="nz oa gj gh gi ob oc bd b be z dk translated"><a class="ae mm" rel="noopener" target="_blank" href="/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53">具有卷积和最大池的 CNN 结构的例子</a></p></figure><p id="e1fe" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">现在，让我们为同一个 Kaggle 水果数据集构建 CNN 模型。</p><p id="3bf1" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><strong class="kv jf">超参数:</strong></p><p id="acee" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">纪元数量:10</p><p id="6015" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">学习率:0.001</p><p id="2630" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">优化函数:亚当</p><pre class="nk nl nm nn gt no np nq nr aw ns bi"><span id="0e9f" class="nt mo je np b gy nu nv l nw nx">class <strong class="np jf">FruitsModel</strong>(ImageClassificationBase):<br/>    def <strong class="np jf">__init__</strong>(self):<br/>        super().__init__()<br/>        self.network = nn.Sequential(<br/>            nn.Conv2d(3, 32, kernel_size=3, padding=1), <em class="od">#3 channels to 32 channels</em><br/>            nn.ReLU(),<br/>            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),<br/>            nn.ReLU(),<br/>            nn.MaxPool2d(2, 2), <em class="od"># output: 64 channels x 50 x 50 image size - decrease</em><br/><br/>            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),<br/>            nn.ReLU(),<br/>            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1), <em class="od">#can keep the same, increase power of model , go deeper as u add linearity to non-linearity</em><br/>            nn.ReLU(),<br/>            nn.MaxPool2d(2, 2), <em class="od"># output: 128 x 25 x 25</em><br/><br/>            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),<br/>            nn.ReLU(),<br/>            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),<br/>            nn.ReLU(),<br/>            nn.MaxPool2d(5, 5), <em class="od"># output: 256 x 5 x 5</em><br/><br/>            nn.Flatten(), <em class="od">#a single vector 256*5*5,</em><br/>            nn.Linear(256*5*5, 1024),<br/>            nn.ReLU(),<br/>            nn.Linear(1024, 512),<br/>            nn.ReLU(),<br/>            nn.Linear(512, 131))<br/>        <br/>    def <strong class="np jf">forward</strong>(self, xb):<br/>        return self.network(xb)</span></pre><p id="bb83" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">除了在我们的模型中的改变之外，我们使用 Adam 优化器函数，因为它是在分类问题中寻找最小成本函数的更有效的方式。</p><pre class="nk nl nm nn gt no np nq nr aw ns bi"><span id="40aa" class="nt mo je np b gy nu nv l nw nx"><strong class="np jf">Final test accuracy rate: 92.571%</strong></span></pre><p id="6058" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我们已经实现了非常高的最终测试准确率，大约比前馈神经网络高<strong class="kv jf">6</strong>。然而，让我们通过额外的残差块和对 CNN 模型的微小调整来进一步拓展边界。</p><h1 id="0df4" class="mn mo je bd mp mq mr ms mt mu mv mw mx kk my kl mz kn na ko nb kq nc kr nd ne bi translated"><strong class="ak"> 3。</strong>残差神经网络(<strong class="ak"> ResNet9) </strong></h1><p id="d9fc" class="pw-post-body-paragraph kt ku je kv b kw nf kf ky kz ng ki lb lc nh le lf lg ni li lj lk nj lm ln lo im bi translated"><strong class="kv jf">超参数:</strong></p><p id="8001" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">最大学习率:0.01</p><p id="dc8b" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">纪元数量:10</p><p id="9259" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">优化函数:亚当</p><pre class="nk nl nm nn gt no np nq nr aw ns bi"><span id="351f" class="nt mo je np b gy nu nv l nw nx">def <strong class="np jf">conv_block</strong>(in_channels, out_channels, pool=False):<br/>    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), <br/>              nn.BatchNorm2d(out_channels), <br/>              nn.ReLU(inplace=True)]<br/>    if pool: layers.append(nn.MaxPool2d(2))<br/>    return nn.Sequential(*layers)<br/><br/>class <strong class="np jf">ResNet9</strong>(ImageClassificationBase):<br/>    def <strong class="np jf">__init__</strong>(self, in_channels, num_classes):<br/>        super().__init__()<br/>        <br/>        self.conv1 = conv_block(in_channels, 64)<br/>        self.conv2 = conv_block(64, 128, pool=True)<br/>        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))<br/>        <br/>        self.conv3 = conv_block(128, 256, pool=True)<br/>        self.conv4 = conv_block(256, 512, pool=True)<br/>        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))<br/>        <br/>        self.classifier = nn.Sequential(nn.MaxPool2d(4), <br/>                                        nn.Flatten(), <br/>                                        nn.Linear(4608, num_classes))<br/>        <br/>    def <strong class="np jf">forward</strong>(self, xb):<br/>        out = self.conv1(xb)<br/>        out = self.conv2(out)<br/>        out = self.res1(out) + out<br/>        out = self.conv3(out)<br/>        out = self.conv4(out)<br/>        out = self.res2(out) + out<br/>        out = self.classifier(out)<br/>        return out</span></pre><p id="7065" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">除此之外，我们还将引入<strong class="kv jf">“一个周期学习率策略”</strong>，它会逐渐提高学习率，直至达到用户设定的最大学习率，然后逐渐降至极低的学习率。这种学习率的变化发生在每一批训练之后。</p><p id="e457" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">很难找到正确的学习速率，因为相对较高的学习速率会导致发散，而相对较低的学习速率会导致模型过拟合。</p><figure class="nk nl nm nn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ph"><img src="../Images/bcf181ba2e6ba85fe449739d4d7e4b81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JVfkdHMwVtv-e3aP.png"/></div></div><p class="nz oa gj gh gi ob oc bd b be z dk translated"><a class="ae mm" href="https://www.jeremyjordan.me/nn-learning-rate/" rel="noopener ugc nofollow" target="_blank">学习率</a></p></figure><p id="c48e" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">然而,“一个周期学习率策略”通过为我们的模型找到一个最佳学习率范围克服了这样的问题。</p><figure class="nk nl nm nn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pi"><img src="../Images/d33f8cd5e4968f400a9ea26f867b36e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q98-pMjinte4Dxv4VoiW2g.png"/></div></div><p class="nz oa gj gh gi ob oc bd b be z dk translated">学习率在大约第 1200 批次时达到峰值 0.01</p></figure><pre class="nk nl nm nn gt no np nq nr aw ns bi"><span id="e654" class="nt mo je np b gy nu nv l nw nx"><strong class="np jf">Final test accuracy: 98.85% </strong></span></pre><p id="e9fc" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">经过一些修改，我们的最终测试精度又提高了<strong class="kv jf">6%。</strong></p><h1 id="6b7f" class="mn mo je bd mp mq mr ms mt mu mv mw mx kk my kl mz kn na ko nb kq nc kr nd ne bi translated">总结:</h1><figure class="nk nl nm nn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pj"><img src="../Images/8ecbaaaec3746fac1dc23fb8d31258ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_LOHgHUWwvi-LDmomXzDOQ.png"/></div></div></figure><figure class="nk nl nm nn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pj"><img src="../Images/0d5047eb7dd8b9127d5b1a0f6413dd4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dxX4fnuEUz3qE1UmQQ4K-g.png"/></div></div></figure><figure class="nk nl nm nn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pj"><img src="../Images/da686fc1f1d56dbd78bc7dd5ae71cb8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bUXaK68Z11Wft1tlpDFOuQ.png"/></div></div></figure><figure class="nk nl nm nn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pj"><img src="../Images/0660781e98abefbfbabcf8043d31faea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SExDlvLUz6Ggn4TNLVkhsA.png"/></div></div></figure><p id="8036" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在这 3 个不同的模型中，ResNet9 的测试准确率最高，为 98.85%。</p><h2 id="7b07" class="nt mo je bd mp pk pl dn mt pm pn dp mx lc po pp mz lg pq pr nb lk ps pt nd pu bi translated"><strong class="ak">未来工作:</strong></h2><ol class=""><li id="9765" class="ly lz je kv b kw nf kz ng lc pv lg pw lk px lo md me mf mg bi translated">数据转换(数据扩充和标准化)</li><li id="17dd" class="ly lz je kv b kw mh kz mi lc mj lg mk lk ml lo md me mf mg bi translated">高级迁移学习</li></ol><h2 id="fc8f" class="nt mo je bd mp pk pl dn mt pm pn dp mx lc po pp mz lg pq pr nb lk ps pt nd pu bi translated"><strong class="ak">演职员表:</strong></h2><p id="d3c9" class="pw-post-body-paragraph kt ku je kv b kw nf kf ky kz ng ki lb lc nh le lf lg ni li lj lk nj lm ln lo im bi translated">第一张水果照片由<a class="ae mm" href="https://unsplash.com/@hugerio?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">侯塞因</a>在<a class="ae mm" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p><p id="c6f8" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">第二张水果照片由<a class="ae mm" href="https://unsplash.com/@brookelark?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">布鲁克·拉克</a>在<a class="ae mm" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p><p id="17d5" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">课程资料来自<a class="ae mm" href="https://jovian.ml/forum/c/pytorch-zero-to-gans/18" rel="noopener ugc nofollow" target="_blank">深度学习用 py torch:Zero to GANs&amp;freeCodeCamp</a></p><figure class="nk nl nm nn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi py"><img src="../Images/aaefe79bfc85156aed5df08b5ca15b5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3VKYzqpy5iY0vG-w"/></div></div></figure></div></div>    
</body>
</html>