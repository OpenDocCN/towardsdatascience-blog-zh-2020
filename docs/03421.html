<html>
<head>
<title>Translating Sign Language in Real Time With AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用人工智能实时翻译手语</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-ai-to-translate-sign-language-in-real-time-96fe8c8223ed?source=collection_archive---------14-----------------------#2020-04-01">https://towardsdatascience.com/using-ai-to-translate-sign-language-in-real-time-96fe8c8223ed?source=collection_archive---------14-----------------------#2020-04-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7fb5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一个集成 AI 和 ASL 的项目</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ef280e6e6608e0ecd0402e4bb9595a6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MjOwogMdi9kEixG2Sue3lQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">致谢:<a class="ae ky" href="https://www.pexels.com/photo/photo-of-person-s-open-hands-2258248/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">佩克斯</a>的路易斯·金特罗</p></figure><p id="534b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">世界上有成千上万种语言。几乎所有最流行的语言都可以使用谷歌翻译等软件进行实时翻译。所使用的软件主要基于 NLP 算法，该算法通过文本接收一种语言并通过文本产生其翻译。对于真正的实时翻译，一些软件通过麦克风利用语音来翻译信息，而无需用户键入。这对口语很有用。但是，有 7000 万人不能说话或不能听，他们使用手语作为交流的方式。手语是一种不同的语言，因为它不能说。如果说不出来，那么现在的任何翻译软件都翻译不出来。那么如何翻译手语呢？当然是用相机和一点人工智能魔法！当前的手语翻译者利用摄像机进行翻译，例如<a class="ae ky" href="https://www.signall.us/" rel="noopener ugc nofollow" target="_blank">signal 1</a>，他使用彩色手套，并利用多个摄像机来理解手势。相机是给计算机视觉的一种方法，让它们能够看到世界。我决定尝试建立自己的手语翻译器。因为我住在美国，所以美国手语翻译是最有意义的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/bf91e37ce69180921848fce2a708d50d.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/format:webp/0*Ckq7NxtSANukImXT.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">信用:<a class="ae ky" href="https://en.wikipedia.org/wiki/User:Ds13" rel="noopener ugc nofollow" target="_blank"> Ds13 </a>，通过<a class="ae ky" href="https://commons.wikimedia.org/wiki/File:Asl_alphabet_gallaudet.png" rel="noopener ugc nofollow" target="_blank">维基</a></p></figure><p id="10cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">卷积神经网络(CNN)是计算机可以对图像进行分类的方式之一。他们可以对数千张照片进行训练，并学习将每张照片分类到正确的类别中，或者在这种情况下是翻译。我选择做一个简单的 ASL 翻译，在这里我翻译了 ASL <strong class="lb iu"> <em class="lw">字母表</em> </strong>。它由 26 个手形符号和一个删除和空格符号组成。我把这些标志翻译成英文字母。在我进入代码之前，我先简单介绍一下 CNN。</p><h1 id="68c9" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">卷积神经网络</h1><p id="6288" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">CNN 真的很酷，因为他们可以对图像进行分类。对于一个人来说，识别两个物品之间的区别是很容易的，比如一只狗和一只猫，但是对于一台计算机来说，要做到这一点就困难得多。计算机并没有真正“看到”图像。他们把它们看做一系列排列成阵列的数字。CNN 由多层组成。这些层通常是卷积层、池层和全连接层。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/d14a0813330bd37c19dcbc4ec857539a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3QAK_3IiMy7BK7o_.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">信用:<a class="ae ky" href="https://commons.wikimedia.org/w/index.php?title=User:Aphex34&amp;action=edit&amp;redlink=1" rel="noopener ugc nofollow" target="_blank"> Aphex34 </a>，通过<a class="ae ky" href="https://commons.wikimedia.org/wiki/File:Typical_cnn.png" rel="noopener ugc nofollow" target="_blank">维基</a> (CC BY-SA 4.0)</p></figure><h1 id="0db3" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated"><strong class="ak"> 1) </strong></h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/ab39d96840f60e5c685a70171c2d60b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/0*9e6k_-h5t1ysxr_m.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">信用:<a class="ae ky" href="https://commons.wikimedia.org/wiki/User:Trougnouf" rel="noopener ugc nofollow" target="_blank"> Trougnouf </a>，via <a class="ae ky" href="https://commons.wikimedia.org/wiki/File:Convolution_with_stride%3D3.svg" rel="noopener ugc nofollow" target="_blank"> wiki </a> (CC BY-SA 4.0)</p></figure><p id="4137" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">卷积层由一个指定大小的内核/滤波器组成，它在像素上滑动或卷积，将值相乘并求和，最终将其输出到一个新的更小的简化矩阵中。过滤器遍历照片中的每个像素，创建一个新的矩阵，称为<strong class="lb iu">特征矩阵。</strong>这个新的更小的矩阵很重要，因为它突出了图片中最重要的特征(因此得名)。它也更容易训练，因为更小=更少的重量=识别这些重量所需的训练更少。</p><h1 id="42ef" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated"><strong class="ak"> 2) </strong></h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/7c88e06d7d16f1329aadaa0068351dcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/0*KGzHURI_2NDeJpiG.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">信用:<a class="ae ky" href="https://commons.wikimedia.org/w/index.php?title=User:Aphex34&amp;action=edit&amp;redlink=1" rel="noopener ugc nofollow" target="_blank"> Aphex34 </a>，via <a class="ae ky" href="https://commons.wikimedia.org/wiki/File:Max_pooling.png" rel="noopener ugc nofollow" target="_blank"> wiki </a> (CC BY-SA 4.0)</p></figure><p id="48e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下一层是<strong class="lb iu">池层</strong>。汇集层进一步减小了矩阵的大小。它在特征矩阵上传递一个池内核，并取最高像素值(最大池)或平均值(平均池)。在我的例子中，我使用了 max-pooling，因为它采用了图像中更极端的特征，比如边缘，这对识别手势很重要。现在我们有了一个更小的矩阵，重量更轻，需要的训练更少。该矩阵包含图中所有更高级别的细节。</p><h1 id="35d7" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated"><strong class="ak"> 3) </strong></h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mx"><img src="../Images/a232875efc405a05fd483dadd42c27d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QFxHsMJDPAGmBwRg9S79Fw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">署名:维克拉姆·梅农</p></figure><p id="2f96" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们继续到<strong class="lb iu">全连接层</strong>。这里是分类发生的地方。矩阵首先被展平成向量，然后通过神经网络。它通过的神经网络类似于人工神经网络，因为它通过向量，应用权重和偏差，最终以分类结束。CNN 通过使用<strong class="lb iu"> <em class="lw"> softmax 激活</em> </strong>函数对图像进行分类，该函数给出了输入来自某个类别的概率。</p></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><h1 id="7665" class="lx ly it bd lz ma nf mc md me ng mg mh jz nh ka mj kc ni kd ml kf nj kg mn mo bi translated"><strong class="ak">工作原理</strong></h1><p id="3ebb" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">请点击此处查看 GitHub 资源库中的完整代码:</p><div class="nk nl gp gr nm nn"><a href="https://github.com/vikram-menon/ASL-Alphabet-Translation" rel="noopener  ugc nofollow" target="_blank"><div class="no ab fo"><div class="np ab nq cl cj nr"><h2 class="bd iu gy z fp ns fr fs nt fu fw is bi translated">维克拉姆语-梅农语/美国手语-字母表-翻译</h2><div class="nu l"><h3 class="bd b gy z fp ns fr fs nt fu fw dk translated">使用 CNN 翻译美国手语字母。为维克拉姆语-梅农语/美国手语-字母表-翻译的发展做出贡献</h3></div><div class="nv l"><p class="bd b dl z fp ns fr fs nt fu fw dk translated">github.com</p></div></div><div class="nw l"><div class="nx l ny nz oa nw ob ks nn"/></div></div></a></div><p id="2d7a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">数据准备</strong></p><p id="b39a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些层的输入是 ASL 数据集，可以在<a class="ae ky" href="https://www.kaggle.com/grassknoted/asl-alphabet" rel="noopener ugc nofollow" target="_blank">这里</a>找到。数据被组织到 29 个文件夹中，每个文件夹中有 3000 张图片，代表字母表中的每个字母。3 个额外的文件夹是空间，删除和什么都没有。我组织了数据，这样 80%的照片是在训练中，20%是在验证中。此外，为了加快训练速度，我将数据集中的所有图片从 200x200 缩小到 48x48。</p></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><p id="7ac6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">可选层和池层</strong></p><p id="2ab9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该模型中使用了 4 个卷积层和池层。对于每一层，执行 5 个动作:</p><ol class=""><li id="7ca5" class="oc od it lb b lc ld lf lg li oe lm of lq og lu oh oi oj ok bi translated">在第一行中，定义了<strong class="lb iu">过滤器的数量和过滤器尺寸</strong>。对于第一层，使用 64 个 3×3 滤波器。图像的输入尺寸在这里也被定义为 48x48。</li><li id="1afa" class="oc od it lb b lc ol lf om li on lm oo lq op lu oh oi oj ok bi translated">矩阵经过卷积形成特征矩阵后，经过<strong class="lb iu">批量归一化</strong>。这减少了隐藏层值的移动。这使得训练更容易，因为它稳定了重量，提高了准确性。</li><li id="f171" class="oc od it lb b lc ol lf om li on lm oo lq op lu oh oi oj ok bi translated">我们接下来通过一个<strong class="lb iu">再逻辑单元函数</strong>运行它。这给该层带来了一些非线性，允许 CNN 理解输入的复杂图片。</li><li id="00e7" class="oc od it lb b lc ol lf om li on lm oo lq op lu oh oi oj ok bi translated">下一行是<strong class="lb iu">汇集</strong>发生的地方。我们已经将池过滤器大小定义为 2x2，并使用最大池。这进一步减小了矩阵的大小。</li><li id="58ba" class="oc od it lb b lc ol lf om li on lm oo lq op lu oh oi oj ok bi translated">最后，矩阵通过一个<strong class="lb iu">漏失</strong>层。丢弃层的作用是随机丢弃神经网络中的节点。删除节点的好处是网络对每个节点的权重变得不那么敏感。这使得网络的预测更加一般化，提高了准确性。在所使用的模型中，我们丢弃了 25%的现有节点，这些节点将在下一层中被新节点替换。</li></ol><p id="5ad7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第一卷积层的输出现在成为下一层的输入。矩阵已经变得越来越小，但通过更多的层，它变得更小，只显示照片的关键部分进行分类。这些步骤发生 4 次，唯一改变的是卷积过程中使用的滤波器大小和滤波器数量。</p></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><p id="8aee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">全连接层</strong></p><p id="26b3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">卷积后，是时候完全连接的层。但是在这之前，数据被展平到一个列向量中。</p><ol class=""><li id="8065" class="oc od it lb b lc ld lf lg li oe lm of lq og lu oh oi oj ok bi translated">现在数据可以通过神经网络，使用了一个<strong class="lb iu">密集层</strong>。致密层相当于神经网络。它传递来自前面步骤的输入，并将其全部输出到它的神经元。神经元相互连接，将数据从一层传递到下一层。在这种情况下，有 256 个神经元。</li><li id="4b4a" class="oc od it lb b lc ol lf om li on lm oo lq op lu oh oi oj ok bi translated">然后经过<strong class="lb iu">批量归一化</strong>。</li><li id="5839" class="oc od it lb b lc ol lf om li on lm oo lq op lu oh oi oj ok bi translated">然后使用<strong class="lb iu"> ReLU 功能</strong>进行激活。</li><li id="1edc" class="oc od it lb b lc ol lf om li on lm oo lq op lu oh oi oj ok bi translated">最后，使用<strong class="lb iu"> dropout </strong>再次丢弃 25%的节点。</li><li id="3d6b" class="oc od it lb b lc ol lf om li on lm oo lq op lu oh oi oj ok bi translated">有两个完全连接的层，所以代码重复 512 个节点。</li><li id="7e5f" class="oc od it lb b lc ol lf om li on lm oo lq op lu oh oi oj ok bi translated">一旦通过第二个完全连接的层，输出通过一个<strong class="lb iu"> softmax 函数</strong>，该函数用于给出图像属于 29 个类别之一的概率。</li><li id="baef" class="oc od it lb b lc ol lf om li on lm oo lq op lu oh oi oj ok bi translated">最后几行设置<strong class="lb iu">学习率</strong>并评估模型的<strong class="lb iu">精度</strong>。</li></ol><h1 id="f60c" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated"><strong class="ak">培训</strong></h1><p id="a85e" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">既然我们已经定义了模型，我们必须训练它。训练模型是 CNN 活起来的地方。训练是“过滤器和全连接层的权重是多少？”已回答。CNN 使用反向传播来定义所有层的权重。反向传播包括四个步骤:向前传递、损失函数、向后传递和最后的权重更新。</p><p id="c12b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 1) </strong></p><p id="e0a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正向传递由穿过模型的图像组成。首先，所有的权重和偏差都是随机的，因此分类也是随机的。这是因为模型，特别是滤波器不知道如何识别图像的边缘和特征。</p><p id="6e50" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 2) </strong></p><p id="8382" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">分类精度用损失函数来表示。损失函数告诉你你的模型对每张图片的分类有多好。它将图像的预测标签与训练图像的实际标签进行比较。在我们的案例中，分类交叉熵被用作损失函数。</p><p id="7068" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 3) </strong></p><p id="7b92" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，是反向传递，其识别哪个权重导致损失函数高。</p><p id="1596" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 4) </strong></p><p id="642d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当这些权重被识别时，权重被更新，使得损失减少。学习率指定了权重可以改变的程度。最终，目标是让预测的标签始终与图片的实际标签相匹配。</p></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><h1 id="f459" class="lx ly it bd lz ma nf mc md me ng mg mh jz nh ka mj kc ni kd ml kf nj kg mn mo bi translated"><strong class="ak">结果</strong></h1><p id="0e6b" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">经过 50 个时期的训练，该模型在数据集内达到了 100%的验证准确性。这相当令人印象深刻，但该模型能够达到 100%的准确性有一个明确的原因:数据集。当查看数据集中一个类别的图片时，它们实际上都是相同背景上的相同照片。因此，该模型很容易达到 100%的准确性，因为每张照片之间没有太多的变化，从而非常快地达到高准确性。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/ca05a964dc14be27ba5d7c14f4448b82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KYSvc7kBRmBRKNqF4ligUw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">各时期模型的损失和准确性图表</p></figure><h1 id="59ef" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated"><strong class="ak">现场预测</strong></h1><p id="1531" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">我仍然想让模型执行实时预测，以实现制作实时翻译器的目标。使用 cv2，我能够利用笔记本电脑上的网络摄像头捕捉帧，并通过模型发送它们，以预测每个帧的类别。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="or os l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">字母表的前几个字母</p></figure><p id="1a6d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">成功了！它能够预测大多数字母，但由于数据集范围有限以及我缺乏手语知识，有时会遇到困难。它也只翻译了美国手语字母，而不是单词，但这是一个开始！</p></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><p id="0faa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个项目制作起来非常有趣，因为最终的结果非常值得。请继续关注我的下一个版本！</p></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><p id="23aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lw">联系我:</em></p><p id="2417" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lw">领英:</em><a class="ae ky" href="https://www.linkedin.com/in/vikram-menon-986a67193" rel="noopener ugc nofollow" target="_blank"><em class="lw">https://www.linkedin.com/in/vikram-menon-986a67193</em></a></p><p id="4f09" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lw">电子邮件:vikrammenon03@gmail.com</em></p></div></div>    
</body>
</html>