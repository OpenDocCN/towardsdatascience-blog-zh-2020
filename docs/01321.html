<html>
<head>
<title>Food for Thought — Paper Tuesday</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">思考的食粮——纸星期二</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/food-for-thought-paper-tuesday-3c0a9b3e432f?source=collection_archive---------38-----------------------#2020-02-05">https://towardsdatascience.com/food-for-thought-paper-tuesday-3c0a9b3e432f?source=collection_archive---------38-----------------------#2020-02-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9968" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用形状偏差数据提高了准确性和鲁棒性</h2></div><p id="9241" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">每周二，我都会强调我在研究或工作中遇到的一篇有趣的论文。希望我的评论能帮助你在 2 分钟内获得论文中最多汁的部分！</p><h1 id="1ab0" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">基本思想</h1><p id="b2e3" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">人们普遍认为，CNN 通过提取曲线和边缘等形状特征来学习图像。然而，来自图宾根大学和爱丁堡的一组研究人员在他们的 ICLR 2019 论文中挑战了这一信念<em class="ly"> ImageNet 训练的 CNN 偏向于纹理；增加形状偏差可以提高精确度和鲁棒性</em>。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi lz"><img src="../Images/f10cb32b74c3dcd78234630125e8b2d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pYZnVleUoR1Sg-QklBMkcA.png"/></div></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">来自<a class="ae mp" href="https://openreview.net/pdf?id=Bygh9j09KX" rel="noopener ugc nofollow" target="_blank">的论文</a></p></figure><p id="91b1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面是链接:【https://openreview.net/pdf?id=Bygh9j09KX】T4</p><p id="310b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过巧妙设计几个实验，研究人员证明了 CNN 比人们预期的更偏向于图像纹理。由此，他们进一步发现，形状增强数据集可以作为一种有效的数据增强方法，提高模型的准确性和鲁棒性。</p><p id="7177" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">研究人员认为，CNN 严重偏向于局部特征，这可能是由于卷积滤波器的感知范围较小。他们的论点得到了 CNN 在无纹理图像上令人惊讶的低性能的支持，如下图所示</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/39377d2e3a4a8217675167265db0112d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*AB1vRObNksAqcPs3UFbjCg.png"/></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">摘自<a class="ae mp" href="https://openreview.net/pdf?id=Bygh9j09KX" rel="noopener ugc nofollow" target="_blank">论文</a></p></figure><p id="96f8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如图所示，当纹理信息(轮廓和边缘)被移除时，所有主流架构如 AlexNet、GoogleNet 和 VGG16 都经历了显著的性能下降。同时，只要存在纹理(纹理)，即使当形状信息被移除时，CNN 也产生高置信度。</p><h1 id="c933" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">结果</h1><p id="bd19" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">为了进一步测试他们的假设，研究人员生成了一个新的数据集，称为风格化图像网(SIN)，其图像的局部纹理特征被无信息的随机特征所取代。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/0901f6cfbac707f910c84e92c66a6b4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*5EYVoCAPQqd87d_wsENTWg.png"/></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">来自<a class="ae mp" href="https://openreview.net/pdf?id=Bygh9j09KX" rel="noopener ugc nofollow" target="_blank">的论文</a></p></figure><p id="6de4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果 CNN 偏向于局部纹理特征，我们可以预期在原始 ImageNet 数据集上训练的 CNN 在 SIN 上表现不佳。事实的确如此，如下表所示</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi mr"><img src="../Images/bba5da37ef657c4ef5498f1c861ef3db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oSsBDvM4uDur-Fd66y5FHA.png"/></div></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">来自<a class="ae mp" href="https://openreview.net/pdf?id=Bygh9j09KX" rel="noopener ugc nofollow" target="_blank">的论文</a></p></figure><p id="c1fe" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">好了，现在我们确信 CNN 偏向于本地纹理。但是我们如何利用这些信息呢？研究人员证明，在 SIN 和 IN 上联合训练的模型对图像失真(噪声、裁剪、过滤等)更具鲁棒性，并在图像分类和对象检测方面实现了出色的准确性。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi ms"><img src="../Images/0faa8dc39ae21ed64a36cad2d790195c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x_jh1t2RZdLP4jXA5A63Zw.png"/></div></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">来自<a class="ae mp" href="https://openreview.net/pdf?id=Bygh9j09KX" rel="noopener ugc nofollow" target="_blank">的论文</a></p></figure><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi mt"><img src="../Images/4ee7266a6aff847254d7d5886cc7f8e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pDD6F4Dcf-KfUxZ_GRNY8A.png"/></div></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">来自<a class="ae mp" href="https://openreview.net/pdf?id=Bygh9j09KX" rel="noopener ugc nofollow" target="_blank">的论文</a></p></figure><h1 id="ec4d" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">一些想法</h1><p id="91fa" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">很长一段时间，我相信 CNN 有能力进行图像分类，因为它有强大的边缘检测器。这篇论文为我们打开了一扇新的门——有许多关于神经网络的手工解释和理解。要理解哪怕是一种最简单的神经网络形式，还有大量的理论工作要做！</p></div></div>    
</body>
</html>