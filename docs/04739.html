<html>
<head>
<title>Using Association Rules for HR Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用关联规则进行人力资源分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-association-rules-with-categorical-data-e984f8bb8ee4?source=collection_archive---------32-----------------------#2020-04-26">https://towardsdatascience.com/using-association-rules-with-categorical-data-e984f8bb8ee4?source=collection_archive---------32-----------------------#2020-04-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="450d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">或者:如何将Apriori用于购物篮商店分析之外的数据</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/52210b9372c0dc7f2b46b474a30f09bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QbWawzvbQj3ChVoS"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">米卡·鲍梅斯特在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="e96a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated"><span class="l lw lx ly bm lz ma mb mc md di"> A </span>关联规则算法，如<strong class="lb iu"> Apriori </strong>是一种很好的方法，可以找到数据集中经常出现的项目，并查看它们之间的关系。<br/>这是一种无监督的机器学习模型，通常用于发现交易中的关系，例如客户购买。</p><p id="36a7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果一个项目的出现次数<em class="me">大于我们设置的阈值</em>，则该项目被认为是频繁的。如果您有100行数据，并将阈值设置为0.1，那么发生10次以上的所有数据都会显示在我们的结果中。</p><p id="390d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这个例子中，我们将对不同类型的问题使用先验知识。我们将使用包含年龄、性别、教育水平等信息的人力资源数据集，我们将尝试找出员工<em class="me">没有流失</em>时出现的常见特征。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="4a28" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先快速回顾一下主要的先验要素:</p><blockquote class="mm mn mo"><p id="88fc" class="kz la me lb b lc ld ju le lf lg jx lh mp lj lk ll mq ln lo lp mr lr ls lt lu im bi translated"><strong class="lb iu"> <em class="it">支持</em> </strong> <em class="it">是一个项目出现多少次</em> <br/> freq(A，B)/Total</p><p id="b245" class="kz la me lb b lc ld ju le lf lg jx lh mp lj lk ll mq ln lo lp mr lr ls lt lu im bi translated"><strong class="lb iu"> <em class="it">置信度</em> </strong> <em class="it">是给定A发生的概率</em> <br/> freq(A，B)/freq(A)</p><p id="835e" class="kz la me lb b lc ld ju le lf lg jx lh mp lj lk ll mq ln lo lp mr lr ls lt lu im bi translated"><strong class="lb iu"> <em class="it"> Lift </em> </strong> <em class="it">类似于confidence但这也说明了B有多受欢迎</em> <br/> freq(A，B)/support(A)*Support(B)</p></blockquote></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="f407" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本例中，我们将使用Kaggle的IBM HR Analytics员工流失和绩效，您可以从以下链接下载:</p><div class="ms mt gp gr mu mv"><a href="https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset" rel="noopener  ugc nofollow" target="_blank"><div class="mw ab fo"><div class="mx ab my cl cj mz"><h2 class="bd iu gy z fp na fr fs nb fu fw is bi translated">IBM HR Analytics员工流失和绩效</h2><div class="nc l"><h3 class="bd b gy z fp na fr fs nb fu fw dk translated">预测你有价值的员工的流失</h3></div><div class="nd l"><p class="bd b dl z fp na fr fs nb fu fw dk translated">www.kaggle.com</p></div></div><div class="ne l"><div class="nf l ng nh ni ne nj ks mv"/></div></div></a></div><p id="f58b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这段代码将使用MLxtend库(<a class="ae ky" href="http://rasbt.github.io/mlxtend/" rel="noopener ugc nofollow" target="_blank">http://rasbt.github.io/mlxtend/</a>)用Python编写</p><p id="b003" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们导入我们的库。这个项目只需要<strong class="lb iu">熊猫</strong>和<strong class="lb iu"> MLxtend </strong>。</p><pre class="kj kk kl km gt nk nl nm nn aw no bi"><span id="da3a" class="np nq it nl b gy nr ns l nt nu">import pandas as pd<br/>from mlxtend.frequent_patterns import apriori<br/>from mlxtend.frequent_patterns import association_rules</span></pre><p id="5ab9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在阅读完数据后，我们可以看到有35列需要处理，但是我们将只使用我们认为更有趣的几列。</p><p id="1b17" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有几个使用起来不错的列，但是它们<strong class="lb iu">不是分类的</strong>，所以我们能做的是为它们创建<em class="me">库</em>。Pandas <strong class="lb iu"> qcut </strong>函数可以为我们将年龄、离家距离和小时列分成4个箱。</p><pre class="kj kk kl km gt nk nl nm nn aw no bi"><span id="fa13" class="np nq it nl b gy nr ns l nt nu">pd.qcut(df['Age'], q=4)</span></pre><p id="d183" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这段代码向我们展示了年龄列可以分为以下四类:</p><p id="0ec9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="me">类别(4，区间[float64]): [(17.999，30.0] &lt; (30.0，36.0] &lt; (36.0，43.0】&lt;【43.0，60.0】]</em></p><p id="0804" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，我们可以像这样创建一个Age_Range列:</p><pre class="kj kk kl km gt nk nl nm nn aw no bi"><span id="87b5" class="np nq it nl b gy nr ns l nt nu">df['Age_Range'] = pd.qcut(df['Age'], q=4, labels=['&lt;=30', '&gt;30 &lt;=36', '&gt;36 &lt;=43', '&gt;43'])</span></pre><p id="cf09" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对DistanceFromHome和HourlyRate做了同样的操作后，现在我们必须为算法准备数据。Apriori只接受<strong class="lb iu">布尔值</strong>，所以我们不会发送包含“单身”、“已婚”和“离婚”值的MaritalStatus列，而是将它转换为3个不同的列，分别称为“MaritalStatus _单身”、“MaritalStatus _已婚”和“MaritalStatus _离婚”，其中包含0或1值。</p><p id="ba8f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为此，熊猫<strong class="lb iu"> get_dummies </strong>函数可以用于每个需要转换的列。首先，我们将创建一个包含所有将要使用的列的列表，以及另一个包含剩余列的列表。在使用get_dummies之后，原始列将被删除，只有布尔列会在那里，但是，未使用的列仍然在那里，所以我们删除它们。</p><pre class="kj kk kl km gt nk nl nm nn aw no bi"><span id="cb30" class="np nq it nl b gy nr ns l nt nu">columns = ['Attrition',<br/>          'Age_Range',<br/>          'BusinessTravel',<br/>          'Department',<br/>          'DistanceFromHome_Range',<br/>          'Education',<br/>          'EducationField',<br/>          'EnvironmentSatisfaction',<br/>          'Gender',<br/>          'HourlyRate_Range',<br/>          'JobInvolvement',<br/>          'JobLevel',<br/>          'JobRole',<br/>          'JobSatisfaction',<br/>          'MaritalStatus']</span><span id="cda4" class="np nq it nl b gy nv ns l nt nu">not_used_columns = list(set(df.columns.to_list()) - set(columns))</span><span id="1226" class="np nq it nl b gy nv ns l nt nu">df = pd.get_dummies(df, columns=columns)</span><span id="aecc" class="np nq it nl b gy nv ns l nt nu">df.drop(labels=not_used_columns, axis=1, inplace=True)</span></pre><p id="0cea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们有了一个数据框架，可以使用并生成频繁项。</p><p id="2579" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的数据集总共有1470行，所以让我们开始选择0.05 的<em class="me">最小支持。这意味着只有在我们的数据中发生<strong class="lb iu">超过</strong>73次的结果才会被考虑。而<em class="me"> max_len </em>是antecedents列中生成的列组合的数量。</em></p><pre class="kj kk kl km gt nk nl nm nn aw no bi"><span id="9277" class="np nq it nl b gy nr ns l nt nu">#Apriori min support<br/>min_support = 0.05</span><span id="bbc4" class="np nq it nl b gy nv ns l nt nu">#Max lenght of apriori n-grams<br/>max_len = 3</span><span id="006c" class="np nq it nl b gy nv ns l nt nu">frequent_items = apriori(df, use_colnames=True, min_support=min_support, max_len=max_len + 1)</span><span id="2ccb" class="np nq it nl b gy nv ns l nt nu">rules = association_rules(frequent_items, metric='lift', min_threshold=1)</span><span id="303b" class="np nq it nl b gy nv ns l nt nu">rules.head(10).sort_values(by='confidence', ascending=False)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/2b164792e03f00aa45d947bbbce4fa4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*La-sTQsRhYrw2Q7HNPGQHA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">关联规则结果</p></figure><p id="1d2d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就是这样！现在，您可以看到数据集中的频繁关系。</p><p id="1b36" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是，如果我们只想知道在结果列中是什么给出了<strong class="lb iu">‘attraction _ Yes’</strong>还是<strong class="lb iu">‘attraction _ No’</strong>呢？</p><p id="aee8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，让我们看看在我们的数据帧中每种情况出现了多少次。</p><pre class="kj kk kl km gt nk nl nm nn aw no bi"><span id="a343" class="np nq it nl b gy nr ns l nt nu">df['Attrition_No'].value_counts()</span><span id="5c74" class="np nq it nl b gy nv ns l nt nu">#1     1233<br/>#0     237<br/>#Name: Attrition_No, dtype: int64</span></pre><p id="74b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="me">否</em>的情况比<em class="me">是</em>的情况多得多，所以我们在选择阈值时也需要考虑到这一点，因为一个比另一个更常见。</p><p id="f4f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于<em class="me">否</em>，让我们将阈值增加到0.1，并过滤<strong class="lb iu">损耗_否</strong>的后续列:</p><pre class="kj kk kl km gt nk nl nm nn aw no bi"><span id="994a" class="np nq it nl b gy nr ns l nt nu">#Apriori min support<br/>min_support = 0.1</span><span id="029c" class="np nq it nl b gy nv ns l nt nu">#Max lenght of apriori n-grams<br/>max_len = 3</span><span id="5173" class="np nq it nl b gy nv ns l nt nu">frequent_items = apriori(df, use_colnames=True, min_support=min_support, max_len=max_len + 1)<br/>rules = association_rules(frequent_items, metric='lift', min_threshold=1)</span><span id="50ab" class="np nq it nl b gy nv ns l nt nu">target = '{\'Attrition_No\'}'</span><span id="4913" class="np nq it nl b gy nv ns l nt nu">results_attrition_no = rules[rules['consequents'].astype(str).str.contains(target, na=False)].sort_values(by='confidence', ascending=False)</span><span id="e4da" class="np nq it nl b gy nv ns l nt nu">results_attrition_no.head(10)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/d9bb056abb663cd50cb229d137d3429e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y1bXaZrcGMpXCXslGaDOyg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">关联规则结果在结果列中只有attachment _ No</p></figure><p id="e9ed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们可以看到，在我们的数据集中，来自研发部门、工作级别为2的人出现的几率为11%,然而<strong class="lb iu">几乎95%的</strong> <strong class="lb iu">都没有自然减员</strong>。</p><p id="49aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">附注:前提和结果列是如下所示的冷冻集:</p><p id="d837" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="me">array([frozenset({ ' job satisfaction _ 4 '，' JobLevel_2'})，<br/>frozenset({ ' Department _ Research _&amp;_ Development '，' JobLevel_2'})，<br/>frozenset({ ' Department _ Research _&amp;_ Development '，' job inclusion _ 3 '，' job level _ 2 ' })……</em></p><p id="5f30" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您想美化它并导出这个结果，您可以使用这段代码:</p><pre class="kj kk kl km gt nk nl nm nn aw no bi"><span id="5c24" class="np nq it nl b gy nr ns l nt nu">df['antecedents'] = df['antecedents'].apply(lambda x: ','.join(list(x))).astype('unicode')</span><span id="cc08" class="np nq it nl b gy nv ns l nt nu">df['antecedents'] = df['antecedents'].str.title().str.replace('_', ' ')</span></pre><p id="085b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们将阈值更改为0.02，看看<strong class="lb iu">损耗有多少_是</strong>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/ec729086904b63224b15b73a1e1e69c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hmpVnIdypk8VnTdIM-KTpQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">关联规则结果在结果列中只有Attrition _ Yes</p></figure><p id="a0e4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">信心最大的是30岁以下，单身，工作一级的人。但与前一个案例不同的是，<em class="me">这些案例中只有45%的人出现流失</em>。</p><p id="34ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是对HR数据使用Apriori的基础！希望您在下一个项目中尝试一下，并在您的数据集中找到新的关系，这可以让您对您的问题有更多的见解。</p><p id="6453" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在这里下载所有用来创建这个帖子的笔记本:<a class="ae ky" href="https://gist.github.com/eduardoftdo/e3d2b7ca4a06d8d86b144482d0aed5a1" rel="noopener ugc nofollow" target="_blank">https://gist . github . com/eduardoftdo/e 3d 2 b 7 ca 4a 06 D8 d 86 b 144482d 0 aed 5 a 1</a></p><p id="958c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您有任何问题，并希望与我联系，请随时发送消息到https://www.linkedin.com/in/eduardo-furtado/<a class="ae ky" href="https://www.linkedin.com/in/eduardo-furtado/" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>