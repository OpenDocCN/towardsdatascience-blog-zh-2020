<html>
<head>
<title>An intuitive explanation of word2vec</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">word2vec的直观解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-intuitive-explanation-of-word2vec-208bed0a0599?source=collection_archive---------24-----------------------#2020-01-29">https://towardsdatascience.com/an-intuitive-explanation-of-word2vec-208bed0a0599?source=collection_archive---------24-----------------------#2020-01-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/85efe6300919f232dcf3128c33ff3a16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TV_HnXgPcQ9WeTnXe4R4Qw.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">照片由<a class="ae jg" href="https://unsplash.com/@anphotos?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">阿克谢·纳纳瓦蒂</a>在<a class="ae jg" href="https://unsplash.com/s/photos/matrix?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><div class=""/><div class=""><h2 id="9606" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">没有数学，没有代码，只有单词嵌入背后的逻辑</h2></div><h2 id="c6ec" class="ky kz jj bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">对单词嵌入的需求</h2><p id="20db" class="pw-post-body-paragraph lu lv jj lw b lx ly kk lz ma mb kn mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">在传统的监督机器学习任务中，数据科学家需要两个关键要素:</p><ol class=""><li id="3abe" class="mn mo jj lw b lx mp ma mq lh mr ll ms lp mt mm mu mv mw mx bi translated">数据</li><li id="473b" class="mn mo jj lw b lx my ma mz lh na ll nb lp nc mm mu mv mw mx bi translated">发现数据模式的方法(算法)</li></ol><p id="5b24" class="pw-post-body-paragraph lu lv jj lw b lx mp kk lz ma mq kn mc lh nd me mf ll ne mh mi lp nf mk ml mm im bi translated">反过来，计算机可以做两件事:</p><ol class=""><li id="86ea" class="mn mo jj lw b lx mp ma mq lh mr ll ms lp mt mm mu mv mw mx bi translated">通过将算法应用于数据来学习模式</li><li id="e71d" class="mn mo jj lw b lx my ma mz lh na ll nb lp nc mm mu mv mw mx bi translated">使用这些学习到的模式对新数据进行预测</li></ol><p id="4da1" class="pw-post-body-paragraph lu lv jj lw b lx mp kk lz ma mq kn mc lh nd me mf ll ne mh mi lp nf mk ml mm im bi translated">一个经典的例子——我们取了一些关于不同花的数据点(即花瓣长度，花瓣宽度)，我们选择一个分类算法(即。随机森林)，我们的计算机使用该算法来识别模式并对其他花卉进行分类。</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ng"><img src="../Images/c06faaacfdaa01278fd1c4b769873f88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4SV0O3FfKrzaBUlVkjlQKg.png"/></div></div></figure><p id="6b54" class="pw-post-body-paragraph lu lv jj lw b lx mp kk lz ma mq kn mc lh nd me mf ll ne mh mi lp nf mk ml mm im bi translated">将这种通用方法联系在一起的一个关键因素是，数据科学家用计算机理解的语言——数字——与计算机交流。提供的“数据”必须是数字，这样才能工作。</p><p id="9e91" class="pw-post-body-paragraph lu lv jj lw b lx mp kk lz ma mq kn mc lh nd me mf ll ne mh mi lp nf mk ml mm im bi translated">那么，当我们拥有的“数据”是文本而不是数字时，我们能做什么呢？当花瓣长度= 1.4厘米，花瓣宽度= 0.2厘米时，我们有一个句子——“我爱数据。”自然，我们必须找到一种方法将文本转换成数字。</p><p id="0584" class="pw-post-body-paragraph lu lv jj lw b lx mp kk lz ma mq kn mc lh nd me mf ll ne mh mi lp nf mk ml mm im bi translated">一种方法是简单地创建用1和0表示单词的数据点。整个词典中的每个单词都成为一个数据点，只有给定句子、短语或文档中的单词被标记为1。</p><p id="8b4b" class="pw-post-body-paragraph lu lv jj lw b lx mp kk lz ma mq kn mc lh nd me mf ll ne mh mi lp nf mk ml mm im bi translated">例如，如果整个字典包含单词“I”、“love”、“data”、“Is”和“Cool”，我们对句子“I love data”的表示将是[1，1，1，0，0]，其中前三个1表示存在“I”、“Love”和“Data”，后面的零表示不存在“Is”和“Cool”。“爱很酷”这句话看起来应该是这样的:[0，1，0，1，1]。</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nl"><img src="../Images/c7bceb99ddec55f1ac37c5d6a417f157.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eP78OGsETi8H8nXMEIf9zQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">句子的一键编码表示</p></figure><p id="b59d" class="pw-post-body-paragraph lu lv jj lw b lx mp kk lz ma mq kn mc lh nd me mf ll ne mh mi lp nf mk ml mm im bi translated">如果我们将上面的例子扩展到有更多单词的字典，我们现在有一个可伸缩的方法将文本转换成数字。这种方法被称为“一个热门编码”或“一袋单词”——通常对文本分类和情感分析等事情非常有用。例如，我可以将许多不同的推文转换成这些数字列表，然后训练一个模型来预测推文是正面还是负面(我可以使用数字1表示正面，0表示负面)。</p><p id="7f99" class="pw-post-body-paragraph lu lv jj lw b lx mp kk lz ma mq kn mc lh nd me mf ll ne mh mi lp nf mk ml mm im bi translated">虽然这种方法有其优点，但它在几个关键方面失败了:</p><ol class=""><li id="6541" class="mn mo jj lw b lx mp ma mq lh mr ll ms lp mt mm mu mv mw mx bi translated"><strong class="lw jk">没有意义感或上下文感:</strong>计算机可以学习包含“欣喜若狂”这个词的推文是一条快乐的推文，但它无法学习“欣喜若狂”这个词与“激动不已”这个词几乎同义，与“失望”这个词几乎相反。</li><li id="ebb6" class="mn mo jj lw b lx my ma mz lh na ll nb lp nc mm mu mv mw mx bi translated"><strong class="lw jk">太多的数据点:</strong>为了对字典中每个单词的存在或不存在进行编码，每个单词都需要一个数据点(又名变量或特征)。英语中大约有一百万个单词<a class="ae jg" href="https://englishlive.ef.com/blog/language-lab/many-words-english-language/" rel="noopener ugc nofollow" target="_blank">。</a></li></ol><p id="174b" class="pw-post-body-paragraph lu lv jj lw b lx mp kk lz ma mq kn mc lh nd me mf ll ne mh mi lp nf mk ml mm im bi translated">解决方案是创建数字列表(线性代数术语中的“向量”)，以更有创意的方式表示单词。这被称为单词嵌入。</p><p id="631d" class="pw-post-body-paragraph lu lv jj lw b lx mp kk lz ma mq kn mc lh nd me mf ll ne mh mi lp nf mk ml mm im bi translated">Word2Vec是Google在2013年开发的一种建模方法，用于创建这样的嵌入。(Word2Vec旗下有几种不同的型号。我在下面概述了跳过克的方法)。</p><h2 id="4892" class="ky kz jj bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">创建复杂的单词嵌入</h2><p id="45e4" class="pw-post-body-paragraph lu lv jj lw b lx ly kk lz ma mb kn mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">为了克服单词袋方法的不足，我们需要一个系统来为相似的单词创建彼此相似的向量。</p><p id="63bd" class="pw-post-body-paragraph lu lv jj lw b lx mp kk lz ma mq kn mc lh nd me mf ll ne mh mi lp nf mk ml mm im bi translated">例如，单词dog和cat应该用比单词dog和orange更接近的数字来表示。大概是这样的:</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/c2c6d024fb7e306035e885ff21e959c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*vuBtxYCrQFED6xgCWEDsig.png"/></div></figure><p id="55fe" class="pw-post-body-paragraph lu lv jj lw b lx mp kk lz ma mq kn mc lh nd me mf ll ne mh mi lp nf mk ml mm im bi translated">为了创建这个系统，我们可以通过查看文本中“附近”的单词来利用上下文。例如，它可以了解到狗和猫有些相似，因为它们出现在句子中“treat”和“playing”这样的词附近:</p><blockquote class="nn no np"><p id="b020" class="lu lv nq lw b lx mp kk lz ma mq kn mc nr nd me mf ns ne mh mi nt nf mk ml mm im bi translated">“我给了我的狗一份礼物”</p><p id="299f" class="lu lv nq lw b lx mp kk lz ma mq kn mc nr nd me mf ns ne mh mi nt nf mk ml mm im bi translated">“我的狗喜欢玩捡球游戏”</p><p id="6280" class="lu lv nq lw b lx mp kk lz ma mq kn mc nr nd me mf ns ne mh mi nt nf mk ml mm im bi translated">“我的猫喜欢这种款待”</p><p id="bc5b" class="lu lv nq lw b lx mp kk lz ma mq kn mc nr nd me mf ns ne mh mi nt nf mk ml mm im bi translated">“我总是看到我的猫在玩那个玩具”</p></blockquote><p id="ba1e" class="pw-post-body-paragraph lu lv jj lw b lx mp kk lz ma mq kn mc lh nd me mf ll ne mh mi lp nf mk ml mm im bi translated">现在——困难的部分——我们如何教计算机解决这个问题？</p><p id="9be6" class="pw-post-body-paragraph lu lv jj lw b lx mp kk lz ma mq kn mc lh nd me mf ll ne mh mi lp nf mk ml mm im bi translated">Word2vec的方法是训练一个模型，该模型可以预测整个文本(语料库)中每个单词的每次出现的所有相邻单词。</p><p id="4e12" class="pw-post-body-paragraph lu lv jj lw b lx mp kk lz ma mq kn mc lh nd me mf ll ne mh mi lp nf mk ml mm im bi translated">我们可以将我们正在关注的每个单词称为“中心单词”，将每个邻近的单词称为“上下文单词”。同样，我们试图预测全文中每个中心词的每次出现的所有上下文词。</p><p id="0e36" class="pw-post-body-paragraph lu lv jj lw b lx mp kk lz ma mq kn mc lh nd me mf ll ne mh mi lp nf mk ml mm im bi translated">下面是我们将用来训练模型的前9个“实例”，给定上面的句子，并假设窗口为2(该窗口指定我们应该在每个中心单词的左右两侧寻找多少个点):</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/13a1a0e5c3abaa84bdda3ae18aaa2233.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*H7d7nRMS4BDWiP4rL7FIqg.png"/></div></figure><p id="8737" class="pw-post-body-paragraph lu lv jj lw b lx mp kk lz ma mq kn mc lh nd me mf ll ne mh mi lp nf mk ml mm im bi translated">为了对每个训练实例进行预测，我们从字典中每个单词的随机数字向量开始。同样，我们这个练习的最终目标是让相似的单词有相似的向量。</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nv"><img src="../Images/4d4c394aaa0b48f3fda47453727cfe01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G73ActKfyKou8nhIRD1twA.png"/></div></div></figure><p id="93e3" class="pw-post-body-paragraph lu lv jj lw b lx mp kk lz ma mq kn mc lh nd me mf ll ne mh mi lp nf mk ml mm im bi translated">在这个例子中，每个单词向量的长度为3，但是理论上它可以是我们指定的任何长度。</p><p id="4139" class="pw-post-body-paragraph lu lv jj lw b lx mp kk lz ma mq kn mc lh nd me mf ll ne mh mi lp nf mk ml mm im bi translated">一旦我们有了这些“起始向量”，我们就使用文本中的每个中心词/上下文词对来遵循以下步骤:</p><ol class=""><li id="5396" class="mn mo jj lw b lx mp ma mq lh mr ll ms lp mt mm mu mv mw mx bi translated"><strong class="lw jk">将中心单词向量乘以单词表示的完整矩阵。</strong>这个矩阵是所有其他单词向量的简单水平堆叠(行)。当这个乘法完成后，我们剩下一个向量，它有一个元素代表字典中的每个单词。下面是一个简单的视觉:</li></ol><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nw"><img src="../Images/7382ece9494f490214a952ddeab83d4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R4e3EeoD_9bgic2rVlrdQg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">实际上，我们对每个上下文单词都有一个“结果向量”。</p></figure><p id="ddda" class="pw-post-body-paragraph lu lv jj lw b lx mp kk lz ma mq kn mc lh nd me mf ll ne mh mi lp nf mk ml mm im bi translated"><strong class="lw jk"> 2。将向量转换成概率。</strong>这里我们使用的是softmax函数，它实际上是将每个数字除以向量中所有数字的总和。这给了我们一个有用的特性，即新向量中的所有数字的总和都是1。它们现在可以被认为是概率。</p><p id="3d75" class="pw-post-body-paragraph lu lv jj lw b lx mp kk lz ma mq kn mc lh nd me mf ll ne mh mi lp nf mk ml mm im bi translated">3.<strong class="lw jk">计算概率。</strong>现在我们有了一个概率向量，我们的下一步是将它与“目标变量”<strong class="lw jk"> </strong>(基础事实)进行比较。<strong class="lw jk"> </strong>我们如何表示那些目标变量？我们只需要一个热编码。一个向量，上下文单词用1表示，其他单词用0表示。</p><p id="c589" class="pw-post-body-paragraph lu lv jj lw b lx mp kk lz ma mq kn mc lh nd me mf ll ne mh mi lp nf mk ml mm im bi translated">然后我们可以计算一个损失函数(你的预测有多错误的分数)。这鼓励系统调整其预测向量，使得它们在更可能出现在上下文中的单词上具有更大的<em class="nq">权重</em>。</p><p id="e1a0" class="pw-post-body-paragraph lu lv jj lw b lx mp kk lz ma mq kn mc lh nd me mf ll ne mh mi lp nf mk ml mm im bi translated">系统<strong class="lw jk"> <em class="nq">怎么知道</em> </strong>去调整这些向量值也就是所谓的权重？</p><p id="bfeb" class="pw-post-body-paragraph lu lv jj lw b lx mp kk lz ma mq kn mc lh nd me mf ll ne mh mi lp nf mk ml mm im bi translated">4.<strong class="lw jk">尽量减少损失。</strong>最后一步——反向传播——是神经网络调整其权重以最小化损失函数的过程。在这种情况下，权重是每个词向量的值。它们调整得越好，预测向量就越精确，损失就越低。</p><p id="3ef2" class="pw-post-body-paragraph lu lv jj lw b lx mp kk lz ma mq kn mc lh nd me mf ll ne mh mi lp nf mk ml mm im bi translated">突然间，最初随机的权重被收紧，以创造我们所寻求的现实:彼此相似的词向量具有相似的数字<strong class="lw jk">，因为这些数字最小化了损失函数</strong>。他们为什么要最小化损失函数？因为它们准确地预测了相同的上下文单词。</p><h2 id="7cf0" class="ky kz jj bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated"><strong class="ak">申请</strong></h2><p id="238e" class="pw-post-body-paragraph lu lv jj lw b lx ly kk lz ma mb kn mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">最终，我们对文本中的每个单词都进行了随机加权，并对它们进行了优化以表达含义，从而构建了一种新的与计算机对话的方言。下面是3个例子，说明如何使用生成的向量:</p><ol class=""><li id="eb14" class="mn mo jj lw b lx mp ma mq lh mr ll ms lp mt mm mu mv mw mx bi translated"><strong class="lw jk">文本分类</strong> — <strong class="lw jk"> </strong>通过平均/组合单词向量，以无数不同的方式对文本进行分类。</li><li id="c209" class="mn mo jj lw b lx my ma mz lh na ll nb lp nc mm mu mv mw mx bi translated"><strong class="lw jk">语音识别</strong> —将口语单词转换成矢量，以便识别意思。</li><li id="8ba1" class="mn mo jj lw b lx my ma mz lh na ll nb lp nc mm mu mv mw mx bi translated"><strong class="lw jk">建议</strong> — <strong class="lw jk"> </strong>创建任何有“上下文”的数字表示例如，<a class="ae jg" rel="noopener" target="_blank" href="/using-word2vec-for-music-recommendations-bb9649ac2484">歌曲</a>可以表示为预测播放列表或队列中附近歌曲的向量。</li></ol><figure class="nh ni nj nk gt iv"><div class="bz fp l di"><div class="nx ny l"/></div></figure></div></div>    
</body>
</html>