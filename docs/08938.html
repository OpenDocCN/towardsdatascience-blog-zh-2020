<html>
<head>
<title>A comprehensive beginners guide to tackle text classification problems</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解决文本分类问题的初学者综合指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-comprehensive-beginners-guide-to-tackle-text-classification-problems-e39a8ce22cff?source=collection_archive---------31-----------------------#2020-06-27">https://towardsdatascience.com/a-comprehensive-beginners-guide-to-tackle-text-classification-problems-e39a8ce22cff?source=collection_archive---------31-----------------------#2020-06-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a8af" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">利用文本分类方法分析 Twitter 数据中的错误信息</h2></div><p id="ea2f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">作者</em> <a class="ae lc" href="https://www.linkedin.com/in/nikhil-joshi-344b9aa7/" rel="noopener ugc nofollow" target="_blank"> <em class="lb">尼基尔·乔希</em> </a> <em class="lb">和</em> <a class="ae lc" href="https://www.linkedin.com/in/narasimha-kamath-ardi-133169132/" rel="noopener ugc nofollow" target="_blank"> <em class="lb">纳拉辛哈·卡马特·阿迪</em></a><em class="lb">—2020 年 6 月 26 日</em></p></div><div class="ab cl ld le hu lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ij ik il im in"><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi lk"><img src="../Images/3733b0548276264fe2c180c4a3008231.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ty0AFPbf49smvzursTMSYA.jpeg"/></div></div></figure><p id="d72b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">简介</strong></p><p id="6858" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">众所周知，对数据科学家的需求一直在稳步上升。我们辞去了一份高薪的咨询工作，去追求数据科学领域的职业生涯。当我们作为学生开始我们的旅程时，我们真的不知所措，不知道如何开始学习过程。作为一个不断发展的领域，互联网上有很多内容/平台。当已经有这么多可能的事情时，一个人自然会发现很难找到一个完美的开始，我们在第一季度的前两个月面临同样的问题。</p><p id="f235" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当我们在网上寻找内容时，他们大多专注于机器学习算法，NLP 概念，一开始看起来超级令人兴奋。此外，当我们开始了解 Python 及其内置库的重要性时，我们对自己的职业选择非常着迷。然而，作为一个初学者，我们面临着如此多的困惑，我们将在这个博客中讨论。这篇文章是有意针对新手候选人的，我们将尝试详细说明应该注意的每一点，以便在这一流程中建立一个坚实的基础。</p><p id="3827" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">数据科学不是闹着玩的！</strong></p><p id="0f96" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是一个极具挑战性的领域，需要纯粹的统计学知识来理解基本概念。ML 看起来很吸引人，Python 也做对了你的大部分工作，那为什么还要学统计学呢？这是我们关于数据科学的第一个流言被终结的地方。我们遇到了各种旨在通过将大部分精力集中在构建模型上来解决问题的帖子/项目，并得出结论，它对给定的用例执行准确！！这是我们大多数人出错的地方。你还在迷茫吗，别急！请允许我们通过考虑一个经典的文本分类问题来阐述这一点；我们的第一个数据科学项目教会了我们很多在学习阶段从未预料到的事情。</p><p id="8eb1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">预测全球疫情期间推特上的错误信息</strong></p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi lw"><img src="../Images/7a2a1f1c0df64765b01c7b21eac65dd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2maE7yYenvyiLuVHU57uzw.png"/></div></div></figure><p id="b0fb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">啊！众所周知，Twitter 是数据科学项目的金矿。但是我们应该用 Twitter 做什么项目呢？当我们在 GitHub 上寻找几个项目来获得灵感时，我们发现大多数项目都倾向于情感分析。等等，我们要进行情感分析吗？选择一个项目主题是我们作为初学者面临的首要挑战。</p><p id="5f7e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">提示 1:一开始就着手一个复杂的项目是绝对不行的。要脚踏实地！一步一步来！</p><p id="4bd9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">像其他人一样，我们在开始时太受驱动了，想做一个复杂的项目。然而，我们意识到这不是正确的方法。我们想先搞清楚基本情况，经过几天的头脑风暴，我们敲定了几个有趣的话题。最后，我们决定对 twitter 上有关抗病毒药物、消毒剂和冠状病毒预防措施的错误信息进行分析。此外，选择这一主题的动机是为了理解实现解决方案背后的数学原理，以减少 Twitter 上的有害内容。</p><p id="23c5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">我们是如何解决这个问题的？</strong></p><p id="bd91" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">大多数像我们这样的新手在项目期间犯的主要错误是直接跳到项目要使用的 ML 算法的类型上！</p><p id="bfb5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">提示 2:控制你的肾上腺素分泌！先看问题。请不要忽视数据工程部分。分析问题陈述，看看在你目前的知识水平下是否可行。</strong></p><p id="ea55" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">谢谢你走了这么远。从这里开始，我们将解释解决这个问题的逐步方法。</p><p id="916a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">第一步:获取 TWITTER 开发者账户访问权限</strong></p><p id="a52c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了使用 twitter 数据，我们需要一个 twitter 开发者帐户。这将为我们提供通过 TweePy 获取 tweets 的授权。但是，我们是如何创建 twitter 开发者账户的呢？</p><p id="6e72" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">遵循以下步骤:</p><p id="c8c6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">a.登录开发者账号，点击<strong class="kh ir">“创建 app”</strong>。</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi lx"><img src="../Images/f76b54307c299ccbf9f71ddf1684d33f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7YfmA1hhUZsFLIxiKuWjsw.png"/></div></div></figure><p id="7286" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">b.将出现一个弹出窗口。点击<strong class="kh ir">‘应用’</strong>并从下面的仪表板中选择相关选项。</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi ly"><img src="../Images/5a1c8cb8aaf332325bcc6988a3ff999b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*47fBSDblR6mZWvHI8RRL7g.png"/></div></div></figure><p id="11c2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">c.填写所需的详细信息，并获取访问密钥和令牌</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi lz"><img src="../Images/3eb5f6b6c7cdd9ebe2060bb564866586.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ibgiEAdWELOs7SZAkEUN-g.png"/></div></div></figure><p id="51fa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">呜哇！！！第一步现已完成。获得访问权限后，请确保点击<strong class="kh ir">“密钥和令牌”</strong>选项卡，并复制所提供的令牌。它将进一步用于通过 TweePy 访问 REST API。</p><p id="47f5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">第二步:数据收集和存储</strong></p><p id="f7b9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们通过 TweePy 使用 REST API 抓取推文。在这篇文章中，我们假设我们所有的读者都已经有了很好的 Python 实践经验。如果没有，我们强烈建议访问任何免费的 Python 在线课程，让自己熟悉该语言的语法。</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi ma"><img src="../Images/c120ee2587005253a6dc8834e5147cd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*00wdyo_WQY5-xJvdlXlNBw.png"/></div></div></figure><p id="1b4d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦从 Twitter 收到令牌和密钥并安装了 TweePy，就可以开始通过 Twitter API 提取数据了。您可以通过<a class="ae lc" href="https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> Twitter 标准 API 搜索字段</strong> </a> <strong class="kh ir"> </strong>找到不同的可用数据字段。</p><p id="3ddb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">技巧 3:永远不要仅仅为了完成任务而写脚本。优化它以执行多个操作。下面的代码片段一次性完成了管道的获取和清理。编码是一门艺术！练习直到你做对为止！</p><p id="033c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，让我们导入所需的库:</p><pre class="ll lm ln lo gt mb mc md me aw mf bi"><span id="f30f" class="mg mh iq mc b gy mi mj l mk ml"><strong class="mc ir"># Data extraction &amp; exploratory analysis</strong><br/>import tweepy<br/>from textblob import TextBlob<br/>from tweepy import OAuthHandler<br/>import pandas as pd<br/>import numpy as np <br/>import re</span><span id="ddca" class="mg mh iq mc b gy mm mj l mk ml"><strong class="mc ir">#NLP</strong><br/>from textblob import TextBlob<br/>import nltk<br/>from nltk.corpus import stopwords<br/>from nltk.tokenize import word_tokenize<br/>from sklearn.feature_extraction.text import TfidfVectorizer<br/>from sklearn.model_selection import train_test_split<br/>from nltk.stem import PorterStemmer<br/>from nltk.stem import WordNetLemmatizer<br/>nltk.download('punkt')<br/>from nltk.corpus import words<br/>nltk.download('stopwords')</span><span id="2ea2" class="mg mh iq mc b gy mm mj l mk ml"><strong class="mc ir">#ML Libraries for text classification</strong><br/>from sklearn.metrics import accuracy_score<br/>from sklearn.naive_bayes import MultinomialNB<br/>from sklearn.linear_model import LogisticRegression</span></pre><p id="48ce" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦你的申请被批准，使用下面的脚本添加你自己的个性化 tokes。</p><pre class="ll lm ln lo gt mb mc md me aw mf bi"><span id="3c04" class="mg mh iq mc b gy mi mj l mk ml"><strong class="mc ir"># Removed access keys and tokens for the sake of security</strong></span><span id="297e" class="mg mh iq mc b gy mm mj l mk ml">access_token = ''<br/>access_token_secret = ''<br/>consumer_key = ''<br/>consumer_secret = ''</span></pre><p id="8bbd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如前所述，现在是我们开始从 Twitter API 中提取数据的时候了。</p><pre class="ll lm ln lo gt mb mc md me aw mf bi"><span id="79f3" class="mg mh iq mc b gy mi mj l mk ml"><strong class="mc ir"># authorize access to TweePy</strong></span><span id="ef53" class="mg mh iq mc b gy mm mj l mk ml">auth = tweepy.OAuthHandler(consumer_key,consumer_secret)<br/>auth.set_access_token(access_token,access_token_secret)<br/>api = tweepy.API(auth,wait_on_rate_limit=True, wait_on_rate_limit_notify=True)</span><span id="b067" class="mg mh iq mc b gy mm mj l mk ml"><strong class="mc ir"># Fetch tweets</strong></span><span id="32d4" class="mg mh iq mc b gy mm mj l mk ml">tweets = []<br/>sentiments =[]<br/>count = 1<br/>query = "#hydroxychloroquine OR #remdesivir OR #Remdesivir OR hydroxychloroquine OR remdesivir OR #GileadSciences OR GileadSciences OR #drug OR drug OR #antiviral OR antiviral OR #Antibiotic OR antibiotic"</span><span id="7519" class="mg mh iq mc b gy mm mj l mk ml">for tweet in tweepy.Cursor(api.search,q=query,count=450).items(50000):<br/>    print(count)<br/>    count+=1<br/>    <br/>    try:<br/>        data = [tweet.created_at,tweet.id,tweet.text,tweet.source,tweet.retweet_count,tweet.user._json['screen_name'],tweet.user._json['created_at'],tweet.user._json['location'],tweet.coordinates,tweet.entities['urls']]<br/>        data = tuple(data)<br/>        tweets.append(data)<br/>        <br/>    except tweepy.TweepError as e:<br/>        print(e.reason)<br/>        continue<br/>    <br/>    try:<br/>        sentiment_data = [tweet.created_at,tweet.text]<br/>        sentiment_data = tuple(sentiment_data)<br/>        textWords=sentiment_data[1].split()<br/>        #clean tweets<br/>        cleanedTweet=' '.join(re.sub("(@[A-Za-z0-9]+)|([^0-9A-Za-z \t])|(\w+:\/\/\S+)|(RT)", " ", sentiment_data[1]).split())<br/>        analysis= TextBlob(cleanedTweet)<br/>        polarity = 'Positive'<br/>        if(analysis.sentiment.polarity &lt; 0):<br/>            polarity = 'Negative'<br/>        if(0&lt;=analysis.sentiment.polarity &lt;=0.2):<br/>            polarity = 'Neutral'<br/>        #print (polarity)<br/>        dic={}<br/>        dic['Sentiment']=polarity<br/>        dic['Tweet']=cleanedTweet<br/>        dic['Polarity'] = analysis.sentiment.polarity<br/>        dic['Created_at'] = sentiment_data[0]<br/>        sentiments.append(dic)<br/>        <br/>    except tweepy.TweepError as e:<br/>        print(e.reason)<br/>        continue<br/>    <br/>    except StopIteration:<br/>        break<br/>        <br/>df_analysis = pd.DataFrame(tweets, columns = ['created_at','tweet_id','tweet_text','tweet_source','retweet_count','screen_name','account_creation_date','location','coordinates','urls'])</span><span id="2eb7" class="mg mh iq mc b gy mm mj l mk ml">df_analysis.to_csv('File Path')</span><span id="9bad" class="mg mh iq mc b gy mm mj l mk ml">df_sentiment=pd.DataFrame(sentiments)</span><span id="0ce0" class="mg mh iq mc b gy mm mj l mk ml">df_sentiment.to_csv('File Path'</span></pre><p id="d32a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们使用查询字符串来添加我们正在寻找的任何标签、关键字、关键短语或句柄(例如 query = " #羟氯喹" )，然后使用。items()功能。</p><p id="a181" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在上面的脚本中，<a class="ae lc" href="https://textblob.readthedocs.io/en/dev/" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">文本 Blob </strong> </a> <strong class="kh ir"> </strong>将我们的文本分类为阳性、阴性和中性标签(基于极性)。但是，我们为什么要使用<a class="ae lc" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> NLTK </strong> </a>呢？使用这两个库的唯一目的是理解每个包如何以自己的方式对文本处理做出贡献。此外，我们还强烈推荐浏览<a class="ae lc" href="https://spacy.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> SpaCy </strong> </a>，这是一个高级自然语言处理的开源软件库。</p><p id="23b9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，我们可以设置自定义日期过滤器(since 和 until 参数)来查询给定日期范围内的 tweets。在执行此脚本之前，请确保添加您的文件路径来存储原始数据集和干净数据集。</p><pre class="ll lm ln lo gt mb mc md me aw mf bi"><span id="74e6" class="mg mh iq mc b gy mi mj l mk ml">tweepy.Cursor(api.search,q=query,since=2020-06-26 count=450).items(50000)</span></pre><p id="7661" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是，请记住，Twitter 标准 API 搜索只能追溯到当前日期的 7 天之后。此外，计数参数指的是速率限制，请保持不变，即 450。</p><p id="6154" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">除了下载我们在上面实现的历史推文，我们还可以使用流 API 下载实时推文。请<a class="ae lc" href="https://developer.twitter.com/en/docs/tutorials/consuming-streaming-data" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">查看</strong></a>Twitter 开发者手册了解更多信息。</p><p id="3987" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">第三步:分析并理解我们如何应用分类方法</strong></p><p id="3ab7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">文本分类是一个有监督的学习问题，它在机器学习和自然语言处理的帮助下将文本/标记分类到有组织的组中。<a class="ae lc" href="https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">点击这里</strong> </a>了解更多详情。另外，情绪分析的基础知识可以在<a class="ae lc" href="https://monkeylearn.com/sentiment-analysis/#:~:text=Sentiment%20analysis%20is%20the%20interpretation,in%20online%20conversations%20and%20feedback." rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">这里找到</strong> </a> <strong class="kh ir">。</strong></p><p id="56f1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面是我们的干净数据集后处理的快照:</p><pre class="ll lm ln lo gt mb mc md me aw mf bi"><span id="84f6" class="mg mh iq mc b gy mi mj l mk ml">df = pd.read_csv("text_analysis_antiviral.csv")<br/>df.head()</span></pre><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mn"><img src="../Images/c5b8d94e4664d7059e823999ba0a8447.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DjoPF4oDuImFv6VqOqHF3Q.png"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">清理数据集快照</p></figure><p id="c4ee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果您仔细观察数据集，会发现添加了 2 个新属性，其中包括情感和极性。它们说明了什么？好吧，我们假设你已经浏览了我上面附加的链接，这些链接有助于你理解分类方法的基础。</p><p id="6f54" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们如何使用机器学习将这些文本分类为正面、负面和中性标签？在此之前，为什么我们甚至把他们排到上述标签？由于 TextBlob 已经按照极性对数据进行了分类，我们将使用它作为机器学习分类器的训练数据集。NLTK 在这里的工作是删除停用词并将句子分解成标记。然后，这些标记将经历词干化或词汇化的过程。</p><pre class="ll lm ln lo gt mb mc md me aw mf bi"><span id="897b" class="mg mh iq mc b gy mi mj l mk ml"><strong class="mc ir"># Perform text processing operations on the cleaned tweets</strong><br/>def preprocess_tweet_text(tweet):<br/>    tweet.lower()<br/>    <br/>  <strong class="mc ir">  # Remove urls</strong><br/>    tweet = re.sub(r"http\S+|www\S+|https\S+", '', tweet, flags=re.MULTILINE)<br/>    <br/>    <strong class="mc ir"># Remove stopwords</strong><br/>    stop = stopwords.words('english')<br/>    <br/>    <strong class="mc ir">#Tokenization</strong><br/>    tweet_tokens = word_tokenize(tweet)<br/>    filtered_words = [w for w in tweet_tokens if not w in stop]<br/>    <br/>    <strong class="mc ir"># Stemming</strong><br/>    ps = PorterStemmer()<br/>    stemmed_words = [ps.stem(w) for w in filtered_words]<br/>    <br/>    <strong class="mc ir">#Lemmatization</strong><br/>    lemmatizer = WordNetLemmatizer()<br/>    lemma_words = [lemmatizer.lemmatize(w, pos='a') for w in stemmed_words]<br/>    <br/>    return " ".join(filtered_words)</span></pre><p id="70fe" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">提示 4:在阅读下面的内容之前，请仔细阅读上面的链接，以便对主题有一个清晰的了解。</strong></p><p id="b3f9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里的第一种方法是找到包含虚假声明/信息的推文，并将它们贴上负面标签。但是，TextBlob 不是已经这样做了吗？为什么要走这么远，还要用 ML 分类器？这是一种我们一开始就在谈论的自省。数据科学不仅仅是建模和准确性！它有很多方面，但不幸的是大多数时候都被低估了。</p><p id="8e6f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以“孙杀”为例。你认为这篇文章的标签应该是什么？TextBlob 会将其识别为中性，这是绝对正确的，因为它预测了这里的情绪。然而，我们的问题声明指出，错误信息应被视为负面标签。请不要混淆:)我们使用 TextBlob 来减少准备带有标签的训练数据集的负担。但是，TextBlob 可能无法正确识别标签。现在这完全没问题，因为我们都刚刚步入数据科学的世界！因此，随着我们的前进，我们可以创建自己的带有所需标签的训练数据，并针对各种用例进行测试！</p><p id="06e6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">步骤 4:让我们应用期待已久的 ML 分类器来训练数据集！</p><p id="47fd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在应用模型之前，我们使用<a class="ae lc" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf#:~:text=In%20information%20retrieval%2C%20tf%E2%80%93idf,in%20a%20collection%20or%20corpus." rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> TF-IDF </strong> </a>技术为提取的记号分配加权因子。下面的代码片段还将数据分为训练和测试。此外，我们的火车数据集中有大约<strong class="kh ir"> 76000 </strong>条推文。</p><pre class="ll lm ln lo gt mb mc md me aw mf bi"><span id="667d" class="mg mh iq mc b gy mi mj l mk ml">tf_vector = get_feature_vector(np.array(dataset_train.iloc[:, 0]).ravel())<br/>X = tf_vector.transform(np.array(dataset_train.iloc[:, 0]).ravel())<br/>y = np.array(dataset_train.iloc[:, 1]).ravel()<br/>X_train = X<br/>y_train = y<br/>X_test = tf_vector.transform(np.array(dataset_test.iloc[:, 0]).ravel())<br/>y_test = np.array(dataset_test.iloc[:, 1]).ravel()</span></pre><p id="a743" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你们不要担心！我们还将附上 GitHub 资源库的链接，该资源库将包含本项目中使用的所有 Python 笔记本。现在请把注意力集中在正确的概念上！</p><p id="b7c2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们应该考虑应用哪种 ML 模型？我们使用流行的<a class="ae lc" href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">朴素贝叶斯分类器</strong> </a> <strong class="kh ir"> </strong>和<a class="ae lc" href="https://en.wikipedia.org/wiki/Logistic_regression#:~:text=Logistic%20regression%20is%20a%20statistical,a%20form%20of%20binary%20regression)." rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">逻辑回归</strong> </a> <strong class="kh ir"> </strong>进行分类。请点击<a class="ae lc" href="https://dataespresso.com/en/2017/10/24/comparison-between-naive-bayes-and-logistic-regression/#:~:text=Na%C3%AFve%20Bayes%20is%20a%20classification,being%20associated%20with%20a%20label.&amp;text=Logistic%20regression%20is%20a%20linear,belonging%20to%20a%20certain%20class." rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">链接</strong> </a>了解这些型号之间的更多差异。</p><p id="d100" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对 TextBlob 生成的数据集进行后训练，我们实现了 LR 模型 70%的准确率和 NB 模型 66%的准确率。</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/523b9d4e6495603cd62fffc0c112e6cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*hVuQB8y7ykFccpMigqPx7g.png"/></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">模特培训</p></figure><p id="04eb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第五步:测试时间到了！！</p><p id="f4ca" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当我们将测试数据集输入 LR 模型时，我们发现了一些非常有趣的见解！！</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/47f03f1931da3d20f9757d7a93b9618c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*pWqEpH2yzs2nGuRPYbpxfQ.png"/></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">根据 LR 模型测试数据集</p></figure><p id="da2d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">哇哦。你们有没有看到《孙杀》已经被正确的认定为阴性了？？在训练数据集时，除了 TextBlob 生成的数据之外，我们还包含了另外 300 个数据点！通过这种方式，它正确地将一些错误信息文本标记为负面的。不过，推文“我们喝漂白剂吧”还是中性的。有趣的是，我们训练过的模型错误标记了一些文本。这是我们作为数据科学家必须开始思考的地方。如前所述，我们刚刚开始我们的旅程。作为初学者完成这些步骤本身就是一项值得称赞的工作。因此，我们强烈建议正确理解这些概念。此外，一旦基础得到加强，高级思维的范围总是存在的！</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/50c2e1c11b78eeb9c8d8593981fd8753.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*1tWpWkTHt3arGxa2v7_BVA.jpeg"/></div></figure><p id="5ff7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如前所述，下面是<strong class="kh ir"> </strong> <a class="ae lc" href="https://github.com/TeamHiddenLeaf/text_classifier_python" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> GitHub 资源库链接</strong> </a>供大家参考！</p><p id="39db" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">谢谢大家！</p><p id="a112" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如有任何问题或疑虑，您也可以发电子邮件给我们:</p><p id="9038" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">nikhiljoshi19@uchicago.edu&amp;nkamathardi@uchicago.edu</strong></p></div><div class="ab cl ld le hu lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ij ik il im in"><p id="035f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">参考</strong></p><p id="414c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lc" href="https://firstdraftnews.org/latest/how-to-investigate-health-misinformation-and-anything-else-using-twitters-api/" rel="noopener ugc nofollow" target="_blank">https://first draft news . org/latest/how-to-investigation-health-misinformation-and-any-otherwise-using-twitters-API/</a></p></div></div>    
</body>
</html>