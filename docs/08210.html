<html>
<head>
<title>The Power of Pickletools</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pickletools的力量</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-power-of-pickletools-handling-large-model-pickle-files-7f9037b9086b?source=collection_archive---------22-----------------------#2020-06-16">https://towardsdatascience.com/the-power-of-pickletools-handling-large-model-pickle-files-7f9037b9086b?source=collection_archive---------22-----------------------#2020-06-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="dac7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">处理大型ML模型pickle文件</h2></div><p id="c36b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">数据量正在增加。数据越多，我们就越能利用它来解决不同的问题。假设您为某个解决方案训练了一个机器学习模型，并希望保存它以供以后预测。下面来介绍一些序列化-反序列化的方法:<strong class="kk iu">Pickle</strong>(Pickle，cPickle，Joblib，JsonPickle，Dill，Mlflow)，保存为<strong class="kk iu"> PMML </strong>格式为管道(sklearn2pmml)，保存为<strong class="kk iu"> JSON </strong>格式(sklearn _ json，sklearn _ export，msgpack，JsonPickle)。</p><p id="5a11" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您还可以使用<strong class="kk iu"> m2cgen </strong>库<strong class="kk iu"> </strong>将您的模型导出到python/java/c++代码，或者编写您自己的代码来序列化和反序列化您的模型。</p><p id="77cf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当你建立一个机器学习模型，通过使用大量数据来解决一些问题时，这个模型也将是巨大的！因此，当您试图将这种巨大的编码保存到您的系统时，问题就出现了(我在这里将讨论我试图处理的大型RandomForestClassifier模型/pickle文件)。</p><h1 id="f1b3" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">解决方案1:</h1><p id="b167" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">更多的数据意味着大尺寸的模型。尽量减少你的数据，又不丢失数据中你有价值的信息。去除<strong class="kk iu">重复或近似重复</strong>、<strong class="kk iu">分层欠采样</strong>可以在这里拯救你。</p><h1 id="adca" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">解决方案2:</h1><p id="00d5" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">尝试通过调整模型参数来缩小模型尺寸，而不影响精度。<strong class="kk iu">在这种情况下，超参数调整</strong>将对您有所帮助。我的基本型号<em class="mb"> RandomForestClassifier </em>有很大的60 GB，但是超参数调优设法把它降到了8 GB。还是大号？让我们看看下一种疗法。</p><h1 id="a9bd" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">解决方案3:</h1><p id="b36d" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">现在，您已经尽一切努力使您的模型更轻，而没有牺牲太多的预测能力，并且仍然获得8 GB的pickle文件。哦，亲爱的，生活太不公平了。</p><p id="2a03" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">坚持住，还有一些希望。Pickletools 前来救援！</p><p id="8a04" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该库帮助您减小pickle文件的大小，并使pickle文件作为RF对象的加载变得更加容易和快速。</p><p id="46dd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然Joblib和使用压缩方法如<strong class="kk iu"> zlib、gzip </strong>使我的pickle文件缩小到1 GB，但是将该文件作为随机森林分类器对象加载回来是一件令人头痛的事情。加载我的pickle (1 GB大小)和反序列化RF对象需要16 GB以上的RAM，这将导致<em class="mb"> MemoryError。</em></p><p id="cf16" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用Pickletools解决了缩小pickle文件大小和更快加载pickle文件的问题，而不会占用超过系统处理能力的内存，如下所示。</p><p id="3773" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要序列化:</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="7e20" class="ml lf it mh b gy mm mn l mo mp">clf.fit(X_train, y_train) #your classifier/regressor model</span><span id="f008" class="ml lf it mh b gy mq mn l mo mp">import gzip, pickle, pickletools</span><span id="4c50" class="ml lf it mh b gy mq mn l mo mp">filepath = "random_forest.pkl"<br/>with gzip.open(filepath, "wb") as f:<br/>    pickled = pickle.dumps(clf)<br/>    optimized_pickle = pickletools.optimize(pickled)<br/>    f.write(optimized_pickle)</span></pre><p id="1c00" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要反序列化/加载回:</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="1f09" class="ml lf it mh b gy mm mn l mo mp">with gzip.open(filepath, 'rb') as f:<br/>    p = pickle.Unpickler(f)<br/>    clf = p.load()</span></pre><p id="73a1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">呜哇！！虽然gzip有助于减小pickle的大小(到1 GB)，但pickletools有助于pickle文件加载更快，而不会消耗太多内存(这次占用了7 GB RAM)</p><p id="7207" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为此，您还可以设置pickle属性fast = True，但将来可能会被弃用，因为文档中是这么说的:</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="1893" class="ml lf it mh b gy mm mn l mo mp">import pickle</span><span id="d8eb" class="ml lf it mh b gy mq mn l mo mp">filepath = "random_forest.pkl"</span><span id="529e" class="ml lf it mh b gy mq mn l mo mp">with open(filepath, 'wb') as f:<br/>    p = pickle.Pickler(f)<br/>    p.fast = True<br/>    p.dump(clf)</span><span id="f097" class="ml lf it mh b gy mq mn l mo mp">with open(filepath, 'rb') as f:<br/>    p = pickle.Unpickler(f)<br/>    clf = p.load()</span></pre><h1 id="451c" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">额外解决方案:</h1><p id="23a9" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">如果您可以通过让CPU的每个核心同时工作来以任何方式并行化整个过程，那么在某种程度上，它也可以拯救您！</p><p id="ac47" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">好了，该你自己试试了。愿原力与你同在！</p><p id="b1df" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="mb">延伸阅读及参考文献:</em> </strong></p><ol class=""><li id="6926" class="mr ms it kk b kl km ko kp kr mt kv mu kz mv ld mw mx my mz bi translated">【https://docs.python.org/3/library/pickle.html#pickle. T4】Pickler.fast </li><li id="4264" class="mr ms it kk b kl nb ko nc kr nd kv ne kz nf ld mw mx my mz bi translated"><a class="ae na" href="https://docs.python.org/3/library/pickletools.html#pickletools.optimize" rel="noopener ugc nofollow" target="_blank">https://docs . python . org/3/library/pickle tools . html # pickle tools . optimize</a></li><li id="ea31" class="mr ms it kk b kl nb ko nc kr nd kv ne kz nf ld mw mx my mz bi translated"><a class="ae na" href="https://wiki.python.org/moin/ParallelProcessing" rel="noopener ugc nofollow" target="_blank">https://wiki.python.org/moin/ParallelProcessing</a></li><li id="9640" class="mr ms it kk b kl nb ko nc kr nd kv ne kz nf ld mw mx my mz bi translated"><a class="ae na" href="https://stackoverflow.com/questions/23916413/celery-parallel-distributed-task-with-multiprocessing" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/23916413/celery-parallel-distributed-task with multi-processing</a></li><li id="7aee" class="mr ms it kk b kl nb ko nc kr nd kv ne kz nf ld mw mx my mz bi translated"><a class="ae na" href="https://docs.python.org/3/library/multiprocessing.html" rel="noopener ugc nofollow" target="_blank">https://docs.python.org/3/library/multiprocessing.html</a></li></ol></div></div>    
</body>
</html>