<html>
<head>
<title>Keeping Up with PyTorch Lightning and Hydra</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">跟上 PyTorch 闪电和九头蛇</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/keeping-up-with-pytorch-lightning-and-hydra-31e8ed70b2cc?source=collection_archive---------19-----------------------#2020-08-27">https://towardsdatascience.com/keeping-up-with-pytorch-lightning-and-hydra-31e8ed70b2cc?source=collection_archive---------19-----------------------#2020-08-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="88c8" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">我如何使用 PyTorch Lightning 1.1 和 Hydra 1.0 的新特性将我的训练脚本缩减了 50%</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/b292d2c2ccbfe2ddb7bbd50ff5db1548.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TdCZYq9z_CWUwMZKDZJAqA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">努力跟上！— <a class="ae kv" href="https://unsplash.com/photos/H30w37gpkro" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="5ea7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls">2021 年 02 月 09 日更新:这个故事是关于 PyTorch Lightning 0.9.0 和 Hydra 1.0.0rc4 的。从那时起，他们已经发布了他们的正式生产就绪版本，我也发布了这个故事的第二版</em><a class="ae kv" href="https://peterkeunwoo.medium.com/keeping-up-with-pytorch-lightning-and-hydra-2nd-edition-34f88e9d5c90" rel="noopener"><em class="ls"/></a><em class="ls">，其中包括了所有最新的变化。我把这个故事留给后人，但请查看第二版</em><a class="ae kv" href="https://peterkeunwoo.medium.com/keeping-up-with-pytorch-lightning-and-hydra-2nd-edition-34f88e9d5c90" rel="noopener"><em class="ls"/></a><em class="ls">！</em></p><h1 id="f868" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">介绍</h1><p id="49da" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">上周，<a class="ae kv" href="https://medium.com/pytorch/pytorch-lightning-0-9-synced-batchnorm-datamodules-and-final-api-aae885398a9d" rel="noopener"> PyTorch Lightning 0.9.0 </a>和<a class="ae kv" href="https://github.com/facebookresearch/hydra/releases/tag/v1.0.0rc4" rel="noopener ugc nofollow" target="_blank"> Hydra 的第四个候选版本 1.0.0 </a>发布了，充满了新功能和大部分最终 API。我认为这是一个很好的机会让我重温我的边项目<a class="ae kv" href="https://github.com/yukw777/leela-zero-pytorch" rel="noopener ugc nofollow" target="_blank"> Leela Zero PyTorch </a>，看看这些新版本是如何融入其中的。在这篇文章中，我将谈论这两个库的一些新特性，以及它们如何帮助 Leela Zero PyTorch。我不会在这里过多地谈论关于 Leela Zero PyTorch 的细节，所以如果你想更多地了解我的副业项目，你可以在这里阅读我以前关于它的博文<a class="ae kv" rel="noopener" target="_blank" href="/training-neural-networks-for-leela-zero-using-pytorch-and-pytorch-lightning-bbf588683065">。</a></p><h1 id="a540" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">PyTorch 闪电 0.9.0</h1><p id="0035" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">对于 PyTorch Lightning 团队来说，这是一个重要的里程碑，因为他们正在努力工作以发布 1.0.0 版本。它引入了许多新特性和一个更接近最终版本的 API。在我们开始之前，如果你想了解更多关于这个版本的信息，请查看官方的<a class="ae kv" href="https://medium.com/pytorch/pytorch-lightning-0-9-synced-batchnorm-datamodules-and-final-api-aae885398a9d" rel="noopener">博客文章</a>。如果你想了解更多关于 PyTorch Lightning 的知识，请查看 Github 页面和官方文档<a class="ae kv" href="https://pytorch-lightning.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank"/>。</p><h2 id="c7cd" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">结果</h2><p id="df72" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">你有没有发现自己重复地实现<code class="fe nc nd ne nf b">*_epoch_end</code>方法，只是为了从你的<code class="fe nc nd ne nf b">*_step</code>方法中聚集结果？您是否发现自己在如何正确记录您的<code class="fe nc nd ne nf b">*_step</code>和<code class="fe nc nd ne nf b">*_epoch_end</code>方法中计算出的指标时被绊倒了？你并不孤单，PyTorch Lightning 0.9.0 引入了一个叫做<code class="fe nc nd ne nf b">Result</code>的新抽象来解决这些问题。</p><p id="cb52" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nc nd ne nf b">Result</code>、<code class="fe nc nd ne nf b">TrainResult</code>和<code class="fe nc nd ne nf b">EvalResult</code>两种。顾名思义，<code class="fe nc nd ne nf b">TrainResult</code>用于训练，<code class="fe nc nd ne nf b">EvalResult</code>用于验证和测试。它们的接口很简单:您指定在实例化期间要操作的主要指标(对于<code class="fe nc nd ne nf b">TrainResult</code>，要最小化的指标，对于<code class="fe nc nd ne nf b">EvalResult</code>，要检查点或提前停止的指标)，然后您指定要记录的附加指标。让我们看看它们是如何在我的项目中使用的:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">TrainResult 和 EvalResult 有助于您不重复度量记录。</p></figure><p id="ac7b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在<code class="fe nc nd ne nf b">training_step()</code>中，我指定了要最小化的总损耗，并记录了总损耗(也指定要在进度条中显示)、均方误差损耗、交叉熵损耗以及最后的精度(使用 PyTorch Lightning 的新度量包计算，稍后将讨论)。我不需要编写代码来在纪元级别聚合它们，因为<code class="fe nc nd ne nf b">TrainResult</code>会处理这些。事实上，您可以使用<code class="fe nc nd ne nf b">TrainResult</code>指定每个指标应该聚合和记录的级别(步骤、时期或两者都有)，它会自动为您处理一切。</p><p id="eab8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">类似地，在<code class="fe nc nd ne nf b">validation_step()</code>中，我指定了用于检查点的总损失，并记录总损失、均方误差损失、交叉熵损失和准确性。同样，我不需要编写<code class="fe nc nd ne nf b">validation_epoch_end()</code>，因为聚合和日志记录是由<code class="fe nc nd ne nf b">EvalResult</code>处理的。此外，我不需要为<code class="fe nc nd ne nf b">test_step()</code>重复我自己，只需调用<code class="fe nc nd ne nf b">validation_step()</code>并为要记录的指标重命名键。</p><p id="d0ab" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">得益于<code class="fe nc nd ne nf b">Result</code>，您可以立即看到我的代码变得更加简单、可读性更好、可维护性更高。你可以在这里了解更多信息<a class="ae kv" href="https://pytorch-lightning.readthedocs.io/en/0.9.0/results.html#" rel="noopener ugc nofollow" target="_blank">。</a></p><h2 id="c853" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">韵律学</h2><p id="76bf" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">PyTorch Lightning 团队在 0.8 中继续他们的工作，在 0.9.0 中引入了更多的度量实现。PyTorch Lightning 中的每一个指标实现都是一个 PyTorch 模块，并且有其对应的功能，使用起来非常简单灵活。对于我的项目，我决定集成 accuracy 的功能实现，这只是导入它并在适当的<code class="fe nc nd ne nf b">*_step</code>方法中调用它的问题。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">函数精度在 training_step()方法中被调用。</p></figure><p id="064c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">PyTorch Lightning 现在包含许多其他指标实现，包括高级 NLP 指标，如 BLEU score。你可以在这里阅读更多关于它的<a class="ae kv" href="https://pytorch-lightning.readthedocs.io/en/0.9.0/metrics.html" rel="noopener ugc nofollow" target="_blank">。</a></p><h2 id="b27a" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">照明数据模块</h2><p id="4830" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">PyTorch Lightning 的另一个棘手问题是处理各种数据集。直到 0.9.0，PyTorch Lightning 对如何组织你的数据处理代码保持沉默，除了你使用 PyTorch 的<a class="ae kv" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset" rel="noopener ugc nofollow" target="_blank">数据集</a>和<a class="ae kv" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" rel="noopener ugc nofollow" target="_blank">数据加载器</a>。这无疑给了您很大的自由，但也使您很难保持数据集实现的整洁、可维护和易于与他人共享。在 0.9.0 中，PyTorch Lightning 在<code class="fe nc nd ne nf b">LightningDataModule</code>中引入了一种新的组织数据处理代码的方式，封装了数据处理中最常见的步骤。它有一个简单的接口，有五种方法:<code class="fe nc nd ne nf b">prepare_data()</code>、<code class="fe nc nd ne nf b">setup()</code>、<code class="fe nc nd ne nf b">train_dataloader()</code>、<code class="fe nc nd ne nf b">val_dataloader()</code>和<code class="fe nc nd ne nf b">test_dataloader()</code>。让我们回顾一下它们在我的项目中是如何实现的，以理解它们的作用。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div></figure><ul class=""><li id="48e8" class="ni nj iq ky b kz la lc ld lf nk lj nl ln nm lr nn no np nq bi translated"><code class="fe nc nd ne nf b">prepare_data()</code>:该方法适用于任何在主流程中必须完成的事情，然后再派生出分布式培训的子流程。下载、预处理或保存到磁盘等任务是这种方法的理想选择。需要注意的一点是，在这里设置的任何状态都不会被带到分布式培训中的子流程，因此您应该注意不要在这里设置任何状态。在我的项目中，我依赖 Leela Zero 来预处理 Go sgf 文件，所以我决定跳过实现这个方法，但是我可以在技术上实现这个方法中的预处理步骤。</li><li id="c869" class="ni nj iq ky b kz nr lc ns lf nt lj nu ln nv lr nn no np nq bi translated">setup():该方法用于分布式培训的每个子流程中必须完成的任何事情。您应该构造实际的 PyTorch <code class="fe nc nd ne nf b">Datasets</code>并在这里设置任何必要的状态。在 Leela Zero PyTorch 中，我初始化了我的<code class="fe nc nd ne nf b">Datasets</code>，它从磁盘读入数据，并将其转换为张量，并保存为状态。</li><li id="b0b2" class="ni nj iq ky b kz nr lc ns lf nt lj nu ln nv lr nn no np nq bi translated"><code class="fe nc nd ne nf b">*_dataloader()</code>:这是你初始化<code class="fe nc nd ne nf b">DataLoaders</code>进行训练/验证/测试的地方。在我的例子中，我简单地使用在<code class="fe nc nd ne nf b">setup()</code>中构建的数据集以及在<code class="fe nc nd ne nf b">LightningDataModule</code>初始化期间传递的配置来初始化<code class="fe nc nd ne nf b">DataLoaders</code>。</li></ul><p id="e451" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，只需要将<code class="fe nc nd ne nf b">LightningDataModule</code>转换成<code class="fe nc nd ne nf b">trainer.fit()</code>和<code class="fe nc nd ne nf b">trainer.test()</code>就可以了。您也可以想象这样一个场景，我为不同类型的数据集(比如国际象棋游戏数据)实现了另一个<code class="fe nc nd ne nf b">LightningDataModule</code>,培训师也会同样接受它。我可以更进一步，使用 Hydra 的对象实例化模式，在各种数据模块之间轻松切换。</p><h1 id="f914" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">九头蛇 1.0.0rc4</h1><p id="6e02" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">1.0.0rc4 使 Hydra 更加接近其 1.0.0 正式版本。它包含许多错误修复和一些重要的 API 更改，使该库更加成熟和易于使用。在我们开始之前，如果你想了解更多关于九头蛇的信息，请查看<a class="ae kv" href="https://hydra.cc/" rel="noopener ugc nofollow" target="_blank">官方网站</a>以及<a class="ae kv" href="https://hydra.cc/docs/next/intro" rel="noopener ugc nofollow" target="_blank">官方文档</a>！</p><h2 id="d106" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">@hydra.main()</h2><p id="5d46" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">您可以将这个装饰器添加到任何接受 OmegaConf 的<code class="fe nc nd ne nf b">DictConfig</code>的函数中，Hydra 将自动处理您脚本的各个方面。这本身并不是一个新特性，但是我最初决定不使用这个特性，因为它接管了输出目录结构和工作目录。我实际上使用了 Hydra 的实验性 Compose API 来解决这个问题，我将在后面讨论。然而，在与 Hydra 的创建者<a class="nw nx ep" href="https://medium.com/u/18354ccdb814?source=post_page-----31e8ed70b2cc--------------------------------" rel="noopener" target="_blank"> Omry </a>交谈后，我意识到这不仅不是推荐的方法，而且我还失去了 Hydra 提供的一些很酷的功能，如命令行界面的自动处理、自动帮助消息和 tab 补全。此外，在使用一段时间后，我发现 Hydra 的输出目录和工作目录管理非常有用，因为我不必在 PyTorch Lightning 端手动设置日志目录结构。你可以在<a class="ae kv" href="https://hydra.cc/docs/next/tutorials/basic/your_first_app/simple_cli" rel="noopener ugc nofollow" target="_blank"> Hydra 的基础教程</a>中读到更多关于这个装饰者的内容。</p><h2 id="93c2" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">打包指令</h2><p id="aac1" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">在 Hydra 0.11 中，配置只有一个全局名称空间，但在 1.0.0 中，您可以使用 package 指令在不同的名称空间中组织配置。这允许您保持 yaml 配置文件的平整和整洁，没有不必要的嵌套。让我们来看看 Leela Zero PyTorch 的网络规模配置:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">“@package _group_”表示此配置应在当前组下，在本例中为“网络”。</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/215bf7cb9129803519f1d8b9926cd8b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0h0lqQd2HVwTJ9c_laCALA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">网络大小配置已按规定添加到“网络”下。请注意“board_size”和“in_channels”来自数据配置(composition！)</p></figure><p id="1509" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如您所见，包指令使您的配置更易于管理。你可以在这里阅读更多关于包指令及其更高级的用例<a class="ae kv" href="https://hydra.cc/docs/next/advanced/overriding_packages" rel="noopener ugc nofollow" target="_blank">。</a></p><h2 id="cf77" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">实例化对象</h2><p id="6a94" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">Hydra 提供了一个特性，可以根据配置实例化一个对象或调用一个函数。当您希望您的脚本有一个简单的接口在各种实现之间切换时，这是非常有用的。这也不是一个新功能，但它的界面在 1.0.0rc4 中有了很大的改进。在我的情况下，我使用它在网络大小、训练记录器和数据集之间切换。我们以网络规模配置为例。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">“大”、“巨型”和“小型”网络的配置</p></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">基于所选配置实例化网络。请注意，您可以传入额外的参数来实例化()，就像我在这里对 cfg.train 所做的那样。</p></figure><p id="7396" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nc nd ne nf b">NetworkLightningModule</code>对其<code class="fe nc nd ne nf b">__init__()</code>、<code class="fe nc nd ne nf b">network_conf</code>和<code class="fe nc nd ne nf b">train_conf</code>接受两种说法。前者从配置中传入，后者在<code class="fe nc nd ne nf b">instantiate()</code> ( <code class="fe nc nd ne nf b">cfg.train</code>)中作为额外参数传入。你所要做的就是在命令行中输入<code class="fe nc nd ne nf b">+network={small,big,huge}</code>来选择不同的网络大小。您甚至可以想象通过用不同的<code class="fe nc nd ne nf b">_target_</code>创建一个新的配置，并在命令行中传递配置名，来选择一个完全不同的架构。不需要通过命令行传递所有的小细节！你可以在这里阅读更多关于这个模式的信息<a class="ae kv" href="https://hydra.cc/docs/next/patterns/instantiate_objects/instantiate_objects_overview" rel="noopener ugc nofollow" target="_blank">。</a></p><h2 id="9c59" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">撰写 API</h2><p id="8f9f" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">尽管 Hydra 的 Compose API 不是编写脚本的推荐方式，但它仍然是编写单元测试的推荐方式，并且非常有用。我用它来为主培训脚本编写单元测试。同样，这并不是一个新特性，但是 Hydra 1.0.0rc4 确实为使用 Python 的上下文管理器的 Compose API 引入了一个更干净的接口(<code class="fe nc nd ne nf b">with</code>语句)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">您可以使用 Hydra 的 Compose API 轻松编写配置字典。它有助于保持单元测试的整洁和易于调试。</p></figure><p id="4865" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可以在这里阅读更多关于 Compose API <a class="ae kv" href="https://hydra.cc/docs/next/experimental/compose_api" rel="noopener ugc nofollow" target="_blank">的内容，以及如何在这里</a>使用它进行单元测试<a class="ae kv" href="https://hydra.cc/docs/next/advanced/unit_testing" rel="noopener ugc nofollow" target="_blank">。</a></p><h2 id="df3f" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">未使用的功能:结构化配置和变量插值</h2><p id="0ff4" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">Hydra 1.0.0rc4 中还有很多其他特性我没有利用，主要是因为我还没有足够的时间来集成它们。我将讨论本节中最大的一个问题——结构化配置。</p><p id="f532" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">结构化配置是 1.0.0 中引入的一个主要新特性，它利用<a class="ae kv" href="https://docs.python.org/3/library/dataclasses.html" rel="noopener ugc nofollow" target="_blank"> Python 的 dataclasses </a>来提供运行时和静态类型检查，这在应用程序变得复杂时非常有用。我可能会在将来有时间的时候整合它们，所以请继续关注另一篇博文！</p><h1 id="3623" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">结论</h1><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">我的新旧训练脚本。行数从 56 增加到 28。五折优惠！</p></figure><p id="48b7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">自从我写了关于 Leela Zero PyTorch 的第一篇博文以来，Hydra 和 PyTorch Lightning 都引入了许多新的特性和抽象，可以帮助您极大地简化 PyTorch 脚本。正如你在上面看到的，我的主要训练脚本现在只有 28 行，而以前是 56 行。此外，训练管道的每个部分，神经网络体系结构，数据集和记录器，都是模块化的，易于交换。这使得迭代更快，维护更容易，重现性更好，让您可以专注于项目中最有趣和最重要的部分。我希望这篇博文对你“跟上”这两个了不起的库有所帮助！你可以在这里找到 Leela Zero PyTorch 的代码。</p></div></div>    
</body>
</html>