<html>
<head>
<title>AI Synthwave</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工合成波</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ai-synthwave-51da9251a1b7?source=collection_archive---------38-----------------------#2020-05-20">https://towardsdatascience.com/ai-synthwave-51da9251a1b7?source=collection_archive---------38-----------------------#2020-05-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f44f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用GANs从YouTube生成合成波图像</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/061af082b79c472ec931f30deb745b41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DEOHgJ1tLKcHNSxhbtnlTg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用经过合成波成像训练的DCGAN生成图像</p></figure><p id="f71e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi lu translated"><span class="l lv lw lx bm ly lz ma mb mc di"> G </span>世代对抗网络(GANs)，或者像Yann Lecun喜欢叫它们的那样，<a class="ae md" href="https://www.quora.com/What-are-some-recent-and-potentially-upcoming-breakthroughs-in-unsupervised-learning" rel="noopener ugc nofollow" target="_blank"> <em class="me">【自切片面包以来最酷的东西】</em></a><em class="me"/>简直就是现象级的。</p><p id="e86c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我长久以来一直迷恋于这些神秘的网络，它们能够实现我只能称之为魔法的东西。</p><p id="d2b3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">作为这些网络的忠实粉丝，我想创造一些有趣的东西。你们中的许多人可能对synthwave类型很熟悉。这是一部独特的怀旧70年代和80年代科幻电影，非常有趣。</p><p id="b950" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Synthwave也是我在工作或学习时最喜欢听的音乐类型之一，所以我经常被YouTube上这种类型简单迷人的视觉效果所吸引。</p><p id="16b2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">自然地，GANs和synthwave看起来是一个很酷的组合。synthwave从科幻中汲取了大量灵感，而GANs实际上也是科幻。</p><p id="4066" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，我们将分解如何从YouTube中抓取图像数据，以及如何将这些数据输入并设置一个深度卷积GAN (DCGAN)。</p><p id="7888" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这段代码也适用于任何范围的YouTube视频。当然，图像的复杂性和您想要的结果都是代码可直接转移的重要因素。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="1929" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">刮削和预处理</h1><p id="0b8f" class="pw-post-body-paragraph ky kz it la b lb ne ju ld le nf jx lg lh ng lj lk ll nh ln lo lp ni lr ls lt im bi translated">首先当然是数据。幸运的是，YouTube上有很多synthwave视频。在选择了一些synthwave可视视频之后，我们可以使用<code class="fe nj nk nl nm b">pytube</code>库来下载它们。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="2632" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">视频下载后，我们使用<code class="fe nj nk nl nm b">opencv</code>库从每个视频中提取数千帧，存储在本地以备训练时提取。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><h2 id="83d8" class="np mn it bd mo nq nr dn ms ns nt dp mw lh nu nv my ll nw nx na lp ny nz nc oa bi translated">处理</h2><p id="08a0" class="pw-post-body-paragraph ky kz it la b lb ne ju ld le nf jx lg lh ng lj lk ll nh ln lo lp ni lr ls lt im bi translated">一旦我们有了所有的图像文件，我们可以循环通过每一个，导入和下采样每一个图像…下采样的程度将取决于计算能力，以及你想从这个过程中得到什么。在我们的GAN中，每个像素都会增加我们网络的规模。</p><div class="kj kk kl km gt ab cb"><figure class="ob kn oc od oe of og paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/64be3a064733a928c22599bb590c06aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*U3Jo_C_-8nhtfWqtK8Wo8w.jpeg"/></div></figure><figure class="ob kn oc od oe of og paragraph-image"><img src="../Images/cb89e38e68d544978d308db502bdbe52.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*aI7SpZmC7Al9bRnISZvaBw.jpeg"/><p class="ku kv gj gh gi kw kx bd b be z dk oh di oi oj translated">原始图像的360p分辨率(左)和该图像的二倍下采样(右)|照片由<a class="ae md" href="https://unsplash.com/@lorenzoherrera?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Lorenzo Herrera </a>在<a class="ae md" href="https://unsplash.com/s/photos/synthwave?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure></div><p id="dcb3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">单个360 x 640 RGB图像由<code class="fe nj nk nl nm b">360*640*3 = <strong class="la iu">691200</strong></code>个值组成，通过因子<strong class="la iu">两个</strong>的下采样给我们一个<strong class="la iu">四倍</strong>的减少量<code class="fe nj nk nl nm b">180*320*3 = <strong class="la iu">172800</strong></code>。这大大降低了复杂性，因此也降低了运行时间。</p><p id="4f95" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果您的网络太大(这不一定是由于输入图像的大小，但可能是)，您将收到<code class="fe nj nk nl nm b">Error: OOM when allocating tensor</code>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="1512" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后我们需要将数据格式化成TensorFlow可读的格式。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="cfde" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用<a class="ae md" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset" rel="noopener ugc nofollow" target="_blank"> TensorFlow数据集对象</a>，这很容易。我们首先混洗数据，这样我们就不会同时将同一组图像输入到鉴别器中。然后我们对数据进行批处理，这意味着在我们更新网络权重之前，网络将会看到<code class="fe nj nk nl nm b">batchsize</code>个样本。</p><p id="a5b6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我见过使用GANs生成图像时，最常见的批量范围是16到64。</p><p id="32ec" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">还有建议使用鉴别器的<code class="fe nj nk nl nm b"><a class="ae md" href="https://github.com/soumith/ganhacks" rel="noopener ugc nofollow" target="_blank">SGD</a></code> <a class="ae md" href="https://github.com/soumith/ganhacks" rel="noopener ugc nofollow" target="_blank">优化功能，这实际上会在单个训练示例后更新权重。尽管如此，我们还是使用了<code class="fe nj nk nl nm b">Adam</code>和一个<code class="fe nj nk nl nm b">batchsize = 64</code>。</a></p><h1 id="6f84" class="mm mn it bd mo mp ok mr ms mt ol mv mw jz om ka my kc on kd na kf oo kg nc nd bi translated">DCGAN</h1><p id="9b6e" class="pw-post-body-paragraph ky kz it la b lb ne ju ld le nf jx lg lh ng lj lk ll nh ln lo lp ni lr ls lt im bi translated">我们使用<a class="ae md" href="https://arxiv.org/pdf/1511.06434.pdf" rel="noopener ugc nofollow" target="_blank">深度卷积GAN </a>架构。<a class="ae md" href="https://en.wikisource.org/wiki/Oxford_Book_of_English_Verse_1250-1900/Simplex_Munditiis" rel="noopener ugc nofollow" target="_blank">Simplex Mundi tis</a>专为最大化结果和最小化复杂性而设计。</p><p id="f5b9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">与典型的卷积神经网络(CNN)或递归神经网络(RNN)设置不同，GANs要求我们将TensorFlow设置到稍低的级别。</p><p id="a857" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这意味着我们将把代码分成四个关键部分:</p><ul class=""><li id="beba" class="op oq it la b lb lc le lf lh or ll os lp ot lt ou ov ow ox bi translated"><strong class="la iu">发电机设置</strong> —包括架构设置、损耗计算和优化器。</li><li id="92da" class="op oq it la b lb oy le oz lh pa ll pb lp pc lt ou ov ow ox bi translated"><strong class="la iu">鉴别器设置</strong>——包括同上。</li><li id="aaab" class="op oq it la b lb oy le oz lh pa ll pb lp pc lt ou ov ow ox bi translated"><strong class="la iu">步骤</strong> —在训练、噪声生成、模型预测、损失和权重更新期间，我们对每一次迭代采取的过程。</li><li id="30ca" class="op oq it la b lb oy le oz lh pa ll pb lp pc lt ou ov ow ox bi translated"><strong class="la iu"> Fit </strong> —训练控制器功能，包括可视化和模型检查点保存。</li></ul><p id="1f3e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">模型架构本身就挺有意思的。DCGAN几乎只使用CNN(没有最大池，最小密集连接的nn)。</p><p id="14b3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们将在接下来的章节中进行更深入的探讨，但简而言之——发生器和鉴别器是两个独立的、几乎相反的CNN。</p><p id="ffb9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">生成器生成图像，鉴别器识别假图像(由生成器生成)和真图像(我们从YouTube检索)。</p><p id="aae3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">通过竞争，我们产生了一个图像生成器。能够骗过CNN(鉴别者)。</p><h2 id="caa0" class="np mn it bd mo nq nr dn ms ns nt dp mw lh nu nv my ll nw nx na lp ny nz nc oa bi translated">发电机</h2><p id="ba7b" class="pw-post-body-paragraph ky kz it la b lb ne ju ld le nf jx lg lh ng lj lk ll nh ln lo lp ni lr ls lt im bi translated">生成器存储在一个创造性地命名为<code class="fe nj nk nl nm b">Generator</code>的类中。在这里，我们将有三种方法— <code class="fe nj nk nl nm b">dcgan</code>、<code class="fe nj nk nl nm b">optimiser</code>和<code class="fe nj nk nl nm b">loss</code>。</p><p id="95f0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们的第一个方法，<code class="fe nj nk nl nm b">dcgan</code>，包含模型设置。我们将构建这个来产生大小为360 * 640的RGB图像(一个<code class="fe nj nk nl nm b">640, 360, 3</code>的数组形状)。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="e054" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们首先初始化一个TensorFlow <code class="fe nj nk nl nm b">Sequential</code>模型。在这之后，我们简单地使用<code class="fe nj nk nl nm b">add</code>方法添加每个连续的层。有三个层段，输入<code class="fe nj nk nl nm b">Dense</code>和<code class="fe nj nk nl nm b">Reshape</code>，后面是两个<code class="fe nj nk nl nm b">Conv2DTranspose</code>段。</p><p id="4ee4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输入部分采用我们的<code class="fe nj nk nl nm b">latent_units</code>，它只是一个输入层的噪声，我们将其输入到发生器，并将其输入到一个密集连接的神经网络。然后，这些NN激活被整形以适合下面的转置卷积层。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl pd"><img src="../Images/5e7d13f46a212ebd89558e48ef6eda4a.png" data-original-src="https://miro.medium.com/v2/format:webp/1*btNvLTk6N8N5DTiFZiDrCg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">泄漏激活功能</p></figure><p id="6a0a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在每个NN层之后，我们包括一个<code class="fe nj nk nl nm b">BatchNormalization</code>和<code class="fe nj nk nl nm b">LeakyReLU</code>层。<code class="fe nj nk nl nm b">BatchNormalization</code>确保模型权重正常化，从而降低渐变消失或爆炸的几率。<code class="fe nj nk nl nm b">LeakyReLU</code>是我们的激活功能。</p><p id="9dda" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后的<code class="fe nj nk nl nm b">Conv2DTranspose</code>层产生我们生成的图像。我们在这里使用一个<code class="fe nj nk nl nm b">tanh</code>激活函数<a class="ae md" href="https://github.com/soumith/ganhacks" rel="noopener ugc nofollow" target="_blank">，在开发GANs时，推荐使用</a>而不是<code class="fe nj nk nl nm b">sigmoid</code>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="b6a8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们的发电机优化器和损耗分别用<code class="fe nj nk nl nm b">optimiser</code>和<code class="fe nj nk nl nm b">loss</code>定义。发电机的损耗通过<code class="fe nj nk nl nm b">fake_preds</code>——鉴频器的输出来计算。</p><p id="b0dd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在鉴别器错误地将所有假图像<code class="fe nj nk nl nm b">0</code>预测为真实图像<code class="fe nj nk nl nm b">1</code>的情况下，发电机损耗被最小化。因此我们在二元交叉熵计算中使用了<code class="fe nj nk nl nm b">tf.ones_like</code>。</p><h2 id="a41f" class="np mn it bd mo nq nr dn ms ns nt dp mw lh nu nv my ll nw nx na lp ny nz nc oa bi translated">鉴别器</h2><p id="4d6c" class="pw-post-body-paragraph ky kz it la b lb ne ju ld le nf jx lg lh ng lj lk ll nh ln lo lp ni lr ls lt im bi translated">鉴别器与我们的生成器非常相似，但是我们没有使用<code class="fe nj nk nl nm b">Conv2DTranspose</code>层，而是使用普通的<code class="fe nj nk nl nm b">Conv2D</code>。我们还包括一个<code class="fe nj nk nl nm b">Dropout</code>层，它赋予每个值在任一时刻被屏蔽的50%的概率。帮助我们防止过度拟合并鼓励一般化。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="1759" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们使用相同的优化器和相似的损失函数。在这种情况下，当鉴别器成功地将真实图像识别为<code class="fe nj nk nl nm b">1</code>并将虚假图像识别为<code class="fe nj nk nl nm b">0</code>时，损失被最小化。</p><h2 id="89b5" class="np mn it bd mo nq nr dn ms ns nt dp mw lh nu nv my ll nw nx na lp ny nz nc oa bi translated">步骤</h2><p id="532a" class="pw-post-body-paragraph ky kz it la b lb ne ju ld le nf jx lg lh ng lj lk ll nh ln lo lp ni lr ls lt im bi translated"><code class="fe nj nk nl nm b">step</code>和<code class="fe nj nk nl nm b">fit</code>都包含在<code class="fe nj nk nl nm b">Train</code>类中，我们用生成器<code class="fe nj nk nl nm b">G</code>和鉴别器<code class="fe nj nk nl nm b">D</code>模型对其进行初始化。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="ee69" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于每个步骤/迭代，我们必须做几件事:</p><ul class=""><li id="b470" class="op oq it la b lb lc le lf lh or ll os lp ot lt ou ov ow ox bi translated">生成<code class="fe nj nk nl nm b">noise</code> —使用大小的正态分布<code class="fe nj nk nl nm b">batchsize, latent_units</code>，在我们的例子中是<code class="fe nj nk nl nm b">64, 100</code>。</li><li id="8ec5" class="op oq it la b lb oy le oz lh pa ll pb lp pc lt ou ov ow ox bi translated">通过处理<code class="fe nj nk nl nm b">noise</code>到<code class="fe nj nk nl nm b">G.model</code>生成<code class="fe nj nk nl nm b">fake_images</code>。</li><li id="1988" class="op oq it la b lb oy le oz lh pa ll pb lp pc lt ou ov ow ox bi translated">通过处理<code class="fe nj nk nl nm b">real_images</code>和<code class="fe nj nk nl nm b">fake_images</code>到<code class="fe nj nk nl nm b">D.model</code>进行预测。</li><li id="ca25" class="op oq it la b lb oy le oz lh pa ll pb lp pc lt ou ov ow ox bi translated">计算<code class="fe nj nk nl nm b">G_loss</code>和<code class="fe nj nk nl nm b">D_loss</code> —将<code class="fe nj nk nl nm b">real_output</code>和<code class="fe nj nk nl nm b">fake_output</code>输入到我们在每个类中定义的<code class="fe nj nk nl nm b">loss</code>函数、<code class="fe nj nk nl nm b">G.loss</code>和<code class="fe nj nk nl nm b">D.loss</code>中。</li><li id="a6cc" class="op oq it la b lb oy le oz lh pa ll pb lp pc lt ou ov ow ox bi translated">计算<code class="fe nj nk nl nm b">G</code>和<code class="fe nj nk nl nm b">D</code>梯度——使用每个模型的<code class="fe nj nk nl nm b">tf.GradientTape</code>,我们输入模型损失和可训练变量。</li><li id="8577" class="op oq it la b lb oy le oz lh pa ll pb lp pc lt ou ov ow ox bi translated">最后，我们使用<code class="fe nj nk nl nm b">opt.apply_gradients</code>应用渐变更新。</li></ul><p id="1c15" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在代码中，这看起来像:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="321c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请注意，<code class="fe nj nk nl nm b">self</code>正在被使用，因为这是一个在<code class="fe nj nk nl nm b">Train</code>类内部的方法。在该方法的最后，我们将发生器和鉴别器损耗的平均值添加到我们的<code class="fe nj nk nl nm b">history</code>数据帧中，我们稍后将使用该数据帧来可视化损耗。</p><h2 id="6844" class="np mn it bd mo nq nr dn ms ns nt dp mw lh nu nv my ll nw nx na lp ny nz nc oa bi translated">合适的</h2><p id="cafe" class="pw-post-body-paragraph ky kz it la b lb ne ju ld le nf jx lg lh ng lj lk ll nh ln lo lp ni lr ls lt im bi translated">这是我们最后的主要方法，它作为我们刚刚讨论过的所有代码的控制器。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="3cec" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">与以前的代码相比，这部分更容易掌握。首先，我们创建<code class="fe nj nk nl nm b">gen_noise</code>作为我们用来生成可视化效果的唯一噪声轮廓。这不是在培训中使用的，它只是为了让我们直观地衡量发电机如何随着时间的推移而发展。</p><p id="ebcb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们将<code class="fe nj nk nl nm b">gen_noise</code>输入生成器<code class="fe nj nk nl nm b">G.model</code>，它给我们一个生成的图像数组<code class="fe nj nk nl nm b">gen_image</code>。这个数组被格式化，转换成PIL图像对象，然后保存到文件中。</p><p id="f978" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">用<code class="fe nj nk nl nm b">sns.lineplot</code>显示发生器和鉴别器的损耗，然后保存到文件中。两个损失值也会打印到控制台。</p><p id="ca21" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，我们使用<code class="fe nj nk nl nm b">save_weights</code>方法每500个时期保存一次模型权重。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/52bda6a95c4c14ecd0c8c7720dfb5d77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ktg8pdf205AOkjcXm8VUXw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">生成的图像</p></figure></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="0d88" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">虽然仍处于早期阶段，但看到那些从GAN生成的图像中出现的迈阿密复古太阳的第一张图像是一种惊人的体验。</p><p id="7925" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是一个正在进行的项目，有很大的改进空间。但是gan很有趣，对于任何考虑看一看它们的人，我强烈推荐它。</p><p id="5e68" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果有什么不清楚的，随时问我。如果你有改进的建议，请告诉我！我将在下面的参考资料中留下涵盖所有GAN代码部分的资源链接。</p><p id="c9f2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">感谢阅读！</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="db88" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">参考</h1><p id="c922" class="pw-post-body-paragraph ky kz it la b lb ne ju ld le nf jx lg lh ng lj lk ll nh ln lo lp ni lr ls lt im bi translated">Aviv Elbag，<a class="ae md" href="https://www.youtube.com/watch?v=tX-6CMNnT64" rel="noopener ugc nofollow" target="_blank">生成式对抗网络(GANs)完整编码示例教程在Tensorflow 2.0 </a>，YouTube</p><p id="5a83" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae md" href="https://www.tensorflow.org/tutorials/generative/dcgan" rel="noopener ugc nofollow" target="_blank">深度卷积生成对抗网络教程</a>，TensorFlow</p><p id="9d28" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Soumith Chintala，<a class="ae md" href="https://github.com/soumith/ganhacks" rel="noopener ugc nofollow" target="_blank">如何训练一个GAN？让GANs发挥作用的技巧和诀窍</a>，GitHub</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/43466b1aba24774097f296acd61e8792.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kiQiLeHkFNd7tm4M.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在Matplotlib中构建的Synthwave图</p></figure><p id="3f30" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个想法源于我做的一个早期项目，在那里我使用Matplotlib构建了你在上面看到的Synthwave visual。如果你有兴趣了解这些，你可以在这里阅读:</p><div class="pf pg gp gr ph pi"><a rel="noopener follow" target="_blank" href="/creating-synthwave-with-matplotlib-ea7c9be59760"><div class="pj ab fo"><div class="pk ab pl cl cj pm"><h2 class="bd iu gy z fp pn fr fs po fu fw is bi translated">用Matplotlib创建Synthwave</h2><div class="pp l"><h3 class="bd b gy z fp pn fr fs po fu fw dk translated">正确使用Matplotlib创建复古的Synthwave视觉效果</h3></div><div class="pq l"><p class="bd b dl z fp pn fr fs po fu fw dk translated">towardsdatascience.com</p></div></div><div class="pr l"><div class="ps l pt pu pv pr pw ks pi"/></div></div></a></div></div></div>    
</body>
</html>