<html>
<head>
<title>Robust Linear Regression Models for Nonlinear, Heteroscedastic Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">非线性异方差数据的稳健线性回归模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/robust-linear-regression-models-for-nonlinear-heteroscedastic-data-14b1a87c1952?source=collection_archive---------8-----------------------#2020-01-25">https://towardsdatascience.com/robust-linear-regression-models-for-nonlinear-heteroscedastic-data-14b1a87c1952?source=collection_archive---------8-----------------------#2020-01-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/2497e7bc716c08588568671f283e1324.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6qv88irEcy00Jgp32sjpAw.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图片由来自<a class="ae jg" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=4158911" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae jg" href="https://pixabay.com/service/license/" rel="noopener ugc nofollow" target="_blank"> Pixabay 许可</a>的<a class="ae jg" href="https://pixabay.com/users/waldnob-9842518/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=4158911" rel="noopener ugc nofollow" target="_blank">诺贝特·瓦尔德豪森</a>拍摄</p></figure><div class=""/><div class=""><h2 id="af62" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">Python 的分步教程</h2></div><p id="c9c3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们将讨论以下内容:</p><ol class=""><li id="6f76" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated"><strong class="la jk">线性回归模型假设的简要概述</strong>，其中包括关系的线性和同方差(即恒定方差)残差。</li><li id="d7c3" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><strong class="la jk">逐步指导</strong>将回归线性模型拟合到<em class="mi">真实世界</em>数据，而<strong class="la jk">真实世界数据通常是非线性且非均方的</strong>。</li><li id="4274" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><strong class="la jk">段涂抹估计量介绍:</strong>减少预测误差的必要工具。</li><li id="ff1e" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><strong class="la jk">一个基于 Python 的教程:</strong>一直以来，我们将使用来自美国 FRED 的<em class="mi">黄金出口价格指数</em>的真实世界数据集，我们将使用<strong class="la jk"> <em class="mi"> Python、Pandas、Numpy、Patsy 和 Statsmodels </em> </strong>详细说明每个步骤。</li></ol><p id="ab43" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="mi">这篇文章有一种“边学边写”的风格。</em></p><p id="e1e6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我将从第一点的一点理论开始，然后我们将直接进入第二到第四点的动手部分。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h2 id="d962" class="mq mr jj bd ms mt mu dn mv mw mx dp my lh mz na nb ll nc nd ne lp nf ng nh ni bi translated">线性回归模型的假设</h2><p id="f0c3" class="pw-post-body-paragraph ky kz jj la b lb nj kk ld le nk kn lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">线性回归模型，如线性回归模型，如线性回归模型，对线性关系的建模非常有效。它们的运行特性已经被很好地理解，并且它们得到了数十年研究的支持，导致了可解释的、可辩护的和高度可用的结果。</p><p id="cfa2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">线性回归模型有几个假设，即:</p><ul class=""><li id="cfb6" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt no ma mb mc bi translated"><strong class="la jk">线性:</strong>因变量和解释变量之间的关系被假定为线性的，即可以用下面的等式来表示:<br/><strong class="la jk">y</strong>=<strong class="la jk"><em class="mi">β</em></strong><em class="mi">*</em><strong class="la jk"><em class="mi">x</em></strong><em class="mi">+</em><strong class="la jk"><em class="mi">ϵ<br/></em></strong>其中<strong class="la jk"> <em class="mi"> y </em> </strong>是因变量向量 <strong class="la jk"> <em class="mi"> β </em> </strong>是(<strong class="la jk">常值</strong>)回归系数的向量，<strong class="la jk"><em class="mi">【ϵ】</em></strong>是误差项的向量，即<strong class="la jk"><em class="mi"/></strong>y<strong class="la jk"><em class="mi">【x</em></strong>无法解释的部分。</li><li id="99fb" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt no ma mb mc bi translated"><strong class="la jk">独立同分布残差:</strong>回归模型的残差<strong class="la jk"><em class="mi">【ϵ】</em></strong>被假设为<strong class="la jk"> i </strong>相互独立(即残差之间没有相关性)并且<strong class="la jk">I</strong>I<strong class="la jk">d</strong>同分布。此外，我们更喜欢(但不要求)残差是正态分布的。</li><li id="2803" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt no ma mb mc bi translated"><strong class="la jk">同方差残差:</strong>残差中的方差被假定为常数，特别是方差应该<strong class="la jk">而不是</strong>是因变量<strong class="la jk"><em class="mi"/></strong>(或解释变量<strong class="la jk"><em class="mi">×时间</em> </strong>)的函数，或者是时间的函数(在时间序列数据的情况下)。</li></ul><p id="64ab" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">在真实世界的数据集中，数据通常是非线性的和异方差的(即非异方差的)。模型的残差也可能不是完全同分布或正态分布的。</strong></p><p id="bfb1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，我们将了解如何将线性模型拟合到数据中，尽管存在这些实际障碍。</p><p id="f325" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们开始吧。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h2 id="6f6a" class="mq mr jj bd ms mt mu dn mv mw mx dp my lh mz na nb ll nc nd ne lp nf ng nh ni bi translated">真实世界的数据集</h2><p id="dc79" class="pw-post-body-paragraph ky kz jj la b lb nj kk ld le nk kn lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">我们将使用以下黄金价格指数数据集(<a class="ae jg" href="https://gist.github.com/sachinsdate/c2a92fd009c62fee9364c835aff7e2f0" rel="noopener ugc nofollow" target="_blank">此处可用</a>):</p><p id="15b0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae jg" href="https://fred.stlouisfed.org/series/IQ12260#0" rel="noopener ugc nofollow" target="_blank"> <em class="mi">出口价格指数(最终用途):非货币黄金</em> </a> <em class="mi">(来源:美国弗雷德)</em></p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h2 id="0f53" class="mq mr jj bd ms mt mu dn mv mw mx dp my lh mz na nb ll nc nd ne lp nf ng nh ni bi translated">步骤 1:加载数据集</h2><p id="def4" class="pw-post-body-paragraph ky kz jj la b lb nj kk ld le nk kn lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">让我们将数据加载到一个<em class="mi">熊猫数据框架</em>中:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="f74b" class="mq mr jj nu b gy ny nz l oa ob">import pandas as pd</span><span id="1155" class="mq mr jj nu b gy oc nz l oa ob">import numpy as np</span><span id="e29e" class="mq mr jj nu b gy oc nz l oa ob">from matplotlib import pyplot as plt</span><span id="be19" class="mq mr jj nu b gy oc nz l oa ob">df = pd.read_csv('monthly_gold_price_index_fred.csv', header=0, infer_datetime_format=True, parse_dates=[0], index_col=[0])</span><span id="c241" class="mq mr jj nu b gy oc nz l oa ob">print(df.head(10))</span></pre><p id="f7d8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">以下是前 10 行:</p><figure class="np nq nr ns gt iv gh gi paragraph-image"><div class="gh gi od"><img src="../Images/409c8703d8945de513f4501b41e14800.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*bBfESlCCQ33eRkdE6ynk0Q.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">(图片由<a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">作者</a>)</p></figure><p id="ba15" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们将添加一个名为<strong class="la jk"><em class="mi">Time _ Period</em></strong><em class="mi"/>的新列，其取值范围为 1 到 132。</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="0a85" class="mq mr jj nu b gy ny nz l oa ob">df['Time_Period'] = range(1, len(df)+1)</span></pre><p id="ceb0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">打印前 10 行:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="cdd9" class="mq mr jj nu b gy ny nz l oa ob">print(df.head(10))</span></pre><figure class="np nq nr ns gt iv gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/d6f179831032021ef4cdaeff8b49e541.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*9NGJWupeuUs-WJ2zdUvLkg.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">(图片由<a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">作者</a>提供)</p></figure></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h2 id="23a1" class="mq mr jj bd ms mt mu dn mv mw mx dp my lh mz na nb ll nc nd ne lp nf ng nh ni bi translated">步骤 2:检查数据</h2><p id="54fe" class="pw-post-body-paragraph ky kz jj la b lb nj kk ld le nk kn lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">绘制因变量<em class="mi">出口价格黄金指数</em>与<em class="mi">时间段</em>的关系图:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="e007" class="mq mr jj nu b gy ny nz l oa ob"><strong class="nu jk">#Create a new pyplot figure to plot into<br/></strong>fig = plt.figure()</span><span id="b0c6" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#Set the title of the plot<br/></strong>fig.suptitle('Export Price Index of Gold')</span><span id="d483" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#Set the X and Y axis labels<br/></strong>plt.xlabel('Time Period')<br/>plt.ylabel('Price Index')</span><span id="9479" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#plot the time series and store the plot in the <em class="mi">actual</em> variable. We'll need that later for the legend.<br/></strong>actual, = plt.plot(df['Time_Period'], df['Export_Price_Index_of_Gold'], 'bo-', label='Gold Price Index')</span><span id="72da" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#Set up the legend. There is only one time series in the legend.<br/></strong>plt.legend(handles=[actual])</span><span id="b7f4" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#Show everything<br/></strong>plt.show()</span></pre><p id="2cd6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">剧情是这样的:</p><figure class="np nq nr ns gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi of"><img src="../Images/5831f81cec401eb1055f965f06c57d0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bVWEAfDQHSGewhPiSfedow.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">从 2001 年 1 月到 2011 年 12 月连续 132 个月的黄金出口价格指数(<em class="og">来源:</em> <a class="ae jg" href="https://fred.stlouisfed.org/series/IQ12260#0" rel="noopener ugc nofollow" target="_blank"> <em class="og">美国弗雷德</em> </a> <em class="og"> ) </em>(图片由<a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">作者</a></p></figure><p id="c33e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="mi">价格数据显示</em> <strong class="la jk"> <em class="mi">异方差</em> </strong> <em class="mi">即非常数方差，以及</em> <strong class="la jk"> <em class="mi">非线性增长</em> </strong> <em class="mi">。</em></p><p id="ba65" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了确认异方差性，让我们绘制<em class="mi">出口价格黄金指数</em>相对于<em class="mi">时间段</em>的第一个差值:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="f4b7" class="mq mr jj nu b gy ny nz l oa ob"><strong class="nu jk">#create a time lagged column<br/></strong>df['LAGGED_Export_Price_Index_of_Gold'] = df['Export_Price_Index_of_Gold'].shift(1)</span><span id="7a01" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#Do a diff between the Export_Price_Index_of_Gold column and the time lagged version<br/></strong>df['DIFF_Export_Price_Index_of_Gold'] = df['Export_Price_Index_of_Gold']-df['LAGGED_Export_Price_Index_of_Gold']</span><span id="f8e7" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#Plot the diff column using Series.plot()<br/></strong>df['DIFF_Export_Price_Index_of_Gold'].plot()</span><span id="1c1d" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#Display the plot<br/></strong>plt.show()</span></pre><p id="f95d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是一阶差分图，显示方差随时间增加:</p><figure class="np nq nr ns gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oh"><img src="../Images/3184033be02976d70472acb0b8b2fc37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*08QYY5a3bsYfaita9e6Mxg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">显示异方差的出口价格指数的第一个差异(图片由<a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">作者</a>提供)</p></figure></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h2 id="07ed" class="mq mr jj bd ms mt mu dn mv mw mx dp my lh mz na nb ll nc nd ne lp nf ng nh ni bi translated">第三步:消除非线性</h2><p id="c4a3" class="pw-post-body-paragraph ky kz jj la b lb nj kk ld le nk kn lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">我们将首先处理数据中的非线性。</p><p id="74a4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="mi">取因变量的</em> <strong class="la jk"> <em class="mi">对数</em> </strong> <em class="mi">或</em> <strong class="la jk"> <em class="mi">平方根</em> </strong> <em class="mi">具有使数据线性的效果，同时减弱其中的异方差。</em></p><p id="4272" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们将使用出口价格指数的自然对数，因为对数函数比平方根函数增长得更慢，所以它的转换效果比平方根更强。</p><p id="e3f1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在使用这两种变换(对数和平方根)时，我们也应该记住它们的缺点。</p><h2 id="6dd0" class="mq mr jj bd ms mt mu dn mv mw mx dp my lh mz na nb ll nc nd ne lp nf ng nh ni bi translated"><strong class="ak">对数和平方根变换的缺点:</strong></h2><ul class=""><li id="ebcc" class="lu lv jj la b lb nj le nk lh oi ll oj lp ok lt no ma mb mc bi translated"><strong class="la jk">负值:</strong>两种变换都产生负<em class="mi"> y </em>值的未定义值。数据集的负部分需要以不同的方式处理，例如通过两部分模式。</li><li id="7a3a" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt no ma mb mc bi translated"><strong class="la jk">零值:</strong>对于 y=0，对数变换未定义。这可以通过在每个<em class="mi"> y </em>值上增加一个微小的正值来解决，代价是引入一个偏差。更好的方法是使用两部分模型，其中逻辑回归模型学习区分零数据和非零数据，而 OLSR 模型适用于正值数据的对数转换 y。另一种方法是使用一个可以容许零值的<strong class="la jk"> G </strong>一般化<strong class="la jk"> L </strong>线性<strong class="la jk"> M </strong>模型(GLM)。</li></ul><p id="332e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="mi">对数和平方根转换最适用于正值数据。</em></p><p id="4c7d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">还有其他转换可供选择，例如双指数数据的双对数转换。</p><p id="f4b5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">那么，为您的数据选择哪种正确的变换(也称为标度)呢？</p><p id="1865" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="mi">对数变换的基本假设是原始数据呈现指数趋势。使用平方根变换，您假设原始数据呈现幂趋势。</em></p><p id="91f8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在他们的书“广义线性模型”中，McCullagh 和 Nelder 先生提供了一条关于选择正确变换的简洁建议，我将解释如下:</p><blockquote class="ol"><p id="1167" class="om on jj bd oo op oq or os ot ou lt dk translated">一个好的数据转换函数应该能够实现以下三个目标:</p><p id="490d" class="om on jj bd oo op oq or os ot ou lt dk translated">它使方差或多或少地保持恒定，即它减弱了数据中的异方差。</p><p id="c888" class="om on jj bd oo op oq or os ot ou lt dk translated">它使得模型的残差几乎呈正态分布。</p><p id="27b7" class="om on jj bd oo op oq or os ot ou lt dk translated">它确保了线性模型的解释变量和因变量之间的线性加性关系。</p></blockquote><p id="8f81" class="pw-post-body-paragraph ky kz jj la b lb ov kk ld le ow kn lg lh ox lj lk ll oy ln lo lp oz lr ls lt im bi translated">让我们继续进行对数变换的变换练习。</p><p id="d978" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们向名为<em class="mi">LOG _ Export _ Price _ Index _ of _ Gold</em>的数据框添加一个新列，其中包含。我们将使用<em class="mi"> numpy.log() </em>来完成这项工作。</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="8911" class="mq mr jj nu b gy ny nz l oa ob">df['LOG_Export_Price_Index_of_Gold'] = np.log(df['Export_Price_Index_of_Gold'])</span></pre><p id="61e4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">原始变量和记录变量的并排比较揭示了对数变换已经使时间序列线性化:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="2aa6" class="mq mr jj nu b gy ny nz l oa ob"><strong class="nu jk">#Create a (2 x 1) grid of subplots</strong><br/>ax = plt.subplot(1, 2, 1)</span><span id="bc5e" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#Set the title of the first sub-plot</strong><br/>ax.set_title('Export_Price_Index_of_Gold versus Time_Period', fontdict={'fontsize': 12})</span><span id="c423" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#Plot the RAW scale plot</strong><br/>plt.scatter(x=df['Time_Period'].values, y=df['Export_Price_Index_of_Gold'].values, color='r', marker='.')</span><span id="4b87" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#Setup the second subplot</strong><br/>ax = plt.subplot(1, 2, 2)</span><span id="f69d" class="mq mr jj nu b gy oc nz l oa ob">ax.set_title('LOG(Export_Price_Index_of_Gold) versus Time_Period', fontdict={'fontsize': 12})</span><span id="8a42" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#Plot the LOG scale plot</strong><br/>plt.scatter(x=df['Time_Period'].values, y=df['LOG_Export_Price_Index_of_Gold'].values, color='b', marker='.')</span><span id="c121" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#Display both subplots</strong><br/>plt.show()</span></pre><figure class="np nq nr ns gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pa"><img src="../Images/51c883225b4fed4543e47a5f05c5d283.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MjtMMcRLoHAAGKpPXa42xA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">黄金价格指数原始比例图和对数比例图的比较(图片由<a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">作者</a>提供)</p></figure></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h2 id="1c79" class="mq mr jj bd ms mt mu dn mv mw mx dp my lh mz na nb ll nc nd ne lp nf ng nh ni bi translated">步骤 4:将线性回归模型拟合到经过对数变换的数据集</h2><p id="3346" class="pw-post-body-paragraph ky kz jj la b lb nj kk ld le nk kn lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">由于<em class="mi">log(</em><strong class="la jk"><em class="mi">y</em></strong><em class="mi">)</em>相对于<em class="mi"> Time_Period </em>是线性的，我们将使用以下线性回归方程来拟合<em class="mi">log(</em><strong class="la jk"><em class="mi">y</em></strong><em class="mi">)</em>的 OLS 回归模型:</p><p id="45d1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk"><em class="mi">log(Export _ Price _ Index _ of _ Gold)</em></strong><em class="mi"><strong class="la jk"><em class="mi">β_ 0</em></strong><em class="mi">+</em><strong class="la jk"><em class="mi">β_ 1</em></strong><em class="mi">*</em><strong class="la jk"><em class="mi">Time _ Period</em></strong></em></p><p id="cb93" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其中，<strong class="la jk"><em class="mi">β_ 0</em></strong><em class="mi">&amp;</em><strong class="la jk"><em class="mi">β_ 1</em></strong>分别为回归截距和回归系数。</p><p id="7461" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">导入回归包:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="8e18" class="mq mr jj nu b gy ny nz l oa ob"><strong class="nu jk">import </strong>statsmodels.api <strong class="nu jk">as </strong>sm<br/><strong class="nu jk">import </strong>statsmodels.formula.api <strong class="nu jk">as </strong>smf<br/><strong class="nu jk">from </strong>patsy <strong class="nu jk">import </strong>dmatrices</span></pre><p id="18b5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在<a class="ae jg" href="https://patsy.readthedocs.io/en/latest/quickstart.html" rel="noopener ugc nofollow" target="_blank"> patsy 语法</a>中形成模型表达式。我们告诉 Patsy<em class="mi">黄金的 LOG _ Export _ Price _ Index _ of _ Gold</em>依赖于<em class="mi"> Time_Period </em>。Patsy 将自动包含截距<em class="mi"> β_0 </em>:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="8bb5" class="mq mr jj nu b gy ny nz l oa ob">expr = 'LOG_Export_Price_Index_of_Gold ~ Time_Period'</span></pre><p id="fd6e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">创建训练集和测试集:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="469e" class="mq mr jj nu b gy ny nz l oa ob"><strong class="nu jk">#We'll train the model on the first 120 time periods i.e. 120 months of data and we'll test its predictions on the last 12 time periods i.e. 12 months<br/></strong>split_index = 119</span><span id="1534" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#Get the indexed date at the split position<br/></strong>split_date = df.index[split_index]</span><span id="f61b" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#time periods 0 to 119 is the training set<br/></strong>df_train = df.loc[df.index &lt;= split_date].copy()</span><span id="1df0" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#time periods 120 to 131 is the testing set<br/></strong>df_test = df.loc[df.index &gt; split_date].copy()</span><span id="dcd5" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">print</strong>('Model will train on the first ' + str(len(df_train)) + ' months and make predictions for the final ' + str(len(df_test)) + ' months.')</span></pre><p id="9837" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="mi">我特意选择了最后 12 个时间段作为维持(测试)集。如果你仔细观察黄金价格指数图，你会发现在过去的 10-20 个时间段内，数据变得更加非线性，从预测的角度来看，这个区域对于线性模型来说尤其具有挑战性。</em></p><p id="9df2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们在训练集上建立并训练一个普通的最小二乘回归(OLSR)模型:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="7676" class="mq mr jj nu b gy ny nz l oa ob">olsr_results = smf.ols(expr, df_train).fit()</span></pre><p id="2e89" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">打印培训总结:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="4b36" class="mq mr jj nu b gy ny nz l oa ob">print(olsr_results.summary())</span></pre><figure class="np nq nr ns gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pb"><img src="../Images/64595f6a81697cb08aaf20696f43f001.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fuqrofTyZVp45z4DalwGpw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">OLSR 模式总结(图片由<a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">作者</a></p></figure><p id="6a11" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们检查模型的性能:</p><p id="9fb9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk"> R 平方:</strong>该模型能够解释 log(y)中 97.7%的方差，这是一个非常好的拟合。</p><p id="e315" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae jg" rel="noopener" target="_blank" href="/fisher-test-for-regression-analysis-1e1687867259"> <strong class="la jk"> F 统计量</strong></a><strong class="la jk">:</strong>6.42 e-99 的 p 值小得令人难以置信——远小于一个连 0.1% (0.001)都没有的临界值。因此，我们<strong class="la jk">拒绝 f 检验的零假设</strong>，即模型不比仅截距模型好，并且<strong class="la jk">我们接受 f 检验的替代假设</strong>，即模型的系数联合显著。</p><p id="6102" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">模型系数的显著性:</strong>模型系数的 p 值表明它们分别<em class="mi">具有统计显著性</em>。</p><p id="0db7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">总体而言，该模型似乎在训练数据集上实现了高拟合优度。</p><p id="5569" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们获取模型对训练集和测试集的预测。</p><p id="92f5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="mi">注意，我们是预测 log(</em><strong class="la jk"><em class="mi"/></strong><em class="mi">)，而不是 raw</em><strong class="la jk"><em class="mi"/></strong><em class="mi">。</em></p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="c4c7" class="mq mr jj nu b gy ny nz l oa ob"><strong class="nu jk">#Predict log(y) on the training data set</strong><br/>olsr_predictions_training_set = olsr_results.predict(df_train['Time_Period'])</span><span id="60ad" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#Predict log(y) on the testing data set</strong><br/>olsr_predictions_testing_set = olsr_results.predict(df_test['Time_Period'])</span></pre><p id="fd5c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在对数标度上绘制预测值和实际值:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="2eb6" class="mq mr jj nu b gy ny nz l oa ob"><strong class="nu jk">#Create the pyplot figure for plotting</strong><br/>fig = plt.figure()</span><span id="5469" class="mq mr jj nu b gy oc nz l oa ob">fig.suptitle('Predicted versus actual values of LOG(price index)')</span><span id="df2a" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#Plot the log-scale PREDICTIONS for the training data set</strong><br/>predicted_training_set, = plt.plot(df_train.index, olsr_predictions_training_set, 'go-', label='Predicted (Training data set)')</span><span id="48de" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#Plot the log-scale ACTUALS fpr the training data set</strong><br/>actual_training_set, = plt.plot(df_train.index, df_train['LOG_Export_Price_Index_of_Gold'], 'ro-', label='Actuals (Training data set)')</span><span id="e77a" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#Plot the log-scale PREDICTIONS for the testing data set</strong><br/>predicted_testing_set, = plt.plot(df_test.index, olsr_predictions_testing_set, 'bo-', label='Predicted (Testing data set)')</span><span id="88aa" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#Plot the log-scale ACTUALS for the testing data set</strong><br/>actual_testing_set, = plt.plot(df_test.index, df_test['LOG_Export_Price_Index_of_Gold'], 'mo-', label='Actuals (Testing data set)')</span><span id="f656" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#Set up the legends</strong><br/>plt.legend(handles=[predicted_training_set, actual_training_set, predicted_testing_set, actual_testing_set])</span><span id="d1a9" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#Display everything</strong><br/>plt.show()</span></pre><figure class="np nq nr ns gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pc"><img src="../Images/24c51f78ca309f1e69d4e7326fde6819.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wFiVjczbr-oRnFxyCoCP3A.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">训练和测试数据集上<strong class="bd pd"><em class="og">【y】</em></strong>的预测值与实际值(图片由<a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">作者</a>提供)</p></figure></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h2 id="9727" class="mq mr jj bd ms mt mu dn mv mw mx dp my lh mz na nb ll nc nd ne lp nf ng nh ni bi translated">步骤 5:将模型的预测从对数比例转换回原始比例</h2><p id="c1fd" class="pw-post-body-paragraph ky kz jj la b lb nj kk ld le nk kn lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">这是一个需要小心的地方。我们的本能可能是简单地将对数标度预测指数化回原始标度<strong class="la jk"> <em class="mi"> y </em> </strong>。</p><p id="166e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是我们的直觉是错误的。让我们看看这是为什么。</p><p id="db32" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="mi">如果你喜欢，你可以跳过下面的一点点数学，向下滚动到段的涂抹估计器</em>  <em class="mi">的章节。</em></p><p id="6017" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="mi">log(</em><strong class="la jk"><em class="mi">y</em></strong><em class="mi">)</em>对<strong class="la jk"> <em class="mi"> X </em> </strong>的条件期望通过以下线性方程与拟合模型的预测相关:</p><p id="d34b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="mi">e(log(</em><strong class="la jk"><em class="mi">y</em></strong><em class="mi">)|</em><strong class="la jk"><em class="mi">x</em></strong><em class="mi">)=</em><strong class="la jk"><em class="mi">β_ fitted</em></strong><em class="mi">*</em><strong class="la jk"><em class="mi">x</em></strong><em class="mi">+</em><strong class="la jk"><em class="mi"/></strong>…(1)</p><p id="346b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其中:</p><ul class=""><li id="f74c" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt no ma mb mc bi translated"><em class="mi">E(log(</em><strong class="la jk"><em class="mi">y</em></strong><em class="mi">)|</em><strong class="la jk"><em class="mi">X</em></strong><em class="mi">)</em>是<em class="mi">log(</em><strong class="la jk"><em class="mi">y</em></strong><em class="mi">)</em>即<em class="mi">y<em class="mi">的值</em></em></li><li id="a67c" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt no ma mb mc bi translated"><strong class="la jk"> <em class="mi"> β_fitted </em> </strong>是训练模型系数的向量，包括截距的占位符。</li><li id="14fb" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt no ma mb mc bi translated"><strong class="la jk"> <em class="mi"> X </em> </strong>是回归变量的矩阵+一列为回归截距。</li><li id="8e3a" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt no ma mb mc bi translated"><em class="mi"> ϵ </em>是拟合模型的残差向量。<strong class="la jk"><em class="mi">ϵ=predictions</em></strong><em class="mi">减去</em> <strong class="la jk"> <em class="mi">实际值</em> </strong></li></ul><p id="f2fa" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了将预测转换回原始比例，我们对等式(1)的两边取幂:</p><p id="dc2a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">exp(<em class="mi">e(log(</em><strong class="la jk"><em class="mi">y</em></strong><em class="mi">)|</em><strong class="la jk"><em class="mi">x</em></strong><em class="mi">)= exp(</em><strong class="la jk"><em class="mi">β_ fitted</em></strong><em class="mi">*</em><strong class="la jk"><em class="mi">x</em></strong><em class="mi">+</em></p><p id="897c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们要的是<strong class="la jk">不是</strong>exp(<em class="mi">E(log(</em><strong class="la jk"><em class="mi">y</em></strong><em class="mi">)|</em><strong class="la jk"><em class="mi">X</em></strong><em class="mi">)。</em>相反我们要的是<em class="mi">E(exp(log(</em><strong class="la jk"><em class="mi">y</em></strong><em class="mi">)|</em><strong class="la jk"><em class="mi">X</em></strong><em class="mi">))。注意这两者之间微妙但重要的区别。</em></p><p id="561a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，我们将<em class="mi"> E() </em>运算符应用于等式(2)的两边:</p><p id="caa2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="mi">e(exp(e(log(</em><strong class="la jk"><em class="mi">y</em></strong><em class="mi">)|</em><strong class="la jk"><em class="mi">x</em></strong><em class="mi">))= e(exp(</em><strong class="la jk"><em class="mi">β_ fitted</em></strong><em class="mi">*</em><strong class="la jk"><em class="mi">x</em><em class="mi">+</em><strong class="la jk"><em class="mi">【ϵ</em></strong></strong></p><p id="50d6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">经过一些简化后，它变成了:</p><p id="5c20" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="mi">e(</em><strong class="la jk"><em class="mi">y</em></strong><em class="mi">|</em><strong class="la jk"><em class="mi">x</em></strong><em class="mi">)= e(exp(</em><strong class="la jk"><em class="mi">β_ fitted</em></strong><em class="mi">*</em><strong class="la jk">x)<em class="mi"/></strong>【t90)</p><p id="ff3d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这最终简化为:</p><p id="0a70" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="mi">e(</em><strong class="la jk"><em class="mi">y</em></strong><em class="mi">)|</em><strong class="la jk"><em class="mi">x</em></strong><em class="mi">)= exp(</em><strong class="la jk"><em class="mi">β_ fitted</em></strong><em class="mi">*</em><strong class="la jk"><em class="mi">x</em>)<em class="mi"/></strong><em class="mi">* e</em></p><p id="a402" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其中:</p><ul class=""><li id="3399" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt no ma mb mc bi translated"><em class="mi">E(</em><strong class="la jk"><em class="mi">X</em></strong><em class="mi">)|</em><strong class="la jk"><em class="mi">y</em></strong><em class="mi">)</em>是原始标度中的条件期望。正是我们想要的<em class="mi">。</em></li><li id="252a" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt no ma mb mc bi translated"><em class="mi">exp(</em><strong class="la jk"><em class="mi">β_ fitted</em></strong><em class="mi">*</em><strong class="la jk"><em class="mi">X</em>)</strong>是模型的对数标度预测，取幂后转换为原始标度。</li><li id="4504" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt no ma mb mc bi translated"><em class="mi">e(exp(</em><strong class="la jk"><em class="mi"/></strong><em class="mi">)</em>是模型的对数标度模型残差的期望值，在取幂以便将它们转换成原始标度之后。</li></ul><h2 id="12d8" class="mq mr jj bd ms mt mu dn mv mw mx dp my lh mz na nb ll nc nd ne lp nf ng nh ni bi translated">段涂抹估计量</h2><p id="bea7" class="pw-post-body-paragraph ky kz jj la b lb nj kk ld le nk kn lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">总之，为了正确地将模型预测从对数标度重新转换回原始标度，我们需要执行以下操作:</p><ol class=""><li id="e702" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">对回归模型的预测求幂，</li><li id="5879" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">将指数化预测乘以指数化对数标度误差的期望值，即<em class="mi">e(exp(</em><strong class="la jk"><em class="mi">【ϵ</em></strong><em class="mi">))。</em></li></ol><blockquote class="ol"><p id="f5f6" class="om on jj bd oo op pe pf pg ph pi lt dk translated">指数化残差的期望 e(<strong class="ak">)</strong>)称为段涂抹估计量，也称为涂抹因子。</p></blockquote><p id="609b" class="pw-post-body-paragraph ky kz jj la b lb ov kk ld le ow kn lg lh ox lj lk ll oy ln lo lp oz lr ls lt im bi translated"><em class="mi"> E 的值(exp(</em><strong class="la jk"><em class="mi">ϵ</em></strong><em class="mi">)</em>取决于<em class="mi">对数标度</em>残差<strong class="la jk"><em class="mi"/></strong><em class="mi">、</em> <strong class="la jk"> <em class="mi"> </em> </strong>的分布如下:</p><p id="830d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">情况一:对数尺度残差<em class="mi"> ϵ </em>正态分布:</strong>t35】如果<strong class="la jk"> <em class="mi"> ϵ </em> </strong> ~ <em class="mi"> N(0，σ ) </em>即<strong class="la jk"> <em class="mi"> ϵ </em> </strong>正态分布，均值<em class="mi"> </em> =0，方差<em class="mi"> σ，</em>则涂抹因子<em class="mi"> E(exp()这就是<em class="mi"> N(0，σ ) </em>的一阶矩，即。<em class="mi"> exp(0 + 0.5σ ) = exp(0.5σ ) </em></em></p><p id="233f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">情况二:对数尺度残差<em class="mi"> ϵ </em>同分布但不正态分布:<br/> </strong>如果对数尺度残差是<strong class="la jk">I</strong>n 独立，<strong class="la jk">I</strong>d 同分布随机变量但不是<em class="mi"> N(，σ ) </em>，则需要找出它们的分布并然后我们取该分布的一阶矩来得到涂抹因子的值<em class="mi">e(exp(</em><strong class="la jk"><em class="mi">【ϵ</em></strong><em class="mi">)</em>。</p><p id="4c46" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">情况 3:对数尺度残差分布未知:<br/> </strong>在这种情况下:</p><figure class="np nq nr ns gt iv gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/6cc44d4281b8664daecd7105b74ee9ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:468/format:webp/1*G76AtrXcd5MHXXr9CZMSTA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">(图片由<a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">作者</a>)</p></figure><p id="c4df" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其中<em class="mi"> ϵ_i </em> =第 I 个样本的误差，<em class="mi">n</em>=样本数。</p><p id="a730" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从上述三个案例中，我们可以看出:</p><blockquote class="ol"><p id="6a85" class="om on jj bd oo op oq or os ot ou lt dk translated">当误差分布较大时，即方差<em class="og"> σ </em>较大时，涂抹因子较大，或者在情况#3 中，涂抹因子的值较大。</p></blockquote><p id="a9ed" class="pw-post-body-paragraph ky kz jj la b lb ov kk ld le ow kn lg lh ox lj lk ll oy ln lo lp oz lr ls lt im bi translated">让我们为我们的例子计算涂抹因子。</p><h2 id="8e00" class="mq mr jj bd ms mt mu dn mv mw mx dp my lh mz na nb ll nc nd ne lp nf ng nh ni bi translated">步骤 5A:计算段的拖尾因子</h2><p id="6106" class="pw-post-body-paragraph ky kz jj la b lb nj kk ld le nk kn lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">让我们看看残差是否是正态分布的(上面的情况 1)。</p><p id="9645" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们的对数标度模型的残差存储在<code class="fe pk pl pm nu b">olsr_results.resid</code>中。下面是最上面的几行:</p><figure class="np nq nr ns gt iv gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/1ab3b56242ce8629918b5b3acb52c990.png" data-original-src="https://miro.medium.com/v2/resize:fit:626/format:webp/1*RdIVExhHi9Q2t34D3DdhGg.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">OLSR 的残差(图片由<a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">作者</a>提供)</p></figure><p id="8836" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了知道误差是否正态分布，我们将关注 OLSR 模型输出底部的 4 个证据:</p><figure class="np nq nr ns gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi po"><img src="../Images/1592052564e945529f2f1eb0edf67559.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1I0Dyx2g3aLH6JV927bakQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">OLSR 模型剩余误差的特性(图片由<a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">作者</a>提供)</p></figure><p id="92a6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">偏斜度:</strong>残差的偏斜度(-0.025)几乎为零。相比之下，正态分布的偏斜度为零。</p><p id="d981" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">峰度:</strong>残差的峰度(2.984)几乎等于 3.0。正态分布的峰度是 3.0。</p><p id="a40e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">正态性的综合 K 检验:</strong>综合检验极高的 p 值(0.96)使我们接受了检验的零假设，即残差呈正态分布。</p><p id="e0a8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">Jarque-Bera 正态性检验:</strong>JB 检验极高的 p 值(0.993)再次验证了 JB 检验的残差正态分布的零假设。</p><p id="689d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">所有证据表明残差呈正态分布。</strong></p><p id="1f57" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这一结论也从视觉上得到证实:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="810b" class="mq mr jj nu b gy ny nz l oa ob">plt.hist(olsr_results.resid, bins=20)<br/>plt.show()</span></pre><figure class="np nq nr ns gt iv gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/a05b8137b8a01e5c3085e9be359501da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*Lc9Kozm7De_8-jc7dPK-9g.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">残差直方图(图片由<a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">作者</a>提供)</p></figure><p id="d1dc" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们使用<code class="fe pk pl pm nu b">pandas.core.series.Series</code>对象的<em class="mi"> mean() </em>和<em class="mi"> var() </em>函数打印出残差的均值<em class="mi"> </em>和方差<em class="mi"> σ </em>:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="1d98" class="mq mr jj nu b gy ny nz l oa ob">print('Mean of residual errors='+str(olsr_results.resid.mean()))<br/>print('Variance of residual errors='+str(olsr_results.resid.var()))</span><span id="7f0a" class="mq mr jj nu b gy oc nz l oa ob">Mean of residual errors=-3.841371665203042e-15<br/>Variance of residual errors=0.005319971501418866</span></pre><p id="eade" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以看到，平均值实际上是零。这完全可以从 OLSR 模型中预料到。方差为 0.00532。</p><p id="e6ed" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">由于我们已经证明残差是<em class="mi"> N(0，σ ) </em>分布，根据<strong class="la jk">情形#1 </strong>，段的涂抹因子为:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="c964" class="mq mr jj nu b gy ny nz l oa ob"><em class="mi">E(exp(</em><strong class="nu jk"><em class="mi">ϵ</em></strong><em class="mi">)) = exp(0.5σ²) = exp(0.5*</em>0.00532) = <strong class="nu jk">1.00266</strong></span></pre><p id="0a49" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们的抹黑因素到位了。我们准备好使用它了吗？还没有。我们还需要检查最后一件事:</p><p id="7b97" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">残差是齐次的吗？</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h2 id="4935" class="mq mr jj bd ms mt mu dn mv mw mx dp my lh mz na nb ll nc nd ne lp nf ng nh ni bi translated">步骤 5B:检查残差是否是同方差的</h2><p id="375e" class="pw-post-body-paragraph ky kz jj la b lb nj kk ld le nk kn lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated"><em class="mi">如果残差</em><strong class="la jk"><em class="mi"/></strong><em class="mi">不是异方差的，即它们是异方差的，则段的涂抹因子产生有偏的结果。</em></p><p id="b369" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当<strong class="la jk"> <em class="mi"> ϵ </em> </strong>为异方差时，<em class="mi">方差(</em><strong class="la jk"><em class="mi">ϵ</em></strong><em class="mi">)</em>不是常数。事实上<em class="mi">方差(</em><strong class="la jk"><em class="mi"/></strong><em class="mi">)</em>可以是模型的解释变量<strong class="la jk"><em class="mi">×t58】的函数。在我们的例子中，<strong class="la jk"><em class="mi">X</em></strong><em class="mi">=</em><strong class="la jk"><em class="mi">Time _ Period</em></strong></em></strong></p><p id="c545" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，如果<strong class="la jk"><em class="mi"/></strong><em class="mi">为 N( 0，σ(</em><strong class="la jk"><em class="mi">x</em></strong><em class="mi">)</em>分布，即残差服从零均值正态分布，并且有一个方差函数:<em class="mi">【σ(</em><strong class="la jk"><em class="mi">x</em></strong><em class="mi">)</em>，那么根据前面提到的<strong class="la jk">案例#1 </strong>:</p><p id="9a68" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="mi">涂抹因子= e(exp(</em><strong class="la jk"><em class="mi">)ϵ</em></strong><em class="mi">)= exp(0.5 *σ(</em><strong class="la jk"><em class="mi">x</em></strong><em class="mi">)</em></p><p id="49d7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="mi">当回归模型的残差在对数尺度上是异方差时，为了计算涂抹因子，我们需要知道如何计算方差函数σ (X)。</em></p><p id="3146" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然而在实践中，计算方差函数<em class="mi">σ(</em><strong class="la jk"><em class="mi">X</em></strong><em class="mi">)</em>可能不是一件容易的事情。</p><p id="5042" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当残差在对数尺度上是异方差的时，通常最好执行以下操作:</p><h2 id="4e8b" class="mq mr jj bd ms mt mu dn mv mw mx dp my lh mz na nb ll nc nd ne lp nf ng nh ni bi translated">处理异方差残差的方法</h2><ul class=""><li id="f1da" class="lu lv jj la b lb nj le nk lh oi ll oj lp ok lt no ma mb mc bi translated">验证通货膨胀和季节性的影响已经通过通货膨胀调整和季节性调整被抵消。这与货币数据尤其相关。</li><li id="b068" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt no ma mb mc bi translated">检查模型中是否缺少任何重要的解释变量，并将它们添加进来。</li><li id="8cc7" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt no ma mb mc bi translated">代替使用原始残差<strong class="la jk"><em class="mi"/></strong>，使用<strong class="la jk"> <em class="mi">异方差调整残差</em> </strong>(也称为“白化”残差)来计算段的涂抹估计量<strong class="la jk"> <em class="mi">。</em> </strong> <em class="mi"> Statsmodels </em>通过变量<code class="fe pk pl pm nu b">RegressionResults.wresid</code>使白化残差在回归模型的训练输出中可用。</li><li id="a367" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt no ma mb mc bi translated">切换到 a <strong class="la jk"> G </strong>通用<strong class="la jk"> L </strong>线性<strong class="la jk"> M </strong>模式(<strong class="la jk"> GLM </strong>)。GLM 假设<em class="mi">方差</em>是<em class="mi">均值</em>的函数，而<em class="mi">均值</em>本身是解释变量<strong class="la jk"> <em class="mi"> X </em> </strong>的函数。</li><li id="a18e" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt no ma mb mc bi translated">切换到一个<strong class="la jk"> W </strong>八个<strong class="la jk"> L </strong>东<strong class="la jk"> S </strong>方(<strong class="la jk"> WSS </strong>)或一个<strong class="la jk"> G </strong>一般化<strong class="la jk"> L </strong>东 S 方(<strong class="la jk"> GLS </strong>)模型，该模型不假设方差是同质的。</li><li id="c4b2" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt no ma mb mc bi translated">最后，如果残差中的异方差很小，并且你的<strong class="la jk"> OLSR </strong>模型在其他方面表现良好，<strong class="la jk">就照原样接受你的 OLSR 模型吧！</strong></li></ul><p id="b507" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们测试一下我们的模型的残差是否是同方差的。如果是，我们是清白的，否则我们应该考虑上述 4 个补救措施之一。</p><p id="5f92" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Statsmodels 包含一个异方差的<strong class="la jk">怀特测试的实现，它可以很容易地应用于我们的残差，如下所示:</strong></p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="57cc" class="mq mr jj nu b gy ny nz l oa ob"><strong class="nu jk">#Using patsy, pull out the <em class="mi">X</em> matrix containing the Time_Period and the intercept columns from the pandas Data Frame.</strong></span><span id="0cd8" class="mq mr jj nu b gy oc nz l oa ob">expr = 'LOG_Export_Price_Index_of_Gold ~ Time_Period'</span><span id="b6a0" class="mq mr jj nu b gy oc nz l oa ob">y_train, X_train = dmatrices(expr, df_train, return_type='dataframe')</span></pre><p id="2cde" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">导入测试包并运行 White 的测试:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="3052" class="mq mr jj nu b gy ny nz l oa ob">from statsmodels.stats.diagnostic import <strong class="nu jk">het_white</strong></span><span id="887a" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">from </strong>statsmodels.compat <strong class="nu jk">import </strong>lzip</span><span id="42d8" class="mq mr jj nu b gy oc nz l oa ob">keys = ['<strong class="nu jk">Lagrange Multiplier statistic:</strong>', '<strong class="nu jk">LM test\'s p-value:</strong>', '<strong class="nu jk">F-statistic:</strong>', '<strong class="nu jk">F-test\'s p-value:</strong>']</span><span id="72a4" class="mq mr jj nu b gy oc nz l oa ob">test = <strong class="nu jk">het_white</strong>(olsr_results.resid, X_train)</span><span id="3986" class="mq mr jj nu b gy oc nz l oa ob">lzip(keys, test)</span></pre><p id="bcf5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这将打印出以下输出:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="6666" class="mq mr jj nu b gy ny nz l oa ob">[('<strong class="nu jk">Lagrange Multiplier statistic:</strong>', 3.2148975951052883), <br/> ("<strong class="nu jk">LM test's p-value:</strong>", 0.20039821889655918), <br/> ('<strong class="nu jk">F-statistic:</strong>', 1.610406682366166), <br/> ("<strong class="nu jk">F-test's p-value:</strong>", 0.2042032693339592)]</span></pre><p id="7cf3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk"> LM 检验:</strong>LM 检验的统计量遵循卡方分布，自由度=模型-1 的 DF =(3–1)= 2。p 值 0.2 使我们<strong class="la jk">接受检验的零假设，即残差中没有异方差</strong>。</p><p id="7066" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">f 检验:f 检验的统计量遵循 f 分布。同样，0.204 的高 p 值<strong class="la jk">证实了检验的零假设</strong>，即残差中不存在异方差。</p><p id="d349" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">总体而言，我们的结论是残差是同方差的。</strong></p><p id="9ca7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们进行回归分析的最后一步，将预测值转换回原始标度，并使用段的模糊因子进行修正。</p><h2 id="07d2" class="mq mr jj bd ms mt mu dn mv mw mx dp my lh mz na nb ll nc nd ne lp nf ng nh ni bi translated">步骤 5C:将预测从对数标度转换为原始标度</h2><p id="54cf" class="pw-post-body-paragraph ky kz jj la b lb nj kk ld le nk kn lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">回想一下，训练集和测试集的对数标度<strong class="la jk">预测</strong>和对数标度<strong class="la jk">实际值</strong>存储在以下变量中:</p><ul class=""><li id="141b" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt no ma mb mc bi translated"><code class="fe pk pl pm nu b">olsr_predictions_training_set</code>和<code class="fe pk pl pm nu b">df_train['LOG_Export_Price_Index_of_Gold']</code></li><li id="c7fc" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt no ma mb mc bi translated"><code class="fe pk pl pm nu b">olsr_predictions_testing_set </code>和<code class="fe pk pl pm nu b">df_test['LOG_Export_Price_Index_of_Gold']</code>。</li></ul><p id="09e8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们对所有四个变量进行指数运算，将它们转换回原始比例。为此，我们将使用<em class="mi"> numpy.exp() </em>:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="aef3" class="mq mr jj nu b gy ny nz l oa ob">olsr_predictions_raw_scale_training_set = <strong class="nu jk">np.exp</strong>(olsr_predictions_training_set)</span><span id="32f6" class="mq mr jj nu b gy oc nz l oa ob">actuals_raw_scale_training_set = <strong class="nu jk">np.exp</strong>(df_train['LOG_Export_Price_Index_of_Gold'])</span><span id="59bf" class="mq mr jj nu b gy oc nz l oa ob">olsr_predictions_raw_scale_testing_set = <strong class="nu jk">np.exp</strong>(olsr_predictions_testing_set)</span><span id="772b" class="mq mr jj nu b gy oc nz l oa ob">actuals_raw_scale_testing_set = <strong class="nu jk">np.exp</strong>(df_test['LOG_Export_Price_Index_of_Gold'])</span></pre><p id="9af4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">将原始比例预测值乘以我们之前计算的段涂抹系数<strong class="la jk"> 1.00266 </strong>。</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="b6e7" class="mq mr jj nu b gy ny nz l oa ob"><strong class="nu jk">adjusted</strong>_olsr_predictions_raw_scale_training_set = olsr_predictions_raw_scale_training_set*<strong class="nu jk">1.00266</strong></span><span id="112e" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">adjusted</strong>_olsr_predictions_raw_scale_testing_set = olsr_predictions_raw_scale_testing_set*<strong class="nu jk">1.00266</strong></span></pre><p id="024e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，绘制所有四个(调整后的)原始比例值:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="7d7c" class="mq mr jj nu b gy ny nz l oa ob"><strong class="nu jk">#Create the pyplot figure for plotting</strong><br/>fig = plt.figure()</span><span id="6146" class="mq mr jj nu b gy oc nz l oa ob">fig.suptitle('Predicted versus actual values of Gold Price Index')</span><span id="076d" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#Plot the raw scale predictions made on the training data set</strong><br/>predicted_training_set, = plt.plot(df_train.index, adjusted_olsr_predictions_raw_scale_training_set, 'go-', label='Predicted (Training data set)')</span><span id="b748" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#Plot the raw scale actual values in the training data set</strong><br/>actual_training_set, = plt.plot(df_train.index, df_train['Export_Price_Index_of_Gold'], 'ro-', label='Actuals (Training data set)')</span><span id="49a1" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#Plot the raw scale predictions made on the testing data set</strong><br/>predicted_testing_set, = plt.plot(df_test.index, adjusted_olsr_predictions_raw_scale_testing_set, 'bo-', label='Predicted (Testing data set)')</span><span id="29d5" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#Plot the raw scale actual values in the testing data set</strong><br/>actual_testing_set, = plt.plot(df_test.index, df_test['Export_Price_Index_of_Gold'], 'mo-', label='Actuals (Testing data set)')</span><span id="17c1" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#Set up the legends</strong><br/>plt.legend(handles=[predicted_training_set, actual_training_set, predicted_testing_set, actual_testing_set])</span><span id="965e" class="mq mr jj nu b gy oc nz l oa ob"><strong class="nu jk">#Display everything</strong><br/>plt.show()</span></pre><p id="c755" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们得到如下的情节:</p><figure class="np nq nr ns gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pq"><img src="../Images/638e69c1dc7a890930c55f1fde859d0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JXpAxHWCwMECoXiw_c2c0g.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">训练和测试数据集上的<strong class="bd pd"> <em class="og">原始标度 y </em> </strong>的预测值与实际值(图片由<a class="ae jg" href="https://sachin-date.medium.com/" rel="noopener">作者</a>提供)</p></figure><p id="218d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">人们不应该对测试数据集上的实际值(洋红色)和预测值(蓝色)之间的较大偏差感到太失望，原因有两个:</p><ol class=""><li id="194d" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">请注意，在维持期间，原始数据变得明显非线性，因此我们的维持集对于线性模型尤其具有挑战性，</li><li id="d14f" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">我们要求我们的模型预测未来整整 12 个月的价格指数！实际上，我们会做<strong class="la jk">n 步滚动预测</strong>，其中 n 最多可以是 1 到 6 个月。</li></ol></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h2 id="8a0a" class="mq mr jj bd ms mt mu dn mv mw mx dp my lh mz na nb ll nc nd ne lp nf ng nh ni bi translated">摘要</h2><p id="108d" class="pw-post-body-paragraph ky kz jj la b lb nj kk ld le nk kn lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">我们在本文中讨论了几个主题。我们来总结一下:</p><ol class=""><li id="d900" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">线性回归模型假设概述。</li><li id="6d6a" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">非线性数据线性化技术，这些技术的缺点以及如何处理这些缺点。</li><li id="e3ce" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">如何将线性模型拟合到线性化数据，以及如何评估其性能。</li><li id="172f" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">概述<strong class="la jk">段的涂抹因子</strong>以及如何使用它来提高拟合模型的预测精度。</li><li id="0128" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">如何在模型的剩余误差中发现异方差以及你处理它的选择。</li></ol></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h2 id="c63c" class="mq mr jj bd ms mt mu dn mv mw mx dp my lh mz na nb ll nc nd ne lp nf ng nh ni bi translated">参考</h2><p id="cf72" class="pw-post-body-paragraph ky kz jj la b lb nj kk ld le nk kn lg lh nl lj lk ll nm ln lo lp nn lr ls lt im bi translated">段，N. (1983)，“<strong class="la jk">涂抹估计:一种非参数重变换方法</strong>，《美国统计学会杂志》，78，605–610。</p><p id="3ee9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">曼宁，w .，穆拉希，J. (2001)，“<strong class="la jk">估计对数模型:转变还是不转变</strong>，《卫生经济学杂志》，20，461–494</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h2 id="f6ea" class="mq mr jj bd ms mt mu dn mv mw mx dp my lh mz na nb ll nc nd ne lp nf ng nh ni bi translated">相关阅读</h2><div class="is it gp gr iu pr"><a rel="noopener follow" target="_blank" href="/assumptions-of-linear-regression-5d87c347140"><div class="ps ab fo"><div class="pt ab pu cl cj pv"><h2 class="bd jk gy z fp pw fr fs px fu fw ji bi translated">线性回归的假设</h2><div class="py l"><h3 class="bd b gy z fp pw fr fs px fu fw dk translated">以及如何使用 Python 测试它们。</h3></div><div class="pz l"><p class="bd b dl z fp pw fr fs px fu fw dk translated">towardsdatascience.com</p></div></div><div class="qa l"><div class="qb l qc qd qe qa qf ja pr"/></div></div></a></div><div class="is it gp gr iu pr"><a rel="noopener follow" target="_blank" href="/heteroscedasticity-is-nothing-to-be-afraid-of-730dd3f7ca1f"><div class="ps ab fo"><div class="pt ab pu cl cj pv"><h2 class="bd jk gy z fp pw fr fs px fu fw ji bi translated">异方差没有什么可怕的</h2><div class="py l"><h3 class="bd b gy z fp pw fr fs px fu fw dk translated">使用 Python 的原因、影响、测试和解决方案</h3></div><div class="pz l"><p class="bd b dl z fp pw fr fs px fu fw dk translated">towardsdatascience.com</p></div></div><div class="qa l"><div class="qb l qc qd qe qa qf ja pr"/></div></div></a></div><div class="is it gp gr iu pr"><a rel="noopener follow" target="_blank" href="/testing-for-normality-using-skewness-and-kurtosis-afd61be860"><div class="ps ab fo"><div class="pt ab pu cl cj pv"><h2 class="bd jk gy z fp pw fr fs px fu fw ji bi translated">使用偏度和峰度检验正态性</h2><div class="py l"><h3 class="bd b gy z fp pw fr fs px fu fw dk translated">…以及使用综合 K 平方和 Jarque–Bera 正态性检验的分步指南</h3></div><div class="pz l"><p class="bd b dl z fp pw fr fs px fu fw dk translated">towardsdatascience.com</p></div></div><div class="qa l"><div class="qg l qc qd qe qa qf ja pr"/></div></div></a></div><div class="is it gp gr iu pr"><a rel="noopener follow" target="_blank" href="/fisher-test-for-regression-analysis-1e1687867259"><div class="ps ab fo"><div class="pt ab pu cl cj pv"><h2 class="bd jk gy z fp pw fr fs px fu fw ji bi translated">回归分析的 f 检验</h2><div class="py l"><h3 class="bd b gy z fp pw fr fs px fu fw dk translated">如何使用它，如何解释它的结果</h3></div><div class="pz l"><p class="bd b dl z fp pw fr fs px fu fw dk translated">towardsdatascience.com</p></div></div><div class="qa l"><div class="qh l qc qd qe qa qf ja pr"/></div></div></a></div></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><p id="a203" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="mi">感谢阅读！如果您喜欢这篇文章，请关注我的</em><a class="ae jg" href="https://timeseriesreasoning.medium.com" rel="noopener"><strong class="la jk"><em class="mi">Sachin Date</em></strong></a><em class="mi">以获得关于回归和时间序列分析主题的提示、操作方法和编程建议。</em></p></div></div>    
</body>
</html>