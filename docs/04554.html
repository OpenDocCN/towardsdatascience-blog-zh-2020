<html>
<head>
<title>Scraping Google Maps reviews in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python抓取谷歌地图评论</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/scraping-google-maps-reviews-in-python-2b153c655fc2?source=collection_archive---------3-----------------------#2020-04-23">https://towardsdatascience.com/scraping-google-maps-reviews-in-python-2b153c655fc2?source=collection_archive---------3-----------------------#2020-04-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="b0b0" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用BeautifulSoup和Selenium抓取最新评论</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/a9705757b457b84ab5405d4e8b6b3d22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ZXUn2POVDm_zRj5r"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@hjkp?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">亨利·佩克斯</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="a6d1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇文章中，我想和你分享一些关于如何使用<strong class="ky ir"> Python </strong> <strong class="ky ir"> Selenium </strong>和<strong class="ky ir"> BeautifulSoup </strong>库来应用数据抓取的知识:这两个工具以正确的方式结合起来允许定义一组API来从几乎任何网站收集数据。</p><p id="61a1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">注意:</strong>从网站收集的任何数据都可能受到版权保护，这意味着未经所有者同意不得重复使用，并且不得明确用于商业目的。</p><p id="509c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本文的主要目标是展示如何作为编码练习收集数据，以及如何为研究和/或个人项目构建数据集。</p><p id="f8c7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这个简短的免责声明之后，我们可以开始了吗？</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="fa7e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">先从工具说起。</p><h2 id="bc83" class="lz ma iq bd mb mc md dn me mf mg dp mh lf mi mj mk lj ml mm mn ln mo mp mq mr bi translated">蟒蛇</h2><p id="41aa" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">Anaconda是一个框架，它使用虚拟环境的概念，以透明的方式帮助维护每个项目的Python库依赖关系:您创建一个环境，在其中安装每个库，并根据您的需要激活/停用该环境，而不会干扰其他项目的依赖关系。你可以在这里下载<a class="ae kv" href="https://www.anaconda.com/distribution/" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="7ee6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个工具不是强制性的，它可以由任何虚拟环境库(例如:virtualenv)代替，但如果您想在这里介绍的管道末端添加进一步的步骤，如数据清理、数据分析和机器学习，它可能是有用的。此外，您也可以通过pip安装所描述的库。</p><p id="7424" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">无论如何，要创建我们的抓取环境，请运行以下代码:</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="061e" class="lz ma iq my b gy nc nd l ne nf">conda create --name scraping python=3.6<br/>conda activate scraping </span></pre><h2 id="e25e" class="lz ma iq bd mb mc md dn me mf mg dp mh lf mi mj mk lj ml mm mn ln mo mp mq mr bi translated">硒</h2><p id="c0a8" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">Selenium是一个为web应用程序自动测试而构建的框架:它的API允许我们模拟点击、滚动和网站上发生的任何其他交互。因此，它对于抓取网站也非常有用:点击和滚动会触发页面的变化，从而加载更多的数据(或其他类型的数据)。</p><p id="afba" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该库是用Java、Python、C#、JavaScript和许多其他语言编写的:在本文中，我们将使用Python实现来加载目标web页面，并生成检索附加信息所需的所有交互。</p><p id="9d5e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要安装Selenium，请运行命令:</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="159d" class="lz ma iq my b gy nc nd l ne nf">conda install -c conda-forge selenium</span></pre><p id="b0d8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们还需要安装我们想要使用的浏览器的web驱动程序。webdriver是自动运行浏览器实例的软件，Selenium将在其上工作。</p><p id="f3c6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我决定使用<strong class="ky ir">的谷歌Chromedriver </strong>，你可以从<a class="ae kv" href="https://chromedriver.chromium.org" rel="noopener ugc nofollow" target="_blank">这里</a>下载，但是任何驱动都可以正常工作。</p><p id="fe29" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">注意:</strong>我们将在后面看到的手动测试必须使用我们在这一步选择的浏览器来运行。</p><h2 id="2099" class="lz ma iq bd mb mc md dn me mf mg dp mh lf mi mj mk lj ml mm mn ln mo mp mq mr bi translated">美丽的声音</h2><p id="691c" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated"><a class="ae kv" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank"> BeautifulSoup </a>是一个解析HTML和XML文件的原生Python库:它帮助导航树的节点，以非常直观的方式访问属性和特性。</p><p id="ee33" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对我们来说，主要用途是解析经过Selenium处理的HTML页面，将信息提取为原始文本，并将其发送给进一步的处理。</p><p id="29da" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要在我们的conda环境中安装库，运行命令:</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="7d38" class="lz ma iq my b gy nc nd l ne nf">conda install -c anaconda beautifulsoup4</span></pre></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="3641" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">好了，现在我们应该准备好开始定义我们的抓取模块了！</p><p id="6987" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">目标示例将显示如何收集<strong class="ky ir">最新的</strong> <strong class="ky ir"> Google Maps评论</strong>:我们将定义一个导航到特定兴趣点(从现在开始是POI)并检索其相关最新评论的scraper。</p><h2 id="5097" class="lz ma iq bd mb mc md dn me mf mg dp mh lf mi mj mk lj ml mm mn ln mo mp mq mr bi translated"><em class="nh"> 1。初始化</em></h2><p id="a355" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">作为第一步，我们需要初始化我们的网络驱动。该驱动程序可以配置多个选项，但目前我们仅将英语设置为浏览器语言:</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="13c3" class="lz ma iq my b gy nc nd l ne nf">options = Options()<br/>options.add_argument("--lang=en")<br/>driver = webdriver.Chrome(chrome_options=options)</span></pre><h2 id="c0ab" class="lz ma iq bd mb mc md dn me mf mg dp mh lf mi mj mk lj ml mm mn ln mo mp mq mr bi translated">2.URL输入</h2><p id="e4fc" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">然后，我们需要提供我们的目标页面:当我们想要抓取Google Maps评论时，我们选择一个POI并获得直接指向评论的url。在这一步中，驱动程序只需打开页面。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/18fd6950b7c764229854ab59e10a7bca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IPsbCyblh7fHzptmuHjnuw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">总经理评估的目标页面示例</p></figure><p id="e7d7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这种类型的URL相当复杂:我们需要手动将其从浏览器复制到一个变量中，并将其传递给驱动程序。</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="76d7" class="lz ma iq my b gy nc nd l ne nf">url = <a class="ae kv" href="https://www.google.it/maps/place/Pantheon/@41.8986108,12.4746842,17z/data=!3m1!4b1!4m7!3m6!1s0x132f604f678640a9:0xcad165fa2036ce2c!8m2!3d41.8986108!4d12.4768729!9m1!1b1" rel="noopener ugc nofollow" target="_blank">https://www.google.it/maps/place/Pantheon/@41.8986108,12.4746842,17z/data=!3m1!4b1!4m7!3m6!1s0x132f604f678640a9:0xcad165fa2036ce2c!8m2!3d41.8986108!4d12.4768729!9m1!1b1</a></span><span id="23a2" class="lz ma iq my b gy nj nd l ne nf">driver.get(url)</span></pre><h2 id="5210" class="lz ma iq bd mb mc md dn me mf mg dp mh lf mi mj mk lj ml mm mn ln mo mp mq mr bi translated">3.单击菜单按钮</h2><p id="854b" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">现在，我们要提取<em class="ng">的</em> <em class="ng">最新的</em>评论，而页面默认设置呈现<em class="ng">最相关的</em>评论。我们需要点击“排序”菜单，然后点击“最新”标签。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/e4bd661a2e92c421796d1f7c30804e30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hu628BeX0sS_xN34AmqqDg.png"/></div></div></figure><p id="6b88" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这就是Selenium(和编码技能)真正发挥作用的地方:我们需要找到按钮，单击它，然后单击第二个按钮。为此，我使用了Selenium提供的XPath搜索方法:这比CSS搜索更容易，这也要感谢<a class="ae kv" href="https://autonomiq.io/chropath/" rel="noopener ugc nofollow" target="_blank"> Chropath </a>，这是一个浏览器扩展，它将XPath解释器添加到浏览器开发工具中。</p><p id="5646" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这样，我们<em class="ng">检查</em>页面以测试表达式，直到我们突出显示所需的元素:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/ca6b8b962f33d257c9cb515255b73c89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rBl1O_HOFzPdKKTQIF4VOg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">第一个按钮的XPath表达式测试</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/f642a706b9034a5d9b8402ccee13c335.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hINHgrOEoxNOoGrLdsNtvA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">第二个按钮的XPath表达式测试</p></figure><p id="421d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">不幸的是，这还不够。Google Maps网站(和许多其他现代网站一样)主要是使用AJAX实现的:网站的许多部分是异步加载的<strong class="ky ir"/>，这意味着如果Selenium在加载页面后立即查找按钮，它们可能不会被加载。</p><p id="4df1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是在那种情况下我们也有解决办法。Selenium实现了<em class="ng">等待功能</em>:在某些条件被验证之后或者在最大超时时间过去之后执行点击。等到元素在页面上出现并可点击，就解决了前面的问题。</p><p id="01c1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该部分的代码是:</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="bf7b" class="lz ma iq my b gy nc nd l ne nf">wait = WebDriverWait(driver, 10)<br/>menu_bt = wait.until(EC.element_to_be_clickable(<br/>                       (By.XPATH, '//button[<a class="ae kv" href="http://twitter.com/data" rel="noopener ugc nofollow" target="_blank">@data</a>-value=\'Sort\']'))<br/>                   )  <br/>menu_bt.click()<br/>recent_rating_bt = driver.find_elements_by_xpath(<br/>                                     '//div[<a class="ae kv" href="http://twitter.com/role" rel="noopener ugc nofollow" target="_blank">@role</a>=\'menuitem\']')[1]<br/>recent_rating_bt.click()<br/>time.sleep(5)</span></pre><p id="19b2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Sleep函数被添加到这个块的末尾，因为点击触发了一个AJAX调用来重新加载评论，因此我们需要在进入下一步之前等待…</p><h2 id="f05b" class="lz ma iq bd mb mc md dn me mf mg dp mh lf mi mj mk lj ml mm mn ln mo mp mq mr bi translated">4.审查数据提取</h2><p id="5b1f" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">现在，我们终于达到了目标，<strong class="ky ir">评论数据</strong>。我们将页面发送到BeautifulSoup解析器，它帮助找到正确的HTML标签、div和属性。</p><p id="7539" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，我们确定了review的包装器div:find _ all方法创建了一个div元素列表，这些元素具有特定的属性。在我们的例子中，列表包含页面上的评论的div。</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="4168" class="lz ma iq my b gy nc nd l ne nf">response = BeautifulSoup(driver.page_source, 'html.parser')<br/>rlist = response.find_all('div', class_='section-review-content')</span></pre><p id="029c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于每个评论，我们解析它的信息:评级星、文本内容(如果有的话)、评论日期、评论者姓名、评论id。</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="c94a" class="lz ma iq my b gy nc nd l ne nf">id_r = r.find('button', <br/>              class_='section-review-action-menu')['data-review-id']<br/>username = r.find('div', <br/>                  class_='section-review-title').find('span').text</span><span id="1363" class="lz ma iq my b gy nj nd l ne nf">try:<br/>    review_text = r.find('span', class_='section-review-text').text<br/>except Exception:<br/>    review_text = None</span><span id="f55b" class="lz ma iq my b gy nj nd l ne nf">rating = r.find('span', class_='section-review-stars')['aria-label']<br/>rel_date = r.find('span', class_='section-review-publish-date').text</span></pre><h2 id="12fd" class="lz ma iq bd mb mc md dn me mf mg dp mh lf mi mj mk lj ml mm mn ln mo mp mq mr bi translated">5.卷动</h2><p id="77ad" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">最后但同样重要的是:该页面已经加载了20篇评论，但是如果不向下滚动页面，其他评论就不可用。</p><p id="42b7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Selenium API中没有直接实现滚动，但是它们允许执行JavaScript代码并将其应用于页面的特定元素:我们标识可以滚动的div对象，并运行简单的JS代码行来滚动到页面底部。</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="91ee" class="lz ma iq my b gy nc nd l ne nf">scrollable_div = driver.find_element_by_css_selector(<br/> 'div.section-layout.section-scrollbox.scrollable-y.scrollable-show'<br/>                     )<br/>driver.execute_script(<br/>               'arguments[0].scrollTop = arguments[0].scrollHeight', <br/>                scrollable_div<br/>               )</span></pre></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="f9ea" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如你所看到的，在这个简短的教程中，我试图解释从谷歌地图上抓取评论的核心要素，但同样的概念也适用于许多现代网站。复杂性很高，我在这里没有考虑所有的细节:如果你想有一个完整的例子，检查我在Github <a class="ae kv" href="https://github.com/gaspa93/googlemaps-scraper" rel="noopener ugc nofollow" target="_blank">这里</a>的知识库。</p><p id="46ca" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">感谢您的阅读。让我知道你对它的想法，如果你有任何问题！</p></div></div>    
</body>
</html>