<html>
<head>
<title>GAVRO — Managed Big Data Schema Evolution</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">GAVRO —托管大数据模式演进</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/gavro-managed-big-data-schema-evolution-8217431f278f?source=collection_archive---------39-----------------------#2020-05-11">https://towardsdatascience.com/gavro-managed-big-data-schema-evolution-8217431f278f?source=collection_archive---------39-----------------------#2020-05-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1ab5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">构建一个适应变化的数据接收架构不是很好吗？更具体地说，对模式演变具有弹性。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9948c30f801d213eab107ece49b7171a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0UuaIMUUNXTQjDcBR2WuZQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源<a class="ae ky" href="http://Pixabay.com" rel="noopener ugc nofollow" target="_blank">Pixabay.com</a></p></figure><p id="6571" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于架构师和软件工程师来说，管理模式变更总是很麻烦。构建大数据平台没有什么不同，管理模式演变仍然是一个需要解决的挑战。NoSQL、Hadoop和读取模式的咒语在一定程度上缓解了严格的模式执行的束缚。然而，集成开发人员、分析师和数据科学家在从大数据中提取准确见解时，仍然会受到大量数据争论的阻碍。</p><p id="b944" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">“成功的业务”以加速和放大已知数据模式的易变的步伐成长和发展。数据集不是静态的，而且是不断发展的，因此了解业务事实数据在业务的当前和历史时期代表了什么对于做出自信的信息洞察至关重要。</p><p id="31e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过这篇文章和附带的GitHub <a class="ae ky" href="https://github.com/GaryStrange/GAVRO" rel="noopener ugc nofollow" target="_blank"> repo </a>，我将展示如何使用微软Azure技术在大数据平台中管理模式演进。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><blockquote class="mc"><p id="999b" class="md me it bd mf mg mh mi mj mk ml lu dk translated">这是一个在实践中容易被忽略的领域，直到您遇到第一个生产问题。如果没有仔细考虑数据管理和模式演化，人们通常会在以后付出更高的代价。</p></blockquote><blockquote class="mm mn mo"><p id="5569" class="kz la mp lb b lc mq ju le lf mr jx lh ms mt lk ll mu mv lo lp mw mx ls lt lu im bi translated">confluent . io(2020年4月29日)，模式演变和兼容性。<a class="ae ky" href="https://docs.confluent.io/current/schema-registry/avro.html#schema-evolution-and-compatibility" rel="noopener ugc nofollow" target="_blank">https://docs . confluent . io/current/schema-registry/avro . html # schema-evolution-and-compatibility</a></p></blockquote></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="a8b4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作为一名作家，很难决定如何讲述你的故事。我是直接进入技术解决方案，以满足寻找简洁例子的工程师，还是从为什么和动机开始？所以我就交给读者了。如果您想直接进入技术示例，请访问<a class="ae ky" href="https://github.com/GaryStrange/GAVRO/blob/master/README.md" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>。如果你想知道更详细的情况，请继续阅读…</p><h1 id="8d8c" class="my mz it bd na nb nc nd ne nf ng nh ni jz nj ka nk kc nl kd nm kf nn kg no np bi translated">模式管理</h1><p id="17bd" class="pw-post-body-paragraph kz la it lb b lc nq ju le lf nr jx lh li ns lk ll lm nt lo lp lq nu ls lt lu im bi translated">如果消费者理解用于写入数据的模式并且该模式从不改变，那么序列化要存储在文件中以供以后分析的数据是相当简单的。</p><p id="5214" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是，如果模式随着时间的推移而演变，会发生什么呢？它变得有点复杂。</p><p id="d663" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当写模式由于新的业务需求而发展时，消费者(读者)必须理解新模式是何时引入的，以及新模式的定义，以便成功地反序列化数据。未能理解模式更改事件将影响数据处理管道，服务将出错，因为它们无法反序列化数据。</p><p id="696f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个问题有几种解决方案……(这绝不是一个详尽的列表)。</p><p id="006a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">发布协调</strong></p><p id="dfc9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作者和读者协调他们的积压工作和软件发布。当编写器和读取器应用程序由同一个工程团队开发和维护时，这可能会工作得很好。然而，通常情况下，作者和读者在整个企业中致力于不同的目标和优先级。应该避免通过严格的接口依赖来临时耦合独立的团队积压工作，因为这会抑制敏捷性和交付速度。</p><p id="7cf1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">模式版本管理</strong></p><p id="6c00" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">版本化写模式支持向前和向后兼容性管理。提供向前和向后的兼容性可以消除积压和优先级，允许工程团队独立地实现他们的目标。</p><p id="913d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">版本控制通常在两个不同的子主题的上下文中讨论。</p><p id="6f4c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">主要—主要版本变更通常会破坏系统之间的接口和契约。主要的模式更改通常会阻止读者读取新模式版本写入的数据。向前和向后兼容很困难或不可能。</p><p id="8d83" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">次要—次要版本变更通常被视为低影响变更。向前和向后兼容通常是可能的。读取器通常会像以前一样继续操作，成功地对数据进行解序列化，而不会升级到模式的最新版本。</p><p id="de90" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">构建一个能够适应变化的数据接收架构不是很好吗？更具体地说，是对模式演变的弹性。</p><p id="ef31" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是我将用来描述如何成功管理模式进化的Azure架构。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/8afc803c71006fa460648756d9ad9fef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qYae130ca741J2CRBVvIkw.png"/></div></div></figure><h1 id="b756" class="my mz it bd na nb nc nd ne nf ng nh ni jz nj ka nk kc nl kd nm kf nn kg no np bi translated">模式注册表</h1><p id="6f8e" class="pw-post-body-paragraph kz la it lb b lc nq ju le lf nr jx lh li ns lk ll lm nt lo lp lq nu ls lt lu im bi translated">Kafka的Schema Registry提供了一个在流架构上管理模式演化的很好的例子。Azure Event Hubs是微软的Kafka类产品，目前没有模式注册功能。发布到事件中心的事件被序列化为嵌套在事件中心Avro模式体中的二进制blob(图1)。我们将很快讨论细节，但本质上发布的事件数据是无模式的，任何下游读取器都需要通过在读取时断言模式来对二进制blob进行反序列化。有一些巧妙的变通方法，利用了Confluent的模式注册表和事件中心。我将在这些建议的基础上，提供一种模式进化弹性的替代方法。在我之前的故事(<a class="ae ky" href="https://medium.com/@gary.strange/evolving-into-a-big-data-driven-business-in-the-azure-cloud-data-ingestion-65bc8b659570?source=your_stories_page---------------------------" rel="noopener">发展成为Azure Cloud中的大数据驱动业务:数据摄取</a>)中，我描述了一个数据湖摄取架构，该架构利用事件中心和事件中心捕获来形成大数据分析的批处理层。我将使用这个架构作为处理模式演变的参考。</p><blockquote class="mm mn mo"><p id="d7fc" class="kz la mp lb b lc ld ju le lf lg jx lh ms lj lk ll mu ln lo lp mw lr ls lt lu im bi translated">图一。</p></blockquote><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="a6b3" class="ob mz it nx b gy oc od l oe of">{</span><span id="5e77" class="ob mz it nx b gy og od l oe of">"type":"record",<br/>    "name":"EventData",<br/>    "namespace":"Microsoft.ServiceBus.Messaging",<br/>    "fields":[<br/>                 {"name":"SequenceNumber","type":"long"},<br/>                 {"name":"Offset","type":"string"},<br/>                 {"name":"EnqueuedTimeUtc","type":"string"},<br/>                 {"name":"SystemProperties","type":{"type":"map","values":["long","double","string","bytes"]}},<br/>                 {"name":"Properties","type":{"type":"map","values":["long","double","string","bytes"]}},<br/>                 {"name":"<strong class="nx iu">Body</strong>","type":["null","bytes"]}<br/>             ]<br/>}</span></pre><p id="1503" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">活动中心</strong></p><p id="006e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">多少？我应该有几个活动中心？或者换句话说，我应该为我的所有数据使用一个大管道，还是为每种消息类型使用许多小管道？关于卡夫卡的话题，也有人问过同样的问题，但没有明确的答案。有一件事很有可能，不同的用例会偏好不同的方法。如果您关心的只是从A到B获取消息，或者您正在与您控制之外的架构集成，那么消息可能会通过一个事件中心，一个大管道流动。如果您的一些数据高度敏感，并且您只希望某些订户读取和处理这些数据，或者您可能需要特定的分区策略，这将导致在一个名称空间中采用许多事件中心、许多更小的管道。</p><p id="11ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">大烟斗</p><ul class=""><li id="88a2" class="oh oi it lb b lc ld lf lg li oj lm ok lq ol lu om on oo op bi translated">如果一个事件中心包含许多具有不同模式的消息类型，我们如何正确地识别和反序列化各种消息？</li></ul><p id="5cc1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">小管</p><ul class=""><li id="8c25" class="oh oi it lb b lc ld lf lg li oj lm ok lq ol lu om on oo op bi translated">当一个事件中心只包含一种消息类型，并且这种消息类型会随着时间的推移而演变时，消费者如何反序列化新版本的消息呢？</li></ul><p id="5546" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">乍一看，这些问题似乎毫无关联。然而，它们是同一个核心问题的表现。如何管理数据的去序列化？</p><p id="1575" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">事件中心上的所有消息都是二进制的匿名blobs。一种选择是让消费者推断模式。然而，这种方法是不确定的，并且是基于抽样的，所以推断出的模式只能是一种近似。另一种方法可能是断言消费模式。然而，这意味着使用消息的工程团队暂时与模式的发展相结合，即使是很小的变化。事件中心捕捉为我们提供了一个打破时间耦合的机会，让消费者能够以自己的节奏消费从t0**开始的数据。但是，如果使用者想要读取和使用由事件中心捕获流程生成的所有AVRO文件，他们还需要知道在捕获事件期间使用了哪些写模式来写入二进制消息。这可能是几个月甚至几年的数据。作为消费者，我需要知道模式演变的时间线，否则我将很难利用这些数据。</p><p id="0553" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mp"> **井至少从乞讨事件中枢捕获配置。</em></p><p id="8053" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">活动中心捕捉的早期印象可能会让您认为AVRO被用来帮助解决上述问题。然而，在阅读了<a class="ae ky" href="https://avro.apache.org/docs/current/spec.html" rel="noopener ugc nofollow" target="_blank"> AVRO规范</a>之后，似乎只有微小的版本变化是可能的。因此，无法管理重大变更，也不可能有多种消息类型的AVRO文件。</p><p id="8a6d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">事件中心允许我们在发布消息时添加额外的元数据。这些元数据是管理模式演变的关键。</p><p id="d2ea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有两种可能的选择。</p><p id="3a6e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">1)写模式与每个消息一起存储在事件中心客户端属性字典中。这将严重抬高存储成本。</p><p id="6f14" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2)消息类型标识符存储在事件中心客户端属性字典中。然后，该标识符用于从中央存储中查找模式。</p><p id="0484" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于这两种解决方案，模式总是直接或间接地与数据存储在一起。Event Hub Capture生成的文件总是有一种识别写模式的方法。此外，每个文件可以包含x个消息类型和y个消息版本。</p><p id="e36c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们来看一个使用客户端SDK将消息发布到Event Hub的Azure函数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oq or l"/></div></figure><p id="d76f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">模式标识符总是存储在数据旁边(第17行)。</p><h1 id="d4c1" class="my mz it bd na nb nc nd ne nf ng nh ni jz nj ka nk kc nl kd nm kf nn kg no np bi translated">Azure函数</h1><p id="ab98" class="pw-post-body-paragraph kz la it lb b lc nq ju le lf nr jx lh li ns lk ll lm nt lo lp lq nu ls lt lu im bi translated">在上面的例子中，函数使用一个定时器触发器每5秒执行一次函数的新实例。函数触发器是不相关的，它可以很容易地成为一个CosmosDB变更提要处理绑定或任何其他生成待处理数据的绑定。而且，用功能app也无关紧要，重要的是你发布到事件中枢的内容。函数app本身就是一个简洁的例子。</p><p id="22bc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">需要注意的是，通过添加对eventData.Properties的引用，消息的模式版本与消息一起被持久化。当事件发布到事件中心时，模式标识符总是与数据一起存储。</p><h2 id="c99b" class="ob mz it bd na os ot dn ne ou ov dp ni li ow ox nk lm oy oz nm lq pa pb no pc bi translated">事件中心捕获</h2><p id="47c2" class="pw-post-body-paragraph kz la it lb b lc nq ju le lf nr jx lh li ns lk ll lm nt lo lp lq nu ls lt lu im bi translated">我将事件中心捕获配置为每分钟或每500mb生成一个新的AVRO文件，以先到者为准。因此，我们现在有了模式标识符和在整齐分区的AVRO文件中捕获的数据，但是我们如何在大数据管道中处理它呢？在我之前的故事中，我讨论了维护模式存储库的主题，以获取所有企业模式的真实描述。这种回购是用来创造一个人工制品，将在数据处理管道消费。这个产品是一个简单的键值存储，将版本化的模式标识符与所使用的写模式连接起来。出于本文的目的，我将使用一个简单的Databrick Python笔记本来处理AVRO数据。</p><h1 id="122e" class="my mz it bd na nb nc nd ne nf ng nh ni jz nj ka nk kc nl kd nm kf nn kg no np bi translated">数据块—笔记本</h1><p id="ddc4" class="pw-post-body-paragraph kz la it lb b lc nq ju le lf nr jx lh li ns lk ll lm nt lo lp lq nu ls lt lu im bi translated">我不会对完整的笔记本进行详细描述，而是关注最重要的单元(完整的笔记本在GitHub repo中)。</p><h2 id="e797" class="ob mz it bd na os ot dn ne ou ov dp ni li ow ox nk lm oy oz nm lq pa pb no pc bi translated">AVRO非军事化</h2><p id="0659" class="pw-post-body-paragraph kz la it lb b lc nq ju le lf nr jx lh li ns lk ll lm nt lo lp lq nu ls lt lu im bi translated">首先是读取事件中心数据捕获AVRO。Spark的AVRO dataframeReader用于从存储器中读取AVRO文件，并将它们解编为数据帧。我们可以让Spark在这一点上推断模式，因为我们知道它是非易失的(即Azure Event Hub模式)。properties属性保存用于将数据写入二进制字段“Body”的模式版本信息。对数据进行简单的投影，以处理具有三列的精确数据帧。模式版本是从properties对象中提取的(序列化属性字典中的存储值存储在子属性member2中)。“Body”属性被转换成一个字符串，因为我们想在后面的笔记本中对它使用spark的JSON反序列化器。</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="0081" class="ob mz it nx b gy oc od l oe of"><strong class="nx iu">from</strong> pyspark.sql.functions <strong class="nx iu">import</strong> col</span><span id="6f34" class="ob mz it nx b gy og od l oe of">rawAvroDf = spark.read.format("avro").load("wasbs://" + containerName + "@" + storageAccName + ".blob.core.windows.net/gavroehnamespace/gavroeh/*/2020/*/*/*/*/*.avro")</span><span id="5a9a" class="ob mz it nx b gy og od l oe of">avroDf = rawAvroDf.select(col("Properties.SchemaVersion.member2").alias('SchemaVersion'), col("Body").cast("string"))</span><span id="5b97" class="ob mz it nx b gy og od l oe of">display(avroDf)</span></pre><h2 id="856b" class="ob mz it bd na os ot dn ne ou ov dp ni li ow ox nk lm oy oz nm lq pa pb no pc bi translated">模式查找</h2><p id="aa60" class="pw-post-body-paragraph kz la it lb b lc nq ju le lf nr jx lh li ns lk ll lm nt lo lp lq nu ls lt lu im bi translated">第二个是模式查找对象。出于简化示例的目的，我将手动创建一些模式，用于反序列化AVRO数据。然而，在实践中，这些模式将从模式存储库中生成，并作为运行时工件存储。自我提醒，需要将此作为后续文章来写。</p><p id="37f1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">存储在一维数组中的模式代表一个已经进化的实体。在这个理论上的例子中，企业已经成长并开始以新的货币进行海外交易。交易现在需要货币标识符，因此在销售订单数据模式中添加了一个新的属性“currency”。作为读者，我们需要能够成功地对新数据进行反序列化。</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="79f3" class="ob mz it nx b gy oc od l oe of"><strong class="nx iu">from</strong> pyspark.sql.types <strong class="nx iu">import</strong> StructType, StructField, LongType, StringType, ArrayType, DoubleType</span><span id="e13a" class="ob mz it nx b gy og od l oe of">salesOrderV1 =StructType([StructField('OrderId',StringType(),<strong class="nx iu">True</strong>),StructField('OrderAmount',DoubleType(),<strong class="nx iu">True</strong>),StructField('OrderCreatedUTC',StringType(),<strong class="nx iu">True</strong>)])</span><span id="2208" class="ob mz it nx b gy og od l oe of">salesOrderV2 =StructType([StructField('OrderId',StringType(),<strong class="nx iu">True</strong>),StructField('OrderAmount',DoubleType(),<strong class="nx iu">True</strong>),StructField('Currency',StringType(),<strong class="nx iu">False</strong>),StructField('OrderCreatedUTC',StringType(),<strong class="nx iu">True</strong>)])</span><span id="ece5" class="ob mz it nx b gy og od l oe of">salesOrderSchemaDictionary = { "v1.0":salesOrderV1, "v2.0":salesOrderV2 }</span><span id="09f5" class="ob mz it nx b gy og od l oe of">salesOrderSchemaDictionary</span></pre><h2 id="cdde" class="ob mz it bd na os ot dn ne ou ov dp ni li ow ox nk lm oy oz nm lq pa pb no pc bi translated">JSON去军事化</h2><p id="d4c3" class="pw-post-body-paragraph kz la it lb b lc nq ju le lf nr jx lh li ns lk ll lm nt lo lp lq nu ls lt lu im bi translated">我想关注的第三个单元是实际读取数据并对数据进行反序列化的单元。先前读入数据帧的事件中枢数据捕获输出用于确定数据中存在的模式版本的不同列表。对于每个模式版本，将创建一个新的临时SparkSQL表来访问反序列化的数据。原始AVRO数据帧在“for”循环的每次迭代中被过滤，通过不同的模式版本对记录进行分组以产生数据子集。然后，使用salesOrderSchemaDictionary中的相应模式对每个子集进行反序列化。将创建许多新的临时表，该单元的输出将显示已创建对象的列表。</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="89e7" class="ob mz it nx b gy oc od l oe of"><strong class="nx iu">from</strong> pyspark.sql.functions <strong class="nx iu">import</strong> concat, lit, regexp_replace</span><span id="259d" class="ob mz it nx b gy og od l oe of">distinctSchemaVersions = avroDf.select('SchemaVersion').distinct()</span><span id="52c1" class="ob mz it nx b gy og od l oe of">objectToCreate = distinctSchemaVersions.withColumn('TableName', concat(lit('SalesOrder'),regexp_replace(col('SchemaVersion'), '[.]', '_'))).collect()</span><span id="0f28" class="ob mz it nx b gy og od l oe of">display(objectToCreate)</span><span id="8725" class="ob mz it nx b gy og od l oe of"><strong class="nx iu">for</strong> record <strong class="nx iu">in</strong> objectToCreate:</span><span id="032b" class="ob mz it nx b gy og od l oe of">schemaVersion = record.SchemaVersion</span><span id="d283" class="ob mz it nx b gy og od l oe of">jsonRdd = avroDf.filter(col("SchemaVersion") == schemaVersion).select(avroDf.Body)</span><span id="04fa" class="ob mz it nx b gy og od l oe of">objectJson = jsonRdd.rdd.map(<strong class="nx iu">lambda</strong> x: x[0])</span><span id="614c" class="ob mz it nx b gy og od l oe of">dataExtract = spark.read.schema(salesOrderSchemaDictionary[schemaVersion]).json(objectJson)</span><span id="046c" class="ob mz it nx b gy og od l oe of">dataExtract.registerTempTable(record.TableName)</span></pre><h2 id="683b" class="ob mz it bd na os ot dn ne ou ov dp ni li ow ox nk lm oy oz nm lq pa pb no pc bi translated">最后</h2><p id="2ada" class="pw-post-body-paragraph kz la it lb b lc nq ju le lf nr jx lh li ns lk ll lm nt lo lp lq nu ls lt lu im bi translated">最后，SparkSQL可用于探索临时表中成功的去序列化数据。</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="3a31" class="ob mz it nx b gy oc od l oe of">%sql<br/><strong class="nx iu">select</strong> * <strong class="nx iu">from</strong> SalesOrderv1_0</span><span id="f431" class="ob mz it nx b gy og od l oe of">%sql<br/><strong class="nx iu">select</strong> * <strong class="nx iu">from</strong> SalesOrderv2_0</span></pre><h1 id="efb5" class="my mz it bd na nb nc nd ne nf ng nh ni jz nj ka nk kc nl kd nm kf nn kg no np bi translated">结论</h1><p id="d0a2" class="pw-post-body-paragraph kz la it lb b lc nq ju le lf nr jx lh li ns lk ll lm nt lo lp lq nu ls lt lu im bi translated">我应该先弄清楚伽弗洛是什么。抱歉让你失望了，但这不是你不知道的新Apache孵化器项目。我的同事给我在本文中描述的方法起了一个可爱的名字。我相信这是我的首字母和AVRO的组合，起初我发现他们对这种方法的昵称是团队友谊的产物，但后来它坚持下来了。</p><p id="173f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我不相信设计和规定方法是完全精确的，应该无条件地适用于每个企业，因为每个企业都是不同的。因此，如果你从阅读这篇文章中学到了什么，那么我希望它是思考你的大数据管道中糟糕管理的模式演变的内涵的动力。我们一次又一次地听到组织在从大数据中提取信息和可操作的洞察力方面遇到的困难，以及数据科学家浪费80%的时间在数据准备上是多么昂贵。如果应用得当，模式管理是一种武器，可以用来加速数据理解和减少洞察时间。所以花时间投资它，你会收获健康的回报。</p><h2 id="c063" class="ob mz it bd na os ot dn ne ou ov dp ni li ow ox nk lm oy oz nm lq pa pb no pc bi translated">引文</h2><p id="e0b5" class="pw-post-body-paragraph kz la it lb b lc nq ju le lf nr jx lh li ns lk ll lm nt lo lp lq nu ls lt lu im bi translated">[1]沃尔坎·西韦莱克，事件中心模式验证(2019年4月1日)，<a class="ae ky" href="https://azure.microsoft.com/en-gb/blog/schema-validation-with-event-hubs/" rel="noopener ugc nofollow" target="_blank">https://azure . Microsoft . com/en-GB/blog/Schema-validation-with-Event-Hubs/</a></p><p id="53e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[2]马丁·克莱普曼，是否应该把几个事件类型放在同一个卡夫卡主题里？(2018年1月18日)，<a class="ae ky" href="https://martin.kleppmann.com/2018/01/18/event-types-in-kafka-topic.html" rel="noopener ugc nofollow" target="_blank">https://Martin . kleppmann . com/2018/01/18/event-types-in-Kafka-topic . html</a></p><h2 id="1889" class="ob mz it bd na os ot dn ne ou ov dp ni li ow ox nk lm oy oz nm lq pa pb no pc bi translated">影响</h2><p id="1e10" class="pw-post-body-paragraph kz la it lb b lc nq ju le lf nr jx lh li ns lk ll lm nt lo lp lq nu ls lt lu im bi translated">雅虎的Apache Pulsar系统:<a class="ae ky" href="https://pulsar.apache.org/docs/en/schema-evolution-compatibility/" rel="noopener ugc nofollow" target="_blank">https://Pulsar . Apache . org/docs/en/schema-evolution-compatibility/</a></p><p id="9c4d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Confluent.io的Schema-Registry:<a class="ae ky" href="https://docs.confluent.io/current/schema-registry/index.html" rel="noopener ugc nofollow" target="_blank">https://docs . confluent . io/current/Schema-Registry/index . html</a></p><p id="ea0f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">杰伊·克雷普斯，《日志:每个软件工程师都应该知道的实时数据统一抽象》(2013年12月16日)，<a class="ae ky" href="https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying" rel="noopener ugc nofollow" target="_blank">https://engineering . LinkedIn . com/distributed-systems/Log-What-every-a-software-engineer-should-know-on-real-time-datas-unified</a></p></div></div>    
</body>
</html>