<html>
<head>
<title>Regression Basics: Code Walk-Through</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">回归基础:代码演练</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/regression-basics-code-walk-through-c2eac24da2e9?source=collection_archive---------42-----------------------#2020-08-03">https://towardsdatascience.com/regression-basics-code-walk-through-c2eac24da2e9?source=collection_archive---------42-----------------------#2020-08-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="69a4" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">通过预测汽车销售价格发现回归的基本原理</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/f718614d437fc6f7d2dabad9728d0ee9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xy9ddYccr9GPfDau"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@danielcgold?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">丹金</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="3d04" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本文通过使用一个<a class="ae kv" href="https://www.kaggle.com/nehalbirla/vehicle-dataset-from-cardekho" rel="noopener ugc nofollow" target="_blank"> Kaggle 二手车数据集</a>展示完整数据项目的代码和全面解释，引导您了解回归的基础知识。该项目利用线性回归、岭 CV、套索 CV 和弹性净 CV 模型来预测销售价格。Github 上有完整的代码<a class="ae kv" href="https://github.com/jewelbritton/Car-Price-Prediction" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="a3db" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">正在设置</h1><p id="617b" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">二手车数据集可从<a class="ae kv" href="https://www.kaggle.com/nehalbirla/vehicle-dataset-from-cardekho" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>下载，格式为 CSV 文件。信息由印度二手车网站 cardekho 提供。一旦您下载了 CSV 文件，您就可以利用 Pandas <em class="mp"> </em>库来查看和分析数据。</p><p id="a4dc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">引号内的文件路径会因保存文件的位置而异。在 Mac 上，你可以通过右击文件并按住 Option 键来找到文件路径。应该会出现一个“复制”file.csv“作为路径名”的选项，然后你可以将它粘贴在括号中，就像我下面这样。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="1952" class="mv lt iq mr b gy mw mx l my mz">import pandas as pd</span><span id="ea0f" class="mv lt iq mr b gy na mx l my mz"># upload data from csv</span><span id="fafb" class="mv lt iq mr b gy na mx l my mz">car = pd.read_csv('/Users/Jewel/Desktop/Car-Price-Prediction/car details.csv')</span></pre><p id="2e4a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在 CSV 被保存为熊猫数据帧。要查看我们正在处理的数据类型，我们可以使用下面的代码来查看我们刚刚创建的数据框的前 5 行。如果我们想要查看特定数量的行，我们可以在括号中输入一个数字来查看这些行(cars.head(10)将显示前 10 行)。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="eef9" class="mv lt iq mr b gy mw mx l my mz">car.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/4a711055f63beedb9f3f37489a697822.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*PQBSFNE8lBw2bQDi1zV3DA.png"/></div></figure><p id="8e84" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这使我们能够看到数据框包含的内容、列以及包含的二手车详细信息的一些示例。每一行都是一辆独一无二的汽车，每一列代表汽车的不同特征。在这个项目中，我们将使用这些特性来预测每辆车的“销售价格”。为此，我们将使用回归，但首先我们应该探索数据，并根据需要清理数据。</p><h1 id="317a" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">探索性数据分析和清理</h1><h2 id="1e37" class="mv lt iq bd lu nc nd dn ly ne nf dp mc lf ng nh me lj ni nj mg ln nk nl mi nm bi translated">1.检查缺少的值</h2><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="04c1" class="mv lt iq mr b gy mw mx l my mz">car.isnull().sum()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/6e210cd8443310e26f599a78fbda196b.png" data-original-src="https://miro.medium.com/v2/resize:fit:334/format:webp/1*H82SqV4FcIeZuDE-ZCQYIQ.png"/></div></figure><p id="a60e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">没有任何丢失的值！耶。如果存在缺失值，则很难对信息进行正确建模。通常数据集中有许多缺失值，为了对数据建模，我们要么删除缺失值的行，要么用另一个值(平均值、前一个值……)替换该实例。</p><h2 id="83dd" class="mv lt iq bd lu nc nd dn ly ne nf dp mc lf ng nh me lj ni nj mg ln nk nl mi nm bi translated">2.检查数据类型</h2><p id="7d23" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">探索数据的下一步是查看哪些类型的数据存储在列中。这有助于注意看起来被数字填充的列是否被错误地编码为“对象”。如果是这种情况，您可以轻松地更改数据类型，以便计算机正确理解您提供的信息。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="9195" class="mv lt iq mr b gy mw mx l my mz">car.dtypes</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/6b91fb0a4bd8d23c0c27c6e577518630.png" data-original-src="https://miro.medium.com/v2/resize:fit:402/format:webp/1*pcljjNEOff-dtZdFzuW3CQ.png"/></div></figure><p id="4ca8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> float </strong> =带小数的数字(1.678) <br/> <strong class="ky ir"> int </strong> =不带小数的整数或整数(1，2，3) <br/> <strong class="ky ir"> obj </strong> =对象、字符串或单词(' hello') <br/>这些数据类型后的<strong class="ky ir"> 64 </strong>是指该值占用多少位的存储空间。你会经常看到 32 或 64。</p><p id="67ca" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">根据我们到目前为止看到的数据框的前几行，数据类型看起来都是正确的。</p><h2 id="f749" class="mv lt iq bd lu nc nd dn ly ne nf dp mc lf ng nh me lj ni nj mg ln nk nl mi nm bi translated">4.数据概述</h2><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="2adc" class="mv lt iq mr b gy mw mx l my mz">car.describe()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/c252ae58c95af943ff452bae81376b3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:586/format:webp/1*L5Oz3mxs0rELYCAZPIomUQ.png"/></div></figure><p id="0f28" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此表为我们提供了有关数字数据列的统计信息的概述。因为只有三列是整数或浮点数，所以我们在图表上只看到这三列。如果数字数据被错误地编码为“对象”,我们将无法查看列上的统计信息。</p><p id="55cf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用此表，我们可以看到不同的值，如平均值、最小值、最大值和标准偏差。该表有助于快速概述列中的数据，并允许我们识别异常值。例如，当我第一次看到这张表时，我认为二手车 50 万美元的平均价格高得令人难以置信。但后来我看了看数据源，才知道数据是一家印度公司的，50 万卢比约合 6600 美元。合理多了！</p><p id="71f3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此表中另一个突出的地方是 km_driven 的最小值是 1 千米。对于一辆二手车来说，这个价格似乎很低，所以我想进一步调查这辆车。为此，我们可以按照行驶公里数从低到高对数据框进行排序。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="3eb4" class="mv lt iq mr b gy mw mx l my mz">car.sort_values(by = 'km_driven')</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/ca281a32b26c92178ac2521fac1139c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kA3ve-fT87Oc7pLRU-T1dA.png"/></div></div></figure><p id="5c82" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">顶部的那辆车行驶了 1 公里，由于这辆车至少有过两个主人，而且是 2014 年的，所以它只有 1 公里似乎不太现实。这可能是一个异常值，或者数据可能输入错误，所以为了安全起见，我将删除这一行。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="b0a9" class="mv lt iq mr b gy mw mx l my mz">car.drop([1312], inplace = True)<br/>#1312 is the index of the row (which can be seen all the way on the left of the first row</span></pre><h2 id="ee36" class="mv lt iq bd lu nc nd dn ly ne nf dp mc lf ng nh me lj ni nj mg ln nk nl mi nm bi translated">5.可视化相关性</h2><p id="0a1e" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">使用 Seaborn 库，我们还可以可视化不同特性之间的相关性。相关性将只记录具有数字数据的列，但是研究这些特征之间的关系仍然是有帮助的。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="48d4" class="mv lt iq mr b gy mw mx l my mz">import seaborn as sns</span><span id="9e81" class="mv lt iq mr b gy na mx l my mz">sns.heatmap(car.corr(), annot= True);</span><span id="8cb3" class="mv lt iq mr b gy na mx l my mz">#annot = True shows the correlation values in the squares</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/affe519d3197b3a369d952eee2ec32b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*-J0OnznDGgrtQ7G0fFjWQA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">接近 1 的正相关性告诉我们，这两个特征具有正线性关系(随着一个特征上升，另一个特征也上升)。负相关接近-1 表示两者具有负线性关系(一个增加，另一个减少)。</p></figure><p id="96cb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们从这个关联图中获得的信息直观上是有意义的，并且可能证实我们的一些信念——这总是令人高兴的。年份和售价是相对正相关的，所以随着年份的增加，售价也会增加。年份和行驶的公里数是负相关的，所以随着车越来越旧，行驶的公里数也会越来越多。</p><h1 id="628c" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">特征工程</h1><p id="f23f" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">既然我们已经仔细查看了数据及其周围的统计数据，我们就可以为建模准备数据了。</p><p id="350c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">数据框中的“名称”列非常具体，当我们在相对有限的数据集上建模时，有时更模糊一些会更好。这允许模型基于更多过去的样本进行预测。为了研究数据中汽车名称的多样性，我们可以使用下面的代码来计算每种汽车名称的数量。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="1331" class="mv lt iq mr b gy mw mx l my mz">car['name'].value_counts()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/c1cf77cfe123f637e469a8ea783198f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*slqGkseCK7Y15CVrBYKDNw.png"/></div></figure><p id="b874" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有超过 1400 个不同的汽车名称包括在内，许多例子不到 30 个。如果每辆车只有几个例子，我们的模型将很难预测销售价格。为了使这成为一个更普遍的特征，我们可以只包括汽车的品牌。幸运的是，品牌名称是每一行的第一个单词，所以我们可以创建一个只包含汽车品牌名称的新特性。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="83c7" class="mv lt iq mr b gy mw mx l my mz">#make an empty list to append new names to</span><span id="af96" class="mv lt iq mr b gy na mx l my mz">brand_name = []<br/>for x in car.name:<br/>    y = x.split(' ')<br/>    brand_name.append(y[0]) #append only the first word to the list</span><span id="5ca6" class="mv lt iq mr b gy na mx l my mz">#we can drop the previous column that had the full name<br/>car = car.drop(['name'], axis = 1)</span><span id="1b3b" class="mv lt iq mr b gy na mx l my mz">#and add the new column that just has the brand name<br/>car['brand_name'] = brand_name</span><span id="2c8d" class="mv lt iq mr b gy na mx l my mz">#now let's check how many of each brand is in the column<br/>car.brand_name.value_counts()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/55a16f83e44186f824376b1af2e77297.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*y8ksY2KVLa1mHsRQfkbvgQ.png"/></div></figure><p id="3ed9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因为这个专栏现在只有品牌名称，所以有少于 1400 个不同的值，许多有超过 30 种不同的汽车。此时，您仍然可以选择删除只有 1 或 2 辆汽车的汽车品牌行(Force、Isuzu、Kian、Daewoo…)，但我现在会保留这些。我们已经极大地限制了品种，所以我们的模型现在应该更强大。</p><h2 id="2084" class="mv lt iq bd lu nc nd dn ly ne nf dp mc lf ng nh me lj ni nj mg ln nk nl mi nm bi translated">将特征二值化</h2><p id="4788" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在我们可以对特性建模之前，最后一步是为非数字特性创建二进制列。计算机很难理解所有汽车名称之间的含义差异，因此二进制化只是告诉计算机“是的，这是一辆沃尔沃，”或“不，这不是一辆沃尔沃。”</p><p id="4b42" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">二进制化为每个汽车品牌创建一个特定的列，然后每行将有一个 0(不是那个汽车品牌)或 1(是那个汽车品牌)。为每个特性创建二进制列的过程也称为“虚拟化”变量，可以用 Pandas 中的代码轻松完成。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="3616" class="mv lt iq mr b gy mw mx l my mz">car_dummies = pd.get_dummies(car, drop_first = True)<br/>#set this equal to a new variable since it will be a different data set<br/>#dropping the first column just removes the redundancy of having all the columns there</span><span id="01fc" class="mv lt iq mr b gy na mx l my mz">car_dummies.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/4f9f1434607fafc74578fabd4630db5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V9Vnse6LauoDb7lMhn00Ng.png"/></div></div></figure><p id="b4c6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于虚拟/二进制列，数据框现在看起来像这样-填充了 0 和 1 的列，但三个数字列除外。尽管有更多的列，但是这个过程使得模型能够理解您提供给它的信息。</p><h1 id="71ed" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">建模</h1><p id="6e42" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">现在(终于)我们可以对我们的数据建模来预测这些二手车的销售价格。</p><h2 id="471e" class="mv lt iq bd lu nc nd dn ly ne nf dp mc lf ng nh me lj ni nj mg ln nk nl mi nm bi translated">分割目标和预测变量</h2><p id="518b" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">首先，我们需要定义 X 和 y 变量。y 是我们预测的价格(销售价格), X 是我们用来帮助我们做出预测的一切。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="2da5" class="mv lt iq mr b gy mw mx l my mz">X = car_dummies.copy()</span><span id="cb51" class="mv lt iq mr b gy na mx l my mz">y = X.pop('selling_price')<br/>#.pop() removes the column/list from X and saves it to the new variable</span></pre><h2 id="90f1" class="mv lt iq bd lu nc nd dn ly ne nf dp mc lf ng nh me lj ni nj mg ln nk nl mi nm bi translated">训练和测试分割</h2><p id="5417" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">接下来，我们需要为我们的模型创建一个训练和测试组。我们可以使用下面的代码随机选择 70%的数据作为我们模型的训练组，30%将作为我们测试模型质量的测试组。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="9d09" class="mv lt iq mr b gy mw mx l my mz">from sklearn.model_selection import train_test_split</span><span id="ff86" class="mv lt iq mr b gy na mx l my mz">X_train, X_test, y_train, y_test = train_test_split(<br/>    X, y, test_size=0.3, random_state=1)</span></pre><h2 id="5cee" class="mv lt iq bd lu nc nd dn ly ne nf dp mc lf ng nh me lj ni nj mg ln nk nl mi nm bi translated">标准化 X 值</h2><p id="e0b1" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">最后，我们将需要标准化所有的 X 值，使它们在一个一致的范围内。这不会改变数字之间的比例关系。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="fa87" class="mv lt iq mr b gy mw mx l my mz">from sklearn.preprocessing import StandardScaler</span><span id="94ab" class="mv lt iq mr b gy na mx l my mz">scaler = StandardScaler()<br/>X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)<br/>#you fit_transform on your train data only because you don't want your model to be influenced in any way by the test data. The test data acts as unseen, brand new data to test the quality of the model.</span><span id="4025" class="mv lt iq mr b gy na mx l my mz">X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)<br/>#you only transform the test data so you can conform it to the parameters set with the mean from the training data</span></pre><h2 id="fbab" class="mv lt iq bd lu nc nd dn ly ne nf dp mc lf ng nh me lj ni nj mg ln nk nl mi nm bi translated">线性回归</h2><p id="faf2" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我们将尝试的第一个模型是简单的线性回归。评估交叉验证分数、训练分数和测试分数以反映模型的表现是很重要的。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="dd26" class="mv lt iq mr b gy mw mx l my mz">from sklearn.linear_model import LinearRegression<br/>from sklearn.model_selection import cross_val_score</span><span id="de15" class="mv lt iq mr b gy na mx l my mz">#create a model instance<br/>lr_model = LinearRegression()</span><span id="2444" class="mv lt iq mr b gy na mx l my mz">#fit the model on the training data<br/>lr_model.fit(X_train, y_train)</span><span id="2803" class="mv lt iq mr b gy na mx l my mz"># get cross validated scores<br/>scores = cross_val_score(lr_model, X_train, y_train, cv=5)<br/>print("Cross-validated training scores:", scores)<br/>print("Mean cross-validated training score:", scores.mean())<br/><br/>#training score<br/>print("Training Score:", lr_model.score(X_train, y_train))<br/># evaluate the data on the test set<br/>print("Test Score:", lr_model.score(X_test, y_test))</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/723b8da11cf523140d4460b9c4b5429f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SQXihWqHmrQMzqjcy9Bh4A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">线性回归分数</p></figure><p id="e81a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于训练分数比测试分数好得多，这表明模型过度拟合了训练数据。这意味着该模型很难对看不见的数据进行预测——这可不好！此外，平均交叉验证分数是一个非常大的负数。理论上，我们希望这三个分数都尽可能接近 1.0，但是由于分数对于这个模型来说非常糟糕，我们可以尝试其他一些回归模型，这些模型也可以调整数据。</p><h2 id="c57d" class="mv lt iq bd lu nc nd dn ly ne nf dp mc lf ng nh me lj ni nj mg ln nk nl mi nm bi translated">山脊 CV</h2><p id="828a" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">岭回归是正则化变量的一种方法，在处理共线性时通常很有用。当存在大量特征，并且许多/所有特征以相似的强度影响目标变量时，岭通常是有用的。在处理任何回归问题时，最好尝试所有这些模型，看看哪种模型表现最好。使用 RidgeCV 模型，我们还可以设置一系列阿尔法值来尝试，模型会选择最好的。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="bc32" class="mv lt iq mr b gy mw mx l my mz">from sklearn.linear_model import RidgeCV<br/>import numpy as np</span><span id="1636" class="mv lt iq mr b gy na mx l my mz"># create a RidgeCV model instance<br/>ridge_model = RidgeCV(alphas=np.logspace(-10, 10, 30), cv=5)<br/># fit the model<br/>ridge_model.fit(X_train, y_train)</span><span id="0737" class="mv lt iq mr b gy na mx l my mz">#mean cv score on training data<br/>scores = cross_val_score(ridge_model, X_train, y_train, cv=5)</span><span id="ba2c" class="mv lt iq mr b gy na mx l my mz">print("Cross-validated training scores:", scores)<br/>print("Mean cross-validated training score:", scores.mean())<br/><br/>#training score<br/>print("Training Score:", ridge_model.score(X_train, y_train))<br/># evaluate the data on the test set<br/>print("Test Score:", ridge_model.score(X_test, y_test))</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/9082e27098344d28d0a4a641512be3f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GXJSdvpq-UGjDjM06gWVQQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">岭简历分数</p></figure><p id="5975" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在三个分数都大致相同，在几个小数以内。因为这些分数比线性回归分数好得多，所以我们可以假设正则化对建模有帮助。</p><h2 id="3f1d" class="mv lt iq bd lu nc nd dn ly ne nf dp mc lf ng nh me lj ni nj mg ln nk nl mi nm bi translated">拉索 CV</h2><p id="20c3" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">另一种方法，我们可以调整我们的特点是使用套索。当有许多要素对目标变量几乎没有影响时，这种正则化通常有助于减少共线性。Lasso 会将这些变为零，只保留对预测有重大影响的要素。同样，最好尝试所有模型，看看哪种模型最适合您的模型。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="5efd" class="mv lt iq mr b gy mw mx l my mz">from sklearn.linear_model import LassoCV</span><span id="dbcc" class="mv lt iq mr b gy na mx l my mz"># create a LassoCV model instance<br/>lasso_model = LassoCV(eps= [.0001, .001, .01, .1], alphas=np.logspace(-8, 8, 20), max_iter = 1000000, cv=5)<br/># fit the model<br/>lasso_model.fit(X_train, y_train)</span><span id="dcf9" class="mv lt iq mr b gy na mx l my mz"># evaluate on the training set<br/>training_score = lasso_model.score(X_train, y_train)<br/># evaluate on the test set<br/>test_score = lasso_model.score(X_test, y_test)</span><span id="321d" class="mv lt iq mr b gy na mx l my mz">#mean cv score on training data<br/>scores = cross_val_score(lasso_model, X_train, y_train, cv=5)</span><span id="48a4" class="mv lt iq mr b gy na mx l my mz">print("Cross-validated training scores:", scores)<br/>print("Mean cross-validated training score:", scores.mean())<br/><br/>#training score<br/>print("Training Score:", lasso_model.score(X_train, y_train))<br/># evaluate the data on the test set<br/>print("Test Score:", lasso_model.score(X_test, y_test))</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/a76f601e83538852ad82f4c3328c0f51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5cpTLKaUMkA6sX8kIxIkFA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">拉索 CV 评分</p></figure><p id="5a31" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Lasso 得分与 Ridge 非常相似，但平均 CV 得分略高。比较模型的一个好指标是平均 CV 或测试分数。</p><h2 id="f1fb" class="mv lt iq bd lu nc nd dn ly ne nf dp mc lf ng nh me lj ni nj mg ln nk nl mi nm bi translated">弹性网 CV</h2><p id="efcf" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我们将测试的最后一个模型是弹性网络 CV，它创建了套索和脊正则化的组合。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="f107" class="mv lt iq mr b gy mw mx l my mz">#Elastic net model with scores<br/>from sklearn.linear_model import ElasticNetCV</span><span id="0728" class="mv lt iq mr b gy na mx l my mz">enet_model = ElasticNetCV(alphas=np.logspace(-4, 4, 10), <br/>                     l1_ratio=np.array([.1, .5, .7, .9, .95, .99, 1]),<br/>                     max_iter = 100000,<br/>                     cv=5)<br/># fit the model<br/>enet_model.fit(X_train, y_train)</span><span id="2ea8" class="mv lt iq mr b gy na mx l my mz"># evaluate on the training set<br/>training_score = enet_model.score(X_train, y_train)<br/># evaluate on the test set<br/>test_score = enet_model.score(X_test, y_test)</span><span id="8d0e" class="mv lt iq mr b gy na mx l my mz">#mean cv score on training data<br/>scores = cross_val_score(enet_model, X_train, y_train, cv=5)</span><span id="26cb" class="mv lt iq mr b gy na mx l my mz">print("Cross-validated training scores:", scores)<br/>print("Mean cross-validated training score:", scores.mean())<br/>print()<br/>#training score<br/>print("Training Score:", enet_model.score(X_train, y_train))<br/># evaluate the data on the test set<br/>print("Test Score:", enet_model.score(X_test, y_test))</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/d4778c58546f4cf7a43d65fc5b2b6446.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_2hlIZzZxL01wLb5L-or5g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">弹性净简历分数</p></figure><p id="820b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所有三个正则化模型的得分相对相似，但在比较平均交叉验证得分时，Lasso CV 表现最好，相差很小(. 001)。让我们仔细看看套索模型以及它是如何做出预测的。</p><h1 id="2a98" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">寻找最好的模型</h1><h2 id="d011" class="mv lt iq bd lu nc nd dn ly ne nf dp mc lf ng nh me lj ni nj mg ln nk nl mi nm bi translated">特征重要性</h2><p id="360a" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">查看系数可以向我们显示哪些特征对模型如何进行预测影响最大(或最小)。下图显示了对汽车销售价格产生最大积极影响的特性。例如，成为宝马、奔驰或奥迪会导致销售价格上涨——就像成为一辆新车一样。通过将 ascending 更改为“False ”,我们还可以查看对价格有负面影响的特性。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="f248" class="mv lt iq mr b gy mw mx l my mz">fi = pd.DataFrame({<br/>    'feature': X_train.columns,<br/>    'importance': lasso_model.coef_<br/>})</span><span id="75fd" class="mv lt iq mr b gy na mx l my mz">fi.sort_values('importance', ascending=True, inplace=True)</span><span id="d68e" class="mv lt iq mr b gy na mx l my mz">#sns.set_style('ticks')<br/>sns.set(font_scale = 2)<br/>fig, ax = plt.subplots()<br/># the size of A4 paper<br/>fig.set_size_inches(16, 12)<br/>sns.barplot(x='importance', y='feature', data=fi[-15:], orient='h', palette = 'rocket', saturation=0.7)  <br/>ax.set_title("Feature Importance", fontsize=40, y=1.01)<br/>ax.set_xlabel('Importance', fontsize = 30)<br/>ax.set_ylabel('Feature', fontsize = 30)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/82e3d396e82aa17597b4d32074194bc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G56H01OgvLgCC0a5YFwPJw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">套索正特征重要性</p></figure><h2 id="ddf9" class="mv lt iq bd lu nc nd dn ly ne nf dp mc lf ng nh me lj ni nj mg ln nk nl mi nm bi translated">预测和残差</h2><p id="0185" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我们可以评估模型的另一种方式是通过将模型预测的值与实际值进行比较。这向我们展示了我们的模型在哪里出错，以及它的预测有多错误。我们可以在数据框中查看这些信息，也可以将这些信息转换成图表，对比实际值和预测值。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="990c" class="mv lt iq mr b gy mw mx l my mz">predictions = lasso_model.predict(X_test)<br/>residuals_df = pd.DataFrame(predictions, y_test)<br/>residuals_df.reset_index(inplace = True)<br/>residuals_df.rename({'selling_price': 'actual', 0: 'predictions'}, axis = 1, inplace = True)<br/>residuals_df['residuals'] = residuals_df.actual - residuals_df.predictions<br/>residuals_df</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/e2d786692e6d62fb5a0c5625d13d1f92.png" data-original-src="https://miro.medium.com/v2/resize:fit:558/format:webp/1*1B4_TiqqMfqVF15i8tpjDA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">实际值和预测值的数据框架，以及残差(实际值-预测值)</p></figure><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="1a5b" class="mv lt iq mr b gy mw mx l my mz">#predicted y values<br/>predictions = lasso_model.predict(X_test)</span><span id="610a" class="mv lt iq mr b gy na mx l my mz">#residuals (or error between predictions and actual)<br/>residuals = y_test - predictions</span><span id="6ce3" class="mv lt iq mr b gy na mx l my mz">sns.axes_style(style='white')</span><span id="96e2" class="mv lt iq mr b gy na mx l my mz">sns.set(font_scale = 2)<br/>fig, ax = plt.subplots()<br/>fig.set_size_inches(16, 12)<br/>ax = sns.regplot(x="predictions", y="actual", data= residuals_df,  scatter_kws = {'color': 'lightsalmon'}, <br/>                 line_kws = {'color': 'darksalmon'})<br/>ax.set_xlabel('Predicted', fontsize = 30)<br/>ax.set_ylabel('Actual', fontsize = 30)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/135d3b7d6ed0b91d9e82158ce992e2d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vc8425xzpYZR6o64OWWr_A.png"/></div></div></figure><p id="76d2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从这些值中，我们可以看到我们的模型在创建准确预测方面做得不错，但是有许多异常值似乎不符合我们的模型。</p><h2 id="e979" class="mv lt iq bd lu nc nd dn ly ne nf dp mc lf ng nh me lj ni nj mg ln nk nl mi nm bi translated">均方根误差</h2><p id="dae1" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">最后一种评估模型性能的方法是计算均方根误差。这是所有残差平方和，然后是该值的平方根。这告诉我们我们的预测平均有多远。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="5f0f" class="mv lt iq mr b gy mw mx l my mz">from sklearn.metrics import mean_squared_error<br/>(mean_squared_error(y_test, predictions))**0.5</span></pre><p id="8869" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个模型的根 MSE 是 327，518.584，相当于 4，370 美元。虽然我们总是想最小化这个值，但能够预测一辆二手车的价格在 4000 美元以内也是一项不错的成就。使用这种模型，汽车公司可以只根据品牌、行驶公里数、燃料类型和年份等细节合理地给汽车定价。</p><h1 id="ffbf" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论</h1><p id="a773" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">希望这是一个有帮助的数据项目演练，引导您了解 EDA、回归和 Python 建模的一些基础知识。查看 Github 上的<a class="ae kv" href="https://github.com/jewelbritton/Car-Price-Prediction" rel="noopener ugc nofollow" target="_blank">完整代码了解更多细节。</a></p><p id="e0f6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你准备好进行下一步，<a class="ae kv" rel="noopener" target="_blank" href="/classification-basics-walk-through-with-the-iris-data-set-d46b0331bf82">查看虹膜数据集的引导走查，学习分类的基础知识</a>。</p></div></div>    
</body>
</html>