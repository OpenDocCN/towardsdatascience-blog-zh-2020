<html>
<head>
<title>Neural Networks Intuitions — 7. Self-Supervised Learning and SimCLR Paper Explanation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络直觉-7。自我监督学习和SimCLR论文解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/neural-networks-intuitions-7-self-supervised-learning-and-simclr-paper-explanation-ba0101f10c99?source=collection_archive---------31-----------------------#2020-03-23">https://towardsdatascience.com/neural-networks-intuitions-7-self-supervised-learning-and-simclr-paper-explanation-ba0101f10c99?source=collection_archive---------31-----------------------#2020-03-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="771e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">大家好:-)</h2></div><p id="debe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">今天我将谈论深度学习领域最重要和最有趣的话题之一—<strong class="kk iu"><em class="le"/></strong>自我监督学习和最近一篇展示SOTA自我监督学习结果的论文— <a class="ae lf" href="https://arxiv.org/pdf/2002.05709.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="le">视觉表征对比学习的简单框架</em> </a> <em class="le">。</em></p><p id="72b1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">自我监督学习之所以至关重要，是因为在<strong class="kk iu"><em class="le"/></strong>规模下对数据进行<em class="le">手动标记是非常非常昂贵和繁琐的。因此，焦点自动集中在<em class="le">自我监督</em>和<em class="le">非监督学习</em>领域——以减少对大量数据进行标记的需要。</em></p><p id="d65a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们首先了解什么是自我监督学习，以及它如何帮助解决上述人工标记的问题(或者至少最小化它)。</p><p id="61a7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在整篇文章中，我将从解决现实世界问题的角度来解释事情。</p></div><div class="ab cl lg lh hx li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="im in io ip iq"><h1 id="897b" class="ln lo it bd lp lq lr ls lt lu lv lw lx jz ly ka lz kc ma kd mb kf mc kg md me bi translated">问题:</h1><p id="71f8" class="pw-post-body-paragraph ki kj it kk b kl mf ju kn ko mg jx kq kr mh kt ku kv mi kx ky kz mj lb lc ld im bi translated">让我们考虑有1000个类别的图像分类问题。我们有覆盖这1000类的未标记数据(比如100万张图片)。我们如何着手解决这个问题？</p><ol class=""><li id="15d9" class="mk ml it kk b kl km ko kp kr mm kv mn kz mo ld mp mq mr ms bi translated">首先，我们需要<strong class="kk iu"> <em class="le">手动标注</em> </strong>这些图像。</li><li id="d51b" class="mk ml it kk b kl mt ko mu kr mv kv mw kz mx ld mp mq mr ms bi translated">如有必要，应用<strong class="kk iu"> <em class="le">增强</em> </strong>。</li><li id="a42b" class="mk ml it kk b kl mt ko mu kr mv kv mw kz mx ld mp mq mr ms bi translated">然后简单地用<strong class="kk iu"> <em class="le"> resnet50 </em> </strong>骨干<strong class="kk iu"> <em class="le">训练一个分类器</em></strong>——用<strong class="kk iu"> <em class="le"> ImageNet </em> </strong>预训练的权重或者<strong class="kk iu"> <em class="le">随机</em> </strong>权重。</li></ol><p id="b8c6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">步骤2和3非常简单。如果您已经有了所需的框架，那么您可以快速扩充和训练分类器。</p><blockquote class="my"><p id="4620" class="mz na it bd nb nc nd ne nf ng nh ld dk translated">当然，步骤3需要我们试验不同的主干、输入图像分辨率、优化器、损失函数、超参数，如学习速率、批量等等。</p></blockquote><p id="d552" class="pw-post-body-paragraph ki kj it kk b kl ni ju kn ko nj jx kq kr nk kt ku kv nl kx ky kz nm lb lc ld im bi translated">但是第一步也是最重要的一步是给数据贴上标签。手动标记如此大量的数据需要大量的资源，如时间和人力。最重要的是，我们需要确保<strong class="kk iu"> <em class="le">人为错误尽可能少。</em>T47】</strong></p><p id="64bb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因为标记所有的数据是乏味的，所以让我们只注释随机的数据子集。</p><blockquote class="nn no np"><p id="eb18" class="ki kj le kk b kl km ju kn ko kp jx kq nq ks kt ku nr kw kx ky ns la lb lc ld im bi translated">为了简单起见，我选择了一个随机子集，但我们可以优化这个选择。</p></blockquote><p id="9566" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">既然我们要标注一小部分，我们如何减少手工标注的工作量或者完全消除这个标注过程？(<em class="le">尽管这似乎是一个不切实际的目标:)</em>，或者至少利用这<em class="le">大量未标记的数据</em>来帮助提高准确性。</p></div><div class="ab cl lg lh hx li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="im in io ip iq"><h1 id="7328" class="ln lo it bd lp lq lr ls lt lu lv lw lx jz ly ka lz kc ma kd mb kf mc kg md me bi translated">解决方案:</h1><h1 id="479e" class="ln lo it bd lp lq nt ls lt lu nu lw lx jz nv ka lz kc nw kd mb kf nx kg md me bi translated"><strong class="ak"> 1。转移学习:</strong></h1><p id="c2e7" class="pw-post-body-paragraph ki kj it kk b kl mf ju kn ko mg jx kq kr mh kt ku kv mi kx ky kz mj lb lc ld im bi translated">一个显而易见的方法是使用一些与我们的数据集非常相似的开源数据集(即使我们经常找不到)，在开源数据集上进行训练，然后在我们的数据集上微调网络。</p><p id="7c28" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这确实有助于提高分类器的准确性，但不是在很大程度上，并且总是比从随机权重开始更受欢迎。</p><p id="2253" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Btw，为什么我说这个比随机初始化好？</p><blockquote class="nn no np"><p id="ac83" class="ki kj le kk b kl km ju kn ko kp jx kq nq ks kt ku nr kw kx ky ns la lb lc ld im bi translated">这是因为它有助于实现更高的精度和更快的收敛！</p></blockquote><p id="1fe5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">很好，但是怎么做？</p><blockquote class="nn no np"><p id="47da" class="ki kj le kk b kl km ju kn ko kp jx kq nq ks kt ku nr kw kx ky ns la lb lc ld im bi translated">由于我们在类似于我们的目标数据分布的开源数据集上训练我们的网络，这意味着我们的网络已经学习了一些相关特征，而不是随机特征。因此，一旦我们在我们的目标数据集上再次训练网络，自然期望它表现良好并避免在小目标集上过度拟合。这可以被视为等同于“<strong class="kk iu">在更多数据上训练网络”。</strong></p></blockquote><blockquote class="my"><p id="e1d9" class="mz na it bd nb nc ny nz oa ob oc ld dk translated">但是，我们可以通过从我们的未标记目标数据分布中学习的表示来做得更好，而不是从不同的数据分布中学习的表示。</p></blockquote><p id="73ba" class="pw-post-body-paragraph ki kj it kk b kl ni ju kn ko nj jx kq kr nk kt ku kv nl kx ky kz nm lb lc ld im bi translated">因此，我们的下一个方法是自动地从这个未标记的目标分布中学习表示！</p><blockquote class="my"><p id="b73c" class="mz na it bd nb nc nd ne nf ng nh ld dk translated">这种使用未标记的数据来帮助监督任务的技术被称为<strong class="ak"> <em class="od">自监督学习</em> </strong>，并且帮助从这种未标记的目标分布中学习表示的方法被称为<strong class="ak"> <em class="od">借口任务。</em>T15】</strong></p></blockquote><ul class=""><li id="7a05" class="mk ml it kk b kl ni ko nj kr oe kv of kz og ld oh mq mr ms bi translated">这里被监督的任务是<em class="le">在标记数据上训练一个分类器，也称为</em> <strong class="kk iu"> <em class="le">下游任务。</em> </strong></li></ul><h1 id="eb81" class="ln lo it bd lp lq nt ls lt lu nu lw lx jz nv ka lz kc nw kd mb kf nx kg md me bi translated"><strong class="ak"> 2。自我监督学习:</strong></h1><p id="76aa" class="pw-post-body-paragraph ki kj it kk b kl mf ju kn ko mg jx kq kr mh kt ku kv mi kx ky kz mj lb lc ld im bi translated">现在我们知道了什么是自我监督学习，让我们看看有哪些类型的借口任务，以及它们实际上如何帮助学习表征。</p><p id="5073" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇文章将涉及多个借口任务。因此，我将只给出这些任务的概述，以及如何使用它们来解决我们手头的问题:-) </p></div><div class="ab cl lg lh hx li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="im in io ip iq"><h2 id="ee63" class="oi lo it bd lp oj ok dn lt ol om dp lx kr on oo lz kv op oq mb kz or os md ot bi translated"><strong class="ak"> <em class="od"> a .自动编码器:</em> </strong></h2><p id="bdac" class="pw-post-body-paragraph ki kj it kk b kl mf ju kn ko mg jx kq kr mh kt ku kv mi kx ky kz mj lb lc ld im bi translated">Autoencoder是一种神经网络，它试图重建输入，从而学习输入数据表示。</p><p id="ece1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">自动编码器看起来像:</p><figure class="ov ow ox oy gt oz gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/665ad2f814e509349cfa8851f0425d8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/1*wKE69-fX180Q_gkzYzGbwg.png"/></div><p class="pc pd gj gh gi pe pf bd b be z dk translated"><a class="ae lf" href="https://en.wikipedia.org/wiki/Autoencoder#/media/File:Autoencoder_structure.png" rel="noopener ugc nofollow" target="_blank">自动编码器的架构</a></p></figure><ul class=""><li id="331a" class="mk ml it kk b kl km ko kp kr mm kv mn kz mo ld oh mq mr ms bi translated">在我们的例子中，输入和输出将是一个图像。</li></ul><p id="e08d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">网络接收图像并输出相同的图像。通常使用的损失是MSE损失。这里要注意的主要是<strong class="kk iu"> <em class="le">代码(或者嵌入)。</em>T3表示从输入数据中学习到的特征。</strong></p><p id="000a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这对解决我们的问题有什么帮助？</p><blockquote class="my"><p id="b081" class="mz na it bd nb nc nd ne nf ng nh ld dk translated">我们可以在未标记的数据上训练一个自动编码器(resnet50编码器，avgpool的输出作为嵌入)，加载编码器的权重，并在标记的子集上训练。</p></blockquote></div><div class="ab cl lg lh hx li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="im in io ip iq"><h2 id="c049" class="oi lo it bd lp oj ok dn lt ol om dp lx kr on oo lz kv op oq mb kz or os md ot bi translated">b.范例-CNN:</h2><p id="e9a1" class="pw-post-body-paragraph ki kj it kk b kl mf ju kn ko mg jx kq kr mh kt ku kv mi kx ky kz mj lb lc ld im bi translated">论文:- <a class="ae lf" href="https://arxiv.org/pdf/1406.6909.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="le">有判别力的无监督特征学习与样例卷积神经网络</em> </a></p><p id="26ca" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">作者提出了以下方法:</p><ol class=""><li id="33e2" class="mk ml it kk b kl km ko kp kr mm kv mn kz mo ld mp mq mr ms bi translated">对于数据集中每个未标记的图像，应用随机变换，例如平移、旋转、缩放和其他颜色变换。</li><li id="b52d" class="mk ml it kk b kl mt ko mu kr mv kv mw kz mx ld mp mq mr ms bi translated">得到的增强图像集被认为是一个类的一部分(称为<em class="le">代理类)。</em></li><li id="dfd3" class="mk ml it kk b kl mt ko mu kr mv kv mw kz mx ld mp mq mr ms bi translated">之后，训练一个分类器来区分这些代理类。</li></ol><figure class="ov ow ox oy gt oz gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/fcf4bea7cecc09470b2d28970fc45a65.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*BgN_s9x-4YAmHg_obQBcCA.png"/></div><p class="pc pd gj gh gi pe pf bd b be z dk translated">图来自<a class="ae lf" href="https://arxiv.org/pdf/1406.6909.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="od">利用样本卷积神经网络进行的判别无监督特征学习</em> </a></p></figure><blockquote class="my"><p id="7880" class="mz na it bd nb nc ny nz oa ob oc ld dk translated">请注意，可能有太多的代理类表示同一个基本事实类，因为不可能事先知道它们，所以我们可以首先对这些未标记的图像进行聚类(从相似数据集上的预训练模型或在同一数据集上使用autoencoder进行嵌入)，然后对这些聚类应用变换。</p></blockquote><p id="0193" class="pw-post-body-paragraph ki kj it kk b kl ni ju kn ko nj jx kq kr nk kt ku kv nl kx ky kz nm lb lc ld im bi translated">在理想的情况下，每个类(这是我们的<em class="le">代理类)</em>只有一个样本，随机变换被应用于每个样本并进行训练。</p><blockquote class="my"><p id="e978" class="mz na it bd nb nc nd ne nf ng nh ld dk translated">像自动编码器一样，我们可以将训练好的分类器的权重用于我们的下游任务。</p></blockquote></div><div class="ab cl lg lh hx li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="im in io ip iq"><h2 id="1233" class="oi lo it bd lp oj ok dn lt ol om dp lx kr on oo lz kv op oq mb kz or os md ot bi translated">c.对比学习— SimCLR:</h2><p id="27a6" class="pw-post-body-paragraph ki kj it kk b kl mf ju kn ko mg jx kq kr mh kt ku kv mi kx ky kz mj lb lc ld im bi translated">论文<a class="ae lf" href="https://arxiv.org/pdf/2002.05709.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="le">视觉表征对比学习的简单框架</em> </a> <em class="le"> </em>提出了另一种机制，使用<strong class="kk iu"> <em class="le">对比学习</em> </strong>从未标记的数据集中学习有用的表征，该表征稍后可用于下游任务。</p><p id="f764" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">提议的方法:</p><ol class=""><li id="8d1f" class="mk ml it kk b kl km ko kp kr mm kv mn kz mo ld mp mq mr ms bi translated">在训练期间，对N个 未标记图像中的一个<strong class="kk iu"> <em class="le">批次进行采样。</em></strong></li><li id="8827" class="mk ml it kk b kl mt ko mu kr mv kv mw kz mx ld mp mq mr ms bi translated">对于每幅图像，<strong class="kk iu"> <em class="le">应用两种变换——随机裁剪和调整大小，</em> </strong>生成两幅图像，这两幅图像被认为是<strong class="kk iu"> <em class="le">正</em> </strong>样本。同批剩余的<strong class="kk iu"> <em class="le"> (N-1)张</em> </strong>被认为是<strong class="kk iu"> <em class="le">阴性</em> </strong>样本。现在用这两个类训练一个分类器。对该批中的每个图像重复该过程。</li><li id="a035" class="mk ml it kk b kl mt ko mu kr mv kv mw kz mx ld mp mq mr ms bi translated">使用的基本编码器是Resnet50(2048)，后面是一个2层MLP，它将表示从2048转换为128维。</li><li id="087a" class="mk ml it kk b kl mt ko mu kr mv kv mw kz mx ld mp mq mr ms bi translated">所用的损失是NT-Xent(归一化温度标度交叉熵损失)</li></ol><figure class="ov ow ox oy gt oz gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/a111fa38cb7be4c3f0d8a197c76fae7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*bBKzwTqGsmjEfDgfl2RdSg.png"/></div></figure><p id="9e63" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中sim =余弦相似度，𝟙 ∈ {0，1 } IFF<em class="le">k</em>≦<em class="le">I，</em>τ表示温度参数。</p><p id="25d5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">目标是学习两个正图像和其余N-1个负图像的相似表示，以具有与这两个图像完全不同的表示。但是这是如何实现的呢？</p><ol class=""><li id="a4b0" class="mk ml it kk b kl km ko kp kr mm kv mn kz mo ld mp mq mr ms bi translated">为该批中的所有嵌入对计算<strong class="kk iu"> <em class="le">余弦相似度</em> </strong>。</li><li id="42cc" class="mk ml it kk b kl mt ko mu kr mv kv mw kz mx ld mp mq mr ms bi translated">对于<strong class="kk iu"> <em class="le">每个正对(I，j) </em> </strong>，我们计算一个<strong class="kk iu"> <em class="le">归一化相似度得分</em> </strong>，并使用<strong class="kk iu"> <em class="le"> log loss/CE loss将其最小化。</em> </strong></li><li id="1cd2" class="mk ml it kk b kl mt ko mu kr mv kv mw kz mx ld mp mq mr ms bi translated">对批(2N)中的所有图像进行此操作，最后取一个<strong class="kk iu"> <em class="le">平均值</em> </strong>。</li></ol><p id="1f2f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，这里有一点很重要:</p><blockquote class="my"><p id="1c86" class="mz na it bd nb nc nd ne nf ng nh ld dk translated">我们如何确保一批中用于阴性类别的(N-1)幅图像不包含阳性样本，因为我们首先不知道它们的标签？</p></blockquote><p id="976f" class="pw-post-body-paragraph ki kj it kk b kl ni ju kn ko nj jx kq kr nk kt ku kv nl kx ky kz nm lb lc ld im bi translated">可惜，文件没有清楚说明这点，我也不知道上述问题的答案。我们可以做的一件事是基于预训练的嵌入来挑选负面图像，但我不认为这种情况会发生！如果有人知道答案，请告诉我:-)</p></div><div class="ab cl lg lh hx li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="im in io ip iq"><h2 id="5eff" class="oi lo it bd lp oj ok dn lt ol om dp lx kr on oo lz kv op oq mb kz or os md ot bi translated">其他常见借口任务:</h2><p id="052d" class="pw-post-body-paragraph ki kj it kk b kl mf ju kn ko mg jx kq kr mh kt ku kv mi kx ky kz mj lb lc ld im bi translated">所有上述借口任务直接学习分类底层类(除了自动编码器)，但也有任务试图<em class="le">优化不同的目标，但学习有用的表示</em>为下游任务。</p><ol class=""><li id="c8ca" class="mk ml it kk b kl km ko kp kr mm kv mn kz mo ld mp mq mr ms bi translated"><strong class="kk iu">生成对抗网络:</strong>我们可以训练GAN从我们的未标记数据分布中生成图像，使用<em class="le">生成器(即编码器)的权重</em>并在我们的标记子集上重新训练。</li><li id="3f7f" class="mk ml it kk b kl mt ko mu kr mv kv mw kz mx ld mp mq mr ms bi translated">预测图像旋转— <a class="ae lf" href="https://arxiv.org/abs/1803.07728" rel="noopener ugc nofollow" target="_blank"> <em class="le">通过预测图像旋转进行无监督表示学习</em> </a></li><li id="7431" class="mk ml it kk b kl mt ko mu kr mv kv mw kz mx ld mp mq mr ms bi translated">预测图像中一个面片wrt与另一个面片的相对位置— <a class="ae lf" href="https://arxiv.org/abs/1505.05192" rel="noopener ugc nofollow" target="_blank"> <em class="le">通过上下文预测的无监督视觉表示学习</em> </a></li></ol></div><div class="ab cl lg lh hx li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="im in io ip iq"><h2 id="d0b8" class="oi lo it bd lp oj ok dn lt ol om dp lx kr on oo lz kv op oq mb kz or os md ot bi translated">参考资料:</h2><ol class=""><li id="3687" class="mk ml it kk b kl mf ko mg kr pi kv pj kz pk ld mp mq mr ms bi translated"><a class="ae lf" href="https://arxiv.org/pdf/1406.6909.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="le">用样例卷积神经网络进行判别性无监督特征学习</em> </a> <em class="le">。</em></li><li id="0ccf" class="mk ml it kk b kl mt ko mu kr mv kv mw kz mx ld mp mq mr ms bi translated"><a class="ae lf" href="https://arxiv.org/pdf/2002.05709.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="le">视觉表征对比学习的简单框架</em> </a> <em class="le">。</em></li><li id="0fa4" class="mk ml it kk b kl mt ko mu kr mv kv mw kz mx ld mp mq mr ms bi translated"><a class="ae lf" href="https://lilianweng.github.io/lil-log/2019/11/10/self-supervised-learning.html" rel="noopener ugc nofollow" target="_blank">https://lilian Weng . github . io/lil-log/2019/11/10/self-supervised-learning . html</a></li></ol></div></div>    
</body>
</html>