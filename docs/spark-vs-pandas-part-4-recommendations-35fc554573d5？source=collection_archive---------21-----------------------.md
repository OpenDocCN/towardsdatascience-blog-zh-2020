# 星火大战熊猫，第 4 部分—建议

> 原文：<https://towardsdatascience.com/spark-vs-pandas-part-4-recommendations-35fc554573d5?source=collection_archive---------21----------------------->

## 为什么星火和熊猫都不比对方强。或者:总是为正确的工作选择正确的工具。

![](img/e2151dcea21267adabbb1055cee167ac.png)

塞萨尔·卡利瓦里诺·阿拉贡在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍照

最初我想写一篇文章来公平地比较熊猫和火花，但它继续增长，直到我决定把它分开。这是小编的第二部。

*   [星火大战熊猫，第一部——熊猫](/spark-vs-pandas-part-1-pandas-10d768b979f5)
*   [星火大战熊猫，第二部——星火](/spark-vs-pandas-part-2-spark-c57f8ea3a781)
*   [星火大战熊猫，第三部分——语言](/spark-vs-pandas-part-3-scala-vs-python-7b267b130158)
*   星火大战熊猫，第 4 部分—推荐

## 期待什么

本系列的最后一部分将为您提供一些建议，告诉您如何在实现给定任务的两种技术之间进行选择。

# 什么时候更喜欢熊猫而不是星火

在详细分析了两个竞争者 Pandas 和 Spark 之后，我们现在可以总结两者的优势和劣势，并提供何时使用什么的指示。

先说熊猫吧。

## 强项

熊猫很容易使用，你可以找到很多有价值的信息和在线资源。只要数据量不太大，Pandas 执行所有 it 操作的速度都相当快。它很好地集成到一个完整的数字、统计和机器学习库生态系统中，如 SciKit Learn、Tensorflow 等。

## 弱点

熊猫一点也没有伸缩性。它不能利用多个 CPU，并且整个数据集需要放入本地机器的 RAM 中。像 Dask 这样的一些项目试图解决这些缺点，但那是另一回事。

Python 作为一种语言，由于是动态类型的，所以有点弱。编写健壮的代码比静态编译语言更难。

## 结论

因为它的简单性、灵活性和可用性，我总是用 Pandas 进行数据探索和实验——只要数据适合内存。具体到 ML 项目，我不会三思而行，从熊猫开始，因为所有强大的库，都与熊猫很好地集成在一起。即使最终的数据量可能太大，熊猫和它的朋友仍然是一个足够简单和灵活的工具，可以用完整数据集的子集进行第一次实验。

另一方面，现在我在使用 Pandas 进行生产工作负载之前会三思，因为 Python 作为一种动态类型语言，其正确性保证较弱。但是由于许多重要的 ML 库的可用性，Python 和 Pandas 也在生产中占有一席之地。(可惜)。

# 什么时候更喜欢星火而不是熊猫

Spark 在熊猫有一些弱点的许多领域大放异彩，我们将在下面看到。

## 强项

Spark 可以很好地扩展——包括 CPU 数量、机器数量以及最重要的数据量。除了时间之外，您可以用有限的资源处理多少数据并没有真正的限制。

由于各种数据源和接收器都有大量的连接器可用，Spark 非常适合集成来自不同来源的数据。

最后，依靠 Scala 作为静态类型和编译语言，Spark 代码通常比 Python 代码具有更高的内在健壮性。这使得 Spark 和 Scala 成为非常好的产品候选。

## 弱点

Spark 是为海量数据而生的——尽管它比它的老祖先 Hadoop 快得多，但在小数据集上仍然经常较慢，对于 Pandas 来说不到一秒钟。

Spark 提供了一些 ML 算法，但是你可能永远也不会得到像 Python 那样丰富的宇宙。

需要记住的一点是，Spark 被设计为在机器集群中运行的关系代数——但是关系代数的处理原子(连接、投影、过滤、聚合、简单转换等)不同于矩阵代数的处理原子(矩阵乘法、分解等),后者是大多数 ML 算法所需要的。当你花些时间观察 Spark 中 ML 算法的[实现时，你会发现开发人员不得不将数值问题转化为 map/reduce 问题，以便进行分布式处理。虽然这是可能的，但它当然比使用分布式矩阵代数要困难得多，这反过来也解释了 ML 领域中新功能 Spark 的缓慢开发。](https://github.com/apache/spark/tree/master/mllib/src/main/scala/org/apache/spark/ml)

## 结论

Spark 非常适合典型的 ETL/ELT 工作负载，但由于可用算法的数量有限，它只是*我的*机器学习项目的第二选择。如果你有大量的数据，子采样是行不通的，Spark 仍然是一个不错的选择。

# 星火和熊猫的结合

到目前为止，我的观点是在给定的任务中使用*或者*熊猫*或者* Spark，但是不将它们组合在一个应用程序中。但有时候这个世界会有一些礼物送给你，这次是 *PySpark* 。尽管 PySpark 主要是 Spark 的 Python 包装器，但它包含了对在 Spark 中集成 Pandas 代码的*的支持。*

Spark 内部直接支持 Pandas 的主要驱动力是，即使是 Spark 开发人员也明白 Spark 不能也不应该试图在某些场景中取代 Pandas，尤其是在项目的 ML 部分。相反，Spark 将其开发重点放在整合像 Pandas 甚至 Tensorflow 这样的框架上。

Spark 基本上提供了两个级别的熊猫集成:

## 转换数据帧

Pandas 的第一个也是最简单直接的集成是 Spark 数据帧和 Pandas 数据帧之间的转换能力。这允许开发人员使用两种框架并在它们之间切换。但是要注意，Spark 不会神奇地消除 Pandas 的限制:当将 Spark 数据帧转换成 Pandas 数据帧时，整个数据集再次需要适合本地机器的 RAM。

虽然这种限制对于某些场景来说可能是一个障碍，但在其他场景中是可以接受的，在这些场景中，您使用 Spark 来减少数据量(通过采样或聚合)，然后使用 Pandas 及其朋友(SciKit Learn 等)来继续处理较小的数据集。

## 嵌入熊猫

正如我们所见，简单地在 Spark 数据帧和 Pandas 数据帧之间来回切换是不可取的，但幸运的是，在 PySpark 应用程序中使用 Pandas 有一种更好的方法:

在 2.3.0 版本中，Apache Spark 引入了所谓的 [*Pandas 用户定义函数*](https://spark.apache.org/docs/3.0.1/sql-pyspark-pandas-with-arrow.html#pandas-udfs-aka-vectorized-udfs)(UDF)以及已经存在的 Python UDFs。在 2.3.0 版本之前，编写应该由 Apache Spark 在所有执行器上并行执行的定制 Python 代码的唯一方法是编写一个包含所需逻辑的小 Python 函数，并将该函数包装到 Python UDF 中。然后 Spark 将对每条记录执行 UDF。

虽然听起来不错，但这种方法是出了名的慢。Spark 中的 Python UDFs 是通过在 Spark(位于一个 JVM 进程中)和多个 Python 进程之间交换数据来实现的，然后为每条记录调用用户定义的 Python 函数。这种方法包含两个重要的瓶颈:首先，数据交换涉及 CPU 密集型的数据序列化和反序列化步骤，其次，为每个单独的记录调用 Python 函数非常慢。

为了改善这种情况，Spark 实现了一个新的 API 来创建 Pandas UDFs，以提供显著的性能提升。使用 Pandas UDFs，您现在可以提供 Python 函数，这些函数不再对单个记录起作用，而是转换 Pandas 数据帧或包含要转换的多批记录的系列。此外，通过使用 [Apache Arrow](https://arrow.apache.org/) Spark 不再需要执行昂贵的序列化/反序列化。相反，Spark 使用共享内存或直接传递内存块，不进行任何转换，在 JVM 和 Python 之间交换数据。

这种结合将把来自两个世界的特性引入到一个应用程序中:通过使用 Pandas，您有了更大程度的灵活性，并且通过在 Spark 中嵌入 Pandas 代码，它可以在集群中的多台机器上并行执行。

# 结论

不要试图用 Spark 代替熊猫，它们是互补的，各有利弊。

使用熊猫还是 Spark 取决于你的用例。对于大多数机器学习任务，你可能最终会使用熊猫，即使你用 Spark 做预处理。但是对于复杂的数据工程任务，通常也需要扩展到大量的数据，我强烈推荐使用 Spark 和 Scala(不要害怕 Scala——从项目的角度来看，投资 Scala 是有回报的)。