<html>
<head>
<title>Inside Convolutional Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络内部</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/inside-convolutional-neural-network-e1c4c1d44fa2?source=collection_archive---------69-----------------------#2020-06-09">https://towardsdatascience.com/inside-convolutional-neural-network-e1c4c1d44fa2?source=collection_archive---------69-----------------------#2020-06-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/21f516340fc989764ca0538be977a65c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*evl1rZpcj7-uR8gIpNWvVg.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">作者图片</p></figure><h1 id="a25f" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated"><strong class="ak">简介</strong></h1><p id="c5a4" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><strong class="lc ir">卷积神经网络(CNN) </strong>是用于识别、分类等的深度学习算法之一。最常用于分析视觉图像，这是做、设计或实现它的困难任务之一。在这里，网络的每一层都与下一层的所有神经元相连。从20世纪50年代的一项生物学实验开始，这个领域已经有了很大的进步和发展。通常，几十年前，计算机很难识别猫和狗，但现在它已经变得像一个“<em class="ly">你好世界</em>项目”。</p><p id="e4a1" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">在过去的几十年里，<strong class="lc ir">图像识别</strong>或<strong class="lc ir">计算机视觉</strong>已经成为一个在研究、分析和预测方面越来越有兴趣、持续和进步的伟大课题。我们人类识别图像及其类型的方式，电子机器已经训练自己更深入地识别和看待事物。计算机视觉比人类视觉认知系统更擅长从图像中识别模式。</p><p id="c766" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated"><strong class="lc ir">计算机视觉</strong>或i <strong class="lc ir">图像识别</strong>由深度学习算法驱动，该算法使用<strong class="lc ir"> CNN </strong>来获得图像的感觉。它不仅能识别模式，还能记忆应该为每个输入图像提供的理想输出(在<em class="ly">监督学习</em>的情况下)，或者通过扫描轮廓和颜色等特征对图像的组成部分进行分类。然后在扫描这些图像时使用这些内存。</p><p id="23c5" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">当第一次进入CNN模型时，真的很难更深入地理解它。所以，我试着用基本而简短的回答来弄清楚CNN的内幕。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi me"><img src="../Images/7a0ef36fcc58d1e35020dc3f6456460a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BMOsij92-KqiIYf1lBamkA.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">作者图片</p></figure><p id="cb75" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">人工神经网络中的多隐层前馈神经网络通常被称为<strong class="lc ir">(DNN)</strong>深度神经网络。卷积神经网络也是一种前馈神经网络。到目前为止，可以说CNN是一种广泛应用于识别和图像处理的识别算法，它具有结构简单、训练参数少、适应性强等特点。</p><p id="095a" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">因为神经网络接收输入(张量)并通过一系列隐藏层对其进行转换。每个隐藏层由一组神经元组成，其中每个神经元都与前一层中的所有神经元完全连接。</p><p id="82a6" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">在每一层，单元被组织成称为特征地图的二维网格。这些特征图中的每一个都是卷积<strong class="lc ir">的结果，即</strong>相同的卷积层(<em class="ly">权重集</em>)被应用于该层中的每个位置。因此，在2-D网格上特定位置的单元只能从该层上类似位置的单元接收输入。并且对于特征图中的每个单元，附加到输入的权重是相同的。</p><p id="c581" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">当卷积层完成后，其他一些计算也完成了。其中之一是交叉特征归一化。这里，单元在特征地图中的特定空间位置的活动除以单元在其他特征地图中的相同位置的活动。另一个常见的操作是合用。池缩小了要素地图的大小。这一整套操作合起来称为<strong class="lc ir">【层】</strong>。网络的架构是由层数和与其相关的各种参数的选择来定义的，例如卷积滤波器的大小。</p><p id="d6ec" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">在卷积层内部，我们需要指定滤波器的数量、滤波器大小、填充、激活函数/非线性。</p><p id="aff9" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">让我们和其他人讨论其中的一些。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/27c38d3aa03e0806667f246433f7cadf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*e-Wwir7QhVBXvpcMeB-DvQ.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图:CNN架构Img Ref:<a class="ae mk" href="https://neurdiness.wordpress.com/2018/05/17/deep-convolutional-neural-networks-as-models-of-the-visual-system-qa/" rel="noopener ugc nofollow" target="_blank">neur idines</a></p></figure><p id="d408" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">简而言之，CNN包含以下不同层:</p><p id="3ae6" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated"><strong class="lc ir"> a .致密层</strong></p><p id="4066" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated"><strong class="lc ir"> b .卷积层</strong></p><p id="6d9d" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated"><strong class="lc ir"> c .最大池层</strong></p><p id="b2f1" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated"><strong class="lc ir"> d .辍学</strong></p><p id="6812" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">所以，了解了它的基本架构之后，问题来了<strong class="lc ir">我们如何用代码设计卷积神经网络？</strong></p><p id="9302" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">这个问题看起来很难，但实际上并不难。Python有很好的库和框架来设计神经网络，不管它是CNN，RNN T21还是其他什么。我们唯一需要了解的是层、池和它们内部的其他参数。</p><p id="e805" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">让我们用一种简单的方法来设计它，并以抽象的方式选择最佳参数和超参数。</p><p id="2b4e" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">卷积层是卷积网络的核心构建模块，承担大部分繁重的计算工作。选择层数时，最好从最小的<strong class="lc ir">层</strong>开始，然后逐渐增加层的尺寸，或者从大的模型层开始，然后逐渐减小。当使用较大的模型时，选择我们最初构建的模型有多大变得非常困难。</p><p id="ab00" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">当更深的网络能够开始收敛时，退化问题就暴露出来了:随着网络深度的增加，精度达到饱和(这可能不足为奇)，然后迅速退化。出乎意料的是，这种退化不是由<em class="ly">过拟合</em>引起的，并且向适当深度的模型添加更多层导致<em class="ly">更高的训练误差。</em></p><p id="8654" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">训练精度的下降表明，并不是所有的系统都同样容易优化。</p><p id="c58d" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">虽然给出了相同数量的可训练参数，但可能出现在使用更多层或每层更多单元之间做出决定的情况。从这个意义上来说，通常更深比更宽更好。另一种使深度模型更容易的方法是添加连接非连续层的跳过连接。像我们可以使用<strong class="lc ir"> ResNet </strong>架构类型的连接。</p><p id="0ead" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">跳跃连接还为梯度更容易地回流创建了额外的路径。这使得更容易优化早期的层。在神经网络设计中，使用跳过连接是一种常见的模式。</p><h2 id="b28a" class="ml kd iq bd ke mm mn dn ki mo mp dp km ll mq mr kq lp ms mt ku lt mu mv ky mw bi translated">汇集层</h2><p id="4842" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">池层使表示更小、更易管理，并独立地在每个激活图上操作。汇集层接受三维体积，需要三个超参数，它们的空间范围为<strong class="lc ir"/><strong class="lc ir">F</strong>，<strong class="lc ir">步距为S </strong>，并产生三维体积，其中<strong class="lc ir"> W=(W1-F)/S+1 </strong>，<strong class="lc ir"> H=(H1-F)/S+1 </strong>，<strong class="lc ir"> D2=D1 </strong>。池层引入了零参数，因为它计算输入的固定函数。我们不使用零填充来合并层。</p><p id="99ca" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">使用内核或过滤器模型时，通常最好使用<strong class="lc ir"> 3X3 </strong>或<strong class="lc ir"> 1X1 </strong>内核，因为大多数时候它工作得最好。我们可以将<strong class="lc ir"> 3X3 </strong>内核相互堆叠，以获得更大的感受野。使用<strong class="lc ir"> 1X1 </strong>滤镜的一个好处就是可以用于降维。</p><h1 id="cced" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">摘要</h1><p id="87fd" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">简而言之，我们可以说<strong class="lc ir">卷积层</strong>是接受体积为<strong class="lc ir">W1 * H1 * D1</strong>(<strong class="lc ir">W</strong>eights、<strong class="lc ir"> H </strong> eights和<strong class="lc ir"> D </strong> epth)的层，这需要四个超参数，其中<strong class="lc ir">滤波器</strong>的数量被定义为<strong class="lc ir"> K，</strong>它们的<strong class="lc ir">空间范围</strong> <strong class="lc ir"> F，</strong> <strong class="lc ir">步距</strong> 用数量为<strong class="lc ir">的零填充</strong> <strong class="lc ir"> P. </strong>利用上述输入，卷积层产生大小为<strong class="lc ir"> W2*H2*D2 </strong>的体积，其中<strong class="lc ir"> W2 =(W1-F+2P)/S+1，H2 =(H1-F+2P)/S+1 </strong>(即<strong class="lc ir">宽度</strong>和<strong class="lc ir">高度</strong>通过对称相等地计算)和<strong class="lc ir">D2 = k .<strong class="lc ir"> K </strong>重量和<strong class="lc ir"> K </strong>偏差。在输出体积中，<strong class="lc ir"> d- </strong> th <strong class="lc ir"> </strong>深度切片(大小为<strong class="lc ir"> W2*H2 </strong>)是在输入体积上以<strong class="lc ir"> S、</strong>步距执行<strong class="lc ir"> d- </strong> th滤波器的有效卷积的结果，然后偏移<strong class="lc ir"> d- </strong> th偏置。</strong></p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mx"><img src="../Images/f6740d95ae97dbc4dc58c79a9c505649.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4o114oe7bI8zmyLD-bJC7Q.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图:带过滤器的CNN</p></figure><p id="3aa1" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated"><em class="ly">感谢阅读。</em></p><p id="2fe9" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated"><em class="ly">参考文献:</em></p><p id="78ca" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated"><em class="ly"> 1。</em><a class="ae mk" href="https://arxiv.org/pdf/1506.01195.pdf" rel="noopener ugc nofollow" target="_blank"><em class="ly">https://arxiv.org/pdf/1506.01195.pdf</em></a></p><p id="d3a2" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated"><em class="ly"> 2。</em><a class="ae mk" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank"><em class="ly">https://en.wikipedia.org/wiki/Convolutional_neural_network</em></a></p><p id="9107" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated"><em class="ly"> 3。</em><a class="ae mk" href="https://www.forbes.com/sites/cognitiveworld/2019/06/26/the-present-and-future-of-computer-" rel="noopener ugc nofollow" target="_blank"><em class="ly">https://www . Forbes . com/sites/cognitive world/2019/06/26/the-present-and-future-of-computer-</em></a><a class="ae mk" href="https://www.forbes.com/sites/cognitiveworld/2019/06/26/the-present-and-future-of-computer-vision/#185e3778517d" rel="noopener ugc nofollow" target="_blank"><em class="ly">vision/# 185 e 3778517d</em></a></p><p id="fb06" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">4.<a class="ae mk" href="https://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">https://cs231n.github.io/convolutional-networks/</a></p><p id="24e5" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">5.<a class="ae mk" href="https://neurdiness.wordpress.com/2018/05/17/deep-convolutional-neural-networks-as-models-of-the-visual-system-qa/" rel="noopener ugc nofollow" target="_blank">https://neur diness . WordPress . com/2018/05/17/deep-convolutionary-neural-networks-as-models-of-the-visual-system-QA/</a></p><p id="f533" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">6.http://cs231n.stanford.edu/<a class="ae mk" href="http://cs231n.stanford.edu/" rel="noopener ugc nofollow" target="_blank"/></p><p id="9aba" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">7.【https://www.youtube.com/watch?v=fTw3K8D5xDs T4】</p><p id="7377" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">8.<a class="ae mk" href="https://keras.io/api/applications/resnet/" rel="noopener ugc nofollow" target="_blank">https://keras.io/api/applications/resnet/</a></p><p id="eb22" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">9.<a class="ae mk" href="https://arxiv.org/pdf/1512.03385.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1512.03385.pdf</a></p><p id="3f72" class="pw-post-body-paragraph la lb iq lc b ld lz lf lg lh ma lj lk ll mb ln lo lp mc lr ls lt md lv lw lx ij bi translated">10.<a class="ae mk" href="https://cs231n.github.io/" rel="noopener ugc nofollow" target="_blank">https://cs231n.github.io/</a></p></div></div>    
</body>
</html>