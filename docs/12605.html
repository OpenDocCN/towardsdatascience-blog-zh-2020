<html>
<head>
<title>Farewell RNNs, Welcome TCNs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">告别 RNNs，欢迎 TCNs</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/farewell-rnns-welcome-tcns-dd76674707c8?source=collection_archive---------1-----------------------#2020-08-31">https://towardsdatascience.com/farewell-rnns-welcome-tcns-dd76674707c8?source=collection_archive---------1-----------------------#2020-08-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3515" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">时间卷积网络如何有利于序列建模-股票趋势预测。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/85b645dbedee1466ea6b35a56f38a2bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j5ZGkHb3uN75QmlYlLikrg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/s/photos/wall-street?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae ky" href="https://unsplash.com/@aditya1702?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Aditya Vyas </a>拍摄</p></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="d6cb" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><em class="mc">免责声明:本文假设读者对 LSTM 神经网络的模型直觉和架构有初步的了解。</em></p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="4344" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">概观</h1><ol class=""><li id="5700" class="mv mw it li b lj mx lm my lp mz lt na lx nb mb nc nd ne nf bi translated"><strong class="li iu"><em class="mc">FTS 深度学习背景</em> </strong></li><li id="a725" class="mv mw it li b lj ng lm nh lp ni lt nj lx nk mb nc nd ne nf bi translated"><strong class="li iu"><em class="mc">FTS 值得注意的数据预处理做法</em> </strong></li><li id="3a8d" class="mv mw it li b lj ng lm nh lp ni lt nj lx nk mb nc nd ne nf bi translated"><strong class="li iu"> <em class="mc">时态卷积网络架构</em> </strong></li><li id="f950" class="mv mw it li b lj ng lm nh lp ni lt nj lx nk mb nc nd ne nf bi translated"><strong class="li iu"><em class="mc">FTS 时态卷积网络应用实例</em> </strong></li></ol><ul class=""><li id="a7e5" class="mv mw it li b lj lk lm ln lp nl lt nm lx nn mb no nd ne nf bi translated"><strong class="li iu"> <em class="mc">通过 TCN 进行知识驱动的股票走势预测和解释</em> </strong></li></ul><h1 id="97e8" class="md me it bd mf mg np mi mj mk nq mm mn jz nr ka mp kc ns kd mr kf nt kg mt mu bi translated">1.背景</h1><p id="68b7" class="pw-post-body-paragraph lg lh it li b lj mx ju ll lm my jx lo lp nu lr ls lt nv lv lw lx nw lz ma mb im bi translated">金融时间序列(FTS)建模是一项历史悠久的实践，它在 20 世纪 70 年代初首次革新了算法交易。FTS 的分析分为两类:基本面分析和技术面分析。这两种做法都受到了有效市场假说(EMH)的质疑。自 1970 年首次出版以来备受争议的 EMH 假设股票价格最终是不可预测的。这并没有限制通过使用线性、非线性和最大似然模型对 FTS 进行建模的研究，如下文所述。</p><p id="7bc9" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">由于金融时间序列具有非平稳、非线性、高噪声的特点，传统的统计模型很难对其进行高精度的预测。因此，近年来越来越多的人试图将深度学习应用于股票市场预测，尽管还远远不够完美。仅举几个例子:</p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><blockquote class="nx ny nz"><p id="6479" class="lg lh mc li b lj lk ju ll lm ln jx lo oa lq lr ls ob lu lv lw oc ly lz ma mb im bi translated"><strong class="li iu"> <em class="it"> 2013 </em> </strong></p></blockquote><p id="ff06" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><a class="ae ky" href="https://ieeexplore.ieee.org/document/6706743/" rel="noopener ugc nofollow" target="_blank">林<em class="mc">等</em> </a>提出了一种利用支持向量机建立两部分特征选择和预测模型进行股票预测的方法，并证明该方法比传统方法具有更好的泛化能力。</p><blockquote class="nx ny nz"><p id="5b2e" class="lg lh mc li b lj lk ju ll lm ln jx lo oa lq lr ls ob lu lv lw oc ly lz ma mb im bi translated"><strong class="li iu"> <em class="it"> 2014 </em> </strong></p></blockquote><p id="a967" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">万贾瓦<em class="mc">等人</em>。提出了一种使用带有误差反向传播的前馈多层感知器的人工神经网络来预测股票价格。结果表明，该模型可以预测一个典型的股票市场。</p><blockquote class="nx ny nz"><p id="cbce" class="lg lh mc li b lj lk ju ll lm ln jx lo oa lq lr ls ob lu lv lw oc ly lz ma mb im bi translated"><strong class="li iu">T5】2017T7】</strong></p></blockquote><p id="1ba4" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">进入<strong class="li iu">LSTM</strong>——关于 LSTM 神经网络应用于时间序列数据的研究激增。</p><p id="cbbf" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><a class="ae ky" href="https://www.semanticscholar.org/paper/Time-Weighted-LSTM-Model-with-Redefined-Labeling-Zhao-Rao/d89fa15ae56701ac8901ee5baf9187b41e3d8968" rel="noopener ugc nofollow" target="_blank">赵<em class="mc">等</em> </a>，神经网络加入了时间加权函数，结果超过了其他模型。</p><blockquote class="nx ny nz"><p id="b89c" class="lg lh mc li b lj lk ju ll lm ln jx lo oa lq lr ls ob lu lv lw oc ly lz ma mb im bi translated"><strong class="li iu">T17】2018T19】</strong></p></blockquote><p id="9cc1" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><a class="ae ky" href="https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0227222&amp;type=printable" rel="noopener ugc nofollow" target="_blank">张<em class="mc">等</em> </a>后来把卷积神经网络(CNN)和递归神经网络()结合起来提出了一种新的架构，即深度和广域神经网络()。结果表明，与一般的 RNN 模型相比，DWNN 模型可以将预测均方差降低 30%。</p><p id="c843" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><a class="ae ky" href="https://www.sciencedirect.com/science/article/abs/pii/S0957417418301416" rel="noopener ugc nofollow" target="_blank">哈<em class="mc">等人</em>。</a>，CNN 被用来开发一种定量选股策略，以确定股票走势，然后使用 LSTM 来预测股票价格，推广一种混合神经网络模型，用于定量择时策略，以增加利润。</p><p id="1c8c" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><a class="ae ky" href="https://link.springer.com/chapter/10.1007/978-3-319-93351-1_32" rel="noopener ugc nofollow" target="_blank">姜<em class="mc">等人</em>。</a>用 LSTM 神经网络和 RNN 构建模型，发现 LSTM 能更好地应用于股票预测。</p><blockquote class="nx ny nz"><p id="d246" class="lg lh mc li b lj lk ju ll lm ln jx lo oa lq lr ls ob lu lv lw oc ly lz ma mb im bi translated"><strong class="li iu">T33】2019T35】</strong></p></blockquote><p id="eb7f" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><a class="ae ky" href="https://link.springer.com/article/10.1007/s00521-019-04504-2?shared-article-renderer" rel="noopener ugc nofollow" target="_blank">金<em class="mc">等人</em>。</a>在模型分析中增加投资者情绪倾向，引入经验模态分解(EMD)结合 LSTM，获得更准确的股票预测。基于注意机制的 LSTM 模型在语音和图像识别中很常见，但在金融中很少使用。</p><p id="84c9" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><a class="ae ky" href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" rel="noopener ugc nofollow" target="_blank"><em class="mc">等</em> </a> <em class="mc"> </em>现在热门的前身，<strong class="li iu"> GPT-3 </strong>，<em class="mc"> </em> GPT-2 的目标是设计一个多任务学习器，它利用预训练和监督微调的结合来实现更灵活的转移形式。因此，它有 1542 米的参数，比其他比较模型大得多。</p><p id="f340" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><a class="ae ky" href="https://core.ac.uk/download/pdf/222446995.pdf" rel="noopener ugc nofollow" target="_blank">舒敏<em class="mc">等人</em> </a>。使用<em class="mc">时间卷积网络(</em> KDTCN)进行股票趋势预测和解释的知识驱动方法。他们首先从金融新闻中提取结构化事件，并利用知识图获得事件嵌入。然后，结合事件嵌入和价格值来预测股票趋势。实验证明，这可以(I)更快地对突然变化做出反应，并在股票数据集上胜过最先进的方法。(这将是本文的重点。)</p><blockquote class="nx ny nz"><p id="98f7" class="lg lh mc li b lj lk ju ll lm ln jx lo oa lq lr ls ob lu lv lw oc ly lz ma mb im bi translated"><strong class="li iu"> <em class="it"> 2020 </em> </strong></p></blockquote><p id="6517" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><a class="ae ky" href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0227222#pone.0227222.ref016" rel="noopener ugc nofollow" target="_blank">嘉鱼<em class="mc">等人</em>。</a>和<a class="ae ky" href="https://arxiv.org/abs/1812.07699" rel="noopener ugc nofollow" target="_blank"> Thomas <em class="mc">等人</em>和</a>提出了基于最近新闻序列的混合注意网络来预测股票走势。具有注意机制的 lstm 优于常规 lstm，因为它由于其独特的存储单元结构而防止了长期依赖性。</p><p id="85ad" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><a class="ae ky" href="https://arxiv.org/pdf/2002.12530.pdf" rel="noopener ugc nofollow" target="_blank">红岩<em class="mc">等人</em> </a> <em class="mc"> </em>提出了一种探索性的架构，称为<em class="mc">时态卷积基于注意的网络(TCAN) </em>，它结合了时态卷积网络和注意机制。TCAN 包括两个部分，一个是<em class="mc">时间注意(TA) </em>，它捕捉序列内部的相关特征，另一个是<em class="mc">增强残差(ER) </em>，它提取浅层的重要信息并传递到深层。</p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="3e29" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">上面的时间线仅仅是为了提供对 FTS 在深度学习方面的历史背景的一瞥，而不是淡化序列模型学术界在类似时期所做的重要工作。</p><p id="3775" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">然而，这里有一句话值得一提。FTS 预测领域的学术出版物可能经常误导人。由于大量使用模拟器，许多 FTS 预测论文倾向于夸大其表现以获得认可，并过度拟合其模型。这些论文中声称的许多表现很难复制，因为它们不能概括预测的特定 FTS 的未来变化。</p><h1 id="2f42" class="md me it bd mf mg np mi mj mk nq mm mn jz nr ka mp kc ns kd mr kf nt kg mt mu bi translated">2.FTS 值得注意的数据预处理实践</h1><h2 id="3db9" class="od me it bd mf oe of dn mj og oh dp mn lp oi oj mp lt ok ol mr lx om on mt oo bi translated">2.1 去噪</h2><p id="2663" class="pw-post-body-paragraph lg lh it li b lj mx ju ll lm my jx lo lp nu lr ls lt nv lv lw lx nw lz ma mb im bi translated">金融时间序列数据——尤其是股票价格，会随着季节性、噪音和自动修正而不断波动。传统的预测方法使用移动平均线和差分来减少预测的噪声。然而，FTS 通常是非平稳的，并且表现出有用信号和噪声的重叠，这使得传统的去噪无效。</p><p id="9b09" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">小波分析在图像和信号处理等领域取得了显著的成就。由于其能够弥补傅立叶分析的缺点，逐渐被引入到经济和金融领域。<strong class="li iu">小波变换在解决传统的时间序列分析问题上具有独特的优势，因为它可以从不同的时间和频率域尺度上分解和重构金融时间序列数据</strong>。</p><p id="90c2" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">小波变换本质上是利用多尺度特征对数据集进行去噪，有效地将有用信号从噪声中分离出来。在由<a class="ae ky" href="https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0227222&amp;type=printable" rel="noopener ugc nofollow" target="_blank"> <em class="mc">邱佳宇、、</em> </a> <em class="mc">、</em>的论文中，他们使用了具有三个分解层的 coif3 小波函数，并通过其信噪比(SNR)和均方根误差(RMSE)来评价小波变换的效果。<strong class="li iu">信噪比越高，RMSE 越小，小波变换的去噪效果越好</strong>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/79b9585b682fe52603726a79ab0d63a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mqbTuP4AcCoRydB1Qnz1Vw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0227222&amp;type=printable" rel="noopener ugc nofollow" target="_blank"> <em class="oq">嘉鱼秋 1、</em>、</a></p></figure><h2 id="6d00" class="od me it bd mf oe of dn mj og oh dp mn lp oi oj mp lt ok ol mr lx om on mt oo bi translated">2.2 数据洗牌</h2><p id="3bef" class="pw-post-body-paragraph lg lh it li b lj mx ju ll lm my jx lo lp nu lr ls lt nv lv lw lx nw lz ma mb im bi translated">在 FTS，选择哪部分数据作为验证集并不简单。事实上，有无数的方法可以做到这一点，对于不同波动性的股票指数必须仔细考虑。</p><p id="659c" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">固定原点法是最简单、最常用的方法。给定一定的分割大小，数据的开始是训练集，结束是验证集。然而，这是一个特别基本的选择方法，尤其是对于亚马逊这样的高增长股票。出现这种情况的原因是，亚马逊的股价一开始波动性很低，随着股价的增长，波动性越来越大。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/74eda0e430800e5e94aa361017d4adb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hdYQOK9cydudM_ULGt3XgQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">AMZN 年初至今价格(来源:谷歌财经)</p></figure><p id="3af1" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">因此，我们将训练一个关于低波动动态的模型，并期望它处理未知的高波动动态以进行预测。事实证明，这是很困难的，而且这类股票的表现是有代价的。因此，如果我们只考虑这一点，我们的验证损失和性能基准可能会产生误导。然而，对于像英特尔这样波动性更恒定的股票(COVID 危机前)，这种方法是合理的。</p><p id="3c10" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">滚动原点重新校准方法比固定原点重新校准方法稍不容易受到影响，因为它允许通过取数据的各种不同分割的平均值来计算验证损失，以避免遇到高波动性时间框架的非代表性问题。</p><p id="7c96" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">最后，<strong class="li iu">滚动窗口法</strong>通常是最有用的方法之一，因为它特别适用于长时间运行的 FTS 算法。事实上，该模型输出多个滚动数据窗口的平均验证误差。这意味着我们得到的最终值更能代表最近的模型性能，因为我们不太会因为遥远过去的表现好坏而产生偏差。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/70d7ca8f15896cec536421064f9f9e90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q_ZodeTq4VsluPSA7QK7eg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">洗牌技术可视化(<a class="ae ky" href="https://arxiv.org/abs/1812.07699" rel="noopener ugc nofollow" target="_blank"> Thomas Hollis，Antoine Viscardi，Seung Eun Yi，2018 </a></p></figure><p id="62eb" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">由<a class="ae ky" href="https://arxiv.org/abs/1812.07699" rel="noopener ugc nofollow" target="_blank"> Thomas Hollis、Antoine Viscardi、Seung Eun Yi </a>完成的一项研究表明，滚动窗口(RW)和滚动原点重新校准(ROR)描述了比简单的固定原点方法略微更好的性能(58%和 60%)。这表明，对于像亚马逊这样不稳定的股票，使用这些洗牌方法是不可避免的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/bc28d3b93b38d0753bd63cacd942448f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PPuFVgTOtO3DQbe8n8URaA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">洗牌方法的性能比较</p></figure><h1 id="21d0" class="md me it bd mf mg np mi mj mk nq mm mn jz nr ka mp kc ns kd mr kf nt kg mt mu bi translated">3.时间卷积网络</h1><p id="fa1e" class="pw-post-body-paragraph lg lh it li b lj mx ju ll lm my jx lo lp nu lr ls lt nv lv lw lx nw lz ma mb im bi translated"><strong class="li iu">时间卷积网络</strong>，或简称为 TCN，是一种用于序列建模任务的卷积神经网络，结合了 RNN 和 CNN 架构的各个方面。对 TCNs 的初步经验评估表明，简单的卷积架构在各种任务和数据集上优于 LSTMs 等规范的递归网络，同时表现出更长的有效记忆。</p><p id="c655" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">TCNs 的显著特征是:</p><ol class=""><li id="0608" class="mv mw it li b lj lk lm ln lp nl lt nm lx nn mb nc nd ne nf bi translated">体系结构中的卷积是因果的，这意味着从未来到过去没有信息“泄漏”。</li><li id="3b24" class="mv mw it li b lj ng lm nh lp ni lt nj lx nk mb nc nd ne nf bi translated"><strong class="li iu">该架构可以接受任意长度的序列，并将其映射到相同长度的输出序列，就像 RNN 一样。TCN 使用非常深的网络(用剩余层扩充)和扩张的卷积的组合，拥有非常长的有效历史大小(即，网络查看非常远的过去以做出预测的能力)。</strong></li></ol><h2 id="b7fc" class="od me it bd mf oe of dn mj og oh dp mn lp oi oj mp lt ok ol mr lx om on mt oo bi translated">3.1 模型架构概述</h2><p id="6313" class="pw-post-body-paragraph lg lh it li b lj mx ju ll lm my jx lo lp nu lr ls lt nv lv lw lx nw lz ma mb im bi translated"><strong class="li iu"> 3.1.1 因果卷积</strong></p><p id="8236" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">如上所述，TCN 基于两个原则:网络产生与输入长度相同的输出，以及未来不会泄漏到过去。为了实现第一点，TCN 使用了 1D 全卷积网络(FCN)架构，其中每个隐藏层的长度与输入层相同，长度的零填充(内核大小 1)被添加到<strong class="li iu">以保持后续层与先前层的长度相同</strong>。为了实现第二点，TCN 使用<em class="mc">因果卷积</em>，卷积在时间<em class="mc"> t </em>的输出仅与来自时间<em class="mc"> t </em>和先前层中更早的元素卷积。</p><p id="96f7" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">简单来说:<strong class="li iu"> TCN = 1D FCN +因果卷积。</strong></p><p id="84d7" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu"> 3.1.2 扩张的脑回</strong></p><p id="d1c0" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">一个简单的因果卷积只能回顾网络深度中具有线性大小的历史。这使得将上述因果卷积应用于序列任务具有挑战性，尤其是那些需要较长历史的任务。由白、科特和科尔顿(2020 年  <em class="mc"> ) </em>实施的解决方案是采用扩大的回旋来实现指数级大的感受野。更正式地说，对于一维序列输入 x ∈ Rⁿ和滤波器 f:{0，…，k1 }→r，序列元素 s 上的扩展卷积运算 f 定义为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/b311bc56e586d7d88c3dad3e8ff91730.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gdzEDjS5L4y0JBD_34QjEw.png"/></div></div></figure><p id="8596" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">其中<em class="mc"> d </em>为膨胀因子，<em class="mc"> k </em>为滤波器大小，<em class="mc">s</em>—<em class="mc">d</em><em class="mc">I</em>表示过去的方向。因此，膨胀相当于在每两个相邻的滤波器抽头之间引入一个固定的步长。当<em class="mc"> d </em> = 1 时，一个膨胀的卷积会变成一个规则的卷积。使用更大的扩张使顶层的输出能够代表更大范围的输入，从而有效地扩展了 ConvNet 的感受域。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/ba912179675bdb0df24454657247e20f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4ynb-Xmv0ELQsBhNFozqgg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">膨胀因子 d = 1，2，4 且滤波器大小 k = 3 的膨胀因果卷积。感受野能够覆盖来自输入序列的所有值。</p></figure><p id="a8e4" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu"> 3.1.3 剩余连接</strong></p><p id="ece7" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">残余块有效地允许层学习对身份映射的修改，而不是整个变换，这已被反复证明有益于非常深的网络。</p><p id="d593" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">由于 TCN 的感受野取决于网络深度<em class="mc"> n </em>以及过滤器尺寸<em class="mc"> k </em>和扩张因子<em class="mc"> d </em>，更深更大的 TCN 的稳定变得重要。</p><h2 id="5282" class="od me it bd mf oe of dn mj og oh dp mn lp oi oj mp lt ok ol mr lx om on mt oo bi translated">3.2 利弊</h2><p id="0ffd" class="pw-post-body-paragraph lg lh it li b lj mx ju ll lm my jx lo lp nu lr ls lt nv lv lw lx nw lz ma mb im bi translated">使用 TCN 进行序列建模的几个优点:</p><p id="3567" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">平行度</strong>。不像在 rnn 中，对后面时间步长的预测必须等待它们的前一个完成，卷积可以并行完成，因为在每一层中使用相同的滤波器。因此，在训练和评估中，长输入序列可以在 TCN 中作为一个整体来处理，而不是像在 RNN 中那样按顺序处理。</p><p id="6867" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">灵活的感受野大小。TCN 可以通过多种方式改变其感受野的大小。例如，堆叠更多的膨胀(因果)卷积层，使用更大的膨胀因子，或增加滤波器大小都是可行的选择。因此，TCN 可以更好地控制模型的内存大小，并且易于适应不同的领域。</strong></p><p id="558c" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">稳定梯度</strong>。不同于递归架构，TCN 有一个反向传播路径不同于序列的时间方向。因此，TCN 避免了爆炸/消失梯度的问题，这是 rnn 的一个主要问题(并导致了 LSTM 和 GRU 的发展)。</p><p id="e027" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">训练所需内存低</strong>。尤其是在长输入序列的情况下，LSTMs 和 GRUs 很容易用尽大量存储器来存储其多个单元门的部分结果。然而，在 TCN 中，过滤器跨图层共享，反向传播路径仅取决于网络深度。因此，在实践中，发现门控 rnn 可能比 TCN 使用多数倍的存储器。</p><p id="438b" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">可变长度输入</strong>。就像以递归方式模拟可变长度输入的 RNNs 一样，TCNs 也可以通过滑动 1D 卷积核来接受任意长度的输入。这意味着对于任意长度的顺序数据，TCN 可以作为 rnn 的替代。</p><p id="a875" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">使用 TCN 有两个明显的缺点:</p><p id="f7d2" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">评估期间的数据存储</strong>。TCN 需要接收原始序列直到有效历史长度，因此在评估期间可能需要更多的存储器。</p><p id="0f7c" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">域名转让的潜在参数变化。</strong>不同的领域对模型进行预测所需的历史数据量有不同的要求。因此，当将模型从只需要很少内存的域(即，小的<em class="mc"> k </em>和<em class="mc"> d </em>)转移到需要更长内存的域(即，大得多的<em class="mc"> k </em>和<em class="mc"> d </em>)时，TCN 可能会因为没有足够大的感受野而表现不佳。</p><h2 id="e14d" class="od me it bd mf oe of dn mj og oh dp mn lp oi oj mp lt ok ol mr lx om on mt oo bi translated">3.3 基准</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ow"><img src="../Images/2aa13058d7cde02ed10c9cbf9ef335ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sOYZB16lafm15WamAlIIxw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">对典型序列建模任务的 TCN 和递归架构的评估，这些任务通常用于基准 RNN 变体(<a class="ae ky" href="https://arxiv.org/abs/1803.01271" rel="noopener ugc nofollow" target="_blank"> Bai、Kolter 和 Koltun，2020 </a>)</p></figure><p id="63be" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">执行摘要:</p><p id="7c57" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">结果强烈表明，在广泛的序列建模任务中，具有最小调整的通用 TCN 体系结构<em class="mc">优于规范的递归体系结构</em>，这些任务通常用于测试递归体系结构本身的性能。</p><h1 id="9979" class="md me it bd mf mg np mi mj mk nq mm mn jz nr ka mp kc ns kd mr kf nt kg mt mu bi translated">4.通过 TCN 进行知识驱动的股票趋势预测和解释</h1><h2 id="37f5" class="od me it bd mf oe of dn mj og oh dp mn lp oi oj mp lt ok ol mr lx om on mt oo bi translated"><strong class="ak"> 4.1 背景</strong></h2><p id="abe4" class="pw-post-body-paragraph lg lh it li b lj mx ju ll lm my jx lo lp nu lr ls lt nv lv lw lx nw lz ma mb im bi translated">股票趋势预测中的大多数深度神经网络都有两个共同的缺点:(i) <strong class="li iu">当前的方法对股票趋势的突然变化不够敏感</strong>；以及(ii) <strong class="li iu">预测结果对人类来说不可解释</strong>。为了解决这两个问题，<a class="ae ky" href="https://dl.acm.org/doi/10.1145/3308560.3317701" rel="noopener ugc nofollow" target="_blank">邓等，2019 </a>提出了一种新颖的<em class="mc">知识驱动的时态卷积网络(KDTCN) </em>用于股票趋势预测和解释，通过将背景知识、新闻事件和价格数据融入深度预测模型，解决了股票趋势预测和解释的突变问题。</p><p id="cc67" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">为了解决突变预测问题，从财经新闻中提取事件并结构化为事件元组，如“英国退出欧盟”表示为(<em class="mc">英国</em>、<em class="mc">退出</em>、从、<em class="mc">欧盟</em>)。然后将事件元组中的实体和关系链接到 kg，比如 Freebase 和 Wikidata。其次，将结构化知识、文本新闻以及价格值分别矢量化，然后连接在一起。最后，将这些嵌入内容输入到基于 TCN 的模型中。</p><p id="59b2" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">实验表明，KDTCN 可以(I)更快地对突变做出反应，并在股票数据集上优于最先进的方法，以及(ii)促进对预测的解释，特别是在突变的情况下。</p><p id="2413" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">此外，基于具有突变的预测结果，为了解决做出解释的问题，通过使用知识图(KG)呈现事件之间的联系来可视化事件的影响。通过这样做，我们可以解释(I)知识驱动事件如何在不同层面上影响股票市场波动，以及(ii)知识如何帮助将事件与股票趋势预测中的突变联系起来。</p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="0b4f" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><em class="mc">注下面这一节仅仅概括成一篇论文的大概概述</em> <a class="ae ky" href="https://core.ac.uk/download/pdf/222446995.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="mc">舒敏等人</em> </a> <em class="mc">。，如果你想了解更多的技术细节，可以参考这篇论文。</em></p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h2 id="6d97" class="od me it bd mf oe of dn mj og oh dp mn lp oi oj mp lt ok ol mr lx om on mt oo bi translated"><strong class="ak"> 4.2 模型架构概述</strong></h2><p id="1167" class="pw-post-body-paragraph lg lh it li b lj mx ju ll lm my jx lo lp nu lr ls lt nv lv lw lx nw lz ma mb im bi translated">这里提到的基本 TCN 模型架构源自上面的第 3 节——由因果卷积、剩余连接和扩张卷积组成的通用 TCN 架构。</p><p id="c0fb" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">KDTCN 架构的概述如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/11bcc8d60988de259680883eb7f5ee3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o7-w3dO8t-53kWoBzooOqg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">KDTCN 框架说明</p></figure><p id="26da" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">原始模型输入为<strong class="li iu">价格值<em class="mc">X</em>T15】、<strong class="li iu">新闻文集<em class="mc">N</em>T19】、<strong class="li iu">知识图<em class="mc">G</em>T23】。价格值被标准化并映射到价格向量，表示为</strong></strong></strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/351679e469ca933b524f0bb48f9320fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*lmzaebuHPn2pfrnpR6cmdg.png"/></div></figure><p id="e651" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">其中，每个向量 p <em class="mc"> t </em>代表一个股票交易日的实时价格向量<em class="mc"> t </em>，时间跨度为<em class="mc"> T </em>。</p><p id="134c" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">对于新闻语料，将新闻片段表示为事件集，<em class="mc">ε</em>；然后，结构化为事件元组<strong class="li iu"> <em class="mc"> e </em> = ( <em class="mc"> s </em>，<em class="mc"> p </em>，<em class="mc"> o </em> ) </strong>，其中<strong class="li iu"> <em class="mc"> p </em> </strong>为动作/谓词，<strong class="li iu"> <em class="mc"> s </em> </strong>为动作者/主体，<strong class="li iu"> <em class="mc"> o </em> </strong>为动作所针对的对象；然后，将事件元组中的每一项链接到 KG，对应 KG 中的实体和关系；最后，通过训练事件元组和 KG 三元组获得事件嵌入<em class="mc"> V </em>。更详细的过程记录在<a class="ae ky" href="https://core.ac.uk/download/pdf/222446995.pdf" rel="noopener ugc nofollow" target="_blank">舒敏<em class="mc">等人</em> </a> <em class="mc">中。</em></p><p id="32b4" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">最后，事件嵌入，结合价格向量被输入到一个基于 TCN 的模型。</p><h2 id="488e" class="od me it bd mf oe of dn mj og oh dp mn lp oi oj mp lt ok ol mr lx om on mt oo bi translated"><strong class="ak"> 4.2.1 数据集&amp;基线</strong></h2><p id="4064" class="pw-post-body-paragraph lg lh it li b lj mx ju ll lm my jx lo lp nu lr ls lt nv lv lw lx nw lz ma mb im bi translated"><strong class="li iu">数据集:</strong></p><ol class=""><li id="74db" class="mv mw it li b lj lk lm ln lp nl lt nm lx nn mb nc nd ne nf bi translated"><strong class="li iu">时间序列价格数据<em class="mc">X</em></strong>:<em class="mc"/>DJIA 指数日价值记录的价格数据集</li><li id="84e0" class="mv mw it li b lj ng lm nh lp ni lt nj lx nk mb nc nd ne nf bi translated"><strong class="li iu">文本新闻数据<em class="mc"> N </em> : </strong>由来自 Reddit 世界新闻频道的历史新闻标题组成的新闻数据集(基于投票的前 25 个帖子)。</li><li id="8d8c" class="mv mw it li b lj ng lm nh lp ni lt nj lx nk mb nc nd ne nf bi translated"><strong class="li iu">结构化知识数据<em class="mc"> G </em> : </strong>由两个常用于研究的开放知识图的结构化数据构建的子图——Freebase 和 Wikidata。</li></ol><p id="02ea" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">基线:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/9d634335c9329a871faa9f3dd185cea0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*68Fk0U-CM9Thk5t8gBnpqA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">具有不同输入的基线模型。在第一列中，前缀 WB 表示单词嵌入，EB 表示事件嵌入，PV 表示价格向量，KD 表示知识驱动。注意<strong class="bd pa">事件嵌入(a) </strong>和<strong class="bd pa">事件嵌入(b </strong>分别表示无 KG 和有 KG 的事件嵌入。</p></figure><h2 id="53da" class="od me it bd mf oe of dn mj og oh dp mn lp oi oj mp lt ok ol mr lx om on mt oo bi translated">4.4 预测评估</h2><p id="14a1" class="pw-post-body-paragraph lg lh it li b lj mx ju ll lm my jx lo lp nu lr ls lt nv lv lw lx nw lz ma mb im bi translated">KDTCN 的性能在三个方面进行了基准测试:(I)基本 TCN 架构的评估，(ii)不同模型输入对 TCN 的影响，以及(iii)基于 TCN 的模型对突变的性能。</p><p id="3d64" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">基本 TCN 建筑:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/ffda84ba25f9e421ed459295806e9742.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uBq7Y3BxPEQ-_9OprrFsOw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">用不同的基本预测模型对 DJIA 指数数据集进行股票趋势预测的结果。</p></figure><p id="b9f0" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">请注意，本部分报告的所有实验仅输入<strong class="li iu">价格值</strong>。</p><p id="d37a" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在股票趋势预测任务上，TCN 大大超过了基线模型。TCN 取得了比传统的最大似然模型(ARIMA)或深度神经网络(如 LSTM 和 CNN)更好的性能，表明 TCN 在序列建模和分类问题上具有更明显的优势。</p><p id="1606" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">TCN 的不同型号输入:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/d0fe73e9250f64c12adfa68e3b334274.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TpThjHxDUIUxZ4iX4joXJQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">基于 TCN 模型的不同输入的整个 DJIA 指数数据集的股票趋势预测结果。</p></figure><p id="f1d7" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">正如所见，WB-TCN 和 EB-TCN 都比 TCN 表现更好，表明文本信息<strong class="li iu">有助于提高预测。</strong></p><p id="22f3" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">KDTCN 获得了最高的准确性和 F1 分数，这样的结果证明了模型输入与结构化知识、金融新闻和价格值集成的有效性。</p><p id="2b4b" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">突变的模型性能:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/d5f3c0cb27874cb4094fe4debfdf1c2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*av3j_IHrU1ACgDBq2NLstA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用不同的模型输入，对突然变化的本地 DJIA 指数数据集的股票趋势预测结果。</p></figure><p id="8812" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">据观察，具有知识驱动的事件嵌入输入的模型，如 KDEB-TCN 和 KDTCN，可以大大优于基于数字数据和基于文本数据的模型。这些比较结果表明，知识驱动模型在对股票市场的突然变化做出快速反应方面具有优势。</p><p id="db1e" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">关于如何量化股票波动程度的补充说明如下。</p><p id="99c8" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">首先，通过计算相邻两个股票交易日的股票波动程度 D( <em class="mc">波动)</em>的差异，得到突变的时间间隔</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/7539add5587790d7ad210bcc9a35ecf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*ACxr2y08nbScX7r9bSkBRA.png"/></div></figure><p id="d22e" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">其中在时间<em class="mc"> t </em>的<em class="mc"> x </em>表示股票交易日 t 的股票价格值，那么波动程度之差 C 定义为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/ba51bd2989707139673c92116eced6c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*7rfGXE5z9Oi1J6oEzr_yzA.png"/></div></figure><p id="41a5" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">如果|Ci |超过某个阈值，可以认为股价在第<em class="mc"> i </em>天发生了突变。</p><h2 id="b162" class="od me it bd mf oe of dn mj og oh dp mn lp oi oj mp lt ok ol mr lx om on mt oo bi translated">预测的解释</h2><p id="a81c" class="pw-post-body-paragraph lg lh it li b lj mx ju ll lm my jx lo lp nu lr ls lt nv lv lw lx nw lz ma mb im bi translated">对为什么知识驱动事件是没有 ML 专业知识的人的突变的常见来源的解释在两个方面完成:(i) <strong class="li iu">可视化知识驱动事件</strong>对具有突变的预测结果的影响，以及(ii) <strong class="li iu">通过将事件链接到外部 KG </strong>来检索知识驱动事件的背景事实。</p><p id="7145" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">事件效果可视化:</strong></p><p id="181b" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">下图的预测结果是，DJIA 指数的趋势将会下降。注意，相同颜色的条柱具有相同的事件效果，条柱的高度反映了效果的程度，事件受欢迎程度从左到右递减。直觉上，流行度较高的事件对突变的股票趋势预测应该有较大的影响，但并不总是如此。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/65dcf5ba8c35461261b30d58d043fa2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VuYkkxdpwaELVdVgcQNICQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">事件对股票趋势预测的影响举例</p></figure><p id="f986" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">几乎所有其他具有负面影响的事件都与这两个事件有关，<em class="mc">例如</em>。，(<em class="mc">英镑下跌近 5% </em>)和(<em class="mc">北爱尔兰，呼吁对联合爱尔兰进行投票</em>)。</p><p id="e760" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">虽然也有一些事件对预测股票走势上涨有积极作用，并且具有很高的知名度，<em class="mc">即</em>。，(<em class="mc">富，变得，更富</em>)，总的效果是负的。因此，股票指数波动的突变可以看作是事件的影响和流行的综合结果。</p><p id="c616" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">链接到 KG 的事件元组的可视化:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pf"><img src="../Images/e26fa33b3a77d084fdc6765863b994f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aHcE7Kvn93y3ZFEmV53rtw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">以公斤为单位的三元组与事件关联的图示</p></figure><p id="9abc" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">首先，搜索在股票趋势运动中具有重大影响或高人气的事件元组。然后，回溯到包含这些事件的新闻文本。最后，通过实体链接检索与事件元组链接的相关 KG 三元组。在上图中，每个事件元组都用蓝色标记，其中的实体都链接到 KG。</p><p id="8eef" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这些列出的事件元组，如(<em class="mc">英国，退出，欧盟</em>)、(<em class="mc">英国，投票离开，欧盟</em>)、(<em class="mc">英镑，下跌，近 5% </em>)、(<em class="mc"> J. K .罗琳，带头支持苏格兰独立</em>)和(<em class="mc">北爱尔兰，呼吁对联合王国进行投票</em>)，从字面上看并不是很相关。然而，通过与 KG 的联系，它们可以相互建立关联，并与英国退出欧盟事件和欧盟公投密切相关。通过纳入对事件影响的解释，可以证明知识驱动的事件是突变的常见来源。</p><h1 id="00d9" class="md me it bd mf mg np mi mj mk nq mm mn jz nr ka mp kc ns kd mr kf nt kg mt mu bi translated"><strong class="ak"> 5。结论</strong></h1><p id="c94b" class="pw-post-body-paragraph lg lh it li b lj mx ju ll lm my jx lo lp nu lr ls lt nv lv lw lx nw lz ma mb im bi translated">递归网络在序列建模中享有的优势可能在很大程度上是历史的遗迹。直到最近，在引入扩张卷积和剩余连接等架构元素之前，卷积架构确实比较弱。最近的学术研究表明，有了这些元素，简单的卷积架构在不同的序列建模任务中比 LSTMs 等递归架构更有效。由于 TCNs 的可比较的清晰和简单性，在<a class="ae ky" href="https://arxiv.org/abs/1803.01271" rel="noopener ugc nofollow" target="_blank"> <em class="mc"> Bai，s .、Kolter，j .和 Koltun，v .【2020】</em></a><em class="mc">、</em>中提出<em class="mc"> </em>卷积网络应被视为序列建模的自然起点和强有力的工具包。</p><p id="4109" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">此外，如上文在股票趋势预测中 TCNs 的应用中所见，通过结合新闻事件和知识图，TCNs 可以显著优于规范 RNNs。</p><h1 id="0e52" class="md me it bd mf mg np mi mj mk nq mm mn jz nr ka mp kc ns kd mr kf nt kg mt mu bi translated">引文和参考文献</h1><p id="8c0a" class="pw-post-body-paragraph lg lh it li b lj mx ju ll lm my jx lo lp nu lr ls lt nv lv lw lx nw lz ma mb im bi translated">[1]<a class="ae ky" href="https://arxiv.org/abs/1812.07699" rel="noopener ugc nofollow" target="_blank">t . Hollis，Viscardi，a .和 Yi，S. (2020)。<em class="mc">预测金融时间序列的 Lstms 与注意机制的比较</em>。</a></p><p id="ac27" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">[2] <a class="ae ky" href="https://doi.org/10.1371/journal.pone.0227222" rel="noopener ugc nofollow" target="_blank">邱健，王 B，周 C. (2020)。<em class="mc">基于注意机制的长短期记忆神经网络预测股票价格。</em> </a></p><p id="e570" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">[3] <a class="ae ky" href="https://arxiv.org/abs/1409.0473" rel="noopener ugc nofollow" target="_blank"> Bahdanau、Dzmitry、Kyunghyun Cho 和 Yoshua Bengio。(2020).<em class="mc">“联合学习对齐翻译的神经机器翻译”</em>。</a></p><p id="de47" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">[4] <a class="ae ky" href="https://arxiv.org/abs/1803.01271" rel="noopener ugc nofollow" target="_blank">白，s .，科尔特尔，j .和科尔敦，v .，2020。<em class="mc">用于序列建模的通用卷积和递归网络的经验评估</em>。</a></p><p id="bdbd" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">[6] <a class="ae ky" href="https://dl.acm.org/doi/10.1145/3308560.3317701" rel="noopener ugc nofollow" target="_blank">邓，s，张，n，张，w，陈，j，潘，j，陈，h，2019。<em class="mc">通过时态卷积网络进行知识驱动的股票趋势预测和解释</em>。</a></p><p id="3c45" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">[5] <a class="ae ky" href="https://arxiv.org/abs/2002.12530" rel="noopener ugc nofollow" target="_blank">郝海林，王，夏，杨，赵，沈，等，2020。<em class="mc">时序建模的基于时态卷积注意力的网络</em>。</a></p></div></div>    
</body>
</html>