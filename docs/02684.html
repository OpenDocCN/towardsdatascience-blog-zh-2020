<html>
<head>
<title>Understanding Probability And Statistics: Central Limit Theorem And Convergence For Data Scientists</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解概率和统计:数据科学家的中心极限定理和收敛</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-probability-and-statistics-central-limit-theorem-and-convergence-for-data-scientists-653c53145400?source=collection_archive---------22-----------------------#2020-03-15">https://towardsdatascience.com/understanding-probability-and-statistics-central-limit-theorem-and-convergence-for-data-scientists-653c53145400?source=collection_archive---------22-----------------------#2020-03-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ef05" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">“理解概率和统计”系列的第二篇文章，解释收敛和中心极限定理(CLT)</h2></div><p id="6889" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">数据科学领域围绕着概率和统计。特别是，收敛和中心极限定理(CLT)是每个数据科学家必须熟悉的一些最重要的概念。因此，本文旨在解释什么是随机变量的收敛性，这是一个在数学中大量使用的概念。此外，它提供了中心极限定理的概述。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/7d29ac2510872da46020ecfbbef72946.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fb4hkcowcPKhono_Zzt78w.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">概率与统计</p></figure><p id="df65" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你想从最基本的方面理解概率和统计的概念，请阅读下面的第一篇文章。它解释了概率的本质:</p><div class="lu lv gp gr lw lx"><a rel="noopener follow" target="_blank" href="/understanding-probability-and-statistics-the-essentials-of-probability-for-data-scientists-459d61a8da44"><div class="ly ab fo"><div class="lz ab ma cl cj mb"><h2 class="bd iu gy z fp mc fr fs md fu fw is bi translated">理解概率和统计:数据科学家的概率基础</h2><div class="me l"><h3 class="bd b gy z fp mc fr fs md fu fw dk translated">为统计学家解释概率的关键概念</h3></div><div class="mf l"><p class="bd b dl z fp mc fr fs md fu fw dk translated">towardsdatascience.com</p></div></div><div class="mg l"><div class="mh l mi mj mk mg ml lo lx"/></div></div></a></div><h1 id="b248" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">1.文章目标</h1><p id="faeb" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">本文将概述以下关键部分:</p><ol class=""><li id="a54a" class="nj nk it kk b kl km ko kp kr nl kv nm kz nn ld no np nq nr bi translated">趋同是什么意思？</li><li id="0867" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld no np nq nr bi translated">什么是中心极限定理？</li></ol><p id="0723" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">根据每个人的兴趣，本系列的下一组文章将解释连续随机变量的联合分布以及关键的正态分布，如卡方分布、T分布和F分布。随后，下一篇文章将旨在解释统计和贝叶斯推理的基础，以及马尔可夫链和泊松过程。</p><blockquote class="ny"><p id="cee6" class="nz oa it bd ob oc od oe of og oh ld dk translated"><em class="oi">这些文章的目标是向数据科学家简化概率和统计的概念。</em></p></blockquote><h1 id="b9a4" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz oj ka my kc ok kd na kf ol kg nc nd bi translated">2.趋同是什么意思？</h1><p id="675f" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">收敛的概念是一个非常重要的概念。在我们讨论收敛性之前，让我们先了解一下<em class="nx">极限</em>在数学中的含义。</p><p id="e910" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">数学中的“极限”是什么？</strong></p><p id="6f5e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">考虑这个函数:<em class="nx"> f(x) = /x </em>，其中x为正数。</p><p id="e691" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们取一系列值0 &lt; x ≤ ∞，并开始将它们代入函数f(x ),那么我们将得到以下结果:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi om"><img src="../Images/a73d2de0794a5992e85655f25f563474.png" data-original-src="https://miro.medium.com/v2/resize:fit:268/format:webp/1*5p9IuUPaeiqCjW_esNyNxA.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">显示x的递增值和f(x)的相应值的表格</p></figure><p id="1f23" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以看到，随着x的增大，f(x)减小。它暗示x和f(x)彼此成反比。</p><p id="d5ef" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们将结果绘制成图表来可视化，那么我们会看到它形成了以下形状:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi on"><img src="../Images/770b53bb89b0c7388710e9d18e00db7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*42Ax4t5xTAsJaeFLD82crg.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">显示x和f(x)的图表</p></figure><p id="a31e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以看到，随着x的增加，f(x)越来越接近0，尽管f(x)从未接近0。因此，我们可以得出结论，当x逼近∞时，f(x)的极限为0。</p><p id="807d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当x →∞，极限f(x) = 0。</p><p id="72f4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">此外，y = 0是f(x)的渐近线，因为这条线越来越接近0，但从未穿过0。</p><p id="faf1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是所谓的函数极限。</p><p id="4217" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以把1/n的极限写成:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/a280307e6793308d5b98392f5a83f0b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:224/format:webp/1*HmCsH0zJMFER_lcfXaGNEg.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">当x达到无穷大时，1/x达到0</p></figure><blockquote class="ny"><p id="be20" class="nz oa it bd ob oc op oq or os ot ld dk translated">我们可以注意到f(x)收敛于0</p></blockquote><p id="ee1d" class="pw-post-body-paragraph ki kj it kk b kl ou ju kn ko ov jx kq kr ow kt ku kv ox kx ky kz oy lb lc ld im bi translated">极限在数学中用于简化复杂性。它可以近似一个函数。</p><p id="8546" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">收敛的概念可以用不同的方式来解释，重要的是要理解它的变体。</p><p id="f988" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">假设我们收集了两个随机变量A和b的数据样本，这两个变量可以是任何东西，比如股票的历史价格，甚至运动员训练的时间等等。</p><p id="4c33" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">随机变量的样本具有抽样分布。</p><p id="dc8f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">抽样分布是实际分布的近似值。为了简单起见，我们可以得出结论，随着样本量的增加，我们可以用极限来近似变量的分布。这是要记住的关键！</p><blockquote class="ny"><p id="9b44" class="nz oa it bd ob oc od oe of og oh ld dk translated">收敛的概念可以用样本的潜在概率来解释。</p></blockquote><p id="df5b" class="pw-post-body-paragraph ki kj it kk b kl ou ju kn ko ov jx kq kr ow kt ku kv ox kx ky kz oy lb lc ld im bi translated">要注意的关键是，可以分析随机变量的概率，以评估随机变量是否收敛。</p><h1 id="2872" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">3.什么是中心极限定理？</h1><p id="3053" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">在我解释中心极限定理(CLT)之前，我将试图打下一个坚实的基础，以便我们能容易地理解CLT。</p><p id="bcbd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们也考虑一下，我们想找出变量有多接近？</p><p id="3088" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里的<em class="nx">关闭</em>到底是什么意思？</p><ul class=""><li id="015b" class="nj nk it kk b kl km ko kp kr nl kv nm kz nn ld oz np nq nr bi translated">是指计算两个变量各点的绝对差值吗？</li><li id="961c" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld oz np nq nr bi translated">或者，这是否意味着我们需要计算两个变量的分布，然后计算期望之间的差？</li><li id="3c3c" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld oz np nq nr bi translated">或者，这是否意味着我们需要计算两个变量之间的相关性。</li></ul><p id="8301" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们通过了解大数定律来理解它。</p><h2 id="4088" class="pa mn it bd mo pb pc dn ms pd pe dp mw kr pf pg my kv ph pi na kz pj pk nc pl bi translated">3.1大数定律</h2><p id="457c" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">本节解释了大数的概念。对于数据科学家来说，这是一个重要的概念。</p><p id="969f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个概念很简单，理解起来非常重要。</p><p id="d340" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，记住每个随机变量都有一个期望值(可能是算术平均值)，而且随机变量的每个样本都有其样本平均值。这两个均值可以不同，但它们彼此相关，我们希望样本均值尽可能接近随机变量的期望均值。当我们增加样本量时，我们就更接近预期的平均值。</p><p id="a349" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">简单来说，大数定律表明，随着实验次数的增加，样本的平均值将趋向于随机变量的期望值。</p><p id="1dda" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这给我们带来了大数定律的两个最重要的版本；弱大数定律和强大数定律。</p><p id="31b2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> 3.2弱定律:</strong></p><p id="d324" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">假设我们有一个独立的随机变量序列。在这里，独立性的概念意味着第一个样本不会影响下一个样本，例如多次投掷硬币。</p><p id="0c06" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所有随机变量的平均值是相同的，并且它们的方差≤ v，其中v &lt; ∞。这意味着均值是一个常数，方差有一个上限。</p><p id="5030" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该定律指出，随着样本数量增加到无穷大，样本均值以概率收敛到共同均值。</p><p id="6b40" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> 3.3强定律:</strong></p><p id="d940" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">强大数定律表明，当我们将样本大小增加到无穷大时，样本的期望值以概率1收敛到随机变量的期望值，而不仅仅是收敛到期望值。</p><blockquote class="ny"><p id="1dfb" class="nz oa it bd ob oc od oe of og oh ld dk translated">记住，概率1表示一个事件确实发生了</p></blockquote><p id="f883" class="pw-post-body-paragraph ki kj it kk b kl ou ju kn ko ov jx kq kr ow kt ku kv ox kx ky kz oy lb lc ld im bi translated">因此，强大的大数定律表明，随着试验次数增加到无穷大，变量以概率1收敛到期望值:</p><blockquote class="ny"><p id="9a69" class="nz oa it bd ob oc od oe of og oh ld dk translated"><em class="oi"> P(lim n → ∞ Xₙ =μ) = 1 </em></p></blockquote><p id="52e7" class="pw-post-body-paragraph ki kj it kk b kl ou ju kn ko ov jx kq kr ow kt ku kv ox kx ky kz oy lb lc ld im bi translated">另一方面，弱定律简单地说明概率收敛于一个公共E(X)。</p><h2 id="9d54" class="pa mn it bd mo pb pc dn ms pd pe dp mw kr pf pg my kv ph pi na kz pj pk nc pl bi translated">3.4中心极限定理(CLT)</h2><p id="1172" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">这就把我们带到了文章的核心。</p><p id="1fe9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我将尝试用三个容易理解的要点来解释中心极限定理的概念。这个概念在数据科学项目中大量使用，特别是在我们试图预测变量的项目中。</p><blockquote class="ny"><p id="2d57" class="nz oa it bd ob oc od oe of og oh ld dk translated">事实上，我们很容易将中心极限定理视为概率统计理论中最重要的概念之一。</p></blockquote><p id="b62e" class="pw-post-body-paragraph ki kj it kk b kl ou ju kn ko ov jx kq kr ow kt ku kv ox kx ky kz oy lb lc ld im bi translated"><strong class="kk iu"> 1️⃣ - </strong>要记住的第一点是，两个变量的分布可以收敛。当两个随机变量的分布接近时，那么这些随机变量也可以认为是接近的。这就是所谓的分布趋同。</p><p id="7ae9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果随机变量序列X <em class="nx"> ₙ </em>收敛于分布函数F <em class="nx"> ₙ </em> (x)那么序列分布的极限是:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/f63769ac766de8eb66efc896c7239c13.png" data-original-src="https://miro.medium.com/v2/resize:fit:270/format:webp/1*q0Ft0aQhq62v8FefMXEh5Q.png"/></div></figure><p id="8ba6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我会多解释一点这一要点，因为理解它相当重要。</p><p id="548f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们假设我们取了一个随机变量序列，X1，X2，..，Xn。</p><p id="fea5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们也考虑这些随机变量是相互独立的，并且是同分布的。而且它们的方差是有限的。随着随机变量样本数量的增加(n → ∞),样本总数的分布将收敛到一个共同的分布。</p><p id="f083" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">CLT有助于我们理解这种常见的分布将是正态分布。</p><p id="f931" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们考虑Sn = X1 + X2 + … + Xn。那么Sn的分布将在n * μ附近，方差将在n* μ附近，其数量级为n的平方根</p><p id="6746" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> 2️⃣ </strong> —需要注意的第二点是，中心极限定理都是关于正态分布的。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/0b684cad481f562d75c329d89bd2f1b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*ypmm6qXY50YnH_dzP_3HXA.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">草图显示钟形正态曲线</p></figure><p id="87d2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正态分布是一个需要理解的基本概念。这篇文章解释说:</p><div class="lu lv gp gr lw lx"><a href="https://medium.com/fintechexplained/ever-wondered-why-normal-distribution-is-so-important-110a482abee3" rel="noopener follow" target="_blank"><div class="ly ab fo"><div class="lz ab ma cl cj mb"><h2 class="bd iu gy z fp mc fr fs md fu fw is bi translated">想过为什么正态分布如此重要吗？</h2><div class="me l"><h3 class="bd b gy z fp mc fr fs md fu fw dk translated">解释为什么高斯分布是如此成功和广泛使用的概率分布</h3></div><div class="mf l"><p class="bd b dl z fp mc fr fs md fu fw dk translated">medium.com</p></div></div><div class="mg l"><div class="po l mi mj mk mg ml lo lx"/></div></div></a></div><p id="e35d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">基调指出样本均值的分布是正态的。为了解释这一点，考虑我们进行一项实验并收集一个随机变量的大量观察值。让我们把这些观察作为一个例子来参考。</p><p id="a581" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">随后，我们可以计算样本的平均值。</p><p id="d259" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们重复这个实验很多次，那么我们将开始收集大量的样本。然后，我们可以计算每个样本的平均值，并开始分析样本平均值的分布。</p><p id="459f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们会注意到样本预期平均值的分布将由正态分布近似，这是一个非常重要的概念。</p><p id="5b49" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">需要注意的关键是，随机变量必须相互独立，并且必须同分布。</p><p id="579a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">3️⃣——最后要考虑的一点是，中心极限定理允许我们用正态分布来近似大量的分布。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/9bf5138431835e338b6e3963e901d85b.png" data-original-src="https://miro.medium.com/v2/resize:fit:308/format:webp/1*pwsL2PKi80br3Hosz_fcew.png"/></div></figure><p id="9f23" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上面的公式有助于我们标准化一个随机变量，因为我们实际上是减去平均值，然后用方差除每个样本，此外还考虑了标准误差。</p><p id="fd84" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了进一步解释，如果随机变量存在，并且随机变量的每个序列具有有限的均值μ和方差σ，那么中心极限定理表明，如果我们标准化随机变量以确保均值为0，方差为1，那么当n → ∞时，则分布收敛于正态分布，而不管单个随机变量样本的分布如何。</p><p id="67ab" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">作为例子，这些独立的随机变量可以具有伯努利或泊松分布。它可能是右偏或左偏的，即使这样，随着样本的增加，分布也会收敛到正态。</p><blockquote class="ny"><p id="d51a" class="nz oa it bd ob oc od oe of og oh ld dk translated">我们增加的样本越多，分布就越接近正态分布。</p></blockquote><p id="e91a" class="pw-post-body-paragraph ki kj it kk b kl ou ju kn ko ov jx kq kr ow kt ku kv ox kx ky kz oy lb lc ld im bi translated">一旦我们假设数据呈正态分布，我们就可以开始简化复杂的数据集，并开始近似合理的预测，但需要注意的关键是样本量应该很大(通常&gt; 30)。</p><p id="e563" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是为什么中心极限定理是概率统计学科中的一个中心概念的原因。</p><h1 id="d842" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">3.摘要</h1><p id="ad0b" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">本文解释了什么是随机变量的收敛，并提供了中心极限定理的概述。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/65b4e93fad7c18acda3bcceea0e13117.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZfNp-Liz7cMiJRRSw0V4lw.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">感谢您的阅读</p></figure><p id="fb31" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这两个概念都是数据科学家必须了解的。</p><p id="171f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这一节为本系列的下一篇文章奠定了基础。</p><p id="17e3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">根据每个人的兴趣，本系列的下一组文章将解释连续随机变量的联合分布以及关键的正态分布，如卡方分布、T分布和F分布。随后，本系列的文章将致力于解释统计和贝叶斯推理，以及马尔可夫链和泊松过程。</p></div></div>    
</body>
</html>