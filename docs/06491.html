<html>
<head>
<title>A Tutorial of what Kaggle won’t teach you: Web Scraping, Data Cleaning and more</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一个Kaggle不会教你的教程:网页抓取，数据清理等等</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-tutorial-of-what-kaggle-wont-teach-you-web-scraping-data-cleaning-and-more-16d402a206e8?source=collection_archive---------24-----------------------#2020-05-23">https://towardsdatascience.com/a-tutorial-of-what-kaggle-wont-teach-you-web-scraping-data-cleaning-and-more-16d402a206e8?source=collection_archive---------24-----------------------#2020-05-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8341" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">因为数据科学不仅仅是EDA和培训模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/00cbe32125f169231a46905daecbb0ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cKBWrL5qgeOKB_hoPQ-Tsg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/photos/HpWwEURimK8" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="5eff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Kaggle太棒了。你可以从一个伟大的社区中学到很多东西。你可以与世界上最优秀的数据科学家竞争和比较，这一切都是免费的。然而，Kaggle并不完美。它不会告诉您在导入CSV文件和训练模型之前会发生什么。</p><p id="826c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本教程的目的是填补“真实”项目和Kaggle之间的空白。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="fd3e" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated"><strong class="ak">定义问题</strong></h2><p id="fd9d" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">任何项目(无论是哪个领域)的第一步都是定义问题。你的问题是什么，你想回答什么？问题可能来自你的老板，但是能够创造值得回答的问题不会伤害你。Kaggle一般会给你定义问题(特别是在比赛中)</p><p id="48a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于本教程，假设的问题将是:是什么决定了加拿大魁北克省(我来自那里)每个地区的冠状病毒病例数。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="4592" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">网页抓取和数据清理</h2><p id="0d73" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">一旦有了想要回答的问题，就需要数据来回答。Kaggle为您提供了完美的CSV文件，其中包含您的因变量和所有您需要做出伟大预测的预测器。显然，实际情况通常不是这样。</p><p id="620f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">回到手头的问题，首先需要的是魁北克省每个地区的病例数，即因变量。当然，这不是我在电脑上某个地方存储在CSV文件中的数据，所以我不得不继续从这个网站上收集数据:<a class="ae ky" href="https://www.quebec.ca/en/health/health-issues/a-z/2019-coronavirus/situation-coronavirus-in-quebec/" rel="noopener ugc nofollow" target="_blank">https://www . Quebec . ca/en/health/health-issues/a-z/2019-coronavirus/situation-coronavirus-in-Quebec/</a>。下面是我如何使用Python一步一步完成的。</p><p id="a550" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">导入库之后，首先要做的是使用请求库提取URL的内容:</p><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="74a7" class="mc md it nb b gy nf ng l nh ni"><strong class="nb iu"># Import libraries<br/></strong>from bs4 import BeautifulSoup<br/>import requests<br/>import pandas as pd<br/>import re<br/>from re import findall</span><span id="223d" class="mc md it nb b gy nj ng l nh ni"><strong class="nb iu">#Get URL and extract content<br/></strong>url = requests.get('<a class="ae ky" href="https://www.quebec.ca/sante/problemes-de-sante/a-z/coronavirus-2019/situation-coronavirus-quebec/'" rel="noopener ugc nofollow" target="_blank">https://www.quebec.ca/sante/problemes-de-sante/a-z/coronavirus-2019/situation-coronavirus-quebec/'</a>)</span><span id="10f1" class="mc md it nb b gy nj ng l nh ni">c = url.content</span></pre><p id="358c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦完成，我们就可以使用BeautifulSoup创建一个soup对象，beautiful soup是用于从HTML文件中提取数据的终极Python库。这个美丽的物体是我们将继续工作的对象。</p><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="9a87" class="mc md it nb b gy nf ng l nh ni"><strong class="nb iu"># Create a soup object<br/></strong>soup = BeautifulSoup(c, 'html.parser')</span></pre><p id="76ed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们必须定义我们想要从我们指定的URL中得到什么。通过检查页面(右击，检查)，我们可以看到网站的结构。在那里，通过Ctrl+shift+C，您可以浏览页面，并轻松识别哪个代码块与网站的哪个部分相关。</p><p id="af77" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在下面，我们看到“contenttable”表包含了我们想要收集的信息，即魁北克每个地区冠状病毒病例的数量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/0c399be55e2e13d38dea28af7fc88ccb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4BtaKHCO193IkEcOlSBUQQ.png"/></div></div></figure><p id="0414" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用BeautifulSoup中的find函数，我们可以找到表并导入数据。</p><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="2bf8" class="mc md it nb b gy nf ng l nh ni">my_table = soup.find('table', attrs = {'class': 'contenttable'})</span></pre><p id="1da5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">之后，我们看到所有我们想要的信息都存储在一个<tr>标签中，它定义了HTML表中的一行。</tr></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/5bafbbccc77aee3c27fcb689753c3c45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U6LovqUx4jrYUzWHMEnsSA.png"/></div></div></figure><p id="96b4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过使用find_all和get_text函数，我们可以从我们识别的表中的所有<tr>标签中提取所有文本。</tr></p><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="944c" class="mc md it nb b gy nf ng l nh ni">data=[]<br/>for link in my_table.find_all('tr'):<br/>    data.append(link.get_text())</span><span id="26be" class="mc md it nb b gy nj ng l nh ni">data</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/cb0d6b698ae85ef59ce516f504f1d643.png" data-original-src="https://miro.medium.com/v2/resize:fit:1166/format:webp/1*ztWt9qJfvgU0rm16tBOMQw.png"/></div></figure><p id="345a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果是一个包含所有数据的列表。我们离我们想要的已经很近了，但还不到那个程度。这里有一堆我们不需要的东西。列表中的一些元素是无用的，在每个元素中，都有一些我们不想要的字符/数字。这就是能够清理数据派上用场的地方，这是Kaggle不会教你的另一件事。首先，我将删除列表的前两个和后三个元素，因为这里不需要它们。</p><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="ef66" class="mc md it nb b gy nf ng l nh ni">del data[0:2]<br/>del data[18:21]</span></pre><p id="d9e8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，如果我们仔细观察，我们会发现列表中的每个相关元素都有一个模式。它总是这样:“一个数字-地区+案例”。我们可以对re库使用正则表达式，以便只保留region+cases部分，去掉其余部分。下面是对列表中的所有元素执行此操作的循环。</p><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="4c39" class="mc md it nb b gy nf ng l nh ni">real_data=[]<br/>for i in range(0,18):<br/>    pattern = re.compile('[0-9][0-9] - (.*)')<br/>    result = pattern.findall(data[i])<br/>    real_data.append(result)</span></pre><p id="63f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们仔细看看下面的代码:'[0–9][0–9]—(。*)'.这意味着我们正在寻找一个包含00到99之间的任意数字的模式，一个“-”，最后是我们想要保留的部分(。*).findall函数将在每个元素中寻找这种模式，并返回我们想要保留的部分。</p><p id="24b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们想把这一地区从病例中分离出来。为此，我们只需要两个命令:一个只保存字符，另一个只保存数字。下面的代码就是这样做的，并用输出创建两个列表。</p><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="907e" class="mc md it nb b gy nf ng l nh ni"><strong class="nb iu">#Creating the separate lists<br/></strong>regions=[]<br/>cases=[]<br/>for i in range(0,18):<br/>    strings = ''.join([i for i in real_data[i] if not i.isdigit()])<br/>    no_numbers = ''.join([i for i in strings if not i.isdigit()])<br/>    no_letters = ''.join(filter(lambda x: x.isdigit(), strings))<br/>    regions.append(no_numbers)<br/>    cases.append(no_letters)</span></pre><p id="0071" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，最后，我们可以创建一个以列表为列的数据框架。</p><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="3500" class="mc md it nb b gy nf ng l nh ni"><strong class="nb iu">#Dataframe</strong><br/>df=pd.DataFrame()<br/>df['regions'] = regions<br/>df['cases'] = cases</span><span id="c397" class="mc md it nb b gy nj ng l nh ni">df.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/b4e34cd1c3a2ff101ddb3c68fccef1f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/1*8zvPKIU4iGz8QTxFdg3F3w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据帧的头部</p></figure><p id="ed57" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们有因变量，但我们现在需要预测。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="101c" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">预测器创建</h2><p id="311e" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">在Kaggle上，你将总是被提供你必须用来提出你的预测的预测者。在现实生活中，不仅数据不会给你，而且你也不一定知道哪些预测是有用的。</p><p id="d923" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">回到我们的问题，我们需要弄清楚什么样的变量可以帮助预测每个地区的冠状病毒病例数。有些是显而易见的(人口，测试次数等。)但有时候，你需要跳出框框思考。也许城市中国际机场的存在有助于预测病例数？也许一个地区的教育水平也能说明一些问题？找到哪些预测因素会对你定义的问题产生影响是任何项目的一个重要部分，Kaggle在这方面不会真正帮助你。</p><p id="6b22" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于本教程，我保持简单，按地区刮人口。</p><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="60b3" class="mc md it nb b gy nf ng l nh ni"><strong class="nb iu">#Get URL and extract content</strong><br/>url2 = requests.get('<a class="ae ky" href="https://www.stat.gouv.qc.ca/statistiques/population-demographie/structure/ra-totaux.htm'" rel="noopener ugc nofollow" target="_blank">https://www.stat.gouv.qc.ca/statistiques/population-demographie/structure/ra-totaux.htm'</a>)</span><span id="4a8c" class="mc md it nb b gy nj ng l nh ni">c2 = url2.content</span><span id="4c2a" class="mc md it nb b gy nj ng l nh ni"><strong class="nb iu">#Create soup object<br/></strong>soup2 = BeautifulSoup(c2, 'html.parser')</span><span id="fcb9" class="mc md it nb b gy nj ng l nh ni"><strong class="nb iu">#From table, get only text <br/></strong>my_table2 = soup2.find(id='contenu_table')</span><span id="ece2" class="mc md it nb b gy nj ng l nh ni">data2=[]<br/>for link in my_table2.find_all('td'):<br/>    data2.append(link.get_text())</span><span id="8a2d" class="mc md it nb b gy nj ng l nh ni"><strong class="nb iu">#Only keep elements we need in the list<br/></strong>population = data2[39:232:12]</span><span id="dd1c" class="mc md it nb b gy nj ng l nh ni"><strong class="nb iu">#Add missing region<br/></strong>population.append(str(17141))</span><span id="7120" class="mc md it nb b gy nj ng l nh ni"><strong class="nb iu">#Add population to the dataframe<br/></strong>df['population'] = population</span></pre><p id="5fc5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我定义population时，我使用了“data2[39:232:12]”，因为所需的信息出现在data2列表的第12个元素中，从第39个元素开始。另一个清理数据的酷招！另外，一个地区的人口，Terre-kress de la Baie-James，没有列在我搜集的网站上，所以我手动将其添加到人口列表中，正如你在上面看到的。</p><p id="89ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当然，在实践中，需要更多的预测器。对于本教程，我将到此为止。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="50f9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Kaggle很牛逼。你应该尽可能多的花时间在这上面。然而，它不会教会你成为最好的数据科学家所需要知道的一切。</p><p id="7076" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">非常感谢你的阅读！</p></div></div>    
</body>
</html>