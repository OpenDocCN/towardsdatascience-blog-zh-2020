<html>
<head>
<title>Text To Speech with Tacotron-2 and FastSpeech using ESPnet.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Tacotron-2 进行文本到语音转换，使用 ESPnet 进行快速语音转换。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/text-to-speech-with-tacotron-2-and-fastspeech-using-espnet-3a711131e0fa?source=collection_archive---------20-----------------------#2020-09-02">https://towardsdatascience.com/text-to-speech-with-tacotron-2-and-fastspeech-using-espnet-3a711131e0fa?source=collection_archive---------20-----------------------#2020-09-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9638" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">端到端神经文本到语音的初学者指南..</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/e1daad0f6513a1ee46886b8086610a78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jgq2Pn0MslfymMtc"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">迈克尔·马森在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="32d7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">顾名思义，文本到语音(TTS)朗读文本。它将书面文字作为输入，并将其转换为音频。TTS 可以帮助那些不想花力气去阅读一本书、博客或文章的人。在本文中，我们将看到如何在我们对 TTS 一无所知的情况下创建一个 TTS 引擎。</p><h1 id="88bd" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">文本到语音体系结构</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mn"><img src="../Images/1f52a8ae45a3b656ab4410678be4eca2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uOt4ctzySgVxe0BuM8I72w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我们的 TTS 架构</p></figure><p id="de39" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上图是我们将要遵循的架构的简单表示。我们将详细研究每一个组件，我们将使用<a class="ae ky" href="https://github.com/espnet/espnet" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> ESPnet </strong> </a>框架来实现目的。</p><h2 id="d51e" class="mo lw it bd lx mp mq dn mb mr ms dp mf li mt mu mh lm mv mw mj lq mx my ml mz bi translated">前端</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/d3de15a6fa4164096d851201c7e2ba1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*VckdA-0MUyNMFnDpRl3KAg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我们的前端。</p></figure><p id="cd7f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它主要有三个组成部分:</p><ol class=""><li id="f2d8" class="nb nc it lb b lc ld lf lg li nd lm ne lq nf lu ng nh ni nj bi translated"><strong class="lb iu">词性标注器:</strong>对输入文本进行词性标注。</li><li id="8899" class="nb nc it lb b lc nk lf nl li nm lm nn lq no lu ng nh ni nj bi translated"><strong class="lb iu">分词:</strong>将句子分词。</li><li id="d299" class="nb nc it lb b lc nk lf nl li nm lm nn lq no lu ng nh ni nj bi translated"><strong class="lb iu">发音:</strong>根据发音将输入文本分解成音素。例如你好，你好→ HH AH0 L OW，HH AW1 AA1 R Y UW1。这是通过一个字素到音素的转换器来完成的，在这种情况下，我们使用一个神经预训练的<a class="ae ky" href="https://github.com/Kyubyong/g2p" rel="noopener ugc nofollow" target="_blank"> G2P(字素到音素)模型</a>。该模型旨在将英语字素(拼写)转换为音素(发音)。为了简单地说明这个 G2P 模型的工作，我们可以说，如果我们想知道某个单词的发音，它会查阅字典，如果该单词没有存储在字典中，它会使用基于 TensorFlow 的 seq2seq 模型来预测音素。</li></ol><h2 id="9b14" class="mo lw it bd lx mp mq dn mb mr ms dp mf li mt mu mh lm mv mw mj lq mx my ml mz bi translated">序列到序列回归器:</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/dea4fdd42bccd4318975e5d63cc03983.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yEs_H8efenNXR9X7ObXAug.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">序列-2-序列回归器。</p></figure><p id="4f97" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用预先训练的 seq-to-seq 回归器，它输入语言特征(音素)并输出声学特征(Mel-spectrogram)。在这里，我们将使用 Tacotron-2(谷歌的)和 Fastspeech(脸书的)进行操作。因此，让我们快速了解一下这两种情况:</p><h2 id="a694" class="mo lw it bd lx mp mq dn mb mr ms dp mf li mt mu mh lm mv mw mj lq mx my ml mz bi translated">Tacotron-2</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/6773811e776dad06de11a73a644d2b26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lh2VPtnPelIl_n3wBAvFJw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Tacotron-2 架构。图片<a class="ae ky" href="https://ai.googleblog.com/2017/12/tacotron-2-generating-human-like-speech.html" rel="noopener ugc nofollow" target="_blank">来源</a>。</p></figure><p id="462d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://ai.googleblog.com/2017/12/tacotron-2-generating-human-like-speech.html" rel="noopener ugc nofollow" target="_blank"> Tacotron </a>是一个人工智能驱动的语音合成系统，可以将文本转换为语音。Tacotron 2 的神经网络架构直接从文本中合成语音。它基于卷积神经网络(CNN)和递归神经网络(RNN)的组合来工作。</p><h2 id="30a6" class="mo lw it bd lx mp mq dn mb mr ms dp mf li mt mu mh lm mv mw mj lq mx my ml mz bi translated">快速演讲</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/21bdd612722334b1fb3691e109e83547.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bsKfId8FiwAKnou7q3zniA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">FastSpeech 的整体架构。(a)前馈变压器。(b)前馈变压器块。长度调节器。持续时间预测值。MSE 损失表示预测持续时间和提取持续时间之间的损失，它只存在于训练过程中。图片<a class="ae ky" href="https://www.microsoft.com/en-us/research/blog/fastspeech-new-text-to-speech-model-improves-on-speed-accuracy-and-controllability/" rel="noopener ugc nofollow" target="_blank">来源</a>。</p></figure><p id="df5d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> (a)、(b)前馈变压器:</strong></p><p id="913d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://www.microsoft.com/en-us/research/blog/fastspeech-new-text-to-speech-model-improves-on-speed-accuracy-and-controllability/" rel="noopener ugc nofollow" target="_blank"> FastSpeech </a>采用了新颖的前馈变压器结构，抛弃了常规的编码器-注意力-解码器框架，如上图所示。前馈变压器的主要组件是前馈变压器模块(FFT 模块，如图(b)所示)，由自关注和 1D 卷积组成。FFT 块用于从音素序列到 mel 谱图序列的转换，在音素侧和 mel 谱图侧分别有<em class="ns"> N </em>个堆叠块。独特的是，在它们之间有一个长度调节器，用于桥接音素和 Mel-频谱图序列之间的长度不匹配。(注意:音素是语音的微小而独特的声音。)</p><p id="6adc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> (c)长度调节器:</strong></p><p id="4801" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该型号的长度调节器如上图所示。由于音素序列的长度小于 mel 谱图序列的长度，所以一个音素对应于几个 mel 谱图。对准一个音素的 mel 频谱图的数量被称为<em class="ns">音素持续时间</em>。长度调节器根据持续时间扩展隐藏的音素序列，以便匹配 mel 谱图序列的长度。我们可以按比例增加或减少音素持续时间来调整语速，也可以改变空白标记的持续时间来调整单词之间的间隔，以便控制部分韵律。</p><p id="0843" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> (d)持续时间预测值:</strong></p><p id="2fc1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">持续时间预测器对于长度调节器能够确定每个音素的持续时间非常关键。如上图所示，持续时间预测器由两层 1D 卷积和一个线性层组成，用于预测持续时间。持续时间预测器堆叠在音素侧的 FFT 块上，并且通过均方误差(MSE)损失函数与 FastSpeech 联合训练。音素持续时间的标签是从自回归教师模型中编码器和解码器之间的注意力对准中提取的。</p><h2 id="a73a" class="mo lw it bd lx mp mq dn mb mr ms dp mf li mt mu mh lm mv mw mj lq mx my ml mz bi translated">波形发生器/声码器:</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/ff0f8733387241ee73cf58749f7e979d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_Bo-eFuG1KOGz_Rytqeo6Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">声码器</p></figure><p id="71e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用预先训练的序列到序列模型，该模型输入声学特征(Mel 频谱图)并输出波形(音频)。这里我们将使用并行 WaveGAN 声码器。这里一个<a class="ae ky" href="https://en.wikipedia.org/wiki/Generative_adversarial_network" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">生成对抗网络</strong> ( <strong class="lb iu">【甘)</strong> </a>架构用于从 Mel-spectrograms 生成波形，关于这个架构的更多信息可以在<a class="ae ky" href="https://arxiv.org/pdf/1910.11480.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h2 id="5a10" class="mo lw it bd lx mp mq dn mb mr ms dp mf li mt mu mh lm mv mw mj lq mx my ml mz bi translated">履行</h2><p id="1400" class="pw-post-body-paragraph kz la it lb b lc nu ju le lf nv jx lh li nw lk ll lm nx lo lp lq ny ls lt lu im bi translated">我们已经使用<a class="ae ky" href="https://github.com/espnet/espnet" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">ESPnet</strong></a><strong class="lb iu"/>框架实现了上述架构。它提供了一个惊人的结构来轻松实现上述所有预训练的模型，并集成它们。这是完整的文本到语音转换实现的笔记本。</p><h1 id="c878" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="dfeb" class="pw-post-body-paragraph kz la it lb b lc nu ju le lf nv jx lh li nw lk ll lm nx lo lp lq ny ls lt lu im bi translated">我们使用 Tacotron-2、Fastspeech、Parallel WaveGAN 等各种预训练模型实现了一个神经 TTS 系统。我们可以进一步尝试其他可能产生更好结果的模型。</p><h1 id="96ee" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">参考</h1><ol class=""><li id="07fa" class="nb nc it lb b lc nu lf nv li nz lm oa lq ob lu ng nh ni nj bi translated"><a class="ae ky" href="https://github.com/kan-bayashi/ParallelWaveGAN" rel="noopener ugc nofollow" target="_blank">https://github.com/kan-bayashi/ParallelWaveGAN</a></li><li id="0e77" class="nb nc it lb b lc nk lf nl li nm lm nn lq no lu ng nh ni nj bi translated"><a class="ae ky" href="https://github.com/espnet/espnet" rel="noopener ugc nofollow" target="_blank">https://github.com/espnet/espnet</a></li><li id="a18e" class="nb nc it lb b lc nk lf nl li nm lm nn lq no lu ng nh ni nj bi translated"><a class="ae ky" href="https://www.microsoft.com/en-us/research/blog/fastspeech-new-text-to-speech-model-improves-on-speed-accuracy-and-controllability/" rel="noopener ugc nofollow" target="_blank">https://www . Microsoft . com/en-us/research/blog/fast speech-new-text-to-speech-model-improves-on-speed-accuracy-and-control ability/</a></li><li id="c5d7" class="nb nc it lb b lc nk lf nl li nm lm nn lq no lu ng nh ni nj bi translated"><a class="ae ky" href="https://ai.googleblog.com/2017/12/tacotron-2-generating-human-like-speech.html" rel="noopener ugc nofollow" target="_blank">https://ai . Google blog . com/2017/12/taco tron-2-generating-human-like-speech . html</a></li><li id="1efd" class="nb nc it lb b lc nk lf nl li nm lm nn lq no lu ng nh ni nj bi translated"><a class="ae ky" href="http://media.speech.zone/images/Interspeech2017_tutorial_Merlin_for_publication_watermarked_compressed_v2.pdf" rel="noopener ugc nofollow" target="_blank">http://media . speech . zone/images/interspeech 2017 _ tutorial _ Merlin _ for _ publication _ watered _ compressed _ v2 . pdf</a></li><li id="24da" class="nb nc it lb b lc nk lf nl li nm lm nn lq no lu ng nh ni nj bi translated">https://arxiv.org/pdf/1910.11480.pdf<a class="ae ky" href="https://arxiv.org/pdf/1910.11480.pdf" rel="noopener ugc nofollow" target="_blank"/></li></ol></div></div>    
</body>
</html>