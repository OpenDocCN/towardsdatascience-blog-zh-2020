<html>
<head>
<title>Understanding Fast R-CNN and Faster R-CNN for Object Detection.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解快速 R-CNN 和用于目标检测的更快 R-CNN。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-fast-r-cnn-and-faster-r-cnn-for-object-detection-adbb55653d97?source=collection_archive---------9-----------------------#2020-07-13">https://towardsdatascience.com/understanding-fast-r-cnn-and-faster-r-cnn-for-object-detection-adbb55653d97?source=collection_archive---------9-----------------------#2020-07-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="73f1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">让我们详细了解这些基于区域提议的卷积神经网络的最新技术。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/bfc402649ee3c3657b5f8c44ac3695dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*HA4fO717R3xPj2PHfiszCA.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用 Canva 设计</p></figure><p id="f83e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我在上一篇文章中已经详细讨论了对象检测和 R-CNN。你可以在这里阅读<a class="ae lu" rel="noopener" target="_blank" href="/understanding-object-detection-and-r-cnn-e39c16f37600">以获得更好的直觉。</a></p><p id="3f73" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">人们需要了解这些用于对象检测的最先进的模型，这些模型随着时间的推移而发展，现在被认为是当今更强大的网络的强大基础。</p><p id="5480" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们进入主题。</p><p id="0f7b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，使用 R-CNN 版本进行对象检测存在一些缺点。它们是:</p><ol class=""><li id="408d" class="lv lw it la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated">它消耗大量的时间、存储和计算能力。</li><li id="70ea" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">它有一个复杂的多阶段训练管道(3 个阶段——对数损失、SVM 和 BBox 回归器的 L2 损失)。</li></ol><p id="c279" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在 R-CNN 一年后开发的<strong class="la iu">快速 R-CNN </strong>，非常有效地解决了这些问题，在测试时间内比<strong class="la iu"> R-CNN </strong>快<strong class="la iu"> 146 倍</strong>。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="0ff8" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">快速 R-CNN</h1><p id="11f5" class="pw-post-body-paragraph ky kz it la b lb ni ju ld le nj jx lg lh nk lj lk ll nl ln lo lp nm lr ls lt im bi translated">R-CNN 中使用的选择性搜索为每个图像生成大约 2000 个区域提议，并且每个区域提议被馈送到基础网络架构。这意味着，对于单个图像，将有 2000 次向前传递。考虑用 1000 幅图像的数据集来训练网络。那将是 2M 总共<strong class="la iu"/>(2000 * 1000)次向前传球<strong class="la iu">这是巨大的！</strong></p><p id="1bf2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以，快速 R-CNN 是基于一个想法，</p><blockquote class="nn no np"><p id="353f" class="ky kz nq la b lb lc ju ld le lf jx lg nr li lj lk ns lm ln lo nt lq lr ls lt im bi translated">为什么不考虑每张图片运行一次 CNN，然后找到一种方法在 2000 个提案中共享计算结果？</p></blockquote><p id="fee8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在快速 R-CNN 中，图像只被传送到底层 CNN 一次，而选择性搜索则照常运行。然后，通过选择性搜索生成的这些区域提议被投影到由 CNN 生成的特征地图上。这个过程叫做<strong class="la iu"> ROI 投影</strong>(感兴趣区域)。</p><p id="5878" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在开始 ROI 投影之前，需要了解一下<strong class="la iu">子采样率</strong>。<strong class="la iu"> </strong>它是特征图尺寸与图像原始尺寸的比值。举个例子，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/c37e428c08ddae8415974a1ffa102dd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vvnku0ErKUjfHUZdk-vqUg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用 Canva 设计</p></figure></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><p id="e681" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">ROI 投影的思想是我们从 ROI 提议中获得边界框的坐标，并且我们需要通过相对于二次采样比率投影 ROI 提议来将它们投影到特征图上。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/627315337322c4274b6e53c12515e827.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nMiuyTeq-mGgM4m0KgzFIQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用 Canva 设计</p></figure><p id="3cc0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">上图看起来有点复杂，但事实并非如此。考虑一个大小为 688 x 920 的图像被传送到 CNN，CNN 的二次采样率是 T2 的 1/16。所得到的特征图的大小导致了<strong class="la iu">43×58</strong>(<strong class="la iu">688/16</strong>x<strong class="la iu">920/16</strong>)。类似地，ROI 提议的大小<strong class="la iu">320×128</strong>，在二次采样之后导致<strong class="la iu">20×8</strong>。通常，边界框的坐标以两种方式表示。</p><ol class=""><li id="d1a4" class="lv lw it la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated">盒子中点的坐标(X，Y)，宽度，高度。[X，Y，W，H]</li><li id="3f68" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">边界框的对边坐标。[X1，Y1，X2，Y2]</li></ol><p id="0e23" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里，我们考虑第一个符号。从图中可以看出，ROI 建议的中点是<strong class="la iu"> (340，450) </strong>，这导致了特征图中的<strong class="la iu"> (21，28) </strong>。以这种方式，ROI 提议被投影到特征图上。</p><p id="e3c9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在网络中使用固定大小的图像的主要原因是因为完全连接的层。这些期望固定大小的向量，因为分配了固定的权重。这是网络不接受可变尺寸图像的主要原因。为了解决这个问题，Fast R-CNN 的作者想出了一个想法<strong class="la iu"> ROI Pooling </strong>其中特征图上的 ROI 投影被分成固定的维度。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/de1da12e7083db1a721bb775aeb6d669.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*5vzG18aSqBoelD9q__y1rw.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用 Canva 设计</p></figure><p id="060d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如上所示，将红框视为 8 x 8 特征图上的 ROI 投影。假设我们需要一个 2×2 尺寸的输出。那么如果有奇数个维度，就不可能将它们等分。在这种情况下，我们将四舍五入到最接近的值。如图所示，假设我们得到一个<strong class="la iu"> 5 x 4 </strong>大小的提案。为了将其转换成固定尺寸的盒子，我们将高度和宽度除以所需的高度和宽度，即 5/2×4/2 = 2.5×2。对它们取整，任何一种方法都给出<strong class="la iu"> 2 x 2 </strong>和<strong class="la iu"> 3 x 2 </strong>。然后对每个块进行最大池化，并计算输出。这样，对于任何大小可变的区域建议，我们都可以获得固定维度的输出。所以现在，输入的大小没有限制。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/7655d7a81281b59ea4d145217e5659a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/1*9VYRKpNPW_eDP4DGt5WxzA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用 Canva 设计</p></figure><p id="c5af" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因为还涉及到第三个维度，即特征地图中的深度，你可以这样想象，就像在一副卡片上戳一个洞。如上所述，您必须以相同的方式将 ROI Pool 应用于每个切片。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/10d8574abce0f5df7ce3526e9380277d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*24Wt9x4yMQJhQSSEhc2vtg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用 Canva 设计</p></figure><p id="418c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在 Fast R-CNN 中，我们使用一个 7 x 7 的网格进行池化。我们还去掉了最后一个池层。ROI 合并应用于最后一个卷积层的特征图。上面的例子是针对 AlexNet 架构的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/66c5681f2bbf5a649408a82afc48f3ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L-RItcTDliYSFT6YMf3-ww.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用 Canva 设计</p></figure><p id="8d0d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">RCNN 的变化是，他们已经摆脱了 SVM 分类器，而是使用 Softmax。用于 Bbox 的损失函数是平滑 L1 损失。快速 RCNN 的结果是速度的指数增长。在准确性方面，没有太大的改进。这种架构在 PASCAL VOC 07 数据集上的准确率为<strong class="la iu"> 66.9% </strong>。这里的总损失是分类损失和回归损失的总和，并且网络用单个损失反向传播，由此我们可以摆脱多阶段训练问题。</p><h2 id="8d46" class="nx mr it bd ms ny nz dn mw oa ob dp na lh oc od nc ll oe of ne lp og oh ng oi bi translated">结果:</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/52deca53f0972a0f8eae2b22a1a8604e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1NgXOI455imo2QqJco4KWA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用 Canva 设计</p></figure></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="0c5f" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">更快的 R-CNN</h1><p id="6d22" class="pw-post-body-paragraph ky kz it la b lb ni ju ld le nj jx lg lh nk lj lk ll nl ln lo lp nm lr ls lt im bi translated">即使有了所有这些进步，在快速 R-CNN 过程中仍然存在一个剩余的瓶颈，即区域提议器。众所周知，检测物体的第一步是在物体周围生成一组潜在的包围盒。在快速 R-CNN 中，使用<strong class="la iu">选择性搜索</strong>创建区域提议，发现一个相当慢的过程是整个对象检测过程的瓶颈。</p><p id="8ac5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，我们需要一种更好的技术，它给出少于 2000 个区域建议，比选择性搜索更快，与选择性搜索一样准确或更好，并且应该能够提出具有不同纵横比和比例的重叠 ROI。</p><p id="99ee" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从快速 R-CNN，我们知道区域提议依赖于已经用 CNN 的前向传递计算的图像的特征。</p><blockquote class="nn no np"><p id="25a4" class="ky kz nq la b lb lc ju ld le lf jx lg nr li lj lk ns lm ln lo nt lq lr ls lt im bi translated"><strong class="la iu">那么，我们为什么不将 CNN 的结果重新用于地区提案，而不是运行一个单独的选择性搜索算法呢？</strong></p></blockquote><p id="9ac1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">首先，让我们了解不同纵横比和比例的重叠 ROI 的概念。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/fcf7488c33fc964d6ec4522c9e14d051.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EadpquoMbzXrZ-x9VFiPRQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用 Canva 设计</p></figure><p id="8812" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从图像中，我们看到许多物体相互重叠。我们看到一辆汽车，一辆自行车，一个人拿着一台电视机，电视机里还有一只狗。选择性搜索可以解决这个问题，但我们最终会得到大量的 ROI。我们需要想出一个能有效解决这个问题的主意。</p><p id="848a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果我们在不同的物体周围画边界框，它看起来是这样的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/f431e32861e03701e7457735064b8c10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0qgBAeatuvc5_KnhZb2V4A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用 Canva 设计</p></figure><p id="eb8d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">实现这个有点复杂，但是锚盒的想法让它变得简单。我们来了解一下这些锚盒是什么意思。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><p id="d309" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一般来说，对象可以放在正方形的盒子里，也可以放在长方形的盒子里，或者放在长方形的盒子里。概括地说，他们可以说是大，小，或中等大小。因此，通过实验发现，使用 3 种不同比例和 3 种不同纵横比的盒子可以检测到图像中的任何对象。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/117e03ca9786b00d56cee4419ad92ea7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m2AWrKCsiOLgi6dF82dZug.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用 Canva 设计</p></figure><p id="2282" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果我们考虑上面的重叠图像，很有可能组合所有这些框，如上所示，会给你所有的重叠建议，但不是很准确。物体的主要部分将被覆盖。这可能是一种可以用来解决我们替换区域提议者的目的的技术。我们可以考虑一些替代方案，例如:</p><p id="ffbd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">1.移除选择性搜索并在特征地图上应用滑动窗口。但有了这个，我们就能检测到大多数单一尺度的物体。</p><p id="243d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">2.为了处理多种尺度，我们必须在输入端使用影像金字塔。但是使用 5 种不同比例的图像(几乎每个物体都可以被检测到)会使网络变慢 4 倍。</p><p id="2bac" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">3.另一种选择是在特征图上使用不同大小的滑动窗口(如上图所示，9 个)。这个概念被称为特征金字塔。这包括在特征地图上使用 9 个不同大小的滑动窗口。</p><p id="8262" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是对于一个 600x1000 的图像，我们会有一个大约 40x60 的特征图。并且在每个位置使用 9 个不同的滑动窗口，对于特征图中的所有 40x60 值，我们最终得到 40x60x9 =~20，000 个建议。与仅提供 2000 个建议的选择性搜索相比，我们的建议几乎多了 10 倍。这将在计算上更加昂贵，并且还会有更多的误报。</p><p id="2377" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">4.考虑使用简单的 CNN BBox 回归器来代替选择性搜索，以获得图像的近似区域建议，该区域建议可以进一步馈送到底层的快速 R-CNN 架构。这是更快的 R-CNN 背后的核心思想。让我们再深入一点。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/a8b87eb1a476a0db58168cf1696881d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_tacDZU3ZsJXeq3E6LwboQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用 Canva 设计</p></figure><p id="c0ad" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个为我们提供近似 ROI 的网络被称为<strong class="la iu">区域建议网络(RPN) </strong>。那么，我们如何设计这种 RPN，使其能够给出可以进一步处理的近似 ROI 呢？</p><p id="889f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里的想法是我们利用上面讨论的 9 个盒子。这些被称为<strong class="la iu">锚盒</strong>或参考盒。在图像上的任何一点，我们都会得到大约 9 个不同比例和长宽比的不同边界框。</p><p id="d152" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在特征图上使用大小为 3×3 的滑动窗口，并且在每个滑动窗口的顶部，我们将这 9 个框放置在中心，以检测各个窗口中存在的任何对象。让我们放大 RPN。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/a2fa133f571480f18e204b898ea23685.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3IzBHtAw_GbDc2TRqbJp6Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用 Canva 设计</p></figure><p id="fb50" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这就是我们如何从图像的所有区域得到不同的区域建议。9x 代表，该部分在 9 个不同的锚中重复 9 次。由此，我们得到所需的 ROI。但这里的问题是，我们又一次得到了大量的提议。</p><p id="321f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">考虑同样的 40x60 特征地图的例子，我们再次避开<strong class="la iu"> 20K </strong>建议(40 x 60 x 9)。这些盒子中最多有一个没有任何对象，这样的盒子应该被删除。为此，我们使用一个<strong class="la iu">二元分类器</strong>来预测盒子是否包含前景或任何背景。这样，所有包含背景的盒子都被去掉了。我们假设大概有 15K 的背景盒。我们还剩下 5000 多个盒子。由于分类在最后包括 max 层的 S <strong class="la iu">，我们得到每个框的置信度得分，指示该框内存在对象的概率。通过这种方式，我们可以根据置信度得分对盒子进行排序，并将前 n 个提议用作 ROI。n 可以相应地调整。</strong></p><p id="d211" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">此外，请注意，由于我们在 RPN 中不使用 ROI 池层，我们在那里使用卷积运算，其作用类似于滑动窗口，这里的 FC 层由卷积运算代替，类似于 R-CNN 的前身 Overfeat 的卷积运算。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/b090d229c043e4b4b90da91d84e91d53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bmF6QF60To5FnyYLpYz5oQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用 Canva 设计</p></figure><p id="eb94" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，首先用一个 3×3 的窗口或过滤器对特征图进行卷积，这为我们提供了所需的锚点，然后对每个分类和回归部分进行 1×1 卷积。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/d61840c3e3c62e3ab0ade5c6b8443a09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*63m9zLLtcWymZDZC6KCNAw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用 Canva 设计</p></figure><p id="6ee8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">总的来说，这是更快的 R-CNN 的架构。</p><p id="a5a6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">更快的 R-CNN 是用 4 个损耗联合训练的:</p><ol class=""><li id="3bd0" class="lv lw it la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated">RPN 分类(对象前景/背景)</li><li id="a4c5" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">RPN 回归(锚点→ ROI)</li><li id="e56f" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">快速 RCNN 分类(对象类)。</li><li id="f0fc" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">快速 RCNN 回归(ROI →边界框)</li></ol><h2 id="b747" class="nx mr it bd ms ny nz dn mw oa ob dp na lh oc od nc ll oe of ne lp og oh ng oi bi translated">结果:</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/3ae59441c164501a63757af987ea6e05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rrEs65GQX1A7h01hCXjCNA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用 Canva 设计</p></figure><h1 id="0124" class="mq mr it bd ms mt ol mv mw mx om mz na jz on ka nc kc oo kd ne kf op kg ng nh bi translated">结论</h1><p id="be5d" class="pw-post-body-paragraph ky kz it la b lb ni ju ld le nj jx lg lh nk lj lk ll nl ln lo lp nm lr ls lt im bi translated">希望这能理清你对越来越快 R-CNN 的理解。在 2015 年 12 月，<strong class="la iu">更快的 RCNN </strong>与主干网络 as <strong class="la iu"> ResNet -101 </strong>一起赢得了<strong class="la iu"> COCO 物体检测竞赛</strong>，被认为是迄今为止最先进的物体检测模型。希望你今天学到了新东西！我将在接下来的文章中讨论更多关于 Mask R-CNN 和 Detectron2 的内容。</p><p id="fafb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你想取得联系，请在<a class="ae lu" href="https://www.linkedin.com/in/aakarsh-yelisetty-6b691b171/" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu"> LinkedIn </strong> </a>上联系我。</p><p id="9f7d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你想了解更多关于交叉熵的知识，你可以在这里阅读我以前的文章。</p><h1 id="79d8" class="mq mr it bd ms mt ol mv mw mx om mz na jz on ka nc kc oo kd ne kf op kg ng nh bi translated">参考</h1><ol class=""><li id="73d3" class="lv lw it la b lb ni le nj lh oq ll or lp os lt ma mb mc md bi translated"><a class="ae lu" href="https://arxiv.org/pdf/1506.01497.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1506.01497.pdf</a></li><li id="cf2a" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated"><a class="ae lu" href="https://arxiv.org/pdf/1504.08083.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1504.08083.pdf</a></li><li id="0c7c" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated"><a class="ae lu" href="http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture11.pdf" rel="noopener ugc nofollow" target="_blank">http://cs 231n . Stanford . edu/slides/2017/cs 231n _ 2017 _ lecture 11 . pdf</a></li></ol></div></div>    
</body>
</html>