<html>
<head>
<title>Magic Of Calculus: Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">微积分的魔力:线性回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/magic-of-calculus-linear-regression-ad84686371c3?source=collection_archive---------47-----------------------#2020-07-08">https://towardsdatascience.com/magic-of-calculus-linear-regression-ad84686371c3?source=collection_archive---------47-----------------------#2020-07-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/bc7c6dff927bc1660f72bbd118aaaf74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9tAqPEooTx2aC00RbIOrMw.png"/></div></div></figure><p id="7a29" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi kz translated">人类行为拥有异常丰富的知识和技术储备。我们正试图从人脑中了解和产生尽可能多的东西。我觉得操纵人脑的一个突破是数据科学。数据科学是一个故事，是人类大脑、机器和直觉的进化。</p><p id="384a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">为了开始这个故事，数据科学家所做的是用数学的基础来描绘猜测的行为。最基础的代数是从线性代数开始的，所以机器学习最基础的发电站就变成了线性回归。</p><p id="fd42" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在这篇文章中，我们将看到线性回归的基本直觉和发展，以及今天我们如何使用线性回归。当我阅读时，我发现它非常有趣，我相信你也会如此。</p><h1 id="03de" class="li lj it bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">人类有线性直觉力吗？</h1><p id="4704" class="pw-post-body-paragraph kb kc it kd b ke mg kg kh ki mh kk kl km mi ko kp kq mj ks kt ku mk kw kx ky im bi translated">这一切都始于观察，如果 1 公斤苹果成本卢比。100 那两公斤苹果要花卢比。200.但是如果我是一个很好的讨价还价者呢？我 100 卢比买了 1 斤，200 卢比买了 2 斤，450 卢比买了 5 斤，那 10 斤要多少钱？实际值可以是任何值，但我们的直觉告诉我们它可能在 Rs 左右。900 左右。</p><p id="00f2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">观察很清楚，当我们有一个精确的线性关系时，我们预测一个精确的值，当我们有一组非线性的点时，我们试图得出一个最适合给定点的线性方程。</p><p id="1b97" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">最合适的</strong>，现在这个术语可以有很多意思和解释，有些人从这个术语中什么也看不懂。</p><p id="ad29" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">“最佳匹配”仅仅意味着良好的<strong class="kd iu">直觉</strong>。如果我们举一个例子，考虑一组点，我们需要一条穿过大多数点或接近最大点数的线。</p><figure class="mm mn mo mp gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ml"><img src="../Images/b1b1fb2c85e25c415839432a4caa1620.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cjIz2lA8OvTmbAAnuK5aQA.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">对于给定的一组问题，可以使用多行进行预测建模。</p></figure><p id="a593" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我想我们都能说出哪条线“最适合”给定的点集。这是第三个，也是我们的第一个直觉，满足标准— <strong class="kd iu">接近最大点数。</strong></p><p id="e731" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这就是线性回归模型的作用。这是线性回归背后的基本直觉。然后是机器学习在起作用。通过人类的行为，我们可以创造一条生产线，而不是机器，并在这条生产线上改进。</p><h1 id="0668" class="li lj it bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">直觉到智力</h1><p id="b1a7" class="pw-post-body-paragraph kb kc it kd b ke mg kg kh ki mh kk kl km mi ko kp kq mj ks kt ku mk kw kx ky im bi translated">但是我们需要改进一些东西，那就是所谓的<strong class="kd iu">错误</strong>。因此，我们建立了一个度量标准来计算误差，然后我们试图将其最小化。简单地说，误差就是实际值和预测值之间的偏移或偏差。误差越小，现实和可预测性之间的偏差就越小。</p><p id="aa7c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们简单地通过估计实际点和预测点之间的垂直差来计算误差。</p><p id="cd77" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在我们可以将所有误差相加，我们可以将绝对误差相加，但我们要做的是找出误差平方和。选择这个错误模型并拒绝其他模型的背后有很多理论。</p><p id="0e65" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">最基本的理论是矛盾论。每当我们发现一个漏洞或更好的技术，我们修改现有的技术。</p><p id="f95e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">考虑误差的总和，如果我们在数据集中有两个大小相同但符号相反的误差，净误差将为零。在这种情况下，我们没有正确估计模型的准确性。因此，我们建议取误差的绝对值，并将它们相加。增加绝对值可能是一个好的选择，但我们有一个更好的选择。</p><p id="ef66" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">与其他误差分析相比，采用一些平方误差有两个重要的优势，一是不需要采用绝对值，因为它已经被平方了，二是当它表现出色时，即在异常值的情况下，它会惩罚模型。对大误差求平方将导致大的整体误差。</p><p id="22f2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在我们有了一个误差的度量，其中 y <em class="mu"> i </em>是实际值，a0 — a1x <em class="mu"> i </em>是输入为 x <em class="mu"> i </em>时的预测值，a0 和 a1 是线系数。</p><figure class="mm mn mo mp gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mv"><img src="../Images/c3e3fe11f6dc21498f84d9fb33bca602.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*sDbnK-TLYgCnj6A0"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">平方误差项</p></figure><p id="a2a5" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">是时候改进模型了。我们希望将误差降至最低，误差是线路系数的函数。很简单，差异化。</p><figure class="mm mn mo mp gt ju gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/f7ecb77d25937fbecf6a95e2d0098688.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/0*dkZ2-w2E3R-uw3LF"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">偏导数最小化误差项</p></figure><p id="07d2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">一旦我们得到了微分，我们就使它们等于零，以获得系数的值，从而使误差最小。</p><figure class="mm mn mo mp gt ju gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/52bf9de68e5fd5ef403bb4bd68ae1745.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/0*hfCBLtThyu6ny_WO"/></div></figure><p id="8cfa" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">当我们把等式等于零时，神奇的事情发生了。所有的微分方程现在都被转换成一个线性方程，它的变量是线的系数。</p><figure class="mm mn mo mp gt ju gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/20e054dd518e911fa67d66af4f2a7e86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/0*P0FnGoy1ccAwM8Lo"/></div></figure><p id="0f9a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">因此，通过求解这些方程，我们可以获得系数的值，使得误差值最小，或者换句话说，我们获得了最佳拟合线</p><figure class="mm mn mo mp gt ju gh gi paragraph-image"><div class="gh gi my"><img src="../Images/6e8b7fd59b0825caf61eade8dc3cf7a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/format:webp/1*5qM-7RkWOZy2vVZA9yBdcw.png"/></div></figure><figure class="mm mn mo mp gt ju gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/4e873e64f9e27a063856fe867c6de345.png" data-original-src="https://miro.medium.com/v2/resize:fit:556/format:webp/1*HlN7NVyZ8GbdDMhl2duJeg.png"/></div></figure><h1 id="b704" class="li lj it bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">很少欣赏</h1><p id="f588" class="pw-post-body-paragraph kb kc it kd b ke mg kg kh ki mh kk kl km mi ko kp kq mj ks kt ku mk kw kx ky im bi translated">这就是我们如何获得最佳拟合线。线性回归背后的数学很简单，但值得一提，因此我称之为数学的魔力。对于更高级的方法来说，这是一个很好的起点，事实上，许多新奇的统计学习技术可以被视为线性回归的扩展。因此，在进入更复杂的方法之前，理解这个简单的模型将建立一个良好的基础。</p></div></div>    
</body>
</html>