<html>
<head>
<title>Reproducible Models with Weights &amp; Biases</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">具有权重和偏差的可重复模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/reproducible-models-with-weights-biases-415776c4cbb7?source=collection_archive---------44-----------------------#2020-04-30">https://towardsdatascience.com/reproducible-models-with-weights-biases-415776c4cbb7?source=collection_archive---------44-----------------------#2020-04-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="9ddd" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/production-ml" rel="noopener" target="_blank">生产中的机器学习</a></h2><div class=""/><div class=""><h2 id="afa9" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">探索简单的技术，使您的ML实验尽可能具有可重复性。</h2></div><p id="584d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">查看互动仪表盘</strong> <a class="ae ln" href="https://bit.ly/2Yh4oR9" rel="noopener ugc nofollow" target="_blank"> <strong class="kt jd">此处</strong> </a> <strong class="kt jd">。</strong></p><p id="cac0" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">机器学习中有不同层次的随机性。有时他们正在对数据集进行采样，而其他时候则是在机器学习模型(特别是神经网络)本身中。虽然随机性在模型训练中带来了许多优点，但它也引入了一些与可重复性有关的棘手问题。</p><blockquote class="lo lp lq"><p id="466e" class="kr ks lr kt b ku kv kd kw kx ky kg kz ls lb lc ld lt lf lg lh lu lj lk ll lm im bi translated">代码在<a class="ae ln" href="https://github.com/sayakpaul/Reproducibility-in-tf.keras-with-wandb" rel="noopener ugc nofollow" target="_blank">这里</a>可用。</p></blockquote><p id="3d2f" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在这份报告中，我们将回顾一些有望使我们的机器学习实验更具可重复性的方法。在我们进入实质之前，我们将讨论确保我们的机器学习实验可重复的一些动机。</p><p id="72fa" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们开始吧！</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/26d451cd1c270f168215dfaa865fb7bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/0*psOFRi-3TDEZ2QHZ.png"/></div><p class="md me gj gh gi mf mg bd b be z dk translated"><a class="ae ln" href="https://docs.google.com/presentation/d/1yHLPvPhUs2KGI5ZWo0sU-PKU3GimAk3iTsI38Z-B5Gw/edit#slide=id.g4e440241b9_0_27" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><h1 id="02d4" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">我们为什么要关心再现性？</h1><p id="eba1" class="pw-post-body-paragraph kr ks it kt b ku mz kd kw kx na kg kz la nb lc ld le nc lg lh li nd lk ll lm im bi translated">为了开始这一节，我将借用Joel Grus的话<a class="ae ln" href="https://docs.google.com/presentation/d/1yHLPvPhUs2KGI5ZWo0sU-PKU3GimAk3iTsI38Z-B5Gw/edit?usp=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="kt jd"> <em class="lr">再现性作为工程最佳实践的载体</em> </strong> </a> <strong class="kt jd"> <em class="lr">。</em> </strong></p><p id="e57f" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">Joel提出了许多非常重要的观点，说明为什么ML中的再现性是必要的。这是其中一些-</p><ul class=""><li id="152e" class="ne nf it kt b ku kv kx ky la ng le nh li ni lm nj nk nl nm bi translated">再现性确保了正确性。如果社区里的研究员不能重现你声称的结果，那么你的实验设置可能有问题。</li><li id="e9b7" class="ne nf it kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">有了再现性，您就能在ML实验的不同方面获得一种稳健感。例如，数据集的代表性、模型在数据集的任何特定子集上的行为，等等。</li><li id="bd79" class="ne nf it kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">你会希望能够运行你的ML模型，并且在将来仍然得到相同的结果。</li><li id="182d" class="ne nf it kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">其他人也希望能够做同样的事情。它为合作、基线评估和更新的实验提供了机会。</li></ul><p id="f680" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">最重要的是(从乔尔的上述讲话中)</p><blockquote class="lo lp lq"><p id="abf7" class="kr ks lr kt b ku kv kd kw kx ky kg kz ls lb lc ld lt lf lg lh lu lj lk ll lm im bi translated">软件工程的最佳实践会让你成为更好的研究者。</p></blockquote><p id="dbbe" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">老实说，虽然我知道可再现性，但只有在我看过乔尔的《甲板》之后，我才能真正理解对可再现性的迫切需求。</p><p id="1dbc" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">本报告的重点是开发可再现的模型，这反过来又解决了由不可再现性引起的大部分问题。</p><h1 id="bbba" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">开发可复制的模型</h1><p id="68c9" class="pw-post-body-paragraph kr ks it kt b ku mz kd kw kx na kg kz la nb lc ld le nc lg lh li nd lk ll lm im bi translated">在一份报告中满足所有的ML模型和框架并谈论可重复性几乎是不可能的。所以，我们只关注一对——神经网络和张量流。请注意，这些概念中的大部分仍然适用于其他框架。</p><p id="7e94" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在我们编写任何代码之前，我们需要确保我们的硬件/软件基础设施是统一的。当你在一个团队中工作时，这尤其有用。</p><h2 id="216e" class="ns mi it bd mj nt nu dn mn nv nw dp mr la nx ny mt le nz oa mv li ob oc mx iz bi translated">涵盖的方法概述</h2><ul class=""><li id="bb96" class="ne nf it kt b ku mz kx na la od le oe li of lm nj nk nl nm bi translated">统一的硬件和软件设置</li><li id="0941" class="ne nf it kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">随机种子+固定(初始)权重</li><li id="8c2f" class="ne nf it kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">可再生数据管道</li><li id="2bd5" class="ne nf it kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">超参数优化</li><li id="7dd1" class="ne nf it kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">保持理智的版本控制</li><li id="959d" class="ne nf it kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">确保正确性的测试</li><li id="abaa" class="ne nf it kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">模型检查点及其他</li></ul><h1 id="e088" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">地面设置和CUDA-cuDNN</h1><p id="2ca1" class="pw-post-body-paragraph kr ks it kt b ku mz kd kw kx na kg kz la nb lc ld le nc lg lh li nd lk ll lm im bi translated">出于“可复制性”的考虑，我准备用以下配置为我的机器托管一台谷歌云平台AI平台笔记本——</p><ul class=""><li id="c1d2" class="ne nf it kt b ku kv kx ky la ng le nh li ni lm nj nk nl nm bi translated"><code class="fe og oh oi oj b">n1-standard-4vCPUs-15GB</code></li><li id="e2bc" class="ne nf it kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">特斯拉V100</li><li id="1026" class="ne nf it kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">预配置映像:TensorFlow 2.1(采用英特尔MKL-DNN/MKL和CUDA 10.1)</li></ul><p id="7aca" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">遵循基础设施一致性的另一个非常重要的考虑是cuDNN和CUDA的行为(你不会想要在CPU上训练你的大型神经网络)。有许多有效的方法来计算神经网络中涉及的操作，并且它们并不总是每次都产生相同的结果，因为这些结果是近似的。</p><p id="fde7" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">ML库通常利用CUDA和cuDNN提供的这些高效的实现。在这样做的同时，它们引入了随机性(这些实现与上面提到的很接近)。另一个原因是cuDNN在运行时确定要使用的实现类型。因此，当使用TensorFlow (2.1)和兼容的NVIDIA-GPU时，为了避免潜在的再现性危机，最好在代码中做任何其他事情之前做以下事情</p><figure class="lw lx ly lz gt ma"><div class="bz fp l di"><div class="ok ol l"/></div></figure><p id="6876" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这个实践来自于<a class="ae ln" href="https://github.com/NVIDIA/tensorflow-determinism" rel="noopener ugc nofollow" target="_blank">张量流确定性存储库</a>。感谢Sebastian Raschka的<a class="ae ln" href="https://www.youtube.com/watch?v=mZmyp0JjH6s" rel="noopener ugc nofollow" target="_blank"> <strong class="kt jd"> <em class="lr"> L13卷积神经网络介绍(第二部分)1/2 </em> </strong> </a>讲座，CUDA和cuDNN部分的灵感来源于此。请务必查看由Duncan Riach<a class="ae ln" href="https://app.wandb.ai/sayakpaul/reproducible-ml/reports/twitter.com/DuncanARiach" rel="noopener ugc nofollow" target="_blank">所做的</a><a class="ae ln" href="https://developer.download.nvidia.com/video/gputechconf/gtc/2019/presentation/s9911-determinism-in-deep-learning.pdf" rel="noopener ugc nofollow" target="_blank">这一精彩演示</a>，以了解更多关于深度学习中的<strong class="kt jd">决定论</strong>的知识。</p><p id="9a41" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们现在可以关注代码的可再现性。</p><h1 id="5851" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">在代码级别对抗不可再现性</h1><p id="d169" class="pw-post-body-paragraph kr ks it kt b ku mz kd kw kx na kg kz la nb lc ld le nc lg lh li nd lk ll lm im bi translated">我将再次从上面提到的演讲中借用乔尔的一些观点，以及从我自己的经历中得到的一些发现。许多ML算法本质上是随机的，并且当算法中存在本质上不恒定的配置时，这种随机性的大部分被引入。例如，根据定义，我们初始化神经网络权重的方式应该是随机的。</p><h2 id="278e" class="ns mi it bd mj nt nu dn mn nv nw dp mr la nx ny mt le nz oa mv li ob oc mx iz bi translated">随机种子+固定(初始)权重</h2><p id="3f1a" class="pw-post-body-paragraph kr ks it kt b ku mz kd kw kx na kg kz la nb lc ld le nc lg lh li nd lk ll lm im bi translated">这里有两个明显的解决方案-</p><ul class=""><li id="1c13" class="ne nf it kt b ku kv kx ky la ng le nh li ni lm nj nk nl nm bi translated">修复随机数生成器种子，这样每次尝试生成随机数时，都会得到完全相同的结果。我建议对您在实验中使用的所有库(支持修复种子)都这样做。在NumPy和TensorFlow中，可以这样做-</li></ul><figure class="lw lx ly lz gt ma"><div class="bz fp l di"><div class="ok ol l"/></div></figure><p id="468d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">还应该注意的是，这段代码应该放在代码的顶部，也就是说，在你开始任何实验之前。</p><ul class=""><li id="d043" class="ne nf it kt b ku kv kx ky la ng le nh li ni lm nj nk nl nm bi translated">另一个解决方案是在开始训练网络之前序列化网络的权重。这样，我们就可以访问网络的初始权重，并且每次训练网络时，我们都可以使用它们来帮助我们产生相同的结果(使用相同的配置)。</li></ul><p id="30f4" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">现在，当然，神经网络的其他部分也可能引入非确定性——丢弃层、采样层(还记得VAEs吗？)，潜在载体等等。他们引入的非决定论是好的，因为它通常有助于神经网络表现得更好。我们可以在这些层中多次运行我们的训练数据，并测量每个结果的平均偏差。如果没有任何问题，偏差不会很高。</p><h1 id="4041" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">对抗数据的不可再现性</h1><p id="3256" class="pw-post-body-paragraph kr ks it kt b ku mz kd kw kx na kg kz la nb lc ld le nc lg lh li nd lk ll lm im bi translated">很多随机性可以来自机器学习模型的更好的一半——数据！通常，在训练模型时，我们提供不同的训练和验证分割。这当然会导致每次不同的模型性能结果。一个更好的方法是在我们训练模型之前修复训练和验证分裂。</p><p id="355f" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如果数据拆分的序列化很困难，那么我们仍然可以在每次拆分数据时提供种子参数。例如，当使用scikit-Learn的<code class="fe og oh oi oj b">train_test_split</code>方法时，我们可以指定<code class="fe og oh oi oj b">seed</code>参数。这里的想法是修复每次运行函数时会产生不同分裂的所有变量。</p><p id="38b2" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">常见的例子包括-</p><ul class=""><li id="977b" class="ne nf it kt b ku kv kx ky la ng le nh li ni lm nj nk nl nm bi translated">洗牌训练例子。</li><li id="3aab" class="ne nf it kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">使用像<code class="fe og oh oi oj b">glob</code>这样的库来读取文件，因为它不维护文件路径的顺序。</li></ul><p id="c8d7" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">作为一般提示，在调整训练数据点时要非常小心。您不会希望单独打乱要素及其标注。当您执行数据扩充时，总会有一些随机性。在这种情况下，建议尽可能指定种子。</p><h1 id="6dc6" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">超参数，到处都是超参数！</h1><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="on oo di op bf oq"><div class="gh gi om"><img src="../Images/c2eae535bf8d30f3f67d4cd55fbfd6ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_wuXUjYI1eGW5FVF.jpg"/></div></div><p class="md me gj gh gi mf mg bd b be z dk translated">基地形象来自<a class="ae ln" href="https://unsplash.com/photos/JZmdtU8gh7k" rel="noopener ugc nofollow" target="_blank">这里</a></p></figure><p id="cf42" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">超参数仍然是神经网络的核心，超参数调整是一个非常复杂的过程。因此，当您使用相同的网络架构运行不同的实验，但使用不同的超参数配置时，可能很难跟踪这些配置中设置的值。</p><p id="0afb" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">对于不同的网络架构，事情变得更加复杂，每个架构都有一组不同的超参数设置。这正是权重和偏见真正闪光的地方。无论您是在<a class="ae ln" href="http://bit.ly/2MKHR7K" rel="noopener ugc nofollow" target="_blank">运行超参数优化</a>还是只想将超参数配置存放在安全的地方，W &amp; B都能满足您的需求。</p><p id="8631" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">对于超参数调优，只需按照以下方式定义您想要测试的值，然后让W&amp;B <a class="ae ln" href="https://docs.wandb.com/sweeps" rel="noopener ugc nofollow" target="_blank"> <em class="lr">将其清除</em> </a>(完整代码请参见<a class="ae ln" href="https://colab.research.google.com/drive/181GCGp36_75C2zm7WLxr9U2QjMXXoibt#scrollTo=qRZfyqFpaJ5m" rel="noopener ugc nofollow" target="_blank">本笔记本</a>)</p><figure class="lw lx ly lz gt ma"><div class="bz fp l di"><div class="ok ol l"/></div></figure><p id="b50b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">只需几行代码，我们就可以生成如下所示的扫描报告。</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="on oo di op bf oq"><div class="gh gi or"><img src="../Images/7d97a5bce0b05fc1dd6e3b865f72d670.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kePWQsKKNu8B2kiHunOhlg.png"/></div></div><p class="md me gj gh gi mf mg bd b be z dk translated">在此与此表<a class="ae ln" href="https://app.wandb.ai/sayakpaul/reproducible-ml" rel="noopener ugc nofollow" target="_blank">互动</a></p></figure><p id="0199" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在指定了用于定义模型的超参数之后，您只需通过<code class="fe og oh oi oj b">config</code>字典(例如<code class="fe og oh oi oj b">config.epochs</code>)在代码中访问它们。这里有一个端到端的例子<a class="ae ln" href="https://github.com/sayakpaul/Rerproducibility-in-tf.keras-with-wandb/blob/master/Part_I.ipynb" rel="noopener ugc nofollow" target="_blank"/>。即使您没有进行任何超参数调整，记录您的超参数值也是一个好的做法，您可以通过在调用<code class="fe og oh oi oj b">wandb.init()</code>时指定<code class="fe og oh oi oj b">config</code>参数来轻松记录它们的权重和偏差。参见<a class="ae ln" href="https://github.com/sayakpaul/Reproducibility-in-tf.keras-with-wandb/blob/master/Part_I.ipynb" rel="noopener ugc nofollow" target="_blank">这里的</a>示例(检查<code class="fe og oh oi oj b">config_defaults </code>变量)。</p><h1 id="76df" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">保持理智的版本控制</h1><p id="b05c" class="pw-post-body-paragraph kr ks it kt b ku mz kd kw kx na kg kz la nb lc ld le nc lg lh li nd lk ll lm im bi translated">想象一个场景，您修改了当前的数据输入管道，并且在这样做的时候，您意识到您在模型中引入了一个bug。你想恢复到以前的版本，但你已经没有了。你可能会发现自己处于许多不同风格的类似的、潜在的灾难性情况中。</p><p id="4820" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">答案很简单——“对所有包含代码的东西使用版本控制系统！”</p><p id="e387" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">当你用W&amp;B同步你的ML实验时，它获取最新git提交的SHA，并给你一个来自GitHub repo的代码版本的链接。这里的见示例<a class="ae ln" href="https://app.wandb.ai/sayakpaul/reproducible-ml/runs/save-restore-exp/overview?workspace=user-sayakpaul" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="8835" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在机器学习中，模型和<em class="lr">数据版本</em>同样重要。数据版本化比模型版本化要复杂得多。查看<a class="ae ln" href="https://blog.floydhub.com/becoming-one-with-the-data/" rel="noopener ugc nofollow" target="_blank">此处</a>以更好地编辑您的数据。</p><p id="6808" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">要进行模型版本控制，我们可以遵循一些简单的步骤:</p><ul class=""><li id="be38" class="ne nf it kt b ku kv kx ky la ng le nh li ni lm nj nk nl nm bi translated">经常检查模型，以便在需要时完全控制它们的状态</li><li id="a211" class="ne nf it kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">模型架构可以因为许多原因而改变。对于几乎所有的<code class="fe og oh oi oj b">tf.keras</code>型号，W &amp; B记录它们的架构，如下所示(可通过运行页面的<strong class="kt jd">型号</strong>选项卡获得):</li></ul><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="on oo di op bf oq"><div class="gh gi os"><img src="../Images/3f875a0275d8af0a4ae9de3a01e57f4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7AEhe4RP6GnMxgmC.png"/></div></div><p class="md me gj gh gi mf mg bd b be z dk translated">人们可以在Netron live上预览他们的网络架构</p></figure><h1 id="8d23" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">确保正确性的测试</h1><p id="5a2a" class="pw-post-body-paragraph kr ks it kt b ku mz kd kw kx na kg kz la nb lc ld le nc lg lh li nd lk ll lm im bi translated">调试机器学习系统非常困难，这里<a class="ae ln" href="https://karpathy.github.io/2019/04/25/recipe/" rel="noopener ugc nofollow" target="_blank">是</a>的原因。那么，您如何确保您的模型没有错误呢？正如乔尔·格鲁什和杰瑞米·霍华德认为的那样——<em class="lr">确保这一点的最好方法是从一开始就不犯任何错误</em>。这就是编写好的测试可以真正帮助您确信您的模型正在以您期望的方式工作的地方。</p><p id="2c7b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">乔尔，在上面提到的演讲中，为一个ML模型整理了一套通用的测试场景-</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="on oo di op bf oq"><div class="gh gi os"><img src="../Images/a66588709951f0a094552efbe58eaf28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WbBpMUkgIi6PMnx4.png"/></div></div></figure><p id="57e9" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">尽管测试用例会因场景而异，但上面的这些无疑给了您一个很好的起点。因此，长话短说，单元测试有助于确保模型的正确性，从而使它们更具可重复性。</p><h1 id="65ca" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">模型检查点及其他</h1><p id="5fc7" class="pw-post-body-paragraph kr ks it kt b ku mz kd kw kx na kg kz la nb lc ld le nc lg lh li nd lk ll lm im bi translated">想象一下，在训练你的神经网络期间，对于一个特定的时期，网络表现出良好的泛化行为，而就在那个时期之后，它又开始发散。如果您可以设置检查点，在每个时期后保存网络快照，或者在一系列时期内保存网络的最佳快照，岂不是更好？</p><p id="0c97" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如果最好的模型中途崩溃或者你失去了重量，那就更糟了。好消息是Weights and Biases可以<em class="lr">自动</em>为你做到这一点——也就是说，它会自动将你的网络的最佳版本保存到该模型的runs页面。</p><p id="b46c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">目前对于<code class="fe og oh oi oj b">tf.keras</code>模型，W &amp; B可以以<code class="fe og oh oi oj b">.h5</code>格式序列化同步最好的模型。对于定制模型(<a class="ae ln" href="https://www.tensorflow.org/guide/keras/save_and_serialize#part_ii_saving_and_loading_of_subclassed_models" rel="noopener ugc nofollow" target="_blank">不支持序列化为</a> <code class="fe og oh oi oj b"><a class="ae ln" href="https://www.tensorflow.org/guide/keras/save_and_serialize#part_ii_saving_and_loading_of_subclassed_models" rel="noopener ugc nofollow" target="_blank">.h5</a></code> <a class="ae ln" href="https://www.tensorflow.org/guide/keras/save_and_serialize#part_ii_saving_and_loading_of_subclassed_models" rel="noopener ugc nofollow" target="_blank">格式</a>)，您需要手动完成。你可以在本教程中看到。下面我将使用W &amp; B -设置模型检查点并保存</p><figure class="lw lx ly lz gt ma"><div class="bz fp l di"><div class="ok ol l"/></div></figure><p id="02da" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">模型完成训练后，检查点文件将自动上传到相应的W&amp;B运行页面。</p><p id="73fe" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这使得跨分布式团队的合作变得更加容易，因为您团队中的任何人都可以复制您的模型——他们可以访问权重和代码(因为W&amp;B将您的GitHub提交与您的训练运行相链接)。</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="on oo di op bf oq"><div class="gh gi ot"><img src="../Images/379938ca9f51c31c8135021d091f5f5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NSjT61Adr3ZveuCc-N56mA.png"/></div></div><p class="md me gj gh gi mf mg bd b be z dk translated">这里的每次运行(图例)指的是单独的实验，权重和偏差向您显示了与每次运行相关的性能指标</p></figure><h1 id="a44d" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">结论</h1><p id="9cee" class="pw-post-body-paragraph kr ks it kt b ku mz kd kw kx na kg kz la nb lc ld le nc lg lh li nd lk ll lm im bi translated">本报告旨在提供一些简单但有用的方法，帮助您构建可重复的模型。这绝不是一份详尽的清单。我调查了一些<a class="ae ln" href="https://developers.google.com/community/experts" rel="noopener ugc nofollow" target="_blank">机器学习专家</a>关于他们对再现性的想法，以下是他们的回答:</p><ul class=""><li id="f619" class="ne nf it kt b ku kv kx ky la ng le nh li ni lm nj nk nl nm bi translated">尽可能分享公开数据集的结果。当这不可行时，包括一个公共可用的数据集，你的实验结果可以扩展到这个数据集。</li><li id="a3a8" class="ne nf it kt b ku nn kx no la np le nq li nr lm nj nk nl nm bi translated">在可能的情况下，分享在合理预算范围内可获得的计算水平上培训的结果。对于大多数人来说，使用100个TPU v3–2028s演示的结果不容易重现。</li></ul><p id="ec83" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">感谢<a class="ae ln" href="https://twitter.com/mat_kelcey" rel="noopener ugc nofollow" target="_blank"> Mat </a>、<a class="ae ln" href="https://twitter.com/A_K_Nain" rel="noopener ugc nofollow" target="_blank"> Aakash </a>和<a class="ae ln" href="https://www.linkedin.com/in/souradip-chakraborty/" rel="noopener ugc nofollow" target="_blank"> Souradip </a>的贡献。作为ML从业者，除了SOTA结果之外，最大的再现性应该是我们的目标。</p><p id="3c79" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我很想知道你使用什么再现工具/方法。如果你对这份报告有任何反馈，请不要犹豫，发微博给我，地址是<a class="ae ln" href="http://twitter.com/RisingSayak" rel="noopener ugc nofollow" target="_blank"> @RisingSayak </a>。</p></div></div>    
</body>
</html>