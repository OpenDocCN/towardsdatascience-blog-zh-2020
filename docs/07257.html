<html>
<head>
<title>A reading guide about Deep Learning with CNNs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">CNN 深度学习阅读指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-reading-guide-about-deep-learning-with-cnns-3a0e0fc99b78?source=collection_archive---------32-----------------------#2020-06-02">https://towardsdatascience.com/a-reading-guide-about-deep-learning-with-cnns-3a0e0fc99b78?source=collection_archive---------32-----------------------#2020-06-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7457" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">第一部分:图像识别和卷积骨干网</h2></div><p id="0594" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本系列的下一部分是:<a class="ae lb" rel="noopener" target="_blank" href="/a-reading-guide-about-deep-learning-with-cnns-71768f4d87e7">第二部分:图像分割</a></p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h1 id="56ab" class="lj lk iq bd ll lm ln lo lp lq lr ls lt jw lu jx lv jz lw ka lx kc ly kd lz ma bi translated">这个系列是关于什么的</h1><p id="d0b2" class="pw-post-body-paragraph kf kg iq kh b ki mb jr kk kl mc ju kn ko md kq kr ks me ku kv kw mf ky kz la ij bi translated">想象一下，你一觉醒来，感觉有一种数据科学探险的冲动。你决定投身于人们谈论的深度学习。太好了，在深入无尽的 Github 森林，在远程资源库中四处乱砍之前，您打开 PC，查看一些艺术文献。在你准备的过程中，可能会发生的是，你偶然发现了一个有前途的作品，告诉你他们已经使用了三重 ResNeXt-101 级联掩模 R-CNN 或类似的东西…啊哈…</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/35236592006eda00a91809477163b395.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*3FpKhTcJkz0hUMJlM-Qu0A.jpeg"/></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">来源:<a class="ae lb" href="https://imgflip.com/memetemplate/156781749/All-Right-Then-Keep-Your-Secrets" rel="noopener ugc nofollow" target="_blank">img lip</a></p></figure><p id="24e9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你的旅程可能会在这里结束，你会回到你舒适的小屋，没有装满闪亮的算法和知识的箱子，你可以在你当地的酒馆里分享。</p><p id="1697" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这一系列是关于通过你在冒险中必须知道的术语和历史提供一个指南。深度学习文献、科学出版物以及关于它的博客和讨论，充满了概念和模型的缩写和花哨的名称。开始阅读它感觉就像试图用一个普通的水桶抓住一个瀑布。<strong class="kh ir"> <em class="ms">在这个系列中，你会找到一个阅读指南，引导你浏览科学和非科学的里程碑文献，以及关于深度学习和卷积神经网络(CNN)的额外解释。</em> </strong></p><h1 id="20b8" class="lj lk iq bd ll lm mt lo lp lq mu ls lt jw mv jx lv jz mw ka lx kc mx kd lz ma bi translated">这个系列的动机</h1><p id="5434" class="pw-post-body-paragraph kf kg iq kh b ki mb jr kk kl mc ju kn ko md kq kr ks me ku kv kw mf ky kz la ij bi translated">几年前，我正处于投入深度学习冒险的境地。尽管有数据分析的背景，但习惯深度学习中应用的术语和概念还是有点挑战。开始阅读深度学习文学对我来说就像开始阅读《权力的游戏》小说一样:一大堆无尽的名字和关系；高度分支的家族树，以几乎相同的名字在这里和那里合并和分支…仍然，相当令人兴奋的阅读。</p><p id="7d50" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我开始从字面上绘制这些深度学习架构的家谱，最终有了从 2012 年到 2019 年底的 CNN 在图像识别、图像分割和对象检测方面的发展概况。我决定把它写下来，它最终变成了这篇开放存取评论论文[1]:</p><div class="my mz gp gr na nb"><a href="https://www.mdpi.com/2072-4292/12/10/1667" rel="noopener  ugc nofollow" target="_blank"><div class="nc ab fo"><div class="nd ab ne cl cj nf"><h2 class="bd ir gy z fp ng fr fs nh fu fw ip bi translated">基于对地观测数据深度学习的目标检测和图像分割:综述-部分…</h2><div class="ni l"><h3 class="bd b gy z fp ng fr fs nh fu fw dk translated">深度学习(DL)对大部分科学产生了巨大影响，并日益成为一种自适应的学习方法</h3></div><div class="nj l"><p class="bd b dl z fp ng fr fs nh fu fw dk translated">www.mdpi.com</p></div></div><div class="nk l"><div class="nl l nm nn no nk np mm nb"/></div></div></a></div><p id="614e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">非常欢迎任何对以科学文献为重点的 CNN 图像处理深度学习的科学但直观的综述和直接阅读指南感兴趣的人阅读它</strong>。尽管它是为遥感杂志写的，但它从计算机视觉的角度讲述了进化，因此适用于使用 CNN 进行图像处理的每个领域，而不仅仅是遥感。</p><p id="78e0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">"好吧，既然这个指南已经存在，为什么还要写这篇中间文章呢？"合法的问题，为了进一步强调《权力的游戏》的类比，这样考虑它:主要的书籍讲述了所有事实和进展的故事，直到结束；与在会议、同行评审期刊和 arXiv 上发表的关于深度学习的科学文献相同。你可以通过阅读主要文献来了解整个故事。但是还有更多的，支持主要情节的次要故事，同人小说和关于单个角色的讨论，关于我们感兴趣的世界起源的整个故事，或者仅仅是传说。对我来说，我认为像 Medium、Youtube 或 Stackexchange boards 这样的地方是你可以找到关于深度学习文献的知识的来源，这使得主要故事更加直观。因此，除了科学文献之外，这份阅读指南还有一些其他的来源，我发现这些来源对于思考科学发表的论文中所讨论的内容非常有帮助。</p><h1 id="25ac" class="lj lk iq bd ll lm mt lo lp lq mu ls lt jw mv jx lv jz mw ka lx kc mx kd lz ma bi translated">如何使用本指南</h1><p id="45b5" class="pw-post-body-paragraph kf kg iq kh b ki mb jr kk kl mc ju kn ko md kq kr ks me ku kv kw mf ky kz la ij bi translated">下面的表格是以这样一种方式组织的，你可以决定你想要深入到什么程度。每个表格中的前几个来源是介绍、概述或评论。其余的按某种方式排序，你将逐步需要以前来源的信息。所以，我建议去<strong class="kh ir">这个系列的 Github 库</strong>，拿到表格，开始阅读，自己做笔记。花所有你需要的时间来通过，但是每次你在信息的深地牢中迷路时，回到指南并想出下一步去哪里，或者回到一个你感觉舒服的点并重新开始。</p><div class="my mz gp gr na nb"><a href="https://github.com/thho/CNN_reading_guide" rel="noopener  ugc nofollow" target="_blank"><div class="nc ab fo"><div class="nd ab ne cl cj nf"><h2 class="bd ir gy z fp ng fr fs nh fu fw ip bi translated">thho/CNN _ 阅读 _ 指南</h2><div class="ni l"><h3 class="bd b gy z fp ng fr fs nh fu fw dk translated">这份阅读指南发表在媒体故事系列中，是一份关于 CNN 深度学习的阅读指南。它补充道…</h3></div><div class="nj l"><p class="bd b dl z fp ng fr fs nh fu fw dk translated">github.com</p></div></div><div class="nk l"><div class="nq l nm nn no nk np mm nb"/></div></div></a></div><p id="d894" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我希望你能像我一样享受这次冒险，并经历那些洞察力开始相互交融的史诗般的时刻！</p><h1 id="e298" class="lj lk iq bd ll lm mt lo lp lq mu ls lt jw mv jx lv jz mw ka lx kc mx kd lz ma bi translated">深度学习</h1><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="ns nt di nu bf nv"><div class="gh gi nr"><img src="../Images/6600d4a175550091c20bfba919c422db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A2I7Zet8W0opvgZkqPcTAw.png"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">来源:<a class="ae lb" href="https://imgflip.com/memetemplate/18552174/Winter-Is-Coming" rel="noopener ugc nofollow" target="_blank"> imgflip </a></p></figure><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="nw nx l"/></div></figure><h1 id="3bb6" class="lj lk iq bd ll lm mt lo lp lq mu ls lt jw mv jx lv jz mw ka lx kc mx kd lz ma bi translated">图像识别和卷积骨干网</h1><p id="c6fb" class="pw-post-body-paragraph kf kg iq kh b ki mb jr kk kl mc ju kn ko md kq kr ks me ku kv kw mf ky kz la ij bi translated">2012 年，Alex Krizhevsky 等人[2]通过引入 CNN AlexNet 赢得了 ILSVRC。加上 Ciresan 等人(2012) [3]的发表，2012 年可以被视为深度学习和 CNN 研究现代发展的起点。这两个出版物都是关于预测图像的单个标签的任务，即所谓的图像识别或图像分类。这项任务的后继者正致力于优化 CNN 的重要特征提取器，即所谓的卷积骨干网。由于卷积骨干也用于例如图像分割和对象检测，图像识别的发展成为整个领域的驱动力。因此，理解细胞神经网络在图像识别方面的发展对于进一步阅读是至关重要的。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="ns nt di nu bf nv"><div class="gh gi ny"><img src="../Images/5e19594c7fbf11f0445f0d4ea10a5fbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EHlAkaDWVegyxHGLwO8Kbg.png"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">介绍用于图像识别的 CNN 架构及其在 ImageNet 2012 数据集上的性能，圆圈的大小与对数标度中的参数数量有关。资料来源:<a class="ae lb" href="https://www.mdpi.com/2072-4292/12/10/1667" rel="noopener ugc nofollow" target="_blank"> Hoeser and Kuenzer 2020 第 10 页</a> [1]。</p></figure><p id="7ea7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上图显示了分为 5 个系列的里程碑建筑，有助于组织阅读</p><h2 id="029e" class="nz lk iq bd ll oa ob dn lp oc od dp lt ko oe of lv ks og oh lx kw oi oj lz ok bi translated">古典建筑</h2><p id="1b42" class="pw-post-body-paragraph kf kg iq kh b ki mb jr kk kl mc ju kn ko md kq kr ks me ku kv kw mf ky kz la ij bi translated">Vintage 架构以其堆叠运算的理念而闻名，该理念在深入网络的同时从输入数据中提取要素。他们建立了这种经常被比作哺乳动物视觉皮层的结构。</p><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="nw nx l"/></div></figure><h2 id="15aa" class="nz lk iq bd ll oa ob dn lp oc od dp lt ko oe of lv ks og oh lx kw oi oj lz ok bi translated">盗梦空间系列</h2><p id="980a" class="pw-post-body-paragraph kf kg iq kh b ki mb jr kk kl mc ju kn ko md kq kr ks me ku kv kw mf ky kz la ij bi translated">Inception 家族起源于 Le Cun 等人 1989 年的早期工作[4](所谓的 LeNet)，其网络也被称为 GoogLeNet。他们因以下原因而闻名:</p><ul class=""><li id="61cf" class="ol om iq kh b ki kj kl km ko on ks oo kw op la oq or os ot bi translated">复杂的构建模块</li><li id="7860" class="ol om iq kh b ki ou kl ov ko ow ks ox kw oy la oq or os ot bi translated">参数高效设计，如卷积运算的瓶颈设计或因子分解</li><li id="5da1" class="ol om iq kh b ki ou kl ov ko ow ks ox kw oy la oq or os ot bi translated">最重要的是，Inception 家族引入了批量规范化，这对训练深度网络非常重要。</li></ul><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="nw nx l"/></div></figure><h2 id="8cf9" class="nz lk iq bd ll oa ob dn lp oc od dp lt ko oe of lv ks og oh lx kw oi oj lz ok bi translated">ResNet 家族</h2><p id="2ce3" class="pw-post-body-paragraph kf kg iq kh b ki mb jr kk kl mc ju kn ko md kq kr ks me ku kv kw mf ky kz la ij bi translated">ResNet 家族都是关于残余连接的。这种设计卷积模块的新方法，通过连接绕过卷积运算，使网络变得相当深入，但仍然是可训练的。ResNet 家族的架构是当今非常受欢迎的特征提取器。</p><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="nw nx l"/></div></figure><h2 id="b4e6" class="nz lk iq bd ll oa ob dn lp oc od dp lt ko oe of lv ks og oh lx kw oi oj lz ok bi translated">高效的设计</h2><p id="4c04" class="pw-post-body-paragraph kf kg iq kh b ki mb jr kk kl mc ju kn ko md kq kr ks me ku kv kw mf ky kz la ij bi translated">最后一组是 NAS 和 MobileNet 系列，因为它们的目标都是参数高效，它们共同发展，最终成为 2019 年的高效网络模型，即 sota 架构。</p><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="4d92" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">手头有了这些文献，你就为深度学习冒险的第一个挑战做好了充分的准备。我强烈建议你做些旁门左道的事情，比如访问一个在线课程，或者通过探索 TensorFlow 或 Pytorch 来尝试一下，如果你已经准备好进行下一步，就回到你的阅读指南。<a class="ae lb" rel="noopener" target="_blank" href="/a-reading-guide-about-deep-learning-with-cnns-71768f4d87e7">在本系列的下一部分</a>中再见，我们将探讨图像分割这一章。</p><h1 id="4ffc" class="lj lk iq bd ll lm mt lo lp lq mu ls lt jw mv jx lv jz mw ka lx kc mx kd lz ma bi translated">参考</h1><p id="b37e" class="pw-post-body-paragraph kf kg iq kh b ki mb jr kk kl mc ju kn ko md kq kr ks me ku kv kw mf ky kz la ij bi translated">[1]赫泽，T；利用对地观测数据的深度学习进行目标探测和图像分割:综述-第一部分:发展和最近趋势。遥感 2020，12(10)，1667。DOI: 10.3390/rs12101667。</p><p id="bfed" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[2]克里热夫斯基，a；苏茨基弗岛；Hinton，例如，使用深度卷积神经网络的 ImageNet 分类。神经信息处理系统的进展:f .佩雷拉、Burges、C.J.C .、Bottou、l .、Weinberger、K.Q .编辑。；柯伦联合公司:美国纽约州红钩镇，2012 年；第 25 卷，第 1097-1105 页。</p><p id="8f31" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[3] Ciresan，d；Meier，u；用于图像分类的多列深度神经网络。2012 年 IEEE 计算机视觉和模式识别会议(CVPR)论文集，美国罗德岛普罗维登斯，2012 年 6 月 16-21 日；第 3642-3649 页。</p><p id="d1ff" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[4] LeCun，y；博瑟湾；登克，J.S。亨德森博士；霍华德；哈伯德，w。应用于手写邮政编码识别的反向传播。神经计算。1989, 1, 541–551.</p></div></div>    
</body>
</html>