<html>
<head>
<title>Target Encoding and Bayesian Target Encoding</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">目标编码和贝叶斯目标编码</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/target-encoding-and-bayesian-target-encoding-5c6a6c58ae8c?source=collection_archive---------9-----------------------#2020-05-05">https://towardsdatascience.com/target-encoding-and-bayesian-target-encoding-5c6a6c58ae8c?source=collection_archive---------9-----------------------#2020-05-05</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="bfc6" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">数据科学竞赛中常用的分类编码技术</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/9a967690bfda912a4eb2d04364115428.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5Ep0EVjIk-UzknYl"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">安妮·斯普拉特在<a class="ae kz" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="d53d" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">分类变量的编码问题是特征工程中非常重要的一步。不幸的是，没有适用于所有情况的解决方案。人们发明了多种技术，我在这里介绍其中的一些<a class="ae kz" rel="noopener" target="_blank" href="/spectral-encoding-of-categorical-features-b4faebdf4a"/>、这里的<a class="ae kz" rel="noopener" target="_blank" href="/entity-embedding-using-pca-and-kernel-pca-798b8b2e8c2f"/>和这里的<a class="ae kz" rel="noopener" target="_blank" href="/entity-embedding-using-t-sne-973cb5c730d7"/>。</p><p id="910b" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在这篇文章中，我将讨论<strong class="lc iv">目标编码</strong>(又名<strong class="lc iv">平均编码</strong>)及其改进版本<strong class="lc iv">贝叶斯目标编码</strong>，以及其在<strong class="lc iv">采样贝叶斯编码器中的最新改进。</strong></p><h1 id="def2" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">为什么要对类别进行编码？</h1><p id="0f19" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">给定无限量的干净数据，您将不需要对类别进行编码。您可以为每个类别训练一个模型。例如，对于泰坦尼克号问题，你可以为男性和女性训练不同的模型。如果你有几个分类变量，你必须为它们的每一个组合训练一个新的模型。</p><p id="6418" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这种方法有明显的问题:</p><ol class=""><li id="a106" class="mt mu iu lc b ld le lg lh lj mv ln mw lr mx lv my mz na nb bi translated">某些类别组合的数据可能很少。在这种情况下，模型的预测将不具有统计意义。</li><li id="baec" class="mt mu iu lc b ld nc lg nd lj ne ln nf lr ng lv my mz na nb bi translated">某些类别组合可能在训练集中找不到，但可能出现在看不见的数据中。</li></ol><p id="a150" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">通常，这种方法通常会导致过度拟合，并且不用于高基数分类变量。然而，正如在[1]中所证明的，开发正则化技术并实现这种方法的良好推广是可能的。在那里，这项技术被用于模拟DNA序列。</p><h1 id="0ea8" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">基本编码方案</h1><p id="16cf" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">一般来说，分类变量的编码是用一个或多个数字变量替换分类变量的过程，以便得到的数据集可以用于期望数字变量的统计和机器学习算法中。许多编码技术，例如一键编码和顺序编码，都是在20世纪早期发展起来的，它们并没有失去它们的重要性。从scikit-learn查看一个很棒的<a class="ae kz" href="https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-categorical-features" rel="noopener ugc nofollow" target="_blank">用户指南</a>。对于高基数分类变量，这两种技术变得不太有用。序数编码不能从分类变量中提取有用的信息。一键编码为高基数分类变量生成了太多的特征，并且往往产生较差的结果。我们将考虑下面两种对高基数分类变量非常有效的编码。</p><h1 id="7e72" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">目标(平均)编码</h1><p id="6700" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">这种类型的编码被称为目标编码或均值编码。查看Coursera课程<a class="ae kz" href="https://www.coursera.org/learn/competitive-data-science" rel="noopener ugc nofollow" target="_blank">“如何赢得数据科学竞赛:向顶尖高手学习”</a>中对此类编码的精彩解释</p><p id="47c0" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">经典论文[2]给出了这种方法的理论基础。这个想法非常简单:让我们使用目标统计对分类值进行编码。正如论文中所描述的:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nh"><img src="../Images/f602a137c9108fe5f3bf815e94c4e185.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*EFMkhhgvCO_fLfBdAl1Tqw.png"/></div></figure><p id="c0b4" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">实际上，这意味着我们计算每个类别的目标变量的平均值，并用目标平均值对该类别进行编码。这种技术适用于二元分类和回归。对于多类分类，应用类似的技术，其中我们用<code class="fe ni nj nk nl b">m-1</code>新变量编码分类变量，其中<code class="fe ni nj nk nl b">m</code>是类的数量。</p><p id="846e" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">值得注意的是，尽管作者声称使用目标统计对分类变量进行编码，但实际上只使用了均值。虽然它对于二元分类来说是一个充分的统计量，但对于回归来说却不是，因为它忽略了目标变量的类内变化。贝叶斯目标编码解决了这个问题。</p><p id="a438" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">由于目标泄漏，目标(平均)编码有过度拟合的趋势。有各种技术可以解决这个问题。例如，在留一编码器中，从目标统计中减去当前目标值。这减少了目标泄漏。另一种技术是向编码值添加高斯噪声。噪声的强度是模型的超参数。</p><p id="9a22" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">另一个问题是，一些类别几乎没有训练示例，并且这些类别的目标平均值可能采用极值，因此用平均值编码这些值可能会降低模型性能。为了解决这个问题，该类别的目标平均值经常与目标变量的边际平均值相混合[2]:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nm"><img src="../Images/f59a616a7746180a9c21859648c089eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*UIZJNeszbWXBvS3V96JQyA.png"/></div></figure><p id="93ef" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">对于有许多训练示例的类别，权重λ接近1，对于稀有类别，权重λ接近0。例如，它可以被参数化为:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nn"><img src="../Images/3f13e9d2cd4d750b7447b19d2107c78e.png" data-original-src="https://miro.medium.com/v2/resize:fit:422/format:webp/1*c5k5SNCs0g8gAhSbQ6jWvQ.png"/></div></figure><p id="80bb" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">系数λ可用<a class="ae kz" href="https://en.wikipedia.org/wiki/Empirical_Bayes_method" rel="noopener ugc nofollow" target="_blank">经验贝叶斯</a>模型解释。在这种情况下，我们首先拟合边际分布<code class="fe ni nj nk nl b">p(y)</code>，即我们基于整个数据集找到后验分布。然后，我们可以将这个后验分布用作模型<code class="fe ni nj nk nl b">p(y|c)</code>的先验分布，即给定分类变量值的目标变量的分布。</p><p id="2568" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">目标(平均值)编码的这些和其他变体在python包<a class="ae kz" href="https://github.com/scikit-learn-contrib/category_encoders" rel="noopener ugc nofollow" target="_blank">类别编码器</a>【3】中实现。目标编码的不同变体似乎从分类变量中提取出略有不同的信息，因此在数据科学竞赛期间，多种技术经常被用于各种叠加方案中。</p><h1 id="5038" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">贝叶斯目标编码</h1><p id="9371" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">贝叶斯目标编码的主要动机是在编码分类变量时，除了使用目标平均值之外，还使用类别内方差。它是在[4，5]中提出的(看似独立)。主要观点是我们应该计算后验分布的均值、方差和高阶矩。</p><p id="0281" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在贝叶斯学习中，分布的参数本身被认为是随机变量。在看到任何数据之前，参数的分布称为先验分布。基于新数据更新该分布以成为后验分布。对看不见的数据的预测可以通过在参数空间上边缘化来得到。为了避免难以处理的积分，贝叶斯从业者经常使用<a class="ae kz" href="https://en.wikipedia.org/wiki/Conjugate_prior" rel="noopener ugc nofollow" target="_blank">共轭先验</a>。它们的优点在于具有非常简单的更新规则，使得基于训练示例快速计算后验分布成为可能。更多解释请见下文[5]的摘录。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj no"><img src="../Images/3bc1cefca27be372676b311286e71241.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V_IMurCVKT7cd9KkZ7Eqcg.png"/></div></div></figure><p id="fadd" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">例如，考虑二进制分类问题。那么二元变量就可以用<a class="ae kz" href="https://en.wikipedia.org/wiki/Bernoulli_distribution" rel="noopener ugc nofollow" target="_blank">伯努利分布</a>来描述，只有一个参数<code class="fe ni nj nk nl b">p</code>，就是它属于第一类的概率。第二类的概率是<code class="fe ni nj nk nl b">q = 1-p</code>。在贝叶斯统计中，参数<code class="fe ni nj nk nl b">p</code>本身是一个随机变量，共轭先验是<a class="ae kz" href="https://en.wikipedia.org/wiki/Beta_distribution" rel="noopener ugc nofollow" target="_blank">贝塔分布</a>:</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="np nq l"/></div></figure><p id="0ea1" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">后验分布参数的更新规则非常简单:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nr"><img src="../Images/012af122291f19f5a8563c1cb63fcb65.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*dDxOiXGSdrvs9Cyh0dVblg.png"/></div></figure><p id="5d07" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">后验分布参数的解释是α-1成功和β-1失败。</p><p id="9093" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">[4，5]中的想法是计算每个类别的成功和失败次数，然后根据<em class="ns">后验</em>分布的矩生成特征:平均值:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nt"><img src="../Images/f823e9540fd6fc0f5c13b8f8dcd6fd34.png" data-original-src="https://miro.medium.com/v2/resize:fit:404/format:webp/1*892jWYkjDEMCnxsTX1bZvQ.png"/></div></figure><p id="c612" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">方差:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nu"><img src="../Images/d2f0605f0b36c2163f3a2e538353e946.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*jFKtgLoeOKViHUl-p-ceiw.png"/></div></figure><p id="8187" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">偏斜度:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nv"><img src="../Images/a4f38a072b36002605153c563268d81f.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*bBE_unT45kw9Ip8egKc7Ng.png"/></div></figure><p id="6ded" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">可能还有更高的时刻。</p><p id="947c" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">同样的技术也可以用于回归和多类分类模型。在[5]中，这种方法被称为共轭贝叶斯模型(CBM)。对于多类模型，共轭先验是狄利克雷分布，对于回归问题，它是正态-逆伽玛分布。</p><p id="c811" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">如果我们只使用后验分布的一阶矩:它的均值，CBM就简化为目标(均值)编码。通过添加更高的矩，我们可以添加目标变量的类别内分布的细节，这可以提高模型性能，前提是相同的分布对于看不见的数据是真实的。这是这种方法的一个弱点，因为模型可能会在更高的时刻过度拟合，而不会在看不见的数据上推广。在这种情况下，常规目标编码比CBM产生更好的结果。</p><p id="3738" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在[5]中，先验分布是通过在整个训练数据集上拟合贝叶斯模型而得到的。这对于解决稀有类别的问题非常重要。实际上，您希望控制目标变量的边际分布对后验分布的影响程度，因此通常必须缩小先验分布，以实现更好的模型性能。</p><p id="92d7" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">[4]中给出了贝叶斯目标编码的一个很好的实现:</p><div class="nw nx gq gs ny nz"><a href="https://www.kaggle.com/mmotoki/avito-target-encoding" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fp"><div class="ob ab oc cl cj od"><h2 class="bd iv gz z fq oe fs ft of fv fx it bi translated">Avito目标编码</h2><div class="og l"><h3 class="bd b gz z fq oe fs ft of fv fx dk translated">使用Kaggle笔记本探索和运行机器学习代码|使用Avito需求预测挑战赛的数据</h3></div><div class="oh l"><p class="bd b dl z fq oe fs ft of fv fx dk translated">www.kaggle.com</p></div></div><div class="oi l"><div class="oj l ok ol om oi on kt nz"/></div></div></a></div><p id="8b18" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">它只涵盖了二元分类的情况。在<code class="fe ni nj nk nl b">fit()</code>期间，我们计算成功和失败的次数。在<code class="fe ni nj nk nl b">transform()</code>阶段，我们生成具有条件分布的均值和其他统计属性的特征，如下摘录所示:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj oo"><img src="../Images/623b07994fa0a5329d4774c9b8390056.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y94bZlz_1DMPwIexPbwrNQ.png"/></div></div></figure><p id="3da6" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">一个通用的CBM算法可用于不同的github编码:</p><div class="nw nx gq gs ny nz"><a href="https://github.com/aslakey/CBM_Encoding" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fp"><div class="ob ab oc cl cj od"><h2 class="bd iv gz z fq oe fs ft of fv fx it bi translated">aslakey/CBM_Encoding</h2><div class="og l"><h3 class="bd b gz z fq oe fs ft of fv fx dk translated">共轭贝叶斯模型编码代码。该库包含可能提交给2019年ECML的代码…</h3></div><div class="oh l"><p class="bd b dl z fq oe fs ft of fv fx dk translated">github.com</p></div></div><div class="oi l"><div class="op l ok ol om oi on kt nz"/></div></div></a></div><p id="b456" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我希望这种分类编码技术能被合并到分类编码器包[3]或另一个广泛使用的特征工程库中。此外，我希望看到更多的理论讨论，将贝叶斯目标编码技术放在一个更广泛的统计学习的背景下。</p><h1 id="779f" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">更新:采样贝叶斯编码器</h1><p id="dc2c" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated"><a class="ae kz" href="https://arxiv.org/abs/2006.01317" rel="noopener ugc nofollow" target="_blank">最近发表的预印本</a> [6]建议对贝叶斯目标编码技术进行改进。不使用后验分布的矩作为新特征，而是建议对后验分布进行采样，并将采样值作为新特征。该思想基于这样的观察，即一般的目标编码，特别是贝叶斯目标编码，可以被表示为使用弱学习器来发现新特征的分层模型。弱学习者试图基于有限的数据子集学习目标变量的表示，在我们的例子中，只有一个变量。那么由弱学习者产生的预测可以被用作输入来训练更健壮的模型。这种技术用于集合模型，如随机森林和梯度增强树。从贝叶斯的角度来看，使用弱学习者来训练模型可以表示如下:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj oq"><img src="../Images/7fb89b68b37d9504673b8c7d762ee9ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*Ghy9dQddHiBa2YFPKFlOlA.png"/></div></figure><p id="667d" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">让我给你解一下这个等式。在我们的数据集中，我们有<strong class="lc iv"> M </strong>个分类变量，这意味着我们为分类变量<strong class="lc iv"> m </strong>的每个唯一值<strong class="lc iv"> v </strong>训练<strong class="lc iv"> M </strong>个弱学习器。在给定目标值的情况下，我们学习参数<strong class="lc iv"> θ </strong>的后验分布<strong class="lc iv"> p_mv </strong>，而不是取平均值。一般来说，<strong class="lc iv"> θ </strong>是一个矢量。类似于贝叶斯目标编码器，我们可以取几个一阶矩，或者通常将任何函数<strong class="lc iv"> f() </strong>应用于后验分布的参数。注意，我们还没有得到参数的期望值！我们使用这些函数的输出作为输入(以及不需要编码的数值变量<strong class="lc iv"> ξ </strong>)来训练模型<strong class="lc iv"> y_θ </strong>，然后只取后验分布的期望值。与贝叶斯目标编码器相比，这是采样贝叶斯编码器的主要贡献，在贝叶斯目标编码器中，在应用函数<strong class="lc iv"> f()之前过早地获取期望。</strong>这有助于减少目标泄漏和避免过度拟合。</p><p id="246b" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">为了计算期望值，我们可以从后验分布中生成一个样本。因为我们使用共轭先验，这很容易。一旦我们生成了一个样本，我们就可以像这样在上面的等式中估计期望值:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj or"><img src="../Images/00280fd1af39259ceb420d2ea5749a15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*umJqxXSlalABL4QQXM8aRQ.png"/></div></figure><p id="3cfa" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">K是样本大小，或者我们从后验分布生成的参数集的数量。这种方法类似于统计学中的<a class="ae kz" href="https://en.wikipedia.org/wiki/Imputation_(statistics)#Multiple_imputation" rel="noopener ugc nofollow" target="_blank">多重插补</a>方法。它对计算的要求也更高，尤其是对于更大的<strong class="lc iv"> K </strong>。这篇论文的代码以及所有实验与其他方法的比较可以在github报告中找到。</p><h1 id="3b1d" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">结论</h1><p id="540b" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">贝叶斯目标编码技术是对标准目标编码的改进，因为它试图从目标变量的类内分布中提取信息，而目标编码忽略了这一点。该方法在Kaggle竞赛中证明非常有用，并在WeWork上建立了一个模型，该模型处理具有高基数分类变量的数据[5]。采样贝叶斯编码器[6]提供了贝叶斯目标编码的新视角，并为分类特征编码领域的研究和工程提供了更多机会。</p><h1 id="003e" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">参考</h1><p id="098f" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">[1]邓森，大卫&amp;兴，传化。(2012).多元分类数据的非参数Bayes建模。美国统计协会杂志。104.1042–1051.2009.tm08439。</p><p id="5ea7" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">[2]丹尼尔·米西-巴雷卡。(2001).分类和预测问题中高基数分类属性的预处理方案..SIGKDD探索。3.27–32.10.1145/507533.507538.</p><p id="925e" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">[3]麦金尼斯，威廉&amp;肖，查普曼&amp; S，安德烈&amp;黄，韩宇。(2018).分类编码器:一个scikit-learn-contrib转换器包，用于对分类数据进行编码。开源软件杂志。3.501.10.21105/乔斯00501</p><p id="453e" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">[4]马特·基托，贝塔目标编码，<a class="ae kz" href="https://mattmotoki.github.io/beta-target-encoding.html" rel="noopener ugc nofollow" target="_blank">https://mattmotoki.github.io/beta-target-encoding.html</a></p><p id="756f" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">[5]斯莱基，奥斯汀&amp;萨拉斯，丹尼尔&amp;斯坎罗特，约尼。(2019).用共轭贝叶斯模型为WeWork线索评分引擎编码分类变量。</p><p id="36a4" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">[6]迈克尔拉里奥诺夫(2020)。贝叶斯目标编码中的采样技术。<a class="ae kz" href="https://arxiv.org/abs/2006.01317" rel="noopener ugc nofollow" target="_blank"> arXiv:2006.01317 </a></p></div></div>    
</body>
</html>