<html>
<head>
<title>Apache Pig</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">阿帕奇猪</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/apache-pig-1dd61d2ead31?source=collection_archive---------53-----------------------#2020-06-17">https://towardsdatascience.com/apache-pig-1dd61d2ead31?source=collection_archive---------53-----------------------#2020-06-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4f3c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">最简单的MapReduce方法</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/c631fa23b17be7d0a27424766dfed2b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hupRqWi-KZ85p4WZ"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@blankerwahnsinn?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">费边布兰克</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="b867" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi ls translated"><span class="l lt lu lv bm lw lx ly lz ma di">2006年</span>，雅虎的好人们研究开发了一种简单直观的方法来创建和执行大型数据集上的MapReduce作业。第二年，该项目被Apache软件基金会接受，此后不久，作为Apache Pig发布。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mb"><img src="../Images/da0d149879964094a1715aa5b73e2e3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CLMGVlgQyizx2UNQwgC55g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Apache Pig在Hadoop生态系统中的位置</p></figure><p id="0bd2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上图简单展示了Apache Pig在Hadoop生态系统中的位置。Pig不仅与MapReduce兼容，还与Tez和Spark处理引擎兼容，从而显著提高了性能。对于外行来说，Tez可以被认为是MapReduce框架的一个高效版本。最后，存储层默认是HDFS，但是Pig也支持HBase、Hive等等。</p><p id="f077" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">有趣的事实</strong> : Pig在本地模式下工作，也就是说，它通过脚本中的简单配置设置在本地RAM和本地文件系统上运行。很酷吧？</p><h2 id="6d6c" class="mc md iq bd me mf mg dn mh mi mj dp mk lf ml mm mn lj mo mp mq ln mr ms mt mu bi translated">体系结构</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mv"><img src="../Images/4a956c05335dc148f39a907903af075b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ulOOrkedPxkhp7wzsmxUaA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">架构流程</p></figure><ul class=""><li id="7aa7" class="mw mx iq ky b kz la lc ld lf my lj mz ln na lr nb nc nd ne bi translated"><strong class="ky ir">猪拉丁语</strong>:是与猪一起工作时使用的语言。Pig Latin语句是加载、处理和转储数据的基本结构，类似于ETL。它们是以“；”结尾的多行语句并跟随<a class="ae kv" href="https://en.wikipedia.org/wiki/Lazy_evaluation#:~:text=In%20programming%20language%20theory%2C%20lazy,avoids%20repeated%20evaluations%20(sharing)." rel="noopener ugc nofollow" target="_blank">懒评</a>。</li><li id="5d9d" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated"><strong class="ky ir">Grunt Shell</strong>:Apache Pig提供的原生Shell，其中写入/执行所有Pig拉丁脚本。然而，我们也可以在Hue中执行同样的操作。</li><li id="61e3" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated"><strong class="ky ir">解析器</strong>:一旦脚本被执行，它就到达解析器，顾名思义，它被解析为语法和类型检查等。解析器生成一个DAG或有向无环图，它基本上是一个逻辑数据处理流程图。我们将在下面看到。</li><li id="d71b" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated"><strong class="ky ir">优化器</strong>:DAG被传递到优化器，在那里发生以下优化:</li></ul><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nk nl l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">阿帕奇猪优化器</p></figure><p id="8351" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，上述自动优化是默认启用的。</p><ul class=""><li id="ea34" class="mw mx iq ky b kz la lc ld lf my lj mz ln na lr nb nc nd ne bi translated"><strong class="ky ir">编译器</strong>:优化后的脚本被组合成几个作业，无论是MapReduce、Tez还是Spark。</li><li id="2cd7" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated"><strong class="ky ir">执行引擎</strong>:根据选择的处理引擎，任务现在被发送执行。</li></ul><h2 id="24fb" class="mc md iq bd me mf mg dn mh mi mj dp mk lf ml mm mn lj mo mp mq ln mr ms mt mu bi translated">数据模型</h2><div class="kg kh ki kj gt ab cb"><figure class="nm kk nn no np nq nr paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/4977f5971dc9792d16cf394d75e91dff.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/0*Cqyb9-qnFpMnsFUi"/></div></figure><figure class="nm kk ns no np nq nr paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/d359632b5b4e35692906ed99c1a5a4a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/0*O4zK7Haswg_qVlHJ"/></div></figure><figure class="nm kk ns no np nq nr paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/2634ab274724e11006b41e5a83c8e9e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/0*FkM_V9Dy7uAHt_Ju"/></div></figure></div><div class="ab cb"><figure class="nm kk nt no np nq nr paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/787ffa7e1673a15ac4bdeb6cab30f0ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/0*a2NLswEa62R44-Ro"/></div></figure><figure class="nm kk nu no np nq nr paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/59047d20c80f0b9937ca06264755b60d.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/0*L-MxyV2ley6BcY0L"/></div><p class="kr ks gj gh gi kt ku bd b be z dk nv di nw nx translated">时钟:raphal Biscaldi、Alexis Antoine、Lina Verovaya、Priscilla Du Preez和Louis Hansel @shotsoflouis在Unsplash上拍摄的照片</p></figure></div><p id="8a8c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们使用上面任意的图片来理解Apache Pig的数据模型，按照<strong class="ky ir">时钟顺序</strong>。</p><p id="b112" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第一张图片是<strong class="ky ir">原子</strong>，这是Apache Pig中可用的最小数据单元。它可以是任何数据类型，例如，int、long、float、double、char数组和byte数组，它们携带单个信息值。比如<em class="ny">【普拉塔梅什】</em>或者<em class="ny"> 30 </em>或者<em class="ny">【medium 22】</em>。</p><p id="6388" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我们有一组有序的任意数据类型的“字段”,用逗号作为分隔符。把它想象成csv文件中的一行。这个数据结构被称为一个<strong class="ky ir">元组</strong>。比如<em class="ny"> ('Prathamesh '，30，' Medium22') </em>。</p><p id="1cab" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">简单地说，一个<strong class="ky ir">包</strong>是一个无序的元组集或集合。可以将其视为csv中的单个/多个非唯一记录。然而，与csv不同，它没有固定的结构，即它具有灵活的模式，例如第一行可以有5个字段，第二行有30个字段，依此类推。比如<em class="ny"> {('Prathamesh '，30，' Medium22 ')，(' Nimkar '，700)} </em>。</p><p id="2706" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">包有两种类型，外层和内层。外袋是<strong class="ky ir">关系</strong>，是元组的袋子。可以把它想象成关系数据库中的一个表，只是没有固定的模式。一个内袋是另一个袋内的一个关系，一个嵌套袋结构或袋-如果你愿意。</p><p id="e28c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Pig还通过一个<strong class="ky ir"> Map </strong>数据结构支持【char array to element】形式的键值对。该元素可以是任何Pig数据类型。例如，<em class="ny"> ["Name"#"Prathamesh "，" Year"#2020] </em>，其中括号分隔映射，逗号分隔对，哈希分隔键和值。</p></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><blockquote class="og"><p id="ecce" class="oh oi iq bd oj ok ol om on oo op lr dk translated">秀！不要说</p></blockquote></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><p id="fe57" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你一直关注我的帖子，你已经将<a class="ae kv" rel="noopener" target="_blank" href="/apache-sqoop-1113ce453639">结构化</a>和<a class="ae kv" href="https://medium.com/@prathamesh.nimkar/hdfs-commands-79dccfd721d7" rel="noopener">非结构化</a>数据导入HDFS。让我们进入Hue，打开Pig编辑器，探索一些常用的Pig拉丁文命令。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nk nl l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">结构化数据集—脚注中的详细信息</p></figure><h2 id="06a4" class="mc md iq bd me mf mg dn mh mi mj dp mk lf ml mm mn lj mo mp mq ln mr ms mt mu bi translated"><strong class="ak">装载、描述、说明&amp;转储</strong></h2><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nk nl l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">加载、描述、说明和转储</p></figure><p id="c364" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你现在可能已经注意到，猪拉丁语是懒惰的评价。这意味着，它等待某些特定的关键字，以便实际执行手头的任务。<em class="ny">描述、说明和转储</em>就是几个例子。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oq"><img src="../Images/9d155055f7f824f480127003eb0c5656.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vp_qu66FaSbgMLwu9bYVSg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">工作状态</p></figure><p id="b1b4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该作业分为两种类型，“oozie launcher”作为该作业的父包装器，而“piglatin*”。猪”实际上运行MapReduce代码。作业被初始化，资源被授予，作业被监控到完成，输出被显示为oozie启动器的一部分。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi or"><img src="../Images/a4a9760963bbb913a771f760d05ea2e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vNvQzeDHX20dTV505ttekA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">描述一下DESC</p></figure><div class="kg kh ki kj gt ab cb"><figure class="nm kk os no np nq nr paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/4e25b37d4f50877ed211a6784aae8a35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*wz0Q4r7ZzsgkEVM9w-PYqg.png"/></div></figure><figure class="nm kk ot no np nq nr paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/1405b7eaff6fd7f13faf7b2c324f3a37.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*yL4YtTErcM2PEwzwvb6Pew.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk ou di ov nx translated">图解和转储</p></figure></div><p id="1431" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以上是传递给Pig服务器的各个语句的输出。如果您注意到，转储输出反映正确，但插图视图不正确。这是因为Pig不能排除引号中的逗号分隔值，就像我们数据集中的城市名称一样。为了纠正这一点，我们使用<strong class="ky ir">存钱罐用户自定义函数</strong>。Piggy bank是为Apache Pig编写的Java UDFs的常见存储。我们现在要忽略这个错误，所以，想了解更多关于小猪扑满的信息，最好访问这个<a class="ae kv" href="http://pig.apache.org/docs/r0.17.0/udf.html#piggybank" rel="noopener ugc nofollow" target="_blank">网址</a>。</p><h2 id="8c0d" class="mc md iq bd me mf mg dn mh mi mj dp mk lf ml mm mn lj mo mp mq ln mr ms mt mu bi translated">过滤器</h2><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nk nl l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">过滤器</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ow"><img src="../Images/4db20a506105995222127589911b1287.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dAt_LFFeB7qT9XWVs1hdTg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">过滤输出</p></figure><p id="1932" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面的要点只有3行代码，只需通过多个城市名加载和过滤数据集。你认为Apache Pig非常容易使用，非常直观，你说得对，确实如此。这些内置函数中的一些就像口语单词一样。</p><h2 id="4b23" class="mc md iq bd me mf mg dn mh mi mj dp mk lf ml mm mn lj mo mp mq ln mr ms mt mu bi translated">FOREACH，组和商店</h2><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nk nl l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">FOREACH，组和商店</p></figure><p id="05b5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">基于同一个示例，对于每一行，只选择感兴趣的几列。然后，我们根据唯一的运营商id对数据集进行分组，最后，我们将数据集存储回HDFS。就这样，只需3行代码就可以完成这个任务。</p><div class="kg kh ki kj gt ab cb"><figure class="nm kk ox no np nq nr paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/d246655e411c393e8e99e57ea715ac6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/format:webp/1*WgJt83mPzTf3AsWUQHPV8A.png"/></div></figure><figure class="nm kk oy no np nq nr paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/c646161b07b91d29bf5aa29661c928a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*qTz9BdFwFvoowLIn-Q2O8Q.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk oz di pa nx translated">最终输出</p></figure></div><p id="4054" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可能已经注意到，我们不仅执行了提取，还执行了转换和加载，从而完成了Map &amp; Reduce。</p><p id="33be" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我对Apache Pig的简短介绍到此结束，这是最简单的MapReduce方法，尤其是如果你不是计算机出身的话。希望您已经发现它很有用，并且渴望尝试一下。最后，如果你有任何问题，请随时提问。</p></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><p id="c018" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">参考文献:</strong></p><p id="f721" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[1] <a class="ae kv" href="http://pig.apache.org/docs/r0.17.0/" rel="noopener ugc nofollow" target="_blank"> Apache Pig概述</a>，Apache Hadoop，ASF</p><p id="12ea" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2] <a class="ae kv" href="http://pig.apache.org/docs/r0.17.0/start.html" rel="noopener ugc nofollow" target="_blank">入门</a>，阿帕奇猪，ASF</p><p id="2ca2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[3] <a class="ae kv" href="http://pig.apache.org/docs/r0.17.0/perf.html#optimization-rules" rel="noopener ugc nofollow" target="_blank">性能和效率</a>，Apache Pig，ASF</p></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><h2 id="d1e0" class="mc md iq bd me mf mg dn mh mi mj dp mk lf ml mm mn lj mo mp mq ln mr ms mt mu bi translated">数据集</h2><p id="e731" class="pw-post-body-paragraph kw kx iq ky b kz pb jr lb lc pc ju le lf pd lh li lj pe ll lm ln pf lp lq lr ij bi translated">请注意，我没有下载所有的列来创建数据集。但是你可以。</p><p id="e84a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">结构化清洗数据集可以在这里找到<a class="ae kv" href="https://github.com/pratnimk/sqoop-big-data-analysis/raw/master/915662529_T_ONTIME_REPORTING.zip" rel="noopener ugc nofollow" target="_blank">。<br/>用一些数据解释？</a><a class="ae kv" href="https://medium.com/@prathamesh.nimkar/bb6dc35c1a06?source=friends_link&amp;sk=af5eab7956455ae93784c9a0ee8a9fb8" rel="noopener">给你</a>。<br/>原始数据集的首页— <a class="ae kv" href="https://www.bts.gov/" rel="noopener ugc nofollow" target="_blank">此处</a>。<br/>原始数据——此处<a class="ae kv" href="https://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236&amp;DB_Short_Name=On-Time" rel="noopener ugc nofollow" target="_blank">为</a>。<br/>有关字段的更多详细信息— <a class="ae kv" href="https://www.transtats.bts.gov/Fields.asp?Table_ID=236" rel="noopener ugc nofollow" target="_blank">此处为</a>。<br/>加载数据？— <a class="ae kv" rel="noopener" target="_blank" href="/apache-sqoop-1113ce453639">此处</a>。</p></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><div class="kg kh ki kj gt pg"><a rel="noopener follow" target="_blank" href="/simplifying-the-mapreduce-framework-20915f13ebd3"><div class="ph ab fo"><div class="pi ab pj cl cj pk"><h2 class="bd ir gy z fp pl fr fs pm fu fw ip bi translated">MapReduce</h2><div class="pn l"><h3 class="bd b gy z fp pl fr fs pm fu fw dk translated">简化MapReduce框架</h3></div><div class="po l"><p class="bd b dl z fp pl fr fs pm fu fw dk translated">towardsdatascience.com</p></div></div><div class="pp l"><div class="pq l pr ps pt pp pu kp pg"/></div></div></a></div><div class="pv pw gp gr px pg"><a rel="noopener follow" target="_blank" href="/apache-flume-71ed475eee6d"><div class="ph ab fo"><div class="pi ab pj cl cj pk"><h2 class="bd ir gy z fp pl fr fs pm fu fw ip bi translated">阿帕奇水槽</h2><div class="pn l"><h3 class="bd b gy z fp pl fr fs pm fu fw dk translated">使用Apache Flume将非结构化数据涓滴输入HDFS</h3></div><div class="po l"><p class="bd b dl z fp pl fr fs pm fu fw dk translated">towardsdatascience.com</p></div></div><div class="pp l"><div class="py l pr ps pt pp pu kp pg"/></div></div></a></div><div class="pv pw gp gr px pg"><a href="https://medium.com/@prathamesh.nimkar/big-data-analytics-using-the-hadoop-ecosystem-411d629084d3" rel="noopener follow" target="_blank"><div class="ph ab fo"><div class="pi ab pj cl cj pk"><h2 class="bd ir gy z fp pl fr fs pm fu fw ip bi translated">使用Hadoop生态系统的大数据分析渠道</h2><div class="pn l"><h3 class="bd b gy z fp pl fr fs pm fu fw dk translated">登录页面</h3></div><div class="po l"><p class="bd b dl z fp pl fr fs pm fu fw dk translated">medium.com</p></div></div><div class="pp l"><div class="pz l pr ps pt pp pu kp pg"/></div></div></a></div></div></div>    
</body>
</html>