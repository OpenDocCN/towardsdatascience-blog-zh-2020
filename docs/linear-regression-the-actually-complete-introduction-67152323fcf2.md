# çº¿æ€§å›å½’:(å®é™…ä¸Š)å®Œå…¨ä»‹ç»

> åŸæ–‡ï¼š<https://towardsdatascience.com/linear-regression-the-actually-complete-introduction-67152323fcf2?source=collection_archive---------38----------------------->

## ä¸€ä½åŒå­¦ç”¨ Python å¯¹è¿™ä¸ªç®€å•çš„æœºå™¨å­¦ä¹ ç®—æ³•è¿›è¡Œäº†å…¨é¢ã€æ·±å…¥çš„è§£é‡Š

![](img/cf5bd82f2f93eba469169ebeb869d0db.png)

Python çº¿æ€§å›å½’ä»£ç (æ‰€æœ‰ç…§ç‰‡ç”±ä½œè€…æä¾›)

# I ç®€ä»‹

æˆ‘è®°å¾—æˆ‘ç¬¬ä¸€æ¬¡é’»ç ”æœºå™¨å­¦ä¹ é¢†åŸŸæ—¶æ˜¯å¤šä¹ˆå…´å¥‹ã€‚ç‚’ä½œæ˜¯å¯ä»¥ç†è§£çš„ï¼Œæœ‰å“ªä¸ªè½¯ä»¶å·¥ç¨‹ä¸“ä¸šçš„å­¦ç”Ÿä¸æƒ³æŠ•èº«åˆ°å½“ä»Šæœ€æ¿€åŠ¨äººå¿ƒçš„ç›¸å…³æŠ€æœ¯ä¸­å‘¢ï¼Ÿ

ä½†æ˜¯éšç€æˆ‘å…´è¶£çš„å¢é•¿ï¼Œæˆ‘å¼€å§‹åœ¨è¿™ä¸ªé—®é¢˜ä¸Šè‡ªå­¦ï¼Œæˆ‘ç»å¸¸è¢«æˆ‘è¯»åˆ°çš„ä¸€äº›æ–‡ç« çš„æŠ€æœ¯æ€§å“åˆ°ã€‚ç²¾å½©çš„æ–‡ç« ï¼Œæ¯«æ— ç–‘é—®ï¼Œä½†å†™å¾—å¤ªè¶…å‰äº†ï¼Œå³ä½¿æ˜¯é‚£äº›é’ˆå¯¹åˆå­¦è€…çš„æ–‡ç« ã€‚å¦ä¸€æ–¹é¢ï¼Œè®¸å¤šäººè¿‡äºåŠ¡å®ï¼Œå¿½ç•¥äº†ç†è®ºè§£é‡Šï¼Œè€Œå€¾å‘äºè®©æ–°çš„å­¦ä¹ è€…å°½å¿«ä¸Šæ‰‹ã€‚è™½ç„¶ä¸¤è€…éƒ½å¾ˆæœ‰ä»·å€¼ï¼Œä½†æˆ‘è§‰å¾—ï¼Œä½œä¸ºä¸€åå­¦ç”Ÿï¼Œæˆ‘å¯ä»¥åœ¨è¿™é‡Œå¡«è¡¥ä¸€ä¸ªç©ºç™½ã€‚

**æˆ‘çš„ç›®æ ‡æ˜¯æ•´åˆæˆ‘å¸Œæœ›åœ¨å¼€å§‹æ—¶å°±èƒ½æŒæ¡çš„æ‰€æœ‰ä¿¡æ¯ï¼Œæ¦‚è¿°è¿™ä¸ªç®€å•çš„æœºå™¨å­¦ä¹ ç®—æ³•èƒŒåçš„ç†è®ºï¼Œç„¶åä»¥ä¸€ç§å¯ç†è§£ä½†å…¨é¢çš„æ–¹å¼ç»™å‡ºä¸€ä¸ªè§£é‡Šé€å½»çš„å®é™…ä¾‹å­ã€‚** *ä¸€ä¸ªå­¦ç”Ÿå¯¹å¦ä¸€ä¸ªå­¦ç”Ÿã€‚*

> **å› æ­¤ï¼Œæ¬¢è¿é˜…è¯»æˆ‘å¸Œæœ›åœ¨æ„å»ºç¬¬ä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹æ—¶èƒ½å¤Ÿè¯»åˆ°çš„æ–‡ç« ã€‚**

# ä¸€äº›ç†è®º

R å›å½’åˆ†ææ˜¯ä¸€å¥—ç»Ÿè®¡è¿‡ç¨‹ï¼Œæˆ‘ä»¬é€šè¿‡å®ƒæ¥ä¼°è®¡ä¸€ä¸ªæˆ–å¤šä¸ªç»™å®šè‡ªå˜é‡*ã€xã€‘*çš„å› å˜é‡*ã€yã€‘*ä¹‹é—´çš„å…³ç³»ã€‚åœ¨æœºå™¨å­¦ä¹ çš„èƒŒæ™¯ä¸‹ï¼Œå®ƒæ˜¯ç›‘ç£å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸã€‚

å›å½’æœ‰å‡ ç§ç±»å‹ï¼Œæ¯ä¸€ç§æè¿°è‡ªå˜é‡å’Œå› å˜é‡ä¹‹é—´ä¸åŒçš„æ•°å­¦å…³ç³»ã€‚ä¸€äº›å¸¸è§çš„ä¾‹å­åŒ…æ‹¬å¤šé¡¹å¼ï¼Œé€»è¾‘å’Œï¼Œæœ¬æ–‡çš„ä¸»é¢˜ï¼Œçº¿æ€§ã€‚

[](/polynomial-regression-the-only-introduction-youll-need-49a6fb2b86de) [## å¤šé¡¹å¼å›å½’:ä½ éœ€è¦çš„å”¯ä¸€ä»‹ç»

### ä¸€åå­¦ç”Ÿå¯¹ Python ä¸­æœºå™¨å­¦ä¹ ç®—æ³•èƒŒåçš„ç†è®ºå’Œåº”ç”¨çš„æ·±å…¥æ¢ç©¶

towardsdatascience.com](/polynomial-regression-the-only-introduction-youll-need-49a6fb2b86de) 

ä½†æ˜¯ä½ å¦‚ä½•é€‰æ‹©å‘¢ï¼Ÿæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿå—¯ï¼Œå°±åƒæˆ‘ä¸Šé¢è¯´çš„ï¼Œè¦çœ‹æ•°æ®ã€‚ä¸¾ä¸ªä¾‹å­:æ¯”æ–¹è¯´ï¼Œæˆ‘ä»¬å¸Œæœ›é¢„æµ‹ä¸€ç§ç–¾ç—…åœ¨äººç¾¤ä¸­è”“å»¶å¹¶é€æ¸æ¶ˆå¤±çš„è¿‡ç¨‹ã€‚è‡ªç„¶åœ°ï¼Œéšç€å¤©æ•°çš„å¢åŠ ï¼Œç—…ä¾‹æ•°ä¹Ÿä¼šå¢åŠ â€”â€”ç›´åˆ°å®ƒä»¬å¼€å§‹ä¸‹é™ï¼Œå½¢æˆæŠ›ç‰©çº¿å½¢çŠ¶ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæœ€ä½³æ‹Ÿåˆç›´çº¿æ— æ³•å‡†ç¡®é¢„æµ‹ç¬¬ 100 å¤©çš„ç—…ä¾‹æ•°ã€‚ä½†æ˜¯å¤šé¡¹å¼å›å½’å¯ä»¥ã€‚ä½†æ˜¯æˆ‘ä»¬å°†åœ¨ä¸‹ä¸€ç¯‡æ–‡ç« ä¸­æ·±å…¥æ¢è®¨è¿™ä¸ªé—®é¢˜ã€‚

![](img/7f4e3ccd0a816fd996a03b3db8095a91.png)

çº¿æ€§å›å½’ä¸é€‚ç”¨çš„ä¾‹å­

ç›¸åï¼Œå½“æˆ‘ä»¬æœ‰å¦‚ä¸‹å›¾æ‰€ç¤ºçš„è¶‹åŠ¿å˜åŒ–çš„æ•°æ®æ—¶ï¼Œä¸€æ¡ç›´çº¿å°±ç›¸å½“å‡†ç¡®ã€‚è¿™æ˜¯ä¸€ä¸ªçº¿æ€§å›å½’:

![](img/db88804644e3af148e750b839176a16c.png)

çº¿æ€§å›å½’é€‚ç”¨çš„ä¾‹å­

> å› æ­¤ï¼Œå½“å› å˜é‡å’Œè‡ªå˜é‡ä¹‹é—´çš„å…³ç³»å¯ä»¥ç›¸å½“å‡†ç¡®åœ°å»ºæ¨¡ä¸ºç›´çº¿æ—¶ï¼Œå°±ä½¿ç”¨çº¿æ€§å›å½’ã€‚

è¿™å°†æ˜¯æˆ‘ä»¬çš„*æœ€ä½³æ‹Ÿåˆçº¿ï¼Œ*ä½ å¯èƒ½è¿˜è®°å¾—é«˜ä¸­æ—¶çš„ç­‰å¼:

```
The way I learnt it in high school:   y = mx + c
Machine Learning convention:          h(X) = W0 + W1.X
```

å…¶ä¸­:

1.  *y* æˆ– *h(x)* =å› å˜é‡(ä¹Ÿå°±æ˜¯æˆ‘ä»¬è¯•å›¾ä¼°è®¡çš„)
2.  *m* æˆ– *W1* =å¡åº¦
3.  *x* æˆ– *X* =å› å˜é‡(åˆåè¾“å…¥å€¼)
4.  *c* æˆ–*W0*= y è½´ä¸Šçš„æˆªè·

# æœ¯è¯­

æˆ‘ä»¬å¦‚ä½•æ‰¾åˆ°æœ€ä½³æ‹Ÿåˆç›´çº¿çš„æ–¹ç¨‹ï¼Ÿé€šè¿‡è°ƒæ•´ä¸€ç»„å‚æ•°(W0 å’Œ W1)ç›´åˆ°æˆ‘ä»¬æ‰¾åˆ°å®ƒä»¬å„è‡ªçš„å€¼ï¼Œä½¿å¾—æ¨¡å‹çš„æ®‹å·®å¹³æ–¹å’Œ(å®é™…å€¼å’Œé¢„æµ‹å€¼ä¹‹é—´çš„å·®)*å°½å¯èƒ½å°ã€‚*

![](img/a8e25e60f1c3cd9cfb6346132da209a7.png)

çº¿æ€§å›å½’çš„ä¸€äº›æ®‹å·®

åœ¨ç»§ç»­ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å¤ä¹ ä¸€äº›é‡è¦çš„æœ¯è¯­ã€‚å¾ˆå®¹æ˜“æ··æ·†è¿™äº›æœ¯è¯­ï¼Œä½†æ˜¯ç†è§£è¿™äº›æŒ‡æ ‡å¯¹äºç¡®å®šæ¨¡å‹çš„å¯é æ€§è‡³å…³é‡è¦ã€‚

## å·®å¼‚

æœ¬è´¨ä¸Šï¼Œæ–¹å·®æ˜¯å¯¹æˆ‘ä»¬çš„æœ€ä½³æ‹Ÿåˆçº¿æœ‰å¤šä¸å‡†ç¡®çš„ä¸€ç§åº¦é‡ï¼Œå¹¶é€šè¿‡ *R* åˆ†æ•°æ¥é‡åŒ–ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ä½¿æ–¹å·®å°½å¯èƒ½å°ï¼Œæ‰€ä»¥æˆ‘ä»¬çš„ *R* å¾—åˆ†è¶Šé«˜è¶Šå¥½ã€‚

## ç¨€æœ‰

æœ‰æ—¶ç§°ä¸º*æˆæœ¬*å‡½æ•°ï¼Œç”¨äºå°†æ–¹å·®è¡¨ç¤ºä¸ºé¢„æµ‹çš„*å†³å®šç³»æ•° R* ï¼Œå…¶èŒƒå›´ä» 0 åˆ° 1ï¼Œ1 ä¸ºæœ€ä½³æ‹Ÿåˆã€‚

## å‡æ–¹è¯¯å·®

è¯¯å·®å¹³æ–¹çš„å¹³å‡å€¼(æˆ‘ä»¬å°†å®ƒä»¬å¹³æ–¹ï¼Œå› æ­¤æ²¡æœ‰è´Ÿå€¼)ã€‚æ•°å­—è¶Šå¤§ï¼Œè¯¯å·®è¶Šå¤§ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯å°½é‡å‡å°‘è¿™ç§æƒ…å†µã€‚

# è¯¥ç®—æ³•

æˆ‘ä»¬å°†ä½¿ç”¨ ***æ™®é€šæœ€å°äºŒä¹˜æ³•*** æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§ç®€å•çš„è§£æçš„éè¿­ä»£è§£æ³•ã€‚å¦‚æœæˆ‘ä»¬æƒ³è¦åº”ç”¨æ›´å¤æ‚çš„æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œæ¯”å¦‚æ”¯æŒå‘é‡æœºï¼Œé‚£ä¹ˆæˆ‘ä»¬éœ€è¦ä½¿ç”¨ ***æ¢¯åº¦ä¸‹é™*ï¼Œ**ï¼Œè¿™å°†ç»™æˆ‘ä»¬ä¸€ä¸ªè¿­ä»£å®Œæˆçš„ OLS è§£çš„è¿‘ä¼¼å€¼ã€‚ä½†æ˜¯è¿™æ˜¯å¦ä¸€ç¯‡æ–‡ç« çš„ä¸»é¢˜ã€‚

å› æ­¤ï¼Œä½¿ç”¨ä¸Šè¿°å‡½æ•°ï¼Œæˆ‘ä»¬è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ï¼Œç›´åˆ°å®ƒå­¦ä¹ åˆ°æœ€å°åŒ–æ®‹å·®å¹³æ–¹å’Œçš„æœ€ä½³ç³»æ•°ã€‚ä¸€æ—¦æˆ‘ä»¬åœ¨ä¸€äº›æ•°æ®(æ¯”å¦‚è¯´ï¼Œæ•°æ®é›†çš„å‰ 80%)ä¸Šè®­ç»ƒäº†æˆ‘ä»¬çš„æ¨¡å‹ï¼Œæˆ‘ä»¬å°†åœ¨å…¶ä½™çš„æ•°æ®(å¦å¤–çš„ 20%)ä¸Šæµ‹è¯•å®ƒã€‚

# è¿™ä¸ªä¾‹å­

è®©æˆ‘ä»¬ä»å¤´å¼€å§‹ï¼Œè¿›å£:

1.  matplotlib(py plot & RC params)â€”â€”åˆ›å»ºæˆ‘ä»¬çš„æ•°æ®å¯è§†åŒ–
2.  sci kit-Learn(load _ diabetes & linear _ model)â€”æ‰§è¡Œæœºå™¨å­¦ä¹ 
3.  NumPyâ€”â€”åšç§‘å­¦è®¡ç®—

```
import matplotlib.pyplot as plt
from matplotlib import rcParams
from sklearn.datasets import load_diabetes
from sklearn import linear_model
import numpy as np
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åŠ è½½æ•°æ®é›†å¹¶åˆ›å»ºä¸€ä¸ªå¯¹è±¡ *dxã€‚*ç³–å°¿ç—…æ•°æ®é›†æ¥è‡ª Scikit-Learnï¼Œç”± 10 ä¸ªç”Ÿç†å˜é‡(å¹´é¾„ã€æ€§åˆ«ã€ä½“é‡ã€è¡€å‹ç­‰)ç»„æˆã€‚)å’Œä¸€å¹´åç–¾ç—…è¿›å±•çš„æŒ‡æ ‡ã€‚ç›®æ ‡æ˜¯ä»ç”Ÿç†å˜é‡é¢„æµ‹ç–¾ç—…è¿›å±•ã€‚

ç°åœ¨ï¼ŒScikit-Learn æ•°æ®é›†è¿”å›ä¸€ä¸ªå«åš *Bunch* çš„ä¸œè¥¿ï¼Œå®ƒç±»ä¼¼äºä¸€ä¸ªå­—å…¸ã€‚è¿™ä¸€å †æœ‰å„ç§å±æ€§ï¼Œå…¶ä¸­ä¹‹ä¸€æ˜¯*æ•°æ®ã€‚*è¿™æ˜¯æˆ‘ä»¬å¸Œæœ›ä½¿ç”¨çš„æ•°æ®çŸ©é˜µã€‚å¦ä¸€ä¸ªæ˜¯*ç›®æ ‡*ï¼Œæˆ‘ä»¬å¾ˆå¿«å°±ä¼šè°ˆåˆ°ã€‚ä½†æ˜¯æˆ‘ä»¬ä¸éœ€è¦æ‰€æœ‰çš„æ•°æ®ï¼Œæ‰€ä»¥æˆ‘ä»¬é€‰æ‹©æˆ‘ä»¬æƒ³è¦çš„ç‰¹æ€§ï¼Œå¹¶ä½¿ç”¨ numpy.newaxis å°†æ•°ç»„ç»´æ•°ä» 1 å¢åŠ åˆ° 2ã€‚æˆ‘ä»¬ç°åœ¨å·²ç»æŠŠæ•°ç»„å˜æˆäº†ä¸€ä¸ªåˆ—å‘é‡ã€‚

```
d =â€‹ â€‹load_diabetesâ€‹()
dx = d.data[:, np.newaxis, 2]
```

å¦‚æœè¿™ä¸€æ­¥æœ‰ç‚¹æ··ä¹±ï¼Œæ²¡å…³ç³»ã€‚é‡ç‚¹æ˜¯ï¼Œæˆ‘ä»¬ç°åœ¨æœ‰äº†ä¸€ä¸ªåŒ…å«æ•°æ®çš„ 2D æ•°ç»„ï¼Œè¿™æ˜¯å¿…è¦çš„æ ¼å¼ã€‚æ‚¨çœŸçš„å¯ä»¥ç”¨ä»»ä½•æ•°æ®é›†(è‡ªå®šä¹‰åˆ—è¡¨æˆ–. csv æ–‡ä»¶)æ¥å®ç°è¿™ä¸€ç‚¹ï¼Œå…¶ä¸­æ‚¨æœ‰å¸¦æœ‰ x å’Œ y å€¼çš„æ•°æ®ç‚¹ã€‚æ‰€ä»¥ç°åœ¨æˆ‘ä»¬çš„çœ‹èµ·æ¥åƒè¿™æ ·:

```
[[ 0.06169621]
 [-0.05147406]
 [ 0.04445121]
 [-0.01159501]
 [-0.03638469]
 [-0.04069594]
 [-0.04716281]
 [...        ]]
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æ•°æ®é›†åˆ†æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†â€”â€”è¿™æ˜¯æœºå™¨å­¦ä¹ çš„åŸºæœ¬éƒ¨åˆ†ã€‚ä½ ä¼šæ³¨æ„åˆ°ã€‚æˆ‘å‰é¢æåˆ°çš„*ç›®æ ‡*å±æ€§ã€‚è¿™äº›åŸºæœ¬ä¸Šæ˜¯æ­£ç¡®çš„å€¼ï¼Œæˆ–*å“åº”å˜é‡*ã€‚

```
dx_train = dx[:-20]
dy_train = d.target[:-20]
dx_test = dx[-20:]
dy_test = d.target[-20:]
```

æ­¤æ—¶ï¼Œæ•£ç‚¹å›¾ä¼šæœ‰æ‰€å¸®åŠ©ã€‚ä»…ä»…é€šè¿‡è§‚å¯Ÿï¼Œæˆ‘ä»¬å°±å¯ä»¥æ¨æ–­å‡ºçº¿æ€§å›å½’æ˜¯å¦ä¼šæä¾›ä¸€ä¸ªå‡†ç¡®çš„æ¨¡å‹ã€‚æˆ‘å°†ä½¿ç”¨ rcParams æ·»åŠ ä¸€äº›æ ·å¼ï¼Œä½¿å®ƒçœ‹èµ·æ¥æ›´æœ‰å¸å¼•åŠ›ï¼Œä½†ä¸è¦æ‹…å¿ƒè¿™ä¸€ç‚¹ã€‚

```
rcParams['axes.spines.top'] = False
rcParams['axes.spines.right'] = False
rcParams['lines.linewidth'] = 2plt.scatter(dx_train, dy_train, c='#9dd4a7', label='Training data')
plt.scatter(dx_test, dy_test, c='#d66565', label='Testing data')plt.legend(loc="upper left")
```

![](img/c83ddec4f47e96ec4fedb95074285947.png)

æ•£ç‚¹å›¾ä¸Šæˆ‘ä»¬çš„è®­ç»ƒå’Œæµ‹è¯•æ•°æ®

ä½ å¯èƒ½çŸ¥é“ï¼Œçœ‹èµ·æ¥å¥½åƒä¸€æ¡ç›´çº¿å¯ä»¥æˆ–å¤šæˆ–å°‘åœ°é¢„æµ‹è¿™ä¸€è¶‹åŠ¿çš„èµ°å‘ã€‚

ç°åœ¨æœ‰è¶£çš„éƒ¨åˆ†æ¥äº†ã€‚æˆ‘ä»¬å°†ä¸ºçº¿æ€§å›å½’åˆ›å»ºä¸€ä¸ªå¯¹è±¡ *lr* ï¼Œå¹¶å°†æ•°æ®æ‹Ÿåˆåˆ°å…¶ä¸­ã€‚

```
lr = linear_model.LinearRegression()
lr.fit(dx_train, dy_train)
```

æˆ‘ä»¬å‰©ä¸‹è¦åšçš„å°±æ˜¯åœ¨æ•£ç‚¹å›¾ä¸Šç»˜åˆ¶æœ€ä½³æ‹Ÿåˆçº¿:

```
plt.plot(dx_test, lr.predict(dx_test), c='#404040', label='Line of best fit')
```

![](img/4a6adefaa8c31ee501590aaeb6cb3795.png)

æˆ‘ä»¬çš„æœ€ä½³æ‹Ÿåˆå’Œæµ‹è¯•æ•°æ®ç³»åˆ—

> **æ­å–œä½ ï¼**æ‚¨å·²ç»æˆåŠŸè®­ç»ƒå¹¶æµ‹è¯•äº†ä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹ã€‚

ä½†æ˜¯æˆ‘ä»¬ç°åœ¨è¿˜ä¸èƒ½æ²¾æ²¾è‡ªå–œâ€¦

# æ½œå¾—æ›´æ·±

åœ¨è¿™ä¸ªé˜¶æ®µï¼Œæˆ‘è§‰å¾—æˆ‘ä»¬åº”è¯¥æ›´æ·±å…¥ã€‚æˆ‘ä»¬å¿…é¡»äº†è§£åˆ°åº•å‘ç”Ÿäº†ä»€ä¹ˆã€‚

LinearRegression()ç±»æ˜¯å¥½äº‹å‘ç”Ÿçš„åœ°æ–¹ã€‚è¿™å°±æ˜¯çº¿æ€§æ¨¡å‹ *lr* é€‚åˆæœ€å°åŒ–é¢„æµ‹å€¼å’Œç›®æ ‡å€¼ä¹‹é—´çš„æ®‹å·®å¹³æ–¹å’Œçš„ç³»æ•°çš„åœ°æ–¹ï¼Œæ­£å¦‚æˆ‘å‰é¢æåˆ°çš„ã€‚

è¿™ä¸ªç±»åŒ…å«äº†*ã€‚fit()* å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å®ƒè¢«åº”ç”¨äºçº¿æ€§å›å½’å¯¹è±¡ *lr* ã€‚æˆ‘ä»¬å°†è®­ç»ƒæ•°æ®(x å’Œ y å€¼)ä½œä¸ºå‚æ•°ä¼ å…¥ï¼Œå‡½æ•°è¿”å›å¯¹è±¡çš„ä¸€ä¸ªå®ä¾‹ï¼Œç°åœ¨è¯¥å®ä¾‹å·²ä¸æ•°æ®ç›¸åŒ¹é…ã€‚

æœ€åï¼Œæˆ‘ä»¬çœ‹åˆ°ã€‚ *predict()ï¼Œ*linear regression()ç±»çš„å¦ä¸€ä¸ªå‡½æ•°ã€‚è¿™æ˜¯é€šè¿‡è®¡ç®—æœ€ä½³æ‹Ÿåˆç›´çº¿çš„æ–¹ç¨‹è¿”å›é¢„æµ‹å€¼çš„å‡½æ•°ã€‚

**ç†è§£è¿™äº›å‡½æ•°çš„æœ€å¥½æ–¹æ³•æ˜¯*é‡å†™æ²¡æœ‰å®ƒä»¬çš„ç¨‹åºã€‚***

è¿™æ˜¯æ™®é€šæœ€å°äºŒä¹˜ç®—æ³•çš„èµ·ç‚¹ã€‚æˆ‘ä»¬éœ€è¦åšçš„ç¬¬ä¸€ä»¶äº‹æ˜¯æ‰¾åˆ°æœ€ä½³æ‹Ÿåˆçº¿*çš„æ¢¯åº¦ *m* å’Œ y è½´æˆªè· *c* ã€‚*ä»¥ä¸‹æ˜¯å„è‡ªçš„å…¬å¼:

*   *m*=(Î¼(*x*)*Î¼(*y*)â€”Î¼(*x***y*)/((Î¼(*x*))2Î¼(*x*2))
*   *c*=Î¼(*y*)â€”*m**Î¼(*x*)

æˆ‘ä»¬ç”¨ numpy.mean æ¥æ±‚å¹³å‡å€¼ *Î¼* ã€‚æˆ‘å°†è¿™ä¸¤ä¸ªå…¬å¼å®ç°ä¸ºä¸€ä¸ªå‡½æ•°:

```
def find_gradient_and_y_intercept(): m = (np.mean(dx_train) * np.mean(dy_train)
   - np.mean(dx_train *  dy_train)) / ((np.mean(dx_train)) **
   2 -  np.mean(dx_train ** 2)) c = np.mean(dy_train) - m * np.mean(dx_train) return m, c
```

è¯·æ³¨æ„ï¼Œç°åœ¨æˆ‘ä»¬ä¸å¿…åƒä»¥å‰ä¸€æ ·å°†æ•°ç»„æ›´æ”¹ä¸º 2Dï¼Œå› ä¸ºæˆ‘ä»¬æ²¡æœ‰ä½¿ç”¨ã€‚ *fit()* åŠŸèƒ½äº†ã€‚å› æ­¤ï¼Œå°†æˆ‘ä»¬ä¹‹å‰ä½¿ç”¨ *numpy.newaxis* çš„é‚£ä¸€è¡Œä¿®æ”¹æˆè¿™æ ·:

```
dx = d.data[:, 2]
```

ç°åœ¨ï¼Œå½“æˆ‘ä»¬ç»˜åˆ¶æœ€ä½³æ‹Ÿåˆçº¿æ—¶ï¼Œä¸ä½¿ç”¨ã€‚ *predict()* å‡½æ•°ï¼Œæˆ‘ä»¬å®é™…ä¸Šè¾“å…¥äº†æˆ‘ä»¬å¯¹äºæœ€ä½³æ‹Ÿåˆçº¿çš„æ–¹ç¨‹ï¼Œ *mx + cï¼Œ*ä½œä¸º *y* å€¼ã€‚

```
plt.plot(dx_test, ((m * dx_test) + b), c='0.2', label="Line of Best Fit")
```

![](img/83ee03e1f25f1160adea34cbf7f3b692.png)

ä¸€æ¡ä¸ä¹‹å‰å®Œå…¨ç›¸åŒçš„æœ€ä½³æ‹Ÿåˆçº¿

> **è¿™æ¬¡çœŸçš„æ­å–œä½ äº†ï¼**ä½ åˆšåˆšä»é›¶å¼€å§‹å†™äº†ä¸€ä¸ªçº¿æ€§å›å½’ç®—æ³•ã€‚å¸Œæœ›æ‚¨ç°åœ¨å·²ç»å¯¹ç®—æ³•åŠå…¶ç›¸å…³åŠŸèƒ½æœ‰äº†é€å½»çš„ç†è§£ã€‚

ä½œä¸ºå¥–åŠ±ï¼Œè®©æˆ‘ä»¬è®¡ç®—æˆ‘ä»¬æ¨¡å‹çš„*å‡æ–¹è¯¯å·®*å’Œ*å¾—åˆ†*(å‰é¢å®šä¹‰çš„é¢„æµ‹çš„å†³å®šç³»æ•° *Rã€*)ã€‚

ä½¿ç”¨ LinearRegression()ç±»:

```
mse = np.mean((lr.predict(dx_test)-dy_test)**2)
score = lr.score(dx_test, dy_test)
```

ä¸ä½¿ç”¨ç±»:ç³»æ•° *R* å®šä¹‰ä¸º *(1 â€” u/v)* ï¼Œå…¶ä¸­ u ä¸ºæ®‹å·®å¹³æ–¹å’Œ *((y_true â€” y_pred) ** 2)ã€‚sum()* å’Œ *v* æ˜¯å¹³æ–¹å’Œçš„æ€»å’Œ *((y_true â€” y_true.mean()) ** 2)ã€‚sum():*

```
mse = np.mean((((m * dx_test) + b) - dy_test) ** 2)
score = (1 - ((dy_test - ((m * dx_test) + b)) ** 2).sum() / ((dy_test - dy_test.mean()) ** 2).sum())
```

ç­”æ¡ˆå¾—å‡º *mse* = 2548.07 å’Œ *R* = 0.47ã€‚

# ç»“è®º

è¿™å°±æ˜¯å¯¹æœºå™¨å­¦ä¹ æœ€ç®€å•çš„ç®—æ³•â€”â€”çº¿æ€§å›å½’çš„å…¨é¢ä»‹ç»ã€‚æˆ‘å¸Œæœ›ï¼Œä½œä¸ºä¸€åå­¦ç”Ÿï¼Œæˆ‘èƒ½å¤Ÿä»¥ä¸€ç§ç›¸å…³å’Œå…¨é¢çš„æ–¹å¼è§£é‡Šè¿™äº›æ¦‚å¿µã€‚

**ç®€å•å›é¡¾ä¸€ä¸‹æˆ‘ä»¬è®²è¿‡çš„å†…å®¹:**

1.  çº¿æ€§å›å½’çš„å®šä¹‰
2.  ä¸€äº›é‡è¦æœ¯è¯­
3.  å¯¹ç®—æ³•çš„è§£é‡Š
4.  Python ä¸­çš„ä¸€ä¸ªå®é™…ä¾‹å­
5.  å¯¹ç¤ºä¾‹ä¸­å‡½æ•°çš„è¯¦ç»†æ£€æŸ¥

å¦‚æœæ‚¨è§‰å¾—è¿™ç¯‡æ–‡ç« æœ‰å¸®åŠ©ï¼Œæˆ‘å¾ˆä¹æ„ä¸æ‚¨åˆä½œï¼å…³æ³¨æˆ‘ [Instagram](https://www.instagram.com/adenhaus/) äº†è§£æ›´å¤šæœºå™¨å­¦ä¹ ã€è½¯ä»¶å·¥ç¨‹å’Œåˆ›ä¸šå†…å®¹ã€‚

ç¼–ç å¿«ä¹ï¼

[**è®¢é˜…**](https://medium.com/subscribe/@adenhaus) ğŸ“šä¸ºäº†ä¸é”™è¿‡æˆ‘çš„ä¸€ç¯‡æ–°æ–‡ç« ï¼Œå¦‚æœä½ è¿˜ä¸æ˜¯ä¸­ç­‰ä¼šå‘˜ï¼Œ [**åŠ å…¥**](https://medium.com/@adenhaus/membership) ğŸš€å»è¯»æˆ‘æ‰€æœ‰çš„ï¼Œè¿˜æœ‰æˆåƒä¸Šä¸‡çš„å…¶ä»–æ•…äº‹ï¼

# èµ„æº

**Scikit å­¦ä¹ ** *çº¿æ€§ _ æ¨¡å‹ã€‚LinearRegression()æ–‡æ¡£:*[https://sci kit-learn . org/stable/modules/generated/sk learn . linear _ modelã€‚linear regression . html # sk learn . linear _ modelã€‚çº¿æ€§å›å½’.é¢„æµ‹](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.predict)

**Scikit Learn** *çº¿æ€§å›å½’ç¤ºä¾‹:*[https://Scikit-Learn . org/stable/auto _ examples/Linear _ model/plot _ ols . html](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html)

**sci kit Learn***load _ diabetes æ–‡æ¡£:*[https://sci kit-Learn . org/stable/modules/generated/sk Learn . datasets . load _ diabetes . html # sk Learn . datasets . load _ diabetes](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes)

**Scikit Learn** *æœºå™¨å­¦ä¹ ç®€ä»‹:*[https://Scikit-Learn . org/stable/tutorial/basic/tutorial . html](https://scikit-learn.org/stable/tutorial/basic/tutorial.html)

**çœŸå® Python** *çº¿æ€§å›å½’:*[https://Real Python . com/Linear-Regression-in-Python/# simple-Linear-Regression](https://realpython.com/linear-regression-in-python/#simple-linear-regression)

**Statisticsbyjim** *è§£è¯» R:*[https://Statisticsbyjim . com/regression/interpret-R-squared-regression/](https://statisticsbyjim.com/regression/interpret-r-squared-regression/)

**BMC** *å‡æ–¹å·®&R:*[https://www . BMC . com/blogs/Mean-squared-error-R2-and-variance-in-regression-analysis/](https://www.bmc.com/blogs/mean-squared-error-r2-and-variance-in-regression-analysis/)