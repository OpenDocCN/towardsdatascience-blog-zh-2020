<html>
<head>
<title>Standardizing Traditional Machine Learning pipelines to Tensor Computation using Hummingbird</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Hummingbird 将传统机器学习管道标准化为张量计算</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/standardizing-traditional-machine-learning-pipelines-to-tensor-computation-using-hummingbird-7a0b3168670?source=collection_archive---------38-----------------------#2020-06-20">https://towardsdatascience.com/standardizing-traditional-machine-learning-pipelines-to-tensor-computation-using-hummingbird-7a0b3168670?source=collection_archive---------38-----------------------#2020-06-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/7fded02a51354e6a68a0c3c637c9501b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IAPMYqYyPbfI22du"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图片由<a class="ae jg" href="https://unsplash.com/@jannerboy62" rel="noopener ugc nofollow" target="_blank">尼克·费因斯</a>提供(来源于 unsplash)</p></figure><div class=""/><div class=""><h2 id="fcac" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">来自<strong class="ak">微软研究员</strong>的<strong class="ak">蜂鸟</strong>包的应用</h2></div><h1 id="1c9e" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">背景和挑战📋</h1><p id="c1e1" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi mm translated"><span class="l mn mo mp bm mq mr ms mt mu di"> T </span>这里仅仅是没有新闻中提到的<strong class="ls jk">机器学习</strong>、<strong class="ls jk">深度学习</strong>、<strong class="ls jk">人工智能</strong>的日子。说到传统 ML <strong class="ls jk">，</strong>我想提一下发展了很久的基础算法；与<strong class="ls jk">深度神经网络</strong> (DNNs)形成对比。尽管<strong class="ls jk">深度学习</strong>近年来在计算机视觉、自然语言处理或推荐系统等许多方面发展迅速，...<strong class="ls jk">传统的机器学习</strong>仍然完全占据主导地位。</p><figure class="mw mx my mz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mv"><img src="../Images/50ca288736e4964c8e510d48dea3b590.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Go9PJfKQ6iQGv3L-tFO9Dw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">Kaggle 调查 2019 结果(图片由作者提供)</p></figure><p id="66e2" class="pw-post-body-paragraph lq lr jj ls b lt na kk lv lw nb kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">另一项<a class="ae jg" href="https://arxiv.org/abs/1912.09536" rel="noopener ugc nofollow" target="_blank"> <em class="nf">调查</em> </a>研究了 2017 年 7 月(GH2017)在<strong class="ls jk"> GITHUB </strong>上的 120 万个公开可用的数据科学笔记本和 2019 年 7 月(GH2019)的 510 万个笔记本中的“使用最多的库”，表明<strong class="ls jk"> </strong>最广泛使用的四个库是<strong class="ls jk"> NumPy、Matplotlib、Pandas、</strong>和<strong class="ls jk"> Scikit-learn </strong>(不是 DNNs 框架此外，<strong class="ls jk"> Scikit-learn </strong>的知名度大约是 PyTorch 和 TensorFlow 总和的 5 倍，而且增长速度也超过了这两家公司。</p><p id="64d9" class="pw-post-body-paragraph lq lr jj ls b lt na kk lv lw nb kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">它们仍然备受关注的主要原因是解释黑盒的能力，以便在软件基础设施中为业务、更简单和更有效的使用做出正确的指示。最近，不仅是大型企业，还有中小型企业都在寻求<strong class="ls jk">机器学习</strong>来帮助解决业务挑战，包括预测性维护、客户流失预测和供应链优化。对于企业来说，他们更喜欢理解数据，研究每个参数的特征，并彻底考虑它们，而不是仅仅朝着高度准确的预测前进。</p><p id="7352" class="pw-post-body-paragraph lq lr jj ls b lt na kk lv lw nb kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">然而，交互式或分析型企业应用程序有一条关键路径，即<strong class="ls jk">模型评分</strong>。在数据科学解决方案的总成本中，模型得分占<strong class="ls jk">45–65%</strong>(基于 AWS 报告[1])。通常，在部署时，甚至在培训期间，ML 模型被多次评分并应用于实际工作应用中(例如，横向扩展批量或交互式服务、个人计算机、移动和物联网设备)。由于可移植性、可维护性、部署和监控方面的考虑，评分控制了复杂性。因此，评分模型的延迟(计时)和吞吐量是企业非常关心的问题。</p><p id="d8f8" class="pw-post-body-paragraph lq lr jj ls b lt na kk lv lw nb kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">到目前为止，最流行的工具包像 ML.NET 的<strong class="ls jk"/>(。NET)、Scikit-learn(基于 Python)和 H2O(基于 Java)来生成操作符的预测管道(pipeline ),例如训练模型、预处理程序、特征化器、缺失值估算器，但是它们主要是针对训练而优化的，而不是针对部署期间测试集的评分。这些框架的可移植性通常受限于在许多环境中支持它们的操作者。优化<strong class="ls jk">模型评分</strong>的解决方案之一是<strong class="ls jk"> </strong>通过将复杂多样的<strong class="ls jk">传统 ML </strong>转化为一小组简单张量，从 DNNs 中利用<strong class="ls jk">有向无环图</strong> (DAGs)的优势。基于这一想法，许多系统已经被建立，如<strong class="ls jk"> ONNX 运行时</strong>【2】、<strong class="ls jk">torch script</strong>【3】和<strong class="ls jk">TVM</strong>【4】，利用了神经网络 DNN 运行时优化的相对计算简单性，但是它们在与<strong class="ls jk">传统 ML 一起工作的能力和适用性方面仍然有限。</strong></p><p id="0313" class="pw-post-body-paragraph lq lr jj ls b lt na kk lv lw nb kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">最近发布了<strong class="ls jk">、</strong>、<a class="ae jg" href="https://github.com/microsoft/hummingbird" rel="noopener ugc nofollow" target="_blank">、<strong class="ls jk">蜂鸟</strong>、</a>、<strong class="ls jk"> - </strong>一个来自微软研究团队的库，它可以将特征化运算符和<strong class="ls jk">传统 ML </strong>模型编译成一小组张量运算，以增强 CPU 和硬件加速器(GPU，TPU)的高效计算。它为降低基础设施复杂性和<strong class="ls jk">传统 ML </strong>的模型评分成本开辟了新的途径。在接下来的章节中，<strong class="ls jk">系统架构和实现</strong>在三个基本研究问题方面的重点将使您对其有一个清晰的概述。</p><blockquote class="ng nh ni"><p id="3efc" class="lq lr nf ls b lt na kk lv lw nb kn ly nj nc mb mc nk nd mf mg nl ne mj mk ml im bi translated">传统的最大似然算子(基于线性代数的，如线性模型，算法的，如决策树)可以转化为张量计算吗？</p><p id="cfcd" class="lq lr nf ls b lt na kk lv lw nb kn ly nj nc mb mc nk nd mf mg nl ne mj mk ml im bi translated">张量空间中产生的(密集)计算能与我们作为输入(例如，遍历一棵树)得到的(稀疏)命令性选择竞争吗？</p><p id="12b6" class="lq lr nf ls b lt na kk lv lw nb kn ly nj nc mb mc nk nd mf mg nl ne mj mk ml im bi translated">HUMMINGBIRD 能帮助降低软件复杂性和提高模型可移植性吗？</p></blockquote></div><div class="ab cl nm nn hx no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="im in io ip iq"><h1 id="8fd4" class="ky kz jj bd la lb nt ld le lf nu lh li kp nv kq lk ks nw kt lm kv nx kw lo lp bi translated">技术亮点📄</h1><figure class="mw mx my mz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ny"><img src="../Images/a2ce31b417d826ecd17ebcb3588d2d77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n-fmj0L3a-SymBEetQeGug.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><strong class="bd nz">蜂鸟</strong>的高层架构(图片由作者提供)</p></figure><p id="62d4" class="pw-post-body-paragraph lq lr jj ls b lt na kk lv lw nb kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated"><strong class="ls jk">蜂鸟</strong>库是基于对<strong class="ls jk">传统 ML 流水线</strong>周期寿命的简单观察。一旦应用了特征并训练了模型，就可以将整个管线符号化为将输入特征转换为预测分数的函数(例如，对于二元分类为真或假)。因此，<strong class="ls jk"> Hummingbird </strong>的目标是将流水线中每个操作符的预测函数(而不是训练算法)编译成张量计算，并将它们适当地联系起来。为此，<strong class="ls jk">蜂鸟</strong>引入了三个主要组件:</p><ol class=""><li id="58d4" class="oa ob jj ls b lt na lw nb lz oc md od mh oe ml of og oh oi bi translated"><strong class="ls jk">管道解析器</strong>:生成内存中的中间表示(IR)对象，用其输入参数和相关的输入/输出依赖关系对给定预测管道中的每个运算符进行编码。</li><li id="b32a" class="oa ob jj ls b lt oj lw ok lz ol md om mh on ml of og oh oi bi translated"><strong class="ls jk">优化器:</strong>为操作符搜索潜在的编译策略，并产生潜在的修改 IR。</li><li id="c102" class="oa ob jj ls b lt oj lw ok lz ol md om mh on ml of og oh oi bi translated"><strong class="ls jk">张量 DAG 编译器:</strong>挑选优化的 IR 对象，并将其编译成遵循目标 DNN 运行时格式的张量运算。</li></ol><p id="da6f" class="pw-post-body-paragraph lq lr jj ls b lt na kk lv lw nb kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated"><strong class="ls jk">蜂鸟</strong>目前支持将很多有代表性的算法算子编译成张量计算。在实践中，没有一种策略始终支配其他策略，它取决于每个输入和模型结构。更多细节，可以去看看他们的<a class="ae jg" href="https://github.com/microsoft/hummingbird" rel="noopener ugc nofollow" target="_blank"><strong class="ls jk">Github</strong></a><strong class="ls jk"/>或者这篇<a class="ae jg" href="https://scnakandala.github.io/papers/TR_2020_Hummingbird.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="ls jk">论文</strong> </a> <strong class="ls jk">。</strong></p><p id="22e4" class="pw-post-body-paragraph lq lr jj ls b lt na kk lv lw nb kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">在这篇文章中，介绍了基于树的模型的方法。编译基于树的模型有三种不同的策略:<strong class="ls jk">通用矩阵乘法</strong> (GEMM)、<strong class="ls jk"> TreeTraversal、</strong>和<strong class="ls jk"> PerfectTreeTraversal。</strong></p><ul class=""><li id="ce84" class="oa ob jj ls b lt na lw nb lz oc md od mh oe ml oo og oh oi bi translated"><strong class="ls jk"> GEMM </strong>策略可以在批量小或者有大量小树的模型上高效运行(CPU 上 D≤ 3，GPU 上 D≤10——D 是树的高度)。</li><li id="81c2" class="oa ob jj ls b lt oj lw ok lz ol md om mh on ml oo og oh oi bi translated"><strong class="ls jk"> TreeTraversal: </strong>对于大批量和较高的树(D &gt; 10)，<strong class="ls jk"> TreeTraversal </strong>策略通常优于<strong class="ls jk"> GEMM </strong>策略。</li><li id="989c" class="oa ob jj ls b lt oj lw ok lz ol md om mh on ml oo og oh oi bi translated"><strong class="ls jk"> PerfectTreeTraversal </strong>比<strong class="ls jk"> TreeTraversal </strong>稍快，因为索引查找次数减少，合并内存访问更好，但如果树太深，<strong class="ls jk"> PerfectTreeTraversal </strong>会遇到内存占用问题(D≤ 10)。</li></ul><p id="df2b" class="pw-post-body-paragraph lq lr jj ls b lt na kk lv lw nb kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">让我们来看一个简单的例子，看看<strong class="ls jk">蜂鸟</strong>如何用<strong class="ls jk"> GEMM </strong>策略编译简单的回归树。在这个例子中，树将输入作为具有五个元素(<em class="nf"> x </em> ∈R5)、四个决策节点(橙色)和五个叶节点(蓝色)的特征向量。<strong class="ls jk">蜂鸟</strong>将<strong class="ls jk"> </strong>将决策树模型翻译成如下神经网络:</p><figure class="mw mx my mz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi op"><img src="../Images/42134e8fbf113458e18f0512670f557e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0nr5_jmBxPVLo6sArPsXtQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">简单回归树(作者图片)</p></figure><figure class="mw mx my mz gt iv gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/ceffddcfa131b7edf35457b54c03707e.png" data-original-src="https://miro.medium.com/v2/resize:fit:954/format:webp/1*Pot9bWCegt0eicgDOyEomw.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">假设我们想要计算这个观察的输出</p></figure><ul class=""><li id="b97d" class="oa ob jj ls b lt na lw nb lz oc md od mh oe ml oo og oh oi bi translated"><strong class="ls jk">步骤 1: </strong>将输入张量乘以张量 A(从上面的决策树模型计算得到),该张量捕获输入特征和内部节点之间的关系。然后将其与张量 B 进行比较，张量 B 被设置为每个内部节点的阈值，以创建表示从输入到节点的路径的高音输入路径。在这种情况下，树模型具有 4 个条件，输入向量是 5，因此，张量 A 的形状是 5×4，张量 B 是 1×4。</li></ul><figure class="mw mx my mz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi or"><img src="../Images/ea2f62e6817abbd4602aa536fdfcf72d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T4PzG1QIwyWQmyXu2IYbOQ.png"/></div></div></figure><ul class=""><li id="f973" class="oa ob jj ls b lt na lw nb lz oc md od mh oe ml oo og oh oi bi translated"><strong class="ls jk">步骤 2: </strong>张量 p 将与张量 C 相乘，张量 C 捕捉内部节点是否是该内部节点的父节点，如果是，它是在左子树还是右子树中(左= 1，右=-1，否则=0)，然后检查与张量 D 的等号，张量 D 捕捉从叶节点到树根的路径中其父节点的左子节点的计数，以创建表示从节点到输出的路径的 tenor 输出路径。在这种情况下，该树模型具有 4 个条件的 5 个输出，因此，张量 C 的形状是 4x5，张量 D 是 1x5。</li></ul><figure class="mw mx my mz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi os"><img src="../Images/74176da51a8348dc85b4bbdd3c7cae4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9YgyjwrIMffeElIxMgi1TQ.png"/></div></div></figure><ul class=""><li id="3908" class="oa ob jj ls b lt na lw nb lz oc md od mh oe ml oo og oh oi bi translated"><strong class="ls jk">第三步:</strong>张量 P 将与捕获叶节点之间映射的张量 E 相乘，以推断最终预测。在这种情况下，树模型有 5 个输出，因此，张量 E 的形状是 5x1。</li></ul><figure class="mw mx my mz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ot"><img src="../Images/612135b4c017a9501005645bddaa8f55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yomMkIIKGd4A6kh6K1DSdw.png"/></div></div></figure><p id="0115" class="pw-post-body-paragraph lq lr jj ls b lt na kk lv lw nb kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">从这个例子中，我们可以清楚地想象出<strong class="ls jk">蜂鸟</strong>如何编译一个基于树的模型。此外，<strong class="ls jk">蜂鸟</strong>还有其他技术可以高效地编译<strong class="ls jk">传统的 ML </strong>，比如自动广播、最小化操作符调用、… <strong class="ls jk"> </strong>目前<strong class="ls jk">蜂鸟</strong>支持超过 40 个 scikit-learn 操作符<strong class="ls jk">(</strong><a class="ae jg" href="https://github.com/microsoft/hummingbird" rel="noopener ugc nofollow" target="_blank"><strong class="ls jk">Github</strong></a><strong class="ls jk">)</strong></p><figure class="mw mx my mz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ou"><img src="../Images/bb69cc0f8a7c12849e10670c00ecae79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tVRE4-s6-SZOVCqICuaopw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><strong class="bd nz"> Scikit-learn </strong>目前在<strong class="bd nz">蜂鸟</strong>中支持的操作符(图片由作者提供)</p></figure><p id="d11a" class="pw-post-body-paragraph lq lr jj ls b lt na kk lv lw nb kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">即使<strong class="ls jk"> Hummingbird </strong>非常有用，为企业和数据科学家节省了大量时间和金钱，但它仍处于开发阶段，有许多局限性，需要社区做出更多贡献来改进:</p><ul class=""><li id="55f5" class="oa ob jj ls b lt na lw nb lz oc md od mh oe ml oo og oh oi bi translated">不支持任意用户定义的运算符</li><li id="c1c5" class="oa ob jj ls b lt oj lw ok lz ol md om mh on ml oo og oh oi bi translated">不支持稀疏数据</li><li id="c98e" class="oa ob jj ls b lt oj lw ok lz ol md om mh on ml oo og oh oi bi translated">不支持文本特征提取</li><li id="69ff" class="oa ob jj ls b lt oj lw ok lz ol md om mh on ml oo og oh oi bi translated">目前正在开发中</li></ul><h1 id="1b83" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">实验评估📊</h1><p id="5b6b" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">让我们用<strong class="ls jk">加州住房数据集来测试<strong class="ls jk">蜂鸟</strong>在回归<strong class="ls jk"> </strong>模型中的表现。</strong>总观察值为 20640，有 8 个数字输入特征，目标变量为房屋价值中值。这个数据集是从<a class="ae jg" href="http://lib.stat.cmu.edu/datasets/" rel="noopener ugc nofollow" target="_blank"> StatLib </a>存储库中获得的，您也可以使用<code class="fe ov ow ox oy b"><a class="ae jg" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html#sklearn.datasets.fetch_california_housing" rel="noopener ugc nofollow" target="_blank"><strong class="ls jk">sklearn.datasets.fetch_california_housing</strong></a></code>函数下载。</p><figure class="mw mx my mz gt iv"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="e7d1" class="pw-post-body-paragraph lq lr jj ls b lt na kk lv lw nb kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">在本实验中，从简单到复杂测试了 4 种不同的模型，分别是<strong class="ls jk">线性回归、决策树回归、RandomForestRegressor 和 xgb 回归。</strong>要使用的指标是 MSE 和运行时间，显示在帖子的末尾。</p><figure class="mw mx my mz gt iv"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="fb9f" class="pw-post-body-paragraph lq lr jj ls b lt na kk lv lw nb kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">毫无疑问，使用复杂的模型，准确性会提高，但训练时间以及评分时间也会增加。让我们将这些模型编译成张量运算符，并检查编译是否有助于减少运行时间。首先，这些转换后的模型将在 CPU 中运行。</p><figure class="mw mx my mz gt iv"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="e156" class="pw-post-body-paragraph lq lr jj ls b lt na kk lv lw nb kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">运行时间在所有情况下都没有减少。原因是测试数据的数量不大，每个模型本身的复杂程度是正常的。让我们看看转换后的模型在 GPU 中运行的性能。</p><figure class="mw mx my mz gt iv"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="502b" class="pw-post-body-paragraph lq lr jj ls b lt na kk lv lw nb kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">在这段时间里，运行时间比在 CPU 中运行减少了。然而，与原始模型相比，只有 RandomForestRegressor 和 XGBRegressor 的运行时间有所减少，而 LinearRegression 和 DecisionTreeRegressor 的运行时间仍然较高，因为模型本身很简单。所有结果汇总如下。</p><figure class="mw mx my mz gt iv"><div class="bz fp l di"><div class="oz pa l"/></div></figure><h1 id="cf63" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">最后的想法📕</h1><p id="42f4" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">很明显可以看出模型的复杂性(或准确性)与运行时间之间的权衡。由于测试数据的数量、数据集的复杂性和模型的复杂性，在某些情况下将传统模型转换为张量算子无助于减少评分时间。你可以自由地用更复杂的<strong class="ls jk">特征符</strong>来测试编译模型的性能，在管道模型中如使用变换技术(RobustScaler，StandardScaler，KBinsDiscretizer，..)、插补技术(SimpleImputer，MissingIndicator，..)或特征提取技术(多项式特征，特征散列器，..)来查看转换为张量运算符的效率。</p><p id="af69" class="pw-post-body-paragraph lq lr jj ls b lt na kk lv lw nb kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">如果你想进一步讨论，可以联系我。这是我的<a class="ae jg" href="https://www.linkedin.com/in/vumichien/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a></p><p id="6ed4" class="pw-post-body-paragraph lq lr jj ls b lt na kk lv lw nb kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">尽情享受吧！！！👦🏻</p><h1 id="39b0" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">参考</h1><p id="cd97" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">[1]亚马逊。亚马逊 sagemaker 的总拥有成本(tco)。https://pages.awscloud.com/rs/112-TZM-766/图片/亚马逊 _SageMaker_TCO_uf.pdf，2020。</p><p id="f82c" class="pw-post-body-paragraph lq lr jj ls b lt na kk lv lw nb kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">[2] ONNX 运行时。<a class="ae jg" href="https://github.com/microsoft/onnxruntime." rel="noopener ugc nofollow" target="_blank">https://github.com/microsoft/onnxruntime.</a></p><p id="845d" class="pw-post-body-paragraph lq lr jj ls b lt na kk lv lw nb kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">[3] TorchScript 文档。<a class="ae jg" href="https://pytorch.org/docs/stable/jit.html." rel="noopener ugc nofollow" target="_blank">https://pytorch.org/docs/stable/jit.html.</a></p><p id="8176" class="pw-post-body-paragraph lq lr jj ls b lt na kk lv lw nb kn ly lz nc mb mc md nd mf mg mh ne mj mk ml im bi translated">[4]陈、莫罗、江、郑、严、科恩、沈、王、胡、策泽、盖斯特林和克里希那穆提。Tvm:深度学习的自动化端到端优化编译器，2018</p></div></div>    
</body>
</html>