<html>
<head>
<title>Tackling the Small Object Problem in Object Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">目标检测中小目标问题的处理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tackling-the-small-object-problem-in-object-detection-6e1c9976ee69?source=collection_archive---------24-----------------------#2020-08-25">https://towardsdatascience.com/tackling-the-small-object-problem-in-object-detection-6e1c9976ee69?source=collection_archive---------24-----------------------#2020-08-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2501" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">注意:我们也在博客上发布了<a class="ae ki" href="https://blog.roboflow.com/detect-small-objects/" rel="noopener ugc nofollow" target="_blank">解决小物体问题</a>。<a class="ae ki" href="https://blog.roboflow.com/detect-small-objects/" rel="noopener ugc nofollow" target="_blank">检测小物体</a>是计算机视觉中最具挑战性和最重要的问题之一。在本帖中，我们将讨论我们在 Roboflow 通过迭代数百个小型<a class="ae ki" href="https://blog.roboflow.com/object-detection/" rel="noopener ugc nofollow" target="_blank">物体检测模型</a>开发的一些策略。</h2></div><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi kj"><img src="../Images/ff7e11f944a1bcec6e763dab8d16ca7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*B8X2cDUk6y93ZziN.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">在<a class="ae ki" href="https://public.roboflow.ai/object-detection/aerial-maritime/1" rel="noopener ugc nofollow" target="_blank">公共航空海事数据集</a>中，无人机从上方看到的小物体</p></figure><p id="62e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了提高模型在小对象上的性能，我们推荐以下技术:</p><ul class=""><li id="caf1" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">提高您的<a class="ae ki" href="https://blog.roboflow.com/you-might-be-resizing-your-images-incorrectly/" rel="noopener ugc nofollow" target="_blank">图像捕捉分辨率</a></li><li id="4bb4" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">提高您的型号的<a class="ae ki" href="https://blog.roboflow.com/you-might-be-resizing-your-images-incorrectly/" rel="noopener ugc nofollow" target="_blank">输入分辨率</a></li><li id="a993" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">平铺您的图像</li><li id="7845" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ki" href="https://blog.roboflow.com/boosting-image-detection-performance-with-data-augmentation/" rel="noopener ugc nofollow" target="_blank">通过增强生成更多数据</a></li><li id="fd22" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">自动学习<a class="ae ki" href="https://blog.roboflow.com/what-is-an-anchor-box/" rel="noopener ugc nofollow" target="_blank">模型锚</a></li><li id="516c" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ki" href="https://blog.roboflow.com/introducing-class-management/" rel="noopener ugc nofollow" target="_blank">过滤掉无关类</a></li></ul><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="mj mk l"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">如果你喜欢视频，我也记录了这篇文章的讨论</p></figure><h1 id="3f25" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">小物体问题为什么难？</h1><p id="05ee" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">小目标问题困扰着世界范围内的目标检测模型。不买？查看<a class="ae ki" href="https://www.youtube.com/watch?v=B4gNml3V2cc" rel="noopener ugc nofollow" target="_blank"> COCO </a>对最新型号<a class="ae ki" href="https://blog.roboflow.com/training-a-yolov3-object-detection-model-with-a-custom-dataset/" rel="noopener ugc nofollow" target="_blank"> YOLOv3 </a>、<a class="ae ki" href="https://blog.roboflow.com/breaking-down-efficientdet/" rel="noopener ugc nofollow" target="_blank"> EfficientDet </a>和<a class="ae ki" href="https://blog.roboflow.com/training-yolov4-on-a-custom-dataset/" rel="noopener ugc nofollow" target="_blank"> YOLOv4 </a>的评估结果:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/80802c2bbc128348d932dc164747e368.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/0*nnnTcjL18dxFKlvD.png"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">查看 AP_S、AP_M、AP_L 的最新型号。小物件硬！( <a class="ae ki" href="https://arxiv.org/abs/2004.10934" rel="noopener ugc nofollow" target="_blank"> <em class="nj">引用</em> </a> <em class="nj"> ) </em></p></figure><p id="f4d5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，在 EfficientDet 中，小对象的 AP 仅为 12%，而大对象的 AP 为 51%。这几乎是五倍的差异！</p><p id="781f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">那么为什么探测小物体如此困难呢？</p><p id="ab46" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一切都归结于模型。<a class="ae ki" href="https://blog.roboflow.com/the-ultimate-guide-to-object-detection/" rel="noopener ugc nofollow" target="_blank">物体检测模型</a>通过聚集卷积层中的像素来形成特征。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/aea1eb3dde0d789aa56b37634788b56e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*j6Ot7pQhODAL_Xel.png"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated"><em class="nj"/><a class="ae ki" href="https://arxiv.org/pdf/2007.12099.pdf" rel="noopener ugc nofollow" target="_blank"><em class="nj">PP-YOLO</em></a>中用于物体检测的特征聚合</p></figure><p id="b3e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">并且在网络的末端，基于损失函数进行预测，该损失函数基于预测和地面真实之间的差异对像素求和。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/0b68797b6c70eea3ac7219c5fba5348f.png" data-original-src="https://miro.medium.com/v2/resize:fit:878/format:webp/0*b2TbOUtRKmzak2sm.png"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated"><em class="nj">YOLO 的</em> <a class="ae ki" href="https://stats.stackexchange.com/questions/287486/yolo-loss-function-explanation" rel="noopener ugc nofollow" target="_blank"> <em class="nj">损失函数</em> </a></p></figure><p id="7946" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果地面真值盒不大，训练时信号会变小。</p><p id="b594" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，小物体最有可能出现数据标签错误，它们的标识可能会被忽略。</p><p id="9dad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">经验上和理论上，小物体很难。</p><h1 id="46db" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">提高图像捕捉分辨率</h1><p id="3696" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">分辨率，分辨率，分辨率…这都是关于<a class="ae ki" href="https://blog.roboflow.com/you-might-be-resizing-your-images-incorrectly/" rel="noopener ugc nofollow" target="_blank">分辨率</a>。</p><p id="37d6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">非常小的对象在边界框内可能只包含几个像素，这意味着提高图像的分辨率以增加检测器可以从那个小框中形成的特征的丰富性非常重要。</p><p id="27d0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，如果可能的话，我们建议捕捉尽可能高分辨率的图像。</p><h1 id="0632" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">提高模型的输入分辨率</h1><p id="a511" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">一旦你有了更高<a class="ae ki" href="https://blog.roboflow.com/you-might-be-resizing-your-images-incorrectly/" rel="noopener ugc nofollow" target="_blank">分辨率</a>的图像，你就可以放大你的模型的输入分辨率。警告:这将导致大型模型需要更长的训练时间，并且在开始部署时推断速度会更慢。您可能需要进行实验来找出速度和性能之间的正确权衡。</p><p id="63e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的<a class="ae ki" href="https://blog.roboflow.com/training-yolov4-on-a-custom-dataset/" rel="noopener ugc nofollow" target="_blank">训练 YOLOv4 </a>教程中，你可以通过改变配置文件中的<a class="ae ki" href="https://blog.roboflow.com/you-might-be-resizing-your-images-incorrectly/" rel="noopener ugc nofollow" target="_blank">图像大小</a>来轻松缩放你的输入分辨率。</p><pre class="kk kl km kn gt nm nn no np aw nq bi"><span id="f69c" class="nr mm it nn b gy ns nt l nu nv">[net] <br/>batch=64 <br/>subdivisions=36 <br/>width={YOUR RESOLUTION WIDTH HERE} <br/>height={YOUR RESOLUTION HEIGHT HERE} <br/>channels=3 <br/>momentum=0.949 <br/>decay=0.0005 <br/>angle=0 <br/>saturation = 1.5 <br/>exposure = 1.5 <br/>hue = .1  <br/>learning_rate=0.001 <br/>burn_in=1000 <br/>max_batches=6000 <br/>policy=steps <br/>steps=4800.0,5400.0 <br/>scales=.1,.1</span></pre><p id="6569" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们关于如何训练 YOLOv5 的<a class="ae ki" href="https://blog.roboflow.com/how-to-train-yolov5-on-a-custom-dataset/" rel="noopener ugc nofollow" target="_blank">教程中，您还可以通过更改训练命令中的图像大小参数来轻松缩放您的输入分辨率:</a></p><pre class="kk kl km kn gt nm nn no np aw nq bi"><span id="5648" class="nr mm it nn b gy ns nt l nu nv">!python train.py --img {YOUR RESOLUTON SIZE HERE} --batch 16 --epochs 10 --<strong class="nn iu">data</strong> '../data.yaml' --cfg ./models/custom_yolov5s.yaml --weights '' --name yolov5s_results  --cache</span></pre><p id="e1ee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意:只有达到训练数据的最大分辨率时，您才会看到改进的结果。</p><h1 id="85eb" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">平铺您的图像</h1><p id="4de1" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">检测小图像的另一个伟大策略是将图像平铺作为预处理步骤。平铺可以有效地放大小物体上的检测器，但允许您保持所需的小输入分辨率，以便能够运行快速推断。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/870a0c25110e61e6bd6e5273a91a9069.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*b40b_kQXH1sQLs23.gif"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated"><em class="nj">在 Roboflow 中平铺图像作为预处理步骤</em></p></figure><p id="1f6b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你在训练中使用平铺，记住你也需要在推理时平铺你的图像是很重要的。</p><h1 id="496f" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">通过增强生成更多数据</h1><p id="fb85" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated"><a class="ae ki" href="https://blog.roboflow.com/boosting-image-detection-performance-with-data-augmentation/" rel="noopener ugc nofollow" target="_blank">数据扩充</a>从你的基本数据集生成新图像。这对于防止模型过度适应训练集非常有用。</p><p id="9854" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一些对小物体检测特别有用的增强包括<a class="ae ki" href="https://blog.roboflow.com/why-and-how-to-implement-random-crop-data-augmentation/" rel="noopener ugc nofollow" target="_blank">随机裁剪</a>、<a class="ae ki" href="https://blog.roboflow.com/why-and-how-to-implement-random-rotate-data-augmentation/" rel="noopener ugc nofollow" target="_blank">随机旋转</a>和<a class="ae ki" href="https://blog.roboflow.com/advanced-augmentations/" rel="noopener ugc nofollow" target="_blank">马赛克增强</a>。</p><h1 id="621b" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">自动学习模型锚</h1><p id="c2e1" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated"><a class="ae ki" href="https://blog.roboflow.com/what-is-an-anchor-box/" rel="noopener ugc nofollow" target="_blank">锚框</a>是模型学习预测的原型边界框。也就是说，锚定框可以预先设置，有时对您的训练数据来说不是最佳的。这是很好的定制调整这些你手头的任务。幸运的是，<a class="ae ki" href="https://blog.roboflow.com/how-to-train-yolov5-on-a-custom-dataset/" rel="noopener ugc nofollow" target="_blank"> YOLOv5 模型架构</a>会根据您的定制数据自动为您完成这项工作。你所要做的就是开始训练。</p><pre class="kk kl km kn gt nm nn no np aw nq bi"><span id="1dad" class="nr mm it nn b gy ns nt l nu nv">Analyzing anchors... anchors/target = 4.66, Best Possible Recall (BPR) = 0.9675. Attempting to generate improved anchors, please wait... WARNING: Extremely small objects found. 35 of 1664 labels are &lt; 3 pixels in width or height. Running kmeans for 9 anchors on 1664 points... thr=0.25: 0.9477 best possible recall, 4.95 anchors past thr n=9, img_size=416, metric_all=0.317/0.665-mean/best, past_thr=0.465-mean: 18,24,  65,37,  35,68,  46,135,  152,54,  99,109,  66,218,  220,128,  169,228 Evolving anchors with Genetic Algorithm: fitness = 0.6825: 100%|██████████| 1000/1000 [00:00&lt;00:00, 1081.71it/s] thr=0.25: 0.9627 best possible recall, 5.32 anchors past thr n=9, img_size=416, metric_all=0.338/0.688-mean/best, past_thr=0.476-mean: 13,20,  41,32,  26,55,  46,72,  122,57,  86,102,  58,152,  161,120,  165,204</span></pre><h1 id="ab29" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">过滤掉无关的类</h1><p id="f110" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated"><a class="ae ki" href="https://blog.roboflow.com/label-management-for-computer-vision/" rel="noopener ugc nofollow" target="_blank">类管理</a>是提高数据集质量的一项重要技术。如果有一个类与另一个类明显重叠，则应该从数据集中过滤掉该类。或许，您认为数据集中的小对象不值得检测，因此您可能想要将其删除。您可以使用作为<a class="ae ki" href="https://roboflow.com/pro" rel="noopener ugc nofollow" target="_blank"> Roboflow Pro </a>一部分的<a class="ae ki" href="https://public.roboflow.com/object-detection/hard-hat-workers/health#intro" rel="noopener ugc nofollow" target="_blank">高级数据集健康检查</a>快速识别所有这些问题。</p><p id="9c99" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">类省略和类重命名都可以通过<a class="ae ki" href="https://blog.roboflow.com/label-management-for-computer-vision/" rel="noopener ugc nofollow" target="_blank"> Roboflow 的本体管理工具</a>实现。</p><h1 id="919d" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">结论</h1><p id="5ad3" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">正确检测小物体确实是一个挑战。在本帖中，我们讨论了一些改进小型<a class="ae ki" href="https://blog.roboflow.com/the-ultimate-guide-to-object-detection/" rel="noopener ugc nofollow" target="_blank">物体探测器</a>的策略，即:</p><ul class=""><li id="24cf" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">提高您的<a class="ae ki" href="https://blog.roboflow.com/you-might-be-resizing-your-images-incorrectly/" rel="noopener ugc nofollow" target="_blank">图像捕捉分辨率</a></li><li id="2e48" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">提高您的<a class="ae ki" href="https://blog.roboflow.com/you-might-be-resizing-your-images-incorrectly/" rel="noopener ugc nofollow" target="_blank">型号的输入分辨率</a></li><li id="bc10" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">平铺您的图像</li><li id="9e02" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ki" href="https://blog.roboflow.com/boosting-image-detection-performance-with-data-augmentation/" rel="noopener ugc nofollow" target="_blank">通过增强生成更多数据</a></li><li id="af70" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">自动学习<a class="ae ki" href="https://blog.roboflow.com/what-is-an-anchor-box/" rel="noopener ugc nofollow" target="_blank">模型锚</a></li><li id="3166" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ki" href="https://blog.roboflow.com/introducing-class-management/" rel="noopener ugc nofollow" target="_blank">过滤掉无关类</a></li></ul><p id="3a7d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一如既往，愉快的检测！</p></div></div>    
</body>
</html>