<html>
<head>
<title>BigData/ETL: 4 Easy steps to setting up an ETL Data pipeline from scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">BigData/ETL:从头开始设置 ETL 数据管道的 4 个简单步骤</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/4-easy-steps-to-setting-up-an-etl-data-pipeline-from-scratch-a6e67c40b6e1?source=collection_archive---------21-----------------------#2020-01-21">https://towardsdatascience.com/4-easy-steps-to-setting-up-an-etl-data-pipeline-from-scratch-a6e67c40b6e1?source=collection_archive---------21-----------------------#2020-01-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5e82" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用几个命令建立 ETL 管道</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/758c50e4f7a7dfeb5c124d142eea6162.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XhlDlxwU3_5K0W0-NxiBkw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">ETL(提取转换负载)</p></figure><blockquote class="ky kz la"><p id="c71a" class="lb lc ld le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">这个博客有什么不可期待的？AWS Glue、AWS 数据迁移服务或 Apache Airflow 等托管 ETL 解决方案。基于云的技术是受管理的，但不是免费的。并且不在本文的讨论范围内。</p></blockquote><h1 id="b0b6" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">目录</h1><ol class=""><li id="6f46" class="mq mr it le b lf ms li mt mu mv mw mx my mz lx na nb nc nd bi translated"><strong class="le iu">什么是 ETL 管道？</strong></li><li id="8d95" class="mq mr it le b lf ne li nf mu ng mw nh my ni lx na nb nc nd bi translated"><strong class="le iu">ETL 管道有哪些不同的用例？</strong></li><li id="3dd4" class="mq mr it le b lf ne li nf mu ng mw nh my ni lx na nb nc nd bi translated"><strong class="le iu"> ETL 先决条件—Docker+Debezium+Kafka+Kafka Connect—鸟瞰图</strong></li><li id="636a" class="mq mr it le b lf ne li nf mu ng mw nh my ni lx na nb nc nd bi translated"><strong class="le iu"> ETL 设置——4 步流程</strong></li></ol><h1 id="2771" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated"><strong class="ak"> 1:什么是 ETL？</strong></h1><p id="60a0" class="pw-post-body-paragraph lb lc it le b lf ms ju lh li mt jx lk mu nj ln lo mw nk lr ls my nl lv lw lx im bi translated">ETL 代表提取转换加载管道。它用于建立数据仓库或数据湖。</p><blockquote class="ky kz la"><p id="c785" class="lb lc ld le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">注意:数据仓库收集多种结构化数据源，如关系数据库，但是在数据湖中，我们存储结构化和非结构化数据。</p></blockquote><h1 id="4bfe" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">2: <strong class="ak"> <em class="nm">一个 ETL 管道的各种用例有哪些？</em>T15】</strong></h1><p id="df10" class="pw-post-body-paragraph lb lc it le b lf ms ju lh li mt jx lk mu nj ln lo mw nk lr ls my nl lv lw lx im bi translated">ETL 有广泛的用例，如下所示:</p><ul class=""><li id="0a3b" class="mq mr it le b lf lg li lj mu nn mw no my np lx nq nb nc nd bi translated">为非结构化数据赋予结构，因为我们将它存储到数据仓库中，通常我们使用数据仓库来存储来自多个资源的结构化数据。</li><li id="d833" class="mq mr it le b lf ne li nf mu ng mw nh my ni lx nq nb nc nd bi translated">ML 工程师获取模型训练数据的数据管道。并且经常是 ML 工程师/数据科学家(L1)的首要任务。</li><li id="c4cf" class="mq mr it le b lf ne li nf mu ng mw nh my ni lx nq nb nc nd bi translated">用于制作备份或临时数据源。</li></ul><blockquote class="ky kz la"><p id="e536" class="lb lc ld le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated"><strong class="le iu">注意:</strong>在这个例子中，我们将使用源作为 MySQL 数据库，目的地作为 Elasticsearch，它固有地与 Kibana 集成，用于数据可视化和机器学习。</p></blockquote><h1 id="13c6" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated"><strong class="ak"> <em class="nm"> 3: ETL 先决条件—Docker+Debezium+Kafka+Kafka Connect—鸟瞰图</em> </strong></h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/f8222c9269ddec76acdc22b48d4f2b09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z_se01KYnKPOWzGYTM9IQw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">MySQL(源)+Debezium+Kafka/Kafka Connect+elastic search(目的地)+ Kibana</p></figure><p id="66f7" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk mu lm ln lo mw lq lr ls my lu lv lw lx im bi translated">从上图中可以看出，我们将使用以下内容:</p><ul class=""><li id="470e" class="mq mr it le b lf lg li lj mu nn mw no my np lx nq nb nc nd bi translated"><strong class="le iu"> <em class="ld"> Docker: </em> </strong>一个容器管理系统(CMS)。为了简单起见，我们使用 Docker。<a class="ae ns" href="https://www.docker.com/" rel="noopener ugc nofollow" target="_blank">https://www.docker.com/</a></li><li id="9c82" class="mq mr it le b lf ne li nf mu ng mw nh my ni lx nq nb nc nd bi translated"><strong class="le iu"> Debezium: </strong> Debezium 只不过是一个变更数据捕获(CDC)。它跟踪来自源数据库的每个事件(插入、更新、删除),并使用 Kafka Connect 将事件推送到 Kafka。它使用源数据库日志来读取每个事务，并为特定的事务创建一个事件。</li></ul><blockquote class="ky kz la"><p id="849f" class="lb lc ld le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated"><strong class="le iu">注意:</strong>对于 MySQL，我们称之为 binlog，对于 PostgreSQL，我们称之为 wal-logs(预写日志)</p></blockquote><ul class=""><li id="498f" class="mq mr it le b lf lg li lj mu nn mw no my np lx nq nb nc nd bi translated"><strong class="le iu"> <em class="ld">卡夫卡连接:</em> </strong>顾名思义，帮助 Debezium 与卡夫卡连接。</li><li id="4bd8" class="mq mr it le b lf ne li nf mu ng mw nh my ni lx nq nb nc nd bi translated"><strong class="le iu"> <em class="ld">卡夫卡:</em> </strong>卡夫卡帮助事件流和实时消费。卡夫卡和动物园管理员一起追踪这些事件。<a class="ae ns" href="https://bit.ly/2Gb9Sm7" rel="noopener ugc nofollow" target="_blank">https://bit.ly/2Gb9Sm7</a></li><li id="fe89" class="mq mr it le b lf ne li nf mu ng mw nh my ni lx nq nb nc nd bi translated"><strong class="le iu"><em class="ld">ELK(destination):</em></strong>我们考虑将 Elasticsearch 作为我们的目标数据源，默认情况下，它与 Kibana 集成在一起，用于数据可视化&amp;机器学习，这就是俗称的 elastic search+Logstash+Kibana(ELK stack)<a class="ae ns" href="https://bit.ly/36dmioe" rel="noopener ugc nofollow" target="_blank">https://bit.ly/36dmioe</a></li></ul></div><div class="ab cl nt nu hx nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="im in io ip iq"><h1 id="543b" class="ly lz it bd ma mb oa md me mf ob mh mi jz oc ka mk kc od kd mm kf oe kg mo mp bi translated"><strong class="ak"> <em class="nm"> 4:让我们开始设置它——一个 4 步流程</em> </strong></h1><p id="b84d" class="pw-post-body-paragraph lb lc it le b lf ms ju lh li mt jx lk mu nj ln lo mw nk lr ls my nl lv lw lx im bi translated"><strong class="le iu"> <em class="ld">第一步:</em> </strong>更改 Debezium 喜欢的 MySQL binlog 格式:只需进入/etc/my.cnf，基本上在 MySQL 配置文件中添加以下配置即可:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/996453850cb3432145e7b2f75cb33148.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ov9FpI4rQ2Z5bJc8c0mZtA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">/etc/my.cnf (MySQL 配置文件)</p></figure><p id="7506" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk mu lm ln lo mw lq lr ls my lu lv lw lx im bi translated"><strong class="le iu"> <em class="ld">第二步:</em> </strong>启动 Zookeeper，Kafka &amp; Kafka 使用 Docker 连接:</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="b454" class="ol lz it oh b gy om on l oo op">$ docker run -it --rm --name zookeeper -p 2181:2181 -p 2888:2888 -p 3888:3888 debezium/zookeeper<!-- --> </span><span id="f0af" class="ol lz it oh b gy oq on l oo op">$ docker run -it --rm --name kafka -p 9092:9092 --link zookeeper:zookeeper debezium/kafka:1.0</span><span id="e4af" class="ol lz it oh b gy oq on l oo op">$ docker run -it --rm --name connect -p 8083:8083 -e GROUP_ID=1 -e CONFIG_STORAGE_TOPIC=my_connect_configs -e OFFSET_STORAGE_TOPIC=my_connect_offsets -e STATUS_STORAGE_TOPIC=my_connect_statuses --link zookeeper:zookeeper --link kafka:kafka --link mysql:mysql debezium/connect:1.0</span></pre><blockquote class="ky kz la"><p id="8e62" class="lb lc ld le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated"><strong class="le iu">注:</strong>熟悉 Docker 的可以用 docker-compose.yaml，可以在这里找到:<a class="ae ns" href="https://github.com/debezium/debezium-examples/blob/master/tutorial/docker-compose-mysql.yaml" rel="noopener ugc nofollow" target="_blank">https://github . com/debezium/debezium-examples/blob/master/tutorial/</a></p></blockquote><p id="3f70" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk mu lm ln lo mw lq lr ls my lu lv lw lx im bi translated"><strong class="le iu"> <em class="ld">步骤 3(提取)</em> </strong>:我们将使用<code class="fe or os ot oh b">curl</code>向我们的 Kafka Connect 服务提交一个 JSON 请求消息，以开始使用 Debezium 从源数据库捕获事件(它需要下面的源数据库凭证):</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="903b" class="ol lz it oh b gy om on l oo op">curl -i -X POST <br/>-H "Accept:application/json" <br/>-H "Content-Type:application/json" <br/>localhost:8083/connectors/ -d <br/>'{ "name": "etl-connector", <br/>"config": {                                                 "connector.class":      "io.debezium.connector.mysql.MySqlConnector", <br/>"tasks.max": "1", <br/>"database.hostname": "&lt;mysql_host&gt;", <br/>"database.port": "3306", <br/>"database.user": "&lt;mysql_username&gt;", <br/>"database.password": "&lt;mysql_password&gt;", <br/>"database.server.id": "184054", <br/>"database.server.name": "dbserver1", <br/>"database.whitelist": "&lt;database_name&gt;", "database.history.kafka.bootstrap.servers": "kafka:9092", "database.history.kafka.topic": "dbhistory.&lt;db_name&gt;" } }'</span></pre><p id="5df0" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk mu lm ln lo mw lq lr ls my lu lv lw lx im bi translated"><strong class="le iu"> <em class="ld">第四步(变换&amp;加载)</em> </strong>:最后一步，写一个卡夫卡式的消费者。消费者只不过是一个简单的函数/代码，它将提取 Debezium 事件，对其进行转换，并将其加载到 ELK 目的地。</p><p id="cc84" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk mu lm ln lo mw lq lr ls my lu lv lw lx im bi translated">请在这里找到完整的参考源代码模板:<a class="ae ns" href="https://github.com/burhanuddinbhopalwala/etl-elasticsearch-app" rel="noopener ugc nofollow" target="_blank">https://github . com/burhanuddinbhopalwala/ETL-elastic search-app</a></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ou ov l"/></div></figure><p id="ee48" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk mu lm ln lo mw lq lr ls my lu lv lw lx im bi translated">搞定了！在本例中，我们使用批量插入进行弹性搜索。你可以从上面的源代码中看到下面的日志。</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="8aa3" class="ol lz it oh b gy om on l oo op">...<br/>2017-09-21 07:38:48,385 INFO   MySQL|dbserver1|task  Kafka version : 0.11.0.0   [org.apache.kafka.common.utils.AppInfoParser]<br/>2org.apache.kafka.clients.consumer.internals.AbstractCoordinator]<br/>2017-09-21 07:38:48,402 INFO   MySQL|dbserver1|task  Successfully joined group inventory-connector-dbhistory with generation 1   [org.apache.kafka.clients.consumer.internals.AbstractCoordinator]<br/>2017-09-21 07:38:48,403 INFO   MySQL|dbserver1|task  Setting newly assigned partitions [dbhistory.inventory-0] for group inventory-connect WorkerSourceTask{id=inventory-connector-0} finished initialization and start   [org.apache.kafka.connect.runtime.WorkerSourceTask</span><span id="8fbd" class="ol lz it oh b gy oq on l oo op">INFO -- : CREATING MASTER DB CONNECTION<br/>INFO -- : CONNECT ELASTICSEARCH<br/>INFO -- : CONNECTED KAFKA<br/>INFO -- : WAITING FOR 500 MESSAGES, RECEIVED 1, ID: 685475<br/>INFO -- : WAITING FOR 500 MESSAGES, RECEIVED 2, ID: 457548<br/>INFO -- : WAITING FOR 500 MESSAGES, RECEIVED 3, ID: 985484<br/>INFO -- : WAITING FOR 500 MESSAGES, RECEIVED 4, ID: 258547<br/>INFO -- : WAITING FOR 500 MESSAGES, RECEIVED 5, ID: 257544</span></pre><blockquote class="ky kz la"><p id="d627" class="lb lc ld le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated"><strong class="le iu">错误</strong>:如果你有任何错误，你可以去 Debezium 网站:<a class="ae ns" href="https://debezium.io/" rel="noopener ugc nofollow" target="_blank">https://debezium.io/</a>。</p></blockquote><p id="1c18" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk mu lm ln lo mw lq lr ls my lu lv lw lx im bi translated">最后，感谢阅读。我希望这篇博客对你有所帮助。一如既往地记得呼吸:)</p></div><div class="ab cl nt nu hx nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="im in io ip iq"><p id="ac5c" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk mu lm ln lo mw lq lr ls my lu lv lw lx im bi translated"><strong class="le iu"> <em class="ld">连接</em> </strong>🤝<strong class="le iu"><em class="ld">:</em>T50】</strong></p><ul class=""><li id="2d8f" class="mq mr it le b lf lg li lj mu nn mw no my np lx nq nb nc nd bi translated"><strong class="le iu"> <em class="ld">邮箱</em></strong>:<em class="ld">bbhopalw @ Gmail</em></li><li id="5419" class="mq mr it le b lf ne li nf mu ng mw nh my ni lx nq nb nc nd bi translated"><strong class="le iu"><em class="ld">Linkedin</em></strong>:<a class="ae ns" href="http://www.linkedin.com/in/bbhoaplw" rel="noopener ugc nofollow" target="_blank"><em class="ld">www.linkedin.com/in/bbhoaplw</em></a></li></ul></div><div class="ab cl nt nu hx nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="im in io ip iq"><p id="10d0" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk mu lm ln lo mw lq lr ls my lu lv lw lx im bi translated"><strong class="le iu"> <em class="ld">用于进一步阅读</em></strong>✍️<strong class="le iu"><em class="ld">:</em></strong></p><p id="edb7" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk mu lm ln lo mw lq lr ls my lu lv lw lx im bi translated"><strong class="le iu"> <em class="ld">大数据&amp;云工程博客:</em> </strong></p><ul class=""><li id="3043" class="mq mr it le b lf lg li lj mu nn mw no my np lx nq nb nc nd bi translated"><strong class="le iu">【https://medium.com/@burhanuddinbhopalwala】走向数据科学出版: </strong> <a class="ae ns" href="https://medium.com/@burhanuddinbhopalwala" rel="noopener"> <em class="ld"/></a></li></ul><p id="14ce" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk mu lm ln lo mw lq lr ls my lu lv lw lx im bi translated"><strong class="le iu"> <em class="ld">后端工程&amp;软件工程博客:</em> </strong></p><ul class=""><li id="b62b" class="mq mr it le b lf lg li lj mu nn mw no my np lx nq nb nc nd bi translated"><strong class="le iu"> <em class="ld"> DEV 社区:</em><br/></strong><a class="ae ns" href="https://dev.to/burhanuddinbhopalwala" rel="noopener ugc nofollow" target="_blank"><em class="ld">https://dev.to/burhanuddinbhopalwala</em></a></li></ul></div></div>    
</body>
</html>