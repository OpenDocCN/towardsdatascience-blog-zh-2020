# 信任:为什么人工智能伦理和 MLOps 齐头并进

> 原文：<https://towardsdatascience.com/trust-why-ai-ethics-and-mlops-go-hand-in-hand-5ff346669e57?source=collection_archive---------46----------------------->

## 对你的人工智能努力来说，可能发生的最糟糕的事情是，你最终通过良好的意图破坏了人们的生活。

![](img/da082ea5aec8913dd4bb4556c37a3720.png)

劳伦·露露·泰勒在 [Unsplash](https://unsplash.com/s/photos/trust-child?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上的照片

对你的人工智能努力来说，可能发生的最糟糕的事情是，你最终通过良好的意图破坏了人们的生活。

如果没有适当的人工智能道德实践，你聪明的人工智能应用程序可能会根据性别从工作申请中筛选最佳候选人，你可能会阻止好公民获得贷款资格，或者你的人工智能应用程序甚至可能导致孩子被不公平地从父母身边带走。

这些例子听起来有些极端，但它们都发生过，以非常糟糕的方式影响着人们的生活。然而，如果这些应用程序的创作者遵循了人工智能道德最佳实践，这些事件本来是可以避免的。

人工智能伦理有许多方面，包括:

*   管理层支持和监督
*   创造和实施最佳实践的人工智能伦理委员会
*   接受人工智能伦理培训的人工智能和商业专业人士
*   人工智能平台和工具可以自动检测和修复偏见，并向人类解释基于人工智能的建议背后的原因
*   执行偏差检测和可解释性的人工智能方法——这就是 MLOps 的用武之地

MLOps 通常被描述为结合数据科学家和运营团队的工作来管理 ML 生命周期。

我会更进一步:MLOps 结合人工智能道德最佳实践，将数据科学家和运营团队的工作结合起来，以大规模提供道德人工智能。

MLOps 涉及通过实施持续集成和持续交付(CI/CD)管道，将数据科学概念验证转移到生产前和生产中的最佳实践。你如何让这些管道合乎道德？确保您的 MLOps 最佳实践包括:

*   偏差监控
*   偏差的自动校正
*   公平性检测
*   漂移检测
*   模型可解释性

# **这就是 MLOps 和人工智能伦理如何结合起来，使人工智能的良好意图成为现实。**

阅读更多关于信任与人工智能的内容:[https://towards data science . com/how-to-不仅生存，而且领导人工智能革命-981d249f1bc7](/how-to-not-only-survive-but-lead-in-the-ai-revolution-981d249f1bc7)

你认为——请在评论中写下你需要信任人工智能做什么最重要的决定？