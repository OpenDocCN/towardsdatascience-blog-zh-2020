<html>
<head>
<title>Lady tasting tea: A Bayesian approach</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">女士品茶:贝叶斯方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/lady-tasting-tea-a-bayesian-approach-1b0b94ca1530?source=collection_archive---------38-----------------------#2020-06-03">https://towardsdatascience.com/lady-tasting-tea-a-bayesian-approach-1b0b94ca1530?source=collection_archive---------38-----------------------#2020-06-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e7da" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">假设检验的贝叶斯方法和频率方法的介绍和比较</h2></div><p id="9936" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一位女士声称，她可以通过品尝来发现一杯奶茶是先加茶还是先加牛奶。我们如何评价她的主张？通过解决这个被称为<a class="ae lb" href="https://en.wikipedia.org/wiki/Lady_tasting_tea" rel="noopener ugc nofollow" target="_blank">女士品茶</a>问题的问题，<a class="ae lb" href="https://en.wikipedia.org/wiki/Ronald_Fisher" rel="noopener ugc nofollow" target="_blank">罗纳德·费雪</a>先生首次引入了<a class="ae lb" href="https://en.wikipedia.org/wiki/Statistical_hypothesis_testing" rel="noopener ugc nofollow" target="_blank">假设检验</a>和<a class="ae lb" href="https://en.wikipedia.org/wiki/P-value" rel="noopener ugc nofollow" target="_blank"> p 值</a>的概念。</p><p id="f90a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本文中，我重温了 Fisher 的解决方案(即频率主义方法)，使用贝叶斯方法解决女士品茶的问题，并比较他们的结果。</p><h1 id="0c8a" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">问题的正式陈述</h1><p id="8068" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">给一杯奶茶，我们假设这位女士会以概率<em class="lz"> p </em>猜出正确答案(即先加茶还是先加奶)。如果她随机猜测，我们预计<em class="lz"> p </em>等于 0.5——也就是所谓的机会水平。如果她有某种神奇的技能，那么我们期望找到大于 0.5 的概率。</p><p id="b5ed" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，要决定她是否说谎，我们应该测试是否<em class="lz"> p=0.5 </em>(称为<a class="ae lb" href="https://en.wikipedia.org/wiki/Null_hypothesis" rel="noopener ugc nofollow" target="_blank">零假设</a>，通常用<em class="lz"> H₀ </em>或<em class="lz"> M₀ </em>或<em class="lz"> p &gt; 0.5 </em>(称为替代假设，用<em class="lz"> H₁ </em>或<em class="lz"> M₁ </em>表示)。为此，我们请她品尝了 N 杯奶茶，并告诉我们她的猜测。我们用 n 表示她猜对的次数。</p><p id="6553" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在的问题是:我们如何利用这些信息(即<em class="lz"> n </em>和<em class="lz"> N </em>)来决定她是否说谎？</p><h1 id="38ed" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">常客方法</h1><p id="0b5e" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">检验零假设的 frequentist 方法基于<a class="ae lb" href="https://en.wikipedia.org/wiki/P-value" rel="noopener ugc nofollow" target="_blank"> p 值</a>的计算。对于这位女士品茶的例子，p 值是假设<strong class="kh ir">这位女士在她的能力上撒了</strong>谎，在<em class="lz"> N 个</em>杯子中有超过或等于<em class="lz"> n 个</em>正确猜测的概率。如果这种概率非常小，那么很难相信她能做出这么多正确的选择仅仅是因为纯粹的偶然。因此，对于 p 值非常小的情况，我们将拒绝零假设。</p><p id="be92" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，p 值有多小将是接受女士主张的标准(即替代假设，<em class="lz"> M₁ </em>)。拒绝零假设有一些传统的阈值。下表提供了总结。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi ma"><img src="../Images/404952b2f92a152df59e5e6fb4e7ae2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IoLyZZ-BNoH4su4MzeP2FQ.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">表 1。接受替代假设的阈值</p></figure><p id="131d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在的问题是:我们应该如何计算 p 值？</p><h2 id="3333" class="mq ld iq bd le mr ms dn li mt mu dp lm ko mv mw lo ks mx my lq kw mz na ls nb bi translated">精确 p 值</h2><p id="4cda" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">对于一个任意的<em class="lz"> p </em>，在<em class="lz"> N </em>次猜测中有<em class="lz"> m </em>次正确猜测的概率是</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi nc"><img src="../Images/acbf1523412fdfe933fa28eda9260386.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T1rFM2nPokjJ4JFYyWLcuQ.png"/></div></div></figure><p id="dd7e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">给定零假设，我们有<em class="lz"> p=0.5 </em>，因此，我们可以计算 p 值为</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi nd"><img src="../Images/520e5907c7e947884bf7249430a19ced.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I5DfnagAEMVu8XLt4UMNFw.png"/></div></div></figure><h2 id="8d82" class="mq ld iq bd le mr ms dn li mt mu dp lm ko mv mw lo ks mx my lq kw mz na ls nb bi translated">近似 p 值</h2><p id="b34a" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">随着<em class="lz"> N </em>增加，根据<a class="ae lb" href="https://en.wikipedia.org/wiki/Central_limit_theorem" rel="noopener ugc nofollow" target="_blank">中心极限定理</a> ⁴.，具有<em class="lz"> m </em>个正确猜测的分布收敛到具有均值<em class="lz"> Np </em>和方差<em class="lz"> Np(1-p) — </em>的高斯分布然后，p 值可以近似为 by⁵</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi ne"><img src="../Images/97814b56cf2232bb0cce44cdaea374cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xoezNwNHirWe1V-TOjcikA.png"/></div></div></figure><p id="7bf5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中第二项是值为<em class="lz"> n </em>的高斯分布的累积密度函数(cdf)，平均值为<em class="lz"> N/2 </em>，方差为<em class="lz"> N/4 </em>。</p><h1 id="c25a" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">贝叶斯方法</h1><p id="5850" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">从贝叶斯的角度来看，无效假设和替代假设可以分别看作是两个不同的模型<em class="lz"> M₀ </em>和<em class="lz"> M₁ </em>，它们都是生成数据的候选对象。那么，贝叶斯假设检验就相当于贝叶斯模型选择:哪个模型更好地解释数据？</p><p id="1c40" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">贝叶斯模型选择的思想是在给定观察数据的情况下计算每个模型的后验概率，例如在我们的设置中的<em class="lz"> P(M₀|n) </em>。奇后验比定义为两个后验概率的比值，如下所示</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi nf"><img src="../Images/4991e8f1b80b47228d5642e3b6ae2345.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PPYPxMtbs6uYxrUquydoQQ.png"/></div></div></figure><p id="fa4a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中右边第一项称为奇数先验比，第二项称为<a class="ae lb" href="https://en.wikipedia.org/wiki/Bayes_factor" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">【贝叶斯因子】</strong> </a> ⁶ <strong class="kh ir">。</strong>如果两个模型之间没有先验偏好(即，当我们在模型上有一致的先验时)，奇数后验比等于贝叶斯因子。</p><p id="7283" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">贝叶斯因子是贝叶斯假设检验和 selection⁷.模型中的核心概念贝叶斯因子的高值告诉我们，在给定观察值的情况下，替代模型比零模型更有可能。因此，贝叶斯因子有多大将是接受这位女士的说法的标准(即替代假设，<em class="lz"> M₁ </em>)。类似于 p 值的情况，有一些传统的阈值用于拒绝零假设，总结在表 1 中。</p><p id="bc4c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在的问题是:我们应该如何计算贝叶斯因子？</p><h2 id="d724" class="mq ld iq bd le mr ms dn li mt mu dp lm ko mv mw lo ks mx my lq kw mz na ls nb bi translated">什么是<em class="ng"> M₀和 M₁？</em></h2><p id="3282" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">对于女士品茶的问题，每个模型都可以通过单次正确猜测的概率的先验分布来表征。零模型的特征是直接的，没有任何模糊:<em class="lz"> p </em>等于 0.5——先验是 0.5 处的δ分布。因此，条件概率<em class="lz"> P(n|M₀) </em>可以使用上一节提到的公式轻松计算。</p><p id="e101" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，替代车型<em class="lz"> M₁ </em>的特性并不简单。我们知道先验分布必须使其整个质量在<em class="lz"> p &gt; 0.5 </em>上，但是我们需要精确地指定先验的形式——这对于<em class="lz"> P(n|M₁) </em>的计算是必要的。那么，什么是好的先验选择呢？</p><h2 id="7adf" class="mq ld iq bd le mr ms dn li mt mu dp lm ko mv mw lo ks mx my lq kw mz na ls nb bi translated">先验选择的精确贝叶斯因子</h2><p id="c483" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">一个非常简单但直观的先验选择是在<em class="lz">【0.5，1】</em>的区间上均匀分布。使用此先验，对数贝叶斯因子可以计算为</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi nh"><img src="../Images/ed6f320c53d72b8462dae1765c2441f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pPnuoSA_msbF-DMoecbNfw.png"/></div></div></figure><p id="fa46" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们用数值计算积分。</p><h2 id="5ed6" class="mq ld iq bd le mr ms dn li mt mu dp lm ko mv mw lo ks mx my lq kw mz na ls nb bi translated">使用 BIC 的贝叶斯因子的先验独立近似</h2><p id="646e" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">可以证明 that⁸，如果先验分布在参数<em class="lz"> p </em>的最大似然(ML)估计的邻域内非零，那么随着<em class="lz"> N </em>的增加，对数条件概率 log(<em class="lz">p(n|m₁)</em>可以通过(常数 times⁹) <a class="ae lb" href="https://en.wikipedia.org/wiki/Bayesian_information_criterion" rel="noopener ugc nofollow" target="_blank">贝叶斯信息准则</a> (BIC)来估计。令人惊讶但真实的是，随着<em class="lz"> N </em>的增加，先验的影响消失了。因此，对于较大的<em class="lz"> N </em>，贝叶斯因子可以近似为(无论何时<em class="lz"> n &gt; N/2 </em>)</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi ni"><img src="../Images/e2f2a5420181d874c99bf360e5707ce2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fQfsWXRT08T-fLSM5d5uJA.png"/></div></div></figure><p id="b1f8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当<em class="lz"> n </em> ≤ <em class="lz"> N/2 </em>时，我们有 logBF( <em class="lz"> n </em> )≈-log(N)/2，但它可能不再是一个精确的近似值，因为<em class="lz"> p </em>的 ML 估计超出了先验的支持——小于<em class="lz"> 0.5 </em>。</p><h1 id="8fab" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">对比:我们什么时候相信这位女士？</h1><p id="ba83" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">对于<em class="lz"> N </em>和<em class="lz"> n </em>的不同选择，我们计算了精确和近似的 p 值和贝叶斯因子。然后，对于每个显著性水平，根据表 1，我们计算正确猜测的临界比率(即<em class="lz"> n/N </em> ) <em class="lz"> </em>，超过该比率我们拒绝零假设。图 1 示出了“临界”、“中等”、“强”和“非常强”4 种不同水平的界限。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi nj"><img src="../Images/0552d07889923633ca97f4e93a5f3c55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tu6sUzjnkBSbT0gqpqdnMg.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">图一。对于每个 N，显示了表 1 中提到的不同显著性水平的拒绝零假设的比率决策阈值。绿线对应于贝叶斯方法，紫线对应于频率主义方法。虚线是近似版本，实线是精确版本。</p></figure><p id="8ac0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里有一些有趣的信息:</p><ol class=""><li id="ba56" class="nk nl iq kh b ki kj kl km ko nm ks nn kw no la np nq nr ns bi translated">贝叶斯和频率主义方法有非常相似的拒绝零假设的标准，而贝叶斯方法更保守一些。</li><li id="020c" class="nk nl iq kh b ki nt kl nu ko nv ks nw kw nx la np nq nr ns bi translated">随着<em class="lz"> N </em>的增加，近似值变得更好，同时即使对于<em class="lz"> N </em>的小值，它们也相当精确。</li><li id="c225" class="nk nl iq kh b ki nt kl nu ko nv ks nw kw nx la np nq nr ns bi translated">当<em class="lz"> N </em>小于大约 8 或 9 时，我们无法做出任何陈述，我们需要至少 17 到 19 个样本才能做出非常有力的陈述。</li><li id="751c" class="nk nl iq kh b ki nt kl nu ko nv ks nw kw nx la np nq nr ns bi translated">正如所料，随着<em class="lz"> N </em>的增加，我们能够检测到相对于<em class="lz"> p=0.5 </em>的更小偏差。</li></ol><p id="daee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">与 frequentist 方法相反，用于假设检验的 Bayesian 方法也可以做出关于接受零假设的声明。逻辑是一样的，我们只需要看负的对数贝叶斯因子。可以找到一组相似的正确猜测的临界比率，在该比率以下，我们将接受零假设(女士说谎)。边界如图 2 所示。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi nj"><img src="../Images/20155b998cfcb775714435a459d28758.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3pR7uOLAO_0V-VA2KOsdkQ.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">图二。对于每个 N，对于表 1 中提到的不同显著性水平，显示了接受零假设的比率决定阈值。虚线是近似版本，实线是精确版本。</p></figure><p id="8a6b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">结果可以概括为三点:</p><ol class=""><li id="cd81" class="nk nl iq kh b ki kj kl km ko nm ks nn kw no la np nq nr ns bi translated">近似版本和精确版本不再那么接近，原因是<em class="lz"> p </em>的最大似然估计小于 0.5。</li><li id="0930" class="nk nl iq kh b ki nt kl nu ko nv ks nw kw nx la np nq nr ns bi translated">即使样本少于 5 个，我们也可以接受零假设。</li><li id="9249" class="nk nl iq kh b ki nt kl nu ko nv ks nw kw nx la np nq nr ns bi translated">少于 20 个样本不可能做出任何强有力的陈述，少于(至少！)60 个样本！</li></ol><h1 id="fcb3" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">结论</h1><p id="657a" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">我们从贝叶斯和频率论的角度研究了假设检验，以女性品茶为例。三个一般性结论是:</p><ol class=""><li id="f3af" class="nk nl iq kh b ki kj kl km ko nm ks nn kw no la np nq nr ns bi translated">这些方法的决策界限非常相似。</li><li id="cb64" class="nk nl iq kh b ki nt kl nu ko nv ks nw kw nx la np nq nr ns bi translated">正态分布和 BIC 的近似值相当准确，只要它们的假设得到满足。</li><li id="eb15" class="nk nl iq kh b ki nt kl nu ko nv ks nw kw nx la np nq nr ns bi translated">贝叶斯假设检验在拒绝零假设方面稍微保守一些，但是它使得陈述也接受零假设是可行的。</li></ol></div><div class="ab cl ny nz hu oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="ij ik il im in"><h1 id="4fb4" class="lc ld iq bd le lf of lh li lj og ll lm jw oh jx lo jz oi ka lq kc oj kd ls lt bi translated">承认</h1><p id="e36a" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">我非常感谢<a class="ae lb" href="https://www.linkedin.com/in/navid-ardeshir-983ab739/" rel="noopener ugc nofollow" target="_blank"> Navid Ardeshir </a>、Kian Kalhor、Mohammad Tinati 和<a class="ae lb" href="https://scholar.google.com/citations?user=GFDOkb0AAAAJ&amp;hl=en" rel="noopener ugc nofollow" target="_blank"> Parnian Kassraie </a>在过去几年中就相关主题进行了许多有益且有趣的讨论。</p><h1 id="db44" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">代码:</h1><p id="c678" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">分析的代码(用 Julia 语言编写)可以在这里找到。</p><h1 id="de5a" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">脚注:</h1><p id="3bed" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">请参阅 A. C. Davison 的《统计模型》第七章或 l .乏色曼的《所有统计学》第十章，从频率主义者的角度进一步研究假设检验。</p><p id="1e15" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">值得一提的是，frequentist 的假设检验方法的目的只是拒绝零假设，它不能对接受零假设做出任何声明。</p><p id="8a43" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该表由 B. Efron 和 T. Hastie 的<a class="ae lb" href="https://web.stanford.edu/~hastie/CASI/" rel="noopener ugc nofollow" target="_blank">“计算机时代统计推断”</a>和 L. Held 和 M. Ott 的<a class="ae lb" href="https://www.zora.uzh.ch/id/eprint/148600/" rel="noopener ugc nofollow" target="_blank">“关于 p 值和 Bayes 因子”</a>的信息组合而成。</p><p id="7c8c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">⁴ <em class="lz"> m </em>可以看作是概率为 1 的<em class="lz"> N </em>伯努利随机变量求和的输出。因此，对于大的<em class="lz"> N </em>，其分布收敛于高斯分布。</p><p id="478b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">⁵:这相当于在这些<em class="lz"> N </em>试验中使用单样本 t 检验。</p><p id="8014" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">⁶好奇的读者可以思考一下奈曼-皮尔逊引理中贝叶斯因子和似然比之间的关系。</p><p id="d8d0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">⁷看到 A. Neath 和 J. Cavanaugh 的惊人文章<a class="ae lb" href="https://onlinelibrary.wiley.com/doi/full/10.1002/wics.199?casa_token=e2HHDRri8CkAAAAA%3Aa9DQrgcaQLtDP8Wg_O3NPGhwrrN06qCGOJFcA7b8GpOhiJdE5Wzro_Jp1449XFpbYDQHpF3H-N5G3Hze" rel="noopener ugc nofollow" target="_blank">“贝叶斯信息标准:背景、推导和应用”</a>和 B. Efron 和 T. Hastie 的<a class="ae lb" href="https://web.stanford.edu/~hastie/CASI/" rel="noopener ugc nofollow" target="_blank">“计算机时代统计推断”</a>的第 13 章，以获得进一步的研究。</p><p id="3b0b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">⁸对贝叶斯模型选择的介绍见 B. Efron 和 T. Hastie 的<a class="ae lb" href="https://web.stanford.edu/~hastie/CASI/" rel="noopener ugc nofollow" target="_blank">“计算机时代统计推断”</a>第 13 章，t 检验和回归检验的贝叶斯替代方法见<a class="ae lb" href="https://link.springer.com/article/10.3758/PBR.16.2.225" rel="noopener ugc nofollow" target="_blank"> Rouder 等人(2009) </a>和<a class="ae lb" href="https://pubmed.ncbi.nlm.nih.gov/26735007/" rel="noopener ugc nofollow" target="_blank"> Rouder 等人(2012) </a>。</p><p id="eca9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">⁹常数取决于 BIC 的定义。如果我们取<a class="ae lb" href="https://web.stanford.edu/~hastie/CASI/" rel="noopener ugc nofollow" target="_blank">“计算机时代统计推断”</a>中提到的定义，常数为 1，但如果我们取<a class="ae lb" href="https://en.wikipedia.org/wiki/Bayesian_information_criterion" rel="noopener ugc nofollow" target="_blank">维基百科</a>中的定义，我们需要常数为<em class="lz"> -0.5 </em>。</p></div><div class="ab cl ny nz hu oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="ij ik il im in"><h1 id="654a" class="lc ld iq bd le lf of lh li lj og ll lm jw oh jx lo jz oi ka lq kc oj kd ls lt bi translated">附录！</h1><p id="ba24" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">几周前我发现了这首歌。这是非常可爱和有趣的，而深深的黑暗和悲伤。我真的很喜欢它，所以我决定利用它的封面显示两位女士喝茶(咖啡？)并将其链接放在本文末尾！</p><figure class="mb mc md me gt mf"><div class="bz fp l di"><div class="ok ol l"/></div></figure></div></div>    
</body>
</html>