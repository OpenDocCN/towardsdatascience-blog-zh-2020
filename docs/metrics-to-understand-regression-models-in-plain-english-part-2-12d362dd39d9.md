# 用简单的英语理解回归模型的高级度量

> 原文：<https://towardsdatascience.com/metrics-to-understand-regression-models-in-plain-english-part-2-12d362dd39d9?source=collection_archive---------30----------------------->

## ML 概念解释

## 数据科学面试官希望对这些指标有直观的理解

![](img/394fbe0e7221b2ef9a859197a49d64be.png)

马库斯·斯皮斯克在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

[在之前的一篇文章中，我讨论了 MAE、MSE、RMSE、RMSLE 和 R-Squared。](/metrics-to-understand-regression-models-in-plain-english-part-1-c902b2f4156f)这篇文章是关于*调整的 R 平方，预测的 R 平方，残差图，变量的 P 值，回归系数，F 统计量。*

# 调整后的 R 平方:

在之前的文章中，R 平方被解释为模型解释的变化量，或者回归模型与均值模型相比有多好。虽然此指标量化了模型的表现，但有一个限制，即它总是随着模型输入参数数量的增加而增加。即使通过添加一堆完全不相关的特征来随机减少误差(回归线的误差平方和)，人们也可以通过这种方式不断增加 R 平方，这基本上与统计数据有关。

为了解决这一限制，可以使用调整后的 R 平方度量，其中调整基于自由度。

![](img/dd6bcfeddb7e20ead59e509a87b14fd2.png)

来源:[www.graphpad.com](https://www.graphpad.com/guides/prism/7/curve-fitting/reg_adjustedr2equation.png)

在 R 平方公式中，如果使用每单位自由度的 SSresiduals 和 SStotal 而不是 SSresiduals & SStotal，则计算调整后的 R 平方度量。如果额外的特征被添加到具有相同的 ***n*** 的回归模型中，那么 ***n-K*** (K 是要估计的参数的数量)将下降 SSresidual 上升，总体上降低调整后的 R 平方。为了使这个额外的变量在不损害调整后的 R 平方的情况下带来一些值，它应该在一定程度上减少分子中的 SSresidual。分母是均值模型的误差平方和，因此只有 1 个参数需要估计。 ***n-K*** 就是这里的 ***n-1*** 。

什么时候用这个？如果要比较两个具有不同参数数量的模型，可使用调整后的 R 平方进行比较。或者，如果您通过添加更多的特性来迭代一个模型，这个度量可以用来查看添加的新特性是否带来了一些价值。

*如果你已经知道什么是***自由度？请跳过。**

*简单来说，它可以被认为是一个人拥有的关于数据的额外信息。如果有三个未知数和三个方程，使用线性代数可以计算出这三个未知数是什么。但是，如果三个未知数有三个以上的方程，就不可能找到完全满足所有方程的三个未知数。所以，最佳不完美解决方案的目标是。*

*为了说明，*

*![](img/3db586306e8e91cbc755570f5dc51723.png)*

*解三个方程*

*如果是这种情况，x，y，z 的值除了在这里得到的值之外，不能取其他值。对于这三个值，没有变化的自由，因此自由度为 0。如果我们引入另一个具有相同数量变量的观测值或方程，我们就引入了变异。现在，x，y，z 有一些自由度，有多少自由度？ ***n-K*** 单位。需要三个方程来获得 x、y、z 值，但任何超过这个数的数据都是自由度。*

# *预测的 R 平方:*

*这是一个很好的衡量标准，可以看出你的模型是否过度拟合，或者换句话说，你的模型是否适合新的观察。如果你听说过[交叉验证评估技术](/cross-validation-in-machine-learning-72924a69872f)，你可以看到这个指标与那个方法有多么相似。*

*最初**，残差平方和(PRESS)** 需要计算如下*

1.  *除了所有可用的数据之外，继续观察，假设总共有 n 行。*
2.  *建立一个有 n-1 行的模型*
3.  *使用该模型来预测遗漏观察目标变量*
4.  *计算观察值和预测值之间的平方差，这就是本例中的误差*
5.  *重复上述四个步骤，直到每一个数据点都作为一个测试用例，并获得 n 个错误*
6.  *将这 n 个误差相加得到压力*

*一旦我们得到压力，用它来代替 R 平方公式中回归的误差平方和，得到*

***预测 R** **= 1 —(按下/SSEM)***

*[*关于 R 平方的更多信息，查看此*](/metrics-to-understand-regression-models-in-plain-english-part-1-c902b2f4156f)*

# *残差图:*

*通常，X 轴为预测值，y 轴为误差或残差的散点图称为残差图(残差中的 X 轴也可以是任何其他自变量)。你观察到的散射看起来应该是随机的，如下图所示*

*![](img/68455b5815cd49c585eec72ba81a41e1.png)*

*(X 轴和 Y 轴上的值可以标准化，而不是实际值)*

*如果该图似乎具有定义的形状，如圆锥或曲线，我们可以说模型误差随着输入值的增加而增加。该模型的主要目标是从信号+噪声中捕获信号，并在残差图中显示噪声。噪音应该是嘈杂的。如果它有一个模式，这意味着我们没有完全捕捉信号。*

# *p 值:*

*我想可以肯定的是，您已经在回归输出中遇到了以下内容。*

*这里每个系数都有一个与之相关的 P 值。在假设检验中，P 值基本上用于拒绝/不拒绝零假设。但是它在这里做什么？*

*这通常不会被明确提及，但是假设检验也发生在这里。回归方程中的每个系数对输出/预测都有一定的影响，从无影响到最大影响不等。因此，零假设和替代假设可以表述如下*

*H0:零假设:系数(x)对产出没有影响*

*Ha:替代假设:系数(x)对输出有一些影响*

*如果 p 值小于某个阈值(0.05。0.01.0.1)，这意味着我们可以拒绝零假设，并说系数/特征/预测器对输出有一些影响。如果 p 值大于阈值，则特征在统计上不显著，因此对预测没有贡献。(*这可能是另一个小帖子，以实际了解这个 p 值是如何计算的)**

# *回归系数:*

*当你看到这样的回归方程时*

*y = a0x0 + a1x1 + a2x2 …(anxn)*

*回归系数 a0，a1，a2..对预测 y 有不同程度的贡献。当一个预测变量(x0，x1，x2…)发生单位变化，而其余预测变量保持不变时，这些系数中的每一个都代表预测值或预测值的变化。*

*举个例子，*

*y(房价)= 150 * x1(平方英尺)+ 1300 * x2(卧室数量)+ 1251 * x3(浴室数量)+ 1214*

*在这里，如果你有上面的等式来估计房价，两个相同平方英尺和相同数量的卧室但不同数量的浴室的房子将只有不同的 x3 值，房价的差异将是 1251 *(x3(home 1)-x3(home 2))。如果这个 1251 *(预测变量的差是 1，那么它是一个单位变化，1251 将代表预测值或房屋价格的变化。*

**我已经看过了常用的指标，但还有很多可以讨论的。如果有什么可以为这篇文章增色的，请评论。**

*另外，我推荐阅读 neptune.ai 的另一篇博文:[https://Neptune . ai/blog/performance-metrics-in-machine-learning-complete-guide](https://neptune.ai/blog/performance-metrics-in-machine-learning-complete-guide)*