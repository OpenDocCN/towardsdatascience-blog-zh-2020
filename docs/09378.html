<html>
<head>
<title>Early Fire detection system using deep learning and OpenCV</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于深度学习和 OpenCV 的早期火灾探测系统</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/early-fire-detection-system-using-deep-learning-and-opencv-6cb60260d54a?source=collection_archive---------3-----------------------#2020-07-05">https://towardsdatascience.com/early-fire-detection-system-using-deep-learning-and-opencv-6cb60260d54a?source=collection_archive---------3-----------------------#2020-07-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="27fb" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">深度学习| OpenCV</h2><div class=""/><div class=""><h2 id="9ad1" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">为室内和室外火灾探测创建定制的 InceptionV3 和 CNN 架构。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/6c6d3cf4ac85ab1fecb478cd446848f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JnPBvsCRc-9PBEZWLCL97w.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">伊利亚·安东内尔在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="45f1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">嵌入式处理领域的最新进展已经允许基于视觉的系统在监控期间使用卷积神经网络来检测火灾。在本文中，我们实现了两个定制的 CNN 模型，为监控视频提供了一个经济高效的火灾探测 CNN 架构。第一个模型是受 AlexNet 架构启发定制的基本 CNN 架构。我们将实现并查看它的输出和限制，并创建一个定制的 InceptionV3 模型。为了平衡效率和准确性，考虑到目标问题的性质和射击数据，对模型进行微调。我们将使用三个不同的数据集来训练我们的模型。数据集的链接可以在本文末尾找到。让我们进入编码部分。</p><h1 id="7b1e" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">1.创建定制的 CNN 架构</h1><p id="c65f" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">我们将使用 TensorFlow API Keras 构建我们的模型。让我们首先创建 ImageDataGenerator 来标记我们的数据。[1]和[2]数据集在这里用于训练。最后，我们将有 980 幅图像用于训练，239 幅图像用于验证。我们也将使用数据增强。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="82a4" class="ng mf it nc b gy nh ni l nj nk">import tensorflow as tf<br/>import keras_preprocessing<br/>from keras_preprocessing import image<br/>from keras_preprocessing.image import ImageDataGenerator</span><span id="1541" class="ng mf it nc b gy nl ni l nj nk">TRAINING_DIR = "Train"<br/>training_datagen = ImageDataGenerator(rescale = 1./255,<br/>                                  horizontal_flip=True,<br/>                                  rotation_range=30,<br/>                                  height_shift_range=0.2,<br/>                                  fill_mode='nearest')</span><span id="a1e4" class="ng mf it nc b gy nl ni l nj nk">VALIDATION_DIR = "Validation"<br/>validation_datagen = ImageDataGenerator(rescale = 1./255)<br/>train_generator = training_datagen.flow_from_directory(TRAINING_DIR,<br/>                                         target_size=(224,224),<br/>                                         class_mode='categorical',<br/>                                         batch_size = 64)</span><span id="1e81" class="ng mf it nc b gy nl ni l nj nk">validation_generator = validation_datagen.flow_from_directory(      <br/>                                           VALIDATION_DIR,<br/>                                           target_size=(224,224),<br/>                                           class_mode='categorical',<br/>                                           batch_size= 16)</span></pre><p id="e140" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在上面的代码中，应用了 3 种数据扩充技术——水平翻转、旋转和高度移动。</p><p id="912c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，我们将创建我们的 CNN 模型。该模型包含三个 Conv2D-MaxPooling2D 层对，后跟三个密集层。为了克服过度拟合的问题，我们还将增加脱落层。最后一层是 softmax 层，它将给出火灾和非火灾这两个类别的概率分布。<em class="nm">还可以在最后一层使用“sigmoid”激活函数，将类的数量改为 1。</em></p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="b70b" class="ng mf it nc b gy nh ni l nj nk">from tensorflow.keras.optimizers import Adam<br/>model = tf.keras.models.Sequential([<br/>tf.keras.layers.Conv2D(96, (11,11), strides=(4,4), activation='relu', input_shape=(224, 224, 3)), tf.keras.layers.MaxPooling2D(pool_size = (3,3), strides=(2,2)),<br/>tf.keras.layers.Conv2D(256, (5,5), activation='relu'),<br/>tf.keras.layers.MaxPooling2D(pool_size = (3,3), strides=(2,2)),<br/>tf.keras.layers.Conv2D(384, (5,5), activation='relu'),<br/>tf.keras.layers.MaxPooling2D(pool_size = (3,3), strides=(2,2)),<br/>tf.keras.layers.Flatten(),<br/>tf.keras.layers.Dropout(0.2),<br/>tf.keras.layers.Dense(2048, activation='relu'),<br/>tf.keras.layers.Dropout(0.25),<br/>tf.keras.layers.Dense(1024, activation='relu'),<br/>tf.keras.layers.Dropout(0.2),<br/>tf.keras.layers.Dense(2, activation='softmax')])</span><span id="ba04" class="ng mf it nc b gy nl ni l nj nk">model.compile(loss='categorical_crossentropy',<br/>optimizer=Adam(lr=0.0001),<br/>metrics=['acc'])</span><span id="5e1b" class="ng mf it nc b gy nl ni l nj nk">history = model.fit(<br/>train_generator,<br/>steps_per_epoch = 15,<br/>epochs = 50,<br/>validation_data = validation_generator,<br/>validation_steps = 15<br/>)</span></pre><p id="aed8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将使用 Adam 作为优化器，学习率为 0.0001。经过 50 个周期的训练，我们得到了 96.83 的训练准确率和 94.98 的验证准确率。训练和验证损失分别为 0.09 和 0.13。</p><div class="ks kt ku kv gt ab cb"><figure class="nn kw no np nq nr ns paragraph-image"><img src="../Images/2c2bf2a8c64d92b2cc6c49eff0ed50d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*jVq0XJP6XfTaTb-T5vuuXg.png"/></figure><figure class="nn kw no np nq nr ns paragraph-image"><img src="../Images/23efbf33c2b8dd16b290a536f2decedf.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*34wF1pAoFhx8KSEjDKPgYQ.png"/><p class="ld le gj gh gi lf lg bd b be z dk nt di nu nv translated">我们模型的训练过程</p></figure></div><p id="6321" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们对任何图像测试我们的模型，看看它是否能猜对。为了测试，我选择了 3 张图片，包括一张火的图片，一张非火的图片，还有一张我的图片，包含火一样的颜色和阴影。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/0098b1a6ceedab754b7d517fc2ed6632.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/1*5cFT4Eqo76G-ytlL4Sa0AQ.gif"/></div></figure><p id="5cb1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这里，我们可以看到我们上面创建的模型在对我的图像进行分类时犯了一个错误。模型有 52%的把握图像中有火。这是因为它被训练的数据集。在数据集中很少有图像教导关于室内火灾的模型。因此，该模型只知道室外火灾，因此当给定一个室内火灾一样的阴影图像时，它会出错。另一个原因是，我们的模型不是一个可以学习火的复杂特征的复杂模型。</p><p id="83e0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们接下来要做的是，使用标准的 InceptionV3 模型并对其进行定制。复杂模型能够从图像中学习复杂特征。</p><h1 id="466a" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">2.正在创建自定义的 InceptionV3 模型</h1><p id="c202" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">这次我们将使用一个不同的数据集[3]，这个数据集包含室外和室内的火灾图像。我在这个数据集中训练了我们以前的 CNN 模型，结果是它过度拟合，因为它无法处理这个相对较大的数据集，也无法从图像中学习复杂的特征。</p><p id="1493" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们从为我们定制的 InceptionV3 创建 ImageDataGenerator 开始。数据集包含 3 个类，但是对于本文，我们将只使用 2 个类。它包含 1800 幅用于训练的图像和 200 幅用于验证的图像。此外，我添加了我的起居室的 8 张图像，以在数据集中添加一些噪声。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="6769" class="ng mf it nc b gy nh ni l nj nk">import tensorflow as tf<br/>import keras_preprocessing<br/>from keras_preprocessing import image<br/>from keras_preprocessing.image import ImageDataGenerator</span><span id="182e" class="ng mf it nc b gy nl ni l nj nk">TRAINING_DIR = "Train"<br/>training_datagen = ImageDataGenerator(rescale=1./255,<br/>zoom_range=0.15,<br/>horizontal_flip=True,<br/>fill_mode='nearest')</span><span id="2c0f" class="ng mf it nc b gy nl ni l nj nk">VALIDATION_DIR = "/content/FIRE-SMOKE-DATASET/Test"<br/>validation_datagen = ImageDataGenerator(rescale = 1./255)</span><span id="fafd" class="ng mf it nc b gy nl ni l nj nk">train_generator = training_datagen.flow_from_directory(<br/>TRAINING_DIR,<br/>target_size=(224,224),<br/>shuffle = True,<br/>class_mode='categorical',<br/>batch_size = 128)</span><span id="04b4" class="ng mf it nc b gy nl ni l nj nk">validation_generator = validation_datagen.flow_from_directory(<br/>VALIDATION_DIR,<br/>target_size=(224,224),<br/>class_mode='categorical',<br/>shuffle = True,<br/>batch_size= 14)</span></pre><p id="6db5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了使训练更加准确，我们可以使用数据增强技术。在上面的代码中，应用了两种数据扩充技术——水平翻转和缩放。</p><p id="3af7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们从 Keras API 导入我们的 InceptionV3 模型。我们将在 InceptionV3 模型的顶部添加我们的层，如下所示。我们将添加一个全局空间平均池层，然后是 2 个密集层和 2 个下降层，以确保我们的模型不会过度拟合。最后，我们将为 2 个类添加一个 softmax 激活的密集层。</p><p id="ce24" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">接下来，我们将首先只训练我们添加并随机初始化的层。这里我们将使用 RMSprop 作为优化器。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="ff2a" class="ng mf it nc b gy nh ni l nj nk">from tensorflow.keras.applications.inception_v3 import InceptionV3<br/>from tensorflow.keras.preprocessing import image<br/>from tensorflow.keras.models import Model<br/>from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Dropout</span><span id="e612" class="ng mf it nc b gy nl ni l nj nk">input_tensor = Input(shape=(224, 224, 3))<br/>base_model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)</span><span id="411b" class="ng mf it nc b gy nl ni l nj nk">x = base_model.output<br/>x = GlobalAveragePooling2D()(x)<br/>x = Dense(2048, activation='relu')(x)<br/>x = Dropout(0.25)(x)<br/>x = Dense(1024, activation='relu')(x)<br/>x = Dropout(0.2)(x)<br/>predictions = Dense(2, activation='softmax')(x)</span><span id="65d6" class="ng mf it nc b gy nl ni l nj nk">model = Model(inputs=base_model.input, outputs=predictions)</span><span id="40e3" class="ng mf it nc b gy nl ni l nj nk">for layer in base_model.layers:<br/>  layer.trainable = False</span><span id="58ae" class="ng mf it nc b gy nl ni l nj nk">model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])</span><span id="3354" class="ng mf it nc b gy nl ni l nj nk">history = model.fit(<br/>train_generator,<br/>steps_per_epoch = 14,<br/>epochs = 20,<br/>validation_data = validation_generator,<br/>validation_steps = 14)</span></pre><p id="2ded" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在对我们的顶层进行 20 个时期的训练之后，我们将冻结模型的前 249 层，并训练其余的层，即前 2 个先启块。这里，我们将使用 SGD 作为优化器，学习率为 0.0001。</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="7aca" class="ng mf it nc b gy nh ni l nj nk">#To train the top 2 inception blocks, freeze the first 249 layers and unfreeze the rest.</span><span id="8dd9" class="ng mf it nc b gy nl ni l nj nk">for layer in model.layers[:249]:<br/>  layer.trainable = False</span><span id="0dfa" class="ng mf it nc b gy nl ni l nj nk">for layer in model.layers[249:]:<br/>  layer.trainable = True</span><span id="3547" class="ng mf it nc b gy nl ni l nj nk">#Recompile the model for these modifications to take effect</span><span id="fd18" class="ng mf it nc b gy nl ni l nj nk">from tensorflow.keras.optimizers import SGD<br/>model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['acc'])</span><span id="23d4" class="ng mf it nc b gy nl ni l nj nk">history = model.fit(<br/>train_generator,<br/>steps_per_epoch = 14,<br/>epochs = 10,<br/>validation_data = validation_generator,<br/>validation_steps = 14)</span></pre><p id="b85d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">经过 10 个历元的训练，我们得到的训练准确率为 98.04，验证准确率为 96.43。训练和验证损失分别为 0.063 和 0.118。</p><div class="ks kt ku kv gt ab cb"><figure class="nn kw no np nq nr ns paragraph-image"><img src="../Images/d4c82ac0cc0bd281372fa49fdc781bba.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*AkrxWoTXr_HcrU83TQGctw.png"/></figure><figure class="nn kw no np nq nr ns paragraph-image"><img src="../Images/5f8ce42465bb89d50047e079f29dccee.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*8HfU9RvK6bVRjP7ZAvq6PQ.png"/><p class="ld le gj gh gi lf lg bd b be z dk nt di nu nv translated">上述 10 个时期的训练过程</p></figure></div><p id="2d0f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们对相同的图像测试我们的模型，看看它是否能猜对。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/97c1857709b512595d8ea8122bd574d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/1*5jUV5XDhW7a-Zy5qgEjh3w.gif"/></div></figure><p id="8f35" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这一次，我们的模型可以让所有三个预测正确。96%确定我的图像不包含任何火。我用于测试的另外两张图像是:</p><div class="ks kt ku kv gt ab cb"><figure class="nn kw no np nq nr ns paragraph-image"><img src="../Images/b5bc0763f85c340b63d29a7a65a9cac7.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/1*COlr_IoyKKWZYJtztF3goQ.jpeg"/></figure><figure class="nn kw no np nq nr ns paragraph-image"><img src="../Images/311acbfb0a377d21f866e0f12bc001fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/1*HxIt2kyBhOoGmC_-FR-yiw.jpeg"/><p class="ld le gj gh gi lf lg bd b be z dk nt di nu nv translated">来自下面引用的数据集的非火灾图像</p></figure></div><h1 id="1de5" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">实时测试:</h1><p id="f10f" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">现在，我们的模型已经准备好接受真实场景的测试了。下面是使用 OpenCV 访问我们的网络摄像头并预测每一帧是否包含火焰的示例代码。如果一个帧中包含火，我们希望将该帧的颜色更改为 B&amp;W</p><pre class="ks kt ku kv gt nb nc nd ne aw nf bi"><span id="04e9" class="ng mf it nc b gy nh ni l nj nk">import cv2<br/>import numpy as np<br/>from PIL import Image<br/>import tensorflow as tf<br/>from keras.preprocessing import image</span><span id="9dfd" class="ng mf it nc b gy nl ni l nj nk">#Load the saved model<br/>model = tf.keras.models.load_model('InceptionV3.h5')<br/>video = cv2.VideoCapture(0)</span><span id="cd2a" class="ng mf it nc b gy nl ni l nj nk">while True:<br/>        _, frame = video.read()</span><span id="e0f0" class="ng mf it nc b gy nl ni l nj nk">#Convert the captured frame into RGB<br/>        im = Image.fromarray(frame, 'RGB')</span><span id="ef7a" class="ng mf it nc b gy nl ni l nj nk">#Resizing into 224x224 because we trained the model with this image size.<br/>        im = im.resize((224,224))<br/>        img_array = image.img_to_array(im)<br/>        img_array = np.expand_dims(img_array, axis=0) / 255<br/>        probabilities = model.predict(img_array)[0]<br/>        #Calling the predict method on model to predict 'fire' on the image<br/>        prediction = np.argmax(probabilities)<br/>        #if prediction is 0, which means there is fire in the frame.<br/>        if prediction == 0:<br/>                frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)<br/>                print(probabilities[prediction])</span><span id="0c42" class="ng mf it nc b gy nl ni l nj nk">cv2.imshow("Capturing", frame)<br/>        key=cv2.waitKey(1)<br/>        if key == ord('q'):<br/>                break<br/>video.release()<br/>cv2.destroyAllWindows()</span></pre><p id="3ed7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下面是上面代码的实时输出。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/1dadd71f3f7e82687ea8631888e23564.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/1*_8v2Wq1JgbTavHJJ1v8FIQ.gif"/></div></figure><p id="f972" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Github 关于这个项目的链接是<a class="ae lh" href="https://github.com/jackfrost1411/fire-detection" rel="noopener ugc nofollow" target="_blank">这里是</a>。您可以在那里找到数据集和上面的所有代码。您可以从<a class="ae lh" href="https://www.linkedin.com/in/dhruvilshah28/" rel="noopener ugc nofollow" target="_blank">这里</a>在 LinkedIn 上与我联系。如果有任何疑问，请在这里或我的 LinkedIn 收件箱中回复。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nz"><img src="../Images/25da9c3288d73f434fe4a636aca449d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qwRnYwWtoePLmmfW"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">照片由<a class="ae lh" href="https://unsplash.com/@luvlyanand?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Anandaram G </a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="ef01" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">结论</h1><p id="a904" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">使用智能摄像机，您可以识别各种可疑事件，如碰撞、医疗急救和火灾。其中，火灾是最危险的异常事件，因为不在早期阶段控制它会导致巨大的灾难，导致人类、生态和经济损失。受 CNN 巨大潜力的启发，我们可以在早期从图像或视频中检测火灾。本文展示了两个火灾探测的定制模型。考虑到 CNN 模型的火灾探测准确性，它可以帮助灾害管理团队及时管理火灾，从而防止巨大的损失。</p><h1 id="131f" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">本文使用的数据集:</h1><div class="oa ob gp gr oc od"><a href="https://www.kaggle.com/atulyakumar98/test-dataset" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd jd gy z fp oi fr fs oj fu fw jc bi translated">1.火灾探测数据集</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">标签 1 表示火灾，而 0 表示正常</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">www.kaggle.com</p></div></div><div class="om l"><div class="on l oo op oq om or lb od"/></div></div></a></div><div class="oa ob gp gr oc od"><a href="https://www.kaggle.com/phylake1337/fire-dataset" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd jd gy z fp oi fr fs oj fu fw jc bi translated">2.火灾数据集</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">用于计算机视觉任务的室外火灾图像和非火灾图像。</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">www.kaggle.com</p></div></div><div class="om l"><div class="os l oo op oq om or lb od"/></div></div></a></div><div class="oa ob gp gr oc od"><a href="https://github.com/DeepQuestAI/Fire-Smoke-Dataset" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd jd gy z fp oi fr fs oj fu fw jc bi translated">3.深水/火灾-烟雾-数据集</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">用于训练火和帧检测的图像数据集 AI 火-火焰数据集是收集用于训练的数据集…</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">github.com</p></div></div><div class="om l"><div class="ot l oo op oq om or lb od"/></div></div></a></div></div></div>    
</body>
</html>