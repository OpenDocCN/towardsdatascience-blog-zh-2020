<html>
<head>
<title>Real-Time Mask Detection with YOLOv3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 YOLOv3 进行实时掩模检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/real-time-mask-detection-with-yolov3-21ae0a1724b4?source=collection_archive---------22-----------------------#2020-05-28">https://towardsdatascience.com/real-time-mask-detection-with-yolov3-21ae0a1724b4?source=collection_archive---------22-----------------------#2020-05-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/13a4b7b3f145862128ca1ec1c8c48908.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5m8qI6Xb_mdnH36m-gfnAA.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">来源:<a class="ae kc" href="https://www.pexels.com/@cottonbro" rel="noopener ugc nofollow" target="_blank"> cottonbro </a>，via <a class="ae kc" href="https://www.pexels.com/photo/mona-lisa-with-face-mask-3957982/" rel="noopener ugc nofollow" target="_blank"> Pexels </a></p></figure><h1 id="6d19" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">介绍</h1><p id="2add" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">由于冠状病毒疫情，我们都知道 2020 年的灾难性开始。我们所知的生命已经停止。研究一直表明，基本卫生，如洗手和打喷嚏或咳嗽时捂住口鼻，会大有帮助。<strong class="ld ir">在这种场合，</strong> <strong class="ld ir">在公共场所戴口罩是必不可少的</strong>。</p><p id="0abd" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">在这篇文章中，我将谈论一个我使用<a class="ae kc" href="https://pjreddie.com/darknet/" rel="noopener ugc nofollow" target="_blank"> Darknet </a>训练的自定义对象检测器，它可以检测你是否戴了面具。Darknet 是一个用 C 和 CUDA 编写的开源神经网络框架，支持 CPU 和 GPU 计算。使用 Darknet，我训练了一个 YOLO(你只能看一次)物体探测器。</p><p id="6062" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">简单来说，YOLO 可以一次探测到图像中的所有物体。这篇文章不会讨论 YOLO 的细节。YOLO 的详细情况可以在<a class="ae kc" href="https://arxiv.org/pdf/1506.02640.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>和<a class="ae kc" href="https://arxiv.org/pdf/1804.02767.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>的文件中找到。</p><h1 id="891b" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">先决条件</h1><p id="1265" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">首先，你需要一个运行<strong class="ld ir"> Linux </strong>和<strong class="ld ir"> GPU 的系统，最好是</strong>。虽然你可以使用 AlexAB 的实现在 Windows 上设置 Darknet，但是我强烈建议你坚持使用 Linux ，因为这个过程要简单得多。好吧，我明白了，你用的是 Windows，你不想经历笔记本电脑双重启动的麻烦。不管你的选择是什么，这篇文章将帮助你的物体探测器启动并运行！除此之外，我将在 Python 3.7 中使用 OpenCV。请随意使用您已经安装的 Python 版本。确保还安装了 numpy 和 argparse python 库。</p><blockquote class="me"><p id="44ab" class="mf mg iq bd mh mi mj mk ml mm mn ly dk translated">TLDR；如果你出于任何原因不想经历训练模型的麻烦，我会帮你搞定的！跳到最后一节。</p></blockquote><h1 id="d0e9" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko mo kq kr ks mp ku kv kw mq ky kz la bi translated">安装暗网</h1><h2 id="6d9d" class="mr ke iq bd kf ms mt dn kj mu mv dp kn lm mw mx kr lq my mz kv lu na nb kz nc bi translated">对于 Linux</h2><p id="8de5" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在 Linux 上安装 Darknet 非常简单。建议看官方指南<a class="ae kc" href="https://pjreddie.com/darknet/install/" rel="noopener ugc nofollow" target="_blank">这里</a>。要开始，请打开您的终端并键入以下内容:</p><pre class="nd ne nf ng gt nh ni nj nk aw nl bi"><span id="4a02" class="mr ke iq ni b gy nm nn l no np">git clone https://github.com/pjreddie/darknet.git<br/>cd darknet<br/>make</span></pre><p id="3ccc" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">如果你有 NVIDIA 支持的 GPU，你应该考虑安装 CUDA，因为它可以大大减少培训时间。<a class="ae kc" href="https://medium.com/@exesse/cuda-10-1-installation-on-ubuntu-18-04-lts-d04f89287130" rel="noopener">这篇</a>帖子让安装过程变得简单，将为您节省大量时间。用 CUDA 和 OpenCV 编译 Darknet，只需打开<code class="fe nq nr ns ni b">/darknet/Makefile</code>，编辑<code class="fe nq nr ns ni b">GPU=1</code>、<code class="fe nq nr ns ni b">CUDNN=1</code>、<code class="fe nq nr ns ni b">OPENCV=1</code>，用<code class="fe nq nr ns ni b">make</code>命令构建软件即可。</p><h2 id="bd1e" class="mr ke iq bd kf ms mt dn kj mu mv dp kn lm mw mx kr lq my mz kv lu na nb kz nc bi translated">对于 Windows</h2><p id="ca8e" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">对于 Windows，这个过程稍微复杂一些。首先，克隆 AlexAB 的存储库:</p><pre class="nd ne nf ng gt nh ni nj nk aw nl bi"><span id="f633" class="mr ke iq ni b gy nm nn l no np">git clone <a class="ae kc" href="https://github.com/AlexeyAB/darknet.git" rel="noopener ugc nofollow" target="_blank">https://github.com/AlexeyAB/darknet.git</a></span></pre><p id="8686" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">完成后，转到存储库的需求页面:</p><p id="f541" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><a class="ae kc" href="https://github.com/AlexeyAB/darknet#requirements" rel="noopener ugc nofollow" target="_blank">https://github.com/AlexeyAB/darknet#requirements</a></p><p id="8411" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">在继续之前，确保您已经满足了<strong class="ld ir">所有要求</strong>，然后进入本节:</p><p id="50ab" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><a class="ae kc" href="https://github.com/AlexeyAB/darknet#how-to-compile-on-windows-using-cmake" rel="noopener ugc nofollow" target="_blank">https://github . com/AlexeyAB/darknet #如何使用 cmake 在 windows 上编译</a></p><p id="182f" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">选择您想要用来构建软件的方法。我建议使用<strong class="ld ir"> CMake 方法</strong>(这也是作者推荐的方法)，因为使用 vcpkg 可能会令人厌倦。</p><h1 id="ca56" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">模特培训</h1><p id="3da2" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">继续克隆我的存储库:</p><pre class="nd ne nf ng gt nh ni nj nk aw nl bi"><span id="4ad6" class="mr ke iq ni b gy nm nn l no np">git clone <a class="ae kc" href="https://github.com/rushad7/mask-detection.git" rel="noopener ugc nofollow" target="_blank">https://github.com/rushad7/mask-detection.git</a></span></pre><p id="6dd2" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">文件夹结构应该类似于:</p><pre class="nd ne nf ng gt nh ni nj nk aw nl bi"><span id="9004" class="mr ke iq ni b gy nm nn l no np">.<br/>├── annotations<br/>├── cfg<br/>├── class_names<br/>├── data<br/>│   ├── mask<br/>│   └── no-mask<br/>├── misc<br/>├── results<br/>├── weights<br/>└── yolo</span></pre><p id="3419" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><code class="fe nq nr ns ni b">data</code>文件夹包含<code class="fe nq nr ns ni b">mask</code>和<code class="fe nq nr ns ni b">no-mask</code>文件夹，它们包含戴面具和不带面具的人的图像。<code class="fe nq nr ns ni b">annotations</code>文件夹包含<code class="fe nq nr ns ni b">data</code>文件夹中的所有图像，但带有各自的<code class="fe nq nr ns ni b">.txt</code>注释文件。</p><p id="9a56" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">将<code class="fe nq nr ns ni b">/mask-detection/annotations</code>文件夹中的图像和<code class="fe nq nr ns ni b">.txt</code>文件复制到<code class="fe nq nr ns ni b">/darknet/obj/</code>文件夹中。如果您希望<strong class="ld ir">添加您的训练图像</strong>，也将它们添加到上面的文件夹中。为了给图像添加注释，我使用了<a class="ae kc" href="https://github.com/tzutalin/labelImg" rel="noopener ugc nofollow" target="_blank"> LabelImg </a>，这是一个免费且易于使用的标签工具，支持 Linux、Windows 和 Mac。在使用它的时候，只要<strong class="ld ir">确保你是以 YOLO 格式</strong>保存文件(可以通过点击保存按钮附近的按钮来设置)。同样，将<code class="fe nq nr ns ni b">/mask-detection/cfg/yolov3-custom.cfg</code>文件复制到<code class="fe nq nr ns ni b">/darknet/cfg/</code>文件夹，将<code class="fe nq nr ns ni b">/mask-detection/yolo/voc.data</code>文件复制到<code class="fe nq nr ns ni b">/darknet/cfg/</code>文件夹。</p><p id="6131" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">从终端运行<code class="fe nq nr ns ni b">/mask-detection/misc/test_train_split.py</code> python 脚本(检查脚本的用法)，它将在<code class="fe nq nr ns ni b">/mask-detector/train_test/</code>文件夹中生成<code class="fe nq nr ns ni b">train.txt</code>和<code class="fe nq nr ns ni b">test.txt</code>文件。打开<code class="fe nq nr ns ni b">/mask-detection/yolo/voc.data</code>并用上述文件的路径编辑<code class="fe nq nr ns ni b">train</code>和<code class="fe nq nr ns ni b">test</code>变量。</p><p id="fad3" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">另外，你<strong class="ld ir">可能</strong>需要修改路径，这取决于你在系统的什么地方使用了 Darknet 和 my repository。如果你使用的是 Windows 系统，你必须将路径改为 Windows ie。<code class="fe nq nr ns ni b">C:/Users/...</code></p><p id="5d97" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">最后，从<a class="ae kc" href="https://pjreddie.com/media/files/darknet53.conv.74" rel="noopener ugc nofollow" target="_blank">这里</a>下载 darknet53 模型的卷积权重，并将其放在您的 darknet 目录中。</p><p id="52bb" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">现在我们都准备好接受训练了！要开始训练模型，请转到您的 darknet 目录并键入:</p><pre class="nd ne nf ng gt nh ni nj nk aw nl bi"><span id="967a" class="mr ke iq ni b gy nm nn l no np">./darknet detector train /cfg/voc.data cfg/yolov3-custom.cfg darknet53.conv.74</span></pre><p id="6e66" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">根据您训练的图像数量以及是在 CPU 还是 GPU 上，训练时间会有所不同。我在英伟达 GTX 1050 上训练了这个数据集，花了我大约 6 个小时。</p><p id="a92b" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">附:如果你得到一个关于 CUDA 内存不足的错误，试着在<code class="fe nq nr ns ni b">yolov3-voc.cfg</code>文件中改变批量大小。</p><p id="34ec" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">现在你要做的就是等待训练结束！Darknet 每 100 次迭代保存权重，直到第 1000 次迭代，然后每 10，000 次迭代保存在<code class="fe nq nr ns ni b">/darknet/backup/</code>文件夹中。</p><h1 id="6bee" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">测试对象检测器</h1><p id="0648" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">转到<code class="fe nq nr ns ni b">/darknet/backup</code>并将最后生成的<code class="fe nq nr ns ni b">.weights</code>文件复制到我的存储库中。</p><p id="a7e5" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir">对于那些没有训练模型</strong>、<a class="ae kc" href="https://github.com/rushad7/mask-detection" rel="noopener ugc nofollow" target="_blank">的、</a>克隆我的 GitHub 库的人，我已经把我训练的权重包含在里面了。</p><p id="3fa1" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">要运行实时屏蔽检测，只需从终端运行<code class="fe nq nr ns ni b">yolo-live-cv2.py</code>脚本，如下所示:</p><pre class="nd ne nf ng gt nh ni nj nk aw nl bi"><span id="8bd7" class="mr ke iq ni b gy nm nn l no np">python yolo-live-cv2.py --yolo yolo</span></pre><p id="0d04" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">瞧啊。，你的 YOLO 面具探测器正在工作！检测器表现相当好，但大约 10 到 15 FPS。我注意到，模型的准确性可以通过增加数据的大小和质量来提高。我在 GitHub 上找到了<a class="ae kc" href="https://github.com/prajnasb/observations/tree/master/experiements/data" rel="noopener ugc nofollow" target="_blank">这个</a>数据集，可能会有帮助。</p></div></div>    
</body>
</html>