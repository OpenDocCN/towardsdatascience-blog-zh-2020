<html>
<head>
<title>Deep Learning on graphs: convolution is all you need</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">图形的深度学习:卷积是你所需要的</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-on-graphs-convolution-is-all-you-need-3c1cf8f1e715?source=collection_archive---------8-----------------------#2020-03-07">https://towardsdatascience.com/deep-learning-on-graphs-convolution-is-all-you-need-3c1cf8f1e715?source=collection_archive---------8-----------------------#2020-03-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4099" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">图卷积网络及其应用介绍</h2></div><h1 id="ec7c" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">0.动机</h1><p id="c16f" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">你有没有想过为什么深度神经网络(DNNs)比传统的机器学习模型(嗯，有时候)更好？当然也有很多例外，在表格数据上，梯度推进机器优于全连接神经网络。在DNNs的独特特征中，我不认为非线性变换使它们从传统的ML模型中脱颖而出。许多传统的ML模型，如决策树和SVM，也能够处理数据空间中的非线性。我很少遇到一个简单的全连接DNN在任何基准上都达到了最先进的性能。</p><p id="bb3f" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">真正使DNNs区别于传统ML模型的是那些支持参数共享的专用神经网络层，例如时间的递归层和空间的卷积层。有了这些专门的神经元层，DNN作为自动特征提取器蓬勃发展，以取代手工设计的特征。LSTM和GRU等递归层利用数据的时间依赖性，非常适合文本和语音，而卷积层利用空间平移不变性，适用于文本(Conv1D)、图像(Conv2D)和3D图像(Conv3D)。</p><p id="38ab" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">但是没有时间或空间结构的数据怎么办？许多类型的数据实际上都有底层的图形结构，包括:</p><ul class=""><li id="17c0" class="mb mc it lc b ld lw lg lx lj md ln me lr mf lv mg mh mi mj bi translated"><strong class="lc iu">社交</strong>:社交媒体如脸书、推特以及引文网络等。</li><li id="ae60" class="mb mc it lc b ld mk lg ml lj mm ln mn lr mo lv mg mh mi mj bi translated"><strong class="lc iu">知识</strong>:知识可以组织成图，<a class="ae mp" href="https://www.google.com/intl/bn/search/about/" rel="noopener ugc nofollow" target="_blank"> Google的知识图</a>可以更好的检索相关搜索结果；维基百科的文章也可以通过超链接连接成图。</li><li id="05ff" class="mb mc it lc b ld mk lg ml lj mm ln mn lr mo lv mg mh mi mj bi translated"><strong class="lc iu">生物学</strong>:蛋白质和基因可以分别根据它们的物理或调控相互作用组织成图，如蛋白质-蛋白质相互作用网络和基因调控网络。</li></ul><p id="5ba6" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">鉴于图的普遍性，我们是否可以开发神经网络层，利用图的拓扑来更好地表示和推断图中的节点？</p><h1 id="4a6b" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">1.图形的深度学习</h1><p id="63bc" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">2019年，图形神经网络(GNNs)正式成为NeurIPS 2019 的热门研究课题<a class="ae mp" href="https://huyenchip.com/2019/12/18/key-trends-neurips-2019.html" rel="noopener ugc nofollow" target="_blank">。但是它的起源要追溯到更早。</a></p><p id="85c2" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">一些将深度学习应用于图表的早期尝试受到了开创性的<a class="ae mp" href="https://arxiv.org/abs/1301.3781" rel="noopener ugc nofollow" target="_blank"> Word2vec模型的启发(米科洛夫<em class="mq">等人</em>)。2013) </a>在文字嵌入。我们知道，Word2vec通过使用向量表示预测大型语料库中任何给定单词的上下文，来学习低维空间中的单词嵌入。与图中的节点不同，单词是按顺序出现的，因此每个单词只有两个邻居。但在某种意义上，一个句子可以被认为是一个以单个单词为节点的<a class="ae mp" href="https://en.wikipedia.org/wiki/Path_graph" rel="noopener ugc nofollow" target="_blank">路径图</a>。如果我们能把一个图形转换成一个序列，或者多个序列，我们就可以采用自然语言处理的模型。</p><p id="b387" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">为此，<a class="ae mp" href="https://arxiv.org/pdf/1403.6652.pdf" rel="noopener ugc nofollow" target="_blank"> DeepWalk(佩罗齐<em class="mq">等人</em>。2014) </a>使用随机漫步将图展平为序列，随机漫步是一种随机过程，随机漫步通过沿着相邻节点移动来遍历图。更具体地，DeepWalk使用从截断的随机行走获得的局部信息，通过将随机行走访问的节点视为句子的等价物来学习潜在表示。同样，<a class="ae mp" href="https://arxiv.org/pdf/1607.00653.pdf" rel="noopener ugc nofollow" target="_blank">node 2 vec(Grover&amp;lesko vec 2016)</a>模拟有偏随机游走，可以高效地探索多样的邻域。</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/af1a55ad274d5017b989f0f4897240cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*bquh_S2JJnouLoQxNaykLw.png"/></div><p class="mz na gj gh gi nb nc bd b be z dk translated">由node2vec生成的les missérables同现网络，标签颜色反映同质性(图3来自<a class="ae mp" href="https://arxiv.org/pdf/1607.00653.pdf" rel="noopener ugc nofollow" target="_blank">Grover&amp;lesko vec 2016</a></p></figure><p id="4a5a" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">DeepWalk和Node2vec都以智能方式将图转换为序列，以应用神经方法对序列进行建模，但是没有开发神经机制来直接使用图中的局部邻域信息。</p><h1 id="63b8" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">2.图上的卷积</h1><p id="23e0" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">也许研究人员的动机是与图中的相邻节点共享参数，而不是采用递归，图像中常用的<strong class="lc iu">卷积</strong>现在在图上也是可能的。</p><p id="4f3d" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">根据定义，卷积是对两个函数(<em class="mq"> f </em>和<em class="mq"> g </em>)的数学运算，产生第三个函数，表示一个函数的形状如何被另一个函数修改。直观地说，你可以把卷积想象成沿着一个函数移动另一个函数，它们重叠的区域就是最终的卷积函数。</p><p id="7066" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">显然，根据一位深度学习大师和他的拙劣描述，卷积比你想象的要常见得多:</p><figure class="ms mt mu mv gt mw"><div class="bz fp l di"><div class="nd ne l"/></div></figure><figure class="ms mt mu mv gt mw"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="bc4b" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">玩笑归玩笑，我们如何将卷积应用于图形呢？</p><p id="5f3d" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">理论上，卷积运算可以在空间(欧几里德)域或频谱(频率)域中进行。图的局部邻域信息不容易在空间域表示，图的卷积是在谱域进行的。</p><p id="579a" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">根据卷积定理，全图卷积包括对图的<a class="ae mp" href="https://en.wikipedia.org/wiki/Laplacian_matrix" rel="noopener ugc nofollow" target="_blank">拉普拉斯矩阵</a>(<strong class="lc iu">)𝐿</strong>进行<a class="ae mp" rel="noopener" target="_blank" href="/pca-and-svd-explained-with-numpy-5d13b0d2a4d8">特征分解</a>，然后对图进行傅立叶变换:</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/d8f107185599b261c2e2cb7551bd4ca7.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*1YfGH6VSBDGqddTb_JlwaA.png"/></div><p class="mz na gj gh gi nb nc bd b be z dk translated">全图形卷积正向传递</p></figure><p id="ced9" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">这里，上标(I)表示神经网络层，<strong class="lc iu"> <em class="mq"> H </em> </strong>是𝑁× <em class="mq"> F_i </em>特征矩阵(<em class="mq"> N </em>:图中的节点数；<em class="mq"> F_i </em>:图层特征数量<em class="mq">I</em>)；<strong class="lc iu"><em class="mq">W</em></strong>(<em class="mq">F _ I</em>×<em class="mq">F _ { I+1 }</em>)为权重矩阵；<strong class="lc iu"><em class="mq">U</em></strong>(<em class="mq">N</em>×<em class="mq">N</em>)是<strong class="lc iu"> <em class="mq"> L. </em> </strong>的特征向量</p><p id="8be6" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">然而，计算全图卷积代价太大，于是研究人员开发了局部卷积方法来近似全图卷积。图形卷积的一般正向传递可以写成:</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/173e1ee22d0cd30edecd715e1cae6617.png" data-original-src="https://miro.medium.com/v2/resize:fit:1068/format:webp/1*yeq2V2IUZ4Wdmq0mxdhsmw.png"/></div><p class="mz na gj gh gi nb nc bd b be z dk translated">局部图形卷积正向传递</p></figure><p id="c1d6" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">其中前向传递函数<em class="mq"> f </em>采用来自前一层的特征和图邻接矩阵<strong class="lc iu"><em class="mq"/></strong>(通常是归一化的或变换的)来表示图的邻域信息，然后应用诸如ReLU的非线性激活函数𝜎(⋅来传播到下一层。</p><p id="9703" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">在这里，我们重点关注两种早期开发的近似方法:</p><ul class=""><li id="9808" class="mb mc it lc b ld lw lg lx lj md ln me lr mf lv mg mh mi mj bi translated"><a class="ae mp" href="https://arxiv.org/abs/1606.09375" rel="noopener ugc nofollow" target="_blank"> Defferrard等人<em class="mq"> NIPS </em> 2016 </a>:切比雪夫多项式基滤波器</li></ul><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/13cf4bd1d206fa96c8b953f308fab5d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*fW3ZeryJGwcKNfmhCbvdbg.png"/></div><p class="mz na gj gh gi nb nc bd b be z dk translated">切比雪夫多项式基滤波器的前向传递</p></figure><p id="887f" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">，其中<em class="mq"> T_k </em> (⋅)是<a class="ae mp" href="https://en.wikipedia.org/wiki/Chebyshev_polynomials" rel="noopener ugc nofollow" target="_blank">切比雪夫多项式函数</a>，𝑘定义了k阶邻域，𝐿̃是由其最大特征值归一化的拉普拉斯矩阵。</p><ul class=""><li id="28d5" class="mb mc it lc b ld lw lg lx lj md ln me lr mf lv mg mh mi mj bi translated"><a class="ae mp" href="https://arxiv.org/abs/1609.02907" rel="noopener ugc nofollow" target="_blank"> Kipf &amp;威灵ICLR 2017 </a>:本地汇集过滤器:</li></ul><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/d772bd4290e2a2f046e1c2af3ef953a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*ClRjPt1a8PvYdQLds4ObGQ.png"/></div><p class="mz na gj gh gi nb nc bd b be z dk translated">图卷积网络的正向传递</p></figure><p id="1455" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">，其中𝐴̂是对称归一化邻接矩阵。</p><h1 id="0c60" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">3.图卷积网的应用</h1><p id="80bc" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">由于图在许多类型的真实世界数据中普遍存在，GCNs也可以用于解决各种问题。这些应用程序可以分为以节点为中心的问题和以图形为中心的问题。</p><h2 id="08bb" class="nj kj it bd kk nk nl dn ko nm nn dp ks lj no np ku ln nq nr kw lr ns nt ky nu bi translated">3.1.GCNs的以节点为中心的应用(学习图中节点的标签或表示):</h2><ul class=""><li id="d321" class="mb mc it lc b ld le lg lh lj nv ln nw lr nx lv mg mh mi mj bi translated"><strong class="lc iu">半监督节点分类</strong>:利用图结构和节点特征来预测未标记节点的标签。示例包括在文档的引用网络上预测文档分类，其中仅标注引用网络中的文档子集(节点)。</li><li id="d96e" class="mb mc it lc b ld mk lg ml lj mm ln mn lr mo lv mg mh mi mj bi translated"><strong class="lc iu">节点表示学习:</strong>给定一个图和一个节点的特征矩阵，学习图中节点的低维表示。前面提到的DeepWalk和Node2vec都是为此应用程序开发的。</li></ul><h2 id="674e" class="nj kj it bd kk nk nl dn ko nm nn dp ks lj no np ku ln nq nr kw lr ns nt ky nu bi translated">3.2.GCNs的以图形为中心的应用(学习给定节点特征和图形结构的图形的标签或表示)</h2><ul class=""><li id="68f1" class="mb mc it lc b ld le lg lh lj nv ln nw lr nx lv mg mh mi mj bi translated"><strong class="lc iu">图形信号处理(分类/回归):</strong>给定一个具有<em class="mq"> N </em>个节点的固定图形(<em class="mq"> G </em>，以及一个特征矩阵<strong class="lc iu"><em class="mq">X</em></strong>(<em class="mq">M</em>个实例由<em class="mq"> N </em>个特征构成)，目标是学习一个函数<em class="mq"> f </em>来对那些<em class="mq"> M </em>个实例做出预测:<em class="mq"> y </em> = <em class="mq">这本质上是监督学习的一个特例，可以将特征组织成一个图。这也是图像分类的图等价:其中像素被组织成二维网格，并且卷积(CNN)被应用于空间域。图形信号处理的一个实例，由<a class="ae mp" href="https://arxiv.org/abs/1806.06975" rel="noopener ugc nofollow" target="_blank"> Dutil <em class="mq">等人</em>演示。2018 </a>，将GCNs应用于基因表达数据(由<em class="mq"> N </em>个基因组成的<em class="mq"> M </em>个样本的矩阵)，连同基因网络(由<em class="mq"> N </em>个基因组成的代表调控关系的图)一起预测单个基因的表达水平。</em></li><li id="aa4f" class="mb mc it lc b ld mk lg ml lj mm ln mn lr mo lv mg mh mi mj bi translated"><strong class="lc iu">图的表征学习</strong>:给定一组图，目标是学习图的潜在表征:<em class="mq"> f </em> ( <em class="mq"> G </em>)。小分子化合物的化学结构可以被视为图形，其中原子是节点，键是边。GCNs可用于学习分子指纹(<a class="ae mp" href="https://papers.nips.cc/paper/5954-convolutional-networks-on-graphs-for-learning-molecular-fingerprints" rel="noopener ugc nofollow" target="_blank"> Duvenaud <em class="mq"> et al </em>)。，2015 </a>)，这样的分子图表示也可以用来预测分子性质(<a class="ae mp" href="https://arxiv.org/abs/1805.10988" rel="noopener ugc nofollow" target="_blank"> Ryu <em class="mq">等</em>)。，2018 </a>)。</li></ul><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="nz oa di ob bf oc"><div class="gh gi ny"><img src="../Images/aa01400cc62fc50573a02c3f3d98a7bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*1JiFkqv_FTxUN_BuXNuRJA.png"/></div></div><p class="mz na gj gh gi nb nc bd b be z dk translated">有机化合物可以表示为由化学键(边)连接的原子(节点)的图形</p></figure><h1 id="e3b8" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">4.GCN对MNIST在图形信号处理问题上的实验</h1><p id="cb97" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><a class="ae mp" href="https://arxiv.org/abs/1606.09375" rel="noopener ugc nofollow" target="_blank"> Defferrard等人(2016) </a>在优秀的老MNIST手写数字分类数据集上设计了一个有趣的实验，以展示GCNs的效用。他们没有在原始空间中组织像素，而是创建了一个网格图，使用最近邻将像素连接到原始欧几里得空间中的邻居。然后，该2D网格图可以用于表示gcn的那些像素的相同空间信息。在这里，我复制了他们的2D网格，并对图做了一些可视化处理，以及它的邻接矩阵<strong class="lc iu"> <em class="mq"> A </em> </strong>和度矩阵<strong class="lc iu"> <em class="mq"> D </em> </strong>。请注意，网格图的四个角有一些伪像。</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="nz oa di ob bf oc"><div class="gh gi od"><img src="../Images/89eb9410fad1240a90ab908d5afce376.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zu0rRvzyowVxOh8JzOHM-A.png"/></div></div><p class="mz na gj gh gi nb nc bd b be z dk translated">GCN使用的全网格图</p></figure><p id="261a" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">他们的实验发现，在对数字进行分类时，GCN利用2D网格图获得了与经典CNN相当的性能。受此实验的启发，我非常好奇潜在的图形结构是否会影响GCN的预测性能。具体来说，我们是否可以从数据集本身创建一些有意义的图表来为标注的预测提供信息？</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="nz oa di ob bf oc"><div class="gh gi od"><img src="../Images/5a970bac4cf5dae040416c3443594510.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K2yxaqulM2JdgGCYynh80g.png"/></div></div><p class="mz na gj gh gi nb nc bd b be z dk translated">训练集中的平均数字和数字特定的图形(第2行:修剪的网格；第3行:相关图)</p></figure><p id="694c" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">因此，我创建了20个上面可视化的像素图:第一行绘制了来自训练集的平均位数；第二行是通过使用平均信号修整完整的2D网格图创建的图(数字特定的修整网格图)；第三行是根据来自各个数字的像素之间的相关性构建的图(特定于数字的像素相关性图)。</p><p id="0ae2" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">为了设置我的实验，我使用了来自<a class="ae mp" href="https://spektral.graphneural.network/" rel="noopener ugc nofollow" target="_blank">speck tral</a>的GCN层来实现我的简单GCN，它有10个图形卷积滤波器，后面是输出层。首先，我用完全相同的2D网格和没有任何图形的GCN获得了GCN的基线性能，以显示我的GCN模型确实在工作，并且与没有图形卷积机制的模型相比，实现了更好的性能:</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/31957f34eded40eb297fe61fd2f14e22.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*emFh5SZcNupamOTRxVvVSA.png"/></div><p class="mz na gj gh gi nb nc bd b be z dk translated">基线模式MNIST分类任务的测试集精度:全网格、空图的GCN模式；和全连接(FC)网络</p></figure><p id="0bb6" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">接下来，我将完整的2D网格切换到不同数字形状的修剪网格。从下表中可以看出，与全网格(0.932)相比，GCNs的性能下降了一点点(平均为0.920)，这有点出乎意料，因为神经网络现在只能看到组织成网格的像素的子集，其余的是分散的。也许让我有点惊讶的是，虽然2D网格被修剪成单个数字的形状，但GCNs并没有获得识别相应数字的卓越能力。</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="nz oa di ob bf oc"><div class="gh gi of"><img src="../Images/f78166f24abd03a68e62a2113e3aa054.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l0ZWjSHeM6lVSMpQbdwhEg.png"/></div></div><p class="mz na gj gh gi nb nc bd b be z dk translated">用修剪网格和相关图对20个GCN模式的MNIST分类的测试集精确度</p></figure><p id="c049" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">我没有修剪网格图，而是考虑从数据本身构建要素(像素)的相似度图，看看这是否能提高性能。对于任何数据集来说，这可能是一种更通用的方法，即使要素之间没有基础的图表结构。通过连接训练集中各个数字实例中具有高相关性的像素，我创建了那些特定于数字的相关图，并发现它们有助于提高GCN模型的预测精度(跨数字平均为0.935)。然而，这些数字特定的相关图也没有更好地识别它们各自的数字。</p><h2 id="7103" class="nj kj it bd kk nk nl dn ko nm nn dp ks lj no np ku ln nq nr kw lr ns nt ky nu bi translated">结论:</h2><p id="2ac6" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">GCNs对于图形信号处理问题非常有用，并且当与特征图结合时，可以潜在地提高神经网络对表格数据的适用性。</p></div><div class="ab cl og oh hx oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="im in io ip iq"><p id="beb6" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">感谢阅读！如果你有兴趣，这篇文章中描述的实验的Jupyter笔记本可以在这里找到:【https://github.com/wangz10/gcn-playground<a class="ae mp" href="https://github.com/wangz10/gcn-playground" rel="noopener ugc nofollow" target="_blank"/></p><h1 id="cf1d" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">主要参考文献:</h1><ul class=""><li id="69d2" class="mb mc it lc b ld le lg lh lj nv ln nw lr nx lv mg mh mi mj bi translated"><a class="ae mp" href="https://arxiv.org/abs/1606.09375" rel="noopener ugc nofollow" target="_blank"> Defferrard等人(2016):具有快速局部频谱滤波的图上的卷积神经网络</a></li><li id="af70" class="mb mc it lc b ld mk lg ml lj mm ln mn lr mo lv mg mh mi mj bi translated"><a class="ae mp" href="https://arxiv.org/abs/1609.02907" rel="noopener ugc nofollow" target="_blank"> Kipf &amp; Welling (2017):使用图卷积网络的半监督分类</a></li><li id="b3ce" class="mb mc it lc b ld mk lg ml lj mm ln mn lr mo lv mg mh mi mj bi translated">泽维尔·布列松:图上的卷积神经网络</li><li id="8300" class="mb mc it lc b ld mk lg ml lj mm ln mn lr mo lv mg mh mi mj bi translated"><a class="ae mp" href="https://tkipf.github.io/graph-convolutional-networks/" rel="noopener ugc nofollow" target="_blank">托马斯·基普夫:图卷积网络</a></li><li id="0d87" class="mb mc it lc b ld mk lg ml lj mm ln mn lr mo lv mg mh mi mj bi translated"><a class="ae mp" rel="noopener" target="_blank" href="/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780">如何用图卷积网络在图上做深度学习</a></li></ul></div></div>    
</body>
</html>