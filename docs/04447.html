<html>
<head>
<title>How to stabilize GAN training</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何稳定甘训练</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/wasserstein-distance-gan-began-and-progressively-growing-gan-7e099f38da96?source=collection_archive---------16-----------------------#2020-04-21">https://towardsdatascience.com/wasserstein-distance-gan-began-and-progressively-growing-gan-7e099f38da96?source=collection_archive---------16-----------------------#2020-04-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="0e3e" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">Wasserstein距离、边界平衡和渐进生长GAN</h1><p id="5675" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">gan主导图像生成和图像翻译等深度学习任务。</p><p id="dde3" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">在之前的<a class="ae lo" href="https://theaisummer.com/gan-computer-vision-object-generation/" rel="noopener ugc nofollow" target="_blank">帖子</a>中，我们已经了解了不成对的图像到图像的转换。然而，在你实现你自己的超级酷的深度GAN模型之前，有一些真正重要的概念你必须理解。</p><p id="a206" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">在这一部分，我们将看看一些基础性的工作。我们将看到<strong class="kn ir">最常见的GAN距离函数</strong>及其工作原理。然后，我们会把甘斯的训练感知为试图寻找一个两人博弈的均衡。最后，我们将看到渐进式训练的革命性成果，首次实现了<strong class="kn ir">逼真的百万像素图像分辨率</strong>。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi lp"><img src="../Images/3d6abfcc40b7225cb87b7abc817cb380.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aRxWc5RhWzIlIFQYFZ-V7A.jpeg"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">图片来自作者。希腊某地的日出。如果你的GAN模特训练得像日出一样流畅岂不是很好？</p></figure><p id="d0f3" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们将探索的研究主要解决<strong class="kn ir">模式崩溃</strong>和训练不稳定性。一些从未训练过GAN的人会很容易地认为我们总是指这两个轴。在现实生活中，<strong class="kn ir">为一个新问题训练一个大规模的GAN可能是一场噩梦</strong>。</p><p id="848b" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">如果你开始阅读和实施最新的方法，在新问题中训练新手几乎是不可能成功的。其实就像中了彩票一样。</p><blockquote class="mf mg mh"><p id="0674" class="kl km mi kn b ko lj kq kr ks lk ku kv mj ll ky kz mk lm lc ld ml ln lg lh li ij bi translated">当你离开最常见的数据集(CIFAR、MNIST、CELEBA)时，你已经陷入混乱。</p></blockquote><blockquote class="mm"><p id="bc48" class="mn mo iq bd mp mq mr ms mt mu mv li dk translated">这个评论系列的目标是像我们这样的人，他们超级有野心，但不想花所有的时间阅读该领域的所有参考书目。</p></blockquote><p id="34e7" class="pw-post-body-paragraph kl km iq kn b ko mw kq kr ks mx ku kv kw my ky kz la mz lc ld le na lg lh li ij bi translated">通常情况下，您试图在调试时直观地理解学习曲线，以便猜测可能工作得更好的超参数。但是GAN训练是如此不稳定，以至于这个过程经常是浪费时间。这个可爱的工作是第一个为甘训练计划提供广泛理论依据的工作之一。有趣的是，他们发现了分布之间所有现存距离的模式。</p><h1 id="9e8a" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">核心理念</h1><p id="e81e" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kn ir">核心思想</strong>是有效测量<strong class="kn ir">模型分布与真实分布</strong>的接近程度。因为选择如何测量距离会直接影响模型的收敛。正如我们现在所知道的，GANs可以表示来自低维流形的分布(噪声z)。</p><blockquote class="mf mg mh"><p id="6972" class="kl km mi kn b ko lj kq kr ks lk ku kv mj ll ky kz mk lm lc ld ml ln lg lh li ij bi translated">直觉上，这个距离越弱，就越容易定义从参数空间(θ-空间)到概率空间的映射，因为已经证明分布更容易收敛。</p></blockquote><p id="54ef" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们有理由要求这种连续映射。主要是因为可以定义一个连续函数来满足这个连续映射，这个连续映射给出了期望的概率空间或生成的样本。</p><p id="4ddb" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">出于这个原因，这项工作引入了一个新的距离，称为<strong class="kn ir">瓦瑟斯坦-甘</strong>。它是<a class="ae lo" href="https://jeremykun.com/2018/03/05/earthmover-distance/" rel="noopener ugc nofollow" target="_blank">推土机(EM)距离</a>的近似值，理论上表明它可以逐步优化GAN的训练。令人惊讶的是，不需要在训练期间平衡D和G，也不需要网络架构的特定设计。这样，减少了GANs中固有的模式崩溃。</p><h1 id="8d36" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">理解Wasserstein距离</h1><p id="a1e8" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在我们深入讨论拟议损失之前，让我们先来看一些数学计算。正如<a class="ae lo" href="https://en.wikipedia.org/wiki/Infimum_and_supremum" rel="noopener ugc nofollow" target="_blank"> wiki </a>中完美描述的，部分<strong class="kn ir">有序</strong>集合的子集的<strong class="kn ir">上确界</strong> ( <strong class="kn ir"> sup) </strong>是大于或等于的所有元素中的最小元素。因此，上确界也被称为最小<strong class="kn ir">上界。</strong>我个人把它称为<strong class="kn ir"> T </strong>中能找到的所有可能组合的子集的最大值。</p><p id="7e76" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">现在，让我们在GAN术语中引入这个概念。<strong class="kn ir"> T </strong>是我们可以从<strong class="kn ir"> G </strong>和<strong class="kn ir"> D </strong>中得到的所有可能的配对函数近似值f。S 将是那些函数的子集，我们将约束这些函数以使训练更好(某种正则化)。排序将自然地来自计算的损失函数。基于以上所述，我们最终可以看到Wasserstein损失函数，其测量两个分布Pr和Pθ之间的距离。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/64a219fdd3b49b8f2d9d3d939e3d5469.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*7Tt3IjKywPHAw7NBlW0whw.png"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">图片由作者提供，最初用Latex编写。</p></figure><p id="e7e8" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">这个严格的数学约束被称为K-Lipschitz函数以得到子集。但是如果它被广泛证明，你不需要知道更多的数学。但是我们如何引入这种约束呢？</p><blockquote class="mf mg mh"><p id="1e21" class="kl km mi kn b ko lj kq kr ks lk ku kv mj ll ky kz mk lm lc ld ml ln lg lh li ij bi translated">处理这种情况的一种方法是通过训练一个神经网络，使其权重位于一个<strong class="kn ir">紧凑空间中，来粗略地近似这个约束。为了达到这一点，最简单的方法就是将砝码固定在一个固定的范围内。</strong></p></blockquote><p id="f518" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">就是这样，重量剪裁如我们所愿！因此，每次梯度更新后，我们将w范围削波至[0.01，0.01]。这样，我们显著地加强了Lipschitz约束。简单，但我可以向你保证它的工作！</p><p id="b993" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">事实上，有了这个距离损失函数，它当然是连续的和可微的，我们现在可以用提出的标准<strong class="kn ir">训练<strong class="kn ir"> D </strong>直到最优</strong>，而其他距离饱和。饱和意味着鉴频器的损耗为零，生成的样本仅在某些情况下有意义。所以现在，饱和(自然导致模式崩溃)得到了缓解，我们可以在所有训练范围内使用更线性风格的梯度进行训练。让我们看一个例子来阐明这一点:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nc"><img src="../Images/61932b2905b305e465d692629c398761.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pgiKgK6DB8ixPoNx.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">图片由WGAN paper[https://arxiv.org/abs/1701.07875]提供</p></figure><p id="f8ad" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><em class="mi">WGAN标准在空间的所有部分提供了清晰的梯度。</em></p><p id="3c5f" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">为了在实践中看到所有以前的数学，我们在<a class="ae lo" href="https://github.com/The-AI-Summer/GANs-in-Computer-Vision/blob/master/snippets/wgan_code_part_3.py" rel="noopener ugc nofollow" target="_blank"> Pytorch </a>中提供了WGAN编码方案。您可以直接修改您的项目以包含此损失标准。通常在真实的<a class="ae lo" href="https://github.com/The-AI-Summer/GANs-in-Computer-Vision/blob/master/snippets/wgan_code_part_3.py" rel="noopener ugc nofollow" target="_blank">代码</a>里看比较好。值得一提的是，为了保存子集并获取上限，这意味着我们必须获取许多对。这就是为什么你会看到我们每隔一段时间就训练一次生成器，以便鉴别器得到更新。这样，我们就有了定义上确界的集合。注意，为了接近上确界，我们也可以在升级<strong class="kn ir"> D </strong>之前为<strong class="kn ir"> G </strong>做很多步骤。</p></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><p id="adf2" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">在后来的<a class="ae lo" href="https://arxiv.org/pdf/1704.00028.pdf" rel="noopener ugc nofollow" target="_blank">工作</a>中，事实证明，即使这个想法是可靠的，重量削减也是一种加强期望约束的可怕方式。使函数成为<a class="ae lo" href="http://math.univ-lyon1.fr/~begnac/articles/LipTM.pdf" rel="noopener ugc nofollow" target="_blank"> K-Lipschitz </a>的另一种方法是<strong class="kn ir">梯度惩罚</strong>。</p><blockquote class="mf mg mh"><p id="b17a" class="kl km mi kn b ko lj kq kr ks lk ku kv mj ll ky kz mk lm lc ld ml ln lg lh li ij bi translated">关键的想法是一样的:<strong class="kn ir">将重量保持在紧凑的空间</strong>。然而，他们通过<strong class="kn ir">约束评论家的输出相对于其输入的梯度规范</strong>来做到这一点。</p></blockquote><p id="87b0" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们不会讨论这篇文章，但是为了一致性和方便用户实验，我们提供了代码<a class="ae lo" href="https://github.com/The-AI-Summer/GANs-in-Computer-Vision/blob/master/snippets/wgan_code_part_3.py" rel="noopener ugc nofollow" target="_blank">作为普通wgan的改进替代方案。</a></p><h1 id="216f" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">结果和讨论</h1><p id="aec8" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在我们简短的描述之后，我们现在可以进入一些结果。看到GAN在训练中如何学习是很美好的，如下图所示:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nk"><img src="../Images/5b1a879bd219a11a0efa81d719ebef61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8HenvuQo_gpQZCQb.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">图片由WGAN paper[https://arxiv.org/abs/1701.07875]提供</p></figure><p id="a16e" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">使用DCGAN发生器的Wasserstein损耗准则。如您所见，损耗快速稳定下降，同时样品质量提高。这项工作被认为是GANs理论方面的基础，可以总结为:</p><h1 id="203d" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">TL；速度三角形定位法(dead reckoning)</h1><ul class=""><li id="dad9" class="nl nm iq kn b ko kp ks kt kw nn la no le np li nq nr ns nt bi translated">瓦瑟斯坦准则允许我们训练<strong class="kn ir"> D </strong>直到最优。当准则达到最佳值时，它只是向生成器提供一个损耗，我们可以像训练任何其他神经网络一样训练该损耗。</li><li id="5b7d" class="nl nm iq kn b ko nu ks nv kw nw la nx le ny li nq nr ns nt bi translated">我们不再需要适当地平衡<strong class="kn ir"> G </strong>和<strong class="kn ir"> D </strong>容量。</li><li id="4014" class="nl nm iq kn b ko nu ks nv kw nw la nx le ny li nq nr ns nt bi translated">Wasserstein损失导致训练<strong class="kn ir"> G </strong>的梯度质量更高。</li><li id="4eeb" class="nl nm iq kn b ko nu ks nv kw nw la nx le ny li nq nr ns nt bi translated">据观察，对于发电机和超参数调谐的架构选择，WGANs比普通gan更加鲁棒</li></ul><p id="1d97" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">的确，我们确实提高了优化过程的稳定性。然而，没有什么是零成本的。WGAN训练变得不稳定<a class="ae lo" href="https://ruder.io/optimizing-gradient-descent/" rel="noopener ugc nofollow" target="_blank">基于动量的优化器</a>如Adam，以及高学习率。这是合理的，因为标准损失是高度不稳定的，所以基于动量的优化器似乎表现更差。这就是他们使用<a class="ae lo" href="https://ruder.io/optimizing-gradient-descent/" rel="noopener ugc nofollow" target="_blank"> RMSProp </a>的原因，众所周知RMSProp在非平稳问题上表现出色。</p><p id="233b" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">最后，理解本文的一个直观方式是与层内激活函数历史上的梯度进行类比。特别是，sigmoid和tanh激活的梯度消失，有利于ReLUs，因为在整个数值范围内梯度得到了改善。</p></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="e731" class="jn jo iq bd jp jq nz js jt ju oa jw jx jy ob ka kb kc oc ke kf kg od ki kj kk bi translated"><a class="ae lo" href="https://arxiv.org/abs/1703.10717" rel="noopener ugc nofollow" target="_blank">始于</a>(边界均衡生成对抗网络2017)</h1><p id="8787" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我们经常看到，鉴频器在刚开始训练的时候进步太快。然而，平衡鉴别器和生成器的收敛是一个现有的挑战。</p><p id="2d16" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">这是第一个能够控制图像多样性和视觉质量之间的<strong class="kn ir">平衡的作品。利用简单的模型架构和标准的训练方案，获得高分辨率图像。</strong></p><p id="9683" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">为了实现这一点，作者引入了一个技巧来平衡生成器和鉴别器的训练。BEGAN的核心思想是这种新的强制平衡与描述的Wasserstein距离相结合。为此，他们训练了一个基于自动编码器的鉴别器。有趣的是，<strong class="kn ir">由于D现在是一个</strong> <a class="ae lo" href="https://theaisummer.com/Autoencoder/" rel="noopener ugc nofollow" target="_blank"> <strong class="kn ir">自动编码器，它产生图像</strong> </a> <strong class="kn ir">作为输出，而不是标量。在我们继续之前，让我们记住这一点！</strong></p><p id="ad1c" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">正如我们所见，匹配误差分布比直接匹配样本分布更有效。一个关键点是，这项工作旨在优化自动编码器损耗分布之间的Wasserstein距离，而不是样本分布之间的wasser stein距离。begin的一个优点是<strong class="kn ir">不明确要求鉴别器受K-Lipschitz约束</strong>。自动编码器通常用L1或L2范数来训练。</p><h1 id="7781" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">两人博弈均衡的形成</h1><p id="a9b7" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">为了用<a class="ae lo" href="https://www.youtube.com/watch?v=0fpUZT0Pvd4" rel="noopener ugc nofollow" target="_blank">博弈论</a>来表达问题，增加了一个平衡鉴别器和生成器的平衡项。假设我们可以理想地生成不可区分的样本。那么，它们的误差分布应该是相同的，包括它们的期望误差，也就是我们在处理每一批后测量的误差。完美平衡的训练将导致L(x)和L(G(z)的期望值相等。然而，从来不是这样！由此开始决定<strong class="kn ir">量化平衡定额</strong>，定义为:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/ea1255e3022a047c1c648037fb7f6ddd.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/format:webp/1*5QhiQFzPLFFB16EXC2rgfw.png"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">图片由作者提供，最初用Latex编写</p></figure><p id="38fb" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">这个量在网络中被建模为超参数。因此，新的训练方案涉及两个相互竞争的目标:a)自动编码真实图像和b)辨别</p><p id="8863" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">真实来自生成的图像。γ项让我们平衡这两个目标。<strong class="kn ir">γ值越低，图像多样性越低</strong>，因为鉴别器更侧重于自动编码真实图像。但是，当预期损失变化时，如何控制这个超参数呢？</p><h1 id="81a8" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">边界平衡GAN(开始)</h1><p id="5823" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">答案很简单:我们只需引入另一个落入[0，1]范围内的变量kt。这个变量将被设计来控制在训练期间放在L(G(z))上的焦点。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi of"><img src="../Images/00de117074d587b7477690d0277ae303.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g2_NYR01HWNrmwmopGyMOQ.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">图片由作者提供，最初用Latex编写</p></figure><p id="538a" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">它初始化为k0 = 0，λ_k也被定义为本研究中<strong class="kn ir"> k </strong>(使用0.001)的比例增益。这可以被视为闭环反馈控制的一种形式，其中kt在每一步都被调整，以保持所选超参数γ的期望平衡。</p><p id="221d" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">注意，在早期训练阶段，<strong class="kn ir"> G </strong>倾向于为<strong class="kn ir"> D </strong>生成易于重建的数据。同时，真实的数据分布还没有被准确地获知。基本上就是L(x) &gt; L(G(z))。与许多GANs相反，BEGAN不需要预训练，可以用Adam进行优化。最后，通过使用平衡概念，导出收敛的全局度量。</p><p id="2bdb" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">本质上，可以将收敛过程公式化为<strong class="kn ir">寻找a)最接近的重构L(x)和b)控制算法| |γL(x)—L(G(z))| |的最低绝对值</strong>。将这两项相加，我们就可以知道网络何时收敛。</p><h1 id="ab62" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">模型架构</h1><p id="f7df" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">模型架构非常简单。一个主要的区别是引入了指数线性单位而不是ReLUs。他们使用带有深度编码器和解码器的自动编码器。超参数化旨在避免典型的GAN训练技巧。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi og"><img src="../Images/6ab9ba9948b67fa013660633b896a5df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*b8igRZjN9cPyHphI.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">图片来自https://arxiv.org/abs/1703.10717报纸。模型架构</p></figure><p id="8da5" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">使用U形结构，没有<a class="ae lo" href="https://theaisummer.com/skip-connections/" rel="noopener ugc nofollow" target="_blank">跳过连接</a>。下采样被实现为核为3、步长为2的子采样卷积。另一方面，上采样是通过最近邻插值完成的。在编码器和解码器之间，经过处理的数据的张量通过完全连接的层被映射，没有任何非线性。</p><h1 id="8bcd" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">结果和讨论</h1><p id="b80d" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在下面的128x128插值图像中可以看到一些呈现的视觉效果:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi oh"><img src="../Images/45ed1a24ea145548d861b7ed8bfda94e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*F8mA5IToYoP2RGSK.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">图片由begin[https://arxiv . org/ABS/1703.10717]提供。由BEGAN生成的插值128x128图像</p></figure><p id="509f" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">值得注意的是，观察到<strong class="kn ir">变化随着γ增加，但伪像(噪声)也增加。</strong>可以看出，插值显示出良好的连续性。在第一行，头发过渡和发型被改变。同样值得注意的是，左图中的一些特征消失了(香烟)。第二行和最后一行显示简单的旋转。虽然旋转是平滑的，但是我们可以看到侧面照片没有被完美地捕捉。</p><p id="9c78" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">最后一点，使用BEGAN平衡法，网络收敛到多样的视觉愉悦的图像。这在128x128分辨率下仍然适用，只需稍加修改。训练是稳定的、快速的，并且对于小的参数变化是鲁棒的。</p><p id="658c" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">但是让我们看看<strong class="kn ir">真的高分辨率</strong>会发生什么！</p></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><h1 id="51e9" class="jn jo iq bd jp jq nz js jt ju oa jw jx jy ob ka kb kc oc ke kf kg od ki kj kk bi translated"><a class="ae lo" href="https://arxiv.org/abs/1710.10196" rel="noopener ugc nofollow" target="_blank">渐进GAN</a>(2017年为提高质量、稳定性和变化而渐进生长GAN)</h1><p id="d23e" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">到目前为止，我们所描述的方法可以产生清晰的图像。然而，它们只能以相对较小的分辨率生成图像，并且变化有限。<strong class="kn ir">分辨率低的原因之一是训练不稳定。</strong>如果您已经部署了自己的GAN模型，您可能知道由于计算空间的复杂性，大分辨率需要较小的小批量。以这种方式，时间复杂性的问题也增加了，这意味着你需要几天来训练一个GAN。</p><h1 id="7abe" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">增量增长架构</h1><p id="1b9f" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">为了解决这些问题，作者<strong class="kn ir">从低到高分辨率图像开始，逐步增加生成器和鉴别器</strong>。</p><blockquote class="mf mg mh"><p id="7503" class="kl km mi kn b ko lj kq kr ks lk ku kv mj ll ky kz mk lm lc ld ml ln lg lh li ij bi translated">直觉是，随着训练的进行，新添加的层旨在捕捉对应于高分辨率图像的更高频率的细节。</p></blockquote><p id="ee93" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">但是是什么让这种方法如此好呢？</p><p id="80e8" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">答案很简单:模型首先发现大规模(全局)结构，然后发现局部细粒度细节，而不是必须同时学习所有规模<strong class="kn ir">。增量训练自然以此为目标。值得注意的是，在整个训练过程中，所有层都是可训练的，并且网络架构是对称的(镜像)。下面描述了所描述的体系结构的图示:</strong></p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi oi"><img src="../Images/feaca232b5f2f6bbcea5e63d76932907.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*700g0Qyxsa7OnK_i.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">甘斯纸业[https://arxiv.org/abs/1710.10196]逐步增长的图像</p></figure><p id="db91" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">然而，由于不健康的竞争，模式崩溃<strong class="kn ir">仍然存在，这增加了<strong class="kn ir"> G </strong>和<strong class="kn ir"> D </strong>中误差信号的幅度。</strong></p><h1 id="5ee4" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">在过渡之间引入平滑层</h1><p id="df98" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这项工作的关键创新是新增层的<strong class="kn ir">平滑过渡</strong>到<strong class="kn ir">稳定训练</strong>。但是每次转变之后会发生什么呢？</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi oj"><img src="../Images/e6df93a52e874cd5905a9fa2bf9b3c74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Yc0msn-L8M_E7L_j.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">图片由甘斯纸业逐步成长而来，链接:<a class="ae lo" href="https://arxiv.org/abs/1710.10196" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1710.10196</a></p></figure><p id="f11e" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">真正发生的是图像分辨率翻倍。因此在<strong class="kn ir"> G </strong>和<strong class="kn ir"> D </strong>上新增一层。这就是奇迹发生的地方。在过渡期间，在较高分辨率上操作的层被用作剩余的<a class="ae lo" href="https://theaisummer.com/skip-connections/" rel="noopener ugc nofollow" target="_blank">跳跃连接</a>块，其权重(α)从0线性增加到1。一个意味着跳过连接被丢弃。</p><p id="86f8" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">所描绘的<strong class="kn ir"> toRGB </strong>块代表<strong class="kn ir">层，该层将一维特征向量投影和整形</strong>为RGB颜色。它可以被视为总是以正确的形状带来图像的连接层。并行地，来自RGB 的<strong class="kn ir">执行相反的操作，而两者都使用1 × 1卷积。真实图像被相应地缩小以匹配当前尺寸。</strong></p><blockquote class="mf mg mh"><p id="0726" class="kl km mi kn b ko lj kq kr ks lk ku kv mj ll ky kz mk lm lc ld ml ln lg lh li ij bi translated">有趣的是，在转换过程中，作者在真实图像的两种分辨率之间进行插值，以模拟GANs式学习。此外，对于渐进式GAN，大多数迭代都是在较低的分辨率下执行的，从而导致2到6次训练加速。因此，这是第一个达到百万像素分辨率的作品，即<strong class="kn ir"> 1024x1024 </strong>。</p></blockquote><p id="7544" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">与遇到协方差偏移的下游任务不同，<strong class="kn ir">gan表现出越来越大的误差信号幅度和竞争问题</strong>。为了解决这些问题，他们使用正态分布初始化和每层<a class="ae lo" href="https://mlexplained.com/2018/01/13/weight-normalization-and-layer-normalization-explained-normalization-in-deep-learning-part-2/" rel="noopener ugc nofollow" target="_blank">权重归一化</a>，通过每批动态计算的标量。这被认为是使模型学习尺度不变性。为了进一步限制信号幅度，它们还将逐像素特征向量归一化为生成器中的单位长度。<strong class="kn ir">这防止了特征地图的升级，同时不会显著恶化结果。</strong>附带的<a class="ae lo" href="https://youtu.be/G06dEcZ-QTg" rel="noopener ugc nofollow" target="_blank">视频</a>可能有助于理解设计选择。官方代码发布在TensorFlow <a class="ae lo" href="https://github.com/tkarras/progressive_growing_of_gans" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><h1 id="e119" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">TL；DR:结果和讨论</h1><p id="a611" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">结果可总结如下:</p><p id="4c5e" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">1)网络容量的逐渐增加解释了收敛速度的提高<strong class="kn ir">。</strong>直觉上，现有的层学习较低的尺度，因此在过渡之后，引入的层仅负责通过逐渐变小的尺度效果来改进表示。</p><p id="5c14" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">2)渐进增长的<strong class="kn ir">加速随着输出分辨率的增加而增加</strong>。这使得第一次能够生成1024x1024的清晰图像。</p><p id="95d4" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">3)即使实现这样的架构真的很难，并且缺少很多培训细节(即何时进行过渡以及为什么)，但它仍然是我个人崇拜的不可思议的作品。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ok"><img src="../Images/4a1111710bf7af22cab3165750d05c89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*vCW7-HzQ7GAKETZV.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">GANs渐进生长图像，百万像素分辨率，链接:<a class="ae lo" href="https://arxiv.org/abs/1710.10196" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1710.10196</a></p></figure><h1 id="fd03" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">结论</h1><p id="15b9" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在这篇文章中，我们遇到了一些至今仍在使用的最先进的训练理念。我们关注这些重要培训方面的原因是为了能够进一步展示更高级的应用程序。如果你想从游戏理论的角度来看甘斯，我们强烈建议你去看<a class="ae lo" href="https://www.youtube.com/watch?v=0fpUZT0Pvd4" rel="noopener ugc nofollow" target="_blank">达斯卡拉基斯的谈话</a>。最后，对于我们的数学爱好者来说，这里有一篇精彩的文章<a class="ae lo" href="https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html" rel="noopener ugc nofollow" target="_blank"/>，它更详细地介绍了向WGAN的过渡。</p><p id="cb66" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">总之，我们已经找到了几种方法来处理模式崩溃、大规模数据集和百万像素分辨率的增量训练。欲了解整个文章系列，请访问<a class="ae lo" href="https://theaisummer.com/" rel="noopener ugc nofollow" target="_blank">艾夏。</a></p><h1 id="0ea0" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">参考</h1><p id="1735" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">[1]阿尔乔夫斯基，m .，钦塔拉，s .，&amp;博图，L. (2017)。瓦瑟斯坦·甘。<em class="mi"> arXiv预印本arXiv:1701.07875 </em>。</p><p id="6a28" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">[2]贝特洛博士、舒姆博士和梅斯博士(2017年)。开始:边界平衡生成对抗网络。<em class="mi"> arXiv预印本arXiv:1703.10717 </em>。</p><p id="21b9" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">[3]t . Karras，t . Aila，t . Laine，s .，&amp; Lehtinen，J. (2017)。为了提高质量、稳定性和多样性而逐步种植甘蔗。<em class="mi"> arXiv预印本arXiv:1710.10196 </em>。</p><p id="4967" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">[4]达斯卡拉基斯，c .，a .，西尔格卡尼斯，v .，&amp;曾，H. (2017)。<a class="ae lo" href="https://arxiv.org/abs/1711.00141" rel="noopener ugc nofollow" target="_blank">乐观地训练甘斯</a>。<em class="mi"> arXiv预印本arXiv:1711.00141 </em>。</p><p id="0c21" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">[5]古尔拉贾尼、艾哈迈德、阿尔乔夫斯基、杜穆林和库维尔(2017年)。改进了瓦瑟斯坦·甘斯的训练。在<em class="mi">神经信息处理系统的进展</em>(第5767–5777页)。</p><p id="f5b7" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><em class="mi">原载于2020年4月21日https://theaisummer.com</em><em class="mi">T21</em><a class="ae lo" href="https://theaisummer.com/gan-computer-vision-incremental-training/" rel="noopener ugc nofollow" target="_blank">。</a></p></div></div>    
</body>
</html>