<html>
<head>
<title>PCA Explained with Dynamic Plotly Visualizations</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用动态图形可视化解释主成分分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pca-explained-with-dplotly-visualizations-7ae2f6685e01?source=collection_archive---------27-----------------------#2020-09-12">https://towardsdatascience.com/pca-explained-with-dplotly-visualizations-7ae2f6685e01?source=collection_archive---------27-----------------------#2020-09-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d59e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">PCA 和 Plotly 实用指南。</h2></div><p id="2635" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">PCA(主成分分析)是一种无监督的学习算法，它在数据集中寻找特征之间的关系。它也被广泛用作监督学习算法的预处理步骤。</p><p id="4c6b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用 PCA 的目的是通过找到尽可能解释数据集中差异的主成分来减少特征的数量。主成分是原始数据集特征的线性组合。</p><p id="2af2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">PCA 的优点是使用比原始数据集少得多的特征保留了原始数据集的大量差异。主成分是根据它们所代表的方差来排序的。</p><p id="0fca" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这篇文章中，我们将首先实现一个 PCA 算法，然后用 Plotly 创建动态可视化来更清楚地解释 PCA 背后的思想。</p><p id="e724" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇文章更实际一些。如果你想更深入地了解 PCA 实际上是如何工作的，这里有更详细的理论方面的<a class="ae le" rel="noopener" target="_blank" href="/principal-component-analysis-explained-d404c34d76e7">帖子</a>。</p><p id="3def" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> Plotly Python </strong> (plotly.py)是一个基于 plotly javascript (plotly.js)构建的开源绘图库，它提供了一个高级 API ( <strong class="kk iu"> plotly express </strong>)和一个低级 API ( <strong class="kk iu"> graph objects </strong>)来创建动态和交互式可视化。使用 plotly express，我们可以用很少的代码行创建一个很好的情节。另一方面，我们需要用图形对象编写更多的代码，但是对我们创建的内容有更多的控制。</p><p id="0b4b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们从导入相关的库开始:</p><pre class="lf lg lh li gt lj lk ll lm aw ln bi"><span id="4f41" class="lo lp it lk b gy lq lr l ls lt">import numpy as np<br/>import pandas as pd<br/>from sklearn.decomposition import PCA<br/>from sklearn.datasets import load_breast_cancer</span></pre><p id="6976" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我将使用乳腺癌数据集，它包含 30 个特征和一个指示细胞是恶性还是良性的目标变量。为了简化可视化，我将随机选择 5 个特征。</p><pre class="lf lg lh li gt lj lk ll lm aw ln bi"><span id="c84f" class="lo lp it lk b gy lq lr l ls lt">dataset = load_breast_cancer()<br/>X, y = load_breast_cancer(return_X_y = True)</span><span id="3003" class="lo lp it lk b gy lu lr l ls lt">df = pd.DataFrame(X, columns=dataset.feature_names)<br/>df = df.sample(n=5, axis=1)<br/>df['target'] = y</span><span id="f798" class="lo lp it lk b gy lu lr l ls lt">df.head()</span></pre><figure class="lf lg lh li gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi lv"><img src="../Images/f69d4edd0e3f00f65f72d6e45b28057a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XWjwqs3CobaIpI7DPAJWaA.png"/></div></div></figure></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><p id="6d98" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们创建一个 scatter_matrix 来显示特征对的散点图。我们得到了特征对在分离目标类方面有多成功的概述。</p><pre class="lf lg lh li gt lj lk ll lm aw ln bi"><span id="77ca" class="lo lp it lk b gy lq lr l ls lt">import plotly.express as px</span><span id="a16d" class="lo lp it lk b gy lu lr l ls lt">fig = px.scatter_matrix(df, dimensions=df.columns[:-1], color='target', title='Scatter Matrix of Features', height=800)</span></pre><figure class="lf lg lh li gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mk"><img src="../Images/98a86bf1773413d8a46d700bf1aae6bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jOhc6FIvO41-Se1HTF2wuw.png"/></div></div></figure><p id="e9d6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有些特征更能区分目标阶层。</p><p id="5e5a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们应用主成分分析来用 2 个主成分表示这 5 个特征。</p><pre class="lf lg lh li gt lj lk ll lm aw ln bi"><span id="7c4d" class="lo lp it lk b gy lq lr l ls lt">X = df.drop(['target'], axis=1)</span><span id="74ca" class="lo lp it lk b gy lu lr l ls lt">#Normalize<br/>from sklearn.preprocessing import StandardScaler<br/>sc = StandardScaler()<br/>X_normalized = sc.fit_transform(X)</span><span id="db99" class="lo lp it lk b gy lu lr l ls lt">#Principal components<br/>pca = PCA(n_components=2)<br/>components = pca.fit_transform(X_normalized)</span></pre><p id="fc54" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">PCA 类的一个属性是<strong class="kk iu">explained _ variance _ ratio _</strong>，顾名思义，它告诉我们每个主成分解释了总方差的多少。</p><pre class="lf lg lh li gt lj lk ll lm aw ln bi"><span id="83ba" class="lo lp it lk b gy lq lr l ls lt">pca.explained_variance_ratio_<br/>array([0.69369623, 0.20978844])</span></pre><p id="8181" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">原始数据集中 90%的方差由两个主成分解释。</p><p id="a228" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们用主成分创建一个散布矩阵。</p><pre class="lf lg lh li gt lj lk ll lm aw ln bi"><span id="7868" class="lo lp it lk b gy lq lr l ls lt">labels = {<br/>str(i): f"PC {i+1} ({var:.1f}%)" <br/>for i, var in enumerate(pca.explained_variance_ratio_ * 100)<br/>}</span><span id="b3a0" class="lo lp it lk b gy lu lr l ls lt">fig = px.scatter_matrix(components, labels=labels, dimensions=range(2), color=df['target'])</span><span id="ee33" class="lo lp it lk b gy lu lr l ls lt">fig.show()</span></pre><figure class="lf lg lh li gt lw gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/71b711c13b5d06b03d6a4dc2a63692ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/1*0lQ8nb1_2pxvG48vGIJmKg.gif"/></div></figure></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><p id="c186" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Plotly 还提供了 3D 散点图，当我们有 3 个主要组成部分时，它会很有用。为了实验 3D 图，我们首先需要再次对数据集应用 PCA 以创建 3 个主成分。</p><pre class="lf lg lh li gt lj lk ll lm aw ln bi"><span id="4048" class="lo lp it lk b gy lq lr l ls lt">pca = PCA(n_components=3)<br/>components = pca.fit_transform(X_normalized)</span></pre><p id="d6c1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们现在可以创建一个 3D 散点图。</p><pre class="lf lg lh li gt lj lk ll lm aw ln bi"><span id="9c1f" class="lo lp it lk b gy lq lr l ls lt">var = pca.explained_variance_ratio_.sum()</span><span id="6e16" class="lo lp it lk b gy lu lr l ls lt">fig = px.scatter_3d(components, x=0, y=1, z=2, color=df['target'],title=f'Total Explained Variance: {var}',<br/>labels={'0':'PC1', '1':'PC2', '2':'PC3'})</span><span id="4454" class="lo lp it lk b gy lu lr l ls lt">fig.show()</span></pre><figure class="lf lg lh li gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mm"><img src="../Images/ec48bf3cf9aa3041cd4c3719d79eedf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*S67cLjFiOr-tZHeUsVVLIg.gif"/></div></div></figure><p id="8dcc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">两个主成分的总解释方差为%90。当添加第三个主成分时，它增加了%7。</p></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><p id="1a07" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">出于演示目的，我们使用了乳腺癌数据集的子集。随意使用整个集合，看看主成分解释了总方差的多少。</p><p id="dd0a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">绘制主要成分将有助于深入了解数据集中的结构以及要素之间的关系。</p><p id="55ef" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢您的阅读。如果您有任何反馈，请告诉我。</p></div></div>    
</body>
</html>