<html>
<head>
<title>Textfeatures: Library for extracting basic features from text data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Textfeatures:用于从文本数据中提取基本特征的库</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/textfeatures-library-for-extracting-basic-features-from-text-data-f98ba90e3932?source=collection_archive---------33-----------------------#2020-07-23">https://towardsdatascience.com/textfeatures-library-for-extracting-basic-features-from-text-data-f98ba90e3932?source=collection_archive---------33-----------------------#2020-07-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/0caa3141cefc25befc38b8991ddb998c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yPZap7X4nhqiLrkQZe-6wQ.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">弗兰基·查马基在<a class="ae kf" href="https://unsplash.com/s/photos/machine-learning?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="03c8" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">简介:文本特征</h1><p id="d847" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">当我们处理文本数据时，我们总是关心数据特征、数据的预处理以及更可能的预测。为了改进我们的模型，理解数据并在数据中找到更有趣的特征是很重要的，比如标签、链接等等。</p><h2 id="8f67" class="mc kh it bd ki md me dn km mf mg dp kq lp mh mi ku lt mj mk ky lx ml mm lc mn bi translated">什么是文本特征？</h2><p id="e664" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这是一个 python 包，可以帮助你从文本数据中提取基本特征，如标签、停用词、数字，这将帮助你理解数据，更有效地改进你的模型。</p><blockquote class="mo mp mq"><p id="fe0d" class="le lf mr lg b lh ms lj lk ll mt ln lo mu mv lr ls mw mx lv lw my mz lz ma mb im bi translated"><strong class="lg iu">函数调用结构:</strong></p><p id="2549" class="le lf mr lg b lh ms lj lk ll mt ln lo mu mv lr ls mw mx lv lw my mz lz ma mb im bi translated"><strong class="lg iu"> function_name(dataframe，“text_column”，“new _ column”)</strong></p><p id="47d0" class="le lf mr lg b lh ms lj lk ll mt ln lo mu mv lr ls mw mx lv lw my mz lz ma mb im bi translated">在哪里，</p><p id="f334" class="le lf mr lg b lh ms lj lk ll mt ln lo mu mv lr ls mw mx lv lw my mz lz ma mb im bi translated"><strong class="lg iu">数据帧:- </strong>数据帧的名称</p><p id="b7f9" class="le lf mr lg b lh ms lj lk ll mt ln lo mu mv lr ls mw mx lv lw my mz lz ma mb im bi translated"><strong class="lg iu"> text_column:- </strong>要从中提取特征的列的名称。</p><p id="611d" class="le lf mr lg b lh ms lj lk ll mt ln lo mu mv lr ls mw mx lv lw my mz lz ma mb im bi translated"><strong class="lg iu"> new_column:- </strong>通过从 text_column 提取特征而导出的新列。</p></blockquote><h1 id="54e4" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">textfeatures 将为您提供什么服务？</h1><p id="16fa" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="lg iu"> 1。word_count():- </strong>给出文本数据中的总字数。</p><p id="5492" class="pw-post-body-paragraph le lf it lg b lh ms lj lk ll mt ln lo lp mv lr ls lt mx lv lw lx mz lz ma mb im bi translated"><strong class="lg iu"> 2。char_count():- </strong>给出字符数。</p><p id="8044" class="pw-post-body-paragraph le lf it lg b lh ms lj lk ll mt ln lo lp mv lr ls lt mx lv lw lx mz lz ma mb im bi translated"><strong class="lg iu"> 3。avg_word_length():- </strong>给出平均单词长度。</p><p id="1365" class="pw-post-body-paragraph le lf it lg b lh ms lj lk ll mt ln lo lp mv lr ls lt mx lv lw lx mz lz ma mb im bi translated"><strong class="lg iu"> 4。</strong> :-给出停用词的计数。</p><p id="46e8" class="pw-post-body-paragraph le lf it lg b lh ms lj lk ll mt ln lo lp mv lr ls lt mx lv lw lx mz lz ma mb im bi translated"><strong class="lg iu"> 5。停用字词()</strong> :-从文本数据中提取停用字词。</p><p id="2bf3" class="pw-post-body-paragraph le lf it lg b lh ms lj lk ll mt ln lo lp mv lr ls lt mx lv lw lx mz lz ma mb im bi translated"><strong class="lg iu"> 6。hashtags_count():- </strong>给出 hashtags 的计数。</p><p id="411a" class="pw-post-body-paragraph le lf it lg b lh ms lj lk ll mt ln lo lp mv lr ls lt mx lv lw lx mz lz ma mb im bi translated"><strong class="lg iu"> 7。hashtags():- </strong>从文本数据中提取 hashtags。</p><p id="1124" class="pw-post-body-paragraph le lf it lg b lh ms lj lk ll mt ln lo lp mv lr ls lt mx lv lw lx mz lz ma mb im bi translated">8。links_count():- 给出文本数据中嵌入的链接数。</p><p id="6376" class="pw-post-body-paragraph le lf it lg b lh ms lj lk ll mt ln lo lp mv lr ls lt mx lv lw lx mz lz ma mb im bi translated"><strong class="lg iu"> 9。links():- </strong>从文本数据中提取链接。</p><p id="b511" class="pw-post-body-paragraph le lf it lg b lh ms lj lk ll mt ln lo lp mv lr ls lt mx lv lw lx mz lz ma mb im bi translated"><strong class="lg iu"> 10。numeric_count():- </strong>给出数字的位数。</p><p id="6814" class="pw-post-body-paragraph le lf it lg b lh ms lj lk ll mt ln lo lp mv lr ls lt mx lv lw lx mz lz ma mb im bi translated"><strong class="lg iu"> 11。user_mentions_count():- </strong>从文本数据中给出用户提及次数。</p><p id="adcf" class="pw-post-body-paragraph le lf it lg b lh ms lj lk ll mt ln lo lp mv lr ls lt mx lv lw lx mz lz ma mb im bi translated"><strong class="lg iu"> 12。user_mentions():- </strong>从文本数据中提取用户提及。</p><p id="83a0" class="pw-post-body-paragraph le lf it lg b lh ms lj lk ll mt ln lo lp mv lr ls lt mx lv lw lx mz lz ma mb im bi translated"><strong class="lg iu"> 13。clean():- </strong>给出去除文本数据中不必要材料后的预处理数据。</p><p id="4998" class="pw-post-body-paragraph le lf it lg b lh ms lj lk ll mt ln lo lp mv lr ls lt mx lv lw lx mz lz ma mb im bi translated"><strong class="lg iu">让我们了解一下 textfeatures 包提供的语法和功能。</strong></p><p id="1835" class="pw-post-body-paragraph le lf it lg b lh ms lj lk ll mt ln lo lp mv lr ls lt mx lv lw lx mz lz ma mb im bi translated">我们使用的是 Kaggle 上的<a class="ae kf" href="https://www.kaggle.com/ameyband/covid19-tweets" rel="noopener ugc nofollow" target="_blank">新冠肺炎推特数据集</a>。</p><p id="8a8b" class="pw-post-body-paragraph le lf it lg b lh ms lj lk ll mt ln lo lp mv lr ls lt mx lv lw lx mz lz ma mb im bi translated">安装 textfeatures 包的最佳方式是使用 pip。</p><pre class="na nb nc nd gt ne nf ng nh aw ni bi"><span id="8d5f" class="mc kh it nf b gy nj nk l nl nm">pip install textfeatures</span></pre><p id="6d8e" class="pw-post-body-paragraph le lf it lg b lh ms lj lk ll mt ln lo lp mv lr ls lt mx lv lw lx mz lz ma mb im bi translated">让我们导入构建模型所需的必要库。</p><pre class="na nb nc nd gt ne nf ng nh aw ni bi"><span id="7255" class="mc kh it nf b gy nj nk l nl nm">import textfeatures as tf<br/>import pandas as pd</span></pre><p id="11e2" class="pw-post-body-paragraph le lf it lg b lh ms lj lk ll mt ln lo lp mv lr ls lt mx lv lw lx mz lz ma mb im bi translated">使用 pandas 读取数据 CSV 文件，并用数据框定义它。预览数据集。</p><pre class="na nb nc nd gt ne nf ng nh aw ni bi"><span id="7e51" class="mc kh it nf b gy nj nk l nl nm">#enconding is applicable for this dataset.<br/>df = pd.read_csv("COVID-19_Tweets.csv",encoding="latin")<br/>df.head()</span></pre><figure class="na nb nc nd gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nn"><img src="../Images/99e9f079a08e3ea4cd592e902cc5e142.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4t8KHh4gl5I0Stp5et9Khg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图 1:数据集预览</p></figure><h2 id="f7a6" class="mc kh it bd ki md me dn km mf mg dp kq lp mh mi ku lt mj mk ky lx ml mm lc mn bi translated">1.字数()</h2><ul class=""><li id="e338" class="no np it lg b lh li ll lm lp nq lt nr lx ns mb nt nu nv nw bi translated">这是特征提取的首要任务。</li><li id="9df5" class="no np it lg b lh nx ll ny lp nz lt oa lx ob mb nt nu nv nw bi translated">我们计算数据集中每一行的字数。</li></ul><pre class="na nb nc nd gt ne nf ng nh aw ni bi"><span id="9d10" class="mc kh it nf b gy nj nk l nl nm">tf.word_count(df,"Tweets","word_cnt")<br/>df[["Tweets","word_cnt"]].head()</span></pre><figure class="na nb nc nd gt ju gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/ce6536f9ad707eeb97389c3c08c0cc48.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/format:webp/1*NZzulmVZjD2B1TGt_YxNww.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图 2:字数</p></figure><h2 id="563c" class="mc kh it bd ki md me dn km mf mg dp kq lp mh mi ku lt mj mk ky lx ml mm lc mn bi translated">2.char_count()</h2><ul class=""><li id="356c" class="no np it lg b lh li ll lm lp nq lt nr lx ns mb nt nu nv nw bi translated">我们计算数据集中每一行的字符数。</li><li id="91fd" class="no np it lg b lh nx ll ny lp nz lt oa lx ob mb nt nu nv nw bi translated">这可以通过计算推文的长度来实现。</li></ul><pre class="na nb nc nd gt ne nf ng nh aw ni bi"><span id="703f" class="mc kh it nf b gy nj nk l nl nm">tf.char_count(df,"Tweets","char_len")<br/>df[["Tweets","char_len"]].head()</span></pre><figure class="na nb nc nd gt ju gh gi paragraph-image"><div class="gh gi od"><img src="../Images/ad2b10194fdcd4da033af634d097aefb.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*hATn0zIr3RR7tFOxKKPUFg.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图 3:字符长度</p></figure><h2 id="5413" class="mc kh it bd ki md me dn km mf mg dp kq lp mh mi ku lt mj mk ky lx ml mm lc mn bi translated">3.平均单词长度()</h2><ul class=""><li id="916f" class="no np it lg b lh li ll lm lp nq lt nr lx ns mb nt nu nv nw bi translated">为了更好地理解这些数据，我们将找出平均单词长度。</li><li id="0576" class="no np it lg b lh nx ll ny lp nz lt oa lx ob mb nt nu nv nw bi translated">我们简单地计算出所有单词的长度之和，然后除以推文的总长度。</li></ul><pre class="na nb nc nd gt ne nf ng nh aw ni bi"><span id="bed8" class="mc kh it nf b gy nj nk l nl nm">tf.avg_word_length(df,"Tweets","avg_wrd_length")<br/>df[["Tweets","avg_wrd_length"]].head()</span></pre><figure class="na nb nc nd gt ju gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/03b91bb18ed6330ae0d47a9329c04aa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*MTrtNKdNJj2o-NjRdYwNmA.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图 4:平均单词长度</p></figure><h2 id="88c5" class="mc kh it bd ki md me dn km mf mg dp kq lp mh mi ku lt mj mk ky lx ml mm lc mn bi translated">4.停用字词计数()</h2><ul class=""><li id="b8d9" class="no np it lg b lh li ll lm lp nq lt nr lx ns mb nt nu nv nw bi translated">为了处理任何自然语言处理问题，我们总是试图清理我们的数据。所以找到停用词是首要任务。</li><li id="ba53" class="no np it lg b lh nx ll ny lp nz lt oa lx ob mb nt nu nv nw bi translated">我们将找到文本数据中出现的停用词的计数。</li></ul><pre class="na nb nc nd gt ne nf ng nh aw ni bi"><span id="ea64" class="mc kh it nf b gy nj nk l nl nm">tf.stopwords_count(df,"Tweets","stopwords_cnt")<br/>df[["Tweets","stopwords_cnt"]].head()</span></pre><figure class="na nb nc nd gt ju gh gi paragraph-image"><div class="gh gi of"><img src="../Images/eef5401e8a29ff3fa8e5ff194d1d0a58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*o5SNx-4pUxwmLdavjNbq_g.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图 5:停用词计数</p></figure><h2 id="3e41" class="mc kh it bd ki md me dn km mf mg dp kq lp mh mi ku lt mj mk ky lx ml mm lc mn bi translated">5.停用词()</h2><ul class=""><li id="169d" class="no np it lg b lh li ll lm lp nq lt nr lx ns mb nt nu nv nw bi translated">我们在文本数据中找到停用词，并将其存储在一个列表中，以便您可以找到数据中的干扰，并使其更具交互性。</li></ul><pre class="na nb nc nd gt ne nf ng nh aw ni bi"><span id="baaf" class="mc kh it nf b gy nj nk l nl nm">tf.stopwords(df,"Tweets","stopwords")<br/>df[["Tweets","stopwords"]].head()</span></pre><figure class="na nb nc nd gt ju gh gi paragraph-image"><div class="gh gi og"><img src="../Images/9046a09a2cec95fa7ea30ed246d8f5b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*ttFcYludAkH_QnM08Ue47A.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图 6:停用词</p></figure><h2 id="95ee" class="mc kh it bd ki md me dn km mf mg dp kq lp mh mi ku lt mj mk ky lx ml mm lc mn bi translated">6.hashtags_count()</h2><ul class=""><li id="6ec8" class="no np it lg b lh li ll lm lp nq lt nr lx ns mb nt nu nv nw bi translated">找出数据中的标签是最有趣的任务，因为标签帮助我们获得最大的观众，这样你的帖子或推文也会得到最大的响应。</li><li id="5d8e" class="no np it lg b lh nx ll ny lp nz lt oa lx ob mb nt nu nv nw bi translated">我们将首先计算标签的数量。</li></ul><pre class="na nb nc nd gt ne nf ng nh aw ni bi"><span id="f0bf" class="mc kh it nf b gy nj nk l nl nm">tf.hashtags_count(df,"Tweets","hashtags_count")<br/>df[["Tweets","hashtags_count"]].head()</span></pre><figure class="na nb nc nd gt ju gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/22aa2a7ddf4be2c863308ddfd49207b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*5OI4bVslDiU41N552DTNxg.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图 7:标签数</p></figure><h2 id="90c5" class="mc kh it bd ki md me dn km mf mg dp kq lp mh mi ku lt mj mk ky lx ml mm lc mn bi translated">7.标签()</h2><ul class=""><li id="01e2" class="no np it lg b lh li ll lm lp nq lt nr lx ns mb nt nu nv nw bi translated">现在，我们将提取标签并将其存储到列表中，以便对数据进行更多的预处理和可视化。</li></ul><pre class="na nb nc nd gt ne nf ng nh aw ni bi"><span id="8ee0" class="mc kh it nf b gy nj nk l nl nm">tf.hashtags(df,"Tweets","hashtags")<br/>df[["Tweets","hashtags"]].head()</span></pre><figure class="na nb nc nd gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oi"><img src="../Images/ec3daac463cf80c1a5cb1151969d13d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*at6owk7cSGJUF-GP8lZM-Q.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图 8:标签</p></figure><h2 id="ea6a" class="mc kh it bd ki md me dn km mf mg dp kq lp mh mi ku lt mj mk ky lx ml mm lc mn bi translated">8.links_count()</h2><ul class=""><li id="86cb" class="no np it lg b lh li ll lm lp nq lt nr lx ns mb nt nu nv nw bi translated">为了从数据中找到更多的见解，我们还找到了嵌入的链接。</li><li id="e970" class="no np it lg b lh nx ll ny lp nz lt oa lx ob mb nt nu nv nw bi translated">我们将找到链接的计数。</li></ul><pre class="na nb nc nd gt ne nf ng nh aw ni bi"><span id="7953" class="mc kh it nf b gy nj nk l nl nm">tf.links_count(df,"Tweets","links_count")<br/>df[["Tweets","links_count"]].head()</span></pre><figure class="na nb nc nd gt ju gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/c0818af89a0eede2d614cd1056575816.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/1*OAfKZv-KhLu8BuJoNQw0PQ.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图 9:链接计数</p></figure><h2 id="5545" class="mc kh it bd ki md me dn km mf mg dp kq lp mh mi ku lt mj mk ky lx ml mm lc mn bi translated">9.链接()</h2><ul class=""><li id="6d29" class="no np it lg b lh li ll lm lp nq lt nr lx ns mb nt nu nv nw bi translated">让我们找出嵌入在文本数据中的链接，将其存储在列表中并用于进一步的分析。</li></ul><pre class="na nb nc nd gt ne nf ng nh aw ni bi"><span id="bece" class="mc kh it nf b gy nj nk l nl nm">tf.links(df,"Tweets","Links")<br/>df[["Tweets","Links"]].head()</span></pre><figure class="na nb nc nd gt ju gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/eb33d284226f727a51a39f111a234442.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*Tc2_JLrfpX9c6MvP5D5ThA.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图 10:链接</p></figure><h2 id="5085" class="mc kh it bd ki md me dn km mf mg dp kq lp mh mi ku lt mj mk ky lx ml mm lc mn bi translated">10.数字计数()</h2><ul class=""><li id="48c9" class="no np it lg b lh li ll lm lp nq lt nr lx ns mb nt nu nv nw bi translated">就像我们搜索单词、标签、链接和许多其他东西一样，我们也会发现数字的数量。</li><li id="7386" class="no np it lg b lh nx ll ny lp nz lt oa lx ob mb nt nu nv nw bi translated">对我们处理文本数据肯定会有帮助。</li></ul><pre class="na nb nc nd gt ne nf ng nh aw ni bi"><span id="88f5" class="mc kh it nf b gy nj nk l nl nm">tf.numerics_count(df,"Tweets","num_len")<br/>df[["Tweets","num_len"]].head()</span></pre><figure class="na nb nc nd gt ju gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/8a8299d859fa8f3ea7e89ca2333e530c.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*HON0VZui9kNAL6wfRSZWVQ.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图 11:数字计数</p></figure><h2 id="2e39" class="mc kh it bd ki md me dn km mf mg dp kq lp mh mi ku lt mj mk ky lx ml mm lc mn bi translated">11.用户提及次数计数()</h2><ul class=""><li id="0167" class="no np it lg b lh li ll lm lp nq lt nr lx ns mb nt nu nv nw bi translated">在处理 twitter 数据时，我们总是会接触到用户提及(@)。我们对这种类型的数据特征很好奇，它帮助我们更有效地分析数据并理解它的重要性。</li><li id="1775" class="no np it lg b lh nx ll ny lp nz lt oa lx ob mb nt nu nv nw bi translated">我们在这里找到了用户提及的次数。</li></ul><pre class="na nb nc nd gt ne nf ng nh aw ni bi"><span id="2a02" class="mc kh it nf b gy nj nk l nl nm">tf.user_mentions_count(df,"Tweets","user_mentions_cnt")<br/>df[["Tweets","user_mentions_cnt"]].head()</span></pre><figure class="na nb nc nd gt ju gh gi paragraph-image"><div class="gh gi om"><img src="../Images/6a6f4d71e5c0c7fe54f3639166b50833.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/1*dufck-KYg_7ehJDo_yNcsQ.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图 12:用户提及计数</p></figure><h2 id="8e5a" class="mc kh it bd ki md me dn km mf mg dp kq lp mh mi ku lt mj mk ky lx ml mm lc mn bi translated">12.用户提及次数()</h2><ul class=""><li id="a043" class="no np it lg b lh li ll lm lp nq lt nr lx ns mb nt nu nv nw bi translated">让我们找出用户提及，将其存储在列表中并用于信息可视化。</li></ul><pre class="na nb nc nd gt ne nf ng nh aw ni bi"><span id="c7a7" class="mc kh it nf b gy nj nk l nl nm">tf.user_mentions(df,"Tweets","user_mentions")<br/>df[["Tweets","user_mentions"]].head()</span></pre><figure class="na nb nc nd gt ju gh gi paragraph-image"><div class="gh gi on"><img src="../Images/74bcb4f68e09abb2836edf3ee98c4889.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*dtYMBzMJR0ZNb6rO1u0XfQ.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图 13:用户提及</p></figure><h2 id="05cd" class="mc kh it bd ki md me dn km mf mg dp kq lp mh mi ku lt mj mk ky lx ml mm lc mn bi translated">13.清洁()</h2><ul class=""><li id="aa77" class="no np it lg b lh li ll lm lp nq lt nr lx ns mb nt nu nv nw bi translated">在提取了所有有意义的特征之后，我们需要清理数据以进行进一步的情感分析。</li><li id="bcee" class="no np it lg b lh nx ll ny lp nz lt oa lx ob mb nt nu nv nw bi translated">因此，我们有一个 clean()函数，它将在删除不需要的数据(如数字、停用词、标点符号和链接)后，为您提供预处理的数据。</li></ul><pre class="na nb nc nd gt ne nf ng nh aw ni bi"><span id="4b53" class="mc kh it nf b gy nj nk l nl nm">tf.clean(df,"Tweets","Clean_tweets")<br/>df[["Tweets","Clean_tweets"]].head()</span></pre><figure class="na nb nc nd gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oo"><img src="../Images/812b7ea98f9d3699c3935d87716c0861.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rO_0_k6oOKz0oI5cV_CdMA.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图 14:清洁()</p></figure><h1 id="7851" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">结论</h1><p id="0309" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我希望你理解这个库提供的基本功能。现在是时候让你设计一些有趣的实现了。如果你想做贡献，那么请把资源库放到 GitHub 上，继续做好工作。</p><h1 id="a965" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">关键要点</h1><ul class=""><li id="3d41" class="no np it lg b lh li ll lm lp nq lt nr lx ns mb nt nu nv nw bi translated"><a class="ae kf" href="https://pypi.org/project/textfeatures/" rel="noopener ugc nofollow" target="_blank">包</a></li><li id="f403" class="no np it lg b lh nx ll ny lp nz lt oa lx ob mb nt nu nv nw bi translated"><a class="ae kf" href="https://colab.research.google.com/drive/1qzzVKptV9C6ebwDgta6rPW0u1s3GzDw5?usp=sharing" rel="noopener ugc nofollow" target="_blank">谷歌 Colab 演示</a></li><li id="5d70" class="no np it lg b lh nx ll ny lp nz lt oa lx ob mb nt nu nv nw bi translated"><a class="ae kf" href="https://github.com/Amey23/textfeatures" rel="noopener ugc nofollow" target="_blank"> Github 资源库</a></li></ul><p id="0771" class="pw-post-body-paragraph le lf it lg b lh ms lj lk ll mt ln lo lp mv lr ls lt mx lv lw lx mz lz ma mb im bi translated">享受学习！</p><blockquote class="mo mp mq"><p id="a37a" class="le lf mr lg b lh ms lj lk ll mt ln lo mu mv lr ls mw mx lv lw my mz lz ma mb im bi translated">你好👋我希望你能从我的文章中获得知识。如果你愿意支持我，请随意给我买些咖啡🙏☕ </p><p id="2070" class="le lf mr lg b lh ms lj lk ll mt ln lo mu mv lr ls mw mx lv lw my mz lz ma mb im bi translated"><a class="ae kf" href="https://www.buymeacoffee.com/amey23" rel="noopener ugc nofollow" target="_blank"><strong class="lg iu">https://www.buymeacoffee.com/amey23</strong></a></p><p id="c51c" class="le lf mr lg b lh ms lj lk ll mt ln lo mu mv lr ls mw mx lv lw my mz lz ma mb im bi translated"><strong class="lg iu">或通过 ameypband23@gmail.com 联系我</strong></p><p id="0ef3" class="le lf mr lg b lh ms lj lk ll mt ln lo mu mv lr ls mw mx lv lw my mz lz ma mb im bi translated"><strong class="lg iu">乐意为您效劳。</strong></p></blockquote></div></div>    
</body>
</html>