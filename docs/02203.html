<html>
<head>
<title>Self-supervised Learning for Medical Image Analysis Using Image Context Restoration</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于图像上下文恢复的医学图像分析自监督学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/self-supervised-learning-for-medical-image-analysis-using-image-context-restoration-557c8c35d27f?source=collection_archive---------23-----------------------#2020-03-02">https://towardsdatascience.com/self-supervised-learning-for-medical-image-analysis-using-image-context-restoration-557c8c35d27f?source=collection_archive---------23-----------------------#2020-03-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="70f6" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">一种称为上下文恢复的新型自我监督学习策略</h2></div><p id="6c98" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是论文“<em class="lb">使用图像上下文恢复进行医学图像分析的自我监督学习</em>”的博客帖子。</p><p id="ed92" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">原载于</em><a class="ae lc" href="https://wiki.tum.de/display/dlma/Self-supervised+learning+for+medical+image+analysis+using+image+context+restoration" rel="noopener ugc nofollow" target="_blank"><em class="lb">wiki . tum . de</em>T7】</a></p></div><div class="ab cl ld le hu lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ij ik il im in"><h1 id="de7e" class="lk ll iq bd lm ln lo lp lq lr ls lt lu jw lv jx lw jz lx ka ly kc lz kd ma mb bi translated">介绍</h1><p id="30cc" class="pw-post-body-paragraph kf kg iq kh b ki mc jr kk kl md ju kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">深度学习方法在计算机视觉领域取得了巨大成功。特别是，CNN最近在医学图像领域，如疾病分类[1]和器官分割[2]中展示了令人印象深刻的结果。好的深度学习模型通常需要相当数量的标签，但在许多情况下，未标记的数据量远远大于已标记的数据量。此外，来自自然图像的预训练模型在医学图像上没有用，因为强度分布不同。此外，标记自然图像很容易，简单的人类知识就足够了。然而，医学图像的注释需要专业知识。</p><blockquote class="mh"><p id="736f" class="mi mj iq bd mk ml mm mn mo mp mq la dk translated">那么，我们应该如何学习无标签的表征呢？</p></blockquote><p id="1d7e" class="pw-post-body-paragraph kf kg iq kh b ki mr jr kk kl ms ju kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">答案很简单；从数据或图像本身获得监督。这意味着我们可以通过以特定的形式构建监督学习任务来实现这一点，以利用其余信息来预测仅一部分信息。这就是所谓的<em class="lb">自我监督学习</em>。</p><p id="8a59" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="lb">什么是自我监督学习？</em>T13】</strong></p><p id="ff5c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">它仍然是监督学习，因为它使用标记数据。它提取并使用自然可用的相关上下文。从这一事实来看，有监督的大量训练实例是可用的。由于这一点，基于这种自我监督来预训练CNN，它导致基于具有有限人工标签的数据来初始化后续CNN的有用权重。图1向我们展示了自我监督学习的概要。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi mw"><img src="../Images/bf361870e10139d44cc0b29d7d529ea2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J4GgG3Pvw3K3VFjF2IAGnw.png"/></div></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">图一。自我监督学习概述[3]</p></figure><p id="c1b2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于现有的自我监督学习策略在医学图像上没有显著的性能改善，作者提出了另一种自我监督策略，称为<em class="lb">上下文恢复</em>。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi nm"><img src="../Images/24a9edbaef609b702e59f5cf79c651a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p6Urs73DwNj6ryy3eTl8Jw.png"/></div></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">图二。上下文恢复方法概述(图片由作者提供)</p></figure><p id="e9b4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">图2是上下文恢复如何工作的很好的概述。基本上，有输入图像，然后算法破坏并试图恢复它们。在这个恢复过程中，它学习权重，这将在处理后续任务时给我们带来更好的结果。</p><p id="d43a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中一项名为<em class="lb">通过上下文预测的无监督视觉表示学习【4】</em>的自我监督研究，从给定图像中预测3 × 3面片网格中中心面片与其周围面片之间的相对位置。例如，图3-a向我们展示了猫的右耳相对于猫的眼睛应该在右上的位置。但是它有三个缺点:可能有多个正确答案(例如，汽车或建筑物)，它仍然学习在医学图像中没有用的琐碎特征，最后，补丁不包含关于图像的全局上下文的信息。</p><p id="0a4b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在特征学习方面，提出了另一个自我监督的研究，名为<em class="lb">上下文编码器:通过修复进行特征学习[5]。</em>它<em class="lb"> </em>被训练来填补图像中缺失的一块，如图3-b所示，因此，在学习有意义的潜在表征的同时，重构原始输入。此外，这种方法也有一些缺点:它改变了图像的强度分布。因此，所得到的图像属于另一个域，并且所学习的特征对于原始域中的图像可能是无用的。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi nn"><img src="../Images/d794c33215c0575bee00e9ed1f93d1d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YOyGmFT4G0X3APC_2U0iHw.png"/></div></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">图3。相对位置(a)和上下文预测(b)方法的演示[4，5]</p></figure><h1 id="7e02" class="lk ll iq bd lm ln no lp lq lr np lt lu jw nq jx lw jz nr ka ly kc ns kd ma mb bi translated">方法学</h1><p id="f64b" class="pw-post-body-paragraph kf kg iq kh b ki mc jr kk kl md ju kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">论文提出了一种新的自我监督策略，他们称之为<em class="lb">上下文恢复</em>。该方法很简单，在给定的图像中随机选择两个孤立的小块并交换它们的上下文。重复这些操作T次，直到强度分布仍然保留，但其空间信息被改变。图4向我们展示了迭代1和10后的情况。</p><p id="2821" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本文在医学成像中的三个常见问题上验证了上下文恢复策略:<strong class="kh ir">分类</strong>、<strong class="kh ir">定位</strong>和<strong class="kh ir">分割</strong>。胎儿2D超声图像中的扫描平面检测:在计算机断层摄影(CT)图像中定位腹部器官；为了分割多模态磁共振(MR)图像中的脑肿瘤，使用了。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/4fc5b3fe2143b5ad7ac91afb57810919.png" data-original-src="https://miro.medium.com/v2/resize:fit:882/format:webp/1*Y5doF1jOpyKfZtmtQZdg7g.png"/></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">图4。生成用于自监督上下文乱序的训练图像:分别是大脑T1 MR图像、腹部CT图像和2D胎儿超声图像。在第二列的图中，红框突出显示了第一次迭代后交换的面片。(图片由作者提供)</p></figure><p id="bb58" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所提出的自监督学习策略使用了细胞神经网络，它由两部分组成:一个<em class="lb">分析部分</em>和一个<em class="lb">重构部分</em>。图5示出了可行CNN的一般架构的概述。分析部分将给定的无序图像编码成特征图，重建部分使用这些特征图来产生正确上下文的输出图像。</p><p id="30c1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">分析部分</strong></p><p id="543c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这部分包括卷积单元和下采样单元的堆栈，它们从给定的图像中提取特征图。</p><p id="4e6e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">重建部分</strong></p><p id="2767" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里，它包括卷积层和上采样层的堆栈，从而恢复图像。每个后续任务的重建部分是不同的。对于分类任务，简单的结构如几个反褶积层是优选的。对于分割任务，与分割CNN一致的复杂结构是优选的。</p><p id="d3f1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">结果，几乎所有后续分割CNN的权重都可以使用在自我监督预训练中学习到的权重来初始化。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi nu"><img src="../Images/267fb3f63bd5d3df9b9db66ce55c732a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YaTthWqg-uUGPx-EqR5adg.png"/></div></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">图5。用于上下文恢复自监督学习的通用CNN结构。(图片由作者提供)</p></figure><h1 id="0515" class="lk ll iq bd lm ln no lp lq lr np lt lu jw nq jx lw jz nr ka ly kc ns kd ma mb bi translated">实验装置</h1><p id="1cae" class="pw-post-body-paragraph kf kg iq kh b ki mc jr kk kl md ju kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">所提出的使用上下文恢复任务的自我监督可以由CNN在三个不同的数据集上执行，包括脑部MR图像、腹部CT图像和胎儿US图像，并且他们使用预训练的CNN分别执行后续任务，例如分类、定位和分割。对于这些问题中的每一个，使用不同的CNN架构和数据:</p><p id="55d8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="lb">分类</em> </strong></p><p id="730b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该数据集由2694个胎龄在18至22周之间的胎儿(224×288)的2D超声检查组成[6]。</p><p id="4aa0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个分类问题的CNN是SonoNet-64，它在[6]中取得了最好的性能。</p><p id="dc88" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">CNN在这种分类任务中的性能通过精确度、召回率和F1分数来测量。</p><p id="db4e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="lb">本地化</em> </strong></p><p id="6b63" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">采用了来自150名受试者3D腹部CT图像的数据集[7]。</p><p id="3e79" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">数据集被随机分成两半。前半部分用于训练和验证，另一半用于测试。</p><p id="b91a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">用于多器官定位任务的CNN类似于SonoNet [6]。由于输入图像为512×512，大约是每侧已处理2D超声帧的两倍，因此它比SonoNet多了一个卷积堆栈和池层。</p><p id="a62d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过计算边界框之间的质心和墙的距离来测量性能。</p><p id="95b0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="lb">分割</em> </strong></p><p id="6361" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">BraTS 2017挑战赛的数据集，由285名受试者组成[8]。每个对象都有多种模式的MR图像，即自然T1 (T1)、增强后T1加权(T1-Gd)、T2加权(T2)、T2液体衰减反转恢复(FLAIR)。<em class="lb">如果您想进一步了解这些术语，请访问本网站</em><a class="ae lc" href="https://mrimaster.com/index-2.html" rel="noopener ugc nofollow" target="_blank"><em class="lb"/></a><em class="lb">。</em></p><p id="31e8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">285幅图像中的142幅用于训练和验证，剩余的143幅用于测试。</p><p id="6265" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本实验中使用的CNN是2D U-Net [9]。</p><p id="0709" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">他们在BraTS 2017挑战赛中使用了相同的评估指标:骰子得分、灵敏度、特异性和Hausdorff距离。</p></div><div class="ab cl ld le hu lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ij ik il im in"><p id="f581" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作者比较了不同的自我监督学习策略，即随机[6]，随机+增强，自动编码器[10]，使用补丁相对位置预测的自我监督[4]，Jigsaw [11]，以及使用局部上下文预测的自我监督[5]和提议的上下文恢复。</p><h1 id="d1e7" class="lk ll iq bd lm ln no lp lq lr np lt lu jw nq jx lw jz nr ka ly kc ns kd ma mb bi translated">结果和讨论</h1><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi nv"><img src="../Images/e2169894669ce4931e5a594f8a35ec29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8TPc-9sC5SR-MePtJZhljg.png"/></div></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">图6。胎儿2D超声图像标准扫描平面的分类(图片由作者提供)</p></figure><p id="1e70" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">图6展示了不同配置下CNN的性能结果。由于自我监督的预训练，当使用小训练数据集时，CNN的性能可以得到改善。上下文恢复预训练对SonoNet性能的改善最大。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi nw"><img src="../Images/ce758947de07bbd9e7138bcf6ce474e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IQ1F2Ug6GxDPnPk1YpUHmg.png"/></div></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">图7。CNN在不同训练环境下解决多器官定位(本结果中为左肾)问题的表现(图片由作者提供)</p></figure><p id="4b46" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">图7表示CNN在不同训练方法中的定位性能。在某些情况下，使用<strong class="kh ir">上下文恢复</strong>预训练的CNN在更多标记的训练数据上与无预训练相当甚至更好。就在左肾上的性能而言，CNN在半个训练数据上略微优于在所有训练数据上。值得注意的是，如果较少的训练数据导致结果显著下降，自我监督学习往往会显著改善结果。</p><figure class="mx my mz na gt nb gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi nx"><img src="../Images/f62378c19db370c8f161f574f669047f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d3ow3DEN8vLW7-J0KZlkJQ.png"/></div></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">图8。不同训练设置下定制U-Nets的分割结果(图片由作者提供)</p></figure><p id="6526" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">图8显示了BraTS问题的结果。增强的肿瘤核心中的Dice分数甚至稍好。并且，它向我们展示了使用一半的训练数据集，所提出的自监督策略产生了与使用整个训练数据集相似的性能。同样，我们可以看到基于上下文恢复的自我监督为分段任务提供了最佳的预训练方法。</p><p id="b561" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">提出了一种新的基于上下文恢复的自监督学习策略。这使得CNN能够在没有任何标签的情况下学习有用的图像语义，并用于后续任务。因此，我们可以总结出以下要点:</p><ul class=""><li id="7d81" class="ny nz iq kh b ki kj kl km ko oa ks ob kw oc la od oe of og bi translated">在分类、定位和分割这三项任务中，使用上下文恢复预训练比其他方法表现更好</li><li id="ac94" class="ny nz iq kh b ki oh kl oi ko oj ks ok kw ol la od oe of og bi translated">如果减少训练数据导致性能显著下降，上下文恢复预训练可以提高性能</li><li id="baad" class="ny nz iq kh b ki oh kl oi ko oj ks ok kw ol la od oe of og bi translated">语境还原有三个显著特征；学习语义图像特征；这些语义特征对于不同的后续任务是有用的；实现简单明了</li><li id="048d" class="ny nz iq kh b ki oh kl oi ko oj ks ok kw ol la od oe of og bi translated">缺点是L2损失导致图像模糊。</li></ul><h1 id="ea14" class="lk ll iq bd lm ln no lp lq lr np lt lu jw nq jx lw jz nr ka ly kc ns kd ma mb bi translated">未来作品</h1><p id="8f59" class="pw-post-body-paragraph kf kg iq kh b ki mc jr kk kl md ju kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">探索更有效的自我监督学习策略，使自我监督预训练在未来能像监督预训练一样好，是值得关注的。此外，还会出现以下问题:</p><ul class=""><li id="cf16" class="ny nz iq kh b ki kj kl km ko oa ks ob kw oc la od oe of og bi translated">如果使用更大的数据集会发生什么？还是优化的自我监督学习模型？</li><li id="dd9d" class="ny nz iq kh b ki oh kl oi ko oj ks ok kw ol la od oe of og bi translated">如果他们可以使用3x3补丁并随机交换，结果会受到什么影响？</li><li id="764f" class="ny nz iq kh b ki oh kl oi ko oj ks ok kw ol la od oe of og bi translated">添加额外的模型？</li><li id="bc9f" class="ny nz iq kh b ki oh kl oi ko oj ks ok kw ol la od oe of og bi translated">使用另一种损失函数代替L2，例如对抗性损失？</li></ul></div><div class="ab cl ld le hu lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ij ik il im in"><p id="3478" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作者:粱晨、保罗·本特利、森健作、三泽和里、藤原道孝、丹尼尔·吕克特</p><p id="35ce" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">关于这项工作的更多细节，请查看<a class="ae lc" href="https://www.sciencedirect.com/science/article/abs/pii/S1361841518304699" rel="noopener ugc nofollow" target="_blank">关于科学指导的论文</a>。</p><h1 id="7ea2" class="lk ll iq bd lm ln no lp lq lr np lt lu jw nq jx lw jz nr ka ly kc ns kd ma mb bi translated">参考</h1><p id="2c41" class="pw-post-body-paragraph kf kg iq kh b ki mc jr kk kl md ju kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">[1]王，x，彭，y，陆，l，陆，z，巴盖里，m，萨默斯，R. M，2017 .ChestX-ray8:医院规模的胸部X射线数据库和常见胸部疾病的弱监督分类和定位基准。IEEE计算机视觉和模式识别会议论文集。第3462-3471页。网址https://arxiv.org/abs/1705.02315<a class="ae lc" href="https://arxiv.org/abs/1705.02315" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="aac0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[2]Suk h .-I .，Lee s-w .，Shen d .，Initiative，A. D. N .等人，2014年。用于AD/MCI诊断的分层特征表示和具有深度学习的多模态融合。神经影像101，569–582。网址<a class="ae lc" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4165842/" rel="noopener ugc nofollow" target="_blank">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4165842/</a>。</p><p id="a0c3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[3] Yann LeCun，自我监督学习:机器能否像人类一样学习，2018。网址<a class="ae lc" href="https://www.youtube.com/watch?v=7I0Qt7GALVk" rel="noopener ugc nofollow" target="_blank">youtube.com</a>。</p><p id="b031" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[4]多尔施，c .，古普塔，a .，埃夫罗斯，A. A .，2015。基于上下文预测的无监督视觉表征学习。IEEE计算机视觉国际会议论文集。第1422-1430页。网址<a class="ae lc" href="https://arxiv.org/abs/1505.05192" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1505.05192</a>。</p><p id="6671" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[5] Pathak，d .，Krahenbuhl，p .，Donahue，j .，Darrell，t .，Efros，A. A .，2016年。上下文编码器:通过修补进行特征学习。IEEE计算机视觉和模式识别会议论文集。第2536-2544页。网址<a class="ae lc" href="https://arxiv.org/abs/1604.07379" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1604.07379</a>。</p><p id="c716" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[6]鲍姆加特纳，C. F .，卡姆尼萨斯，k .，马修，j .，弗莱彻，T. P .，史密斯，s .，科赫，L. M .，坎因茨，b .，吕克特，d .，2017。SonoNet:徒手超声中胎儿标准扫描平面的实时检测和定位。IEEE医学成像汇刊36 (11)，2204–2215。网址<a class="ae lc" href="https://arxiv.org/abs/1612.05601" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1612.05601</a>。</p><p id="2394" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[7] Tong，t .，Wolz，r .，Wang，z .，Gao，q .，Misawa，k .，藤原，m .，Mori，k .，Hajnal，J. V .，Rueckert，d .，2015年。用于腹部多器官分割的判别字典学习。医学图像分析23 (1)，92–104。网址https://www.ncbi.nlm.nih.gov/pubmed/25988490<a class="ae lc" href="https://www.ncbi.nlm.nih.gov/pubmed/25988490" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="b995" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[8] Menze，B. H .，Jakab，a .，Bauer，s .，Kalpathy-Cramer，j .，Farahani，k .，Kirby，j .，Burren，y .，Porz，n .，Slotboom，j .，Wiest，r .，等人，2015年。多模态脑肿瘤图像分割基准(BRATS)。IEEE医学成像汇刊34 (10)，1993–2024。网址https://ieeexplore.ieee.org/document/6975210<a class="ae lc" href="https://ieeexplore.ieee.org/document/6975210" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="4525" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[9]罗内贝格，o .，菲舍尔，p .，布罗克斯，t .，2015。生物医学图像分割的卷积网络。医学图像计算和计算机辅助介入国际会议论文集。第234-241页。网址<a class="ae lc" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1505.04597</a>。</p><p id="3616" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[10]本吉奥，y .，兰布林，p .，波博维奇，拉罗歇尔，h .，2007年。深度网络的贪婪分层训练。神经信息处理系统进展。第153-160页。网址<a class="ae lc" href="https://papers.nips.cc/paper/3048-greedy-layer-wise-training-of-deep-networks.pdf" rel="noopener ugc nofollow" target="_blank">https://papers . nips . cc/paper/3048-greedy-layer-wise-training-of-deep-networks . pdf</a>。</p><p id="8b40" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[11]诺鲁齐，m .，法瓦罗页，2016年。通过解决拼图游戏实现视觉表征的无监督学习。《欧洲计算机视觉会议论文集》。第69-84页。网址<a class="ae lc" href="https://arxiv.org/abs/1603.09246" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1603.09246</a>。</p></div></div>    
</body>
</html>