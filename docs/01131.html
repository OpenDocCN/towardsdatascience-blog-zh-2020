<html>
<head>
<title>Python For Data Science — A Guide To Classification Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于数据科学的Python分类机器学习指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/python-for-data-science-a-guide-to-classification-machine-learning-9ff51d237842?source=collection_archive---------16-----------------------#2020-02-01">https://towardsdatascience.com/python-for-data-science-a-guide-to-classification-machine-learning-9ff51d237842?source=collection_archive---------16-----------------------#2020-02-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="fdcb" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何正确执行分类机器学习并对其进行评估</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/1bfced14b335c170460441d0af3345a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ekRjTqGM7NWwfNlZn-uohw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">分类机器学习</p></figure><p id="c8f1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">亲爱的读者们，新年快乐。终于到了2020年。<br/>随着数据的上升，<br/>你掌握了21世纪最性感的技巧了吗？<br/>它叫做——<strong class="la iu">机器学习。</strong></p><p id="509b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">那是什么？你没有时间学习它，但你非常想掌握它？你找不到一篇关于机器学习的好文章，教你如何正确地<strong class="la iu">执行</strong>和<strong class="la iu">评估</strong>你的模型？</p><p id="76ca" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">别担心，我会解决你所有的问题——如果我有足够的数据的话。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lu lv l"/></div></figure><p id="2cb2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">今天，我们将谈论所有关于<strong class="la iu">机器学习的话题。<br/> </strong>是啊，大家最爱的话题，是不是很刺激？</p><p id="c286" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">根据<a class="ae lw" href="https://www.payscale.com/research/US/Job=Machine_Learning_Engineer/Salary" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu">薪级表</strong> </a>，一名<strong class="la iu">机器学习工程师</strong>的平均年薪为<strong class="la iu">110，000美元</strong>，不包括绩效奖金。我们都知道机器学习正在兴起，我们也知道你现在就需要学习它。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lx"><img src="../Images/647714f62b0fcfd0491e6563b24eddd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8voAw-_GxuvnWMGB7YtvHg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">谷歌机器学习趋势</p></figure><p id="1b34" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">那么，机器学习<strong class="la iu"> </strong>到底是什么？<br/>机器学习是人工智能(AI)的一个子集，它在机器中引入了“<strong class="la iu">学习</strong>”的能力。把它想象成机器能够在它们的人工大脑中开发出一个<strong class="la iu">模式</strong>，给定你提供给它的<strong class="la iu">数据</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ly"><img src="../Images/a1820efc97b19918e459d87804785648.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DoFLfX_Q7Z27QzcGhJrjwQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae lw" href="https://commons.wikimedia.org/wiki/File:AI-ML-DL.png" rel="noopener ugc nofollow" target="_blank">维基媒体</a></p></figure><p id="fc30" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">传统上，我们<strong class="la iu">通过给机器</strong>规则来给它们编程做一些事情，比如一个<strong class="la iu"> if-else </strong>语句。现在，我们让机器<strong class="la iu">通过向它们提供数据来发现</strong>这些规则。这里有一个形象化的例子可以帮助你更好地理解它。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/344c7a5819cc8d67780844fd93979326.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*Z31ttBK05ynCVdpaJ-m9NA.png"/></div></figure><p id="0fc1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">机器能够通过训练过程发现这些规则，在训练过程中，机器尝试不同的规则，并评估每个规则与我们的数据的拟合程度。发现规则后，我们现在可以说机器根据我们的数据造出了一个<strong class="la iu">模型</strong>。</p><p id="a9df" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该过程的一个例子是:</p><ul class=""><li id="b8c7" class="ma mb it la b lb lc le lf lh mc ll md lp me lt mf mg mh mi bi translated">将猫的图像<strong class="la iu">传入机器，并贴上“猫”的标签</strong></li><li id="3168" class="ma mb it la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">传入女孩的数据和她们的<strong class="la iu">习惯</strong>，同时给她们贴上“女孩”的标签</li><li id="ea56" class="ma mb it la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">传入每个员工的工资以及他们的<strong class="la iu">职位</strong>和<strong class="la iu">资格</strong></li></ul><p id="23d5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这个过程之后，机器将能够<strong class="la iu">预测</strong>:</p><ul class=""><li id="aa87" class="ma mb it la b lb lc le lf lh mc ll md lp me lt mf mg mh mi bi translated">如果<strong class="la iu">图像</strong>是猫或其他动物</li><li id="bc33" class="ma mb it la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">如果是女孩或男孩，根据这个人的<strong class="la iu">习惯</strong></li><li id="b268" class="ma mb it la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">具有某个<strong class="la iu">职位</strong>和<strong class="la iu">资格</strong>的员工的工资</li></ul><p id="05a4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">机器学习有多种形式。经常提到的有监督、无监督和强化学习。定义您将处理哪种形式的机器学习的主要因素将是您的<strong class="la iu">数据集，或数据。</strong></p><p id="1ae6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你有一组<strong class="la iu">输入</strong>和<strong class="la iu">输出</strong>，大多数时候它会被归类为<strong class="la iu">监督机器学习。</strong>为了简单起见，我们将在本文中只讨论<strong class="la iu">监督学习</strong>来帮助您入门。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="5738" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">分类和回归</h1><p id="efbe" class="pw-post-body-paragraph ky kz it la b lb nn ju ld le no jx lg lh np lj lk ll nq ln lo lp nr lr ls lt im bi translated">监督机器学习处理两个主要问题，<br/> <strong class="la iu">分类</strong>和<strong class="la iu">回归</strong>。</p><p id="12ac" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你注意了，我上面展示的例子是关于—</p><ul class=""><li id="ca6f" class="ma mb it la b lb lc le lf lh mc ll md lp me lt mf mg mh mi bi translated">女孩还是男孩——分类</li><li id="6c34" class="ma mb it la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">员工工资-回归</li></ul><p id="339d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">相当直接。<br/>分类通常有<strong class="la iu">离散</strong>输出，而<br/>回归有<strong class="la iu">连续</strong>输出。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="5cd4" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">先决条件</h1><p id="fc09" class="pw-post-body-paragraph ky kz it la b lb nn ju ld le no jx lg lh np lj lk ll nq ln lo lp nr lr ls lt im bi translated">首先，我们需要知道您将如何<strong class="la iu">收集</strong>您的数据。</p><p id="48aa" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">今天，大多数现实世界的企业都使用机器学习来优化他们的产品/服务。</p><ul class=""><li id="62ab" class="ma mb it la b lb lc le lf lh mc ll md lp me lt mf mg mh mi bi translated">当您停止使用某项服务一段时间后，您可能会收到一封电子邮件，向您提供<strong class="la iu">折扣/奖励</strong>以继续使用该服务。</li><li id="32ef" class="ma mb it la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">当你浏览Youtube/网飞时，你会得到与你的兴趣相符的推荐，这会让你在这个平台上呆得更久。</li><li id="6a7c" class="ma mb it la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">当你的照片被发布到脸书上时，你会自动被平台识别并被标记。</li></ul><p id="7c18" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你在这些组织中的一个工作，他们已经建立了适当的数据仓库，包含了大部分的数据。然后，您可以在大多数情况下通过使用<strong class="la iu"> SQL </strong>来提取这些数据。因此，您首先需要的是<strong class="la iu"> SQL </strong>。</p><p id="0f34" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">列表上的下一个可能是<strong class="la iu"> Python </strong>，带有特定的库。<br/> <a class="ae lw" rel="noopener" target="_blank" href="/python-for-data-science-basics-of-pandas-5f8d9680617e"> <strong class="la iu"> Pandas </strong> </a>将是Python中用来操作数据的主库，所以那应该是你掌握的第一个库。</p><div class="ns nt gp gr nu nv"><a rel="noopener follow" target="_blank" href="/python-for-data-science-basics-of-pandas-5f8d9680617e"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd iu gy z fp oa fr fs ob fu fw is bi translated">用于数据科学的Python熊猫指南</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">10分钟内完成数据探索指南</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">towardsdatascience.com</p></div></div><div class="oe l"><div class="of l og oh oi oe oj ks nv"/></div></div></a></div><p id="7e88" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">之后，我们将通过本文中的<a class="ae lw" rel="noopener" target="_blank" href="/python-for-data-science-a-guide-to-data-visualization-with-plotly-969a59997d0c"><strong class="la iu"/></a>来<strong class="la iu">可视化</strong>我们的大量数据和发现。没有它，没有人能真正理解我们在做什么。<br/>我已经写了多篇关于<a class="ae lw" rel="noopener" target="_blank" href="/python-for-data-science-advance-guide-to-data-visualization-with-plotly-8dbeaedb9724"><strong class="la iu"/></a>的文章，一定要看看它们来刷新你的记忆。</p><div class="ns nt gp gr nu nv"><a rel="noopener follow" target="_blank" href="/python-for-data-science-a-guide-to-data-visualization-with-plotly-969a59997d0c"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd iu gy z fp oa fr fs ob fu fw is bi translated">面向数据科学的python——Plotly数据可视化指南</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">现在是2020年，是时候停止使用Matplotlib和Seaborn了</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">towardsdatascience.com</p></div></div><div class="oe l"><div class="ok l og oh oi oe oj ks nv"/></div></div></a></div><div class="ns nt gp gr nu nv"><a rel="noopener follow" target="_blank" href="/python-for-data-science-advance-guide-to-data-visualization-with-plotly-8dbeaedb9724"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd iu gy z fp oa fr fs ob fu fw is bi translated">用于数据科学的Python使用Plotly进行数据可视化的高级指南</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">如何在Plotly中添加和自定义滑块、下拉菜单和按钮</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">towardsdatascience.com</p></div></div><div class="oe l"><div class="ol l og oh oi oe oj ks nv"/></div></div></a></div><p id="7a53" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">继续，知道如何正确地<strong class="la iu">探索</strong>你的数据也是很好的。<br/>拿到数据集后，很多数据从业者往往不知道该怎么处理。这种情况经常导致我们都想避免的优化较差的机器学习模型。</p><p id="2bdd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，请阅读我的文章<a class="ae lw" rel="noopener" target="_blank" href="/python-for-data-science-what-to-do-before-performing-machine-learning-a30f62465632"><strong class="la iu"/></a><strong class="la iu">。</strong></p><div class="ns nt gp gr nu nv"><a rel="noopener follow" target="_blank" href="/python-for-data-science-what-to-do-before-performing-machine-learning-a30f62465632"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd iu gy z fp oa fr fs ob fu fw is bi translated">用于数据科学的Python在执行机器学习之前要做什么？</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">不要沉迷于机器学习模型，先了解你的数据。</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">towardsdatascience.com</p></div></div><div class="oe l"><div class="om l og oh oi oe oj ks nv"/></div></div></a></div><p id="6da3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从Plotly到熊猫再到机器学习。我掩护你。既然已经出来了，是时候开始了。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/de22e5c82ce10f96e88f3a174817b4bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-XRZxl4JbzQxY1dZ"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae lw" href="https://unsplash.com/@ricaros?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">丹尼尔·里卡洛斯</a>在<a class="ae lw" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="120b" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">进口</h1><p id="1022" class="pw-post-body-paragraph ky kz it la b lb nn ju ld le no jx lg lh np lj lk ll nq ln lo lp nr lr ls lt im bi translated">像往常一样，我们将与<a class="ae lw" href="https://jupyter.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu"> Jupyter笔记本</strong> </a>一起工作。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="ea61" class="ot mw it op b gy ou ov l ow ox">#all plotly<br/>from plotly.offline import init_notebook_mode,iplot<br/>import plotly.graph_objects as go<br/>import cufflinks as cf<br/>init_notebook_mode(connected=True)</span><span id="58d9" class="ot mw it op b gy oy ov l ow ox">#others<br/>import pandas as pd<br/>import numpy as np</span></pre><h1 id="9217" class="mv mw it bd mx my oz na nb nc pa ne nf jz pb ka nh kc pc kd nj kf pd kg nl nm bi translated">导入数据集</h1><p id="1046" class="pw-post-body-paragraph ky kz it la b lb nn ju ld le no jx lg lh np lj lk ll nq ln lo lp nr lr ls lt im bi translated">在本文中，我们将使用一个<a class="ae lw" href="https://www.kaggle.com/blastchar/telco-customer-churn" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu">电信客户流失数据集</strong> </a>。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="9671" class="ot mw it op b gy ou ov l ow ox">df = pd.read_csv(filepath)</span></pre></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="d90a" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">机器学习的数据预处理</h1><p id="e8c7" class="pw-post-body-paragraph ky kz it la b lb nn ju ld le no jx lg lh np lj lk ll nq ln lo lp nr lr ls lt im bi translated">在这个阶段，我们将把数据预处理成机器可读的格式。请记住，机器实际上并不理解文本，因为它们只是将文本作为输入。例如，机器不理解文本“男性”和“女性”之间的<strong class="la iu">差异</strong>。因此，在我们通过训练过程之前，我们需要正确地处理我们的分类和数字数据。</p><h2 id="928c" class="ot mw it bd mx pe pf dn nb pg ph dp nf lh pi pj nh ll pk pl nj lp pm pn nl po bi translated">分类数据</h2><p id="b7d5" class="pw-post-body-paragraph ky kz it la b lb nn ju ld le no jx lg lh np lj lk ll nq ln lo lp nr lr ls lt im bi translated">将分类数据转换成可理解输入的最常用方法是为每个类别创建<strong class="la iu">虚拟变量</strong>。例如，我们的合同栏中有3种类型的合同，即“逐月”、“一年”和“两年”。然后，合同列被转换为3列，每种类型的合同对应一个真或假指示器。这里有一幅图可以帮忙。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pp"><img src="../Images/ebf199f5c1952c5194a686593b8996a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*raYgWMPUAzmPP-aEMfINdw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">分类数据预处理</p></figure><p id="024e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以通过熊猫的get_dummies函数很容易地做到这一点。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="034e" class="ot mw it op b gy ou ov l ow ox">#Creating Dummy Variables for Categorical Columns<br/>df = pd.get_dummies(data = df,columns = cat_cols )</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pq"><img src="../Images/a4a036f51915a2a548c19bd009373682.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5e4KDpU20mxd_x6WilO84Q.png"/></div></div></figure><p id="00b0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以看到分类列已经被处理过了。然而，也有布尔列只包含两个类别，通常是或否。我们可以使用以下公式将这些值编码为1和0:</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="d572" class="ot mw it op b gy ou ov l ow ox">from sklearn.preprocessing import LabelEncoder<br/>#Encoding bool_cols<br/>le = LabelEncoder()<br/>for i in bool_cols :<br/>    df[i] = le.fit_transform(df[i])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pr"><img src="../Images/bb19d8f38b2f10fddb2a969032d63b9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DhfAI3OtPBcHwPFiUw1B2Q.png"/></div></div></figure><p id="2f01" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在所有的分类和布尔列都完成了。<br/>我们只剩下—</p><h2 id="17c0" class="ot mw it bd mx pe pf dn nb pg ph dp nf lh pi pj nh ll pk pl nj lp pm pn nl po bi translated">数字列</h2><p id="9594" class="pw-post-body-paragraph ky kz it la b lb nn ju ld le no jx lg lh np lj lk ll nq ln lo lp nr lr ls lt im bi translated">数字列的预处理包括<strong class="la iu">缩放</strong>，使得一个量的变化等于另一个量的变化。机器需要理解，仅仅因为一些列(如“总费用”)有很大的值，并不意味着它在预测结果方面起很大作用。为了实现这一点，我们将所有的数字列放在同一个<strong class="la iu">标度</strong>中，这样它们就不会被另一个支配。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="4423" class="ot mw it op b gy ou ov l ow ox">from sklearn.preprocessing import StandardScaler<br/>#Scaling Numerical columns<br/>std = StandardScaler()<br/>scaled = std.fit_transform(df[num_cols])<br/>scaled = pd.DataFrame(scaled,columns=num_cols)</span><span id="27f8" class="ot mw it op b gy oy ov l ow ox">df.drop(columns = num_cols,axis = 1, inplace= True)<br/>df = df.merge(scaled,left_index=True,right_index=True,how = "left")</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pr"><img src="../Images/b5907b73b1232ffdf7622f8afaec6872.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9MNQbVOv-ZwIRNkgoCo6QA.png"/></div></div></figure><h2 id="31bb" class="ot mw it bd mx pe pf dn nb pg ph dp nf lh pi pj nh ll pk pl nj lp pm pn nl po bi translated">分割训练和测试</h2><p id="1205" class="pw-post-body-paragraph ky kz it la b lb nn ju ld le no jx lg lh np lj lk ll nq ln lo lp nr lr ls lt im bi translated">完美。现在我们的数据已经被完美地缩放和分类了。我们可以将它们分成我们的训练集和测试集。</p><p id="0b4b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">训练集是我们传递到训练过程中的数据，而测试数据用于评估我们的模型。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="af18" class="ot mw it op b gy ou ov l ow ox">#splitting train and test data <br/>train,test = train_test_split(df,test_size = .25 ,random_state = 111)</span><span id="4a75" class="ot mw it op b gy oy ov l ow ox">#defining our features and metric<br/>cols    = [i for i in df.columns if i not in Id_col + metric_col]<br/>train_X = train[cols]<br/>train_Y = train[metric_col]<br/>test_X  = test[cols]<br/>test_Y  = test[metric_col]</span></pre></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="ae25" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">取样操作</h1><p id="70a7" class="pw-post-body-paragraph ky kz it la b lb nn ju ld le no jx lg lh np lj lk ll nq ln lo lp nr lr ls lt im bi translated">如今，来自现实生活情况的数据经常导致对每个潜在输出的不平衡数量的观察。<br/>通过数据探索，我们做的第一件事是找出流失客户和非流失客户的数量。结果是—</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/1d2386e1d8abd16657e4ebb68dabf352.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*Cb3qHju9UFJKKXBHaSLC3Q.gif"/></div></figure><p id="77fb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如您所见，非流失客户的数量<strong class="la iu">明显高于流失客户的数量</strong>。不需要太多的细节，这将给我们的模型带来一个问题，因为机器正在获得更多关于非流失客户的<strong class="la iu">信息</strong>，并且可能将流失客户误认为非流失客户。因此，这将降低预测<strong class="la iu">客户流失</strong>的准确性。</p><p id="4d4d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">换句话说，我们的模型将擅长预测客户是否会<strong class="la iu">留在</strong>，但在预测客户是否会<strong class="la iu">流失</strong>时表现不佳。根据业务需求，这显然与我们试图实现的目标相矛盾。我们希望尽可能准确地预测客户流失情况，以便抓住所有客户，并采取额外的商业行动来说服他们留下来。例如，如果我们知道客户即将流失，就发送折扣代码。</p><h2 id="0346" class="ot mw it bd mx pe pf dn nb pg ph dp nf lh pi pj nh ll pk pl nj lp pm pn nl po bi translated">过采样</h2><p id="fc69" class="pw-post-body-paragraph ky kz it la b lb nn ju ld le no jx lg lh np lj lk ll nq ln lo lp nr lr ls lt im bi translated">也就是说，我们可以通过<br/>过采样来最小化这个问题的影响。过采样是人为增加数据集中某一类的观察次数的方法。通常，我们更喜欢平衡每个类的观察数量，这意味着我们应该有50%的流失观察和50%的非流失观察。</p><h2 id="b127" class="ot mw it bd mx pe pf dn nb pg ph dp nf lh pi pj nh ll pk pl nj lp pm pn nl po bi translated">重击</h2><p id="817c" class="pw-post-body-paragraph ky kz it la b lb nn ju ld le no jx lg lh np lj lk ll nq ln lo lp nr lr ls lt im bi translated">我们将使用的方法是SMOTE，代表综合少数过采样技术。在不涉及太多细节的情况下，SMOTE人为地创造了新的观察结果，而不仅仅是现有少数民族案例的副本。相反，该算法通过涉及向量、随机数和每个样本的最近邻居来创建新的观察值。对我们来说，最主要的收获是，现在公平地创造了更多对<strong class="la iu">流失</strong>客户的观察。</p><p id="88d4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae lw" href="https://medium.com/analytics-vidhya/balance-your-data-using-smote-98e4d79fcddb" rel="noopener">这里是</a>为了便于理解，对SMOTE算法的补充阅读。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="7d7f" class="ot mw it op b gy ou ov l ow ox">from imblearn.over_sampling import SMOTE</span><span id="70e4" class="ot mw it op b gy oy ov l ow ox">cols    = [i for i in df.columns if i not in Id_col+metric_col]<br/>smote_X = df[cols]<br/>smote_Y = df[metric_col]</span><span id="b3b4" class="ot mw it op b gy oy ov l ow ox">#Split train and test data<br/>smote_train_X,smote_test_X,smote_train_Y,smote_test_Y = train_test_split(smote_X,smote_Y,                                                           test_size = .25 ,                                                                         random_state = 111)</span><span id="76ae" class="ot mw it op b gy oy ov l ow ox">#oversampling minority class using smote<br/>os = SMOTE(random_state = 0)<br/>os_smote_X,os_smote_Y = os.fit_sample(smote_train_X.to_numpy(),smote_train_Y.to_numpy())<br/>os_smote_X = pd.DataFrame(data = os_smote_X,columns=cols)<br/>os_smote_Y = pd.DataFrame(data = os_smote_Y,columns=metric_col)</span></pre><p id="156b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，我们有<strong class="la iu"> 2 </strong>列车组和<strong class="la iu"> 2 </strong>测试组。<br/>其中一个是原始数据，另一个应用了SMOTE。<br/>我们稍后会比较他们的表现。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="7cad" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">特征选择</h1><p id="4b55" class="pw-post-body-paragraph ky kz it la b lb nn ju ld le no jx lg lh np lj lk ll nq ln lo lp nr lr ls lt im bi translated">现在我们有了一组平衡的数据。<br/>我们如何知道<strong class="la iu">包括</strong>和<strong class="la iu">不包括</strong>的特征？</p><p id="f30a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们不应该假设所有的特征在预测结果时都起着重要的作用。其中有些可能无关紧要，也可能无关紧要。我们可以在相关图中清楚地观察到这一点。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="f695" class="ot mw it op b gy ou ov l ow ox">#correlation<br/>correlation = df.corr()<br/>#tick labels<br/>matrix_cols = correlation.columns.tolist()<br/>#convert to array<br/>corr_array  = np.array(correlation)</span><span id="d805" class="ot mw it op b gy oy ov l ow ox">#Plotting<br/>trace = go.Heatmap(z = corr_array,<br/>                   x = matrix_cols,<br/>                   y = matrix_cols,<br/>                   colorscale = "Magma",<br/>                   colorbar   = dict(title = "Pearson Correlation coefficient",<br/>                                     titleside = "right"<br/>                                    ) ,<br/>                  )</span><span id="02a8" class="ot mw it op b gy oy ov l ow ox">layout = go.Layout(dict(title = "Correlation Matrix for variables",<br/>                        autosize = False,<br/>                        height  = 720,<br/>                        width   = 800,<br/>                        margin  = dict(r = 0 ,l = 210,<br/>                                       t = 25,b = 210,<br/>                                      ),<br/>                        yaxis   = dict(tickfont = dict(size = 9)),<br/>                        xaxis   = dict(tickfont = dict(size = 9))<br/>                       )<br/>                  )</span><span id="b44f" class="ot mw it op b gy oy ov l ow ox">data = [trace]<br/>fig = go.Figure(data=data,layout=layout)<br/>iplot(fig)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pt"><img src="../Images/c87a5d1bcca5e7576c40857ba2d8809d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p3i2Ie-11lZMKMX12pTd1A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">相关图表</p></figure><p id="df0b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以从关联热图中观察到，不同的特征对客户流失有不同的影响。过多特征的结果是噪声，这会降低我们模型的性能。因此，我们如何确定哪些特征是重要的？— <strong class="la iu">功能选择</strong></p><p id="bcf4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">特征选择是机器学习中的核心技术之一，它将提高性能，缩短训练时间，并提高模型的简单性。有多种特征选择算法，我们今天将使用的一种被称为— <br/> <strong class="la iu">递归特征消除</strong>。</p><p id="218e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">递归特征消除(RFE)拟合模型并消除最弱的特征，直到达到指定的特征数量。下面是对它的详细解释:</p><blockquote class="pu pv pw"><p id="43e8" class="ky kz px la b lb lc ju ld le lf jx lg py li lj lk pz lm ln lo qa lq lr ls lt im bi translated">如前所述，递归特征消除(RFE，Guyon等人(<a class="ae lw" href="https://bookdown.org/max/FES/references.html#ref-Guyon" rel="noopener ugc nofollow" target="_blank"> 2002 </a>))基本上是预测器的向后选择。该技术首先在整个预测因子集上建立一个模型，并计算每个预测因子的重要性分数。然后移除最不重要的预测值，重新构建模型，并再次计算重要性分数。在实践中，分析师指定要评估的预测值子集的数量以及每个子集的大小。因此，子集大小是RFE的一个调整参数。优化性能标准的子集大小用于基于重要性排名选择预测器。然后，最佳子集用于训练最终模型。[4]</p></blockquote><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="f96f" class="ot mw it op b gy ou ov l ow ox">from sklearn.linear_model import LogisticRegression</span><span id="a20d" class="ot mw it op b gy oy ov l ow ox">from sklearn.feature_selection import RFE<br/>from sklearn.linear_model import LogisticRegression</span><span id="86b1" class="ot mw it op b gy oy ov l ow ox">log = LogisticRegression()</span><span id="e957" class="ot mw it op b gy oy ov l ow ox">rfe = RFE(log,10)<br/>rfe = rfe.fit(os_smote_X,os_smote_Y.values.ravel())</span><span id="2ea1" class="ot mw it op b gy oy ov l ow ox">#identified columns Recursive Feature Elimination<br/>idc_rfe = pd.DataFrame({"rfe_support" :rfe.support_,<br/>                       "columns" : [i for i in df.columns if i not in Id_col + metric_col],<br/>                       "ranking" : rfe.ranking_,<br/>                      })<br/>cols = idc_rfe[idc_rfe["rfe_support"] == True]["columns"].tolist()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qb"><img src="../Images/782e340c3a3d427a633986ad08d68ae4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_OdmN3K6RhodJ9aRSO2yFw.png"/></div></div></figure><p id="8ae7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这段代码中，我们选择了10个最好的特性来包含在我们的逻辑回归模型中。然后我们可以画出RFE的排名。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="8d5b" class="ot mw it op b gy ou ov l ow ox">import plotly.figure_factory as ff<br/>tab_rk = ff.create_table(idc_rfe)<br/>iplot(tab_rk)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qc"><img src="../Images/b9b65edd7e4fcf5418a13acee2606c79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*56_-kc1RNUHKYd0kCv5PtQ.png"/></div></div></figure><p id="21ed" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这张表显示了RFE选择的特性，以及它们各自的排名，这样你就可以衡量某个特性的重要性。<br/>我们现在可以分离数据集了。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="6bea" class="ot mw it op b gy ou ov l ow ox">#separating train and test data SMOTE<br/>train_rf_X_smote = os_smote_X[cols]<br/>train_rf_Y_smote = os_smote_Y<br/>test_rf_X_smote  = test[cols]<br/>test_rf_Y_smote  = test[metric_col]</span><span id="8835" class="ot mw it op b gy oy ov l ow ox">#separating train and test data Original<br/>train_rf_X = train_X[cols]<br/>train_rf_Y = train_Y<br/>test_rf_X = test_X[cols]<br/>test_rf_Y = test_Y</span></pre><p id="21f3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这个阶段，我们有<strong class="la iu"> 2 </strong>训练集和<strong class="la iu"> 2 </strong>测试集，其中所有特征都被递归消除。其中一个是原始数据，另一个应用了SMOTE。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="75f0" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">培训模式</h1><p id="65f8" class="pw-post-body-paragraph ky kz it la b lb nn ju ld le no jx lg lh np lj lk ll nq ln lo lp nr lr ls lt im bi translated">现在到了我们训练模型的实际阶段。<br/>有多种算法用于训练分类问题。<br/>我们无法判断哪种算法最适合我们的数据，因此我们通常使用多种算法进行训练，并根据精心选择的标准比较它们的性能。今天，我们将只关注<strong class="la iu">逻辑回归</strong>以及它与我们数据的吻合程度。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qd"><img src="../Images/af0c919f043ab6239115fdb81922dba1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6dBzfMkBEtnkeHKIfx_j5w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">维基媒体的Sigmoid函数</p></figure><p id="1b9e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">逻辑回归</strong>是最常用的机器学习算法之一，用来预测<strong class="la iu">二进制</strong>类，在这种情况下<strong class="la iu">流失</strong>而<strong class="la iu">不流失。</strong>它的工作原理是将基于Sigmoid函数的0和1之间的<strong class="la iu">输出概率</strong>附加到每个输入。基于默认为0.5的<strong class="la iu">阈值</strong>，高于该阈值的将被归类为<strong class="la iu"> 1 </strong>(流失)，低于该阈值的将被归类为<strong class="la iu"> 0 </strong>(非流失)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qe"><img src="../Images/f0b57ce1133fe0f3ec4a6aac027869a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kff3L1uPscTy_91CrrVn2g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae lw" href="https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html#decision-boundary" rel="noopener ugc nofollow" target="_blank"> ML-Cheatsheet </a>决定边界</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qf"><img src="../Images/d9b2d972277d022a6b2fea6f52ee044c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*igkHs_pbTFHaD5GCw4WYEw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">决策阈值</p></figure><p id="bbcb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，如果我们的阈值是0.5，而我们对一组特征的预测概率是0.7，那么在我们的例子中，我们会将这个观察结果归类为<strong class="la iu">变动</strong>。</p><p id="4715" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">理解了这一点，让我们训练我们的数据。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="9d2a" class="ot mw it op b gy ou ov l ow ox">#training for dataset without smote<br/>logit_ori_rfe = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,<br/>          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,<br/>          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,<br/>          verbose=0, warm_start=False)<br/>logit_ori_rfe.fit(train_rf_X,train_rf_Y)</span><span id="cd6a" class="ot mw it op b gy oy ov l ow ox">#training for dataset with smote<br/>logit_smote_rfe = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,<br/>          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,<br/>          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,<br/>          verbose=0, warm_start=False)<br/>logit_smote_rfe.fit(train_rf_X_smote,train_rf_Y_smote)</span></pre><p id="f4eb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">差不多就是这样，我们的模型已经训练好了。如你所见，训练一个模特并没有你想象的那么复杂。<br/>大多数时候，将数据转换成“好的”格式进行训练，以及评估您的模型，这是非常耗时的部分。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="6f4e" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">评估您的模型</h1><p id="6d86" class="pw-post-body-paragraph ky kz it la b lb nn ju ld le no jx lg lh np lj lk ll nq ln lo lp nr lr ls lt im bi translated">我们有两种型号。一个用<strong class="la iu"> SMOTE </strong>数据集训练，一个用<strong class="la iu">原始</strong>数据集训练。我们可以开始使用这些模型进行预测，但我们想首先<strong class="la iu">评估</strong>这些模型的准确程度。<br/>为了评估模型，我们需要考虑一些标准。</p><p id="158b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于分类，我们用来评估模型的几个常用指标是</p><ul class=""><li id="075a" class="ma mb it la b lb lc le lf lh mc ll md lp me lt mf mg mh mi bi translated">准确(性)</li><li id="1d98" class="ma mb it la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">精确</li><li id="8e6f" class="ma mb it la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">召回</li><li id="0337" class="ma mb it la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">f1-分数</li><li id="1607" class="ma mb it la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">ROC曲线</li></ul><p id="15f4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我解释一下每一个的意思。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qg"><img src="../Images/cb0d2d28af7df4e4606a733a49016af7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*od1pORZ9KyT_IqdExqxkPA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">精确度和召回由<a class="ae lw" href="https://en.wikipedia.org/wiki/Precision_and_recall" rel="noopener ugc nofollow" target="_blank">维基媒体</a></p></figure><p id="f6d0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在讨论召回率和精确度之前，我们需要了解什么是误报、漏报以及它们的对应情况。</p><p id="4730" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这可以通过左边的图表更好地解释，想象完整的图表是我们的数据集，圆圈是我们模型的预测。图的左边是实际的正值(1)，图的右边是实际的负值(0)。</p><p id="7038" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">看左边的圆圈，圆圈内的所有点都被我们的模型预测为正，而圆圈外的所有点都被我们的模型预测为负。我们还知道，在图的左边，圆圈外的所有点都是正的。因此，它被错误地预测，指示一个<strong class="la iu">假阴性。</strong>图表左侧圆圈中的所有点都被正确预测，表明<strong class="la iu">真阳性</strong>。</p><p id="df50" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">反之亦然适用于图的右侧。</p><h2 id="89c3" class="ot mw it bd mx pe pf dn nb pg ph dp nf lh pi pj nh ll pk pl nj lp pm pn nl po bi translated">精确度和召回率</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qh"><img src="../Images/5d50950934d4f39410e9d9424af1aa47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5oSIzp0QcoY0enr5rZwT6A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">维基百科的精确度和召回率</p></figure><p id="41c1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">精确度和召回率使我们对模型有了更深入的理解。<br/>精度定义为相关结果的百分比，<br/>召回定义为正确分类的相关结果的百分比。</p><p id="6f2c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在不涉及太多细节的情况下，我们模型中的精度指的是被正确分类的<strong class="la iu">预测流失客户</strong>的百分比。</p><p id="59fd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">召回措施为正确分类的<strong class="la iu">实际流失客户</strong>的百分比。</p><h2 id="ac08" class="ot mw it bd mx pe pf dn nb pg ph dp nf lh pi pj nh ll pk pl nj lp pm pn nl po bi translated">F1分数</h2><p id="37e7" class="pw-post-body-paragraph ky kz it la b lb nn ju ld le no jx lg lh np lj lk ll nq ln lo lp nr lr ls lt im bi translated">在许多情况下，我们可以根据您试图解决的问题来优先考虑精度或回忆。在我们的案例中，我们肯定希望<strong class="la iu">优先考虑</strong> <strong class="la iu">尽可能准确地预测实际客户流失</strong>，这样我们就可以说服他们留下来。</p><p id="78bc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在一般情况下，有一个指标可以协调精确度和召回率，这就是F1分数。总体目标是最大化F1分数，使你的模型更好。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qi"><img src="../Images/af48f7986fb362cfaa104792d17fcae6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0Xc3PC7RTb3QdbQOcjyfVQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">F1分数公式</p></figure><h2 id="5e03" class="ot mw it bd mx pe pf dn nb pg ph dp nf lh pi pj nh ll pk pl nj lp pm pn nl po bi translated">ROC曲线和AUC</h2><p id="0bca" class="pw-post-body-paragraph ky kz it la b lb nn ju ld le no jx lg lh np lj lk ll nq ln lo lp nr lr ls lt im bi translated">在调整多个变量以最大化我们的精确度、召回率和F1分数之后，我们还可以调整模型的阈值。</p><p id="63e3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，阈值默认为0.5，高于该值的任何输出概率都将被归类为1。我们可以<strong class="la iu">将阈值</strong>更改为更低/更高的值，以进一步增加我们的首选指标。</p><p id="01cf" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了形象化这种变化，我们可以画出每个阈值对假阳性率和真阳性率的影响。曲线看起来会像这样。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qj"><img src="../Images/a8aa958395502045c4221eadb0fbf9a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qTce1X_3PR-j_kpZgCRJKQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">受试者工作特征曲线</p></figure><p id="5ae5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">再说一次，不要涉及太多的细节，你的模型越好，曲线(蓝色)就越靠近图的左上角。相反，一个在分类方面做得很差的模型会向直线(红色)收敛，这不比随机猜测好。</p><p id="8056" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用ROC曲线，我们可以正确地确定一个模型是否优于另一个模型。我们也可以根据我们是否应该<strong class="la iu">最大化真阳性率</strong>，或者<strong class="la iu">最小化假阳性率</strong>来选择我们的分类阈值。在我们的情况下，我们应该以最大化真实阳性率为目标。因此，这也将增加我们的<strong class="la iu">召回</strong>指标。</p><h2 id="f66d" class="ot mw it bd mx pe pf dn nb pg ph dp nf lh pi pj nh ll pk pl nj lp pm pn nl po bi translated">准确(性)</h2><p id="1273" class="pw-post-body-paragraph ky kz it la b lb nn ju ld le no jx lg lh np lj lk ll nq ln lo lp nr lr ls lt im bi translated">准确性是衡量模型性能的最基本的标准。它基本上是根据测试集正确预测的输出的百分比。</p><p id="09cc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，我们确实应该考虑将<strong class="la iu">召回</strong>、<strong class="la iu">准确性</strong>和<strong class="la iu"> F1 </strong> <strong class="la iu">得分</strong>作为这个特定模型的重要指标。</p><p id="8b11" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们开始吧。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="7975" class="ot mw it op b gy ou ov l ow ox">#perfoming evaluation for original dataset<br/>predictions   = logit_ori_rfe.predict(test_rf_X)<br/>probabilities = logit_ori_rfe.predict_proba(test_rf_X)</span><span id="8bde" class="ot mw it op b gy oy ov l ow ox">print(classification_report(test_rf_Y,predictions))</span><span id="3d1b" class="ot mw it op b gy oy ov l ow ox">#confusion matrix<br/>conf_matrix = confusion_matrix(test_rf_Y,predictions)<br/>conf_matrix</span><span id="9589" class="ot mw it op b gy oy ov l ow ox">#roc_auc_score<br/>model_roc_auc = roc_auc_score(test_rf_Y,predictions) <br/>print ("Area under curve : ",model_roc_auc,"\n")<br/>fpr,tpr,thresholds = roc_curve(test_rf_Y,probabilities[:,1])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qk"><img src="../Images/54f197f5041c369e9d1b134a220e5898.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y6RxnGvJ9UURFbOWMK3Pbg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">评估指标</p></figure><p id="66cc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从我们在原始数据集上训练的模型来看，总体准确率相当高，为<strong class="la iu"> 81% </strong>。然而，我们可以看到代表<strong class="la iu">流失客户</strong>的<strong class="la iu">类别1 </strong>的所有指标都相当低。</p><ul class=""><li id="234b" class="ma mb it la b lb lc le lf lh mc ll md lp me lt mf mg mh mi bi translated">精度为69%</li><li id="5f6a" class="ma mb it la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">召回率为56%</li><li id="470d" class="ma mb it la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">F1为62%</li></ul><p id="dc2d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">由于观察值数量的不平衡，我们得到了一个相当高的加权平均值，因为与类别1相比，类别0的观察值要多得多。这是一个危险信号的迹象，因为我们的首要任务是能够准确预测1级。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="07ed" class="ot mw it op b gy ou ov l ow ox">#plot roc curve<br/>trace2 = go.Scatter(x = fpr,y = tpr,<br/>                    name = "Roc : " + str(model_roc_auc),<br/>                    line = dict(color = ('rgb(22, 96, 167)'),width = 2))<br/>trace3 = go.Scatter(x = [0,1],y=[0,1],<br/>                    line = dict(color = ('rgb(205, 12, 24)'),width = 2,<br/>                    dash = 'dot'))</span><span id="e272" class="ot mw it op b gy oy ov l ow ox">data = [trace2,trace3]</span><span id="15f9" class="ot mw it op b gy oy ov l ow ox">layout = go.Layout(dict(title = "Receiver operating characteristic",<br/>                        autosize = False,<br/>                        height = 700,width = 800,<br/>                        plot_bgcolor = 'rgba(240,240,240, 0.95)',<br/>                        paper_bgcolor = 'rgba(240,240,240, 0.95)',<br/>                        margin = dict(b = 195),<br/>                        xaxis = dict(title = "false positive rate"),<br/>                        yaxis = dict(title = "true positive rate"),<br/>                       )<br/>                  )</span><span id="0384" class="ot mw it op b gy oy ov l ow ox">#defining figure and plotting<br/>fig = go.Figure(data,layout=layout)<br/>iplot(fig)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/8bdf391a2d214760463fddadb11325fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*gsl_mRlpLmouRjriZRsT9Q.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">受试者工作特征曲线</p></figure><p id="d070" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从ROC曲线上我们看到AUC是73%，后面可以对比其他模型。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="6ab2" class="ot mw it op b gy ou ov l ow ox">visualizer = DiscriminationThreshold(logit_ori_rfe)<br/>visualizer.fit(train_X,train_Y)<br/>visualizer.poof()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ql"><img src="../Images/fdb113828903f40dc9fb983a48b4cd9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cjIM2L-Ck7rQFIv26f0gmQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">阈值图</p></figure><p id="556d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">阈值图对于我们确定<strong class="la iu">阈值</strong>也很有用。正如我们所知，我们正试图<strong class="la iu">最大化</strong> <strong class="la iu">召回</strong>，同时不牺牲太多其他指标。阈值图帮助我们准确地做到这一点。<br/>看起来接近0.3的阈值将允许我们最大限度地提高召回率，同时保持其他指标不变。</p><p id="1ecd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这就是我们迄今为止对第一个模型的理解，让我们评估一下由SMOTE数据集训练的模型。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="4835" class="ot mw it op b gy ou ov l ow ox">#perfoming evaluation for original dataset<br/>predictions   = logit_smote_rfe.predict(train_rf_X_smote)<br/>probabilities = logit_smote_rfe.predict_proba(train_rf_X_smote)</span><span id="97a4" class="ot mw it op b gy oy ov l ow ox">print(classification_report(train_rf_Y_smote,predictions))</span><span id="ad9a" class="ot mw it op b gy oy ov l ow ox">#confusion matrix<br/>conf_matrix = confusion_matrix(train_rf_Y_smote,predictions)<br/>conf_matrix</span><span id="cc8e" class="ot mw it op b gy oy ov l ow ox">#roc_auc_score<br/>model_roc_auc = roc_auc_score(train_rf_Y_smote,predictions) <br/>print ("Area under curve : ",model_roc_auc,"\n")<br/>fpr,tpr,thresholds = roc_curve(train_rf_Y_smote,probabilities[:,1])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qm"><img src="../Images/6a68e3b4cede49ca0fe25cd6cc0005ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KLbx2NypWZuCp4X0oGTmkQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">评估指标</p></figure><p id="23b3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">很快，您可以观察到<strong class="la iu">第1类(流失客户)</strong>的所有指标都显著增加。不利的一面是，整体精度会略有下降。</p><ul class=""><li id="1549" class="ma mb it la b lb lc le lf lh mc ll md lp me lt mf mg mh mi bi translated">精度为75%</li><li id="ba21" class="ma mb it la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">召回率为83%(几乎增加了30%)</li><li id="4bfe" class="ma mb it la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">F1为78%</li></ul><p id="3624" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">作为一名专业的数据科学家，您应该在一天中的任何时候推荐这个模型而不是第一个模型。因为当务之急是准确预测<strong class="la iu"/><strong class="la iu"/>的客户流失，所以你必须明白这个模型比之前的模型做得好得多，即使整体准确性略有下降。这就是真正的数据科学家与平庸的数据科学家的区别。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="43ae" class="ot mw it op b gy ou ov l ow ox">#plot roc curve<br/>trace2 = go.Scatter(x = fpr,y = tpr,<br/>                    name = "Roc : " + str(model_roc_auc),<br/>                    line = dict(color = ('rgb(22, 96, 167)'),width = 2))<br/>trace3 = go.Scatter(x = [0,1],y=[0,1],<br/>                    line = dict(color = ('rgb(205, 12, 24)'),width = 2,<br/>                    dash = 'dot'))</span><span id="3a4c" class="ot mw it op b gy oy ov l ow ox">data = [trace2,trace3]</span><span id="f7ca" class="ot mw it op b gy oy ov l ow ox">layout = go.Layout(dict(title = "Receiver operating characteristic",<br/>                        autosize = False,<br/>                        height = 700,width = 800,<br/>                        plot_bgcolor = 'rgba(240,240,240, 0.95)',<br/>                        paper_bgcolor = 'rgba(240,240,240, 0.95)',<br/>                        margin = dict(b = 195),<br/>                        xaxis = dict(title = "false positive rate"),<br/>                        yaxis = dict(title = "true positive rate"),<br/>                       )<br/>                  )</span><span id="62e7" class="ot mw it op b gy oy ov l ow ox">#defining figure and plotting<br/>fig = go.Figure(data,layout=layout)<br/>iplot(fig)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/a4e350beeda39e6573119309e9b41d50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*HAVnAVoagx8iRy1n2e3OFw.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">受试者工作特征曲线</p></figure><p id="4931" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从ROC曲线中，我们观察到AUC约为78%,比我们之前的模型高出约5%。这表明我们的SMOTE模型优于以前的模型。</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="963e" class="ot mw it op b gy ou ov l ow ox">visualizer = DiscriminationThreshold(logit_smote_rfe)<br/>visualizer.fit(train_rf_X_smote,train_rf_Y_smote)<br/>visualizer.poof()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qn"><img src="../Images/84c988b9ba153e0e5ae7b4501fcd65a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5Bkdqil_0SiAAwREN3dv6g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">阈值图</p></figure><p id="79c5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">阈值图也表明了我们当前模型的性能优势。请注意，我们如何在这里将阈值调得更高，以获得相对较高的召回率、精确度和准确度。</p><p id="3be3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当前模型，阈值=0.4:</p><ul class=""><li id="7dc5" class="ma mb it la b lb lc le lf lh mc ll md lp me lt mf mg mh mi bi translated">约90%的召回率</li><li id="a0cd" class="ma mb it la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">F1分数约为80%</li><li id="a594" class="ma mb it la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">大约70%的精度</li></ul><p id="78f8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">以前的模型，阈值= 0.3:</p><ul class=""><li id="b9dc" class="ma mb it la b lb lc le lf lh mc ll md lp me lt mf mg mh mi bi translated">约80%的召回率</li><li id="3bd0" class="ma mb it la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">F1分数约为60%</li><li id="61cf" class="ma mb it la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">大约50%的精度</li></ul><p id="cd59" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请注意，我们希望<strong class="la iu">避免</strong>设置太低的阈值，否则我们会以过多的误报而告终。看起来我们有一个明显的赢家。</p><p id="aa1e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">总的来说，我们用两个不同的数据集使用逻辑回归训练了两个模型，一个使用SMOTE采样，一个不使用。基于几个标准，SMOTE模型在预测流失客户方面表现<strong class="la iu">明显更好。现在，您可以使用该模型来预测未来的客户流失。</strong></p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="5a09" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">结论</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qo"><img src="../Images/05901e3de8f3371eb8f7b4794cd43eb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OrMUlRoempjQiZH3"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae lw" href="https://unsplash.com/@acharki95?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">阿齐兹·阿查基</a>在<a class="ae lw" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="4d9b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">做得好，我知道这是一个漫长的，但它是值得的。<br/>机器学习是一个复杂的过程，有许多因素决定你的模型的性能，从而决定你的技能组合。</p><p id="18eb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，您已经了解到:</p><ul class=""><li id="aec3" class="ma mb it la b lb lc le lf lh mc ll md lp me lt mf mg mh mi bi translated">什么是机器学习</li><li id="6207" class="ma mb it la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">数据预处理(数值和分类)</li><li id="de99" class="ma mb it la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">取样操作</li><li id="0e75" class="ma mb it la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">特征选择</li><li id="56b3" class="ma mb it la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">培训模型</li><li id="53c3" class="ma mb it la b lb mj le mk lh ml ll mm lp mn lt mf mg mh mi bi translated">评估模型</li></ul><p id="d2ae" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这些技术只是机器学习的开始，<br/>我们还有更多的内容要介绍。</p><h2 id="5017" class="ot mw it bd mx pe pf dn nb pg ph dp nf lh pi pj nh ll pk pl nj lp pm pn nl po bi translated">在你走之前</h2><p id="5c29" class="pw-post-body-paragraph ky kz it la b lb nn ju ld le no jx lg lh np lj lk ll nq ln lo lp nr lr ls lt im bi translated">我们的数据之旅还没有结束。随着数据行业人才的缺乏，用机器学习的适当知识来教育自己将使你在获得数据角色方面具有优势。请继续关注，我将在下一篇文章中讨论如何为您的数据集选择正确的模型，以及更多关于数据行业的故事、指南和经验。与此同时，请随意查看我的其他文章，以暂时满足您对数据的渴望。</p><p id="a7d4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一如既往，我引用一句话作为结束。</p><blockquote class="pu pv pw"><p id="2694" class="ky kz px la b lb lc ju ld le lf jx lg py li lj lk pz lm ln lo qa lq lr ls lt im bi translated">在机器学习和人工智能领域，我们需要迎头赶上。——<strong class="la iu">克劳斯·弗罗利希</strong></p></blockquote></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h2 id="3b67" class="ot mw it bd mx pe pf dn nb pg ph dp nf lh pi pj nh ll pk pl nj lp pm pn nl po bi translated"><a class="ae lw" href="https://www.nicholas-leong.com/sign-up-here" rel="noopener ugc nofollow" target="_blank">订阅我的时事通讯，保持联系。</a></h2><p id="068b" class="pw-post-body-paragraph ky kz it la b lb nn ju ld le no jx lg lh np lj lk ll nq ln lo lp nr lr ls lt im bi translated">也可以通过<a class="ae lw" href="https://nickefy.medium.com/membership" rel="noopener"> <strong class="la iu">我的链接</strong> </a>注册中等会员来支持我。你将能够从我和其他不可思议的作家那里读到无限量的故事！</p><p id="3afa" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我正在撰写更多关于数据行业的故事、文章和指南。你绝对可以期待更多这样的帖子。与此同时，可以随时查看我的其他<a class="ae lw" href="https://medium.com/@nickmydata" rel="noopener"> <strong class="la iu">文章</strong> </a>来暂时填补你对数据的饥渴。</p><p id="eecb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> <em class="px">感谢</em> </strong> <em class="px">的阅读！如果你想与我取得联系，请随时联系我在nickmydata@gmail.com或我的</em> <a class="ae lw" href="https://www.linkedin.com/in/nickefy/" rel="noopener ugc nofollow" target="_blank"> <em class="px"> LinkedIn个人资料</em> </a> <em class="px">。也可以在我的</em><a class="ae lw" href="https://github.com/nickefy" rel="noopener ugc nofollow" target="_blank"><em class="px">Github</em></a><em class="px">中查看之前写的代码。</em></p></div></div>    
</body>
</html>