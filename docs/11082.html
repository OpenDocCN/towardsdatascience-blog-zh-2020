<html>
<head>
<title>Everything Has Its Price — How to Price Words and Phrases, in Online Ad Bidding and More</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">任何东西都有它的价格——如何给单词和短语定价，在线广告竞价等等</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/everything-has-its-price-how-to-price-words-for-ad-bidding-etc-7df38e1d152?source=collection_archive---------36-----------------------#2020-08-01">https://towardsdatascience.com/everything-has-its-price-how-to-price-words-for-ad-bidding-etc-7df38e1d152?source=collection_archive---------36-----------------------#2020-08-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="e391" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这篇文章概述了自然语言单词或短语定价的 NLP 方法。它创造性地利用了(1)模型 word2vec，它从给定的语料库中学习上下文和单词之间的关联；(Mondovo 数据集，它为我们进一步引导我们的应用程序提供了基本的构建块。该解决方案将在诸如在线广告竞价、在线营销、搜索引擎优化等领域具有有趣的应用。这篇文章是定价问题的初始基线解决方案的一个示例，渴望了解更多关于我在实践中是如何做的以及对该主题更深入的处理的读者欢迎收听我的后续出版物。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/0ecc3631e43ebaca44d6bee1b114c047.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ovvUoeXjnimC7rky"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">由<a class="ae lf" href="https://unsplash.com/@markuswinkler?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马库斯·温克勒</a>在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="00b0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">人们正在量化一切。当我们无法做到这一点时，我们称之为无价值的或神秘的，或熟练地将其视为幻觉；爱情、忠诚、诚实等等就是如此。</p><p id="f296" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在线广告竞价行业绝对不是例外，他们最大的问题之一是如何为他们选择的广告关键词或短语提供准确的竞价价格，以确保出版商网站上的一些热点广告。困境是这样的:如果出价太高，你可能肯定会得到广告位，但你也将不得不支付你出价的高昂价格；如果你把出价定得太低，你可能很难得到那个广告位。显然，这种微妙的权衡需要创造性地解决将单词/短语量化为价格的问题。</p><p id="2ed7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">幸运的是，我们可以放心一个响亮的好消息:<strong class="js iu">单词也可以定价！对于这个问题，我们可能没有像 Black-Scholes 期权定价模型那样精心制作的处方，但我们有多种方法可以解决这个问题。</strong></p><p id="a905" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在本文中，我将为关键词定价问题草拟一个简单的解决方案，它基本上使用了一种叫做<strong class="js iu"> word2vec 的自然语言处理技术。</strong>接下来的部分将展示如何处理数据，在哪里使用 word2vec，如何<strong class="js iu"> </strong>将我们的问题转化为一个回归任务，最后展示整个管道的性能。</p><p id="7a85" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们开始吧。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi lg"><img src="../Images/dea6b03ed9b0fa772dea4af686b6621c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4XQNkIWMVhzXq1dJ"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><a class="ae lf" href="https://unsplash.com/@johnking?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">约翰·金</a>在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><h1 id="f55d" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">word2vec 简介</h1><p id="bb3d" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn im bi translated">追溯统计语言模型的演变可能是有帮助的。首先，我们有简单的<strong class="js iu">词袋模型</strong>，在这个模型中，我们离散地对待语料库中的每个词；没有上下文，没有依赖，只有独立的词。对于这样一个模型，你能做的最好的事情就是想出一个词频图表。</p><p id="b10a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">接下来是<strong class="js iu"> n 元模型</strong>。单字，即单个单词，没有那么强大，但我们可以扩展到双字、三字、四字等，其中每 N (2、3、4 或更多)个连续的单词被视为一个整体(作为单个单词)。可以说，这样的模型将能够捕捉大小为 N 的单词上下文，并使我们能够进行更复杂的预测和推理。例如，我们可以轻松地构建更强大的概率状态转移模型，如马尔可夫链，它支持日常应用，如单词自动暗示或自动完成。</p><p id="853a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">相比之下，<strong class="js iu"> word embedding </strong>是一个语言模型家族，其中使用向量来描述/表示词汇表中的单词或短语，而<strong class="js iu"> word2vec </strong>是最流行的技术之一。一般来说，它使用神经网络从给定的语料库中学习单词关联/关系，并使用给定长度的向量来表示每个单词，使得单词之间的语义相似性将与它们的向量表示之间的向量相似性相关。维基百科页面将提供一个很好的初始指针，对于这个主题的更深入的处理，请继续关注我未来的帖子。</p><h1 id="ddca" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">数据处理</h1><p id="1a8b" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn im bi translated">这是极其重要的一步。为了让我们提出任何模型，我们首先需要数据。此外，为了让我们的模型学习数据之间任何有意义的关系，我们希望数据包含从自然语言单词到价格的示例映射。不幸的是，互联网上有许多这样的数据集，我能找到的一个来自<a class="ae lf" href="https://www.mondovo.com/keywords/most-asked-questions-on-google" rel="noopener ugc nofollow" target="_blank"> Mondovo </a>。这个特定的数据集包含了 Google 上最常问的 1000 个问题及其相关的全球每次点击成本，尽管数据集相当小，但它提供了我们需要的基本成分:单词及其价格。</p><p id="7b41" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">将这 1000 行数据打包成一个包含两列的 pandas dataframe 是相当容易的:<em class="ko">关键字</em>和<em class="ko">价格</em>，从现在开始我们称这个 dataframe 为<em class="ko"> df </em>。</p><p id="31f0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后，让我们执行以下步骤，以确保数据的顺序确实是随机的:</p><pre class="kq kr ks kt gt mk ml mm mn aw mo bi"><span id="89e9" class="mp li it ml b gy mq mr l ms mt">df = df.sample(frac=1).reset_index(drop=True)</span></pre><p id="076b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这就是我们的数据预处理。</p><h1 id="828a" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated"><strong class="ak">模型导入</strong></h1><p id="449d" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn im bi translated">现在让我们稍微关心一下 word2vec。在这项任务中，我们将依赖于一些现成的向量表示，而不是从我们自己的语料库(即 1000 个短语)中学习单词向量表示。以下代码片段将介绍 Google 的开箱即用解决方案:</p><pre class="kq kr ks kt gt mk ml mm mn aw mo bi"><span id="9452" class="mp li it ml b gy mq mr l ms mt">import gensim.downloader as api</span><span id="dd0d" class="mp li it ml b gy mu mr l ms mt">wv = api.load('word2vec-google-news-300')</span></pre><p id="77f4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">据<a class="ae lf" href="https://github.com/mmihaltz/word2vec-GoogleNews-vectors" rel="noopener ugc nofollow" target="_blank">这位消息人士</a>称，该模型建立在‘预先训练好的谷歌新闻语料库(30 亿个运行词)，(并包含)词向量模型(300 万个 300 维英文词向量)’。</p><h1 id="8ecd" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">从单词到句子</h1><p id="70d6" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn im bi translated">这里有一个问题:<strong class="js iu">模型 word2vec 只包含单个单词的向量表示，但是我们需要像我们数据集中的那些短句/短语</strong>的向量表示。</p><p id="bb75" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">至少有三种方法可以解决这个问题:</p><p id="5fee" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">(1)取短句中所有单词的向量的平均值；</p><p id="52c6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">(2)类似地，取平均值，但是使用单词的 idf(逆文档频率)分数对每个向量进行加权；</p><p id="43b5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">(3)使用 doc2vec，而不是 word2vec。</p><p id="b72e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这里，我很想看看基线模型的表现如何，所以让我们暂时使用(1 ),将其他选项留给将来的探索。</p><p id="1d19" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">以下代码片段将提供一个简单的示例来实现平均函数:</p><pre class="kq kr ks kt gt mk ml mm mn aw mo bi"><span id="ac6b" class="mp li it ml b gy mq mr l ms mt">def get_avg(phrase, wv):<br/>    vec_result = []<br/>    tokens = phrase.split(' ')</span><span id="05c6" class="mp li it ml b gy mu mr l ms mt">    for t in tokens:<br/>        if t in wv:<br/>            vec_result.append(wv[t].tolist())<br/>        else:<br/>            #300 is the dimension of the Google wv model<br/>            vec_result.append([0.0]*300)</span><span id="4fca" class="mp li it ml b gy mu mr l ms mt">    return np.average(vec_result, axis=0)</span></pre><p id="c376" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请注意<em class="ko">如果</em>条件在某个“停用词”(给定语言中极其常见且通常无信息的词)中是必要的。在英语中，认为“the”、“it”、“which”等已被排除在谷歌模式之外。在上面的片段中，我留了一些余地，跳过了详细处理缺少单词或停用词的主题。在我以后的文章中，将会有更深入的讨论。请继续收看！</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mv"><img src="../Images/f175f7859208dfe7211ad3d5b8c8b26c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*anOVCGt4Swy8AAky"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">照片由<a class="ae lf" href="https://unsplash.com/@mbaumi?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">米卡·鲍梅斯特</a>在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="c50c" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">回归问题设置</h1><p id="a7c3" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn im bi translated"><strong class="js iu">请记住，从根本上讲，几乎所有的机器学习算法都期望数字输入</strong>:例如，在图像处理问题中，黑白图片作为 0–1 的矩阵提供给算法，彩色图片作为 RGB 张量。我们的问题也不例外，这就是为什么我们不厌其烦地介绍 word2vec。</p><p id="5fe7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">考虑到这一点，让我们看看机器学习算法中使用的特征矩阵和目标向量:</p><pre class="kq kr ks kt gt mk ml mm mn aw mo bi"><span id="a658" class="mp li it ml b gy mq mr l ms mt">X = np.array([get_avg(phrase, wv) for phrase in df['keyword']])</span><span id="135b" class="mp li it ml b gy mu mr l ms mt">y = df['price']</span></pre><p id="0ce3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">由于我们预测的是一些数值，这是一个回归问题。让我们为此任务选择一些简便的回归算法:</p><pre class="kq kr ks kt gt mk ml mm mn aw mo bi"><span id="1abd" class="mp li it ml b gy mq mr l ms mt">from sklearn.ensemble import RandomForestRegressor</span><span id="a8a2" class="mp li it ml b gy mu mr l ms mt">#leaving out all params tuning to show absolute baseline performance<br/>reg = RandomForestRegressor(random_state=0)</span></pre><h1 id="09a1" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">表演</h1><p id="8ff1" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn im bi translated">现在我们终于能够看到我们的绝对基线模型的表现了。让我们建立如下 10 重交叉验证方案:</p><pre class="kq kr ks kt gt mk ml mm mn aw mo bi"><span id="87ad" class="mp li it ml b gy mq mr l ms mt">from sklearn.model_selection import KFold</span><span id="d084" class="mp li it ml b gy mu mr l ms mt">from sklearn.metrics import mean_absolute_error</span><span id="95a3" class="mp li it ml b gy mu mr l ms mt">#set up 10-fold Cross Validation:<br/>kf = KFold(n_splits=10)</span><span id="6d2e" class="mp li it ml b gy mu mr l ms mt">#loop over each fold and retrieve result<br/>for train_index, test_index in kf.split(X):<br/>    X_train, X_test = X[train_index], X[test_index]<br/>    y_train, y_test = y[train_index], y[test_index]</span><span id="af94" class="mp li it ml b gy mu mr l ms mt">    reg.fit(X_train, y_train)<br/>    <br/>    print(mean_absolute_error(y_test, reg.predict(X_test)))</span></pre><p id="3305" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我的实验中，运行上面的代码给出了 MAE 分数 1.53、0.98、1.06、1.23、1.02、1.01、1.06、1.19、0.96 和 0.96，导致平均 MAE 为 1.1，这意味着我们的估计价格平均可能会偏离真实价值 1.1 美元。</p><p id="c534" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">考虑到可用的数据稀少，训练数据中缺乏单词冗余，样本内数据点稀疏，以及我们在没有任何参数优化的情况下的绝对基线假设，我对我们目前的方法能够推进的程度印象深刻。不难想象，一些热心的读者自己做实验一定会取得更好的结果。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="mw mx l"/></div></figure></div></div>    
</body>
</html>