<html>
<head>
<title>Building predictive models with MyAnimeList and Sklearn (Part 1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用MyAnimeList和Sklearn构建预测模型(第1部分)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-predictive-models-with-myanimelist-and-sklearn-54edc6c9fff3?source=collection_archive---------49-----------------------#2020-03-30">https://towardsdatascience.com/building-predictive-models-with-myanimelist-and-sklearn-54edc6c9fff3?source=collection_archive---------49-----------------------#2020-03-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="14c0" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">本文使用MyAnimeList数据库中的许多特性变量来预测用户评分</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b7cd9615e018993c14e5c8574024186d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*25bQsi_QN8hgVKtIcE59Gg.png"/></div></div></figure><p id="2749" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi"><a class="ae lq" href="https://myanimelist.net/" rel="noopener ugc nofollow" target="_blank"><strong class="kw iu">MyAnimeList</strong></a> is one of the largest online data repositories for anime on the internet with listings ranging from TV series to Manga comics and data dating back to ~1905 (for anyone interested, this is <a class="ae lq" href="https://myanimelist.net/anime/33187/Katsudou_Shashin" rel="noopener ugc nofollow" target="_blank"><strong class="kw iu">活動写真/Katsudou Shashin</strong></a>). Luckily this data is all <a class="ae lq" href="https://www.kaggle.com/azathoth42/myanimelist" rel="noopener ugc nofollow" target="_blank"><strong class="kw iu">available on Kaggle</strong></a><strong class="kw iu"> </strong>and comes split into different components/data-frames: user ratings and anime listing information. Given my mutual love for anime and all things data, I thought it would be cool to combine data and to build some predictive models and basic recommendation systems in Python. I will discuss the intricacies of such in more detail below. The first section of my work with the MyAnimeList will focus on some machine learning techniques used to predict user rating scores using a variety of features that were computed for analysis using Sklearn. The second section will follow this post and will hone in on some simple techniques used to recommend anime content, based on both user rating correlations and feature variables.</p><h2 id="409f" class="lr ls it bd lt lu lv dn lw lx ly dp lz ld ma mb mc lh md me mf ll mg mh mi mj bi translated">数据准备</h2><p id="4841" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">在执行任何分析之前，安装必要的软件包:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="fdd7" class="lr ls it mq b gy mu mv l mw mx">import numpy as np<br/>import pandas as pd<br/>import sklearn<br/>import matplotlib.pyplot as plt<br/>import seaborn as sb<br/>from sklearn.preprocessing import LabelEncoder<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor<br/>from sklearn.model_selection import GridSearchCV<br/>from sklearn.metrics import accuracy_score<br/>from sklearn.neural_network import MLPRegressor, MLPClassifier<br/>from sklearn import metrics<br/>from matplotlib import rcParams<br/>import joblib<br/>from sklearn.tree import export_graphviz<br/>import pydot<br/>from IPython.display import Image</span></pre><p id="9363" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">从本地导入两个数据框:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="8152" class="lr ls it mq b gy mu mv l mw mx">local_1 = '/Users/hopkif05/Desktop/rating.csv'<br/>ratings = pd.read_csv(local_1)</span><span id="8ce2" class="lr ls it mq b gy my mv l mw mx">local_2 = '/Users/hopkif05/Desktop/AnimeList.csv'<br/>anime_list = pd.read_csv(local_2)</span></pre><p id="a072" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">并将它们连接在一个唯一的标识符上，在这种情况下是它们的<em class="mz"> anime_id </em>:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="80a7" class="lr ls it mq b gy mu mv l mw mx">anime = pd.merge(ratings, anime_list, on=’anime_id’)<br/>anime.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/1b45fda42ea92e92b2fcfda7f93d0f76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ArxKjySWp2O45335Z8WD1g.png"/></div></div></figure><p id="6bad" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">您可以从上面的数据框中看到，我们现在在数据库中有每个用户的评级，这些评级已经与该内容相关的所有元数据合并在一起。这里有大约800万个用户评级，有33行，每一行代表我们模型的一个潜在特征变量。为了后续的分析，我已经<em class="mz">选择了user_id、anime_id、rating_x、title_english、type、source、scored_by、score、favorites、members、popularity </em>和<em class="mz"> studio </em>作为模型中包含的变量；并将它们存储在一个新的数据帧中:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="727e" class="lr ls it mq b gy mu mv l mw mx">anime_df = anime[[‘user_id’,’anime_id’,’rating_x’,’title_english’,’type’,’source’,’scored_by’,’score’,’favorites’,’members’,’popularity’,’studio’]].copy()<br/>anime_df.head(100)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/03c35e7257faa59a9e327c91587c5860.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GUyST4c6G9Et0sD335ogZA.png"/></div></div></figure><p id="9ec8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">您可能会注意到，一些变量是分类变量，并且目前没有正确的格式来包含在任何后续的建模中。为了准备这些特性，我们可以对数据中的某些列进行一次性编码。我将使用我们的源特性作为例子:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="a105" class="lr ls it mq b gy mu mv l mw mx">enconder = LabelEncoder()<br/>source_labels = enconder.fit_transform(anime_df[‘source’])<br/>source_mappings = {index: label for index, label in <br/> enumerate(enconder.classes_)}<br/>source_mappings</span><span id="ca4a" class="lr ls it mq b gy my mv l mw mx">&gt;&gt;&gt;&gt;&gt;&gt; {0: '4-koma manga',<br/> 1: 'Book',<br/> 2: 'Card game',<br/> 3: 'Digital manga',<br/> 4: 'Game',<br/> 5: 'Light novel',<br/> 6: 'Manga',<br/> 7: 'Music',<br/> 8: 'Novel',<br/> 9: 'Original',<br/> 10: 'Other',<br/> 11: 'Picture book',<br/> 12: 'Radio',<br/> 13: 'Unknown',<br/> 14: 'Visual novel',<br/> 15: 'Web manga'}</span></pre><p id="eb63" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">正如您从我们的<em class="mz">源</em>变量中看到的，每个源类型都被分配了一个数字变量，可用作我们预测模型的特征变量。对您希望在建模中使用的变量重复此操作，并将它们合并回您的原始数据框:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="60ab" class="lr ls it mq b gy mu mv l mw mx">anime_df[‘source_label’] = source_labels<br/>anime_df[‘type_label’] = type_labels<br/>anime_df[‘title_label’] = title_labels</span></pre><h2 id="c4cc" class="lr ls it bd lt lu lv dn lw lx ly dp lz ld ma mb mc lh md me mf ll mg mh mi mj bi translated"><strong class="ak">数据建模</strong></h2><p id="e81d" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">现在我们已经准备好了我们的特征变量，我们准备开始数据建模。在此之前，重要的是在我们的数据框架中可视化变量之间的关系。因为我们希望预测用户评级，所以我们希望了解我们的变量与<em class="mz"> rating_x: </em>的相关程度</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="7f9b" class="lr ls it mq b gy mu mv l mw mx">plt.figure(figsize=(12,10))<br/>cor = anime_df.corr()<br/>sb.heatmap(cor, annot=True, cmap=plt.cm.Dark2)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nc"><img src="../Images/c95926a95898e7326c7dca4a7da20a76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_4cJeCiKfTyEoYvb15qvog.png"/></div></div></figure><p id="dbce" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">查看我们数据中总体分数的分布也很有用:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="a366" class="lr ls it mq b gy mu mv l mw mx">sb.distplot(anime_df[‘score’], color=”orchid”)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/02c3d0e69b4921b61a7234d823676714.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QiTUrKlkkfhQMNKFHWALkQ.png"/></div></div></figure><p id="6ec5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">由于我们的结果变量(<em class="mz"> rating_x </em>)与计算出的任何特征变量几乎没有相关性，因此我创建了一个二元结果测量，它使用平均用户评级分数作为高于或低于平均分数的阈值:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="43a8" class="lr ls it mq b gy mu mv l mw mx">anime_df.rating_x.mean()<br/>anime_df[‘rating_bracket’] = np.where(anime_df[‘rating_x’] &gt;= 6.14, ‘1’, ‘0’)</span></pre><p id="0e68" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在，我们希望将这些数据分成训练、测试和验证部分，相应地将结果度量和特征变量分开。由于我们当前的框架中有大约800万行数据，运行模型可能会很耗时；为此，我从<em class="mz"> anime_df </em>数据帧中随机抽取了250k的样本:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="e7e4" class="lr ls it mq b gy mu mv l mw mx">## Take a random sample</span><span id="a15e" class="lr ls it mq b gy my mv l mw mx">anime_sample = anime_df.sample(n=250000, random_state=1)</span><span id="a363" class="lr ls it mq b gy my mv l mw mx">features = anime_sample[[‘favorites’,’members’, ‘popularity’,’scored_by’,’source_label’, ‘type_label’,’title_label’]].copy()<br/>labels = anime_sample[‘rating_bracket’]</span><span id="beb8" class="lr ls it mq b gy my mv l mw mx">## Train — test</span><span id="9716" class="lr ls it mq b gy my mv l mw mx">X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=42)</span><span id="714d" class="lr ls it mq b gy my mv l mw mx">## Validation<br/><br/>X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)</span></pre><h2 id="e2dc" class="lr ls it bd lt lu lv dn lw lx ly dp lz ld ma mb mc lh md me mf ll mg mh mi mj bi translated">随机森林模型</h2><p id="9c60" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">我们要训练的第一个模型是随机森林；你可以在我之前写的 的<a class="ae lq" href="https://medium.com/better-programming/odi-match-prediction-with-elo-scores-and-sklearn-b9dc60900ff5" rel="noopener"> <strong class="kw iu">博客中读到更多关于训练一个随机森林模型的内容。在运行我们的随机森林模型之前，我们将首先优化两个输入参数，它们是<a class="ae lq" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" rel="noopener ugc nofollow" target="_blank"> <em class="mz"> n_estimators </em> </a>和<a class="ae lq" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" rel="noopener ugc nofollow" target="_blank"> <em class="mz"> max_depth </em> </a>，它们分别代表决策树的数量和每棵树的深度:</strong></a></p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="a97f" class="lr ls it mq b gy mu mv l mw mx">def print_results(results):<br/> print(‘BEST PARAMS: {}\n’.format(results.best_params_))</span><span id="3a0a" class="lr ls it mq b gy my mv l mw mx">means = results.cv_results_[‘mean_test_score’]<br/> stds = results.cv_results_[‘std_test_score’]<br/> for mean, std, params in zip(means, stds, results.cv_results_[‘params’]):<br/> print(‘{} (+/-{}) for {}’.format(round(mean, 3), round(std * 2, 3), params))</span><span id="4029" class="lr ls it mq b gy my mv l mw mx">rf = RandomForestClassifier()<br/>parameters = {<br/> ‘n_estimators’: [50,100],<br/> ‘max_depth’: [10,20,None]<br/>}</span><span id="5dec" class="lr ls it mq b gy my mv l mw mx">rf_cv = GridSearchCV(rf, parameters, cv=5)<br/>rf_cv.fit(X_train, y_train.values.ravel())</span><span id="56a7" class="lr ls it mq b gy my mv l mw mx">print_results(rf_cv)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/97a2a1e2050735c183636a57f2ef84b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OwmNy9vHu53QrVKHlTQuPw.png"/></div></div></figure><p id="5fca" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可以将最佳参数设置存储到本地机器，以便在评估结束时用于模型验证:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="95a7" class="lr ls it mq b gy mu mv l mw mx">joblib.dump(rf_cv.best_estimator_, ‘/.../.../.../AnimeRecs/RF_model.pkl’)</span></pre><p id="1781" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在，我们可以使用优化的参数运行随机森林，并打印模型的准确性:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="e4b2" class="lr ls it mq b gy mu mv l mw mx">rf_model = RandomForestClassifier(n_estimators=100, max_depth=20)<br/>rf_model.fit(X_train, y_train)<br/>rf_predicted_values = rf_model.predict(X_test)<br/>score = accuracy_score(y_test,rf_predicted_values)<br/>print(score)</span><span id="9af0" class="lr ls it mq b gy my mv l mw mx">&gt;&gt;&gt;&gt; Accuracy: 0.695905</span></pre><p id="59ed" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">您可以看到，我们的随机森林模型达到了大约70%的准确率，这表明我们可以使用我们为此分析创建的特征变量以相当高的准确率预测用户评分。在得出这个结论之前，评估哪些变量与模型成功相关是很重要的。我们可以这样看待输入变量的相对重要性:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="c680" class="lr ls it mq b gy mu mv l mw mx">for name, importance in zip(features.columns, rf_model.feature_importances_):<br/>… print(name, “=”, importance)</span><span id="a766" class="lr ls it mq b gy my mv l mw mx">favorites = 0.2778530464552122<br/>members = 0.19784680037872093<br/>popularity = 0.1759396781482536<br/>scored_by = 0.15560656547263593<br/>source_label = 0.0509643924057434<br/>type_label = 0.04176822827070301<br/>title_label = 0.10002128886873099</span></pre><p id="5ab7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">以上变量按降序排列，最重要的特性在顶部。您可以看到，我们编码的变量对我们的模型产生的重要性很小，并且在这种情况下可能具有最小的预测能力。就对我们的模型的相对重要性而言，最相关的特征变量是动画内容有多少个收藏夹，这完全是直观的。</p><p id="c986" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们还可以在随机森林模型中可视化一个单独的决策树，以查看数据是如何传递的:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="2e85" class="lr ls it mq b gy mu mv l mw mx">export_graphviz(tree,<br/> feature_names=features.columns,<br/> out_file=’rf_anime_tree.dot’,<br/> filled=True,<br/> rounded=True)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nf"><img src="../Images/55e8d55afaeef6b09c795bfccf1448a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q3Q-1_aBxVTlJN4O2wys_w.png"/></div></div></figure><h2 id="309c" class="lr ls it bd lt lu lv dn lw lx ly dp lz ld ma mb mc lh md me mf ll mg mh mi mj bi translated">前馈多层感知器</h2><p id="bd92" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">我们要训练的第二个模型是多层感知器(<strong class="kw iu"> MLP </strong>)，这是一类前馈神经网络，旨在模拟大脑处理和存储信息的神经生理过程。MLP通常用于监督学习问题，它们在一组输入-输出对上进行训练，并学习对它们之间的相关性进行建模。想了解更多关于MLP的信息，请阅读我之前的一篇文章。</p><p id="75fb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们将为我们的MLP模型优化的超参数是<em class="mz"> hidden_layer_sizes </em>，这是第I个隐藏层中的节点数，以及<em class="mz">激活</em>、<em class="mz">T5】，这是隐藏层的激活函数。对于激活功能，我们将确定逻辑激活和relu激活之间哪个功能更好:</em></p><blockquote class="ng nh ni"><p id="44db" class="ku kv mz kw b kx ky ju kz la lb jx lc nj le lf lg nk li lj lk nl lm ln lo lp im bi translated"><strong class="kw iu">逻辑</strong>:使用sigmoid函数(如逻辑回归)，返回f(x) = 1 / (1 + exp(-x))</p><p id="8fde" class="ku kv mz kw b kx ky ju kz la lb jx lc nj le lf lg nk li lj lk nl lm ln lo lp im bi translated"><strong class="kw iu"> Relu </strong>:整流后的线性单位函数，返回f(x) = max(0，x)。如果value值为正，该函数输出输入值，否则传递一个零</p></blockquote><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="23f9" class="lr ls it mq b gy mu mv l mw mx">mlp = MLPClassifier()<br/>parameters = {<br/> ‘hidden_layer_sizes’: [(10,), (50,)],<br/> ‘activation’: [‘relu’, ‘logistic’]<br/>}<br/>mlp_cv = GridSearchCV(mlp, parameters, cv=5)<br/>mlp_cv.fit(X_train, y_train.values.ravel())<br/>print_results(mlp_cv)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/5f879be6304561c1be3feef369345a76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*APy6utpTKu-2zp3Hg1gv3Q.png"/></div></div></figure><p id="8e9d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可以将最佳参数设置存储到本地机器，以便在评估结束时用于模型验证:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="fcf5" class="lr ls it mq b gy mu mv l mw mx">joblib.dump(rf_cv.best_estimator_, ‘/.../.../.../AnimeRecs/MLP_model.pkl’)</span></pre><p id="ed4f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在，我们可以使用优化的参数运行我们的MLP模型，并打印我们模型的精确度:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="4a3d" class="lr ls it mq b gy mu mv l mw mx">rf_model = RandomForestClassifier(n_estimators=100, max_depth=20)<br/>rf_model.fit(X_train, y_train)<br/>rf_predicted_values = rf_model.predict(X_test)<br/>score = accuracy_score(y_test,rf_predicted_values)<br/>print(score)</span><span id="d62c" class="lr ls it mq b gy my mv l mw mx">&gt;&gt;&gt;&gt; Accuracy: 0.6758805</span></pre><p id="2755" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如您所见，该模型达到了大约68%的准确率，低于我们的随机森林模型。由于MLP模型循环遍历数据的方式，在不同的时期/遍数遍历整个训练数据集之后评估模型的性能非常重要。为了评估这一点，我们可以设想模型随时间的验证损失:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="03d2" class="lr ls it mq b gy mu mv l mw mx">loss_values = mlp_model.loss_curve_<br/>mlp_model.score<br/>plt.plot(loss_values)<br/>plt.ylim((0.61,0.640))<br/>plt.axvline(10,0,0.7)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/aa9f7de1c7c1f19abdea09e85f6b8a93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J1dQck1Lm2mwJhiHfuLtSg.png"/></div></div></figure><p id="7842" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">从上图可以看出，10个时期后，验证损失开始增加，这表明模型过度拟合。减少通过我们的训练数据的完整次数可能是有价值的，从而减少训练我们的模型的时间。然而，值得考虑的是，这可能会降低模型的整体准确性。</p><h2 id="3594" class="lr ls it bd lt lu lv dn lw lx ly dp lz ld ma mb mc lh md me mf ll mg mh mi mj bi translated">模型验证</h2><p id="973f" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">如前所述，我们对数据进行了分割，这样我们就有了一个验证集，用于在评估的最后阶段对模型进行比较。这些数据对于所使用的两个模型中的任何一个都是完全看不到的，因此可以用作我们训练的模型的性能的强有力的衡量标准。此外，我们还存储了为此目的使用各种超参数的最佳估计值。</p><p id="d3d9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">以下代码将遍历您存储的最佳估计值:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="9314" class="lr ls it mq b gy mu mv l mw mx">models = {}<br/>for mdl in [‘MLP’, ‘RF’]:<br/> models[mdl] = joblib.load(‘/Users/hopkif05/Desktop/AnimeRecs/{}_model.pkl’.format(mdl))<br/>models</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/637b11a82205a3e7da5dd44b46e8d48a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lYI3tyEdR-B5PLqfWDMcKQ.png"/></div></div></figure><p id="509b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下面的代码将创建一个函数来评估和比较所使用的两个模型的准确性。正如所见，<em class="mz"> model.predict() </em>函数存在于开始和结束时间函数之间，这意味着我们可以计算每个模型的延迟值，以评估它们计算预测需要多长时间:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="86dd" class="lr ls it mq b gy mu mv l mw mx">def evaluate_model(name, model, features, labels):<br/>    start = time()<br/>    pred = model.predict(features)<br/>    end = time()<br/>    accuracy = round(accuracy_score(labels, pred), 3)<br/>    print('{} -- Accuracy: {} / Latency: {}ms'.format(name,<br/>                                                                                   accuracy,<br/>                                                                                   round((end - start)*1000, 1)))</span></pre><p id="3da7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们现在可以遍历我们的模型来确定它们的准确性:</p><pre class="kj kk kl km gt mp mq mr ms aw mt bi"><span id="601a" class="lr ls it mq b gy mu mv l mw mx">for name, mdl in models.items():<br/>    evaluate_model(name, mdl, X_val, y_val)</span><span id="2cb1" class="lr ls it mq b gy my mv l mw mx">MLP -- Accuracy: 0.683 / Latency: 675.7ms<br/>RF -- Accuracy: 0.713 / Latency: 668.9ms</span></pre><p id="0d69" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如上所述，随机森林模型在看不见的验证数据上表现最好。有趣的是，它还具有更短的延迟，这表明MLP模型已经被训练了太长时间；如前所述，这会对训练神经网络产生负面影响。</p><p id="f2f5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，可以总结为，我们的随机森林模型可以使用各种特征变量来预测MyAnimeList上的用户评级。考虑到随机森林模型在分类问题上表现良好，如我们的动漫数据中使用的二元结果测量，这一结果并不十分令人惊讶。给定我们为我们的随机森林输出计算的特征重要性，可以进一步确定与我们的随机森林模型的准确性最相关的变量是:<em class="mz">收藏夹</em> (0.28)、<em class="mz">成员</em> (0.20)、<em class="mz">流行度</em> (0.18)和<em class="mz">由</em> (0.16)评分。这些发现得到了上面打印的相关矩阵的支持，考虑到这些指标的性质，这些发现并不令人惊讶；因此，与我们的一次性编码变量相比，预计它们会产生相对较高的预测能力。</p></div></div>    
</body>
</html>