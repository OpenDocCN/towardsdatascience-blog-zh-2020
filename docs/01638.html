<html>
<head>
<title>Real-Time Object Detection with YOLO</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用YOLO进行实时目标检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/real-time-object-detection-with-yolo-9dc039a2596b?source=collection_archive---------25-----------------------#2020-02-14">https://towardsdatascience.com/real-time-object-detection-with-yolo-9dc039a2596b?source=collection_archive---------25-----------------------#2020-02-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/3bbfeb4ef7cb2cea60297dab7f826ec2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vCEXB3nFrGdWt7z19QGtWA.png"/></div></div></figure><h1 id="98b0" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">这是特斯拉的自动驾驶Model S。</h1><figure class="kw kx ky kz gt jr"><div class="bz fp l di"><div class="la lb l"/></div></figure><p id="7c5a" class="pw-post-body-paragraph lc ld iq le b lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">现在，除了直到最近无人驾驶汽车的想法还闻所未闻这一事实之外，人们不得不怀疑无人驾驶汽车实际上是如何工作的？我的意思是，我们把自己的生命——以及我们的朋友和家人的生命——托付给了一堆金属和电路。不幸的是，答案非常复杂，包括各种组件，如雷达、激光雷达、GPS定位等。然而，自动驾驶汽车大脑的核心是YOLO物体检测。</p><p id="d60e" class="pw-post-body-paragraph lc ld iq le b lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在我的<a class="ae mb" rel="noopener" target="_blank" href="/cnns-explained-giving-sight-to-artificial-intelligence-304f252346bc/">上一篇文章</a>中，我谈到了卷积神经网络，以及它们如何让计算机对图像中的对象进行分类。然而，要像特斯拉的自动驾驶仪一样工作，汽车不仅需要识别它看到的<strong class="le ir"><em class="ma"/></strong>图像，还需要知道这些物体的确切位置<strong class="le ir"><em class="ma"/></strong>。对于这一点，分类器是不够的——这就是YOLO的用武之地。</p><h1 id="874c" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">超快速、实时的物体检测</h1><p id="ea29" class="pw-post-body-paragraph lc ld iq le b lf mc lh li lj md ll lm ln me lp lq lr mf lt lu lv mg lx ly lz ij bi translated">澄清一下，YOLO物体检测并不代表“你只活一次”物体检测(我不想用那个软件上车)，而是<strong class="le ir">“你只看一次”</strong>物体检测。传统的分类器需要在图像上滑动窗口多次来检测不同的类别，而YOLO——正如所料——只需要看一次。这是一种非常快速的实时方法，不仅可以识别物体，还可以定位物体，速度高达惊人的每秒155帧。</p><figure class="kw kx ky kz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mh"><img src="../Images/d12bdf90c3ef4100a882405d2d590b6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*N1uY62a26zgeSLZn.jpg"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">YOLO物体探测在行动</p></figure><h2 id="8de5" class="mm jz iq bd ka mn mo dn ke mp mq dp ki ln mr ms km lr mt mu kq lv mv mw ku mx bi translated">边框和网格</h2><p id="8697" class="pw-post-body-paragraph lc ld iq le b lf mc lh li lj md ll lm ln me lp lq lr mf lt lu lv mg lx ly lz ij bi translated">YOLO的工作原理是将一个<em class="ma">单</em>神经网络应用于完整的图像输入。网络将每个输入图像分成一个S乘S的网格，每个网格单元预测预定数量的边界框。这些框预测对象的x坐标、y坐标、宽度和高度。这些框还包括一个置信度得分，以确定该对象属于所识别的类别。</p><figure class="kw kx ky kz gt jr gh gi paragraph-image"><div class="gh gi my"><img src="../Images/37ce3daf0e43fec97056ac8fcee5b87c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/0*xMgiSDWlFU5VmIXr.jpeg"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">YOLO网格和边界框</p></figure><h2 id="4b46" class="mm jz iq bd ka mn mo dn ke mp mq dp ki ln mr ms km lr mt mu kq lv mv mw ku mx bi translated">交集超过联合模型评估</h2><figure class="kw kx ky kz gt jr gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/48e91c8b1b812862bc82532166a1c272.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*2LPQLE87SJBRCSXhpow9sA.png"/></div></figure><p id="2737" class="pw-post-body-paragraph lc ld iq le b lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">为了评估模型的性能，YOLO使用了一种叫做<strong class="le ir">交集超过并集</strong> ( <strong class="le ir"> IoU)，</strong>的东西，计算方法是将预测边界框和地面真实之间的重叠面积除以两者之间的并集面积。IoU是一种衡量YOLO网络在识别物体时准确性的指标，它将网络的输出与手动标记的数据进行比较。</p><h2 id="f4fd" class="mm jz iq bd ka mn mo dn ke mp mq dp ki ln mr ms km lr mt mu kq lv mv mw ku mx bi translated">非最大抑制</h2><p id="a63b" class="pw-post-body-paragraph lc ld iq le b lf mc lh li lj md ll lm ln me lp lq lr mf lt lu lv mg lx ly lz ij bi translated">最终，每个网格单元最终给我们一个<strong class="le ir">集合</strong>数量的边界框，每个边界框都有一个置信度得分和分类。这些边界框中的大多数往往是无用的或不相关的，因此只有那些高于某个置信度阈值的边界框被保留作为YOLO网络的最终输出。</p><figure class="kw kx ky kz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi na"><img src="../Images/2ab9216823d50ccd1b6c55c0a4652ef5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OBGOgRabddmC57-Y"/></div></div></figure><h1 id="2deb" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">YOLO异议检测的优势</h1><p id="bcf0" class="pw-post-body-paragraph lc ld iq le b lf mc lh li lj md ll lm ln me lp lq lr mf lt lu lv mg lx ly lz ij bi translated">虽然在它之前有许多前辈，但在实时对象检测方面，没有任何计算机视觉算法像YOLO一样快速或有效。概括地说，YOLO是:</p><h2 id="c15b" class="mm jz iq bd ka mn mo dn ke mp mq dp ki ln mr ms km lr mt mu kq lv mv mw ku mx bi translated">1.极快</h2><p id="198f" class="pw-post-body-paragraph lc ld iq le b lf mc lh li lj md ll lm ln me lp lq lr mf lt lu lv mg lx ly lz ij bi translated">现在，在这一点上，你可能厌倦了我用YOLO真的真的很快这个事实来打击你，但是这一点我怎么强调都不为过。将人工智能应用于现实生活的主要障碍之一是，在大多数情况下，计算机在现实世界中花费的时间太长。我们根本不能让无人驾驶汽车到处游荡，如果每次他们都需要停下来思考几秒钟，不管他们面前是一个孩子还是一个塑料袋！在大多数情况下，计算机视觉总是准确的，但由于其速度，YOLO允许计算机视觉在现实生活中更加适用和实用。</p><figure class="kw kx ky kz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nb"><img src="../Images/5625dcbb27f1796457db11a461721dfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wTlo1IVWnzb6jEQP"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">由<a class="ae mb" href="https://unsplash.com/@goumbik?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">卢卡斯·布拉塞克</a>在<a class="ae mb" href="https://unsplash.com/s/photos/time?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h2 id="c051" class="mm jz iq bd ka mn mo dn ke mp mq dp ki ln mr ms km lr mt mu kq lv mv mw ku mx bi translated">2.情境感知</h2><p id="f75b" class="pw-post-body-paragraph lc ld iq le b lf mc lh li lj md ll lm ln me lp lq lr mf lt lu lv mg lx ly lz ij bi translated">在训练过程中，YOLO也接受了完整图像的训练，这意味着它不会孤立地看特定的物体。它不仅编码了关于类外观的信息，还编码了关于它的上下文信息。这样，YOLO网络几乎不会被误认为物体的潜在背景噪音所困扰。该网络知道汽车经常被其他汽车和路面包围——所以影子看起来有点像森林中的汽车？很可能不是车。</p><h2 id="2757" class="mm jz iq bd ka mn mo dn ke mp mq dp ki ln mr ms km lr mt mu kq lv mv mw ku mx bi translated">3.广义网络</h2><p id="fcfe" class="pw-post-body-paragraph lc ld iq le b lf mc lh li lj md ll lm ln me lp lq lr mf lt lu lv mg lx ly lz ij bi translated">最后，由于其架构和训练方式，YOLO是一个高度通用的网络。YOLO不仅学习如何识别孤立的物体，还学习它们的广义表示。当应用于意想不到的输入和不熟悉的情况时，它发生故障或失败的可能性要小得多——如果我必须说的话，这是无人驾驶汽车非常希望拥有的。</p><figure class="kw kx ky kz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/dd83955e35a09f101cb39a768fefb442.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_EKlygl7i2qjSrcv.jpg"/></div></div></figure></div></div>    
</body>
</html>