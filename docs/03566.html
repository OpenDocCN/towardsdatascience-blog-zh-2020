<html>
<head>
<title>Mercari price recommendation for online retail sellers using Machine learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用机器学习的在线零售卖家的 Mercari 价格推荐</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/mercari-price-recommendation-for-online-retail-sellers-979c4d07f45c?source=collection_archive---------23-----------------------#2020-04-04">https://towardsdatascience.com/mercari-price-recommendation-for-online-retail-sellers-979c4d07f45c?source=collection_archive---------23-----------------------#2020-04-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f7be" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">作为自我案例研究的一部分，对 Kaggle 中的 mercari 数据集进行回归实验和二次研究——使用 Python 的应用人工智能课程</h2></div><h1 id="0ff0" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">目录</h1><ol class=""><li id="7d1a" class="la lb it lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">商业问题</li><li id="a3c8" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln lo lp lq lr bi translated">使用机器学习/深度学习来解决业务问题</li><li id="74a9" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln lo lp lq lr bi translated">评估指标(RMSLE)</li><li id="0b44" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln lo lp lq lr bi translated">探索性数据分析</li><li id="7428" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln lo lp lq lr bi translated">特征工程(生成 19 个新特征)</li><li id="b5ac" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln lo lp lq lr bi translated">现有解决方案</li><li id="248e" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln lo lp lq lr bi translated">我的改进模型实验</li><li id="61ca" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln lo lp lq lr bi translated">摘要、结果和结论</li><li id="d41e" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln lo lp lq lr bi translated">未来的工作</li><li id="9481" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln lo lp lq lr bi translated">链接到我的个人资料— Github 代码和 Linkedin</li><li id="bcde" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln lo lp lq lr bi translated">参考</li></ol></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi me"><img src="../Images/a143b704e4f69a45d3218bf28b63e4c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*veifkIn1-ndiMx5LSpJPXQ.jpeg"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">图片来源—<a class="ae mu" href="https://unsplash.com/photos/Q1p7bh3SHj8" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/photos/Q1p7bh3SHj8</a></p></figure><h1 id="9921" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">1.商业问题</h1><p id="5b2a" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">本案例研究基于 2018 年由在线购物应用<a class="ae mu" href="https://www.mercari.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu"> Mercari </strong> </a>举办的一场 Kaggle 比赛。链接到卡格尔比赛—<a class="ae mu" href="https://www.kaggle.com/c/mercari-price-suggestion-challenge" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/mercari-price-suggestion-challenge</a>。</p><p id="5dd6" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">你可以在我的 github 档案中找到我的全部代码(链接在这篇博客的末尾)。</p><p id="075a" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">Mercari 是一个在线销售应用程序(与印度的 Quikr 非常相似)。卖家在商店上传他们想要出售的二手/翻新产品。当他们在 Mercari 应用程序上上传产品时，他们想知道他们应该卖多少钱。这有助于卖家在实际销售之前对产品进行定价/估价。</p><p id="301b" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">卖家上传商品信息，如<strong class="lc iu">商品名称(文本格式)</strong>、<strong class="lc iu">商品描述(文本格式)、商品品牌、商品类别、商品状况、发货状态</strong>。当他们在 Mercari 应用程序上上传这些产品信息时，作为回报，他们会得到<strong class="lc iu">推荐</strong> <strong class="lc iu">价格</strong>。</p><p id="a4cd" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">本案例研究的目标是在给定产品属性的情况下，预测产品列表的价格。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi nn"><img src="../Images/a865f1a3f3abdca5adf769540ce8a3eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*flYqR9XPKSQ6tFg9eWVhVg.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">来源—<a class="ae mu" href="https://www.kaggle.com/c/mercari-price-suggestion-challenge/" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/mercari-price-suggestion-challenge/</a></p></figure></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="f5d1" class="ki kj it bd kk kl no kn ko kp np kr ks jz nq ka ku kc nr kd kw kf ns kg ky kz bi translated">2.使用机器学习/深度学习来解决业务问题</h1><p id="6e63" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">使用机器学习技术可以最好地解决这个问题，这基本上是一个<strong class="lc iu">回归建模</strong>任务，它基本上查看相似的历史产品信息/属性以及销售价格，并相应地建议价格。</p><p id="ac37" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">让我们查看一行训练数据并理解它的字段。(整个训练数据包含~<strong class="lc iu">140 万个</strong>物品清单)</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi nt"><img src="../Images/1f9e1e013fd4c5b993aa7b93eb10d437.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nFkn9-wZqiRS_1UjuJKexg.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">样品项目列表</p></figure><p id="6101" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">数据集由以下字段组成—</p><ol class=""><li id="5228" class="la lb it lc b ld ni lf nj lh nu lj nv ll nw ln lo lp lq lr bi translated"><strong class="lc iu">名称</strong> —这是卖家正在列出的产品的<strong class="lc iu">项目名称/产品名称</strong>。(文本格式)</li><li id="fde6" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln lo lp lq lr bi translated"><strong class="lc iu">项目条件 id </strong> —包含(1，2，3，4，5)之一的值。基本上，它是一个代表物品状况的数字，范围从 1 到 5。</li><li id="2dd9" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln lo lp lq lr bi translated"><strong class="lc iu">类别</strong> —包含项目的<a class="ae mu" href="https://www.bigcommerce.com/blog/product-taxonomy/#what-is-product-taxonomy" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu">产品类别分类</strong> </a>作为三级层次结构(用'/'分隔符分隔)。在上面的例子中，电子产品为 1 级，计算机&amp;平板电脑为 2 级，组件&amp;零件为 3 级。</li><li id="6205" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln lo lp lq lr bi translated"><strong class="lc iu">品牌</strong> —所列商品的品牌。60%的行是空的。</li><li id="510b" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln lo lp lq lr bi translated"><strong class="lc iu">发货</strong> —包含布尔型— 1，0。‘1’表示运费由卖家支付，‘0’表示卖家不支付。</li><li id="28c1" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln lo lp lq lr bi translated"><strong class="lc iu">物品描述— </strong>包含物品的详细文字描述。其中包含尽可能多的关于产品状况、特性和所有其他相关信息的信息。自然，我们可以想象这些信息与我们非常相关，因为价格取决于功能、某些功能的工作条件等。这将是一个有趣的<a class="ae mu" href="https://cs224d.stanford.edu/" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu">深度 NLP </strong> </a>任务来解决。</li><li id="9c80" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln lo lp lq lr bi translated"><strong class="lc iu">价格</strong>(待预测)—这是我们案例中待预测的价格。包含 0 到 2009 之间的浮点值。</li></ol><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi nx"><img src="../Images/eb5179ccda5b3e91884324843285bc20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KPzu8CXp_xqKp8yJFJg8_w.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">熊猫数据框——训练数据截图</p></figure></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="bcea" class="ki kj it bd kk kl no kn ko kp np kr ks jz nq ka ku kc nr kd kw kf ns kg ky kz bi translated">3.评估指标(RMSLE)</h1><p id="85e8" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">注意——这里不是 RMSE。是 RMSLE </p><p id="a406" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">比赛使用的评估标准基本上是一个分数。<strong class="lc iu"> RMSLE </strong>代表<strong class="lc iu">均方根对数误差</strong>。我找到了一篇很棒的博文，这篇博文解释了 RMSE 和 RMSLE 之间的差异，以及在什么情况下 RMSLE 更适合用作回归任务的评估指标—<a class="ae mu" href="https://medium.com/analytics-vidhya/root-mean-square-log-error-rmse-vs-rmlse-935c6cc1802a" rel="noopener"><strong class="lc iu">https://medium . com/analytics-vid hya/root-mean-square-log-error-RMSE-vs-RM LSE-935 c6cc 1802 a</strong></a></p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/aa473258bbbcc907edb9deea57ab6a68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*OzivnlbPY1AvNTF3rmbqzg.png"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">来源——towardsdatascience.com</p></figure><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="nz oa l"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">代码— RMSLE 分数</p></figure><p id="12b1" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">总结一下这篇博文中关于为什么在这里使用 RMSLE 作为衡量标准的几点</p><ol class=""><li id="5946" class="la lb it lc b ld ni lf nj lh nu lj nv ll nw ln lo lp lq lr bi translated"><strong class="lc iu">当你低估而不是高估时，RMSLE 的惩罚更多— </strong>换句话说，RMSLE 用在这个项目中，意思是如果你对某些项目给出更高的价格建议是可以的，但如果你低估了实际价格，这是不可接受的。如果我们预测不足，RMSLE 将显著增加，相比之下，如果我们预测过量，RMSLE 将显著增加。我认为这对于这个案例研究来说是有商业意义的，因为我们可能会对某些物品给出比实际价格更高的估价，但如果我们低估了一件物品的价格，这就不好了，因为买家可能不想在这种情况下出售。</li><li id="78af" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln lo lp lq lr bi translated"><strong class="lc iu"> RMSLE 可以缓冲数据中异常值的影响</strong> —如果您在 RMSE 进行评估，由于 RMSE 的平方误差惩罚，数据集中某些具有非常高价格值的项目实际上可能会扭曲模型，而 RMSLE 对高价值汽车的惩罚仅比低价值汽车略高，因为 RMSLE 在度量中有一个对数项来缓冲这种影响。</li><li id="2b5b" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln lo lp lq lr bi translated"><strong class="lc iu"> RMSLE </strong> <strong class="lc iu">只考虑相对误差</strong>而不考虑绝对误差(因为对数项)，所以 9 对 10 的预测和 900 对 1000 的预测都具有相同的<strong class="lc iu">相对误差。</strong></li></ol><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi ob"><img src="../Images/94811264c92718d705b0d5982646646c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h46SdHfoVHeVdG2NAsbchA.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">来源—<a class="ae mu" href="https://www.kaggle.com/c/ashrae-energy-prediction/discussion/113064" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/ASHRAE-energy-prediction/discussion/113064</a></p></figure></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="0f1d" class="ki kj it bd kk kl no kn ko kp np kr ks jz nq ka ku kc nr kd kw kf ns kg ky kz bi translated">4.探索性数据分析</h1><p id="bffe" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">我们总是建议，在开始预测建模之前，首先要很好地理解数据。这是一项极其重要的任务。让我们浏览一下数据，获得一些信息和见解:</p><h2 id="7707" class="oc kj it bd kk od oe dn ko of og dp ks lh oh oi ku lj oj ok kw ll ol om ky on bi translated">物品列表的价格分布</h2><p id="c3a1" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">这里的价格遵循一个<a class="ae mu" href="https://en.wikipedia.org/wiki/Log-normal_distribution" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu">对数正态分布</strong> </a>。从一个现有的 Kaggle 内核中，我发现 Mercari 只允许 3 到 2000 之间的价格列表。因此，我们将筛选这些项目列表。如果你看到下面的图表，即使<strong class="lc iu"> 99.9 百分位</strong>值也在 400 左右。拐点出现在那之后。我们可以构建价格板(根据<strong class="lc iu"> 5 百分位板)</strong>来更好地分析商品列表的价格分布。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi oo"><img src="../Images/52060251021817ebd9397b0540fc5d53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fUiQTzNcPrWTyVQie5zOyQ.jpeg"/></div></div></figure><div class="mf mg mh mi gt ab cb"><figure class="op mj oq or os ot ou paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><img src="../Images/eff458df8cb41f3165b73c179737e957.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*g_M0VztpIrT9z94BjtK86g.jpeg"/></div></figure><figure class="op mj ov or os ot ou paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><img src="../Images/5f1650eff6b49c4dcf53b5f038891ff5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*vP6i67Xhtqr7aM1C1ul9IQ.jpeg"/></div></figure></div><h2 id="ce43" class="oc kj it bd kk od oe dn ko of og dp ks lh oh oi ku lj oj ok kw ll ol om ky on bi translated">项目条件、运输状态的价格差异</h2><p id="abc3" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated"><strong class="lc iu">发货状态</strong>是二进制— (1，0)。1 代表运费由卖方支付。0 表示运费不是由卖家支付。我们可以查看一下<a class="ae mu" href="https://en.wikipedia.org/wiki/Violin_plot" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu">小提琴的剧情</strong> </a> <strong class="lc iu"> </strong>下面的剧情。我们可以看到,“0”的价格比“1”的价格略高(尽管我认为情况会相反，因为我的假设是，如果卖家已经支付了运费，那么价格应该会略高)。但是<a class="ae mu" href="https://en.wikipedia.org/wiki/Statistical_significance" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu">的差异有统计学意义</strong> </a> <strong class="lc iu">吗？</strong> —我们可以进行单向<a class="ae mu" href="https://en.wikipedia.org/wiki/One-way_analysis_of_variance" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu"> ANOVA </strong> </a>测试，以达到 5%的显著性，这表明装运状态下的价格差异确实具有统计显著性。</p><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="nz oa l"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">代码—统计检验</p></figure><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi ow"><img src="../Images/7a58af1636276ae3cf9eb08858a92db3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EAYLuvlzt_oTRipBr5PlhA.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">数据分析——运输状态中的价格变化</p></figure><p id="44ed" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">下面对<strong class="lc iu">项目条件</strong>进行了类似的分析。这里的价格差异在统计上也很显著。在这两个特征中没有发现缺失值。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi ox"><img src="../Images/ece7cb20a5001f82ab4be3f86b0c9dd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2_Hd2xUdXyklr0JKuPLRMg.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">数据分析-项目条件 ID 中的价格变化</p></figure><h2 id="1667" class="oc kj it bd kk od oe dn ko of og dp ks lh oh oi ku lj oj ok kw ll ol om ky on bi translated">不同类别的价格差异</h2><p id="b108" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">此处的类别功能出现在“/”分隔值中。大多数类别有 3 级分隔符。(见下图)。因此，这里的命名法是<strong class="lc iu">第 1 类/第 2 类/第 3 类</strong>，其中<strong class="lc iu">第 1 类</strong>是高级类别，后面跟着<strong class="lc iu">第 2 类</strong> &amp; <strong class="lc iu">第 3 类</strong>是次级类别。</p><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="nz oa l"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">代码片段—拆分类别级别</p></figure><pre class="mf mg mh mi gt oy oz pa pb aw pc bi"><span id="6881" class="oc kj it oz b gy pd pe l pf pg"><strong class="oz iu">import seaborn as sns</strong><br/>sns.set(rc={'figure.figsize':(8,6)}, style = 'whitegrid')<br/>sns.barplot(x = "count", y="cat1", data=df_cat1_counts,palette="Blues_d")</span></pre><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi ph"><img src="../Images/569fd508962245a7d819c586b1dc64c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*roLan_3UQbvMGW7aVVVW9A.jpeg"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">按类别级别 1 盘点物料</p></figure><p id="d302" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">让我们使用<a class="ae mu" href="https://www.geeksforgeeks.org/generating-word-cloud-python/" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu">词云</strong> </a>来看看本专栏中出现了哪些类型的词。此外，让我们使用 violin plots 分析跨类别的价格分布。</p><pre class="mf mg mh mi gt oy oz pa pb aw pc bi"><span id="a074" class="oc kj it oz b gy pd pe l pf pg">sns.set(rc={'figure.figsize':(19,7)})<br/>sns.violinplot(x="cat1", y="log_price", data = df_train)<br/>plt.title('Violin Plots - Price variation in cat1')<br/>plt.show()</span></pre><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi pi"><img src="../Images/3c4baabd467c4525ef4f054c9b34defb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zK3T7L-KOrbd638WUjSXhg.jpeg"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">类别价格-小提琴图</p></figure><pre class="mf mg mh mi gt oy oz pa pb aw pc bi"><span id="3a08" class="oc kj it oz b gy pd pe l pf pg"><strong class="oz iu">import</strong> <strong class="oz iu">matplotlib.pyplot</strong> <strong class="oz iu">as</strong> <strong class="oz iu">plt</strong><br/><strong class="oz iu">from</strong> <strong class="oz iu">wordcloud</strong> <strong class="oz iu">import</strong> <strong class="oz iu">WordCloud<br/></strong>wordcloud = WordCloud(collocations=<strong class="oz iu">False</strong>).generate(text_cat)<br/>plt.figure(figsize = (12,6))<br/>plt.imshow(wordcloud, interpolation='bilinear')<br/>plt.axis("off")<br/>plt.title('WordCloud for Category Name')<br/>plt.show()</span></pre><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi pj"><img src="../Images/23da254404e2c97c6a72591210518a2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sCIor9_Rveg3B6H6V3jpSQ.jpeg"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">类别名称— Wordcloud</p></figure><h2 id="933c" class="oc kj it bd kk od oe dn ko of og dp ks lh oh oi ku lj oj ok kw ll ol om ky on bi translated">不同品牌的价格差异</h2><p id="10f5" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">该功能包含约 4800 个品牌(其中<strong class="lc iu"> 60%的行缺少</strong>)。数据框架中列出了顶级品牌(按数量排列)。我们可以看到，前 1000 个品牌(约 25%的顶级品牌)约占产品列表的 97%。(接近一个<a class="ae mu" href="https://en.wikipedia.org/wiki/Power_law" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu">幂律分布</strong> </a>)</p><div class="mf mg mh mi gt ab cb"><figure class="op mj pk or os ot ou paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><img src="../Images/9d5a18f42ff9a3a17524e9fd9aef907a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1350/format:webp/1*xIBRIOtksbVa3s7bYSzWpQ.jpeg"/></div></figure><figure class="op mj pl or os ot ou paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><img src="../Images/ec774aeb6bb4ceaa639ad4dfcb320d0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*mMpyBjnG5SHdx1n1bQhc8A.jpeg"/></div></figure></div><p id="bf29" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">不同的品牌有不同的价格分布(如预期)。品牌应该出现在最相关的特征中，因为产品的价格是产品品牌的一个非常重要的功能。如下图所示，遵循长尾偏态分布。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi pm"><img src="../Images/849495fcaff90e891fc9072c6d3d2b6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-EYiW_hxnvCOwgYRbbMs5A.jpeg"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">4800 个品牌的平均价格分布</p></figure><h2 id="c077" class="oc kj it bd kk od oe dn ko of og dp ks lh oh oi ku lj oj ok kw ll ol om ky on bi translated">了解项目名称和项目描述的内容</h2><p id="05ca" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">让我们通过绘制他们的文字云来理解。(但是经过一些<strong class="lc iu">文本预处理</strong></p><pre class="mf mg mh mi gt oy oz pa pb aw pc bi"><span id="a022" class="oc kj it oz b gy pd pe l pf pg"><strong class="oz iu"># reference - Applied AI Course (Code for Text Preprocessing)<br/>import re<br/>from tqdm import tqdm_notebook</strong></span><span id="0756" class="oc kj it oz b gy pn pe l pf pg"><strong class="oz iu">def</strong> decontracted(phrase):<br/>    phrase = re.sub(r"won't", "will not", phrase)<br/>    phrase = re.sub(r"can\'t", "can not", phrase)<br/>    phrase = re.sub(r"n\'t", " not", phrase)<br/>    phrase = re.sub(r"\'re", " are", phrase)<br/>    phrase = re.sub(r"\'s", " is", phrase)<br/>    phrase = re.sub(r"\'d", " would", phrase)<br/>    phrase = re.sub(r"\'ll", " will", phrase)<br/>    phrase = re.sub(r"\'t", " not", phrase)<br/>    phrase = re.sub(r"\'ve", " have", phrase)<br/>    phrase = re.sub(r"\'m", " am", phrase)<br/>    <strong class="oz iu">return</strong> phrase</span><span id="65e1" class="oc kj it oz b gy pn pe l pf pg"><strong class="oz iu">def</strong> text_preprocess(data):<br/>    preprocessed = []<br/>    <strong class="oz iu">for</strong> sentance <strong class="oz iu">in</strong> tqdm_notebook(data):<br/>        sent = decontracted(sentance)<br/>        sent = sent.replace('<strong class="oz iu">\\</strong>r', ' ')<br/>        sent = sent.replace('<strong class="oz iu">\\</strong>"', ' ')<br/>        sent = sent.replace('<strong class="oz iu">\\</strong>n', ' ')<br/>        sent = re.sub('[^A-Za-z0-9]+', ' ', sent)<br/>        <em class="po"># https://gist.github.com/sebleier/554280</em><br/>        sent = ' '.join(e <strong class="oz iu">for</strong> e <strong class="oz iu">in</strong> sent.split() <strong class="oz iu">if</strong> e <strong class="oz iu">not</strong> <strong class="oz iu">in </strong>stopwords)<br/>        preprocessed.append(sent.lower().strip())<br/>    <strong class="oz iu">return</strong> preprocessed</span></pre><div class="mf mg mh mi gt ab cb"><figure class="op mj pp or os ot ou paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><img src="../Images/f7fe19011a17514b7b74d26bd873b5d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Y-Bccxsd1hA7fsNxMxXvpg.jpeg"/></div></figure><figure class="op mj pq or os ot ou paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><img src="../Images/f25a5674afd45bb62dcf168fadd998bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*HnoJq-LKuaiqGv7mPE1N9Q.jpeg"/></div></figure></div><p id="44aa" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">上面的图表看起来不错——它给出了最常出现的单词的信息。</p><h2 id="47c6" class="oc kj it bd kk od oe dn ko of og dp ks lh oh oi ku lj oj ok kw ll ol om ky on bi translated">使用潜在狄利克雷分配(LDA)的主题建模</h2><p id="8542" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">让我们也做一些<a class="ae mu" href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu">的题目造型使用潜狄利克雷分配</strong> </a> <strong class="lc iu">。</strong>不涉及细节，这基本上是一个无监督的算法，在整个文本语料库中找到句子谈论的主题。这个分析的灵感来自于这个 Kaggle 内核— <a class="ae mu" href="https://www.kaggle.com/thykhuely/mercari-interactive-eda-topic-modelling" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu">链接</strong> </a>。</p><p id="e90f" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">让我们来看一些由生成的<strong class="lc iu">主题(通过将相似的单词/句子分组到主题中 LDA 算法就是这样做的)。在我们的例子中，当应用于<strong class="lc iu">项目描述</strong>特性时，LDA 做得相当不错。</strong></p><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="nz oa l"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">LDA 代码</p></figure><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi pr"><img src="../Images/9fe32708559a71e39fd49377d0903ef4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rVlDEYbFCpJEzpnA13bIvQ.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">LDA 的结果</p></figure><p id="9527" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">话题 0 最有可能指的是<strong class="lc iu">珠宝</strong>——(项链、手链、链子、黄金)。同样，主题 3 指的是<strong class="lc iu">服装</strong>——(衬衫、耐克、男士、女士)。主题 7 指的是<strong class="lc iu">配饰— </strong>(皮革、包、钱包)等。因此，我们很好地理解了“项目描述”专栏所谈论的内容，以及其中呈现的各种主题的摘要。这个特征将是一个非常重要的价格预测器，因为它包含了与物品状况、新度、产品的详细特征等相关的信息。</p><p id="fa6b" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">我的第一直觉是，这将是一个深度 NLP 任务，需要使用某种形式的<a class="ae mu" href="https://en.wikipedia.org/wiki/Long_short-term_memory" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu"> LSTM 神经网络</strong> </a>来解决。</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="cd97" class="ki kj it bd kk kl no kn ko kp np kr ks jz nq ka ku kc nr kd kw kf ns kg ky kz bi translated">5.特征工程(生成新特征)</h1><p id="b682" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">这是 ML 系统中最重要的部分之一。受此启发 Kaggle 内核<a class="ae mu" href="https://www.kaggle.com/gspmoreira/cnn-glove-single-model-private-lb-0-41117-35th" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu">链接</strong> </a> <strong class="lc iu">。</strong>产生了一些新特征。</p><h2 id="0da0" class="oc kj it bd kk od oe dn ko of og dp ks lh oh oi ku lj oj ok kw ll ol om ky on bi translated">特征工程(集合 1)-情感得分</h2><p id="a508" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">这里的假设是，商品描述中传达的情感越好，买家愿意为该商品支付的价格越高。我预计商品描述的情感分数和价格之间存在正相关关系。</p><pre class="mf mg mh mi gt oy oz pa pb aw pc bi"><span id="5042" class="oc kj it oz b gy pd pe l pf pg"><strong class="oz iu">from</strong> <strong class="oz iu">nltk.sentiment.vader</strong> <strong class="oz iu">import</strong> <strong class="oz iu">SentimentIntensityAnalyzer<br/></strong>def generate_sentiment_scores(data):<br/>    sid = SentimentIntensityAnalyzer()<br/>    scores = []<br/>    for sentence in tqdm_notebook(data): <br/>        sentence_sentiment_score = sid.polarity_scores(sentence)<br/>        scores.append(sentence_sentiment_score['compound'])<br/>    return scores</span></pre><h2 id="42de" class="oc kj it bd kk od oe dn ko of og dp ks lh oh oi ku lj oj ok kw ll ol om ky on bi translated">特征工程(集合 2)-分组价格统计</h2><p id="7f1c" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">我借用了这个 Kaggle 内核的这段代码片段— <a class="ae mu" href="https://www.kaggle.com/gspmoreira/cnn-glove-single-model-private-lb-0-41117-35th" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu">链接</strong> </a> <strong class="lc iu"> </strong>。这基本上是通过将(<strong class="lc iu">类别、品牌、运输</strong>)特征组合在一起并生成价格统计数据来获得价格统计数据的，这些价格统计数据是<strong class="lc iu">平均值</strong>、<strong class="lc iu">中值</strong>、<strong class="lc iu">标准值。偏差</strong>、<a class="ae mu" href="https://en.wikipedia.org/wiki/Coefficient_of_variation" rel="noopener ugc nofollow" target="_blank">、<strong class="lc iu">变异系数</strong>、<strong class="lc iu">基于 2 个标准的预期价格范围</strong>。偏离平均值等。这是有意义的，因为我们基本上是在查看一组商品的<strong class="lc iu">历史价格，并将它们输入到特性集中，假设它们可能与当前价格密切相关。</strong></a></p><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="nz oa l"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">特征生成的代码</p></figure><h2 id="7144" class="oc kj it bd kk od oe dn ko of og dp ks lh oh oi ku lj oj ok kw ll ol om ky on bi translated">特征工程(集合 3)-项目描述文本统计</h2><p id="a4db" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">我再次借用上面发布的同一 Kaggle 内核链接中的这段代码。代码基本上从<strong class="lc iu">项目描述</strong>栏创建新功能，如字数、特殊字符数、数字数等。</p><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="nz oa l"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">代码-描述特征</p></figure><h2 id="8346" class="oc kj it bd kk od oe dn ko of og dp ks lh oh oi ku lj oj ok kw ll ol om ky on bi translated">Co 将新生成的功能与价格相关联</h2><p id="c55a" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">最重要的问题是，这些新功能是否与价格密切相关——为此，我们可以绘制相关热图。</p><pre class="mf mg mh mi gt oy oz pa pb aw pc bi"><span id="f4ed" class="oc kj it oz b gy pd pe l pf pg"><strong class="oz iu"><em class="po">#ref = </em></strong><a class="ae mu" href="https://datatofish.com/correlation-matrix-pandas/" rel="noopener ugc nofollow" target="_blank"><strong class="oz iu"><em class="po">https://datatofish.com/correlation-matrix-pandas/</em></strong></a><em class="po"><br/></em># df_corr contains all the newly generated features<br/>corrMatrix  = df_corr.corr()<br/>plt.figure(figsize = (18,9))<br/>sns.heatmap(corrMatrix, annot=<strong class="oz iu">True</strong>)<br/>plt.show()</span></pre><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi ps"><img src="../Images/a3e83ec699bf7cb36e710e8d7756e5ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b9fQyz0aA_0aFo2DFau_1Q.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">关联热图(新生成的要素)</p></figure><p id="e936" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">正如我们从上面的热图中看到的，3 个特征与价格输出有很强的相关性，相关性&gt;<strong class="lc iu"> 0.5。</strong>生成的平均、最小预期、最大预期价格特征似乎最为显著。我们将只保留这 3 个新功能。</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="504d" class="ki kj it bd kk kl no kn ko kp np kr ks jz nq ka ku kc nr kd kw kf ns kg ky kz bi translated">6.现有解决方案</h1><p id="3f12" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">有许多不同方法的核心，其中一些包括—</p><ol class=""><li id="6a7f" class="la lb it lc b ld ni lf nj lh nu lj nv ll nw ln lo lp lq lr bi translated"><strong class="lc iu"> CNN 带手套进行单词嵌入——</strong>内核<a class="ae mu" href="https://www.kaggle.com/gspmoreira/cnn-glove-single-model-private-lb-0-41117-35th" rel="noopener ugc nofollow" target="_blank">链接</a>。这使用 CNN 模型对项目名称、项目描述以及分类特征进行单词嵌入，以使其通过密集 MLP。模型给出的 RMSLE 得分为 0.41(第 35 位)</li><li id="3f31" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln lo lp lq lr bi translated"><strong class="lc iu">稀疏的 MLP — </strong>内核<a class="ae mu" href="https://www.kaggle.com/lopuhin/mercari-golf-0-3875-cv-in-75-loc-1900-s" rel="noopener ugc nofollow" target="_blank">链接</a>。这使用稀疏 MLP 通过文本的 Tfidf 矢量化和分类要素的一次热编码来生成输出。模型给出的均方根误差为 0.38(第一名)</li><li id="135c" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln lo lp lq lr bi translated"><strong class="lc iu">岭模型— </strong>内核<a class="ae mu" href="https://www.kaggle.com/apapiu/ridge-script" rel="noopener ugc nofollow" target="_blank">链接</a>。对 Tfidf 文本要素使用简单的岭回归来生成预测。模型给出的均方根误差为 0.47</li><li id="931c" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln lo lp lq lr bi translated"><strong class="lc iu"> LGBM 模型— </strong>内核<a class="ae mu" href="https://www.kaggle.com/tunguz/more-effective-ridge-lgbm-script-lb-0-44823" rel="noopener ugc nofollow" target="_blank">链接</a>。使用 LightGBM 回归器给出 0.44 的输出分数。</li></ol></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="593b" class="ki kj it bd kk kl no kn ko kp np kr ks jz nq ka ku kc nr kd kw kf ns kg ky kz bi translated">7.我的改进模型实验</h1><h2 id="965b" class="oc kj it bd kk od oe dn ko of og dp ks lh oh oi ku lj oj ok kw ll ol om ky on bi translated"><strong class="ak">数据准备</strong></h2><p id="b91d" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">我们可以使用原始训练数据拆分成训练/测试，测试数据大小为 25%。</p><pre class="mf mg mh mi gt oy oz pa pb aw pc bi"><span id="08b1" class="oc kj it oz b gy pd pe l pf pg"><strong class="oz iu">from sklearn.model_selection import train_test_split<br/></strong>df_train = pd.read_csv('train.tsv',sep = '<strong class="oz iu">\t</strong>')<br/>df_train_model,df_test_model = train_test_split(df_train,test_size = 0.25)</span></pre><h2 id="8cd5" class="oc kj it bd kk od oe dn ko of og dp ks lh oh oi ku lj oj ok kw ll ol om ky on bi translated">数据编码</h2><p id="3c28" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">输入特征包括分类和文本特征，以及 3 个新生成的数字特征。分类编码包括一个热门编码器，标签二进制化器。文本编码涉及 Tfidf 和 Count (BOW)矢量器。数字编码涉及使用 StandardScaler 进行标准化。</p><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="3715" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">如 ed a 部分所述，输出变量——价格涉及对数变换。</p><pre class="mf mg mh mi gt oy oz pa pb aw pc bi"><span id="5ea0" class="oc kj it oz b gy pd pe l pf pg"><strong class="oz iu">import numpy as np</strong><br/>y_train  = np.log1p(df_train['price'])</span></pre><h2 id="d13f" class="oc kj it bd kk od oe dn ko of og dp ks lh oh oi ku lj oj ok kw ll ol om ky on bi translated">用 GridSearchCV 改进岭回归</h2><p id="3760" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">我们可以从用 L2 正则化建立一个简单的线性模型开始，这基本上被称为岭回归。该模型在测试数据上给出了 0.474 的 RMSLE。请注意，solver = 'lsqr '用于更快的训练，训练该模型不到一分钟。</p><pre class="mf mg mh mi gt oy oz pa pb aw pc bi"><span id="d79b" class="oc kj it oz b gy pd pe l pf pg"><strong class="oz iu">%%time<br/>from</strong> <strong class="oz iu">sklearn.linear_model</strong> <strong class="oz iu">import</strong> <strong class="oz iu">Ridge<br/></strong>ridge_model = Ridge(solver = "lsqr", fit_intercept=<strong class="oz iu">False</strong>)<br/>ridge_model.fit(X_train, y_train)<br/>preds = np.expm1(ridge_model.predict(X_test))</span></pre><p id="34cb" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">我们可以尝试在这个模型上使用<a class="ae mu" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html" rel="noopener ugc nofollow" target="_blank"><strong class="lc iu">GridSearchCV</strong></a><strong class="lc iu"/>看看是否可以提高分数。</p><pre class="mf mg mh mi gt oy oz pa pb aw pc bi"><span id="af5e" class="oc kj it oz b gy pd pe l pf pg"><strong class="oz iu">from</strong> <strong class="oz iu">sklearn.model_selection</strong> <strong class="oz iu">import</strong> <strong class="oz iu">GridSearchCV</strong><br/>parameters = {'alpha':[0.0001,0.001,0.01,0.1,1,10,100,1000,10000],<br/>              'fit_intercept' : [False],<br/>              'solver' : ['lsqr']}<br/><br/>gs_ridge = GridSearchCV(estimator = Ridge(),<br/>                        param_grid = parameters,<br/>                        cv = 3, <br/>                        scoring = 'neg_mean_squared_error',<br/>                        verbose = 100,<br/>                        return_train_score = True,<br/>                        n_jobs = -2)<br/>gs_ridge.fit(X_train, y_train)</span></pre><p id="4077" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">正如我们在下面看到的，当使用三重交叉验证时，alpha=10 给出最低的交叉验证分数。但是在使用这个模型的时候。RMSLE 仅从<strong class="lc iu"> 0.474 </strong>降低到<strong class="lc iu"> 0.472 </strong>，这并不是非常显著的改进。注意在下面的图表中，使用了 10 的对数标度，因为在进行网格搜索时，所有的超参数α值都是 10 的幂。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi pt"><img src="../Images/c06b197226cb468a4557c876c785c3a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sXS1lVEZvhTEz69lWnq8rQ.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">超参数图</p></figure><h2 id="5415" class="oc kj it bd kk od oe dn ko of og dp ks lh oh oi ku lj oj ok kw ll ol om ky on bi translated">LightGBM 回归模型的超参数调整</h2><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="nz oa l"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">代码片段— LGBM 模型</p></figure><pre class="mf mg mh mi gt oy oz pa pb aw pc bi"><span id="b6fb" class="oc kj it oz b gy pd pe l pf pg">lgbm_params_1 = {'n_estimators': 900, <br/>                 'learning_rate': 0.15,<br/>                 'max_depth': 5,<br/>                 'num_leaves': 31, <br/>                 'subsample': 0.9,<br/>                 'colsample_bytree': 0.8,<br/>                 'min_child_samples': 50,<br/>                 'n_jobs': -2}</span></pre><p id="276b" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">我们可以通过调整超参数来改进模型，通过<strong class="lc iu">增加估计器</strong>、<strong class="lc iu">降低学习速率</strong>、<strong class="lc iu">不限制最大深度、增加叶子数量等来稍微过度拟合。</strong>通过调整这些，模型从<strong class="lc iu"> 0.50 提高到 0.47 </strong>，这确实是一个显著的进步，尤其是在 Kaggle 比赛中，而且得分是以对数标度(RMSLE)进行的。尽管这个模型有点过度拟合，我们可以通过在最后建立一个集合来减少模型的方差，正如我们将看到的。LightGBM 的主要问题是培训时间——在我的 16 GB RAM 的桌面上运行需要将近 2-3 个小时。</p><pre class="mf mg mh mi gt oy oz pa pb aw pc bi"><span id="2f67" class="oc kj it oz b gy pd pe l pf pg">lgbm_params_2 = {'n_estimators': 1500,<br/>                 'learning_rate': 0.05,<br/>                 'max_depth': -1,<br/>                 'num_leaves': 50,<br/>                 'subsample': 0.8,<br/>                 'colsample_bytree': 0.8,<br/>                 'min_child_samples': 50,<br/>                 'n_jobs': -1}</span></pre><h2 id="9b3c" class="oc kj it bd kk od oe dn ko of og dp ks lh oh oi ku lj oj ok kw ll ol om ky on bi translated">LSTM 神经网络(第 1 版)</h2><p id="c64d" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">这是第一个直觉，我们可以安全地假设该模型将工作良好，因为我们的大部分数据都以文本的形式出现在项目名称和项目描述中。此外，所有新生成的 17 个数字特征都已作为输入传递给数字特征。我的假设是，如果这些特征相关或不相关，神经网络会自己学习——所以不会损害模型。</p><p id="4c16" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">下面附上的是第一个 LSTM 模型-正如您在下面看到的，文本和分类特征首先通过嵌入层，然后展平以连接成密集的神经网络结构。</p><pre class="mf mg mh mi gt oy oz pa pb aw pc bi"><span id="5ed4" class="oc kj it oz b gy pd pe l pf pg"><strong class="oz iu">from</strong> <strong class="oz iu">tensorflow.keras.utils</strong> <strong class="oz iu">import</strong> <strong class="oz iu">plot_model<br/>from</strong> <strong class="oz iu">IPython.display</strong> <strong class="oz iu">import</strong> <strong class="oz iu">Image</strong><br/>plot_model(baseline_lstm_model, to_file='baseline_lstm_model.png', show_shapes=True, show_layer_names=True)<br/>Image(filename='baseline_lstm_model.png')</span></pre><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi pu"><img src="../Images/b49ea976b144c8671330fcc8d8ce8471.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xEWu7WdmNBpaO8z1dJND_g.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">LSTM 模型 1</p></figure><p id="9d28" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">上述模型在 60 个周期后给出的 RMSLE 为<strong class="lc iu"> 0.48 </strong>，当与 adam optimizer 一起使用时，val 损失未能显著改善。下面是生成上述 LSTM 模型 1 的代码。</p><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="nz oa l"/></div></figure><h2 id="0f3c" class="oc kj it bd kk od oe dn ko of og dp ks lh oh oi ku lj oj ok kw ll ol om ky on bi translated">LSTM 网络文本句子填充长度的选择</h2><p id="e09f" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">我们可以通过绘制句子长度的分布来选择句子长度。</p><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="nz oa l"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">代码片段—填充长度选择</p></figure><p id="a2a8" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">从代码中我们可以看到，在项目描述列中只有 0.59%的行的句子长度超过 125。这意味着几乎所有的句子长度都属于这个范畴，我们可以用它来选择句子长度。</p><pre class="mf mg mh mi gt oy oz pa pb aw pc bi"><span id="5949" class="oc kj it oz b gy pd pe l pf pg"><strong class="oz iu">&gt;&gt;&gt;select_padding(train_desc,tokenizer_desc,"Item Descriptions",125)</strong></span><span id="533f" class="oc kj it oz b gy pn pe l pf pg"><strong class="oz iu">Output :</strong><br/>Total number of words in the document are  138419<br/>0.5927708414700212  % of rows have sentence length &gt;  125</span></pre><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi pv"><img src="../Images/8cf4003e2e7f288927cb3ca3ee94ad08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*bvEuF21W6IcHXrQgsWMUvg.png"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">直方图—句子长度</p></figure><h2 id="7600" class="oc kj it bd kk od oe dn ko of og dp ks lh oh oi ku lj oj ok kw ll ol om ky on bi translated">LSTM 神经网络(第 2 版)</h2><p id="9573" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">在这个模型中，我们将名称、描述、品牌、类别中的文本连接起来，并创建了一个文本特征。我还选择了与价格高度相关的 3 个数字特征作为数字输入。该模型给出的均方根误差为<strong class="lc iu"> 0.47 </strong></p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi pw"><img src="../Images/48117f984a8acd52881df2a213bb7ec4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*24TVIONDb55s_G-4mRsg9w.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">LSTM 模型 2</p></figure><h2 id="97b2" class="oc kj it bd kk od oe dn ko of og dp ks lh oh oi ku lj oj ok kw ll ol om ky on bi translated">通过添加更多层来构建稀疏 MLP 模型的 2 个变体</h2><p id="a9a9" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">获胜者的解决方案模型使用简单的 MLP 模型，其中要素的稀疏输入表示只有 4 个图层。与 LSTM/LGBM 模型相比，该模型能够以更好的方式学习特征交互，因此结果良好。为了避免过度拟合，我在实验中在此基础上增加了几层，同时加入了辍学和批处理规范化。在构建了两个这样的模型之后，我们可以使用某种形式的组装来组合它们。</p><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="6786" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">正如你在上面看到的，这个模型非常简单。三款 MLP 车型的 RMSLE 得分分别为<strong class="lc iu"> 0.415、0.411 </strong>。</p><h2 id="9ed1" class="oc kj it bd kk od oe dn ko of og dp ks lh oh oi ku lj oj ok kw ll ol om ky on bi translated">最终集合模型</h2><p id="811e" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">在构建了许多这样的模型之后，我们可以以某种方式将它们组合起来，以提供更好的性能。我们可以使用交叉验证方法来获得最佳的集成模型组合。然而，对于我的最终模型，我决定只使用山脊模型和 MLP 模型，因为它们训练起来更快(&lt; 15 mins), whereas LSTM and LGBM models individually took &gt; 3 小时)。</p><figure class="mf mg mh mi gt mj"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="f245" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">在上面的方法中，我们在这里所做的是获取我们想要集成的 2 个模型的预测，并以给出最佳 RMSLE 的方式为每个模型分配权重——我们可以使用交叉验证来找到这一点。当我们对(2 个岭模型+ 2 个 MLP 模型)的集合进行此操作时，我们得到的 RMSLE 为<strong class="lc iu"> 0.408 </strong>，显著低于所有单个模型。</p><pre class="mf mg mh mi gt oy oz pa pb aw pc bi"><span id="4296" class="oc kj it oz b gy pd pe l pf pg">preds_final=ensemble_generator(preds_final_ridges,preds_final_mlps)</span></pre><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi px"><img src="../Images/a7c0ed153b8c08ae8f03da6c7cbc8ecc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DXLAA1fzroltqGUEXyvHXg.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">集成的权重选择</p></figure><p id="307c" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">岭型车型的大约<strong class="lc iu"> 0.1 </strong>权重和 MLP 车型的剩余<strong class="lc iu"> 0.9 </strong>权重给出了最好的分数。</p><pre class="mf mg mh mi gt oy oz pa pb aw pc bi"><span id="14d2" class="oc kj it oz b gy pd pe l pf pg">preds_f = 0.1*preds_ridge + 0.9*preds_mlps</span></pre></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="6a3e" class="ki kj it bd kk kl no kn ko kp np kr ks jz nq ka ku kc nr kd kw kf ns kg ky kz bi translated">8.摘要、结果和结论</h1><p id="2a73" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">下面是所有训练模型和获得的 RMSLE 分数的总结。正如我们所见，合奏模型是赢家。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi py"><img src="../Images/54d1c9df4c9c79d0883fd0beee6ec778.png" data-original-src="https://miro.medium.com/v2/resize:fit:1338/format:webp/1*FBt2ODoJVPzXONSjMneW1w.png"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">模型摘要</p></figure><p id="4350" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">在 Kaggle 中对看不见的测试数据集进行最终提交给出了 RMSLE 分数<strong class="lc iu"> 0.39 </strong>，这将在<strong class="lc iu"> top 1%排行榜</strong>中出现。</p><div class="mf mg mh mi gt ab cb"><figure class="op mj pz or os ot ou paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><img src="../Images/1b6eafa4bcb4faa48586eec7a6e5099d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*BTZM1JcZ5d3Wm8yS0IOzhQ.jpeg"/></div></figure><figure class="op mj qa or os ot ou paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><img src="../Images/a89caa6cde571311cc3d4eb5f2fade57.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*xcmQ-tRH1MdSBEX7Hg2vuQ.jpeg"/></div><p class="mq mr gj gh gi ms mt bd b be z dk qb di qc qd translated">Kaggle 提交</p></figure></div><h2 id="e66c" class="oc kj it bd kk od oe dn ko of og dp ks lh oh oi ku lj oj ok kw ll ol om ky on bi translated">可视化预测和误差</h2><p id="ce38" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">从下图可以看出，大约 55%的点有误差&lt; 5 and ~76% of points have errors &lt; 10. This is one of the way we can visualize the distribution of errors. Here <strong class="lc iu">误差=(实际—预测)</strong>。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi qe"><img src="../Images/a58e6f3fef5f31e9741d9d97fb20fcba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mHSjeKHVJFGUSz585bs9yQ.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">柱状图——误差分布</p></figure><p id="e4a5" class="pw-post-body-paragraph mv mw it lc b ld ni ju mx lf nj jx my lh nk na nb lj nl nd ne ll nm ng nh ln im bi translated">我们可以做的另一个图是绘制<strong class="lc iu">对数(绝对误差)</strong>图，因为我们已经完成了对数标度的价格建模。在下图中，x 轴是<strong class="lc iu">对数(Abs 误差)</strong>，左边的 y 轴代表该误差的点数(蓝色 histgoram)。橙色线给出了右侧 y 轴上的累积点数。我们可以看到，~ <strong class="lc iu"> 99%的点都有 Log(Abs 误差)&lt; 4 </strong>。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi qf"><img src="../Images/22a983439ca72fe2aab26b8a57232cdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8s_FyHf9UlFdcP_oABYjGg.png"/></div></div></figure></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="c98d" class="ki kj it bd kk kl no kn ko kp np kr ks jz nq ka ku kc nr kd kw kf ns kg ky kz bi translated">9.未来的工作</h1><p id="8e8b" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">我们可以在这方面做更多的实验来进一步改进预测—</p><ul class=""><li id="e087" class="la lb it lc b ld ni lf nj lh nu lj nv ll nw ln qg lp lq lr bi translated">使用<strong class="lc iu"> hyperas </strong>库来微调神经网络架构，以进一步提高性能</li><li id="3a39" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln qg lp lq lr bi translated">对文本数据使用其他矢量化方法，如<strong class="lc iu"> DictVectorizer() </strong>生成文本特征</li><li id="f866" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln qg lp lq lr bi translated">对文本数据上的单词嵌入使用卷积层</li></ul></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="7aac" class="ki kj it bd kk kl no kn ko kp np kr ks jz nq ka ku kc nr kd kw kf ns kg ky kz bi translated">10.链接到我的个人资料— github 代码和 linkedin</h1><p id="567a" class="pw-post-body-paragraph mv mw it lc b ld le ju mx lf lg jx my lh mz na nb lj nc nd ne ll nf ng nh ln im bi translated">你可以在 github <a class="ae mu" href="https://github.com/debayanmitra1993-data/Mercari-Price-Recommendation" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu">链接</strong> </a>找到我的完整代码。如果你想讨论，可以在我的 linkedin 个人资料<a class="ae mu" href="https://www.linkedin.com/in/debayan-mitra-63282398/" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu">链接</strong> </a>上联系我。你也可以帮我接通 debayanmitra1993@gmail.com 的电话。</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="5c8a" class="ki kj it bd kk kl no kn ko kp np kr ks jz nq ka ku kc nr kd kw kf ns kg ky kz bi translated">11.参考</h1><ul class=""><li id="17be" class="la lb it lc b ld le lf lg lh li lj lk ll lm ln qg lp lq lr bi translated"><a class="ae mu" href="https://www.appliedaicourse.com/course/11/Applied-Machine-learning-course" rel="noopener ugc nofollow" target="_blank">https://www . Applied ai course . com/course/11/Applied-Machine-learning-course</a></li><li id="47d1" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln qg lp lq lr bi translated"><a class="ae mu" href="https://medium.com/unstructured/how-i-lost-a-silver-medal-in-kaggles-mercari-price-suggestion-challenge-using-cnns-and-tensorflow-4013660fcded" rel="noopener">https://medium . com/unstructured/how-I-lost-a-silver-medal-in-kaggles-mercari-price-suggestion-challenge-using-CNN-and-tensor flow-4013660 fcded</a></li><li id="d9a6" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln qg lp lq lr bi translated"><a class="ae mu" href="https://www.kaggle.com/thykhuely/mercari-interactive-eda-topic-modelling" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/thykhuely/mercari-interactive-EDA-topic-modeling</a></li><li id="8ebb" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln qg lp lq lr bi translated"><a class="ae mu" href="https://www.kaggle.com/valkling/mercari-rnn-2ridge-models-with-notes-0-42755" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/valkling/mercari-rnn-2 ridge-models-with-notes-0-42755</a></li><li id="1664" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln qg lp lq lr bi translated"><a class="ae mu" href="https://www.kaggle.com/lopuhin/mercari-golf-0-3875-cv-in-75-loc-1900-s" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/lopu hin/mercari-golf-0-3875-cv-in-75-loc-1900-s</a></li><li id="19c7" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln qg lp lq lr bi translated"><a class="ae mu" href="https://www.kaggle.com/apapiu/ridge-script" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/apapiu/ridge-script</a></li><li id="4cf8" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln qg lp lq lr bi translated"><a class="ae mu" href="https://www.kaggle.com/tunguz/more-effective-ridge-lgbm-script-lb-0-44823" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/tunguz/more-effective-ridge-lgbm-script-l b-0-44823</a></li><li id="10ad" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln qg lp lq lr bi translated"><a class="ae mu" href="https://www.kaggle.com/gspmoreira/cnn-glove-single-model-private-lb-0-41117-35th" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/gspmoreira/CNN-glove-single-model-private-l b-0-41117-35 号</a></li><li id="79f9" class="la lb it lc b ld ls lf lt lh lu lj lv ll lw ln qg lp lq lr bi translated"><a class="ae mu" href="https://www.youtube.com/watch?v=QFR0IHbzA30" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=QFR0IHbzA30</a></li></ul></div></div>    
</body>
</html>