<html>
<head>
<title>Building a Semantic Search Engine for Large-Scale Fact-Checking and Question Answering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建面向大规模事实核查和问题回答的语义搜索引擎</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-semantic-search-engine-for-large-scale-fact-checking-and-question-answering-9aa356632432?source=collection_archive---------20-----------------------#2020-07-31">https://towardsdatascience.com/building-a-semantic-search-engine-for-large-scale-fact-checking-and-question-answering-9aa356632432?source=collection_archive---------20-----------------------#2020-07-31</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="64d7" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">开发一个语义检索模型，并使用它来建立一个新冠肺炎语义搜索引擎。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/92edd4ecd2f0df349a5bbeac17f26ac2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_n_IdZZ2ew5oR7Gq4Rl8NQ.png"/></div></div></figure><p id="5ed0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">段落检索是事实核查和问题回答系统的一个非常重要的部分。大多数系统通常只依赖稀疏检索，稀疏检索会对召回率产生重大影响，尤其是当相关段落与查询语句几乎没有重叠词时。在本文中，我们展示了我们如何开发一个优于稀疏段落检索的文本嵌入模型，以及我们如何利用它来构建<a class="ae ln" href="https://quin.algoprog.com/" rel="noopener ugc nofollow" target="_blank"> Quin </a>，一个关于新冠肺炎疫情事实的语义搜索引擎。</p></div><div class="ab cl lo lp hu lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="ij ik il im in"><h1 id="b4d7" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">段落检索</h1><p id="0b01" class="pw-post-body-paragraph kr ks iq kt b ku mn jr kw kx mo ju kz la mp lc ld le mq lg lh li mr lk ll lm ij bi translated">段落检索问题定义如下:给定一个段落语料库 D 和一个查询 q，我们希望使用带有两个参数 q 和 d ∈ D 的评分函数 f 返回与查询最相关的前 k 个段落，该评分函数计算相关性分数 f(q，d) ∈ R。</p><h2 id="8969" class="ms lw iq bd lx mt mu dn mb mv mw dp mf la mx my mh le mz na mj li nb nc ml nd bi translated">稀疏表示的局限性</h2><p id="72d6" class="pw-post-body-paragraph kr ks iq kt b ku mn jr kw kx mo ju kz la mp lc ld le mq lg lh li mr lk ll lm ij bi translated">TF-IDF 和 BM25 将文本表示为稀疏的高维向量，可以使用倒排索引数据结构对其进行有效搜索。这些稀疏表示可以有效地减少基于关键字的搜索空间。比如，当我们想回答一个类似<em class="ne">“电影《盗梦空间》是谁导演的？”</em>，我们显然想把重点放在包含单词<em class="ne">电影</em>和<em class="ne">盗梦空间</em>的段落上。然而，稀疏表示可能是限制性的，因为它们需要查询和段落之间的单词重叠，并且它们不能捕捉潜在的语义关系。例如，如果我们想要检索声明<em class="ne">“年轻人死于新冠肺炎”</em>的段落，包含类似于<em class="ne">“婴儿死于新冠肺炎”</em>或<em class="ne">“男孩死于新冠肺炎”</em>的句子的相关段落将被遗漏。</p><h2 id="d510" class="ms lw iq bd lx mt mu dn mb mv mw dp mf la mx my mh le mz na mj li nb nc ml nd bi translated">潜在密集检索</h2><p id="8186" class="pw-post-body-paragraph kr ks iq kt b ku mn jr kw kx mo ju kz la mp lc ld le mq lg lh li mr lk ll lm ij bi translated">基于变压器和语言建模任务预训练的神经模型，如 BERT、GPT 和 T5，已经导致许多自然语言处理任务的显著改进，包括段落检索。在我们的系统中，我们使用了一个基于 BERT 的文本嵌入模型。更具体地说，我们使用φ(q)和φ(d)的点积作为我们的段落评分函数:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/7df1ac1298802de01f4bb7dcff2d32a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:398/format:webp/1*vaG_bN8whGCfDGaAYakYZg.png"/></div><p class="ng nh gj gh gi ni nj bd b be z dk translated">段落评分功能</p></figure><p id="2bc3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">其中φ(。)是一个嵌入函数，它将一个段落或查询映射到一个密集向量。函数 f 的选择允许我们利用<a class="ae ln" href="https://github.com/facebookresearch/faiss" rel="noopener ugc nofollow" target="_blank"> FAISS </a>库进行有效的最大内积搜索，并轻松地将我们的系统扩展到数百万个文档。对于嵌入函数φ(。)，我们使用 BERT-base 的平均令牌嵌入，它已经在许多任务上进行了微调:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/2888c912c1bfa048a70bd9dd449fcef5.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/format:webp/1*TG_didTNfJk6ZeFa7hYt5A.png"/></div><p class="ng nh gj gh gi ni nj bd b be z dk translated">段落嵌入函数</p></figure><p id="2da3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">其中 BERT(d，I)是段落 d 中第 I 个标记的嵌入，而|d|是 d 中标记的数量。下图显示了称为 QR-BERT 的密集检索模型，该模型确定段落是否与查询相关。我们的密集检索模型由一个编码器组成，该编码器将查询和段落嵌入到相同的 k 维空间中。查询和段落之间的相似性(段落的相关性)由它们的嵌入表示的余弦相似性给出。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/844df698d602bc08df516d8388a9db6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:382/format:webp/1*wDT8jHhHNWeyMDMBtwnrbQ.png"/></div><p class="ng nh gj gh gi ni nj bd b be z dk translated">暹罗密集检索模型</p></figure><h2 id="80fb" class="ms lw iq bd lx mt mu dn mb mv mw dp mf la mx my mh le mz na mj li nb nc ml nd bi translated">训练嵌入模型</h2><p id="66f7" class="pw-post-body-paragraph kr ks iq kt b ku mn jr kw kx mo ju kz la mp lc ld le mq lg lh li mr lk ll lm ij bi translated">QR-BERT 通过一组查询段落示例进行训练。设 D+是正查询段落对的集合。我们通过最大化对数似然来估计评分函数的模型参数θ:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/7b53a5c6aaab42419888af59d9a08544.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*xPH5eaU5-OkJHAqP6flbqQ.png"/></div><p class="ng nh gj gh gi ni nj bd b be z dk translated">等式 1:损失函数</p></figure><p id="464a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">条件概率 p(d|q)由 softmax 近似表示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/26763cb99b644dbfa402e88a33e35592.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*2HCDr7YEB0BNUhG4zQdHXg.png"/></div><p class="ng nh gj gh gi ni nj bd b be z dk translated">等式 2:给定 q，检索 d 的概率</p></figure><p id="71e8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">注意，获得等式 2 中所有通道的分母在计算上是昂贵的。因此，我们将计算仅限于当前训练批次中的段落。最终损失函数由下式给出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/efd39f2e887e50629ff4d88f17afd9a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*1AqEKQLz-INzSzNw37WGzQ.png"/></div><p class="ng nh gj gh gi ni nj bd b be z dk translated">等式 3:最终损失函数</p></figure><p id="6829" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">其中 D_B 是训练批次 B 中的段落集，D_B+是 B 中的正查询-段落对集。使用 Adam 优化器在 MSMARCO 数据集上训练该模型。我们的实验表明，QR-BERT 比 BM25 段落检索好得多。</p><h2 id="dbd5" class="ms lw iq bd lx mt mu dn mb mv mw dp mf la mx my mh le mz na mj li nb nc ml nd bi translated">使用 NLI 数据进行预训练</h2><p id="9a9d" class="pw-post-body-paragraph kr ks iq kt b ku mn jr kw kx mo ju kz la mp lc ld le mq lg lh li mr lk ll lm ij bi translated">我们发现，在自然语言推理数据上预先训练嵌入模型实际上可以改进它。我们将两个流行的 NLI 数据集(SNLI 和 MultiNLI)合并为一个，称为 NLI，并且我们还从现有的问答数据集派生出一个新的 FactualNLI 数据集。在我们的<a class="ae ln" href="https://www.researchgate.net/publication/342815574_Latent_Retrieval_for_Large-Scale_Fact-Checking_and_Question_Answering_with_NLI_training" rel="noopener ugc nofollow" target="_blank">论文</a>中详细描述了推导新 NLI 数据集的方法。FactualNLI 数据集用于训练和评估用于事实检查的检索模型，也用于预训练用于答案检索的模型。使用 NLI 数据，我们使用分类目标对模型进行预训练:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/481f2e4c05070bbfc499ed8427e16211.png" data-original-src="https://miro.medium.com/v2/resize:fit:620/format:webp/1*JZPPAgc2DVsHGGaT8BT0bA.png"/></div><p class="ng nh gj gh gi ni nj bd b be z dk translated">等式 4:分类目标</p></figure><p id="8df3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">其中 u 是前提句的嵌入，v 是假设句的嵌入，W_3×3k 是线性变换矩阵，其中 k = 768 是 BERT-base 的隐藏表示的维数，而[u；五；| u v |]是 u、v 及其绝对差| u v |的级联向量。我们使用交叉熵损失和 Adam 优化器对 QR-BERT 进行预训练。我们的实验表明，在 NLI 和 FactualNLI 上的预训练提高了检索召回率。</p><h2 id="e51f" class="ms lw iq bd lx mt mu dn mb mv mw dp mf la mx my mh le mz na mj li nb nc ml nd bi translated">混合检索</h2><p id="4ee9" class="pw-post-body-paragraph kr ks iq kt b ku mn jr kw kx mo ju kz la mp lc ld le mq lg lh li mr lk ll lm ij bi translated">在我们的实验中，当我们合并 BM25 检索器和 QR-BERT 的顶部结果，并使用二元相关性分类器对它们重新排序时，我们得到了最佳结果。我们使用 MSMARCO 数据集(如 Nogueira 等人的 monoBERT)训练了基于 BERT-large 的二元相关性分类器。</p><p id="18dc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">关于模型评估的更多细节可以在我们的<a class="ae ln" href="https://www.researchgate.net/publication/342815574_Latent_Retrieval_for_Large-Scale_Fact-Checking_and_Question_Answering_with_NLI_training" rel="noopener ugc nofollow" target="_blank">论文</a>中找到。</p><h2 id="e2e3" class="ms lw iq bd lx mt mu dn mb mv mw dp mf la mx my mh le mz na mj li nb nc ml nd bi translated">定性分析</h2><p id="7764" class="pw-post-body-paragraph kr ks iq kt b ku mn jr kw kx mo ju kz la mp lc ld le mq lg lh li mr lk ll lm ij bi translated">下表显示了 QR-BERT 和 BM25 检索到的一些问题和主张的主要摘录:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi np"><img src="../Images/8d4d42faa3e250967a0890fa5e015e3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pxmrbvN3ucWbWV3QomR-Uw.png"/></div></div><p class="ng nh gj gh gi ni nj bd b be z dk translated">QR-BERT 和 BM25 检索到的与新冠肺炎相关的查询片段</p></figure><p id="9cea" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">对于前两个查询，只有 QR-BERT 返回相关段落。这是因为基于关键字的检索不足以显示最相关的段落。对于第三个查询，两个模型都成功地检索到了相关的片段。对这个查询的一个有趣观察是，QR-BERT 检索到的片段只有单词<em class="ne">病毒</em>与查询相同。这表明该模型有能力捕捉文本的潜在含义，并识别同义词术语，如<em class="ne">取消</em>(对于<em class="ne">取消</em>)和语义相近的术语，如<em class="ne">会议</em>(接近<em class="ne">事件</em>)。</p><p id="e0c1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">一般来说，当查询足够具体以允许通过关键字匹配容易地发现相关段落时，稀疏检索工作得很好。然而，这在实践中是不够的。我们的实验表明，密集检索模型可以给出更准确的结果，并且当在具有稀疏检索结合重新排序的架构中使用时，我们可以实现显著更高的召回率。</p></div><div class="ab cl lo lp hu lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="ij ik il im in"><h1 id="86e2" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">奎因系统</h1><p id="6a5b" class="pw-post-body-paragraph kr ks iq kt b ku mn jr kw kx mo ju kz la mp lc ld le mq lg lh li mr lk ll lm ij bi translated">使用密集检索模型，我们开发了 Quin，这是一个可扩展的语义搜索引擎，可以返回最多五个句子的片段，包含与新冠肺炎疫情相关的问题或声明的答案。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/538fbaa99f65436dbffc895b9eae22cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KKOojj3mHNbUbwcRZ2xQRQ.png"/></div></div><p class="ng nh gj gh gi ni nj bd b be z dk translated">Quin 语义搜索引擎</p></figure><p id="e4a6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Quin 有一个模块用于抓取 RSS 提要，并存储新闻文章的 html 源代码。我们去掉样板文件，分离出新闻文章的主要内容。通过在每篇文章的句子序列上使用滑动窗口，我们从干净的文本中提取每篇文章的 5 个句子的片段。我们利用<a class="ae ln" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> nltk </a>库将文档分割成句子。为了促进高效的大规模检索，我们在片段上构建了两个索引:(a)用于 BM25 检索的高效稀疏倒排索引(关键字索引)，以及(b)支持最大内积搜索的 FAISS 密集(语义)索引。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/3d1fd3063e8b7f51b7b154f8e1604a06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-LaR_PfEbfJcH_BpD0Sptg.png"/></div></div><p class="ng nh gj gh gi ni nj bd b be z dk translated">索引(左)和搜索(右)</p></figure><p id="c453" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">该查询用于在片段的稀疏和密集(FAISS)索引上执行搜索。我们从每个索引中检索前 500 个结果，并计算每个结果的相关性分数。结果按照它们的相关性分数排序，我们输出最终排序的结果列表。当查询是一个语句时，我们有一个额外的步骤，使用 NLI 模型将检索到的段落分为三类，这样它们显示在三个选项卡下；<em class="ne">所有</em>、<em class="ne">支持</em>和<em class="ne">反驳</em>的证据。</p><p id="1d51" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">除了新闻，Quin 还支持与新冠肺炎相关的研究论文的语义搜索。在撰写本文时，Quin 拥有超过<strong class="kt ir"> 20 万篇</strong>与新冠肺炎相关的新闻文章和<strong class="kt ir"> 10 万篇</strong>研究出版物的索引。我们希望这个系统将有助于对抗错误信息，并帮助一些研究人员寻找新冠肺炎的治疗方法。</p><p id="5114" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">[ <a class="ae ln" href="https://github.com/algoprog/Quin" rel="noopener ugc nofollow" target="_blank">项目页面</a>，[ <a class="ae ln" href="https://www.researchgate.net/publication/342815574_Latent_Retrieval_for_Large-Scale_Fact-Checking_and_Question_Answering_with_NLI_training" rel="noopener ugc nofollow" target="_blank">论文</a>，[ <a class="ae ln" href="https://quin.algoprog.com/" rel="noopener ugc nofollow" target="_blank">演示</a></p></div></div>    
</body>
</html>