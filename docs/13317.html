<html>
<head>
<title>Image Noise Reduction in 10 Minutes with Deep Convolutional Autoencoders</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度卷积自动编码器在 10 分钟内降低图像噪声</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-noise-reduction-in-10-minutes-with-convolutional-autoencoders-d16219d2956a?source=collection_archive---------7-----------------------#2020-09-13">https://towardsdatascience.com/image-noise-reduction-in-10-minutes-with-convolutional-autoencoders-d16219d2956a?source=collection_archive---------7-----------------------#2020-09-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="4c3b" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">深度学习案例研究</h2><div class=""/><div class=""><h2 id="5307" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">借助时尚 MNIST |使用 TensorFlow 的无监督深度学习，使用自动编码器清理(或去噪)有噪声的图像</h2></div><p id="f33e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如果你正在阅读这篇文章，我确信我们有着相似的兴趣，并且现在/将来会从事相似的行业。那么我们就通过 <a class="ae lo" href="https://linkedin.com/in/orhangaziyalcin/" rel="noopener ugc nofollow" target="_blank"> <em class="ln"> Linkedin </em> </a> <em class="ln">来连线吧！请不要犹豫发送联系请求！</em><a class="ae lo" href="https://linkedin.com/in/orhangaziyalcin/" rel="noopener ugc nofollow" target="_blank"><em class="ln">Orhan g . yaln—Linkedin</em></a></p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi lp"><img src="../Images/86e96ed73e4482fa4951f1c56bdded85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*RVsX901R3uAFhGD_qTWoSA.gif"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">图一。一只贪玩的狗的图像降噪前后(由<a class="ae lo" href="https://unsplash.com/@annadudkova" rel="noopener ugc nofollow" target="_blank"> Anna Dudkova </a>在<a class="ae lo" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄)</p></figure><p id="350d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="ln">如果你在这个页面上，你也可能对不同的神经网络架构有些熟悉。你可能听说过前馈神经网络，CNN，RNNs，这些神经网络非常适合解决监督学习任务，如回归和分类。</em></p><p id="5226" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="ln">但是，在无监督学习领域，我们有大量的问题，例如降维、特征提取、异常检测、数据生成、增强以及降噪。对于这些任务，我们需要专门为无监督学习任务开发的特殊神经网络的帮助。因此，他们必须能够在不需要监督的情况下解数学方程。这些特殊的神经网络架构之一是自动编码器</em>。</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="mf mg l"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">获取最新的机器学习教程</p></figure><h1 id="e1e2" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">自动编码器</h1><h2 id="19f1" class="mz mi it bd mj na nb dn mn nc nd dp mr la ne nf mt le ng nh mv li ni nj mx iz bi translated">什么是自动编码器？</h2><p id="6f92" class="pw-post-body-paragraph kr ks it kt b ku nk kd kw kx nl kg kz la nm lc ld le nn lg lh li no lk ll lm im bi translated">自动编码器是由两个子网络组成的神经网络架构，即编码器和解码器网络，它们通过潜在空间相互联系。自动编码器最初是由人工智能界最受尊敬的科学家之一 Geoffrey Hinton 和 PDP 小组在 20 世纪 80 年代开发的。Hinton 和 PDP 小组旨在通过将输入作为教师来解决“无教师反向传播”问题，也称为无监督学习。换句话说，他们只是将特征数据用作特征数据和标签数据。让我们仔细看看自动编码器是如何工作的！</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi np"><img src="../Images/b74761d47b002dad384deaed5dd35591.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sahNK4wy4teFA0r6tJJwKQ.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">图二。具有编码器和解码器网络的自动编码器网络</p></figure><h2 id="a7fd" class="mz mi it bd mj na nb dn mn nc nd dp mr la ne nf mt le ng nh mv li ni nj mx iz bi translated">自动编码器架构</h2><p id="b1d5" class="pw-post-body-paragraph kr ks it kt b ku nk kd kw kx nl kg kz la nm lc ld le nn lg lh li no lk ll lm im bi translated">自动编码器由一个编码器网络组成，它获取特征数据并对其进行编码以适应潜在空间。该编码数据(即代码)被解码器用来转换回特征数据。在编码器中，模型学习的是如何有效地编码数据，以便解码器可以将其转换回原始数据。因此，自动编码器训练的基本部分是生成优化的潜在空间。</p><p id="4d0b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">现在，我们知道，在大多数情况下，潜在空间中的神经元数量比输入和输出层要少得多，但也不一定是这样。有不同类型的自动编码器，如欠完整、过完整、稀疏、去噪、收缩和变化自动编码器。在本教程中，我们只关注用于去噪的欠完整自动编码器。</p><h2 id="1313" class="mz mi it bd mj na nb dn mn nc nd dp mr la ne nf mt le ng nh mv li ni nj mx iz bi translated">自动编码器中的图层</h2><p id="f2ed" class="pw-post-body-paragraph kr ks it kt b ku nk kd kw kx nl kg kz la nm lc ld le nn lg lh li no lk ll lm im bi translated">构建自动编码器时的标准做法是设计一个编码器，并创建该网络的反向版本作为该自动编码器的解码器。因此，只要编码器和解码器网络之间存在反向关系，您就可以自由地向这些子网添加任何层。例如，如果您正在处理图像数据，您肯定会需要卷积和池层。另一方面，如果您正在处理序列数据，您可能需要 LSTM、GRU 或 RNN 单位。这里重要的一点是，你可以自由地建造任何你想要的东西。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nq"><img src="../Images/ea65bd206f54ba9cf98dcaa065e4b82d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ybznnsVX2au5ZUVI-_Al4A.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">图 3。欠完整自动编码器中的潜在空间通常比其他层窄</p></figure><p id="fa15" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">现在，您已经有了可以为图像降噪构建自动编码器的想法，我们可以继续学习教程，并开始为我们的图像降噪模型编写代码。对于本教程，我们选择做我们自己对 TensorFlow 的官方教程之一，<a class="ae lo" href="https://www.tensorflow.org/tutorials/generative/autoencoder" rel="noopener ugc nofollow" target="_blank">自动编码器简介</a>，我们将使用人工智能社区成员中非常受欢迎的数据集:<strong class="kt jd"> <em class="ln">时尚 MNIST </em> </strong>。</p><h1 id="ec6f" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">下载时尚 MNIST 数据集</h1><p id="14e2" class="pw-post-body-paragraph kr ks it kt b ku nk kd kw kx nl kg kz la nm lc ld le nn lg lh li no lk ll lm im bi translated">时尚 MNIST 由位于德国柏林的欧洲电子商务公司 Zalando 设计和维护。时尚 MNIST 由 60，000 幅图像的训练集和 10，000 幅图像的测试集组成。每个示例都是 28×28 灰度图像，与来自 10 个类别的标签相关联。“时尚 MNIST”包含服装商品的图像(如图 4 所示)，它被设计为包含手写数字的 MNIST 数据集的替代数据集。我们选择时尚 MNIST 仅仅是因为 MNIST 已经在许多教程中被过度使用。</p><p id="a176" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">下面几行导入 TensorFlow 和 load Fashion MNIST:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nr mg l"/></div></figure><p id="b16e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">现在，让我们用数据集的样本生成一个网格，代码如下:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nr mg l"/></div></figure><p id="47ad" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们的输出显示了测试数据集中的前 50 个样本:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/56c0aaf463d9b1221cfc6cb0ace35fe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*tRTpKOHukueJ9h-Up6OsuQ.png"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">图 4。显示时尚 MNIST 测试数据集中前 50 个样本的 5x10 网格</p></figure><h1 id="f6ff" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">处理时尚 MNIST 数据</h1><p id="ff02" class="pw-post-body-paragraph kr ks it kt b ku nk kd kw kx nl kg kz la nm lc ld le nn lg lh li no lk ll lm im bi translated">为了计算效率和模型可靠性，我们必须对我们的图像数据应用最小最大归一化，将值范围限制在 0 和 1 之间。由于我们的数据是 RGB 格式的，最小值是 0，最大值是 255，我们可以用下面几行进行最小最大规范化操作:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nr mg l"/></div></figure><p id="2e0e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们还必须调整 NumPy 数组的形状，因为数据集的当前形状是(60000，28，28)和(10000，28，28)。我们只需要添加一个具有单一值的第四维(例如，从(60000，28，28)到(60000，28，28，1))。第四维几乎可以证明我们的数据是灰度格式的，用一个值表示从白色到黑色的颜色信息。如果我们有彩色图像，那么我们就需要第四维中的三个值。但是我们所需要的是包含单一值的第四维，因为我们使用灰度图像。以下代码行可以做到这一点:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nr mg l"/></div></figure><p id="44e0" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">让我们用下面几行来看看 NumPy 数组的形状:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nr mg l"/></div></figure><p id="c377" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd"> <em class="ln">输出:</em> </strong> <em class="ln"> (60000，28，28，1)和(10000，28，28，1) </em></p><h1 id="cca7" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">向图像添加噪声</h1><p id="e022" class="pw-post-body-paragraph kr ks it kt b ku nk kd kw kx nl kg kz la nm lc ld le nn lg lh li no lk ll lm im bi translated">请记住，我们的目标是建立一个能够对图像进行降噪的模型。为了做到这一点，我们将使用现有的图像数据，并将它们添加到随机噪声中。然后，我们将原始图像作为输入，含噪图像作为输出。我们的自动编码器将学习干净的图像和有噪声的图像之间的关系，以及如何清洁有噪声的图像。因此，让我们创建一个噪声版本的时尚 MNIST 数据集。</p><p id="811b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">对于此任务，我们使用 tf.random.normal 方法向每个数组项添加一个随机生成的值。然后，我们将这个随机值乘以一个 noise_factor，你可以随意使用它。以下代码向图像添加了噪声:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nr mg l"/></div></figure><p id="b8aa" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们还需要确保数组项的值在 0 到 1 的范围内。为此，我们可以使用<em class="ln"> tf.clip_by_value </em>方法。<em class="ln"> clip_by_value </em>是一种张量流方法，它剪切最小-最大范围之外的值，并用指定的最小或最大值替换它们。以下代码将值截取到范围之外:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nr mg l"/></div></figure><p id="4032" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">现在我们已经创建了数据集的正则化和噪声版本，我们可以检查它的外观:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nr mg l"/></div></figure><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nt"><img src="../Images/0841303b2b13ee50cc6fd8f50205156f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JR58_vUvg5eMXwV1nY-jig.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">图 5。显示清晰和嘈杂图像样本的 2x5 网格</p></figure><p id="6899" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">正如你所看到的，几乎不可能理解我们在嘈杂的图像中看到的东西。然而，我们的自动编码器会神奇地学会清理它。</p><h1 id="fb5c" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">构建我们的模型</h1><p id="861d" class="pw-post-body-paragraph kr ks it kt b ku nk kd kw kx nl kg kz la nm lc ld le nn lg lh li no lk ll lm im bi translated">在 TensorFlow 中，除了顺序 API 和函数 API 之外，还有第三种构建模型的选择:模型子类化。在模型子类化中，我们可以自由地从头开始实现任何东西。模型子类化是完全可定制的，使我们能够实现我们自己的定制模型。这是一个非常强大的方法，因为我们可以建立任何类型的模型。但是，它需要基本的面向对象编程知识。我们的自定义类将继承 tf.keras.Model 对象。它还需要声明几个变量和函数。不过，这没什么可怕的。</p><p id="c7eb" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">另请注意，由于我们处理的是图像数据，因此构建卷积自动编码器会更有效，如下所示:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nu"><img src="../Images/4e674061f44e9941d37be03a7e62c847.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uFdhkxp2ghFX03kKL8vVew.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">图 6。卷积自动编码器示例</p></figure><p id="8f74" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">要构建模型，我们只需完成以下任务:</p><ul class=""><li id="aaba" class="nv nw it kt b ku kv kx ky la nx le ny li nz lm oa ob oc od bi translated">创建一个扩展 keras 的类。模型对象</li><li id="7334" class="nv nw it kt b ku oe kx of la og le oh li oi lm oa ob oc od bi translated">创建一个<strong class="kt jd"> __init__ </strong>函数来声明用顺序 API 构建的两个独立的模型。在它们内部，我们需要声明可以相互反转的层。一个 Conv2D 层用于编码器模型，而一个 conv 2d 转置层用于解码器模型。</li><li id="aeff" class="nv nw it kt b ku oe kx of la og le oh li oi lm oa ob oc od bi translated">创建一个调用函数，告诉模型如何通过<strong class="kt jd"> __init__ </strong>方法使用初始化的变量处理输入:</li><li id="942c" class="nv nw it kt b ku oe kx of la og le oh li oi lm oa ob oc od bi translated">我们需要调用初始化的编码器模型，该模型将图像作为输入</li><li id="8d8d" class="nv nw it kt b ku oe kx of la og le oh li oi lm oa ob oc od bi translated">我们还需要调用初始化的解码器模型，该模型将编码器模型(已编码)的输出作为输入</li><li id="b131" class="nv nw it kt b ku oe kx of la og le oh li oi lm oa ob oc od bi translated">返回解码器的输出</li></ul><p id="cb16" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们可以用下面的代码实现所有这些:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nr mg l"/></div></figure><p id="880e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">让我们用一个对象调用来创建模型:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nr mg l"/></div></figure><h1 id="86aa" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">配置我们的模型</h1><p id="5c87" class="pw-post-body-paragraph kr ks it kt b ku nk kd kw kx nl kg kz la nm lc ld le nn lg lh li no lk ll lm im bi translated">对于这项任务，我们将使用 Adam 优化器和模型的均方误差。我们可以很容易地使用<strong>编译</strong>功能来配置我们的自动编码器，如下所示:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nr mg l"/></div></figure><p id="d9b9" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">最后，我们可以通过输入有噪声和干净的图像来运行我们的模型 10 个时期，这将需要大约 1 分钟来训练。我们还使用测试数据集进行验证。以下代码用于训练模型:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nr mg l"/></div></figure><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi oj"><img src="../Images/f773c623c08fce6259b851cef3e24003.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wzMJ6KpX7Z_xpbJ921m8-w.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">图 7。深度卷积自动编码器训练性能</p></figure><h1 id="2e20" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">使用我们训练有素的自动编码器降低图像噪音</h1><p id="0058" class="pw-post-body-paragraph kr ks it kt b ku nk kd kw kx nl kg kz la nm lc ld le nn lg lh li no lk ll lm im bi translated">既然我们已经训练了我们的自动编码器，我们可以开始清理噪声图像。注意，我们可以访问编码器和解码器网络，因为我们是在 NoiseReducer 对象下定义它们的。</p><p id="b0fc" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">因此，首先，我们将使用一个编码器来编码我们的噪声测试数据集(x _ test _ noisy)。然后，我们将把编码器的编码输出送入解码器，以获得干净的图像。以下代码行完成这些任务:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nr mg l"/></div></figure><p id="8f59" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">让我们绘制前 10 个样本，进行并列比较:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nr mg l"/></div></figure><p id="a165" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">第一行是有噪声的图像，第二行是干净的(重建的)图像，最后，第三行是原始图像。查看清理后的图像与原始图像有何相似之处:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nt"><img src="../Images/c036e549bb6f82f8523a60e6c7c6e7a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*swjWq5rvsnePG-EZq1Edgg.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">图 5。一个 3x10 的网格，显示干净和有噪声的图像样本以及它们的重建副本</p></figure><h1 id="99f2" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">恭喜</h1><p id="447a" class="pw-post-body-paragraph kr ks it kt b ku nk kd kw kx nl kg kz la nm lc ld le nn lg lh li no lk ll lm im bi translated">你已经建立了一个 autoencoder 模型，它可以成功地清理非常嘈杂的图像，这是它以前从未见过的(<em class="ln">我们使用了测试数据集</em>)。显然有一些未恢复的失真，例如右边第二个图像中缺失的拖鞋底部。然而，如果你考虑噪声图像的变形程度，我们可以说我们的模型在恢复失真图像方面相当成功。</p><p id="ad81" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在我的脑海中，你可以-例如-考虑扩展这个自动编码器，并将其嵌入到照片增强应用程序中，这可以增加照片的清晰度和清晰度。</p><h1 id="b082" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">订阅邮件列表获取完整代码</h1><p id="8a88" class="pw-post-body-paragraph kr ks it kt b ku nk kd kw kx nl kg kz la nm lc ld le nn lg lh li no lk ll lm im bi translated">如果你想访问 Google Colab 的全部代码，并访问我的最新内容，请订阅邮件列表:</p><blockquote class="ok"><p id="0226" class="ol om it bd on oo op oq or os ot lm dk translated"><a class="ae lo" href="http://eepurl.com/hd6Xfv" rel="noopener ugc nofollow" target="_blank">现在就订阅</a></p></blockquote><h1 id="23db" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ou kj mt kl ov km mv ko ow kp mx my bi translated">喜欢这篇文章</h1><p id="a2dd" class="pw-post-body-paragraph kr ks it kt b ku nk kd kw kx nl kg kz la nm lc ld le nn lg lh li no lk ll lm im bi translated">如果你喜欢这篇文章，可以考虑看看我的其他类似文章:</p><div class="ox oy gp gr oz pa"><a rel="noopener follow" target="_blank" href="/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d"><div class="pb ab fo"><div class="pc ab pd cl cj pe"><h2 class="bd jd gy z fp pf fr fs pg fu fw jc bi translated">使用 MNIST 数据集在 10 分钟内完成图像分类</h2><div class="ph l"><p class="bd b dl z fp pf fr fs pg fu fw dk translated">towardsdatascience.com</p></div></div><div class="pi l"><div class="pj l pk pl pm pi pn lz pa"/></div></div></a></div><div class="ox oy gp gr oz pa"><a rel="noopener follow" target="_blank" href="/image-generation-in-10-minutes-with-generative-adversarial-networks-c2afc56bfa3b"><div class="pb ab fo"><div class="pc ab pd cl cj pe"><h2 class="bd jd gy z fp pf fr fs pg fu fw jc bi translated">利用生成性对抗网络在 10 分钟内生成图像</h2><div class="po l"><h3 class="bd b gy z fp pf fr fs pg fu fw dk translated">使用无监督深度学习生成手写数字与深度卷积甘斯使用张量流和…</h3></div><div class="ph l"><p class="bd b dl z fp pf fr fs pg fu fw dk translated">towardsdatascience.com</p></div></div><div class="pi l"><div class="pp l pk pl pm pi pn lz pa"/></div></div></a></div><div class="ox oy gp gr oz pa"><a rel="noopener follow" target="_blank" href="/sentiment-analysis-in-10-minutes-with-bert-and-hugging-face-294e8a04b671"><div class="pb ab fo"><div class="pc ab pd cl cj pe"><h2 class="bd jd gy z fp pf fr fs pg fu fw jc bi translated">伯特和拥抱脸 10 分钟情感分析</h2><div class="po l"><h3 class="bd b gy z fp pf fr fs pg fu fw dk translated">学习预训练的自然语言处理模型的基础，伯特，并建立一个使用 IMDB 电影评论的情感分类器…</h3></div><div class="ph l"><p class="bd b dl z fp pf fr fs pg fu fw dk translated">towardsdatascience.com</p></div></div><div class="pi l"><div class="pq l pk pl pm pi pn lz pa"/></div></div></a></div><div class="ox oy gp gr oz pa"><a rel="noopener follow" target="_blank" href="/tensorflow-and-vgg19-can-help-you-convert-your-photos-into-beautiful-pop-art-pieces-c1abe87e7e01"><div class="pb ab fo"><div class="pc ab pd cl cj pe"><h2 class="bd jd gy z fp pf fr fs pg fu fw jc bi translated">TensorFlow 和 VGG19 可以帮助您将照片转换成美丽的波普艺术作品</h2><div class="po l"><h3 class="bd b gy z fp pf fr fs pg fu fw dk translated">神经风格转移基于安迪沃霍尔的门罗双联画与预训练的计算机视觉网络 VGG19，转移…</h3></div><div class="ph l"><p class="bd b dl z fp pf fr fs pg fu fw dk translated">towardsdatascience.com</p></div></div><div class="pi l"><div class="pr l pk pl pm pi pn lz pa"/></div></div></a></div></div></div>    
</body>
</html>