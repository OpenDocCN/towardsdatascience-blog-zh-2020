<html>
<head>
<title>Introduction to NLP - Part 2: Difference between lemmatisation and stemming</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP 介绍-第 2 部分:引理满足和词干的区别</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introduction-to-nlp-part-2-difference-between-lemmatisation-and-stemming-3789be1c55bc?source=collection_archive---------48-----------------------#2020-06-07">https://towardsdatascience.com/introduction-to-nlp-part-2-difference-between-lemmatisation-and-stemming-3789be1c55bc?source=collection_archive---------48-----------------------#2020-06-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="bb27" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你想知道引理满足和词干的区别吗？如果你很想知道答案，这篇文章将试图解释它。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/bc3090cf2e362152ff88d54a66ee0e8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CTpUNKAs938AkHA4"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">照片由<a class="ae le" href="https://unsplash.com/@retrosupply?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上反推</a></p></figure></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><h1 id="58c5" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">1.定义📗</h1><p id="0e7f" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">引理和词干是规范化文本以获得单词的词根形式的不同技术。Christopher D. Manning、Prabhakar Raghavan 和 Hinrich Schütze 在他们的著作中对这两个概念做了如下简明的定义:<em class="mp">信息检索导论</em>，2008:</p><blockquote class="mq mr ms"><p id="dbf3" class="jq jr mp js b jt ju jv jw jx jy jz ka mt kc kd ke mu kg kh ki mv kk kl km kn im bi translated"><strong class="js iu"> <em class="it">💡</em> </strong> <a class="ae le" href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html" rel="noopener ugc nofollow" target="_blank">“词干化通常指一种粗糙的启发式过程，即砍掉词尾，希望在大多数时候都能正确实现这一目标，通常还包括去除派生词缀……词干分析器使用特定于语言的规则，但是它们比词汇分析器需要更少的知识…”</a></p><p id="f2d0" class="jq jr mp js b jt ju jv jw jx jy jz ka mt kc kd ke mu kg kh ki mv kk kl km kn im bi translated"><strong class="js iu">T13】💡 </strong> <a class="ae le" href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html" rel="noopener ugc nofollow" target="_blank">“词汇化通常是指利用词汇和词的形态分析来恰当地做事情，通常旨在仅去除屈折词尾并返回词的基本形式或词典形式，这就是所谓的词汇……一个词法分析器，它需要完整的词汇和词法分析来正确地对单词进行词法分析…”</a></p></blockquote><p id="8b15" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果这是你第一次阅读这些定义，他们可能不会马上点击。因为这些定义相当丰富和密集，所以慢慢地、仔细地、反复地阅读是有帮助的。如果你读完这篇文章后回来，希望这些定义会更有意义。</p><p id="378d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">简化概述:</strong>词干化使用<em class="mp">预定义规则</em>将单词转化为<em class="mp">词干</em>，而词条化使用<em class="mp">上下文</em>和<em class="mp">词库</em>派生<em class="mp">词条</em>。<em class="mp">词干</em>不一定总是有效单词，而<em class="mp">词条</em>将总是有效单词，因为<em class="mp">词条</em>是单词的字典形式。</p><p id="52ac" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">正如我们很快将在示例中看到的，这两种技术有时会产生相同的输出。</p></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><h1 id="0aac" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">2.Python 设置🔧</h1><p id="6717" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">本节假设您已经访问并熟悉 Python，包括安装包、定义函数和其他基本任务。如果你是 Python 的新手，<a class="ae le" href="https://www.python.org/about/gettingstarted/" rel="noopener ugc nofollow" target="_blank">这个</a>是一个很好的开始。</p><p id="4936" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我已经使用并测试了 Python 3.7.1 中的脚本。在使用代码之前，让我们确保您有合适的工具。</p><h2 id="4359" class="mw ln it bd lo mx my dn ls mz na dp lw kb nb nc ma kf nd ne me kj nf ng mi nh bi translated">⬜️确保安装了所需的软件包:熊猫和 nltk</h2><p id="29d4" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">我们将使用以下强大的第三方软件包:</p><ul class=""><li id="251a" class="ni nj it js b jt ju jx jy kb nk kf nl kj nm kn nn no np nq bi translated"><em class="mp">熊猫</em>:数据分析库和</li><li id="9bbc" class="ni nj it js b jt nr jx ns kb nt kf nu kj nv kn nn no np nq bi translated"><em class="mp"> nltk: </em>自然语言工具包库</li></ul><h2 id="e569" class="mw ln it bd lo mx my dn ls mz na dp lw kb nb nc ma kf nd ne me kj nf ng mi nh bi translated">⬜️从 nltk 下载“wordnet”语料库</h2><p id="dedf" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">下面的脚本可以帮助你下载这个语料库。如果您已经下载了它，运行它将通知您它是最新的:</p><pre class="kp kq kr ks gt nw nx ny nz aw oa bi"><span id="76be" class="mw ln it nx b gy ob oc l od oe">import nltk<br/>nltk.download('wordnet')</span></pre></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><h1 id="95b4" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">3.输出比较🔍</h1><p id="babb" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">在我们深入例子之前，您应该知道有不同类型的词干分析器和词尾分析器可用。正如您所料，一种类型的词干分析器可能与其他类型的词干分析器有所不同。对于 lemmatisers 来说也是如此。</p><p id="c7ae" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我们的例子中，我们将使用来自<em class="mp"> nltk </em>的<em class="mp"> PorterStemmer、LancasterStemmer </em>和<em class="mp"> WordNetLemmatizer </em>来规范化单词。</p><blockquote class="mq mr ms"><p id="a59c" class="jq jr mp js b jt ju jv jw jx jy jz ka mt kc kd ke mu kg kh ki mv kk kl km kn im bi translated"><em class="it">💡</em><strong class="js iu"><em class="it"/>PorterStemmer<em class="it">:</em></strong><em class="it">最常用的词干分析器之一。它基于波特词干算法。更多信息，查看官方网页:【https://tartarus.org/martin/PorterStemmer/】<a class="ae le" href="https://tartarus.org/martin/PorterStemmer/" rel="noopener ugc nofollow" target="_blank"><em class="it"/></a></em></p><p id="b865" class="jq jr mp js b jt ju jv jw jx jy jz ka mt kc kd ke mu kg kh ki mv kk kl km kn im bi translated"><em class="it">💡</em><strong class="js iu">Lancaster stemmer<em class="it">:</em></strong><em class="it">它基于 Lancaster 词干算法，有时会产生比</em> PorterStemmer <em class="it">更激进的词干。</em></p><p id="152a" class="jq jr mp js b jt ju jv jw jx jy jz ka mt kc kd ke mu kg kh ki mv kk kl km kn im bi translated"><em class="it">💡</em><strong class="js iu">【WordNet lemma tiser】<em class="it">:</em></strong><a class="ae le" href="https://wordnet.princeton.edu/" rel="noopener ugc nofollow" target="_blank"><em class="it">使用 WordNet 词汇数据库。如果在 WordNet 中找不到输入单词，则返回不变的输入单词。</em>T45】</a></p></blockquote><p id="a207" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们创建一个函数，使用以下三种方法对单词进行规范化:</p><pre class="kp kq kr ks gt nw nx ny nz aw oa bi"><span id="54b2" class="mw ln it nx b gy ob oc l od oe"># Import packages<br/>import pandas as pd<br/>from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer</span><span id="ec8b" class="mw ln it nx b gy of oc l od oe"># Instantiate stemmers and lemmatiser<br/>porter = PorterStemmer()<br/>lancaster = LancasterStemmer()<br/>lemmatiser = WordNetLemmatizer()</span><span id="fd12" class="mw ln it nx b gy of oc l od oe"># Create function that normalises text using all three techniques<br/>def normalise_text(words, pos='v'):<br/>    """Stem and lemmatise each word in a list. Return output in a dataframe."""<br/>    normalised_text = pd.DataFrame(index=words, columns=['Porter', 'Lancaster', 'Lemmatiser'])<br/>    for word in words:<br/>        normalised_text.loc[word,'Porter'] = porter.stem(word)<br/>        normalised_text.loc[word,'Lancaster'] = lancaster.stem(word)<br/>        normalised_text.loc[word,'Lemmatiser'] = lemmatiser.lemmatize(word, pos=pos)<br/>    return normalised_text</span></pre><p id="d4e8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将从 10 个任意名词开始，并比较它们的规范化形式:</p><pre class="kp kq kr ks gt nw nx ny nz aw oa bi"><span id="8302" class="mw ln it nx b gy ob oc l od oe">normalise_text(['apples', 'pears', 'tasks', 'children', 'earrings', 'dictionary', 'marriage', 'connections', 'universe', 'university'], pos='n')</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi og"><img src="../Images/62b999f908ef0bf48ff9fc618a5d3110.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/1*l4h1zEdVseYSaP2PoVjwKQ.png"/></div></figure><p id="a1df" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你可以看到<em class="mp">词干</em>并不总是一个有效的单词，而<em class="mp">词条</em>却是。大学和宇宙一旦被毁灭，看起来是一样的，但一旦被毁灭，情况就不同了。你有没有注意到上面的词干都不是以 e 结尾的？可能是因为词干的一个规则是去掉结尾的 e 吗？让我们用一些以“e”结尾的单词来检验这个假设:</p><pre class="kp kq kr ks gt nw nx ny nz aw oa bi"><span id="a7ad" class="mw ln it nx b gy ob oc l od oe">normalise_text(['pie', 'globe', 'house', 'knee', 'angle', 'acetone', 'time', 'brownie', 'climate', 'independence'], pos='n')</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/354009df1c15d86b181d873c4230cc59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*OAeJXM-_qUeTY45VxubKQA.png"/></div></figure><p id="46c4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">不完全是，有些词干是以 e 结尾的。虽然这个假设不成立，但我想指出的是，词干提取有可观察到的趋势，因为它们是基于规则的。</p><p id="6aeb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果我让你建议一些规则来规范各种形式的动词，你会推荐什么？是去掉后缀“ing”还是“ed”？如果有两个辅音，前面有一个元音，那么你会把最后一个辅音也去掉吗？诸如此类…</p><p id="15bc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">虽然我不熟悉底层算法的复杂细节，但使用上述规则进行词干提取似乎是实际词干提取的过度简化版本，从计算和语言的角度来看，它将利用更加复杂和深思熟虑的规则。</p><p id="041f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，让我们来看看一些动词:</p><pre class="kp kq kr ks gt nw nx ny nz aw oa bi"><span id="e687" class="mw ln it nx b gy ob oc l od oe">normalise_text(['wrote', 'thinking', 'remembered', 'relies', 'ate', 'gone', 'won', 'ran', 'swimming', 'mistreated'], pos='v')</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/f8127642be1ecc39f3d9985550b76eaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*rkLZFHFpeJMLGsmJEmPijg.png"/></div></figure><p id="dd41" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">虽然“思考”和“游泳”在所有三个规格化器中以完全相同的方式规格化，但其他一些动词有不同的输出。例如，你有没有注意到 lemmatiser 如何将不规则动词如“ate”和“gone”进行了合理的转换，而 stemmers 却没有。我认为这是因为为这些少数例外情况定制规则很棘手。我希望到目前为止，这些简短的例子已经让您了解了词干分析器和词汇分析器是如何规范化单词的。</p></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><h1 id="d953" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">4.速度比较🐎</h1><p id="4692" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">在研究词干匹配和词干匹配时，我遇到了许多资源，这些资源声称词干匹配比词干匹配更快。然而，当我在我的计算机上对一个样本数据测试三个规格化器时，我观察到完全相反的情况:</p><pre class="kp kq kr ks gt nw nx ny nz aw oa bi"><span id="e84a" class="mw ln it nx b gy ob oc l od oe">from nltk.corpus import movie_reviews<br/>from nltk.tokenize import RegexpTokenizer</span><span id="17e2" class="mw ln it nx b gy of oc l od oe"># Import data<br/>reviews = []<br/>for fileid in movie_reviews.fileids():<br/>    tag, filename = fileid.split('/')<br/>    reviews.append((tag, movie_reviews.raw(fileid)))<br/>sample = pd.DataFrame(reviews, columns=['target', 'document'])</span><span id="3a5c" class="mw ln it nx b gy of oc l od oe"># Prepare one giant string <br/>sample_string = " ".join(sample['document'].values)</span><span id="b15b" class="mw ln it nx b gy of oc l od oe"># Tokenise data<br/>tokeniser = RegexpTokenizer(r'\w+')<br/>tokens = tokeniser.tokenize(sample_string)</span><span id="f318" class="mw ln it nx b gy of oc l od oe">%%timeit <br/>lemmatiser = WordNetLemmatizer()<br/>[lemmatiser.lemmatize(token, 'v') for token in tokens]</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/fa36208aba9440f93c2ef4c06ca381ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*T850o0ixXsM1bjwdVAPemg.png"/></div></figure><pre class="kp kq kr ks gt nw nx ny nz aw oa bi"><span id="eda7" class="mw ln it nx b gy ob oc l od oe">%%timeit <br/>porter = PorterStemmer()<br/>[porter.stem(token) for token in tokens]</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/4271e4aa8780f6ca69ed88f6f34d2a88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*jyujI5tXHBvcFNz4EF2lbg.png"/></div></figure><pre class="kp kq kr ks gt nw nx ny nz aw oa bi"><span id="81db" class="mw ln it nx b gy ob oc l od oe">%%timeit <br/>lancaster = LancasterStemmer()<br/>[lancaster.stem(token) for token in tokens]</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/7e2afb81f3e7e55df65208fe2ffbc971.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/1*2-I0KqSDa6yit2eEoCWe2g.png"/></div></figure><p id="5ad3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">正如你所看到的，从这个快速评估中，lemmatiser 实际上更快，甚至当我们用平均+/- 3 个标准差来比较一个范围时。因此，Lemmatiser 看起来更有利，因为它规范化得更合理，运行速度更快。在下一节中，我将分享两个有效的引理满足技巧作为奖励。</p><p id="4f6c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="mp">请注意，本帖中没有提到的其他词干分析器和词干分析器可能会给我们一个不同的故事。</em></p></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><h1 id="93f9" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">5.有效引理满足的两个技巧💡</h1><h2 id="2459" class="mw ln it bd lo mx my dn ls mz na dp lw kb nb nc ma kf nd ne me kj nf ng mi nh bi translated">5.1.词性标签💬</h2><p id="d4b2" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">如果您查看规范化示例名词和动词的代码片段，您会注意到两者之间的<code class="fe om on oo nx b">pos</code>参数有所不同。这个参数指的是一个单词的词性标签，它在单词如何被词汇化的过程中起着重要作用。词性标签向 lemmatiser 提供单词的<em class="mp">上下文</em>。让我们看一些例子:</p><pre class="kp kq kr ks gt nw nx ny nz aw oa bi"><span id="767c" class="mw ln it nx b gy ob oc l od oe">lemmatiser = WordNetLemmatizer()<br/>print(f"Lemmatising 'remembered' with pos='v' results in: {lemmatiser.lemmatize('remembered', 'v')}")<br/>print(f"Lemmatising 'remembered' with pos='n' results in: {lemmatiser.lemmatize('remembered', 'n')}\n")<br/>print(f"Lemmatising 'universities' with pos='v' results in: {lemmatiser.lemmatize('universities', 'v')}")<br/>print(f"Lemmatising 'universities' with pos='n' results in: {lemmatiser.lemmatize('universities', 'n')}")</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi op"><img src="../Images/49ea5994516e5c90e376b0c3a1928173.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*3BpYbJbd51yfe3l-aoRbkQ.png"/></div></figure><p id="0bc3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如您所见，为了有效地规范化带有<code class="fe om on oo nx b">WordNetLemmatizer</code>的单词，为每个单词提供正确的<code class="fe om on oo nx b">pos</code>参数是很重要的。</p><h2 id="0a88" class="mw ln it bd lo mx my dn ls mz na dp lw kb nb nc ma kf nd ne me kj nf ng mi nh bi translated">5.2.情况🔠 🔡</h2><p id="886b" class="pw-post-body-paragraph jq jr it js b jt mk jv jw jx ml jz ka kb mm kd ke kf mn kh ki kj mo kl km kn im bi translated">此外，单词的大小写也很重要:</p><pre class="kp kq kr ks gt nw nx ny nz aw oa bi"><span id="84b6" class="mw ln it nx b gy ob oc l od oe">print(f"Lemmatising 'Remembered' with pos='v' results in: {lemmatiser.lemmatize('Remembered', 'v')}")<br/>print(f"Lemmatising 'Remembered' with pos='n' results in: {lemmatiser.lemmatize('Remembered', 'n')}\n")<br/>print(f"Lemmatising 'Universities' with pos='v' results in: {lemmatiser.lemmatize('Universities', 'v')}")<br/>print(f"Lemmatising 'Universities' with pos='n' results in: {lemmatiser.lemmatize('Universities', 'n')}")</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/407125ded9309deca9489558dd724241.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/1*NaSuo71gxbQdCLkX0wfvnw.png"/></div></figure><p id="0a11" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">大写时，单词即使有正确的<code class="fe om on oo nx b">pos</code>也保持不变，因为它们被视为专有名词。💭</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi or"><img src="../Images/6b51fb668a92283ba29f2216ff65d461.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*cC3wzOJbWacQNo99"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">照片由<a class="ae le" href="https://unsplash.com/@patrickian4?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">帕特里克·福尔</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="4575" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="mp">您想访问更多这样的内容吗？媒体会员可以无限制地访问媒体上的任何文章。如果你使用</em> <a class="ae le" href="https://zluvsand.medium.com/membership" rel="noopener"> <em class="mp">我的推荐链接</em></a><em class="mp">成为会员，你的一部分会费会直接去支持我。</em></p></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><p id="16a9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">感谢您花时间阅读这篇文章。我希望你学到了一些关于引理满足和词干的知识。读完这篇文章后，如果你再翻一遍定义，你会觉得比第一次读的时候更有意义吗？👀其余帖子的链接整理如下:<br/> ◼️ <a class="ae le" href="https://medium.com/@zluvsand/introduction-to-nlp-part-1-preprocessing-text-in-python-8f007d44ca96" rel="noopener">第一部分:Python 中的文本预处理</a> <br/> ◼️ <strong class="js iu">第二部分:引理和词干化的区别</strong> <br/> ◼️ <a class="ae le" href="https://medium.com/@zluvsand/introduction-to-nlp-part-3-tf-idf-explained-cedb1fc1f7dc" rel="noopener">第三部分:TF-IDF 解释</a> <br/> ◼️ <a class="ae le" href="https://medium.com/@zluvsand/introduction-to-nlp-part-4-supervised-text-classification-model-in-python-96e9709b4267" rel="noopener">第四部分:Python 中的监督文本分类模型</a> <br/> ◼️ <strong class="js iu"> </strong> <a class="ae le" rel="noopener" target="_blank" href="/introduction-to-nlp-part-5a-unsupervised-topic-model-in-python-733f76b3dc2d">第五部分:Python 中的无监督主题模型(sklearn) </a> 【T29</p><p id="4a81" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">正常化快乐！再见🏃💨</p><h1 id="8cd5" class="lm ln it bd lo lp os lr ls lt ot lv lw lx ou lz ma mb ov md me mf ow mh mi mj bi translated">4.参考📁</h1><ul class=""><li id="74ae" class="ni nj it js b jt mk jx ml kb ox kf oy kj oz kn nn no np nq bi translated"><a class="ae le" href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html" rel="noopener ugc nofollow" target="_blank"> Christopher D. Manning，Prabhakar Raghavan 和 Hinrich Schütze，<em class="mp">信息检索导论</em>，剑桥大学出版社，2008 年</a></li><li id="ed32" class="ni nj it js b jt nr jx ns kb nt kf nu kj nv kn nn no np nq bi translated"><a class="ae le" href="http://www.nltk.org/book/" rel="noopener ugc nofollow" target="_blank">伯德、史蒂文、爱德华·洛珀和伊万·克莱恩，<em class="mp">用 Python 进行自然语言处理</em>。奥莱利媒体公司，2009 年</a></li><li id="5cc3" class="ni nj it js b jt nr jx ns kb nt kf nu kj nv kn nn no np nq bi translated">普林斯顿大学 WordNet。2010 年</li><li id="9855" class="ni nj it js b jt nr jx ns kb nt kf nu kj nv kn nn no np nq bi translated"><a class="ae le" href="https://www.nltk.org/api/nltk.stem.html" rel="noopener ugc nofollow" target="_blank"> <em class="mp">茎包</em>，nltk 文档</a></li></ul></div></div>    
</body>
</html>