<html>
<head>
<title>Building a Simple Neural Network from Scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从头开始构建一个简单的神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-simple-neural-network-from-scratch-a5c6b2eb0c34?source=collection_archive---------38-----------------------#2020-06-01">https://towardsdatascience.com/building-a-simple-neural-network-from-scratch-a5c6b2eb0c34?source=collection_archive---------38-----------------------#2020-06-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="60a2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">你有没有想过神经网络是如何工作的？它如何学习，如何扩展到我们输入的海量数据？</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6ed4d483d7ef2d9eae3fae0fe214c07a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UWJ52M5qNZp-38j11STT5g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(<a class="ae ky" href="https://res.mdpi.com/information/information-10-00113/article_deploy/html/images/information-10-00113-g003.png" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="8e20" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们将研究只有一个神经元的简单神经网络的工作原理，并了解它在我们的“Cat v/s Non Cat数据集”上的表现。</p><p id="de70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文结束时，您将能够-</p><ol class=""><li id="59c7" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">从头开始编写你自己的神经网络</li><li id="eee1" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">理解神经网络如何工作</li><li id="8d64" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">如何转换输入数据以输入神经网络</li></ol><h1 id="4edb" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">目标</h1><p id="5d47" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我们将对我们的神经网络进行编码，然后使用经过训练的网络来确定一幅图像中是否包含一只猫。这类问题被称为“二元分类问题”。它包括将输入分为两类，在我们的例子中是“Cat”或“Not cat”。</p><h1 id="f8e3" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">神经网络的基础</h1><h2 id="7bed" class="ng mk it bd ml nh ni dn mp nj nk dp mt li nl nm mv lm nn no mx lq np nq mz nr bi translated">线性回归方程</h2><p id="ce54" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">神经网络中的单个神经元作为直线工作，其具有以下等式:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/2f7100e3ef32ec853d8e0c457c637e83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h-buIpZS3uOugHUYVStjvw.jpeg"/></div></div></figure><p id="a0ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是神经网络的整个概念所基于的基本方程。让我们打破这个等式:</p><p id="5ac0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> y </strong>:因变量(神经网络的输出)</p><p id="160f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> m </strong>:直线的斜率</p><p id="5a28" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> x </strong>:独立变量(输入特征)</p><p id="c501" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> b </strong> : y轴截距</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/5b3445896b51ebb95d63177f17719fdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*bT1JZh7knPPxMTPXKst8zQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">绘制在图表上的线性方程(<a class="ae ky" href="https://research.aimultiple.com/how-neural-networks-work/" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="5999" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就神经网络而言，我们将斜率指定为权重，截距指定为偏差，输出(y)指定为z，因此等式变为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/78f453d8663005f1468f4aed635a66c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*61E5oJyCN2379Su_CQziIg.jpeg"/></div></div></figure><p id="6d5f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这里，我们只有一个特征，我们给模型。要输入多个特征，我们必须放大等式。</p><h2 id="b0e0" class="ng mk it bd ml nh ni dn mp nj nk dp mt li nl nm mv lm nn no mx lq np nq mz nr bi translated">扩展到多种功能</h2><p id="d40c" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">上述等式可以扩展到“n”个特征，可以写成:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/b1f0b99a9b522de0e16be3995a00f4e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2wGtQhys8EB0mKha1htnWw.jpeg"/></div></div></figure><p id="7a34" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这里，我们有“n”个输入特征提供给我们的模型。对应于每个输入特征，我们有一个权重，指定该特征对我们的模型预测输出有多重要。偏差项有助于在轴上移动我们的线，以更好地适应训练数据，否则线将始终穿过原点(0，0)。</p><h2 id="61eb" class="ng mk it bd ml nh ni dn mp nj nk dp mt li nl nm mv lm nn no mx lq np nq mz nr bi translated">同时做这件事</h2><p id="b90c" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我们可以利用矩阵将所有权重与输入相乘，并向它们添加偏差。这可以通过以下方式完成:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/54a6d3461177c2309720eda5b1f0f05e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N3HIak6upoMPedtAGu1IdA.jpeg"/></div></div></figure><p id="c4a8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，每一行代表一个训练示例(在我们的例子中是图像)，每一列代表一个像素数组。</p><p id="a11e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在python中，我们将使用<a class="ae ky" href="https://www.geeksforgeeks.org/vectorization-in-python/" rel="noopener ugc nofollow" target="_blank">矢量化</a>来实现上述概念。</p><blockquote class="nw nx ny"><p id="9ac8" class="kz la nz lb b lc ld ju le lf lg jx lh oa lj lk ll ob ln lo lp oc lr ls lt lu im bi translated">注意:在上面的等式中，我们使用“X.w+b ”,因为我们的输入矩阵是(mXn)的形状，其中“m”是样本的数量,“n”是特征的数量。</p></blockquote><p id="7e47" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">训练神经网络的目标是更新权重和偏差，以获得尽可能准确的预测。</p><h2 id="997a" class="ng mk it bd ml nh ni dn mp nj nk dp mt li nl nm mv lm nn no mx lq np nq mz nr bi translated">神经元</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/396362475b4e30369b31db77ef47adb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4TRCsDiZhROLg2FNXCqs4Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(<a class="ae ky" href="https://subscription.packtpub.com/book/big_data_and_business_intelligence/9781789344073/1/ch01lvl1sec12/the-mechanics-behind-anns" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="2ee4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">神经元是神经网络中的一个单元。它模拟了我们大脑中的神经元，将“树突”作为输入，“核”作为身体，“轴突”作为输出。每个神经元接受一些输入，对其进行处理，然后根据激活函数给出一个输出。</p><p id="b23e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你不能理解这些概念中的任何一个，请耐心听我说，一旦我们开始把事情放在一起，一切都会变得有意义。</p><h1 id="3f76" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">编码我们的神经网络</h1><p id="47ca" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">从创建阶段到获得预测，整个过程分为以下几个部分:</p><ol class=""><li id="0fda" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">准备输入到我们的网络</li><li id="9a77" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">初始化权重和偏差</li><li id="24d6" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">正向传播</li><li id="2d9f" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">计算损失</li><li id="e5f7" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">反向传播</li><li id="2668" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">更新权重和偏差</li><li id="79a2" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">多次重复上述过程(时期)</li><li id="c95b" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">获得预测</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/d4a21a3e51751c50b2b684cd872c8d2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*KNZZYteeBqkJViS1_LT1CQ.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(<a class="ae ky" href="https://www.mql5.com/en/blogs/post/724245" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><h2 id="3949" class="ng mk it bd ml nh ni dn mp nj nk dp mt li nl nm mv lm nn no mx lq np nq mz nr bi translated">准备输入</h2><p id="3a34" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我们的输入是“猫”和“不是猫”的图像集合。每个输入图像都是64x64像素大小的彩色图像。我们在训练数据集中总共有209幅图像，在测试数据集中有50幅图像。为了将这些图像输入到我们的神经网络中，这些图像必须被改造成像素向量。因此，每个图像将按行的顺序排列成一维向量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/69182792103350b29ff3d347f346282d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L3QGQ-yMy4SFdV_D0QKhLA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(<a class="ae ky" href="https://www.jeremyjordan.me/convolutional-neural-networks/" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="c7fb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最初，我们输入的形状是(209，64，64，3)，但现在转换后，它将变成(209，64x64x3)，即(209，12288)。现在这个“12288”是我们神经网络的输入数量，“209”是训练样本的数量。</p><p id="bbfa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的图像是8位的，所以图像中的每个像素都有一个在[0，255]范围内的值，即总共256个值的范围(2⁸=256).因此，我们必须通过将每个像素除以最大值(即255)来标准化我们的图像。</p><blockquote class="nw nx ny"><p id="bccd" class="kz la nz lb b lc ld ju le lf lg jx lh oa lj lk ll ob ln lo lp oc lr ls lt lu im bi translated">神经网络对输入尺度非常敏感。我们不希望我们的输入变化太大，否则较大的输入可能会支配较小的输入。因此，如果输入的范围很大，对其进行归一化总是一个好的做法。</p></blockquote><h2 id="4c6d" class="ng mk it bd ml nh ni dn mp nj nk dp mt li nl nm mv lm nn no mx lq np nq mz nr bi translated">初始化权重和偏差</h2><p id="a5a6" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我们必须将权重和偏差初始化为某个小值，以便能够开始训练过程。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="cc97" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这里，我们将权重乘以0.01，使其在整个训练过程中不会爆炸(变得非常大)。</p><p id="f6ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意:在代码中，‘b’只是一个‘浮点’数，因为python中的<a class="ae ky" href="https://www.geeksforgeeks.org/python-broadcasting-with-numpy-arrays/" rel="noopener ugc nofollow" target="_blank">广播</a>。它会自动将这个“浮点数”转换成所需的矢量形状。</p><p id="aa2f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们已经初始化了权重和偏差，让我们进入下一步。</p><h2 id="072a" class="ng mk it bd ml nh ni dn mp nj nk dp mt li nl nm mv lm nn no mx lq np nq mz nr bi translated">正向传播</h2><p id="4e60" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">这里，我们将使用上面建立的等式计算输出“z ”,然后在输出上使用激活函数。</p><p id="aa6e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在二元分类的情况下，我们将使用sigmoid激活函数，因为sigmoid函数通过将输入变换到[0，1]区间来给出输出。因此，我们可以通过将值设置为大于0.5比1和小于0.5比0来轻松找到目标类。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/f62f95254c6415894ed0d7127d5d82ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rCM7F7wrqnUDyqMd_Eem9A.jpeg"/></div></div></figure><p id="645e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">乙状结肠的公式是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/4a9be82e1e355a96db15ea47059efdac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rAFsEwlI1wCZaKhQ9xqQig.jpeg"/></div></div></figure><p id="22d5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在哪里，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/6625bcbb28f4a8bf67d6b5ac973e2e4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5z3y83OWLPCOXbmCqO0fXQ.jpeg"/></div></div></figure><p id="6b5a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看实现这两个步骤的代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="og oh l"/></div></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="b213" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们已经得到了神经元的输出，我们可以计算损失，看看我们的模型表现得有多好/差。</p><h2 id="40ee" class="ng mk it bd ml nh ni dn mp nj nk dp mt li nl nm mv lm nn no mx lq np nq mz nr bi translated">计算损失</h2><p id="b643" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">在二元分类中，使用的损失函数是<strong class="lb iu">二元交叉熵/对数损失。</strong>它由公式给出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/4b2ec7dd722f37929172be4b7dcf2c28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*prQqwVb_xhQYohqfG8LcNw.jpeg"/></div></div></figure><p id="618b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在哪里，</p><p id="f3f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> m </strong>:数据集中的样本总数</p><p id="e43f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">yᵢ</strong>:iᵗʰ样品的真实标签</p><p id="314f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">aᵢ</strong>:iᵗʰ样本的预测值</p><p id="e2d5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这可以在python中实现为:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="5fdc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个损失将告诉我们离预测正确的产量还有多远。如果损失为0，那么我们就有了一个完美的模型。但实际上，如果损失为0，那么我们的模型可能会过度拟合数据。</p><h2 id="478a" class="ng mk it bd ml nh ni dn mp nj nk dp mt li nl nm mv lm nn no mx lq np nq mz nr bi translated">反向传播</h2><p id="484a" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">这是奇迹发生的地方。在每次迭代中，基于模型输出和预期输出，我们计算梯度。梯度是我们需要改变多少权重和偏差来减少损失。</p><p id="bd5c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了计算梯度，我们使用以下公式:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/0dd8437b6961a2c976594f70883a7ebd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mALpHfjgBUgO5zMmjiHuFQ.jpeg"/></div></div></figure><p id="7731" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在python中，上述等式可以实现为:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="b301" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，“dw”和“db”包含我们需要分别调整权重和偏差的梯度。</p><h2 id="c1f4" class="ng mk it bd ml nh ni dn mp nj nk dp mt li nl nm mv lm nn no mx lq np nq mz nr bi translated">更新权重和偏差</h2><p id="6168" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我们现在需要用刚刚计算的梯度来调整权重和偏差。为此，使用以下等式:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/e15494e32b9e98107f24b06a0026a680.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cQcRGYrfb18SJBT6wkBm3g.jpeg"/></div></div></figure><p id="87de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中'<strong class="lb iu"> α' (alpha) </strong>是学习率，它定义了我们的更新应该有多大/多小。</p><p id="38e7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">更新参数的代码是:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="0d8a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们只需多次重复这些步骤来训练神经网络。</p><h2 id="c905" class="ng mk it bd ml nh ni dn mp nj nk dp mt li nl nm mv lm nn no mx lq np nq mz nr bi translated">训练神经网络</h2><p id="e508" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">为了训练神经网络，我们必须运行上述步骤一些时期(重复这些过程的次数)。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="64b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们的神经网络已经训练好了，我们可以预测新输入的输出。</p><h2 id="d20a" class="ng mk it bd ml nh ni dn mp nj nk dp mt li nl nm mv lm nn no mx lq np nq mz nr bi translated">获得预测</h2><p id="3ab9" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">为了从我们的神经网络获得预测，我们必须转换神经网络的输出‘a ’,使得小于0.5的输出值变成0，否则变成1。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/fc633570bd92b774c7037a68f676111d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZAN2LW4KsQIymFt5ZA3gEA.jpeg"/></div></div></figure><p id="a59c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然我们只有一个神经元，但我们仍然在训练数据上获得了96%的准确率，在测试数据上获得了76%的准确率，这还不错。</p><p id="d1bb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">恭喜你！我们刚刚从零开始制作了第一个神经网络。在下一篇文章中，我将告诉你如何开发一个浅层神经网络，它将有一个包含多个神经元的隐藏层。</p><p id="e922" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">你可以在Github上找到完整的代码:</strong></p><div class="ol om gp gr on oo"><a href="https://github.com/akarsh-saxena/Neural-Network-From-Scratch/tree/master/Artificial%20Neural%20Network/Simple%20Neural%20Network" rel="noopener  ugc nofollow" target="_blank"><div class="op ab fo"><div class="oq ab or cl cj os"><h2 class="bd iu gy z fp ot fr fs ou fu fw is bi translated">akarsh-sa xena/从头开始的神经网络</h2><div class="ov l"><h3 class="bd b gy z fp ot fr fs ou fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="ow l"><p class="bd b dl z fp ot fr fs ou fu fw dk translated">github.com</p></div></div><div class="ox l"><div class="oy l oz pa pb ox pc ks oo"/></div></div></a></div><p id="9659" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是从头开始创建和训练神经网络的整个过程。我希望你明白一切。不过，如果你还有什么不明白的，请在这里留言，我会尽力解答你的疑问。</p><p id="2f65" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">关注我在<a class="ae ky" href="https://bit.ly/AkarshSaxena" rel="noopener ugc nofollow" target="_blank"> Github </a>和<a class="ae ky" href="https://bit.ly/AkarshLinkedIn" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>了解更多信息。</p></div></div>    
</body>
</html>