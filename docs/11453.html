<html>
<head>
<title>Unsupervised Learning — Part 4</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">无监督学习—第 4 部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/unsupervised-learning-part-4-eeb4d3ab601?source=collection_archive---------24-----------------------#2020-08-08">https://towardsdatascience.com/unsupervised-learning-part-4-eeb4d3ab601?source=collection_archive---------24-----------------------#2020-08-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="78d9" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/fau-lecture-notes" rel="noopener" target="_blank"> FAU 讲座笔记</a>关于深度学习</h2><div class=""/><div class=""><h2 id="c654" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">条件和周期甘斯</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/022b5df60463db24bbe955079c1849ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Hm_VvrkaML8O_Ifm.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">FAU 大学的深度学习。下图<a class="ae lh" href="https://creativecommons.org/licenses/by/4.0/" rel="noopener ugc nofollow" target="_blank"> CC BY 4.0 </a>来自<a class="ae lh" href="https://www.youtube.com/watch?v=p-_Stl0t3kU&amp;list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&amp;index=1" rel="noopener ugc nofollow" target="_blank">深度学习讲座</a></p></figure><p id="2a33" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">这些是 FAU 的 YouTube 讲座</strong> <a class="ae lh" href="https://www.youtube.com/watch?v=p-_Stl0t3kU&amp;list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&amp;index=1" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd">深度学习</strong> </a> <strong class="lk jd">的讲义。这是讲座视频&amp;配套幻灯片的完整抄本。我们希望，你喜欢这个视频一样多。当然，这份抄本是用深度学习技术在很大程度上自动创建的，只进行了少量的手动修改。</strong> <a class="ae lh" href="http://autoblog.tf.fau.de/" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd">自己试试吧！如果您发现错误，请告诉我们！</strong></a></p><h1 id="69c9" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">航行</h1><p id="6486" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated"><a class="ae lh" rel="noopener" target="_blank" href="/unsupervised-learning-part-3-7b15038bb884"> <strong class="lk jd">上一讲</strong> </a> <strong class="lk jd"> / </strong> <a class="ae lh" href="https://youtu.be/K27a_doRoxw" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd">观看本视频</strong> </a> <strong class="lk jd"> / </strong> <a class="ae lh" rel="noopener" target="_blank" href="/all-you-want-to-know-about-deep-learning-8d68dcffc258"> <strong class="lk jd">顶级</strong> </a> <strong class="lk jd"> / </strong> <a class="ae lh" rel="noopener" target="_blank" href="/unsupervised-learning-part-5-f8809d7f1f90"> <strong class="lk jd">下一讲</strong> </a></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/e7b667bea2b6ec20bb4e472ca5ac01eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/0*MC1tqxSBtsGP0UDV.gif"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">需要你新专辑的封面吗？我能帮助你。使用<a class="ae lh" href="https://github.com/vvo/gifify" rel="noopener ugc nofollow" target="_blank"> gifify </a>创建的图像。来源:<a class="ae lh" href="https://youtu.be/RtPGIuAZpAo" rel="noopener ugc nofollow" target="_blank"> YouTube </a></p></figure><p id="ac6f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">欢迎回到深度学习！今天我们想讨论一些更高级的 GAN 概念，特别是条件 GAN 和循环 GAN。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/6d16579f66cd5224c52711d812840fdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*f9vv4yLUgfEgZxHT.jpg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">条件 gan 允许控制与某个变量相关的输出。<a class="ae lh" href="https://creativecommons.org/licenses/by/4.0/" rel="noopener ugc nofollow" target="_blank"> CC 下的图片来自<a class="ae lh" href="https://www.youtube.com/watch?v=p-_Stl0t3kU&amp;list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&amp;index=1" rel="noopener ugc nofollow" target="_blank">深度学习讲座</a>的 4.0 </a>。</p></figure><p id="5ca4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们来看看我幻灯片上的内容。这是我们无监督深度学习讲座的第四部分。首先，我们从条件句开始。到目前为止，我们遇到的一个问题是，生成器创建了一个假的通用图像。不幸的是，它不是针对某个条件或特征的。所以让我们说，如果你有文本到图像的生成，那么，当然，图像应该依赖于文本。因此，您需要能够以某种方式对依赖性进行建模。如果你想生成 0，那就不要生成 1。所以，你需要放入一些条件，你是否想要产生数字 0，1，2，3，等等。这可以通过[15]中介绍的编码条件来实现。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/1c751d12bda6796368ed18a300998db3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2SBYQeZTbLP9Zweu.jpg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">使用调节向量来控制 GAN。<a class="ae lh" href="https://creativecommons.org/licenses/by/4.0/" rel="noopener ugc nofollow" target="_blank"> CC 下的图片来自<a class="ae lh" href="https://www.youtube.com/watch?v=p-_Stl0t3kU&amp;list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&amp;index=1" rel="noopener ugc nofollow" target="_blank">深度学习讲座</a>的 4.0 </a>。</p></figure><p id="2956" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这里的想法是，你本质上把你的潜在向量，分成了本质上有观察的集合。然后，你还有条件，它被编码在条件向量<strong class="lk jd"> y </strong>中。你把两者连接起来，用它们来产生某种东西。此外，鉴别器然后获得生成的图像，但是它也获得对条件向量<strong class="lk jd"> y </strong>的访问。因此，它知道应该看到什么，以及生成器的具体输出。所以，他们两个都接受了条件，这实质上又导致了一个两人的极小极大博弈，这个博弈又可以被描述为一个依赖于鉴别者的损失。这里的延伸是，你另外有损失中的<strong class="lk jd"> y </strong>的条件。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/f9be37d9576082a6ed43cd0cf05e27be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JjmXqNtyQutIJhrT.jpg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">现在，我们可以控制面部表情。<a class="ae lh" href="https://creativecommons.org/licenses/by/4.0/" rel="noopener ugc nofollow" target="_blank"> CC 下的图片来自<a class="ae lh" href="https://www.youtube.com/watch?v=p-_Stl0t3kU&amp;list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&amp;index=1" rel="noopener ugc nofollow" target="_blank">深度学习讲座</a>的 4.0 </a>。</p></figure><p id="c39a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">那么这个东西是怎么工作的呢？您添加了一个条件特征，如微笑、性别、年龄或图像的其他属性。然后，发生器和鉴别器学习在这些模式下操作。这就产生了一个属性，你可以生成一个具有某种属性的面。鉴别器知道这是给定特定属性的脸。所以，在这里，你可以看到不同的生成人脸的例子。第一行是随机样本。第二行是老年人的财产。第三行给出的条件是老年加上微笑，这里你可以看到条件向量仍然能够产生类似的图像，但你实际上可以在上面添加这些条件。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/edfa934ad5f65c32d69066d32710b612.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/0*9PZw69ILZgDeCYtO.gif"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">因年老而变得健康的甘人。使用<a class="ae lh" href="https://github.com/vvo/gifify" rel="noopener ugc nofollow" target="_blank"> gifify </a>创建的图像。来源:<a class="ae lh" href="https://youtu.be/x3pdf9S60zo" rel="noopener ugc nofollow" target="_blank"> YouTube </a></p></figure><p id="8c73" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，这允许创建真正非常好的东西，如图像到图像的翻译。下面，你有几个输入和输出的例子。基本上，您可以为街道场景创建标签，可以为地图生成航拍图像，可以为立面生成标签，或者为彩色、白天和夜晚以及照片的边缘生成标签。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/ca4d3c90ea203e46662d4930eca6f8a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*5mL9o08aCDL5lKcg.jpg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">条件甘的应用还有很多。来自<a class="ae lh" href="https://www.youtube.com/watch?v=p-_Stl0t3kU&amp;list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&amp;index=1" rel="noopener ugc nofollow" target="_blank">深度学习讲座</a>的<a class="ae lh" href="https://creativecommons.org/licenses/by/4.0/" rel="noopener ugc nofollow" target="_blank"> CC BY 4.0 </a>下的图片。</p></figure><p id="198a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这里的想法是，我们再次使用标签图像作为条件向量。这使我们观察到这是领域翻译。简直是有条件的甘。给出了判别器的正例。下面的例子展示了一个手袋及其边缘。然后，通过将手提包的边缘交给生成器来创建一个愚弄鉴别者的手提包，来构造负样本。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/8932054ba65f012a322ad0895f8a40f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gk1wcCz70oYnBo3a.jpg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">从边缘到手提包的有条件的 GAN。<a class="ae lh" href="https://creativecommons.org/licenses/by/4.0/" rel="noopener ugc nofollow" target="_blank"> CC 下的图片来自<a class="ae lh" href="https://www.youtube.com/watch?v=p-_Stl0t3kU&amp;list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&amp;index=1" rel="noopener ugc nofollow" target="_blank">深度学习讲座</a>的 4.0 </a>。</p></figure><p id="5819" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">你可以看到，我们能够通过使用条件甘来生成非常复杂的图像。现在，这里的一个关键问题是，当然，你需要两个图像对齐。因此，你的调节图像，如这里的边缘图像，必须与相应的手提包图像完全匹配。如果他们没有，你就不能训练这个。因此，对于使用条件 gan 的域翻译，您需要精确匹配。在许多情况下，您无法获得精确匹配。假设你有一个展示斑马的场景。你可能找不到显示完全相同场景的配对数据集，但是有马。因此，您不能仅将它与有条件的 GAN 一起使用。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/432af9de014372ec484f1e688655d3df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*VdfewvnvXNUDdigl.jpg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">我们能把斑马和马联系起来吗？<a class="ae lh" href="https://creativecommons.org/licenses/by/4.0/" rel="noopener ugc nofollow" target="_blank"> CC 下的图片来自<a class="ae lh" href="https://www.youtube.com/watch?v=p-_Stl0t3kU&amp;list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&amp;index=1" rel="noopener ugc nofollow" target="_blank">深度学习讲座</a>的 4.0 </a>。</p></figure><p id="6995" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这里的关键因素是所谓的循环一致性损失。所以，你把 gan 和可训练的逆映射结合起来。这里的关键思想是，有一个条件 GAN 输入<strong class="lk jd"> x </strong>作为调理镜像，然后产生一些新的输出。如果你把这个新的输出用在 F 的条件变量中，它应该会再次产生<strong class="lk jd"> x </strong>。所以，你用条件变量来形成一个循环，这里的关键是，G 和 F 应该是彼此的倒数。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nc"><img src="../Images/3589a099a7a6ede74db8545766bfae99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nWMnQI8AHZcG-xHm.gif"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">循环一致性损失允许我们训练不成对的域翻译。<a class="ae lh" href="https://creativecommons.org/licenses/by/4.0/" rel="noopener ugc nofollow" target="_blank"> CC 下的图片来自<a class="ae lh" href="https://www.youtube.com/watch?v=p-_Stl0t3kU&amp;list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&amp;index=1" rel="noopener ugc nofollow" target="_blank">深度学习讲座</a>的 4.0 </a>。</p></figure><p id="4426" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">所以，如果你取 F(G( <strong class="lk jd"> x </strong>))，你应该再次以<strong class="lk jd"> x </strong>结束。当然，如果你取 G(F( <strong class="lk jd"> y </strong>)，那么你应该再次得到<strong class="lk jd"> y </strong>。这就产生了下面的概念:所以，你有两个生成器和两个鉴别器，一个从<strong class="lk jd"> x </strong>生成<strong class="lk jd"> y </strong>。一个 GAN F 正在从<strong class="lk jd"> y </strong>产生<strong class="lk jd"> x </strong>。你仍然需要两个鉴别器 Dₓ和 Dᵧ.循环 GAN 损耗进一步具有作为损耗的附加的一致性条件。当然，典型的鉴频器损耗是 Dₓ和 Dᵧ.的原始 GAN 损耗当然，它们分别与 G 和 f 耦合，在上面，你把这个循环一致性损失。循环一致性损失是一种耦合损失，它同时将<strong class="lk jd"> x </strong>转换为<strong class="lk jd"> y </strong>并将<strong class="lk jd"> y </strong>再次转换为<strong class="lk jd"> x </strong>，并确保在<strong class="lk jd"> y </strong>中生成的斑马纹仍然不会被鉴别器识别为假的。同时，你有逆循环一致性，然后使用 F 将<strong class="lk jd"> y </strong>转化为<strong class="lk jd"> x </strong>，然后再次使用 G 将<strong class="lk jd"> x </strong>转化为<strong class="lk jd"> y </strong>，同时愚弄关于<strong class="lk jd"> x </strong>的鉴别器。所以，你需要两个鉴别器。这就导致了循环一致性的丧失，我们已经在这里为你记下了。例如，你可以使用 L1 规范和那些 L1 规范的期望值来形成特定的恒等式。因此，总损耗等于我们之前讨论过的 GAN 损耗加上λ周期一致性损耗。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/5659874c2ae4ce1bae69f5b33eef0792.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UlmuTLi_fItQx2-X.jpg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">来自<a class="ae lh" href="https://www.youtube.com/watch?v=p-_Stl0t3kU&amp;list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&amp;index=1" rel="noopener ugc nofollow" target="_blank">深度学习讲座</a>的 4.0CC 下的 CycleGANs 图像示例。</p></figure><p id="fcee" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">所以，这个概念很容易理解，我可以告诉你这已经被广泛应用了。所以，有很多很多例子。你可以从莫奈翻译到照片，从斑马翻译到马，从夏天翻译到冬天，以及各自的逆运算。如果你再加上更多的 GANs 和更多的周期一致性损失，那么你甚至可以拍一张照片，把它翻译成莫奈、梵高和其他艺术家的作品，让他们代表一种特定的风格。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/a598fb014bdbd0093cdadad7e0046acc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*OpMbUeJLYMi9TeEz.jpg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">自行车 GANs 也在自动驾驶中得到应用。<a class="ae lh" href="https://creativecommons.org/licenses/by/4.0/" rel="noopener ugc nofollow" target="_blank"> CC 下的图片来自<a class="ae lh" href="https://www.youtube.com/watch?v=p-_Stl0t3kU&amp;list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&amp;index=1" rel="noopener ugc nofollow" target="_blank">深度学习讲座</a>的 4.0 </a>。</p></figure><p id="0104" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当然，这对于自动驾驶也很有意思，例如，您可以输入一个场景，然后生成不同的分段遮罩。所以，在这个任务中你也可以用它来进行图像分割。这里，我们对 GAN 周期进行了烧蚀研究，显示了单独的周期、单独的 GAN、GAN 加上正向损耗、GAN 加上反向损耗以及完整的 GAN 周期损耗。你可以看到，随着周期 GAN 的丢失，如果你把它与你各自的地面真相相比较，你会得到更好的来回翻译。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/90571a62e272ab847429123e2d5f4cd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-0UeI4iKDlXomoTp.jpg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">在这个深度学习讲座中，更多令人兴奋的事情即将到来。来自<a class="ae lh" href="https://www.youtube.com/watch?v=p-_Stl0t3kU&amp;list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj&amp;index=1" rel="noopener ugc nofollow" target="_blank">深度学习讲座</a>的<a class="ae lh" href="https://creativecommons.org/licenses/by/4.0/" rel="noopener ugc nofollow" target="_blank"> CC BY 4.0 </a>下的图片。</p></figure><p id="0145" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">好了，关于 GAN 还有几件事要说，这些是高级 GAN 概念，我们下次在深度学习中会谈到。所以，我希望你喜欢这个视频，并期待在下一个视频中见到你。再见！</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/7a966afcd3da41f20721811d783ba7e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/0*1xZGt1ckXmKZm9Qa.gif"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">循环甘斯使外科训练稍微更加现实。使用<a class="ae lh" href="https://github.com/vvo/gifify" rel="noopener ugc nofollow" target="_blank"> gifify </a>创建的图像。来源:<a class="ae lh" href="https://youtu.be/xWqP67y3u8Y" rel="noopener ugc nofollow" target="_blank"> YouTube </a></p></figure><p id="f681" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果你喜欢这篇文章，你可以在这里找到更多的文章，或者看看我们的讲座。如果你想在未来了解更多的文章、视频和研究，我也会很感激关注<a class="ae lh" href="https://www.youtube.com/c/AndreasMaierTV" rel="noopener ugc nofollow" target="_blank"> YouTube </a>、<a class="ae lh" href="https://twitter.com/maier_ak" rel="noopener ugc nofollow" target="_blank"> Twitter </a>、<a class="ae lh" href="https://www.facebook.com/andreas.maier.31337" rel="noopener ugc nofollow" target="_blank">脸书</a>或<a class="ae lh" href="https://www.linkedin.com/in/andreas-maier-a6870b1a6/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>。本文以<a class="ae lh" href="https://creativecommons.org/licenses/by/4.0/deed.de" rel="noopener ugc nofollow" target="_blank"> Creative Commons 4.0 归属许可</a>发布，如果引用，可以转载和修改。如果你有兴趣从视频讲座中获得文字记录，试试<a class="ae lh" href="http://autoblog.tf.fau.de/" rel="noopener ugc nofollow" target="_blank">自动博客</a>。</p><h1 id="7fb6" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">链接</h1><p id="7632" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated"><a class="ae lh" href="http://dpkingma.com/wordpress/wp-content/%20uploads/2015/12/talk_nips_workshop_2015.pdf" rel="noopener ugc nofollow" target="_blank">链接</a> —变分自动编码器:<br/> <a class="ae lh" href="https://www.youtube.com/watch?v=AJVyzd0rqdc" rel="noopener ugc nofollow" target="_blank">链接</a>—NIPS 2016 good fellow 的 GAN 教程<br/> <a class="ae lh" href="https://github.com/soumith/ganhacks" rel="noopener ugc nofollow" target="_blank">链接</a> —如何训练一个 GAN？让 GANs 发挥作用的技巧和诀窍(小心，而不是<br/>一切都是真的了！)<br/> <a class="ae lh" href="https://github.com/hindupuravinash/the-gan-zoo" rel="noopener ugc nofollow" target="_blank">链接</a>——有没有想过怎么给自己的甘起名？</p><h1 id="adc4" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">参考</h1><p id="cb4c" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">[1]陈曦，陈曦，闫端，等.“InfoGAN:基于信息最大化生成对抗网的可解释表征学习”.神经信息处理系统进展 29。柯伦咨询公司，2016 年，第 2172-2180 页。<br/> [2] Pascal Vincent，Hugo Larochelle，Isabelle Lajoie 等，“堆叠去噪自动编码器:用局部去噪标准学习深度网络中的有用表示”。《机器学习研究杂志》第 11 期。2010 年 12 月，第 3371-3408 页。<br/> [3] Emily L. Denton，Soumith Chintala，Arthur Szlam 等，“使用拉普拉斯金字塔对抗网络的深度生成图像模型”。载于:CoRR abs/1506.05751 (2015 年)。arXiv: 1506.05751。<br/> [4]理查德·杜达、彼得·e·哈特和大卫·g·斯托克。模式分类。第二版。纽约:Wiley-Interscience，2000 年 11 月。<br/> [5]阿斯嘉菲舍尔和克里斯蒂安伊格尔。“训练受限制的玻尔兹曼机器:介绍”。载于:模式识别 47.1 (2014)，第 25–39 页。<br/> [6]约翰·高迪尔。用于人脸生成的条件生成对抗网络。2015 年 3 月 17 日。网址:<a class="ae lh" href="http://www.foldl.me/2015/conditional-gans-face-generation/" rel="noopener ugc nofollow" target="_blank">http://www.foldl.me/2015/conditional-gans-face-generation/</a>(2018 年 1 月 22 日访问)。<br/>【7】伊恩·古德菲勒。NIPS 2016 教程:生成性对抗网络。2016.eprint: arXiv:1701.00160。<br/>【8】Martin HEU sel，Hubert Ramsauer，Thomas Unterthiner 等，“通过双时标更新规则训练的 GANs 收敛到局部纳什均衡”。神经信息处理系统进展 30。柯伦联合公司，2017 年，第 6626–6637 页。[9]杰弗里·E·辛顿和鲁斯兰·R·萨拉胡季诺夫。"用神经网络降低数据的维数."刊登在:科学 313.5786(2006 年 7 月)，第 504–507 页。arXiv: 20。<br/>【10】杰弗里·e·辛顿。“训练受限玻尔兹曼机器的实用指南”。神经网络:交易技巧:第二版。柏林，海德堡:施普林格柏林海德堡，2012 年，第 599-619 页。<br/> [11]菲利普·伊索拉，，周廷辉等，“条件对立网络下的意象翻译”。在:(2016 年)。eprint: arXiv:1611.07004。<br/> [12]迪耶德里克·P·金马和马克斯·韦林。“自动编码变分贝叶斯”。载于:arXiv 电子版，arXiv:1312.6114(2013 年 12 月)，arXiv:1312.6114。arXiv:1312.6114[统计。ML】。<br/> [13] Jonathan Masci、Ueli Meier、Dan Ciresan 等人，“用于分层特征提取的堆叠卷积自动编码器”。载于:人工神经网络和机器学习— ICANN 2011。柏林，海德堡:施普林格柏林海德堡，2011 年，第 52-59 页。<br/> [14]卢克·梅茨、本·普尔、大卫·普法乌等人，《展开的生成性敌对网络》。国际学习代表会议。2017 年 4 月。eprint: arXiv:1611.02163。<br/> [15]迈赫迪米尔扎和西蒙奥辛德罗。“条件生成对抗网”。载于:CoRR abs/1411.1784 (2014 年)。arXiv: 1411.1784。<br/> [16]亚历克·拉德福德、卢克·梅斯和索史密斯·钦塔拉。深度卷积生成对抗的无监督表示学习 2015。eprint: arXiv:1511.06434。<br/> [17] Tim Salimans，Ian Goodfellow，Wojciech Zaremba 等，“训练 GANs 的改进技术”。神经信息处理系统进展 29。柯伦咨询公司，2016 年，第 2234–2242 页。<br/>【18】吴恩达。“CS294A 课堂笔记”。2011 年。<br/>【19】张寒、徐涛、李洪生等，“StackGAN:利用堆叠生成式对抗网络进行文本到照片级真实感图像合成”。载于:CoRR abs/1612.03242 (2016 年)。arXiv: 1612.03242。<br/>【20】张寒、徐涛、李洪生等，“Stackgan:利用堆叠生成式对抗网络进行文本到照片级真实感图像合成”。载于:arXiv 预印本 arXiv:1612.03242 (2016)。<br/>【21】周，Aditya Khosla，Agata Lapedriza 等，“学习深度特征用于鉴别性定位”。In: 2016 年 IEEE 计算机视觉与模式识别大会(CVPR)。拉斯维加斯，2016 年 6 月，第 2921–2929 页。arXiv: 1512.04150。<br/> [22]朱俊彦，朴泰成，菲利普·伊索拉等，“利用循环一致的对立网络进行不成对的图像到图像的翻译”。载于:CoRR abs/1703.10593 (2017 年)。arXiv: 1703.10593。</p></div></div>    
</body>
</html>