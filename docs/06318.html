<html>
<head>
<title>Contradistinguisher for Unsupervised Domain Adaptation (CUDA) in a Nutshell</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">简而言之，用于无监督领域适应(CUDA)的对比识别器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/contradistinguisher-for-unsupervised-domain-adaptation-cuda-in-a-nutshell-68182572fbcd?source=collection_archive---------57-----------------------#2020-05-20">https://towardsdatascience.com/contradistinguisher-for-unsupervised-domain-adaptation-cuda-in-a-nutshell-68182572fbcd?source=collection_archive---------57-----------------------#2020-05-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f4db" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">一个处理各种域调整方法中涉及的域对齐的某些缺点的模型，同时给出了最新的结果。</h2></div><p id="6c87" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我们所知，在深度学习世界中，我们可能没有足够的监督数据来训练我们的模型。所以领域适应是一个非常有用的话题。我最近读了一篇<a class="ae lb" href="https://arxiv.org/abs/1909.03442" rel="noopener ugc nofollow" target="_blank">ICDM 19年的论文“无监督域适配的对比识别器”</a>，它提出了一种无监督域适配的直接方法，不需要域对齐。</p><p id="2f6a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这篇博客中，我将尝试简单地给出我对这篇论文的理解。该论文的作者还发布了该论文的一个<a class="ae lb" href="https://github.com/sobalgi/cuda" rel="noopener ugc nofollow" target="_blank">实现</a>。</p><h1 id="c730" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">领域适应</h1><p id="04e6" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">正如我们所知，在深度学习的世界中，我们可能没有足够的监督数据来训练我们的模型。但是可能存在另一组非常相似的数据(具有不同的分布)，对于这些数据，我们有足够数量的标记数据。在这种情况下，如果我们能够以某种方式将基于这些数据训练的模型用于我们的任务，那就太好了。为了了解我们正在讨论的内容，让我们讨论一个小例子:</p><p id="79ed" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">假设我们手里有一个情感分析任务，为了训练的目的，给我们一些带标签的书评。让我们看看其中的一篇书评。</p><blockquote class="lz ma mb"><p id="8a04" class="kf kg mc kh b ki kj jr kk kl km ju kn md kp kq kr me kt ku kv mf kx ky kz la ij bi translated"><strong class="kh ir">回顾-1: </strong>“这本书对其涵盖的主题有深入的概念构建材料。完全值得你花时间。”</p></blockquote><p id="2d0c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在假设我们要做情感分析任务，评论是关于家具的。让我们看看其中一个家具评论。</p><blockquote class="lz ma mb"><p id="b4c3" class="kf kg mc kh b ki kj jr kk kl km ju kn md kp kq kr me kt ku kv mf kx ky kz la ij bi translated">评论-2: “这件家具的边缘处理非常好，非常舒适。”</p></blockquote><p id="66eb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们在这里可以推断的是，没有家具评论会类似于评论-1，即，由于基础分布的差异，在书评上训练的情感分析引擎将与家具评论的不确定性一起工作。</p><p id="c8ba" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我们对视觉数据的分类任务中也可以看到另一个类似类型的例子，其中我们有同一物体的两个不同图像，但它们都来自不同的数据集(如图1所示)。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/eb7c78556d34012a1d94dbbb3770c012.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*wqGuSMppL7njAgRSXUWiPg.png"/></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图1:左边是一个电子商务网站上展示的一辆自行车的图像，右边是一个手机摄像头拍摄的自行车的图像。</p></figure><p id="0a5f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">回到我们之前的例子，假设我们没有标记家具评论，在这种情况下，如果我们可以以某种方式使用我们标记的书评数据集，这将是有用的。处理这些类型的域转移的子学科被称为<strong class="kh ir">域适配。</strong>在更进一步之前，我们需要了解域的含义。</p><p id="6af1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">任意一组数据的域</strong> (D)由其三个属性来表述:其输入特征空间(X)、标签空间(Y)及其底层联合概率分布。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/31d564833e3eb15bc481500baad3dd4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/1*Hwb_yEevD2OGI6UoYY2VvQ.png"/></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图2:一个域的表示</p></figure><h2 id="3ff0" class="mt ld iq bd le mu mv dn li mw mx dp lm ko my mz lo ks na nb lq kw nc nd ls ne bi translated">假设:</h2><p id="b7a7" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">域自适应由两个不同的域组成，即源域和目标域，具有共同的输入和输出空间，具有<em class="mc">域偏移。</em>域偏移是具有公共输入和输出特征空间的两个域的联合概率分布的差异。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi nf"><img src="../Images/b927672dc22032b17f9486484092a70f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E6R9b4UQPuLBtDI7JMHo_A.png"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图3:域转移</p></figure><h1 id="a02d" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">动机</h1><p id="fbad" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">领域适应方法的一般趋势是首先实现源和目标领域对准的中间目标，但是它有一些<em class="mc">缺点</em>。<em class="mc"> </em>大的<em class="mc">畴变</em>使畴变得更难对齐。另一个缺点是使用多分类器，这增加了模型的复杂性。域对齐有时会导致特定于域的信息丢失，因为在此过程中域正在被转换。</p><p id="1ff3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本文提出了一种方法，该方法跳过这个无关的中间比对步骤，并分别在源数据和目标数据上以监督和非监督的方式联合学习单个分类器。作者从Vapnik那里得到了一口气解决问题的灵感。</p><blockquote class="lz ma mb"><p id="5d93" class="kf kg mc kh b ki kj jr kk kl km ju kn md kp kq kr me kt ku kv mf kx ky kz la ij bi translated"><strong class="kh ir"> Vapnik的想法</strong>:任何想要的问题都应该用最直接的方式解决，而不是解决一个更一般的中间任务。</p></blockquote><p id="daa0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本文具体讨论了<strong class="kh ir">无监督</strong>版本的域自适应，其中训练数据包含已标记的源域实例和未标记的目标域实例。</p><blockquote class="lz ma mb"><p id="114d" class="kf kg mc kh b ki kj jr kk kl km ju kn md kp kq kr me kt ku kv mf kx ky kz la ij bi translated"><strong class="kh ir">目的:</strong>通过转移已标记源领域的知识，学习未标记目标领域的分类器。</p></blockquote><h1 id="cd28" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">对比识别器(CUDA)</h1><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi nk"><img src="../Images/7e061c71a42078eef7bcdb236db99226.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xbEBl5aNM494L264tGOQhw.png"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图4:两种域分布的公共决策边界。</p></figure><p id="5053" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该模型充当两种域分布的分类器。这种方法背后的基本思想是调整在源标记数据上学习的决策边界，使其遵循目标域先验。</p><p id="9eca" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们手里有两个发行版。可以使用监督学习来学习源分布。但是我们需要目标分布来建立目标领域分类器。为了调整在源分布上学习到的决策边界，我们试图提出目标联合分布，作为源分布的函数，加强目标域先验。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi nl"><img src="../Images/85cb6e93fa00a50ae1da2085e614deb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*891UTiiH-B-OYgMbVli-ow.png"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图5:包含目标无监督学习前后的决策边界。</p></figure><p id="2f9b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">CUDA模型包含一个编码器和一个同时使用三个数据集训练的分类器。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/3c220ab7f279e829ec997aea6d2e845f.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*ThKR00sFTBwRVdOUeQhVOA.gif"/></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图9:每个时期训练CUDA模型。</p></figure><h2 id="d36c" class="mt ld iq bd le mu mv dn li mw mx dp lm ko my mz lo ks na nb lq kw nc nd ls ne bi translated">寻找源联合分布</h2><p id="aed7" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">根据领域适应的定义，为了传递知识，使用源标记数据来训练模型。交叉熵损失用于学习用于最大化标签相对于它们各自的源实例的条件对数似然的参数。设源分布为P(θ)。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/73e7690427b59e82c4f63d7d59a4eb63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1380/format:webp/1*p4eqZggHooS43CMru58DzQ.png"/></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图6:关注从标记的源数据中学习。</p></figure><h2 id="dd6c" class="mt ld iq bd le mu mv dn li mw mx dp lm ko my mz lo ks na nb lq kw nc nd ls ne bi translated">设计目标联合分布</h2><p id="74a8" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">由于源域和目标域之间的唯一区别是其固有的联合概率分布，并且使用监督学习，我们获得了源域的联合概率之后的参数，我们的任务现在转移到获得目标域的联合分布上。</p><p id="7b1b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们知道，任何域的联合分布都满足给定的两个条件，即x[t]上的边际应给p(y[t])和y[t]上的边际应给p(x[t])。建议的目标分配也必须遵循这两个条件。由于对目标数据进行的学习只能在无人监督的情况下进行，作者巧妙地提出了目标联合分布，它:</p><ul class=""><li id="aec4" class="no np iq kh b ki kj kl km ko nq ks nr kw ns la nt nu nv nw bi translated">是P(θ)以及目标域先验的函数。</li><li id="4bc6" class="no np iq kh b ki nx kl ny ko nz ks oa kw ob la nt nu nv nw bi translated">遵循上述两个条件。</li><li id="aec3" class="no np iq kh b ki nx kl ny ko nz ks oa kw ob la nt nu nv nw bi translated">可以用来寻找最具对比性的特征。</li></ul><p id="0f29" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了获得最多的对比特征，所提出的联合分布被最大化。当最大化时，建议的分布实施两个属性。它试图增加一个实例被标记为一个类的概率，同时减少所有其他实例被标记为同一类的概率。这两个强制使contradistinguisher提取出唯一指定每个实例的特性集。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/46440568b016151bca91711c10128ad7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*__RSS46J6HsnP2p4-GV7xg.png"/></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图7:聚焦于根据未标记的目标数据进行调整。</p></figure><h2 id="17d9" class="mt ld iq bd le mu mv dn li mw mx dp lm ko my mz lo ks na nb lq kw nc nd ls ne bi translated"><strong class="ak">正规化</strong></h2><p id="9cc7" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">在训练期间使用伪标签时可能出现的一个问题是过拟合伪标签。为了解决这个问题，作者还包括了对抗性正则化，其目标是当模型引入一组不属于任何一类的假阴性样本时，包含不确定性。我们首先构建一组假阴性样本，并同时将它们标记到每个类别。在训练期间，模型将学习将不确定性包括到预测中，这在我们的情况下是一个有效的场景。</p><p id="08e3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这种方法类似于熵正则化，其中不是最小化真实目标样本的熵，而是最小化多类、多标签分类任务的二进制交叉熵损失。用于生成假样本的方法取决于所使用的域。该方法提出了两种类型的伪样本生成:</p><ol class=""><li id="4673" class="no np iq kh b ki kj kl km ko nq ks nr kw ns la od nu nv nw bi translated">对于语言类领域，使用高斯或均匀分布随机采样假样本。</li><li id="70ce" class="no np iq kh b ki nx kl ny ko nz ks oa kw ob la od nu nv nw bi translated">对于类似图像的域，使用生成器网络对伪样本进行采样，该生成器网络也在整体模型训练期间被训练。</li></ol><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/ed3854647cc4b6c3ac04dd111b02f70b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*wZkWPkB0vHZ7wsz7V3xeEg.png"/></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图8:专注于包含对抗性的正规化。</p></figure><p id="4be9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作者还提出了对多源域适应的进一步扩展，其中我们可以有多个源域和一个目标域。此处唯一需要的更改是源监督损失。来源监督损失现在将是所有单个来源监督损失的总和。</p><h1 id="65a8" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">结果</h1><p id="7cd5" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">作者对各种类型的数据做了详细的实验。本文给出了低分辨率和高分辨率可视化数据集上的结果，提出的模型给出了所有这些数据集上的最新结果。他们还尝试了语言数据集，在这里，模型也给出了最先进的结果。要详细了解所使用的数据集和与之对应的结果，可以看一下<a class="ae lb" href="https://arxiv.org/abs/1909.03442" rel="noopener ugc nofollow" target="_blank">论文</a>。</p><h1 id="d801" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">结论</h1><p id="ec3f" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">本文提出的联合学习对比鉴别器的方法在不牺牲效率的情况下解决了域对齐的缺点。该方法给出了各种测试场景的最新结果。它有可能成为领域适配领域的里程碑。</p></div></div>    
</body>
</html>