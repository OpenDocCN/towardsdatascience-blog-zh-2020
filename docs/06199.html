<html>
<head>
<title>What’s new in YOLOv4?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">YOLOv4有什么新功能？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/whats-new-in-yolov4-323364bb3ad3?source=collection_archive---------6-----------------------#2020-05-19">https://towardsdatascience.com/whats-new-in-yolov4-323364bb3ad3?source=collection_archive---------6-----------------------#2020-05-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a077" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">YOLO是一个实时物体识别系统，可以在一个帧中识别多个物体——而且它还变得更好了！</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/0ed4bf2c786c246a9361e6bcbf05da11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5_cg0ClDMJg1AQl4tRyYNQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">YOLO实时检测视频中的对象。</p></figure><h1 id="ab5c" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">什么是YOLO？</h1><p id="f1e5" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">YOLO是你只看一次的简称。这是一个实时对象识别系统，可以在单个帧中识别多个对象。YOLO识别物体比其他识别系统更准确、更快速。它可以预测多达9000个类，甚至看不见的类。实时识别系统将从图像中识别多个对象，并在对象周围创建边界框。它可以很容易地在生产系统中训练和部署。</p><p id="6102" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">这里有几个你可能感兴趣的链接:</strong></p><pre class="kj kk kl km gt mr ms mt mu aw mv bi"><span id="a134" class="mw kz it ms b gy mx my l mz na">- <a class="ae nb" href="https://trymito.io/" rel="noopener ugc nofollow" target="_blank">Complete your Python analyses 10x faster with Mito</a> [Product]</span><span id="cf78" class="mw kz it ms b gy nc my l mz na">- <a class="ae nb" href="https://aigents.co/skills" rel="noopener ugc nofollow" target="_blank">Free skill tests for Data Scientists &amp; ML Engineers</a> [Test]</span><span id="1e41" class="mw kz it ms b gy nc my l mz na">- <a class="ae nb" href="https://imp.i115008.net/c/2402645/1116216/11298" rel="noopener ugc nofollow" target="_blank">All New Self-Driving Car Engineer Nanodegree</a><strong class="ms iu"> </strong>[Course]</span></pre><p id="3897" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><em class="nd">你愿意多读一些这样的文章吗？如果是这样，你可以点击上面的任何链接来支持我。其中一些是附属链接，但你不需要购买任何东西。</em></p><h1 id="8adb" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">YOLO是如何工作的？</h1><p id="e7db" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">YOLO是基于一个单一的卷积神经网络(CNN)。CNN将图像划分成区域，然后预测每个区域的边界框和概率。它同时预测这些类别的多个边界框和概率。YOLO在训练和测试期间看到整个图像，因此它隐式地编码了关于类及其外观的上下文信息。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ne nf l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">YOLO v3对YOLO v4</p></figure><h1 id="70bd" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">谁开发了YOLO？</h1><p id="44e7" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">YOLO是由<a class="ae nb" href="https://pjreddie.com/" rel="noopener ugc nofollow" target="_blank">约瑟夫·雷德蒙</a>开发的。2016年推出的YOLO实时物体识别系统是物体识别研究的基石。这导致了更好更快的计算机视觉算法。</p><h1 id="785b" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">YOLOv4是谁开发的？</h1><p id="5e38" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">YOLO v4由阿列克谢·博奇科夫斯基、钱和廖宏远三位开发人员开发。</p><h1 id="eeec" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">为什么Joseph Redmon不开发YOLOv4？</h1><p id="951f" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">他放弃了开发YOLO v4，因为他的技术可能被滥用。他特别提到“军事应用和数据保护问题”。他停止了对计算机视觉的研究，因为他发现其中涉及的伦理问题“变得无法忽视”。</p><h1 id="193b" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">YOLOv4有什么新功能？</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/f44a2c955bb7d5a0816ff003c4934ed0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YECda3fRY0MpCG8NFX3heQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae nb" href="https://arxiv.org/pdf/2004.10934v1.pdf" rel="noopener ugc nofollow" target="_blank"> YOLOv4:物体检测的最佳速度和精度</a></p></figure><p id="e9a1" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">YOLOv4的架构由CSPDarknet53作为主干，空间金字塔池附加模块，PANet路径聚合颈和YOLOv3头组成。</p><p id="5a99" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">CSPDarknet53 是一种能够增强CNN学习能力的新型主干。在CSPDarknet53上添加了<a class="ae nb" href="https://arxiv.org/abs/1406.4729" rel="noopener ugc nofollow" target="_blank">空间金字塔池</a>块，以增加感受野并分离出最重要的上下文特征。PANet取代了YOLOv3中用于目标检测的特征金字塔网络(FPN ),用作不同检测器级别的参数聚合方法。</p><h1 id="b7d9" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">什么是成绩的提高？</h1><p id="cdfe" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">YOLOv4的速度是EfficientDet(竞争识别模型)的两倍，但性能相当。此外，AP(平均精度)和FPS(每秒帧数)相比YOLOv3分别提高了10%和12%。</p><h1 id="4a04" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">结论</h1><p id="0d71" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">YOLO是一种未来主义的识别器，具有更快的FPS，比现有的探测器更准确。该检测器可以在传统的GPU上训练和使用，这使得广泛采用成为可能。YOLOv4中的新功能提高了分类器和检测器的准确性，并可用于其他研究项目。</p><h1 id="8fc3" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">参考</h1><ul class=""><li id="f81b" class="nh ni it ls b lt lu lw lx lz nj md nk mh nl ml nm nn no np bi translated"><a class="ae nb" href="https://arxiv.org/pdf/2004.10934v1.pdf" rel="noopener ugc nofollow" target="_blank"> YOLOv4:物体检测的最佳速度和精度</a></li><li id="86ce" class="nh ni it ls b lt nq lw nr lz ns md nt mh nu ml nm nn no np bi translated">YOLO回来了！版本4拥有改进的速度和准确性</li><li id="e9bd" class="nh ni it ls b lt nq lw nr lz ns md nt mh nu ml nm nn no np bi translated"><a class="ae nb" href="https://syncedreview.com/2020/02/24/yolo-creator-says-he-stopped-cv-research-due-to-ethical-concerns/" rel="noopener ugc nofollow" target="_blank"> YOLO创始人Joseph Redmon因伦理问题停止了简历研究</a></li></ul><h1 id="da20" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">在你走之前</h1><p id="dea3" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">在<a class="ae nb" href="https://twitter.com/romanorac" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上关注我，在那里我定期<a class="ae nb" href="https://twitter.com/romanorac/status/1328952374447267843" rel="noopener ugc nofollow" target="_blank">发布关于数据科学和机器学习的</a>消息。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/b5d426b68cc5a21b1a35d0a157ebc4f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*69rP1pwjJi9mLSFE"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae nb" href="https://unsplash.com/@cmhedger?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Courtney hedge</a>在<a class="ae nb" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure></div></div>    
</body>
</html>