<html>
<head>
<title>Squats detector with OpenCV and Tensorflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 OpenCV 和 Tensorflow 的深蹲检测器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/squats-detector-with-opencv-and-tensorflow-ce934f19aeb9?source=collection_archive---------35-----------------------#2020-06-23">https://towardsdatascience.com/squats-detector-with-opencv-and-tensorflow-ce934f19aeb9?source=collection_archive---------35-----------------------#2020-06-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2a66" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">体育技术中的人工智能</h2></div><p id="1f24" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在隔离期间，我们的身体活动有限，这并不好，尤其是对孩子们来说。</p><p id="19c1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但当我让我的孩子锻炼时，我遇到了阻力，不得不全神贯注地控制整个过程。</p><p id="552c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这很有趣，而且我有了一个自动化这个过程的想法。虽然在这种情况下有点矫枉过正，但灵感却是不可抗拒的。</p><p id="13b3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">考虑到起点，我选择了蹲起。一个具有明确阶段和大幅度的基本动作看起来是最好的竞争者。</p><h2 id="d8fa" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">数据收集</h2><p id="5472" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">带相机的 Raspberry Pi 非常方便，可以轻松地将照片带回家。</p><p id="08df" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">OpenCV 获取图像并将它们写入文件系统。</p><h2 id="8c34" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">动作识别</h2><p id="e2ef" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">最初，我打算用图像分割在图片上找到一个人。但是分割是一个相当繁重的操作，尤其是在资源有限的情况下。</p><p id="6ef5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">此外，分割忽略了一个事实，我们有一系列的帧，而不是一个单一的图片。该序列具有明显的特征，我们需要使用它。</p><p id="d295" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以我继续使用 OpenCV 的<a class="ae mc" href="https://docs.opencv.org/master/de/de1/group__video__motion.html" rel="noopener ugc nofollow" target="_blank">背景去除算法</a>。将这种方法与一些试探法结合起来最终提供了一个可靠的结果。</p><h2 id="9ec9" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">背景减法</h2><p id="ec83" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">首先，创建一个背景减法器:</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="1fcc" class="le lf it mi b gy mm mn l mo mp">backSub = cv.createBackgroundSubtractorMOG2()</span></pre><p id="7f99" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">用框架来填充它:</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="f13e" class="le lf it mi b gy mm mn l mo mp">mask = backSub.apply(frame)</span></pre><p id="c64e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后得到一张有身体轮廓的图:</p><figure class="md me mf mg gt mr gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/27ca986c6ea2d2d8d94a16127682df4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*0eumhaA1ZwDGvpyB.jpeg"/></div></figure><p id="e622" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后放大图像以突出轮廓。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="2d9a" class="le lf it mi b gy mm mn l mo mp">mask = cv.dilate(mask, None, 3)</span></pre><p id="aea3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">将这种算法应用到所有的帧中会产生姿态遮罩。然后我们要把它们归类为站着，蹲着，或者什么都不做。</p><p id="b6af" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下一步是从图片上剪下一个图形。OpenCV 可以找到轮廓:</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="8e64" class="le lf it mi b gy mm mn l mo mp">cnts, _ = cv.findContours(img, cv.RETR_CCOMP, cv.CHAIN_APPROX_SIMPLE)</span></pre><p id="08d7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个想法是最大的轮廓或多或少符合身材。</p><p id="f662" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">不幸的是，结果是不稳定的，最大的轮廓可能只包裹身体，但错过了腿。</p><p id="6fa2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">无论如何，有一系列的图像很有帮助。蹲起发生在同一个地方，所以我们可以假设，所有的动作都在某个区域内进行，而这个区域是稳定的。</p><p id="7647" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，可以迭代地构建边界矩形，如果需要的话，随着最大轮廓而增加。</p><p id="8964" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有一个例子:</p><ul class=""><li id="5c98" class="mu mv it kk b kl km ko kp kr mw kv mx kz my ld mz na nb nc bi translated">最大的轮廓是红色的</li><li id="11ac" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated">包围矩形的轮廓是蓝色的</li><li id="e36e" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated">包围矩形的图形是绿色的</li></ul><figure class="md me mf mg gt mr gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/acfc9484d14e1347d44234f5a5bd9ec1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*jVH5XYTQCcTTc_48.jpeg"/></div></figure><p id="4005" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用这种方法，我们可以得到一个姿态进行进一步的处理。</p><h2 id="dc92" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">分类</h2><p id="3280" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">然后，从图像中剪切出包围矩形，制成正方形，并统一为 64×64 的大小。</p><p id="0b5e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">分类器输入有多个掩码:</p><p id="5ce1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于展台:</p><figure class="md me mf mg gt mr gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/d8256d5056b90006d864914057182ede.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/0*DrPvmp3-15nYWcV3.jpeg"/></div></figure><p id="4a73" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于深蹲:</p><figure class="md me mf mg gt mr gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/3690755fa0e73cff29592212ad825c85.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/0*wN6IV0MUMRbU-nNb.jpeg"/></div></figure><p id="4adf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我使用 Keras + Tensorflow 进行分类。</p><p id="f0b5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最初，我从经典的<a class="ae mc" href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf" rel="noopener ugc nofollow" target="_blank"> Lenet-5 型号</a>开始。它工作得很好，在读了<a class="ae mc" href="https://medium.com/@sh.tsang/paper-brief-review-of-lenet-1-lenet-4-lenet-5-boosted-lenet-4-image-classification-1f5f809dbf17" rel="noopener">一篇关于 Lenet-5 变体的文章</a>后，我决定尝试简化架构。</p><p id="0519" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">结果，一个非常简单的 CNN 显示了几乎相同的准确性:</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="a010" class="le lf it mi b gy mm mn l mo mp">model = Sequential([<br/>        Convolution2D(8,(5,5), activation='relu', input_shape=input_shape),<br/>        MaxPooling2D(),<br/>        Flatten(),<br/>        Dense(512, activation='relu'),<br/>        Dense(3, activation='softmax')<br/>      ])</span><span id="b16b" class="le lf it mi b gy nk mn l mo mp">model.compile(loss="categorical_crossentropy", optimizer=SGD(lr=0.01), metrics=["accuracy"])</span></pre><p id="ff93" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">10 个时期的准确率为 86%，20 个时期的准确率为 94%，30 个时期的准确率为 96%。<br/>长时间的训练可能会导致过度适应，所以是时候在现实生活中尝试这种模式了。</p><h2 id="17b7" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">树莓派</h2><p id="52d2" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">我是<a class="ae mc" href="https://docs.opencv.org/master/d2/d58/tutorial_table_of_content_dnn.html" rel="noopener ugc nofollow" target="_blank"> OpenCV-DNN 模块</a>的忠实粉丝，为了避免 Tensorflow 繁重的设置，我打算使用它。</p><p id="54df" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">不幸的是，当我将 Keras 模型转换为 TF 并在 Raspberry 上运行时:</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="7325" class="le lf it mi b gy mm mn l mo mp">cv2.error: OpenCV(4.2.0) C:\projects\opencv-python\opencv\modules\dnn\src\dnn.cpp:562: error: (-2:Unspecified error) Can't create layer "flatten_1/Shape" of type "Shape" in function 'cv::dnn::dnn4_v20191202::LayerData::getLayerInstance'</span></pre><p id="86c3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是一个关于堆栈溢出的已知问题，但是补丁还没有发布。</p><p id="af95" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以除了张量流别无选择。</p><p id="942a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Google 已经为 Raspberry 支持 TF 好几年了，所以没有任何技巧可以让它工作。</p><p id="52e4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">TF 包含适用于 Keras 型号的适配器，无需转换。</p><p id="dc89" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">加载模型:</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="ebc8" class="le lf it mi b gy mm mn l mo mp">with  open(MODEL_JSON, 'r') as f:<br/>  model_data = f.read()<br/>  model = tf.keras.models.model_from_json(model_data)<br/>  model.load_weights(MODEL_H5)<br/>  graph = tf.get_default_graph()</span></pre><p id="41f7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">并对蹲式面罩进行分类:</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="1d6c" class="le lf it mi b gy mm mn l mo mp">img = cv.imread(path + f, cv.IMREAD_GRAYSCALE)<br/>img = np.reshape(img,[1,64,64,1])<br/>with graph.as_default():<br/>  c = model.predict_classes(img)<br/>  return c[0] if c else None</span></pre><p id="df53" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在 Raspberry 上，输入为 64x64 的分类调用大约需要 60–70 毫秒，接近实时。</p><h2 id="a153" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">树莓 app</h2><p id="a556" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">将上述所有部分整合成一个<a class="ae mc" href="https://github.com/tprlab/squats/tree/master/rasp" rel="noopener ugc nofollow" target="_blank">单一应用</a>:</p><p id="5964" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们使用 Flask 创建一个具有以下条目的服务:</p><ul class=""><li id="184c" class="mu mv it kk b kl km ko kp kr mw kv mx kz my ld mz na nb nc bi translated"><strong class="kk iu">获取/ </strong> —一个应用程序页面(更多信息见下文)</li><li id="0659" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><strong class="kk iu">获取/状态</strong> —获取当前状态、深蹲和帧数</li><li id="370c" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><strong class="kk iu">发布/开始</strong> —开始一项练习</li><li id="f306" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><strong class="kk iu"> POST /stop </strong> —完成练习</li><li id="d7bf" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><strong class="kk iu">获取/传输</strong> —来自摄像机的视频流</li></ul><p id="fb08" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我在服务启动时初始化了 Tensorflow。这通常是一个坏主意，尤其是在 Raspberry 上——TF 将消耗大量资源，服务将响应缓慢，并可能在达到极限时死亡。</p><p id="b2b1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以通常我会在一个单独的进程中启动 TF，并为进程间通信提供一个通道，但是我为这个原型使用了一个简单的方法。</p><p id="637e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">已经有提到的网络应用程序来控制蹲起活动。该应用程序可以:</p><ul class=""><li id="caeb" class="mu mv it kk b kl km ko kp kr mw kv mx kz my ld mz na nb nc bi translated">显示来自摄像机的实时视频</li><li id="2033" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated">开始/停止练习</li><li id="0b1b" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated">计算深蹲和框架</li></ul><figure class="md me mf mg gt mr gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/d77547e5e7370cc29a702c84463829e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/0*JENx9ql3J1Xq1lF5.jpeg"/></div></figure><p id="75b2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当一个练习开始时，服务将图片写入文件系统。</p><p id="78e6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让它们训练神经网络是很方便的，但通常不需要它们。</p><p id="7e4a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该服务处理一系列图片，用 TF 对它们进行分类，当符合站立-蹲-站立模式时，蹲计数器增加。</p><h2 id="ed85" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">标签工具</h2><p id="600f" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">有一个简单的<a class="ae mc" href="https://github.com/tprlab/squats/tree/master/pretrain" rel="noopener ugc nofollow" target="_blank">贴标工具</a>用于人工分类。这是一个用 python + OpenCV 的 GUI 应用程序。</p><p id="1df9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该工具显示带有主要轮廓和边界矩形的图片，并需要键:S(站立)，Q(蹲下)，N(无)，然后自动将图片移动到目标子文件夹中。</p><p id="28a0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，应该将带标签的子文件夹复制到 Keras 模型输入文件夹中，并且需要重复训练过程。</p><h2 id="dc14" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">平台</h2><p id="7809" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">我在 Raspberry 上运行这个应用程序，但没有什么能阻止我使用任何带有 python、OpenCV 和摄像头的 Linux 环境。</p><h2 id="c68f" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">问题</h2><p id="595d" class="pw-post-body-paragraph ki kj it kk b kl lx ju kn ko ly jx kq kr lz kt ku kv ma kx ky kz mb lb lc ld im bi translated">事实上，它可以被接受为 MVP，但是还有很多需要改进的地方。</p><ul class=""><li id="51cf" class="mu mv it kk b kl km ko kp kr mw kv mx kz my ld mz na nb nc bi translated">细化背景去除。阴影会产生嘈杂的斑点，使分类器变得模糊不清。</li><li id="d5a7" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated">为神经网络收集更多数据。</li><li id="0e87" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated">回顾分类器架构。最简单的方法现在显示出令人满意的结果，但是有它自己的局限性。</li></ul><h2 id="79d8" class="le lf it bd lg lh li dn lj lk ll dp lm kr ln lo lp kv lq lr ls kz lt lu lv lw bi translated">链接</h2><ul class=""><li id="c24c" class="mu mv it kk b kl lx ko ly kr nm kv nn kz no ld mz na nb nc bi translated">【Yann LeCun 关于卷积网络的一篇原创文章。</li><li id="ae76" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><a class="ae mc" href="https://docs.opencv.org/master/de/de1/group__video__motion.html" rel="noopener ugc nofollow" target="_blank">OpenCV 中的背景去除</a>。</li><li id="9227" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi translated"><a class="ae mc" href="https://github.com/tprlab/squats" rel="noopener ugc nofollow" target="_blank">蹲点 GitHub 上的探测器源代码</a>。</li></ul></div></div>    
</body>
</html>