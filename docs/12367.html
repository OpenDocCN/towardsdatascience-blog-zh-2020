<html>
<head>
<title>Why is your Facebook Data so valuable? A method to predict humans traits through Facebook Likes.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么你的脸书数据如此有价值？一种通过脸书相似度预测人类特征的方法。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-is-your-facebook-data-so-valuable-a-method-to-predict-humans-traits-through-facebook-likes-e1ae036e80fb?source=collection_archive---------55-----------------------#2020-08-25">https://towardsdatascience.com/why-is-your-facebook-data-so-valuable-a-method-to-predict-humans-traits-through-facebook-likes-e1ae036e80fb?source=collection_archive---------55-----------------------#2020-08-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f9f5" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">为什么你的脸书数据如此有价值？一种通过脸书喜欢预测人类特征(性别，政治倾向，年龄)的方法。</h2></div><p id="e7e2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">随着选举时间的临近，我们将看到我们的脸书数据如何以及为什么对广告商和政治家如此有价值。脸书是世界上最大的社交网络平台，拥有超过 25 亿活跃用户。它以前所未有的规模处理数据，高度复杂的脸书人工智能算法以近乎人类的方式对数据进行筛选、分类和预测。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/50735190d7b5deaa79b1ee50d3886a19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ubfJu-nG2HbAD0wr"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated"><a class="ae lr" href="https://unsplash.com/photos/HUBofEFQ6CA" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/photos/HUBofEFQ6CA</a></p></figure><h1 id="bfc4" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">如何以及为什么</h1><p id="7444" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi mp translated"><span class="l mq mr ms bm mt mu mv mw mx di"> W </span> hy:由于大量数据和处理能力的涌入，我们将探索如何仅使用一组脸书喜欢的东西来预测人类特征。为了实现我们的结果，我们将尝试复制分析来自<a class="ae lr" href="https://en.wikipedia.org/wiki/Facebook%E2%80%93Cambridge_Analytica_data_scandal" rel="noopener ugc nofollow" target="_blank">剑桥分析数据丑闻</a>的数据的流行论文。(<a class="ae lr" href="https://www.pnas.org/content/110/15/5802" rel="noopener ugc nofollow" target="_blank">纸在这里</a>)</p><p id="4e27" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi mp translated"><span class="l mq mr ms bm mt mu mv mw mx di"> H </span> ow:为了建立一个预测模型，我们将利用<a class="ae lr" href="https://www.propublica.org/datastore/dataset/facebook-ad-categories" rel="noopener ugc nofollow" target="_blank">脸书广告类别数据集</a>。利用这一点，我们将尝试创建一个类似用户的稀疏矩阵，其中每个类别对应一个评级。(1 代表，用户喜欢的内容。0 代表，用户不喜欢的内容)</p><h1 id="66ce" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">要求</h1><ul class=""><li id="ccd9" class="my mz iq kh b ki mk kl ml ko na ks nb kw nc la nd ne nf ng bi translated">Python 3.8</li><li id="21dd" class="my mz iq kh b ki nh kl ni ko nj ks nk kw nl la nd ne nf ng bi translated">sci kit-学习</li><li id="d855" class="my mz iq kh b ki nh kl ni ko nj ks nk kw nl la nd ne nf ng bi translated">熊猫</li><li id="cd89" class="my mz iq kh b ki nh kl ni ko nj ks nk kw nl la nd ne nf ng bi translated">Numpy</li></ul><h1 id="e30e" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">资料组</h1><p id="01bd" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">像任何 ML/数据挖掘项目一样，我们将从分析和生成数据集开始。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nm"><img src="../Images/0c70dfcc9d41b48f596ca90d060012a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NXaYoSPD9jJrgwVdQI54ig.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">脸书广告类别数据集的预览。</p></figure><p id="edd8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如你所见，数据集非常广泛，因为它是众包的，这些条目是真实用户的。从数据集中可以明显看出，我们只需要<strong class="kh ir">“name”</strong>列。以此为起点，我们可以生成数据集的下一部分。</p><pre class="lc ld le lf gt nn no np nq aw nr bi"><span id="80b6" class="ns lt iq no b gy nt nu l nv nw">def generate_data(number_of_users=55000, cols=cols):</span><span id="720b" class="ns lt iq no b gy nx nu l nv nw">"""</span><span id="8433" class="ns lt iq no b gy nx nu l nv nw">Generates random data consisting of user's likes and dislikes</span><span id="85ec" class="ns lt iq no b gy nx nu l nv nw">Arguments:</span><span id="52dc" class="ns lt iq no b gy nx nu l nv nw">number_of_users: int</span><span id="a175" class="ns lt iq no b gy nx nu l nv nw">Returns:</span><span id="8613" class="ns lt iq no b gy nx nu l nv nw">DataFrame</span><span id="1974" class="ns lt iq no b gy nx nu l nv nw">"""</span><span id="9705" class="ns lt iq no b gy nx nu l nv nw">assert number_of_users &lt;= len(cols), "Number of users and cols should be less or equal."</span><span id="014f" class="ns lt iq no b gy nx nu l nv nw">index = ["User {}".format(i) for i in range(1, number_of_users+1)] # Number of user</span><span id="b896" class="ns lt iq no b gy nx nu l nv nw"># generic categories</span><span id="b87d" class="ns lt iq no b gy nx nu l nv nw">cols = cols.tolist()</span><span id="096d" class="ns lt iq no b gy nx nu l nv nw">data = {col: [] for col in cols}</span><span id="b16c" class="ns lt iq no b gy nx nu l nv nw"># random liking or disliking ( 1 or 0)</span><span id="f839" class="ns lt iq no b gy nx nu l nv nw">def like_or_not(): return random.randint(0,1)</span><span id="ab27" class="ns lt iq no b gy nx nu l nv nw">for col in cols:</span><span id="9209" class="ns lt iq no b gy nx nu l nv nw">#print("Adding for {}".format(col))</span><span id="e032" class="ns lt iq no b gy nx nu l nv nw">for i in range(1,number_of_users+1):</span><span id="f16e" class="ns lt iq no b gy nx nu l nv nw">data[col].append(like_or_not())</span><span id="a019" class="ns lt iq no b gy nx nu l nv nw">print("Data generation complete.")</span><span id="a8f4" class="ns lt iq no b gy nx nu l nv nw">return pd.DataFrame(data=data, index=index), index, cols</span></pre><p id="4f5b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了生成我们的数据，我们提取“name”列，并为每个用户随机分配 1 或 0。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/3ff723e8f6f768cc02fbc3f775157618.png" data-original-src="https://miro.medium.com/v2/resize:fit:846/format:webp/1*0jQmg4PSj3gS4kKJUXomAQ.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">like_or_not 函数</p></figure><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nz"><img src="../Images/03428d652c273a6d1dad37b7d72fe0d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CupF7kS1Bg3vjscujQogyw.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">用户数=5 时我们生成的数据集的预览</p></figure><h2 id="35eb" class="ns lt iq bd lu oa ob dn ly oc od dp mc ko oe of me ks og oh mg kw oi oj mi ok bi translated">目标变量</h2><p id="6edb" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi mp translated"><span class="l mq mr ms bm mt mu mv mw mx di">到</span>添加我们的目标变量，我们将关注“年龄”、“性别”和“政治”。这些是我们希望通过收集每个用户的脸书喜好来预测的变量。</p><pre class="lc ld le lf gt nn no np nq aw nr bi"><span id="0261" class="ns lt iq no b gy nt nu l nv nw">def generate_target_variables(number_of_users=55000,target=['age', 'gender', 'political']):<br/>  # for each target we will generate random data<br/>  data = {"age":[], "gender":[], "political":[]}</span><span id="5bf3" class="ns lt iq no b gy nx nu l nv nw"># for age (age ranged: 18 to 75)<br/>  # regression<br/>  data['age'] = [random.randint(18, 75) for x in range(1, number_of_users+1)]</span><span id="0229" class="ns lt iq no b gy nx nu l nv nw"># for gender (m or f) ( 1 or 0)<br/>  # classification <br/>  data['gender'] = [random.randint(0,1) for x in range(1, number_of_users+1)]</span><span id="1d97" class="ns lt iq no b gy nx nu l nv nw"># for political<br/>  # classification (1 -&gt; democratic, 0 -&gt; republican)<br/>  data['political'] = [random.randint(0,1) for x in range(1, number_of_users+1)]</span><span id="d350" class="ns lt iq no b gy nx nu l nv nw">return data</span><span id="c2f4" class="ns lt iq no b gy nx nu l nv nw"># adding target variables<br/>data['age'] = target['age']<br/>data['gender'] = target['gender']<br/>data['political'] = target['political']</span></pre><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/4ed4fccc6938e608dabc34ce9677fb58.png" data-original-src="https://miro.medium.com/v2/resize:fit:442/format:webp/1*4UDc7lx2tg1-1syAc8x4Rg.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">数据集中的目标变量</p></figure><h1 id="432f" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">降维</h1><p id="aa66" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi mp translated"><span class="l mq mr ms bm mt mu mv mw mx di">由于</span>我们的数据集包含约 52000+个产品的广告类别，我们将使用奇异值分解进行降维。(论文中也有提及)</p><p id="5ddd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于那些不记得奇异值分解或主成分分析的人，我们将简要概述这一过程。</p><blockquote class="om"><p id="6a89" class="on oo iq bd op oq or os ot ou ov la dk translated"><a class="ae lr" href="https://en.wikipedia.org/wiki/Dimensionality_reduction" rel="noopener ugc nofollow" target="_blank">降维</a>，或称降维，是将数据从高维空间转换到低维空间，使低维表示保留原始数据的一些有意义的属性，理想情况下接近其固有维度。</p></blockquote><p id="c0ff" class="pw-post-body-paragraph kf kg iq kh b ki ow jr kk kl ox ju kn ko oy kq kr ks oz ku kv kw pa ky kz la ij bi mp translated"><span class="l mq mr ms bm mt mu mv mw mx di"> F </span>或 SVD，我们本质上使用<strong class="kh ir">公式</strong>来转换数据:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/9b4c2a3488fcaf90f24cb94c7d29134e.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/format:webp/0*KBPNDVasIhK-BMz8.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated"><a class="ae lr" href="https://en.wikipedia.org/wiki/Singular_value_decomposition" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Singular_value_decomposition</a></p></figure><blockquote class="pc pd pe"><p id="a59e" class="kf kg pf kh b ki kj jr kk kl km ju kn pg kp kq kr ph kt ku kv pi kx ky kz la ij bi translated">为了执行我们的降维，我们将使用<a class="ae lr" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html" rel="noopener ugc nofollow" target="_blank"> sklearn TruncatedSVD </a>类，其中 n_components=100(根据论文。)</p></blockquote><pre class="lc ld le lf gt nn no np nq aw nr bi"><span id="bc02" class="ns lt iq no b gy nt nu l nv nw">def dimen_reduce(values):<br/>    <br/>    reduced = TruncatedSVD(n_components=100)<br/>    tr = reduced.fit_transform(values)<br/>    return tr</span></pre><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi pj"><img src="../Images/a81b194050d3de5898e87fce6ed38d54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3xrDy9VdlhK5klMTc1A0ow.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">在执行 dimen_reduce 时，我们得到了这个转换后的数据帧</p></figure><pre class="lc ld le lf gt nn no np nq aw nr bi"><span id="dc8f" class="ns lt iq no b gy nt nu l nv nw">def generated_reduced_df(df, index, number_of_users=55000):</span><span id="4c5f" class="ns lt iq no b gy nx nu l nv nw">tr = dimen_reduce(df.values)</span><span id="942c" class="ns lt iq no b gy nx nu l nv nw"># 100 components</span><span id="9f1c" class="ns lt iq no b gy nx nu l nv nw">dimen_df = pd.DataFrame(data=tr, index=index)</span><span id="4002" class="ns lt iq no b gy nx nu l nv nw">target = generate_target_variables(len(dimen_df))</span><span id="8e4e" class="ns lt iq no b gy nx nu l nv nw">dimen_df['age'] = target['age']</span><span id="547b" class="ns lt iq no b gy nx nu l nv nw">dimen_df['gender'] = target['gender']</span><span id="15e8" class="ns lt iq no b gy nx nu l nv nw">dimen_df['political'] = target['political']</span><span id="25be" class="ns lt iq no b gy nx nu l nv nw">return dimen_df</span></pre><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi pk"><img src="../Images/4dd91763d7de7a925c9998da49627661.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*02HovBaA1srcbVta7NpOIg.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">我们最终的数据集</p></figure><h1 id="b4bf" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">培养</h1><p id="b4ba" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi mp translated"><span class="l mq mr ms bm mt mu mv mw mx di">如</span>根据本文，我们用线性回归训练年龄目标变量，用逻辑回归(分类)训练其他参数。</p><blockquote class="om"><p id="ef6c" class="on oo iq bd op oq or os ot ou ov la dk translated">论文提到了许多参数，但是由于计算的限制，我们只预测了三个变量(年龄、性别、政治)。</p></blockquote><pre class="pl pm pn po pp nn no np nq aw nr bi"><span id="53f9" class="ns lt iq no b gy nt nu l nv nw">def split_dataset(df,test_size=0.2, stype="linear"):</span><span id="9d44" class="ns lt iq no b gy nx nu l nv nw">features_age, labels_age = df.drop(columns=['age']).values, df['age'].values</span><span id="66b4" class="ns lt iq no b gy nx nu l nv nw">features_gender, labels_gender = df.drop(columns=['gender']).values, df['gender'].values</span><span id="8d11" class="ns lt iq no b gy nx nu l nv nw">features_political, labels_political = df.drop(columns=['political']).values, df['political'].values</span><span id="7363" class="ns lt iq no b gy nx nu l nv nw">if stype == 'linear':</span><span id="0337" class="ns lt iq no b gy nx nu l nv nw">x_train, x_test, y_train, y_test = train_test_split(features_age, labels_age, random_state=42, test_size=test_size)</span><span id="b1fa" class="ns lt iq no b gy nx nu l nv nw">return x_train, x_test, y_train, y_test</span><span id="5617" class="ns lt iq no b gy nx nu l nv nw">if stype == 'clas_gender':</span><span id="880a" class="ns lt iq no b gy nx nu l nv nw">x_train, x_test, y_train, y_test = train_test_split(features_gender, labels_gender, random_state=42, test_size=test_size)</span><span id="1e12" class="ns lt iq no b gy nx nu l nv nw">return x_train, x_test, y_train, y_test</span><span id="8740" class="ns lt iq no b gy nx nu l nv nw">if stype == 'clas_pol':</span><span id="3601" class="ns lt iq no b gy nx nu l nv nw">x_train, x_test, y_train, y_test = train_test_split(features_political, labels_political, random_state=42, test_size=test_size)</span><span id="bb10" class="ns lt iq no b gy nx nu l nv nw">return x_train, x_test, y_train, y_test</span></pre><blockquote class="om"><p id="9273" class="on oo iq bd op oq pq pr ps pt pu la dk translated">由于性别和政治目标变量是 1 和 0 的形式，我们使用 LogisticRegression 来训练我们的模型。我们使用线性回归以年龄作为目标变量来训练我们的模型。</p></blockquote><p id="fbe0" class="pw-post-body-paragraph kf kg iq kh b ki ow jr kk kl ox ju kn ko oy kq kr ks oz ku kv kw pa ky kz la ij bi mp translated"><span class="l mq mr ms bm mt mu mv mw mx di">答</span>根据论文，我们根据奇异值分解对 100 个成分进行 10 重交叉验证。</p><pre class="lc ld le lf gt nn no np nq aw nr bi"><span id="03d2" class="ns lt iq no b gy nt nu l nv nw"># age<br/>cross_val_score(linear_reg, x_train_linear, y_train_linear, cv=10)<br/>cross_val_score(linear_reg, x_train_linear, y_train_linear, cv=10)</span><span id="f2ad" class="ns lt iq no b gy nx nu l nv nw"># gender and political<br/>cross_val_score(log_reg, x_train_gender, y_train_gender, cv=10)<br/>cross_val_score(log_reg, x_train_pol, y_train_pol, cv=10)</span></pre><h1 id="66d7" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论</h1><p id="20bf" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi mp translated"><span class="l mq mr ms bm mt mu mv mw mx di">到</span>总结，我们看到脸书的喜好是如何影响或预测重要的人类特质的。有了足够的数据(n=55000)，我们可以获得可接受的准确度作为测量的 ROC。随着数据的涌入，我们可以看到，如果组织能够访问脸书的数据，那么锁定特定人群是多么容易。</p><h1 id="e502" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">参考</h1><p id="9bde" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated"><strong class="kh ir">【1】</strong>【https://www.pnas.org/content/pnas/110/15/5802.full.pdf】T21</p><h1 id="75cb" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">链接</h1><p id="e231" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">[1]Github:<a class="ae lr" href="https://github.com/aaditkapoor/Facebook-Likes-Model" rel="noopener ugc nofollow" target="_blank">https://github.com/aaditkapoor/Facebook-Likes-Model</a></p><p id="d2ee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[2]Colab:<a class="ae lr" href="https://colab.research.google.com/drive/1k75ODwkhEnXirVDKzyyBImPqNGISqjs6?usp=sharing" rel="noopener ugc nofollow" target="_blank">https://Colab . research . Google . com/drive/1k 75 odwkhenxirvdkzyybimpqngisjs 6？usp =共享</a></p></div></div>    
</body>
</html>