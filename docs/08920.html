<html>
<head>
<title>Multi Label Classification using Bag-of-Words (BoW) and TF-IDF</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用词袋和 TF-IDF 的多标签分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/multi-label-classification-using-bag-of-words-bow-and-tf-idf-4f95858740e5?source=collection_archive---------13-----------------------#2020-06-27">https://towardsdatascience.com/multi-label-classification-using-bag-of-words-bow-and-tf-idf-4f95858740e5?source=collection_archive---------13-----------------------#2020-06-27</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="9c40" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">该项目遵循传统技术，如单词袋和 tf-idf，以数字格式表示语料库中的单词，用于多标签分类。</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj kj"><img src="../Images/7b0a67d7a3b14fbe882700729e8ec663.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*97iJ_XwezR6XD_1WY6VNng.png"/></div><p class="kr ks gk gi gj kt ku bd b be z dk translated">Wordcloud 摘录自 Jigsaw 有毒评论。<em class="kv">免责声明:该数据集包含被视为亵渎、粗俗或冒犯的文本。文章最后给出了构建这个词云的代码。</em></p></figure><h1 id="9c33" class="kw kx iu bd ky kz la lb lc ld le lf lg ka lh kb li kd lj ke lk kg ll kh lm ln bi translated">1.加载数据</h1><p id="f294" class="pw-post-body-paragraph lo lp iu lq b lr ls jv lt lu lv jy lw lx ly lz ma mb mc md me mf mg mh mi mj in bi translated">在这项研究中，我们使用 Kaggle 数据进行<a class="ae mk" href="https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data" rel="noopener ugc nofollow" target="_blank">有毒评论分类挑战</a>。让我们加载并检查数据。这是一个多标签分类问题，其中注释按照毒性级别进行分类:<code class="fe ml mm mn mo b">toxic / severe_toxic / obscene / threat / insult / identity_hate</code></p><pre class="kk kl km kn gu mp mo mq mr aw ms bi"><span id="6b88" class="mt kx iu mo b gz mu mv l mw mx">import pandas as pd<br/>data = pd.read_csv('train.csv')<br/>print('Shape of the data: ', data.shape)<br/>data.head()</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gi gj my"><img src="../Images/418dc487ebe3b14f945832be9049612a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D5D-iuqP7N92qIS5Risd8w.png"/></div></div><p class="kr ks gk gi gj kt ku bd b be z dk translated">数据集的快照</p></figure><pre class="kk kl km kn gu mp mo mq mr aw ms bi"><span id="b03f" class="mt kx iu mo b gz mu mv l mw mx">y_cols = list(data.columns[2:])<br/>is_multilabel = (data[y_cols].sum(axis=1) &gt;1).count()<br/>print('is_multilabel count: ', is_multilabel)</span></pre><ul class=""><li id="4ec5" class="nd ne iu lq b lr nf lu ng lx nh mb ni mf nj mj nk nl nm nn bi translated">从上面的数据可以观察到，并不是所有的评论都有标签。</li><li id="bf8e" class="nd ne iu lq b lr no lu np lx nq mb nr mf ns mj nk nl nm nn bi translated">其次，它是多标签数据，意味着每个评论可以有一个或多个标签。</li></ul><p id="ae52" class="pw-post-body-paragraph lo lp iu lq b lr nf jv lt lu ng jy lw lx nt lz ma mb nu md me mf nv mh mi mj in bi translated">首先，让我们为没有标签的评论添加一个标签“无毒”。此外，探索如何平衡的类。</p><pre class="kk kl km kn gu mp mo mq mr aw ms bi"><span id="d34a" class="mt kx iu mo b gz mu mv l mw mx"># Add a label, ‘non_toxic’ for comments with no label<br/>data['non_toxic'] = 1-data[y_cols].max(axis=1)<br/>y_cols += ['non_toxic']</span><span id="2a09" class="mt kx iu mo b gz nw mv l mw mx"># Inspect the class balance<br/>def get_class_weight(data):<br/>    class_weight = {}<br/>    for num,col in enumerate(y_cols):<br/>        if num not in class_weight:<br/>            class_weight[col] = round((data[data[col] == 1][col].sum())/data.shape[0]*100,2)<br/>    return class_weight<br/>class_weight = get_class_weight(data)</span><span id="7765" class="mt kx iu mo b gz nw mv l mw mx">print('Total class weight: ', sum(class_weight.values()), '%\n\n', class_weight)</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gi gj nx"><img src="../Images/927d6f1b0d9da6db61000ad3ccaff382.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*23uPZSbEy66wUgLuCmjXXA.png"/></div></div></figure><p id="91d9" class="pw-post-body-paragraph lo lp iu lq b lr nf jv lt lu ng jy lw lx nt lz ma mb nu md me mf nv mh mi mj in bi translated">我们可以看到数据是高度不平衡的。不平衡数据指的是分类问题，例如，89%的评论被归类到新建的“无毒”标签下。</p><p id="e3c5" class="pw-post-body-paragraph lo lp iu lq b lr nf jv lt lu ng jy lw lx nt lz ma mb nu md me mf nv mh mi mj in bi translated">任何给定的线性模型如果使用平方损失进行二进制分类，将会非常糟糕地处理类别不平衡。在这个项目中，我们将不讨论解决不平衡问题的技术。如果你想了解更多关于处理不平衡数据的知识，请参考<a class="ae mk" href="https://pub.towardsai.net/imbalanced-data-real-time-bidding-6ee9c4ef957c" rel="noopener ugc nofollow" target="_blank">这篇</a>博客。</p><p id="acf2" class="pw-post-body-paragraph lo lp iu lq b lr nf jv lt lu ng jy lw lx nt lz ma mb nu md me mf nv mh mi mj in bi translated">让我们在使用 BoW(单词包)和 tf-idf(术语频率和逆文档频率)将文本数据转换为数字数据之前，重点关注预处理。</p><h2 id="7132" class="mt kx iu bd ky ny nz dn lc oa ob dp lg lx oc od li mb oe of lk mf og oh lm oi bi translated">2.将数据集分为训练、验证和测试</h2><pre class="kk kl km kn gu mp mo mq mr aw ms bi"><span id="327d" class="mt kx iu mo b gz mu mv l mw mx">from sklearn.model_selection import train_test_split</span><span id="e813" class="mt kx iu mo b gz nw mv l mw mx">X, X_test, y, y_test = train_test_split(X_data, y_data, test_size=0.2, train_size=0.8)<br/>X_train, X_val, y_train, y_val = train_test_split(X,y,test_size = 0.25,train_size =0.75)</span><span id="4eb7" class="mt kx iu mo b gz nw mv l mw mx">X_train[:1]</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gi gj oj"><img src="../Images/9adb53b73ee4fadddb13f34c2c9be725.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jLuAafQFvY-ZTTsJSaUOaA.png"/></div></div></figure><p id="e6cd" class="pw-post-body-paragraph lo lp iu lq b lr nf jv lt lu ng jy lw lx nt lz ma mb nu md me mf nv mh mi mj in bi translated">让我们仔细看看其中一条评论。请注意，由于数据集是随机分割的，因此文本会因您而异。如果你的目标是复制结果，请在分割中使用种子。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gi gj ok"><img src="../Images/53a66c43b08d1a4b4b6edb0bac88fe80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1si0_4WAoM3WNJRJ05Ulug.png"/></div></div></figure><h1 id="0208" class="kw kx iu bd ky kz la lb lc ld le lf lg ka lh kb li kd lj ke lk kg ll kh lm ln bi translated">3.预处理文本</h1><p id="2cf4" class="pw-post-body-paragraph lo lp iu lq b lr ls jv lt lu lv jy lw lx ly lz ma mb mc md me mf mg mh mi mj in bi translated">从上面的例子中，我们可以看到，文本需要预处理，即将其转换为相同的大小写(小写)，在将文本转换为标记之前，删除符号、数字和停用词。为了预处理文本，您需要下载特定的库。</p><pre class="kk kl km kn gu mp mo mq mr aw ms bi"><span id="76b7" class="mt kx iu mo b gz mu mv l mw mx">import re<br/>import numpy as n<br/>import nltk<br/>nltk.download('stopwords')<br/>from nltk.corpus import stopwords<br/>nltk.download('punkt')</span></pre><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="ol om l"/></div><p class="kr ks gk gi gj kt ku bd b be z dk translated">要点学分:<a class="ae mk" href="https://www.coursera.org/learn/language-processing" rel="noopener ugc nofollow" target="_blank"> Coursera </a></p></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gi gj my"><img src="../Images/01e7a21f9d31d03f63c4f7ec76127e72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*58LPEyDUFB7NCBQdX9nwdg.png"/></div></div><p class="kr ks gk gi gj kt ku bd b be z dk translated">预处理文本</p></figure><h1 id="bc9e" class="kw kx iu bd ky kz la lb lc ld le lf lg ka lh kb li kd lj ke lk kg ll kh lm ln bi translated">4.将文本转换为矢量</h1><p id="de15" class="pw-post-body-paragraph lo lp iu lq b lr ls jv lt lu lv jy lw lx ly lz ma mb mc md me mf mg mh mi mj in bi translated">对于机器学习模型，文本数据必须转换为数字数据。这可以通过各种方式实现，如 BoW、tf-idf、单词嵌入等。在这个项目中，我们将关注 BoW 和 tf-idf。</p><h1 id="32fc" class="kw kx iu bd ky kz la lb lc ld le lf lg ka lh kb li kd lj ke lk kg ll kh lm ln bi translated">词汇袋</h1><blockquote class="on oo op"><p id="708e" class="lo lp oq lq b lr nf jv lt lu ng jy lw or nt lz ma os nu md me ot nv mh mi mj in bi translated">在 BoW 模型中，一个文本(如一个句子或一个文档)被表示为其单词的包(多集合),不考虑语法甚至词序，但保持多样性。</p></blockquote><h2 id="f41a" class="mt kx iu bd ky ny nz dn lc oa ob dp lg lx oc od li mb oe of lk mf og oh lm oi bi translated"><em class="kv"> -通过排名建立一个前 N 个流行词的字典。</em></h2><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gi gj ou"><img src="../Images/228c52a7656661f69322a442d1beb1cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KIkoulZqJfjFdFzyode6sQ.png"/></div></div><p class="kr ks gk gi gj kt ku bd b be z dk translated">BoW 表示两个评论，“hello world”和“How are you”</p></figure><p id="8261" class="pw-post-body-paragraph lo lp iu lq b lr nf jv lt lu ng jy lw lx nt lz ma mb nu md me mf nv mh mi mj in bi translated">我们将把自己限制在 N 个流行词，以限制矩阵的大小。而且包含冷门词只会引入稀疏，不会增加太多信息。对于这个项目，让我们用 10000 个流行词。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="ol om l"/></div></figure><pre class="kk kl km kn gu mp mo mq mr aw ms bi"><span id="dfc2" class="mt kx iu mo b gz mu mv l mw mx"># Lets take a look at top 10 popular words<br/>POPULAR_WORDS[:10]</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj ov"><img src="../Images/6c37f060c9d1489586a01d3c1e4fb069.png" data-original-src="https://miro.medium.com/v2/resize:fit:478/format:webp/1*wfGAYzN5yHXCfUr9nC_5Jw.png"/></div></figure><h2 id="fc34" class="mt kx iu bd ky ny nz dn lc oa ob dp lg lx oc od li mb oe of lk mf og oh lm oi bi translated">-建造船首</h2><p id="f8a2" class="pw-post-body-paragraph lo lp iu lq b lr ls jv lt lu lv jy lw lx ly lz ma mb mc md me mf mg mh mi mj in bi translated">对于语料库中的每个评论，创建具有 N 维的零向量，并且对于在评论中找到的单词，将向量中的值增加 1，例如，如果一个单词出现两次，则向量中的索引将得到 2。</p><p id="155f" class="pw-post-body-paragraph lo lp iu lq b lr nf jv lt lu ng jy lw lx nt lz ma mb nu md me mf nv mh mi mj in bi translated">为了有效存储，我们将把这个向量转换成一个稀疏向量，一个利用稀疏性并且实际上只存储非零条目的向量。</p><pre class="kk kl km kn gu mp mo mq mr aw ms bi"><span id="91e7" class="mt kx iu mo b gz mu mv l mw mx">from scipy import sparse as sp_sparse</span></pre><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="ol om l"/></div></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gi gj ow"><img src="../Images/ef2872dbe8981d9b3d7c44127d4b81e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aU3pe3_fOuDTgU_cjTmjKw.png"/></div></div></figure><h1 id="d368" class="kw kx iu bd ky kz la lb lc ld le lf lg ka lh kb li kd lj ke lk kg ll kh lm ln bi translated">TF-IDF</h1><blockquote class="on oo op"><p id="e450" class="lo lp oq lq b lr nf jv lt lu ng jy lw or nt lz ma os nu md me ot nv mh mi mj in bi translated"><a class="ae mk" href="https://en.wikipedia.org/wiki/Tf–idf" rel="noopener ugc nofollow" target="_blank">在信息检索中，<strong class="lq iv">TF–IDF</strong>或<strong class="lq iv"> TFIDF </strong>，是<strong class="lq iv">词频-逆文档频率</strong>的简称，是一种数值统计，意在反映一个词对集合或语料库中的文档有多重要。</a></p></blockquote><p id="5c50" class="pw-post-body-paragraph lo lp iu lq b lr nf jv lt lu ng jy lw lx nt lz ma mb nu md me mf nv mh mi mj in bi translated">这种方法是单词袋的扩展，其中单词的总频率除以文档中的总单词数。这通过在整个文档中规范化过于频繁的单词来惩罚它们。</p><pre class="kk kl km kn gu mp mo mq mr aw ms bi"><span id="4e7d" class="mt kx iu mo b gz mu mv l mw mx">from sklearn.feature_extraction.text import TfidfVectorizer</span></pre><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="ol om l"/></div></figure><h1 id="12bb" class="kw kx iu bd ky kz la lb lc ld le lf lg ka lh kb li kd lj ke lk kg ll kh lm ln bi translated">5.多标签分类</h1><p id="3476" class="pw-post-body-paragraph lo lp iu lq b lr ls jv lt lu lv jy lw lx ly lz ma mb mc md me mf mg mh mi mj in bi translated">我们使用两种不同的技术 BoW 和 tf-idf 准备了数据集。我们可以在两个数据集上运行分类器。由于这是一个多标签分类问题，我们将使用一个简单的 OneVsRestClassfier 逻辑回归。</p><pre class="kk kl km kn gu mp mo mq mr aw ms bi"><span id="a116" class="mt kx iu mo b gz mu mv l mw mx">from sklearn.multiclass import OneVsRestClassifier<br/>from sklearn.linear_model import LogisticRegression</span></pre><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="ol om l"/></div></figure><p id="6f32" class="pw-post-body-paragraph lo lp iu lq b lr nf jv lt lu ng jy lw lx nt lz ma mb nu md me mf nv mh mi mj in bi translated">你可以尝试不同的正则化技术，L1 和 L2 与不同的系数(例如，C 等于 0.1，1，10，100)，直到你满意的结果，这被称为超参数调整。这可以通过 cv 网格搜索、随机搜索和贝叶斯优化来实现。我们不打算在本文中讨论这个话题。如果你想了解更多这方面的信息，请参考这个<a class="ae mk" href="https://medium.com/vantageai/bringing-back-the-time-spent-on-hyperparameter-tuning-with-bayesian-optimisation-2e21a3198afb" rel="noopener">帖子</a>。</p><h1 id="75e8" class="kw kx iu bd ky kz la lb lc ld le lf lg ka lh kb li kd lj ke lk kg ll kh lm ln bi translated">6.估价</h1><p id="0df9" class="pw-post-body-paragraph lo lp iu lq b lr ls jv lt lu lv jy lw lx ly lz ma mb mc md me mf mg mh mi mj in bi translated">我们将使用准确性分数和 f1 分数等指标进行评估。</p><ul class=""><li id="eff6" class="nd ne iu lq b lr nf lu ng lx nh mb ni mf nj mj nk nl nm nn bi translated">准确度分数:在多标签分类中，该函数计算子集准确度:为样本预测的标签集必须<em class="oq">与 y_true 中的相应标签集完全</em>匹配。</li><li id="d51c" class="nd ne iu lq b lr no lu np lx nq mb nr mf ns mj nk nl nm nn bi translated">F1 分数:F1 分数可以解释为精确度和召回率的加权平均值，其中 F1 分数在 1 时达到其最佳值，在 0 时达到其最差分数。精确度和召回率对 F1 分数的相对贡献是相等的。F1 得分= 2 *(精确度*召回率)/(精确度+召回率)</li></ul><p id="dc80" class="pw-post-body-paragraph lo lp iu lq b lr nf jv lt lu ng jy lw lx nt lz ma mb nu md me mf nv mh mi mj in bi translated"><code class="fe ml mm mn mo b">'F1 score micro'</code>:通过计算总的真阳性、假阴性和假阳性来计算全局指标。</p><p id="b14c" class="pw-post-body-paragraph lo lp iu lq b lr nf jv lt lu ng jy lw lx nt lz ma mb nu md me mf nv mh mi mj in bi translated"><code class="fe ml mm mn mo b">'F1 score macro'</code>:计算每个标签的指标，求其未加权平均值。这没有考虑标签不平衡。</p><p id="733a" class="pw-post-body-paragraph lo lp iu lq b lr nf jv lt lu ng jy lw lx nt lz ma mb nu md me mf nv mh mi mj in bi translated"><code class="fe ml mm mn mo b">'F1 score weighted'</code>:计算每个标签的度量，并根据支持度(每个标签真实实例的数量)计算它们的平均值。这改变了“宏”以解决标签不平衡；它会导致 F 值不在精确度和召回率之间。</p><pre class="kk kl km kn gu mp mo mq mr aw ms bi"><span id="14c1" class="mt kx iu mo b gz mu mv l mw mx">from sklearn.metrics import accuracy_score<br/>from sklearn.metrics import f1_score<br/>from sklearn.metrics import roc_auc_score <br/>from sklearn.metrics import average_precision_score<br/>from sklearn.metrics import recall_score</span></pre><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="ol om l"/></div></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gi gj ox"><img src="../Images/7096f1b20f89ebbce02a5ac5436153b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O-ql9yhGLi4FDO17bVhWpA.png"/></div></div></figure><p id="d46e" class="pw-post-body-paragraph lo lp iu lq b lr nf jv lt lu ng jy lw lx nt lz ma mb nu md me mf nv mh mi mj in bi translated">F1 分数加权和说明数据不平衡的宏看起来不错。让我们检查输出、预测标签和实际标签。我们需要用实际的标签替换一次性编码的标签来进行解释。接下来让我们对 tf-idf 模型进行预测。</p><pre class="kk kl km kn gu mp mo mq mr aw ms bi"><span id="5620" class="mt kx iu mo b gz mu mv l mw mx">test_predictions = classifier_tfidf.predict(X_test_tfidf)</span></pre><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="ol om l"/></div></figure><pre class="kk kl km kn gu mp mo mq mr aw ms bi"><span id="e1ad" class="mt kx iu mo b gz mu mv l mw mx">for i in range(90,97):<br/>    print('\ny_label: ', test_labels[i], '\ny_pred: ', test_pred_labels[i])</span><span id="18a3" class="mt kx iu mo b gz nw mv l mw mx">print('\ny_label: ', test_labels[i], '\ny_pred: ', test_pred_labels[i])</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gi gj oy"><img src="../Images/56d0b61299f5c5bc9d9833fefd6d56b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h82iHx9rezWUHHCqWtux_w.png"/></div></div></figure><p id="d8f3" class="pw-post-body-paragraph lo lp iu lq b lr nf jv lt lu ng jy lw lx nt lz ma mb nu md me mf nv mh mi mj in bi translated">成绩不算太差，但还可以做得更好。请尝试使用超参数调整和不同的分类器来检查模型的性能。希望你喜欢阅读。</p><p id="c64a" class="pw-post-body-paragraph lo lp iu lq b lr nf jv lt lu ng jy lw lx nt lz ma mb nu md me mf nv mh mi mj in bi translated">如果你感兴趣，我留下了构建单词云图像的代码。</p><h1 id="dd6b" class="kw kx iu bd ky kz la lb lc ld le lf lg ka lh kb li kd lj ke lk kg ll kh lm ln bi translated">带 Twitter 掩码的词云</h1><pre class="kk kl km kn gu mp mo mq mr aw ms bi"><span id="3704" class="mt kx iu mo b gz mu mv l mw mx">comments_join = ' '.join(POPULAR_WORDS)</span><span id="608b" class="mt kx iu mo b gz nw mv l mw mx">from scipy.misc import imread<br/>from wordcloud import WordCloud, STOPWORDS</span><span id="c4ec" class="mt kx iu mo b gz nw mv l mw mx">twitter_mask = imread('twitter.png', flatten=True)<br/>    <br/>wordcloud = WordCloud(<br/>                      stopwords=STOPWORDS,<br/>                      background_color='white',<br/>                      width=1800,<br/>                      height=1400,<br/>                      mask=twitter_mask<br/>            ).generate(comments_join)</span><span id="437c" class="mt kx iu mo b gz nw mv l mw mx">plt.figure(figsize = (12, 12), facecolor = None) <br/>plt.imshow(wordcloud)<br/>plt.axis("off")<br/>plt.savefig('twitter_comments.png', dpi=300)<br/>plt.show()</span></pre><p id="ae76" class="pw-post-body-paragraph lo lp iu lq b lr nf jv lt lu ng jy lw lx nt lz ma mb nu md me mf nv mh mi mj in bi translated">带代码的 jupyter 笔记本，请点击<a class="ae mk" href="https://github.com/snehalnair/bow_tfidf" rel="noopener ugc nofollow" target="_blank">此处</a>。</p><p id="4245" class="pw-post-body-paragraph lo lp iu lq b lr nf jv lt lu ng jy lw lx nt lz ma mb nu md me mf nv mh mi mj in bi translated">参考资料:</p><p id="72bf" class="pw-post-body-paragraph lo lp iu lq b lr nf jv lt lu ng jy lw lx nt lz ma mb nu md me mf nv mh mi mj in bi translated"><a class="ae mk" href="https://www.coursera.org/learn/language-processing/home/week/1" rel="noopener ugc nofollow" target="_blank">https://www.coursera.org/learn/language-processing/home</a></p></div></div>    
</body>
</html>