# 在数据科学工作面试中表现出色

> 原文：<https://towardsdatascience.com/acing-a-data-science-job-interview-b37e8b68869b?source=collection_archive---------34----------------------->

## 容易避免的常见错误的自以为是的列表

![](img/305f9901d352ab1d82566964dddd9876.png)

[斯科特·格雷厄姆](https://unsplash.com/@sctgrhm?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍照

在我担任数据科学家期间，我有机会面试了相当一部分数据相关职位的候选人。在这样做的时候，我开始注意到一个模式:某些类型的(简单的)错误在候选人中极其频繁！在我看来，与托尔斯泰的一句名言截然不同的是，“案例研究中大多数令人不快的错误看起来都很相似”。

在我的脑海中，我开始想象我会毫不犹豫地雇佣哪种候选人。不，不是 rock star/Guru/布道者，拥有 12 年管理 Kubernetes 集群和使用 Hadoop/Spark 的专业经验，同时为 TensorFlow 的开发做出贡献，获得 2 个博士学位，每年至少发表 3 篇深度学习论文。没有。我会立刻被一个至少没有犯我将要描述的那种错误的人所打动……我可以想象同样的事情会发生在其他公司，发生在其他面试官身上。

虽然这是一个个人的和相当固执己见的列表，但我希望这些小技巧和窍门能对刚开始数据科学生涯的人有所帮助！我在这里只是把我想到的更多的与 DS 相关的东西放在这里，但是当然，编写 Pythonic 式的、可读的、有表现力的代码也会让采访你的人非常高兴！

# 草率使用熊猫

让我们面对现实吧:作为一名数据科学家，对于您的大多数日常任务，您将操作表、对表进行切片、根据列中包含的值对表进行分组、对表应用转换等等。这几乎自动意味着 Pandas 是数据科学家最重要的基础工具之一，如果你能够展示对它的掌握，那么人们会非常认真地对待你。

相反，如果您系统地对存在内置 Pandas 命令的数据帧进行非常低级的操作，您可能会引发各种危险信号。

这里有一些提高熊猫的技巧:

1.  **使用它！**
2.  每当你必须对一个数据帧或系列进行任何操作时，停下来几分钟，阅读文档，检查是否已经有内置的方法可以帮你节省 90%的工作。即使你没有找到它们，在通读文档的过程中，你也会学到很多东西，这些东西将来很可能会派上用场。
3.  看信得过的人写的教程，看看他们是怎么做一些操作的。特别是，汤姆·奥格斯伯格的现代熊猫教程第二部分是一个很好的开始。更好的是，不只是读第二部分，而是整个系列。另外，文森特·d·沃默达姆的这个演讲也值得一看。
4.  如果您必须执行一些复杂的，可能不是内置的数据转换，请考虑将其封装在一个函数中！这样做之后，`.pipe(...)`和`.apply(...)`就是你的朋友了。

最后提示:不要在任何地方使用`inplace=True`。与普遍的看法相反，它不会带来任何性能上的好处，而且自然会让您编写不清楚的代码，因为它会妨碍您链接方法的能力。希望这个功能[会在未来的某个时候](https://github.com/pandas-dev/pandas/issues/16529)停止。

# 从测试集中泄漏的信息

测试集是神圣的；在建立模型或选择迄今为止你得到的最好的一个时，它甚至不应该被看。想一想:我们之所以首先要有一个测试集，是因为我们希望对一个模型的泛化误差有一个无偏的估计。如果我们被允许先睹为快“未来”(即，在训练和模型建立期间，我们根本不应该访问的数据)，几乎可以肯定我们会受到影响，并使我们的误差估计产生偏差。

虽然我从未见过任何人**直接**在测试集上拟合模型，但通常候选人通过查看测试集上的一些度量来执行超参数调整和模型选择。请不要这样做，而是将部分数据保存为验证集，或者更好的方法是执行交叉验证。

另一个导致测试集信息泄漏的常见原因是在整个数据集上安装定标器(如`sklearn.preprocessing.StandardScaler`)或过采样例程(如`imblearn.over_sampling.SMOTE`)。同样，特征工程、重采样等是如何构建和训练模型的一部分:不要让测试集出现在模型中。

# 平均值的缺陷

尽管汇总统计数据(如平均值、分位数等)有助于获得数据的第一印象，但不要犯将分布简化为单一数字的错误，因为这没有意义。一个经典的警示性例子来展示这一点是[安斯科姆的四重奏](https://en.wikipedia.org/wiki/Anscombe%27s_quartet)，但我最喜欢的是[的 Datasaurus 打的](https://www.autodeskresearch.com/publications/samestats)。

![](img/12906918b7bbee389da3e036c4e4120b.png)

来源:Autodesk Research

通常情况下，数据点的分布比它们的平均值更重要，尤其是在一些应用中，分布尾部的形状是最终决定决策的因素。

如果你表现出你考虑到了这类问题，当有人提到[詹森不等式](https://en.wikipedia.org/wiki/Jensen%27s_inequality)时，你甚至不眨眼，那么只有好事会发生。

# 盲目使用图书馆

当你得到一个案例研究时，你通常有一个可以利用的优势:你选择要使用的模型。这意味着你可以预料到面试官可能会问你的一些问题！

例如，如果你最终使用了一个`XGBClassifier`来完成你的任务，尽可能深入地理解它是如何工作的。大家都知道它是基于决策树的，但是它还需要哪些“成分”呢？你知道 XGBoost 是如何处理缺失值的吗？你能用通俗的语言解释一下装袋和抢劫吗？

即使你最终使用了线性回归，你也应该清楚地知道幕后发生了什么，以及你设置的参数背后的意义。如果你说“我把学习率设为 X”，有人接着问“什么是学习率？”，如果你不能至少在它上面花上几句话，那就太糟糕了。

# 糟糕的可视化选择

为你的情节选择正确的选项也有很长的路要走。最后，我认为这里最常见的错误是由于标准化选择不当或者没有使用正确的轴刻度。

我们来看一个例子；以下代码片段

只创建两个带有指数分布样本的数组；然后，它生成以下图形

![](img/9d026ab75c095f9baac99e5fd0bf4909.png)

我无数次看到这种变化。基本上，我们真正想做的是比较两组之间的分布，但在这个图中，我们只显示观察值的原始计数。如果其中一组比另一组有更多的样本，这样的图对于了解潜在的分布是没有意义的。更好的选择是以一种合理的方式将我们显示的内容标准化:在这种情况下，只需设置参数`density=True`即可将原始计数转换为相对频率，并给出以下结果:

![](img/d207f8adb316a09aca3f99ae0cc8bab0.png)

不错！现在我们可以清楚地看到，`a`和`b`毕竟是来自同一个分布的样本。这里仍然有一些我不喜欢的东西:大量的空白，以及对于大于 4 的`a`或`b`值，我看不清楚任何条形。幸运的是，由于 1614 对数是一种常见的数学运算……如此常见，以至于我们甚至在`plt.hist(...)`中有一个专用的关键字参数，它只是将我们的线性 y 轴转换为对数轴:

![](img/00342fa8b6f5c809290cf046f4442806.png)

请注意，这绝不是一个“完美”的情节:我们的轴没有标签，没有图例，它只是看起来有点丑！但是，嘿，至少我们可以通过调用`plt.hist([a,b])`来提取我们永远无法看到的洞察力。

# 结论

上面列出的所有错误的共同点是，通过一些思考和相关知识，它们是很容易避免的，所以我对你下一个数据科学案例研究的建议是:放松，集中精力，努力比他们与你玩的任何心理游戏领先一步，并谷歌搜索东西(很多！).面试可能会有压力，但是如果双方都是公平的(**尤其是**面试并提出任务的人)，几乎不会浪费时间。

非常感谢对本文的任何反馈；我错过了什么你认为特别重要的事情吗？

最后，我祝你事业顺利，无论你现在从事什么工作！也许会在面试时见到你:-)