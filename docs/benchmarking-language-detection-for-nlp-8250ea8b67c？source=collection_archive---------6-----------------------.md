# è‡ªç„¶è¯­è¨€å¤„ç†çš„åŸºå‡†è¯­è¨€æ£€æµ‹

> åŸæ–‡ï¼š<https://towardsdatascience.com/benchmarking-language-detection-for-nlp-8250ea8b67c?source=collection_archive---------6----------------------->

## [å…¥é—¨](https://towardsdatascience.com/tagged/getting-started)

## ç”¨äºè¯†åˆ«æ–‡æœ¬è¯­è¨€çš„å››ä¸ª Python å·¥å…·ï¼Œä»¥åŠé€Ÿåº¦å’Œå‡†ç¡®æ€§æµ‹è¯•

![](img/247febcb5c95276665382aa9351072eb.png)

æ°å¥ç³Â·å¸ƒå…°å¾·éŸ¦æ©åœ¨ [Unsplash](https://unsplash.com/s/photos/languages?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) ä¸Šçš„ç…§ç‰‡

å¤§å¤šæ•° NLP åº”ç”¨ç¨‹åºå¾€å¾€æ˜¯ç‰¹å®šäºè¯­è¨€çš„ï¼Œå› æ­¤éœ€è¦å•è¯­æ•°æ®ã€‚ä¸ºäº†ç”¨ç›®æ ‡è¯­è¨€æ„å»ºåº”ç”¨ç¨‹åºï¼Œæ‚¨å¯èƒ½éœ€è¦åº”ç”¨ä¸€ç§é¢„å¤„ç†æŠ€æœ¯ï¼Œè¿‡æ»¤æ‰ç”¨éç›®æ ‡è¯­è¨€ç¼–å†™çš„æ–‡æœ¬ã€‚è¿™éœ€è¦æ­£ç¡®è¯†åˆ«æ¯ä¸ªè¾“å…¥ç¤ºä¾‹çš„è¯­è¨€ã€‚ä¸‹é¢æˆ‘åˆ—å‡ºäº†ä¸€äº›å·¥å…·ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨å®ƒä»¬ä½œä¸º Python æ¨¡å—æ¥æ»¡è¶³è¿™ä¸ªé¢„å¤„ç†éœ€æ±‚ï¼Œå¹¶æä¾›äº†ä¸€ä¸ªæ€§èƒ½åŸºå‡†æ¥è¯„ä¼°æ¯ä¸€ä¸ªå·¥å…·çš„é€Ÿåº¦å’Œå‡†ç¡®æ€§ã€‚

# 1)è¯­è¨€æ£€æµ‹

[](https://pypi.org/project/langdetect/) [## langdetect

### Nakatani Shuyo çš„è¯­è¨€æ£€æµ‹åº“(ç‰ˆæœ¬ä» 03/03/2014)åˆ° Python çš„ç§»æ¤ã€‚$ pip å®‰è£…è¯­è¨€æ£€æµ‹â€¦

pypi.org](https://pypi.org/project/langdetect/) 

`langdetect`æ˜¯ Google çš„[è¯­è¨€æ£€æµ‹](https://github.com/shuyo/language-detection)åº“ä» Java åˆ° Python çš„é‡æ–°å®ç°ã€‚åªéœ€å°†æ‚¨çš„æ–‡æœ¬ä¼ é€’ç»™å¯¼å…¥çš„`detect`å‡½æ•°ï¼Œå®ƒå°†è¾“å‡ºæ¨¡å‹ç»™å‡ºæœ€é«˜ç½®ä¿¡åº¦å¾—åˆ†çš„è¯­è¨€çš„ä¸¤ä¸ªå­—æ¯çš„ ISO 693 ä»£ç ã€‚(å‚è§[æœ¬é¡µ](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes)äº†è§£ 693 ä¸ªä»£ç åŠå…¶å„è‡ªè¯­è¨€çš„å®Œæ•´åˆ—è¡¨ã€‚)å¦‚æœä½ ä½¿ç”¨`detect_langs`æ¥ä»£æ›¿ï¼Œå®ƒå°†è¾“å‡ºä¸€ä¸ªåˆ—è¡¨ï¼Œåˆ—å‡ºæ¨¡å‹å·²ç»é¢„æµ‹åˆ°çš„é¡¶çº§è¯­è¨€ï¼Œä»¥åŠå®ƒä»¬çš„æ¦‚ç‡ã€‚

```
from langdetect import DetectorFactory, detect, detect_langstext = "My lubimy mleko i chleb."detect(text) #  'cs'
detect_langs(text)  # [cs:0.7142840957132709, pl:0.14285810606233737, sk:0.14285779665739756]
```

å‡ ä¸ªç‚¹ç¼€ç‚¹:

1.  åº“åˆ¶ä½œè€…å»ºè®®æ‚¨å°†`DetectorFactory`ç§å­è®¾ç½®ä¸ºæŸä¸ªæ•°å­—ã€‚è¿™æ˜¯å› ä¸º langdetect çš„ç®—æ³•æ˜¯ä¸ç¡®å®šçš„ï¼Œè¿™æ„å‘³ç€å¦‚æœä½ è¯•å›¾åœ¨å¤ªçŸ­æˆ–å¤ªæ¨¡ç³Šçš„æ–‡æœ¬ä¸Šè¿è¡Œå®ƒï¼Œä½ å¯èƒ½æ¯æ¬¡è¿è¡Œå®ƒéƒ½ä¼šå¾—åˆ°ä¸åŒçš„ç»“æœã€‚è®¾å®šç§å­åœ¨å¼€å‘/è¯„ä¼°æœŸé—´å¼ºåˆ¶æ‰§è¡Œä¸€è‡´çš„ç»“æœã€‚
2.  æ‚¨å¯èƒ½è¿˜æƒ³åœ¨ try/except å—ä¸­ç”¨`LanguageDetectException`åŒ…å›´`detect`è°ƒç”¨ï¼Œå¦åˆ™æ‚¨å¯èƒ½ä¼šå¾—åˆ°ä¸€ä¸ª[â€œæ–‡æœ¬ä¸­æ²¡æœ‰ç‰¹æ€§â€é”™è¯¯](https://github.com/Mimino666/langdetect/issues/44)ï¼Œå½“ç»™å®šè¾“å…¥çš„è¯­è¨€ä¸èƒ½è¢«è¯„ä¼°æ—¶ï¼Œä¾‹å¦‚å½“å®ƒåŒ…å« URLã€æ•°å­—ã€å…¬å¼ç­‰å­—ç¬¦ä¸²æ—¶ï¼Œå°±ä¼šå‡ºç°è¿™ä¸ªé”™è¯¯ã€‚

```
from langdetect import DetectorFactory, detect
from langdetect.lang_detect_exception import LangDetectExceptionDetectorFactory.seed = 0def is_english(text):
    try:
        if detect(text) != "en":
            return False
    except LangDetectException:
        return False
    return True
```

# 2)ç©ºé—´è¯­è¨€æ£€æµ‹å™¨

[](https://spacy.io/universe/project/spacy-langdetect) [## ç©ºé—´æ¢æµ‹ç©ºé—´å®‡å®™

### ä¸€ä¸ªå®Œå…¨å¯å®šåˆ¶çš„è¯­è¨€æ£€æµ‹ç®¡é“ï¼Œç”¨äºç©ºé—´å®‰è£…

ç©ºé—´. io](https://spacy.io/universe/project/spacy-langdetect) 

å¦‚æœæ‚¨ä½¿ç”¨ spaCy æ¥æ»¡è¶³æ‚¨çš„ NLP éœ€æ±‚ï¼Œæ‚¨å¯ä»¥å‘æ‚¨ç°æœ‰çš„ spaCy ç®¡é“æ·»åŠ ä¸€ä¸ªå®šåˆ¶çš„è¯­è¨€æ£€æµ‹ç»„ä»¶ï¼Œè¿™å°†ä½¿æ‚¨èƒ½å¤Ÿåœ¨`Doc`å¯¹è±¡ä¸Šè®¾ç½®ä¸€ä¸ªåä¸º`.language`çš„æ‰©å±•å±æ€§ã€‚ç„¶åå¯ä»¥é€šè¿‡`Doc._.language`è®¿é—®è¯¥å±æ€§ï¼Œå®ƒå°†è¿”å›é¢„æµ‹çš„è¯­è¨€åŠå…¶æ¦‚ç‡ã€‚

```
import spacy
from spacy_langdetect import LanguageDetectortext2 = 'In 1793, Alexander Hamilton recruited Webster to move to New York City and become an editor for a Federalist Party newspaper.'nlp = spacy.load('en_core_web_sm')
nlp.add_pipe(LanguageDetector(), name='language_detector', last=True)doc = nlp(text)
doc._.language  # {'language': 'en', 'score': 0.9999978351575265}
```

# 3) langid

langid ç‰¹åˆ«å¹å˜˜å®ƒçš„é€Ÿåº¦(ä¸‹é¢ä¼šè¯¦ç»†ä»‹ç»)ã€‚å®ƒçš„å·¥ä½œæ–¹å¼ç±»ä¼¼äºä¸Šé¢çš„å·¥å…·ï¼Œä½†æ˜¯å®ƒè¿˜å¯ä»¥é€šè¿‡è¿è¡Œ`python langid.py`ä½œä¸ºå‘½ä»¤è¡Œå·¥å…·ä½¿ç”¨ã€‚æŸ¥çœ‹ä»–ä»¬çš„å›è´­åè®®ï¼Œäº†è§£æ›´å¤šç»†èŠ‚å’Œå…¶ä»–é€‰æ‹©ã€‚

[](https://github.com/saffsd/langid.py) [## saffsd/langid.py

### py æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„è¯­è¨€è¯†åˆ«(langid)å·¥å…·ã€‚è®¾è®¡åŸåˆ™å¦‚ä¸‹:å¿«é€Ÿé¢„è®­ç»ƒâ€¦

github.com](https://github.com/saffsd/langid.py) 

è¦å°† langid ç”¨ä½œ Python åº“ï¼Œè¯·ä½¿ç”¨`classify`å‡½æ•°:

```
import langidlangid.classify(text2)  # ('en', -127.75649309158325)
```

æ‚¨å¯ä»¥å°†æœ€åˆåœ¨å¯¹æ•°æ¦‚ç‡ç©ºé—´ä¸­è®¡ç®—çš„æ¦‚ç‡é¢„æµ‹æ ¡å‡†ä¸ºå¯ä»¥è§£é‡Šä¸º 0 åˆ° 1 èŒƒå›´å†…çš„ç½®ä¿¡åº¦å¾—åˆ†:

```
from langid.langid import LanguageIdentifier, modellang_identifier = LanguageIdentifier.from_modelstring(model, norm_probs=True)
lang_identifier.classify(text2) # ('en', 0.999999999999998)
```

# 4)å¿«é€Ÿæ–‡æœ¬

fasttext æŒ‡å‡ºï¼Œå…¶é¢„è®­ç»ƒçš„è¯­è¨€è¯†åˆ«æ¨¡å‹å ç”¨çš„å†…å­˜ä¸åˆ° 1MBï¼Œä½†æ¯ç§’é’Ÿèƒ½å¤Ÿåˆ†ç±»æ•°åƒä»½æ–‡ä»¶ã€‚

ä¸‹è½½æ‚¨é€‰æ‹©çš„å‹å·:

*   [lid.176.bin](https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin) :é€Ÿåº¦æ›´å¿«ï¼Œç²¾åº¦ç•¥é«˜(æ–‡ä»¶å¤§å°=126MB)ã€‚
*   [lid.176.ftz](https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.ftz) :æ¨¡å‹çš„å‹ç¼©ç‰ˆæœ¬(æ–‡ä»¶å¤§å°=917kB)ã€‚

```
import fasttext

path_to_pretrained_model = '/tmp/lid.176.bin'
fmodel = fasttext.load_model(path_to_pretrained_model)
fmodel.predict([text2])  # ([['__label__en']], [array([0.9331119], dtype=float32)]
```

# é€Ÿåº¦ğŸš…

å¦‚æœæ‚¨è®¡åˆ’åœ¨ç”Ÿäº§ä¸­ä½¿ç”¨éœ€è¦è¯­è¨€è¯†åˆ«çš„åº”ç”¨ç¨‹åºï¼Œé€Ÿåº¦å¯èƒ½æ˜¯ä¸€ä¸ªé‡è¦çš„è€ƒè™‘å› ç´ ã€‚ä¸‹é¢æ˜¯ä¸Šè¿°å››ç§å·¥å…·çš„å¿«é€ŸåŸºå‡†æµ‹è¯•ã€‚

æˆ‘ä» Kaggle ä¸‹è½½äº†ä¸€ä¸ªåŒ…å« 10ï¼Œ502 æ¡æ¨æ–‡çš„æ•°æ®é›†ï¼Œè¿™äº›æ¨æ–‡æ˜¯ä»æ¥è‡ª 130 ä¸ªä¸åŒå›½å®¶çš„å…¬å¼€å‘å¸ƒçš„å¸¦åœ°ç†æ ‡è®°çš„ Twitter æ¶ˆæ¯ä¸­éšæœºæŠ½å–çš„ã€‚é™¤äº†å…¶ä»–ç‰¹å¾ä¹‹å¤–ï¼Œå®ƒä»¬è¿˜è¢«æ ‡æ³¨ä¸ºè‹±è¯­æˆ–éè‹±è¯­ã€‚

æ•°æ®æ¥æº:[https://www . ka ggle . com/rtatman/the-umass-global-English-on-Twitter-dataset](https://www.kaggle.com/rtatman/the-umass-global-english-on-twitter-dataset)ã€‚

```
import pandas as pddf = pd.read_csv('all_annotated.tsv', sep='\t')
```

![](img/252b3cac74cecf1fb5bb8d2e28ca7178.png)

Kaggle æ•°æ®é›†å‰å…­è¡Œ

é€Ÿåº¦æµ‹è¯•çš„ç»“æœï¼

![](img/142b47fe90bf242555d3698fcc4eb3a4.png)

é€Ÿåº¦æµ‹è¯•ç»“æœ

fasttext åªç”¨äº† 129 æ¯«ç§’å°±å¯¹ 10ï¼Œ000 å¤šä¸ªæ•°æ®ç‚¹è¿›è¡Œäº†é¢„æµ‹ã€‚å…°å‰å¾·ååˆ—ç¬¬äºŒï¼Œå…¶ä»–ç«äº‰è€…æ…¢äº†è®¸å¤šæ•°é‡çº§ã€‚

# å‡†ç¡®(æ€§)ğŸ”¬

```
from sklearn.metrics import accuracy_scoreytrue = df['Definitely English'].to_list()
tweets = df['Tweet'].to_list()# get the predictions of each detectorlangdetect_preds = [lang_detect(t) for t in tweets]
spacy_preds = [nlp(t)._.language['language'] for t in tweets]
langid_preds = [lang_identifier.classify(text)[0] for t in tweets]
fasttext_preds = [p[0].replace('__label__', '') for p in fmodel.predict(tweets)[0]]# binarize the labelslangdetect_preds_binary = [1 if p == 'en' else 0 for p in langdetect_preds]
spacy_preds_binary = [1 if p == 'en' else 0 for p in spacy_preds]
langid_preds_binary = [1 if p == 'en' else 0 for p in langid_preds]
fasttext_preds_binary = [1 if p == 'en' else 0 for p in fasttext_preds]# evaluate accuracy against the true labels (1 for English, 0 otherwise)accuracy_score(ytrue, langdetect_preds_binary)  # 0.8448866882498571 
accuracy_score(ytrue, spacy_preds_binary)  # 0.8448866882498571
accuracy_score(ytrue, langid_preds_binary)  # 0.8268901161683488
accuracy_score(ytrue, fasttext_preds_binary)  # **0.8598362216720624**
```

fasttext çš„å‡†ç¡®ç‡æœ€é«˜ï¼Œå…¶æ¬¡æ˜¯ langdetect å’Œ spacy-langdetectã€‚ç›´è§‰å‘Šè¯‰æˆ‘ spacy-langdetect åªæ˜¯å¼•æ“ç›–ä¸‹çš„ langdetectã€‚ï¼›)(å®ƒä»¬æœ‰å®Œå…¨ç›¸åŒçš„å‡†ç¡®ç‡â€¦â€¦è¿™ä¹Ÿè§£é‡Šäº†ç›¸ä¼¼çš„åº“åã€‚)

ä¸ºäº†æ›´å¥½åœ°è¡¡é‡ï¼Œè¿™é‡Œæ˜¯æ¯ä¸ªæ¨¡å‹çš„ç²¾ç¡®åº¦ã€å¬å›ç‡å’Œ f1 å€¼ã€‚

```
from sklearn.metrics import classification_reportprint(classification_report(ytrue, langdetect_preds_binary))
print(classification_report(ytrue, spacy_preds_binary))
print(classification_report(ytrue, langid_preds_binary))
print(classification_report(ytrue, fasttext_preds_binary))# langdetect
              precision    recall  f1-score   support

           0       0.80      0.94      0.86      5416
           1       0.92      0.75      0.82      5086

    accuracy                           0.84     10502
   macro avg       0.86      0.84      0.84     10502
weighted avg       0.86      0.84      0.84     10502# spacy-langdetect
              precision    recall  f1-score   support

           0       0.80      0.94      0.86      5416
           1       0.92      0.75      0.82      5086

    accuracy                           0.84     10502
   macro avg       0.86      0.84      0.84     10502
weighted avg       0.86      0.84      0.84     10502 # langid
              precision    recall  f1-score   support

           0       0.79      0.90      0.84      5416
           1       0.88      0.74      0.81      5086

    accuracy                           0.83     10502
   macro avg       0.83      0.82      0.82     10502
weighted avg       0.83      0.83      0.83     10502# fasttext
              precision    recall  f1-score   support

           0       0.91      0.80      0.86      5416
           1       0.82      0.92      0.86      5086

    accuracy                           0.86     10502
   macro avg       0.86      0.86      0.86     10502
weighted avg       0.87      0.86      0.86     10502
```

# å¤–å–é£Ÿå“

å¦‚æœä½ è¦å¤„ç†ä¸€ä¸ªéå¸¸å¤§çš„æ•°æ®é›†ï¼Œæˆ‘ä¼šé€‰æ‹© fasttextã€‚

![](img/4b734e79ed2a457b32f4c1a898fdb26d.png)