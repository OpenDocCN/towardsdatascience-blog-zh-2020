<html>
<head>
<title>Lesson learnt from Kaggle — Bengali Image Classification Competition</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从 Kaggle —孟加拉影像分类竞赛中得到的启示</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/lesson-learnt-from-kaggle-bengali-image-classification-competition-39c1ed79adb1?source=collection_archive---------43-----------------------#2020-03-22">https://towardsdatascience.com/lesson-learnt-from-kaggle-bengali-image-classification-competition-39c1ed79adb1?source=collection_archive---------43-----------------------#2020-03-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/2e6893019c9676e1a700384ca10f4347.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PSpKv03U1-ZM5Nf69UDa3Q.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><a class="ae kc" href="https://www.kaggle.com/c/bengaliai-cv19/?utm_medium=email&amp;utm_source=intercom&amp;utm_campaign=bengaliai-email-launch" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/bengaliai-cv19/?utm_medium=email&amp;UTM _ source =对讲机&amp;UTM _ campaign =孟加拉语-电子邮件-发射</a></p></figure><p id="cff2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我用 Github Page + <a class="ae kc" href="https://github.com/fastai/fastpages" rel="noopener ugc nofollow" target="_blank"> fastpages </a>创建了一个<a class="ae kc" href="http://mediumnok.ml/" rel="noopener ugc nofollow" target="_blank"> <strong class="kf ir">新博客</strong> </a>，因为它对编码更友好，我基本上只是从那里复制<a class="ae kc" href="https://mediumnok.ml/ml/kaggle/2020/03/21/10-lessons-learnt-from-Kaggle-competition.html" rel="noopener ugc nofollow" target="_blank">页面</a>到 Medium，它工作得很好！你可以订阅<a class="ae kc" href="https://mediumnok.ml/feed.xml" rel="noopener ugc nofollow" target="_blank"> <strong class="kf ir"> RSS </strong> </a>，我仍然会在媒体上发布，但可能会在新博客上发布更多关于编码的内容。</p><h1 id="de20" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">介绍</h1><p id="ccc7" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">我和一个朋友组队参加了<a class="ae kc" href="https://www.kaggle.com/c/bengaliai-cv19/?utm_medium=email&amp;utm_source=intercom&amp;utm_campaign=bengaliai-email-launch" rel="noopener ugc nofollow" target="_blank">孟加拉图片分类比赛</a>。在整个比赛中，我们努力在公共排行榜上获得高排名。最后，结果让所有人都大吃一惊，因为排行榜震动很大。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi me"><img src="../Images/4eeaa833463e67434d9fc576608da932.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*MKURKcwuTM7YEMUg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><a class="ae kc" href="https://www.kaggle.com/c/bengaliai-cv19/leaderboard" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/bengaliai-cv19/leaderboard</a></p></figure><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mj"><img src="../Images/acd4f73ab74a1b8281c05a4dd084f1b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HikAJQ6mRuihA71R"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">【https://www.kaggle.com/c/bengaliai-cv19/leaderboard】</p></figure><p id="bb06" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最终私信分数远低于公信分数。这表明大多数参与者都过度适应公共排行榜。</p><h1 id="e80f" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">分类任务</h1><p id="54ab" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">这是一场图像分类比赛。我们需要预测孟加拉文字的 3 个部分<code class="fe mk ml mm mn b">root</code>、<code class="fe mk ml mm mn b">consonant</code>和<code class="fe mk ml mm mn b">vowel</code>。像 MNIST 数据集一样，这是一个典型的分类任务。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/aa5b1cd587e5b866c95e39a6f0fb7fd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/0*2U_jwn22f4wa2cxd"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><a class="ae kc" href="https://bengali.ai/" rel="noopener ugc nofollow" target="_blank">孟加拉语。艾</a><a class="ae kc" href="https://www.kaggle.com/c/bengaliai-cv19/data" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/bengaliai-cv19/data</a></p></figure><h1 id="eca3" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">评估指标</h1><p id="f4d0" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">竞赛使用宏观回忆作为评价标准。一般来说，人们在训练中的回忆率超过 96%,最优秀的人回忆率甚至超过 99%。</p><h1 id="49ae" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">模型(越大越好)</h1><p id="a988" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">我们从<code class="fe mk ml mm mn b">xresnet50</code>开始，这是一个比较小的型号。因为我们假设这个分类任务是一个非常标准的任务，因此模型的差异将不是最重要的。因此，我们选择 xresnet50，因为它在准确性方面有很好的性能，并且训练相对较快。</p><p id="cb74" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">比赛快结束时，我们换了一个更大的型号<code class="fe mk ml mm mn b">se-resnext101</code>。它需要三倍的训练时间，加上我们必须缩小批量，因为它不适合 GPU 的内存。令人惊讶的是(可能不是每个人都惊讶)，更大的模型确实比我预期的更好地提升了性能，召回率约为 0.3-0.5%。这是一个很大的改进，因为召回率非常高(~0.97)，换句话说，仅仅通过使用一个更好的模型，它就减少了~10%的误差，不错！</p><h1 id="4462" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">增大</h1><p id="f69a" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">深度学习永远没有“足够”的数据，所以我们总是尽力收集更多的数据。由于我们无法收集更多的数据，我们需要数据扩充。我们从旋转+缩放开始。我们还发现 MixUp 和 CutMix 对提高性能非常有效。从 0.96 到 0.964 的召回率，它也给了我们大约 10%的提升。</p><h1 id="281a" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated"><a class="ae kc" href="https://arxiv.org/abs/1905.04899" rel="noopener ugc nofollow" target="_blank">CutMix</a>&amp;<a class="ae kc" href="https://arxiv.org/pdf/1710.09412.pdf" rel="noopener ugc nofollow" target="_blank">mix</a></h1><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/396fd8c4c39a36cb25f51b3cbbc64e23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/0*aE4ZMvpKty_pOKRV"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><a class="ae kc" href="https://arxiv.org/abs/1905.04899" rel="noopener ugc nofollow" target="_blank"> CutMix:训练具有可本地化特征的强分类器的正则化策略</a></p></figure><p id="e2b3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mq"> Mixup </em>很简单，如果你懂摄影的话，对你的照片进行双重曝光也差不多。它通过采样权重来覆盖两幅图像(在本例中为猫+狗)。因此，不是预测 P(狗)= 1，新的目标可以变成 P(狗)= 0.8 和 P(猫)= 0.2。</p><p id="2f72" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mq"> CutMix </em>也有类似的想法，不是叠加两张图像，而是裁剪出图像的某个比例，用另一张替换。</p><p id="5c06" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">令我惊讶的是，这些增加的数据对人类来说没有多大意义，但它对提高模型准确性和减少经验上的过度拟合非常有效。</p><h1 id="d898" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">实验记录</h1><p id="0558" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">我通常只是用一个简单的 CSV 和一些打印消息来记录我的实验。当有一个以上的人工作时，这就变得很乏味了。传达实验结果是很重要的。我在这场比赛中探索了<code class="fe mk ml mm mn b">Hydra</code>和<code class="fe mk ml mm mn b">wandb</code>，它们非常有用。</p><h1 id="1abc" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated"><a class="ae kc" href="https://hydra.cc/" rel="noopener ugc nofollow" target="_blank">九头蛇</a></h1><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mr"><img src="../Images/246861c8cf620c6e8c6f210b581a5581.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*opCeXdtbPWbxx5iM"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">https://hydra.cc/九头蛇</p></figure><p id="5987" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让你的实验可配置通常是个好主意。我们使用<code class="fe mk ml mm mn b">Hydra</code>来实现这个目的，这有助于组成不同的配置组。通过使您的超参数可配置，您可以通过配置文件定义一个实验并运行多个实验。通过记录带有训练统计信息的配置，很容易进行跨模型比较，并找出哪个配置对您的模型有用。我已经写了一个简短的例子,介绍如何在普通的 ML 实验中使用 Hydra。</p><h1 id="6c66" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated"><a class="ae kc" href="https://www.wandb.com/" rel="noopener ugc nofollow" target="_blank"> Wandb </a></h1><p id="4d69" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">wandb(Weight &amp; bias)做了一些事情。它提供了自动记录所有模型统计数据的内置函数，您也可以用简单的函数记录您的自定义指标。</p><ul class=""><li id="1dca" class="ms mt iq kf b kg kh kk kl ko mu ks mv kw mw la mx my mz na bi translated">比较不同实验的配置，找出性能最好的型号。</li><li id="45ea" class="ms mt iq kf b kg nb kk nc ko nd ks ne kw nf la mx my mz na bi translated">用于记录模型权重和梯度的内置函数，用于调试目的。</li><li id="0fb9" class="ms mt iq kf b kg nb kk nc ko nd ks ne kw nf la mx my mz na bi translated">记录您想要的任何指标</li></ul><p id="8e39" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所有这些结合在一起，使协作体验更好。经常同步进度真的很重要，让每个人都在一个平台上获得结果会让这些对话更容易。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ng"><img src="../Images/69e96367929dff0bd1de2c5f472b658c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SBJdl3Bo45YAeglj"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">截图取自我实验的<a class="ae kc" href="https://app.wandb.ai/" rel="noopener ugc nofollow" target="_blank"> wandb </a></p></figure><h1 id="8e7b" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated"><a class="ae kc" href="https://pytorch.org/blog/stochastic-weight-averaging-in-pytorch/" rel="noopener ugc nofollow" target="_blank">随机加权平均</a></h1><p id="76c9" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">这是一个简单而有效的技术，可以给我的模型带来 0.3-0.4%的提升。简而言之，它在训练期间拍摄模型权重的快照，并在最后取平均值。当你只训练一个模型时，它提供了一个廉价的方法来做模型集合。这对这个比赛很重要，因为它让我保持足够短的训练时间，以便在几个小时内得到反馈，并减少过度拟合。)</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nh"><img src="../Images/54198c793b20bdddb8f1edab8a27e2a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CE-hhO22dOayOLWt"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><a class="ae kc" href="https://pytorch.org/blog/stochastic-weight-averaging-in-pytorch/" rel="noopener ugc nofollow" target="_blank">https://py torch . org/blog/random-weight-averaging-in-py torch/</a></p></figure><h1 id="b25d" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">越大越好(图像尺寸)</h1><p id="452c" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">在整个比赛过程中，我们将图像尺寸缩减为 128x128，因为这使得模型训练更快，我们相信大多数技术应该可以转移到更大的图像尺寸。保持你的反馈回路足够短是很重要的(几小时，如果不是几天)。您希望训练数据尽可能小，同时保持它们可转移到整个数据集。一旦我们将我们的图像放大到全尺寸，训练一个模型需要将近 20 个小时，在比赛结束之前，我们几乎没有机会调整超参数。</p><h1 id="82e2" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">调试和检查点</h1><p id="1483" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">曾经有一段时间，我们分开开发模型，有一段时间我们没有同步代码。我们在此期间重构了我们的代码，这是一个巨大的错误。事实证明，我们的预重构代码训练了更好的模型，我们引入了一些未知的错误。因为我们改变了很多东西，所以几乎不可能找到答案。调试一个神经网络是如此困难，彻底测试它是很重要的。注入大量代码可能有助于您更早地运行实验，但是您可能会在之后花费更多的时间来调试它。</p><p id="1cce" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我认为这是适用的，即使你是独自工作。</p><ul class=""><li id="f00b" class="ms mt iq kf b kg kh kk kl ko mu ks mv kw mw la mx my mz na bi translated">保持你的变化小。</li><li id="e7cc" class="ms mt iq kf b kg nb kk nc ko nd ks ne kw nf la mx my mz na bi translated">尽早建立基线，在引入新特性后(尤其是代码重构后)总是进行回归测试</li><li id="3c1c" class="ms mt iq kf b kg nb kk nc ko nd ks ne kw nf la mx my mz na bi translated">创建随时回滚的检查点，尤其是如果您不是每天都在处理它。</li></ul><p id="8409" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">实施是 Kaggle 竞赛的关键(在现实生活中也是如此)。不管你的模型有多好，一个小小的错误可能会悄悄地破坏你的模型</p><h1 id="eb86" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">使用辅助标签</h1><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/9bf11c41d8f3c6f5028612c5450efb92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/0*Ey5noWTrgAT5YJJS"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">来自<a class="ae kc" href="https://www.kaggle.com/c/bengaliai-cv19/leaderboard" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/bengaliai-cv19/</a>的样本数据</p></figure><p id="0223" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如前所述，这个比赛需要预测<code class="fe mk ml mm mn b">root</code>、<code class="fe mk ml mm mn b">vowel</code>和<code class="fe mk ml mm mn b">consonant</code>部分。在训练数据中，他们实际上也提供了<code class="fe mk ml mm mn b">grapheme</code>。很多人说，如果你用<code class="fe mk ml mm mn b">grapheme</code>训练，它会极大地改进模型，并且很容易获得 98%的召回率。</p><p id="737e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是我们在整个比赛中无法重现的，我们在最后一刻尝试过，但似乎并没有改善我们的模型。结果是很多人过度拟合数据，因为测试数据集有更多看不见的特征。</p><p id="9503" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但这仍然是一个很好的注解，带着不是你最终想要的输出的标签训练仍然是非常有用的。</p><h1 id="f914" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">减肥课程</h1><p id="3265" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">训练数据集的分布很不平衡，但是为了得到一个好的结果，我们需要准确地预测每一个类(宏观召回)。为了解决这个问题，我们选择使用类别权重，其中较高的权重将应用于稀有样本。我们对此没有消融研究，但它似乎有助于缩小准确性和回忆之间的差距，并允许我们稍微更好地训练模型。</p><h1 id="b8f1" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">找个队友！</h1><p id="de92" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">最后，如果可以的话，请去找一个队友。开始一场 Kaggle 竞赛是很常见的，但要完成它们却不那么容易。由于工作原因，我在比赛期间停了一个月。在你停下来这么久之后，重新回到比赛中来真的很难。有一个队友有助于激励你，最终，这对我们双方来说都是一次很好的学习经历。</p><h1 id="5e04" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">预训练模型</h1><p id="636e" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">我们还尝试使用预训练模型，因为它允许更短的训练，并通过迁移学习(使用从大型数据集学习的权重作为初始权重)提供更好的性能。它也给了我们的模型一点改进。</p><ul class=""><li id="70a7" class="ms mt iq kf b kg kh kk kl ko mu ks mv kw mw la mx my mz na bi translated">微调模型头部，同时保持其他层冻结(除了 BatchNorm 层)。</li><li id="f1e8" class="ms mt iq kf b kg nb kk nc ko nd ks ne kw nf la mx my mz na bi translated">解冻模型，一起训练所有层。</li></ul><p id="45da" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我还尝试了在完全不冻结任何层的情况下，直接用区分学习率来训练模型。它的表现类似于冻结微调，所以我最后只是从头开始训练整个模型。</p><h1 id="74ff" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">如果代码有效，就不要碰它</h1><p id="56eb" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">这可能不是一个好习惯，但我建议不要为了一场比赛而这样做。在代码重构之后，我们花了大量的时间来调试我们的代码，最终只是回滚到一个旧的提交并挑选新的特性。在比赛中，你没有足够的时间去测试所有的东西。你不需要一个漂亮的抽象类来容纳你的所有特性，可能需要一些重构来保持你的函数/类的整洁，但是不要在这上面花费太多时间。在框架之间跳转甚至很常见(你可能会发现别人的内核很有用)，所以不可能完美地构建你的代码。</p><ul class=""><li id="e475" class="ms mt iq kf b kg kh kk kl ko mu ks mv kw mw la mx my mz na bi translated">如果有人已经创建了一个工作提交脚本，使用它！</li><li id="1471" class="ms mt iq kf b kg nb kk nc ko nd ks ne kw nf la mx my mz na bi translated">如果有人已经创建了一个工作的预处理函数，使用它！</li></ul><p id="8627" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">除非有必要，否则不要花时间去优化这些代码，因为在竞争环境中这样做通常是不值得的。你应该专注于增加新的功能，尝试新的模型，测试新的增强技术。</p><h1 id="6532" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">摘要</h1><p id="3ff5" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">这是一次很棒的学习体验，刷新了我一些过时的计算机视觉模型知识。如果你从未参加过比赛，找个朋友开始吧。如果你刚刚完成了一个，试着写出来，分享你的经验。😉</p></div></div>    
</body>
</html>