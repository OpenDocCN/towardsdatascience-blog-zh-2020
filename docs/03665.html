<html>
<head>
<title>Learn Principal Component Analysis in R</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">学习R中的主成分分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/learn-principle-component-analysis-in-r-ddba7c9b1064?source=collection_archive---------26-----------------------#2020-04-06">https://towardsdatascience.com/learn-principle-component-analysis-in-r-ddba7c9b1064?source=collection_archive---------26-----------------------#2020-04-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/d47abfd6b0e9bd06fb7772165fb9a037.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*6Su4HVKi3JLP5RXOsFTk9g.jpeg"/></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">图片来自<a class="ae kb" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1452987" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae kb" href="https://pixabay.com/users/Pavlofox-514753/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1452987" rel="noopener ugc nofollow" target="_blank"> Pavlofox </a></p></figure><h1 id="5caa" class="kc kd it bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">使用PCA改进您的特征选择过程</h1><p id="d6d0" class="pw-post-body-paragraph la lb it lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">PCA是一种降维技术；这意味着您在建模过程中包含的每个额外变量都代表一个维度。</p><p id="346e" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated"><strong class="lc iu">它是做什么的？:</strong></p><p id="9c0f" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">就PCA实际做的事情而言，它采用高维度的数据集，并将其缩减为少数<em class="md">不相关的</em>成分。需要考虑的是不相关组件的概念。如果我使用客户的收入(如果我碰巧有)&amp;来预测他们的收入，那么我会添加一个额外的变量来表示他们的邮政编码中值收入，这两个变量很可能是相关的，下一个变量不太可能对我的模型准确预测收入的能力产生积极影响。</p><p id="e3f4" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">我刚才解释的想法是多重共线性。给定变量的一个预测因子可以由其他预测因子预测的想法。或者回到我刚才举的例子，实际收入可以通过他们所在地区的收入中值来预测；这两者可能是共线的。</p><p id="7353" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated"><strong class="lc iu">入门</strong>:</p><p id="861c" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated"><strong class="lc iu">组件</strong> <strong class="lc iu">是如何确定的？</strong></p><p id="59da" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">确定每个分量是因为它占了最大的方差，并且根据所占方差的下一个最大部分来选择每个后续分量。因此，组件1将占最大的差异，组件2将占第二大的差异，以此类推。</p><p id="edd9" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated"><strong class="lc iu">步骤:</strong></p><ul class=""><li id="a79a" class="me mf it lc b ld ly lh lz ll mg lp mh lt mi lx mj mk ml mm bi translated">缩放数据集</li><li id="8d1e" class="me mf it lc b ld mn lh mo ll mp lp mq lt mr lx mj mk ml mm bi translated">创建pca对象— prcomp</li><li id="8730" class="me mf it lc b ld mn lh mo ll mp lp mq lt mr lx mj mk ml mm bi translated">打印特征值</li></ul><p id="e412" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">首先，加载R数据集，mtcars</p><p id="d346" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated"><code class="fe ms mt mu mv b">data(mtcars)</code></p><p id="2256" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">接下来，PCA最适合处理数值数据，所以您需要过滤掉任何非数值的变量。在我们的例子中，我们将使用dplyr select函数删除变量<code class="fe ms mt mu mv b">vs</code> &amp; <code class="fe ms mt mu mv b">am</code>。</p><p id="ec2f" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated"><code class="fe ms mt mu mv b">mtcars &lt;- mtcars %&gt;% select(- c(vs, am))</code></p><p id="59d4" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">让我们将更新的、只有数字数据的数据集放入pca函数中，<code class="fe ms mt mu mv b">prcomp.</code></p><p id="a8cc" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated"><code class="fe ms mt mu mv b">pca &lt;- prcomp(mtcars, center = TRUE,scale. = TRUE)</code></p><p id="d2f4" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">这里需要记住的是缩放。缩放的目的是标准化变量间的方差。为什么有人会关心你问？因为每个组成部分背后的想法是，它们尽可能多地解释了差异。没有这种缩放，您的高方差变量将在您的组件中被过度表示。</p><p id="8dce" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated"><strong class="lc iu">现在，我们应该保留多少组件？？:</strong></p><p id="a286" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">在我们开始这一节之前，要记住的是，我们正试图减少我们的尺寸，因此最大限度地减少不必要的组件是理想的。</p><p id="cacb" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">在决定保留多少组件时，我将给出三个主要考虑事项。</p><p id="9174" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">对于第一个跟随！</p><p id="2d1b" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated"><code class="fe ms mt mu mv b">summary(pca)</code></p><figure class="mx my mz na gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi mw"><img src="../Images/9dbb9f9e134fdfc3f71f638dc1a82bb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*essaMFkPoLSRhPLF.png"/></div></div></figure><p id="7872" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">我们在这里寻找的是<code class="fe ms mt mu mv b">proportion of variance</code>。正如我们一直在谈论的，这个想法是围绕着解释变异；如果你继续下去，你会看到第一个组成部分，<code class="fe ms mt mu mv b">PC1</code>占变异的62.8%，<code class="fe ms mt mu mv b">PC2</code>占23%，以此类推。</p><p id="c36a" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">有了这些信息，你就可以考虑用最少数量的组件来解释你需要多少差异。这可能是您决定第一个组件的63%就足够了，它可能是86%的前两个，或91%的三个。</p><p id="a565" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">考虑这类问题的一个有用工具是碎石图。</p><figure class="mx my mz na gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi nf"><img src="../Images/f851d13688f7aafd44b77ad654901875.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*99mA3lT4z0lWkpXk.png"/></div></div></figure><p id="65b5" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">你会看到在碎石图上，我在x轴上画出了分量，在y轴上画出了分量的重要性。我们在上面看到的是，在第二个组件之后，每个附加组件的增量影响会显著下降。虽然有人可能会认为第三个组件的影响非常重要，足以得出值得包含第三个组件的结论，但不太可能有人会认为应该添加更多组件。</p><p id="724f" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">你可能会做的下一个评估是所谓的凯泽-古特曼准则。这里的规则很简单；仅保留特征值大于1的组件。</p><p id="c237" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">如果你不知道如何立即得到特征值；跟我来一次快速旅行吧。要获得每个组件的特征值，您只需要从pca对象中找到每个组件的方差或标准差的平方——如下所示。</p><p id="ce72" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated"><code class="fe ms mt mu mv b">pca$sdev ^ 2</code></p><figure class="mx my mz na gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi ng"><img src="../Images/cbc2e1cbd3af3a5b207e92b4689e4d92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hyccOyiiFsmZ_ZwO.png"/></div></div></figure><p id="aee6" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">如前所述，您将消除任何特征值不大于1的变量。这背后的想法是，如果特征值小于1，那么该组件比单个变量贡献的方差更小。</p><p id="9400" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">基于我们所使用的方法，很明显我们在这里的路线是只使用前两个组件</p><p id="ad0d" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated"><strong class="lc iu">了解您的组件:</strong></p><p id="bc56" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">知道你的组件是由什么组成的很重要。换句话说，哪些变量对任何给定的分量有贡献？geom_hline(yintercept=20)了解组件由什么组成很重要。换句话说，哪些变量对任何给定的分量有贡献。</p><p id="1ebc" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated"><code class="fe ms mt mu mv b">print(pca$rotation)</code></p><figure class="mx my mz na gt ju gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/6556987df0aba95ef9a106149e320beb.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/0*BO2sP1x-J8seejS4.png"/></div></figure><p id="134b" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">看着第一个组成部分的各种贡献，我可能会努力建议第一个组成部分在很大程度上代表了汽车的动力或性能，如汽缸、马力、重量和显示为最高。</p><p id="131b" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">另一个可以很容易看到不同变量分组的方法是双标图。</p><p id="f308" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated"><code class="fe ms mt mu mv b">pca %&gt;% biplot(cex = .5)</code></p><figure class="mx my mz na gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi ni"><img src="../Images/0b057bc48dc1c660340486a8bcd6ddcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*O45JCdqUC2YFtc6M.png"/></div></div></figure><p id="b434" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">正如我之前提到的，你可以看到气缸、马力、显示和重量都分组在一起。</p><p id="ba97" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated"><strong class="lc iu">使用线性回归将您的组件与原始变量进行比较:</strong></p><p id="3b47" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">为了确定使用常规变量与主成分的潜在预测影响，让我们使用每组进行回归，并比较每个模型的r平方。</p><p id="dc9c" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">对于每次回归，我们将尝试使用<code class="fe ms mt mu mv b">mtcars</code>数据集中的其他变量来预测MPG。</p><p id="e7ec" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">我们现在将创建第一个模型，按原样预测所有变量。</p><p id="33c9" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated"><code class="fe ms mt mu mv b">fit_1 &lt;- lm(mpg ~ ., data = mtcars)</code></p><p id="a027" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">现在让我们创建包含mpg和前两个组件的下一个数据集。</p><p id="6662" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated"><code class="fe ms mt mu mv b">components &lt;- cbind(mpg = mtcars[, "mpg"], pca$x[, 1:2]) %&gt;%<br/> as.data.frame()</code></p><p id="945b" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">现在，我们将使用这些组件训练第二个模型</p><p id="132a" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated"><code class="fe ms mt mu mv b">fit_2 &lt;- lm(mpg ~ ., data = components)</code></p><p id="3d1f" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">现在到了关键时刻，让我们比较一下每个模型的r平方！</p><p id="11a8" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated"><code class="fe ms mt mu mv b">summary(fit_1)$adj.r.squared</code></p><p id="7417" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated"><code class="fe ms mt mu mv b">summary(fit_2)$adj.r.squared</code></p><figure class="mx my mz na gt ju gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/6bffeffee81402bdfbdd9073b077b88e.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/0*Xwt6-nleF9T6uiyO.png"/></div></figure><p id="089b" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">正如你在上面看到的，当只使用两个组件时，模型的r平方有一个不那么小的变化。</p><p id="54d9" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated"><strong class="lc iu">结论</strong></p><p id="6c2f" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">我希望这有所帮助！这里要记住的最后一点是，这里的唯一目的是在不损失太多预测能力的情况下进行简化。请随意查看我在datasciencelessons.com的其他帖子&amp;祝数据科学快乐！</p></div></div>    
</body>
</html>