# 理解概率和统计:数据科学家的概率基础

> 原文：<https://towardsdatascience.com/understanding-probability-and-statistics-the-essentials-of-probability-for-data-scientists-459d61a8da44?source=collection_archive---------2----------------------->

## 为统计学家解释概率的关键概念

数据科学领域围绕着概率和统计。因此，对这些概念有一个坚实的理解是至关重要的。

> 本文意在解释*概率*的要领。

![](img/b18e08b02d45037141563c06437476cb.png)

概率与统计

我将写一些关于概率和统计的文章。他们打算从头开始解释这些概念。

本文是该系列的第一篇。

# 为什么要从概率入手？

概率无处不在！

这样想吧；概率是不确定性的科学。因此，每当对一个事件的发生有任何怀疑时，概率的概念就被用来估计一个事件发生的可能性。如果我们想预测一个变量的结果，这个变量可以取许多可用值中的一个，那么我们必须涉及概率的数学。我们要做的就是给一个事件分配一个数字，比如明天下雨的可能性是 30%。

考虑到这一点，难道我们一生都要用到概率论吗？我们会在考试、工作和决策中取得成功吗？我们怎样才能增加成功的机会？

> 因此，理解概率是至关重要的。

明天真的会是晴天吗？股票价格会保持不变直到明天吗？我们有多确定？在接下来的一个小时内，我们接到电话的可能性有多大？

概率是一门极其重要的学科，我决定以概率为主题开始我的系列文章。

*根据每个人的兴趣，在随后的文章中，我将解释中心极限定理、大数定律、收敛如何工作、马尔可夫链、概率转移、概率分布的模拟，我们还将更深入地研究联合和边际分布及其估计。我的目标是用简单的方式解释复杂的概念。随后，我还将解释统计的主题。这将为数据科学奠定坚实的基础。*

# 文章目标

本文的目的是解释以下六个要点:

1.  什么是概率空间？
2.  什么是随机变量？
3.  概率规则
4.  什么是期望？
5.  什么是方差和协方差？
6.  什么是概率分布？

# 1.什么是概率空间？

这一节将通过解释概率空间来开始概率的主题。概率空间的概念构成了概率论的基础，因此理解它是很重要的。

概率空间用于模拟实验。这是一个数学概念，也称为概率三元组。

概率空间有三个组成部分:

![](img/ea1c9f610f84477a09025b4e2d65b4cb.png)

概率三元组的三个组成部分

**1。一个样本空间:**

这是所有可能结果的集合。数学中的集合是元素的独特集合。

作为一个例子，骰子的样本空间是:S= {1，2，3，4，5 和 6}

股票价格运动的样本空间可以是 S = {增加，相同，减少}。由于 Increase 是 S 的一个元素，我们可以把它写成 Increase ∈ S

现在要记住的关键是样本空间可以是一个无限集。例如，一个国家的人口是不断变化的，它是一个具有无限可能性的随机数。

**2。事件集合:**

这是一个包含结果组合的集合。因此，它是样本空间子集的集合。集合中的每个元素称为一个事件。

例如，掷骰子事件的子集可以是{1}、{1，2}等等。

因此，重要的是要注意样本空间(1)是一组事件(2)的元素。S ∈ F

**3。概率度量——事件如何分配给概率的函数:**

每个事件都有一个概率。概率可以是 0 到 1 之间的任何值。需要注意的关键是，它是一个不能大于 1 的非负数。值 1 意味着该事件肯定会发生，而值 0 意味着该事件永远不会发生。

作为一个例子，投掷一个不偏不倚的公平骰子可以导致 6 个可能结果中的一个，因此每个结果有 1/6 的概率。因此得到 4 的概率是 P(4) = 1/6

> 事件发生的可能性越大，概率度量就越高。

![](img/896d235897bdda87e390c04e12f6844f.png)

显示骰子不同可能结果的草图

> 所有样本空间的概率之和为 1

空集的概率为 0。这意味着没有结果不会发生。

> 现在，我想让大家从第一节学到的一个重要概念是，概率测度也是可加的。这意味着，如果我们想要计算一个复杂事件的概率，那么我们可以将组成复杂事件的简单事件的概率相加——只要它们是不相关的。

例如，骰子显示 1 或 4 的概率为

*2/6(得到 1 的 1/6 加上得到 4 的 1/6)*

# 2.什么是随机变量？

让我们进入随机变量的下一部分。在阅读金融论文时，我们经常会遇到“可测量的”或“可观察的”这两个术语。术语“可观察”代表实验中可以测量的随机变量。

随机变量本身就是一个函数。它将一个状态空间映射到一组数字，因此随机变量是一个本质上随机的结果。每一个结果都有与之相关的概率。

举例来说，考虑一个国家的 GDP 是一个随机变量。它可以被认为是许多变量和常数的函数。每个事件都有一个与之相关的概率度量。

这个世界充满了随机变量。例如，世界人口取决于时间、掷骰子、掷硬币、一周的天数、利率、汇率、黄金价格等。都是随机变量。

> 随机变量可以是离散的，也可以是连续的。

## **2.1 离散随机变量**

离散随机变量是一个有有限可能结果的变量。这些结果也可以是无限的，但是要注意的关键是有限的结果集的和应该是 1。

例如，掷骰子、掷硬币、一周中的几天、特定铅笔盒中的颜色、性别、月份、一个月中的几天等等。都是离散随机变量的例子。

![](img/95de6823d12785212527c5c721ff115e.png)

## 2.2 连续随机变量

不是离散的随机变量是连续的随机变量。它有无数可能的结果，无法计算。

例如，依赖于时间、利率、汇率、黄金价格、毫米降雨量等的世界人口。都是连续随机变量的例子。

![](img/36dc43faa7d68c3d3287e7b7c89376d5.png)

> 本节的关键是随机数是结果的函数，其中每个结果都是随机的，并且有与之相关的概率。

# 3.概率规则

本节将概述概率规则，这对理解概率规则非常重要。

假设我有一枚标准的硬币，有两面:正面和反面。

因此，如果我在空中抛硬币，当它落在我手上时，我可能会看到正面或反面。对于一个公平的硬币，得到正面 P(正面)的概率是 0.5，得到反面 P(反面)的概率也是 0.5。

![](img/4ed17f63c517f21874388c42c84857ed.png)

获得正面的概率为 0.5

![](img/795f51da927d9f69a0d2947335584063.png)

0.5 的概率得到尾巴

我们可以看到正面和反面都是两种可能的结果。概率测度之和为 P(正面)U P(反面)= (0.5 + 0.5) = 1。

需要注意的关键是，**还是指加**。

如果我们掷两枚硬币，那么两次都看到正面的概率是 P(正面)x P(正面)。这就是乘法原理。

如果我们抛两个硬币，那么看到正面或反面的概率是 1，因为 or 意味着加法。这就是加法原理。

这两个事件是相互独立的，因为抛一次硬币不会影响我们下一次试验的结果。

现在，考虑一个稍微复杂的例子。假设我们站在路边，数着从我们身边驶过的汽车的颜色和大小。

这个例子应该有助于我们更好地解释概率规则。

这个圆圈代表路上所有从我们身边驶过的汽车。这是我们的样本集:

![](img/9414198762a9ef2f2220606fc4581e9e.png)

下面的红色小圆圈代表所有的红色汽车。r 的补码写成 Rᶜ.A 的补集不是 A 的集合。

![](img/6678938e3ec86b80b0096b9335e8a674.png)

在这种情况下，r 以外的任何东西都是 Rᶜ:

![](img/66be956499bce51545a5fdc4ea1a919a.png)

一辆车是红色的概率是 P(R)

**车不红的概率是 1-P(R)**

迷你蓝色圆圈代表所有蓝色汽车:

![](img/171edce8571b26cf1b0bd577a38e9f39.png)

汽车为红色和蓝色的概率为 0，因为它们是不相交的事件。

汽车是红色或蓝色的概率是 P(R) U P(B) = P(R) + P(B)

所有大型汽车都画在绿色圆圈中:

![](img/b3f39bb0153c93fcaca5de8db3cde8cc.png)

在上图中，只有大型红色汽车。这在图像中标记为黄色，显示了红色圆圈与绿色圆圈相交的部分。

一辆车又红又大的概率是:

*P(R 和 L) = P(R) x P(L|R)*

这就是众所周知的贝叶斯规则，它是数据科学中需要记住的基本规则之一。

这里的“|”是“鉴于”的意思。这意味着一辆红色大汽车的概率是一辆红色汽车的概率乘以一辆红色大汽车的概率。P(L|R)是条件概率。

这是一个非常强大的公式，我们可以用它在机器学习算法中建立统计推断。

因此，我将为此专门写一篇文章。

# 4.什么是期望？

在解释什么是期望之前，我想先说明一下中位数的概念。

## 中位数

如果我们取一组数字，对它们进行排序并计算 CDF，那么区间(a，b)的中值计算如下:

![](img/b93d8458e3dbf648360ca6c12a608d1f.png)

这个公式将给出中点，即集合的索引，也就是中值。注意:a 和 b 是集合的索引，而不是集合的实际元素，例如，在集合{1，5，8，10}中，5 的索引是 2，10 的索引是 4。随后，区间(2，4)的中值为 3。中点 3 指向数值 8。

## 预期

期望值就是平均值。通过对事件的概率求和来计算: *∑ ₓ pₓ(x)*

如果随机变量是连续的，那么期望是∫ *xf(x)dx，*

如果我们将一个可观察值乘以一个常数，那么新的期望值就是该常数乘以原始期望值:

![](img/9878f647a2bba6f56c164931383bc116.png)

如果我们把两个可观测量加在一起，那么它们的联合期望是:

![](img/c933210c6cb1cbed54ca9f2b8295969c.png)

两个可观测量是独立的，如果它们的交集不包含任何元素。因此，这两个可观测量彼此不相关，并且它们的联合期望只是将它们的期望相乘:

![](img/902add70468daa4f979d071d065e0d7e.png)

如果这两个可观测量不是独立的，那么我们需要考虑它们的协方差。

# 5.什么是方差和协方差？

随机变量可以向任何方向移动。标准差衡量随机变量与其平均值或期望值的偏差。方差是标准差的平方。

如果两个可观测量是独立的，那么没有共同运动，它们的协方差是 0。常数的方差为 0。

一旦我们知道了期望值，我们就可以计算方差:

![](img/3b7f16f6b301f0a1ae2453fce34fe11f.png)

两个随机变量 X 和 Y 的协方差为:

![](img/66853b17e3f38cb7f8d1020acbf9cec8.png)

我们也可以将协方差计算为:

![](img/83771faf045b73979d3d775e14eb55c1.png)

关于协方差，有一些重要的注意事项需要了解:

如果我们取两个可观测值 X 和 Y，给它们各加一个常数，再乘以一个常数，那么协方差将如下变化:

![](img/e2d56ce2adbef9a3eca29a3a783e74a9.png)

注意，b 和 d 完全消失了，因为它们没有改变 X 或 y 的方差。

如果两个可观测量不是独立的，那么当我们将两个可观测量相加时，它们的联合方差将变成:

![](img/cf0efda1d27f1bfb2d5dc46d78146177.png)

在这里，协方差被用作两个变量是相互依赖和相互关联的。

# 6.什么是概率分布？

让我们进入概率论的核心。我可以向你保证，到目前为止，我们已经学习了数据科学家必须知道的概率学科的基础知识。

![](img/1bf48625b747b7e8989e9468c4b71ea6.png)

每一个花时间评估数据和执行功能工程的数据科学家都必须遇到以下术语；高斯分布、正态分布、二项式分布、泊松分布、指数分布等等。

本节将解释这些概率分布是什么。

## 让我们来理解概率分布:

随机变量有一个概率分布。它的意思是随机变量 X 的分布是 X 的所有子集的概率的集合。

首先，知道一个随机变量的概率分布是一个非常强大的工具，因为它可以帮助你估计一个变量的运动。

此外，多个随机变量可以具有相同的概率分布。这很有趣，因为如果有两个我们可以测量(观察)的随机变量具有相同的分布，那么我们可以使用第一个变量来了解另一个变量的行为，并将其视为彼此的代理。因此，我们可以建立更好的模型。重要的是要注意，我们不能假设这两个可观测量是相同的，因此评估和理解变量的行为是至关重要的。

如果我们记录一个随机变量的结果及其概率，那么我们可以建立一个概率分布。

一旦我们有了可能的结果集，我们就可以计算它们的概率，然后计算概率的分布。从概率分布，我们可以计算一个概率分布函数。

分布函数必须遵循以下属性:

1.  它不是递减的
2.  它是右连续的
3.  当 x 移动到-无穷大时，它移动到 0，当 x 移动到无穷大时，它移动到 1。

## 最常见的概率分布

概率分布有它自己的形状、行为和性质。我将解释数据科学项目中最常用的发行版。

## 6.1 均匀分布

如果所有事件的概率测度相同，则随机变量 X 具有均匀分布。它也被称为矩形分布，因为所有的事件都有一个恒定的概率。

![](img/f6901c363d0d138f3cf76b75afef656b.png)

这张草图显示了均匀的分布

形式上，如果可观测值是离散的，那么概率密度函数可以写成:

![](img/eaec20a973e2c1e1dd39e930ed01da53.png)

n 是集合的大小。

例如，如果变量是骰子，则 n 是 6，如果随机变量是硬币，则 n 是 2。

一枚公平的硬币可以处于两种状态之一；正面和反面。每个状态都有 50%的概率发生。因此，公平的硬币有均匀的分布。

如果可观测值是连续的，那么两个区间 a 和 b 之间的概率密度函数可以写成:

![](img/7e0c26a70b916a429a2319968879f39d.png)

b 是最大点，a 是最小点。

因此，分布由两个参数定义:最小值和最大值

**例子**

我举个例子解释一下均匀分布。

让我们考虑一下，我们正在测量一个城市中 5 岁儿童的平均身高。我们再考虑一下，高度从 0 到 3 英尺是均匀分布的。

一个 5 岁儿童身高从 1 英尺到 2 英尺的概率是:

(2–1 英尺)* (1/3 英尺)= 1/3

## 6.2 指数分布

![](img/b2c46637164a0b228c7b94b6fc17b251.png)

这张草图显示了指数分布

当我们想要对事件发生之间经过的时间建模时，大多数连续随机变量具有指数分布。

指数分布围绕着速率参数λ。这个值告诉我们一个事件发生的速率。例如，如果每 10 分钟有一辆红色汽车从我们身边驶过，那么红色汽车从我们身边驶过的速度是每分钟的 1/10。

因此λ是 0.1。

因此λ告诉我们单位时间内事件之间的比率。

指数分布适用于连续的随机变量。

当随机变量具有指数分布时，其分布函数为:

![](img/d0281f5e6cfc756414cb593f4dedd102.png)

指数分布是无记忆的，它不依赖于过去。

还值得注意的是:

*   指数分布的期望是:1/λ
*   方差为 1/λ

## 6.3 正态分布

![](img/748666e95ce27e0a6d2c0c4867c7cbae.png)

草图显示了正态分布

最重要和最著名的分布之一是正态分布。它出现在中心极限定理中。它也被称为钟形曲线。

正态分布很容易解释。原因是:

1.  分布的均值、众数和中位数相等。
2.  我们只需要用均值和标准差来解释整个分布。

正态分布也称为高斯分布。它的密度取决于两个参数:均值和方差。

该功能是:

![](img/c8a1ed6c220996f6bc65e10b9fd4df8c.png)

标准的正态分布是 N(0，1)。意味着标准正态分布的随机变量的均值为 0，方差为 1。

请务必注意正态分布的以下属性:

1.  将一个数 **z** 乘以正态分布与将 z 乘以均值和方差具有相同的效果。
2.  将数字 z 加到正态分布上的效果与将数字 z 加到平均值上的效果相同。对分布的方差没有影响。
3.  如果两个随机数 X 和 Y 是独立的，并且具有正态分布，那么将 X 和 Y 相加将创建一个新的具有正态分布的随机变量 Z。然而，Z 的平均值将是 X 和 Y 的平均值之和，方差将是 X 和 Y 的方差之和。

如果你想了解更多关于正态分布的知识，请阅读这篇文章:

[](https://medium.com/fintechexplained/ever-wondered-why-normal-distribution-is-so-important-110a482abee3) [## 想过为什么正态分布如此重要吗？

### 解释为什么高斯分布是如此成功和广泛使用的概率分布

medium.com](https://medium.com/fintechexplained/ever-wondered-why-normal-distribution-is-so-important-110a482abee3) 

## 6.4 伯努利分布

假设我们想抛硬币。结果可能是正面或反面。如果得到正面的概率是 *p* ，那么得到反面的概率是 1-p。p 的值总是 0 < p < 1

可以取两种可能状态之一的随机变量被认为具有伯努利分布。为了概括起见，我们可以把这两种可能的状态称为成功或失败。成功是指我们的目标事件发生时的状态，而失败是指我们的目标没有发生时的状态。

伯努利分布有一个参数 p:

![](img/abddc4112958979b6cfed9d3b59bd0ad.png)

这张草图显示了伯努利分布

p(成功)= p

p(故障)= 1–p

期望值是 p，方差是 p(1 - p)

**举例**

我举个例子解释一下伯努利分布。假设交易对手违约的概率为 10%。这意味着有 90%的可能性交易对手会**而不是**违约。

这是一种伯努利分布，因为交易对手可以采取两种可能状态中的一种。在这种情况下，p 的值是 0.1。

随后，分布的方差为:

*0.1 *(1–0.1)= 0.1 * 0.9 = 0.09*

## 6.5 二项式分布

最常用的分布之一是二项分布。它与伯努利分布非常相似。不同的是，我们可以把伯努利分布看作二项分布的特例。

例如，如果我们想要衡量 *n* 个交易对手的违约，其中每个交易对手可能处于两种可能状态(违约或非违约)中的一种，所有交易对手都具有相同的违约概率(p ),并且它们是独立的，那么变量的分布将是二项式分布。

> 为了简化，伯努利分布作为二项分布的特例，其中 n 为 1。

考虑到有 *n 个独立的*随机变量，并且每个变量都有一个带有相同参数 *p* 的伯努利分布，那么如果我们将这些变量相加，那么它们的总和将是一个带有参数 n 和 p 的二项分布。

概率分布是:

![](img/928c8b6ee0fb7fbe04c134190f3af7b4.png)

这张草图显示了二项式分布

期望值是 **np** 方差是 **np(1-p)**

![](img/b56178d8c68561ffafb6968685e12676.png)

## 6.6 几何分布

![](img/75db28f11fec347ac565825d1a2539a0.png)

这张草图显示了几何分布

几何分布真的很有意思。同样，它与二项式分布有些关系。这种分布通常出现在变量中，实验是计算在遇到目标事件之前我们看不到目标事件的次数。

我来详细说明一下。假设我们想测试一个交易对手是否违约。如果我们开始记录已经违约的交易对手的数量，直到我们遇到第一个没有违约的交易对手，那么变量将遵循几何分布。需要注意的是，在这种情况下，交易对手的违约被认为是相互独立的。

几何分布和指数分布是相关的，我们可以将指数分布视为几何分布的连续版本。

几何分布的概率分布函数是:

![](img/629fdd65190942ac67d67834de055483.png)

它非常类似于指数分布；把它想象成指数分布的离散版本。

## 6.7 泊松分布

![](img/f578103f5c9d42936a75ba6b75d4a48c.png)

这张草图显示了泊松分布

泊松分布与指数分布密切相关。泊松分布总是包含一个时间维度。泊松分布可以帮助我们理解独立事件在未来什么时候会发生。

举例来说，如果我们想测量**何时**我们会看到一辆红色汽车从我们身边驶过，或者**何时**一个交易对手会违约，那么随机变量遵循泊松分布。

泊松分布是离散的。该分布围绕一个参数λ，它告诉我们每单位时间内成功的平均次数。

如果存在均值为λ的随机变量 X，则它的概率分布为:

![](img/f29affeaa496f6ff0a7510b2ce6260a5.png)

随机变量 X 的期望值为λ，方差为λ。

两个独立泊松分布之和也是泊松分布。

# 7.摘要

数据科学领域围绕着概率和统计。这篇文章旨在解释我们都应该熟悉的概率的本质。这篇文章是这个系列的第一篇，它仅仅触及了概率和统计的皮毛。

![](img/468d49f7ac79e66a8fc1c73426e30d3e.png)

感谢您的阅读

文章阐述了以下六个要点:

1.  什么是概率空间？
2.  什么是随机变量？
3.  概率规则
4.  什么是期望？
5.  什么是方差和协方差？
6.  什么是概率分布？

取决于每个人有多感兴趣，在随后的文章中，我将解释中心极限定理、大数定律、收敛如何工作、马尔可夫链、概率转移，我们还将更深入地研究分布及其估计。这将为统计奠定坚实的基础。