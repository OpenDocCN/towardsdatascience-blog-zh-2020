<html>
<head>
<title>Predictive Analytics: Time-Series Forecasting with GRU and BiLSTM in TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">预测分析:用 TensorFlow 中的 GRU 和比尔斯特姆进行时间序列预测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/predictive-analytics-time-series-forecasting-with-gru-and-bilstm-in-tensorflow-87588c852915?source=collection_archive---------0-----------------------#2020-08-30">https://towardsdatascience.com/predictive-analytics-time-series-forecasting-with-gru-and-bilstm-in-tensorflow-87588c852915?source=collection_archive---------0-----------------------#2020-08-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/6fa704cc47b7ff7f9e8a36437df4fc4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e1CZHGfu1MdFfk1VGUM91w.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">Enrique Alarcon 在<a class="ae jg" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><div class=""/><div class=""><h2 id="6f27" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">为时序预测构建 GRU 和双向 LSTM 的分步教程</h2></div><p id="2c1b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi lu translated"><span class="l lv lw lx bm ly lz ma mb mc di"> R </span>当前的神经网络被设计用来处理时序分析中序列相关性的复杂性。在本教程中，我为一个单变量时间序列预测模型建立 GRU 和比尔斯特姆。门控循环单元(GRU)是新一代的神经网络，非常类似于长短期记忆(LSTM)。而双向 lstm(bil STM)的思想是在 LSTM 模型中聚合特定时间步长的过去和未来的输入信息。</p><p id="7844" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面这篇文章很好地介绍了 LSTM、GRU 和比尔斯特姆。</p><div class="is it gp gr iu md"><a rel="noopener follow" target="_blank" href="/predictive-analysis-rnn-lstm-and-gru-to-predict-water-consumption-e6bb3c2b4b02"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jk gy z fp mi fr fs mj fu fw ji bi translated">预测分析:TensorFlow 中的 LSTM、GRU 和双向 LSTM</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">关于开发 LSTM、GRU 和双向 LSTM 模型来预测用水量的分步指南</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">towardsdatascience.com</p></div></div><div class="mm l"><div class="mn l mo mp mq mm mr ja md"/></div></div></a></div><h1 id="8551" class="ms mt jj bd mu mv mw mx my mz na nb nc kp nd kq ne ks nf kt ng kv nh kw ni nj bi translated">什么是时间序列分析？</h1><p id="6d8e" class="pw-post-body-paragraph ky kz jj la b lb nk kk ld le nl kn lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">与回归分析不同，在时间序列分析中，我们没有强有力的证据表明什么影响了我们的目标。时间序列分析使用时间作为变量之一，以观察是否随时间发生变化。</p><h1 id="4fa9" class="ms mt jj bd mu mv mw mx my mz na nb nc kp nd kq ne ks nf kt ng kv nh kw ni nj bi translated">什么是时间序列预测？</h1><p id="83d1" class="pw-post-body-paragraph ky kz jj la b lb nk kk ld le nl kn lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">时间序列预测的目的是根据历史数据拟合一个模型，并使用它来预测未来的观测值。这篇文章致力于使用深度学习方法进行时间序列预测。如果你愿意学习时间序列预测的经典方法，我建议你阅读这个<a class="ae jg" href="https://machinelearningmastery.com/time-series-forecasting-methods-in-python-cheat-sheet/" rel="noopener ugc nofollow" target="_blank">网页</a>。</p><h1 id="9dd4" class="ms mt jj bd mu mv mw mx my mz na nb nc kp nd kq ne ks nf kt ng kv nh kw ni nj bi translated">☺让我们去 code❗</h1><p id="c18f" class="pw-post-body-paragraph ky kz jj la b lb nk kk ld le nl kn lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated"><strong class="la jk">👩‍💻</strong> <a class="ae jg" href="https://github.com/NioushaR/LSTM-TensorFlow-for-Timeseries-forecasting" rel="noopener ugc nofollow" target="_blank"> <strong class="la jk">上的 Python 代码 GitHub </strong> </a></p><h2 id="449e" class="np mt jj bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">资料组</h2><p id="00aa" class="pw-post-body-paragraph ky kz jj la b lb nk kk ld le nl kn lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">对于本项目，数据为加拿大魁北克省 Brossard 市 2011 年 9 月 1 日至 2015 年 9 月 30 日的日用水量。</p><h2 id="f020" class="np mt jj bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">导入库</h2><pre class="ob oc od oe gt of og oh oi aw oj bi"><span id="6123" class="np mt jj og b gy ok ol l om on">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt</span><span id="296c" class="np mt jj og b gy oo ol l om on">from sklearn.preprocessing import MinMaxScaler, StandardScaler</span><span id="3de7" class="np mt jj og b gy oo ol l om on">import warnings<br/>warnings.filterwarnings(‘ignore’)</span><span id="48f4" class="np mt jj og b gy oo ol l om on">from scipy import stats<br/>%matplotlib inline</span><span id="d689" class="np mt jj og b gy oo ol l om on">import tensorflow as tf<br/>from tensorflow import keras<br/>from tensorflow.keras import Sequential, layers, callbacks<br/>from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional</span></pre><h2 id="7df3" class="np mt jj bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">设置随机种子</h2><pre class="ob oc od oe gt of og oh oi aw oj bi"><span id="f07a" class="np mt jj og b gy ok ol l om on">tf.random.set_seed(1234)</span></pre><h1 id="9717" class="ms mt jj bd mu mv mw mx my mz na nb nc kp nd kq ne ks nf kt ng kv nh kw ni nj bi translated">1.读取和浏览数据</h1><p id="6747" class="pw-post-body-paragraph ky kz jj la b lb nk kk ld le nl kn lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">在这个项目中，我处理的是单变量时间序列数据。当我从 CSV 文件导入数据时，我通过<strong class="la jk"> parse_dates = ['Date'] </strong>确保<strong class="la jk"> Date </strong>列具有正确的<em class="op"> DateTime </em>格式。此外，当我处理日期和时间时，如果我将<strong class="la jk">日期</strong>列设置为 dataframe 索引，就会变得容易得多。</p><pre class="ob oc od oe gt of og oh oi aw oj bi"><span id="f81f" class="np mt jj og b gy ok ol l om on">df = pd.read_csv(‘Data.csv’, parse_dates = [‘Date’])</span></pre><figure class="ob oc od oe gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oq"><img src="../Images/26cd6f4b2796b25bafb6aadb61666a85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kDuMaCIo3Jk2xRbuwii7YQ.png"/></div></div></figure><h2 id="56d4" class="np mt jj bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">1.1 时间序列图</h2><p id="d894" class="pw-post-body-paragraph ky kz jj la b lb nk kk ld le nl kn lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">为了更好地理解数据，我绘制了每日、每月和每年的用水量。</p><pre class="ob oc od oe gt of og oh oi aw oj bi"><span id="b781" class="np mt jj og b gy ok ol l om on"><strong class="og jk"># Define a function to draw time_series plot</strong></span><span id="49fb" class="np mt jj og b gy oo ol l om on">def timeseries (x_axis, y_axis, x_label):<br/>    plt.figure(figsize = (10, 6))<br/>    plt.plot(x_axis, y_axis, color =’black’)<br/>    plt.xlabel(x_label, {‘fontsize’: 12}) <br/>    plt.ylabel(‘Water consumption ($m³$/capita.day)’, <br/>                                  {‘fontsize’: 12})<br/>dataset = df.copy()<br/>timeseries(df.index, dataset[‘WC’], ‘Time (day)’)</span><span id="9862" class="np mt jj og b gy oo ol l om on">dataset[‘month’] = dataset.index.month<br/>dataset_by_month = dataset.resample(‘M’).sum()<br/>timeseries(dataset_by_month.index, dataset_by_month[‘WC’], <br/>           ‘Time(month)’)</span><span id="bc1e" class="np mt jj og b gy oo ol l om on">dataset[‘year’] = dataset.index.year<br/>dataset_by_year = dataset.resample(‘Y’).sum()<br/>timeseries(dataset_by_year.index, dataset_by_year[‘WC’], <br/>           ‘Time (month)’)</span></pre><figure class="ob oc od oe gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi or"><img src="../Images/357c1fdbec21c3cfa02c14b8efc05de0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VJ_7YkNPT0mvXATdhfsr6w.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">日用水量时间序列</p></figure><p id="2d37" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可以看到数据有一个季节性的模式。</p><figure class="ob oc od oe gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi or"><img src="../Images/e89c29938e7adac5f972f8f83f002e94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ChfdSsQ3nt8E5E7-enn2nQ.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">月用水量时间序列</p></figure><figure class="ob oc od oe gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi or"><img src="../Images/06b69fc9bf20e019e905187fd19b29fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nAuv4msZSxk3zAlM3oDETw.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">年用水量时间序列</p></figure><h2 id="135a" class="np mt jj bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">1.2 处理缺失值</h2><p id="d8b9" class="pw-post-body-paragraph ky kz jj la b lb nk kk ld le nl kn lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">首先，我想检查缺失值的数量，并确定没有数据值存储的日期。然后我使用线性插值来替换丢失的值。</p><pre class="ob oc od oe gt of og oh oi aw oj bi"><span id="cbbe" class="np mt jj og b gy ok ol l om on"><strong class="og jk"># Check for missing values</strong><br/>print(‘Total num of missing values:’) <br/>print(df.WC.isna().sum())<br/>print(‘’)<br/><strong class="og jk"># Locate the missing value</strong><br/>df_missing_date = df.loc[df.WC.isna() == True]<br/>print(‘The date of missing value:’)<br/>print(df_missing_date.loc[:,[‘Date’]])</span><span id="1fb1" class="np mt jj og b gy oo ol l om on"><strong class="og jk"># Replcase missing value with interpolation</strong><br/>df.WC.interpolate(inplace = True)</span><span id="24dc" class="np mt jj og b gy oo ol l om on"><strong class="og jk"># Keep WC and drop Date</strong><br/>df = df.drop('Date', axis = 1)</span></pre><figure class="ob oc od oe gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi os"><img src="../Images/cd39ab89934381c9857edf20fc0892f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YAtta8Az2n_AhlrsJaidqw.png"/></div></div></figure><h2 id="18c6" class="np mt jj bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">1.3 将数据集分为训练和测试数据</h2><p id="0443" class="pw-post-body-paragraph ky kz jj la b lb nk kk ld le nl kn lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">像我通常做的那样，我将前 80%的数据设置为训练数据，剩下的 20%为测试数据。我用训练数据训练模型，并用测试数据验证其性能。</p><p id="4667" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">💡提醒一下，您必须使用<em class="op"> iloc </em>根据索引位置找到数据帧的子集</p><pre class="ob oc od oe gt of og oh oi aw oj bi"><span id="b3f3" class="np mt jj og b gy ok ol l om on"><strong class="og jk"># Split train data and test data</strong><br/>train_size = int(len(df)*0.8)<br/><br/>train_data = df.iloc[:train_size]<br/>test_data = df.iloc[train_size:]</span></pre><h2 id="6fd2" class="np mt jj bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">1.4 数据转换</h2><p id="af40" class="pw-post-body-paragraph ky kz jj la b lb nk kk ld le nl kn lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">一个很好的经验法则是，规范化的数据会在神经网络中产生更好的性能。在这个项目中，我使用来自<a class="ae jg" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>的<a class="ae jg" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html" rel="noopener ugc nofollow" target="_blank"> MinMaxScaler </a>。</p><p id="e416" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您需要遵循三个步骤来执行数据转换:</p><ul class=""><li id="8676" class="ot ou jj la b lb lc le lf lh ov ll ow lp ox lt oy oz pa pb bi translated">使用可用的训练数据拟合定标器(MinMaxScaler)(这意味着使用训练数据估计最小和最大可观测值。)</li><li id="1b3f" class="ot ou jj la b lb pc le pd lh pe ll pf lp pg lt oy oz pa pb bi translated">将缩放器应用于训练数据</li><li id="ae3e" class="ot ou jj la b lb pc le pd lh pe ll pf lp pg lt oy oz pa pb bi translated">将定标器应用于测试数据</li></ul><p id="95da" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">💡需要注意的是，<em class="op"> MinMaxScaler()的输入。fit() </em>可以是数组状或数据帧状(n_samples，n_features)。在这个项目中:</p><p id="9759" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">train_data.shap = (1192，1)</p><pre class="ob oc od oe gt of og oh oi aw oj bi"><span id="835f" class="np mt jj og b gy ok ol l om on">scaler = MinMaxScaler().fit(train_data)<br/>train_scaled = scaler.transform(train_data)<br/>test_scaled = scaler.transform(test_data)</span></pre><h2 id="1fe3" class="np mt jj bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">1.5 创建输入</h2><p id="844b" class="pw-post-body-paragraph ky kz jj la b lb nk kk ld le nl kn lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">GRU 和比尔斯特姆采用一个三维输入(数量 _ 样本，数量 _ 时间步长，数量 _ 特征)。因此，我创建了一个助手函数<em class="op"> create_dataset </em>，来重塑输入。</p><p id="039d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这个项目中，我定义 look_back = 30。这意味着模型基于最近 30 天的数据进行预测(在 for-loop 的第一次迭代中，输入携带前 30 天，输出是第 30 天的用水量)。</p><pre class="ob oc od oe gt of og oh oi aw oj bi"><span id="9eb1" class="np mt jj og b gy ok ol l om on"><strong class="og jk"># Create input dataset</strong><br/>def create_dataset (X, look_back = 1):<br/>    Xs, ys = [], []<br/> <br/>    for i in range(len(X)-look_back):<br/>        v = X[i:i+look_back]<br/>        Xs.append(v)<br/>        ys.append(X[i+look_back])<br/> <br/>    return np.array(Xs), np.array(ys)</span><span id="ca16" class="np mt jj og b gy oo ol l om on">LOOK_BACK = 30</span><span id="f594" class="np mt jj og b gy oo ol l om on">X_train, y_train = create_dataset(train_scaled,LOOK_BACK)<br/>X_test, y_test = create_dataset(test_scaled,LOOK_BACK)</span><span id="3716" class="np mt jj og b gy oo ol l om on"><strong class="og jk"># Print data shape</strong><br/>print(‘X_train.shape: ‘, X_train.shape)<br/>print(‘y_train.shape: ‘, y_train.shape)<br/>print(‘X_test.shape: ‘, X_test.shape) <br/>print(‘y_test.shape: ‘, y_test.shape)</span></pre><figure class="ob oc od oe gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ph"><img src="../Images/838573368707a3e4061813b6b0f019b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y_SvPas6RhfbIJM6sOinSg.png"/></div></div></figure><h1 id="4ee2" class="ms mt jj bd mu mv mw mx my mz na nb nc kp nd kq ne ks nf kt ng kv nh kw ni nj bi translated">2.创建模型</h1><p id="3e9e" class="pw-post-body-paragraph ky kz jj la b lb nk kk ld le nl kn lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">第一个函数，<em class="op"> create_bilstm </em>，创建一个 BiDLSM 并获取隐藏层中的单元(神经元)数量。第二个函数，<em class="op"> create_gru </em>，构建一个 gru 并获得隐藏层中的单元数。</p><p id="d71b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">两者在输入层都有 64 个神经元，一个隐层包括 64 个神经元，在输出层有 1 个神经元。两个模型中的<em class="op">优化器</em>都是<a class="ae jg" href="https://keras.io/api/optimizers/adam/" rel="noopener ugc nofollow" target="_blank"> <em class="op">亚当</em> </a>。为了使 GRU 模型对变化具有鲁棒性，使用了<strong class="la jk">下降</strong>函数。<strong class="la jk">掉线(0.2) </strong>随机掉线 20%的单位。</p><pre class="ob oc od oe gt of og oh oi aw oj bi"><span id="80f8" class="np mt jj og b gy ok ol l om on"><strong class="og jk"># Create BiLSTM model</strong><br/>def create_bilstm(units):<br/>    model = Sequential()<br/>    <strong class="og jk"># Input layer</strong><br/>    model.add(Bidirectional(<br/>              LSTM(units = units, return_sequences=True), <br/>              input_shape=(X_train.shape[1], X_train.shape[2])))<br/>    <strong class="og jk"># Hidden layer</strong><br/>    model.add(Bidirectional(LSTM(units = units)))<br/>    model.add(Dense(1))<br/>    <strong class="og jk">#Compile model</strong><br/>    model.compile(optimizer=’adam’,loss=’mse’)<br/>    return model</span><span id="b50a" class="np mt jj og b gy oo ol l om on">model_bilstm = create_bilstm(64)</span><span id="9a40" class="np mt jj og b gy oo ol l om on"><strong class="og jk"># Create GRU model</strong><br/>def create_gru(units):<br/>    model = Sequential()<br/>    <strong class="og jk"># Input layer</strong><br/>    model.add(GRU (units = units, return_sequences = True, <br/>    input_shape = [X_train.shape[1], X_train.shape[2]]))<br/>    model.add(Dropout(0.2)) <br/>    <strong class="og jk"># Hidden layer</strong><br/>    model.add(GRU(units = units)) <br/>    model.add(Dropout(0.2))<br/>    model.add(Dense(units = 1)) <br/>    <strong class="og jk">#Compile model</strong><br/>    model.compile(optimizer=’adam’,loss=’mse’)<br/>    return model</span><span id="c2f8" class="np mt jj og b gy oo ol l om on">model_gru = create_gru(64)</span></pre><h2 id="b9e1" class="np mt jj bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">2.1 拟合模型</h2><p id="0fa7" class="pw-post-body-paragraph ky kz jj la b lb nk kk ld le nl kn lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">我创建一个函数，<em class="op"> fit_model </em>，获取模型并用 100 个<strong class="la jk">时期</strong>和<strong class="la jk"> batch_size </strong> = 16 的训练数据训练模型。我让模型使用 20%的训练数据作为验证数据。我设置<strong class="la jk"> shuffle = False </strong>是因为它提供了更好的性能。</p><p id="d8b8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了避免过度拟合，我设置了一个<em class="op">提前停止</em>，当<em class="op">验证损失</em>在 10 个周期后没有改善时(耐心= 10)停止训练。</p><pre class="ob oc od oe gt of og oh oi aw oj bi"><span id="7f75" class="np mt jj og b gy ok ol l om on">def fit_model(model):<br/>    early_stop = keras.callbacks.EarlyStopping(monitor = ‘val_loss’,<br/>                                               patience = 10)<br/>    history = model.fit(X_train, y_train, epochs = 100,  <br/>                        validation_split = 0.2,<br/>                        batch_size = 16, shuffle = False, <br/>                        callbacks = [early_stop])<br/>    return history</span><span id="a0bf" class="np mt jj og b gy oo ol l om on">history_gru = fit_model(model_gru)<br/>history_bilstm = fit_model(model_bilstm)</span></pre><h2 id="6ceb" class="np mt jj bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">2.2 目标变量的逆变换</h2><p id="0b7e" class="pw-post-body-paragraph ky kz jj la b lb nk kk ld le nl kn lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">建立模型后，我必须使用<strong class="la jk">scaler . inverse _ transform</strong>将目标变量转换回训练和测试数据的原始数据空间。</p><pre class="ob oc od oe gt of og oh oi aw oj bi"><span id="a470" class="np mt jj og b gy ok ol l om on">y_test = scaler.inverse_transform(y_test)<br/>y_train = scaler.inverse_transform(y_train)</span></pre><h1 id="e4dd" class="ms mt jj bd mu mv mw mx my mz na nb nc kp nd kq ne ks nf kt ng kv nh kw ni nj bi translated">3.评估模型的性能</h1><p id="12d5" class="pw-post-body-paragraph ky kz jj la b lb nk kk ld le nl kn lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">我们将如何评价 GRU 和比尔斯特姆的表现？</p><h2 id="6678" class="np mt jj bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">1-绘制训练损失和验证损失</h2><p id="78d1" class="pw-post-body-paragraph ky kz jj la b lb nk kk ld le nl kn lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">为了评估模型性能，我绘制了训练损失与验证损失的关系图，我预计验证损失低于训练损失😉</p><h2 id="eba7" class="np mt jj bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">2-比较预测和测试数据</h2><p id="ed72" class="pw-post-body-paragraph ky kz jj la b lb nk kk ld le nl kn lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">首先，我用比尔斯特姆和 GRU 模型预测 WC。然后，我绘制了两个模型的测试数据与预测。</p><h2 id="80ad" class="np mt jj bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">3-计算 RMSE 和梅</h2><p id="6711" class="pw-post-body-paragraph ky kz jj la b lb nk kk ld le nl kn lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">我使用两种拟合优度来评估模型的准确性。</p><h2 id="d6b0" class="np mt jj bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">3.1 绘制列车损失和验证损失</h2><pre class="ob oc od oe gt of og oh oi aw oj bi"><span id="8390" class="np mt jj og b gy ok ol l om on">def plot_loss (history, model_name):<br/>    plt.figure(figsize = (10, 6))<br/>    plt.plot(history.history[‘loss’])<br/>    plt.plot(history.history[‘val_loss’])<br/>    plt.title(‘Model Train vs Validation Loss for ‘ + model_name)<br/>    plt.ylabel(‘Loss’)<br/>    plt.xlabel(‘epoch’)<br/>    plt.legend([‘Train loss’, ‘Validation loss’], loc=’upper right’)<br/> <br/>plot_loss (history_gru, ‘GRU’)<br/>plot_loss (history_bilstm, ‘Bidirectional LSTM’)</span></pre><figure class="ob oc od oe gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi or"><img src="../Images/b8b52804516a5f52b94fad9c647ba2bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CPvEyazhLUc-LRpSLT5VAQ.jpeg"/></div></div></figure><figure class="ob oc od oe gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi or"><img src="../Images/10849eb2dbfbb04668d63c73354c3fe9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_J-_g3quJW-Tujo1lI6Q8A.jpeg"/></div></div></figure><h2 id="5757" class="np mt jj bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">3.2 比较预测和测试数据</h2><pre class="ob oc od oe gt of og oh oi aw oj bi"><span id="e124" class="np mt jj og b gy ok ol l om on"><strong class="og jk"># Make prediction</strong><br/>def prediction(model):<br/>    prediction = model.predict(X_test)<br/>    prediction = scaler.inverse_transform(prediction)<br/>    return prediction</span><span id="6625" class="np mt jj og b gy oo ol l om on">prediction_gru = prediction(model_gru)<br/>prediction_bilstm = prediction(model_bilstm)</span><span id="4c75" class="np mt jj og b gy oo ol l om on"><strong class="og jk"># Plot test data vs prediction</strong><br/>def plot_future(prediction, model_name, y_test):<br/>    plt.figure(figsize=(10, 6))<br/>    range_future = len(prediction)<br/>    plt.plot(np.arange(range_future), np.array(y_test), <br/>             label=’Test   data’)<br/>    plt.plot(np.arange(range_future), <br/>             np.array(prediction),label=’Prediction’)</span><span id="879c" class="np mt jj og b gy oo ol l om on">    plt.title(‘Test data vs prediction for ‘ + model_name)<br/>    plt.legend(loc=’upper left’)<br/>    plt.xlabel(‘Time (day)’)<br/>    plt.ylabel(‘Daily water consumption ($m³$/capita.day)’)<br/> <br/>plot_future(prediction_gru, ‘GRU’, y_test)<br/>plot_future(prediction_bilstm, ‘Bidirectional LSTM’, y_test)</span></pre><figure class="ob oc od oe gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi or"><img src="../Images/54d02bc93325f4f0f1bc0f67a2be0fe5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ml4PCfFSrt7fdroN17QzNA.jpeg"/></div></div></figure><figure class="ob oc od oe gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi or"><img src="../Images/5c163fd5648f339abc651b973fc6451b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3GrFsjLKAgDBiNG5Edw8WA.jpeg"/></div></div></figure><h2 id="4e41" class="np mt jj bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">3.3 计算 RMSE 和梅</h2><pre class="ob oc od oe gt of og oh oi aw oj bi"><span id="65cc" class="np mt jj og b gy ok ol l om on">def evaluate_prediction(predictions, actual, model_name):<br/>    errors = predictions — actual<br/>    mse = np.square(errors).mean()<br/>    rmse = np.sqrt(mse)<br/>    mae = np.abs(errors).mean()<br/>    print(model_name + ‘:’)<br/>    print(‘Mean Absolute Error: {:.4f}’.format(mae))<br/>    print(‘Root Mean Square Error: {:.4f}’.format(rmse))<br/>    print(‘’)</span><span id="e951" class="np mt jj og b gy oo ol l om on">evaluate_prediction(prediction_gru, y_test, ‘GRU’)<br/>evaluate_prediction(prediction_bilstm, y_test, ‘Bidirectiona LSTM’)</span></pre><figure class="ob oc od oe gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pi"><img src="../Images/17208a94807d24d56d0776af7518a24d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rDxOWDDvleqzHLTrRMsmTQ.png"/></div></div></figure><h1 id="d31e" class="ms mt jj bd mu mv mw mx my mz na nb nc kp nd kq ne ks nf kt ng kv nh kw ni nj bi translated">4.30 天用水量的多步预测</h1><p id="bcf8" class="pw-post-body-paragraph ky kz jj la b lb nk kk ld le nl kn lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">为了使用经过训练的 GRU 和比尔斯特姆模型进行预测，我需要至少 60 天的观察数据来预测未来 30 天的情况。为了便于说明，我从观测数据中选择了 60 天的用水量，并用 GRU 和比尔斯特姆预测了未来 30 天的用水量。</p><pre class="ob oc od oe gt of og oh oi aw oj bi"><span id="2c7c" class="np mt jj og b gy ok ol l om on"><strong class="og jk"># Make prediction for new data</strong><br/>def prediction(model):<br/>    prediction = model.predict(X_30)<br/>    prediction = scaler.inverse_transform(prediction)<br/>    return prediction</span><span id="3dc5" class="np mt jj og b gy oo ol l om on">prediction_gru = prediction(model_gru)<br/>prediction_bilstm = prediction(model_bilstm)</span><span id="16b4" class="np mt jj og b gy oo ol l om on"><strong class="og jk"># Plot history and future</strong><br/>def plot_multi_step(history, prediction1, prediction2):<br/>    <br/>    plt.figure(figsize=(15, 6))<br/>    <br/>    range_history = len(history)<br/>    range_future = list(range(range_history, range_history +<br/>                        len(prediction1)))</span><span id="c6de" class="np mt jj og b gy oo ol l om on">    plt.plot(np.arange(range_history), np.array(history), <br/>             label='History')<br/>    plt.plot(range_future, np.array(prediction1),<br/>             label='Forecasted for GRU')<br/>    plt.plot(range_future, np.array(prediction2),<br/>             label='Forecasted for BiLSTM')<br/>      <br/>    plt.legend(loc='upper right')<br/>    plt.xlabel('Time step (day)')<br/>    plt.ylabel('Water demand (lit/day)')<br/>        <br/>plot_multi_step(new_data, prediction_gru, prediction_bilstm)</span></pre><figure class="ob oc od oe gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pj"><img src="../Images/672e95b761b11dd27c44163df3a4b7b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_8uBnS2jHzl4Zzhtm79aRA.jpeg"/></div></div></figure><h1 id="cc5e" class="ms mt jj bd mu mv mw mx my mz na nb nc kp nd kq ne ks nf kt ng kv nh kw ni nj bi translated">结论</h1><p id="9b0a" class="pw-post-body-paragraph ky kz jj la b lb nk kk ld le nl kn lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">感谢您阅读这篇文章。我希望它能帮助你在 Tensorflow 中开发用于时间序列预测的 GRU 和比尔斯特姆模型😊</p><p id="119b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">非常感谢您的反馈。你可以在 LinkedIn 上找到我。</p></div></div>    
</body>
</html>