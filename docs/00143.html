<html>
<head>
<title>Scanned Document Classification using Computer Vision</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用计算机视觉的扫描文档分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/scanned-document-classification-using-computer-vision-33a42d9e01f9?source=collection_archive---------6-----------------------#2020-01-05">https://towardsdatascience.com/scanned-document-classification-using-computer-vision-33a42d9e01f9?source=collection_archive---------6-----------------------#2020-01-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ba29" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一种解决扫描文档分类问题的深度学习方法</h2></div><p id="b85c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在数字经济时代，银行、保险、管理、医疗和法律等部门仍然需要处理各种手写笔记和扫描文档。在业务生命周期的后期，手动维护和分类这些文档变得非常繁琐。对这些非机密文档进行简单而有意义的自动化宁滨将使维护和利用这些信息变得容易得多，并大大减少人工工作量。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/efcd4ef36f7cabf70535347c9a420b14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6unLXqD_aodyszeIaMAm3w.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">扫描的文档</p></figure><p id="78aa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">本案例研究的目标是开发一个基于深度学习的解决方案，可以自动对文档进行分类。</p><p id="273c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">数据:</strong>对于本案例研究，我们将使用RVL-CDIP(瑞尔森视觉实验室复杂文档信息处理)数据集，该数据集由16类400，000幅灰度图像组成，每类25，000幅图像。有320，000幅训练图像、40，000幅验证图像和40，000幅测试图像。调整图像大小，使其最大尺寸不超过1000像素。该数据集的大小超过200 GB。</p><p id="0bfc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">业务-ML问题映射:</strong>我们可以将业务问题映射为多类分类问题。当前数据集中有16个类别。我们需要仅基于扫描文档的像素值来预测文档的类别，这使得问题变得困难。<strong class="kk iu"> <em class="lu">但是等等，为什么不能用OCR提取文字，应用NLP技术呢？是的，我们也对这个想法感到兴奋，但是低质量的扫描导致了较差的文本提取质量。在实际的商业场景中，我们也无法控制扫描的质量，因此依赖于OCR的模型即使经过适当的预处理也可能会泛化能力差。</em></strong></p><p id="0ff2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> KPI和业务约束:</strong>数据集相当平衡。因此，我们选择准确性作为主要指标，微观平均F1分数作为次要指标，以惩罚错误分类的数据点。我们还使用混淆度量来验证模型的性能。对延迟的要求适中，对可解释性没有具体要求。</p><p id="000f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">我们能从文档的像素强度和大小中得到什么吗？</strong></p><p id="2cb5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们尝试使用一个方框图来显示文档的平均像素强度和大小</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi lv"><img src="../Images/72045302cbc2a6a095926b48fc39288c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sOVePQQInri__OZQBHnqmQ.png"/></div></div></figure><p id="a9e8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从方框图中，我们可以观察到某些类型的扫描文件的尺寸与其他文件大不相同，但也有重叠。例如，类别13和类别9的文件大小差别很大，但是类别9的大小与类别4和类别6，7重叠。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi lw"><img src="../Images/dac578c7e87847d4dca158a9c1f1da6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VewNiqn9xV5S1jYHx-fqig.png"/></div></div></figure><p id="29bb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以观察到，对于75%的情况，类别4的平均像素强度位于160–230像素之间。但是对于大约50%的情况，它也与类别6的平均像素值重叠。对于其他类，平均像素值重叠。</p><p id="80c0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">分析方法</strong></p><p id="a685" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了解决眼前的问题，我们在扩充的数据上训练了卷积神经网络(CNN)。我们已经尝试在有和没有数据增强的情况下训练模型，结果是可比较的。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi lx"><img src="../Images/5fe42f48d88e0e9ee77965a8f2fae7ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kD40MXj74iJlhdUKeE637w.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">高级分析工作流程图</p></figure><p id="8d39" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">太好了！但是如何决定网络架构呢？你是如何训练网络的，因为数据一次装不下？</strong></p><p id="82b3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从头开始训练神经网络需要大量的时间和计算资源来收敛，为了避免这种情况，我们采用了迁移学习的帮助。我们从在ImageNet数据集上训练和在我们的数据集上重新训练的预训练网络的权重开始。针对这类问题的当前SOTA模型使用域间和域内迁移学习，其中图像被分成四个部分:页眉、页脚、左体和右体。首先使用预训练的VGG16模型来训练整个图像(域间)，然后使用该模型来训练部分图像(域内)。</p><p id="41a3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这个实验中，我们采用了一种稍微不同的方法。我们没有使用VGG16进行域内迁移学习，而是训练了两个并行模型VGG16和InceptionResNetV2，并使用这些模型的堆栈作为我们的最终模型。我们的假设是，由于这两个模型的不同架构，他们将学习图像的不同方面，并将它们堆叠将导致良好的概括。<strong class="kk iu"> <em class="lu">但是我们如何选择这些型号呢？</em> </strong> <em class="lu">这基本上来自交叉验证的结果。</em> <strong class="kk iu"> <em class="lu"> </em> </strong>我们尝试了各种网络架构，像VGG16、VGG19、DenseNet、ResNet、InceptionNet，选出了最好的两个。</p><p id="7c9b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们使用keras的ImageDataGenerator类来预处理和加载训练数据，而不是将整个数据一次性加载到内存中。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ly"><img src="../Images/8ec53afd08eeaf4dae0c2b3d44b13ed2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qaud8FmO_CTKf7w21wZCkQ.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">VGG16网络的最终培训阶段</p></figure><p id="d1de" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">好的。但是如何处理超参数呢？</strong></p><p id="eec3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于任何CNN的超级参数是:学习率，池大小，网络大小，批量大小，优化器的选择，正则化，输入大小等。</p><p id="f7f0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">学习速率对神经网络的收敛起着重要的作用。深度学习问题中使用的损失函数是非凸的，这意味着在存在几个局部最小值和鞍点的情况下，找到全局最小值不是一件容易的事情。如果学习率太低，它将缓慢收敛，如果学习率太高，它将开始振荡。在本案例研究中，我们使用了一种称为“循环学习率”的技术，其目的是以这样一种方式训练神经网络，即对于每个训练批次，学习率以循环方式变化。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi lz"><img src="../Images/3b27624a5115b197fca15696bc23087c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aYxLAuN1rBspXwXOCL1oQg.png"/></div></div></figure><p id="8541" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但是它为什么会起作用呢？在CLR中，我们在一个阈值内改变学习率。周期性的较高学习率有助于克服它是否停留在鞍点或局部最小值。</p><p id="0f17" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于其他超参数，我们开发了定制的效用函数来检查哪种配置效果更好。假设在10个时期之后，我们得到了47%的准确度。我们将在那时使用该模型作为测试基线，并使用效用函数来检查哪个配置集(即batch _ size/optimizer/learning _ rate)将在未来时代产生更好的准确性。</p><p id="39ea" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">结果</strong></p><p id="e5fc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们使用VGG16模型实现了90.7%的准确率，使用InceptionResNetV2实现了88%的准确率。上述两个模型的比例叠加模型获得了97%的训练准确率和91.45%的测试准确率。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ma"><img src="../Images/e15aeacf5156b9ff63df71dbf14225b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9bXMeuSo2wAW0dY6UicYxg.png"/></div></div></figure><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi mb"><img src="../Images/c4f9af2dd083185acc0e5c10b91d9142.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ep0xjUfIhzuTrZegG1SgQw.png"/></div></div></figure><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi mc"><img src="../Images/ae2f484a56c0719b0a0583a976bd362e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*odrfy3Kgii4PNVnDwzZhKg.png"/></div></div></figure><p id="d1ec" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可以在这里找到完整的实现<a class="ae md" href="https://github.com/arpan65/Scanned-document-classification-using-deep-learning" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="d5d0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">引用:</strong></p><ol class=""><li id="c839" class="me mf it kk b kl km ko kp kr mg kv mh kz mi ld mj mk ml mm bi translated">A.W. Harley，A. Ufkes，K. G. Derpanis，“用于文档图像分类和检索的深度卷积网的评估”，ICDAR，2015年。</li><li id="7621" class="me mf it kk b kl mn ko mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae md" href="https://arxiv.org/abs/1506.01186" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1506.01186</a></li><li id="4d33" class="me mf it kk b kl mn ko mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae md" href="https://www.researchgate.net/publication/332948719_Segmentation_of_Scanned_Documents_Using_Deep-Learning_Approach" rel="noopener ugc nofollow" target="_blank">https://www . research gate . net/publication/332948719 _ Segmentation _ of _ Scanned _ Documents _ Using _ Deep-Learning _ Approach</a></li></ol></div></div>    
</body>
</html>