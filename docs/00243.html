<html>
<head>
<title>Numba: “weapon of mass optimization”</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Numba:“大规模优化的武器”</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/numba-weapon-of-mass-optimization-43cdeb76c7da?source=collection_archive---------9-----------------------#2020-01-08">https://towardsdatascience.com/numba-weapon-of-mass-optimization-43cdeb76c7da?source=collection_archive---------9-----------------------#2020-01-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="931a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Numba如何节省您的时间并加速您的代码</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a7b4a3596ac5fd9a57f33a41211ad423.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZBRdJA1CKJqUi35vHpbjHw.jpeg"/></div></div></figure><p id="6aae" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Numba是一个Python编译器，专门针对数字函数，允许您使用直接用Python编写的高性能函数来加速应用程序。</p><p id="4102" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Numba使用LLVM生成从纯Python代码优化的机器码。通过几处简单的修改，我们的Python代码(面向函数的)可以“实时”优化，获得类似于C、C++的性能，而不必改变语言。</p><p id="a2ad" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你可以在我的<a class="ae lq" href="https://github.com/alejandrods/Numba" rel="noopener ugc nofollow" target="_blank"> GitHub </a>中找到完整的代码！:)</p><h1 id="def4" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">索引</h1><ol class=""><li id="b340" class="mj mk it kw b kx ml la mm ld mn lh mo ll mp lp mq mr ms mt bi translated">什么是Numba？</li><li id="9650" class="mj mk it kw b kx mu la mv ld mw lh mx ll my lp mq mr ms mt bi translated">第一步:为CPU编译</li><li id="2de9" class="mj mk it kw b kx mu la mv ld mw lh mx ll my lp mq mr ms mt bi translated">GPU的Numba</li><li id="d945" class="mj mk it kw b kx mu la mv ld mw lh mx ll my lp mq mr ms mt bi translated">结论</li></ol><h1 id="32ae" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">什么是Numba？</h1><p id="e0b2" class="pw-post-body-paragraph ku kv it kw b kx ml ju kz la mm jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">Numba是一个编译器，允许您为CPU和GPU加速Python代码(数值函数):</p><ol class=""><li id="af6f" class="mj mk it kw b kx ky la lb ld nc lh nd ll ne lp mq mr ms mt bi translated"><strong class="kw iu"> <em class="nf">函数编译器:</em> </strong> Numba编译Python函数，而不是整个应用或部分应用。基本上，Numba是另一个提高函数性能的Python模块。</li><li id="e75a" class="mj mk it kw b kx mu la mv ld mw lh mx ll my lp mq mr ms mt bi translated"><strong class="kw iu"> <em class="nf"> Just-in-time: </em> </strong>(动态翻译)Numba将字节码(比机器码更抽象的中间代码)在其执行前立即翻译成机器码，以提高执行速度。</li><li id="12fc" class="mj mk it kw b kx mu la mv ld mw lh mx ll my lp mq mr ms mt bi translated"><strong class="kw iu"> <em class="nf">数值型:</em> </strong> Numba关注的是数值型数据，比如<code class="fe ng nh ni nj b">int</code>、<code class="fe ng nh ni nj b">float</code>、<code class="fe ng nh ni nj b">complex</code>。目前，对字符串数据使用它有一些限制。</li></ol><p id="7812" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Numba不是CUDA唯一的编程方式，通常是直接用C/C ++为它编程。但是Numba允许你直接用Python编程，并对CPU和GPU进行优化，只需对我们的代码做很少的修改。关于Python，还有其他替代方案，如pyCUDA，下面是它们之间的比较:</p><p id="bd0e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> CUDA C/C++: </strong></p><ol class=""><li id="361c" class="mj mk it kw b kx ky la lb ld nc lh nd ll ne lp mq mr ms mt bi translated">这是CUDA中最常见和最灵活的编程方式</li><li id="7b6c" class="mj mk it kw b kx mu la mv ld mw lh mx ll my lp mq mr ms mt bi translated">加速C、C ++中的应用程序。</li></ol><p id="31af" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> pyCUDA </strong></p><ol class=""><li id="1650" class="mj mk it kw b kx ky la lb ld nc lh nd ll ne lp mq mr ms mt bi translated">这是Python最有效的CUDA形式</li><li id="a9bc" class="mj mk it kw b kx mu la mv ld mw lh mx ll my lp mq mr ms mt bi translated">它需要用我们的Python代码进行C编程，一般来说，还需要许多代码修改。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/35a9582fe41f081165dbec52ac035e1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8-0wqXY4e0AHT8uJZd1LEQ.png"/></div></div><p class="nl nm gj gh gi nn no bd b be z dk translated">PyCUDA示例</p></figure><p id="61cf" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">数字巴</strong></p><ol class=""><li id="03f7" class="mj mk it kw b kx ky la lb ld nc lh nd ll ne lp mq mr ms mt bi translated">效率不如pyCUDA</li><li id="50c5" class="mj mk it kw b kx mu la mv ld mw lh mx ll my lp mq mr ms mt bi translated">它允许您用Python编写代码，并通过少量修改对其进行优化</li><li id="a16d" class="mj mk it kw b kx mu la mv ld mw lh mx ll my lp mq mr ms mt bi translated">它还为CPU优化了Python代码</li></ol><h1 id="427c" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">目标</h1><p id="0c28" class="pw-post-body-paragraph ku kv it kw b kx ml ju kz la mm jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">本次会谈的目标如下:</p><ul class=""><li id="48e1" class="mj mk it kw b kx ky la lb ld nc lh nd ll ne lp np mr ms mt bi translated">使用Numba在CPU上编译函数</li><li id="759c" class="mj mk it kw b kx mu la mv ld mw lh mx ll my lp np mr ms mt bi translated">了解Numba是如何工作的</li><li id="3596" class="mj mk it kw b kx mu la mv ld mw lh mx ll my lp np mr ms mt bi translated">在GPU中加速Numpy ufuncs</li><li id="a5bf" class="mj mk it kw b kx mu la mv ld mw lh mx ll my lp np mr ms mt bi translated">使用Numba编写内核<em class="nf">(下一个教程)</em></li></ul><h1 id="96d0" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">第一步:为CPU编译</h1><p id="a71a" class="pw-post-body-paragraph ku kv it kw b kx ml ju kz la mm jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">Numba除了能够加速GPU中的函数之外，还可以用来优化CPU中的函数。为此，使用了Python decorators(函数修饰符)。</p><p id="4c5e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">首先我们要开始评估函数<code class="fe ng nh ni nj b">hypot</code>来试试Numba是怎么工作的。我们需要在函数中使用装饰器<code class="fe ng nh ni nj b">@jit</code>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq nr l"/></div></figure><pre class="kj kk kl km gt ns nj nt nu aw nv bi"><span id="821c" class="nw ls it nj b gy nx ny l nz oa">&gt;&gt;&gt; # Numba function<br/>&gt;&gt;&gt; hypot(3.0, 4.0)<br/><strong class="nj iu">5.0</strong></span><span id="1080" class="nw ls it nj b gy ob ny l nz oa">&gt;&gt;&gt; # Python function<br/>&gt;&gt;&gt; hypot.py_func(3.0, 4.0)<br/><strong class="nj iu">5.0</strong></span></pre><p id="c680" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Numba中的结果与Python函数中的结果相同，因为Numba将函数的原始实现保存在<code class="fe ng nh ni nj b">.py_func</code>中。</p><h2 id="af99" class="nw ls it bd lt oc od dn lx oe of dp mb ld og oh md lh oi oj mf ll ok ol mh om bi translated">标杆管理</h2><p id="1c95" class="pw-post-body-paragraph ku kv it kw b kx ml ju kz la mm jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">自然，测量我们代码的性能，检查Numba是否真的工作良好，并观察Python实现和Numba实现之间的差异是很重要的。此外，库<code class="fe ng nh ni nj b">math</code>已经包含了<code class="fe ng nh ni nj b">hypot</code>函数，我们也可以对其进行评估。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq nr l"/></div></figure><pre class="kj kk kl km gt ns nj nt nu aw nv bi"><span id="0ff9" class="nw ls it nj b gy nx ny l nz oa">&gt;&gt;&gt; # Python function<br/>&gt;&gt;&gt; %timeit hypot.py_func(3.0, 4.0)</span><span id="e717" class="nw ls it nj b gy ob ny l nz oa"><strong class="nj iu">The slowest run took 17.62 times longer than the fastest. This could mean that an intermediate result is being cached. 1000000 loops, best of 3: 260 ns per loop</strong></span><span id="e893" class="nw ls it nj b gy ob ny l nz oa">&gt;&gt;&gt; # Numba function<br/>&gt;&gt;&gt; %timeit hypot(3.0, 4.0)</span><span id="20c4" class="nw ls it nj b gy ob ny l nz oa"><strong class="nj iu">The slowest run took 33.89 times longer than the fastest. This could mean that an intermediate result is being cached. 1000000 loops, best of 3: 216 ns per loop</strong></span><span id="b223" class="nw ls it nj b gy ob ny l nz oa">&gt;&gt;&gt; # math function<br/>&gt;&gt;&gt; %timeit math.hypot(3.0, 4.0)</span><span id="7d9f" class="nw ls it nj b gy ob ny l nz oa"><strong class="nj iu">The slowest run took 105.55 times longer than the fastest. This could mean that an intermediate result is being cached. 10000000 loops, best of 3: 133 ns per loop</strong></span></pre><p id="f2cf" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"/><code class="fe ng nh ni nj b">math.hypot</code><strong class="kw iu">功能甚至比Numba还快！！</strong>这是因为Numba为每个函数调用引入了一定的开销，这比Python函数调用的开销要大，非常快的函数(就像上一个)会受此影响。</p><p id="c8a8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">(但是，如果从另一个函数调用Numba函数，开销很小，如果编译器将该函数集成到另一个函数中，开销有时甚至为零。总之用Numba检查一下功能是不是真的在加速)。</p><div class="on oo gp gr op oq"><a href="https://numba.pydata.org/numba-doc/dev/user/performance-tips.html#performance-tips" rel="noopener  ugc nofollow" target="_blank"><div class="or ab fo"><div class="os ab ot cl cj ou"><h2 class="bd iu gy z fp ov fr fs ow fu fw is bi translated">1.14.性能提示-Numba 0 . 48 . 0 . dev 0+134 . g 709967 b-py 3.7-Linux-x86 _ 64 . egg文档</h2><div class="ox l"><h3 class="bd b gy z fp ov fr fs ow fu fw dk translated">这是一个简短的指南，介绍Numba中的一些特性，这些特性有助于从代码中获得最佳性能。二…</h3></div><div class="oy l"><p class="bd b dl z fp ov fr fs ow fu fw dk translated">numba.pydata.org</p></div></div></div></a></div><h2 id="7f4a" class="nw ls it bd lt oc od dn lx oe of dp mb ld og oh md lh oi oj mf ll ok ol mh om bi translated">Numba是如何工作的？</h2><p id="86b1" class="pw-post-body-paragraph ku kv it kw b kx ml ju kz la mm jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">当我们初始化<code class="fe ng nh ni nj b">hypot</code>函数时:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/054c0f0022de15bf5b3fc4e7073104dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S0S4QUjR-BsdTICtT9797Q.png"/></div></div><p class="nl nm gj gh gi nn no bd b be z dk translated">Numba如何工作</p></figure><ul class=""><li id="b8dd" class="mj mk it kw b kx ky la lb ld nc lh nd ll ne lp np mr ms mt bi translated">中间表示法</li><li id="521e" class="mj mk it kw b kx mu la mv ld mw lh mx ll my lp np mr ms mt bi translated"><strong class="kw iu">字节码分析</strong>中间代码比机器码更抽象</li><li id="1fb5" class="mj mk it kw b kx mu la mv ld mw lh mx ll my lp np mr ms mt bi translated">LLVM低级虚拟机，开发编译器的基础设施</li><li id="bcc2" class="mj mk it kw b kx mu la mv ld mw lh mx ll my lp np mr ms mt bi translated">NVVM是一个基于LLVM的IR编译器，它被设计用来表示GPU内核</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pa nr l"/></div></figure><p id="70a6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">python的每一行前面都有几行Numba IR代码。最有用的是查看向我们展示Numba如何处理变量的类型注释，例如，在“pyobject”中，它表明Numba不知道<code class="fe ng nh ni nj b">np.sin</code>函数，他应该从Python中调用它。我们可以使用<code class="fe ng nh ni nj b">.inspect_types()</code>检查<code class="fe ng nh ni nj b">hypot</code>的过程。</p><pre class="kj kk kl km gt ns nj nt nu aw nv bi"><span id="5ce9" class="nw ls it nj b gy nx ny l nz oa">&gt;&gt;&gt; @jit<br/>&gt;&gt;&gt; def foo_np(x):<br/>&gt;&gt;&gt;     return np.sin(x)</span><span id="1dea" class="nw ls it nj b gy ob ny l nz oa">&gt;&gt;&gt; foo_np(2)<br/>&gt;&gt;&gt; foo_np.inspect_types()</span><span id="62c3" class="nw ls it nj b gy ob ny l nz oa"><strong class="nj iu">foo_np (int64,)<br/>----------------------------<br/># File: &lt;ipython-input-18-02574ac7ba04&gt; <br/># --- LINE 1 ---  <br/># label 0  </strong></span><span id="200f" class="nw ls it nj b gy ob ny l nz oa"><strong class="nj iu">@jit  </strong></span><span id="c3d3" class="nw ls it nj b gy ob ny l nz oa"><strong class="nj iu"># --- LINE 2 ---   <br/>def foo_np(x):    <br/># --- LINE 3 ---    <br/>#   x = arg(0, name=x)  :: int64   <br/>#   $0.1 = global(np: &lt;module 'numpy' from '/usr/local/lib/python3.6/dist-packages/numpy/__init__.py'&gt;)  :: Module(&lt;module 'numpy' from '/usr/local/lib/python3.6/dist-packages/numpy/__init__.py'&gt;)  <br/> <br/>#   $0.2 = getattr(value=$0.1, attr=sin)  :: Function(&lt;ufunc 'sin'&gt;)   #   del $0.1   <br/>#   $0.4 = call $0.2(x, func=$0.2, args=[Var(x, &lt;ipython-input-18-02574ac7ba04&gt; (3))], kws=(), vararg=None)  :: (int64,) -&gt; float64   </strong></span><span id="4e9a" class="nw ls it nj b gy ob ny l nz oa"><strong class="nj iu">#   del x   <br/>#   del $0.2   <br/>#   $0.5 = cast(value=$0.4)  :: float64   <br/>#   del $0.4   <br/>#   return $0.5    return np.sin(x)   ==============================================</strong></span></pre><h2 id="778b" class="nw ls it bd lt oc od dn lx oe of dp mb ld og oh md lh oi oj mf ll ok ol mh om bi translated">示例:创建分形</h2><p id="ddb9" class="pw-post-body-paragraph ku kv it kw b kx ml ju kz la mm jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">我们将使用<strong class="kw iu"> Mandelbrot集合</strong>来测量创建分形的性能，我们将看到Numba如何帮助我们提高性能。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq nr l"/></div></figure><pre class="kj kk kl km gt ns nj nt nu aw nv bi"><span id="cbcc" class="nw ls it nj b gy nx ny l nz oa"><strong class="nj iu">1 loop, best of 3: 4.62 s per loop<br/>&lt;matplotlib.image.AxesImage at 0x7f986ce23780&gt;</strong></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/32f07661e63f39d628a2aeeadb33ff1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*33wX9XAct28Y5YbjcsR1WA.png"/></div></figure><p id="6c08" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">使用Mandelbrot集合生成一个分形大约需要<strong class="kw iu"> 4.62秒</strong>，现在我们将使用Numba来提高性能，我们只需添加<code class="fe ng nh ni nj b">@jit</code>装饰器。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq nr l"/></div></figure><pre class="kj kk kl km gt ns nj nt nu aw nv bi"><span id="3dcf" class="nw ls it nj b gy nx ny l nz oa"><strong class="nj iu">The slowest run took 4.17 times longer than the fastest. This could mean that an intermediate result is being cached. 1 loop, best of 3: 52.4 ms per loop</strong></span></pre><p id="6f27" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可以观察到我们是如何实现将构建分形的时间从<strong class="kw iu"> 4.62秒减少到52.4毫秒… </strong>并且这是通过<strong class="kw iu">添加装饰器实现的！！</strong></p><h2 id="44de" class="nw ls it bd lt oc od dn lx oe of dp mb ld og oh md lh oi oj mf ll ok ol mh om bi translated">一些常见错误</h2><p id="2685" class="pw-post-body-paragraph ku kv it kw b kx ml ju kz la mm jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">我们说过Numba <strong class="kw iu">只对数字函数</strong>有效，虽然Numba可以编译和运行任何Python代码，但是有些类型的数据它还不能编译(比如字典)，而且编译它们也没有意义。</p><pre class="kj kk kl km gt ns nj nt nu aw nv bi"><span id="70d7" class="nw ls it nj b gy nx ny l nz oa">&gt;&gt;&gt; @jit<br/>&gt;&gt;&gt; def dictionary(dict_test):<br/>&gt;&gt;&gt;    return dict_test['house']dictionary({'house': 2, 'car': 35})<br/><strong class="nj iu">2</strong></span></pre><p id="d0a3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">但它并没有失败！！</strong>我们说过Numba不编译字典…这里的重点是Numba创建了两个函数，一个用Python，另一个用Numba。这里我们看到的是python解决方案，我们可以通过做<code class="fe ng nh ni nj b">nopython = True</code>来验证这一点。</p><blockquote class="pc pd pe"><p id="3a46" class="ku kv nf kw b kx ky ju kz la lb jx lc pf le lf lg pg li lj lk ph lm ln lo lp im bi translated"><code class="fe ng nh ni nj b"><em class="it">jit(nopython = True)</em></code>相当于<code class="fe ng nh ni nj b">njit</code></p></blockquote><pre class="kj kk kl km gt ns nj nt nu aw nv bi"><span id="3dd2" class="nw ls it nj b gy nx ny l nz oa">&gt;&gt;&gt; @jit(nopython = True)<br/>&gt;&gt;&gt; def dictionary(dict_test):<br/>&gt;&gt;&gt;    return dict_test['house']dictionary({'house': 2, 'car': 35})</span><span id="9158" class="nw ls it nj b gy ob ny l nz oa"><strong class="nj iu">-----------------------------------------<br/>TypingError                Traceback (most recent call last)</strong></span><span id="2fbc" class="nw ls it nj b gy ob ny l nz oa"><strong class="nj iu">&lt;ipython-input-31-14d1c8683c01&gt; in &lt;module&gt;()<br/>      3   return dict_test['house']<br/>      4 <br/>----&gt; 5 dictionary({'house': 245, 'car': 350})2 frames</strong></span><span id="ca59" class="nw ls it nj b gy ob ny l nz oa"><strong class="nj iu">/usr/local/lib/python3.6/dist-packages/numba/six.py in reraise(tp, value, tb)<br/>    656             value = tp()<br/>    657         if value.__traceback__ is not tb:<br/>--&gt; 658             raise value.with_traceback(tb)<br/>    659         raise value<br/>    660</strong></span><span id="fd76" class="nw ls it nj b gy ob ny l nz oa"><strong class="nj iu">TypingError: Failed in nopython mode pipeline (step: nopython frontend)<br/>Internal error at &lt;numba.typeinfer.ArgConstraint object at 0x7f986c1bed68&gt;:<br/>--%&lt;-----------------------------------------</strong></span></pre><h1 id="21b7" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">GPU的Numba</h1><p id="20ea" class="pw-post-body-paragraph ku kv it kw b kx ml ju kz la mm jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">使用Numba在GPU中编程有两种方式:</p><p id="7b94" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> 1。</strong> ufuncs/gufuncs__</p><p id="bd46" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> 2。</strong> CUDA Python内核<em class="nf">(下一个教程)</em></p><h2 id="534d" class="nw ls it bd lt oc od dn lx oe of dp mb ld og oh md lh oi oj mf ll ok ol mh om bi translated">函数ufunc</h2><p id="50eb" class="pw-post-body-paragraph ku kv it kw b kx ml ju kz la mm jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated"><strong class="kw iu"> GPU的主要设计特性之一是并行处理数据的能力</strong>，因此numpy (ufunc)的通用函数是在GPU编程中实现它们的理想候选。</p><p id="3ef6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> <em class="nf">注</em> </strong> : ufunc是对numpy数组的每个元素执行相同操作的函数。例如:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq nr l"/></div></figure><h2 id="2f06" class="nw ls it bd lt oc od dn lx oe of dp mb ld og oh md lh oi oj mf ll ok ol mh om bi translated">实践:为GPU创建函数</h2><p id="3d5b" class="pw-post-body-paragraph ku kv it kw b kx ml ju kz la mm jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">正如我们之前说过的，ufunc函数是将它们与GPU一起使用的理想选择，因为它们具有并行性。因此，Numba有能力在不使用c的情况下创建编译的ufunc函数，要做到这一点，我们必须使用decorator <code class="fe ng nh ni nj b">@vectorize</code>。</p><p id="e40f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们从一个使用<code class="fe ng nh ni nj b">@vectorize</code>编译和优化CPU ufunc的例子开始。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq nr l"/></div></figure><pre class="kj kk kl km gt ns nj nt nu aw nv bi"><span id="bc7e" class="nw ls it nj b gy nx ny l nz oa"><strong class="nj iu">array([ 24, 343,  15,   9])</strong></span></pre><p id="42a7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们将在GPU中使用CUDA，而不是使用CPU来编译和执行前面的函数，为此我们必须使用“目标属性”。我们将指出每个变量的类型(参数和返回值)。</p><p id="0a51" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><code class="fe ng nh ni nj b">return_value_type(argument1_value_type, argument2_value_type, ...)</code></p><p id="e19e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为此，我们将使用前面的函数，该函数需要2个int64值并返回另一个int64值。我们将指定<code class="fe ng nh ni nj b">target = 'cuda'</code>能够在GPU中执行它。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq nr l"/></div></figure><pre class="kj kk kl km gt ns nj nt nu aw nv bi"><span id="a36b" class="nw ls it nj b gy nx ny l nz oa"><strong class="nj iu">array([ 24, 343,  15,   9])</strong></span></pre><p id="1819" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可以检查它在CPU或GPU上运行的速度:</p><pre class="kj kk kl km gt ns nj nt nu aw nv bi"><span id="7e46" class="nw ls it nj b gy nx ny l nz oa">&gt;&gt;&gt; %timeit np.add(a, b)   # Numpy en CPU</span><span id="f768" class="nw ls it nj b gy ob ny l nz oa"><strong class="nj iu">The slowest run took 38.66 times longer than the fastest. This could mean that an intermediate result is being cached. 1000000 loops, best of 3: 511 ns per loop</strong></span><span id="9052" class="nw ls it nj b gy ob ny l nz oa">&gt;&gt;&gt; %timeit add_ufunc_gpu(a, b)   # Numpy en GPU</span><span id="7d25" class="nw ls it nj b gy ob ny l nz oa"><strong class="nj iu">The slowest run took 4.01 times longer than the fastest. This could mean that an intermediate result is being cached. 1000 loops, best of 3: 755 µs per loop</strong></span></pre><p id="6157" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> GPU比CPU慢！！！安静，这有一个解释…但是首先让我们看看当我们调用那个函数时会发生什么…</strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="a3d5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">当我们执行这个函数时，Numba产生:</p><ol class=""><li id="8066" class="mj mk it kw b kx ky la lb ld nc lh nd ll ne lp mq mr ms mt bi translated"><strong class="kw iu"> <em class="nf">编译CUDA内核，对输入数组</em> </strong>的所有元素并行执行ufunc函数</li><li id="4dca" class="mj mk it kw b kx mu la mv ld mw lh mx ll my lp mq mr ms mt bi translated"><strong class="kw iu"> <em class="nf">将输入和输出分配给GPU内存</em> </strong></li><li id="b8e5" class="mj mk it kw b kx mu la mv ld mw lh mx ll my lp mq mr ms mt bi translated"><strong class="kw iu"> <em class="nf">将输入复制到GPU </em> </strong></li><li id="436d" class="mj mk it kw b kx mu la mv ld mw lh mx ll my lp mq mr ms mt bi translated"><strong class="kw iu"> <em class="nf">运行CUDA内核</em> </strong></li><li id="e062" class="mj mk it kw b kx mu la mv ld mw lh mx ll my lp mq mr ms mt bi translated"><strong class="kw iu"> <em class="nf">将结果从GPU复制回CPU </em> </strong></li><li id="fa4d" class="mj mk it kw b kx mu la mv ld mw lh mx ll my lp mq mr ms mt bi translated"><strong class="kw iu"> <em class="nf">以numpy数组的形式返回结果</em> </strong></li></ol><p id="fed9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">与C中的实现相比，Numba允许您以更简洁的方式执行这些类型的任务。</p><p id="bad2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">为什么GPU比CPU慢？</strong></p><ul class=""><li id="8370" class="mj mk it kw b kx ky la lb ld nc lh nd ll ne lp np mr ms mt bi translated">我们的输入太小:GPU使用并行性一次对数千个值进行操作来实现更好的性能。我们的输入是4或64维，我们需要更大的阵列来保持GPU被占用。</li><li id="4a6f" class="mj mk it kw b kx mu la mv ld mw lh mx ll my lp np mr ms mt bi translated">非常简单的计算:与调用CPU函数相比，将计算结果发送到GPU需要很多“努力”。如果我们的函数不需要过多的数学计算(这通常被称为*算术强度*)，那么GPU可能会比CPU花费更长的时间。</li><li id="53af" class="mj mk it kw b kx mu la mv ld mw lh mx ll my lp np mr ms mt bi translated">Numba将数据复制到GPU。</li><li id="1e35" class="mj mk it kw b kx mu la mv ld mw lh mx ll my lp np mr ms mt bi translated">我们输入的变量类型比需要的大:我们的例子使用int64，我们可能不需要它们。实际上，在CPU中，32位和64位具有相同的计算速度，但在GPU中，64位的计算速度略有增加(它可以分别比32位慢24倍)。因此，在GPU中执行函数时，记住这一点非常重要。</li></ul><p id="baf1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">考虑到这一点，我们将尝试应用前面几点学到的东西，看看在GPU上运行是否真的比CPU快。</strong>我们将计算一个密度函数，对于较大的数组，这是一个稍微复杂一点的操作。</p><p id="266b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">给定平均值和sigma，让我们计算<code class="fe ng nh ni nj b">x</code>中高斯密度函数的值:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq nr l"/></div></figure><pre class="kj kk kl km gt ns nj nt nu aw nv bi"><span id="2b28" class="nw ls it nj b gy nx ny l nz oa">&gt;&gt;&gt; %timeit norm_pdf.pdf(x, loc=mean, scale=sigma)  # CPU function<br/><strong class="nj iu">10 loops, best of 3: 60.8 ms per loop</strong></span><span id="2863" class="nw ls it nj b gy ob ny l nz oa">&gt;&gt;&gt; %timeit gaussian_dens_gpu(x, mean, sigma) # GPU function<br/><strong class="nj iu">100 loops, best of 3: 6.88 ms per loop</strong></span></pre><h1 id="d428" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">耶啊！</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pi nr l"/></div></figure><p id="3816" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们甚至可以使用Numba定义在CPU中执行的函数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq nr l"/></div></figure><pre class="kj kk kl km gt ns nj nt nu aw nv bi"><span id="3220" class="nw ls it nj b gy nx ny l nz oa">&gt;&gt;&gt; %timeit gaussian_dens_cpu(x, mean, sigma) # CPU<br/><strong class="nj iu">10 loops, best of 3: 23.6 ms per loop</strong></span></pre><p id="19f5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">它甚至比用Python编写的函数还要快，但比在GPU中执行的函数要慢。</p><p id="cd11" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">不幸的是，有几个函数不在ufunc的定义范围内，因此，为了在GPU中执行不满足该要求的函数，我们使用<code class="fe ng nh ni nj b">cuda.jit</code>。我们可以使用运行在GPU上的“设备功能”。</p><p id="f155" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> <em class="nf">注</em> </strong>:“设备函数”是只能从内核或另一个“设备”函数调用的函数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq nr l"/></div></figure><pre class="kj kk kl km gt ns nj nt nu aw nv bi"><span id="818d" class="nw ls it nj b gy nx ny l nz oa">&gt;&gt;&gt; %timeit polar_distance(rho1, theta1, rho2, theta2)<br/><strong class="nj iu">The slowest run took 23.16 times longer than the fastest. This could mean that an intermediate result is being cached. 1 loop, best of 3: 10.2 ms per loop</strong></span></pre><h1 id="6c8a" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">结论</h1><p id="d729" class="pw-post-body-paragraph ku kv it kw b kx ml ju kz la mm jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">总而言之，Numba是一个Python编译器，专门针对数值函数，允许您使用直接用Python编写的高性能函数来加速应用程序。</p><p id="5f75" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">它是一个稳定的工具，允许您优化面向数组操作的代码。感谢它的易用性<strong class="kw iu">(只是一个装修工！！)</strong>为我们提供了一个非常强大的工具来提高我们代码的性能。</p><p id="5783" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">欢迎建议和评论。关注我，感谢你的阅读！:)</p></div></div>    
</body>
</html>