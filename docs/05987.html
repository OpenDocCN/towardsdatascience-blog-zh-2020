<html>
<head>
<title>The Google’s 7 steps of Machine Learning in practice: a TensorFlow example for structured data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">谷歌机器学习实践的 7 个步骤:结构化数据的 TensorFlow 示例</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-googles-7-steps-of-machine-learning-in-practice-a-tensorflow-example-for-structured-data-96ccbb707d77?source=collection_archive---------9-----------------------#2020-05-16">https://towardsdatascience.com/the-googles-7-steps-of-machine-learning-in-practice-a-tensorflow-example-for-structured-data-96ccbb707d77?source=collection_archive---------9-----------------------#2020-05-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="dd31" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一步一步的教程，把 7 个步骤付诸实践，并从头开始建立一个机器学习模型。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a9b539c377e4b49dc433873608c37c4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*56iTiim-CNiOomjzE-lrmQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">谷歌机器学习实践的 7 个步骤</p></figure><p id="2c5b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">网上有很多很棒的机器学习教程。然而，它们中的大多数集中在机器学习的特定部分，例如，探索数据、建立模型、训练和评估。他们中很少有人介绍建立机器学习模型的完整步骤。</p><p id="001e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最受欢迎的概述机器学习过程步骤的文章之一是国玉峰的<a class="ae lu" rel="noopener" target="_blank" href="/the-7-steps-of-machine-learning-2877d7e5548e">机器学习的 7 个步骤</a>，由谷歌云平台推出。</p><p id="6e70" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">https://www.youtube.com/watch?v=nKW8Ndu7Mjw<a class="ae lu" href="https://www.youtube.com/watch?v=nKW8Ndu7Mjw" rel="noopener ugc nofollow" target="_blank"/></p><p id="24c2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">郭列出了如下 7 个步骤:</p><ol class=""><li id="4079" class="lv lw it la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated">收集数据</li><li id="ca83" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">准备数据(和探索数据)</li><li id="ad78" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">选择模型</li><li id="d2b4" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">培养</li><li id="4a5f" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">估价</li><li id="8943" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">超参数调谐</li><li id="9eeb" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">预测(和保存模型)</li></ol><p id="657d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，我们将把上述步骤付诸实践，并从头构建一个机器学习模型。</p><h1 id="33f5" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">定义问题和环境设置</h1><p id="2809" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">在我们进入细节之前，我们需要为任何机器学习项目做的第一件事是为我们的机器学习模型定义问题。</p><p id="3e20" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本教程中，我们将处理来自 Kaggle 的<a class="ae lu" href="https://www.kaggle.com/c/titanic/overview" rel="noopener ugc nofollow" target="_blank">泰坦尼克号数据集。这是一个非常著名的数据集，通常是学生学习机器的第一步。</a></p><p id="d777" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">假设我们被要求创建一个系统来预测泰坦尼克号上的幸存者。</p><h2 id="2a92" class="ng mk it bd ml nh ni dn mp nj nk dp mt lh nl nm mv ll nn no mx lp np nq mz nr bi translated">环境设置</h2><p id="51b0" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">为了运行本教程，您需要安装</p><blockquote class="ns"><p id="d4bc" class="nt nu it bd nv nw nx ny nz oa ob lt dk translated">TensorFlow 2，TensorBoard 2，numpy，pandas，matplotlib，seaborn</p></blockquote><p id="7c2f" class="pw-post-body-paragraph ky kz it la b lb oc ju ld le od jx lg lh oe lj lk ll of ln lo lp og lr ls lt im bi translated">它们都可以通过 PyPI 直接安装，我强烈建议创建一个新的虚拟环境。最好避免使用<strong class="la iu"> <em class="oh"> base(root) </em> </strong>，因为这可能会破坏您的系统。</p><p id="42ab" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您可以查看以下文章，了解如何创建 Python 虚拟环境:</p><div class="oi oj gp gr ok ol"><a rel="noopener follow" target="_blank" href="/create-virtual-environment-using-virtualenv-and-add-it-to-jupyter-notebook-6e1bf4e03415"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd iu gy z fp oq fr fs or fu fw is bi translated">使用“virtualenv”创建虚拟环境，并将其添加到 Jupyter 笔记本中</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">你是机器学习工程师，正在使用 Python 和 Jupyter Notebook 吗？在这篇文章中，你会看到为什么…</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">towardsdatascience.com</p></div></div><div class="ou l"><div class="ov l ow ox oy ou oz ks ol"/></div></div></a></div><div class="oi oj gp gr ok ol"><a href="https://medium.com/analytics-vidhya/create-virtual-environment-using-conda-and-add-it-to-jupyter-notebook-d319a81dfd1" rel="noopener follow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd iu gy z fp oq fr fs or fu fw is bi translated">使用“conda”创建虚拟环境，并将其添加到 Jupyter 笔记本中</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">你正在使用 anaconda 和使用 Jupyter Notebook 和 Python 吗？在这篇文章中，你将看到如何创建虚拟的…</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">medium.com</p></div></div><div class="ou l"><div class="pa l ow ox oy ou oz ks ol"/></div></div></a></div><h2 id="1c01" class="ng mk it bd ml nh ni dn mp nj nk dp mt lh nl nm mv ll nn no mx lp np nq mz nr bi translated">源代码</h2><p id="6ce5" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">所有的说明都在这篇文章里，我已经把笔记本开源了，源代码请查看下面的 Github 项目</p><blockquote class="ns"><p id="9df2" class="nt nu it bd nv nw nx ny nz oa ob lt dk translated">Google 的 7 步机器学习实践，在 Github 中是免费的。更多教程可从<a class="ae lu" href="https://github.com/BindiChen/machine-learning" rel="noopener ugc nofollow" target="_blank"> Github Repo </a>获得。</p></blockquote><h1 id="eca4" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz pb ka mv kc pc kd mx kf pd kg mz na bi translated">1.收集数据</h1><p id="c0b6" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">一旦我们定义了我们的问题，就到了机器学习的第一步:<strong class="la iu">收集数据</strong>。这一步最重要，因为您收集的数据的质量和数量将直接决定您的预测模型有多好。</p><p id="3f1b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本教程中，数据将来自 Kaggle。让我们导入一些库并加载数据来开始吧</p><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="48d6" class="ng mk it pf b gy pj pk l pl pm">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>%matplotlib inline</span></pre><p id="4f80" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们将<strong class="la iu"> train.csv </strong>和<strong class="la iu"> test.csv </strong>文件加载到 pandas DataFrame 中。</p><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="cbbf" class="ng mk it pf b gy pj pk l pl pm">df_train_raw = pd.<strong class="pf iu">read_csv</strong>('data/titanic/train.csv')<br/>df_test_raw = pd.<strong class="pf iu">read_csv</strong>('data/titanic/test.csv')</span><span id="b2d6" class="ng mk it pf b gy pn pk l pl pm">df_train_raw.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi po"><img src="../Images/0243839bde02c47fc405b6e5998c35a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iHyU5t4yAdkFWZ2nMn-w8Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">泰坦尼克号数据预览</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pp"><img src="../Images/27c944ae7d86ea3d72bf0cef6f1e0b11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LjhzuWmkFglARigqOXy95Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自<a class="ae lu" href="https://www.kaggle.com/c/titanic/data?select=train.csv" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>的数据字典</p></figure><h1 id="74e9" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">2.准备数据</h1><p id="e48d" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">先说一些<strong class="la iu">探索性的数据分析</strong> (EDA)。我们将从检查缺失值开始。</p><h2 id="cbea" class="ng mk it bd ml nh ni dn mp nj nk dp mt lh nl nm mv ll nn no mx lp np nq mz nr bi translated">2.1 缺失值</h2><p id="6e1e" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">我们可以使用 seaborn 创建一个简单的热图来查看哪里缺少值</p><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="3a1d" class="ng mk it pf b gy pj pk l pl pm">sns.heatmap(<strong class="pf iu">df_train_raw.isnull()</strong>, <br/>            yticklabels=False, <br/>            cbar=False, <br/>            cmap='viridis')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pq"><img src="../Images/37e0207c6a63fbf435159edc417a7508.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EFDiQt48lrE-JZPePRkhRQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">缺失值的 seaborn 热图输出</p></figure><p id="a4b8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"><em class="oh"/></strong><strong class="la iu"><em class="oh">小屋</em></strong><strong class="la iu"><em class="oh"/></strong>有缺失值。<strong class="la iu"> <em class="oh">年龄</em> </strong>缺失的比例很可能小到足以用某种形式的插补进行合理替换。查看<strong class="la iu"> <em class="oh">舱</em> </strong>列，看起来那些数据缺少太多的值，无法做一些有用的事情。我们以后很可能会去掉<strong class="la iu"> <em class="oh">舱</em> </strong>，或者改成另一个类似“已知舱:1 或 0”的特性。上船失踪的比例很小，这个教程还是留着吧。</p><h2 id="b4dd" class="ng mk it bd ml nh ni dn mp nj nk dp mt lh nl nm mv ll nn no mx lp np nq mz nr bi translated">2.2 可视化更多的数据</h2><p id="0c06" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">让我们继续将更多的数据可视化</p><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="a26d" class="ng mk it pf b gy pj pk l pl pm">sns.countplot(<strong class="pf iu">x='Survived'</strong>, data=df_train_raw, palette='RdBu_r')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pr"><img src="../Images/376c1fe2fe505e46176c746a33b35aa6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wu6DBhe9Km-vwHjMxYhhig.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">幸存的情节</p></figure><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="0ee3" class="ng mk it pf b gy pj pk l pl pm">sns.countplot(<strong class="pf iu">x='Survived',</strong> <br/>              <strong class="pf iu">hue='Sex',</strong> <br/>              data=df_train_raw,<br/>              palette='RdBu_r')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ps"><img src="../Images/79edc0ef71165ba660c03171c9fe4313.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UwhOcct_A3iJoyxjvK0wFw.png"/></div></div></figure><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="fe0a" class="ng mk it pf b gy pj pk l pl pm">sns.countplot(<strong class="pf iu">x='Survived',</strong><br/>              <strong class="pf iu">hue='Pclass',</strong> <br/>              data=df_train_raw,<br/>              palette='rainbow')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pt"><img src="../Images/e7c6cb4876004bcbe737ec19c240eb80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZdJ47ZLACMKUBpRjSMJ6pw.png"/></div></div></figure><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="393f" class="ng mk it pf b gy pj pk l pl pm">sns.distplot(<strong class="pf iu">df_train_raw['Age'].dropna(),</strong><br/>             <strong class="pf iu">kde=True,</strong><br/>             color='darkred',<br/>             bins=30)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pu"><img src="../Images/84edebb2cc8376f121cff78d22e96ab7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jiceTKB8X2RUHJyxZ-tnBA.png"/></div></div></figure><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="e161" class="ng mk it pf b gy pj pk l pl pm">sns.countplot(x='SibSp',data=df_train_raw)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pv"><img src="../Images/f0e583a74a71353be7392f7cff4487f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sKFpoVo9NZ-TDclB9Lh6cw.png"/></div></div></figure><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="acb7" class="ng mk it pf b gy pj pk l pl pm">df_train_raw['Fare'].hist(color='green', <br/>                          bins=40, <br/>                          figsize=(8,4))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pw"><img src="../Images/846d17dcec7d5636a9c2ac94a03942bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GSAAYME6nPIsbqgOj5jRsg.png"/></div></div></figure><h2 id="6f31" class="ng mk it bd ml nh ni dn mp nj nk dp mt lh nl nm mv ll nn no mx lp np nq mz nr bi translated">2.3 数据清理</h2><p id="5c0b" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">我们想用某种形式的插补来代替缺失的年龄。一种方法是填写所有乘客的平均年龄。然而，我们可以更聪明地处理这个问题，按乘客级别检查平均年龄。例如:</p><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="fd42" class="ng mk it pf b gy pj pk l pl pm">sns.boxplot(<strong class="pf iu">x='Pclass',</strong><br/>            <strong class="pf iu">y='Age',</strong><br/>            data=df_train_raw,<br/>            palette='winter')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi px"><img src="../Images/1aec379c525fbafa5ac2c18e2be60601.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P3Gyu5-oSgRvQ4xFfklvsg.png"/></div></div></figure><p id="b49c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以看到，在较高的阶层中，较富裕的乘客往往年龄较大，这是有道理的。我们将根据年龄的 Pclass 使用这些平均年龄值进行估算。</p><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="f36b" class="ng mk it pf b gy pj pk l pl pm">def impute_age(cols):<br/>    Age = cols[0]<br/>    Pclass = cols[1]<br/>    <br/>    if pd.isnull(Age):<br/>        <strong class="pf iu">if Pclass == 1:</strong><br/>            return 37<br/>        <strong class="pf iu">elif Pclass == 2:</strong><br/>            return 29<br/>        <strong class="pf iu">else:</strong><br/>            return 24<br/>    else:<br/>        return Age</span></pre><p id="47aa" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在让我们应用这个函数并检查它是否工作</p><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="eae5" class="ng mk it pf b gy pj pk l pl pm"># Make a copy for test only<br/>train_copy = df_train_raw.copy() <br/>train_copy['Age'] = train_copy[['Age','Pclass']]<br/>   <strong class="pf iu">.apply(impute_age, axis=1)</strong></span><span id="eee1" class="ng mk it pf b gy pn pk l pl pm"># check that heat map again<br/>sns.heatmap(<strong class="pf iu">train_copy.isnull(),</strong> <br/>            yticklabels=False, <br/>            cbar=False, <br/>            cmap='viridis')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi py"><img src="../Images/ae4cd7f22f41d6ff8b41fe839b78cc8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nO4GKl5JhtM7l1Vuffshgg.png"/></div></div></figure><p id="e7c1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">太好了！<code class="fe pz qa qb pf b">impute_age()</code>作品。让我们继续转换分类特征并删除<strong class="la iu"> <em class="oh">小屋</em> </strong>列。</p><h2 id="b311" class="ng mk it bd ml nh ni dn mp nj nk dp mt lh nl nm mv ll nn no mx lp np nq mz nr bi translated">2.4 转换分类特征</h2><p id="1701" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">我们需要将分类特征转换成<a class="ae lu" rel="noopener" target="_blank" href="/what-is-one-hot-encoding-and-how-to-use-pandas-get-dummies-function-922eb9bd4970">一次性编码</a>。否则，我们的机器学习算法将无法直接将这些特征作为输入。</p><p id="1a6d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们用<code class="fe pz qa qb pf b">info()</code>检查列数据类型</p><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="68f8" class="ng mk it pf b gy pj pk l pl pm">df_train_raw.info()</span><span id="a330" class="ng mk it pf b gy pn pk l pl pm">&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 712 entries, 0 to 711<br/>Data columns (total 12 columns):<br/> #   Column       Non-Null Count  Dtype  <br/>---  ------       --------------  -----  <br/> 0   PassengerId  712 non-null    int64  <br/> 1   Survived     712 non-null    int64  <br/> 2   Pclass       712 non-null    int64  <br/> 3   Name         712 non-null    <strong class="pf iu">object</strong> <br/> 4   Sex          712 non-null    <strong class="pf iu">object</strong> <br/> 5   Age          566 non-null    float64<br/> 6   SibSp        712 non-null    int64  <br/> 7   Parch        712 non-null    int64  <br/> 8   Ticket       712 non-null    <strong class="pf iu">object</strong> <br/> 9   Fare         712 non-null    float64<br/> 10  Cabin        168 non-null    <strong class="pf iu">object</strong> <br/> 11  Embarked     710 non-null    <strong class="pf iu">object</strong> <br/>dtypes: float64(2), int64(5), <strong class="pf iu">object(5)</strong><br/>memory usage: 66.9+ KB</span></pre><p id="d062" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">有 5 列的数据类型为 object。其中<strong class="la iu"> <em class="oh">姓名</em> </strong>、<strong class="la iu"> <em class="oh">车票</em> </strong>、<strong class="la iu"> <em class="oh">客舱</em> </strong>不需要。另外，我们注意到<strong class="la iu"> <em class="oh"> Pclass </em> </strong>根据我们上面看到的数据字典是一个分类数据。让我们制作一个函数<code class="fe pz qa qb pf b">preprocessing()</code>来保留这些有用的数字特征，并将<strong class="la iu"> <em class="oh"> Pclass </em> </strong>，<strong class="la iu"> <em class="oh"> Sex，</em> </strong>和<em class="oh">apolled</em>转换成一键编码。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qc"><img src="../Images/8254b93a835d03adcec2404fe41db15f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TPn13dVDKbMvtR4bT7BjDg.png"/></div></div></figure><p id="9459" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们应用该函数，并为构建我们的机器学习模型创建训练和测试数据集。</p><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="3f1c" class="ng mk it pf b gy pj pk l pl pm">x_train = <strong class="pf iu">preprocessing(df_train_raw)</strong><br/>y_train = <strong class="pf iu">df_train_raw['Survived'].values</strong></span><span id="7d50" class="ng mk it pf b gy pn pk l pl pm">x_test = <strong class="pf iu">preprocessing(df_test_raw)</strong><br/>y_test = <strong class="pf iu">df_test_raw['Survived'].values</strong></span><span id="bfc0" class="ng mk it pf b gy pn pk l pl pm">print("x_train.shape =", x_train.shape )<br/>print("x_test.shape =", x_test.shape )</span></pre><p id="412a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">通过上面的运行，您应该得到如下所示的训练和测试数据集的形状:</p><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="e208" class="ng mk it pf b gy pj pk l pl pm">x_train.shape = (712, 13)<br/>x_test.shape = (179, 13)</span></pre><p id="663d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们看看<code class="fe pz qa qb pf b">x_train.head()</code>的数据</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qd"><img src="../Images/cb79e6266ed5d5b5c09adc11a50eb8e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m4NywFmumSXJL9yZ3CaW7A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我们的数据经过<code class="fe pz qa qb pf b">preprocessing()</code></p></figure><p id="c5c4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">太好了！我们的数据已经可以建模了</p><h1 id="4bf5" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">3.选择型号</h1><p id="c7b0" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">在 TensorFlow 2.0 中有三种方法实现神经网络架构:</p><ul class=""><li id="c6d6" class="lv lw it la b lb lc le lf lh lx ll ly lp lz lt qe mb mc md bi translated"><strong class="la iu">顺序模型</strong>:是使用 Keras 最简单的方法。</li><li id="52e1" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt qe mb mc md bi translated"><strong class="la iu">功能 API </strong>:针对更复杂的模型。</li><li id="4692" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt qe mb mc md bi translated"><strong class="la iu">模型子类</strong>:完全可定制，使您能够实现自己定制的模型前向传递。</li></ul><p id="86af" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为简单起见，我们用最简单的方法:带<code class="fe pz qa qb pf b">Sequential()</code>的时序模型。让我们继续建立一个具有 3 个密集层的神经网络。每层中的所有参数都已硬编码，如下所示:</p><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="2ea5" class="ng mk it pf b gy pj pk l pl pm">import tensorflow as tf <br/>from tensorflow.keras import models, layers</span><span id="6b0a" class="ng mk it pf b gy pn pk l pl pm">tf.keras.backend.clear_session()</span><span id="0575" class="ng mk it pf b gy pn pk l pl pm">model = <strong class="pf iu">models.Sequential()</strong><br/>model.add(<strong class="pf iu">layers.Dense(10, activation='relu', input_shape=(13,)</strong>))<br/>model.add(<strong class="pf iu">layers.Dense(20, activation='relu' )</strong>)<br/>model.add(<strong class="pf iu">layers.Dense(1, activation='sigmoid')</strong>)</span><span id="cb2e" class="ng mk it pf b gy pn pk l pl pm">model.summary()</span></pre><p id="ddec" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面是<code class="fe pz qa qb pf b">model.summary()</code>的输出</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qf"><img src="../Images/0444f51c7551685c56ac1e3928f1b2f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6aq1gN8A-rKHY8I41rUoeA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><code class="fe pz qa qb pf b">model.summary()</code>的输出</p></figure><h1 id="9685" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">4.培养</h1><p id="325a" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">首先，让我们使用<code class="fe pz qa qb pf b">model.compile()</code>来配置我们的模型</p><ul class=""><li id="6f51" class="lv lw it la b lb lc le lf lh lx ll ly lp lz lt qe mb mc md bi translated">使用优化器<strong class="la iu">随机梯度下降</strong>(缩写为<code class="fe pz qa qb pf b">sgd</code>)</li><li id="3b7c" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt qe mb mc md bi translated">使用二元交叉熵损失函数(<code class="fe pz qa qb pf b">binary_crossentropy</code>)用于我们的二元分类</li><li id="cdd0" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt qe mb mc md bi translated">为简单起见，使用<code class="fe pz qa qb pf b">'accuracy'</code>作为我们在训练和测试期间评估模型的评估指标</li></ul><p id="5826" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于训练，有三种方法可以训练 Keras 模型:</p><ul class=""><li id="14e2" class="lv lw it la b lb lc le lf lh lx ll ly lp lz lt qe mb mc md bi translated">将<code class="fe pz qa qb pf b">model.fit()</code>用于固定历元数的模型</li><li id="fdf3" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt qe mb mc md bi translated">使用<code class="fe pz qa qb pf b">model.train_on_batch()</code>只进行一次单批次训练。</li><li id="0bd7" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt qe mb mc md bi translated">创建自定义训练循环。</li></ul><p id="0274" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本教程中，让我们用最简单的方法<code class="fe pz qa qb pf b">model.fit()</code>继续。</p><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="f18f" class="ng mk it pf b gy pj pk l pl pm"># Convert DataFrame into np array<br/>x_train = np.asarray(x_train)<br/>y_train = np.asarray(y_train)</span><span id="ecdb" class="ng mk it pf b gy pn pk l pl pm"># Get around with KMP duplicate issue<br/>import os<br/>os.environ['KMP_DUPLICATE_LIB_OK']='True'</span><span id="191c" class="ng mk it pf b gy pn pk l pl pm"># Use binary cross entropy loss function for binary classification<br/>model.compile(<strong class="pf iu">optimizer='sgd'</strong>,<br/>            <strong class="pf iu">loss='binary_crossentropy'</strong>,<br/>            <strong class="pf iu">metrics=['accuracy']</strong>)</span><span id="ade4" class="ng mk it pf b gy pn pk l pl pm">history = <strong class="pf iu">model.fit</strong>(x_train,y_train,<br/>                    batch_size= 64,<br/>                    epochs= 30,<br/>                    validation_split=0.2<br/>                   )</span></pre><p id="4489" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果一切顺利，我们应该得到如下输出。</p><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="46f8" class="ng mk it pf b gy pj pk l pl pm">Train on 569 samples, validate on 143 samples<br/>Epoch 1/30<br/>569/569 [==============================] - 1s 2ms/sample - loss: 0.5568 - accuracy: 0.7206 - val_loss: 0.6139 - val_accuracy: 0.6713<br/>Epoch 2/30<br/>569/569 [==============================] - 0s 91us/sample - loss: 0.5639 - accuracy: 0.7047 - val_loss: 0.6212 - val_accuracy: 0.6643<br/>Epoch 3/30<br/>569/569 [==============================] - 0s 112us/sample - loss: 0.5705 - accuracy: 0.6907 - val_loss: 0.6379 - val_accuracy: 0.6573<br/>Epoch 4/30<br/>569/569 [==============================] - 0s 109us/sample - loss: 0.5538 - accuracy: 0.7065 - val_loss: 0.6212 - val_accuracy: 0.6713<br/>......<br/>......<br/>Epoch 30/30<br/>569/569 [==============================] - 0s 102us/sample - loss: 0.5597 - accuracy: 0.7065 - val_loss: 0.6056 - val_accuracy: 0.7203</span></pre><h1 id="ea97" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">5.模型评估</h1><p id="0889" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">一旦训练完成，就该看看模型是否适合模型评估了。模型评估通常包括</p><ol class=""><li id="d3da" class="lv lw it la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated">绘制<strong class="la iu">损失</strong>和<strong class="la iu">准确性</strong>指标的进度</li><li id="7f52" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">用从未用于训练的数据来测试我们的模型。这就是我们之前搁置的测试数据集<code class="fe pz qa qb pf b">df_test</code>发挥作用的地方。</li></ol><p id="0ddd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们创建一个函数<code class="fe pz qa qb pf b">plot_metric()</code>来绘制指标。</p><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="15c3" class="ng mk it pf b gy pj pk l pl pm">%matplotlib inline<br/>%config InlineBackend.figure_format = 'svg'</span><span id="5761" class="ng mk it pf b gy pn pk l pl pm">def plot_metric(history, metric):<br/>    train_metrics = history.history[metric]<br/>    val_metrics = history.history['val_'+metric]<br/>    epochs = range(1, len(train_metrics) + 1)<br/>    plt.plot(epochs, train_metrics, 'bo--')<br/>    plt.plot(epochs, val_metrics, 'ro-')<br/>    plt.title('Training and validation '+ metric)<br/>    plt.xlabel("Epochs")<br/>    plt.ylabel(metric)<br/>    plt.legend(["train_"+metric, 'val_'+metric])<br/>    plt.show()</span></pre><p id="b121" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">通过运行<code class="fe pz qa qb pf b">plot_metric(history, 'loss')</code>来绘制损失进度。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qg"><img src="../Images/6756b17c4d2efb75ec32a69f552699ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1ygY6lc5DtDeveOG5PG4bQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">损失图</p></figure><p id="e607" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">通过运行<code class="fe pz qa qb pf b">plot_metric(history, 'accuracy')</code>绘制精度进度。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qh"><img src="../Images/0b71abb95febff6d500791206e5ac916.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vgFEbCrQCiU9aTgPlMcqRg.png"/></div></div></figure><p id="e16b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">根据测试数据集测试我们的模型</p><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="2459" class="ng mk it pf b gy pj pk l pl pm"># Convert DataFrame into np array<br/>x_test = np.asarray(x_test)<br/>y_test = np.asarray(y_test)</span><span id="58d4" class="ng mk it pf b gy pn pk l pl pm"><strong class="pf iu">model.evaluate(x = x_test,y = y_test)</strong></span></pre><p id="556d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们应该得到一个具有损耗和精度的输出，如下所示:</p><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="65d6" class="ng mk it pf b gy pj pk l pl pm">179/1 [====] - 0s 43us/sample - <strong class="pf iu">loss: 0.5910</strong> - <strong class="pf iu">accuracy: 0.6760</strong></span><span id="4c88" class="ng mk it pf b gy pn pk l pl pm">[0.5850795357586951, 0.67597765]</span></pre><h1 id="f7c4" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">6.超参数调谐</h1><p id="9229" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">酷，我们已经对我们的第一个机器学习模型进行了评估。现在是时候看看我们是否能以任何方式进一步改善这种情况了。我们可以通过转动超参数来做到这一点。在我们进行第一次培训时，我们隐含地假设了一些参数，现在是时候回去测试这些假设并尝试其他值了。</p><p id="34eb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于本教程，我们只关注模型中以下三个超参数的实验:</p><ol class=""><li id="b2aa" class="lv lw it la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated">第一密集层中的单元数</li><li id="4030" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">第二密集层中的单元数</li><li id="2441" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">【计算机】优化程序</li></ol><h2 id="3f6a" class="ng mk it bd ml nh ni dn mp nj nk dp mt lh nl nm mv ll nn no mx lp np nq mz nr bi translated">6.1 实验设置</h2><p id="55a3" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">首先，从加载 TensorBoard 笔记本扩展开始</p><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="6d12" class="ng mk it pf b gy pj pk l pl pm"># Load the TensorBoard notebook extension<br/><strong class="pf iu">%load_ext tensorboard</strong></span></pre><p id="0965" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后，添加一条语句来清除上一次运行的所有日志。如果你不清理它们，它会把你的仪表板搞乱。</p><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="fa0f" class="ng mk it pf b gy pj pk l pl pm"># Clear any logs from previous runs<br/><strong class="pf iu">!rm -rf ./logs/</strong></span></pre><p id="d511" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">导入 TensorBoard HParams 插件:</p><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="a375" class="ng mk it pf b gy pj pk l pl pm"><strong class="pf iu">from tensorboard.plugins.hparams import api as hp</strong></span></pre><p id="32a3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">列出要尝试的值，并将实验配置记录到 TensorBoard。</p><ul class=""><li id="8340" class="lv lw it la b lb lc le lf lh lx ll ly lp lz lt qe mb mc md bi translated"><code class="fe pz qa qb pf b">5</code>、<code class="fe pz qa qb pf b">10</code>、<code class="fe pz qa qb pf b">20</code>为第一层单元数</li><li id="d5c7" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt qe mb mc md bi translated"><code class="fe pz qa qb pf b">10</code>、<code class="fe pz qa qb pf b">20</code>、<code class="fe pz qa qb pf b">40</code>为第二层单元数</li><li id="7496" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt qe mb mc md bi translated">优化器的<code class="fe pz qa qb pf b">adam</code>和<code class="fe pz qa qb pf b">sgd</code></li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qi"><img src="../Images/6b5e9db2582aefa04683babd62392ddb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BLZSt1utGCRyZ2ce4UTy6g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">超参数调谐的实验设置</p></figure><h2 id="3e37" class="ng mk it bd ml nh ni dn mp nj nk dp mt lh nl nm mv ll nn no mx lp np nq mz nr bi translated">6.2 调整 TensorFlow 运行以记录超参数和指标</h2><p id="cb28" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">我们的模型很简单:3 个密集层。代码看起来很熟悉，尽管超参数不再是硬编码的。相反，超参数在<code class="fe pz qa qb pf b">hyparams</code>字典中提供，并在整个训练功能中使用:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qj"><img src="../Images/531d569b503620a773f617ade7fbddd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rty6asLj81uPObfEzCx8XQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">调整 tensorflow 运行以记录超参数和指标</p></figure><p id="ee0e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于每次运行，记录一份<code class="fe pz qa qb pf b">hparams</code>摘要，包括超参数和最终精度</p><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="5379" class="ng mk it pf b gy pj pk l pl pm">def run(run_dir, hparams):<br/>  with tf.summary.create_file_writer(run_dir).as_default():<br/>    hp.hparams(hparams)  # record the values used in this trial<br/>    accuracy = <strong class="pf iu">train_test_model(hparams)</strong><br/>    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)</span></pre><h2 id="42ba" class="ng mk it bd ml nh ni dn mp nj nk dp mt lh nl nm mv ll nn no mx lp np nq mz nr bi translated">6.3 开始运行并记录它们</h2><p id="c794" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">我们现在可以尝试多个实验，用一套不同的超短波来训练每个实验。为了简单起见，让我们使用一个<strong class="la iu"> <em class="oh">网格搜索</em> </strong>来尝试离散参数的所有组合，并且只尝试实值参数的上下界。</p><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="c526" class="ng mk it pf b gy pj pk l pl pm">session_num = 0</span><span id="db3c" class="ng mk it pf b gy pn pk l pl pm">for num_units_one in HP_NUM_UNITS_ONE.domain.values:<br/>  for num_units_two in HP_NUM_UNITS_TWO.domain.values:<br/>    for optimizer in HP_OPTIMIZER.domain.values:<br/>      <strong class="pf iu">hparams = {<br/>          HP_NUM_UNITS_ONE: num_units_one,<br/>          HP_NUM_UNITS_TWO: num_units_two,<br/>          HP_OPTIMIZER: optimizer,<br/>      }</strong><br/>      run_name = "run-%d" % session_num<br/>      print('&gt;&gt; Starting trial: %s' % run_name)<br/>      print({h.name: hparams[h] for h in hparams})<br/>      <strong class="pf iu">run('logs/hparam_tuning/' + run_name, hparams)</strong><br/>      session_num += 1</span></pre><p id="38fb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果一切顺利，我们应该得到如下输出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qk"><img src="../Images/f318cbcbb2d21bfd5c49bc4013dbb93a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*G_5r9Cb43_Yi-ch7-BmcMw.gif"/></div></div></figure><h2 id="48b0" class="ng mk it bd ml nh ni dn mp nj nk dp mt lh nl nm mv ll nn no mx lp np nq mz nr bi translated">6.4 在 TensorBoard 的 HParams 插件中可视化结果</h2><p id="072f" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">一旦运行完成，打开你的终端和<code class="fe pz qa qb pf b">cd</code>进入项目目录。然后，现在可以通过在终端中运行以下命令来打开 HParams 仪表板</p><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="4058" class="ng mk it pf b gy pj pk l pl pm">admin@Mac:~/Code/WorkSpace/machine-learning/tf2<br/>⇒  <strong class="pf iu">tensorboard --logdir logs/hparam_tuning</strong></span><span id="5b98" class="ng mk it pf b gy pn pk l pl pm">Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all</span><span id="1d31" class="ng mk it pf b gy pn pk l pl pm">TensorBoard 2.0.0 at <a class="ae lu" href="http://localhost:6006/" rel="noopener ugc nofollow" target="_blank">http://localhost:6006/</a> (Press CTRL+C to quit)</span></pre><p id="d649" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在浏览器中打开仪表板，直接进入<strong class="la iu"> HPARAMS </strong> - &gt; <strong class="la iu">平行坐标视图</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ql"><img src="../Images/91fda73000b0dfde815180da0dc54555.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*HqHGJxDzkQjmNNHrCXlWkg.gif"/></div></div></figure><p id="9a10" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">通过查看<strong class="la iu">平行坐标视图</strong>，点击并拖动精度轴，可以选择精度最高的运行。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qm"><img src="../Images/692bb8bec28a41f5ff080e69cac68211.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VeRvdlvGWlQq3HMO3-ucCw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">表现最好的那个</p></figure><p id="43e9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当这些运行通过不同的超参数时，我们可以得出结论</p><ul class=""><li id="6d30" class="lv lw it la b lb lc le lf lh lx ll ly lp lz lt qe mb mc md bi translated"><code class="fe pz qa qb pf b"><strong class="la iu">5</strong></code> <strong class="la iu"> </strong>单位<strong class="la iu"> </strong>在第一层、</li><li id="4d72" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt qe mb mc md bi translated"><code class="fe pz qa qb pf b"><strong class="la iu">10</strong></code> <strong class="la iu"> </strong>单位在第二层，</li><li id="19fc" class="lv lw it la b lb me le mf lh mg ll mh lp mi lt qe mb mc md bi translated">和<strong class="la iu"> </strong>同<strong class="la iu"> </strong> <code class="fe pz qa qb pf b"><strong class="la iu">'adam'</strong></code> <strong class="la iu"> </strong>优化器</li></ul><p id="b299" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这些实验中表现最好。</p><h1 id="d948" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">7.预测(和保存模型)</h1><p id="a772" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">现在，我们已经得到了精确度最好的机器学习模型。最后一步是使用这个模型进行预测或推断。这是所有这些工作的重点，也是机器学习的价值得以实现的地方。我们终于可以用我们的模型来预测乘客是否幸存。</p><p id="2bce" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用模型进行预测</p><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="3f52" class="ng mk it pf b gy pj pk l pl pm"><strong class="pf iu">model.predict</strong>(x_test[0:10])</span><span id="d539" class="ng mk it pf b gy pn pk l pl pm">array([[0.56895125],<br/>       [0.37735564],<br/>       [0.5005745 ],<br/>       [0.60003537],<br/>       [0.5371451 ],<br/>       [0.36402294],<br/>       [0.49169463],<br/>       [0.49049523],<br/>       [0.4984674 ],<br/>       [0.1470165 ]], dtype=float32)</span></pre><p id="2973" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用模型为输入样本生成分类预测。</p><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="835c" class="ng mk it pf b gy pj pk l pl pm"><strong class="pf iu">model.predict_classes</strong>(x_test[0:10])</span><span id="522b" class="ng mk it pf b gy pn pk l pl pm">array([[1],<br/>       [0],<br/>       [1],<br/>       [1],<br/>       [1],<br/>       [0],<br/>       [0],<br/>       [0],<br/>       [0],<br/>       [0]], dtype=int32)</span></pre><p id="b7f5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，我们可以将整个模型保存到一个 HDF5 文件中:</p><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="88cc" class="ng mk it pf b gy pj pk l pl pm">model.<strong class="pf iu">save</strong>('data/keras_model.h5')</span></pre><p id="34d4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">并加载通过<code class="fe pz qa qb pf b">save()</code>保存的模型</p><pre class="kj kk kl km gt pe pf pg ph aw pi bi"><span id="9f74" class="ng mk it pf b gy pj pk l pl pm">model = <strong class="pf iu">models.load_model</strong>('data/keras_model.h5')</span><span id="9ffd" class="ng mk it pf b gy pn pk l pl pm"># Predict class<br/>model.predict_classes(x_test[0:10])</span></pre><h1 id="6eaf" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">就这样，接下来呢？</h1><p id="cb64" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">本文是一个快速教程，主要是向大家展示如何将 Google 的机器学习 7 步付诸实践。我试图避免许多机器学习概念，并尽可能使本教程简单。</p><p id="4e5b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请在我的 Github  上查看<a class="ae lu" href="https://github.com/BindiChen/machine-learning/blob/master/tensorflow2/001-googles-7-steps-of-machine-learning-in-practice/001-googles-7-steps-of-machine-learning-in-practice.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu">笔记本获取源代码。</strong></a></p><p id="8495" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在实际应用中，需要考虑的因素要多得多。例如，选择评估度量、特征缩放、选择有意义的特征、分割数据集、处理过拟合和欠拟合等。此外，本教程仅针对结构化数据，现实世界中的数据并不总是结构化数据，所有像图像、音频或文本这样的东西都是非结构化数据。</p><p id="0022" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下一次，我们将构建一个 Keras 机器学习模型，它有三种不同的方式:顺序、函数和模型子类化。</p><p id="97ff" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你对机器学习的实用方面感兴趣，请继续关注。</p></div></div>    
</body>
</html>