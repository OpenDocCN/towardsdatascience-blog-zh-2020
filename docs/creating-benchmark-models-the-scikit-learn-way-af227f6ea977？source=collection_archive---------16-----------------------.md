# 以 scikit-learn 方式创建基准模型

> 原文：<https://towardsdatascience.com/creating-benchmark-models-the-scikit-learn-way-af227f6ea977?source=collection_archive---------16----------------------->

![](img/7d1d7545d5aa06027930717c1a4811bb.png)

来源: [pixabay](https://pixabay.com/photos/work-typing-computer-notebook-731198/)

## 了解如何为分类和回归问题创建一系列基准模型

我真正喜欢`scikit-learn`的是我经常偶然发现一些我以前没有意识到的功能。我最近的“发现”是`DummyClassifier`。虚拟估计器不从特征中学习任何模式，它使用简单的试探法(从目标中推断)来计算预测。

我们可以使用那个简单的估计量作为我们更高级模型的一个简单的健全性检查。为了通过检查，所考虑的模型应该产生比简单基准更好的性能。

在这篇短文中，我将展示如何使用`DummyClassifier`,并解释可用的启发式方法。

# 设置

我们需要导入所需的库:

在本文中，我编写了一个简单的函数，打印一些选择的评估指标来评估模型的性能。除了准确性之外，我还包括了在类不平衡的情况下有助于评估性能的指标(这个列表并不详尽)。

# 加载数据

对于本文，我使用著名的 Iris 数据集。为了进一步简化问题，我将多类问题转化为二元分类，同时引入类不平衡。这个练习的目的是预测给定的植物是属于杂色类还是“其他”(Setosa 或 Virginica)。

改造后班级比例为 2:1。

训练模型前的最后一步是使用`train_test_split`函数将数据分成训练集和测试集:

因为我们有意引入了阶级不平衡

# 探索`DummyClassifier`的变种

`DummyClassifier`估计器提供了一些可能的规则(称为策略)，我们可以用它们来确定基准类预测。下面我将简要描述它们，并给出相应的代码片段来展示实现。

## “持续”战略

可以说是虚拟分类器的最简单的变体。这个想法是用一个值代替所有的标签。这种变体的一个可能的用例是，当我们想要根据 F1 分数来评估一个潜在的评估者时，F1 分数是精确度和召回率的调和平均值。

我使用少数类(Versicolour)来创建天真的预测。同样值得一提的是，这些特性在确定预测值时不起任何作用，它们只是为了匹配`scikit-learn`的 fit + predict 风格。在下面的总结中，我们看到我们实现了完美的回忆，F1 得分为 0.5。

```
{'accuracy': 0.3333333333333333,
 'recall': 1.0,
 'precision': 0.3333333333333333,
 'f1_score': 0.5}
```

## “统一”战略

在这个变体中，从可用的类中随机地(一致地)生成天真的预测。

运行代码会产生以下摘要:

```
{'accuracy': 0.4,
 'recall': 0.4,
 'precision': 0.25,
 'f1_score': 0.3076923076923077}
```

此外，我们使用`Counter`检查预测标签的分布:

```
Counter({0: 14, 1: 16})
```

正如均匀绘制所预期的，目标的分布是随机的，并不反映标签的真实分布。

## “分层”战略

为了解决前面提到的缺点，我们可以使用`stratified`规则。预测是随机生成的，但是保留了来自训练集的类的分布。正如在分层的`train_test_split`中一样。

运行代码会产生以下摘要:

```
{'accuracy': 0.6333333333333333,
 'recall': 0.3,
 'precision': 0.42857142857142855,
 'f1_score': 0.3529411764705882}
```

我们再一次查看每一类的观察次数:

```
Counter({0: 23, 1: 7})
```

使用``stratified``策略会产生类似于我们在观察值中看到的分布。

## “最频繁”策略

策略的名称很容易理解——预测值是标签中最常见的值。

运行代码会产生以下摘要:

```
{'accuracy': 0.6666666666666666,
 'recall': 0.0,
 'precision': 0.0,
 'f1_score': 0.0}
```

运行代码时，我们收到以下警告:`UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.`原因是我们选择的策略。由于多数类用于所有预测，因此没有少数类的观测值，并且无法计算精度和召回率等指标。

## “优先”策略

与`‘most_frequent’`策略非常相似的策略。伪分类器总是预测最大化类先验的类。区别在于拟合分类器的`predict_proba`方法。在`‘prior’`策略的情况下，它返回类别先验(类别概率由训练集中标签的比率决定)。

`‘prior’`和`‘most_frequent’`策略的结果是相同的，所以为了简洁起见，我不再展示它们。

值得一提的是，对于所有策略，`predict`方法完全忽略了输入数据，用作预测的值是在拟合阶段确定的(或在使用`‘constant’`策略时由我们提供)。

# 训练一个实际的评估者

在尝试了创建基准模型的多种策略之后，是时候训练一个简单的分类器并评估它是否优于基准了。为此，我使用带有默认设置的决策树分类器(除了为再现性指定的`random_state`)。

通过检查下面的总结，我们可以清楚地表明决策树优于所有的基准。

```
{'accuracy': 0.9473684210526315,
 'recall': 0.9230769230769231,
 'precision': 0.9230769230769231,
 'f1_score': 0.9230769230769231}
```

# DummyRegressor

我已经展示了如何使用`scikit-learn`的`DummyClassifier`来评估分类任务的基准模型。自然，回归问题存在一个类比估计量——`DummyRegressor`。我就不赘述了，因为用法和`DummyClassifier`很像。为了完整起见，我只提到可用的策略:

*   `'mean’` —估计器使用目标(来自训练集)的平均值作为预测
*   `'median’` —估计器使用目标(训练集)的中值作为预测
*   `'constant’` —估计器使用常数值作为预测值
*   `'quantile’` —估计器使用目标(训练集)的指定分位数作为预测

与`DummyClassifier`类似，`predict`方法忽略计算预测的输入数据。

# 结论

在本文中，我展示了如何使用简单的试探法使用`scikit-learn`中可用的估计器来创建基准模型。我们可以使用这样的模型进行健全性检查，看看我们的评估者是否比天真的基线表现得更好。如果不是，我们应该调查是什么导致了这个问题(也许这些特性没有帮助或者类的不平衡影响了结果)。

您可以在我的 [GitHub](https://github.com/erykml/medium_articles/blob/master/Machine%20Learning/dummy_classifier_intro.ipynb) 上找到本文使用的代码。一如既往，我们欢迎任何建设性的反馈。你可以在推特上或者评论里联系我。

我最近出版了一本关于使用 Python 解决金融领域实际任务的书。如果你有兴趣，我贴了一篇文章介绍这本书的内容。你可以在亚马逊或者 Packt 的网站上买到这本书。