<html>
<head>
<title>Database Migration using AWS Data Migration Service (DMS) — A few lessons learnt along the way</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 AWS 数据迁移服务(DMS)进行数据库迁移—一路走来的一些经验教训</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/database-migration-using-aws-data-migration-service-dms-a-few-lessons-learnt-along-the-way-8c9a1624b8db?source=collection_archive---------45-----------------------#2020-07-27">https://towardsdatascience.com/database-migration-using-aws-data-migration-service-dms-a-few-lessons-learnt-along-the-way-8c9a1624b8db?source=collection_archive---------45-----------------------#2020-07-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="daef" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Oracle 数据库到 Amazon Aurora PostgreSQL 的异构迁移</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/0b3abf11c6316bda31ce987ac1c38732.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*5VWaWlDUZllPuIbFTMUjcQ.jpeg"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图片由 Pixabay 提供</p></figure><p id="2b3a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最近，我们将一个相当大的内部 Oracle 数据库迁移到了 Amazon Aurora PostgreSQL。开始不同数据库平台之间的异构迁移从来都不容易。将此与将数据库迁移到云结合起来，无疑增加了挑战。</p><p id="59c0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">本文的目的是分享迁移方法，并强调我们遇到的一些问题和陷阱。</p><h1 id="4bbb" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">关于内部 Oracle 数据库</h1><p id="475a" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated"><strong class="kw iu">数据库版本:</strong> Oracle 企业版 12</p><p id="bb76" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">数据大小:</strong> 1.6 TB</p><p id="01ff" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">最大的表大小:</strong>90 亿行，超过 2000 个分区和子分区</p><h1 id="1fe1" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">迁移方法</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi mn"><img src="../Images/fc99da51abb8e0293441430788743bbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xE-_Wa_nEh7tuH0hwkk-WQ.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">(<em class="ms">图片作者</em>)</p></figure><p id="e2c6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">由于数据的大小相当大，我们决定不要让 AWS DMS 使用 VPN 连接从本地位置获取源数据。相反，我们选择了 Amazon EC2 上的一个临时 Oracle 实例。毫无疑问，从性能角度来看，这很有意义。</p><h2 id="1a4a" class="mt lr it bd ls mu mv dn lw mw mx dp ma ld my mz mc lh na nb me ll nc nd mg ne bi translated">数据恢复</h2><ol class=""><li id="efa3" class="nf ng it kw b kx mi la mj ld nh lh ni ll nj lp nk nl nm nn bi translated">客户向我们发送了一个在内部创建的 Oracle 数据泵完整数据库导出(expdp ),并将转储文件复制到亚马逊 S3。转储是使用<strong class="kw iu">文件大小=64G </strong>创建的</li><li id="9d62" class="nf ng it kw b kx no la np ld nq lh nr ll ns lp nk nl nm nn bi translated">一旦转储文件被复制到亚马逊 S3，我们就在一个临时 Oracle 迁移实例上恢复这些文件。为此，我们在 AWS 上构建了一个<strong class="kw iu">m5a . 8x 大型 RHEL 7.6 实例</strong>。</li><li id="1eb4" class="nf ng it kw b kx no la np ld nq lh nr ll ns lp nk nl nm nn bi translated">数据恢复完成后，我们验证了本地 Oracle 数据库与 Oracle 迁移数据库之间的行数。</li></ol><h2 id="722e" class="mt lr it bd ls mu mv dn lw mw mx dp ma ld my mz mc lh na nb me ll nc nd mg ne bi translated">模式转换</h2><p id="2a9b" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">我们使用<a class="ae nt" href="https://aws.amazon.com/dms/schema-conversion-tool/" rel="noopener ugc nofollow" target="_blank"> AWS 模式转换工具</a>进行异构数据库迁移。这个工具工作起来非常顺畅。任何无法转换的对象都被清楚地标记出来，以便可以手动转换它们来完成迁移。假设您没有很多存储过程、函数和包，那么 AWS 模式转换工具将会转换您的大多数模式对象。</p><p id="19c6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">一些经验教训……</strong></p><ol class=""><li id="8fd7" class="nf ng it kw b kx ky la lb ld nu lh nv ll nw lp nk nl nm nn bi translated">Oracle 中的触发器代码迁移方式略有不同。触发器代码被转换成 PostgreSQL 函数，该函数又从 PostgreSQL 中的触发器调用。</li><li id="7713" class="nf ng it kw b kx no la np ld nq lh nr ll ns lp nk nl nm nn bi translated"><em class="nx">Oracle 中的数字</em>数据类型被转换为 PostgreSQL 中的<em class="nx"> double_precis </em> ion。在正常情况下，这应该不成问题。然而，在数据迁移步骤中，我们确实遇到了数据截断问题。我们将在本文后面更详细地讨论这一点。</li><li id="4444" class="nf ng it kw b kx no la np ld nq lh nr ll ns lp nk nl nm nn bi translated">如果在列名中有一个保留字，那么这个名称就会用双引号括起来，比如“PRECISION”。不幸的是，没有简单的方法来标记这些列并预先修复它们。因此，创建一个脚本并根据 PostgreSQL 保留字列表验证列名是一个好主意。获得保留单词列表的一个简单方法是使用下面的 SQL:<br/><strong class="kw iu">SELECT * FROM pg _ get _ keywords()</strong></li></ol><h2 id="3309" class="mt lr it bd ls mu mv dn lw mw mx dp ma ld my mz mc lh na nb me ll nc nd mg ne bi translated">模式验证</h2><ol class=""><li id="2e30" class="nf ng it kw b kx mi la mj ld nh lh ni ll nj lp nk nl nm nn bi translated">我们使用<em class="nx"> pytest </em>框架进行模式验证。我们首先创建单元测试，用于比较常见的模式对象，如表、索引、约束、视图等。在目标数据库中。这个脚本每天都按计划运行，这样我们就能及时发现任何差异。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi ny"><img src="../Images/ee308ca36276d46682d5f4655c3b2ddc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nEBpchyFC4sWEFY2CQak6g.jpeg"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">(<em class="ms">图片作者</em>)</p></figure><p id="3382" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">吸取的一些教训… </strong></p><ol class=""><li id="61e4" class="nf ng it kw b kx ky la lb ld nu lh nv ll nw lp nk nl nm nn bi translated">我们错过了为 double_precision 问题添加验证源数据的单元测试。实际问题是在数据迁移阶段发现的，这并不好…对于下一次迁移，最好事先知道这个问题</li><li id="a9ed" class="nf ng it kw b kx no la np ld nq lh nr ll ns lp nk nl nm nn bi translated">我们还错过了为保留关键字添加单元测试。这个问题是在应用程序测试期间发现的，当时有些列用双引号括起来。最好预先标记这些列，并建议修改列名。</li></ol><h2 id="3278" class="mt lr it bd ls mu mv dn lw mw mx dp ma ld my mz mc lh na nb me ll nc nd mg ne bi translated">数据迁移</h2><p id="c58f" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">我们使用<a class="ae nt" href="https://aws.amazon.com/dms/" rel="noopener ugc nofollow" target="_blank"> AWS 数据库迁移服务</a>将庞大的数据集从 Oracle 迁移到 PostgreSQL。</p><h2 id="8ee6" class="mt lr it bd ls mu mv dn lw mw mx dp ma ld my mz mc lh na nb me ll nc nd mg ne bi translated">DMS 复制实例和 DMS 端点</h2><p id="4cd4" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">一个<strong class="kw iu"> r4.4xlarge </strong>实例。Oracle 和 PostgreSQL 各一个端点。</p><h2 id="c655" class="mt lr it bd ls mu mv dn lw mw mx dp ma ld my mz mc lh na nb me ll nc nd mg ne bi translated">数据迁移任务</h2><p id="bde1" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">所有维度表都很小，因此我们创建一个 DMS 作业，一次性迁移所有这些表的数据。</p><p id="dde7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">对于最大的事实表，我们创建了多个 DMS 作业，每个作业复制 5-6 亿行。分割是使用如下选择过滤器完成的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi nz"><img src="../Images/d3b88da88126a79bcd59f92b7bf64ab0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*msH8wKB94KKa7fWWKe0OMA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">(<em class="ms">图片作者</em>)</p></figure><p id="f7ee" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">一些经验教训……</strong></p><ol class=""><li id="d1ac" class="nf ng it kw b kx ky la lb ld nu lh nv ll nw lp nk nl nm nn bi translated">数据迁移后，我们发现一些列的数据被截断。这些列的数据值大于 40 个精度值。这一次，我们使用<em class="nx"> numeric(38，25) </em>执行了另一次数据复制迭代，但这没有帮助。最终，我们通过将这些列转换为源和目的地的<em class="nx"> varchar i </em> n、复制数据并最终在 PostgreSQL 中将这些列重置为<em class="nx"> numeric </em>类型来解决这个问题</li><li id="7c16" class="nf ng it kw b kx no la np ld nq lh nr ll ns lp nk nl nm nn bi translated">确保为复制实例提供足够的已分配存储，否则您的作业将运行非常缓慢，甚至会失败。我们最初使用默认的 50 GB 大小，但是作业开始变慢和/或失败。我们花了一段时间才找到问题的根源，但当我们将存储容量更改为 200 GB 时，所有作业都成功完成了。以下指标将清楚地向您展示在实施分配的存储更改后，写入和读取延迟下降的确切时间点…此后一帆风顺</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi oa"><img src="../Images/6b5a5c2ffa4c89388d8c42d7474bd152.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*44gX2HqKd2s_3pn3iNhQTg.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">(<em class="ms">图片作者</em>)</p></figure><h2 id="3d0d" class="mt lr it bd ls mu mv dn lw mw mx dp ma ld my mz mc lh na nb me ll nc nd mg ne bi translated">数据有效性</h2><p id="fef4" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">这是我们花时间最多的部分。我们的目标是比较 Oracle 和 PostgreSQL 的每一行数据。</p><p id="117c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们首先创建了一个数据验证框架，它使用 JDBC 连接从 Oracle 表中获取数据。然后将每个块与 PostgreSQL 中相应的块进行比较。我们确实预料到 JDBC 方法会很慢，但是该框架在正确性和性能的测试迁移中工作得相当好。然而，在生产运行期间，由于数据量的增加，事情很快就变糟了。在某一点上，我们计算出框架需要一个月的时间来做比较…同样不好。</p><p id="aae1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们通过改变方法解决了上述问题。我们没有选择 JDBC，而是选择将 Oracle 和 PostgreSQL 表作为 Parquet 格式文件转储到亚马逊 S3 上。然后，我们编写了一个简单的 Pyspark 程序，使用 Datafames 执行比较。我们使用一个 EMR 集群启动了 Spark 程序，该集群有 1 个<strong class="kw iu"> m5.xlarge </strong>主节点<strong class="kw iu">和</strong> 4 个使用<strong class="kw iu"> c4.8xlarge </strong>点实例<strong class="kw iu">的核心节点。</strong>一个月的工作缩短到不到 1.5 天…..还不错。</p><p id="8202" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最后，Pyspark 脚本的结果……听起来很不错。查看<strong class="kw iu"> failed_count </strong>列。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi ob"><img src="../Images/4ec8c2efa12c98b5926a0eec79e6eb7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w-4_YqKgkBWpjYM6paDBAQ.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">(<em class="ms">作者图片</em>)</p></figure><p id="7186" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">希望这篇文章对你有所帮助。我希望它能在您的迁移过程中节省一些时间和烦恼。如果您需要 Pyspark 脚本，请随时 ping 我。我很乐意提供给你。</p><p id="9aed" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我希望这篇文章是有帮助的。AWS 数据迁移服务是由<a class="ae nt" href="http://www.datafence.com" rel="noopener ugc nofollow" target="_blank"> Datafence Cloud Academy </a>提供的 AWS 大数据分析课程的一部分。课程是周末自己在网上教的。</p></div></div>    
</body>
</html>