<html>
<head>
<title>Hands-On Guide to Feature Engineering in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python 中要素工程的实践指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/hands-on-guide-to-feature-engineering-de793efc785?source=collection_archive---------39-----------------------#2020-08-04">https://towardsdatascience.com/hands-on-guide-to-feature-engineering-de793efc785?source=collection_archive---------39-----------------------#2020-08-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4edf" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一步一步地从数据中提取有用的见解</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9fd66b41f4ef2eff9d45b6935cb7160e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SABnYfT-DtAuwGOgkqs79g.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@sortino?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">约书亚·索蒂诺</a>在<a class="ae ky" href="https://unsplash.com/s/photos/innovation?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="2ea0" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="8f2d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在本指南中，我将介绍如何利用数据操作来手动提取特征。</p><p id="f7ea" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">手动特征工程可能会令人疲惫不堪，并且需要大量的时间、经验和领域知识来开发正确的特征。有许多可用的自动特征工程工具，如 FeatureTools 和 AutoFeat。然而，手动特征工程对于理解这些高级工具是必不可少的。此外，这将有助于建立一个稳健的通用模型。我将使用 Kaggle 平台上可用的住房信贷违约风险数据集。我将只使用主文件夹中的两个表<code class="fe ms mt mu mv b">bureau</code>和<code class="fe ms mt mu mv b">bureau_balance</code>。根据竞争页面上的数据集描述，表格如下:</p><p id="5c72" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu"> bureau.csv </strong></p><ul class=""><li id="2e22" class="mw mx it lt b lu mn lx mo ma my me mz mi na mm nb nc nd ne bi translated">此表包括所有客户以前从其他金融机构向信用局报告的信用。</li></ul><p id="ba3e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu"> bureau_balance.csv </strong></p><ul class=""><li id="3dff" class="mw mx it lt b lu mn lx mo ma my me mz mi na mm nb nc nd ne bi translated">信用局早期贷款的每月余额。</li><li id="da7f" class="mw mx it lt b lu nf lx ng ma nh me ni mi nj mm nb nc nd ne bi translated">该表中有一行记录了每个月向信用局报告的每笔贷款的历史。</li></ul></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="6723" class="kz la it bd lb lc nr le lf lg ns li lj jz nt ka ll kc nu kd ln kf nv kg lp lq bi translated">本教程将涵盖相关主题</h1><ol class=""><li id="843c" class="mw mx it lt b lu lv lx ly ma nw me nx mi ny mm nz nc nd ne bi translated">读取和管理数据—定制 KDE 图</li><li id="d5c1" class="mw mx it lt b lu nf lx ng ma nh me ni mi nj mm nz nc nd ne bi translated">调查相关性</li><li id="b008" class="mw mx it lt b lu nf lx ng ma nh me ni mi nj mm nz nc nd ne bi translated">聚合数字列</li><li id="ceaf" class="mw mx it lt b lu nf lx ng ma nh me ni mi nj mm nz nc nd ne bi translated">获取 bureau_balance 的统计数据</li><li id="0998" class="mw mx it lt b lu nf lx ng ma nh me ni mi nj mm nz nc nd ne bi translated">调查分类变量</li><li id="1b45" class="mw mx it lt b lu nf lx ng ma nh me ni mi nj mm nz nc nd ne bi translated">将计算出的特征插入训练数据集中</li><li id="25a9" class="mw mx it lt b lu nf lx ng ma nh me ni mi nj mm nz nc nd ne bi translated">检查缺失的数据</li><li id="b68e" class="mw mx it lt b lu nf lx ng ma nh me ni mi nj mm nz nc nd ne bi translated">相关</li><li id="8fdb" class="mw mx it lt b lu nf lx ng ma nh me ni mi nj mm nz nc nd ne bi translated">共线性</li></ol></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="93ef" class="kz la it bd lb lc nr le lf lg ns li lj jz nt ka ll kc nu kd ln kf nv kg lp lq bi translated">1.读取和管理数据</h1><p id="8827" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我将从导入一些有助于理解数据的重要库开始。</p><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="7927" class="oe la it mv b gy of og l oh oi"><em class="oj"># pandas and numpy for data manipulation<br/></em>import pandas as pd<br/>import numpy as np<br/><br/><em class="oj"># matplotlib and seaborn for plotting</em><br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/><br/><em class="oj"># Suppress warnings from pandas</em><br/>import warnings<br/>warnings.filterwarnings('ignore')<br/><br/>plt.style.use('fivethirtyeight')</span></pre><p id="259c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我先开始分析 bureau.csv:</p><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="0687" class="oe la it mv b gy of og l oh oi"><em class="oj"># Read in bureau</em><br/>bureau = pd.read_csv('../input/home-credit-default-risk/bureau.csv')<br/>bureau.head()</span></pre><p id="643c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">该表有 1716428 个观察值和 17 个特征。</p><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="849e" class="oe la it mv b gy of og l oh oi">SK_ID_CURR                  int64<br/>SK_ID_BUREAU                int64<br/>CREDIT_ACTIVE              object<br/>CREDIT_CURRENCY            object<br/>DAYS_CREDIT                 int64<br/>CREDIT_DAY_OVERDUE          int64<br/>DAYS_CREDIT_ENDDATE       float64<br/>DAYS_ENDDATE_FACT         float64<br/>AMT_CREDIT_MAX_OVERDUE    float64<br/>CNT_CREDIT_PROLONG          int64<br/>AMT_CREDIT_SUM            float64<br/>AMT_CREDIT_SUM_DEBT       float64<br/>AMT_CREDIT_SUM_LIMIT      float64<br/>AMT_CREDIT_SUM_OVERDUE    float64<br/>CREDIT_TYPE                object<br/>DAYS_CREDIT_UPDATE          int64<br/>AMT_ANNUITY               float64<br/>dtype: object</span></pre><p id="85ce" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们需要得到每个客户 id 是多少以前的贷款<code class="fe ms mt mu mv b">SK_ID_CURR</code>。我们可以使用 pandas 聚合函数<code class="fe ms mt mu mv b">groupby</code>和<code class="fe ms mt mu mv b">count().</code>来得到这个结果，然后在为了可读性而将<code class="fe ms mt mu mv b">SK_ID_BUREAU</code>重命名为<code class="fe ms mt mu mv b">previous_loan_count</code>之后，将新的结果存储在一个新的数据帧中。</p><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="34e8" class="oe la it mv b gy of og l oh oi"><em class="oj"># groupby client-id, count #previous loans</em><br/><strong class="mv iu">from</strong> <strong class="mv iu">pandas</strong> <strong class="mv iu">import</strong> DataFrame<br/><br/>prev_loan_count = bureau.groupby('SK_ID_CURR', as_index = <strong class="mv iu">False</strong>).count().rename(columns = {'SK_ID_BUREAU': 'previous_loan_count'})</span></pre><p id="1162" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">新的<code class="fe ms mt mu mv b">prev_loan_count</code>只有 305811 个观测值。现在，我将通过客户端 id <code class="fe ms mt mu mv b">SK_ID_CURR</code>将<code class="fe ms mt mu mv b">prev_loan_count</code>数据帧合并到<code class="fe ms mt mu mv b">train</code>数据集中，然后用 0 填充缺失的值。最后，检查新列是否已经使用<code class="fe ms mt mu mv b">dtypes</code>函数添加。</p><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="ae1d" class="oe la it mv b gy of og l oh oi"># join with the training dataframe<br/># read train.csv</span><span id="eb10" class="oe la it mv b gy ok og l oh oi">pd.set_option('display.max_column', None)<br/>train = pd.read_csv('../input/home-credit-default-risk/application_train.csv')<br/>train = train.merge(prev_loan_count, on = 'SK_ID_CURR', how = 'left')</span><span id="cfdc" class="oe la it mv b gy ok og l oh oi"># fill the missing values with 0</span><span id="c552" class="oe la it mv b gy ok og l oh oi">train['previous_loan_count'] = train['previous_loan_count'].fillna(0)<br/>train['previous_loan_count'].dtypes</span><span id="b686" class="oe la it mv b gy ok og l oh oi">dtype('float64')</span></pre><p id="479b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">它已经在那里了！</p></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="76da" class="kz la it bd lb lc nr le lf lg ns li lj jz nt ka ll kc nu kd ln kf nv kg lp lq bi translated">2.调查相关性</h1><p id="026f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">下一步是通过特征重要性探索属性之间的皮尔逊相关值或(<strong class="lt iu"> r 值</strong>)。它不是衡量新变量重要性的标准；但是，它提供了一个变量对模型是否有帮助的参考。</p><p id="3285" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">因变量的相关性越高，意味着该变量的任何变化都会导致因变量的显著变化。因此，在下一步中，我将研究相对于因变量的 r 值的最高绝对值。</p><p id="4b00" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">核密度估计(KDE)是描述因变量和自变量之间关系的最佳方法。</p><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="e613" class="oe la it mv b gy of og l oh oi"># Plots the disribution of a variable colored by value of the dependent variable</span><span id="66dc" class="oe la it mv b gy ok og l oh oi">def kde_target(var_name, df):<br/>    <br/>    # Calculate the correlation coefficient between the new variable and the target<br/>    corr = df['TARGET'].corr(df[var_name])<br/>    <br/>    # Calculate medians for repaid vs not repaid<br/>    avg_repaid = df.loc[df['TARGET'] == 0, var_name].median()<br/>    avg_not_repaid = df.loc[df['TARGET'] == 1, var_name].median()<br/>    <br/>    plt.figure(figsize = (12, 6))<br/>    <br/>    # Plot the distribution for target == 0 and target == 1<br/>    sns.kdeplot(df.loc[df['TARGET'] == 0, var_name], label = 'TARGET == 0')<br/>    sns.kdeplot(df.loc[df['TARGET'] == 1, var_name], label = 'TARGET == 1')<br/>    <br/>    # label the plot<br/>    plt.xlabel(var_name); plt.ylabel('Density'); plt.title('%s Distribution' % var_name)<br/>    plt.legend();<br/>    <br/>    # print out the correlation<br/>    print('The correlation between %s and the TARGET is %0.4f' % (var_name, corr))</span><span id="0522" class="oe la it mv b gy ok og l oh oi">    # Print out average values<br/>    print('Median value for loan that was not repaid = %0.4f' % avg_not_repaid)</span><span id="47d6" class="oe la it mv b gy ok og l oh oi">    print('Median value for loan that was repaid =     %0.4f' % avg_repaid)</span></pre><p id="ba28" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">然后对照<code class="fe ms mt mu mv b">Target</code>检查<code class="fe ms mt mu mv b">previous_loan_count</code>的分配</p><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="cffd" class="oe la it mv b gy of og l oh oi">kde_target('previous_loan_count', train)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/1fd609bf58dbafbad808116597dc8a6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vAA8m0MKbb9_Bx3u8meGvg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">上一次贷款计数的 KDE 图</p></figure><p id="3ec6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">很难看出<code class="fe ms mt mu mv b">TARGET</code>和<code class="fe ms mt mu mv b">previous_loan_count</code>之间有任何显著的相关性。从图上看不出有明显的相关性。因此，需要使用聚合函数来研究更多的变量。</p></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="e925" class="kz la it bd lb lc nr le lf lg ns li lj jz nt ka ll kc nu kd ln kf nv kg lp lq bi translated">3.聚合数字列</h1><p id="bf47" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我将选择按客户端 id 分组的数字列，然后应用统计函数<code class="fe ms mt mu mv b">min, max, sum, mean, and count</code>来获得每个数字特性的汇总统计信息。</p><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="8e07" class="oe la it mv b gy of og l oh oi"><em class="oj"># Group by the client id, calculate aggregation statistics</em><br/>bureau_agg = bureau.drop(columns = ['SK_ID_BUREAU']).groupby('SK_ID_CURR', as_index = <strong class="mv iu">False</strong>).agg(['count', 'mean', 'min','max','sum']).reset_index()</span></pre><p id="849d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为可读性起见，为每个列创建一个新名称。然后与<code class="fe ms mt mu mv b">train</code>数据集合并。</p><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="c9a9" class="oe la it mv b gy of og l oh oi"><em class="oj"># List of column names</em><br/>columns = ['SK_ID_CURR']<br/><br/><em class="oj"># Iterate through the variables names</em><br/><strong class="mv iu">for</strong> var <strong class="mv iu">in</strong> bureau_agg.columns.levels[0]:<br/>    <em class="oj"># Skip the id name</em><br/>    <strong class="mv iu">if</strong> var != 'SK_ID_CURR':<br/>        <br/>        <em class="oj"># Iterate through the stat names</em><br/>        <strong class="mv iu">for</strong> stat <strong class="mv iu">in</strong> bureau_agg.columns.levels[1][:-1]:<br/>            <em class="oj"># Make a new column name for the variable and stat</em><br/>            columns.append('bureau_<strong class="mv iu">%s</strong>_<strong class="mv iu">%s</strong>' % (var, stat))</span><span id="83c9" class="oe la it mv b gy ok og l oh oi"><em class="oj"># Assign the list of columns names as the dataframe column names</em><br/>bureau_agg.columns = columns</span><span id="a1ed" class="oe la it mv b gy ok og l oh oi"># merge with the train dataset<br/>train = train.merge(bureau_agg, on = 'SK_ID_CURR', how = 'left')</span></pre><p id="f395" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">使用<code class="fe ms mt mu mv b">TARGET</code>变量获取相关性，然后使用<code class="fe ms mt mu mv b">sort_values()</code> Python 函数按绝对值对相关性进行排序。</p><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="6218" class="oe la it mv b gy of og l oh oi"># Calculate correlation between variables and the dependent variable<br/># Sort the correlations by the absolute value</span><span id="89a0" class="oe la it mv b gy ok og l oh oi">new_corrs = train.drop(columns=['TARGET']).corrwith(train['TARGET']).sort_values(ascending=False)<br/>new_corrs[:15]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/93ea498e7828826bed41248387c50775.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gm2xBIBhAmBjy7aEswzhHA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">与目标变量的相关性</p></figure><p id="3f91" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在检查新创建的变量的 KDE 图</p><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="ba70" class="oe la it mv b gy of og l oh oi">kde_target('bureau_DAYS_CREDIT_mean', train)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/bc0e8bdcac6a332f452be2e37f507556.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PKmz5xg6_swLn5D5h4sZSg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">bureau_DAYS_CREDIT_mean 和目标之间的相关性</p></figure><p id="2e90" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如图所示，相关性非常弱，可能只是噪声。此外，较大的负数表示该贷款在当前贷款申请之前。</p></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="f004" class="kz la it bd lb lc nr le lf lg ns li lj jz nt ka ll kc nu kd ln kf nv kg lp lq bi translated">4.获取 bureau_balance 的统计数据</h1><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="cace" class="oe la it mv b gy of og l oh oi">bureau_balance = pd.read_csv('../input/home-credit-default-risk/bureau_balance.csv')</span><span id="5eb0" class="oe la it mv b gy ok og l oh oi">bureau_balance.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/2199595bb48bbb21c16aa6c2b05b208f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mUzY85Ke9KIjG1Tjivtbvg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">bureau_balance.csv</p></figure></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="01ef" class="kz la it bd lb lc nr le lf lg ns li lj jz nt ka ll kc nu kd ln kf nv kg lp lq bi translated">5.调查分类变量</h1><p id="e5e7" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">下面的函数遍历 dataframe，选择分类列并为其创建一个虚拟变量。</p><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="d4a0" class="oe la it mv b gy of og l oh oi">def process_categorical(df, group_var, col_name):<br/>    """Computes counts and normalized counts for each observation<br/>    of `group_var` of each unique category in every categorical variable<br/>    <br/>    Parameters<br/>    --------<br/>    df : dataframe <br/>        The dataframe to calculate the value counts for.<br/>        <br/>    group_var : string<br/>        The variable by which to group the dataframe. For each unique<br/>        value of this variable, the final dataframe will have one row<br/>        <br/>    col_name : string<br/>        Variable added to the front of column names to keep track of columns</span><span id="14e0" class="oe la it mv b gy ok og l oh oi">Return<br/>    --------<br/>    categorical : dataframe<br/>        A dataframe with counts and normalized counts of each unique category in every categorical variable<br/>        with one row for every unique value of the `group_var`.<br/>        <br/>    """<br/>    # pick the categorical column <br/>    categorical = pd.get_dummies(df.select_dtypes('O'))<br/>    <br/>    # put an id for each column<br/>    categorical[group_var] = df[group_var]<br/>    <br/>    # aggregate the group_var<br/>    categorical = categorical.groupby(group_var).agg(['sum', 'mean'])<br/>    <br/>    columns_name = []<br/>    <br/>    # iterate over the columns in level 0<br/>    for var in categorical.columns.levels[0]:<br/>        # iterate through level 1 for stats<br/>        for stat in ['count', 'count_norm']:<br/>            # make new column name<br/>            columns_name.append('%s_%s_%s' %(col_name, var, stat))<br/>            <br/>    categorical.columns = columns_name<br/>    <br/>    return categorical</span></pre><p id="4f35" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这个函数将为每个分类列返回一个统计数据<code class="fe ms mt mu mv b">sum</code>和<code class="fe ms mt mu mv b">mean</code>。</p><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="4ea7" class="oe la it mv b gy of og l oh oi">bureau_count = process_categorical(bureau, group_var = 'SK_ID_CURR',col_name = 'bureau')</span></pre><p id="4f95" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">对 bureau_balance 执行相同的操作</p><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="76c2" class="oe la it mv b gy of og l oh oi">bureau_balance_counts = process_categorical(df = bureau_balance, group_var = 'SK_ID_BUREAU', col_name = 'bureau_balance')</span></pre><p id="f6fc" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在，我们有了每笔贷款的计算结果。我们需要为每个<em class="oj">客户端</em>进行聚合。我将把所有以前的数据帧合并在一起，然后再次汇总按<code class="fe ms mt mu mv b">SK_ID_CURR</code>分组的统计数据。</p><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="d365" class="oe la it mv b gy of og l oh oi"># dataframe grouped by the loan <br/>bureau_by_loan = bureau_balance_agg.merge(bureau_balance_counts, right_index = True, left_on = 'SK_ID_BUREAU', how = 'outer')</span><span id="e52f" class="oe la it mv b gy ok og l oh oi"># Merge to include the SK_ID_CURR<br/>bureau_by_loan = bureau[['SK_ID_BUREAU', 'SK_ID_CURR']].merge(bureau_by_loan, on = 'SK_ID_BUREAU', how = 'left')</span><span id="bfbb" class="oe la it mv b gy ok og l oh oi"># Aggregate the stats for each client<br/>bureau_balance_by_client = agg_numeric(bureau_by_loan.drop(columns = ['SK_ID_BUREAU']), group_var = 'SK_ID_CURR', col_name = 'client')</span></pre></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="d9af" class="kz la it bd lb lc nr le lf lg ns li lj jz nt ka ll kc nu kd ln kf nv kg lp lq bi translated">6.将计算出的特征插入训练数据集中</h1><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="e06d" class="oe la it mv b gy of og l oh oi">original_features = list(train.columns)<br/>print('Original Number of Features: ', len(original_features))</span></pre><p id="8ac7" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">输出:原始特征数:122</p><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="0056" class="oe la it mv b gy of og l oh oi"># Merge with the value counts of bureau<br/>train = train.merge(bureau_counts, on = 'SK_ID_CURR', how = 'left')</span><span id="8b31" class="oe la it mv b gy ok og l oh oi"># Merge with the stats of bureau<br/>train = train.merge(bureau_agg, on = 'SK_ID_CURR', how = 'left')</span><span id="8423" class="oe la it mv b gy ok og l oh oi"># Merge with the monthly information grouped by client<br/>train = train.merge(bureau_balance_by_client, on = 'SK_ID_CURR', how = 'left')</span><span id="02ad" class="oe la it mv b gy ok og l oh oi">new_features = list(train.columns)<br/>print('Number of features using previous loans from other institutions data: ', len(new_features))</span><span id="be65" class="oe la it mv b gy ok og l oh oi"># Number of features using previous loans from other institutions data:  333</span></pre><p id="566d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">输出为:使用以前从其他机构贷款的特征数数据:333</p></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="fbe9" class="kz la it bd lb lc nr le lf lg ns li lj jz nt ka ll kc nu kd ln kf nv kg lp lq bi translated">7.检查缺失的数据</h1><p id="3870" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">合并新特征后，检查训练集中缺失的数据非常重要。</p><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="0337" class="oe la it mv b gy of og l oh oi"># Function to calculate missing values by column# Funct <br/>def missing_percent(df):</span><span id="f0c5" class="oe la it mv b gy ok og l oh oi">"""Computes counts and normalized counts for each observation<br/>    of `group_var` of each unique category in every categorical variable<br/>    <br/>    Parameters<br/>    --------<br/>    df : dataframe <br/>        The dataframe to calculate the value counts for.</span><span id="241b" class="oe la it mv b gy ok og l oh oi">Return<br/>    --------<br/>    mis_column : dataframe<br/>        A dataframe with missing information .<br/>        <br/>    """<br/>        # Total missing values<br/>        mis_val = df.isnull().sum()<br/>        <br/>        # Percentage of missing values<br/>        mis_percent = 100 * df.isnull().sum() / len(df)<br/>        <br/>        # Make a table with the results<br/>        mis_table = pd.concat([mis_val, mis_percent], axis=1)<br/>        <br/>        # Rename the columns<br/>        mis_columns = mis_table.rename(<br/>        columns = {0 : 'Missing Values', 1 : 'Percent of Total Values'})<br/>        <br/>        # Sort the table by percentage of missing descending<br/>        mis_columns = mis_columns[<br/>            mis_columns.iloc[:,1] != 0].sort_values(<br/>        'Percent of Total Values', ascending=False).round(2)<br/>        <br/>        # Print some summary information<br/>        print ("Your selected dataframe has " + str(df.shape[1]) + " columns.\n"      <br/>            "There are " + str(mis_columns.shape[0]) +<br/>              " columns that have missing values.")<br/>        <br/>        # Return the dataframe with missing information<br/>        return mis_columns</span><span id="d0bc" class="oe la it mv b gy ok og l oh oi">train_missing = missing_percent(train)<br/>train_missing.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/a1ca834f5e2518c9c9a96c08a7faa344.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G7NHnA_wpwkBMN073lE6Qw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">火车 _ 失踪</p></figure><p id="3629" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">有相当多的列有大量缺失数据。我将删除任何缺失数据超过 90%的列。</p><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="0ce5" class="oe la it mv b gy of og l oh oi">missing_vars_train = train_missing.loc[train_missing['Percent of Total Values'] &gt; 90, 'Percent of Total Values']<br/>len(missing_vars_train)<br/># 0</span></pre><p id="4eea" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我将对测试数据做同样的事情</p><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="6389" class="oe la it mv b gy of og l oh oi"><em class="oj"># Read in the test dataframe</em><br/>test = pd.read_csv('../input/home-credit-default-risk/application_test.csv')<br/><br/><em class="oj"># Merge with the value counts of bureau</em><br/>test = test.merge(bureau_counts, on = 'SK_ID_CURR', how = 'left')<br/><br/><em class="oj"># Merge with the stats of bureau</em><br/>test = test.merge(bureau_agg, on = 'SK_ID_CURR', how = 'left')<br/><br/><em class="oj"># Merge with the value counts of bureau balance</em><br/>test = test.merge(bureau_balance_by_client, on = 'SK_ID_CURR', how = 'left')</span></pre><p id="bf32" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">然后，将对齐<code class="fe ms mt mu mv b">train</code>和<code class="fe ms mt mu mv b">test</code>数据集，并检查它们的形状和相同的列。</p><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="8e05" class="oe la it mv b gy of og l oh oi"><em class="oj"># create a train target label </em><br/>train_label = train['TARGET']<br/><br/><em class="oj"># align both dataframes, this will remove TARGET column</em><br/>train, test = train.align(test, join='inner', axis = 1)<br/><br/>train['TARGET'] = train_label<br/>print('Training Data Shape: ', train.shape)<br/>print('Testing Data Shape: ', test.shape)</span><span id="01eb" class="oe la it mv b gy ok og l oh oi">#Training Data Shape:  (307511, 333)<br/>#Testing Data Shape:  (48744, 332)</span></pre><p id="475d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">让我们检查一下<code class="fe ms mt mu mv b">test</code>组的缺失百分比。</p><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="bc1c" class="oe la it mv b gy of og l oh oi">test_missing = missing_percent(test) <br/>test_missing.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/ac0c8b8d333bb24e3ed0846353f6a3ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WkPc2qsTNR0VgRJNG6nMwA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">test_missing.head()</p></figure></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="64fd" class="kz la it bd lb lc nr le lf lg ns li lj jz nt ka ll kc nu kd ln kf nv kg lp lq bi translated">8.相关</h1><p id="3f70" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我将检查与<code class="fe ms mt mu mv b">TARGET</code>变量和新创建的特征的相关性。</p><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="b952" class="oe la it mv b gy of og l oh oi"># calculate correlation for all dataframes<br/>corr_train = train.corr()</span><span id="4072" class="oe la it mv b gy ok og l oh oi"># Sort the resulted values in an ascending order<br/>corr_train = corr_train.sort_values('TARGET', ascending = False)</span><span id="749d" class="oe la it mv b gy ok og l oh oi"># show the ten most positive correlations<br/>pd.DataFrame(corr_train['TARGET'].head(10))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/657e71188db414676b0e5b2317052336.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UN7BZxua5RkS_Zd5nKCj5Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">与目标变量相关的前 10 个特征</p></figure><p id="76f5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">从上面的例子中可以看出，最相关的变量是早期设计的变量。然而，相关性并不意味着因果关系，这就是为什么我们需要评估这些相关性，并选择对<code class="fe ms mt mu mv b">TARGET</code>有更深影响的变量。为此，我将坚持使用<code class="fe ms mt mu mv b">KDE</code>剧情。</p><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="58b4" class="oe la it mv b gy of og l oh oi">kde_target('bureau_DAYS_CREDIT_mean', train)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/b54db191101347bba679eb59bd604ef9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*erKpTWCANmksMrWGf6NZlQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">KDE 图为局 _ 天 _ 信用 _ 均值</p></figure><p id="d622" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">该图表明，每月每笔贷款记录较多的申请人倾向于偿还新贷款。让我们更深入地研究一下<code class="fe ms mt mu mv b">bureau_CREDIT_ACTIVE_Active_count_norm</code>变量，看看这是不是真的。</p><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="e9eb" class="oe la it mv b gy of og l oh oi">kde_target('bureau_CREDIT_ACTIVE_Active_count_norm', train)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/25fe44ab962d3f778a6b72b656ad4fe3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Inas7ebKjRGhoKpJnUyWBw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">局的 KDE 图 _ 信用 _ 活跃 _ 活跃 _ 计数 _ 定额</p></figure><p id="81d3" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这里的相关性很弱，我们看不出有什么意义。</p></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="8954" class="kz la it bd lb lc nr le lf lg ns li lj jz nt ka ll kc nu kd ln kf nv kg lp lq bi translated">9.共线性</h1><p id="9d4e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我将设置一个 80%的阈值来删除任何与<code class="fe ms mt mu mv b">TARGET</code>高度相关的变量</p><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="b4cd" class="oe la it mv b gy of og l oh oi"><em class="oj"># Set the threshold</em><br/>threshold = 0.8<br/><br/><em class="oj"># Empty dictionary to hold correlated variables</em><br/>above_threshold_vars = {}<br/><br/><em class="oj"># For each column, record the variables that are above the threshold</em><br/><strong class="mv iu">for</strong> col <strong class="mv iu">in</strong> corr_train:<br/>    above_threshold_vars[col] = list(corr_train.index[corr_train[col] &gt; threshold])</span><span id="9588" class="oe la it mv b gy ok og l oh oi"><em class="oj"># Track columns to remove and columns already examined</em><br/>cols_to_remove = []<br/>cols_seen = []<br/>cols_to_remove_pair = []<br/><br/><em class="oj"># Iterate through columns and correlated columns</em><br/><strong class="mv iu">for</strong> key, value <strong class="mv iu">in</strong> above_threshold_vars.items():<br/>    <em class="oj"># Keep track of columns already examined</em><br/>    cols_seen.append(key)<br/>    <strong class="mv iu">for</strong> x <strong class="mv iu">in</strong> value:<br/>        <strong class="mv iu">if</strong> x == key:<br/>            next<br/>        <strong class="mv iu">else</strong>:<br/>            <em class="oj"># Only want to remove one in a pair</em><br/>            <strong class="mv iu">if</strong> x <strong class="mv iu">not</strong> <strong class="mv iu">in</strong> cols_seen:<br/>                cols_to_remove.append(x)<br/>                cols_to_remove_pair.append(key)<br/>            <br/>cols_to_remove = list(set(cols_to_remove))<br/>print('Number of columns to remove: ', len(cols_to_remove))</span></pre><p id="ebe5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">输出是:要删除的列数:134</p><p id="ae1c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">然后，我们可以从数据集中删除这些列，作为用于模型构建的准备步骤</p><pre class="kj kk kl km gt oa mv ob oc aw od bi"><span id="18b1" class="oe la it mv b gy of og l oh oi">rain_corrs_removed = train.drop(columns = cols_to_remove)<br/>test_corrs_removed = test.drop(columns = cols_to_remove)<br/><br/>print('Training Corrs Removed Shape: ', train_corrs_removed.shape)<br/>print('Testing Corrs Removed Shape: ', test_corrs_removed.shape)</span></pre><p id="bcd2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">训练 Corrs 删除形状:(307511，199) <br/>测试 Corrs 删除形状:(48744，198)</p></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="f9fb" class="kz la it bd lb lc nr le lf lg ns li lj jz nt ka ll kc nu kd ln kf nv kg lp lq bi translated">摘要</h1><p id="636b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">本教程的目的是向您介绍许多在开始时可能会令人困惑的概念:</p><ol class=""><li id="6c34" class="mw mx it lt b lu mn lx mo ma my me mz mi na mm nz nc nd ne bi translated">使用熊猫函数的特征工程。</li><li id="1a2c" class="mw mx it lt b lu nf lx ng ma nh me ni mi nj mm nz nc nd ne bi translated">定制核密度估计图。</li><li id="9cf2" class="mw mx it lt b lu nf lx ng ma nh me ni mi nj mm nz nc nd ne bi translated">评估新提取的特征</li><li id="f47b" class="mw mx it lt b lu nf lx ng ma nh me ni mi nj mm nz nc nd ne bi translated">消除数据中的共线性</li></ol></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="2a81" class="kz la it bd lb lc nr le lf lg ns li lj jz nt ka ll kc nu kd ln kf nv kg lp lq bi translated">参考</h1><ol class=""><li id="30e4" class="mw mx it lt b lu lv lx ly ma nw me nx mi ny mm nz nc nd ne bi translated"><a class="ae ky" href="https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction/" rel="noopener ugc nofollow" target="_blank">特征工程简介</a> —威尔·科尔森</li><li id="2d5e" class="mw mx it lt b lu nf lx ng ma nh me ni mi nj mm nz nc nd ne bi translated"><a class="ae ky" href="https://github.com/salma71/home_credit_risk/blob/master/notebooks/KBF_engineering/credit_risk_part%232.ipynb" rel="noopener ugc nofollow" target="_blank">GitHub 上本教程的完整笔记本</a></li><li id="e24d" class="mw mx it lt b lu nf lx ng ma nh me ni mi nj mm nz nc nd ne bi translated"><a class="ae ky" href="https://www.kaggle.com/salmaeng/credit-risk-part-1/" rel="noopener ugc nofollow" target="_blank">Kaggle</a>的完整笔记本——准备运行</li><li id="af39" class="mw mx it lt b lu nf lx ng ma nh me ni mi nj mm nz nc nd ne bi translated"><a class="ae ky" href="https://www.kaggle.com/c/home-credit-default-risk" rel="noopener ugc nofollow" target="_blank">Kaggle 上的住房信贷违约风险竞赛</a></li></ol></div></div>    
</body>
</html>