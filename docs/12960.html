<html>
<head>
<title>Do Not Use Decision Tree Like This</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不要像这样使用决策树</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/do-not-use-decision-tree-like-this-369769d6104d?source=collection_archive---------26-----------------------#2020-09-06">https://towardsdatascience.com/do-not-use-decision-tree-like-this-369769d6104d?source=collection_archive---------26-----------------------#2020-09-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/e2a2378a3493b9af639476cd45d7bada.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1JdKaXTt43SqHdzzzh6n0Q.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">由<a class="ae jg" href="https://pixabay.com/users/geralt-9301/" rel="noopener ugc nofollow" target="_blank"> geralt </a>在<a class="ae jg" href="https://pixabay.com/photos/book-read-student-students-board-4126483/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>上拍摄的照片</p></figure><div class=""/><div class=""><h2 id="d6a5" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">展示 ID3 中信息获取的局限性以及使用 C4.5 的优势</h2></div><p id="3c86" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">作为最流行的经典机器学习算法之一，决策树在可解释性方面比其他算法更直观。在我以前的一篇文章中，我介绍了决策树模型的基本思想和机制。它使用一种称为 ID3 的算法演示了这种机器学习模型，ID3 是训练决策树分类模型的最经典的算法之一。</p><div class="is it gp gr iu lu"><a rel="noopener follow" target="_blank" href="/go-out-for-exercise-or-not-let-data-science-decide-34f8f28ce7b4"><div class="lv ab fo"><div class="lw ab lx cl cj ly"><h2 class="bd jk gy z fp lz fr fs ma fu fw ji bi translated">出去锻炼还是不锻炼？让数据科学来决定</h2><div class="mb l"><h3 class="bd b gy z fp lz fr fs ma fu fw dk translated">决策树机器学习算法简介</h3></div><div class="mc l"><p class="bd b dl z fp lz fr fs ma fu fw dk translated">towardsdatascience.com</p></div></div><div class="md l"><div class="me l mf mg mh md mi ja lu"/></div></div></a></div><p id="cf49" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果您对决策树不是很熟悉，强烈建议您在阅读本文之前先看看上面的文章。</p><p id="348c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要直观地理解决策树，从 ID3 开始确实不错。但是，在实践中使用它可能不是一个好主意。在本文中，我将介绍一种构建决策树模型的常用算法— C4.5。</p><h1 id="5249" class="mj mk jj bd ml mm mn mo mp mq mr ms mt kp mu kq mv ks mw kt mx kv my kw mz na bi translated">经典 ID3 算法的缺点</h1><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/eef459a9f3593315dc9cfc4b0a9426c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I0_wlpixy9NVkNWJ4q77gw.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">照片由<a class="ae jg" href="https://pixabay.com/users/aitoff-388338/" rel="noopener ugc nofollow" target="_blank">艾托夫</a>在<a class="ae jg" href="https://pixabay.com/photos/railway-platform-mind-gap-1758208/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>上拍摄</p></figure><p id="e7ee" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在我们演示 ID3 算法的主要缺点之前，让我们先来看看它的主要构件是什么。基本上，重要的是熵和信息增益。</p><h2 id="4d9b" class="nf mk jj bd ml ng nh dn mp ni nj dp mt lh nk nl mv ll nm nn mx lp no np mz nq bi translated">熵概述</h2><p id="7a9c" class="pw-post-body-paragraph ky kz jj la b lb nr kk ld le ns kn lg lh nt lj lk ll nu ln lo lp nv lr ls lt im bi translated">这是熵的公式:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nw"><img src="../Images/6822516875a71ea455b688b7aeaae814.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7HRrIgxIu9Z_Kfmju_HVaA.png"/></div></div></figure><p id="4a6b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">集合“<em class="nx"> X </em>”是节点集合中的一切，“<em class="nx"> xᵢ </em>是指每个样本的具体决策。因此，“<em class="nx">【p(xᵢ】)</em>”是用某个决策做出的集合的概率。</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ny"><img src="../Images/2ebef2d1fc3b98c9d56bed33d6a0a034.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nHdgM7seiBseQnrtikl5cg.png"/></div></div></figure><p id="b6d9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们以同一个训练数据集为例。假设我们的决策树中有一个“天气=下雨”的内部节点。可以看出，最后的决定都是“否”。然后，我们可以很容易地计算这个节点的熵，如下所示:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nz"><img src="../Images/9b2189a6c07387a2510140a50db77dd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KCFm4c_RuokjLwv6xDFOtQ.png"/></div></div></figure><p id="1b8e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">基本上，回答“否”的概率是 2/2 = 1，而回答“是”的概率是 0/2 = 0。</p><h2 id="6833" class="nf mk jj bd ml ng nh dn mp ni nj dp mt lh nk nl mv ll nm nn mx lp no np mz nq bi translated">信息增益概述</h2><p id="f671" class="pw-post-body-paragraph ky kz jj la b lb nr kk ld le ns kn lg lh nt lj lk ll nu ln lo lp nv lr ls lt im bi translated">在熵的概念之上，我们可以计算信息增益，这是决定一个特征是否应该作为要分裂的节点的基本标准。</p><p id="5ee1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">比如我们有三个特征:“天气”、“温度”、“风力等级”。当我们开始使用 ID3 构建决策树时，我们如何决定哪一个应该被用作根节点呢？</p><p id="6782" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">ID3 使用信息增益作为标准。规则是，在所有特征中选择具有最大信息增益的特征。下面是计算信息增益的公式:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oa"><img src="../Images/6450b8d93d946d0d80e2200c82f6cc4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OP3_nPIlozxkeQPXudEaEg.png"/></div></div></figure><p id="5918" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在哪里</p><ul class=""><li id="fdd0" class="ob oc jj la b lb lc le lf lh od ll oe lp of lt og oh oi oj bi translated">“T”是父节点,“a”是“T”的属性集</li><li id="63d6" class="ob oc jj la b lb ok le ol lh om ll on lp oo lt og oh oi oj bi translated">符号“|T|”表示集合的大小</li></ul><p id="0f5b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用相同的例子，当我们计算“天气=下雨”的信息增益时，我们还需要考虑它的子节点的熵。具体的推导和计算过程可以在引言中分享的文章中找到。</p><h2 id="34f9" class="nf mk jj bd ml ng nh dn mp ni nj dp mt lh nk nl mv ll nm nn mx lp no np mz nq bi translated">使用信息增益的主要缺点</h2><p id="7b6c" class="pw-post-body-paragraph ky kz jj la b lb nr kk ld le ns kn lg lh nt lj lk ll nu ln lo lp nv lr ls lt im bi translated">使用信息增益作为确定将哪个特征用作根/下一个节点的标准的主要缺点是，它倾向于使用具有更多唯一值的特征。</p><p id="43ce" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是为什么呢？让我用一个极端的场景来演示一下。比方说，我们的训练集多了一个特性:“日期”。</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi op"><img src="../Images/6a6a510f343a43cca571a961c96817d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*icqc0KwYtbCLdVjwz8We-Q.png"/></div></div></figure><p id="6c9a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可能会说，在这种情况下不应该考虑“日期”这个特征，因为直觉上它对决定我们是否应该出去跑步没有帮助。是的，你说得对。然而，实际上，我们可能有更复杂的数据集要分类，我们可能无法理解所有的特征。因此，我们可能并不总是能够确定一个特性是否有意义。在这里，我将用“日期”作为一个例子。</p><p id="1622" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，让我们计算“日期”的信息增益。我们可以开始计算其中一个日期的熵，比如“2020–01–01”。</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oq"><img src="../Images/4209efe3a7c391f1dd0afe3fa76bdfd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5fGcqOCDBgNGEhWVfcNFaQ.png"/></div></div></figure><p id="30d5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因为每个日期只有一行，所以最后的决定必须是“是”或“否”。所以，熵一定是 0！就信息理论而言，这相当于说:</p><blockquote class="or"><p id="d454" class="os ot jj bd ou ov ow ox oy oz pa lt dk translated">日期没有告诉我们任何事情，因为结果只有一个，这是确定的。所以，根本不存在“不确定性”。</p></blockquote><p id="1d56" class="pw-post-body-paragraph ky kz jj la b lb pb kk ld le pc kn lg lh pd lj lk ll pe ln lo lp pf lr ls lt im bi translated">类似地，对于所有其他日期，它们的熵也是 0。</p><p id="dd93" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，让我们计算日期本身的熵。</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pg"><img src="../Images/63e7d05c3b14f87eeea099848d279639.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TUHvdI3ZrNni1cjgbmPTOg.png"/></div></div></figure><p id="8841" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">哇，与其他功能相比，这是一个相当大的数字。所以，我们现在可以计算“日期”的信息增益了。</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ph"><img src="../Images/51a4d6d968c52fdeffe5eb27c71d5a65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*05oUKQES4P3Fsyq6ms7i-w.png"/></div></div></figure><p id="00cf" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">不出所料,“日期”的信息增益就是它本身的熵，因为它的所有属性的熵都是 0。</p><p id="ede6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果我们计算其他三个特征的信息增益(您可以在引言中链接的文章中找到详细信息)，它们是:</p><ul class=""><li id="9216" class="ob oc jj la b lb lc le lf lh od ll oe lp of lt og oh oi oj bi translated">天气的信息增益为 0.592</li><li id="d317" class="ob oc jj la b lb ok le ol lh om ll on lp oo lt og oh oi oj bi translated">温度的信息增益为 0.522</li><li id="4df1" class="ob oc jj la b lb ok le ol lh om ll on lp oo lt og oh oi oj bi translated">风级的信息增益为 0.306</li></ul><p id="a177" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">显然，迄今为止的信息增益远远大于其他的。此外，可以看出，如果训练数据集更大，它甚至会更大。之后，别忘了“日期”这个特征实际上在决定我们是否应该出去跑步时没有意义，但它被决定为“最好”的一个作为根节点。</p><p id="94c4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">更有趣的是，在我们决定使用“日期”作为我们的根节点后，我们就完成了:)</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pi"><img src="../Images/724c76079d19300adc73d242ccc038b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0YllgawHIY9bCjLemsqyRA.png"/></div></div></figure><p id="e58d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们最终得到如上所示的决策树。这是因为“约会”这个特性太好了。如果我们把它作为根节点，它的所有属性都会简单的告诉我们是否应该出去跑步。没有必要具有其他特征。</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pj"><img src="../Images/cf3af487da0fadd88342e400a029258a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8b9SA_6rJXvGp1izltHxYw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">由<a class="ae jg" href="https://pixabay.com/vectors/fish-funny-cartoon-odd-surprised-33712/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>上的<a class="ae jg" href="https://pixabay.com/users/Clker-Free-Vector-Images-3736/" rel="noopener ugc nofollow" target="_blank"> Clker-Free-Vector-Images </a>拍摄的图像</p></figure><p id="2cdc" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">是的，你此刻可能有一张像这条鱼一样的脸，我也有。</p><h1 id="92c0" class="mj mk jj bd ml mm mn mo mp mq mr ms mt kp mu kq mv ks mw kt mx kv my kw mz na bi translated">修复信息增益限制</h1><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/3b458600e1b2ff34eb24e0c9a4b00cdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NdAqNM1TJVG75yGaukTB9g.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">照片由<a class="ae jg" href="https://pixabay.com/users/jarmoluk-143740/" rel="noopener ugc nofollow" target="_blank"> jarmoluk </a>在<a class="ae jg" href="https://pixabay.com/photos/electrician-electric-electricity-1080554/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>上拍摄</p></figure><p id="9e6f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">ID3 算法中存在的信息增益限制的最简单解决方案来自另一种称为 C4.5 的决策树算法。减少这一问题的基本思想是使用<strong class="la jk">信息增益比</strong>而不是信息增益。</p><p id="1a2f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">具体来说，信息增益比是简单地通过除以父节点的熵在信息增益上添加惩罚。</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pk"><img src="../Images/75f6f0bcd3619f1e4e97b97a667f84d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rqy1opXj8Xmbr7QZ4JKr6A.png"/></div></div></figure><p id="9c11" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">换句话说，</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/965eba63183d354fdde071a9ad33115f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*UNstK0qYaRcRgWV-0eCsBg.png"/></div></figure><p id="e4ec" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，如果我们使用 C4.5 而不是 ID3，特性“日期”的信息增益比将如下。</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pm"><img src="../Images/8a1bb865d7f85ae2d3b8c94c0128663c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jZdBoWBhlL_NwVZi0jJJBA.png"/></div></div></figure><p id="0656" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">与其他特性相比，它确实是最大的一个，但是不要忘记我们实际上是在使用一个极端的例子，特性“Date”的每个属性值只有一行。在实践中，信息增益比将足以避免信息增益将导致偏差的大多数情况。</p><h1 id="8465" class="mj mk jj bd ml mm mn mo mp mq mr ms mt kp mu kq mv ks mw kt mx kv my kw mz na bi translated">C4.5 的其他改进</h1><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/ca8b17aecf90d48431c0a73ae020593f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rid7gIfr6hmT8L6cyUyIRQ.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">由<a class="ae jg" href="https://pixabay.com/users/silviarita-3142410/" rel="noopener ugc nofollow" target="_blank"> silviarita </a>在<a class="ae jg" href="https://pixabay.com/photos/bake-motto-world-improve-sweetness-1838364/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>上拍摄的照片</p></figure><p id="8744" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在我看来，使用信息增益比是从 ID3 到 C4.5 最显著的改进。尽管如此，在 C4.5 中还有更多你应该知道的改进。</p><h2 id="da0e" class="nf mk jj bd ml ng nh dn mp ni nj dp mt lh nk nl mv ll nm nn mx lp no np mz nq bi translated">悲观错误修剪</h2><p id="3331" class="pw-post-body-paragraph ky kz jj la b lb nr kk ld le ns kn lg lh nt lj lk ll nu ln lo lp nv lr ls lt im bi translated">如果您不熟悉决策树的“修剪”概念，您可能需要再次查看我之前的文章，该文章附在本文的介绍中。</p><p id="c5b4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">PEP 是 C4.5 中的另一个重大改进。具体来说，它将以自顶向下的方式修剪树。对于每个内部节点，该算法将计算其错误率。然后，尝试剪枝这个分支，比较剪枝前后的错误率。因此，我们决定是否应该保留这个分支。</p><p id="e626" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">PEP 的一些特征:</p><ol class=""><li id="fb34" class="ob oc jj la b lb lc le lf lh od ll oe lp of lt pn oh oi oj bi translated">这是后剪枝方法之一。</li><li id="4680" class="ob oc jj la b lb ok le ol lh om ll on lp oo lt pn oh oi oj bi translated">它在不依赖验证数据集的情况下修剪树。</li><li id="0985" class="ob oc jj la b lb ok le ol lh om ll on lp oo lt pn oh oi oj bi translated">通常很好地避免了过度拟合，从而提高了未知数据的分类性能。</li></ol><h2 id="75ed" class="nf mk jj bd ml ng nh dn mp ni nj dp mt lh nk nl mv ll nm nn mx lp no np mz nq bi translated">离散化连续特征</h2><p id="00d0" class="pw-post-body-paragraph ky kz jj la b lb nr kk ld le ns kn lg lh nt lj lk ll nu ln lo lp nv lr ls lt im bi translated">C4.5 支持连续值。所以，我们并不局限于拥有“低”、“中”、“高”这样的分类值。取而代之的是，C4.5 会自动检测能够产生<strong class="la jk">最大</strong>信息增益比的连续值的<strong class="la jk">阈值</strong>，然后使用该阈值分裂节点。</p><h1 id="4aba" class="mj mk jj bd ml mm mn mo mp mq mr ms mt kp mu kq mv ks mw kt mx kv my kw mz na bi translated">摘要</h1><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pj"><img src="../Images/a23dd881c812703abe075a87e60ea129.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vfM9nN2dUFElP1iZGEbYOg.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">照片由<a class="ae jg" href="https://pixabay.com/users/Bessi-909086/" rel="noopener ugc nofollow" target="_blank">贝西</a>在<a class="ae jg" href="https://pixabay.com/photos/tree-lake-reflection-water-calm-838667/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>上拍摄</p></figure><p id="67db" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，我解释了 ID3 不理想的原因。主要原因是它使用的标准-信息增益-可能会明显偏向那些具有大量不同值的特征。</p><p id="23de" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">另一个名为 C4.5 的决策树算法中给出了解决方案。它改进了信息增益与信息增益的比率，这将减少属性的大量不同值的影响。</p><p id="505d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">同样，如果你觉得需要更多关于决策树的上下文和基础知识，请查看我以前的文章。</p><div class="is it gp gr iu lu"><a rel="noopener follow" target="_blank" href="/go-out-for-exercise-or-not-let-data-science-decide-34f8f28ce7b4"><div class="lv ab fo"><div class="lw ab lx cl cj ly"><h2 class="bd jk gy z fp lz fr fs ma fu fw ji bi translated">出去锻炼还是不锻炼？让数据科学来决定</h2><div class="mb l"><h3 class="bd b gy z fp lz fr fs ma fu fw dk translated">决策树机器学习算法简介</h3></div><div class="mc l"><p class="bd b dl z fp lz fr fs ma fu fw dk translated">towardsdatascience.com</p></div></div><div class="md l"><div class="me l mf mg mh md mi ja lu"/></div></div></a></div><div class="is it gp gr iu lu"><a href="https://medium.com/@qiuyujx/membership" rel="noopener follow" target="_blank"><div class="lv ab fo"><div class="lw ab lx cl cj ly"><h2 class="bd jk gy z fp lz fr fs ma fu fw ji bi translated">通过我的推荐链接加入 Medium 克里斯托弗·陶</h2><div class="mb l"><h3 class="bd b gy z fp lz fr fs ma fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="mc l"><p class="bd b dl z fp lz fr fs ma fu fw dk translated">medium.com</p></div></div><div class="md l"><div class="po l mf mg mh md mi ja lu"/></div></div></a></div><p id="948c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你觉得我的文章有帮助，请考虑加入 Medium 会员来支持我和成千上万的其他作者！(点击上面的链接)</p></div></div>    
</body>
</html>