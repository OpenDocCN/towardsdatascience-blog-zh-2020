<html>
<head>
<title>Semi-Supervised Learning with K-Means Clustering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于 K 均值聚类的半监督学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/semi-supervised-learning-with-k-means-clustering-6e837158c54a?source=collection_archive---------19-----------------------#2020-06-19">https://towardsdatascience.com/semi-supervised-learning-with-k-means-clustering-6e837158c54a?source=collection_archive---------19-----------------------#2020-06-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="be54" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">机器学习</h2><div class=""/><div class=""><h2 id="bbd7" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">有限数据标签下 NBA 球员位置预测的半监督学习案例研究。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/ac0a8c97721b1b9acb71a3f485a98ae2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wRf2unsEJnMimE3d"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">照片由<a class="ae lh" href="https://unsplash.com/@bodisanal?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">бодьсанал·布吉</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="d39c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi me translated">有监督学习和无监督学习是机器学习中的两大任务。当所有实例的输出可用时，使用监督学习模型，而当我们没有“真实标签”时，应用无监督学习。</p><p id="ea52" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">尽管无监督学习的探索在未来的研究中具有巨大的潜力，但有监督学习仍然主导着该领域。然而，当我们的数据中没有足够的标记样本时，我们通常需要建立一个监督学习模型。</p><p id="9a37" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这种情况下，可以考虑半监督学习。其思想是基于非监督学习过程的输出来构建监督学习模型。</p><p id="283e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我想举一个简单的例子。</p><h2 id="2482" class="mn mo it bd mp mq mr dn ms mt mu dp mv lr mw mx my lv mz na nb lz nc nd ne iz bi translated">问题:我们可以根据 NBA 球员的比赛数据来对他们的位置进行分类吗？</h2><p id="902f" class="pw-post-body-paragraph li lj it lk b ll nf kd ln lo ng kg lq lr nh lt lu lv ni lx ly lz nj mb mc md im bi translated">我收集了 2018-2019 赛季 NBA 球员的场均数据。球员的位置被定义为传统的篮球位置:控球后卫(PG)、得分后卫(SG)、小前锋(SF)、大前锋(PF)和中锋(C)。</p><p id="1176" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在建模过程之前，我对数据集做了一些预处理。首先，去掉每场比赛上场时间不到 10 分钟的球员。然后，用 0 填充 NA 值(比如中锋球员从来不投三分球)。</p><pre class="ks kt ku kv gt nk nl nm nn aw no bi"><span id="608d" class="mn mo it nl b gy np nq l nr ns">df_used = df_num.loc[df.MP.astype('float32') &gt;= 10]<br/>df_used.fillna(0,inplace=True)</span></pre><p id="99f0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">预处理后，数据如下所示:</p><pre class="ks kt ku kv gt nk nl nm nn aw no bi"><span id="695f" class="mn mo it nl b gy np nq l nr ns">df_used.head()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nt"><img src="../Images/00223d59b348ee1050bd9f6efeaff282.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wxKAmJBIeuFLOwUhJjvLww.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">数据头</p></figure><p id="d842" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然后，我将数据分离到训练集和测试集。</p><pre class="ks kt ku kv gt nk nl nm nn aw no bi"><span id="d94a" class="mn mo it nl b gy np nq l nr ns">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(df_used, labels_)</span></pre></div><div class="ab cl nu nv hx nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="im in io ip iq"><h2 id="8800" class="mn mo it bd mp mq mr dn ms mt mu dp mv lr mw mx my lv mz na nb lz nc nd ne iz bi translated">监督学习(给出所有玩家的位置)</h2><p id="a955" class="pw-post-body-paragraph li lj it lk b ll nf kd ln lo ng kg lq lr nh lt lu lv ni lx ly lz nj mb mc md im bi translated">如果所有标签(玩家位置)都给了，那就是一个简单的监督分类问题。我用一个简单的逻辑回归模型来拟合训练数据集。</p><pre class="ks kt ku kv gt nk nl nm nn aw no bi"><span id="a8ea" class="mn mo it nl b gy np nq l nr ns">from sklearn.linear_model import LogisticRegression <br/>from sklearn.pipeline import Pipeline<br/>from sklearn.preprocessing import StandardScaler</span><span id="baa6" class="mn mo it nl b gy ob nq l nr ns">pipeline = Pipeline([<br/>        ("scaler", StandardScaler()),<br/>        ("log_reg", LogisticRegression()),<br/>    ])</span><span id="3413" class="mn mo it nl b gy ob nq l nr ns">pipeline.fit(X_train, y_train)</span></pre><p id="ee6a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我在测试数据集上评估了这个模型。</p><pre class="ks kt ku kv gt nk nl nm nn aw no bi"><span id="f0b5" class="mn mo it nl b gy np nq l nr ns">pipeline.score(X_test, y_test)</span></pre><p id="4cb4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这个过程给出 0.644，这意味着 64.4%的预测是正确的。从这个结果中，我们知道分类器的改进空间非常大。然而，在本文中，我并不关注分类器的开发。</p><p id="fced" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我将讨论数据标签仅部分可见的情况。</p></div><div class="ab cl nu nv hx nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="im in io ip iq"><h2 id="a802" class="mn mo it bd mp mq mr dn ms mt mu dp mv lr mw mx my lv mz na nb lz nc nd ne iz bi translated">半监督学习(只给出 100 个玩家的位置)</h2><p id="411f" class="pw-post-body-paragraph li lj it lk b ll nf kd ln lo ng kg lq lr nh lt lu lv ni lx ly lz nj mb mc md im bi translated">如果只允许我看到训练数据中 100 个球员的位置信息，会对模型的性能产生怎样的变化？有许多策略可以用来选择 100 个玩家作为分类器的输入。</p><p id="4078" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">第一种策略是随机选择 100 个玩家，比如前 100 个玩家。我检查了只在这个子集上训练的逻辑回归模型的性能。</p><pre class="ks kt ku kv gt nk nl nm nn aw no bi"><span id="de57" class="mn mo it nl b gy np nq l nr ns">n_labeled = 100</span><span id="519e" class="mn mo it nl b gy ob nq l nr ns">pipeline.fit(X_train[:n_labeled], y_train[:n_labeled])<br/>pipeline.score(X_test, y_test)</span></pre><p id="c32e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这次我只得到 56.8%的准确率。这是意料之中的，因为我只看到了真实标签的一个子集。</p><p id="efa6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，我们可以通过选择 100 个标签的不同子集来提高性能吗？答案是肯定的。</p><p id="84f1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">第二种策略是应用无监督学习过程来对整个训练数据集中的数据进行聚类，并暴露每个聚类的代表的标签。这样，我们可以假设在聚类空间中彼此接近的数据点应该有很高的机会拥有相同的标签。</p><p id="cf0a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">换句话说，比赛数据相似的球员应该在场上打同样的位置。</p><pre class="ks kt ku kv gt nk nl nm nn aw no bi"><span id="ea79" class="mn mo it nl b gy np nq l nr ns">from sklearn.cluster import KMeans</span><span id="5fb1" class="mn mo it nl b gy ob nq l nr ns">k=100<br/>kmeans = KMeans(n_clusters=k)<br/>X_dist = kmeans.fit_transform(X_train) <br/>representative_idx = np.argmin(X_dist, axis=0) <br/>X_representative = X_train.values[representative_idx]</span></pre><p id="bb41" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在代码中，X_dist 是到聚类质心的距离矩阵。representative_idx 是最接近每个聚类质心的数据点的索引。</p><p id="d0de" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在选择了特征空间中的代表之后，我们收集了这些数据点的真实标签。这里，我只需要从原始数据中提取标签。</p><pre class="ks kt ku kv gt nk nl nm nn aw no bi"><span id="7266" class="mn mo it nl b gy np nq l nr ns">y_representative = [list(y_train)[x] for x in representative_idx]</span></pre><p id="792f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">但是请注意，实际情况是我们不知道有什么真正的标签，所以需要手动标注这些选中的数据点。</p><p id="8f09" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们来检查在这个训练数据子集上训练的模型的性能。</p><pre class="ks kt ku kv gt nk nl nm nn aw no bi"><span id="bb51" class="mn mo it nl b gy np nq l nr ns">pipeline.fit(X_representative, y_representative)<br/>pipeline.score(X_test, y_test)</span></pre><p id="918c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我得到了 59.6%的准确率！尽管它不能与在整个训练集上训练的模型相比，但它比随机选择的 100 个数据点要好。</p></div><div class="ab cl nu nv hx nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="im in io ip iq"><h2 id="7654" class="mn mo it bd mp mq mr dn ms mt mu dp mv lr mw mx my lv mz na nb lz nc nd ne iz bi translated">讨论</h2><p id="2419" class="pw-post-body-paragraph li lj it lk b ll nf kd ln lo ng kg lq lr nh lt lu lv ni lx ly lz nj mb mc md im bi translated">随着篮球的发展，根据球员的比赛数据来判断他们的位置变得越来越困难。这就是为什么我们只有 60%左右的准确率。</p><p id="306a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">尽管在聚类质心上训练的模型的性能比在随机数据点上训练的模型的性能好，但是改进是有限的。这可以解释为，在目前的 NBA 中，同一位置的球员的比赛数据可能会有很大的差异。</p></div><div class="ab cl nu nv hx nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="im in io ip iq"><h1 id="f1dc" class="oc mo it bd mp od oe of ms og oh oi mv ki oj kj my kl ok km nb ko ol kp ne om bi translated">参考资料:</h1><ol class=""><li id="a258" class="on oo it lk b ll nf lo ng lr op lv oq lz or md os ot ou ov bi translated"><a class="ae lh" href="https://github.com/quantumahesh/Hands-On-Machine-Learning-Book/blob/master/Hands-on-Machine-Learning.pdf" rel="noopener ugc nofollow" target="_blank">用 scikit 动手机器学习——学习 keras 和 tensorflow </a></li><li id="2fc8" class="on oo it lk b ll ow lo ox lr oy lv oz lz pa md os ot ou ov bi translated"><a class="ae lh" href="https://www.basketball-reference.com/" rel="noopener ugc nofollow" target="_blank">篮球参考。</a></li></ol></div><div class="ab cl nu nv hx nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="im in io ip iq"><p id="5abb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">希望这篇短文对你有用！干杯！</p></div></div>    
</body>
</html>