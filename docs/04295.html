<html>
<head>
<title>Productionizing ML Projects with Google BigQuery and PySpark: Predicting Hotel Cancellations</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Google BigQuery 和 PySpark 生产 ML 项目:预测酒店取消</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/productionising-ml-projects-with-google-bigquery-and-pyspark-predicting-hotel-cancellations-8bf94fdc4af?source=collection_archive---------35-----------------------#2020-04-18">https://towardsdatascience.com/productionising-ml-projects-with-google-bigquery-and-pyspark-predicting-hotel-cancellations-8bf94fdc4af?source=collection_archive---------35-----------------------#2020-04-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="26c0" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">数据科学家经常陷入数据科学的探索阶段，即在特定数据集上运行多个模型并优化准确性。</h2></div><p id="c197" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">机器学习的探索阶段无疑是重要的。在生产过程中投入大量时间和资源之前，确保模型正确运行并具有预测能力是必要的。</p><p id="3637" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，总是有在这个阶段花费太多时间而在生产上花费不够的风险。也就是说，整理来自多个来源的数据，并确保基础设施适合处理大型数据流。</p><p id="5a76" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是一个使用梯度推进分类器预测酒店取消的 ML 管道示例。在这个例子中，为两个不同的酒店(H1 和 H2)构建并运行了两个模型。</p><h1 id="e035" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">管道</h1><p id="51ca" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">具体来说，管道设置如下:</p><ol class=""><li id="1f5d" class="mb mc it kk b kl km ko kp kr md kv me kz mf ld mg mh mi mj bi translated">从酒店取消表中选择的列从 Google BigQuery 数据库下载到带有 pythonbq 的 Jupyter 笔记本中，Python bq 是 BigQuery 的 Python 客户端。</li><li id="1612" class="mb mc it kk b kl mk ko ml kr mm kv mn kz mo ld mg mh mi mj bi translated">使用 pyspark 初始化 Spark 会话。进行相关的数据转换是为了让 GBTClassifier 能够处理相关的数据。</li><li id="2583" class="mb mc it kk b kl mk ko ml kr mm kv mn kz mo ld mg mh mi mj bi translated">进行 80/20 训练测试分割，以允许模型评估训练集的不可见部分的性能。</li><li id="bb09" class="mb mc it kk b kl mk ko ml kr mm kv mn kz mo ld mg mh mi mj bi translated">模型预测从 Spark 转换为 pandas 数据框架，然后导出为 CSV。然后，这些预测被读回 Jupyter 笔记本，并生成一个混淆矩阵来评估模型的准确性。</li></ol><figure class="mq mr ms mt gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi mp"><img src="../Images/f62bf1600e5af5c1c64d5fda8fe133ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2FaRLE7AEggVkCks.png"/></div></div></figure><h1 id="9ad4" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">谷歌大查询</h1><p id="e15a" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">首先，H1 的相关 CSV 文件可以上传到 Google BigQuery 并存储为表格。</p><figure class="mq mr ms mt gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi nb"><img src="../Images/c2dfeba9f968ea398c04552323e38e8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*htUQRywuN_pS-WL1.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">来源:谷歌大查询</p></figure><p id="49b2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这种情况下，选择了模式的“自动检测”选项，并生成了表。</p><p id="eee1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面是 Google BigQuery 中显示的表格:</p><figure class="mq mr ms mt gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi ng"><img src="../Images/13ee57d46051b3e49370468f305819a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pSc-2pMqj3RABXDH.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">来源:谷歌大查询</p></figure><h1 id="724e" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">与 PySpark 的相互作用</h1><p id="32eb" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">Spark 专为处理“大数据”而设计。虽然本例中数据集的大小仍然适合使用 Python 本身固有的模型运行，但是我们假设随着更多的数据添加到数据库中，最终将需要使用 Spark 来高效地处理这些大数据批次。此外，Spark 更适合处理不断流动和更新的数据。</p><p id="9730" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Spark 会话用 pyspark 初始化，pythonbq 用于从 BigQuery 加载数据:</p><pre class="mq mr ms mt gt nh ni nj nk aw nl bi"><span id="dac1" class="nm lf it ni b gy nn no l np nq">import pyspark<br/>conf = pyspark.SparkConf()</span><span id="c8f5" class="nm lf it ni b gy nr no l np nq">conf.set('spark.local.dir', 'path')<br/>sc = pyspark.SparkContext(conf=conf)</span><span id="370d" class="nm lf it ni b gy nr no l np nq">from pythonbq import pythonbq</span><span id="0665" class="nm lf it ni b gy nr no l np nq">myProject=pythonbq(<br/>  bq_key_path='json_file',<br/>  project_id='project_id'<br/>)</span></pre><p id="fd0c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是 Jupyter 笔记本中所选功能的表格显示:</p><figure class="mq mr ms mt gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi ns"><img src="../Images/45683cfcfe400c3b1d4013422aba3473.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7937eOCyveBkYqbd.png"/></div></div></figure><p id="20e1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">加载相关特征和输出标签:</p><pre class="mq mr ms mt gt nh ni nj nk aw nl bi"><span id="8040" class="nm lf it ni b gy nn no l np nq">from pyspark.ml import Pipeline<br/>from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler<br/>categoricalColumns = ["Country", "MarketSegment", "ArrivalDateMonth", "DepositType", "CustomerType"]</span><span id="4544" class="nm lf it ni b gy nr no l np nq">stages = []<br/>for categoricalCol in categoricalColumns:<br/>    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + "Index")<br/>    encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + "classVec"])<br/>    stages += [stringIndexer, encoder]</span><span id="d11d" class="nm lf it ni b gy nr no l np nq">label_stringIdx = StringIndexer(inputCol="IsCanceled", outputCol="label")<br/>stages += [label_stringIdx]</span><span id="2a3c" class="nm lf it ni b gy nr no l np nq">numericCols = ["LeadTime", "ArrivalDateYear", "ArrivalDateWeekNumber", "ArrivalDateDayOfMonth", "RequiredCarParkingSpaces"]<br/>assemblerInputs = [c + "classVec" for c in categoricalColumns] + numericCols<br/>assembler = VectorAssembler(inputCols=assemblerInputs, outputCol="features")<br/>stages += [assembler]</span></pre><h1 id="4f7d" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">gbt 分类器</h1><p id="8f27" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">现在可以加载 gbt 分类器(或梯度增强分类器)来用相关数据进行训练。</p><pre class="mq mr ms mt gt nh ni nj nk aw nl bi"><span id="59b9" class="nm lf it ni b gy nn no l np nq">from pyspark.ml.classification import GBTClassifier<br/>  <br/>partialPipeline = Pipeline().setStages(stages)<br/>pipelineModel = partialPipeline.fit(dataset)<br/>preppedDataDF = pipelineModel.transform(dataset)</span><span id="59ed" class="nm lf it ni b gy nr no l np nq">gbtClassifier = GBTClassifier()<br/>trainedModel = gbtClassifier.fit(preppedDataDF)</span></pre><p id="6e9f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在将数据分成 80%训练和 20%测试时，可以训练分类器。</p><pre class="mq mr ms mt gt nh ni nj nk aw nl bi"><span id="b1ff" class="nm lf it ni b gy nn no l np nq">gbtModel = gbtClassifier.fit(trainingData)<br/>predictions = gbtModel.transform(testData)<br/>selected = predictions.select("label", "prediction", "probability")</span></pre><p id="d741" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们来评价一下模型。</p><pre class="mq mr ms mt gt nh ni nj nk aw nl bi"><span id="6384" class="nm lf it ni b gy nn no l np nq">from pyspark.ml.evaluation import BinaryClassificationEvaluator<br/>evaluator = BinaryClassificationEvaluator(rawPredictionCol="rawPrediction")<br/>evaluator.evaluate(predictions)</span></pre><p id="1880" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该模型返回的评估值为 0.9131。</p><p id="a906" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">预测现在可以转换成熊猫数据帧并导出到 CSV:</p><pre class="mq mr ms mt gt nh ni nj nk aw nl bi"><span id="dab1" class="nm lf it ni b gy nn no l np nq">selected.toPandas().to_csv('h1predictions.csv')</span></pre><p id="f6c9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">再次导入预测时，这里有一个包含结果的混淆矩阵。</p><figure class="mq mr ms mt gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi nt"><img src="../Images/dba7d0c4cb17dcdede511d7e6d85bdfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hTUlt5Xfj0fddLf8.png"/></div></div></figure><p id="9dbe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">f1 得分的总体准确率为 84%，而召回率为 66%表明该模型正确识别了 66%取消酒店预订的客户。</p><p id="94f5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对 H2 表运行相同的程序——下面是混淆矩阵结果。</p><figure class="mq mr ms mt gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi nu"><img src="../Images/c67edb9ecd209f6173bb2e19d376116d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3DOwQFDQ7vwQrUW8.png"/></div></div></figure><p id="58fc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">f1 分数的准确率为 94%，而回忆率为 79%。</p><h1 id="9357" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">结论</h1><p id="bf8f" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">在本例中，我们看到:</p><ul class=""><li id="fc12" class="mb mc it kk b kl km ko kp kr md kv me kz mf ld nv mh mi mj bi translated">如何在 Google BigQuery 中填充表格</li><li id="3963" class="mb mc it kk b kl mk ko ml kr mm kv mn kz mo ld nv mh mi mj bi translated">将 Jupyter 笔记本与 BigQuery 数据库进行交互</li><li id="d8fe" class="mb mc it kk b kl mk ko ml kr mm kv mn kz mo ld nv mh mi mj bi translated">使用 pyspark.ml 实现梯度增强分类器</li></ul><p id="d5d6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">非常感谢您的时间——非常感谢您的任何想法或反馈！</p><p id="f66b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个例子的相关 GitHub 库可以在<a class="ae nw" href="https://github.com/MGCodesandStats/hotel-cancellations" rel="noopener ugc nofollow" target="_blank">这里</a>找到，你也可以在 michael-grogan.com<a class="ae nw" href="https://michael-grogan.com/" rel="noopener ugc nofollow" target="_blank">找到更多我的数据科学内容</a>。</p><p id="7b9c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="nx">免责声明:本文是在“原样”的基础上编写的，没有担保。本文旨在提供数据科学概念的概述，不应以任何方式解释为专业建议。</em></p></div></div>    
</body>
</html>