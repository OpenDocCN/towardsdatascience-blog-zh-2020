<html>
<head>
<title>How to reshape data and do regression for time series using LSTM</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用 LSTM 重塑数据并对时间序列进行回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-reshape-data-and-do-regression-for-time-series-using-lstm-133dad96cd00?source=collection_archive---------5-----------------------#2020-04-12">https://towardsdatascience.com/how-to-reshape-data-and-do-regression-for-time-series-using-lstm-133dad96cd00?source=collection_archive---------5-----------------------#2020-04-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8858" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">逐步解释如何使用 LSTM 进行时间序列回归，包括多对多和多对一架构的输入整形。</h2></div><p id="ca53" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在过去的几年里，一般的递归神经网络，特别是 LSTM，在许多数据科学从业者中变得非常流行。尽管 LSTMs 的主要应用是自然语言处理(NLP ),但对于计算科学家和工程师来说，LSTMs 为数据中存在时间相关性的问题提供了创建强大回归模型的可能性。</p><p id="117e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">你将学到什么</strong></p><p id="75a9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本文中，您将学习如何:</p><ul class=""><li id="08e0" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">重塑 LSTM 培训的输入数据</li><li id="7892" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">用<strong class="kk iu"> Keras </strong>拟合 LSTM 时间序列数据</li><li id="b323" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">使用 LSTM 处理单变量和多变量数据集</li></ul><p id="22fc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">输入数据形状混乱</strong></p><p id="67ec" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">撰写本文的主要原因之一是，在 Keras 等神经网络框架中，您需要以 3D 格式提供 LSTM 输入数据，这可能会让许多人感到非常困惑。更令人困惑的是 Keras 中输入维度的命名方式。<strong class="kk iu"> <em class="ls">根据文档和源代码，Keras LSTM 输入数据的格式必须为:[batch_size，timesteps，input_dim]。</em> </strong>此外，可能不需要指定 batch_size。令人困惑。我知道。让我们看看如何将我们的 1D 和 2D 数据改造成 3D 数据形状，以便 LSTM 能够工作！</p><p id="bbf0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> LSTM 架构以及与输入数据形状的关系</strong></p><p id="cb38" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在开始数据重塑之前，让我们回顾一下存在哪些 LSTM 架构。我们来看下图:</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi lt"><img src="../Images/df99974cda6473a20b9564fe5f354bb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RsRIEyJyfgvisdW363CbDw.jpeg"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">图 1—http://karpathy.github.io/2015/05/21/rnn-effectiveness/ LSTM 网络架构(来源—<a class="ae mj" href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" rel="noopener ugc nofollow" target="_blank"/>)</p></figure><p id="c029" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="ls">我们不会逐一介绍。在我看来，对于时间序列问题，最有用的是多对一和多对多(图 1 中的最后一个)，所以我们将更详细地讨论它们。</em></p><p id="1539" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="ls">在 Keras 中，时间步长的数量等于 LSTM 单元的数量。这就是单词“时间步长”在形状的 3D 张量中的含义[batch_size，time steps，input_dim]。</em>T19】</strong></p><p id="814b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了更好地理解这一点，让我们考虑一个玩具(完全随机)数据集，如图 2 所示。在数据集中，我们有 2 个特征和 6 个时间步长(因为我们使用 Python，所以我们从 0 开始计数)。</p><p id="24af" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，考虑多对一的例子。</p><p id="5927" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这种情况下，Keras 希望我们对数据进行整形，以便根据指定数量的先前和当前时间步长特征来计算时间步长<em class="ls"> t </em>处的预测。<strong class="kk iu"> <em class="ls">在右图所示的 LSTM 架构中，时间步数设置为 3。</em> </strong></p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi mk"><img src="../Images/325f00521b21f7b1dfd4b1dcf80d18c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ImNjEulNPD1CYhOdEXU2BQ.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">图 2 —多对一架构示例</p></figure><p id="0275" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="ls">要素的数量等于 2D 数据集中的要素数量。因此，shape [batch_size，timesteps，input_dim]的 3D 张量中的单词“input_dim”表示原始数据集中的要素数量。在我们的例子中," input_dim"=2 </em> </strong></p><p id="9baf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了将我们的原始 2D 数据整形为 3D“滑动窗口”形状，如图 2 所示，我们将创建以下函数:</p><pre class="lu lv lw lx gt ml mm mn mo aw mp bi"><span id="db25" class="mq mr it mm b gy ms mt l mu mv">def lstm_data_transform(x_data, y_data, num_steps=5):<br/>    """ Changes data to the format for LSTM training <br/>for sliding window approach """</span><span id="0067" class="mq mr it mm b gy mw mt l mu mv">    # Prepare the list for the transformed data<br/>    X, y = list(), list()</span><span id="9079" class="mq mr it mm b gy mw mt l mu mv">    # Loop of the entire data set<br/>    for i in range(x_data.shape[0]):<br/>        # compute a new (sliding window) index<br/>        end_ix = i + num_steps</span><span id="338e" class="mq mr it mm b gy mw mt l mu mv">        # if index is larger than the size of the dataset, we stop<br/>        if end_ix &gt;= x_data.shape[0]:<br/>            break</span><span id="29ec" class="mq mr it mm b gy mw mt l mu mv">        # Get a sequence of data for x<br/>        seq_X = x_data[i:end_ix]<br/>        # Get only the last element of the sequency for y<br/>        seq_y = y_data[end_ix]</span><span id="f5d5" class="mq mr it mm b gy mw mt l mu mv">        # Append the list with sequencies<br/>        X.append(seq_X)<br/>        y.append(seq_y)</span><span id="0ac4" class="mq mr it mm b gy mw mt l mu mv">    # Make final arrays<br/>    x_array = np.array(X)<br/>    y_array = np.array(y)</span><span id="ac83" class="mq mr it mm b gy mw mt l mu mv">    return x_array, y_array</span></pre><p id="8705" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="ls">形状的 3D 张量中的 batch _ size【batch _ size，timesteps，input_dim】可能不需要指定，可以指定只是为了加速训练过程。</em>T13】</strong></p><p id="1dbc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，让我们看看我们需要如何为多对多 LSTM 模型重塑数据。为此，请看图 3。这里，我们有 2 个特征，数据集中的 6 个时间步长和 LSTM 神经网络中的 3 个时间步长。因此，为了将 2D 数据转换成所需的 3D 张量，我们可以如下使用 Numpy 功能:</p><pre class="lu lv lw lx gt ml mm mn mo aw mp bi"><span id="eecb" class="mq mr it mm b gy ms mt l mu mv">num_steps = 3<br/>num_features = 2<br/>x_shaped = np.reshape(x, newshape=(-1, num_steps, num_features))</span></pre><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi mx"><img src="../Images/4084f5c4bca02aa0bb497f56d44d3e30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ohcrPZjBUKtj2hEgWIa6zg.jpeg"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">图 3—多对多架构示例</p></figure><p id="464f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，让我们考虑两个例子，这样我们就可以完全理解如何重塑数据，并使用多对一和多对多 LSTM 模型。在第一个例子中，我们将有一个正弦波的一维自回归模型，而在第二个例子中，我们将有一个包含 3 个特征的 2D 数据集。</p><h1 id="ca90" class="my mr it bd mz na nb nc nd ne nf ng nh jz ni ka nj kc nk kd nl kf nm kg nn no bi translated">1D 示例—正弦波的自回归模型</h1><p id="8879" class="pw-post-body-paragraph ki kj it kk b kl np ju kn ko nq jx kq kr nr kt ku kv ns kx ky kz nt lb lc ld im bi translated">在这种情况下，我们要做的是使用指定数量的先前时间步长预测时间步长<em class="ls"> t </em>处的函数值。首先，让我们生成数据。</p><pre class="lu lv lw lx gt ml mm mn mo aw mp bi"><span id="1adf" class="mq mr it mm b gy ms mt l mu mv">x = np.arange(0, 200, 0.5).reshape(-1, 1)<br/>y = np.sin(x).reshape(-1, 1)</span></pre><p id="1b89" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">假设我们想要使用 sin 波的前 10 个时间步长来预测 sin 函数的下一个值。然后，为了将 LSTM 用于此任务，我们使用已经定义的函数来转换数据:</p><pre class="lu lv lw lx gt ml mm mn mo aw mp bi"><span id="3521" class="mq mr it mm b gy ms mt l mu mv">num_steps = 10<br/>x_new, y_new = lstm_data_transform(y, y, num_steps=num_steps)<br/>print ("The new shape of x is", x_new.shape)</span><span id="10e5" class="mq mr it mm b gy mw mt l mu mv">The new shape of x is (390, 10, 1)</span></pre><p id="ea3a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">请注意，我们为函数的 x 和 y 参数都传递了 y，因为我们想要创建一个自回归模型。</strong></p><p id="3bd3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">太好了！现在，我们有了 LSTM 形状，这应该对我们有用。接下来，我们分割数据集，80%用于模型训练，20%用于模型测试。</p><pre class="lu lv lw lx gt ml mm mn mo aw mp bi"><span id="deb1" class="mq mr it mm b gy ms mt l mu mv">train_ind = int(0.8 * x.shape[0])<br/>x_train = x_new[:train_ind]<br/>y_train = y_new[:train_ind]<br/>x_test = x_new[train_ind:]<br/>y_test = y_new[train_ind:]</span></pre><p id="2b2f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，我们定义一个简单的 Keras 模型并训练它！</p><pre class="lu lv lw lx gt ml mm mn mo aw mp bi"><span id="e6ab" class="mq mr it mm b gy ms mt l mu mv">model = Sequential()<br/>model.add(LSTM(100, activation='tanh', input_shape=(num_steps, 1), <br/>               return_sequences=False))<br/>model.add(Dense(units=50, activation='relu'))<br/>model.add(Dense(units=1, activation='linear'))<br/>adam = optimizers.Adam(lr=0.0001)<br/>model.compile(optimizer=adam, loss='mse')<br/>model.fit(x_train, y_train, epochs=20)</span></pre><p id="12e5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后在测试集上进行预测:</p><pre class="lu lv lw lx gt ml mm mn mo aw mp bi"><span id="b69f" class="mq mr it mm b gy ms mt l mu mv">test_predict = model.predict(x_test)<br/>plt.style.use('ggplot')<br/>plt.figure(figsize=(20, 7))<br/>plt.plot(y_test, label="True value")<br/>plt.plot(test_predict.ravel(), label="Predicted value")<br/>plt.legend()</span></pre><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi nu"><img src="../Images/123298c6270b2890efbbb0819511e5ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CyFUYGC6wczn2Jan3P18iQ.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">图 4。—用于估计正弦波的多对一 LSTM 模型结果</p></figure><p id="530b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们得到了一个很好的 sin 函数！这为您提供了一个如何将 1D 数据重塑为 3D 数据以创建多对一架构的 LSTM 模型的示例。<strong class="kk iu"> <em class="ls">注意，这里我们做了一个自回归模型，把 y 放在“lstm_data_transform”的 x_data 和 y_data 两个输入上。请随意将您的要素数据转换为 x_data，这样它会将 x_data 转换为所需的形式。</em>T3】</strong></p><h1 id="70aa" class="my mr it bd mz na nb nc nd ne nf ng nh jz ni ka nj kc nk kd nl kf nm kg nn no bi translated">2D 示例——通过节流阀的流量</h1><p id="a7ec" class="pw-post-body-paragraph ki kj it kk b kl np ju kn ko nq jx kq kr nr kt ku kv ns kx ky kz nt lb lc ld im bi translated">在这个例子中，我们将考虑有 3 个特性和 1 个目标变量的情况，并将使用<strong class="kk iu">多对多和多对一架构。</strong>目标变量是通过<a class="ae mj" href="https://en.wikipedia.org/wiki/Choke_valve" rel="noopener ugc nofollow" target="_blank">阻风门</a>的流量。<em class="ls">如果您对该流程一无所知，请不要担心，这只是一个说明性的示例，该概念将完全适用于手头的任何问题。</em></p><p id="018c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们看看数据帧的开头。在“特征”中，我们有节流器前的压力(P_WHCU)、节流器后的压力(P_WHCD)和节流器开口(0 到 1 之间的值)。因此，我们有 3 个特征和 1 个目标变量，即通过节流器的流量。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/3d84ec81e1ad3c79c24208b670894ce3.png" data-original-src="https://miro.medium.com/v2/resize:fit:902/format:webp/1*EBbXfO2dmHqEV6CTwrmzoA.jpeg"/></div></figure><h2 id="ac34" class="mq mr it bd mz nw nx dn nd ny nz dp nh kr oa ob nj kv oc od nl kz oe of nn og bi translated">资料组</h2><p id="ae64" class="pw-post-body-paragraph ki kj it kk b kl np ju kn ko nq jx kq kr nr kt ku kv ns kx ky kz nt lb lc ld im bi translated">在数据集中，我们有 6570 个点。像以前一样，80%用于培训，20%用于测试。最初，我还使用应用于训练数据的标准缩放器来重新缩放数据，并转换训练和测试数据。</p><p id="eabc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">拆分:</p><pre class="lu lv lw lx gt ml mm mn mo aw mp bi"><span id="b3d7" class="mq mr it mm b gy ms mt l mu mv">train_ind = int(0.8 * x_data.shape[0])<br/>x_train = x_data[:train_ind]<br/>x_test = x_data[train_ind:]<br/>y_train = y_data[:train_ind]<br/>y_test = y_data[train_ind:]</span></pre><p id="d018" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">缩放:</p><pre class="lu lv lw lx gt ml mm mn mo aw mp bi"><span id="753e" class="mq mr it mm b gy ms mt l mu mv"># scalers<br/>scaler_x = StandardScaler()<br/>scaler_y = StandardScaler()<br/># scaling<br/>x_train_sc = scaler_x.fit_transform(x_train)<br/>x_test_sc = scaler_x.transform(x_test)<br/>y_train_sc = scaler_y.fit_transform(y_train)<br/>y_test_sc = scaler_y.transform(y_test)</span></pre><p id="cb41" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">多对多培训</strong></p><p id="7fa3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">假设我们想要使用 3 个先前的时间步长特征来预测通过节流器的流量的当前值。首先，我们按如下方式重塑数据:</p><pre class="lu lv lw lx gt ml mm mn mo aw mp bi"><span id="03ac" class="mq mr it mm b gy ms mt l mu mv">num_steps = 3<br/># training set<br/>x_train_shaped = np.reshape(x_train_sc, newshape=(-1, num_steps, 3))<br/>y_train_shaped = np.reshape(y_train_sc, newshape=(-1, num_steps, 3))<br/>assert x_train_shaped.shape[0] == y_train_shaped.shape[0]<br/># test set<br/>x_test_shaped = np.reshape(x_test_sc, newshape=(-1, num_steps, 3))<br/>y_test_shaped = np.reshape(y_test_sc, newshape=(-1, num_steps, 3))<br/>assert x_test_shaped.shape[0] == y_test_shaped.shape[0]</span></pre><p id="5bd0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">“newshape”参数的最后一个参数等于 3，因为我们有 3 个特征。</p><p id="c6e6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，我们编译这个模型。<strong class="kk iu">请注意，对于多对多模型，我们需要使用 return _ sequences = True:</strong></p><pre class="lu lv lw lx gt ml mm mn mo aw mp bi"><span id="057a" class="mq mr it mm b gy ms mt l mu mv">model = Sequential()<br/>model.add(LSTM(20, activation='tanh', input_shape=(num_steps, 3), return_sequences=True))<br/>model.add(Dense(units=20, activation='relu'))<br/>model.add(Dense(units=1, activation='linear'))<br/>adam = optimizers.Adam(lr=0.001)<br/>model.compile(optimizer=adam, loss='mse')</span></pre><p id="2091" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">拟合模型并根据测试数据进行预测:</p><pre class="lu lv lw lx gt ml mm mn mo aw mp bi"><span id="345d" class="mq mr it mm b gy ms mt l mu mv">model.fit(x_train_shaped, y_train_shaped, epochs=10)<br/>test_predict = model.predict(x_test_shaped)</span></pre><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi oh"><img src="../Images/6be37bef6479c3fa5fff47214b5386d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yuEnrYR9RntyfmSn0HtLCw.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">图 5-节流流量的多对多估计结果</p></figure><p id="872a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们看到，预测是好的，除了一些波动行为，这可能是由过拟合引起的，并通过更好的模型训练来减少。<em class="ls">现在，让我们考虑相同的数据集，但采用多对一架构。</em></p><p id="46ea" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">多对一培训</strong></p><p id="b24b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">和以前一样，我们需要重塑我们的数据，但现在我们需要使用预建的函数:</p><pre class="lu lv lw lx gt ml mm mn mo aw mp bi"><span id="543f" class="mq mr it mm b gy ms mt l mu mv">num_steps = 3</span><span id="efdc" class="mq mr it mm b gy mw mt l mu mv"># training set<br/>(x_train_transformed,<br/> y_train_transformed) = lstm_data_transform(x_train_sc, y_train_sc, num_steps=num_steps)<br/>assert x_train_transformed.shape[0] == y_train_transformed.shape[0]</span><span id="d996" class="mq mr it mm b gy mw mt l mu mv"># test set<br/>(x_test_transformed,<br/> y_test_transformed) = lstm_data_transform(x_test_sc, y_test_sc, num_steps=num_steps)<br/>assert x_test_transformed.shape[0] == y_test_transformed.shape[0]</span></pre><p id="e2ce" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">之后，数据集就可以进行训练了。我们编译与多对多相同的模型。<strong class="kk iu">请注意，对于多对一模型，我们需要使用 return _ sequences = False:</strong></p><pre class="lu lv lw lx gt ml mm mn mo aw mp bi"><span id="a5b4" class="mq mr it mm b gy ms mt l mu mv">model = Sequential()<br/>model.add(LSTM(20, activation='tanh', input_shape=(num_steps, 3), return_sequences=False))<br/>model.add(Dense(units=20, activation='relu'))<br/>model.add(Dense(units=1, activation='linear'))<br/>adam = optimizers.Adam(lr=0.001)<br/>model.compile(optimizer=adam, loss='mse')</span></pre><p id="db4b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，我们拟合模型并对测试集进行预测:</p><pre class="lu lv lw lx gt ml mm mn mo aw mp bi"><span id="9c0f" class="mq mr it mm b gy ms mt l mu mv">model.fit(x_train_transformed, y_train_transformed, epochs=10)<br/>test_predict = model.predict(x_test_shaped)</span></pre><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi oh"><img src="../Images/50985ed347265a09e306b7014f38ccd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sf0bKVMZVTsrTxc5NnwtLw.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">图 6-节流流量的多对一估计结果</p></figure><p id="54a0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如我们所见，我们得到了与多对多模型相似的拟合。然而，这是一个简单的数据集，对于许多问题，结果可能不同。</p><h1 id="0977" class="my mr it bd mz na nb nc nd ne nf ng nh jz ni ka nj kc nk kd nl kf nm kg nn no bi translated">结论</h1><p id="d29c" class="pw-post-body-paragraph ki kj it kk b kl np ju kn ko nq jx kq kr nr kt ku kv ns kx ky kz nt lb lc ld im bi translated">在这篇文章中，我们考虑了如何使用 Keras LSTM 模型进行时间序列回归。我们展示了如何将 1D 和 2D 数据集转换为 3D 张量，以便 LSTM 适用于多对多和多对一架构。在多对多的情况下，我们可以使用 Numpy 功能，而对于多对一，我们需要使用转换函数。此外，对于多对多，Keras 参数 return_sequence 必须等于 True，而对于多对一模型，它必须等于 False。我希望这篇文章对你有用，它将允许你从现在起在研究和日常工作中更多地使用 LSTM 模型！</p></div></div>    
</body>
</html>