<html>
<head>
<title>Saving 95% on infrastructure costs using AWS Lambda for scikit-learn predictions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 AWS Lambda 进行 scikit-learn 预测可节省 95%的基础设施成本</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/saving-95-on-infrastructure-costs-using-aws-lambda-for-scikit-learn-predictions-3ff260a6cd9d?source=collection_archive---------36-----------------------#2020-07-27">https://towardsdatascience.com/saving-95-on-infrastructure-costs-using-aws-lambda-for-scikit-learn-predictions-3ff260a6cd9d?source=collection_archive---------36-----------------------#2020-07-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="549e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用于实时机器学习推理的 AWS Lambda 与 AWS SageMaker</h2></div><p id="43da" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">声明:我是</em> <a class="ae lf" href="https://modelzoo.dev/" rel="noopener ugc nofollow" target="_blank"> <em class="le">模型动物园</em> </a> <em class="le">的开发者，一个专注于易用性的模型部署平台。</em></p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi lg"><img src="../Images/78345260b5b688e9734d3f5d859dba58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lMaHOOJE_7QVso6ggc0hfA.png"/></div></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">在 https://modelzoo.dev/lambda-vs-sagemaker-cost/<a class="ae lf" href="https://modelzoo.dev/lambda-vs-sagemaker-cost/" rel="noopener ugc nofollow" target="_blank">试用我们的工具</a></p></figure><p id="dc6c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你是一个需要部署机器学习模型进行实时推理的 AWS 客户，你可能会考虑使用<strong class="kk iu"> AWS SageMaker 推理端点</strong>。然而，模型部署还有一个选项，这个选项有时会被忽略:直接在<strong class="kk iu"> AWS Lambda 上部署。</strong>虽然它有一些警告，但是 Lambda 的简单性和成本效益使得它值得考虑 SageMaker 端点用于模型部署，特别是当使用<strong class="kk iu"> scikit-learn </strong>、<strong class="kk iu"> xgboost </strong>或<strong class="kk iu"> spaCy </strong>时。在本文中，我们将回顾使用 AWS Lambda 进行 ML 推理的一些好处和注意事项，并深入一些相关的基准测试。我们表明，在低使用率的情况下(每月&lt; 2M 预测)，当将模型从 SageMaker 迁移到 Lambda 时，您可以节省高达<strong class="kk iu"> 95%的基础设施成本</strong>。我们还将展示<a class="ae lf" href="https://github.com/model-zoo/scikit-learn-lambda" rel="noopener ugc nofollow" target="_blank"> scikit-learn-lambda </a>，这是我们的开源工具包，用于在 AWS Lambda 上轻松部署 scikit-learn。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="4221" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">什么是 AWS SageMaker 推理端点？</h1><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi mv"><img src="../Images/8d62d6630edc5612bb3790b43d67de57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Dvjgwqa1oc40ozL6"/></div></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">通过 SageMaker 端点进行实时 ML 推理的 AWS 基础设施图</p></figure><p id="2cc1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">SageMaker 推理端点是 AWS 提供的令人印象深刻的端到端机器学习工具包的许多部分之一，从数据标记(<a class="ae lf" href="https://aws.amazon.com/sagemaker/groundtruth/" rel="noopener ugc nofollow" target="_blank"> AWS SageMaker 地面真相</a>)到模型监控(<a class="ae lf" href="https://docs.aws.amazon.com/sagemaker/latest/dg/monitoring-overview.html" rel="noopener ugc nofollow" target="_blank"> AWS SageMaker 模型监控器</a>)。SageMaker 推理端点提供了围绕 GPU 加速、自动缩放、AB 测试、与培训管道集成以及与离线评分集成的功能(<a class="ae lf" href="https://docs.aws.amazon.com/sagemaker/latest/dg/inference-pipeline-batch.html" rel="noopener ugc nofollow" target="_blank"> AWS 批量转换</a>)。这些特性的代价很高——最便宜的推断端点(ml.t2.medium)将花费您<strong class="kk iu">$ 50/月</strong>来运行 24/7。下一个最佳终点(ml.t2.xlarge)是<strong class="kk iu">$ 189.65/月</strong>。</p><h1 id="2d69" class="md me it bd mf mg mw mi mj mk mx mm mn jz my ka mp kc mz kd mr kf na kg mt mu bi translated">什么是 AWS Lambda？</h1><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nb"><img src="../Images/fd60b1c41379adeac27c2910c0566775.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mgVCfNnvgIWK-NLT.png"/></div></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">AWS Lambda 是一个通用的无服务器计算平台</p></figure><p id="11fd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">AWS Lambda 是无服务器计算运动的先驱，让您无需提供或管理服务器即可运行任意功能。它只在需要的时候执行你的代码，并且自动伸缩，从每天几个请求到每秒几百个请求。Lambda 是一个通用的函数执行引擎，没有任何机器学习的特定功能。它激发了一个不断增长的工具社区，一些来自 AWS 本身(<a class="ae lf" href="https://aws.amazon.com/serverless/sam/" rel="noopener ugc nofollow" target="_blank">无服务器应用模型</a>)和一些外部附属的(<a class="ae lf" href="https://www.serverless.com/" rel="noopener ugc nofollow" target="_blank">无服务器框架</a>)。</p><h1 id="7043" class="md me it bd mf mg mw mi mj mk mx mm mn jz my ka mp kc mz kd mr kf na kg mt mu bi translated">AWS Lambda 对实时机器学习推理的好处</h1><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nc"><img src="../Images/98d5c910dbcb5726ad48d168ab3d2f9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*vAAaPDS3UFB1oUM3.png"/></div></div></figure><ul class=""><li id="e5e1" class="nd ne it kk b kl km ko kp kr nf kv ng kz nh ld ni nj nk nl bi translated">Lambda 有一个<strong class="kk iu">按请求付费</strong>模式，可以随着你的成长而扩展。这是赞成还是反对取决于你的使用水平，但特别是<strong class="kk iu">成本效益</strong>服务在 2M 预测每月。在撰写本文时，SageMaker 不支持在低活动期自动调整到零。</li><li id="8b2b" class="nd ne it kk b kl nm ko nn kr no kv np kz nq ld ni nj nk nl bi translated">Lambda 需要一个<strong class="kk iu">更简单的实现</strong>计算模型，其中并发/自动伸缩可以在逻辑之外透明地处理。</li><li id="3414" class="nd ne it kk b kl nm ko nn kr no kv np kz nq ld ni nj nk nl bi translated">Lambda 要求<strong class="kk iu">降低</strong> <strong class="kk iu">维护工作量</strong>，无需管理任何底层服务器或逻辑。</li><li id="4b97" class="nd ne it kk b kl nm ko nn kr no kv np kz nq ld ni nj nk nl bi translated">Lambda 有一个丰富的开发者生态系统(开源和 SaaS)，用于监控、记录和测试无服务器应用，比如无服务器应用。有了 SageMaker，你就依赖于 AWS 特有的资源，比如用于工具的<a class="ae lf" href="https://github.com/aws/sagemaker-containers" rel="noopener ugc nofollow" target="_blank"> SageMaker 兼容容器</a>和<a class="ae lf" href="https://sagemaker.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank"> SageMaker Python SDK </a>。</li></ul><h1 id="6b14" class="md me it bd mf mg mw mi mj mk mx mm mn jz my ka mp kc mz kd mr kf na kg mt mu bi translated">AWS Lambda 用于实时机器学习推理的缺点</h1><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nr"><img src="../Images/0920cf8976d9432bb0871aa154c1b0f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*CXxkpWovpPKmnMwg.png"/></div></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">导致冷启动延迟的请求生命周期。</p></figure><ul class=""><li id="5f6a" class="nd ne it kk b kl km ko kp kr nf kv ng kz nh ld ni nj nk nl bi translated">Lambda 对可用资源有限制，最大<strong class="kk iu"> 3，008 MB 物理内存</strong>和<strong class="kk iu">不支持 GPU 加速</strong>。对于使用具有严格延迟要求的大型模型的基础架构来说，这可能是一个障碍。</li><li id="bc4b" class="nd ne it kk b kl nm ko nn kr no kv np kz nq ld ni nj nk nl bi translated">当在 5-10 分钟的不活动期后调用该函数时，Lambda 会导致<strong class="kk iu">冷启动延迟</strong>。<a class="ae lf" href="https://mikhail.io/serverless/coldstarts/aws/#:~:text=This%20article%20describes%20AWS%20Lambda,Cold%20Starts%20in%20Serverless%20Functions." rel="noopener ugc nofollow" target="_blank">AWS Lambda</a>上的冷启动是一篇很棒的博文，深入探讨了影响冷启动延迟的一些因素。</li><li id="676d" class="nd ne it kk b kl nm ko nn kr no kv np kz nq ld ni nj nk nl bi translated"><strong class="kk iu">AWS Lambda 中的包大小限制</strong>非常严格，压缩后为 50 MB，解压缩后为 250 MB。有变通办法(<a class="ae lf" href="https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html" rel="noopener ugc nofollow" target="_blank"> AWS Lambda Layers </a>)，但是这对于捆绑常见的 ML 依赖项(如 TensorFlow (~400 MB)和 PyTorch (~250 MB)来说可能是一个恼人的障碍。</li><li id="a5bb" class="nd ne it kk b kl nm ko nn kr no kv np kz nq ld ni nj nk nl bi translated">Lambda 不能直接使用 Docker 容器作为依赖，而是有自己的依赖管理系统<a class="ae lf" href="https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html" rel="noopener ugc nofollow" target="_blank"> AWS Lambda Layers </a>。这有时需要用户在打包时做一点额外的工作。</li></ul><h1 id="a497" class="md me it bd mf mg mw mi mj mk mx mm mn jz my ka mp kc mz kd mr kf na kg mt mu bi translated">案例研究:scikit-learn</h1><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi ns"><img src="../Images/1ad6045494c3db281b07df888ce77827.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*uIAKC9nBA27-PJW_.jpg"/></div></div></figure><p id="9a87" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae lf" href="https://pharmassess.ca/" rel="noopener ugc nofollow" target="_blank">pharm assesse</a>是一个模型动物园用户，其任务是更自信、更高效地治疗更多患者。他们开发了一个专有模型，可以使用 scikit-learn 自动进行小病评估、诊断和治疗&amp;文档，现在正在与一组初始用户一起测试它。他们的模型大小约为 50 MB，是 Lambda 部署的理想选择。</p><h1 id="08e2" class="md me it bd mf mg mw mi mj mk mx mm mn jz my ka mp kc mz kd mr kf na kg mt mu bi translated">设置</h1><p id="2b8d" class="pw-post-body-paragraph ki kj it kk b kl nt ju kn ko nu jx kq kr nv kt ku kv nw kx ky kz nx lb lc ld im bi translated">通过 Model Zoo，PharmAssess 能够使用简单的 Python API 部署其 scikit-learn 模型。在幕后，Model Zoo 将把 scikit-learn 模型打包并部署到 AWS Lambda 函数中(参见我们的<a class="ae lf" href="https://colab.research.google.com/github/model-zoo/examples/blob/master/scikit-learn-quickstart/quickstart.ipynb" rel="noopener ugc nofollow" target="_blank"> quickstart </a>获取完整示例)。</p><pre class="lh li lj lk gt ny nz oa ob aw oc bi"><span id="0df4" class="od me it nz b gy oe of l og oh">import modelzoo.sklearn</span><span id="f51f" class="od me it nz b gy oi of l og oh">model = ...  # train model<br/>modelzoo.sklearn.deploy(model)</span></pre><p id="befe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您喜欢维护自己的模型存储、部署和监控堆栈，您可以使用我们的开源包<a class="ae lf" href="https://github.com/model-zoo/scikit-learn-lambda" rel="noopener ugc nofollow" target="_blank"> scikit-learn-lambda </a>通过无服务器框架将模型部署到您自己的 AWS 云上:</p><pre class="lh li lj lk gt ny nz oa ob aw oc bi"><span id="8135" class="od me it nz b gy oe of l og oh">$ git clone <a class="ae lf" href="https://github.com/model-zoo/scikit-learn-lambda" rel="noopener ugc nofollow" target="_blank">https://github.com/model-zoo/scikit-learn-lambda</a><br/>$ cd scikit-learn-lambda<br/>$ cp &lt;model file&gt; scikit-learn-lambda/model.joblib<br/>$ serverless deploy</span></pre><h1 id="c68f" class="md me it bd mf mg mw mi mj mk mx mm mn jz my ka mp kc mz kd mr kf na kg mt mu bi translated">延迟基准</h1><figure class="lh li lj lk gt ll gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/fd3b17fe3238848612f1222d974d796f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*JiCdgOTgAG4D_qjT0WB9Fw.png"/></div></figure><p id="73f0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">AWS Lambda 的一个重要警告是“冷启动”，即在 5-10 分钟不活动后发生的初始化开销。为了了解严重性，我们生成了具有三个隐藏层的<a class="ae lf" href="https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html" rel="noopener ugc nofollow" target="_blank"> MLPClassifier </a>模型，每个隐藏层使用 100、250、500、750 和 900 的层大小。每个模型都在 iris 数据集上训练，并使用<a class="ae lf" href="https://joblib.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank"> joblib </a>库序列化到磁盘。这导致模型文件的大小分别为 0.68 MB、4.08 MB、16.17 MB、36.25 MB 和 52.13 MB。我们使用 scikit-learn-lambda 将每一个部署到具有 1024 MB 内存的 lambda 函数，并测量三个样本的平均冷启动延迟，以生成上面的基准。</p><p id="5a9a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们还在下面绘制了十五个样本的平均“热”延迟，每个模型的平均延迟在 2-5 毫秒左右。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/4d95b9513051bf6d6db295a3a75ba418.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*hinCaUW1Oze_pwrCEX9x8g.png"/></div></figure><p id="0a12" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有一些解决冷启动延迟的方法，比如<a class="ae lf" href="https://github.com/FidelLimited/serverless-plugin-warmup" rel="noopener ugc nofollow" target="_blank">每隔几分钟就触发你的函数来保持它的热度</a>或者使用<a class="ae lf" href="https://aws.amazon.com/blogs/aws/new-provisioned-concurrency-for-lambda-functions/" rel="noopener ugc nofollow" target="_blank">提供的并发</a>。但是，如果针对 p90+延迟进行优化是一项重要的业务需求，那么无服务器模式可能不适合您的使用案例。</p><h1 id="c0b4" class="md me it bd mf mg mw mi mj mk mx mm mn jz my ka mp kc mz kd mr kf na kg mt mu bi translated">成本基准</h1><p id="c0a4" class="pw-post-body-paragraph ki kj it kk b kl nt ju kn ko nu jx kq kr nv kt ku kv nw kx ky kz nx lb lc ld im bi translated">AWS Lambda 的使用情况很难结合每个请求的时间、内存使用情况和每月的总请求量来衡量。我们创建了这种交互式可视化，以帮助我们了解各种使用场景下的每月成本，以 SageMaker 端点为基准。</p><div class="ok ol gp gr om on"><a href="https://modelzoo.dev/lambda-vs-sagemaker-cost/" rel="noopener  ugc nofollow" target="_blank"><div class="oo ab fo"><div class="op ab oq cl cj or"><h2 class="bd iu gy z fp os fr fs ot fu fw is bi translated">AWS Lambda 与 AWS SageMaker 成本计算器</h2><div class="ou l"><h3 class="bd b gy z fp os fr fs ot fu fw dk translated">modelzoo.dev</h3></div></div></div></a></div><p id="8bce" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">成本差异不言自明:使用上面观察到的平均热延迟和 1024 MB 的分配内存，Lambda 比来自最低成本层的单个 SageMaker 端点便宜一个数量级。按请求付费的模型也使其非常适合 AB 测试和原型开发——您可以部署您训练的每一个模型，而不必担心利用不足。</p><h1 id="4a52" class="md me it bd mf mg mw mi mj mk mx mm mn jz my ka mp kc mz kd mr kf na kg mt mu bi translated">TL；dr:什么时候应该使用 AWS Lambda？</h1><p id="9ad8" class="pw-post-body-paragraph ki kj it kk b kl nt ju kn ko nu jx kq kr nv kt ku kv nw kx ky kz nx lb lc ld im bi translated">一般来说，AWS Lambda 对较小的模型(&lt;50MB) that can use CPUs for inference and for which you expect a usage pattern of &lt;2M requests/month. This makes it ideal for building <strong class="kk iu">原型</strong>或<strong class="kk iu">新产品</strong>有意义，它们使用轻量级模型库【2】，如<strong class="kk iu"> scikit-learn </strong>、<strong class="kk iu"> xgboost </strong>或<strong class="kk iu"> spaCy </strong>。</p></div></div>    
</body>
</html>