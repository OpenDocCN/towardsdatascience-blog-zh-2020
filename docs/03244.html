<html>
<head>
<title>Spherical Projection for Point Clouds</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">点云的球面投影</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/spherical-projection-for-point-clouds-56a2fc258e6c?source=collection_archive---------8-----------------------#2020-03-28">https://towardsdatascience.com/spherical-projection-for-point-clouds-56a2fc258e6c?source=collection_archive---------8-----------------------#2020-03-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="b373" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">大家好，这是我的第一个媒体帖子，我希望让大家参与到最后。在这篇文章中，我将谈论如何使用球面投影将3D点云投影到图像中。我也写了同样的代码，可以在我的GitHub库<a class="ae kl" href="https://github.com/anirudhtopiwala/OpenSource_Problems/tree/master/Spherical_View_Projection" rel="noopener ugc nofollow" target="_blank">这里</a>找到。所以让我们开始吧！！！</p><p id="df16" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">球形投影或前视图投影只不过是将3D点云数据表示成2D图像数据的一种方式，因此本质上，它也充当降维方法。球面投影越来越多地用于不同的深度学习解决方案中，用于处理点云。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi km"><img src="../Images/6ffdb158473f0dbb724accf8bf8e9e6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*LeHUFEgfKsXu5gmtO5bycg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">语义分割(作者:<a class="ae kl" href="http://semantic-kitti.org/" rel="noopener ugc nofollow" target="_blank"> SemanticKitti </a></p></figure><p id="9fed" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">应用最广泛的领域之一是对点云中的物体进行分类和分割。这可以在各种出版物中看到，如<a class="ae kl" href="https://arxiv.org/abs/1807.06288" rel="noopener ugc nofollow" target="_blank"> PointSeg </a>、<a class="ae kl" href="https://arxiv.org/abs/1710.07368" rel="noopener ugc nofollow" target="_blank">squeeze g、</a> <a class="ae kl" href="https://www.groundai.com/project/salsanet-fast-road-and-vehicle-segmentation-in-lidar-point-clouds-for-autonomous-driving/1" rel="noopener ugc nofollow" target="_blank"> SalsaNet </a>等等。将点云表示为图像的最大优点是，它将过去十年中对2D图像所做的所有研究都开放给了3D点云。例如，不同的最先进的网络，如<a class="ae kl" href="https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf" rel="noopener ugc nofollow" target="_blank"> FCN </a>、<a class="ae kl" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank"> U-Net </a>、<a class="ae kl" href="https://arxiv.org/abs/1703.06870" rel="noopener ugc nofollow" target="_blank"> Mask-RCNN </a>、<a class="ae kl" href="https://arxiv.org/abs/1506.01497" rel="noopener ugc nofollow" target="_blank">和fast-RCNN</a>现在可以扩展到点云数据，这是许多研究人员正在努力实现的目标，特别是在自动驾驶领域。</p><h1 id="4715" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated"><strong class="ak">直观解释</strong></h1><p id="5d9f" class="pw-post-body-paragraph jn jo iq jp b jq lw js jt ju lx jw jx jy ly ka kb kc lz ke kf kg ma ki kj kk ij bi translated">为了理解这一点，让我们深入了解激光雷达是如何形成一点云扫描的。让我们考虑下图所示的16激光雷达的情况。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi mb"><img src="../Images/5b4b4fc15c72ae55869856bed7d609b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FEg6D6V_CzlSaDsCxXzfLg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">左图显示了由16个激光器组成的激光雷达。由激光雷达的第一个和最后一个激光器形成的最大和最小视角由FOV _上和FOV _下指示。右边的矩形是当我们将激光雷达形成的空心圆柱体投影到平面上时得到的。(作者:阿尼鲁德·托皮瓦拉)</p></figure><p id="94c1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">16个激光器中的每一个都以固定的角度定向，这取决于垂直角分辨率，FOV _上(上部视场)和FOV _下(下部视场)。每个激光雷达都有一个发射和接收单元。这些点是通过计算每个激光从物体反射后的飞行时间而形成的。这16束激光旋转360度形成一个点云。</p><blockquote class="mg mh mi"><p id="096e" class="jn jo mj jp b jq jr js jt ju jv jw jx mk jz ka kb ml kd ke kf mm kh ki kj kk ij bi translated">因此，这将导致的几何形状是一个<strong class="jp ir">空心圆柱体</strong>，激光雷达位于其中心。当我们从一个垂直于圆柱体主轴的轴将这个空心圆柱体投影到一个平面上时，我们得到一个图像。这种图像称为球面投影图像。</p></blockquote><h1 id="4332" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated"><strong class="ak">现在让我们用一些数学来解决技术问题吧！！</strong></h1><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi mn"><img src="../Images/c0b2e6f5c252208bc8affac398ddc2f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dwx4RdGRknJUk415dZoILw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者:阿尼鲁德·托皮瓦拉)</p></figure><p id="5ce1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的目标是找到所有(x，y，z)点的投影图像的像素坐标。这可以通过使用<a class="ae kl" href="https://en.wikipedia.org/wiki/Spherical_coordinate_system" rel="noopener ugc nofollow" target="_blank">球面坐标系</a>来实现。看上图，我们可以看到，如果+ive x轴是激光雷达的前视图，那么云的每个点都会与xy平面形成一个倾角<em class="mj">角度</em> <strong class="jp ir">，<em class="mj">俯仰</em> </strong>和<em class="mj">角度</em> <strong class="jp ir"> <em class="mj">，偏航</em> </strong>与xz轴。这里我们要把空心圆柱体投影到zy平面上形成图像。利用基本的三角学，我们可以得到每个点的俯仰和偏航值。由于原点位于图像的中心，这些偏航和俯仰值构成了投影图像的每个像素位置。因此，通过计算每个点的偏航和俯仰，我们可以完整地形成投影图像。在这一点上，我还想指出，俯仰值的范围将从[FOV向上，FOV向下]，因为它是激光指向的最大和最小角度，偏航值的范围将从[-π，π]，因为这是由atan2函数给出的范围。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi mo"><img src="../Images/f6529f0cbc685ca48dd1e4d39d69e66e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dlW9j28n2ak83NXB94xaHA.png"/></div></div></figure><p id="1353" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">虽然我们现在有了投影图像，但是由于两个问题，我们仍然不能使用它。首先，我们需要将原点平移到图像的左上角，如下所示。这是因为，在计算机视觉中，标准是原点在图像的左上角。第二，我们需要根据使用的激光雷达的类型来缩放图像。这两个步骤如下所示:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi mp"><img src="../Images/1e896b4f9b7c0f0622624edb10d67fc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RQ54xCRVudI39TaF4hAg_Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者:阿尼鲁德·托皮瓦拉)</p></figure><h2 id="4a54" class="mq kz iq bd la mr ms dn le mt mu dp li jy mv mw lm kc mx my lq kg mz na lu nb bi translated">1.翻译原文</h2><p id="116b" class="pw-post-body-paragraph jn jo iq jp b jq lw js jt ju lx jw jx jy ly ka kb kc lz ke kf kg ma ki kj kk ij bi translated">这是一个简单的翻译起源问题。查看上图，我们可以通过向偏航轴添加π角来将原点移动到图像的左边缘，而通过从FOV_Up中减去俯仰角来将原点移动到图像的顶部。因此，新方程变成:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi nc"><img src="../Images/2398105b6207a5c30994b8ba7de0e34e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WHPRhG1tlM0K9dNOz5SgJQ.png"/></div></div></figure><h2 id="a532" class="mq kz iq bd la mr ms dn le mt mu dp li jy mv mw lm kc mx my lq kg mz na lu nb bi translated">2.标准化和缩放</h2><blockquote class="mg mh mi"><p id="b731" class="jn jo mj jp b jq jr js jt ju jv jw jx mk jz ka kb ml kd ke kf mm kh ki kj kk ij bi translated">这一步骤是必要的，因为对于不同类型的激光雷达，投影图像的大小会有所不同，主要目的是在投影图像中拟合尽可能多的点。</p></blockquote><p id="2703" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如我们在这篇博文中观察到的，整个过程是关于降维的，因此，我们会丢失数据是事实。这里的想法是以这样一种方式形成图像维度，即我们能够从图像中的云中捕捉最相关的点。因此，我们可以从逻辑上看到，激光雷达的<strong class="jp ir">个激光应该相当于投影图像的宽度</strong>。这样，图像的每一行将与从激光雷达的每个激光器获得的点相关。该值称为row_scale因子，乘以归一化的俯仰轴。例如，<a class="ae kl" href="https://velodynelidar.com/products/hdl-64e/" rel="noopener ugc nofollow" target="_blank">威力登HDL 64-E激光雷达</a>有64个激光器，因此，投影图像的宽度应该通过将该值乘以俯仰轴来设置为64。</p><p id="1406" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">图像的长度构成了偏航角分辨率。该参数可以调整以适应尽可能多的点</strong>。图像的这个长度也称为col_scale，乘以归一化的偏航轴，得到最终的图像尺寸。同样，对于HDL 64-E，最大水平分辨率为0.35度。因此，在最坏的情况下，我们将至少得到每个激光器(360/0.35 = 1028)个点。在深度学习和卷积网络中，图像大小优选为2的幂。因此，1024的长度将适合图像中的最大点数，我们将把这个值乘以偏航轴。</p><p id="d818" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，64X1024的图像尺寸对于HDL 64-E来说是理想的。可以对<a class="ae kl" href="http://velodynelidar" rel="noopener ugc nofollow" target="_blank">威力登VLP-16 </a>进行类似的计算，其中最佳图像尺寸为16x1024。</p><p id="7462" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">归一化等式现在可以重写为:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi nd"><img src="../Images/9b235f06172da5978eb5cf9ceda838dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3tWawCiH6jrlqccNAApzsg.png"/></div></div></figure><p id="9a45" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果总的FOV = FOV _上+ABS(FOV _下)，那么(u，v)的最终方程通过一些值的重新排列可以写成:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi ne"><img src="../Images/252f854d98f334231c84c5821335e535.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JZCurin1q7ZOF1t7IJw4DA.png"/></div></div></figure><p id="8d66" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于威力登HDL 64-E激光雷达，同样的方程可以改写为:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi ne"><img src="../Images/ea9a520039a76af2bea25c467fda4ae7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uk9j7Xa_TBWZw58rnNH5Aw.png"/></div></div></figure><blockquote class="mg mh mi"><p id="ff1d" class="jn jo mj jp b jq jr js jt ju jv jw jx mk jz ka kb ml kd ke kf mm kh ki kj kk ij bi translated">这样，借助上面的方程，我们就可以把云的每个点(x，y，z)投影到它对应的球面投影(u，v)上。</p></blockquote><h1 id="7bb3" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">将点信息编码到图像中</h1><p id="19c9" class="pw-post-body-paragraph jn jo iq jp b jq lw js jt ju lx jw jx jy ly ka kb kc lz ke kf kg ma ki kj kk ij bi translated">一旦我们获得了云的每个点的(u，v)像素，我们需要对其进行舍入以获得最接近的整数，并将点信息编码到其中。通常，在每个像素处添加5个关键值，即X、Y、Z、R和I。这里，(X，Y，Z)是点的坐标，R是该点与激光雷达的欧氏距离或范围，I是强度。Range是我们计算的唯一值，因为对于激光雷达形成的云的每个点，X、Y、Z和I值已经存在。因此，我们得到的最终图像尺寸是:</p><blockquote class="mg mh mi"><p id="4d55" class="jn jo mj jp b jq jr js jt ju jv jw jx mk jz ka kb ml kd ke kf mm kh ki kj kk ij bi translated"><strong class="jp ir">图像尺寸=激光雷达的激光数量*投影图像的长度* 5(五个通道是X、Y、Z、R、I) </strong></p></blockquote><h1 id="408a" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">现在是你期待已久的部分..结果！！！</h1><p id="6450" class="pw-post-body-paragraph jn jo iq jp b jq lw js jt ju lx jw jx jy ly ka kb kc lz ke kf kg ma ki kj kk ij bi translated">使用上面得到的公式，我写了一个c++代码，可以在这里找到<a class="ae kl" href="https://github.com/anirudhtopiwala/OpenSource_Problems" rel="noopener ugc nofollow" target="_blank"/>。这段代码使用<a class="ae kl" href="http://pointclouds.org/" rel="noopener ugc nofollow" target="_blank"> PCL </a>库来加载点云，使用<a class="ae kl" href="https://opencv.org/" rel="noopener ugc nofollow" target="_blank"> openCV </a>来可视化所形成的球面图像的每个维度。为了测试我的实现，我使用了来自SemanticKitti的数据集。下面gif的上半部分显示了由下半部分显示的点云形成的球形图像的亮度值。</p><blockquote class="mg mh mi"><p id="9426" class="jn jo mj jp b jq jr js jt ju jv jw jx mk jz ka kb ml kd ke kf mm kh ki kj kk ij bi translated">概括地说，由于该数据集中使用的激光雷达是威力登HDL 64-E，形成的球形图像的尺寸是64 * 1024* 5。</p></blockquote><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/7badecb92da74a8e04e58bf8b77749b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*b-kIpWiYhDt91Tky2tI1MQ.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">上半部分是形成的球形图像的强度维度，下半部分是输入点云。(作者:阿尼鲁德·托皮瓦拉)</p></figure><h2 id="6d1f" class="mq kz iq bd la mr ms dn le mt mu dp li jy mv mw lm kc mx my lq kg mz na lu nb bi translated">一些重要观察结果:</h2><blockquote class="mg mh mi"><p id="f47e" class="jn jo mj jp b jq jr js jt ju jv jw jx mk jz ka kb ml kd ke kf mm kh ki kj kk ij bi translated">1.球形图像的每一行对应于从激光雷达的每个激光器获得的点。这里，图像中最低的一行对应于激光雷达中最低的激光，这是激光雷达附近最近的环，如上面的gif所示。</p><p id="66ef" class="jn jo mj jp b jq jr js jt ju jv jw jx mk jz ka kb ml kd ke kf mm kh ki kj kk ij bi translated">2.形成的球形图像本质上是圆形的，这意味着你将能够观察到当物体从左侧离开图像时，它们可能会在图像的右侧重新出现。</p><p id="d6a5" class="jn jo mj jp b jq jr js jt ju jv jw jx mk jz ka kb ml kd ke kf mm kh ki kj kk ij bi translated">3.图像中的物体可以用人眼识别。意思是，如果你看图像，很容易区分汽车、自行车、建筑物、道路等等。如果它可以被人眼区分，那么在这样的图像上训练的深度网络就有很大的机会能够给出良好的分割和分类结果。</p><p id="e912" class="jn jo mj jp b jq jr js jt ju jv jw jx mk jz ka kb ml kd ke kf mm kh ki kj kk ij bi translated">4.此投影中丢失的点是那些与激光雷达中心具有相同俯仰角和偏航角但距离值不同的点。因此，只有连接激光雷达中心和该点的射线上的一个点会在投影图像中被捕获。</p></blockquote><p id="f792" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">结果的清晰视频可以在这里找到<a class="ae kl" href="https://www.youtube.com/watch?v=1vSI_j435Vs" rel="noopener ugc nofollow" target="_blank">。</a></p><h2 id="e4ce" class="mq kz iq bd la mr ms dn le mt mu dp li jy mv mw lm kc mx my lq kg mz na lu nb bi translated">总之，球面投影是以图像形式表示点云数据的一个非常强大的工具。使用它可以帮助我们将过去十年在图像空间所做的所有研究扩展到点云数据，因此在机器人和自动驾驶汽车领域有着各种各样的应用。</h2><p id="4fd9" class="pw-post-body-paragraph jn jo iq jp b jq lw js jt ju lx jw jx jy ly ka kb kc lz ke kf kg ma ki kj kk ij bi translated">我对这个主题以及计算机视觉和深度学习领域的其他主题的任何建议或头脑风暴会议都持开放态度，所以请随时与我联系<a class="ae kl" href="https://anirudhtopiwala.com/" rel="noopener ugc nofollow" target="_blank">！！！</a></p></div></div>    
</body>
</html>