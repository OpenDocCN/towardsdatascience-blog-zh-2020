<html>
<head>
<title>Unsupervised Machine Learning Example in Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Keras 中的无监督机器学习示例</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/unsupervised-machine-learning-example-in-keras-8c8bf9e63ee0?source=collection_archive---------10-----------------------#2020-05-28">https://towardsdatascience.com/unsupervised-machine-learning-example-in-keras-8c8bf9e63ee0?source=collection_archive---------10-----------------------#2020-05-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="59ac" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用自动编码器对欺诈性健康保险索赔进行异常检测。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/3c58969293cf79c7bf22b7c438a47482.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FuZrV0uEFOy_oyddlRblAg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://pixabay.com/users/geralt-9301/" rel="noopener ugc nofollow" target="_blank"> geralt </a>在<a class="ae ky" href="https://pixabay.com/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>上拍摄的照片</p></figure><p id="dfe1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇文章是关于无监督学习和我在健康保险欺诈索赔检测方面的研究。</p><p id="5bb0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在健康保险中，欺诈性索赔检测存在一些挑战。首先，没有与医疗保险索赔欺诈相关的公开数据，这与数据隐私问题有关。第二，很难确定一套有助于识别欺诈性索赔的规则。这意味着带有标签数据的监督机器学习方法很难适用于我们的情况。无监督的机器学习似乎会是更好的匹配。在无监督的机器学习中，网络在没有标签的情况下训练，它发现模式并将数据分成组。这对于数据中的异常检测特别有用，在这种情况下，我们要寻找的数据很少。医疗保险欺诈就是这种情况——与索赔总额相比，这是不正常的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/e224855e2f93b097ce84363cbcf3b97c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BKvYt1EHtzHOd_HWjm-Jrw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://www.google.com/search?q=unsupervised+learning&amp;sxsrf=ALeKk00uZcvCnHyS6bNphYxj_3sQQsVqlA:1590667589937&amp;source=lnms&amp;tbm=isch&amp;sa=X&amp;ved=2ahUKEwiNoZ3FwtbpAhVshosKHULSAdUQ_AUoAXoECBQQAw&amp;biw=1680&amp;bih=948" rel="noopener ugc nofollow" target="_blank">谷歌图片</a></p></figure><p id="2962" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我建议通过使用 Python 书籍的<a class="ae ky" href="https://www.amazon.com/Hands-Unsupervised-Learning-Using-Python-ebook/dp/B07NY447H8" rel="noopener ugc nofollow" target="_blank">实践无监督学习来更好地实践对这个主题的理解。这本书有一个</a><a class="ae ky" href="https://github.com/aapatel09/handson-unsupervised-learning" rel="noopener ugc nofollow" target="_blank"> GitHub </a>回购。在我的例子中，我使用了本书中的异常分数计算函数。</p><p id="c61e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们识别欺诈的方法是检测异常情况。在无监督学习中，可以用自动编码器检测异常。Autoencoder 将原始数据转换为学习过的表示，基于此，我们可以运行一个函数，并计算学习过的表示离原始数据有多远。欺诈性数据以更高的错误率重建，这有助于识别异常。自动编码器适用于无监督学习——训练不需要标记数据。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lw"><img src="../Images/52221506ec9a77a07f8456470bfd995c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GZekgkSevIrR0GMYeynEdw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://www.google.com/search?q=anomaly+detection+with+autoencoders&amp;tbm=isch&amp;ved=2ahUKEwiAqbaKw9bpAhWWvCoKHXjCDOQQ2-cCegQIABAA&amp;oq=anomaly+detection+with+au&amp;gs_lcp=CgNpbWcQARgBMgQIIxAnMgQIABAYMgQIABAYMgQIABAYULQ6WLo7YKlQaABwAHgAgAFJiAGHAZIBATKYAQCgAQGqAQtnd3Mtd2l6LWltZw&amp;sclient=img&amp;ei=16nPXsDhApb5qgH4hLOgDg&amp;bih=948&amp;biw=1680" rel="noopener ugc nofollow" target="_blank">谷歌图片</a></p></figure><p id="83f1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我的例子是基于定位欺诈性健康保险索赔的想法。可能有各种类型的欺诈，例如，医院可能会向保险公司收取过高的费用。我们的任务是检测欺诈性索赔，该模型在 Keras 中使用无监督的方式进行训练，没有标签。</p><p id="435d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">很难获得健康保险的公共数据(隐私问题)。出于这个原因，我使用生成的数据(基于这篇文章— <a class="ae ky" rel="noopener" target="_blank" href="/data-science-with-no-data-b3c21acee17c">没有数据的数据科学</a>):</p><ul class=""><li id="ebbd" class="lx ly it lb b lc ld lf lg li lz lm ma lq mb lu mc md me mf bi translated">培训:100 000(有效索赔)，100 0(欺诈索赔)</li><li id="5c3b" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">测试:30 000(有效索赔)，30 0(欺诈索赔)</li><li id="9a6d" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">欺诈索赔规则:索赔的保险费用增加一倍</li></ul><p id="56b0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">检测数据重建错误率的异常分数函数:</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="13e2" class="mq mr it mm b gy ms mt l mu mv">def anomalyScores(originalDF, reducedDF):<br/>    loss = np.sum((np.array(originalDF) - \<br/>                   np.array(reducedDF))**2, axis=1)<br/>    loss = pd.Series(data=loss,index=originalDF.index)<br/>    loss = (loss-np.min(loss))/(np.max(loss)-np.min(loss))<br/>    <br/>    print('Mean for anomaly scores: ', np.mean(loss))<br/>    <br/>    return loss</span></pre><p id="01b6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Autoencoder 用 Keras/TensorFlow 实现。神经网络定义为 3 层(节点数=数据维数)。使用线性激活，优化器<em class="mw">亚当:</em></p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="b943" class="mq mr it mm b gy ms mt l mu mv"># Call neural network API<br/>model = Sequential()</span><span id="a7c8" class="mq mr it mm b gy mx mt l mu mv"># Apply linear activation function to input layer<br/># Generate hidden layer with 14 nodes, the same as the input layer<br/>model.add(Dense(units=14, activation='linear',input_dim=14))<br/>model.add(Dense(units=14, activation='linear'))</span><span id="059e" class="mq mr it mm b gy mx mt l mu mv"># Apply linear activation function to hidden layer<br/># Generate output layer with 14 nodes<br/>model.add(Dense(units=14, activation='linear'))</span><span id="bea8" class="mq mr it mm b gy mx mt l mu mv"># Compile the model<br/>model.compile(optimizer='adam',<br/>              loss='mean_squared_error',<br/>              metrics=['accuracy'])</span></pre><p id="b916" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是无人监督的学习—欺诈标签不包含在培训中:</p><pre class="kj kk kl km gt ml mm mn mo aw mp bi"><span id="36f2" class="mq mr it mm b gy ms mt l mu mv"># Train the model<br/>num_epochs = 10<br/>batch_size = 256</span><span id="2e58" class="mq mr it mm b gy mx mt l mu mv">history = model.fit(x=dataX, y=dataX,<br/>                    epochs=num_epochs,<br/>                    batch_size=batch_size,<br/>                    shuffle=True,<br/>                    validation_data=(dataX, dataX),<br/>                    verbose=1)</span></pre><p id="7497" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该模型在 10 轮中被训练。每次运行后，计算异常分数以测量重建精度。最佳模型被保存。使用精度召回和接收器操作特性来测量准确度。示例培训结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi my"><img src="../Images/2ca9ee85c8908adf194334b86142710d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZXF1c3rHPXDbt3lkZAQKWw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者:安德烈·巴拉诺夫斯基</p></figure><p id="556a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">欺诈检测逻辑在<em class="mw">欺诈检测</em>笔记本中实现。<em class="mw">预测</em>功能在无标签的测试数据上执行。使用异常分数函数计算异常分数。我已经计算了平均异常分数，这将有助于定义区分有效索赔和欺诈索赔的阈值。基于测试数据的计算平均值:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/9ca55af066db048c9722c87a2c60fb52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6_acN_IX4duEXue2hsOVMw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者:安德烈·巴拉诺夫斯基</p></figure><p id="a55e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我将预测标签与实际测试集标签进行比较，这使我们能够通过训练好的模型来衡量欺诈检测的准确性。</p><p id="87f1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">欺诈检测阈值= 0.01 </strong>。</p><p id="3868" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果:</p><ul class=""><li id="e5cd" class="lx ly it lb b lc ld lf lg li lz lm ma lq mb lu mc md me mf bi translated">有效索赔:30 000</li><li id="0867" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">欺诈:286(准确率 95%)</li><li id="c42f" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">未被认定为欺诈的:14</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/6b1687bac87efce94fa8f38d0ac60a67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R-nEYKy-9kDoJOKGMYceAA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者:安德烈·巴拉诺夫斯基</p></figure><p id="b2f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">欺诈检测阈值= 0.005 </strong>(更接近计算平均值 0.003)。</p><p id="7bad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果:</p><ul class=""><li id="d981" class="lx ly it lb b lc ld lf lg li lz lm ma lq mb lu mc md me mf bi translated">有效索赔:29 636</li><li id="00d0" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">欺诈:293(准确率 98%)</li><li id="825d" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">有效识别为欺诈:364</li><li id="4e5b" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">未被认定为欺诈的:7</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/12804aceaa917103ad18fe04050358b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AD1LPsC8_6Pr615Q9pBoxw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者:安德烈·巴拉诺夫斯基</p></figure><p id="91d4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">欺诈检测阈值= 0.003 </strong>(等于计算的平均值 0.003)。</p><p id="b9d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果:</p><ul class=""><li id="5500" class="lx ly it lb b lc ld lf lg li lz lm ma lq mb lu mc md me mf bi translated">有效索赔:26 707</li><li id="238f" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">欺诈:300(准确率 100%)</li><li id="9d61" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">有效识别为欺诈:3293</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/56920e909a3e0286bdae1307c7850c65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zQxBj3vRnX4cQoK7bN1L-A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者:安德烈·巴拉诺夫斯基</p></figure><p id="be48" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">结论</strong></p><p id="9b84" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随着异常分数变小，我们对异常进行更严格的检查。这使我们能够捕捉所有欺诈性索赔，但作为回报，我们会将更多有效索赔标记为欺诈。</p><p id="8101" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从上面的图表中可以看出，识别低价值的欺诈性索赔更加困难。当数量较少时，这是有意义的——更有可能被遗漏。</p><p id="fded" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">源代码</strong> : <a class="ae ky" href="https://github.com/abaranovskis-redsamurai/automation-repo/tree/master/unsupervised" rel="noopener ugc nofollow" target="_blank"> GitHub </a>回购</p></div></div>    
</body>
</html>