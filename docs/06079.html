<html>
<head>
<title>Detecting Masks in Dense Crowds in Real-time with AI and Computer Vision</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用人工智能和计算机视觉实时检测密集人群中的面具</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/detecting-masks-in-dense-crowds-in-real-time-with-ai-and-computer-vision-9e819eb9047e?source=collection_archive---------49-----------------------#2020-05-17">https://towardsdatascience.com/detecting-masks-in-dense-crowds-in-real-time-with-ai-and-computer-vision-9e819eb9047e?source=collection_archive---------49-----------------------#2020-05-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/677735293f8c5b0b8a7595e8d56c6b75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gG6IF9t4tfDbuDpmYZNtRw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">迈向美好未来的一小步</p></figure></div><div class="ab cl kf kg hx kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="im in io ip iq"><p id="2e25" class="pw-post-body-paragraph km kn it ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated">这是从半夜醒来开始的，在极度困难的过程中，由于新冠肺炎·疫情病毒，封锁期很长。</p><p id="6bd7" class="pw-post-body-paragraph km kn it ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated">一个周六的早上5点，我起床去买东西，看到一群人在附近的办公区踢足球。然后我想，为什么我们不能从远处发现谁在不戴面具的情况下走来走去。</p><p id="617b" class="pw-post-body-paragraph km kn it ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated">然后我突然想到，等等……你可以！我可以试试。(有时候你忘了，你自己拥有什么技能。我们大多数人都会这样！😂)我带着兴奋的心情回家，设置好自己的深度学习环境。</p><p id="dcc8" class="pw-post-body-paragraph km kn it ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated">我使用我的版本<a class="ae lk" href="https://pjreddie.com/darknet/" rel="noopener ugc nofollow" target="_blank"> DarkNet </a>运行YOLOv3模型进行场景检测，并快速旋转标准场景检测模型。然后，我开始从不同的公共数据集和存储库中，管理一个由屏蔽和未屏蔽图像组成的数据集。</p><p id="a92a" class="pw-post-body-paragraph km kn it ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated"><a class="ae lk" href="https://pjreddie.com/darknet/" rel="noopener ugc nofollow" target="_blank"> DarkNet </a>的美妙之处在于，一旦你构建了它所有的C二进制文件和绑定，重新训练它最外层的迁移学习就相当容易了。因此，我得到了模型的权重，然后我必须对数据集进行注释，并开始在我的GTX 1060上用<a class="ae lk" href="https://developer.nvidia.com/cuda-downloads" rel="noopener ugc nofollow" target="_blank"> CUDA </a>进行大约10个小时的训练。</p><p id="fc5a" class="pw-post-body-paragraph km kn it ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated">我达到一个点，直到损失为0.02，然后导出生成的权重。</p><figure class="lm ln lo lp gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ll"><img src="../Images/8d01add52d922f2bab8c89cf255dc50f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YyV5VNoSN1y1Gp29xJpoFw.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">对我的网络摄像头拍摄的照片进行第一次测试</p></figure><p id="8ec8" class="pw-post-body-paragraph km kn it ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated">这是第一个结果。</p><p id="87b0" class="pw-post-body-paragraph km kn it ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated">我在几种光照条件下运行它，看到结果在低光照环境下波动，所以我添加了一些<a class="ae lk" href="https://docs.opencv.org/master/d5/daf/tutorial_py_histogram_equalization.html" rel="noopener ugc nofollow" target="_blank">直方图均衡</a>技术。</p><p id="7487" class="pw-post-body-paragraph km kn it ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated">直方图均衡化为现有图像增加并平衡了一定程度的对比度。结果相当好。</p><p id="c409" class="pw-post-body-paragraph km kn it ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated">下一步是通过视频来运行它。现在，在当前的封锁情况下，我无法使用IP摄像头，所以我让我的室友指向并拍摄我(原谅我的短裤😅，这里太热了！)从窗口到街上。</p><figure class="lm ln lo lp gt ju gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/68016db0948efc22d6ec999d5139b3cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*cA58VmNfo-4USDH8wJodgA.gif"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">第二个测试来自我手机拍摄的视频</p></figure><p id="f36c" class="pw-post-body-paragraph km kn it ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated">一旦精度适合我，我意识到我需要更多的性能提升。所以我尝试了不同的方法。我需要优化分配给运行该作业的线程的内存量，以及每个节拍处理的帧的缓存。</p><p id="e330" class="pw-post-body-paragraph km kn it ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated">因此，我没有使用Python脚本来运行这项工作，而是必须整体构建DarkNet的其他模块，并使用<a class="ae lk" href="https://cmake.org/" rel="noopener ugc nofollow" target="_blank"> CMake </a>来构建我的操作系统的C绑定，并将DarkNet添加到我的系统路径变量中。现在，我可以只使用CLI运行推理了😉</p><p id="e116" class="pw-post-body-paragraph km kn it ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated">然后我开始在密集人群的视频上进行测试</p><figure class="lm ln lo lp gt ju gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/82e8534f85c837672c432f03240835a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*C972QFNjuIOk5yrMeRiJkQ.gif"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">使用该模型在视频上运行推理</p></figure><figure class="lm ln lo lp gt ju gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/dc8132846df3b756d47e6c0f1b5413c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*s_Q64RCgs8ws6PgBkN7DMA.gif"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">在印度的人群中取得了惊人的效果</p></figure><p id="eac6" class="pw-post-body-paragraph km kn it ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated">这是YouTube上运行项目演示的最终视频。</p><figure class="lm ln lo lp gt ju"><div class="bz fp l di"><div class="ls lt l"/></div></figure><p id="fedf" class="pw-post-body-paragraph km kn it ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated">我达到了大约40FPS，这对于视频处理来说足够好了。我真的很想运行网络摄像头，但遗憾的是，被隔离并没有给我在我的公寓里太多的空间来大规模测试一些东西。</p><p id="3374" class="pw-post-body-paragraph km kn it ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated">这意味着我们现在可以在IP摄像机、无人机、公共场所的闭路电视和系统网络摄像头上运行这一功能。</p><p id="df17" class="pw-post-body-paragraph km kn it ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated">理想的情况是将它部署在数据中心GPU上，如Nvidia 2020主题演讲中宣布的新<a class="ae lk" href="https://www.nvidia.com/en-in/data-center/v100/" rel="noopener ugc nofollow" target="_blank"> Nvidia V100 </a>，以获得惊人的性能和大规模的结果。</p><p id="f1ea" class="pw-post-body-paragraph km kn it ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated">如果我们只是发现问题，我们可以建立很多东西，我觉得大多数问题只是每天出现。我们只需要在这方面有所创新。</p><p id="9a00" class="pw-post-body-paragraph km kn it ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj im bi translated">#住宿之家#住宿安全</p></div></div>    
</body>
</html>