# 在 R 中使用梯度推进机器进行分类

> 原文：<https://towardsdatascience.com/using-gradient-boosting-machines-for-classification-in-r-b22b2f8ec1f1?source=collection_archive---------30----------------------->

## 机器学习中的分类方法

# 背景

**分析目的:**

了解推动学生成功的因素，以便开放大学能够分配资源来提高学生的成功

**数据集描述:**

开放大学学习分析数据集是一个公开可用的数据集，包含七个选定课程(模块)的课程、学生及其与 VLE 互动的数据。

由于所有数据表的唯一标识符是学生 ID、模块和课程描述，因此数据在这一级进行聚合。分析中使用了以下变量:

**变量名称变量类型变量名称变量类型**id _ 学生唯一标识符/主键 id 段分类代码 _ 模块分类段分类代码 _ 演示分类前一次尝试的次数数字学习者分类学分分类区域分类残疾分类最高教育分类最终结果数字总和加权分数数字平均模块长度数字平均提交持续时间数字平均比例内容访问数字平均日期注册数字修整评估类型分类

# 方法学

# 数据转换

*   基于唯一标识符(学生 ID、课程和代码描述)组合数据集
*   在唯一标识符级别聚合变量
*   将名义变量类型从字符更新为因子

**预测值:**

*   代码模块
*   代码呈现(更改为 1 = B 和 2 = J)，
*   性别、地区、最高教育程度、IMD 级别、年龄级别、先前尝试次数、学习学分、
*   平均提交持续时间(平均为单个代码演示可以有多个提交持续时间不同的评估)，
*   平均模块长度，
*   被访问内容的平均比例(基于“ou”内容和资源/测验/词汇表的总点击数除以每个代码描述的总点击数)，
*   平均注册日期和
*   修剪评估类型(因为一个代码描述可以有多个评估和多个相同类型的评估。确定每门课程的评估类型和描述是否能推动学生取得成功是很重要的)

*排除变量:学号和加权总分*

*排除原因:学号——识别信息，加权分数总和——与最终结果相关*

**定义“成功”目标变量**

*   响应变量:成功(“通过”或“区别”=“是”、“失败”或“撤回”=“否”

*不使用“最终结果”作为成功因素的原因:数据集中有不成比例的“通过”记录，因此降低了预测“失败”、“撤回”和“区别”的模型准确性。因此，响应变量是二进制的。*

*   *检查将输入模型的每个变量的空值、缺失值和异常值*

> 为什么我们要检查丢失的数据？—如果大部分数据缺失/为空，样本的代表性不足以提供准确的结果。当缺失/空数据由于有效原因而缺失时，情况并非如此。

# 数据设置

将数据分为名义预测值和二元预测值的训练集和测试集，以测试模型的准确性

> 为什么我们要将数据分为训练集和测试集—模型是在训练集上训练的。在测试集上测试模型的准确性，以确定模型在预测它没有“看到”的数据的成功与否方面的能力。

# 数据建模

*   **分析方法:**梯度推进机(GBM)
*   也可以使用其他方法，但模型精度足够好——分布式随机森林(DRF)和广义线性模型(GLMNET)
*   使用混淆矩阵(即正确预测的比例)和曲线下面积(与随机机会相比，我们做得有多好)检查**模型的准确性**。

# 输出

*   最佳预测值(按可变重要性分数)

# 数据 ETL

所有数据探索、转换和最终数据集的加载都在 Alteryx 中完成，以避免编写代码并测试其基本数据转换步骤的功能，这些步骤通常在 R 中执行，如 joins、mutate 和 group by。

首先，我通过 ID 评估(主键)连接了三个数据集— assessments.csv、studentAssessments.csv 和 courses.csv。

接下来，我设计了两个特性:加权分数和提交持续时间。日期通常没有意义，除非它们被转换成有用的特征。课程描述只有两个类别，为了便于参考，我将其转换为 1 和 2。

![](img/558c4010c853b853f783a6dfbac1afbd.png)

下一步是添加学生与虚拟学习平台(VLE)互动的数据。为了便于分析，进行了一些功能工程，例如创建一个名为 activity_type_sum 的新变量，将活动类型中的类别数量减少为两大类——内容访问和浏览。这样做的原因是粒度类别只会产生更多的特征，并减少每个类别的观察数量。点击次数由活动类型特征相加。还计算了与浏览和内容访问相关的活动占总活动的比例。这是创建与另一个要素相关并按总活动比例缩放的要素的好方法，从而确保所有学生都按其活动类型以相似的比例表示。

![](img/941b6723c1be9e2fd4729e558fba52e0.png)

使用 student_id、code_module 和 code_presentation 作为主键将块 1 连接到块 2。结果输出如下所示。

![](img/687d1d77c48cb41740f3339e66b6aaf5.png)

上面的输出(块 3)使用 student_id、code_module 和 code_presentation 将学生注册数据连接起来，以显示 data_registered 字段。

*date_unregistered* 字段被忽略，因为它有许多缺失值。此外，未注册字段单元格为空的学生将*撤回*作为其*最终结果*的值。这个变量是我们的*目标/响应*变量。因此， *date_unregistered* 字段似乎是 final_result 的代理度量，因此从我们的分析中排除该变量是有意义的。

![](img/71d036344735d0b6e0206a9d40099639.png)

如上图，对于给定的 id_student、code_module、code_presentation，重复 module_presentation length、proportion_content、date_registration。由于我们希望拥有唯一的记录，我们可以将数据汇总如下:

*   使用总和总结加权分数
*   平均提交持续时间
*   平均模块呈现(您也可以使用其他聚合，如最小值、最大值和中值)
*   比例 _ 内容 _ 访问的平均值
*   平均日期 _ 注册

数据现在处于学生标识、代码模块、代码演示和评估类型级别；但是，目标变量—最终结果—处于学生标识、代码模块和代码演示级别。因此，需要进一步汇总这些数据。

先看学生信息。这里的唯一记录是 id_student、code_module、code_presentation。
因此，我们需要后退一步，总结出一个 student_id、code_module 和 code_presentation 来代表个人进行的所有评估。我们仍将使用之前的汇总公式。

![](img/fb023b3fe10fd4fae32d57bd464ff8ef.png)

通过这样做，我们有 8 种独特的评估类型，学生可以针对给定的代码模块和代码演示进行评估。评估类型不重复(仅微调)，因此如果学生参加了 3 次 TMA，则不会反映出来，如下所示。

![](img/08c9740d534943053e5076dba72b2d89.png)

可以创建一个变量来计算每种评估类型的评估数量，但它会包含许多缺失值，因为并非所有评估都具有所有三种评估类型。
现在，我们准备好加入学生信息数据，输出如下所示。

![](img/bbce6214e5c77ff68c1742244334b1e4.png)

现在，我们有 18 列。
我们被告知，如果在二月和十月进行演示，演示可能会有所不同。我们将假设每年没有不同(即 2013 年 b 与 2014 年 b 相同)。因此，我们将把 code_presentation 作为二进制变量重新编码为 1 代表 B，2 代表 J。

最终输出如下所示。

![](img/f09d22b8543314f2aa109acd90725feb.png)

终于到了一些数据探索的时候了。

# 探索性数据分析

分类变量可以用条形图表示，其中 y 轴是给定类别出现的频率。例如，在下面的图表中，我们可以看到最常使用的代码模块是 *FFF* ，其次是 *BBB。*有七个唯一的代码模块，没有缺失值。

![](img/ca37c5269e43ff19423bd9788b66925a.png)

对于连续变量，可以使用五点汇总法，对于分类变量，可以使用模式进行数字汇总，如下所示。

从下面的总结中我们可以看出，更常见的学生是苏格兰男性学生，他们没有残疾，Imd_band 在 20%到 40%之间，最终结果是典型的及格。

![](img/1d74cc58f2466a1d99f032b417a7399a.png)

现在，我们可以开始对数据集建模了。

# 机器学习模型

我们被要求帮助开放大学更好地理解学生的成功。我们将假设学生的成功是通过最终结果来衡量的，其中通过和优秀是“成功”的指标，撤回和失败是“不成功”的指标。
对于独立变量，我们将使用之前表格中的所有变量，除了 weighted_score。这是因为加权分数决定了给定学生的最终成绩。因此，它与最终结果高度相关(多重共线性),因此将被排除。
学生证是识别信息，因此不会被用作预测因素。

*GBM(梯度增强模型)*被用作选择的模型。这种类型的模型创建了一系列弱学习器(浅树),其中每个新树都试图提高前一个树的错误率。最终的树是具有最低错误率的树。这是一种集成机器学习方法，因为创建了几棵树来提供最终结果。然而，不像在 *randomForest* 中，这些树是串行创建的，而不是并行创建的。此外，这些树不是独立的，而是依赖于前一个树的错误率，而后面的三个树将更努力地改善对更困难情况的预测。这是由一个称为学习率的参数控制的。

该模型运行了 500 轮(500 棵树)，树的最小和最大深度为 4。通常，拥有非常深的树并不好，因为这会导致算法试图解释数据集中的每个观察值的过度拟合，因为它增加了树的深度，导致叶子包含非常少量的符合给定规则的观察值。

![](img/e82477f66f3a61ab00bb5d782dc9449a.png)

我们可以从上面的输出中看到，该模型的 RMSE(均方根误差)值为 0.55，这是相当高的。它特别不擅长预测*区分*和*失败*，这可能是由于数据集的不平衡，从我们的探索性数据分析中我们知道*通过*是最常见的最终结果。

为了解决这一不平衡问题，目标变量被重新定义为“成功”(优秀和及格)和“失败”(不及格和退出)。组合类别来处理不平衡数据集是很常见的。其他方法是欠采样(即减少最频繁类的实例数量)或过采样(即为非频繁类创建人工观察)。

模型重新运行，输出如下。在这里，我们可以看到平均每类误差显著下降。曲线下面积(AUC)是另一个准确性指标，它告诉您模型在正确分类病例方面有多好(即最大化真实阳性率(TPR))。AUC 越高，模型越精确。因为 AUC 是在 0 和 1 之间测量的，所以 0.87 的 AUC 是相当好的。

分类问题中常用的另一个度量是 F1 分数，它是精确度和召回率的调和平均值。这两个指标都旨在最大化 TPR，同时最小化假阴性率(召回率)或假阳性率(精确度)。真正的肯定是成功或失败被正确分类。一个*假阴性*是成功被贴上失败的标签。一个*假阳性*是当一个失败被贴上成功的标签。F1 分数要高，精度和召回率都要高。

混淆矩阵表明总错误率为 17.11%，这主要是由模型在成功分类方面的良好程度决定的。该模型不太擅长对故障进行分类，错误率为 39.07%。同样，这可能是由于“遍数”过多地代表了数据。因此，应谨慎对待结果，并使用更平衡的数据集重新运行模型。

![](img/9a61b3b95e3fb0e8b9dede5c41cd54a8.png)![](img/c2dd7a2d2ff73b7ac3580e084fa89726.png)

现在，让我们通过查看*变量重要性列表来看看成功或失败的主要预测因素。*

*   前 3 个变量是代码模块、trimmed_assessment_type 和平均提交持续时间。
*   预测给定学生是否会取得成功的最后 3 个变量是残疾状况、平均注册日期和性别。
*   *注意:由于代码模块和代码表示是唯一标识符的一部分，它们应该被排除在分析之外。然而，由于一些课程在二月和十月的介绍可能不同，两个变量都保留在模型中。排除这些变量可能会提高准确性或使其他变量变得更“重要”。*

![](img/a7184c28f5a0b91a7dc9d62189b5dd72.png)

现在，让我们来看看最重要的预测信息，以便更好地理解这个模型。下面的堆积条形图显示了课程模块和 final_result 的记录比例。我们可以推断，与其他课程相比，学生更有可能成功完成 AAA、EEE 和 GGG 课程。

![](img/c786a14e3d4a417703248c37024f3729.png)![](img/368ba5b175d23d4cdc5d1155977650e7.png)

*   从上表中，我们可以看到，如果考试是给定课程和演示文稿的唯一评估，那么成功率是 100%。
*   如果只有计算机标记的评估构成了课程的组成部分，那么不及格率和退学率就非常高。调查为什么将 CMA 作为演示评估的一部分会导致成功率下降是很有趣的。

![](img/f6c78f01773ed39dec70c4224ad51beb.png)

上面的直方图显示了成功和失败的平均提交持续时间。

似乎当学生成功时，他们更有可能在评估提交日期后的 10 天(+/-)内提交作业。

# 包扎

机器学习被用来快速识别学生成功的主要因素。

模型改进的建议包括:

*   使用平衡数据集
*   包括数据集中资源分配的替代措施
*   按课程类型统计评估数量，并作为
    功能进行演示
*   删除相互关联的分类变量(即使用卡方独立性检验)

希望您现在对利用 GBM 解决分类问题、分类问题的缺陷(即不平衡数据集)以及各种准确性指标的使用有了更好的理解。

我的 git 资源库中提供了所有 R 代码的参考:[https://github.com/shedoesdatascience/openlearning](https://github.com/shedoesdatascience/openlearning)