<html>
<head>
<title>A taste of ACL2020: 6 new Datasets &amp; Benchmarks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">体验 ACL2020: 6 个新数据集和基准</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-taste-of-acl2020-6-new-datasets-benchmarks-4f5584f3f0ba?source=collection_archive---------34-----------------------#2020-07-04">https://towardsdatascience.com/a-taste-of-acl2020-6-new-datasets-benchmarks-4f5584f3f0ba?source=collection_archive---------34-----------------------#2020-07-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ddc5" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">计算语言学协会今年的会议挤满了 700 多份出版物。为了让你更容易地浏览，这里有一个新的刷新数据集和语言任务基准的论文选择。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/ae4757337f1b42638803b810d1a144c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QDI0IJnJAs894C-U"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/@phoebezzf?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">周</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="b076" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">数据集和基准是自然语言理解进展的核心(NLU) </strong>:在排行榜驱动的研究中，进展受到我们评估的<em class="ls">质量</em>的上限。虽然机器学习的数据集曾经持续很久——即 MNIST 在推出十多年后才达到人类的表现——但最新的自然语言理解基准变得过时的速度比我们预期的还要快，这凸显了找到更好的基准的重要性。</p><p id="61a5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">关于这个主题的论文数量之多令人震惊，因此在<a class="ae kv" href="https://www.zeta-alpha.com" rel="noopener ugc nofollow" target="_blank"> Zeta-Alpha </a>上，我们精选了 ACL2020 上最有趣的作品，这些作品<strong class="ky ir">将影响如何衡量该领域的进展</strong>。</p><h2 id="bedf" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lf mc md me lj mf mg mh ln mi mj mk ml bi translated"><a class="ae kv" href="https://www.aclweb.org/anthology/2020.acl-main.441/" rel="noopener ugc nofollow" target="_blank"> 1。对抗性 NLI:自然语言理解的新基准</a></h2><p id="5bc8" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">在这篇论文中——已经引起了+20 次引用——作者雄辩地说明了<strong class="ky ir">为什么静态 NLU 基准很快就过时了</strong>并且模型经常利用在数据收集阶段检测不到的虚假统计模式。</p><p id="8311" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">他们引入了自然语言推理的数据集(NLI)，其中给定了前提和本质，人们应该确定它们是必然的，矛盾的还是中性的。问题是，他们还引入了一个框架，根据来自训练模型的反馈对数据集进行迭代，并且人类在循环中引入了对立的例子；目的是在模型失败的地方创建数据集。如下图所示，注释的<em class="ls">圆</em>包括:</p><ul class=""><li id="2fd8" class="mr ms iq ky b kz la lc ld lf mt lj mu ln mv lr mw mx my mz bi translated">注释数据集并在其上训练模型。</li><li id="aa0b" class="mr ms iq ky b kz na lc nb lf nc lj nd ln ne lr mw mx my mz bi translated">让注释者在给定的上下文中编写新的对抗性假设，并在训练好的模型上测试它们。</li><li id="7020" class="mr ms iq ky b kz na lc nb lf nc lj nd ln ne lr mw mx my mz bi translated">如果模型成功，我们将新样本添加到训练集中。</li><li id="9a9b" class="mr ms iq ky b kz na lc nb lf nc lj nd ln ne lr mw mx my mz bi translated">当模型失败并且另一个人同意注释时，我们将他们添加到开发、测试或训练集中。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/551a4fd660471706fa55e762ddc8f79f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*veDlZtg60SR_vakbllY8Dg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">对抗性人在回路数据收集图。来源:<a class="ae kv" href="https://www.aclweb.org/anthology/2020.acl-main.441/" rel="noopener ugc nofollow" target="_blank">对抗性的 NLI:自然语言理解的新基准</a></p></figure><p id="f2cd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作者将这一过程称为 HAMLET ( <em class="ls">人和模型在回路中启用的培训</em>)，在论文中，他们展示了 3 轮数据集的创建，其中注释者受到激励，提出模型将失败的假设。这导致<strong class="ky ir">的数据集</strong>越来越具有挑战性，并且作为副作用，他们在 MNLI 数据集的一些变体上达到了最先进的水平。虽然他们推测，由于其收集方式，该基准不会很快饱和，但他们强调，即使如此，仍可以增加新的回合来克服这一点。</p><p id="9f3d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">动态数据集的主要不便之处在于标准化的困难，这使得不同作品的比较成为可能。虽然<strong class="ky ir">对抗性的人在回路中并不是一个新的想法</strong>，但这个干净的实例有可能成为未来迭代的灵感，并可能克服标准化的障碍，在不久的将来，动态数据集将成为规范。</p><h2 id="de3d" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lf mc md me lj mf mg mh ln mi mj mk ml bi translated"><a class="ae kv" href="https://www.aclweb.org/anthology/2020.acl-main.408/" rel="noopener ugc nofollow" target="_blank"> 2。橡皮擦:评估合理化 NLP 模型的基准</a></h2><p id="3c23" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">本文介绍了一个由 7 个任务组成的成熟的语言基准，这些任务不仅包括标签，而且受<a class="ae kv" href="https://gluebenchmark.com" rel="noopener ugc nofollow" target="_blank"> GLUE 基准</a>成功的启发，还有<strong class="ky ir">人类注释的“基本原理”</strong>。这些任务包括:<a class="ae kv" href="https://www.aclweb.org/anthology/N19-1371.pdf" rel="noopener ugc nofollow" target="_blank">证据推理</a>、<a class="ae kv" href="https://arxiv.org/pdf/1905.10044.pdf" rel="noopener ugc nofollow" target="_blank"> BoolQ </a>(布尔 QA)<a class="ae kv" href="https://www.aclweb.org/anthology/D08-1004.pdf" rel="noopener ugc nofollow" target="_blank">影评</a>、<a class="ae kv" href="https://www.aclweb.org/anthology/N18-1074.pdf" rel="noopener ugc nofollow" target="_blank">发烧</a>(事实提取验证)<a class="ae kv" href="https://cogcomp.seas.upenn.edu/papers/2018-MultiRC-NAACL.pdf" rel="noopener ugc nofollow" target="_blank"> MultiRC </a>(阅读理解)<a class="ae kv" href="https://www.aclweb.org/anthology/P19-1487.pdf" rel="noopener ugc nofollow" target="_blank">常识解释</a>(CoS-E)<a class="ae kv" href="https://arxiv.org/pdf/1812.01193.pdf" rel="noopener ugc nofollow" target="_blank">E-SNLI</a>(语言蕴涵)<em class="ls">人情约定</em>。</p><p id="efe1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作者提出了一个精确-召回曲线度量下的区域，用于评估模型和人类注释推理的符合性，但是他们知道这种评估很难客观地进行，这就是为什么他们明确地呼吁在这个方向上进行更多的研究。</p><p id="3e7c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个被提议的基准测试是迈向一个更具解释力的语言模型综合评估的宏伟愿景的第一步。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/3a697b76852dcb43778b736f8a5518b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CZ-ZaFkbTii5hch5iEBB8A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">擦除基准中的任务示例。来源:<a class="ae kv" href="https://www.aclweb.org/anthology/2020.acl-main.408.pdf" rel="noopener ugc nofollow" target="_blank"> ERASER:评估合理化 NLP 模型的基准</a></p></figure><h2 id="2419" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lf mc md me lj mf mg mh ln mi mj mk ml bi translated"><a class="ae kv" href="https://www.aclweb.org/anthology/2020.acl-main.372/" rel="noopener ugc nofollow" target="_blank"> 3。GoEmotions:一个细粒度情感的数据集</a></h2><p id="6f69" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">情感分析长期以来一直是 NLP 中的一项基本任务，但一些最广泛使用的数据集(如具有二元积极/消极情感的 SST2)正在超越人类表现，对于衡量有意义的进展来说已经过时。</p><p id="ec88" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">GoEmotions 是一个数据集，由来自流行英语 subreddit 评论的 58k 个人工注释样本组成，它<strong class="ky ir">非常细粒度，有 27 个情感标签(或中性标签)</strong>。数据收集过程坚持高标准，进行全面的人工审查、长度过滤、情感平衡、子编辑平衡以及屏蔽专有名称和宗教术语。伯特模型的早期基线测试表明，还有很大的改进空间，当前最先进的 NLU 模型未能在这一程度上理解情绪，使其成为一个具有挑战性的新情绪基准。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/935695f9d9cd020132cc5ea9fc089203.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JPZHCDvT_lh9LFDkWlggLQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">GoEmotions 数据集的类统计数据，以及情绪相关性的热图及其对粗糙情绪(积极、消极和模糊)的聚类。来源:<a class="ae kv" href="https://www.aclweb.org/anthology/2020.acl-main.372.pdf" rel="noopener ugc nofollow" target="_blank"> GoEmotions:一个细粒度情感的数据集</a></p></figure><p id="62b5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这种类型的数据集在这个时代非常有价值，可以帮助我们理解互联网上复杂的大规模社会动态。</p><p id="e8f3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">类似地，也是在 ACL2020 上，<a class="ae kv" href="https://www.aclweb.org/anthology/2020.acl-main.118.pdf" rel="noopener ugc nofollow" target="_blank"> iSarcasm:一个有意讽刺的数据集</a>，是一个专注于有意讽刺和感知讽刺之间的<strong class="ky ir">区别的数据集</strong>，这样我们就可以克服当前模型只检测更明显形式的偏见。该数据集规模较小，只有 4.4k 个样本，也强调了该主题作为理解社交媒体背景下的社交互动的一种手段的重要性。</p><h2 id="188f" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lf mc md me lj mf mg mh ln mi mj mk ml bi translated"><a class="ae kv" href="https://www.aclweb.org/anthology/2020.acl-main.502/" rel="noopener ugc nofollow" target="_blank"> 4。SCDE:含有高质量考试干扰项的句子完形填空数据集</a></h2><p id="a028" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">句子完形填空任务包括从一组候选词中填充句子大小的空白。类似的句子级任务经常被用作语言模型预训练的自我监督(即 BERT 的下一句预测)；然而，这项任务通常<em class="ls">过于简单</em>，因为它可以依赖虚假的句子模式，因为自我监督的候选句子不够有挑战性。</p><p id="950f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这项工作中，他们引入了<strong class="ky ir">干扰句</strong>，这是由英语教师设计的人类策划的句子，这些句子<strong class="ky ir">需要语言的非本地语篇层面</strong>才能成功完成任务。目前的模型只能达到 72%的准确率，而人类可以达到 87%左右，这表明还有相当大的改进空间。</p><h2 id="67c2" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lf mc md me lj mf mg mh ln mi mj mk ml bi translated"><a class="ae kv" href="https://www.aclweb.org/anthology/2020.acl-main.425/" rel="noopener ugc nofollow" target="_blank"> 5。死亡杀死了猫或者:BabelPic，一个非具体概念的多模态数据集</a></h2><p id="b5b5" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">人类不会孤立地学习语言，那么我们应该期待机器会这样做吗？多模态机器学习探索了利用不同模式的数据，如视觉和语言，来制作更好的世界模型的想法。</p><blockquote class="ni nj nk"><p id="ebd3" class="kw kx ls ky b kz la jr lb lc ld ju le nl lg lh li nm lk ll lm nn lo lp lq lr ij bi translated">“[……]语言理解系统应该能够对描绘<strong class="ky ir">隐退</strong>和<strong class="ky ir">悔恨</strong>的图像进行分类，而不仅仅是<strong class="ky ir">猫</strong>、<strong class="ky ir">狗</strong>和<strong class="ky ir">桥</strong>。”</p></blockquote><p id="7c35" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在对大多数当前多模态视觉和语言数据集进行这种挑衅性的描述后，这项工作建立了关注非具体概念的<a class="ae kv" href="http://www.babelpic.org" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir"/></a><strong class="ky ir">数据集，作为扩大多模态语义理解覆盖范围的一步。该数据集是通过结合 WordNet 和 BabelNet 词汇知识库建立的。</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/4f815f8404ddef1d9e9d6791be443552.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jf7AQoEDGR9AX_7qf-7_4Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">巴贝皮克的非混凝土样本。来源:<a class="ae kv" href="https://www.aclweb.org/anthology/2020.acl-main.425.pdf" rel="noopener ugc nofollow" target="_blank">死亡杀死了猫或:BabelPic，一个非具体概念的多模态数据集</a></p></figure><p id="a7bd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">经过许多过滤技巧、试探法和手动验证后，最终的“黄金”数据集具有 2.7k <em class="ls">同义词集</em>(同义词集)和 15k 匹配图像，以及由视觉语言模型通过使用 WordNet 中的自然语言定义生成的具有 10k <em class="ls">同义词集</em>的扩展“白银”集。</p><h2 id="c943" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lf mc md me lj mf mg mh ln mi mj mk ml bi translated"><a class="ae kv" href="https://www.aclweb.org/anthology/2020.acl-main.602/" rel="noopener ugc nofollow" target="_blank"> 6。R4C:评估 RC 系统的基准，以便为正确的原因获得正确的答案</a></h2><p id="1bda" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">同样，正如对抗性的 NLI 指出的，许多阅读理解任务依赖于现有数据集中的注释工件和其他偏见，使得任务的完成不需要任何<em class="ls">理解</em>。为了减轻这一点，井上直也等人。艾尔提出了一个任务，不仅要求在阅读理解任务中找到正确答案，而且<strong class="ky ir">还要求提供足够的支持事实</strong>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi np"><img src="../Images/f153b06cd104c43460cc43cb446e5e80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vvi-ZyxYX5v-zJPs2grgtg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">包括基本原理的问答示例，其中示例来自 HotpotQA⁶.来源:<a class="ae kv" href="https://www.aclweb.org/anthology/2020.acl-main.602.pdf" rel="noopener ugc nofollow" target="_blank"> R4C:一个评估 RC 系统的基准，为了正确的理由得到正确的答案</a> &amp; HotpotQA⁴</p></figure><p id="3dba" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">得到的带注释的数据集是总共 7.1k 个训练样本和 6.6k 个开发样本，它们是从 HotpotQA⁴数据集采样的，其中每个答案的理由都包含在注释中。这项任务的评估包括对答案打分和评估“基本原理与地面事实的一致性”的正确性。</p></div><div class="ab cl nq nr hu ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="ij ik il im in"><p id="9690" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然<strong class="ky ir">这绝不是今年 ACL 中首次亮相的数据集和基准的全面列表</strong>，但它是一个有代表性的样本，显示了会议是如何挤满了贡献。在<a class="ae kv" href="https://twitter.com/ZetaVector" rel="noopener ugc nofollow" target="_blank"> @zetavector </a>的团队将会关注会议，并从我们的 twitter feed 中报告见解，所以请不要错过任何事情！</p></div><div class="ab cl nq nr hu ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="ij ik il im in"><h2 id="8278" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lf mc md me lj mf mg mh ln mi mj mk ml bi translated">参考</h2><ol class=""><li id="98b5" class="mr ms iq ky b kz mm lc mn lf nx lj ny ln nz lr oa mx my mz bi translated"><a class="ae kv" href="https://www.aclweb.org/anthology/N18-2017.pdf" rel="noopener ugc nofollow" target="_blank">自然语言推理数据中的标注工件</a>。Suchin Gururangan，Swabha Swayamdipta et。al 2017。</li><li id="d3a0" class="mr ms iq ky b kz na lc nb lf nc lj nd ln ne lr oa mx my mz bi translated">WordNet:一个英语词汇数据库。乔治·米勒 1995。</li><li id="9658" class="mr ms iq ky b kz na lc nb lf nc lj nd ln ne lr oa mx my mz bi translated"><a class="ae kv" href="https://www.sciencedirect.com/science/article/pii/S0004370212000793?via%3Dihub" rel="noopener ugc nofollow" target="_blank"> BabelNet:一个广覆盖多语言语义网络的自动构建、评估和应用</a>。RobertoNavigli，Simone Paolo Ponzetto，2012 年。</li><li id="1ed0" class="mr ms iq ky b kz na lc nb lf nc lj nd ln ne lr oa mx my mz bi translated"><a class="ae kv" href="https://arxiv.org/pdf/1809.09600.pdf" rel="noopener ugc nofollow" target="_blank"> HOTPOTQA:一个多样化的、可解释的多跳问答数据集</a>。杨，彭琪，张赛正等。al 2018。</li></ol></div></div>    
</body>
</html>