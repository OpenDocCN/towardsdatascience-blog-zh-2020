<html>
<head>
<title>How Injecting Randomness Can Improve Model Accuracy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">注入随机性如何提高模型精度</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-injecting-randomness-can-improve-model-accuracy-11cdc04b3eeb?source=collection_archive---------49-----------------------#2020-06-13">https://towardsdatascience.com/how-injecting-randomness-can-improve-model-accuracy-11cdc04b3eeb?source=collection_archive---------49-----------------------#2020-06-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/d86ceab74dba09b2dead62f1227a6a18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wh6Ko_UkC3XNFTC2"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://unsplash.com/photos/m4sGYaHYN5o" rel="noopener ugc nofollow" target="_blank">来源</a>。图片免费分享。</p></figure><div class=""/><div class=""><h2 id="8a07" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">自举聚合的魔力</h2></div><p id="16d2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">装袋，或者说<strong class="la jk"> b </strong> ootstrap <strong class="la jk"> ag </strong>种族隔离，是机器学习中的一个独特想法。这个概念假设，在不增加任何新数据或知识的情况下，人们仍然可以简单地通过增加随机因素来提高模型的准确性。这个想法是训练一个模型集合，其中每个模型都根据数据的子集进行训练，然后汇总每个模型的预测。</p><p id="84dd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因为每个模型都是在随机选择的大多数数据子集(通常在 60%到 75%之间)上训练的，所以数据中显然会有明显的重叠。然而，根据这个简单的想法，像 Random Forest 这样的 bagging 模型几乎普遍比它们的非 bagging 模型表现得更好，在这种情况下就是决策树。然而，没有添加数据——现有数据只是简单地结合了随机性——那么简单的装袋概念怎么会导致模型性能如此之高呢？</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lu"><img src="../Images/ae8654e9807e3ecc56b6798340612c3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ijq95LVNbixY6os6uvpblQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者创建的图像。</p></figure><p id="5c0e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">首先，重要的是要对装袋减少方差这一事实有一个直观的理解。虽然在少数情况下这不是真的，但一般来说这是真的。作为一个例子，看看从<em class="lz"> x </em>的正弦波-值 0 到 20，随机噪声来自正态分布。显然，这是非常嘈杂的数据，像决策树这样的高方差算法可能会陷入高度的随机性中，因此泛化能力很差。</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ma"><img src="../Images/f97ce5b3e51f7bda288e43c21c076f8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DILvylrzBafgzzmkhT9Xsw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者创建的图像。</p></figure><p id="e7f8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">另一方面，考虑一个袋装模型。为了产生这种可视化，绘制了十条独立的曲线，每条曲线包含随机选择的百分之二十的原始数据。然后将这些点相对于其周围点的值进行平均，以形成“袋装”曲线，这大大降低了方差和噪声。</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mb"><img src="../Images/b227754fcb1ab7e1da53c3e01de6ef20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tdV-c3RV_56UI9WwGvMdHA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者创建的图像。</p></figure><p id="49e4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">显而易见的是，由于随机性，自举人为地“消除”了巨大的差异。当随机性加入到系统中时，正随机性和负随机性相互抵消。通过数据的重复重叠，高方差被剔除，更清晰的关系被支持和揭示。</p><p id="fec9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">由于模型的均方误差(MSE)等于<em class="lz"> v </em> + <em class="lz"> b </em>，其中<em class="lz"> v </em>代表方差，<em class="lz"> b </em>代表偏差，自然，如果方差降低，MSE 也会降低。在某些情况下，当方差降低时，偏差会增加。由于 MSE 权重的计算是偏差的平方，而方差只是偏差本身，在这种情况下，装袋实际上会降低性能。</p><p id="9dd5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然而，在大多数情况下，减少方差而不相应增加偏差是可能的。这可以用正弦波的例子来说明，其中方差减小了，但是关系只是变得更清楚，而不是变得更有偏差。</p><p id="758e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">尽管对装袋成功的方差减少的解释是直观的并且被广泛相信，但是它还没有被经验证明是尽可能准确的。bootstrap aggregating 成功的另一个解释是，打包等于影响力。这个想法的中心概念围绕着<em class="lz">杠杆</em>的想法，这是一个点对模型有多大影响的度量。因此，高杠杆点的存在会显著影响模型，例如，异常值对线性回归系数的影响。</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mc"><img src="../Images/ec0a6c4f059d996fcab0a3de3706158b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6cYjMdRBKe6c5tCOlwexmg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.40.1298" rel="noopener ugc nofollow" target="_blank">来源</a>。图片免费分享。</p></figure><p id="98e5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如虚线回归所示，不良的杠杆会使模型发生负向倾斜，而良好的杠杆可以稳定该线。不良杠杆的问题是，即使一条线不适合大多数点，指标也会因为不良杠杆的影响而改善。</p><p id="250d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在大多数情况下，杠杆有一个坏的影响，衰减杠杆可能会减少模型中不必要的方差。一个不稳定的估计值可以被定义为一个预测值，其中有许多非常有影响力的点，而自举具有降低整体杠杆的效果。当大多数杠杆点都有负面影响时，这是积极的。在某些情况下，已经表明装袋可以提高性能，即使在数学上方差没有减少的情况下，当大多数杠杆点对性能为正时也是如此。</p><p id="a196" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，差异只是降低杠杆的下游效应。Bagging 工作得如此之好，是因为它通常通过增加随机性来减少影响，这是用正弦波观察到的。这也是为什么在杠杆点普遍影响不大的情况下，装袋表现不佳的原因。这是一个强大的概念，主要应用于基于树的方法，因为它们往往有许多 bagging 试图减少的高影响力的杠杆点。在许多方面，bagging 解决了树方法的记忆和过拟合问题，同时保留了它的许多优点。</p></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h1 id="c03b" class="mk ml jj bd mm mn mo mp mq mr ms mt mu kp mv kq mw ks mx kt my kv mz kw na nb bi translated">如果你喜欢，</h1><p id="d608" class="pw-post-body-paragraph ky kz jj la b lb nc kk ld le nd kn lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">你可能会喜欢我的其他一些机器学习文章。</p><div class="is it gp gr iu nh"><a href="https://medium.com/swlh/real-artificial-intelligence-understanding-extrapolation-vs-generalization-b8e8dcf5fd4b" rel="noopener follow" target="_blank"><div class="ni ab fo"><div class="nj ab nk cl cj nl"><h2 class="bd jk gy z fp nm fr fs nn fu fw ji bi translated">真正的人工智能:理解外推 vs 概括</h2><div class="no l"><h3 class="bd b gy z fp nm fr fs nn fu fw dk translated">机器学习模型不需要智能，它们的大多数应用都需要执行任务，如…</h3></div><div class="np l"><p class="bd b dl z fp nm fr fs nn fu fw dk translated">medium.com</p></div></div><div class="nq l"><div class="nr l ns nt nu nq nv ja nh"/></div></div></a></div><div class="is it gp gr iu nh"><a href="https://medium.com/analytics-vidhya/gans-for-everyone-an-intuitive-explanation-of-the-revolutionary-concept-2f962c858b95" rel="noopener follow" target="_blank"><div class="ni ab fo"><div class="nj ab nk cl cj nl"><h2 class="bd jk gy z fp nm fr fs nn fu fw ji bi translated">每个人的 GANs</h2><div class="no l"><h3 class="bd b gy z fp nm fr fs nn fu fw dk translated">革命性人工智能概念的直观解释</h3></div><div class="np l"><p class="bd b dl z fp nm fr fs nn fu fw dk translated">medium.com</p></div></div><div class="nq l"><div class="nw l ns nt nu nq nv ja nh"/></div></div></a></div><div class="is it gp gr iu nh"><a href="https://medium.com/analytics-vidhya/batch-normalization-the-greatest-breakthrough-in-deep-learning-77e64909d81d" rel="noopener follow" target="_blank"><div class="ni ab fo"><div class="nj ab nk cl cj nl"><h2 class="bd jk gy z fp nm fr fs nn fu fw ji bi translated">批量规范化:深度学习的最大突破</h2><div class="no l"><h3 class="bd b gy z fp nm fr fs nn fu fw dk translated">它是如何工作的——又是如何如此有效的？</h3></div><div class="np l"><p class="bd b dl z fp nm fr fs nn fu fw dk translated">medium.com</p></div></div><div class="nq l"><div class="nx l ns nt nu nq nv ja nh"/></div></div></a></div></div></div>    
</body>
</html>