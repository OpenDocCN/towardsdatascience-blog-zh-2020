<html>
<head>
<title>Bayesian Statistics: Metropolis-Hastings from scratch in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">贝叶斯统计:Python 中从零开始的大都会-黑斯廷斯</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/bayesian-statistics-metropolis-hastings-from-scratch-in-python-c3b10cc4382d?source=collection_archive---------4-----------------------#2020-08-13">https://towardsdatascience.com/bayesian-statistics-metropolis-hastings-from-scratch-in-python-c3b10cc4382d?source=collection_archive---------4-----------------------#2020-08-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f1a2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用 Python 探索马尔可夫链蒙特卡罗抽样</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/aaa4ddf6e4dacfec7cba331d936d9885.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*huA8kCuGNJQgE42HOipLAQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">信用:Pixabay</p></figure><h2 id="c8ac" class="ky kz it bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">你在<em class="lu">这里</em></h2><p id="ede0" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md lh me mf mg ll mh mi mj lp mk ml mm mn im bi translated">如果你正在阅读这篇文章，很有可能:(1)你对贝叶斯统计感兴趣，但是(2)你不知道马尔可夫链蒙特卡罗(MCMC)抽样方法是如何工作的，以及(3)你意识到除了最简单的玩具问题，所有问题都需要 MCMC 抽样，所以你有点不确定如何前进。</p><p id="19e1" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md lh mq mf mg ll mr mi mj lp ms ml mm mn im bi translated">不用担心，我们将使用一维正态分布来探索这个棘手的概念，只使用 python、用户定义的函数和随机模块(特别是均匀分布。)我们将从酒吧、啤酒和与你的朋友外出的夜晚的角度来讨论所有这些无意义的事情。</p><h2 id="85e8" class="ky kz it bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">想象自己在酒吧里</h2><p id="12f8" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md lh me mf mg ll mh mi mj lp mk ml mm mn im bi translated">这是星期五晚上，你和你的朋友出去吃汉堡，喝啤酒，看电视转播的棒球比赛。假设你任意选择了第一个酒吧(我们称之为<em class="mt">拉里体育酒吧</em>，你坐下来，拿起菜单，考虑你的选择。如果食物和饮料价格合理，这是留下来的好理由；但是如果只有站着的地方，你就有理由离开。如果酒吧里摆满了大屏幕电视，而且都在播放正确的游戏，这是我留下来的另一个原因。如果食物或饮料不吸引人，你就有了另一个离开的理由。等等，你明白了。</p><p id="c0aa" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md lh mq mf mg ll mr mi mj lp ms ml mm mn im bi translated">现在，让我们假设你的一个(或几个)朋友对现在的机构有抱怨——食物是冷的，啤酒价格过高，不管是什么原因。所以他提议这帮人离开<em class="mt">拉里的体育酒吧</em>而去<em class="mt">托尼的比萨店和啤酒花园</em>因为那里的食物更好、更新鲜等等。因此，该团伙商议，提出问题(A)拉里的有多有利？(二)托尼的好感度如何？和(C) <strong class="lx iu">托尼相对于拉里的有利程度如何？</strong></p><p id="b75f" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md lh mq mf mg ll mr mi mj lp ms ml mm mn im bi translated">这种相对比较真的是最重要的细节。如果托尼的仅仅比拉里的好一点点(或者差很多),那么很有可能不值得花力气去重新定位。但是如果托尼的无疑是两个中更好的，那么你留下来的机会就很小了。这才是让 Metropolis-Hastings“工作”的真正动力</p><h2 id="9987" class="ky kz it bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">该算法</h2><p id="70ca" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md lh me mf mg ll mh mi mj lp mk ml mm mn im bi translated">Metropolis-Hastings 算法可以:</p><ol class=""><li id="ae07" class="mu mv it lx b ly mo mb mp lh mw ll mx lp my mn mz na nb nc bi translated">从<strong class="lx iu">随机</strong>样本开始</li><li id="3757" class="mu mv it lx b ly nd mb ne lh nf ll ng lp nh mn mz na nb nc bi translated">确定与样本相关的概率密度</li><li id="9794" class="mu mv it lx b ly nd mb ne lh nf ll ng lp nh mn mz na nb nc bi translated">提出一个<strong class="lx iu">新的</strong>，任意样本(并确定其概率密度)</li><li id="54b1" class="mu mv it lx b ly nd mb ne lh nf ll ng lp nh mn mz na nb nc bi translated">比较密度(通过除法)，量化<strong class="lx iu">想要</strong>移动的程度</li><li id="4368" class="mu mv it lx b ly nd mb ne lh nf ll ng lp nh mn mz na nb nc bi translated">生成一个随机数，与移动的欲望进行比较，然后<strong class="lx iu">决定:移动还是停留</strong></li><li id="ff68" class="mu mv it lx b ly nd mb ne lh nf ll ng lp nh mn mz na nb nc bi translated">重复</li></ol><blockquote class="ni"><p id="4087" class="nj nk it bd nl nm nn no np nq nr mn dk translated">真正的关键是(正如我们已经讨论过的)量化这个举动有多可取，作为一个行动/不行动的标准，然后(新的东西提醒！)<strong class="ak">观察随机事件</strong>，与所述阈值进行比较，并做出决定。</p></blockquote><h2 id="d292" class="ky kz it bd la lb ns dn ld le nt dp lg lh nu lj lk ll nv ln lo lp nw lr ls lt bi translated">随机事件</h2><p id="2707" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md lh me mf mg ll mh mi mj lp mk ml mm mn im bi translated">出于我们的目的，我们的阈值是建议样本的概率密度与当前样本的概率密度之比。如果该阈值接近(或高于)1，则意味着之前的位置非常不理想(接近 0 的数字，非常不可能)，而建议的位置非常理想(尽可能接近 1，接近分布的预期)。现在，我们需要从均匀分布中生成一个范围为[0，1]的数。如果产生的数字小于或等于阈值，我们就移动。否则，我们留下。就是这样！</p><h2 id="05dc" class="ky kz it bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">难的东西呢？</h2><p id="81fd" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md lh me mf mg ll mh mi mj lp mk ml mm mn im bi translated">这听起来有点好得难以置信，对吧？我们还没有讨论马尔可夫链或蒙特卡洛模拟，但不用担心。这两者本身都是很大的话题，我们只需要对它们有最基本的了解就可以利用 MCMC 的魔力。</p><p id="9aa0" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md lh mq mf mg ll mr mi mj lp ms ml mm mn im bi translated">马尔可夫链是离散事件的链，其中下一个事件的概率仅取决于当前事件。(例:我刚学完，是去睡觉还是去酒吧？<em class="mt">这些是我在有限的选择中唯一的选择。</em>)在这个离散选择的系统中，存在一个转移矩阵，它量化了从任何给定状态转移到任何给定状态的概率。蒙特卡洛方法实际上只是一个依赖于随机数使用的模拟/实验的花哨名称。</p><p id="d964" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md lh mq mf mg ll mr mi mj lp ms ml mm mn im bi translated">如前所述，我们将从正态分布中取样——一个连续的，而不是离散的分布。那么怎么会有转移矩阵呢？<strong class="lx iu">惊喜！</strong> —根本没有转换矩阵。(它实际上被称为一个<a class="ae nx" href="https://en.wikipedia.org/wiki/Markov_kernel" rel="noopener ugc nofollow" target="_blank">马尔可夫核</a>，它只是概率密度的比较，至少对我们的目的来说是这样的。)</p><h2 id="2187" class="ky kz it bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">代码</h2><p id="c3d9" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md lh me mf mg ll mh mi mj lp mk ml mm mn im bi translated">下面，我们定义三个函数:(1)正态，在给定参数 mu 和 sigma 的情况下，评估任何观测值的概率密度。(2) Random_coin，参考了一个 TDS 作者同行的帖子(下面划线)。以及(3) Gaussian_mcmc，其采样执行上述算法。</p><p id="1fd9" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md lh mq mf mg ll mr mi mj lp ms ml mm mn im bi translated">正如所承诺的，我们不会从 numpy、scipy 等调用任何高斯或正态函数。在第三个函数中，我们将当前样本初始化为均匀分布的实例(其中下限和上限是平均值的+/- 5 个标准偏差)。)同样，运动的定义也是如此。最后，我们根据随机事件相对于接受度的观察值移动(或停留)，这是在别处详细讨论的概率密度比较。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae nx" href="https://gist.github.com/jdmoore7/a5841d5307085bc5fd33ac046109d877" rel="noopener ugc nofollow" target="_blank"> Github 要诀</a></p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/abc37a5296765bc196e75d27dc3e419e.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*G4TXGMb2mlVF5You83mTkg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">直方图与实际分布</p></figure><p id="f3f9" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md lh mq mf mg ll mr mi mj lp ms ml mm mn im bi translated">最后，我们必须始终给予应有的信任:<a class="ob oc ep" href="https://medium.com/u/e8cce06956c9?source=post_page-----c3b10cc4382d--------------------------------" rel="noopener" target="_blank"> Rahul Agarwal </a>的<a class="ae nx" rel="noopener" target="_blank" href="/mcmc-intuition-for-everyone-5ae79fff22b1">帖子</a>定义β分布 MH 采样器对我开发上述高斯分布 MH 采样器很有帮助。我鼓励你也阅读他的文章，更详细地探索基本概念，即马尔可夫链和蒙特卡洛模拟。</p><h2 id="4025" class="ky kz it bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">离别笔记</h2><p id="b182" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md lh me mf mg ll mh mi mj lp mk ml mm mn im bi translated">亲爱的读者，我注意到一种模式，即<em class="mt">用户将我的故事添加到他们的列表中，但不鼓掌或订阅</em>。请——如果你喜欢我的内容，<strong class="lx iu">通过鼓掌、评论和订阅</strong>来认识到它是有用的。这(1)有助于我确定下一步为您创建什么内容的优先级，以及(2)有助于其他媒体用户找到我的内容。<strong class="lx iu">谢谢！</strong></p></div></div>    
</body>
</html>