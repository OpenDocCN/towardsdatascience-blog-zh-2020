<html>
<head>
<title>Efficient Web Scraping with Scrapy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Scrapy进行有效的网页抓取</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/efficient-web-scraping-with-scrapy-571694d52a6?source=collection_archive---------39-----------------------#2020-06-21">https://towardsdatascience.com/efficient-web-scraping-with-scrapy-571694d52a6?source=collection_archive---------39-----------------------#2020-06-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/1426df8f8449a46c47df178404c14708.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3pxDK9ZqJRxIh9VG"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://unsplash.com/@markusspiske" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/@markusspiske</a></p></figure><div class=""/><div class=""><h2 id="295d" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">Scrapy的新功能使您的刮削效率</h2></div><p id="1683" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Scrapy作为一个网页抓取框架是强大的和可扩展的。它有一个活跃的用户群，每次更新都会有新的功能出现。在本文中，我们将介绍其中的一些特性，以充分利用您的抓取项目。</p><h1 id="d61f" class="lu lv jj bd lw lx ly lz ma mb mc md me kp mf kq mg ks mh kt mi kv mj kw mk ml bi translated">在本文中，您将了解到</h1><ol class=""><li id="6a96" class="mm mn jj la b lb mo le mp lh mq ll mr lp ms lt mt mu mv mw bi translated">更有效地跟踪链接</li><li id="eacb" class="mm mn jj la b lb mx le my lh mz ll na lp nb lt mt mu mv mw bi translated">html属性的更清晰提取</li><li id="cae6" class="mm mn jj la b lb mx le my lh mz ll na lp nb lt mt mu mv mw bi translated">Scrapy中函数间更清晰的变量传递</li><li id="06d9" class="mm mn jj la b lb mx le my lh mz ll na lp nb lt mt mu mv mw bi translated">使用attribute属性在没有xpath或css选择器的情况下获取html属性</li></ol><h1 id="7424" class="lu lv jj bd lw lx ly lz ma mb mc md me kp mf kq mg ks mh kt mi kv mj kw mk ml bi translated">1.以下链接</h1><p id="a845" class="pw-post-body-paragraph ky kz jj la b lb mo kk ld le mp kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">为了让你的蜘蛛跟踪链接，这是通常的做法</p><pre class="nf ng nh ni gt nj nk nl nm aw nn bi"><span id="1bbc" class="no lv jj nk b gy np nq l nr ns">links = response.css("a.entry-link::attr(href)").extract()<br/>for link in links:<br/>    yield scrapy.Request(url=response.urljoin(link),  callback=self.parse_blog_post)</span></pre><p id="2cf9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在使用requests方法就可以了，但是我们可以使用另一个名为response.follow()的方法来清理这个问题。</p><pre class="nf ng nh ni gt nj nk nl nm aw nn bi"><span id="9377" class="no lv jj nk b gy np nq l nr ns">links = response.css("a.entry-link")<br/>for link in links:<br/>    yield response.follow(link, callback=self.parse_blog_post)</span></pre><p id="22b6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">看看我们为什么不必提取链接或使用urljoin，这是因为response.follow接受<a>标签。Response.follow()自动使用href属性。</a></p><pre class="nf ng nh ni gt nj nk nl nm aw nn bi"><span id="9140" class="no lv jj nk b gy np nq l nr ns">for link in response.css("a.entry-link"):<br/>  yield <!-- -->response.follow(link, callback=self.parse_blog_post)</span></pre><p id="8dd9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">事实上，scrapy可以使用follow_all()方法处理多个请求。这样做的好处是follow_all将直接接受css和xpath。</p><pre class="nf ng nh ni gt nj nk nl nm aw nn bi"><span id="adca" class="no lv jj nk b gy np nq l nr ns">yield from response.follow_all(css='a.entry-link', <!-- -->allback=self.parse_blog_post) </span></pre><figure class="nf ng nh ni gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/63cd8df6c1b9047b9ebc9d590226eabd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tA1uwCYvLgOcSwOD"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://unsplash.com/@nasa" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/@nasa</a></p></figure><h1 id="9974" class="lu lv jj bd lw lx ly lz ma mb mc md me kp mf kq mg ks mh kt mi kv mj kw mk ml bi translated">2.提取数据</h1><p id="a6df" class="pw-post-body-paragraph ky kz jj la b lb mo kk ld le mp kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">从标签中提取数据的常用方法是<code class="fe nt nu nv nk b">extract()</code>和<code class="fe nt nu nv nk b">extract_first()</code>。我们可以用一个方法<code class="fe nt nu nv nk b">get()</code>和<code class="fe nt nu nv nk b">get_all()</code>，看起来干净一点。</p><p id="d31a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从</p><pre class="nf ng nh ni gt nj nk nl nm aw nn bi"><span id="ea6d" class="no lv jj nk b gy np nq l nr ns">def parse_blog_post(self, response):<br/>    yield {<br/>        "title": response.css(".post-title::text").extract_first(),<br/>        "author": response.css(".entry-author::text").extract_first(),<br/>        "tags": response.css(".tag::text").extract(),<br/>    }</span></pre><p id="9406" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">到</p><pre class="nf ng nh ni gt nj nk nl nm aw nn bi"><span id="538d" class="no lv jj nk b gy np nq l nr ns">def parse_blog_post(self, response):<br/>    yield {<br/>        "title": response.css(".post-title::text").get(),<br/>        "author": response.css(".entry-author::text").get(),<br/>        "tags": response.css(".tag::text").getall(),<br/>    }</span></pre><figure class="nf ng nh ni gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/95376128fabd9e9791679d0d21c99258.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-XB1aBmNH5MZ9CU1"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://unsplash.com/@franki" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/@franki</a></p></figure><h1 id="3c6c" class="lu lv jj bd lw lx ly lz ma mb mc md me kp mf kq mg ks mh kt mi kv mj kw mk ml bi translated">3.使用属性选择数据</h1><p id="ea1c" class="pw-post-body-paragraph ky kz jj la b lb mo kk ld le mp kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">如果您不习惯xpath或css选择器，Scrapy可以让您以类似字典的方式获取属性。</p><p id="007b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从</p><pre class="nf ng nh ni gt nj nk nl nm aw nn bi"><span id="6d27" class="no lv jj nk b gy np nq l nr ns"><strong class="nk jk">&gt;&gt; </strong>response.css('a::attr(href)').getall()<br/>['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span></pre><p id="b0b2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">到</p><pre class="nf ng nh ni gt nj nk nl nm aw nn bi"><span id="5f28" class="no lv jj nk b gy np nq l nr ns"><strong class="nk jk">&gt;&gt;</strong> [a.attrib['href'] <strong class="nk jk">for</strong> a <strong class="nk jk">in</strong> response.css('a')]<br/>['image1.html', 'image2.html', 'image3.html', 'image4.html', 'image5.html']</span></pre><p id="b0d7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用<code class="fe nt nu nv nk b">attrib</code>你可以获取html属性，而不是使用xpath或css！</p><figure class="nf ng nh ni gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/c1857b82822b3893d2352dbe578b4dc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*RszYuaGoKYjwk8ay"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://unsplash.com/@marius" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/@marius</a></p></figure><h1 id="3fa9" class="lu lv jj bd lw lx ly lz ma mb mc md me kp mf kq mg ks mh kt mi kv mj kw mk ml bi translated">4.从回调传递数据</h1><p id="532d" class="pw-post-body-paragraph ky kz jj la b lb mo kk ld le mp kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">通常当你做一些网络抓取时，你需要将信息从一个函数传递到另一个函数。这是您通常使用response.meta函数的地方。</p><pre class="nf ng nh ni gt nj nk nl nm aw nn bi"><span id="351f" class="no lv jj nk b gy np nq l nr ns">def parse_blog_post(self, response):<br/>   <br/>    for link in links:<br/>        yield scrapy.Request(<br/>            link,<br/>            meta={"author": author, "date": post_date},<br/>            callback=self.parse_full_blog_post,<br/>        )<br/><br/>def parse_full_blog_post(self, response):<br/>    author = response.meta["author]<br/>    post_date = response.meta["post_date]</span></pre><p id="6758" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们可以使用follow_all()函数和名为<code class="fe nt nu nv nk b">cb_kwargs</code>的新关键字，这允许我们传递一个值的字典，然后我们可以在回调函数中访问它。</p><pre class="nf ng nh ni gt nj nk nl nm aw nn bi"><span id="e4c7" class="no lv jj nk b gy np nq l nr ns">def parse_blog_post(self, response):<br/>    yield from response.follow_all(<br/>        links,<br/>        cb_kwargs={"author": author, "date": post_date},<br/>        callback=self.parse_full_blog_post,<br/>    )<br/><br/>def parse_full_blog_post(self, response, author, post_date):</span></pre><p id="e03f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们在字典中定义变量<code class="fe nt nu nv nk b">author</code>和<code class="fe nt nu nv nk b">post_date</code>，并在<code class="fe nt nu nv nk b">parse_full_blog_post</code>中声明它们。干净多了！</p><p id="c33b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我希望你会发现这些技巧对充分利用Scrapy框架很有用。</p><h2 id="b883" class="no lv jj bd lw nw nx dn ma ny nz dp me lh oa ob mg ll oc od mi lp oe of mk og bi translated">参考</h2><ol class=""><li id="6ce8" class="mm mn jj la b lb mo le mp lh mq ll mr lp ms lt mt mu mv mw bi translated"><a class="ae jg" href="https://stummjr.org/post/scrapy-in-2020/" rel="noopener ugc nofollow" target="_blank">https://stummjr.org/post/scrapy-in-2020/</a>——这篇文章的来源和一篇很棒的博客文章详细介绍了这些观点！</li></ol><h1 id="bbe7" class="lu lv jj bd lw lx ly lz ma mb mc md me kp mf kq mg ks mh kt mi kv mj kw mk ml bi translated">相关文章</h1><div class="is it gp gr iu oh"><a rel="noopener follow" target="_blank" href="/approach-to-learning-python-f1c9a02024f8"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd jk gy z fp om fr fs on fu fw ji bi translated">学习Python的方法</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">今天如何最大限度地学习python</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">towardsdatascience.com</p></div></div><div class="oq l"><div class="or l os ot ou oq ov ja oh"/></div></div></a></div><div class="is it gp gr iu oh"><a href="https://medium.com/swlh/5-python-tricks-you-should-know-d4a8b32e04db" rel="noopener follow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd jk gy z fp om fr fs on fu fw ji bi translated">你应该知道的5个Python技巧</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">如何轻松增强python的基础知识</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">medium.com</p></div></div><div class="oq l"><div class="ow l os ot ou oq ov ja oh"/></div></div></a></div><div class="is it gp gr iu oh"><a rel="noopener follow" target="_blank" href="/scrapy-this-is-how-to-successfully-login-with-ease-ea980e2c5901"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd jk gy z fp om fr fs on fu fw ji bi translated">Scrapy:这就是如何轻松成功登录</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">揭秘用Scrapy登录的过程。</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">towardsdatascience.com</p></div></div><div class="oq l"><div class="ox l os ot ou oq ov ja oh"/></div></div></a></div><p id="594d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请看<a class="ae jg" href="http://www.coding-medic.com/" rel="noopener ugc nofollow" target="_blank">这里</a>关于我在我的博客和其他帖子上关于项目的更多细节。更多技术/编码相关内容，请点击这里订阅我的简讯<a class="ae jg" href="https://aaronsmith.substack.com/p/coming-soon?r=6yuie&amp;utm_campaign=post&amp;utm_medium=web&amp;utm_source=copy" rel="noopener ugc nofollow" target="_blank"/></p><p id="96f1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我将非常感谢任何评论，或者如果你想与python合作或需要帮助，请联系我。如果你想和我联系，请在这里asmith53@ed.ac.uk或在twitter上联系。</p></div></div>    
</body>
</html>