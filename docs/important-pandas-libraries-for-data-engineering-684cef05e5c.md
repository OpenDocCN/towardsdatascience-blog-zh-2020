# æ•°æ®å·¥ç¨‹ç†ŠçŒ«ç®€æ˜æŒ‡å—â€”ç¬¬ 1 éƒ¨åˆ†

> åŸæ–‡ï¼š<https://towardsdatascience.com/important-pandas-libraries-for-data-engineering-684cef05e5c?source=collection_archive---------32----------------------->

**æ•°æ®å·¥ç¨‹**æ˜¯**æ•°æ®**ç§‘å­¦çš„ä¸€ä¸ªæ–¹é¢ï¼Œä¾§é‡äº**æ•°æ®é‡‡é›†**å’Œ**åˆ†æ**[æ¥æº](https://www.datasciencegraduateprograms.com/data-engineering/#:~:text=Data%20engineering%20is%20the%20aspect,collecting%20and%20validating%20that%20information.)çš„å®é™…åº”ç”¨ã€‚ä»–ä»¬å»ºç«‹çš„ç®¡é“å¯¹æ•°æ®ç§‘å­¦å®¶è½¬æ¢æ•°æ®éå¸¸æœ‰ç”¨ã€‚ä»–ä»¬éœ€è¦äº†è§£æ— æ•°çš„æŠ€æœ¯ï¼Œå¹¶ä¸ºè¿™é¡¹å·¥ä½œé€‰æ‹©åˆé€‚çš„å·¥å…·ã€‚

![](img/5ca66552babc150f97e6ce860482478e.png)

ç™Œç—‡æ‚£è€…çš„æ•°æ®å›¾è¡¨

## **å†…å®¹**:

1.  è¿›å£
2.  å‡ºå£
3.  çœ‹æ³•
4.  ç´¢å¼•
5.  å­é›†åŒ–
6.  æå–è¡Œå’Œåˆ—
7.  å–ä»£
8.  æ·»åŠ /åˆ é™¤
9.  æ’åºå’Œé‡å‘½å
10.  ç»“åˆ
11.  èšé›†

# **å¯¼å…¥:**

å¯¼å…¥ pandas åº“ä»¥å°† CSV æ–‡ä»¶æˆ– XLSX æ ¼å¼çš„æ–‡ä»¶è½¬æ¢ä¸º dataframeã€‚

```
import pandas as pd
import numy as npcancer_df = pd.read_excel("cancer_patient_data_sets.xlsx")
cancer_df = pd.read_csv("cancer_patient_data_sets.csv")
```

è¦æˆåŠŸè¿è¡Œä»¥ä¸Šä»£ç è¡Œï¼Œè¯·ç¡®ä¿å°†æ–‡ä»¶ä¸Šä¼ åˆ° Google Colab çš„`content`æ–‡ä»¶å¤¹ä¸­ï¼Œæˆ–è€…å½“æ‚¨åœ¨ Jupyter Notebook ä¸­å·¥ä½œæ—¶ä¸Šä¼ åˆ°æ‚¨çš„æœ¬åœ°æ–‡ä»¶å¤¹ä¸­ã€‚ä½ ä¹Ÿå¯ä»¥ä» S3 æˆ–è°·æ­Œç¡¬ç›˜ä¸Šè¯»å–æ–‡ä»¶ã€‚

**è°·æ­Œé©±åŠ¨:**

I)å°†æ‚¨çš„ google drive å®‰è£…åˆ° colab

```
from google.colab import drive 
drive.mount('/content/gdrive')
```

ii)ç°åœ¨ï¼Œæ‚¨å°†åœ¨å·¦ä¾§çª—æ ¼(æ–‡ä»¶æµè§ˆå™¨)ä¸­çœ‹åˆ°æ‚¨çš„ Google Drive æ–‡ä»¶ã€‚å³é”®å•å‡»éœ€è¦å¯¼å…¥çš„æ–‡ä»¶ï¼Œé€‰æ‹©å¤åˆ¶è·¯å¾„ã€‚ç„¶ååœ¨ pandas ä¸­ç…§å¸¸å¯¼å…¥ï¼Œä½¿ç”¨è¿™ä¸ªå¤åˆ¶çš„è·¯å¾„ã€‚

```
import pandas as pd 
cancer_df = pd.read_csv('gdrive/My Drive/cancer_patient_data_sets.csv')
```

AWS S3:ç°åœ¨ç†ŠçŒ«å¯ä»¥å¤„ç† AWS S3 ç½‘å€äº†ã€‚ç®€å•åœ°åš

```
import pandas as pd
import s3fs

cancer_df = pd.read_csv('s3://bucket-name/file_name.csv')
```

**æ„å»ºæ•°æ®æ¡†æ¶:**å¦‚æœä½ æœ‰æ•°æ®ï¼Œæƒ³æ„å»ºä¸€ä¸ªæ•°æ®æ¡†æ¶ï¼Œä½ å¯ä»¥è¿™ä¹ˆåšã€‚

```
sample_df = pd.DataFrame([[1,'Bob','M','31','Builder'],
                  [2,'Sally','F','29','Baker'],
                  [3,'Scott','M','28','Candle Stick Maker']], 
columns=['id','name','gender','age','occupation'])
```

# **å¯¼å‡º:**

æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹ä»£ç è¡Œå°†æœ€ç»ˆè¾“å‡ºä¿å­˜ä¸º CSV æˆ– EXCEL æ ¼å¼

```
output_df.to_csv('saved_patients.csv', index=False)
output_df.to_excel('saved_patients.xlsx', index=False)
```

# æŸ¥çœ‹:

**æ˜¾ç¤ºæ•°æ®å¸§é¡¶éƒ¨æˆ–åº•éƒ¨çš„å‡ æ¡è®°å½•**

```
sample_df.head(5)
sample_df.tail(5)
```

# **ç´¢å¼•:**

**ç´¢å¼•æ‚¨çš„æ•°æ®å¸§:**

*   ä»…ç´¢å¼•æ•°æ®å¸§ä¸­çš„ä¸€ä¸ªåˆ—:

```
sample_df = sample_df.set_index('id')
sample_df
```

*   å¯¹æ•°æ®å¸§ä¸­çš„å¤šåˆ—**è¿›è¡Œç´¢å¼•:**

```
sample_df = sample_df.set_index(['id','age'])
sample_df
```

*   è¦é‡ç½®æ•°æ®å¸§ä¸­çš„ç´¢å¼•:

```
sample_df.reset_index(inplace = True)
sample_df
```

# **å­é›†åŒ–:**

*   è¦ä»ç°æœ‰æ•°æ®æ¡†æ¶ä¸­é€‰æ‹©æœ‰é™æ•°é‡çš„åˆ—å¹¶å°†å…¶å­˜å‚¨åœ¨æ–°æ•°æ®æ¡†æ¶ä¸­:

```
df = sample_df[['age', 'name', 'occupation']]
df
```

*   è¦å¯¹è¡Œè¿›è¡Œå­é›†åˆ’åˆ†å¹¶è€ƒè™‘æ‰€æœ‰åˆ—:

```
#Select first 3 rows :
df[0:3]*# Select first 5 rows (rows 0, 1, 2, 3, 4)* df[:5]*# Select the last element in the list
# (the slice starts at the last element, and ends at the end of the list)* df[-1:]
```

*   ä½¿ç”¨`loc`æ–¹æ³•ä»æˆ‘ä»¬çš„æ•°æ®å¸§ä¸­é€‰æ‹©è¡Œå’Œåˆ—:è¿™ä¸ªå‘½ä»¤é€šè¿‡è¡Œå’Œåˆ—çš„æ ‡ç­¾é€‰æ‹©æ•°æ®ã€‚

```
*# Select all columns for specific rows of index values 0 and 2 where no specific column in the dataframe has any index*data = pd.read_csv("nba.csv")
df = data.loc[[0, 2], :]*# Select all columns for a specific row or multiple rows where a column is set as an index* data = pd.read_csv("nba.csv", index="name")
df **=** data.loc[["Avery Bradley"]] 
OR 
df **=** data.loc[["Avery Bradley", "R.J. Hunter"]]# *Select specific rows and specific columns*data = pd.read_csv("nba.csv", index="name")
df = [["Avery Bradley", "R.J. Hunter"],["Team", "Number", "Position"]]*# Select only one or multiple specific row/rows and multiple columns after resetting index*data.reset_index(inplace = True)
df = data.loc[0, ['Name', 'Number', 'Age', 'Position']] 
OR
df = data.loc[[0,5], ['Name', 'Number', 'Age', 'Position']]
```

*   ä½¿ç”¨`iloc`æ–¹æ³•ä»æˆ‘ä»¬çš„æ•°æ®å¸§ä¸­æå–è¡Œå’Œåˆ—çš„å­é›†:è¿™ä¸ªå‘½ä»¤å…è®¸æˆ‘ä»¬æŒ‰ä½ç½®æ£€ç´¢è¡Œå’Œåˆ—ã€‚

```
# *Slice certain number of rows and columns*
df = sample_df.iloc[0:3, 1:4]

*# Select the value of second row and third column* df = sample_df.iloc[2, 3]*# Select all rows and selected columns* df = sample_df.iloc [:, [1, 2]]# *Select certain range of rows and all columns*
df = sample_df.iloc[[0, 2]]
```

*   è¦æ ¹æ®æ ‡å‡†é€‰æ‹©æ•°æ®å¸§:

```
# Select dataframe where the value of a column is given
df[df.year == 2002]# Select dataframe on multiple conditions
df[(df.year >= 1980) & (df.year <= 1985)]ORdf = df[(df.year >= 2000) & (df.gender == 'M')]
```

*   ä½¿ç”¨`isin`å‘½ä»¤:Pandas `isin()` æ–¹æ³•æœ‰åŠ©äºé€‰æ‹©ç‰¹å®šåˆ—ä¸­å…·æœ‰ç‰¹å®šå€¼æˆ–å¤šä¸ªå€¼çš„è¡Œã€‚

```
new = sample_df["gender"].isin(["M"])
sample_df[new]ORfilter1 **=** sample_df["gender"].isin(["M"])
filter2 **=** sample_df["occupation"].isin(["Baker", "Builder"])# displaying data with both filter applied and mandatory
sample_df[filter1 & filter2]
```

*   è¦é€‰æ‹©æ•°æ®å¸§ä¸­åŒ…å«ç©ºå€¼çš„è¡Œ:

```
*# To select just the rows with NaN values, we can use the 'any()' method* sample_df[pd.isnull(sample_df).any(axis=1)]
```

*   ä½¿ç”¨ lookup()å‡½æ•°:lookup()å‡½æ•°ä¸º DataFrame è¿”å›åŸºäºæ ‡ç­¾çš„â€œèŠ±å¼ç´¢å¼•â€å‡½æ•°:

![](img/d123534808f35b12fc35acfa6bd4edcc.png)

# **æ›´æ¢:**

**æ›¿æ¢æ•°æ®å¸§ä¸­çš„å€¼:**

*   å‡½æ•°`mask()`ç”¨äºæ›¿æ¢æ ‡å‡†æ•°æ®æ¡†ä¸­çš„æ‰€æœ‰å€¼

```
# replace all the values greater than 10 with -25
df.mask(df > 10, **-**25)# replace the Na values with 1000
df.mask(df.isna(), 1000))
```

*   ä½¿ç”¨`where()`å‡½æ•°æ ¹æ®ä¸€ä¸ªæˆ–å¤šä¸ªç‰¹å®šæ ‡å‡†è¿‡æ»¤æ•°æ®é›†

```
filter **=** sample_df["gender"]**==**"M"
data.where(filter, inplace **=** True)ORfilter1 **=** sample_df["gender"]**==**"M"
filter2 **=** sample_df["age"]>24
sample_df.where(filter1 & filter2, inplace **=** True)
```

# **æå–è¡Œæˆ–åˆ—:**

*   ä½¿ç”¨`get()`å‡½æ•°ä»æ•°æ®å¸§ä¸­æå–ä¸€åˆ—æˆ–å¤šåˆ—

```
sample_df.get("occupation")ORsample_df.get(["name", "age", "occupation"])
```

*   ä½¿ç”¨`pop()`åŠŸèƒ½åˆ é™¤ä¸€åˆ—æˆ–å¤šåˆ—

```
# Remove one column from the original dataframe
popped_col **=** sample_df.pop("occupation")
sample_df# make a copy of the data frame and insert the popped column at the end of the other data frame
new **=** sample_df.copy()
popped_col **=** new.pop("name")
# creating new col and passing popped col
new["New Col"]**=** popped_col
new
```

# **æ·»åŠ /åˆ é™¤:**

**åˆ é™¤åˆ—:**

```
del sample_df['column_name']
```

*   ä½¿ç”¨`drop()`åŠŸèƒ½åˆ é™¤ä¸€è¡Œæˆ–å¤šè¡Œæˆ–å¤šåˆ—

```
df = data.drop('column_1', axis=1)# Delete multiple columns from the dataframe
df = data.drop(["column_1", "column_2", "column_3"], axis=1)# Delete multiple rows from the dataframe
data = df.drop([0,1], axis=0)
data# drop rows where age is less than 25
df_filtered **=** df[df['Age'] >**=** 25]# drop rows with null values
df **=** df.dropna(how **=** 'all')
```

*   å‘ç°æœ‰æ•°æ®æ¡†æ¶æ·»åŠ æ–°åˆ—æˆ–æ–°è¡Œ

```
# Add a new column in the existing dataframe by providing the values manually in a list format
sample_df['salary'] = [250000, 150000, 100000]
sample_df# Add a new column by performing simple calculation on any other existing column
sample_df['new_col'] = sample_df['salary']*2
sample_df# Add a new column having same constant values
sample_df['new'] = 'y'
sample_df
OR
sample_df['new'] = sample_df.apply(lambda x: 'y', axis=1)# Insert a new row in an existing dataframe:
sample_df.loc[3] = [4, 'Mike', 26, 'Delivery boy']
sample_dfOR
```

![](img/994d37bb90555c0cf706d8aa04edc6d8.png)

åœ¨ç°æœ‰æ•°æ®æ¡†æ¶ä¸­æ’å…¥æ–°è¡Œ

# **æ’åºå’Œé‡å‘½å:**

æŒ‰è¡Œå’Œåˆ—å¯¹æ•°æ®å¸§è¿›è¡Œæ’åº:

```
# use sort_index() to sort by row index or names
sample_df = sample_df.set_index('name')
sample_df.sort_index(inplace**=**True)# sort on multiple columns by descending order
sort_by_age_occ **=** sample_df.sort_values(by = ['age','occupation'], ascending = False)# sort a column in ascending order
a **=** sample_df.sort_values(by **=**'age', ascending **=** True)
```

é‡å‘½åæ•°æ®å¸§ä¸­çš„åˆ—:

```
sample_df.rename(columns **=** {'occupation':'Occupation', 'age':'Age', 'name':'Name'}, inplace **=** True)
```

# **ç»“åˆ:**

æœ‰å„ç§ç±»å‹çš„è¿æ¥:

*   **ä¸€å¯¹ä¸€**è¿æ¥:ä¾‹å¦‚å½“è¿æ¥ç´¢å¼•ä¸Šçš„ä¸¤ä¸ªå¯¹è±¡æ—¶(å¿…é¡»åŒ…å«å”¯ä¸€å€¼)ã€‚
*   **å¤šå¯¹ä¸€**è¿æ¥:ä¾‹å¦‚ï¼Œå°†ä¸€ä¸ªç´¢å¼•(å”¯ä¸€çš„)è¿æ¥åˆ°ä¸åŒæ•°æ®æ¡†æ¶ä¸­çš„ä¸€ä¸ªæˆ–å¤šä¸ªåˆ—ã€‚
*   **å¤šå¯¹å¤š**è”æ¥:è”æ¥åˆ—ä¸Šçš„åˆ—ã€‚
*   ä½¿ç”¨ merge()è¿æ¥ä¸¤ä¸ªæ•°æ®å¸§

```
'''
 There are 3 dataframes (df1, df2, df3) having similar column names - 'id', 'Feature1', 'Feature2'. You can merge 2 dataframes on a specific column.
'''
df_merge = pd.merge(df1, df2, on='id') # Combine two dataframes which will contain all the records
df_outer = pd.merge(df1, df2, on='id', how='outer')# Combine two dataframes which will contain only the common records between the them
df_inner = pd.merge(df1, df2, on='id', how='inner')# Combine two dataframes which will contain the common records between the them along with all the records of first dataframe
df_left = pd.merge(df1, df2, on='id', how='left')# Combine two dataframes which will contain the common records between the them along with all the records of second dataframe
df_right = pd.merge(df1, df2, on='id', how='right')#Combine two dataframes on the records present in the index column
df_index = pd.merge(df1, df2, right_index=True, left_index=True)  df_index
```

*   ä½¿ç”¨ concat()è¿æ¥ç›¸ä¼¼åˆ—åçš„ä¸¤ä¸ªæ•°æ®å¸§

![](img/5c33a31519695b3c7c1a506f7a74fd91.png)

æˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨`append()`é€šè¿‡ä½¿ç”¨`result = df1.append(df2)`å¾—åˆ°ä¸Šé¢çš„ç»“æœ

*   ä½¿ç”¨ concat()è¿æ¥ä¸åŒåˆ—åå’Œä¸åŒè¡Œçš„ä¸¤ä¸ªæ•°æ®å¸§

![](img/fa43a8471b112238f539464367bfd71d.png)

# **èšåˆ:**

å¯ä»¥å°† max()ã€min()ã€mean()ã€first()ã€last()ç­‰å‡½æ•°å¿«é€Ÿåº”ç”¨äº GroupBy å¯¹è±¡ï¼Œä»¥è·å¾—æ•°æ®å¸§ä¸­æ¯ä¸ªç»„çš„æ±‡æ€»ç»Ÿè®¡ä¿¡æ¯ã€‚

å¦‚æœä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Œä½ å¯èƒ½ä¹Ÿä¼šå–œæ¬¢ä¸‹ä¸€ç¯‡[æ–‡ç« ](https://medium.com/@pb.careofpriyanka/important-pandas-libraries-for-data-engineering-part-2-434dd2005c39)ï¼Œå®ƒå°†æ›´åŠ å…³æ³¨ä¸€äº›é‡è¦çš„å‡½æ•°ä»¥åŠå®ƒä»¬åœ¨æ•°æ®å·¥ç¨‹ä¸­çš„ç”¨é€”ã€‚

æ„Ÿè°¢é˜…è¯»ã€‚ğŸ˜ƒå¸Œæœ›ä½ èƒ½åƒæˆ‘å‡†å¤‡è¿™ç¯‡æ–‡ç« æ—¶ä¸€æ ·å–œæ¬¢å®ƒ..