# 自动机和超级智能

> 原文：<https://towardsdatascience.com/automatons-and-super-intelligence-d8f638c0c74?source=collection_archive---------49----------------------->

![](img/f83a38ddde737edbed7f1b295bfdf90b.png)

照片由 [Maximalfocus](https://unsplash.com/@maximalfocus?utm_source=medium&utm_medium=referral) 在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄

## 通过人工智能的两种潜在状态来理解它。

近十年来，人工智能一直是技术和媒体领域的新流行语。它(很快)未来的工作自动化是[杨安泽的普遍基本收入](https://www.yang2020.com/what-is-freedom-dividend-faq/)的动机，它通过谷歌和脸书对我们的理解导致了隐私和道德方面的可疑行动——导致了两部著名的网飞纪录片 [The Great Hack](https://www.thegreathack.com/) 和[The Social Dilemma](https://www.netflix.com/title/81254224)——其快速的改进速度让许多领域外的人感到恐惧。

一旦人工智能达到超级智能，没有人知道人类的未来将走向何方——就像普通公众如何忘记我们的数据将成为新的石油一样。未来人工智能将呈现两种状态:机器人和超级智能生物。自动机是一种能够准确有效地执行重复性程序任务的机器人，而超级智能生物是——你猜对了——一种超越我们目前所理解的智能的程序，为了方便起见，我现在在本文的其余部分将其称为 AGI(人工通用智能)。

现在，我必须指出显而易见的是，AI 的这两种状态产生了许多可能性。在这篇文章中，我的目标是分解我们应该从这些状态中期待什么，以及在处理它们时可能出现的伦理问题。

# 在自动机的情况下:

目前有许多不同模式的自动机在运行，但没有一种能与 AGI 的潜力相提并论。暂且忽略典型的人工智能程序，[机械臂、爪子和其他自动化机械主导着工厂生产，因为它们与人类相比具有一致的生产率](https://futurism.com/2-production-soars-for-chinese-factory-who-replaced-90-of-employees-with-robots)，而且随着时间的推移，这只会进一步增加。

我们已经习惯了生活中许多方面的自动化。越来越多的工作被机器人自动化只是时间问题。当与 AGI 的潜力相比时，我认为我们看到并与之交互的大多数——如果不是全部——人工智能程序在未来将被视为基本的自动机，因为它们很简单。

但是等等，谷歌和脸书利用我们的大量数据，可能比我们更了解我们。那不算超级聪明吗？

你完全可以说，与人类相比，谷歌和脸书的广告人工智能超级聪明。然而，我仍然认为它是一台自动机——是我们迄今为止最聪明的一台。这种考虑的主要原因很简单:它所做的一切都可以归结为一个目标:为我们提供它认为我们喜欢的帖子(无论是图片、视频、广告等等)。)它有一个目标，并不断优化以实现这个目标，而且做得很好。

**快速切线:**我想非常明确的说，它的知识库来自于不可逾越的数据量。对我来说，试图描述数据到底有多大是没有意义的，因为我们都不会真正理解它。把它想象成空间的大小，你知道它很大但是它到底有多大？随着这些数据而来的是智能，让我们与为我们量身定制的东西进行交互。然而，由于其唯一目标的“局限性”，它只是一个真正智能的自动机，给我们提供越来越多各种形式的帖子，而没有真正理解我们如何解释帖子——它只是(准确地)假设我们会与它互动。

那么，所有这些都摆在我们面前，我们该何去何从呢？

机器人将不可避免地在各自的应用领域变得更加智能，并取代人类完成这些任务。这些任务可以是在麦当劳卖汉堡，给我们送信，清扫街道，建造摩天大楼。任何物理任务都可以而且将会自动化。

作为一个集体，我们的工作是让技术进步改善我们的生活，而不是毁掉它。为机器以很小的价格(长期)夺走了你的工作而愤怒是一回事，但为机器抢走了你的工作而愤怒*又是另一回事。这忽略了一个事实，那就是取代你的是人类的决定，而不是机器人。当谈到自动机时，它们不会决定一个濒临财务不稳定的努力工作的工人阶级家庭的未来。另一个人会。*

# 就 AGI 而言:

把机器人和 AGI 混为一谈是愚蠢的。很多人都这样做。别犯傻了。

尽管 GPT-3 是目前写这篇文章时最好的自然语言模型，但与人类相比，它还是很笨。我相当节制地使用愚蠢；这是一个极其智能的程序，但这是因为用于训练它的数据量庞大，而不是因为它的实际智能。它在性能上的失败表明，要被认为与人类没有区别，它还有很长的路要走。就目前而言，这是一个记忆和反刍大量文本的优秀程序。

出于一个原因，很难对 AGI 做出假设。就像我们无法预测谷歌和脸书内部的技术-广告复合体一样，我们也无法准确预测 AGI 将如何形成。我不怀疑许多公司推动以人为中心的 AGI 背后的动机，例如 [OpenAI](https://openai.com/) 、 [DeepMind](https://deepmind.com/) 和 [SingularityNET](https://singularitynet.io/) 。事实上，他们是我个人最信任的公司。然而，即使有了所有的制衡机制，我们仍然无法预测结果会是什么。

我们不知道 AGI 是否会从智力低下的起点开始，随着时间的推移慢慢提高，或者以超出人类理解的速度成倍提高。我们不知道它在运作时将如何或是否考虑人的价值。我们不知道它是否会爱我们，帮助我们更多地了解自己，是否会恨我们，杀死我们所有人，或者认为我们如此愚蠢，以至于人类对他们没有价值，让地球完全把我们带回到我们开始的地方。

无论是在面部识别中大量使用 POC[技术，还是](https://techxplore.com/news/2020-08-ai-technologies-police-facial-recognition.html)[在招聘中歧视女性](https://fortune.com/2018/10/10/amazon-ai-recruitment-bias-women-sexist/)，以及[如果你有很重的口音就无法识别你的声音](https://www.washingtonpost.com/graphics/2018/business/alexa-does-not-understand-your-accent/)，这些事件发生的一个主要原因是:偏见。假设 AGI 有能力学习人类的一切，当我们自己对彼此的看法有偏见时，它将永远达不到这种潜力。然而，创造无偏见的数字头脑是极其困难的，因为我们只能在这些机器已经为大众使用而训练和调整时才能看到它们的偏见。即使非常小心地确保一个系统是公正的，它也可能不可避免地在其他地方表现出偏见。一些偏差，像上面提到的那些，并不是微不足道的，并且显示了这些模型的当前和未来迭代的大量危险信号。

关于高维度偏见是什么样子，或者它如何影响 AGI 对人类的“态度”，没有固定的答案。然而，彻底消除偏见是伟大的第一步。然而，说起来容易做起来难。这个论点来自于一个人类物种不知道如何消除彼此之间的偏见。

总而言之，随着人工智能越来越多地与人类融为一体，人类生活将从根本上发生变化。这种转变对许多人来说是可怕的，对另一些人来说是令人兴奋的，但也有一些人对此视而不见。如果历史重演，我相信人工智能会让人类走向更高的生活水平和更好的生活质量。考虑到这一点，不平等必然会一直存在。我们只能希望这些超级聪明的人发现不平等是一个微不足道的人类问题，需要解决，而不是加剧。

> 感谢您的阅读。