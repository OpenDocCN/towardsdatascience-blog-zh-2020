<html>
<head>
<title>Designing and developing an occlusion based face detector</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于遮挡的人脸检测器的设计与开发</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/designing-and-developing-an-occlusion-based-face-detector-cc4ce8d9aff3?source=collection_archive---------60-----------------------#2020-05-13">https://towardsdatascience.com/designing-and-developing-an-occlusion-based-face-detector-cc4ce8d9aff3?source=collection_archive---------60-----------------------#2020-05-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f9f8" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">“增强安全性的最佳方式是通过面部识别——它很快就会成为标准。”—凯莎·威廉姆斯</h2></div><p id="4ab7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">嗨，大家好，我又带来了另一篇文章，但这次它不是基于任何理论，而是关于开发一个现实世界问题的应用程序。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/f0de00f1c6b146d60273fbb073a8e2c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jQG5aHVMMijNzp2V"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">来源:<a class="ae lr" href="https://images.pexels.com/photos/430208/pexels-photo-430208.jpeg?auto=compress&amp;cs=tinysrgb&amp;dpr=2&amp;h=650&amp;w=940" rel="noopener ugc nofollow" target="_blank">斯科特·韦伯拍摄的Pexels图片</a></p></figure><p id="db99" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以，我希望你们都感到兴奋，因为今天我们将学习开发一个成熟的人脸检测系统，它可以处理遮挡的人脸以及其他场景。但是等等，等等…被遮挡的脸是什么意思？被遮挡的脸是指不完全可见的脸，我的意思是它的一部分被一些东西覆盖着，如面具或相机由于遮挡或其他原因无法捕捉到脸部的镜头。</p><p id="3b82" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们为什么需要这个？嗯，这可以在捕捉某人进行一些邪恶的活动或其他事情时找到很多应用。</p><p id="cfa7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以我们的要求是:</p><ol class=""><li id="ee0b" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la lx ly lz ma bi translated">计算机编程语言</li><li id="2284" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated">打开简历</li><li id="032b" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated">人脸识别模块。</li></ol><p id="f91e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我相信你们都非常熟悉前两个，并且随着我们的深入了解第三个。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><p id="6c68" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">这是我们的文章提纲。</strong></p><ol class=""><li id="a0e2" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la lx ly lz ma bi translated">我们将与图像一起使用的文件</li><li id="277d" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated">正在生成编码。</li><li id="5b7d" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated">使用人脸检测模型检测人脸[图像+视频]</li><li id="8e24" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated">结论。</li></ol><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/651cb4c79cc00bd1c8cc93160210d543.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lO9IV9NcP_3l0CQR"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">来源:负空间Pexel</p></figure><h2 id="8d9a" class="mn mo iq bd mp mq mr dn ms mt mu dp mv ko mw mx my ks mz na nb kw nc nd ne nf bi translated">要使用的文件和图像</h2><p id="8532" class="pw-post-body-paragraph kf kg iq kh b ki ng jr kk kl nh ju kn ko ni kq kr ks nj ku kv kw nk ky kz la ij bi translated">我们将维护两个名为<em class="nl"> gen_encoding.py </em>的文件，用于生成编码和检测人脸的人脸识别。</p><p id="28fc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将使用我们想要检测其面部的人的图像。如果能给我们几张照片就更好了。我们将把这些人的图像存储在一个单独的文件夹中，该文件夹以图像所属的人的名字命名。</p><h2 id="068e" class="mn mo iq bd mp mq mr dn ms mt mu dp mv ko mw mx my ks mz na nb kw nc nd ne nf bi translated">生成编码。</h2><pre class="lc ld le lf gt nm nn no np aw nq bi"><span id="4afb" class="mn mo iq nn b gy nr ns l nt nu">import opencv<br/>import face_recognition<br/>import pickle<br/>import cv2</span><span id="ecaf" class="mn mo iq nn b gy nv ns l nt nu">for i,image_p in enumerate("image directory path"): <br/>    image =cv2.imread(image_p))<br/>    name = image_p.split(".")[0]</span></pre><p id="e26a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在上面的代码片段中，我们在顶部导入所需的库，并使用for循环从图像目录中串行读取图像，并通过分割图像扩展名来获取图像的名称。</p><pre class="lc ld le lf gt nm nn no np aw nq bi"><span id="218f" class="mn mo iq nn b gy nr ns l nt nu">rgb = cv2.cvtColor(image,cv2.COLOR_BGR2RGB) <br/>boxes = face_recognition.face_locations(rgb,model="cnn")<br/>encodings = face_recognition.face_encodings(rgb,boxes)</span></pre><p id="dae8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在上面的代码片段中，我们根据face_recognition库中的模型来转换图像的颜色。</p><p id="572b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在第二行中，我们从face_location函数中获取图像的位置，该函数返回维数的平方。</p><p id="cfd0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">进一步使用这些位置，我们裁剪出面部区域，并使用face_recognition的face_encodings功能生成图像编码，该功能使用了特定的神经网络模型来完成一些工作，但我不会详细介绍它，因为它与上下文无关。</p><pre class="lc ld le lf gt nm nn no np aw nq bi"><span id="7193" class="mn mo iq nn b gy nr ns l nt nu">encodings=[], known_names= []<br/>for encoding in encodings:<br/>  #Processsing the encodings  known<br/>  encodings.append(encoding)<br/>  known_names.append(name)</span></pre><p id="2f8c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在上面的代码中，我们将图像的编码和名称存储在一个列表中，并将它们存储在一个pickle文件中，如下所示。</p><pre class="lc ld le lf gt nm nn no np aw nq bi"><span id="e58e" class="mn mo iq nn b gy nr ns l nt nu">data = {"encoding": known_encodings, "names":known_names}<br/>f =open("encoding file name","wb"):<br/>    f.write(pickle.dumps(data))</span></pre><h2 id="0550" class="mn mo iq bd mp mq mr dn ms mt mu dp mv ko mw mx my ks mz na nb kw nc nd ne nf bi translated">使用人脸检测模型检测人脸。</h2><p id="9235" class="pw-post-body-paragraph kf kg iq kh b ki ng jr kk kl nh ju kn ko ni kq kr ks nj ku kv kw nk ky kz la ij bi translated">现在编码部分已经足够了。现在，我们将与检测脸的真实切片一起工作。</p><p id="8697" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了编写我们的代码，我们将使用<em class="nl"> face_recognition.py </em>命名文件。</p><p id="bc3e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在下面的代码中，我们将打开如上生成的编码文件，并将其存储在数据变量中。</p><pre class="lc ld le lf gt nm nn no np aw nq bi"><span id="aa61" class="mn mo iq nn b gy nr ns l nt nu">data = pickle.loads(open(args["encoding"],"rb").read())</span></pre><blockquote class="nw nx ny"><p id="cd28" class="kf kg nl kh b ki kj jr kk kl km ju kn nz kp kq kr oa kt ku kv ob kx ky kz la ij bi translated"><strong class="kh ir">用图像检测</strong></p></blockquote><p id="305e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本节中，我们将在提供的图像中进行人脸检测。因此，首先我们将加载图像，并将其转换为标准的颜色格式，我们将生成它的编码进行比较。</p><pre class="lc ld le lf gt nm nn no np aw nq bi"><span id="e423" class="mn mo iq nn b gy nr ns l nt nu">image = cv2.imread(os.path.join("image_path"))<br/>rgb = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)<br/>boxes= face_recognition.face_locations(rgb,model= "cnn")<br/>encodings = face_recognition.face_encodings(rgb,boxes)<em class="nl">Detection with vidoes</em></span></pre><p id="1129" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，在下面的代码片段中，我将图像生成的编码与所有已经存储的人脸编码进行比较。如果它们之间的差异低于阈值，我们将其作为相应人脸的编码并用imshow()函数显示。</p><pre class="lc ld le lf gt nm nn no np aw nq bi"><span id="6bb4" class="mn mo iq nn b gy nr ns l nt nu">for encoding in encodings:<br/>   matches=face_recognition.compare_faces(data,encoding) <br/>   name = "Unknown"<br/>   if True in matches:<br/>      match_idx = [i for (i,b) in    enumerate(matches) if b]<br/>      counts= {}<br/>      for i in match_idx:<br/>         name = data["names"][i]<br/>         counts[name] =counts.get(name,0)+1<br/>      name = max(counts, key= counts.get)<br/>   names.append(name)<br/>for ((top,right,bottom,left),name) in zip(boxes,names): <br/>     cv2.rectangle(image,(left,top),(right,bottom),(0,255,0),2)<br/>     y = top-15 if top-15&gt;15 else top+15<br/>     cv2.putText(image,name,(left,y),cv2.FONT_HERSHEY_SIMPLEX,0.45,<br/>     (0,255,0),2)<br/>cv2.imshow("Image",image)</span></pre><blockquote class="nw nx ny"><p id="af28" class="kf kg nl kh b ki kj jr kk kl km ju kn nz kp kq kr oa kt ku kv ob kx ky kz la ij bi translated"><strong class="kh ir">视频帧中的检测</strong></p></blockquote><p id="d7be" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在重复几乎相同的过程，现在是视频帧而不是图像。</p><p id="70eb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在下面的代码中，我们正在初始化我们电脑的网络摄像头。</p><pre class="lc ld le lf gt nm nn no np aw nq bi"><span id="23e3" class="mn mo iq nn b gy nr ns l nt nu">vs= VideoStream(src=0).start()</span></pre><p id="cb08" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在下面给出的代码中，我们只是读取每一帧，并根据face_recognition库中的模型将其转换为标准颜色格式。</p><p id="cdf1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们使用face_location函数检测视频帧中的人脸位置，并在代码的最后一行生成其编码。</p><pre class="lc ld le lf gt nm nn no np aw nq bi"><span id="91bc" class="mn mo iq nn b gy nr ns l nt nu">while True: <br/>    frame = vs.read()<br/>    rgb = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)<br/>    rgb = imutils.resize(rgb,width=750)<br/>    r =frame.shape[1]/float(rgb.shape[1])<br/>    boxes= face_recognition.face_locations(rgb,model="cnn") <br/>    encodings =face_recognition.face_encodings(rgb,boxes) <br/>    names=[]</span></pre><p id="8abc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，在下面的代码中，我们将帧的编码与已经存储的人脸编码进行比较，如果我们发现差异低于某个阈值，则认为该帧包含编码已经存储的人的人脸。</p><pre class="lc ld le lf gt nm nn no np aw nq bi"><span id="4af7" class="mn mo iq nn b gy nr ns l nt nu">for encoding in encodings:<br/>    matches=<br/>    face_recognition.compare_faces("encoding.pickle",encoding)       <br/>    name="Unknown"  print(matches)<br/>    if True in matches:<br/>       matchesIdx =[i for (i,b) in matches if b] <br/>       counts={}<br/>       for i in matchesIdx: <br/>           name = data["names"][i]<br/>           counts[name]= counts.get(name,0)+1 <br/>       name =max(counts,key= count.get)<br/>   names.append(name)</span></pre><p id="cfee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，在下面的代码中，我们只是在脸部周围画一些方框，并在上面显示这个人的名字。</p><pre class="lc ld le lf gt nm nn no np aw nq bi"><span id="5edd" class="mn mo iq nn b gy nr ns l nt nu">for((top,right,bottom,left),name) in zip(boxes,names):  <br/>    top=int(top*r)<br/>    right=int(right*r) <br/>    bottom=int(bottom*r)  <br/>    left=int(left*r)  <br/>    cv2.rectangle(frame,(left, top),(right, bottom),(0,255,0),2) <br/>    y=top-15 if top-15&gt;15 else top+15  <br/>    cv2.putText(frame,name ,(left,y),cv2.FONT_HERSHEY_SIMPLEX,0.75,<br/>    ((0,255,0),2) <br/>cv2.destroyAllWindows()vs.stop()</span></pre><p id="e832" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">万岁…你做到了。恭喜你开发出第一个高级人脸识别模型。</p><h2 id="7c42" class="mn mo iq bd mp mq mr dn ms mt mu dp mv ko mw mx my ks mz na nb kw nc nd ne nf bi translated">结论:</h2><p id="dd3d" class="pw-post-body-paragraph kf kg iq kh b ki ng jr kk kl nh ju kn ko ni kq kr ks nj ku kv kw nk ky kz la ij bi translated">虽然代码乍一看似乎很复杂，但整个代码背后的概念非常简单。好吧，让我给你简单介绍一下我们所做的一切。首先，我们为所有可用的图像生成了编码。现在，在检测时，我们只是将正在检测的人的编码与已经存储的人的编码进行比较。所以很明显同一个人会表现出较少的差异。如果差异没有超过阈值，我们会将该人脸标记为未知人。简单！！</p><p id="431f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">完整代码可以访问我的<a class="ae lr" href="https://github.com/shobhitsrivastava-ds/Occlusion-based-face-detection/" rel="noopener ugc nofollow" target="_blank"> <em class="nl"> Github简介</em> </a></p><p id="5410" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你喜欢的内容，并希望更多这样的，跟着我一样。</p><p id="cb79" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">谢谢你</p></div></div>    
</body>
</html>