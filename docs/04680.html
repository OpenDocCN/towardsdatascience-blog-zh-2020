<html>
<head>
<title>HDFS Erasure Coding</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">HDFS擦除编码</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/simplifying-hdfs-erasure-coding-9d9588975113?source=collection_archive---------31-----------------------#2020-04-25">https://towardsdatascience.com/simplifying-hdfs-erasure-coding-9d9588975113?source=collection_archive---------31-----------------------#2020-04-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="aef4" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">通过利用擦除编码，显著降低HDFS集群的存储开销</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/e07982e38b59d58f0a4b52b159047c81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dvZcq0zHB_Sq1C7Q1C1rXg.png"/></div></div></figure><p id="5e7d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">假设:</p><p id="7be4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">您已经了解并内化了Hadoop分布式文件系统或HDFS的基本概念— <a class="ae ln" rel="noopener" target="_blank" href="/hadoop-distributed-file-system-b09946738555">数据块&amp;复制因子、存储&amp;复制和机架感知</a></p></div><div class="ab cl lo lp hu lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="ij ik il im in"><h2 id="6888" class="lv lw iq bd lx ly lz dn ma mb mc dp md la me mf mg le mh mi mj li mk ml mm mn bi translated"><strong class="ak">背景</strong></h2><p id="d1bb" class="pw-post-body-paragraph kr ks iq kt b ku mo jr kw kx mp ju kz la mq lc ld le mr lg lh li ms lk ll lm ij bi translated">Hadoop分布式文件系统(HDFS)数据块和复制方法有两个关键概念，即“数据块大小”和“复制因子”。进入HDFS的每个文件都被分成几个块或“区块”。块数取决于分配的最大块大小，通常为128 MB。创建数据块后，它们会在HDFS集群中复制。副本的数量由复制因子(RF)决定，通常配置为3 (1份原件和2份副本)。这种冗余有助于建立弹性和容错能力，也就是说，当一个数据块出现故障时，我们可以从另一个数据块安全地恢复数据。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mt"><img src="../Images/a4029f7f098ce0e9048179a8c45f289c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5uMChLGcPlCMTJI3u9E-ng.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">基于块大小的文件分割= 128 MB</p></figure><p id="96ab" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">上图是我们刚刚讨论过的分割的快速演示。一个700 MB的文件被分成6个块。128 MB的5份和60 MB的1份。复制系数为3时，它将消耗(6*3) = 18个数据块和(700 MB * 3) = 2100 MB的存储。考虑将其扩展到Pb级，您将很快意识到由于数据复制带来的冗余而导致的可用空间的严重利用不足。</p><p id="d6a9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">因此，对于3-n/3路复制(即RF = 3)，其中n =副本数量，我们有2个复制的数据块，即200%的存储开销，效率为(1/n)或(1/3)或33%，n-1 = 2作为容错。更不用说创建、维护和执行BAU活动的网络和I/O使用情况了。</p><p id="8b7c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">虽然廉价的存储和出色的网络带宽是当今世界的现实，但这种为容错和弹性建立冗余的方法仍然非常低效。这带来了一种新的模式，可以显著提高保护数据的效率。</p><h2 id="8d57" class="lv lw iq bd lx ly lz dn ma mb mc dp md la me mf mg le mh mi mj li mk ml mm mn bi translated">擦除编码</h2><p id="4f4b" class="pw-post-body-paragraph kr ks iq kt b ku mo jr kw kx mp ju kz la mq lc ld le mr lg lh li ms lk ll lm ij bi translated">通过英特尔和Cloudera的优秀人员的共同努力，擦除编码(EC)在3.x版中被引入Hadoop。</p><p id="fa9e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">继续同一个示例，一旦数据在HDFS被分割成几个块，它就作为输入被传递给EC，EC返回许多奇偶校验块。这个过程称为编码，而(数据+奇偶校验块)称为编码组。在失败(也称为擦除)的情况下，可以从该编码组中重建数据，称为解码。</p><p id="9317" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">引擎盖下发生了什么？</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi my"><img src="../Images/626faba2b82206d72858b03aae73c288.png" data-original-src="https://miro.medium.com/v2/resize:fit:846/format:webp/1*uwwvMsdO9PxFKT4Y9JZjHw.png"/></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">对OR和XOR有基本的数学理解</p></figure><p id="13a4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在被称为⊕的<strong class="kt ir">异或</strong>或<strong class="kt ir">异或编码</strong>中，数据(INs)通过被称为异或的数学运算传递，结果(OUT)为单个奇偶校验块，如上所示。此外，XOR有两个漂亮的数学特性:</p><blockquote class="mz"><p id="1302" class="na nb iq bd nc nd ne nf ng nh ni lm dk translated"><em class="nj">可交换的</em> : B1⊕ B2 = B2⊕ B1</p><p id="c065" class="na nb iq bd nc nd ne nf ng nh ni lm dk translated"><em class="nj">联想</em>:b1⊕【b2⊕B3】=【b1⊕b2]⊕B3</p></blockquote><p id="277c" class="pw-post-body-paragraph kr ks iq kt b ku nk jr kw kx nl ju kz la nm lc ld le nn lg lh li no lk ll lm ij bi translated">意思是——输入的排列不会改变输出。</p><p id="1bbf" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">作为推论，我们可以扩展到我们的示例，使用6个数据块作为输入，我们将在磁盘上总共消耗7个存储块，6个数据块和1个奇偶校验块。与HDFS的三向复制相比，这显著提高了效率。并且如果任何一个数据块失败，例如如果B2失败，则剩余的块被异或，即b1⊕<strong class="kt ir"><em class="np">P1</em></strong>⊕b3⊕b4⊕b5⊕b6，以恢复丢失的数据B2。然而，≥2个同时故障且数据<em class="np">不可恢复</em>。因此，XOR最多可以容忍1次故障，效率为((n-1)/n)或约83%，其中n =数据块的总数。由于XOR具有低容错性，所以它对于HDFS的要求来说是完全不可接受的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/ed4a0c03ce5536784d09d68d5f420040.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*StX-YGZvN2qOfwgB66WVVw.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">里德·所罗门编码(<a class="ae ln" href="https://www.usenix.org/legacy/event/fast09/tech/full_papers/plank/plank.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="8708" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">Reed-Solomon</strong><strong class="kt ir">【RS】</strong><strong class="kt ir">编码</strong>通过使用复数线性代数生成多个奇偶校验块，解决了HDFS处理多个同时失效的需求。RS编码表示为RS₍ₖ,ₘ₎，使用两个参数，其中k是数据块的向量，m是奇偶校验块的数量。这是通过将数据块向量k乘以生成矩阵(Gᵀ)得到长度= (k+m)或长度=(数据+奇偶校验)的Codeword₍ₖ₊ₘ₎向量而生成的，如上图所示。</p><p id="a070" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">当故障发生时，通过将剩余的块(或幸存者)乘以生成矩阵的逆矩阵来进行恢复，前提是k个块总是可用的。因此，最多可以容忍m个故障。在我们的示例中，使用k &amp; m的最佳实践参数，即RS(6，3)，具有6个数据块的文件将消耗磁盘上的9个存储块(即6个数据块和3个奇偶校验块)，或者每2个数据块消耗1个奇偶校验块。因此，只需要50%的存储开销，效率为(k/(k+m))或约67%。</p><p id="5254" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">还有另一种流行的RS配置，即RS(10，4)，其效率为(k/(k+m))或约71%，存储开销约为50%。</p><h2 id="4fdb" class="lv lw iq bd lx ly lz dn ma mb mc dp md la me mf mg le mh mi mj li mk ml mm mn bi translated"><strong class="ak">选择正确的区块布局</strong></h2><p id="f578" class="pw-post-body-paragraph kr ks iq kt b ku mo jr kw kx mp ju kz la mq lc ld le mr lg lh li ms lk ll lm ij bi translated">我希望到现在为止，你们都支持HDFS的(6，3)或(10，4)配置的Reed Solomon擦除编码。</p><p id="011b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在<strong class="kt ir">连续块布局</strong>中，你在HDFS基础上有一个更简单的实现。考虑部署在连续块布局上的HDFS EC RS(10，4 ),块大小固定为128 MB。无论您有10个数据块还是1个数据块要写入，都会写入4个奇偶校验块。因此，对于单个数据块(比如B5)，存储效率开销现在约为400%,比三向复制还要糟糕。我们所有的存储效率收益都化为乌有。为了证明从HDFS三向复制切换到具有连续布局的EC的合理性，需要写入所有10个数据块。同样，对于具有相同块布局的RS(6，3)，我们需要6个写入的数据块来确保存储效率。</p><p id="c906" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">根据几个项目的个人经验和Cloudera的行业研究(参考下文)，存储在HDFS的大约70–95%的数据小于1个数据块或128 MB。在<strong class="kt ir">条带化块布局</strong>中，文件被“条带化”为较小的大小，通常为64 KB或1 MB数据“单元”。因此，无论我们使用RS(10，4)还是RS(6，3)，创建的奇偶校验单元都不会对存储开销产生太大影响。</p><p id="565a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最重要的是，HDFS <em class="np">允许在集群中的目录或文件级配置不同的复制和擦除编码策略</em>。<em class="np"> </em>由于文件大小是块布局的决定因素，从数据持久性和存储效率的角度来看，在文件/目录级别应用擦除编码策略的能力非常有益。</p><h2 id="68db" class="lv lw iq bd lx ly lz dn ma mb mc dp md la me mf mg le mh mi mj li mk ml mm mn bi translated">HDFS的建筑变革</h2><p id="686f" class="pw-post-body-paragraph kr ks iq kt b ku mo jr kw kx mp ju kz la mq lc ld le mr lg lh li ms lk ll lm ij bi translated">为了用条带化布局处理EC，进行了某些体系结构上的更改。</p><p id="a1b9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">名称节点扩展</strong>:</p><p id="d1d1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">文件的逻辑块或字节范围已从存储块中分离出来，存储块在数据节点中存储实际的数据块。HDFS命名节点现在将其块ID分别映射到数据节点的存储块和逻辑块。这在名称节点上产生了大约250–440%的巨大存储开销。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/755a7a5da2e23ed2969ec51294211f05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jlN3ggouOU3dnQSQGukfRQ.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">具有3个部分的分层块</p></figure><p id="bc07" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">因此，引入了一种新的分层块命名协议来解决空间使用过度增长的问题。我们不是基于时间戳顺序分配块id，而是将块映射分成3个部分，如上所述。<em class="np">注意，对于连续区块布局，只有2个部分</em>。因此，神经网络能够以摘要-细节或分层协议的形式管理逻辑和存储块，并将开销限制在大约21–76%。</p><p id="a4a4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">客户端扩展</strong>:</p><p id="53f4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">将DFSInputStream (Java数据类型)扩展为DFS<strong class="kt ir">Striped</strong>InputStream，将DFSOutputStream (Java数据类型)扩展为DFS<strong class="kt ir">Striped</strong>OutputStream，以适应数据分条和EC。由于逻辑块和存储块现在是分开的，使用*条带化*数据类型，我们可以在HDFS实现块的并行创建/处理。</p><p id="147c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">数据节点扩展</strong>:</p><p id="4a3c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">神经网络识别丢失的块，并将恢复分配给数据节点。这由一个新的组件来处理，即ECW或<strong class="kt ir"> ErasureCodingWorker </strong>、<strong class="kt ir"> </strong>，它执行三个任务。首先，它向所有没有失败的数据源发送一个读请求。第二，使用英特尔优化的Reed Solomon Erasure编解码器框架，<a class="ae ln" href="https://www.youtube.com/watch?v=2wn79fy2XyQ&amp;list=PLg-UKERBljNyTX8RGRxKnHP7GZ0UP3sST&amp;index=8&amp;t=0s" rel="noopener ugc nofollow" target="_blank"> <strong class="kt ir"> ISA-L </strong> </a>，ECW对数据进行解码。第三，它将恢复的数据推送到故障数据节点。</p><p id="1044" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最后，让我们总结一下到目前为止我们所讨论的利弊:</p><h2 id="a152" class="lv lw iq bd lx ly lz dn ma mb mc dp md la me mf mg le mh mi mj li mk ml mm mn bi translated"><strong class="ak">优点</strong></h2><ul class=""><li id="029f" class="ns nt iq kt b ku mo kx mp la nu le nv li nw lm nx ny nz oa bi translated">在线电子商务支持:将数据实时转换为电子商务，从而立即节省存储空间，并完全避免临时/导入后数据转换过程。</li><li id="4aa5" class="ns nt iq kt b ku ob kx oc la od le oe li of lm nx ny nz oa bi translated">低存储开销:将存储开销降低到仅50%左右。</li><li id="661b" class="ns nt iq kt b ku ob kx oc la od le oe li of lm nx ny nz oa bi translated">向后兼容:HDFS的大多数功能，如快照、加密和缓存，在EC模式下也可用。</li></ul><h2 id="5759" class="lv lw iq bd lx ly lz dn ma mb mc dp md la me mf mg le mh mi mj li mk ml mm mn bi translated"><strong class="ak">限制</strong></h2><ul class=""><li id="1ce8" class="ns nt iq kt b ku mo kx mp la nu le nv li nw lm nx ny nz oa bi translated">由于架构的变化，HDFS的一些原生特性，如hflush、hsync和append在EC模式下不可用。然而，作为HDFS-欧共体第二阶段的一部分，这一问题可能会得到解决。</li><li id="ced4" class="ns nt iq kt b ku ob kx oc la od le oe li of lm nx ny nz oa bi translated">在线/离线EC对集群提出了大量带宽和IO要求。但是，带宽与存储效率和耐用性之间的权衡应该被视为一种微妙的平衡，因为当使用EC进行条带化时，这种权衡是真正有益的。</li></ul></div><div class="ab cl lo lp hu lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="ij ik il im in"><p id="3a50" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">参考文献</strong>:</p><p id="a275" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">[1] <a class="ae ln" href="https://hadoop.apache.org/docs/r3.0.0/hadoop-project-dist/hadoop-hdfs/HDFSErasureCoding.html" rel="noopener ugc nofollow" target="_blank"> HDFS擦除编码</a> (2017)，Apache Hadoop，ASF</p><p id="6f99" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">[2] A.Wang，Z. Zhang，K. Zheng，U. Maheshwara和V. Kumar，<a class="ae ln" href="https://blog.cloudera.com/introduction-to-hdfs-erasure-coding-in-apache-hadoop/" rel="noopener ugc nofollow" target="_blank">Apache Hadoop中的擦除编码介绍</a> (2015)，Cloudera</p><p id="171a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">J. Plank教授，<a class="ae ln" href="http://web.eecs.utk.edu/~jplank/plank/papers/2013-02-11-FAST-Tutorial.pdf" rel="noopener ugc nofollow" target="_blank">存储应用擦除编码教程，第1部分</a> (2013)，田纳西大学EECS系</p></div><div class="ab cl lo lp hu lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="ij ik il im in"><div class="kg kh ki kj gt og"><a href="https://medium.com/@prathamesh.nimkar/big-data-analytics-using-the-hadoop-ecosystem-411d629084d3" rel="noopener follow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd ir gy z fp ol fr fs om fu fw ip bi translated">使用Hadoop生态系统的大数据分析渠道</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">登录页面</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">medium.com</p></div></div><div class="op l"><div class="oq l or os ot op ou kp og"/></div></div></a></div></div></div>    
</body>
</html>