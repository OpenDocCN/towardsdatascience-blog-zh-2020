<html>
<head>
<title>Neural Network Calibration with Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于 Keras 的神经网络校准</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/neural-network-calibration-with-keras-76fb7c13a55?source=collection_archive---------7-----------------------#2020-04-14">https://towardsdatascience.com/neural-network-calibration-with-keras-76fb7c13a55?source=collection_archive---------7-----------------------#2020-04-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f58a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在真实场景中调整神经网络概率分数</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/cac953814b27f01f6ffbdd141271c255.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BouwzWxZGctLIF2G"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae ky" href="https://unsplash.com/@_lewis_f?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Lewis Fagg </a>拍照</p></figure><p id="fdf6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">概率的概念在机器学习领域很常见。在分类任务中，概率是几乎每个预测模型的输出分数以及相对标签。将它们显示在一起比只提供原始分类报告更能提供信息。通过这种方式，我们使用概率作为置信分数来近似我们的模型预测的不确定性。这是一种常见的做法，反映了我们的推理方式。</p><p id="f80e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">问题是我们的算法不够智能，无法以可信的置信度分数的形式提供概率。他们倾向于不校准结果，也就是说，如果我们将结果与预期的准确度进行比较，他们会高估或低估概率。这导致了误导性的可靠性，破坏了我们的决策政策。</p><p id="bb09" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我们想用概率来处理神经网络校准的问题。正如我们将看到的，建立一个校准的模型不是显而易见的，我们必须在开发过程中小心谨慎。我们操作适当的技术来校准真实分类问题中的分数，以使<em class="lv">不会在<em class="lv"> </em>自动拍卖中被踢</em>，在自动拍卖中，风险是购买一个<em class="lv">柠檬</em>。</p><h1 id="8884" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">数据</h1><p id="b357" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">数据集是从 Kaggle 收集的，来自过去的比赛'<a class="ae ky" href="https://www.kaggle.com/c/DontGetKicked" rel="noopener ugc nofollow" target="_blank"> <em class="lv">不要被踢！</em></a>’。<em class="lv">这个比赛的挑战是预测在拍卖会上购买的汽车是否是一个好东西</em>。当车辆出现严重问题或其他一些不可预见的问题时，经常会导致跳车，给经销商造成很高的成本。我们必须找出哪些汽车被淘汰的风险更高，从而为经销商提供真正的价值。该问题可以作为一个二进制分类任务来进行(<em class="lv">好坏买？</em>)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/4ca10a7f2e5bea05c30e486c03f9acab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1222/format:webp/1*mG7GLHtbBqUjjXCg8hjZWA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">标签分发</p></figure><p id="5232" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以处理的变量是分类变量和数字变量的混合:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/800e3082a46605565784db77c3d5526b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PQ4F_jvOrpiZn72ZFvsX5g.png"/></div></div></figure><p id="a06c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们操作一个标准的预处理:NaNs 值用中位数(对于数值)和“未知”类(对于分类)填充。然后对数值变量进行标准缩放，对分类变量进行普通编码。</p><h1 id="bf30" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">模型</h1><p id="f218" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">用于预测我们的购买是否划算的模型是一个具有分类嵌入的前馈神经网络。类别嵌入在第二层连接，而在最后部分，我们保持原始输出层(logits)和激活(softmax)之间的分离，用于概率计算。当我们需要校准模型时，这个小技巧会对我们有用。</p><pre class="kj kk kl km gt mv mw mx my aw mz bi"><span id="248a" class="na lx it mw b gy nb nc l nd ne">def get_model(cat_feat, emb_dim=8):<br/>    <br/>    def get_embed(inp, size, emb_dim, name):</span><span id="d019" class="na lx it mw b gy nf nc l nd ne">        emb = Embedding(size, emb_dim)(inp)<br/>        emb = Flatten(name=name)(emb)</span><span id="585e" class="na lx it mw b gy nf nc l nd ne">        return emb<br/>    <br/>    inp_dense = Input(shape=len(num_))<br/>    <br/>    embs, inps = [], [inp_dense]<br/>    <br/>    x = Dense(128, activation='relu')(inp_dense)<br/>    <br/>    for f in cat_feat:<br/>        inp = Input((1,), name=f+'_inp')<br/>        embs.append(get_embed(inp, cat_[f]+1, emb_dim, f))<br/>        inps.append(inp)<br/>        <br/>    x = Concatenate()([x]+embs)<br/>    x = BatchNormalization()(x)<br/>    x = Dropout(0.3)(x)<br/>    x = Dense(64, activation='relu')(x)<br/>    x = Dropout(0.3)(x)<br/>    x = Dense(32, activation='relu')(x)<br/>    <br/>    logits = Dense(2, name='logits')(x)<br/>    out = Activation('softmax')(logits)<br/>    <br/>    model = Model(inps, out)<br/>    model.compile(optimizer='adam', <br/>                  loss ='categorical_crossentropy', <br/>                  metrics=[tf.keras.metrics.AUC()])<br/>    <br/>    return model</span></pre><p id="7efe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们在训练、验证和测试中分离初始数据集。验证将首先用于网络调谐，然后在第二阶段拟合校准程序的温度标度系数。拟合后，我们在测试数据上实现了 0.90%的精确度，这比将所有汽车分类为好交易的随机模型要好。</p><h1 id="a552" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">神经网络校准</h1><p id="1efc" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">正如我们所看到的，我们的模型可以在看不见的数据上提供良好的性能。但是<em class="lv">这个结果有多靠谱？</em>预测校准良好的概率的优点是，如果预测的概率接近 1 或 0，我们可以有信心，否则就不那么有信心。在我们的例子中，如果没有，我们的分类器可能会过度预测类似的汽车为“<em class="lv">柠檬</em>”，这可能导致不购买实际上状况良好的汽车的决定。</p><p id="ff76" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据定义，如果对于任何概率值 p，对应于具有 p*100 %精度水平的类别预测，则模型被完美校准。为了检查我们的分类器是否校准良好，我们需要做的就是绘制一个图！同时，产生校准概率非常简单，因为应用了后处理技术。</p><p id="e711" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第一步是绘制可靠性图，在这里我们可以比较预期的准确性和预测的可信度。为方便起见，每个等宽组/箱计算阳性分数和平均预测值。这可以针对二元或多类问题进行计算，并为每个类生成一条曲线。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/ec1806a8dced59b89e5d72e648855c8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zE3K_-n5x_fOM2h__h-LuQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">校准前的可靠性图</p></figure><p id="d254" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最佳情况是当我们在计算的概率和阳性分数之间有一个完美的线性关系时(蓝色虚线)。在我们的例子中，我们的神经网络倾向于分别高估和低估中间两类的概率。我们可以用一个适当的指数来量化校准的好坏，即所谓的预期校准误差(ECE)，即预期精度和预测置信度之间差异的加权(每个箱中样本的比例)平均值(越低越好)。</p><p id="6cce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以通过应用一种技术来调整 ECE，这种技术是温度缩放的扩展，称为普拉特缩放。神经网络输出一个称为 logits 的向量。Platt scaling 简单地将 logits 向量除以一个学习到的标量参数<em class="lv"> T，</em>，然后将其传递给 softmax 函数以获得类概率。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/3d53e1fe8d2895501c71a154b19015f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/1*4buVAqjWvFJFvh0Ts9i1yA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">y_hat 是预测值，z 是逻辑值，<em class="ni"> T </em>是学习参数</p></figure><p id="319e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">实际上，只需几行代码，我们就可以构建自己的函数来计算温度比例。比例因子<em class="lv"> T </em>是在预定义的验证集上学习的，其中我们试图最小化平均成本函数(在 tensor flow:<em class="lv">TF . nn . soft max _ cross _ entropy _ with _ logits</em>)。输入和输出将分别是我们的逻辑值，用可学习的<em class="lv"> T </em>进行缩放，以及虚拟向量形式的真实输出。列车是用随机梯度下降法经典计算的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/79cbfedf95555b47a82d30a7f5210b62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rYugY8tOlt0boE_NXJ7nsg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">校准后的可靠性图</p></figure><p id="0004" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，两个班级的 ECE 分数都有所提高。正如我们在上面新的可靠性图表中看到的，我们可以得到更精确的概率。</p><h1 id="ac10" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">摘要</h1><p id="bbc7" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在这篇文章中，我们研究了一种后处理技术来校准我们的神经网络的概率，并在可能的情况下(并非总是温度标度有效)，让它成为一种更可信的工具。这是一个非常简单的技巧，适用于任何地方，如果我们关心我们的模型计算决策的概率，这变得很有用。</p></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><p id="714e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://github.com/cerlymarco/MEDIUM_NoteBook" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">查看我的 GITHUB 回购</strong> </a></p><p id="65c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">保持联系:<a class="ae ky" href="https://www.linkedin.com/in/marco-cerliani-b0bba714b/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a></p></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><p id="17b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">参考文献</strong></p><ul class=""><li id="e24e" class="nr ns it lb b lc ld lf lg li nt lm nu lq nv lu nw nx ny nz bi translated"><a class="ae ky" href="https://medium.com/stellargraph/graph-neural-network-model-calibration-for-trusted-predictions-e49628487e7b" rel="noopener">StellarGraph——图上的机器学习</a></li><li id="6685" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated">关于现代神经网络的校准:郭川，杰夫·普莱斯，孙玉，基利安·q·温伯格</li></ul></div></div>    
</body>
</html>