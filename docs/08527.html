<html>
<head>
<title>Siamese Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">暹罗网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/siamese-networks-line-by-line-explanation-for-beginners-55b8be1d2fc6?source=collection_archive---------5-----------------------#2020-06-21">https://towardsdatascience.com/siamese-networks-line-by-line-explanation-for-beginners-55b8be1d2fc6?source=collection_archive---------5-----------------------#2020-06-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f530" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">针对初学者的逐行解释</h2></div><h1 id="0a7e" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">摘要</h1><p id="7342" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi lw translated"><span class="l lx ly lz bm ma mb mc md me di">S</span>iamesse网络是一类能够一次性学习的神经网络。这篇文章针对深度学习初学者，他们熟悉python和卷积神经网络的基础知识。我们将逐行解释如何使用Python中的Keras实现暹罗网络。当您浏览代码时，如果您觉得有些事情可以用更好的方式解释或完成，请随时发表评论。</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mf"><img src="../Images/fb1a3179000de384f2388fbd214ecb57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WnshPm2314PxXiSS24w15Q.jpeg"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">图片由<a class="ae mv" href="https://pixabay.com/users/geralt-9301/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=4550606" rel="noopener ugc nofollow" target="_blank"> Gerd Altmann </a>从<a class="ae mv" href="https://pixabay.com/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=4550606" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>拍摄</p></figure><h1 id="144b" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">介绍</h1><p id="1b79" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">让我们假设我们有一个1000名员工的公司。我们决定实施面部识别系统来记录你的员工的出勤情况。如果我们使用传统的神经网络，我们将不得不面对两个主要问题。第一个是数据集。从我们每个员工那里收集大量的数据集几乎是不可能的，我们最终会得到每个员工最多5张照片。但是传统的CNN(卷积神经网络)无法学习如此小的集合的特征。我们最终还会得到1000个输出类。让我们考虑一下，不知何故，我们从每个员工那里获得了一个巨大的数据集，我们训练了一个非常好的CNN模型。当一名新员工加入我们的组织时会发生什么？我们如何将此人纳入我们的面部识别系统？所有这些缺点都可以通过使用连体网络来克服。在这篇文章中，我们将使用暹罗网络进行一次性学习实验，该网络专注于差异而不是特征匹配。</p><p id="98ed" class="pw-post-body-paragraph la lb it lc b ld mw ju lf lg mx jx li lj my ll lm ln mz lp lq lr na lt lu lv im bi translated">我们计算不同类别的图像之间的相似性得分，而不是使用每个类别的大量数据。这个网络的输入将是属于相同类别或不同类别的两个图像。输出将是范围在0和1之间的浮点数，其中1表示两个图像属于同一类，0表示它们来自不同的图像。让我首先解释它与使用CNN架构的图像分类有何不同。</p><h1 id="ab00" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">体系结构</h1><p id="49d1" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在CNN模型中，有一系列卷积层和池层，后面是一些密集层和一个可能带有softmax函数的输出层。这里的卷积层负责从图像中提取特征，而softmax层负责为每个类别提供一个概率范围。然后，我们决定具有最高概率值的神经元的图像类别。</p><p id="79fc" class="pw-post-body-paragraph la lb it lc b ld mw ju lf lg mx jx li lj my ll lm ln mz lp lq lr na lt lu lv im bi translated">看看<a class="ae mv" rel="noopener" target="_blank" href="/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53">这篇伟大的文章</a>了解更多关于CNN如何工作的信息。</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi nb"><img src="../Images/0239cc890f84217c4eb8e3f9fab657e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vkQ0hXDaQv57sALXAJquxA.jpeg"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">传统CNN架构由<a class="nc nd ep" href="https://medium.com/u/631ee5e6343e?source=post_page-----55b8be1d2fc6--------------------------------" rel="noopener" target="_blank">苏米特·萨哈</a></p></figure><p id="4fc5" class="pw-post-body-paragraph la lb it lc b ld mw ju lf lg mx jx li lj my ll lm ln mz lp lq lr na lt lu lv im bi translated">对于暹罗网络，除了没有softmax层之外，它具有类似的卷积层和池层构成。所以，我们从致密层开始。如前所述，由于网络有两个图像作为输入，我们将得到两个密集层。现在我们计算这两层的差异，并将结果输出到具有sigmoid激活函数(0到1)的单个神经元。因此，这个网络的训练数据必须以这样一种方式构造，即有一个由两个图像和一个变量0或1组成的列表。</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi ne"><img src="../Images/2fe25c83e3be9f2617b32059cfe84553.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eMehqF0SloigS1tppMEiEw.png"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">暹罗网络</p></figure><p id="b89b" class="pw-post-body-paragraph la lb it lc b ld mw ju lf lg mx jx li lj my ll lm ln mz lp lq lr na lt lu lv im bi translated"><strong class="lc iu">注意:</strong>只有一个网络，两个图像通过同一个网络。只是有两个输入。因此，两个输入将从卷积层和密集层通过相同的权重矩阵。</p><p id="c6bf" class="pw-post-body-paragraph la lb it lc b ld mw ju lf lg mx jx li lj my ll lm ln mz lp lq lr na lt lu lv im bi translated">如果你仍然不清楚这是如何工作的，参考这个<a class="ae mv" href="https://www.youtube.com/watch?v=6jfw8MuKwpI" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><h1 id="54c2" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">密码</h1><p id="60df" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在这篇文章中，我使用了Kaggle的<a class="ae mv" href="https://www.kaggle.com/moltean/fruits" rel="noopener ugc nofollow" target="_blank"> Fruits 360 </a>数据集。但是，可以随意试验其他数据集。代码托管在Kaggle中。如果您对代码有疑问，请随意使用下面的笔记本，亲自体验一下。</p><p id="c023" class="pw-post-body-paragraph la lb it lc b ld mw ju lf lg mx jx li lj my ll lm ln mz lp lq lr na lt lu lv im bi translated"><a class="ae mv" href="https://www.kaggle.com/krishnaprasad96/siamese-network" rel="noopener ugc nofollow" target="_blank"><strong class="lc iu"><em class="nf">https://www.kaggle.com/krishnaprasad96/siamese-network</em></strong></a></p><h2 id="c762" class="ng kj it bd kk nh ni dn ko nj nk dp ks lj nl nm ku ln nn no kw lr np nq ky nr bi translated">导入库</h2><p id="e1ec" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">让我们从导入我们正在使用的库开始。如前所述，这段代码使用Keras构建模型，使用NumPy，pillow进行数据预处理。</p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="e6ca" class="pw-post-body-paragraph la lb it lc b ld mw ju lf lg mx jx li lj my ll lm ln mz lp lq lr na lt lu lv im bi translated">注意:不要将Keras作为"<em class="nf">从tensorflow导入Keras </em></p><h2 id="3620" class="ng kj it bd kk nh ni dn ko nj nk dp ks lj nl nm ku ln nn no kw lr np nq ky nr bi translated">数据预处理</h2><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="ns nt l"/></div></figure><ul class=""><li id="ee4d" class="nu nv it lc b ld mw lg mx lj nw ln nx lr ny lv nz oa ob oc bi translated"><strong class="lc iu">第1行:</strong>包含数据集的基础目录</li><li id="f8ed" class="nu nv it lc b ld od lg oe lj of ln og lr oh lv nz oa ob oc bi translated">第2行:表示将用于培训的百分比。其余的将用于测试</li><li id="0891" class="nu nv it lc b ld od lg oe lj of ln og lr oh lv nz oa ob oc bi translated"><strong class="lc iu">第三行:</strong>由于Fruits 360是一个用于图像分类的数据集，所以它每个类别都有很多图像。但是对于我们的实验来说，一小部分就足够了</li><li id="007d" class="nu nv it lc b ld od lg oe lj of ln og lr oh lv nz oa ob oc bi translated"><strong class="lc iu">第6行:</strong>从文件夹中获取目录列表。每个文件夹都属于一个类</li><li id="3948" class="nu nv it lc b ld od lg oe lj of ln og lr oh lv nz oa ob oc bi translated"><strong class="lc iu">第10–13行:</strong>声明三个空列表，记录X(图片)，y(标签)，cat_list(记录每张图片的类别)</li><li id="2c13" class="nu nv it lc b ld od lg oe lj of ln og lr oh lv nz oa ob oc bi translated"><strong class="lc iu">第16–24行:</strong>遍历类文件夹，从每个类中选择10张图像，将它们转换成RGB格式，并附加到一个列表中。在cat_list[]中记录图像的类别，以备将来参考</li><li id="1dca" class="nu nv it lc b ld od lg oe lj of ln og lr oh lv nz oa ob oc bi translated"><strong class="lc iu">第26–28行</strong>:将所有列表转换成NumPy数组。因为任何图像的范围都是从0到255，所以为了简化，将数组x除以255</li></ul><h2 id="230d" class="ng kj it bd kk nh ni dn ko nj nk dp ks lj nl nm ku ln nn no kw lr np nq ky nr bi translated">列车测试分离</h2><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="ns nt l"/></div></figure><ul class=""><li id="b2d6" class="nu nv it lc b ld mw lg mx lj nw ln nx lr ny lv nz oa ob oc bi translated"><strong class="lc iu">第1行:</strong>通过乘以train_test_split计算将用于训练的类的数量</li><li id="a2c0" class="nu nv it lc b ld od lg oe lj of ln og lr oh lv nz oa ob oc bi translated"><strong class="lc iu">第2行:</strong>从可用的总类中减去train_size，得到test_size</li><li id="260c" class="nu nv it lc b ld od lg oe lj of ln og lr oh lv nz oa ob oc bi translated"><strong class="lc iu">第4行:</strong>将train_size乘以每个类中的文件数，得到训练文件总数</li><li id="694c" class="nu nv it lc b ld od lg oe lj of ln og lr oh lv nz oa ob oc bi translated"><strong class="lc iu">第7–15行:</strong>将之前计算的值用于子集X、Y和cat_list</li></ul><h2 id="1666" class="ng kj it bd kk nh ni dn ko nj nk dp ks lj nl nm ku ln nn no kw lr np nq ky nr bi translated">生成批次</h2><p id="b3ba" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">此部分用于生成用于培训的批处理文件。批处理文件应该具有X和y。在图像分类的通常情况下，如果批处理大小为64，图像大小为(100，100，3)，则X的大小将是大小为64的列表，并且列表中的每个元素的大小将为(100，100，3)。</p><p id="38db" class="pw-post-body-paragraph la lb it lc b ld mw ju lf lg mx jx li lj my ll lm ln mz lp lq lr na lt lu lv im bi translated">在我们的例子中，因为我们有2个输入，所以将有一个大小为64的列表(假设为“A”)，并且“A”中的每个元素将有一个长度为2的列表(假设为“B”)，并且“B”中的每个元素的大小将为(100，100，3)。为了训练，我们将生成一个批处理，使得一半的输入对B[0]和B[1]属于同一类别。给这些图像对赋值0。对于另一半输入对，B[0]和B[1]属于不同的类别。给这些图像对赋值1。</p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="ns nt l"/></div></figure><ul class=""><li id="2016" class="nu nv it lc b ld mw lg mx lj nw ln nx lr ny lv nz oa ob oc bi translated"><strong class="lc iu">第3–7行:</strong>将x_train、cat_train的值以及训练规模的开始和结束规模存储在一个临时变量中</li><li id="d786" class="nu nv it lc b ld od lg oe lj of ln og lr oh lv nz oa ob oc bi translated"><strong class="lc iu">第9–11行:</strong>将Y的batch_size的一半指定为0，其他的指定为1</li><li id="a54b" class="nu nv it lc b ld od lg oe lj of ln og lr oh lv nz oa ob oc bi translated"><strong class="lc iu">第13行</strong>:从要使用的培训类别列表中随机生成一个类别列表。另外，追加两个image_size*batch_size数组</li><li id="063d" class="nu nv it lc b ld od lg oe lj of ln og lr oh lv nz oa ob oc bi translated"><strong class="lc iu">第17–25行</strong>:对于每次迭代，在batch_x[0]的情况下，从类别列表中指定的类别中选择一个图像。对于batch_x[1],如果y[i]为0，则从同一类别中选择图像，否则从除同一类别之外的任何其他类别中选择batch_x[1]</li></ul><h2 id="7d92" class="ng kj it bd kk nh ni dn ko nj nk dp ks lj nl nm ku ln nn no kw lr np nq ky nr bi translated">暹罗网络</h2><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="ns nt l"/></div></figure><ul class=""><li id="b1f4" class="nu nv it lc b ld mw lg mx lj nw ln nx lr ny lv nz oa ob oc bi translated"><strong class="lc iu">第1行:</strong>声明输入图像的形状。</li><li id="3dda" class="nu nv it lc b ld od lg oe lj of ln og lr oh lv nz oa ob oc bi translated"><strong class="lc iu">第2行:</strong>用图像的形状声明两个输入。</li><li id="ec57" class="nu nv it lc b ld od lg oe lj of ln og lr oh lv nz oa ob oc bi translated"><strong class="lc iu">第6–7行:</strong>声明初始化网络权重和偏差的参数。如论文中所述选择这些值。</li><li id="6f19" class="nu nv it lc b ld od lg oe lj of ln og lr oh lv nz oa ob oc bi translated"><strong class="lc iu">第9–20行:</strong>声明一个具有4个卷积层和最大池层的顺序模型。最后使用一个平整层，然后是一个致密层。</li><li id="aca5" class="nu nv it lc b ld od lg oe lj of ln og lr oh lv nz oa ob oc bi translated"><strong class="lc iu">第22–23行:</strong>将两个输入传递给同一个模型。</li><li id="f0fd" class="nu nv it lc b ld od lg oe lj of ln og lr oh lv nz oa ob oc bi translated"><strong class="lc iu">第25–27行</strong>:从两幅图像中减去密集层，并使其通过具有s形激活功能的单个神经元。</li><li id="10da" class="nu nv it lc b ld od lg oe lj of ln og lr oh lv nz oa ob oc bi translated"><strong class="lc iu">第29–30行:</strong>将带有损耗的模型编译为“二元交叉熵”和“亚当”优化器。</li><li id="0e1f" class="nu nv it lc b ld od lg oe lj of ln og lr oh lv nz oa ob oc bi translated"><strong class="lc iu">第32行:</strong><strong class="lc iu">siamese _ net</strong>的绘图模型函数输出如下。</li></ul><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi oi"><img src="../Images/a72524e191d0c2eb3ddd2aef5d117d87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PEXd_7LGfYQYYTahoriBAQ.png"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">暹罗网络</p></figure><h2 id="02d3" class="ng kj it bd kk nh ni dn ko nj nk dp ks lj nl nm ku ln nn no kw lr np nq ky nr bi translated">单向一次学习</h2><p id="388d" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">这是一个验证一次性学习的过程，我们挑选“n”个输入对，使得只有一个输入对属于同一类别，而其他所有输入对都来自不同类别。如果我们考虑9路单次验证，并且网络的每个输入需要两个图像，则x[0]对于所有9对都保持恒定，x[1]仅对于9对中的1属于x[0]的相同类别，而对于其他所有的都不同。如果所有的9对都给了该模型，则预期属于同一类别的对将具有9对中的最低值。在这种情况下，我们认为这是一次成功的预测。</p><p id="7ff2" class="pw-post-body-paragraph la lb it lc b ld mw ju lf lg mx jx li lj my ll lm ln mz lp lq lr na lt lu lv im bi translated">输入参数<strong class="lc iu"> n_val </strong>是指验证步骤的数量。<strong class="lc iu"> n_way </strong>指每个验证步骤的路数。记住，上面提到的x[0]在每个验证步骤中都保持不变。</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/88912d3deca888e6f4394f1e99809740.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/1*fllv47nDkHdGUDbMEwR4Ug.png"/></div></figure><p id="8d18" class="pw-post-body-paragraph la lb it lc b ld mw ju lf lg mx jx li lj my ll lm ln mz lp lq lr na lt lu lv im bi translated"><strong class="lc iu"> <em class="nf">(更深入的理解，请叉开Kaggle的笔记本，尝试从该功能调试每一行)</em> </strong></p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="ns nt l"/></div></figure><ul class=""><li id="8aa3" class="nu nv it lc b ld mw lg mx lj nw ln nx lr ny lv nz oa ob oc bi translated"><strong class="lc iu">第3–7行:</strong>将x_val，cat_test存储在一个临时变量中</li><li id="f209" class="nu nv it lc b ld od lg oe lj of ln og lr oh lv nz oa ob oc bi translated"><strong class="lc iu">第9行:</strong>这与批处理生成中的第13行相同，除了我们从测试集中创建了一批随机类别</li><li id="8366" class="nu nv it lc b ld od lg oe lj of ln og lr oh lv nz oa ob oc bi translated"><strong class="lc iu">第11–24行</strong>:对于每个验证步骤，我们遍历n_way，从class_list中取出相应的类别列表，从该类别中挑选一个图像，并将其存储在x[0]中。对于x[1],如果它是第一次迭代，则从相同的类别中选择一个图像，而对于其他图像，则从不同的类别中选择。这个内部循环几乎与上面讨论的batch_generation()方法相同。</li><li id="3fad" class="nu nv it lc b ld od lg oe lj of ln og lr oh lv nz oa ob oc bi translated"><strong class="lc iu">第26–31行:</strong>对于每个验证步骤，使用模型预测输出，并检查结果[0]与其他结果相比是否有最小值。请注意，结果数组将是一个大小为n_way的列表。如果是，在n_correct上加1。对所有其他验证步骤重复相同的步骤。</li><li id="27ba" class="nu nv it lc b ld od lg oe lj of ln og lr oh lv nz oa ob oc bi translated"><strong class="lc iu">第32行:</strong>使用n_correct和验证步骤数计算精度。</li></ul><h2 id="2a39" class="ng kj it bd kk nh ni dn ko nj nk dp ks lj nl nm ku ln nn no kw lr np nq ky nr bi translated">训练模型</h2><p id="565a" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">训练模型有4个超参数(时期，批量大小，n_val，n_way)</p><figure class="mg mh mi mj gt mk"><div class="bz fp l di"><div class="ns nt l"/></div></figure><ul class=""><li id="7d84" class="nu nv it lc b ld mw lg mx lj nw ln nx lr ny lv nz oa ob oc bi translated"><strong class="lc iu">第6–7行</strong>:声明两个列表，记录损耗和精度值，以便进一步可视化。</li><li id="89c5" class="nu nv it lc b ld od lg oe lj of ln og lr oh lv nz oa ob oc bi translated"><strong class="lc iu">第8–20行</strong>:对于每个历元，获取x和y的批次，使用这些输入训练模型，并将损失附加到列表中。对于每“N”(本例中为250)个时期，通过进行N向一次性学习来检查模型的表现。</li></ul><h2 id="663d" class="ng kj it bd kk nh ni dn ko nj nk dp ks lj nl nm ku ln nn no kw lr np nq ky nr bi translated">成果和未来工作</h2><p id="1197" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">上面的代码在Kaggle中训练了5000个纪元。使用GPU将显著减少训练时间。</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi ok"><img src="../Images/ba418f71fdb0235f088e85801e762ba1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GL1ru0kYIY3cWSSgjtQ6pg.png"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">模型的训练损失</p></figure><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi ol"><img src="../Images/0ee66741c239bb9db34fa5367ad4b25d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c0dPzuATK_OKlf07OdGY-Q.png"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">模型的准确性</p></figure><p id="f638" class="pw-post-body-paragraph la lb it lc b ld mw ju lf lg mx jx li lj my ll lm ln mz lp lq lr na lt lu lv im bi translated">我们能够在验证集上达到90%的准确率。为了进一步提高精度，我们可以尝试从预先训练的模型中导入权重，如VGG-16、雷斯网-50等。</p><h1 id="5696" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">结束的</h1><p id="5960" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">如果你有任何问题，请告诉我。我会尽力回应。由于这是我的第一篇博文，请告诉我它是否对你的项目有所帮助，或者我是否应该改变解释事物的方式。</p><p id="da04" class="pw-post-body-paragraph la lb it lc b ld mw ju lf lg mx jx li lj my ll lm ln mz lp lq lr na lt lu lv im bi translated">我期待着创造更多关于计算机视觉的帖子。让我知道你希望涵盖的主题。黑客快乐！</p></div></div>    
</body>
</html>