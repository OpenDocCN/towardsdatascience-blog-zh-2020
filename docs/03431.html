<html>
<head>
<title>Explainable, efficient and accurate node classification in Knowledge Graphs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">知识图中可解释、高效和准确的节点分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/explainable-efficient-and-accurate-node-classification-in-knowledge-graphs-a5d3ba02c245?source=collection_archive---------24-----------------------#2020-04-01">https://towardsdatascience.com/explainable-efficient-and-accurate-node-classification-in-knowledge-graphs-a5d3ba02c245?source=collection_archive---------24-----------------------#2020-04-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9845" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">用 MINDWALC 挖掘区别性行走</h2></div><h2 id="46e9" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">1.用(知识)图表示更丰富的数据</h2><p id="221e" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">图形是一种数据结构，可用于表示无处不在的现象，如社交网络、化学分子和推荐系统。它们的优势之一在于，它们显式地对单个单元(即节点)之间的关系(即边)进行建模，这为数据增加了额外的维度。我们可以用 Cora 引用网络来说明这种数据的丰富。这是一个数据集，包含了几百篇论文的单词包表示以及这些论文之间的引用关系。如果我们应用降维(t-SNE)来创建单词袋表示的 2D 图，我们可以看到(相似研究主题的)聚类出现，但它们重叠。如果我们生成一个嵌入图网络，考虑到引用信息，我们可以看到聚类被更好地分离。</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/c8f379819792a68418b059c7e1a647c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/1*DRp2KgNFil7DwxoTCusHAQ.png"/></div><p class="md me gj gh gi mf mg bd b be z dk translated">左图:每篇论文的单词袋表示的 t-SNE 嵌入。右:图网络产生的嵌入，考虑了论文之间的引用。来源:Velickovic 等人的“Deep Graph Infomax”。</p></figure><p id="ecad" class="pw-post-body-paragraph lb lc iq ld b le mh jr lg lh mi ju lj ko mj ll lm ks mk lo lp kw ml lr ls lt ij bi translated">知识图是一种特殊类型的图。它们是多关系的(即不同类型的关系有不同的边)和有向的(即关系有主体和客体)。幸运的是，我们可以将知识图转换为正则有向图，这便于进一步的分析。</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mm"><img src="../Images/33d8e573e3854d45969bdff77308d8f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YlKuLVza7eHa9TVri3kW_g.png"/></div></div><p class="md me gj gh gi mf mg bd b be z dk translated">将多关系有向知识图转换为正则有向图。</p></figure><h2 id="9143" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">2.(知识)图中的节点分类</h2><p id="6fd2" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">图形越来越多地被用于各种机器学习任务。例如，可以在社交网络中向用户推荐新朋友，预测一个人在协作网络中的角色，或者在生物交互图中对蛋白质的角色进行分类。在这篇文章中，我们将重点关注<strong class="ld ir">节点分类</strong>的任务:我们在一个图中获得了一组标记节点，需要创建一个模型来预测未标记节点的类别。</p><p id="ad4e" class="pw-post-body-paragraph lb lc iq ld b le mh jr lg lh mi ju lj ko mj ll lm ks mk lo lp kw ml lr ls lt ij bi translated">在本帖中，我们将使用一个运行示例，目标是将研究人员分类到正确的机构中。下面我描绘了 5 名研究人员。他们的颜色与他们的机构相对应。我们可以检索这些节点的邻居来扩展我们的图。可以看出，图表的大小增长很快。经过 2 次迭代的扩展，我们不再能直观地看到我们的图形。</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mr"><img src="../Images/a67ceffc6eb023c20f01ae7ae9a65c5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_9DTMFVBoFIiMNzdywMxbQ.png"/></div></div><p class="md me gj gh gi mf mg bd b be z dk translated">通过检索节点的邻居来扩展我们的图。经过 2 次迭代后，很难将图形可视化。</p></figure><h2 id="ecb0" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">3.遍历和通配符</h2><p id="6ca5" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">我们的目标是挖掘对某一类非常有区别的行走(或图中的路径)。我们可以按如下方式记录一次行走:</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/c3f9ae61741690307569c58de9d6ac91.png" data-original-src="https://miro.medium.com/v2/resize:fit:622/format:webp/1*8ThJFUz5en0Uy_7kBQfomw.png"/></div><p class="md me gj gh gi mf mg bd b be z dk translated">一个 n 跳行走的例子。</p></figure><p id="7d58" class="pw-post-body-paragraph lb lc iq ld b le mh jr lg lh mi ju lj ko mj ll lm ks mk lo lp kw ml lr ls lt ij bi translated">如果它有向“v0”的方向，则可以在“根”的邻域中找到这个行走<strong class="ld ir">。从那里,“v0”和“v1”之间必须存在有向边，如此类推，直到我们到达“vn”。如果突然我们不能再穿过一条边到达下一跳，我们就说找不到<strong class="ld ir">了。</strong></strong></p><p id="7154" class="pw-post-body-paragraph lb lc iq ld b le mh jr lg lh mi ju lj ko mj ll lm ks mk lo lp kw ml lr ls lt ij bi translated">此外，我们在遍历中引入了通配符(" * ")。这个通配符的语义是任何顶点都可以在那个位置匹配:</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/eaaa1652686c734054ed80ada8c08e72.png" data-original-src="https://miro.medium.com/v2/resize:fit:606/format:webp/1*t4E2OQxvCk-QJKYst5oEAw.png"/></div><p class="md me gj gh gi mf mg bd b be z dk translated">在我们的行走中引入通配符。</p></figure><p id="b521" class="pw-post-body-paragraph lb lc iq ld b le mh jr lg lh mi ju lj ko mj ll lm ks mk lo lp kw ml lr ls lt ij bi translated">现在，如果它具有到节点的有向边，该节点具有到 v1 的有向边，则可以在根的邻域中找到该行走。中间节点上的标签无关紧要。</p><h2 id="4436" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">4.MINDWALC:有效挖掘歧视性行走</h2><p id="3a30" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated"><a class="ae lu" href="http://github.com/IBCNServices/MINDWALC" rel="noopener ugc nofollow" target="_blank">MINDWALC</a>(<strong class="ld ir">M</strong>ining<strong class="ld ir">In</strong>expertable，<strong class="ld ir">D</strong>is criminative<strong class="ld ir">Wal</strong>ks for<strong class="ld ir">C</strong>classification of Nodes In a Knowledge Graph)是一种允许高效地挖掘特定格式的遍历的技术。一次 l 跳的遍历必须由 l-1 个通配符组成，最后跟一个顶点:</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/7eb85f63859f58ebf874689ce2684c86.png" data-original-src="https://miro.medium.com/v2/resize:fit:456/format:webp/1*1qNTpt4_x8eNP7useEMy4g.png"/></div></figure><p id="9013" class="pw-post-body-paragraph lb lc iq ld b le mh jr lg lh mi ju lj ko mj ll lm ks mk lo lp kw ml lr ls lt ij bi translated">如果 x 可以在 l 次跳跃中到达，则可以在根的邻域中找到这种行走。由于这种走查的格式，我们可以引入一个数据结构，该数据结构将允许测试是否可以在<strong class="ld ir">恒定时间</strong>内在一个邻域中找到这样的走查。数据结构是一个<strong class="ld ir">集合列表</strong>。列表中索引 I 上的每个集合包含可以在恰好 I 跳中到达的节点。下面显示了如何构建该数据结构的代码片段:</p><figure class="lw lx ly lz gt ma"><div class="bz fp l di"><div class="mv mw l"/></div><p class="md me gj gh gi mf mg bd b be z dk translated">构建一个数据结构，允许在恒定时间内测试行走的存在</p></figure><p id="8c49" class="pw-post-body-paragraph lb lc iq ld b le mh jr lg lh mi ju lj ko mj ll lm ks mk lo lp kw ml lr ls lt ij bi translated">MINDWALC 的目标是找到能最大限度获取信息的行走方式。信息增益可以被定义为由数据划分导致的熵的减少。熵是对不确定性的一种度量，如下所示:</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/b4355cea3d148ab78e408c2b8b3bbbaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:522/format:webp/1*VY1VVzZAx8QcyJ3iqvXK4g.png"/></div><p class="md me gj gh gi mf mg bd b be z dk translated">熵是不确定性的度量。不确定性越多，熵就越高。</p></figure><p id="349c" class="pw-post-body-paragraph lb lc iq ld b le mh jr lg lh mi ju lj ko mj ll lm ks mk lo lp kw ml lr ls lt ij bi translated">由于我们可以在恒定时间内测试这些特定行走的存在，我们可以对所有可能的<strong class="ld ir">(深度，顶点)候选</strong>进行强力搜索。深度定义了我们遍历中的跳数(因此我们将使用深度为 1 的通配符)，顶点是我们最后一跳的标签。</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi my"><img src="../Images/f1e187beb76237e0977b7bb5aafe13e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0F3pVAdu2H7iZOv5p51xzA.png"/></div></div><p class="md me gj gh gi mf mg bd b be z dk translated">MINDWALC 允许快速计算所有可能行走的信息增益。</p></figure><h2 id="a8be" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">5.将挖掘算法与分类技术相结合</h2><p id="272c" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">我们的挖掘算法可以与几种分类技术相结合。首先，我们可以递归地应用该算法，以便归纳出一个<strong class="ld ir">决策树</strong>。最终的模型是完全可解释的，因为我们可以很容易地将整个树可视化，或者在我们的决策树中突出显示所采用的路径以形成预测。在这篇文章中，我们将通过检查和讨论一个归纳决策树来进一步证明这一点。第二，我们可以归纳出多个决策树，每个决策树都有训练实体和可能的子结构的子样本，以便形成一个<strong class="ld ir">森林</strong>。这种集成技术通常导致更好的预测性能，但代价是较低的可解释性和较长的训练时间。最后，我们可以通过对数据执行一次遍历来分离建模和挖掘，以挖掘信息丰富的行走集合。然后，这些遍历可以用于创建高维二进制特征向量(<strong class="ld ir">特征变换</strong>)，这些向量可以被传递给任何分类算法。</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mz"><img src="../Images/f07490c6c92212e56394c912ec5bf9cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W0vTGqNjJG-GPBrRykf4Xw.png"/></div></div></figure><h2 id="265a" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">6.可解释的和最先进的分类结果</h2><p id="da50" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">我们使用四个基准数据集将我们的技术与两个黑盒替代方案进行了比较。黑盒替代品是<a class="ae lu" href="https://madoc.bib.uni-mannheim.de/41307/1/Ristoski_RDF2Vec.pdf" rel="noopener ugc nofollow" target="_blank"> RDF2Vec </a>和<a class="ae lu" href="https://arxiv.org/pdf/1703.06103.pdf" rel="noopener ugc nofollow" target="_blank"> R-GCN </a>。下表列出了四个基准数据集的属性:</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi na"><img src="../Images/749e9e22f7fe730d255136a597e35a48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dXKWAHor6D6clHPQQMYxTw.png"/></div></div><p class="md me gj gh gi mf mg bd b be z dk translated">我们研究中使用的四个基准数据集的属性。AIFB 数据集对应于本文中使用的运行示例。</p></figure><p id="79e2" class="pw-post-body-paragraph lb lc iq ld b le mh jr lg lh mi ju lj ko mj ll lm ks mk lo lp kw ml lr ls lt ij bi translated">对于每个数据集，我们运行了 10 次。在测试集上获得的平均准确度分数及其相应的标准偏差总结如下:</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nb"><img src="../Images/e5382d2cf868d6cd1aa66569b9572ab4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yJilhZCPA6L13gZUv5BobA.png"/></div></div><p class="md me gj gh gi mf mg bd b be z dk translated">两种黑盒方案和我们的算法的分类精度。</p></figure><p id="4c69" class="pw-post-body-paragraph lb lc iq ld b le mh jr lg lh mi ju lj ko mj ll lm ks mk lo lp kw ml lr ls lt ij bi translated">这些结果清楚地表明，对于 KGs 中的节点分类，所有三种提出的技术至少与当前最先进的技术相竞争。最后，我们检查了在 AIFB 数据集上归纳的决策树，这是我们对不同研究人员进行分类的运行示例:</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nc"><img src="../Images/2b205f1fb90754f7fa6465675acd6662.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KEAEcBbvLzaLSt8G4LUJrg.png"/></div></div><p class="md me gj gh gi mf mg bd b be z dk translated">在 AIFB 数据集上诱导的决策树。</p></figure><p id="24d7" class="pw-post-body-paragraph lb lc iq ld b le mh jr lg lh mi ju lj ko mj ll lm ks mk lo lp kw ml lr ls lt ij bi translated">在根节点中，我们找到了行走<em class="nd">root-&gt;*-&gt;*-&gt;*-&gt;*-&gt;*-&gt;viewProjektOWL/id68 instance</em>。当这个遍历可以在一个实例的附近找到时，它就不再属于研究机构<em class="nd"> id4instance </em>，因为这个叶子没有出现在右边的子树中。此外，通过在我们的遍历中使用通配符，这种类型的遍历已经展示了具有固定深度的附加值。事实上，从一个实例到一个类型为<em class="nd">项目</em>的实体，只需要两次跳跃(例如<em class="nd">root-&gt;*-&gt;viewProjektOWL/id68 instance</em>)就可以结束，但是这导致的信息增益比需要六次跳跃时少得多。当检查原始 KG 时，似乎只有两个人直接参与了<em class="nd">项目</em><em class="nd">id68 实例</em>，或者换句话说，只有两跳的路径可以匹配。另一方面，这两个人似乎与他们所属的其他研究人员一起写了相当多的论文。因此，首先从某个人(根)跳转到他或她的一篇论文，并通过<em class="nd">作者</em>谓词从那里转到前面提到的两个人中的一个，可以找到来自从属关系<em class="nd">ID3 实例</em>的 45 个人、来自<em class="nd">id2 实例</em>的 3 个人和来自<em class="nd">id1 实例</em>的 2 个人。从根开始的右边子树中的剩余节点信息较少，因为这些节点试图将来自两个附属关系<em class="nd"> id2instance </em>和<em class="nd"> id1instance </em>的 5 个人与其他 45 个人分开。</p><h2 id="d0b3" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">7.结论</h2><p id="30d5" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">这篇关于 MINDWALC 的博文到此结束。MINDWALC 是一种算法，它允许在知识图的节点分类的上下文中挖掘特定类型的行走，这些行走对于某些类(组)是有信息的。此外，我们表明，这种算法是一个很好的预测模型的基础，当结合使用在这项工作中提出的三种不同技术之一。在四个 KG 基准数据集上的实验表明，我们提出的方法优于当前最先进的技术，同时，与这些技术相比，是完全可解释的。这对于关键领域的应用非常重要。</p><h2 id="9f53" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">参考</h2><ol class=""><li id="9adf" class="ne nf iq ld b le lf lh li ko ng ks nh kw ni lt nj nk nl nm bi translated">Velič ković，Petar 等人，《深度图 infomax》<em class="nd"> arXiv 预印本 arXiv:1809.10341 </em> (2018)。</li><li id="b8bd" class="ne nf iq ld b le nn lh no ko np ks nq kw nr lt nj nk nl nm bi translated">用图卷积网络建模关系数据。<em class="nd">欧洲语义网大会</em>。施普林格，查姆，2018。</li><li id="d8e5" class="ne nf iq ld b le nn lh no ko np ks nq kw nr lt nj nk nl nm bi translated">《RDF2Vec: RDF 图嵌入及其应用》<em class="nd">语义网</em>10.4(2019):721–752。</li><li id="8d2b" class="ne nf iq ld b le nn lh no ko np ks nq kw nr lt nj nk nl nm bi translated">引导一棵有区别路径的决策树来分类知识图中的实体。<em class="nd"> SEPDA2019，第四届语义驱动的数据挖掘与分析国际研讨会</em>。2019.</li><li id="fab9" class="ne nf iq ld b le nn lh no ko np ks nq kw nr lt nj nk nl nm bi translated">https://github.com/IBCNServices/MINDWALC<a class="ae lu" href="https://github.com/IBCNServices/MINDWALC" rel="noopener ugc nofollow" target="_blank"/></li></ol></div></div>    
</body>
</html>