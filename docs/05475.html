<html>
<head>
<title>Web-Scraping and Pre-Processing for NLP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">面向自然语言处理的网页抓取和预处理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/web-scraping-and-pre-processing-for-nlp-2e78810b40f1?source=collection_archive---------24-----------------------#2020-05-08">https://towardsdatascience.com/web-scraping-and-pre-processing-for-nlp-2e78810b40f1?source=collection_archive---------24-----------------------#2020-05-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="ceef" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/the-meditations" rel="noopener" target="_blank">冥想项目</a></h2><div class=""/><div class=""><h2 id="f4dd" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">使用Python抓取和处理web上的文本数据</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/760c2cabc3fd11f7cec1519e0c63050f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CbEZS4YcozE4VD6x"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">照片由<a class="ae lh" href="https://unsplash.com/@the_roaming_platypus?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> timJ </a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="032f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi me translated">对于自然语言处理，干净的数据很重要。当数据来自网络时更是如此。在这篇文章中，我们将通过一个斯多葛派哲学文本生成器的web抓取和数据预处理的真实例子。</p><p id="90f8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将使用的数据是由流亡的罗马参议员塞内卡在斯托晚期写的《致卢西留斯的道德书》。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="9b65" class="mu mv it bd mw mx my mz na nb nc nd ne ki nf kj ng kl nh km ni ko nj kp nk nl bi translated">书信</h1><p id="11c4" class="pw-post-body-paragraph li lj it lk b ll nm kd ln lo nn kg lq lr no lt lu lv np lx ly lz nq mb mc md im bi translated">这些信件来源于<a class="ae lh" href="https://en.wikisource.org/wiki/Moral_letters_to_Lucilius" rel="noopener ugc nofollow" target="_blank">维基资源，这里是</a>。这一页包括所有124封信的列表。其中每个字母都包含在它自己的页面中。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/98a65b304a8c4ae6b12d7d05b93ab34d.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/1*WLZ6GRBxsV3i5ssDx8SUrQ.png"/></div></figure><p id="6caf" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">首先，我们必须从这个内容页面中提取HTML。为此，我们使用Python的<code class="fe ns nt nu nv b">requests</code>和<code class="fe ns nt nu nv b">BeautifulSoup</code>库。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="10a4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这给了我们一个漂亮的Soup对象，它包含了我们通过<code class="fe ns nt nu nv b">html</code>给出的原始html。让我们看看这是什么样子。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ny"><img src="../Images/5e396413be73cd3a31bd59ee20c5c815.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IEaOm38qgUG9503KL4BgwQ.png"/></div></div></figure><p id="cd2b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这种情况下，我们必须提取每个字母的本地路径。BeautifulSoup对象允许我们用<code class="fe ns nt nu nv b">soup.find_all('a')</code>提取所有的<code class="fe ns nt nu nv b">&lt;a&gt;</code>元素。然而，这将返回所有的 <code class="fe ns nt nu nv b">&lt;a&gt;</code>元素，所以我们需要过滤那些链接到字母的元素。</p><p id="5f8f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们使用正则表达式来实现这一点，这非常简单，我们构建正则表达式来搜索任何以<code class="fe ns nt nu nv b">Letter</code>开头，后跟一个或多个空格<code class="fe ns nt nu nv b">\s+</code>，最后以一到三位数<code class="fe ns nt nu nv b">\d{1,3}</code>结尾的内容。这给了我们<code class="fe ns nt nu nv b">re.compile(r"^Letter\s+\d{1,3}$")</code>。</p><p id="3200" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">通过将这个正则表达式应用于BeautifulSoup提供的<code class="fe ns nt nu nv b">&lt;a&gt;</code>元素列表，我们将得到如下结果。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nz"><img src="../Images/593ff2559e621e58d84a9b1e676a7cce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zSlTmV-fq-BWli0as7Xe-Q.png"/></div></div></figure><h2 id="4d51" class="oa mv it bd mw ob oc dn na od oe dp ne lr of og ng lv oh oi ni lz oj ok nk iz bi translated">麻痹性鼻出血</h2><p id="15af" class="pw-post-body-paragraph li lj it lk b ll nm kd ln lo nn kg lq lr no lt lu lv np lx ly lz nq mb mc md im bi translated">现在我们需要定义一个函数来解析每个页面的HTML。这实际上非常简单，因为字母文本全部包含在页面上仅有的<code class="fe ns nt nu nv b">&lt;p&gt;</code>元素中。</p><p id="237b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，与之前类似，我们提取所有的<code class="fe ns nt nu nv b">&lt;p&gt;</code>元素。然后，在返回信件文本之前，我们进行少量的格式化，使文本更具可读性。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nw nx l"/></div></figure><h2 id="9287" class="oa mv it bd mw ob oc dn na od oe dp ne lr of og ng lv oh oi ni lz oj ok nk iz bi translated">Omnis书信</h2><p id="a55a" class="pw-post-body-paragraph li lj it lk b ll nm kd ln lo nn kg lq lr no lt lu lv np lx ly lz nq mb mc md im bi translated">通过我们的<code class="fe ns nt nu nv b">pull_letter</code>功能和<code class="fe ns nt nu nv b">letters_regex</code>，我们可以阅读所有的信件，我们将把它们放在<code class="fe ns nt nu nv b">moral_letters</code>中。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="e9e5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">此时我们已经得到了所有需要的数据，整齐地存储在<code class="fe ns nt nu nv b">moral_letters</code>中。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ol"><img src="../Images/eafb1086d9f8c260973617636dfca545.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4lhjpleRsnMGSxr2l7eX0g.png"/></div></div></figure></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="831a" class="mu mv it bd mw mx my mz na nb nc nd ne ki nf kj ng kl nh km ni ko nj kp nk nl bi translated">准备工作</h1><p id="8075" class="pw-post-body-paragraph li lj it lk b ll nm kd ln lo nn kg lq lr no lt lu lv np lx ly lz nq mb mc md im bi translated">将我们的数据格式化成NLP友好的格式要简单得多，尽管抽象得多。</p><p id="efa6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们需要将当前的文本转换成数字，创建数据的数字表示，我们称之为<code class="fe ns nt nu nv b">data_idx</code>。</p><p id="a04d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为此，我们将创建一个<code class="fe ns nt nu nv b">char2idx</code>字典，代表<strong class="lk jd">字符索引</strong>。顾名思义，这将字符<code class="fe ns nt nu nv b">'a', 'b', 'c'</code>转换为索引<code class="fe ns nt nu nv b">0, 1, 2</code>。</p><p id="2ba4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><code class="fe ns nt nu nv b">char2idx</code>中的每个字符也必须映射到一个唯一的索引。为此，我们必须在数据中创建所有字符的集合(集合只是列出唯一的值)。这组字符被称为词汇表，我们将把它定义为<code class="fe ns nt nu nv b">vocab</code>。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="07e7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，让我们用新的格式来读塞内加的第一封信。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi om"><img src="../Images/fb5de2167785e0c8bcdde3a8ee7c3e01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rmEWrByvKixF-34gUc4ECg.png"/></div></div></figure><p id="e94c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">虽然这看起来很荒谬，但这正是我们在为NLP格式化文本数据时想要的。</p><p id="2e24" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在剩下的就是对我们的数据进行切片和洗牌，然后就可以输入到模型中了。在我们的例子中，我们使用的是<code class="fe ns nt nu nv b">tensorflow</code>。</p><h2 id="fa76" class="oa mv it bd mw ob oc dn na od oe dp ne lr of og ng lv oh oi ni lz oj ok nk iz bi translated">单形世界</h2><p id="c48c" class="pw-post-body-paragraph li lj it lk b ll nm kd ln lo nn kg lq lr no lt lu lv np lx ly lz nq mb mc md im bi translated">TensorFlow允许我们使用<code class="fe ns nt nu nv b"><a class="ae lh" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset" rel="noopener ugc nofollow" target="_blank">tf.data.Dataset</a></code>，一个我们可以用来简化数据集转换过程的API。为了从我们的Numpy数组<code class="fe ns nt nu nv b">data_idx</code>创建数据集，我们使用<code class="fe ns nt nu nv b">tf.data.Dataset.from_tensor_slices</code>。</p><p id="2af0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在训练中，我们一次只会看一段文字。为了将数据分割成序列，我们使用<code class="fe ns nt nu nv b">Dataset</code> <code class="fe ns nt nu nv b">.batch</code>方法。</p><p id="b620" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">由于这是一个文本生成器，我们的目标数据将只包含输入数据，向前移动一个字符。为此，我们将定义一个名为<code class="fe ns nt nu nv b">split_xy</code>的函数。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi on"><img src="../Images/ccd2dc10fbb3edd6f3ee73f0f106a41f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_cQnVFE8lG3nU_mR9TEHEw.png"/></div></div></figure><p id="98ba" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最后，我们再次使用<code class="fe ns nt nu nv b">.batch</code>创建64个序列的批次，然后使用<code class="fe ns nt nu nv b">.shuffle</code>将它们混洗。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="3b12" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在<code class="fe ns nt nu nv b">dataset</code>里面，我们有175个批次<em class="oo">(由于</em> <code class="fe ns nt nu nv b"><em class="oo">len(txt) / (SEQLEN * BATCHSIZE)</em></code> <em class="oo"> ) </em>。每个批处理都包含一个由<code class="fe ns nt nu nv b">split_xy</code>函数构建的输入和目标数组。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi op"><img src="../Images/a1c039c12c3c29f4c9210741af2d867c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ry-Wpa2RgDRROaEZyAj8Ww.png"/></div></div></figure><p id="e81d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些数据现在已经完全准备好了，可以输入到模型中进行训练。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="5731" class="mu mv it bd mw mx my mz na nb nc nd ne ki nf kj ng kl nh km ni ko nj kp nk nl bi translated">结论是什么</h1><p id="9226" class="pw-post-body-paragraph li lj it lk b ll nm kd ln lo nn kg lq lr no lt lu lv np lx ly lz nq mb mc md im bi translated">尽管外表复杂。机器学习的实现不再是一项庞大的任务，只留给我们这个时代最聪明的人。</p><p id="a128" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们现在生活在这样一个时代，我们可以教计算机从人类历史上一些最伟大的头脑中复制哲学。我们不仅能做到，而且非常容易做到。</p><p id="b1cb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这是一个迷人的时代，我希望我们都能充分利用这个时代。</p><p id="2d43" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">感谢阅读！</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><p id="8e1f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我以前写过设计神经网络来重现斯多葛派哲学。如果你感兴趣，你可以在这里阅读:</p><div class="oq or gp gr os ot"><a rel="noopener follow" target="_blank" href="/stoic-philosophy-built-by-algorithms-9cff7b91dcbd"><div class="ou ab fo"><div class="ov ab ow cl cj ox"><h2 class="bd jd gy z fp oy fr fs oz fu fw jc bi translated">斯多葛派哲学——由算法构建</h2><div class="pa l"><h3 class="bd b gy z fp oy fr fs oz fu fw dk translated">再现历史上最有权势的人之一所写的斯多葛派哲学</h3></div><div class="pb l"><p class="bd b dl z fp oy fr fs oz fu fw dk translated">towardsdatascience.com</p></div></div><div class="pc l"><div class="pd l pe pf pg pc ph lb ot"/></div></div></a></div><pre class="ks kt ku kv gt pi nv pj pk aw pl bi"><span id="59f7" class="oa mv it nv b gy pm pn l po pp">For anyone that is curious, here are my (attempted) Latin translations of the article headers.</span><span id="6d66" class="oa mv it nv b gy pq pn l po pp"><strong class="nv jd">Epistulae</strong>: Letters<br/><strong class="nv jd">Unum Epistula Legimus</strong>: We read one letter<br/><strong class="nv jd">Omnis Epistulae</strong>: All letters<br/><strong class="nv jd">Praeparatio</strong>: Preparation (eg preparing the data)<br/><strong class="nv jd">Simplex Munditiis</strong>: Elegance through simplicity<br/><strong class="nv jd">Qui Conclusioni</strong>: Here concludes / the conclusion</span></pre></div></div>    
</body>
</html>