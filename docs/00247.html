<html>
<head>
<title>WTH are R-squared and Adjusted R-squared?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">WTH 是 R 平方和调整后的 R 平方？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/wth-are-r-squared-and-adjusted-r-squared-7b816eef90d9?source=collection_archive---------13-----------------------#2020-01-08">https://towardsdatascience.com/wth-are-r-squared-and-adjusted-r-squared-7b816eef90d9?source=collection_archive---------13-----------------------#2020-01-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="df67" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">理解 R 平方背后的数学和直觉。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6aad7cda8cc9aac90907e79ddcb94a3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iqREoMVQBfOYJULZqlEAng.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Daria Nepriakhina 在<a class="ae ky" href="https://unsplash.com/s/photos/r?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="9a2a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated"><span class="l lw lx ly bm lz ma mb mc md di"> T </span>今天我将从机器学习的角度来解释 R 平方和调整的 R 平方的概念。我还将向您展示如何找到 ML 模型的 R 平方值。让我们开始吧…</p><h1 id="5132" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">r 平方</h1><p id="47e7" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">它充当回归模型的评估指标。为了更好地理解它，让我引入一个回归问题。假设我正在构建一个模型，根据我在某个月的空闲时间来预测我在这个月会写多少文章。因此，这里的<strong class="lb iu">目标变量</strong>是文章数量，空闲时间是<strong class="lb iu">独立变量</strong>(也称为特性)。这是我创建的虚拟数据。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/1bba5a2a35f9deb59a4a1bc43a83758d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*4ZDSFIRwWeBu9iurLwYAqg.png"/></div></figure><p id="56c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这种情况下，简单的线性回归模型应该足够了。该模型的方程是…</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/b9c55c43eac36666c5c5eab765177fb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:274/format:webp/1*QLGAH8xTe_6B13QxVi0Amg.png"/></div></figure><p id="10ed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">模型的参数(<strong class="lb iu"><em class="nd">w1</em></strong>和<strong class="lb iu"> <em class="nd"> b </em> </strong>)可以通过最小化所有数据点的平方误差来找到。这也被称为最小平方损失函数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/621e27d990ebba8f7df4112c5479c1c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/format:webp/1*OjF4N2g12ussF8GWQvwYtg.png"/></div></figure><p id="bc08" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这个优化步骤之后，我们发现红线是我们的模型(<strong class="lb iu">最佳拟合线</strong>)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/57119b6cf4353b7f9694f5dff74ffa09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*EFwwmWvQL60NFOSocnD6XQ.png"/></div></figure><p id="29a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们想知道我们的模型有多好。这可以通过许多方式实现，但 R-squared 使用一种叫做<strong class="lb iu">方差的统计方法。</strong>方差表示数值围绕其平均值分布的程度。数学上，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/578ea7a33a0e73058e5e0677a4551bea.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/1*OI_QDBcYr5RioaodO-_ghA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">n 是数据点的数量</p></figure><p id="8934" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">R-squared 计算模型(独立变量的函数)解释了目标变量的多少方差。但是要找到它，我们需要知道两件事。<strong class="lb iu"> 1)目标变量围绕平均值的方差(平均方差)，2)目标变量围绕最佳拟合线的方差(模型方差)。</strong></p><p id="8d05" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">平均方差也可以被视为模型的方差，该模型输出每个输入的目标变量的平均值。我们可以把这个模型想象成一条水平线，它在所有数据点的 y 坐标的平均值处切割 y 轴。看图中的绿线。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/dd77c5c6d5832dff16d9f1cf7fc1a1b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*ixzaW-b-R73wkcM_KZt-rg.png"/></div></figure><p id="0f26" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">忽略因子<strong class="lb iu"> <em class="nd"> 1/n，</em> </strong>我们可以写…</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/f30aaee476057fa193d108f7d050b3f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*oe1qzT0cJbKNKHe5B8P1tQ.png"/></div></figure><p id="0ee4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">模型方差的公式是…</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/0ade6b84b2c6100c2a43488ad5b7bf46.png" data-original-src="https://miro.medium.com/v2/resize:fit:556/format:webp/1*lkw2PP--C-fG_eqxC7eFZg.png"/></div></figure><p id="6ed5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们可以理解 R 平方的公式了。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/25db4792f34c318d5d8787afcb1bdbf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*tHgnPI4hTkwPV-VG7WmhNw.png"/></div></figure><h1 id="6a03" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">如何解读？</h1><blockquote class="nj nk nl"><p id="f732" class="kz la nd lb b lc ld ju le lf lg jx lh nm lj lk ll nn ln lo lp no lr ls lt lu im bi translated">正如我前面提到的，R 平方值表示可以用你的模型解释的目标变量的方差的比例。解释的方差比例越多，你的模型就越好。因此，接近 1 的 R 平方值对应于好模型，接近 0 的值对应于坏模型。</p></blockquote><p id="f6ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">假设我们模型的 R 值是<strong class="lb iu"> <em class="nd"> 0.78。</em> </strong>这种说法意味着我们的模型解释了<strong class="lb iu"> <em class="nd"> 78% </em> </strong>的文章数量对应的数据的方差。它接近于<strong class="lb iu"> <em class="nd"> 1 </em> </strong>所以我们可以说这是一个很好的模型。</p><h1 id="71c1" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">R 的可能值</h1><p id="c0ab" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated"><strong class="lb iu"> <em class="nd"> R = 0 </em> </strong>当我们的模型与平均模型相同时。<strong class="lb iu"> <em class="nd"> R &gt; 0 </em> </strong>表示我们的模型比一般模型要好。R 的最大可能值等于<strong class="lb iu"> <em class="nd"> 1 </em> </strong>。虽然它的名字中有一个正方形，但它可能取负值。<strong class="lb iu"> <em class="nd"> R &lt; 0 </em> </strong>表示我们的模型比一般模型差。这种情况一般不会发生，因为优化步骤会产生比平均模型更好的模型。</p><h1 id="8998" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">R 平方的问题</h1><p id="2490" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">起初，看起来一切都很好，但是随着我们添加更多的特性，R 出现了一个巨大的问题。随着新要素添加到模型中，r 平方永远不会减少。</p><blockquote class="nj nk nl"><p id="5a8a" class="kz la nd lb b lc ld ju le lf lg jx lh nm lj lk ll nn ln lo lp no lr ls lt lu im bi translated">这是一个问题，因为即使我们向我们的模型添加无用的或随机的特征，R 平方值也会增加，这表明新模型比以前的模型更好。这是错误的，因为新特征与输出变量无关，只会导致过度拟合。</p></blockquote><h1 id="89be" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">为什么 R 的平方永远不能减小？</h1><p id="b60f" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">为了理解这一点，让我们为我们的模型引入一个新特性，它与我写的文章数量(输出变量)没有关系。我将一个月的平均温度作为我们的新特征。姑且称之为<strong class="lb iu"> <em class="nd"> x_2。</em> </strong>所以我们的模型就变成了……</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/82080e75bca0bb1d5ea3d20a05174d20.png" data-original-src="https://miro.medium.com/v2/resize:fit:436/format:webp/1*o7fldxpxvLBmeanKyhikzA.png"/></div></figure><p id="663b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在优化之后，对于 w_2 可能出现两种情况:</p><ol class=""><li id="edb0" class="nq nr it lb b lc ld lf lg li ns lm nt lq nu lu nv nw nx ny bi translated">我们得到<strong class="lb iu"> <em class="nd"> w_2 </em> </strong>为<strong class="lb iu"> <em class="nd"> 0 </em> </strong>。这意味着<strong class="lb iu"> <em class="nd"> x_2 </em> </strong>和输出变量之间没有相关性，我们被之前的损失函数最小值卡住了。因此，我们的模型与之前的模型保持不变。所以，在这种情况下，R 值保持不变。</li><li id="e827" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">我们得到一个非零值<strong class="lb iu"> <em class="nd"> w_2 </em> </strong>。这意味着已经找到了<strong class="lb iu"><em class="nd">x2</em></strong>和输出变量之间的一些相关性，并且我们实现了损失函数的更好的最小值。所以，R 值增加。</li></ol><p id="2fcc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">几乎总是出现第二种情况，因为在随机性中很容易找到小的相关性。但是这种小的相关性过度拟合了模型。为了解决这个问题，我们使用调整的 R 平方。</p><h1 id="41fc" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">调整后的 R 平方</h1><p id="06b5" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">调整后的 R-squared 背后的想法是，随着我们向模型中添加更多的特征，我们会对分数进行惩罚。我们来看看调整后的 R 平方的公式。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/bb6d5924415297ddef4b4ab9192d7ad7.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*4EWlKLcPQohCTRt1Ktn7ow.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">n 是数据点的数量；m 是独立特征的数量</p></figure><p id="7400" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">分母<strong class="lb iu"> <em class="nd"> (n-m-1) </em> </strong>随着特征数量的增加而增加。因此，如果我们没有发现 R 的显著增加，那么整个表达式的值不会增加(甚至可能减少)。这就是为什么调整后的 R 在某种程度上抵抗了我们在普通 R 中所面临的问题。</p><h1 id="7148" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">如何求 R(使用 StatsModels)？</h1><p id="df3c" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">Statsmodels 库提供了一种执行许多统计任务的简单方法。首先，我创建了一个假数据集，并建立了一个线性回归模型。之后，我通过调用<strong class="lb iu"> summary() </strong>函数打印了 R 和调整后的 R 值。下面是代码…</p><pre class="kj kk kl km gt of og oh oi aw oj bi"><span id="5d94" class="ok mf it og b gy ol om l on oo">from pandas import DataFrame<br/>import statsmodels.api as sm</span><span id="140a" class="ok mf it og b gy op om l on oo"># making the fake dataset<br/>data = { <br/>         'month': [12,11,10,9,8,7,6,5,4],<br/>         'free_time': [120,110,100,90,80,85,60,50,40],<br/>         'num_articles': [8,8,7,6,6,7,6,4,5]<br/>       }</span><span id="9e95" class="ok mf it og b gy op om l on oo">df = DataFrame(data, columns=['month', 'free_time', 'num_articles'])</span><span id="8a03" class="ok mf it og b gy op om l on oo"># features<br/>X = df[['free_time']] <br/># target variable<br/>Y = df['num_articles']<br/># adding a constant<br/>X = sm.add_constant(X)</span><span id="13b4" class="ok mf it og b gy op om l on oo"># applying method of least squares<br/>model = sm.OLS(Y, X).fit()<br/>predictions = model.predict(X)</span><span id="371f" class="ok mf it og b gy op om l on oo">print_model = model.summary()<br/>print(print_model)</span></pre><p id="45a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在关注输出的选定部分。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/df311b75cd58db3a1ee6818e3c375311.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AAyWzIdEep4gNYFhC3nIBg.png"/></div></div></figure><h2 id="01b1" class="ok mf it bd mg or os dn mk ot ou dp mo li ov ow mq lm ox oy ms lq oz pa mu pb bi translated">还好奇？看一个我最近做的视频…</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pc pd l"/></div></figure><p id="0e0d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望你喜欢阅读。下次见…学习愉快！</p></div></div>    
</body>
</html>