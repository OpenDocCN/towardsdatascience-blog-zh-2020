<html>
<head>
<title>Distributed Deep Learning Training with Horovod on Kubernetes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 Kubernetes 上使用 Horovod 进行分布式深度学习训练</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/distributed-deep-learning-training-with-horovod-on-kubernetes-6b28ac1d6b5d?source=collection_archive---------16-----------------------#2020-09-16">https://towardsdatascience.com/distributed-deep-learning-training-with-horovod-on-kubernetes-6b28ac1d6b5d?source=collection_archive---------16-----------------------#2020-09-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="5b37" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你可能已经注意到，即使是像英伟达 DGX 这样强大的机器也不足以足够快地训练深度学习模型。更不用说将数据复制到 DGX 的漫长等待时间了。数据集变得越来越大，GPU 从存储中分离出来，使用 GPU 的工作人员需要协调模型检查点和日志保存。您的系统可能会超出单个服务器，团队希望轻松共享 GPU 硬件和数据。</p><p id="03c1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过 Kubernetes 上的 Horovod 进入分布式培训。在这篇博客中，我将通过 Kubernetes 上的 Horovod 在多工人分布式环境中训练一个深度学习模型的设置。</p><h1 id="1744" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">Kubernetes 上有张量流的 Horovod</h1><p id="c0b5" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated"><a class="ae lr" href="https://horovod.readthedocs.io/en/stable/summary_include.html#why-horovod" rel="noopener ugc nofollow" target="_blank"> Horovod </a>是一个面向 TensorFlow、Keras、PyTorch 和 Apache MXNet 的分布式深度学习训练框架。由优步开源的 Horovod 已经证明，只需很少的代码更改，它就可以将单个 GPU 训练扩展到并行运行在多个 GPU 上。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ls"><img src="../Images/8f4219084aeb11637532c434243284fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3xpFPbIW76FoZ_iinoVang.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">Horovod 缩放效率(图片来自<a class="ae lr" href="https://horovod.readthedocs.io/en/stable/summary_include.html" rel="noopener ugc nofollow" target="_blank"> Horovod 网站</a></p></figure><p id="9324" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">作为一个例子，我将使用 Horovod 和 TensorFlow 和 Keras 训练一个电影评论情感模型。尽管 Keras 本身支持<a class="ae lr" href="https://keras.io/guides/distributed_training/" rel="noopener ugc nofollow" target="_blank">分布式训练</a>，但我发现它比 Horovod 更复杂，也更不稳定。</p><p id="988a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">很多时候，客户问我如何在这样的环境下分配和管理团队成员的 GPU 时间表。这在多服务器环境中变得更加重要。我听说过像 Excel 中的时间表(很糟糕，但仍然很常见)、Python 脚本、Kubernetes 和商业软件这样的解决方案。我将使用 Kubernetes，因为它支持在集群上运行许多应用程序容器(包括深度学习)的良好界面。</p><p id="78da" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">快速共享存储/文件系统对于简化分布式培训至关重要。它是将机器学习工作流程的不同阶段结合在一起的粘合剂，它使团队能够共享 GPU 硬件和数据。我将使用 FlashBlade S3 来托管数据集，使用 FlashBlade NFS 来设置检查点和存储 TensorBoard 日志。</p><p id="a648" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">以下是该设置的架构:</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi mi"><img src="../Images/f95eb8939faa64c8d9bdddd9c413a459.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*47uOs4jaUiz8cHhks7ZgJQ.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">针对 Kubernetes 和 FlashBlade 上 TensorFlow 的 Horovod 分布式培训</p></figure><h1 id="8a2d" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">在库伯内特斯部署霍洛佛德</h1><p id="6169" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">在多工作者 Horovod 设置中，单个主要和多个工作者节点协调以并行训练模型。它使用<a class="ae lr" href="https://www.mpi-forum.org/" rel="noopener ugc nofollow" target="_blank"> MPI </a>和 SSH 来交换和更新模型参数。在 Kubernetes 上运行 Horovid 的一种方法是使用<a class="ae lr" href="https://www.kubeflow.org/" rel="noopener ugc nofollow" target="_blank"> kubeflow </a>和它的<a class="ae lr" href="https://github.com/kubeflow/examples/tree/master/demos/yelp_demo/ks_app/vendor/kubeflow/mpi-job" rel="noopener ugc nofollow" target="_blank"> mpi-job 库</a>，我发现仅仅为了这个目的而引入 kubeflow 有点过了。Kubeflow 本身就是一个大项目。现在，让我们保持简单。</p><p id="6c49" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们需要先安装 MTP 和 SSH。Horovod 为此提供了一个<a class="ae lr" href="https://github.com/horovod/horovod/blob/master/Dockerfile.gpu" rel="noopener ugc nofollow" target="_blank">官方 Docker 文件</a>。我已经<a class="ae lr" href="https://github.com/uprush/kube-dtrain/blob/master/horovod/docker/Dockerfile.cpu" rel="noopener ugc nofollow" target="_blank">定制了它</a>来适应我的需求。虽然可以将 MPI 和 SSH 设置放入 Docker 映像中，但是我们确实需要为 Horovod pods 配置无密码 SSH 身份验证。这不是一个硬性要求，但是为了使示例更加简洁，我使用 Kubernetes 持久卷(PV)来存储我的 SSH 配置，并在<code class="fe mj mk ml mm b">/root/.ssh</code>将它挂载到所有容器上。</p><pre class="lt lu lv lw gt mn mm mo mp aw mq bi"><span id="9bc7" class="mr kp it mm b gy ms mt l mu mv">apiVersion: v1<br/>kind: PersistentVolumeClaim<br/>metadata:<br/>  name: horovod-ssh-shared<br/>spec:<br/>  accessModes:<br/>    - <strong class="mm iu">ReadWriteMany</strong><br/>  resources:<br/>    requests:<br/>      storage: 1Gi<br/>  storageClassName: <strong class="mm iu">pure-file</strong></span></pre><p id="5a69" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请注意，PV 是一个具有<code class="fe mj mk ml mm b">ReadWriteMany</code>访问模式的<code class="fe mj mk ml mm b">pure-file</code>级(由 NFS 闪存支持)。同样，我还为检查点和张量板日志创建了另一个名为<code class="fe mj mk ml mm b">tf-shared</code>的 PV。我将这些 PV 安装到所有容器上:</p><pre class="lt lu lv lw gt mn mm mo mp aw mq bi"><span id="f1fd" class="mr kp it mm b gy ms mt l mu mv">volumeMounts:<br/>  - name: horovod-ssh-vol<br/>    mountPath: /root/.ssh<br/>  - name: tf-shared-vol<br/>    mountPath: /tf/models</span></pre><p id="a91e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在 Horovod 主容器启动之前，我使用 Kubernetes<a class="ae lr" href="https://kubernetes.io/docs/concepts/workloads/pods/init-containers/" rel="noopener ugc nofollow" target="_blank">Init Container</a>运行一个<code class="fe mj mk ml mm b">init-ssh.sh</code>脚本来生成 SSH 无密码认证配置。</p><pre class="lt lu lv lw gt mn mm mo mp aw mq bi"><span id="75c3" class="mr kp it mm b gy ms mt l mu mv">initContainers:<br/>- name: init-ssh<br/>image: uprush/horovod-cpu:latest<br/>volumeMounts:<br/>  - name: horovod-ssh-vol<br/>    mountPath: /root/.ssh<br/>command: ['/bin/bash', '/root/init-ssh.sh']</span></pre><p id="23ff" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><code class="fe mj mk ml mm b">init-ssh.sh</code>的内容是这样的:</p><pre class="lt lu lv lw gt mn mm mo mp aw mq bi"><span id="ceb4" class="mr kp it mm b gy ms mt l mu mv">if [ -f /root/.ssh/authorized_keys ]<br/>then<br/>    echo "SSH already configured."<br/>else<br/>    ssh-keygen -t rsa -b 2048 -N '' -f /root/.ssh/id_rsa<br/>    cp /root/.ssh/id_rsa.pub /root/.ssh/authorized_keys<br/>    chmod 700 /root/.ssh<br/>    chmod 600 /root/.ssh/authorized_keys<br/>fi</span></pre><p id="224d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后，我声明两个 Kubernetes 部署:一个用于主节点，另一个用于工作节点。当主服务器什么都不做时，工作人员在 pod 中启动一个 SSH 服务器。</p><pre class="lt lu lv lw gt mn mm mo mp aw mq bi"><span id="9dfa" class="mr kp it mm b gy ms mt l mu mv">- name: horovod-cpu<br/>    image: "uprush/horovod-cpu:latest"<br/>    command: [ "sh", "-c", "/usr/sbin/sshd -p 2222; sleep infinity" ]</span></pre><p id="3598" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">有了这些，<code class="fe mj mk ml mm b">root</code>主 pod 上的用户无需密码即可通过 SSH 连接到工作人员。Horovod 设置就绪。</p><h2 id="bdc6" class="mr kp it bd kq mw mx dn ku my mz dp ky kb na nb lc kf nc nd lg kj ne nf lk ng bi translated">在 TensorFlow 中访问 S3 数据集</h2><p id="4396" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">我的数据集作为 TensorFlow 记录文件存储在 S3 的 FlashBlade 中。我希望我的 TensorFlow 脚本直接访问它，而不是下载到本地目录。所以我使用 Kubernetes Secret 在部署中添加了几个环境变量:</p><pre class="lt lu lv lw gt mn mm mo mp aw mq bi"><span id="348c" class="mr kp it mm b gy ms mt l mu mv">env:<br/>- name: AWS_ACCESS_KEY_ID<br/>  valueFrom:<br/>    secretKeyRef:<br/>      name: tf-s3<br/>      key: access-key<br/>- name: AWS_SECRET_ACCESS_KEY<br/>  valueFrom:<br/>    secretKeyRef:<br/>      name: tf-s3<br/>      key: secret-key<br/>- name: S3_ENDPOINT<br/>  value: 192.168.170.11<br/>- name: S3_USE_HTTPS<br/>  value: "0"</span></pre><p id="da18" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我的 TensorFlow 脚本的后面，我将使用这些变量进行 S3 认证:</p><pre class="lt lu lv lw gt mn mm mo mp aw mq bi"><span id="918c" class="mr kp it mm b gy ms mt l mu mv">endpoint_url = f"<a class="ae lr" rel="noopener ugc nofollow" target="_blank" href="/{os.environ['S3_ENDPOINT'">http://{os.environ['S3_ENDPOINT'</a>]}"<br/>kwargs = {'endpoint_url':endpoint_url}<br/>s3 = s3fs.S3FileSystem(anon=False, client_kwargs=kwargs)</span><span id="5418" class="mr kp it mm b gy nh mt l mu mv"># List all training tfrecord files<br/>training_files_list = s3.ls("s3://datasets/aclImdb/train/")<br/>training_files = [f"s3://{f}" for f in training_files_list]</span><span id="f872" class="mr kp it mm b gy nh mt l mu mv"># Now let's create tf datasets<br/>training_ds = tf.data.TFRecordDataset(training_files, num_parallel_reads=AUTO)</span></pre><p id="53c9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">FlashBlade S3 速度非常快，最低部署可以达到 7GB/s 的读取吞吐量，持续约 3 毫秒的延迟。对于许多 DL 培训工作来说，这已经足够好了。</p><h2 id="629f" class="mr kp it bd kq mw mx dn ku my mz dp ky kb na nb lc kf nc nd lg kj ne nf lk ng bi translated">Kubernetes 上的 GPU 调度</h2><p id="5e0f" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">为了让 Kubernetes 基于 GPU 资源请求调度 pod，我们需要安装<a class="ae lr" href="https://github.com/NVIDIA/k8s-device-plugin" rel="noopener ugc nofollow" target="_blank"> Nvidia k8s 设备插件</a>。需要使用<code class="fe mj mk ml mm b">nvidia-docker2</code>包而不是常规 docker 作为默认运行时。遵循自述文件，了解如何准备 GPU 节点。设备插件的安装很简单<a class="ae lr" href="https://github.com/NVIDIA/k8s-device-plugin#deployment-via-helm" rel="noopener ugc nofollow" target="_blank">使用舵</a>。在我的实验室里，我只在装有 Tesla GPUs 的节点上安装插件。所以我给我的 GPU 节点添加了节点标签。</p><pre class="lt lu lv lw gt mn mm mo mp aw mq bi"><span id="c996" class="mr kp it mm b gy ms mt l mu mv">kubectl label nodes fb-ubuntu01 nvidia.com/gpu.family=tesla</span><span id="fbe2" class="mr kp it mm b gy nh mt l mu mv">helm install \<br/>    --version=0.6.0 \<br/>    --generate-name \<br/>    --set compatWithCPUManager=true \<br/>    --set nodeSelector."nvidia\.com/gpu\.family"=tesla \<br/>    nvdp/nvidia-device-plugin</span></pre><p id="37f6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">该插件将作为 DaemonSet 安装在<code class="fe mj mk ml mm b">kube-system</code>名称空间中。如果一切顺利，GPU 节点现在应该具有 GPU 容量:</p><pre class="lt lu lv lw gt mn mm mo mp aw mq bi"><span id="fb11" class="mr kp it mm b gy ms mt l mu mv">kubectl describe node fb-ubuntu01<br/><br/>Capacity:<br/>  cpu:                32<br/>  ephemeral-storage:  292889880Ki<br/>  hugepages-1Gi:      0<br/>  hugepages-2Mi:      0<br/>  memory:             264092356Ki<br/>  <strong class="mm iu">nvidia.com/gpu:     1</strong><br/>  pods:               110</span></pre><p id="3416" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后，我们可以为 Horovod pods 请求 GPU 资源:</p><pre class="lt lu lv lw gt mn mm mo mp aw mq bi"><span id="57c8" class="mr kp it mm b gy ms mt l mu mv">resources:<br/>  limits:<br/>    nvidia.com/gpu: 2 # requesting 2 GPUs</span></pre><h1 id="db23" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">准备训练</h1><p id="819d" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">接下来，我使用一个<a class="ae lr" href="https://github.com/uprush/kube-dtrain/blob/master/horovod/examples/pre-train.sh" rel="noopener ugc nofollow" target="_blank">预训练脚本</a>来准备训练环境。该脚本使用 Kubernetes CLI 选择 Horovod pods，然后执行以下操作:</p><ul class=""><li id="12ea" class="ni nj it js b jt ju jx jy kb nk kf nl kj nm kn nn no np nq bi translated">生成一个<code class="fe mj mk ml mm b">pip-install.sh</code>脚本，在所有 pod 上安装 Python 依赖项。</li><li id="9763" class="ni nj it js b jt nr jx ns kb nt kf nu kj nv kn nn no np nq bi translated">生成一个<code class="fe mj mk ml mm b">horovod-run.sh</code>脚本来启动 Horovod 作业。</li><li id="cb36" class="ni nj it js b jt nr jx ns kb nt kf nu kj nv kn nn no np nq bi translated">将源代码和生成的脚本从我的工作站复制到 Horovod 主 pod 的共享 PV 中。</li></ul><p id="4ab1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">运行<code class="fe mj mk ml mm b">pre-train.sh</code>脚本后，我的主 pod 将在共享 PV 中包含这些文件:</p><pre class="lt lu lv lw gt mn mm mo mp aw mq bi"><span id="09cc" class="mr kp it mm b gy ms mt l mu mv">root@horovod-primary-84fcd7bdfd-2j8tc:/tf/models/examples# ls<br/>horovod-run.sh  imdb-sentiment.py  pip-install.sh  pre-train.sh  requirements.txt</span></pre><p id="0219" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下面是一个生成<code class="fe mj mk ml mm b">horovod-run.sh</code>的例子:</p><pre class="lt lu lv lw gt mn mm mo mp aw mq bi"><span id="e70c" class="mr kp it mm b gy ms mt l mu mv">mkdir -p /tf/models/aclImdb/checkpoints</span><span id="a7cb" class="mr kp it mm b gy nh mt l mu mv">AWS_LOG_LEVEL=3 horovodrun -np 3 \<br/> -H localhost:1,10-244-1-129.default.pod:1,10-244-0-145.default.pod:1 \<br/> -p 2222 \<br/> python imdb-sentiment.py</span></pre><p id="ce67" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">该脚本在三个并行单元上运行培训作业，每个单元使用一个 CPU。这里我们不用 GPU，因为模型很小。</p><p id="d2d3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因为一切都是自动化的，所以每次我在我的 VSCode 中更改培训代码时(我使用<a class="ae lr" href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-ssh" rel="noopener ugc nofollow" target="_blank">远程扩展</a>通过 SSH 在服务器上编写代码)，我都会运行以下代码来启动培训作业:</p><ol class=""><li id="2151" class="ni nj it js b jt ju jx jy kb nk kf nl kj nm kn nw no np nq bi translated">运行<code class="fe mj mk ml mm b">pre-train.sh</code>脚本重新生成并复制源代码。</li><li id="51f7" class="ni nj it js b jt nr jx ns kb nt kf nu kj nv kn nw no np nq bi translated">进入 Horovod 主吊舱。</li><li id="efae" class="ni nj it js b jt nr jx ns kb nt kf nu kj nv kn nw no np nq bi translated">运行<code class="fe mj mk ml mm b">pip-install.sh</code>在所有 pod 上安装依赖项。</li><li id="0db8" class="ni nj it js b jt nr jx ns kb nt kf nu kj nv kn nw no np nq bi translated">运行<code class="fe mj mk ml mm b">horovod-run.sh</code>开始 Horovod 培训工作。</li></ol><p id="fe20" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">到目前为止，这个工作流程对我来说很好。</p><h1 id="7a01" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">具有张量流的 Horovod</h1><p id="93f7" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">在 TensorFlow 中使用 Horovod 所需的培训脚本的修改在<a class="ae lr" href="https://horovod.readthedocs.io/en/stable/tensorflow.html" rel="noopener ugc nofollow" target="_blank">这里</a>有详细说明。</p><p id="cfef" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我的<a class="ae lr" href="https://github.com/uprush/kube-dtrain/blob/master/horovod/examples/imdb-sentiment.py" rel="noopener ugc nofollow" target="_blank">示例代码</a>是一个端到端可运行的脚本，用来训练一个影评情感模型。它类似于单节点训练，除了:</p><ul class=""><li id="4b12" class="ni nj it js b jt ju jx jy kb nk kf nl kj nm kn nn no np nq bi translated">代码在所有的 Horovod pods 上并行运行。</li><li id="c005" class="ni nj it js b jt nr jx ns kb nt kf nu kj nv kn nn no np nq bi translated">每个 pod 只处理训练和验证批次总数的一部分，因此需要切分数据集(使用<code class="fe mj mk ml mm b">tf.data.Dataset.shard()</code>)并在调用<code class="fe mj mk ml mm b">model.fit</code>时正确设置<code class="fe mj mk ml mm b">steps_per_epoch</code>和<code class="fe mj mk ml mm b">validation_steps</code>。</li><li id="27aa" class="ni nj it js b jt nr jx ns kb nt kf nu kj nv kn nn no np nq bi translated">一些任务，例如保存检查点、张量板日志和模型，应该注意只在主 pod ( <code class="fe mj mk ml mm b">hvd.rank() = 0</code>)上运行，以防止其他工作人员破坏它们。</li><li id="2068" class="ni nj it js b jt nr jx ns kb nt kf nu kj nv kn nn no np nq bi translated">因为 pods 可以在 Kubernetes 集群中的任何服务器上运行(只有在请求 GPU 资源时才运行 GPU 节点),所以我们应该将检查点、TensorBoard 日志和模型保存在持久卷(在我的示例中是 FlashBlade NFS)或对象存储(例如，FlashBlade S3)中。</li></ul><p id="8c1f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我将在这里跳过训练代码的细节。请参考我的<a class="ae lr" href="https://github.com/uprush/kube-dtrain/blob/master/horovod/examples/imdb-sentiment.py" rel="noopener ugc nofollow" target="_blank">示例代码</a>。</p><p id="aee9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下面是一个运行输出:</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi nx"><img src="../Images/5aa3386ebdc38c0f8decbf491891f82a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XE5Ej9Ck_BTlAh0YbV3TUA.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">运行输出示例</p></figure><p id="429d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果我查看我的 Kubernetes 监控 UI，我可以看到所有 Horovod pods 的 CPU 使用率都在上升。这表明培训作业正在所有 pod 上并行运行。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ny"><img src="../Images/35b7b1a11e7dec55f05fddc4dec19116.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rGjW-vC2Uu7DftTHsiFsbQ.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">Horovod 训练期间的 Pod 资源使用</p></figure><h1 id="152c" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">摘要</h1><p id="3cfc" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">分布式训练是深度学习的未来。使用 Horovod 和 Kubernetes，我们演示了快速旋转动态分布式深度学习训练环境的步骤。这使得深度学习工程师和研究人员能够轻松共享、调度和充分利用昂贵的 GPU 和数据。</p><p id="d367" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">像 FlashBlade 这样的共享存储在这种设置中起着重要的作用。FlashBlade 使资源和数据共享成为可能。它让我不用保存/聚集检查点、张量板日志和模型。有了 Kubernetes 和 FlashBlade 的 Horovod 让我的深度学习生活变得容易多了。</p><p id="93b5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Excel 中不再有时间表！</p></div></div>    
</body>
</html>