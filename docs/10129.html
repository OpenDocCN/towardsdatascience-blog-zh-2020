<html>
<head>
<title>Understanding Word Embeddings from scratch | LSTM model |</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从零开始理解单词嵌入| LSTM 模型|</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/word-embeddings-and-the-chamber-of-secrets-lstm-gru-tf-keras-de3f5c21bf16?source=collection_archive---------7-----------------------#2020-07-17">https://towardsdatascience.com/word-embeddings-and-the-chamber-of-secrets-lstm-gru-tf-keras-de3f5c21bf16?source=collection_archive---------7-----------------------#2020-07-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2ae7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">直观理解单词嵌入的最终目的…最后</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9a3d92b3a5a0dfd296f944dfd1149091.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QQECWHSaGPFEQ2fY"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">乔恩·泰森在<a class="ae ky" href="https://unsplash.com/s/photos/text?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="7b3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">哟读者！我是<a class="ae ky" href="https://www.linkedin.com/in/maniksoni" rel="noopener ugc nofollow" target="_blank">马尼克</a>。怎么了？。</p><blockquote class="lv"><p id="1131" class="lw lx it bd ly lz ma mb mc md me lu dk translated">希望你做得很好，并为你的目标努力工作。如果没有，也不迟。现在就开始，就在此时此刻。</p></blockquote><p id="fb47" class="pw-post-body-paragraph kz la it lb b lc mf ju le lf mg jx lh li mh lk ll lm mi lo lp lq mj ls lt lu im bi translated">有了这些信息，你将对深度神经网络的序列和文本处理有一个清晰的解释，包括:</p><ol class=""><li id="dee8" class="mk ml it lb b lc ld lf lg li mm lm mn lq mo lu mp mq mr ms bi translated">什么是一键编码？</li><li id="4d1b" class="mk ml it lb b lc mt lf mu li mv lm mw lq mx lu mp mq mr ms bi translated">使用 keras 的 OneHot 编码。</li><li id="6030" class="mk ml it lb b lc mt lf mu li mv lm mw lq mx lu mp mq mr ms bi translated">什么是单词嵌入以及它们相对于一键编码的优势？</li><li id="f9f6" class="mk ml it lb b lc mt lf mu li mv lm mw lq mx lu mp mq mr ms bi translated">单词嵌入想说什么？</li><li id="90b6" class="mk ml it lb b lc mt lf mu li mv lm mw lq mx lu mp mq mr ms bi translated">使用 LSTM 和 GRU 图层在 keras 中将原始文本转换为单词嵌入的完整示例。</li></ol><p id="98d5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想了解 LSTMs，你可以去这里</p><div class="my mz gp gr na nb"><a href="https://binarykeys.in/2020/07/lstm-cell-architecture-scratch-code/" rel="noopener  ugc nofollow" target="_blank"><div class="nc ab fo"><div class="nd ab ne cl cj nf"><h2 class="bd iu gy z fp ng fr fs nh fu fw is bi translated">LSTM 细胞:用代码从零开始理解架构</h2><div class="ni l"><h3 class="bd b gy z fp ng fr fs nh fu fw dk translated">LSTMs 是一种特殊的 rnn，具有处理长期依赖关系的能力。他们还提供解决方案…</h3></div><div class="nj l"><p class="bd b dl z fp ng fr fs nh fu fw dk translated">binarykeys.in</p></div></div><div class="nk l"><div class="nl l nm nn no nk np ks nb"/></div></div></a></div><h1 id="38cd" class="nq nr it bd ns nt nu nv nw nx ny nz oa jz ob ka oc kc od kd oe kf of kg og oh bi translated">让我们开始吧。</h1><blockquote class="oi oj ok"><p id="1a36" class="kz la ol lb b lc ld ju le lf lg jx lh om lj lk ll on ln lo lp oo lr ls lt lu im bi translated">“你的祖先和我的祖先曾追逐乳齿象或野猪，就像奥林匹克短跑运动员一样，手里拿着长矛，用树叶和虎皮盖住自己，作为他们的早餐”——历史</p></blockquote><p id="ea1b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的句子是文本形式的，为了让神经网络理解和吸收它，我们需要将其转换成某种数字形式。两种方法是<strong class="lb iu">一种是热编码</strong>另一种是<strong class="lb iu">字嵌入</strong>。</p><h1 id="ba04" class="nq nr it bd ns nt nu nv nw nx ny nz oa jz ob ka oc kc od kd oe kf of kg og oh bi translated">一个热点</h1><p id="68a5" class="pw-post-body-paragraph kz la it lb b lc op ju le lf oq jx lh li or lk ll lm os lo lp lq ot ls lt lu im bi translated">这是一种用 0 和 1 的数组来表示每个单词的方法。在数组中，只有一个索引有“1 ”,其余的都是 0。</p><p id="e35c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">示例:下面的向量只代表一个单词，在一个有 6 个唯一单词的句子中。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/ab6af32738247ebdba1e5ca140851573.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*TR6TLAYTA0Rp5_2NDTvTCg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h1 id="b039" class="nq nr it bd ns nt nu nv nw nx ny nz oa jz ob ka oc kc od kd oe kf of kg og oh bi translated">与 numpy 一夜情</h1><p id="f11a" class="pw-post-body-paragraph kz la it lb b lc op ju le lf oq jx lh li or lk ll lm os lo lp lq ot ls lt lu im bi translated">让我们找出句子中所有独特的单词。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ov ow l"/></div></figure><pre class="kj kk kl km gt ox oy oz pa aw pb bi"><span id="72d3" class="pc nr it oy b gy pd pe l pf pg">array(['Yours', 'a', 'after', 'an', 'ancestors', 'and', 'boar,',<br/>       'breakfast', 'covering', 'for', 'had', 'hand', 'in','leaves',<br/>       'like', 'mastodons', 'mine', 'olympic', 'or', 'run', 'skin,',<br/>       'spear', 'sprinter,', 'their', 'themselves', 'tiger', 'wild',<br/>       'with'], dtype='&lt;U10')</span><span id="9748" class="pc nr it oy b gy ph pe l pf pg">shape: (28,)</span></pre><p id="1e58" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，给他们每个人一个索引，即创建一个 word_index，其中每个单词在字典中都有一个索引。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ov ow l"/></div></figure><p id="a867" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可能已经在上面的代码中观察到，0 没有分配给任何单词。这是 Keras 中的一个保留索引(我们稍后会讲到)。</p><pre class="kj kk kl km gt ox oy oz pa aw pb bi"><span id="f5c1" class="pc nr it oy b gy pd pe l pf pg">{'Yours': 1, 'a': 2, 'after': 3, 'an': 4, 'ancestors': 5, 'and': 6, 'boar,': 7, 'breakfast': 8, 'covering': 9, 'for': 10, 'had': 11, 'hand': 12, 'in': 13, 'leaves': 14, 'like': 15, 'mastodons': 16, 'mine': 17, 'olympic': 18, 'or': 19, 'run': 20, 'skin,': 21, 'spear': 22, 'sprinter,': 23, 'their': 24, 'themselves': 25, 'tiger': 26, 'wild': 27, 'with': 28}</span></pre><p id="7d1a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们为它们创建一个一次性编码。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ov ow l"/></div></figure><p id="3be2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">示例输出:这就是“你的”是如何表示的。</p><pre class="kj kk kl km gt ox oy oz pa aw pb bi"><span id="a950" class="pc nr it oy b gy pd pe l pf pg">Yours [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]</span></pre><h2 id="77dd" class="pc nr it bd ns pi pj dn nw pk pl dp oa li pm pn oc lm po pp oe lq pq pr og ps bi translated"><em class="pt">单热 keras 示例</em></h2><p id="1736" class="pw-post-body-paragraph kz la it lb b lc op ju le lf oq jx lh li or lk ll lm os lo lp lq ot ls lt lu im bi translated">text_to_matrix 是用于返回独热编码的方法。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ov ow l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者</p></figure><p id="e9f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以看到，为了表示一个单词，我们实际上浪费了大量的内存来设置 0(稀疏矩阵)。这些一次性编码也不能反映相似单词之间的任何关系。它们只是一些带有“1”的单词的表示。在一键编码中，两个相似的词(如“准确的”和“精确的”)可能位于非常不同的位置。</p><p id="50ed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们可以用更少的空间来表示一个单词，并且让它的表示有一个意义，这样我们就可以学到一些东西。</p><h1 id="dace" class="nq nr it bd ns nt nu nv nw nx ny nz oa jz ob ka oc kc od kd oe kf of kg og oh bi translated">单词嵌入</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pu"><img src="../Images/2e19e5edec5b36a3893bf6ea2ef84e1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*C3EJEPTHttzSO3AE.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">单词向量示例</p></figure><ul class=""><li id="fee3" class="mk ml it lb b lc ld lf lg li mm lm mn lq mo lu pv mq mr ms bi translated">单词嵌入也表示数组中的单词，不是以 0 和 1 的形式，而是连续的向量。</li><li id="4577" class="mk ml it lb b lc mt lf mu li mv lm mw lq mx lu pv mq mr ms bi translated">它们可以在几个维度上表示任何单词，主要基于我们文本中独特单词的数量。</li><li id="d580" class="mk ml it lb b lc mt lf mu li mv lm mw lq mx lu pv mq mr ms bi translated">它们是密集的低维向量</li><li id="3e86" class="mk ml it lb b lc mt lf mu li mv lm mw lq mx lu pv mq mr ms bi translated">不是硬编码的，而是通过数据“学习”的。</li></ul><h2 id="14f3" class="pc nr it bd ns pi pj dn nw pk pl dp oa li pm pn oc lm po pp oe lq pq pr og ps bi translated">单词嵌入想说什么？</h2><ul class=""><li id="7296" class="mk ml it lb b lc op lf oq li pw lm px lq py lu pv mq mr ms bi translated">词与词之间的几何关系嵌入词中可以表示词与词之间的语义关系。与彼此远离的单词相比，彼此靠近的单词具有更强的关联性。</li><li id="57b9" class="mk ml it lb b lc mt lf mu li mv lm mw lq mx lu pv mq mr ms bi translated">向量/单词彼此更接近意味着它们之间的余弦距离或几何距离与其他相比更小。</li><li id="261a" class="mk ml it lb b lc mt lf mu li mv lm mw lq mx lu pv mq mr ms bi translated">可以有向量“男性对女性”,它表示单词和它的阴性之间的关系。这个向量可以帮助我们预测句子中使用“he”时的“king”和使用“Queen”时的“Queen”。</li></ul><h2 id="d3de" class="pc nr it bd ns pi pj dn nw pk pl dp oa li pm pn oc lm po pp oe lq pq pr og ps bi translated">单词嵌入是什么样子的？</h2><p id="a50f" class="pw-post-body-paragraph kz la it lb b lc op ju le lf oq jx lh li or lk ll lm os lo lp lq ot ls lt lu im bi translated">下面是单行嵌入矩阵，表示来自具有 100K 个唯一单词的文本的 100 维中的单词'<em class="ol">和'</em>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pz"><img src="../Images/d882b5763bc854eacb79e323f28f7a3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y-_KrK17-GiBJ02IBO5c9A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd qa">嵌入矩阵中的一行，表示 100 维中的一个单词</strong></p></figure><p id="ea00" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种矩阵是从数据中学习来的，并且可以在 100、200、1000 或更多维中表示具有数百万字的任何文本(如果使用一键编码，则同样需要 1 毫米的维度)。</p><p id="198d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看如何用递归神经网络在 keras 中创建我们的文本嵌入。</p><h2 id="c2f0" class="pc nr it bd ns pi pj dn nw pk pl dp oa li pm pn oc lm po pp oe lq pq pr og ps bi translated"><strong class="ak">将原始数据转换为嵌入数据的步骤:</strong></h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qb"><img src="../Images/83e7ace81ca83fff83b7e366bae7e761.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*BYzzejeXxAIX27ShVQQp8w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">流动</p></figure><ol class=""><li id="51f6" class="mk ml it lb b lc ld lf lg li mm lm mn lq mo lu mp mq mr ms bi translated">在数组中加载文本数据。</li><li id="dc8a" class="mk ml it lb b lc mt lf mu li mv lm mw lq mx lu mp mq mr ms bi translated">处理数据。</li><li id="f2db" class="mk ml it lb b lc mt lf mu li mv lm mw lq mx lu mp mq mr ms bi translated">使用标记器将文本转换为序列，并用 keras . preprocessing . text . pad _ sequences 方法填充它们。</li><li id="6cf6" class="mk ml it lb b lc mt lf mu li mv lm mw lq mx lu mp mq mr ms bi translated">使用<strong class="lb iu">尺寸</strong>(最大字数，表示尺寸，输入尺寸)的嵌入层初始化模型</li></ol><ul class=""><li id="f06c" class="mk ml it lb b lc ld lf lg li mm lm mn lq mo lu pv mq mr ms bi translated"><em class="ol"> max_words </em>:您的数据中唯一单词的个数</li><li id="d500" class="mk ml it lb b lc mt lf mu li mv lm mw lq mx lu pv mq mr ms bi translated"><em class="ol">表示 _ 维度</em>:表示你想要表示一个词的维度个数。通常，它是(唯一的 words)^(1/4)的数字</li><li id="9db2" class="mk ml it lb b lc mt lf mu li mv lm mw lq mx lu pv mq mr ms bi translated">input_size:填充序列的大小(<em class="ol"> maxlen </em>)</li></ul><p id="1210" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">5 .运行模型</p><p id="e718" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们按照上面的步骤来处理 IMDB 原始数据。下面所有的代码都在我的<a class="ae ky" href="https://bit.ly/30oTCaG" rel="noopener ugc nofollow" target="_blank"> Kaggle 笔记本里。</a></p><h2 id="a516" class="pc nr it bd ns pi pj dn nw pk pl dp oa li pm pn oc lm po pp oe lq pq pr og ps bi translated">第一步。必要的进口</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ov ow l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">必要的进口</p></figure><h2 id="26ba" class="pc nr it bd ns pi pj dn nw pk pl dp oa li pm pn oc lm po pp oe lq pq pr og ps bi translated">第二步。加载文本数据。</h2><p id="8a6f" class="pw-post-body-paragraph kz la it lb b lc op ju le lf oq jx lh li or lk ll lm os lo lp lq ot ls lt lu im bi translated">用熊猫加载文本数据。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ov ow l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">读取数据</p></figure><h2 id="bb44" class="pc nr it bd ns pi pj dn nw pk pl dp oa li pm pn oc lm po pp oe lq pq pr og ps bi translated">第三步:处理数据。</h2><p id="ce19" class="pw-post-body-paragraph kz la it lb b lc op ju le lf oq jx lh li or lk ll lm os lo lp lq ot ls lt lu im bi translated">给正面影评打 1 分，给负面影评打 0 分。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ov ow l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">过程数据</p></figure><h2 id="153e" class="pc nr it bd ns pi pj dn nw pk pl dp oa li pm pn oc lm po pp oe lq pq pr og ps bi translated">步骤 4:创建和填充序列。</h2><p id="6a9e" class="pw-post-body-paragraph kz la it lb b lc op ju le lf oq jx lh li or lk ll lm os lo lp lq ot ls lt lu im bi translated">创建 keras 的 Tokenizer 类的一个实例，并将序列填充到“<em class="ol"> maxlen </em>”。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ov ow l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">定序</p></figure><h2 id="f990" class="pc nr it bd ns pi pj dn nw pk pl dp oa li pm pn oc lm po pp oe lq pq pr og ps bi translated">第五步。初始化我们的模型</h2><p id="53b0" class="pw-post-body-paragraph kz la it lb b lc op ju le lf oq jx lh li or lk ll lm os lo lp lq ot ls lt lu im bi translated">一种以嵌入为第一层的简单递归神经网络。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ov ow l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">典型递归模型</p></figure><h2 id="0366" class="pc nr it bd ns pi pj dn nw pk pl dp oa li pm pn oc lm po pp oe lq pq pr og ps bi translated">第六步:运行模型！</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ov ow l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">运行这该死的东西</p></figure><h1 id="05ee" class="nq nr it bd ns nt nu nv nw nx ny nz oa jz ob ka oc kc od kd oe kf of kg og oh bi translated">输出</h1><h2 id="43bf" class="pc nr it bd ns pi pj dn nw pk pl dp oa li pm pn oc lm po pp oe lq pq pr og ps bi translated">与 GRU:</h2><div class="kj kk kl km gt ab cb"><figure class="qc kn qd qe qf qg qh paragraph-image"><img src="../Images/42e21a1f4d5ae0a36a707c805c700ece.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/0*nPvWwsdmnpDIa-Aj.png"/></figure><figure class="qc kn qi qe qf qg qh paragraph-image"><img src="../Images/0e305b87b5f3cafe00d5e4fa7c37608d.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/0*F49LQN5ubQDMbBfu.png"/><p class="ku kv gj gh gi kw kx bd b be z dk qj di qk ql translated">GRU 培训和验证</p></figure></div><h2 id="b18a" class="pc nr it bd ns pi pj dn nw pk pl dp oa li pm pn oc lm po pp oe lq pq pr og ps bi translated">与 LSTM:</h2><div class="kj kk kl km gt ab cb"><figure class="qc kn qm qe qf qg qh paragraph-image"><img src="../Images/ee769f518f032e2599700f2c20eaa2a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/0*ozVRv-hk6Ilk7M6n.png"/></figure><figure class="qc kn qn qe qf qg qh paragraph-image"><img src="../Images/8373e9deab84a680e4f6966cff3bec71.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/0*3iMuWyW8OWjWlSWs.png"/><p class="ku kv gj gh gi kw kx bd b be z dk qj di qk ql translated">LSTM 培训和验证</p></figure></div><p id="16d3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以上所有代码都呈现在<a class="ae ky" href="https://www.kaggle.com/maniksoni/experiments-sentiment-analysis-raw-data-gru-lstm" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="f913" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果这篇文章对你有所帮助，请与他人分享你的知识！</p><p id="22e6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢你来到这里！太好了！</p><div class="my mz gp gr na nb"><a href="https://binarykeys.in/" rel="noopener  ugc nofollow" target="_blank"><div class="nc ab fo"><div class="nd ab ne cl cj nf"><h2 class="bd iu gy z fp ng fr fs nh fu fw is bi translated">二进制密钥|技术比特的密钥</h2><div class="ni l"><h3 class="bd b gy z fp ng fr fs nh fu fw dk translated">日本横河电机公司(Yokogawa Electric Corp .)决定投资一只基金中的基金，支持印度初创企业 Hello Stardust！今天…</h3></div><div class="nj l"><p class="bd b dl z fp ng fr fs nh fu fw dk translated">binarykeys.in</p></div></div><div class="nk l"><div class="qo l nm nn no nk np ks nb"/></div></div></a></div><div class="my mz gp gr na nb"><a href="https://www.linkedin.com/in/maniksoni" rel="noopener  ugc nofollow" target="_blank"><div class="nc ab fo"><div class="nd ab ne cl cj nf"><h2 class="bd iu gy z fp ng fr fs nh fu fw is bi translated">马尼克索尼- SDE -亚马逊| LinkedIn</h2><div class="ni l"><h3 class="bd b gy z fp ng fr fs nh fu fw dk translated">查看 Manik Soni 在全球最大的职业社区 LinkedIn 上的个人资料。Manik 有 8 个工作列在他们的…</h3></div><div class="nj l"><p class="bd b dl z fp ng fr fs nh fu fw dk translated">www.linkedin.com</p></div></div><div class="nk l"><div class="qp l nm nn no nk np ks nb"/></div></div></a></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qq"><img src="../Images/1909b507d9d22d827fd5ff6bf7286598.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9tNXI55uXVO1YKwS"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com/@kellysikkema?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">凯利·西克玛</a>在<a class="ae ky" href="https://unsplash.com/s/photos/thanks?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure></div></div>    
</body>
</html>