<html>
<head>
<title>Snowflake and Dask</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">雪花和达克</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/snowflake-and-dask-33c84ce0bc36?source=collection_archive---------23-----------------------#2020-07-16">https://towardsdatascience.com/snowflake-and-dask-33c84ce0bc36?source=collection_archive---------23-----------------------#2020-07-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ed3a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何高效地将数据从雪花加载到 Dask</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/e58b702801c24d7142986bfe3c709dbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1eMuTOOVhrwG3Bod"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@dariuscotoi?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">大流士·科托伊</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure></div><div class="ab cl kw kx hu ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ij ik il im in"><p id="60ab" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">雪花是土星用户中最受欢迎的数据仓库。本文将介绍将雪花数据加载到 Dask 的有效方法，这样您就可以大规模地进行非 sql 操作(比如机器学习)。声明:我是土星云的首席技术官，我们专注于企业 Dask。</p><h1 id="c4e5" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">基础知识</h1><p id="344f" class="pw-post-body-paragraph ld le iq lf b lg mr jr li lj ms ju ll lm mt lo lp lq mu ls lt lu mv lw lx ly ij bi translated">首先，一些基础知识，将雪花数据加载到 Pandas 的标准方法:</p><pre class="kg kh ki kj gt mw mx my mz aw na bi"><span id="5295" class="nb ma iq mx b gy nc nd l ne nf">import snowflake.connector<br/>import pandas as pd</span><span id="3f82" class="nb ma iq mx b gy ng nd l ne nf">ctx = snowflake.connector.connect(<br/>    user='YOUR_USER',<br/>    password='YOUR_PASSWORD',<br/>    account='YOUR_ACCOUNT'<br/>)<br/>query = "SELECT * FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.CUSTOMER"<br/>pd.read_sql(query, ctx)</span></pre><p id="1e5a" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">雪花最近为这个操作引入了一个更快的方法，<code class="fe nh ni nj mx b">fetch_pandas_all</code>和<code class="fe nh ni nj mx b">fetch_pandas_batches</code>利用了<a class="ae kv" href="https://arrow.apache.org/" rel="noopener ugc nofollow" target="_blank">箭头</a></p><pre class="kg kh ki kj gt mw mx my mz aw na bi"><span id="e5b4" class="nb ma iq mx b gy nc nd l ne nf">cur = ctx.cursor()<br/>cur.execute(query)<br/>df = cur.fetch_pandas_all()</span></pre><p id="b354" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><code class="fe nh ni nj mx b">fetch_pandas_batches</code>返回一个迭代器，但是由于我们将把重点放在将它加载到一个分布式数据帧中(从多台机器中提取)，我们将设置我们的查询来分割数据，并在我们的 workers 上使用<code class="fe nh ni nj mx b">fetch_pandas_all</code>。</p><h1 id="0a25" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">雪花有什么好处？</h1><p id="432b" class="pw-post-body-paragraph ld le iq lf b lg mr jr li lj ms ju ll lm mt lo lp lq mu ls lt lu mv lw lx ly ij bi translated">将所有数据从雪花中分离出来，以便在 Dask 中使用，这可能非常诱人。这肯定是可行的，但是，snowflake 在对数据应用类似 sql 的操作方面要快得多。雪花存储数据，并有高度优化的例程，以获得查询的每一盎司的性能。这些示例将假装我们正在将整个数据加载到 Dask 中，在您的情况下，您可能会有一些 sql 查询，它执行您所关心的类似 SQL 的转换，并且您将把结果集加载到 Dask 中，这是 Dask 擅长的事情(可能是某些类型的功能工程和机器学习)。<a class="ae kv" href="https://www.saturncloud.io/s/" rel="noopener ugc nofollow" target="_blank">土星云</a>已经与<a class="ae kv" href="https://www.saturncloud.io/s/snowflake/" rel="noopener ugc nofollow" target="_blank"> Dask 和雪花</a>进行了原生集成，所以<a class="ae kv" href="https://https//manager.aws.saturnenterprise.io/register" rel="noopener ugc nofollow" target="_blank">如果你对这个感兴趣的话就去看看</a>。</p><h1 id="6f10" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">Dask 如何加载数据？</h1><p id="f67d" class="pw-post-body-paragraph ld le iq lf b lg mr jr li lj ms ju ll lm mt lo lp lq mu ls lt lu mv lw lx ly ij bi translated">你可以把一个 Dask 数据帧想象成一个大熊猫数据帧，它已经被切碎并分散在一堆计算机上。当我们从 Snowflake 加载数据时(假设数据很大)，将所有数据加载到一台机器上，然后分散到您的集群中，效率并不高。我们将重点让 Dask 集群中的所有机器加载数据的一个分区(一小部分)。</p><h1 id="b31a" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">数据分组</h1><p id="d911" class="pw-post-body-paragraph ld le iq lf b lg mr jr li lj ms ju ll lm mt lo lp lq mu ls lt lu mv lw lx ly ij bi translated">我们需要一种方法将数据分割成小的分区，这样我们就可以将数据加载到集群中。SQL 中的数据不一定有任何自然的顺序。您不能只是说将前 10k 行放入一个分区，而将后 10k 行放入另一个分区。这种划分必须基于一列数据。例如，您可以按日期字段对数据进行分区。或者您可以通过在雪花表格中添加一个<code class="fe nh ni nj mx b">identity</code>列来创建一个行号。</p><p id="0a21" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">一旦您决定了要在哪个列上对数据进行分区，在雪花一侧设置数据聚类就非常重要。每个工人都会要求一小部分数据。大约</p><pre class="kg kh ki kj gt mw mx my mz aw na bi"><span id="cf35" class="nb ma iq mx b gy nc nd l ne nf">select * from table where id &lt; 20000 and id &gt;= 10000</span></pre><p id="76bb" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">如果不设置数据集群，每个查询都会触发对结果数据库的全表扫描(我可能夸大了这个问题，但是如果没有数据集群，这里的性能会非常差)</p><h1 id="c228" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">装弹！</h1><p id="4fef" class="pw-post-body-paragraph ld le iq lf b lg mr jr li lj ms ju ll lm mt lo lp lq mu ls lt lu mv lw lx ly ij bi translated">这里我们不打算使用 dask 库中的<code class="fe nh ni nj mx b">read_sql_table</code>。我更喜欢对如何从雪花加载数据有更多的控制，我们想调用<code class="fe nh ni nj mx b">fetch_pandas_all</code>，这是一个雪花特定的函数，因此不支持<code class="fe nh ni nj mx b">read_sql_table</code></p><pre class="kg kh ki kj gt mw mx my mz aw na bi"><span id="6c47" class="nb ma iq mx b gy nc nd l ne nf">import snowflake.connector<br/>from dask.dataframe import from_delayed<br/>from dask.distributed import delayed<br/></span><span id="f909" class="nb ma iq mx b gy ng nd l ne nf">@delayed<br/>def load(connection_info, query, start, end):<br/>    conn = snowflake.connector.connect(**connection_info)<br/>    cur = conn.cursor()<br/>    cur.execute(query, start, end)<br/>    return cur.fetch_pandas_all()<br/></span><span id="2135" class="nb ma iq mx b gy ng nd l ne nf">ddf = from_delayed(*[load(connection_info, query, st, ed) for st, ed in partitions])<br/>ddf.persist()</span></pre><p id="aff4" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">此代码假设分区是开始/结束分区的列表，例如:</p><pre class="kg kh ki kj gt mw mx my mz aw na bi"><span id="8ac0" class="nb ma iq mx b gy nc nd l ne nf">partitions = [(0, 10000), (10000, 20000), ...]</span></pre><p id="60fc" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><code class="fe nh ni nj mx b">delayed</code>是一个装饰器，它把一个 Python 函数变成一个适合在 dask 集群上运行的函数。当您执行它时，它会返回一个<code class="fe nh ni nj mx b">delayed</code>结果，代表函数的返回值。<code class="fe nh ni nj mx b">from_delayed</code>获取这些<code class="fe nh ni nj mx b">delayed</code>对象的列表，并将它们连接成一个巨大的数据帧。</p><h1 id="1dec" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">内存优化</h1><p id="fd6e" class="pw-post-body-paragraph ld le iq lf b lg mr jr li lj ms ju ll lm mt lo lp lq mu ls lt lu mv lw lx ly ij bi translated">这是先进的概念，但我强烈建议您阅读这一部分，它可以为您节省大量时间，并避免您工作站内存不足的问题。不要因为 Snowflake 说一个数据集是 20GB，就以为加载到<code class="fe nh ni nj mx b">pandas</code>里就是 20GB。内存表示中的<code class="fe nh ni nj mx b">pandas</code>总是要大得多，尽管您可以通过更好地使用数据类型来做得更好。</p><h1 id="a42d" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">诊断内存使用情况</h1><p id="1cca" class="pw-post-body-paragraph ld le iq lf b lg mr jr li lj ms ju ll lm mt lo lp lq mu ls lt lu mv lw lx ly ij bi translated"><code class="fe nh ni nj mx b">df.memory_usage(deep=True)</code>是了解每一列使用了多少内存的好方法。这有助于您了解将数据转换为适当的数据类型的好处。</p><h1 id="23f7" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">StringDType</h1><p id="5cf1" class="pw-post-body-paragraph ld le iq lf b lg mr jr li lj ms ju ll lm mt lo lp lq mu ls lt lu mv lw lx ly ij bi translated">Python 字符串大约有 40 字节的开销。这听起来不是很多，但如果你有十亿个字符串，它可以很快累加起来。新的 StringDType 可以在这方面有所帮助。</p><pre class="kg kh ki kj gt mw mx my mz aw na bi"><span id="1c03" class="nb ma iq mx b gy nc nd l ne nf">df['column'] = df['column'].astype(pd.StringDType())</span></pre><h1 id="cd18" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">分类数据类型</h1><p id="13b5" class="pw-post-body-paragraph ld le iq lf b lg mr jr li lj ms ju ll lm mt lo lp lq mu ls lt lu mv lw lx ly ij bi translated">许多字符串和数值字段实际上是分类的。取一个名为“家庭收入”的栏目。你通常得到的不是一个数值，而是一组数据，比如“0-$40，000”或者“超过$100，000”。</p><p id="818f" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">一般来说，我通常会寻找唯一值的数量与行数之比小于 1%的列。</p><p id="b15a" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在熊猫中，这是相关的代码。</p><pre class="kg kh ki kj gt mw mx my mz aw na bi"><span id="6035" class="nb ma iq mx b gy nc nd l ne nf">df['column'] = df['column'].astype("category")</span></pre><p id="dbd5" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">但是，我假设从雪花中加载整个列来计算分类数据类型是不可行的。我建议使用以下类型的查询来确定哪些列适合分类数据类型:</p><pre class="kg kh ki kj gt mw mx my mz aw na bi"><span id="3ffd" class="nb ma iq mx b gy nc nd l ne nf">select <br/>  count(distinct(col1)),<br/>  count(distinct(col2)),<br/>  ...<br/> from table</span></pre><p id="eff3" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">您可以将结果与表中的行数进行比较，以确定哪些列应该是分类的。</p><p id="325c" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">然后算出独特的价值</p><pre class="kg kh ki kj gt mw mx my mz aw na bi"><span id="a618" class="nb ma iq mx b gy nc nd l ne nf">select distinct(col1) from table</span></pre><h1 id="2f81" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">把所有的放在一起</h1><p id="b652" class="pw-post-body-paragraph ld le iq lf b lg mr jr li lj ms ju ll lm mt lo lp lq mu ls lt lu mv lw lx ly ij bi translated">假设您已经完成了上面列出的一些内存优化，并且已经确定了一些应该转换为 StringDType 的字段，一些应该转换为 categoricals。假设您有一个名为<code class="fe nh ni nj mx b">dtypes</code>的字典，它是列名到您希望将结果强制转换成的 dtype 的映射。</p><pre class="kg kh ki kj gt mw mx my mz aw na bi"><span id="d9e7" class="nb ma iq mx b gy nc nd l ne nf">import snowflake.connector<br/>from dask.dataframe import from_delayed<br/>from dask.distributed import delayed<br/></span><span id="1941" class="nb ma iq mx b gy ng nd l ne nf">@delayed<br/>def load(connection_info, query, start, end, dtypes):<br/>    conn = snowflake.connector.connect(**connection_info)<br/>    cur = conn.cursor()<br/>    cur.execute(query, start, end)<br/>    return cur.fetch_pandas_all().astype(dtypes)<br/></span><span id="a929" class="nb ma iq mx b gy ng nd l ne nf">ddf = from_delayed(*[load(connection_info, query, st, ed) for st, ed in partitions])<br/>ddf.persist()</span></pre><p id="2433" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">感谢阅读。如果你有兴趣将<a class="ae kv" href="https://www.saturncloud.io/s/snowflake/" rel="noopener ugc nofollow" target="_blank"> Dask 用于雪花</a>，那么<a class="ae kv" href="https://manager.aws.saturnenterprise.io/register?trackid=17314f965cd13a-02aa54870e0bee-24414032-317040-17314f965ce320" rel="noopener ugc nofollow" target="_blank">我推荐你去看看土星云</a>。</p></div></div>    
</body>
</html>