<html>
<head>
<title>Multiclass Classification and Information Bottleneck — An example using Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多类分类和信息瓶颈——以 Keras 为例</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/multiclass-classification-and-information-bottleneck-an-example-using-keras-5591b9a2c000?source=collection_archive---------10-----------------------#2020-09-03">https://towardsdatascience.com/multiclass-classification-and-information-bottleneck-an-example-using-keras-5591b9a2c000?source=collection_archive---------10-----------------------#2020-09-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c8dd" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用 Keras 对路透社数据集中的新闻进行分类，看看神经网络如何杀死你的数据。</h2></div><p id="1b46" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="le">多类</em> <em class="le">分类</em> </strong>是对两类以上样本的分类。将样本精确地分为两类，通俗地称为<em class="le">二元</em>T10】分类。</p><p id="c57e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇文章将设计一个神经网络，使用 Python 库 Keras 将路透社 1986 年发布的路透社数据集中的新闻影片分类为 46 个互斥类。这个问题是一个典型的<em class="le">单标签、多类分类问题。</em></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/441f949ae3a1e735a9320f43228274de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*maaQsIBMoKexMaPdB-9FCg.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">由<a class="ae lv" href="https://unsplash.com/@freegraphictoday?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">absolute vision</a>在<a class="ae lv" href="https://unsplash.com/s/photos/news?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h2 id="ad71" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">信息瓶颈</h2><p id="e6fc" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">神经网络由许多层组成。每一层都对数据执行某种转换，将输入映射到网络的输出。但是，需要注意的是，这些层不会生成任何额外的数据，它们只处理从前面的层接收到的数据。</p><p id="4a14" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">比方说，如果一个层丢失了一些相关数据，那么所有后续层都无法访问这些信息。这些信息将永久丢失，并且无法恢复。丢弃该信息的层现在充当了瓶颈，抑制了模型的准确性和性能的提高，从而充当了信息瓶颈。</p><p id="35b5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">稍后我们将看到这一点。</p><h1 id="bc67" class="mu lx it bd ly mv mw mx mb my mz na me jz nb ka mh kc nc kd mk kf nd kg mn ne bi translated">路透社的数据集</h1><p id="1eff" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">路透社数据集是一组简短的新闻报道，分为 46 个互斥的话题。路透社在 1986 年发表了它。这个数据集被广泛用于文本分类。共有 46 个主题，其中一些主题比其他主题出现得多。但是，在训练集中，每个主题至少包含十个示例。</p><p id="40ca" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">路透社<em class="le">数据集</em>预装了 Keras，包含 8982 个训练样本和 2246 个测试样本。</p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="0482" class="mu lx it bd ly mv nm mx mb my nn na me jz no ka mh kc np kd mk kf nq kg mn ne bi translated">加载数据</h1><p id="2837" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">从 Keras 中预先打包的模块加载数据。我们将把数据限制在 10，000 个最频繁出现的单词。为此，我们将<code class="fe nr ns nt nu b">num_words=10000</code>参数传递给<code class="fe nr ns nt nu b">load_data</code>函数。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nv nw l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">代码由<a class="ae lv" href="http://github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> rakshitraj </a>托管在<a class="ae lv" href="https://gist.github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上</p></figure><h2 id="5146" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">一些探索性数据分析</h2><p id="2a74" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">我们将在数据集上执行一些老式的 EDA。这样做可以让我们对数据的广度和范围有一个大致的了解。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nv nw l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">代码由<a class="ae lv" href="http://github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> rakshitraj </a>托管在<a class="ae lv" href="https://gist.github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上</p></figure><h2 id="1855" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">解读一个故事</h2><p id="3a98" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">让我们继续解码一个故事。解码帮助我们获得数据的组织和编码的要点。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nv nw l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">代码由<a class="ae lv" href="http://github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> rakshitraj </a>托管在<a class="ae lv" href="https://gist.github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上</p></figure></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="5c02" class="mu lx it bd ly mv nm mx mb my nn na me jz no ka mh kc np kd mk kf nq kg mn ne bi translated">准备数据</h1><p id="f46f" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">我们不能向神经网络输入整数序列；因此，我们将对每个序列进行矢量化，并将其转换为<em class="le">张量</em>。我们通过对每个序列进行<em class="le">一键编码</em>来做到这一点。</p><p id="51b9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们的训练和测试数据中有 10，000 个独特的元素。对我们的输入数据进行矢量化将产生两个 2D 张量；形状的<em class="le">训练输入张量</em>(8982，10000)和形状的<em class="le">测试输入张量</em>(2246，10000)。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nv nw l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">由<a class="ae lv" href="http://github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> rakshitraj </a>托管在<a class="ae lv" href="https://gist.github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上的代码</p></figure><p id="84d7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个问题的标签包括 46 个不同的类。标签用 1 到 46 范围内的整数表示。为了对标签进行矢量化，我们可以，</p><ul class=""><li id="7b58" class="nx ny it kk b kl km ko kp kr nz kv oa kz ob ld oc od oe of bi translated">将标签转换为整数张量</li><li id="3541" class="nx ny it kk b kl og ko oh kr oi kv oj kz ok ld oc od oe of bi translated">对标签数据进行一次性编码</li></ul><p id="6f76" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将对标签数据进行<em class="le">一键编码</em>。这将给我们张量，它的第二轴有 46 维。这可以使用 Keras 中的<code class="fe nr ns nt nu b">to_categorical</code>函数轻松完成。</p><p id="0ea9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了更加清晰，我们将手动执行。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nv nw l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">代码由<a class="ae lv" href="http://github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> rakshitraj </a>托管在<a class="ae lv" href="https://gist.github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上</p></figure><p id="9440" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">执行标签的一次性分类编码的另一种方法是使用内置函数，如上面的要点所示。为了清楚起见，这里又是:</p><pre class="lg lh li lj gt ol nu om on aw oo bi"><span id="0f92" class="lw lx it nu b gy op oq l or os">from keras.utils.np_utils import to_categorical<br/>Y_train = to_categorical(train_labels)<br/>Y_test = to_categorical(test_labels)</span></pre></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="15e3" class="mu lx it bd ly mv nm mx mb my nn na me jz no ka mh kc np kd mk kf nq kg mn ne bi translated">构建神经网络</h1><p id="5ae0" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">主题分类的问题(<em class="le">单标签多类分类 _)类似于文本字段的 _ 二元分类</em>。这两个问题都遵循类似的数据处理和预处理方法。实现神经网络的教学方法保持不变。然而，有一个新的限制:类的数量从 2 个增加到 46 个。<em class="le">输出空间</em>的<em class="le">维度</em>要高得多。</p><p id="db93" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，每一层都必须处理更多的数据，这就出现了真正的<em class="le">信息瓶颈</em>。</p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="f80b" class="mu lx it bd ly mv nm mx mb my nn na me jz no ka mh kc np kd mk kf nq kg mn ne bi translated">信息瓶颈</h1><p id="5ede" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">给定一个<em class="le">多类分类</em>问题，与二进制<em class="le">分类</em>问题相比，我们需要对数据执行的处理量显著增加。</p><p id="0eb4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在<em class="le">密集</em>层的<em class="le">堆栈</em>中，就像我们所使用的，每一层只能访问前一层输出中的信息。如果一个层丢弃了相关信息，该信息对于所有后续层都是永久不可访问的。信息一旦丢失，就永远不能被后面的层恢复。在像<em class="le">多类分类这样的情况下，数据是有限且关键的，每一层都可能成为信息瓶颈</em>。</p><blockquote class="ot ou ov"><p id="d06f" class="ki kj le kk b kl km ju kn ko kp jx kq ow ks kt ku ox kw kx ky oy la lb lc ld im bi translated">如果一个层丢失了相关的信息，这可能是一个信息瓶颈。</p></blockquote><p id="0ba4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这些层很容易成为我们网络性能的瓶颈。为了确保关键数据不会被丢弃，我们将使用具有更多<em class="le">隐藏单元的层，即更大的层</em>。为了比较，我们在 IMDB 评论的情感分析的两类分类示例中，使用具有<em class="le"> 16 个隐藏单元</em> <code class="fe nr ns nt nu b"><em class="le">Dense(16)</em></code> <em class="le">的层。在这种情况下，输出维度是 46，我们将使用 64 个隐藏单元的层，<code class="fe nr ns nt nu b">Dense(64)</code>。</em></p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h2 id="5840" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">模型定义</h2><p id="c687" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">我们将用两个全连接的 ReLU 激活层来定义我们的网络，每个层有 64 个隐藏单元。第三和最后一层将是尺寸为 46 的致密层。该层将使用一个<em class="le"> softmax </em>激活，并将输出一个 46 维矢量。每一维都是属于该类的输入的概率。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nv nw l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">代码由<a class="ae lv" href="http://github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> rakshitraj </a>托管在<a class="ae lv" href="https://gist.github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上</p></figure><h2 id="d974" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">编译模型</h2><p id="2f40" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">对于我们的网络，我们将使用<em class="le">优化器</em> <code class="fe nr ns nt nu b">rmsprop</code>、_loss function_、<code class="fe nr ns nt nu b">categorical_crossentropy</code>，并将监控模型的<code class="fe nr ns nt nu b">accuracy</code> (_metrics_)。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nv nw l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">代码由<a class="ae lv" href="http://github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> rakshitraj </a>托管在<a class="ae lv" href="https://gist.github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上</p></figure><h2 id="1ca8" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">设置验证集</h2><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nv nw l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">由<a class="ae lv" href="http://github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> rakshitraj </a>托管在<a class="ae lv" href="https://gist.github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上的代码</p></figure></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="b639" class="mu lx it bd ly mv nm mx mb my nn na me jz no ka mh kc np kd mk kf nq kg mn ne bi translated">训练我们的模型</h1><p id="1486" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">最初，我们将在 512 个样本的小批量中为 20 个时期训练我们的模型。我们还将把我们的<em class="le">验证集</em>传递给<code class="fe nr ns nt nu b">fit</code>方法。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nv nw l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">由<a class="ae lv" href="http://github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> rakshitraj </a>托管在<a class="ae lv" href="https://gist.github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上的代码</p></figure><p id="d860" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">调用<code class="fe nr ns nt nu b">fit</code>方法返回一个<code class="fe nr ns nt nu b">History</code>对象。这个对象包含一个成员<code class="fe nr ns nt nu b">history</code>，它存储了关于训练过程的所有数据，包括随着时间的推移可观察到的或监控到的量的值。我们将保存该对象，因为它包含的信息将帮助我们确定更好地应用于训练步骤的微调。</p><p id="d170" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在训练结束时，我们达到了 95%的训练准确率和 80.9%的验证准确率</p><p id="0110" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">既然我们已经训练了我们的网络，我们将观察存储在<code class="fe nr ns nt nu b">History</code>对象中的性能指标。</p><p id="e952" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">调用<code class="fe nr ns nt nu b">fit</code>方法返回一个<code class="fe nr ns nt nu b">History</code>对象。这个对象有一个属性<code class="fe nr ns nt nu b">history</code>，它是一个包含四个条目的字典:每个被监控的指标一个条目。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nv nw l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">由<a class="ae lv" href="http://github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> rakshitraj </a>托管在<a class="ae lv" href="https://gist.github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上的代码</p></figure><p id="2a8c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><code class="fe nr ns nt nu b">history_dict</code>包含以下值</p><ul class=""><li id="dfd4" class="nx ny it kk b kl km ko kp kr nz kv oa kz ob ld oc od oe of bi translated">培训损失</li><li id="e962" class="nx ny it kk b kl og ko oh kr oi kv oj kz ok ld oc od oe of bi translated">训练准确性</li><li id="03a5" class="nx ny it kk b kl og ko oh kr oi kv oj kz ok ld oc od oe of bi translated">验证损失</li><li id="50a1" class="nx ny it kk b kl og ko oh kr oi kv oj kz ok ld oc od oe of bi translated">验证准确性</li></ul><p id="56a2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在每个时期结束时。</p><p id="ed4e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们使用 Matplotlib 并排绘制训练和验证损失以及训练和验证准确性。</p><h2 id="e969" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">培训和验证损失</h2><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/8cfc442d73dbec5bfe2c0ad53624a95f.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*khbZuhwplStoLATKS__nWg.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">损失与时代</p></figure><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nv nw l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">代码由<a class="ae lv" href="http://github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> rakshitraj </a>托管在<a class="ae lv" href="https://gist.github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上</p></figure><h2 id="20bd" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">培训和验证准确性</h2><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/6bbe219ee54051cc38f19ac00b0ad841.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*WeU2R9adC4sJiHlXpHygvA.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">模型与时代的准确性</p></figure><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nv nw l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">代码由<a class="ae lv" href="http://github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> rakshitraj </a>托管在<a class="ae lv" href="https://gist.github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上</p></figure><h2 id="3b06" class="lw lx it bd ly lz ma dn mb mc md dp me kr mf mg mh kv mi mj mk kz ml mm mn mo bi translated">过度拟合:损失和精度数据的趋势</h2><p id="f869" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">我们观察到<em class="le">最小验证损失</em>和<em class="le">最大验证准确度</em>在大约 9-10 个时期达到。之后，我们观察到两个趋势:</p><ul class=""><li id="2b97" class="nx ny it kk b kl km ko kp kr nz kv oa kz ob ld oc od oe of bi translated">验证损失增加，培训损失减少</li><li id="e82d" class="nx ny it kk b kl og ko oh kr oi kv oj kz ok ld oc od oe of bi translated">验证准确性降低，培训准确性提高</li></ul><p id="ddc9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这意味着该模型在对训练数据的情绪进行分类方面越来越好，但当它遇到新的、以前从未见过的数据时，会做出持续更差的预测，这是过度拟合的标志。在第 10 个时期之后，模型开始过于接近训练数据。</p><p id="2573" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了解决过度拟合的问题，我们将把历元的数量减少到 9。这些结果可能会因您的机器以及不同型号的随机重量分配的本质而异。</p><p id="1b9e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在我们的情况下，我们将在九个纪元后停止训练。</p><h1 id="a119" class="mu lx it bd ly mv mw mx mb my mz na me jz nb ka mh kc nc kd mk kf nd kg mn ne bi translated">从头开始重新训练我们的模型</h1><p id="9e5a" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">既然我们知道过多的时期导致我们的模型过度拟合，我们将限制时期的数量并从头重新训练我们的模型。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nv nw l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">代码由<a class="ae lv" href="http://github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> rakshitraj </a>托管在<a class="ae lv" href="https://gist.github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上</p></figure></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="8929" class="mu lx it bd ly mv nm mx mb my nn na me jz no ka mh kc np kd mk kf nq kg mn ne bi translated">预测结果和评估</h1><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nv nw l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">代码由<a class="ae lv" href="http://github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> rakshitraj </a>托管在<a class="ae lv" href="https://gist.github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上</p></figure><p id="257c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们的方法产生了大约 80%的效率</p><p id="7e75" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果这是一个平衡的数据集，使用简单的概率，标签的随机属性将导致 50%的准确性。但是由于这个数据集是不平衡的，随机分类器的准确性可能会更低。</p><blockquote class="ot ou ov"><p id="1300" class="ki kj le kk b kl km ju kn ko kp jx kq ow ks kt ku ox kw kx ky oy la lb lc ld im bi translated">随机分类器随机给样本分配标签。客观地说，你当地动物园的黑猩猩会用随机分类器来分类这些新闻短片。</p></blockquote><p id="5b18" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们确定这个随机基线:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nv nw l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">代码由<a class="ae lv" href="http://github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> rakshitraj </a>托管在<a class="ae lv" href="https://gist.github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上</p></figure><p id="f417" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">考虑到随机基线约为 19%，我们的模型以约 80%的准确度表现得相当好。</p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="d000" class="mu lx it bd ly mv nm mx mb my nn na me jz no ka mh kc np kd mk kf nq kg mn ne bi translated">一个信息瓶颈模型</h1><p id="592c" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">这次我们在模型中引入了一个信息瓶颈。我们的一个图层将会丢失数据，我们将会看到它对模型性能的影响，即其准确性的下降。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="nv nw l"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">由<a class="ae lv" href="http://github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> rakshitraj </a>托管在<a class="ae lv" href="https://gist.github.com/rakshitraj" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上的代码</p></figure><p id="2de6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">存在瓶颈时，测试精度会下降 10%</p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="3ce7" class="mu lx it bd ly mv nm mx mb my nn na me jz no ka mh kc np kd mk kf nq kg mn ne bi translated">结论</h1><p id="e241" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">至此，您已经成功地将路透社数据集中的新闻短片按照各自的主题进行了分类。您还将看到隐藏单元数量不足的层如何通过杀死宝贵的数据来破坏模型的性能。</p><blockquote class="ot ou ov"><p id="2a9b" class="ki kj le kk b kl km ju kn ko kp jx kq ow ks kt ku ox kw kx ky oy la lb lc ld im bi translated">信息瓶颈的影响是显而易见的，因为预测准确性大大降低。</p></blockquote><p id="56ee" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我建议你配合这篇文章。您可以使用类似的策略解决大多数多类分类问题。如果你解决了这个问题，试着修改网络及其层的设计和参数。这样做将帮助您更好地理解您所选择的模型的属性和架构。</p><p id="2941" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我在每篇文章中都详细讨论了一个话题。在这一篇中，我们探索了信息瓶颈。对任何特定主题的详尽解释从来不在我的写作范围之内；然而，你会发现大量的快速旁白。</p><p id="d5f1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我假设读者不是机器学习领域的完全新手。我在这篇文章之前和之前的更多工作链接如下；</p><div class="pa pb gp gr pc pd"><a rel="noopener follow" target="_blank" href="/binary-classification-of-imdb-movie-reviews-648342bc70dd"><div class="pe ab fo"><div class="pf ab pg cl cj ph"><h2 class="bd iu gy z fp pi fr fs pj fu fw is bi translated">IMDB 电影评论的二元分类</h2><div class="pk l"><h3 class="bd b gy z fp pi fr fs pj fu fw dk translated">使用 Keras 根据情感对评论进行分类。</h3></div><div class="pl l"><p class="bd b dl z fp pi fr fs pj fu fw dk translated">towardsdatascience.com</p></div></div><div class="pm l"><div class="pn l po pp pq pm pr lp pd"/></div></div></a></div><div class="pa pb gp gr pc pd"><a rel="noopener follow" target="_blank" href="/solve-the-mnist-image-classification-problem-9a2865bcf52a"><div class="pe ab fo"><div class="pf ab pg cl cj ph"><h2 class="bd iu gy z fp pi fr fs pj fu fw is bi translated">解决 MNIST 图像分类问题</h2><div class="pk l"><h3 class="bd b gy z fp pi fr fs pj fu fw dk translated">“你好，世界！”深度学习和 Keras</h3></div><div class="pl l"><p class="bd b dl z fp pi fr fs pj fu fw dk translated">towardsdatascience.com</p></div></div><div class="pm l"><div class="ps l po pp pq pm pr lp pd"/></div></div></a></div><p id="866a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">想了解更多，请查看我发誓的书——Francois Chollet 的《用 Python 进行深度学习》。</p><p id="b842" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请随意查看本文的<a class="ae lv" href="https://github.com/rakshitraj/fchollet/" rel="noopener ugc nofollow" target="_blank">实现</a>以及我在<a class="ae lv" href="https://github.com/rakshitraj/" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上的更多工作。</p><p id="99ec" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢阅读！</p></div></div>    
</body>
</html>