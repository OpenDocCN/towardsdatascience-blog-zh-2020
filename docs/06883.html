<html>
<head>
<title>7 PyTorch functions for your next Machine Learning project</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为您的下一个机器学习项目提供7个PyTorch函数</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/useful-pytorch-functions-356de5f31a1e?source=collection_archive---------34-----------------------#2020-05-28">https://towardsdatascience.com/useful-pytorch-functions-356de5f31a1e?source=collection_archive---------34-----------------------#2020-05-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="c656" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">机器学习</h2><div class=""/><div class=""><h2 id="faf5" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">探索各种PyTorch函数</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ko"><img src="../Images/1ca4e44f20f200c220b9b8908c26f592.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*yfMzZipUVEITSGagEIxQHQ.jpeg"/></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">图片来自<a class="ae la" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1995786" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae la" href="https://pixabay.com/users/geralt-9301/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1995786" rel="noopener ugc nofollow" target="_blank"> Gerd Altmann </a></p></figure><p id="1e09" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">PyTorch是一个越来越受欢迎的机器学习库。在本文中，我们将探索PyTorch中的七个可用函数。</p><p id="ce57" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">首先，我们将使用<code class="fe lx ly lz ma b">import torch</code>导入PyTorch</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h2 id="996e" class="mi mj iq bd mk ml mm dn mn mo mp dp mq lk mr ms mt lo mu mv mw ls mx my mz iw bi translated">功能一:torch.linspace</h2><p id="8959" class="pw-post-body-paragraph lb lc iq ld b le na ka lg lh nb kd lj lk nc lm ln lo nd lq lr ls ne lu lv lw ij bi translated"><code class="fe lx ly lz ma b">torch.linspace</code>用于在值<code class="fe lx ly lz ma b">start</code>和<code class="fe lx ly lz ma b">end</code>之间创建一个1D等距张量。我们可以用<code class="fe lx ly lz ma b">steps</code>参数指定张量的大小。默认为<code class="fe lx ly lz ma b">steps=100</code></p><p id="8bbb" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated"><strong class="ld ja"> <em class="nf">例-1: </em> </strong></p><pre class="kp kq kr ks gt ng ma nh ni aw nj bi"><span id="49d0" class="mi mj iq ma b gy nk nl l nm nn">torch.linspace(1, 10)</span><span id="d2a6" class="mi mj iq ma b gy no nl l nm nn"><strong class="ma ja">Output:</strong><br/>tensor([ 1.0000, 1.0909, 1.1818, 1.2727, 1.3636, 1.4545, 1.5455, 1.6364, 1.7273, 1.8182, 1.9091, 2.0000, 2.0909, 2.1818, 2.2727, 2.3636, 2.4545, 2.5455, 2.6364, 2.7273, 2.8182, 2.9091, 3.0000, 3.0909, 3.1818, 3.2727, 3.3636, 3.4545, 3.5455, 3.6364, 3.7273, 3.8182, 3.9091, 4.0000, 4.0909, 4.1818, 4.2727, 4.3636, 4.4545, 4.5455, 4.6364, 4.7273, 4.8182, 4.9091, 5.0000, 5.0909, 5.1818, 5.2727, 5.3636, 5.4545, 5.5455, 5.6364, 5.7273, 5.8182, 5.9091, 6.0000, 6.0909, 6.1818, 6.2727, 6.3636, 6.4545, 6.5455, 6.6364, 6.7273, 6.8182, 6.9091, 7.0000, 7.0909, 7.1818, 7.2727, 7.3636, 7.4545, 7.5455, 7.6364, 7.7273, 7.8182, 7.9091, 8.0000, 8.0909, 8.1818, 8.2727, 8.3636, 8.4545, 8.5455, 8.6364, 8.7273, 8.8182, 8.9091, 9.0000, 9.0909, 9.1818, 9.2727, 9.3636, 9.4545, 9.5455, 9.6364, 9.7273, 9.8182, 9.9091, 10.0000])</span></pre><p id="2231" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated"><strong class="ld ja"> <em class="nf">例-2: </em> </strong></p><pre class="kp kq kr ks gt ng ma nh ni aw nj bi"><span id="35dd" class="mi mj iq ma b gy nk nl l nm nn">torch.linspace(start=1, end=10, steps=5)</span><span id="d89a" class="mi mj iq ma b gy no nl l nm nn"><strong class="ma ja">Output:</strong><br/>tensor([ 1.0000,  3.2500,  5.5000,  7.7500, 10.0000])</span></pre></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h2 id="f7e2" class="mi mj iq bd mk ml mm dn mn mo mp dp mq lk mr ms mt lo mu mv mw ls mx my mz iw bi translated">功能二:手电筒.眼睛</h2><p id="a4a5" class="pw-post-body-paragraph lb lc iq ld b le na ka lg lh nb kd lj lk nc lm ln lo nd lq lr ls ne lu lv lw ij bi translated"><code class="fe lx ly lz ma b">torch.eye</code>返回对角线值为1，其他值为0的2D张量<br/>该函数需要两个参数— <code class="fe lx ly lz ma b">n</code>和<code class="fe lx ly lz ma b">m</code>。如果没有指定<code class="fe lx ly lz ma b">m</code>，那么它返回一个大小为<code class="fe lx ly lz ma b">nxn</code>的2D张量</p><p id="2a4c" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated"><strong class="ld ja"> <em class="nf">例-1: </em> </strong></p><pre class="kp kq kr ks gt ng ma nh ni aw nj bi"><span id="bb3e" class="mi mj iq ma b gy nk nl l nm nn">torch.eye(n=4, m=5)</span><span id="335d" class="mi mj iq ma b gy no nl l nm nn"><strong class="ma ja">Output:<br/></strong>tensor([[1., 0., 0., 0., 0.],<br/>        [0., 1., 0., 0., 0.],<br/>        [0., 0., 1., 0., 0.],<br/>        [0., 0., 0., 1., 0.]])</span></pre><p id="fa2f" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated"><strong class="ld ja"> <em class="nf">例-2: </em> </strong></p><pre class="kp kq kr ks gt ng ma nh ni aw nj bi"><span id="71fd" class="mi mj iq ma b gy nk nl l nm nn">torch.eye(n=3)</span><span id="0929" class="mi mj iq ma b gy no nl l nm nn"><strong class="ma ja">Output:</strong><br/>tensor([[1., 0., 0.],<br/>        [0., 1., 0.],<br/>        [0., 0., 1.]])</span></pre></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h2 id="f705" class="mi mj iq bd mk ml mm dn mn mo mp dp mq lk mr ms mt lo mu mv mw ls mx my mz iw bi translated">功能三:火炬。满</h2><p id="a04c" class="pw-post-body-paragraph lb lc iq ld b le na ka lg lh nb kd lj lk nc lm ln lo nd lq lr ls ne lu lv lw ij bi translated"><code class="fe lx ly lz ma b">torch.full</code>返回一个大小为<code class="fe lx ly lz ma b">size</code>的张量，其值填充为<code class="fe lx ly lz ma b">fill_value</code><br/><code class="fe lx ly lz ma b">size</code>可以是一个列表或元组。</p><p id="a876" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated"><strong class="ld ja"> <em class="nf">例题-1: </em> </strong></p><pre class="kp kq kr ks gt ng ma nh ni aw nj bi"><span id="fca8" class="mi mj iq ma b gy nk nl l nm nn">torch.full(size=(3,2), fill_value=10)</span><span id="d640" class="mi mj iq ma b gy no nl l nm nn"><strong class="ma ja">Output:<br/></strong>tensor([[10., 10.],<br/>        [10., 10.],<br/>        [10., 10.]])</span></pre><p id="7d49" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated"><strong class="ld ja"> <em class="nf">例-2: </em> </strong></p><pre class="kp kq kr ks gt ng ma nh ni aw nj bi"><span id="b665" class="mi mj iq ma b gy nk nl l nm nn">torch.full(size=[2, 3, 4], fill_value=5)</span><span id="94bf" class="mi mj iq ma b gy no nl l nm nn"><strong class="ma ja">Output:</strong><br/>tensor([[[5., 5., 5., 5.],<br/>         [5., 5., 5., 5.],<br/>         [5., 5., 5., 5.]],</span><span id="3593" class="mi mj iq ma b gy no nl l nm nn">[[5., 5., 5., 5.],<br/>         [5., 5., 5., 5.],<br/>         [5., 5., 5., 5.]]])</span></pre></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h2 id="e96b" class="mi mj iq bd mk ml mm dn mn mo mp dp mq lk mr ms mt lo mu mv mw ls mx my mz iw bi translated">功能四:torch.cat</h2><p id="a9f3" class="pw-post-body-paragraph lb lc iq ld b le na ka lg lh nb kd lj lk nc lm ln lo nd lq lr ls ne lu lv lw ij bi translated"><code class="fe lx ly lz ma b">torch.cat</code>连接指定维度上的一系列张量<code class="fe lx ly lz ma b">dim</code>。所有的张量必须是相同的形状</p><p id="2d24" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated"><strong class="ld ja"> <em class="nf">例-1: </em> </strong></p><pre class="kp kq kr ks gt ng ma nh ni aw nj bi"><span id="8e30" class="mi mj iq ma b gy nk nl l nm nn">a = torch.ones(3,2)<br/>b = torch.zeros(3,2)<br/>torch.cat((a, b)) # default dim=0</span><span id="2d2c" class="mi mj iq ma b gy no nl l nm nn"><strong class="ma ja">Output:<br/></strong>tensor([[1., 1.],<br/>        [1., 1.],<br/>        [1., 1.],<br/>        [0., 0.],<br/>        [0., 0.],<br/>        [0., 0.]])</span></pre><p id="1aeb" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated"><strong class="ld ja"> <em class="nf">例-2: </em> </strong></p><pre class="kp kq kr ks gt ng ma nh ni aw nj bi"><span id="82b8" class="mi mj iq ma b gy nk nl l nm nn">x = torch.full((3,3), fill_value=4)<br/>y = torch.full((3,3), fill_value=7)<br/>torch.cat((x, y), dim=1)</span><span id="75e6" class="mi mj iq ma b gy no nl l nm nn"><strong class="ma ja">Output:<br/></strong>tensor([[4., 4., 4., 7., 7., 7.],<br/>        [4., 4., 4., 7., 7., 7.],<br/>        [4., 4., 4., 7., 7., 7.]])</span></pre></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h2 id="4794" class="mi mj iq bd mk ml mm dn mn mo mp dp mq lk mr ms mt lo mu mv mw ls mx my mz iw bi translated">功能五:火炬.拿</h2><p id="cadb" class="pw-post-body-paragraph lb lc iq ld b le na ka lg lh nb kd lj lk nc lm ln lo nd lq lr ls ne lu lv lw ij bi translated"><code class="fe lx ly lz ma b">torch.take</code>返回给定索引处输入张量元素的张量。输入张量被视为1D张量来返回值。</p><p id="a311" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated"><strong class="ld ja"> <em class="nf">例-1: </em> </strong></p><pre class="kp kq kr ks gt ng ma nh ni aw nj bi"><span id="e5dd" class="mi mj iq ma b gy nk nl l nm nn"># 1D input Tensor<br/>b = torch.tensor([10, 20, 30, 40, 50])<br/>torch.take(b, torch.tensor([2]))</span><span id="0174" class="mi mj iq ma b gy no nl l nm nn"><strong class="ma ja">Output:</strong><br/>tensor([30])</span></pre><p id="0106" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated"><strong class="ld ja"> <em class="nf">例-2: </em> </strong></p><pre class="kp kq kr ks gt ng ma nh ni aw nj bi"><span id="d33b" class="mi mj iq ma b gy nk nl l nm nn"># 2D input tensor<br/>a = torch.tensor([[1, 2, 3],<br/>                  [4, 5, 6]])<br/>torch.take(a, torch.tensor([3,4]))</span><span id="a800" class="mi mj iq ma b gy no nl l nm nn"><strong class="ma ja">Output:<br/></strong>tensor([4, 5])</span></pre></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h2 id="b3fd" class="mi mj iq bd mk ml mm dn mn mo mp dp mq lk mr ms mt lo mu mv mw ls mx my mz iw bi translated">功能6: torch.unbind</h2><p id="227e" class="pw-post-body-paragraph lb lc iq ld b le na ka lg lh nb kd lj lk nc lm ln lo nd lq lr ls ne lu lv lw ij bi translated"><code class="fe lx ly lz ma b">torch.unbind</code>沿给定维度<code class="fe lx ly lz ma b">dim</code> <br/>删除一个张量维度，默认维度为0，即<code class="fe lx ly lz ma b">dim=0</code></p><p id="fec2" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated"><strong class="ld ja"> <em class="nf">例-1: </em> </strong></p><pre class="kp kq kr ks gt ng ma nh ni aw nj bi"><span id="698a" class="mi mj iq ma b gy nk nl l nm nn">a = torch.tensor([[1, 2, 3],<br/>                  [4, 5, 6]])<br/>torch.unbind(a)</span><span id="a5f3" class="mi mj iq ma b gy no nl l nm nn"><strong class="ma ja">Output:</strong><br/>(tensor([1, 2, 3]), tensor([4, 5, 6]))</span></pre><p id="532b" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated"><strong class="ld ja"> <em class="nf">例-2: </em> </strong></p><pre class="kp kq kr ks gt ng ma nh ni aw nj bi"><span id="fc38" class="mi mj iq ma b gy nk nl l nm nn">a = torch.tensor([[1, 2, 3],<br/>                  [4, 5, 6]])<br/>torch.unbind(a, dim=1)</span><span id="0122" class="mi mj iq ma b gy no nl l nm nn"><strong class="ma ja">Output:</strong><br/>(tensor([1, 4]), tensor([2, 5]), tensor([3, 6]))</span></pre></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h2 id="9f0f" class="mi mj iq bd mk ml mm dn mn mo mp dp mq lk mr ms mt lo mu mv mw ls mx my mz iw bi translated">功能七:火炬。张量克隆</h2><p id="6b38" class="pw-post-body-paragraph lb lc iq ld b le na ka lg lh nb kd lj lk nc lm ln lo nd lq lr ls ne lu lv lw ij bi translated"><code class="fe lx ly lz ma b">torch.Tensor.clone</code>返回相同大小和数据类型的张量副本。</p><p id="3c1d" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">当我们使用<code class="fe lx ly lz ma b">x=y</code>创建张量的副本时，改变一个变量也会影响另一个变量，因为它指向相同的内存位置。</p><p id="d7f4" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">举个例子，</p><pre class="kp kq kr ks gt ng ma nh ni aw nj bi"><span id="53b6" class="mi mj iq ma b gy nk nl l nm nn">a = torch.tensor([[1., 2.],<br/>                  [3., 4.],<br/>                  [5., 6.]])<br/>b = a<br/>a[1,0]=9<br/>b</span><span id="ae02" class="mi mj iq ma b gy no nl l nm nn"><strong class="ma ja">Output:</strong><br/>tensor([[1., 2.],<br/>        [9., 4.],<br/>        [5., 6.]])</span></pre><p id="585e" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">为了避免这种情况，我们可以使用<code class="fe lx ly lz ma b">.clone</code>方法创建张量的深度副本。</p><p id="bebf" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated"><strong class="ld ja"> <em class="nf">举例:</em> </strong></p><pre class="kp kq kr ks gt ng ma nh ni aw nj bi"><span id="e9f5" class="mi mj iq ma b gy nk nl l nm nn">a = torch.tensor([[1., 2.],<br/>                  [3., 4.],<br/>                  [5., 6.]])<br/>b = a.clone()<br/>a[1,0]=9<br/>b</span><span id="be70" class="mi mj iq ma b gy no nl l nm nn"><strong class="ma ja">Output:</strong><br/>tensor([[1., 2.],<br/>        [3., 4.],<br/>        [5., 6.]])</span></pre></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="6b8a" class="np mj iq bd mk nq nr ns mn nt nu nv mq kf nw kg mt ki nx kj mw kl ny km mz nz bi translated">结论</h1><p id="a5a7" class="pw-post-body-paragraph lb lc iq ld b le na ka lg lh nb kd lj lk nc lm ln lo nd lq lr ls ne lu lv lw ij bi translated">在本文中，我们看到了PyTorch中七个可用函数的工作原理。希望这篇文章能帮助你理解这些功能。还有许多其他有用的功能。您可以参考<a class="ae la" href="https://pytorch.org/docs/stable/index.html" rel="noopener ugc nofollow" target="_blank">官方文档</a>获取可用功能的完整列表。</p><h2 id="9452" class="mi mj iq bd mk ml mm dn mn mo mp dp mq lk mr ms mt lo mu mv mw ls mx my mz iw bi translated">参考</h2><ul class=""><li id="558a" class="oa ob iq ld b le na lh nb lk oc lo od ls oe lw of og oh oi bi translated">【https://pytorch.org/docs/stable/torch.html】</li><li id="95a7" class="oa ob iq ld b le oj lh ok lk ol lo om ls on lw of og oh oi bi translated"><a class="ae la" href="https://pytorch.org/docs/stable/tensors.html" rel="noopener ugc nofollow" target="_blank">https://pytorch.org/docs/stable/tensors.html</a></li></ul><h2 id="65aa" class="mi mj iq bd mk ml mm dn mn mo mp dp mq lk mr ms mt lo mu mv mw ls mx my mz iw bi translated">资源</h2><p id="9420" class="pw-post-body-paragraph lb lc iq ld b le na ka lg lh nb kd lj lk nc lm ln lo nd lq lr ls ne lu lv lw ij bi translated">本文中使用的代码片段可以在我的GitHub页面上找到。</p><h2 id="d0c2" class="mi mj iq bd mk ml mm dn mn mo mp dp mq lk mr ms mt lo mu mv mw ls mx my mz iw bi translated">让我们连接</h2><p id="4a42" class="pw-post-body-paragraph lb lc iq ld b le na ka lg lh nb kd lj lk nc lm ln lo nd lq lr ls ne lu lv lw ij bi translated">领英:<a class="ae la" href="https://www.linkedin.com/in/jimit105/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/jimit105/</a><br/>GitHub:<a class="ae la" href="https://github.com/jimit105" rel="noopener ugc nofollow" target="_blank">https://github.com/jimit105</a><br/>推特:<a class="ae la" href="https://twitter.com/jimit105" rel="noopener ugc nofollow" target="_blank">https://twitter.com/jimit105</a></p></div></div>    
</body>
</html>