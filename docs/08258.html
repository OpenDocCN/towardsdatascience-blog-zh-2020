<html>
<head>
<title>Entropy, Cross-Entropy, and KL-Divergence Explained!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">熵，交叉熵，KL-散度解释！</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/entropy-cross-entropy-and-kl-divergence-explained-b09cdae917a?source=collection_archive---------6-----------------------#2020-06-17">https://towardsdatascience.com/entropy-cross-entropy-and-kl-divergence-explained-b09cdae917a?source=collection_archive---------6-----------------------#2020-06-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0bd1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">让我们试着去理解最广泛使用的损失函数——交叉熵。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c51c463d0ee0551527ab933fae24cd5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*puZoiNjS-9-E_-4coQP0MA.gif"/></div></div></figure><p id="a01c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">交叉熵</strong>(也称为 log-loss)是分类问题最常用的损失函数之一。但是我们大多数人经常在没有真正了解熵的核心概念的情况下就开始解决问题，这是由于当今庞大的库和框架的存在以及它们的易用性。因此，在这篇文章中，让我们来看看<strong class="kw iu">熵</strong>背后的基本直觉，将它与<strong class="kw iu">交叉熵</strong>和<strong class="kw iu">KL-散度</strong>联系起来。我们还将检查一个使用损失函数作为交叉熵的分类问题的例子。</p><h1 id="53bd" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">熵是什么？</h1><p id="2f27" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">为了开始了解熵到底指的是什么，让我们深入一些信息论的基础知识。在这个数字时代，信息由比特(0 和 1)组成。交流的时候，有些比特是有用的，有些是多余的，有些是错误的，等等。当我们传递信息时，我们希望向接收者传递尽可能多的有用信息。</p><blockquote class="mn mo mp"><p id="fed7" class="ku kv mq kw b kx ky ju kz la lb jx lc mr le lf lg ms li lj lk mt lm ln lo lp im bi translated">在克劳德·香农的论文《通信的数学理论》(1948 年)中，他指出，传输 1 比特的信息意味着将接收者的不确定性减少 2 倍。</p></blockquote><p id="7e61" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们看看他是什么意思。例如，假设一个地方的天气是随机的，每天有 50%的几率是晴天或雨天。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/aeb82ab209f0c681bbfa6edd47cb9672.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0-R7tJPKYOIFvPmSx5kHSA.png"/></div></div></figure><p id="4563" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在，如果一个气象站告诉你明天会下雨，那么他们已经把你的不确定性降低了 2 倍。起初，有两种同样可能的可能性，但在收到气象站的更新后，我们只有一种可能。这里，气象站给我们发送了一点有用的信息，不管他们如何编码这些信息，这都是真的。</p><p id="5a92" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">即使发送的消息是‘Rainy’并且每个字符占用一个字节，消息的总大小对应于 40 比特，但是它们仍然只传达了 1 比特的有用信息。</p><p id="f393" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">假设天气有 8 种可能的状态，所有的可能性相等。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/fcfb8d53cb630078a99cb182e3aaaecf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qc4jR_dYJOnVu3fWaBxpbQ.png"/></div></div></figure><p id="3cd7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在，当气象站给你第二天的天气时，他们就把你的不确定性降低了 8 倍。因为每个事件有 1/8 的机会发生，所以缩减系数是 8。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mv"><img src="../Images/f3c1ba57f29d8044d05f8de45cf3fbe4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lXZdA5VkvlE52iDsX9Ixgg.png"/></div></div></figure></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><p id="def5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">但是如果可能性不相等呢？</p><p id="1420" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">比方说，75%的机会是晴天，25%的机会是雨天。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/9cda59d746a2c87bc600045bcc6064fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9-GVusf41EyDGZ75atbPaQ.png"/></div></div></figure><p id="3055" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在，如果气象站说第二天将会下雨，那么你的不确定性下降了 4 倍，这是 2 比特的信息。不确定性的减少正好是事件概率的倒数。在这种情况下，25%的倒数是 4，对数(4)以 2 为底等于 2。所以，我们得到了两个有用的信息。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/2ac6b47747a3318726421286223dff86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qgPQnG_1I2K-x68je4AakA.png"/></div></div></figure><p id="e921" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果气象站说第二天将是晴天，那么我们得到 0.41 比特的有用信息。那么，平均来说，我们能从气象站获得多少信息呢？</p><p id="56d6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">嗯，明天有 75%的可能性是晴天，这给了你 0.41 比特的信息，而明天有 25%的可能性是雨天，这给了你 2 比特的信息，相当于，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/214064c6db2e81cfd7d267c2112affc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d68rPVramZU56ofFc62H8g.png"/></div></div></figure><p id="ace4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们平均每天从气象站得到 0.81 比特的信息。所以，我们刚刚计算的叫做熵。这很好地衡量了事件的不确定性。它是由，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/c5c8a6c2fda4705bb227391a1a3ecaec.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*NTU9P7Q105DEYTHxvZ7X2w.png"/></div></figure><p id="700b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">希望熵的方程式现在能完全有意义。它测量的是你每天了解天气时获得的平均信息量。一般来说，它给出了我们从一个给定的<strong class="kw iu">概率分布 p </strong>中抽取的样本中获得的平均信息量。它告诉我们概率分布是多么不可预测。</p><p id="b187" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果我们住在每天都阳光明媚的沙漠中心，平均来说，我们每天都不会从气象站获得太多信息。熵将接近于零。另一方面，如果天气变化很大，熵会大得多。</p></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><h1 id="3cce" class="lq lr it bd ls lt nf lv lw lx ng lz ma jz nh ka mc kc ni kd me kf nj kg mg mh bi translated">交叉熵</h1><p id="a98d" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">现在，我们来谈谈交叉熵。它只是平均消息长度。考虑同样的 8 种可能的天气状况的例子，所有都是同等可能的，每一种都可以用 3 比特编码。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/047b198121c2400b49a4c6dcb781148c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BTqGEd85ounUrHymqvIB9w.png"/></div></div></figure><p id="cb9f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这里的平均消息长度是 3，这就是交叉熵。</p><p id="f640" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">但是现在，假设你住在一个阳光充足的地区，那里的天气概率分布如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/41bae500c51f74c320c228c97ae46d0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tzPWaOz9fHhylnsC7BI8Yg.png"/></div></div></figure><p id="eb33" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">每天有 35%的机会是晴天，只有 1%的机会是雷雨。所以，我们可以计算这个概率分布的熵，我们得到，</p><p id="65bb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">熵=-(0.35 * log(0.35)+0.35 * log(0.35)+0.1 * log(0.1)+0.1 * log(0.1)+0.04 * log(0.04)+0.01 * log(0.01)+0.01 * log(0.01))</strong></p><p id="c43f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">熵= 2.23 比特</strong></p><p id="19cd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">注意，这里使用的日志是一个<strong class="kw iu">二进制日志。</strong></p><p id="933e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，平均来说，气象站发送了 3 个比特，但接收者只能得到 2.23 个有用的比特。我们可以做得更好。</p><p id="a1e2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">例如，让我们这样修改代码:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/734c95d21bd206f5023895b5ca153edf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NsKqsgzbBp00jeVDE0aW_A.png"/></div></div></figure><p id="b94d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们现在只使用 2 位表示晴天或部分晴天，3 位表示多云和大部分多云，4 位表示小雨和中雨，5 位表示大雨和雷雨。天气是以一种明确的方式编码的，如果你将多条消息链接起来，只有一种方式来解释比特序列。例如，01100 只能表示部分晴，然后是小雨。所以，如果我们计算电台每天发送的平均比特数，那么我们得到，</p><p id="4611" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">35% * 2+35% * 2+10% * 3+10% * 3+4% * 4+4% * 4+1% * 5+1% * 5 = 2.42 位</strong></p><p id="8685" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是我们新的和改进的交叉熵，比我们以前的 3 位更好。现在，假设我们在不同的地方使用相同的代码，那里的天气是相反的，大部分时间是多雨的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/90ac07d91161f59614b8f4413a723538.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hsuQ4426UFXL-87EZiiy5w.png"/></div></div></figure><p id="fde7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">对于这个，如果我们计算交叉熵，</p><p id="8ffd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">1% * 2+1% * 2+4% * 3+4% * 3+10% * 4+10% * 4+35% * 5+35% * 5 = 4.58 位</strong></p><p id="0582" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们得到 4.58 比特。它大约是熵的两倍。平均而言，该站发送 4.58 比特，但只有 2.23 比特对接收者有用。每封邮件发送的信息是必要信息的两倍。这是因为我们使用的代码对天气分布做了一些隐含的假设。例如，当我们用一个 2 位的信息来表示晴朗的天气时，我们隐含地预测了晴天的概率为 25%。这是因为负二进制对数(0.25)给出 2。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/f9cdc501bf8e532040420818e143c2af.png" data-original-src="https://miro.medium.com/v2/resize:fit:338/format:webp/1*TuSUYxyBMA6ZMDmxptwEEg.png"/></div></figure><p id="a958" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">同样，我们计算所有的天气条件。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/2e18ded73b9f96d6b8b4d994b476a287.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nKRdrhNyiDAu7qwvVl4dQg.png"/></div></div></figure><p id="4e8e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">分母中 2 的幂对应于用于传输消息的位数。现在，很明显，预测的分布<strong class="kw iu"> <em class="mq"> q </em> </strong>与真实的分布<strong class="kw iu"> <em class="mq"> p </em> </strong>大相径庭。</p><p id="b0d6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，现在我们可以将交叉熵表示为真实概率分布<strong class="kw iu"> <em class="mq"> p </em> </strong>和预测概率分布<strong class="kw iu"> <em class="mq"> q </em> </strong>的函数，其表示为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/fb754dd94d066880c83251490569fcad.png" data-original-src="https://miro.medium.com/v2/resize:fit:938/format:webp/1*KI8UdQQfy3gpnuw0EGCukg.png"/></div></figure><p id="3a05" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">请注意，我们示例中使用的日志是针对<strong class="kw iu">基 2 </strong>的。</p><p id="372a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如你所见，它看起来非常类似于熵方程，除了我们在这里使用预测概率的对数。如果我们的预测是完美的，即预测的分布等于真实的分布，那么交叉熵就等于熵。但是，如果分布不同，那么交叉熵将比熵大一些位数。交叉熵超过熵的这个量被称为<strong class="kw iu">相对熵</strong>或者更普遍地被称为<strong class="kw iu">库尔巴克-莱布勒散度(KL 散度)</strong>。简言之，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/d4228d2049898175c8271f3b4bb284be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UOgoqPiXjYCgvWrsWJp2XQ.png"/></div></div></figure><p id="3b96" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">从上面的例子中，我们得到</p><p id="bc8a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> K-L 散度=交叉熵-熵= 4.58–2.23 = 2.35 比特。</strong></p></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><h1 id="114b" class="lq lr it bd ls lt nf lv lw lx ng lz ma jz nh ka mc kc ni kd me kf nj kg mg mh bi translated">应用</h1><p id="20e6" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">现在，让我们在一个应用中使用交叉熵。假设我们正在训练一个图像分类器来分类不同的看起来很像的动物，比如浣熊、小熊猫、狐狸等等。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/f07ac73b6f66ba0f95dd916eca655d3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dlhjjZxaxKIDC9lWkIODmQ.png"/></div></div></figure><p id="f248" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，对于可能的 7 个类别中的每一个，分类器估计一个概率，这被称为预测分布。由于这是一个监督学习问题，我们知道真实的分布。</p><p id="b1da" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在上面的例子中，我拍摄了一只浣熊的图像，因此在真实分布中，它的概率为 100%，其他的概率为 0。我们可以使用这两个分布之间的交叉熵作为成本函数，称为<strong class="kw iu">交叉熵损失</strong>。</p><p id="87e1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这只是我们之前看到的等式，只是它通常使用自然对数，而不是二进制对数。这对于训练来说关系不大，因为二进制 log(x)等于自然 log(x)/log(2)，其中分母是常数。</p><p id="65ae" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，当类别概率被称为一个热点向量(这意味着一个类别有 100%，其余的都是 0)时，那么交叉熵就是真实类别的估计概率的负对数。</p><p id="8e68" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这个例子中，<strong class="kw iu">交叉熵是-1*log(0.3) = — log(0.3) = 1.203 </strong></p><p id="8a97" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在，你可以看到，当真实类的预测概率接近于 0 时，成本会增长得非常大。但是当预测概率接近 1 时，代价函数接近 0。</p><p id="639d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">由于获得的损失更多(因为预测的分布太低)，我们需要用每个类别的更多数量的示例来训练分类器，以减少损失量。</p></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><h1 id="4624" class="lq lr it bd ls lt nf lv lw lx ng lz ma jz nh ka mc kc ni kd me kf nj kg mg mh bi translated">结论</h1><p id="8f58" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">我们举了一个气象站更新第二天天气的例子来理解香农信息论的概念。然后我们把它与熵和交叉熵联系起来。最后，我们通过一个例子来说明交叉熵损失函数的实际应用。我希望这篇文章阐明了熵、交叉熵和 KL 散度背后的基本直觉以及它们之间的关系。</p></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><h2 id="b207" class="nn lr it bd ls no np dn lw nq nr dp ma ld ns nt mc lh nu nv me ll nw nx mg ny bi translated"><strong class="ak">参考文献</strong></h2><ol class=""><li id="3b12" class="nz oa it kw b kx mi la mj ld ob lh oc ll od lp oe of og oh bi translated">"使用 Scikit-Learn 和 TensorFlow 进行机器实践学习."作者奥雷连·盖伦。</li><li id="9ba3" class="nz oa it kw b kx oi la oj ld ok lh ol ll om lp oe of og oh bi translated"><a class="ae on" href="https://www.youtube.com/watch?v=ErfnhcEV1O8" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=ErfnhcEV1O8</a></li></ol></div></div>    
</body>
</html>