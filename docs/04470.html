<html>
<head>
<title>Having Fun Learning CNNs: Example of Dog Breed Prediction Applicable to Human Images</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">愉快地学习CNN:适用于人类图像的狗品种预测示例</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/having-fun-learning-cnns-example-of-dog-breed-prediction-applicable-to-human-images-59b0700462b5?source=collection_archive---------39-----------------------#2020-04-21">https://towardsdatascience.com/having-fun-learning-cnns-example-of-dog-breed-prediction-applicable-to-human-images-59b0700462b5?source=collection_archive---------39-----------------------#2020-04-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="efbd" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">应用程序的核心算法，根据狗的品种对狗的图像进行分类，并在提供人的图像时输出最相似的品种。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/2c1b867dcd2b1dcb8edcf75a12a4a5fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*OOaUe_weWfTWhXQLGVkY0A.jpeg"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">图0:预期输出。</p></figure><h1 id="d2e0" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">一.项目定义</h1><h2 id="b0c6" class="lj ks iq bd kt lk ll dn kx lm ln dp lb lo lp lq ld lr ls lt lf lu lv lw lh lx bi translated"><strong class="ak">项目概述</strong></h2><p id="b84b" class="pw-post-body-paragraph ly lz iq ma b mb mc jr md me mf ju mg lo mh mi mj lr mk ml mm lu mn mo mp mq ij bi translated">这个项目旨在创建一个核心算法，根据狗的品种对狗的图像进行分类，这可以用作移动或网络应用的一部分。该应用程序应该提供一个有趣的用户体验，因为它不仅接受狗的图像，而且接受任何用户提供的图像作为输入。如果检测到狗，算法应该输出狗的品种预测。如果检测到人类，输出的应该是最像狗的品种！</p><h2 id="a570" class="lj ks iq bd kt lk ll dn kx lm ln dp lb lo lp lq ld lr ls lt lf lu lv lw lh lx bi translated"><strong class="ak">问题陈述</strong></h2><p id="ed0c" class="pw-post-body-paragraph ly lz iq ma b mb mc jr md me mf ju mg lo mh mi mj lr mk ml mm lu mn mo mp mq ij bi translated">使用的分类器是卷积神经网络(CNN)，它被称为最先进的图像分类。涉及以下步骤:</p><p id="05a8" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">-预处理图像</p><p id="8f46" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">-建立辅助功能，如人类探测器和狗探测器</p><p id="1a78" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">-从头开始尝试构建CNN分类器</p><p id="60c5" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">-使用迁移学习训练分类器</p><p id="1b26" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">-预测和分析结果</p><p id="0664" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">在整个项目中，用于构建CNN架构的主要库是Keras。</p><h2 id="0c32" class="lj ks iq bd kt lk ll dn kx lm ln dp lb lo lp lq ld lr ls lt lf lu lv lw lh lx bi translated"><strong class="ak">指标</strong></h2><p id="40fa" class="pw-post-body-paragraph ly lz iq ma b mb mc jr md me mf ju mg lo mh mi mj lr mk ml mm lu mn mo mp mq ij bi translated">犬种分类器是一个多类分类问题，因此最相关的评价指标是准确性。准确度被定义为正确预测的数量与做出的预测的总数之比。值得注意的是，该模型将仅在狗图像上进行评估，尽管它将用于预测与人类图像最相似的狗品种。</p></div><div class="ab cl mw mx hu my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="ij ik il im in"><h1 id="88ae" class="kr ks iq bd kt ku nd kw kx ky ne la lb jw nf jx ld jz ng ka lf kc nh kd lh li bi translated">二。分析</h1><h2 id="aa14" class="lj ks iq bd kt lk ll dn kx lm ln dp lb lo lp lq ld lr ls lt lf lu lv lw lh lx bi translated"><strong class="ak">数据探索</strong></h2><p id="528a" class="pw-post-body-paragraph ly lz iq ma b mb mc jr md me mf ju mg lo mh mi mj lr mk ml mm lu mn mo mp mq ij bi translated">主数据集总共包含8351张狗的图片(Credit: <a class="ae ni" href="https://github.com/udacity/dog-project" rel="noopener ugc nofollow" target="_blank"> Udacity </a>)，数量相当少。这些图片预先标注了133个犬种名称。数据集分为训练集、评估集和测试集，比例分别为80%、10%和10%。</p><p id="a985" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">这里展示了一些狗的图片:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nk nl di nm bf nn"><div class="gh gi nj"><img src="../Images/cb70adbcf458f94a94aa4425e9ed24a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*titQEGE_fhkowmGMKE4izA.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">图1:数据集中狗图像的一些例子。数据集信用:<a class="ae ni" href="https://github.com/udacity/dog-project" rel="noopener ugc nofollow" target="_blank"> Udacity </a></p></figure><p id="5cc9" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">很容易发现以下情况:</p><p id="7670" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">-图像大小不均匀，因此必须进行图像预处理。</p><p id="8f73" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">-在一幅图像中可以有不止一只狗，因此分类模型的学习任务将更加复杂。</p><p id="7372" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">-图像提供有白色背景或彩色和不同背景，其中可以发现各种对象。</p><p id="6d3b" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">分类的任务是非常具有挑战性的，因为在一些犬种对之间存在最小的类间差异，即使是人也很难区分。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/81cb0e77e4f1e0da39b415b0e0d329d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*_UoymN0boR8OQDnYipUmDg.jpeg"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">图2:模型能够区分布列塔尼和威尔士史宾格猎犬吗？。信用:<a class="ae ni" href="https://github.com/udacity/dog-project" rel="noopener ugc nofollow" target="_blank"> Udacity。</a></p></figure><p id="18ec" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">同时，由于高的类内变异，算法将不得不找出如何将不同颜色的狗分类为同一品种。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nk nl di nm bf nn"><div class="gh gi np"><img src="../Images/2808f69604f643721b8dbdad8f3d3f6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KHjGgSxBM2SAehqJwDEnGw.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">图3:将黄色、巧克力色和黑色拉布拉多归类为同一品种很有挑战性。信用:<a class="ae ni" href="https://github.com/udacity/dog-project" rel="noopener ugc nofollow" target="_blank"> Udacity </a>。</p></figure><p id="878a" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">此外，还提供了13，233幅人体图像的数据集。这将有助于测试人类检测器的功能以及最终算法的输出。</p><h2 id="d308" class="lj ks iq bd kt lk ll dn kx lm ln dp lb lo lp lq ld lr ls lt lf lu lv lw lh lx bi translated"><strong class="ak">数据可视化</strong></h2><p id="97f3" class="pw-post-body-paragraph ly lz iq ma b mb mc jr md me mf ju mg lo mh mi mj lr mk ml mm lu mn mo mp mq ij bi translated">下图显示了每类训练图像的分布。可见品类之间是不平衡的。频率最高的类大约是训练集大小的1.2%，而频率最低的类大约低3倍(训练集大小的0.4%)。这种不平衡问题可能会导致过度拟合，而模型可能更适合常见的犬种。</p><p id="65dd" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">然而，这种不平衡并不严重，就像有些班级图像很少一样。事实上，就绝对数量而言，每类图像的数量大约在26到80之间。这不会阻止模型学习并以一定的准确度输出预测。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nk nl di nm bf nn"><div class="gh gi nq"><img src="../Images/76243afcc6a39a42c8490d406a6040df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gnNUSkHMJWfWfKCK5BgFhw.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">图4:训练狗图像分布不均衡。</p></figure></div><div class="ab cl mw mx hu my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="ij ik il im in"><h1 id="c0a8" class="kr ks iq bd kt ku nd kw kx ky ne la lb jw nf jx ld jz ng ka lf kc nh kd lh li bi translated">三。方法学</h1><h2 id="c5b7" class="lj ks iq bd kt lk ll dn kx lm ln dp lb lo lp lq ld lr ls lt lf lu lv lw lh lx bi translated"><strong class="ak">数据预处理</strong></h2><p id="7608" class="pw-post-body-paragraph ly lz iq ma b mb mc jr md me mf ju mg lo mh mi mj lr mk ml mm lu mn mo mp mq ij bi translated">由Keras构建的CNN需要具有形状(nb_samples，rows，column，channels)的4D输入张量，其中nb_samples对应于图像的总数，rows，column和channels分别对应于每个图像的行数、列数和通道数。</p><p id="4ebc" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">从上面可以看出，输入图像需要预处理。图像预处理函数以彩色图像文件路径作为输入，加载图像，将其调整为224x224像素的正方形图像，将其转换为数组，最后输出适合Keras模型的4D张量。为了加快训练过程，每个图像都被重新缩放:每个像素在被馈送到模型之前被除以255。</p><h2 id="2c2f" class="lj ks iq bd kt lk ll dn kx lm ln dp lb lo lp lq ld lr ls lt lf lu lv lw lh lx bi translated"><strong class="ak">助手功能</strong></h2><p id="2a21" class="pw-post-body-paragraph ly lz iq ma b mb mc jr md me mf ju mg lo mh mi mj lr mk ml mm lu mn mo mp mq ij bi translated">为了检测输入图像包含人还是狗的图像，建立了两个辅助函数:第一个用于人脸检测，第二个用于狗的检测。</p><p id="9457" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">人类检测器使用OpenCV实现的<a class="ae ni" href="http://docs.opencv.org/trunk/d7/d8b/tutorial_py_face_detection.html" rel="noopener ugc nofollow" target="_blank">基于Haar特征的级联分类器</a>来检测图像中的人脸。在预训练模型被下载之后，人体检测器功能接受图像作为输入，并将其转换为灰度。根据在输入图像中是否检测到人脸，它输出一个布尔值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/8e1c7b7d4137a1aa30a5830e1ec42ce5.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*1QFnvGvCY3dUVSKAge6ccQ.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">图5:人体探测器。</p></figure><p id="08b0" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">人脸检测器功能已经在100幅人类图像和100幅狗图像上分别以100%和89%的准确率进行了测试。值得注意的是，在由算法检测到人脸的11幅狗图像中，有一幅具有清晰的人脸，两幅具有人体存在。尽管它在狗的图像上表现得并不完美，但它的准确性仍然是可以接受的。</p><p id="3394" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">同样，dog detector使用的是<a class="ae ni" href="http://ethereon.github.io/netscope/#/gist/db945b393d40bfa26006" rel="noopener ugc nofollow" target="_blank"> Resnet50 </a>模型，该模型已经在<a class="ae ni" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>上进行了预训练，这是一个来自<a class="ae ni" href="https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a" rel="noopener ugc nofollow" target="_blank"> 1000个类别</a>的+1000万图像数据集。虽然Resnet50模型预测ImageNet上的可用类别之一，但我们的狗检测器有一个附加功能:它检查预测的类别是否对应于狗类别，如果是，则返回True，否则返回False。</p><p id="3a52" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">就准确性而言，它在人和狗的图像上都表现完美。没有人的图像被检测为具有狗，并且100%的狗图像具有检测到的狗。</p><h2 id="d017" class="lj ks iq bd kt lk ll dn kx lm ln dp lb lo lp lq ld lr ls lt lf lu lv lw lh lx bi translated"><strong class="ak">实现</strong></h2><p id="7d9a" class="pw-post-body-paragraph ly lz iq ma b mb mc jr md me mf ju mg lo mh mi mj lr mk ml mm lu mn mo mp mq ij bi translated">实施过程可以分为两个主要步骤:</p><p id="e211" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">1.从头开始构建CNN模型</p><p id="b442" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">2.利用迁移学习获得更好的绩效</p><p id="51b7" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">第一阶段旨在试验不同的Keras基本模型。这一步应该很好地反映了如何在下一阶段调整预训练模型。</p><p id="9878" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">当从头开始构建CNN时，主要思想是增加整个层的频道数量，同时减少层的长度和宽度。</p><p id="f77a" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">为了能够快速测试性能，我构建了具有三到五个2D卷积层的小型架构。三种不同的模型进行了基准测试:</p><p id="4074" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">-第一个使用3个卷积层和3个填充层，随后是2个全连接层；</p><p id="857b" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">-第二个使用5个卷积层和5个填充层，然后是2个全连接层。</p><p id="1602" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">-第三个使用5个卷积层和5个填充层，然后是3个全连接层。</p><p id="72be" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">在每种情况下，密集层都配备了脱扣，以防止过度拟合。最终输出层配备了softmax功能。</p><p id="eaf9" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">对于第一个2D卷积层，我选择16作为信道数量，因为这是一个合理的数量，它将在各层中增加2倍。</p><p id="2e81" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">为了保持图像边缘附近像素处的输入值，选择相同的填充而不是有效的填充。</p><p id="8ba7" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">Relu激活被选择在2D卷积层，因为它在训练CNN模型的性能上的声誉。</p><p id="6179" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">在整个CNN中使用步长为1的3×3内核大小，以便捕捉每个像素的输入。这是由一些品种的高类内变异引起的，因此必须提取任何以狗的模式为特征的值。与5x5或7x7内核大小相比，这种内核大小还有助于减少参数数量。例如:对于第二个模型，3x3内核大小的网络有2616157个参数要训练，而5x5 CNN有3051101个，7x7 CNN有3703517个参数。</p><p id="40f2" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">对于池图层，选择大小为3、步幅为2的重叠最大池，以便提取邻近邻域中的主要特征值。这种选择是基于这样一个事实，即存在具有最小类间差异的犬种对，因此必须提取任何不同的特征值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nk nl di nm bf nn"><div class="gh gi ns"><img src="../Images/bf80c4bfbfc1d49d8d56e3617bde0c05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e1vpS7NWNA9nCwDIYIzG_w.jpeg"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">图6:从零开始构建CNN，你需要的只是Zen。在<a class="ae ni" href="https://unsplash.com/photos/MD6E2Sv__iA" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>归功于MartinSanchez。</p></figure><p id="c3a4" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">在第二阶段，迁移学习用于提高准确性和减少训练时间。预训练的<a class="ae ni" href="https://neurohive.io/en/popular-networks/vgg16/" rel="noopener ugc nofollow" target="_blank"> VGG-16 </a>被导入，它的最后卷积输出被馈送到我们的模型。模型中添加了一个全局平均池层和一个具有133个节点的全连接层。</p><h2 id="33fc" class="lj ks iq bd kt lk ll dn kx lm ln dp lb lo lp lq ld lr ls lt lf lu lv lw lh lx bi translated"><strong class="ak">精致</strong></h2><p id="3f84" class="pw-post-body-paragraph ly lz iq ma b mb mc jr md me mf ju mg lo mh mi mj lr mk ml mm lu mn mo mp mq ij bi translated">如上面实施部分所实验，使用迁移学习有助于提高模型准确性。但是，为了获得更高的性能并使算法更高效，有必要对模型进行微调。</p><p id="9b0f" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">导入了Resnet50模型的预计算功能，并向模型中添加了几个附加层:一个全局最大池层，后面是两个带有dropout的全连接层。最大池允许检测噪声，所以我认为它应该在类间有一些最小变化的地方表现良好。为了防止过度拟合，在两个致密层中加入了脱扣。</p><p id="c4b5" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">请注意，全局最大池层的输出有2048个神经元。它们被馈送到配备有ReLU激活功能的第一密集层，以便过滤出前500个相关输出。这些输出然后被送入第二个密集层“投票”，与softmax激活功能，最大概率的标签。</p><pre class="kg kh ki kj gt nt nu nv nw aw nx bi"><span id="19f0" class="lj ks iq nu b gy ny nz l oa ob">_________________________________________________________________</span><span id="b024" class="lj ks iq nu b gy oc nz l oa ob">Layer (type)                 Output Shape              Param #</span><span id="435d" class="lj ks iq nu b gy oc nz l oa ob">=================================================================</span><span id="2ed2" class="lj ks iq nu b gy oc nz l oa ob">global_max_pooling2d_1 (Glob (None, 2048)              0</span><span id="7215" class="lj ks iq nu b gy oc nz l oa ob">_________________________________________________________________</span><span id="30f3" class="lj ks iq nu b gy oc nz l oa ob">dropout_12 (Dropout)         (None, 2048)              0</span><span id="0f11" class="lj ks iq nu b gy oc nz l oa ob">_________________________________________________________________</span><span id="0d8b" class="lj ks iq nu b gy oc nz l oa ob">dense_13 (Dense)             (None, 500)               1024500</span><span id="c33b" class="lj ks iq nu b gy oc nz l oa ob">_________________________________________________________________</span><span id="3fa2" class="lj ks iq nu b gy oc nz l oa ob">dropout_13 (Dropout)         (None, 500)               0</span><span id="da47" class="lj ks iq nu b gy oc nz l oa ob">_________________________________________________________________</span><span id="a74a" class="lj ks iq nu b gy oc nz l oa ob">dense_14 (Dense)             (None, 133)               66633</span><span id="18a9" class="lj ks iq nu b gy oc nz l oa ob">=================================================================</span><span id="6217" class="lj ks iq nu b gy oc nz l oa ob">Total params: 1,091,133</span><span id="f110" class="lj ks iq nu b gy oc nz l oa ob">Trainable params: 1,091,133</span><span id="5bdb" class="lj ks iq nu b gy oc nz l oa ob">Non-trainable params: 0</span><span id="c712" class="lj ks iq nu b gy oc nz l oa ob">_________________________________________________________________</span></pre><p id="7110" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">与之前的实验模型一样，我继续使用分类交叉熵损失和RMSProp作为优化器，因为它们工作得很好。</p><p id="b5f6" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">然后，具有最高精确度的模型被用于创建最终算法，该算法接受文件路径作为输入，并且首先确定是否有狗、人或者两者都没有。如果检测到狗或人，它应该分别返回预测的狗品种或最相似的狗品种。如果两者都没有检测到，将显示一条错误消息。这就是早先构建的助手功能(人脸检测器和狗检测器)发挥作用的地方。</p></div><div class="ab cl mw mx hu my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="ij ik il im in"><h1 id="0e5c" class="kr ks iq bd kt ku nd kw kx ky ne la lb jw nf jx ld jz ng ka lf kc nh kd lh li bi translated">四。结果</h1><h2 id="b092" class="lj ks iq bd kt lk ll dn kx lm ln dp lb lo lp lq ld lr ls lt lf lu lv lw lh lx bi translated"><strong class="ak">模型评估和验证</strong></h2><p id="e59a" class="pw-post-body-paragraph ly lz iq ma b mb mc jr md me mf ju mg lo mh mi mj lr mk ml mm lu mn mo mp mq ij bi translated">每个模型被训练20个时期。验证集用于评估模型，并检查验证损失是否减少。如果是这种情况，模型权重用一个检查指针保存，稍后将被加载用于测试。</p><p id="8b93" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">从零开始构建的三个模型分别报告了7.65%、14.35%和17.10%的准确率。从这个基准测试中，我们可以得出结论，更多的卷积层和更多的全连接层有助于提高模型精度。当添加更深的层时，在图像的边缘和形状已经被较浅的层检测到之后，该模型能够捕获高级特征。</p><p id="a3c9" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">使用VGG 16网络的迁移学习在测试集上报告了42.34%的准确率。这一结果与上述分析一致，因为VGG-16有多达16层，特别是在超过1000万张图像上进行了预训练。</p><p id="61b6" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">结合预训练的Resnet50模型和定制架构的最终模型达到了80.14%的良好准确率。然后用它来构建最终的算法。</p><p id="731f" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">为了验证这种算法的鲁棒性，使用我的个人电脑中的输入图像进行了几次检查。当输入两幅猫的图像时，该模型给出正确答案，并准确预测3/4的狗品种。请注意，它正确地预测了布列塔尼，这是一个具有挑战性的品种。对于人类图像，结果是相当令人信服的，然而，这是应用程序的有趣部分，没有应用准确性度量。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nk nl di nm bf nn"><div class="gh gi od"><img src="../Images/969a1705fdbeb11b6e308f7bae42a744.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d6OzhLVJgA_tiXCo8SP_vA.jpeg"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">图7:模型正确预测了秋田犬。</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/6d27cd61b10b3ddd2ff5118af5bb2b87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/1*rfJROENA8e1DpzbXRHYxgQ.jpeg"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">图8:马耳他人？</p></figure><h2 id="5180" class="lj ks iq bd kt lk ll dn kx lm ln dp lb lo lp lq ld lr ls lt lf lu lv lw lh lx bi translated"><strong class="ak">正当理由</strong></h2><p id="663f" class="pw-post-body-paragraph ly lz iq ma b mb mc jr md me mf ju mg lo mh mi mj lr mk ml mm lu mn mo mp mq ij bi translated">从零开始然后从上述部分迁移学习模型的实验表明，预训练模型对于提高模型精度非常好，但是为了达到可接受的和有效的性能，需要根据这里的具体问题进行微调。如前所述，狗的品种分类是很有挑战性的，因为数据集很大，类间的差异很小，类内的差异也很大。</p><p id="a2ff" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">使用从大数据集学习的预训练模型允许算法快速获得瓶颈特征，并且几个附加层有助于为狗品种分类任务定制它。请注意，仅添加一个密集层可能不足以获得可接受的性能(基于预训练的VGG-16模型的实验)。这个观察可以为下一部分的改进反思打开一个好的思路。</p></div><div class="ab cl mw mx hu my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="ij ik il im in"><h1 id="5964" class="kr ks iq bd kt ku nd kw kx ky ne la lb jw nf jx ld jz ng ka lf kc nh kd lh li bi translated">动词 （verb的缩写）结论</h1><h2 id="b025" class="lj ks iq bd kt lk ll dn kx lm ln dp lb lo lp lq ld lr ls lt lf lu lv lw lh lx bi translated"><strong class="ak">倒影</strong></h2><p id="963e" class="pw-post-body-paragraph ly lz iq ma b mb mc jr md me mf ju mg lo mh mi mj lr mk ml mm lu mn mo mp mq ij bi translated">总而言之，该项目已经通过了以下步骤:</p><p id="dd97" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">-问题概述和陈述</p><p id="ae4f" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">-导入数据集、浏览数据和预处理输入图像</p><p id="39e7" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">-为最终算法构建辅助函数</p><p id="0bd6" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">-构建不同的CNN架构并对分类器进行基准测试</p><p id="251f" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">-选择最终模型，并将其集成到最终算法中</p><p id="0bca" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">-评估和验证算法的鲁棒性</p><p id="c09f" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">最具挑战性和最有趣的部分是从零开始构建模型。看到特定分类任务的困难，即使要求是1%,从0开始创建一个给出最低精度的东西也不容易。这一部分需要我寻找文件和研究论文，但也是我学到最多的地方。在深度CNN中，没有比建立和实验我自己的模型更好的理解方式了。最后，结果比我预期的要好得多。</p><h2 id="716c" class="lj ks iq bd kt lk ll dn kx lm ln dp lb lo lp lq ld lr ls lt lf lu lv lw lh lx bi translated"><strong class="ak">改进</strong></h2><p id="b441" class="pw-post-body-paragraph ly lz iq ma b mb mc jr md me mf ju mg lo mh mi mj lr mk ml mm lu mn mo mp mq ij bi translated">为了提高模型性能，有几条途径值得考虑:</p><ul class=""><li id="1562" class="of og iq ma b mb mr me ms lo oh lr oi lu oj mq ok ol om on bi translated">使用更多完全连接的层:从零开始构建模型，更密集的层可能会提高模型的准确性。</li><li id="9e90" class="of og iq ma b mb oo me op lo oq lr or lu os mq ok ol om on bi translated">执行数据收集或数据扩充:数据集非常小，而且类别不平衡。收集额外的图像和/或为低频率的类创建变换图像可能是个好主意。</li><li id="0012" class="of og iq ma b mb oo me op lo oq lr or lu os mq ok ol om on bi translated">为了配合有趣的用户体验目标的应用程序，这将是一个伟大的实现猫探测器，然后训练模型，以便它将输出最相似的狗！</li></ul></div><div class="ab cl mw mx hu my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="ij ik il im in"><p id="8571" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">希望你喜欢阅读这篇长文。觉得有用就拍手！</p><p id="3fa0" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">这篇博文是<a class="ae ni" href="https://www.udacity.com/course/data-scientist-nanodegree--nd025" rel="noopener ugc nofollow" target="_blank"> Udacity的数据科学家Nanodegree </a> Capstone项目的一部分。完整的Python代码可以在这个<a class="ae ni" href="https://github.com/ngthianhphuong/deep-learning-dog-breed-classification" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>上找到。</p></div><div class="ab cl mw mx hu my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="ij ik il im in"><h2 id="d39f" class="lj ks iq bd kt lk ll dn kx lm ln dp lb lo lp lq ld lr ls lt lf lu lv lw lh lx bi translated">参考资料:</h2><p id="dcd3" class="pw-post-body-paragraph ly lz iq ma b mb mc jr md me mf ju mg lo mh mi mj lr mk ml mm lu mn mo mp mq ij bi translated">-亚历克斯·克里日夫斯基、伊利亚·苏茨基弗和杰弗里·e·辛顿。<a class="ae ni" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" rel="noopener ugc nofollow" target="_blank">“使用深度卷积神经网络的ImageNet分类”</a> NIPS 2012</p><p id="a13c" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">- Quora: <a class="ae ni" href="https://www.quora.com/How-does-pooling-control-overfitting-in-CNN)" rel="noopener ugc nofollow" target="_blank">在CNN </a>中pooling是如何控制过拟合的？</p><p id="8779" class="pw-post-body-paragraph ly lz iq ma b mb mr jr md me ms ju mg lo mt mi mj lr mu ml mm lu mv mo mp mq ij bi translated">- Quora: <a class="ae ni" href="https://www.quora.com/What-is-the-motivation-for-pooling-in-convolutional-neural-networks-CNN" rel="noopener ugc nofollow" target="_blank">卷积神经网络(CNN)中池化的动机是什么？</a></p></div></div>    
</body>
</html>