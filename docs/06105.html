<html>
<head>
<title>Building a Neural Network with a Single Hidden Layer using Numpy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ä½¿ç”¨Numpyæ„å»ºå•éšå±‚ç¥ç»ç½‘ç»œ</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://towardsdatascience.com/building-a-neural-network-with-a-single-hidden-layer-using-numpy-923be1180dbf?source=collection_archive---------9-----------------------#2020-05-18">https://towardsdatascience.com/building-a-neural-network-with-a-single-hidden-layer-using-numpy-923be1180dbf?source=collection_archive---------9-----------------------#2020-05-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="e84b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">ä½¿ç”¨Numpyå®ç°å…·æœ‰å•ä¸ªéšè—å±‚çš„ä¸¤ç±»åˆ†ç±»ç¥ç»ç½‘ç»œ</p><p id="d79a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">åœ¨<a class="ae ko" rel="noopener" target="_blank" href="/build-a-simple-neural-network-using-numpy-2add9aad6fc8?source=your_stories_page---------------------------">ä¸Šä¸€ç¯‡</a>ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†å¦‚ä½•ä½¿ç”¨NumPyåˆ¶ä½œä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œã€‚åœ¨æœ¬å¸–ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºå¦‚ä½•åˆ¶ä½œä¸€ä¸ªå…·æœ‰éšè—å±‚çš„æ·±åº¦ç¥ç»ç½‘ç»œã€‚</p><ol class=""><li id="1cec" class="kp kq it js b jt ju jx jy kb kr kf ks kj kt kn ku kv kw kx bi translated"><strong class="js iu">å¯¼å…¥åº“</strong></li></ol><p id="1155" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">æˆ‘ä»¬å°†å¯¼å…¥ä¸€äº›åŸºæœ¬çš„pythonåº“ï¼Œå¦‚numpyã€matplotlib(ç”¨äºç»˜åˆ¶å›¾å½¢)ã€sklearn(ç”¨äºæ•°æ®æŒ–æ˜å’Œåˆ†æå·¥å…·)ç­‰ã€‚è¿™æ˜¯æˆ‘ä»¬éœ€è¦çš„ã€‚</p><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="773e" class="lh li it ld b gy lj lk l ll lm">import numpy as np<br/>import matplotlib.pyplot as plt<br/>from sklearn.model_selection import train_test_split</span></pre><p id="9c8c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 2ã€‚æ•°æ®é›†</strong></p><p id="03fa" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">æˆ‘ä»¬å°†ä½¿ç”¨é’ç¥¨æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†æ¶‰åŠåœ¨ç»™å®šä»ç…§ç‰‡ä¸­è·å–çš„å‡ ä¸ªæµ‹é‡å€¼çš„æƒ…å†µä¸‹é¢„æµ‹ç»™å®šé’ç¥¨æ˜¯å¦æ˜¯çœŸå®çš„ã€‚è¿™æ˜¯ä¸€ä¸ªäºŒå…ƒ(2ç±»)åˆ†ç±»é—®é¢˜ã€‚æœ‰1ï¼Œ372ä¸ªå…·æœ‰4ä¸ªè¾“å…¥å˜é‡å’Œ1ä¸ªè¾“å‡ºå˜é‡çš„è§‚å¯Ÿå€¼ã€‚æ›´å¤šè¯¦æƒ…è¯·å‚è§<a class="ae ko" href="http://archive.ics.uci.edu/ml/datasets/banknote+authentication" rel="noopener ugc nofollow" target="_blank">é“¾æ¥ã€‚</a></p><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="4645" class="lh li it ld b gy lj lk l ll lm">data = np.genfromtxt(â€˜data_banknote_authentication.txtâ€™, delimiter = â€˜,â€™)<br/>X = data[:,:4]<br/>y = data[:, 4]</span></pre><p id="bca7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ•£ç‚¹å›¾æ¥å¯è§†åŒ–æ•°æ®é›†ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸¤ç±»(çœŸå®å’ŒéçœŸå®)æ˜¯å¯åˆ†çš„ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯å»ºç«‹ä¸€ä¸ªæ¨¡å‹æ¥æ‹Ÿåˆè¿™äº›æ•°æ®ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬å¸Œæœ›å»ºç«‹ä¸€ä¸ªç¥ç»ç½‘ç»œæ¨¡å‹æ¥å®šä¹‰åŒºåŸŸæ˜¯çœŸå®çš„è¿˜æ˜¯ä¸çœŸå®çš„ã€‚</p><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="7dde" class="lh li it ld b gy lj lk l ll lm">plt.scatter(X[:, 0], X[:, 1], alpha=0.2,<br/> c=y, cmap=â€™viridisâ€™)<br/>plt.xlabel(â€˜variance of waveletâ€™)<br/>plt.ylabel(â€˜skewness of waveletâ€™);</span></pre><figure class="ky kz la lb gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi ln"><img src="../Images/0fdfb456843706e089ebf9127861bd56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rde2-gYfSfqZVVLV4P7lZw.png"/></div></div></figure><p id="9dbf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">ç°åœ¨ï¼Œè®©æˆ‘ä»¬å°†æ•°æ®åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚è¿™å¯ä»¥ä½¿ç”¨sk learn<em class="lv">train _ test _ split()</em>å‡½æ•°æ¥å®Œæˆã€‚é€‰æ‹©20%çš„æ•°æ®ç”¨äºæµ‹è¯•ï¼Œ80%ç”¨äºè®­ç»ƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†æ£€æŸ¥è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„å¤§å°ã€‚è¿™å°†æœ‰åŠ©äºä»¥åè®¾è®¡æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚</p><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="b97c" class="lh li it ld b gy lj lk l ll lm">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><span id="3565" class="lh li it ld b gy lw lk l ll lm">X_train = X_train.T<br/>y_train = y_train.reshape(1, y_train.shape[0])</span><span id="0f93" class="lh li it ld b gy lw lk l ll lm">X_test = X_test.T<br/>y_test = y_test.reshape(1, y_test.shape[0])</span><span id="defe" class="lh li it ld b gy lw lk l ll lm">print (â€˜Train X Shape: â€˜, X_train.shape)<br/>print (â€˜Train Y Shape: â€˜, y_train.shape)<br/>print (â€˜I have m = %d training examples!â€™ % (X_train.shape[1]))<br/><br/>print ('\nTest X Shape: ', X_test.shape)</span></pre><figure class="ky kz la lb gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lx"><img src="../Images/6771a4ab036427284afd5be1b5171553.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dAqKtklsnvs5OcZghJq0cw.png"/></div></div></figure><p id="af3c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 3ã€‚ç¥ç»ç½‘ç»œæ¨¡å‹</strong></p><p id="956b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">æ„å»ºç¥ç»ç½‘ç»œçš„ä¸€èˆ¬æ–¹æ³•æ˜¯:</p><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="f659" class="lh li it ld b gy lj lk l ll lm">1. Define the neural network structure ( # of input units,  # of hidden units, etc). <br/>2. Initialize the model's parameters<br/>3. Loop:<br/>    - Implement forward propagation<br/>    - Compute loss<br/>    - Implement backward propagation to get the gradients<br/>    - Update parameters (gradient descent)</span></pre><p id="e1d5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">æˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªå…·æœ‰å•ä¸€éšè—å±‚çš„ç¥ç»ç½‘ç»œï¼Œå¦‚ä¸‹å›¾æ‰€ç¤º:</p><figure class="ky kz la lb gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi ly"><img src="../Images/7199eb5af9eac8c65207db9ff1e5ec2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uzTQjsb5sKNED_45Cu5aUA.png"/></div></div></figure><p id="c2f1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 3.1å®šä¹‰ç»“æ„</strong></p><p id="a0f7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">æˆ‘ä»¬éœ€è¦å®šä¹‰è¾“å…¥å•å…ƒçš„æ•°é‡ã€éšè—å•å…ƒçš„æ•°é‡å’Œè¾“å‡ºå±‚ã€‚è¾“å…¥å•ä½ç­‰äºæ•°æ®é›†ä¸­çš„è¦ç´ æ•°é‡(4)ï¼Œéšè—å±‚è®¾ç½®ä¸º4(ä¸ºæ­¤)ï¼Œé—®é¢˜æ˜¯æˆ‘ä»¬å°†ä½¿ç”¨å•ä¸€å›¾å±‚è¾“å‡ºçš„äºŒè¿›åˆ¶åˆ†ç±»ã€‚</p><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="77d1" class="lh li it ld b gy lj lk l ll lm">def <strong class="ld iu">define_structure</strong>(X, Y):<br/>    input_unit = X.shape[0] # size of input layer<br/>    hidden_unit = 4 #hidden layer of size 4<br/>    output_unit = Y.shape[0] # size of output layer<br/>    return (input_unit, hidden_unit, output_unit)</span><span id="1da9" class="lh li it ld b gy lw lk l ll lm">(input_unit, hidden_unit, output_unit) = <strong class="ld iu">define_structure</strong>(X_train, y_train)<br/>print("The size of the input layer is:  = " + str(input_unit))<br/>print("The size of the hidden layer is:  = " + str(hidden_unit))<br/>print("The size of the output layer is:  = " + str(output_unit))</span></pre><figure class="ky kz la lb gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lz"><img src="../Images/097c15de3a1f0efd693ae1d416dcdfcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Eayp7GKwrYW3-5Q3C6A0g.png"/></div></div></figure><p id="b9f8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 3.2åˆå§‹åŒ–æ¨¡å‹å‚æ•°</strong></p><p id="c0e4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">æˆ‘ä»¬éœ€è¦åˆå§‹åŒ–æƒé‡çŸ©é˜µå’Œåç½®å‘é‡ã€‚å½“åå·®è®¾ç½®ä¸ºé›¶æ—¶ï¼Œæƒé‡è¢«éšæœºåˆå§‹åŒ–ã€‚è¿™å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„å‡½æ•°æ¥å®Œæˆã€‚</p><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="510c" class="lh li it ld b gy lj lk l ll lm">def <strong class="ld iu">parameters_initialization</strong>(input_unit, hidden_unit, output_unit):<br/>    np.random.seed(2) <br/>    W1 = np.random.randn(hidden_unit, input_unit)*0.01<br/>    b1 = np.zeros((hidden_unit, 1))<br/>    W2 = np.random.randn(output_unit, hidden_unit)*0.01<br/>    b2 = np.zeros((output_unit, 1))<br/>    parameters = {"W1": W1,<br/>                  "b1": b1,<br/>                  "W2": W2,<br/>                  "b2": b2}<br/>    <br/>    return parameters</span></pre><p id="5b7f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 3.3.1æ­£å‘ä¼ æ’­</strong></p><p id="eb6b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">å¯¹äºæ­£å‘ä¼ æ’­ï¼Œç»™å®šä¸€ç»„è¾“å…¥ç‰¹å¾(X)ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—æ¯ä¸€å±‚çš„æ¿€æ´»å‡½æ•°ã€‚å¯¹äºéšè—å±‚ï¼Œæˆ‘ä»¬ä½¿ç”¨<strong class="js iu"> tanh </strong>æ¿€æ´»å‡½æ•°:</p><figure class="ky kz la lb gt lo gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/f3767c6521f7b1684a5d8139a99b3b6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:590/format:webp/1*mhWIgRP9hphQLyFMKVgO_A.png"/></div></figure><figure class="ky kz la lb gt lo gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/eba1afaf39f8eed185d50f4fe2f192ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:564/format:webp/1*UqIf10cyDcqB-5NUQNIAUg.png"/></div></figure><p id="0a8a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">åŒæ ·ï¼Œå¯¹äºè¾“å‡ºå±‚ï¼Œæˆ‘ä»¬ä½¿ç”¨sigmoidæ¿€æ´»å‡½æ•°ã€‚</p><figure class="ky kz la lb gt lo gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/a934d9cdb6fa5dc275881f81d1dbce56.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/format:webp/1*bM-DJpSISMjAGEamnmis5g.png"/></div></figure><figure class="ky kz la lb gt lo gh gi paragraph-image"><div class="gh gi md"><img src="../Images/8f99b142e777a89456f84c29b2d284cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*k5yZN1cv4qi0L_9Lc9Uzyg.png"/></div></figure><p id="ef34" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„ä»£ç æ¥å®ç°å‘å‰ä¼ æ’­ã€‚</p><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="601f" class="lh li it ld b gy lj lk l ll lm">def <strong class="ld iu">sigmoid</strong>(z):<br/>    return 1/(1+np.exp(-z))</span><span id="747e" class="lh li it ld b gy lw lk l ll lm">def <strong class="ld iu">forward_propagation</strong>(X, parameters):<br/>    W1 = parameters['W1']<br/>    b1 = parameters['b1']<br/>    W2 = parameters['W2']<br/>    b2 = parameters['b2']<br/>    <br/>    Z1 = np.dot(W1, X) + b1<br/>    A1 = np.tanh(Z1)<br/>    Z2 = np.dot(W2, A1) + b2<br/>    A2 = sigmoid(Z2)<br/>    cache = {"Z1": Z1,"A1": A1,"Z2": Z2,"A2": A2}<br/>    <br/>    return A2, cache</span></pre><p id="1054" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">3.3.2è®¡ç®—æˆæœ¬</p><p id="8e4b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">æˆ‘ä»¬å°†è®¡ç®—äº¤å‰ç†µæˆæœ¬ã€‚åœ¨ä¸Šä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬è®¡ç®—äº†A2ã€‚ä½¿ç”¨A2ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å…¬å¼è®¡ç®—äº¤å‰ç†µæˆæœ¬ã€‚</p><figure class="ky kz la lb gt lo gh gi paragraph-image"><div class="gh gi me"><img src="../Images/d22632929230d0e612f9287c0890480c.png" data-original-src="https://miro.medium.com/v2/resize:fit:824/format:webp/1*ejahWVN7FidYqwPzBQYn1g.png"/></div></figure><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="ad3f" class="lh li it ld b gy lj lk l ll lm">def <strong class="ld iu">cross_entropy_cost</strong>(A2, Y, parameters):<br/>    # number of training example<br/>    m = Y.shape[1] <br/>    # Compute the cross-entropy cost<br/>    logprobs = np.multiply(np.log(A2), Y) + np.multiply((1-Y), np.log(1 - A2))<br/>    cost = - np.sum(logprobs) / m<br/>    cost = float(np.squeeze(cost))<br/>                                    <br/>    return cost</span></pre><p id="e4b6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 3.3.3åå‘ä¼ æ’­</strong></p><p id="2cfa" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">æˆ‘ä»¬éœ€è¦è®¡ç®—ä¸åŒå‚æ•°çš„æ¢¯åº¦ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚</p><figure class="ky kz la lb gt lo gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/95a52f8673fa6251252af73885a06132.png" data-original-src="https://miro.medium.com/v2/resize:fit:1106/format:webp/1*OOKSEES8CRYkeMZ5qVTIqQ.png"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">å›¾ç‰‡æä¾›:<a class="ae ko" href="https://www.coursera.org/learn/neural-networks-deep-learning/" rel="noopener ugc nofollow" target="_blank">å´æ©è¾¾</a></p></figure><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="1430" class="lh li it ld b gy lj lk l ll lm">def <strong class="ld iu">backward_propagation</strong>(parameters, cache, X, Y):<br/>    #number of training example<br/>    m = X.shape[1]<br/>    <br/>    W1 = parameters['W1']<br/>    W2 = parameters['W2']<br/>    A1 = cache['A1']<br/>    A2 = cache['A2']<br/>   <br/>    dZ2 = A2-Y<br/>    dW2 = (1/m) * np.dot(dZ2, A1.T)<br/>    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)<br/>    dZ1 = np.multiply(np.dot(W2.T, dZ2), 1 - np.power(A1, 2))<br/>    dW1 = (1/m) * np.dot(dZ1, X.T) <br/>    db1 = (1/m)*np.sum(dZ1, axis=1, keepdims=True)<br/>    <br/>    grads = {"dW1": dW1, "db1": db1, "dW2": dW2,"db2": db2}<br/>    <br/>    return grads</span></pre><p id="8082" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 3.3.4æ¢¯åº¦ä¸‹é™(æ›´æ–°å‚æ•°)</strong></p><p id="dcb7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">æˆ‘ä»¬éœ€è¦ä½¿ç”¨æ¢¯åº¦ä¸‹é™è§„åˆ™æ›´æ–°å‚æ•°ï¼Œå³</p><figure class="ky kz la lb gt lo gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/bbb2ea5678acb752985381225c5f947d.png" data-original-src="https://miro.medium.com/v2/resize:fit:188/format:webp/1*eBzTEHvFYZW5q2Oty-aA6w.png"/></div></figure><p id="5cdd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">å…¶ä¸­<strong class="js iu"> ğ›¼ </strong>æ˜¯å­¦ä¹ ç‡<strong class="js iu"> ğœƒ </strong>æ˜¯å‚æ•°ã€‚</p><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="2200" class="lh li it ld b gy lj lk l ll lm">def <strong class="ld iu">gradient_descent</strong>(parameters, grads, learning_rate = 0.01):<br/>    W1 = parameters['W1']<br/>    b1 = parameters['b1']<br/>    W2 = parameters['W2']<br/>    b2 = parameters['b2']<br/>   <br/>    dW1 = grads['dW1']<br/>    db1 = grads['db1']<br/>    dW2 = grads['dW2']<br/>    db2 = grads['db2']</span><span id="3180" class="lh li it ld b gy lw lk l ll lm">    W1 = W1 - learning_rate * dW1<br/>    b1 = b1 - learning_rate * db1<br/>    W2 = W2 - learning_rate * dW2<br/>    b2 = b2 - learning_rate * db2<br/>    <br/>    parameters = {"W1": W1, "b1": b1,"W2": W2,"b2": b2}<br/>    <br/>    return parameters</span></pre><p id="0ff1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 4ã€‚ç¥ç»ç½‘ç»œæ¨¡å‹</strong></p><p id="d294" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">æœ€åï¼ŒæŠŠæ‰€æœ‰çš„åŠŸèƒ½æ”¾åœ¨ä¸€èµ·ï¼Œæˆ‘ä»¬å¯ä»¥å»ºç«‹ä¸€ä¸ªåªæœ‰ä¸€ä¸ªéšè—å±‚çš„ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚</p><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="617c" class="lh li it ld b gy lj lk l ll lm">def <strong class="ld iu">neural_network_model</strong>(X, Y, hidden_unit, num_iterations = 1000):<br/>    np.random.seed(3)<br/>    input_unit = <strong class="ld iu">define_structure</strong>(X, Y)[0]<br/>    output_unit = <strong class="ld iu">define_structure</strong>(X, Y)[2]<br/>    <br/>    parameters = <strong class="ld iu">parameters_initialization</strong>(input_unit, hidden_unit, output_unit)<br/>   <br/>    W1 = parameters['W1']<br/>    b1 = parameters['b1']<br/>    W2 = parameters['W2']<br/>    b2 = parameters['b2']<br/>    <br/>    for i in range(0, num_iterations):<br/>        A2, cache = <strong class="ld iu">forward_propagation</strong>(X, parameters)<br/>        cost = <strong class="ld iu">cross_entropy_cost</strong>(A2, Y, parameters)<br/>        grads = <strong class="ld iu">backward_propagation</strong>(parameters, cache, X, Y)<br/>        parameters = <strong class="ld iu">gradient_descent</strong>(parameters, grads)<br/>        if i % 5 == 0:<br/>            print ("Cost after iteration %i: %f" %(i, cost))</span><span id="1031" class="lh li it ld b gy lw lk l ll lm">    return parameters</span><span id="d3f9" class="lh li it ld b gy lw lk l ll lm">parameters = <strong class="ld iu">neural_network_model</strong>(X_train, y_train, 4, num_iterations=1000)</span></pre><figure class="ky kz la lb gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lx"><img src="../Images/1efa51d0becb001cbe722d4c6de49c0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BijLxY8e4qQjPsLARK4KOw.png"/></div></div></figure><p id="d674" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 5ã€‚é¢„æµ‹</strong></p><p id="055f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">ä½¿ç”¨å­¦ä¹ åˆ°çš„å‚æ•°ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨å‰å‘ä¼ æ’­æ¥é¢„æµ‹æ¯ä¸ªç¤ºä¾‹çš„ç±»ã€‚</p><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="d03c" class="lh li it ld b gy lj lk l ll lm">def <strong class="ld iu">prediction</strong>(parameters, X):<br/>    A2, cache = forward_propagation(X, parameters)<br/>    predictions = np.round(A2)<br/>    <br/>    return predictions</span></pre><p id="071a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">å¦‚æœ<em class="lv">æ¿€æ´»&gt; 0.5ï¼Œ</em>åˆ™é¢„æµ‹ä¸º1å¦åˆ™ä¸º0ã€‚</p><pre class="ky kz la lb gt lc ld le lf aw lg bi"><span id="b865" class="lh li it ld b gy lj lk l ll lm">predictions = <strong class="ld iu">prediction</strong>(parameters, X_train)<br/>print ('Accuracy Train: %d' % float((np.dot(y_train, predictions.T) + np.dot(1 - y_train, 1 - predictions.T))/float(y_train.size)*100) + '%')</span><span id="73ac" class="lh li it ld b gy lw lk l ll lm">predictions = <strong class="ld iu">prediction</strong>(parameters, X_test)<br/>print ('Accuracy Test: %d' % float((np.dot(y_test, predictions.T) + np.dot(1 - y_test, 1 - predictions.T))/float(y_test.size)*100) + '%')</span></pre><figure class="ky kz la lb gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lz"><img src="../Images/0376f1544d550ae36b986e0314a53ca8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Jx3bsA5zvAoV6ebkJA2RA.png"/></div></div></figure><p id="06fe" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼Œè®­ç»ƒç²¾åº¦çº¦ä¸º97%ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬çš„æ¨¡å‹æ­£åœ¨å·¥ä½œï¼Œå¹¶ä¸”ä»¥é«˜æ¦‚ç‡æ‹Ÿåˆè®­ç»ƒæ•°æ®ã€‚æµ‹è¯•å‡†ç¡®ç‡åœ¨96%å·¦å³ã€‚ç»™å®šç®€å•çš„æ¨¡å‹å’Œå°çš„æ•°æ®é›†ï¼Œæˆ‘ä»¬å¯ä»¥è®¤ä¸ºå®ƒæ˜¯ä¸€ä¸ªå¥½çš„æ¨¡å‹ã€‚</p><blockquote class="ml mm mn"><p id="6c91" class="jq jr lv js b jt ju jv jw jx jy jz ka mo kc kd ke mp kg kh ki mq kk kl km kn im bi translated">åœ¨è¿™é‡Œæˆä¸ºMediumä¼šå‘˜<a class="ae ko" href="https://medium.com/@rmesfrmpkr/membership" rel="noopener">ï¼Œæ”¯æŒç‹¬ç«‹å†™ä½œï¼Œæ¯æœˆ5ç¾å…ƒï¼Œå¯ä»¥å®Œå…¨è®¿é—®Mediumä¸Šçš„æ¯ä¸ªæ•…äº‹ã€‚</a></p></blockquote></div></div>    
</body>
</html>