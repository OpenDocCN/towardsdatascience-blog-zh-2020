<html>
<head>
<title>How To Tag Any Image Using Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用深度学习标记任何图像</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-tag-any-image-using-deep-learning-84a0dc2e03c2?source=collection_archive---------10-----------------------#2020-05-16">https://towardsdatascience.com/how-to-tag-any-image-using-deep-learning-84a0dc2e03c2?source=collection_archive---------10-----------------------#2020-05-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4d82" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用Pytorch闪电！</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/82c71de39421069ab7c26c84526b10cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kvw2-_OC-O6FW9zz"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@alienaperture?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">麦克尔·罗杰斯</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="e3f6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你大概有照片吧？</p><p id="2a2c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可能想让那些照片自动被标记，对吗？</p><p id="4268" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是你也不想为此写一大堆代码。</p><p id="780d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">继续阅读，了解如何使用深度学习和Pytorch用不到60行代码标记任何照片。最棒的是，你只需要修改大约3行代码就可以让它为你自己的图像工作了！</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="4d15" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">标记猴子</h1><p id="5588" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">一个极其常见的机器学习问题是对图像进行分类或标记。影像分类是指当您有一组预定义的类别要为其分配影像时。</p><p id="0ff6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">假设你在动物园工作，总是忘记所有猴子的名字。如果你有办法把各种猴子的图片自动分类到合适的种类，那就太好了。</p><p id="18c5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你会问，为什么是猴子？因为Kaggle上有可用的<a class="ae ky" href="https://www.kaggle.com/slothkong/10-monkey-species" rel="noopener ugc nofollow" target="_blank">数据集</a>。:)这个数据集包含了10个不同种类猴子的大约1400张图片。这是白头卷尾猴的照片:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/0fb1181cb22a23b78c83f9477f2e57db.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/0*hTYh2UDcZ6fjt5IE.jpeg"/></div></figure><p id="47a2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中一只帕塔斯猴:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/d07087dad813d1e71c544cf52d12edea.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/0*I1KpvfDsEBr2hrxf.jpeg"/></div></figure><p id="7722" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">拥有数据是关键。对于你自己的问题，确保你有一些已经被标记的图片。我的建议是每个班至少有50张带标签的图片。</p><p id="0006" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦你有了你的图片，让我们把它们正确地组织起来。您需要创建两个文件夹:“培训”和“验证”。你在训练文件夹中的照片将用于训练我们的深度学习模型。验证照片将用于确保我们的模型调整良好。</p><p id="19b7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在每个文件夹中，为每个标签创建一个文件夹。对于我们的猴子，我们有10个标签，我们将称它们为n0-n9。因此，我们的文件夹结构如下所示:</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="20dd" class="ng md it nc b gy nh ni l nj nk">└── training<br/>    ├── n0<br/>    ├── n1<br/>    ├── n2<br/>    ├── n3<br/>    ├── n4<br/>    ├── n5<br/>    ├── n6<br/>    ├── n7<br/>    ├── n8<br/>    └── n9<br/>└── validation<br/>    ├── n0<br/>    ├── n1<br/>    ├── n2<br/>    ├── n3<br/>    ├── n4<br/>    ├── n5<br/>    ├── n6<br/>    ├── n7<br/>    ├── n8<br/>    └── n9</span></pre><p id="aaa2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，将适当的图像放入每个文件夹中。也许将70%的标记图像用于训练，20%用于验证，剩下10%用于测试。</p><p id="bb00" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还将维护从n0-n9到实际物种名称的映射，因此我们不会忘记:</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="0e45" class="ng md it nc b gy nh ni l nj nk">Label,  Latin Name           , Common Name                   <br/>n0   , alouatta_palliata     , mantled_howler              <br/>n1   , erythrocebus_patas    , patas_monkey                  <br/>n2   , cacajao_calvus	     , bald_uakari                   <br/>n3   , macaca_fuscata	     , japanese_macaque            <br/>n4   , cebuella_pygmea	     , pygmy_marmoset               <br/>n5   , cebus_capucinus	     , white_headed_capuchin        <br/>n6   , mico_argentatus	     , silvery_marmoset             <br/>n7   , saimiri_sciureus	     , common_squirrel_monkey       <br/>n8   , aotus_nigriceps	     , black_headed_night_monkey     <br/>n9   , trachypithecus_johnii , nilgiri_langur</span></pre><h1 id="aee8" class="mc md it bd me mf nl mh mi mj nm ml mm jz nn ka mo kc no kd mq kf np kg ms mt bi translated">构建您的模型</h1><h1 id="5e38" class="mc md it bd me mf nl mh mi mj nm ml mm jz nn ka mo kc no kd mq kf np kg ms mt bi translated">ResNet-50</h1><p id="fcd6" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">一个非常流行的用于标记图像的神经网络架构是ResNet-50。它很好地平衡了准确性和复杂性。这个深度学习模型我就不深入了，不过你可以在这里了解更多<a class="ae ky" rel="noopener" target="_blank" href="/understanding-and-coding-a-resnet-in-keras-446d7ff84d33">。对于我们的目的，只要知道它是一个非常好的图像分类模型，如果你有GPU，你应该能够在合理的时间内训练它。如果你没有，看看</a><a class="ae ky" href="https://colab.research.google.com/notebooks/intro.ipynb" rel="noopener ugc nofollow" target="_blank"> Google Colab </a>获得免费的GPU资源。</p><h1 id="50f4" class="mc md it bd me mf nl mh mi mj nm ml mm jz nn ka mo kc no kd mq kf np kg ms mt bi translated">微调</h1><p id="f74d" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">当训练我们的模型时，我们将使用的技巧之一是使用微调的想法，希望能够学习如何仅用几个例子就准确地标记。</p><p id="aca4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">微调从已经在另一个数据集上训练过的权重开始我们的模型。然后，我们使用自己的数据进一步调整权重。作为微调起点的一个非常常见的数据集是<a class="ae ky" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>数据集。该数据集最初包含大约100万幅图像和1000个类别或标签。图像标签的广度使其成为一个很好的微调数据集。</p><h1 id="bd14" class="mc md it bd me mf nl mh mi mj nm ml mm jz nn ka mo kc no kd mq kf np kg ms mt bi translated">Pytorch闪电</h1><p id="6aaa" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">除了微调，我们还可以应用其他技巧来帮助我们的深度学习模型根据我们的数据进行良好的训练。例如，使用学习率查找器来选择最佳学习率。</p><p id="3c4a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">实现所有这些最佳实践并跟踪所有培训步骤会产生大量代码。为了避免这些样板文件，我们将使用<a class="ae ky" href="https://github.com/PyTorchLightning/pytorch-lightning" rel="noopener ugc nofollow" target="_blank"> Pytorch Lightning </a>。我喜欢这个图书馆。我发现它真的帮助我很好地组织我的Pytorch代码，并避免愚蠢的错误，如忘记将我的渐变归零。</p><p id="9884" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将通过编写一个实现LightningModule的类来使用Pytorch Lightning。这是我们的大部分代码，然后我们将带您浏览它:</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="1a15" class="ng md it nc b gy nh ni l nj nk">class ImagenetTransferLearning(LightningModule):<br/>    def __init__(self, hparams):<br/>        super().__init__()<br/>        # init a pretrained resnet<br/>        self.hparams = hparams<br/>        self.classifier = models.resnet50(pretrained=True)<br/>        num_ftrs = self.classifier.fc.in_features<br/>        self.classifier.fc = nn.Linear(num_ftrs,     self.hparams.num_target_classes)</span><span id="3ab6" class="ng md it nc b gy nq ni l nj nk">    def forward(self, x):<br/>        return self.classifier(x)<br/>    <br/>    def training_step(self, batch, batch_idx):<br/>        x, y = batch<br/>        y_hat = self(x)<br/>        loss = F.cross_entropy(y_hat, y)<br/>        tensorboard_logs = {'train_loss': loss}<br/>        return {'loss': loss, 'log': tensorboard_logs}</span><span id="5758" class="ng md it nc b gy nq ni l nj nk">    def configure_optimizers(self):<br/>        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)<br/>    <br/>    def train_dataloader(self):<br/>        train_transforms = transforms.Compose([<br/>            transforms.RandomResizedCrop(224),<br/>            transforms.RandomHorizontalFlip(),<br/>            transforms.ToTensor(),<br/>            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])<br/>        dataset = datasets.ImageFolder(self.hparams.train_dir, train_transforms)<br/>        loader = data.DataLoader(dataset, batch_size=self.hparams.batch_size, num_workers=4, shuffle=True)<br/>        return loader<br/>    <br/>    def validation_step(self, batch, batch_idx):<br/>        x, y = batch<br/>        y_hat = self(x)<br/>        loss = F.cross_entropy(y_hat, y)<br/>        tensorboard_logs = {'val_loss': loss}<br/>        return {'val_loss': loss, 'log': tensorboard_logs}<br/>    <br/>    def validation_epoch_end(self, outputs):<br/>        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()<br/>        tensorboard_logs = {'val_loss': avg_loss}<br/>        return {'val_loss': avg_loss, 'log': tensorboard_logs}<br/>    <br/>    def val_dataloader(self):<br/>        val_transforms = transforms.Compose([<br/>            transforms.Resize(224),<br/>            transforms.CenterCrop(224),<br/>            transforms.ToTensor(),<br/>            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])<br/>        dataset = datasets.ImageFolder(self.hparams.val_dir, val_transforms)<br/>        loader = data.DataLoader(dataset, batch_size=self.hparams.batch_size, num_workers=4)<br/>        return loader</span></pre><p id="594d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们定义的第一个函数是<strong class="lb iu"> init() </strong>。这是我们用来初始化模型的函数。我们从Pytorch的预训练Resnet50开始，对它稍加修改，使它能够预测适当的类数。您想要预测的类或标签的数量作为hparams的一部分作为<strong class="lb iu"> num_target_classes传递。</strong></p><p id="da20" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们有了<strong class="lb iu"> forward() </strong>函数。这个很简单，我们只是通过我们的网络传递输入给它。</p><p id="c01f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后我们有了<strong class="lb iu"> training_step() </strong>函数。该函数接受两个输入—批次和批次索引。在这个函数中，我们需要定义的是我们希望在每个训练步骤中发生什么。对于这个模型来说，很简单。我们通过我们的神经网络<strong class="lb iu"> self() </strong>传递数据，然后计算交叉熵作为我们的损失。对于这个函数，标准的做法是返回一个包含计算损失的字典以及Tensorboard的日志变量。Pytorch Lightning的一大好处是，如果你这样做了，你就可以基本上免费获得<strong class="lb iu"> Tensorboard </strong>日志，这真是太棒了！</p><p id="f7c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">configure _ optimizer()</strong>函数用于定义您的优化器。我们将使用Adam优化器，并通过我们的hparams传递学习率。</p><p id="6ab7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，对于训练，您有<strong class="lb iu"> train_dataloader() </strong>函数。这是负责加载训练数据并将其传递到训练步骤的函数。我们确保定义我们的转换来调整图像的大小，并以与我们的Resnet预训练相同的方式缩放它们。我们还用<strong class="lb iu"> RandomResizedCrop() </strong>和<strong class="lb iu"> RandomHorizontalFlip() </strong>应用了一些数据扩充。然后我用Pytorch的<strong class="lb iu"> ImageFolder() </strong>函数加载数据。这个函数从一个文件夹中加载图像，只要这个文件夹遵循我们之前定义的结构。数据被传递给一个<strong class="lb iu"> DataLoader() </strong>，Pytorch用它来实际加载数据。在这个函数中，我们可以定义诸如batch_size这样的项目。我们通过hparams将batch_size作为超参数传递。</p><p id="b649" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为我们也有验证数据，所以我们可以定义完全相同的函数，除了它们不用于验证数据:<strong class="lb iu"> validation_step() </strong>和<strong class="lb iu"> val_dataloader() </strong>。这些功能非常相似。一些区别是我们不再做数据扩充，我们的步骤返回val_loss。</p><p id="87b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">验证部分还有一个额外的功能:<strong class="lb iu"> validation_epoch_end() </strong>。这定义了在一个时期结束时应该对验证结果做什么。我们只是简单地返回平均验证损失。如果您愿意，也可以在培训步骤中这样做。</p><h2 id="164f" class="ng md it bd me nr ns dn mi nt nu dp mm li nv nw mo lm nx ny mq lq nz oa ms ob bi translated">培养</h2><p id="cf74" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">现在我们已经完成了定义所有必要步骤的繁重工作，我们可以坐下来让Pytorch Lightning施展它的魔法了。首先，让我们定义我们的超参数(Pytorch Lightning希望它是一个argparse名称空间):</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="ee03" class="ng md it nc b gy nh ni l nj nk">hparams = Namespace(train_dir = &lt;PATH TO YOUR TRAINING DIRECTORY&gt;,<br/>                   val_dir = &lt;PATH TO YOUR VALIDATION DIRECTORY&gt;,<br/>                   num_target_classes = &lt;NUMBER OF TAGS/CLASSES&gt;,<br/>                   lr = 0.001,<br/>                   batch_size=8)</span></pre><p id="e38c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我将批处理大小设置得很小，以便与几乎任何GPU一起工作。</p><p id="e8d7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们初始化我们的模型并进行训练！</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="251b" class="ng md it nc b gy nh ni l nj nk">model = ImagenetTransferLearning(hparams)<br/>trainer = Trainer(gpus=1,<br/>                  early_stop_checkpoint=True,<br/>                  auto_lr_find=True,<br/>                  max_epochs=50<br/>                 )</span></pre><p id="8525" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">真正神奇的事情发生在训练者身上。首先，我们告诉它要在多少个GPU上训练，然后我们让它知道如果val_loss没有改善，就提前停止训练，最酷的选项之一是<strong class="lb iu"> auto_lr_finder </strong>。这告诉训练者使用一种算法来找到我们的模型和数据的最佳学习速率，然后使用该速率而不是我们指定的速率。注意:只有当您将hparams传递给模型并且hparams中有lr值时，这才有效。最后，为了避免运行太长时间，我们将<strong class="lb iu"> max_epochs </strong>设置为50。</p><p id="66d4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你已经做了很多深度学习，你可以欣赏我们的教练清洁()。我们不需要在数据上写一个循环，所有的都是为我们准备的。如果我们将代码转移到有8个GPU的机器上，我们所要做的就是将GPU改为8个。就是这样。如果我们可以访问TPU，Pytorch Lightning也支持这些，您只需打开选项。在某种程度上，你绝对应该查看一下<a class="ae ky" href="https://pytorch-lightning.readthedocs.io/en/latest/trainer.html" rel="noopener ugc nofollow" target="_blank">文档</a>中教练()提供的所有伟大选项。</p><h1 id="2106" class="mc md it bd me mf nl mh mi mj nm ml mm jz nn ka mo kc no kd mq kf np kg ms mt bi translated">结果呢</h1><p id="f0fb" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">那么——我们的模型在标记猴子方面表现如何？Pytorch Lightning自动检查具有最佳验证结果的模型，对我来说，这发生在第26纪元。我用这段代码加载了这个模型:</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="d62e" class="ng md it nc b gy nh ni l nj nk">model = ImagenetTransferLearning.load_from_checkpoint(&lt;PATH TO MODEL&gt;)</span></pre><p id="47f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">用这些代码，我对所有的验证数据进行了预测:</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="eb24" class="ng md it nc b gy nh ni l nj nk">model.eval()<br/>val_outs = []<br/>truth_outs = []<br/>for val_batch in tqdm(model.val_dataloader()):<br/>    x, y = val_batch<br/>    truth_outs.extend(y.numpy().tolist())<br/>    val_out = model(x)<br/>    val_outs.extend(val_out.detach().numpy().argmax(1).tolist())</span></pre><p id="de4a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是我的分类报告(使用scikit-learn):</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="a2b1" class="ng md it nc b gy nh ni l nj nk">precision    recall  f1-score   support</span><span id="6e54" class="ng md it nc b gy nq ni l nj nk">           0       0.89      0.92      0.91        26<br/>           1       0.93      0.89      0.91        28<br/>           2       1.00      0.93      0.96        27<br/>           3       0.97      0.93      0.95        30<br/>           4       1.00      0.88      0.94        26<br/>           5       1.00      1.00      1.00        28<br/>           6       1.00      1.00      1.00        26<br/>           7       1.00      0.96      0.98        28<br/>           8       0.93      1.00      0.96        27<br/>           9       0.84      1.00      0.91        26</span><span id="356c" class="ng md it nc b gy nq ni l nj nk">   micro avg       0.95      0.95      0.95       272<br/>   macro avg       0.96      0.95      0.95       272<br/>weighted avg       0.96      0.95      0.95       272</span></pre><p id="757c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">还不错！我的f1平均分数是0.95，我在班上的最低f1分数是0.91。</p><p id="c897" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不过，这些都是验证结果，所以他们很可能是乐观的。为了更好地表示我们的模型有多好，我们需要对不在训练集或验证集中的图像进行预测。</p><p id="8200" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我没有花时间去创建一个完整的测试集，但是我从谷歌上随机抓取了两张猴子的图片。事实上，这些图片就是这篇文章顶部的两张图片。我们的模型能够正确地预测它们！</p><p id="762a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，这里是用于培训的张量板图:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/726fc23247cbfdc7028d65422c4cad05.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/0*5zmW-XzMFZDeCBIz.png"/></div></figure><p id="6f1d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">可以肯定地说，由于我们的深度学习模型，我们现在是猴子物种的专家。:)</p><h1 id="75ae" class="mc md it bd me mf nl mh mi mj nm ml mm jz nn ka mo kc no kd mq kf np kg ms mt bi translated">自己去做！</h1><p id="1053" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">美妙的是，你现在可以很容易地对任何你想要的图片进行分类。你所要做的就是标记一些你自己的图片，适当地组织它们(如上所述)，然后<strong class="lb iu">修改3行代码</strong>。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="ac13" class="ng md it nc b gy nh ni l nj nk">hparams = Namespace(train_dir = &lt;PATH TO YOUR TRAINING DIRECTORY&gt;,<br/>                   val_dir = &lt;PATH TO YOUR VALIDATION DIRECTORY&gt;,<br/>                   num_target_classes = &lt;NUMBER OF TAGS/CLASSES&gt;,<br/>                   lr = 0.001,<br/>                   batch_size=8)</span></pre><p id="aea1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您只需要更新train_dir、val_dir和num_target_classes的值。就是这样！所以——自己去做吧，让我知道你把什么酷的东西归类了！</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="ccc3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://datascienceleadership.substack.com/" rel="noopener ugc nofollow" target="_blank">免费获取掌握数据科学的11种极其有用的资源</a></p></div></div>    
</body>
</html>