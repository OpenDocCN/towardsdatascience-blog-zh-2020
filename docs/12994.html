<html>
<head>
<title>Using Genetic Algorithms to Train Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用遗传算法训练神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-genetic-algorithms-to-train-neural-networks-b5ffe0d51321?source=collection_archive---------5-----------------------#2020-09-07">https://towardsdatascience.com/using-genetic-algorithms-to-train-neural-networks-b5ffe0d51321?source=collection_archive---------5-----------------------#2020-09-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/369f067d6a4a5edc5c318210d5508da6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Aet_aDBS-ZylYtYs1PSl9w.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated"><a class="ae kf" href="https://www.pexels.com/photo/low-angle-view-of-spiral-staircase-against-black-background-247676/" rel="noopener ugc nofollow" target="_blank">图像来源</a></p></figure><p id="e199" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">许多人使用遗传算法作为无监督算法，来优化特定环境中的代理，但是没有意识到将神经网络应用到代理中的可能性。</p><h1 id="4105" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">什么是遗传算法？</h1><p id="23d6" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">遗传算法是一种学习算法，它使用的思想是，交叉两个好的神经网络的权重，会产生更好的神经网络。</p><p id="539b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">遗传算法如此有效的原因是因为没有直接的优化算法，允许可能有极其不同的结果。此外，他们通常会提出非常有趣的解决方案，这些方案通常会对问题提供有价值的见解。</p><h1 id="f6d3" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">它们是如何工作的？</h1><p id="75d4" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">生成一组随机权重。这是第一个代理的神经网络。在代理上执行一组测试。代理会收到基于测试的分数。重复几次，创建一个群体。选择人口中前 10%的人进行杂交。从前 10%中选择两个随机亲本，并且它们的权重是交叉的。每次交叉发生时，都有很小的变异机会:这是一个不在双亲权重中的随机值。</p><p id="9ea9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">随着代理慢慢适应环境，这个过程会慢慢优化代理的性能。</p><h1 id="ab20" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">优点和缺点:</h1><p id="5809" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">优势:</p><ul class=""><li id="a450" class="mh mi it ki b kj kk kn ko kr mj kv mk kz ml ld mm mn mo mp bi translated">计算不密集</li></ul><p id="fb43" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">没有线性代数计算要做。唯一需要的机器学习计算是通过神经网络的正向传递。因此，与深度神经网络相比，系统要求非常广泛。</p><ul class=""><li id="72a8" class="mh mi it ki b kj kk kn ko kr mj kv mk kz ml ld mm mn mo mp bi translated">适合的</li></ul><p id="1ee3" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">人们可以适应和插入许多不同的测试和方法来操纵遗传算法的灵活性。人们可以在遗传算法中创建一个 GAN，方法是让代理传播生成器网络，测试作为鉴别器。这是一个至关重要的好处，它使我相信遗传算法的使用在未来将会更加广泛。</p><ul class=""><li id="ff42" class="mh mi it ki b kj kk kn ko kr mj kv mk kz ml ld mm mn mo mp bi translated">可理解的</li></ul><p id="db19" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于正常的神经网络来说，算法的学习模式充其量也是神秘的。对于遗传算法来说，很容易理解为什么会发生一些事情:例如，当遗传算法处于井字游戏环境中时，某些可识别的策略会慢慢发展。这是一个很大的好处，因为机器学习的使用是利用技术来帮助我们获得对重要问题的洞察力。</p><p id="3135" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">缺点:</p><ul class=""><li id="6700" class="mh mi it ki b kj kk kn ko kr mj kv mk kz ml ld mm mn mo mp bi translated">需要很长一段时间</li></ul><p id="7e2a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">不幸的交叉和突变可能会对程序的准确性产生负面影响，因此使程序收敛更慢或达到某个损失阈值。</p><h1 id="4714" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">代码:</h1><p id="4550" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">现在你已经对遗传算法及其优势和局限性有了相当全面的了解，我现在可以向你展示这个程序了:</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="7221" class="mz lf it mv b gy na nb l nc nd">import random<br/>import numpy as np</span></pre><p id="31cc" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这只是这个程序的两个依赖项。这是因为实现的神经网络基础设施是我自己创建的简单版本。要实现更复杂的网络，可以导入 keras 或 tensorflow。</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="7bba" class="mz lf it mv b gy na nb l nc nd">class genetic_algorithm:<br/>        <br/>    def execute(pop_size,generations,threshold,X,y,network):<br/>        class Agent:<br/>            def __init__(self,network):</span></pre><p id="cc4e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是“genetic_algorithm”类的创建，它包含了与遗传算法以及它应该如何工作有关的所有函数。主函数是 execute 函数，它将 pop_size、generations、threshold、X，y、network 作为参数。pop_size 是生成种群的大小，generations 是历元的术语，threshold 是您满意的损失值。x 和 y 用于标记数据的遗传算法的应用。对于没有数据或数据未标记的问题，可以删除 X 和 y 的所有实例。网络是神经网络的网络结构。</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="cefe" class="mz lf it mv b gy na nb l nc nd">class neural_network:<br/>                    def __init__(self,network):<br/>                        self.weights = []<br/>                        self.activations = []<br/>                        for layer in network:<br/>                            if layer[0] != None:<br/>                                input_size = layer[0]<br/>                            else:<br/>                                input_size = network[network.index(layer)-1][1]<br/>                            output_size = layer[1]<br/>                            activation = layer[2]<br/>                            self.weights.append(np.random.randn(input_size,output_size))<br/>                            self.activations.append(activation)<br/>                    def propagate(self,data):<br/>                        input_data = data<br/>                        for i in range(len(self.weights)):<br/>                            z = np.dot(input_data,self.weights[i])<br/>                            a = self.activations[i](z)<br/>                            input_data = a<br/>                        yhat = a<br/>                        return yhat<br/>                self.neural_network = neural_network(network)<br/>                self.fitness = 0</span></pre><p id="49ef" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该脚本描述了每个代理的神经网络的权重初始化和网络传播。</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="2670" class="mz lf it mv b gy na nb l nc nd">def generate_agents(population, network):<br/>            return [Agent(network) for _ in range(population)]</span></pre><p id="93ab" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该函数创建将被测试的第一个代理群体。</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="9dd8" class="mz lf it mv b gy na nb l nc nd">def fitness(agents,X,y):<br/>            for agent in agents:<br/>                yhat = agent.neural_network.propagate(X)<br/>                cost = (yhat - y)**2<br/>                agent.fitness = sum(cost)<br/>            return agents</span></pre><p id="c51c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因为我使用的例子利用了标记数据。适应度函数仅仅是计算预测的 MSE 或成本函数。</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="46c8" class="mz lf it mv b gy na nb l nc nd">def selection(agents):<br/>            agents = sorted(agents, key=lambda agent: agent.fitness, reverse=False)<br/>            print('\n'.join(map(str, agents)))<br/>            agents = agents[:int(0.2 * len(agents))]<br/>            return agents</span></pre><p id="4e3f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个函数模仿了进化论中的选择理论:最优秀的生存下来，而其他的则任其自生自灭。在这种情况下，他们的数据会被遗忘，不会被再次使用。</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="d1fa" class="mz lf it mv b gy na nb l nc nd">def unflatten(flattened,shapes):<br/>            newarray = []<br/>            index = 0<br/>            for shape in shapes:<br/>                size = np.product(shape)<br/>                newarray.append(flattened[index : index + size].reshape(shape))<br/>                index += size<br/>            return newarray</span></pre><p id="954f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了执行交叉和变异功能，权重需要展平和取消展平为原始形状。</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="2c0b" class="mz lf it mv b gy na nb l nc nd">def crossover(agents,network,pop_size):<br/>            offspring = []<br/>            for _ in range((pop_size - len(agents)) // 2):<br/>                parent1 = random.choice(agents)<br/>                parent2 = random.choice(agents)<br/>                child1 = Agent(network)<br/>                child2 = Agent(network)<br/>                <br/>                shapes = [a.shape for a in parent1.neural_network.weights]<br/>                <br/>                genes1 = np.concatenate([a.flatten() for a in parent1.neural_network.weights])<br/>                genes2 = np.concatenate([a.flatten() for a in parent2.neural_network.weights])<br/>                <br/>                split = random.ragendint(0,len(genes1)-1)</span><span id="8d51" class="mz lf it mv b gy ne nb l nc nd">child1_genes = np.asrray(genes1[0:split].tolist() + genes2[split:].tolist())<br/>                child2_genes = np.array(genes1[0:split].tolist() + genes2[split:].tolist())<br/>                <br/>                child1.neural_network.weights = unflatten(child1_genes,shapes)<br/>                child2.neural_network.weights = unflatten(child2_genes,shapes)<br/>                <br/>                offspring.append(child1)<br/>                offspring.append(child2)<br/>            agents.extend(offspring)<br/>            return agents</span></pre><p id="d76f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">交叉函数是程序中最复杂的函数之一。它产生两个新的“子”代理，它们的权重被替换为两个随机产生的父代理的交叉。这是创建权重的过程:</p><ol class=""><li id="2f9f" class="mh mi it ki b kj kk kn ko kr mj kv mk kz ml ld nf mn mo mp bi translated">拉平父母的权重</li><li id="bf8e" class="mh mi it ki b kj ng kn nh kr ni kv nj kz nk ld nf mn mo mp bi translated">生成两个分割点</li><li id="bc41" class="mh mi it ki b kj ng kn nh kr ni kv nj kz nk ld nf mn mo mp bi translated">使用分割点作为索引来设置两个子代理的权重</li></ol><p id="d141" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是智能体交叉的全过程。</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="06ab" class="mz lf it mv b gy na nb l nc nd">def mutation(agents):<br/>            for agent in agents:<br/>                if random.uniform(0.0, 1.0) &lt;= 0.1:<br/>                    weights = agent.neural_network.weights<br/>                    shapes = [a.shape for a in weights]</span><span id="9294" class="mz lf it mv b gy ne nb l nc nd">flattened = np.concatenate([a.flatten() for a in weights])<br/>                    randint = random.randint(0,len(flattened)-1)<br/>                    flattened[randint] = np.random.randn()</span><span id="ac4f" class="mz lf it mv b gy ne nb l nc nd">newarray = [a ]<br/>                    indeweights = 0<br/>                    for shape in shapes:<br/>                        size = np.product(shape)<br/>                        newarray.append(flattened[indeweights : indeweights + size].reshape(shape))<br/>                        indeweights += size<br/>                    agent.neural_network.weights = newarray<br/>            return agents </span></pre><p id="eaa5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是变异函数。展平与交叉功能相同。不是分割点，而是选择一个随机点，用一个随机值替换。</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="e7e7" class="mz lf it mv b gy na nb l nc nd">for i in range(generations):<br/>            print('Generation',str(i),':')<br/>            agents = generate_agents(pop_size,network)<br/>            agents = fitness(agents,X,y)<br/>            agents = selection(agents)<br/>            agents = crossover(agents,network,pop_size)<br/>            agents = mutation(agents)<br/>            agents = fitness(agents,X,y)<br/>            <br/>            if any(agent.fitness &lt; threshold for agent in agents):<br/>                print('Threshold met at generation '+str(i)+' !')<br/>                <br/>            if i % 100:<br/>                clear_output()<br/>                <br/>        return agents[0]</span></pre><p id="a6d5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是 execute 函数的最后一部分，它执行所有已定义的函数。</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="2f13" class="mz lf it mv b gy na nb l nc nd">X = np.array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])<br/>y = np.array([[0, 1, 1, 0]]).T<br/>network = [[3,10,sigmoid],[None,1,sigmoid]]<br/>ga = genetic_algorithm<br/>agent = ga.execute(100,5000,0.1,X,y,network)<br/>weights = agent.neural_network.weights<br/>agent.fitness<br/>agent.neural_network.propagate(X)</span></pre><p id="e482" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这执行整个遗传算法。对于网络变量，每个嵌套列表保存输入神经元数目、输出神经元数目和激活函数。执行函数返回最佳代理。</p><h1 id="59a7" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">我的链接:</h1><p id="a665" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">如果你想看更多我的内容，点击这个<a class="ae kf" href="https://linktr.ee/victorsi" rel="noopener ugc nofollow" target="_blank"> <strong class="ki iu">链接</strong> </a>。</p></div></div>    
</body>
</html>