<html>
<head>
<title>You don’t have to win a Kaggle competition to showcase your data science ability!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你不必赢得一场 Kaggle 比赛来展示你的数据科学能力！</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/you-dont-have-to-win-a-kaggle-competition-to-showcase-your-data-science-ability-2852a77b6d8c?source=collection_archive---------45-----------------------#2020-07-25">https://towardsdatascience.com/you-dont-have-to-win-a-kaggle-competition-to-showcase-your-data-science-ability-2852a77b6d8c?source=collection_archive---------45-----------------------#2020-07-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/6ec370a642ca4a162b96b7e081f64cef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4HeTiaFbyKY9xyZpR8PYDQ.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">(图片由作者提供)</p></figure><div class=""/><div class=""><h2 id="c5b0" class="pw-subtitle-paragraph kf jh ji bd b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw dk translated">我曾经坚持认为只有 Kaggle 比赛的获胜者才能展示他们的背景，现在我发现 Kaggle 的每个新人都可以在没有像样的排行榜的情况下展示他们的努力！</h2></div><p id="32cc" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi lt translated">我们可以用我们的作品在 Kaggle 比赛中做什么？获得一个体面的排名，并可能获得大量奖励，这个答案对一些天才来说可能听起来不错。但是你不够聪明怎么办？这场比赛会完全没有意义吗？肯定没有！<a class="ae mc" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>作为数据科学家和机器学习爱好者的最大社区，不仅是为了排名和金钱，也是一个提高我们数据科学/建模技术的完美平台。</p><p id="ef6a" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">在文章的其余部分，我将介绍一种方法来展示你在 Kaggle 比赛中所做的事情，这是一个非常有用的组合，尤其是当你未能在排行榜上排名第一时，更重要的是给你的面试官留下深刻印象！</p></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h1 id="d6b5" class="mk ml ji bd mm mn mo mp mq mr ms mt mu ko mv kp mw kr mx ks my ku mz kv na nb bi translated"><strong class="ak">我要讲的是哪个比赛？</strong></h1><p id="9635" class="pw-post-body-paragraph kx ky ji kz b la nc kj lc ld nd km lf lg ne li lj lk nf lm ln lo ng lq lr ls im bi translated">我最近参加了由萨斯喀彻温大学主办的<a class="ae mc" href="https://www.kaggle.com/c/global-wheat-detection" rel="noopener ugc nofollow" target="_blank"> <strong class="kz jj">全球小麦检测</strong> </a>，该项目旨在帮助农民在他们的田地里做出管理决策时评估健康和成熟度。该竞赛鼓励候选人尽可能提高图像中小麦籽粒的检测精度。直到编辑完这篇文章，本次比赛的№1 候选队伍已经取得了 0.7772 的成绩，这是比赛开展前的巨大飞跃，因为首发笔记本的成绩只有 0.66 左右。其截止日期为 2020 年 8 月 4 日。所以，如果你对计算机视觉感兴趣或者想赢得一些钱(一等奖 8000 美元！)，你绝对没有理由错过！</p><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nh"><img src="../Images/3460e6db55c627c873f1d7014d460628.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PHj9rP7kWCLuP7iCmMqY8w.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">全球小麦检测竞赛主页(图片由作者提供)</p></figure></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h1 id="d882" class="mk ml ji bd mm mn mo mp mq mr ms mt mu ko mv kp mw kr mx ks my ku mz kv na nb bi translated">开始之前</h1><p id="76dc" class="pw-post-body-paragraph kx ky ji kz b la nc kj lc ld nd km lf lg ne li lj lk nf lm ln lo ng lq lr ls im bi translated">如果你没有耐心通读整页(跟我一样:)，现在就可以通过，直接去我的 GitHub repo:</p><blockquote class="nm nn no"><p id="5fb6" class="kx ky np kz b la lb kj lc ld le km lf nq lh li lj nr ll lm ln ns lp lq lr ls im bi translated"><a class="ae mc" href="https://github.com/MemphisMeng/global-wheat-detection-web-app" rel="noopener ugc nofollow" target="_blank">https://github . com/MemphisMeng/global-wheat-detection-we B- app</a>。</p></blockquote><p id="585a" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">现在让我们来谈谈这个项目所需的依赖关系:</p><ol class=""><li id="1280" class="nt nu ji kz b la lb ld le lg nv lk nw lo nx ls ny nz oa ob bi translated"><a class="ae mc" href="https://docs.streamlit.io/en/stable/" rel="noopener ugc nofollow" target="_blank"> <strong class="kz jj">细流</strong> </a></li><li id="0c09" class="nt nu ji kz b la oc ld od lg oe lk of lo og ls ny nz oa ob bi translated"><a class="ae mc" href="https://albumentations.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> <strong class="kz jj">相册</strong> </a></li><li id="1a5f" class="nt nu ji kz b la oc ld od lg oe lk of lo og ls ny nz oa ob bi translated"><a class="ae mc" href="https://matplotlib.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kz jj"> matplotlib </strong> </a></li><li id="4d01" class="nt nu ji kz b la oc ld od lg oe lk of lo og ls ny nz oa ob bi translated"><a class="ae mc" href="https://numpy.org/doc/stable/" rel="noopener ugc nofollow" target="_blank"> <strong class="kz jj"> numpy </strong> </a></li><li id="323b" class="nt nu ji kz b la oc ld od lg oe lk of lo og ls ny nz oa ob bi translated"><a class="ae mc" href="https://github.com/skvark/opencv-python" rel="noopener ugc nofollow" target="_blank"> <strong class="kz jj"> opencv-python </strong> </a></li><li id="fcc1" class="nt nu ji kz b la oc ld od lg oe lk of lo og ls ny nz oa ob bi translated"><a class="ae mc" href="https://pandas.pydata.org/docs/" rel="noopener ugc nofollow" target="_blank"> <strong class="kz jj">熊猫</strong> </a></li><li id="0b26" class="nt nu ji kz b la oc ld od lg oe lk of lo og ls ny nz oa ob bi translated"><a class="ae mc" href="https://python-imaging.github.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="kz jj">枕头</strong> </a></li><li id="ca6a" class="nt nu ji kz b la oc ld od lg oe lk of lo og ls ny nz oa ob bi translated"><a class="ae mc" href="https://docs.scipy.org/doc/" rel="noopener ugc nofollow" target="_blank"><strong class="kz jj">scipy</strong>T24】</a></li></ol><p id="0922" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">如果您不熟悉以上任何一个，请随意点击超链接并参考它们各自的文档。</p><p id="4a9f" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">最后一件值得注意的事情是，我将要建立的是一个面向 JPG 图像的麦穗检测器。换句话说，我会让模型告诉你一个图像中有多少个麦穗，它们位于哪里，只要你在应用中上传一个。</p><h1 id="2336" class="mk ml ji bd mm mn oh mp mq mr oi mt mu ko oj kp mw kr ok ks my ku ol kv na nb bi translated">我们来编码吧！</h1><p id="f174" class="pw-post-body-paragraph kx ky ji kz b la nc kj lc ld nd km lf lg ne li lj lk nf lm ln lo ng lq lr ls im bi translated">首先，为了利用我在上一节中提到的所有库，需要做的就是简单地导入它们中的每一个:</p><pre class="ni nj nk nl gt om on oo op aw oq bi"><span id="52e4" class="or ml ji on b gy os ot l ou ov"><strong class="on jj">import </strong>numpy <strong class="on jj">as </strong>np<br/><strong class="on jj">import </strong>pandas <strong class="on jj">as </strong>pd<br/><strong class="on jj">import </strong>re<br/><strong class="on jj">from </strong>PIL <strong class="on jj">import </strong>Image<br/><strong class="on jj">import </strong>albumentations <strong class="on jj">as </strong>A<br/><strong class="on jj">from </strong>albumentations.pytorch.transforms <strong class="on jj">import </strong>ToTensorV2<br/><strong class="on jj">import </strong>torch<br/><strong class="on jj">import </strong>torchvision<br/><strong class="on jj">from </strong>torchvision.models.detection.faster_rcnn <strong class="on jj">import </strong>FastRCNNPredictor<br/><strong class="on jj">import </strong>streamlit <strong class="on jj">as </strong>st<br/><strong class="on jj">from </strong>torch.utils.data <strong class="on jj">import </strong>DataLoader, Dataset<br/><strong class="on jj">from </strong>matplotlib <strong class="on jj">import </strong>pyplot <strong class="on jj">as </strong>plt<br/><strong class="on jj">import </strong>cv2</span></pre><p id="81f4" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">为了处理每一张上传的图片，我把它看作一个数据集，方便以后涉及 PyTorch 的操作。</p><pre class="ni nj nk nl gt om on oo op aw oq bi"><span id="5e4d" class="or ml ji on b gy os ot l ou ov"><strong class="on jj">class </strong>WheatTestDataset(Dataset):<br/><br/>    <strong class="on jj">def </strong>__init__(self, image, transforms=<strong class="on jj">None</strong>):<br/>        super().__init__()<br/>        self.transforms = transforms<br/>        self.image = [image]<br/><br/>    <strong class="on jj">def </strong>__getitem__(self, index):<br/>        image = cv2.cvtColor(np.asarray(self.image[index]), cv2.COLOR_BGR2RGB).astype(np.float32)<br/>        <em class="np"># st.write('image', image)<br/>        # image = np.asarray(self.image[index]).astype(np.float32)<br/>        </em>image /= 255.0<br/><br/>        <strong class="on jj">if </strong>self.transforms:<br/>            sample = {<br/>                <strong class="on jj">'image'</strong>: image,<br/>            }<br/>            sample = self.transforms(**sample)<br/>            image = sample[<strong class="on jj">'image'</strong>]<br/><br/>        <strong class="on jj">return </strong>np.asarray(image)<br/><br/>    <strong class="on jj">def </strong>__len__(self) -&gt; int:<br/>        <strong class="on jj">return </strong>len(self.image)</span><span id="87b0" class="or ml ji on b gy ow ot l ou ov"><em class="np"># Albumentations<br/></em><strong class="on jj">def </strong>get_test_transform():<br/>    <strong class="on jj">return </strong>A.Compose([<br/>        <em class="np"># A.Resize(512, 512),<br/>        </em>ToTensorV2(p=1.0)<br/>    ])<br/><br/><br/><strong class="on jj">def </strong>collate_fn(batch):<br/>    <strong class="on jj">return </strong>tuple(zip(*batch))</span></pre><p id="8381" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">因此，我们可以这样加载图像:</p><pre class="ni nj nk nl gt om on oo op aw oq bi"><span id="3379" class="or ml ji on b gy os ot l ou ov">test_dataset = WheatTestDataset(image, get_test_transform())<br/>test_data_loader = DataLoader(<br/>    test_dataset,<br/>    batch_size=1,<br/>    shuffle=<strong class="on jj">False</strong>,<br/>    num_workers=4,<br/>    drop_last=<strong class="on jj">False</strong>,<br/>    collate_fn=collate_fn<br/>)</span></pre><p id="80c6" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">之后，我还需要加载或配置神经网络模型。为了方便起见，我只是加载了基于 FasterRCNN 的预训练模型，你也可以在这里下载<a class="ae mc" href="https://www.kaggle.com/pestipeti/pytorch-starter-fasterrcnn-inference/output" rel="noopener ugc nofollow" target="_blank">。因此，建模部分看起来像:</a></p><pre class="ni nj nk nl gt om on oo op aw oq bi"><span id="5c56" class="or ml ji on b gy os ot l ou ov">WEIGHTS_FILE = <strong class="on jj">'fasterrcnn_resnet50_fpn_best.pth' # downloaded weights<br/></strong><em class="np"># load a model; pre-trained on COCO<br/></em>model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=<strong class="on jj">False</strong>, pretrained_backbone=<strong class="on jj">False</strong>)<br/>device = torch.device(<strong class="on jj">'cuda'</strong>) <strong class="on jj">if </strong>torch.cuda.is_available() <strong class="on jj">else </strong>torch.device(<strong class="on jj">'cpu'</strong>)<br/>num_classes = 2  <em class="np"># 1 class (wheat) + background<br/># get number of input features for the classifier<br/></em>in_features = model.roi_heads.box_predictor.cls_score.in_features<br/><em class="np"># replace the pre-trained head with a new one<br/></em>model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)<br/><em class="np"># Load the trained weights<br/></em>model.load_state_dict(torch.load(WEIGHTS_FILE, map_location=device))<br/>model.eval()</span></pre><p id="39d1" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">接下来，应该在网页上添加一些必要的元素:</p><pre class="ni nj nk nl gt om on oo op aw oq bi"><span id="d441" class="or ml ji on b gy os ot l ou ov">st.header(<strong class="on jj">"""<br/>WELCOME TO GLOBAL WHEAT HEAD CHALLENGE!<br/>"""</strong>)<br/>st.subheader(<strong class="on jj">'Please open this website with Google Chrome.'</strong>)<br/>uploaded_file = st.file_uploader(<strong class="on jj">"Choose an image... (jpg only)"</strong>, type=<strong class="on jj">"jpg"</strong>)<br/>confidence_threshold = st.number_input(<strong class="on jj">'Please specify the confidence of a wheat head'</strong>)<br/>button = st.button(<strong class="on jj">'Confirm'</strong>)</span></pre><p id="91cb" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">最后，我们可以直接使用我们的模型来检测项目:</p><pre class="ni nj nk nl gt om on oo op aw oq bi"><span id="378f" class="or ml ji on b gy os ot l ou ov">detection_threshold = confidence_threshold <strong class="on jj">or </strong>0.5<br/>results = []<br/>outputs = <strong class="on jj">None<br/></strong>images = <strong class="on jj">None<br/><br/>if </strong>button <strong class="on jj">and </strong>uploaded_file <strong class="on jj">is not None</strong>:<br/>    image = Image.open(uploaded_file)<br/>    st.image(image, caption=<strong class="on jj">'Uploaded Image'</strong>, use_column_width=<strong class="on jj">True</strong>)<br/>    st.write(<strong class="on jj">""</strong>)<br/>    st.write(<strong class="on jj">"Detecting..."</strong>)<br/>    test_dataset = WheatTestDataset(image, get_test_transform())<br/>    test_data_loader = DataLoader(<br/>        test_dataset,<br/>        batch_size=1,<br/>        shuffle=<strong class="on jj">False</strong>,<br/>        num_workers=4,<br/>        drop_last=<strong class="on jj">False</strong>,<br/>        collate_fn=collate_fn<br/>    )<br/><br/>    <strong class="on jj">for </strong>images <strong class="on jj">in </strong>test_data_loader:<br/>        images = torch.Tensor([images[0][0], images[1][0], images[2][0]])<br/>        images = torch.reshape(images, (3, 1024, 1024))<br/>        images = (images,)<br/>        images = list(image.to(device) <strong class="on jj">for </strong>image <strong class="on jj">in </strong>images)<br/>        outputs = model(images)<br/><br/>        <strong class="on jj">for </strong>i, image <strong class="on jj">in </strong>enumerate(images):<br/>            boxes = outputs[i][<strong class="on jj">'boxes'</strong>].data.cpu().numpy()<br/>            scores = outputs[i][<strong class="on jj">'scores'</strong>].data.cpu().numpy()<br/><br/>            boxes = boxes[scores &gt;= detection_threshold].astype(np.int32)<br/>            scores = scores[scores &gt;= detection_threshold]<br/><br/>            boxes[:, 2] = boxes[:, 2] - boxes[:, 0]<br/>            boxes[:, 3] = boxes[:, 3] - boxes[:, 1]<br/><br/>            <strong class="on jj">for </strong>j <strong class="on jj">in </strong>zip(boxes, scores):<br/>                result = {<br/>                    <strong class="on jj">'Detected Boxes'</strong>: <strong class="on jj">"{} {} {} {}"</strong>.format(j[0][0], j[0][1], j[0][2], j[0][3]),<br/>                    <strong class="on jj">'Confidence%'</strong>: j[1]<br/>                }<br/>                results.append(result)<br/><br/><strong class="on jj">if </strong>len(results) != 0:<br/>    <em class="np"># print out results<br/>    </em>sample = images[0].permute(1, 2, 0).cpu().numpy()<br/>    boxes = outputs[0][<strong class="on jj">'boxes'</strong>].data.cpu().numpy()<br/>    scores = outputs[0][<strong class="on jj">'scores'</strong>].data.cpu().numpy()<br/>    boxes = boxes[scores &gt;= detection_threshold].astype(np.int32)<br/>    fig, ax = plt.subplots(1, 1, figsize=(32, 16))<br/>    <strong class="on jj">for </strong>box <strong class="on jj">in </strong>boxes:<br/>        x1, y1, x2, y2 = box<br/>        sample = cv2.rectangle(img=sample,<br/>                               pt1=(x1, y1),<br/>                               pt2=(x2, y2),<br/>                               color=(0, 0, 255), thickness=3)<br/>    ax.set_axis_off()<br/>    st.image(cv2.UMat.get(sample), clamp=<strong class="on jj">True</strong>)<br/>    st.write(<strong class="on jj">"# Results"</strong>)<br/>    st.dataframe(pd.DataFrame(results))<br/><strong class="on jj">else</strong>:<br/>    st.write(<strong class="on jj">""</strong>)<br/>    st.write(<strong class="on jj">"""<br/>    No wheat heads detected in the image!<br/>    """</strong>)</span></pre><p id="fde8" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">所以现在这个 web app 是在本地端完成的，所以当你在终端输入<code class="fe ox oy oz on b">streamlit run app.py</code>的时候，你就可以在本地主机上访问和测试程序。</p></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h1 id="0245" class="mk ml ji bd mm mn mo mp mq mr ms mt mu ko mv kp mw kr mx ks my ku mz kv na nb bi translated">下一步是什么？</h1><p id="0fa7" class="pw-post-body-paragraph kx ky ji kz b la nc kj lc ld nd km lf lg ne li lj lk nf lm ln lo ng lq lr ls im bi translated">既然我们已经开发了这个检测工具，如果我们能与任何需要它的人分享它，那将是完美的。因此，将其部署为任何人都可以随时查看的 web 应用程序绝对是一个不错的选择。各种企业开发的 web 服务有一堆，现在我就以 Google 云平台为例。谷歌云平台(<a class="ae mc" href="https://cloud.google.com/" rel="noopener ugc nofollow" target="_blank"> GCP </a>)是谷歌提供的一套网络服务，包括一套管理工具和一系列模块化云服务。这一次，我们主要需要使用它的容器化和 GPU 服务。</p><p id="6257" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">我实现这一部分的策略与<a class="pa pb ep" href="https://medium.com/u/fba05660b60f?source=post_page-----2852a77b6d8c--------------------------------" rel="noopener" target="_blank"> Moez Ali </a>发表的这篇<a class="ae mc" rel="noopener" target="_blank" href="/deploy-machine-learning-app-built-using-streamlit-and-pycaret-on-google-kubernetes-engine-fd7e393d99cb">帖子</a>中的任务 4 基本相同。需要注意的是，由于我们的项目使用 PyTorch 作为框架来配置神经网络模型，因此从<a class="ae mc" href="https://hub.docker.com/r/pytorch/pytorch/" rel="noopener ugc nofollow" target="_blank"> docker hub </a>导入已建立的 docker 映像总是更好，而不是要求主机在 requirements.txt 中安装。该选项的最大好处是它有效地节省了机器的内存空间。因此，完整的 docker 文件如下所示:</p><pre class="ni nj nk nl gt om on oo op aw oq bi"><span id="311b" class="or ml ji on b gy os ot l ou ov">FROM pytorch/pytorch:1.4-cuda10.1-cudnn7-runtime<br/>RUN pip install virtualenv<br/>ENV VIRTUAL_ENV=/venv<br/>RUN virtualenv venv -p python3<br/>ENV PATH="VIRTUAL_ENV/bin:$PATH"</span><span id="e18c" class="or ml ji on b gy ow ot l ou ov">WORKDIR /app<br/>ADD . /app</span><span id="de5b" class="or ml ji on b gy ow ot l ou ov"># Install dependencies<br/>RUN apt update<br/>RUN apt-get install -y libglib2.0-0 libsm6 libxrender1 libxext6<br/>RUN pip install -r requirements.txt</span><span id="7c42" class="or ml ji on b gy ow ot l ou ov"># copying all files over<br/>COPY . /app</span><span id="2342" class="or ml ji on b gy ow ot l ou ov"># Expose port <br/>ENV PORT 8501</span><span id="8d79" class="or ml ji on b gy ow ot l ou ov"># cmd to launch app when container is run<br/>CMD streamlit run app.py</span><span id="877b" class="or ml ji on b gy ow ot l ou ov"># streamlit-specific commands for config<br/>ENV LC_ALL=C.UTF-8<br/>ENV LANG=C.UTF-8<br/>RUN mkdir -p /root/.streamlit<br/>RUN bash -c 'echo -e "\<br/>[general]\n\<br/>email = \"\"\n\<br/>" &gt; /root/.streamlit/credentials.toml'</span><span id="ac9b" class="or ml ji on b gy ow ot l ou ov">RUN bash -c 'echo -e "\<br/>[server]\n\<br/>enableCORS = false\n\<br/>" &gt; /root/.streamlit/config.toml'</span></pre></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h1 id="ef29" class="mk ml ji bd mm mn mo mp mq mr ms mt mu ko mv kp mw kr mx ks my ku mz kv na nb bi translated">干得好！</h1><p id="9fe2" class="pw-post-body-paragraph kx ky ji kz b la nc kj lc ld nd km lf lg ne li lj lk nf lm ln lo ng lq lr ls im bi translated">现在我们已经成功地将该项目部署到 GCP，然后任何对你的工作感兴趣的人都可以从中得到乐趣。</p><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/5f2c315c1e57b7f78188b65a2328445e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*XEZxkjXxaHS4SDFBbdHvZw.gif"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">网络应用网址:<a class="ae mc" href="http://35.188.98.72/" rel="noopener ugc nofollow" target="_blank">http://35.188.98.72/</a>(图片由作者提供)</p></figure></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h1 id="0d4c" class="mk ml ji bd mm mn mo mp mq mr ms mt mu ko mv kp mw kr mx ks my ku mz kv na nb bi translated">思想</h1><p id="fb7f" class="pw-post-body-paragraph kx ky ji kz b la nc kj lc ld nd km lf lg ne li lj lk nf lm ln lo ng lq lr ls im bi translated">我写这篇文章是因为我最近受到一个人的启发，他问我这个行业可以用我的 Kaggle 项目做什么。我曾经陷入这样一个陷阱:除非你在 Kaggle 上有一个像样的个人资料，否则你将无法找到一份数据科学的工作。这并没有错，虽然没有人可以定义你的体面。而那个人的话让我更多的为行业考虑，这应该是一个有志的数据科学家找工作应该具备的“体面”。</p><p id="d300" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">所以我努力发展自己的方式来展示我在 Kaggle 上所做的事情，试图让每个人都理解我的项目，并说服他们我的项目对他们的业务有价值，即使他们没有 IT 背景。把一个项目包装成一个网络应用程序，让每个人都能享受其中的乐趣，这是我现在最好的选择。</p><p id="c3c5" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">这是我的第一篇关于媒介的文章，如果你喜欢，请给我一个掌声，因为这将是你对我最大的鼓励。未来，我将发表更多文章，分享我的数据科学之路。所以有兴趣的请跟我来！</p></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><p id="fcff" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated"><strong class="kz jj">参考文献:</strong></p><p id="250d" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">[1] <a class="pa pb ep" href="https://medium.com/u/fba05660b60f?source=post_page-----2852a77b6d8c--------------------------------" rel="noopener" target="_blank"> Moez Ali </a>，<a class="ae mc" rel="noopener" target="_blank" href="/deploy-machine-learning-app-built-using-streamlit-and-pycaret-on-google-kubernetes-engine-fd7e393d99cb">在 Google Kubernetes 引擎上部署使用 Streamlit 和 PyCaret 构建的机器学习应用</a></p><p id="393e" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">[2]<a class="ae mc" href="https://www.kaggle.com/pestipeti/pytorch-starter-fasterrcnn-inference" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/pesti peti/py torch-starter-fasterr CNN-推论</a></p></div></div>    
</body>
</html>