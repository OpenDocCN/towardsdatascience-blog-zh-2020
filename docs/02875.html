<html>
<head>
<title>The magic behind Recommendation Systems</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">推荐系统背后的魔力</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-magic-behind-recommendation-systems-c3fc44927b3c?source=collection_archive---------27-----------------------#2020-03-19">https://towardsdatascience.com/the-magic-behind-recommendation-systems-c3fc44927b3c?source=collection_archive---------27-----------------------#2020-03-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/2b067ec0b1a99dd1675a0c15fa5ddce3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3UGs7nKDZk9PIZpxtkIGsQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">来源:Shutterstock</p></figure><div class=""/><p id="bde0" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们经常会对亚马逊上的购物推荐、网飞上的观看推荐或 Spotify 上的收听推荐的准确性感到惊讶。我们觉得这些公司知道我们的大脑是如何工作的，并从这个神奇的猜谜游戏中获利。他们在行为科学上有很深的基础，我们的工作是以一种既容易理解又涵盖最重要概念的方式使所有这些概念成为现实。</p><blockquote class="ld le lf"><p id="6916" class="kf kg lg kh b ki kj kk kl km kn ko kp lh kr ks kt li kv kw kx lj kz la lb lc im bi translated">记住:人是非常容易预测的。行为表明性格。个性塑造我们的行为，而我们的行为决定我们的决定。</p></blockquote><figure class="ll lm ln lo gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lk"><img src="../Images/d73901c75495d4844ed0742991b35b9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UeC8ajRoZcDYWyNPLHmmnw.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">来源:Shutterstock。产品推荐</p></figure><p id="c376" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">更正式地说，推荐系统是信息过滤系统的一个子类。简而言之，信息过滤系统从数据流中删除冗余或不需要的数据。它们在语义层面上减少噪音。围绕这个主题有大量的文献，从天文学到金融风险分析。</p><p id="829a" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">有两种主要类型的推荐系统:</p><ul class=""><li id="ae5a" class="lp lq ji kh b ki kj km kn kq lr ku ls ky lt lc lu lv lw lx bi translated">协同过滤(CF)</li><li id="cf53" class="lp lq ji kh b ki ly km lz kq ma ku mb ky mc lc lu lv lw lx bi translated">基于内容的过滤</li></ul><p id="ac61" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们将探索这两种类型，并给出例子和利弊。没有完美的系统，但是有更适合特定需求以及不同复杂程度的解决方案。</p><h1 id="51c2" class="md me ji bd mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na bi translated"><strong class="ak"> <em class="nb">【协同过滤】</em> </strong></h1><p id="e160" class="pw-post-body-paragraph kf kg ji kh b ki nc kk kl km nd ko kp kq ne ks kt ku nf kw kx ky ng la lb lc im bi translated">这种过滤类型的基础是用户/项目反馈循环。</p><p id="cd08" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这种反馈可以是用户评级、竖起大拇指和竖起大拇指，甚至是用户对特定内容的参与程度。协作过滤有两种含义，狭义的和更广义的。</p><p id="2227" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在狭义上，协同过滤是一种通过聚集偏好或从几个用户(协作)收集数据来构建关于用户兴趣的自动预测(过滤)的方法。</p><p id="8fce" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">协同过滤方法的基本假设是，如果人 A 在一个问题上与人 B 有相同的观点，则 A 更有可能在一个不同的问题上与随机选择的人有不同的观点。网飞可以使用协同过滤来预测一个用户会喜欢哪个电视节目，给定一个用户喜好(喜欢或不喜欢)的部分列表。注意，这些预测是特定于用户的，但是使用从许多用户那里收集的信息。</p><figure class="ll lm ln lo gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nh"><img src="../Images/79e5c19abb79a3dac958237ea92c9b23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K-_vbU1vfEd1K3lBf26v7g.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">来源:Shutterstock。评级/评论</p></figure><p id="ad0c" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">协作过滤公式将客户表示为 N 维向量 N，其中 N 是各种不同的目录数据。向量的元素对于被访问或正面评价的内容是正的，对于负面评价的信息是负的。</p><p id="04b6" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">从计算角度来说，协同过滤在最坏的情况下是 O(MN ),其中 M 是客户的数量，N 是产品目录数据的数量。实际上，由于平均客户端向量非常小，因此性能更接近于 O(M+N)。</p><figure class="ll lm ln lo gt iv gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/48309b6905013716dd54037eba384e5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*-C7Ky5Uw5VUCwDRDRJHTJw.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">来源:InCubeGroup。顾客和品味(MxN 矩阵)</p></figure><p id="e539" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在更一般的意义上，协作过滤是使用涉及多个代理、观点、数据源等之间协作的技术来过滤信息或模式的过程。它通常涉及非常大的数据集。一些公开的可以在这里找到<a class="ae nj" href="https://github.com/caserec/Datasets-for-Recommender-Systems" rel="noopener ugc nofollow" target="_blank">。</a></p></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><p id="bf46" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们有不同类型的协同过滤:</p><ul class=""><li id="2291" class="lp lq ji kh b ki kj km kn kq lr ku ls ky lt lc lu lv lw lx bi translated">用户-用户</li><li id="a942" class="lp lq ji kh b ki ly km lz kq ma ku mb ky mc lc lu lv lw lx bi translated">项目-项目</li><li id="d815" class="lp lq ji kh b ki ly km lz kq ma ku mb ky mc lc lu lv lw lx bi translated">用户项目</li></ul><p id="a837" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><strong class="kh jj"> <em class="lg">用户-用户:</em> </strong>最常用的推荐算法遵循“喜欢你的人喜欢那个”的逻辑。它会推荐相似用户以前喜欢的物品。两个用户之间的<strong class="kh jj">相似性是根据他们在数据集中共有的项目数量计算的。当用户数量小于项目数量时，该算法是有效的。一个很好的例子是一个中等规模的电商网站，有几百万的产品。主要的缺点是添加新用户是昂贵的，因为它需要更新用户之间的所有相似性。</strong></p><p id="5565" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><strong class="kh jj"> <em class="lg"> Item-Item: </em> </strong>它使用相同的方法，但是颠倒了用户和项目之间的视图。它遵循“如果你喜欢这个，你可能也会喜欢那个”的逻辑。换句话说，它会推荐与您之前喜欢的项目相似的项目。和以前一样，两个项目之间的相似性是使用它们在数据集中共有的用户数量来计算的。当项目数量远小于用户数量时，该算法更好。一个例子可能是一个大型的网上商店，当你的物品不经常改变时。主要缺点是项目-项目相似性表必须预先计算。添加新项目时更新该表的成本很高。</p><p id="7fe6" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><strong class="kh jj"> <em class="lg">用户-项目:</em> </strong>它结合了两种方法来生成建议。最简单的是基于矩阵分解技术。目标是<strong class="kh jj">为所有用户和所有项目创建低维向量</strong>(“嵌入”)，这样将它们相乘就可以发现用户是否喜欢某个项目。</p><p id="4b4a" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">用户-项目矩阵是传统协同过滤技术的基础，但存在数据稀疏问题。</p><p id="6195" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">矩阵分解可以使用<a class="ae nj" href="https://medium.com/@m_n_malaeb/singular-value-decomposition-svd-in-recommender-systems-for-non-math-statistics-programming-4a622de653e9" rel="noopener"> SVD </a>来完成，但是它的计算量很大，并且扩展性不好。对于中等规模的数据集，<a class="ae nj" rel="noopener" target="_blank" href="/prototyping-a-recommender-system-step-by-step-part-2-alternating-least-square-als-matrix-4a76c58714a1"> ALS </a>可能是一个不错的选择。对于大型数据集，只有<a class="ae nj" rel="noopener" target="_blank" href="/overview-of-matrix-factorisation-techniques-using-python-8e3d118a9b39"> SGD </a>算法能够扩展，但总是需要相当大的计算能力。</p><p id="222e" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">一旦预先计算了用户的嵌入和项目的嵌入，就可以实时提供推荐。这种方法的另一个好处是，您可以使用它们的嵌入来了解更多关于用户和项目的信息。</p><p id="8c00" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">用户项目算法都有一个缺点，即在添加新项目或新用户后，没有有效的方法来更新嵌入。</p><p id="71d5" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">正如在个性化推荐场景中，新用户或新项目的引入可能导致<strong class="kh jj">冷启动问题</strong>，因为这些新条目上的数据不足以使协同过滤准确工作。为了给新用户做出适当的推荐，系统必须首先通过分析过去的投票或评级活动来学习用户的偏好。协同过滤系统要求大量用户在推荐新项目之前对该项目进行评级。</p><p id="7d82" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在下一篇文章中，我们将深入探讨两种主要类型的协同过滤系统:</p><ul class=""><li id="481e" class="lp lq ji kh b ki kj km kn kq lr ku ls ky lt lc lu lv lw lx bi translated"><a class="ae nj" href="http://e_Filtering" rel="noopener ugc nofollow" target="_blank">基于模型的</a>:使用不同的技术，如数据挖掘、机器学习算法来预测用户对未评级项目的评级。通常使用基于聚类的算法(k 近邻或 KNN)、矩阵分解技术(SVD)、概率分解或深度学习(神经网络)。</li><li id="f9dc" class="lp lq ji kh b ki ly km lz kq ma ku mb ky mc lc lu lv lw lx bi translated"><a class="ae nj" href="https://medium.com/@kyasar.mail/recommender-systems-memory-based-collaborative-filtering-methods-b5d58ca8383" rel="noopener">基于内存的</a>:使用用户评分数据计算相似度。它通常使用余弦或皮尔逊相关性来寻找相似性，并对评级进行加权平均。这种方法更容易解释，但是扩展性不好。</li></ul></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="0bf5" class="md me ji bd mf mg nr mi mj mk ns mm mn mo nt mq mr ms nu mu mv mw nv my mz na bi translated">基于内容</h1><p id="c97a" class="pw-post-body-paragraph kf kg ji kh b ki nc kk kl km nd ko kp kq ne ks kt ku nf kw kx ky ng la lb lc im bi translated">所有以前的模型都存在所谓的冷启动问题。</p><p id="a996" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">基于内容的过滤方法基于项目的描述和用户偏好的配置文件。这些方法最适合于已知项目数据(名称、位置、描述等)的情况。)，但不在用户身上。基于内容的推荐器将推荐视为特定于用户的分类问题，并根据产品特征学习用户喜欢和不喜欢的分类器。</p><p id="19bd" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在该系统中，使用关键字来描述项目，并且建立简档来指示该用户喜欢的项目类型。该算法试图推荐与用户过去喜欢的或者现在正在检查的项目相似的项目。这种方法源于信息检索和信息过滤研究。</p><p id="5c20" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">机器学习中模式识别的最新进展使得使用从图像或文本描述中提取的信息的基于内容的模型有了很大的改进。</p><p id="853f" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">该方法与之前的用户-用户或项目-项目算法相同，除了相似性是使用<strong class="kh jj">仅基于内容的特征</strong>计算的。</p><figure class="ll lm ln lo gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nw"><img src="../Images/670ee7ef5f6f40489746760948c3fdb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mz9tzP1LjPBhmiWXeHyQkQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">CF 与基于内容的过滤</p></figure></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="c07e" class="md me ji bd mf mg nr mi mj mk ns mm mn mo nt mq mr ms nu mu mv mw nv my mz na bi translated">个案研究</h1><p id="7633" class="pw-post-body-paragraph kf kg ji kh b ki nc kk kl km nd ko kp kq ne ks kt ku nf kw kx ky ng la lb lc im bi translated">对于以下案例研究，我们将使用 Python 和公共数据集。</p><p id="6e00" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">具体来说，我们将使用 GroupLens Research 收集的<a class="ae nj" href="https://grouplens.org/datasets/movielens/" rel="noopener ugc nofollow" target="_blank"> MovieLens </a>数据集。包含<a class="ae nj" href="https://grouplens.org/datasets/movielens/100k/" rel="noopener ugc nofollow" target="_blank"> MovieLens 100k 数据集</a>的文件是一个稳定的基准数据集，具有 943 个用户对 1682 部电影给出的 100，000 个评级，每个用户至少对 20 部电影进行了评级。</p><p id="76d5" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这个数据集由许多文件组成，这些文件包含关于电影、用户以及用户对他们所观看的电影的评级的信息。感兴趣的有以下几个:</p><ul class=""><li id="26d1" class="lp lq ji kh b ki kj km kn kq lr ku ls ky lt lc lu lv lw lx bi translated"><code class="fe nx ny nz oa b"><strong class="kh jj">u.item</strong></code> <strong class="kh jj"> : </strong>电影列表</li><li id="f097" class="lp lq ji kh b ki ly km lz kq ma ku mb ky mc lc lu lv lw lx bi translated"><code class="fe nx ny nz oa b"><strong class="kh jj">u.data</strong></code> <strong class="kh jj"> : </strong>用户给出的评分列表</li></ul><p id="0629" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">文件的前五行如下所示:</p><figure class="ll lm ln lo gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ob"><img src="../Images/d689f3bcfb4dc3fd3655be261aff1440.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*O1Mk8NDmYrsN7zBX.jpg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">来源:Kaggle。MovieLens 100k 数据集</p></figure><p id="0c59" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">该文件包含用户对特定电影的评价。该文件包含 100，000 个评级，将用于预测用户未观看的电影的评级。</p><h2 id="d7bc" class="oc me ji bd mf od oe dn mj of og dp mn kq oh oi mr ku oj ok mv ky ol om mz on bi translated">基于记忆的协同过滤</h2><p id="1532" class="pw-post-body-paragraph kf kg ji kh b ki nc kk kl km nd ko kp kq ne ks kt ku nf kw kx ky ng la lb lc im bi translated">在这种变化中，统计技术应用于整个数据集来计算预测。</p><p id="b133" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">为了找到用户<strong class="kh jj"> U </strong>将给予项目<strong class="kh jj"> I </strong>的评级<strong class="kh jj"> R </strong>，该方法包括:</p><ul class=""><li id="6d15" class="lp lq ji kh b ki kj km kn kq lr ku ls ky lt lc lu lv lw lx bi translated">正在查找与<strong class="kh jj"> U </strong>相似的用户，他们已经对项目<strong class="kh jj"> I </strong>进行了评级</li><li id="fc68" class="lp lq ji kh b ki ly km lz kq ma ku mb ky mc lc lu lv lw lx bi translated">根据上一步中找到的用户评分计算评分<strong class="kh jj"> R </strong></li></ul><p id="580b" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">考虑到每个用户都是一个向量，scikit 有一个函数可以计算每个向量的余弦距离。</p><pre class="ll lm ln lo gt oo oa op oq aw or bi"><span id="c04b" class="oc me ji oa b gy os ot l ou ov">&gt;&gt;&gt; from scipy import spatial<br/>&gt;&gt;&gt; a = [1, 2]<br/>&gt;&gt;&gt; b = [2, 4]<br/>&gt;&gt;&gt; c = [2.5, 4]<br/>&gt;&gt;&gt; d = [4.5, 5]<br/><br/>&gt;&gt;&gt; spatial.distance.cosine(c,a)<br/>0.004504527406047898<br/><br/>&gt;&gt;&gt; spatial.distance.cosine(c,b)<br/>0.004504527406047898<br/><br/>&gt;&gt;&gt; spatial.distance.cosine(c,d)<br/>0.015137225946083022<br/><br/>&gt;&gt;&gt; spatial.distance.cosine(a,b)<br/>0.0</span></pre><p id="9875" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">矢量<strong class="kh jj"> C </strong>和<strong class="kh jj"> A </strong>之间的较低角度给出了较低的余弦距离值。</p><p id="8133" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">注意，用户<strong class="kh jj"> A </strong>和<strong class="kh jj"> B </strong>在余弦相似性度量中被认为是绝对相似的，尽管具有不同的评级。这在现实世界中其实是常有的事，像用户<strong class="kh jj"> A </strong>这样的用户就是你所谓的<strong class="kh jj">强硬评分者</strong>。一个例子是一个电影评论家，他给出的评分总是低于平均水平，但他们列表中的项目的排名与平均评分者相似，如<strong class="kh jj"> B </strong>。</p><p id="26ab" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">为了考虑这种个人用户偏好，我们可以标准化评级以消除他们的偏见。我们可以通过从该用户评价的每个项目中减去该用户对所有项目给出的平均评价来做到这一点。</p><p id="05af" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">下面是这个<strong class="kh jj">正常化</strong>的样子:</p><ul class=""><li id="bc5a" class="lp lq ji kh b ki kj km kn kq lr ku ls ky lt lc lu lv lw lx bi translated">对于用户<strong class="kh jj"> A </strong>，评分向量<code class="fe nx ny nz oa b">[1, 2]</code>具有平均值<code class="fe nx ny nz oa b">1.5</code>。从每个评分中减去<code class="fe nx ny nz oa b">1.5</code>会得到向量<code class="fe nx ny nz oa b">[-0.5, 0.5]</code>。</li><li id="189c" class="lp lq ji kh b ki ly km lz kq ma ku mb ky mc lc lu lv lw lx bi translated">对于用户<strong class="kh jj"> B </strong>，评价向量<code class="fe nx ny nz oa b">[2, 4]</code>具有平均值<code class="fe nx ny nz oa b">3</code>。从每个评分中减去<code class="fe nx ny nz oa b">3</code>会得到向量<code class="fe nx ny nz oa b">[-1, 1]</code>。</li></ul><p id="7bcb" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">对用户<strong class="kh jj"> C </strong>和<strong class="kh jj"> D </strong>进行同样的操作，我们可以看到，评级现在被调整为所有用户的平均值为 0，这使他们处于相同的水平，并消除了他们的偏见。</p><p id="9d4f" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">调整后的向量之间的夹角余弦称为<strong class="kh jj">中心余弦</strong>。这种方法通常用在向量中有很多缺失值的时候，你需要放置一个公共值来填充缺失值。</p><p id="ed9c" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">填充缺失值的一个很好的选择可以是每个用户的平均评级，但是用户<strong class="kh jj"> A </strong>和<strong class="kh jj"> B </strong>的原始平均值分别是<code class="fe nx ny nz oa b">1.5</code>和<code class="fe nx ny nz oa b">3</code>，用<code class="fe nx ny nz oa b">1.5</code>填充<strong class="kh jj"> A </strong>的所有空值以及用<code class="fe nx ny nz oa b">3</code>填充<strong class="kh jj"> B </strong>的所有空值将使他们成为不同的用户。这个问题通过我们的归一化解决了，因为两个用户的以<strong class="kh jj">为中心的</strong>平均值是<code class="fe nx ny nz oa b">0</code>，这带来了所有缺失值都是<code class="fe nx ny nz oa b">0.</code>的想法</p><p id="e842" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在我们确定了一个类似于用户<strong class="kh jj"> U </strong>的用户列表后，我们就可以计算出<strong class="kh jj"> U </strong>会给某个项目<strong class="kh jj"> I </strong>的<strong class="kh jj"> R </strong>。我们可以通过多种方式做到这一点。</p><p id="af28" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们可以预测，用户对项目<strong class="kh jj"> I </strong>的评级<strong class="kh jj"> R </strong>将接近与<strong class="kh jj"> U </strong>最相似的前 5 名或前 10 名用户给予<strong class="kh jj"> I </strong>的评级的平均值。由<em class="lg"> n </em>用户给出的平均评分的数学公式如下:</p><figure class="ll lm ln lo gt iv gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/b706e697b75b6058f941abb2d26466ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/0*t_klo2W-7kcZc5Hm.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">N 个相似用户的平均评分</p></figure><p id="d0c6" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这个公式表明，n 个相似用户给出的平均评分等于他们给出的评分之和除以相似用户的数量，这是 n。</p><p id="0b85" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">会有这样的情况，你找到的<em class="lg"> n </em>个相似用户与目标用户<strong class="kh jj"> U </strong>不完全相似。他们中的前 3 名可能非常相似，其余的可能不像前 3 名那样与<strong class="kh jj"> U </strong>相似。在这种情况下，您可以考虑一种方法，其中最相似用户的评级比第二相似用户更重要，依此类推。加权平均可以帮助我们实现这一目标。</p><p id="6a38" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在加权平均方法中，您将每个评级乘以一个相似性因子(它表明用户有多相似)。通过乘以相似性因子，您可以为评级增加权重。权重越大，评级就越重要。</p><p id="6623" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">充当权重的相似性因子应该是上面讨论的距离的倒数，因为距离越小意味着相似性越高。例如，您可以从 1 中减去余弦距离来获得余弦相似度。</p><p id="88dd" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">利用与目标用户<strong class="kh jj"> U </strong>相似的每个用户的相似性因子<strong class="kh jj"> S </strong>，我们可以使用以下公式计算加权平均值:</p><figure class="ll lm ln lo gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ox"><img src="../Images/23b2df96b456100a8ce690fb1fa1bb3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*oZ-1hhGviXcURjPc.png"/></div></div></figure><p id="753d" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在上面的公式中，每个评级都乘以给出该评级的用户的相似性因子。用户<strong class="kh jj"> U </strong>的最终预测评级将等于加权评级的总和除以权重的总和。</p><p id="5ee5" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">通过加权平均，我们按照相似性的顺序更多地考虑相似用户的评级。</p><p id="d726" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这种技术是用户-用户 CF 的一个例子。如果我们使用评分矩阵根据用户给他们的评分来寻找相似的项目，那么这种方法就是项目-项目 CF。</p><p id="b1f4" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">但是，对于包含浏览或娱乐相关项目(如电影镜头)的数据集，项目-项目方法的性能很差。这种数据集使用矩阵分解技术会得到更好的结果，我们将在基于模型的 CF 部分看到这一点。</p><h2 id="bcdd" class="oc me ji bd mf od oe dn mj of og dp mn kq oh oi mr ku oj ok mv ky ol om mz on bi translated">基于模型的 CF</h2><p id="5d0b" class="pw-post-body-paragraph kf kg ji kh b ki nc kk kl km nd ko kp kq ne ks kt ku nf kw kx ky ng la lb lc im bi translated">在用户-项目矩阵中，有两个维度:</p><ol class=""><li id="3023" class="lp lq ji kh b ki kj km kn kq lr ku ls ky lt lc oy lv lw lx bi translated">用户数量</li><li id="aaa2" class="lp lq ji kh b ki ly km lz kq ma ku mb ky mc lc oy lv lw lx bi translated">项目的数量</li></ol><p id="1d88" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">如果矩阵大部分是空的(稀疏的)，降低维数可以在空间和时间两方面提高算法的性能。最常用的方法之一叫做矩阵分解。</p><p id="492e" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><strong class="kh jj">矩阵因式分解</strong>可以看作是将一个大矩阵分解成多个小矩阵的乘积。这类似于整数的因式分解，其中<code class="fe nx ny nz oa b">12</code>可以写成<code class="fe nx ny nz oa b">6 x 2</code>或<code class="fe nx ny nz oa b">4 x 3</code>。在矩阵的情况下，一个维数为<code class="fe nx ny nz oa b">m x n</code>的矩阵<strong class="kh jj"> A </strong>可以简化为两个维数分别为<code class="fe nx ny nz oa b">m x p</code>和<code class="fe nx ny nz oa b">p x n</code>的矩阵<strong class="kh jj"> X </strong>和<strong class="kh jj"> Y </strong>的乘积。</p><p id="9de0" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">根据用于维数缩减的算法，缩减矩阵的数量也可以多于两个。</p><p id="af60" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">简化的矩阵实际上分别代表用户和项目。第一个矩阵中的<strong class="kh jj"> m </strong>行代表<strong class="kh jj"> m </strong>用户，而<strong class="kh jj"> p </strong>列告诉您用户的特征或特性。具有<strong class="kh jj"> n </strong>个项目和<strong class="kh jj"> p </strong>个特性的项目矩阵也是如此。下面是矩阵分解的一个例子:</p><figure class="ll lm ln lo gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oz"><img src="../Images/655f062a80bb375b240f79500aadc7ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*K3MRD_OZ7gc4XKeT.jpg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">来源:维基百科(GNU)</p></figure><p id="baa6" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在上图中，矩阵被简化为两个矩阵。左边的是有<em class="lg"> m </em>个用户的用户矩阵，上面的是有<em class="lg"> n </em>个条目的条目矩阵。额定值<code class="fe nx ny nz oa b">4</code>被降低或分解为:</p><ol class=""><li id="016e" class="lp lq ji kh b ki kj km kn kq lr ku ls ky lt lc oy lv lw lx bi translated">用户向量<code class="fe nx ny nz oa b">(2, -1)</code></li><li id="d52c" class="lp lq ji kh b ki ly km lz kq ma ku mb ky mc lc oy lv lw lx bi translated">一个项目向量<code class="fe nx ny nz oa b">(2.5, 1)</code></li></ol><p id="1f08" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">用户矩阵中的两列和项目矩阵中的两行被称为潜在因素，并且是关于用户或项目的隐藏特征的指示。因子分解的一种可能解释如下:</p><ul class=""><li id="4a26" class="lp lq ji kh b ki kj km kn kq lr ku ls ky lt lc lu lv lw lx bi translated">假设在一个用户向量<code class="fe nx ny nz oa b">(u, v)</code>中，<code class="fe nx ny nz oa b">u</code>代表用户有多喜欢恐怖片，而<code class="fe nx ny nz oa b">v</code>代表他们有多喜欢言情片。</li><li id="82fd" class="lp lq ji kh b ki ly km lz kq ma ku mb ky mc lc lu lv lw lx bi translated">因此，用户向量<code class="fe nx ny nz oa b">(2, -1)</code>表示喜欢恐怖电影并对其进行正面评价，不喜欢浪漫电影并对其进行负面评价的用户。</li><li id="3715" class="lp lq ji kh b ki ly km lz kq ma ku mb ky mc lc lu lv lw lx bi translated">假设在一个项目向量<code class="fe nx ny nz oa b">(i, j)</code>中，<code class="fe nx ny nz oa b">i</code>表示一部电影有多少属于恐怖片，而<code class="fe nx ny nz oa b">j</code>表示那部电影有多少属于言情片。</li><li id="284b" class="lp lq ji kh b ki ly km lz kq ma ku mb ky mc lc lu lv lw lx bi translated">电影<code class="fe nx ny nz oa b">(2.5, 1)</code>恐怖评分<code class="fe nx ny nz oa b">2.5</code>，浪漫评分<code class="fe nx ny nz oa b">1</code>。使用矩阵乘法规则乘以用户向量得到<code class="fe nx ny nz oa b">(2 * 2.5) + (-1 * 1) = 4</code>。</li><li id="faff" class="lp lq ji kh b ki ly km lz kq ma ku mb ky mc lc lu lv lw lx bi translated">所以，这部电影属于恐怖片类型，用户本来可以给它评分<code class="fe nx ny nz oa b">5</code>，但是稍微加入了言情片就导致最终评分降到了<code class="fe nx ny nz oa b">4</code>。</li></ul><p id="8c17" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">因素矩阵可以提供关于用户和项目的洞察，但实际上，它们通常要复杂得多。这些因素的数量可以是从一个到数百个甚至数千个。这个数字是模型训练过程中需要优化的东西之一。</p><p id="ae21" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在这个例子中，你有两个电影类型的潜在因素，但是在真实的场景中，这些潜在因素不需要太多的分析。这些是数据中的模式，无论你是否理解它们的潜在含义，它们都会自动发挥作用。</p><p id="abc4" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">潜在因素的数量以这样的方式影响推荐，其中因素的数量越多，推荐变得越个性化。但是太多的因素会导致模型中的过度拟合。</p><pre class="ll lm ln lo gt oo oa op oq aw or bi"><span id="c845" class="oc me ji oa b gy os ot l ou ov"># load_data.py<br/><br/>import pandas as pd<br/>from surprise import Dataset<br/>from surprise import Reader<br/><br/># This is the same data that was plotted for similarity earlier<br/># with one new user "E" who has rated only movie 1<br/>ratings_dict = {<br/>    "item": [1, 2, 1, 2, 1, 2, 1, 2, 1],<br/>    "user": ['A', 'A', 'B', 'B', 'C', 'C', 'D', 'D', 'E'],<br/>    "rating": [1, 2, 2, 4, 2.5, 4, 4.5, 5, 3],<br/>}<br/><br/>df = pd.DataFrame(ratings_dict)<br/>reader = Reader(rating_scale=(1, 5))<br/><br/># Loads Pandas dataframe<br/>data = Dataset.load_from_df(df[["user", "item", "rating"]], reader)<br/># Loads the builtin Movielens-100k data<br/>movielens = Dataset.load_builtin('ml-100k')</span></pre><h2 id="5815" class="oc me ji bd mf od oe dn mj of og dp mn kq oh oi mr ku oj ok mv ky ol om mz on bi translated">k 近邻和矩阵分解。</h2><p id="73ce" class="pw-post-body-paragraph kf kg ji kh b ki nc kk kl km nd ko kp kq ne ks kt ku nf kw kx ky ng la lb lc im bi translated">惊喜库有很多算法我们可以很轻松的使用，k-NN。</p><pre class="ll lm ln lo gt oo oa op oq aw or bi"><span id="450b" class="oc me ji oa b gy os ot l ou ov"># recommender.py<br/><br/>from surprise import KNNWithMeans<br/><br/># To use item-based cosine similarity<br/>sim_options = {<br/>    "name": "cosine",<br/>    "user_based": False,  # Compute  similarities between items<br/>}<br/>algo = KNNWithMeans(sim_options=sim_options)</span></pre><p id="b128" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们可以用 k-NN 来训练和预测。</p><pre class="ll lm ln lo gt oo oa op oq aw or bi"><span id="b1e3" class="oc me ji oa b gy os ot l ou ov">&gt;&gt;&gt; from load_data import data<br/>&gt;&gt;&gt; from recommender import algo<br/><br/>&gt;&gt;&gt; trainingSet = data.build_full_trainset()<br/><br/>&gt;&gt;&gt; algo.fit(trainingSet)<br/>Computing the cosine similarity matrix...<br/>Done computing similarity matrix.<br/>&lt;surprise.prediction_algorithms.knns.KNNWithMeans object at 0x7f04fec56898&gt;<br/><br/>&gt;&gt;&gt; prediction = algo.predict('E', 2)<br/>&gt;&gt;&gt; prediction.est<br/>4.15</span></pre><p id="d256" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">最后，我们可以微调超参数和均方根误差。</p><pre class="ll lm ln lo gt oo oa op oq aw or bi"><span id="beb1" class="oc me ji oa b gy os ot l ou ov">from surprise import KNNWithMeans<br/>from surprise import Dataset<br/>from surprise.model_selection import GridSearchCV<br/><br/>data = Dataset.load_builtin("ml-100k")<br/>sim_options = {<br/>    "name": ["msd", "cosine"],<br/>    "min_support": [3, 4, 5],<br/>    "user_based": [False, True],<br/>}<br/><br/>param_grid = {"sim_options": sim_options}<br/><br/>gs = GridSearchCV(KNNWithMeans, param_grid, measures=["rmse", "mae"], cv=3)<br/>gs.fit(data)<br/><br/>print(gs.best_score["rmse"])<br/>print(gs.best_params["rmse"])</span></pre><h2 id="ae5b" class="oc me ji bd mf od oe dn mj of og dp mn kq oh oi mr ku oj ok mv ky ol om mz on bi translated">奇异值分解推荐器</h2><p id="b471" class="pw-post-body-paragraph kf kg ji kh b ki nc kk kl km nd ko kp kq ne ks kt ku nf kw kx ky ng la lb lc im bi translated">作为一种变化，我们可以使用 SVD 而不是 k-NN 来运行推荐算法。</p><pre class="ll lm ln lo gt oo oa op oq aw or bi"><span id="0417" class="oc me ji oa b gy os ot l ou ov">from surprise import SVD<br/>from surprise import Dataset<br/>from surprise.model_selection import GridSearchCV<br/><br/>data = Dataset.load_builtin("ml-100k")<br/><br/>param_grid = {<br/>    "n_epochs": [5, 10],<br/>    "lr_all": [0.002, 0.005],<br/>    "reg_all": [0.4, 0.6]<br/>}<br/>gs = GridSearchCV(SVD, param_grid, measures=["rmse", "mae"], cv=3)<br/><br/>gs.fit(data)<br/><br/>print(gs.best_score["rmse"])<br/>print(gs.best_params["rmse"])</span></pre><p id="6e19" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">上述程序的输出如下:</p><pre class="ll lm ln lo gt oo oa op oq aw or bi"><span id="4ee7" class="oc me ji oa b gy os ot l ou ov">0.9642278631521038<br/>{'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.4}</span></pre><h1 id="43b7" class="md me ji bd mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na bi translated">参考</h1><p id="460c" class="pw-post-body-paragraph kf kg ji kh b ki nc kk kl km nd ko kp kq ne ks kt ku nf kw kx ky ng la lb lc im bi translated">Suresh Chandra Satapathy，Vikrant Bhateja，Amit Joshi。数据工程和通信技术国际会议论文集。2016.</p><div class="is it gp gr iu pa"><a href="https://realpython.com/build-recommendation-engine-collaborative-filtering/" rel="noopener  ugc nofollow" target="_blank"><div class="pb ab fo"><div class="pc ab pd cl cj pe"><h2 class="bd jj gy z fp pf fr fs pg fu fw jh bi translated">用协同过滤构建推荐引擎——Real Python</h2><div class="ph l"><h3 class="bd b gy z fp pf fr fs pg fu fw dk translated">在本教程中，您将了解到协同过滤，这是最常见的构建…</h3></div><div class="pi l"><p class="bd b dl z fp pf fr fs pg fu fw dk translated">realpython.com</p></div></div><div class="pj l"><div class="pk l pl pm pn pj po ja pa"/></div></div></a></div><p id="e34c" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><a class="ae nj" href="https://en.wikipedia.org/wiki/Loren_Terveen" rel="noopener ugc nofollow" target="_blank">特维恩，洛伦</a>；希尔，威尔(2001)。<a class="ae nj" href="http://www.grouplens.org/papers/pdf/rec-sys-overview.pdf" rel="noopener ugc nofollow" target="_blank">《超越推荐系统:帮助人们互相帮助》</a>。艾迪森-韦斯利。第 6 页。</p><p id="dbfc" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">Badrul Sarwar、George Karypis、Joseph Konstan 和 John Riedl (2001 年)。<a class="ae nj" href="http://files.grouplens.org/papers/www10_sarwar.pdf" rel="noopener ugc nofollow" target="_blank">【基于项目的协同过滤推荐算法】</a>。GroupLens 研究小组/陆军 HPC 研究中心。第一篇发表在基于项目的推荐器上的论文。</p><p id="c0ac" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">大卫 a .戈德堡，大卫 a .尼科尔斯，道格拉斯 b .特里。<a class="ae nj" href="https://scinapse.io/papers/1966553486" rel="noopener ugc nofollow" target="_blank">“用协同过滤编织信息织锦”</a>。ACM 的通信。1991.术语协同过滤的首次使用。</p><p id="f2ea" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">库<a class="ae nj" href="https://github.com/lyst/lightfm" rel="noopener ugc nofollow" target="_blank">light FM</a><strong class="kh jj">:</strong>Python 中的一种混合推荐算法。</p><p id="3fd4" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">库<a class="ae nj" href="https://github.com/ocelma/python-recsys" rel="noopener ugc nofollow" target="_blank"> Python-recsys </a>:用于实现推荐系统的 Python 库。</p><p id="feea" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">库<a class="ae nj" href="https://github.com/NicolasHug/Surprise" rel="noopener ugc nofollow" target="_blank">惊喜</a>:Python scikit 构建和分析推荐系统，处理显式评级数据。</p><p id="4880" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">Aggarwal，Charu C. (2016 年)。<em class="lg">推荐系统:教科书</em>。斯普林格。</p><p id="e217" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">彼得·布鲁斯洛夫斯基(2007 年)。"<em class="lg">自适应网络</em>"第 325 页。</p><p id="5bc2" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">Aditya，p .和 Budi，Indra 和 Munajat，Qorib。(2016).“基于记忆和基于模型的协同过滤在印度尼西亚电子商务推荐系统实施中的比较分析:案例研究第十卷”。第 303-308 页</p><p id="488c" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">InCubeGroup。<a class="ae nj" href="https://www.incubegroup.com/blog/recommender-system-for-private-banking/" rel="noopener ugc nofollow" target="_blank">私人银行推荐系统</a>。参考 2020 年 3 月 18 日。</p></div></div>    
</body>
</html>