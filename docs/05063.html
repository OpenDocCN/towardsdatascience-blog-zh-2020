<html>
<head>
<title>Simple Machine Learning Pipeline</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">简单的机器学习管道</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/simple-machine-learning-pipeline-770eb3f08a2d?source=collection_archive---------41-----------------------#2020-05-01">https://towardsdatascience.com/simple-machine-learning-pipeline-770eb3f08a2d?source=collection_archive---------41-----------------------#2020-05-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="85cf" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">将所有必要的部分结合在一起，构建一个简单而强大的机器学习管道。这将包括Keras/TensorFlow模型训练、测试、自动再训练和REST API</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c3117c29a2e369a65c1f2158aa0b3ac7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VlI_8DRDhU6ng5xMpV_kEQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://pixabay.com/users/alexei_other-9114223/" rel="noopener ugc nofollow" target="_blank"> Alexei_other </a>在<a class="ae ky" href="https://pixabay.com/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>上的照片</p></figure><p id="fc5e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我将涵盖多个主题，并解释如何建立机器学习管道。什么是ML管道？这是一个帮助自动重新训练ML模型并通过API使其可用的解决方案。重新训练间隔可以通过调度程序配置，模型可以每天或以任何其他选定的间隔更新。</p><p id="6f2f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">解决方案的简要架构:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/a522128a67a6a82ad8a827e589f07bb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nqTFp3M4ASHuEl_xYmaUxA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">简单的ML管道(作者:Andrej Baranovskij)</p></figure><p id="02eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我正在使用Keras构建一个模型，它可以计算企业报表生成的等待时间。时间是根据报告ID、报告参数和日部分计算的。有一个常见的规则，即模型在培训期间获得的规则，即报表运行速度较慢，参数较少，并且在一天的第二部分。</p><p id="4434" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">训练Keras模型的Python函数是获取数据，处理数据，然后调用Keras API来拟合模型。模型训练分十次进行，以选出最佳结果。最佳结果是根据模型评估结果和测试数据选择的，稍后会详细介绍。新模型是使用时间戳保存的，这使得如果有任何活动的调用同时发生，当前模型仍然可以得到服务(或者可能一些用户仍然喜欢调用以前的模型，这增加了额外的灵活性)。</p><p id="8188" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从<a class="ae ky" href="https://apscheduler.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank">日程安排器</a>执行模型再训练。我使用后台调度程序选项，这允许我们将它与REST API进程一起运行(我使用PM2来运行Python进程)。这使得控制更加简单，并且当重新训练任务运行时，REST API调用不会被阻塞。</p><p id="ce66" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">REST API使用<a class="ae ky" href="https://flask.palletsprojects.com/en/1.1.x/" rel="noopener ugc nofollow" target="_blank"> Flask </a>库运行。模型预测函数是通过用tf.keras.models.load_model API加载最新的可用模型，并在其上调用预测函数来执行的。</p><p id="0f70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">型号</strong></p><p id="1501" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">模型逻辑在<em class="lw">report _ exec _ time _ model . py</em>中实现。</p><p id="8991" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">函数<strong class="lb iu"> <em class="lw"> fetch_data </em> </strong>从CSV中读取数据。在本例中，它总是读取相同的数据(出于简单的原因)，但是在实际实现中，对于每次重新训练，您很可能会读取新的数据。获取训练和测试数据集。对于<em class="lw">报告参数</em>特性，训练数据包含0–10个值，测试数据包含11–20个值。这是故意的，我们正在用训练中不知道的数据进行测试。这将允许我们检查模型是否能够获得正确的趋势——执行时间应该随着更多的报告参数而减少。特征<em class="lw">报告参数</em>通过计算log进行归一化，使值更小，从而帮助模型更好地学习它。这同样适用于训练和测试数据集。20%的训练数据用于验证。数据结构:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/9d7074e3d06f72e21f713b74f2f8f626.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*3r-5cTzncK0mOA6WBWOOUg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">截图作者:Andrej Baranovskij</p></figure><p id="9c1d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lw">报告参数</em>的测试数据来自不同的集合，并且在规模上不同于训练集合，但是使用log可以通过相同的规则标准化不同集合中的数据:</p><pre class="kj kk kl km gt ly lz ma mb aw mc bi"><span id="4a6c" class="md me it lz b gy mf mg l mh mi"><em class="lw"># Normalize training feature - report_params</em><br/>eps=0.001<br/>dataframe['report_params'] = np.log(dataframe.pop('report_params') +eps)<br/>normed_df = dataframe</span></pre><p id="46ed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">函数<strong class="lb iu"><em class="lw">build _ feature _ layer</em></strong>定义张量流特征层。这是一个元数据层，有助于将数据自动转换为可用于训练算法的格式。特征<em class="lw">报告ID </em>和<em class="lw">日部分</em>是分类的。这两个特征都使用TensorFlow分类特征支持编码为指示器列。<em class="lw">报表参数</em>特性被定义为数值列。所有三列都定义为TensorFlow要素图层-这允许转换数据而无需额外的自定义处理:</p><pre class="kj kk kl km gt ly lz ma mb aw mc bi"><span id="9d82" class="md me it lz b gy mf mg l mh mi">feature_columns = []<br/><br/>report_id = feature_column.categorical_column_with_vocabulary_list('report_id', [1, 2, 3, 4, 5])<br/>report_id_one_hot = feature_column.indicator_column(report_id)<br/>feature_columns.append(report_id_one_hot)<br/><br/>    feature_columns.append(feature_column.numeric_column('report_params'))<br/><br/>day_part = feature_column.categorical_column_with_vocabulary_list('day_part', [1, 2, 3])<br/>day_part_one_hot = feature_column.indicator_column(day_part)<br/>feature_columns.append(day_part_one_hot)<br/>    <br/>feature_layer = tf.keras.layers.DenseFeatures(feature_columns)</span></pre><p id="1aae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">函数<strong class="lb iu"><em class="lw">build _ dataset</em></strong>将熊猫数据转换为TensorFlow数据集。这种数据集可以直接发送到Keras模型训练:</p><pre class="kj kk kl km gt ly lz ma mb aw mc bi"><span id="5af4" class="md me it lz b gy mf mg l mh mi">batch_size = 16</span><span id="f9b0" class="md me it lz b gy mj mg l mh mi">train_ds = df_to_dataset(train, shuffle=<strong class="lz iu">False</strong>,batch_size=batch_size)<br/>val_ds = df_to_dataset(val, shuffle=<strong class="lz iu">False</strong>, batch_size=batch_size)<br/>test_ds = df_to_dataset(normed_df_test, shuffle=<strong class="lz iu">False</strong>, batch_size = batch_size)</span></pre><p id="c307" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我用的是批量= 16。根据我的测试，这是在给定数据的模型训练期间找到最佳拟合的最佳批次。我们不需要打乱训练数据，在分成训练集和验证集的过程中已经打乱了。</p><p id="2f6b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">函数<strong class="lb iu"> <em class="lw"> build_model </em> </strong>构建顺序Keras模型。该模型接受第一层——要素层(要素列表及其表示方式)。不需要指定输入维度。有三层，第三层是输出层(一个单位/神经元)。前两层分别设置16和8个单元/神经元和<em class="lw"> relu </em>激活。通过试验不同的设置来选择层和单元的数量。</p><pre class="kj kk kl km gt ly lz ma mb aw mc bi"><span id="73ec" class="md me it lz b gy mf mg l mh mi">model = tf.keras.Sequential([<br/>        feature_layer,<br/>        layers.Dense(16, activation='relu'),<br/>        layers.Dense(8, activation='relu'),<br/>        layers.Dense(1)<br/>    ])</span><span id="2d5e" class="md me it lz b gy mj mg l mh mi">optimizer = tf.keras.optimizers.RMSprop(0.001)<br/><br/>model.compile(loss='mse',<br/>              optimizer=optimizer,<br/>              metrics=['mae', 'mse'])</span></pre><p id="208a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该模型是在<strong class="lb iu"> <em class="lw"> train_model </em> </strong>功能中训练的。从零开始反复训练十次。结果保存了最佳模型。模型以TensorFlow格式保存。训练循环完成后，最佳模型被复制到API端点可访问的部署文件夹中。每个新模型都存储有时间戳，这允许实现模型版本控制。训练配置为提前停止回调，当10个周期没有改善时，训练停止。使用TensorFlow数据集的模型训练:</p><pre class="kj kk kl km gt ly lz ma mb aw mc bi"><span id="c0c2" class="md me it lz b gy mf mg l mh mi">EPOCHS = 1000<br/><em class="lw"># The patience parameter is the amount of epochs to check <br/># for improvement</em><br/>early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)<br/>        <br/>history = model.fit(train_ds,<br/>                      validation_data=val_ds,<br/>                      epochs=EPOCHS,<br/>                      verbose=0,<br/>                      callbacks=[early_stop])</span></pre><p id="b01d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">保存最佳模型。基于测试集评估模型。我将报表参数大于10的数据包含在测试集中，以便能够测试回归如何作用于看不见的数据。模型应该在训练过程中选择一个规则—报表参数越多，执行时间应该越短。我很高兴看到那个模特实际上正确地学习了这条规则:</p><pre class="kj kk kl km gt ly lz ma mb aw mc bi"><span id="febf" class="md me it lz b gy mf mg l mh mi">loss, mae, mse = model.evaluate(test_ds, verbose=0)</span><span id="ff5d" class="md me it lz b gy mj mg l mh mi">rmse = math.sqrt(mse)<br/>print("Testing set RMSE Error:<strong class="lz iu">{:5.2f}</strong>".format(math.sqrt(mse)))<br/><strong class="lz iu">if</strong> rmse &lt; best_rmse:<br/>    print("Saving model with RMSE Error <strong class="lz iu">{:5.2f}</strong>".format(math.sqrt(mse)))<br/>    model.save('./model_exec_time_temp/', save_format='tf')<br/>            <br/>    best_history = history<br/>    best_rmse = rmse</span></pre><p id="19d5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将最佳模型复制到API可访问的目录中，以及用于版本控制的时间戳值:</p><pre class="kj kk kl km gt ly lz ma mb aw mc bi"><span id="52af" class="md me it lz b gy mf mg l mh mi">ts = calendar.timegm(time.gmtime())<br/>print('Creating new model:', ts)<br/>copyDirectory('./model_exec_time_temp/', './model_exec_time/' + str(ts))</span></pre><p id="bdaf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是RMSE = 8.02秒的模型训练结果(这意味着在计算测试集数据的报告执行时间时出现约8秒的误差)。我们可以看到，在提前停止回调终止训练之前，大约需要100个时期:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mk"><img src="../Images/4fc8c5459df0f7a3b494317f45b71a0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kQP60ROp_Gv5uHbBYUacFg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">截图作者:Andrej Baranovskij</p></figure><p id="4401" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">函数<strong class="lb iu"> <em class="lw"> run_predict </em> </strong>接受输入数据进行推理，加载最新的可用模型，执行预测调用。</p><p id="645b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">终点</strong></p><p id="66a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">端点逻辑在<em class="lw">report _ exec _ time _ endpoint . py</em>中实现</p><p id="b4d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这个脚本中，我实现了重新训练调度器和REST API。重新训练在后台线程中运行，这允许保持REST API运行而不会阻塞。</p><p id="a0e4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">计划程序被配置为每天运行一次，但是重新训练的时间间隔由您决定。当新数据可用时，重新训练是有意义的:</p><pre class="kj kk kl km gt ly lz ma mb aw mc bi"><span id="5ee2" class="md me it lz b gy mf mg l mh mi"># create scheduler<br/>scheduler = BackgroundScheduler()<br/>scheduler.start()</span><span id="698b" class="md me it lz b gy mj mg l mh mi"># Using UTC time to schedule job, once per day.<br/>scheduler.add_job(<br/>    func=report_model.train_model,<br/>    trigger='cron',<br/>    hour='9', <br/>    minute='45')</span></pre><p id="c2a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">REST API通过<a class="ae ky" href="https://flask.palletsprojects.com/en/1.1.x/" rel="noopener ugc nofollow" target="_blank"> Flask </a>实现。请求参数被发送用于推理到模型中(自动从调度器中挑选出最佳的最新模型，或者你可以基于模型版本化实现其他逻辑)预测方法，结果被返回给客户端:</p><pre class="kj kk kl km gt ly lz ma mb aw mc bi"><span id="a936" class="md me it lz b gy mf mg l mh mi">app = Flask(__name__)<br/>CORS(app)</span><span id="4ac2" class="md me it lz b gy mj mg l mh mi"><a class="ae ky" href="http://twitter.com/app" rel="noopener ugc nofollow" target="_blank">@app</a>.route("/katana-ml/api/v1.0/predict/reporttime", methods=['POST'])<br/>def predict():<br/>    report_id = request.json['report_id']<br/>    report_params = request.json['report_params']<br/>    day_part = request.json['day_part']<br/>    <br/>    input_data = [[report_id, report_params, day_part]]<br/>    result = report_model.run_predict(input_data)<br/>    <br/>    return str(result[0][0])</span><span id="559e" class="md me it lz b gy mj mg l mh mi"># running REST interface port=3000<br/>if __name__ == "__main__":<br/>    app.run(debug=False, host='0.0.0.0', port=3000)</span></pre><p id="ef4a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们来验证一下模型。以来自模型训练集的数据为例(报告ID、报告参数、日部分=时间):</p><pre class="kj kk kl km gt ly lz ma mb aw mc bi"><span id="1179" class="md me it lz b gy mf mg l mh mi">1, 10, 3 = 440</span></pre><p id="7bc4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">用15个报表参数做推断。正如所料，执行时间更短= 429，这意味着模型训练正确:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ml"><img src="../Images/2148bb3855a5cd21bfd9f7a905e84ffe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ly96mmeOnEFvkOlFKgXONw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">截图作者:Andrej Baranovskij</p></figure><p id="9eb0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果有11个报告参数，执行时间会稍微长一点，这是应该的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mm"><img src="../Images/f9195db3dd462e25268c44fcacee7666.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p7oB9VbrNThb6JBri1v4Og.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">截图作者:Andrej Baranovskij</p></figure><p id="cafe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以尝试不同的报告ID和日部分值，看看执行时间计算是如何变化的。</p><p id="7409" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">部署</strong></p><p id="84c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Python端点进程正在使用<a class="ae ky" href="https://pm2.keymetrics.io/" rel="noopener ugc nofollow" target="_blank"> PM2 </a>管理器运行。用PM2命令启动进程:</p><pre class="kj kk kl km gt ly lz ma mb aw mc bi"><span id="b453" class="md me it lz b gy mf mg l mh mi">pm2 start report_exec_time_endpoint.py</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mn"><img src="../Images/e60fcde9a1f09a142e315096d71fec16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wSBBNu18BLpphG1rv6Q4Eg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">截图作者:Andrej Baranovskij</p></figure><p id="0255" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">结论</strong></p><p id="4ccd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">希望本文描述的信息能够帮助您在生产中运行可扩展的机器学习管道。我认为核心部分是一个自动化的重新训练选项，这有助于在新数据可用时保持模型更新。在单独的线程中运行预定的再训练的能力允许我们在与API端点相同的过程中管理它。这使得管道更简单，更易于维护。</p><p id="2645" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">源代码</strong> : <a class="ae ky" href="https://github.com/abaranovskis-redsamurai/automation-repo/tree/master/pipeline" rel="noopener ugc nofollow" target="_blank"> GitHub </a> repo。</p></div></div>    
</body>
</html>