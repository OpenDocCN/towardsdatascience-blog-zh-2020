<html>
<head>
<title>A Practical Machine Learning Guide</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">实用机器学习指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-practical-machine-learning-guide-fa2111c65f42?source=collection_archive---------42-----------------------#2020-09-06">https://towardsdatascience.com/a-practical-machine-learning-guide-fa2111c65f42?source=collection_archive---------42-----------------------#2020-09-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="27ba" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">从 EDA 到模型评估的银行客户流失预测。</h2></div><p id="86f3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">流失预测是机器学习领域的一个常见用例。如果你不熟悉这个术语，churn 的意思是“离开公司”。对于一个企业来说，了解客户可能流失的原因和时间是非常重要的。拥有一个强大而准确的客户流失预测模型有助于企业采取措施防止客户离开公司。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/9692dbfc8ee4a29edecb4dca640a85bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3dFMVorIgdsnOfBi.jpeg"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">克里斯·利维拉尼在<a class="ae lu" href="https://unsplash.com/s/photos/customer?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="547c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这篇文章中，我们的目标是建立一个监督学习算法来执行分类任务。目标是使用提供的功能预测客户是否会流失(即退出= 1)。数据集可在 Kaggle 上的<a class="ae lu" href="https://www.kaggle.com/sonalidasgupta95/churn-prediction-of-bank-customers" rel="noopener ugc nofollow" target="_blank">这里</a>获得。</p><p id="e405" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第一步是将数据集读入熊猫数据帧。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="13f3" class="ma mb it lw b gy mc md l me mf">import pandas as pd<br/>import numpy as np</span><span id="1625" class="ma mb it lw b gy mg md l me mf">df_churn = pd.read_csv("/content/Churn_Modelling.csv")</span><span id="3be0" class="ma mb it lw b gy mg md l me mf">df_churn.shape<br/>(10000, 14)</span><span id="660f" class="ma mb it lw b gy mg md l me mf">df_churn.columns<br/>Index(<br/>['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography','Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard','IsActiveMember', 'EstimatedSalary', 'Exited'],       dtype='object')</span></pre><p id="7fbf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">数据集包含 10000 个客户(即行)和关于银行客户及其产品的 14 个特征。</p></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><h1 id="8397" class="mo mb it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated"><strong class="ak">探索数据</strong></h1><p id="0225" class="pw-post-body-paragraph ki kj it kk b kl nf ju kn ko ng jx kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">有一些多余的功能。“RowNumber”列只是一个索引。“客户 Id”和“姓氏”列对于机器学习模型来说显然是无用的。客户的姓氏或 ID 不会告诉我们任何关于客户流失的信息。因此，我们应该删除它们，以免给模型带来不必要的计算负担。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="9e46" class="ma mb it lw b gy mc md l me mf">df_churn.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, inplace=True)</span><span id="c1fd" class="ma mb it lw b gy mg md l me mf">df_churn.head()</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nk"><img src="../Images/6cbf8b03b917942bd1daf73a1c378bcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ba9JpIPqyXRO-XO9o67n7A.png"/></div></div></figure><p id="e719" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们还要检查数据集中是否有任何缺失值。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="68d1" class="ma mb it lw b gy mc md l me mf">df_churn.isna().sum()</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/3c7b7472293c7cbf7587266e2796bb2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*h704hZDMQLdLOkd1CWmnIw.png"/></div></figure><p id="918b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该数据集没有任何缺少的值，这在现实生活的数据集中是不常见的。<a class="ae lu" rel="noopener" target="_blank" href="/handling-missing-values-with-pandas-b876bf6f008f">处理缺失值</a>是机器学习流水线的重要组成部分。如果与数据集的大小相比，缺少的值非常少，我们可以选择删除缺少值的行。否则，最好用合适的值替换它们。Pandas <strong class="kk iu"> fillna </strong>函数可以用来处理这个任务。</p><p id="2663" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">重要说明:</strong>如果您选择基于列中的非缺失值估算缺失值(例如，用列的平均值填充缺失值)，您应该在将数据集拆分为训练和测试子集后执行此操作。否则，您会将测试集中的数据泄露给机器学习模型，这些数据应该是新的、以前未见过的数据。</p><p id="7abb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们还应该确保数据以适当的数据类型存储。例如，数值不应该存储为“对象”。<strong class="kk iu"> Dtypes </strong>函数返回每一列的数据类型。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="34e6" class="ma mb it lw b gy mc md l me mf">df_churn.dtypes</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/a56b5da8fc5f16bc65860c666839eee5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*FsyM5YciWH6ncmgbQ5pvsQ.png"/></div></figure><p id="0af1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">数据类型似乎是合适的。</p><p id="5bda" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们永远不应该只是将原始数据转储到机器学习模型中。垃圾进，垃圾出！这就是为什么我们需要探索数据集并理解特征和目标之间的关系。</p><p id="baff" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">地理和性别特征可能会对客户流失产生影响。一种方法是使用熊猫的<strong class="kk iu"> groupby </strong>功能。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="d1c6" class="ma mb it lw b gy mc md l me mf">df_churn[['Geography','Gender','Exited']].groupby(['Geography','Gender']).agg(['mean','count'])</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/84f8140c868f73d22d3b5db94b3aa2f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*3nOFZR38ZcNTMRkJPF-93A.png"/></div></figure><p id="2894" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">发现</strong>:在这三个国家，女性比男性更容易跳槽。</p><p id="173e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">发现</strong>:德国的流失率高于其他两个国家的流失率。法国的顾客最多。</p><p id="94b0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们看看客户的年龄与流失率之间的关系。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="cf18" class="ma mb it lw b gy mc md l me mf">plt.figure(figsize=(10,6))</span><span id="2a58" class="ma mb it lw b gy mg md l me mf">sns.catplot(x='Exited', y='Age', hue='Gender', data=df_churn)</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi no"><img src="../Images/5c62da08a76b1f3d801338c946c4fff7.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*AFYj1WmKaV7Ouf-ZVDT3qw.png"/></div></figure><p id="ef9c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">就客户流失而言，年龄不会造成非常显著的差异。然而，在不流失(退出=0)的一方有更多的老年人。我们还应该检查年龄栏的分布。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="0a18" class="ma mb it lw b gy mc md l me mf">plt.figure(figsize=(10,6))</span><span id="a9f7" class="ma mb it lw b gy mg md l me mf">sns.distplot(df_churn['Age'], hist=False)</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi np"><img src="../Images/810a67b922103d437707377e987c6445.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*023Z1ERqqxIGWl36BdLYzQ.png"/></div></figure><p id="ee06" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">分布是右偏的，这表明异常值在右侧。这在规范化特征时很重要。我们会谈到这一点。</p><p id="4251" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">任期，即客户成为客户的时间，也可能是客户流失的一个指示性因素。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="ec9e" class="ma mb it lw b gy mc md l me mf">df_churn[['Tenure','Exited']].groupby('Tenure').agg(['mean','count']).sort_values(by=[('Exited','mean')])</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/e5650541a300bbc2d5a347d6596f08e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*UGry60UX9bze5GRK50HHkA.png"/></div></figure><p id="e6d6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在任期和流失之间没有一个容易识别的模式。</p><p id="4d98" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">相关矩阵通过提供成对的相关值，为我们提供了变量之间关系的概述。它只接受数值。因此，最好将“地理”和“性别”列中的类别转换为数字类别。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="b597" class="ma mb it lw b gy mc md l me mf">gender = {'Female':0, 'Male':1}</span><span id="62d6" class="ma mb it lw b gy mg md l me mf">country = {'France':0, 'Germany':1, 'Spain':2}</span><span id="1f35" class="ma mb it lw b gy mg md l me mf">df_churn['Gender'].replace(gender, inplace=True)</span><span id="a6a8" class="ma mb it lw b gy mg md l me mf">df_churn['Geography'].replace(country, inplace=True)</span><span id="275c" class="ma mb it lw b gy mg md l me mf">df_churn.head()</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nr"><img src="../Images/246ad8dc9e10cc48de317313877074d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LSORaUGcA13EBR6mWz0XLg.png"/></div></div></figure><p id="46bd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">pandas 的<strong class="kk iu"> corr </strong>功能创建了一个关联矩阵，然后可以用<strong class="kk iu">热图</strong>可视化。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="d4cc" class="ma mb it lw b gy mc md l me mf">corr_matrix = df_churn.corr()</span><span id="c57b" class="ma mb it lw b gy mg md l me mf">plt.figure(figsize=(12,8))</span><span id="e019" class="ma mb it lw b gy mg md l me mf">sns.heatmap(corr_matrix, cmap='Blues_r', annot=True)</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ns"><img src="../Images/804a9df85ea24061d64a76c9d9898d6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vFENg5YCmCK-hTfTWGQbCQ.png"/></div></div></figure><p id="1608" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">“HasCrCard”特征与目标变量的相关性最小。此外，由于信用卡是一种产品，该特性的信息能力部分存在于“NumOfProducts”列中。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="6f22" class="ma mb it lw b gy mc md l me mf">df_churn[['HasCrCard','Exited']].groupby('HasCrCard').agg(['mean','count'])</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/17cf44eae7d5aa0c39198179654435a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*vzoNqULhV5TMVfK46__ipA.png"/></div></figure><p id="08f5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">“HasCrCard”特性的两个值(0 和 1)的平均流失率几乎相同。</p></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><h1 id="9fe6" class="mo mb it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated"><strong class="ak">编码分类变量</strong></h1><p id="c3b9" class="pw-post-body-paragraph ki kj it kk b kl nf ju kn ko ng jx kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">我们将类别转换成数值。然而，我们还需要一个步骤来使它们适用于机器学习模型。</p><p id="cfb2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">法国变成了 0，德国变成了 1，西班牙变成了 2。如果我们像这样离开他们，模型可能会认为西班牙比法国更重要。</p><p id="5f30" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一个解决方案是<strong class="kk iu"> one-hot encoding </strong>，这意味着为每个类别创建一个新列。根据原始列中的值，新列的值为 1 或 0。</p><p id="e12f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可以使用 scikit-learn 的 onehotencoder，但我更喜欢手动操作，因为类别的数量只有 3 个。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="90f9" class="ma mb it lw b gy mc md l me mf">df_churn['Germany'] = df_churn['Geography'].where(df_churn['Geography'] == 1, 0)</span><span id="0f84" class="ma mb it lw b gy mg md l me mf">df_churn['Spain'] = df_churn['Geography'].where(df_churn['Geography'] == 2, 0)<br/>df_churn['Spain'] = df_churn['Spain'].replace(2,1)</span><span id="4150" class="ma mb it lw b gy mg md l me mf">df_churn.drop(['Geography'], axis=1, inplace=True)</span><span id="bfe8" class="ma mb it lw b gy mg md l me mf">df_churn.head()</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nu"><img src="../Images/c1006cad7b494988d33a77b7ff90e1be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*56_G79H5Q3nVBHNCb1fBSg.png"/></div></div></figure><p id="311f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果有 n 个类别，我们需要 n-1 列。如果其他 n-1 列中的值为零，我们已经有了关于最后一列的信息。例如，原始数据帧中的第一行是“法国”。我们已经有了这些信息，因为“德国”和“西班牙”列为零。</p><p id="267e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于“性别”列有两个不同的值，我们不需要一次性编码它。</p></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><h1 id="c213" class="mo mb it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated"><strong class="ak">阶层失衡</strong></h1><p id="abe9" class="pw-post-body-paragraph ki kj it kk b kl nf ju kn ko ng jx kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">数据不平衡通常是分类问题中的一个问题，它表示类别分布不均匀。像客户流失、垃圾邮件检测这样的任务很可能具有不均匀的类别分布。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/9ed26d76f9c0b268c0c5c718ae548271.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/1*IfjtY3wIXBr4jWXVGYepfA.png"/></div></figure><p id="e721" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">存在大约 4 比 1 的不平衡。如果分类模型是在不平衡的数据集上训练的，它将高度偏向主导类。因此，该模型将反映潜在的类别分布。为了有一个准确的模型，我们需要解决不平衡问题。</p><p id="8283" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有不同的方法来使用它作为解决方案。我们可以进行过采样(增加少数类的观测值)或欠采样(减少多数类的观测值)。</p><p id="8bb3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有不同的过采样技术。其中最常见的是<strong class="kk iu"> SMOTE </strong>(合成少数过采样技术)。SMOTE 算法根据已有的样本创建新的样本。它采用两个或更多相似的观察值，并通过一次改变一个属性来创建一个综合观察值。变化量是随机的，但会将新观测值保持在所用现有观测值的相邻距离内。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="d208" class="ma mb it lw b gy mc md l me mf">from imblearn.over_sampling import SMOTE</span><span id="2537" class="ma mb it lw b gy mg md l me mf">sm = SMOTE(random_state=42)</span><span id="9822" class="ma mb it lw b gy mg md l me mf">X = df_churn.drop('Exited', axis=1)</span><span id="12dc" class="ma mb it lw b gy mg md l me mf">y = df_churn['Exited']</span><span id="44ca" class="ma mb it lw b gy mg md l me mf">X_res, y_res = sm.fit_resample(X, y)</span><span id="f315" class="ma mb it lw b gy mg md l me mf">print(pd.Series(y_res).value_counts())<br/>1    7963 <br/>0    7963</span></pre><p id="9f9f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">目标变量中的数字 0 和 1 现在相等。</p></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><h1 id="0872" class="mo mb it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated"><strong class="ak">列车试裂</strong></h1><p id="cee6" class="pw-post-body-paragraph ki kj it kk b kl nf ju kn ko ng jx kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">我们现在需要将数据集分成训练和测试子集。该模型将在训练集上进行训练，并在测试集上进行测试。</p><p id="1b06" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在应用特征工程技术之前分割数据集是很重要的。模型不应该得到任何关于测试集的信息，测试集应该是由新的、以前看不到的特性组成的。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="bc9e" class="ma mb it lw b gy mc md l me mf">from sklearn.model_selection import train_test_split</span><span id="6d2b" class="ma mb it lw b gy mg md l me mf">X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2)</span></pre></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><h1 id="5c51" class="mo mb it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated"><strong class="ak">正常化</strong></h1><p id="6bdf" class="pw-post-body-paragraph ki kj it kk b kl nf ju kn ko ng jx kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">特性的取值范围差别很大。例如，“任期”的最大值是 10，而“估计工资”的值高达 20 万。</p><p id="a2c5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们将具有不同值范围的特征输入到模型中，则具有较高值的特征可能被赋予更大的重要性。我们不希望这样，所以我们将把功能纳入类似的范围。</p><p id="97c8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">归一化有不同的技术，如最小最大缩放器、标准缩放器和鲁棒缩放器。</p><p id="3c50" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">当数据集中存在异常值时，RobustScaler </strong>是一个不错的选择。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="5d5a" class="ma mb it lw b gy mc md l me mf">from sklearn.preprocessing import RobustScaler</span><span id="3e85" class="ma mb it lw b gy mg md l me mf">transformer = RobustScaler().fit(X_train)</span><span id="8bad" class="ma mb it lw b gy mg md l me mf">X_train_transformed = transformer.transform(X_train)</span><span id="f4eb" class="ma mb it lw b gy mg md l me mf">X_test_transformed = transformer.transform(X_test)</span></pre><p id="f54a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请记住，我们仅将训练集中的特征适配到缩放器。然后，训练集和测试集都用训练好的尺度进行变换。</p></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><h1 id="4749" class="mo mb it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated"><strong class="ak">功能选择</strong></h1><p id="9525" class="pw-post-body-paragraph ki kj it kk b kl nf ju kn ko ng jx kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">我们已经在一定程度上探索了特征的重要性，并深入了解了它们与目标变量之间的关系。</p><p id="59c5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">特性选择仅仅意味着使用更有价值的特性。这里的价值是信息。就目标变量而言，我们希望使用信息更丰富的特性。</p><p id="d92a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将使用递归特征消除(RFE ),它通过递归消除特征来工作。该消除是基于来自估计器的输出来完成的，该估计器将某种权重分配给特征。例如，权重可以是线性回归的系数或决策树的特征重要性。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="c561" class="ma mb it lw b gy mc md l me mf">from sklearn.linear_model import LogisticRegression</span><span id="b9ad" class="ma mb it lw b gy mg md l me mf">from sklearn.feature_selection import RFE</span><span id="351d" class="ma mb it lw b gy mg md l me mf">log_reg = LogisticRegression()</span><span id="112a" class="ma mb it lw b gy mg md l me mf">rfe = RFE(estimator=log_reg, n_features_to_select=7, step=1)</span><span id="6179" class="ma mb it lw b gy mg md l me mf">rfe.fit(X_train_transformed, y_train)</span><span id="d447" class="ma mb it lw b gy mg md l me mf">rfe.ranking_<br/>array([1, 1, 1, 3, 1, 1, 2, 1, 4, 1, 5])</span></pre><p id="c2dd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们使用逻辑回归作为估计量。所需的特征数量由<strong class="kk iu"> n_features_to_select </strong>参数决定。RFE 给每个特征分配一个等级。分配有 1 的功能是选定的功能。</p><p id="c216" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在我们的例子中，被删除的特征是“任期”、“HasCrCard”、“EstimatedSalary”和“西班牙”。</p><p id="ce68" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">回想一下，在我们的 EDA 过程中，我们发现“HasCrCard”特性与“Exited”列的相关性最低。</p><p id="69a1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们过滤所选的特征。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="96eb" class="ma mb it lw b gy mc md l me mf">X_train_selected = X_train_transformed[:,[0,1,2,4,5,7,9]]</span><span id="9a8b" class="ma mb it lw b gy mg md l me mf">X_test_selected = X_test_transformed[:,[0,1,2,4,5,7,9]]</span></pre></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><h1 id="3830" class="mo mb it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated"><strong class="ak">模型</strong></h1><p id="22b6" class="pw-post-body-paragraph ki kj it kk b kl nf ju kn ko ng jx kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">我将使用随机森林分类器。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="1192" class="ma mb it lw b gy mc md l me mf">from sklearn.ensemble import RandomForestClassifier</span><span id="8e1a" class="ma mb it lw b gy mg md l me mf">rf = RandomForestClassifier(max_depth=10, n_estimators=200)</span><span id="fa60" class="ma mb it lw b gy mg md l me mf">rf.fit(X_train_selected, y_train)</span></pre><p id="3a88" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们已经训练了这个模型。让我们对训练集和测试集进行预测。然后，我们将检查模型的准确性。</p><pre class="lf lg lh li gt lv lw lx ly aw lz bi"><span id="11fc" class="ma mb it lw b gy mc md l me mf">from sklearn.metrics import confusion_matrix</span><span id="59a4" class="ma mb it lw b gy mg md l me mf">y_pred = rf.predict(X_train_selected)<br/>cm_train = confusion_matrix(y_train, y_pred)<br/>print(cm_train)</span><span id="4c0e" class="ma mb it lw b gy mg md l me mf">y_test_pred = rf.predict(X_test_selected)<br/>cm_test = confusion_matrix(y_test, y_test_pred)<br/>print(cm_test)</span><span id="dcc9" class="ma mb it lw b gy mg md l me mf">train_acc = (cm_train[0][0] + cm_train[1][1]) / cm_train.sum()<br/>test_acc = (cm_test[0][0] + cm_test[1][1]) / cm_test.sum()</span><span id="edcc" class="ma mb it lw b gy mg md l me mf">print(f'Train accuracy is {train_acc}. Test accuracy is {test_acc}')</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/d2a4ead826515f3f206e2f330310bbc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*2qbP7qwr2aC13u47c-BbXg.png"/></div></figure><p id="4ff7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在训练集上的准确度是%91.7，在测试集上的准确度是%90.7。好消息是我们的模型没有过度拟合。但是，精确度可以提高。</p><p id="ef37" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们还打印了混淆矩阵，显示了有多少正(1)类和负(0)类被正确预测。根据任务的不同，特定类的预测更重要。在我们的例子中，正确预测正类(Exited=1)应该是重点，因为我们想知道哪些客户会离开我们。</p><p id="2cff" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在分类问题上，准确性并不能提供对模型的全面评估。根据任务的不同，精度、召回率和 AUC 等其他指标可能更合适。</p><p id="53f5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在<a class="ae lu" rel="noopener" target="_blank" href="/improving-the-performance-of-a-machine-learning-model-5637c12fc41c">的下一篇</a>文章中，我们将致力于:</p><ul class=""><li id="663c" class="nx ny it kk b kl km ko kp kr nz kv oa kz ob ld oc od oe of bi translated">如何提高准确率(正负类都有)</li><li id="394b" class="nx ny it kk b kl og ko oh kr oi kv oj kz ok ld oc od oe of bi translated">如何将模型的焦点更多地向正面类倾斜</li></ul></div><div class="ab cl mh mi hx mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="im in io ip iq"><p id="742b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢您的阅读。如果您有任何反馈，请告诉我。</p></div></div>    
</body>
</html>