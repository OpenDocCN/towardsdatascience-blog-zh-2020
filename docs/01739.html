<html>
<head>
<title>Why is your Horovod slower than the usual?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么你的Horovod比平时慢？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-is-your-horovod-slower-than-the-usual-201b4b8574d5?source=collection_archive---------26-----------------------#2020-02-17">https://towardsdatascience.com/why-is-your-horovod-slower-than-the-usual-201b4b8574d5?source=collection_archive---------26-----------------------#2020-02-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/06a38f48fb52bd1c9a35509565552b28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a4xJe-I8NB1fGQ4EOjHfkw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated"><a class="ae kf" href="https://github.com/horovod/horovod" rel="noopener ugc nofollow" target="_blank">https://github.com/horovod/horovod</a></p></figure><p id="4a3e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">本文讨论了如何使用Horovod进行更快的训练，以及在使用Nvidia GPUs作为加速器时可能导致训练速度下降的一些常见瓶颈。</p><p id="6d79" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae kf" href="https://github.com/horovod/horovod" rel="noopener ugc nofollow" target="_blank"> Horovod </a>是一个大规模执行分布式深度学习训练的框架。它的目标是用仅仅五行代码将大规模分发到深度学习作业中(嗯，差不多，取决于你想做什么)。让你的深度学习工作分布式的提升在你这边非常低，至少用<a class="ae kf" href="https://www.tensorflow.org/guide/keras" rel="noopener ugc nofollow" target="_blank"> tf.keras </a> API是这样。你自己用一个MNIST的例子来看看吧。</p></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><div class="ll lm ln lo gt lp"><a href="https://github.com/horovod/horovod/blob/master/examples/tensorflow_keras_mnist.py" rel="noopener  ugc nofollow" target="_blank"><div class="lq ab fo"><div class="lr ab ls cl cj lt"><h2 class="bd iu gy z fp lu fr fs lv fu fw is bi translated">霍罗沃德/霍罗沃德</h2><div class="lw l"><h3 class="bd b gy z fp lu fr fs lv fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="lx l"><p class="bd b dl z fp lu fr fs lv fu fw dk translated">github.com</p></div></div><div class="ly l"><div class="lz l ma mb mc ly md jz lp"/></div></div></a></div></div><div class="ab cl le lf hx lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="im in io ip iq"><p id="2b86" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下几点可能有助于您在使用GPU时调试缓慢的horovod作业:</p><ol class=""><li id="518d" class="me mf it ki b kj kk kn ko kr mg kv mh kz mi ld mj mk ml mm bi translated"><strong class="ki iu">环境设置:</strong>确保您已经安装了正确的环境。这包括使用无bug的MPI，比如OpenMPI。从horovod的<a class="ae kf" href="https://github.com/horovod/horovod/blob/master/README.rst" rel="noopener ugc nofollow" target="_blank">自述</a>中可以看出。</li></ol><blockquote class="mn mo mp"><p id="d701" class="kg kh mq ki b kj kk kl km kn ko kp kq mr ks kt ku ms kw kx ky mt la lb lc ld im bi translated">注意:Open MPI 3.1.3有一个可能导致挂起的问题。建议的修复方法是降级到Open MPI 3.1.2或升级到Open MPI 4.0.0。</p></blockquote><p id="caeb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用深度学习框架的无bug GPU版本(至少在TensorFlow的情况下)总是有帮助的。我记得tensorflow-gpu 1.13.1有一个bug，它会产生比所需数量更多的进程，使进程争夺没有有效完成任何工作的gpu资源。</p><p id="0fae" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> 2。正确的绑定参数:</strong>使用带有正确MPI参数的<strong class="ki iu"> mpirun </strong>或<strong class="ki iu"> horovodrun(取决于您使用的硬件)</strong>可以提高性能。理想情况下，控制GPU的进程应该绑定到最近的CPU插槽。这是可变的，取决于您用来训练模型的服务器硬件。在<a class="ae kf" href="https://www.dell.com/en-us/work/shop/povw/poweredge-c4140" rel="noopener ugc nofollow" target="_blank">戴尔EMC PowerEdge C4140 </a>上，最佳选项是— <strong class="ki iu">按插槽映射</strong>。不需要指定任何绑定选项。看起来大概是这样的:</p><p id="8551" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">mpirun-map-by socket-NP x python pyfile . py--py options</strong></p><p id="b6a8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> 3。每个GPU一个进程:</strong>作业应该设置为一个MPI进程在一个GPU上工作。如果进程的数量超过GPU的数量，这些进程将会竞争计算资源，并且无法以良好的性能运行作业。在上面的例子中，<strong class="ki iu"> x </strong>应该是要使用的相同数量的GPU。</p><p id="0af5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要为每个GPU设置一个进程，使用TensorFlow的ConfigProto()如下:<strong class="ki iu">config . GPU _ options . visible _ device _ list = str(hvd . local _ rank())</strong></p><p id="a49b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> 4。</strong>要检查使用GPU的进程数量，可以使用GPU的内存消耗<strong class="ki iu">‘watch NVIDIA-SMI’</strong>命令<strong class="ki iu"> </strong>。这也允许查看功耗。</p><figure class="ll lm ln lo gt ju gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/537b5e0e574b8433fef7d1541bf90c38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*ogyatb6cd5Me6_RcKmYqYQ.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">观看nvidia-smi</p></figure><p id="e4f2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> 5。闲置GPU: </strong>这是你工作变慢的一大元凶。如果你的图形处理器急需数据，那么工作很容易变慢。我见过需要数天/数小时培训的工作，如果数据管道处理正确，可以在不到一小时内完成。确保您的<strong class="ki iu"> </strong>代码实现了数据流水线机制，如<a class="ae kf" href="https://www.tensorflow.org/guide/data" rel="noopener ugc nofollow" target="_blank"> tf.data </a>或<a class="ae kf" href="https://docs.nvidia.com/deeplearning/sdk/dali-developer-guide/docs/examples/multigpu.html" rel="noopener ugc nofollow" target="_blank"> dali </a>或任何能够在训练发生时进行更快预处理并准备好下一批的机制。</p><p id="3e6b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果数据管道设置正确并且mpirun参数正确，一旦模型训练开始，GPU利用率应该会持续超过80-90%。偶尔降低到10–25%的利用率是可以接受的，但是不应该太频繁。</p><p id="ed46" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> 5。检查是什么让事情变慢了:</strong>使用<a class="ae kf" href="https://horovod.readthedocs.io/en/latest/timeline.html" rel="noopener ugc nofollow" target="_blank"> horovod timeline </a>和<a class="ae kf" href="https://devblogs.nvidia.com/cuda-pro-tip-profiling-mpi-applications/" rel="noopener ugc nofollow" target="_blank"> nvprof </a>查看任何可能出现的瓶颈，来描述你的工作。瓶颈很可能是由以下原因之一造成的:</p><p id="a9e1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">a) TF数据管道没有设置好，因此在加速器空闲时花费了大量时间来准备数据。若要解决此问题，必须更正tf管道。查看<a class="ae kf" href="https://github.com/tensorflow/models/tree/master/official/vision/image_classification" rel="noopener ugc nofollow" target="_blank"> tf官方模型报告</a>以获得建立高效数据管道的灵感。</p><p id="854d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">b)通信可能没有使用正确的结构—确保您使用的是<a class="ae kf" href="https://www.mellanox.com/pdf/whitepapers/IB_Intro_WP_190.pdf" rel="noopener ugc nofollow" target="_blank"> InfiniBand </a>，在运行mpirun时查看结构用法包括<strong class="ki iu">–x NCCL _调试=信息</strong>，如下所示:<br/><strong class="ki iu">mpirun-NP 4—map-by socket-x NCCL _调试=信息python something . py-{ params }</strong><br/>或使用包含–x绑定的<strong class="ki iu">horovidun</strong>。</p><p id="fd98" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> 6。GPU通信:</strong>为了正确地实现分布，GPU之间需要进行有效的通信。如果他们不能有效地沟通，这就会导致沟通瓶颈。要查看他们是否以最佳方式进行沟通，请使用以下流程:</p><ol class=""><li id="a967" class="me mf it ki b kj kk kn ko kr mg kv mh kz mi ld mj mk ml mm bi translated">使用<strong class="ki iu"> NCCL调试=信息</strong>可以向你展示图形处理器是如何说话的。如果GPU在说话:</li></ol><p id="a43e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> a. </strong>在节点内以一种最优的方式将看起来类似于这样:<strong class="ki iu">GPU 002:1299562:1299573[0]NCCL信息环00 : 0[0] - &gt; 1[1]通过P2P/IPC </strong></p><p id="4b7b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> b. </strong>最优方式下的外部节点看起来将与此类似:</p><p id="f13b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">GPU 028:149460:149495[0]NCCL信息环01 : 16 - &gt; 0【发送】via NET/IB/0 </strong></p><p id="8899" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">GPU 009:164181:164216[0]NCCL信息环01 : 12 - &gt; 8【接收】via NET/IB/0 </strong></p><p id="8632" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">GPU 009:164181:164216[0]NCCL信息环01 : 4 - &gt; 8【接收】via NET/IB/0 </strong></p><p id="72b7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">6。其他通用提示:设置批处理大小，使GPU内存几乎已满，但要加以限制，以免超出内存要求。重要的是要考虑完成学习率缩放的方式。学习率缩放的概念是，随着GPU数量的增加，学习率也必须乘以与GPU数量成比例的因子。这允许模型有效地收敛。这样，通过将最大数量的可能图像安装到GPU上，可以减少i/o操作的数量，而不会影响模型的收敛性。必须注意的是，在分布式工作负载设置中，学习率缩放并不总是改善模型收敛的最佳解决方案。<br/>检查是否需要学习率缩放:</p><ol class=""><li id="9400" class="me mf it ki b kj kk kn ko kr mg kv mh kz mi ld mj mk ml mm bi translated">a)以分布式模式训练具有和不具有学习率缩放的模型。<br/> b)如果没有学习率缩放的模型比具有学习率缩放的模型执行得更好，则不需要学习率缩放。</li><li id="990f" class="me mf it ki b kj mv kn mw kr mx kv my kz mz ld mj mk ml mm bi translated">特别是当训练收敛时，并不总是强制性的规则来适应每批图像的最高可能数量。数据科学家必须能够根据他们的使用案例，在批量大小和收敛(是否使用学习率缩放)之间做出权衡。<br/>同样，你可以使用<strong class="ki iu">‘观看NVIDIA-SMI’</strong>来查看GPU内存的消耗。使用学习率调整时，通常会有预热阶段，如本文中<a class="ae kf" href="https://arxiv.org/abs/1706.02677" rel="noopener ugc nofollow" target="_blank">所述。</a></li></ol><p id="113f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">3.安装最新的库。</p><p id="8685" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">分配你的深度学习工作有时会很有挑战性，特别是当使用的节点/GPU数量不能有效地转化为相应的性能时。为确保从加速器投资中获得最大收益，请确保实施以下最佳实践:</p><ul class=""><li id="4f41" class="me mf it ki b kj kk kn ko kr mg kv mh kz mi ld na mk ml mm bi translated">正确的绑定选项已经就绪，</li><li id="86df" class="me mf it ki b kj mv kn mw kr mx kv my kz mz ld na mk ml mm bi translated">评估不浪费GPU内存的多个进程，</li><li id="8e5d" class="me mf it ki b kj mv kn mw kr mx kv my kz mz ld na mk ml mm bi translated">使用现代流水线方法，</li><li id="7d3e" class="me mf it ki b kj mv kn mw kr mx kv my kz mz ld na mk ml mm bi translated">查看GPU的剖析至少在作业运行的80%的时间里被使用，</li><li id="04d0" class="me mf it ki b kj mv kn mw kr mx kv my kz mz ld na mk ml mm bi translated">使用最新的<a class="ae kf" href="https://developer.nvidia.com/cuda-downloads" rel="noopener ugc nofollow" target="_blank"> CUDA </a>相关库，比如CUDA驱动包括<a class="ae kf" href="https://developer.nvidia.com/nccl" rel="noopener ugc nofollow" target="_blank"> NCCL </a>等。</li></ul><p id="a569" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你有更多的解决方案，我会很高兴听到。请评论。</p></div></div>    
</body>
</html>