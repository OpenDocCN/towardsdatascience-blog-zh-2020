<html>
<head>
<title>From DataFrame to N-Grams</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从数据框架到 N 元语法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/from-dataframe-to-n-grams-e34e29df3460?source=collection_archive---------5-----------------------#2020-05-22">https://towardsdatascience.com/from-dataframe-to-n-grams-e34e29df3460?source=collection_archive---------5-----------------------#2020-05-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="dd8a" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">数据科学/ Python NLP 片段</h2><div class=""/><div class=""><h2 id="0a47" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">使用 nltk 为自然语言处理创建和可视化 n 元语法排序的快速入门指南。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/7476d965d2936a34b725c74f28513f2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bjm0i2-vnk8Nb4rJjgaitw.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">坦纳·马迪斯在 Unsplash<a class="ae lh" href="https://unsplash.com/s/photos/texts?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">拍摄的照片</a></p></figure><p id="5c0f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="me">当我第一次开始学习 NLP 的时候，我记得我被信息过载弄得沮丧或害怕，所以我决定写一篇涵盖最基本内容的帖子。你知道他们说什么，“先走后跑！”</em></p><p id="39bc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这是一个非常温和的介绍，所以我们不会在这里使用任何花哨的代码。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="a2cb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">简而言之，自然语言处理或 NLP 简单地指使用计算机阅读和理解书面或口头语言的过程。举个最简单的例子，我们可以用电脑来阅读一本书，并计算每个单词被使用了多少次，而不是我们手动去做。</p><p id="d157" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">NLP 是一个很大的话题，已经有很多关于这个主题的文章，所以我们在这里不做介绍。相反，我们将关注如何快速实现 NLP 中最简单但有用的技术之一:N 元语法排序。</p><h1 id="ef38" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">n 元语法排序</h1><p id="fdf2" class="pw-post-body-paragraph li lj it lk b ll ne kd ln lo nf kg lq lr ng lt lu lv nh lx ly lz ni mb mc md im bi translated">简单地说，一个 n-gram 是一个由<em class="me"> n </em>个字组成的序列，其中<em class="me"> n </em>是一个范围从 1 到无穷大的离散数字！例如，单词“cheese”是 1-gram (unigram)。单词“奶酪味”的组合是一个 2 克(双字母)。同样，“奶酪风味小吃”是一个 3 克(三元组)。而“终极芝士味零食”是 4 克(qualgram)。如此等等。</p><p id="e0bb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在 n-gram 排名中，我们只是根据 n-gram 在文本主体中出现的次数对其进行排名，无论是一本书、一组推文还是贵公司客户留下的评论。</p><p id="33cf" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们开始吧！</p><h1 id="08ab" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">获取数据</h1><p id="c34a" class="pw-post-body-paragraph li lj it lk b ll ne kd ln lo nf kg lq lr ng lt lu lv nh lx ly lz ni mb mc md im bi translated">首先，让我们获取数据并将其加载到 dataframe 中。你可以在这里下载样本数据集<a class="ae lh" href="https://github.com/ecdedios/ngram-quick-start" rel="noopener ugc nofollow" target="_blank"/>或者从<a class="ae lh" href="http://www.trumptwitterarchive.com/archive" rel="noopener ugc nofollow" target="_blank">特朗普推特档案</a>创建你自己的数据集。</p><pre class="ks kt ku kv gt nj nk nl nm aw nn bi"><span id="ffa3" class="no mn it nk b gy np nq l nr ns">import pandas as pd</span><span id="d8df" class="no mn it nk b gy nt nq l nr ns">df = pd.read_csv('tweets.csv')</span></pre><p id="1420" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">使用<code class="fe nu nv nw nk b">df.head()</code>我们可以快速熟悉数据集。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nx"><img src="../Images/e194a4ade25984d4ce6099a5c3bd32cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jc08DdNU6LPb-w_IsdSUkg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">特朗普总统的推文样本。</p></figure><h1 id="ec9d" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">导入包</h1><p id="169f" class="pw-post-body-paragraph li lj it lk b ll ne kd ln lo nf kg lq lr ng lt lu lv nh lx ly lz ni mb mc md im bi translated">接下来，我们将导入包，以便正确设置我们的 Jupyter 笔记本:</p><pre class="ks kt ku kv gt nj nk nl nm aw nn bi"><span id="bcd6" class="no mn it nk b gy np nq l nr ns"># natural language processing: n-gram ranking<br/>import re<br/>import unicodedata<br/>import nltk<br/>from nltk.corpus import stopwords</span><span id="f945" class="no mn it nk b gy nt nq l nr ns"># add appropriate words that will be ignored in the analysis<br/>ADDITIONAL_STOPWORDS = ['covfefe']</span><span id="d058" class="no mn it nk b gy nt nq l nr ns"><br/>import matplotlib.pyplot as plt</span></pre><p id="0c6d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在上面的代码块中，我们导入了熊猫，这样我们就可以用各种不同的奇妙方式来塑造和操作我们的数据！接下来，我们为 regex 导入了<code class="fe nu nv nw nk b">re</code>，为 Unicode 数据导入了<code class="fe nu nv nw nk b">unicodedata</code>，并导入了<code class="fe nu nv nw nk b">nltk</code>来帮助解析文本并稍微清理一下。然后，我们指定了我们想要忽略的额外的停用词。这有助于降低噪音。最后，我们导入了<code class="fe nu nv nw nk b">matplotlib</code> matplotlib，这样我们可以在以后可视化我们的 n 元排序的结果。</p><p id="8471" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">接下来，让我们创建一个执行基本数据清理的函数。</p><h1 id="d7a7" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">基本清洁</h1><pre class="ks kt ku kv gt nj nk nl nm aw nn bi"><span id="0e56" class="no mn it nk b gy np nq l nr ns">def basic_clean(text):<br/>  """<br/>  A simple function to clean up the data. All the words that<br/>  are not designated as a stop word is then lemmatized after<br/>  encoding and basic regex parsing are performed.<br/>  """<br/>  wnl = nltk.stem.WordNetLemmatizer()<br/>  stopwords = nltk.corpus.stopwords.words('english') + ADDITIONAL_STOPWORDS<br/>  text = (unicodedata.normalize('NFKD', text)<br/>    .encode('ascii', 'ignore')<br/>    .decode('utf-8', 'ignore')<br/>    .lower())<br/>  words = re.sub(r'[^\w\s]', '', text).split()<br/>  return [wnl.lemmatize(word) for word in words if word not in stopwords]</span></pre><p id="b86c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">上面的函数接受一列单词或文本作为输入，并返回一组更清晰的单词。该函数执行规范化、编码/解码、小写和词汇化。</p><p id="f800" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们使用它！</p><pre class="ks kt ku kv gt nj nk nl nm aw nn bi"><span id="a7ae" class="no mn it nk b gy np nq l nr ns">words = basic_clean(''.join(str(df['text'].tolist())))</span></pre><p id="9f56" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">上面，我们只是简单地调用函数<code class="fe nu nv nw nk b">basic_lean()</code>来处理我们的数据帧<code class="fe nu nv nw nk b">df</code>的<code class="fe nu nv nw nk b">'text'</code>列，并使它成为一个带有<code class="fe nu nv nw nk b">tolist()</code>的简单列表。然后我们将结果分配给<code class="fe nu nv nw nk b">words</code>。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/d2d185f9e995b7a7a0ce5d8ef3c20157.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*1DB44qOacnyUcoZ-7EuR9Q.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">已经清理、规范化和词条化的单词列表。</p></figure><h1 id="e37d" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">N-grams</h1><p id="b727" class="pw-post-body-paragraph li lj it lk b ll ne kd ln lo nf kg lq lr ng lt lu lv nh lx ly lz ni mb mc md im bi translated">有趣的部分来了！在一行代码中，我们可以找出哪些二元模型在这个特定的 tweets 样本中出现得最多。</p><pre class="ks kt ku kv gt nj nk nl nm aw nn bi"><span id="e148" class="no mn it nk b gy np nq l nr ns">(pd.Series(nltk.ngrams(words, 2)).value_counts())[:10]</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nz"><img src="../Images/6ccad9fde538115064501681e24d27df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RnQXnnpmUcV4GFWagu01aA.png"/></div></div></figure><p id="aa1b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们可以很容易地将数字 2 替换为 3，这样我们就可以得到前 10 个三元模型。</p><pre class="ks kt ku kv gt nj nk nl nm aw nn bi"><span id="6978" class="no mn it nk b gy np nq l nr ns">(pd.Series(nltk.ngrams(words, 3)).value_counts())[:10]</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oa"><img src="../Images/d842b2b20c74c2e3f6f10d5809b0ac60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6AR7MQKp97v6ltG--4y6Tw.png"/></div></div></figure><p id="3ac4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">瞧啊。我们给自己开了个好头。但是为什么现在停止呢？让我们尝试一下，做一个小眼睛糖果。</p><h1 id="75b1" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">奖励回合:可视化</h1><p id="54bd" class="pw-post-body-paragraph li lj it lk b ll ne kd ln lo nf kg lq lr ng lt lu lv nh lx ly lz ni mb mc md im bi translated">为了让事情变得简单一点，让我们将 n 元语法的结果赋给具有有意义名称的变量:</p><pre class="ks kt ku kv gt nj nk nl nm aw nn bi"><span id="a602" class="no mn it nk b gy np nq l nr ns">bigrams_series = (pd.Series(nltk.ngrams(words, 2)).value_counts())[:12]</span><span id="3ccb" class="no mn it nk b gy nt nq l nr ns">trigrams_series = (pd.Series(nltk.ngrams(words, 3)).value_counts())[:12]</span></pre><p id="de58" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我用<code class="fe nu nv nw nk b">[:12]</code>替换了<code class="fe nu nv nw nk b">[:10]</code>,因为我希望结果中有更多的 n-grams。这是一个任意值，因此您可以根据自己的情况选择对您最有意义的值。</p><p id="8210" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们创建一个水平条形图:</p><pre class="ks kt ku kv gt nj nk nl nm aw nn bi"><span id="bcea" class="no mn it nk b gy np nq l nr ns">bigrams_series.sort_values().plot.barh(color='blue', width=.9, figsize=(12, 8))</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ob"><img src="../Images/b8f92f16d75a18cf29756c01daf3c0d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jmy_v8FXU8lo5TEl9bMSyQ.png"/></div></div></figure><p id="2690" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们通过添加标题和轴标签来美化一下:</p><pre class="ks kt ku kv gt nj nk nl nm aw nn bi"><span id="4c18" class="no mn it nk b gy np nq l nr ns">bigrams_series.sort_values().plot.barh(color='blue', width=.9, figsize=(12, 8))<br/>plt.title('20 Most Frequently Occuring Bigrams')<br/>plt.ylabel('Bigram')<br/>plt.xlabel('# of Occurances')</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oc"><img src="../Images/97978fb3a02b1b9a6fe01ca762737349.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8dkmp0kA_n-hp_cnc3OvPQ.png"/></div></div></figure><p id="081a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">就是这样！通过几行简单的代码，我们很快从一个熊猫数据帧中制作了一个 n-grams 的排序，甚至制作了一个水平条形图。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="e48f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我希望你喜欢这个。自然语言处理是一个很大的话题，但是我希望这个温和的介绍将鼓励你探索更多并扩展你的技能。</p><p id="f532" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="me">在下一篇文章中，我们将</em> <a class="ae lh" rel="noopener" target="_blank" href="/create-an-n-gram-ranking-in-power-bi-b27ba076366"> <em class="me">可视化一个 n-gram 在 Power BI </em> </a> <em class="me">中的排名，只需简单地点击几下鼠标和一小段 Python！</em></p><p id="9462" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="me">敬请期待！</em></p><p id="e9a5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">你可以通过推特或 T2【LinkedIn】联系我。</p></div></div>    
</body>
</html>