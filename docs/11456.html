<html>
<head>
<title>Cracking Blackjack — Part 5</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">破解 21 点——第五部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/cracking-blackjack-part-5-70bd2f726133?source=collection_archive---------27-----------------------#2020-08-08">https://towardsdatascience.com/cracking-blackjack-part-5-70bd2f726133?source=collection_archive---------27-----------------------#2020-08-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="f3af" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/Cracking-Blackjack" rel="noopener" target="_blank">破解二十一点</a></h2><div class=""/><div class=""><h2 id="318a" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">完成首次访问蒙特卡罗算法</h2></div><p id="dd23" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">嗨！</p><p id="490f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果您还没有这样做，请在继续之前阅读<a class="ae lk" href="https://towardsdatascience.com/tagged/Cracking-Blackjack" rel="noopener" target="_blank">第 1–4 部分</a>。本文的其余部分将假设您已经阅读并理解了前面的文章。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ll"><img src="../Images/a7978b05f97abdb221b52a213f2da86f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OpqWu7BFD2fhbHtq"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">图片来自<a class="ae lk" href="https://unsplash.com/photos/P787-xixGio" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="af5f" class="mi mj iq bd mk ml mm mn mo mp mq mr ms kf mt kg mu ki mv kj mw kl mx km my mz bi translated">这篇文章的大纲</h1><ul class=""><li id="8daf" class="na nb iq kq b kr nc ku nd kx ne lb nf lf ng lj nh ni nj nk bi translated">了解<code class="fe nl nm nn no b">run_mc()</code>函数如何简化算法。</li><li id="fd8c" class="na nb iq kq b kr np ku nq kx nr lb ns lf nt lj nh ni nj nk bi translated">深入研究初诊 MC 算法的第 6 步，在这一步中，Q 表和概率表在每集之后更新。</li></ul><h1 id="8c72" class="mi mj iq bd mk ml nu mn mo mp nv mr ms kf nw kg mu ki nx kj mw kl ny km my mz bi translated">第 4 部分首次访问 MC 的 10，000 英尺概述</h1><ol class=""><li id="d3d8" class="na nb iq kq b kr nc ku nd kx ne lb nf lf ng lj nz ni nj nk bi translated">从第 2 部分的<a class="ae lk" rel="noopener" target="_blank" href="/cracking-blackjack-part-2-75e32363e38?source=friends_link&amp;sk=41bdbc0e16dddd80c172c7ddb039eb42">中初始化 21 点环境。</a></li><li id="b610" class="na nb iq kq b kr np ku nq kx nr lb ns lf nt lj nz ni nj nk bi translated">定义第三部分中解释的 Q 表、概率表、α、ε、ε衰减、ε最小和γ。</li><li id="312a" class="na nb iq kq b kr np ku nq kx nr lb ns lf nt lj nz ni nj nk bi translated">定义您希望您的代理学习多少集。更多的情节通常会产生更有利可图的政策。</li><li id="1ead" class="na nb iq kq b kr np ku nq kx nr lb ns lf nt lj nz ni nj nk bi translated">播放一集。记录剧集中所有的(<strong class="kq ja">状态→动作→奖励)</strong>元组。</li><li id="3640" class="na nb iq kq b kr np ku nq kx nr lb ns lf nt lj nz ni nj nk bi translated">剧集结束后，对ε应用ε-decay/ε-min。</li><li id="e01d" class="na nb iq kq b kr np ku nq kx nr lb ns lf nt lj nz ni nj nk bi translated">然后，使用来自步骤 4 的(<strong class="kq ja">状态→动作→奖励)</strong>元组和相关公式更新 Q 表和概率表。</li><li id="c5df" class="na nb iq kq b kr np ku nq kx nr lb ns lf nt lj nz ni nj nk bi translated">对于步骤 3 中定义的剧集数量，重复步骤 4-6。</li><li id="4b4d" class="na nb iq kq b kr np ku nq kx nr lb ns lf nt lj nz ni nj nk bi translated">在所有事件之后，产生的 Q 表和概率表代表了 AI 代理刚刚学习的 21 点的优化策略。</li></ol><h1 id="30ab" class="mi mj iq bd mk ml nu mn mo mp nv mr ms kf nw kg mu ki nx kj mw kl ny km my mz bi translated">如何促进第 4-6 步</h1><p id="0fbd" class="pw-post-body-paragraph ko kp iq kq b kr nc ka kt ku nd kd kw kx oa kz la lb ob ld le lf oc lh li lj ij bi translated">在<a class="ae lk" rel="noopener" target="_blank" href="/cracking-blackjack-part-4-8b4a9caa38eb">第 4 部分</a>中，我们学习了如何在<code class="fe nl nm nn no b">play_game()</code>函数中实现步骤 4。在深入到第 5 步&amp;第 6 步之前，我想介绍一下<code class="fe nl nm nn no b">run_mc()</code>函数，它允许第 4 步到第 6 步协同工作。</p><p id="1bda" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">浏览下面的代码。我将在下面详细解释。点击查看完整的代码。</p><figure class="lm ln lo lp gt lq"><div class="bz fp l di"><div class="od oe l"/></div></figure><h2 id="48cb" class="of mj iq bd mk og oh dn mo oi oj dp ms kx ok ol mu lb om on mw lf oo op my iw bi translated">实现关键数据结构和值</h2><p id="7f27" class="pw-post-body-paragraph ko kp iq kq b kr nc ka kt ku nd kd kw kx oa kz la lb ob ld le lf oc lh li lj ij bi translated"><code class="fe nl nm nn no b">run_mc()</code>是明确定义 Q 表和 Prob 表的地方。</p><p id="1cf8" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">Q 表存储每个可能状态的每个动作的相对值(或 Q 值)。同样，状态由玩家的手牌值和庄家的上牌组成。</p><p id="e8d5" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为了在 Python 中表示这一点，<code class="fe nl nm nn no b">Q</code>是一个二维列表，其中外部列表的每个索引对应于一个唯一的状态，每个内部列表是一个 2 元素的 Q 值列表，用于命中和站立在与索引对应的状态。</p><p id="8d4a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><code class="fe nl nm nn no b">numpy.zeros()</code>函数允许我们指定想要用来表示 Q 表的 Numpy 数组的形状，从而简化了这个过程。我们还希望所有的 Q 值都从 0 开始，以便在代理开始试验和探索选项时不会产生偏差。<code class="fe nl nm nn no b">numpy.zeros()</code>通过用零填充我们指定的 Numpy 数组来实现这一点。</p><p id="d514" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">根据我们在<a class="ae lk" rel="noopener" target="_blank" href="/cracking-blackjack-part-2-75e32363e38?source=friends_link&amp;sk=41bdbc0e16dddd80c172c7ddb039eb42">第 2 部分</a>中的 21 点环境，<code class="fe nl nm nn no b">env.observation_space[0].n</code>是 18，代表可能的玩家手牌值(3–20)，而<code class="fe nl nm nn no b">env.observation_space[1].n</code>是 10，代表可能的庄家升牌值(2–11)。<code class="fe nl nm nn no b">env.action_space.n</code>是 2，因为唯一可能的行动是打和站。</p><p id="1842" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">因此，可能的状态数为<code class="fe nl nm nn no b">env.observation_space[0].n</code> * <code class="fe nl nm nn no b">env.observation_space[1].n</code>，为 180。这意味着<code class="fe nl nm nn no b">Q</code>的外部列表有 180 个值。<code class="fe nl nm nn no b">Q</code>中的这 180 个值中的每一个都是一个大小为<code class="fe nl nm nn no b">env.action_space.n</code>(或 2)的内部零列表。</p><pre class="lm ln lo lp gt oq no or os aw ot bi"><span id="e0ee" class="of mj iq no b gy ou ov l ow ox">Q = np.zeros([env.observation_space[0].n * env.observation_space[1].n, env.action_space.n], dtype=np.float16)</span></pre><p id="59e4" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们以完全相同的方式定义 Prob-table(或<code class="fe nl nm nn no b">prob</code> ) <strong class="kq ja">，</strong>，除了每个值从 0.5(或 50%)而不是 0 开始，以确保每个动作在学习过程开始时有均等的机会被选中。</p><pre class="lm ln lo lp gt oq no or os aw ot bi"><span id="51aa" class="of mj iq no b gy ou ov l ow ox">prob = np.zeros([env.observation_space[0].n * env.observation_space[1].n, env.action_space.n], dtype=np.float16) + 0.5</span></pre><p id="0e6d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><code class="fe nl nm nn no b">run_mc()</code>也是<a class="ae lk" rel="noopener" target="_blank" href="/cracking-blackjack-part-3-8fd3a5870efd?source=friends_link&amp;sk=98055a00e2e685239d7148524a2d0b17">第 3 部分</a>中讨论的重要杠杆(ε、α和γ)被明确定义的地方。赋予每个值背后的原因将在下一篇文章中解释。</p><pre class="lm ln lo lp gt oq no or os aw ot bi"><span id="27cb" class="of mj iq no b gy ou ov l ow ox">alpha = 0.001<br/><br/>epsilon = 1<br/>    <br/>decay = 0.9999<br/>    <br/>epsilon_min = 0.9<br/><br/>gamma = 0.8</span></pre><h2 id="2dff" class="of mj iq bd mk og oh dn mo oi oj dp ms kx ok ol mu lb om on mw lf oo op my iw bi translated">步骤 4–6 协同工作</h2><p id="42e4" class="pw-post-body-paragraph ko kp iq kq b kr nc ka kt ku nd kd kw kx oa kz la lb ob ld le lf oc lh li lj ij bi translated">这几行代码概括了所有的步骤 4-6。</p><pre class="lm ln lo lp gt oq no or os aw ot bi"><span id="7a05" class="of mj iq no b gy ou ov l ow ox"><strong class="no ja">for</strong> _ <strong class="no ja">in</strong> range(num_episodes):<br/>    episode = play_game(env, Q, prob)<br/>        <br/>    epsilon = max(epsilon * decay, epsilon_min)<br/>        <br/>    Q = update_Q(env, episode, Q, alpha, gamma)<br/>    prob = update_prob(env, episode, Q, prob, epsilon)</span></pre><p id="2bb7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">首先，我们使用<a class="ae lk" rel="noopener" target="_blank" href="/cracking-blackjack-part-4-8b4a9caa38eb?source=friends_link&amp;sk=1e6c7e29a69e70f123a863f100f15c86">第四部分</a>中讨论的<code class="fe nl nm nn no b">play_game()</code>功能模拟一集。<strong class="kq ja">这是第四步</strong>。</p><p id="033a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然后，我们将<code class="fe nl nm nn no b">decay</code>因子应用于<code class="fe nl nm nn no b">epsilon</code>，或者如果<code class="fe nl nm nn no b">epsilon</code>已经低于<code class="fe nl nm nn no b">epsilon_min</code>，就使用<code class="fe nl nm nn no b">epsilon_min</code>。<strong class="kq ja">这是第五步</strong>。</p><p id="7a87" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">最后，我们使用<code class="fe nl nm nn no b">update_Q()</code>和<code class="fe nl nm nn no b">update_prob()</code>更新我们的 Q 表和 Prob 表。<code class="fe nl nm nn no b">episode</code>和<code class="fe nl nm nn no b">epsilon</code>是这些功能的关键论据，而且每集都有变化。<strong class="kq ja">这是第 6 步</strong>。</p><h1 id="6ab6" class="mi mj iq bd mk ml nu mn mo mp nv mr ms kf nw kg mu ki nx kj mw kl ny km my mz bi translated">深入第 6 步</h1><p id="9709" class="pw-post-body-paragraph ko kp iq kq b kr nc ka kt ku nd kd kw kx oa kz la lb ob ld le lf oc lh li lj ij bi translated">在我继续之前，祝贺你读到这里！你将要学习这个蒙特卡罗过程的最后，也是最重要的部分。你已经走了很长的路了！花点时间思考一下吧！</p><h2 id="cb74" class="of mj iq bd mk og oh dn mo oi oj dp ms kx ok ol mu lb om on mw lf oo op my iw bi translated">update_Q()</h2><p id="01be" class="pw-post-body-paragraph ko kp iq kq b kr nc ka kt ku nd kd kw kx oa kz la lb ob ld le lf oc lh li lj ij bi translated">之所以称之为<strong class="kq ja">“首次访问”</strong> MC 算法，是因为我们有一种<strong class="kq ja">首次访问</strong>的方法来评估奖励。</p><p id="5ecd" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">“首次访问”意味着我们希望从一集第一次出现开始跟踪状态-动作对的奖励，然后使用该集的累积奖励来更新我们的<code class="fe nl nm nn no b">Q</code>-表中该状态-动作对的 Q 值。</p><p id="8a98" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">另一个选项是<strong class="kq ja">“每次访问”</strong>方法。在这种方法中，每当 <strong class="kq ja">在一集</strong>中出现时，我们使用状态-动作对<strong class="kq ja">的即时奖励来更新 Q 值。</strong></p><p id="0e0a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">鉴于 21 点的形式以及我们如何设置我们的环境，对我们的问题使用<strong class="kq ja">每次访问</strong>的方法是没有意义的。</p><p id="8c5c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在我们的剧集中，除了最后的状态-动作对，状态-动作对的奖励都是 0。这是因为在 21 点回合(或插曲)的结果已知之前，21 点玩家(和我们的代理人)可能必须做出不止一个决定(意味着不止一个国家行动对)。</p><p id="3db1" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">因此，如果我们强迫我们的代理在每个状态-动作对之后使用$0 的即时奖励来更新 Q 表中的 Q 值，我们的代理将不会有很大的改进。相反，我们将使用最终状态-动作对的奖励，并<strong class="kq ja">贴现</strong>它们，以近似同一集内先前状态-动作对的价值。</p><p id="4d65" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们将使用以下公式为每集中的状态-动作对找到折扣奖励:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi oy"><img src="../Images/36fce390cb27746a6cc5a1f6c9310e43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pmYU5UjOB5HckSwmwfTFBg.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">作者制作的图像</p></figure><p id="263a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">计算折扣奖励的示例如<a class="ae lk" rel="noopener" target="_blank" href="/cracking-blackjack-part-3-8fd3a5870efd?source=friends_link&amp;sk=98055a00e2e685239d7148524a2d0b17">第 3 部分</a>所示:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi oz"><img src="../Images/e98d7c540d214c5cf7296204ba500a17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RY6wCza_KaNDGcNVce0m1w.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">作者制作的图像</p></figure><p id="d09a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">一个直观的例子:</strong></p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi pa"><img src="../Images/46557aa554571428eb430a17bc5becdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*90EP8HUpO8Ix0m0hm_ZCFA.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">作者制作的图像</p></figure><p id="ed22" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">放在一起:</strong>对于<code class="fe nl nm nn no b">episode</code>中的每个(<strong class="kq ja">状态→动作→奖励)</strong>元组，我们将使用状态-动作对的<strong class="kq ja">折扣奖励</strong>来更新<code class="fe nl nm nn no b">Q</code>表中相应的 Q 值。</p><p id="de11" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">以下是我们这一集遇到的每个状态-动作对的 Q 值变化公式:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi pb"><img src="../Images/450e57ec192c0446247f67a70e877cfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*obGCbAnZqNlCSKH65UXfqQ.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">作者制作的图像</p></figure><p id="e42b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><code class="fe nl nm nn no b">update_Q()</code>本质上为我们这一集看到的每个状态-动作对计算⍙ <strong class="kq ja"> Q </strong>，并将⍙ <strong class="kq ja"> Q </strong>加到当前 q 值上。实现如下。</p><figure class="lm ln lo lp gt lq"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="3d5c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">下面是我们<code class="fe nl nm nn no b">episode</code>中每个状态-动作对的<strong class="kq ja">贴现奖励</strong>的计算。<code class="fe nl nm nn no b">step</code>在前面已经定义过了，本质上是我们公式中的<em class="pc"> i </em>下标，它记录了我们正在分析的状态-动作对。</p><pre class="lm ln lo lp gt oq no or os aw ot bi"><span id="8168" class="of mj iq no b gy ou ov l ow ox">total_reward = 0<br/>gamma_exp = 0<br/><strong class="no ja">for</strong> curr_step <strong class="no ja">in</strong> range(step, len(episode)):<br/>    curr_reward = episode[curr_step][2]<br/>    total_reward += (gamma ** gamma_exp) * curr_reward<br/>    gamma_exp += 1</span></pre><p id="0208" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">下面是⍙ <strong class="kq ja"> Q </strong>的计算，并使用它来更新我们的<code class="fe nl nm nn no b">Q</code>表中相应的 q 值。</p><pre class="lm ln lo lp gt oq no or os aw ot bi"><span id="b3cd" class="of mj iq no b gy ou ov l ow ox"><em class="pc"># Update the Q-value</em><br/>Q_state_index = get_Q_state_index(state)<br/>curr_Q_value = Q[Q_state_index][action]<br/>Q[Q_state_index][action] = curr_Q_value + alpha * (total_reward - curr_Q_value)</span></pre><p id="6aee" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在学习过程的最后，我们可以简单地查看我们的<code class="fe nl nm nn no b">Q</code>-表，看看对于任何给定的状态，哪个动作具有更大的相对值。</p><h2 id="1f97" class="of mj iq bd mk og oh dn mo oi oj dp ms kx ok ol mu lb om on mw lf oo op my iw bi translated">update_prob()</h2><p id="677c" class="pw-post-body-paragraph ko kp iq kq b kr nc ka kt ku nd kd kw kx oa kz la lb ob ld le lf oc lh li lj ij bi translated">请多花点时间消化<code class="fe nl nm nn no b">update_Q()</code>。如果你完全理解了<code class="fe nl nm nn no b">update_Q()</code>，那么<code class="fe nl nm nn no b">update_prob()</code>就轻而易举了！</p><p id="81ba" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为了刷新你的记忆，<code class="fe nl nm nn no b">update_prob()</code>调整了在我们的剧集中遇到的每个状态采取行动的概率分布。<code class="fe nl nm nn no b">update_prob()</code>在<code class="fe nl nm nn no b">update_Q()</code>结束后被调用，因为 Q 值影响概率更新的方式，我们需要最新的 Q 值。</p><p id="d106" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这次我将从代码开始，因为<code class="fe nl nm nn no b">update_prob()</code>的公式比<strong class="kq ja">简单得多。</strong></p><figure class="lm ln lo lp gt lq"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="31fa" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在<code class="fe nl nm nn no b">update_prob()</code>中，我们使用<code class="fe nl nm nn no b">Q</code>表来找出哪个动作(击打或站立)对于我们正在更新的状态具有更大的 Q 值。这是<code class="fe nl nm nn no b">best_action</code>。</p><p id="39ca" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">首先，我们调整给定状态下选择<code class="fe nl nm nn no b">best_action</code>的概率。⍙ <strong class="kq ja">概率</strong>的计算公式如下(其中<code class="fe nl nm nn no b">prob[Q_state_index][best_action]</code>是选择<code class="fe nl nm nn no b">best_action</code>的当前概率):</p><pre class="lm ln lo lp gt oq no or os aw ot bi"><span id="db81" class="of mj iq no b gy ou ov l ow ox">⍙<strong class="no ja">Prob = </strong>prob[Q_state_index][best_action] + 1 - epsilon</span></pre><p id="657e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">⍙ <strong class="kq ja">概率</strong>有可能超过 1(或 100%)，所以我们更新<code class="fe nl nm nn no b">prob</code>表中的概率如下:</p><pre class="lm ln lo lp gt oq no or os aw ot bi"><span id="f60a" class="of mj iq no b gy ou ov l ow ox">prob[Q_state_index][best_action] = min(1, ⍙<strong class="no ja">Prob</strong>)</span></pre><p id="1739" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">最后，我们将根据<code class="fe nl nm nn no b">best_action</code>的新概率更新<code class="fe nl nm nn no b">other_action</code>的概率:</p><pre class="lm ln lo lp gt oq no or os aw ot bi"><span id="5dac" class="of mj iq no b gy ou ov l ow ox">prob[Q_state_index][other_action] = 1 - prob[Q_state_index][best_action]</span></pre><p id="73bd" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">更新这些概率很重要，因为这将影响我们学习过程中的<strong class="kq ja">探索</strong>与<strong class="kq ja">利用</strong>动态(详见<a class="ae lk" rel="noopener" target="_blank" href="/cracking-blackjack-part-3-8fd3a5870efd?source=friends_link&amp;sk=98055a00e2e685239d7148524a2d0b17">第 3 部分</a>)。</p><p id="e830" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">学习过程开始时较小的⍙ <strong class="kq ja">概率</strong>值确保了在<code class="fe nl nm nn no b">best_action</code>成为代理的主导选择之前需要一段时间。接近结束时较大的⍙ <strong class="kq ja">概率</strong>值将最终导致<code class="fe nl nm nn no b">best_action</code>的概率为 100%，代理可以开始总是采取它认为是最优的决策。</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h2 id="6b2d" class="of mj iq bd mk og oh dn mo oi oj dp ms kx ok ol mu lb om on mw lf oo op my iw bi translated">下一步是什么</h2><p id="c8f6" class="pw-post-body-paragraph ko kp iq kq b kr nc ka kt ku nd kd kw kx oa kz la lb ob ld le lf oc lh li lj ij bi translated">恭喜你。你现在知道“破解”21 点背后的所有<strong class="kq ja">科学</strong>！接下来，我们将深入到试验这种算法的<strong class="kq ja">艺术</strong>中，以找到可能的最佳 21 点回报！</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><p id="ca1d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">感谢您的阅读！</p><p id="6a50" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我真的很感激任何形式的反馈！我想成为一个更一致、更有效的内容创作者。</p><p id="f676" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">你学到什么了吗？我很难理解吗？</p><p id="3cbc" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">欢迎在下面留言或发电子邮件给我，地址是 adithyasolai7@gmail.com！</p><p id="639e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae lk" href="https://github.com/adithyasolai/Monte-Carlo-Blackjack" rel="noopener ugc nofollow" target="_blank">本项目的 GitHub 回购。</a></p></div></div>    
</body>
</html>