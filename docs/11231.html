<html>
<head>
<title>DecisionTreeRegressor — Stop Using For Future Projections!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">决策树回归器—停止用于未来预测！</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/decisiontreeregressor-stop-using-for-future-projections-e27104537f6a?source=collection_archive---------24-----------------------#2020-08-04">https://towardsdatascience.com/decisiontreeregressor-stop-using-for-future-projections-e27104537f6a?source=collection_archive---------24-----------------------#2020-08-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="442a" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" rel="noopener" target="_blank" href="https://towardsdatascience.com/machine-learning/home">内部 AI </a></h2><div class=""/><figure class="gl gn ka kb kc kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi jz"><img src="../Images/125387b14a859df25ac0c86b73ec01fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Aj91A0Z3CHgFgu4U"/></div></div><p class="kk kl gj gh gi km kn bd b be z dk translated"><a class="ae ko" href="https://unsplash.com/@pankajpatel?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">潘卡杰·帕特尔</a>在<a class="ae ko" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="a109" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">Scikit-learn 是 Python 中最著名的机器学习库之一。它提供了几种分类、回归和聚类算法，在我看来，它的主要优势是与 Numpy、Pandas 和 Scipy 的无缝集成。</p><p id="8fbe" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">Scikit-learn 由开发人员编写得非常好，只需几行代码，我们就可以通过许多不同的算法来检查模型预测。我觉得有时候，Scikit-learn 的这种优势会在不经意间对其不利。机器学习开发者。经验相对较少的人在没有掌握特定算法的显著特征和局限性的情况下实现不适当的预测算法。</p><p id="937b" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在本文中，我将讨论为什么我们不应该使用决策树回归算法来进行涉及外推数据的预测。</p></div><div class="ab cl ln lo hx lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="im in io ip iq"><p id="acf9" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jd"> <em class="lu">目标</em> </strong></p><p id="0d19" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们有豌豆从农场采摘到 1142 天的铁、钙和蛋白质含量。让我们假设，与蛋白质含量相比，测定铁和钙的含量更容易、更经济。</p><p id="3dee" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们将使用这些数据来训练决策树回归算法，然后根据与铁含量、钙和天数相关的新数据点来预测蛋白质含量。</p><p id="d827" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jd"> <em class="lu">样本数据文件</em> </strong></p><p id="2f23" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我认为数据文件是不言自明的。这些行显示了自收获以来豌豆的铁、钙和蛋白质含量。</p><figure class="lw lx ly lz gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi lv"><img src="../Images/e34576427322524ef35dc0f408c88017.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sM7Izmf6RO6CnEZBxXjA3g.png"/></div></div></figure><p id="854a" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jd"> <em class="lu">步骤 1</em></strong>——我们将导入包 pandas、matplotlib 以及 DecisionTreeRegressor 和 NumPy，我们将使用它们进行分析。</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="a9ef" class="mf mg it mb b gy mh mi l mj mk">from sklearn.tree import DecisionTreeRegressor<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import numpy as np</span></pre><p id="031a" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jd"> <em class="lu">第二步- </em> </strong>将完整的数据样本数据 excel 文件读入名为“数据”的 PandasDataframe 中。</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="8de3" class="mf mg it mb b gy mh mi l mj mk">data= pd.read_excel("Peas Nutrient.xlsx")</span></pre><p id="c80e" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我不会关注初步的数据质量检查，如空白值、异常值等。和各自的修正方法，并假设不存在与差异相关的数据序列。</p><p id="daac" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jd"> <em class="lu">步骤 3- </em> </strong>我们将把完整的数据集分成两部分，即训练和测试设备。顾名思义，我们将使用训练数据集来训练决策树回归算法，并根据测试集中的数据将蛋白质预测与实际含量进行比较。</p><p id="b0ab" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在下面的代码中，从第 1 天到第 900 天的数据记录被分割为训练数据，从第 901 天到第 1142 天的数据记录被分割为测试数据。</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="f1da" class="mf mg it mb b gy mh mi l mj mk">Training_data= data[:900]<br/>Test_data=data.loc[901:1142]</span></pre><p id="5f1f" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jd"> <em class="lu">第四步- </em> </strong>“经过天数”、“铁含量”、“钙含量”是用于预测的自变量。预测的“蛋白质含量”是因变量。通常，自变量用“X”表示，因变量用“y”表示。</p><p id="94cf" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在下面的代码中，“蛋白质含量”数据列从数据帧中删除，剩余的数据(即独立变量数据点)被声明为 X_train。类似地，除了“蛋白质含量”之外的所有数据列都被删除，并声明为 y_train。</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="40f0" class="mf mg it mb b gy mh mi l mj mk">X_train=Training_data.drop(["Protein Content "], axis=1)<br/>y_train=Training_data.drop(["Days Passed", "Iron Content " ,"Calcium Content "], axis=1)</span></pre><p id="828b" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在下面的代码中对测试数据集重复相同的过程，即从第 901 天到第 1142 天的值，</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="db37" class="mf mg it mb b gy mh mi l mj mk">X_test=Test_data.drop(["Protein Content "], axis=1)<br/>y_test=Test_data.drop(["Days Passed", "Iron Content " ,"Calcium Content "], axis=1)</span></pre><p id="d02e" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jd"> <em class="lu">步骤 5- </em> </strong>用训练数据集训练决策树回归器模型。此外，检查分数以了解算法在该数据上训练得有多好。</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="cdfe" class="mf mg it mb b gy mh mi l mj mk">tree_reg = DecisionTreeRegressor().fit(X_train, y_train)<br/>print("The model training score is" , tree_reg.score(X_train, y_train))</span></pre><p id="f505" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">满分 1.0 本身就说明模型的过拟合。</p><figure class="lw lx ly lz gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi ml"><img src="../Images/708ed2ce892b2194d9ec24b77fe6678e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ox2-X7kTtdWi5PlyqPdIaA.png"/></div></div></figure><p id="2047" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jd"> <em class="lu">步骤 5- </em> </strong>为了解决在训练模型期间由于树的无约束深度而导致的过度拟合，我们将设置最大深度为 4 的约束。</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="596f" class="mf mg it mb b gy mh mi l mj mk">tree_reg = DecisionTreeRegressor(max_depth=6).fit(X_train, y_train)<br/>print("The model training score is" , tree_reg.score(X_train, y_train))</span></pre><p id="596b" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这解决了模型对训练数据的过度拟合，并且模型准备好基于测试数据点来预测蛋白质含量。</p><figure class="lw lx ly lz gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi mm"><img src="../Images/4e64a5715224e24ba7e0360e64da60a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jKpX9Denf2-dbW12gN2kbw.png"/></div></div></figure><p id="3067" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jd"> <em class="lu">步骤 6- </em> </strong>在下面的代码中，基于各自的“经过天数”、“铁含量”和“钙含量”数据，预测测试数据集(即从第 901 天到第 1142 天)的“蛋白质含量”。</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="3e71" class="mf mg it mb b gy mh mi l mj mk">y_pred_tree = tree_reg.predict(X_test)</span></pre><p id="8290" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kr jd"> <em class="lu">步骤 7- </em> </strong>我们将通过决策树回归模型绘制预测的蛋白质含量，并与第 901 天至第 1142 天的测试数据集中的实际蛋白质含量进行比较。</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="07c4" class="mf mg it mb b gy mh mi l mj mk">plt.plot(X_test["Days Passed"],y_test, label="Actual Data")<br/>plt.plot(X_test["Days Passed"],np.rint(y_pred_tree), label="Predicted Data")<br/>plt.ylabel("Days Passed")<br/>plt.xlabel('Protin Content (in Grams)')<br/>plt.legend(loc='best')<br/>plt.show()</span></pre><figure class="lw lx ly lz gt kd gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi mn"><img src="../Images/948d891375cfa759ec8d7fb88c8f7911.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IELPPDj1f-9bL8oandlbBw.png"/></div></div></figure><p id="fed5" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们可以看到，在具有 0.93 分数的训练数据集中训练得相当好的决策树回归器模型在预测测试数据上的蛋白质含量方面失败得很惨。该模型预测所有天的蛋白质含量都相同，约为 51.34。</p><p id="0812" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们不应该使用决策树回归模型进行涉及外推数据的预测。这只是一个例子，我们机器学习从业者的主要收获是在开始建模之前考虑数据、预测目标、算法的优势和局限性。</p><p id="ca52" class="pw-post-body-paragraph kp kq it kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在为机器学习监督算法选择独立变量时，我们可能会犯类似的错误。在文章中，<a class="ae ko" rel="noopener" target="_blank" href="/how-to-identify-the-right-independent-variables-for-machine-learning-supervised-algorithms-439986562d32">“如何为机器学习监督算法识别正确的自变量？”</a>我已经讨论了一种结构化的方法来识别适当的独立变量，以做出准确的预测。</p></div></div>    
</body>
</html>