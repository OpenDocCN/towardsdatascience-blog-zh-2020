<html>
<head>
<title>Unraveling the Staged Execution in Apache Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解开Apache Spark中的分阶段执行</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/unraveling-the-staged-execution-in-apache-spark-eff98c4cdac9?source=collection_archive---------14-----------------------#2020-05-31">https://towardsdatascience.com/unraveling-the-staged-execution-in-apache-spark-eff98c4cdac9?source=collection_archive---------14-----------------------#2020-05-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/997920d2ef484a0c24a3a852dc76cbb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TeRfEK6miSO82TDFoA7vnA.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://pixabay.com/images/" rel="noopener ugc nofollow" target="_blank">参考</a></p></figure><h2 id="bf20" class="jh ji jj bd b dl jk jl jm jn jo jp dk jq translated" aria-label="kicker paragraph">APACHE SPARK执行指南</h2><div class=""/><div class=""><h2 id="0bb9" class="pw-subtitle-paragraph kp js jj bd b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg dk translated">Spark中的Stage表示并行计算的逻辑单元。许多这样的阶段组装在一起，构建了Spark应用程序的执行框架。这个故事试图解开火花阶段的概念，并描述了重要的相关方面。</h2></div><p id="c477" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">火花阶段可以被理解为计算分布式集合的数据分区的计算块，该计算块能够在计算节点的集群中并行执行。Spark使用单个或多个阶段为Spark应用程序构建并行执行流。Stages提供模块化、可靠性和弹性来激发应用程序执行。以下是与火花阶段相关的各个重要方面:</p><p id="2627" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">阶段由DAG调度程序创建、执行和监控:</strong>每个正在运行的Spark应用程序都有一个与之相关联的DAG调度程序实例。该调度器响应于作业的提交而创建阶段，其中作业实质上表示对应于Spark应用中采取的动作的RDD执行计划(也称为RDD DAG)。如果在一个Spark应用程序中执行多个操作，那么多个作业可能会被提交给DAG调度程序。对于提交给它的每个作业，DAG调度程序创建一个或多个阶段，构建阶段DAG以列出阶段依赖关系图，然后根据阶段DAG为创建的阶段规划执行调度。此外，调度程序还监视阶段执行完成的状态，结果可能是成功、部分成功或失败。相应地，调度器尝试阶段重新执行，推断作业失败/成功，或者按照阶段DAG调度相关阶段。</p><p id="9367" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">以下是针对作业的RDD执行计划(DAG)示例:</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="8a4c" class="mm mn jj mi b gy mo mp l mq mr">(200) MapPartitionsRDD[36] <br/> | ShuffledRowRDD[35] <br/> +-(500) MapPartitionsRDD[34] <br/> | MapPartitionsRDD[33] <br/> | MapPartitionsRDD[32] <br/> | ShuffledRowRDD[31] <br/> +-(3) MapPartitionsRDD[30] <br/> | MapPartitionsRDD[29] <br/> | FileScanRDD[28]</span></pre><p id="0500" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">DAG调度程序为上述RDD执行计划创建了以下三个阶段:</p><figure class="md me mf mg gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ms"><img src="../Images/daf7c50580feb39ae00c39ff9f50a392.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lu05ymyQPjZavB3VbX-e7Q.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图(2):根据图(2)所示的RDD执行计划创建的三个阶段</p></figure><p id="a203" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">以下是DAG计划程序根据上述阶段创建的阶段DAG，它清楚地表明了阶段间的依赖关系:</p><figure class="md me mf mg gt iv gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/83a4d7a41811fbc799b49a20db862599.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*PTBbDIyuxw_q4UwJgWmCmw.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图(3):根据图(1)所示的作业的RDD执行计划，为图(2)所示的三个阶段创建的阶段DAG</p></figure><blockquote class="mu mv mw"><p id="4648" class="lh li mx lj b lk ll kt lm ln lo kw lp my lr ls lt mz lv lw lx na lz ma mb mc im bi translated">DAG调度程序创建的每个阶段在Spark应用程序的所有作业中都有一个唯一的ID。此外，根据阶段DAG来调度阶段以供执行，这意味着在已经计算了所有相关阶段(如阶段DAG中所列)之后，调度阶段以供执行。如果两个阶段互不依赖，并且它们的所有其他依赖阶段都已经计算过，则可以同时执行这两个阶段。</p></blockquote><p id="d70a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">在混洗边界上创建阶段</strong> : DAG调度程序通过在计划中由ShuffleRDD指示的混洗边界处分割RDD执行计划/DAG(与作业相关联)来创建多个阶段。因此，在这个拆分过程中，RDD执行计划的一个片段(本质上是RDD管道)成为了阶段的一部分。对于Spark应用程序中提到的大范围转换，Shuffle是必需的，例如聚合、连接或重新分区操作。</p><p id="cbfa" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">下面是在各种洗牌边界的舞台创作的插图。</p><figure class="md me mf mg gt iv gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/3c259d341d6373a800fef802205f7e71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*qw57LABv93GSqyVrEdi7EA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">洗牌边界的舞台创作插图。</p></figure><p id="af67" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">此外，在图(1)所示的例子中，如RDD执行计划中的两个ShuffleRowRDD所示，发生了两次洗牌，因此创建了三个阶段，如图(2)所示。从图(2)可以明显看出，三个阶段中每一个都包含一个RDD流水线(作业的原始RDD执行计划/DAG的一部分)。</p><blockquote class="mu mv mw"><p id="d1c6" class="lh li mx lj b lk ll kt lm ln lo kw lp my lr ls lt mz lv lw lx na lz ma mb mc im bi translated">如果提交的作业中不需要重排，DAG调度程序将仅为该作业创建和调度单个阶段</p></blockquote><p id="06bc" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">阶段有ShuffleMapStage或ResultStage两种类型:</strong>ShuffleMapStage类型的阶段是一个作业执行计划的中间阶段，该作业由Spark应用程序中提到的动作触发。ShuffleMapStage实质上产生由ShuffledRDD在后续阶段中使用的混洗数据文件。但是，在产生输出数据之前，ShuffleMapStage必须执行ShuffleMapStage中包含的作业的RDD执行计划段(实质上是一个RDD管道)。ShuffleMapStage产生的混洗数据量可作为称为ShuffleWrite的阶段度量。此外，由于SortShuffle过程主要用于产生混洗数据文件，所以由ShuffleMapStage产生的混洗数据文件的数量等于由该级的RDD流水线计算的数据分区的数量。</p><figure class="md me mf mg gt iv gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/35a9b254a1133a63914497785adb000e.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*xq9NbHRiAH8lOKlUnGIMDA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">ShuffleMapStage生成一组随机文件的图示。shuffle文件的数量等于ShuffleMapStage中分区的数量</p></figure><p id="0128" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">ResultStage是作业执行计划中的最后一个阶段，其中一个函数(对应于启动作业的动作)被应用于所有或一些分区，这些分区是通过执行包含在ResultStage中的RDD执行计划的段来计算的。该函数产生spark应用程序中相应动作执行的最终期望输出。<a class="ae jg" href="https://spark.apache.org/docs/latest/rdd-programming-guide.html#actions" rel="noopener ugc nofollow" target="_blank">此处列出了spark应用的可能操作列表。</a></p><blockquote class="mu mv mw"><p id="9418" class="lh li mx lj b lk ll kt lm ln lo kw lp my lr ls lt mz lv lw lx na lz ma mb mc im bi translated">由Spark应用程序中的操作触发的作业，要么仅由单个ResultStage组成，要么由中间ShuffleMapStage和单个ResultStage的组合组成。但是，对于自适应查询规划或自适应调度，一些仅由ShuffleMapStage组成的特殊作业可以由DAG调度程序根据请求执行。</p><p id="509e" class="lh li mx lj b lk ll kt lm ln lo kw lp my lr ls lt mz lv lw lx na lz ma mb mc im bi translated">ShuffleMapStage或ResultStage的数据是从输入文件、来自先前shuffle map stage的shuffle文件或缓存的rdd单独或组合提供的。</p></blockquote><p id="5b0e" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">每个阶段都有一个相关的任务集用于执行:</strong>对于一个阶段的执行尝试，DAG调度程序会创建一个相应的任务集。阶段任务集基本上是任务的集合，其中每个任务执行特定数据分区的阶段RDD管道，并产生所需的输出。</p><p id="3428" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">与阶段类型类似，阶段任务集中的任务属于ShuffleMapTask或ResultTask类型。ShuffleMapTasks是为ShuffleMapStage创建的，而ResultTasks是为ResultStage创建的。</p><p id="e3fe" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为stage的执行尝试创建的Taskset被提交给Spark应用程序的任务调度器实例。反过来，任务调度器在集群中的适当位置调度每个任务(包含在任务集中)的执行。在任务集中的所有任务被执行之后，任务集中每个任务的相应执行状态被报告回DAG调度器。因此，DAG调度器将阶段执行标记为完全成功、部分成功或完全失败。</p><figure class="md me mf mg gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nd"><img src="../Images/02257255620e6c2981317b3313856179.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dll7b78t90QYNe5zBKnxgw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">DAG调度程序为某个阶段创建任务集，将任务集提交给任务调度程序，以及DAG调度程序调度(已提交任务集的)任务，以便在Spark集群中的执行器上执行</p></figure><p id="4312" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在部分成功的情况下，使用仅包含先前失败的任务的部分任务集重新尝试阶段执行。在完全失败的情况下，将使用成熟的任务集重新尝试阶段执行。</p><blockquote class="mu mv mw"><p id="f00f" class="lh li mx lj b lk ll kt lm ln lo kw lp my lr ls lt mz lv lw lx na lz ma mb mc im bi translated">一个阶段只重试一定的次数，当所有的重试都不能将阶段执行标记为完全成功时，阶段执行被标记为失败，导致提交给DAG调度程序的相应作业的执行失败。</p><p id="8e45" class="lh li mx lj b lk ll kt lm ln lo kw lp my lr ls lt mz lv lw lx na lz ma mb mc im bi translated">此外，大多数情况下，由于父级产生的部分或全部混洗数据文件不可用，一个级会部分失败。这导致在报告失败的阶段被再次重试之前，父阶段的部分重新执行(以便计算丢失的混洗文件)。此外，如果在祖先中的连续级别处存在丢失的混洗文件，则这种重新执行也可以到达父级祖先中更深级别处存在的级。当托管文件的执行器由于内存溢出或集群管理器强制终止而丢失时，无序文件变得不可用。此外，当相应的ShuffledRDD被垃圾收集时，shuffle文件仍然不可用。</p></blockquote><p id="c493" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">阶段计算可在时间</strong>跳过:DAG调度程序可决定跳过已提交作业中ShuffleMap阶段的计算，前提是已针对提交给调度程序的前一个作业计算了类似的阶段。如果这两个阶段执行相同的RDD流水线，则它们被认为是相似的。这种跳过是可能的，因为混洗输出文件保留在磁盘中，直到混洗的RDD引用保留在Spark应用程序中。</p><p id="7db9" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">此外，在另一实例中，如果从属下游阶段所需的混洗RDD已经被缓存，DAG调度器可以决定跳过混洗映射阶段的计算，该缓存是在针对提交给调度器的先前作业的另一阶段的执行期间完成的。</p><p id="731a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">下面是一个示例Spark应用程序，用于说明DAG调度程序的阶段跳过，这个特定的应用程序缓存一个重新分区的数据集(在第10行),该数据集分别在第15行和第20行的两个文件写入操作中使用:</p><figure class="md me mf mg gt iv"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="fa5a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">下面是上述Spark应用程序中属于两个不同作业(由两个操作触发)的RDD执行计划(带有阶段标记)。在应用程序中，数据集“ds”被缓存，导致相应的“ShuffledRowRDD[11]”被缓存。</p><figure class="md me mf mg gt iv gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/a4bb0f3bcf8cb3ed4996041e051c8cd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*9pWkL8RBcSlCzpTp-Ofcog.png"/></div></figure><p id="f9c1" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">以下是DAG调度程序为这两个作业构建的阶段计算DAG:</p><figure class="md me mf mg gt iv gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/9a4baa40cda339f05ddb256183ab6895.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*wM1rC__Sn9h-BsXCvXcFhg.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作业1的阶段计算DAG</p></figure><figure class="md me mf mg gt iv gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/f6c7c94c6094e5debae5b355974f3e86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*zN4Vck71hQotHhadOq0upA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作业2的阶段计算DAG</p></figure><p id="94ee" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">从两个作业的阶段计算DAG可以清楚地看出，在作业-2的阶段计算DAG中，阶段4被跳过用于计算(被跳过的阶段是灰色的)，因为在作业-2的阶段5中使用的“ShuffledRowRDD[11]”已经被计算并缓存在作业-1的阶段2中，作业-1提前提交用于执行。</p><p id="caf9" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">总结</strong>:现在应该很明显了，Spark中执行流的分段如何为Spark应用程序的整体执行提供模块化和弹性。用户可以跟踪Spark应用程序的阶段进度，可以访问多个阶段指标来评估阶段执行效率。最后，也是最重要的一点，阶段进度和相关指标可以为应用优化提供线索。</p><p id="cad0" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果对Spark stages有任何疑问，或者对这个故事有任何反馈，请写在评论区。</p></div></div>    
</body>
</html>