<html>
<head>
<title>Explainability and Visibility into Covid-19 X-Ray Classifiers by Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过深度学习对新冠肺炎X射线分类器的可解释性和可见性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/explainability-and-visibility-in-covid-19-x-ray-classifiers-with-deep-learning-c12c3247f905?source=collection_archive---------48-----------------------#2020-05-14">https://towardsdatascience.com/explainability-and-visibility-in-covid-19-x-ray-classifiers-with-deep-learning-c12c3247f905?source=collection_archive---------48-----------------------#2020-05-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="94d5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">关键词:深度学习，Grad-CAM，X射线，新冠肺炎</p><p id="3b3f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ko">编者按:</em> </strong> <em class="ko"> </em> <a class="ae kp" href="http://towardsdatascience.com/" rel="noopener" target="_blank"> <em class="ko">走向数据科学</em> </a> <em class="ko">是一份以数据科学和机器学习研究为主的中型刊物。我们不是健康专家或流行病学家，本文的观点不应被解释为专业建议。想了解更多关于疫情冠状病毒的信息，可以点击</em> <a class="ae kp" href="https://www.who.int/emergencies/diseases/novel-coronavirus-2019/situation-reports" rel="noopener ugc nofollow" target="_blank"> <em class="ko">这里</em> </a> <em class="ko">。</em></p><h1 id="f31b" class="kq kr it bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">目的</h1><p id="cd5d" class="pw-post-body-paragraph jq jr it js b jt lo jv jw jx lp jz ka kb lq kd ke kf lr kh ki kj ls kl km kn im bi translated">在复活节的周末，我接触了一些用于新冠肺炎肺的深度学习分类器。演示结果看起来很好，似乎与当时关于这个主题的一些学术研究出版物相匹配。但是真的“没事”吗？</p><p id="439f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最近我碰巧听了一个关于“机器学习中的可解释性”的在线午餐网络研讨会，演讲者在最后谈到了这个分类结果:</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/426d63f6528b2ad0b09ac00cb479f05e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/0*SA3ng_pk-BiwYd_O.png"/></div></figure><p id="c668" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">上图也在这篇研究论文中呈现:<a class="ae kp" href="https://arxiv.org/pdf/1602.04938.pdf" rel="noopener ugc nofollow" target="_blank">“我为什么要相信你？”解释任何分类器的预测</a>。我们可以看到，分类器实际上被训练为将背景像素(例如，雪等野生环境)作为主要输入来分类它是宠物狗还是野狼。</p><p id="7128" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这唤起了我以前的兴趣，现在肯定激起了一点好奇心:</p><ul class=""><li id="22ef" class="mb mc it js b jt ju jx jy kb md kf me kj mf kn mg mh mi mj bi translated">我们如何“研究”这些通常以“黑盒”形式出现的新冠肺炎分类器，以了解哪些像素实际上促成了“新冠肺炎肺”的结果？</li><li id="fd4e" class="mb mc it js b jt mk jx ml kb mm kf mn kj mo kn mg mh mi mj bi translated">在这种情况下，我们可以利用的最简单的方式或最简单的工具是什么？</li></ul><p id="5a08" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是旅途中另一个10分钟的笔记。</p><h1 id="2ff9" class="kq kr it bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">范围</h1><p id="2c6f" class="pw-post-body-paragraph jq jr it js b jt lo jv jw jx lp jz ka kb lq kd ke kf lr kh ki kj ls kl km kn im bi translated">幸运的是，在过去的几年里，出现了各种CNN衍生分类器的便利工具:</p><p id="2ad3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将使用<strong class="js iu"> Grad-CAM </strong>对我们之前的新冠肺炎肺分类器做一个快速演示。</p><p id="3fef" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">“tensor flow 2 . 2 . 0 RC+Jupyter”</strong>Docker用于搭载英伟达T4 GPU的AWS Ubuntu 16.04服务器上。Tensorflow 2提供了一个简单的“<strong class="js iu">梯度带</strong>”实现。</p><p id="dd2b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下面是我在Ubuntu服务器上启动它的快速提示:</p><pre class="lu lv lw lx gt mp mq mr ms aw mt bi"><span id="c728" class="mu kr it mq b gy mv mw l mx my">docker run -itd — runtime=nvidia -v /zhong/tf/:/tf -p 8896 :8888 -p 6026 :6006 — name tf-gpu2 tensorflow/tensorflow: 2.2.0rc2-gpu-py3-jupyter</span></pre><h1 id="c3b8" class="kq kr it bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">方法</h1><p id="8dc3" class="pw-post-body-paragraph jq jr it js b jt lo jv jw jx lp jz ka kb lq kd ke kf lr kh ki kj ls kl km kn im bi translated">你可以放心地忽略上面Grad-CAM研究出版物中引用的一点数学知识。</p><p id="ca7c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这里引用它只是为了我们对最初的提议(在第4页&amp; 5) 与后来使用的Python代码进行持续的交叉检查，希望结果也有更好的透明度。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/9e2d86e09d4d5acf0fbef9c50c458aa4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/format:webp/0*3sOoZouoQM76Satj.png"/></div></figure><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi na"><img src="../Images/be26824c8bbad051d76bd78380f5e06b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/format:webp/0*fxRkJpxpHDIrDw7R.png"/></div></figure><p id="7850" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">(1):为了获得任何类别c的宽度u和高度v的类别区别定位图，我们首先计算类别c的分数yc(在softmax之前)相对于卷积层的特征图Ak的梯度。这些流回的梯度被全局平均汇集，以获得目标类的神经元重要性权重ak。(2):在为目标类c计算ak之后，我们执行激活图的加权组合，并在其后跟随ReLU。<strong class="js iu">这会产生一个与卷积特征图大小相同的粗略热图</strong>。</p><h1 id="9534" class="kq kr it bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">试验</h1><p id="2d44" class="pw-post-body-paragraph jq jr it js b jt lo jv jw jx lp jz ka kb lq kd ke kf lr kh ki kj ls kl km kn im bi translated">现在让我们尝试一下目前为止我们能找到的最简单的编码:</p><p id="485f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 1。导入包</strong></p><pre class="lu lv lw lx gt mp mq mr ms aw mt bi"><span id="0e1b" class="mu kr it mq b gy mv mw l mx my">import tensorflow as tf;<br/>print(tf.__version__)</span></pre><p id="1df1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">2.2.0-rc2</p><pre class="lu lv lw lx gt mp mq mr ms aw mt bi"><span id="fb98" class="mu kr it mq b gy mv mw l mx my">import tensorflow as tf<br/>import tensorflow.keras.backend as K<br/>from tensorflow.keras.applications.inception_v3 import InceptionV3<br/>from tensorflow.keras.preprocessing import image<br/>from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions<br/>import numpy as np<br/>import os<br/>import imutils<br/>import matplotlib.pyplot as plt<br/>import cv2</span></pre><p id="eb89" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 2。加载我们之前训练并保存的</strong> <a class="ae kp" href="https://community.intersystems.com/post/run-some-covid-19-lung-x-ray-classification-and-ct-detection-demos" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu">模型</strong> </a></p><pre class="lu lv lw lx gt mp mq mr ms aw mt bi"><span id="c753" class="mu kr it mq b gy mv mw l mx my">new_model = tf.keras.models.load_model('saved_model/inceptionV3')<br/>new_model.summary()</span></pre><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi nb"><img src="../Images/e505b2ea0948f58b9529d7c15f39418c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WdKwvETv-DvT_sJP.png"/></div></div></figure><p id="cf87" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以看到，在最终的全球平均池之前，我们模型中4D的最后一个CNN层被称为“<strong class="js iu"> mixed10 </strong>”。</p><p id="f878" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 3。计算Grad-CAM热图</strong></p><p id="f5f8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下面是一个简单的热图，实现了上面的Grad-CAM方程(1)和(2)。在本帖中有解释<a class="ae kp" href="https://medium.com/analytics-vidhya/visualizing-activation-heatmaps-using-tensorflow-5bdba018f759" rel="noopener">。</a></p><pre class="lu lv lw lx gt mp mq mr ms aw mt bi"><span id="051c" class="mu kr it mq b gy mv mw l mx my">with tf.GradientTape() as tape:<br/> last_conv_layer = model.get_layer('mixed10') <br/> iterate = tf.keras.models.Model([model.inputs], [model.output, last_conv_layer.output])<br/> model_out, last_conv_layer = iterate(testX)<br/> class_out = model_out[:, np.argmax(model_out[0])]<br/> grads = tape.gradient(class_out, last_conv_layer)<br/> pooled_grads = K.mean(grads, axis=(0, 1, 2))<br/> heatmap = tf.reduce_mean(tf.multiply(pooled_grads, last_conv_layer), axis=-1)<!-- --> </span></pre><p id="7f97" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我们的例子中，它将生成一个(27，6，6)的heatmap numpy数组。然后，我们可以将它调整到原始X射线图像的大小，并将其覆盖在X射线图像的顶部——就这样。</p><p id="9d19" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然而，在这种情况下，我们将使用一个稍微更详细的版本，这个版本在本文中也有很好的解释。它使用Grad-CAM热图编写了一个函数，该热图的大小已经调整为原始X射线的大小:</p><pre class="lu lv lw lx gt mp mq mr ms aw mt bi"><span id="82f8" class="mu kr it mq b gy mv mw l mx my"># import the necessary packages<br/>from tensorflow.keras.models import Model<br/>import tensorflow as tf<br/>import numpy as np<br/>import cv2</span><span id="3c5e" class="mu kr it mq b gy ng mw l mx my">class GradCAM:<br/>    def __init__(self, model, classIdx, layerName=None):<br/>        self.model = model<br/>        self.classIdx = classIdx<br/>        self.layerName = layerName<br/>        if self.layerName is None:<br/>            self.layerName = self.find_target_layer()</span><span id="8dcd" class="mu kr it mq b gy ng mw l mx my">def find_target_layer(self):<br/>        for layer in reversed(self.model.layers):<br/>            # check to see if the layer has a 4D output<br/>            if len(layer.output_shape) == 4:<br/>                return layer.name<br/>        raise ValueError("Could not find 4D layer. Cannot apply GradCAM.")</span><span id="94c9" class="mu kr it mq b gy ng mw l mx my">def compute_heatmap(self, image, eps=1e-8):<br/>        gradModel = Model(<br/>            inputs=[self.model.inputs],<br/>            outputs=[self.model.get_layer(self.layerName).output,<br/>                self.model.output])<br/>        # record operations for automatic differentiation<br/><strong class="mq iu">        with tf.GradientTape() as tape:<br/>            inputs = tf.cast(image, tf.float32)<br/>            (convOutputs, predictions) = gradModel(inputs)<br/>            loss = predictions[:, self.classIdx]</strong><br/><strong class="mq iu">        # use automatic differentiation to compute the gradients<br/>        grads = tape.gradient(loss, convOutputs)</strong><br/>        # compute the guided gradients<br/>        castConvOutputs = tf.cast(convOutputs &gt; 0, "float32")<br/>        castGrads = tf.cast(grads &gt; 0, "float32")<br/>        guidedGrads = castConvOutputs * castGrads * grads<br/>        convOutputs = convOutputs[0]<br/>        guidedGrads = guidedGrads[0]<br/>        weights = tf.reduce_mean(guidedGrads, axis=(0, 1))<br/>        cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)</span><span id="2af1" class="mu kr it mq b gy ng mw l mx my"># resize the heatmap to oringnal X-Ray image size<br/>        (w, h) = (image.shape[2], image.shape[1])<br/>        heatmap = cv2.resize(cam.numpy(), (w, h))</span><span id="1418" class="mu kr it mq b gy ng mw l mx my"># normalize the heatmap<br/>        numer = heatmap - np.min(heatmap)<br/>        denom = (heatmap.max() - heatmap.min()) + eps<br/>        heatmap = numer / denom<br/>        heatmap = (heatmap * 255).astype("uint8")</span><span id="2f96" class="mu kr it mq b gy ng mw l mx my"># return the resulting heatmap to the calling function<br/>        return heatmap</span></pre><p id="8388" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 4。装一张新冠肺炎肺部x光片</strong></p><p id="6400" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，我们加载一个从未在模型训练和验证过程中使用过的测试X射线。(也上传到了之前的帖子里)</p><pre class="lu lv lw lx gt mp mq mr ms aw mt bi"><span id="669f" class="mu kr it mq b gy mv mw l mx my">filename = ‘./test/nejmoa2001191_f1-PA.jpeg’<br/>orignal = cv2.imread(filename)<br/>plt.imshow(orignal)<br/>plt.show()</span></pre><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/a527fbddfad28a066ef9d1e0bffba25c.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/0*gpl2lUe46iPMfFmr.png"/></div></figure><p id="8cd1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后调整大小为256 x 256，并将其规范化为像素值在0.0和1.0之间的numpy数组“dataXG”。</p><pre class="lu lv lw lx gt mp mq mr ms aw mt bi"><span id="c896" class="mu kr it mq b gy mv mw l mx my">orig = cv2.cvtColor(orignal, cv2.COLOR_BGR2RGB)<br/>resized = cv2.resize(orig, (256, 256))<br/>dataXG = np.array(resized) / 255.0<br/>dataXG = np.expand_dims(dataXG, axis=0)</span></pre><p id="dcec" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 5。进行快速分类</strong></p><p id="d545" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在我们可以调用上面新加载的模型来进行快速预测</p><pre class="lu lv lw lx gt mp mq mr ms aw mt bi"><span id="df54" class="mu kr it mq b gy mv mw l mx my">preds = new_model.predict(dataXG)<br/>i = np.argmax(preds[0])<br/>print(i, preds)</span></pre><p id="cb7f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi">0 [[0.9171522 0.06534185 0.01750595]]</p><p id="1ea0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">所以被归类为0型——新冠肺炎肺，概率为0.9171522。</p><p id="3cab" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 6。计算Grad-CAM热图</strong></p><pre class="lu lv lw lx gt mp mq mr ms aw mt bi"><span id="8871" class="mu kr it mq b gy mv mw l mx my"># Compute the heatmap based on step 3<br/>cam = GradCAM(model=new_model, classIdx=i, layerName='mixed10') # find the last 4d shape "mixed10" in this case<br/>heatmap = cam.compute_heatmap(dataXG)</span><span id="b001" class="mu kr it mq b gy ng mw l mx my">#show the calculated heatmap<br/>plt.imshow(heatmap)<br/>plt.show()</span></pre><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/4ad351a5446d9279ae087fc888bf792b.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*BssRlyus25rNwMxk.png"/></div></figure><p id="c9ae" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 7。在原始x光片上显示热图</strong></p><pre class="lu lv lw lx gt mp mq mr ms aw mt bi"><span id="c915" class="mu kr it mq b gy mv mw l mx my"># Old fashioned way to overlay a transparent heatmap onto original image, the same as above<br/>heatmapY = cv2.resize(heatmap, (orig.shape[1], orig.shape[0]))<br/>heatmapY = cv2.applyColorMap(heatmapY, cv2.COLORMAP_HOT)  # COLORMAP_JET, COLORMAP_VIRIDIS, COLORMAP_HOT<br/>imageY = cv2.addWeighted(heatmapY, 0.5, orignal, 1.0, 0)<br/>print(heatmapY.shape, orig.shape)</span><span id="d4af" class="mu kr it mq b gy ng mw l mx my"># draw the orignal x-ray, the heatmap, and the overlay together<br/>output = np.hstack([orig, heatmapY, imageY])<br/>fig, ax = plt.subplots(figsize=(20, 18))<br/>ax.imshow(np.random.rand(1, 99), interpolation='nearest')<br/>plt.imshow(output)<br/>plt.show()</span></pre><p id="7052" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi">(842, 1090, 3) (842, 1090, 3)</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi nj"><img src="../Images/aa37d040ecc504d4d1ac0028e4e604da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mR7xWoWOIHwZT8E4.png"/></div></div></figure><p id="9848" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这似乎表明我们的新冠肺炎演示分类器“相信”患者在“右气管旁条纹”周围有一点“不透明”问题？我真的不知道，除非我和真正的放射科医生核实一下。</p><p id="c17e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">好了，让我们再尝试一些从真实案例提交到GitHub存储库中的测试图片:</p><pre class="lu lv lw lx gt mp mq mr ms aw mt bi"><span id="e9f1" class="mu kr it mq b gy mv mw l mx my">filename = ‘./test/1-s2.0-S0929664620300449-gr2_lrg-b.jpg’</span></pre><p id="8c67" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[9.9799889 e-01 3.8319459 e-04 1.6178709 e-03]]</p><p id="70f4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这似乎也是一个合理的新冠肺炎解释，表明问题更多发生在左心线区域？</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi nn"><img src="../Images/82ba98ab1329862e4f435cf4f849361e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*x3RWBoArm4XUjqlm.png"/></div></div></figure><p id="b378" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们试试另一种随机测试x光:</p><pre class="lu lv lw lx gt mp mq mr ms aw mt bi"><span id="7496" class="mu kr it mq b gy mv mw l mx my">filename = ‘../Covid_M/all/test/covid/radiol.2020200490.fig3.jpeg’</span></pre><p id="c33f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi">0 [[0.9317619 0.0169084 0.05132957]]</p><p id="fb6f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">令人惊讶的是，这看起来并不完全正确，但再看看它似乎也不太离谱，对不对？它显示了两个问题区域——主要问题在左侧，一些问题在右侧，与人类放射科医师的标记有些一致？(同时希望它不是在人类标记上训练——这是另一个层次的可解释性问题)。</p><p id="51f1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">好了，我就说到这里，因为我不确定会有多少人对阅读这份10分钟的简短记录感兴趣。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi no"><img src="../Images/bee4f2a61ddfb44ff795a145115eb9c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kc1B3DzX40zrKiB0.png"/></div></div></figure><p id="a6ad" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">好了，我就说到这里，因为我不确定是否有太多的人会对阅读X射线感兴趣。</p><h1 id="2167" class="kq kr it bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">为什么？</h1><p id="bd90" class="pw-post-body-paragraph jq jr it js b jt lo jv jw jx lp jz ka kb lq kd ke kf lr kh ki kj ls kl km kn im bi translated">那么，我们为什么要为此烦恼呢？为什么我们要触及这个话题并记下来以备后用？</p><p id="5ee7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我个人深深体会到“可解释性”和“可解释性”的重要性，以及实现它们的任何技术方法。任何进入这个维度的微小尝试都是值得努力的，不管它们有多微小。最终，“数据公平”、“数据公正”和“数据信任”将建立在数字经济的过程透明性之上。此外，它现在开始变得可用。现在我们有<a class="ae kp" rel="noopener" target="_blank" href="/an-overview-of-model-explainability-in-modern-machine-learning-fc0f22c8c29a">越来越多的研究和工具，</a>就在今天人工智能开发者的指尖。</p><p id="10d0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最后但同样重要的是，具体到这个演示，我对这种工具的一个欣赏是，它甚至不需要像素级标记，它试图自动为您生成肺部病变区域，有点半自动标记。在真实作品中是有意义的。我确实记得去年我的一个放射科朋友帮助我为U-Net训练一次又一次地为一些骨折数据生成一些像素级标签——这种练习确实伤害了我们的眼睛。</p><h1 id="9548" class="kq kr it bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">然后</h1><p id="f041" class="pw-post-body-paragraph jq jr it js b jt lo jv jw jx lp jz ka kb lq kd ke kf lr kh ki kj ls kl km kn im bi translated">我现在有点走神了。得益于过去10多年来深度学习的快速发展，医学成像是人工智能领域中相对成熟的方向。它值得一些好时光。然而，接下来我希望我们可以在NLP方面做更多的尝试，如果我们有一点时间的话。</p><h1 id="a618" class="kq kr it bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">确认</h1><p id="41dc" class="pw-post-body-paragraph jq jr it js b jt lo jv jw jx lp jz ka kb lq kd ke kf lr kh ki kj ls kl km kn im bi translated">所有的资料来源都已在需要的地方插入上述文本。如果需要，我会放入更多的参考资料。</p><h1 id="c6db" class="kq kr it bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">免责声明:</h1><p id="0b2b" class="pw-post-body-paragraph jq jr it js b jt lo jv jw jx lp jz ka kb lq kd ke kf lr kh ki kj ls kl km kn im bi translated">同样，上面应该是一个快速笔记，以防如果我现在不记录它，几周后它就消失了。都是作为一个“开发者”的个人看法。内容和文本可以根据需要随时修改。以上更多的是展示想法和方法，而不是临床解释，这将需要专业的放射科医生在良好的数据数量和质量上建立黄金法则。</p></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><p id="4029" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">前贴:<a class="ae kp" href="https://medium.com/@zhongli_69231/covid-19-lung-x-ray-classification-and-ct-detection-demos-in-10-minutes-9a686433a45a" rel="noopener">10分钟内新冠肺炎肺部X线分类和CT检测演示</a></p><p id="7ed6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下一篇文章:<a class="ae kp" href="https://medium.com/@zhongli_69231/deploy-covid-19-models-into-a-consolidated-ai-demo-service-stack-ac170c3293cc" rel="noopener">将新冠肺炎模型部署到一个统一的人工智能演示平台上</a></p><p id="3d39" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">【https://community.intersystems.com】最初发表于<a class="ae kp" href="https://community.intersystems.com/post/explainability-and-visibility-covid-19-x-ray-classifiers-deep-learning" rel="noopener ugc nofollow" target="_blank"><em class="ko"/></a><em class="ko">。</em></p></div></div>    
</body>
</html>