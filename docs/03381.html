<html>
<head>
<title>Combine LSTM and VAR for Multivariate Time Series Forecasting</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多元时间序列预测的LSTM和VAR组合方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/combine-lstm-and-var-for-multivariate-time-series-forecasting-abdcb3c7939b?source=collection_archive---------3-----------------------#2020-03-31">https://towardsdatascience.com/combine-lstm-and-var-for-multivariate-time-series-forecasting-abdcb3c7939b?source=collection_archive---------3-----------------------#2020-03-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="03a7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">多步训练过程在时间序列预测领域的应用</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/306b83c72f8b106561cacd07bc51b872.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*w-V6nHg_mXRhA6yi"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae ky" href="https://unsplash.com/@jannerboy62?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">尼克·费因斯</a>拍摄</p></figure><p id="d1bb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在经典的时间序列预测任务中，建模时的第一个标准决策涉及采用统计方法或其他纯机器学习模型，包括基于树的算法或深度学习技术。这种选择与我们正在解决的问题密切相关，但总的来说:当我们面临一个自回归问题，而未来只与过去相关时，统计技术就足够了；而机器学习模型适用于更复杂的情况，也可以组合多样化的数据源。</p><p id="dfbc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我试图将统计方法从经验中学习的能力与深度学习技术的推广相结合。我们的任务是一个多变量时间序列预测问题，所以我们使用ARIMA的多变量扩展，称为VAR，和一个简单的LSTM结构。我们不生产一个集合模型；我们使用VAR的能力来过滤和研究历史，并在预测未来时为我们的神经网络提供益处。</p><p id="d575" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的工作流程可以总结如下:</p><ul class=""><li id="1a79" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">根据我们的训练数据正确估计VAR</li><li id="703a" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">提取VAR学到的知识，并将其用于改进执行两步培训的LSTM模型的培训流程。</li></ul><p id="9bf5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们会发现我们的结果并不明显，因为按照这个步骤，我们必须与灾难性遗忘的问题作斗争。</p><h1 id="9466" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">数据</h1><p id="7423" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我们实验的<a class="ae ky" href="https://archive.ics.uci.edu/ml/datasets/Air+Quality" rel="noopener ugc nofollow" target="_blank">数据</a>包含嵌入在空气质量多传感器设备中的金属氧化物化学传感器的每小时平均响应，该设备位于意大利城市污染严重地区的场地<em class="ng">。</em>记录了一年的数据，包括一氧化碳、非后生碳氢化合物、苯、总氮氧化物(NOx)和二氧化氮(NO2)的实际小时平均浓度。此外，还提供了外部变量，如天气状况。存在大量nan，因此在继续之前需要进行线性插值(排除训练数据中nan超过50%的序列)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/5bf7ff190a947a6609b7f495a9d0a1cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FDEAWu6l-Kfs0VRKQoVPBQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由我们支配的时间序列的例子(图片由作者提供)</p></figure><h1 id="d421" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">VAR建模</h1><p id="3850" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">对于ARIMA，我们使用每个变量的过去值来预测未来。当我们有多个时间序列可供支配时，我们也可以从它们的关系中提取信息，这样VAR就是ARIMA的多元推广，因为它理解并使用几个输入之间的关系。这有助于描述数据的动态行为，并提供更好的预测结果。</p><p id="16a2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要正确开发风险值模型，必须满足拟合ARIMA时遇到的相同经典假设。我们需要给予平稳性并利用自相关行为。这些先决条件使我们能够开发一个稳定的模型。我们所有的时间序列平均都是平稳的，显示出每日和每周的模式。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/b59b49ff1823a6f32e7ccef56ede9123.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Slkk5f4chf3VJ3eiI-Ic4g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我们所掌握的一些时间序列的自相关例子(图片由作者提供)</p></figure><p id="7e43" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这些初步检查之后，我们准备好拟合我们的VAR。最佳滞后阶数的选择是根据AIC/BIC准则自动进行的。我们用AIC来操作选择:我们需要做的就是递归拟合我们的模型，改变滞后阶数，并标注AIC分数(<em class="ng">越低越好</em>)。可以仅考虑我们的列车数据来执行该过程。在我们的例子中，27是最好的延迟顺序。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/2a788923441b2f6f4b2c522474700b09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qd9sBKqiJmgaXTjnW1i7jA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">用AIC方法进行VAR滞后阶数选择(图片由作者提供)</p></figure><h1 id="e4c3" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">将VAR和LSTM结合起来</h1><p id="d671" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">现在我们的范围是使用我们拟合的VAR来改善我们神经网络的训练。VAR已经了解了我们的多变量数据源的内部行为，调整了疯狂的值，纠正了异常的趋势，并正确地重建了NaNs。所有这些信息都存储在拟合值中，它们是模型在训练过程中处理过的原始数据的平滑版本。换句话说，我们可以将这些值视为原始列车的一种增强数据源。</p><p id="d713" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的策略包括应用两步训练程序。我们使用VAR产生的拟合值，开始为我们的LSTM自动编码器提供数据，用于我们处理的所有序列的多步预测(多变量输出)。然后，我们用原始数据结束训练，在我们的情况下，它们是我们之前用来拟合VAR的相同数据。通过我们的神经网络，我们还可以结合外部数据源，例如，天气状况或一些时间属性，如我们循环编码的工作日、小时和月。</p><p id="8f1a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们希望我们的神经网络可以从两个不同但相似的数据源中学习，并在我们的测试数据上表现得更好。我们的方法听起来很棒，但这不是“免费的午餐”。在进行多步训练时，我们必须注意<a class="ae ky" href="https://arxiv.org/pdf/1312.6211.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">灾难性遗忘</strong> </a> <strong class="lb iu"> </strong>的问题。<em class="ng">灾难性遗忘是很多模型和算法面临的问题。当在一个任务上训练，然后在第二个任务上训练时，许多机器学习模型“忘记”如何执行第一个任务。这被广泛认为是神经网络的一个严重问题。</em></p><p id="296e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了避免这个繁琐的问题，整个网络的结构必须进行适当的调整，以提供性能方面的好处。根据这些观察，我们保留了之前培训的最后一部分作为验证。</p><p id="4d53" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从技术上讲，网络非常简单。它由一个seq2seq LSTM自动编码器构成，可以提前N步预测未来可用的传感器。使用<a class="ae ky" href="https://github.com/cerlymarco/keras-hypetune" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">keras-hype tune</strong></a><strong class="lb iu">执行训练程序。</strong>该框架以非常直观的方式提供了神经网络结构的<strong class="lb iu">超参数优化</strong>。对所有三个涉及的训练(对VAR拟合值的拟合、对原始数据的微调拟合和直接对原始数据的标准拟合)都进行了这一步。</p><p id="c444" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们可以将根据VAR的拟合值加上原始数据训练的模型与仅根据原始训练数据训练的相同结构进行比较。在大多数情况下，当我们执行两个训练步骤时，误差较低。我们还报告了使用基线获得的性能，该基线由最近可用观察的简单重复组成。该程序是验证预测是否不是重复的当前值(即不是有用的预测)的良好实践。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/c0eca2956730824864f4e6e92e572d33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HFrbq1L1G41Fuc2IUGNzDQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">测试台上的RMSE(图片由作者提供)</p></figure><h1 id="ec8c" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">摘要</h1><p id="9103" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">在本文中，我们尝试使用VAR模型获得的信息来完成一项多变量时间序列任务，以提高经过训练的预测未来的递归神经网络的性能。我们实施了两步训练程序，解决了灾难性遗忘的问题，并提高了整体表现。</p></div><div class="ab cl nl nm hx nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="im in io ip iq"><p id="90b7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://github.com/cerlymarco/MEDIUM_NoteBook" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">查看我的GITHUB回购</strong> </a></p><p id="9202" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">保持联系:<a class="ae ky" href="https://www.linkedin.com/in/marco-cerliani-b0bba714b/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a></p></div><div class="ab cl nl nm hx nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="im in io ip iq"><p id="005b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">参考文献</strong></p><p id="6d78" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">基于梯度的神经网络中灾难性遗忘的实证研究</p></div></div>    
</body>
</html>