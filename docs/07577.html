<html>
<head>
<title>NLP-Preprocessing Clinical data to find Sections</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP-预处理临床数据以找到切片</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/nlp-preprocessing-clinical-data-to-find-sections-461fdadbec77?source=collection_archive---------46-----------------------#2020-06-07">https://towardsdatascience.com/nlp-preprocessing-clinical-data-to-find-sections-461fdadbec77?source=collection_archive---------46-----------------------#2020-06-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="492a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">清洗医学文本</h2></div><p id="0dc1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本帖中，我们将<strong class="kk iu">使用医疗图表笔记数据</strong> ( <em class="le">医生的潦草笔记</em> ) <strong class="kk iu">对临床笔记中存在的主题进行建模。记住，写这些笔记是没有结构的。</strong></p><p id="b401" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在后面的故事中，我们将总结这些笔记。</p><h1 id="e0cd" class="lf lg it bd lh li lj lk ll lm ln lo lp jz lq ka lr kc ls kd lt kf lu kg lv lw bi translated">将在 4 篇文章中讨论的 NLP 任务:</h1><ol class=""><li id="3b08" class="lx ly it kk b kl lz ko ma kr mb kv mc kz md ld me mf mg mh bi translated"><strong class="kk iu">预处理和清洗</strong></li><li id="a10e" class="lx ly it kk b kl mi ko mj kr mk kv ml kz mm ld me mf mg mh bi translated"><a class="ae mn" href="https://medium.com/@tyagigaurika27/text-summarization-for-clustering-documents-2e074da6437a" rel="noopener">文本摘要</a></li><li id="3923" class="lx ly it kk b kl mi ko mj kr mk kv ml kz mm ld me mf mg mh bi translated"><a class="ae mn" href="https://medium.com/@tyagigaurika27/nlp-topic-modeling-to-identify-clusters-ca207244d04f" rel="noopener">使用潜在狄利克雷分配(LDA)的主题建模</a></li><li id="6b61" class="lx ly it kk b kl mi ko mj kr mk kv ml kz mm ld me mf mg mh bi translated"><a class="ae mn" href="https://medium.com/@tyagigaurika27/identifying-relationships-in-clinical-text-nlp-clustering-929eb04b5942" rel="noopener">聚类</a></li></ol><blockquote class="mo mp mq"><p id="86b4" class="ki kj le kk b kl km ju kn ko kp jx kq mr ks kt ku ms kw kx ky mt la lb lc ld im bi translated">如果您想<strong class="kk iu">亲自尝试整个代码或跟随，请</strong>访问我在 GitHub 上发布的 jupyter 笔记本:<a class="ae mn" href="https://github.com/gaurikatyagi/Natural-Language-Processing/blob/master/Introdution%20to%20NLP-Clustering%20Text.ipynb" rel="noopener ugc nofollow" target="_blank">https://GitHub . com/gaurikatyagi/Natural-Language-Processing/blob/master/introduction % 20 to % 20 NLP-Clustering % 20 text . ipynb</a></p></blockquote><h1 id="167e" class="lf lg it bd lh li lj lk ll lm ln lo lp jz lq ka lr kc ls kd lt kf lu kg lv lw bi translated">数据:</h1><p id="4106" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mu kt ku kv mv kx ky kz mw lb lc ld im bi translated">来源:<a class="ae mn" href="https://mimic.physionet.org/about/mimic/" rel="noopener ugc nofollow" target="_blank">https://mimic.physionet.org/about/mimic/</a></p><p id="8e30" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">医生在他们的电脑上做笔记，80%的记录是没有结构的。这使得信息处理更加困难。我们不要忘记，解释医疗术语也不是一件容易的事情。它需要大量的上下文来解释。让我们看看我们有什么:</p><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi mx"><img src="../Images/41819305195cbfdfcaf6aaee80150983.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*njHwI4RWEKNw_cRxZhizrA.png"/></div></div><p class="nj nk gj gh gi nl nm bd b be z dk translated">按作者分类的图像:作为输入的文本数据</p></figure><p id="77be" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们立即注意到的事情:</p><ol class=""><li id="79f9" class="lx ly it kk b kl km ko kp kr nn kv no kz np ld me mf mg mh bi translated">这是没有标记的纯文本。如果它有标记，我们可以使用像<a class="ae mn" href="https://www.pythonforbeginners.com/beautifulsoup/beautifulsoup-4-python" rel="noopener ugc nofollow" target="_blank">美丽的汤</a>这样的库</li><li id="d4a5" class="lx ly it kk b kl mi ko mj kr mk kv ml kz mm ld me mf mg mh bi translated">这些行被人工换行(每当您看到单个\n</li><li id="3868" class="lx ly it kk b kl mi ko mj kr mk kv ml kz mm ld me mf mg mh bi translated">没有错别字..哇哦，但是太多首字母缩写和大写字母了</li><li id="84de" class="lx ly it kk b kl mi ko mj kr mk kv ml kz mm ld me mf mg mh bi translated">有像逗号、撇号、引号、问号这样的标点，还有像“后续”这样的连字符描述</li><li id="217d" class="lx ly it kk b kl mi ko mj kr mk kv ml kz mm ld me mf mg mh bi translated">使用了大量有序数据，因此出现了“1”, '2.'诸如此类。但是，请注意，即使在这些数字之前，实际上也有一个单线制动(如 2 中所示)</li><li id="d6a3" class="lx ly it kk b kl mi ko mj kr mk kv ml kz mm ld me mf mg mh bi translated">看看那些不确定的名字是如何被替换成“姓”或“名 3”，“医院病房名”之类的，好在这些都在方括号内，很容易识别。这些后面也总是跟着一个括号。耶！一些我们可以从一开始就去除的东西！</li><li id="1a38" class="lx ly it kk b kl mi ko mj kr mk kv ml kz mm ld me mf mg mh bi translated">注意可能需要如何处理日期(如果它们都不是相同的格式)</li><li id="1f4b" class="lx ly it kk b kl mi ko mj kr mk kv ml kz mm ld me mf mg mh bi translated">注意一些格式:比如:\n\n <strong class="kk iu"> *** </strong> \n\n 或者 n？？？？？？\tT。我们需要处理好这一切</li></ol><h1 id="f2b1" class="lf lg it bd lh li lj lk ll lm ln lo lp jz lq ka lr kc ls kd lt kf lu kg lv lw bi translated">1.预处理</h1><p id="7584" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mu kt ku kv mv kx ky kz mw lb lc ld im bi translated">a.<strong class="kk iu">正则表达式</strong>:我们将使用正则表达式模式来清理我们的文本。<em class="le">是的，我们确实需要多次反复的清理！</em></p><figure class="my mz na nb gt nc"><div class="bz fp l di"><div class="nq nr l"/></div><p class="nj nk gj gh gi nl nm bd b be z dk translated">图片作者:Regex Cleaning</p></figure><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi ns"><img src="../Images/e96f86885cdf97068a4a06cdcf187c71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6By0pgZe7aNsuZXwq5H3HQ.png"/></div></div><p class="nj nk gj gh gi nl nm bd b be z dk translated">作者图片:正则表达式清理的输出</p></figure><p id="7a06" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">b.<strong class="kk iu">添加</strong> <strong class="kk iu"> Context 和 Lemmatize text: </strong>看，我们是怎么讲 Lemmatize 和 not stemming 的。理解两个之间的<a class="ae mn" href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html" rel="noopener ugc nofollow" target="_blank">差异很重要。</a></p><p id="9ab7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本节中，我们使用大写单词提取“潜在主题”来识别图表中的子主题。然后，专家手动将这些短语标记为“T”或“F”，以表示<em class="le">接受</em>。一旦我们有了它，我们就改变了所有其他单词的大小写。等等，没那么容易，记住我们需要把它归类。</p><figure class="my mz na nb gt nc"><div class="bz fp l di"><div class="nq nr l"/></div><p class="nj nk gj gh gi nl nm bd b be z dk translated">作者图片:<a class="ae mn" href="https://gist.github.com/gaurikatyagi/c0546c357f181da82be8d4493a8b68ed#file-adding-subsections-with-context" rel="noopener ugc nofollow" target="_blank">为上下文添加子部分</a></p></figure><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi nt"><img src="../Images/e059a6041e7fb8bebd70e9e50c91d67f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3r4AgmMXJNIMAYOmuTfV7g.png"/></div></div><p class="nj nk gj gh gi nl nm bd b be z dk translated">作者图片:确定了 124 个副标题</p></figure><p id="ddf2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，我们将把所有大写单词的大小写改为小写，除非它们是上面确定的主题</p><p id="a3b8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通过运行 lemmatizer <strong class="kk iu">找到上述所有主题的<strong class="kk iu">词条</strong>。我们删除了主题中的停用词，以便在“大写单词列表”</strong>中捕捉更多的主题。</p><figure class="my mz na nb gt nc"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="b695" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">那么，这里发生了什么变化？</p><pre class="my mz na nb gt nu nv nw nx aw ny bi"><span id="15ce" class="nz lg it nv b gy oa ob l oc od">for index in range(len(lemmatized_topics_index)):<br/>    print("Original Topic: %s \n New Topic Index: %s\n New Topic value: %s"%(topics[index],                                                                                       lemmatized_topics_index[index],                                                                lemmatized_topics_values[index]<br/>)<br/>)<br/>    ##you can remove this to see all pairs<br/>    if index&gt;2:<br/>        break<br/>    print("\n\n")</span></pre><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi oe"><img src="../Images/32c03669f10d5911b2a014e81eb2590f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m9fbPXJW_X3KU-o8EDu5sA.png"/></div></div><p class="nj nk gj gh gi nl nm bd b be z dk translated">作者图片:词汇化和词干化的区别</p></figure><p id="0f9d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">比较每个主题的词干，如果与词条化主题的词干不匹配，则将其改为小写。</em></p><blockquote class="of"><p id="2a39" class="og oh it bd oi oj ok ol om on oo ld dk translated">为什么先做词条解释，然后只匹配词干？因为词汇化是根据单词属于哪个词类来完成的。然而，词干提取只是试图通过去除常见的复数(etc)字母来找到单词的词根。</p><p id="9d2a" class="og oh it bd oi oj ok ol om on oo ld dk translated">因此，我们与词干部分进行比较，但保留已识别主题的词汇作为最终主题。这甚至允许我们在不同的图表注释中获得标准化的主题</p></blockquote><figure class="op oq or os ot nc"><div class="bz fp l di"><div class="nq nr l"/></div></figure><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi ou"><img src="../Images/23852ba56309de963643fb3b2a75ffd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gTM7BngIFqqQ9fWb7Ud7Gg.png"/></div></div><p class="nj nk gj gh gi nl nm bd b be z dk translated">作者图片:已清理主题</p></figure><p id="e242" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里是我们最终的主题列表，分析师可以使用 Spacy 中的 spans 来解析和提取所需的信息。这不是很好吗！</p><p id="3809" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae mn" href="https://medium.com/@tyagigaurika27/text-summarization-for-clustering-documents-2e074da6437a" rel="noopener">在我的下一篇文章</a>中，我将谈论<strong class="kk iu">文本摘要。</strong></p></div></div>    
</body>
</html>