<html>
<head>
<title>Amsterdam Airbnb dataset: An End-to-End Project</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">阿姆斯特丹Airbnb数据集:一个端到端的项目</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-end-to-end-data-science-project-that-will-boost-your-portfolio-c53cfe16f0e3?source=collection_archive---------9-----------------------#2020-01-09">https://towardsdatascience.com/an-end-to-end-data-science-project-that-will-boost-your-portfolio-c53cfe16f0e3?source=collection_archive---------9-----------------------#2020-01-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><blockquote class="jq jr js"><p id="1ae8" class="jt ju jv jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr im bi translated">一个数据科学组合项目就像为你的驾驶执照实践考试而学习，你不是在学习驾驶，而是在学习如何通过考试。</p></blockquote><p id="df61" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">准备作品集时，重要的是要有涵盖不同领域、技术并能讲述一个故事的项目。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi kv"><img src="../Images/6f3182fb952a0c0d6944eb84d82494c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PowhmlLED2SygWtUaX7y4Q.jpeg"/></div></div><p class="lh li gj gh gi lj lk bd b be z dk translated">Chait Goli在pexels.com拍摄的照片</p></figure><p id="5d84" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi ll translated"><span class="l lm ln lo bm lp lq lr ls lt di">在本文中，我的主要目标是展示我将如何做一个数据科学组合项目，该项目涵盖可视化、数据预处理、建模和最终考虑以及生产建议。</span></p><p id="600a" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">给定一系列<strong class="jw iu"> </strong>预测因素，我使用<a class="ae lu" href="https://www.kaggle.com/adityadeshpande23/amsterdam-airbnb" rel="noopener ugc nofollow" target="_blank">阿姆斯特丹Airbnb数据集</a>预测一套公寓的价格。</p><h1 id="45b7" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">简介:</h1><p id="4e47" class="pw-post-body-paragraph jt ju it jw b jx mt jz ka kb mu kd ke ks mv kh ki kt mw kl km ku mx kp kq kr im bi translated">数据集一旦导入Python，就会使用<code class="fe my mz na nb b"><a class="ae lu" href="https://github.com/pandas-profiling/pandas-profiling" rel="noopener ugc nofollow" target="_blank">pandas_profiling</a></code>进行分析，这是一个非常有用的工具，它扩展了pandas中的<code class="fe my mz na nb b">df.info()</code>功能。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi nc"><img src="../Images/ed69b9bb4146ce7ae1165c00bccd962e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UJzAdx0fx_HY1pfOJ6ivRw.png"/></div></div><p class="lh li gj gh gi lj lk bd b be z dk translated">报告的第一部分</p></figure><p id="0b9a" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">如报告中所述，数据集包含14个变量，10个是数字变量，2个是分类变量(建模时，我们<em class="jv">可能</em>需要为这些变量获取虚拟变量)。</p><p id="bae5" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">此外，根据报告变量<code class="fe my mz na nb b">host_listings_count</code>和<code class="fe my mz na nb b">calculated_host_listings_count</code>与0.94的皮尔逊分数高度相关，因此我们将放弃前者以避免<a class="ae lu" href="https://en.wikipedia.org/wiki/Multicollinearity" rel="noopener ugc nofollow" target="_blank">多重共线性</a>问题。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/c5767a9708ee5a9da7a32f406a855a8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*uua4Y1WIEtsOlx6gklmcdw.png"/></div></figure><p id="3e06" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">我们可以看到我们的目标变量<code class="fe my mz na nb b">price</code>不是一个数字，让我们看看最长的一个，以便了解是否有任何格式需要在转换前删除:</p><pre class="kw kx ky kz gt ne nb nf ng aw nh bi"><span id="43ed" class="ni lw it nb b gy nj nk l nl nm">max(df[‘price’].values, key = len)</span><span id="3abb" class="ni lw it nb b gy nn nk l nl nm">&gt;&gt;&gt; '$1,305.00'</span></pre><p id="cf7b" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">首先，我们可以看到我们的目标变量有2个不同的字符需要去掉，即符号<code class="fe my mz na nb b">$</code>和识别千位的逗号。让我们用<code class="fe my mz na nb b">df.apply()</code>来摆脱它们。</p><pre class="kw kx ky kz gt ne nb nf ng aw nh bi"><span id="69b5" class="ni lw it nb b gy nj nk l nl nm">df[‘price’] = df[‘price’].apply(lambda x: x.replace(‘$’, ‘’))<br/>df[‘price’] = df[‘price’].apply(lambda x: x.replace(‘,’, ‘’))</span><span id="4b80" class="ni lw it nb b gy nn nk l nl nm">df[‘price’] = pd.to_numeric(df[‘price’])</span></pre><h1 id="4e38" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">数据可视化:</h1><p id="6074" class="pw-post-body-paragraph jt ju it jw b jx mt jz ka kb mu kd ke ks mv kh ki kt mw kl km ku mx kp kq kr im bi translated">数据集有两列，包含公寓所在位置的坐标信息，此外还有我们的目标变量。因此，我们可以创建一个热图，以更好地了解公寓的位置以及价格如何受到位置的影响</p><p id="f90c" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">为了实现这一点，我们将使用<code class="fe my mz na nb b"><a class="ae lu" href="https://pypi.org/project/gmaps/" rel="noopener ugc nofollow" target="_blank">gmaps</a></code>，一个使用谷歌地图创建交互式地图的python包。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi no"><img src="../Images/4d4f410e1a5768b9f05093407c14b569.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*81UqjlcIHagTREm78mf40Q.png"/></div></div><p class="lh li gj gh gi lj lk bd b be z dk translated">使用GMaps的热图示例</p></figure><p id="ce17" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">你可以使用免费版本，没有API密钥，但是，你会得到带有难看的“仅供开发”水印的地图，如果你想消除这些水印，你可以注册(通过添加信用卡)到谷歌云平台，并申请免费积分。点击此处了解更多信息。</p><blockquote class="jq jr js"><p id="4480" class="jt ju jv jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr im bi translated">请小心使用API键，尤其是如果你想在线共享你的项目。(在把笔记本推给GitHub之前，我禁用了我的键🙃)</p></blockquote><p id="0cf4" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">您可以在Jupyter笔记本上安装<code class="fe my mz na nb b">gmaps</code>,首先通过终端<code class="fe my mz na nb b">ipywidgets</code>扩展启用:</p><p id="7b4c" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated"><code class="fe my mz na nb b">$ jupyter nbextension enable — py — sys-prefix widgetsnbextension</code></p><p id="dbcd" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">然后:</p><p id="8e01" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated"><code class="fe my mz na nb b">$ pip install gmaps</code></p><p id="1749" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">最后，用以下代码加载扩展:</p><p id="73da" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated"><code class="fe my mz na nb b">$ jupyter nbextension enable — py — sys-prefix gmaps</code></p><p id="a44f" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">用<code class="fe my mz na nb b">gmaps</code>创建热图很简单，我们指定一个<code class="fe my mz na nb b">Map</code>对象，然后传递带有坐标和权重的数据帧。</p><pre class="kw kx ky kz gt ne nb nf ng aw nh bi"><span id="99bf" class="ni lw it nb b gy nj nk l nl nm">fig = gmaps.Map(layout={‘width’: ‘1000px’, ‘height’: ‘500px’, ‘padding’: ‘10px’})</span><span id="3d18" class="ni lw it nb b gy nn nk l nl nm">fig.add_layer(gmaps.heatmap_layer(df[[‘latitude’, ‘longitude’]],<br/> weights=df[‘price’]))</span><span id="6b59" class="ni lw it nb b gy nn nk l nl nm">fig</span></pre><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi np"><img src="../Images/6933f9f860157065536f2d49e238740d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DR0nViUpJpx1B508K1jMqw.png"/></div></div><p class="lh li gj gh gi lj lk bd b be z dk translated">名词（noun的缩写）如果你安装了gmaps，并做了所有正确的事情，但地图没有显示，只需重新启动jupyter笔记本，它将(很可能)工作！</p></figure><p id="cca5" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">地图显示，市中心的位置更贵，而郊区更便宜(这种模式可能不仅仅存在于阿姆斯特丹)。另外，市中心似乎也有自己的格局。</p><p id="5adf" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">为了捕捉一些地理模式，我们需要应用一些特征工程，一个很好的方法是找到一个兴趣点(POI)列表，并计算每个观察值和POI之间的距离。</p><blockquote class="jq jr js"><p id="037e" class="jt ju jv jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr im bi translated">如果我们知道一个特定的地点离我们认为很贵的地方很近，很可能整个周边地区都会很贵。</p></blockquote><p id="f1c3" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">为了计算以千米为单位的距离，我使用了一个函数来检索<a class="ae lu" href="https://en.wikipedia.org/wiki/Haversine_formula" rel="noopener ugc nofollow" target="_blank">哈弗线距离</a>，也就是球体上两点之间的距离。</p><p id="51ef" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">这种度量有其利弊:它提供了一种计算两点之间距离的简单方法，但它没有考虑建筑物、湖泊、河流、边界等障碍。</p><p id="3640" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">为了得到一个兴趣点的列表，我在谷歌上搜索，我搜索了每个兴趣点的地理坐标。</p><p id="2c26" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">结果如下:</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/aeda2bafceb9a7a1a9a59d7bac44f716.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*QO09B0mY5351Txr04ucE-w.png"/></div></figure><p id="3e2d" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">现在可以定义一个函数来计算一个房屋到每个POI的距离:</p><pre class="kw kx ky kz gt ne nb nf ng aw nh bi"><span id="ab0e" class="ni lw it nb b gy nj nk l nl nm">from math import radians, cos, sin, asin, sqrt</span><span id="87a7" class="ni lw it nb b gy nn nk l nl nm">def haversine(lon1, lat1, lon2, lat2):<br/> “””<br/> Calculate the great circle distance between two points <br/> on the earth (specified in decimal degrees)<br/> “””<br/> # convert decimal degrees to radians <br/> lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])<br/> # haversine formula <br/> dlon = lon2 — lon1 <br/> dlat = lat2 — lat1 <br/> a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2<br/> c = 2 * asin(sqrt(a)) <br/> km = 6367 * c<br/> return km</span></pre><p id="135d" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">现在，我们可以迭代数据集的每一行，对于每一行，我们迭代我们的POI数据帧，并计算每个POI的距离(我说了太多次“每个”或“POI”了吗？)</p><p id="ef74" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">现在让我们用poi再次绘制我们的地图，我们可以通过迭代<code class="fe my mz na nb b">poi</code>数据帧的每一行并使用列表理解创建一个元组来做到这一点:</p><pre class="kw kx ky kz gt ne nb nf ng aw nh bi"><span id="5b8d" class="ni lw it nb b gy nj nk l nl nm">fig.add_layer(gmaps.symbol_layer([tuple(x) for x in poi.to_numpy()]<br/> , fill_color=’green’, stroke_color=’green’))<br/>fig</span></pre><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi nr"><img src="../Images/3d2edc7db15d388b24f760add5c4e629.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_ZMfCndG2Gd164O2WkgFDg.png"/></div></div></figure><p id="9204" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">从可视化中可以看出，Willemspark附近的公寓比周围地区少得多，此外，大多数poi都位于“昂贵”区域，尤其是Dam Square区域周围。</p><h1 id="74c0" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">建模:</h1><p id="8fc1" class="pw-post-body-paragraph jt ju it jw b jx mt jz ka kb mu kd ke ks mv kh ki kt mw kl km ku mx kp kq kr im bi translated">现在让我们开始建模部分，我们将通过对分类变量<code class="fe my mz na nb b">room_type</code>进行编码并将其分为训练和测试来准备数据集</p><pre class="kw kx ky kz gt ne nb nf ng aw nh bi"><span id="9179" class="ni lw it nb b gy nj nk l nl nm">df = pd.get_dummies(df)</span><span id="cb52" class="ni lw it nb b gy nn nk l nl nm">X = df.drop([‘price’], axis=1)<br/>y = df[‘price’]</span><span id="e09c" class="ni lw it nb b gy nn nk l nl nm">from sklearn.model_selection import train_test_split</span><span id="1cd0" class="ni lw it nb b gy nn nk l nl nm">X_train, X_test, y_train, y_test = train_test_split(<br/> X, y, test_size=0.2, random_state=1)</span></pre><p id="f27f" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">数据集在训练和测试之间分成80–20%。</p><h1 id="9549" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">基线模型📏：</h1><p id="87f4" class="pw-post-body-paragraph jt ju it jw b jx mt jz ka kb mu kd ke ks mv kh ki kt mw kl km ku mx kp kq kr im bi translated">使用的第一个模型将用作基线，因为我们需要一个基准来评估其他模型的性能并比较结果。</p><p id="4e3d" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">它包括一个经典的线性回归，使用<code class="fe my mz na nb b">r2</code>和<code class="fe my mz na nb b">MAE</code>指标上的<code class="fe my mz na nb b">GridSearchCV</code>类进行交叉验证评估。</p><p id="28aa" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">让我们来适应它:</p><pre class="kw kx ky kz gt ne nb nf ng aw nh bi"><span id="9b19" class="ni lw it nb b gy nj nk l nl nm">from sklearn.linear_model import LinearRegression</span><span id="a317" class="ni lw it nb b gy nn nk l nl nm">lin_reg = LinearRegression()</span><span id="0131" class="ni lw it nb b gy nn nk l nl nm">lin_reg.fit(X_train, y_train)<br/>y_pred = lin_reg.predict(X_test)</span></pre><p id="bc54" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">现在，我们可以通过创建虚拟数据帧来存储每个模型的结果，从而计算r2和MAE误差:</p><pre class="kw kx ky kz gt ne nb nf ng aw nh bi"><span id="d20f" class="ni lw it nb b gy nj nk l nl nm">from sklearn import metrics</span><span id="7590" class="ni lw it nb b gy nn nk l nl nm">r2 = metrics.r2_score(y_test, y_pred)<br/>mae = metrics.mean_absolute_error(y_test, y_pred)</span><span id="e985" class="ni lw it nb b gy nn nk l nl nm">scores = pd.DataFrame({‘Baseline (regression)’ : [r2, mae]}, index=[‘R2’, ‘MAE’])</span><span id="7019" class="ni lw it nb b gy nn nk l nl nm">scores</span></pre><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/3444d0c86dcf8776ea39e106039a2f7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*d7lW6Z379haIFdztVRhz6g.png"/></div></figure><p id="3112" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated"><code class="fe my mz na nb b">mae</code>告诉我们，我们的预测平均相差40美元，而R2告诉我们，我们的数据相当稀疏。</p><p id="5491" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">以图形方式评估回归结果的一个有趣的图是测试集和预测值相对于我们的测试集的差异:</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi nt"><img src="../Images/1e9a232f85bb6b83139e4ca3b978bf65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ikfSP7MiVRsRMARBBi08Rw.png"/></div></div><p class="lh li gj gh gi lj lk bd b be z dk translated">理想情况下，我们希望看到我们的结果越稀疏越好，以45°穿过图</p></figure><p id="19ef" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">这些值越接近0越好，因为delta <code class="fe my mz na nb b">y_test — y_pred</code>应该是<em class="jv">理想的是</em> 0。</p><h2 id="518e" class="ni lw it bd lx nu nv dn mb nw nx dp mf ks ny nz mj kt oa ob mn ku oc od mr oe bi translated">支持向量机模型📈：</h2><p id="ecd6" class="pw-post-body-paragraph jt ju it jw b jx mt jz ka kb mu kd ke ks mv kh ki kt mw kl km ku mx kp kq kr im bi translated">根据sklearn <a class="ae lu" href="https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html" rel="noopener ugc nofollow" target="_blank">地图</a>选择了下一个模型，它由一个支持向量机组成。然而，由于使用参数并不总是容易，而且可能需要特定的知识<code class="fe my mz na nb b">GridSearchCV</code>将会有所帮助:</p><pre class="kw kx ky kz gt ne nb nf ng aw nh bi"><span id="0550" class="ni lw it nb b gy nj nk l nl nm">if 'svr_gridsearch_cv.pkl' in os.listdir():<br/>    <br/>    svr_grid_search = joblib.load('svr_gridsearch_cv.pkl')<br/>    <br/>else:<br/>    <br/>    from sklearn.svm import SVR</span><span id="2367" class="ni lw it nb b gy nn nk l nl nm">svr = SVR()</span><span id="cc48" class="ni lw it nb b gy nn nk l nl nm">param_grid = [<br/>      {'C': [1, 10, 100, 1000], 'kernel': ['linear']},<br/>      {'C': [1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001], 'kernel': ['rbf']}]</span><span id="bd25" class="ni lw it nb b gy nn nk l nl nm">svr_grid_search = GridSearchCV(svr, param_grid=param_grid, <br/>                                   n_jobs=-1, <br/>                                   scoring=['r2', 'neg_mean_squared_error'],<br/>                                  refit='neg_mean_squared_error', verbose=100)</span><span id="c320" class="ni lw it nb b gy nn nk l nl nm">svr_grid_search.fit(X_train, y_train)</span><span id="bb7a" class="ni lw it nb b gy nn nk l nl nm">joblib.dump(svr_grid_search.best_estimator_, 'svr_gridsearch_cv.pkl')</span></pre><p id="37eb" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">请注意，这项任务可能需要40多分钟，这就是为什么在拟合之前，我会检查模型是否已经存在，如果存在，我会加载它。</p><p id="78cd" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">然后，我们将再次根据来自<code class="fe my mz na nb b">GridSearchCV</code>的最佳参数来预测和计算我们的指标</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi of"><img src="../Images/c4fb759d2c0edc6e4e6492e0b1683fdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*ennGyoilYCS7wDWsdbTUkw.png"/></div><p class="lh li gj gh gi lj lk bd b be z dk translated">使用支持向量机，我们已经从我们的基本模型进行了改进。</p></figure><p id="d8ea" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">与我们的基准模型相比，<code class="fe my mz na nb b">mae</code>平均降低了近4美元。</p><p id="dd9c" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">让我们也为这个模型绘制预测值与误差增量的关系图:</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi og"><img src="../Images/e2c22138964cf84d495b927606ddd472.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sfke3vWmUuz2CZMXI4zSjQ.png"/></div></div><p class="lh li gj gh gi lj lk bd b be z dk translated">与前一个相比，预测不那么稀疏，这解释了R2的小幅增长。</p></figure><h2 id="45bf" class="ni lw it bd lx nu nv dn mb nw nx dp mf ks ny nz mj kt oa ob mn ku oc od mr oe bi translated">梯度推进树模型🌲：</h2><p id="8291" class="pw-post-body-paragraph jt ju it jw b jx mt jz ka kb mu kd ke ks mv kh ki kt mw kl km ku mx kp kq kr im bi translated">我们将测试的第三个模型是基于随机梯度下降的，我将使用<a class="ae lu" href="https://lightgbm.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> <strong class="jw iu"> LightGBM </strong> </a>，这是微软的一个库，在行业中广泛使用，是赢得Kaggle竞赛最常用的<a class="ae lu" href="https://www.kaggle.com/milesh1/kaggle-s-most-popular-python-and-r-packages" rel="noopener ugc nofollow" target="_blank">库之一。</a></p><pre class="kw kx ky kz gt ne nb nf ng aw nh bi"><span id="53ba" class="ni lw it nb b gy nj nk l nl nm">if 'gbm_gridsearch_cv.pkl' in os.listdir():<br/>    <br/>    gbm_grid_search = joblib.load('gbm_gridsearch_cv.pkl')<br/>    <br/>else:<br/>    <br/>    from lightgbm import LGBMRegressor</span><span id="d9ee" class="ni lw it nb b gy nn nk l nl nm">gbm = LGBMRegressor()</span><span id="7e9d" class="ni lw it nb b gy nn nk l nl nm">param_grid = {<br/>    'learning_rate': [0.01, 0.1, 1],<br/>    'n_estimators': [50, 100, 150],<br/>    'boosting_type': ['gbdt', 'dart'],<br/>    'num_leaves': [15, 31, 50]}</span><span id="bffc" class="ni lw it nb b gy nn nk l nl nm">gbm_grid_search = GridSearchCV(gbm, param_grid=param_grid, <br/>                                   n_jobs=-1, <br/>                                   scoring=['r2', 'neg_mean_squared_error'],<br/>                                  refit='neg_mean_squared_error', verbose=100)</span><span id="145f" class="ni lw it nb b gy nn nk l nl nm">gbm_grid_search.fit(X_train, y_train)</span><span id="c645" class="ni lw it nb b gy nn nk l nl nm">joblib.dump(gbm_grid_search.best_estimator_, 'gbm_gridsearch_cv.pkl')</span></pre><p id="5ba4" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">模型训练相当快，结果一点也不差:</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi oh"><img src="../Images/29f340e22c02b82bd6847c04eb5a9e8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bRF32U6V_-Z9BP49mk2JMw.png"/></div></div></figure><p id="901c" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">到目前为止，表现最好的模型是GBM，它将R2提高了约6%,而<code class="fe my mz na nb b">mae</code>略差。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi oi"><img src="../Images/e9d92cbef243323b916d31e766c941d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EdK4Fk262f3JLK6izaBPlA.png"/></div></div><p class="lh li gj gh gi lj lk bd b be z dk translated">很多差值似乎是负数，这意味着预测值经常高估真实值。</p></figure><h1 id="65bb" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">神经网络🧠:</h1><p id="8f29" class="pw-post-body-paragraph jt ju it jw b jx mt jz ka kb mu kd ke ks mv kh ki kt mw kl km ku mx kp kq kr im bi translated">在考虑如何进一步改进我们的回归变量时，我首先想到的显然是神经网络！所以我决定实现一个简单的方法:</p><pre class="kw kx ky kz gt ne nb nf ng aw nh bi"><span id="067c" class="ni lw it nb b gy nj nk l nl nm">def build_model():<br/> model = keras.Sequential([<br/> <!-- -->tf.keras.<!-- -->layers.Dense(64, activation=’relu’, input_shape=(25,)), <br/> <!-- -->tf.keras.<!-- -->layers.Dropout(0.2), <br/> <!-- -->tf.keras.<!-- -->layers.Dense(128, activation=’relu’),<br/> <!-- -->tf.keras.<!-- -->layers.Dropout(0.2), <br/> <!-- -->tf.keras.<!-- -->layers.Dense(1)<br/> ])</span><span id="dbe6" class="ni lw it nb b gy nn nk l nl nm">optimizer = <!-- -->tf.keras.optimizers.RMSprop(0.001)</span><span id="c95f" class="ni lw it nb b gy nn nk l nl nm">model.compile(loss=’mean_squared_error’,<br/> optimizer=optimizer,<br/> metrics=[‘mae’, r2_keras])<br/> return model</span></pre><p id="7c1c" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">然而，在玩了一会儿并运行了100个纪元后，结果并不特别令人惊讶:</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi oj"><img src="../Images/a648df37aadac55381a985a3350a25bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3R_KReuBjRtQpPOnVQb_iw.png"/></div></div></figure><p id="da8d" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">结果基本上是GBM和SVR之间的平均值，并且绘制误差给出了与之前非常相似的图。</p><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi ok"><img src="../Images/9c650729d5e12e0759f7eed91399401c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yct8mHGJn8TJaomS1h0dTA.png"/></div></div></figure><h1 id="0d72" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated"><strong class="ak">那么哪个才是最好的模式呢？</strong></h1><p id="37b8" class="pw-post-body-paragraph jt ju it jw b jx mt jz ka kb mu kd ke ks mv kh ki kt mw kl km ku mx kp kq kr im bi translated">尽管已经有了模型性能的度量标准，但是为了给出哪个模型被认为是最佳的最终评估，有必要添加其他评估度量标准，例如实现模型所需的资源和训练模型所需的时间。</p><p id="c897" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">考虑第二个模型SVR:它表现异常，实现了最好的MAE，但是实现网格搜索的训练时间花费了40多分钟，这意味着每次想要检查或更改某个东西都至少要花费40分钟。</p><p id="b68f" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">第三个模型(梯度推进树)，花了几秒钟来拟合，结果相当好，实际上达到了整体最好的结果。</p><p id="aabf" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">考虑到最后一个模型，神经网络，它也没有花太多时间来训练，几分钟，但是，结果并没有从根本上优于以前的模型，实际上，它的表现或多或少是相同的，可能是因为我没有选择正确的超参数，可能是因为数据量，可能是因为其他多种原因，但是，它并没有从根本上优于以前的模型。</p><p id="a626" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">此外，这是一个不太容易解释的模型，这意味着我们很难解释预测是如何决定的，而例如，对于线性回归，我们可以拥有所有数据，如截距和系数:</p><pre class="kw kx ky kz gt ne nb nf ng aw nh bi"><span id="8791" class="ni lw it nb b gy nj nk l nl nm">coefficients = pd.concat([pd.DataFrame(X.columns, columns=['variable']), <br/>pd.DataFrame(np.transpose(lin_reg.coef_), columns ['coefficients'])], axis = 1)</span><span id="c3dd" class="ni lw it nb b gy nn nk l nl nm">coefficients</span></pre><figure class="kw kx ky kz gt la gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/e024a8b25518564a9b04b61ab09575df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*Y0hO-qidOLr8yeQ7H0-e7g.png"/></div><p class="lh li gj gh gi lj lk bd b be z dk translated">我们基线模型的系数</p></figure><h1 id="f4a3" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">总结一下:</h1><p id="700f" class="pw-post-body-paragraph jt ju it jw b jx mt jz ka kb mu kd ke ks mv kh ki kt mw kl km ku mx kp kq kr im bi translated">考虑到前面提到的注意事项，并指出妥协通常是一个很好的近似，我们可以得出结论，根据我们的指标，最佳模型是梯度推进树(LightGBM)，它在一眨眼的时间内训练完毕，结果是其他候选模型中最好的。</p><p id="da91" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">此外，选择机器学习模型提供了一个优势:决策树是一个可解释的模型，可以分解它，并找到它为什么以及如何计算特定的结果，而不是另一个，在树回归器上调用以下方法，可以查看树的图表:</p><pre class="kw kx ky kz gt ne nb nf ng aw nh bi"><span id="6203" class="ni lw it nb b gy nj nk l nl nm">import lightgbm</span><span id="8267" class="ni lw it nb b gy nn nk l nl nm">lightgbm.create_tree_digraph(gbm_grid_search.best_estimator_)</span></pre><figure class="kw kx ky kz gt la gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi om"><img src="../Images/36901cc0c5cc021da977dcd617662126.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MHtJJMWdijwryiDJekGbTQ.png"/></div></div></figure><p id="849a" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">XAI或可解释的人工智能是现代数据科学的一个非常重要的方面，它专注于如何实现特定的预测，而不是将模型视为黑盒。</p><p id="360f" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">引用波恩大学的一篇论文:</p><blockquote class="jq jr js"><p id="db60" class="jt ju jv jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr im bi translated">获得科学成果的先决条件是领域知识，这是获得可解释性以及增强科学一致性所必需的。</p></blockquote><p id="f7d7" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke ks kg kh ki kt kk kl km ku ko kp kq kr im bi translated">[*] Ribana Roscher，Bastian Bohn，Marco F. Duarte和Jochen Garcke，<a class="ae lu" href="https://arxiv.org/pdf/1905.08883.pdf" rel="noopener ugc nofollow" target="_blank">科学见解和发现的可解释机器学习</a> (2019)。</p></div><div class="ab cl on oo hx op" role="separator"><span class="oq bw bk or os ot"/><span class="oq bw bk or os ot"/><span class="oq bw bk or os"/></div><div class="im in io ip iq"><pre class="kw kx ky kz gt ne nb nf ng aw nh bi"><span id="8eaf" class="ni lw it nb b gy nj nk l nl nm"><strong class="nb iu">I have a newsletter 📩.</strong></span><span id="9ae7" class="ni lw it nb b gy nn nk l nl nm">Every week I’ll send you a brief findings of articles, links, tutorials, and cool things that caught my attention. If tis sounds cool to you subscribe.</span><span id="16f2" class="ni lw it nb b gy nn nk l nl nm"><em class="jv">That means </em><strong class="nb iu"><em class="jv">a lot</em></strong><em class="jv"> for me.</em></span></pre><div class="ou ov gp gr ow ox"><a href="https://relentless-creator-2481.ck.page/68d9def351" rel="noopener  ugc nofollow" target="_blank"><div class="oy ab fo"><div class="oz ab pa cl cj pb"><h2 class="bd iu gy z fp pc fr fs pd fu fw is bi translated">米尔斯形式</h2><div class="pe l"><h3 class="bd b gy z fp pc fr fs pd fu fw dk translated">编辑描述</h3></div><div class="pf l"><p class="bd b dl z fp pc fr fs pd fu fw dk translated">无情-创造者-2481.ck.page</p></div></div></div></a></div></div></div>    
</body>
</html>