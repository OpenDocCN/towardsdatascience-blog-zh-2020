<html>
<head>
<title>Label Propagation Demystified</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">标签传播去神秘化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/label-propagation-demystified-cd5390f27472?source=collection_archive---------4-----------------------#2020-03-06">https://towardsdatascience.com/label-propagation-demystified-cd5390f27472?source=collection_archive---------4-----------------------#2020-03-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9cfb" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">基于图的标签传播的简单介绍</h2></div><p id="49c9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">社交媒体网络已经遍布全球，并且与日俱增。考虑一个社交媒体网络，你知道一些人的兴趣，你想预测其他人的兴趣，这样我们就可以有针对性地开展营销活动。为此，我们可以使用基于图的半监督机器学习技术，称为<strong class="kk iu">标签传播</strong>。在本文中，我将通过一些例子和样本代码来解释标签传播过程。</p><h1 id="95c1" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">什么是标签传播？</h1><p id="7315" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated"><strong class="kk iu">标签传播算法(LPA) </strong>是一种迭代算法，其中我们通过在数据集内传播标签来将标签分配给未标记的点。该算法由<strong class="kk iu">小金朱</strong>和<strong class="kk iu">邹斌·格拉马尼</strong>【1】于2002年<strong class="kk iu"/>首次提出。LPA属于<strong class="kk iu">直推学习</strong>，因为我们想要预测已经给我们的未标记数据点的标签。</p><p id="2368" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">假设我们有一个如下所示的人的网络，有两个标签类别“<em class="mb">对板球感兴趣</em>”和“<em class="mb">对板球不感兴趣</em>”。那么问题来了，我们能预测剩下的人是否对板球感兴趣吗？</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi mc"><img src="../Images/b50fa54b9a41c51d85bc29abd41b94a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GpbGmXXvoABu3ezRiDsx1A.png"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">来自<a class="ae ms" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3846597" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae ms" href="https://pixabay.com/users/GDJ-1086657/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3846597" rel="noopener ugc nofollow" target="_blank"> Gordon Johnson </a>的原始图片。</p></figure><p id="9386" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于LPA在这种情况下的工作，我们必须做一个假设；连接两个节点的边带有相似性的概念。即，如果两个人联系在一起，这意味着这两个人很可能有相同的兴趣。我们可以做出这样的假设，因为人们倾向于和其他有相似兴趣的人联系。</p><h1 id="3692" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">在图中随机行走</h1><p id="86f4" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">考虑图1中给出的示例图，其中我们有2个标签类(红色和绿色)和4个彩色节点(每个类2个)。我们想预测节点4的标签。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi mt"><img src="../Images/27897fb3c4020c3d6a3407289c2a2a2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IH6h0CC_eOHyx2uK1kWgQg.png"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图一。样本图表1</p></figure><p id="4ef1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以在图中随机行走，从节点4开始，直到我们遇到任何标记的节点。当我们碰到一个有标签的节点时，我们停止行走。因此，这些被标记的节点被称为<strong class="kk iu">吸收态</strong>。让我们考虑从节点4开始的所有可能的路径。在所有可能的遍历中，下面的遍历将以绿色节点结束。</p><ol class=""><li id="4d45" class="mu mv it kk b kl km ko kp kr mw kv mx kz my ld mz na nb nc bi">4 → 9 → 15 → 16</li><li id="36ab" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi">4 → 9 → 13 → 14</li><li id="b888" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi">4 → 9 → 13 → 15 → 16</li><li id="f81e" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi">4 → 9 → 15 → 13 → 14</li></ol><p id="5d66" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面的遍历将以红色节点结束。</p><ol class=""><li id="8fd7" class="mu mv it kk b kl km ko kp kr mw kv mx kz my ld mz na nb nc bi">4 → 7 → 8</li><li id="7c57" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi">4 → 7 → 6 → 5 → 1</li><li id="ac0a" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi">4 → 5 → 1</li><li id="b0e2" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi">4 → 5 → 6 → 7 → 8</li><li id="0470" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld mz na nb nc bi">4 → 2 → 1</li></ol><p id="a14a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">基于从节点4开始的所有可能的随机行走，我们可以看到大多数行走都以红色节点结束。所以，我们可以把节点4涂成红色。这是LPA背后的基本直觉。</p><h1 id="fa2f" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">数学公式</h1><p id="5ce8" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">设<code class="fe ni nj nk nl b">Xₗ</code>为被标记节点的集合，<code class="fe ni nj nk nl b">Yₗ</code>为被标记数据的独热标签(如果不了解独热编码，可以参考这个<a class="ae ms" href="https://medium.com/@michaeldelsole/what-is-one-hot-encoding-and-how-to-do-it-f0ae272f1179" rel="noopener">链接</a>)。假设有<code class="fe ni nj nk nl b">{1,…,C}</code>类标签。<code class="fe ni nj nk nl b">Xᵤ</code>是未标注的顶点。我们不知道<code class="fe ni nj nk nl b">Yᵤ</code>，因此<code class="fe ni nj nk nl b">Yᵤ</code>将包含零。</p><p id="3483" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以将随机游走表示如下。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi nm"><img src="../Images/ed04250a1b6778c19234964e75ccd77a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KhENTRcbtASKd9deJmSx2Q.png"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图二。随机漫步</p></figure><p id="aedf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在矩阵形式中，该方程将如下所示。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi nn"><img src="../Images/8ac3ac2662989f5e203097cd3702f011.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qNgarLNnu1l6xtEq3UvbZw.png"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图三。矩阵形式的随机游动</p></figure><p id="0eab" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们可以计算概率转移矩阵<strong class="kk iu"> T </strong>，我们就可以计算所有未标记节点的标记概率。</p><h1 id="2e07" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">如何计算概率转移矩阵？</h1><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi no"><img src="../Images/9b0cb6228c0893dc2c6ff1299f4382d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/format:webp/1*gbSYSINcX1ksWPztSJ8dgA.png"/></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图4。样本图表2</p></figure><p id="6d31" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">考虑如图4所示的具有吸收态的样本图。对于每个节点，我们都要计算跳到其他节点的概率。当我们到达吸收状态时，行走结束，因为我们陷入吸收状态(在图中表示为自循环)。这是一个无向图，所以我们可以向任何方向移动。</p><p id="9d35" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">假设从一个节点转移到其邻居的概率是相等的，我们可以将T写成如下。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi np"><img src="../Images/0b67d173f4bfabd685929681aa8a9929.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XrKs8JMCQ8NLUVs2ZX4eVw.png"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图五。图4中样本图2的矩阵T</p></figure><p id="f167" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从节点1到节点1的概率是1，因为节点1处于吸收状态。从节点1，我们无法到达任何其他节点。因此，从节点1到达其他节点的概率将是0。同样的方法也适用于节点2。</p><p id="aaa4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从节点4，您可以转到节点1、3和5。因此，从节点4移动到节点1、3和5是同样可能的，每个节点的概率为0.33。类似地，从节点5，我们可以移动到节点4和6，每个节点的概率为0.5。</p><p id="cd76" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意，我们可以使用图的度矩阵(D)和邻接矩阵(A ),使用下面的等式来计算T。</p><blockquote class="nq"><p id="ce44" class="nr ns it bd nt nu nv nw nx ny nz ld dk translated"><code class="fe ni nj nk nl b">T = D⁻¹A</code></p></blockquote><p id="c235" class="pw-post-body-paragraph ki kj it kk b kl oa ju kn ko ob jx kq kr oc kt ku kv od kx ky kz oe lb lc ld im bi translated">现在请注意，我们可以拆分矩阵T，如图6所示。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi np"><img src="../Images/abaf3134016c74dde87b46641ec5774f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yUOIpxrP692NVBv7oZt49A.png"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图六。t可以分成4块</p></figure><ul class=""><li id="165a" class="mu mv it kk b kl km ko kp kr mw kv mx kz my ld of na nb nc bi translated">Tₗₗ —从标记节点到标记节点的概率</li><li id="4b88" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld of na nb nc bi translated">Tₗᵤ —从标记节点到未标记节点的概率</li><li id="bb45" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld of na nb nc bi translated">Tᵤₗ —从未标记节点到标记节点的概率</li><li id="10f1" class="mu mv it kk b kl nd ko ne kr nf kv ng kz nh ld of na nb nc bi translated">Tᵤᵤ —从未标记节点到未标记节点的概率</li></ul><p id="5cda" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="mb">注:</em> </strong> Tₗₗ将是一个单位矩阵，而Tₗᵤ将是一个零矩阵，因为我们不能从被标记的节点移出，因为它们是吸收态。</p><p id="a9f1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们将矩阵T乘以<em class="mb"> t </em>倍，然后将<em class="mb"> t </em>送至无穷大(∞)，会发生什么？你可以在MATLAB中输入这个矩阵，得到T ⁰⁰.你会得到这样的结果。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi og"><img src="../Images/99da29baebcaf90ed099c2d7e55a33b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YRUhwiBbS8JmDIY0TGNwGw.png"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图7。t在MATLAB上自乘100次</p></figure><p id="99a1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当你将T提高到更大的幂时，概率将停止变化(达到饱和)并导致稳定的转移概率。您现在可以看到，只有前两列包含非零值，其余列都为零。</p><p id="90b7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以用数学方法描述如下。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi nn"><img src="../Images/c04643b230978a66ee45bb3296bb082d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zK0b1f2yYxo4cjqtVFAAyw.png"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图7。T乘以自身无限倍的公式</p></figure><h1 id="749b" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">获得最终答案</h1><p id="2c73" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">最后，带标签的矩阵看起来像这样，我们可以得到带标签节点的标签向量和不带标签节点的标签向量。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi nm"><img src="../Images/e34890acaa605b189c4430ce0819d0eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pafU2UADMkRUtSX1Z1bl7g.png"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图8。有标号和无标号节点的一键标号公式</p></figure><p id="4ef0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在让我们考虑图4中的示例图2，我们希望预测未标记节点的标签。使用我们的MATLAB结果，我们可以得到如下标签。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi oh"><img src="../Images/2a7a5c5ee9a7e8d588c011c78613f938.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UBMKGpoy7X5GmJ2cqQ-H_g.png"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图九。获取未标记节点的标签</p></figure><p id="6f2f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于每个未标记的节点，我们分配具有最大概率的类别标签。但是，你可以看到节点5有相等的概率是红色和绿色。因此，我们的最终标记图将如图10所示。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi no"><img src="../Images/ba2a20a7703817a8a081232f7bc88eca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/format:webp/1*406IAvbao_cR05Iu1XcYBA.png"/></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图10。样本图的最终标记2</p></figure><h1 id="bcb7" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">示例代码</h1><figure class="md me mf mg gt mh"><div class="bz fp l di"><div class="oi oj l"/></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">带有LPA简单实现的示例代码</p></figure><p id="e73d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你也可以阅读我以前的文章<a class="ae ms" rel="noopener" target="_blank" href="/visualising-graph-data-with-python-igraph-b3cc81a495cf">用Python-igraph可视化图形数据</a>来学习如何用Python表示图形数据。</p><div class="ok ol gp gr om on"><a rel="noopener follow" target="_blank" href="/visualising-graph-data-with-python-igraph-b3cc81a495cf"><div class="oo ab fo"><div class="op ab oq cl cj or"><h2 class="bd iu gy z fp os fr fs ot fu fw is bi translated">用Python-igraph可视化图形数据</h2><div class="ou l"><h3 class="bd b gy z fp os fr fs ot fu fw dk translated">使用CiteSeer数据集介绍python-igraph模块</h3></div><div class="ov l"><p class="bd b dl z fp os fr fs ot fu fw dk translated">towardsdatascience.com</p></div></div><div class="ow l"><div class="ox l oy oz pa ow pb mm on"/></div></div></a></div><h1 id="11fc" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">最后的想法</h1><p id="e46d" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">LPA使用已标记节点的标签作为基础，并试图预测未标记节点的标签。然而，如果初始标记是错误的，这会影响标记传播过程，并且错误的标记可能被传播。为了克服这个问题，标签扩散被引入，其中我们在学习无标签节点的标签的同时也学习有标签节点的标签。这也应用了一些标签修正。你可以从周等人的文章<a class="ae ms" href="https://papers.nips.cc/paper/2506-learning-with-local-and-global-consistency.pdf" rel="noopener ugc nofollow" target="_blank">学习本地和全球一致性</a>中了解更多关于标签传播的信息。</p><p id="dbb8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">希望你觉得这个解释有用。我很想听听你的想法。感谢您的阅读。</p><p id="0496" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">干杯！</p><h1 id="11a4" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">参考</h1><p id="e567" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">[1]朱小金和邹斌·格拉马尼。利用标签传播从有标签和无标签数据中学习。宾夕法尼亚州匹兹堡市卡内基梅隆大学计算机科学学院，技术报告。CMU CALD 2002年2月107日。</p><p id="4751" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[2]网络分析。第十七讲(第一部分)。列昂尼德·茹科夫(<a class="ae ms" href="https://youtu.be/hmashUPJwSQ" rel="noopener ugc nofollow" target="_blank">https://youtu.be/hmashUPJwSQ</a>)教授的图的标号传播。</p></div></div>    
</body>
</html>