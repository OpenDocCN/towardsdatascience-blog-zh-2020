<html>
<head>
<title>14 Popular Evaluation Metrics in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中的14个流行评估指标</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/14-popular-evaluation-metrics-in-machine-learning-33d9826434e4?source=collection_archive---------47-----------------------#2020-06-24">https://towardsdatascience.com/14-popular-evaluation-metrics-in-machine-learning-33d9826434e4?source=collection_archive---------47-----------------------#2020-06-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="01c5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解分类和回归机器学习模型中使用的所有评估指标及其使用sklearn库的实现</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/3d4256e1f9a41b04cf8f0f57cbc49127.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*i28K25Cw2neNUYI2"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae ky" href="https://unsplash.com/@hiteshchoudhary?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Hitesh Choudhary </a>拍摄的照片</p></figure><p id="1bca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">评估度量用于测量机器学习模型的性能。对于一个模型来说，评价指标的正确选择是非常重要的。本文将涵盖分类和回归机器学习模型中使用的所有指标。</p><p id="9e71" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">文章中讨论的评估指标:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/31243a06e90fc2b5f898d98b3f9b8a42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*Z1KQ-ASUqga5AYnboUQUdg.png"/></div></figure><blockquote class="lw"><p id="7d07" class="lx ly it bd lz ma mb mc md me mf lu dk translated">分类模型中使用的指标:</p></blockquote><p id="dd48" class="pw-post-body-paragraph kz la it lb b lc mg ju le lf mh jx lh li mi lk ll lm mj lo lp lq mk ls lt lu im bi translated">对于分类机器学习算法，模型的输出可以是目标类别标签或概率分数。这两种方法使用不同的评估标准。</p><h2 id="3ec7" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">当ML模型的预测是类标签时使用的度量:</h2><blockquote class="ne nf ng"><p id="dd6f" class="kz la nh lb b lc ld ju le lf lg jx lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated"><strong class="lb iu">混乱矩阵:</strong></p></blockquote><p id="6b89" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">混淆矩阵是衡量分类问题性能的最简单的方法。它用于可视化和观察ML模型的预测性能。对于k类分类模型，使用大小为k*k的矩阵来观察预测。对于二元类分类问题，使用标准的2*2大小的矩阵。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/d54e91c4cb57b75d3c97695aa3a28b8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2DiXJjAmOA7LtbkpBGODkg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" rel="noopener" target="_blank" href="/decoding-the-confusion-matrix-bb4801decbb">来源</a>，用于二进制分类的混淆矩阵</p></figure><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="43bd" class="ml mm it nn b gy nr ns l nt nu"><strong class="nn iu">Notations,</strong><br/><strong class="nn iu">TP: True Postive:</strong> Number of Points which are actually positive and predicted to be positive<br/><strong class="nn iu">FN: False Negative: </strong>Number of Points which are actually positive but predicted to be negative<br/><strong class="nn iu">FP: False Positive: </strong>Number of Points which are actually negative but predicted to be positive<br/><strong class="nn iu">TN: True Negative: </strong>Number of Points which are actually negative and predicted to be negative</span></pre><p id="37d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果主对角线上的数字最大，非对角线上的数字最小，则认为ML模型是好的。对于二进制混淆矩阵，<strong class="lb iu"> TP和TN </strong>应该为高，<strong class="lb iu"> FN和FP </strong>应该为低。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="7cf1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不同的问题有不同的指标可供选择:</p><ul class=""><li id="5686" class="nx ny it lb b lc ld lf lg li nz lm oa lq ob lu oc od oe of bi translated">对于癌症诊断的问题，TP应该很高，<strong class="lb iu"> FN应该很低</strong>接近于0。患有癌症的患者不应该被预测为不是癌症，这是FN的情况。</li><li id="a007" class="nx ny it lb b lc og lf oh li oi lm oj lq ok lu oc od oe of bi translated">对于垃圾邮件检测的问题，<strong class="lb iu"> FP应该很低</strong>。不应该将不是垃圾邮件的邮件预测为垃圾邮件。</li></ul><p id="7462" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">什么是一型和二型错误？</strong></p><p id="e18e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第一类错误也称为假阳性(FP)。第二类错误也称为假阴性(FN)。</p><blockquote class="ne nf ng"><p id="41f6" class="kz la nh lb b lc ld ju le lf lg jx lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated"><strong class="lb iu">精度:</strong></p></blockquote><p id="0bf1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">准确度是分类算法最常用的性能指标。精确度主要用于平衡数据集。它被定义为正确预测的数量与所有预测的数量之比。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/69d80d626ebd79d00f6f4fb9dbd62f87.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/1*f-B68-tHtDtmQMkvaVkP2A.gif"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/77701c02660c4ec26d2bc9f7ced301a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/1*de_ZRoS5eSRs1p8394cPTQ.gif"/></div></div></figure><ul class=""><li id="018e" class="nx ny it lb b lc ld lf lg li nz lm oa lq ob lu oc od oe of bi translated">精度度量可能不适用于不平衡的数据集，因为它可能偏向于多数类。下述指标克服了这一缺点。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nv nw l"/></div></figure><blockquote class="ne nf ng"><p id="f8de" class="kz la nh lb b lc ld ju le lf lg jx lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated"><strong class="lb iu"> TPR(真阳性率):</strong></p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/56f014e0eabd744093726b7d99d87b46.png" data-original-src="https://miro.medium.com/v2/resize:fit:320/format:webp/1*RYigX453znEdcfkjstZZng.png"/></div></figure><p id="2c21" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">TPR是正确预测的肯定类别数与肯定类别总数的比率。</p><blockquote class="ne nf ng"><p id="525c" class="kz la nh lb b lc ld ju le lf lg jx lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated"><strong class="lb iu"> TNR(真阴性率):</strong></p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/c737086a7ab67e9905994cfa25618ab4.png" data-original-src="https://miro.medium.com/v2/resize:fit:324/format:webp/1*8WZLsRxeOfft2SOeBHVXxQ.png"/></div></figure><p id="36d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">TNR是正确预测的否定类别数与否定类别总数的比率。</p><blockquote class="ne nf ng"><p id="d646" class="kz la nh lb b lc ld ju le lf lg jx lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated"><strong class="lb iu"> FPR(假阳性率):</strong></p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/ea03a22d7bb79b87c43ac73b6a2dcd1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:322/format:webp/1*VZBgMcxhtFBn5l4JZPeKiA.png"/></div></figure><p id="2fa1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">FPR是错误预测的肯定类别的数量与否定类别的总数的比率。</p><blockquote class="ne nf ng"><p id="19b7" class="kz la nh lb b lc ld ju le lf lg jx lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated"><strong class="lb iu"> FNR(假阴性率):</strong></p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/2a8175feb4110013ab81acf8387e10d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:326/format:webp/1*UCyfDg6MBmw5Jl4qCUEOqQ.png"/></div></figure><p id="8f68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">TNR是正确错误地否定类别的数量与肯定类别的总数的比率。</p><blockquote class="ne nf ng"><p id="f40e" class="kz la nh lb b lc ld ju le lf lg jx lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated"><strong class="lb iu">精度:</strong></p></blockquote><p id="a817" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">信息检索中使用的精度度量被定义为从预测为正的所有点中，有多少点实际上是正的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/dc07deeb1cddaccb72e7f6bb59574859.png" data-original-src="https://miro.medium.com/v2/resize:fit:366/1*sR_w-RirBFyCN5KxAMJkEw.gif"/></div></figure><p id="b82e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">精确度指标用于ML模型，其中低误报率(FP)很重要，例如垃圾邮件检测。</p><blockquote class="ne nf ng"><p id="d7f3" class="kz la nh lb b lc ld ju le lf lg jx lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated"><strong class="lb iu">回忆:</strong></p></blockquote><p id="b705" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">召回率也被称为敏感度，敏感度被定义为从实际上为正的所有点中，有多少点被预测为正。召回率与真实阳性率(TPR)相同。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/54417187e567e2a3613cca42d1ccb398.png" data-original-src="https://miro.medium.com/v2/resize:fit:314/1*ElKHeI-lBvZMEqwUyHxMWw.gif"/></div></figure><p id="ffb1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">召回指标用于低假阴性(FN)很重要的ML模型，如癌症诊断。</p><blockquote class="ne nf ng"><p id="8e6d" class="kz la nh lb b lc ld ju le lf lg jx lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated"><strong class="lb iu"> F-beta评分:</strong></p></blockquote><p id="e1c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于FN和FP同样重要的ML模型来说，那么我们可以在一个新的称为F-beta score的度量中结合精确度和召回率的优势。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/5a9b1b73c3d7bd39be80548f3402061e.png" data-original-src="https://miro.medium.com/v2/resize:fit:546/1*a0UGQOd-_7qUYKjv0tW60w.gif"/></div></figure><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="51ca" class="ml mm it nn b gy nr ns l nt nu">Here beta is a variable,<br/>(Beta &lt; 1) is used when FP have more impact than FN<br/>(Beta &gt; 1) is used when FN have more impact than FP<br/>(Beta == 1) is used when FN and FP have equal importance</span></pre><p id="081c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当Beta=1时，该指标被称为F1得分，对精确度和召回率给予同等的重视。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/90ea54758a3111d26eaed8ccaf50aa2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/1*dOoAs8m8bjbg6320IxsZUw.gif"/></div></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nv nw l"/></div></figure><h2 id="5ccc" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">当ML模型的预测是概率得分时使用的度量:</h2><blockquote class="ne nf ng"><p id="4909" class="kz la nh lb b lc ld ju le lf lg jx lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated"><strong class="lb iu"> ROC曲线和AUC: </strong></p></blockquote><p id="8a70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ROC(接收机工作特性)曲线主要用于基于二元分类的ML模型。ROC曲线和AUC(曲线下面积)可用于输出概率得分的ML模型。</p><p id="58b3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ROC曲线是连接TPR对FPR图中不同阈值的所有点的曲线。</p><p id="db76" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ML模型的输出是概率值，对于不同的阈值，找到y_hat值，然后计算TPR和FPR。进一步，画一个图来观察ROC曲线和AUC。</p><p id="e66e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于下面的样本数据集:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/bf39066966301d301973353c756a1405.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*IHnL5qJ49rCR3SGRINaW1w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，样本数据集不同阈值的TPR和FPR分数</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/53afaa7da555e7869186da4b66a5df6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/1*2myoYSbBlnFTelMdJLnhbA.png"/></div></figure><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="1b42" class="ml mm it nn b gy nr ns l nt nu">Notation,<br/><strong class="nn iu">x_i:</strong> ith data point<br/><strong class="nn iu">y:</strong> target binary class label<br/><strong class="nn iu">y_hat:</strong> predicted probability value<br/><strong class="nn iu">y_hat(t):</strong> predicted binary class label for threshold - <strong class="nn iu">t</strong></span></pre><p id="4a97" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">关于样本数据集的ROC曲线(蓝色曲线)如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/ae4db08f72f7df0a2b06a489862cbb1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ws4Um6ieA1GBuVt7W3PaWQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，上述样本数据集的ROC曲线</p></figure><p id="e11f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于真实世界的数据集，ROC曲线看起来像这样:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/902fe0a18f1848adfc77574b500d3583.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MdmlTmDUGqHZpVxXbjyfyA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，ROC曲线—蓝线</p></figure><p id="c286" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的图是ROC曲线(蓝色曲线)，曲线下的面积称为AUC(曲线下面积)。橙色线就是x=y线，ROC曲线会一直在这条线上面。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nv nw l"/></div></figure><blockquote class="ne nf ng"><p id="1fec" class="kz la nh lb b lc ld ju le lf lg jx lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated"><strong class="lb iu">日志丢失:</strong></p></blockquote><p id="2f0d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对数损失也称为交叉熵损失，它使用概率估计来计算模型的性能。模型的概率估计值在0到1之间。模型的对数损失总是大于0，0分是最好的模型。对数损失是我们预测的不确定性量，基于它与实际标签的差异程度。在Log Loss值的帮助下，我们可以更准确地了解模型的性能。二元分类的测井曲线损失方程为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/66d6076f3c5c971c547f37850334433b.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/1*v8Pphrj2cpC9U42gY41_pA.gif"/></div></figure><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="e74d" class="ml mm it nn b gy nr ns l nt nu">Notations,<br/>n: number of points in dataset<br/>p_i: predicted probability of ith point<br/>y_i: actual output class label</span></pre><p id="2b0a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是一个样本数据集:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/8883457187f76e339975fae4030fe7f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zH6-HPvV44gmwVZwX16gXA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(按作者分类的图片)，样本数据集的实际和预测目标类表</p></figure><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="00c6" class="ml mm it nn b gy nr ns l nt nu">Notation,<br/><strong class="nn iu">x_i:</strong> ith data point<br/><strong class="nn iu">y:</strong> target binary class label<br/><strong class="nn iu">y_hat:</strong> predicted probability value</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/c10499b134de4cc1149d708e922eacd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*n2tJzDgzmH2ZlLC46nqcRw.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/07827c4cdfacfe7098374ce42e882551.png" data-original-src="https://miro.medium.com/v2/resize:fit:382/format:webp/1*LRb-8T0bJp6fMo_2uNbDOg.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/f6f7238cddf64c765807329e70f91f2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:258/format:webp/1*AHD2oAs5tm1SSV6lJr_xIQ.png"/></div></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nv nw l"/></div></figure><blockquote class="lw"><p id="1416" class="lx ly it bd lz ma mb mc md me mf lu dk translated">回归模型中使用的指标:</p></blockquote><p id="4ca8" class="pw-post-body-paragraph kz la it lb b lc mg ju le lf mh jx lh li mi lk ll lm mj lo lp lq mk ls lt lu im bi translated">对于回归问题，ML模型的输出是实值的。计算回归模型性能的各种指标有:</p><blockquote class="ne nf ng"><p id="35f7" class="kz la nh lb b lc ld ju le lf lg jx lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated"><strong class="lb iu">平均绝对误差(MAE): </strong></p></blockquote><p id="0ff8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">MAE是回归问题中使用的最简单的误差度量。MAE定义为预测值和实际值之间的绝对差值的平均值之和。它通过对实际值的预测可变性求和来计算回归模型的性能。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/744b2cbf17da2eca0205f2f293b66fd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:398/format:webp/1*BZKz7tpviuVNqjhhMgrySQ.png"/></div></figure><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="c0f2" class="ml mm it nn b gy nr ns l nt nu">Notation,<br/><strong class="nn iu">n:</strong> number of data point<br/><strong class="nn iu">y:</strong> actual real value<br/><strong class="nn iu">y_hat:</strong> predicted real value</span></pre><blockquote class="ne nf ng"><p id="3623" class="kz la nh lb b lc ld ju le lf lg jx lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated"><strong class="lb iu">均方根误差(RMSE)和均方误差(MSE): </strong></p></blockquote><p id="76a5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">MSE与MAE相同，但唯一的区别是，它在对实际输出值和预测输出值求和之前，对它们之间的差进行平方，而不是使用绝对值。RMSE正在计算MSE的平方根。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/a35400c3975a762236944b42c391cbc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:414/format:webp/1*e5xeXxBW_muG9jbR8vOGsg.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/5d54da3af9dff431d2e4790cea3a1601.png" data-original-src="https://miro.medium.com/v2/resize:fit:496/format:webp/1*aLMzoX5k3W2EcwdITmQung.png"/></div></figure><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="186a" class="ml mm it nn b gy nr ns l nt nu">Notation,<br/><strong class="nn iu">n:</strong> number of data point<br/><strong class="nn iu">y:</strong> actual real value<br/><strong class="nn iu">y_hat:</strong> predicted real value</span></pre><blockquote class="ne nf ng"><p id="0de6" class="kz la nh lb b lc ld ju le lf lg jx lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated"><strong class="lb iu"> R平方误差:</strong></p></blockquote><p id="e460" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">r平方度量通常用于解释目的，表示一组预测输出值与实际输出值的拟合优度。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/39302ee788087de948c800eb20abf40a.png" data-original-src="https://miro.medium.com/v2/resize:fit:386/format:webp/1*pcQVhANJI4aIngGgaUwgjw.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/457e10bb396acef26a1e4e23e7bd1786.png" data-original-src="https://miro.medium.com/v2/resize:fit:368/format:webp/1*BnZK1ksg6xxh1m0Hhv6d5w.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/8efc93205cfbfc4d5bbbed31c4f1230f.png" data-original-src="https://miro.medium.com/v2/resize:fit:284/format:webp/1*NqANGRSUamF7EWQVvnv0xg.png"/></div></figure><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="1194" class="ml mm it nn b gy nr ns l nt nu">Notation,<br/><strong class="nn iu">n:</strong> number of data point<br/><strong class="nn iu">y_i:</strong> ith actual real value<br/><strong class="nn iu">y_hat:</strong> predicted real value<br/><strong class="nn iu">y_bar: mean of y</strong></span></pre><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nv nw l"/></div></figure><blockquote class="lw"><p id="9ef5" class="lx ly it bd lz ma mb mc md me mf lu dk translated">感谢您的阅读！</p></blockquote></div></div>    
</body>
</html>