<html>
<head>
<title>Feature Visualization on Convolutional Neural Networks (Keras)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络的特征可视化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/feature-visualization-on-convolutional-neural-networks-keras-5561a116d1af?source=collection_archive---------16-----------------------#2020-05-30">https://towardsdatascience.com/feature-visualization-on-convolutional-neural-networks-keras-5561a116d1af?source=collection_archive---------16-----------------------#2020-05-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="de3d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">卷积神经网络中的每个滤波器在做什么？它正在学习检测哪种图像？这里有一个方法可以知道</h2></div><p id="8e1a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">根据维基百科的说法，<a class="ae lb" href="https://en.wikipedia.org/wiki/Apophenia" rel="noopener ugc nofollow" target="_blank"> apophenia </a>是<em class="lc">“错误感知不相关事物之间的联系和意义的倾向”</em>。它也被用作“人类在随机信息中寻找模式的倾向”。无论是科学家在实验室里做研究，还是阴谋论者警告我们“这一切都是联系在一起的”，我想人们需要感觉我们明白发生了什么，即使面对明显随机的信息。</p><p id="ce51" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">与XGboost或<a class="ae lb" href="https://github.com/interpretml/interpret" rel="noopener ugc nofollow" target="_blank">可解释的增强机器</a>等更透明的模型相比，深度神经网络通常被视为“黑盒”,因为它们的<strong class="kh ir">不可预测性</strong>。</p><p id="c8c3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，有一种方法可以解释卷积神经网络中每个单独的滤波器正在做什么，以及它正在学习检测哪种图像。</p><p id="bda6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">至少从2012年开始，卷积神经网络开始崭露头角，当时<a class="ae lb" href="http://image-net.org/challenges/LSVRC/2012/supervision.pdf" rel="noopener ugc nofollow" target="_blank"> AlexNet </a>以85%的准确率赢得了<a class="ae lb" href="http://www.image-net.org/challenges/LSVRC/2012/index#workshop" rel="noopener ugc nofollow" target="_blank"> ImageNet计算机视觉竞赛</a>。第二名的比例仅为74%,一年后<a class="ae lb" href="http://www.image-net.org/challenges/LSVRC/2013/results.php#cls" rel="noopener ugc nofollow" target="_blank"/>大多数竞争者都转向这种“新”算法。</p><p id="a9bc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">它们广泛用于许多不同的任务，大多与<strong class="kh ir">图像处理</strong>相关。这些包括图像分类，检测问题，以及许多其他问题。</p><p id="7b19" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我不会深入探讨卷积神经网络是如何工作的，但如果你是这方面的初学者，我建议你阅读我的<a class="ae lb" href="https://www.datastuff.tech/machine-learning/convolutional-neural-networks-an-introduction-tensorflow-eager/" rel="noopener ugc nofollow" target="_blank">卷积神经网络实用介绍</a>和工作张量流代码。</p><p id="8ee5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你已经掌握了卷积神经网络是如何工作的，那么这篇文章就是你理解<strong class="kh ir">什么特征可视化</strong>和它如何工作所需要知道的全部。</p><h1 id="3277" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">特征可视化是如何工作的？</h1><p id="0611" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">通常，你会训练一个CNN给它提供图像和标签，并使用梯度下降或类似的优化方法来<strong class="kh ir">拟合神经网络的权重</strong>，以便它预测正确的标签。</p><p id="06ed" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在整个过程中，人们希望图像保持不变，这同样适用于标签。</p><p id="e340" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，如果我们选取任何图像，在我们(已经训练好的)网络中选择一个卷积滤波器，并对输入图像应用梯度下降<strong class="kh ir">以<strong class="kh ir">最大化该滤波器的输出</strong>，同时<strong class="kh ir">保持网络的权重不变</strong>，您认为会发生什么？</strong></p><p id="3e13" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">突然间，我们的视角发生了转变。我们不再训练一个模型来预测图像的标签。相反，我们现在正在将图像与模型相匹配，让它生成我们想要的任何输出。</p><p id="3bd1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在某种程度上，这就像我们在问模型“看到这个过滤器了吗？什么样的图像能打开它？”。</p><p id="0536" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我们的网络已经被适当地训练，那么我们期望大多数过滤器携带有趣的、有价值的信息，帮助模型为其分类任务做出准确的预测。我们期望过滤器的激活带有语义含义。</p><p id="3a79" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，显而易见的是,“激活”过滤器，使其具有大量输出的图像应该具有与数据集中(以及模型标签中)存在的某个对象相似的特征。</p><p id="fd51" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，鉴于卷积是一种局部变换<strong class="kh ir"/>，在我们图像的许多不同区域，触发卷积滤波器重复“发芽”的模式是很常见的。</p><p id="7e9e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这一过程产生了谷歌深梦模型流行的那种画面。</p><p id="3a91" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本教程中，我们将使用<strong class="kh ir"> TensorFlow的Keras </strong>代码来<strong class="kh ir">生成最大化给定滤镜输出的图像</strong>。</p><p id="5145" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于滤波器的输出在技术上是一个矩阵，我们将最大化的实际函数是该矩阵组件的平均值，<strong class="kh ir">是整个图像</strong>的平均值。通过这种方式，我们的算法将被激励来生成贯穿整个图像的激活过滤器的任何模式。</p><h1 id="61d7" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">实现过滤器可视化</h1><p id="c479" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">正如我之前提到的，要做到这一点，我们需要首先<strong class="kh ir">训练一个神经网络分类器</strong>。幸运的是，我们不需要经历整个混乱而昂贵的过程:<strong class="kh ir"> Keras </strong>已经配备了一整套预先训练好的神经网络，我们可以下载并使用。</p><h1 id="83f4" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">使用预先训练好的神经网络</h1><p id="32a7" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">对于本文，我们将使用VGG16，这是一个在相同的ImageNet竞争数据集上训练的巨大卷积神经网络。还记得我提过AlexNet以85%的准确率胜出，颠覆了图像分类领域吗？VGG16在同样的任务上得分92%。</p><blockquote class="ma mb mc"><p id="8ab0" class="kf kg lc kh b ki kj jr kk kl km ju kn md kp kq kr me kt ku kv mf kx ky kz la ij bi translated"><em class="iq"> VGG16是由英国牛津大学的K. Simonyan和A. Zisserman在论文《用于大规模图像识别的甚深卷积网络》中提出的卷积神经网络模型。该模型在ImageNet中达到了92.7%的top-5测试准确率，ImageNet是一个包含属于1000个类的超过1400万个图像的数据集。那是提交给</em><a class="ae lb" href="http://www.image-net.org/challenges/LSVRC/2014/results" rel="noopener ugc nofollow" target="_blank"><em class="iq">ils vrc-2014</em></a><em class="iq">的著名模型之一。它通过用多个3×3内核大小的滤波器一个接一个地替换大内核大小的滤波器(在第一和第二卷积层中分别是11和5)来对AlexNet进行改进。VGG16 </em> <strong class="kh ir"> <em class="iq">训练了几周，用的是NVIDIA Titan Black GPU的</em> </strong> <em class="iq">。</em></p><p id="55d0" class="kf kg lc kh b ki kj jr kk kl km ju kn md kp kq kr me kt ku kv mf kx ky kz la ij bi translated"><a class="ae lb" href="https://neurohive.io/en/popular-networks/vgg16/" rel="noopener ugc nofollow" target="_blank"><em class="iq">https://neurohive.io/en/popular-networks/vgg16/</em></a><em class="iq">—vgg 16—用于分类和检测的卷积网络(重点地雷)</em></p></blockquote><p id="5fc1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于这些实验，我将使用<a class="ae lb" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"> Google colab的</a> GPU机器，并调整Keras库的示例<a class="ae lb" href="https://github.com/keras-team/keras/blob/master/examples/conv_filter_visualization.py" rel="noopener ugc nofollow" target="_blank">过滤器可视化</a>代码。</p><p id="3691" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">关于原始脚本是如何工作的，你可以看看Keras的博客。我只对它进行了轻微的修改，以方便配置文件名和其他小细节，所以我认为不值得链接到我自己的笔记本上。</p><p id="c7a5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个重要函数的作用是:</p><ul class=""><li id="aee0" class="mg mh iq kh b ki kj kl km ko mi ks mj kw mk la ml mm mn mo bi translated">定义一个损失函数，它等于所选的<strong class="kh ir">滤波器在整个图像</strong>上的平均输出。在我们的代码中，我们这样做:<code class="fe mp mq mr ms b">loss = K.mean(layer_output[:, filter_index, :, :])</code>。</li><li id="cc93" class="mg mh iq kh b ki mt kl mu ko mv ks mw kw mx la ml mm mn mo bi translated">初始化一个小的<strong class="kh ir">起始图片</strong>，典型的是以RGB(128，128，128)为中心的<strong class="kh ir">随机均匀噪声</strong>(我实际上用这个玩了一会儿，稍后会详细说明)。</li><li id="2685" class="mg mh iq kh b ki mt kl mu ko mv ks mw kw mx la ml mm mn mo bi translated">针对该损失计算输入图像的<strong class="kh ir">梯度，并执行梯度下降。<br/>注意，我们正在<strong class="kh ir">向神经网络</strong>输入图像，但是忽略了我们关心的那一层之后的任何一层。</strong></li><li id="59ad" class="mg mh iq kh b ki mt kl mu ko mv ks mw kw mx la ml mm mn mo bi translated">重复N次，然后调整图片大小，使其稍微变大(默认值为20%)。我们从一张小图片开始，随着我们生成过滤器的最大化图像，它会越来越大，因为否则该算法会创建一个重复多次的小图案，而不是创建一个具有更大(主观上更美观)形状的低频图案。</li><li id="d784" class="mg mh iq kh b ki mt kl mu ko mv ks mw kw mx la ml mm mn mo bi translated">重复最后两步，直到达到所需的分辨率。</li></ul><p id="89c7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">差不多就是这样。我链接到的代码还发生了一些事情(图像标准化，将许多过滤器生成的图像拼接成可爱的拼贴画)，但这是最重要的一点。</p><figure class="my mz na nb gt nc"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="4f6e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是那个函数的代码，现在你知道发生了什么，就没那么可怕了，对吗？</p><p id="a73e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在有趣的部分，让我们试试这个，看看哪种过滤器出来。</p><h1 id="f3d2" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">我尝试特征可视化的结果</h1><p id="d3f8" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">在尝试之前，我阅读了<a class="ae lb" href="https://distill.pub/2017/feature-visualization/" rel="noopener ugc nofollow" target="_blank">许多</a> <a class="ae lb" rel="noopener" target="_blank" href="/how-to-visualize-convolutional-features-in-40-lines-of-code-70b7d87b0030">不同的</a> <a class="ae lb" href="https://arxiv.org/pdf/1311.2901.pdf" rel="noopener ugc nofollow" target="_blank">例子</a>的特性可视化文章。以下是我学到的一些东西。</p><ul class=""><li id="85ee" class="mg mh iq kh b ki kj kl km ko mi ks mj kw mk la ml mm mn mo bi translated">第一个卷积层(靠近输入的层)产生更简单的视觉效果。它们通常只是粗糙的纹理，比如平行的波浪线，或者彩色的圆圈。</li></ul><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi nf"><img src="../Images/058809a51e930c8fcc23f16b13d4b388.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xL7HEr7FqNzhkyNHYBszHQ.png"/></div></div><p class="nm nn gj gh gi no np bd b be z dk translated">VGG16上卷积滤波器的可视化，第二层。</p></figure><ul class=""><li id="373a" class="mg mh iq kh b ki kj kl km ko mi ks mj kw mk la ml mm mn mo bi translated">更接近输出的卷积层产生更复杂的纹理和图案。有些甚至类似于存在的物体，或者看起来可能存在(以一种非常神秘的方式)。</li></ul><p id="c95a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">老实说，这也是我玩得最开心的地方。我尝试了许多不同的“初始图像”，从随机噪声到均匀灰度，再到渐进退化。</p><p id="0d35" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">任何给定过滤器的结果都非常相似。这让我想到，考虑到我使用的迭代次数，初始图像本身变得非常不相关。至少，它没有对结果产生可预测的影响。</p><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi nf"><img src="../Images/bcd36e5944f0c678fbfb44fa856e0fa1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I-7-NKpo9008cG7Pj7_jCQ.png"/></div></div><p class="nm nn gj gh gi no np bd b be z dk translated">VGG16的第一个卷积层中的块4滤波器的特征可视化。大多数图案看起来规则而有颗粒，但比我们在第一层看到的早期乡村纹理要复杂得多。</p></figure><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi nf"><img src="../Images/2e255fa6d4f90883742fe2550bc972cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_OnIu3CKWARdB6q24niFkw.png"/></div></div><p class="nm nn gj gh gi no np bd b be z dk translated">块4的滤波器可视化，VGG16的第二卷积层中的滤波器。注意这些图案是如何重复的，但是产生的纹理看起来比第一层要复杂得多。</p></figure><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi nf"><img src="../Images/f60beece0a8a5e08771984922b513751.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CaLf2OWfsLQk4-sw4gleiw.png"/></div></div><p class="nm nn gj gh gi no np bd b be z dk translated">块4的滤波器可视化，VGG16的第三卷积层中的滤波器。一些更容易渗透的模式似乎出现了。</p></figure><p id="066f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">随着我们越来越深入，并且<strong class="kh ir">越来越接近完全连接的层</strong>，我们到达了<strong class="kh ir">的最后一个卷积层</strong>。它生成的图像是迄今为止最复杂的<strong class="kh ir"/>，它们制作的图案很多时候都类似于现实生活中的物品。</p><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi nf"><img src="../Images/f95438bc5428e99d0e55e1f0cfa046d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DNM6maX9QHItW1JMn_OgzQ.png"/></div></div><p class="nm nn gj gh gi no np bd b be z dk translated">块5的滤波器可视化，VGG16的第一卷积层中的滤波器</p></figure><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi nq"><img src="../Images/c153c43426b7e814e90bb6d2657f0389.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OnqliCU1ldLBYhjYgYzPDA.png"/></div></div><p class="nm nn gj gh gi no np bd b be z dk translated">块5的滤波器可视化，VGG16的第三卷积层中的滤波器</p></figure><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="gh gi nf"><img src="../Images/fa0ccb9a7e194d124c9b54c602cb2782.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1NmmKZrU_GmJkeC1PcozBw.png"/></div></div><p class="nm nn gj gh gi no np bd b be z dk translated">块5，第二卷积层中的滤波器。所有这些模式都是通过最大化一个“简单的”(尽管是超维的)数学函数出现的，这难道不疯狂吗？</p></figure><p id="9533" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，看着这些图像寻找模式，很容易感觉到一个人正在坠入阿波菲斯。然而，我想我们都同意，其中一些图片的特征<strong class="kh ir">看起来很像</strong> …你可以放大图片，自己完成句子。特征可视化是新的凝视云。</p><p id="f05a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我自己的猜测是这只是一种新的抽象艺术。</p><p id="9d5c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我向你展示一些我认为视觉上最有趣的滤镜:</p><div class="my mz na nb gt ab cb"><figure class="nr nc ns nt nu nv nw paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><img src="../Images/9c108b2de5a8eacdb94f239be12c3401.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*mBigWTXSW3wu6fhpXa9DuA.png"/></div></figure><figure class="nr nc ns nt nu nv nw paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><img src="../Images/cb710cc41c660cac3202b27d5ea36687.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*_jNEaXHwzoRhcAG1MVF2oA.png"/></div></figure></div><div class="ab cb"><figure class="nr nc ns nt nu nv nw paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><img src="../Images/7f6f63e996a08be1d706dcbb2efe54a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*DTt6V6LMZGLMvOMoNWTyXw.png"/></div></figure><figure class="nr nc ns nt nu nv nw paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><img src="../Images/4bc1b4f1990cdff32fe39a296a154595.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*AurcTrzl84qvRk8an_54IQ.png"/></div><p class="nm nn gj gh gi no np bd b be z dk nx di ny nz translated">棉花，橘子皮，眼睛？奇怪的发霉螺旋。</p></figure></div><p id="84b1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我还有大约240张这样的照片，如果有足够的兴趣，我可以把它们做成一个画廊，但我担心过一会儿它可能会变得重复。</p><h1 id="5b63" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">结论</h1><p id="91d6" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">老实说，我从这个项目中获得了很多乐趣。直到几周前，我才真正听说过Google Colab(感谢<a class="ae lb" href="https://www.reddit.com/r/MediaSynthesis/" rel="noopener ugc nofollow" target="_blank"> r/mediaSynthesis </a>)。能够免费使用一台好的GPU机器，感觉太棒了。</p><p id="81d9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">几年前，我也读过关于这个主题的大部分论文，但是从来没有真正测试过代码或者写过这样的文章。我很高兴我终于把它从我的清单上划掉了(或者特雷罗，我在骗谁呢？).</p><p id="c270" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，在未来，我想尝试不同的网络架构，并想象图像如何在每次迭代中变形，而不是简单地看着成品。</p><p id="f11d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请在评论中让我知道哪些其他实验或参考书目值得查看，以继续扩展这个主题！</p><p id="c407" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lc">如果你喜欢这篇文章，请考虑在推特上发布或在其他地方分享！</em> <em class="lc">关注我的</em><a class="ae lb" href="https://www.twitter.com/strikingloo" rel="noopener ugc nofollow" target="_blank"><em class="lc">Twitter</em></a><em class="lc">进一步讨论这些问题，或者关注我的最新文章。</em></p><p id="5c37" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可以在我的 <a class="ae lb" href="http://strikingloo.github.io/wiki" rel="noopener ugc nofollow" target="_blank"> <em class="lc">个人网站</em> </a> <em class="lc">中看到我正在做的事情以及我最近的文章和笔记。</em></p></div></div>    
</body>
</html>