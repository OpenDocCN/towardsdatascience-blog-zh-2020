<html>
<head>
<title>ABBYY NeoML: How We Made The Open Source Machine Learning Library And Why We Need It</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ABBYY NeoML:我们如何创建开源机器学习库以及我们为什么需要它</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/abbyy-neoml-how-we-made-the-open-source-machine-learning-library-and-why-we-need-it-dc0a13e4c3f?source=collection_archive---------46-----------------------#2020-06-16">https://towardsdatascience.com/abbyy-neoml-how-we-made-the-open-source-machine-learning-library-and-why-we-need-it-dc0a13e4c3f?source=collection_archive---------46-----------------------#2020-06-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div class="gh gi ir"><img src="../Images/0abd822690d2052da860c45f42a71a84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/0*UNMDqclxJDoUpO8l.jpg"/></div><p class="iy iz gj gh gi ja jb bd b be z dk translated"><a class="ae jc" href="https://www.freepik.com/user12683362" rel="noopener ugc nofollow" target="_blank">用户12683362 </a>在<a class="ae jc" href="https://www.freepik.com/premium-photo/hand-touching-telecommunication-network-wireless-mobile-internet-technology-with-5g-lte-data-connection-global-business-fintech-blockchain_5988680.htm" rel="noopener ugc nofollow" target="_blank"> freepik </a>上的照片</p></figure><div class=""/><figure class="gl gn kd ke kf iv gh gi paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="gh gi kc"><img src="../Images/58ebbeba4825e0fc41e14a3812f316b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8SVCOgKbiEI6j7Sl.png"/></div></div></figure><p id="daef" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated"><em class="li">该框架为软件开发者提供了强大的深度学习和传统的机器学习算法，用于创建推动数字化转型的应用。</em></p><figure class="lj lk ll lm gt iv"><div class="bz fp l di"><div class="ln lo l"/></div></figure><p id="d21b" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">数字智能公司ABBYY推出了<a class="ae jc" href="https://cts.businesswire.com/ct/CT?id=smartlink&amp;url=https%3A%2F%2Fgithub.com%2Fneoml-lib&amp;esheet=52235643&amp;newsitemid=20200616005112&amp;lan=en-US&amp;anchor=NeoML&amp;index=1&amp;md5=2d6d047d552f3d145ed989f9a476f3bb" rel="noopener ugc nofollow" target="_blank"> NeoML </a>，这是一个用于构建、训练和部署机器学习模型的开源库。NeoML现已在GitHub上发布，支持深度学习和传统的机器学习算法。跨平台框架针对在云环境、桌面和移动设备上运行的应用程序进行了优化。根据下面显示的测试，与流行的开源库相比，NeoML为在任何设备上运行的预训练图像处理模型提供了15–20%的更快性能。更高的推理速度与平台无关性相结合，使该库成为需要无缝客户体验和设备上数据处理的移动解决方案的理想选择。</p><p id="a9e8" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">NeoML是一个跨平台的C ++库，它允许你组织一个完整的ML模型开发周期。它的主要重点是在各种平台上简单有效地推出现成的模型。即使这些模型是由其他框架创建的。</p><blockquote class="lp lq lr"><p id="df48" class="kk kl li km b kn ko kp kq kr ks kt ku ls kw kx ky lt la lb lc lu le lf lg lh im bi translated">ABBYY的人工智能宣传员Ivan Yamshchikov表示:“NeoML的推出反映了我们致力于推动全行业人工智能创新的承诺。“ABBYY拥有超过400项专利和专利申请的技术创新记录。共享我们的框架允许开发人员利用它的推理速度、跨平台能力，特别是它在移动设备上的潜力，同时他们的反馈和贡献将增长和改进库。我们很高兴推动人工智能的进步，并支持机器学习应用于越来越高价值和有影响力的用例。”</p></blockquote><p id="d031" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">你可能会问:为什么我们需要另一个机器学习库？</p><p id="bd0d" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">下面我来回答这个问题，告诉你我们在ABBYY是怎么创建我们的库的，遇到了什么困难，最后发生了什么。</p><h2 id="2f85" class="lv lw jf bd lx ly lz dn ma mb mc dp md kv me mf mg kz mh mi mj ld mk ml mm mn bi translated">ABBYY开始机器学习的地方</h2><p id="c136" class="pw-post-body-paragraph kk kl jf km b kn mo kp kq kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh im bi translated">机器学习和人工智能的发展长期以来一直是ABBYY数字智能技术的一部分。随着时间的推移，很明显ML的工作需要统一。我们开始思考如何以最干净、最简单、最有效的方式改进我们的机器学习工厂。该公司几乎所有的代码都是用C ++编写的——这意味着我们需要一个C / C ++解决方案。然而，没有一个C ++框架能满足我们所有的需求。当然，现在有不同的库实现不同的功能。比如Liblinear，XGBoost，Scikit-learn，Libsvm，Caffe，TensorFlow等。我们开始分析他们的能力。</p><p id="ee0b" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">大多数库适合于研究目的，但不适合于生产。他们的代码需要大量的修改:日志、错误处理、内存管理。此外，许多额外的功能，不同的构建系统，额外的依赖。不是每个人都有C ++界面。库发展和变化很快，并且不总是可预测的；他们的表现和稳定性引发了质疑，没有人承诺支持。我们别无选择，只能开始我们自己的发展，所以我们决定创建我们自己的图书馆，在里面收集我们需要的一切，然后我们为自己决定未来的道路。</p><figure class="lj lk ll lm gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="gh gi mt"><img src="../Images/f3b4e010f373f0ca327954628e2dea53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qsU0-McBZV-xRHb-"/></div></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">马库斯·斯皮斯克在<a class="ae jc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h2 id="062c" class="lv lw jf bd lx ly lz dn ma mb mc dp md kv me mf mg kz mh mi mj ld mk ml mm mn bi translated">经典算法</h2><p id="0820" class="pw-post-body-paragraph kk kl jf km b kn mo kp kq kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh im bi translated">开源库Liblinear、Libsvm、Scikit-learn和XGBoost已经存在，并且非常有用。我们开始利用它们，但是在分析了它们的能力之后，我们用我们需要的东西实现了类似的想法，并且增加了一些优化。例如，我们只处理适合内存的样本，只在CPU上处理，不进行低级优化。因此，经典算法的速度在我们的问题中并不是瓶颈，所以我们并没有认真努力去优化它们，但是我们成功地超越了上述类似算法的速度。</p><p id="07d1" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">统一产生了良好的效果:培训变得更快，质量更高。发展速度也提高了。每个程序员不再需要重新发明轮子——一个人现在可以简单地使用默认设置，并立即得到一个结果，而在此之前他们至少要花几天的时间进行实验。</p><p id="82b6" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">因此，库中出现了解决分类、回归和聚类问题的方法。</p><figure class="lj lk ll lm gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="gh gi mu"><img src="../Images/70bd55f422f466592473b7055926a036.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*5YESX855BlzZVn_L.png"/></div></div></figure><p id="a9ea" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">在我看来，经典算法的实现并不是一项非常困难的任务，神经网络的情况更有趣。</p><h2 id="c039" class="lv lw jf bd lx ly lz dn ma mb mc dp md kv me mf mg kz mh mi mj ld mk ml mm mn bi translated">神经网络</h2><p id="8ac1" class="pw-post-body-paragraph kk kl jf km b kn mo kp kq kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh im bi translated">经典算法本质上是一组使用公共原语的独立方法。但是神经网络的实现要困难得多。除了数学和算法问题之外，非显而易见的架构和底层优化问题也出现在其中。</p><p id="6379" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">在查看了当时存在的Caffe和TensorFlow库之后，我们认为Caffe的想法更接近我们的愿景。这就是为什么我们用blobs而不是tensors来表示数据。我们希望以更高层次的概念进行操作，在训练期间修改网络，能够在使用过程中完成它，并为用户透明地组织GPU上的计算。</p><p id="ad72" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">在NeoML中，网络是一个有向图，其顶点表示层，边表示从一些层的输出到其他层的输入的数据传输。层是执行某种操作的元素。操作可以是任何东西，从改变输入数据的形状或计算简单的数学函数到卷积或LSTM。可以随时在网络中添加和移除图层。网络中的所有数据——输入、输出和层间传输的数据——都以blobs的形式呈现。blob是一段连续的内存。该库不直接使用blob内存，而是通过一个特殊的独立于平台的接口。因此，实现了算法部分与直接执行计算的设备的独立性。例如，通过使用CUDA实现这个接口，可以在GPU上进行计算。</p><p id="ba90" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">如果我们谈论网络的架构，我们从卷积网络开始，我们添加了各种卷积层、池、全连接层、激活和损失函数。简单的梯度下降被用作优化器。</p><p id="390a" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">稍后，循环网络LSTM和GRU，高级优化器，甚至更多的激活和损失函数，CTC，CRF等。得到了支持。</p><p id="b2fa" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">目前，该库有大约100种不同类型的层，这允许我们实现几乎所有的现代网络架构。</p><figure class="lj lk ll lm gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="gh gi mv"><img src="../Images/1af3c767e71e765743c3738c5f333098.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UzSbSieR2Xckn2VU.png"/></div></div></figure><p id="6502" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">随着新架构在我们的任务中证明其有效性，我们试图扩展功能。</p><p id="681d" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">于是效率之争开始了。</p><figure class="lj lk ll lm gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="gh gi mw"><img src="../Images/7640da8d710b5da390b9ad922cbd46eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7Ck-BccYl3wxlVfl"/></div></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">克里斯蒂安·威迪格在<a class="ae jc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h2 id="942b" class="lv lw jf bd lx ly lz dn ma mb mc dp md kv me mf mg kz mh mi mj ld mk ml mm mn bi translated">CPU计算</h2><p id="430d" class="pw-post-body-paragraph kk kl jf km b kn mo kp kq kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh im bi translated">一个神经网络通常是一个巨大的计算量，如果没有低级别的优化，你将一事无成。首先，我们开始针对面向Windows的x86处理器进行优化，这是我们的主要平台，我们希望在这个平台上取得尽可能大的成功。</p><p id="c241" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">神经网络中的大多数操作都可以归结为BLAS(基本线性代数子程序)，而x86的最佳BLAS当然是英特尔MKL。我们开始使用它。其余操作必须使用SIMD系统独立实施。我们只使用SSE指令，也有AVX / AVX2的实验，但它们并没有给我们的操作带来多少收益，为了降低支持成本，我们决定拒绝它们。当英特尔发布MKL-DNN法案时，我们非常高兴:终于，你可以不用自己写这些了！但是，不幸的是，对比显示我们的包工作速度快了20%,这个想法还没有被放弃。</p><p id="7dbb" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">目前，NeoML在x86上工作得很好，但仍有很大的优化空间，我们计划在未来的版本中进行优化。</p><figure class="lj lk ll lm gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="gh gi mx"><img src="../Images/6464370be15d63706cffa3dc9504b1ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*X1l7arBZNIju_dG9"/></div></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">在<a class="ae jc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的<a class="ae jc" href="https://unsplash.com/@thisisengineering?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> ThisisEngineering RAEng </a></p></figure><h2 id="caca" class="lv lw jf bd lx ly lz dn ma mb mc dp md kv me mf mg kz mh mi mj ld mk ml mm mn bi translated">GPU计算</h2><p id="4f4c" class="pw-post-body-paragraph kk kl jf km b kn mo kp kq kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh im bi translated">对我们来说，GPU计算主要是学习。培训通常在公司内部或我们的云中进行。在这里，我们可以选择我们将在其上执行此操作的设备，这简化了工作:例如，如果客户端没有AVX，则不需要支持SSE。因此，他们决定使用CUDA实现GPU的计算引擎，并在支持它的Nvidia显卡上进行计算。我们做出这个决定，除了别的以外，是因为有专门的库可用:cuDNN、cuBLAS、cuSparse等。尽管由于不断的错误和低效的操作，我们在未来放弃了cuDNN，转而支持我们自己的实现。其余的库表现得很好，我们没有成功地编写自己的内核。</p><p id="e7b5" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">GPU引入的结果是显而易见的。许多网络的训练速度加快了一个数量级。得益于此，开发速度加快了，模型的质量也提高了。</p><p id="4048" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">在主平台上获得了不错的结果，并且建立了有效的培训之后，我们考虑将这个库发布到其他平台上。</p><figure class="lj lk ll lm gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="gh gi my"><img src="../Images/f7dabbbd584aa4163938fc5edfcb8d5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*egkd-dUm5nQccEoR"/></div></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">照片由<a class="ae jc" href="https://unsplash.com/@nasa?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> NASA </a>在<a class="ae jc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><h2 id="9dc4" class="lv lw jf bd lx ly lz dn ma mb mc dp md kv me mf mg kz mh mi mj ld mk ml mm mn bi translated">跨平台</h2><p id="e7f3" class="pw-post-body-paragraph kk kl jf km b kn mo kp kq kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh im bi translated">ABBYY的主要开发是在Windows上，用于培训和测试的服务器也在Windows上，因此库的第一个版本只适用于这个操作系统。然而，ABBYY的产品也可以在其他平台上工作，很快我们开始将我们的库移植到Linux和macOS。转移非常容易，因为我们需要的唯一英特尔MKL依赖项是这些操作系统的版本，并且不需要CUDA支持培训。唯一的困难是Microsoft Visual Studio编译器与GCC和Clang的差异，但这并没有花费太多时间。</p><p id="f7f4" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">现在，我们正在积极地使用Linux版本的库与竞争对手进行比较测量，因为Windows支持往往还有许多不足之处。此外，云中还有学习网络的任务。因此，在下一个版本中，我们将有一个在Linux上支持CUDA的NeoML版本。</p><figure class="lj lk ll lm gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="gh gi mw"><img src="../Images/a259ead4395b7bf31008c905fe6097b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9WYclECfvF5SBxLm"/></div></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">马文·迈耶在<a class="ae jc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h2 id="3472" class="lv lw jf bd lx ly lz dn ma mb mc dp md kv me mf mg kz mh mi mj ld mk ml mm mn bi translated">移动平台</h2><p id="87fe" class="pw-post-body-paragraph kk kl jf km b kn mo kp kq kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh im bi translated">ABBYY正在开发和销售用于图像处理和文本识别的SDK，包括那些适用于手机的SDK。因此，随着这些SDK中神经网络的出现，关于它们在移动平台上的有效启动的问题出现了。这一刻，我们又一次想到了是否使用第三方解决方案。在评估了TensorFlow Lite for Android和Core ML for iOS的集成后，我们得出的结论是，同时使用几个框架将会非常昂贵，最好改进您自己的框架，即使这是低效的。</p><p id="1f0b" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">我们开始为ARM创造一个“计算引擎”。用NEON替换SSE，用Eigen替换MKL，在几周内，我们做出了运行在ARM CPU上的第一个版本的库。事实证明，就效率而言，最终的解决方案完全适合我们；它甚至在速度上超过了同类产品。当然，从那时起，TF Lite和Core ML都取得了长足的进步，但我们也做了许多重大的优化，其中大部分与x86版本重叠，并且不是很昂贵。然而，有一些特定于ARM的优化。其中最严重的是我们自己的矩阵乘法，多亏了它，我们超过了特征库20%左右的速度，结果拒绝使用它。</p><p id="1662" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">目前，NeoML在CPU上的运行方式与其同类产品大致相同，这完全符合我们的需求。</p><p id="f3b8" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">此外，为了简化iOS和Android上现成模型的发布，我们为ObjectiveC和Java语言添加了推理包装器。</p><figure class="lj lk ll lm gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="gh gi ir"><img src="../Images/9e71014489af307fbb64ded2f3555935.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/0*cW2X_PK-K9rgZfoY.jpg"/></div></div></figure><h2 id="835a" class="lv lw jf bd lx ly lz dn ma mb mc dp md kv me mf mg kz mh mi mj ld mk ml mm mn bi translated">移动GPU</h2><p id="1f3c" class="pw-post-body-paragraph kk kl jf km b kn mo kp kq kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh im bi translated">几乎所有现代的Android和iOS手机都配备了独立的GPU。有趣的是，我们思考并开始研究如何开始使用它。第一次实验是用RenderScript完成的，完全没有结果，一切都非常慢…然而，用OpenCL、Vulkan和Metal进行的实验显示了良好的结果。在大型网络中，GPU可以提供5到7倍的优势。在小型计算机上，由于开销的原因，CPU仍然更快；即使在大型网络上，也不是每个GPU都能盈利；只有顶级型号上的昂贵芯片才能正常工作。此外，事实证明，对于不同系列的GPU，您需要编写不同的代码:例如，针对Adreno优化的着色器在Mali上不一定工作得一样好。总的来说，现在对我们来说，在移动设备中使用GPU的话题是有争议的，但潜在的非常有前途。目前，我们已经实现了在Vulkan和Metal上运行的计算引擎，我们在有限的任务中使用它们，同时继续致力于它们的开发。我必须说，移动GPU上的计算是一个相当广阔的话题，在许多方面不同于桌面上的计算，关于它的故事值得单独撰写一篇文章。</p><figure class="lj lk ll lm gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="gh gi mz"><img src="../Images/3810eac7143522ba90e71ab61b80149b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JXwhWxMh-TdieaMr.png"/></div></div></figure><h2 id="45f6" class="lv lw jf bd lx ly lz dn ma mb mc dp md kv me mf mg kz mh mi mj ld mk ml mm mn bi translated">ONNX</h2><p id="0f50" class="pw-post-body-paragraph kk kl jf km b kn mo kp kq kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh im bi translated">所以，我们有了一个完全自给自足的框架。有了它，我们可以了解自己的网络，轻松地将它们集成到桌面应用程序中，并转移到移动平台上，而无需额外的成本。一个问题仍然存在:在阅读新文章、探索新架构及其使用示例时，我们的数据科学家经常会遇到其他框架。为了快速有效地开发解决任何问题的模型，他们需要能够将模型从第三方框架转换到我们的框架中。</p><p id="77cc" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">新的ONNX格式是一个很大的改进，尽管这种格式还很年轻，它在许多框架中的支持还有很多需要改进的地方，但是它正在被积极地开发，我们认为它是目前解决这个问题的最佳方案。我们支持将神经网络模型从ONNX下载到我们的库中。当然，我们并不支持整个格式:它有相当大的规格和几个版本，但这不是主要的。在不同的框架中，其使用的语义是不同的。比如同一个模型，如果上传到不同框架的ONNX上，看起来可能完全不一样。我们决定在这件事上关注PyTorch。当然，其他人的ONNX模型也可以工作，但可能效率不高。</p><p id="08ac" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">因此，模型开发过程可能看起来像这样:在PyTorch上完成模型的第一次实验，然后将模型存储在ONNX中，从ONNX加载到NeoML中，重新训练NeoML模型，测量其速度和质量，然后模型进入修订或生产。</p><p id="91dd" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">现在，我们拥有了支持ML模型整个开发周期所需的一切。</p><figure class="lj lk ll lm gt iv gh gi paragraph-image"><div class="gh gi ir"><img src="../Images/832b5204ad4774da37858b63f1c0deb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/0*Q9Ovk7-D1EwbcLTl.jpg"/></div></figure><h2 id="d3f6" class="lv lw jf bd lx ly lz dn ma mb mc dp md kv me mf mg kz mh mi mj ld mk ml mm mn bi translated">开源</h2><p id="3ea0" class="pw-post-body-paragraph kk kl jf km b kn mo kp kq kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh im bi translated">我们决定下一步做什么？我们决定创建一个开源库，这样其他人也可以从中受益</p><p id="c470" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">这是图书馆发展的一个新步骤。我们与社区分享我们的最佳实践，作为回应，我们希望收到评论和建议，以使我们的图书馆更快、更方便。</p><p id="e0bc" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">该库已经有了几个独特的特性，可以成为在各种平台上的各种应用程序中启动模型的有效手段。我们希望拥有类似脚本的开发人员会喜欢NeoML，并可能在不久的将来加入到这个库的工作中来。</p><figure class="lj lk ll lm gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="gh gi ir"><img src="../Images/77ba8c7cce403d8c932c278055b1a15e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/0*ZoJJHQxK8FhyNWkr.jpg"/></div></div></figure><h2 id="b4bb" class="lv lw jf bd lx ly lz dn ma mb mc dp md kv me mf mg kz mh mi mj ld mk ml mm mn bi translated">比较测量</h2><p id="ccc8" class="pw-post-body-paragraph kk kl jf km b kn mo kp kq kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh im bi translated">我们试图定期与同行(最常见的是TensorFlow)比较我们的库在我们的任务上的有效性，以了解我们当前的水平。在这里，例如，我将比较从MobileNetV2架构的TorchVision包直接访问公共网络的速度，该架构被训练为对ImageNet数据集进行分类。网络输入的尺寸为224x224x3。测量是在我现在触手可及的台式机CPU和几部手机上进行的(如你所知，这个帖子是在自我隔离期间创建的)。</p><p id="3cc6" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">在运行Ubuntu 20.04的酷睿i5–4400处理器的电脑上，我们获得了以下10，000次网络启动的结果:</p><figure class="lj lk ll lm gt iv gh gi paragraph-image"><div class="gh gi na"><img src="../Images/4505b99d99088ccd47a5ff00e01d7ae8.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/0*qIMtbv7QU-VUhmX2.png"/></div></figure><p id="92de" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">内存消耗如下:</p><figure class="lj lk ll lm gt iv gh gi paragraph-image"><div class="gh gi na"><img src="../Images/2df9309931e81d065ab12024bd4e0f77.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/0*QuXQI-2jexiL0VGV.png"/></div></figure><p id="a41c" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">在10，000次启动的Android手机上，结果如下:</p><figure class="lj lk ll lm gt iv gh gi paragraph-image"><div class="gh gi na"><img src="../Images/21bfa8f6e92c80db694561d212bb560b.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/0*CuBNSNrUhZwmwuuq.png"/></div></figure><figure class="lj lk ll lm gt iv gh gi paragraph-image"><div class="gh gi na"><img src="../Images/5570485a72086ab67e1eb4ebbb3a11ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/0*MQpK028h-IJpPVQp.png"/></div></figure><p id="81f1" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">在iOS手机上:</p><figure class="lj lk ll lm gt iv gh gi paragraph-image"><div class="gh gi na"><img src="../Images/3c3ff8e9908ffaf5ab30851aa5c94d06.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/0*OOouz0BEukeBrsnj.png"/></div></figure><figure class="lj lk ll lm gt iv gh gi paragraph-image"><div class="gh gi na"><img src="../Images/ead848275f4b501ac9aae33cd7a526b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/0*0XJdGIJZcmfD6hxs.png"/></div></figure><p id="f31f" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">值得注意的是手机上的运行时间测量——一个吃力不讨好的任务。如果您愿意，您可以测量几乎任何结果，对几个流的测量甚至更不具有指示性(因此，这里没有显示)。但还是可以看到发射数量相当多的整体画面。</p><p id="ad71" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">为了详细分析和优化，我们通常使用各种处理器计数器，如cpu_cycles、cpu_instructions、cache_access、cache_miss、branch_count、branch_miss、bus_cycles等。您还可以从中看出两个库的工作方式大致相同。</p><h2 id="3c9a" class="lv lw jf bd lx ly lz dn ma mb mc dp md kv me mf mg kz mh mi mj ld mk ml mm mn bi translated">使用强大的NeoML框架来构建、训练和部署机器学习模型</h2><ul class=""><li id="42ae" class="nb nc jf km b kn mo kr mp kv nd kz ne ld nf lh ng nh ni nj bi translated">支持超过100层类型的神经网络</li><li id="d8d7" class="nb nc jf km b kn nk kr nl kv nm kz nn ld no lh ng nh ni nj bi translated">CPU和GPU支持，快速推断</li><li id="241f" class="nb nc jf km b kn nk kr nl kv nm kz nn ld no lh ng nh ni nj bi translated">语言:C++，Java，Objective</li><li id="21d8" class="nb nc jf km b kn nk kr nl kv nm kz nn ld no lh ng nh ni nj bi translated">传统机器学习:20多种算法(分类、回归、聚类等)</li><li id="a0a1" class="nb nc jf km b kn nk kr nl kv nm kz nn ld no lh ng nh ni nj bi translated">ONNX支持</li><li id="0480" class="nb nc jf km b kn nk kr nl kv nm kz nn ld no lh ng nh ni nj bi translated">跨平台:相同的代码可以在Windows、Linux、macOS、iOS和Android上运行</li></ul><h2 id="bb60" class="lv lw jf bd lx ly lz dn ma mb mc dp md kv me mf mg kz mh mi mj ld mk ml mm mn bi translated">随处部署</h2><p id="6226" class="pw-post-body-paragraph kk kl jf km b kn mo kp kq kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh im bi translated">NeoML由ABBYY工程师用于计算机视觉和自然语言任务，包括图像预处理、分类、文档布局分析、OCR以及从结构化和非结构化文档中提取数据。您可以在云中、本地、浏览器或设备上部署模型。</p><h2 id="daaa" class="lv lw jf bd lx ly lz dn ma mb mc dp md kv me mf mg kz mh mi mj ld mk ml mm mn bi translated">下一步是什么</h2><p id="303f" class="pw-post-body-paragraph kk kl jf km b kn mo kp kq kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh im bi translated">NeoML支持<a class="ae jc" href="https://cts.businesswire.com/ct/CT?id=smartlink&amp;url=https%3A%2F%2Fonnx.ai%2F&amp;esheet=52235643&amp;newsitemid=20200616005112&amp;lan=en-US&amp;anchor=the+Open+Neural+Network+Exchange+%28ONNX%29&amp;index=3&amp;md5=93cc525d73f4e42244dbe9ff4a95faa9" rel="noopener ugc nofollow" target="_blank">开放神经网络交换(ONNX) </a>，这是一个用于互操作ML模型的全球开放生态系统，它提高了工具的兼容性，使开发人员更容易使用正确的组合来实现他们的目标。ONNX标准是由微软、脸书和其他合作伙伴共同支持的一个开源项目。</p><p id="4c1b" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">ABBYY邀请开发人员、数据科学家和业务分析师在GitHub 上使用并贡献<a class="ae jc" href="https://cts.businesswire.com/ct/CT?id=smartlink&amp;url=https%3A%2F%2Fgithub.com%2Fneoml-lib&amp;esheet=52235643&amp;newsitemid=20200616005112&amp;lan=en-US&amp;anchor=NeoML+on+GitHub&amp;index=4&amp;md5=a3d1307ad40807d9ce5118c6772b8a40" rel="noopener ugc nofollow" target="_blank"> NeoML，其代码在Apache License 2.0下获得许可。该公司提供个性化的开发人员支持、持续的报告审查、定期更新和性能增强。展望未来，ABBYY计划添加新的算法和架构，以及进一步提高使用框架算法可实现的速度。</a></p><p id="bc24" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">总之，我们可以说我们得到了一个体面的解决方案，允许我们组织一个完整的ML模型开发和实现周期。目前，NeoML几乎用于该公司的所有产品，并且每天都在证明其有效性。</p><p id="43d1" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">机器学习是ABBYY的首要任务之一。我们计划通过定期发布新版本来发展我们的库。在即将发布的版本中，我们希望添加一个Python包装器，支持新的网络架构，扩展对ONNX格式的支持，当然，还要努力提高生产率。</p><p id="d218" class="pw-post-body-paragraph kk kl jf km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">如果你的工作遇到与我们相似的场景，那么<a class="ae jc" href="https://github.com/neoml-lib/neoml" rel="noopener ugc nofollow" target="_blank">访问我们的Github </a>并尝试NeoML。我们欢迎任何反馈。还有，在评论里写上你的管道是什么样子的，你在里面遇到了什么问题！</p></div></div>    
</body>
</html>