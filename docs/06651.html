<html>
<head>
<title>Generative Adversarial Networks | GANs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成性对抗网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generative-adversarial-networks-gans-8fc303ad5fa1?source=collection_archive---------50-----------------------#2020-05-25">https://towardsdatascience.com/generative-adversarial-networks-gans-8fc303ad5fa1?source=collection_archive---------50-----------------------#2020-05-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="af67" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">GANs系列</h2><div class=""/><h1 id="c34e" class="jw jx iq bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">1 —以更简单的方式理解GANs</h1><h2 id="c939" class="ku jx iq bd jy kv kw dn kc kx ky dp kg kz la lb kk lc ld le ko lf lg lh ks iw bi translated">在谈到甘斯时，脸书首席人工智能科学家、ACM图灵奖获得者扬·勒村(Yann LeCun)曾公开引用说，对抗性训练是，</h2><blockquote class="li"><p id="f357" class="lj lk iq bd ll lm ln lo lp lq lr ls dk translated">“过去10年中最有趣的想法”</p></blockquote><p id="069d" class="pw-post-body-paragraph lt lu iq lv b lw lx ly lz ma mb mc md kz me mf mg lc mh mi mj lf mk ml mm ls ij bi translated">gan是ML领域中相对较新的发明。它是由伊恩·古德菲勒等人在2014年通过这篇令人惊叹的<a class="ae mn" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank">研究论文</a>介绍的。</p><h2 id="4366" class="ku jx iq bd jy kv kw dn kc kx ky dp kg kz la lb kk lc ld le ko lf lg lh ks iw bi translated">那么，甘斯到底有什么了不起的？</h2><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi mo"><img src="../Images/b94c1fb59c0bf0ab288d2d17ddffb616.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*buWplCYinlQPhVUy"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated">与Raj 在<a class="ae mn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>的<a class="ae mn" href="https://unsplash.com/@roadtripwithraj?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">公路旅行照片</a></p></figure><p id="2d8b" class="pw-post-body-paragraph lt lu iq lv b lw ne ly lz ma nf mc md kz ng mf mg lc nh mi mj lf ni ml mm ls ij bi translated">我们先来单独看一下术语— <code class="fe nj nk nl nm b">Generative Adversarial Network</code> <br/>生成性是什么意思？</p><p id="d696" class="pw-post-body-paragraph lt lu iq lv b lw ne ly lz ma nf mc md kz ng mf mg lc nh mi mj lf ni ml mm ls ij bi translated">深度学习可以分为两种类型的模型目标，它们是</p><ul class=""><li id="8135" class="nn no iq lv b lw ne ma nf kz np lc nq lf nr ls ns nt nu nv bi translated"><strong class="lv ja">判别模型</strong> <br/>这些模型用于从给定的输入数据中映射出一个可能的输出。在这个领域中，你能想到的最常见的例子是分类器。他们的目标是简单地识别一类输入数据，如“垃圾邮件或非垃圾邮件”，或者像手写字符识别等。<br/>这些模型捕捉条件概率P(y|x)，即‘给定x的y的概率’。</li><li id="87b6" class="nn no iq lv b lw nw ma nx kz ny lc nz lf oa ls ns nt nu nv bi translated"><strong class="lv ja">生成模型</strong> <br/>这些模型用于寻找数据集的概率分布，并生成类似结构的数据。<br/>生成模型主要是为了从给定的数据概率分布中找到<strong class="lv ja">密度函数</strong>。如下图所示，这些点表示数据在一维轴上的分布，该轴由右侧图像中的高斯密度拟合。</li></ul><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi ob"><img src="../Images/9652fbbb05c362494b5bca99456b7ad2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1JUcHcBGpI3H20LV38uJ1g.png"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated"><strong class="bd oc">密度估计</strong> —作者从<a class="ae mn" href="https://arxiv.org/abs/1701.00160" rel="noopener ugc nofollow" target="_blank"> NIPS 2016教程复制的图像:生成对抗网络</a></p></figure><p id="6805" class="pw-post-body-paragraph lt lu iq lv b lw ne ly lz ma nf mc md kz ng mf mg lc nh mi mj lf ni ml mm ls ij bi translated">GANs并不专注于精确地找到这个密度函数，而是观察给定的数据集，并在两个互为<strong class="lv ja">对手</strong>的模型的帮助下，生成符合给定数据样本中潜在结构的新样本。因此得名—<strong class="lv ja"><em class="od"/></strong></p><h1 id="a509" class="jw jx iq bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">GANs的工作</h1><p id="35e1" class="pw-post-body-paragraph lt lu iq lv b lw oe ly lz ma of mc md kz og mf mg lc oh mi mj lf oi ml mm ls ij bi translated">GANs由两种模型组成，即:</p><ul class=""><li id="673d" class="nn no iq lv b lw ne ma nf kz np lc nq lf nr ls ns nt nu nv bi translated"><strong class="lv ja">生成器</strong> <br/>其功能是获取输入噪声向量(z)并将其映射到一个图像，该图像有望类似于训练数据集中的图像。</li><li id="d7c6" class="nn no iq lv b lw nw ma nx kz ny lc nz lf oa ls ns nt nu nv bi translated"><strong class="lv ja">鉴别器</strong> <br/>鉴别器模型的主要目的是找出哪个图像来自实际训练数据集，哪个是生成器模型的输出。</li></ul><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi oj"><img src="../Images/0b453f01201be17d5f77587dfbebd650.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VnPsLPFkuRf46wbY1HLkjg.png"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated">由发生器和鉴别器模型组成的GANs的基本结构(图片由作者提供)</p></figure><p id="7b02" class="pw-post-body-paragraph lt lu iq lv b lw ne ly lz ma nf mc md kz ng mf mg lc nh mi mj lf ni ml mm ls ij bi translated">你可以把生成器模型想象成伪币制造者，他们想要生成假币并愚弄所有人相信它是真的，而鉴别器模型是警察，他们想要识别假币并抓住伪币制造者。</p><p id="e859" class="pw-post-body-paragraph lt lu iq lv b lw ne ly lz ma nf mc md kz ng mf mg lc nh mi mj lf ni ml mm ls ij bi translated">开始时，伪造者制造出完全不像真货币的随机货币。在被警察抓住后，他们从错误中吸取教训(在我们的案例中，模型丢失了),并创造出比以前更好的新货币。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi ok"><img src="../Images/69fed8923b1310a15c82bf0130ecba62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cz7hUcHourXT49nTUOhPPw.png"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated"><strong class="bd oc">假币与真币不相似的例子</strong>(图片由作者提供)</p></figure><p id="102a" class="pw-post-body-paragraph lt lu iq lv b lw ne ly lz ma nf mc md kz ng mf mg lc nh mi mj lf ni ml mm ls ij bi translated">这样，警察就能更好地辨别假币和真币，同时，伪造者也能更好地制造看起来和真币相似的货币。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi ok"><img src="../Images/228f0477bd2f89ae26ab466ca3beb466.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GvZcBvhJQWp6RKGNnPei8g.png"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated"><strong class="bd oc">造假者在制造假币方面训练有素的时间点</strong>(图片由作者提供)</p></figure><p id="22b4" class="pw-post-body-paragraph lt lu iq lv b lw ne ly lz ma nf mc md kz ng mf mg lc nh mi mj lf ni ml mm ls ij bi translated">这是两个模型之间的最小-最大2人游戏，其中发电机模型试图最小化其损耗，最大化鉴别器损耗。<br/>因此，生成器模型将输入向量(z)映射到与训练数据集中的数据相似的输出。</p><p id="da1f" class="pw-post-body-paragraph lt lu iq lv b lw ne ly lz ma nf mc md kz ng mf mg lc nh mi mj lf ni ml mm ls ij bi translated">最后，当鉴频器不再能识别假输出时，它的准确度约为50%。这意味着它现在是在进行随机猜测，以区分假数据和真实数据。这就是所谓的纳什均衡点。</p><blockquote class="ol om on"><p id="bb1b" class="lt lu od lv b lw ne ly lz ma nf mc md oo ng mf mg op nh mi mj oq ni ml mm ls ij bi translated">注意:在实践中，很难达到这个平衡点，因此会产生一些问题。其中之一是<strong class="lv ja">模式崩溃问题</strong>，发生器在训练的早期阶段产生一个非常好的输出，然后更频繁地使用它，因为鉴别器还不能将其归类为假的。结果，生成器仅学习输出其中具有很少多样性的数据。有各种方法可以克服这一点，例如使用不同的损失函数，如<a class="ae mn" href="https://arxiv.org/abs/1701.07875" rel="noopener ugc nofollow" target="_blank"> <strong class="lv ja"> Wasserstein损失</strong> </a> <strong class="lv ja">。</strong></p></blockquote><h1 id="4129" class="jw jx iq bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">甘斯能做什么？</h1><p id="7b3d" class="pw-post-body-paragraph lt lu iq lv b lw oe ly lz ma of mc md kz og mf mg lc oh mi mj lf oi ml mm ls ij bi translated">GANs的主要目标是从给定的数据集生成新的样本。自从GANs发明以来，他们已经发展到可以用更好的结果和更多的特性来完成这个任务。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi or"><img src="../Images/49a048520b6931f5cf20f06a5ad72756.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*AyzNHv-ftBzHQ2uwmwG08A.png"/></div><p class="na nb gj gh gi nc nd bd b be z dk translated">Ian J. Goodfellow等人2014年，<a class="ae mn" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank">生成对抗网络</a></p></figure><p id="e7e1" class="pw-post-body-paragraph lt lu iq lv b lw ne ly lz ma nf mc md kz ng mf mg lc nh mi mj lf ni ml mm ls ij bi translated">上图显示的是Ian Goodfellow等人在2014年发表的第一篇GANs论文的输出结果。集合a)包含在手写数字的MNIST数据集上生成的输出，集合b)示出了Toronto Face数据集的结果，集合c)具有来自CIFAR-10数据集上的全连接模型的输出，集合d)包含由CIFAR-10数据集上的卷积鉴别器和“去卷积”生成器模型生成的输出。</p><p id="8d47" class="pw-post-body-paragraph lt lu iq lv b lw ne ly lz ma nf mc md kz ng mf mg lc nh mi mj lf ni ml mm ls ij bi translated"><strong class="lv ja"> Progressive GAN </strong>于2017年推出，作者表明，通过在开始时训练生成器输出低分辨率图像，并随着训练的进行提高分辨率，可以显著提高生成图像的质量。通过这种方式，他们能够从CelebA HQ数据集上训练的生成器中生成1024x1024分辨率的高质量人脸图像。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi os"><img src="../Images/b7d9c284f2f7ae4749df3bd05d2e2dc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AF5LMg1rzozJvRi5_p2jfA.png"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated">Tero Karras，Timo Aila，Samuli Laine，Jaakko Lehtinen 2017，<a class="ae mn" href="https://arxiv.org/abs/1710.10196" rel="noopener ugc nofollow" target="_blank">为提高质量、稳定性和变化性而逐步种植GANs】</a></p></figure><p id="22b9" class="pw-post-body-paragraph lt lu iq lv b lw ne ly lz ma nf mc md kz ng mf mg lc nh mi mj lf ni ml mm ls ij bi translated">关于<strong class="lv ja">DC GAN</strong>的论文是最重要的研究之一，它表明在GAN模型中使用深度卷积有助于产生更好的结果。他们没有使用任何有助于提高效率的完全连接和池化层。</p><p id="6519" class="pw-post-body-paragraph lt lu iq lv b lw ne ly lz ma nf mc md kz ng mf mg lc nh mi mj lf ni ml mm ls ij bi translated">本文中有趣的一点是<strong class="lv ja">向量空间算法</strong>，它显示输出结果可以根据简单的算术等式进行更改，如下图所示。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi ot"><img src="../Images/3a1854149662103683c10d8bced93655.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7NYvilnrM2yrId_nkB5q_Q.png"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated">亚历克·拉德福德等2015，<a class="ae mn" href="https://arxiv.org/abs/1511.06434" rel="noopener ugc nofollow" target="_blank">深度卷积生成对抗网络的无监督表示学习</a></p></figure><p id="bb5d" class="pw-post-body-paragraph lt lu iq lv b lw ne ly lz ma nf mc md kz ng mf mg lc nh mi mj lf ni ml mm ls ij bi translated"><strong class="lv ja">Cycle-gan</strong>能够将输入类映射到期望的输出集。训练是在两组数据上进行的，不需要其他标签。该模型学习将一组图像转换成另一组图像。</p><p id="c107" class="pw-post-body-paragraph lt lu iq lv b lw ne ly lz ma nf mc md kz ng mf mg lc nh mi mj lf ni ml mm ls ij bi translated">在下面的图像中，你可以看到马的图像是如何转换成斑马的图像的。这里值得注意的一点是，该模型了解到，相对于斑马，马主要与更绿的草原相关联。因此，该模型的结果是，斑马的输出背景较暗。当我们试图将斑马图像转换为马时，这也会产生更绿的马。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi ou"><img src="../Images/beb17a42f5cf5c7d16b583f84a599f91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xqG5uC9b4B5OC0hdhxZUag.png"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated">朱俊彦，朴泰星，菲利普·伊索拉，阿列克谢·埃夫罗斯2017，<a class="ae mn" href="https://arxiv.org/abs/1703.10593" rel="noopener ugc nofollow" target="_blank">使用循环一致对抗网络的不成对图像到图像翻译</a></p></figure><p id="391d" class="pw-post-body-paragraph lt lu iq lv b lw ne ly lz ma nf mc md kz ng mf mg lc nh mi mj lf ni ml mm ls ij bi translated">最后，最有趣的GAN变体之一是<strong class="lv ja"> StarGAN。</strong>它获取面部的输入图像，然后将其映射到相应的提升面部特征。</p><p id="c764" class="pw-post-body-paragraph lt lu iq lv b lw ne ly lz ma nf mc md kz ng mf mg lc nh mi mj lf ni ml mm ls ij bi translated">例如，你可以输入一张脸并将其转换成相反的性别，使其更年轻或更老，改变其肤色，等等。</p><p id="b355" class="pw-post-body-paragraph lt lu iq lv b lw ne ly lz ma nf mc md kz ng mf mg lc nh mi mj lf ni ml mm ls ij bi translated">下图的右侧显示了如何使用StarGAN来改变任何输入人脸的面部表情。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi ov"><img src="../Images/dd39cd2e17993db3d191b68b11978a97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cAMjJ9zPMFlePmhs-1Vs9w.png"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated">Yunjey Choi等人2017，<a class="ae mn" href="https://arxiv.org/abs/1711.09020" rel="noopener ugc nofollow" target="_blank"> StarGAN:用于多领域图像到图像翻译的统一生成对抗网络</a></p></figure><h1 id="a819" class="jw jx iq bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">结论</h1><p id="b4ef" class="pw-post-body-paragraph lt lu iq lv b lw oe ly lz ma of mc md kz og mf mg lc oh mi mj lf oi ml mm ls ij bi translated">所以，你已经看到甘有多强大，他们能做什么。关于GANs最令人惊奇的事情是，它是一个相当复杂的目标的非常简单的实现。</p><p id="d044" class="pw-post-body-paragraph lt lu iq lv b lw ne ly lz ma nf mc md kz ng mf mg lc nh mi mj lf ni ml mm ls ij bi translated">如果你对卷积神经网络的工作原理和反向传播有一个基本的了解，那么你可以马上开始研究GANs。这篇文章是为了介绍生成性对抗网络背后的基本工作，以及它的变化如何有助于产生不同的和更好的结果。</p><p id="2549" class="pw-post-body-paragraph lt lu iq lv b lw ne ly lz ma nf mc md kz ng mf mg lc nh mi mj lf ni ml mm ls ij bi translated"><strong class="lv ja"> <em class="od">在以后的帖子中，我会分享如何从头开始构建GAN并从中产生美妙的结果。我已经构建了一个DCGAN来从CelebA数据集生成新的面孔，以及一个条件GAN来学习获取一个动画的黑白草图并将其转换为彩色输出，如下所示。</em> </strong></p><div class="mp mq mr ms gt ab cb"><figure class="ow mt ox oy oz pa pb paragraph-image"><img src="../Images/896dedbd5e6e907b22fba77982002b77.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/1*uCabC476SAf8zW5Y4cPsBw.gif"/></figure><figure class="ow mt ox oy oz pa pb paragraph-image"><img src="../Images/db38479a5d099269c1b00f64a55d9a6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/1*4jR_s5GPI4qNvH4qfdRCsA.gif"/><p class="na nb gj gh gi nc nd bd b be z dk pc di pd pe translated">在数据集上训练DCGAN模型，显示左边的<strong class="bd oc"> MNIST和右边的</strong>西里巴<strong class="bd oc">(图片由作者提供)</strong></p></figure></div><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi pf"><img src="../Images/d332af23c9cf1127939ffd52b8914532.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o5hxKIhqUr8MMzB_CNFHzQ.png"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated"><strong class="bd oc">左栏为之前未见过的黑白草图测试图像，右栏为模型预测的彩色输出图像，但不知道真实情况</strong>(图片由作者提供)</p></figure></div></div>    
</body>
</html>