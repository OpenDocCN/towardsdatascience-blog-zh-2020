<html>
<head>
<title>How To Model Time Series Data With Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用线性回归对时间序列数据建模</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-model-time-series-data-with-linear-regression-cd94d1d901c0?source=collection_archive---------0-----------------------#2020-04-08">https://towardsdatascience.com/how-to-model-time-series-data-with-linear-regression-cd94d1d901c0?source=collection_archive---------0-----------------------#2020-04-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="4d8a" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/time-series-modeling" rel="noopener" target="_blank">探索时间序列建模</a></h2><div class=""/><div class=""><h2 id="8189" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">用Python代码进行时间序列建模</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/4ad0d546260a21e7f22e90d295ac4167.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*NS8utnPL-0YBZzBJ"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上<a class="ae lh" href="https://unsplash.com/@tangib?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> tangi bertin </a>拍摄的照片</p></figure><p id="391c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">欢迎回来！这是<a class="ae lh" href="https://towardsdatascience.com/tagged/time-series-modeling" rel="noopener" target="_blank">专栏</a>的第4篇文章，探讨用Python代码分析和建模时间序列数据。在前三篇文章中，我们已经介绍了<a class="ae lh" rel="noopener" target="_blank" href="/fundamental-statistics-7770376593b"><strong class="lk jd"/></a><a class="ae lh" rel="noopener" target="_blank" href="/how-to-analyse-a-single-time-series-variable-11dcca7bf16c"><strong class="lk jd">单个时间序列变量的分析</strong> </a>和<a class="ae lh" rel="noopener" target="_blank" href="/how-to-analyse-multiple-time-series-variable-5a8d3a242a2e"> <strong class="lk jd">多个时间序列变量的分析</strong> </a>。从这篇文章开始，我们将进一步探索使用线性回归建模时间序列数据。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="0934" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">1.普通最小二乘法(OLS)</h1><p id="2018" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">我们在学校都学过线性回归，线性回归的概念似乎很简单。给定因变量y对自变量x的散点图，我们可以找到一条与数据非常吻合的直线。但是等一下，我们如何衡量一条线是否很好地符合数据？我们不能只是将图形可视化，然后说某条线比其他线更符合数据，因为不同的人可能会做出不同的评估决策。如何才能量化评价？</p><p id="b1b3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">普通最小二乘法(OLS)是一种量化评价不同回归线的方法。根据OLS，我们应该选择使观察到的因变量和预测的因变量之间的差的平方和最小化的回归线。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ni"><img src="../Images/5bcd5f29fd34d4ccf37a5f6364f8b069.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cfD_EOOIo6sG1Thch6QeTQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">OLS回归图解</p></figure><h1 id="5738" class="ml mm it bd mn mo nj mq mr ms nk mu mv ki nl kj mx kl nm km mz ko nn kp nb nc bi translated">2.高斯-马科夫假设</h1><p id="2be3" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">根据OLS的评价标准，我们可以找到一条最符合观测数据的直线。该行的一般格式是:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi no"><img src="../Images/6f3796dd5e406299ee29362e4bef8568.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BsIOb5DT_4L6ZOqsyK7M7A.png"/></div></div></figure><p id="986c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这里，μᵢ是剩余的术语，是yᵢ的一部分，xᵢ.无法解释我们可以根据OLS的要求找到这条最好的回归线，但是我们能肯定OLS产生了最好的估计量吗？一个例子是，当存在异常值时，根据OLS计算出的“最佳”回归线显然不符合观察到的数据。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ni"><img src="../Images/4999b8dc3059df265756feb62eaed45a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zvhHrnoVtF8QZrS-tfnIiQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">OLS没有生成描述数据的最佳回归线的情况</p></figure><p id="1aac" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> 2.1截面数据的高斯-马尔可夫假设</strong></p><p id="5912" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">事实证明，只有当某些假设得到满足，OLS计算出最好的线性无偏估计量(蓝色)，很好地估计人口参数。对于横截面数据，高斯-马科夫假设有六个假设，确保使用OLS计算的估计量是蓝色的。当任何一个高斯-马科夫假设被违反时，使用OLS计算的样本参数不再能很好地代表总体参数。</p><ol class=""><li id="aa71" class="np nq it lk b ll lm lo lp lr nr lv ns lz nt md nu nv nw nx bi translated">参数的线性。这个假设要求参数β是线性的。然而，对自变量的线性没有要求。yᵢ=α + βxᵢ +μᵢ和yᵢ=α + βIn(xᵢ) +μᵢ都有线性β。</li><li id="47a7" class="np nq it lk b ll ny lo nz lr oa lv ob lz oc md nu nv nw nx bi translated">自变量x和因变量y都是随机变量。值得一提的是，如果x和y都是随机变量，则余项μ不会自相关。</li><li id="c06a" class="np nq it lk b ll ny lo nz lr oa lv ob lz oc md nu nv nw nx bi translated">多个独立变量x₁和x₂.之间不存在完美的共线性如果存在完美的共线性，线性回归结果将是随机的，因为它不能区分x₁和x₂.的贡献通常，当R结果很好，但每个独立变量的t检验很差时，这表明存在共线性。</li><li id="6ee0" class="np nq it lk b ll ny lo nz lr oa lv ob lz oc md nu nv nw nx bi translated">剩余项μ是内生的。要内生性，μᵢ不随xᵢ.而变它可以表达为cov(μᵢ，xᵢ)=0.内生性可能产生于反向因果关系或x中的测量误差，导致cov(μᵢ，xᵢ)！=0.</li><li id="5c9a" class="np nq it lk b ll ny lo nz lr oa lv ob lz oc md nu nv nw nx bi translated">剩余项μᵢ.的同方差性它要求μᵢ的方差不随xᵢ.而变</li><li id="bad9" class="np nq it lk b ll ny lo nz lr oa lv ob lz oc md nu nv nw nx bi translated">剩余项μᵢ.没有自相关它可以表达为cov(μᵢ，μⱼ)=0.μᵢ的自相关可由遗漏的独立变量、错误指定的回归函数、独立变量中的测量误差和聚类误差引起。</li></ol><p id="3036" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">时间序列数据的2.2高斯-马尔可夫假设</strong></p><p id="8965" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">时间序列数据与横截面数据略有不同。对于横截面数据，我们从总体中获取样本，高斯-马尔可夫假设要求自变量x和因变量y都是随机变量。对于时间序列数据，我们是从同一个过程中得到样本，不能再假设自变量x是随机变量。因此，高斯-马尔可夫假设对于时间序列数据在内生性、同方差性和无自相关性方面更为严格。由于x不再是一个随机变量，需要满足所有时间点的所有xₖ的要求，而不仅仅是剩余项μᵢ.在该时间点的xᵢ</p><h1 id="1c78" class="ml mm it bd mn mo nj mq mr ms nk mu mv ki nl kj mx kl nm km mz ko nn kp nb nc bi translated">3.线性回归的假设检验</h1><p id="45b4" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated"><strong class="lk jd">3.1 Python中的线性回归</strong></p><p id="a09f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这里，我们继续使用从<a class="ae lh" href="https://sg.finance.yahoo.com/quote/AAPL/" rel="noopener ugc nofollow" target="_blank">雅虎财经</a>获得的历史AAPL价格和间谍价格。我们先把AAPL价格和间谍价格分开。然后，为了发现AAPL价格在多大程度上可以由整体股票市场价格来解释，我们将建立以SPY价格为自变量x和AAPL价格为因变量y的线性回归模型</p><p id="8c96" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">使用Python中的statsmodels库可以轻松完成线性回归。</p><pre class="ks kt ku kv gt od oe of og aw oh bi"><span id="ba74" class="oi mm it oe b gy oj ok l ol om">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import statsmodels.api as sm</span><span id="c58b" class="oi mm it oe b gy on ok l ol om">AAPL_price = pd.read_csv('AAPL.csv',usecols=['Date', 'Close'])<br/>SPY_price = pd.read_csv('SPY.csv',usecols=['Date', 'Close'])</span><span id="edff" class="oi mm it oe b gy on ok l ol om">X = sm.add_constant(SPY_price['Close'])<br/>model = sm.OLS(AAPL_price['Close'],X)<br/>results = model.fit()</span><span id="39b2" class="oi mm it oe b gy on ok l ol om">plt.scatter(SPY_price['Close'],AAPL_price['Close'],alpha=0.3)<br/>y_predict = results.params[0] + results.params[1]*SPY_price['Close']<br/>plt.plot(SPY_price['Close'],y_predict, linewidth=3)</span><span id="1d40" class="oi mm it oe b gy on ok l ol om">plt.xlim(240,350)<br/>plt.ylim(100,350)<br/>plt.xlabel('SPY_price')<br/>plt.ylabel('AAPL_price')<br/>plt.title('OLS Regression')</span><span id="c4d9" class="oi mm it oe b gy on ok l ol om">print(results.summary())</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/6db63d1ce9f392286a28b246ed731aa2.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*cWBMsoGgEhCO39_nrp2Log.png"/></div></figure><p id="2a6e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">连同可视化OLS线性回归结果的绘图，我们可以打印一个汇总表，如下所示:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi op"><img src="../Images/9ef80c4d6445d80a6235b5767c16ef1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*ST-bL7LLxhgk8r8Rn7C3YQ.png"/></div></figure><p id="b0ae" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们为什么要做这些复杂的假设检验？我们如何解释这些假设检验结果？我们将在接下来的会议中回答这些问题。</p><p id="75b3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> 3.2为什么要对线性回归进行假设检验？</strong></p><p id="409e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">由于我们使用样本来估计总体，我们需要评估样本参数估计总体参数的效果。对样本参数进行假设检验，需要知道样本参数分布。</p><p id="1ae2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">根据中心极限定理，当样本量足够大时，β的样本分布为正态分布:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oq"><img src="../Images/47b024eede022e9de6864acbf770ef7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ruvZ0Xc2hJxg7BfdIpIj3w.png"/></div></div></figure><p id="c801" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，我们不知道确切的总体剩余方差(σ)。我们可以用样本残差方差(σʰᵃᵗ)来估计总体残差方差，但这样样本β分布就不再是正态分布了。它变成了t分布:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi or"><img src="../Images/0373950db810a53bf1e89f0a0f88a3de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QQD_uLVv_rpwwdF_0ooXOA.png"/></div></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi os"><img src="../Images/f830b2b709e0ff2ffd71ce1110f76f56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jJKjgT5ugFYy9CbY1p6iEQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">β的样本分布服从t分布，因为我们不确切知道总体残差方差的方差。标准误差是样本参数的方差。</p></figure><p id="faa2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> 3.3如何解读OLS统计摘要？</strong></p><p id="fa17" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在是时候回到OLS回归结果表，并尝试解释汇总结果。</p><p id="5e44" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">汇总表的第一部分有R和F统计量，它们衡量自变量对因变量的总体解释能力。</p><p id="0c6d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">r是解释的误差平方和除以误差平方和。R介于0和1之间，R越大，说明自变量能更好地解释因变量。R =解释的误差平方和/误差平方和。自变量越多，得到的R将越接近1，但同时，自变量越多可能导致过拟合。通过惩罚多余的自变量，调整后的R偏好较少的自变量。</p><p id="efa4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">独立变量联合效应的统计检验。F统计检验的低p值表明自变量不能很好地解释因变量。</p><p id="0cd7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">汇总表的第二部分是t统计量，对每个独立变量进行测试。同时使用F统计量和t统计量有助于检查自变量中是否存在共线性。好的F统计量和差的t统计量表示共线性。</p><p id="ed5e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Durbin-Watson和Jarque-Bera在第三次会议的汇总表中报告了残差项的平稳性和正态性，这将在下面的会议中详细讨论。</p><h1 id="06c8" class="ml mm it bd mn mo nj mq mr ms nk mu mv ki nl kj mx kl nm km mz ko nn kp nb nc bi translated">4.线性回归残差</h1><p id="52af" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">剩余项很重要。通过使用残差项检查高斯-马科夫假设是否成立，我们可以推断线性回归的质量。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ot"><img src="../Images/4cd87bd9a276cfeb01a2dfa233d9429a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3sd1TlhWfGSt-f4wKsURIw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">样本β的期望值</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ou"><img src="../Images/241c639287c15ce2c87bf4b5b4b0ed8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-q3Je4RyUrwGAe0zLe7unA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">样本β的方差</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/8f70a649d468af59fe3da4fcaf60483c.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*QEA1QMyqLKsxVuFKyz-BZA.png"/></div></figure><p id="cdc0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> 4.1常态测试</strong></p><p id="fc17" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">检验残差是否正态分布是很重要的。如果残差不是正态分布的，则残差不应用于z检验或任何其他从正态分布导出的检验，如t检验、f检验和chi2检验。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ov"><img src="../Images/6f1dce09d084d1ca597212337eba7208.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dXgVdSaG6i-_LNx8oHJnNw.png"/></div></div></figure><pre class="ks kt ku kv gt od oe of og aw oh bi"><span id="3a9c" class="oi mm it oe b gy oj ok l ol om">import pandas as pd<br/>import statsmodels.api as sm<br/>from scipy import stats</span><span id="0fe1" class="oi mm it oe b gy on ok l ol om">AAPL_price = pd.read_csv('AAPL.csv',usecols=['Date', 'Close'])<br/>SPY_price = pd.read_csv('SPY.csv',usecols=['Date', 'Close'])</span><span id="4828" class="oi mm it oe b gy on ok l ol om">X = sm.add_constant(SPY_price['Close'])<br/>model = sm.OLS(AAPL_price['Close'],X)<br/>results = model.fit()</span><span id="92df" class="oi mm it oe b gy on ok l ol om">residual = AAPL_price['Close']-results.params[0] - results.params[1]*SPY_price['Close']</span><span id="54b0" class="oi mm it oe b gy on ok l ol om">print('p value of Jarque-Bera test is: ', stats.jarque_bera(residual)[1])<br/>print('p value of Shapiro-Wilk test is: ', stats.shapiro(residual)[1])<br/>print('p value of Kolmogorov-Smirnov test is: ', stats.kstest(residual, 'norm')[1])</span></pre><p id="ba4b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">输出:</p><p id="10a2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">雅尔克-贝拉检验的p值为:0.0 <br/>夏皮罗-维尔克检验的p值为:9.164991873555915e-20 <br/>科尔莫戈罗夫-斯米尔诺夫检验的p值为:1.134826980654097 e-55</p><p id="1f67" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果我们选择0.05的显著性水平，那么所有三个正态性检验都表明残差项不遵循正态分布。</p><p id="2bd2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> 4.2同质性测试</strong></p><p id="ab14" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">三种常用的异方差统计检验是Goldfeld-Quandt检验、Breusch-Pagan检验和White检验。在同样的序列中，检验更一般的同质性。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ow"><img src="../Images/5ebced9af1f9212625cda9f37aa2e00e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jc9PDg3u1D6nwUxghs1CjA.png"/></div></div></figure><pre class="ks kt ku kv gt od oe of og aw oh bi"><span id="f630" class="oi mm it oe b gy oj ok l ol om">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import statsmodels.api as sm<br/>import statsmodels.stats.api as sms</span><span id="715b" class="oi mm it oe b gy on ok l ol om">AAPL_price = pd.read_csv('AAPL.csv',usecols=['Date', 'Close'])<br/>SPY_price = pd.read_csv('SPY.csv',usecols=['Date', 'Close'])</span><span id="b4f6" class="oi mm it oe b gy on ok l ol om">X = sm.add_constant(SPY_price['Close'])<br/>model = sm.OLS(AAPL_price['Close'],X)<br/>results = model.fit()</span><span id="79f4" class="oi mm it oe b gy on ok l ol om">residual = AAPL_price['Close']-results.params[0] - results.params[1]*SPY_price['Close']</span><span id="60be" class="oi mm it oe b gy on ok l ol om">print('p value of Goldfeld–Quandt test is: ', sms.het_goldfeldquandt(results.resid, results.model.exog)[1])<br/>print('p value of Breusch–Pagan test is: ', sms.het_breuschpagan(results.resid, results.model.exog)[1])<br/>print('p value of White test is: ', sms.het_white(results.resid, results.model.exog)[1])</span></pre><p id="9a48" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">输出是:</p><p id="036b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Goldfeld–Quandt试验的p值为:2.3805273535080445 e-38<br/>breus ch–Pagan试验的p值为:2.599557770260936e-06 <br/>白色试验的p值为:1.0987132773425074e-22</p><p id="2516" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果我们选择0.05的显著性水平，那么所有三个正态性检验都表明残差项不遵循正态分布。</p><p id="5ba3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> 4.3平稳性测试</strong></p><p id="7a1d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Durbin-Watson测试检测滞后为1的残差项的自相关，而Breusch-Godfrey测试检测滞后为N的残差项的自相关，具体取决于测试中的设置。</p><pre class="ks kt ku kv gt od oe of og aw oh bi"><span id="ab44" class="oi mm it oe b gy oj ok l ol om">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import statsmodels.api as sm</span><span id="311b" class="oi mm it oe b gy on ok l ol om">AAPL_price = pd.read_csv('AAPL.csv',usecols=['Date', 'Close'])<br/>SPY_price = pd.read_csv('SPY.csv',usecols=['Date', 'Close'])</span><span id="de9e" class="oi mm it oe b gy on ok l ol om">X = sm.add_constant(SPY_price['Close'])<br/>model = sm.OLS(AAPL_price['Close'],X)<br/>results = model.fit()</span><span id="3736" class="oi mm it oe b gy on ok l ol om">import statsmodels.stats.api as sms<br/>print('The Durbin-Watson statistic is: ', sms.durbin_watson(results.resid))<br/>print('p value of Breusch-Godfrey test is: ', sms.acorr_breusch_godfrey(results,nlags=1)[3])</span></pre><p id="6ab9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">输出:</p><p id="d3e8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">德宾-沃森统计量为:0.06916423461968918 <br/>布氏-戈弗雷检验的p值为:4.6463126097712 e-150</p><p id="8fbb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Durbin-Watson和Breusch-Godfrey检验都表明滞后为1的剩余项存在自相关。当德宾-沃森统计量为2时，不存在自相关。当德宾-沃森统计量趋向于0时，存在正自相关。</p><h1 id="59cc" class="ml mm it bd mn mo nj mq mr ms nk mu mv ki nl kj mx kl nm km mz ko nn kp nb nc bi translated">5.解决违反高斯-马科夫假设的问题</h1><p id="286e" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated"><strong class="lk jd"> 5.1违反高斯-马科夫假设</strong></p><p id="8acc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当违反高斯-马科夫假设时，从样本计算出的估计量不再是蓝色的。下表显示了违反Gauss-Marcov假设如何影响线性回归质量。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ox"><img src="../Images/5e7b2c97802845b0ce6ac86c77b9e76d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z1Cz1U_AozDit32HkN4jAg.png"/></div></div></figure><p id="51de" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> 5.2加权最小二乘法(WLS) </strong></p><p id="d9fb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了解决异方差误差，可以使用加权最小二乘法(WLS)。WLS变换自变量和因变量，因此OLS在变换后保持蓝色。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oy"><img src="../Images/30c029237069d8e21304fd4ba4cbd682.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k_F7OxRdKaYoB393OCPqHQ.png"/></div></div></figure><p id="ac61" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> 5.3广义最小二乘法(GLS) </strong></p><p id="63e0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了考虑异方差误差和序列相关误差，可以使用广义最小二乘法(GLS)。GLS转换自变量和因变量的方式比WLS更复杂，因此OLS在转换后仍为蓝色。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oz"><img src="../Images/def58667052eaf162b060078d14b743a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LMmh1bZmxm-4MqRLUMgomA.png"/></div></div></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="0d42" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">摘要</h1><p id="a251" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">在这篇文章中，我们了解到只有当高斯-马科夫假设成立时，OLS才能产生好的估计量。因此，线性回归后，检查残差项以确保不违反高斯-马科夫假设总是很重要的。幸运的是，使用Python中的statsmodels库，在线性回归过程中会自动进行许多统计测试。OLS线性回归汇总表的简单打印使我们能够快速评估线性回归的质量。如果违反了高斯-马科夫假设，WLS和GLS的进一步解决方案也可用于转换自变量和因变量，使OLS保持蓝色。</p><p id="263d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">希望您喜欢使用线性回归学习时间序列数据建模！</p></div></div>    
</body>
</html>