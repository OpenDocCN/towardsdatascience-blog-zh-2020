<html>
<head>
<title>Once Upon a Repository: How to Write Readable, Maintainable Code with PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从前的知识库:如何用PyTorch编写可读、可维护的代码</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/once-upon-a-repository-how-to-write-readable-maintainable-code-with-pytorch-951f03f6a829?source=collection_archive---------24-----------------------#2020-01-30">https://towardsdatascience.com/once-upon-a-repository-how-to-write-readable-maintainable-code-with-pytorch-951f03f6a829?source=collection_archive---------24-----------------------#2020-01-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="3618" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://medium.com/towards-data-science/data-science-in-the-real-world/home" rel="noopener"> <strong class="ak">现实世界中的数据科学</strong> </a></h2><div class=""/><div class=""><h2 id="ab71" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">深度学习代码库系列的英雄之旅—第一部分</h2></div><p id="a20f" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">由<a class="ae ln" href="https://www.linkedin.com/in/dan-malowany-78b2b21/" rel="noopener ugc nofollow" target="_blank">丹·马洛瓦尼</a>和<a class="ae ln" href="https://www.linkedin.com/in/gal-hyams-2146a662/" rel="noopener ugc nofollow" target="_blank">加尔·海姆斯</a> <br/> <a class="lo lp ep" href="https://medium.com/u/7743e9a45144?source=post_page-----951f03f6a829--------------------------------" rel="noopener" target="_blank">创作的快板艾团队</a></p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/18628d9f9c7e20f5d0ec78a184acce08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*XpQT3YR7S1rKu3q3B65W3w.png"/></div></figure><p id="13d9" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们的目标都是编写一个可维护的模块化代码库，支持从研究到生产的R&amp;D过程。高效和成功的深度学习项目的关键，这不是一个容易的壮举。这就是为什么我们决定写这个博客系列——分享我们从众多深度学习项目中获得的经验，并展示使用开源工具实现这一目标的方法。</p><p id="7ae2" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">本系列的第一篇文章是关于如何利用PyTorch生态系统和Allegro Trains experiments manager来轻松编写可读和可维护的计算机视觉代码的教程。我们主要关注PyTorch生态系统中的两个包，Torchvision和Ignite。Torchvision是一个流行的包，由流行的数据集包装器、模型架构和计算机视觉的通用图像转换组成。Ignite是一个新的库，可以简单明了地将指标报告、提前停止、模型检查点和其他功能添加到您的培训循环中。在这篇文章中，我们编写了一个代码库，在<a class="ae ln" href="http://cocodataset.org/#home" rel="noopener ugc nofollow" target="_blank"> COCO </a>数据集上训练和评估一个<a class="ae ln" href="https://arxiv.org/abs/1703.06870" rel="noopener ugc nofollow" target="_blank"> Mask-RCNN模型</a>。然后，我们将训练数据(损失、准确性等)注册到Pytorch本机<a class="ae ln" href="https://pytorch.org/docs/stable/tensorboard.html" rel="noopener ugc nofollow" target="_blank"> Tensorboard </a>中，并使用<a class="ae ln" href="https://github.com/allegroai/trains" rel="noopener ugc nofollow" target="_blank">Allegro Trains</a>experiment&amp;autoML manager来管理和跟踪我们的训练实验。通过这些步骤，我们实现了一个无缝的、有组织的、高效的模型培训流程。</p><h1 id="a24d" class="ly lz it bd ma mb mc md me mf mg mh mi ki mj kj mk kl ml km mm ko mn kp mo mp bi translated">我们的开源资源</h1><p id="7674" class="pw-post-body-paragraph kr ks it kt b ku mq kd kw kx mr kg kz la ms lc ld le mt lg lh li mu lk ll lm im bi translated">Ignite框架的本质是它的引擎类，该类在数据集上循环给定次数，并执行处理功能。例如，训练引擎循环遍历训练数据集并更新模型参数。此外，引擎具有可配置的事件系统，便于运行的每个步骤上的交互:(1)引擎启动/完成；(2)纪元开始/完成；(3)迭代开始/完成。因此，您可以将自定义代码作为事件处理程序来执行。<br/> Allegro Trains是一个“自动逻辑”实验&amp; AutoML manager，它通过代码版本控制、性能指标和模型来源来跟踪和控制培训过程。Trains还为工作人员灵活地执行队列管理，并使多个用户能够协作和管理他们的实验。</p><h1 id="3dd6" class="ly lz it bd ma mb mc md me mf mg mh mi ki mj kj mk kl ml km mm ko mn kp mo mp bi translated">让代码开始</h1><p id="155d" class="pw-post-body-paragraph kr ks it kt b ku mq kd kw kx mr kg kz la ms lc ld le mt lg lh li mu lk ll lm im bi translated">请注意，为了运行本教程，应该安装以下开源包:PyTorch、TorchVision、Ignite、TensorBoard、NumPy和Allegro Trains。请访问以下页面进行安装:</p><ul class=""><li id="b098" class="mv mw it kt b ku kv kx ky la mx le my li mz lm na nb nc nd bi translated"><a class="ae ln" href="https://pytorch.org/get-started/locally/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a></li><li id="a723" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm na nb nc nd bi translated"><a class="ae ln" href="https://pytorch.org/docs/stable/torchvision/index.html" rel="noopener ugc nofollow" target="_blank">火炬传递</a></li><li id="ba86" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm na nb nc nd bi translated"><a class="ae ln" href="https://pytorch.org/ignite/" rel="noopener ugc nofollow" target="_blank"> PyTorch点燃</a></li><li id="d7f4" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm na nb nc nd bi translated"><a class="ae ln" href="https://pytorch.org/docs/stable/tensorboard.html" rel="noopener ugc nofollow" target="_blank">张量板</a></li><li id="3747" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm na nb nc nd bi translated"><a class="ae ln" href="https://numpy.org/" rel="noopener ugc nofollow" target="_blank"> NumPy </a></li><li id="7fb1" class="mv mw it kt b ku ne kx nf la ng le nh li ni lm na nb nc nd bi translated"><a class="ae ln" href="https://github.com/allegroai/trains" rel="noopener ugc nofollow" target="_blank">快板列车</a></li></ul><p id="733e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们从Trains两条线的集成开始编码。将这两行代码添加到任何代码都会在您执行Trains任务时启动它。project_name参数将在Trains web app中打开一个专用项目(如果不存在),并以task_name参数中定义的名称注册您的实验。</p><p id="a5dc" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">每次你执行代码时，Trains会自动在创建的任务中记录你所有的实验信息(git repo、commit id、使用的python包、argparse参数等)，这将让你在默认的演示服务器或你自己的私有<a class="ae ln" href="https://github.com/allegroai/trains-server" rel="noopener ugc nofollow" target="_blank"> Trains服务器</a>上跟踪、复制和管理你所有的实验(即做科学实验)。此外，将argparse参数注册到Trains任务中可以在以后使用<a class="ae ln" href="https://github.com/allegroai/trains-agent" rel="noopener ugc nofollow" target="_blank"> Trains代理</a>执行自动超参数优化。</p><pre class="lr ls lt lu gt nj nk nl nm aw nn bi"><span id="895c" class="no lz it nk b gy np nq l nr ns"><em class="nt">from </em>trains <em class="nt">import </em>Task<br/>task = Task.init(project_name='Object Detection with TRAINS, Ignite<br/>                               and TensorBoard',<br/>                 task_name='Train MaskRCNN with torchvision')</span></pre><p id="7a46" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">Trains具有的另一个有用的特性是将配置数据连接到模型的能力，因此在系统中注册的每个模型都将包括用于训练它的配置数据。您可以连接一个配置文件，或者只提供一个配置字典。为此，我们还将在两行集成代码之后添加以下两行代码。</p><pre class="lr ls lt lu gt nj nk nl nm aw nn bi"><span id="7b34" class="no lz it nk b gy np nq l nr ns"># Connect the model configuration data to train as well: configuration_data = {'image_size': 512,<br/>                      'mask_predictor_hidden_layer': 256}<br/>configuration_data = task.connect_configuration(configuration_data)</span></pre><h1 id="834c" class="ly lz it bd ma mb mc md me mf mg mh mi ki mj kj mk kl ml km mm ko mn kp mo mp bi translated">数据争论</h1><p id="801a" class="pw-post-body-paragraph kr ks it kt b ku mq kd kw kx mr kg kz la ms lc ld le mt lg lh li mu lk ll lm im bi translated">为了训练Torchvision模型，我们使用__getitem__方法将数据集设置在一个类中，该方法将下一个数据集实例作为PIL图像元组和元数据字典返回。元数据字典包括将用于在每个图像上训练模型的地面真相的盒子、标签和遮罩。__getitem__方法通过对图像和元数据执行提供给类构造函数__init__的转换来结束。</p><pre class="lr ls lt lu gt nj nk nl nm aw nn bi"><span id="1fe1" class="no lz it nk b gy np nq l nr ns"><em class="nt">class </em>CocoMask(CocoDetection):<br/>    <em class="nt">def __init__</em>(self, <em class="nt">root</em>, <em class="nt">annFile</em>, <em class="nt">transform</em>=<em class="nt">None</em>,<br/>                 <em class="nt">target_transform</em>=<em class="nt">None</em>, <em class="nt">transforms</em>=<em class="nt">None</em>,<br/>                 <em class="nt">use_mask</em>=<em class="nt">True</em>):<br/>        super(CocoMask, self).__init__(<em class="nt">root</em>, <em class="nt">annFile</em>, <em class="nt">transforms</em>,<br/>              <em class="nt">target_transform</em>, <em class="nt">transform</em>)<br/>        self.transforms = <em class="nt">transforms<br/>        </em>self.use_mask = <em class="nt">use_mask<br/>    <br/>    def __getitem__</em>(self, <em class="nt">index</em>): <br/>        coco = self.coco<br/>        img_id = self.ids[<em class="nt">index</em>]<br/>        ann_ids = coco.getAnnIds(imgIds=img_id)<br/>        target = coco.loadAnns(ann_ids)<br/>        <em class="nt">if </em>len(ann_ids) == 0:<br/>            <em class="nt">return None<br/>        <br/>        </em>path = coco.loadImgs(img_id)[0]['file_name']<br/>        img = Image.open(os.path.join(self.root,<br/>                         path)).convert('RGB')<br/>        <br/>        # From boxes [x, y, w, h] to [x1, y1, x2, y2]<br/>        new_target = {"image_id":torch.as_tensor(target[0]<br/>                                 ['image_id'], dtype=torch.int64),<br/>                      "area":torch.as_tensor([obj['area'] <br/>                             <em class="nt">for </em>obj <em class="nt">in </em>target],<br/>                             dtype=torch.float32),<br/>                      "iscrowd":torch.as_tensor([obj['iscrowd'] <br/>                                <em class="nt">for </em>obj <em class="nt">in </em>target], <br/>                                dtype=torch.int64),<br/>                      "boxes":torch.as_tensor([obj['bbox'][:2] + <br/>                              list(map(add, obj['bbox'][:2], <br/>                              obj['bbox'][2:])) <br/>                              <em class="nt">for </em>obj <em class="nt">in </em>target], <br/>                              dtype=torch.float32),<br/>                      "labels": torch.as_tensor([obj['category_id'] <br/>                                <em class="nt">for </em>obj <em class="nt">in </em>target], <br/>                                dtype=torch.int64)}<br/>        <em class="nt">if </em>self.use_mask:<br/>            mask = [coco.annToMask(ann) <em class="nt">for </em>ann <em class="nt">in </em>target]<br/>            <em class="nt">if </em>len(mask) &gt; 1:<br/>                mask = np.stack(tuple(mask), axis=0)<br/>            new_target["masks"] = torch.as_tensor(mask,<br/>                                  dtype=torch.uint8)<br/>        <br/>        <em class="nt">if </em>self.transforms <em class="nt">is not None</em>:<br/>            img, new_target = self.transforms(img, new_target)<br/>        <br/>        <em class="nt">return </em>img, new_target</span></pre><p id="8b1c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">一旦使用__getitem__方法将数据包装在一个类中，就可以将训练验证集构造为PyTorch数据集，并启动相应的数据加载器。DataLoader类基本上提供了一个高效的迭代器，它使用CPU加载和准备数据，而GPU运行深度学习模型。该类为用户提供了对常见深度学习数据加载属性的控制，如批量大小、随机播放等。注意，除了加载器之外，下面的函数也返回‘标签枚举’。它是一个字典，将标签名称与它们的数字id连接起来，这些数字id将在稍后阶段使用。</p><pre class="lr ls lt lu gt nj nk nl nm aw nn bi"><span id="290b" class="no lz it nk b gy np nq l nr ns"><em class="nt">def </em>get_data_loaders(<em class="nt">train_ann_file</em>, <em class="nt">test_ann_file</em>, <em class="nt">batch_size</em>,<br/>                     <em class="nt">test_size</em>, <em class="nt">image_size</em>, <em class="nt">use_mask</em>):<br/>    # Create PyTorch dataset objects, for train and validation data.<br/>    dataset = CocoMask(<br/>        root=Path.joinpath(Path(<em class="nt">train_ann_file</em>).parent.parent, <br/>             <em class="nt">train_ann_file</em>.split('_')[1].split('.')[0]),<br/>        annFile=<em class="nt">train_ann_file</em>,<br/>        transforms=get_transform(train=<em class="nt">True</em>, image_size=<em class="nt">image_size</em>),<br/>        use_mask=<em class="nt">use_mask</em>)<br/>    dataset_test = CocoMask(<br/>        root=Path.joinpath(Path(<em class="nt">test_ann_file</em>).parent.parent, <br/>             <em class="nt">test_ann_file</em>.split('_')[1].split('.')[0]),<br/>        annFile=<em class="nt">test_ann_file</em>,<br/>        transforms=get_transform(train=<em class="nt">False</em>,image_size=<em class="nt">image_size</em>),<br/>        use_mask=<em class="nt">use_mask</em>)<br/>    <br/>    labels_enumeration = dataset.coco.cats<br/>    <br/>    indices_val = torch.randperm(len(dataset_test)).tolist()<br/>    dataset_val = torch.utils.data.Subset(dataset_test,<br/>                  indices_val[:<em class="nt">test_size</em>])<br/><br/>    # set train and validation data-loaders<br/>    train_loader = DataLoader(dataset, batch_size=<em class="nt">batch_size</em>, <br/>                   shuffle=<em class="nt">True</em>, num_workers=6,<br/>                   collate_fn=safe_collate, pin_memory=<em class="nt">True</em>)<br/>    val_loader = DataLoader(dataset_val, batch_size=<em class="nt">batch_size</em>, <br/>                 shuffle=<em class="nt">False</em>, num_workers=6,<br/>                 collate_fn=safe_collate, pin_memory=<em class="nt">True</em>)<br/>    <br/>    <em class="nt">return </em>train_loader, val_loader, labels_enumeration</span></pre><h1 id="42c0" class="ly lz it bd ma mb mc md me mf mg mh mi ki mj kj mk kl ml km mm ko mn kp mo mp bi translated">创造火炬点燃引擎</h1><p id="0fc5" class="pw-post-body-paragraph kr ks it kt b ku mq kd kw kx mr kg kz la ms lc ld le mt lg lh li mu lk ll lm im bi translated">完成数据集准备后，我们用下面的“运行”方法训练MaskRCNN模型。首先，为任务设置模型(作为GPU模型—如果机器上有此选项)。如果您从先前的训练方案继续，加载预训练的模型权重。然后，设置前面代码片段中定义的数据加载器。由于TensorBoard现在是Pytorch的原生版本，您可以轻松导入并设置TensorBoard SummaryWriter来记录您的所有报告。此外，您所有的TensorBoard报告将自动注册到Trains服务器中，以便您能够实时监控您的所有实验。只需设置Tensorboard Summary Writer，并在相关的引擎事件处理程序中添加标量和图像的报告。<br/>最后，创建Ignite训练器和评估器引擎，并运行训练器引擎。</p><pre class="lr ls lt lu gt nj nk nl nm aw nn bi"><span id="7363" class="no lz it nk b gy np nq l nr ns"><em class="nt">def </em>run(<em class="nt">task_args</em>):<br/>    # Define train and test datasets<em class="nt"><br/>    </em>train_loader, val_loader, labels_enum = <br/>       get_data_loaders(<em class="nt">task_args</em>.train_dataset_ann_file,<br/>                        <em class="nt">task_args</em>.val_dataset_ann_file,<br/>                        <em class="nt">task_args</em>.batch_size,<br/>                        <em class="nt">task_args</em>.test_size,<br/>                        configuration_data.get('image_size'),<br/>                        use_mask=True)</span><span id="b0e9" class="no lz it nk b gy nu nq l nr ns">    val_dataset = list(chain.from_iterable(zip(*batch) <br/>                  <em class="nt">for </em>batch <em class="nt">in </em>iter(val_loader)))<br/>    coco_api_val_dataset = convert_to_coco_api(val_dataset)<br/>    num_classes = max(labels_enum.keys()) + 1  <br/>    configuration_data['num_classes'] = num_classes<br/>    <br/>    # set the training device to GPU if available<br/>    device = torch.cuda.current_device() <br/>             <em class="nt">if </em>torch.cuda.is_available() <em class="nt">else </em>torch.device('cpu')<br/>    # optimization for fixed input size    <br/>    torch.backends.cudnn.benchmark = <em class="nt">True <br/>             if </em>torch.cuda.is_available() <em class="nt">else False  </em><br/>    <br/>    model = get_model_instance_segmentation(<br/>            num_classes, <br/>            configuration_data.get('mask_predictor_hidden_layer'))<br/>    iou_types = get_iou_types(model)    </span><span id="de12" class="no lz it nk b gy nu nq l nr ns">    # if there is more than one GPU, parallelize the model<br/>    <em class="nt">if </em>torch.cuda.device_count() &gt; 1:<br/>        print("{} GPUs were detected - we will use all of <br/>              them".format(torch.cuda.device_count()))<br/>        model = torch.nn.DataParallel(model)<br/>    <br/>    # copy the model to each device<br/>    model.to(device)<br/>   <br/>    <em class="nt">if task_args</em>.input_checkpoint:<br/>        print('Loading model checkpoint from'<br/>              .format(<em class="nt">task_args</em>.input_checkpoint))<br/>        input_checkpoint = torch.load(<em class="nt">task_args</em>.input_checkpoint,<br/>                           map_location=torch.device(device))<br/>        model.load_state_dict(input_checkpoint['model'])<br/>    <br/>    writer = SummaryWriter(log_dir=<em class="nt">task_args</em>.log_dir)<br/>    <br/>    # define Ignite's train and evaluation engines<br/>    trainer = create_trainer(model, device)<br/>    evaluator = create_evaluator(model, device)</span><span id="59d5" class="no lz it nk b gy nu nq l nr ns">### Here we will later define the engines events handlers ###<br/>   <br/>    trainer.run(train_loader, max_epochs=task_args.epochs)<br/>    writer.close()</span></pre><p id="2be3" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">让我们深入了解一下Ignite的训练引擎从内部看起来是什么样子。每个引擎都有更新功能，根据给定的数据批次更新模型。它向前传递数据以计算损失，然后通过反向传播更新模型权重，最后返回输入数据、地面实况和损失字典。</p><pre class="lr ls lt lu gt nj nk nl nm aw nn bi"><span id="3fee" class="no lz it nk b gy np nq l nr ns"><em class="nt">def </em>create_trainer(<em class="nt">model</em>, <em class="nt">device</em>):<br/>    <em class="nt">def </em>update_model(<em class="nt">engine</em>, <em class="nt">batch</em>):<br/>        images, targets = copy.deepcopy(<em class="nt">batch</em>)<br/>        images_model, targets_model = prepare_batch(<em class="nt">batch</em>,<br/>                                      device=device)<br/><br/>        loss_dict = model(images_model, targets_model)<br/>        losses = sum(loss <em class="nt">for </em>loss <em class="nt">in </em>loss_dict.values())<br/><br/>        # reduce losses over all GPUs for logging purposes<br/>        loss_dict_reduced = utils.reduce_dict(loss_dict)<br/>        losses_reduced = sum(loss <em class="nt">for </em>loss <em class="nt">in<br/>                         </em>loss_dict_reduced.values())<br/><br/>        loss_value = losses_reduced.item()<br/><br/>        <em class="nt">engine</em>.state.optimizer.zero_grad()<br/>        <em class="nt">if not </em>math.isfinite(loss_value):<br/>            print("Loss is {}, resetting loss and skipping training<br/>                  iteration".format(loss_value))<br/>            print('Loss values were: ', loss_dict_reduced)<br/>            loss_dict_reduced = {k: torch.tensor(0) <em class="nt">for </em>k, v <em class="nt">in<br/>                                 </em>loss_dict_reduced.items()}<br/>        <em class="nt">else</em>:<br/>            losses.backward()<br/>            <em class="nt">engine</em>.state.optimizer.step()<br/><br/>        <em class="nt">if engine</em>.state.warmup_scheduler <em class="nt">is not None</em>:<br/>            <em class="nt">engine</em>.state.warmup_scheduler.step()<br/><br/>        images_model = targets_model = <em class="nt">None<br/><br/>        return </em>images, targets, loss_dict_reduced<br/>    <em class="nt">return </em>Engine(update_model)</span></pre><h1 id="01fa" class="ly lz it bd ma mb mc md me mf mg mh mi ki mj kj mk kl ml km mm ko mn kp mo mp bi translated">定义Ignite处理程序</h1><p id="ae2a" class="pw-post-body-paragraph kr ks it kt b ku mq kd kw kx mr kg kz la ms lc ld le mt lg lh li mu lk ll lm im bi translated">一旦定义了引擎，您就可以释放Ignite事件处理程序的能力。每个引擎都连接有Ignite处理程序，一旦事件发生，这些处理程序就可以执行给定功能。函数的定义是通过在函数中添加一个装饰器来完成的，说明相关的引擎和事件，在我们的例子中，引擎是训练器和评估器。请注意，操作人员必须熟悉他们的引擎。将事件设置为定义引擎的函数的嵌套函数，只是该需求的一个简单实现。下面是我们感兴趣的处理程序。您可以在代码中找到更多信息。</p><p id="cb4a" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">第一个要讨论的训练员是训练开始。在这个处理程序中，在训练过程开始时执行，设置模型优化器和学习率。</p><pre class="lr ls lt lu gt nj nk nl nm aw nn bi"><span id="5ceb" class="no lz it nk b gy np nq l nr ns">@trainer.on(Events.STARTED)<br/><em class="nt">def </em>on_training_started(<em class="nt">engine</em>):<br/>    # construct an optimizer<br/>    params = [p <em class="nt">for </em>p <em class="nt">in </em>model.parameters() <em class="nt">if </em>p.requires_grad]<br/>    <em class="nt">engine</em>.state.optimizer = torch.optim.SGD(<br/>                             params,<br/>                             lr=task_args.lr,<br/>                             momentum=task_args.momentum,                  <br/>                             weight_decay=task_args.weight_decay)<br/>    <em class="nt">engine</em>.state.scheduler = torch.optim.lr_scheduler.StepLR(<br/>                             <em class="nt">engine</em>.state.optimizer, <br/>                             step_size=3, <br/>                             gamma=0.1)<br/>    <em class="nt">if </em>task_args.input_checkpoint <em class="nt">and </em>task_args.load_optimizer:<br/>       <em class="nt">engine</em>.state.optimizer.load_state_dict(<br/>       input_checkpoint['optimizer'])</span><span id="fee5" class="no lz it nk b gy nu nq l nr ns">       <em class="nt">engine</em>.state.scheduler.load_state_dict(<br/>       input_checkpoint['lr_scheduler'])</span></pre><p id="c6b2" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">epoch-completed处理程序将epoch平均精度标量注册到TensorBoard，这使得它可在Trains-Server webapp上查看。然后，它保存模型检查点，该检查点自动神奇地连接为Trains-task输出模型。</p><pre class="lr ls lt lu gt nj nk nl nm aw nn bi"><span id="7158" class="no lz it nk b gy np nq l nr ns">@trainer.on(Events.EPOCH_COMPLETED)<br/><em class="nt">def </em>on_epoch_completed(<em class="nt">engine</em>):<br/>    <em class="nt">engine</em>.state.scheduler.step()<br/>    evaluator.run(val_loader)</span><span id="41c5" class="no lz it nk b gy nu nq l nr ns">    <em class="nt">for </em>res_type <em class="nt">in </em>evaluator.state.coco_evaluator.iou_types:<br/>        average_precision_05 =<br/>        evaluator.state.coco_evaluator.coco_eval[res_type].stats[1]<br/>        writer.add_scalar("validation-{}/average precision 0_5"<br/>                          .format(res_type), average_precision_05,<br/>                          <em class="nt">engine</em>.state.iteration)</span><span id="3e81" class="no lz it nk b gy nu nq l nr ns">    checkpoint_path = os.path.join(task_args.output_dir,<br/>                    'model_epoch_{}.pth'.format(<em class="nt">engine</em>.state.epoch))<br/>    checkpoint = {<br/>        'model': model.state_dict(),<br/>        'optimizer': <em class="nt">engine</em>.state.optimizer.state_dict(),<br/>        'lr_scheduler': <em class="nt">engine</em>.state.scheduler.state_dict(),<br/>        'epoch': <em class="nt">engine</em>.state.epoch,<br/>        'configuration': configuration_data,<br/>        'labels_enumeration': labels_enum}<br/>    utils.save_on_master(checkpoint, checkpoint_path)<br/>    print('Model checkpoint from epoch {} was saved at {}'<br/>          .format(<em class="nt">engine</em>.state.epoch, checkpoint_path))</span></pre><p id="e10b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">以下句柄是评估时句柄的一个示例。它计算并注册调试图像到TensorBoard，可以在Trains-Server上查看——类似于TensorBoard标量。这使用户可以密切监视模型的进展性能。</p><pre class="lr ls lt lu gt nj nk nl nm aw nn bi"><span id="5870" class="no lz it nk b gy np nq l nr ns">@evaluator.on(Events.ITERATION_COMPLETED)<br/><em class="nt">def </em>on_eval_iteration_completed(<em class="nt">engine</em>):<br/>    images, targets, results = <em class="nt">engine</em>.state.output</span><span id="ea1b" class="no lz it nk b gy nu nq l nr ns">    <em class="nt">if engine</em>.state.iteration % task_args.log_interval == 0:<br/>        print("Evaluation: Iteration: {}"<br/>              .format(<em class="nt">engine</em>.state.iteration))<br/>    <br/>    <em class="nt">if engine</em>.state.iteration % task_args.debug_images_interval== 0:<br/>        <em class="nt">for </em>n, debug_image <em class="nt">in </em>enumerate(<br/>               draw_debug_images(images, targets, results)):<br/>            writer.add_image("evaluation/image_{}_{}"<br/>                             .format(<em class="nt">engine</em>.state.iteration,n),<br/>                             debug_image,trainer.state.iteration,<br/>                             dataformats='HWC')<br/>            <em class="nt">if </em>'masks' <em class="nt">in </em>targets[n]:<br/>                writer.add_image("evaluation/image_{}_{}_mask"<br/>                                 .format(<em class="nt">engine</em>.state.iteration, n),<br/>                                 draw_mask(targets[n]), <br/>                                 trainer.state.iteration,<br/>                                 dataformats='HW')<br/>                curr_image_id = int(targets[n]['image_id'])<br/>                writer.add_image(<br/>                       "evaluation/image_{}_{}_predicted_mask"<br/>                       .format(<em class="nt">engine</em>.state.iteration, n),<br/>                       draw_mask(results[curr_image_id]).squeeze(),<br/>                       trainer.state.iteration, <br/>                       dataformats='HW')</span></pre><h1 id="083c" class="ly lz it bd ma mb mc md me mf mg mh mi ki mj kj mk kl ml km mm ko mn kp mo mp bi translated">坐下来，放松并监控你的实验</h1><p id="feab" class="pw-post-body-paragraph kr ks it kt b ku mq kd kw kx mr kg kz la ms lc ld le mt lg lh li mu lk ll lm im bi translated">现在我们的代码库已经准备好了，我们可以执行train脚本，并在Trains webapp中监控它的进度。由于统计数据和调试图像记录在Trains中，您可以在您自己的专用Trains服务器(或Trains演示服务器)上查看它们。通过查看统计数据和调试图像，您可以跟踪训练过程，并确保它按计划运行。例如，查看报告的调试图像可以让您知道您的基本事实是否有问题和/或数据扩充是否产生了错误的结果。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="nw nx di ny bf nz"><div class="gh gi nv"><img src="../Images/1cc5678b1734d0e5ce393e0508ab210a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A8fclOy9Tr8mSXiVC6w_fg.png"/></div></div><p class="oa ob gj gh gi oc od bd b be z dk translated">图Allegro Trains webapp的调试图像快照</p></figure><p id="15a2" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在上面的快照中，您可以查看实验列表，这些实验是同一个项目的一部分。点击特定的实验使我们能够在训练周期中监控预测的遮罩和边界框。在下面的快照中，您可以看到同一实验的训练统计数据—在本例中，是边界框和遮罩的平均精度。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="nw nx di ny bf nz"><div class="gh gi oe"><img src="../Images/64271c1f02fe286a2f4c91659cce6fb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a4Qx17pn9UiVAB8C8WK7UQ.png"/></div></div><p class="oa ob gj gh gi oc od bd b be z dk translated">图Allegro Trains webapp中培训过程的快照</p></figure><h1 id="172f" class="ly lz it bd ma mb mc md me mf mg mh mi ki mj kj mk kl ml km mm ko mn kp mo mp bi translated">摘要</h1><p id="60ef" class="pw-post-body-paragraph kr ks it kt b ku mq kd kw kx mr kg kz la ms lc ld le mt lg lh li mu lk ll lm im bi translated">我们希望你喜欢这个教程，并且现在已经更好地掌握了如何编写可读、可维护和可复制的深度学习代码。使用Ignite和<a class="ae ln" href="https://github.com/allegroai/trains" rel="noopener ugc nofollow" target="_blank"> Trains </a>可以实现更简单、更高效的机器和深度学习工作流。完整的代码可以在<a class="ae ln" href="https://github.com/allegroai/trains-blogs/tree/master/once_upon_a_repository" rel="noopener ugc nofollow" target="_blank">这里</a>找到。<br/>我们的代码库受到PyTorch的<a class="ae ln" href="https://github.com/pytorch/ignite/blob/master/examples/mnist/mnist_with_tensorboardx.py" rel="noopener ugc nofollow" target="_blank"> mnist with tensorboardX </a>和torch vision<a class="ae ln" href="http://pytorch.org/tutorials/intermediate/torchvision_tutorial.html" rel="noopener ugc nofollow" target="_blank">object detection fine tune教程</a>的启发。</p><p id="2701" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在本系列的下一篇文章中，我们将展示我们在这里展示的代码库的模块化结构如何能够用SSD模型轻松替换MaskRCNN。我们将解释单镜头和双镜头对象检测模型之间的差异，以及如何在TorchVision特征提取器上设置SSD模型。然后，我们将执行我们刚刚与您一起编写的训练和评估脚本——这一次使用单次检测器。<a class="ae ln" href="https://medium.com/@allegroai" rel="noopener">敬请期待！</a></p></div><div class="ab cl of og hx oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="im in io ip iq"><p id="b899" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="nt">原载于2020年1月30日</em><a class="ae ln" href="https://allegro.ai/blog/once-upon-a-repository-how-to-write-readable-maintainable-code-with-pytorch-ignite/" rel="noopener ugc nofollow" target="_blank"><em class="nt">https://allegro . ai</em></a><em class="nt">。</em></p></div></div>    
</body>
</html>