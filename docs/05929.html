<html>
<head>
<title>How to Evaluate Machine Learning Model’s Performance in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何评价机器学习模型在 Python 中的性能</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-evaluate-machine-learning-model-performance-in-python-135b4ae27f7e?source=collection_archive---------22-----------------------#2020-05-15">https://towardsdatascience.com/how-to-evaluate-machine-learning-model-performance-in-python-135b4ae27f7e?source=collection_archive---------22-----------------------#2020-05-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="f39c" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">机器学习，数据科学</h2><div class=""/><div class=""><h2 id="a290" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">一种实用的方法来计算模型的性能，并在 Python 中实现，涵盖了所有的数学推理</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/be1b75b6e10997931029ff78bf316909.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*G7qITBR1EDmXtR0U"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">雪莉·胡利在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="4722" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi me translated">欢迎光临！您是否准备好了在数百万个数据点上训练的酷机器学习模型，现在您想测试它的性能，但不知道从哪里开始，也不知道有什么更好的方法可以做到这一点？</p><p id="6be7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在本文中，我们将讨论测试模型性能所需的一切，无论是<strong class="lk jd">分类</strong>模型还是<strong class="lk jd">回归</strong>模型，在本文中，我们将深入了解机器学习模型的评估过程，这对于机器学习工程师或数据科学家来说确实是非常关键的一步。</p><p id="4fd5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">所以让我们开始吧！</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="e11c" class="mu mv it bd mw mx my mz na nb nc nd ne ki nf kj ng kl nh km ni ko nj kp nk nl bi translated">分类算法评估</h1><p id="b2d7" class="pw-post-body-paragraph li lj it lk b ll nm kd ln lo nn kg lq lr no lt lu lv np lx ly lz nq mb mc md im bi translated">让我们从理解如何评估一个分类算法开始。分类模型将输出预测为类别标签。假设有一个随机变量'<strong class="lk jd"> xᵢ </strong>'，那么<strong class="lk jd"> xᵢ </strong>的预测值为'<strong class="lk jd"> yᵢ </strong>'，标注为:</p><blockquote class="nr"><p id="7c31" class="ns nt it bd nu nv nw nx ny nz oa md dk translated"><strong class="ak">yᵢ∈{一班，二班，三班，…} </strong></p></blockquote><p id="753a" class="pw-post-body-paragraph li lj it lk b ll ob kd ln lo oc kg lq lr od lt lu lv oe lx ly lz of mb mc md im bi translated">下面是一些非常有用的方法来衡量分类模型的性能。在我们下面的研究中，为了便于理解这个概念，我们将主要处理二元分类，这可以很容易地扩展到多类分类。</p><h2 id="44c3" class="og mv it bd mw oh oi dn na oj ok dp ne lr ol om ng lv on oo ni lz op oq nk iz bi translated">准确(性)</h2><p id="083f" class="pw-post-body-paragraph li lj it lk b ll nm kd ln lo nn kg lq lr no lt lu lv np lx ly lz nq mb mc md im bi translated">准确度告诉我们正确分类的数据点相对于总数据点的数量。顾名思义，准确性是指预测值与目标值的接近程度。</p><blockquote class="nr"><p id="ee6d" class="ns nt it bd nu nv nw nx ny nz oa md dk translated">准确度=正确分类点数/总点数</p></blockquote><p id="2a1b" class="pw-post-body-paragraph li lj it lk b ll ob kd ln lo oc kg lq lr od lt lu lv oe lx ly lz of mb mc md im bi translated">但是由于假设的简单性，准确性并不总是模型评估的好方法。让我们看看这两个例子，在这两个例子中，精确度不是一个好的衡量标准。</p><ol class=""><li id="474e" class="or os it lk b ll lm lo lp lr ot lv ou lz ov md ow ox oy oz bi translated"><strong class="lk jd">不平衡数据</strong>:在现实世界的大多数问题中，类数据并不是均匀分布的，我们有一些高频率的类和一些低频率的类。例如，以癌症患者为例，假设 90%的数据是没有患癌症的人，而 10%的人被诊断患有癌症。因此，在这种情况下，即使是未经训练的基于规则的模型也可以预测所有的点为负面，并且可以达到 90%的准确性，这在许多情况下是非常危险的。这个问题可以通过使用本文后面部分讨论的<strong class="lk jd"> ROC-AUC </strong>来解决。</li><li id="fdca" class="or os it lk b ll pa lo pb lr pc lv pd lz pe md ow ox oy oz bi translated"><strong class="lk jd">概率估计</strong>:与其他测量不同，准确性不理解来自模型的概率值，而是只考虑二进制值。因此，对概率值分别为 97%和 3%的正值和负值进行分类的模型与另一个概率值为 62%和 38%的模型具有相同的精度，但我们知道第一个模型比第二个模型好得多，这里精度无法评估这一点。使用本文后面部分讨论的<strong class="lk jd">日志损失</strong>可以很容易地识别出这一点。</li></ol></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="7f70" class="og mv it bd mw oh oi dn na oj ok dp ne lr ol om ng lv on oo ni lz op oq nk iz bi translated">混淆矩阵</h2><p id="4717" class="pw-post-body-paragraph li lj it lk b ll nm kd ln lo nn kg lq lr no lt lu lv np lx ly lz nq mb mc md im bi translated">混淆矩阵是机器学习中许多评价方法的核心基础方法之一。混淆矩阵是分类模型的一个“<strong class="lk jd"> n 维</strong>矩阵，它在 x 轴上标注实际值，在 y 轴上标注预测值。</p><p id="f128" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">通常对于二元分类器，混淆矩阵是一个<strong class="lk jd"> 2x2 维</strong>矩阵，其中<strong class="lk jd"> 0 </strong>为<strong class="lk jd">负</strong>类，<strong class="lk jd"> 1 </strong>为<strong class="lk jd">正</strong>类。</p><blockquote class="pf pg ph"><p id="92a1" class="li lj pi lk b ll lm kd ln lo lp kg lq pj ls lt lu pk lw lx ly pl ma mb mc md im bi translated">对于一个好的模型，混淆矩阵的主对角线元素应该是高值，非对角线元素应该是低值。</p></blockquote><p id="4ba1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">混淆矩阵中的每个单元对于理解模型的性能都起着非常重要的作用。<strong class="lk jd"> TN </strong>、<strong class="lk jd"> FN </strong>、<strong class="lk jd"> FP </strong>、<strong class="lk jd"> TP </strong>是根据每个单元格在该单元格中的实际值和预测值给每个单元格起的名字。让我们一个一个地理解它们，然后我们会从它们身上发现一些惊人的联系。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/7a0c39c7ef24737b95b6365ebe1d66fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*lNQx8kWVlc41o8HdWiCEgQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图 1:二元分类器的混淆矩阵。</p></figure><p id="06fd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> TN =真阴性</strong>(实际为阴性且被模型正确分类为阴性类别的数据)。</p><p id="9ab2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> FN =假阴性</strong>(实际为阳性但被模型错误分类为阴性的数据)。</p><p id="3a89" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> FP =假阳性</strong>(实际为阴性但被模型错误分类为阳性的数据)。</p><p id="e67b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> TP =真阳性</strong>(实际为阳性且被模型正确分类为阳性类别的数据)。</p><h2 id="5d36" class="og mv it bd mw oh oi dn na oj ok dp ne lr ol om ng lv on oo ni lz op oq nk iz bi translated"><strong class="ak">如何记住它们？</strong></h2><p id="f3b8" class="pw-post-body-paragraph li lj it lk b ll nm kd ln lo nn kg lq lr no lt lu lv np lx ly lz nq mb mc md im bi translated">有一个简单的方法来记住它们，<strong class="lk jd">的第一个字母</strong>回答了问题“<strong class="lk jd">我们是正确的吗？</strong>和<strong class="lk jd">第二个字母</strong>讲述的是<strong class="lk jd">预测值</strong>。</p><p id="0ffa" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些符号之间有一些惊人的关系，对我们的评估非常有用。在此之前，让我们看看什么是<strong class="lk jd">实际正</strong>和<strong class="lk jd">实际负</strong>值。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/7a81588207c0a30151d848602534ff2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*nrDE_rWh_TDq8TmTCPo2Dg.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图 2:混淆矩阵中的负值和正值</p></figure><p id="f9bb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">阳性(P) </strong>:假阴性值和真阳性值之和就是数据中实际的一组正值。<strong class="lk jd">T19】P = FN+TPT21】</strong></p><p id="1445" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> Negative (N) </strong>:真负值和假正值之和就是数据中实际的一组正值。<strong class="lk jd"> <em class="pi"> N = TN+FP </em> </strong></p><p id="5169" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在我们知道了单元符号和正负符号，有 4 个重要的测量值是使用这些符号计算的，它们对于模型性能估计非常有用。它们如下:</p><ol class=""><li id="f4b3" class="or os it lk b ll lm lo lp lr ot lv ou lz ov md ow ox oy oz bi translated"><strong class="lk jd">真阳性率(TPR) </strong>:真阳性/总阳性= TP/P</li><li id="5786" class="or os it lk b ll pa lo pb lr pc lv pd lz pe md ow ox oy oz bi translated"><strong class="lk jd">真阴性率(TNR) </strong>:真阴性/总阴性= TN/N</li><li id="6e01" class="or os it lk b ll pa lo pb lr pc lv pd lz pe md ow ox oy oz bi translated"><strong class="lk jd">假阳性率(FPR) </strong>:假阳性/总阴性= FP/N</li><li id="5309" class="or os it lk b ll pa lo pb lr pc lv pd lz pe md ow ox oy oz bi translated"><strong class="lk jd">假阴性率</strong>:假阴性/总阳性= FN/P</li></ol><p id="0864" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">它们听起来有点令人困惑，但当我们查看困惑矩阵，并形象地找到这些关系时，它们就开始给出某种意义了。</p><blockquote class="pf pg ph"><p id="b8a6" class="li lj pi lk b ll lm kd ln lo lp kg lq pj ls lt lu pk lw lx ly pl ma mb mc md im bi translated">对于一个执行良好的车型<strong class="lk jd"><em class="it">【TPR 和 TNR 应该是高值】</em></strong><strong class="lk jd"><em class="it">【FPR 和 FNR 应该是低值】</em> </strong>。</p></blockquote><blockquote class="nr"><p id="53bc" class="ns nt it bd nu nv po pp pq pr ps md dk translated">TPR⬆、TNR⬆、FPR⬇、FNR⬇</p></blockquote></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="4a0d" class="og mv it bd mw oh oi dn na oj ok dp ne lr ol om ng lv on oo ni lz op oq nk iz bi translated">精确度和召回率</h2><p id="cc31" class="pw-post-body-paragraph li lj it lk b ll nm kd ln lo nn kg lq lr no lt lu lv np lx ly lz nq mb mc md im bi translated">精确度和召回率主要用于<strong class="lk jd">信息检索</strong>的情况。对于二进制分类问题，这两个度量主要集中在<strong class="lk jd">正类</strong>上。对，正课。现在，让我们来看看关于图 3 中的混淆矩阵的精确度和召回率的公式。我们可以清楚地看到，精确度和召回率的全部焦点都在混淆矩阵的<strong class="lk jd">真阳性</strong>单元上，它们与真阴性无关。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pt"><img src="../Images/9504acfc734def090ec8bc558b4c7bf3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/1*mSe84YpKtyILUTOo8uq_Bg.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图 3:使用混淆矩阵的精确和回忆理解</p></figure><blockquote class="pf pg ph"><p id="2d63" class="li lj pi lk b ll lm kd ln lo lp kg lq pj ls lt lu pk lw lx ly pl ma mb mc md im bi translated"><strong class="lk jd">精度</strong>:在所有模型预测为正的点中，有多少是真的正。</p></blockquote><blockquote class="nr"><p id="60d1" class="ns nt it bd nu nv po pp pq pr ps md dk translated"><strong class="ak">精度= TP / (TP+FP) </strong></p></blockquote><blockquote class="pf pg ph"><p id="fa17" class="li lj pi lk b ll ob kd ln lo oc kg lq pj od lt lu pk oe lx ly pl of mb mc md im bi translated"><strong class="lk jd">回忆</strong>:在所有实际上积极的点中，有多少是模型预测为积极的。</p></blockquote><blockquote class="nr"><p id="399c" class="ns nt it bd nu nv po pp pq pr ps md dk translated">回忆= TPR = TP / P = TP / (TP+FN)</p></blockquote><p id="5013" class="pw-post-body-paragraph li lj it lk b ll ob kd ln lo oc kg lq lr od lt lu lv oe lx ly lz of mb mc md im bi translated">Precision 和 Recall 两个值都在[0，1]的范围内，我们总是希望这两个值尽可能的高<strong class="lk jd"/>。有时，将两个不同的值结合起来比单独分析它们更好，因此为了将它们结合起来，我们有一个名为<a class="ae lh" href="https://en.wikipedia.org/wiki/F1_score" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd"> F1-score </strong> </a>的指标，即<strong class="lk jd"> <em class="pi">“精确度和召回率的调和平均值”。</em>T13】</strong></p><blockquote class="nr"><p id="2e6b" class="ns nt it bd nu nv nw nx ny nz oa md dk translated">f1-得分= 2 *精度*召回/(精度+召回)</p></blockquote><p id="7950" class="pw-post-body-paragraph li lj it lk b ll ob kd ln lo oc kg lq lr od lt lu lv oe lx ly lz of mb mc md im bi translated">在 Kaggle.com<a class="ae lh" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank">的一些比赛中，F1 分数有时被用作模型评估的指标，但用简单的英语理解有点困难，而精确度和召回率则更容易解释。</a></p><p id="1650" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们在 Python 3.x 中实现它。下面是使用混淆矩阵的模型评估的手动实现。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pu pv l"/></div></figure><p id="19da" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下面是上述代码实现的示例输出。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pw"><img src="../Images/d0b2b2e1ab98e3e7b3c38a98314c334e.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/format:webp/1*muHbB-aJZJc3k9jXPquAnA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">使用混淆矩阵的评估输出示例</p></figure></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="fb63" class="og mv it bd mw oh oi dn na oj ok dp ne lr ol om ng lv on oo ni lz op oq nk iz bi translated">ROC 曲线和 AUC</h2><p id="7ce5" class="pw-post-body-paragraph li lj it lk b ll nm kd ln lo nn kg lq lr no lt lu lv np lx ly lz nq mb mc md im bi translated"><a class="ae lh" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd">接收机工作特性曲线</strong> </a>或<strong class="lk jd"> ROC </strong>是<strong class="lk jd"> TPR 对 FPR </strong>的曲线图，形成一条曲线，代表不同阈值的 TPR 和 FPR 值“<strong class="lk jd"> 𝜏 </strong>”。AUC 是曲线下的<strong class="lk jd">面积。<strong class="lk jd"> </strong>它们有时合在一起称为 AUROC(受试者工作特性下的面积)曲线。</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi px"><img src="../Images/2a41ce159a3ec038343f952938cb22d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*7ko7Fi297DWirwrOYVR-Tw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图 4:来源:接收机工作特性曲线<a class="ae lh" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></figure><p id="2971" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">给定一个阈值参数<strong class="lk jd"> 𝜏 </strong>，如果<strong class="lk jd"> X &gt; 𝜏 </strong>该实例被归类为<strong class="lk jd"> <em class="pi">正类</em> </strong>，如果<strong class="lk jd"> X &lt; =𝜏 </strong>则归类为<strong class="lk jd"> <em class="pi">负类</em> </strong>。如果实例实际上属于<strong class="lk jd"><em class="pi"/></strong>，则 x 遵循概率密度<strong class="lk jd"> f1(x) </strong>，如果实例属于<strong class="lk jd"><em class="pi"/></strong>负类，则遵循概率密度<strong class="lk jd"> f0(x) </strong>。因此，真实阳性率由下式给出:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi py"><img src="../Images/9e9390a084ee9bcaab10effbc512a958.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*kDbhY4CbZX6hEP31PD8zmQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">使用 ROC 的 TPR</p></figure><p id="722e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">假阳性率由下式给出:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi py"><img src="../Images/3abd501697b790ebf4e293318775a359.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*MuXyO2w1Tj9UXAkaXuHAgg.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">FPR 使用 ROC</p></figure><p id="681a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">ROC 曲线参数化地绘制了<strong class="lk jd"> TPR(𝜏)对</strong>fpr(𝜏，阈值<strong class="lk jd"> 𝜏 </strong>作为曲线上的变化参数，给出了类似于图 4 接收器工作特性曲线所示的形状。</p><p id="1647" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">AUC 是曲线下的面积。<strong class="lk jd"> <em class="pi"> AUC 位于</em>【0，1】</strong><em class="pi">范围内。</em><strong class="lk jd">0.5</strong>的值表示模型的性能是<strong class="lk jd">随机的</strong>。在[0.5，1]范围内的 AUC 值表明模型表现良好，而在[0，0.5]范围内的 AUC 值表明模型表现不佳。</p><blockquote class="nr"><p id="19cb" class="ns nt it bd nu nv nw nx ny nz oa md dk translated">"<strong class="ak">AUC 值越高，模型表现越好</strong>。"</p></blockquote><h2 id="f7b8" class="og mv it bd mw oh pz dn na oj qa dp ne lr qb om ng lv qc oo ni lz qd oq nk iz bi translated">AUC 值低于 0.5 怎么处理？</h2><p id="441c" class="pw-post-body-paragraph li lj it lk b ll nm kd ln lo nn kg lq lr no lt lu lv np lx ly lz nq mb mc md im bi translated">当 AUC 在[0，0.5]范围内时，有一个非常简单的技巧来处理模型性能。<strong class="lk jd">绝招</strong>::<em class="pi">简单切换模型预测的类别标签。</em>“是的，假设我们得到的 AUC 为 0.32，那么在将类别标签从 0 切换到 1 和从 1 切换到 0 之后，我们得到的 AUC 值为 1–0.32 =<strong class="lk jd">0.68</strong>，这使它成为一个好模型。就这么简单！</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="57d9" class="og mv it bd mw oh oi dn na oj ok dp ne lr ol om ng lv on oo ni lz op oq nk iz bi translated">使用对数损失计算概率分数！</h2><p id="f17c" class="pw-post-body-paragraph li lj it lk b ll nm kd ln lo nn kg lq lr no lt lu lv np lx ly lz nq mb mc md im bi translated">Log-Loss 用于发现<strong class="lk jd">二元分类</strong>算法的模型性能，该算法可以容易地扩展到多类分类。它考虑由机器学习模型预测的所有概率分数，并使用下面图 5 中的公式计算相对于'<strong class="lk jd"> yᵢ </strong>'的真实值和预测值'<strong class="lk jd"> p(yᵢ) </strong>'的损失。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi qe"><img src="../Images/5ce279153891dd515fedc9f5263948d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/1*PDtIfRHpMfbbXbhj26I-OA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图 5:测井损失计算公式</p></figure><p id="827e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">理解这个公式很简单，对于每个<strong class="lk jd"> yᵢ=1 </strong>，值<strong class="lk jd">log(p(yᵢ)】</strong>被加到损失上，而对于每个<strong class="lk jd"> yᵢ=0 </strong>值<strong class="lk jd">log(1-p(yᵢ)】</strong>被加到损失上，然后通过将计算的总和除以<strong class="lk jd"> N </strong>(数据点的数量)来计算平均值。</p><blockquote class="pf pg ph"><p id="c306" class="li lj pi lk b ll lm kd ln lo lp kg lq pj ls lt lu pk lw lx ly pl ma mb mc md im bi translated">简单地说，对数损失是平均负对数(正确分类标签的概率)</p></blockquote><p id="31e4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">简而言之，我们可以说，当'<strong class="lk jd">【p(yᵢ】)</strong>'较低时，这意味着模型预测'<strong class="lk jd"/>'的值更不确定，那么对它的惩罚就更多，对数损失也更多，反之亦然。</p><blockquote class="nr"><p id="a843" class="ns nt it bd nu nv nw nx ny nz oa md dk translated">预测概率⬇对数损失⬆</p><p id="38f0" class="ns nt it bd nu nv nw nx ny nz oa md dk translated">预测概率⬆对数损失⬇</p></blockquote><p id="c1af" class="pw-post-body-paragraph li lj it lk b ll ob kd ln lo oc kg lq lr od lt lu lv oe lx ly lz of mb mc md im bi translated">查看下图 6，了解预测概率和测井曲线损失之间的反比关系。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi qf"><img src="../Images/24cc8c7a7f3ac239d4f3d5ed45da6ade.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*nRm22de7rpGDteDUSNcJAw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图 6:与预测概率相关的测井曲线的来源<a class="ae lh" href="https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html" rel="noopener ugc nofollow" target="_blank">图像</a></p></figure><ol class=""><li id="f4a2" class="or os it lk b ll lm lo lp lr ot lv ou lz ov md ow ox oy oz bi translated">因此，我们需要<strong class="lk jd"> Log-Loss 尽可能小</strong>才能说我们的模型表现良好。</li><li id="174c" class="or os it lk b ll pa lo pb lr pc lv pd lz pe md ow ox oy oz bi translated">对数损耗可以在<strong class="lk jd">【0，INF】</strong>的范围内，如图 6 所示。</li></ol><p id="2320" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">也就是说，现在让我们看看如何实现日志丢失。下面是 Python3 中的代码实现。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pu pv l"/></div></figure><p id="b9dd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">但是<strong class="lk jd"> Scikit-learn </strong>提供了一行输入来计算日志损失，</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pu pv l"/></div></figure><p id="d09f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">使用 Log-Loss 的一个缺点是有点难以解释，因为我们不能仅仅通过看到 Log-Loss 的一些值来说什么。这是因为对数损耗并不限定输出值的范围，而是从 0 到无穷大。例如，如果我们得到一个 Log-Loss = 12 的值，那么仅仅通过看到这个值，我们不能说什么。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="6496" class="mu mv it bd mw mx my mz na nb nc nd ne ki nf kj ng kl nh km ni ko nj kp nk nl bi translated">回归算法评估</h1><p id="36c4" class="pw-post-body-paragraph li lj it lk b ll nm kd ln lo nn kg lq lr no lt lu lv np lx ly lz nq mb mc md im bi translated">分类和回归算法的区别在于分类的输出属于一个类，而回归算法的输出属于实数，如<strong class="lk jd"> yᵢ ∈ ℝ </strong>。</p><p id="7aef" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">设<strong class="lk jd"> yᵢ </strong>是输入<strong class="lk jd"> xᵢ </strong>的实值输出，而<strong class="lk jd"> ŷᵢ </strong> (y-hat)是回归算法的预测实值输出。因此，误差<strong class="lk jd"> eᵢ </strong>计算如下:</p><blockquote class="nr"><p id="9ba9" class="ns nt it bd nu nv nw nx ny nz oa md dk translated"><strong class="ak">eᵢ=yᵢ</strong>—<strong class="ak">ŷᵢ</strong></p></blockquote><p id="82fa" class="pw-post-body-paragraph li lj it lk b ll ob kd ln lo oc kg lq lr od lt lu lv oe lx ly lz of mb mc md im bi translated">因此，让我们看看用于回归模型性能测量的各种类型的模型评估技术。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="ea54" class="og mv it bd mw oh oi dn na oj ok dp ne lr ol om ng lv on oo ni lz op oq nk iz bi translated">r 或决定系数</h2><p id="d7a4" class="pw-post-body-paragraph li lj it lk b ll nm kd ln lo nn kg lq lr no lt lu lv np lx ly lz nq mb mc md im bi translated">先来了解一下<strong class="lk jd">平方和</strong> ( <strong class="lk jd"> SS </strong>)是一个随机变量'<strong class="lk jd"> xᵢ </strong>'的'<strong class="lk jd"> yᵢ </strong>'的方差值之和。这里'<strong class="lk jd"> ȳ </strong> '(y-bar)是所有'<strong class="lk jd"> yᵢ </strong>'的值的<strong class="lk jd">的意思</strong>。</p><blockquote class="nr"><p id="6552" class="ns nt it bd nu nv nw nx ny nz oa md dk translated"><strong class="ak">平方和</strong>ₜₒₜₐₗ<strong class="ak">=σ(yᵢ+ȳ)</strong></p></blockquote><blockquote class="pf pg ph"><p id="afd8" class="li lj pi lk b ll ob kd ln lo oc kg lq pj od lt lu pk oe lx ly pl of mb mc md im bi translated">简单来说，平方和(<strong class="lk jd"> SS- total </strong>)是其真实值相对于其平均值的误差平方和。</p></blockquote><p id="15b8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">而且，</p><blockquote class="nr"><p id="09d3" class="ns nt it bd nu nv nw nx ny nz oa md dk translated">平方和ᵣₑₛ=σ(yᵢ+<strong class="ak">ŷ</strong>ᵢ)</p></blockquote><blockquote class="pf pg ph"><p id="39d9" class="li lj pi lk b ll ob kd ln lo oc kg lq pj od lt lu pk oe lx ly pl of mb mc md im bi translated">平方和(<strong class="lk jd"> SS- residue </strong>)是其真实值相对于其<strong class="lk jd">预测值</strong>的误差平方和。</p></blockquote><p id="45f7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">所以，R 被定义为，</p><blockquote class="nr"><p id="b429" class="ns nt it bd nu nv nw nx ny nz oa md dk translated">R = 1 - (SSᵣₑₛ / SSₜₒₜₐₗ)</p></blockquote><p id="2cc8" class="pw-post-body-paragraph li lj it lk b ll ob kd ln lo oc kg lq lr od lt lu lv oe lx ly lz of mb mc md im bi translated">让我们考虑几个案例，基于这些案例，当我们看到 R 值时，我们可以获得关于模型性能的一些直觉。</p><ol class=""><li id="3ff1" class="or os it lk b ll lm lo lp lr ot lv ou lz ov md ow ox oy oz bi translated">如果误差 e =σ(yᵢ+ŷᵢ)为<strong class="lk jd"> 0 </strong>那么，r 为<strong class="lk jd"> 1 ( </strong>为最佳值)。</li><li id="0043" class="or os it lk b ll pa lo pb lr pc lv pd lz pe md ow ox oy oz bi translated">如果 SSᵣₑₛ &lt; SSₜₒₜₐₗ then R² lied between <strong class="lk jd"> 0 </strong>和<strong class="lk jd"> 1 </strong>(一般接受)。</li><li id="1a5e" class="or os it lk b ll pa lo pb lr pc lv pd lz pe md ow ox oy oz bi translated">如果 SSᵣₑₛ = SSₜₒₜₐₗ，那么 r 就变成了<strong class="lk jd"> 0 </strong>(性能不好)。</li><li id="3b55" class="or os it lk b ll pa lo pb lr pc lv pd lz pe md ow ox oy oz bi translated">如果 SSᵣₑₛ &gt; SSₜₒₜₐₗ，那么 r 变成负的值(最差性能)。</li></ol><p id="f828" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们看看 Python3 中 R 的实现</p><p id="a4b6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://gist.github.com/paras009/b46ded4f1ea24ab48508623f6024294b" rel="noopener ugc nofollow" target="_blank">https://gist . github . com/paras 009/b 46 ded 4 f1 ea 24 ab 48508623 f 6024294 b</a></p><p id="0082" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Scikit-Learn 为 compute R 提供了一个单行导入。</p><p id="9df3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://gist.github.com/paras009/229ad9ba3a7595b26ba8bfb7e179c379" rel="noopener ugc nofollow" target="_blank">https://gist . github . com/paras 009/229 ad 9 ba 3a 7595 b 26 ba 8 bfb 7 e 179 c 379</a></p><p id="c33d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">需要注意的重要一点是，R 在某些情况下表现不佳:</p><p id="dc61" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">有异常值的数据</strong> : <strong class="lk jd"> </strong>如果数据中有一些异常值，那么 R 不是计算回归模型性能的一个很好的方法，误差值会立即增加，并反过来严重影响 R 值。因此，在这种情况下，我们将使用下一节讨论的<strong class="lk jd">中值绝对偏差</strong>的概念。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="c1db" class="og mv it bd mw oh oi dn na oj ok dp ne lr ol om ng lv on oo ni lz op oq nk iz bi translated">中位数绝对偏差</h2><p id="928f" class="pw-post-body-paragraph li lj it lk b ll nm kd ln lo nn kg lq lr no lt lu lv np lx ly lz nq mb mc md im bi translated">由于异常值对误差“<strong class="lk jd"> eᵢ </strong>”有很大影响，因此 MAD 通过计算所有误差值的中值并计算它们与每个误差值的绝对偏差来解决这个问题，这有助于计算 MAD 值，从而消除异常值对误差值的影响。</p><blockquote class="nr"><p id="2599" class="ns nt it bd nu nv nw nx ny nz oa md dk translated">MAD =中位数(|<strong class="ak">eᵢ</strong>—中位数(<strong class="ak"> eᵢ </strong> )|)</p></blockquote><p id="e02e" class="pw-post-body-paragraph li lj it lk b ll ob kd ln lo oc kg lq lr od lt lu lv oe lx ly lz of mb mc md im bi translated"><strong class="lk jd">中位数和 MAD 对异常值稳健</strong>。中值和 MAD 的较小值表明该模型表现非常好。请记住，我们可以使用均值或标准差，但它们不能处理异常值，而 MAD 对异常值没有显著影响。</p><p id="88da" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">注</strong>:绘制误差分布图有助于理解异常值以及误差值是如何传播的。分布“<strong class="lk jd">右偏</strong>越多，模型表现越好。这意味着大多数点的<strong class="lk jd">误差较低</strong>，只有极少数点的误差值较高，这些误差值并不显著，可以使用 MAD 进行归一化。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi qg"><img src="../Images/fddc75b976d358ecee06f62c9ee79cd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*DtT2RvYRRaI4KK0W50APsw.jpeg"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">概率与误差图</p></figure></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><p id="713e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">所以，就这样，我们到了这篇文章的结尾。现在，你可以放心大胆地评估你的模型了！</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi gj"><img src="../Images/879ddc4fb72dc381e778915104dd04c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*Hbw_x3L0-iCDI96qCuzTvA.gif"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">来源:<a class="ae lh" href="https://media.giphy.com/media/5nkIn9AEfUQ6JtXL43/source.gif" rel="noopener ugc nofollow" target="_blank">https://media.giphy.com/media/5nkIn9AEfUQ6JtXL43/source.gif</a></p></figure></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="0e30" class="og mv it bd mw oh oi dn na oj ok dp ne lr ol om ng lv on oo ni lz op oq nk iz bi translated">参考</h2><ol class=""><li id="3010" class="or os it lk b ll nm lo nn lr qh lv qi lz qj md ow ox oy oz bi translated"><a class="ae lh" href="https://en.wikipedia.org/wiki/Evaluation_of_binary_classifiers" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/wiki/Evaluation _ of _ binary _ classifiers</a></li><li id="f4e6" class="or os it lk b ll pa lo pb lr pc lv pd lz pe md ow ox oy oz bi translated"><a class="ae lh" href="https://en.wikipedia.org/wiki/Confusion_matrix" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Confusion_matrix</a></li><li id="b99e" class="or os it lk b ll pa lo pb lr pc lv pd lz pe md ow ox oy oz bi translated"><a class="ae lh" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/wiki/Receiver _ operating _ character istic</a></li><li id="b9bf" class="or os it lk b ll pa lo pb lr pc lv pd lz pe md ow ox oy oz bi translated"><a class="ae lh" href="https://en.wikipedia.org/wiki/Loss_functions_for_classification" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/wiki/Loss _ functions _ for _ class ification</a></li><li id="6a5b" class="or os it lk b ll pa lo pb lr pc lv pd lz pe md ow ox oy oz bi translated"><a class="ae lh" href="https://en.wikipedia.org/wiki/Coefficient_of_determination" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Coefficient_of_determination</a></li><li id="8a7d" class="or os it lk b ll pa lo pb lr pc lv pd lz pe md ow ox oy oz bi translated"><a class="ae lh" href="https://en.wikipedia.org/wiki/Median_absolute_deviation" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Median_absolute_deviation</a></li></ol></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="d481" class="og mv it bd mw oh oi dn na oj ok dp ne lr ol om ng lv on oo ni lz op oq nk iz bi translated">更多关于机器学习的文章:</h2><div class="qk ql gp gr qm qn"><a rel="noopener follow" target="_blank" href="/k-nearest-neighbour-explained-part-1-5e5e9192050"><div class="qo ab fo"><div class="qp ab qq cl cj qr"><h2 class="bd jd gy z fp qs fr fs qt fu fw jc bi translated">k-最近邻解释-第 1 部分</h2><div class="qu l"><h3 class="bd b gy z fp qs fr fs qt fu fw dk translated">KNN 算法背后的科学解释！</h3></div><div class="qv l"><p class="bd b dl z fp qs fr fs qt fu fw dk translated">towardsdatascience.com</p></div></div><div class="qw l"><div class="qx l qy qz ra qw rb lb qn"/></div></div></a></div><div class="qk ql gp gr qm qn"><a href="https://medium.com/@pv009/q-q-plots-explained-5aa8495426c0" rel="noopener follow" target="_blank"><div class="qo ab fo"><div class="qp ab qq cl cj qr"><h2 class="bd jd gy z fp qs fr fs qt fu fw jc bi translated">Q-Q 图解释</h2><div class="qu l"><h3 class="bd b gy z fp qs fr fs qt fu fw dk translated">探索 Q-Q 图的力量。</h3></div><div class="qv l"><p class="bd b dl z fp qs fr fs qt fu fw dk translated">medium.com</p></div></div><div class="qw l"><div class="rc l qy qz ra qw rb lb qn"/></div></div></a></div><div class="qk ql gp gr qm qn"><a href="https://medium.com/@pv009/the-powers-of-normal-distribution-4cbb06e4a955" rel="noopener follow" target="_blank"><div class="qo ab fo"><div class="qp ab qq cl cj qr"><h2 class="bd jd gy z fp qs fr fs qt fu fw jc bi translated">“正态分布”的功效</h2><div class="qu l"><h3 class="bd b gy z fp qs fr fs qt fu fw dk translated">理解钟形曲线背后的科学！</h3></div><div class="qv l"><p class="bd b dl z fp qs fr fs qt fu fw dk translated">medium.com</p></div></div><div class="qw l"><div class="rd l qy qz ra qw rb lb qn"/></div></div></a></div><p id="2c88" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">还有更多在<a class="re rf ep" href="https://medium.com/u/22b31444736c?source=post_page-----135b4ae27f7e--------------------------------" rel="noopener" target="_blank"> Paras Varshney </a>的。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><p id="3dbc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果你从这篇文章中学到了新的东西或者喜欢阅读它，那么就分享出来，让其他人也能感受到。欢迎给我留言。</p><p id="e22c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">谢谢！</strong></p></div></div>    
</body>
</html>