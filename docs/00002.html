<html>
<head>
<title>Understanding and implementing a fully convolutional network (FCN)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解和实施全卷积网络(FCN)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/implementing-a-fully-convolutional-network-fcn-in-tensorflow-2-3c46fb61de3b?source=collection_archive---------1-----------------------#2020-01-01">https://towardsdatascience.com/implementing-a-fully-convolutional-network-fcn-in-tensorflow-2-3c46fb61de3b?source=collection_archive---------1-----------------------#2020-01-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="befa" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用Keras在TensorFlow中构建、训练和部署小型灵活的FCN影像分类模型的教程</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/8d3ea6f95a8e46534554db975fb96e23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nQn7jgVxRB-g_frB"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://unsplash.com/@dtravisphd?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">大卫·特拉维斯</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="fba2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">卷积神经网络(CNN)非常适合计算机视觉任务。使用在ImageNet、COCO等大型数据集上训练的预训练模型。我们可以快速专门化这些架构，使之适用于我们独特的数据集。这个过程被称为迁移学习。然而，有一个陷阱！用于图像分类和对象检测任务的预训练模型通常在固定的输入图像尺寸上训练。这些通常从<code class="fe ls lt lu lv b">224x224x3</code>到<code class="fe ls lt lu lv b">512x512x3</code>左右，并且大多具有1的纵横比，即图像的宽度和高度相等。如果它们不相等，那么图像被调整到相等的高度和宽度。</p><p id="b367" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">较新的架构确实具有处理可变输入图像大小的能力，但与图像分类任务相比，它更常见于对象检测和分割任务。最近，我遇到了一个有趣的用例，其中我有5个不同类别的图像，每个类别都有微小的差异。此外，图像的长宽比也比平时高。图像的平均高度约为30像素，宽度约为300像素。这是一个有趣的问题，原因如下:</p><ol class=""><li id="2187" class="lw lx iq ky b kz la lc ld lf ly lj lz ln ma lr mb mc md me bi translated">调整图像大小很容易扭曲重要的特征</li><li id="0b63" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">预先训练的架构非常庞大，并且总是过度适应数据集</li><li id="c506" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">这项任务要求低延迟</li></ol><h2 id="baa9" class="mk ml iq bd mm mn mo dn mp mq mr dp ms lf mt mu mv lj mw mx my ln mz na nb nc bi translated">需要具有可变输入维度的CNN</h2><p id="38c3" class="pw-post-body-paragraph kw kx iq ky b kz nd jr lb lc ne ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">我尝试了MobileNet和EfficientNet的基本模型，但都不起作用。需要一种对输入图像大小没有任何限制并能立即执行图像分类任务的网络。首先打动我的是全卷积网络(fcn)。FCN是一种不包含任何“密集”层(如传统CNN)的网络，而是包含执行完全连接层(密集层)任务的1x1卷积。虽然密集层的缺失使得可变输入成为可能，但有两种技术可以让我们在珍惜可变输入维度的同时使用密集层。本教程描述了其中的一些技术。在本教程中，我们将经历以下步骤:</p><ol class=""><li id="ddfa" class="lw lx iq ky b kz la lc ld lf ly lj lz ln ma lr mb mc md me bi translated">使用Keras在TensorFlow中构建全卷积网络(FCN)</li><li id="7abb" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">下载和分割样本数据集</li><li id="25fc" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">在Keras中创建一个生成器来加载和处理内存中的一批数据</li><li id="3c72" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">用可变批量维度训练网络</li><li id="7c1b" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">使用TensorFlow服务部署模型</li></ol><p id="6be3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">更新</strong>:从头开始建造和训练FCN时，你会遇到许多超参数。我写了另一篇文章，其中我给出了超参数优化的一个演练，包括数据扩充，使用了本文中讨论的相同的FCN架构。你可以在这里阅读<a class="ae kv" rel="noopener" target="_blank" href="/hyperparameter-tuning-with-keras-and-ray-tune-1353e6586fda"/>。</p><div class="ni nj gp gr nk nl"><a rel="noopener follow" target="_blank" href="/hyperparameter-tuning-with-keras-and-ray-tune-1353e6586fda"><div class="nm ab fo"><div class="nn ab no cl cj np"><h2 class="bd ir gy z fp nq fr fs nr fu fw ip bi translated">使用Keras和光线调节进行超参数调节</h2><div class="ns l"><h3 class="bd b gy z fp nq fr fs nr fu fw dk translated">使用贝叶斯优化为机器学习模型选择最佳超参数的实用教程。</h3></div><div class="nt l"><p class="bd b dl z fp nq fr fs nr fu fw dk translated">towardsdatascience.com</p></div></div><div class="nu l"><div class="nv l nw nx ny nu nz kp nl"/></div></div></a></div><h1 id="238f" class="oa ml iq bd mm ob oc od mp oe of og ms jw oh jx mv jz oi ka my kc oj kd nb ok bi translated">去拿圣经</h1><p id="d6a5" class="pw-post-body-paragraph kw kx iq ky b kz nd jr lb lc ne ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">在我的教程中，这里是上传到GitHub的项目链接。请克隆回购，并按照教程一步一步地更好地理解。<strong class="ky ir">注意</strong>:本文中的代码片段只突出了实际脚本的一部分，完整代码请参考GitHub repo。</p><div class="ni nj gp gr nk nl"><a href="https://github.com/himanshurawlani/fully_convolutional_network.git" rel="noopener  ugc nofollow" target="_blank"><div class="nm ab fo"><div class="nn ab no cl cj np"><h2 class="bd ir gy z fp nq fr fs nr fu fw ip bi translated">himanshurawlani/全卷积网络</h2><div class="ns l"><h3 class="bd b gy z fp nq fr fs nr fu fw dk translated">该库中的代码是在使用Python 3.6.7的Ubuntu 18.04.3 LTS上开发和测试的。以下是软件包…</h3></div><div class="nt l"><p class="bd b dl z fp nq fr fs nr fu fw dk translated">github.com</p></div></div><div class="nu l"><div class="ol l nw nx ny nu nz kp nl"/></div></div></a></div><h1 id="9d26" class="oa ml iq bd mm ob oc od mp oe of og ms jw oh jx mv jz oi ka my kc oj kd nb ok bi translated">1.设计发动机(model.py)</h1><p id="520f" class="pw-post-body-paragraph kw kx iq ky b kz nd jr lb lc ne ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">我们通过堆叠由2D卷积层(<code class="fe ls lt lu lv b">Conv2D</code>)和所需的正则化(<code class="fe ls lt lu lv b">Dropout</code>和<code class="fe ls lt lu lv b">BatchNormalization</code>)组成的卷积块来构建我们的FCN模型。正则化可以防止过度拟合，并有助于快速收敛。我们还添加了一个激活层来整合非线性。在Keras中，输入批次维度是自动添加的，我们不需要在输入层中指定它。由于输入图像的高度和宽度是可变的，我们将输入形状指定为<code class="fe ls lt lu lv b">(None, None, 3)</code>。3代表我们图像中的通道数，对于彩色图像(RGB)来说是固定的。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="om on l"/></div></figure><h2 id="71cc" class="mk ml iq bd mm mn mo dn mp mq mr dp ms lf mt mu mv lj mw mx my ln mz na nb nc bi translated">最小图像尺寸要求</h2><p id="bd58" class="pw-post-body-paragraph kw kx iq ky b kz nd jr lb lc ne ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">对输入应用卷积块后，输入的高度和宽度将根据<code class="fe ls lt lu lv b">kernel_size</code>和<code class="fe ls lt lu lv b">strides</code>的值减小。如果输入图像尺寸太小，那么我们可能达不到下一个卷积块所需的最小高度和宽度(应该大于或等于内核尺寸)。确定最小输入尺寸的试错法如下:</p><ol class=""><li id="f09c" class="lw lx iq ky b kz la lc ld lf ly lj lz ln ma lr mb mc md me bi translated">决定要堆叠的卷积块的数量</li><li id="be9a" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">选择任意输入形状，比如说<code class="fe ls lt lu lv b">(32, 32, 3)</code>,将卷积块与越来越多的通道进行堆叠</li><li id="6864" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">尝试建立模型并打印<code class="fe ls lt lu lv b">model.summary()</code>以查看每层的输出形状。</li><li id="86a3" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">确保从最后一个卷积块中得到<code class="fe ls lt lu lv b">(1, 1, num_of_filters)</code>作为输出尺寸(这将输入到完全连接的层)。</li><li id="f79e" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">尝试减少/增加输入形状、内核大小或步幅，以满足步骤4中的条件。满足条件的输入形状以及其他配置是网络所需的最小输入维度。</li></ol><p id="7b44" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">还有一种数学方法来计算输出体积的空间大小，作为输入体积的函数，如这里的<a class="ae kv" href="http://cs231n.github.io/convolutional-networks/#conv" rel="noopener ugc nofollow" target="_blank">所示</a>。找到最小输入维度后，我们现在需要将最后一个卷积块的输出传递给完全连接的层。但是，任何维度大于最小输入维度的输入都需要汇集起来，以满足步骤4中的条件。我们知道如何用我们的主要原料做到这一点。</p><h2 id="2d04" class="mk ml iq bd mm mn mo dn mp mq mr dp ms lf mt mu mv lj mw mx my ln mz na nb nc bi translated">主要成分</h2><p id="e7f9" class="pw-post-body-paragraph kw kx iq ky b kz nd jr lb lc ne ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">完全连接的层(FC层)将为我们执行分类任务。我们可以通过两种方式构建FC层:</p><ol class=""><li id="b291" class="lw lx iq ky b kz la lc ld lf ly lj lz ln ma lr mb mc md me bi translated">致密层</li><li id="ebc4" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">1x1卷积</li></ol><p id="eba8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们想要使用密集层，那么模型输入尺寸必须是固定的，因为作为密集层输入的参数的数量必须被预定义以创建密集层。具体来说，我们希望最后一个卷积块输出的<code class="fe ls lt lu lv b">(height, width, num_of_filters)</code>中的高度和宽度为常数或1。滤波器的数量总是固定的，因为这些值是由我们在每个卷积模块中定义的。</p><p id="68ea" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">1x1卷积的输入维度可以是<code class="fe ls lt lu lv b">(1, 1, num_of_filters)</code>或<code class="fe ls lt lu lv b">(height, width, num_of_filters)</code>，因为它们沿着<code class="fe ls lt lu lv b">num_of_filters</code>维度模拟FC层的功能。然而，在1x1卷积之后，对最后一层(Softmax激活层)的输入必须是固定长度的(类的数量)。</p><p id="9a6e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">主要成分:<strong class="ky ir">GlobalMaxPooling2D()</strong>/<strong class="ky ir">GlobalAveragePooling2D()</strong>。Keras中的这些层将尺寸为<code class="fe ls lt lu lv b">(height, width, num_of_filters)</code>的输入转换为<code class="fe ls lt lu lv b">(1, 1, num_of_filters)</code>的输入，实质上是沿<code class="fe ls lt lu lv b">num_of_filters</code>尺寸的每个过滤器沿高度和宽度尺寸取最大值或平均值。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="om on l"/></div></figure><h2 id="2552" class="mk ml iq bd mm mn mo dn mp mq mr dp ms lf mt mu mv lj mw mx my ln mz na nb nc bi translated">密集层与1x1卷积</h2><p id="a3c4" class="pw-post-body-paragraph kw kx iq ky b kz nd jr lb lc ne ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">代码包括密集层(注释掉)和1x1卷积。在使用这两种配置构建和训练了模型之后，以下是我的一些观察:</p><ol class=""><li id="9997" class="lw lx iq ky b kz la lc ld lf ly lj lz ln ma lr mb mc md me bi translated">两种模型包含相同数量的可训练参数。</li><li id="09ba" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">相似的训练和推理时间。</li><li id="f198" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">密集层比1x1卷积更容易概括。</li></ol><p id="d2bb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第三点不能一概而论，因为它取决于数据集中的图像数量、使用的数据扩充、模型初始化等因素。然而，这些是我在实验中观察到的。您可以通过触发命令<code class="fe ls lt lu lv b">$python model.py</code>来独立运行脚本，以测试模型是否构建成功。</p><h1 id="0484" class="oa ml iq bd mm ob oc od mp oe of og ms jw oh jx mv jz oi ka my kc oj kd nb ok bi translated">2.下载燃料(data.py)</h1><p id="94cb" class="pw-post-body-paragraph kw kx iq ky b kz nd jr lb lc ne ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">本教程中使用的flowers数据集主要是为了理解我们在训练具有可变输入维度的模型时所面临的挑战。一些测试我们的FCN模型的有趣数据集可能来自医学成像领域，其中包含对图像分类至关重要的微观特征，以及其他包含几何图案/形状的数据集，这些图案/形状在调整图像大小后可能会扭曲。</p><p id="d260" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">提供的脚本(data.py)需要独立运行(<code class="fe ls lt lu lv b">$python data.py</code>)。它将执行以下任务:</p><ol class=""><li id="6550" class="lw lx iq ky b kz la lc ld lf ly lj lz ln ma lr mb mc md me bi translated">下载包含5个类别的花卉数据集(“雏菊”、“蒲公英”、“玫瑰”、“向日葵”、“郁金香”)。关于数据集<a class="ae kv" href="https://www.tensorflow.org/datasets/catalog/tf_flowers" rel="noopener ugc nofollow" target="_blank">的更多细节请点击</a>。</li><li id="d0b4" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">将数据集拆分为定型集和验证集。您可以设置要复制到训练集和验证集中的图像数量。</li><li id="3307" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">给出数据集的统计数据，如图像的最小、平均和最大高度和宽度。</li></ol><p id="3e20" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个脚本下载<code class="fe ls lt lu lv b">.tar</code>文件，并使用<code class="fe ls lt lu lv b">keras.utils.get_file()</code>提取当前目录中的内容。如果你想使用TensorFlow数据集(TFDS ),你可以查看<a class="ae kv" href="https://medium.com/@himanshurawlani/getting-started-with-tensorflow-2-0-faf5428febae" rel="noopener">这篇</a>教程，它展示了TFDS和数据扩充的用法。</p><h1 id="b99f" class="oa ml iq bd mm ob oc od mp oe of og ms jw oh jx mv jz oi ka my kc oj kd nb ok bi translated">3.专用化油器(generator.py)</h1><p id="37a0" class="pw-post-body-paragraph kw kx iq ky b kz nd jr lb lc ne ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">我们希望在不同的输入维度上训练我们的模型。给定批次和跨批次的每个图像都有不同的尺寸。那么问题出在哪里？让我们后退一步，重新审视我们如何训练传统的图像分类器。在传统的图像分类器中，图像被<strong class="ky ir">调整</strong>到给定的维度，通过转换成<strong class="ky ir"> numpy数组或张量</strong>打包成<strong class="ky ir">批</strong>，并且这批数据通过模型向前传播。指标(损失、准确性等。)在该批次中进行评估。基于这些度量来计算要反向传播的梯度。</p><p id="ad10" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们不能调整图像的大小(因为我们会失去微观特征)。现在，由于我们不能调整图像的大小，将它们转换成numpy数组就变得不可能了。这是因为如果你有一个包含10幅尺寸为<code class="fe ls lt lu lv b">(height, width, 3)</code>的图像的列表，它们的<code class="fe ls lt lu lv b">height</code>和<code class="fe ls lt lu lv b">width</code>的值不同，并且你试图将它传递给<code class="fe ls lt lu lv b">np.array()</code>，那么得到的数组将是<code class="fe ls lt lu lv b">(10,)</code>的形状，而不是<code class="fe ls lt lu lv b">(10, height, width, 3)</code>！然而，我们的模型期望输入维度是后一种形状。解决此问题的方法是编写一个执行以下操作的自定义训练循环:</p><ol class=""><li id="19ea" class="lw lx iq ky b kz la lc ld lf ly lj lz ln ma lr mb mc md me bi translated">我们通过使用<code class="fe ls lt lu lv b">np.expand_dims(img, axis=0)</code>将<code class="fe ls lt lu lv b">(height, width, 3)</code>转换为<code class="fe ls lt lu lv b">(1, height, width, 3)</code>来传递列表(批处理)中的每个图像。</li><li id="b94f" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">在python列表(批处理)中累积每个图像的度量。</li><li id="d33c" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">使用累积的指标计算损耗和梯度。将渐变更新应用于模型。</li><li id="1c32" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">重置指标值，并创建新的图像列表(批次)。</li></ol><p id="1c1f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我尝试了上述步骤，我的建议是不要采用上述策略。这很费力，导致复杂和不可持续的代码，并且运行非常慢！人人都爱优雅而经典的<em class="oo"/><code class="fe ls lt lu lv b">model.fit()</code><code class="fe ls lt lu lv b">model.fit_generator()</code>。我们将在这里使用后者！但是首先，化油器。</p><p id="f9b1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">化油器是一种将内燃机的空气和燃料以适当的空燃比混合以进行燃烧的装置。这就是我们需要的，空气！我们找到一批图像中最大的高度和宽度，然后每隔一个图像用零填充，这样批中的每个图像都有相等的尺寸。现在我们可以很容易地将其转换为numpy数组或张量，并将其传递给<code class="fe ls lt lu lv b">fit_generator()</code>。该模型自动学习忽略零(基本上是黑色像素),并从填充图像的预期部分学习特征。这样，我们就有了一批具有相同图像尺寸的图像，但每批都有不同的形状(由于不同批次图像的最大高度和宽度不同)。您可以使用<code class="fe ls lt lu lv b">$python generator.py</code>独立运行<code class="fe ls lt lu lv b">generator.py</code>文件，并交叉检查输出。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="eb9d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在Keras中创建生成器非常简单，这里有一个很好的入门教程<a class="ae kv" href="https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly" rel="noopener ugc nofollow" target="_blank"/>。对<code class="fe ls lt lu lv b">generator.py</code>的一个很好的补充是包括对数据扩充的支持，你可以在这里获得一些灵感。</p><h1 id="8a00" class="oa ml iq bd mm ob oc od mp oe of og ms jw oh jx mv jz oi ka my kc oj kd nb ok bi translated">4.点火到认知(train.py)</h1><p id="9d95" class="pw-post-body-paragraph kw kx iq ky b kz nd jr lb lc ne ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">训练脚本导入并实例化以下类:</p><ol class=""><li id="b8de" class="lw lx iq ky b kz la lc ld lf ly lj lz ln ma lr mb mc md me bi translated">生成器:我们需要指定由<code class="fe ls lt lu lv b">data.py</code>创建的<code class="fe ls lt lu lv b">train</code>和<code class="fe ls lt lu lv b">val</code>目录的路径。</li><li id="4290" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">FCN模型:我们需要指定最终输出层所需的类的数量。</li></ol><p id="35f6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上述对象被传递给<code class="fe ls lt lu lv b">train()</code>函数，该函数使用Adam优化器和分类交叉熵损失函数编译模型。我们创建一个检查点回调来保存训练期间的最佳模型。基于在每个时期结束时对验证集计算的损失值来确定最佳模型。我们可以看到<code class="fe ls lt lu lv b">fit_generator()</code>函数在很大程度上简化了代码，令人赏心悦目。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="4627" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我建议在Google Colab上进行训练，除非你的本地机器上有GPU。GitHub repo包括一个Colab笔记本，它将培训所需的所有内容放在一起。您可以在Colab本身中修改python脚本，并在您选择的数据集上训练不同的模型配置。完成培训后，您可以从Colab的“文件”选项卡下载最佳快照到您的本地机器。</p><h1 id="3fba" class="oa ml iq bd mm ob oc od mp oe of og ms jw oh jx mv jz oi ka my kc oj kd nb ok bi translated">5.使用TensorFlow服务部署模型(inference.py)</h1><p id="4c38" class="pw-post-body-paragraph kw kx iq ky b kz nd jr lb lc ne ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">下载完模型后，您需要使用<code class="fe ls lt lu lv b">export_savedmodel.py</code>将其导出为SavedModel格式。在主函数中指定下载模型(<code class="fe ls lt lu lv b">.h5</code>文件)的路径，并使用命令<code class="fe ls lt lu lv b">$python export_savedmodel.py</code>执行脚本。该脚本使用TensorFlow 2.0中的新功能，从<code class="fe ls lt lu lv b">.h5</code>文件加载Keras模型，并将其保存为TensorFlow SavedModel格式。SavedModel将被导出到脚本中指定的<code class="fe ls lt lu lv b">export_path</code>。TensorFlow服务docker映像需要此SavedModel。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="f007" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要启动TensorFlow服务服务器，请转到导出SavedModel的目录(在本例中为<code class="fe ls lt lu lv b">./flower_classifier</code>)并运行以下命令(注意:您的计算机上必须安装Docker):</p><pre class="kg kh ki kj gt op lv oq or aw os bi"><span id="b827" class="mk ml iq lv b gy ot ou l ov ow">$ docker run --rm -t -p 8501:8501 -v "$(pwd):/models/flower_classifier" -e MODEL_NAME=flower_classifier --name flower_classifier tensorflow/serving</span></pre><p id="9c1c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上述命令执行以下步骤:</p><ol class=""><li id="ae66" class="lw lx iq ky b kz la lc ld lf ly lj lz ln ma lr mb mc md me bi translated">如果本地没有<code class="fe ls lt lu lv b">tensorflow/serving</code> docker图像，则提取该图像。</li><li id="b416" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">“-p”标志将本地机器上的端口8501映射到docker容器中的端口8501。</li><li id="38f0" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">“-v”标志将当前目录(由<code class="fe ls lt lu lv b">$(pwd)</code>指定)装载到docker容器中的<code class="fe ls lt lu lv b">/models/flower_classifier</code>中。</li><li id="1dcf" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">“-e”标志设置docker容器中的环境变量，TensorFlow服务服务器使用该变量来创建REST端点。</li><li id="c29f" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">“-RM”标志在删除容器时删除与容器关联的任何匿名卷。</li><li id="977f" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">“-t”显示当前终端中的容器日志。您可以按CTRL+C返回到您的终端，容器将继续在后台运行。</li></ol><p id="9edc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以使用<code class="fe ls lt lu lv b">$ docker ps</code>命令来验证您的容器是否在后台运行。您还可以使用<code class="fe ls lt lu lv b">$ docker logs your_container_id</code>查看容器日志。<code class="fe ls lt lu lv b">inference.py</code>脚本包含构建统一图像尺寸批次并将这些批次作为POST请求发送到TensorFlow服务服务器的代码。从服务器接收的输出在终端中被解码和打印。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="om on l"/></div></figure><h1 id="27c7" class="oa ml iq bd mm ob oc od mp oe of og ms jw oh jx mv jz oi ka my kc oj kd nb ok bi translated">梦想的传递</h1><p id="8e3b" class="pw-post-body-paragraph kw kx iq ky b kz nd jr lb lc ne ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">在本教程中，我们了解了以下内容:</p><ol class=""><li id="ac9c" class="lw lx iq ky b kz la lc ld lf ly lj lz ln ma lr mb mc md me bi translated">为具有可变输入维数的图像分类建立一个标准的完全卷积网络。</li><li id="cd1f" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">用一批中相同的图像形状和不同的批形状训练FCN模型。</li><li id="8190" class="lw lx iq ky b kz mf lc mg lf mh lj mi ln mj lr mb mc md me bi translated">使用TensorFlow服务docker图像部署训练好的模型。</li></ol><p id="6e4f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，本教程仅介绍了机器学习工作流程中的单个组件。ML管道由大量的特定于组织及其用例的训练、推理和监控周期组成。建立这些管道需要更深入地了解司机、乘客和车辆的路线。只有这样才有可能交付梦想的运输工具！</p></div><div class="ab cl ox oy hu oz" role="separator"><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc"/></div><div class="ij ik il im in"><p id="4896" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我希望这篇教程对你构建下一个令人敬畏的机器学习项目有所帮助。我很乐意听取您对资源库的建议和改进，也可以随时提出GitHub的问题。如果你发现文章中有任何错误或遗漏的信息，请在评论区告诉我。谢谢！</p></div></div>    
</body>
</html>