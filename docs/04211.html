<html>
<head>
<title>Installing Hadoop 3.2.1 Single node cluster on Windows 10</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 Windows 10 上安装 Hadoop 3.2.1 单节点集群</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/installing-hadoop-3-2-1-single-node-cluster-on-windows-10-ac258dd48aef?source=collection_archive---------0-----------------------#2020-04-17">https://towardsdatascience.com/installing-hadoop-3-2-1-single-node-cluster-on-windows-10-ac258dd48aef?source=collection_archive---------0-----------------------#2020-04-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="c9ba" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">两年前在做一个<a class="ae kl" href="https://www.researchgate.net/project/ORADIEX-A-Big-Data-driven-smart-framework-for-real-time-surveillance-and-analysis-of-individual-exposure-to-radioactive-pollution" rel="noopener ugc nofollow" target="_blank">项目</a>的时候，我写了一个<a class="ae kl" rel="noopener" target="_blank" href="/installing-hadoop-3-1-0-multi-node-cluster-on-ubuntu-16-04-step-by-step-8d1954b31505">在 Ubuntu 16.04 </a>操作系统上安装 Hadoop 3.1.0 的分步指南。由于我们目前正在进行一个新项目，需要在 Windows 10 上安装 Hadoop 集群，我决定为这个过程编写一个指南。</p><p id="9157" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">本文是我们在 TowardsDataScience.com 上发布的系列文章的一部分，旨在说明如何在 Windows 操作系统上安装大数据技术。</p><p id="4afc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">本系列其他发表文章:</strong></p><ul class=""><li id="798c" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated"><a class="ae kl" rel="noopener" target="_blank" href="/installing-apache-pig-0-17-0-on-windows-10-7b19ce61900d">在 Windows 10 上安装 Apache Pig 0 . 17 . 0</a></li><li id="86a4" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated"><a class="ae kl" rel="noopener" target="_blank" href="/installing-apache-hive-3-1-2-on-windows-10-70669ce79c79">在 Windows 10 上安装 Apache Hive 3 . 1 . 2</a></li></ul><h1 id="774b" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">1.先决条件</h1><p id="fe2f" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">首先，我们需要确保安装了以下先决条件:</p><p id="d0f5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">1.Java 8 运行时环境(JRE): <a class="ae kl" href="https://cwiki.apache.org/confluence/display/HADOOP/Hadoop+Java+Versions" rel="noopener ugc nofollow" target="_blank"> Hadoop 3 需要安装 Java 8</a>。我更喜欢使用离线安装程序。</p><p id="fffe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2.<a class="ae kl" href="https://www.oracle.com/java/technologies/javase-jdk8-downloads.html" rel="noopener ugc nofollow" target="_blank"> Java 8 开发套件(JDK) </a></p><p id="72f0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">3.为了解压下载的 Hadoop 二进制文件，我们应该安装<a class="ae kl" href="https://www.7-zip.org/download.html" rel="noopener ugc nofollow" target="_blank"> 7zip </a>。</p><p id="6f44" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">4.我将在本地机器上创建一个文件夹“E:\hadoop-env”来存储下载的文件。</p><h1 id="2783" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">2.下载 Hadoop 二进制文件</h1><p id="f827" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">第一步，从<a class="ae kl" href="https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz" rel="noopener ugc nofollow" target="_blank">官网</a>下载 Hadoop 二进制。二进制包的大小约为 342 MB。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi md"><img src="../Images/a0ab777c195d4527d0ff625fea573c5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cXELegHaPy2qUUdXa4FDsA.png"/></div></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">图 1 — Hadoop 二进制文件下载链接</p></figure><p id="73bb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">完成文件下载后，我们应该使用 7zip int 分两步解压软件包。首先，我们应该提取 hadoop-3.2.1.tar.gz 库，然后，我们应该解压缩提取的 tar 文件:</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mt"><img src="../Images/7ac5b9744ed75801ad8fc61b663b83a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RWPxRqHqDKZgrbW9JhloqA.png"/></div></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">图 2 —使用 7zip 提取 hadoop-3.2.1.tar.gz 包</p></figure><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/f2544f69e4cd82de460108a6234d8fd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*SDBrDoXFegBy7SMEI9aV4w.png"/></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">图 3 —提取的 hadoop-3.2.1.tar 文件</p></figure><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mv"><img src="../Images/98d9c68f1e3e20d6fc431d8dd28af581.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DD-r-pgDCfVvaqoMNvB5Bg.png"/></div></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">图 4 —提取 hadoop-3.2.1.tar 文件</p></figure><p id="20b9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">tar 文件提取可能需要几分钟才能完成。最后，您可能会看到一些关于符号链接创建的警告。请忽略这些警告，因为它们与 windows 无关。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mw"><img src="../Images/0e7dbe8e341477c675c2b841633542ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kvGOx5bKh2B5CxsNEslgfw.png"/></div></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">图 5-符号链接警告</p></figure><p id="6192" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">解包后，我们要添加 Hadoop 原生 IO 库，可以在下面的 GitHub 库找到:<a class="ae kl" href="https://github.com/cdarlint/winutils" rel="noopener ugc nofollow" target="_blank">https://github.com/cdarlint/winutils</a>。</p><p id="b9f3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于我们正在安装 Hadoop 3.2.1，我们应该下载位于<a class="ae kl" href="https://github.com/cdarlint/winutils/tree/master/hadoop-3.2.1/bin" rel="noopener ugc nofollow" target="_blank">https://github . com/cdarlint/winutils/tree/master/Hadoop-3 . 2 . 1/bin</a>中的文件，并将其复制到“hadoop-3.2.1\bin”目录中。</p><h1 id="bfd5" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">3.设置环境变量</h1><p id="54e9" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">安装 Hadoop 及其先决条件后，我们应该配置环境变量来定义 Hadoop 和 Java 默认路径。</p><p id="3215" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要编辑环境变量，请转到控制面板&gt;系统和安全&gt;系统(或右键单击&gt;我的电脑上的属性图标)，然后单击“高级系统设置”链接。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mx"><img src="../Images/9c71e2111bcdaaec5eee10d326b158bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KujiHwlx5OJGEuO9ddPOgQ.png"/></div></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">图 6 —打开高级系统设置</p></figure><p id="da2b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当“高级系统设置”对话框出现时，转到“高级”选项卡并单击位于对话框底部的“环境变量”按钮。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi my"><img src="../Images/a942efcda9f52a5c468711634a81ca32.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/1*TQ9PKtcdkh4zphC9VPQe_w.png"/></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">图 7 —高级系统设置对话框</p></figure><p id="708c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在“环境变量”对话框中，按“新建”按钮添加一个新变量。</p><blockquote class="mz na nb"><p id="b70a" class="jn jo nc jp b jq jr js jt ju jv jw jx nd jz ka kb ne kd ke kf nf kh ki kj kk ij bi translated">注意:在本指南中，我们将添加用户变量，因为我们是为单个用户配置 Hadoop。如果您希望为多个用户配置 Hadoop，您可以改为定义系统变量。</p></blockquote><p id="b669" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有两个变量需要定义:</p><p id="151c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">1.JAVA_HOME: JDK 安装文件夹路径</p><p id="f49a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2.HADOOP_HOME: Hadoop 安装文件夹路径</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/6a3789fbef960f49d7e4d9905a75f547.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*5OlIdj_CLEPF1ykacUwZcg.png"/></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">图 8 —添加 JAVA_HOME 变量</p></figure><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/e95ac272ea1872b63eb77d034f9bdfcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*7eN0XKSPdjuESi75KgNOiQ.png"/></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">图 9 —添加 HADOOP_HOME 变量</p></figure><p id="fe88" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们应该编辑 PATH 变量来添加 Java 和 Hadoop 二进制文件路径，如下图所示。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/742d2539ec9596418d195f8adc9cafdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*JAix-8FASR3UiXQmT0GscA.png"/></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">图 10 —编辑路径变量</p></figure><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/198cfa525573372f254278c0414c2015.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*VAArTHhLJLkKM9vrQrzc1Q.png"/></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">图 11 —编辑路径变量</p></figure><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/c582976125a443f14e232a6554bd671c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*X8qPWrU2pNYMG09867Frkg.png"/></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">图 12—向 PATH 变量添加新路径</p></figure><h2 id="0784" class="nj lb iq bd lc nk nl dn lg nm nn dp lk jy no np lo kc nq nr ls kg ns nt lw nu bi translated">3.1.JAVA_HOME 设置错误</h2><p id="8340" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">现在，让我们打开 PowerShell 并尝试运行以下命令:</p><pre class="me mf mg mh gt nv nw nx ny aw nz bi"><span id="a716" class="nj lb iq nw b gy oa ob l oc od">hadoop -version</span></pre><p id="9bd9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本例中，由于 JAVA_HOME 路径包含空格，我收到了以下错误:</p><pre class="me mf mg mh gt nv nw nx ny aw nz bi"><span id="e6c6" class="nj lb iq nw b gy oa ob l oc od">JAVA_HOME is incorrectly set</span></pre><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi oe"><img src="../Images/920dcffc70b4f3c76053cff89b354ddc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1158/format:webp/1*ZYU0nEMPkAbIf4ZCTLPOCg.png"/></div></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">图 13 — JAVA_HOME 错误</p></figure><p id="4620" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要解决这个问题，我们应该改用 windows 8.3 路径。举个例子:</p><ul class=""><li id="03dd" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated">使用“Progra~1”而不是“程序文件”</li><li id="4d0a" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">使用“Progra~2”而不是“程序文件(x86)”</li></ul><p id="bc16" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在将“程序文件”替换为“Progra~1”之后，我们关闭并重新打开 PowerShell，并尝试了相同的命令。如下图所示，它运行时没有错误。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi of"><img src="../Images/73d8b5f201a03bb1e214367a1a94b13a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*tEkTKDFw1n2tgUgUEJLJ3A.png"/></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">图 14 — hadoop 版本命令成功执行</p></figure><h1 id="0bec" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">4.配置 Hadoop 集群</h1><p id="b282" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">为了配置 Hadoop 集群，我们应该更改四个文件:</p><ol class=""><li id="4990" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk og ks kt ku bi translated">% HADOOP _ HOME % \ etc \ HADOOP \ HDFS-site . XML</li><li id="a9ce" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk og ks kt ku bi translated">% HADOOP _ HOME % \ etc \ HADOOP \ core-site . XML</li><li id="538d" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk og ks kt ku bi translated">% HADOOP _ HOME % \ etc \ HADOOP \ map red-site . XML</li><li id="63ea" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk og ks kt ku bi translated">% HADOOP _ HOME % \ etc \ HADOOP \ yarn-site . XML</li></ol><h2 id="124d" class="nj lb iq bd lc nk nl dn lg nm nn dp lk jy no np lo kc nq nr ls kg ns nt lw nu bi translated">4.1.HDFS 站点配置</h2><p id="a708" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">众所周知，Hadoop 是使用主从模式构建的。在修改 HDFS 配置文件之前，我们应该创建一个目录来存储所有主节点(名称节点)数据，并创建另一个目录来存储数据(数据节点)。在本例中，我们创建了以下目录:</p><ul class=""><li id="7824" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated">e:\ Hadoop-env \ Hadoop-3 . 2 . 1 \ data \ DFS \ NameNode</li><li id="571c" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">e:\ Hadoop-env \ Hadoop-3 . 2 . 1 \ data \ DFS \ datanode</li></ul><p id="497d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，让我们打开位于“%HADOOP_HOME%\etc\hadoop”目录中的“hdfs-site.xml”文件，我们应该在<configuration> </configuration>元素中添加以下属性:</p><pre class="me mf mg mh gt nv nw nx ny aw nz bi"><span id="b4d3" class="nj lb iq nw b gy oa ob l oc od">&lt;property&gt;</span><span id="9c06" class="nj lb iq nw b gy oh ob l oc od">&lt;name&gt;dfs.replication&lt;/name&gt;</span><span id="38c0" class="nj lb iq nw b gy oh ob l oc od">&lt;value&gt;1&lt;/value&gt;</span><span id="04ea" class="nj lb iq nw b gy oh ob l oc od">&lt;/property&gt;</span><span id="f96d" class="nj lb iq nw b gy oh ob l oc od">&lt;property&gt;</span><span id="3530" class="nj lb iq nw b gy oh ob l oc od">&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><span id="c8d5" class="nj lb iq nw b gy oh ob l oc od">&lt;value&gt;file:///E:/hadoop-env/hadoop-3.2.1/data/dfs/namenode&lt;/value&gt;</span><span id="7646" class="nj lb iq nw b gy oh ob l oc od">&lt;/property&gt;</span><span id="2bbc" class="nj lb iq nw b gy oh ob l oc od">&lt;property&gt;</span><span id="e80d" class="nj lb iq nw b gy oh ob l oc od">&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><span id="aadf" class="nj lb iq nw b gy oh ob l oc od">&lt;value&gt;file:///E:/hadoop-env/hadoop-3.2.1/data/dfs/datanode&lt;/value&gt;</span><span id="a879" class="nj lb iq nw b gy oh ob l oc od">&lt;/property&gt;</span></pre><blockquote class="mz na nb"><p id="722f" class="jn jo nc jp b jq jr js jt ju jv jw jx nd jz ka kb ne kd ke kf nf kh ki kj kk ij bi translated">请注意，我们已经将复制因子设置为 1，因为我们正在创建单节点集群。</p></blockquote><h2 id="3a4a" class="nj lb iq bd lc nk nl dn lg nm nn dp lk jy no np lo kc nq nr ls kg ns nt lw nu bi translated">4.2.核心站点配置</h2><p id="2c18" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">现在，我们应该配置名称节点 URL，将以下 XML 代码添加到“core-site.xml”内的<configuration> </configuration>元素中:</p><pre class="me mf mg mh gt nv nw nx ny aw nz bi"><span id="3d95" class="nj lb iq nw b gy oa ob l oc od">&lt;property&gt;</span><span id="bb9b" class="nj lb iq nw b gy oh ob l oc od">&lt;name&gt;fs.default.name&lt;/name&gt;</span><span id="6557" class="nj lb iq nw b gy oh ob l oc od">&lt;value&gt;hdfs://localhost:9820&lt;/value&gt;</span><span id="3e3f" class="nj lb iq nw b gy oh ob l oc od">&lt;/property&gt;</span></pre><h2 id="30dd" class="nj lb iq bd lc nk nl dn lg nm nn dp lk jy no np lo kc nq nr ls kg ns nt lw nu bi translated">4.3.地图简化站点配置</h2><p id="3782" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">现在，我们应该将下面的 XML 代码添加到“mapred-site.xml”中的<configuration> </configuration>元素中:</p><pre class="me mf mg mh gt nv nw nx ny aw nz bi"><span id="c257" class="nj lb iq nw b gy oa ob l oc od">&lt;property&gt;</span><span id="ebd7" class="nj lb iq nw b gy oh ob l oc od">&lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><span id="3eb4" class="nj lb iq nw b gy oh ob l oc od">&lt;value&gt;yarn&lt;/value&gt;</span><span id="62e8" class="nj lb iq nw b gy oh ob l oc od">&lt;description&gt;MapReduce framework name&lt;/description&gt;</span><span id="c919" class="nj lb iq nw b gy oh ob l oc od">&lt;/property&gt;</span></pre><h2 id="a2c1" class="nj lb iq bd lc nk nl dn lg nm nn dp lk jy no np lo kc nq nr ls kg ns nt lw nu bi translated">4.4.纱线位置配置</h2><p id="6a00" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">现在，我们应该将下面的 XML 代码添加到“yarn-site.xml”中的<configuration> </configuration>元素中:</p><pre class="me mf mg mh gt nv nw nx ny aw nz bi"><span id="1023" class="nj lb iq nw b gy oa ob l oc od">&lt;property&gt;</span><span id="a0a8" class="nj lb iq nw b gy oh ob l oc od">&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><span id="208f" class="nj lb iq nw b gy oh ob l oc od">&lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><span id="20f6" class="nj lb iq nw b gy oh ob l oc od">&lt;description&gt;Yarn Node Manager Aux Service&lt;/description&gt;</span><span id="7889" class="nj lb iq nw b gy oh ob l oc od">&lt;/property&gt;</span></pre><h1 id="d5dd" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">5.格式化名称节点</h1><p id="a2ee" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">完成配置后，让我们尝试使用以下命令格式化名称节点:</p><pre class="me mf mg mh gt nv nw nx ny aw nz bi"><span id="9774" class="nj lb iq nw b gy oa ob l oc od">hdfs namenode -format</span></pre><p id="5422" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于 Hadoop 3.2.1 版本中的<a class="ae kl" href="https://issues.apache.org/jira/browse/HDFS-14890" rel="noopener ugc nofollow" target="_blank">错误，您将收到以下错误:</a></p><pre class="me mf mg mh gt nv nw nx ny aw nz bi"><span id="05d1" class="nj lb iq nw b gy oa ob l oc od">2020–04–17 22:04:01,503 ERROR namenode.NameNode: Failed to start namenode.</span><span id="a70b" class="nj lb iq nw b gy oh ob l oc od">java.lang.UnsupportedOperationException</span><span id="9740" class="nj lb iq nw b gy oh ob l oc od">at java.nio.file.Files.setPosixFilePermissions(Files.java:2044)</span><span id="0bb2" class="nj lb iq nw b gy oh ob l oc od">at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.clearDirectory(Storage.java:452)</span><span id="3f09" class="nj lb iq nw b gy oh ob l oc od">at org.apache.hadoop.hdfs.server.namenode.NNStorage.format(NNStorage.java:591)</span><span id="9742" class="nj lb iq nw b gy oh ob l oc od">at org.apache.hadoop.hdfs.server.namenode.NNStorage.format(NNStorage.java:613)</span><span id="d0ae" class="nj lb iq nw b gy oh ob l oc od">at org.apache.hadoop.hdfs.server.namenode.FSImage.format(FSImage.java:188)</span><span id="2bfc" class="nj lb iq nw b gy oh ob l oc od">at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1206)</span><span id="b171" class="nj lb iq nw b gy oh ob l oc od">at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1649)</span><span id="16d0" class="nj lb iq nw b gy oh ob l oc od">at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1759)</span><span id="ec6f" class="nj lb iq nw b gy oh ob l oc od">2020–04–17 22:04:01,511 INFO util.ExitUtil: Exiting with status 1: java.lang.UnsupportedOperationException</span><span id="829d" class="nj lb iq nw b gy oh ob l oc od">2020–04–17 22:04:01,518 INFO namenode.NameNode: SHUTDOWN_MSG:</span></pre><p id="aa90" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个问题将在下一个版本中解决。目前，您可以使用以下步骤暂时修复它(<a class="ae kl" href="https://kontext.tech/column/hadoop/377/latest-hadoop-321-installation-on-windows-10-step-by-step-guide" rel="noopener ugc nofollow" target="_blank">参考</a>):</p><ol class=""><li id="9822" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk og ks kt ku bi translated">从<a class="ae kl" href="https://github.com/FahaoTang/big-data/blob/master/hadoop-hdfs-3.2.1.jar" rel="noopener ugc nofollow" target="_blank">下面的链接</a>下载 hadoop-hdfs-3.2.1.jar 文件。</li><li id="5c31" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk og ks kt ku bi translated">将文件夹% HADOOP _ HOME % \ share \ HADOOP \ HDFS 中的文件名 hadoop-hdfs-3.2.1.jar 重命名为 hadoop-hdfs-3.2.1.bak</li><li id="654e" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk og ks kt ku bi translated">将下载的 hadoop-hdfs-3.2.1.jar 复制到文件夹% HADOOP _ HOME % \ share \ HADOOP \ HDFS</li></ol><p id="3cfa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，如果我们尝试重新执行 format 命令(以管理员身份运行命令提示符或 PowerShell)，您需要批准文件系统格式。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi oi"><img src="../Images/263baf051829531a4ea8785364c10f82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kT7ic0bgRKPq5NrSAp5QLQ.png"/></div></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">图 15 —文件系统格式批准</p></figure><p id="96dd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">并且命令成功执行:</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi oj"><img src="../Images/c95a6d76a8133a0772c9daee8807eeb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*27VdkFVpfXoJ9hpFf35stQ.png"/></div></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">图 16 —成功执行的命令</p></figure><h1 id="dd57" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">6.启动 Hadoop 服务</h1><p id="900b" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">现在，我们将打开 PowerShell，并导航到“%HADOOP_HOME%\sbin”目录。然后，我们将运行以下命令来启动 Hadoop 节点:</p><pre class="me mf mg mh gt nv nw nx ny aw nz bi"><span id="6c8f" class="nj lb iq nw b gy oa ob l oc od">.\start-dfs.cmd</span></pre><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi oj"><img src="../Images/f9456c703d65332e275f56262423f0ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mVea1BrGIIscyGJROmMahA.png"/></div></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">图 17 —启动 Hadoop 节点</p></figure><p id="94e7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">将打开两个命令提示符窗口(一个用于名称节点，一个用于数据节点)，如下所示:</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi ok"><img src="../Images/7a00b7c675bd4970c7b9f7ce2530fd84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cG5yk7I92Z2W-ujfVpkWBg.png"/></div></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">图 18 — Hadoop 节点命令提示符窗口</p></figure><p id="f285" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，我们必须使用以下命令启动 Hadoop Yarn 服务:</p><pre class="me mf mg mh gt nv nw nx ny aw nz bi"><span id="6a23" class="nj lb iq nw b gy oa ob l oc od">./start-yarn.cmd</span></pre><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi oi"><img src="../Images/9f22aa9bc4c72e6bd17a3be27f1e862b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gCTbS1N7n39jhLOkgWRn0Q.png"/></div></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">图 19 —启动 Hadoop 纱线服务</p></figure><p id="9347" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">将打开两个命令提示符窗口(一个用于资源管理器，一个用于节点管理器)，如下所示:</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi ok"><img src="../Images/33546a830948f442734f5c12f4e7f688.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yv5-wHHKIntM43pyu8kB1Q.png"/></div></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">图 20—节点管理器和资源管理器命令提示符窗口</p></figure><p id="67e6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了确保所有服务都成功启动，我们可以运行以下命令:</p><pre class="me mf mg mh gt nv nw nx ny aw nz bi"><span id="fc4e" class="nj lb iq nw b gy oa ob l oc od">jps</span></pre><p id="1c61" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它应该显示以下服务:</p><pre class="me mf mg mh gt nv nw nx ny aw nz bi"><span id="d1e8" class="nj lb iq nw b gy oa ob l oc od">14560 DataNode<br/>4960 ResourceManager<br/>5936 NameNode<br/>768 NodeManager<br/>14636 Jps</span></pre><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi ol"><img src="../Images/bfe37944e3332ee2d2c2851ca664e041.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vG4CaIzV33jw3SOrHAb2Eg.png"/></div></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">图 21 —执行 jps 命令</p></figure><h1 id="6389" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">7.Hadoop Web 用户界面</h1><p id="b86f" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">有三种网络用户界面可供使用:</p><ul class=""><li id="b2fc" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated">名称节点网页:<a class="ae kl" href="http://localhost:9870/dfshealth.html" rel="noopener ugc nofollow" target="_blank">http://localhost:9870/DFS health . html</a></li></ul><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi ok"><img src="../Images/a2ea32a60cea3623431773e68d6fe7f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IjBr21eB-zkZ8AeDTPVHRg.png"/></div></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">图 22 —名称节点网页</p></figure><ul class=""><li id="b4b5" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated">数据节点网页:<a class="ae kl" href="http://localhost:9864/datanode.html" rel="noopener ugc nofollow" target="_blank">http://localhost:9864/datanode . html</a></li></ul><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi ok"><img src="../Images/46ac6cda601490cdb4f0becbc2f1576c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*URxS56RVBMEt5A9Q6FmUtg.png"/></div></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">图 23 —数据节点网页</p></figure><ul class=""><li id="b0ee" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated">纱线网页:<a class="ae kl" href="http://localhost:8088/cluster" rel="noopener ugc nofollow" target="_blank">http://localhost:8088/cluster</a></li></ul><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi ok"><img src="../Images/6b46e6f65d462c5e25dbc240c5dbedda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hWsXp0dgPs-Ce9vKWDHxwQ.png"/></div></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">图 24 —纱线网页</p></figure><h1 id="8103" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">8.参考</h1><ol class=""><li id="6367" class="km kn iq jp b jq ly ju lz jy om kc on kg oo kk og ks kt ku bi translated">Hadi Fadlallah，<a class="ae kl" rel="noopener" target="_blank" href="/installing-hadoop-3-1-0-multi-node-cluster-on-ubuntu-16-04-step-by-step-8d1954b31505">在 Ubuntu 16.04 上逐步安装 Hadoop 3.1.0 多节点集群</a>，TowardsDataScience.com</li><li id="623e" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk og ks kt ku bi translated"><a class="ae kl" href="https://www.joe0.com/about-me/" rel="noopener ugc nofollow" target="_blank"> Jozef Jarosciak </a>，<a class="ae kl" href="https://www.joe0.com/2017/02/02/how-to-install-a-hadoop-single-node-cluster-on-windows-10/" rel="noopener ugc nofollow" target="_blank">如何在 Windows 10 上安装 Hadoop 单节点集群</a></li><li id="8b7b" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk og ks kt ku bi translated">Raymond Tang，<a class="ae kl" href="https://kontext.tech/column/hadoop/377/latest-hadoop-321-installation-on-windows-10-step-by-step-guide" rel="noopener ugc nofollow" target="_blank">在 Windows 10 上安装 Hadoop 3.2.1 分步指南</a>，kontext.tech</li><li id="a678" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk og ks kt ku bi translated"><a class="ae kl" href="http://www.stackoverflow.com" rel="noopener ugc nofollow" target="_blank">栈溢出问答网站</a></li></ol></div></div>    
</body>
</html>