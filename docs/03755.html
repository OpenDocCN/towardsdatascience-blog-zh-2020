<html>
<head>
<title>Using Transformer-Based Language Models for Sentiment Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用基于转换器的语言模型进行情感分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-transformer-based-language-models-for-sentiment-analysis-dc3c10261eec?source=collection_archive---------14-----------------------#2020-04-08">https://towardsdatascience.com/using-transformer-based-language-models-for-sentiment-analysis-dc3c10261eec?source=collection_archive---------14-----------------------#2020-04-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/b289edf54dcdd32c86d25377606c57f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7lMC0I6rYfK31Gc__H5xsA.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">来源:<a class="ae jd" href="https://www.shutterstock.com/de/image-photo/kiev-ukraine-may-29-2019-new-1410410843" rel="noopener ugc nofollow" target="_blank"> shutterstock </a></p></figure><div class=""/><div class=""><h2 id="4037" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">如何轻松击败最先进的情感模型</h2></div><p id="d0e2" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">情感分析对许多企业来说是有用的，有助于评估客户对公司或特定产品的情绪。它的任务是根据文本的极性对文本进行分类，即识别作者对主题的感觉是积极的、消极的还是中性的。</p><p id="11d9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了能够大规模地自动进行情感分析，我们需要在带注释的数据集上训练模型。本文将展示如何通过使用开源框架<a class="ae jd" href="https://github.com/deepset-ai/FARM" rel="noopener ugc nofollow" target="_blank"> FARM </a>以快速简单的方式将最先进的transformer模型应用于情感分析，从而大幅超越当前的基准测试(提高约5个百分点)。</p><h1 id="2ae9" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">数据集</h1><p id="5d01" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">如前所述，我们需要带注释的数据来监督训练一个模型。为此，我使用了两个共享任务的数据集:<a class="ae jd" href="http://alt.qcri.org/semeval2017/" rel="noopener ugc nofollow" target="_blank"> SemEval 2017 </a>和<a class="ae jd" href="https://sites.google.com/view/germeval2017-absa/home" rel="noopener ugc nofollow" target="_blank"> Germeval 2017 </a>。<br/>seme val数据集由英语推文组成，而GermEval数据集包含来自不同社交媒体和网络来源的关于<em class="mo"> Deutsche Bahn </em>(德国铁路公司)的德语文本。两个数据集合的文本根据其极性(即正、负或中性)进行标记。</p><h1 id="aa39" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">用FARM微调变压器模型</h1><p id="1f80" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">当涉及不同的NLP任务时，如文本分类、命名实体识别和问答，像BERT这样的Transformer模型是当前最先进的。有多种不同的预训练模型。对于Germeval 2017数据集，使用了deepset的<a class="ae jd" href="https://deepset.ai/german-bert" rel="noopener ugc nofollow" target="_blank"> GermanBERT </a>，因为它在一系列任务中表现出了强大的性能。<br/>然而，对于SemEval-2017数据集，由于训练数据由英语文本组成，但结果模型的目的是评估德国客户对文本的情感，因此尝试了零镜头学习方法，因此需要多语言模型。为此，使用了XLM-罗伯塔-拉奇，它受过100种不同语言的训练。如果你想更多地了解XLM-罗伯塔，我强烈推荐这篇博客文章。</p><p id="7442" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由于预训练模型仅被训练来捕捉对语言的一般理解，而不是特定下游NLP任务的细微差别，所以我们需要使这些模型适应我们的特定目的。为了实现这一点，使用了用于调整表示模型(FARM) 的<a class="ae jd" href="https://github.com/deepset-ai/FARM" rel="noopener ugc nofollow" target="_blank">框架。FARM允许轻松调整变压器模型以适应不同的NLP任务。为了实现构建一个可靠的情感分类器的目标，我遵循了FARM的</a><a class="ae jd" href="https://github.com/deepset-ai/FARM/blob/master/examples/doc_classification.py" rel="noopener ugc nofollow" target="_blank"> doc_classification示例</a>。下面的代码片段展示了我如何通过几个步骤使GermanBERT适应情感分析的任务:</p><h2 id="992f" class="mp ls jg bd lt mq mr dn lx ms mt dp mb le mu mv md li mw mx mf lm my mz mh na bi translated">数据处理</h2><p id="f54e" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">为了能够加载训练实例，数据集需要在csv文件中，其中每一行都由训练示例及其标签组成。<code class="fe nb nc nd ne b">TextClassificationProcessor</code>加载并转换数据，以便建模组件可以使用它。为此，我们需要指定可能的标签集、包含训练集和测试集的数据目录，以及包含每个训练实例的标签的列的名称。这里，我们还必须指出我们的模型中使用的最大序列长度。<br/>转换后的数据随后被传递到<code class="fe nb nc nd ne b">DataSilo</code>。其目的是存储数据，并逐批提供给模型。因此，必须在这一步指定批量大小。</p><figure class="nf ng nh ni gt is"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h2 id="8991" class="mp ls jg bd lt mq mr dn lx ms mt dp mb le mu mv md li mw mx mf lm my mz mh na bi translated">建模</h2><p id="71d2" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">下一步是定义模型架构。首先，我们需要决定我们想要微调的语言模型。在这种情况下，我们使用<code class="fe nb nc nd ne b">bert-base-german-cased</code>。然后，我们必须为我们的特定任务选择正确的预测头。因为我们想使用离散值根据文本的情感对文本进行分类，所以我们需要选择一个<code class="fe nb nc nd ne b">TextClassificationHead</code>。最后一步是在语言模型上堆叠预测头，这是由<code class="fe nb nc nd ne b">AdaptiveModel</code>完成的。</p><figure class="nf ng nh ni gt is"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h2 id="0d77" class="mp ls jg bd lt mq mr dn lx ms mt dp mb le mu mv md li mw mx mf lm my mz mh na bi translated">培养</h2><p id="844e" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">既然已经加载了数据并且定义了模型架构，我们就可以开始训练模型了。首先，我们必须初始化一个优化器。在这里，我们设置学习率和我们想要训练模型的时期数。不仅初始化一个优化器，而且初始化一个学习率调度器。默认情况下，所有训练步骤的前10%是学习率的线性热身。<br/>最后，我们可以将所有组件输入到<code class="fe nb nc nd ne b">Trainer</code>，开始训练并保存生成的模型以备后用。在Germeval-17数据集上微调GermanBERT在Tesla V100 16GB GPU上耗时不到16分钟；根据SemEval-17的数据调整XLM-罗伯塔需要28分多一点的时间。</p><figure class="nf ng nh ni gt is"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h1 id="72cc" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">结果</h1><p id="e6ef" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">对于Germeval 2017共享任务，使用微观平均F1分数评估提交模型的性能。提供了两个不同的测试集:一个包含与训练数据集相同时期的tweet(同步测试集)，另一个测试集包含稍后时期的tweet(历时测试集)。<br/>最佳提交(Naderalvojoud et al. 2017)在共时测试集上取得了74.9%的微观平均F1分，在历时测试集上取得了73.6%的微观平均F1分。使用GermanBERT和FARM训练的模型比这些分数高出5%以上，在同步测试集上实现了80.1%的微观平均F1分数，在历时测试集上实现了80.2%的微观平均F1分数。</p><figure class="nf ng nh ni gt is"><div class="bz fp l di"><div class="nj nk l"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">Germeval-2017数据集的评估结果</p></figure><p id="b3e8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然而，对SemEval 2017共享任务的提交的性能是通过宏观平均召回来评估的。在那里，最佳提交(placend 2017，Baziotis等人2017)实现了68.1%的宏观平均召回率。同样，使用XLM-罗伯塔-大型和农场训练的模型比这些提交的模型高出5%以上，实现了73.6%的宏观平均召回率。</p><figure class="nf ng nh ni gt is"><div class="bz fp l di"><div class="nj nk l"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">SemEval-2017数据集的评估结果</p></figure><p id="5c18" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因为使用XLM-罗伯塔而不是单语模型的原因是将该模型应用于德国数据，所以也在Germeval-17测试集上评估了XLM-罗伯塔情感模型。这里，我们在同步测试集和历时测试集上分别获得了59.1%和57.5%的微观平均F1值。这一表现比分数分别为65.6%和67.2%的基本多数类基线差。出现这种情况的一个原因可能是两个数据集的类别分布差异很大。虽然Germeval数据集中的大多数实例被标记为<em class="mo">中性</em>，几乎没有包含正面情绪的案例，但SemEval数据集中的大多数类别是<em class="mo">正面</em>。<br/>另一个问题可能是两个数据集包含主题不同的文本。Germeval数据集就其主题而言非常有限，主要包含来自不同社交媒体和网络来源的关于德国铁路公司的文本。相反，SemEval数据集不受主题限制。</p><figure class="nf ng nh ni gt is"><div class="bz fp l di"><div class="nj nk l"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">Germeval-2017和SemEval-2017数据集的类别分布</p></figure><p id="476b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">所有上述结果都是使用以下超参数获得的:</p><figure class="nf ng nh ni gt is"><div class="bz fp l di"><div class="nj nk l"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">用于训练模型的超参数</p></figure><h1 id="e47b" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">结论</h1><p id="3a3e" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">这篇博客文章展示了我们如何使用transformer模型来训练我们自己的情感模型。我们看到，在框架农场的帮助下，可以轻松地对预训练模型进行微调，我们甚至能够击败不同共享任务的排行榜。如果你有兴趣亲自尝试一下GermanBERT情绪模型，你可以通过<a class="ae jd" href="https://huggingface.co/deepset/bert-base-german-cased-sentiment-Germeval17" rel="noopener ugc nofollow" target="_blank"> huggingface的模型中心</a>访问它。</p></div></div>    
</body>
</html>