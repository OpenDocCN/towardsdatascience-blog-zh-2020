<html>
<head>
<title>Star Wars Episode IV (1977) Remastered</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">星球大战第四集(1977年)重新制作</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/remastering-star-wars-using-deep-learning-b21713928a53?source=collection_archive---------38-----------------------#2020-06-19">https://towardsdatascience.com/remastering-star-wars-using-deep-learning-b21713928a53?source=collection_archive---------38-----------------------#2020-06-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="65b2" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">一个深度学习管道来重新制作被删除的场景</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/760f70f5563645ec550206b71ce0d780.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nI8Sd-4HVh5aHOXZa-wpeQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由<a class="ae kv" href="https://unsplash.com/@koalamoose" rel="noopener ugc nofollow" target="_blank">阿格尼耶斯卡·科瓦尔茨克</a>在<a class="ae kv" href="https://unsplash.com/photos/c0VRNWVEjOA" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="efe0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> TLDR </strong></p><p id="921e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是模型的输出。左边是重制输出。右为原创视频。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div></figure><p id="8b3d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">用于训练和跑步推理的完整Jupyter笔记本可在<a class="ae kv" href="https://github.com/spiyer99/spiyer99.github.io/blob/master/nbs/star_wars_remastery.ipynb" rel="noopener ugc nofollow" target="_blank"> Github </a>上获得</p><p id="4495" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">被删除场景的新希望</strong></p><p id="8865" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我是《星球大战》的超级粉丝。和许多星战迷一样，我也迷上了卡通频道和迪士尼+的《星球大战:克隆人战争》。这是一场非凡的演出。</p><p id="f7a7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是当我看旧的东西时，我总是对视频质量的下降感到恼火。例如，这里是从《星球大战:第四集:新的希望》(1977)中删除的场景。这是第一部被创作出来的星球大战。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">视频由<a class="ae kv" href="https://www.youtube.com/channel/UCSrRYklbl6GDioKfoQsjfeQ" rel="noopener ugc nofollow" target="_blank">马塞洛·祖尼加</a></p></figure><p id="5efc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些奇怪的黑色眼镜不断出现。难怪这些是被删除的场景。</p><p id="d41c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">显然那些奇怪的规格被称为<a class="ae kv" href="https://en.wikipedia.org/wiki/Cue_mark" rel="noopener ugc nofollow" target="_blank">提示符号</a>。它们是胶片上划痕留下的痕迹。《星球大战》是一部很棒的剧集，但它也很古老。</p><p id="c6e4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">深度学习最近被用于视频恢复。结果非常有希望。例如，Deoldify 允许用户给旧视频和图像着色。<a class="ae kv" href="https://www.youtube.com/watch?v=P0fMwA3X5KI" rel="noopener ugc nofollow" target="_blank"> NVIDIA的Noise2Noise model </a>可以让人们将旧图像恢复到曾经的辉煌。</p><p id="724d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但到目前为止，据我所知，还没有什么东西能专门去除旧胶片上的“记号”和粒状斑点。所以让我们来建造它吧！</p><h1 id="eb43" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">创建数据集</h1><p id="56bb" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf mp lh li lj mq ll lm ln mr lp lq lr ij bi translated">创建数据集很棘手，但仍然可行。我是这么做的。我从youtube上下载了高质量的视频。然后我毁了他们。我添加了黑色眼镜，降低了视频的分辨率。Ffmpeg在这方面非常有用。</p><p id="4bae" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，我们将下载视频。</p><pre class="kg kh ki kj gt ms mt mu mv aw mw bi"><span id="7d2d" class="mx lw iq mt b gy my mz l na nb">youtube-dl --format best -o seinfeld.mp4 <a class="ae kv" href="https://www.youtube.com/watch?v=nEAO60ON7yo" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=nEAO60ON7yo</a></span></pre><p id="b42b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我在用这个视频。我用的是《T2》中宋飞的一个片段。为什么不呢？</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">视频由<a class="ae kv" href="https://www.youtube.com/channel/UCFg3kyRzqAGpeEedLMPDZlA" rel="noopener ugc nofollow" target="_blank">系列制作</a></p></figure><p id="1f98" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">那我们就要毁了它。为了做到这一点，我从youtube上下载了一个颗粒状的电影叠加。然后我用ffmpeg叠加视频，混合设置为柔光。找到正确的混合设置需要大量的试验和错误。ffmpeg <a class="ae kv" href="https://ffmpeg.org/documentation.html" rel="noopener ugc nofollow" target="_blank">文档</a>没有很多例子。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc lt l"/></div></figure><p id="e64f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们有两个视频。一个质量很好，另一个质量很差。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者提供的视频</p></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者提供的视频</p></figure><p id="8b29" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们将从每个视频中提取帧。最初，我采用了一种天真的方法来做这件事。我会在python中浏览视频并单独抓取每一帧。但这花了太长时间。我最终意识到，我们可以在这里使用多处理来真正加快速度。这是根据海登·福尔克的剧本改编的。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc lt l"/></div></figure><p id="fd41" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">太好了。现在我们有两个数据集。一个劣质图像(取自受损视频)和一个优质图像(取自高质量视频)。为了让这些垃圾图片更垃圾，我会缩小它们(虽然这不是必要的步骤)。</p><pre class="kg kh ki kj gt ms mt mu mv aw mw bi"><span id="6113" class="mx lw iq mt b gy my mz l na nb">def resize_one(img, size):</span><span id="c234" class="mx lw iq mt b gy nd mz l na nb">   targ_sz = resize_to(img, size, use_min = True)<br/>   img = img.resize(targ_sz, resample =  PIL.Image.BILINEAR).convert('RGB')<br/>   return img</span></pre><p id="2e27" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这就是现在蹩脚的正常图像的样子。旁注:这是《宋飞正传》中一个很棒的场景。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/e9c7487ac26a1f9e0b991703f6d1bde8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/0*fYq2ApvCdd65ItPd.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/b3e0382993a6d1943564fdc6da78f5ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/0*KIwkIykgYKvMgvhZ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="46ba" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">快速检查显示，我们有大约<code class="fe nf ng nh mt b">10014</code>个文件的数据集。非常好。</p><h1 id="8905" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">神经网络</h1><p id="90d9" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf mp lh li lj mq ll lm ln mr lp lq lr ij bi translated">让我们通过使用转换来充分利用这些<code class="fe nf ng nh mt b">10014</code>文件。</p><p id="8e78" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我添加了水平和垂直翻转，缩放变化，灯光变化和旋转变化。使用Fastai，这真的很容易做到。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc lt l"/></div></figure><p id="803c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以下是一些图像转换。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/3b8cf62eb4ab77f5ef685c35755c78e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/0*OFvtOyHG0r8VDuYT.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="cdf0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">还不错！</p><p id="ae48" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将在这些数据上使用fastai和jason antic首创的<a class="ae kv" href="https://www.fast.ai/2019/05/03/decrappify/" rel="noopener ugc nofollow" target="_blank"> NoGAN网络</a>。这个代码的灵感来自fastai课程的第7课。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc lt l"/></div></figure><p id="2e6e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我在google colab的免费GPU上训练了这个模型。他们是一个伟大的资源，我不能相信他们是免费的。</p><h1 id="6f96" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">培养</h1><p id="5ea0" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf mp lh li lj mq ll lm ln mr lp lq lr ij bi translated">fastai <a class="ae kv" href="https://www.youtube.com/watch?v=9spwoDYwW_I" rel="noopener ugc nofollow" target="_blank">推荐</a>的有趣的事情是逐渐增加你的图片的尺寸。</p><p id="5333" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，首先，你在小尺寸图像上训练，然后你升级你的图像，在大图像上再训练。这会节省你很多时间。相当聪明。</p><p id="81b9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，我们将在大小为128x128的图像上进行训练。因为图像太小了，我可以把批量增加到64张。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc lt l"/></div></figure><p id="6ab9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我为此选择了一个<code class="fe nf ng nh mt b">1e-2</code>的学习率。我想要一些有攻击性的东西，但仍然是安全的爆炸。这已经被<a class="ae kv" href="https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html" rel="noopener ugc nofollow" target="_blank">证明</a>非常有用。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc lt l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nj"><img src="../Images/21f6175e820c854c7c5e27bdec58b974.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PBtoBj9cgm_-cRSM.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="4355" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">网络将在训练期间打印结果。输入在左边，预测在中间，目标在右边。结果看起来很有希望！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/bb91d8c97ff9549db56fbd8822f16039.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*wbEQJ3I8cyp9TYM9.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="d08b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我调整了尺寸，再次训练。再一次。每次我把尺寸调整得比以前稍微大一点。我将视频帧的尺寸从128x128改为480x480。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc lt l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/56d7a3036ecda80659c8401cd3029ec2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gJTRIkkHuiPmw6Oe.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="a9f9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是最后一班火车。为此我使用了<code class="fe nf ng nh mt b">pct_start = 0.3</code>。我想在培训期间减少70%的学习时间。在微调模型时，我更喜欢较低的学习率。这次训练的结果看起来非常好。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nm"><img src="../Images/566e0969f4af28e04fc5e5dea2469d41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*aDytged6tGX0kUDn.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h1 id="21b5" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">推论:适用于星球大战</h1><p id="d91a" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf mp lh li lj mq ll lm ln mr lp lq lr ij bi translated">一旦这个网络训练完毕，我就进行推理。这比我原先想的要复杂得多。</p><p id="3813" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我必须下载星球大战删除的场景(使用<a class="ae kv" href="https://github.com/ytdl-org/youtube-dl" rel="noopener ugc nofollow" target="_blank"> youtube-dl </a>)，然后提取这个视频中的所有帧。我提取帧使用相同的方法之前。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/758d2d91cfeae3343aa24d0bbaf0d7f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/0*3fazAhXbwYPeVWGq.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="fceb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后我不得不在视频的每一个单独的帧上运行来自学习者的推断。那需要很长时间。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc lt l"/></div></figure><p id="d2f5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我在这里添加了一些黑客。</p><p id="86c6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，我添加了渲染因子。这是从<a class="ae kv" href="https://github.com/jantic/DeOldify" rel="noopener ugc nofollow" target="_blank">解密</a>中截取的。这个想法是，我缩小图像，并将其转换为一个正方形。然后我对那张图片进行推理。该模型更容易接受正方形的图像。这已经被<a class="ae kv" href="https://github.com/jantic/DeOldify#stuff-that-should-probably-be-in-a-paper" rel="noopener ugc nofollow" target="_blank">显示为</a>大大减少了“故障”。</p><p id="c426" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在正方形图像上运行推理后，我将它转换回原始形状。我发现这可以减少故障，通常会导致更平滑的视频输出。我将<code class="fe nf ng nh mt b">render_factor</code>设置为<code class="fe nf ng nh mt b">40</code>，虽然如果我们想要更高的分辨率输出，它可以更高。不过，我可能需要更大的内存。</p><p id="05cf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第二，我调节亮度。这不是真正的黑客。似乎更像是一个错误，我是正确的手动。出于某种原因，模型推断导致图像亮度非常低。</p><p id="02ef" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我怀疑这与我们之前用于ffmpeg的<code class="fe nf ng nh mt b">softlight</code>过滤器有关。但是我必须在这里手动更正。我需要进一步调查此事。</p><p id="cbdb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第三，我使用matplotlib的保存功能。我发现fastai的<a class="ae kv" href="https://docs.fast.ai/vision.image.html#Image.save" rel="noopener ugc nofollow" target="_blank">保存图像</a>功能给了我非常奇怪的结果(Luke的衣服是荧光蓝色和红色)。但是奇怪的是，matplotlib的保存功能给了我很好的结果。我需要调查这件事。我怀疑我可能会损失图像的质量，因为我正在使用matplotlib的<code class="fe nf ng nh mt b">savefig</code>功能。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc lt l"/></div></figure><p id="670f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是模型的一些输出。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/a3f807ed81686059860c81b0fe6f1a9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/0*GMI6YGn7qJBTMTHA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者提供的图片</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/bde95fbd789d2c1cbf23069f40f167af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/0*gZYY4VnxUM-StEgB.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/7b443f33969b183ddfba4d46d21c981f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/0*ciOw5qZZL8G8B0lG.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="4f37" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后我不得不把所有这些画面拼接在一起，制作一个视频。为了做到这一点，我最初使用ffmpeg，但我结束了我的RAM超载。相反，我用了opencv2的<code class="fe nf ng nh mt b">VideoWriter</code>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc lt l"/></div></figure><p id="0d3a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是最终的输出。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者提供的视频</p></figure><p id="a322" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">和原始视频</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">视频由<a class="ae kv" href="https://www.youtube.com/channel/UCSrRYklbl6GDioKfoQsjfeQ" rel="noopener ugc nofollow" target="_blank">马塞洛·祖尼加</a></p></figure><h1 id="422f" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">丰富</h1><ol class=""><li id="7b42" class="nn no iq ky b kz mn lc mo lf np lj nq ln nr lr ns nt nu nv bi translated">天空需要更多的工作。但是我喜欢背景的活力。这是一个有趣的(完全没有计划的)效果。目标是从视频中删除“提示标记”(恼人的黑色规格)。我认为在这方面已经做得很好了——但是还有更多的事情要做。<br/>我喜欢网络是如何强化了阳光的。当比格斯说他要加入反抗军时，卢克和比格斯之间的场景完全改变了。</li></ol><div class="kg kh ki kj gt ab cb"><figure class="nw kk nx ny nz oa ob paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/6c3255ac86ee7cd37f82761764882c51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*yTpeIJWou2E_1_qh.png"/></div></figure><figure class="nw kk nx ny nz oa ob paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/66f9c96e97fe318a5b2c169c965c2f28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/0*q5Kxj3ljFU8t0wB9.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk oc di od oe translated">原始帧(左)。网络输出(右侧)</p></figure></div><p id="c82d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">2.在<code class="fe nf ng nh mt b">22</code>秒标记周围出现了一条奇怪的横条线。我没有在训练集中添加任何水平条，所以完全可以理解网络根本没有删除它。但是在未来，我需要在我的训练集中增加更多的单杠来解决这些问题。</p><p id="502a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">3.我也在考虑对视频做更多的超分辨率处理。高质量地展示一个年轻的卢克·天行者会很不错。为了做到这一点，我可以在进一步训练之前调整图像的大小。我已经缩小了图像，但我还可以进一步缩小。<br/>或者，为了实现superres，我可能会使用现成的升级工具，比如<a class="ae kv" href="https://github.com/AlphaAtlas/VapourSynth-Super-Resolution-Helper" rel="noopener ugc nofollow" target="_blank"> VapourSynth </a>。这可能是最好的选择，因为原始视频的质量已经很差。</p><p id="4bf1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">4.推论也是一个问题。它会导致内存过载和崩溃。结果是，<code class="fe nf ng nh mt b">42</code>秒是我在这个视频中能得到的最长时间。我不完全确定如何解决这个问题。但是如果我要进一步使用它，我需要解决它。</p><p id="3249" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这么多事要做！</p><p id="1590" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">完整代码可从<a class="ae kv" href="https://github.com/spiyer99/spiyer99.github.io/blob/master/nbs/star_wars_remastery.ipynb" rel="noopener ugc nofollow" target="_blank"> Github </a>获得</p></div><div class="ab cl of og hu oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="ij ik il im in"><p id="1d1a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="lu">原载于2020年6月19日</em><a class="ae kv" href="https://spiyer99.github.io/Star-Wars-Remastery/" rel="noopener ugc nofollow" target="_blank"><em class="lu">https://spiyer 99 . github . io</em></a><em class="lu">。</em></p></div></div>    
</body>
</html>