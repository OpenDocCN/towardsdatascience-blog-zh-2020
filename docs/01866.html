<html>
<head>
<title>Practical Spark Tips for Data Scientists</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据科学家的实用火花技巧</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/practical-spark-tips-for-data-scientists-145d85e9b2d8?source=collection_archive---------13-----------------------#2020-02-21">https://towardsdatascience.com/practical-spark-tips-for-data-scientists-145d85e9b2d8?source=collection_archive---------13-----------------------#2020-02-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/9bcf72e7835f7b4d71c63cb03eeb9f28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HLSjxt9F7Es-sfvQm6PWnw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图片由<a class="ae jg" href="https://pixabay.com/users/aitoff-388338/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1984421" rel="noopener ugc nofollow" target="_blank">安德鲁·马丁</a>来自<a class="ae jg" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1984421" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><div class=""/><div class=""><h2 id="2e56" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">与pySpark一起工作时，让您的生活更加舒适</h2></div><p id="1c40" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我知道——Spark有时令人沮丧。T9】</p><p id="ac00" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk"> <em class="lu">虽然有时候我们可以使用</em></strong><a class="ae jg" rel="noopener" target="_blank" href="/minimal-pandas-subset-for-data-scientist-on-gpu-d9a6c7759c7f?source=---------5------------------"><strong class="la jk"><em class="lu">Rapids</em></strong></a><strong class="la jk"><em class="lu">或</em> </strong> <a class="ae jg" rel="noopener" target="_blank" href="/add-this-single-word-to-make-your-pandas-apply-faster-90ee2fffe9e8?source=---------11------------------"> <strong class="la jk"> <em class="lu">并行化</em></strong></a><strong class="la jk"><em class="lu"/></strong>等工具来管理我们的大数据，但是如果您正在处理数TB的数据，就无法避免使用<strong class="la jk"> <em class="lu"> </em> </strong> Spark。</p><p id="ffd5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在我关于Spark的最后几篇文章中，我解释了如何使用PySpark RDDs和T42数据帧。尽管这些帖子解释了很多关于如何使用rdd和Dataframe操作的内容，但它们仍然不够。</p><p id="295b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为什么？因为spark经常出现内存错误，而且只有当您真正使用Spark处理大数据集时，您才能真正使用Spark。</p><p id="4f0a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">这篇文章的主题是“数据科学家实用的火花和内存管理技巧”</strong></p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="d34d" class="mc md jj bd me mf mg mh mi mj mk ml mm kp mn kq mo ks mp kt mq kv mr kw ms mt bi translated">1.地图端连接</h1><figure class="mv mw mx my gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mu"><img src="../Images/ba7d9015b8e349b56479e1b43a934a9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WMTktzXaRCERwuCm.jpg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">连接数据框架</p></figure><p id="e3b0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Spark中的连接语法与pandas非常相似:</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="43b1" class="ne md jj na b gy nf ng l nh ni">df3 = df1.join(df2, df1.column == df2.column,how='left')</span></pre><p id="23da" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是我面临一个问题。<code class="fe nj nk nl na b">df1</code>大约有10亿行，而<code class="fe nj nk nl na b">df2</code>大约有100行。当我尝试上述连接时，它不起作用，并在运行20分钟后出现内存耗尽错误。</p><p id="d5b4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我在一个非常大的集群上编写这段代码，这个集群有400多个执行器，每个执行器都有4GB以上的RAM。当我尝试使用多种方案对数据帧进行重新分区时，我被难住了，但似乎没有任何效果。</p><p id="b20c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">那我该怎么办呢？Spark不能处理仅仅十亿行吗？不完全是。我只需要使用Spark术语中的地图端连接或广播。</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="8c09" class="ne md jj na b gy nf ng l nh ni"><strong class="na jk">from</strong> <strong class="na jk">pyspark.sql.functions</strong> <strong class="na jk">import</strong> broadcast<br/>df3 = df1.join(broadcast(df2), df1.column == df2.column,how='left')</span></pre><p id="fcc2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用上面简单的广播代码，我能够将较小的<code class="fe nj nk nl na b">df2</code>发送到所有节点，这并没有花费很多时间或内存。后端发生的事情是将<code class="fe nj nk nl na b">df2</code>的副本发送到所有分区，每个分区使用该副本进行连接。这意味着df1没有数据移动，它比df2大很多。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="8b0a" class="mc md jj bd me mf mg mh mi mj mk ml mm kp mn kq mo ks mp kt mq kv mr kw ms mt bi translated">2.火花簇构型</h1><figure class="mv mw mx my gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mu"><img src="../Images/27ac86d90e518426adac14008fa85b98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8KzrShBltUeZfaIQ.jpg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">根据您的任务大小设置并行度和工作节点</p></figure><p id="e49a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当我开始使用Spark时，让我的生活变得困难的还有Spark集群需要配置的方式。基于您想要运行的作业，您的spark集群可能需要大量定制配置和调优。</p><p id="f79f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一些最重要的配置和选项如下:</p><h2 id="b43d" class="ne md jj bd me nm nn dn mi no np dp mm lh nq nr mo ll ns nt mq lp nu nv ms nw bi translated">a.spark.sql.shuffle.partitions和spark.default.parallelism:</h2><p id="f8ba" class="pw-post-body-paragraph ky kz jj la b lb nx kk ld le ny kn lg lh nz lj lk ll oa ln lo lp ob lr ls lt im bi translated"><code class="fe nj nk nl na b">spark.sql.shuffle.partitions</code>配置为连接或聚合而重排数据时要使用的分区数量。<code class="fe nj nk nl na b">spark.default.parallelism</code>是rdd中由<code class="fe nj nk nl na b">join</code>、<code class="fe nj nk nl na b">reduceByKey</code>和<code class="fe nj nk nl na b">parallelize</code>等转换返回的默认分区数量，当用户没有设置时。这些值的默认值是200。</p><p id="56b2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk"> <em class="lu">简而言之，这些设置了您想要在集群中拥有的并行度。</em>T11】</strong></p><p id="4987" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果您没有很多数据，值200没问题，但是如果您有大量数据，您可能希望增加这些数字。也要看你有多少遗嘱执行人。我的集群相当大，有400个执行者，所以我把它保持在1200。一个经验法则是保持它是执行人数量的倍数，这样每个执行人最终都有多个工作。</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="28af" class="ne md jj na b gy nf ng l nh ni">sqlContext.setConf( "spark.sql.shuffle.partitions", 800)<br/>sqlContext.setConf( "spark.default.parallelism", 800)</span></pre><h2 id="e1ba" class="ne md jj bd me nm nn dn mi no np dp mm lh nq nr mo ll ns nt mq lp nu nv ms nw bi translated">b.spark . SQL . parquet . binaryasstring</h2><p id="8987" class="pw-post-body-paragraph ky kz jj la b lb nx kk ld le ny kn lg lh nz lj lk ll oa ln lo lp ob lr ls lt im bi translated">我在Spark中处理<code class="fe nj nk nl na b">.parquet</code>文件，我的大部分数据列都是字符串。但不知何故，每当我在Spark中加载数据时，字符串列都会被转换成二进制格式，在这种格式下，我无法使用任何字符串操作函数。我解决这个问题的方法是使用:</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="f3fa" class="ne md jj na b gy nf ng l nh ni">sqlContext.setConf("spark.sql.parquet.binaryAsString","true")</span></pre><p id="07f7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">上述配置在加载拼花文件时将二进制格式转换为字符串。现在这是我在使用Spark时设置的默认配置。</p><h2 id="62db" class="ne md jj bd me nm nn dn mi no np dp mm lh nq nr mo ll ns nt mq lp nu nv ms nw bi translated">c.纱线配置:</h2><p id="3967" class="pw-post-body-paragraph ky kz jj la b lb nx kk ld le ny kn lg lh nz lj lk ll oa ln lo lp ob lr ls lt im bi translated">您可能需要调整其他配置来定义您的集群。但是这些需要在集群启动时设置，不像上面的那些那样动态。我想放在这里的几个是用于管理executor节点上的内存溢出。有时，执行程序核心会承担大量工作。</p><ul class=""><li id="5045" class="oc od jj la b lb lc le lf lh oe ll of lp og lt oh oi oj ok bi translated">spark . yarn . executor . memory overhead:8192</li><li id="311c" class="oc od jj la b lb ol le om lh on ll oo lp op lt oh oi oj ok bi translated">yarn . node manager . vmem-check-enabled:False</li></ul><p id="0777" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在设置spark集群时，您可能需要调整很多配置。你可以在<a class="ae jg" href="https://spark.apache.org/docs/latest/configuration.html" rel="noopener ugc nofollow" target="_blank">官方文件</a>里看看。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="5bef" class="mc md jj bd me mf mg mh mi mj mk ml mm kp mn kq mo ks mp kt mq kv mr kw ms mt bi translated">3.分配</h1><figure class="mv mw mx my gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mu"><img src="../Images/43cf4c75b56870192f6f891488d5a599.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Mj8fP1YmhfJ-usrF.jpg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">让员工处理等量的数据，让他们满意</p></figure><p id="dd39" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果在处理所有转换和连接时，您觉得数据有偏差，您可能需要对数据进行重新分区。最简单的方法是使用:</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="56a2" class="ne md jj na b gy nf ng l nh ni">df = df.repartition(1000)</span></pre><p id="ef13" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">有时，您可能还希望按照已知的方案进行重新分区，因为该方案可能会在以后被某个连接或聚集操作使用。您可以使用多个列通过以下方式进行重新分区:</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="69bc" class="ne md jj na b gy nf ng l nh ni"><em class="lu">df = df.repartition('cola', 'colb','colc','cold')</em></span></pre><p id="b13d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您可以使用以下公式获得数据框中的分区数量:</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="2705" class="ne md jj na b gy nf ng l nh ni">df.rdd.getNumPartitions()</span></pre><p id="9ad0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您还可以通过使用<code class="fe nj nk nl na b">glom</code>函数来检查分区中记录的分布。这有助于理解在处理各种转换时发生的数据偏差。</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="a135" class="ne md jj na b gy nf ng l nh ni"><em class="lu">df.glom().map(len).collect()</em></span></pre></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="e41f" class="mc md jj bd me mf mg mh mi mj mk ml mm kp mn kq mo ks mp kt mq kv mr kw ms mt bi translated">结论</h1><p id="e0d2" class="pw-post-body-paragraph ky kz jj la b lb nx kk ld le ny kn lg lh nz lj lk ll oa ln lo lp ob lr ls lt im bi translated">有很多事情我们不知道，我们不知道。这些被称为未知的未知。只有通过多次代码失败和读取多个堆栈溢出线程，我们才明白我们需要什么。</p><p id="f808" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这里，我尝试总结了一些我在使用Spark时遇到的内存问题和配置问题，以及如何解决这些问题。Spark中还有很多其他的配置选项，我没有介绍，但是我希望这篇文章能让你对如何设置和使用它们有所了解。</p><p id="e19a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，如果你需要学习Spark基础知识，看看我以前的帖子:</p><div class="is it gp gr iu oq"><a rel="noopener follow" target="_blank" href="/the-hitchhikers-guide-to-handle-big-data-using-spark-90b9be0fe89a"><div class="or ab fo"><div class="os ab ot cl cj ou"><h2 class="bd jk gy z fp ov fr fs ow fu fw ji bi translated">使用Spark处理大数据的指南</h2><div class="ox l"><h3 class="bd b gy z fp ov fr fs ow fu fw dk translated">不仅仅是介绍</h3></div><div class="oy l"><p class="bd b dl z fp ov fr fs ow fu fw dk translated">towardsdatascience.com</p></div></div><div class="oz l"><div class="pa l pb pc pd oz pe ja oq"/></div></div></a></div><p id="a58d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">还有，如果你想了解更多关于Spark和Spark DataFrames的知识，我想调出这些关于<a class="ae jg" href="https://coursera.pxf.io/4exq73" rel="noopener ugc nofollow" target="_blank"> <strong class="la jk">大数据精要的优秀课程:Coursera上的HDFS、MapReduce和Spark RDD </strong> </a>。</p><p id="2dc8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">谢谢你的阅读。将来我也会写更多初学者友好的帖子。在<a class="ae jg" href="https://medium.com/@rahul_agarwal?source=post_page---------------------------" rel="noopener"> <strong class="la jk">中</strong> </a>关注我或者订阅我的<a class="ae jg" href="http://eepurl.com/dbQnuX?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"> <strong class="la jk">博客</strong> </a>了解他们。一如既往，我欢迎反馈和建设性的批评，可以通过Twitter<a class="ae jg" href="https://twitter.com/MLWhiz?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"><strong class="la jk">@ mlwhiz</strong></a>联系</p><p id="3f61" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">此外，一个小小的免责声明——这篇文章中可能会有一些相关资源的附属链接，因为分享知识从来都不是一个坏主意。</p></div></div>    
</body>
</html>