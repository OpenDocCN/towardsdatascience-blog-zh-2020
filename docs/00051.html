<html>
<head>
<title>Keras and R: Predicting Blood Glucose Levels with the Sequential Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Keras和R:用序列模型预测血糖水平</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/keras-and-r-predicting-blood-glucose-levels-with-the-sequential-model-596efe89a6b8?source=collection_archive---------22-----------------------#2020-01-02">https://towardsdatascience.com/keras-and-r-predicting-blood-glucose-levels-with-the-sequential-model-596efe89a6b8?source=collection_archive---------22-----------------------#2020-01-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c8c2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">这个例子说明了如何使用Keras和R来实现基于回归的神经网络。</h2></div><p id="14fa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">随着TensorFlow 2.0的出现，<em class="le"> Keras </em>现在是这个版本的默认API。Keras用于构建深度学习目的的神经网络。因此，Keras是对大型数据集进行分析的非常有用的工具。</p><p id="2e18" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，你知道Keras API也可以在R中运行吗？</p><p id="7351" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这个例子中，<em class="le"> Keras </em>用于生成一个神经网络，目的是解决r中的一个回归问题</p><p id="84a0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">具体来说，<a class="ae lf" href="https://www.kaggle.com/uciml/pima-indians-diabetes-database" rel="noopener ugc nofollow" target="_blank">皮马印第安人糖尿病数据集</a>用于使用相关特征预测患者的血糖水平。</p><p id="d172" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这方面，本文概述了:</p><ul class=""><li id="2f8d" class="lg lh it kk b kl km ko kp kr li kv lj kz lk ld ll lm ln lo bi translated">R中的特征选择方法</li><li id="f417" class="lg lh it kk b kl lp ko lq kr lr kv ls kz lt ld ll lm ln lo bi translated">如何在Keras中定义顺序模型</li><li id="0dbb" class="lg lh it kk b kl lp ko lq kr lr kv ls kz lt ld ll lm ln lo bi translated">验证和测试模型预测的方法</li></ul><h1 id="ed6e" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">数据集</h1><p id="3544" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">在这个例子中，Pima Indians糖尿病数据集被分成三个独立的数据集。</p><p id="5ec1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">训练和验证:</strong> <em class="le">皮马-印度人-diabetes1.csv </em>。原始数据集的80%是从完整数据集分割出来的。反过来，该数据集的70%用于训练模型，剩余的30%用于验证预测。</p><p id="d7e5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">测试:</strong> <em class="le">皮马-印第安人-糖尿病2.csv </em>和<em class="le">皮马-印第安人-糖尿病3.csv </em>。原始数据集的剩余20%用作看不见的数据，以确定模型生成的预测在处理全新数据时是否表现良好。<em class="le"> pima-indians-diabetes2 </em>包含特征(或自变量)，而<em class="le"> pima-indians-diabetes3 </em>包含因变量(血糖水平)。</p><h1 id="a32e" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">特征选择</h1><p id="64e9" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">特征选择的目的是确定那些对因变量影响最大的特征。</p><p id="9ece" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在我们的例子中，有八个特征，其中一些在确定血糖水平时比其他的更重要。</p><p id="b46d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里使用的两种特征选择方法是:</p><ul class=""><li id="92fb" class="lg lh it kk b kl km ko kp kr li kv lj kz lk ld ll lm ln lo bi translated">相关图</li><li id="90a6" class="lg lh it kk b kl lp ko lq kr lr kv ls kz lt ld ll lm ln lo bi translated">多元线性回归</li></ul><h1 id="c6f7" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">相关图</h1><p id="a16b" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">相关图使我们能够直观地确定:</p><ol class=""><li id="2f87" class="lg lh it kk b kl km ko kp kr li kv lj kz lk ld mr lm ln lo bi translated">与因变量高度相关的特征</li><li id="2aec" class="lg lh it kk b kl lp ko lq kr lr kv ls kz lt ld mr lm ln lo bi translated">彼此高度相关的特征</li></ol><p id="483e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果某些特征与血糖水平高度相关，那么这表明这些特征在预测血糖水平方面是重要的。具有低相关性的特征被指示为不重要。</p><p id="25fa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，彼此高度相关的特征将表明这些特征中的一些是多余的(因为它们实际上试图解释相同的事情)。</p><p id="d461" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是第一个相关图:</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="288b" class="nb lv it mx b gy nc nd l ne nf">M &lt;- cor(diabetes1)<br/>corrplot(M, method = "circle")</span></pre><figure class="ms mt mu mv gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi ng"><img src="../Images/c89f8f54950d1023d2572625da72cc2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Ft-BWlYlWWPupvnT.png"/></div></div></figure><p id="456d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以看到<strong class="kk iu">胰岛素</strong>和<strong class="kk iu">结果</strong>变量与<strong class="kk iu">葡萄糖</strong>变量特别相关，而<strong class="kk iu">年龄</strong>和<strong class="kk iu">怀孕</strong>和<strong class="kk iu">胰岛素</strong>和<strong class="kk iu">皮肤厚度</strong>之间也有相关性。</p><p id="92c5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但是，我们可以更详细地了解并获得每个特征的特定相关系数:</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="1a58" class="nb lv it mx b gy nc nd l ne nf">corrplot(M, method = "number")</span></pre><figure class="ms mt mu mv gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi ng"><img src="../Images/50c881c1d6e9613e5612bf141657b87e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*197MYZb_Ty8jr80r.png"/></div></div></figure><h1 id="2752" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">多元线性回归</h1><p id="f15a" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">多元线性回归的目的是:</p><ol class=""><li id="92ee" class="lg lh it kk b kl km ko kp kr li kv lj kz lk ld mr lm ln lo bi translated">在解释因变量时，确定每个特征的系数的大小和性质。</li><li id="ec6d" class="lg lh it kk b kl lp ko lq kr lr kv ls kz lt ld mr lm ln lo bi translated">确定每个特征的重要性或不重要性。</li></ol><p id="3dc9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是线性回归的结果:</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="2b3f" class="nb lv it mx b gy nc nd l ne nf">Call:<br/>lm(formula = Glucose ~ Pregnancies + Outcome + Age + DiabetesPedigreeFunction + <br/>    BMI + Insulin + SkinThickness + BloodPressure, data = diabetes1)</span><span id="bdbc" class="nb lv it mx b gy no nd l ne nf">Residuals:<br/>    Min      1Q  Median      3Q     Max <br/>-68.709 -18.148  -2.212  15.176  80.950 </span><span id="4c01" class="nb lv it mx b gy no nd l ne nf">Coefficients:<br/>                          Estimate Std. Error t value Pr(&gt;|t|)    <br/>(Intercept)              78.401064   6.363612  12.320  &lt; 2e-16 ***<br/>Pregnancies              -0.481865   0.363730  -1.325  0.18575    <br/>Outcome                  25.590805   2.384153  10.734  &lt; 2e-16 ***<br/>Age                       0.527262   0.106097   4.970  8.8e-07 ***<br/>DiabetesPedigreeFunction  0.052534   3.198192   0.016  0.98690    <br/>BMI                       0.318452   0.167106   1.906  0.05718 .  <br/>Insulin                   0.082208   0.009843   8.352  4.8e-16 ***<br/>SkinThickness            -0.202236   0.077372  -2.614  0.00918 ** <br/>BloodPressure             0.083865   0.058081   1.444  0.14929    <br/>---<br/>Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span><span id="ff1c" class="nb lv it mx b gy no nd l ne nf">Residual standard error: 24.94 on 590 degrees of freedom<br/>Multiple R-squared:  0.362,	Adjusted R-squared:  0.3533 <br/>F-statistic: 41.84 on 8 and 590 DF,  p-value: &lt; 2.2e-16</span></pre><p id="6084" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在5%的水平上，<strong class="kk iu">结果</strong>、<strong class="kk iu">年龄</strong>、<strong class="kk iu">胰岛素</strong>和<strong class="kk iu">皮肤厚度</strong>被认为是显著的。其他特征在5%的水平上被认为是不重要的。</p><h1 id="285f" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">使用Breusch-Pagan进行异方差检验</h1><p id="8748" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">在这种情况下，没有必要对多重共线性进行正式测试，因为相关图显示了彼此高度相关的要素。</p><p id="0820" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，可能存在异方差(跨标准误差的不均匀方差)，例如，由于患者的年龄不同。为了检验这一点，进行了Breusch-Pagan检验——p值低于0.05表示存在异方差。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="a426" class="nb lv it mx b gy nc nd l ne nf">&gt; bptest(fit)</span><span id="63e3" class="nb lv it mx b gy no nd l ne nf">	studentized Breusch-Pagan test</span><span id="5d55" class="nb lv it mx b gy no nd l ne nf">data:  fit<br/>BP = 36.585, df = 8, p-value = 1.372e-05</span></pre><p id="2f3b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于表明存在异方差，所以运行稳健的回归——特别是使用Huber权重。这样做的目的是降低数据集中异常值的价值。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="561c" class="nb lv it mx b gy nc nd l ne nf">&gt; # Huber Weights (Robust Regression)<br/>&gt; summary(rr.huber &lt;- rlm(Glucose ~ Pregnancies + Outcome + Age + DiabetesPedigreeFunction + BMI + Insulin + SkinThickness + BloodPressure, data=diabetes1))</span><span id="ea00" class="nb lv it mx b gy no nd l ne nf">Call: rlm(formula = Glucose ~ Pregnancies + Outcome + Age + DiabetesPedigreeFunction + <br/>    BMI + Insulin + SkinThickness + BloodPressure, data = diabetes1)<br/>Residuals:<br/>    Min      1Q  Median      3Q     Max <br/>-68.627 -16.842  -1.543  15.576  83.793 </span><span id="74d9" class="nb lv it mx b gy no nd l ne nf">Coefficients:<br/>                         Value   Std. Error t value<br/>(Intercept)              78.3319  6.2990    12.4357<br/>Pregnancies              -0.4675  0.3600    -1.2984<br/>Outcome                  25.0513  2.3599    10.6152<br/>Age                       0.5448  0.1050     5.1881<br/>DiabetesPedigreeFunction -0.5482  3.1657    -0.1732<br/>BMI                       0.3297  0.1654     1.9935<br/>Insulin                   0.0925  0.0097     9.4912<br/>SkinThickness            -0.2530  0.0766    -3.3032<br/>BloodPressure             0.0673  0.0575     1.1706</span><span id="047b" class="nb lv it mx b gy no nd l ne nf">Residual standard error: 24.53 on 590 degrees of freedom</span></pre><p id="179f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在<strong class="kk iu"> 590 </strong>自由度上，双尾t临界值如下:</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="88b8" class="nb lv it mx b gy nc nd l ne nf">&gt; abs(qt(0.05/2, 590))<br/>[1] 1.963993</span></pre><p id="d77b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当t统计量&gt; t临界值时，零假设被拒绝。对此，<strong class="kk iu">结局</strong>、<strong class="kk iu">年龄</strong>、<strong class="kk iu">身体质量指数</strong>、<strong class="kk iu">胰岛素</strong>、<strong class="kk iu">皮肤厚度</strong>的t值绝对值大于临界值。</p><p id="0bf0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">考虑到相关图和多元线性回归的发现，选择<strong class="kk iu">结果</strong>、<strong class="kk iu">年龄</strong>、<strong class="kk iu">胰岛素</strong>和<strong class="kk iu">皮肤厚度</strong>作为分析的相关特征。</p><h1 id="6cbb" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">数据准备</h1><p id="5b04" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">既然已经选择了相关特征，就可以构建神经网络了。在此之前:</p><ol class=""><li id="e017" class="lg lh it kk b kl km ko kp kr li kv lj kz lk ld mr lm ln lo bi translated">最大-最小归一化用于在0和1之间缩放每个变量。这是为了确保变量之间有一个共同的范围，以便神经网络可以正确地解释它们。</li></ol><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="89f9" class="nb lv it mx b gy nc nd l ne nf">normalize &lt;- function(x) {<br/>  return ((x - min(x)) / (max(x) - min(x)))<br/>}</span><span id="28ca" class="nb lv it mx b gy no nd l ne nf">maxmindf &lt;- as.data.frame(lapply(df, normalize))<br/>attach(maxmindf)<br/>maxmindf&lt;-as.matrix(maxmindf)</span></pre><ol class=""><li id="9676" class="lg lh it kk b kl km ko kp kr li kv lj kz lk ld mr lm ln lo bi translated">训练验证集被分成70/30。</li></ol><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="d1a4" class="nb lv it mx b gy nc nd l ne nf">ind &lt;- sample(2, nrow(maxmindf), replace=TRUE, prob = c(0.7,0.3))</span><span id="95f0" class="nb lv it mx b gy no nd l ne nf">X_train &lt;- maxmindf[ind==1, 1:4]<br/>X_val &lt;- maxmindf[ind==2, 1:4]<br/>y_train &lt;- maxmindf[ind==1, 5]<br/>y_val &lt;- maxmindf[ind==2, 5]</span></pre><h1 id="0a67" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">顺序模型</h1><p id="03fd" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">现在，定义了顺序模型。四个输入特征(结果、年龄、胰岛素、皮肤厚度)包括在输入层中，该层中定义了9个神经元。定义一个具有60个神经元的隐藏层，并且定义一个具有1个神经元的线性输出层。</p><p id="83b7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正如<a class="ae lf" href="https://medium.com/fintechexplained/what-are-hidden-layers-4f54f7328263" rel="noopener">法尔哈德·马利克</a>在本文中所解释的，每层神经元的数量配置如下:</p><ul class=""><li id="7a1c" class="lg lh it kk b kl km ko kp kr li kv lj kz lk ld ll lm ln lo bi translated"><strong class="kk iu">输入层:</strong>输入层的神经元数量计算如下:</li></ul><p id="4cf7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><code class="fe np nq nr mx b">Number of features in the training set + 1</code></p><p id="5dc3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这种情况下，由于训练集中有8个特征，因此相应地定义了<strong class="kk iu"> 9个</strong>输入神经元。</p><ul class=""><li id="63b1" class="lg lh it kk b kl km ko kp kr li kv lj kz lk ld ll lm ln lo bi translated"><strong class="kk iu">隐藏层:</strong>定义一个隐藏层，因为单个层适用于处理大多数数据集。隐藏层中神经元的数量确定如下:</li></ul><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="2d55" class="nb lv it mx b gy nc nd l ne nf">Training Data Samples/Factor * (Input Neurons + Output Neurons)</span></pre><p id="0bed" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这种情况下，将因子设置为1，该因子的目的是防止过度拟合。因子可以取1到10之间的值。输入层中有9个神经元，输出层中有1个神经元，训练集中有599个观察值，隐藏层被分配了60个神经元。</p><ul class=""><li id="d1f6" class="lg lh it kk b kl km ko kp kr li kv lj kz lk ld ll lm ln lo bi translated"><strong class="kk iu">输出层:</strong>由于这是结果层，输出层默认取值1。</li></ul><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="fb9f" class="nb lv it mx b gy nc nd l ne nf">model &lt;- keras_model_sequential() <br/>model %&gt;% <br/>  layer_dense(units = 9, activation = 'relu', kernel_initializer='RandomNormal', input_shape = c(4)) %&gt;% <br/>  layer_dense(units = 60, activation = 'relu') %&gt;%<br/>  layer_dense(units = 1, activation = 'linear')</span><span id="0540" class="nb lv it mx b gy no nd l ne nf">summary(model)</span></pre><p id="c535" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是输出:</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="52fd" class="nb lv it mx b gy nc nd l ne nf">Model: "sequential"<br/>________________________________________________________________________________<br/>Layer (type)                        Output Shape                    Param #     <br/>================================================================================<br/>dense (Dense)                       (None, 9)                       45          <br/>________________________________________________________________________________<br/>dense_1 (Dense)                     (None, 60)                      600         <br/>________________________________________________________________________________<br/>dense_2 (Dense)                     (None, 1)                       61          <br/>================================================================================<br/>Total params: 706<br/>Trainable params: 706<br/>Non-trainable params: 0<br/>________________________________________________________________________________</span></pre><p id="8f05" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该模型现在经过30个时期的训练，并基于其损失和平均绝对误差进行评估。假设因变量为区间，则使用均方差来确定预测值和实际值之间的偏差。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="8a39" class="nb lv it mx b gy nc nd l ne nf">model %&gt;% compile(<br/>  loss = 'mean_squared_error',<br/>  optimizer = 'adam',<br/>  metrics = c('mae')<br/>)</span><span id="24d4" class="nb lv it mx b gy no nd l ne nf">history &lt;- model %&gt;% fit(<br/>  X_train, y_train, <br/>  epochs = 30, batch_size = 50, <br/>  validation_split = 0.2<br/>)</span></pre><h1 id="e53d" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">模型评估</h1><p id="09b6" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">预测值和实际值会按比例还原为其原始格式:</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="fc5d" class="nb lv it mx b gy nc nd l ne nf">model %&gt;% evaluate(X_val, y_val)<br/>model<br/>pred &lt;- data.frame(y = predict(model, as.matrix(X_val)))<br/>predicted=pred$y * abs(diff(range(df$Glucose))) + min(df$Glucose)<br/>actual=y_val * abs(diff(range(df$Glucose))) + min(df$Glucose)<br/>df&lt;-data.frame(predicted,actual)<br/>attach(df)</span></pre><p id="d190" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是输出:</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="8eba" class="nb lv it mx b gy nc nd l ne nf">$loss<br/>    0.0266957393988254<br/>$mae<br/>    0.132186755537987</span><span id="98c0" class="nb lv it mx b gy no nd l ne nf">Model<br/>Model: "sequential"<br/>________________________________________________________________________________<br/>Layer (type)                        Output Shape                    Param #     <br/>================================================================================<br/>dense (Dense)                       (None, 9)                       45          <br/>________________________________________________________________________________<br/>dense_1 (Dense)                     (None, 60)                      600         <br/>________________________________________________________________________________<br/>dense_2 (Dense)                     (None, 1)                       61          <br/>================================================================================<br/>Total params: 706<br/>Trainable params: 706<br/>Non-trainable params: 0<br/>________________________________________________________________________________</span></pre><p id="fde4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是损失和平均绝对误差的曲线图:</p><figure class="ms mt mu mv gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi ng"><img src="../Images/aa7de7ac65f1b7969ce46fac215bea63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*BeAnKyMIBl2hAWdq.png"/></div></div></figure><p id="f788" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该模型产生的损失略高于2%，平均绝对误差略高于13%。</p><p id="ce1a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le"> MLmetrics </em>库也可用于计算MAPE(平均绝对百分比误差)。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="4b43" class="nb lv it mx b gy nc nd l ne nf">install.packages("MLmetrics")<br/>library(MLmetrics)<br/>MAPE(predicted, actual)</span></pre><p id="2867" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">验证集的MAPE为<strong class="kk iu"> 18% </strong>。增加模型中隐藏层的数量并不能提高MAPE，因此决定在模型配置中保留一个隐藏层。</p><h1 id="369d" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">预测和测试数据</h1><p id="cac4" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">尽管这个模型显示了强大的预测能力，我们的工作还没有完成。</p><p id="2b96" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然该模型在验证数据上表现良好，但我们现在需要评估该模型在完全看不见的数据上是否也表现良好。</p><p id="5a6d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从pima-indians-diabetes2加载特征变量，并再次调用max0min归一化:</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="7a5a" class="nb lv it mx b gy nc nd l ne nf">normalize &lt;- function(x) {<br/>  return ((x - min(x)) / (max(x) - min(x)))<br/>}</span><span id="fc87" class="nb lv it mx b gy no nd l ne nf">maxmindf2 &lt;- as.data.frame(lapply(df2, normalize))<br/>attach(maxmindf2)</span></pre><p id="6ed8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用R中的预测函数，为葡萄糖变量生成预测:</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="d202" class="nb lv it mx b gy nc nd l ne nf">pred_test &lt;- data.frame(y = predict(model, as.matrix(maxmindf2)))<br/>predicted_test = pred_test$y * abs(diff(range(diabetes1$Glucose))) + min(diabetes1$Glucose)<br/>predicted_test</span></pre><p id="b497" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后将预测值与pima-indians-diabetes中的实际值进行比较3:</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="7736" class="nb lv it mx b gy nc nd l ne nf">actual_test = diabetes3$Glucose<br/>df2&lt;-data.frame(predicted_test,actual_test)<br/>attach(df2)<br/>df2</span></pre><figure class="ms mt mu mv gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi ns"><img src="../Images/973f8aee1b7b6b1a459514528bdb0b51.png" data-original-src="https://miro.medium.com/v2/resize:fit:404/format:webp/0*DFgxWw2MuqZwhM2H.png"/></div></div></figure><p id="fcb4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，使用测试值计算平均绝对百分比误差:</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="1653" class="nb lv it mx b gy nc nd l ne nf">MAPE(predicted_test, actual_test)</span></pre><p id="d4d4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">计算出17%的平均百分比误差:</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="a020" class="nb lv it mx b gy nc nd l ne nf">0.177895157636775</span></pre><p id="5d8d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">观察到，虽然平均百分比误差略高于使用训练和验证数据计算的误差，但是该模型在测试集上的所有未观察到的观察中预测血糖水平仍然表现良好。</p><h1 id="f10d" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">结论</h1><p id="d777" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">在本例中，我们看到:</p><ul class=""><li id="4636" class="lg lh it kk b kl km ko kp kr li kv lj kz lk ld ll lm ln lo bi translated">如何在R中实现特征选择方法</li><li id="888d" class="lg lh it kk b kl lp ko lq kr lr kv ls kz lt ld ll lm ln lo bi translated">使用Keras API构建一个神经网络来分析回归数据</li><li id="7068" class="lg lh it kk b kl lp ko lq kr lr kv ls kz lt ld ll lm ln lo bi translated">使用测试数据的仪表预测精度</li></ul><p id="bd87" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">非常感谢你的时间！你也可以在michael-grogan.com找到更多我的数据科学内容。</p><p id="ea3f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">免责声明:本文是在“原样”的基础上编写的，没有担保。本文旨在提供数据科学概念的概述，不应以任何方式解释为专业建议。</em></p></div></div>    
</body>
</html>