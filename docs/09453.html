<html>
<head>
<title>5 Common Machine Learning Security Risks and How to Overcome Them</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">5 常见的机器学习安全风险以及如何克服它们</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/5-common-machine-learning-security-risks-and-how-to-overcome-them-2f90115a699d?source=collection_archive---------28-----------------------#2020-07-06">https://towardsdatascience.com/5-common-machine-learning-security-risks-and-how-to-overcome-them-2f90115a699d?source=collection_archive---------28-----------------------#2020-07-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/fec553d3acdc7702b23a0b2051f36f8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SasPDt75TsJb94VtW9mPKQ.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">阿里安·达尔维什在<a class="ae kf" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Upsplash </a>上拍摄的照片</p></figure><p id="e1a6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我仍然记得软件开发行业刚刚起步的日子。许多人担心软件漏洞和利用，他们当时是对的，因为黑客利用这些利用并开始实现他们的恶意设计。每次数据泄露和<a class="ae kf" href="https://totalsecurityadvisor.blr.com/cybersecurity/7-types-of-cybersecurity-attacks-and-what-you-need-to-know-about-them/" rel="noopener ugc nofollow" target="_blank">网络安全攻击</a>都被主流媒体广泛报道，包括印刷和电子媒体。</p><p id="dff8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">重点更多的是清除个别的错误，而不是识别问题的根本原因。几年后，我们意识到唯一的解决方案是构建安全的软件。几十年后，软件安全已经成为网络安全计划不可或缺的一部分。</p><p id="ebbb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">随着今天的软件和应用程序使用<a class="ae kf" href="https://www.branex.ca/blog/how-machine-learning-optimizing-user-experience/" rel="noopener ugc nofollow" target="_blank">机器学习和人工智能</a>，保护您正在使用的机器学习和人工智能系统非常重要。不要误会我的意思，机器学习在图像分类、翻译、玩和赢国际象棋等复杂游戏以及其他视频游戏等任务方面比人类做得好得多。</p><p id="da0c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">尽管有其优势，一些企业仍然不愿意使用基于机器学习的系统，因为它们存在安全风险。如果你以一种随意的方式采用机器学习，你更有可能增加你的安全风险。这就是为什么对于考虑采用机器学习的企业来说，了解其附带的安全风险非常重要。</p><p id="b90f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本文中，您将了解五种常见的机器学习安全风险，以及如何降低这些风险。</p><h1 id="6e04" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated"><strong class="ak">机器学习安全挑战</strong></h1><p id="28b6" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">保护机器学习系统的最大障碍之一是，机器学习系统中的数据在安全方面扮演着外部角色。这使得保护你的机器学习系统更加困难。在大多数情况下，机器学习系统接受训练的数据集占 60%的风险，而学习算法和源代码占 40%的风险。</p><p id="f524" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是为什么对于企业来说，将所有的精力转移到架构风险分析上是很重要的。根据一份<a class="ae kf" href="https://berryvilleiml.com/wp-login.php?action=register&amp;redirect_to=/results/ara.pdf" rel="noopener ugc nofollow" target="_blank">报告</a>，架构风险分析是企业需要采取的保护其机器学习系统的重要第一步。该报告进一步强调了与机器学习系统相关的 70 多种风险。保护已经成为机器学习模型不可或缺的一部分的数据是另一个巨大的挑战。</p><h2 id="3ae2" class="mh lf it bd lg mi mj dn lk mk ml dp lo kr mm mn ls kv mo mp lw kz mq mr ma ms bi translated"><strong class="ak"> 1。愚弄系统</strong></h2><p id="a69c" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">对机器学习系统最常见的攻击之一是通过给出恶意输入来欺骗它们做出错误的预测。简而言之，它们是机器的视错觉，机器向它们展示了一幅现实世界中并不存在的画面，并迫使它们基于此做出决定。覆盖面和关注度都很大，这使得它比其他<a class="ae kf" href="https://hackernoon.com/7-sneaky-ways-hackers-are-using-machine-learning-to-steal-your-data-d0933w6a" rel="noopener ugc nofollow" target="_blank">机器学习安全风险</a>的威胁要大得多。这种类型的攻击通常以机器学习模型为目标。</p><h2 id="92b8" class="mh lf it bd lg mi mj dn lk mk ml dp lo kr mm mn ls kv mo mp lw kz mq mr ma ms bi translated"><strong class="ak"> 2。数据中毒</strong></h2><p id="6541" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">机器学习系统依赖数据进行学习。这就是为什么确保数据的可靠性、完整性和安全性对企业来说非常重要，否则，您可能会得到错误的预测。黑客知道这一点，并试图锁定机器学习系统使用的数据。他们操纵、破坏和毒害数据，以至于让整个机器学习系统陷入瘫痪。</p><p id="a9e1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">商家应该特别注意，把风险降到最低。机器学习专家应该通过最小化网络罪犯可以控制的训练数据量和控制程度来防止损害。更糟糕的是，你必须保护所有的数据源，因为攻击者可以操纵你可能用于训练机器学习系统的任何数据源。如果你做不到这一点，你的机器学习训练失控的风险就会急剧增加。</p><h2 id="bc4d" class="mh lf it bd lg mi mj dn lk mk ml dp lo kr mm mn ls kv mo mp lw kz mq mr ma ms bi translated"><strong class="ak"> 3。在线系统的操作</strong></h2><p id="e8ea" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">大多数机器学习系统连接到互联网，尤其是在操作使用期间，因为它继续学习。这给了攻击者可乘之机。网络犯罪分子可以通过给错误的系统输入，将机器学习系统误导到错误的方向，甚至更糟的是，慢慢地重新训练它们按照命令行事，做错误的事情。</p><p id="4b81" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">操纵一个在线机器学习系统不仅容易，而且非常微妙，受害者甚至不会意识到他们的机器学习系统正在别人手里玩。<a class="ae kf" rel="noopener" target="_blank" href="/mlevsds-3c89425baabb?source=collection_home---4------5-----------------------">机器学习工程师</a>可以通过选择正确的算法、维护数据所有权记录以及简化和保护系统操作来解决这个问题。</p><h2 id="7387" class="mh lf it bd lg mi mj dn lk mk ml dp lo kr mm mn ls kv mo mp lw kz mq mr ma ms bi translated"><strong class="ak"> 4。转移学习攻击</strong></h2><p id="4093" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">大多数机器学习系统利用已经训练好的<a class="ae kf" rel="noopener" target="_blank" href="/lessons-learned-from-almost-failing-to-deploy-a-simple-machine-learning-model-in-the-cloud-69f041704f03?source=collection_home---4------1-----------------------">机器学习模型</a>。这种通用的机器学习模型经过调整，通过提供专门的培训来实现特定的目的。这时迁移学习攻击可能是致命的。如果你选择的模型是流行的，攻击者可以发起攻击，甚至可以欺骗你的任务特定的机器学习模型。</p><p id="fee8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">始终关注可疑和意外的机器学习行为，以识别这些类型的攻击。由于机器学习算法是在转移过程中有意使用的，这增加了风险，尤其是如果学习转移发生在预期用途之外。最好选择集团发布模型，因为它们清楚地定义了系统的功能以及如何控制风险。</p><h2 id="65af" class="mh lf it bd lg mi mj dn lk mk ml dp lo kr mm mn ls kv mo mp lw kz mq mr ma ms bi translated"><strong class="ak"> 5。数据隐私和保密</strong></h2><p id="2839" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">如前所述，机器学习算法使用数据进行训练和学习。确保这些数据的隐私和机密性至关重要，尤其是当这些数据被构建到机器学习模型中时。黑客可以发起可以在雷达下飞行的数据提取攻击，这可能会使您的整个机器学习系统面临风险。</p><p id="b46d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">即使这些攻击失败，网络罪犯也可以发起更小的子符号函数提取攻击，这不仅需要更少的努力和资源来执行，而且还可以帮助他们执行其他类型的攻击，例如带有恶意输入的对抗性攻击。这意味着你不仅要保护你的机器学习系统免受数据提取攻击，还要防止函数提取攻击。</p><p id="e75c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你如何克服机器学习的安全问题？欢迎在下面的评论区与我们分享。</p></div></div>    
</body>
</html>