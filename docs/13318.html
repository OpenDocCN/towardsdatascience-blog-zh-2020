<html>
<head>
<title>What to Do When Your Data Is Too Big for Your Memory?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">当你的数据对于你的内存来说太大了怎么办？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-to-do-when-your-data-is-too-big-for-your-memory-65c84c600585?source=collection_archive---------8-----------------------#2020-09-13">https://towardsdatascience.com/what-to-do-when-your-data-is-too-big-for-your-memory-65c84c600585?source=collection_archive---------8-----------------------#2020-09-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a919" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用 Panda 处理大数据</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f41ff4f476085117613a0507fbe71039.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cAx3fzADLYjc8ufALCoQew.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由来自<a class="ae ky" href="https://www.pexels.com/photo/dark-computer-green-software-225769/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Pexels </a>的<a class="ae ky" href="https://www.pexels.com/@markusspiske?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Markus Spiske </a>拍摄</p></figure><p id="e5a7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我们在进行任何数据科学项目时，要采取的一个基本步骤是从 API 下载一些数据到内存，以便我们可以处理它。</p><p id="fcc1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这样做的时候，有些问题是我们可以面对的；其中一个问题是有太多的数据需要处理。如果我们数据的大小大于我们可用内存(RAM)的大小，我们在完成项目时可能会面临一些问题。</p><p id="9eea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">那么，接下来该怎么办呢？</em> </strong></p><p id="6ac3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">解决大<em class="lv">数据、</em>T10】小问题有不同的选择。这些解决方案要么耗费时间，要么耗费金钱。</p><h2 id="f808" class="lw lx it bd ly lz ma dn mb mc md dp me li mf mg mh lm mi mj mk lq ml mm mn mo bi translated">可能的解决方案</h2><ol class=""><li id="0ac6" class="mp mq it lb b lc mr lf ms li mt lm mu lq mv lu mw mx my mz bi translated"><strong class="lb iu">成本计算解决方案</strong>:一个可能的解决方案是购买一台新电脑，配备更强大的 CPU 和更大的 RAM，能够处理整个数据集。或者，租用云或虚拟内存，然后创建一些集群安排来处理工作负载。</li><li id="614f" class="mp mq it lb b lc na lf nb li nc lm nd lq ne lu mw mx my mz bi translated"><strong class="lb iu">时间成本解决方案</strong>:你的 RAM 可能太小，无法处理你的数据，但通常你的硬盘要比 RAM 大得多。那么，为什么不直接用它呢？使用硬盘来处理你的数据会使它的处理速度慢得多，因为即使是 SSD 硬盘也比 RAM 慢。</li></ol><p id="6e60" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，这两种解决方案都非常有效，也就是说，如果你有资源这样做的话。如果您的项目预算很大，或者时间不是一个限制因素，那么使用其中一种技术是最简单、最直接的答案。</p><p id="8f32" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">但是，</em></p><p id="3c54" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果不能呢？如果你在做预算呢？如果您的数据非常大，从硬盘加载会增加您的处理时间 5X 或 6 倍甚至更多？有没有不花钱也不花时间的处理大数据的解决方案？</p><p id="3373" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我很高兴你问了——或者我问了？。</p><p id="95f0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以使用一些技术来处理大数据，而不需要花费任何资金或处理很长的加载时间。这篇文章将介绍三种技术，你可以使用<strong class="lb iu">熊猫</strong>来处理大型数据集。</p><h1 id="c0ad" class="nf lx it bd ly ng nh ni mb nj nk nl me jz nm ka mh kc nn kd mk kf no kg mn np bi translated">技巧 1:压缩</h1><p id="15b7" class="pw-post-body-paragraph kz la it lb b lc mr ju le lf ms jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">我们要介绍的第一项技术是<em class="lv">压缩数据。</em>这里的压缩不是指把数据放在 ZIP 文件中；相反，它意味着将数据以压缩格式存储在内存中。</p><p id="505c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">换句话说，压缩数据就是找到一种以不同的方式来表示数据的方法，这种方式将使用更少的内存。数据压缩有两种:<em class="lv">无损</em>压缩和<em class="lv">有损</em>一种。这两种类型只会影响数据的加载，不会导致代码的处理部分发生任何变化。</p><h2 id="af32" class="lw lx it bd ly lz ma dn mb mc md dp me li mf mg mh lm mi mj mk lq ml mm mn mo bi translated">无损压缩</h2><p id="999a" class="pw-post-body-paragraph kz la it lb b lc mr ju le lf ms jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">无损压缩不会造成任何数据损失。也就是说，原始数据和压缩数据在语义上是相同的。您可以通过三种方式对数据帧执行无损压缩:</p><p id="79ff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文的剩余部分，我将使用这个包含美国不同县的新冠肺炎案例的数据集。</p><ul class=""><li id="e036" class="mp mq it lb b lc ld lf lg li nt lm nu lq nv lu nw mx my mz bi translated"><strong class="lb iu">加载特定列</strong></li></ul><p id="0f50" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我使用的数据集具有以下结构:</p><pre class="kj kk kl km gt nx ny nz oa aw ob bi"><span id="ab07" class="lw lx it ny b gy oc od l oe of">import pandas as pd<br/>data = pd.read_csv("<a class="ae ky" href="https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv</a>")<br/>data.sample(10)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/e60555b145be073a803077dcf0b62bd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gND_Wq7wgK0dcv4z066koQ.png"/></div></div></figure><p id="47cc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">加载整个数据集需要 111 MB 的内存！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/3046ce90e668134ccd88e4936b70858b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3qY76gBDpWe4NHVBuj7tRQ.png"/></div></div></figure><p id="56e9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，我真的只需要这个数据集的两列，county 和 case 列，那么我为什么要加载整个数据集呢？只加载我需要的两列需要 36 MB，这减少了 32%的内存使用。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/c7d9c903320c23d5198b4ee7c7f8066d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OU8bNQztpewX7vKa0ef0Fw.png"/></div></div></figure><p id="b765" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我可以像这样使用 Pandas 只加载我需要的列</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/884804c91afc7252f0274bac5af5720b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dlFxlVPWZijRQRm2KB6kjg.png"/></div></div></figure><p id="7c91" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此部分的代码片段</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ok ol l"/></div></figure><ul class=""><li id="3106" class="mp mq it lb b lc ld lf lg li nt lm nu lq nv lu nw mx my mz bi translated"><strong class="lb iu">操作数据类型</strong></li></ul><p id="a8ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一种减少数据内存使用的方法是截断数据中的数字项。例如，每当我们将一个 CSV 文件加载到一个数据框的列中时，如果该文件包含数字，它将把它存储为需要 64 个字节来存储一个数值。但是，我们可以截断它，并使用其他 int 格式来节省一些内存。</p><p id="b5da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe om on oo ny b">int8</code>可以存储-128 到 127 的整数。</p><p id="ce8e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe om on oo ny b">int16</code>可以存储-32768 到 32767 的整数。</p><p id="5ee9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe om on oo ny b">int64</code>可以存储从-9223372036854775808 到 9223372036854775807 的整数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/e6f4b5c1d4c28e4cc19250e22adb0ca7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mkWKbTs1HeDqc7pDQZLzMQ.png"/></div></div></figure><p id="2183" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您知道特定列中的数字永远不会高于 32767，您可以使用一个<code class="fe om on oo ny b">int16</code>或<code class="fe om on oo ny b">int32</code>，并将该列的内存使用减少 75%。</p><p id="958c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，假设每个县的病例数不能超过 32767 —这在现实生活中是不正确的—那么，我们可以将该列截断为<code class="fe om on oo ny b">int16 </code>而不是<code class="fe om on oo ny b">int64</code>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/603e68a03838c9a3f7a68e94fd1c35b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mU047aGQviInzGvHOmTQWg.png"/></div></div></figure><ul class=""><li id="a8bf" class="mp mq it lb b lc ld lf lg li nt lm nu lq nv lu nw mx my mz bi translated"><strong class="lb iu">稀疏列</strong></li></ul><p id="5480" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果数据有一列或更多的列存储为<code class="fe om on oo ny b">NaN</code>的空值，你可以使用<a class="ae ky" href="https://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html" rel="noopener ugc nofollow" target="_blank">稀疏列表示</a>来节省内存，这样你就不会浪费内存来存储所有这些空值。</p><p id="88ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">假设 county 列有一些<code class="fe om on oo ny b">NaN</code>值，我只想跳过包含<code class="fe om on oo ny b">NaN</code>的行，我可以使用稀疏序列轻松地做到这一点。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/c3ba15944662acdbff40451e7a7e78c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kpe2Na26doR5yMce2GCuvw.png"/></div></div></figure><h2 id="f280" class="lw lx it bd ly lz ma dn mb mc md dp me li mf mg mh lm mi mj mk lq ml mm mn mo bi translated">有损压缩</h2><p id="0516" class="pw-post-body-paragraph kz la it lb b lc mr ju le lf ms jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">如果执行无损压缩还不够呢？如果我需要进一步压缩数据，该怎么办？在这种情况下，您可以使用有损压缩，因此为了节省内存，您牺牲了数据的 100%准确性。</p><p id="c4a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以通过两种方式执行有损压缩:修改数值和采样。</p><ul class=""><li id="8ceb" class="mp mq it lb b lc ld lf lg li nt lm nu lq nv lu nw mx my mz bi translated"><strong class="lb iu">修改数值:</strong>有时，您不需要完全精确的数值数据，这样您可以将它们从<code class="fe om on oo ny b">int64</code>截断到<code class="fe om on oo ny b">int32</code>或<code class="fe om on oo ny b">int16</code>。</li><li id="d7af" class="mp mq it lb b lc na lf nb li nc lm nd lq ne lu nw mx my mz bi translated"><strong class="lb iu">抽样:</strong>也许你想证明有些州的 COVID 病例比其他州高，所以你对一些县进行抽样，看看哪些州的病例更多。这样做被认为是有损压缩，因为您没有考虑所有行。</li></ul><h1 id="7b01" class="nf lx it bd ly ng nh ni mb nj nk nl me jz nm ka mh kc nn kd mk kf no kg mn np bi translated">技巧 2:分块</h1><p id="904e" class="pw-post-body-paragraph kz la it lb b lc mr ju le lf ms jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">处理大型数据集的另一种方法是分块。也就是说，将一个大型数据集切割成较小的块，然后分别处理这些块。处理完所有数据块后，您可以比较结果并计算最终结果。</p><p id="431b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该数据集包含 1923 行。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/94ebcc996a6e542b76aac4de9a5e7210.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l-MHAOY4BCvBPDFavrbhFg.png"/></div></div></figure><p id="c424" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">假设我想找到病例最多的国家。我可以将我的数据集分成 100 行的块，分别处理每一行，然后获取较小结果中的最大值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/00891812e2927f91fbea9fc49c424556.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zDWqJGojA_t306TABQdmMQ.png"/></div></div></figure><p id="1740" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此部分的代码片段</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ok ol l"/></div></figure><h1 id="758d" class="nf lx it bd ly ng nh ni mb nj nk nl me jz nm ka mh kc nn kd mk kf no kg mn np bi translated">技巧 3:索引</h1><p id="bf49" class="pw-post-body-paragraph kz la it lb b lc mr ju le lf ms jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">如果您只需要加载一次数据集，分块是很好的选择，但是如果您想要加载多个数据集，那么索引是一个不错的选择。</p><p id="7db7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">把索引想象成一本书的索引；你不需要阅读整本书就可以知道某个方面的必要信息。</p><p id="537f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，假设我想获得特定州的案例。在这种情况下，组块是有意义的；我可以写一个简单的函数来实现它。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/8aee52e532893321114ddc84d695a279.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5rhgnAZ7v52SxSfrOUXYlQ.png"/></div></div></figure><h2 id="1296" class="lw lx it bd ly lz ma dn mb mc md dp me li mf mg mh lm mi mj mk lq ml mm mn mo bi translated">索引与分块</h2><p id="7808" class="pw-post-body-paragraph kz la it lb b lc mr ju le lf ms jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">在分块中，你需要读取所有数据，而在索引中，你只需要一部分数据。</p><p id="4e91" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，我的小函数加载每个块中的所有行，但只关心我想要的状态。这导致了巨大的开销。我可以通过使用熊猫旁边的数据库来避免这种情况。我能用的最简单的是 SQLite。</p><p id="4e5a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为此，我首先需要将我的数据框加载到 SQLite 数据库中。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ok ol l"/></div></figure><p id="b065" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后我需要重新编写我的<code class="fe om on oo ny b">get_state_info</code>函数，并使用其中的数据库。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/42024610d971a3adc36c95569e65cb6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HtqC8dalEoaWCNPeGTOhSA.png"/></div></div></figure><p id="e65a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过这样做，我可以减少 50%的内存使用。</p><h1 id="e23b" class="nf lx it bd ly ng nh ni mb nj nk nl me jz nm ka mh kc nn kd mk kf no kg mn np bi translated">结论</h1><p id="3543" class="pw-post-body-paragraph kz la it lb b lc mr ju le lf ms jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">处理大型数据集可能会很麻烦，尤其是当它不适合您的内存时。有些解决方案既费时又费钱，这是最简单、最直接的方法。</p><p id="1c69" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，如果您没有资源，您可以使用 Pandas 中的一些技术来减少加载数据的内存使用——如压缩、索引和抓取等技术。</p></div></div>    
</body>
</html>