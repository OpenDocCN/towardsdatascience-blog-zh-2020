<html>
<head>
<title>Group2Vec for Advance Categorical Encoding</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Group2Vec 用于高级分类编码</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/group2vec-for-advance-categorical-encoding-54dfc7a08349?source=collection_archive---------33-----------------------#2020-03-04">https://towardsdatascience.com/group2vec-for-advance-categorical-encoding-54dfc7a08349?source=collection_archive---------33-----------------------#2020-03-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f0d3" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">创建高基数类别的有价值的表示</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ece58119424a687a1ffa447640c4bc32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*AlQFuP3gWbozQr7Q"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae ky" href="https://unsplash.com/@vanveenjf?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> VanveenJF </a>拍摄的照片</p></figure><p id="5ba0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对分类变量进行编码是每个机器学习项目中必需的预处理步骤。选择正确的编码技术是一项严肃而重要的任务。有许多选择:从经典的一键或整数映射到巧妙的目标编码或散列函数，最后得到更复杂的向量表示。</p><p id="0bd5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">固定的收据是不存在的，采用一种技术而不是另一种技术是基于我们可以处理的数据类型和我们的分析范围。例如，one-hot 保持了类别的对称性，但是它很消耗内存。整数映射更简单，但是在类之间创建了无意义的关系。目标编码与目标直接相关，但如果应用不当，往往会过度拟合。嵌入表示是一种新趋势，包括分配一个神经网络来产生类别的感知向量表示。</p><p id="5d03" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我处理了一个点击欺诈识别的问题。我们的分析领域是移动设备，只有分类变量可供我们使用。我们的范围是从这个数据结构中提取值，引入一些用于分类编码的高级矢量化技术。<strong class="lb iu">共有三种不同的方法:前两种通过组计数和其他变换，应用手动创建矢量特征来管理数据；最新的是一个纯粹的神经网络结构，用于创建类别的深度表示，以某种方式，它倾向于从'<em class="lv">组</em> ' </strong>(因此得名 Group2Vec)中提取值。</p><h1 id="7448" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">数据</h1><p id="f8ee" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated"><a class="ae ky" href="https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection" rel="noopener ugc nofollow" target="_blank">通话数据和跟踪欺诈检测</a>是卡格尔为<a class="ae ky" href="https://www.talkingdata.com/" rel="noopener ugc nofollow" target="_blank">通话数据</a><em class="lv">主办的挑战，该平台是中国最大的独立大数据服务平台，覆盖全国 70%以上的移动设备。他们每天处理 30 亿次点击，其中 90%是潜在的欺诈。他们目前为应用程序开发人员防止点击欺诈的方法是，测量用户在他们的文件夹中点击的行程，并标记产生大量点击但从未安装应用程序的 IP 地址。利用这些信息，他们建立了一个 IP 黑名单和设备黑名单。</em>他们需要构建一个算法，来预测用户点击移动应用广告后是否会下载应用。为此，他们提供了一个丰富的数据集，在 4 天内覆盖了大约 2 亿次点击！</p><p id="4086" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">可用信息以点击记录的形式存在，具有以下结构:<em class="lv"> ip、app、device、os、channel、点击时间、归属时间，是归属</em>(我们的目标)。阅读和使用所有怪物数量的数据是出于我们的目的。我们提取了 3 个时间样本:第一个(200.000 次点击)用于 train，另两个(每次 50.000 次点击)用于验证和测试；我们还提供了验证和测试之间的时间下降，以提高结果的可靠性。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/0c062ac128685da47263da7eb42199d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n4RR5vwSj3gR0u6KT2Sq_w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">列车集中时间函数的标签分布</p></figure><p id="5fa8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们掌握的有价值的变量是<em class="lv"> ip、应用、设备、操作系统、渠道；</em>均为分类式。每个特性的大量类是我们想要评估的一个积极方面。从这个意义上说，经典的编码方法并没有发挥出最好的效果，我们需要更多，因此，我们建立了一些特殊而有趣的方法。<em class="lv">分组</em>和<em class="lv">计数</em>是开发我们先进编码技术的两个神奇元素，它们是从我们手工特征工程过程的第一步开始引入的。最后，我们尝试在不需要人工工程的情况下，创建一个足够聪明的神经网络结构，以产生有价值且可比的结果，但让我们按顺序进行！</p><h1 id="aa54" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">组计数+截断的 SVD</h1><p id="bf46" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我们介绍的第一种技术利用了截断奇异值分解(LSA)，LDA 或类似的方法也是很好的选择。如前所述，我们的范围是对我们的分类列进行编码，生成其中每个类的向量表示。这里是模式化的过程:</p><ul class=""><li id="0152" class="mu mv it lb b lc ld lf lg li mw lm mx lq my lu mz na nb nc bi translated"><em class="lv">分组依据</em>各分类变量训练(<em class="lv">分组依据</em>);</li><li id="e958" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated">对于每一个剩余的分类变量(<em class="lv"> passive_key </em>)，我们按组计算可用类的连接，就像它们是字符串一样。每对<em class="lv"> group_key — passive_key </em>是一串来自<em class="lv"> passive_key </em>域的类；</li><li id="ffeb" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated">用 CountVectorizer 将字符串检索为数字编码；</li><li id="960f" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated">然后用截断的 SVD 来减少所得到的稀疏矩阵。</li></ul><p id="0956" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这样，我们获得了每个分类变量的每个类别的向量表示，作为截断 SVD 向量的串联。向量的长度取决于归约分量的数量和串联的数量，由所有可能的组合(n_comp*n_cat*(n_cat-1))导出。在我们的例子中，3 是简化组件的数量，每个变量中的每个类是一个长度为 60(3 * 5 * 5(5–1))的向量。为了澄清，没有出现在 trainset 或 NaN 中的类别类在早期被编码为 0。</p><p id="1762" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所创建的特征对于每一种进一步的任务都是有用的。我们用它们来构建欺诈性点击预测的模型。使用一个简单的 RandomForest，在验证上进行调整，我们在看不见的测试数据上达到 0.908 AUC。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/e7ca6a323c06d3f6eb4bb2a83b6c53e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KEHh_G4xX37pIPz1JMncmw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据特性方面的 TNSE(左起:app、ip、渠道)</p></figure><h1 id="18f5" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">组计数+熵</h1><p id="188f" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">如上所述，第二种技术采用人工分组的方式将原始范畴转换成数字。这里是图解程序:</p><ul class=""><li id="fd06" class="mu mv it lb b lc ld lf lg li mw lm mx lq my lu mz na nb nc bi translated"><em class="lv"> groupby </em>按每个分类变量训练(<em class="lv">group _ key</em>)；</li><li id="4be3" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated">依次对每个剩余的分类变量(<em class="lv"> passive_key </em>)，计算未堆叠计数矩阵。其中在第一维上我们有<em class="lv"> group_key </em>类，而在第二维上我们有<em class="lv"> passive_key </em>类。交集是分组计数频率；</li><li id="43c8" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated">对行应用熵来总结计数事件。</li></ul><p id="a2ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过这种方式，我们获得了作为熵值串联的每个分类变量的每个类别的向量表示。因为熵是单个标量值，所以向量表示的长度取决于由所有可能的适用组合(n_cat*(n_cat-1))导出的串联的数量。在我们的例子中是 20(5 * 5(5–1))。</p><p id="d1e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如下所示，我们使用生成的特征集来输入机器学习模型，该模型预测哪些点击是欺诈性的。使用一个简单的 RandomForest，在验证上进行调整，我们在看不见的测试数据上达到了 0.896 的 AUC。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/7764d1e1a5b821af809b61b14b2e97cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xPNYGeiWIY0PEXDBbs2xBQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">验证数据方面的 TNSE(左起:应用、ip、渠道)</p></figure><h1 id="8502" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">Group2Vec</h1><p id="06ae" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在本节中，我们将介绍一种自动技术，它试图为我们制作所有以前的手工特征工程。由于神经网络和深度学习的力量，这种神奇是可能的。这个任务的架构被称为 Group2Vec(在示意图可视化下方)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/e7c78fd6066e16b1d20dcfae00fc0503.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*MOHw9SZ7dvm4qfeMXNfH4g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Group2Vec 架构</p></figure><p id="9596" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它接收表格分类特征作为输入，并试图以监督的方式学习它们的有价值的嵌入表示。这个问题对于神经网络来说并不新鲜:最简单的模型学习分类数据的嵌入表示，训练嵌入层，最后，在输出之前连接所有的分类数据。我们的策略既简单又有效:</p><ul class=""><li id="c505" class="mu mv it lb b lc ld lf lg li mw lm mx lq my lu mz na nb nc bi translated">为每个分类输入初始化嵌入层；</li><li id="3f14" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated">对于每个类别，在其他嵌入表示中计算点积。这些是我们在分类层次上的'<em class="lv">组</em>；</li><li id="f304" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated">汇总各'<em class="lv">'组'</em>采用平均汇集；</li><li id="14d5" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated">串接'<em class="lv">'组'</em>平均值；</li><li id="61b9" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated">应用正规化技术，如批处理正规化或退出；</li><li id="e3e7" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated">输出概率。</li></ul><p id="e7cb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的特定任务上训练的组 2Vec 在测试数据上实现了 0.937 的 AUC。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/e2d6030a280b05a4db7f1885d426bcc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5S90JqmXGPJczej9iXRyuQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">验证数据方面的 TNSE(左起:应用、ip、渠道)</p></figure><h1 id="34fe" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">摘要</h1><p id="63c5" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在这篇文章中，我介绍了一些分类编码的高级技术。它们不同于随处可得的标准方法，如果在分类任务中采用，同时显示出巨大的预测能力。在具有大量类别的分类特征的情况下，它们的有用性是明显的，同时避免了维度和代表性问题。</p></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><p id="35ae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://github.com/cerlymarco/MEDIUM_NoteBook" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">查看我的 GITHUB 回购</strong> </a></p><p id="c430" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">保持联系:<a class="ae ky" href="https://www.linkedin.com/in/marco-cerliani-b0bba714b/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a></p></div></div>    
</body>
</html>