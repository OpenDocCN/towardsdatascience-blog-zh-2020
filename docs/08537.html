<html>
<head>
<title>Removing non-linear trends from timeseries data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从时间序列数据中移除非线性趋势</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/removing-non-linear-trends-from-timeseries-data-b21f7567ed51?source=collection_archive---------15-----------------------#2020-06-21">https://towardsdatascience.com/removing-non-linear-trends-from-timeseries-data-b21f7567ed51?source=collection_archive---------15-----------------------#2020-06-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="5362" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有时需要从时间序列数据中移除趋势，为后续步骤做准备，或者作为数据清理过程的一部分。如果你能确定一个趋势，然后简单地从数据中减去它，结果就是去趋势数据。</p><p id="3027" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果趋势是线性的，你可以通过线性回归找到它。但是如果趋势不是线性的呢？一会儿我们会看看对此我们能做些什么。</p><p id="9af7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是首先，简单的例子。</p><h1 id="c765" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">线性趋势</h1><p id="2757" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">以下是有趋势的时间序列数据:</p><p id="f7aa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae lo" href="https://raw.githubusercontent.com/FlorinAndrei/misc/master/qdata.csv" rel="noopener ugc nofollow" target="_blank">https://raw . githubusercontent . com/FlorinAndrei/misc/master/qdata . CSV</a></p><p id="5002" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们加载它，看看它看起来像什么:</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="8ad3" class="ly km iq lu b gy lz ma l mb mc">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>from sklearn.linear_model import LinearRegression<br/>from sklearn.preprocessing import PolynomialFeatures<br/>from sklearn.metrics import mean_squared_error, r2_score</span><span id="785c" class="ly km iq lu b gy md ma l mb mc">ser = pd.read_csv('qdata.csv', index_col=0, squeeze=True)<br/>ser</span><span id="93ba" class="ly km iq lu b gy md ma l mb mc">x<br/>0      473.917764<br/>1       75.324825<br/>2     -306.969479<br/>3       53.271476<br/>4      372.966686<br/>         ...     <br/>95    4650.550473<br/>96    4604.573344<br/>97    4891.704638<br/>98    5265.948162<br/>99    5618.909339<br/>Name: y, Length: 100, dtype: float64</span><span id="4e79" class="ly km iq lu b gy md ma l mb mc">plt.plot(ser)<br/>plt.show()</span></pre><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi me"><img src="../Images/616b4c99054b1d5ccaaccad60b802904.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5zpqExuXyBo2nYYGMgXfAw.png"/></div></div></figure><p id="936d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">好吧，这是一个趋势。让我们假设它是线性的——让我们进行线性回归并找出答案。这是线性回归的直接应用。上面导入的 sklearn 库有我们做回归所需的一切。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="42b2" class="ly km iq lu b gy lz ma l mb mc">X = ser.index<br/>X = np.reshape(X, (len(X), 1))<br/>y = ser.values</span><span id="78ff" class="ly km iq lu b gy md ma l mb mc">model = LinearRegression()<br/>model.fit(X, y)<br/>trend = model.predict(X)</span><span id="fd93" class="ly km iq lu b gy md ma l mb mc">plt.plot(y)<br/>plt.plot(trend)<br/>plt.legend(['data', 'trend'])<br/>plt.show()</span></pre><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi me"><img src="../Images/2677317df89d7fb94a48419e1c10f90d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CK2Nn-xbVqooG5h__2Ru5A.png"/></div></div></figure><p id="0c25" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">似乎很合适，但可能不太合适。让我们从数据中减去趋势，看看去趋势后的数据是什么样的:</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="5890" class="ly km iq lu b gy lz ma l mb mc">detr = [y[i] - trend[i] for i in range(0, len(y))]<br/>plt.plot(detr)<br/>plt.title('data detrended in a linear fashion')<br/>plt.show()</span></pre><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi me"><img src="../Images/42d10e7d072d3dd114a1c9f22df3f0be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*837BmeU3TKM2toP8HC3xAg.png"/></div></div></figure><p id="cf77" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">不太有说服力。数据中仍有一个凹趋势。或许最初的趋势并不是线性的。</p><p id="764d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们计算数据和我们提取的趋势之间的 RMSE 和 R 值。我们稍后将回到这些数字。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="f28e" class="ly km iq lu b gy lz ma l mb mc">r2 = r2_score(y, trend)<br/>rmse = np.sqrt(mean_squared_error(y, trend))<br/>print('r2:', r2)<br/>print('rmse', rmse)<br/>r2: 0.8782399672701933<br/>rmse 553.6078593008505</span></pre><h1 id="1649" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">多项式瞧</h1><p id="48e3" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">如果趋势不是线性的，我们可以尝试用多项式曲线来拟合。但是事情是这样的:即使我们拟合的曲线是一个高次多项式，它仍然是线性回归，将被用来找到它。怎么会这样</p><p id="6f9e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">好吧，考虑这个二次表达式:</p><p id="026a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">y = a + bx + cx</p><p id="c0c7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们寻找的值是 a、b 和 c，它们都是线性的(1 的幂)。忘了 x 的幂，我们看的是 a，b，c 的幂，还记得为什么广义线性模型叫“线性”吗？因为系数是线性的，所以 x 值可以有不同的幂。</p><p id="df35" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以是线性回归——只是碰巧我们必须一次做多维的线性回归。</p><p id="89bd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们假设我们的数据有一个二次趋势。然后我们需要将 X 转换成二次形式:</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="d70a" class="ly km iq lu b gy lz ma l mb mc">pf = PolynomialFeatures(degree=2)<br/>Xp = pf.fit_transform(X)<br/>Xp</span></pre><p id="9e04" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">看起来像这样:</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="f16e" class="ly km iq lu b gy lz ma l mb mc">array([[1.000e+00, 0.000e+00, 0.000e+00],<br/>       [1.000e+00, 1.000e+00, 1.000e+00],<br/>       [1.000e+00, 2.000e+00, 4.000e+00],<br/>       [1.000e+00, 3.000e+00, 9.000e+00],<br/>       [1.000e+00, 4.000e+00, 1.600e+01],<br/>       [1.000e+00, 5.000e+00, 2.500e+01],<br/>       [1.000e+00, 6.000e+00, 3.600e+01],<br/>...<br/>       [1.000e+00, 9.600e+01, 9.216e+03],<br/>       [1.000e+00, 9.700e+01, 9.409e+03],<br/>       [1.000e+00, 9.800e+01, 9.604e+03],<br/>       [1.000e+00, 9.900e+01, 9.801e+03]])</span></pre><p id="f7b5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第一列是 X 的 0 次幂。第二列是 X。第三列是 X 的 2 次方。这就好比上图所示的二次表达式(y = a + bx + cx)。</p><p id="1089" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们将使用二次形式来拟合数据，并生成二次趋势。使用线性回归找到二次表达式的参数。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="d272" class="ly km iq lu b gy lz ma l mb mc">md2 = LinearRegression()<br/>md2.fit(Xp, y)<br/>trendp = md2.predict(Xp)</span></pre><p id="c2fa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">趋势是什么样的？</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="be50" class="ly km iq lu b gy lz ma l mb mc">plt.plot(X, y)<br/>plt.plot(X, trendp)<br/>plt.legend(['data', 'polynomial trend'])<br/>plt.show()</span></pre><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi me"><img src="../Images/6dd3a3febda3574691546b92513d344a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bXSHd_eXZUGQdfaoMgP9bQ.png"/></div></div></figure><p id="5a21" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">很合身，不是吗？现在让我们看看去趋势数据:</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="c81c" class="ly km iq lu b gy lz ma l mb mc">detrpoly = [y[i] - trendp[i] for i in range(0, len(y))]<br/>plt.plot(X, detrpoly)<br/>plt.title('polynomially detrended data')<br/>plt.show()</span></pre><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi me"><img src="../Images/2a2f3aa153971b93123696d308b50bbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JeGB8Ai4pZkCNN-UmiV62A.png"/></div></div></figure><p id="5212" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这显然更好。那里没有留下任何可以视觉识别的趋势。但是让我们看看数字是怎么说的:</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="f5cf" class="ly km iq lu b gy lz ma l mb mc">r2 = r2_score(y, trendp)<br/>rmse = np.sqrt(mean_squared_error(y, trendp))<br/>print('r2:', r2)<br/>print('rmse', rmse)<br/>r2: 0.9343217231542871<br/>rmse 406.5937924291518</span></pre><p id="dab3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">与线性趋势相比，多项式趋势 R 增加，RMSE 减少。两者都是好的改变。两个平均多项式比线性拟合更好。</p><h1 id="accf" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">高次多项式</h1><p id="9f75" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">您可以选择任意阶的多项式，只需在此处为 N 指定不同的值:</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="22f3" class="ly km iq lu b gy lz ma l mb mc">pf = PolynomialFeatures(degree=N)</span></pre><p id="e45f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一般来说，使用较低的 N 值。如果 N 值增加，但变化不大，则返回较小的值。</p><p id="b0d6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有一个弯曲的曲线可能可以用二次函数来描述。有两个弯曲的曲线可以用三次函数来描述。诸如此类。N-1 次弯曲需要一个 n 次幂的表达式。</p><p id="07b4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你增加 N 很多，最终你的“最佳拟合”曲线将开始跟随数据中的噪声，而不是拟合趋势。你过度拟合了曲线，现在已经没有意义了。要么减少 N，要么增加更多的数据点。</p></div></div>    
</body>
</html>