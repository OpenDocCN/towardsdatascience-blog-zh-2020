<html>
<head>
<title>YOLOv5 is Here!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">YOLOv5 来了！</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/yolo-v5-is-here-b668ce2a4908?source=collection_archive---------8-----------------------#2020-06-15">https://towardsdatascience.com/yolo-v5-is-here-b668ce2a4908?source=collection_archive---------8-----------------------#2020-06-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2fa7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用定制数据集&amp; YOLOV5 进行大象检测器训练</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/e304378e1655bc891dec3e5b418d8e9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bSLNlG7crv-p-m4LVYYk3Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:https://pjreddie.com/</p></figure><p id="5f1b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated"><span class="l lw lx ly bm lz ma mb mc md di"> Y </span> OLO " <strong class="lb iu">你只看一次</strong>"是 AI 工程师最流行、最喜欢的算法之一。它一直是实时对象检测的首选。</p><p id="5e37" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">YOLO 出现至今，因为它的第一个版本。让我们简单讨论一下 YOLO 的早期版本，然后我们将直接进入训练部分。</p><h1 id="87d7" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">以前的 YOLO 版本</h1><p id="3c5c" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">YOLO v1 于 2016 年 5 月由 Joseph Redmon 以论文“<a class="ae ky" href="https://arxiv.org/pdf/1506.02640.pdf" rel="noopener ugc nofollow" target="_blank">你只看一次:统一的实时对象检测</a>推出这是实时物体检测领域最大的进步之一。</p><p id="ad7a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2017 年 12 月，约瑟夫用纸推出了另一个版本的 YOLO“<a class="ae ky" href="https://arxiv.org/pdf/1506.02640.pdf" rel="noopener ugc nofollow" target="_blank">yolo 9000:更好、更快、更强</a>”它也被称为 YOLO 9000。</p><p id="5b72" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一年后的 2018 年 4 月，最受欢迎和稳定的 YOLO 版本推出。约瑟夫这次有了一个合作伙伴，他们用纸“<a class="ae ky" href="https://arxiv.org/pdf/1804.02767.pdf" rel="noopener ugc nofollow" target="_blank"> YOLOv3:增量改进</a>”发布了 YOLOv3。</p><p id="3f5f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，在 2020 年 4 月，Alexey Bochkovskiy 用论文介绍了 yolov 4 "<a class="ae ky" href="https://arxiv.org/abs/2004.10934" rel="noopener ugc nofollow" target="_blank">yolov 4:物体检测的最佳速度和精度</a> " Alexey 不是以前版本的 YOLO 的官方作者，但 Joseph 和 Ali 从 YOLO 后退了一步，必须有人来处理这个时代。</p><p id="60bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">YOLOv4 引入了一些令人震惊的新东西，它以很高的利润超过了 YOLOv3，而且与 EfficientDet 系列相比，它的平均精度也很高。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/070a8ee5226146561f48442385c9ca41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*32ucN5yYa3ldqEDJEqJEpA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://arxiv.org/pdf/2004.10934.pdf" rel="noopener ugc nofollow" target="_blank"> YOLOv4 论文</a>。</p></figure><p id="fb40" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">几天后的 2020 年 6 月 9 日，仅仅四天前，另一位非官方作者 Glenn Jocher 发布了 YOLOv5。关于“YOLOv5”这个名字和其他东西的选择有很多争议。格伦推出了基于 PyTorch 的 YOLOv5 版本，并进行了出色的改进。因此，他还没有发布任何官方文件。</p><p id="bcb8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个版本是相当惊人的，超越了所有以前的版本，并以更高的 FPS 接近 EfficientDet AP。你可以注意到下图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nc"><img src="../Images/5316a7eaf34c26fecd1c2cfb14ce5d7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7UXLYoPteNz6IO9Oc3-jAw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:https://github.com/ultralytics</p></figure><p id="1e3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如需进一步比较，请访问 https://blog.roboflow.ai/yolov4-versus-yolov5/的<a class="ae ky" href="https://blog.roboflow.ai/yolov4-versus-yolov5/" rel="noopener ugc nofollow" target="_blank"/>。</p></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h1 id="bde7" class="me mf it bd mg mh nk mj mk ml nl mn mo jz nm ka mq kc nn kd ms kf no kg mu mv bi translated">在自定义数据集上训练 YOLOv5</h1><p id="30e4" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">该部分包括如下所列的多个步骤，</p><ol class=""><li id="7ee5" class="np nq it lb b lc ld lf lg li nr lm ns lq nt lu nu nv nw nx bi translated">正在准备数据集</li><li id="03dc" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu nu nv nw nx bi translated">环境设置</li><li id="c874" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu nu nv nw nx bi translated">配置/修改文件和目录结构</li><li id="e34b" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu nu nv nw nx bi translated">培养</li><li id="1ca9" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu nu nv nw nx bi translated">推理</li><li id="da1a" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu nu nv nw nx bi translated">结果</li></ol><p id="caf2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本教程的代码可以在<a class="ae ky" href="https://github.com/mihir135/yolov5" rel="noopener ugc nofollow" target="_blank">的这个</a> GitHub 资源库中找到。</p><h2 id="147b" class="od mf it bd mg oe of dn mk og oh dp mo li oi oj mq lm ok ol ms lq om on mu oo bi translated">正在准备数据集</h2><p id="60af" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">一旦获得了 YOLO 格式的标注数据集，就可以开始工作了。</p><p id="0f24" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本教程中，我们将使用来自<a class="ae ky" href="https://storage.googleapis.com/openimages/web/index.html" rel="noopener ugc nofollow" target="_blank">开放图像数据集</a>的大象检测数据集。</p><p id="6bb2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要获得带标签的数据集，你可以搜索开源数据集，或者你可以从网上抓取图片，并使用像<a class="ae ky" href="https://github.com/tzutalin/labelImg" rel="noopener ugc nofollow" target="_blank"> LabelImg </a>这样的工具对其进行注释。</p><blockquote class="op oq or"><p id="0d8b" class="kz la os lb b lc ld ju le lf lg jx lh ot lj lk ll ou ln lo lp ov lr ls lt lu im bi translated">注意:你的注释格式应该是 YOLO 格式。</p></blockquote><p id="ef8a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">确保您将注释和图像保存在同一个目录中。</p><p id="6d95" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后生成训练、测试和验证 txt 文件，为此只需复制图像文件并将路径粘贴到 txt 文件中。最佳实践是将 70%的数据保存在定型集中，20%保存在验证集中，10 %保存在测试集中。</p><p id="89a7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于本教程，我将使用这个<a class="ae ky" href="https://github.com/mihir135/yolov5/blob/master/data/train_elephant.txt" rel="noopener ugc nofollow" target="_blank">训练</a>、<a class="ae ky" href="https://github.com/mihir135/yolov5/blob/master/data/test_elephant.txt" rel="noopener ugc nofollow" target="_blank">测试</a>和<a class="ae ky" href="https://github.com/mihir135/yolov5/blob/master/data/val_elephant.txt" rel="noopener ugc nofollow" target="_blank">验证</a> txt 文件。</p><p id="88e6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，我还添加了一个带标签的数据集<a class="ae ky" href="https://github.com/mihir135/yolov5/tree/master/data" rel="noopener ugc nofollow" target="_blank">，这里是</a>，images 目录包含所有图像，txt 目录包含所有注释。</p><h2 id="6421" class="od mf it bd mg oe of dn mk og oh dp mo li oi oj mq lm ok ol ms lq om on mu oo bi translated">环境设置</h2><p id="8c09" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">需要注意的重要一点是，您将需要 PyTorch 版本≥ 1.5、Python 版本 3.7 和 CUDA 版本 10.2。</p><p id="3265" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用 pip 或<a class="ae ky" href="https://github.com/mihir135/yolov5/blob/master/requirements.txt" rel="noopener ugc nofollow" target="_blank"> requirement.txt </a>文件可以很容易地安装下面的依赖项。</p><pre class="kj kk kl km gt ow ox oy oz aw pa bi"><span id="d6d1" class="od mf it ox b gy pb pc l pd pe">numpy==1.17<br/>scipy==1.4.1<br/>cudatoolkit==10.2.89<br/>opencv-python<br/>torch==1.5<br/>torchvision==0.6.0<br/>matplotlib<br/>pycocotools<br/>tqdm<br/>pillow<br/>tensorboard<br/>pyyaml</span></pre><blockquote class="op oq or"><p id="8b64" class="kz la os lb b lc ld ju le lf lg jx lh ot lj lk ll ou ln lo lp ov lr ls lt lu im bi translated">注:本教程我用的是 ubuntu 16.04。</p></blockquote><p id="52e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦成功安装了所有的依赖项，就可以继续前进了。</p><h2 id="a606" class="od mf it bd mg oe of dn mk og oh dp mo li oi oj mq lm ok ol ms lq om on mu oo bi translated">配置/修改文件和目录结构</h2><p id="a3fc" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">要训练 YOLOv5 模型，您需要执行一些步骤。</p><p id="5e3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，从 YOLOv5 的克隆存储库开始。如果你正在学习本教程，你可以从<a class="ae ky" href="https://github.com/mihir135/yolov5" rel="noopener ugc nofollow" target="_blank">这里</a>开始克隆。你可以从官方回购克隆，也可以在这里形成<a class="ae ky" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="82dc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第二，修改你需要添加的 YAML 文件来描述你的数据集参数。请参考以下 YAML 文件，并根据您的需要进行相应的修改。</p><pre class="kj kk kl km gt ow ox oy oz aw pa bi"><span id="a68c" class="od mf it ox b gy pb pc l pd pe"># here you need to specify the files train, test and validation txt # files created in step 1.<br/>train: /self/elephant_dataset/train_elephant.txt<br/>val: /self/elephant_dataset/val_elephant.txt<br/>test: /self/elephant_dataset/test_elephant.txt</span><span id="707f" class="od mf it ox b gy pf pc l pd pe"># number of classes in your dataset<br/>nc: 1</span><span id="3b97" class="od mf it ox b gy pf pc l pd pe"># class names<br/>names: ['Elephant']</span></pre><p id="766a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们稍后将使用该文件来训练模型。</p><h2 id="7122" class="od mf it bd mg oe of dn mk og oh dp mo li oi oj mq lm ok ol ms lq om on mu oo bi translated">培养</h2><p id="01d8" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">为了训练约洛夫 5，格伦提出了 4 个版本。</p><ol class=""><li id="a7e7" class="np nq it lb b lc ld lf lg li nr lm ns lq nt lu nu nv nw nx bi translated">yolov5-s 这是一个小版本</li><li id="84fa" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu nu nv nw nx bi translated">yolov5-m 这是一个中等版本</li><li id="9d55" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu nu nv nw nx bi translated">yolov5-l 这是一个大版本</li><li id="2ea6" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu nu nv nw nx bi translated">yolov5-x 是一个特大号版本</li></ol><p id="a2e7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在这里看到他们的对比<a class="ae ky" href="https://github.com/ultralytics/yolov5#user-content-pretrained-checkpoints" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="c5e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在训练时，你可以通过 YAML 文件来选择这些模型中的任何一个。所有的 YAML 文件都在这里<a class="ae ky" href="https://github.com/mihir135/yolov5/tree/master/models" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="e418" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在一切都配置好了，我们准备训练我们的 YOLOv5 模型！</p><p id="5065" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">转到目录，使用下面的命令开始训练。</p><pre class="kj kk kl km gt ow ox oy oz aw pa bi"><span id="59cc" class="od mf it ox b gy pb pc l pd pe">python train.py --img 640 --batch 8 --epochs 30 --data ./data/elephant.yaml --cfg ./models/yolov5s.yaml --weights '' --device 0</span></pre><ul class=""><li id="9d0e" class="np nq it lb b lc ld lf lg li nr lm ns lq nt lu pg nv nw nx bi translated">— img:输入图像的大小</li><li id="02e7" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu pg nv nw nx bi translated">—批次:批次大小</li><li id="dbb0" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu pg nv nw nx bi translated">-时期:时期的数量</li><li id="8f6d" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu pg nv nw nx bi translated">—数据:在步骤 3 中创建的 YAML 文件</li><li id="046d" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu pg nv nw nx bi translated">cfg:模型选择 YAML 文件。我在本教程中选择了“s”。</li><li id="e916" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu pg nv nw nx bi translated">—权重:应用迁移学习的权重文件，您可以在此处找到它们<a class="ae ky" href="https://drive.google.com/drive/folders/1Drs_Aiu7xx6S-ix95f9kNsA6ueKRpN2J" rel="noopener ugc nofollow" target="_blank">。</a></li><li id="c66c" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu pg nv nw nx bi translated">—设备:选择训练设备，“0”代表 GPU，“cpu”代表 CPU。</li></ul><p id="c86c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该命令将立即开始模型训练。我已经决定训练 30 个纪元的模型。</p><p id="e1e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">训练完成后，模型将保存在您的“权重”目录中，生成的矩阵图如下。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nc"><img src="../Images/0e5b80fd57d9f4360d89861c391d77c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eemx0TkhrE6swFgT-csfiQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://github.com/mihir135" rel="noopener ugc nofollow" target="_blank">https://github.com/mihir135</a></p></figure><p id="9f82" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我们所看到的，这个模型被训练得非常好，mAP@0.5 几乎是 0.78，非常好！</p><h2 id="dea5" class="od mf it bd mg oe of dn mk og oh dp mo li oi oj mq lm ok ol ms lq om on mu oo bi translated">推理</h2><p id="0641" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">现在模型已经训练好了，让我们在一些图像上测试它的性能。</p><p id="f158" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要运行模型推理，请使用以下命令。</p><pre class="kj kk kl km gt ow ox oy oz aw pa bi"><span id="1e04" class="od mf it ox b gy pb pc l pd pe">python detect.py --source sample_img/  --weights weights/best.pt --conf 0.4</span></pre><ul class=""><li id="86e3" class="np nq it lb b lc ld lf lg li nr lm ns lq nt lu pg nv nw nx bi translated">—来源:输入图像目录或单个图像路径或视频路径</li><li id="6477" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu pg nv nw nx bi translated">-权重:训练模型路径</li><li id="9d51" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu pg nv nw nx bi translated">— conf:置信度阈值</li></ul><p id="4b4b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这将处理输入并将输出存储在您的推理目录中。</p><h2 id="98a7" class="od mf it bd mg oe of dn mk og oh dp mo li oi oj mq lm ok ol ms lq om on mu oo bi translated">结果</h2><p id="c9df" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">在这里，我附上一些来自训练有素的模型推理输出图像。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ph"><img src="../Images/bf3730e710bcd3a50dbce44995226bcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*PbBTabYmB6hyvPwlsgxDow.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:https://github.com/mihir135/yolov5</p></figure><p id="ff91" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">很棒吧！</p><p id="3bdd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在这里找到训练有素的大象探测器<a class="ae ky" href="https://github.com/mihir135/yolov5/blob/master/weights_elephant/last.pt" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="6f26" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以从<a class="ae ky" href="https://github.com/mihir135/yolov5" rel="noopener ugc nofollow" target="_blank">这里</a>下载并探索本教程的代码。</p><p id="81e9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您有任何疑问，可以在回复部分发表评论。</p><p id="d1c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我的<a class="ae ky" href="https://github.com/mihir135" rel="noopener ugc nofollow" target="_blank"> GitHub </a>或者<a class="ae ky" href="https://www.linkedin.com/in/mihir-rajput/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>。</p><p id="72a3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">特别感谢<a class="ae ky" href="https://medium.com/u/52e4be8e717a?source=post_page-----6adeca4f2b24----------------------" rel="noopener"> Mayur Patel </a>的贡献与合作。</p><p id="94b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">任何反馈或建议将不胜感激。</p></div></div>    
</body>
</html>