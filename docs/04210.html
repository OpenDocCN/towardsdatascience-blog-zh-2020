<html>
<head>
<title>Day 107 of #NLP365: NLP Papers Summary — Make Lead Bias in Your Favor: A Simple and Effective Method for News Summarization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">#NLP365 的第 107 天:NLP 论文摘要——让领导偏向于你:一个简单有效的新闻摘要方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/day-107-of-nlp365-nlp-papers-summary-make-lead-bias-in-your-favor-a-simple-and-effective-4c52b1a569b8?source=collection_archive---------53-----------------------#2020-04-16">https://towardsdatascience.com/day-107-of-nlp365-nlp-papers-summary-make-lead-bias-in-your-favor-a-simple-and-effective-4c52b1a569b8?source=collection_archive---------53-----------------------#2020-04-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/61a393f717c1685f581a48076c22cd22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HDhaS8ed285Bb9L80C5U0g.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">阅读和理解研究论文就像拼凑一个未解之谜。汉斯-彼得·高斯特在<a class="ae jg" href="https://unsplash.com/s/photos/research-papers?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片。</p></figure><h2 id="d589" class="jh ji jj bd b dl jk jl jm jn jo jp dk jq translated" aria-label="kicker paragraph"><a class="ae ep" href="https://medium.com/towards-data-science/inside-ai/home" rel="noopener">内线艾</a> <a class="ae ep" href="http://towardsdatascience.com/tagged/nlp365" rel="noopener" target="_blank"> NLP365 </a></h2><div class=""/><div class=""><h2 id="f41e" class="pw-subtitle-paragraph kp js jj bd b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg dk translated">NLP 论文摘要是我总结 NLP 研究论文要点的系列文章</h2></div><p id="ce19" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">项目#NLP365 (+1)是我在 2020 年每天记录我的 NLP 学习旅程的地方。在这里，你可以随意查看我在过去的 100 天里学到了什么。</p><p id="781c" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">今天的 NLP 论文是<strong class="lj jt"> <em class="md">让铅偏向于你:一种简单有效的新闻摘要方法</em> </strong>。以下是研究论文的要点。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="5f13" class="ml mm jj bd mn mo mp mq mr ms mt mu mv ky mw kz mx lb my lc mz le na lf nb nc bi translated">目标和贡献</h1><p id="b6b1" class="pw-post-body-paragraph lh li jj lj b lk nd kt lm ln ne kw lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">目的是使用新闻数据中现有的领先偏倚来预训练无标记数据集上的摘要模型。我们希望该模型使用文章的其余部分来预测引导句。引导偏差是新闻数据集中的一个常见问题，文章开头的几个句子包含最重要的信息，因此在新闻数据集上训练的模型会偏向于选择这些句子，而忽略文章后面的句子。</p><h1 id="b871" class="ml mm jj bd mn mo ni mq mr ms nj mu mv ky nk kz mx lb nl lc mz le nm lf nb nc bi translated">数据集</h1><p id="36d2" class="pw-post-body-paragraph lh li jj lj b lk nd kt lm ln ne kw lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">我们根据前 3 个句子与文章其余部分的重叠不停顿词比率过滤文章后，收集了 21.4M 篇文章(2016 年 6 月—2019 年 6 月)。高重叠不间断单词比率告诉我们有很强的语义联系。</p><p id="2646" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在三个基准新闻摘要数据集上进行评估:</p><ol class=""><li id="2674" class="nn no jj lj b lk ll ln lo lq np lu nq ly nr mc ns nt nu nv bi translated">纽约时报(NYT)语料库— 104K 新闻文章</li><li id="11c9" class="nn no jj lj b lk nw ln nx lq ny lu nz ly oa mc ns nt nu nv bi translated">Xsum — 227K 新闻文章</li><li id="4dec" class="nn no jj lj b lk nw ln nx lq ny lu nz ly oa mc ns nt nu nv bi translated">CNN/每日邮报— 312K 新闻文章</li></ol><h1 id="2dab" class="ml mm jj bd mn mo ni mq mr ms nj mu mv ky nk kz mx lb nl lc mz le nm lf nb nc bi translated">方法学</h1><figure class="oc od oe of gt iv gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/505fadebf44b48f3969b7fbdfcd57a93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/0*uUdVAxSwUTBjVrM1.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">使用 lead-3 作为摘要的数据集创建流程[1]</p></figure><p id="e13e" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">给定一篇新闻文章，我们把 lead-3 作为目标摘要，把文章的其余部分作为新闻内容，如上图所示。这允许我们利用未标记的新闻数据集来训练我们的摘要模型。这种预训练方法可以应用于任何具有结构偏差的数据集，例如，具有摘要的学术论文或具有目录的书籍。然而，预训练需要仔细的检查和清理，以确保我们对我们的内容有一个好的目标总结。</p><h1 id="a407" class="ml mm jj bd mn mo ni mq mr ms nj mu mv ky nk kz mx lb nl lc mz le nm lf nb nc bi translated">实验</h1><p id="2ffc" class="pw-post-body-paragraph lh li jj lj b lk nd kt lm ln ne kw lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">抽象概括模型是传统的变换器编码器-解码器架构。我们不会在此详述架构。用未标记的导联-3 (PL)对目标数据集进行微调的预训练被表示为 PL-FT，而没有微调的被表示为 PL-NoFT。</p><h2 id="db81" class="og mm jj bd mn oh oi dn mr oj ok dp mv lq ol om mx lu on oo mz ly op oq nb jp bi translated">数据清理流程是怎样的？</h2><ol class=""><li id="2f0e" class="nn no jj lj b lk nd ln ne lq or lu os ly ot mc ns nt nu nv bi translated">使用正则表达式删除媒体机构、日期和其他无关内容</li><li id="35e2" class="nn no jj lj b lk nw ln nx lq ny lu nz ly oa mc ns nt nu nv bi translated">只保留前三句有 10-150 个单词的文章，文章的其余部分有 150-1200 个单词。此外，删除所有在文章其余部分重复出现 lead-3 句子的文章。这是为了过滤掉太长或太短的文章，并鼓励抽象的总结</li><li id="9757" class="nn no jj lj b lk nw ln nx lq ny lu nz ly oa mc ns nt nu nv bi translated">删除含有“不相关”前 3 句的文章。使用前导 3 句子和文章其余部分之间的重叠单词的比率来计算相关性。高重叠词比率意味着前三句是文章其余部分的典型总结。阈值比率为 0.65。</li></ol><h2 id="8fe3" class="og mm jj bd mn oh oi dn mr oj ok dp mv lq ol om mx lu on oo mz ly op oq nb jp bi translated">模型比较</h2><ul class=""><li id="21da" class="nn no jj lj b lk nd ln ne lq or lu os ly ot mc ou nt nu nv bi translated">Lead-X:使用前 X 个句子作为摘要(对于 NYT 和 CNN/DM，X = 3；对于 XSum，X = 1)</li><li id="b225" class="nn no jj lj b lk nw ln nx lq ny lu nz ly oa mc ou nt nu nv bi translated">指针生成器网络</li><li id="2aba" class="nn no jj lj b lk nw ln nx lq ny lu nz ly oa mc ou nt nu nv bi translated">DRM:使用深度强化学习</li><li id="2cbd" class="nn no jj lj b lk nw ln nx lq ny lu nz ly oa mc ou nt nu nv bi translated">TConvS2S:卷积神经网络</li><li id="9cc0" class="nn no jj lj b lk nw ln nx lq ny lu nz ly oa mc ou nt nu nv bi translated">自下而上:总结的两步方法</li><li id="e1e5" class="nn no jj lj b lk nw ln nx lq ny lu nz ly oa mc ou nt nu nv bi translated">SEQ:使用重构和话题丢失</li><li id="10e1" class="nn no jj lj b lk nw ln nx lq ny lu nz ly oa mc ou nt nu nv bi translated">GPT-2:预训练语言模型</li></ul><h1 id="49c5" class="ml mm jj bd mn mo ni mq mr ms nj mu mv ky nk kz mx lb nl lc mz le nm lf nb nc bi translated">结果</h1><p id="9884" class="pw-post-body-paragraph lh li jj lj b lk nd kt lm ln ne kw lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">评估指标是传统的 ROUGE 分数(ROUGE-1、ROUGE-2 和 ROUGE-1)。所有三个评估数据集的结果如下图所示:</p><figure class="oc od oe of gt iv gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/fcfa13dd3888589f9d4b8d0a35ba72f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/0*JMJfKjGtTQ88zxcR.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">NYT 和 CNN/每日邮报测试集的 ROUGE 分数[1]</p></figure><figure class="oc od oe of gt iv gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/b5ed828858079fd5db02d41305141868.png" data-original-src="https://miro.medium.com/v2/resize:fit:610/format:webp/0*y5ynm9akGBn60nnK.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">XSum 测试集[1]的 ROUGE 分数</p></figure><ul class=""><li id="7051" class="nn no jj lj b lk ll ln lo lq np lu nq ly nr mc ou nt nu nv bi translated">PL-FT 模型在 NYT 和 Xsum 数据集上都优于所有基线模型。在美国有线电视新闻网/每日邮报上，除了自下而上，它的表现超过了所有</li><li id="8846" class="nn no jj lj b lk nw ln nx lq ny lu nz ly oa mc ou nt nu nv bi translated">PL-NoFT 在 CNN/Daily Mail 上的表现远远超过了所有无监督的模型。在 Xsum 中也表现不错。PL-NoFT 在所有三个数据集上都是相同的模型，展示了它的泛化能力</li></ul><h2 id="ffa6" class="og mm jj bd mn oh oi dn mr oj ok dp mv lq ol om mx lu on oo mz ly op oq nb jp bi translated">抽象性</h2><p id="a557" class="pw-post-body-paragraph lh li jj lj b lk nd kt lm ln ne kw lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">PL-noFT 和 PL-FT 生成的摘要比参考摘要具有更新颖的单字。PL-noFT 与其他 n-grams 中的参考具有相似的新颖率，但是 PL-FT 在微调后具有相对较低的新颖率。</p><figure class="oc od oe of gt iv gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/001d754224f057ec787ff29d93a4cdfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/format:webp/0*Bm_OnrHkfMT9xuo-.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">新 n 元语法在生成的摘要中所占的百分比，用于衡量抽象性[1]</p></figure><h2 id="0c3f" class="og mm jj bd mn oh oi dn mr oj ok dp mv lq ol om mx lu on oo mz ly op oq nb jp bi translated">人类评估</h2><p id="5c5d" class="pw-post-body-paragraph lh li jj lj b lk nd kt lm ln ne kw lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">对 PL 模型和指针生成器网络生成的摘要进行人工评估。评分系统和结果如下所示。结果表明，PL-noFT 和 PL-FT 都优于指针生成器网络。这展示了预训练和微调策略的威力。</p><figure class="oc od oe of gt iv gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/05bed903f481ebee95a42b47632ea184.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/0*tcTv3G2UcEX40Ug_.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">人体评价时的评分标准和评价结果[1]</p></figure><h1 id="11f7" class="ml mm jj bd mn mo ni mq mr ms nj mu mv ky nk kz mx lb nl lc mz le nm lf nb nc bi translated">结论和未来工作</h1><p id="f215" class="pw-post-body-paragraph lh li jj lj b lk nd kt lm ln ne kw lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">本文利用新闻数据中存在的倾向性作为目标摘要和训练前摘要模型。我们的未经微调的预训练模型在不同的新闻摘要数据集上取得了 SOTA 结果。通过微调，性能进一步提高。总的来说，这种预训练方法可以应用于任何存在结构偏差的数据集。</p><h2 id="b345" class="og mm jj bd mn oh oi dn mr oj ok dp mv lq ol om mx lu on oo mz ly op oq nb jp bi translated">来源:</h2><p id="2f4f" class="pw-post-body-paragraph lh li jj lj b lk nd kt lm ln ne kw lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">[1]朱，，等.“使引导偏向于你:一种简单而有效的新闻摘要方法”<em class="md"> arXiv 预印本 arXiv:1912.11602 </em> (2019)。网址:【https://arxiv.org/pdf/1912.11602.pdf T2】</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="a6e9" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">【https://ryanong.co.uk】原载于 2020 年 4 月 16 日<a class="ae jg" href="https://ryanong.co.uk/2020/04/16/day-107-nlp-research-papers-make-lead-bias-in-your-favor-a-simple-and-effective-method-for-news-summarization/" rel="noopener ugc nofollow" target="_blank"><em class="md"/></a><em class="md">。</em></p></div></div>    
</body>
</html>