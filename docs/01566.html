<html>
<head>
<title>The Basics of Simple Linear Regression (Non-Technical)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">简单线性回归的基础(非技术性)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-basics-of-simple-linear-regression-non-technical-4b559d55d611?source=collection_archive---------14-----------------------#2020-02-12">https://towardsdatascience.com/the-basics-of-simple-linear-regression-non-technical-4b559d55d611?source=collection_archive---------14-----------------------#2020-02-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/c93d6e0838af6e67c98c92c1ea3b8f46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6rXNZolpw7Cuj9Og"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">彼得·德·格兰迪在<a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="ba60" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">自从开始我的数据科学之旅以来，我一直在研究线性回归模型。与财富 300 强公司的多个业务利益相关者一起工作过，我有幸理解了对数据科学家的期望。这是一个非技术性的博客，但它确实包含了一些对模型的数学理解。我鼓励一个非技术人员也参考一下，因为让你的手变脏并理解机器学习的细微差别是值得的。</p><blockquote class="le lf lg"><p id="7d64" class="kg kh lh ki b kj kk kl km kn ko kp kq li ks kt ku lj kw kx ky lk la lb lc ld im bi translated">永远不要低估基础知识，尤其是在数据科学领域。</p></blockquote><p id="ce21" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">回归是一种监督学习方法，在这种方法中，您使用历史<em class="lh">数字</em>数据，训练<strong class="ki iu">模型</strong>，然后使用它来获得尽可能多的点的最佳拟合线。在二维空间中，这叫做直线；在 n 维空间中，我们称之为<em class="lh">超平面</em>。回归是预测分析模型中最常用的方法。</p><div class="ll lm gp gr ln lo"><a rel="noopener follow" target="_blank" href="/interpret-linear-regression-in-10-mins-non-technical-3f78f1f1dbd1"><div class="lp ab fo"><div class="lq ab lr cl cj ls"><h2 class="bd iu gy z fp lt fr fs lu fu fw is bi translated">在 10 分钟内解释线性回归(非技术性)</h2><div class="lv l"><h3 class="bd b gy z fp lt fr fs lu fu fw dk translated">当有那么多伟大的文章和对最常见算法的解释时，为什么还要花力气…</h3></div><div class="lw l"><p class="bd b dl z fp lt fr fs lu fu fw dk translated">towardsdatascience.com</p></div></div><div class="lx l"><div class="ly l lz ma mb lx mc jz lo"/></div></div></a></div><p id="79c8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> CRISP-DM </strong>是一个开发模型时应该知道的花哨词。它简单地代表了工业标准流程，数据流程，T21 流程。这类似于软件开发中的 SDLC(软件开发生命周期)。跟着它！或者至少让你的利益相关者知道你会这么做。😛</p><h1 id="3742" class="md me it bd mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na bi translated">简单线性回归:</h1><p id="1eb4" class="pw-post-body-paragraph kg kh it ki b kj nb kl km kn nc kp kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">这是回归的基础。您有一个<strong class="ki iu">单个</strong>特征，用于预测另一个变量。这个用于预测的单一特征被称为<strong class="ki iu">预测器</strong>或独立变量。您正在预测的值是<em class="lh">因变量</em>。</p><p id="40cb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你知道直线的方程式是:</p><pre class="ng nh ni nj gt nk nl nm nn aw no bi"><span id="4c81" class="np me it nl b gy nq nr l ns nt">y = mx + c,</span><span id="6a21" class="np me it nl b gy nu nr l ns nt">Where,<br/>y = Dependent Variable<br/>m = Slope of the line (The angle of the line)<br/>x = Independent Variable<br/>c = Some constant</span></pre><p id="5779" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以，我谷歌了一下<em class="lh">简单线性回归</em>，这是弹出的第一批图片之一。</p><figure class="ng nh ni nj gt ju gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/dd507e88ff5abe7dfe49df15d7d746c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/0*h4IxxuOmfglGQd1v.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">来源:<a class="ae kf" href="https://www.javatpoint.com/simple-linear-regression-in-machine-learning" rel="noopener ugc nofollow" target="_blank">学分</a></p></figure><p id="353a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们在这里理解什么？<br/> X 轴:自变量—工作年限<br/> Y 轴:因变量—工资</p><p id="87d9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们知道，工资多少取决于工作年限，可以用下面的等式表示:</p><pre class="ng nh ni nj gt nk nl nm nn aw no bi"><span id="0e0a" class="np me it nl b gy nq nr l ns nt">Salary = (slope)*(Years of experience) + some constant</span><span id="fdc2" class="np me it nl b gy nu nr l ns nt">Essentially,<br/>Y = mx + c</span><span id="fa34" class="np me it nl b gy nu nr l ns nt">So, a good way to understand the constant here would be that if your number if years of experience was zero, you would still get some salary.</span></pre><h2 id="09d6" class="np me it bd mf nw nx dn mj ny nz dp mn kr oa ob mr kv oc od mv kz oe of mz og bi translated">最佳拟合线</h2><p id="0fbd" class="pw-post-body-paragraph kg kh it ki b kj nb kl km kn nc kp kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">理解最佳拟合线的最简单方法是画一条穿过这些点的直线，使它尽可能接近所有点。我们只是试图最小化回归线和点之间的距离。为了理解和量化这一点，我们寻求一些指标的帮助。</p><h2 id="d8bd" class="np me it bd mf nw nx dn mj ny nz dp mn kr oa ob mr kv oc od mv kz oe of mz og bi translated">RSS:</h2><p id="20c5" class="pw-post-body-paragraph kg kh it ki b kj nb kl km kn nc kp kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">残差平方和。不要惊慌失措，你还处于初级阶段。</p><p id="6874" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">问:什么是剩余？<br/>答:很简单。假设使用线性回归，你已经在呈现线性关系的点之间形成了一条线。</p><blockquote class="le lf lg"><p id="3dde" class="kg kh lh ki b kj kk kl km kn ko kp kq li ks kt ku lj kw kx ky lk la lb lc ld im bi translated"><em class="it">待预测的</em>点到<em class="it">预测的</em>线的垂直距离称为残差。</p></blockquote><figure class="ng nh ni nj gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oh"><img src="../Images/9ae4889056710a3f05e8f737b2e67ea1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*dG6m4wnx3ARPtZPd8qf1tQ.gif"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">来源:<a class="ae kf" rel="noopener" target="_blank" href="/introduction-to-linear-regression-and-polynomial-regression-f8adc96f31cb">这里！</a></p></figure><p id="45af" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通过最小化 RSS:残差平方和误差找到最佳拟合线。</p><p id="5fa0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">好吧，现在这很尴尬，我必须承认如果你在这里<a class="ae kf" href="https://medium.com/@anishmahapatra" rel="noopener">或在</a><a class="ae kf" href="https://www.linkedin.com/in/anishmahapatra/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上关注我，你会意识到我是一名数据科学家，但不是数学的最大粉丝。<strong class="ki iu">数学</strong>，对我来说，是一种<strong class="ki iu">必要的恶</strong>。我建议你详细地研究一下数学，这在我的博客中是绝不会出现的。</p><blockquote class="le lf lg"><p id="6b13" class="kg kh lh ki b kj kk kl km kn ko kp kq li ks kt ku lj kw kx ky lk la lb lc ld im bi translated">为了数据科学的应用，我更喜欢优雅的逻辑过程和简单的代码。</p></blockquote><p id="f5c3" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你想知道术语之外的数学知识，谷歌一下。如果你想理解数学的直觉，请跟随我。</p><figure class="ng nh ni nj gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oi"><img src="../Images/6caf4dfb8dede79e137b361b8471488d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ZLG7m9DCcB8drpP2"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">照片由<a class="ae kf" href="https://unsplash.com/@emilymorter?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">艾米丽·莫特</a>在<a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="6203" class="md me it bd mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na bi translated">线性回归的强度</h1><p id="1e38" class="pw-post-body-paragraph kg kh it ki b kj nb kl km kn nc kp kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">你的模型有多好？因此，有人告诉我，我们可以借助以下指标来计算线性回归模型的强度:</p><ol class=""><li id="892e" class="oj ok it ki b kj kk kn ko kr ol kv om kz on ld oo op oq or bi translated">r 或决定系数</li><li id="b3d7" class="oj ok it ki b kj os kn ot kr ou kv ov kz ow ld oo op oq or bi translated">剩余标准误差</li></ol><h2 id="367d" class="np me it bd mf nw nx dn mj ny nz dp mn kr oa ob mr kv oc od mv kz oe of mz og bi translated">1.r 或决定系数</h2><p id="2581" class="pw-post-body-paragraph kg kh it ki b kj nb kl km kn nc kp kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">因此，标题被突出显示，以便您记住 R 的同义词是决定系数。啊！为了给你解释 R，我需要告诉你什么是 TSS 或者总平方和。</p><p id="9def" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，当我们想看看一个简单的线性模型做得好不好，我们需要有一个基线。最简单而有效的基线是模型的平均值。如果你不能打败一个模型的平均值，那么，你所拥有的就是坏的，非常坏的。我从维基百科页面<a class="ae kf" href="https://en.wikipedia.org/wiki/Total_sum_of_squares" rel="noopener ugc nofollow" target="_blank">这里</a>截取的片段很好地代表了这一点。</p><figure class="ng nh ni nj gt ju gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/be77bbeb84fa2a6c7ee8fcdab4312ae2.png" data-original-src="https://miro.medium.com/v2/resize:fit:326/format:webp/1*EZitcqXyta0rc7Es5Pt8Rg.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">TSS:总平方和:我们应该预测的值——所有点的平均值(<a class="ae kf" href="https://en.wikipedia.org/wiki/Total_sum_of_squares" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="a023" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以，R 是一个度量(数字)，简单地说，它解释了给定数据的哪一部分。r 介于 0 和 1 之间。总体而言，R 平方值越高，模型就越符合您的数据。</p><p id="251d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">奇怪的是，我不得不在这里再次解释 RSS 是什么意思。RSS 是点的实际值和点的预测值之差，它是由维基百科页面上的另一个片段精确定义的。</p><figure class="ng nh ni nj gt ju gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/2ef887cc09995cf4162ade886ac228cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*BXxR8TJML3nc3i0S0WLlGg.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">RSS:实际值—预测值(<a class="ae kf" href="https://en.wikipedia.org/wiki/Residual_sum_of_squares" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="da3d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">问:为什么选择 RSS/TSS？<br/> A .很简单。你的模型至少要打败一个在点的中间画直线的家伙。如果值为 0，说明比那个差。R 的值越接近，模型越好。</p><figure class="ng nh ni nj gt ju gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/2816798503758557ec9d58e65ccacd31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/1*QpjFw2QcyWe-X5VxATY7Gw.gif"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">R 的物理意义(<a class="ae kf" href="http://www.biostathandbook.com/linearregression.html" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="5c15" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">相同的代码库可以在这里找到:</p><div class="ll lm gp gr ln lo"><a href="https://github.com/anishmahapatra01/MasterDataScience/tree/master/Course02-machineLearning-I/01LinearRegression" rel="noopener  ugc nofollow" target="_blank"><div class="lp ab fo"><div class="lq ab lr cl cj ls"><h2 class="bd iu gy z fp lt fr fs lu fu fw is bi translated">anishmahapatra 01/masterdata science</h2><div class="lv l"><h3 class="bd b gy z fp lt fr fs lu fu fw dk translated">在 GitHub 上创建一个帐户，为 anishmahapatra 01/masterdata science 开发做出贡献。</h3></div><div class="lw l"><p class="bd b dl z fp lt fr fs lu fu fw dk translated">github.com</p></div></div><div class="lx l"><div class="pa l lz ma mb lx mc jz lo"/></div></div></a></div><figure class="ng nh ni nj gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi pb"><img src="../Images/99acc0ac2e6b2b3a03e4e7482d973737.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LYicbna77jZ5T899"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated"><a class="ae kf" href="https://unsplash.com/@nervum?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">千斤顶 B </a>在<a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><h2 id="7b12" class="np me it bd mf nw nx dn mj ny nz dp mn kr oa ob mr kv oc od mv kz oe of mz og bi translated">高潮:</h2><p id="ec29" class="pw-post-body-paragraph kg kh it ki b kj nb kl km kn nc kp kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated"><strong class="ki iu"> R = 1 — (RSS/TSS) </strong> ~决定系数</p><figure class="ng nh ni nj gt ju gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/b3d6d57336d840d4dd2a15801c90e901.png" data-original-src="https://miro.medium.com/v2/resize:fit:290/format:webp/1*Pw8ke1v2rvMDI5J3QiVLog.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated"><a class="ae kf" href="https://en.wikipedia.org/wiki/Coefficient_of_determination" rel="noopener ugc nofollow" target="_blank">维基来源</a></p></figure><h1 id="667a" class="md me it bd mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na bi translated">RSE:剩余标准误差</h1><figure class="ng nh ni nj gt ju gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/b317e5f50e3cb6ec5465a53d9b7a1611.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*FP9K0Zt1g1ffmrX0cwMuaw.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated"><a class="ae kf" href="https://stats.stackexchange.com/questions/204238/why-divide-rss-by-n-2-to-get-rse" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="0c52" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">原因是试图获得回归中潜在误差方差的无偏估计量。什么是<a class="ae kf" href="https://stats.stackexchange.com/questions/57746/what-is-residual-standard-error" rel="noopener ugc nofollow" target="_blank">它</a>？</p><p id="f141" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这并不像上面展示的 R 那样被广泛使用。</p><div class="ll lm gp gr ln lo"><a rel="noopener follow" target="_blank" href="/running-jupyter-notebook-on-the-cloud-in-15-mins-azure-79b7797e4ef6"><div class="lp ab fo"><div class="lq ab lr cl cj ls"><h2 class="bd iu gy z fp lt fr fs lu fu fw is bi translated">在 15 分钟内在云上运行 Jupyter 笔记本电脑#Azure</h2><div class="lv l"><h3 class="bd b gy z fp lt fr fs lu fu fw dk translated">文章做到了标题所说的。在 Azure 笔记本电脑(免费或付费)上运行 Jupyter Notebook，其成本仅为……</h3></div><div class="lw l"><p class="bd b dl z fp lt fr fs lu fu fw dk translated">towardsdatascience.com</p></div></div><div class="lx l"><div class="pe l lz ma mb lx mc jz lo"/></div></div></a></div><h1 id="6c8b" class="md me it bd mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na bi translated">结论:</h1><p id="7fe6" class="pw-post-body-paragraph kg kh it ki b kj nb kl km kn nc kp kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">很好地达到了这里，特别是如果你是一个非技术人员。像我们其他人一样成为一名数据科学家的秘诀就是有勇气去谷歌搜索你的想法。正如我所承诺的，我希望你已经成功地理解了简单线性回归。我花了很多时间研究，并且非常喜欢写这篇文章。如果这对你有帮助，给我点爱！😄我也写关于<a class="ae kf" href="https://medium.com/@anishmahapatra/the-millennial-burn-out-is-real-a0acebff25ae" rel="noopener">千禧一代的生活方式</a>、<a class="ae kf" href="https://medium.com/@anishmahapatra/my-top-5-learnings-as-a-consultant-accc5989ec34" rel="noopener">咨询</a>、<a class="ae kf" href="https://chatbotslife.com/how-you-can-build-your-first-chatbot-using-rasa-in-under-15-minutes-ce557ea52f2f" rel="noopener ugc nofollow" target="_blank">聊天机器人</a>和<a class="ae kf" href="https://medium.com/@anishmahapatra/the-investment-guide-for-smart-noobs-9d0e2ca09457" rel="noopener">财经</a>！如果您对此有任何问题或建议，请随时通过<a class="ae kf" href="https://www.linkedin.com/in/anishmahapatra/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>联系我或关注我<a class="ae kf" href="https://medium.com/@anishmahapatra" rel="noopener">这里</a>，我很乐意听取您的想法！</p><div class="ll lm gp gr ln lo"><a href="https://www.linkedin.com/in/anishmahapatra/" rel="noopener  ugc nofollow" target="_blank"><div class="lp ab fo"><div class="lq ab lr cl cj ls"><h2 class="bd iu gy z fp lt fr fs lu fu fw is bi translated">Anish Mahapatra -数据科学家-穆适马公司| LinkedIn</h2><div class="lv l"><h3 class="bd b gy z fp lt fr fs lu fu fw dk translated">我正在努力理解数学、商业和技术如何帮助我们在未来做出更好的决策…</h3></div><div class="lw l"><p class="bd b dl z fp lt fr fs lu fu fw dk translated">www.linkedin.com</p></div></div><div class="lx l"><div class="pf l lz ma mb lx mc jz lo"/></div></div></a></div></div></div>    
</body>
</html>