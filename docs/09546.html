<html>
<head>
<title>TensorFlow Performance: Loading Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TensorFlow 性能:加载模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tensorflow-performance-loading-models-fb2d0dc340a3?source=collection_archive---------43-----------------------#2020-07-07">https://towardsdatascience.com/tensorflow-performance-loading-models-fb2d0dc340a3?source=collection_archive---------43-----------------------#2020-07-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="843c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">有许多方法可以保存训练好的模型。但是哪种格式加载最快呢？</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/b88bf46ee660d4526b5b3a67b9ebf148.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DypEjJMDC8YNOtGZ"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Kolleen Gladden 在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="6a3e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">模型的加载时间有时是一个被忽视的质量。然而，我们不能总是依赖我们的模型在缓存中舒适地等待，我们仍然需要快速预测。在这种情况下选择什么格式？最近我遇到了这个问题，我很惊讶两者之间的差异有多大。我希望以下对我的发现的简要总结会对你有所帮助。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="d21e" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">测量环境和模型</h1><p id="9763" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">我不打算对这个话题做全面的研究。相反，我将向你展示我在装有 Arch Linux 和最新的<strong class="ky ir"> TensorFlow 2.2 </strong>和<strong class="ky ir"> Python 3.8 </strong>的笔记本电脑上测得的加载时间。(我也试过 TensorFlow 2.3rc0，结果差不多。)我将为您提供<a class="ae kv" href="https://github.com/liborvaneksw/tf-performance/blob/master/model_loading.py" rel="noopener ugc nofollow" target="_blank">完整的脚本</a>，以便您可以在自己选择的环境中重现这些实验。如果你能在这种情况下与我分享结果，我会很高兴。</p><p id="8d55" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我对深度<strong class="ky ir">卷积神经网络</strong> (CNN)很感兴趣。我挑选了三个参数数量不同的知名模型——<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV2" rel="noopener ugc nofollow" target="_blank">MobileNet V2</a>、<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/DenseNet201" rel="noopener ugc nofollow" target="_blank"> DenseNet201 </a>和<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet152V2" rel="noopener ugc nofollow" target="_blank"> Resnet152 V2 </a>。所有这些都是<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/keras/applications" rel="noopener ugc nofollow" target="_blank"> tf.keras.applications </a>模块的一部分，很容易用于迁移学习。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="005f" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">可用选项</h1><p id="4e48" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">TensorFlow 2 支持两种基本格式— <strong class="ky ir"> SavedModel </strong>和<strong class="ky ir"> HDF5 </strong>。您可以保存整个模型，也可以只保存模型的重量。在后一种情况下，您必须重新创建模型架构，然后加载保存的权重。(为了详尽起见，您可以只保存架构，但是我们目前对这个选项不感兴趣。我们希望能够做出预测。)在<a class="ae kv" href="https://www.tensorflow.org/guide/keras/save_and_serialize" rel="noopener ugc nofollow" target="_blank">官方文档</a>中有很多信息，详情请参考那里。我觉得在这里重新表述是多余的。</p><p id="4543" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">小注意，我将<code class="fe mw mx my mz b">save()</code>方法的<code class="fe mw mx my mz b">include_optimizer</code>参数设置为<code class="fe mw mx my mz b">False.</code>，这对加载时间没有太大影响，但是我们的用例中不需要优化器，所以让我们忽略它。</p><h2 id="824a" class="na ma iq bd mb nb nc dn mf nd ne dp mj lf nf ng ml lj nh ni mn ln nj nk mp nl bi translated">TensorFlow Lite</h2><p id="0d81" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">除此之外，<a class="ae kv" href="https://www.tensorflow.org/lite/guide/get_started" rel="noopener ugc nofollow" target="_blank"> TensorFlow Lite </a>不得不提。它有自己的格式。由于精简版是为移动、嵌入式和物联网设备设计的，该模型应该更快。用于预测和加载。尤其是当你用强大的服务器代替我们的智能手机的时候。不幸的是，一切都是有代价的。如这里所解释的<a class="ae kv" href="https://www.tensorflow.org/lite/guide/ops_compatibility" rel="noopener ugc nofollow" target="_blank"/>:</p><blockquote class="nm nn no"><p id="2b17" class="kw kx np ky b kz la jr lb lc ld ju le nq lg lh li nr lk ll lm ns lo lp lq lr ij bi translated">由于 TensorFlow Lite 操作集小于 TensorFlow 的操作集，因此并非每个模型都是可转换的。即使对于受支持的操作，出于性能原因，有时也需要非常具体的使用模式。我们希望在未来的 TensorFlow Lite 版本中扩展支持的操作集。</p></blockquote></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="067d" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">结果</h1><p id="f290" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">要了解模型在参数数量和占用空间方面有多大，请查看下表。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/ae5aa933b8aeda164fdf86171918d03c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1WtWYQvw1X6eNQeGFXpg-g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">所选模型的大小(参数，MiB)。(*不同的解释者，不等于其余者。)</p></figure><p id="0aec" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，让我们看看装货时间。我还包括了参数的数量，所以您不需要参考上面的表。在“仅<strong class="ky ir">重量</strong>一栏中，测量的时间用于<strong class="ky ir">重新创建</strong>模型和<strong class="ky ir">加载</strong>保存的重量。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/a06c253a00995692861cd48d8d1aad12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EgHvu0pOV4KDnnwvLGpSgQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">所选模型的加载时间。(*不同的解释者，不等于其余者。)</p></figure><p id="67cb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">或者你喜欢图表的话，可以在下面图形化的看到。我省略了 TensorFlow lite，因为数量级是如此不同。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/e4f0a63c5cbe8c7cda36312e9df7568b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5TJBvkMS20jw3M5O27eItQ.png"/></div></div></figure><p id="8767" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">需要解释吗？新的 SavedModel 格式为我们提供了比旧的 HDF5 模型更好的改进。(我一直不喜欢<code class="fe mw mx my mz b">custom_objects</code>这个参数。)不幸的是装载时间非常糟糕。另一方面，TensorFlow lite 在这方面似乎做了很多工作。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="bb03" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">我们能优化模型吗？</h1><p id="6c31" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">不直接针对模型尺寸。在<a class="ae kv" href="https://www.tensorflow.org/model_optimization" rel="noopener ugc nofollow" target="_blank">官方文档</a>中有不少关于优化的资源。本页面主要关注 TensorFlow Lite，包括模型选择、训练和训练后优化。除此之外，您还可以直接查看适用于标准模型的<a class="ae kv" href="https://www.tensorflow.org/model_optimization/api_docs/python/tfmot" rel="noopener ugc nofollow" target="_blank"> TensorFlow 模型优化 Python API </a>。</p><p id="fcc5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以使用两种简单的方法:</p><ul class=""><li id="a66a" class="nw nx iq ky b kz la lc ld lf ny lj nz ln oa lr ob oc od oe bi translated"><strong class="ky ir">量化</strong>:将权重转换为预测减少的类型，</li><li id="644f" class="nw nx iq ky b kz of lc og lf oh lj oi ln oj lr ob oc od oe bi translated"><strong class="ky ir">修剪</strong>:去除无关紧要的权重。</li></ul><p id="f9fd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可以想象，这些方法影响了机器学习循环的许多部分。这包括模型大小，因此也包括加载时间，但主要关注的是预测时间，其副作用是精度可能会降低。</p><p id="c170" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，这些技术高度依赖于您问题领域。因此，我不认为我能得出足够一般的结论，对本文有用。你需要尝试。请随意<a class="ae kv" href="https://github.com/liborvaneksw/tf-performance/blob/master/model_loading.py" rel="noopener ugc nofollow" target="_blank">下载我的脚本</a>来测量模型加载时间，并添加您自己的优化模型进行比较。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="a067" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">最后的想法</h1><p id="ab2c" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">要记住的关键点很简单，就像博文本身一样。装载时间是一个问题。在你为你的问题选择合适的模型之前，你应该考虑如何使用它。你需要快速启动吗？也许你应该选择 TensorFlow Lite。并选择仅包含受支持操作的模型。有很多，但是如果你忽略了这一部分，最后的惊喜可能不会令人愉快。</p><p id="9d2c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">希望这篇文章对你有用。请随时评论，批评，提问！谢谢你的关注。</p></div></div>    
</body>
</html>