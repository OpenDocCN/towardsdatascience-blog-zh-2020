<html>
<head>
<title>Bounding Box Prediction from Scratch using PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 PyTorch 从头开始预测包围盒</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/bounding-box-prediction-from-scratch-using-pytorch-a8525da51ddc?source=collection_archive---------1-----------------------#2020-07-07">https://towardsdatascience.com/bounding-box-prediction-from-scratch-using-pytorch-a8525da51ddc?source=collection_archive---------1-----------------------#2020-07-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="77bd" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">多任务学习——包围盒回归+图像分类</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/7348684e728b043333c9519486673de7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F0CMfx6bGUHWjFSgQWSAEg.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者点击的图像</p></figure><p id="fbf7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对象检测是计算机视觉中非常流行的任务，其中，给定一幅图像，你预测图像中存在的对象周围的框(通常是矩形),并且还识别对象的类型。你的图像中可能有多个物体，有各种最先进的技术和架构来解决这个问题，如<a class="ae lr" href="https://arxiv.org/pdf/1506.01497.pdf" rel="noopener ugc nofollow" target="_blank"> Faster-RCNN </a>和<a class="ae lr" href="https://pjreddie.com/media/files/papers/YOLOv3.pdf" rel="noopener ugc nofollow" target="_blank"> YOLO v3 </a>。</p><p id="9e34" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">本文讨论了图像中只存在一个感兴趣对象的情况。这里的重点是如何正确地读取图像及其边界框、调整大小和执行放大，而不是模型本身。目标是很好地掌握对象检测背后的基本思想，您可以扩展它以更好地理解更复杂的技术。</p><p id="4b16" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这里有一个笔记本的链接，其中包含了我在本文中使用的所有代码:<a class="ae lr" href="https://jovian.ml/aakanksha-ns/road-signs-bounding-box-prediction" rel="noopener ugc nofollow" target="_blank">https://jovian . ml/aakanksha-ns/road-signs-bounding-box-prediction</a></p><p id="9db1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果你是深度学习或 PyTorch 的新手，或者只是需要复习，这可能会让你感兴趣:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ls lt l"/></div></figure><h1 id="16f1" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">问题陈述</h1><p id="7f01" class="pw-post-body-paragraph kv kw iq kx b ky mm jr la lb mn ju ld le mo lg lh li mp lk ll lm mq lo lp lq ij bi translated">给定由路标组成的图像，预测路标周围的边界框并识别路标的类型。</p><p id="e7eb" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这些迹象可能属于四个不同的类别:</p><ul class=""><li id="d679" class="mr ms iq kx b ky kz lb lc le mt li mu lm mv lq mw mx my mz bi translated">交通灯</li><li id="8001" class="mr ms iq kx b ky na lb nb le nc li nd lm ne lq mw mx my mz bi translated">停止</li><li id="24d8" class="mr ms iq kx b ky na lb nb le nc li nd lm ne lq mw mx my mz bi translated">速度限制</li><li id="8ba4" class="mr ms iq kx b ky na lb nb le nc li nd lm ne lq mw mx my mz bi translated">人行横道</li></ul><p id="447b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这被称为多任务学习问题，因为它涉及执行两个任务——1)回归以找到边界框坐标，2)分类以识别路标的类型</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/fa2d18a26d89e185418257ff03405221.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m_z7HSOmWdwgaU_eU5h7ew.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">样本图像。<a class="ae lr" href="https://www.kaggle.com/andrewmvd/road-sign-detection" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><h1 id="ee08" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">资料组</h1><p id="d727" class="pw-post-body-paragraph kv kw iq kx b ky mm jr la lb mn ju ld le mo lg lh li mp lk ll lm mq lo lp lq ij bi translated">我使用了 Kaggle 的路标检测数据集:</p><div class="ng nh gp gr ni nj"><a href="https://www.kaggle.com/andrewmvd/road-sign-detection" rel="noopener  ugc nofollow" target="_blank"><div class="nk ab fo"><div class="nl ab nm cl cj nn"><h2 class="bd ir gy z fp no fr fs np fu fw ip bi translated">路标检测</h2><div class="nq l"><h3 class="bd b gy z fp no fr fs np fu fw dk translated">属于 4 类的 877 个图像。</h3></div><div class="nr l"><p class="bd b dl z fp no fr fs np fu fw dk translated">www.kaggle.com</p></div></div><div class="ns l"><div class="nt l nu nv nw ns nx kp nj"/></div></div></a></div><p id="fc3e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">它由 877 幅图像组成。这是一个非常不平衡的数据集，大多数图像属于<code class="fe ny nz oa ob b">speed limit</code>类，但由于我们更关注边界框预测，我们可以忽略这种不平衡。</p><h1 id="faee" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">加载数据</h1><p id="a161" class="pw-post-body-paragraph kv kw iq kx b ky mm jr la lb mn ju ld le mo lg lh li mp lk ll lm mq lo lp lq ij bi translated">每个图像的注释都存储在单独的<code class="fe ny nz oa ob b">XML</code>文件中。我按照以下步骤创建了培训数据框架:</p><ul class=""><li id="b181" class="mr ms iq kx b ky kz lb lc le mt li mu lm mv lq mw mx my mz bi translated">浏览培训目录以获得所有<code class="fe ny nz oa ob b">.xml</code>文件的列表。</li><li id="c9d5" class="mr ms iq kx b ky na lb nb le nc li nd lm ne lq mw mx my mz bi translated">使用<code class="fe ny nz oa ob b">xml.etree.ElementTree</code>解析<code class="fe ny nz oa ob b">.xml</code>文件</li><li id="a844" class="mr ms iq kx b ky na lb nb le nc li nd lm ne lq mw mx my mz bi translated">为每个图像创建一个由<code class="fe ny nz oa ob b">filepath</code>、<code class="fe ny nz oa ob b">width</code>、<code class="fe ny nz oa ob b">height</code>、边界框坐标(<code class="fe ny nz oa ob b">xmin</code>、<code class="fe ny nz oa ob b">xmax</code>、<code class="fe ny nz oa ob b">ymin</code>、<code class="fe ny nz oa ob b">ymax</code>)和<code class="fe ny nz oa ob b">class</code>组成的字典，并将该字典附加到一个列表中。</li><li id="c0fd" class="mr ms iq kx b ky na lb nb le nc li nd lm ne lq mw mx my mz bi translated">使用图像统计字典列表创建一个熊猫数据框架。</li></ul><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div></figure><ul class=""><li id="b14a" class="mr ms iq kx b ky kz lb lc le mt li mu lm mv lq mw mx my mz bi translated">标签编码<code class="fe ny nz oa ob b">class</code>列</li></ul><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div></figure><h1 id="d15e" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">调整图像大小和边界框</h1><p id="09da" class="pw-post-body-paragraph kv kw iq kx b ky mm jr la lb mn ju ld le mo lg lh li mp lk ll lm mq lo lp lq ij bi translated">由于训练计算机视觉模型需要图像具有相同的大小，因此我们需要调整图像及其相应的边界框的大小。调整图像的大小很简单，但是调整边界框的大小有点棘手，因为每个框都与图像及其尺寸相关。</p><p id="3017" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">以下是调整边界框大小的工作方式:</p><ul class=""><li id="30e9" class="mr ms iq kx b ky kz lb lc le mt li mu lm mv lq mw mx my mz bi translated">将边框转换为与其对应的图像大小相同的图像(称为蒙版)。这个遮罩只有背景的<code class="fe ny nz oa ob b">0</code>和边界框覆盖的区域的<code class="fe ny nz oa ob b">1</code>。</li></ul><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">原象</p></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">边界框的遮罩</p></figure><ul class=""><li id="f58f" class="mr ms iq kx b ky kz lb lc le mt li mu lm mv lq mw mx my mz bi translated">将遮罩调整到所需的尺寸。</li><li id="b629" class="mr ms iq kx b ky na lb nb le nc li nd lm ne lq mw mx my mz bi translated">从调整大小的遮罩中提取边界框坐标。</li></ul><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">辅助函数从包围盒中创建遮罩，从遮罩中提取包围盒坐标</p></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">函数来调整图像大小，写入新路径，并获取调整后的边界框坐标</p></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div></figure><h1 id="ed7e" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">数据扩充</h1><p id="8284" class="pw-post-body-paragraph kv kw iq kx b ky mm jr la lb mn ju ld le mo lg lh li mp lk ll lm mq lo lp lq ij bi translated">数据扩充是一种通过使用现有图像的不同变体创建新的训练图像来更好地概括我们的模型的技术。在我们当前的训练集中，我们只有 800 张图像，因此数据扩充对于确保我们的模型不会过度拟合非常重要。</p><p id="f867" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于这个问题，我使用了翻转，旋转，中心裁剪和随机裁剪。我在本文中讨论了各种数据扩充技术:</p><div class="ng nh gp gr ni nj"><a rel="noopener follow" target="_blank" href="/image-processing-techniques-for-computer-vision-11f92f511e21"><div class="nk ab fo"><div class="nl ab nm cl cj nn"><h2 class="bd ir gy z fp no fr fs np fu fw ip bi translated">计算机视觉的图像处理技术</h2><div class="nq l"><h3 class="bd b gy z fp no fr fs np fu fw dk translated">图像处理是计算机视觉的一个组成部分。我们几乎总是想调整图像大小，增加数据…</h3></div><div class="nr l"><p class="bd b dl z fp no fr fs np fu fw dk translated">towardsdatascience.com</p></div></div><div class="ns l"><div class="od l nu nv nw ns nx kp nj"/></div></div></a></div><p id="1542" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这里唯一要记住的是确保边界框也以和图像相同的方式变换。为此，我们遵循与调整大小相同的方法—将边界框转换为遮罩，将与原始图像相同的变换应用于遮罩，并提取边界框坐标。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">辅助函数用于居中裁剪和随机裁剪图像</p></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">变换图像和遮罩</p></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">显示边界框</p></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div></figure><h1 id="9d5c" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">PyTorch 数据集</h1><p id="4ad9" class="pw-post-body-paragraph kv kw iq kx b ky mm jr la lb mn ju ld le mo lg lh li mp lk ll lm mq lo lp lq ij bi translated">现在我们已经有了数据扩充，我们可以进行训练验证分割并创建 PyTorch 数据集。我们使用 ImageNet stats 标准化图像，因为我们使用预训练的 ResNet 模型，并在训练时在我们的数据集中应用数据扩充。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">列车有效分离</p></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">创建训练和有效数据集</p></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">设置批处理大小和创建数据加载器</p></figure><h1 id="84e2" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">PyTorch 模型</h1><p id="a5fa" class="pw-post-body-paragraph kv kw iq kx b ky mm jr la lb mn ju ld le mo lg lh li mp lk ll lm mq lo lp lq ij bi translated">对于这个模型，我使用了一个非常简单的预训练 resNet-34 模型。因为我们在这里有两个任务要完成，所以有两个最后的层——边界框回归器和图像分类器。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div></figure><h1 id="7c26" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">培养</h1><p id="f026" class="pw-post-body-paragraph kv kw iq kx b ky mm jr la lb mn ju ld le mo lg lh li mp lk ll lm mq lo lp lq ij bi translated">对于损失，我们需要考虑分类损失和包围盒回归损失，因此我们使用交叉熵和 L1 损失(真实值和预测坐标之间的所有绝对差的总和)的组合。我用因子 1000 来衡量 L1 损失，因为分类和回归损失都在相似的范围内。除此之外，这是一个标准的 PyTorch 训练循环(使用 GPU):</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div></figure><h1 id="08c1" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">对测试图像的预测</h1><p id="7ab3" class="pw-post-body-paragraph kv kw iq kx b ky mm jr la lb mn ju ld le mo lg lh li mp lk ll lm mq lo lp lq ij bi translated">既然我们已经完成了训练，我们可以选择一个随机的图像并在上面测试我们的模型。即使我们有相当少量的训练图像，我们最终在测试图像上获得了相当不错的预测。</p><p id="cfd6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这将是一个有趣的练习，用你的手机拍一张真实的照片，并测试模型。另一个有趣的实验是不执行任何数据扩充，训练模型并比较两个模型。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc lt l"/></div></figure><h1 id="b0fc" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">结论</h1><p id="1bd7" class="pw-post-body-paragraph kv kw iq kx b ky mm jr la lb mn ju ld le mo lg lh li mp lk ll lm mq lo lp lq ij bi translated">既然我们已经介绍了对象检测的基本原理，并从头开始实现了它，您可以将这些想法扩展到多对象的情况，并尝试更复杂的模型，如 RCNN 和 YOLO！此外，查看这个名为<a class="ae lr" href="https://github.com/albumentations-team/albumentations" rel="noopener ugc nofollow" target="_blank">albuminations</a>的超酷库，轻松执行数据扩充。</p><h1 id="5a23" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">参考</h1><ul class=""><li id="b2a2" class="mr ms iq kx b ky mm lb mn le oe li of lm og lq mw mx my mz bi translated">旧金山大学<a class="ae lr" href="https://www.usfca.edu/arts-sciences/graduate-programs/data-science" rel="noopener ugc nofollow" target="_blank">数据科学</a>硕士项目的深度学习夏季选修课</li><li id="da22" class="mr ms iq kx b ky na lb nb le nc li nd lm ne lq mw mx my mz bi translated"><a class="ae lr" href="https://www.usfca.edu/data-institute/certificates/fundamentals-deep-learning" rel="noopener ugc nofollow" target="_blank">https://www . usfca . edu/data-institute/certificates/fundamentals-deep-learning</a></li></ul></div></div>    
</body>
</html>