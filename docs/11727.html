<html>
<head>
<title>Implementing AlexNet CNN Architecture Using TensorFlow 2.0+ and Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 TensorFlow 2.0+和 Keras 实现 AlexNet CNN 架构</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/implementing-alexnet-cnn-architecture-using-tensorflow-2-0-and-keras-2113e090ad98?source=collection_archive---------1-----------------------#2020-08-14">https://towardsdatascience.com/implementing-alexnet-cnn-architecture-using-tensorflow-2-0-and-keras-2113e090ad98?source=collection_archive---------1-----------------------#2020-08-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/b4f7f5f03ea34c31c8086571316fd59f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sm5RHZoXeXbzYmPPpcW3-w.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">由<a class="ae jg" href="https://unsplash.com/@urielsc26?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">乌列尔 SC </a>在<a class="ae jg" href="https://unsplash.com/s/photos/neural-network?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h2 id="3aa6" class="jh ji jj bd b dl jk jl jm jn jo jp dk jq translated" aria-label="kicker paragraph">技术的</h2><div class=""/><div class=""><h2 id="02aa" class="pw-subtitle-paragraph kp js jj bd b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg dk translated">了解如何实施 2012 年开启深度卷积神经网络革命的神经网络架构。</h2></div><blockquote class="lh li lj"><p id="f8e2" class="lk ll lm ln b lo lp kt lq lr ls kw lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated"><a class="ae jg" href="https://www.oreilly.com/live-events/practical-introduction-to-the-world-of-computer-vision-and-deep-learning-with-tensorflow-keras/0636920060577/0636920061406/" rel="noopener ugc nofollow" target="_blank"> <strong class="ln jt">在我主持的这个现场培训环节，用 TensorFlow 和 Keras 学习 AI 和深度学习的基础知识。</strong> </a></p></blockquote><h1 id="0994" class="mh mi jj bd mj mk ml mm mn mo mp mq mr ky ms kz mt lb mu lc mv le mw lf mx my bi translated">介绍</h1><p id="334e" class="pw-post-body-paragraph lk ll jj ln b lo mz kt lq lr na kw lt nb nc lw lx nd ne ma mb nf ng me mf mg im bi translated"><strong class="ln jt">本文的主要内容将介绍如何使用 TensorFlow 和 Keras 实现 AlexNet 卷积神经网络(CNN)架构。</strong></p><p id="da9b" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">但首先，请允许我提供一个 AlexNet CNN 架构背后的简短背景。</p><p id="4d5c" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">AlexNet 在赢得 ImageNet 大规模视觉识别挑战赛(ILSSVRC 2012 竞赛)时首次用于公共场合。正是在这次比赛中，AlexNet 展示了深度卷积神经网络可以用于解决图像分类。</p><p id="251f" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">AlexNet 以微弱优势赢得了 ILSVRC 2012 大赛。</p><p id="3bb7" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">详细介绍 CNN 架构内部组件的<a class="ae jg" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" rel="noopener ugc nofollow" target="_blank">研究论文</a>也介绍了一些新颖的技术和方法，如高效的计算资源利用；数据扩充、GPU 训练和防止神经网络内过度拟合的多种策略。</p><p id="baca" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">我写了一篇<a class="ae jg" rel="noopener" target="_blank" href="/what-alexnet-brought-to-the-world-of-deep-learning-46c7974b46fc">文章</a>，介绍了 AlexNet 带给计算机视觉和深度学习世界的关键思想和技术。</p><h2 id="4910" class="nh mi jj bd mj ni nj dn mn nk nl dp mr nb nm nn mt nd no np mv nf nq nr mx jp bi translated">以下是本文中的一些关键学习目标:</h2><ul class=""><li id="104a" class="ns nt jj ln b lo mz lr na nb nu nd nv nf nw mg nx ny nz oa bi translated"><strong class="ln jt"> <em class="lm">介绍用 Keras 和 TensorFlow 实现神经网络</em> </strong></li><li id="2544" class="ns nt jj ln b lo ob lr oc nb od nd oe nf of mg nx ny nz oa bi translated"><strong class="ln jt"> <em class="lm">用 TensorFlow 进行数据预处理</em> </strong></li><li id="0e36" class="ns nt jj ln b lo ob lr oc nb od nd oe nf of mg nx ny nz oa bi translated"><strong class="ln jt"> <em class="lm">用冲浪板训练可视化</em> </strong></li><li id="bbea" class="ns nt jj ln b lo ob lr oc nb od nd oe nf of mg nx ny nz oa bi translated"><strong class="ln jt"> <em class="lm">标准机器学习术语和术语的描述</em> </strong></li></ul></div><div class="ab cl og oh hx oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="im in io ip iq"><h1 id="f5f3" class="mh mi jj bd mj mk on mm mn mo oo mq mr ky op kz mt lb oq lc mv le or lf mx my bi translated">AlexNet 实现</h1><p id="2800" class="pw-post-body-paragraph lk ll jj ln b lo mz kt lq lr na kw lt nb nc lw lx nd ne ma mb nf ng me mf mg im bi translated">AlexNet CNN 可能是理解深度学习概念和技术的最简单的方法之一。</p><p id="3e35" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">与最近几年出现的一些最先进的 CNN 架构相比，AlexNet 并不是一个复杂的架构。</p><p id="2b5f" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">AlexNet 对于初学者和中级深度学习从业者来说足够简单，可以获得一些关于模型实现技术的良好实践。</p><p id="d55c" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">本文中的所有代码都是使用 Jupyter 实验室编写的。在本文的最后是一个 GitHub 链接，其中包含了实现部分的所有代码。</p><p id="7cbc" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated"><em class="lm">那么我们开始吧。</em></p><h2 id="da63" class="nh mi jj bd mj ni nj dn mn nk nl dp mr nb nm nn mt nd no np mv nf nq nr mx jp bi translated">1.工具和库</h2><p id="11e4" class="pw-post-body-paragraph lk ll jj ln b lo mz kt lq lr na kw lt nb nc lw lx nd ne ma mb nf ng me mf mg im bi translated">我们从导入以下库开始实施:</p><ul class=""><li id="9c97" class="ns nt jj ln b lo lp lr ls nb os nd ot nf ou mg nx ny nz oa bi translated"><a class="ae jg" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"><strong class="ln jt"><em class="lm">tensor flow</em></strong></a><em class="lm">:机器学习模型实现、训练、部署的开源平台。</em></li><li id="aa9e" class="ns nt jj ln b lo ob lr oc nb od nd oe nf of mg nx ny nz oa bi translated"><a class="ae jg" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"><strong class="ln jt"><em class="lm">Keras</em></strong></a><em class="lm">:一个开源库，用于实现运行在 CPU 和 GPU 上的神经网络架构。</em></li><li id="ee3b" class="ns nt jj ln b lo ob lr oc nb od nd oe nf of mg nx ny nz oa bi translated"><a class="ae jg" href="https://matplotlib.org/" rel="noopener ugc nofollow" target="_blank"><strong class="ln jt"><em class="lm">Matplotlib</em></strong></a><em class="lm">:可视化 python 工具，用于演示交互式图表和图像。</em></li></ul><pre class="ov ow ox oy gt oz pa pb pc aw pd bi"><span id="17ff" class="nh mi jj pa b gy pe pf l pg ph">import tensorflow as tf<br/>from tensorflow import keras<br/>import matplotlib.pyplot as plt<br/>import os<br/>import time</span></pre></div><div class="ab cl og oh hx oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="im in io ip iq"><h2 id="8464" class="nh mi jj bd mj ni nj dn mn nk nl dp mr nb nm nn mt nd no np mv nf nq nr mx jp bi translated">2.资料组</h2><p id="8175" class="pw-post-body-paragraph lk ll jj ln b lo mz kt lq lr na kw lt nb nc lw lx nd ne ma mb nf ng me mf mg im bi translated">CIFAR-10 数据集包含 60，000 幅彩色图像，每幅图像的尺寸为<em class="lm"> 32x32px </em>。数据集内的图像内容是从 10 个类别中取样的。</p><figure class="ov ow ox oy gt iv gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/0df822836aa0dbc631a0224f52ab3597.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*JpVHW8V5SJCysjPDR6oEtg.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank">CIFAR-10 数据集中的类</a></p></figure><p id="e4f8" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">CIFAR-10 图像由 AlexNet 网络的一些创建者、<a class="ae jg" href="https://www.cs.toronto.edu/~kriz/index.html" rel="noopener ugc nofollow" target="_blank"> Alex Krizhevsky </a>和<a class="ae jg" href="https://www.cs.toronto.edu/~hinton/" rel="noopener ugc nofollow" target="_blank"> Geoffrey Hinton </a>聚合而成。</p><p id="0fed" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">深度学习 Keras 库通过其<a class="ae jg" href="https://keras.io/api/datasets/" rel="noopener ugc nofollow" target="_blank">数据集模块</a>，相对容易地提供对 CIFAR10 数据集的直接访问。使用 Keras，访问通用数据集，如<a class="ae jg" href="https://keras.io/api/datasets/cifar10/" rel="noopener ugc nofollow" target="_blank"> CIFAR10 </a>或<a class="ae jg" href="https://keras.io/api/datasets/mnist/" rel="noopener ugc nofollow" target="_blank"> MNIST </a>，变成了一项微不足道的任务。</p><pre class="ov ow ox oy gt oz pa pb pc aw pd bi"><span id="8fe1" class="nh mi jj pa b gy pe pf l pg ph">(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()</span></pre><p id="d98b" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">为了在可视化阶段引用图像的类名，用变量名<code class="fe pj pk pl pa b"><em class="lm">CLASS_NAMES</em>.</code>初始化包含类的 python 列表</p><pre class="ov ow ox oy gt oz pa pb pc aw pd bi"><span id="0a31" class="nh mi jj pa b gy pe pf l pg ph">CLASS_NAMES= ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']</span></pre><p id="cf2c" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">默认情况下，CIFAR 数据集分为 50，000 个训练数据和 10，000 个测试数据。我们需要的数据集的最后一个分区是验证数据。</p><p id="b3a1" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">通过获取训练数据中的最后 5000 个图像来获得验证数据。</p><pre class="ov ow ox oy gt oz pa pb pc aw pd bi"><span id="efbe" class="nh mi jj pa b gy pe pf l pg ph">validation_images, validation_labels = train_images[:5000], train_labels[:5000]<br/>train_images, train_labels = train_images[5000:], train_labels[5000:]</span></pre><blockquote class="lh li lj"><p id="d197" class="lk ll lm ln b lo lp kt lq lr ls kw lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated"><strong class="ln jt">训练数据集</strong>:这是我们用来直接训练神经网络的一组数据集。训练数据是指在训练期间暴露给神经网络的数据集分区。</p><p id="df90" class="lk ll lm ln b lo lp kt lq lr ls kw lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated"><strong class="ln jt">验证数据集</strong>:这组数据集在训练期间被用来评估网络在不同迭代中的性能。</p><p id="cc19" class="lk ll lm ln b lo lp kt lq lr ls kw lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated"><strong class="ln jt">测试数据集</strong>:数据集的这个分区在训练阶段完成后评估我们网络的性能。</p></blockquote><p id="d0f0" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">TensorFlow 提供了一套功能和操作，可通过定义的输入管道轻松操作和修改数据。</p><p id="ba62" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">为了能够访问这些方法和过程，我们需要将数据集转换为 TensorFlow 熟悉的高效数据表示。这是使用<a class="ae jg" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset" rel="noopener ugc nofollow" target="_blank"><em class="lm">TF . data . dataset</em></a><em class="lm"/>API 实现的。</p><p id="e2d2" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">更具体地说，<a class="ae jg" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices" rel="noopener ugc nofollow" target="_blank"><em class="lm">TF . data . Dataset . from _ tensor _ slices</em></a>方法采用训练、测试和验证数据集分区，并返回相应的 TensorFlow 数据集表示。</p><pre class="ov ow ox oy gt oz pa pb pc aw pd bi"><span id="3f37" class="nh mi jj pa b gy pe pf l pg ph">train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))<br/>test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))<br/>validation_ds = tf.data.Dataset.from_tensor_slices((validation_images, validation_labels))</span></pre></div><div class="ab cl og oh hx oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="im in io ip iq"><h2 id="3372" class="nh mi jj bd mj ni nj dn mn nk nl dp mr nb nm nn mt nd no np mv nf nq nr mx jp bi translated">3.预处理</h2><p id="393d" class="pw-post-body-paragraph lk ll jj ln b lo mz kt lq lr na kw lt nb nc lw lx nd ne ma mb nf ng me mf mg im bi translated">任何机器学习中的预处理都与数据从一种形式到另一种形式的转换相关联。</p><p id="afc1" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">通常，进行预处理是为了确保所使用的数据符合适当的格式。</p><p id="c263" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">首先，让我们将 CIFAR-10 数据集中的图像可视化。</p><p id="2371" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">下面的代码片段使用 Matplotlib 库将来自五幅训练图像的数据的像素信息呈现到实际图像中。还存在图像中每个描绘的内容所属的类别的指示符。</p><p id="03ac" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated"><em class="lm">原谅图像的模糊；CIFAR-10 图像尺寸较小，这使得实际图片的可视化有点困难。</em></p><pre class="ov ow ox oy gt oz pa pb pc aw pd bi"><span id="7eb8" class="nh mi jj pa b gy pe pf l pg ph">plt.figure(figsize=(20,20))<br/>for i, (image, label) in enumerate(train_ds.take(5)):<br/>    ax = plt.subplot(5,5,i+1)<br/>    plt.imshow(image)<br/>    plt.title(CLASS_NAMES[label.numpy()[0]])<br/>    plt.axis('off')</span></pre><figure class="ov ow ox oy gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pm"><img src="../Images/4fbab8ace4760852e49c5ff45e761e38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4tfbf17Xg3KrtYF-N3vcPQ.png"/></div></div></figure><p id="99a3" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">将对呈现给网络的数据施加的主要预处理转换是:</p><ul class=""><li id="5ef1" class="ns nt jj ln b lo lp lr ls nb os nd ot nf ou mg nx ny nz oa bi translated">标准化和规范化图像。</li><li id="c627" class="ns nt jj ln b lo ob lr oc nb od nd oe nf of mg nx ny nz oa bi translated">将图像尺寸从<em class="lm"> 32x32 </em>调整到<em class="lm"> 227x227 </em>。AlexNet 网络输入需要 227x227 的图像。</li></ul><p id="00bc" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">我们将创建一个名为<code class="fe pj pk pl pa b">process_images.</code>的函数</p><p id="e355" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">该函数将执行我们需要的所有数据预处理工作。这个函数在机器学习工作流程中被进一步调用。</p><pre class="ov ow ox oy gt oz pa pb pc aw pd bi"><span id="10df" class="nh mi jj pa b gy pe pf l pg ph">def process_images(image, label):<br/>    # Normalize images to have a mean of 0 and standard deviation of 1<br/>    image = tf.image.per_image_standardization(image)<br/>    # Resize images from 32x32 to 277x277<br/>    image = tf.image.resize(image, (227,227))<br/>    return image, label</span></pre><h2 id="d99f" class="nh mi jj bd mj ni nj dn mn nk nl dp mr nb nm nn mt nd no np mv nf nq nr mx jp bi translated">4.数据/输入管道</h2><p id="3b32" class="pw-post-body-paragraph lk ll jj ln b lo mz kt lq lr na kw lt nb nc lw lx nd ne ma mb nf ng me mf mg im bi translated">到目前为止，我们已经获得并分区了数据集，并创建了一个函数来处理数据集。下一步是构建输入管道。</p><p id="ec74" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">输入/数据管道被描述为一系列连续调用的函数或方法。输入管道是一系列函数，这些函数或者作用于数据，或者对流经管道的数据执行操作。</p><p id="ea1c" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">让我们获得我们创建的每个数据集分区的大小；数据集分区的大小是必需的，以确保数据集在通过网络之前被彻底混洗。</p><pre class="ov ow ox oy gt oz pa pb pc aw pd bi"><span id="0666" class="nh mi jj pa b gy pe pf l pg ph">train_ds_size = tf.data.experimental.cardinality(train_ds).numpy()<br/>test_ds_size = tf.data.experimental.cardinality(test_ds).numpy()<br/>validation_ds_size = tf.data.experimental.cardinality(validation_ds).numpy()<br/>print("Training data size:", train_ds_size)<br/>print("Test data size:", test_ds_size)<br/>print("Validation data size:", validation_ds_size)</span></pre><p id="1e26" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated"><strong class="ln jt">对于我们的基本输入/数据管道，我们将进行三个主要操作:</strong></p><ol class=""><li id="35ce" class="ns nt jj ln b lo lp lr ls nb os nd ot nf ou mg pn ny nz oa bi translated"><strong class="ln jt">预处理数据集内的数据</strong></li><li id="a9a2" class="ns nt jj ln b lo ob lr oc nb od nd oe nf of mg pn ny nz oa bi translated"><strong class="ln jt">打乱数据集</strong></li><li id="f3f8" class="ns nt jj ln b lo ob lr oc nb od nd oe nf of mg pn ny nz oa bi translated"><strong class="ln jt">数据集内的批量数据</strong></li></ol><pre class="ov ow ox oy gt oz pa pb pc aw pd bi"><span id="0406" class="nh mi jj pa b gy pe pf l pg ph">train_ds = (train_ds<br/>                  .map(process_images)<br/>                  .shuffle(buffer_size=train_ds_size)<br/>                  .batch(batch_size=32, drop_remainder=True))</span><span id="29a7" class="nh mi jj pa b gy po pf l pg ph">test_ds = (test_ds<br/>                  .map(process_images)<br/>                  .shuffle(buffer_size=train_ds_size)<br/>                  .batch(batch_size=32, drop_remainder=True))</span><span id="b44f" class="nh mi jj pa b gy po pf l pg ph">validation_ds = (validation_ds<br/>                  .map(process_images)<br/>                  .shuffle(buffer_size=train_ds_size)<br/>                  .batch(batch_size=32, drop_remainder=True))</span></pre></div><div class="ab cl og oh hx oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="im in io ip iq"><h2 id="86fd" class="nh mi jj bd mj ni nj dn mn nk nl dp mr nb nm nn mt nd no np mv nf nq nr mx jp bi translated">5.模型实现</h2><p id="6b7c" class="pw-post-body-paragraph lk ll jj ln b lo mz kt lq lr na kw lt nb nc lw lx nd ne ma mb nf ng me mf mg im bi translated">在本节中，我们将从头开始实现 AlexNet CNN 架构。</p><p id="c340" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">通过利用<a class="ae jg" href="https://www.tensorflow.org/api_docs/python/tf/keras/Sequential" rel="noopener ugc nofollow" target="_blank"> Keras Sequential API </a>，我们可以在彼此堆叠的模型中实现连续的神经网络层。</p><p id="1b63" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">以下是 AlexNet CNN 架构组成的层类型，并附有简要说明:</p><blockquote class="lh li lj"><p id="695d" class="lk ll lm ln b lo lp kt lq lr ls kw lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated"><strong class="ln jt">卷积层</strong>:卷积是一个数学术语，描述两组元素之间的点积相乘。在深度学习中，卷积运算作用于卷积层中的滤波器/内核和图像数据阵列。因此，卷积层只是一个包含滤波器和通过卷积神经网络的图像之间的卷积运算的层。</p><p id="b55c" class="lk ll lm ln b lo lp kt lq lr ls kw lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated"><a class="ae jg" rel="noopener" target="_blank" href="/batch-normalization-explained-algorithm-breakdown-23d2794511c"> <strong class="ln jt">批量标准化层</strong> </a>:批量标准化是一种技术，它通过引入一个附加层来减轻神经网络内不稳定梯度的影响，该附加层对来自前一层的输入执行操作。这些操作对输入值进行标准化和规范化，然后通过缩放和移位操作转换输入值。</p><p id="7ef6" class="lk ll lm ln b lo lp kt lq lr ls kw lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated"><a class="ae jg" rel="noopener" target="_blank" href="/you-should-understand-sub-sampling-layers-within-deep-learning-b51016acd551">下面的 max-pooling 操作有一个 2x2 的窗口，并滑过输入数据，输出内核感受域内像素的平均值。</a></p><p id="618c" class="lk ll lm ln b lo lp kt lq lr ls kw lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated"><strong class="ln jt">展平图层</strong>:取一个输入形状，将输入图像数据展平成一维数组。</p><p id="ead2" class="lk ll lm ln b lo lp kt lq lr ls kw lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated"><strong class="ln jt">密集层</strong>:密集层内部嵌入了任意数量的单元/神经元。每个神经元都是一个感知器。</p></blockquote><p id="3ea7" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated"><strong class="ln jt">Alex net CNN 中值得一提的一些其他操作和技术有:</strong></p><blockquote class="lh li lj"><p id="2eca" class="lk ll lm ln b lo lp kt lq lr ls kw lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated"><a class="ae jg" href="https://en.wikipedia.org/wiki/Activation_function#:~:text=In%20artificial%20neural%20networks%2C%20the,0)%2C%20depending%20on%20input." rel="noopener ugc nofollow" target="_blank"> <strong class="ln jt">激活函数</strong> </a>:将神经元的结果或信号转化为归一化输出的数学运算。作为神经网络组件的激活函数的目的是在网络中引入非线性。包含激活函数使神经网络具有更大的表示能力和解决复杂的函数。</p><p id="9199" class="lk ll lm ln b lo lp kt lq lr ls kw lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated"><strong class="ln jt">整流线性单元激活函数(ReLU) </strong>:一种对神经元的值结果进行转换的激活函数。ReLU 对来自神经元的值施加的变换由公式<strong class="ln jt"> <em class="jj"> y=max(0，x) </em> </strong>表示。ReLU 激活函数将来自神经元的任何负值钳制为 0，而正值保持不变。这种数学变换的结果被用作当前层的输出，并被用作神经网络内的连续层的输入。</p><p id="6cbd" class="lk ll lm ln b lo lp kt lq lr ls kw lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated"><strong class="ln jt"> Softmax 激活函数</strong>:一种激活函数，用于导出输入向量中一组数字的概率分布。softmax 激活函数的输出是一个向量，其中它的一组值表示一个类或事件发生的概率。向量中的值加起来都是 1。</p><p id="4cfa" class="lk ll lm ln b lo lp kt lq lr ls kw lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated"><a class="ae jg" rel="noopener" target="_blank" href="/understanding-and-implementing-dropout-in-tensorflow-and-keras-a8a3a02c1bfa"> <strong class="ln jt">辍学</strong> </a> <strong class="ln jt"> : </strong>辍学技术通过随机减少神经网络内互连神经元的数量来工作。在每一个训练步骤中，每个神经元都有可能被遗漏，或者更确切地说，被排除在连接神经元的整理贡献之外。</p></blockquote><p id="3b52" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated"><strong class="ln jt">代码片段代表 AlexNet CNN 架构的 Keras 实现。</strong></p><pre class="ov ow ox oy gt oz pa pb pc aw pd bi"><span id="7dc7" class="nh mi jj pa b gy pe pf l pg ph">model = keras.models.Sequential([<br/>    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3)),<br/>    keras.layers.BatchNormalization(),<br/>    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),<br/>    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding="same"),<br/>    keras.layers.BatchNormalization(),<br/>    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),<br/>    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding="same"),<br/>    keras.layers.BatchNormalization(),<br/>    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding="same"),<br/>    keras.layers.BatchNormalization(),<br/>    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding="same"),<br/>    keras.layers.BatchNormalization(),<br/>    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),<br/>    keras.layers.Flatten(),<br/>    keras.layers.Dense(4096, activation='relu'),<br/>    keras.layers.Dropout(0.5),<br/>    keras.layers.Dense(4096, activation='relu'),<br/>    keras.layers.Dropout(0.5),<br/>    keras.layers.Dense(10, activation='softmax')<br/>])</span></pre><h2 id="006f" class="nh mi jj bd mj ni nj dn mn nk nl dp mr nb nm nn mt nd no np mv nf nq nr mx jp bi translated">6.张量板</h2><p id="eb4d" class="pw-post-body-paragraph lk ll jj ln b lo mz kt lq lr na kw lt nb nc lw lx nd ne ma mb nf ng me mf mg im bi translated">至此，我们已经实现了自定义的 AlexNet 网络。</p><p id="5456" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">在我们继续用数据对网络进行训练、验证和评估之前，我们首先必须设置一些监控设施。</p><p id="2d89" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated"><a class="ae jg" href="https://www.tensorflow.org/tensorboard" rel="noopener ugc nofollow" target="_blank"> TensorBoard </a>是一款提供一套可视化和监控机制的工具。对于本教程中的工作，我们将利用 TensorBoard 来监控网络训练的进度。</p><p id="3405" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">更具体地说，我们将监控以下指标:t <em class="lm">培训损失、培训准确度、验证损失、验证准确度。</em></p><p id="8c0e" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">在下面的代码片段中，我们创建了一个目录的引用，我们希望所有的 TensorBoard 文件都存储在这个目录中。函数<code class="fe pj pk pl pa b">get_run_logdir </code>返回根据训练阶段开始的当前时间命名的确切目录的位置。</p><p id="3edf" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">为了完成当前的过程，我们将存储特定训练课程的 TensorBoard 相关文件的目录传递给<a class="ae jg" href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard" rel="noopener ugc nofollow" target="_blank"> TensorBoard 回调</a>。</p><pre class="ov ow ox oy gt oz pa pb pc aw pd bi"><span id="54e0" class="nh mi jj pa b gy pe pf l pg ph">root_logdir = os.path.join(os.curdir, "logs\\fit\\")</span><span id="abad" class="nh mi jj pa b gy po pf l pg ph">def get_run_logdir():<br/>    run_id = time.strftime("run_%Y_%m_%d-%H_%M_%S")<br/>    return os.path.join(root_logdir, run_id)</span><span id="b12b" class="nh mi jj pa b gy po pf l pg ph">run_logdir = get_run_logdir()<br/>tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)</span></pre></div><div class="ab cl og oh hx oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="im in io ip iq"><h2 id="12ec" class="nh mi jj bd mj ni nj dn mn nk nl dp mr nb nm nn mt nd no np mv nf nq nr mx jp bi translated">7.培训和结果</h2><p id="9c36" class="pw-post-body-paragraph lk ll jj ln b lo mz kt lq lr na kw lt nb nc lw lx nd ne ma mb nf ng me mf mg im bi translated">为了训练网络，我们必须编译它。</p><p id="71db" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">编译过程包括指定以下项目:</p><blockquote class="lh li lj"><p id="00a0" class="lk ll lm ln b lo lp kt lq lr ls kw lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated"><strong class="ln jt">损失函数</strong>:一种量化机器学习模型表现<em class="jj"/>好坏的方法。量化是基于一组输入的输出(成本)，这些输入被称为参数值。参数值用于估计预测，而“损失”是预测值和实际值之间的差异。</p><p id="55f1" class="lk ll lm ln b lo lp kt lq lr ls kw lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated"><strong class="ln jt">优化算法</strong>:神经网络内的优化器是一种算法实现，它通过最小化损失函数提供的损失值来促进神经网络内的梯度下降过程。为了减少损失，适当地选择网络内的权重值是至关重要的。</p><p id="f679" class="lk ll lm ln b lo lp kt lq lr ls kw lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated"><strong class="ln jt">学习率</strong>:神经网络实现细节的一个组成部分，因为它是一个因子值，决定了对网络权值的更新水平。学习率是一种超参数。</p></blockquote><pre class="ov ow ox oy gt oz pa pb pc aw pd bi"><span id="9a4c" class="nh mi jj pa b gy pe pf l pg ph">model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.optimizers.SGD(lr=0.001), metrics=['accuracy'])<br/>model.summary()</span></pre><p id="0b04" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">我们还可以通过运行<code class="fe pj pk pl pa b">model.summary()</code>函数来提供网络摘要，以便更深入地了解网络的层组成。</p><pre class="ov ow ox oy gt oz pa pb pc aw pd bi"><span id="07e1" class="nh mi jj pa b gy pe pf l pg ph">Model: "sequential" _________________________________________________________________ Layer (type)                 Output Shape              Param #    ================================================================= conv2d (Conv2D)              (None, 55, 55, 96)        34944      _________________________________________________________________ batch_normalization (BatchNo (None, 55, 55, 96)        384        _________________________________________________________________ max_pooling2d (MaxPooling2D) (None, 27, 27, 96)        0          _________________________________________________________________ conv2d_1 (Conv2D)            (None, 27, 27, 256)       614656     _________________________________________________________________ batch_normalization_1 (Batch (None, 27, 27, 256)       1024       _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 13, 13, 256)       0          _________________________________________________________________ conv2d_2 (Conv2D)            (None, 13, 13, 384)       885120     _________________________________________________________________ batch_normalization_2 (Batch (None, 13, 13, 384)       1536       _________________________________________________________________ conv2d_3 (Conv2D)            (None, 13, 13, 384)       147840     _________________________________________________________________ batch_normalization_3 (Batch (None, 13, 13, 384)       1536       _________________________________________________________________ conv2d_4 (Conv2D)            (None, 13, 13, 256)       98560      _________________________________________________________________ batch_normalization_4 (Batch (None, 13, 13, 256)       1024       _________________________________________________________________ max_pooling2d_2 (MaxPooling2 (None, 6, 6, 256)         0          _________________________________________________________________ flatten (Flatten)            (None, 9216)              0          _________________________________________________________________ dense (Dense)                (None, 4096)              37752832   _________________________________________________________________ dropout (Dropout)            (None, 4096)              0          _________________________________________________________________ dense_1 (Dense)              (None, 4096)              16781312   _________________________________________________________________ dropout_1 (Dropout)          (None, 4096)              0          _________________________________________________________________ dense_2 (Dense)              (None, 10)                40970      ================================================================= Total params: 56,361,738 Trainable params: 56,358,986 Non-trainable params: 2,752 _________________________________________________________________</span></pre><p id="d62a" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">至此，我们已经准备好训练网络了。</p><p id="9a54" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">通过 TensorFlow 启用 Keras 模块，训练自定义 AlexNet 网络非常简单。我们只需调用<code class="fe pj pk pl pa b">fit()</code>方法并传递相关参数。</p><blockquote class="lh li lj"><p id="fdcc" class="lk ll lm ln b lo lp kt lq lr ls kw lt lu lv lw lx ly lz ma mb mc md me mf mg im bi translated"><strong class="ln jt"> Epoch: </strong>这是一个数值，表示网络暴露于训练数据集中所有数据点的次数。</p></blockquote><pre class="ov ow ox oy gt oz pa pb pc aw pd bi"><span id="cc26" class="nh mi jj pa b gy pe pf l pg ph">model.fit(train_ds,<br/>          epochs=50,<br/>          validation_data=validation_ds,<br/>          validation_freq=1,<br/>          callbacks=[tensorboard_cb])</span></pre><p id="22e6" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">在笔记本中执行这个代码单元后，网络将开始根据所提供的数据进行训练和验证。您将开始看到如下所示的培训和验证日志:</p><pre class="ov ow ox oy gt oz pa pb pc aw pd bi"><span id="92ea" class="nh mi jj pa b gy pe pf l pg ph">Train for 1562 steps, validate for 156 steps<br/>Epoch 1/50<br/>   1/1562 [..............................] - ETA: 3:05:44 - loss: 5.6104 - accuracy: 0.0625WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.168881). Check your callbacks.<br/>1562/1562 [==============================] - 42s 27ms/step - loss: 2.0966 - accuracy: 0.3251 - val_loss: 1.4436 - val_accuracy: 0.4920<br/>Epoch 2/50<br/>1562/1562 [==============================] - 39s 25ms/step - loss: 1.5864 - accuracy: 0.4382 - val_loss: 1.2939 - val_accuracy: 0.5447<br/>Epoch 3/50<br/>1562/1562 [==============================] - 39s 25ms/step - loss: 1.4391 - accuracy: 0.4889 - val_loss: 1.1749 - val_accuracy: 0.5859<br/>Epoch 4/50<br/>1562/1562 [==============================] - 39s 25ms/step - loss: 1.3278 - accuracy: 0.5307 - val_loss: 1.0841 - val_accuracy: 0.6228<br/>Epoch 5/50<br/>1562/1562 [==============================] - 39s 25ms/step - loss: 1.2349 - accuracy: 0.5630 - val_loss: 1.0094 - val_accuracy: 0.6569<br/>Epoch 6/50<br/>1562/1562 [==============================] - 40s 25ms/step - loss: 1.1657 - accuracy: 0.5876 - val_loss: 0.9599 - val_accuracy: 0.6851<br/>Epoch 7/50<br/>1562/1562 [==============================] - 39s 25ms/step - loss: 1.1054 - accuracy: 0.6128 - val_loss: 0.9102 - val_accuracy: 0.6937<br/>Epoch 8/50<br/>1562/1562 [==============================] - 40s 26ms/step - loss: 1.0477 - accuracy: 0.6285 - val_loss: 0.8584 - val_accuracy: 0.7109<br/>Epoch 9/50<br/>1562/1562 [==============================] - 39s 25ms/step - loss: 1.0026 - accuracy: 0.6461 - val_loss: 0.8392 - val_accuracy: 0.7137<br/>Epoch 10/50<br/>1562/1562 [==============================] - 39s 25ms/step - loss: 0.9601 - accuracy: 0.6627 - val_loss: 0.7684 - val_accuracy: 0.7398<br/>Epoch 11/50<br/>1562/1562 [==============================] - 40s 25ms/step - loss: 0.9175 - accuracy: 0.6771 - val_loss: 0.7683 - val_accuracy: 0.7476<br/>Epoch 12/50<br/>1562/1562 [==============================] - 40s 25ms/step - loss: 0.8827 - accuracy: 0.6914 - val_loss: 0.7012 - val_accuracy: 0.7702<br/>Epoch 13/50<br/>1562/1562 [==============================] - 40s 25ms/step - loss: 0.8465 - accuracy: 0.7035 - val_loss: 0.6496 - val_accuracy: 0.7903<br/>Epoch 14/50<br/>1562/1562 [==============================] - 40s 26ms/step - loss: 0.8129 - accuracy: 0.7160 - val_loss: 0.6137 - val_accuracy: 0.7991<br/>Epoch 15/50<br/>1562/1562 [==============================] - 40s 26ms/step - loss: 0.7832 - accuracy: 0.7250 - val_loss: 0.6181 - val_accuracy: 0.7957<br/>Epoch 16/50<br/>1562/1562 [==============================] - 40s 25ms/step - loss: 0.7527 - accuracy: 0.7371 - val_loss: 0.6102 - val_accuracy: 0.7953<br/>Epoch 17/50<br/>1562/1562 [==============================] - 40s 26ms/step - loss: 0.7193 - accuracy: 0.7470 - val_loss: 0.5236 - val_accuracy: 0.8327<br/>Epoch 18/50<br/>1562/1562 [==============================] - 40s 26ms/step - loss: 0.6898 - accuracy: 0.7559 - val_loss: 0.5091 - val_accuracy: 0.8425<br/>Epoch 19/50<br/>1562/1562 [==============================] - 40s 25ms/step - loss: 0.6620 - accuracy: 0.7677 - val_loss: 0.4824 - val_accuracy: 0.8468<br/>Epoch 20/50<br/>1562/1562 [==============================] - 40s 26ms/step - loss: 0.6370 - accuracy: 0.7766 - val_loss: 0.4491 - val_accuracy: 0.8620<br/>Epoch 21/50<br/>1562/1562 [==============================] - 41s 26ms/step - loss: 0.6120 - accuracy: 0.7850 - val_loss: 0.4212 - val_accuracy: 0.8694<br/>Epoch 22/50<br/>1562/1562 [==============================] - 41s 26ms/step - loss: 0.5846 - accuracy: 0.7943 - val_loss: 0.4091 - val_accuracy: 0.8746<br/>Epoch 23/50<br/>1562/1562 [==============================] - 40s 26ms/step - loss: 0.5561 - accuracy: 0.8070 - val_loss: 0.3737 - val_accuracy: 0.8872<br/>Epoch 24/50<br/>1562/1562 [==============================] - 40s 26ms/step - loss: 0.5314 - accuracy: 0.8150 - val_loss: 0.3808 - val_accuracy: 0.8810<br/>Epoch 25/50<br/>1562/1562 [==============================] - 40s 26ms/step - loss: 0.5107 - accuracy: 0.8197 - val_loss: 0.3246 - val_accuracy: 0.9048<br/>Epoch 26/50<br/>1562/1562 [==============================] - 40s 26ms/step - loss: 0.4833 - accuracy: 0.8304 - val_loss: 0.3085 - val_accuracy: 0.9115<br/>Epoch 27/50<br/>1562/1562 [==============================] - 41s 26ms/step - loss: 0.4595 - accuracy: 0.8425 - val_loss: 0.2992 - val_accuracy: 0.9111<br/>Epoch 28/50<br/>1562/1562 [==============================] - 40s 26ms/step - loss: 0.4395 - accuracy: 0.8467 - val_loss: 0.2566 - val_accuracy: 0.9305<br/>Epoch 29/50<br/>1562/1562 [==============================] - 41s 26ms/step - loss: 0.4157 - accuracy: 0.8563 - val_loss: 0.2482 - val_accuracy: 0.9339<br/>Epoch 30/50<br/>1562/1562 [==============================] - 40s 26ms/step - loss: 0.3930 - accuracy: 0.8629 - val_loss: 0.2129 - val_accuracy: 0.9449<br/>Epoch 31/50<br/>1562/1562 [==============================] - 40s 26ms/step - loss: 0.3727 - accuracy: 0.8705 - val_loss: 0.1999 - val_accuracy: 0.9525<br/>Epoch 32/50<br/>1562/1562 [==============================] - 40s 26ms/step - loss: 0.3584 - accuracy: 0.8751 - val_loss: 0.1791 - val_accuracy: 0.9593<br/>Epoch 33/50<br/>1562/1562 [==============================] - 41s 26ms/step - loss: 0.3387 - accuracy: 0.8830 - val_loss: 0.1770 - val_accuracy: 0.9557<br/>Epoch 34/50<br/>1562/1562 [==============================] - 41s 26ms/step - loss: 0.3189 - accuracy: 0.8905 - val_loss: 0.1613 - val_accuracy: 0.9643<br/>Epoch 35/50<br/>1562/1562 [==============================] - 40s 26ms/step - loss: 0.3036 - accuracy: 0.8969 - val_loss: 0.1421 - val_accuracy: 0.9681<br/>Epoch 36/50<br/>1562/1562 [==============================] - 41s 26ms/step - loss: 0.2784 - accuracy: 0.9039 - val_loss: 0.1290 - val_accuracy: 0.9736<br/>Epoch 37/50<br/>1562/1562 [==============================] - 40s 26ms/step - loss: 0.2626 - accuracy: 0.9080 - val_loss: 0.1148 - val_accuracy: 0.9762<br/>Epoch 38/50<br/>1562/1562 [==============================] - 41s 26ms/step - loss: 0.2521 - accuracy: 0.9145 - val_loss: 0.0937 - val_accuracy: 0.9828<br/>Epoch 39/50<br/>1562/1562 [==============================] - 42s 27ms/step - loss: 0.2387 - accuracy: 0.9190 - val_loss: 0.1045 - val_accuracy: 0.9768<br/>Epoch 40/50<br/>1562/1562 [==============================] - 40s 26ms/step - loss: 0.2215 - accuracy: 0.9247 - val_loss: 0.0850 - val_accuracy: 0.9860<br/>Epoch 41/50<br/>1562/1562 [==============================] - 40s 26ms/step - loss: 0.2124 - accuracy: 0.9274 - val_loss: 0.0750 - val_accuracy: 0.9862<br/>Epoch 42/50<br/>1562/1562 [==============================] - 41s 26ms/step - loss: 0.1980 - accuracy: 0.9335 - val_loss: 0.0680 - val_accuracy: 0.9896<br/>Epoch 43/50<br/>1562/1562 [==============================] - 41s 26ms/step - loss: 0.1906 - accuracy: 0.9350 - val_loss: 0.0616 - val_accuracy: 0.9912<br/>Epoch 44/50<br/>1562/1562 [==============================] - 40s 26ms/step - loss: 0.1769 - accuracy: 0.9410 - val_loss: 0.0508 - val_accuracy: 0.9922<br/>Epoch 45/50<br/>1562/1562 [==============================] - 41s 26ms/step - loss: 0.1648 - accuracy: 0.9455 - val_loss: 0.0485 - val_accuracy: 0.9936<br/>Epoch 46/50<br/>1562/1562 [==============================] - 41s 26ms/step - loss: 0.1571 - accuracy: 0.9487 - val_loss: 0.0435 - val_accuracy: 0.9952<br/>Epoch 47/50<br/>1562/1562 [==============================] - 40s 26ms/step - loss: 0.1514 - accuracy: 0.9501 - val_loss: 0.0395 - val_accuracy: 0.9950<br/>Epoch 48/50<br/>1562/1562 [==============================] - 41s 26ms/step - loss: 0.1402 - accuracy: 0.9535 - val_loss: 0.0274 - val_accuracy: 0.9984<br/>Epoch 49/50<br/>1562/1562 [==============================] - 40s 26ms/step - loss: 0.1357 - accuracy: 0.9549 - val_loss: 0.0308 - val_accuracy: 0.9966<br/>Epoch 50/50<br/>1562/1562 [==============================] - 42s 27ms/step - loss: 0.1269 - accuracy: 0.9596 - val_loss: 0.0251 - val_accuracy: 0.9976</span><span id="9c5b" class="nh mi jj pa b gy po pf l pg ph">&lt;tensorflow.python.keras.callbacks.History at 0x2de3aaa0ec8&gt;</span></pre><p id="6348" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">为了更好地可视化和监控训练表现，我们将使用 TensorBoard 功能。</p><p id="c277" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">在 TensorBoard 日志文件夹所在的目录级别打开一个终端，并运行以下命令:</p><pre class="ov ow ox oy gt oz pa pb pc aw pd bi"><span id="b7b9" class="nh mi jj pa b gy pe pf l pg ph">tensorboard --logdir logs</span></pre><figure class="ov ow ox oy gt iv gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/e821b76f2954ca94eebf585c375b7301.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*VPV1QKKwUSjwdFJ6IXQHOw.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">TensorBoard 日志文件所在的目录级别</p></figure><p id="29ee" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">按照终端上的指示，导航到'<em class="lm"> localhost:6006 </em>'(这可能是一个不同的端口号)。</p><p id="6915" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">唉，您将看到一个类似于下图的页面:</p><figure class="ov ow ox oy gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pq"><img src="../Images/1604dc3472612602a74d23614526aca2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rDlh1OCrmH00HW8wE3m8GA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">张量板工具</p></figure><p id="68aa" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">下面是 TensorBoard 提供的完整培训和验证阶段的可视化片段。</p><figure class="ov ow ox oy gt iv gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/17e8adaf6d19f6cb3e4f1eea24b70671.png" data-original-src="https://miro.medium.com/v2/resize:fit:1358/format:webp/1*V6-aA0ENbEjXljxaXnSppQ.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">TensorBoard 培训和验证监控</p></figure><h2 id="8d22" class="nh mi jj bd mj ni nj dn mn nk nl dp mr nb nm nn mt nd no np mv nf nq nr mx jp bi translated">8.估价</h2><p id="bc59" class="pw-post-body-paragraph lk ll jj ln b lo mz kt lq lr na kw lt nb nc lw lx nd ne ma mb nf ng me mf mg im bi translated">最后一个官方步骤是通过网络评估对训练好的网络进行评估。</p><p id="f53c" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">评估阶段将根据看不见的数据提供训练模型的性能分数。对于模型的评估阶段，我们将利用在早期步骤中创建的一批测试数据。</p><p id="a41b" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">评估一个模型非常简单，你只需调用<code class="fe pj pk pl pa b">evaluate()</code>方法并传递批量测试数据。</p><pre class="ov ow ox oy gt oz pa pb pc aw pd bi"><span id="cd5d" class="nh mi jj pa b gy pe pf l pg ph">model.evaluate(test_ds)</span></pre><p id="ed6e" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">在执行了上面的单元块之后，我们看到了一个分数，它表明了模型在看不见的数据上的性能。</p><pre class="ov ow ox oy gt oz pa pb pc aw pd bi"><span id="621d" class="nh mi jj pa b gy pe pf l pg ph">312/312 [==============================] - 8s 27ms/step - loss: 0.9814 - accuracy: 0.7439<br/>[0.9813630809673132, 0.7438902]</span></pre><p id="b01b" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">返回结果的第一个元素包含评估损失:0.9813，第二个元素指示评估准确度 0.74389。</p><h2 id="d572" class="nh mi jj bd mj ni nj dn mn nk nl dp mr nb nm nn mt nd no np mv nf nq nr mx jp bi translated">定制实施的 AlexNet 网络在 CIFAR-10 数据集上进行训练、验证和评估，以创建一个在包含 5000 个数据点的测试数据集上具有 74%评估准确性的模型。</h2></div><div class="ab cl og oh hx oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="im in io ip iq"><h1 id="5d25" class="mh mi jj bd mj mk on mm mn mo oo mq mr ky op kz mt lb oq lc mv le or lf mx my bi translated">奖金(可选)</h1><p id="82c6" class="pw-post-body-paragraph lk ll jj ln b lo mz kt lq lr na kw lt nb nc lw lx nd ne ma mb nf ng me mf mg im bi translated">本节包括补充 AlexNet 卷积神经网络实现的一些信息。</p><p id="3a98" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">虽然这些附加信息对于理解实现过程并不重要，但是这些部分将为读者提供一些在未来工作中可以利用的附加背景知识。</p><p id="b9ad" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated"><strong class="ln jt">所涵盖的部分如下:</strong></p><ul class=""><li id="ac43" class="ns nt jj ln b lo lp lr ls nb os nd ot nf ou mg nx ny nz oa bi translated"><strong class="ln jt"> <em class="lm">局部响应归一化</em> </strong></li><li id="577d" class="ns nt jj ln b lo ob lr oc nb od nd oe nf of mg nx ny nz oa bi translated"><strong class="ln jt"> <em class="lm">信息转化为为什么我们在训练之前对数据集进行批处理和洗牌</em> </strong></li></ul><h2 id="40c8" class="nh mi jj bd mj ni nj dn mn nk nl dp mr nb nm nn mt nd no np mv nf nq nr mx jp bi translated">局部反应标准化</h2><p id="42a2" class="pw-post-body-paragraph lk ll jj ln b lo mz kt lq lr na kw lt nb nc lw lx nd ne ma mb nf ng me mf mg im bi translated">许多人都熟悉批量标准化，但 AlexNet 架构在网络内使用了一种不同的标准化方法:本地响应标准化(LRN)。</p><p id="20f8" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">LRN 是一种最大限度地激活邻近神经元的技术。相邻神经元描述共享相同空间位置的若干特征地图上的神经元。通过标准化神经元的激活，具有高激活的神经元被突出显示；这基本上模仿了神经生物学中发生的侧抑制。</p><p id="180d" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">LRN 在现代 CNN 架构中没有被广泛使用，因为还有其他更有效的归一化方法。尽管 LRN 实现仍然可以在一些标准的<a class="ae jg" href="https://www.tensorflow.org/api_docs/python/tf/nn/local_response_normalization" rel="noopener ugc nofollow" target="_blank">机器学习库和框架</a>中找到，所以请随意试验。</p><h2 id="3210" class="nh mi jj bd mj ni nj dn mn nk nl dp mr nb nm nn mt nd no np mv nf nq nr mx jp bi translated">我们为什么要打乱数据集？</h2><p id="2f79" class="pw-post-body-paragraph lk ll jj ln b lo mz kt lq lr na kw lt nb nc lw lx nd ne ma mb nf ng me mf mg im bi translated">在训练之前混洗数据集是典型的机器学习项目中的传统过程。但是我们为什么要这样做呢？</p><p id="4eec" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">进行数据聚合时，通常会连续累积对应于相同类别和标签的图像或数据点。在加载用于训练和验证网络的数据之后，典型的最终结果是按照相应类别的顺序排列的一组图像/数据点。</p><p id="3f70" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">神经网络在深度学习中学习的方法是通过检测图像内空间信息之间的模式。</p><p id="864c" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">假设我们有一个包含 10，000 张图片的数据集，分为五类。前 2000 个图像属于类别 1；第二个 2000 个图像属于类别 2，依此类推。</p><p id="a712" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">在训练阶段，如果我们向网络提供未受干扰的训练数据，我们会发现神经网络将学习与类别 1 密切相关的模式，因为这些是神经网络首先暴露的图像和数据点。这将增加优化算法为整个数据集发现最优解的难度。</p><p id="c062" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated"><strong class="ln jt">通过改组数据集，我们确保了两件关键的事情:</strong></p><p id="0286" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">1.数据集中有足够大的差异，使得训练数据中的每个数据点对网络都有独立的影响。因此，我们可以拥有一个能够很好地概括整个数据集的网络，而不是数据集的一个子部分。</p><p id="3499" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">2.我们的数据集的验证分区是从训练数据中获得的；如果我们不能适当地打乱数据集，我们会发现我们的验证数据集将不能代表训练数据中的类。例如，我们的验证数据集可能只包含来自训练数据的最后一个类的数据点，而不是用数据集平等地表示每个类。</p><h2 id="50dd" class="nh mi jj bd mj ni nj dn mn nk nl dp mr nb nm nn mt nd no np mv nf nq nr mx jp bi translated">为什么我们要在训练前对数据集进行批处理？</h2><p id="f48c" class="pw-post-body-paragraph lk ll jj ln b lo mz kt lq lr na kw lt nb nc lw lx nd ne ma mb nf ng me mf mg im bi translated">出于内存优化的原因，数据集分区通常是批处理的。有两种方法可以训练网络。</p><ol class=""><li id="6dca" class="ns nt jj ln b lo lp lr ls nb os nd ot nf ou mg pn ny nz oa bi translated">将所有训练数据一次呈现给网络</li><li id="699c" class="ns nt jj ln b lo ob lr oc nb od nd oe nf of mg pn ny nz oa bi translated">将训练数据分批成更小的分段(例如，8、16、32、64)，并且在每次迭代中，将单个批次呈现给网络。</li></ol><p id="ca61" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">方法#1 适用于小型数据集，但是当您开始处理大型数据集时，您会发现方法#1 消耗了大量内存资源</p><p id="731c" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">通过对大型数据集使用方法#1，图像或数据点保存在内存中，这通常会在训练期间导致“内存不足”错误。</p><p id="09e2" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">方法#2 是一种在考虑有效内存管理的同时，用大数据集训练网络的更保守的方法。通过对训练数据进行批处理，我们在任何给定时间都只能在内存中保存 16、32 或 128 个数据点，而不是整个数据集。</p></div><div class="ab cl og oh hx oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="im in io ip iq"><h1 id="5108" class="mh mi jj bd mj mk on mm mn mo oo mq mr ky op kz mt lb oq lc mv le or lf mx my bi translated">结论</h1><p id="f355" class="pw-post-body-paragraph lk ll jj ln b lo mz kt lq lr na kw lt nb nc lw lx nd ne ma mb nf ng me mf mg im bi translated">这篇详细的文章涵盖了一些围绕深度学习项目中典型过程的主题。我们已经讨论了以下主题领域:</p><ul class=""><li id="43f9" class="ns nt jj ln b lo lp lr ls nb os nd ot nf ou mg nx ny nz oa bi translated">机器和深度学习工具和库</li><li id="2637" class="ns nt jj ln b lo ob lr oc nb od nd oe nf of mg nx ny nz oa bi translated">数据划分</li><li id="5da6" class="ns nt jj ln b lo ob lr oc nb od nd oe nf of mg nx ny nz oa bi translated">使用 TensorFlow 创建输入和数据管道</li><li id="0a5a" class="ns nt jj ln b lo ob lr oc nb od nd oe nf of mg nx ny nz oa bi translated">数据预处理</li><li id="cfc6" class="ns nt jj ln b lo ob lr oc nb od nd oe nf of mg nx ny nz oa bi translated">卷积神经网络实现(AlexNet)</li><li id="a2c1" class="ns nt jj ln b lo ob lr oc nb od nd oe nf of mg nx ny nz oa bi translated">使用 TensorBoard 监控模型性能</li><li id="6300" class="ns nt jj ln b lo ob lr oc nb od nd oe nf of mg nx ny nz oa bi translated">模型评估</li></ul><p id="0ea7" class="pw-post-body-paragraph lk ll jj ln b lo lp kt lq lr ls kw lt nb lv lw lx nd lz ma mb nf md me mf mg im bi translated">将来，我们将介绍另一个众所周知的卷积神经网络架构的实现:GoogLeNet。</p></div><div class="ab cl og oh hx oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="im in io ip iq"><h1 id="9d93" class="mh mi jj bd mj mk on mm mn mo oo mq mr ky op kz mt lb oq lc mv le or lf mx my bi translated">想要更多吗？</h1><ol class=""><li id="e20d" class="ns nt jj ln b lo mz lr na nb nu nd nv nf nw mg pn ny nz oa bi translated"><a class="ae jg" href="https://richmondalake.medium.com/membership" rel="noopener"> <strong class="ln jt">成为推荐媒介会员，支持我的写作</strong> </a></li><li id="e165" class="ns nt jj ln b lo ob lr oc nb od nd oe nf of mg pn ny nz oa bi translated"><a class="ae jg" href="https://richmondalake.medium.com/subscribe" rel="noopener"> <strong class="ln jt">订阅</strong> </a> <strong class="ln jt"> </strong>在我发表文章时得到通知</li><li id="98ad" class="ns nt jj ln b lo ob lr oc nb od nd oe nf of mg pn ny nz oa bi translated">通过<a class="ae jg" href="https://www.linkedin.com/in/richmondalake/" rel="noopener ugc nofollow" target="_blank"> <strong class="ln jt"> LinkedIn </strong> </a>联系我</li><li id="ccdb" class="ns nt jj ln b lo ob lr oc nb od nd oe nf of mg pn ny nz oa bi translated">在<a class="ae jg" href="https://www.oreilly.com/live-events/practical-introduction-to-the-world-of-computer-vision-and-deep-learning-with-tensorflow-keras/0636920060577/0636920060576/" rel="noopener ugc nofollow" target="_blank"> <strong class="ln jt">奥莱利</strong> </a>跟我学</li></ol></div><div class="ab cl og oh hx oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="im in io ip iq"><div class="ov ow ox oy gt ps"><a rel="noopener follow" target="_blank" href="/are-there-black-people-in-ai-fb6928166d73"><div class="pt ab fo"><div class="pu ab pv cl cj pw"><h2 class="bd jt gy z fp px fr fs py fu fw js bi translated">AI 里有黑人吗？</h2><div class="pz l"><h3 class="bd b gy z fp px fr fs py fu fw dk translated">我们仍然是人工智能中代表最少的种族之一，然而我们可能会因为它的利用和滥用而遭受最大的痛苦。</h3></div><div class="qa l"><p class="bd b dl z fp px fr fs py fu fw dk translated">towardsdatascience.com</p></div></div><div class="qb l"><div class="qc l qd qe qf qb qg ja ps"/></div></div></a></div><div class="is it gp gr iu ps"><a rel="noopener follow" target="_blank" href="/what-alexnet-brought-to-the-world-of-deep-learning-46c7974b46fc"><div class="pt ab fo"><div class="pu ab pv cl cj pw"><h2 class="bd jt gy z fp px fr fs py fu fw js bi translated">AlexNet 给深度学习世界带来了什么</h2><div class="pz l"><h3 class="bd b gy z fp px fr fs py fu fw dk translated">花一分钟来了解琐碎的技术和神经网络架构，革命性的如何深入…</h3></div><div class="qa l"><p class="bd b dl z fp px fr fs py fu fw dk translated">towardsdatascience.com</p></div></div><div class="qb l"><div class="qh l qd qe qf qb qg ja ps"/></div></div></a></div><div class="is it gp gr iu ps"><a rel="noopener follow" target="_blank" href="/understanding-and-implementing-lenet-5-cnn-architecture-deep-learning-a2d531ebc342"><div class="pt ab fo"><div class="pu ab pv cl cj pw"><h2 class="bd jt gy z fp px fr fs py fu fw js bi translated">理解和实现 LeNet-5 CNN 架构(深度学习)</h2><div class="pz l"><h3 class="bd b gy z fp px fr fs py fu fw dk translated">在本文中，我们使用定制实现的 LeNet-5 神经网络对 MNIST 数据集进行图像分类</h3></div><div class="qa l"><p class="bd b dl z fp px fr fs py fu fw dk translated">towardsdatascience.com</p></div></div><div class="qb l"><div class="qi l qd qe qf qb qg ja ps"/></div></div></a></div></div></div>    
</body>
</html>