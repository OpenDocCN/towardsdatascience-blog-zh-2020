<html>
<head>
<title>Google’s Approach To Flexibility In Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">谷歌在机器学习中的灵活性方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/googles-approach-to-flexibility-in-machine-learning-170bd9d8f169?source=collection_archive---------37-----------------------#2020-03-23">https://towardsdatascience.com/googles-approach-to-flexibility-in-machine-learning-170bd9d8f169?source=collection_archive---------37-----------------------#2020-03-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="250c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何建立一个亚麻阿尔法版本的CNN？</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/6f43b08fc57709ee5f9f489cf802a0a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rnq4I-HcARDgDCXmE-FO7w.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://unsplash.com/collections/8762704/flax?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上<a class="ae kv" href="https://unsplash.com/@musicfox?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> MusicFox Fx </a>拍摄的照片</p></figure><p id="e61f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">想到机器学习，首先想到的框架是Tensorflow和PyTorch，如果你想与深度神经网络合作，这是目前最先进的框架。技术变化很快，需要更多的灵活性，因此谷歌的研究人员正在为开源社区开发一个新的高性能框架:Flax。</p><p id="2edd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">计算的基础是JAX而不是NumPy，NumPy也是谷歌的一个研究项目。JAX最大的优势之一是使用了XLA，一个特殊的线性代数编译器，<strong class="ky ir">支持在GPU和TPU上执行。对于那些不知道的人来说，TPU(张量处理单元)是一个专门为机器学习优化的芯片。JAX重新实现了NumPy的一部分，在GPU/TPU上运行你的函数。</strong></p><p id="cb0c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Flax专注于以下关键点:</p><ul class=""><li id="1002" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><strong class="ky ir">轻松</strong>阅读代码</li><li id="6e4a" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">更喜欢复制</strong>，而不是糟糕的抽象或膨胀的功能</li><li id="04fe" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">有用的错误消息</strong>，似乎他们从Tensorflow错误消息中吸取了教训</li><li id="14b3" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">基本实现的易扩展性</li></ul><p id="4cac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">赞够了，现在开始编码吧。</p><p id="7060" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因为MNIST的例子变得很无聊，我将为辛普森一家建立一个图像分类，不幸的是，Maggie在数据集中丢失了:-(。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/c87f0b7f24ca113818cfd1b64d1ef006.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*WWFOOlGcw6egCJ-CNXV1XA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">数据集的样本图像</p></figure><p id="0df0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，我们安装必要的库并解压缩数据集。不幸的是，此时您仍然需要Tensorflow，因为Flax缺少一个好的数据输入管道。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="41ae" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们导入库。你可以看到我们有两个“版本”的numpy，普通的numpy库和JAX实现的API的一部分。print语句根据可用的硬件输出CPU、GPU或TPU。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="b4eb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了训练和评估，我们首先必须创建两个Tensorflow数据集，并将它们转换成numpy/jax数组，因为FLAX不接受TF数据类型。这是目前有点hacky，因为评估方法不采取批次。我必须为eval步骤创建一个大的批处理，并从中创建一个TF特征字典，它现在是可解析的，并可以在每个时期后提供给我们的eval步骤。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><h1 id="e2a5" class="mj mk iq bd ml mm mn mo mp mq mr ms mt jw mu jx mv jz mw ka mx kc my kd mz na bi translated">模型</h1><p id="e194" class="pw-post-body-paragraph kw kx iq ky b kz nb jr lb lc nc ju le lf nd lh li lj ne ll lm ln nf lp lq lr ij bi translated">CNN-class包含了我们的卷积神经网络。当你熟悉Tensorflow/Pytorch时，你会发现它非常简单。我们的<code class="fe ng nh ni nj b">flax.nn.Conv</code>的每个调用都定义了一个可学习的内核。我使用了MNIST的例子，并用一些额外的层来扩展它。最后，我们有四个输出神经元的密集层，因为我们有一个四类问题。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="f406" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">与Tensorflow不同，激活函数是显式调用的，这使得测试新的和自己编写的激活函数变得非常容易。FLAX基于模块抽象，启动和调用网络都是通过apply函数完成的。</p><h1 id="5149" class="mj mk iq bd ml mm mn mo mp mq mr ms mt jw mu jx mv jz mw ka mx kc my kd mz na bi translated">亚麻的度量标准</h1><p id="c25a" class="pw-post-body-paragraph kw kx iq ky b kz nb jr lb lc nc ju le lf nd lh li lj ne ll lm ln nf lp lq lr ij bi translated">当然，我们想衡量我们的网络变得有多好。因此，我们计算损失和准确性等指标。我们的精度是用JAX库计算的，而不是NumPy，因为我们可以在TPU/GPU上使用JAX。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="26d3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了测量我们的损失，我们使用交叉熵损失，不像在Tensorflow中它是由你自己计算的，我们还没有可能使用现成的损失对象。如你所见，我们使用<code class="fe ng nh ni nj b">@jax.vmap</code>作为损失函数的函数装饰器。这将我们的代码矢量化，以便在批处理中高效运行。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="bb9a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ng nh ni nj b">cross_entropy_loss</code>是如何工作的？<code class="fe ng nh ni nj b">@jax.vmap</code>接受两个数组，logits和label，并对每一对执行我们的<code class="fe ng nh ni nj b">cross_entropy_loss</code>，从而允许批处理的并行计算。单个示例的交叉熵公式为:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/ea906f405bf9f519cc125191ebdef224.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*TOR3SWQk5wjPlGbCzMLbkQ.png"/></div></figure><p id="0386" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于四个输出神经元中的一个，我们的基本事实y是0或1，因此我们的代码中不需要求和公式，因为我们只需要计算正确标签的log(y_hat)。在我们的损失计算中使用平均值，因为我们有批次。</p><h1 id="98e3" class="mj mk iq bd ml mm mn mo mp mq mr ms mt jw mu jx mv jz mw ka mx kc my kd mz na bi translated"><strong class="ak">培训</strong></h1><p id="7da7" class="pw-post-body-paragraph kw kx iq ky b kz nb jr lb lc nc ju le lf nd lh li lj ne ll lm ln nf lp lq lr ij bi translated">在我们训练步骤中，我们再次使用函数装饰器<code class="fe ng nh ni nj b">@jax.jit</code>，来加速我们的函数。这与Tensorflow非常相似。请记住<code class="fe ng nh ni nj b">batch[0]</code>是我们的图像数据，<code class="fe ng nh ni nj b">batch[1]</code>是我们的标签。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="d8e1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">损失函数<code class="fe ng nh ni nj b">loss_fn</code>返回当前模型<code class="fe ng nh ni nj b">optimizer.target</code>的损失，我们的<code class="fe ng nh ni nj b">jax.grad()</code>计算其梯度。在计算之后，我们像在张量流中一样应用梯度。</p><p id="5242" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在FLAX中，评估步骤非常简单。请注意，完整的评估数据集将传递给此函数。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="10b5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">经过50个纪元后，我们有了非常高的精确度。当然，我们可以继续调整模型和优化超参数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/841adf1dbbaf6a4a82d80a81688abe0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*XVlr1W5TAMnIowgvxosi7w.png"/></div></figure><p id="2a25" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于这个实验，我使用了Google Colab，所以如果你想自己测试，用GPU/TPU创建一个新环境，并从Github导入我的笔记本。请注意，FLAX目前不在Windows下工作。</p><h1 id="b382" class="mj mk iq bd ml mm mn mo mp mq mr ms mt jw mu jx mv jz mw ka mx kc my kd mz na bi translated">结论</h1><p id="ddd9" class="pw-post-body-paragraph kw kx iq ky b kz nb jr lb lc nc ju le lf nd lh li lj ne ll lm ln nf lp lq lr ij bi translated">值得注意的是<strong class="ky ir"> FLAX目前仍处于alpha </strong>阶段，并不是谷歌的官方产品。</p><p id="84e5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">到目前为止，这项工作给快速、轻量级和高度可定制的ML框架带来了希望<strong class="ky ir">。目前完全缺少的是数据输入管道，所以Tensorflow仍然必须使用。目前的一组优化器很不幸地仅限于带有动量的ADAM和SGD。我特别喜欢如何使用这个框架的非常严格的前进方向和高度的灵活性。我的下一个计划是开发一些目前还没有的激活功能。Tensorflow、PyTorch和FLAX之间的速度比较也会非常有趣。</strong></p><p id="7a09" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你想尝试一下FLAX，可以查看一下<a class="ae kv" href="https://flax.readthedocs.io/en/latest/notebooks/flax_intro.html" rel="noopener ugc nofollow" target="_blank">文档</a>和他们的<a class="ae kv" href="https://github.com/google/flax/tree/prerelease" rel="noopener ugc nofollow" target="_blank"> Github页面</a>。</p><p id="8de7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你想下载我的带有数据集的例子，只需克隆SimpsonsFaceRecognitionFlax。</p></div></div>    
</body>
</html>