<html>
<head>
<title>AI Generates Trending Video Ideas</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能产生流行的视频创意</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ai-generates-trending-video-ideas-968f5cba8616?source=collection_archive---------21-----------------------#2020-03-13">https://towardsdatascience.com/ai-generates-trending-video-ideas-968f5cba8616?source=collection_archive---------21-----------------------#2020-03-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/09d99fcedc7acc48028bb4ee8c0fcdaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5b6ux5JLIlLve2Ld"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">Kon Karampelas 在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><div class=""/><div class=""><h2 id="a76f" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">使用递归神经网络激发下一个病毒视频</h2></div><p id="a002" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi lu translated"><span class="l lv lw lx bm ly lz ma mb mc di"> Y </span> ouTube是一个庞大的平台——成功获得推荐算法青睐的视频可以获得数亿次观看。当内容创作者试图创造下一个病毒式视频时，人工智能可以产生许多你想要的趋势视频创意！</p><p id="e23e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这篇文章中，我将展示任何人如何用四行代码创建和训练递归神经网络来生成趋势视频想法！</p></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h1 id="7550" class="mk ml jj bd mm mn mo mp mq mr ms mt mu kp mv kq mw ks mx kt my kv mz kw na nb bi translated">首先，一点轻理论…</h1><p id="f12d" class="pw-post-body-paragraph ky kz jj la b lb nc kk ld le nd kn lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">如果你对递归神经网络如何工作不感兴趣，可以直接跳到实现上。</p><p id="0b06" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">递归神经网络(RNN)是一种专门处理序列的神经网络。给定一个种子“她遛了她的_ _ ”, RNN可能会预测“狗”。RNNs在文本生成中的技巧是使用预测作为进一步预测的种子。</p><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nh"><img src="../Images/08ceea0db2a1186e716c06bec7c28ab9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e_TJ_F4T6j5mIe8cJMzvrQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">给定种子“她”，RNN如何生成文本。粗体字是RNN的输出。</p></figure><p id="8052" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">应用于文本生成的标准神经网络的一个问题是它具有固定的输入和输出大小。例如，在MNIST数据集上训练的卷积神经网络中，每个训练和测试示例只能有784个值，不能多，也不能少。虽然这在像图像识别这样的任务中是可行的，但它肯定不适用于自然语言处理任务，在自然语言处理任务中，输入和输出可能在几个字符到几个句子甚至更多之间变化。</p><p id="0452" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">RNNs允许可变长度的输入和输出。RNN可以看起来像下面的任何一种，其中红色是输入，绿色是RNN，蓝色是输出:</p><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nm"><img src="../Images/ec530a39a8a1c8d2eb839f307dfbe82c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*niT8XE3KtHsyuoinFbr7VQ.png"/></div></div></figure><p id="dd35" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">标准和卷积神经网络对于每个输入值或像素具有不同的一组权重和偏差，而递归神经网络对于所有输入具有相同的一组权重和偏差。RNN通常有三组权重和偏差-一组在输入图层和隐藏图层之间(红色到绿色)，一组在隐藏图层和另一个隐藏图层之间(绿色到绿色)，另一组在隐藏图层和输出图层之间(绿色到蓝色)。</p><p id="2671" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因为在每个层到层的链路上使用相同的权重和偏差集，所以可以非常容易地调整层中的像元数量，包括输入和输出。因为参数很少，所以可以确定最佳的权重和偏差。</p><p id="e401" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">那么，为什么RNN如此擅长生成文本呢？</p><p id="a0e9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">RNN文本生成基于一个基本原则，即句子中的下一个单词总是以相同的想法应用。这是有道理的——作为一个作者，你写下的下一个单词和前一个单词的意图是一样的。</p><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nn"><img src="../Images/6683b9a1818735d5b4ad53e2e962b1c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*miwsoTEpDQNSfVDBRHybYA.png"/></div></div></figure><p id="1da8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在上图中，第一个句子是这样写的，每个单词都有相同的意图。第二句话以同样的意图开始，但因为它不断转换，最终结果与最初的意图相去甚远。</p><p id="e9c9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">通过在每组单词上应用相同的RNN，句子的意图(它试图去哪里，它包含什么思想)以及句子的措辞都得到了保持。</p><p id="bd7f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你想对RNNs有更深入的解释，可以看看这些研究论文。</p><ul class=""><li id="7fdb" class="no np jj la b lb lc le lf lh nq ll nr lp ns lt nt nu nv nw bi translated"><a class="ae jg" href="http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf" rel="noopener ugc nofollow" target="_blank">基于递归神经网络的语言模型</a></li><li id="cc6c" class="no np jj la b lb nx le ny lh nz ll oa lp ob lt nt nu nv nw bi translated"><a class="ae jg" href="http://www.fit.vutbr.cz/research/groups/speech/publi/2011/mikolov_icassp2011_5528.pdf" rel="noopener ugc nofollow" target="_blank">基于递归神经网络语言模型的扩展</a></li></ul></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h1 id="c8dc" class="mk ml jj bd mm mn mo mp mq mr ms mt mu kp mv kq mw ks mx kt my kv mz kw na nb bi translated">实现病毒式视频标题生成器</h1><p id="46af" class="pw-post-body-paragraph ky kz jj la b lb nc kk ld le nd kn lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">所有的机器学习模型都需要数据。我们将使用的数据集是<a class="ae jg" href="https://www.kaggle.com/datasnaek/youtube-new" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上的趋势YouTube视频统计数据集。</p><p id="8b12" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当加载和查看数据集时，我们可以了解数据的结构:</p><pre class="ni nj nk nl gt oc od oe of aw og bi"><span id="48f8" class="oh ml jj od b gy oi oj l ok ol">import pandas as pd<br/>data = pd.read_csv('/kaggle/input/youtube-new/USvideos.csv')<br/>data.head()</span></pre><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi om"><img src="../Images/6d66f19789758f50f23680e71be542dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Taf84IiIaIbgzdw5TTmhg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">*右边还有更多列，但我们不需要它们</p></figure><p id="8d6f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们对<code class="fe on oo op od b">title</code>栏感兴趣——这将为训练RNN提供数据。该数据有40，949行；与一些较大的数据集相比，这并不算多，但是为了保持合理的训练时间，让我们将训练数据减少到5，000个实例。</p><p id="070f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">此外，我们应该缩小培训数据的类别:</p><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi om"><img src="../Images/d9dda25d1e0bdf21b5ed1a965a063eab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OYLkwboi8xcA2ApValiHbA.png"/></div></div></figure><p id="432c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在查看了不同的类别后，很明显有些类别是新闻、音乐视频、电影预告片等。，这在创意生成器的上下文中没有意义，因为新闻、歌曲标题、音乐视频标题等要么无法生成，要么没有意义。类别IDs 22、23和24专用于由小型内容创建者创建的喜剧和较短片段。这些更符合我们想要生成的内容。</p><p id="51ba" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面的代码选择<code class="fe on oo op od b">data</code>中属于类别22、23或24的行，并将它们放入名为<code class="fe on oo op od b">sub_data</code>的数据帧中。</p><pre class="ni nj nk nl gt oc od oe of aw og bi"><span id="d1fd" class="oh ml jj od b gy oi oj l ok ol">sub_data = data[(data['category_id']==24) | (data['category_id']==23) | (data['category_id']==22)]</span></pre><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oq"><img src="../Images/2865a5bae53b833bd05e1f55a5485144.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J6ZBuQPQeCQUvT_SdmBXuQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">右边还有更多未显示的列。</p></figure><p id="6f2e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">仍然有16，631行—为了将其减少到5，000行，我们将随机洗牌几次，然后选择前5，000行作为训练数据。<code class="fe on oo op od b">sklearn</code>方便的<code class="fe on oo op od b">shuffle</code>功能可以帮助:</p><pre class="ni nj nk nl gt oc od oe of aw og bi"><span id="ac49" class="oh ml jj od b gy oi oj l ok ol">from sklearn.utils import shuffle<br/>sub_data = shuffle(shuffle(sub_data))</span></pre><p id="fdc3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要将数据输入到模型中，数据必须在文本文件中，每个新的训练实例在单独的一行上。下面的代码就是这样做的:</p><pre class="ni nj nk nl gt oc od oe of aw og bi"><span id="1cf6" class="oh ml jj od b gy oi oj l ok ol">titles = open('title.txt','w+')<br/>for item in sub_data.head(5_000)['title']:<br/>    titles.write(item)<br/>    titles.write('\n')<br/>titles.close()</span></pre><p id="87f0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">注意，<code class="fe on oo op od b">.head(n)</code>函数选择数据帧中最上面的<code class="fe on oo op od b">n</code>行。</p><p id="553f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要查看<code class="fe on oo op od b">title.txt</code>，我们可以调用<code class="fe on oo op od b">print(open(‘title.txt’,’r’).read())</code>。</p><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi or"><img src="../Images/14635c5c684d3713a79b1720e216f9ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B9RlA71POzfMcFS1xcIc2g.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">文件的一部分，实际文件要大得多。</p></figure><p id="3138" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，培训文件准备好了。有许多强大的库可以实现rnn，如Keras (TensorFlow)和Pytorch，但我们将使用一个库，它可以跳过选择名为<code class="fe on oo op od b">textgenrnn</code>的网络架构的复杂性。这个模块可以在3行代码中调用、训练和使用(如果从pip安装的话是4行)，代价是缺乏可定制性。</p><pre class="ni nj nk nl gt oc od oe of aw og bi"><span id="fba3" class="oh ml jj od b gy oi oj l ok ol">!pip install textgenrnn</span></pre><p id="fa03" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">…在Kaggle笔记本电脑环境中安装模块。如果在其他环境中操作，您可以移除<code class="fe on oo op od b">!</code>。</p><p id="1e5f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">训练很简单:</p><pre class="ni nj nk nl gt oc od oe of aw og bi"><span id="182a" class="oh ml jj od b gy oi oj l ok ol">from textgenrnn import textgenrnn<br/>textgen = textgenrnn()<br/>textgen.train_from_file('title.txt', num_epochs=50)</span></pre><p id="907c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">由于textgenrnn建立在Keras RNN框架上，它将输出一个熟悉的Keras进度跟踪打印:</p><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi os"><img src="../Images/684cecb9e1de11eff0d3ffe59fc4463c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BFQm63Ioc8oYG0elsRqL0Q.png"/></div></div></figure><p id="c8e6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这需要大约2.5小时来运行所有50个时期。</p><pre class="ni nj nk nl gt oc od oe of aw og bi"><span id="f0ad" class="oh ml jj od b gy oi oj l ok ol">textgen.generate(temperature=0.5)</span></pre><p id="4643" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">…可用于生成示例。“温度”是对生成的示例有多新颖的度量(越少，越新颖)。这是一种创造性(较小的温度)但又不会偏离任务本质太远的平衡，是适配不足和适配过度之间的平衡。</p><h2 id="930b" class="oh ml jj bd mm ot ou dn mq ov ow dp mu lh ox oy mw ll oz pa my lp pb pc na pd bi translated">最后是生成的视频片头！</h2><p id="758e" class="pw-post-body-paragraph ky kz jj la b lb nc kk ld le nd kn lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">为了显示模型随时间的进展，我将包括(大约)每10个时代的三个标题，然后留给您一个由50个时代模型生成的标题组成的宝库。</p><p id="df39" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">1个纪元(损失:1.9178) —</p><ul class=""><li id="4571" class="no np jj la b lb lc le lf lh nq ll nr lp ns lt nt nu nv nw bi translated">让我制造更多猫的时刻即将到来的时刻|时刻|时刻</li><li id="a9f1" class="no np jj la b lb nx le ny lh nz ll oa lp ob lt nt nu nv nw bi translated">Keryn迷失——Marlari Grace(独立之年)</li><li id="c179" class="no np jj la b lb nx le ny lh nz ll oa lp ob lt nt nu nv nw bi translated">阅读Omarakhondras | Now Cultu 1010–75</li></ul><p id="d047" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">10个时代(损失:0.9409) —</p><ul class=""><li id="0d2b" class="no np jj la b lb lc le lf lh nq ll nr lp ns lt nt nu nv nw bi translated">格莱美舞蹈系列帮助一个好的Teass形状|威尔·史密斯和第五季官方预告片</li><li id="7107" class="no np jj la b lb nx le ny lh nz ll oa lp ob lt nt nu nv nw bi translated">卡迪图书广告TBS上的舞蹈</li><li id="1c28" class="no np jj la b lb nx le ny lh nz ll oa lp ob lt nt nu nv nw bi translated">为什么你的男朋友穿手帕</li></ul><p id="ff87" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">20个时代(损失:0.5871) —</p><ul class=""><li id="c3e5" class="no np jj la b lb lc le lf lh nq ll nr lp ns lt nt nu nv nw bi translated">我妈妈给我买衣服！</li><li id="dd41" class="no np jj la b lb nx le ny lh nz ll oa lp ob lt nt nu nv nw bi translated">恐龙瑜伽挑战！！</li><li id="b026" class="no np jj la b lb nx le ny lh nz ll oa lp ob lt nt nu nv nw bi translated">电影-全部Tam | Lele Pons &amp; hule &amp; Jurassic continest for Anime | E！</li></ul><p id="2d9d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">30个时代(损失:0.3069) —</p><ul class=""><li id="99fd" class="no np jj la b lb lc le lf lh nq ll nr lp ns lt nt nu nv nw bi translated">镜面抛光的日本箔球挑战赛在液压机里粉碎-里面是什么？</li><li id="0172" class="no np jj la b lb nx le ny lh nz ll oa lp ob lt nt nu nv nw bi translated">为什么贾斯汀比伯是最差的SNL嘉宾| WWHL</li><li id="77fb" class="no np jj la b lb nx le ny lh nz ll oa lp ob lt nt nu nv nw bi translated">你从未见过的最著名的演员</li></ul><p id="ac80" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">40个时代(损失:0.1618) —</p><ul class=""><li id="4634" class="no np jj la b lb lc le lf lh nq ll nr lp ns lt nt nu nv nw bi translated">威尔·史密斯和乔尔·埃哲顿回答网上搜索最多的问题</li><li id="6844" class="no np jj la b lb nx le ny lh nz ll oa lp ob lt nt nu nv nw bi translated">亚当和詹娜的陈文静——舞者Sharisons &amp;揭示你的门ftta回答Saffle官员</li><li id="f8ad" class="no np jj la b lb nx le ny lh nz ll oa lp ob lt nt nu nv nw bi translated">Bravon去首尔Charman的Fabar Things 2买运动鞋</li></ul><p id="1cdc" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">…最后，前五个50时代(损失:0.1561)生成的标题！</p><ul class=""><li id="5179" class="no np jj la b lb lc le lf lh nq ll nr lp ns lt nt nu nv nw bi translated">我儿子帮我化妆</li><li id="4139" class="no np jj la b lb nx le ny lh nz ll oa lp ob lt nt nu nv nw bi translated">24小时BOX FORT监狱越狱</li><li id="9c88" class="no np jj la b lb nx le ny lh nz ll oa lp ob lt nt nu nv nw bi translated">利亚姆·佩恩去买运动鞋</li><li id="c8d1" class="no np jj la b lb nx le ny lh nz ll oa lp ob lt nt nu nv nw bi translated">星球大战:单身汉大结局</li><li id="70fd" class="no np jj la b lb nx le ny lh nz ll oa lp ob lt nt nu nv nw bi translated">迪士尼公主推着卡车</li></ul></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h1 id="f95b" class="mk ml jj bd mm mn mo mp mq mr ms mt mu kp mv kq mw ks mx kt my kv mz kw na nb bi translated">更进一步…</h1><p id="6312" class="pw-post-body-paragraph ky kz jj la b lb nc kk ld le nd kn lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">…这是一个关于RNNs能力的幽默例子。你可能已经注意到，随着时代数量的增加，这些想法越来越缺乏原创性——过度适应。这和我们限制训练例子的数量有关。如果您想自己尝试一下(并且有几个小时的计算时间)，您可以尝试只限制be类别，而不限制训练示例的数量(或者使用整个数据)，这样生成的标题可能会更有趣。</p></div><div class="ab cl md me hx mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="im in io ip iq"><h1 id="bfbe" class="mk ml jj bd mm mn mo mp mq mr ms mt mu kp mv kq mw ks mx kt my kv mz kw na nb bi translated">感谢阅读！</h1><p id="3e11" class="pw-post-body-paragraph ky kz jj la b lb nc kk ld le nd kn lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">如果你喜欢，你可以看看RNNs的其他一些有趣的应用:</p><ul class=""><li id="b410" class="no np jj la b lb lc le lf lh nq ll nr lp ns lt nt nu nv nw bi translated"><a class="ae jg" rel="noopener" target="_blank" href="/ai-writes-shakespearean-plays-e0d5f30c16b2">使用RNNs生成仿莎剧</a>(使用TensorFlow)</li><li id="6922" class="no np jj la b lb nx le ny lh nz ll oa lp ob lt nt nu nv nw bi translated"><a class="ae jg" rel="noopener" target="_blank" href="/death-match-ai-bernie-vs-ai-joe-87e80347b0a5">使用RNNs在艾·乔·拜登和艾·伯尼·桑德斯</a>之间创建一场辩论死亡赛(使用<code class="fe on oo op od b">textgenrnn</code></li></ul></div></div>    
</body>
</html>