<html>
<head>
<title>Zero to Hero in Computer Vision with TensorFlow 2 — Part I</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TensorFlow 2 计算机视觉从零到英雄—第一部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/zero-to-hero-in-computer-vision-with-tensorflow-2-part-i-973775b9b898?source=collection_archive---------26-----------------------#2020-09-16">https://towardsdatascience.com/zero-to-hero-in-computer-vision-with-tensorflow-2-part-i-973775b9b898?source=collection_archive---------26-----------------------#2020-09-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f6a8" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用 TensorFlow 开始使用神经网络的基本实现指南。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/1186c7645204b9fd249bfca31e217230.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9OG5H-uEJn7TYw7hLSglvA.png"/></div></div></figure><h2 id="c94f" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">免责声明！</h2><p id="a328" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">本系列不解释算法的底层数学，而只关注逻辑实现和使用带有特定参数集的特定算法的推理。学习神经网络和底层数学基础的资源包含在我的博客<a class="ae mj" href="https://medium.com/@harshit_tyagi/google-certified-tensorflow-developer-learning-plan-tips-faqs-my-journey-9f88016048e3?source=---------12------------------" rel="noopener">中，我是如何通过 TensorFlow 开发人员证书考试的</a>。</p><h1 id="13a0" class="mk kv it bd kw ml mm mn kz mo mp mq lc jz mr ka lg kc ms kd lk kf mt kg lo mu bi translated">计算机视觉导论</h1><p id="b4da" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">最近，计算机终于能够执行看似琐碎的任务，检测图像中的物体/有机体，甚至识别口语。</p><p id="5fd9" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">更重要的问题是，为什么这些任务对人类来说如此微不足道？<br/>简而言之，我们的意识缺乏理解这种感知的能力，这种感知利用了大脑中专门的视觉、听觉和其他感官模块。它是如此之快，以至于当感官信息到达我们的意识时，图像、视频或音频的高级特征已经被放大了。</p><p id="3bc7" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">卷积神经网络(CNN)已经从我们大脑视觉皮层的研究中出现，它们是一种深度学习模型，普遍用于计算机视觉应用。</p><p id="e83c" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">但是在我们深入开发 CNN 之前，让我们先研究一下深度神经网络的构建模块。</p><p id="435c" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">这篇博客文章通过两个例子的帮助涵盖了开发深度学习模型:</p><ol class=""><li id="f14c" class="na nb it ls b lt mv lw mw ld nc lh nd ll ne mi nf ng nh ni bi translated"><strong class="ls iu">用单神经元神经网络预测房价。</strong></li><li id="e15b" class="na nb it ls b lt nj lw nk ld nl lh nm ll nn mi nf ng nh ni bi translated"><strong class="ls iu">使用密集神经网络从图像中对时尚服装进行分类。</strong></li></ol><p id="30e6" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">让我们从第一个非常简单的神经网络的实现开始。</p><h1 id="04c6" class="mk kv it bd kw ml mm mn kz mo mp mq lc jz mr ka lg kc ms kd lk kf mt kg lo mu bi translated">构建最简单的神经网络</h1><p id="76b9" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">为了对神经网络如何工作有一个基本的了解，我选择了这个非常简单的房价预测的例子。我们将根据房子里卧室的数量来预测房价。</p><p id="6419" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">数据遵循简单的线性函数<code class="fe no np nq nr b"><em class="ns">y = mx + c</em></code> <em class="ns">。</em></p><p id="bc34" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">这些数据仅仅是经过组织的:对于每间卧室，我们增加了 50K 美元的成本，等式中的 y 轴截距(当 x = 0 时)是 50K</p><p id="63a1" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">我们不需要深度学习来解决这样的琐碎问题，这只是为了了解神经网络——它们是如何定义、编译、训练的，以及它们是如何进行预测的。</p><h2 id="b5e7" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">导入库</h2><p id="f906" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">因此，第一步是导入所需的库，这里是 TensorFlow 和 NumPy:</p><pre class="kj kk kl km gt nt nr nu nv aw nw bi"><span id="dc73" class="ku kv it nr b gy nx ny l nz oa">##importing the main deep learning</span><span id="ca87" class="ku kv it nr b gy ob ny l nz oa">import tensorflow as tf<br/>from tensorflow import keras<br/>import numpy as np</span><span id="66f7" class="ku kv it nr b gy ob ny l nz oa">print("Tensorflow Version: ", tf.__version__)<br/>print("Keras Version: ", keras.__version__)</span><span id="3cbc" class="ku kv it nr b gy ob ny l nz oa">##output: <br/>Tensorflow Version:  2.3.0 <br/>Keras Version:  2.4.0</span></pre><p id="5162" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">确保你用的是 TensorFlow 2.x，我们已经单独导入了 Keras，可以直接使用。</p><h2 id="c3fc" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">数据</h2><p id="9eb5" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">接下来，我们按照上面解释的公式定义数据:</p><pre class="kj kk kl km gt nt nr nu nv aw nw bi"><span id="4561" class="ku kv it nr b gy nx ny l nz oa">bedrooms = np.array([2,3,4,5,6,7])<br/>house_prices = np.array([150, 200, 250, 300, 350, 400])</span></pre><h2 id="4f36" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">模型定义</h2><p id="e601" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">这将是你建立的最简单的神经网络模型。我们只需要一层，并且那层中只有一个神经元。输入形状也是<code class="fe no np nq nr b">[1]</code>，因为我们有一维数据。</p><p id="5654" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">我们将使用 Keras' <code class="fe no np nq nr b">Sequential</code> API 来创建一系列相连的层:</p><pre class="kj kk kl km gt nt nr nu nv aw nw bi"><span id="c552" class="ku kv it nr b gy nx ny l nz oa">model = tf.keras.Sequential([<br/>    tf.keras.layers.Dense(units = 1, input_shape=[1])<br/>])</span></pre><p id="4532" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated"><code class="fe no np nq nr b">units</code> —层中神经元的数量。</p><p id="c450" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated"><code class="fe no np nq nr b">Dense</code> —构建密集的神经网络。虽然这个只有一层。</p><p id="1523" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated"><code class="fe no np nq nr b">input_shape</code>-告诉模型输入数据的维度。</p><h2 id="2a7c" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">模型汇编和培训</h2><p id="6dc3" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">如果你一直想知道数学在机器学习中的作用，这是你应该更多探索的部分。虽然，我们有令人惊讶的定义函数，很好地封装了数学。</p><pre class="kj kk kl km gt nt nr nu nv aw nw bi"><span id="3253" class="ku kv it nr b gy nx ny l nz oa"># model compilation<br/>model.compile(optimizer='sgd', loss='mean_squared_error')</span><span id="f30c" class="ku kv it nr b gy ob ny l nz oa">#model training<br/>model.fit(bedrooms, house_prices, epochs=100)</span></pre><p id="77aa" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">我们知道我们的数据遵循一个简单的数学函数，卧室(x)和房价(y)之间的关系是</p><p id="3867" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">y=50x+50。</p><p id="0537" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">当机器试图学习那个函数时，它会进行猜测…可能是 y=5x+10。然后，<code class="fe no np nq nr b">loss</code>函数根据实际答案评估这个猜测的答案，以测量模型预测的误差。</p><p id="6875" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated"><code class="fe no np nq nr b">optimizer</code>函数试图通过另一种猜测来改善这种损失。随着每一次预测，它会尽量减少损失。经过多次迭代(历元)，可能会达到一个接近 y=45x+45 的函数，这个函数仍然不正确，但更接近实际函数。</p><p id="76e9" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">我们使用<code class="fe no np nq nr b">mean_squared_error</code>作为优化器的损失函数和随机梯度下降(<code class="fe no np nq nr b">sgd</code>)。</p><p id="af0b" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">如何为特定场景找出合适的损失和优化函数是一项需要时间和实践来培养的技能。</p><h2 id="5ba0" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">模型预测法</h2><pre class="kj kk kl km gt nt nr nu nv aw nw bi"><span id="c2b2" class="ku kv it nr b gy nx ny l nz oa">print(model.predict([10]))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/e5c33352683a8ffc38156f9003b03735.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/1*0zH2BlVGiqkxCZWKJnpD3g.png"/></div></figure><p id="55b5" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">上图显示了一个 10 间卧室的房子的训练结果和图像末尾的预测值，该值应为 550，但模型预测值为 579.13。也许多训练几个时期的模型可以改进预测。你为什么不试试呢？</p></div><div class="ab cl od oe hx of" role="separator"><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi"/></div><div class="im in io ip iq"><h1 id="0b4a" class="mk kv it bd kw ml ok mn kz mo ol mq lc jz om ka lg kc on kd lk kf oo kg lo mu bi translated"><strong class="ak">构建密集神经网络，从图像中对时尚服装进行分类</strong></h1><p id="d879" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">既然我们对 TensorFlow 制作的序列模型的各个组件有了相当好的理解，那么我们解决复杂的问题就会容易得多，例如图像分类，其中包括基于手头数据的一些预处理，在模型中添加密集层，以及更改输入和输出神经元。</p><h2 id="cc1a" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">资料组</h2><p id="7ee4" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">我们使用的是<a class="ae mj" href="https://www.tensorflow.org/datasets/catalog/fashion_mnist" rel="noopener ugc nofollow" target="_blank">时尚 MNIST 数据集</a>，它是著名的 MNIST 数据集的替代品。它有 70，000 张 28x28 像素的灰度图像，但这些图像代表了时尚单品。因此，每一个阶层都更加多样化，问题也比 MNIST 更具挑战性。</p><p id="45f6" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">让我们使用 Keras 实用函数加载数据集，以获取和加载常见的数据集，包括 MNIST 和时尚 MNIST，以及其他许多数据集。</p><pre class="kj kk kl km gt nt nr nu nv aw nw bi"><span id="2dfc" class="ku kv it nr b gy nx ny l nz oa">##loading fashion MNIST dataset from tensorflow data API<br/>fashion_mnist = keras.datasets.fashion_mnist<br/>(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()</span></pre><p id="87a1" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated"><code class="fe no np nq nr b">load_data</code>方法将我们的图像分成训练和测试集。</p><p id="6ebe" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">让我们检查一下训练集的形状:</p><pre class="kj kk kl km gt nt nr nu nv aw nw bi"><span id="bd08" class="ku kv it nr b gy nx ny l nz oa">X_train.shape</span><span id="3c81" class="ku kv it nr b gy ob ny l nz oa">##output: <br/>(60000, 28, 28)</span></pre><p id="788a" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">我们的数据集中有 60，000 张图片，每张都是 28x28 像素。</p><p id="a7ce" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">类似地，我们在测试集中有 10，000 张图像。</p><p id="e1da" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">让我们看看打印出来的图像是什么样的:</p><pre class="kj kk kl km gt nt nr nu nv aw nw bi"><span id="e27d" class="ku kv it nr b gy nx ny l nz oa">X_train[0]</span><span id="f6fc" class="ku kv it nr b gy ob ny l nz oa">#output:</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/19b987bb9c4e97af8bb91d447a62fe49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*ug09sARJqBTVqIhiaegBUA.png"/></div></figure><p id="e39b" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">我们在一个 2D 阵列中有 28×28 个强度。所有这些强度都在 0-255 之间。</p><h2 id="38f8" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">从训练集创建验证集</h2><p id="52ee" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">由于我们在这里没有验证数据，我们将进一步分割我们的训练数据以创建验证集，如下所示:</p><ul class=""><li id="007e" class="na nb it ls b lt mv lw mw ld nc lh nd ll ne mi oq ng nh ni bi translated">为验证集保留前 5000 行图像。</li><li id="98c1" class="na nb it ls b lt nj lw nk ld nl lh nm ll nn mi oq ng nh ni bi translated">因为我们将使用梯度下降来训练神经网络，所以我们必须缩放输入特征，也就是说，我们将通过将强度除以 255.0 来将强度缩小到 0–1 范围</li></ul><pre class="kj kk kl km gt nt nr nu nv aw nw bi"><span id="c9ef" class="ku kv it nr b gy nx ny l nz oa">X_valid, X_train = X_train[:5000] / 255.0, X_train[5000:] / 255.0<br/>y_valid, y_train = y_train[:5000], y_train[5000:]<br/>X_test = X_test / 255.0</span></pre><p id="788b" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">此外，根据数据集描述，我们在数据集中有 10 种时尚服装，它们的编码都是从 0 到 9，我们将创建这些商品的列表:</p><pre class="kj kk kl km gt nt nr nu nv aw nw bi"><span id="8eeb" class="ku kv it nr b gy nx ny l nz oa">class_names = ["T-shirt/top", "Trouser", "Pullover", "Dress", "Coat","Sandal", "Shirt", "Sneaker", "Bag", "Ankle boot"]</span><span id="857b" class="ku kv it nr b gy ob ny l nz oa">class_names[y_train[1]]</span><span id="24be" class="ku kv it nr b gy ob ny l nz oa">#output: <br/>'T-shirt/Top'</span></pre><h2 id="c0ff" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">可视化数据集</h2><pre class="kj kk kl km gt nt nr nu nv aw nw bi"><span id="1c92" class="ku kv it nr b gy nx ny l nz oa">import matplotlib.pyplot as plt<br/>%matplotlib inline</span><span id="4e61" class="ku kv it nr b gy ob ny l nz oa">plt.imshow(X_train[0], cmap='binary')<br/>plt.axis('off')<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/d42331092d886a075aaa8c69079eb06a.png" data-original-src="https://miro.medium.com/v2/resize:fit:446/format:webp/1*43SZXY0nMqUXxln6sM5oPw.png"/></div></div></figure><p id="8ba0" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">看看前 40 件衣服，</p><pre class="kj kk kl km gt nt nr nu nv aw nw bi"><span id="d0ea" class="ku kv it nr b gy nx ny l nz oa">n_rows = 4<br/>n_cols = 10<br/>plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))<br/>for row in range(n_rows):<br/>    for col in range(n_cols):<br/>        index = n_cols * row + col<br/>        plt.subplot(n_rows, n_cols, index + 1)<br/>        plt.imshow(X_train[index], cmap="binary", interpolation="nearest")<br/>        plt.axis('off')<br/>        plt.title(class_names[y_train[index]], fontsize=12)<br/>plt.subplots_adjust(wspace=0.2, hspace=0.5)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/901433b3b559e173277f1862af958380.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*tkDNuFQAu63mEq8QOBp2CA.png"/></div></figure><h2 id="daca" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">模型定义</h2><p id="1e40" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">下一步是定义模型:</p><pre class="kj kk kl km gt nt nr nu nv aw nw bi"><span id="7430" class="ku kv it nr b gy nx ny l nz oa">model = keras.models.Sequential([<br/>    keras.layers.Flatten(input_shape=[28, 28]), # input flatten layer<br/>    keras.layers.Dense(300, activation='relu'),<br/>    keras.layers.Dense(100, activation='relu'),<br/>    keras.layers.Dense(10, activation='softmax') # output layer<br/>])</span></pre><p id="f7c5" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">让我们来分解一下这个模型:</p><ul class=""><li id="f2e8" class="na nb it ls b lt mv lw mw ld nc lh nd ll ne mi oq ng nh ni bi translated">我们已经为密集神经网络创建了一个<code class="fe no np nq nr b">Sequential</code> Keras 模型，该神经网络由顺序连接的单个层堆栈组成。</li><li id="d843" class="na nb it ls b lt nj lw nk ld nl lh nm ll nn mi oq ng nh ni bi translated">接下来，我们构建第一层，这是一个<code class="fe no np nq nr b">Flatten</code>层，它将每个输入图像转换成一个 1D 数组:如果它接收到输入数据<code class="fe no np nq nr b">X</code>，它将计算<code class="fe no np nq nr b">X.reshape(-1, 28*28)</code>。它是密集层之前的一个简单的预处理层。由于它是模型中的第一层，我们指定了<code class="fe no np nq nr b">input_shape</code>，它只包括实例的形状。</li><li id="d928" class="na nb it ls b lt nj lw nk ld nl lh nm ll nn mi oq ng nh ni bi translated">随后，我们添加一个有 300 个神经元的<code class="fe no np nq nr b">Dense</code>隐藏层。它还使用 ReLU 激活功能。</li><li id="9b24" class="na nb it ls b lt nj lw nk ld nl lh nm ll nn mi oq ng nh ni bi translated">接下来，我们添加第二个有 100 个神经元的<code class="fe no np nq nr b">Dense</code>隐藏层，同样使用 ReLU 激活函数。</li><li id="01cf" class="na nb it ls b lt nj lw nk ld nl lh nm ll nn mi oq ng nh ni bi translated">最后，我们添加一个有 10 个神经元的<code class="fe no np nq nr b">Dense</code>输出层(每个类一个)，使用 softmax 激活函数(因为类是排他的)。</li></ul><p id="e989" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">每个<code class="fe no np nq nr b">Dense</code>层管理自己的权重矩阵，包含神经元及其输入之间的所有连接权重。它还管理一个偏差项向量(每个神经元一个)。</p><p id="ab48" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">我们可以访问这些层、它们的初始化权重和偏差:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/1adfc21e834cf5b20d126d6d54c51e67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/1*B002Ir9_kRrAw0OyE9ZHuA.png"/></div></figure><p id="7816" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">模型摘要:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/0ad754cfacf281f83716c8d11765b931.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*N0foh7y_BdVggSXlw4BwGw.png"/></div></figure><p id="168b" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">权重和偏差:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/790f3624c3a046c924793e77b83b19e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/1*MnsPxrJLo8G7tT_Ta_He5Q.png"/></div></figure><h2 id="ca89" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">编译和训练模型</h2><pre class="kj kk kl km gt nt nr nu nv aw nw bi"><span id="2d6b" class="ku kv it nr b gy nx ny l nz oa">model.compile(loss="sparse_categorical_crossentropy",<br/>              optimizer="sgd",<br/>              metrics=["accuracy"])</span></pre><ol class=""><li id="26bc" class="na nb it ls b lt mv lw mw ld nc lh nd ll ne mi nf ng nh ni bi translated"><strong class="ls iu">损失</strong>:我们使用“稀疏 _ 分类 _ 交叉熵”损失，因为我们有稀疏标签(即，对于每个实例，只有一个目标类索引，在这种情况下从 0 到 9)，并且类是唯一的。</li><li id="ab3d" class="na nb it ls b lt nj lw nk ld nl lh nm ll nn mi nf ng nh ni bi translated"><strong class="ls iu">优化器</strong>:“SGD”表示我们将使用简单的随机梯度下降来训练模型。基本上，Keras 将执行所讨论的反向传播算法。</li><li id="ce4c" class="na nb it ls b lt nj lw nk ld nl lh nm ll nn mi nf ng nh ni bi translated"><strong class="ls iu"> Metrics </strong>:由于这是一个分类问题，测量模型的准确性会很有用。</li></ol><p id="e150" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated"><strong class="ls iu">训练:</strong></p><pre class="kj kk kl km gt nt nr nu nv aw nw bi"><span id="ee9f" class="ku kv it nr b gy nx ny l nz oa">history = model.fit(X_train, y_train, epochs=30, <br/>                     validation_data=(X_valid, y_valid))</span></pre><p id="db31" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">在历史对象中捕获模型训练历史，我们将使用它来绘制模型的损失和准确性。</p><h2 id="8560" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">模型评估</h2><p id="faa3" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">我们可以通过传递测试实例和实际标签来评估模型的性能。</p><pre class="kj kk kl km gt nt nr nu nv aw nw bi"><span id="86a7" class="ku kv it nr b gy nx ny l nz oa">model.evaluate(X_test, y_test)</span><span id="300b" class="ku kv it nr b gy ob ny l nz oa"># output:<br/>313/313 [==============================] - 0s 533us/step - loss: 0.3326 - accuracy: 0.8823<br/>[0.3326309025287628, 0.8823000192642212]</span></pre><p id="c02f" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">该模型在这一点上具有 88%的准确性。您可以使用不同的参数来调整模型，以查看效果。</p><h2 id="2c3c" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">绘制模型历史</h2><pre class="kj kk kl km gt nt nr nu nv aw nw bi"><span id="29c8" class="ku kv it nr b gy nx ny l nz oa">history = pd.DataFrame(history.history)<br/>history.plot(figsize = (12,8))</span><span id="da1c" class="ku kv it nr b gy ob ny l nz oa">plt.grid(True)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ow"><img src="../Images/74ee8bdbc5fee80ea928e4bb9aa5d539.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ffU1Ko7xZ42Cwl5z19aYfQ.png"/></div></div></figure><p id="dcab" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">您可以看到，历史记录有助于我们将模型训练准确性和损失与验证准确性和验证损失进行比较，即模型对未知数据的性能。</p><p id="fe90" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">与其在训练数据上的性能相比，模型的性能总是略低。如果模型在训练和测试数据上的准确度较低，那么我们会遇到<strong class="ls iu">欠拟合</strong>的情况，但是如果模型在训练和数据上表现准确，而在验证数据上表现不太准确，那么我们会遇到<strong class="ls iu">过拟合</strong>的情况。</p><h2 id="406a" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">对样本测试图像进行随机预测</h2><p id="80ae" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">在测试数据集样本上运行它:</p><pre class="kj kk kl km gt nt nr nu nv aw nw bi"><span id="655a" class="ku kv it nr b gy nx ny l nz oa"># extracting first 5 sample images<br/>X_sample = X_test[:5]<br/>y_proba = model.predict(X_sample)<br/>y_proba.round(2)</span><span id="58d9" class="ku kv it nr b gy ob ny l nz oa">y_pred = model.predict_classes(X_sample)<br/>y_pred</span><span id="664d" class="ku kv it nr b gy ob ny l nz oa">#output:<br/>array([9, 2, 1, 1, 6])</span></pre><p id="fc9d" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">我们可以使用上面创建的列表获得这些服装的名称:</p><pre class="kj kk kl km gt nt nr nu nv aw nw bi"><span id="42bc" class="ku kv it nr b gy nx ny l nz oa">np.array(class_names)[y_pred]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/31e53f1fd2e18097ea9cccbd58717737.png" data-original-src="https://miro.medium.com/v2/resize:fit:1102/format:webp/1*6ppmlZcf3PgDSA3_54tREw.png"/></div></figure><p id="a8e4" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">实际标签:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/0d975ac2d8080818ab2b621a65fcea14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1106/format:webp/1*dqpQaofM3d859C-moCzC7A.png"/></div></figure><p id="09f5" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">您可以使用 Google Colab 笔记本试用这些模型并测试其他功能和参数:</p><div class="oz pa gp gr pb pc"><a href="https://colab.research.google.com/github/dswh/tf-end-to-end-image-classification/blob/master/Introduction.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="pd ab fo"><div class="pe ab pf cl cj pg"><h2 class="bd iu gy z fp ph fr fs pi fu fw is bi translated">谷歌联合实验室</h2><div class="pj l"><h3 class="bd b gy z fp ph fr fs pi fu fw dk translated">编辑描述</h3></div><div class="pk l"><p class="bd b dl z fp ph fr fs pi fu fw dk translated">colab.research.google.com</p></div></div><div class="pl l"><div class="pm l pn po pp pl pq ks pc"/></div></div></a></div><blockquote class="pr ps pt"><p id="ff35" class="lq lr ns ls b lt mv ju lv lw mw jx ly pu mx ma mb pv my md me pw mz mg mh mi im bi translated">注意:这将是一系列博客(可能有 3 个)，我们将在其中讨论基本的计算机视觉问题，用卷积对真实世界的图像进行分类&amp;汇集并使用预先训练的模型来解决复杂的问题。</p></blockquote><p id="a800" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">以下是这篇博客的视频版本:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="px py l"/></div></figure><h1 id="39eb" class="mk kv it bd kw ml mm mn kz mo mp mq lc jz mr ka lg kc ms kd lk kf mt kg lo mu bi translated"><a class="ae mj" href="https://www.youtube.com/c/DataSciencewithHarshit?sub_confirmation=1" rel="noopener ugc nofollow" target="_blank">数据科学与 Harshit </a></h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="px py l"/></div></figure><p id="d034" class="pw-post-body-paragraph lq lr it ls b lt mv ju lv lw mw jx ly ld mx ma mb lh my md me ll mz mg mh mi im bi translated">通过这个渠道，我计划推出几个覆盖整个数据科学领域的<a class="ae mj" rel="noopener" target="_blank" href="/hitchhikers-guide-to-learning-data-science-2cc3d963b1a2?source=---------8------------------">系列</a>。以下是你应该订阅<a class="ae mj" href="https://www.youtube.com/channel/UCH-xwLTKQaABNs2QmGxK2bQ" rel="noopener ugc nofollow" target="_blank">频道</a>的原因:</p><ul class=""><li id="d182" class="na nb it ls b lt mv lw mw ld nc lh nd ll ne mi oq ng nh ni bi translated">这些系列将涵盖每个主题和子主题的所有必需/要求的高质量教程，如<a class="ae mj" rel="noopener" target="_blank" href="/python-fundamentals-for-data-science-6c7f9901e1c8?source=---------5------------------">数据科学的 Python 基础</a>。</li><li id="5b12" class="na nb it ls b lt nj lw nk ld nl lh nm ll nn mi oq ng nh ni bi translated">解释了为什么我们在 ML 和深度学习中这样做的数学和推导。</li><li id="8e75" class="na nb it ls b lt nj lw nk ld nl lh nm ll nn mi oq ng nh ni bi translated"><a class="ae mj" href="https://www.youtube.com/watch?v=a2pkZCleJwM&amp;t=2s" rel="noopener ugc nofollow" target="_blank">与谷歌、微软、亚马逊等公司的数据科学家和工程师</a>以及大数据驱动型公司的首席执行官的播客。</li><li id="2a4e" class="na nb it ls b lt nj lw nk ld nl lh nm ll nn mi oq ng nh ni bi translated"><a class="ae mj" rel="noopener" target="_blank" href="/building-covid-19-analysis-dashboard-using-python-and-voila-ee091f65dcbb?source=---------2------------------">项目和说明</a>实施到目前为止所学的主题。了解新的认证、训练营以及破解这些认证的资源，例如 Google 举办的<a class="ae mj" href="https://youtu.be/yapSsspJzAw" rel="noopener ugc nofollow" target="_blank"> <strong class="ls iu"> TensorFlow 开发者证书考试。</strong>T15】</a></li></ul></div></div>    
</body>
</html>