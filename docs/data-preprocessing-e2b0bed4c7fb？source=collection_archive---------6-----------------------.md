# 了解数据预处理

> 原文：<https://towardsdatascience.com/data-preprocessing-e2b0bed4c7fb?source=collection_archive---------6----------------------->

![](img/7cc393d967d653c3f2c67d58d3eff364.png)

弗兰基·查马基在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

数据预处理是一项重要的任务。它是一种数据挖掘技术，将原始数据转换成更容易理解、有用和有效的格式。

> 数据有更好的想法。这种思路在进行数据预处理后会更加清晰易懂。

## 为什么需要数据预处理？

真实世界的数据通常是:

**不完整:**某些属性或值或两者缺失，或者只有汇总数据。

**噪音:**数据包含错误或异常值

**不一致:**数据包含代码或名称等差异。

# 数据预处理中的任务

1.  **数据清洗:**又称擦洗。这项任务包括填充缺失值、平滑或去除噪声数据和异常值，以及解决不一致问题。
2.  **数据集成:**该任务涉及集成来自多个来源的数据，如数据库(关系型和非关系型)、数据立方体、文件等。数据源可以是同类的，也可以是异类的。从源获得的数据在格式上可以是结构化的、非结构化的或半结构化的。
3.  **数据转换:**这包括根据数据集的需要对数据进行标准化和汇总。
4.  **数据缩减:**在此步骤中，数据被缩减。可以减少记录的数量或属性或维度的数量。进行缩减时要记住，缩减后的数据应该产生与原始数据相同的结果。
5.  **数据离散化:**被认为是数据约简的一部分。数值属性被标称属性取代。

# 数据清理

数据清理过程检测并消除数据中存在的错误和不一致，并提高数据质量。由于数据输入过程中的拼写错误、缺少值或任何其他无效数据，会出现数据质量问题。基本上，“脏”数据被转换成干净的数据。“脏”数据不会产生准确而好的结果。垃圾数据给出了垃圾。因此处理这些数据变得非常重要。专业人士在这一步花了很多时间。

## “脏”或“不干净”数据的原因

1.  虚拟值
2.  数据缺失
3.  违反商业规则
4.  数据集成问题
5.  矛盾的数据
6.  地址线使用不当
7.  重用的主键
8.  非唯一标识符

## 如何清理数据？

1.  处理缺失值
2.  处理噪音和异常值
3.  删除不需要的数据

## 处理缺失值

无法在数据集中查看缺失值。他们必须被处理。此外，许多模型不接受缺失值。有几种处理缺失数据的技术，选择正确的技术至关重要。处理缺失数据的技术选择取决于问题域和数据挖掘过程的目标。处理缺失数据的不同方法有:

1.  **忽略数据行:**对于缺少最大数量数据的记录，建议使用这种方法，这样记录就没有意义了。当只有较少的属性值丢失时，通常避免使用这种方法。如果忽略(即删除)所有缺失值的行，将会导致性能下降。
2.  **手动填充缺少的值:**这是一个非常耗时的方法，因此对于几乎所有场景都不可行。
3.  **使用一个全局常量来填充缺失值:**像“NA”或 0 这样的全局常量可以用来填充所有缺失的数据。这种方法用于难以预测缺失值的情况。
4.  **使用属性均值或中值:**属性的均值或中值用于填充缺失值。
5.  **使用向前填充或向后填充方法:**在这种情况下，要么使用前一个值，要么使用下一个值来填充缺少的值。也可以使用先前和后续值的平均值。
6.  使用数据挖掘算法预测最可能的值

## 处理噪音和异常值

数据中的噪声可能由于数据收集中的错误、数据输入期间的错误或由于数据传输错误等而被引入。未知的编码(例如:婚姻状况— Q)、超出范围的值(例如:年龄— 10)、不一致的数据(例如:出生日期—1999 年 10 月 4 日，年龄— 50)、不一致的格式(例如:司法部—2000 年 1 月 13 日，出生日期—2016 年 10 月 10 日)等。是不同类型的噪声和异常值。

可以使用**宁滨处理噪音。**在这种技术中，排序后的数据被放入箱或桶中。可以通过等宽(距离)或等深(频率)划分来创建箱。在这些箱上，可以应用平滑。平滑可以通过条均值、条中值或条边界来实现。

使用宁滨平滑异常值，然后对其进行平滑。它们可以通过视觉分析或箱线图检测出来。聚类可用于识别离群数据组。可以平滑或去除检测到的异常值。

## 删除不需要的数据

不需要的数据是重复的或不相关的数据。如果效率不高，从不同来源抓取数据然后集成可能会导致一些重复数据。应该删除这些冗余数据，因为它们没有任何用处，只会增加数据量和训练模型的时间。此外，由于冗余记录，该模型可能无法提供准确的结果，因为重复数据会干扰分析过程，从而使重复值更加重要。

# 数据集成

在这个步骤中，准备一个相干数据源。这是通过从多个来源(如数据库、遗留系统、平面文件、数据立方体等)收集和集成数据来实现的。

> 数据就像垃圾。在你收集它之前，你最好知道你要用它做什么。——马克·吐温

## 数据集成中的问题

1.  **模式集成:**来自不同来源的元数据(即模式)可能不兼容。这就导致了*实体识别问题* **。**例:考虑两个数据源 R 和 S，R 中的客户 id 表示为 cust_id，S 中表示为 c_id。它们表示相同的东西，代表相同的东西，但是有不同的名称，这导致了集成问题。检测和解决这些问题对于获得一致的数据源非常重要。
2.  **数据值冲突:**对于不同数据源中的相同真实世界实体，相同数据的值、度量或表示可能不同。这导致相同数据的不同表示、不同的比例等。示例:数据源 R 中的重量以千克表示，而源 S 中的重量以克表示。要解决这个问题，应该使数据表示一致，并相应地执行转换。
3.  **冗余数据:**在整合不同来源的数据时，可能会出现重复的属性或元组。这也可能导致不一致。通过仔细整合来自多个来源的数据，可以减少这些冗余或不一致。这将有助于提高挖掘速度和质量。此外，可以执行相关分析来检测冗余数据。

# 数据整理

如果数据非常大，则执行数据缩减。有时，还会从大量属性中找出最合适的属性子集。这就是所谓的降维。数据简化还包括减少属性值的数量和/或元组的数量。各种数据简化技术包括:

1.  **数据立方体聚集:**在这种技术中，通过应用像切片、切块或卷起这样的 OLAP 操作来减少数据。它使用解决问题所需的最小级别。
2.  **降维:**对数据属性或维度进行降维。并非所有属性都是数据挖掘所必需的。通过使用如正向选择、反向消除、决策树归纳或正向选择和反向消除的组合的技术来选择最合适的属性子集。
3.  **数据压缩:**在这种技术中。大量数据被压缩，即用于存储数据的位数减少。这可以通过使用有损或无损压缩来实现。在*有损压缩中，*为了进一步压缩，数据质量会受到影响。在*无损压缩中，*更高的压缩级别不会影响数据质量。
4.  **数量减少:**这种技术通过选择更小的数据表示形式来减少数据量。可以使用直方图、聚类或数据采样来减少数量。减少数量是必要的，因为处理整个数据集既昂贵又耗时。