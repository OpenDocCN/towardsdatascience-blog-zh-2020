<html>
<head>
<title>A Quick Deep Learning Recipe: Time Series Forecasting with Keras in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一个快速的深度学习方法:用 Python 中的 Keras 进行时间序列预测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-quick-deep-learning-recipe-time-series-forecasting-with-keras-in-python-f759923ba64?source=collection_archive---------5-----------------------#2020-03-28">https://towardsdatascience.com/a-quick-deep-learning-recipe-time-series-forecasting-with-keras-in-python-f759923ba64?source=collection_archive---------5-----------------------#2020-03-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="bf0b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在本教程中，我们将讨论/比较三个不同的人工神经网络(DNN、RNN 和 LTSM)在同一个<strong class="js iu">单变量</strong>数据集上的表现——一家电子商务公司的广告日常支出。</p><h1 id="8049" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">目录</h1><ol class=""><li id="0cc1" class="lm ln it js b jt lo jx lp kb lq kf lr kj ls kn lt lu lv lw bi translated"><strong class="js iu">简介</strong></li></ol><ul class=""><li id="0914" class="lm ln it js b jt ju jx jy kb lx kf ly kj lz kn ma lu lv lw bi translated">时间序列分析</li><li id="6196" class="lm ln it js b jt mb jx mc kb md kf me kj mf kn ma lu lv lw bi translated">为什么选择深度学习</li><li id="48a0" class="lm ln it js b jt mb jx mc kb md kf me kj mf kn ma lu lv lw bi translated">进行深度学习的过程</li></ul><p id="eb49" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">2.<strong class="js iu">车型</strong></p><ul class=""><li id="ff67" class="lm ln it js b jt ju jx jy kb lx kf ly kj lz kn ma lu lv lw bi translated">DNNs</li><li id="ffa8" class="lm ln it js b jt mb jx mc kb md kf me kj mf kn ma lu lv lw bi translated">RNNs</li><li id="d3de" class="lm ln it js b jt mb jx mc kb md kf me kj mf kn ma lu lv lw bi translated">LSTM</li></ul><p id="f929" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">3.<strong class="js iu">对比车型</strong></p><p id="dcbe" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">4.<strong class="js iu">期末总结</strong></p><h1 id="ac71" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">1.1 时间序列分析</h1><p id="4346" class="pw-post-body-paragraph jq jr it js b jt lo jv jw jx lp jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">详细说明在我以前的帖子<a class="ae mj" rel="noopener" target="_blank" href="/a-quick-start-of-time-series-forecasting-with-a-practical-example-using-fb-prophet-31c4447a2274">这里</a>。</p><h1 id="99a1" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">1.2 为什么选择深度学习</h1><p id="1004" class="pw-post-body-paragraph jq jr it js b jt lo jv jw jx lp jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">我们知道统计模型可以预测时间序列。但是，这些方法有一些限制:</p><ol class=""><li id="1822" class="lm ln it js b jt ju jx jy kb lx kf ly kj lz kn lt lu lv lw bi translated">需要<strong class="js iu">完成</strong>数据进行培训。某些缺失值会导致模型的性能非常差。尽管有一些方法可以处理丢失的值，但是很难做到</li><li id="2c95" class="lm ln it js b jt mb jx mc kb md kf me kj mf kn lt lu lv lw bi translated">通常，处理<strong class="js iu">单变量</strong>数据集，应用于<strong class="js iu">多变量</strong>数据集具有挑战性</li><li id="ff90" class="lm ln it js b jt mb jx mc kb md kf me kj mf kn lt lu lv lw bi translated"><strong class="js iu">对缺失值敏感</strong></li></ol><p id="766f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">深度学习方法能够应对上述挑战:</p><ol class=""><li id="ecce" class="lm ln it js b jt ju jx jy kb lx kf ly kj lz kn lt lu lv lw bi translated">对缺失值不敏感</li><li id="5ed3" class="lm ln it js b jt mb jx mc kb md kf me kj mf kn lt lu lv lw bi translated">合并外生变量的容易程度(适用于<strong class="js iu">单变量</strong>数据集和<strong class="js iu">多变量</strong>数据集<strong class="js iu"> ) </strong></li><li id="9c1e" class="lm ln it js b jt mb jx mc kb md kf me kj mf kn lt lu lv lw bi translated">捕捉<strong class="js iu">非线性</strong>特征交互</li><li id="fc1b" class="lm ln it js b jt mb jx mc kb md kf me kj mf kn lt lu lv lw bi translated">自动特征提取</li></ol><p id="4db8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我将简要解释神经网络方法的关键组件/概念，并展示如何用 python 代码中的 Keras 一步一步地应用神经网络。对于每个模型，我将遵循 5 个步骤来展示如何使用 Keras 建立一个预测时间序列的基本网络。</p><ol class=""><li id="c72a" class="lm ln it js b jt ju jx jy kb lx kf ly kj lz kn lt lu lv lw bi translated">预处理</li><li id="4f51" class="lm ln it js b jt mb jx mc kb md kf me kj mf kn lt lu lv lw bi translated">定义神经网络形状和模型编译</li><li id="f209" class="lm ln it js b jt mb jx mc kb md kf me kj mf kn lt lu lv lw bi translated">拟合模型</li><li id="4047" class="lm ln it js b jt mb jx mc kb md kf me kj mf kn lt lu lv lw bi translated">估价</li><li id="b580" class="lm ln it js b jt mb jx mc kb md kf me kj mf kn lt lu lv lw bi translated">可视化预测</li></ol><p id="d5af" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，让我们编码吧！</p><p id="5296" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">首先，快速浏览一下数据集:2017 年 1 月 1 日至 2019 年 9 月 23 日的广告日支出包括 996 天。数据集的前五行:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi mk"><img src="../Images/ebf4b02a7d8027955b3f6c8c42ed40d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PViiSD0RnIta07WArc1dOQ.png"/></div></div><p class="mw mx gj gh gi my mz bd b be z dk translated">数据帧的前五行</p></figure><p id="0bb9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">绘制滚动平均值以可视化趋势/季节性，并运行<a class="ae mj" href="https://en.wikipedia.org/wiki/Dickey%E2%80%93Fuller_test" rel="noopener ugc nofollow" target="_blank"> Dickey-Fuller 测试</a>以检查数据集的平稳性，与我们在之前的教程第一部分和第二部分中所做的一样。</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi na"><img src="../Images/cff30fe00ecf00b64f01107ff9c57a00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NqFFmP6ztLe4FXpIfLnzmQ.png"/></div></div></figure><h1 id="3d5f" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">模式 1: DNN</h1><p id="569b" class="pw-post-body-paragraph jq jr it js b jt lo jv jw jx lp jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated"><em class="nb">一个深度神经网络(</em><strong class="js iu"><em class="nb">【DNN】</em></strong><em class="nb">)是一个</em> <strong class="js iu"> <em class="nb">人工神经网络</em> </strong> <em class="nb"> ( </em> <strong class="js iu"> <em class="nb">安</em> </strong> <em class="nb">)在输入层</em> <strong class="js iu"> <em class="nb">和输出层</em></strong><em class="nb"/>—<a class="ae mj" href="https://en.wikipedia.org/wiki/Deep_learning" rel="noopener ugc nofollow" target="_blank">来自维基</a></p><p id="f52f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如何对时间序列数据应用 DNN？这里的<strong class="js iu">关键思想</strong>是:我们把时间序列看作线性模型:{X(i) …X(i+t)}~Y(i+t+1)。在该格式中，显示了使用 t 步输入时间序列来预测下一步 Y(i+t+1)。</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi nc"><img src="../Images/5fdbcd6b4123ac5f3e08dcbb61548f70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*27ZYFO6l4ODcKEIzoNXFXg.png"/></div></div><p class="mw mx gj gh gi my mz bd b be z dk translated">带有一个隐藏层的简单 DNN</p></figure><p id="783c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在图中，我显示了一个隐藏层的 DNN 结构。接下来，让我们看看如何在我们的广告支出数据上实现这个模型。</p><p id="4be5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第一步:数据预处理</strong></p><p id="756a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">导入 convert2matrix 的辅助函数来修整数据集，以便创建 DNN 的二维输入形状。一个完全连接的网络——RNN 和 LTSM 的主要区别</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="dd92" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">将数据集分为测试数据集和训练数据集。</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="1d16" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第二步:定义神经网络形状并编译模型</strong></p><p id="ec13" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我建立了一个非常简单的 DNN，只有一个隐藏层。</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="078b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第三步:拟合模型</strong></p><p id="bf50" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">model=model_dnn(回看)</p><p id="90db" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">history=model.fit(trainX，trainY，epochs=100，batch_size=30，verbose=1，validation_data=(testX，testY)，callbacks =[early stopping(monitor = ' val _ loss '，patience=10)]，shuffle=False)</p><p id="03dd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第四步:模型评估</strong></p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div></figure><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="e795" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">打印出误差指标并生成模型损耗图。</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi nf"><img src="../Images/704b334e96b0c0f0e312d47d613772e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jTLA_N47lKyMnlmAOHReXA.png"/></div></div></figure><p id="9a0a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从上面的图表中，很明显我们过度拟合了我们的模型，因为模型在 40 个时期后几乎没有做任何事情。</p><p id="2c2f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">步骤五。可视化预测</strong></p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="4751" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过调用以下命令检查预测图:</p><p id="11be" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">预测 _ 绘图(测试，测试 _ 预测)</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi ng"><img src="../Images/2e879d0255edb1227a33fc7d93f5ae14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mAcDhO7O9OQP5GZvTX4URw.png"/></div></div></figure><p id="1fd4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从图上看，尽管它错过了一些波峰和波谷，但它能够捕捉总体趋势和季节性，而无需任何参数调整或归一化预处理。</p><h1 id="49cc" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">模式 2: RNN</h1><p id="6513" class="pw-post-body-paragraph jq jr it js b jt lo jv jw jx lp jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated"><strong class="js iu"> RNN(递归神经网络)</strong>处理的序列不同于之前显示的全连接 DNN。</p><p id="bcbd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这里的<strong class="js iu">关键思想</strong>:时序数据集是序列。</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi nc"><img src="../Images/9ecb6f41de700ff2800ea7d545880207.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D5xg4AYoZQvteXhp5eWjGA.png"/></div></div><p class="mw mx gj gh gi my mz bd b be z dk translated">有两个隐藏层的 RNN</p></figure><p id="e1b0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将在下面的案例研究中看到这个 RNN 形状。</p><p id="6682" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第一步:数据预处理</strong></p><p id="2a28" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">RNN 输入形状:(批量大小，窗口大小，输入特征)</p><p id="fd9d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">导入助手函数以创建矩阵</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div></figure><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="964b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第二步:定义神经网络形状并编译模型</strong></p><p id="d5db" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">建立了一个有两个隐藏层的 RNN 模型。</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="6dbd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第三步:拟合模型</strong></p><p id="7253" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">模型=模型 _rnn(回望)</p><p id="14a8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">history=model.fit(trainX，trainY，epochs=100，batch_size=30，verbose=1，validation_data=(testX，testY)，callbacks =[early stopping(monitor = ' val _ loss '，patience=10)]，shuffle=False)</p><p id="e356" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第四步:模型评估</strong></p><p id="bc78" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">打印出误差指标并生成模型损耗图。</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div><p class="mw mx gj gh gi my mz bd b be z dk translated"><strong class="ak">产量低于</strong></p></figure><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi nh"><img src="../Images/efb52674faae5d39534b2e243ea8280c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jugG0rseCavmAaEn82oTRA.png"/></div></div></figure><p id="ecb2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从上面的图表中，很明显我们过度拟合了我们的模型，因为模型在 20 个时期后几乎没有做任何事情。</p><p id="638a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第五步。可视化预测</strong></p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div></figure><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi ni"><img src="../Images/8a536a3fc885839514133f2ce046af3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aCKbsbxo2_krUk9sVubGbg.png"/></div></div></figure><p id="a13f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一般来说，预测看起来不错，测试误差较小。尽管它错过了一些高峰和低谷，但它能够捕捉总体趋势和季节性。</p><h1 id="c227" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">模式 3:LSTM——RNN 家庭的一员</h1><p id="bfcc" class="pw-post-body-paragraph jq jr it js b jt lo jv jw jx lp jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">LSTM(长短期记忆)，由四个主要部件构成:输入门、输出门、存储单元和遗忘门</p><ul class=""><li id="476b" class="lm ln it js b jt ju jx jy kb lx kf ly kj lz kn ma lu lv lw bi translated"><strong class="js iu">输入门</strong>:控制向单元格状态添加信息。换句话说，输入门将考虑哪些信息应该添加到单元状态，以确保添加重要信息而不是冗余信息或噪声。</li><li id="8210" class="lm ln it js b jt mb jx mc kb md kf me kj mf kn ma lu lv lw bi translated"><strong class="js iu">内存</strong> <strong class="js iu">单元格</strong> : (1)控制可以删除或刷新的值(2)包含可能需要保存的值，作为许多其他时间步骤的附加信息。</li><li id="1d2c" class="lm ln it js b jt mb jx mc kb md kf me kj mf kn ma lu lv lw bi translated"><strong class="js iu">输出门</strong>:控制从当前单元状态中选择有用的学习信息作为输出。</li><li id="5d61" class="lm ln it js b jt mb jx mc kb md kf me kj mf kn ma lu lv lw bi translated"><strong class="js iu">遗忘门</strong>:控制从细胞状态中删除 LTSM 学习不再需要或不太重要的信息。这有助于优化 LSTM 网络的性能。</li></ul><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi nj"><img src="../Images/9f7e0ad89897ade7315630c6ef827b86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ETvfq2Oo_lPe7iTde5QxUg.png"/></div></div><p class="mw mx gj gh gi my mz bd b be z dk translated">我修改了 https://en.wikipedia.org/wiki/Long_short-term_memory 的原始图片</p></figure><p id="c006" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第一步:数据预处理:</strong></p><p id="2143" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">LSTMs 对输入数据的规模很敏感。在预处理步骤中，我应用了 scikit-learn 模块中的<strong class="js iu"> MinMaxScaler </strong>预处理类来标准化/重定数据集。</p><p id="77e3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">导入助手函数以创建矩阵</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="a33f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">将数据集的范围重新调整为 0–1。</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="b270" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">将数据集分为训练数据集和测试数据集。为 LSTM 创建输入三维输入形状。</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="6e44" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第二步:定义神经网络形状并编译模型</strong></p><p id="d11a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这里，一个非常简单的两层 LTSM 没有隐藏层</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="b8ab" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第三步:拟合模型</strong></p><p id="a33a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">model=model_lstm(回望)</p><p id="cc17" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">history = model.fit(trainX，trainY，epochs=100，batch_size=30，validation_data=(testX，testY)，callbacks =[early stopping(monitor = ' val _ loss '，patience=10)]，verbose=1，shuffle=False)</p><p id="ab78" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这里有一个小提示:通常，当 LSTM 表现出过度适应时，尝试 GRU(门控循环单元)是 LSTM 的“简化版”。</p><p id="b920" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第四步:模型评估</strong></p><p id="2836" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">打印出误差指标并生成模型损耗图。</p><figure class="ml mm mn mo gt mp"><div class="bz fp l di"><div class="nd ne l"/></div></figure><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi nk"><img src="../Images/e9caa2a856a3e99c38db1965981e5217.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oknwNTsfH3bEQ2EasltV7A.png"/></div></div></figure><p id="a12d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从上面的图表中，很明显我们过度拟合了我们的模型，因为模型在 20 个时期后几乎没有做任何事情。</p><p id="955c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过在本文中比较不同模型的误差度量，我们得到了更好的结果(LSTM 显示了更小的误差度量)。迄今为止，LSTM 的表现优于其他两款车型。我们预测大约 2 个月(具体来说是 65 天)，MAE 等于 3744。换句话说，2 个月的预测广告支出将比实际支出少大约 3744 美元。平均每月花费 250 万美元以上。这是一个非常好的预测！此外，这是对我另一篇文章中的<a class="ae mj" rel="noopener" target="_blank" href="/time-series-forecasting-with-statistical-models-in-python-code-da457a46d68a">统计模型结果的一大改进。</a></p><p id="240a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">第五步。可视化预测</strong></p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi nl"><img src="../Images/63a07b6aff2cc88bf9ad1984c25b198c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5XXV1Vj6lnC2IQGLuR2E4g.png"/></div></div></figure><p id="3f50" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">尽管它不能完美地捕捉所有的波峰和波谷，但在这个用例中，它确实比 DNN 或 RNN 模型做了更好的预测。</p><h1 id="e178" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated"><strong class="ak">总结</strong></h1><p id="8ccc" class="pw-post-body-paragraph jq jr it js b jt lo jv jw jx lp jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">到目前为止，我展示了在这个用例中使用深度学习来预测单变量时间序列数据。实际上，深度学习可以做得更多！我们可以通过添加其他特征(如星期几、节假日、经济影响等)将单变量时间序列数据转换为多变量时间序列，这对于应用于传统的统计模型来说是一个挑战。</p><p id="ae10" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">除了为输入数据添加更多特征之外，还可以考虑其他过程来改进神经网络。</p><ul class=""><li id="1d96" class="lm ln it js b jt ju jx jy kb lx kf ly kj lz kn ma lu lv lw bi translated">增加嵌入输出大小</li><li id="1337" class="lm ln it js b jt mb jx mc kb md kf me kj mf kn ma lu lv lw bi translated">添加批量标准化图层</li><li id="e927" class="lm ln it js b jt mb jx mc kb md kf me kj mf kn ma lu lv lw bi translated">尝试不同的学习率，激活功能，其他超参数</li><li id="89cf" class="lm ln it js b jt mb jx mc kb md kf me kj mf kn ma lu lv lw bi translated">稍后添加辍学</li><li id="26b1" class="lm ln it js b jt mb jx mc kb md kf me kj mf kn ma lu lv lw bi translated">尝试其他模式，如 GRU 或切换到<a class="ae mj" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank">有线电视新闻网</a></li><li id="a525" class="lm ln it js b jt mb jx mc kb md kf me kj mf kn ma lu lv lw bi translated">等等。</li></ul><h2 id="bfdf" class="nm kp it bd kq nn no dn ku np nq dp ky kb nr ns lc kf nt nu lg kj nv nw lk nx bi translated">参考资料:</h2><div class="ny nz gp gr oa ob"><a href="http://cs231n.stanford.edu/" rel="noopener  ugc nofollow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd iu gy z fp og fr fs oh fu fw is bi translated">用于视觉识别的卷积神经网络</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">计算机视觉在我们的社会中已经变得无处不在，在搜索、图像理解、应用程序、地图绘制…</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">cs231n.stanford.edu</p></div></div><div class="ok l"><div class="ol l om on oo ok op mu ob"/></div></div></a></div><div class="ny nz gp gr oa ob"><a href="https://github.com/keras-team/keras/tree/master/examples" rel="noopener  ugc nofollow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd iu gy z fp og fr fs oh fu fw is bi translated">keras-team/keras</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">mnist_mlp.py 在 mnist 数据集上训练一个简单的深度多层感知器。py 在…上训练一个简单的 convnet</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">github.com</p></div></div><div class="ok l"><div class="oq l om on oo ok op mu ob"/></div></div></a></div></div></div>    
</body>
</html>