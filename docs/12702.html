<html>
<head>
<title>Convert PDFs to Audiobooks with Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用机器学习将 pdf 转换为有声读物</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/convert-pdfs-to-audiobooks-with-machine-learning-6f2f6461a29c?source=collection_archive---------15-----------------------#2020-09-01">https://towardsdatascience.com/convert-pdfs-to-audiobooks-with-machine-learning-6f2f6461a29c?source=collection_archive---------15-----------------------#2020-09-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/4b7415e5c1b628035c2bfd6f6d8d98bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-x0hdApOZA9yjjK418dC4w.png"/></div></div></figure><div class=""/><div class=""><h2 id="9328" class="pw-subtitle-paragraph kb jd je bd b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks dk translated">使用 ML 将 pdf 和图像转换成有声读物或播客</h2></div><p id="022b" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><em class="lp">这个项目最初是由</em> <a class="lq lr ep" href="https://medium.com/u/4b21e207ea2c?source=post_page-----6f2f6461a29c--------------------------------" rel="noopener" target="_blank"> <em class="lp">和佐藤</em> </a> <em class="lp">设计的。</em></p><figure class="ls lt lu lv gt iv"><div class="bz fp l di"><div class="lw lx l"/></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">我把这个帖子拍成了视频。看看吧！</p></figure><p id="901e" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">散步——这是新冠肺炎最大的(也是唯一的)乐趣之一，不是吗？如今，你可以步行做任何事情:听新闻、参加会议，甚至写笔记(通过语音听写)。走路的时候唯一不能做的事情就是看机器学习研究论文。</p><p id="1870" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">还是不能？</p><p id="a679" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在这篇文章中，我将向您展示如何使用机器学习，通过计算机视觉和文本到语音转换，将 PDF 或图像格式的文档转换为有声读物。这样，您可以在旅途中阅读研究论文。</p><p id="c236" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">但是你应该吗？这由你来决定。</p><p id="6170" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">想直接跳到代码？在<a class="ae mc" href="https://github.com/kazunori279/pdf2audiobook" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上查看。</p><p id="29e1" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">但首先:这要归功于<a class="ae mc" href="https://github.com/kazunori279" rel="noopener ugc nofollow" target="_blank"> Kaz Sato </a>，一位在日本的谷歌工程师，他最初创建了这个<a class="ae mc" href="https://github.com/kazunori279/pdf2audiobook" rel="noopener ugc nofollow" target="_blank">项目</a>(他正在根据计算机科学教科书创建日语有声读物)。我把借来的建筑稍加改动。</p><p id="4500" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我们将通过三个主要步骤来构建 PDF 到有声读物的转换器:</p><ol class=""><li id="6a9d" class="md me je kv b kw kx kz la lc mf lg mg lk mh lo mi mj mk ml bi translated">从 pdf(或图像)中提取文本</li><li id="4581" class="md me je kv b kw mm kz mn lc mo lg mp lk mq lo mi mj mk ml bi translated">决定将文本的哪些部分包含在有声读物中</li><li id="a2bb" class="md me je kv b kw mm kz mn lc mo lg mp lk mq lo mi mj mk ml bi translated">将文本转换成口语</li></ol><p id="b532" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在这篇文章中，我将向您展示如何将<a class="ae mc" href="http://link-springer-com-443.webvpn.fjmu.edu.cn/content/pdf/10.1007%2F978-3-030-53518-6_1.pdf" rel="noopener ugc nofollow" target="_blank">这篇密集的研究论文</a>(“通向自动规范化和通用人工智能的一条有前途的道路”)转换成有声读物。它看起来是这样的:</p><figure class="ls lt lu lv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mr"><img src="../Images/dfb6d257d18488a9ad2c733aa454d19d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Ue1wpz0KFbCjOenp.png"/></div></div></figure><h1 id="d3e6" class="ms mt je bd mu mv mw mx my mz na nb nc kk nd kl ne kn nf ko ng kq nh kr ni nj bi translated">从 pdf 到文本</h1><p id="877a" class="pw-post-body-paragraph kt ku je kv b kw nk kf ky kz nl ki lb lc nm le lf lg nn li lj lk no lm ln lo im bi translated">首先，我们将使用 OCR 从文档中提取文本。您可以使用许多不同类型的工具来完成这项工作，例如:</p><ul class=""><li id="85b3" class="md me je kv b kw kx kz la lc mf lg mg lk mh lo np mj mk ml bi translated"><a class="ae mc" href="https://github.com/Calamari-OCR/calamari" rel="noopener ugc nofollow" target="_blank"> Calamari </a>，在开源 Python 库上</li><li id="e432" class="md me je kv b kw mm kz mn lc mo lg mp lk mq lo np mj mk ml bi translated">谷歌云<a class="ae mc" href="https://cloud.google.com/vision/docs" rel="noopener ugc nofollow" target="_blank">视觉人工智能 API </a></li><li id="6fff" class="md me je kv b kw mm kz mn lc mo lg mp lk mq lo np mj mk ml bi translated">(新！)Google Cloud <a class="ae mc" href="https://cloud.google.com/solutions/document-ai" rel="noopener ugc nofollow" target="_blank">文档 AI API </a>。这个 API 不仅提取文本，还智能地解析表格和表单</li></ul><p id="33f0" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">对于这个项目，我使用了 Vision API(比新文档 AI API 便宜)，发现质量相当不错。查看 Kaz 的 GitHub repo ,看看你到底是如何调用 API 的。</p><p id="1ff6" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">当您通过 Vision API 传递文档时，会返回原始文本和布局信息。下面是回应的样子:</p><figure class="ls lt lu lv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nq"><img src="../Images/1b1a18456c3fddedf4092312d4e60e78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6PqGsdc2wAzORedY.gif"/></div></div></figure><p id="985f" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">如您所见，API 不仅返回页面上的原始文本，还返回每个字符的(x，y)位置。</p><p id="8e2c" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在这一点上，如果你是个傻瓜，你可以把所有的原始文本直接转储到有声读物中。但是你不是一个傻瓜，你可能不希望这样做，因为那样你会听到各种各样无趣的东西，比如图像标题、页码、文档页脚等等。</p><p id="248d" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">所以下一步，我们将决定哪些原始文本应该包含在有声读物中。</p><h1 id="e824" class="ms mt je bd mu mv mw mx my mz na nb nc kk nd kl ne kn nf ko ng kq nh kr ni nj bi translated">在 pdf 中查找相关文本</h1><p id="0cc1" class="pw-post-body-paragraph kt ku je kv b kw nk kf ky kz nl ki lb lc nm le lf lg nn li lj lk no lm ln lo im bi translated">我们希望在有声读物中包含研究论文的哪一部分？可能是论文的标题、作者的名字、章节标题、正文，但这些都没有用红色突出显示:</p><figure class="ls lt lu lv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nr"><img src="../Images/33d749e71cad0e1a07e22cb470f64116.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*qKuiNfJKmN6AhmmT.png"/></div></div></figure><p id="fd56" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">事实证明，识别这些相关部分是一个棘手的问题，有许多可能的解决方案。在这篇文章中，我将向您展示两种方法，一种是快速但不干净的方法，另一种是高质量但需要更多工作的方法。</p><h1 id="f8c1" class="ms mt je bd mu mv mw mx my mz na nb nc kk nd kl ne kn nf ko ng kq nh kr ni nj bi translated">使用机器学习查找相关文本</h1><p id="dc1a" class="pw-post-body-paragraph kt ku je kv b kw nk kf ky kz nl ki lb lc nm le lf lg nn li lj lk no lm ln lo im bi translated">当你看一篇研究论文时，你可能很容易通过注意布局来掩饰不相关的部分:标题大而粗；字幕很小；正文为中等大小，位于页面中央。</p><p id="24ec" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">利用页面上文本布局的空间信息，我们也可以训练一个机器学习模型来做到这一点。我们向模型展示了一堆正文、标题文本等等的例子，希望它能学会识别它们。</p><p id="62a8" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这是这个项目的原作者 Kaz 在试图将教科书变成有声读物时采取的方法。</p><p id="2e11" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在这篇文章的前面，我提到 Google Cloud Vision API 不仅返回页面上的文本，还返回它的布局。它将文本分组为块(页面、块、段落、单词和字符),并返回它在页面上的位置。具体来说，对于每个单词，它都返回一个类似如下的边界框:</p><pre class="ls lt lu lv gt ns nt nu nv aw nw bi"><span id="9efe" class="nx mt je nt b gy ny nz l oa ob">"boundingBox": {<br/><br/>   "normalizedVertices": [<br/>		{"x": 0.9248292,"y": 0.06006006},<br/> 		{"x": 0.9384966,"y": 0.06006006},<br/>        {"x": 0.9384966,"y": 0.067567565},<br/>        {"x": 0.9248292,"y": 0.067567565}<br/>    ]<br/><br/>}</span></pre><p id="5de1" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><em class="lp">上面的边框描述了一个单词在页面上的位置，以及它有多大</em>。</p><p id="3426" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我们可以用这些数据来训练一个模型。下面我们来看看 Kaz 收集的数据:</p><figure class="ls lt lu lv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oc"><img src="../Images/9f8a4f5edec438911eaad597938b282c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hv5mPPFZTl0WxPGt.png"/></div></div></figure><p id="d9b6" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">显然，Kaz 正在转换的书是日文的。对于每一个文本块，他都创建了一套特征来描述它:文本块中有多少个字符？它有多大，在页面上的什么位置？包围文本的框的长宽比是多少(例如，一个窄框可能只是一个侧栏)？</p><p id="f9a1" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">请注意，在上面的电子表格中还有一个名为“label”的列。这是因为，为了训练机器学习模型，我们需要一个带标签的训练数据集，模型可以从中“学习”对于训练数据中的每个文本块，Kaz 必须手动将该文本块标记为“正文”、“标题”、“标题”或“其他”。标注训练数据总是 ML 项目中比较耗时的部分之一，这次也不例外！</p><p id="54ba" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这就是为什么，当我重新创建 Kaz 的项目时，我使用了一个黑客来避免它(下面会有更多)。</p><p id="2f40" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在 Kaz 收集并标记了一堆文档后，他使用<a class="ae mc" href="https://cloud.google.com/automl-tables" rel="noopener ugc nofollow" target="_blank"> Google Cloud AutoML Tables </a>训练了一个机器学习模型。这是一个基于表格数据构建模型的无代码工具。这里有一个小的 gif 展示了这个工具的样子，以及 Kaz 如何用它来训练一个模型:</p><figure class="ls lt lu lv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi od"><img src="../Images/a672eb84a4060ea7b3efdf1d3234385c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Wlf3JrCg7bUvHT6j.gif"/></div></div></figure><p id="705f" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">如您所见，该模型相当准确(约 95%的精确度和召回率)！所以 Kaz 使用这个模型作为一个中间步骤来确定将哪些文本放入有声读物。</p><h1 id="dc24" class="ms mt je bd mu mv mw mx my mz na nb nc kk nd kl ne kn nf ko ng kq nh kr ni nj bi translated">用 Spit、Glue 和字体大小查找相关文本</h1><p id="60cc" class="pw-post-body-paragraph kt ku je kv b kw nk kf ky kz nl ki lb lc nm le lf lg nn li lj lk no lm ln lo im bi translated">看，我不是娘娘腔——我一生中花了很多时间来标记训练数据(尽管，这些天来，你<a class="ae mc" href="https://cloud.google.com/ai-platform/data-labeling/docs" rel="noopener ugc nofollow" target="_blank">真的不必</a>)。但是对于这个项目，我想知道我是否可以使用一个简单的启发式方法(一个可以让我避免标记数据的方法)来代替。</p><p id="c04a" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我觉得光看字体大小就能学到很多东西。比如:论文的标题很可能是用最大的文字尺寸写的。同时，正文是文档中最常见的文本。根据这些观察，我使用了这个启发法:</p><ol class=""><li id="8402" class="md me je kv b kw kx kz la lc mf lg mg lk mh lo mi mj mk ml bi translated">计算所有单词的字体大小</li><li id="61ad" class="md me je kv b kw mm kz mn lc mo lg mp lk mq lo mi mj mk ml bi translated">计算最常见的字体大小。用字体大小“body”来标记文本的每一位</li><li id="e284" class="md me je kv b kw mm kz mn lc mo lg mp lk mq lo mi mj mk ml bi translated">计算最大字体大小。将该字体大小每一位文本标记为“标题”</li></ol><p id="675e" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">第一步，计算字体大小，我减去单词周围的 y 坐标:</p><figure class="ls lt lu lv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oe"><img src="../Images/70000d6ca6f16781835f1693b66dad86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jyqNqktB1Pu36PKB.jpg"/></div></div></figure><p id="f8b4" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">接下来，为了看看我的想法是否可行，我绘制了文档中字体大小的分布:</p><figure class="ls lt lu lv gt iv gh gi paragraph-image"><div class="gh gi of"><img src="../Images/97cbb53726e04d40f93cbe9feb3f22e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/0*j-nThOOua8C8DWLO.jpg"/></div></figure><p id="93c2" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">你可以看到在右边，有一个点(最大的文本)代表文档标题(woohoo！).同时，中间那一大段点，就是正文。标题和其他文档元数据，甚至更小的文本，都在图的左侧。</p><p id="df31" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这个图表给了我信心，我的小技巧会起作用，至少对这个文档是这样(注意，它并不适用于<em class="lp">所有的</em>研究论文，尤其是那些有花哨的侧栏或垂直布局的论文！).</p><p id="b51f" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">然而，这里有一个棘手的问题，正文字体大小在一个<em class="lp">范围内</em>(不是一个固定值)。这是因为我不是像我们通常认为的那样计算字体大小(即 12 磅)，而是作为减去的像素值，并且有一些噪声。找出界限(例如，什么是正文的界限？)，我用的是<a class="ae mc" href="https://en.wikipedia.org/wiki/Jenks_natural_breaks_optimization" rel="noopener ugc nofollow" target="_blank"> Jenks Natural Breaks 算法</a>(如果你没听说过这个，没关系——我在这个项目之前也没听说过！).</p><p id="486a" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我知道我说的有点快，所以请在这里或 Twitter 上给我留言，我一定会回答你的问题！</p><h1 id="7a24" class="ms mt je bd mu mv mw mx my mz na nb nc kk nd kl ne kn nf ko ng kq nh kr ni nj bi translated">从文本到口语</h1><p id="d825" class="pw-post-body-paragraph kt ku je kv b kw nk kf ky kz nl ki lb lc nm le lf lg nn li lj lk no lm ln lo im bi translated">这个项目最有趣的部分无疑是选择一个电脑声音来做我们的解说员。为此，我使用了谷歌文本到语音转换 API，它使用了一种叫做<a class="ae mc" href="https://deepmind.com/blog/article/wavenet-generative-model-raw-audio" rel="noopener ugc nofollow" target="_blank"> WaveNet </a>的技术来产生非常逼真的声音。API 支持许多声音和语言，你可以直接从<a class="ae mc" href="https://cloud.google.com/text-to-speech" rel="noopener ugc nofollow" target="_blank">产品页面</a>的输入文本中自己比较它们。</p><p id="01c5" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我选择男声读论文题目，女声读论文正文。以下是由此产生的“有声读物”听起来的样子:</p><p id="6b8c" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><a class="ae mc" href="https://soundcloud.com/dale-markowitz/a-promising-path-towards-autoformalization-and-general-artificial-intelligence" rel="noopener ugc nofollow" target="_blank">https://soundcloud . com/dale-markowitz/a-promising-path-against-auto formalization-and-general-artificial-intelligence</a></p><p id="baf4" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">不算太坏，对吧？</p><p id="77ba" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">反正目前就这些了。</p><p id="5ede" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">如果你做出了这样的好东西，请与我分享，我会在社交媒体上展示它！</p><p id="202f" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">同时，我们在<a class="ae mc" href="https://daleonai.com/instagram.com/dale_on_ai" rel="noopener ugc nofollow" target="_blank"> Instagram </a>或<a class="ae mc" href="https://daleonai.com/twitter.com/dalequark" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上连线吧！</p></div><div class="ab cl og oh hx oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="im in io ip iq"><p id="3cc2" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><em class="lp">原载于 2020 年 9 月 1 日 https://daleonai.com</em><a class="ae mc" href="https://daleonai.com/pdf-to-audiobook" rel="noopener ugc nofollow" target="_blank"><em class="lp"/></a><em class="lp">。</em></p></div></div>    
</body>
</html>