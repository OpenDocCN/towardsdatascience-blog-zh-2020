<html>
<head>
<title>NEON.LIFE: Your REAL Virtual Assistant, For Real This Time?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">霓虹。生活:你真正的虚拟助手，这次是真的吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/neon-life-your-real-virtual-assistant-for-real-this-time-6de4a52e66c4?source=collection_archive---------18-----------------------#2020-01-18">https://towardsdatascience.com/neon-life-your-real-virtual-assistant-for-real-this-time-6de4a52e66c4?source=collection_archive---------18-----------------------#2020-01-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a0d2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">氖的剖析与理论建构。生命，三星的新“人造人”</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/bfa982d93ebb477c9b9597204d411a23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pbfygQlozOYzIXYx.jpg"/></div></div></figure><p id="b4e2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi lq translated"><span class="l lr ls lt bm lu lv lw lx ly di"> A </span> nyone看过<a class="ae lz" href="https://www.imdb.com/title/tt1856101/" rel="noopener ugc nofollow" target="_blank"> Blade Running 2049 </a>一定还记得‘Joi’，一个人造人漂亮精致的全息投影。她和你说话，帮你做家务，给你讲笑话，陪你，还有更多…就像一个真正的人一样。她甚至对你有自己的记忆，并随着时间的推移形成了自己的性格。除了“她”不是人类。她只是一个超级复杂的真人“模型”,可以像真人一样说话、行动和反应。然而，仍有相当多的人暗地里希望他们也能有自己的“Joi”。她可能没有你想的那么远。进入<a class="ae lz" href="https://www.neon.life/" rel="noopener ugc nofollow" target="_blank">霓虹</a>，三星的新人造人。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/a016b8a2583d8f6ea0d1f90c8347d3ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/0*qewd9ME91MB7hJnH.gif"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">来自<a class="ae lz" href="https://gfycat.com/grouchyfaintesok" rel="noopener ugc nofollow" target="_blank"> Gfycat </a>的Joi</p></figure></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="9caa" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">遭遇</h1><p id="24a9" class="pw-post-body-paragraph ku kv it kw b kx ne ju kz la nf jx lc ld ng lf lg lh nh lj lk ll ni ln lo lp im bi lq translated">我上周在CES 2020展会上走在地板上。像过去几年一样，出现了许多新的装置和新技术。也有大量的展示。小的，大的，巨大的，可折叠的，半透明的，应有尽有。其中，有一件展品引起了我的注意。一个栩栩如生的人站在一个显示器内，带着温暖的微笑看着我，还用丰富的手势谈论一些事情。这是干什么用的？也许是新的远程视频服务？出于好奇，我走近查看。结果，这些非常逼真的人物都不是人。他们被称为NEONs，是三星支持的公司STAR Labs创造的人造人。</p><blockquote class="nj nk nl"><p id="bc08" class="ku kv nm kw b kx ky ju kz la lb jx lc nn le lf lg no li lj lk np lm ln lo lp im bi translated"><em class="it">霓虹，我们的第一个人造人来了。霓虹是一个通过计算创建的虚拟生物，它的外表和行为都像一个真实的人，具有表现情感和智能的能力。—星际实验室</em></p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/3c8425bd0a3e6eff518c16a419316f90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4apnXkka8XrrtBaX.jpg"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">来自霓虹。生活</p></figure><p id="d835" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这个样子，表情，手势是如此自然，我真的不能告诉它是否是预先录制的视频或CGI。仔细看，明明是CGI，只是非常非常‘真实’。真正意义上的“类人”而非“高分辨率”。我深入挖掘，发现这些是基于预先录制的真实人类视频的人工智能生成的CGI镜头，是对人类演员视频的“再创造”。非常像詹姆斯·卡梅隆在电影《阿凡达》中第一次做的事情。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/d6d9ea0b686da4e963a037ff67a1a80f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*1a6inxMk4U1I2xVH.jpg"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">图片来自<a class="ae lz" href="http://lyon.onvasortir.com/pourquoi-j-039ai-pas-mange-mon-pere-3873571.html" rel="noopener ugc nofollow" target="_blank">lyon.onvasortir.com</a></p></figure><p id="d13b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">但是霓虹并没有就此止步，它把事情推得更远。这些NEONs可以脱离剧本，发展自己的“个性”。它可以从自己独特的“个性”中产生新的表情、手势和反应。这些“个性”也可以被训练并适应外部刺激。现在，这不仅仅是模仿面部表情！三星是如何做到这一点的，这意味着什么？展会上没有透露太多细节。我内心的数据科学家立刻被打开了，让我们试着弄清楚(猜测)这是如何实现的，它会对我们的社会和行业产生什么影响，好吗？</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="9485" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">解剖</h1><p id="a6c9" class="pw-post-body-paragraph ku kv it kw b kx ne ju kz la nf jx lc ld ng lf lg lh nh lj lk ll ni ln lo lp im bi lq translated"><span class="l lr ls lt bm lu lv lw lx ly di">那么</span>他们是怎么做到的呢？我们先来看看它能做什么。为了实现他们所宣称的，NEON需要做几件事:</p><p id="7f9f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><em class="nm">注意:下面的部分只是我的“有根据的预测”,因此与霓虹实际上是如何工作或创造的没有任何关系。三星尚未公布NEON的更多细节。</em></p><h1 id="eb2a" class="mm mn it bd mo mp ns mr ms mt nt mv mw jz nu ka my kc nv kd na kf nw kg nc nd bi translated">物理建模:真人视频到CGI，穿越恐怖谷</h1><p id="6549" class="pw-post-body-paragraph ku kv it kw b kx ne ju kz la nf jx lc ld ng lf lg lh nh lj lk ll ni ln lo lp im bi translated">给定一个演员的一些视频数据集，该模型需要学习如何将视频转换为CGI镜头，越相似越好。这项技术随着头像和表演捕捉的兴起，已经得到了很好的发展。演员被拍摄时，他们的脸上有一些彩色点网格，用来记录他们的面部表情，并将这些面部表情网格运动转换成CGI角色表情。这是一项相当成熟的技术。霓虹所做的只是有点不同。它可能没有网格作为参考，但使用深度学习，深度神经网络找到任务所需的特征并不太难，它可能比像面部网格这样的简单模型做得更好。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="f543" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">数据输入:</strong>视频短片</p><p id="a891" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">数据输出:</strong>面部/身体网格运动时间序列数据。</p><h1 id="0681" class="mm mn it bd mo mp ns mr ms mt nt mv mw jz nu ka my kc nv kd na kf nw kg nc nd bi translated">表情建模:表情/手势投影到CGI</h1><p id="621a" class="pw-post-body-paragraph ku kv it kw b kx ne ju kz la nf jx lc ld ng lf lg lh nh lj lk ll ni ln lo lp im bi translated">因此，从视频片段中，我们现在有一个网格运动时间序列数据集，如果我们可以用不同的表达式标记这些数据集，我们应该能够训练某种自动编码器，可以将CGI时间序列编码为表达式编码，然后重新生成相同的CGI时间序列数据。然后我们可以看看编码，弄清楚什么是微笑、哭泣、惊讶、生气等等。这也是一个已经解决的问题。你可以在下面找到一个例子:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nz ny l"/></div></figure><p id="a961" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">数据输入:</strong> CGI时间序列数据集</p><p id="c043" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">数据输出:</strong>表达式编码/嵌入层数</p><h1 id="7e62" class="mm mn it bd mo mp ns mr ms mt nt mv mw jz nu ka my kc nv kd na kf nw kg nc nd bi translated">个性建模:从情感到表达</h1><p id="52b9" class="pw-post-body-paragraph ku kv it kw b kx ne ju kz la nf jx lc ld ng lf lg lh nh lj lk ll ni ln lo lp im bi translated">所以现在我们可以通过表情编码来控制我们的CGI化身的表情，下一步就是将情感映射到表情上。表达是情感的外化，但映射并不总是直截了当的。你可能认为人们开心的时候会笑，但是人性远比这复杂。一些外向的人会笑出声来，而内向的人可能只是微妙地傻笑。控制情绪到表情映射的是性格。现在我们如何塑造人格？这需要大量的领域知识(这也是三星声称他们仍在努力的部分，我认为最具挑战性。因为人性，你知道…)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/13db90e201c677c6a5caf879d57ce97e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4kfOSTR1OQfyoXf1"/></div></div></figure><p id="a5c5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">数据输入:</strong>情感标签(多个标签，因为一个表情后面可能有多个情感)</p><p id="3d60" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">数据输出:</strong>表示给定化身的情绪的表情编码/嵌入</p><h1 id="df2f" class="mm mn it bd mo mp ns mr ms mt nt mv mw jz nu ka my kc nv kd na kf nw kg nc nd bi translated">三星关于NEON的说法包括</h1><p id="2a26" class="pw-post-body-paragraph ku kv it kw b kx ne ju kz la nf jx lc ld ng lf lg lh nh lj lk ll ni ln lo lp im bi translated">从演示中，我们知道氖实际上由三部分组成:</p><ul class=""><li id="e37d" class="ob oc it kw b kx ky la lb ld od lh oe ll of lp og oh oi oj bi translated">行为神经网络(<strong class="kw iu">表达模型？</strong>)</li><li id="91f9" class="ob oc it kw b kx ok la ol ld om lh on ll oo lp og oh oi oj bi translated">进化生成智能(<strong class="kw iu">人格模型？</strong>)</li><li id="73c4" class="ob oc it kw b kx ok la ol ld om lh on ll oo lp og oh oi oj bi translated">计算现实(<strong class="kw iu">物理模型？</strong>)</li></ul><p id="5908" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我上面的假设是真的吗？我们将在不久的将来了解更多，但如果你有不同的想法，请留下一些回应！</p><h1 id="ba03" class="mm mn it bd mo mp ns mr ms mt nt mv mw jz nu ka my kc nv kd na kf nw kg nc nd bi translated">理论加工</h1><p id="2943" class="pw-post-body-paragraph ku kv it kw b kx ne ju kz la nf jx lc ld ng lf lg lh nh lj lk ll ni ln lo lp im bi lq translated"><span class="l lr ls lt bm lu lv lw lx ly di">那么</span>这些部分是如何组合在一起形成霓虹的呢？它可以像管道一样工作:</p><p id="6d71" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">首先使用一个人类演员的视频镜头来训练一个可以生成CGI网格时间序列数据的神经网络。这将赋予控制CGI化身尽可能像人类一样的能力。神经网络将不可避免地学习人类手势和人类面部表情的模式，这为进一步的抽象奠定了基础。</p><p id="bb53" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">利用CGI网格运动时间序列数据，我们可以训练一个自动编码器，它可以进行某种降维，创建一些中间层编码器，然后重新生成CGI。一旦重新生成的CGI与原始时间序列数据足够相似，我们将获得视频、表情和手势的更抽象层(表情编码器)。一旦我们有了编码器或嵌入，我们就可以玩一玩，看看哪种权重组合可以生成特定的表情，例如微笑、生气、惊讶等。然后，我们可以使用这些权重(可能需要做一些主成分分析，使其更易于管理)来控制我们的化身的表情，使其微笑、哭泣等。</p><p id="e614" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">就这一点而言，虚拟角色的表情可以在很大程度上由人工控制，但现在还没有。我们需要的是让虚拟角色自己“生成”表情，对外界刺激做出反应。这就是人格模型发挥作用的地方。使用心理学、情绪科学的领域知识，可以开发许多不同的个性特征，它们与表达和外部刺激的关系可以被建模。如果我们以某个名人(比如说李小龙)为例，通过对他的行为(表情)和外界刺激(言语的情绪，手势等)进行标签化。)，我们可以开发一个“个性”模型，反映名人对不同情绪的不同表达会有什么反应。然后，我们使用这个个性模型来根据外部情绪(可能是从情绪分类器神经网络输出的)控制霓虹灯的反应表达。</p><p id="691f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在霓虹官方视频中，霓虹的“情绪激活”状态是实时可视化的，表明霓虹对外界刺激的反应。相当酷。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/98a8798874da9e6562e40e0243755877.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*qdaUUj1a0AmtNuoV_Erg4g.png"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">霓虹实时的情绪地图，灯泡就是她当前状态所在的地方，文字就是不同的情绪状态。</p></figure><p id="e73b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">除此之外，NEON可以学习领域知识，提供更多的价值。三星声称他们有另一个名为Spectra的云人工智能平台，第三方开发者将能够为NEON开发这些“技能”。认为Siri有漂亮的脸蛋，迷人的声音，还能教你功夫。😜</p><p id="fc2b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我不得不说，即使他们在CES 2020上展示的演示远非完美，但NEON是开创性的。这个团队的想法很宏大，并且打下了良好的基础和框架。此刻的计算饥饿应用可能意味着NEON不能生活在边缘，但随着5G的快速发展和更好的云平台，我相信NEON的未来潜力是巨大的。</p><h1 id="ea1b" class="mm mn it bd mo mp ns mr ms mt nt mv mw jz nu ka my kc nv kd na kf nw kg nc nd bi translated">视力</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/8bcac965a6890a1422eae2613819bc0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Bxam4hzol0C0TINZ"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">你想要哪种霓虹灯？瑜伽导师？魔术师？商务助理？私人摄影师？</p></figure><p id="d70d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi lq translated">这是文章中允许我放肆的部分。让我们看看霓虹灯能做什么:</p><ul class=""><li id="2a98" class="ob oc it kw b kx ky la lb ld od lh oe ll of lp og oh oi oj bi translated"><strong class="kw iu">博彩业中的完美NPC。在RPG游戏中，NPC通常都很笨。他们的面部表情和反应太假了。NEON可以改变这一点，给玩家一个非常真实的体验。</strong></li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">检查整个系列，它是金色的…</p></figure><ul class=""><li id="a365" class="ob oc it kw b kx ky la lb ld od lh oe ll of lp og oh oi oj bi translated">重现你逝去的亲人或朋友。如果你读过<a class="ae lz" href="https://www.wired.com/story/a-sons-race-to-give-his-dying-father-artificial-immortality/" rel="noopener ugc nofollow" target="_blank">这篇文章</a>讲的是一个男孩试图创造一个聊天机器人，说话和他爸爸一模一样，并在他爸爸去世后一直让他陪着，你知道我在说什么。NEON可以走得更远，不仅聊天机器人可以像他的父亲一样生成文本，它可以看起来像他的父亲，听起来像他的父亲，甚至具有相似的“个性”。(也许有点令人毛骨悚然，但我有什么资格评判……)</li><li id="87c8" class="ob oc it kw b kx ok la ol ld om lh on ll oo lp og oh oi oj bi translated"><strong class="kw iu">各种服务助理。</strong>喜欢瑜伽导师，理财规划师，或者只是让你有个好的性格作伴。</li><li id="1f0e" class="ob oc it kw b kx ok la ol ld om lh on ll oo lp og oh oi oj bi translated"><strong class="kw iu">残疾人的向导/帮手。</strong></li><li id="d6e3" class="ob oc it kw b kx ok la ol ld om lh on ll oo lp og oh oi oj bi translated"><strong class="kw iu">粉丝崇拜的名人“副本”</strong></li><li id="0736" class="ob oc it kw b kx ok la ol ld om lh on ll oo lp og oh oi oj bi translated"><strong class="kw iu">自闭症治疗师</strong></li></ul><p id="ac49" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这个清单可以一直列下去，但是你要明白。由于它是一个开放的平台，它很可能成为技术领域的下一个大事件。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="f618" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">结论</h1><p id="ab8e" class="pw-post-body-paragraph ku kv it kw b kx ne ju kz la nf jx lc ld ng lf lg lh nh lj lk ll ni ln lo lp im bi lq translated">表面上看，CES是关于工程创新而不是科学突破的，但我认为NEON有点处于中间位置。这支队伍还很年轻，我很兴奋看到他们在不久的将来能做什么，并了解他们的方法。这真的是一个隐藏的宝石，我觉得必须向我的读者介绍。你认为人造人能做什么？做不到。还是永远不应该做？</p><p id="75d9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">关于CES舞台上展示的更多细节，你可以看看这个详细的视频:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nz ny l"/></div></figure></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="b902" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">觉得这篇文章有用？在Medium上关注我(<a class="ae lz" href="https://medium.com/u/72c98619a048?source=post_page-----dbe7106145f5----------------------" rel="noopener">李立伟</a>)或者你可以在Twitter <a class="ae lz" href="https://twitter.com/lymenlee" rel="noopener ugc nofollow" target="_blank"> @lymenlee </a>或者我的博客网站<a class="ae lz" href="https://wayofnumbers.com/" rel="noopener ugc nofollow" target="_blank">wayofnumbers.com</a>上找到我。你也可以看看我下面最受欢迎的文章！</p><div class="oq or gp gr os ot"><a rel="noopener follow" target="_blank" href="/this-is-cs50-a-pleasant-way-to-kick-off-your-data-science-education-d6075a6e761a"><div class="ou ab fo"><div class="ov ab ow cl cj ox"><h2 class="bd iu gy z fp oy fr fs oz fu fw is bi translated">“这是CS50”:开始数据科学教育的愉快方式</h2><div class="pa l"><h3 class="bd b gy z fp oy fr fs oz fu fw dk translated">为什么CS50特别适合巩固你的软件工程基础</h3></div><div class="pb l"><p class="bd b dl z fp oy fr fs oz fu fw dk translated">towardsdatascience.com</p></div></div><div class="pc l"><div class="pd l pe pf pg pc ph ks ot"/></div></div></a></div><div class="oq or gp gr os ot"><a rel="noopener follow" target="_blank" href="/two-sides-of-the-same-coin-fast-ai-vs-deeplearning-ai-b67e9ec32133"><div class="ou ab fo"><div class="ov ab ow cl cj ox"><h2 class="bd iu gy z fp oy fr fs oz fu fw is bi translated">一枚硬币的两面:杰瑞米·霍华德的fast.ai vs吴恩达的deeplearning.ai</h2><div class="pa l"><h3 class="bd b gy z fp oy fr fs oz fu fw dk translated">如何不通过同时参加fast.ai和deeplearning.ai课程来“过度适应”你的人工智能学习</h3></div><div class="pb l"><p class="bd b dl z fp oy fr fs oz fu fw dk translated">towardsdatascience.com</p></div></div><div class="pc l"><div class="pi l pe pf pg pc ph ks ot"/></div></div></a></div><div class="oq or gp gr os ot"><a rel="noopener follow" target="_blank" href="/what-you-need-to-know-about-netflixs-jupyter-killer-polynote-dbe7106145f5"><div class="ou ab fo"><div class="ov ab ow cl cj ox"><h2 class="bd iu gy z fp oy fr fs oz fu fw is bi translated">你需要了解网飞的“朱庇特黑仔”:冰穴📖</h2><div class="pa l"><h3 class="bd b gy z fp oy fr fs oz fu fw dk translated">是时候让Jupyter笔记本有个有价值的竞争对手了</h3></div><div class="pb l"><p class="bd b dl z fp oy fr fs oz fu fw dk translated">towardsdatascience.com</p></div></div><div class="pc l"><div class="pj l pe pf pg pc ph ks ot"/></div></div></a></div></div></div>    
</body>
</html>