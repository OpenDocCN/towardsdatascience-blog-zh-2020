<html>
<head>
<title>Training Object Detectors with No Real Data using Domain Randomization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用域随机化训练没有真实数据的对象检测器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/training-object-detectors-with-no-real-data-using-domain-randomization-1569cb3b8c6?source=collection_archive---------16-----------------------#2020-01-15">https://towardsdatascience.com/training-object-detectors-with-no-real-data-using-domain-randomization-1569cb3b8c6?source=collection_archive---------16-----------------------#2020-01-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="05c9" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在没有预算的情况下解决专用对象检测器的模拟 2 真实传输</h2></div><p id="d91a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">深度学习最近已经成为解决物体检测问题的首选方法。然而，与这项技术的许多其他用途一样，注释训练数据既麻烦又耗时，尤其是如果您是一家有特定用例的小公司。在这篇文章中，我介绍了我们在物体检测的合成数据生成方面的一些工作，并展示了一些实例。</p><p id="447c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最近，许多研究论文和私营企业都将注意力集中在图像中的自动目标检测上。金字塔滑动盒检测器的时代已经一去不复返，卷积神经网络的时代已经到来。世界各地的研究人员正在微调网络，并在他们的训练计划中添加铃铛和哨子，以提高大型数据集的分数，如<a class="ae lc" href="http://host.robots.ox.ac.uk/pascal/VOC/" rel="noopener ugc nofollow" target="_blank">帕斯卡 VOC </a>或<a class="ae lc" href="http://cocodataset.org/#home" rel="noopener ugc nofollow" target="_blank">可可</a>。</p><p id="3706" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是如果你不想在申请中找到 COCO 提供的任何课程呢？通常情况下，您必须为所选感兴趣对象(OOI)的新数据集提供资金，这可能会非常昂贵和耗时，尤其是如果您是一家小公司。好的数据集从不同的角度、在不同的光照下显示你的 OOI，并且有许多额外的差异，使得检测器不会过度适应一个特定的版本；例如，在单个人身上训练人体探测器，或者在单个汽车模型上训练汽车探测器，都是适得其反的。</p><p id="5db8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">自从训练数据存在以来，随着噪声被添加到信号输入和图像区域上的黑盒，增强的训练数据一直是一件事情。随着对<a class="ae lc" href="https://lilianweng.github.io/lil-log/2019/05/05/domain-randomization.html" rel="noopener ugc nofollow" target="_blank">域随机化(DR) </a>的需求和引入，这种范式略有改变，这是一种用于改善机器人机动和需要大量训练数据的类似任务的强大工具。DR 依赖于对手头任务不重要的随机参数，这样网络就学会忽略这些参数。假设你想用相机检测一个树莓派。它们有不同的颜色，可以有不同的背景和照明环境。它们也可能被各种其他物体阻挡，并在许多方向上靠近或远离摄像机。这些是您想要随机化的参数。在这种情况下，你不希望随机化的一件事是物体的一般物理形状。</p><p id="c8ac" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">多亏了现代计算机图形学，我们可以控制这些参数，并在给定树莓的 3D 模型的情况下，连续渲染树莓的无限多种变化。这给我们留下两条路:使用良好的照明和真实的环境渲染图像，可能使用一些高级的 CG 编程方法，如光线跟踪，或者使用低细节和次优照明渲染更快的图像。</p><p id="3f64" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">巧合的是，我们一直在用任意数量的随机参数对合成数据单独进行训练对象检测器的实验。我们在这方面的理念是，我们可以在更短的时间内提供越多不同的训练数据，我们的模型就可以更好、更快地学习概括。一个真实的、看起来自然的物体的图像突然变成了模型可能已经看到的另一个变体。</p><h1 id="bb98" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">创建合成数据生成器</h1><p id="8143" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">我们在实验室中选择了五个具有匹配 3D 模型的对象，并着手创建一个快速合成图像生成器。由于我以前使用 Unity 的经验和项目的规模，这是我们选择的引擎。系统的整体思路很简单；完全随机化对象及其环境的所有参数，这些参数对于确定其类别和位置并不重要。这主要是实验性的，为了观察完全域随机化提供的机会。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/887cf6e5bae05009b9ac749363656f40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/0*iTgfhsNETaQxTjC6.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">随机生成的 Unity3D 场景，包含光源、随机“垃圾”对象和感兴趣的对象。</p></figure><p id="ae36" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将相机参数、材质颜色和其他材质属性、场景中灯光的强度、颜色和数量以及许多其他东西随机化，以便尽可能创建最多样的数据集。OOI 被随机缩放、旋转和定位。然后场景被渲染两次；一次用于生成图像，一次用于生成边界框。这里可以看到一个随机生成场景的例子。</p><p id="cb47" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面，我展示了系统输出的一些奇怪的树莓图片。红框只是告诉我们边界框在哪里，当然不是训练数据的一部分。如您所见，输出看起来一点也不真实。事实上，很难立即看出它们代表了什么。然而，我可以在我的笔记本电脑上每小时生成几十万个这样的东西，这给了我们的模型一个很好的机会来学习物体的形状表示，我们假设，学习忽略其他一切。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/eea6e5fd1335a570f138bda21170a005.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/0*oKk5caZm5Ix6Foad.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">用作训练数据的随机生成的树莓 Pi 图像的示例</p></figure><p id="3074" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我决定在 MobilenetV2 上训练单次多盒检测器(SSD)模型，因为我们对在移动应用中使用训练好的模型感兴趣。这意味着精度预计会比基于 VGG19 的模型略低，但该模型应该训练和运行得更快。我编写了一个快速脚本，从 Unity 应用程序中连续获取图像，并将它们写入 Tensorflow。记录文件。这允许我们使用带有<a class="ae lc" href="https://github.com/tensorflow/models/blob/master/research/object_detection/model_main.py" rel="noopener ugc nofollow" target="_blank"> model_main.py </a>的迁移学习，这是一个 Tensorflow 脚本，它根据一些可配置的参数重新训练现有的模型。然后我们可以使用 Tensorboard 可视化结果。我还准备了一个使用<a class="ae lc" href="https://github.com/tzutalin/labelImg" rel="noopener ugc nofollow" target="_blank">标签</a>标注的真实图像的小测试数据集。</p><h1 id="eb0d" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">在合成数据上训练对象检测器</h1><p id="8ad0" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">这项努力向我们展示的一件事是，根据合成数据训练的模型往往非常不稳定。在验证步骤之间，损失和图结果波动很大。解决这个问题的一个关键是增加批量。此外，我们在没有硬示例挖掘的情况下测试训练，硬示例挖掘是在对象检测训练中已经成为标准的方法。这里的假设是，一些例子可能被赋予了很高的权重，以至于模型在评估时对它们进行了过度拟合。证据是，在每个验证步骤中，几个真实图像预测了在位置和大小上非常相似的边界框和类，尽管图像甚至不包含该类的对象。这方面的例子如下所示。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/99dfe706624d4a7ba21c5500ef0520ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/0*f1s4UpcqgrbPF8EG.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">使用硬示例挖掘进行预测的示例。左:预测。右:地面真相。</p></figure><p id="0577" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">培训损失和评估损失之间也有很大的差异。这是意料之中的，因为图像的类型并不相似。由于训练损失比评估损失收敛得快得多，后者很难随着前者的减缓而改善。额外的数据扩充技术和训练方法在这里派上用场；我们包括随机黑色斑块、像素偏移和高斯斑点，以进一步增加检测器的难度，并在网络中引入信号丢失。如果你试图在家里这样做，要小心；需要耐心。这个想法需要一段时间来“点击”探测器，此时地图得分将开始增加。一旦正则化损失开始持续下降，通常会出现“咔哒声”。在此之前，猜测可能看起来完全是随机的，损失可能会大幅波动。</p><h1 id="2aad" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">结果和考虑</h1><p id="2b4c" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">下面，我们展示了第 28，000 步的一些结果。训练如此多的迭代所需的图像数据量需要几个小时才能生成。这些图像来自 Tensorboard，显示了评估集的预测和实际边界框。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/a99bfaed9af3a277bce6db5a879d5b42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/format:webp/0*2-qIEzZVpDR6VrKH.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">在第 28，000 步做出的正确预测。左:预测。右:地面真相。</p></figure><p id="541e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这张图片展示了网络做出的一些不错的预测。尽管(很可能)从未接受过任何像这样逼真的训练，但该网络似乎能够相对准确地预测和分类树莓皮和钻头，即使在场景和 OOI 前面散布着随机物体。</p><p id="5ca5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此时，网络已经开始学习对象的强表示。然而，需要更多的数据来更好地区分实际物体和背景噪声。下面是一些例子。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mn"><img src="../Images/cd46556476f1644c4e98e1b072671250.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/0*Y_qI5HZhzQbgAqWI.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">在第 28，000 步做出的预测很差。左:预测。右:地面真相。</p></figure><p id="e405" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些图像显示了在第 28000 步做出的一些错误预测。请注意，探测器仍然可以探测到物体的大致轮廓，只是不是正确的轮廓。它预测为 Raspberry Pi 的对象也是那里最详细的对象，这表明它已经以某种方式了解到许多线条和轮廓可能表示该类。还要注意，这些置信度明显低于先前图像中正确预测的类别，这表明在可视化期间稍高的阈值可能会减轻这个问题。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/be4e295a5298deb476327e14772bbebc.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/0*0NQIZO4tyjUpCh4Y.gif"/></div></figure><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/73c2c32fab1c7c198e94c687f0687425.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/0*R7F8_mn2LlrtyqZr.gif"/></div></figure><p id="f0dc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了更好地显示结果，我向您展示运行在 android 的<a class="ae lc" href="https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android" rel="noopener ugc nofollow" target="_blank"> TensorflowLite 对象检测器演示应用程序中的检测器。这些结果基于之前讨论的配置，即没有硬示例挖掘，但我让模型在几百万张图像上训练。在合成数据生成时间中，这大致相当于在你离开办公室时开始生成，而在你第二天早上上班时就完成了。</a></p><p id="0397" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个项目是一个有趣的实验，它向我们证明了合成数据是真实数据的一个可行的替代品，在时间和金钱方面的成本都要低得多。事实上，这个项目没花我们一分钱。所有的部分都是免费使用和开源的。这只是证明，无论你是业余爱好者，项目负责人，还是介于两者之间的任何人，你都有机会使用最新的深度学习来创建出色的软件，而不需要你付出任何成本，只需要一点努力。</p><p id="d370" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">我在 Alexandra Institute 的视觉计算实验室工作，这是一家丹麦非营利公司，专门研究最先进的 it 解决方案。在我们的实验室，我们专注于利用最新的计算机视觉和计算机图形研究。我们目前正在研究数据注释、生成和增强技术，以允许较小的公司和个人开始深度学习。我们永远欢迎合作！</em></p></div></div>    
</body>
</html>