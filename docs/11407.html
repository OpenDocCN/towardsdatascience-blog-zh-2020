<html>
<head>
<title>A good Machine Learning classifier’s accuracy metric for the Poker-hand dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一个好的机器学习分类器对扑克牌数据集的精度度量</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-good-machine-learning-classifiers-accuracy-metric-for-the-poker-hand-dataset-44cc3456b66d?source=collection_archive---------30-----------------------#2020-08-07">https://towardsdatascience.com/a-good-machine-learning-classifiers-accuracy-metric-for-the-poker-hand-dataset-44cc3456b66d?source=collection_archive---------30-----------------------#2020-08-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/38ab746b2bda39a169fcde02c1727574.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fwnncyyXnluGlE46"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">马库斯·温克勒在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><div class=""><h2 id="3b61" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">一个非常适合高度不平衡数据集的指标</h2></div><h1 id="a0c0" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">什么是数据集？</h1><p id="38c5" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated"><a class="ae jg" href="https://archive.ics.uci.edu/ml/datasets/Poker+Hand" rel="noopener ugc nofollow" target="_blank">扑克手数据集</a>【Cattral 等人，2007 年】是公开可用的，并且在<a class="ae jg" href="http://archive.ics.uci.edu/ml" rel="noopener ugc nofollow" target="_blank"> UCI 机器学习知识库</a>【Dua 等人，2019 年】中有非常好的记录。[Cattral 等人，2007 年]将其描述为:</p><blockquote class="mm mn mo"><p id="7588" class="lq lr mp ls b lt mq kk lv lw mr kn ly ms mt mb mc mu mv mf mg mw mx mj mk ml im bi translated">对于分类算法来说，这是一个具有挑战性的数据集</p></blockquote><p id="08a3" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated">这是一个 11 维的数据集，有 25K 个样本用于训练，超过 100 万个样本用于测试。每个数据集实例都是一手 5 张牌的扑克，每张牌使用两个特征(花色和级别)和一手扑克标签。</p><h1 id="39e6" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">为什么很难？</h1><p id="1328" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">它有两个特性使得分类算法特别具有挑战性:它全是<strong class="ls jk">分类特征</strong>和它<strong class="ls jk">极度不平衡</strong>。<a class="ae jg" href="https://www.datacamp.com/community/tutorials/categorical-data" rel="noopener ugc nofollow" target="_blank">分类特征</a>很难，因为典型的距离(又称相似性)度量不能自然地应用于此类特征。例如，该数据集有两个特征:等级和套件，计算“黑桃”和“红桃”之间的欧几里德距离根本没有意义。<a class="ae jg" href="https://medium.com/analytics-vidhya/what-is-balance-and-imbalance-dataset-89e8d7f46bc5" rel="noopener">不平衡的</a>数据集很难，因为机器学习算法假设了良好的平衡，<a class="my mz ep" href="https://medium.com/u/f374d0159316?source=post_page-----44cc3456b66d--------------------------------" rel="noopener" target="_blank">机器学习大师<a class="ae jg" href="https://machinelearningmastery.com/what-is-imbalanced-classification/" rel="noopener ugc nofollow" target="_blank">的</a>Jason Brownlee</a>将这个问题描述为:</p><blockquote class="mm mn mo"><p id="651e" class="lq lr mp ls b lt mq kk lv lw mr kn ly ms mt mb mc mu mv mf mg mw mx mj mk ml im bi translated">不平衡的分类对预测建模提出了挑战，因为用于分类的大多数机器学习算法是围绕每个类别的相等数量的样本的假设而设计的</p></blockquote><h1 id="3b40" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">那么，为什么我会得到好的结果呢？</h1><p id="b143" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">那么，如果这个数据集被认为是困难的，为什么一个简单的神经网络可以在没有任何特殊调整或数据预处理的情况下达到 90%以上的准确性？</p><p id="511d" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated">在<a class="ae jg" href="https://medium.com/@virgoady7/poker-hand-prediction-7a801e254acd" rel="noopener">这篇文章</a> , <a class="my mz ep" href="https://medium.com/u/43bd75e69f79?source=post_page-----44cc3456b66d--------------------------------" rel="noopener" target="_blank"> Aditya Bhardwaj </a>显示他的神经网络达到了 90.04 的准确率。下面，我展示了一个简单的<a class="ae jg" href="https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html" rel="noopener ugc nofollow" target="_blank">多层感知器神经网络</a> k 实现了超过 99%的准确率。发生这种情况的一个原因是由于<strong class="ls jk">职业不平衡问题</strong>。[Ling 等人，2011 年]解释说:</p><blockquote class="mm mn mo"><p id="77d0" class="lq lr mp ls b lt mq kk lv lw mr kn ly ms mt mb mc mu mv mf mg mw mx mj mk ml im bi translated">当类别分布高度不平衡时，数据被认为遭受了类别不平衡问题。在这种情况下，许多分类学习算法对非频繁类的预测精度较低。</p></blockquote><p id="4883" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated">扑克手数据集碰巧非常不平衡，在训练集和测试集中，前两个类代表了 90%的样本。一个学习如何正确分类这两个类别，但完全错误分类其余类别的分类器，仍将达到 90%的预测准确率。<strong class="ls jk">这不是一个好的分类器！</strong>。分类器仍然获得高分的原因很简单，因为<strong class="ls jk">类别不平衡考虑到了</strong>，即<strong class="ls jk">优势类别的正确预测被赋予了与样本数量成比例的权重。</strong>“非频繁类的低预测准确性”被来自那些有大量样本可供学习的类的较好预测所掩盖。</p><h1 id="20ad" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">我们能做些什么呢？</h1><p id="052c" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">一个不考虑阶级不平衡的度量标准，例如，对所有阶级给予同等的权重，而不考虑他们的主导地位，可以提供更“真实”或准确的结果。<strong class="ls jk"> Scikit-learn </strong>的<a class="ae jg" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html" rel="noopener ugc nofollow" target="_blank">分类报告</a>有一个这样的指标。<strong class="ls jk"> F1 得分</strong>结合了精确度和召回率两方面的结果，分类报告包括一个<strong class="ls jk">F1</strong>T24】宏观平均度量<strong class="ls jk">，</strong>即<strong class="ls jk">未加权的每个标签的 F1 得分平均值！</strong>。正如 Scikit-learn 关于 F-metrics 的<a class="ae jg" href="https://scikit-learn.org/stable/modules/model_evaluation.html#precision-recall-f-measure-metrics" rel="noopener ugc nofollow" target="_blank">文档中提到的:</a></p><blockquote class="mm mn mo"><p id="9ae8" class="lq lr mp ls b lt mq kk lv lw mr kn ly ms mt mb mc mu mv mf mg mw mx mj mk ml im bi translated">在非频繁类仍然重要的问题中，宏平均可能是突出其性能的一种方法</p></blockquote><p id="d9a3" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated">这是一个很好的度量示例，可用于衡量分类器在这种高度不平衡的数据集上的性能。</p><p id="5648" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated">在机器学习文献中已经提出了许多其他方法和度量来处理这里提到的一些问题。例如，Boriah 等人在他们的论文“<strong class="ls jk">分类数据的相似性度量:比较评估”</strong>中讨论了用于处理分类特征的一些现有方法。讨论这个不是这篇文章的范围，因此我会简单地给你留下一个论文的链接<a class="ae jg" href="https://www.researchgate.net/publication/220907006_Similarity_Measures_for_Categorical_Data_A_Comparative_Evaluation" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><h1 id="9ab3" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">请出一些结果？</h1><p id="d735" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">我继续运行一个多层感知器神经网络，这是我得到的结果。这个网络使用<strong class="ls jk"> 3 个隐层，每个隐层 100 个神经元，alpha=0.0001，学习率=0.01。</strong>下面是<a class="ae jg" href="https://en.wikipedia.org/wiki/Confusion_matrix" rel="noopener ugc nofollow" target="_blank"> <strong class="ls jk">混淆矩阵</strong> </a>。可以观察到，神经网络总体上做得很好，正确地分类了前 6 个类别中的大多数，对于类别 7 和 9(四个同花和同花)有一些特别差的结果。</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div class="gh gi na"><img src="../Images/7b0507341adece163ef2fc93ec1b1b7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*j-dZyDg73hmKsd8-o362QA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">混淆矩阵</p></figure><p id="24de" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated"><strong class="ls jk">该分类器报告的准确率为 99% </strong>。尽管第 7 类和第 9 类的表现非常糟糕，但它们只贡献了 100 万个测试样本中的 233 个。几个非主导类的坏结果完全被其他类掩盖了。这显然给人一种成功的错觉！神经网络错误分类了 66%和 77%的皇家同花顺和四张一类的手牌，但它得到了正确但误导性的 99%的准确性结果。</p><p id="5653" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated">下面显示的<strong class="ls jk">分类报告</strong>包括前面提到的<strong class="ls jk">所有类别的宏观平均 F1 分数</strong>。这种未加权的平均值更好地概括了分类器的表现。可以看出，大多数班级实际上做得很好，但也有几个班级做得特别差。<strong class="ls jk">但更重要的是，可以观察到报告的宏观平均值为 78%。</strong>对于观察到的结果，这是一个更合适的分数！2/10 的班级表现很差，而其他班级表现得更好，这反映在指标中，当指标被仔细选择时。</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="1f12" class="nk kz jj ng b gy nl nm l nn no">              precision    recall  f1-score   support</span><span id="9c12" class="nk kz jj ng b gy np nm l nn no">           0       1.00      0.99      0.99    501209<br/>           1       0.99      0.99      0.99    422498<br/>           2       0.96      1.00      0.98     47622<br/>           3       0.99      0.99      0.99     21121<br/>           4       0.85      0.64      0.73      3885<br/>           5       0.97      0.99      0.98      1996<br/>           6       0.77      0.98      0.86      1424<br/>           7       0.70      0.23      0.35       230<br/>           8       1.00      0.83      0.91        12<br/>           9       0.04      0.33      0.07         3</span><span id="c098" class="nk kz jj ng b gy np nm l nn no">    accuracy                           0.99   1000000<br/>   <strong class="ng jk">macro avg       0.83      0.80      0.78   1000000</strong><br/>weighted avg       0.99      0.99      0.99   1000000</span></pre><h1 id="b3b0" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">参考</h1><p id="b88e" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">[1]卡特拉尔和奥帕彻(2007 年)。扑克手数据集[<a class="ae jg" href="https://archive.ics.uci.edu/ml/datasets/Poker+Hand" rel="noopener ugc nofollow" target="_blank">https://archive.ics.uci.edu/ml/datasets/Poker+Hand</a>]<br/>卡尔顿大学计算机科学系。<br/>智能系统研究小组</p><p id="9297" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated">[2]Dua d .和 Graff c .(2019 年)。http://archive.ics.uci.edu/ml 的 UCI 机器学习知识库。加州欧文:加州大学信息与计算机科学学院。</p><p id="529e" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated">[3]凌春霞，盛诉生(2011)阶层失衡问题。在:萨姆特 c，韦伯 G.I .(编辑)机器学习百科全书。马萨诸塞州波士顿斯普林格。https://doi.org/10.1007/978-0-387-30164-8_110<a class="ae jg" href="https://doi.org/10.1007/978-0-387-30164-8_110" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>