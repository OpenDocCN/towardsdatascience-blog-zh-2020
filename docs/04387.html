<html>
<head>
<title>Speed-up inference with Batch Normalization Folding</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">批量归一化折叠加速推理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/speed-up-inference-with-batch-normalization-folding-8a45a83a89d8?source=collection_archive---------25-----------------------#2020-04-20">https://towardsdatascience.com/speed-up-inference-with-batch-normalization-folding-8a45a83a89d8?source=collection_archive---------25-----------------------#2020-04-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3e69" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何删除批处理规范化层，使您的神经网络更快。</h2></div><h2 id="3dca" class="ki kj it bd kk kl km dn kn ko kp dp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">介绍</h2><p id="7e65" class="pw-post-body-paragraph le lf it lg b lh li ju lj lk ll jx lm kr ln lo lp kv lq lr ls kz lt lu lv lw im bi translated">批量标准化是一种技术，它负责标准化每一层的输入，以使训练过程更快、更稳定。实际上，这是一个额外的层，我们通常在计算层之后和非线性之前添加。</p><p id="142e" class="pw-post-body-paragraph le lf it lg b lh lx ju lj lk ly jx lm kr lz lo lp kv ma lr ls kz mb lu lv lw im bi translated">它包括2个步骤:</p><ul class=""><li id="3652" class="mc md it lg b lh lx lk ly kr me kv mf kz mg lw mh mi mj mk bi translated">通过先减去其平均值μ，然后除以其标准偏差σ来归一化该批次。</li><li id="8c45" class="mc md it lg b lh ml lk mm kr mn kv mo kz mp lw mh mi mj mk bi translated">进一步缩放因子γ并移位因子β。这些是批量归一化层的参数，在网络不需要数据的均值为0且标准差为1的情况下需要这些参数。</li></ul><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/9fa8eccafb7573c8c5e3076b5e47c704.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*25tFnm9meCMAo-14iRbWVw@2x.png"/></div></figure><p id="db53" class="pw-post-body-paragraph le lf it lg b lh lx ju lj lk ly jx lm kr lz lo lp kv ma lr ls kz mb lu lv lw im bi translated">由于批处理规范化对训练神经网络的效率，它现在被广泛使用。但是在推理的时候有多大用处呢？</p><p id="96db" class="pw-post-body-paragraph le lf it lg b lh lx ju lj lk ly jx lm kr lz lo lp kv ma lr ls kz mb lu lv lw im bi translated">一旦训练结束，每个批次归一化层都拥有一组特定的γ和β，以及μ和σ，后者是在训练期间使用指数加权平均值计算的。这意味着在推断过程中，批量标准化是对前一层的结果进行简单的线性变换，通常是卷积。</p><p id="6aff" class="pw-post-body-paragraph le lf it lg b lh lx ju lj lk ly jx lm kr lz lo lp kv ma lr ls kz mb lu lv lw im bi translated">由于卷积也是线性变换，这也意味着两种运算可以合并成一个线性变换！</p><p id="791a" class="pw-post-body-paragraph le lf it lg b lh lx ju lj lk ly jx lm kr lz lo lp kv ma lr ls kz mb lu lv lw im bi translated">这将删除一些不必要的参数，但也减少了推理时要执行的操作的数量。</p></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><h2 id="f0fd" class="ki kj it bd kk kl km dn kn ko kp dp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">在实践中如何做到这一点？</h2><p id="25ce" class="pw-post-body-paragraph le lf it lg b lh li ju lj lk ll jx lm kr ln lo lp kv lq lr ls kz lt lu lv lw im bi translated">借助一点数学知识，我们可以很容易地重新排列卷积的项，以考虑批量标准化。</p><p id="95c3" class="pw-post-body-paragraph le lf it lg b lh lx ju lj lk ly jx lm kr lz lo lp kv ma lr ls kz mb lu lv lw im bi translated">稍微提醒一下，对于输入<em class="nf"> x </em>，批量归一化操作之后的卷积操作可以表示为:</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/d0ef444f6edc8fc7b7d2508448234fa6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*rjlOnTVDi6-vrkGUq8z73Q@2x.png"/></div></figure><p id="1bfc" class="pw-post-body-paragraph le lf it lg b lh lx ju lj lk ly jx lm kr lz lo lp kv ma lr ls kz mb lu lv lw im bi translated">因此，如果我们重新安排卷积的<strong class="lg iu"> W </strong>和<strong class="lg iu"> b </strong>来考虑批量归一化的参数，则:</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/bb8e3753e9d65e904c4e63f41cdaf743.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*p1tzta8ApjCBJEEklofuKg@2x.png"/></div></figure><p id="14d9" class="pw-post-body-paragraph le lf it lg b lh lx ju lj lk ly jx lm kr lz lo lp kv ma lr ls kz mb lu lv lw im bi translated">我们可以删除批处理规范化层，但仍然有相同的结果！</p><blockquote class="nh ni nj"><p id="15d2" class="le lf nf lg b lh lx ju lj lk ly jx lm nk lz lo lp nl ma lr ls nm mb lu lv lw im bi translated"><strong class="lg iu">注意</strong>:通常情况下，在批量标准化层之前的层中没有偏差。这是无用的，也是参数的浪费，因为任何常数都将被批量标准化所抵消。</p></blockquote></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><h2 id="bb05" class="ki kj it bd kk kl km dn kn ko kp dp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">效率如何？</h2><p id="974f" class="pw-post-body-paragraph le lf it lg b lh li ju lj lk ll jx lm kr ln lo lp kv lq lr ls kz lt lu lv lw im bi translated">我们将尝试两种常见的架构:</p><ul class=""><li id="b8fa" class="mc md it lg b lh lx lk ly kr me kv mf kz mg lw mh mi mj mk bi translated">带批次标准的VGG16</li><li id="3b65" class="mc md it lg b lh ml lk mm kr mn kv mo kz mp lw mh mi mj mk bi translated">ResNet50</li></ul><p id="3083" class="pw-post-body-paragraph le lf it lg b lh lx ju lj lk ly jx lm kr lz lo lp kv ma lr ls kz mb lu lv lw im bi translated">仅仅为了演示，我们将使用<a class="ae nn" href="https://github.com/fastai/imagenette" rel="noopener ugc nofollow" target="_blank"> ImageNette数据集</a>和PyTorch。两个网络都将被训练5个历元，以及在参数数目和推理时间方面有什么变化。</p><h2 id="0caa" class="ki kj it bd kk kl km dn kn ko kp dp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">1.VGG16</h2><p id="c604" class="pw-post-body-paragraph le lf it lg b lh li ju lj lk ll jx lm kr ln lo lp kv lq lr ls kz lt lu lv lw im bi translated">先来训练VGG16个历元(最终精度无所谓):</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi no"><img src="../Images/db2324aa926542a57d17fe7ed66b5f9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W2TH_5baGZM4TnfF9e7t0A.png"/></div></div></figure><p id="5c6f" class="pw-post-body-paragraph le lf it lg b lh lx ju lj lk ly jx lm kr lz lo lp kv ma lr ls kz mb lu lv lw im bi translated">然后显示其参数数量:</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi nt"><img src="../Images/6107caf323fc0f9c1d0930c93a5aa90a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e8ONRJbsHIGBGxv7U3Q-WQ.png"/></div></div></figure><p id="5626" class="pw-post-body-paragraph le lf it lg b lh lx ju lj lk ly jx lm kr lz lo lp kv ma lr ls kz mb lu lv lw im bi translated">单幅图像的初始推断时间为:</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi nu"><img src="../Images/cfaaf767b26f578d937994de62cb0b92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nf6r_oPyhf8hSWzkUkcYSA.png"/></div></div></figure><p id="8623" class="pw-post-body-paragraph le lf it lg b lh lx ju lj lk ly jx lm kr lz lo lp kv ma lr ls kz mb lu lv lw im bi translated">现在，如果我们应用批量归一化折叠，我们有:</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi nv"><img src="../Images/e105611140b38d73fe70cf7156d25962.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GAnq1JZ3_0jocJr3qLTARg.png"/></div></div></figure><p id="f836" class="pw-post-body-paragraph le lf it lg b lh lx ju lj lk ly jx lm kr lz lo lp kv ma lr ls kz mb lu lv lw im bi translated">并且:</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi nu"><img src="../Images/3e08e8887a36b42b337343bb074952e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d9LQlqo2ccfGWIHxk-QLSg.png"/></div></div></figure><p id="afdf" class="pw-post-body-paragraph le lf it lg b lh lx ju lj lk ly jx lm kr lz lo lp kv ma lr ls kz mb lu lv lw im bi translated">所以去掉8448参数甚至更好，几乎快了0.4 ms的推断！最重要的是，这是完全无损的，在性能方面完全没有变化:</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi nw"><img src="../Images/035fbf65e9784b6dade06121ed4e73e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FCwnnABg54fKUjO8_DbfnA.png"/></div></div></figure><p id="3dd0" class="pw-post-body-paragraph le lf it lg b lh lx ju lj lk ly jx lm kr lz lo lp kv ma lr ls kz mb lu lv lw im bi translated">让我们看看它在Resnet50的情况下是如何表现的！</p><h2 id="29ff" class="ki kj it bd kk kl km dn kn ko kp dp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">2.Resnet50</h2><p id="f345" class="pw-post-body-paragraph le lf it lg b lh li ju lj lk ll jx lm kr ln lo lp kv lq lr ls kz lt lu lv lw im bi translated">同样，我们从训练它5个时期开始:</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi nx"><img src="../Images/b3f4db8a5346170b3262724c7b493dc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HWqXPVvncyHQKZVgDcxNgw.png"/></div></div></figure><p id="bf47" class="pw-post-body-paragraph le lf it lg b lh lx ju lj lk ly jx lm kr lz lo lp kv ma lr ls kz mb lu lv lw im bi translated">参数的初始数量是:</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi ny"><img src="../Images/2ebf0851f1e6c9ebe912ded73af92bd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j_1oVNl24Ma7hN0xqYy6gg.png"/></div></div></figure><p id="1ffc" class="pw-post-body-paragraph le lf it lg b lh lx ju lj lk ly jx lm kr lz lo lp kv ma lr ls kz mb lu lv lw im bi translated">而推断时间是:</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi nz"><img src="../Images/0891bed869c81cb65854f2b2ce2900fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OLb9LFaTZtDPOrmu5-bh_A.png"/></div></div></figure><p id="ce44" class="pw-post-body-paragraph le lf it lg b lh lx ju lj lk ly jx lm kr lz lo lp kv ma lr ls kz mb lu lv lw im bi translated">使用批量标准化折叠后，我们有:</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi oa"><img src="../Images/9008f80999b19ac8833ea64ee8c8c212.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zb8IW7NjDyC-66RpMiwUlQ.png"/></div></div></figure><p id="29fd" class="pw-post-body-paragraph le lf it lg b lh lx ju lj lk ly jx lm kr lz lo lp kv ma lr ls kz mb lu lv lw im bi translated">并且:</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi ob"><img src="../Images/1fc6d33dea8a6ed211f9f18087d79d0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aeZofTnyJ-HnRY6r6wLB7Q.png"/></div></div></figure><p id="b510" class="pw-post-body-paragraph le lf it lg b lh lx ju lj lk ly jx lm kr lz lo lp kv ma lr ls kz mb lu lv lw im bi translated">现在，我们删除了26，560个参数，更令人印象深刻的是，推断时间减少了1.5毫秒！并且仍然没有任何性能下降。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi oc"><img src="../Images/9246d7d826071b4b679a94b023704fae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*31lPpDdubNOeHnjlOqRMCg.png"/></div></div></figure><p id="e1a7" class="pw-post-body-paragraph le lf it lg b lh lx ju lj lk ly jx lm kr lz lo lp kv ma lr ls kz mb lu lv lw im bi translated">因此，如果我们可以在不降低性能的情况下减少推理时间和模型的参数数量，为什么我们不能一直这样做呢？</p><h2 id="4fb0" class="ki kj it bd kk kl km dn kn ko kp dp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">希望这篇博文对你有所帮助！如果有不清楚的地方，请随时给我反馈或问我问题。</h2></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><h2 id="4d21" class="ki kj it bd kk kl km dn kn ko kp dp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">此处提供代码:</h2><div class="od oe gp gr of og"><a href="https://github.com/nathanhubens/fasterai" rel="noopener  ugc nofollow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd iu gy z fp ol fr fs om fu fw is bi translated">纳坦胡本斯/法斯特赖</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">FasterAI:一个用FastAI库制作更小更快模型的库。-纳坦胡本斯/法斯特莱</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">github.com</p></div></div><div class="op l"><div class="oq l or os ot op ou mw og"/></div></div></a></div><h2 id="acef" class="ki kj it bd kk kl km dn kn ko kp dp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">参考资料和进一步阅读材料:</h2><ul class=""><li id="9a57" class="mc md it lg b lh li lk ll kr ov kv ow kz ox lw mh mi mj mk bi translated"><a class="ae nn" href="https://arxiv.org/pdf/1502.03167.pdf" rel="noopener ugc nofollow" target="_blank">批量规格化论文</a></li><li id="d0dd" class="mc md it lg b lh ml lk mm kr mn kv mo kz mp lw mh mi mj mk bi translated"><a class="ae nn" href="https://www.youtube.com/watch?v=tNIpEZLv_eg&amp;t=1s" rel="noopener ugc nofollow" target="_blank"> DeepLearning.ai批量归一化课</a></li></ul></div></div>    
</body>
</html>