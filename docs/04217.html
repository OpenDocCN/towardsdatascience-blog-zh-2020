<html>
<head>
<title>Your First Neural Network in PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你在PyTorch的第一个神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/your-first-neural-network-in-pytorch-725631ae0fc?source=collection_archive---------6-----------------------#2020-04-17">https://towardsdatascience.com/your-first-neural-network-in-pytorch-725631ae0fc?source=collection_archive---------6-----------------------#2020-04-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="dd3b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">让我们把电脑预热一下。</h2></div><p id="eb12" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">随着深度学习领域日益升温，网络上有太多的高级文章，很容易认为深度学习是只为数学博士保留的高级领域——但让我们证明你错了。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/44c331ed047c3469e6763ea6ef1a717c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_WT4QQ7xSn5fYRUn"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">照片由<a class="ae lu" href="https://unsplash.com/@acharki95?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Aziz Acharki </a>在<a class="ae lu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="7e1d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">深度学习领域，至少是实践部分，从未像现在这样容易起步——因为资源的数量在增长，图书馆也在变得更好。</p><p id="6ec9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇文章的目标读者是那些知道人工神经网络的基础理论但不知道如何编码的人。相信我，事情会比你想象的简单。</p><p id="cae5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇文章的结构如下:</p><ol class=""><li id="4f4b" class="lv lw it kk b kl km ko kp kr lx kv ly kz lz ld ma mb mc md bi translated">导入和数据集</li><li id="20d8" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">训练/测试分割</li><li id="2e50" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">定义神经网络模型</li><li id="6388" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">模特培训</li><li id="6aaf" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">模型评估</li><li id="9b64" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">结论</li></ol><p id="b9a0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这看起来很多，但是我保证——如果你安装了必要的库，你最多可以在10分钟内读完，如果你决定跟随代码，15分钟就可以了。</p><p id="b1ee" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">读完这篇文章后，你将对如何在PyTorch库中实现一个<strong class="kk iu">人工神经网络</strong>算法来对以前看不见的数据进行预测有一个基本的想法。</p><p id="d042" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请记住，这篇文章并没有涵盖高级的内容，因为这些内容将会出现在后面的文章中。所以事不宜迟，我们开始吧。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="23aa" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">导入和数据集</h1><p id="41ea" class="pw-post-body-paragraph ki kj it kk b kl ni ju kn ko nj jx kq kr nk kt ku kv nl kx ky kz nm lb lc ld im bi translated">对于这个简单的例子，我们将只使用几个库:</p><ul class=""><li id="dc01" class="lv lw it kk b kl km ko kp kr lx kv ly kz lz ld nn mb mc md bi translated"><code class="fe no np nq nr b">Pandas</code>:用于数据加载和操作</li><li id="0285" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld nn mb mc md bi translated"><code class="fe no np nq nr b">Scikit-learn</code>:用于列车测试分割</li><li id="5e8c" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld nn mb mc md bi translated"><code class="fe no np nq nr b">Matplotlib</code>:用于数据可视化</li><li id="4a30" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld nn mb mc md bi translated"><code class="fe no np nq nr b">PyTorch</code>:用于模型训练</li></ul><p id="63c6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您只想复制/粘贴，以下是导入内容:</p><pre class="lf lg lh li gt ns nr nt nu aw nv bi"><span id="b82b" class="nw mr it nr b gy nx ny l nz oa">import torch<br/>import torch.nn as nn<br/>import torch.nn.functional as F<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>from sklearn.model_selection import train_test_split</span></pre><p id="a296" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">至于数据集，<strong class="kk iu">虹膜数据集</strong>，可以在<a class="ae lu" href="https://raw.githubusercontent.com/pandas-dev/pandas/master/pandas/tests/data/iris.csv" rel="noopener ugc nofollow" target="_blank">这个URL </a>上找到。下面介绍如何在熊猫中直接导入:</p><pre class="lf lg lh li gt ns nr nt nu aw nv bi"><span id="88b8" class="nw mr it nr b gy nx ny l nz oa">iris = pd.read_csv('<a class="ae lu" href="https://raw.githubusercontent.com/pandas-dev/pandas/master/pandas/tests/data/iris.csv'" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/pandas-dev/pandas/master/pandas/tests/data/iris.csv</a>')<br/>iris.head()</span></pre><p id="5018" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">前几行看起来像这样:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/c6c96972305e9da847b7e7f56965cff5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1068/format:webp/1*RnCWb8UPqrM5RIAyB2CiEQ.png"/></div></figure><p id="69f2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们现在要做的是将<code class="fe no np nq nr b">Name</code>列中的值更改或重新映射为数字——比如说<code class="fe no np nq nr b">0, 1, 2</code>。下面是如何做到这一点:</p><pre class="lf lg lh li gt ns nr nt nu aw nv bi"><span id="8bf9" class="nw mr it nr b gy nx ny l nz oa">mappings = {<br/>   'Iris-setosa': 0,<br/>   'Iris-versicolor': 1,<br/>   'Iris-virginica': 2<br/>}</span><span id="7a42" class="nw mr it nr b gy oc ny l nz oa">iris['Name'] = iris['Name'].apply(lambda x: mappings[x])</span></pre><p id="5e3e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">执行上面的代码会产生以下数据帧:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi od"><img src="../Images/c7e2f6bfa4943e257a7fe1d563340c4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*HU3Z2u7wVk5RNQDVbM1G1A.png"/></div></figure><p id="4de1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">也就是说我们可以继续了。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="48a7" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">训练/测试分割</h1><p id="6d2a" class="pw-post-body-paragraph ki kj it kk b kl ni ju kn ko nj jx kq kr nk kt ku kv nl kx ky kz nm lb lc ld im bi translated">在本节中，我们将使用<code class="fe no np nq nr b">Scikit-Learn</code>库来进行训练/测试分割。之后，我们将把分割数据从<code class="fe no np nq nr b">Numpy arrays</code>转换到<code class="fe no np nq nr b">PyTorch tensors</code>。</p><p id="cce6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们看看怎么做。</p><p id="afbf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，我们需要将虹膜数据集分为<strong class="kk iu">特征</strong>和<strong class="kk iu">目标</strong> —或者X和y。列<code class="fe no np nq nr b">Name</code>将是目标变量，其他所有内容都将是特征(或预测值)。</p><p id="0306" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我也将使用一个随机的种子，所以你能够复制我的结果。代码如下:</p><pre class="lf lg lh li gt ns nr nt nu aw nv bi"><span id="2048" class="nw mr it nr b gy nx ny l nz oa">X = iris.drop('Name', axis=1).values<br/>y = iris['Name'].values</span><span id="d821" class="nw mr it nr b gy oc ny l nz oa">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><span id="1f28" class="nw mr it nr b gy oc ny l nz oa">X_train = torch.FloatTensor(X_train)<br/>X_test = torch.FloatTensor(X_test)<br/>y_train = torch.LongTensor(y_train)<br/>y_test = torch.LongTensor(y_test)</span></pre><p id="3244" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您现在检查从<code class="fe no np nq nr b">X_train</code>开始的前3行，您会得到这样的结果:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/65f8a919c60d5d87d705177570c07eec.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/1*1fbwYkyR4wZ2ZrWbUHMS_A.png"/></div></figure><p id="963d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">同样适用于<code class="fe no np nq nr b">y_train</code>:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi of"><img src="../Images/bb0d8551e2e2b1782017190482a559e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:368/format:webp/1*Rh1d4zUy4Qy1vimF3CXODA.png"/></div></figure><p id="8113" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们现在已经具备了创建神经网络所需的一切——让我们在下一节开始吧。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="49d4" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">定义神经网络模型</h1><p id="e8d3" class="pw-post-body-paragraph ki kj it kk b kl ni ju kn ko nj jx kq kr nk kt ku kv nl kx ky kz nm lb lc ld im bi translated">至于模型的架构，会很简单。让我们看看网络将如何构建:</p><ol class=""><li id="0004" class="lv lw it kk b kl km ko kp kr lx kv ly kz lz ld ma mb mc md bi translated"><strong class="kk iu">全连通层</strong> ( <strong class="kk iu"> 4 </strong>输入特征(X中的特征数)，<strong class="kk iu"> 16 </strong>输出特征(任意))</li><li id="a5e8" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated"><strong class="kk iu">全连通层</strong> ( <strong class="kk iu"> 16 </strong>输入特征(来自上一层的输出特征数)，<strong class="kk iu"> 12 </strong>输出特征(任意))</li><li id="a7b8" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated"><strong class="kk iu">输出层</strong> ( <strong class="kk iu"> 12 </strong>输入特征(来自前一层的输出特征的数量)，<strong class="kk iu"> 3 </strong>输出特征(不同类的数量))</li></ol><p id="e277" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">差不多就是这样。除此之外，我们将使用<strong class="kk iu"> ReLU </strong>作为我们的激活函数。让我们看看如何用代码实现这一点:</p><pre class="lf lg lh li gt ns nr nt nu aw nv bi"><span id="420c" class="nw mr it nr b gy nx ny l nz oa">class ANN(nn.Module):<br/>   def __init__(self):<br/>       super().__init__()<br/>       self.fc1 = nn.Linear(in_features=4, out_features=16)<br/>       self.fc2 = nn.Linear(in_features=16, out_features=12)<br/>       self.output = nn.Linear(in_features=12, out_features=3)<br/> <br/> def forward(self, x):<br/>     x = F.relu(self.fc1(x))<br/>     x = F.relu(self.fc2(x))<br/>     x = self.output(x)<br/>     return x</span></pre><p id="e68d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">PyTorch使用这种面向对象的方式来声明模型，并且非常直观。在<strong class="kk iu">构造函数</strong>中，您将定义所有的层及其架构，在<code class="fe no np nq nr b">forward()</code>方法中，您将定义一个向前传递。</p><p id="0090" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">就这么简单。</p><p id="1e8a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，让我们创建一个模型实例，并验证其架构是否与我们上面指定的架构相匹配:</p><pre class="lf lg lh li gt ns nr nt nu aw nv bi"><span id="5f4a" class="nw mr it nr b gy nx ny l nz oa">model = ANN()<br/>model</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi og"><img src="../Images/e99861334e7ce1063ec78d2fd5b1df51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*7pknKD25TMA7vvl81tploQ.png"/></div></div></figure><p id="1cca" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">太好了。在我们训练模型之前，我们还需要声明几件事情:</p><ul class=""><li id="cb0e" class="lv lw it kk b kl km ko kp kr lx kv ly kz lz ld nn mb mc md bi translated"><strong class="kk iu">标准</strong>:基本上我们如何衡量损失，我们将使用<code class="fe no np nq nr b">CrossEntropyLoss</code></li><li id="a7bf" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld nn mb mc md bi translated"><strong class="kk iu">优化器</strong>:优化算法，我们将使用学习率为<code class="fe no np nq nr b">0.01</code>的<code class="fe no np nq nr b">Adam</code></li></ul><p id="c231" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面是如何用代码实现它:</p><pre class="lf lg lh li gt ns nr nt nu aw nv bi"><span id="3a84" class="nw mr it nr b gy nx ny l nz oa">criterion = nn.CrossEntropyLoss()<br/>optimizer = torch.optim.Adam(model.parameters(), lr=0.01)</span></pre><p id="7978" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在是我们期待已久的部分——模特培训！</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="b2f7" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">模特培训</h1><p id="23d8" class="pw-post-body-paragraph ki kj it kk b kl ni ju kn ko nj jx kq kr nk kt ku kv nl kx ky kz nm lb lc ld im bi translated">这部分也会极其简单。我们将训练模型100个纪元，记录时间和损失。每隔10个时期，我们将向控制台输出当前状态——指示我们所处的时期以及当前的损失。</p><p id="59a4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">代码如下:</p><pre class="lf lg lh li gt ns nr nt nu aw nv bi"><span id="948c" class="nw mr it nr b gy nx ny l nz oa">%%time</span><span id="10ba" class="nw mr it nr b gy oc ny l nz oa">epochs = 100<br/>loss_arr = []</span><span id="49a3" class="nw mr it nr b gy oc ny l nz oa">for i in range(epochs):<br/>   y_hat = model.forward(X_train)<br/>   loss = criterion(y_hat, y_train)<br/>   loss_arr.append(loss)<br/> <br/>   if i % 10 == 0:<br/>       print(f'Epoch: {i} Loss: {loss}')<br/> <br/>   optimizer.zero_grad()<br/>   loss.backward()<br/>   optimizer.step()</span></pre><p id="c680" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你想知道最后3行在做什么，答案很简单— <strong class="kk iu">反向传播</strong> —因此更新权重和偏差，这样模型就可以真正“学习”。</p><p id="36b5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面是上面代码的结果:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/30404bf50bfda848696f9c2276e55410.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/format:webp/1*j3y_A7E0qD2AImhI-MCjLg.png"/></div></figure><p id="a59e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">太快了——请不要习惯这种感觉。</p><p id="662a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果简单的数字对你来说毫无意义，这里有一个我们损失的可视化(x轴上的纪元编号和y轴上的损失):</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi oi"><img src="../Images/1f52cd9ca2550a29facaa04ef3396a48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XQpyTy_S93XysSu_yFMHyA.png"/></div></div></figure><p id="db83" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们已经训练了模型，但是现在呢？我们需要<strong class="kk iu">以某种方式在以前看不见的数据上评估</strong>。在这里多呆一分钟，你就会知道怎么做了。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="44f3" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">模型评估</h1><p id="8fd0" class="pw-post-body-paragraph ki kj it kk b kl ni ju kn ko nj jx kq kr nk kt ku kv nl kx ky kz nm lb lc ld im bi translated">在评估过程中，我们希望以某种方式跟踪模型做出的预测。我们需要迭代<code class="fe no np nq nr b">X_test</code>并做出预测，然后将它与实际值进行比较。</p><p id="ed7d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里我们将使用<code class="fe no np nq nr b">torch.no_grad()</code>,因为我们只是在评估——没有必要更新权重和偏差。</p><p id="bd20" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">总之，代码如下:</p><pre class="lf lg lh li gt ns nr nt nu aw nv bi"><span id="6797" class="nw mr it nr b gy nx ny l nz oa">preds = []</span><span id="462b" class="nw mr it nr b gy oc ny l nz oa">with torch.no_grad():<br/>   for val in X_test:<br/>       y_hat = model.forward(val)<br/>       preds.append(y_hat.argmax().item())</span></pre><p id="ac18" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">预测现在存储在<code class="fe no np nq nr b">preds</code>数组中。我们现在可以用以下3个属性制作一个熊猫数据帧:</p><ul class=""><li id="807a" class="lv lw it kk b kl km ko kp kr lx kv ly kz lz ld nn mb mc md bi translated"><code class="fe no np nq nr b">Y</code>:实际值</li><li id="15f6" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld nn mb mc md bi translated"><code class="fe no np nq nr b">YHat</code>:预测值</li><li id="373b" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld nn mb mc md bi translated"><code class="fe no np nq nr b">Correct</code>:标志，1表示<code class="fe no np nq nr b">Y</code>和<code class="fe no np nq nr b">YHat</code>匹配，否则为0</li></ul><p id="02f9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">代码如下:</p><pre class="lf lg lh li gt ns nr nt nu aw nv bi"><span id="2bb6" class="nw mr it nr b gy nx ny l nz oa">df = pd.DataFrame({'Y': y_test, 'YHat': preds})</span><span id="45c0" class="nw mr it nr b gy oc ny l nz oa">df['Correct'] = [1 if corr == pred else 0 for corr, pred in zip(df['Y'], df['YHat'])]</span></pre><p id="a157" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><code class="fe no np nq nr b">df</code>的前5行将如下所示:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi oj"><img src="../Images/80ee11329593fae8efb58c311bb543b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/format:webp/1*0jaVO3ww3WKTshs1StonWQ.png"/></div></div></figure><p id="73b9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这很好，但是实际上如何计算精确度呢？</p><p id="a0ca" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这很简单——我们只需要对<code class="fe no np nq nr b">Correct</code>列求和，然后除以<code class="fe no np nq nr b">df</code>的长度:</p><pre class="lf lg lh li gt ns nr nt nu aw nv bi"><span id="c62d" class="nw mr it nr b gy nx ny l nz oa">df['Correct'].sum() / len(df)</span><span id="0aa6" class="nw mr it nr b gy oc ny l nz oa"><strong class="nr iu">&gt;&gt;&gt; 1.0</strong></span></pre><p id="1a48" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们的模型对以前未见过的数据的准确率是100%。请记住，这只是因为虹膜数据集非常容易分类，这绝不是说神经网络是该数据集的最佳算法。我会说NN对于这种类型的问题来说太过了，但是这是另一个时间的讨论。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="26a8" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">结论</h1><p id="6330" class="pw-post-body-paragraph ki kj it kk b kl ni ju kn ko nj jx kq kr nk kt ku kv nl kx ky kz nm lb lc ld im bi translated">这就是你所要写的最简单的神经网络，有一个完美干净的数据集，没有丢失的值，最少的层和神经元，承认吧，这很容易。</p><p id="f0fd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下一次就不会了——因为更多的先进概念将会被引入。</p><p id="a74d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢阅读。再见。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="ok ol l"/></div></figure></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><p id="cab9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="om">喜欢这篇文章吗？成为</em> <a class="ae lu" href="https://medium.com/@radecicdario/membership" rel="noopener"> <em class="om">中等会员</em> </a> <em class="om">继续无限制学习。如果你使用下面的链接，我会收到你的一部分会员费，不需要你额外付费。</em></p><div class="on oo gp gr op oq"><a href="https://medium.com/@radecicdario/membership" rel="noopener follow" target="_blank"><div class="or ab fo"><div class="os ab ot cl cj ou"><h2 class="bd iu gy z fp ov fr fs ow fu fw is bi translated">通过我的推荐链接加入Medium-Dario rade ci</h2><div class="ox l"><h3 class="bd b gy z fp ov fr fs ow fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="oy l"><p class="bd b dl z fp ov fr fs ow fu fw dk translated">medium.com</p></div></div><div class="oz l"><div class="pa l pb pc pd oz pe lo oq"/></div></div></a></div></div></div>    
</body>
</html>