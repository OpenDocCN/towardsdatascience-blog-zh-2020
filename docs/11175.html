<html>
<head>
<title>Deep Learning in Histopathology (Part II)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">组织病理学中的深度学习(下)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-in-histopathology-35c0294d38eb?source=collection_archive---------40-----------------------#2020-08-03">https://towardsdatascience.com/deep-learning-in-histopathology-35c0294d38eb?source=collection_archive---------40-----------------------#2020-08-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="4c1b" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">计算机视觉/深度学习/医学成像</h2><div class=""/><div class=""><h2 id="92f2" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">文献综述</h2></div><p id="69db" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在最后一部分的<a class="ae ln" href="https://link.medium.com/EMIJptwAR7" rel="noopener">中，我们开始了关于深度学习在组织病理学中的现状的介绍性讨论，我们讨论了组织病理学、数字组织病理学、机器学习在该领域的可能性以及各种应用，随后详细讨论了处理数字显微切片图像以及将深度学习算法应用于这些图像所涉及的挑战。</a></p><p id="4afd" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在这篇博客中，我们将从方法论的角度更详细地讨论深度学习对组织病理学的适用性，以及它使用相关工作进行说明来帮助完成的任务。</p><p id="c847" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">深度学习的适用性可以根据它执行的任务或学习范式来研究，这是我们将在这篇文章中使用的分类。不同的学习算法，即用于组织病理学的深度学习，以及任务在以下概述中进行了可视化。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lo"><img src="../Images/11c2faaed7f1ce133ed580bdf5bab6fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cgSICZX2SZ9kp_6TJJPmAQ.jpeg"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">图:这里看到的是计算组织病理学中的深度神经网络模型、各种应用和任务的概述。来源:<a class="ae ln" href="https://arxiv.org/abs/1912.12378" rel="noopener ugc nofollow" target="_blank"> <strong class="bd me"> <em class="mf">斯里尼迪等人</em> </strong> </a></p></figure><p id="8f75" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">基于这些，在文献中已经提出了许多 DL 模型，这些模型传统上基于卷积神经网络(CNN)、递归神经网络(RNNs)、生成对抗网络(GANs)、自动编码器(AEs)和其他变体。</p><h1 id="5a0c" class="mg mh it bd mi mj mk ml mm mn mo mp mq ki mr kj ms kl mt km mu ko mv kp mw mx bi translated">监督学习</h1><p id="5885" class="pw-post-body-paragraph kr ks it kt b ku my kd kw kx mz kg kz la na lc ld le nb lg lh li nc lk ll lm im bi translated">在监督学习技术中，我们根据数字组织病理学中解决的任务的性质确定了三种主要的规范深度学习模型:分类、回归和分割。</p><h2 id="d2b9" class="nd mh it bd mi ne nf dn mm ng nh dp mq la ni nj ms le nk nl mu li nm nn mw iz bi translated">监督分类法</h2><p id="03be" class="pw-post-body-paragraph kr ks it kt b ku my kd kw kx mz kg kz la na lc ld le nb lg lh li nc lk ll lm im bi translated">它可以进一步细分为局部和全球一级的分类。<strong class="kt jd"> <em class="no">局部级别分类</em> </strong>需要识别整个载玻片图像的小块中的细胞或细胞核。深度学习已被证明在通过滑动窗口方法对图像补片进行逐像素预测方面非常成功，病理学家将这些图像补片标注为包含感兴趣对象(细胞/细胞核)或背景的区域。<br/>局部分类中最突出的工作之一出现在 2019 年，当时<a class="ae ln" href="https://arxiv.org/abs/1805.03699" rel="noopener ugc nofollow" target="_blank"> <strong class="kt jd"> <em class="no"> Qaiser 等人</em></strong></a><strong class="kt jd"><em class="no"/></strong>在其论文中使用<a class="ae ln" href="https://epjdatascience.springeropen.com/articles/10.1140/epjds/s13688-017-0109-5#:~:text=Persistent%20homology%20(PH)%20is%20a,qualitative%20features%20of%20the%20input." rel="noopener ugc nofollow" target="_blank"><em class="no"/></a>轮廓作为区分特征，以便通过将斑块分类为肿瘤区域或正常区域来分割结肠肿瘤区域。<em class="no">持续同源性分布图</em>是一个区域的紧凑的数学特征表示，对于输入数据、维度和坐标中的规模、扰动具有独特性和鲁棒性。<br/>他们将训练数据集的 PHP 与使用 CNN 提取的特征结合起来使用，然后对它们分别使用<a class="ae ln" rel="noopener" target="_blank" href="/random-forest-and-its-implementation-71824ced454f"><em class="no"/></a>随机森林回归，随后使用多阶段集成策略进行最终分类。这种混合方法被证明是既准确又高效的 wrt 推理速度。<br/>在<strong class="kt jd"> <em class="no">全局水平分类</em> </strong>中，大部分已发表的工作都集中在一种基于面片的分类方法上，用于全切片水平的疾病预测任务。它可以包括小块水平的定位以及整个载玻片水平的疾病分类或分级。这些方法的主要缺点是在整个 WSI 上进行密集的逐块预测需要相对较长的计算时间。不同的作品以不同的方式处理这个问题，一些使用<em class="no">启发式采样策略</em>到最近的使用基于任务驱动<a class="ae ln" href="https://medium.com/@sunnerli/visual-attention-in-deep-learning-77653f611855" rel="noopener"> <em class="no">视觉注意</em> </a>的粗处理。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi np"><img src="../Images/6f09804e41ff4a4e03a618a279579807.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7pRpUNdvW88W-3aBQ3rZHA.jpeg"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">图:基于视觉注意力的观察、调查和分类模型的流程。来源:<a class="ae ln" href="https://arxiv.org/abs/1902.10946" rel="noopener ugc nofollow" target="_blank"> <strong class="bd me">徐等(2019) </strong> </a></p></figure><p id="3a90" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><a class="ae ln" href="https://arxiv.org/abs/1902.10946" rel="noopener ugc nofollow" target="_blank"> <strong class="kt jd">【徐】</strong></a><strong class="kt jd"><em class="no"/></strong>在他们的工作中，通过<em class="no">硬视觉注意算法</em>自适应地从原始图像中选择一系列粗糙区域，然后对于每个这样的区域，能够基于<em class="no">软注意</em>机制<em class="no">来调查异常部分。</em>然后，在顶部构建一个<em class="no">递归网络</em>以对图像区域进行分类，并且还预测在下一时间步要研究的图像区域的位置。这样，分类只需要调查一小部分像素</p><p id="31ad" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">将基于视觉注意力的模型用于整个幻灯片图像全局分类任务的优点是:</p><ul class=""><li id="1865" class="nq nr it kt b ku kv kx ky la ns le nt li nu lm nv nw nx ny bi translated">该模型试图只学习对疾病预测最相关的诊断有用的区域，因为它实施了区域选择机制。</li><li id="0c3c" class="nq nr it kt b ku nz kx oa la ob le oc li od lm nv nw nx ny bi translated">模型的复杂度与 WSI 的大小无关。</li></ul><p id="1743" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">由<a class="ae ln" href="https://www.nature.com/articles/s41598-019-50313-x" rel="noopener ugc nofollow" target="_blank"> <strong class="kt jd"> <em class="no">哈利切克、马丁等人</em> </strong> </a>进行的另一项全球分类的近期工作使用 CNN 使用完全不同的方法对<em class="no">鳞状细胞癌【SCC】</em>和<em class="no">甲状腺细胞癌</em>进行基于补丁的定位和全切片分类。<br/>从每个概述的组织学载玻片产生癌症区域的地面实况二元掩模。使用<a class="ae ln" href="https://www.giassa.net/?page_id=207#:~:text=Nearest%20neighbour%20interpolation%20is%20the,the%20intensity%20value%20of%20it." rel="noopener ugc nofollow" target="_blank"> <em class="no">最近邻插值</em> </a>将 WSIs 和相应的地面实况向下采样四倍。然后将降采样后的载玻片分成大小为<strong class="kt jd"> 101 x 101 </strong>的小块。为了确保通用性，通过应用 90 度旋转和反射，图像补片的数量增加了<strong class="kt jd"> 8x </strong>，以开发一种更强大的诊断方法。此外，为了建立颜色特征不变性和对载玻片之间的<a class="ae ln" href="https://en.wikipedia.org/wiki/H%26E_stain#:~:text=The%20H%26E%20staining%20method%20involves,bluing%20in%20mildly%20alkaline%20water." rel="noopener ugc nofollow" target="_blank"> <em class="no"> H &amp; E 染色</em> </a>的差异的容忍度的水平，在馈送到用于检测头颈癌的<a class="ae ln" rel="noopener" target="_blank" href="/review-inception-v4-evolved-from-googlenet-merged-with-resnet-idea-image-classification-5e8c339d18bc"> <em class="no"> Inception-v4 </em> </a>模型之前，随机操纵每个块的色调、饱和度、亮度和对比度，以形成更严格的训练范例。</p><h2 id="300a" class="nd mh it bd mi ne nf dn mm ng nh dp mq la ni nj ms le nk nl mu li nm nn mw iz bi translated">监督回归</h2><p id="a5a9" class="pw-post-body-paragraph kr ks it kt b ku my kd kw kx mz kg kz la na lc ld le nb lg lh li nc lk ll lm im bi translated">在这种方法中，我们集中于直接回归像素作为对象中心的可能性，以检测或定位对象。与分类不同，回归给我们一个连续的值，通常是概率分数，而不是简单的作为输出的类别标签。回归有助于通过加强拓扑约束进行更好的检测，例如为靠近对象中心的像素分配更高的概率值。<br/>回归也有助于应对细胞/细胞核检测中面临的挑战，这些挑战是由于高度不规则的外观以及它们作为重叠的团块出现而导致分离它们的问题而引起的。文献中提出的深度回归模型主要基于 CNN 或<a class="ae ln" href="https://arxiv.org/abs/1411.4038" rel="noopener ugc nofollow" target="_blank"> <em class="no">全卷积网络(FCN) </em> </a>架构。</p><p id="e73d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">由<a class="ae ln" href="https://arxiv.org/abs/1812.06499" rel="noopener ugc nofollow" target="_blank"> <strong class="kt jd"> <em class="no">格雷厄姆等人</em> </strong> </a>在<em class="no"> HoVer-Net </em>上发表的论文是整个研究领域中最具开创性的作品之一。它提出了一个统一的 FCN 模型，同时核实例分割和分类。它利用核像素到其质心的垂直和水平距离内编码的丰富实例信息。然后利用这些距离来分离成簇的细胞核，从而产生精确的分割，特别是在具有重叠实例的区域中。<br/>然后，对于每个分割的实例，网络通过专用的上采样分支预测细胞核的类型。该网络由用于三种不同任务的三个平行分支组成。对于三个分支中的每一个，我们都有相应的数据基础事实注释。</p><ul class=""><li id="1183" class="nq nr it kt b ku kv kx ky la ns le nt li nu lm nv nw nx ny bi translated"><em class="no">细胞核像素(NP) </em>分支预测像素是否属于细胞核或背景，</li><li id="61ec" class="nq nr it kt b ku nz kx oa la ob le oc li od lm nv nw nx ny bi translated">而<em class="no">水平-垂直(悬停)</em>分支预测核像素到其质心的水平和垂直距离。这里，颜色表示每个核像素到质心的距离的等级。</li><li id="8b8c" class="nq nr it kt b ku nz kx oa la ob le oc li od lm nv nw nx ny bi translated">蓝色代表最大+1 的正距离，表示像素在水平贴图的情况下位于 COM 的左侧，在垂直贴图的情况下位于 COM 的上方。类似地，红色表示负距离，最大为-1，意味着像素相应地位于 COM 的右侧/底部。</li><li id="dc01" class="nq nr it kt b ku nz kx oa la ob le oc li od lm nv nw nx ny bi translated">然后，<em class="no">细胞核分类(NC) </em>分支(可选)预测每个像素的细胞核类型。</li></ul><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi oe"><img src="../Images/35e4facb910f93bb1dba7b6ddc1f491b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IB_vLsXFJBJby1He3dztLQ.jpeg"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">图:由一个编码器和三个并行解码器组成的 HoVernet 架构 FCN 网络。来源:<a class="ae ln" href="https://arxiv.org/abs/1812.06499" rel="noopener ugc nofollow" target="_blank"> <strong class="bd me"> <em class="mf">格雷厄姆等人</em> </strong> </a></p></figure><p id="1c31" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">具体来说，<em class="no"> NP </em>和<em class="no"> HoVer </em>分支通过先从背景中分离出细胞核像素(NP 分支)，再分离出接触细胞核(<em class="no"> HoVer 分支</em>)共同实现细胞核实例分割。这是用于组织的定位和聚类步骤的相同模型，用于将整个载玻片图像建模为图形，以便使用<a class="ae ln" href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w16/Lu_Capturing_Cellular_Topology_in_Multi-Gigapixel_Pathology_Images_CVPRW_2020_paper.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="no">图形神经网络</em> </a>进行后续学习，如前一篇文章中所述。</p><p id="b9d7" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在我们关于组织病理学深度学习讨论的下一个也是最后一个部分，我们将讨论数字组织病理学背景下的监督分割、弱监督和非监督学习方法，以及适当的应用和相关文献。</p><p id="b330" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">PS:我已经将技术上重要的术语链接到解释它们的相应资源。</p></div><div class="ab cl of og hx oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="im in io ip iq"><h1 id="a126" class="mg mh it bd mi mj om ml mm mn on mp mq ki oo kj ms kl op km mu ko oq kp mw mx bi translated">参考</h1><ol class=""><li id="cda3" class="nq nr it kt b ku my kx mz la or le os li ot lm ou nw nx ny bi translated">Qaiser，Tsang，Y.W .，Taniyama，d .，Sakamoto，n .，Nakane，k .，Epstein，d .，Rajpoot，n .，2019b .利用持续同源性和深度卷积特征快速准确地分割组织学图像中的肿瘤。医学图像分析 55，1–14。</li><li id="4a45" class="nq nr it kt b ku nz kx oa la ob le oc li od lm ou nw nx ny bi translated">徐，b，刘，j，侯，x，刘，b，加里波第，j，埃利斯，国际组织，格林，a，沈，l，邱，g，2019。看，调查，分类:乳腺癌分类的深度混合注意方法，载于:2019 IEEE 第 16 届国际生物医学成像研讨会(ISBI 2019)，第 914–918 页。</li><li id="cf2f" class="nq nr it kt b ku nz kx oa la ob le oc li od lm ou nw nx ny bi translated">使用卷积神经网络进行数字化全切片组织学中的头颈癌检测。<em class="no">科学报告</em>9.1(2019):1–11。</li><li id="a02f" class="nq nr it kt b ku nz kx oa la ob le oc li od lm ou nw nx ny bi translated">Graham，s .，Vu，Q.D .，Raza，S.E.A .，Azam，a .，Tsang，Y.W .，Kwak，J.T .，Rajpoot，n . 2019 b .Hover-net:多组织组织学图像中细胞核的同时分割和分类。医学图像分析 58，101563。</li><li id="44d9" class="nq nr it kt b ku nz kx oa la ob le oc li od lm ou nw nx ny bi translated">斯里尼迪，切坦 l，奥赞西加和安妮 l 马特尔。"用于计算组织病理学的深度神经网络模型:综述."<em class="no"> arXiv 预印本 arXiv:1912.12378 </em> (2019)。</li></ol></div></div>    
</body>
</html>