<html>
<head>
<title>How to solve randomness in an artificial neural network?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何解决人工神经网络中的随机性？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-solve-randomness-in-an-artificial-neural-network-3befc4f27d45?source=collection_archive---------20-----------------------#2020-01-31">https://towardsdatascience.com/how-to-solve-randomness-in-an-artificial-neural-network-3befc4f27d45?source=collection_archive---------20-----------------------#2020-01-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="235b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解一个人工神经网络随机性的原因以及如何修复。</h2></div><p id="d5d4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这篇短文中，我们将了解</p><ul class=""><li id="ce4f" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">人工神经网络<em class="ln">的随机性是什么？</em></li><li id="1fbb" class="le lf it kk b kl lo ko lp kr lq kv lr kz ls ld lj lk ll lm bi translated">为什么我们在ANN中会有随机性？</li><li id="802e" class="le lf it kk b kl lo ko lp kr lq kv lr kz ls ld lj lk ll lm bi translated">如何修复随机性，让一个神经网络稳定？</li><li id="d2a6" class="le lf it kk b kl lo ko lp kr lq kv lr kz ls ld lj lk ll lm bi translated">keras中的简单代码实现，用于从人工神经网络获得一致的结果</li></ul><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi lt"><img src="../Images/ca30d74be6092eaff8679da79a494919.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZxTNzS5FNVFUvw4dRfKW_g.png"/></div></div></figure><p id="ac39" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="ln">人工神经网络(ANN)的随机性是什么？</em> </strong></p><p id="2d9d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">人工神经网络(ANN)的随机性是指当相同的神经网络对相同的数据进行训练时，它会产生不同的结果。</strong></p><p id="1617" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有时，我们可能已经随机选择了训练数据和测试数据，如果我们从训练数据和测试数据中去除随机性，即使使用相同的神经网络，每次执行我们仍然可能得到不同的结果。</p><p id="23ea" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">结果的这种随机性使得神经网络不稳定和不可靠，尤其是在与他人共享您的代码或展示您的工作时。</p><p id="6e5e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="ln">人工神经网络为什么会有随机性？</em>T11】</strong></p><p id="e6cc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">人工神经网络中的随机性可能由于多种原因而发生</p><ol class=""><li id="6ecd" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld mf lk ll lm bi translated">权重和偏差的随机初始化</li><li id="f3b3" class="le lf it kk b kl lo ko lp kr lq kv lr kz ls ld mf lk ll lm bi translated">像辍学这样的正规化技术中的随机性</li><li id="dd9b" class="le lf it kk b kl lo ko lp kr lq kv lr kz ls ld mf lk ll lm bi translated">随机梯度下降(SGD)等优化技术中的随机性</li></ol><p id="66d2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="ln">我们如何修复一个ANN的随机性？</em>T15】</strong></p><p id="2a30" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们使随机性更可预测，我们就能获得一致的结果。</p><p id="6846" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了使随机性可预测，我们使用了<strong class="kk iu"> <em class="ln">种子的概念。</em>T19】</strong></p><blockquote class="mg"><p id="f395" class="mh mi it bd mj mk ml mm mn mo mp ld dk translated">Seed有助于每次获得可预测、可重复的结果</p></blockquote><p id="f537" class="pw-post-body-paragraph ki kj it kk b kl mq ju kn ko mr jx kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">如果我们不设置种子，那么我们在每次调用时都会得到不同的随机数</p><p id="3679" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">将种子设置为某个值，比如0或123，将在同一台机器或不同机器上多次执行代码时生成相同的随机数。</p><p id="d582" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了解决我们使用的人工神经网络的随机性</p><ul class=""><li id="6683" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated"><strong class="kk iu"> numpy随机种子</strong></li><li id="7290" class="le lf it kk b kl lo ko lp kr lq kv lr kz ls ld lj lk ll lm bi translated"><strong class="kk iu">张量流集合_随机_种子</strong></li></ul><p id="9099" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们在不设置随机种子的情况下构建一个简单的ANN，接下来，我们将设置随机种子。我们将在ketas中实现代码</p><p id="db5b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我使用了Kaggle的<a class="ae mv" href="https://www.kaggle.com/apratim87/housingdata/data" rel="noopener ugc nofollow" target="_blank">房屋数据集</a></p><h2 id="565f" class="mw mx it bd my mz na dn nb nc nd dp ne kr nf ng nh kv ni nj nk kz nl nm nn no bi translated">证明人工神经网络的随机性</h2><pre class="lu lv lw lx gt np nq nr ns aw nt bi"><span id="b95d" class="mw mx it nq b gy nu nv l nw nx">#Importing required libraries<br/>import numpy as np<br/>import pandas as pd<br/>from keras import Sequential<br/>from keras.layers import Dense</span><span id="9f52" class="mw mx it nq b gy ny nv l nw nx"># Reading the data<br/>dataset = pd.read_csv('housingdata.csv')<br/>dataset.head(2)</span><span id="552f" class="mw mx it nq b gy ny nv l nw nx"># Creating independent and dependent variable<br/>X=dataset.iloc[:,0:13]<br/>y=dataset.iloc[:,13].values</span><span id="673d" class="mw mx it nq b gy ny nv l nw nx"># creating train and test data<br/>from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test =X[:400], X[400:], y[:400], y[400:]</span><span id="0765" class="mw mx it nq b gy ny nv l nw nx"># Building a simple ANN for regression<br/><strong class="nq iu">def build_regressor():</strong><br/>    regressor = Sequential()<br/>    regressor.add(Dense(units=13, input_dim=13))<br/>    regressor.add(Dense(units=1))<br/>    regressor.compile(optimizer='adam', loss='mean_squared_error',  metrics=['mae','accuracy'])<br/>    return regressor</span><span id="27fa" class="mw mx it nq b gy ny nv l nw nx"># creating the kears Regressor with 100 epochs<br/>from keras.wrappers.scikit_learn import KerasRegressor<br/>regressor = KerasRegressor(build_fn=build_regressor, batch_size=32,epochs=100)</span><span id="008d" class="mw mx it nq b gy ny nv l nw nx"># Fitting the training data<br/>results=regressor.fit(X_train,y_train)</span><span id="2426" class="mw mx it nq b gy ny nv l nw nx"># Making prediction the test data<br/>y_pred= regressor.predict(X_test)</span><span id="0834" class="mw mx it nq b gy ny nv l nw nx"># printing the first 5 predictions for comparison<br/>y_pred= regressor.predict(X_test)<br/>y_pred[:5]</span></pre><p id="031b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">程序第一次运行的输出</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi nz"><img src="../Images/b5547d438141ae3c87f2e44db68d217c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wk_lTNDDhctZ5gOzLIgOZg.png"/></div></div></figure><p id="7e6a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第二次运行的输出</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi oa"><img src="../Images/f57b270eb0a2f9e57303d36a27778d10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JtHfo6M0-rHFacrpzdXDYQ.png"/></div></div></figure><p id="ff35" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您将在每次执行时得到不同的输出</p><h2 id="6c9d" class="mw mx it bd my mz na dn nb nc nd dp ne kr nf ng nh kv ni nj nk kz nl nm nn no bi translated">修复我们人工神经网络的随机性</h2><p id="77a6" class="pw-post-body-paragraph ki kj it kk b kl ob ju kn ko oc jx kq kr od kt ku kv oe kx ky kz of lb lc ld im bi translated">我们将导入另外两个库并设置种子</p><pre class="lu lv lw lx gt np nq nr ns aw nt bi"><span id="65af" class="mw mx it nq b gy nu nv l nw nx"><strong class="nq iu">from numpy.random import seed<br/>from tensorflow import set_random_seed</strong></span></pre><p id="5b48" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">设置numpy种子和tensorflow种子</p><pre class="lu lv lw lx gt np nq nr ns aw nt bi"><span id="0530" class="mw mx it nq b gy nu nv l nw nx"><strong class="nq iu">seed(0)<br/>set_random_seed(0)</strong></span></pre><p id="33e9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">最终代码</strong></p><pre class="lu lv lw lx gt np nq nr ns aw nt bi"><span id="fee3" class="mw mx it nq b gy nu nv l nw nx">#Importing required libraries<br/>import numpy as np<br/>import pandas as pd<br/><strong class="nq iu">from numpy.random import seed<br/>from tensorflow import set_random_seed</strong><br/>from keras import Sequential<br/>from keras.layers import Dense</span><span id="68fc" class="mw mx it nq b gy ny nv l nw nx"><strong class="nq iu"># settingt he seed<br/>seed(0)<br/>set_random_seed(0)</strong></span><span id="febb" class="mw mx it nq b gy ny nv l nw nx"># Reading the data<br/>dataset = pd.read_csv('housingdata.csv')<br/>dataset.head(2)</span><span id="d671" class="mw mx it nq b gy ny nv l nw nx"># Creating independent and dependent variable<br/>X=dataset.iloc[:,0:13]<br/>y=dataset.iloc[:,13].values</span><span id="8122" class="mw mx it nq b gy ny nv l nw nx"># creating train and test data<br/>from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test =X[:400], X[400:], y[:400], y[400:]</span><span id="cef6" class="mw mx it nq b gy ny nv l nw nx"># Building a simple ANN for regression<br/><strong class="nq iu">def build_regressor():</strong><br/>    regressor = Sequential()<br/>    regressor.add(Dense(units=13, input_dim=13))<br/>    regressor.add(Dense(units=1))<br/>    regressor.compile(optimizer='adam', loss='mean_squared_error',  metrics=['mae','accuracy'])<br/>    return regressor</span><span id="b610" class="mw mx it nq b gy ny nv l nw nx"># creating the kears Regressor with 100 epochs<br/>from keras.wrappers.scikit_learn import KerasRegressor<br/>regressor = KerasRegressor(build_fn=build_regressor, batch_size=32,epochs=100)</span><span id="cc93" class="mw mx it nq b gy ny nv l nw nx"># Fitting the training data<br/>results=regressor.fit(X_train,y_train)</span><span id="7480" class="mw mx it nq b gy ny nv l nw nx"># Making prediction the test data<br/>y_pred= regressor.predict(X_test)</span><span id="4c41" class="mw mx it nq b gy ny nv l nw nx"># printing the first 5 predictions for comparison<br/>y_pred= regressor.predict(X_test)<br/>y_pred[:5]</span></pre><p id="0eb8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首次运行和任何运行时的输出</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi og"><img src="../Images/0ce7c68e39cf98189876dbb92b1a8d4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*13w99CXxTyQm2QP_zEd9zA.png"/></div></div></figure><h2 id="9260" class="mw mx it bd my mz na dn nb nc nd dp ne kr nf ng nh kv ni nj nk kz nl nm nn no bi translated">结论:</h2><p id="8975" class="pw-post-body-paragraph ki kj it kk b kl ob ju kn ko oc jx kq kr od kt ku kv oe kx ky kz of lb lc ld im bi translated">由于权重的随机初始化、偏差、使用漏失和不同的优化技术，人工神经网络本质上是不确定的。我们可以为numpy和TensorFlow设置种子，以便在同一台计算机或不同的计算机上使用相同的数据集获得一致的结果。</p></div></div>    
</body>
</html>