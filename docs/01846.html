<html>
<head>
<title>Four ways teams win on Kaggle</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">团队在Kaggle上获胜的四种方式</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/four-ways-teams-win-on-kaggle-50e62acb87f4?source=collection_archive---------23-----------------------#2020-02-20">https://towardsdatascience.com/four-ways-teams-win-on-kaggle-50e62acb87f4?source=collection_archive---------23-----------------------#2020-02-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="791f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">框架、多重处理、云以及更大的团队</h2></div><p id="cb80" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Kaggle是最好和最差的机器学习的家园。这是成千上万个团队的战场，他们争相建立最佳模型，在最后期限内解决现实世界的问题，赌注是几十万美元。在大型数据集上训练这些世界级的模型通常需要数百个计算小时。在本帖中，我们将探索获胜团队使用的一些技巧以及如何加快速度。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/9bada25f41afba6853335933e9209f8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jbvK3hHwKZRTA3fS"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">[图片<a class="ae lu" href="https://pixabay.com/illustrations/superhero-girl-speed-runner-534120/" rel="noopener ugc nofollow" target="_blank">来源】</a></p></figure><h1 id="a4c1" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">#1 —使用顶层框架</h1><p id="9414" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">有时Kaggle上的竞争会导致模型无法复制或者<a class="ae lu" rel="noopener" target="_blank" href="/kaggle-1st-place-winner-cheated-10-000-prize-declared-irrecoverable-bb7e1b639365">彻头彻尾的欺诈</a>。但其中一些竞争为整个行业设立了新的标准。Kaggle是机器学习成为焦点并取得巨大进展的地方。世界上最好的模型构建框架受到Kaggle竞赛的启发并围绕其构建。</p><p id="fe9e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">获胜——团队从他们的工具中榨出每一分每一毫的绩效。当工具不够好或不够快时——更好的工具就会被制造出来。这方面的例子有流行的梯度增强库:</p><ul class=""><li id="03f7" class="ms mt it kk b kl km ko kp kr mu kv mv kz mw ld mx my mz na bi translated">2014—XGBoost—<a class="ae lu" href="https://github.com/dmlc/xgboost" rel="noopener ugc nofollow" target="_blank">【github】</a>【论文】—2015年Kaggle比赛期间，29个获奖方案<a class="ae lu" href="https://www.linkedin.com/pulse/present-future-kdd-cup-competition-outsiders-ron-bekkerman/" rel="noopener ugc nofollow" target="_blank">中有17个方案使用了XGBoost </a>。</li><li id="dacf" class="ms mt it kk b kl nb ko nc kr nd kv ne kz nf ld mx my mz na bi translated">2017—light GBM(LGBM)—<a class="ae lu" href="https://github.com/microsoft/LightGBM" rel="noopener ugc nofollow" target="_blank">【github】</a><a class="ae lu" href="https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf" rel="noopener ugc nofollow" target="_blank">【paper】</a>—由微软开发，比XGBoost快20倍，但并不总是那么准确。这个库是2019年Kaggle 上流行内核的<a class="ae lu" href="https://www.kaggle.com/c/ga-customer-revenue-prediction/discussion/66048" rel="noopener ugc nofollow" target="_blank">默认选择。</a></li><li id="fa21" class="ms mt it kk b kl nb ko nc kr nd kv ne kz nf ld mx my mz na bi translated">2017—CatBoost—<a class="ae lu" href="https://github.com/catboost/catboost" rel="noopener ugc nofollow" target="_blank">【github】</a><a class="ae lu" href="https://arxiv.org/abs/1706.09516" rel="noopener ugc nofollow" target="_blank">【论文】</a> —没有LightGBM常用，但在利用分类列的<a class="ae lu" href="https://datascience.stackexchange.com/questions/49567/lightgbm-vs-xgboost-vs-catboost" rel="noopener ugc nofollow" target="_blank">中可以有优势。</a></li></ul><p id="8732" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">竞赛获胜者经常结合多个模型构建库来稍微提高性能。关于这些梯度增强框架的深入比较，请参见本文。许多竞赛获胜者也使用Keras库，尽管它最初的设计并没有考虑到Kaggles。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ng"><img src="../Images/fde200f37cce1a644bb5f157045ccf3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Yvn_FSIzaL-7P9a8"/></div></div></figure><p id="8643" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上面的图片来自Keras图书馆的作者Franç ois Chollet的一条推文。在这条线索中，他指出:</p><p id="f968" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="nh">赢家是那些经历了“进步循环”的“更多迭代”的人——从一个想法，到它的实施，再到可操作的结果。所以获胜的团队就是那些能够跑得更快的团队。</em></p><h1 id="da18" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">#2 —利用多重处理</h1><p id="84f6" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">为了获胜，Kaggle团队需要在有限的时间内测试尽可能多的想法。对于千兆字节的数据，每次迭代都以小时为单位。有许多参数可以调整，使训练过程更短。但是，为了优化排行榜分数，训练必须“进行到11”。考虑到需要许多小时的计算，自然的优化是并行化。</p><p id="8bda" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在Python中，由于全局解释器锁(GIL)，使用线程来并行化工作通常是没有意义的。Kaggle上流行的框架都在内部进行了多线程优化，以利用多个内核将训练时间减少10倍。他们还可以利用GPU将训练速度提高<a class="ae lu" href="https://xgboost.ai/2018/07/04/gpu-xgboost-update.html" rel="noopener ugc nofollow" target="_blank">10倍</a>。但是，测试许多超参数和特征组合意味着进一步增加工作量。仅仅是加载数据就可能非常耗时，以至于一些团队使用<a class="ae lu" href="https://www.kaggle.com/nroman/lgb-single-model-lb-0-9419" rel="noopener ugc nofollow" target="_blank">多重处理来应对这种情况</a>,如下所示:</p><pre class="lf lg lh li gt ni nj nk nl aw nm bi"><span id="f3a4" class="nn lw it nj b gy no np l nq nr">files = ['../input/test_identity.csv', <br/>         '../input/test_transaction.csv',<br/>         '../input/train_identity.csv',<br/>         '../input/train_transaction.csv',<br/>         '../input/sample_submission.csv']</span><span id="ca49" class="nn lw it nj b gy ns np l nq nr">def load_data(file):<br/>    return pd.read_csv(file)</span><span id="1ff2" class="nn lw it nj b gy ns np l nq nr">with multiprocessing.Pool() as pool:<br/>    test_id, test_tr, train_id, train_tr, sub = pool.map(load_data, files)</span></pre><p id="3f39" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">多重处理本身可以在强大的机器上本地工作。不幸的是，我的MacBook有点温顺。最重要的是，繁重的任务完全消耗了我的机器资源。后台任务繁重，即使阅读电子邮件也变得缓慢而痛苦。</p><h1 id="bdc6" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">#3 —云上的多重多处理</h1><p id="db10" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">启动一台机器来运行一个可能需要一个多小时才能返回的函数可能是值得的。让机器运转几个小时来实现多种功能尤其有用。有很多方法可以获得一台机器来完成工作，比如使用AWS Fargate、Google Cloud Run和其他提供商。在<a class="ae lu" href="https://xgboost.readthedocs.io/en/latest/tutorials/index.html" rel="noopener ugc nofollow" target="_blank"> XGBoost分布式培训教程</a>中有一些这样的例子。</p><p id="597b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用云时要考虑的权衡是速度、成本和设置一切的复杂程度。下面的代码片段使用了<a class="ae lu" href="https://docs.dis.co/quick-start-guide/discomp" rel="noopener ugc nofollow" target="_blank">dismap</a>，它提供了对<code class="fe nt nu nv nj b">multiprocessing.Pool()</code>的替换，所以它非常简单。map中的每次迭代可能会发现自己在不同的机器上，而我们的主机只会等待结果。</p><pre class="lf lg lh li gt ni nj nk nl aw nm bi"><span id="bb8e" class="nn lw it nj b gy no np l nq nr">def pow3(x):<br/>    print (x**3)<br/>    return (x**3)<br/>    <br/>with discomp.Pool() as po:<br/>    results = po.map(pow3, range(10))<br/>    print(results)<br/>    # prints [0, 1, 8, 27, 64, 125, 216, 343, 512, 729]</span></pre><p id="e70f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然这个例子很简单，但是您可以推断出可以做什么。对于更完整的场景，您可以看到我如何使用XGBoost在信用卡欺诈数据集中比较不同超参数配置的性能。使用传统的<code class="fe nt nu nv nj b">map</code>呼叫测试30组参数需要82分钟，使用<code class="fe nt nu nv nj b">multiprocessing.Pool().map</code>需要35分钟，使用<code class="fe nt nu nv nj b">discomp.Pool().map</code>需要9分钟。使用云机器，我可以以9倍的速度运行测试。使用云确实要花钱，所以它并不是适合所有人的解决方案。有点像这艘船。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/a3b9a52fc7e233beaefacfd6ed93fbd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*eURm2udHgHJa1zhB"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">[图片<a class="ae lu" href="https://pixabay.com/photos/powerboat-speed-speedboat-fast-2784250/" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><h1 id="80cf" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">#4 —更大的团队</h1><p id="cb8b" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">通常较大的团队在Kaggle上有优势，因为每个团队成员都用不同的参数和库探索不同的特性和不同的模型。团队中的每个人也将贡献自己的计算资源。最后，所有的模型将被组合成一个<a class="ae lu" href="https://en.wikipedia.org/wiki/Ensemble_averaging_(machine_learning)" rel="noopener ugc nofollow" target="_blank">集合平均值</a>，它往往比每个单独的模型表现得更好。要更深入地分析团队规模趋势，<a class="ae lu" href="https://www.kaggle.com/gpreda/meta-kaggle-what-happened-to-the-team-size" rel="noopener ugc nofollow" target="_blank">请查看本笔记本</a>。</p><h1 id="0c9f" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">优化时间</h1><p id="f7d7" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">在Kaggle中，给你的是带标签的数据，所以机器学习中的一个大问题已经解决了。所有竞争者剩下要做的就是预处理，选择正确的模型，使用最好的软件包，设计最好的特性和确定最好的参数。这仍然是一项很少有人擅长的艰巨任务。一个团队可以测试的组合数量直接受限于他们周期的持续时间以及他们可以在多少台机器上运行它们。幸运的是，现在有许多选择可以节省时间并获得计算资源。请告诉我你是否觉得这些技巧有用，或者只是在twitter上打个招呼。</p></div></div>    
</body>
</html>