<html>
<head>
<title>Building an Automated Machine Learning Pipeline: Part Two</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建自动化机器学习管道:第二部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-an-automated-machine-learning-pipeline-part-two-1d3c86e6fe42?source=collection_archive---------43-----------------------#2020-05-22">https://towardsdatascience.com/building-an-automated-machine-learning-pipeline-part-two-1d3c86e6fe42?source=collection_archive---------43-----------------------#2020-05-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="05a2" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" rel="noopener" target="_blank" href="https://towardsdatascience.com/machine-learning/home">机器学习</a></h2><div class=""/><div class=""><h2 id="6d29" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">设置评估指标&amp;建立基线、选择算法和执行超参数调整步骤</h2></div><ul class=""><li id="5d31" class="kr ks it kt b ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/building-an-automated-machine-learning-pipeline-part-one-5c70ae682f35?source=friends_link&amp;sk=8de05327eedb3d0dadcfa4b1a8e8cc75">第 1 部分:理解、清理、探索、处理数据</a></li><li id="5448" class="kr ks it kt b ku lk kw ll ky lm la ln lc lo le lf lg lh li bi translated">第 2 部分:设置度量和基线，选择和调整模型(您现在正在阅读)</li><li id="fa49" class="kr ks it kt b ku lk kw ll ky lm la ln lc lo le lf lg lh li bi translated"><a class="ae lj" href="https://medium.com/p/building-an-automated-machine-learning-pipeline-a74acda76b98?source=email-287e9909d3b5--writer.postDistributed&amp;sk=1790d8dd404126a45828c3905f47432c" rel="noopener">第三部分:培训、评估和解释模型</a>(现场！)</li><li id="2032" class="kr ks it kt b ku lk kw ll ky lm la ln lc lo le lf lg lh li bi translated">第 4 部分:使用 Docker 和 Luigi 自动化您的管道。)</li></ul><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi lp"><img src="../Images/f3e99a09f7605ac73997a389e26755bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*g1xLxEuCxDMJ6W0C"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">照片由<a class="ae lj" href="https://unsplash.com/@zachhagy?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Zachariah Hagy </a>在<a class="ae lj" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="abc3" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">在这一系列文章中，我们将我们的课程设置为构建一个 9 步机器学习(ML)管道(我们称之为葡萄酒评级预测器)并将其自动化。最后，我们将观察每个步骤在生产系统中是如何聚集和运行的。</p><p id="3193" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">我们正在研究一个监督回归问题。我们希望开发一个高性能的，可理解的，好的葡萄酒评级预测器，它可以预测<em class="ms">点</em>，一个葡萄酒质量的衡量标准。</p><p id="2d3f" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">在第一篇文章中，我们定义了构建葡萄酒评级预测器背后的问题和动机。然后，我们通过可视化特征和目标之间的关系以及<strong class="kt jd"> <em class="ms">理解&amp;清理&amp;格式数据</em></strong><strong class="kt jd"><em class="ms">探索性数据分析</em> </strong>步骤来详细查看数据。</p><p id="f7a6" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">在<strong class="kt jd"> <em class="ms">特征工程&amp;预处理</em> </strong>步骤中，我们添加了新的更有用的特征。此外，我们准备了在模型的训练和评估期间使用的训练和测试数据集。作为第一篇文章的最后一步，我们从用于模型选择的训练数据集创建了验证数据集。</p><p id="bbba" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">在本文中，我们将完成以下步骤:</p><p id="0c19" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">4.设置评估指标并建立基线</p><p id="4c80" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">5.基于评估度量选择 ML 模型</p><p id="05e2" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">6.对所选模型执行超参数调整</p><p id="dc82" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">这篇文章背后的代码可以在这个笔记本里找到<a class="ae lj" href="https://github.com/cereniyim/Wine-Rating-Predictor-ML-Model/blob/master/notebooks/WineRatingPredictor-2.ipynb" rel="noopener ugc nofollow" target="_blank">。GitHub 上提供了完整的项目:</a></p><div class="mt mu gp gr mv mw"><a href="https://github.com/cereniyim/Wine-Rating-Predictor-ML-Model" rel="noopener  ugc nofollow" target="_blank"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd jd gy z fp nb fr fs nc fu fw jc bi translated">cereniyim/葡萄酒评级预测模型</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">在这个项目中，我为一个在线葡萄酒卖家构建了一个葡萄酒评级预测器。这款葡萄酒预测器旨在显示良好的…</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">github.com</p></div></div><div class="nf l"><div class="ng l nh ni nj nf nk lz mw"/></div></div></a></div><p id="90bf" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">请随意分享，分叉，并利用这个回购为您的项目！</p></div><div class="ab cl nl nm hx nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="im in io ip iq"><h1 id="4034" class="ns nt it bd nu nv nw nx ny nz oa ob oc ki od kj oe kl of km og ko oh kp oi oj bi translated">在我们开始之前:</h1><p id="31f5" class="pw-post-body-paragraph mf mg it kt b ku ok kd mh kw ol kg mi ky om mk ml la on mn mo lc oo mq mr le im bi translated">我们将要使用的数据集在<code class="fe op oq or os b"><a class="ae lj" href="https://github.com/cereniyim/Wine-Rating-Predictor-ML-Model/tree/master/notebooks/transformed" rel="noopener ugc nofollow" target="_blank">notebooks/transformed</a></code>中提供</p><ul class=""><li id="91d6" class="kr ks it kt b ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated"><code class="fe op oq or os b"><a class="ae lj" href="https://github.com/cereniyim/Wine-Rating-Predictor-ML-Model/blob/master/notebooks/transformed/X_train.csv" rel="noopener ugc nofollow" target="_blank">X_train</a></code>由特色(<em class="ms">国家、省份、地区 _1、</em> <em class="ms">品种、价格、</em> <em class="ms">年份、</em> <em class="ms">品酒师 _ 姓名、<em class="ms">正 _ 红</em>、<em class="ms">正 _ 白</em>、<em class="ms">正 _ 玫瑰</em>、<em class="ms">正 _ 干</em>、<em class="ms">正 _ 甜、正 _ 闪亮、正 _ 混合</em>和<code class="fe op oq or os b"><a class="ae lj" href="https://github.com/cereniyim/Wine-Rating-Predictor-ML-Model/blob/master/notebooks/transformed/y_train.csv" rel="noopener ugc nofollow" target="_blank">y_train</a></code>目标(<em class="ms">组成</em></em></li><li id="6ffd" class="kr ks it kt b ku lk kw ll ky lm la ln lc lo le lf lg lh li bi translated">由特征组成的<code class="fe op oq or os b"><a class="ae lj" href="https://github.com/cereniyim/Wine-Rating-Predictor-ML-Model/blob/master/notebooks/transformed/X_valid.csv" rel="noopener ugc nofollow" target="_blank">X_valid</a></code>和由目标组成的<em class="ms">和</em>来验证模型</li></ul><p id="f0f3" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">在本笔记本中，我们将需要以下 Python 库:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="ba8f" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">让我们将数据集加载到数据帧中，并使用以下函数转换为数组:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="ot ou l"/></div></figure><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="ot ou l"/></div></figure><pre class="lq lr ls lt gt ov os ow ox aw oy bi"><span id="e9ee" class="oz nt it os b gy pa pb l pc pd">X_train = pd.read_csv("transformed/X_train.csv")<br/>X_train_array = convert_features_to_array(X_train)</span><span id="a094" class="oz nt it os b gy pe pb l pc pd">X_valid = pd.read_csv("transformed/X_valid.csv")<br/>X_valid_array = convert_features_to_array(X_valid)</span><span id="ce75" class="oz nt it os b gy pe pb l pc pd">y_train = pd.read_csv("transformed/y_train.csv")<br/>y_train_array = convert_target_to_array(y_train)</span><span id="839b" class="oz nt it os b gy pe pb l pc pd">y_valid = pd.read_csv("transformed/y_valid.csv")<br/>y_valid_array = convert_target_to_array(y_valid)</span></pre><h1 id="4709" class="ns nt it bd nu nv pf nx ny nz pg ob oc ki ph kj oe kl pi km og ko pj kp oi oj bi translated">4.设置评估指标并建立基线</h1><p id="39d7" class="pw-post-body-paragraph mf mg it kt b ku ok kd mh kw ol kg mi ky om mk ml la on mn mo lc oo mq mr le im bi translated">如果这是一场<a class="ae lj" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>竞赛，我们将跳过这一步，因为我们将获得评估指标。</p><p id="56a7" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">然而，在数据科学/机器学习的实际应用中，评估指标是由数据科学家根据利益相关者对 ML 模型的期望来设置的。这就是为什么这是一个重要的步骤。</p><p id="fd08" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">在我们决定评估指标后，为了量化我们的初始动机——建立一个好的葡萄酒评级预测器，并与我们的模型性能进行比较，我们将形成一个基线。</p><h2 id="81fc" class="oz nt it bd nu pk pl dn ny pm pn dp oc ky po pp oe la pq pr og lc ps pt oi iz bi translated">4.1.设置评估指标</h2><p id="70aa" class="pw-post-body-paragraph mf mg it kt b ku ok kd mh kw ol kg mi ky om mk ml la on mn mo lc oo mq mr le im bi translated">将<strong class="kt jd"> <em class="ms">均方误差</em> </strong> <strong class="kt jd"> <em class="ms"> (MSE) </em> </strong>设定为评价指标。它是残差平方和的平均值，其中<strong class="kt jd"> <em class="ms">残差</em> </strong>是目标变量的预测值减去实际值。</p><p id="d41b" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">换句话说，模型的评估是通过查看平方误差(残差)有多大来进行的。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi pu"><img src="../Images/cef01492a7bee32c2a9e189b1dbae9f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*n6zGmU6_uoCBFwlM.jpg"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">图像致谢:对<a class="ae lj" href="https://www.dataquest.io/blog/understanding-regression-error-metrics/" rel="noopener ugc nofollow" target="_blank"> Dataquest.io </a>的均方误差计算</p></figure><p id="9aff" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">我们选择 MSE 是因为它是可解释的，类似于方差，并且是 ML 模型中广泛使用的优化标准。(例如线性回归、随机森林)</p><h2 id="590b" class="oz nt it bd nu pk pl dn ny pm pn dp oc ky po pp oe la pq pr og lc ps pt oi iz bi translated">4.2.建立基线</h2><p id="d67c" class="pw-post-body-paragraph mf mg it kt b ku ok kd mh kw ol kg mi ky om mk ml la on mn mo lc oo mq mr le im bi translated">一个<strong class="kt jd"> <em class="ms">基线</em> </strong>可以解释为利用专家知识或几行代码生成一个对目标值的天真猜测。它还有助于衡量 ML 模型的性能。</p><p id="d1e5" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">如果构建的模型(葡萄酒评级预测器)不能超过这个基线，那么选择的 ML 算法可能不是解决这个问题的最佳方法，或者我们可能想要重新访问管道的先前步骤。</p><p id="f1be" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">回想一下<em class="ms">点</em>(目标)在 80 和 100 之间呈正态分布。平均值为 88.45，方差为 9.1。</p><p id="8fd3" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">我们将通过以下方式形成基线:</p><ul class=""><li id="0869" class="kr ks it kt b ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">使用这些统计数据和</li><li id="05c4" class="kr ks it kt b ku lk kw ll ky lm la ln lc lo le lf lg lh li bi translated">计算验证集中每个点与训练数据集平均值之间的差异，然后取差异平方和的平均值(计算 MSE 的类似方法):</li></ul><pre class="lq lr ls lt gt ov os ow ox aw oy bi"><span id="1d19" class="oz nt it os b gy pa pb l pc pd"><em class="ms"># set baseline as mean of training set's target value</em><br/>baseline = (np<br/>            .mean(<br/>                y_train_array))</span><span id="1f6e" class="oz nt it os b gy pe pb l pc pd"><em class="ms"># calculate MSE baseline</em><br/>mse_baseline = (np<br/>                .mean(<br/>                    np.square(<br/>                        baseline - y_valid_array)))</span></pre><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi pv"><img src="../Images/94565e310d150ea01700d78780ec5b3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gG07QLLNl9KghyjB0z4Bog.png"/></div></div></figure><p id="52f5" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated"><em class="ms">点的方差</em>和基线误差几乎相等，这不是巧合。您可以将这个基线 MSE 视为手动计算的方差，其中包含来自我们数据集的一个较小的集合。</p><p id="835d" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">这个数字(9.01)将伴随我们进入下一步— <strong class="kt jd"> <em class="ms">在我们测试不同的 ML 算法时，根据评估指标</em> </strong>选择一个 ML 模型。</p><h2 id="952c" class="oz nt it bd nu pk pl dn ny pm pn dp oc ky po pp oe la pq pr og lc ps pt oi iz bi translated">5.基于评估度量选择 ML 模型</h2><p id="9de6" class="pw-post-body-paragraph mf mg it kt b ku ok kd mh kw ol kg mi ky om mk ml la on mn mo lc oo mq mr le im bi translated">我总是发现尝试几种背后有不同原理的算法是有用的，因为我相信这整个过程也包括实验！(“科学家”作为数据科学家的一部分现在有意义了🙃)</p><p id="d7b7" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">在搜索最佳算法时，我们将观察算法的 MSE 和运行时间的改进(在单元格的开始使用<code class="fe op oq or os b">%%time</code> magic ),并将算法的 MSE 与我们的基线 MSE 进行比较。同时，我们将牢记葡萄酒评级预测器的可理解性和性能要求。</p><p id="6dd3" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">我们将尝试一种线性算法、两种基于距离的算法和两种基于树的算法，从最简单到最复杂依次为:</p><ul class=""><li id="5482" class="kr ks it kt b ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">线性回归</li><li id="98dc" class="kr ks it kt b ku lk kw ll ky lm la ln lc lo le lf lg lh li bi translated">k-最近邻回归量</li><li id="01d0" class="kr ks it kt b ku lk kw ll ky lm la ln lc lo le lf lg lh li bi translated">支持向量回归机</li><li id="2421" class="kr ks it kt b ku lk kw ll ky lm la ln lc lo le lf lg lh li bi translated">随机森林回归量</li><li id="eecb" class="kr ks it kt b ku lk kw ll ky lm la ln lc lo le lf lg lh li bi translated">光梯度增强回归器</li></ul><p id="4a65" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">我们将用训练集来训练它们，并将它们的泛化性能与验证集进行比较。下面的函数将为我们完成这项工作。</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="3fa8" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">在这一步的最后，我们将详细说明所选择的算法是如何工作的。</p><h2 id="7752" class="oz nt it bd nu pk pl dn ny pm pn dp oc ky po pp oe la pq pr og lc ps pt oi iz bi translated">5.1.线性回归:</h2><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi pw"><img src="../Images/eea16099cc0b5660880aa9974e1059db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cTQlTtClohP_Lrnt2ACpzw.png"/></div></div></figure><p id="2edb" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated"><a class="ae lj" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html" rel="noopener ugc nofollow" target="_blank">线性回归</a>略微降低了基线指标，表明它不是一个好的预测器的候选。</p><h2 id="4c5c" class="oz nt it bd nu pk pl dn ny pm pn dp oc ky po pp oe la pq pr og lc ps pt oi iz bi translated">5.2.k-最近邻回归量</h2><p id="eb93" class="pw-post-body-paragraph mf mg it kt b ku ok kd mh kw ol kg mi ky om mk ml la on mn mo lc oo mq mr le im bi translated">基于距离的模型使用欧几里德距离(或其他距离度量)进行训练，因此变化的范围会导致基于距离的模型生成不准确的预测。为了应用基于距离的算法，我们在笔记本中的<a class="ae lj" href="https://render.githubusercontent.com/view/ipynb?commit=800ae104b19cb48b4e403ee24aa541e723e1972e&amp;enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f636572656e6979696d2f57696e652d526174696e672d507265646963746f722d4d4c2d4d6f64656c2f383030616531303462313963623438623465343033656532346161353431653732336531393732652f6e6f7465626f6f6b732f57696e65526174696e67507265646963746f722d322e6970796e62&amp;nwo=cereniyim%2FWine-Rating-Predictor-ML-Model&amp;path=notebooks%2FWineRatingPredictor-2.ipynb&amp;repository_id=257017095&amp;repository_type=Repository#Normalize-Datasets-for-KNN-and-SVM" rel="noopener ugc nofollow" target="_blank">之前对数据集进行了标准化缩放。</a></p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi pw"><img src="../Images/eea33669c26a4b5ead0a2df8f41c2c65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z1nttphARXIe4PYrQRsycg.png"/></div></div></figure><p id="2c15" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated"><a class="ae lj" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html" rel="noopener ugc nofollow" target="_blank">K-最近邻回归元</a>表现优于线性回归。然而，MSE 仍然很高，表明该算法也不是一个好的预测器。</p><h2 id="cb73" class="oz nt it bd nu pk pl dn ny pm pn dp oc ky po pp oe la pq pr og lc ps pt oi iz bi translated">5.3.支持向量回归机</h2><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi px"><img src="../Images/d3054a96a682748c809793f0ecfccf58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QIwWQAyyR7DnUBIy4EPMig.png"/></div></div></figure><p id="3f92" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated"><a class="ae lj" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html" rel="noopener ugc nofollow" target="_blank">支持向量回归机</a>在较高的运行时间表现优于 k 近邻回归机。总之，MSE 降低了 35%,表明该算法可能是构建良好预测器的候选算法。</p><h2 id="4420" class="oz nt it bd nu pk pl dn ny pm pn dp oc ky po pp oe la pq pr og lc ps pt oi iz bi translated">5.4.随机森林回归量</h2><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi px"><img src="../Images/546506ea0ea95e18b78d2b193a902eb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*huwrk3My_gE5R5z07xgGyg.png"/></div></div></figure><p id="d950" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated"><a class="ae lj" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html" rel="noopener ugc nofollow" target="_blank">随机森林回归器</a>比支持向量回归器在更短的运行时间内表现更好。它降低了 MSE 44%,取代了好预测列表中的支持向量回归机。</p><h2 id="c6f5" class="oz nt it bd nu pk pl dn ny pm pn dp oc ky po pp oe la pq pr og lc ps pt oi iz bi translated">5.5.光梯度增强回归器</h2><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi px"><img src="../Images/df28950f23101bbc2b5fa50fda641860.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WJ26tRHqZT1lhDeQhiuHuQ.png"/></div></div></figure><p id="ab07" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated"><a class="ae lj" href="https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html#lightgbm.LGBMRegressor" rel="noopener ugc nofollow" target="_blank">轻度梯度推进回归器</a>(轻度 GBM)在所有试验模型中表现最佳。它还降低了基线 MSE 45%,并表明它是在较低运行时间的良好预测器的潜在候选。</p><p id="4ad1" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated"><strong class="kt jd">作为总结:</strong></p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi py"><img src="../Images/7238a1a73af528b55463f04be8b27533.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NjOv9eqxy7cA8gaI1awpAw.png"/></div></div></figure><p id="f433" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">这可能不是一个公平的算法选择，因为我们只用默认的超参数来训练它们。然而，这是流水线的实验步骤，这就是为什么在<strong class="kt jd"> <em class="ms">对所选模型</em> </strong>执行超参数调整步骤中，light GBM 和 random forest 算法都有进一步改进的机会。(您可以在笔记本中找到它<a class="ae lj" href="https://render.githubusercontent.com/view/ipynb?commit=8f4a85d2c45f18c97f086c631778358717a0b0da&amp;enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f636572656e6979696d2f57696e652d526174696e672d507265646963746f722d4d4c2d4d6f64656c2f386634613835643263343566313863393766303836633633313737383335383731376130623064612f6e6f7465626f6f6b732f57696e65526174696e67507265646963746f722d322e6970796e62&amp;nwo=cereniyim%2FWine-Rating-Predictor-ML-Model&amp;path=notebooks%2FWineRatingPredictor-2.ipynb&amp;repository_id=257017095&amp;repository_type=Repository#Tune-Hyperparameters-of-the-Models" rel="noopener ugc nofollow" target="_blank">)在本文中，出于可理解性和性能要求，我们将使用随机森林回归器，我们将仅对其进行详细说明。</a></p><p id="f820" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">在进入下一步之前，让我们了解一下随机森林回归器的工作原理:</p><p id="e014" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated"><strong class="kt jd"> <em class="ms">随机森林回归器</em> </strong>是一种集成算法，一次构建多个决策树，并在数据集的各种子样本和各种特征子集上训练它们。它对数据集和特征子样本的随机选择使得该算法更加鲁棒。</p><p id="09be" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated"><strong class="kt jd"> <em class="ms">决策树</em> </strong>使用树状结构进行预测。它将一个数据集分解成越来越小的子集，同时一个相关的决策树被增量开发。最终结果是一个有决策节点和叶节点的树。决策节点有两个或多个分支，每个分支代表被测试的特性的值。叶节点代表对目标的最终决策。</p><h1 id="7a5f" class="ns nt it bd nu nv pf nx ny nz pg ob oc ki ph kj oe kl pi km og ko pj kp oi oj bi translated">6.对所选模型执行超参数调整</h1><p id="be86" class="pw-post-body-paragraph mf mg it kt b ku ok kd mh kw ol kg mi ky om mk ml la on mn mo lc oo mq mr le im bi translated"><strong class="kt jd"> <em class="ms">超参数</em> </strong>是数据科学家或 ML 工程师定义的一组参数，其值不受模型训练过程的影响。另一方面，<strong class="kt jd"> <em class="ms">模型的参数</em> </strong>在训练过程中被模型搜索优化，并受数据集影响。</p><p id="79cb" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">我喜欢贾森·布朗利关于机器学习掌握的这段引文，以防止两者混淆:</p><blockquote class="pz"><p id="bcf3" class="qa qb it bd qc qd qe qf qg qh qi le dk translated">"如果你必须手工指定一个模型参数，那么它可能是一个模型超参数."</p></blockquote><p id="5e2a" class="pw-post-body-paragraph mf mg it kt b ku qj kd mh kw qk kg mi ky ql mk ml la qm mn mo lc qn mq mr le im bi translated">我们最简单模型中的一个参数示例:线性回归模型的系数，这些系数通过模型训练进行优化。</p><p id="b805" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">我们选择的模型中的一个超参数的例子:在随机森林模型中构建的树的数量，这是由我们或 scikit-learn 指定的。</p><p id="fdd3" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated"><strong class="kt jd"> <em class="ms">超参数调优</em> </strong>是定义、搜索并可能进一步提高模型性能的过程。我们将用<strong class="kt jd"> <em class="ms">随机搜索</em> </strong>和<strong class="kt jd"> <em class="ms"> k 倍交叉验证来搜索最佳参数集。</em> </strong></p><h2 id="3c6a" class="oz nt it bd nu pk pl dn ny pm pn dp oc ky po pp oe la pq pr og lc ps pt oi iz bi translated">6.1.随机搜索</h2><p id="a27d" class="pw-post-body-paragraph mf mg it kt b ku ok kd mh kw ol kg mi ky om mk ml la on mn mo lc oo mq mr le im bi translated"><strong class="kt jd"> <em class="ms">随机搜索</em> </strong>是在每次迭代中随机搜索定义的参数组合，并比较定义的得分(均方误差，针对此问题)的过程。它速度快，运行时效率高，但由于要搜索已定义的超参数的随机组合，您可能并不总能找到最优的超参数集。</p><p id="88c1" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">我们将使用<code class="fe op oq or os b">hyperparameter_grid</code>字典搜索随机森林回归方程的以下超参数:</p><ul class=""><li id="1fbf" class="kr ks it kt b ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated"><code class="fe op oq or os b">n_estimators</code>:模型中使用的树的数量，默认为 100。</li><li id="b91b" class="kr ks it kt b ku lk kw ll ky lm la ln lc lo le lf lg lh li bi translated"><code class="fe op oq or os b">min_samples_split</code>:分割内部节点所需的最小样本数，默认值为 2。</li><li id="7229" class="kr ks it kt b ku lk kw ll ky lm la ln lc lo le lf lg lh li bi translated"><code class="fe op oq or os b">min_samples_leaf</code>:叶子节点需要的最小样本数，默认值为 1。</li><li id="553b" class="kr ks it kt b ku lk kw ll ky lm la ln lc lo le lf lg lh li bi translated"><code class="fe op oq or os b">max_features</code>:寻找最佳分割时要考虑的特征数量，默认值为自动。</li></ul><pre class="lq lr ls lt gt ov os ow ox aw oy bi"><span id="b197" class="oz nt it os b gy pa pb l pc pd"><em class="ms"># define search parameters</em> <br/>n_estimators = [100, 200, 300, 500, 1000] <br/>min_samples_split = [2, 4, 6, 10] <br/>min_samples_leaf = [1, 2, 4, 6, 8] <br/>max_features = ['auto', 'sqrt', 'log2', <strong class="os jd">None</strong>]</span><span id="8aae" class="oz nt it os b gy pe pb l pc pd"><em class="ms"># Define the grid of hyperparameters to search</em> <br/>hyperparameter_grid = {<br/>    "n_estimators": n_estimators,               <br/>    "min_samples_split": min_samples_split,                       <br/>    "min_samples_leaf": min_samples_leaf,                         <br/>    "max_features": max_features}</span></pre><h2 id="5c3b" class="oz nt it bd nu pk pl dn ny pm pn dp oc ky po pp oe la pq pr og lc ps pt oi iz bi translated">6.2.<strong class="ak"> <em class="qo"> K 倍</em> </strong>交叉验证</h2><p id="d561" class="pw-post-body-paragraph mf mg it kt b ku ok kd mh kw ol kg mi ky om mk ml la on mn mo lc oo mq mr le im bi translated"><strong class="kt jd"> <em class="ms"> K 重交叉验证</em> </strong>是用于在完整训练数据集上评估模型性能的方法。对于给定的<em class="ms"> K </em>，数据集被平均划分，而不是将数据集分成训练集和验证集的两个静态子集。然后用<em class="ms"> K-1 个</em>子集训练模型，并在<em class="ms">第 K 个</em>子集上迭代测试。这一过程使得模型对过度拟合更加健壮——在文章的最后会有更多的介绍。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi qp"><img src="../Images/b62b7099b1b6beda89afc0e771f990e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kOeBDUo9JfSpZQt7.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">图片鸣谢:在<a class="ae lj" href="https://scikit-learn.org/stable/modules/cross_validation.html" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>上对 k 倍交叉验证的可视化解释</p></figure><p id="c0ab" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">为了使用随机搜索和 k 倍交叉验证来执行超参数调整，我们将添加训练和验证数据集，并从现在开始继续使用一个训练集。</p><pre class="lq lr ls lt gt ov os ow ox aw oy bi"><span id="f602" class="oz nt it os b gy pa pb l pc pd"><em class="ms"># add dataframes back for to perform random search and cross-validation</em><br/>X = pd.concat([X_train, X_valid])<br/>y = pd.concat([y_train, y_valid])</span><span id="1a5b" class="oz nt it os b gy pe pb l pc pd">X_array = convert_features_to_array(X)<br/>y_array = convert_target_to_array(y)</span></pre><p id="f32c" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">由于我们在训练数据集中只有不到 10.000 行，因此我们将执行 4 次折叠交叉验证，以便在每个折叠中有足够数量的数据点。我们将在<code class="fe op oq or os b"><a class="ae lj" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html" rel="noopener ugc nofollow" target="_blank">RandomizedSearchCV</a></code>对象中整合随机搜索和 k 倍交叉验证:</p><pre class="lq lr ls lt gt ov os ow ox aw oy bi"><span id="2a4b" class="oz nt it os b gy pa pb l pc pd">rf_random_cv = RandomizedSearchCV(<br/>    estimator=rf,<br/>    param_distributions=hyperparameter_grid,<br/>    cv=4, <br/>    n_iter=25,<br/>    scoring='neg_mean_squared_error',<br/>    n_jobs=-1, <br/>    verbose=1,<br/>    return_train_score=<strong class="os jd">True</strong>,<br/>    random_state=42)</span><span id="a93d" class="oz nt it os b gy pe pb l pc pd">rf_random_cv.fit(X_array, y_array)</span></pre><p id="2358" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">使用<code class="fe op oq or os b">fit</code>方法，我们开始搜索在<code class="fe op oq or os b">hyperparameter_grid</code>中为每个超参数定义的值的随机组合。同时，在每一次迭代中为每一个折叠计算<code class="fe op oq or os b">"neg_mean_squared_error"</code>。我们可以通过调用<code class="fe op oq or os b">best_estimator_</code>方法来观察确定的最佳参数集:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi qq"><img src="../Images/1241c6fb3fcd39c3a755a15fcd97918e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j5Y4shr0Uy1agknM-wpjbw.png"/></div></div></figure><p id="6322" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">超参数调整后，最佳超参数集确定为:</p><ul class=""><li id="4f8e" class="kr ks it kt b ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated"><code class="fe op oq or os b">n_estimators</code> : 200</li><li id="b7f8" class="kr ks it kt b ku lk kw ll ky lm la ln lc lo le lf lg lh li bi translated"><code class="fe op oq or os b">min_samples_split</code> : 4</li><li id="ed46" class="kr ks it kt b ku lk kw ll ky lm la ln lc lo le lf lg lh li bi translated"><code class="fe op oq or os b">min_samples_leaf</code> : 2</li><li id="7e10" class="kr ks it kt b ku lk kw ll ky lm la ln lc lo le lf lg lh li bi translated"><code class="fe op oq or os b">max_features</code>:‘sqrt’</li></ul><p id="3683" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">让我们看看这些超参数是否会帮助我们进一步提高随机森林回归的 MSE。</p><h2 id="852a" class="oz nt it bd nu pk pl dn ny pm pn dp oc ky po pp oe la pq pr og lc ps pt oi iz bi translated">6.3.超参数调整后再访随机森林回归方程的 MSE</h2><pre class="lq lr ls lt gt ov os ow ox aw oy bi"><span id="5905" class="oz nt it os b gy pa pb l pc pd">rf_random_cv_model = rf_random_cv.best_estimator_</span></pre><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi qq"><img src="../Images/f0f879d734816ce9289de8c3c34b8aeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*smLL1NRMTRGA_VcMQ5QGng.png"/></div></div></figure><p id="46cd" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">MSE 从 5.41 降低到 4.99，调整后的模型运行时间为 1.12 秒，低于初始随机森林模型的运行时间(1.89 秒)。超参数调优不仅提高了评估指标，还降低了我们的运行时间。</p><p id="516f" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">给定样本数据集、确定的特征集和调整的随机森林回归器，我们已经成功地构建了一个好的葡萄酒评级预测器，而不会陷入欠拟合和过拟合区域！</p><h2 id="ca19" class="oz nt it bd nu pk pl dn ny pm pn dp oc ky po pp oe la pq pr og lc ps pt oi iz bi translated"><strong class="ak">关于</strong> <a class="ae lj" href="https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">过拟合和欠拟合</strong> </a>的几点注记</h2><p id="64c9" class="pw-post-body-paragraph mf mg it kt b ku ok kd mh kw ol kg mi ky om mk ml la on mn mo lc oo mq mr le im bi translated">虽然这个主题本身是另一篇文章，但我认为在这里讨论是很重要的，因为我们提到了这些概念。</p><p id="ad72" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated"><strong class="kt jd"> <em class="ms">过度拟合</em> </strong>发生在 ML 模型完美拟合(或记忆)训练数据集，而不是抓住特征和目标之间的共同模式的时候。一个过度拟合的模型会有一个<strong class="kt jd"> <em class="ms">高方差</em> </strong>，我发现这种情况和一个易碎的玻璃房子有相似之处。它是为其目前的条件而完美建造的，但如果条件改变，它就不太可能存活。</p><blockquote class="qr qs qt"><p id="b116" class="mf mg ms kt b ku kv kd mh kw kx kg mi qu mj mk ml qv mm mn mo qw mp mq mr le im bi translated">你还记得交叉验证使我们的模型对过度拟合更加稳健吗？</p></blockquote><p id="1ed7" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">背后的原因是，我们的模型在训练期间在每个折叠中看到不同的数据集——就像一所房子已经遇到不同的天气条件。这提高了泛化性能，使模型更能抵抗过拟合。</p><p id="83b3" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated"><strong class="kt jd"> <em class="ms">欠拟合</em> </strong>发生在 ML 模型由于没有足够的数据点或特征而无法掌握特征与目标之间的关系时。它的表现可能和对预测的随机猜测一样糟糕。一个欠拟合的模型会有一个<strong class="kt jd"><em class="ms"/></strong>偏高，我把这种情况想成是搭建了一半的棚子。它应该经历一些建设，以服务于它的目的。</p><blockquote class="qr qs qt"><p id="3593" class="mf mg ms kt b ku kv kd mh kw kx kg mi qu mj mk ml qv mm mn mo qw mp mq mr le im bi translated">你还记得线性回归模型只显示基线 MSE 有轻微的改善吗？</p></blockquote><p id="1c4f" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">这是一个不适合的例子。线性回归模型产生了与基线 MSE 几乎相同的 MSE，并且未能理解特征和目标之间的关系。</p><p id="bc36" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">总之，过拟合和欠拟合都会降低机器学习模型的泛化性能，并导致不令人满意的评估度量水平。虽然我们没有测试调优的随机森林回归器，特别是过度拟合的情况，但 45%的改进表明我们处于欠拟合和过度拟合之间的细微差别。</p><p id="0ee9" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">在得出结论之前，让我们将模型保存在目录中，这样我们可以从上一篇文章和笔记本中停止的地方继续。</p><pre class="lq lr ls lt gt ov os ow ox aw oy bi"><span id="9279" class="oz nt it os b gy pa pb l pc pd">filename = 'random_forests_model.sav'<br/>pickle.dump(rf_random_cv_model, <br/>           open(filename, 'wb'))</span></pre><h1 id="cab5" class="ns nt it bd nu nv pf nx ny nz pg ob oc ki ph kj oe kl pi km og ko pj kp oi oj bi translated">结论</h1><p id="ce2c" class="pw-post-body-paragraph mf mg it kt b ku ok kd mh kw ol kg mi ky om mk ml la on mn mo lc oo mq mr le im bi translated">在本文中，我们完成了机器学习流水线的中间步骤。在简要回顾了<a class="ae lj" rel="noopener" target="_blank" href="/building-an-automated-machine-learning-pipeline-part-one-5c70ae682f35?source=friends_link&amp;sk=8de05327eedb3d0dadcfa4b1a8e8cc75">首件</a>和目标之后，我们</p><ol class=""><li id="e205" class="kr ks it kt b ku kv kw kx ky kz la lb lc ld le qx lg lh li bi translated">由于其在 ML 算法中的广泛使用和可解释性，将评估度量设置为均方误差。</li><li id="8f26" class="kr ks it kt b ku lk kw ll ky lm la ln lc lo le qx lg lh li bi translated">建立了与均方误差计算一致的基线，结果为 9.01。</li><li id="337e" class="kr ks it kt b ku lk kw ll ky lm la ln lc lo le qx lg lh li bi translated">尝试了几种不同的最大似然算法，并选择了随机森林回归，它在 1.93 秒的运行时间内报告了 5.4 的 MSE。</li><li id="8c4f" class="kr ks it kt b ku lk kw ll ky lm la ln lc lo le qx lg lh li bi translated">微调了随机森林回归器的超参数，与初始随机森林模型相比，性能提高了 8%(MSE:4.99，运行时间为 1.12 秒)。</li></ol><p id="5de3" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">如果我们考虑我们最初的动机(建立一个好的葡萄酒预测器)和基线 MSE (9.01)，当我们接近管道的末端时，我们正走在正确的道路上。</p><p id="f6a8" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">我们已经显著降低了基线 MSE，从 9.01 降低到 4.99，结果提高了 45%！</p></div><div class="ab cl nl nm hx nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="im in io ip iq"><p id="9226" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">第三篇文章将从加载微调后的随机森林回归模型开始，并重点关注使用测试集对模型进行评估，以及评估的结果。(步骤 7、8 和 9)。</p><div class="mt mu gp gr mv mw"><a rel="noopener follow" target="_blank" href="/building-an-automated-machine-learning-pipeline-a74acda76b98"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd jd gy z fp nb fr fs nc fu fw jc bi translated">构建自动化机器学习管道</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">训练和评估模型，解释模型结果和最终结论</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">towardsdatascience.com</p></div></div><div class="nf l"><div class="qy l nh ni nj nf nk lz mw"/></div></div></a></div><p id="b328" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">最后一篇文章将使用<a class="ae lj" href="https://www.docker.com/" rel="noopener ugc nofollow" target="_blank"> Docker </a>和<a class="ae lj" href="https://luigi.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank"> Luigi </a>来自动化这条流水线。</p><div class="mt mu gp gr mv mw"><a rel="noopener follow" target="_blank" href="/building-an-automated-machine-learning-pipeline-part-four-787cdc50a12d"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd jd gy z fp nb fr fs nc fu fw jc bi translated">构建自动化机器学习管道:第四部分</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">利用 Docker 和 Luigi 实现管道自动化</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">towardsdatascience.com</p></div></div><div class="nf l"><div class="qz l nh ni nj nf nk lz mw"/></div></div></a></div><p id="3afa" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">感谢阅读😊</p><p id="0488" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">对于评论或建设性的反馈，你可以联系我的回复，<a class="ae lj" href="https://twitter.com/cereniyim" rel="noopener ugc nofollow" target="_blank"> Twitter </a>或<a class="ae lj" href="https://www.linkedin.com/in/ceren-iyim" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>！</p><p id="e52f" class="pw-post-body-paragraph mf mg it kt b ku kv kd mh kw kx kg mi ky mj mk ml la mm mn mo lc mp mq mr le im bi translated">在那之前保持安全和健康👋</p></div></div>    
</body>
</html>