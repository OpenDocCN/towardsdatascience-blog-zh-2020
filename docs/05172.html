<html>
<head>
<title>A Game Theoretical Approach for Adversarial Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">对抗性机器学习的博弈论方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-game-theoretical-approach-for-adversarial-machine-learning-7523914819d5?source=collection_archive---------29-----------------------#2020-05-03">https://towardsdatascience.com/a-game-theoretical-approach-for-adversarial-machine-learning-7523914819d5?source=collection_archive---------29-----------------------#2020-05-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/793c0258836672e15718c9de02ba92eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bctW2C6SEqa0CtHHB5Myvw.jpeg"/></div></div></figure><div class=""/><div class=""><h2 id="7a56" class="pw-subtitle-paragraph kb jd je bd b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks dk translated">如何运用博弈论解决对抗性风险？</h2></div><p id="9859" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi lp translated">人工智能近年来取得了巨大的成功，因为它为我们提供了强大的算法，这些算法使用大型数据库进行准确的预测或分类。它们越来越多地用于不同的目的，包括高风险的目的。</p><p id="c28a" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">然而，他们不是绝对可靠的<strong class="kv jf"/>。</p><p id="0cdc" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">事实上，这些算法中的大多数都是根据数据训练的，这些数据可以被试图误导它犯错误的对手故意操纵。</p><p id="7af1" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">让我们举一个简单的例子:<strong class="kv jf">垃圾邮件检测。</strong>起初，朴素贝叶斯等标准分类器在准确性方面效率极高。然而，垃圾邮件制造者很快学会了如何通过改变同义词来愚弄他们，并添加更多的“非垃圾邮件”世界。因此，垃圾邮件过滤器被改变来检测这些伎俩。但是垃圾邮件发送者用新的来回应。因此，这就导致了防守者和进攻者之间的<strong class="kv jf">无休止的博弈，直到达到均衡状态</strong>。</p><p id="afe4" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在这种情况下，<strong class="kv jf">博弈论</strong>可能非常有用，因为它提供了在防御和攻击策略方面对防御者的行为和对手的行为进行建模所需的数学工具。</p><p id="e299" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">更具体地说，基于博弈论的模型使我们能够考虑:</p><ul class=""><li id="df07" class="lz ma je kv b kw kx kz la lc mb lg mc lk md lo me mf mg mh bi translated"><strong class="kv jf">攻击者</strong>在适应分类器的成本和他从攻击中获得的收益之间做出的权衡。</li><li id="e307" class="lz ma je kv b kw mi kz mj lc mk lg ml lk mm lo me mf mg mh bi translated"><strong class="kv jf">防御方</strong>在正确攻击检测的好处和错误警报的代价之间进行权衡。</li></ul><p id="87f9" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">因此，基于博弈论的模型可以确定需要什么样的合适的策略来减少防守方在对抗性攻击中的损失。</p><p id="2db4" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">垃圾邮件过滤并不是这些模型能够带来有价值信息的唯一案例。这个视角可以用来描述<strong class="kv jf">许多其他风险更高的情况:</strong>计算机入侵检测、欺诈检测、空中监视。</p><p id="09cc" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在这篇文章中，我将与你分享我关于如何将博弈论用于对抗性机器学习的<strong class="kv jf">的关键发现。</strong></p><p id="e637" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">阅读本文后，您将了解到:</p><ul class=""><li id="d263" class="lz ma je kv b kw kx kz la lc mb lg mc lk md lo me mf mg mh bi translated">博弈论如何应用于机器学习？</li><li id="ec17" class="lz ma je kv b kw mi kz mj lc mk lg ml lk mm lo me mf mg mh bi translated">博弈论如何帮助解决对抗性学习问题？</li><li id="e6ca" class="lz ma je kv b kw mi kz mj lc mk lg ml lk mm lo me mf mg mh bi translated">如何让你的机器学习算法对对抗性攻击具有鲁棒性？</li></ul><h1 id="3ad7" class="mn mo je bd mp mq mr ms mt mu mv mw mx kk my kl mz kn na ko nb kq nc kr nd ne bi translated">基于博弈论方法的一个例子</h1><p id="6986" class="pw-post-body-paragraph kt ku je kv b kw nf kf ky kz ng ki lb lc nh le lf lg ni li lj lk nj lm ln lo im bi translated">先说一个简单的例子:<strong class="kv jf">垃圾邮件检测。</strong></p><p id="ea8e" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">以下部分描述了W. Liu和S. Chawal在<a class="ae nk" href="https://ieeexplore.ieee.org/document/5360532" rel="noopener ugc nofollow" target="_blank">论文</a>中为对抗性学习开发的博弈论模型。</p><h2 id="1d96" class="nl mo je bd mp nm nn dn mt no np dp mx lc nq nr mz lg ns nt nb lk nu nv nd nw bi translated">一般设置</h2><p id="aa90" class="pw-post-body-paragraph kt ku je kv b kw nf kf ky kz ng ki lb lc nh le lf lg ni li lj lk nj lm ln lo im bi translated">它可以被建模为在<strong class="kv jf">垃圾邮件发送者(S) </strong>和<strong class="kv jf">防御者(D) </strong>之间的双人游戏。</p><ul class=""><li id="e902" class="lz ma je kv b kw kx kz la lc mb lg mc lk md lo me mf mg mh bi translated"><strong class="kv jf">垃圾邮件发送者</strong>可以选择<strong class="kv jf"> 1) </strong>通过改变垃圾邮件并让它们通过垃圾邮件过滤器来攻击分类器，或者<strong class="kv jf"> 2) </strong>在知道一些垃圾邮件可能通过的情况下不进行攻击。</li><li id="f8c6" class="lz ma je kv b kw mi kz mj lc mk lg ml lk mm lo me mf mg mh bi translated"><strong class="kv jf">防御方</strong>可以选择<strong class="kv jf"> 1) </strong>重新训练分类器，以保持较低的误分类率，或者选择<strong class="kv jf"> 2) </strong>不重新训练分类器，尽管误分类的垃圾邮件可能会增加。</li></ul><p id="01d1" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我们将假设垃圾邮件发送者将是第一个采取行动的人。</p><p id="ff43" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">有<strong class="kv jf"> 4种可能的结果</strong>，如下图所示。可以将每个场景与两个玩家的<strong class="kv jf">收益</strong>相关联，以反映最终结果的相对排名。</p><blockquote class="nx ny nz"><p id="a2e7" class="kt ku ly kv b kw kx kf ky kz la ki lb oa ld le lf ob lh li lj oc ll lm ln lo im bi translated">例如，<strong class="kv jf">场景2 </strong>对防御者来说是最坏的场景，对垃圾邮件发送者来说是最好的场景，因为他对未经过训练的分类器的攻击将导致<strong class="kv jf">大量错误分类的垃圾邮件</strong>。</p></blockquote><figure class="oe of og oh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi od"><img src="../Images/0b7060d60a2c2b1d0f40514699c8c562.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HkNIvo1Qzft2lpGM9Y3_Kw.png"/></div></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">垃圾邮件制造者和防御者之间的博弈树</p></figure><h2 id="973f" class="nl mo je bd mp nm nn dn mt no np dp mx lc nq nr mz lg ns nt nb lk nu nv nd nw bi translated">模型定义</h2><p id="ca97" class="pw-post-body-paragraph kt ku je kv b kw nf kf ky kz ng ki lb lc nh le lf lg ni li lj lk nj lm ln lo im bi translated">这种情况可以建模为一个<strong class="kv jf"> Stackelberg博弈</strong>，即一个顺序博弈，其中有<strong class="kv jf">一个领导者</strong>(这里是垃圾邮件发送者)和<strong class="kv jf">一个跟随者</strong>(防守者D)。</p><p id="ca17" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">Stackelberg博弈  <strong class="kv jf"> </strong>通常用于模拟存在等级竞争的市场中理性主体之间的战略互动。</p><p id="d7c5" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在这种情况下，每个玩家通过分别为S和D 从一组可能的动作U和V中选择一个动作来对另一个玩家的动作做出反应。假设这些集合是有界的和凸的。</p><p id="fe12" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">每个结果都与一个<strong class="kv jf">收益函数<em class="ly"> Js、</em>和<em class="ly"> Jd相关联。</em> </strong>收益函数<em class="ly"> Ji </em>是两次可微映射<strong class="kv jf"> <em class="ly"> Ji(U，V) → R </em> </strong>其中R是反应。</p><p id="9c44" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">因此，有可能将参与人I的反应Ri预期为使其收益最大化的反应，即:</p><figure class="oe of og oh gt iv gh gi paragraph-image"><div class="gh gi om"><img src="../Images/68ba25151936439a36af584f7707c3be.png" data-original-src="https://miro.medium.com/v2/resize:fit:402/format:webp/1*qApY4xPI0RR0cV8R6cvgzw.png"/></div></figure><p id="a52a" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">此外，第一个采取行动的人可以<strong class="kv jf">预测</strong>跟随者会如何理性反应，并在他的第一个决定中考虑到这一点。这就是所谓的<strong class="kv jf">倒推</strong>或<strong class="kv jf">倒推</strong>。</p><p id="aa77" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这意味着垃圾邮件发送者的第一个行动是解决下面的<strong class="kv jf">优化问题</strong>:</p><figure class="oe of og oh gt iv gh gi paragraph-image"><div class="gh gi on"><img src="../Images/8a84304cb01e6a24650149b5ab5dfb01.png" data-original-src="https://miro.medium.com/v2/resize:fit:436/format:webp/1*DWQXMbFMgH2zEGr6tApKQQ.png"/></div></figure><p id="73be" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">因此，防守者会选择最优解:</p><figure class="oe of og oh gt iv gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/2484b18d8bf2959be216a0971431e366.png" data-original-src="https://miro.medium.com/v2/resize:fit:210/format:webp/1*yht0fwOLi2EKTKHNfSYPRQ.png"/></div></figure><p id="441b" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这个解(u，v)就是<strong class="kv jf"> Stackelberg平衡</strong>。</p><p id="640d" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">请注意，它不同于<strong class="kv jf">纳什均衡</strong>，其中游戏的两个参与者同时行动<strong class="kv jf"/>，联立方程的解是<strong class="kv jf"> (0，0) </strong>，即两个参与者都没有反应。</p><h2 id="c558" class="nl mo je bd mp nm nn dn mt no np dp mx lc nq nr mz lg ns nt nb lk nu nv nd nw bi translated">模型设定</h2><p id="d479" class="pw-post-body-paragraph kt ku je kv b kw nf kf ky kz ng ki lb lc nh le lf lg ni li lj lk nj lm ln lo im bi translated">现在我们已经定义了一般的设置，我们仍然需要确定在一个<strong class="kv jf">分类问题</strong>的特殊情况下玩家的收益函数。</p><p id="4ace" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">为了简化，我们首先只考虑一个属性。然后可以很容易地推广到多个属性，假设它们是条件独立的，给定它们的类标签。</p><p id="2e61" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">一、选手招式的<strong class="kv jf">影响</strong>是什么？</p><p id="c824" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">让我们定义以下<strong class="kv jf">分布</strong>:</p><ul class=""><li id="76f9" class="lz ma je kv b kw kx kz la lc mb lg mc lk md lo me mf mg mh bi translated"><em class="ly"> P(μ'，σ) </em>:垃圾邮件分布</li><li id="76d1" class="lz ma je kv b kw mi kz mj lc mk lg ml lk mm lo me mf mg mh bi translated">Q <em class="ly"> (μ，σ) </em>:非垃圾邮件的分布</li></ul><p id="37ae" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">用<em class="ly"> μ' &lt; μ，</em>因为非垃圾邮件比垃圾邮件多</p><p id="94cc" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">对手通过移动<em class="ly">μ’</em>到<em class="ly">μ’+u</em>(即朝向<em class="ly"> μ </em>)进行攻击。防守方的反应是将边界从1/2 ( <em class="ly"> μ'+μ') </em>移动到(也向<em class="ly"> μ </em>移动)</p><p id="a6ea" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">第二，玩家的<strong class="kv jf">收益</strong>是什么？</p><p id="c8d8" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">为了评估一个变换u对数据的重要性，可以使用<a class="ae nk" href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence" rel="noopener ugc nofollow" target="_blank"><strong class="kv jf">kull back–lei bler散度</strong> </a> <strong class="kv jf"> KLD </strong>(也叫相对熵)。它衡量一个概率分布如何不同于另一个参考概率分布。</p><p id="9841" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><strong class="kv jf">垃圾邮件发送者的收益:</strong>因为他的目标是增加错误分类的垃圾邮件的数量，所以他的收益可以表示如下:</p><figure class="oe of og oh gt iv gh gi paragraph-image"><div class="gh gi op"><img src="../Images/1811e51610c3eacb21fc29e2c7784111.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*GydJKahew3RfghPTELy1_w.png"/></div></figure><p id="d3e7" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">其中FNR是假阴性率的增加。因此，α代表<strong class="kv jf">成本损失</strong>的强度。</p><p id="cd18" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><strong class="kv jf">防守者的收益:</strong>由于他的目标是提高分类的准确性，他的收益可以表示如下:</p><figure class="oe of og oh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oq"><img src="../Images/90999669fa0fab75491ca7b7be8905b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*JahkTwcGHorPTqMQYAXKoA.png"/></div></div></figure><p id="d82b" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">其中TPR和TNR代表真实正利率和真实负利率的增加。因此，β控制重新训练分类器的<strong class="kv jf">成本的强度。</strong></p><p id="d61a" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在这种情况下，下面的等式可以使用<a class="ae nk" href="https://en.wikipedia.org/wiki/Genetic_algorithm" rel="noopener ugc nofollow" target="_blank"> <strong class="kv jf">遗传算法</strong> </a>来求解:</p><figure class="oe of og oh gt iv gh gi paragraph-image"><div class="gh gi or"><img src="../Images/2d4ab7b41cf355de26fd1ed60c7d68af.png" data-original-src="https://miro.medium.com/v2/resize:fit:420/format:webp/1*_yCXwBx48pM-zj-yNzhzVw.png"/></div></figure><p id="dacb" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">论文<a class="ae nk" href="https://ieeexplore.ieee.org/document/5360532" rel="noopener ugc nofollow" target="_blank">的作者</a>应用这种方法在合成数据和真实数据之间寻找平衡。根据生成攻击和重新训练分类器(通过α和β建模)所产生的成本的重要性，他们找到不同的均衡。</p><h1 id="bd40" class="mn mo je bd mp mq mr ms mt mu mv mw mx kk my kl mz kn na ko nb kq nc kr nd ne bi translated">基于博弈论的方法的其他变体</h1><p id="a3cd" class="pw-post-body-paragraph kt ku je kv b kw nf kf ky kz ng ki lb lc nh le lf lg ni li lj lk nj lm ln lo im bi translated">前一个例子依赖于一组假设:它模拟了一个游戏，其中攻击者和防御者相互竞争。假设<strong class="kv jf">攻击者首先采取行动</strong>。它还假设两个玩家都知道他们各自对手的收益和成本。</p><p id="8f70" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">然而，这些假设并不总是成立的。幸运的是，存在大量基于博弈论方法的模型。它们可以分类如下。</p><h2 id="356c" class="nl mo je bd mp nm nn dn mt no np dp mx lc nq nr mz lg ns nt nb lk nu nv nd nw bi translated">零和与非零和游戏</h2><p id="6229" class="pw-post-body-paragraph kt ku je kv b kw nf kf ky kz ng ki lb lc nh le lf lg ni li lj lk nj lm ln lo im bi translated">在两人零和游戏中，进攻者的收益等于防守者损失的成本，反之亦然。这意味着玩家的效用总和为0。这种假设可能非常悲观，因为防守方的效用损失可能不如对手的效用。</p><h2 id="b3e7" class="nl mo je bd mp nm nn dn mt no np dp mx lc nq nr mz lg ns nt nb lk nu nv nd nw bi translated">同时博弈与顺序博弈</h2><p id="fcee" class="pw-post-body-paragraph kt ku je kv b kw nf kf ky kz ng ki lb lc nh le lf lg ni li lj lk nj lm ln lo im bi translated">在同时移动游戏中，玩家同时选择<strong class="kv jf">他们的策略，而不观察对方的策略。在顺序博弈中，他们一个接一个地选择他们的行动。</strong></p><p id="0f7e" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">对抗性学习主要被建模为一个<strong class="kv jf">序列游戏，防守者是领导者。事实上，人们通常认为，一旦防御者选择了分类器，攻击者就可以观察它并决定自己的策略。</strong></p><p id="77d7" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">上一节描述的模型是少数几个认为攻击者在选择策略之前无法观察分类器的模型之一。</p><h2 id="6855" class="nl mo je bd mp nm nn dn mt no np dp mx lc nq nr mz lg ns nt nb lk nu nv nd nw bi translated">贝叶斯博弈</h2><p id="9488" class="pw-post-body-paragraph kt ku je kv b kw nf kf ky kz ng ki lb lc nh le lf lg ni li lj lk nj lm ln lo im bi translated">贝叶斯游戏模拟了一种游戏，其中玩家拥有关于其他玩家的<strong class="kv jf">不完全信息</strong>。这更有可能是因为防御者可能不知道生成敌对数据的确切成本，并且攻击者可能不知道防御者的确切分类成本。他们只相信这些成本。</p><blockquote class="nx ny nz"><p id="9dcc" class="kt ku ly kv b kw kx kf ky kz la ki lb oa ld le lf ob lh li lj oc ll lm ln lo im bi translated">著名经济学家约翰·C·海萨尼在博弈论方面做出了重大贡献，他特别是在不完全信息环境下，他这样描述贝叶斯博弈:</p><p id="2392" class="kt ku ly kv b kw kx kf ky kz la ki lb oa ld le lf ob lh li lj oc ll lm ln lo im bi translated">游戏中的每个玩家都与一组<strong class="kv jf">类型</strong>相关联，该组中的每种类型都对应于该玩家的一个可能的<strong class="kv jf">支付函数</strong>。除了游戏中的实际玩家，还有一个特殊的玩家叫做<strong class="kv jf">自然</strong>。大自然根据玩家类型空间的<strong class="kv jf">概率分布</strong>为每个玩家随机选择一个类型。所有玩家都知道这个概率分布(“<strong class="kv jf">常见先验假设</strong>”)。这种建模方法将不完全信息博弈转化为<strong class="kv jf">不完全信息博弈</strong>。</p><p id="9090" class="kt ku ly kv b kw kx kf ky kz la ki lb oa ld le lf ob lh li lj oc ll lm ln lo im bi translated">来源:<a class="ae nk" href="https://en.wikipedia.org/wiki/Bayesian_game" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></blockquote><h1 id="a527" class="mn mo je bd mp mq mr ms mt mu mv mw mx kk my kl mz kn na ko nb kq nc kr nd ne bi translated">如何让对抗性学习变得健壮？</h1><p id="0b0a" class="pw-post-body-paragraph kt ku je kv b kw nf kf ky kz ng ki lb lc nh le lf lg ni li lj lk nj lm ln lo im bi translated">依赖于基于博弈论的框架的对抗性学习技术可能是相关的，因为它基于重新训练模型和生成攻击者所产生的<strong class="kv jf">收益和成本</strong>来模拟学习者和对手的<strong class="kv jf">行为</strong>。</p><p id="8d8b" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">但是，如果最初的模型已经能够抵御恶意攻击呢？</p><p id="e1a7" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">提高这种稳健性的最常见方法之一是<strong class="kv jf">对恶意数据</strong>进行建模，这些恶意数据可能是由对手事先生成的，并将其包含在训练阶段。</p><p id="5220" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在本节中，我们将考虑用于<strong class="kv jf">生成对抗数据</strong>的3种主要技术:扰动技术、转移对抗实例、生成对抗网络(GAN)。</p><h2 id="bd1a" class="nl mo je bd mp nm nn dn mt no np dp mx lc nq nr mz lg ns nt nb lk nu nv nd nw bi translated">扰动技术</h2><p id="813c" class="pw-post-body-paragraph kt ku je kv b kw nf kf ky kz ng ki lb lc nh le lf lg ni li lj lk nj lm ln lo im bi translated">这个想法是为了产生可以被潜在对手利用的合成对抗数据。要做到这一点，有必要了解并预测对手是如何发起攻击的。</p><p id="92e6" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这些技术中的大多数依赖于向有效的示例添加少量的噪声或扰动。让我们来看看一些众所周知的例子:</p><p id="b67b" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><a class="ae nk" href="https://arxiv.org/pdf/1312.6199.pdf" rel="noopener ugc nofollow" target="_blank"><strong class="kv jf">BFGS</strong></a></p><p id="c642" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">让我们注意一下:</p><ul class=""><li id="cb1c" class="lz ma je kv b kw kx kz la lc mb lg mc lk md lo me mf mg mh bi translated">f:用于给定观察值<em class="ly"> x </em>的分类器映射，包括<em class="ly"> m </em>特征并返回类别标签</li><li id="1e76" class="lz ma je kv b kw mi kz mj lc mk lg ml lk mm lo me mf mg mh bi translated"><em class="ly">损失:</em>关联的连续损失函数</li><li id="be8b" class="lz ma je kv b kw mi kz mj lc mk lg ml lk mm lo me mf mg mh bi translated"><em class="ly">居:</em>微扰</li></ul><p id="36e0" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">如果攻击者的目标是生成一个被错误分类为a1的示例，他必须解决以下优化问题:</p><figure class="oe of og oh gt iv gh gi paragraph-image"><div class="gh gi os"><img src="../Images/9d41817f7d6dc7a2d2f9ccebd0c41197.png" data-original-src="https://miro.medium.com/v2/resize:fit:296/format:webp/1*lI9vHMe2ty1pF6GutNoJTA.png"/></div></figure><p id="8d72" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这可以通过执行线搜索来找到最小值c &gt; 0来完成，对于该最小值c &gt; 0，以下问题的极小值r满足<em class="ly"> f(x + r) = l : </em></p><figure class="oe of og oh gt iv gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/ce50f1a609439d315e88698516ab37d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:390/format:webp/1*pvmn_qWqIyE94fYej_QhgA.png"/></div></figure><p id="6bc4" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">请注意，对于深度神经网络等复杂模型，该优化问题没有封闭形式的解决方案。但是，可以使用迭代数值方法，这会使生成速度变慢。然而，它的成功率很高。</p><p id="bd32" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><a class="ae nk" href="https://arxiv.org/pdf/1412.6572.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="kv jf">【快速梯度征法】</strong> </a></p><p id="4044" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">让我们注意一下:</p><ul class=""><li id="e915" class="lz ma je kv b kw kx kz la lc mb lg mc lk md lo me mf mg mh bi translated"><em class="ly"> X </em>:清洁观察</li><li id="f6bf" class="lz ma je kv b kw mi kz mj lc mk lg ml lk mm lo me mf mg mh bi translated"><em class="ly"> ∇J(X,y): </em>模型损失函数相对于<em class="ly"> X </em>的梯度</li><li id="caf6" class="lz ma je kv b kw mi kz mj lc mk lg ml lk mm lo me mf mg mh bi translated"><em class="ly"> ϵ: </em>参数<em class="ly">控制对抗性扰动的重要性</em></li></ul><p id="ea1f" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">该方法通过增加损失函数值来产生对抗性扰动，如下所示:</p><figure class="oe of og oh gt iv gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/8fba09417fe8aaaedb2e6f6565d0ab8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:538/format:webp/1*yBVmPv4JnKqY9rdECyzt5A.png"/></div></figure><p id="f672" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">请注意，在梯度方向上增加一个扰动可以有意地改变观测结果，从而使模型对其进行错误分类。</p><p id="5f23" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">与前一种方法相比，这种方法实现起来<strong class="kv jf">更快，计算上更可行</strong>。但其<strong class="kv jf">成功率较低</strong>。</p><p id="eac7" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">Goodfellow等人描述该方法的论文也导致了有趣的观察结果，例如:</p><ul class=""><li id="a8d3" class="lz ma je kv b kw kx kz la lc mb lg mc lk md lo me mf mg mh bi translated">使用干扰的方向比干扰的数量更能有效地创造对立的例子</li><li id="c6a5" class="lz ma je kv b kw mi kz mj lc mk lg ml lk mm lo me mf mg mh bi translated">用对立的例子训练分类器类似于分类器的<strong class="kv jf">正则化</strong></li></ul><p id="afb6" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><a class="ae nk" href="https://arxiv.org/pdf/1607.02533.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="kv jf">迭代快速梯度符号</strong> </a></p><p id="0e67" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">也可以<strong class="kv jf">以较小的步长多次应用fgsm</strong>并对总数进行限幅，同时使干净样本和对立样本之间的失真低于ϵ.</p><figure class="oe of og oh gt iv gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/0c4b760e8c1be0815e3859d063ce7d1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*-lmxs-VFkYJKqUR-tJU9Zw.png"/></div></figure><p id="b37d" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><a class="ae nk" href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Arjun_Nitin_Bhagoji_Practical_Black-box_Attacks_ECCV_2018_paper.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="kv jf">转移抗辩示例</strong> </a></p><p id="4475" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">上面描述的大多数技术都假设攻击者知道所使用的模型。它们属于所谓的<strong class="kv jf">白盒攻击</strong>，与<strong class="kv jf">黑盒攻击</strong>相对。然而，在现实生活中，情况并非总是如此。</p><p id="bfde" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">那么，攻击者通常采用哪些技术呢？</p><p id="435f" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">对手可以通过探测来重建模型，即向模型发送有效的和敌对的例子并观察输出。这使得他能够形成数据集，该数据集可用于训练<strong class="kv jf">替代模型</strong>。然后，可以使用白盒算法来实现对抗性示例的生成。</p><p id="8e73" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">然而，在某些情况下，探测可能会受到被接受的查询的最大数量或对手产生的成本的限制。为了处理这个问题，对手可以生成对抗性的例子来欺骗分类器，并同时训练另一个模型。然后，他可以重复使用这些对立的例子来愚弄多个不同的分类器。</p><p id="f0fb" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">注意，使用通过模型生成的对立例子来欺骗黑盒模型是可能的，并且依赖于<strong class="kv jf">转移属性</strong>。</p><p id="7b49" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><a class="ae nk" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank"> <strong class="kv jf">【乾坤】</strong> </a></p><p id="6726" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">生成敌对网络(GANs)完全依赖于一种<strong class="kv jf">博弈论方法。</strong>在这些模型中，扰动的例子从对手那里生成，同时用于训练学习者的模型，如下图所示。</p><figure class="oe of og oh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ow"><img src="../Images/9f0b07df2f4acda857592b02bfe6f5b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5sMEepHJM_QRFwyyzsjjmg.png"/></div></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">生成对抗性网络框架，来源:文章来自<a class="ae nk" href="https://www.freecodecamp.org/news/an-intuitive-introduction-to-generative-adversarial-networks-gans-7a2264a81394/" rel="noopener ugc nofollow" target="_blank"> FreeCodeCamp </a>，Thalles Silva</p></figure><p id="d06c" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">如上图所示，学习者使用的函数称为<strong class="kv jf">鉴别器</strong>，而对手函数使用的函数称为<strong class="kv jf">生成器</strong>。</p><p id="5222" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">鉴别器和发生器通过零和游戏相互作用<strong class="kv jf">，因为它们都在寻求优化不同的和相反的目标函数，或损失函数。</strong></p><p id="cf23" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在这种情况下，鉴别器和生成器<strong class="kv jf">分别不断调整</strong>它们的预测和数据损坏机制。</p><h1 id="83e0" class="mn mo je bd mp mq mr ms mt mu mv mw mx kk my kl mz kn na ko nb kq nc kr nd ne bi translated">结论</h1><p id="a2fa" class="pw-post-body-paragraph kt ku je kv b kw nf kf ky kz ng ki lb lc nh le lf lg ni li lj lk nj lm ln lo im bi translated">如今，随着个人和企业拥抱数字革命，人工智能算法越来越多地用于解决多种背景下的复杂问题，其中一些可能会有很高的风险。</p><p id="59e6" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">因此，当他们在敌对环境中面临对抗性攻击时，不要低估他们的弱点是很重要的。</p><blockquote class="nx ny nz"><p id="e123" class="kt ku ly kv b kw kx kf ky kz la ki lb oa ld le lf ob lh li lj oc ll lm ln lo im bi translated">这些<strong class="kv jf">例子</strong>就像它们揭示的一样多:用于访问私人空间或有价值信息的图像识别系统，保护个人和公司财富的欺诈检测算法，等等。</p></blockquote><p id="e1e7" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在这种情况下，博弈论为对手和学习者的行为建模提供了<strong class="kv jf">有用的工具</strong>，因为它一方面包括对手攻击的收益和生成对手数据的成本，另一方面包括学习者更新模型的成本。</p><p id="ebc5" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">因此，基于博弈论的方法揭示了对手和学习者都做出的权衡，并可用于评估实施特定技术的风险。因此，它是一个<strong class="kv jf">强大的决策</strong>工具，需要在类似的环境中更广泛地使用。</p><h1 id="3e65" class="mn mo je bd mp mq mr ms mt mu mv mw mx kk my kl mz kn na ko nb kq nc kr nd ne bi translated">参考</h1><p id="e624" class="pw-post-body-paragraph kt ku je kv b kw nf kf ky kz ng ki lb lc nh le lf lg ni li lj lk nj lm ln lo im bi translated">[1] W. Liu和S. Chawla，<a class="ae nk" href="https://ieeexplore.ieee.org/document/5360532" rel="noopener ugc nofollow" target="_blank"> <em class="ly">对抗性学习的博弈理论模型</em> </a>，2009年IEEE国际数据挖掘研讨会，佛罗里达州迈阿密，2009年，第25–30页。</p><p id="2003" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">[2] P. Dasgupta，J. B. Collins，<a class="ae nk" href="https://arxiv.org/abs/1912.02258" rel="noopener ugc nofollow" target="_blank"> <em class="ly">网络安全任务中对抗性机器学习的博弈论方法调查</em> </a> <em class="ly">，</em>信息管理&amp;决策架构(IMDA)分部，美国华盛顿特区美国海军研究实验室信息技术部，<em class="ly"/>2019年12月</p><p id="245e" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">[3] N .达尔维等人，<a class="ae nk" href="https://homes.cs.washington.edu/~pedrod/papers/kdd04.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="ly">对抗性分类</em> </a>，西雅图华盛顿大学计算机科学与工程系，2004年8月</p><p id="86ef" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">[4] P. L .巴霍，<a class="ae nk" href="https://www.toptal.com/machine-learning/adversarial-machine-learning-tutorial" rel="noopener ugc nofollow" target="_blank"> <em class="ly">对抗性机器学习:如何攻防ML模型</em> </a></p><p id="8818" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">[5] C. Molnar，<a class="ae nk" href="https://christophm.github.io/interpretable-ml-book/adversarial.html" rel="noopener ugc nofollow" target="_blank"> <em class="ly">可解释的机器学习</em> </a>，<em class="ly">制作黑盒模型的指南可解释的</em>，2020年4月</p><p id="3003" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">【6】s . sa xena，<a class="ae nk" href="https://www.analyticsvidhya.com/blog/2019/11/game-theory-ai/" rel="noopener ugc nofollow" target="_blank"> <em class="ly">游戏(理论)对于AI？给大家一个图文并茂的指南</em></a><em class="ly"/>2019年11月</p></div></div>    
</body>
</html>