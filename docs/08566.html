<html>
<head>
<title>A minimal example combining H2O’s AutoML and Shapley’s decomposition in R</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">R 中结合 H2O 自动分解和沙普利分解的一个极小例子</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-minimal-example-combining-h2os-automl-and-shapley-s-decomposition-in-r-ba4481282c3c?source=collection_archive---------44-----------------------#2020-06-21">https://towardsdatascience.com/a-minimal-example-combining-h2os-automl-and-shapley-s-decomposition-in-r-ba4481282c3c?source=collection_archive---------44-----------------------#2020-06-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/2ff3ee9bfdad1026eef46e8021c208b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KMlEk1lozeJY0xln"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">Borna Bevanda 在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><p id="94a5" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">作为巴西一家大型金融机构的数据科学家，每天都要为业务的许多不同方面构建预测模型，这是很常见的。这取决于问题规模、数据类型、时间可用性等。，我的方法可以从开发快速和肮脏的模型(例如，基线逻辑回归)到更复杂(也许更精确)的模型。这两种方法都很有价值，在权衡每个问题的成本效益及其潜力时，都应该加以考虑。</p><p id="55a1" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">作为一名经常使用 R 的用户，我最喜欢的机器学习方法之一是将 AutoML 的 H2O 框架的预测建模能力与 Shapley 值的可解释性结合起来。虽然有很多关于这两种技术的在线教程/解释(对于 H2O，我推荐艾琳·莱德尔的视频，比如这个:【https://www.youtube.com/watch?v=DjzKTeIIxOY】，对于沙普利的价值观，斯科特·伦德伯格的视频，比如这个<a class="ae jg" href="https://www.youtube.com/watch?v=ngOBhhINWb8" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=ngOBhhINWb8</a>)，博客帖子，笔记本等等。，我从来没有找到一种材料能以简洁的方式将它们结合在一起。</p><p id="8a31" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇博客文章是我构建的一个方便的脚本中的一个演练，我偶尔会为机器学习任务重新访问这个脚本(该脚本可在<a class="ae jg" href="https://github.com/renanxcortes/SHAP_with_H2O_AutoML/blob/master/SHAP_with_H2O_AutoML.R" rel="noopener ugc nofollow" target="_blank">https://github . com/renanxcortes/SHAP _ with _ H2O _ AutoML/blob/master/SHAP _ with _ H2O _ AutoML 获得。R </a>)。其思想是在拟合后，使用 AutoML 和 Shapley 的可解释性值逐步解释模型估计的整个过程。</p><p id="6c8f" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你准备好了吗？所以，让我们开始吧！</p><figure class="le lf lg lh gt iv"><div class="bz fp l di"><div class="li lj l"/></div></figure></div><div class="ab cl lk ll hx lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="im in io ip iq"><p id="c823" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们首先加载所需的库:</p><pre class="le lf lg lh gt lr ls lt lu aw lv bi"><span id="ee90" class="lw lx jj ls b gy ly lz l ma mb">library(h2o)<br/>library(tidyverse)<br/>library(ggbeeswarm)</span></pre><p id="beea" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因为我想尽可能保持简单，所以让我们为具有五个协变量的二元分类问题构建一个数据框架:</p><pre class="le lf lg lh gt lr ls lt lu aw lv bi"><span id="83e3" class="lw lx jj ls b gy ly lz l ma mb">df &lt;- tibble(y = rep(c(0,1), c(1000,1000)),<br/>x1 = rnorm(2000),<br/>x2 = rf(2000, df1 = 5, df2 = 2),<br/>x3 = runif(2000),<br/>x4 = c(sample(rep(c('A', 'B', 'C'), c(300, 300, 400))),                     sample(c('A', 'B', 'C'), 1000, prob = c(0.25, 0.25, 0.5), replace = T)),<br/>x5 = c(rnorm(1000), rnorm(1000, 0.25)))</span></pre><p id="463c" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，作为中间步骤，H2O 的框架需要处理因子而不是字符。因此，让我们改变一些变量的类:</p><pre class="le lf lg lh gt lr ls lt lu aw lv bi"><span id="8d43" class="lw lx jj ls b gy ly lz l ma mb">df &lt;- df %&gt;%   <br/>mutate(y = as.factor(y)) %&gt;%   <br/>mutate_if(is.character, factor)</span></pre><p id="0feb" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来的三个步骤分别是:在 R 会话中启动 H2O 实例，将数据框转换为 H2O 数据框，以及将数据拆分为定型集和维持集。</p><pre class="le lf lg lh gt lr ls lt lu aw lv bi"><span id="3927" class="lw lx jj ls b gy ly lz l ma mb">h2o.init() <br/>df_frame &lt;- as.h2o(df) <br/>df_frame_split &lt;- h2o.splitFrame(df_frame, ratios = 0.8)</span></pre><p id="de34" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">值得注意的是，在分割画面时，H2O 并没有给出精确的分割。它旨在使用概率分割方法而不是精确分割来高效处理大数据。</p><p id="d2cc" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，时候到了！鉴于我们之前运行的步骤，是时候拟合机器学习模型了。下面的代码完成了这个任务:</p><pre class="le lf lg lh gt lr ls lt lu aw lv bi"><span id="9562" class="lw lx jj ls b gy ly lz l ma mb"># Metric for binary classification (deviance is the default). Check documentation here <a class="ae jg" href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html" rel="noopener ugc nofollow" target="_blank">http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html</a><br/>automl_model &lt;- h2o.automl(y = 'y',<br/>balance_classes = TRUE,<br/>training_frame = df_frame_split[[1]],<br/>nfolds = 4,<br/>leaderboard_frame = df_frame_split[[2]],<br/>max_runtime_secs = 60 * 2,<br/>include_algos = c('DRF', 'GBM', 'XGBoost'),<br/>sort_metric = "AUC")</span></pre><p id="5237" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">好吧…深呼吸，因为这里发生了很多事情。我强烈建议您看一下官方文档，键入<code class="fe mc md me ls b">help(h2o.automl)</code>可以更好地了解每个参数设置。我想强调其中一些我认为至关重要的因素:</p><ul class=""><li id="f952" class="mf mg jj ki b kj kk kn ko kr mh kv mi kz mj ld mk ml mm mn bi translated"><strong class="ki jk"> include_algos </strong>:首先也是更重要的，由于 Shapley 的值分解是为基于树的模型开发的，这篇博文的王牌就是通过设置<code class="fe mc md me ls b">include_algos = c('DRF', 'GBM', 'XGBoost')</code>来限制算法。这样，AutoML 将保证生成的最佳模型对于第二阶段的 Shapley 值生成是可行的；</li><li id="7cab" class="mf mg jj ki b kj mo kn mp kr mq kv mr kz ms ld mk ml mm mn bi translated"><strong class="ki jk"> max_runtime_secs </strong>:其次，一个很重要的论点是<code class="fe mc md me ls b">max_runtime_secs</code>。这是功能运行的最长时间，以秒为单位。如果您有复杂和/或大型数据集，并且有时间等待更准确的模型，则可以将设置为更大的值；</li><li id="adee" class="mf mg jj ki b kj mo kn mp kr mq kv mr kz ms ld mk ml mm mn bi translated"><strong class="ki jk"> sort_metric </strong>:最后，我想强调一下<code class="fe mc md me ls b">sort_metric</code>参数，可以根据您的喜好或机器学习问题对其他度量进行调整(例如，对于回归模型，您可以设置<code class="fe mc md me ls b">sort_metric = "RMSE"</code>)。</li></ul><p id="27bb" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">关于<code class="fe mc md me ls b">h2o.automl</code>最酷的事情之一是它生成了一个排行榜，非常类似于 Kaggle 的排行榜对模特进行排名:</p><pre class="le lf lg lh gt lr ls lt lu aw lv bi"><span id="ee69" class="lw lx jj ls b gy ly lz l ma mb">lb &lt;- as.data.frame(automl_model@leaderboard)</span></pre><figure class="le lf lg lh gt iv gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/297615687d9bbda31768cbabf31cf994.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*sKubxS3bRbq-R53MNjW2pg.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">排行榜的第一行是在这个简单的例子中产生的</p></figure><p id="3fe5" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以提取领导者模型:</p><pre class="le lf lg lh gt lr ls lt lu aw lv bi"><span id="1479" class="lw lx jj ls b gy ly lz l ma mb">aml_leader &lt;- automl_model@leader</span></pre><p id="411d" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，我们计算并绘制 Shapley 值，以获得每个特征如何影响 leader 模型中因变量的总体概述，代码片段如下:</p><pre class="le lf lg lh gt lr ls lt lu aw lv bi"><span id="a83f" class="lw lx jj ls b gy ly lz l ma mb"># SHAP values: http://docs.h2o.ai/h2o/latest-stable/h2o-r/docs/reference/predict_contributions.H2OModel.html <br/>SHAP_values &lt;- predict_contributions.H2OModel(aml_leader, df_frame_split[[2]]) </span><span id="755f" class="lw lx jj ls b gy mu lz l ma mb"># Wrangling inspired here: https://bradleyboehmke.github.io/HOML/iml.html </span><span id="de7a" class="lw lx jj ls b gy mu lz l ma mb">shap_df &lt;- SHAP_values %&gt;%  <br/>as.data.frame() %&gt;%  <br/>select(-BiasTerm) %&gt;%  <br/>gather(feature, shap_value) %&gt;%  <br/>group_by(feature) %&gt;%  <br/>mutate(shap_importance = mean(abs(shap_value)),         <br/>shap_force = mean(shap_value)) %&gt;%   <br/>ungroup() # SHAP contribution plot</span><span id="8766" class="lw lx jj ls b gy mu lz l ma mb">p1 &lt;- ggplot(shap_df, aes(x = shap_value, y = reorder(feature, shap_importance))) +  <br/>ggbeeswarm::geom_quasirandom(groupOnX = FALSE, varwidth = TRUE, size = 0.9, alpha = 0.5, width = 0.15) +  <br/>xlab("SHAP value") +  <br/>ylab(NULL) +  <br/>theme_minimal(base_size = 15) # SHAP importance plot</span><span id="28da" class="lw lx jj ls b gy mu lz l ma mb">p2 &lt;- shap_df %&gt;%   <br/>select(feature, shap_importance) %&gt;%  <br/>distinct() %&gt;%   <br/>ggplot(aes(x = reorder(feature, shap_importance),              <br/>y = shap_importance)) +  <br/>geom_col(fill = 'black') +  <br/>coord_flip() +  <br/>xlab(NULL) +  <br/>ylab("mean(|SHAP value|)") +  <br/>theme_minimal(base_size = 15) # Combine plots</span><span id="39ec" class="lw lx jj ls b gy mu lz l ma mb">gridExtra::grid.arrange(p1, p2, nrow = 1)</span></pre><figure class="le lf lg lh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mv"><img src="../Images/3fce63850cafce2705472d2e6600e0fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l0A0Td3ttAq_5YtslzFSQA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">全球重要性的两个主要图</p></figure><p id="72a5" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然 Shapley 的值在分析局部观测值时更直观，但检查这些全局属性也是有意义的。左侧的图表描述了维持集中每个功能的所有 Shapley 值的分布。可以看出，<strong class="ki jk"> x5 </strong>具有大多数 Shapley 值负值，并且具有更宽的分布，表明其在预测能力或模型中的重要性，而<strong class="ki jk"> x2 </strong>是“不太重要的”。右侧的<em class="mw">重要性图</em>中的图表也加强了这一点，该图由分解的所有绝对值的平均值给出。</p><p id="df5c" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">此外，还可以为每个特性的值构建部分相关图。让我们来看看最重要的特征是如何与因变量相关的:</p><pre class="le lf lg lh gt lr ls lt lu aw lv bi"><span id="4477" class="lw lx jj ls b gy ly lz l ma mb"># Shapley-based dependence plots for a numerical feature<br/>SHAP_values %&gt;%<br/>  as.data.frame() %&gt;%<br/>  select(-BiasTerm) %&gt;% <br/>  mutate(x5_feature_values = as.vector(df_frame_split[[2]]$x5)) %&gt;% <br/>  ggplot(aes(x = x5_feature_values, y = x5)) +<br/>  geom_point(aes(color = x5), width = 0.1) +<br/>  scale_colour_gradient(low = "red", high = "blue", name = 'SHAP values') +<br/>  ylab('Shapley\'s values for x5 feature') +<br/>  xlab('x5 values') +<br/>  theme_minimal(base_size = 15) +<br/>  geom_smooth()</span></pre><figure class="le lf lg lh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mx"><img src="../Images/6a4d167d2b31be9060bafb7de0c0ed67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R4bVg5gx4Y9uo2TZ4wCHfw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">x5 特征的部分相关图:非线性关系</p></figure><p id="3d99" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上图描绘了特征<strong class="ki jk"> x5 </strong>和其 Shapley 值之间明显的非线性关系。</p><p id="5753" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">此外，对于范畴特征，这种情节也是令人感兴趣的:</p><pre class="le lf lg lh gt lr ls lt lu aw lv bi"><span id="fcca" class="lw lx jj ls b gy ly lz l ma mb"># Shapley-based dependence plots for a categorical feature<br/>SHAP_values %&gt;%<br/>  as.data.frame() %&gt;%<br/>  select(-BiasTerm) %&gt;% <br/>  mutate(x4_feature_values = as.vector(df_frame_split[[2]]$x4)) %&gt;% <br/>  ggplot(aes(x = x4_feature_values, y = x4)) +<br/>  geom_jitter(aes(color = x4), width = 0.1) +<br/>  scale_colour_gradient(low = "red", high = "blue", name = 'SHAP values') +<br/>  ylab('Shapley\'s values for x4 feature') +<br/>  xlab('x4 feature classes') +<br/>  theme_minimal(base_size = 15)</span></pre><figure class="le lf lg lh gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi my"><img src="../Images/12a897fd07aa4a79d5ed1b51c08a25b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-neOIxm9gYl6BQW8D1eMNw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">x4 特征的部分相关图:C 类高于其他类</p></figure><p id="c331" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以看到，类别 C 与因变量的较高值相关联，在本例中，因变量是“成功”的较高概率(y = 1)。</p><p id="0874" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki jk"> <em class="mw">收尾</em> </strong></p><p id="ad94" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇文章描述了一个使用 R-数据科学中最常用的语言之一-的最小示例，用于使用 H2O 的 AutoML 和沙普利的值拟合机器学习模型。由于 H2O 的 AutoML 工具具有广泛的预测模型，这种方法的关键点是通过设置<code class="fe mc md me ls b">include_algos = c('DRF', 'GBM', 'XGBoost')</code>将模型搜索限制为仅基于树。此外，为了说明这种方法的可解释性，使用了 Shapley 值、全局重要性图和部分相关性图。</p></div><div class="ab cl lk ll hx lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="im in io ip iq"><p id="eb75" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你喜欢你读到的东西吗？推荐/分享这篇文章，让别人也能看到！还有 ，<strong class="ki jk"> <em class="mw">有什么意见或建议，不要犹豫和我联系！随时欢迎反馈！</em> </strong></p><p id="f71a" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mw">通过</em><a class="ae jg" href="https://www.linkedin.com/in/renan-cortes-a3583a33/" rel="noopener ugc nofollow" target="_blank"><em class="mw">Linkedin</em></a><em class="mw">，</em><a class="ae jg" href="https://twitter.com/renanxcortes" rel="noopener ugc nofollow" target="_blank"><em class="mw">Twitter</em></a><em class="mw">，</em><a class="ae jg" href="https://github.com/renanxcortes" rel="noopener ugc nofollow" target="_blank"><em class="mw">Github</em></a><em class="mw">。另外，你可以看看我的</em> <a class="ae jg" href="https://renanxcortes.github.io/" rel="noopener ugc nofollow" target="_blank"> <em class="mw">网站</em> </a> <em class="mw">。</em></p></div><div class="ab cl lk ll hx lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="im in io ip iq"><p id="ef97" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于 H2O 在幕后依赖于 Java，为了让它正常工作，您可能需要它。更多信息请访问<a class="ae jg" href="https://docs.h2o.ai/h2o/latest-stable/h2o-docs/downloading.html" rel="noopener ugc nofollow" target="_blank">https://docs . H2O . ai/H2O/latest-stable/H2O-docs/downloading . html</a>。</p><p id="5fd0" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">很容易在不考虑绝对值的情况下检查这些方法，试图检查每个特征的“总体方向”。但是，应考虑绝对值，而不是原始的正值和负值，因为正如 Scott Lundberg 所解释的那样，<em class="mw">“正值和负值都很重要，但是如果在测量全局特征重要性时允许它们相互抵消，那么您将不会测量特征对于模型的重要性，而是测量每个特征在您解释的样本和您的背景样本集之间的影响有多大不同。”<a class="ae jg" href="https://github.com/slundberg/shap/issues/696#issuecomment-581993726" rel="noopener ugc nofollow" target="_blank">中提到的</a></em>https://github . com/slund Berg/shap/issues/696 # issue comment-581993726。</p></div></div>    
</body>
</html>