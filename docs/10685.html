<html>
<head>
<title>DeepStyle (Part 1): Using State-of-the-Art Deep Learning to Generate Realistic High Fashion Clothing and Style</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">DeepStyle(第 1 部分):使用最先进的深度学习生成现实的高级时尚服装和风格</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deepstyle-f8557ab9e7b?source=collection_archive---------20-----------------------#2020-07-26">https://towardsdatascience.com/deepstyle-f8557ab9e7b?source=collection_archive---------20-----------------------#2020-07-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1a5d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">提供<a class="ae ki" href="https://github.com/itsuncheng/DeepStyle/blob/master/full_paper.pdf" rel="noopener ugc nofollow" target="_blank">纸</a>和<a class="ae ki" href="https://github.com/itsuncheng/DeepStyle/" rel="noopener ugc nofollow" target="_blank"> github 代码</a>！点击<a class="ae ki" rel="noopener" target="_blank" href="/deepstyle-part-2-4ca2ae822ba0">此处</a>进入第二部分。</h2></div><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi kj"><img src="../Images/d7bd255bcea04c9b7842a2542b80a5bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GF6XODpdba5qoFKX.jpg"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">模特走秀(<a class="ae ki" href="https://pixabay.com/photos/fashion-show-fashion-catwalk-model-1746582/" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="b613" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是我在 2019 年春天在我的家乡大学<a class="ae ki" href="http://www.ust.hk/home" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">香港科技大学</strong> </a>为计算机视觉<strong class="lb iu">深度学习</strong>课程做的一个项目。那时候，我正在慢慢了解时尚和风格的世界:如何穿得更好，跟上现代潮流。我开始观看高级时尚奢侈品牌的时装秀，甚至街上随便一个人都知道。迪奥、古驰、路易威登、香奈儿、爱马仕、乔治·阿玛尼、卡地亚、博柏利等等。随着我看得越来越多，我开始逐渐融入时尚界。当我需要为我的计算机视觉课程想出一个最终项目主题的时候，我想，<strong class="lb iu">为什么不创建一个深度学习系统</strong>，它将能够<strong class="lb iu">生成好看且有创意的高级时装</strong>？想象一下会很有趣，对吗？</p><p id="d1aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以我和我的队友创造了<strong class="lb iu">深度风格</strong>。</p><h1 id="ccb0" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">什么是 DeepStyle？</h1><p id="e7ba" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">简而言之，<strong class="lb iu"> DeepStyle </strong>就是具有生成高级时尚服装单品能力的定制深度学习框架。它可以作为时装设计师的灵感，也可以预测时装业的下一个流行项目。DeepStyle 吸收流行时尚图片，并创造新的产品，作为有效预测未来趋势的一种方式。</p><p id="b3d0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的研究包括两个部分:<strong class="lb iu">建立高级奢侈品时尚数据库，并使用人工智能生成类似的时尚物品</strong>。第一部分，我们需要一个可靠的来源，在那里我们可以收集所有来自 t 台的<strong class="lb iu">高级奢华时尚图片</strong>。但除此之外，我们还希望有一个<strong class="lb iu">模型，可以识别服装</strong>和<strong class="lb iu">裁剪</strong>出图像的其余部分，因为最终，如果我们在后台生成假的模型和观众，那会很奇怪😂。在我们将图像裁剪为仅包含服装本身之后，我们可以将图像输入到另一个模型中，该模型将能够<strong class="lb iu">从头开始生成新的服装</strong>。裁剪图像对于尽可能去除噪声至关重要。</p><h1 id="7078" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">框架</h1><p id="1006" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在简要分析了我们试图构建的东西之后，这里有一个粗略的框架。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/08ed8476e3b10ad89378b2dab5d29bba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/0*IkZG39yzQS9qezuP"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">深度风格框架</p></figure><p id="f09d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">DeepStyle 的第一部分包含<a class="ae ki" href="https://arxiv.org/pdf/1506.01497.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">更快的 R-CNN </strong> </a> <strong class="lb iu"> </strong>这是一个实时对象检测模型，已经证明使用其<a class="ae ki" href="https://arxiv.org/pdf/1506.01497.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">区域提议网络</strong> </a>可以达到最先进的准确性。你可以在这里阅读官方文件<a class="ae ki" href="https://arxiv.org/pdf/1506.01497.pdf" rel="noopener ugc nofollow" target="_blank">了解更多细节。我们将用香港中文大学发布的</a><a class="ae ki" href="http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">深度时尚数据库</strong> </a>来训练我们更快的 R-CNN。</p><p id="ca9e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">深度时尚数据库的快速介绍:这是迄今为止最大的时尚数据集，由大约 80 万张不同的时尚图片组成，这些图片具有不同的背景、角度、光线条件等。这个数据集由四个用于不同目的的基准组成，我们在项目中使用的是<a class="ae ki" href="http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion/AttributePrediction.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">类别和属性预测基准</strong> </a>。该基准具有<strong class="lb iu"> 289，222 幅服装图像</strong>，每幅图像都由包围盒坐标和相应的服装类别标注。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi mt"><img src="../Images/fbd86ae6ffd11efd888650ebfc723d11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HC6gJ8FO4Uo1Td0X"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated"><strong class="bd mu">deep fashion 数据库<a class="ae ki" href="http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html" rel="noopener ugc nofollow" target="_blank">来源</a>的类别和属性预测基准</strong></p></figure><p id="6c59" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在对 DeepFashion 数据库训练更快的 R-CNN 后，该网络将能够预测服装在哪里，给定任何测试图像。这就是 Pinterest 数据库 出现的地方。我们可以建立一个刮刀，从 Pinterest 上刮下几个大型奢侈品牌的高级时装秀，并将其用作我们更快的 R-CNN 的测试图像。我们之所以选择 Pinterest，是因为 Pinterest 提供了大量干净、高质量的图片，而且也很容易刮。</p><p id="fb15" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">经过推理，Pinterest 图像的边界框将被预测，图像的其余部分可以被裁剪掉，因为我们只需要特定的项目。然后，我们最终将它传递给我们的<strong class="lb iu">时尚 GAN </strong>，它将使用<a class="ae ki" href="https://arxiv.org/pdf/1511.06434.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> DCGAN </strong> </a> <strong class="lb iu"> </strong>或深度卷积生成对抗网络来实现。另一个<a class="ae ki" href="https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf" rel="noopener ugc nofollow" target="_blank">甘</a>的快速教程:一个生成式对抗网络基本上包含两个主要组件:生成器和鉴别器。生成器努力创建看起来真实的图像，而鉴别器试图区分真实图像和虚假图像。在训练过程中，随着时间的推移，发生器在生成真实图像方面变得更好，而鉴别器在辨别真假方面变得更好。当鉴别者不再能判断出发生器产生的图像是真是假时，就达到了最终的平衡。</p><p id="c3e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最终结果是由 DCGAN 产生的一组图像。希望它们看起来很时尚！</p><h1 id="f3c1" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">履行</h1><h2 id="abb6" class="mv lw it bd lx mw mx dn mb my mz dp mf li na nb mh lm nc nd mj lq ne nf ml ng bi translated">步骤 1 安装 Detectron 和 DeepFashion 数据集</h2><p id="e8f5" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">为了实现更快的 R-CNN，我们将使用由<a class="ae ki" href="https://ai.facebook.com/" rel="noopener ugc nofollow" target="_blank">脸书 AI </a>提供的<a class="ae ki" href="https://github.com/facebookresearch/detectron" rel="noopener ugc nofollow" target="_blank"> Detectron 库</a>。Detectron 库包含用于实现最先进的对象检测算法的代码，如更快的 R-CNN、Mask R-CNN、Retina-Net 等。可以通过以下步骤安装官方库:</p><p id="188e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据您的 CUDA 版本安装 Caffe2</p><ol class=""><li id="8d42" class="nh ni it lb b lc ld lf lg li nj lm nk lq nl lu nm nn no np bi translated">对于支持 CUDA 9 和 CuDNN 7 的 Caffe2:</li></ol><pre class="kk kl km kn gt nq nr ns nt aw nu bi"><span id="339e" class="mv lw it nr b gy nv nw l nx ny">conda install pytorch-nightly -c pytorch</span></pre><p id="f595" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.对于支持 CUDA 8 和 CuDNN 7 的 Caffe2:</p><pre class="kk kl km kn gt nq nr ns nt aw nu bi"><span id="0bc7" class="mv lw it nr b gy nv nw l nx ny">conda install pytorch-nightly cuda80 -c pytorch</span></pre><p id="d8ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">安装了 Caffe2 之后，现在继续安装 COCO API。</p><pre class="kk kl km kn gt nq nr ns nt aw nu bi"><span id="5949" class="mv lw it nr b gy nv nw l nx ny"># COCOAPI=/path/to/clone/cocoapi<br/>git clone https://github.com/cocodataset/cocoapi.git $COCOAPI<br/>cd $COCOAPI/PythonAPI<br/># Install into global site-packages<br/>make install<br/># Alternatively, if you do not have permissions or prefer<br/># not to install the COCO API into global site-packages<br/>python setup.py install --user</span></pre><p id="63a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，你可以下载官方回购并安装 Detectron。</p><pre class="kk kl km kn gt nq nr ns nt aw nu bi"><span id="f0e6" class="mv lw it nr b gy nv nw l nx ny">git clone <a class="ae ki" href="https://github.com/facebookresearch/Detectron.git" rel="noopener ugc nofollow" target="_blank">https://github.com/facebookresearch/Detectron.git</a></span></pre><p id="76ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以通过以下方式安装 Python 依赖项:</p><pre class="kk kl km kn gt nq nr ns nt aw nu bi"><span id="f818" class="mv lw it nr b gy nv nw l nx ny">cd Detectron<br/>pip install -r requirements.txt</span></pre><p id="5d9f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过以下方式设置 Python 模块:</p><pre class="kk kl km kn gt nq nr ns nt aw nu bi"><span id="4624" class="mv lw it nr b gy nv nw l nx ny">make</span></pre><p id="f987" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以通过以下方式验证 Detectron 是否已成功安装:</p><pre class="kk kl km kn gt nq nr ns nt aw nu bi"><span id="01e1" class="mv lw it nr b gy nv nw l nx ny">python detectron/tests/test_spatial_narrow_as_op.py</span></pre><p id="40a2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">更多安装细节，可以参考<a class="ae ki" href="https://github.com/facebookresearch/Detectron/blob/master/INSTALL.md" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="f638" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nz">注:脸书 AI 最近发布了</em><a class="ae ki" href="https://github.com/facebookresearch/detectron2" rel="noopener ugc nofollow" target="_blank"><em class="nz">Detectron 2</em></a><em class="nz">，是 Detectron 的更新版本。我在做这个项目的时候用过 Detectron，如果你愿意，你可以看看 Detectron 2。</em></p><p id="466a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们要下载<a class="ae ki" href="http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html" rel="noopener ugc nofollow" target="_blank"> DeepFashion 数据集</a>。你可以从他们的<a class="ae ki" href="http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html" rel="noopener ugc nofollow" target="_blank">主页</a>阅读更多关于数据集的细节。你可以从谷歌硬盘上下载数据集。我们想要的是类别和属性预测基准，可以从<a class="ae ki" href="https://drive.google.com/drive/folders/0B7EVK8r0v71pWGplNFhjc01NbzQ" rel="noopener ugc nofollow" target="_blank">这里</a>下载。</p><h2 id="b29d" class="mv lw it bd lx mw mx dn mb my mz dp mf li na nb mh lm nc nd mj lq ne nf ml ng bi translated">步骤 2 将 DeepFashion 数据集转换为 COCO 格式</h2><p id="372b" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">为了使用 Detectron 的自定义数据集训练模型，我们必须首先将数据集转换成<a class="ae ki" href="https://cocodataset.org/#home" rel="noopener ugc nofollow" target="_blank"> COCO 格式</a>。COCO 是一个大规模的对象检测、分割和字幕数据集，也是对象检测数据集的标准格式。我们可以使用以下代码将 DeepFashion 数据集转换为 COCO 格式:</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="6938" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">COCO 基本上将数据集的轮廓保存在一个<code class="fe oc od oe nr b">.json</code>文件中，该文件包括关于对象检测数据集的基本信息。最值得注意的是<code class="fe oc od oe nr b">coco_dict['images']</code>和<code class="fe oc od oe nr b">coco_dict['annotations']</code>,它们分别给出了图像及其相应注释的信息。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi of"><img src="../Images/ddeba599b457be6f395bb7b13739f032.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2cfcn-2Aw-RoG_ltNXNWIg.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">DeepFashion 数据库到 COCO 输出</p></figure><h2 id="46bf" class="mv lw it bd lx mw mx dn mb my mz dp mf li na nb mh lm nc nd mj lq ne nf ml ng bi translated">在 DeepFashion 上训练更快的 R-CNN 模型</h2><p id="b5a0" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在成功地将数据集转换成 COCO 格式后，我们终于可以训练我们更快的 R-CNN 模型了！在此之前，我们需要首先选择我们想要使用的更快的 R-CNN 的具体变体。有大量<strong class="lb iu">端到端</strong>更快的 R-CNN 变体供我们选择:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi og"><img src="../Images/b3a15c553596c7657ae725f0bc7d9660.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2b6xmRZJFN8XXhOVhZuKCA.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">支持更快的 R-CNN 型号(<a class="ae ki" href="https://github.com/facebookresearch/Detectron/blob/master/MODEL_ZOO.md" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="a9a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当时，我训练了三种不同的变体:R-50-FPN_1x，R-101-FPN_1x，X-101–32x8d-FPN _ 1x。然而，为了简单说明的目的，我将只告诉你如何训练 R-50-FPN，因为步骤是相同的。你可以通过访问<a class="ae ki" href="https://github.com/facebookresearch/Detectron/blob/master/MODEL_ZOO.md" rel="noopener ugc nofollow" target="_blank">这里</a>获得 Detectron 支持的型号列表。</p><p id="0024" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们决定使用更快的 R-CNN R-50-FPN_1x 后，我们可以前往<code class="fe oc od oe nr b">configs/12_2017_baselines/</code>查看提供的现有模型配置。我们可以找到我们想要的——它被命名为<code class="fe oc od oe nr b"><a class="ae ki" href="https://github.com/facebookresearch/Detectron/blob/master/configs/12_2017_baselines/e2e_faster_rcnn_R-50-FPN_1x.yaml" rel="noopener ugc nofollow" target="_blank">e2e_faster_rcnn_R-50-FPN_1x.yaml</a></code>。在那里你可以看到并根据我们的意愿修改模型和训练配置。</p><p id="708c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最重要的是将训练和测试数据集改为我们的 DeepFashion 数据集，它已经是 COCO 格式了。我们还可以将规划求解参数更改为我们想要的参数。我的看起来像这样:</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="0d79" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们选择完模型及其配置后，现在我们终于可以开始训练这个模型了！根据您拥有的 GPU 数量，您可以通过执行以下命令开始培训:</p><ol class=""><li id="ae25" class="nh ni it lb b lc ld lf lg li nj lm nk lq nl lu nm nn no np bi translated"><strong class="lb iu">单 GPU 训练</strong></li></ol><pre class="kk kl km kn gt nq nr ns nt aw nu bi"><span id="9085" class="mv lw it nr b gy nv nw l nx ny">python tools/train_net.py \<br/>    --cfg configs/12_2017_baselines/e2e_faster_rcnn_R-50-FPN_1x.yaml \<br/>    OUTPUT_DIR <!-- -->[path/to/output/]</span></pre><p id="4242" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.<strong class="lb iu">多 GPU 支持</strong></p><pre class="kk kl km kn gt nq nr ns nt aw nu bi"><span id="69f0" class="mv lw it nr b gy nv nw l nx ny">python tools/train_net.py \<br/>    --multi-gpu-testing \<br/>    --cfg configs/12_2017_baselines/e2e_faster_rcnn_R-50-FPN_1x.yaml \<br/>    OUTPUT_DIR <!-- -->[path/to/output/]</span></pre><p id="be6e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">运行上面的任何一个命令后，指定为<code class="fe oc od oe nr b">--cfg</code>的模型将开始训练。包括模型参数、验证集检测等的输出。会保存在<code class="fe oc od oe nr b">/tmp/detectron-output</code>下。更多训练细节，可以参考<a class="ae ki" href="https://github.com/facebookresearch/Detectron/blob/master/GETTING_STARTED.md" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><h2 id="4ac9" class="mv lw it bd lx mw mx dn mb my mz dp mf li na nb mh lm nc nd mj lq ne nf ml ng bi translated">第四步建立高级时装的 Pinterest 数据库</h2><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oh"><img src="../Images/0442cb974bbcbb8816d01b52757dbaf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kc0VigBj5YU3bYu7i8x1IQ.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">示例图像(<a class="ae ki" href="https://pixabay.com/photos/fashion-show-fashion-catwalk-model-1746596/" rel="noopener ugc nofollow" target="_blank">左侧源</a>、<a class="ae ki" href="https://pixabay.com/photos/fashion-show-fashion-catwalk-model-1746610/" rel="noopener ugc nofollow" target="_blank">中间源</a>、<a class="ae ki" href="https://pixabay.com/photos/fashion-show-fashion-catwalk-model-1746592/" rel="noopener ugc nofollow" target="_blank">右侧源</a>)</p></figure><p id="8683" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nz">注意:由于版权问题，上面的图片实际上不是 Pinterest 数据库中的项目，而只是作为项目一般外观的参考。</em></p><p id="5e4a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们测试我们更快的 R-CNN 定位服装商品的能力之前，我们首先需要有我们自己的测试数据库。我们可以建立一个刮刀，从 Pinterest 上刮下时装秀的图片。当时，我们搜索了 2017 年，2018 年和 2019 年的秋冬时装秀。我们搜集的品牌包括:博柏利、香奈儿、克洛伊、迪奥、纪梵希、古驰、爱马仕、Jimmy Choo、路易威登、迈克高仕、普拉达、范思哲、圣罗兰。我们最终收集了分散在所有这些品牌中的总共 10，095 张时尚图片。</p><p id="d4f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">尽管我很想给出 Pinterest 的 scraper 代码，<strong class="lb iu">我已经没有代码了:(</strong>)。因为我不再能够访问我们当时在这个项目中使用的虚拟机。然而，使用<a class="ae ki" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank"> BeautifulSoup </a>可以很容易地构建这个刮刀，因为 Pinterest 图片都是静态的，而不是使用 Javascript 动态生成的。</p><p id="8c9a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">恭喜你走了这么远！下一步是在 Pinterest 数据库上运行我们速度更快的 R-CNN。在那之后，我们可以开始构建一个 DCGAN，它将能够获取服装图像，并生成与它们相似的好东西。因为这篇文章已经很长了，我们将把它留到第 2 部分。</p><h1 id="fb59" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">要继续，请点击此处查看第 2 部分:</h1><div class="oi oj gp gr ok ol"><a rel="noopener follow" target="_blank" href="/deepstyle-part-2-4ca2ae822ba0"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd iu gy z fp oq fr fs or fu fw is bi translated">时尚的甘(下)</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">第 2 部分继续:构建 DCGAN 以生成逼真的服装</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">towardsdatascience.com</p></div></div><div class="ou l"><div class="ov l ow ox oy ou oz kt ol"/></div></div></a></div></div></div>    
</body>
</html>