<html>
<head>
<title>Coding a ‘Kryptonite’ for Spammers 📩~ the Naive Bayes Filter</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为垃圾邮件发送者编写“Kryptonite”📩~朴素贝叶斯过滤器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/coding-a-kryptonite-for-spammers-the-naive-bayes-filter-e533e59a681f?source=collection_archive---------36-----------------------#2020-04-14">https://towardsdatascience.com/coding-a-kryptonite-for-spammers-the-naive-bayes-filter-e533e59a681f?source=collection_archive---------36-----------------------#2020-04-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="55e6" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何使用Python制作一个过滤垃圾短信的应用程序</h2></div><p id="b12e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">“如果好得难以置信...很可能是诈骗。”罗恩·韦伯</em></p><div class="lf lg lh li gt ab cb"><figure class="lj lk ll lm ln lo lp paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/287f1226eee6615f87e211d6d6a997b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*x36Pl3N56QiVxdAo_YpBUg.jpeg"/></div></figure><figure class="lj lk lw lm ln lo lp paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/29fabbfd2f5b4e7e8fe2e4f4be80116e.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*zLg5BLxk4OliL_2s9gdRfw.jpeg"/></div><p class="lx ly gj gh gi lz ma bd b be z dk mb di mc md translated"><a class="ae me" href="https://pixabay.com/users/cattu-1462001/" rel="noopener ugc nofollow" target="_blank"> cattu </a>在<a class="ae me" href="https://pixabay.com/photos/spam-mail-email-mailbox-garbage-964521/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a> &amp; <a class="ae me" href="https://unsplash.com/@usgs?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> USGS </a>在<a class="ae me" href="https://unsplash.com/photos/X9fUNniobXQ" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure></div><p id="49b1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">垃圾邮件</strong>通常定义为电子垃圾内容，来自各种通信渠道，如电子邮件、短信等。最常见的是，它来自于某种产品的广告，通过邮件列表甚至电话号码列表发送。</p><p id="1df5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如今，真正的问题是双重的；垃圾邮件浪费了人们的<em class="le">时间</em>，而它<em class="le"> </em>也“吞噬”了大量的网络<em class="le">带宽</em>。因此，许多组织和个人采取持续和巨大的努力来反击。当然，数据科学也不能置身于战场之外…</p><p id="825a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个项目的范围是展示数据科学的工具带如何应对反击垃圾邮件活动，并产生巨大的效果。在这个过程中，我们开发了一个监督ML(机器学习)的案例研究，其中我们创建了一个<strong class="kk iu">朴素贝叶斯分类</strong>算法，该算法将消息(短信、电子邮件等)作为输入，检测并过滤掉垃圾邮件。</p><h1 id="d0bb" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">概念</h1><p id="196c" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">这篇文章是上一篇文章的前传，在上一篇文章中，我们设法使用Python 开发并改进了一个<a class="ae me" rel="noopener" target="_blank" href="/can-a-data-scientist-replace-a-dj-spotify-manipulation-with-python-fbbd4a45ffd5"> Spotify播放列表(而且仅仅是！).为了更好地回忆这一概念，当时“数据公司”为其年轻客户举办了一场派对(<em class="le">因此播放列表</em>)，以奖励他们在青年营销领域的销售额大幅上升。但是，这家公司是如何赢得这样一座奖杯的——这是它为了在如此苛刻的市场中茁壮成长而取得的成就？请想象以下场景…</a></p><blockquote class="nc nd ne"><p id="3afb" class="ki kj le kk b kl km ju kn ko kp jx kq nf ks kt ku ng kw kx ky nh la lb lc ld im bi translated">Data Corp董事会决定在“沟通”类别下推出一款新的手机应用，以提高年轻人市场的销量。为了击败竞争对手，一个潜在的竞争优势被仔细审查——<strong class="kk iu">反垃圾邮件</strong>。特别是，我所属的数据科学部门负责与工程团队联系，并为他们提供一种算法，该算法将用户的短信作为输入，并自动过滤掉垃圾短信。这种算法将被应用到新的应用程序中，并且应该达到至少90%的准确率(竞争对手达到的标准)。</p></blockquote><p id="63d6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了更好地交流结果，提出了一些假设:</p><p id="7a4c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">#1:遵守GDPR义务，公司不利用任何客户的信息。相反，它只处理公共可用的数据集，特别是上传到UCI机器学习库<a class="ae me" href="https://archive.ics.uci.edu/ml/datasets/sms+spam+collection" rel="noopener ugc nofollow" target="_blank">的垃圾短信收集。</a></p><p id="98db" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">#2:我们将分析算法的“核心”,即过滤垃圾内容的机制。【<em class="le">app开发属于工程团队</em>】。</p><h1 id="e9eb" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">作案手法</h1><p id="5bb8" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">为了完成我们的使命，必须遵循以下路线图:</p><ol class=""><li id="022e" class="ni nj it kk b kl km ko kp kr nk kv nl kz nm ld nn no np nq bi translated">简要说明需要的<strong class="kk iu">理论</strong>，以便必要的方程表达和编码。</li><li id="a79d" class="ni nj it kk b kl nr ko ns kr nt kv nu kz nv ld nn no np nq bi translated"><strong class="kk iu">设置</strong>执行代码所需的环境。</li><li id="3ff1" class="ni nj it kk b kl nr ko ns kr nt kv nu kz nv ld nn no np nq bi translated">探索并准备<strong class="kk iu">数据集</strong>。</li><li id="21ac" class="ni nj it kk b kl nr ko ns kr nt kv nu kz nv ld nn no np nq bi translated">使用熊猫、Numpy、NLTK &amp;和一些额外的Python库来开发<strong class="kk iu">算法</strong>。</li><li id="98e6" class="ni nj it kk b kl nr ko ns kr nt kv nu kz nv ld nn no np nq bi translated">执行算法<strong class="kk iu">分类</strong>新消息并测量其<strong class="kk iu">准确度</strong>。</li></ol></div><div class="ab cl nw nx hx ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="im in io ip iq"><h1 id="b0f7" class="mf mg it bd mh mi od mk ml mm oe mo mp jz of ka mr kc og kd mt kf oh kg mv mw bi translated">1.理论</h1><p id="6607" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">朴素贝叶斯算法有几个变体，根据所做的数学和假设，我们区分以下3个最流行的版本:</p><ul class=""><li id="488c" class="ni nj it kk b kl km ko kp kr nk kv nl kz nm ld oi no np nq bi translated">多项式朴素贝叶斯</li><li id="f010" class="ni nj it kk b kl nr ko ns kr nt kv nu kz nv ld oi no np nq bi translated">高斯朴素贝叶斯</li><li id="535b" class="ni nj it kk b kl nr ko ns kr nt kv nu kz nv ld oi no np nq bi translated">伯努利朴素贝叶斯</li></ul><p id="fa4e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这次我们将讨论<strong class="kk iu">多项式</strong>算法。计算机学习人类如何将消息分类为垃圾邮件/非垃圾邮件(从现在开始称为“ham”)，然后使用该知识来估计新(传入)消息的概率，并相应地对它们进行分类。</p><p id="6a9a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">简而言之，当由<code class="fe oj ok ol om b">w1, w2, …, wn</code>个单词组成的新消息进来时，朴素贝叶斯算法试图通过利用集合#2来估计和比较集合#1的等式:</p><figure class="lf lg lh li gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi on"><img src="../Images/f681073c294b18899531e72619839a1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gd0GarBiRhEPq11iKM_2Vg@2x.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">方程组#1</p></figure><figure class="lf lg lh li gt lk gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/bac8e854cd6f8888fde38c0bd344dcbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*jGfIVtDaX3xfRznWKMJWJg@2x.png"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">方程组#2</p></figure><figure class="lf lg lh li gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi op"><img src="../Images/6456ef8f47cc6388d043af4e415b3f42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VAdtZx5UevNSOKDA7LsdHA@2x.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">参数和变量的解释</p></figure><p id="243f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果<code class="fe oj ok ol om b">P(Spam|w1,w2,…wn)</code> &gt; <code class="fe oj ok ol om b">P(Spam<em class="le">c</em>|w1,w2,…wn)</code>，该算法将该消息分类为垃圾邮件，反之亦然。要彻底研究以上方程式，你可以参考这个<a class="ae me" href="https://scikit-learn.org/stable/modules/naive_bayes.html" rel="noopener ugc nofollow" target="_blank">来源</a>。</p><p id="9e39" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">⚠️限制:</p><p id="8eee" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">#1:每个消息中的单词是有条件独立的，尽管它们经常处于依赖关系中。</p><p id="4233" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">#2:每当我们处理不属于词汇表的单词时(参见“特征提取”部分)，我们在计算概率时会忽略它们。</p><p id="03e2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">#3:如果单词(即“money”)只出现在一个类别(即垃圾邮件)中，那么补码概率P(垃圾邮件<em class="le">c</em>|“money”)总是0。为了避免这种影响，我们应用了一种称为<em class="le">加法平滑</em>的技术，通过增加一个平滑参数α。我们将使用拉普拉斯平滑，通过设置a=1(在这里阅读更多<a class="ae me" href="https://en.wikipedia.org/wiki/Additive_smoothing" rel="noopener ugc nofollow" target="_blank"/>)。</p><h1 id="8a7b" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">2.建立</h1><p id="c9a4" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">为了开发和运行该算法，以下组件/库是必不可少的:</p><ul class=""><li id="439a" class="ni nj it kk b kl km ko kp kr nk kv nl kz nm ld oi no np nq bi translated">安装<a class="ae me" href="https://jupyter.org/index.html" rel="noopener ugc nofollow" target="_blank">Jupyter</a>Notebook——一个开源网络应用程序，用于创建/共享包含实时代码、公式、可视化和叙述性文本的文档。你可以在这里按照步骤<a class="ae me" href="https://jupyter.org/install.html" rel="noopener ugc nofollow" target="_blank">进行</a>。</li><li id="7b89" class="ni nj it kk b kl nr ko ns kr nt kv nu kz nv ld oi no np nq bi translated">安装<a class="ae me" href="https://www.nltk.org" rel="noopener ugc nofollow" target="_blank">NLTK</a>——一个Python库，它提供了预处理和清理原始数据的有效模块(删除标点符号、标记等)。您可以使用CLI(命令行界面)或Jupyter笔记本来运行以下命令:</li></ul><figure class="lf lg lh li gt lk"><div class="bz fp l di"><div class="oq or l"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">install.py</p></figure><ul class=""><li id="4a94" class="ni nj it kk b kl km ko kp kr nk kv nl kz nm ld oi no np nq bi translated">下载<a class="ae me" href="https://en.wikipedia.org/wiki/Stop_words" rel="noopener ugc nofollow" target="_blank">停用词</a>——一组常用词(“the”、“a”、“an”等)，它们在句子中频繁出现，但分量不大。</li><li id="92a1" class="ni nj it kk b kl nr ko ns kr nt kv nu kz nv ld oi no np nq bi translated">下载<a class="ae me" href="https://www.nltk.org/_modules/nltk/tokenize/punkt.html" rel="noopener ugc nofollow" target="_blank">Punkt</a>——一个句子分词器，它将文本分成一系列句子。</li><li id="926b" class="ni nj it kk b kl nr ko ns kr nt kv nu kz nv ld oi no np nq bi translated">下载<a class="ae me" href="https://wordnet.princeton.edu/download" rel="noopener ugc nofollow" target="_blank">WordNet</a>——一个大型的英语词汇数据库，其结构使其成为计算语言学和NLP(自然语言处理)的有用工具。</li></ul><figure class="lf lg lh li gt lk"><div class="bz fp l di"><div class="oq or l"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">下载. py</p></figure><ul class=""><li id="0655" class="ni nj it kk b kl km ko kp kr nk kv nl kz nm ld oi no np nq bi translated">导入必要的库:</li></ul><figure class="lf lg lh li gt lk"><div class="bz fp l di"><div class="oq or l"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">import.py</p></figure><h1 id="df53" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">3.数据集探索和分割</h1><p id="6dda" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">完整的数据集包括5.572条SMS消息(<em class="le">已经被人类分类</em>)，这些消息分布在垃圾邮件和垃圾邮件类别中，分别占大约87%和13%。描绘它的<a class="ae me" href="https://github.com/amueller/word_cloud" rel="noopener ugc nofollow" target="_blank">词云</a>，我们可以得到主导词的另一种反映:</p><figure class="lf lg lh li gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi os"><img src="../Images/f4c18a259095b083a8226c295c0273b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RDXrNrpLd5Sg5k9O7KWmoQ@2x.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">原始数据集Wordcloud</p></figure><p id="b332" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将其随机化，以便保留原始的垃圾邮件/火腿比例，然后将其分成两个子集，选择80% — 20%的分割比例:</p><ul class=""><li id="fc09" class="ni nj it kk b kl km ko kp kr nk kv nl kz nm ld oi no np nq bi translated"><code class="fe oj ok ol om b">training_set</code>:用于“训练”计算机如何对信息进行分类</li><li id="7ef9" class="ni nj it kk b kl nr ko ns kr nt kv nu kz nv ld oi no np nq bi translated"><code class="fe oj ok ol om b">test_set</code>:用于最终测试垃圾邮件过滤器的好坏(准确性)</li></ul><figure class="lf lg lh li gt lk"><div class="bz fp l di"><div class="oq or l"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">dataset_division.py</p></figure><div class="lf lg lh li gt ab cb"><figure class="lj lk ot lm ln lo lp paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/349bf90a5fac5579376d4487af03403a.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*6P78uXYg0s1OLiZLXo5i-g@2x.png"/></div></figure><figure class="lj lk ot lm ln lo lp paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/d6ca76d26d5d68a7ae24697daef7544c.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*HZ7u7vQHe6Dw2VnQnslmvw@2x.png"/></div></figure><figure class="lj lk ot lm ln lo lp paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/87d619af830d4b3ba50dc2439549275b.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*7bXBysNZyl3i-zuNiDjk9Q@2x.png"/></div><p class="lx ly gj gh gi lz ma bd b be z dk ou di ov md translated">数据集的垃圾邮件分布</p></figure></div><p id="3145" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">显然，最初的垃圾邮件/火腿比例被有效地保留了下来。</p><h1 id="a182" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">4.算法开发</h1><p id="30b2" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">在NLP中，我们的目标是教会计算机根据上下文理解和操作人类语言，尽管它们只处理数字形式的数据。因为，我们将首先应用一些<strong class="kk iu">预处理</strong>技术，以便数据集留下具有高有意义权重的伪影。然后，我们将把数据集的消息编码成数字向量(<strong class="kk iu">特征提取</strong>)【1】。为了更好地了解整个过程，您可以参考以下流程图:</p><figure class="lf lg lh li gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi ow"><img src="../Images/3822fbf1c0c7638dc57251791fd2af6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J81rSp0P8ZEzw1ODvBRdHA.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">算法流程图</p></figure><h2 id="09eb" class="ox mg it bd mh oy oz dn ml pa pb dp mp kr pc pd mr kv pe pf mt kz pg ph mv pi bi translated">文本预处理</h2><p id="2b28" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">一般来说，根据参考文献[2]，我们区分文本预处理的3个主要组成部分:规范化、标记化和替换。</p><p id="a6e8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> (a)正常化</strong></p><p id="b1f9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，文本需要规范化。这意味着采取一系列的行动，将文本中的单词放在同一个“基线”上，从而形成一个更加统一的过程。这一步包括删除标点符号，将单词转换成相同的大小写(大写/小写)等等。在我们的框架中，我们将通过3个不同的步骤来实现这一目标:</p><p id="405c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> 1。引理化</strong>:根据记号的引理获取其标准形式的过程，即<em class="le">更好</em> → <em class="le">好</em>。与词干提取相比，它更加复杂，通过考虑单词在句子中使用的上下文，它返回更有意义的单词。我们将利用WordNet的英语词汇数据库，它给出了显著的结果。</p><figure class="lf lg lh li gt lk"><div class="bz fp l di"><div class="oq or l"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">词条化. py</p></figure><p id="1227" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> 2。词干化</strong>:通过消除任何词缀(通常是带后缀的&amp;前缀)，将“屈折”的单词减少到其词根(词干)的过程。比如<em class="le">词干，词干→词干</em>。这样，我们只保留了相似单词的语义，同时也实现了标记(单词)数量的总体减少。后者确保减少词汇量，因此占用更少的计算资源。有几种词干模型，我们将使用波特模型。</p><figure class="lf lg lh li gt lk"><div class="bz fp l di"><div class="oq or l"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">词干. py</p></figure><p id="f491" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> 3。自定义操作</strong>:根据具体情况，为进一步清理文本数据而采取的一组操作。对于这一条短信，我们去掉了地址、数字和符号($)，去掉了标点(？！等等)，折叠空白并将所有标记转换为小写。此外，我们删除了在句子中频繁出现的、对整体意思没有显著贡献的停用词(如the、for、is等)。</p><figure class="lf lg lh li gt lk"><div class="bz fp l di"><div class="oq or l"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">custom_normalization.py</p></figure><p id="79b5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> (b)标记化</strong></p><p id="5855" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">将一长串文本分割成小块(段落分割成句子，句子分割成单词)的过程。即文本中使用的标记列表，也被称为<em class="le">语料库</em>。幸运的是，Python有一个名为NLTK(自然语言工具包)的包，其中包含大量有用的操作文本的函数。我们将使用nltk.word_tokenize。</p><figure class="lf lg lh li gt lk"><div class="bz fp l di"><div class="oq or l"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">tokenization.py</p></figure><p id="9244" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> (c)噪声去除</strong></p><p id="9ae2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是一个更加针对特定任务的步骤，因为它细化了非常特殊的数据集。例如，被网络丢弃的文本，应该被HTML、XML和标记“脚印”清理掉。在我们的例子中，我们处理纯短信文本，最终跳过这一部分。</p><p id="e73c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了更好地感受上述技术的效果，让我们将它们全部应用于一个特定的SMS，并获得最终结果:</p><pre class="lf lg lh li gt pj om pk pl aw pm bi"><span id="41e4" class="ox mg it om b gy pn po l pp pq"># Original Message<br/>I would but I’m still cozy. And exhausted from last night.nobody went to school or work. Everything is closed.</span><span id="f494" class="ox mg it om b gy pr po l pp pq"># N<!-- -->ormalization<br/>would still cozy exhausted last went school work everything closed</span><span id="0ea6" class="ox mg it om b gy pr po l pp pq"># Lemmatization<br/>would still cozy exhaust last go school work everything close</span><span id="2101" class="ox mg it om b gy pr po l pp pq"># Stemming<br/>would still cozi exhaust last go school work everyth close</span><span id="6f89" class="ox mg it om b gy pr po l pp pq"># Tokenization<br/>[would, still, cozi, exhaust, last, go, school, work, everyth, close]</span></pre><p id="8f34" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">⚠️:在每一个单独的案例中，应检查实施一种或多种上述技术[停用词、词干等]之间的权衡。例如，我们可能会跳过词汇化而支持词干化。</p><h2 id="aadf" class="ox mg it bd mh oy oz dn ml pa pb dp mp kr pc pd mr kv pe pf mt kz pg ph mv pi bi translated"><strong class="ak">特征提取</strong></h2><p id="0982" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">ML算法不理解纯文本形式的文本，但是期望输入是数字形式的。因此，有必要将我们的最终记号编码成数字——也就是特征向量——这个过程被称为<strong class="kk iu">矢量化</strong>【3】。在可用的类型中，我们选择使用<em class="le">计数矢量化</em>。这个函数创建了一个矩阵，其中包含每个数据集行(SMS)中每个惟一令牌的计数。</p><figure class="lf lg lh li gt lk"><div class="bz fp l di"><div class="oq or l"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">矢量化. py</p></figure><figure class="lf lg lh li gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi ps"><img src="../Images/5dc834b7b8f2e0ad332de7de086d7271.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IfU8nkkIDwzSO9PwoA_aag@2x.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated"><code class="fe oj ok ol om b">final_training_set</code>样品</p></figure><p id="d7fc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">提到普通的文学作品，你可能会想到BoW这个词。也就是说，本质上，在分类方法中通常使用的模型，其中每个标记的出现频率被用作训练分类器的特征[4]。</p><h2 id="a714" class="ox mg it bd mh oy oz dn ml pa pb dp mp kr pc pd mr kv pe pf mt kz pg ph mv pi bi translated">常数和参数计算</h2><p id="0709" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">首先，我们为每个新消息(红色标记)计算方程组中具有常数值的<code class="fe oj ok ol om b">P(Spam)</code>、<code class="fe oj ok ol om b">P(Spam<em class="le">c</em>)</code>、<code class="fe oj ok ol om b">NSpam</code>和<code class="fe oj ok ol om b">NVocabulary</code>:</p><figure class="lf lg lh li gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi on"><img src="../Images/5759ba5705eb39e1a232c88df8579ba9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NTtcTK1QAoDHK9kIEsmpLg@2x.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">从方程组#1计算的常数</p></figure><figure class="lf lg lh li gt lk gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/12e74d431af510546019de885932aa56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*oZZsYTPQGIGti_eLc6THJA@2x.png"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">从方程组#2计算的常数和参数</p></figure><figure class="lf lg lh li gt lk"><div class="bz fp l di"><div class="oq or l"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">calc_constant.py</p></figure><p id="8221" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来，我们计算<code class="fe oj ok ol om b">P(wi|Spam)</code>和<code class="fe oj ok ol om b">P(wi|Spam<em class="le">c</em>)</code>值(蓝色标记)。注意，由于它们依赖于不变的<code class="fe oj ok ol om b">training_set</code>，它们也保持不变。</p><figure class="lf lg lh li gt lk"><div class="bz fp l di"><div class="oq or l"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">calc_params.py</p></figure><h2 id="c6b1" class="ox mg it bd mh oy oz dn ml pa pb dp mp kr pc pd mr kv pe pf mt kz pg ph mv pi bi translated">传入消息分类</h2><p id="246b" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">计算完所有的参数和常数后，我们就可以创建垃圾邮件过滤器了。它可以很容易地被理解为一个函数，它接收一个新消息<code class="fe oj ok ol om b">(w1, w2, …, wn)</code>，计算<code class="fe oj ok ol om b">P(Spam|w1, w2, …, wn)</code>和<code class="fe oj ok ol om b">P(Spam<em class="le">c</em>|w1, w2, …, wn)</code>，比较它们并且:</p><ul class=""><li id="5efe" class="ni nj it kk b kl km ko kp kr nk kv nl kz nm ld oi no np nq bi translated">如果<code class="fe oj ok ol om b">P(Spam<em class="le">c</em>|w1, w2, …, wn)</code> &gt; <code class="fe oj ok ol om b">P(Spam|w1, w2, …, wn)</code>，则将消息分类为ham</li><li id="9fce" class="ni nj it kk b kl nr ko ns kr nt kv nu kz nv ld oi no np nq bi translated">如果<code class="fe oj ok ol om b">P(Spam<em class="le">c</em>|w1, w2, …, wn)</code> &lt; <code class="fe oj ok ol om b">P(Spam|w1, w2, …, wn)</code>，则将该邮件归类为垃圾邮件</li><li id="b67f" class="ni nj it kk b kl nr ko ns kr nt kv nu kz nv ld oi no np nq bi translated">如果<code class="fe oj ok ol om b">P(Spam<em class="le">c</em>|w1, w2, …, wn)</code> = <code class="fe oj ok ol om b">P(Spam|w1, w2, …, wn)</code>，请求人工帮助</li></ul><figure class="lf lg lh li gt lk"><div class="bz fp l di"><div class="oq or l"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">classify_message.py</p></figure><p id="e10c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在最令人愉快的部分来了；使用新的SMS文本测试算法，这些文本还没有在培训部分使用过。第一个来自广告内容，第二个来自私人谈话。</p><figure class="lf lg lh li gt lk"><div class="bz fp l di"><div class="oq or l"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">classify_spam_sms.py</p></figure><pre class="lf lg lh li gt pj om pk pl aw pm bi"><span id="74f6" class="ox mg it om b gy pn po l pp pq"># Output<br/>P(Spam|message): 3.2268434039363386e-33<br/>P(Ham|message): 3.3664743866615654e-34<br/>Label: Spam</span></pre><figure class="lf lg lh li gt lk"><div class="bz fp l di"><div class="oq or l"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">classify_ham_sms.py</p></figure><pre class="lf lg lh li gt pj om pk pl aw pm bi"><span id="c94a" class="ox mg it om b gy pn po l pp pq"># Output<br/>P(Spam|message): 1.5519061681677179e-27<br/>P(Ham|message): 7.759653287935314e-23<br/>Label: Ham</span></pre><p id="0d55" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">幸运的是，两者都被成功标记！</p><h1 id="1c02" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">5.算法实现和精度测量</h1><p id="4f17" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">最后，我们尝试通过对<code class="fe oj ok ol om b">test_set</code>的1.114条消息进行分类来确定过滤器的性能。该功能应用于每个新的SMS，并将其标签注册到新列<code class="fe oj ok ol om b">sms_predicted</code>。</p><figure class="lf lg lh li gt lk"><div class="bz fp l di"><div class="oq or l"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">分类测试设置</p></figure><pre class="lf lg lh li gt pj om pk pl aw pm bi"><span id="a29b" class="ox mg it om b gy pn po l pp pq">Results <br/>-------<br/>Valid: 1087<br/>Invalid: 27<br/>Accuracy: 0.9758</span></pre><p id="50e0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们的垃圾邮件过滤器检查了1.114条未知消息(<em class="le">在培训中未看到</em>)，并成功对1.087条进行了正确分类。几乎97.6%的测量精度高于公司的目标(90%)，因此，我们的模型将被部署到生产中！</p></div><div class="ab cl nw nx hx ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="im in io ip iq"><h1 id="87cf" class="mf mg it bd mh mi od mk ml mm oe mo mp jz of ka mr kc og kd mt kf oh kg mv mw bi translated">结论</h1><p id="b0da" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">沟通渠道不断受到欺诈机制的攻击，这些机制往往会从个人和组织那里“窃取”时间和金钱。也就是说，数据科学能够提供有价值的解决方案。早在2015年，谷歌就已经在阻止垃圾邮件到达收件箱方面达到了99.9%的准确率[4]。最重要的是，通过使用它的“神经网络”[5]，它全速前进以消除剩下的0.1%的误差！</p><p id="2e02" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，数据科学的卖点依赖于其提供有价值的解决方案的能力，即使是在业余用户的初级水平上。本文开发了这样一个初步的案例研究，并通过训练一个<strong class="kk iu"/><strong class="kk iu">分类模型</strong>进行求解，最终达到了97%的显著准确率。总而言之:</p><p id="3919" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> (a) </strong>我们处理了一组信息，并通过应用:</p><p id="645b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">✔️ <strong class="kk iu">文本</strong> <strong class="kk iu">预处理</strong>【规范化、标记化】</p><p id="0b93" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">✔️ <strong class="kk iu">特征提取</strong>【矢量化】</p><p id="18e4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们设法将它们转换成编码向量——对机器来说是小菜一碟，可以理解并从中推断出有意义的价值。</p><p id="e7be" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> (b) </strong>我们<strong class="kk iu">根据贝叶斯定理，通过计算<strong class="kk iu"> </strong>各自的概率来训练</strong>我们的模型。</p><p id="666b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> (c) </strong>最后，通过在<code class="fe oj ok ol om b">test_set</code>上应用该算法，我们<strong class="kk iu">评估了</strong>该模型有效标记新消息的能力。</p></div><div class="ab cl nw nx hx ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="im in io ip iq"><p id="2f58" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最终，尽管我们承认垃圾邮件结构的存在和活动以我们的时间和金钱为代价，但我们应该永远记住，数据科学已经对人类有利…</p><figure class="lf lg lh li gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi pt"><img src="../Images/58630508131b856a4bc1561b3e49d082.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bt-ir9C6fcC7ENg-bWOX1w.jpeg"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">由<a class="ae me" href="https://unsplash.com/@arianismmm?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Arian Darvishi </a>在<a class="ae me" href="https://unsplash.com/photos/wh-RPfR_3_M" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="fa4f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">此外，正如Mokokoma Mokhonoana恰当地引用的那样:</p><p id="cfed" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">垃圾邮件浪费了接收者的时间，也浪费了发送者的乐观。”</p><p id="f187" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢您的阅读！Jupyter <a class="ae me" href="https://github.com/makispl/SMS-Spam-Filter-Naive-Bayes.git" rel="noopener ugc nofollow" target="_blank">笔记本</a>准备立即运行。如果有任何问题，请在下面留言。祝你度过愉快的一周，呆在家里，保持乐观，保证自己和你的<code class="fe oj ok ol om b">inbox</code>的安全！</p></div><div class="ab cl nw nx hx ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="im in io ip iq"><p id="9405" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">参考文献</strong></p><p id="6927" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[1] H. Red，<a class="ae me" href="https://inmachineswetrust.com/posts/sms-spam-filter/" rel="noopener ugc nofollow" target="_blank">使用自然语言处理构建短信垃圾邮件过滤器</a> (2017)，博客“在我们信任的机器中”</p><p id="3acc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[2] M. Mayo，<a class="ae me" href="https://www.kdnuggets.com/2017/12/general-approach-preprocessing-text-data.html" rel="noopener ugc nofollow" target="_blank">文本数据预处理的一般方法</a> (2017)，KDnuggets</p><p id="19cc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[3] N. Kumar，NLP中原始数据的预处理:标记化、词干化、词条化和矢量化(2019)，在线出版物“专业人士观点”</p><p id="37de" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[4] G. Starr，<a class="ae me" href="https://www.csmonitor.com/Technology/2015/0713/Google-fights-spam-with-artificial-intelligence" rel="noopener ugc nofollow" target="_blank">谷歌用人工智能对抗垃圾邮件</a> (2015)，独立国际新闻机构《基督教科学箴言报》</p><p id="aefa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[5] A. Mordvintsev，C. Olah，M. Tyka，<a class="ae me" href="http://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html" rel="noopener ugc nofollow" target="_blank">概念主义:深入神经网络</a> (2015)，谷歌人工智能博客</p></div></div>    
</body>
</html>