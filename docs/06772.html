<html>
<head>
<title>Building a multi-output Convolutional Neural Network with Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Keras构建多输出卷积神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-multi-output-convolutional-neural-network-with-keras-ed24c7bc1178?source=collection_archive---------2-----------------------#2020-05-27">https://towardsdatascience.com/building-a-multi-output-convolutional-neural-network-with-keras-ed24c7bc1178?source=collection_archive---------2-----------------------#2020-05-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="6643" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这篇文章中，我们将探索Keras functional API，以建立一个多输出深度学习模型。我们将展示如何训练能够预测三种不同输出的单一模型。通过使用UTK人脸数据集，该数据集由超过2万张不受控制的环境中的人的照片组成，我们将预测数据集中呈现的每条记录的年龄、性别和性别，性别的准确率达到91%，种族的准确率达到78%。</p><h1 id="0d19" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">数据集</h1><p id="8643" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">UTKFace数据集是一个大型数据集，由超过2万张人脸图像组成，并分别标注了年龄、性别和种族。图像被适当地裁剪到面部区域，但是在姿势、照明、分辨率等方面显示一些变化。</p><p id="f533" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了检索每个记录的注释，我们需要解析文件名。每条记录以如下格式存储:<strong class="jp ir">年龄_性别_种族_日期&amp;time.jpg</strong></p><p id="41c8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中:</p><ul class=""><li id="ced3" class="lo lp iq jp b jq jr ju jv jy lq kc lr kg ls kk lt lu lv lw bi translated">年龄是从0到116的整数</li><li id="fc1c" class="lo lp iq jp b jq lx ju ly jy lz kc ma kg mb kk lt lu lv lw bi translated">性别是一个整数，其中0代表男性，1代表女性</li><li id="c4d0" class="lo lp iq jp b jq lx ju ly jy lz kc ma kg mb kk lt lu lv lw bi translated">种族是一个从0到4的整数，分别代表白人、黑人、亚洲人、印度人和其他人种</li><li id="5b98" class="lo lp iq jp b jq lx ju ly jy lz kc ma kg mb kk lt lu lv lw bi translated">日期和时间，表示照片拍摄的时间</li></ul><p id="7ccd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你想进一步了解这个数据集，请查看他们的<a class="ae mc" href="http://aicip.eecs.utk.edu/wiki/UTKFace" rel="noopener ugc nofollow" target="_blank">网站</a>。</p><p id="723e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们首先导入一些库并创建我们的字典来帮助我们解析来自数据集的信息，以及一些其他信息(数据集位置、训练分割、样本的宽度和高度)。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="8dfe" class="mm km iq mi b gy mn mo l mp mq">import numpy as np <br/>import pandas as pd<br/>import os<br/>import glob<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span><span id="f792" class="mm km iq mi b gy mr mo l mp mq">dataset_folder_name = 'UTKFace'</span><span id="a2b1" class="mm km iq mi b gy mr mo l mp mq">TRAIN_TEST_SPLIT = 0.7<br/>IM_WIDTH = IM_HEIGHT = 198</span><span id="c50a" class="mm km iq mi b gy mr mo l mp mq">dataset_dict = {<br/>    'race_id': {<br/>        0: 'white', <br/>        1: 'black', <br/>        2: 'asian', <br/>        3: 'indian', <br/>        4: 'others'<br/>    },<br/>    'gender_id': {<br/>        0: 'male',<br/>        1: 'female'<br/>    }<br/>}</span><span id="49c7" class="mm km iq mi b gy mr mo l mp mq">dataset_dict['gender_alias'] = dict((g, i) for i, g in dataset_dict['gender_id'].items())<br/>dataset_dict['race_alias'] = dict((r, i) for i, r in dataset_dict['race_id'].items())</span></pre><p id="5743" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们定义一个函数来帮助我们从数据集中提取数据。该函数将用于迭代UTK数据集的每个文件，并返回一个包含我们记录的所有字段(年龄、性别和性别)的熊猫数据帧。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="0a9a" class="mm km iq mi b gy mn mo l mp mq">def parse_dataset(dataset_path, ext='jpg'):<br/>    """<br/>    Used to extract information about our dataset. It does iterate over all images and return a DataFrame with<br/>    the data (age, gender and sex) of all files.<br/>    """<br/>    def parse_info_from_file(path):<br/>        """<br/>        Parse information from a single file<br/>        """<br/>        try:<br/>            filename = os.path.split(path)[1]<br/>            filename = os.path.splitext(filename)[0]<br/>            age, gender, race, _ = filename.split('_')</span><span id="934f" class="mm km iq mi b gy mr mo l mp mq">            return int(age), dataset_dict['gender_id'][int(gender)], dataset_dict['race_id'][int(race)]<br/>        except Exception as ex:<br/>            return None, None, None<br/>        <br/>    files = glob.glob(os.path.join(dataset_path, "*.%s" % ext))<br/>    <br/>    records = []<br/>    for file in files:<br/>        info = parse_info_from_file(file)<br/>        records.append(info)<br/>        <br/>    df = pd.DataFrame(records)<br/>    df['file'] = files<br/>    df.columns = ['age', 'gender', 'race', 'file']<br/>    df = df.dropna()<br/>    <br/>    return df</span><span id="fb50" class="mm km iq mi b gy mr mo l mp mq">df = parse_dataset(dataset_folder_name)<br/>df.head()</span></pre><h1 id="c6b2" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">数据可视化</h1><p id="5c18" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">作为理解数据集分布以及模型生成的预测的重要步骤，建议对数据集执行一些数据可视化过程。我们将首先定义一个助手函数，根据给定的Pandas系列生成饼图:</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="9e37" class="mm km iq mi b gy mn mo l mp mq">import plotly.graph_objects as go</span><span id="8035" class="mm km iq mi b gy mr mo l mp mq">def plot_distribution(pd_series):<br/>    labels = pd_series.value_counts().index.tolist()<br/>    counts = pd_series.value_counts().values.tolist()<br/>    <br/>    pie_plot = go.Pie(labels=labels, values=counts, hole=.3)<br/>    fig = go.Figure(data=[pie_plot])<br/>    fig.update_layout(title_text='Distribution for %s' % pd_series.name)<br/>    <br/>    fig.show()</span></pre><h2 id="140f" class="mm km iq bd kn ms mt dn kr mu mv dp kv jy mw mx kz kc my mz ld kg na nb lh nc bi translated">种族分布</h2><p id="e050" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">让我们首先用我们预定义的<em class="nd"> plot_distribution </em>方法绘制比赛分布图。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="0661" class="mm km iq mi b gy mn mo l mp mq">plot_distribution(df['race'])</span></pre><figure class="md me mf mg gt nf gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/8ee37c8d81808aae0f2464a4e50585c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*zuRw4W9XrD1sOPSxJDHj5w.png"/></div></figure><p id="9786" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">快速浏览一下这个图，我们可以看到几乎一半的样本来自白色人种，所以我们可以期待这个组有很大的准确性。其他种族，如黑人、印度人和亚洲人也显示了大量的样本，可能也使我们获得了准确的数据。另一方面，种族“其他人”(西班牙裔、拉丁裔等)显示少量样本，更可能具有较小的准确性。</p><h2 id="ae7a" class="mm km iq bd kn ms mt dn kr mu mv dp kv jy mw mx kz kc my mz ld kg na nb lh nc bi translated">性别分布</h2><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="3ec4" class="mm km iq mi b gy mn mo l mp mq">plot_distribution(df['gender'])</span></pre><figure class="md me mf mg gt nf gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/67f6f68b75eb576fcd3a994146e421a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*McOAVY6mWUMioM_yELBr5A.png"/></div></figure><p id="176a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于男性和女性样本，我们有相当好的平衡数量的记录，所以当使用我们的模型时，我们应该对两类都有很高的准确性。</p><h2 id="6b53" class="mm km iq bd kn ms mt dn kr mu mv dp kv jy mw mx kz kc my mz ld kg na nb lh nc bi translated">年龄分布</h2><p id="0f3e" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">我们还可以使用一个简单的直方图来绘制年龄特征在数据集上的分布，该直方图包含20个条块/扇区。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="1d04" class="mm km iq mi b gy mn mo l mp mq">import plotly.express as px<br/>fig = px.histogram(df, x="age", nbins=20)<br/>fig.update_layout(title_text='Age distribution')<br/>fig.show()</span></pre><figure class="md me mf mg gt nf gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/ec98024c96c6037ec976ad4b8ba93212.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*XpJfX8mtaAwleO_zDLZErQ.png"/></div></figure><p id="09d7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们也可以在饼图中显示同样的图。让我们将年龄列分组，然后用饼图绘制出来</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="6887" class="mm km iq mi b gy mn mo l mp mq">bins = [0, 10, 20, 30, 40, 60, 80, np.inf]<br/>names = ['&lt;10', '10-20', '20-30', '30-40', '40-60', '60-80', '80+']</span><span id="e68a" class="mm km iq mi b gy mr mo l mp mq">age_binned = pd.cut(df['age'], bins, labels=names)<br/>plot_distribution(age_binned)</span></pre><figure class="md me mf mg gt nf gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/1559fd7f06471a0a6ab1b113c6526139.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*12OhGBUUfOlQDdsw_Dgllg.png"/></div></figure><p id="fdc0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以观察到，我们的数据集主要由年龄在20至30岁之间的个体组成，其次是30至40岁以及40至60岁的个体。这些群体约占我们数据集的70%,因此我们可以假设我们在预测这些范围内的个体时会有很好的准确性。</p><p id="4d09" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们还可以对我们的数据集执行一些多变量分析，但由于这篇文章的范围是演示Keras的多输出模型的用法，所以我们不会涉及它——如果你们感兴趣的话，也许改天吧。</p><h1 id="e459" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">数据生成程序</h1><p id="89ee" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">为了将我们的数据输入到我们的Keras多输出模型中，我们将创建一个辅助对象作为数据集的数据生成器。这将通过生成批量数据来完成，这些数据将用于向我们的多输出模型提供图像及其标签。这一步也要完成，而不是一次将所有数据集加载到内存中，这可能会导致内存不足错误。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="2043" class="mm km iq mi b gy mn mo l mp mq">from keras.utils import to_categorical<br/>from PIL import Image</span><span id="41d2" class="mm km iq mi b gy mr mo l mp mq">class UtkFaceDataGenerator():<br/>    """<br/>    Data generator for the UTKFace dataset. This class should be used when training our Keras multi-output model.<br/>    """<br/>    def __init__(self, df):<br/>        self.df = df<br/>        <br/>    def generate_split_indexes(self):<br/>        p = np.random.permutation(len(self.df))<br/>        train_up_to = int(len(self.df) * TRAIN_TEST_SPLIT)<br/>        train_idx = p[:train_up_to]<br/>        test_idx = p[train_up_to:]</span><span id="84d2" class="mm km iq mi b gy mr mo l mp mq">        train_up_to = int(train_up_to * TRAIN_TEST_SPLIT)<br/>        train_idx, valid_idx = train_idx[:train_up_to], train_idx[train_up_to:]<br/>        <br/>        # converts alias to id<br/>        self.df['gender_id'] = self.df['gender'].map(lambda gender: dataset_dict['gender_alias'][gender])<br/>        self.df['race_id'] = self.df['race'].map(lambda race: dataset_dict['race_alias'][race])</span><span id="a57e" class="mm km iq mi b gy mr mo l mp mq">        self.max_age = self.df['age'].max()<br/>        <br/>        return train_idx, valid_idx, test_idx<br/>    <br/>    def preprocess_image(self, img_path):<br/>        """<br/>        Used to perform some minor preprocessing on the image before inputting into the network.<br/>        """<br/>        im = Image.open(img_path)<br/>        im = im.resize((IM_WIDTH, IM_HEIGHT))<br/>        im = np.array(im) / 255.0<br/>        <br/>        return im<br/>        <br/>    def generate_images(self, image_idx, is_training, batch_size=16):<br/>        """<br/>        Used to generate a batch with images when training/testing/validating our Keras model.<br/>        """<br/>        <br/>        # arrays to store our batched data<br/>        images, ages, races, genders = [], [], [], []<br/>        while True:<br/>            for idx in image_idx:<br/>                person = self.df.iloc[idx]<br/>                <br/>                age = person['age']<br/>                race = person['race_id']<br/>                gender = person['gender_id']<br/>                file = person['file']<br/>                <br/>                im = self.preprocess_image(file)<br/>                <br/>                ages.append(age / self.max_age)<br/>                races.append(to_categorical(race, len(dataset_dict['race_id'])))<br/>                genders.append(to_categorical(gender, len(dataset_dict['gender_id'])))<br/>                images.append(im)<br/>                <br/>                # yielding condition<br/>                if len(images) &gt;= batch_size:<br/>                    yield np.array(images), [np.array(ages), np.array(races), np.array(genders)]<br/>                    images, ages, races, genders = [], [], [], []<br/>                    <br/>            if not is_training:<br/>                break<br/>                <br/>data_generator = UtkFaceDataGenerator(df)<br/>train_idx, valid_idx, test_idx = data_generator.generate_split_indexes()<!-- --> </span></pre><h1 id="c933" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">构建我们的模型</h1><p id="d76a" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">在这一步，我们将定义我们的多输出Keras模型。我们的模型将由三个主要分支组成，每个分支对应一个可用的特征:年龄、性别和种族。</p><p id="cb0b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的卷积层的默认结构基于一个带有ReLU激活的Conv2D层，然后是BatchNormalization层、MaxPooling层，最后是MaxPooling层。这些层中的每一层之后是最终的致密层。对我们试图预测的每个输出重复这一步。</p><p id="0707" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些默认层是在<em class="nd">make _ default _ hidden _ layers</em>方法中定义的，它将在构建我们模型的每个分支时被重用。在下面的代码中，我们将定义负责创建多输出模型的类。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="64d0" class="mm km iq mi b gy mn mo l mp mq">from keras.models import Model<br/>from keras.layers.normalization import BatchNormalization<br/>from keras.layers.convolutional import Conv2D<br/>from keras.layers.convolutional import MaxPooling2D<br/>from keras.layers.core import Activation<br/>from keras.layers.core import Dropout<br/>from keras.layers.core import Lambda<br/>from keras.layers.core import Dense<br/>from keras.layers import Flatten<br/>from keras.layers import Input<br/>import tensorflow as tf</span><span id="1b37" class="mm km iq mi b gy mr mo l mp mq">class UtkMultiOutputModel():<br/>    """<br/>    Used to generate our multi-output model. This CNN contains three branches, one for age, other for <br/>    sex and another for race. Each branch contains a sequence of Convolutional Layers that is defined<br/>    on the make_default_hidden_layers method.<br/>    """<br/>    def make_default_hidden_layers(self, inputs):<br/>        """<br/>        Used to generate a default set of hidden layers. The structure used in this network is defined as:<br/>        <br/>        Conv2D -&gt; BatchNormalization -&gt; Pooling -&gt; Dropout<br/>        """<br/>        x = Conv2D(16, (3, 3), padding="same")(inputs)<br/>        x = Activation("relu")(x)<br/>        x = BatchNormalization(axis=-1)(x)<br/>        x = MaxPooling2D(pool_size=(3, 3))(x)<br/>        x = Dropout(0.25)(x)</span><span id="9db8" class="mm km iq mi b gy mr mo l mp mq">        x = Conv2D(32, (3, 3), padding="same")(x)<br/>        x = Activation("relu")(x)<br/>        x = BatchNormalization(axis=-1)(x)<br/>        x = MaxPooling2D(pool_size=(2, 2))(x)<br/>        x = Dropout(0.25)(x)</span><span id="0a5c" class="mm km iq mi b gy mr mo l mp mq">        x = Conv2D(32, (3, 3), padding="same")(x)<br/>        x = Activation("relu")(x)<br/>        x = BatchNormalization(axis=-1)(x)<br/>        x = MaxPooling2D(pool_size=(2, 2))(x)<br/>        x = Dropout(0.25)(x)</span><span id="2fbd" class="mm km iq mi b gy mr mo l mp mq">        return x</span><span id="1611" class="mm km iq mi b gy mr mo l mp mq">    def build_race_branch(self, inputs, num_races):<br/>        """<br/>        Used to build the race branch of our face recognition network.<br/>        This branch is composed of three Conv -&gt; BN -&gt; Pool -&gt; Dropout blocks, <br/>        followed by the Dense output layer.<br/>        """<br/>        x = self.make_default_hidden_layers(inputs)</span><span id="d2e2" class="mm km iq mi b gy mr mo l mp mq">        x = Flatten()(x)<br/>        x = Dense(128)(x)<br/>        x = Activation("relu")(x)<br/>        x = BatchNormalization()(x)<br/>        x = Dropout(0.5)(x)<br/>        x = Dense(num_races)(x)<br/>        x = Activation("softmax", name="race_output")(x)</span><span id="d5e0" class="mm km iq mi b gy mr mo l mp mq">        return x</span><span id="4ee4" class="mm km iq mi b gy mr mo l mp mq">    def build_gender_branch(self, inputs, num_genders=2):<br/>        """<br/>        Used to build the gender branch of our face recognition network.<br/>        This branch is composed of three Conv -&gt; BN -&gt; Pool -&gt; Dropout blocks, <br/>        followed by the Dense output layer.<br/>        """<br/>        x = Lambda(lambda c: tf.image.rgb_to_grayscale(c))(inputs)</span><span id="df0d" class="mm km iq mi b gy mr mo l mp mq">        x = self.make_default_hidden_layers(inputs)</span><span id="bc29" class="mm km iq mi b gy mr mo l mp mq">        x = Flatten()(x)<br/>        x = Dense(128)(x)<br/>        x = Activation("relu")(x)<br/>        x = BatchNormalization()(x)<br/>        x = Dropout(0.5)(x)<br/>        x = Dense(num_genders)(x)<br/>        x = Activation("sigmoid", name="gender_output")(x)</span><span id="53ba" class="mm km iq mi b gy mr mo l mp mq">        return x</span><span id="a6e4" class="mm km iq mi b gy mr mo l mp mq">    def build_age_branch(self, inputs):   <br/>        """<br/>        Used to build the age branch of our face recognition network.<br/>        This branch is composed of three Conv -&gt; BN -&gt; Pool -&gt; Dropout blocks, <br/>        followed by the Dense output layer.</span><span id="8cce" class="mm km iq mi b gy mr mo l mp mq">        """<br/>        x = self.make_default_hidden_layers(inputs)</span><span id="2659" class="mm km iq mi b gy mr mo l mp mq">        x = Flatten()(x)<br/>        x = Dense(128)(x)<br/>        x = Activation("relu")(x)<br/>        x = BatchNormalization()(x)<br/>        x = Dropout(0.5)(x)<br/>        x = Dense(1)(x)<br/>        x = Activation("linear", name="age_output")(x)</span><span id="0e77" class="mm km iq mi b gy mr mo l mp mq">        return x</span><span id="531b" class="mm km iq mi b gy mr mo l mp mq">    def assemble_full_model(self, width, height, num_races):<br/>        """<br/>        Used to assemble our multi-output model CNN.<br/>        """<br/>        input_shape = (height, width, 3)</span><span id="80f2" class="mm km iq mi b gy mr mo l mp mq">        inputs = Input(shape=input_shape)</span><span id="7147" class="mm km iq mi b gy mr mo l mp mq">        age_branch = self.build_age_branch(inputs)<br/>        race_branch = self.build_race_branch(inputs, num_races)<br/>        gender_branch = self.build_gender_branch(inputs)</span><span id="5f28" class="mm km iq mi b gy mr mo l mp mq">        model = Model(inputs=inputs,<br/>                     outputs = [age_branch, race_branch, gender_branch],<br/>                     name="face_net")</span><span id="7a9d" class="mm km iq mi b gy mr mo l mp mq">        return model<br/>    <br/>model = UtkMultiOutputModel().assemble_full_model(IM_WIDTH, IM_HEIGHT, num_races=len(dataset_dict['race_alias']))</span></pre><p id="b92d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们看一下我们的模型结构，以便更好地理解我们正在构建什么。从中我们可以看到，我们有一个单一的输入，在我们的情况下，是我们正在向CNN提供的图像，它确实分解为三个独立的分支，每个分支都有自己的卷积层，然后是各自的密集层。</p><figure class="md me mf mg gt nf gh gi paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gh gi nl"><img src="../Images/9db8f884288cea03b4bae314e0b8d35f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*0d1EuC-05YszSh-3.png"/></div></div></figure><h1 id="307c" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">训练我们的模型</h1><p id="1a64" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">现在，一旦我们有了可以使用的数据和定义的模型架构，就该训练我们的多输出模型了。但是在进行这一步之前，我们需要编译我们的模型。对于这个任务，我们将使用0.0004的学习率和Adam优化器，但是您也可以随意尝试其他超参数。我们还将为每个特征使用自定义损失权重和自定义损失函数。在构建我们的优化器时，让我们使用一个基于学习率除以时期数的衰减，因此我们将在时期内慢慢降低我们的学习率。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="1858" class="mm km iq mi b gy mn mo l mp mq">from keras.optimizers import Adam</span><span id="fe51" class="mm km iq mi b gy mr mo l mp mq">init_lr = 1e-4<br/>epochs = 100</span><span id="9d2d" class="mm km iq mi b gy mr mo l mp mq">opt = Adam(lr=init_lr, decay=init_lr / epochs)</span><span id="ce18" class="mm km iq mi b gy mr mo l mp mq">model.compile(optimizer=opt, <br/>              loss={<br/>                  'age_output': 'mse', <br/>                  'race_output': 'categorical_crossentropy', <br/>                  'gender_output': 'binary_crossentropy'},<br/>              loss_weights={<br/>                  'age_output': 4., <br/>                  'race_output': 1.5, <br/>                  'gender_output': 0.1},<br/>              metrics={<br/>                  'age_output': 'mae', <br/>                  'race_output': 'accuracy',<br/>                  'gender_output': 'accuracy'})</span></pre><p id="e708" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，让我们用有效集和训练集的批量大小32来训练我们的模型。我们将使用一个<em class="nd">模型检查点</em>回调，以便在每个时期结束时将模型保存在磁盘上。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="bd92" class="mm km iq mi b gy mn mo l mp mq">from keras.callbacks import ModelCheckpoint</span><span id="730a" class="mm km iq mi b gy mr mo l mp mq">batch_size = 32<br/>valid_batch_size = 32<br/>train_gen = data_generator.generate_images(train_idx, is_training=True, batch_size=batch_size)<br/>valid_gen = data_generator.generate_images(valid_idx, is_training=True, batch_size=valid_batch_size)</span><span id="6396" class="mm km iq mi b gy mr mo l mp mq">callbacks = [<br/>    ModelCheckpoint("./model_checkpoint", monitor='val_loss')<br/>]</span><span id="9fe0" class="mm km iq mi b gy mr mo l mp mq">history = model.fit_generator(train_gen,<br/>                    steps_per_epoch=len(train_idx)//batch_size,<br/>                    epochs=epochs,<br/>                    callbacks=callbacks,<br/>                    validation_data=valid_gen,<br/>                    validation_steps=len(valid_idx)//valid_batch_size)</span></pre><p id="1fd1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">训练完模型后，让我们更好地了解一下模型在各个时期的训练集和验证集上的表现:</p><h2 id="0898" class="mm km iq bd kn ms mt dn kr mu mv dp kv jy mw mx kz kc my mz ld kg na nb lh nc bi translated">比赛准确性</h2><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="c9dc" class="mm km iq mi b gy mn mo l mp mq">plt.clf()<br/>fig = go.Figure()<br/>fig.add_trace(go.Scatter(<br/>                    y=history.history['race_output_acc'],<br/>                    name='Train'))</span><span id="810b" class="mm km iq mi b gy mr mo l mp mq">fig.add_trace(go.Scatter(<br/>                    y=history.history['val_race_output_acc'],<br/>                    name='Valid'))<br/></span><span id="1756" class="mm km iq mi b gy mr mo l mp mq">fig.update_layout(height=500, <br/>                  width=700,<br/>                  title='Accuracy for race feature',<br/>                  xaxis_title='Epoch',<br/>                  yaxis_title='Accuracy')</span><span id="f6c7" class="mm km iq mi b gy mr mo l mp mq">fig.show()</span></pre><figure class="md me mf mg gt nf gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/0a0d7bd61f8321ce7cd97b89ec4deddf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1174/format:webp/1*R84W-0delDU34SG8BdVzig.png"/></div></figure><p id="282e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以看到，在第50个时期，我们的模型在验证集上稳定下来，仅在训练集上有所增加，准确率约为80%。</p><h2 id="a189" class="mm km iq bd kn ms mt dn kr mu mv dp kv jy mw mx kz kc my mz ld kg na nb lh nc bi translated">性别准确性</h2><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="36ef" class="mm km iq mi b gy mn mo l mp mq">plt.clf()</span><span id="4eb4" class="mm km iq mi b gy mr mo l mp mq">fig = go.Figure()<br/>fig.add_trace(go.Scatter(<br/>                    y=history.history['gender_output_acc'],<br/>                    name='Train'))</span><span id="f363" class="mm km iq mi b gy mr mo l mp mq">fig.add_trace(go.Scatter(<br/>                    y=history.history['val_gender_output_acc'],<br/>                    name='Valid'))<br/></span><span id="d937" class="mm km iq mi b gy mr mo l mp mq">fig.update_layout(height=500, <br/>                  width=700,<br/>                  title='Accuracy for gender feature',<br/>                  xaxis_title='Epoch',<br/>                  yaxis_title='Accuracy')<br/></span><span id="83ac" class="mm km iq mi b gy mr mo l mp mq">fig.show()</span></pre><figure class="md me mf mg gt nf gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/c51fba56b6dec96216603b946c7df279.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*3d5l0teYpU9Ukx0ctxO6zw.png"/></div></figure><p id="e3be" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">与种族特征类似，我们可以看到，我们的模型能够学习大多数模式，以在第30个时期正确预测给定个体的性别，准确率约为90%。</p><h2 id="b198" class="mm km iq bd kn ms mt dn kr mu mv dp kv jy mw mx kz kc my mz ld kg na nb lh nc bi translated">年龄平均绝对误差</h2><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="2eaa" class="mm km iq mi b gy mn mo l mp mq">plt.clf()</span><span id="1445" class="mm km iq mi b gy mr mo l mp mq">fig = go.Figure()<br/>fig.add_trace(go.Scattergl(<br/>                    y=history.history['age_output_mean_absolute_error'],<br/>                    name='Train'))</span><span id="00fc" class="mm km iq mi b gy mr mo l mp mq">fig.add_trace(go.Scattergl(<br/>                    y=history.history['val_age_output_mean_absolute_error'],<br/>                    name='Valid'))<br/></span><span id="0864" class="mm km iq mi b gy mr mo l mp mq">fig.update_layout(height=500, <br/>                  width=700,<br/>                  title='Mean Absolute Error for age feature',<br/>                  xaxis_title='Epoch',<br/>                  yaxis_title='Mean Absolute Error')</span><span id="8eaf" class="mm km iq mi b gy mr mo l mp mq">fig.show()</span></pre><figure class="md me mf mg gt nf gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/56e959ff179a67cf10e31b2c2e069067.png" data-original-src="https://miro.medium.com/v2/resize:fit:1158/format:webp/1*ftngaweGt0MlXvkZ2WSYwg.png"/></div></figure><p id="b7f7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在预测年龄特征的任务中，我们可以看到，我们的模型需要大约60个时期来适当地稳定其学习过程，平均绝对误差为0.09。</p><h2 id="984d" class="mm km iq bd kn ms mt dn kr mu mv dp kv jy mw mx kz kc my mz ld kg na nb lh nc bi translated">总体损失</h2><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="209b" class="mm km iq mi b gy mn mo l mp mq">fig = go.Figure()<br/>fig.add_trace(go.Scattergl(<br/>                    y=history.history['loss'],<br/>                    name='Train'))</span><span id="f8bd" class="mm km iq mi b gy mr mo l mp mq">fig.add_trace(go.Scattergl(<br/>                    y=history.history['val_loss'],<br/>                    name='Valid'))<br/></span><span id="4ad5" class="mm km iq mi b gy mr mo l mp mq">fig.update_layout(height=500, <br/>                  width=700,<br/>                  title='Overall loss',<br/>                  xaxis_title='Epoch',<br/>                  yaxis_title='Loss')</span><span id="60ec" class="mm km iq mi b gy mr mo l mp mq">fig.show()</span></pre><figure class="md me mf mg gt nf gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/3594e751d77bc79a63321c24b1768744.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*RBpnjMPotVasSVWi5VajIQ.png"/></div></figure><p id="c29e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以注意到，到了时期50，我们的模型开始稳定，损失值大约为1.4。在损失曲线中也有一个峰值，它确实出现在年龄特征的平均绝对误差中，这可以解释年龄特征的学习对总损失的影响。</p><h1 id="de41" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">在测试集上评估我们的模型</h1><p id="4345" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">为了评估我们的模型在测试集上的表现，让我们使用我们的UTK数据生成器类，但是这次使用测试索引。然后，我们将从训练好的模型中调用<em class="nd"> predict_generator </em>方法，该方法将输出测试集的预测。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="d620" class="mm km iq mi b gy mn mo l mp mq">test_batch_size = 128<br/>test_generator = data_generator.generate_images(test_idx, is_training=False, batch_size=test_batch_size)<br/>age_pred, race_pred, gender_pred = model.predict_generator(test_generator, <br/>                                                           steps=len(test_idx)//test_batch_size)</span></pre><p id="6a03" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们在所有测试样本上再迭代一次，以便将它们的标签放在一个列表中。我们还将提取每个记录的<em class="nd"> argmax </em>，以便检索顶级预测和基本事实。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="91d3" class="mm km iq mi b gy mn mo l mp mq">test_generator = data_generator.generate_images(test_idx, is_training=False, batch_size=test_batch_size)<br/>samples = 0<br/>images, age_true, race_true, gender_true = [], [], [], []<br/>for test_batch in test_generator:<br/>    image = test_batch[0]<br/>    labels = test_batch[1]<br/>    <br/>    images.extend(image)<br/>    age_true.extend(labels[0])<br/>    race_true.extend(labels[1])<br/>    gender_true.extend(labels[2])<br/>    <br/>age_true = np.array(age_true)<br/>race_true = np.array(race_true)<br/>gender_true = np.array(gender_true)</span><span id="9136" class="mm km iq mi b gy mr mo l mp mq">race_true, gender_true = race_true.argmax(axis=-1), gender_true.argmax(axis=-1)<br/>race_pred, gender_pred = race_pred.argmax(axis=-1), gender_pred.argmax(axis=-1)</span><span id="ae34" class="mm km iq mi b gy mr mo l mp mq">age_true = age_true * data_generator.max_age<br/>age_pred = age_pred * data_generator.max_age</span></pre><p id="704b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，让我们打印测试集上每个特性的分类报告。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="95e6" class="mm km iq mi b gy mn mo l mp mq">from sklearn.metrics import classification_report</span><span id="ac79" class="mm km iq mi b gy mr mo l mp mq">cr_race = classification_report(race_true, race_pred, target_names=dataset_dict['race_alias'].keys())<br/>print(cr_race)</span><span id="7146" class="mm km iq mi b gy mr mo l mp mq">precision    recall  f1-score   support</span><span id="7f75" class="mm km iq mi b gy mr mo l mp mq">       white       0.80      0.91      0.85      2994<br/>       black       0.86      0.82      0.84      1327<br/>       asian       0.86      0.79      0.83      1046<br/>      indian       0.74      0.74      0.74      1171<br/>      others       0.38      0.19      0.25       502</span><span id="3154" class="mm km iq mi b gy mr mo l mp mq">    accuracy                           0.80      7040<br/>   macro avg       0.73      0.69      0.70      7040<br/>weighted avg       0.78      0.80      0.78      7040</span></pre><p id="7798" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从上面的报告中，我们可以看到，我们的模型在预测亚裔和黑人个体方面非常出色，准确率为86%，其次是白人80%，印度人74%。“其他”种族的精确度仅为38%，但我们需要考虑到，与其他群体相比，该群体由不同的种族和民族以及一些样本组成。这一分类任务的加权准确率为78%，表明我们的分类器能够正确地学习模式以区分不同类型的种族。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="9dee" class="mm km iq mi b gy mn mo l mp mq">cr_gender = classification_report(gender_true, gender_pred, target_names=dataset_dict['gender_alias'].keys())<br/>print(cr_gender)</span><span id="8ea0" class="mm km iq mi b gy mr mo l mp mq"><strong class="mi ir">precision    recall  f1-score   support</strong></span><span id="cfbf" class="mm km iq mi b gy mr mo l mp mq"><strong class="mi ir">        male       0.94      0.87      0.91      3735<br/>      female       0.87      0.94      0.90      3305</strong></span><span id="00e9" class="mm km iq mi b gy mr mo l mp mq"><strong class="mi ir">    accuracy                           0.90      7040<br/>   macro avg       0.90      0.91      0.90      7040<br/>weighted avg       0.91      0.90      0.90      7040</strong></span></pre><p id="9b5d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从这个报告中，我们可以注意到，我们的模型在预测给定个体的性别方面非常出色，对于这项任务，加权准确率为91%。</p><pre class="md me mf mg gt mh mi mj mk aw ml bi"><span id="43fb" class="mm km iq mi b gy mn mo l mp mq">from sklearn.metrics import r2_score</span><span id="23de" class="mm km iq mi b gy mr mo l mp mq">print('R2 score for age: ', r2_score(age_true, age_pred))</span></pre><p id="15a1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">R2年龄得分:0.582979466456328</p><h2 id="bd36" class="mm km iq bd kn ms mt dn kr mu mv dp kv jy mw mx kz kc my mz ld kg na nb lh nc bi translated">参考</h2><p id="01a4" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">http://aicip.eecs.utk.edu/wiki/UTKFace UTK人脸数据集:<a class="ae mc" href="http://aicip.eecs.utk.edu/wiki/UTKFace" rel="noopener ugc nofollow" target="_blank"/></p><p id="ae55" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Keras多输出文档:<a class="ae mc" href="https://keras.io/getting-started/functional-api-guide/" rel="noopener ugc nofollow" target="_blank">https://keras.io/getting-started/functional-api-guide/</a></p><p id="2e7e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">SanjayaSubedi关于多输出模型的帖子:<a class="ae mc" href="https://sanjayasubedi.com.np/deeplearning/multioutput-keras/" rel="noopener ugc nofollow" target="_blank">https://sanjayasubdi . com . NP/deep learning/multi output-keras/</a></p><p id="d69e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">时尚网上的PyImageSearch帖子:<a class="ae mc" href="https://www.pyimagesearch.com/2018/06/04/keras-multiple-outputs-and-multiple-losses/" rel="noopener ugc nofollow" target="_blank">https://www . PyImageSearch . com/2018/06/04/keras-multiple-outputs-and-multiple-loss/</a></p><p id="cb79" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">剧情:<a class="ae mc" href="https://plot.ly/" rel="noopener ugc nofollow" target="_blank">https://plot.ly/</a></p></div></div>    
</body>
</html>