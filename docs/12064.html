<html>
<head>
<title>Stop persisting pandas data frames in CSVs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">停止在 CSV 中保存 pandas 数据帧</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/stop-persisting-pandas-data-frames-in-csvs-f369a6440af5?source=collection_archive---------3-----------------------#2020-08-20">https://towardsdatascience.com/stop-persisting-pandas-data-frames-in-csvs-f369a6440af5?source=collection_archive---------3-----------------------#2020-08-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6882" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">pickle、parquet 和其他产品的优势——更快、更可靠、更高效</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a6b9db5dc1a4bc0338dca065acefb410.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LatSbYCBpL7Fc2nxKJKfOw.jpeg"/></div></div></figure><p id="bfd1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">CSV 是一种很好的数据交换格式。它在世界各地都可以理解，并且可以在普通记事本中编辑。这并不意味着它适合持久化所有数据帧。CSV 的读写速度很慢，它们占用更多的磁盘空间，最重要的是 CSV 不存储关于<strong class="kw iu">数据类型</strong>的信息。</p><p id="9695" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">CSV 的优势:</p><ul class=""><li id="0f75" class="lq lr it kw b kx ky la lb ld ls lh lt ll lu lp lv lw lx ly bi translated">普遍可以理解</li><li id="fcbc" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated">大多数编程语言都支持解析和创建</li></ul><p id="d1d4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">CSV 的缺点:</p><ul class=""><li id="0df0" class="lq lr it kw b kx ky la lb ld ls lh lt ll lu lp lv lw lx ly bi translated">更大的磁盘使用率</li><li id="27f4" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated">读写速度较慢</li><li id="f47e" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated">不要存储关于数据类型的信息</li></ul><p id="5fee" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">伊利亚·扎依采夫对各种熊猫坚持方法的速度和内存使用做了很好的分析。当我们编写自动化性能测试程序时，我会在最后谈到性能。首先，我想关注一件不同的事情——这些文件格式如何处理各种数据类型。</p><h1 id="a6b4" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">熊猫数据类型</h1><p id="4779" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">Pandas 支持丰富的数据类型，其中一些数据类型具有多种子类型，以便更有效地处理大数据框。基本数据类型包括:</p><ul class=""><li id="68b9" class="lq lr it kw b kx ky la lb ld ls lh lt ll lu lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">object </code> —字符串或混合类型</li><li id="45b2" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">string</code> — <a class="ae me" href="https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html" rel="noopener ugc nofollow" target="_blank">自熊猫 1.0.0 </a></li><li id="15ee" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">int </code> —整数</li><li id="4698" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">float </code> —浮点数</li><li id="560d" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">bool </code> —布尔值真和假</li><li id="5187" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">datetime</code> —日期和时间值</li><li id="d1c2" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">timedelta </code>—两个日期时间之间的时间差</li><li id="7ca4" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">category </code> —有限的值列表存储在高效内存查找中</li></ul><p id="9ef1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">由于 pandas 使用 numpy 数组作为其后端结构，<code class="fe nc nd ne nf b">int</code> s 和<code class="fe nc nd ne nf b">float</code> s 可以区分为更高效的内存类型，如<code class="fe nc nd ne nf b">int8</code>、<code class="fe nc nd ne nf b">int16</code>、<code class="fe nc nd ne nf b">int32</code>、<code class="fe nc nd ne nf b">int64</code>、<code class="fe nc nd ne nf b">unit8</code>、<code class="fe nc nd ne nf b">uint16</code>、<code class="fe nc nd ne nf b">uint32</code>和<code class="fe nc nd ne nf b">uint64</code>以及<code class="fe nc nd ne nf b">float32</code>和<code class="fe nc nd ne nf b">float64</code>。</p><p id="07ef" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">CSV 不存储关于数据类型的信息，您必须用每个<code class="fe nc nd ne nf b">read_csv()</code>来指定它。在没有告知 CSV 阅读器的情况下，它将推断所有整数列为效率最低的<code class="fe nc nd ne nf b">int64</code>，浮点为<code class="fe nc nd ne nf b">float64</code>，类别将作为字符串和日期时间加载。</p><pre class="kj kk kl km gt ng nf nh ni aw nj bi"><span id="40dd" class="nk mg it nf b gy nl nm l nn no"># for each loaded dataset you have to specify the formats to make DataFrame efficient</span><span id="9b6b" class="nk mg it nf b gy np nm l nn no">df = pd.read_csv(new_file,<br/>                 dtype={"colA": "int8",<br/>                        "colB": "int16",<br/>                        "colC": "uint8",<br/>                        "colcat": "category"},<br/>                 parse_dates=["colD","colDt"])</span></pre><p id="5c84" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><code class="fe nc nd ne nf b"><strong class="kw iu">TimeDeltas</strong></code>作为字符串存储在 CSV<code class="fe nc nd ne nf b">-5 days +18:59:39.000000</code>中，你必须编写一个特殊的解析器将这些字符串转换回熊猫的 timedelta 格式。</p><p id="6b18" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><code class="fe nc nd ne nf b">Timezones</code>看起来像<code class="fe nc nd ne nf b">2020-08-06 15:35:06-06:00</code>，在<code class="fe nc nd ne nf b">read_csv()</code>中也需要特殊处理。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/01303c2394d1b0c4fc7c1d383dd842b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*gbX3FGbWRXIE4rXvL4nPZw.jpeg"/></div><p class="nr ns gj gh gi nt nu bd b be z dk translated">使用不带参数的 read_csv()比较原始数据类型和自动推断的类型</p></figure></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><h1 id="0601" class="mf mg it bd mh mi oc mk ml mm od mo mp jz oe ka mr kc of kd mt kf og kg mv mw bi translated">CSV 替代方案</h1><p id="ac96" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">幸运的是，csv 不是持久存储数据帧的唯一选择。<a class="ae me" href="https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html" rel="noopener ugc nofollow" target="_blank">阅读熊猫的 IO 工具</a>你看到一个数据帧可以写成多种格式，数据库，甚至剪贴板。</p><p id="96c0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你可以用这个<a class="ae me" href="https://github.com/vaclavdekanovsky/data-analysis-in-examples/blob/master/Pandas/Persistance/Stop%20Persisting%20Pandas%20to%20CSV.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu"> GitHub </strong> </a>笔记本自己运行代码。最后，我将详细描述数据是如何创建的，并使用一个真实的数据帧指导您完成性能测试和健全性检查。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/4466b69963c74eb24bedef16b985a52d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*inwRugaLFdcrz6G-PZI8jg.jpeg"/></div></div><p class="nr ns gj gh gi nt nu bd b be z dk translated">在本文中，我们用几个参数测试了许多类型的持久化方法。由于<a class="ae me" rel="noopener" target="_blank" href="/visualization-with-plotly-express-comprehensive-guide-eb5ee4b50b57"> Plotly </a>的交互功能，您可以探索任何方法的组合，图表将自动更新。</p></figure><h1 id="f172" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">Pickle 和 to_pickle()</h1><p id="3758" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">Pickle 是用于对象序列化的<a class="ae me" href="https://docs.python.org/3/library/pickle.html" rel="noopener ugc nofollow" target="_blank"> python 原生格式</a>。它允许 python 代码实现任何类型的增强，如<a class="ae me" href="https://www.python.org/dev/peps/pep-0574/" rel="noopener ugc nofollow" target="_blank">pep 574</a>pickle 带外数据缓冲区中描述的最新协议 5。</p><p id="d297" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这也意味着在 Python 生态系统之外进行酸洗是困难的。然而，如果你想存储一些预处理过的数据以备后用，或者你不想在没有直接使用这些数据的情况下浪费掉几个小时的分析工作，就把它们保存起来<a class="ae me" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_pickle.html" rel="noopener ugc nofollow" target="_blank"/>。</p><pre class="kj kk kl km gt ng nf nh ni aw nj bi"><span id="dd6b" class="nk mg it nf b gy nl nm l nn no"># Pandas's to_pickle method<br/>df.to_pickle(path)</span></pre><p id="6d47" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">与<code class="fe nc nd ne nf b">.to_csv()</code> <code class="fe nc nd ne nf b">.to_pickle()</code>相反，方法只接受 3 个参数。</p><ul class=""><li id="7ec0" class="lq lr it kw b kx ky la lb ld ls lh lt ll lu lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">path </code> —数据将存储在哪里</li><li id="3938" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">compression </code> —允许选择多种压缩方式</li><li id="13d9" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b"><a class="ae me" href="https://docs.python.org/3/library/pickle.html#data-stream-format" rel="noopener ugc nofollow" target="_blank">protocol </a></code> —更高的协议可以更高效地处理更广泛的数据</li></ul><p id="171c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">泡菜的优点:</p><ul class=""><li id="71ee" class="lq lr it kw b kx ky la lb ld ls lh lt ll lu lp lv lw lx ly bi translated">比 CSV 快(CSV 写入的 5–300%，CSV 读取的 15–200%，具体取决于压缩方法)</li><li id="4f00" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated">生成的文件较小(约为 csv 的 50%)</li><li id="f2c9" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated">它保留了关于数据类型的信息(100%)</li><li id="1bae" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated">不需要指定过多的参数</li></ul><p id="482b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">泡菜的缺点:</p><ul class=""><li id="5854" class="lq lr it kw b kx ky la lb ld ls lh lt ll lu lp lv lw lx ly bi translated">原生于 python，所以它缺乏对其他编程语言的支持</li><li id="a153" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated">即使跨不同 python 版本也不可靠</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/5061bd24edf5041bb703d6053b3e2f3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*_-9rsNp7MsdMtGg1Nqj_Bg.jpeg"/></div><p class="nr ns gj gh gi nt nu bd b be z dk translated">Pickle 能够序列化 100%的 padnas 数据类型</p></figure><p id="0600" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">当您读取在 python 的新版本中创建的 pickle 时，您会得到一个错误:</p><pre class="kj kk kl km gt ng nf nh ni aw nj bi"><span id="e5cc" class="nk mg it nf b gy nl nm l nn no"><strong class="nf iu">ValueError</strong>: unsupported pickle protocol: 5</span></pre><h1 id="0a07" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated"><strong class="ak">拼花和 to_parquet() </strong></h1><p id="9e96" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">Apache Parquet 是 Hadoop 生态系统中使用的压缩二进制列存储格式。它允许序列化复杂的嵌套结构，支持按列压缩和按列编码，并提供快速读取，因为它不需要读取整个列，因为您只需要部分数据。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oj ok l"/></div></figure><pre class="kj kk kl km gt ng nf nh ni aw nj bi"><span id="2961" class="nk mg it nf b gy nl nm l nn no"># Pandas's to_parquet method<br/>df.to_parquet(path, engine, compression, index, partition_cols)</span></pre><p id="24ee" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><code class="fe nc nd ne nf b">.to_parquet()</code>方法只接受几个参数。</p><ul class=""><li id="531b" class="lq lr it kw b kx ky la lb ld ls lh lt ll lu lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">path </code> —存储数据的位置</li><li id="c345" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">engine </code> — pyarrow 或 fastparquet 引擎。<code class="fe nc nd ne nf b">pyarrow</code>通常更快，但它与<code class="fe nc nd ne nf b">timedelta</code>格式斗争。<code class="fe nc nd ne nf b">fastparquet</code>可以明显变慢。</li><li id="441b" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">compression </code> —允许选择多种压缩方式</li><li id="6581" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">index </code> —是否存储数据帧的索引</li><li id="ba89" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">partition_cols </code> —指定列分区的顺序</li></ul><p id="c5f1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">拼花地板的优点:</p><ul class=""><li id="935c" class="lq lr it kw b kx ky la lb ld ls lh lt ll lu lp lv lw lx ly bi translated">比 CSV 快(从 10 行开始，pyarrow 大约快 5 倍)</li><li id="611d" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated">生成的文件更小(约为 CSV 的 50%)</li><li id="3ee4" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated">它保存关于数据类型的信息(pyarrow 不能处理 timedelta，而较慢的 fastparquet 可以)</li><li id="c54e" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated">Hadoop 生态系统中的广泛支持允许在许多分区中进行快速过滤</li></ul><p id="67de" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">拼花地板的缺点:</p><ul class=""><li id="e21b" class="lq lr it kw b kx ky la lb ld ls lh lt ll lu lp lv lw lx ly bi translated">不支持重复的列名</li><li id="858a" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated">pyarrow 引擎不支持某些数据类型</li></ul><p id="c00a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">更多细节请访问<a class="ae me" href="https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#parquet" rel="noopener ugc nofollow" target="_blank">熊猫 IO 页面</a>。</p></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><h1 id="c08d" class="mf mg it bd mh mi oc mk ml mm od mo mp jz oe ka mr kc of kd mt kf og kg mv mw bi translated">Excel 和 to_excel()</h1><p id="e87d" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">有时候，将数据导出到 excel 中很方便。它以最慢的读写速度为代价，增加了易于操作的优势。它还忽略了许多数据类型。<code class="fe nc nd ne nf b">Timezones</code>根本无法写入 excel。</p><pre class="kj kk kl km gt ng nf nh ni aw nj bi"><span id="d49a" class="nk mg it nf b gy nl nm l nn no"># exporting a dataframe to excel<br/>df.to_excel(excel_writer, sheet_name, many_other_parameters)</span></pre><p id="de05" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有用的参数:</p><ul class=""><li id="678c" class="lq lr it kw b kx ky la lb ld ls lh lt ll lu lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">excel_writer </code> —熊猫 excel writer 对象或文件路径</li><li id="c424" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">sheet_name </code> —将输出数据的工作表的名称</li><li id="cab0" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">float_format </code> — excel 的原生数字格式</li><li id="f96f" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">columns </code>-别名数据框列的选项</li><li id="c5bf" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">startrow </code> —向下移动起始单元格的选项</li><li id="bbb2" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">engine </code> — <code class="fe nc nd ne nf b">openpyxl</code>或<code class="fe nc nd ne nf b">xlsxwriter</code></li><li id="e7f3" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">freeze_panes </code> —冻结行和列的选项</li></ul><p id="959c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">excel 的优势:</p><ul class=""><li id="6213" class="lq lr it kw b kx ky la lb ld ls lh lt ll lu lp lv lw lx ly bi translated">允许自定义格式和单元格冻结</li><li id="10cd" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated">人类可读和可编辑的格式</li></ul><p id="00c3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">excel 的缺点:</p><ul class=""><li id="5d8b" class="lq lr it kw b kx ky la lb ld ls lh lt ll lu lp lv lw lx ly bi translated">非常慢的读/写速度(慢 20/40 倍)</li><li id="3ae5" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated">限制为 1048576 行</li><li id="256d" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated">带时区的日期时间序列化失败</li></ul><p id="e976" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">更多关于<a class="ae me" href="https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#excel-files" rel="noopener ugc nofollow" target="_blank">熊猫 IO 页面</a>的信息。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/04681057e0e720e894d16d66607928dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X41fJQeF_znqXk2Rd4cqIw.jpeg"/></div></div><p class="nr ns gj gh gi nt nu bd b be z dk translated">excel 的性能测试结果。只有 54%的列保留了原始的数据类型，它占用了 CSV 的 90%的大小，但是写的时间多了 20 倍，读的时间多了 42 倍</p></figure><h1 id="8663" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">HDF5 和 to_hdf()</h1><p id="ce9d" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">使用内部文件式结构的压缩格式，适用于巨大的异构数据。如果我们需要随机访问数据集的各个部分，这也是非常理想的。如果数据存储为<code class="fe nc nd ne nf b">table</code> (PyTable)，您可以使用<code class="fe nc nd ne nf b">store.select(key,where="A&gt;0 or B&lt;5")</code>直接查询 hdf 存储</p><pre class="kj kk kl km gt ng nf nh ni aw nj bi"><span id="0330" class="nk mg it nf b gy nl nm l nn no"># exporting a dataframe to hdf<br/>df.to_hdf(path_or_buf, key, mode, complevel, complib, append ...)</span></pre><p id="c0d2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有用的参数:</p><ul class=""><li id="dc67" class="lq lr it kw b kx ky la lb ld ls lh lt ll lu lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">path_or_buf</code> —文件路径或 HDFStore 对象</li><li id="7b22" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">key</code>—商场内的团体标识</li><li id="478a" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">mode</code> —写入、附加或读取-附加</li><li id="0746" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">format</code> — <code class="fe nc nd ne nf b">fixed</code>用于快速写入和读取，而<code class="fe nc nd ne nf b">table</code>允许仅选择数据的子集</li></ul><p id="4874" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">HDF5 的优势:</p><ul class=""><li id="d9bb" class="lq lr it kw b kx ky la lb ld ls lh lt ll lu lp lv lw lx ly bi translated">对于某些数据结构，其大小和访问速度可能非常惊人</li></ul><p id="42ea" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">HDF5 的缺点:</p><ul class=""><li id="27a0" class="lq lr it kw b kx ky la lb ld ls lh lt ll lu lp lv lw lx ly bi translated">数据帧可以非常大(甚至比 csv 大 300 倍)</li><li id="7d4c" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated">HDFStore 对于写入不是线程安全的</li><li id="aa3d" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">fixed</code>格式无法处理分类值</li></ul><h1 id="ee81" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated"><strong class="ak"> SQL 和 to_sql() </strong></h1><p id="3f4a" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">将数据持久存储到数据库中通常很有用。像<code class="fe nc nd ne nf b">sqlalchemy</code>这样的库致力于这项任务。</p><pre class="kj kk kl km gt ng nf nh ni aw nj bi"><span id="8c55" class="nk mg it nf b gy nl nm l nn no"># Set up sqlalchemy engine<br/>engine = create_engine(<br/>    'mssql+pyodbc://user:pass@localhost/DB?driver=ODBC+Driver+13+for+SQL+server',<br/>    isolation_level="REPEATABLE READ"<br/>)</span><span id="495e" class="nk mg it nf b gy np nm l nn no"># connect to the DB<br/>connection = engine.connect()</span><span id="eecd" class="nk mg it nf b gy np nm l nn no"># exporting dataframe to SQL<br/>df.to_sql(name="test", con=connection)</span></pre><p id="5888" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有用的参数:</p><ul class=""><li id="b44c" class="lq lr it kw b kx ky la lb ld ls lh lt ll lu lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">name </code>—SQL 表的名称</li><li id="b2e2" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">con </code> —通常由<code class="fe nc nd ne nf b">sqlalchemy.engine</code>连接引擎</li><li id="0fcc" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">chunksize </code> —可以选择按 chunksize 批量加载数据</li></ul><p id="ad8f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">SQL 的优势:</p><ul class=""><li id="db80" class="lq lr it kw b kx ky la lb ld ls lh lt ll lu lp lv lw lx ly bi translated">比在磁盘上持久存储慢(读取 10 次/写入 5 次，但这可以优化)</li><li id="9fe5" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated">所有程序员都能理解数据库</li></ul><p id="1cb9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">SQL 的缺点:</p><ul class=""><li id="f1ae" class="lq lr it kw b kx ky la lb ld ls lh lt ll lu lp lv lw lx ly bi translated">有些数据格式没有保留——类别、整数、浮点和时间增量</li><li id="5dbd" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated">根据数据库的不同，性能可能会很慢</li><li id="8b60" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated">在某些情况下，您可能很难建立数据库连接</li></ul><p id="67ae" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你想增加<code class="fe nc nd ne nf b">.to_sql()</code>的写时间，试试 Kiran Kumar Chilla 在加速批量插入文章中描述的方法。</p><div class="om on gp gr oo op"><a href="https://medium.com/analytics-vidhya/speed-up-bulk-inserts-to-sql-db-using-pandas-and-python-61707ae41990" rel="noopener follow" target="_blank"><div class="oq ab fo"><div class="or ab os cl cj ot"><h2 class="bd iu gy z fp ou fr fs ov fu fw is bi translated">使用 Pandas 和 Python 加速 SQL db 的批量插入</h2><div class="ow l"><h3 class="bd b gy z fp ou fr fs ov fu fw dk translated">本文详细介绍了:1 .使用 pandas 和 pyodbc 将数据帧写入数据库的不同方法 2。如何…</h3></div><div class="ox l"><p class="bd b dl z fp ou fr fs ov fu fw dk translated">medium.com</p></div></div><div class="oy l"><div class="oz l pa pb pc oy pd ks op"/></div></div></a></div><h1 id="0f00" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">羽化和羽化()</h1><p id="7c6e" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated"><a class="ae me" href="https://arrow.apache.org/docs/python/feather.html" rel="noopener ugc nofollow" target="_blank"> Feather </a>是一种轻量级格式，用于存储数据框和箭头表。这是如何存储数据的另一种选择，相对较快，文件较小。它没有包括在测量中，因为引擎在相当长的时间内锁定文件，很难重复几次性能测试。如果您计划将数据框持久化一次，feather 可能是一个理想的选择。</p><h1 id="0161" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">其他方法</h1><p id="5bd8" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">熊猫提供了更多的坚持和阅读方法。我省略了 json 和 fix-width-file，因为它们具有类似 csv 的特征。可以尝试用<code class="fe nc nd ne nf b">.to_gbq()</code>或者<code class="fe nc nd ne nf b">stata</code>格式直接写到谷歌大查询。新的格式肯定会出现，以满足与各种云提供商通信的需求。</p><p id="2956" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">多亏了这篇文章，当我把一行程序复制到电子邮件、excel 或 google doc 时，我开始喜欢上了<code class="fe nc nd ne nf b">.to_clipboard()</code>。</p><h1 id="46e2" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">特性试验</h1><p id="f379" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">许多方法都比 CSV 有优势，但是当 CSV 在世界范围内如此容易理解时，是否值得使用这些不寻常的方法。让我们来看看表演。</p><p id="9912" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在性能测试期间，我关注 4 个关键指标:</p><ul class=""><li id="6905" class="lq lr it kw b kx ky la lb ld ls lh lt ll lu lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">data type preservation</code> —读取后有多少%的列保持原始类型</li><li id="406a" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">compression/size</code> —文件有多大，以 csv 的百分比表示</li><li id="5bb4" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">write_time </code> —编写这种格式需要多长时间，占 csv 编写时间的%</li><li id="35e0" class="lq lr it kw b kx lz la ma ld mb lh mc ll md lp lv lw lx ly bi translated"><code class="fe nc nd ne nf b">read_time </code> —读取此格式需要多长时间，占 csv 读取时间的%</li></ul><p id="5c35" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为此，我准备了一个包含 50K 随机数、字符串、类别、日期时间和布尔值的数据集。数值范围来自<a class="ae me" href="https://numpy.org/doc/stable/user/basics.types.html" rel="noopener ugc nofollow" target="_blank"> numpy 数据类型概述</a>。</p><pre class="kj kk kl km gt ng nf nh ni aw nj bi"><span id="b425" class="nk mg it nf b gy nl nm l nn no">data = []<br/>for i in range(1000000):<br/>    data.append(<br/>        [random.randint(-127,127),  # int8<br/>         random.randint(-32768,32767),  # int16<br/>        ...</span></pre><blockquote class="pe pf pg"><p id="f2c3" class="ku kv ph kw b kx ky ju kz la lb jx lc pi le lf lg pj li lj lk pk lm ln lo lp im bi translated">产生随机样本是几乎每个测试都要用到的技巧。</p></blockquote><p id="41de" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你可以在<a class="ae me" href="https://github.com/vaclavdekanovsky/data-analysis-in-examples/blob/master/Pandas/Persistance/Stop%20Persisting%20Pandas%20to%20CSV.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub </a>笔记本中查看生成随机字符串和日期的支持功能，这里我只提一个:</p><pre class="kj kk kl km gt ng nf nh ni aw nj bi"><span id="c5a2" class="nk mg it nf b gy nl nm l nn no">def get_random_string(length: int) -&gt; str:<br/>    """Generated random string up to the specific lenght"""<br/>    <br/>    letters = string.ascii_letters<br/>    result_str = ''.join([random.choice(letters) for i in range(random.randint(3,length))])<br/>    return result_str</span></pre><p id="2cee" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">生成数据帧的完整代码描述如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pl ok l"/></div><p class="nr ns gj gh gi nt nu bd b be z dk translated">生成随机数据，并在 7 次迭代中测量读/写速度</p></figure><p id="440b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">一旦我们有了一些数据，我们希望通过不同的算法反复处理它们。您可以分别编写每个测试，但是让我们将测试压缩成一行:</p><pre class="kj kk kl km gt ng nf nh ni aw nj bi"><span id="58d4" class="nk mg it nf b gy nl nm l nn no"># performance test<br/>performance_df = performance_test(exporting_types)</span><span id="35c8" class="nk mg it nf b gy np nm l nn no"># results<br/>performance_df.style.format("{:.2%}")</span></pre><p id="f588" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><code class="fe nc nd ne nf b">performance_test </code>函数接受一个带有测试定义的字典，如下所示:</p><pre class="kj kk kl km gt ng nf nh ni aw nj bi"><span id="a9c0" class="nk mg it nf b gy nl nm l nn no">d = { ...</span><span id="e8b6" class="nk mg it nf b gy np nm l nn no">"parquet_fastparquet": {<br/>        "type": "Parquet via fastparquet",<br/>        "extension": ".parquet.gzip",<br/>        "write_function": pd.DataFrame.to_parquet,<br/>        "write_params": {"engine":"fastparquet","compression":"GZIP"},<br/>        "read_function": pd.read_parquet,<br/>        "read_params": {"engine":"fastparquet"}<br/>    }<br/>... }</span></pre><p id="fa76" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">字典包含应该运行的功能，例如<code class="fe nc nd ne nf b">pd.DataFrame.to_parquet</code>和参数。我们迭代字典，一个接一个地运行函数:</p><pre class="kj kk kl km gt ng nf nh ni aw nj bi"><span id="08a3" class="nk mg it nf b gy nl nm l nn no">path = "output_file"<br/># df is our performance test sample dataframe</span><span id="2fe4" class="nk mg it nf b gy np nm l nn no"># persist the df<br/>d["write_function"](df, path, **d["write_params"])</span><span id="8884" class="nk mg it nf b gy np nm l nn no"># load the df <br/>df_loaded = d["read_function"](path, **d["read_params"]</span></pre><p id="4231" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我将结果存储到一个数据帧中，以便利用<a class="ae me" rel="noopener" target="_blank" href="/visualization-with-plotly-express-comprehensive-guide-eb5ee4b50b57">。Express </a>用几行代码显示结果的能力:</p><pre class="kj kk kl km gt ng nf nh ni aw nj bi"><span id="519b" class="nk mg it nf b gy nl nm l nn no"># display the graph with the results<br/>fig = pe.bar(performance_df.T, barmode='group', text="value")</span><span id="ff2a" class="nk mg it nf b gy np nm l nn no"># format the labels<br/>fig.update_traces(texttemplate='%{text:.2%}', textposition='auto')</span><span id="7e5a" class="nk mg it nf b gy np nm l nn no"># add a title<br/>fig.update_layout(title=f"Statistics for {dataset_size} records")<br/>fig.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pm"><img src="../Images/640850306a041b9a875754364cec9f95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pNXOHnjspGuiOInpp2q8zQ.jpeg"/></div></div><p class="nr ns gj gh gi nt nu bd b be z dk translated">性能测试结果。数据格式保存测量成功百分比以及大小和速度与 csv 进行比较。</p></figure><div class="om on gp gr oo op"><a rel="noopener follow" target="_blank" href="/visualization-with-plotly-express-comprehensive-guide-eb5ee4b50b57"><div class="oq ab fo"><div class="or ab os cl cj ot"><h2 class="bd iu gy z fp ou fr fs ov fu fw is bi translated">用 Plotly 可视化。快递:综合指南</h2><div class="ow l"><h3 class="bd b gy z fp ou fr fs ov fu fw dk translated">一个数据集和 70 多个图表。交互性和动画通常只需一行代码。</h3></div><div class="ox l"><p class="bd b dl z fp ou fr fs ov fu fw dk translated">towardsdatascience.com</p></div></div><div class="oy l"><div class="pn l pa pb pc oy pd ks op"/></div></div></a></div><h2 id="c09a" class="nk mg it bd mh po pp dn ml pq pr dp mp ld ps pt mr lh pu pv mt ll pw px mv py bi translated">健全性检查</h2><p id="f1dc" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">在随机样本上测试东西对于获得你的应用程序或工具有多好的第一印象是有用的，但是一旦它必须符合现实。为了避免任何意外，您应该在真实数据上尝试您的代码。我选择了我最喜欢的数据集——美国证券交易委员会季度数据转储——并对其进行性能测试。我已经获得了非常相似的结果，这使我相信我的假设不是完全错误的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pz"><img src="../Images/6ab88593c82c33dfdbd076441169dc02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l0NPZpDRrsXaFXU1dhutfQ.jpeg"/></div></div><p class="nr ns gj gh gi nt nu bd b be z dk translated">对 SEC 季度数据转储的 8 列进行健全性检查的结果证实了性能测试的结果。</p></figure><div class="om on gp gr oo op"><a rel="noopener follow" target="_blank" href="/stock-fundamental-analysis-eda-of-secs-quarterly-data-summary-455e62ff4817"><div class="oq ab fo"><div class="or ab os cl cj ot"><h2 class="bd iu gy z fp ou fr fs ov fu fw is bi translated">股票基本面分析:SEC 季度数据汇总的 EDA</h2><div class="ow l"><h3 class="bd b gy z fp ou fr fs ov fu fw dk translated">大熊猫 2020 SEC 申报的探索性数据分析</h3></div><div class="ox l"><p class="bd b dl z fp ou fr fs ov fu fw dk translated">towardsdatascience.com</p></div></div><div class="oy l"><div class="qa l pa pb pc oy pd ks op"/></div></div></a></div></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><h1 id="a608" class="mf mg it bd mh mi oc mk ml mm od mo mp jz oe ka mr kc of kd mt kf og kg mv mw bi translated">结论</h1><p id="6f8a" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">尽管 pickle 显然赢得了性能竞赛，但在一些用例中，您可能更愿意选择另一种格式。我们还有一个非常特殊的数据集，在真实数据上，性能可能会有所不同。</p><p id="b03d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">请随意使用<a class="ae me" href="https://github.com/vaclavdekanovsky/data-analysis-in-examples/blob/master/Pandas/Persistance/Stop%20Persisting%20Pandas%20to%20CSV.ipynb" rel="noopener ugc nofollow" target="_blank">代码(GitHub) </a>，并在您喜欢的数据集上尝试性能。对我个人来说，当我存储预处理数据集时，<code class="fe nc nd ne nf b">.to_pickle()</code>很棒，因为我不必担心数据格式，我只需将<code class="fe nc nd ne nf b">read_pickle()</code>和工作时间具体化到我的笔记本上。</p><div class="om on gp gr oo op"><a rel="noopener follow" target="_blank" href="/complete-guide-to-pythons-cross-validation-with-examples-a9676b5cac12"><div class="oq ab fo"><div class="or ab os cl cj ot"><h2 class="bd iu gy z fp ou fr fs ov fu fw is bi translated">python 交叉验证的完整指南及示例</h2><div class="ow l"><h3 class="bd b gy z fp ou fr fs ov fu fw dk translated">sklearn 交叉验证的示例和使用案例解释了 k 折叠、洗牌、分层以及它如何影响…</h3></div><div class="ox l"><p class="bd b dl z fp ou fr fs ov fu fw dk translated">towardsdatascience.com</p></div></div><div class="oy l"><div class="qb l pa pb pc oy pd ks op"/></div></div></a></div><div class="om on gp gr oo op"><a rel="noopener follow" target="_blank" href="/is-something-better-than-pandas-when-the-dataset-fits-the-memory-7e8e983c4fe5"><div class="oq ab fo"><div class="or ab os cl cj ot"><h2 class="bd iu gy z fp ou fr fs ov fu fw is bi translated">当数据集符合内存时，是否有比熊猫更好的东西？</h2><div class="ow l"><h3 class="bd b gy z fp ou fr fs ov fu fw dk translated">探索 Vaex，Dask，PySpark，摩丁和朱莉娅</h3></div><div class="ox l"><p class="bd b dl z fp ou fr fs ov fu fw dk translated">towardsdatascience.com</p></div></div><div class="oy l"><div class="qc l pa pb pc oy pd ks op"/></div></div></a></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qd"><img src="../Images/54771ec31d1a5d5d7cf200331a0fa4dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3mo3C_yxIIW6VpkDvcINMg.jpeg"/></div></div><p class="nr ns gj gh gi nt nu bd b be z dk translated">canva.com 制造</p></figure><pre class="kj kk kl km gt ng nf nh ni aw nj bi"><span id="aff3" class="nk mg it nf b gy nl nm l nn no">If you want to create inspiring infographics like the one above, use <a class="ae me" href="https://canva.7eqqol.net/WnbXZ" rel="noopener ugc nofollow" target="_blank">canva.com</a> (affiliate link, when you click on it and purchase a product, you won't pay more, but I can receive a small reward; you can always write canva.com to your browser to avoid this). You can do more than infographic and some features are available for free.</span></pre></div></div>    
</body>
</html>