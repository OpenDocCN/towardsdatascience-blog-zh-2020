<html>
<head>
<title>How to Deal with Imbalanced Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何处理不平衡数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-deal-with-imbalanced-data-34ab7db9b100?source=collection_archive---------8-----------------------#2020-06-21">https://towardsdatascience.com/how-to-deal-with-imbalanced-data-34ab7db9b100?source=collection_archive---------8-----------------------#2020-06-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ac91" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">Python中处理不平衡数据集的分步指南</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/db708be740c1f385a1ca448c2f5fb57d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZOOzbRCbrgRKkptbY26t6Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者照片</p></figure><p id="5e93" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">具有不平衡类的数据集是常见的数据科学问题，也是常见的面试问题。在本文中，我提供了一个分步指南来改进您的模型并很好地处理不平衡的数据。您最常看到不平衡数据的领域是分类问题，如垃圾邮件过滤、欺诈检测和医疗诊断。</p><h2 id="5d94" class="lr ls iq bd lt lu lv dn lw lx ly dp lz le ma mb mc li md me mf lm mg mh mi mj bi translated"><strong class="ak">是什么让不平衡的数据成为问题？</strong></h2><p id="2d63" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">几乎每个数据集都有不同的类表示。只要差异很小，这就不是问题。然而，当一个或多个类非常罕见时，许多模型在识别少数类时不太好用。在本文中，为了简单起见，我将假设一个两类问题(一个多数类和一个少数类)，但是这些技术中的大多数也适用于多个数据集。</p><p id="7a29" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">通常，我们会查看验证分割的准确性，以确定我们的模型是否表现良好。然而，当数据不平衡时，准确性可能会产生误导。例如，假设您有一个数据集，其中92%的数据被标记为“非欺诈”，剩下的8%是“欺诈”案例。数据明显不平衡。现在假设我们的模型最终将它看到的一切都归类为“非欺诈”。然而，如果我们着眼于准确性，这是一个惊人的92%。但银行仍然关心那些“欺诈”案件。这就是它赔钱的地方。那么我们如何改进我们的模型呢？</p><p id="a321" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了克服不平衡数据集的问题，您可以执行以下一系列步骤和决策。</p><h1 id="9dc9" class="mp ls iq bd lt mq mr ms lw mt mu mv lz jw mw jx mc jz mx ka mf kc my kd mi mz bi translated"><strong class="ak"> 1。能收集更多数据吗</strong></h1><p id="213a" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">你可能会说，“好吧，网上的随便一个人，如果我能收集更多的数据，我就不会读这些了，不是吗？收集更多数据”。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi na"><img src="../Images/f7da2a766d0599e4739abc617b3aa7b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1166/format:webp/1*rwZwTifvkQDdAyjJkrp6Kg.jpeg"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">通过https://stopthatrightnow.github.io/<a class="ae nb" href="https://stopthatrightnow.github.io/" rel="noopener ugc nofollow" target="_blank">生成的图像</a></p></figure><p id="ae52" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">但是听我说完。后退一步，考虑以下问题:</p><ul class=""><li id="d690" class="nc nd iq kx b ky kz lb lc le ne li nf lm ng lq nh ni nj nk bi translated">你收到的数据是否经过了筛选，以排除可能导致辅修课观察被忽略的情况。</li><li id="5ebe" class="nc nd iq kx b ky nl lb nm le nn li no lm np lq nh ni nj nk bi translated">你有多少年的历史，如果你回到一两年前，你会得到更多的数据仍然合理的次要类的实例。</li><li id="3ef5" class="nc nd iq kx b ky nl lb nm le nn li no lm np lq nh ni nj nk bi translated">如果是客户数据，我们能否使用不再订阅我们服务的客户，而不影响我们试图解决的参数。也许使用这些以前的客户记录，以及“当前客户”?(Y/N)"布尔变量会有所帮助。</li><li id="5ce5" class="nc nd iq kx b ky nl lb nm le nn li no lm np lq nh ni nj nk bi translated">你能把你的少数民族班合并成一个班吗？例如，如果您正在对一个人的心跳中的不同类型的异常进行分类，而不是试图对每种类型的异常进行分类，那么如果我们将它们都合并到一个单一的“异常心跳”类别中，该模型还会有用吗？</li></ul><p id="1a77" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">只是一些想法和一个提醒，总是考虑不同的可能性。</p><h1 id="f199" class="mp ls iq bd lt mq mr ms lw mt mu mv lz jw mw jx mc jz mx ka mf kc my kd mi mz bi translated"><strong class="ak"> 2。</strong> <strong class="ak">更改绩效指标</strong></h1><p id="cc59" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">如上所述，由于在处理不平衡数据集时，精确度不是一个好的衡量标准，所以让我们考虑更合适的衡量标准。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/0887b0209335defe4afc684c76a24066.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*X6M4nhCbMaHUxfrqUXvr2A.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者的混淆矩阵照片</p></figure><p id="135a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">基于混淆矩阵，我们可以测量以下内容:</p><ul class=""><li id="9b09" class="nc nd iq kx b ky kz lb lc le ne li nf lm ng lq nh ni nj nk bi translated"><strong class="kx ir">精度:</strong>真阳性/所有预测阳性= TP / (TP+FP)。精度是对分类器准确性的度量。低精度表示大量的误报。</li><li id="8638" class="nc nd iq kx b ky nl lb nm le nn li no lm np lq nh ni nj nk bi translated"><strong class="kx ir">回忆:</strong>真阳性/所有实际阳性= TP / (TP + FN)。召回是对分类器完整性的一种度量。它也与敏感度或真实阳性率相同。低召回率表示大量的假阴性。</li><li id="a31e" class="nc nd iq kx b ky nl lb nm le nn li no lm np lq nh ni nj nk bi translated"><strong class="kx ir"> F1得分:</strong> 2TP/(2TP + FP + FN)精度和召回率的加权平均值。如果我们想在精确度和召回率之间取得平衡，那么我们应该看看F1的分数。</li></ul><h2 id="a0c9" class="lr ls iq bd lt lu lv dn lw lx ly dp lz le ma mb mc li md me mf lm mg mh mi mj bi translated">注意:这里我假设少数类在混淆矩阵中被标记为正类。</h2><p id="a3e3" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">查看此<a class="ae nb" href="https://en.wikipedia.org/wiki/Confusion_matrix" rel="noopener ugc nofollow" target="_blank">维基百科</a>页面，获取绩效指标公式列表。</p><p id="0c14" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们还可以看一看:</p><ul class=""><li id="3f70" class="nc nd iq kx b ky kz lb lc le ne li nf lm ng lq nh ni nj nk bi translated"><strong class="kx ir">灵敏度/特异性</strong>ROC曲线:灵敏度与回忆基本一致，告诉我们真实的阳性率。</li><li id="35c3" class="nc nd iq kx b ky nl lb nm le nn li no lm np lq nh ni nj nk bi translated"><strong class="kx ir"> Kappa(或</strong> <a class="ae nb" href="https://en.wikipedia.org/wiki/Cohen%27s_kappa" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ir">科恩的kappa </strong> </a> <strong class="kx ir"> ) </strong>:分类精度由数据中类别的不平衡性归一化。</li></ul><p id="13f3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这种情况下，我们希望寻找高回忆/灵敏度和f1分数，而不是准确性，以查看我们的模型在预测辅修课程方面的表现。</p><p id="b4c6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">Jason Brownlee在这里了解更多关于选择不同绩效指标的信息<a class="ae nb" href="https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="ff88" class="mp ls iq bd lt mq mr ms lw mt mu mv lz jw mw jx mc jz mx ka mf kc my kd mi mz bi translated"><strong class="ak"> 3。</strong> <strong class="ak">尝试不同的算法</strong></h1><p id="49a8" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">与大多数数据科学问题一样，对数据尝试几种不同的合适算法始终是一种好的做法。</p><p id="dc97" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有两种主要类型的算法似乎对不平衡数据集问题有效。</p><h2 id="b4d0" class="lr ls iq bd lt lu lv dn lw lx ly dp lz le ma mb mc li md me mf lm mg mh mi mj bi translated"><strong class="ak">决策树</strong></h2><p id="42ac" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">决策树似乎在不平衡数据集上表现得很好。因为他们在拆分的每个阶段都提出了条件/规则，所以他们最终把两个类都考虑进去了。</p><p id="25d1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们可以尝试一些不同的决策树算法，如随机森林、CART、C4.5。</p><h2 id="1fc4" class="lr ls iq bd lt lu lv dn lw lx ly dp lz le ma mb mc li md me mf lm mg mh mi mj bi translated"><strong class="ak">处罚车型:</strong></h2><p id="86ed" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">惩罚学习模型(代价敏感训练)对模型强加了额外的代价，用于在训练期间对少数类进行分类错误。这迫使模型更多地关注少数类观察。</p><h2 id="cbdc" class="lr ls iq bd lt lu lv dn lw lx ly dp lz le ma mb mc li md me mf lm mg mh mi mj bi translated">异常检测模型:</h2><p id="b4e5" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">如果只是2个类，多数类和少数类，那么您可以考虑使用异常检测模型而不是分类模型。这些异常模型试图做的是为多数类创建一个配置文件。任何不符合这一特征的观察都被认为是异常或异常值，在我们的例子中是来自少数群体的观察。这类模型用于欺诈检测等情况。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/f241626379e9d6f87af3f2811dd3b691.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*xA3W-M88I1QQnlVMg5UmvQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">异常检测图片来自<a class="ae nb" href="https://commons.wikimedia.org/wiki/File:Kernel_Machine.svg" rel="noopener ugc nofollow" target="_blank">维基百科</a> ( <a class="ae nb" href="https://creativecommons.org/licenses/by-sa/4.0" rel="noopener ugc nofollow" target="_blank"> CC BY-SA 4.0 </a>)</p></figure><h1 id="fd4b" class="mp ls iq bd lt mq mr ms lw mt mu mv lz jw mw jx mc jz mx ka mf kc my kd mi mz bi translated"><strong class="ak"> 4。</strong> <strong class="ak">对数据集进行重新采样</strong></h1><p id="8834" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">这一步可以在尝试上述不同的模型方法时完成。不同类型的重采样如下:</p><ol class=""><li id="1d0a" class="nc nd iq kx b ky kz lb lc le ne li nf lm ng lq ns ni nj nk bi translated">对多数类欠采样</li><li id="43f7" class="nc nd iq kx b ky nl lb nm le nn li no lm np lq ns ni nj nk bi translated">对少数民族阶层进行过度采样</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/be814468433f4c9ef7a7db921f92abd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*cgUBkjNSJnPjmnS3GcyB8g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">按作者对数据照片进行重采样</p></figure><h2 id="dcea" class="lr ls iq bd lt lu lv dn lw lx ly dp lz le ma mb mc li md me mf lm mg mh mi mj bi translated">欠采样(下采样)多数类</h2><p id="66bf" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">欠采样随机移除多数类的观测值。这减少了在训练集中使用的多数类观察的数量，并且因此更好地平衡了两个类的观察的数量。当您的数据集中有大量观测值(&gt; 10K观测值)时，这非常适合。风险是你正在丢失信息，因此可能导致不适合。</p><p id="a068" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">Scikit-learn提供了一种“重采样”方法，我们可以用它来进行欠采样。不平衡学习包还提供了更高级的功能。Python代码示例如下所示:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="d388" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由于多数类的许多观测值已被丢弃，因此产生的数据集现在要小得多。这两个班级的比例现在是1:1。</p><p id="e672" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">注:</strong>我们不一定要使用1:1的比率，我们可以使用这种方法将多数类观察的数量减少到任何合理的比率。</p><h2 id="bee2" class="lr ls iq bd lt lu lv dn lw lx ly dp lz le ma mb mc li md me mf lm mg mh mi mj bi translated"><strong class="ak">过采样(上采样)少数类</strong></h2><p id="843e" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">过采样随机复制少数类的观测值，以使其信号更强。最简单的过采样形式是置换采样。当数据集中没有大量观测值(&lt; 10K观测值)时，过采样非常合适。风险在于，如果你重复了太多的观察，那么你就是过度拟合了。</p><p id="a70e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们可以使用相同的scikit-learn“重采样”方法，但使用不同的参数。下面显示了一个代码示例:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="0d2a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这一次，我们使用替换进行采样，以便在最终的训练集中有更多的代表性。但正如我提到的，这可能会导致过度拟合。那么，怎样才能把事情做得更好，避免过度拟合呢？</p><h1 id="215d" class="mp ls iq bd lt mq mr ms lw mt mu mv lz jw mw jx mc jz mx ka mf kc my kd mi mz bi translated"><strong class="ak"> 5。</strong> <strong class="ak">生成合成样本</strong></h1><p id="7d39" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">为了减少上采样期间的过拟合，我们可以尝试创建合成样本。</p><h2 id="06be" class="lr ls iq bd lt lu lv dn lw lx ly dp lz le ma mb mc li md me mf lm mg mh mi mj bi translated">重击</h2><p id="3ad5" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">一个流行的算法是<a class="ae nb" href="https://imbalanced-learn.org/stable/generated/imblearn.over_sampling.SMOTE.html?highlight=smote" rel="noopener ugc nofollow" target="_blank"> SMOTE </a>(合成少数过采样技术)。SMOTE不是使用观测值的副本进行过采样，而是改变观测值的属性来创建新的合成样本。</p><p id="6bdc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">你可以在这里找到SMOTE <a class="ae nb" href="https://imbalanced-learn.org/stable/auto_examples/combine/plot_comparison_combine.html#sphx-glr-auto-examples-combine-plot-comparison-combine-py" rel="noopener ugc nofollow" target="_blank">的例子。</a></p><h2 id="a4df" class="lr ls iq bd lt lu lv dn lw lx ly dp lz le ma mb mc li md me mf lm mg mh mi mj bi translated">增大</h2><p id="0f7e" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">与SMOTE类似，如果您的数据是音频或图像之类的东西，那么您也可以对原始文件执行转换来创建新的样本。</p><h1 id="1dd7" class="mp ls iq bd lt mq mr ms lw mt mu mv lz jw mw jx mc jz mx ka mf kc my kd mi mz bi translated">6.<strong class="ak">结论</strong></h1><p id="cf96" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">正如数据科学和机器学习算法中的大多数事情一样，没有每次都有效的确定的正确方法。根据数据集的性质、类的分布、预测器和模型，上述一些方法会比其他方法更好。这取决于你来找出最佳的组合。</p><p id="5b90" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">需要记住的几点是:</p><ul class=""><li id="ac4d" class="nc nd iq kx b ky kz lb lc le ne li nf lm ng lq nh ni nj nk bi translated">在创建合成/增强样本之前，始终进行训练/测试分割。您希望根据原始数据观察来验证和测试您的模型</li><li id="8ba2" class="nc nd iq kx b ky nl lb nm le nn li no lm np lq nh ni nj nk bi translated">使用相同的衡量标准进行比较——每次你尝试新的东西时，记得正确地进行比较。不要只看一个型号的精度，另一个型号的灵敏度。</li></ul><p id="8a3d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">除了这些步骤之外，不要忘记您还必须做一些事情，例如数据清理、功能选择和超参数调整。</p><p id="05df" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="nw">希望这有所帮助！</em></p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="bfee" class="lr ls iq ny b gy oc od l oe of">if_you_like(this_article):<br/>    please(CLAPS) # Do this :)<br/>else:<br/>     initiate_sad_author()  # Don't do this :(</span><span id="e001" class="lr ls iq ny b gy og od l oe of"># Thanks :)</span></pre></div><div class="ab cl oh oi hu oj" role="separator"><span class="ok bw bk ol om on"/><span class="ok bw bk ol om on"/><span class="ok bw bk ol om"/></div><div class="ij ik il im in"><h1 id="640e" class="mp ls iq bd lt mq oo ms lw mt op mv lz jw oq jx mc jz or ka mf kc os kd mi mz bi translated">参考资料和进一步阅读</h1><p id="5d58" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">博伊尔塔拉。"处理不平衡数据的方法."中等。2019年2月04日。2020年6月21日访问。<a class="ae nb" rel="noopener" target="_blank" href="/methods-for-dealing-with-imbalanced-data-5b761be45a18.">https://towards data science . com/methods-for-processing-unbalanced-data-5b 761 be 45 a 18。</a></p><p id="ce2f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">布朗利，杰森。"在你的机器学习数据集中对抗不平衡类的8个策略."机器学习精通。2020年1月14日。2020年6月21日访问。https://machine learning mastery . com/tactics-to-combat-unbalanced-classes-in-your-machine-learning-dataset/。</p><p id="0224" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">"如何处理机器学习中不平衡的类."2020年5月23日。<a class="ae nb" href="https://elitedatascience.com/imbalanced-classes." rel="noopener ugc nofollow" target="_blank">https://elitedatascience.com/imbalanced-classes.</a></p></div></div>    
</body>
</html>