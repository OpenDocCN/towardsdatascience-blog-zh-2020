<html>
<head>
<title>Early Stopping in Practice: an example with Keras and TensorFlow 2.0</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">实践中的早期停止:以 Keras 和 TensorFlow 2.0 为例</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-practical-introduction-to-early-stopping-in-machine-learning-550ac88bc8fd?source=collection_archive---------3-----------------------#2020-07-28">https://towardsdatascience.com/a-practical-introduction-to-early-stopping-in-machine-learning-550ac88bc8fd?source=collection_archive---------3-----------------------#2020-07-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ebe5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">添加和自定义提前停止的分步教程</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4eaa9e8fe645d5abd033627b8e25ef6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xpYwlkaQO98T0UATIG50nw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">塞缪尔·伯克在<a class="ae ky" href="https://unsplash.com/s/photos/machine-learning?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="7b3e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们将重点关注在我们的机器学习模型中添加和定制早期停止，并查看我们如何在 Keras 和 TensorFlow 2.0 的实践中做到这一点的示例。</p><h1 id="b21d" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">提前停止简介</h1><p id="8426" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在机器学习中，早期停止是最广泛使用的<a class="ae ky" rel="noopener" target="_blank" href="/machine-learning-model-regularization-in-practice-an-example-with-keras-and-tensorflow-2-0-52a96746123e">正则化技术</a>之一，用于对抗<strong class="lb iu"> <em class="ms">过拟合</em> </strong>问题。</p><blockquote class="mt"><p id="048e" class="mu mv it bd mw mx my mz na nb nc lu dk translated">早期停止在训练期间监视保持的验证集上每个时期的模型性能，并根据验证性能终止训练。</p><p id="51f3" class="mu mv it bd mw mx my mz na nb nc lu dk translated">来自动手 ML [1]</p></blockquote><p id="e249" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">早期停止是一种非常不同的正则化机器学习模型的方法。其方法是，一旦验证误差达到最小值，就停止训练。下图显示了一个正在训练的模型。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/6b65e4b77294c85081b548c9a6355714.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iAK5uMoOlX1gZu-cSh1nZw.png"/></div></div></figure><p id="0edf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随着时代的推移，算法倾斜，它在训练集上的误差自然下降，在验证集上的误差也下降。然而，过了一段时间后，验证误差停止下降，实际上开始回升。这表明模型已经开始过度拟合训练数据。通过提前停止，只要验证误差达到最小值，您就可以停止训练。</p><p id="7160" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是一种简单而有效的规则化技术，杰弗里·辛顿称之为“美丽的免费午餐”[1].</p><h2 id="979a" class="nj lw it bd lx nk nl dn mb nm nn dp mf li no np mh lm nq nr mj lq ns nt ml nu bi translated">随机和小批量梯度下降</h2><p id="0095" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">随着随机和小批量梯度下降，曲线不是那么平滑，可能很难知道你是否达到了最小值。一种解决方案是，仅在验证误差超过最小值一段时间后停止(当您确信模型不会做得更好时)，然后将模型参数回滚到验证误差最小的点。</p><p id="1387" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在下面的文章中，我们将在我们的机器学习模型中添加和定制早期停止。</p><h1 id="f27d" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">环境设置和数据集准备</h1><p id="3c86" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我们将使用我们在<a class="ae ky" rel="noopener" target="_blank" href="/machine-learning-model-regularization-in-practice-an-example-with-keras-and-tensorflow-2-0-52a96746123e">模型正则化</a>和<a class="ae ky" rel="noopener" target="_blank" href="/batch-normalization-in-practice-an-example-with-keras-and-tensorflow-2-0-b1ec28bde96f">批量归一化</a>中使用的相同数据集。如果你已经熟悉这一章，你可以跳过它。</p><p id="20f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了运行本教程，您需要安装</p><blockquote class="mt"><p id="7d12" class="mu mv it bd mw mx my mz na nb nc lu dk translated"><em class="nv"> TensorFlow 2，numpy，pandas，sklean，matplotlib </em></p></blockquote><p id="3e1f" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">它们都可以直接安装在 vis PyPI 上，我强烈建议创建一个新的虚拟环境。关于创建 Python 虚拟环境的教程</p><ul class=""><li id="48f2" class="nw nx it lb b lc ld lf lg li ny lm nz lq oa lu ob oc od oe bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/create-virtual-environment-using-virtualenv-and-add-it-to-jupyter-notebook-6e1bf4e03415">使用“virtualenv”创建虚拟环境，并将其添加到 Jupyter 笔记本中</a></li><li id="99e6" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated"><a class="ae ky" href="https://medium.com/analytics-vidhya/create-virtual-environment-using-conda-and-add-it-to-jupyter-notebook-d319a81dfd1" rel="noopener">使用“conda”创建虚拟环境，并将其添加到 Jupyter 笔记本中</a></li></ul><h1 id="bae3" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">源代码</h1><p id="88ef" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">这是一个循序渐进的教程，所有的说明都在这篇文章中。源代码请查看我的 Github <a class="ae ky" href="https://github.com/BindiChen/machine-learning/blob/master/tensorflow2/005-early-stopping/early-stopping.ipynb" rel="noopener ugc nofollow" target="_blank">机器学习报告</a>。</p><h1 id="3c4f" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">数据集准备</h1><p id="f56d" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">本教程使用<a class="ae ky" href="https://en.wikipedia.org/wiki/Iris_flower_data_set" rel="noopener ugc nofollow" target="_blank">安德森鸢尾花(iris) </a>数据集进行演示。数据集包含五个属性下的一组 150 条记录:<em class="ms">萼片长度</em>、<em class="ms">萼片宽度</em>、<em class="ms">花瓣长度</em>、<em class="ms">花瓣宽度、</em>和<em class="ms">类</em>(从 sklearn 数据集称为<em class="ms">目标</em>)。</p><p id="94fa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，让我们导入库并从<strong class="lb iu"> <em class="ms"> scikit-learn </em> </strong>库中获取虹膜数据集。你也可以从<a class="ae ky" href="https://archive.ics.uci.edu/ml/datasets/iris" rel="noopener ugc nofollow" target="_blank"> UCI 虹膜数据集</a>下载。</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="63ec" class="nj lw it ol b gy op oq l or os">import tensorflow as tf<br/>import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>from sklearn.datasets import load_iris<br/>from sklearn.model_selection import train_test_split</span><span id="f3da" class="nj lw it ol b gy ot oq l or os"><strong class="ol iu">iris = load_iris()</strong></span></pre><p id="7ce3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了研究数据，让我们将数据加载到一个数据帧中</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="dce8" class="nj lw it ol b gy op oq l or os"># Load data into a DataFrame<br/><strong class="ol iu">df = pd.DataFrame(iris.data, columns=iris.feature_names)<br/></strong># Convert datatype to float<br/><strong class="ol iu">df = df.astype(float)<br/></strong># append "target" and name it "label"<br/><strong class="ol iu">df['label'] = iris.target<br/></strong># Use string label instead<br/><strong class="ol iu">df['label'] = df.label.replace(dict(enumerate(iris.target_names)))</strong></span></pre><p id="c585" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">并且<code class="fe ou ov ow ol b">df</code>应该如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/f7a3a5bc22ae3744ae58d627f5cad14a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WQ9W6yarWnOyEz56LR87kQ.png"/></div></div></figure><p id="f47c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们注意到<strong class="lb iu"> <em class="ms">标签</em> </strong>列是一个分类特征，需要将其转换为<a class="ae ky" rel="noopener" target="_blank" href="/what-is-one-hot-encoding-and-how-to-use-pandas-get-dummies-function-922eb9bd4970">一键编码</a>。否则，我们的机器学习算法将无法直接将其作为输入。</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="4a6a" class="nj lw it ol b gy op oq l or os"># label -&gt; one-hot encoding<br/><strong class="ol iu">label = pd.get_dummies(df['label'], prefix='label')</strong><br/><strong class="ol iu">df = pd.concat([df, label], axis=1)</strong><br/># drop old label<br/>df.drop(['label'], axis=1, inplace=True)</span></pre><p id="9637" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，<code class="fe ou ov ow ol b">df</code>应该是这样的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/bf6c6ea6826b879c4cc325805781cd65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jWXRJnZEHn2xWcyqqbK0bQ.png"/></div></div></figure><p id="6c5f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，让我们创建<code class="fe ou ov ow ol b">X</code>和<code class="fe ou ov ow ol b">y</code>。Keras 和 TensorFlow 2.0 只接受 Numpy 数组作为输入，所以我们必须将 DataFrame 转换回 Numpy 数组。</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="7e78" class="nj lw it ol b gy op oq l or os"># Creating X and y<strong class="ol iu">X = df[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']]</strong><br/># Convert DataFrame into np array<br/><strong class="ol iu">X = np.asarray(X)y = df[['label_setosa', 'label_versicolor', 'label_virginica']]<br/></strong># Convert DataFrame into np array<br/><strong class="ol iu">y = np.asarray(y)</strong></span></pre><p id="b40e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，让我们使用来自<strong class="lb iu"> sklearn </strong>库中的<code class="fe ou ov ow ol b"><strong class="lb iu">train_test_split()</strong></code> <strong class="lb iu"> </strong>将数据集拆分成训练集(80%)和测试集(20%)。</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="322f" class="nj lw it ol b gy op oq l or os">X_train, X_test, y_train, y_test = <strong class="ol iu">train_test_split</strong>(<br/>  <strong class="ol iu">X,<br/>  y,<br/>  test_size=0.20</strong><br/>)</span></pre><p id="fd84" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">太好了！我们的数据已经准备好建立一个机器学习模型。</p><h1 id="7c94" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">建立一个神经网络</h1><p id="efe8" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">用 Keras 和 TensorFlow 2.0 创建机器学习模型有<a class="ae ky" rel="noopener" target="_blank" href="/3-ways-to-create-a-machine-learning-model-with-keras-and-tensorflow-2-0-de09323af4d3"> 3 种方法。由于我们正在构建一个简单的全连接神经网络，为了简单起见，让我们使用最简单的方法:带有<code class="fe ou ov ow ol b">Sequential()</code>的顺序模型。</a></p><p id="b19b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们继续创建一个名为<code class="fe ou ov ow ol b">create_model()</code>的函数来返回一个序列模型。</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="9867" class="nj lw it ol b gy op oq l or os">from tensorflow.keras.models import Sequential<br/>from tensorflow.keras.layers import Dense</span><span id="e67f" class="nj lw it ol b gy ot oq l or os">def <strong class="ol iu">create_model()</strong>: <br/>    model = Sequential([<br/>        Dense(64, activation='relu', <strong class="ol iu">input_shape=(4,)</strong>),<br/>        Dense(128, activation='relu'),<br/>        Dense(128, activation='relu'),<br/>        Dense(128, activation='relu'),<br/>        Dense(64, activation='relu'),<br/>        Dense(64, activation='relu'),<br/>        Dense(64, activation='relu'),<br/>        <strong class="ol iu">Dense(3, activation='softmax')</strong><br/>    ])<br/>    return model</span></pre><p id="5b3f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的型号有以下规格:</p><ul class=""><li id="aaba" class="nw nx it lb b lc ld lf lg li ny lm nz lq oa lu ob oc od oe bi translated">第一层(也称为输入层)有<code class="fe ou ov ow ol b">input_shape</code>来设置输入大小<code class="fe ou ov ow ol b">(4,)</code></li><li id="6868" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated">输入层有 64 个单元，接着是 3 个密集层，每个层有 128 个单元。然后还有 3 个密集层，每个层有 64 个单元。所有这些层都使用 ReLU 激活功能。</li><li id="e0ea" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated">输出密集层有 3 个单元和 softmax 激活功能。</li></ul><h2 id="0e41" class="nj lw it bd lx nk nl dn mb nm nn dp mf li no np mh lm nq nr mj lq ns nt ml nu bi translated">编译和训练模型</h2><p id="fd56" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">为了训练一个模型，我们首先必须使用<code class="fe ou ov ow ol b">compile()</code>配置我们的模型，并传递以下参数:</p><ul class=""><li id="de0b" class="nw nx it lb b lc ld lf lg li ny lm nz lq oa lu ob oc od oe bi translated">使用 Adam ( <code class="fe ou ov ow ol b">adam</code>)优化算法作为优化器</li><li id="f8e2" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated">对于我们的<strong class="lb iu"> <em class="ms">多类分类</em> </strong>问题，使用分类交叉熵损失函数(<code class="fe ou ov ow ol b">categorical_crossentropy</code></li><li id="ef52" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated">为简单起见，使用<code class="fe ou ov ow ol b">accuracy</code>作为我们在训练和测试期间评估模型的评估指标。</li></ul><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="4c3c" class="nj lw it ol b gy op oq l or os">model.compile(<br/>    <strong class="ol iu">optimizer='adam', <br/>    loss='categorical_crossentropy', <br/>    metrics=['accuracy']</strong><br/>)</span></pre><p id="8c38" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">之后，我们可以调用<code class="fe ou ov ow ol b">model.fit()</code>来使我们的模型适合训练数据。</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="d380" class="nj lw it ol b gy op oq l or os">history = model.fit(<br/>    X_train, <br/>    y_train, <br/>    <strong class="ol iu">epochs=200, <br/>    validation_split=0.25, <br/>    batch_size=40, </strong><br/>    verbose=2<br/>)</span></pre><p id="14ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果一切顺利，我们应该得到如下输出</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="fbf3" class="nj lw it ol b gy op oq l or os">Train on 84 samples, validate on 28 samples<br/>Epoch 1/200<br/>84/84 - 1s - loss: 1.0901 - accuracy: 0.3214 - val_loss: 1.0210 - val_accuracy: 0.7143<br/>Epoch 2/200<br/>84/84 - 0s - loss: 1.0163 - accuracy: 0.6905 - val_loss: 0.9427 - val_accuracy: 0.7143<br/>......<br/>Epoch 200/200<br/>84/84 - 0s - loss: 0.5269 - accuracy: 0.8690 - val_loss: 0.4781 - val_accuracy: 0.8929</span></pre><h2 id="6bf8" class="nj lw it bd lx nk nl dn mb nm nn dp mf li no np mh lm nq nr mj lq ns nt ml nu bi translated">绘制学习曲线</h2><p id="0997" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">最后，让我们在训练集和验证集上绘制损失对时期图。</p><p id="eb33" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最好创建一个小函数来绘制指标。我们继续创建一个函数<code class="fe ou ov ow ol b">plot_metric()</code>。</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="3d19" class="nj lw it ol b gy op oq l or os">%matplotlib inline<br/>%config InlineBackend.figure_format = 'svg'def </span><span id="3ea9" class="nj lw it ol b gy ot oq l or os"><strong class="ol iu">plot_metric(history, metric)</strong>:<br/>    train_metrics = history.history[metric]<br/>    val_metrics = history.history['val_'+metric]<br/>    epochs = range(1, len(train_metrics) + 1)<br/>    plt.plot(epochs, train_metrics)<br/>    plt.plot(epochs, val_metrics)<br/>    plt.title('Training and validation '+ metric)<br/>    plt.xlabel("Epochs")<br/>    plt.ylabel(metric)<br/>    plt.legend(["train_"+metric, 'val_'+metric])<br/>    plt.show()</span></pre><p id="5bac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过运行<code class="fe ou ov ow ol b">plot_metric(history, 'loss')</code>获得损失进度图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/c21ea8881adcdc22587d2ffd7b34c7d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uEA5u8kPZ-akH_xHvIxvZw.png"/></div></div></figure><p id="3a77" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从上面的图表中，<strong class="lb iu">我们可以看到，该模型对训练数据进行了过度拟合，因此其性能优于验证集</strong>。</p><h2 id="3d5d" class="nj lw it bd lx nk nl dn mb nm nn dp mf li no np mh lm nq nr mj lq ns nt ml nu bi translated">添加提前停止</h2><p id="765a" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">Keras 模块包含一个内置的回调函数，用于提前停止[2]。</p><p id="1a77" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，让我们导入<code class="fe ou ov ow ol b">EarlyStopping</code>回调并创建一个提前停止对象<code class="fe ou ov ow ol b">early_stopping</code>。</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="a559" class="nj lw it ol b gy op oq l or os">from tensorflow.keras.callbacks import <strong class="ol iu">EarlyStopping</strong></span><span id="59b9" class="nj lw it ol b gy ot oq l or os"><strong class="ol iu">early_stopping = EarlyStopping()</strong></span></pre><p id="bfbc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe ou ov ow ol b">EarlyStopping()</code>有几个选项和默认:</p><ul class=""><li id="6640" class="nw nx it lb b lc ld lf lg li ny lm nz lq oa lu ob oc od oe bi translated"><code class="fe ou ov ow ol b">monitor='val_loss'</code>:使用验证损失作为绩效衡量标准，终止培训。</li><li id="7024" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated"><code class="fe ou ov ow ol b">patience=0</code>:没有改善的时代数。值<code class="fe ou ov ow ol b">0</code>意味着一旦性能测量从一个时期到下一个时期变得更差，就终止训练。</li></ul><p id="fe00" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们只需要将回调对象传递给<code class="fe ou ov ow ol b">model.fit()</code>方法。</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="d6e0" class="nj lw it ol b gy op oq l or os">history = model.fit(<br/>    X_train, <br/>    y_train, <br/>    epochs=200, <br/>    validation_split=0.25, <br/>    batch_size=40, <br/>    verbose=2,<br/>    <strong class="ol iu">callbacks=[early_stopping]</strong><br/>)</span></pre><p id="d977" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以看到<code class="fe ou ov ow ol b">early_stopping</code>在一个列表中被传递给了<code class="fe ou ov ow ol b">callbacks</code>参数。这是一个列表，因为在实践中，我们可能会为执行不同的任务传递许多回调，例如调试和学习率调度。</p><p id="07b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过执行该语句，您应该得到如下所示的输出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/777e81eb5f3f69a3be305309c9e747f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IVc7GDPFVSb-CubHD0FWzw.png"/></div></div></figure><p id="4327" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">注意:</strong>由于权重初始化不同，您的输出可能会有所不同。</p><p id="299d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于<code class="fe ou ov ow ol b">val_loss</code>值的增加，训练在时期 6 终止，这正是条件<code class="fe ou ov ow ol b">monitor='val_loss'</code>和<code class="fe ou ov ow ol b">patience=0</code>。</p><p id="982d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">看一个剧情往往更方便，我们来运行<code class="fe ou ov ow ol b">plot_metric(history, 'loss')</code>来一个清晰的画面。在下图中，验证损失显示为橙色，很明显，验证误差在第 6 时段增加。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/c658e0318fdf869f691cc7ffd6f432a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rJHM56ztu66FJ2GB_6bacg.png"/></div></div></figure><h2 id="a80d" class="nj lw it bd lx nk nl dn mb nm nn dp mf li no np mh lm nq nr mj lq ns nt ml nu bi translated">定制提前停止</h2><p id="f73b" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">除了我们之前提到的选项<code class="fe ou ov ow ol b">monitor</code>和<code class="fe ou ov ow ol b">patience</code>之外，另外两个选项<code class="fe ou ov ow ol b">min_delta</code>和<code class="fe ou ov ow ol b">mode</code>可能会经常使用。</p><ul class=""><li id="7b9f" class="nw nx it lb b lc ld lf lg li ny lm nz lq oa lu ob oc od oe bi translated"><code class="fe ou ov ow ol b">monitor='val_loss'</code>:使用验证损失作为绩效衡量标准，终止培训。</li><li id="8a06" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated"><code class="fe ou ov ow ol b">patience=0</code>:无改善的时期数。值<code class="fe ou ov ow ol b">0</code>意味着一旦性能测量从一个时期到下一个时期变得更差，就终止训练。</li><li id="26fd" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated"><code class="fe ou ov ow ol b"><strong class="lb iu">min_delta</strong></code>:符合改善条件的监测量的最小变化，即小于<code class="fe ou ov ow ol b">min_delta</code>的绝对变化，将被视为无改善。</li><li id="97dd" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated"><code class="fe ou ov ow ol b"><strong class="lb iu">mode='auto'</strong></code>:应为<code class="fe ou ov ow ol b">auto</code>、<code class="fe ou ov ow ol b">min</code>或<code class="fe ou ov ow ol b">max</code>中的一种。在<code class="fe ou ov ow ol b">'min'</code>模式下，当监控的数量停止减少时，训练将停止；在<code class="fe ou ov ow ol b">'max'</code>模式下，当监控的数量停止增加时，它将停止；在<code class="fe ou ov ow ol b">'auto'</code>模式下，方向由监控量的名称自动推断。</li></ul><p id="41db" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是一个定制的提前停止的例子:</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="6f4c" class="nj lw it ol b gy op oq l or os">custom_early_stopping = EarlyStopping(<br/>    <strong class="ol iu">monitor='val_accuracy', </strong><br/>    <strong class="ol iu">patience=8,</strong> <br/>    <strong class="ol iu">min_delta=0.001,</strong> <br/>    <strong class="ol iu">mode='max'</strong><br/>)</span></pre><p id="9f4b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe ou ov ow ol b">monitor='val_accuracy'</code>使用<strong class="lb iu">验证准确度</strong>作为绩效衡量标准来终止培训。<code class="fe ou ov ow ol b">patience=8</code>表示训练在 8 个周期后终止，没有改善。<code class="fe ou ov ow ol b">min_delta=0.001</code>表示验证准确度必须至少提高 0.001 才能算作改进。<code class="fe ou ov ow ol b">mode='max'</code>表示当监控的数量停止增加时，它将停止。</p><p id="61c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们继续用定制的提前停止来运行它。</p><pre class="kj kk kl km gt ok ol om on aw oo bi"><span id="cc9a" class="nj lw it ol b gy op oq l or os">history = model.fit(<br/>    X_train, <br/>    y_train, <br/>    epochs=200, <br/>    validation_split=0.25, <br/>    batch_size=40, <br/>    verbose=2,<br/>    <strong class="ol iu">callbacks=[custom_early_stopping]</strong><br/>)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/ac23b829610f09adcac2c214b1ff4d72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eGN5WYA64VI8j-Qi9eKhow.png"/></div></div></figure><p id="e86e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这一次，训练在时期 9 终止，因为有 8 个时期在验证准确性上没有改进(它必须≥ 0.001 才能算作改进)。为了清晰起见，让我们通过运行<code class="fe ou ov ow ol b">plot_metric(history, 'accuracy')</code>来看看精确度的图形表示。在下图中，验证准确性显示为橙色，很明显验证准确性没有任何提高。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/1375707e04dd73f6557047bb9d43006f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4lN1Z34kpANNSktIX2NIsw.png"/></div></div></figure><h1 id="ceb0" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">好了</h1><p id="5214" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">感谢阅读。</p><p id="295e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请在我的 Github 笔记本上查看源代码。</p><p id="145b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你对机器学习的实用方面感兴趣，请继续关注。</p><h1 id="1c2f" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">参考</h1><ul class=""><li id="32e9" class="nw nx it lb b lc mn lf mo li pe lm pf lq pg lu ob oc od oe bi translated">[1]使用 scikit-learn、keras 和 tensorflow 进行机器实践学习:构建智能系统的概念、工具和技术</li><li id="1aac" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated">[2] <a class="ae ky" href="https://keras.io/api/callbacks/early_stopping/" rel="noopener ugc nofollow" target="_blank">提前停止的 Keras 官方文件</a></li></ul></div></div>    
</body>
</html>