<html>
<head>
<title>Building the Shannon entropy formula</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建香农熵公式</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-the-shannon-entropy-formula-ca67bdb74cdc?source=collection_archive---------23-----------------------#2020-05-10">https://towardsdatascience.com/building-the-shannon-entropy-formula-ca67bdb74cdc?source=collection_archive---------23-----------------------#2020-05-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a12c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">每个人理解香农熵的直观方法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/5fdca300f9fbb2471a8acb9029ff0a54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zCdeWPjnqgnoJ1z9"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">凯利·西克玛在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="0bb8" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">目的</h1><p id="8f31" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">本文的写作是试图理解可以使用香农熵公式的决策树算法的结果。本文旨在通过首先用一个例子说明熵，然后一步一步地建立公式，来展示公式背后的直观推理。</p><h1 id="6d7a" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">熵是什么？</h1><p id="e723" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><strong class="lt iu">熵是不确定性的度量</strong>，由 Claude E. Shannon 引入信息论领域。在这种情况下，可以区分两个相关的量:熵和自熵，前者处理一组事件，后者与单个事件相关。</p><h1 id="ae6e" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated"><strong class="ak">信息和熵</strong></h1><p id="aa06" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">要记住的一个基本概念是<strong class="lt iu">信息和熵是直接相关的</strong>。</p><p id="8618" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">自熵度量的是事件中包含的不确定性或信息。</strong></p><p id="105b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">当考虑自熵时，高度不确定的事件具有高熵并提供大量信息，而某个事件具有低熵并提供少量信息。</p><p id="b588" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">举个极端的例子，一个总会发生的事件有零自熵，而一个永远不会发生的事件有无限自熵。</p><p id="8272" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">另一方面，熵测量所有事件对系统贡献的平均自熵。</strong></p><p id="1af0" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了说明这两种熵类型，假设您有一个容器，其中只能放置四个球，可以是绿色或红色，如图 1 所示。这导致了五种配置，其中排序并不重要。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/ad05f93192d83fcceb94df411408036d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*gIQSdQkj3-sJa6gj"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 1:熵和自熵与提取绿色球的概率相关</p></figure><p id="2c90" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">考虑到容器配置 1，整个系统的<strong class="lt iu">熵为零，因为提取球</strong>的事件不存在不确定性，因为球总是红色的。提取红球的自熵为零，对于绿球是无穷大。</p><p id="cce4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在容器配置 2 中，整个系统的熵很低，因为人们很可能从容器中抽取一个红球。在这种情况下，提取绿色球的自熵高，而提取红色球的自熵低。</p><p id="703a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">最后一个重要的情况是容器配置 3，因为它提供了最大熵，因为这两个事件的可能性相等。这两个事件的自熵中等，相等。</p><p id="123d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">容器配置 4 和 5 分别与容器配置 2 和 1 相同，只是颠倒了绿色和红色。</p><p id="0c2f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">上述事件的自熵可以通过图 2 中的图表来总结。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/baa10bc593536e3a5e0c38df465a96f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Rl06DJCFpWeXJfq-"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 2:与提取绿色球的概率相关的自熵图</p></figure><p id="e9c6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">同样，两个事件系统的熵可以用图 3 中的图来概括。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/f4881c667c78d49b35909a8f3e5b6c5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OLzNGpacPlRUYl20"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 3:与提取绿色球的概率相关的熵图</p></figure><h1 id="fa3e" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">测量信息</h1><p id="bca9" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">由于熵和信息是直接相关的，测量一个也会导致测量另一个的方法。</p><p id="6332" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">一种更直观的表示信息的方式是使用二进制数字，即比特。例如，整数值可以表示为 0 和 1 的位模式。</p><p id="eb7a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">像从容器中取出一个球这样的事件或者像“客队赢了比赛”这样的消息也可以用表 1 中的某些位模式来表示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mv"><img src="../Images/31493c053b450c4b8facf67ec9193532.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QdW7Yil3ZDUIK-0f"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">表 1:不同事件的潜在位模式表示</p></figure><h1 id="b402" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">测量自熵</h1><p id="db6c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><strong class="lt iu">比特模式可以与取决于比特数的概率相关联。</strong>例如，任何单个位模式的概率为 1/2，而任何两个位的位模式的概率为 1/4，如此类推，如图 4 所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mw"><img src="../Images/a1f7b2b63107bcc4d18252ddc4c22822.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*P32dvtmB6UCVzHeX"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 4:与位数相关的位模式概率</p></figure><p id="fc29" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">通常，某个位模式的概率为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/0e073ce808c1a3d9b9ab2bcf44d52286.png" data-original-src="https://miro.medium.com/v2/resize:fit:318/format:webp/1*TQRfTv99zEetM70eP0ZEsA.png"/></div></figure><p id="f556" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">相反，通过在两面都应用以 2 为底的对数:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi my"><img src="../Images/ebd300498399d11958bda5416e380624.png" data-original-src="https://miro.medium.com/v2/resize:fit:224/format:webp/1*39W3hTp8XYrU81L5EGRGvw.png"/></div></figure><p id="7240" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如图 4 所示，对于[0，1]的整个概率范围，可以获得信息比特的数量，这接近于图 2 中的直觉。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/7ebe942970fd676226ee21fac9966a4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*i9r9Oz0sXBcvliIv"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 5:自熵公式的图表</p></figure><h1 id="cd68" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">测量熵</h1><p id="1d2f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">当测量一个系统的熵时，每个事件的平均自熵贡献被考虑在内。</p><p id="d09b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">举例来说，考虑包含 10 位信息的事件(或消息)。如果该消息以 0.2 的概率出现，那么它对整个系统的平均贡献是 10 比特* 0.2 = 2 比特因此，<strong class="lt iu">考虑到自熵的公式，每个事件的平均贡献是:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/76975d1b12c5de633e77bad11a640040.png" data-original-src="https://miro.medium.com/v2/resize:fit:156/format:webp/1*yWjy8RuG0WjWmNaa2Y_DOg.png"/></div></figure><p id="5a0d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">包含在 n 个事件及其相关概率的系统中的熵是所有这些平均贡献的总和:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/b49ff6dcc32bfe464791e1e27967a9b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:240/format:webp/1*lWsh-kXZJqwAtDBlW0RV-A.png"/></div></figure><p id="3a70" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">回到第一个示例，考虑两个事件的系统，公式变为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/3d51892c0ab094ed81d78aeefc6bbb90.png" data-original-src="https://miro.medium.com/v2/resize:fit:418/format:webp/1*UpRlK7zGluPeX2qCE0Gn_g.png"/></div></figure><p id="83df" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">因为所有概率的总和等于 1，所以上述可以替换为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/dbafd6241c76e137cddb901a1720bcde.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/format:webp/1*DjOgiZSeyEfWB_OyViy-6A.png"/></div></figure><p id="af3e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在图 5 中画出两个事件系统的熵公式，我们可以再次证实图 3 中的直觉。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/69c86df0246512c6bcc328c90025c00a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*YoBy5xrfM6cjiEXo"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 6:两个事件的熵图</p></figure><p id="7864" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">表 2 给出了对两个事件的系统应用自熵和熵公式时得到的 of 值。事件 1 可以与“抽取一个红球”相关联，而事件 2 可以与“抽取一个绿球”相关联，如在所示的例子中。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/a4f3bd9780db9007193aae4474e20333.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*PxTLogIr_SjEYwzc"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">表 2:双事件系统的自熵和熵值</p></figure><h1 id="15dc" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">结论</h1><p id="9417" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我希望这能让我们对熵公式是如何建立的有所了解。</p><p id="7c37" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">回顾本文的目的，决策树使用 Shannon 熵公式来挑选一个特征，该特征将数据集递归地分割成具有高度一致性(低熵值)的子集。更均匀地分割数据集会使决策树深度更小，从而更易于使用。</p><p id="a1bb" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果你有意见或建议，我将很高兴收到你的来信！</p><p id="3ada" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">图 1 中的例子基本上是<a class="nf ng ep" href="https://medium.com/u/ff11baf3f5fe?source=post_page-----ca67bdb74cdc--------------------------------" rel="noopener" target="_blank"> Luis Serrano </a>在文章<a class="ae ky" href="https://medium.com/udacity/shannon-entropy-information-gain-and-picking-balls-from-buckets-5810d35d54b4" rel="noopener">“香农熵、信息增益和从桶中捡球”</a>中的简化版本</p></div></div>    
</body>
</html>