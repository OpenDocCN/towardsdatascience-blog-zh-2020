<html>
<head>
<title>Introduction to Probabilistic Graphical Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">概率图形模型介绍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introduction-to-probabilistic-graphical-models-b8e0bf459812?source=collection_archive---------2-----------------------#2020-02-23">https://towardsdatascience.com/introduction-to-probabilistic-graphical-models-b8e0bf459812?source=collection_archive---------2-----------------------#2020-02-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/5b5c7b3e472e655c84fe82e96200139f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*E_A-fSbQVRLJ1oD5"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">克林特·王茂林在<a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="8505" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">概率图形模型(PGMs) </strong>是使用图形对复杂的联合多元概率分布进行编码的统计模型。换句话说，PGM捕获相互作用的随机变量之间的条件独立性关系。这是有益的，因为多年来在各个领域中已经积累了许多关于图的知识，特别是在分离图上的子集、集团和函数方面。这些知识可以在PGMs中重用。此外，人们可以很容易地将PGM可视化，并快速了解模型结构。</p><p id="dc0f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通过了解PGM的图形结构，可以解决诸如推理(计算一个或多个随机变量的边际分布)或学习(估计概率函数的参数)之类的任务。给定一些数据，人们甚至可以尝试学习图形本身的结构。</p><p id="80d6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这篇文章中，我将简要描述PGM的两种风格，<strong class="ki iu">有向图模型(dgm)，</strong>也称为<strong class="ki iu">贝叶斯网络(BNs)和无向图模型(ugm)或马尔可夫随机场(MRF)</strong>。我将解释这些模型之间的区别，并提供两者的例子。在这篇文章的最后一部分，我将看看bn和MRF之间的转换。我还将简要介绍PGMs中的推理和参数估计。我会在适当的地方提供更多相关信息的链接。</p><h1 id="9d59" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">有向图形模型</h1><p id="8520" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">顾名思义，有向图模型可以用一个图来表示，图的顶点作为随机变量，图的<strong class="ki iu">有向</strong>边作为它们之间的依赖关系(见下图)。</p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mh"><img src="../Images/b1ded09dc7e448bf549c75e83b86eb44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9b7qMsUpwoUjYzTiBnRMRQ.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图DGMs的两个例子。虽然(A)中的模型是循环的，但是(B)是DAG并且可以表示贝叶斯网络。</p></figure><p id="b288" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">边缘的<strong class="ki iu">方向决定了一个随机变量对另一个</strong>的<strong class="ki iu">影响。如果该图不包含循环(在一个封闭链中连接的多个顶点)，它通常被称为<strong class="ki iu">有向无环图(DAG) </strong>。可以使用诸如<strong class="ki iu">置信传播(BP) </strong>或变量消除之类的算法精确地对这些图进行推断。</strong></p><h2 id="35b9" class="mm lf it bd lg mn mo dn lk mp mq dp lo kr mr ms ls kv mt mu lw kz mv mw ma mx bi translated">贝叶斯网络</h2><p id="c861" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">DGM的一个例子是贝叶斯网络(BN) 。贝叶斯网络是一个<strong class="ki iu"> DAG </strong>，其顶点(随机变量)代表模型的可观察变量或潜在变量。</p><p id="a95f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">BN <strong class="ki iu">的<strong class="ki iu">有向边</strong>(“箭头”)代表条件分布</strong>。例如，如果顶点的值是二进制的，则条件分布可以是伯努利分布。在连续值的情况下，条件分布可以是高斯分布。联合概率分布被公式化为条件概率或边际概率的乘积。</p><p id="baa7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">例如，当对下雨或洒水装置开启时给出的湿草概率建模时，我们可以使用这样的DAG来表示它:</p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi my"><img src="../Images/0640cfbfefac4913f66264cb1ce16397.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NHqE8Ofc_9O_Aqz-NUssZQ.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图2:贝叶斯网络的例子。它编码了以下逻辑:草地潮湿的概率取决于打开洒水器和雨水。洒水装置开启的概率本身取决于降雨(下雨时你不会打开洒水装置)。</p></figure><p id="467c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个DAG表示(分解的)概率分布</p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/b5d71ae014b87c9afffc34326867766a.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*eQaisWLY8LTVeJYp5BO6xA.png"/></div></figure><p id="46ed" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">，其中<em class="na"> R </em>为随机变量，为降雨，<em class="na"> S </em>为洒水器，<em class="na"> G </em>为湿草。通过检查图表，您很快就会看到模型中唯一的独立变量是<em class="na"> R </em>。其他两个变量取决于降雨和/或洒水喷头的概率。通常，BN的联合分布是给定其父节点的每个节点的条件概率的乘积:</p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/55dfc14d50c9ba9fa74cbb2ec6fc5c23.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*Ea0L5Ukr3XCRUzYYO02akg.png"/></div></figure><p id="4319" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于大多数节点的父节点远少于节点总数，所以<strong class="ki iu">图通常是稀疏的</strong>。</p><p id="b2a1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然这不是必需的，但是BNs经常被用来建模因果关系。如果BN中的边的方向代表因果性，那么Judea Pearl引入的因果do-calculus允许人们通过执行模拟干预来修改图表，并预测外部干预的影响(如果你想了解更多，请参见<a class="ae kf" href="https://www.inference.vc/untitled/" rel="noopener ugc nofollow" target="_blank">这篇伟大的文章</a>)。</p><h2 id="7e67" class="mm lf it bd lg mn mo dn lk mp mq dp lo kr mr ms ls kv mt mu lw kz mv mw ma mx bi translated">BNs中的推理</h2><p id="8a3f" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">让我们回到湿草的例子，算出草是湿的概率，即<strong class="ki iu">边际概率</strong> <em class="na"> p(G) </em>。这项任务被称为推理。为了确定一个变量的边际概率，通常你必须对图中的所有双亲求和。在这种情况下，边际概率是</p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/10380c49129df7cfe3f2dd74f3336cd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/1*P2ow-uEUgQnyaKtRik2k0w.png"/></div></figure><p id="3347" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这种情况下，我们需要综合所有因素。然而，对于更复杂的图形，利用<strong class="ki iu">稀疏图形结构</strong>，有可能<strong class="ki iu">从总和中提取一些因子并大大简化计算</strong>。</p><p id="3198" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可能感兴趣的另一个任务是计算假定不下雨，草地会湿的条件概率。在这种情况下，我们将如下进行:</p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/48d03e4f300590f5665263e516992ddd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/1*h15VKPB-_Agg5bmySy4NHg.png"/></div></figure><p id="923f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这种情况下，我们只需要对<em class="na"> S </em>进行边缘化，因为<em class="na"> R </em>已经被假定为给定的。这个程序叫做<a class="ae kf" href="https://en.wikipedia.org/wiki/Variable_elimination" rel="noopener ugc nofollow" target="_blank">变量消除</a>。变量消去法是一种精确的推理算法。它还可以用于计算出网络的状态，通过简单地交换最大函数的和，具有最大概率。它的缺点是，对于大型bn，它可能在计算上很难处理。在这些情况下，可以使用近似推理算法，如<a class="ae kf" href="https://en.wikipedia.org/wiki/Gibbs_sampling" rel="noopener ugc nofollow" target="_blank">吉布斯采样</a>或<a class="ae kf" href="https://en.wikipedia.org/wiki/Rejection_sampling" rel="noopener ugc nofollow" target="_blank">拒绝采样</a>。</p><h2 id="bd83" class="mm lf it bd lg mn mo dn lk mp mq dp lo kr mr ms ls kv mt mu lw kz mv mw ma mx bi translated">弄清楚BNs中的独立性</h2><p id="584d" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">给定一个节点，我们如何确定一个BN中的两个节点是否独立？为了回答这个问题，让我们引入d-分离的概念。</p><p id="d190" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">d分离有3个规则:</p><ul class=""><li id="72d5" class="ne nf it ki b kj kk kn ko kr ng kv nh kz ni ld nj nk nl nm bi translated">如果两组节点<em class="na"> X </em>和<em class="na"> Y </em>之间没有单向路径(不考虑其方向性的任何边序列),则它们是d分离的。</li></ul><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nn"><img src="../Images/03bbecbdbc23d94b0d760f18e219a337.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*ttXZW1n3JKy-5uAIEwjvfg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图3:规则1。</p></figure><p id="95e3" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本例中，节点<em class="na"> a </em>和<em class="na"> c </em>是d连接的，而<em class="na"> a </em>和<em class="na"> d </em>或<em class="na"> b </em>和<em class="na"> d </em>是d分离的，因为<em class="na"> b </em>和<em class="na"> d </em>都是<em class="na"> c </em>的父节点。</p><ul class=""><li id="c77c" class="ne nf it ki b kj kk kn ko kr ng kv nh kz ni ld nj nk nl nm bi translated"><em class="na"> X </em>和<em class="na"> Y </em>是d分隔的，给定另一组节点<em class="na"> Z </em>，如果<em class="na"> Z </em>“阻塞”它们之间的任何单向路径。</li></ul><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/443a99bfb810a9d8215837665310743d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*Nc_UT8073t5tM-r-gmWYCg.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图4:规则2。</p></figure><p id="f743" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这种情况下，<em class="na"> b </em>阻断了<em class="na"> a </em>和<em class="na"> c </em>之间的路径，导致它们被d分离。</p><ul class=""><li id="a479" class="ne nf it ki b kj kk kn ko kr ng kv nh kz ni ld nj nk nl nm bi translated">如果一个碰撞体或者它的后代在集合Z中，它打破了它的双亲的d分离。</li></ul><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div class="gh gi no"><img src="../Images/cde47fad715e0d9668b5a75e67c69246.png" data-original-src="https://miro.medium.com/v2/resize:fit:706/format:webp/1*byNP-r1vaZcQKKHoclqrFA.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图5:规则3。</p></figure><p id="f4eb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个需要一些解释:碰撞器是一个有两个或更多父节点的节点。如果对撞机被观察到，它的双亲，虽然之前是独立的，却变成了依赖的。例如，如果我们正在处理二元变量，对撞机的知识使其双亲的概率或多或少。在上图中，<em class="na"> b </em>打破了<em class="na"> a </em>和<em class="na"> c </em>之间的d分离。</p><h1 id="bed9" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">无向图模型(ugm)或马尔可夫随机场(MRF)</h1><p id="5179" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">与贝叶斯网络类似，MRF用于使用图形描述随机变量之间的依赖关系。然而，<strong class="ki iu">MRF使用无向边而不是有向边</strong>。它们也可能包含<strong class="ki iu">周期</strong>，不像贝叶斯网络。因此，MRF可以描述与它们的贝叶斯网络对应物不同的依赖关系集合。请注意，MRF不是dgm的超集，因为有些关系(如因果关系)只能由dgm描述。</p><p id="1faf" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">贝叶斯网络的边表示条件依赖，而<strong class="ki iu">MRF的无向边表示图中派系</strong>的联合概率。看看下面的MRF:</p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div class="gh gi np"><img src="../Images/e2273d2325cb7b46d80eac57229081c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*J7S1U_OBJPGyFWQvce2vjQ.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图6:有三个派系的MRF的例子。</p></figure><p id="49e2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该图描述了3个不同集团中6个变量的联合概率函数。因此，它分解为以下分布乘积:</p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/23bee4a45976d67d36d29715db3252c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*ix6eqVSTHbuxGxLixN0iCQ.png"/></div></figure><p id="e8f5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">MRF的一个基本属性是它们满足<strong class="ki iu">成对的、局部的和全局的马尔可夫属性</strong>。这些性质与BNs的d-分离规则有着深刻的联系。特别地，d-分离定义了有向图上的马尔可夫性质。</p><p id="cde4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">成对马尔可夫性质</strong>表明，给定所有其他变量，两个不相邻的变量是有条件独立的:</p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/1a20e7b669cf21f6557648221adb3e6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:404/format:webp/1*cCW8hKoVus9tPD2rVC34hg.png"/></div></figure><p id="2ddf" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">，其中<em class="na"> X_a </em>和<em class="na"> X_b </em>定义任意两个不相邻的变量，X_ <em class="na"> G </em>是所有变量的集合。</p><p id="e57d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">局部马尔可夫性质</strong>引入了变量的<strong class="ki iu">邻域</strong>的概念:</p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ns"><img src="../Images/497ac329300a626e0beaeb6e8c7800d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:458/format:webp/1*JiaVwLgri9xKzCvG6qmouw.png"/></div></div></figure><p id="f51b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">，其中<em class="na"> N(a) </em>是<em class="na"> X_a </em>的邻域。换句话说，任何变量都有条件地独立于给定其邻域的任何其他变量。</p><p id="4b43" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，<strong class="ki iu">全局马尔可夫性质</strong>表明，给定一个分离子集<em class="na"> X_S </em>，任何变量集合<em class="na"> X_A </em>都独立于任何其他集合<em class="na"> X_B </em>:</p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/f65269f39145a8ad85f934d31a43306b.png" data-original-src="https://miro.medium.com/v2/resize:fit:320/format:webp/1*_tLDwF66kFoC94SI32yMxA.png"/></div></figure><p id="d6b0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一般来说，成对马尔可夫性质来自局部马尔可夫性质，而局部马尔可夫性质又来自全局马尔可夫性质。然而，对于严格正概率分布，这些陈述是等价的。</p><p id="cef2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">MRFs的另一个重要结果是<a class="ae kf" href="https://en.wikipedia.org/wiki/Hammersley%E2%80%93Clifford_theorem" rel="noopener ugc nofollow" target="_blank"> <strong class="ki iu"> Hammersley-Clifford定理</strong> </a>:非正式地，该定理陈述了满足一个(或等价地所有)马尔可夫性质的严格正概率分布可以表示为Gibbs测度。因此，吉布斯测度是在图的集团上分解的严格正函数:</p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/58b633c47392010927bbe7daa4595e16.png" data-original-src="https://miro.medium.com/v2/resize:fit:480/format:webp/1*VJ95JFG-648ibQDCi6H63Q.png"/></div></figure><p id="dd65" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">，其中<em class="na"> Z </em>是适当的归一化常数(也称为配分函数)，<em class="na"> c </em>是图的(最大)团，<em class="na"> ϕ </em>是团上的因式分解函数(不一定归一化)，而<em class="na"> X </em>是随机变量的集合。</p><h2 id="173f" class="mm lf it bd lg mn mo dn lk mp mq dp lo kr mr ms ls kv mt mu lw kz mv mw ma mx bi translated">MRF的例子</h2><p id="830d" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">MRF的一个非常常见的例子是<strong class="ki iu">隐马尔可夫模型(HMM)</strong>:HMM描述了一个具有周期性观察的<strong class="ki iu">动态系统。系统在每个时间步改变隐藏状态。因此，<em class="na"> i </em>时刻的状态仅取决于<em class="na"> i-1 </em>时刻的状态，即HMMs模型马尔可夫过程。此外，在时间<em class="na"> i </em>的观察仅直接取决于时间<em class="na"> i </em>的状态。</strong></p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/312d34d981cb98244b9631582403c227.png" data-original-src="https://miro.medium.com/v2/resize:fit:1310/format:webp/1*I9Kfr6t6vXW04PMVNozMYw.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图7:嗯。隐藏状态表示为S1–S4，相应的观察值为o1-o4。</p></figure><p id="2fbc" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由HMM建模的联合概率分布是:</p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/e87a1bdcbe7eec699b07cbfef8a56d53.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*-i3X481-k8_BDjRMTCkdDg.png"/></div></figure><p id="55ea" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中<em class="na"> S </em>和<em class="na"> O </em>分别为状态和观测随机变量，<em class="na"> T </em>为时间步数。hmm上的推理非常简单:因为图具有链状结构，所以可以使用<strong class="ki iu">动态编程</strong>算法进行推理。例如，在给定所有观察值<em class="na">o _【0:T】</em>的情况下，计算系统在时间<em class="na"> i </em>处于状态<em class="na"> s </em>的概率可以使用<a class="ae kf" href="https://en.wikipedia.org/wiki/Forward%E2%80%93backward_algorithm" rel="noopener ugc nofollow" target="_blank"><strong class="ki iu"/></a>算法来计算。类似地，给定观察值的最可能的隐藏状态序列由<a class="ae kf" href="https://en.wikipedia.org/wiki/Viterbi_algorithm" rel="noopener ugc nofollow" target="_blank"> <strong class="ki iu">维特比算法</strong> </a>计算。</p><p id="0f28" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">MRF还经常用于图像处理等领域，在这些领域中，它们描述了各个像素之间的关系。例如，它们可以通过要求相邻像素具有相似的亮度来加强期望解决方案的某种平滑度。二进制图像平滑(松弛)的一个流行模型是<a class="ae kf" href="https://en.wikipedia.org/wiki/Ising_model" rel="noopener ugc nofollow" target="_blank"> <strong class="ki iu">伊辛模型</strong> </a>。伊辛模型将图像中的每个像素视为图形中的一个节点，嵌入到一个与相邻像素相连的网格中:</p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/08660a8758cbe2afc088936971ae4da3.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/1*l4QgPGK9-39PGqf0SW490g.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图8:具有势J1和J2的伊辛模型。</p></figure><p id="336a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">伊辛模型假设每个节点可以有两种状态:σ ϵ {-1，1}。特定状态的能量由下式描述:</p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/e28ee4916ee66eaf5a6b164ef27647bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/0*tJjY6lIcZh37yc1z.png"/></div></figure><p id="bacb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">，其中<em class="na"> σ_i </em>表示节点<em class="na"> i </em>的状态，第一个总和覆盖网格中的所有邻居，<em class="na"> J_ij </em>是节点<em class="na"> i </em>和<em class="na"> j </em>之间的相互作用，<em class="na"> h_i </em>是单个节点能量的因子(先验概率)。J_ij 可以是正的，鼓励相邻节点具有相同的符号，也可以是负的，使它们具有相反的符号。系统的联合吉布斯分布由下式给出:</p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/05a2c345be0e228733bd1dd29b0e8118.png" data-original-src="https://miro.medium.com/v2/resize:fit:516/format:webp/0*sivmmYqlBKpokE02.png"/></div></figure><p id="be52" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">取这个表达式的对数，表达式分解成图的集团。因此，我们可以看到，根据哈默斯利-克利福德定理，这个模型确实是一个MRF。不幸的是，分母中的归一化因子通常很难计算，这使得近似推断成为涉及伊辛模型的问题的选择方法。</p><h1 id="6b8d" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">BNs和MRF之间的等价性</h1><p id="94dd" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">贝叶斯网络和马尔可夫随机场有什么关系？难道我们不能用一个或另一个来表示概率分布吗？如何才能建立等价？人们可以通过简单地改变箭头的方向来把BN转换成MRF。然而，这是不正确的，因为dgm和ugm编码的独立性关系是不同的。例如，考虑下面的贝叶斯网络和通过移除箭头获得的MRF:</p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oa"><img src="../Images/48a5d0a11cf0c598d2042132c9b8c319.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zco3ZjV8QknPqr2Lra5V9g.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图9 :( A)中的BN和通过移除箭头生成的MRF(B)。正确的道德化的MRF显示在(C)中。</p></figure><p id="7e09" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从上图可以看出，A和B处的图并没有编码相同的条件独立关系:给定节点<em class="na"> b </em>，节点<em class="na"> a </em>和<em class="na"> c </em>根据第三个d-分离规则并不独立。然而,( B)中的MRF不包含这种依赖关系，因为在<em class="na"> a </em>和<em class="na"> c </em>之间没有连线。我们可以通过一个叫做<a class="ae kf" href="https://en.wikipedia.org/wiki/Moral_graph" rel="noopener ugc nofollow" target="_blank"> <strong class="ki iu">道德化</strong> </a>的程序来解决这个问题。这被恰当地命名为:尽管<strong class="ki iu">节点<em class="na"> a </em>和<em class="na"> c </em>有一个共同的子节点，但它们并没有通过连接</strong>而“结合”。通过将<em class="na"> a </em>和<em class="na"> c </em>结合，我们弥补了这种不一致。然而，如果没有给出<em class="na"> b </em>，我们也会<strong class="ki iu">失去<strong class="ki iu">独立性</strong>的一部分，即在<em class="na"> a </em>和<em class="na"> c </em>之间。因此，图表变得更一般，推理可能更复杂。</strong></p><p id="5767" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">逆过程(从MRFs移动到BNs)称为<a class="ae kf" href="https://en.wikipedia.org/wiki/Chordal_graph" rel="noopener ugc nofollow" target="_blank"> <strong class="ki iu">三角测量</strong> </a>。请注意，这个过程比说教更复杂，因为最终的BN可能比原来的MRF大得多。具体来说，MRF中所有具有4个或更多顶点的闭合环都必须划分成三角形。通过执行三角测量，我们得到了所谓的<strong class="ki iu">弦图</strong>。类似于道德化，三角测量也会导致独立信息的丢失。然而，三角测量用于多种推理算法，因为<strong class="ki iu">在一般图上是NP难的问题在弦图上往往变得容易</strong>。作为使用道德化<strong class="ki iu">和</strong>三角剖分的算法的例子，让我们提一下<a class="ae kf" href="https://en.wikipedia.org/wiki/Junction_tree_algorithm" rel="noopener ugc nofollow" target="_blank"> <strong class="ki iu">连接树算法</strong> </a>。</p><h1 id="66da" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">结论</h1><p id="1982" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">概率图形模型提供了一种模拟随机变量之间关系的方法。最近，由于神经网络的普遍存在，它们已经有点失宠了。然而，我认为它们在未来仍然是相关的，特别是因为它们非常容易解释和直观。它们还允许对因果关系进行建模，甚至可能对学习高级概念的表示有用(参见Yoshua Bengio的<a class="ae kf" href="https://arxiv.org/abs/1709.08568" rel="noopener ugc nofollow" target="_blank">本文</a>)。在我看来，找到一种将神经网络与图形模型结合起来的方法，可能对推进整个人工智能领域非常有用。</p></div></div>    
</body>
</html>