<html>
<head>
<title>Used Car Price Prediction using Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于机器学习的二手车价格预测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/used-car-price-prediction-using-machine-learning-e3be02d977b2?source=collection_archive---------7-----------------------#2020-08-03">https://towardsdatascience.com/used-car-price-prediction-using-machine-learning-e3be02d977b2?source=collection_archive---------7-----------------------#2020-08-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="13b8" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">数据清洗、数据预处理、8 种不同的 ML 模型和一些来自数据的见解</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/6b875566d198070a03295ec923c7506c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/1*ZOcUPrSXLYucFxppoI-dYg.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图片由 Panwar Abhash Anil 提供</p></figure><blockquote class="ku kv kw"><p id="7ce1" class="kx ky kz la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="it">在我的</em> <a class="ae lu" href="https://github.com/abhashpanwar/used-car-price-prediction" rel="noopener ugc nofollow" target="_blank"> GitHub 页面</a> <em class="it">可以到达与此相关的所有 Python 脚本。如果您感兴趣，还可以在同一个存储库中找到用于这项研究的数据清理和数据可视化的脚本。</em></p><p id="b815" class="kx ky kz la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="it">该项目也使用 Django 部署在</em><a class="ae lu" href="https://abhash-car-price-prediction.herokuapp.com/" rel="noopener ugc nofollow" target="_blank"><em class="it">Heroku</em></a><em class="it">上，也通过</em><a class="ae lu" href="http://ec2-54-82-16-204.compute-1.amazonaws.com:8080/" rel="noopener ugc nofollow" target="_blank"><em class="it">Dockerizing Django App</em></a>部署在 Amazon EC2 上</p></blockquote><h1 id="39eb" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">内容</h1><ol class=""><li id="4a97" class="mn mo it la b lb mp le mq mr ms mt mu mv mw lt mx my mz na bi translated">数据清理(识别空值、填充缺失值和移除异常值)</li><li id="fd34" class="mn mo it la b lb nb le nc mr nd mt ne mv nf lt mx my mz na bi translated">数据预处理(标准化或规范化)</li><li id="660b" class="mn mo it la b lb nb le nc mr nd mt ne mv nf lt mx my mz na bi translated">ML 模型:线性回归、岭回归、拉索、KNN、随机森林回归、Bagging 回归、Adaboost 回归和 XGBoost</li><li id="9def" class="mn mo it la b lb nb le nc mr nd mt ne mv nf lt mx my mz na bi translated">模型的性能比较</li><li id="76fe" class="mn mo it la b lb nb le nc mr nd mt ne mv nf lt mx my mz na bi translated">来自数据的一些见解</li></ol><h2 id="eb32" class="ng lw it bd lx nh ni dn mb nj nk dp mf mr nl nm mh mt nn no mj mv np nq ml nr bi translated">为什么价格特征通过对数变换进行缩放？</h2><p id="b92f" class="pw-post-body-paragraph kx ky it la b lb mp ju ld le mq jx lg mr ns lj lk mt nt ln lo mv nu lr ls lt im bi translated">在回归模型中，对于 X 的任何固定值，Y 都分布在这个问题数据中——目标值(价格)不是正态分布，它是右偏的。</p><p id="4404" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">为了解决这个问题，当目标变量具有偏斜分布时，对其应用对数变换，并且我们需要对预测值应用反函数来获得实际的预测目标值。</p><p id="b2d0" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">因此，为了评估模型，计算<a class="ae lu" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_log_error.html" rel="noopener ugc nofollow" target="_blank"> <em class="kz"> RMSLE </em> </a>以检查误差，并且还计算<a class="ae lu" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html" rel="noopener ugc nofollow" target="_blank"> <em class="kz"> R2 分数</em> </a>以评估模型的准确性。</p><h1 id="8475" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">一些关键概念:</h1><ul class=""><li id="a531" class="mn mo it la b lb mp le mq mr ms mt mu mv mw lt nv my mz na bi translated"><strong class="la iu">学习率:</strong>学习率是一个超参数，它控制我们根据损耗梯度调整网络权重的程度。该值越低，我们沿下坡行驶的速度越慢。虽然在确保我们不会错过任何局部最小值方面，这可能是一个好主意(使用低学习率),但这也可能意味着我们将需要很长时间才能收敛——特别是如果我们被困在一个平坦区域。</li><li id="7ff7" class="mn mo it la b lb nb le nc mr nd mt ne mv nf lt nv my mz na bi translated">n_estimators :这是在进行最大投票或平均预测之前，你想要建立的树的数量。树的数量越多，性能越好，但代码速度越慢。</li><li id="6d88" class="mn mo it la b lb nb le nc mr nd mt ne mv nf lt nv my mz na bi translated"><strong class="la iu"> R 评分:</strong>是数据与拟合回归线接近程度的统计度量。它也被称为决定系数，或多元回归的多重决定系数。0%表示该模型不能解释响应数据在其平均值附近的任何可变性。</li></ul><h1 id="dc96" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">1.数据:</h1><p id="4bba" class="pw-post-body-paragraph kx ky it la b lb mp ju ld le mq jx lg mr ns lj lk mt nt ln lo mv nu lr ls lt im bi translated">本项目使用的数据集是从<a class="ae lu" href="https://www.kaggle.com/austinreese/craigslist-carstrucks-data" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>下载的。</p><h1 id="92bf" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">2.数据清理:</h1><p id="587d" class="pw-post-body-paragraph kx ky it la b lb mp ju ld le mq jx lg mr ns lj lk mt nt ln lo mv nu lr ls lt im bi translated">第一步是从数据集中移除不相关/无用的特征，如“URL”、“region_url”、“vin”、“image_url”、“description”、“county”、“state”。</p><p id="64fa" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">下一步，检查每个要素的缺失值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/ad3d098ae9ec9d12be554a4fd16668ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*2EPrbZHIVWGSz6xAqUYIIA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">显示缺失值(图片由 Panwar Abhash Anil 提供)</p></figure><p id="1e6e" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">接下来，通过适当的方法用适当的值填充现在缺失的值。</p><p id="772f" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">为了填补缺失值，使用<a class="ae lu" href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html" rel="noopener ugc nofollow" target="_blank"> <em class="kz">迭代估算器</em> </a>方法，实现不同的估计器，然后使用<a class="ae lu" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html" rel="noopener ugc nofollow" target="_blank"><em class="kz">cross _ val _ score</em></a>计算每个估计器的<a class="ae lu" href="https://en.wikipedia.org/wiki/Mean_squared_error" rel="noopener ugc nofollow" target="_blank"> <em class="kz"> MSE </em> </a></p><ol class=""><li id="8b67" class="mn mo it la b lb lc le lf mr nx mt ny mv nz lt mx my mz na bi translated">平均值和中位数</li><li id="a90b" class="mn mo it la b lb nb le nc mr nd mt ne mv nf lt mx my mz na bi translated">贝叶斯岭估计量</li><li id="a986" class="mn mo it la b lb nb le nc mr nd mt ne mv nf lt mx my mz na bi translated">决策树回归估计量</li><li id="e451" class="mn mo it la b lb nb le nc mr nd mt ne mv nf lt mx my mz na bi translated">树外回归估计量</li><li id="5c07" class="mn mo it la b lb nb le nc mr nd mt ne mv nf lt mx my mz na bi translated">kneighbors 回归估计量</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi oa"><img src="../Images/79e119b66ef8180d201023f5945ae6d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5Mp3PscLpgg1Zmck6TqQnw.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">使用不同插补方法的均方误差(图片由 Panwar Abhash Anil 提供)</p></figure><p id="e605" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">从上图中，我们可以得出结论，<em class="kz">extractree regressor</em>估计量将更好地用于填充缺失值的插补方法。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/8ad5e7a0f69dd157ebc5e14fb9f9bb3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/format:webp/1*7h8JugocaValwthZeXIo0A.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">填充后缺少值(图片由<a class="ae lu" href="https://www.linkedin.com/in/abhash-panwar-85126976/" rel="noopener ugc nofollow" target="_blank"> Panwar Abhash Anil </a>拍摄)</p></figure><p id="09db" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">最后，在处理缺失值后，零个空值。</p><p id="677c" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated"><strong class="la iu">异常值:</strong>用四分位差(IQR)法从数据中剔除异常值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/e6326481c1327ed1a7c862dfe7bbcb2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*J3alPNZZJ4Wm9WHf0btCnQ.jpeg"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">显示异常值的价格箱线图(图片由<a class="ae lu" href="https://www.linkedin.com/in/abhash-panwar-85126976/" rel="noopener ugc nofollow" target="_blank"> Panwar Abhash Anil </a>提供)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/7d8f821455911d6f1c12f9953607bf6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*MBJDuHn4xIPy_7EzoH5STA.jpeg"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">显示异常值的里程表方框图(图片由<a class="ae lu" href="https://www.linkedin.com/in/abhash-panwar-85126976/" rel="noopener ugc nofollow" target="_blank"> Panwar Abhash Anil </a>提供)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi oh"><img src="../Images/50fe95ab4f8e32a8484159223289cb04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P6qsfXxrfM9BGanUaIsF_w.jpeg"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">年度柱状图和柱状图(图片由<a class="ae lu" href="https://www.linkedin.com/in/abhash-panwar-85126976/" rel="noopener ugc nofollow" target="_blank"> Panwar Abhash Anil </a>提供)</p></figure><ul class=""><li id="fd20" class="mn mo it la b lb lc le lf mr nx mt ny mv nz lt nv my mz na bi translated">从图 1 中可以看出，低于 6.55 和高于 11.55 的价格是异常值</li><li id="0d88" class="mn mo it la b lb nb le nc mr nd mt ne mv nf lt nv my mz na bi translated">从图 2 中，不可能得出什么结论，因此计算 IQR 来发现异常值，即低于 6.55 和高于 11.55 的里程表值是异常值。</li><li id="bb0d" class="mn mo it la b lb nb le nc mr nd mt ne mv nf lt nv my mz na bi translated">从图 3 来看，1995 年以下和 2020 年以上的年份是异常值。</li></ul><p id="06d9" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">最后，处理前的数据集形状= (435849，25)，处理后的数据集形状= (374136，18)。总共删除了 61713 行和 7 列。</p><h1 id="aa21" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">3.数据预处理:</h1><p id="7fa9" class="pw-post-body-paragraph kx ky it la b lb mp ju ld le mq jx lg mr ns lj lk mt nt ln lo mv nu lr ls lt im bi translated"><strong class="la iu">标签编码器:</strong>在我们的数据集中，12 个特征是分类变量，4 个是数值变量(价格列除外)。为了应用 ML 模型，我们需要将这些分类变量转换成数值变量。而 sklearn 库<a class="ae lu" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html" rel="noopener ugc nofollow" target="_blank"> <em class="kz"> LabelEncoder </em> </a>就是用来解决这个问题的。</p><p id="edb1" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated"><strong class="la iu">归一化</strong>:数据集不是正态分布。所有功能都有不同的范围。如果不进行归一化，ML 模型将尝试忽略低值要素的系数，因为与大值相比，它们的影响非常小。因此为了归一化，使用了<a class="ae lu" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html" rel="noopener ugc nofollow" target="_blank"> <em class="kz"> sklearn 库，即 MinMaxScaler </em> </a>。</p><p id="95c4" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated"><strong class="la iu">训练数据。</strong>在此过程中，90%的数据被分割为列车数据，10%的数据作为测试数据。</p><h1 id="7105" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">4.ML 型号:</h1><p id="8d35" class="pw-post-body-paragraph kx ky it la b lb mp ju ld le mq jx lg mr ns lj lk mt nt ln lo mv nu lr ls lt im bi translated">在本节中，不同的机器学习算法用于预测价格/目标变量。</p><p id="aa53" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">数据集是受监督的，因此模型按给定的顺序应用:</p><ol class=""><li id="8d44" class="mn mo it la b lb lc le lf mr nx mt ny mv nz lt mx my mz na bi translated"><a class="ae lu" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html" rel="noopener ugc nofollow" target="_blank">线性回归</a></li><li id="e430" class="mn mo it la b lb nb le nc mr nd mt ne mv nf lt mx my mz na bi translated"><a class="ae lu" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ridge_regression.html" rel="noopener ugc nofollow" target="_blank">岭回归</a></li><li id="474a" class="mn mo it la b lb nb le nc mr nd mt ne mv nf lt mx my mz na bi translated"><a class="ae lu" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html" rel="noopener ugc nofollow" target="_blank">拉索回归</a></li><li id="39e4" class="mn mo it la b lb nb le nc mr nd mt ne mv nf lt mx my mz na bi translated"><a class="ae lu" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html" rel="noopener ugc nofollow" target="_blank"> K 邻居回归量</a></li><li id="70aa" class="mn mo it la b lb nb le nc mr nd mt ne mv nf lt mx my mz na bi translated"><a class="ae lu" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html" rel="noopener ugc nofollow" target="_blank">随机森林回归器</a></li><li id="740b" class="mn mo it la b lb nb le nc mr nd mt ne mv nf lt mx my mz na bi translated"><a class="ae lu" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html" rel="noopener ugc nofollow" target="_blank">装袋回归器</a></li><li id="544d" class="mn mo it la b lb nb le nc mr nd mt ne mv nf lt mx my mz na bi translated"><a class="ae lu" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html" rel="noopener ugc nofollow" target="_blank"> Adaboost 回归器</a></li><li id="8c70" class="mn mo it la b lb nb le nc mr nd mt ne mv nf lt mx my mz na bi translated"><a class="ae lu" href="https://xgboost.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> XGBoost </a></li></ol><h2 id="82a1" class="ng lw it bd lx nh ni dn mb nj nk dp mf mr nl nm mh mt nn no mj mv np nq ml nr bi translated">1)线性回归:</h2><p id="d611" class="pw-post-body-paragraph kx ky it la b lb mp ju ld le mq jx lg mr ns lj lk mt nt ln lo mv nu lr ls lt im bi translated">在统计学中，线性回归是一种模拟标量响应(或因变量)和一个或多个解释变量(或自变量)之间关系的线性方法。在线性回归中，使用线性预测函数对关系进行建模，其未知模型参数根据数据进行估计。这种模型被称为线性模型。<a class="ae lu" href="https://en.wikipedia.org/wiki/Linear_regression" rel="noopener ugc nofollow" target="_blank"> <em class="kz">更多详情</em> </a></p><p id="c61b" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">系数:每个系数的符号表示预测变量和响应变量之间关系的方向。</p><ul class=""><li id="df89" class="mn mo it la b lb lc le lf mr nx mt ny mv nz lt nv my mz na bi translated">正号表示随着预测变量的增加，响应变量也增加。</li><li id="afe4" class="mn mo it la b lb nb le nc mr nd mt ne mv nf lt nv my mz na bi translated">负号表示随着预测变量的增加，响应变量减少。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi oi"><img src="../Images/da7dcf5a873a3dc5eb7e6d0d6c5a2e6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2xeokQnLn7xbZ2Ipw5tLDw.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">显示线性回归性能的图表(图片由<a class="ae lu" href="https://www.linkedin.com/in/abhash-panwar-85126976/" rel="noopener ugc nofollow" target="_blank"> Panwar Abhash Anil </a>提供)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/50f32647ea4ae3a421764e28b9f63e94.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*Pi93nxezaDaeqFnf-mbtXA.jpeg"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">显示数据集重要特征的图表(图片由<a class="ae lu" href="https://www.linkedin.com/in/abhash-panwar-85126976/" rel="noopener ugc nofollow" target="_blank"> Panwar Abhash Anil </a>提供)</p></figure><p id="ffa9" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">考虑到这个数字，线性回归表明<strong class="la iu"> <em class="kz">年份、气缸、变速器、燃油和里程表</em> </strong>这五个变量是最重要的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/6aec8d7cb529ccc2d72d7d2c6ece0886.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*8BEVfmm_vEGtHw1tdhkEOQ.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">线性回归的结果(图片由<a class="ae lu" href="https://www.linkedin.com/in/abhash-panwar-85126976/" rel="noopener ugc nofollow" target="_blank"> Panwar Abhash Anil </a>提供)</p></figure><h2 id="11c7" class="ng lw it bd lx nh ni dn mb nj nk dp mf mr nl nm mh mt nn no mj mv np nq ml nr bi translated">2)岭回归:</h2><p id="1005" class="pw-post-body-paragraph kx ky it la b lb mp ju ld le mq jx lg mr ns lj lk mt nt ln lo mv nu lr ls lt im bi translated"><strong class="la iu">岭回归</strong>是一种分析多重共线性数据的技术。当多重共线性发生时，最小二乘估计是无偏的，但是它们的方差很大，因此它们可能远离真实值。</p><p id="84cf" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">为了在岭回归中找到最佳 alpha 值，应用了黄砖库<a class="ae lu" href="https://www.scikit-yb.org/en/latest/api/regressor/alphas.html" rel="noopener ugc nofollow" target="_blank"><em class="kz">alpha selection</em></a>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/f5748796aa97d726a77d2f4b6e979ec9.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*8HDeCd_6C6UPXg28gqLwBA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">显示 Alpha 最佳值的图表</p></figure><p id="fb0c" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">从图中可以看出，最适合数据集的 alpha 值是 20.336。</p><p id="73cd" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">注意:α的值不是常数，它随时都在变化。</p><p id="b597" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">使用 alpha 的这个值，实现了 Ridgeregressor。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/0eb9d2998e3e69059a295a93d7a87d98.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*JCldwUXZFuxhUFzXXmaHGg.jpeg"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">显示重要特征的图表</p></figure><p id="c90b" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">考虑到这个数字，拉索回归表明<strong class="la iu"> <em class="kz">年份、气缸、变速器、燃油和里程表</em> </strong>这五个变量是最重要的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/4534a80efdb4c543910c8ee7bbfa4095.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*uEVvsEUyBM1fdv6kRErZZg.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">这个模型的最终结果(图片由<a class="ae lu" href="https://www.linkedin.com/in/abhash-panwar-85126976/" rel="noopener ugc nofollow" target="_blank">潘瓦尔·阿布哈什·阿尼尔</a>提供)</p></figure><p id="e925" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">岭回归的表现几乎和线性回归一样。</p><h2 id="5255" class="ng lw it bd lx nh ni dn mb nj nk dp mf mr nl nm mh mt nn no mj mv np nq ml nr bi translated">3)套索回归:</h2><p id="c90c" class="pw-post-body-paragraph kx ky it la b lb mp ju ld le mq jx lg mr ns lj lk mt nt ln lo mv nu lr ls lt im bi translated">套索回归是一种使用收缩的线性回归。收缩是指数据值向中间点收缩。lasso 程序鼓励简单、稀疏的模型(即参数较少的模型)。</p><p id="f7a4" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated"><strong class="la iu">为什么使用套索回归？</strong></p><p id="be9b" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">套索回归的目标是获得预测因子的子集，使定量响应变量的预测误差最小化。lasso 通过对模型参数施加约束来实现这一点，这会导致某些变量的回归系数向零收缩。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/253d6c44701b662559242f05a8811792.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*6RYwCGUqNXZrKReGji1TUA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">这个模型的最终结果(图片由<a class="ae lu" href="https://www.linkedin.com/in/abhash-panwar-85126976/" rel="noopener ugc nofollow" target="_blank">潘瓦尔·阿布哈什·阿尼尔</a>提供)</p></figure><p id="8008" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">但是对于这个数据集，没有必要进行套索回归，因为误差没有太大的差别。</p><h2 id="c564" class="ng lw it bd lx nh ni dn mb nj nk dp mf mr nl nm mh mt nn no mj mv np nq ml nr bi translated">4)k 近邻回归器:回归——基于 k 近邻。</h2><p id="f080" class="pw-post-body-paragraph kx ky it la b lb mp ju ld le mq jx lg mr ns lj lk mt nt ln lo mv nu lr ls lt im bi translated">通过与训练集的最近邻居相关联的目标的局部插值来预测目标。</p><p id="1632" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated"><em class="kz"> k </em> -NN 是一种<a class="ae lu" href="https://en.wikipedia.org/wiki/Instance-based_learning" rel="noopener ugc nofollow" target="_blank">基于实例的学习</a>，或<a class="ae lu" href="https://en.wikipedia.org/wiki/Lazy_learning" rel="noopener ugc nofollow" target="_blank">懒惰学习</a>，其中函数仅局部近似，所有计算都推迟到函数求值。<a class="ae lu" href="https://www.kite.com/python/docs/sklearn.neighbors.KNeighborsRegressor" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu"> <em class="kz">阅读更多</em> </strong> </a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/604db3559d3a1c80ff2d71882d03e9f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1330/format:webp/1*ozTH4P3Hi0Cw4_rKQPSGtA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">每个 K 范围 1-9 的误差图(图片由<a class="ae lu" href="https://www.linkedin.com/in/abhash-panwar-85126976/" rel="noopener ugc nofollow" target="_blank"> Panwar Abhash Anil </a>提供)</p></figure><p id="4156" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">从上图可以看出，对于 k=5，KNN 给出的误差最小。因此，使用 n_neighbors=5 和 metric='euclidean '来训练数据集。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/68cb3c3c270076e041717b29212ce497.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*emXX4dcH_AWq7xbnrFokSA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">KNN 的最终结果(图片由<a class="ae lu" href="https://www.linkedin.com/in/abhash-panwar-85126976/" rel="noopener ugc nofollow" target="_blank">潘瓦尔·阿布哈什·阿尼尔</a>提供)</p></figure><p id="18ee" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">性能 KNN 更好，并且误差随着精度的增加而减小。</p><h2 id="ad9f" class="ng lw it bd lx nh ni dn mb nj nk dp mf mr nl nm mh mt nn no mj mv np nq ml nr bi translated">5)随机森林:</h2><p id="4414" class="pw-post-body-paragraph kx ky it la b lb mp ju ld le mq jx lg mr ns lj lk mt nt ln lo mv nu lr ls lt im bi translated">随机森林是由许多决策树组成的分类算法。它在构建每棵树时使用 bagging 和特征随机性，试图创建一个不相关的树木森林，其委员会的预测比任何单棵树都更准确。<a class="ae lu" href="https://en.wikipedia.org/wiki/Random_forest" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu"> <em class="kz">阅读更多</em> </strong> </a></p><p id="832e" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">在我们的模型中，用 max_features 0.5 创建了 180 个决策</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi oi"><img src="../Images/c05f2cc3934a2a0df6ee174e559b81da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zkcpztR7BL97M_gJKnbJ4w.jpeg"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">随机森林的性能(真实值与预测值之比)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi op"><img src="../Images/e70cc7d2f79ca831a93dca80ecd13d3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*etX_i8kHXxAA2ZV1relcBw.jpeg"/></div></div></figure><p id="f768" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">这是一个简单的柱状图，说明了<strong class="la iu"> <em class="kz">年</em> </strong>是汽车最重要的特征，然后是<strong class="la iu"> <em class="kz">里程表</em> </strong>变量，然后是其他。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/abf270e15658aef73bca462612855cac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/1*j_A8fK0kDW4XamxL7Fch3A.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">随机森林模型精度表(图片由<a class="ae lu" href="https://www.linkedin.com/in/abhash-panwar-85126976/" rel="noopener ugc nofollow" target="_blank"> Panwar Abhash Anil </a>提供)</p></figure><p id="35f6" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">随机森林的性能更好，精确度提高了大约。10%很好。由于随机森林在建造每棵树时使用装袋，因此将执行下一个装袋回归程序。</p><h2 id="7a4b" class="ng lw it bd lx nh ni dn mb nj nk dp mf mr nl nm mh mt nn no mj mv np nq ml nr bi translated">6)装袋回归器:</h2><p id="cdc5" class="pw-post-body-paragraph kx ky it la b lb mp ju ld le mq jx lg mr ns lj lk mt nt ln lo mv nu lr ls lt im bi translated">Bagging 回归器是一种集合元估计器，它将每个基础回归器拟合到原始数据集的随机子集上，然后聚合它们的预测(通过投票或平均)以形成最终预测。这种元估计器通常可以被用作一种方法，通过将随机化引入到其构造过程中，然后从中进行集成，来减少黑盒估计器(例如，决策树)的方差。<a class="ae lu" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu"> <em class="kz">阅读更多</em> </strong> </a></p><p id="2a2e" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">在我们的模型中，DecisionTreeRegressor 用作估计器，max_depth=20，它创建了 50 个决策树，结果如下所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/71d48426a2ec799ecf5d0742bc6bf93c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*cAW2QHkrcotgdGiBUgZn_Q.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">Bagging 回归器精度表(图片由<a class="ae lu" href="https://www.linkedin.com/in/abhash-panwar-85126976/" rel="noopener ugc nofollow" target="_blank"> Panwar Abhash Anil </a>提供)</p></figure><p id="929f" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">随机森林的性能比 Bagging 回归器好得多。</p><p id="401e" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated"><strong class="la iu">随机森林和 Bagging 的关键区别:</strong>根本区别在于，在<strong class="la iu">随机森林</strong>中，仅从全部<strong class="la iu">和</strong>特征中随机选择一个子集，该子集中的最佳分裂特征用于分裂树中的每个节点，这与<strong class="la iu"> bagging </strong>中考虑所有特征来分裂节点不同。</p><h2 id="132e" class="ng lw it bd lx nh ni dn mb nj nk dp mf mr nl nm mh mt nn no mj mv np nq ml nr bi translated">7) Adaboost 回归器:</h2><p id="1037" class="pw-post-body-paragraph kx ky it la b lb mp ju ld le mq jx lg mr ns lj lk mt nt ln lo mv nu lr ls lt im bi translated">AdaBoost 可用于提升任何机器学习算法的性能。Adaboost 帮助你将多个“弱分类器”组合成单个“强分类器”。<strong class="la iu">库使用:</strong><a class="ae lu" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html" rel="noopener ugc nofollow" target="_blank">AdaBoostRegressor</a>&amp;<a class="ae lu" href="https://en.wikipedia.org/wiki/AdaBoost" rel="noopener ugc nofollow" target="_blank"><strong class="la iu"><em class="kz">阅读更多</em> </strong> </a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/6f0ef0a15c7eb30bf035ea04422e3034.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*jKBeeEm8CJSV2JBccKcxXQ.jpeg"/></div></figure><p id="965a" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">这是一个简单的柱状图，说明了<strong class="la iu"> <em class="kz">年</em> </strong>是汽车最重要的特征，然后是<strong class="la iu"> <em class="kz">里程表</em> </strong>变量，然后是型号等。</p><p id="78d7" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">在我们的模型中，DecisionTreeRegressor 用作具有 24 max_depth 的估计器，创建 200 棵树&amp;以 0.6 learning_rate 学习模型，结果如下所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/fa1603082a37d1ebcadd626bc4c1b808.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/1*YFhcbflIh3SsMSMRsg_cZw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">AdaBoost 回归器的精度表(图片由<a class="ae lu" href="https://www.linkedin.com/in/abhash-panwar-85126976/" rel="noopener ugc nofollow" target="_blank"> Panwar Abhash Anil </a>提供)</p></figure><h2 id="76c0" class="ng lw it bd lx nh ni dn mb nj nk dp mf mr nl nm mh mt nn no mj mv np nq ml nr bi translated">8) XGBoost: XGBoost 代表极端梯度增强</h2><p id="939c" class="pw-post-body-paragraph kx ky it la b lb mp ju ld le mq jx lg mr ns lj lk mt nt ln lo mv nu lr ls lt im bi translated">XGBoost 是一种<a class="ae lu" href="https://en.wikipedia.org/wiki/Ensemble_learning" rel="noopener ugc nofollow" target="_blank">集成学习</a>方法。XGBoost 是梯度提升决策树的实现，旨在提高速度和性能。这种强大算法的美妙之处在于其可扩展性，它通过并行和分布式计算驱动快速学习，并提供高效的内存使用。<a class="ae lu" href="https://www.analyticsvidhya.com/blog/2018/09/an-end-to-end-guide-to-understand-the-math-behind-xgboost/" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu"> <em class="kz">阅读更多</em> </strong> </a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/f5ccc330b29cab89653eafb2828ed24c.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*yXftMIVgQZLnjMJ92Z1w0A.jpeg"/></div></figure><p id="1bfe" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">这是一个简单的重要性递减柱状图，它说明了哪一个<strong class="la iu"> <em class="kz"> </em>特征/变量<em class="kz"> </em> </strong>是汽车的重要特征更重要。</p><p id="e99a" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">根据 XGBoost 的说法，<strong class="la iu">里程表</strong>是一个重要的特征，而从以前的车型<strong class="la iu">年</strong>是一个重要的特征。</p><p id="3d70" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">在该模型中，创建了 200 个最大深度为 24 的决策树，并且该模型以 0.4 的学习速率学习参数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/4e67ee51f30212057da57d1b52e6a564.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*QKrWdcpHiulRLLQuw8pPxw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">XGBoost 回归器精度表(图片由<a class="ae lu" href="https://www.linkedin.com/in/abhash-panwar-85126976/" rel="noopener ugc nofollow" target="_blank"> Panwar Abhash Anil </a>提供)</p></figure><h1 id="279a" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">4)模型的性能比较:</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi ou"><img src="../Images/3b86db73135b5ecb554fdfa57a563ea9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8eZXofAxqfRwtT-i0dtFKg.jpeg"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">每个模型的精度比较(图片由<a class="ae lu" href="https://www.linkedin.com/in/abhash-panwar-85126976/" rel="noopener ugc nofollow" target="_blank"> Panwar Abhash Anil </a>提供)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/a96e7f47b66fa94c12dbeb3a7b93af10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*z81UsHSR2SkVrRsDnzyWrw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">总体精度表(图片由<a class="ae lu" href="https://www.linkedin.com/in/abhash-panwar-85126976/" rel="noopener ugc nofollow" target="_blank">潘瓦尔·阿布哈什·阿尼尔</a>提供)</p></figure><p id="e8c6" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">从上图可以得出结论，XGBoost 回归器以 89.662%的准确率表现优于其他模型。</p><h1 id="f6bb" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">5)来自数据集的一些见解:</h1><p id="fde9" class="pw-post-body-paragraph kx ky it la b lb mp ju ld le mq jx lg mr ns lj lk mt nt ln lo mv nu lr ls lt im bi ow translated">从这一对情节中，我们不能得出任何结论。变量之间没有相关性。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/516369126f16287ac70958bdb305fd96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*4prrHWaa8gMCRoivyabCJQ.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">配对图以寻找相关性</p></figure><p id="3ec4" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi ow translated">从 distplot 中，我们可以得出结论，最初，价格快速上升，但在某个特定点之后，价格开始下降。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/3368a66543f5712d4fbd029d48926ea4.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*DTsSYuGAmFfWgva4LssFSw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">显示价格分布的图表(图片由<a class="ae lu" href="https://www.linkedin.com/in/abhash-panwar-85126976/" rel="noopener ugc nofollow" target="_blank"> Panwar Abhash Anil </a>提供)</p></figure><p id="9e2e" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi ow translated"><span class="l ox oy oz bm pa pb pc pd pe di"> 3 </span>从图 1 中，我们分析出柴油版车型的车价高于电动版车型的车价。混动变形车价格最低。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/c6ca5878cdf64e46e3b8667524a6c8b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*a5diIhr--h_-wTlt6lQKNA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">显示每种燃料价格的条形图</p></figure><p id="a3b3" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi ow translated"><span class="l ox oy oz bm pa pb pc pd pe di"> 4 </span>从图 2 中，我们分析出各种燃料的汽车价格也取决于汽车的状况。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi oi"><img src="../Images/8abf0ffa259e8da7b15b29157d8eff28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PD2pzladq6HRqM7_I_j_Rw.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">燃料和价格与色调条件之间的条形图</p></figure><p id="be5b" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi ow translated">从图 3 中，我们分析出 1995 年后汽车价格每年都在上涨，从图 4 中，汽车的数量也每年都在增加，在某个时间点，即 2012 年，汽车的数量几乎相同。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi ou"><img src="../Images/b01b3006f058c4de06aa3cdb14fccf0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JBIWEiWC0nr4gr8P4vHGGA.jpeg"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">显示价格每年变化的图表</p></figure><p id="1ae9" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi ow translated">从图 5 中，我们可以分析出汽车的价格也取决于汽车的状况，从图 6 中，价格也随着汽车大小的状况而变化。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi pg"><img src="../Images/7afc1ee9767cfe03a1c80db36caafe59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MJrzsqYvonlwCKQfyICkKg.jpeg"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">显示车况价格的柱状图</p></figure><p id="3951" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi ow translated"><span class="l ox oy oz bm pa pb pc pd pe di"> 7 </span>从图 7-8 中，我们分析了汽车价格以及汽车的各个<strong class="la iu">变速器</strong>的价格。人们愿意购买有“其他变速器”的汽车，而有“手动变速器”的汽车价格较低。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi pg"><img src="../Images/216c9fffe188413a34d05a6ae660f845.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C_9omSXvuIkgC8EBGN-A9Q.jpeg"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">柱状图显示了传输的价格(图片由<a class="ae lu" href="https://www.linkedin.com/in/abhash-panwar-85126976/" rel="noopener ugc nofollow" target="_blank"> Panwar Abhash Anil </a>提供)</p></figure><p id="e3a8" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi ow translated"><span class="l ox oy oz bm pa pb pc pd pe di"> 8 </span>下面有相似的图形，具有相同的洞察力，但功能不同。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi ph"><img src="../Images/d195c83199a525291ddbabe3e1f9ac46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xpF9jB6QVtjN7625o7mSAw.jpeg"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi pg"><img src="../Images/d82ec65e9c996f4c7deabe9d03d2f306.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gxm7kSHaGzG5o3u3LKiGCw.jpeg"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi pg"><img src="../Images/0672ee534d5f3f2314acb1608f67518d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vxVVzH4mRffiV_1qA1ynMA.jpeg"/></div></div></figure><h1 id="080c" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论:</h1><p id="8b45" class="pw-post-body-paragraph kx ky it la b lb mp ju ld le mq jx lg mr ns lj lk mt nt ln lo mv nu lr ls lt im bi translated">通过执行不同的最大似然模型，我们的目标是获得更好的结果或最大精度的更少误差。我们的目的是预测有 25 个预测值和 509577 个数据条目的二手车的价格。</p><p id="4e6e" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">首先，执行数据清洗以从数据集中移除空值和离群值，然后实施 ML 模型来预测汽车价格。</p><p id="2077" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">接下来，借助数据可视化特性进行了深入探讨。检查特征之间的关系。</p><p id="f60c" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">从下表可以得出结论，XGBoost 是预测二手车价格的最佳模型。XGBoost 作为回归模型给出了最好的 MSLE 和 RMSLE 值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/a96e7f47b66fa94c12dbeb3a7b93af10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*z81UsHSR2SkVrRsDnzyWrw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">精度表(图片由<a class="ae lu" href="https://www.linkedin.com/in/abhash-panwar-85126976/" rel="noopener ugc nofollow" target="_blank"> Panwar Abhash Anil </a>提供)</p></figure></div><div class="ab cl pi pj hx pk" role="separator"><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn"/></div><div class="im in io ip iq"><p id="1172" class="pw-post-body-paragraph kx ky it la b lb lc ju ld le lf jx lg mr li lj lk mt lm ln lo mv lq lr ls lt im bi translated">仅此而已！如果你读到这里，感谢你的阅读。感谢任何反馈！并且可以在<a class="ae lu" href="https://www.linkedin.com/in/panwar-abhash-anil/" rel="noopener ugc nofollow" target="_blank"><em class="kz">Linkedin</em>T3】上联系到。</a></p></div></div>    
</body>
</html>