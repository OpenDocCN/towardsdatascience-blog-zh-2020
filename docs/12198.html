<html>
<head>
<title>YOLO v4 or YOLO v5 or PP-YOLO?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">YOLO v4 还是 YOLO v5 还是 PP-YOLO？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/yolo-v4-or-yolo-v5-or-pp-yolo-dad8e40f7109?source=collection_archive---------0-----------------------#2020-08-23">https://towardsdatascience.com/yolo-v4-or-yolo-v5-or-pp-yolo-dad8e40f7109?source=collection_archive---------0-----------------------#2020-08-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="09a3" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">2020 年 YOLO 会发布哪些新电影？它们有什么不同？我应该使用哪一个？</h2></div><p id="705e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi le translated">对象检测是一项计算机视觉任务，涉及预测一个或多个对象的存在，以及它们的类别和边界框。YOLO(你只看一次)是一个先进的对象检测器，可以实时执行对象检测具有良好的准确性。</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ln"><img src="../Images/c2b0055380d04301654cf67ee8cb4224.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9jTB1MbpJfvX_OYEvMefuw.jpeg"/></div></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">YOLO 物体检测(<em class="md">图片作者</em></p></figure><p id="48bf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">前三个 YOLO 版本分别于 2016 年、2017 年和 2018 年发布。然而，在 2020 年，在仅仅几个月的时间内，YOLO 的三个主要版本已经发布，命名为 YOLO v4，YOLO v5 和 PP-YOLO。YOLO v5 的发布甚至在机器学习界引起了争议。</p><p id="c428" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">此外，这在那些将要开始他们的机器学习项目的人的头脑中造成了一个困境。在本文中，我们将讨论这些新的 YOLO 版本的原因，同时强调它们的原创性、原创性、性能和主要改进，帮助人们为他们的项目选择最合适的版本。</p><h1 id="20ac" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">YOLO 是如何进化的</h1><p id="3292" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">YOLO 于 2016 年首次推出，由于其能够以更高的精度实时检测物体，因此是物体检测研究的里程碑。</p><p id="bc9f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">它是由华盛顿大学毕业生<a class="ae nb" href="https://pjreddie.com" rel="noopener ugc nofollow" target="_blank">约瑟夫·雷德蒙</a>提出的。描述 YOLO 的论文在 2016 年计算机视觉和模式识别大会(CVPR)上获得了<strong class="kk iu"> OpenCV 人民选择奖</strong>。</p><h2 id="aabf" class="nc mf it bd mg nd ne dn mk nf ng dp mo kr nh ni mq kv nj nk ms kz nl nm mu nn bi translated">约瑟夫·雷德蒙的 YOLO 版本</h2><ol class=""><li id="35ac" class="no np it kk b kl mw ko mx kr nq kv nr kz ns ld nt nu nv nw bi translated">版本 1 <br/> <a class="ae nb" href="https://arxiv.org/abs/1506.02640" rel="noopener ugc nofollow" target="_blank"> ' <em class="nx">你只看一次:统一、实时的物体检测</em> ' </a> (2016)</li><li id="42d9" class="no np it kk b kl ny ko nz kr oa kv ob kz oc ld nt nu nv nw bi translated">版本 2 <br/> <a class="ae nb" href="https://arxiv.org/abs/1612.08242" rel="noopener ugc nofollow" target="_blank"> ' <em class="nx"> YOLO9000:更好更快更强</em> ' </a> (2017)</li><li id="26cf" class="no np it kk b kl ny ko nz kr oa kv ob kz oc ld nt nu nv nw bi translated">版本 3 <br/> <a class="ae nb" href="https://arxiv.org/abs/1804.02767" rel="noopener ugc nofollow" target="_blank"> ' <em class="nx"> YOLOv3:增量改进</em> ' </a> (2018)</li></ol><p id="a8ba" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">YOLO v2 可以以 40–90 FPS 的速度处理图像，而 YOLO v3 允许我们在速度和准确性之间轻松权衡，只需改变模型大小，无需任何重新培训。</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div class="gh gi od"><img src="../Images/153de0c9743cf8453e444a3990d9d7ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*AtsoKR91L6LlA4eseQmDNA.jpeg"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">在 VOC 2007 和 COCO 数据集上 YOLO 的表现(来源:<a class="ae nb" href="https://pjreddie.com" rel="noopener ugc nofollow" target="_blank">pjreddie.com</a></p></figure><h2 id="75bc" class="nc mf it bd mg nd ne dn mk nf ng dp mo kr nh ni mq kv nj nk ms kz nl nm mu nn bi translated">主要的 YOLO 实施</h2><p id="6dd3" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">Redmon 的 YOLO 主要实现基于<a class="ae nb" href="https://github.com/pjreddie/darknet" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu"> Darknet </strong> </a>，这是一个用 C 和 CUDA 编写的开源神经网络框架。暗网设置网络的底层架构，并用作训练 YOLO 的框架。这个实现是由 Redmon 自己介绍的，它速度快，易于安装，支持 CPU 和 GPU 计算。</p><p id="152e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">后来，Ultralytics LLC 的 Glenn Jocher 为 YOLO v3 推出了一个<a class="ae nb" href="https://github.com/ultralytics/yolov3" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu"> PyTorch 翻译</strong> </a>。</p></div><div class="ab cl oe of hx og" role="separator"><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj"/></div><div class="im in io ip iq"><h1 id="7354" class="me mf it bd mg mh ol mj mk ml om mn mo jz on ka mq kc oo kd ms kf op kg mu mv bi translated">v3 之后没有 YOLO 更新？</h1><p id="ec76" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">YOLO 很快就在计算机视觉界出名了，因为它的速度非常快，精确度也很高。然而，在 2020 年 2 月，YOLO <strong class="kk iu">的创造者 Joseph Redmon 宣布他已经停止了计算机视觉</strong>的研究！他还表示，这是由于对其工作的潜在负面影响的一些担忧。</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="oq or l"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">来自 Redmon 的公告(来源:<a class="ae nb" href="https://twitter.com/pjreddie/status/1230524770350817280" rel="noopener ugc nofollow" target="_blank">twitter.com</a>)</p></figure><p id="71a1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这导致了一些热门的社区讨论，并提出了一个重要的问题:将来会有任何 YOLO 更新吗？</p></div><div class="ab cl oe of hx og" role="separator"><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj"/></div><div class="im in io ip iq"><h1 id="aaa8" class="me mf it bd mg mh ol mj mk ml om mn mo jz on ka mq kc oo kd ms kf op kg mu mv bi translated">YOLO v4</h1><p id="842c" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">雷德蒙的退出并不是 YOLO 的终结。重温计算机视觉社区中的许多人，第四代 YOLO 已于 2020 年 4 月发布。Alexey Bochkovskiy 等人在一篇名为'<a class="ae nb" href="https://arxiv.org/abs/2004.10934" rel="noopener ugc nofollow" target="_blank"> <em class="nx"> YOLOv4:物体检测的最佳速度和精度</em> </a> <em class="nx"> ' </em>的论文中介绍了这一点。</p><p id="e402" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">此外，Redmon 的工作由 Alexey 在<a class="ae nb" href="https://github.com/pjreddie/darknet" rel="noopener ugc nofollow" target="_blank">主</a>库的<a class="ae nb" href="https://github.com/AlexeyAB/darknet" rel="noopener ugc nofollow" target="_blank">分支</a>中继续。YOLO v4 被认为是用于物体检测的最快和最准确的实时模型。</p><h2 id="9a9f" class="nc mf it bd mg nd ne dn mk nf ng dp mo kr nh ni mq kv nj nk ms kz nl nm mu nn bi translated">YOLO v4 的主要改进</h2><p id="795e" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">YOLO v4 受到了最先进的 BoF(一袋免费赠品)和几个 BoS(一袋特价商品)的影响。BoF 提高了检测器的准确性，而不增加推理时间。它们只会增加培训成本。另一方面，BoS 增加了少量的推理成本，但是它们显著地提高了目标检测的准确性。</p><h2 id="9792" class="nc mf it bd mg nd ne dn mk nf ng dp mo kr nh ni mq kv nj nk ms kz nl nm mu nn bi translated">YOLO v4 性能</h2><p id="e17f" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">YOLO v4 也基于 Darknet，并在 COCO 数据集上获得了 43.5%的 AP 值，在 Tesla V100 上获得了 65 FPS 的实时速度，在速度和准确性方面击败了最快和最准确的检测器。</p><p id="167a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与 YOLO v3 相比，AP 和 FPS 分别增加了 10%和 12%。</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div class="gh gi os"><img src="../Images/b240a4b25b29f4a733dda3308ac0e425.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*EVPqmfh38YT5KDGXT950tA.png"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">YOLO v4 的速度和准确性(来源:<a class="ae nb" href="https://arxiv.org/abs/2004.10934" rel="noopener ugc nofollow" target="_blank"> YOLO v4 论文</a></p></figure><h2 id="2cf6" class="nc mf it bd mg nd ne dn mk nf ng dp mo kr nh ni mq kv nj nk ms kz nl nm mu nn bi translated">Redmon 对 YOLO 作者身份的回应</h2><p id="b509" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">2020 年 4 月 24 日，Redmon 的原始 github 帐户的自述文件更新了一个链接，指向 Alexey 的分叉知识库和 YOLO v4 论文。Redmon 也在推特上写道:</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="oq or l"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">Redmon 对 YOLO 作者身份的回应(来源:【twitter.com】T2)</p></figure></div><div class="ab cl oe of hx og" role="separator"><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj"/></div><div class="im in io ip iq"><h1 id="70d0" class="me mf it bd mg mh ol mj mk ml om mn mo jz on ka mq kc oo kd ms kf op kg mu mv bi translated">YOLO v5</h1><p id="ace8" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">在 YOLO v4 发布后，仅仅两个月的时间内，YOLO 的另一个版本——YOLO V5 也发布了！作者是 Glenn Jocher，他已经因为创建了流行的 YOLO v3 的 PyTorch 实现而在社区中闻名。</p><p id="95ef" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">2020 年 6 月 9 日，Jocher 声明他的 YOLO v5 实现是公开发布的，并推荐在新项目中使用。然而，在最初发布这个新版本时，他并没有发表一篇论文。</p><h2 id="64af" class="nc mf it bd mg nd ne dn mk nf ng dp mo kr nh ni mq kv nj nk ms kz nl nm mu nn bi translated">YOLO v5 的主要改进</h2><p id="8d28" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">YOLO v5 不同于所有其他以前的版本，因为这是 PyTorch 实现，而不是从原始 Darknet 派生出来的。与 YOLO v4 相同，YOLO v5 有一个 CSP 主干和 PA-NET 颈部。主要改进包括镶嵌数据增强和自动学习边界框锚。</p><h2 id="ea1c" class="nc mf it bd mg nd ne dn mk nf ng dp mo kr nh ni mq kv nj nk ms kz nl nm mu nn bi translated">机器学习社区的争议</h2><p id="8e7d" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">YOLO v5 的发布备受关注，在机器学习社区平台引起了热烈讨论。这主要是由于 Roboflow 团队发表的一篇关于 YOLO v5 的文章中的几个事实。</p><p id="2a8c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇题为“YOLOv5 在这里”的文章于 2020 年 6 月 10 日发表在 Roboflow 博客上，陈述了几个重要的事实。以下是约瑟夫·尼尔森和雅各布·索拉维茨在<a class="ae nb" href="https://blog.roboflow.ai/yolov5-is-here/" rel="noopener ugc nofollow" target="_blank">的博客文章</a>中的一些引言。</p><blockquote class="ot"><p id="9d0a" class="ou ov it bd ow ox oy oz pa pb pc ld dk translated">“运行特斯拉 P100，我们看到每幅图像的推理时间高达 0.007 秒，这意味着每秒 140 帧(FPS)！相比之下，YOLO v4 在转换到同一个 Ultralytics PyTorch 库后实现了 50 FPS。”</p><p id="9ee5" class="ou ov it bd ow ox oy oz pa pb pc ld dk translated">“YOLO v5 很小。具体来说，YOLO v5 的权重文件是 27 兆字节。我们的 YOLO v4(使用 Darknet 架构)的权重文件是 244 兆字节。YOLO v5 比 YOLO v4 小了近 90%。”</p></blockquote><p id="e0c2" class="pw-post-body-paragraph ki kj it kk b kl pd ju kn ko pe jx kq kr pf kt ku kv pg kx ky kz ph lb lc ld im bi translated">所以，据说 YOLO 的 v5 比 YOLO 的 v4 速度更快，重量更轻，而精度却和 YOLO 的 v4 基准相当。但是社区提出的主要问题是:这些基准是准确的和可重复的吗？</p><h2 id="9e42" class="nc mf it bd mg nd ne dn mk nf ng dp mo kr nh ni mq kv nj nk ms kz nl nm mu nn bi translated">反应</h2><p id="5f03" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">《YOLO》v4 的作者阿列克谢对所有这些比较的方式并不满意。他回答了 github 中提出的几个<a class="ae nb" href="https://github.com/pjreddie/darknet/issues/2198" rel="noopener ugc nofollow" target="_blank">问题</a>，提到了那些比较的问题，特别是批量大小。</p><p id="5504" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Roboflow 和 YOLO v5 的开发者也对黑客新闻社区的问题做出了积极回应，并于 6 月 14 日在 Roboflow 博客上发表了一篇<a class="ae nb" href="https://blog.roboflow.com/yolov4-versus-yolov5/" rel="noopener ugc nofollow" target="_blank">文章</a>，描述了他们如何比较这两个版本。</p></div><div class="ab cl oe of hx og" role="separator"><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj"/></div><div class="im in io ip iq"><h1 id="9831" class="me mf it bd mg mh ol mj mk ml om mn mo jz on ka mq kc oo kd ms kf op kg mu mv bi translated">PP-YOLO</h1><p id="aaad" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">PP-YOLO 已于 2020 年 7 月通过向龙等人题为<a class="ae nb" href="https://arxiv.org/abs/2007.12099" rel="noopener ugc nofollow" target="_blank"> PP-YOLO:对象检测器</a>的有效和高效实现的论文引入，它基于 PaddlePaddle(并行分布式深度学习)，这是一个开源的深度学习平台，最初由<a class="ae nb" href="http://research.baidu.com/Blog/index-view?id=126" rel="noopener ugc nofollow" target="_blank">百度科学家</a>开发。</p><h2 id="f086" class="nc mf it bd mg nd ne dn mk nf ng dp mo kr nh ni mq kv nj nk ms kz nl nm mu nn bi translated">PP-YOLO 是一种新颖的模式吗？</h2><p id="1fbb" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">PP-YOLO 基于 YOLO v3 模型。该论文明确指出，PP-YOLO 的目标是实现一种具有相对平衡的有效性和效率的对象检测器，可以直接应用于实际应用场景，而不是提出一种新的检测模型。</p><p id="0c3e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">值得注意的变化包括将 YOLO v3 的 Darknet53 主干替换为 ResNet 主干，并将训练批量从 64 增加到 192(在 8 个 GPU 上为 24 的小批量)。</p><h2 id="8c5c" class="nc mf it bd mg nd ne dn mk nf ng dp mo kr nh ni mq kv nj nk ms kz nl nm mu nn bi translated">聚丙烯-YOLO 性能</h2><p id="effc" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">根据该论文，PP-YOLO 可以实现 45.2% COCO 数据集的地图，这超过了 YOLO v4 的 43.5%。在批量为 1 的 V100 上测试时，PP-YOLO 可以达到 72.9 FPS 的推理速度，也高于 YOLO v4 的 65 FPS。</p><p id="de8f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">PP-YOLO 的作者推测 tensorRT 在 ResNet 模型上比 Darknet 更好的优化是这种性能改善背后的主要原因。</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi pi"><img src="../Images/5657aa83ded958f89bcd7ec5cb98e34d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AAGWRhZkyLE6Hod9aP8Pqg.png"/></div></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">PP-YOLO 的速度和准确性(来源:<a class="ae nb" href="https://github.com/PaddlePaddle/PaddleDetection/" rel="noopener ugc nofollow" target="_blank"> PP-YOLO 回购</a>)</p></figure></div><div class="ab cl oe of hx og" role="separator"><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj"/></div><div class="im in io ip iq"><h1 id="ec5c" class="me mf it bd mg mh ol mj mk ml om mn mo jz on ka mq kc oo kd ms kf op kg mu mv bi translated">最后的话</h1><p id="3f63" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">在本文中，我们讨论了 YOLO 发展的重要里程碑以及 2020 年许多新 YOLO 版本背后的故事，同时强调了这些最新 YOLO 版本的主要改进和性能。总之，YOLO v4 是这种先进的物体检测器的最新的基于暗网的实现。它还有一篇阿列克谢·博奇科夫斯基(Alexey Bochkovskiy)发表的基准论文。另一方面，YOLO v5 是 Ultralytics 的新 PyTorch 实施方案，当以较大批量进行测试时，据说它比大多数检测器具有更高的干扰速度。然而，在撰写本文时，还没有针对 YOLO v5 发表的同行评审论文。PP-YOLO 是另一个基于深度学习框架 PaddlePaddle 的新 YOLO 升级版，它改进了 YOLO v3 模型，以在有效性和效率之间获得更好的平衡。我们讨论的事实，比如每个版本的架构、改进和性能，将有助于为特定项目选择最合适的 YOLO 版本。继续学习！</p><h1 id="c3c2" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">参考</h1><p id="6e37" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">[1]约瑟夫·雷德蒙的<a class="ae nb" href="https://pjreddie.com/" rel="noopener ugc nofollow" target="_blank">官网</a>。</p><p id="a8ff" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[2]发表论文<a class="ae nb" href="https://arxiv.org/abs/1506.02640" rel="noopener ugc nofollow" target="_blank"> YOLO v1 </a>，<a class="ae nb" href="https://arxiv.org/abs/1612.08242" rel="noopener ugc nofollow" target="_blank"> YOLO v2 </a>，<a class="ae nb" href="https://arxiv.org/abs/1804.02767" rel="noopener ugc nofollow" target="_blank"> YOLO v3 </a>，<a class="ae nb" href="https://arxiv.org/abs/2004.10934" rel="noopener ugc nofollow" target="_blank"> YOLO v4 </a>，<a class="ae nb" href="https://arxiv.org/abs/2007.12099" rel="noopener ugc nofollow" target="_blank"> PP-YOLO </a>。</p><p id="22d8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[3]Redmon 的<a class="ae nb" href="https://github.com/pjreddie/darknet" rel="noopener ugc nofollow" target="_blank">原版 YOLO </a>、Alexey 的<a class="ae nb" href="https://github.com/AlexeyAB/darknet" rel="noopener ugc nofollow" target="_blank"> YOLO v4 </a>、Jocher 的<a class="ae nb" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank"> YOLO v5 </a>和向龙的<a class="ae nb" href="https://github.com/PaddlePaddle/PaddleDetection" rel="noopener ugc nofollow" target="_blank"> PP-YOLO </a>的 Github 库。</p><p id="d458" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[4]“<a class="ae nb" href="https://blog.roboflow.ai/yolov5-is-here/" rel="noopener ugc nofollow" target="_blank">约洛夫 5 在这里</a>”和“<a class="ae nb" href="https://blog.roboflow.ai/yolov4-versus-yolov5/" rel="noopener ugc nofollow" target="_blank">回应关于约洛夫 5 </a>的争议”约瑟夫·尼尔森和雅各布·索拉维茨在<a class="ae nb" href="https://blog.roboflow.com/" rel="noopener ugc nofollow" target="_blank"> Roboflow 博客</a>上的博文。</p><p id="4648" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[5] " <a class="ae nb" href="https://syncedreview.com/2020/04/27/yolo-is-back-version-4-boasts-improved-speed-and-accuracy/" rel="noopener ugc nofollow" target="_blank"> YOLO 回来了！第 4 版拥有更高的速度和准确性</a>”syncedreview.com 上发表的黑卡蒂的文章</p></div></div>    
</body>
</html>