<html>
<head>
<title>Old vs New Drake Lyrics With AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">新老德雷克歌词与人工智能</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-differences-between-drakes-old-vs-new-songs-using-text-classification-and-lstm-6381fb568b31?source=collection_archive---------45-----------------------#2020-08-13">https://towardsdatascience.com/understanding-differences-between-drakes-old-vs-new-songs-using-text-classification-and-lstm-6381fb568b31?source=collection_archive---------45-----------------------#2020-08-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c770" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用文本分类和 LSTM 模型理解德雷克的老歌和新歌之间的差异。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/55acd9432a71a9305d8f6cdf4d0a95f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*f41T9JNPedxFR4ft"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">德鲁·比默|<a class="ae ky" href="https://unsplash.com/photos/Kxc7dgkjdNo" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/photos/Kxc7dgkjdNo</a></p></figure><p id="edd3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">德雷克的歌词随着时间的推移有变化吗？如果是这样，那怎么做？</p><p id="5937" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我用机器学习识别老德雷克歌词和新德雷克歌词，准确率 86%！这说明新旧德雷克歌曲歌词是有区别的。现在，让我们找出这些差异，并测试模型预测哪些歌曲是新旧德雷克歌曲。</p><ul class=""><li id="ffbc" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><em class="me">* *如果对过程和结果不感兴趣，请跳到第 5 和第 6 节。</em></li></ul><p id="cf8d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">本文共分 7 节:</strong></p><p id="49a5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">1)数据探索、清理和处理</p><p id="d7f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2)使用计数矢量器的 ML 建模</p><p id="91a5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3)使用 Tfidf 矢量器的 ML 建模</p><p id="2442" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">4)对 2 和 3 中的顶级型号进行参数调整</p><p id="8fe9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">5)分析来自模型的前 40 个特征，以发现新旧德雷克之间的差异。</p><p id="2b72" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">6)让我们通过预测单曲和 mixtape 歌曲是旧的还是新的 Drake 来看看模型的运行情况。</p><p id="0892" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">7)使用 LSTM 的序列建模</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="3dbb" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">1)数据预处理</h1><p id="b593" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">我用 Genius API 收集了德雷克歌词的数据集。我只收录他官方专辑中的歌曲。因此没有单打和功能</p><p id="28ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些数据不需要太多争论。我只是将所有文本转换成小写，并删除了字母表和数字之外的任何字符。</p><p id="f5c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">新德雷克的歌是 2014 年以后的歌，老德雷克的歌是 2014 年以前的。出现这种情况的两个原因是:</p><p id="8d35" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">1)大家普遍认为德雷克最好的项目是在 2014 年之前。</p><p id="791d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2) 2014 年是一个很好的中间点，为每个类别提供了一个相当平衡的数据集。</p><p id="fea0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我还执行随机抽样，并创建一个更加平衡的数据集。我将展示使用两个数据集的结果。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="4fb4" class="no mn it nk b gy np nq l nr ns"><em class="me">#Creating column to define new drake vs old drake</em><br/><em class="me">#1 represents new drake, 0 represents old drake</em><br/><br/>df['drake'] = np.where(df['year'] &gt; 2014, 1, 0)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/2d0e084824a0ce959d7b921207a21e14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5mlnyWb-ToeMIuWEy8_coQ.png"/></div></div></figure><p id="2528" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这里你可以看到德雷克专辑和歌曲的分布</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="91ef" class="no mn it nk b gy np nq l nr ns">sns.countplot(y=df['album'].values, order=df['album'].value_counts(ascending=<strong class="nk iu">True</strong>).index)<br/>plt.title('# Songs Per Album')<br/>plt.xlabel('Number Of Songs', fontsize=12)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/9365a08edcba737f1a4369218a9a3130.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*ucSk3D5QVLW-OFI9JMpn7A.png"/></div></figure><p id="f442" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">数据准备阶段:</strong></p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="e087" class="no mn it nk b gy np nq l nr ns"><em class="me">#Tokenizing Dataset</em><br/><strong class="nk iu">from</strong> <strong class="nk iu">nltk.tokenize</strong> <strong class="nk iu">import</strong> word_tokenize<br/>df['lyrics'] = df['lyrics'].apply(word_tokenize)</span><span id="e308" class="no mn it nk b gy nv nq l nr ns"><em class="me">#Stop word removal</em> <br/><strong class="nk iu">from</strong> <strong class="nk iu">nltk.corpus</strong> <strong class="nk iu">import</strong> stopwords <strong class="nk iu">from</strong> <strong class="nk iu">collections</strong> <strong class="nk iu">import</strong> Counter   stop = stopwords.words('english')  </span><span id="6e3e" class="no mn it nk b gy nv nq l nr ns"><em class="me">#I keep words in this list as I feel they are useful in predicting drake songs</em> <em class="me">#Furthermore, I tested accuracy with and without stop words. This setup is the best</em> </span><span id="7763" class="no mn it nk b gy nv nq l nr ns">remove_stop = ['i', 'me', 'myslef', 'we', 'you', 'we', 'she', 'her', 'they'] </span><span id="fe48" class="no mn it nk b gy nv nq l nr ns"> stop = list((Counter(stop)-Counter(remove_stop)).elements())   </span><span id="88b4" class="no mn it nk b gy nv nq l nr ns">df['lyrics'] = df['lyrics'].apply(<strong class="nk iu">lambda</strong> x: [item <strong class="nk iu">for</strong> item <strong class="nk iu">in</strong> x <strong class="nk iu">if</strong> item <strong class="nk iu">not</strong> <strong class="nk iu">in</strong> stop])</span><span id="bcee" class="no mn it nk b gy nv nq l nr ns"><em class="me">#Lemitization</em><br/><strong class="nk iu">from</strong> <strong class="nk iu">nltk.stem</strong> <strong class="nk iu">import</strong> WordNetLemmatizer <br/><br/><strong class="nk iu">def</strong> lemmatize_text(text):<br/>    lemmatizer = WordNetLemmatizer()<br/>    <strong class="nk iu">return</strong> [lemmatizer.lemmatize(w) <strong class="nk iu">for</strong> w <strong class="nk iu">in</strong> text]</span><span id="5a0e" class="no mn it nk b gy nv nq l nr ns">df['lyrics'] = df['lyrics'].apply(lemmatize_text)</span></pre></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="d3d1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我将数据集分为训练和测试，其中 80%用于训练，20%用于测试。此外，我还将使用 K-fold 验证来测试准确性，因为它对于像这样的较小数据集更准确。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="a84a" class="no mn it nk b gy np nq l nr ns"><em class="me">#Defining X and Y</em><br/>X = df['lyrics']<br/>y = df['drake']</span><span id="4289" class="no mn it nk b gy nv nq l nr ns"><em class="me">## Divide the dataset into Train and Test</em><br/><strong class="nk iu">from</strong> <strong class="nk iu">sklearn.model_selection</strong> <strong class="nk iu">import</strong> train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X,y,test_size= 0.2, random_state = <strong class="nk iu">None</strong>)</span></pre><h1 id="98d0" class="mm mn it bd mo mp nw mr ms mt nx mv mw jz ny ka my kc nz kd na kf oa kg nc nd bi translated">2)使用计数矢量器的 ML 建模</h1><p id="adf5" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">现在是时候用计数矢量器测试模型了。计数矢量器计算文本中的词频，并用词频创建一个数组。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="5ca6" class="no mn it nk b gy np nq l nr ns"><em class="me"># Applying Countvectorizer<br/># Creating the Bag of Words model</em><br/><em class="me">#I tried different n_gram ranges and unigram works best</em><br/><strong class="nk iu">from</strong> <strong class="nk iu">sklearn.feature_extraction.text</strong> <strong class="nk iu">import</strong> CountVectorizer<br/>cv = CountVectorizer()<br/>cv.fit(X_train)<br/>trainx_cv = cv.transform(X_train)<br/>testx_cv = cv.transform(X_test)</span><span id="2ced" class="no mn it nk b gy nv nq l nr ns">#For cross validation I create a new count vectorizer and use it in a sklearn pipeline with the model.</span><span id="f64b" class="no mn it nk b gy nv nq l nr ns">#Example pipeline.<br/>mnb = Pipeline([('vect', CountVectorizer()), ('mnb', MultinomialNB())])<br/>cvs = cross_val_score(mnb, X, y)<br/>print("Accuracy: %0.2f (+/- %0.2f)" % (cvs.mean(), cvs.std() * 2))</span><span id="4a0e" class="no mn it nk b gy nv nq l nr ns"># The pipeline will do feature extraction in each fold separately and prevent leakage.</span></pre><p id="da51" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我为文本分类创建了以下模型:</p><p id="e565" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意:我使用训练/测试/分割和交叉验证来测试模型。以下是交叉验证准确性，因为它们对于像这样的较小数据集更准确。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/e74fc2f58aac191fc1db036432145375.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VpeT2MELN4IE4YMU1Ib2Jg.png"/></div></div></figure><p id="84e6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了节省空间，我不包括这些代码。我的 Github 上有它们的代码。</p><h1 id="8856" class="mm mn it bd mo mp nw mr ms mt nx mv mw jz ny ka my kc nz kd na kf oa kg nc nd bi translated">3)使用 TF-IDF 矢量器的 ML 建模</h1><p id="7064" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">接下来，我重复相同的步骤，但是这次我使用 TF-IDF 矢量器，而不是计数矢量器。TF-IDF 做的事情与 count vectorizer 相同，但是值与 count 成比例增加，与单词的频率成反比。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="9775" class="no mn it nk b gy np nq l nr ns">#Lets try with Tf-IDF<br/>#Steps are repeated as before<br/>#I tried different n_gram ranges and unigram works best<br/>from sklearn.feature_extraction.text import TfidfVectorizer<br/>tf=TfidfVectorizer()<br/>tf.fit(X_train)<br/>trainx_tf = tf.transform(X_train).toarray()<br/>testx_tf = tf.transform(X_test).toarray()</span><span id="20b4" class="no mn it nk b gy nv nq l nr ns">#For cross validation I create a new tfidf vectorizer and use it in a sklearn pipeline with the model.</span><span id="c71c" class="no mn it nk b gy nv nq l nr ns">#Example pipeline.<br/>mnb = Pipeline([('vect', TfidfVectorizer()), ('mnb', MultinomialNB())])<br/>cvs = cross_val_score(mnb, X, y)<br/>print("Accuracy: %0.2f (+/- %0.2f)" % (cvs.mean(), cvs.std() * 2))</span><span id="35d3" class="no mn it nk b gy nv nq l nr ns"># The pipeline will do feature extraction in each fold separately and prevent leakage. </span></pre><p id="9952" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">TF-IDF 矢量器的精度为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/3407c292483928a8b8e34079b82ad061.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xQmQDREXuZpNLfJOia8VQA.png"/></div></div></figure><h1 id="8d20" class="mm mn it bd mo mp nw mr ms mt nx mv mw jz ny ka my kc nz kd na kf oa kg nc nd bi translated">4)参数调整</h1><p id="2a47" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">好了，现在我们知道朴素贝叶斯使用计数矢量器的性能最好，线性 SVC 使用 TF-IDF 矢量器的性能最好。现在让我们尝试进一步优化模型参数:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="a9fd" class="no mn it nk b gy np nq l nr ns">#Multinomial NB tunning<br/>pipeline = Pipeline([<br/>    ('vect', CountVectorizer()),<br/>    ('classifier', MultinomialNB()),<br/>])</span><span id="6ea4" class="no mn it nk b gy nv nq l nr ns">parameters = {<br/>    'vect__max_df': (0.5, 0.75, 1.0),<br/>    'vect__min_df': (1,2,3),<br/>    'vect__max_features': (None, 5000, 10000,15000),<br/>    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams<br/>    'classifier__alpha': (1, 0.1, 0.01, 0.001, 0.0001, 0.00001),<br/>}<br/>Best_NB = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)<br/>Best_NB.fit(X_train, y_train)<br/>best_parameters = Best_NB.best_estimator_.get_params()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/45f5f5d29b6d16127630f1ac3089bebb.png" data-original-src="https://miro.medium.com/v2/resize:fit:634/format:webp/1*pU8WqrupKgvPc3j1VNpthQ.png"/></div></figure><p id="8f41" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在相同的测试数据集上比较调优前后的准确性。</p><p id="06a8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请记住，前面几节中的精度是交叉验证精度。在这里，我比较了同一测试数据集上的火车测试分割精度，以查看相同数据上的性能的直接比较。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/3ffa83811af209d26ea6c95f1f1fd598.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-gGByK5a-TZbflpL8eKN5w.png"/></div></div></figure><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="3019" class="no mn it nk b gy np nq l nr ns">#LinearSVC tunning<br/>pipeline = Pipeline([<br/>    ('tfidf', TfidfVectorizer()),<br/>    ('clf', LinearSVC()),<br/>])</span><span id="a271" class="no mn it nk b gy nv nq l nr ns">parameters = {<br/>    'tfidf__max_df': (0.90, 1.0),<br/>    'tfidf__min_df': (1,2,3,),<br/>    'tfidf__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams<br/>    'clf__C': (0.1, 1, 10, 100, 1000),<br/>    'clf__penalty': ('l1', 'l2'),<br/>}<br/>Best_SVC = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)<br/>Best_SVC.fit(X_train, y_train)<br/>best_parameters = Best_SVC.best_estimator_.get_params()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/4eafd700efc8a7687950ff07dae59a6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/format:webp/1*nfhMyQdxWY39NesNiO7Zhg.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/cf00bedecfa7cfca7d30a755829d5da8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qzTCkZBV_x2LTtuNJ1aHlg.png"/></div></div></figure><p id="afa1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总体而言，在平衡数据集上训练的模型表现稍好。后来，当我对一些新数据进行测试时，我注意到在原始数据集上训练的模型对老歌略有过度拟合，因为它们完美地预测了老歌，但新歌的准确性不如在平衡数据集上训练的模型。在平衡数据集上训练的模型在老歌预测准确性方面略有下降，可能是因为通过移除 30%的数据集而遗漏了一些重要的老歌特征。因此，将来当德雷克推出另一张专辑时，我会用更多的数据重新测试它。</p><p id="ea6e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以现在我们有超过 80%准确率的模型。这表明，有一些特征有助于成功地区分德雷克歌曲是新的还是旧的德雷克。现在让我们来看看新德雷克和老德雷克的不同之处。</p><h1 id="89c6" class="mm mn it bd mo mp nw mr ms mt nx mv mw jz ny ka my kc nz kd na kf oa kg nc nd bi translated">5)特征重要性</h1><p id="d905" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">为此，我将查看模型系数值。此外，我只分析顶级模型。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="107c" class="no mn it nk b gy np nq l nr ns"><em class="me">#Thanks to tobique for the method. Link: https://stackoverflow.com/questions/11116697/how-to-get-most-informative-features-for-scikit-learn-classifiers</em><br/><em class="me">#This method look at the coeficient values and orders them based on most negative and positive </em><br/><em class="me">#The most positive values link to words defining old drake song</em><br/><em class="me">#The most negative values link to words defining new drake song</em><br/><br/><strong class="nk iu">def</strong> show_most_informative_features(vectorizer, clf, n=20):<br/>    feature_names = vectorizer.get_feature_names()<br/>    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))<br/>    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])<br/>    <strong class="nk iu">for</strong> (coef_1, fn_1), (coef_2, fn_2) <strong class="nk iu">in</strong> top:<br/>        print ("<strong class="nk iu">\t%.4f\t%-15s\t\t%.4f\t%-15s</strong>" % (coef_1, fn_1, coef_2, fn_2))</span></pre><p id="93c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如《代码》中所提到的，这种方法的所有功劳都归 Tobique 所有。这种方法查看模型系数，然后根据最大负值和最大正值对它们进行排序。它还将系数映射到特性名称，这使我们很容易理解它们。在我们的例子中，最负的系数与老德雷克歌曲歌词相关，最正的系数与新德雷克歌曲歌词相关。以下是两款车型的 40 大特色:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/0d7029ce51b4b01e11b5263e7e310f08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1310/format:webp/1*qb8F2l7KhFaZj8Vqy6PzQQ.png"/></div></figure><p id="e692" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">老德雷克关键词:</strong>嗯，布特，嗯，钱，美元，汽车，嚯，锄头，婊子，女孩，爱情，她，她，你，爱过，错过，低，品牌，褪色，梦想，球，船员。</p><p id="c724" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">新德雷克关键词:</strong>耶，伊，哇，仍然，不，妈妈，传道，祈祷，上帝，工作，轮班，奉献，妻子，感觉，孤独，宝贝，宝贝，六，侧，婴儿床。</p><p id="97a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要注意的第一个变化是，老德雷克通常使用短语 uh，bout，huh，ho，而新德雷克使用 ayy，woah，nah 来代替。</p><p id="43bd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">老德雷克谈论更多的是爱情/关系，女人，金钱/汽车/品牌等物质化的东西，他的船员(朋友)，被淡化(high)。</p><p id="fe0f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">新德雷克已经不再谈论女性、人际关系和唯物主义，现在他在唱/说唱各种不同的东西，包括上帝/祈祷、他的母亲、多伦多(又名六人组)、工作和他的感受。</p><p id="7994" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，德雷克还改变了他谈论女性的方式。在他以前的歌曲中，他使用了 b*tch，hoes 和 girl，而 new Drake 使用 babe，baby 和 wifey。</p><p id="bb70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，随着德雷克作为一个人的成熟，他的歌词也成熟了。此外，他的新歌词似乎也更加多样化，针对更多的观众。</p><h1 id="16e4" class="mm mn it bd mo mp nw mr ms mt nx mv mw jz ny ka my kc nz kd na kf oa kg nc nd bi translated">6)预测单曲/混音歌曲</h1><p id="29a9" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">现在，让我们用更多的歌曲来测试最好的模型。我从他的单曲和最新的 mixtape Dark Lane 样带中收集了更多的歌词。我收集的数据包括 14 首歌，7 首新歌和 7 首老歌。在这里，您可以看到模型准确预测了哪些歌曲。</p><p id="f33a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">错误的预测用红色表示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/188f01a6fe601f143ea16b85ffef1fc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BETR6RkXhUgPXlnjfmUCSQ.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/f76d51f3bcc6da15fe51b89128539450.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o3E5YetHqQA3uAbZfRxNVw.png"/></div></div></figure><p id="9872" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这个数据集上，朴素贝叶斯和线性 SVC 模型都获得了 12/14 的正确预测！！！</p><p id="cd23" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">线性 SVC 认为欲望是一首古老的德雷克歌曲，而朴素贝叶斯模型认为信任问题是一首新的德雷克歌曲。你认为欲望听起来像老德雷克，信任问题听起来像新德雷克吗？</p><p id="1cdd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一个值得注意的有趣的点是，两个模型都预测芝加哥自由泳是一首老歌，而它是一首新的德雷克歌曲。你觉得芝加哥自由式听起来像老德雷克吗？</p><p id="e57d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该项目已成功识别德雷克的老歌风格和新歌风格的变化。</p><p id="bbc3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果有你想让我测试的歌曲，请告诉我。</p><h1 id="1883" class="mm mn it bd mo mp nw mr ms mt nx mv mw jz ny ka my kc nz kd na kf oa kg nc nd bi translated">7)LSTM 序列模型</h1><p id="bcd9" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">最后，对于那些感兴趣的人，我还使用 LSTM 进行了序列分析，看看在特定序列中使用的单词是否能区分新旧德雷克。为此，我进一步将歌词分成 4462 行单行句子，看看德雷克的新旧歌词中是否有序列。然而，LSTM 模型给出了 60%的准确率。</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="dbc1" class="no mn it nk b gy np nq l nr ns">x = df_final['lyrics'].values y = df_final['drake'].values  x_train, x_test, y_train, y_test = \  train_test_split(x, y, test_size=0.2, random_state=<strong class="nk iu">None</strong>)</span><span id="1caf" class="no mn it nk b gy nv nq l nr ns">tokenizer = Tokenizer(num_words=100) tokenizer.fit_on_texts(x) xtrain= tokenizer.texts_to_sequences(x_train) xtest= tokenizer.texts_to_sequences(x_test)</span><span id="bf2e" class="no mn it nk b gy nv nq l nr ns">vocab_size=len(tokenizer.word_index)+1</span><span id="bc6e" class="no mn it nk b gy nv nq l nr ns">maxlen=15 xtrain=pad_sequences(xtrain,padding='post', maxlen=maxlen) xtest=pad_sequences(xtest,padding='post', maxlen=maxlen)</span><span id="aea4" class="no mn it nk b gy nv nq l nr ns">embedding_dim=50<br/>model=Sequential()<br/>model.add(layers.Embedding(input_dim=vocab_size,<br/>      output_dim=embedding_dim,<br/>      input_length=maxlen))<br/>model.add(layers.LSTM(units=50,return_sequences=<strong class="nk iu">True</strong>))<br/>model.add(layers.LSTM(units=10))<br/>model.add(layers.Dropout(0.5))<br/>model.add(layers.Dense(8))<br/>model.add(layers.Dense(1, activation="sigmoid"))<br/>model.compile(optimizer="adam", loss="binary_crossentropy", <br/>     metrics=['accuracy'])<br/>model.summary()</span><span id="1848" class="no mn it nk b gy nv nq l nr ns">model.fit(xtrain,y_train, epochs=20, batch_size=16, verbose=<strong class="nk iu">False</strong>)<br/><br/>loss, acc = model.evaluate(xtrain, y_train, verbose=<strong class="nk iu">False</strong>)<br/>print("Training Accuracy: " + str(acc))</span><span id="e5b5" class="no mn it nk b gy nv nq l nr ns">loss, acc = model.evaluate(xtest, y_test, verbose=<strong class="nk iu">False</strong>)<br/>print("Test Accuracy: " +  str(acc)</span></pre><p id="f57d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，我不认为老德雷克和新德雷克歌词之间有太多的顺序关系。这种差异归结于单词的使用，而不是它们的使用顺序。</p><h1 id="43c2" class="mm mn it bd mo mp nw mr ms mt nx mv mw jz ny ka my kc nz kd na kf oa kg nc nd bi translated">感谢您的阅读</h1><p id="ec4f" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">请随时留下任何反馈和建议。</p><p id="d60f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我的下一个项目是理解新旧说唱歌曲的区别。敬请关注。</p><p id="9332" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">笔记本:<a class="ae ky" href="https://github.com/HamzaKazmi/Drake_Lyrics_Analysis" rel="noopener ugc nofollow" target="_blank">https://github.com/HamzaKazmi/Drake_Lyrics_Analysis</a></p><p id="180c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个项目的灵感来自鲁斯兰的工作，他使用 LSTM 生成德雷克歌词。<a class="ae ky" rel="noopener" target="_blank" href="/generating-drake-rap-lyrics-using-language-models-and-lstms-8725d71b1b12">https://towards data science . com/generating-drake-rap-lyrics-using-language-models-and-lstms-8725 d71b 12</a></p></div></div>    
</body>
</html>