# 面试官最喜欢的问题-你会如何“扩展你的 ML 模型？”

> 原文：<https://towardsdatascience.com/interviewers-favorite-question-how-would-you-scale-your-ml-model-56e4fa40071b?source=collection_archive---------24----------------------->

## 您正在构建一个生产就绪的 ML 模型吗？

![](img/05a6de292de0d2683849e0e35ee1230f.png)

来源:作者在 [Imgflip](https://imgflip.com/i/49d9xq) 上创建的图片

如果你和我一样，已经疯狂地看完了《鲨鱼池》的所有剧集，那么首先，你好，新的最好的朋友:)其次，更重要的是，你已经知道如何回答这个(棘手的)面试问题了！

凯文·奥利里向任何新企业家提出的最著名的问题之一是——*你将如何扩展你的业务*？比方说，你被邀请去 Shark Tank(你这只幸运的鸭子)推销你的新餐厅创意，这个问题出现了，他们想知道的是——你有什么计划让这个创意成为*功能*创意？所以你应该这样解释:

*   当我的餐馆越来越受欢迎时会发生什么？
*   *我如何跟上厨房基础设施的发展？*
*   *我应该找一个杂货批发供应商，还是坚持现在的零售方式？*
*   *空间呢？我应该继续租赁还是购买房产？*
*   我应该招聘更多员工吗？我有预算吗？
*   *您需要升级到重型机械来满足批量订单吗？*

当凯文向你抛出这个问题时，你应该思考这些问题。

# 为什么面试官都爱问这个问题？

使用一个类似于鲨鱼池的类比，当面试官问你关于 ML 模型的缩放计划时，他们想知道的是:

> 当你的 ML 模型大规模投入生产时，你有多擅长认真考虑它？

请注意，从技术公司的角度来看，这非常重要！这是因为在 Jupyter 笔记本上为预测模型编写 Python 代码是一回事，但将它们部署到日常实际应用中则完全是另一回事。让我们看看如何...

# 作为一名数据科学家，我该如何回答这个问题？

有几个方面是可以关注的。这些在某种程度上与模型建立过程中涉及的三个主要阶段有关，即训练数据的收集、拟合模型和进行预测。

## 缩放 w.r.t .培训数据

正如一句著名的谚语所说:*你的模型的好坏取决于它被训练的基础数据的好坏*，通常都是这样。因此，当潜在的数据假设发生变化时，重新训练你的模型是绝对必要的。例如，根据 80 年代的数据训练的招聘模式不会有很多女性担任高级管理职位，因此，这种模式在 21 世纪已经过时(往好里说)，而且会对推荐女性担任高级职位产生偏见(往坏里说)。

## 扩展 w.r.t .数据洪流

不可避免的是，随着业务的增长，您将拥有比开始时多得多的数据。有了这么多数据，您可能需要**考虑** **并行计算**或**批处理** **(比如使用 SGD 优化)和** **并行处理，如交叉验证和超参数调整**，以便显著提升性能并有效利用您的计算资源。简而言之，寻找算法的分布式版本！

在重新训练 **序列化/酸洗模型**时**使用检查点也是谨慎的。这将为您节省大量重新训练模型的时间(最初构建时有 100 万行)，因为您不必仅仅因为收到了额外的 10k 行就从头开始重新构建它。系统能从你上次离开的地方赶上来。**

*趣闻:* [*H2o 支持检查点创建*](https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/checkpoint.html#checkpoint) *针对 GBM、DRF、XGBoost、深度学习等多个模型。*

## 缩放 w.r.t 框架

当谈到为您的 ML 和深度学习解决方案选择框架时，有几个选项(例如 SkLearn、Pytorch、Keras、Tensorflow、H2o、Theano ),重要的是，您要做出一个从长远来看对您有益的选择。选择可以基于几个因素。

例如，**你想要的抽象层次是什么？您希望编写更少的代码行(用于训练、优化和评估)吗？或者您是否愿意编写带有 CUDA 扩展的 C 代码，以便对编码实现有更多的控制？您也可以**根据社区支持的好坏、允许第三方集成的难易程度以及是否支持分布式 ML** (即是否允许计算并行化)来比较这些框架。**

归根结底，这是个人的选择，归结为你要创造的解决方案的新颖性。

*有趣的事实:尽管 scikit-learn 中的算法非常流行且易于实现，但它们并不是分布式的，但是您仍然可以使用 Spark 和 databrick**来利用* [*分布式计算来完成某些 ML 任务。*](https://quickbooks-engineering.intuit.com/operationalizing-scikit-learn-machine-learning-model-under-apache-spark-b009fb6b6c45)

当我们谈到分布式 ML 的主题时，我们必须仔细考虑为我们的 ML 需求选择正确的处理器(CPU、GPU、TPU)。如果您正在处理深度学习，这一点尤其重要，因为它涉及一些重型矩阵乘法。

## 缩放瓦特功能

随着时间的推移，新的预测因素浮出水面，这是合理的，这些预测因素以前被忽视或认为不重要。(例如，最近人们发现[血型可以作为你对冠状病毒](https://www.medrxiv.org/content/10.1101/2020.03.11.20031096v2)免疫水平的有用指标)。当这种情况发生时，确保这些特性的**添加不会导致模型**过度拟合，并且您也能够见证验证集的改进。

甚至更好的是，**实现正则化技术**(例如，对回归模型使用 Lasso 或 Ridge，对神经网络使用 Dropouts 和 Batch Normalization)来额外确保你的系数不会取极值，并且模型不会太复杂。

在这一点上，我也会停下来想一想，这 0.0001%的精度提升(来自这些新特性的添加)是否是我所关心的事情。这是因为在某个阶段之后，准确性并不是唯一重要的事情，知道何时停止训练你的模型也很重要。精确度的提高必须证明增加的维护和培训成本是合理的。

## 缩放实际预测值

随着您的模型变得(或预计会变得)越来越受欢迎，即预测请求的数量不断涌入，是时候考虑您的模型是否能够足够快地生成预测了。也就是说，**当心像 SVM、KNN 或 NN(神经网络)这样的缓慢模型，尤其是没有 GPU 支持的模型**。

最后，你如何在现实世界中部署你的模型，让每个人都可以使用它，这也取决于几个因素，如批量预测与实时预测，模型的可移植性，有时还有隐私——我相信一个在国防安全领域工作的数据科学家不会对在 Kaggle 上分享他的恐怖分子检测代码(以及权重矩阵)感到太兴奋。

因此，您可以选择**将您的模型集成为现有软件的一部分，创建用于部署模型的容器，或者使用像 Kubernets 这样的编排工具来帮助管理容器和集群。**

*趣闻:查看* [*这*](/deploying-h2o-models-as-apis-using-flask-42065a4fa567) *和* [*这*](/there-are-two-very-different-ways-to-deploy-ml-models-heres-both-ce2e97c7b9b1) *牛逼文章学习两种独特的模型部署方式。*

# 结论

总而言之，重点关注:

*   扩展到新数据、新功能
*   序列化和创建检查点
*   选择合适的框架和处理器
*   并行计算—分布式 ML
*   使用后端 API 进行部署，或者在网络上以硬件加速模型的形式发布

下次当你被问及与模型缩放相关的问题时，我希望你能与面试官讨论一些有趣的问题。这还不是一个详尽的列表，可能还有其他与可伸缩性相关的要点。一如既往，我很好奇你是否能想到其中的一些。

直到下次:)

*这是我最近开始的* ***面试问题*** *系列的第一部分。在* [*第二部分*](https://medium.com/@vishi2020/step-by-step-guide-to-explaining-your-ml-project-during-a-data-science-interview-81dfaaa408bf) *中，我们将讨论如何有条理地向面试官解释你的 ML 项目。敬请期待...*

[](https://medium.com/@vishi2020/step-by-step-guide-to-explaining-your-ml-project-during-a-data-science-interview-81dfaaa408bf) [## 在数据科学面试中解释你的 ML 项目的逐步指南。

### 在结尾有一个额外的样本脚本，让你谨慎地展示你的技术技能！

medium.com](https://medium.com/@vishi2020/step-by-step-guide-to-explaining-your-ml-project-during-a-data-science-interview-81dfaaa408bf)