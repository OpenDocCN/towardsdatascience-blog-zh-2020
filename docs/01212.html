<html>
<head>
<title>Feature Selection Techniques in Python: Predicting Hotel Cancellations</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中的特征选择技术:预测酒店取消</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/feature-selection-techniques-in-python-predicting-hotel-cancellations-48a77521ee4f?source=collection_archive---------20-----------------------#2020-02-03">https://towardsdatascience.com/feature-selection-techniques-in-python-predicting-hotel-cancellations-48a77521ee4f?source=collection_archive---------20-----------------------#2020-02-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1b66" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">机器学习项目最重要的特征之一(没有双关语)是特征选择。</h2></div><p id="d9e6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">特征选择允许识别对响应(或因变量)最重要或最有影响的因素。在这个例子中，特征选择技术被用于预测对客户是否选择取消他们的酒店预订最重要的影响因素。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/2b30d350d84f85565f2786811b32a519.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e9k7-WAlRQEg1G1OC1ZH6g.jpeg"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">资料来源:pixabay.com</p></figure><h1 id="7df2" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">特征选择工具</h1><p id="ca40" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">三种不同的特征选择工具用于分析该数据集:</p><ul class=""><li id="3c90" class="mr ms it kk b kl km ko kp kr mt kv mu kz mv ld mw mx my mz bi translated"><strong class="kk iu">extractreesclassifier:</strong>extractreesclassifier的目的是使多个随机决策树适合数据，在这方面，它是集成学习的一种形式。特别是，对所有观察值进行随机分割，以确保模型不会过度拟合数据。</li><li id="c9c7" class="mr ms it kk b kl na ko nb kr nc kv nd kz ne ld mw mx my mz bi translated"><strong class="kk iu">前进和后退特征选择</strong>:这是一种<strong class="kk iu">“基于包装器”</strong>的特征选择方法，其中特征选择基于特定的机器学习算法(在本例中为RandomForestClassifier)。对于前向步骤选择，每个单独的特征被一次一个地添加到模型中，并且具有最高ROC_AUC分数的特征被选择为最佳特征。当进行后向特征选择时，该过程反向进行，由此每次从模型中丢弃一个特征，即从模型中丢弃具有最低ROC_AUC分数的特征。</li></ul><h1 id="ad19" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">背景和数据处理</h1><p id="e0a2" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">使用这些算法的目的是确定最有助于预测客户是否会取消酒店预订的功能。这是因变量，其中(1 =取消，0 =继续预订)。</p><p id="2ae7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">用于分析的特征如下。</p><h2 id="c0db" class="nf lv it bd lw ng nh dn ma ni nj dp me kr nk nl mg kv nm nn mi kz no np mk nq bi translated">间隔</h2><pre class="lf lg lh li gt nr ns nt nu aw nv bi"><span id="7ddb" class="nf lv it ns b gy nw nx l ny nz">leadtime = train_df['LeadTime']<br/>arrivaldateyear = train_df['ArrivalDateYear']<br/>arrivaldateweekno = train_df['ArrivalDateWeekNumber']<br/>arrivaldatedayofmonth = train_df['ArrivalDateDayOfMonth']<br/>staysweekendnights = train_df['StaysInWeekendNights']<br/>staysweeknights = train_df['StaysInWeekNights']<br/>adults = train_df['Adults']<br/>children = train_df['Children']<br/>babies = train_df['Babies']<br/>isrepeatedguest = train_df['IsRepeatedGuest'] <br/>previouscancellations = train_df['PreviousCancellations']<br/>previousbookingsnotcanceled = train_df['PreviousBookingsNotCanceled']<br/>bookingchanges = train_df['BookingChanges']<br/>agent = train_df['Agent']<br/>company = train_df['Company']<br/>dayswaitinglist = train_df['DaysInWaitingList']<br/>adr = train_df['ADR']<br/>rcps = train_df['RequiredCarParkingSpaces']<br/>totalsqr = train_df['TotalOfSpecialRequests']</span></pre><h2 id="d466" class="nf lv it bd lw ng nh dn ma ni nj dp me kr nk nl mg kv nm nn mi kz no np mk nq bi translated">绝对的</h2><pre class="lf lg lh li gt nr ns nt nu aw nv bi"><span id="ca57" class="nf lv it ns b gy nw nx l ny nz">arrivaldatemonth = train_df.ArrivalDateMonth.astype("category").cat.codes<br/>arrivaldatemonthcat=pd.Series(arrivaldatemonth)<br/>mealcat=train_df.Meal.astype("category").cat.codes<br/>mealcat=pd.Series(mealcat)<br/>countrycat=train_df.Country.astype("category").cat.codes<br/>countrycat=pd.Series(countrycat)<br/>marketsegmentcat=train_df.MarketSegment.astype("category").cat.codes<br/>marketsegmentcat=pd.Series(marketsegmentcat)<br/>distributionchannelcat=train_df.DistributionChannel.astype("category").cat.codes<br/>distributionchannelcat=pd.Series(distributionchannelcat)<br/>reservedroomtypecat=train_df.ReservedRoomType.astype("category").cat.codes<br/>reservedroomtypecat=pd.Series(reservedroomtypecat)<br/>assignedroomtypecat=train_df.AssignedRoomType.astype("category").cat.codes<br/>assignedroomtypecat=pd.Series(assignedroomtypecat)<br/>deposittypecat=train_df.DepositType.astype("category").cat.codes<br/>deposittypecat=pd.Series(deposittypecat)<br/>customertypecat=train_df.CustomerType.astype("category").cat.codes<br/>customertypecat=pd.Series(customertypecat)<br/>reservationstatuscat=train_df.ReservationStatus.astype("category").cat.codes<br/>reservationstatuscat=pd.Series(reservationstatuscat)</span></pre><p id="818c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">关于这些特征，某些特征如提前期是<strong class="kk iu">区间</strong>——换句话说，它们可以取很大范围的值，不一定受特定范围的限制。</p><p id="b879" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但是，某些变量，如<strong class="kk iu"> customertype </strong>是分类变量。在这方面，<em class="oa">类别代码</em>用于将这些变量识别为分类变量，并确保它们在最终分析中不会被错误地排序。例如，考虑以下变量:1 =苹果，2 =香蕉，3 =橙子。这个变量是分类的，数字没有固有的等级，因此如此指定是很重要的。</p><p id="d64f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这方面，以<strong class="kk iu"> customertype </strong>为例，变量首先被转换为categorical，然后存储为pandas系列:</p><pre class="lf lg lh li gt nr ns nt nu aw nv bi"><span id="85cc" class="nf lv it ns b gy nw nx l ny nz">customertypecat=train_df.CustomerType.astype("category").cat.codes<br/>customertypecat=pd.Series(customertypecat)</span></pre><p id="66ac" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">被取消的变量是响应变量:</p><pre class="lf lg lh li gt nr ns nt nu aw nv bi"><span id="43b0" class="nf lv it ns b gy nw nx l ny nz">IsCanceled = train_df['IsCanceled']<br/>y = IsCanceled</span></pre><p id="424d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">将要素加载到Python中后，它们将存储为numpy堆栈(或数组序列):</p><pre class="lf lg lh li gt nr ns nt nu aw nv bi"><span id="42b6" class="nf lv it ns b gy nw nx l ny nz">x = np.column_stack((leadtime,arrivaldateyear,arrivaldatemonthcat,arrivaldateweekno,arrivaldatedayofmonth,staysweekendnights,staysweeknights,adults,children,babies,mealcat,countrycat,marketsegmentcat,distributionchannelcat,isrepeatedguest,previouscancellations,previousbookingsnotcanceled,reservedroomtypecat,assignedroomtypecat,bookingchanges,deposittypecat,dayswaitinglist,customertypecat,adr,rcps,totalsqr,reservationstatuscat))<br/>x = sm.add_constant(x, prepend=True)</span></pre><p id="0687" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">既然已经定义了<strong class="kk iu"> x </strong>和<strong class="kk iu"> y </strong>变量，那么使用特征选择方法来识别哪些变量对酒店取消有最大的影响。</p><p id="e8da" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">具体来说，一旦相关特征被识别，SVM(支持向量机)模型被用于分类。从上述三种技术中识别出的特征被分别输入到模型中，以确定哪种特征选择工具在识别重要特征方面做得最好——这被认为是由较高的AUC分数反映的。</p><h1 id="64d5" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">树外分级机</h1><p id="8e08" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">将生成ExtraTreesClassifier:</p><pre class="lf lg lh li gt nr ns nt nu aw nv bi"><span id="1014" class="nf lv it ns b gy nw nx l ny nz">from sklearn.ensemble import ExtraTreesClassifier<br/>model = ExtraTreesClassifier()<br/>model.fit(x, y)<br/>print(model.feature_importances_)</span></pre><p id="dc63" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">结果如下:</p><pre class="lf lg lh li gt nr ns nt nu aw nv bi"><span id="1911" class="nf lv it ns b gy nw nx l ny nz">[0.00000000e+00 2.41288705e-02 6.54290762e-03 3.56552004e-03<br/> 4.69576062e-03 3.47427522e-03 4.05667428e-03 4.86925873e-03<br/> 2.53797514e-03 2.90658184e-03 3.51521069e-04 2.81228056e-03<br/> 3.98090524e-02 1.76395497e-02 5.72618836e-03 4.67231162e-03<br/> 1.06281516e-02 1.18152913e-03 4.53164843e-03 7.05720850e-03<br/> 4.01953363e-03 4.33681743e-02 5.47423587e-04 1.24294822e-02<br/> 7.31621484e-03 2.21889104e-02 7.26745746e-03 7.51675538e-01]</span></pre><p id="1164" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们将它归类到一个数据框架中，并看看主要特性:</p><pre class="lf lg lh li gt nr ns nt nu aw nv bi"><span id="6dbc" class="nf lv it ns b gy nw nx l ny nz">ext=pd.DataFrame(model.feature_importances_,columns=["extratrees"])<br/>ext<br/>ext.sort_values(['extratrees'], ascending=True)</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/a95a6f369084aec44f8cf4ce1f51462d.png" data-original-src="https://miro.medium.com/v2/resize:fit:226/format:webp/0*QkWHVtMPOLmOKKyN.png"/></div></figure><p id="094f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最常见的特征是特征1、12、13、21、23、25(交付周期、原产国、市场细分、存款类型、客户类型和所需停车位)。请注意，功能<strong class="kk iu"> 27 </strong>(预订状态)在这种情况下无效，因为这实际上代表了与响应变量相同的东西——即客户是否取消或坚持预订。在这种情况下，在分析中包含该特征是错误的。</p><h1 id="93ca" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">向前和向后步进特征选择</h1><p id="9149" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">如前所述，这种特征选择方法基于RandomForestClassifier。就逐步向前的特征选择而言，当每个特征被添加到模型中时，对其ROC_AUC分数进行评估，即具有最高分数的特征被添加到模型中。对于后退特征选择，过程是相反的-基于具有最低ROC_AUC分数的特征从模型中删除。使用此要素选择工具从数据集中选择前六个要素。</p><p id="4326" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正向特征选择实现如下:</p><pre class="lf lg lh li gt nr ns nt nu aw nv bi"><span id="b600" class="nf lv it ns b gy nw nx l ny nz">from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier<br/>from sklearn.metrics import roc_auc_score<br/>from mlxtend.feature_selection import SequentialFeatureSelector</span><span id="d9de" class="nf lv it ns b gy oc nx l ny nz">forward_feature_selector = SequentialFeatureSelector(RandomForestClassifier(n_jobs=-1),<br/>           k_features=6,<br/>           forward=True,<br/>           verbose=2,<br/>           scoring='roc_auc',<br/>           cv=4)<br/>           <br/>fselector = forward_feature_selector.fit(x, y)</span></pre><p id="2405" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面是生成的输出:</p><pre class="lf lg lh li gt nr ns nt nu aw nv bi"><span id="0646" class="nf lv it ns b gy nw nx l ny nz">[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.<br/>[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s<br/>[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:   40.8s finished</span><span id="9bec" class="nf lv it ns b gy oc nx l ny nz">[2020-03-01 19:01:14] Features: 1/6 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.<br/>[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s remaining:    0.0s<br/>[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   37.4s finished</span><span id="8c3c" class="nf lv it ns b gy oc nx l ny nz">[2020-03-01 19:01:52] Features: 2/6 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.<br/>[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.5s remaining:    0.0s<br/>[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:   37.3s finished</span><span id="9366" class="nf lv it ns b gy oc nx l ny nz">...</span><span id="8e60" class="nf lv it ns b gy oc nx l ny nz">[2020-03-01 19:03:49] Features: 5/6 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.<br/>[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s<br/>[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:   40.7s finished</span><span id="f95b" class="nf lv it ns b gy oc nx l ny nz">[2020-03-01 19:04:30] Features: 6/6 -- score: 1.0</span></pre><p id="d963" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以按如下方式标识功能名称(在本例中是数字，因为它们存储在数组中):</p><pre class="lf lg lh li gt nr ns nt nu aw nv bi"><span id="f0b8" class="nf lv it ns b gy nw nx l ny nz">&gt;&gt;&gt; fselector.k_feature_names_<br/>('0', '1', '2', '3', '4', '27')</span></pre><p id="30b7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">后向要素选择方法计算量更大，因为会考虑数据集中的所有要素。</p><p id="f12c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们通过简单地设置<em class="oa"> forward=False </em>来实现。</p><pre class="lf lg lh li gt nr ns nt nu aw nv bi"><span id="a441" class="nf lv it ns b gy nw nx l ny nz">from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier<br/>from sklearn.metrics import roc_auc_score</span><span id="e008" class="nf lv it ns b gy oc nx l ny nz">backward_feature_selector = SequentialFeatureSelector(RandomForestClassifier(n_jobs=-1),<br/>           k_features=6,<br/>           forward=False,<br/>           verbose=2,<br/>           scoring='roc_auc',<br/>           cv=4)<br/>           <br/>bselector = backward_feature_selector.fit(x, y)</span></pre><p id="0c2b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面是生成的输出:</p><pre class="lf lg lh li gt nr ns nt nu aw nv bi"><span id="ab7e" class="nf lv it ns b gy nw nx l ny nz">[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.<br/>[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.4s remaining:    0.0s<br/>[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:  1.1min finished</span><span id="554f" class="nf lv it ns b gy oc nx l ny nz">[2020-03-01 19:05:39] Features: 27/6 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.<br/>[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.2s remaining:    0.0s<br/>[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  1.0min finished</span><span id="8287" class="nf lv it ns b gy oc nx l ny nz">...</span><span id="a3fa" class="nf lv it ns b gy oc nx l ny nz">[2020-03-01 19:17:46] Features: 7/6 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.<br/>[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.7s remaining:    0.0s<br/>[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   13.0s finished</span><span id="05c2" class="nf lv it ns b gy oc nx l ny nz">[2020-03-01 19:17:59] Features: 6/6 -- score: 1.0</span></pre><p id="80e6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是确定的特征:</p><pre class="lf lg lh li gt nr ns nt nu aw nv bi"><span id="df4c" class="nf lv it ns b gy nw nx l ny nz">&gt;&gt;&gt; bselector.k_feature_names_<br/>('0', '1', '3', '4', '5', '27')</span></pre><p id="1aec" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如我们所见，所识别的特征与前向特征选择相同。ExtraTreesClassifier还将要素1(提前期)识别为重要要素，而此方法识别要素3、4、5 (arrivaldatemonth、arrivaldateweekno、arrivaldatedayofmonth)。</p><p id="025b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这方面，此要素选择方法表明数据集中的时间要素比ExtraTreesClassifier方法建议的更重要。</p><h1 id="dd92" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">结论</h1><p id="3093" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">总而言之，我们研究了:</p><ul class=""><li id="b9f4" class="mr ms it kk b kl km ko kp kr mt kv mu kz mv ld mw mx my mz bi translated">如何分析分类和区间特征的特征数据</li><li id="bd3c" class="mr ms it kk b kl na ko nb kr nc kv nd kz ne ld mw mx my mz bi translated">使用树外分类器的特征选择</li><li id="7e28" class="mr ms it kk b kl na ko nb kr nc kv nd kz ne ld mw mx my mz bi translated">向前和向后特征选择方法</li></ul><p id="8b35" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">本例的数据集和笔记本可从MGCodesandStats GitHub库获得，以及对该主题的进一步研究。</p><p id="7095" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="oa">免责声明:本文是在“原样”的基础上编写的，没有担保。本文旨在提供数据科学概念的概述，不应以任何方式解释为专业建议。</em></p><h1 id="8920" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">有用的参考资料</h1><ul class=""><li id="23ea" class="mr ms it kk b kl mm ko mn kr oe kv of kz og ld mw mx my mz bi translated"><a class="ae od" href="https://chrisalbon.com/machine_learning/feature_selection/anova_f-value_for_feature_selection/" rel="noopener ugc nofollow" target="_blank">特征选择的方差分析F值</a></li><li id="2c85" class="mr ms it kk b kl na ko nb kr nc kv nd kz ne ld mw mx my mz bi translated"><a class="ae od" href="https://www.sciencedirect.com/science/article/pii/S2352340918315191" rel="noopener ugc nofollow" target="_blank">安东尼奥、阿尔梅迪亚和努内斯(2019)。酒店预订需求数据集</a></li><li id="a6cc" class="mr ms it kk b kl na ko nb kr nc kv nd kz ne ld mw mx my mz bi translated"><a class="ae od" rel="noopener" target="_blank" href="/feature-selection-using-wrapper-methods-in-python-f0d352b346f">使用Python中的包装方法进行特征选择</a></li><li id="29c1" class="mr ms it kk b kl na ko nb kr nc kv nd kz ne ld mw mx my mz bi translated"><a class="ae od" href="https://machinelearningmastery.com/feature-selection-with-categorical-data/" rel="noopener ugc nofollow" target="_blank">如何使用分类数据进行特征选择</a></li></ul></div></div>    
</body>
</html>