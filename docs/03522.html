<html>
<head>
<title>How to Classify Cat Pics with a Logistic Regression Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用逻辑回归模型对猫图片进行分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/classifying-cat-pics-with-a-logistic-regression-model-e35dfb9159bb?source=collection_archive---------9-----------------------#2020-04-03">https://towardsdatascience.com/classifying-cat-pics-with-a-logistic-regression-model-e35dfb9159bb?source=collection_archive---------9-----------------------#2020-04-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="30f2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">为二元分类建立两层神经网络</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6e52e6e6fb51d093a00570ce4835f35e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7K4Yrnr01gCywskPZpxwbw.jpeg"/></div></div></figure><h1 id="2304" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">1.介绍</h1><p id="2c0b" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">当我全神贯注于学期考试或家务杂事时，我会发现自己总是被猫视频所吸引。更重要的是，猫用可爱的爪子做傻事所带来的快乐超过了拖延的罪恶感。我心想，为什么不把我最大的两个兴趣——猫和机器学习——结合起来，以更好地促进技术进步。因此，用 2 层神经网络(本质上是逻辑回归模型)对猫图像进行即兴分类。</p><p id="93a8" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">本教程的重点是设计一个简单的逻辑回归算法，用神经网络的思维方式来区分猫图像和非猫图像。</p><p id="8d0b" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">这篇文章仅仅关注教程的抽象概念；要深入了解代码，请参考 Github 资源库<a class="ae mn" href="https://github.com/TheClub4/Cat_Classification" rel="noopener ugc nofollow" target="_blank">这里的</a>。该库还具有 L 层深度神经网络，其性能优于 2 层模型。</p><h1 id="9cc3" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">2.数据</h1><h2 id="d7ba" class="mo kv it bd kw mp mq dn la mr ms dp le lv mt mu lg lz mv mw li md mx my lk mz bi translated">2.1 数据汇总</h2><p id="e6a9" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">给定包含以下内容的数据集:</p><ul class=""><li id="ab43" class="na nb it lo b lp mi ls mj lv nc lz nd md ne mh nf ng nh ni bi translated">标记为猫(y=1)或非猫(y=0)的 m_train 图像的训练集。</li><li id="e0a0" class="na nb it lo b lp nj ls nk lv nl lz nm md nn mh nf ng nh ni bi translated">标记为 cat (y=1)或非 cat (y=0)的 m_test 图像的测试集。</li><li id="2668" class="na nb it lo b lp nj ls nk lv nl lz nm md nn mh nf ng nh ni bi translated">每个图像的形状为(num_px，num_px，3)，其中 3 表示 RGB 分量的 3 个通道。因此，每个图像都是(高度=数量 px)和(宽度=数量 px)的平方。</li></ul><h2 id="af64" class="mo kv it bd kw mp mq dn la mr ms dp le lv mt mu lg lz mv mw li md mx my lk mz bi translated">2.2 数据重塑</h2><p id="9e3f" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">为了方便起见，我们应该将图像的形状(num_px，num_px，3)整形为一个 numpy 数组的形状(num _ px∫num _ px∫3，1)。在这之后，我们的训练和测试数据集将被转换成一个 numpy 数组，其中每一列代表一个展平的图像。应该分别有 m_train 和 m_test 列。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/d716c332f581e867ab57a5cbbaea6b54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CSzLzsw3fC6_cE1VOuTFCA.png"/></div></div><p class="np nq gj gh gi nr ns bd b be z dk translated">图像到矢量转换</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="c143" class="mo kv it bd kw mp mq dn la mr ms dp le lv mt mu lg lz mv mw li md mx my lk mz bi translated">2.2 数据预处理</h2><p id="5331" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">为了表示彩色图像，必须为每个像素指定红色、绿色和蓝色通道(RGB );因此，每个像素值实际上是范围从 0 到 255 的三个数字的向量。</p><p id="753d" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">机器学习中一个常见的预处理步骤是对数据集进行居中和标准化，这意味着我们从每个示例中减去整个 numpy 数组的平均值，然后用整个 numpy 数组的标准偏差除以每个示例。但是，对于图片数据集，将数据集的每一行除以 255(像素通道的最大值)更简单、更方便。</p><h1 id="d8bd" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">3.学习算法的一般架构</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/c0c5b5925fe1149c2580711729c74a84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TvNwzBfbyvzHCR6gJM1Wrg.png"/></div></div><p class="np nq gj gh gi nr ns bd b be z dk translated">学习算法体系结构</p></figure><p id="48da" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">展平的输入矩阵将通过加权矩阵的参数 W[i]和偏置向量 b[i]传递。然后通过将参数传递通过 sigmoid 激活函数来预测<em class="nw"> Yhat </em>的值。从参数的值和它们对应的<em class="nw"> Yhat </em>值<em class="nw">，</em>我们可以通过计算成本函数来最小化成本；然后学习建模的参数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/7d4c27c8555ae6d1e163c08499745eb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4e340iabsOCrjz5iI8MQqQ.png"/></div></div><p class="np nq gj gh gi nr ns bd b be z dk translated">算法的数学表达</p></figure><h1 id="c10e" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">4.构建算法</h1><p id="0255" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">构建神经网络的主要步骤是:</p><ol class=""><li id="8bd1" class="na nb it lo b lp mi ls mj lv nc lz nd md ne mh ny ng nh ni bi translated">定义模型结构(如输入要素的数量)</li><li id="2769" class="na nb it lo b lp nj ls nk lv nl lz nm md nn mh ny ng nh ni bi translated">初始化模型的参数</li><li id="a959" class="na nb it lo b lp nj ls nk lv nl lz nm md nn mh ny ng nh ni bi translated">循环:</li></ol><ul class=""><li id="1a9f" class="na nb it lo b lp mi ls mj lv nc lz nd md ne mh nf ng nh ni bi translated">计算电流损耗(正向传播)</li><li id="3e27" class="na nb it lo b lp nj ls nk lv nl lz nm md nn mh nf ng nh ni bi translated">计算电流梯度(反向传播)</li><li id="a348" class="na nb it lo b lp nj ls nk lv nl lz nm md nn mh nf ng nh ni bi translated">使用梯度下降更新参数</li></ul><p id="6240" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">我们通常分别实现功能/步骤 1-3，然后将它们集成到一个我们称之为<code class="fe nz oa ob oc b">model()</code>的功能中。</p><h2 id="89d9" class="mo kv it bd kw mp mq dn la mr ms dp le lv mt mu lg lz mv mw li md mx my lk mz bi translated">4.1 助手功能</h2><p id="a8ce" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">我们将首先使用数学表达式实现 sigmoid 函数:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/52cd1615c4b9508eca4e4023c839c731.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X-e-cTxVrYbLwcqqLHh75g.png"/></div></div><p class="np nq gj gh gi nr ns bd b be z dk translated">sigmoid 函数</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="5b54" class="mo kv it bd kw mp mq dn la mr ms dp le lv mt mu lg lz mv mw li md mx my lk mz bi translated">4.2 初始化参数</h2><p id="d8e9" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">我们必须将 W 和 b 初始化为零的向量。</p><p id="f8c0" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated"><strong class="lo iu">注:</strong>常规上，在更深层次的神经网络(层数和神经元更多)中，我们通常随机初始化向量 W。这是因为第一个隐藏层中的每个神经元将执行相同的计算。因此，即使在梯度下降的多次迭代之后，该层中的每个神经元都将与其他神经元一样计算相同的东西。更多信息请参考<a class="ae mn" href="http://localhost:8888/notebooks/Documents/Cat_Classification/Cat_classification.ipynb#" rel="noopener ugc nofollow" target="_blank"> Github 库</a>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="4094" class="mo kv it bd kw mp mq dn la mr ms dp le lv mt mu lg lz mv mw li md mx my lk mz bi translated">4.3 向前和向后传播</h2><p id="6b1d" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">既然我们的参数已经初始化，我们可以开始学习参数的“向前”和“向后”传播步骤。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/a30b035bff07740ff0e85bbc5edb7855.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CFrxwwg6yRWlpzUsoQNhLQ.png"/></div></div></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="9e62" class="mo kv it bd kw mp mq dn la mr ms dp le lv mt mu lg lz mv mw li md mx my lk mz bi translated">4.4 优化</h2><p id="e343" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">既然我们已经初始化了参数并计算了成本函数及其梯度，我们将继续使用梯度下降来更新参数。</p><p id="b36d" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">目标是通过最小化代价函数<em class="nw">j</em>来学习参数<em class="nw"> w </em>和<em class="nw"> b </em>对于一个参数θ，更新规则为<code class="fe nz oa ob oc b"><strong class="lo iu">θ = θ − αdθ</strong></code>，其中α为学习率。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="824c" class="mo kv it bd kw mp mq dn la mr ms dp le lv mt mu lg lz mv mw li md mx my lk mz bi translated"><strong class="ak"> 4.5 预测<em class="of">Yhat</em>T23】</strong></h2><p id="a20e" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">前一个函数将输出学习到的<em class="nw"> w </em>和<em class="nw">b；</em>因此<em class="nw">，w </em> e 能够使用<em class="nw"> w </em>和<em class="nw"> b </em>通过实现<code class="fe nz oa ob oc b">predict()</code>函数来预测数据集 X 的标签。计算预测有两个步骤:</p><ol class=""><li id="de72" class="na nb it lo b lp mi ls mj lv nc lz nd md ne mh ny ng nh ni bi translated">计算ŷ= a =σ(w . t * x+b)</li><li id="0c5a" class="na nb it lo b lp nj ls nk lv nl lz nm md nn mh ny ng nh ni bi translated">将<em class="nw"> a </em>的条目转换为 0(如果激活&lt; = 0.5)或 1(如果激活&gt;0.5)；将预测存储在矢量<code class="fe nz oa ob oc b">Y_prediction</code>中。</li></ol><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="da09" class="mo kv it bd kw mp mq dn la mr ms dp le lv mt mu lg lz mv mw li md mx my lk mz bi translated">4.6 关键要点</h2><p id="cba5" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">上面实现的功能:</p><ul class=""><li id="c666" class="na nb it lo b lp mi ls mj lv nc lz nd md ne mh nf ng nh ni bi translated">初始化(<em class="nw"> w </em>，<em class="nw"> b </em>)。</li><li id="385d" class="na nb it lo b lp nj ls nk lv nl lz nm md nn mh nf ng nh ni bi translated">迭代优化损失学习参数(<em class="nw"> w </em>，<em class="nw"> b </em>)。</li><li id="75f2" class="na nb it lo b lp nj ls nk lv nl lz nm md nn mh nf ng nh ni bi translated">计算成本及其梯度。</li><li id="b036" class="na nb it lo b lp nj ls nk lv nl lz nm md nn mh nf ng nh ni bi translated">使用梯度下降更新参数。</li><li id="c624" class="na nb it lo b lp nj ls nk lv nl lz nm md nn mh nf ng nh ni bi translated">使用所学的(<em class="nw"> w </em>，<em class="nw"> b </em>)来预测一组给定示例的标签。</li></ul><h1 id="7d90" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">5.建模</h1><p id="6d31" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">现在，我们将按照正确的顺序把所有的构建模块(在前面的部分中实现的功能)放在一起，看看整个模型是如何构建的。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/90a97f1262201da3f9d90431d8fff60a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GfYQMTjhQSFxUC8AfASt1g.png"/></div></div><p class="np nq gj gh gi nr ns bd b be z dk translated">培训和测试准确性</p></figure><p id="36b1" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">训练准确率接近 100%。这是一个很好的健全性检查:我们的模型是有效的，并且有足够高的容量来适应训练数据。另一方面，测试准确率为 70%。考虑到我们使用的小数据集以及逻辑回归是一个线性分类器，对于这个简单的模型来说，这实际上并不坏。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/64853bb94bc07fa3c2403d11463c3a83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lN6uu_MPzQJvx95kk2B5ng.png"/></div></div><p class="np nq gj gh gi nr ns bd b be z dk translated">成本函数和梯度</p></figure><p id="863d" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated"><strong class="lo iu">解读</strong>:可以看到成本在下降。这表明正在学习参数。但是，您会发现您可以在训练集上对模型进行更多的训练。尝试增加上面单元格中的迭代次数，然后重新运行这些单元格。您可能会看到，训练集的准确性提高了，但测试集的准确性却降低了。这叫做过度拟合。</p><h1 id="13c0" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">6.进一步分析</h1><h2 id="e84e" class="mo kv it bd kw mp mq dn la mr ms dp le lv mt mu lg lz mv mw li md mx my lk mz bi translated">6.1 学习率的选择</h2><p id="373a" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">为了让<em class="nw">梯度下降</em>起作用，你必须明智地选择学习率。学习率<em class="nw"> α </em>决定了我们更新参数的速度。如果学习率过大，我们可能会“超调”最优值。类似地，如果它太小，我们将需要大量的迭代来收敛到最佳值。这就是为什么使用一个合理的学习率是至关重要的。</p><p id="a700" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">让我们比较一下我们模型的学习曲线和几种学习率的选择。也可以尝试不同于我们已经初始化的三个变量的值，看看会发生什么。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/9a99ef8d3dfeddd3a46d176b535bd4ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3D3hJzwgy_6ay66LA7mKzA.png"/></div></div></figure><p id="dc37" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated"><strong class="lo iu">解读</strong>:</p><ul class=""><li id="f289" class="na nb it lo b lp mi ls mj lv nc lz nd md ne mh nf ng nh ni bi translated">不同的学习率给出不同的成本，从而得到不同的预测结果。</li><li id="5cc0" class="na nb it lo b lp nj ls nk lv nl lz nm md nn mh nf ng nh ni bi translated">如果学习率过大(0.01)，成本可能会上下振荡。它甚至可能会发散(尽管在这个例子中，使用 0.01 最终仍然是物有所值的)。</li><li id="35ee" class="na nb it lo b lp nj ls nk lv nl lz nm md nn mh nf ng nh ni bi translated">更低的成本并不意味着更好的模式。你必须检查是否有可能过度拟合；当训练精度大大高于测试精度时，就会发生这种情况。</li></ul><p id="2de0" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">在深度学习中，通常建议您选择最能最小化成本函数的学习速率。如果您的模型过度拟合，使用其他技术来减少过度拟合，例如超参数调整。</p><h2 id="0fbb" class="mo kv it bd kw mp mq dn la mr ms dp le lv mt mu lg lz mv mw li md mx my lk mz bi translated">6.2 结果分析</h2><p id="41c6" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">让我们来看一些模型标注错误的图片。这将显示一些标签错误的图像。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/df8967a0d525f3894c45cfc9e3d66f0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BdIbUw7iHowUw4KWC8wgYQ.png"/></div></div><p class="np nq gj gh gi nr ns bd b be z dk translated">标签错误的图像</p></figure><p id="3987" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated"><strong class="lo iu">模型表现不佳的几种图像类型包括:</strong></p><ul class=""><li id="ed59" class="na nb it lo b lp mi ls mj lv nc lz nd md ne mh nf ng nh ni bi translated">猫的身体在一个不寻常的位置</li><li id="5e11" class="na nb it lo b lp nj ls nk lv nl lz nm md nn mh nf ng nh ni bi translated">猫出现在相似颜色的背景下</li><li id="1281" class="na nb it lo b lp nj ls nk lv nl lz nm md nn mh nf ng nh ni bi translated">不寻常的猫的颜色和种类</li><li id="e404" class="na nb it lo b lp nj ls nk lv nl lz nm md nn mh nf ng nh ni bi translated">照像镜头视角</li><li id="5795" class="na nb it lo b lp nj ls nk lv nl lz nm md nn mh nf ng nh ni bi translated">图片的亮度</li><li id="955d" class="na nb it lo b lp nj ls nk lv nl lz nm md nn mh nf ng nh ni bi translated">比例变化(猫在图像中很大或很小)</li></ul><h1 id="8392" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">7.使用 Github 存储库中您自己的图像进行测试！</h1><p id="472f" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">这是我在 Unsplash 上找到的一个样本小猫图片，我决定在模型上测试它:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/2160c6aeb20446d448ca73e9592ea542.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YBqHrzOhqpwtXK6pc98FhA.png"/></div></div><p class="np nq gj gh gi nr ns bd b be z dk translated">来自<a class="ae mn" href="https://unsplash.com/photos/bmGy-eqrl1k" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="3d30" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">猜猜模型输出是什么:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/e23f17708ff3d776fc84de418dfb357c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gCYylHpW-86N_bi2fnJPNw.png"/></div></div><p class="np nq gj gh gi nr ns bd b be z dk translated">输出</p></figure><p id="2c9b" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">万岁！虽然这是从一个简单的逻辑回归模型中推导出来的，但它仍然是值得的——猫总是赢家。前往 Github 知识库，深入了解如何使用两层神经网络和一层深度神经网络对猫图像进行分类。</p><h1 id="9f1a" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">参考</h1><p id="32d2" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">特别感谢<a class="ae mn" href="https://www.deeplearning.ai" rel="noopener ugc nofollow" target="_blank"> <strong class="lo iu"> deeplearning.ai </strong> </a>！</p><p id="f97c" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">[1]用于 2 层和 L 层深度神经网络分类的 Github 知识库:<a class="ae mn" href="https://github.com/TheClub4/Cat_Classification" rel="noopener ugc nofollow" target="_blank">https://github.com/TheClub4/Cat_Classification</a></p><p id="f4ed" class="pw-post-body-paragraph lm ln it lo b lp mi ju lr ls mj jx lu lv mk lx ly lz ml mb mc md mm mf mg mh im bi translated">[2]对于自动重新加载外部模块:<a class="ae mn" href="http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython" rel="noopener ugc nofollow" target="_blank">http://stack overflow . com/questions/1907993/auto reload-of-modules-in-ipython</a></p></div></div>    
</body>
</html>