<html>
<head>
<title>LeNet for Image Classification using GluonCV</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于GluonCV的图像分类网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/lenet-for-image-classification-using-gluoncv-829ae7ec4715?source=collection_archive---------61-----------------------#2020-06-17">https://towardsdatascience.com/lenet-for-image-classification-using-gluoncv-829ae7ec4715?source=collection_archive---------61-----------------------#2020-06-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="92de" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用gluoncv的不同组件，如autograded、trainer、dataset和dataloader来训练用于图像分类的<a class="ae ki" href="http://yann.lecun.com/exdb/lenet/" rel="noopener ugc nofollow" target="_blank"> LeNet网络</a>。</h2></div><p id="d4fa" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">在<a class="ae ki" rel="noopener" target="_blank" href="/image-classification-using-gluoncv-f6ae5401d6ae">之前的文章</a>中，我们讨论了在预训练的网络上使用GluonCV进行图像分类。在本文中，我们将讨论如何通过训练<a class="ae ki" href="http://yann.lecun.com/exdb/lenet/" rel="noopener ugc nofollow" target="_blank"> LeNet </a>来实现二进制图像分类器，通过将gluoncv的不同组件(如自动签名、训练器、数据集和数据加载器)集合在一起来训练LeNet网络。我们可以通过编写一个训练循环来完成这个任务。</p><ol class=""><li id="6ab4" class="lf lg it kl b km kn kp kq ks lh kw li la lj le lk ll lm ln bi translated"><strong class="kl iu">导入库</strong></li></ol><p id="3158" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">我们首先导入库。我们初始化<strong class="kl iu"> <em class="lo"> mxnet.init </em> </strong>用于更多的参数初始化方法，<strong class="kl iu"> <em class="lo"> matplotlib </em> </strong>用于绘图，<strong class="kl iu"> <em class="lo"> time </em> </strong>用于基准测试以及其他胶子包。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="1960" class="ly lz it lu b gy ma mb l mc md">from mxnet import nd, gluon, init, autograd, metric<br/>from mxnet.gluon import nn<br/>from mxnet.gluon.data.vision import datasets, transforms<br/><br/>import matplotlib.pyplot as plt<br/>from time import time</span></pre><p id="728a" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> 2。数据</strong></p><p id="2182" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">我们将使用<strong class="kl iu"> <em class="lo">时尚m-nest </em> </strong>数据集进行训练。</p><p id="74be" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> 2.1负载数据:</strong></p><p id="eaf2" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">时尚m-nest数据集通过<strong class="kl iu"><em class="lo">gluonsdata . vision . datasets</em></strong>模块自动下载。可以使用以下代码下载数据集。它还显示了第一个示例的属性。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="ab76" class="ly lz it lu b gy ma mb l mc md">mnist_train = datasets.FashionMNIST(train=True)<br/>x, y = mnist_train[0]<br/><br/>print('X shape: %s dtype : %s' % (x.shape, x.dtype))<br/>print('Number of images: %d'%len(mnist_train))</span></pre><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi me"><img src="../Images/d5479b27339910c37c481a13bc21a362.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qmFZdCd5PqlmKwGNL0n_7g.png"/></div></div></figure><p id="4d96" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">该数据集中的每个示例都是一幅28×28边的灰度图像，以形状格式为<strong class="kl iu"> <em class="lo">高X宽X通道</em> </strong>的NDRA呈现。标签是一个标量。</p><p id="c3b9" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> 2.2可视化数据</strong></p><p id="89c0" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">为了理解这些数据，我们可以将最初的几幅图像可视化。我们可以看到它们是诸如套头衫、短靴、衬衫、t恤、连衣裙和外套等服装项目的低保真度图像。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="1ca1" class="ly lz it lu b gy ma mb l mc md">fig, axes = plt.subplots(1,6, figsize=(20, 4))<br/>fig.suptitle("Fashing MNET Training Example", fontsize=20)<br/>for idx in range(6):<br/>    axes[idx].imshow(mnist_train[idx][0][:,:,0].asnumpy())<br/>    axes[idx].set_title('Class {}'.format(mnist_train[idx][1]))</span></pre><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi mm"><img src="../Images/ffed9384a75c49b991e31e1721149d41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bVeyhLslEAEOG0e-10og2w.png"/></div></div></figure><p id="c66a" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> 2.3转换数据</strong></p><p id="9908" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">每张图像都需要转换成<strong class="kl iu"> <em class="lo">通道X高度X宽度</em> </strong>、带浮点数据类型的张量格式，这可以通过<strong class="kl iu"><em class="lo">transforms . totenser</em></strong>来完成，以便将数据馈入胶子网络。此外，我们可以使用平均值为0.13、标准差为0.31的归一化变换来归一化所有像素值。我们使用由<strong class="kl iu"> <em class="lo">合成</em> </strong>的转换将这两个转换链接在一起，并将其应用于数据对的第一个元素，即图像。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="fdb6" class="ly lz it lu b gy ma mb l mc md">transformer = transforms.Compose([transforms.ToTensor(), transforms.Normalize(0.13, 0.31)])<br/><br/>mnist_train = mnist_train.transform_first(transformer)</span></pre><p id="6a28" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> 2.4数据加载</strong></p><p id="20b8" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> <em class="lo">时尚m-nest </em> </strong>是<strong class="kl iu"><em class="lo">glon . data . dataset</em></strong>的子类。为了在训练中使用它，我们需要通过网络输入随机批次的例子，这可以很容易地通过胶子数据加载器完成。对于复杂的数据转换，我们将使用256的批处理大小和四个工作线程来并行处理数据。返回的训练数据是一个迭代器，它产生成批的图像和标签对。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="3c00" class="ly lz it lu b gy ma mb l mc md">batch_size = 256<br/>train_data = gluon.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4)<br/><br/>for data, label in train_data:<br/>    print(data.shape, label.shape)<br/>    break</span></pre><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi me"><img src="../Images/bbce268953a88ec89927154d5c23187d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jZXjctCPMtViNfaZjJKRig.png"/></div></div></figure><p id="7349" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> 3。型号</strong></p><p id="89e1" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">我们实现了<a class="ae ki" href="http://yann.lecun.com/exdb/lenet/" rel="noopener ugc nofollow" target="_blank"> LeNet网络</a>；Yann LeCun等人在1998年提出的一种卷积神经网络结构。</p><p id="bf93" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> 3.1 LeNet </strong></p><p id="1e1d" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">LeNet指的是lenet-5，是一个简单的卷积神经网络。</p><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi mn"><img src="../Images/882e85280f5f9027bb41a08d88b91d68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8Ut7fQHswfO2zZngh6BYfg.png"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">LeNet-5架构(卷积神经网络)<a class="ae ki" href="https://www.pyimagesearch.com/2016/08/01/lenet-convolutional-neural-network-in-python/" rel="noopener ugc nofollow" target="_blank">图片来源</a></p></figure><p id="db00" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">LeNet5模型包括两个卷积，然后是MaxPooling块，接着是一系列密集层，卷积层的“relu”激活，以及除最后一个密集层之外的所有密集层。但是，对于深度卷积神经网络，我们将权重初始化方法改为<strong class="kl iu"> <em class="lo"> Xavier </em> </strong>。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="105a" class="ly lz it lu b gy ma mb l mc md">LeNet5 = nn.Sequential()<br/>with LeNet5.name_scope():<br/>    LeNet5.add(<br/>            nn.Conv2D(channels=6, kernel_size=5, activation='relu'),<br/>            nn.MaxPool2D(pool_size=2, strides=2),<br/>            nn.Conv2D(channels=16, kernel_size=3, activation='relu'),<br/>            nn.MaxPool2D(pool_size=2, strides=2),<br/>            nn.Flatten(),<br/>            nn.Dense(120, activation='relu'),<br/>            nn.Dense(84, activation='relu'),<br/>            nn.Dense(10)<br/>    )<br/>LeNet5.initialize(init=init.Xavier())</span></pre><p id="ab54" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> 3.2损失函数</strong></p><p id="f94c" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">除了神经网络之外，我们需要定义在训练期间最小化的损失函数。我们将使用标准的softmax交叉熵来解决分类问题。它首先对输出执行softmax以获得预测的概率，然后将标签与交叉熵进行比较。当真实类别被分配低概率时，交叉熵将会很高。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="09a3" class="ly lz it lu b gy ma mb l mc md">softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()</span></pre><p id="0984" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> 3.3公制(精度)</strong></p><p id="584a" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">我们还需要定义一个准确性指标来衡量网络的性能。为了计算准确性，我们只需要将我们的模型输出或预测与地面真实标签进行比较，并计算输出与标签匹配的部分。Mxnet有一个预定义的度量库，我们可以只使用那里定义的精度类。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="9399" class="ly lz it lu b gy ma mb l mc md">train_acc = metric.Accuracy()</span></pre><p id="7560" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> 4。培训师/优化</strong></p><p id="7017" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">我们还需要定义在训练期间更新模型参数的胶子训练器。我们挑选的优化方法是标准的随机梯度下降法，学习率为0.1。使用网络中的所有参数创建训练器。稍后，我们只需要调用训练器的step方法来更新网络宽度。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="9aee" class="ly lz it lu b gy ma mb l mc md">trainer = gluon.Trainer(LeNet5.collect_params(), 'sgd',{'learning_rate':0.1})</span></pre><p id="7c80" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> 4.1训练循环</strong></p><p id="8216" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">在这一步中，我们将实施完整的培训循环。</p><p id="0179" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">我们将经历10个时期的训练，这意味着我们将在整个数据集上迭代10次，对于每个时期，我们将记录训练损失、训练精度和训练速度。批次上的训练循环发生在历元循环内。</p><p id="5e93" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">我们迭代训练数据加载器，获得成批的训练数据和训练标签。使用自动记录范围，我们计算模型向前传递。首先，我们获得将数据批量馈送到网络的结果，然后我们使用网络输出和训练水平来计算损失。这些执行是在自动签名内执行的，以便记录操作，为计算梯度时的反向传递做好准备。正如我们在前面章节中看到的，这是通过对损失调用逆向函数来实现的。</p><p id="f6b8" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">最后，我们可以通过调用<strong class="kl iu"> <em class="lo"> trainer.step </em> </strong>使用计算机梯度更新网络参数。这就完成了一个批次的训练过程。</p><p id="87f2" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">在进入该时期中的下一批之前，我们记录训练损失和训练准确度，用于内务处理。在每个训练时期结束时，我们还打印该时期后的精度损失。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="556d" class="ly lz it lu b gy ma mb l mc md">for epoch in range(10):<br/>    train_loss = 0<br/>    tic = time()<br/>    for data, label in train_data:<br/>        with autograd.record():<br/>            output = LeNet5(data)<br/>            loss = softmax_cross_entropy(output, label)<br/>        loss.backward()<br/>        <br/>        trainer.step(batch_size)<br/>        <br/>        train_loss += loss.mean().asscalar()<br/>        train_acc.update(label, output)<br/>    <br/>    print("Epoch [%d] Loss:%.3f Acc:%.3f"%(epoch, train_loss/len(train_data), train_acc.get()[1]))<br/><br/>LeNet5.save_parameters("trained_LeNet5.params")</span></pre><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi me"><img src="../Images/29c3004a5bd1615518fd6936ae3cf844.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M-MYTeSna7Wv1X8bCSqJGw.png"/></div></div></figure><p id="59aa" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">如我们所见，在每个历元之后，损失在减少，并且准确度在增加，这表明训练过程正在工作，并且模型正在学习。经过10个时期后，我们能够在训练数据上达到大约91%的准确率。经过10次训练后，用安全参数法保存模型参数。这将在params文件中训练当前状态的参数。</p><p id="d4ca" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> 5。验证</strong></p><p id="7c0d" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">我们将所有参数保存到一个文件<strong class="kl iu"><em class="lo">trained _ lenet 5 . params</em></strong>。现在，让我们把它装回去。要从params文件向网络加载参数，我们可以简单地使用网络的load parameters方法或任何glue和block。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="bbf0" class="ly lz it lu b gy ma mb l mc md">LeNet5.load_parameters('trained_LeNet5.params')</span></pre><p id="6f7f" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">我们将通过运行一些预测来评估经过训练的模型。</p><p id="d9ae" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> 5.1验证数据</strong></p><p id="3eac" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">在运行预测之前，我们需要一个数据集，特别是模型尚未见过的数据集。我们可以使用时尚名人数据集的验证或测试分割来进行评估。我们可以通过将趋势关键字参数设置为false来选择它。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="c1ad" class="ly lz it lu b gy ma mb l mc md">mnist_val = datasets.FashionMNIST(train=False)</span></pre><p id="7161" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> 5.2数据转换</strong></p><p id="7f8f" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">就像我们为训练所做的数据转换一样，我们需要完全相同的转换来进行预测。数据转换由两个转换组成。</p><ol class=""><li id="6c5c" class="lf lg it kl b km kn kp kq ks lh kw li la lj le lk ll lm ln bi translated">将输入图像转换为张量</li><li id="2381" class="lf lg it kl b km ms kp mt ks mu kw mv la mw le lk ll lm ln bi translated">使用平均值和标准偏差标准化图像。</li></ol><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="7421" class="ly lz it lu b gy ma mb l mc md">transform_fn = transforms.Compose([<br/>                transforms.ToTensor(), <br/>                transforms.Normalize(0.13, 0.31)])</span></pre><p id="6387" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> 5.3预测</strong></p><p id="5027" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">例如，我们将预测验证数据集中的前六幅图像。为此，我们迭代我们想要预测的每个图像。首先，我们应用转换，并为我们的网络预期的批量大小添加一个额外的维度。接下来，我们获得每个类的网络预测，并且我们可以采用argmax来获得网络将IRS置信度分配给的类。然后我们可以开始预测，这样我们就可以将它与验证级别进行比较。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="592f" class="ly lz it lu b gy ma mb l mc md">preds = []<br/>for idx in range(6):<br/>    image, label = mnist_val[idx]<br/>    image = transform_fn(image).expand_dims(axis=0)<br/>    pred = LeNet5(image).argmax(axis=1)<br/>    preds.append(pred.astype('int32').asscalar())<br/>print(preds)</span></pre><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi mx"><img src="../Images/7c31c1db444f3e23790d5fd73979924a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cIRkpmAxdX-iERQ-Q7H9-Q.png"/></div></div></figure><p id="201c" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> 5.4可视化结果</strong></p><p id="2f4a" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">我们可以将我们预测的图像和顶部的地面实况标签与底部的网络预测进行比较。下面的代码片段做到了。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="be4b" class="ly lz it lu b gy ma mb l mc md">fig, axes = plt.subplots(1,6, figsize=(20, 4))<br/>fig.suptitle("Predicted vs True Class on Validation Data", fontsize=20)<br/>for idx in range(6):<br/>    axes[idx].imshow(mnist_val[idx][0][:,:,0].asnumpy())<br/>    axes[idx].set_title('True [{}] \n Predicted [{}]'.format(mnist_val[idx][1], preds[idx]))</span></pre><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi my"><img src="../Images/23d0a6fc7a16a447bcda1cb18d1fcbb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pD9jMsaJySX6dHfY.png"/></div></div></figure><p id="fc48" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">我们看到，网络在预测商品的正确时尚类别方面做得很好，或者犯了一些错误，将类别2误认为类别6。</p><p id="7f2c" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> 5.5验证数据加载器</strong></p><p id="02ae" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">我们只是在验证数据的子集上评估了模型。为了使用整个验证数据集，我们可以创建一个验证数据负载，就像我们在培训期间所做的那样。我们说批量大小为256类似于火车数据加载器，并应用相同的转换。但是我们不必洗牌，因为我们不是在训练网络。我们还需要定义用于评估模型性能的指标。因为我们在培训中使用了准确性，所以我们将使用同样的方法进行验证。我们可以简单地使用MxN矩阵包中的精度度量类。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="8479" class="ly lz it lu b gy ma mb l mc md">batch_size = 256<br/>val_data = gluon.data.DataLoader(mnist_val.transform_first(transform_fn),   batch_size=batch_size, num_workers=4)</span><span id="6840" class="ly lz it lu b gy mz mb l mc md">val_acc = metric.Accuracy()</span></pre><p id="e801" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu"> 5.6验证循环</strong></p><p id="029b" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">现在，我们可以实现完整的验证循环。我们只需要检查验证数据加载或需求，不像在培训中我们执行多个批处理。对于每批数据和验证数据集，我们使用模型进行一批预测。然后，我们可以使用模型的输出和基本事实验证自由来计算模型的准确性。对每一批进行求和，除以批数，得到模型的平均精度。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="ef1c" class="ly lz it lu b gy ma mb l mc md">for data, label in val_data:<br/>    output = LeNet5(data)<br/>    val_acc.update(label, output)<br/>print("Validation Accuracy: %0.3f"%(val_acc.get()[1]))</span></pre><figure class="lp lq lr ls gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi na"><img src="../Images/719cca5ef422bec8eef53f440ca95d4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iBrnOWUF-NdX4oPtOijk5g.png"/></div></div></figure><p id="567e" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">对于我们训练的模型，我们可以看到90%的验证准确性非常接近91%的训练准确性。这意味着该模型很好地概括了新的例子。</p><blockquote class="nb nc nd"><p id="c4ee" class="kj kk lo kl b km kn ju ko kp kq jx kr ne kt ku kv nf kx ky kz ng lb lc ld le im bi translated">成为媒体会员<a class="ae ki" href="https://medium.com/@rmesfrmpkr/membership" rel="noopener">这里</a>支持独立写作，每月5美元，获得媒体上的所有故事。</p></blockquote></div></div>    
</body>
</html>