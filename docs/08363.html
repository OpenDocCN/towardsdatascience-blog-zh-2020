<html>
<head>
<title>Feature Importance May Be Lying To You</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">功能重要性可能在骗你</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/feature-importance-may-be-lying-to-you-3247cafa7ee7?source=collection_archive---------30-----------------------#2020-06-18">https://towardsdatascience.com/feature-importance-may-be-lying-to-you-3247cafa7ee7?source=collection_archive---------30-----------------------#2020-06-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8348" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">有一种新的替代方法更加准确</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9333173f2a2fa4de9e41ac29dbea88a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KUWGzh9ZPquvjD1s"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">paweczerwi ski 在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="27ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated"><span class="l lw lx ly bm lz ma mb mc md di">我</span>喜欢随机森林模型。它们很容易设置，不需要太多的力量来训练，并且很容易理解。这也是我在生产中使用的第一批模型之一。</p><p id="ef3b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随机森林是一个可解释的模型，这意味着你可以看到它在幕后做什么。在做一些类似<strong class="lb iu"> </strong>的事情时，可解释性是非常有价值的，预测哪些客户将取消<strong class="lb iu"> </strong>，因为<strong class="lb iu"> </strong>不只是知道哪个<em class="me"> </em>客户将取消，你还可以知道为什么。</p><blockquote class="mf"><p id="36fc" class="mg mh it bd mi mj mk ml mm mn mo lu dk translated">您可能不知道的是，功能重要性的计算完全独立于模型训练。</p></blockquote><h1 id="1896" class="mp mq it bd mr ms mt mu mv mw mx my mz jz na ka nb kc nc kd nd kf ne kg nf ng bi translated">了解随机森林</h1><p id="92b5" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">有两种流行的方法来理解“为什么”，第一种是可视化整个决策树，这有助于你从头到尾看到整个过程，并逐步通过重要的领域。可能会让人不知所措，但是很强大。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/ccef837b8aff4cd40451ca9d00fdeb0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h991p_i4AvlFXJcoi6_iSg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在免费的 IBM telco 数据集上训练的流失模型的整体树形图的一个小片段</p></figure><p id="bbe8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一种方法是可视化要素重要性，它告诉我们模型预测最依赖的数据。这就好理解多了！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/92f1f4ebddb7c4bd2777f09ebae3647a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*rDVZtUCT8wk0Tqfo57CVLQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">相同流失模型的特征重要性分数</p></figure><h1 id="cc6c" class="mp mq it bd mr ms mt mu mv mw mx my mz jz no ka nb kc np kd nd kf nq kg nf ng bi translated">功能重要性的工作原理</h1><p id="81a9" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">您可能不知道的是，功能重要性的计算完全独立于模型训练。这是模型已经做的最好的猜测。</p><p id="5815" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有多种特征重要性算法，但我将重点关注 scikit-learn 中使用的一种算法，称为“杂质平均减少”</p><p id="332d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该算法测量该功能在创建决策树时减少不确定性或方差的有效性。就像我说的，最好的猜测。</p><p id="f92a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它因其速度而被选中，但不幸的是，它并不总是准确的。</p><blockquote class="mf"><p id="dcb4" class="mg mh it bd mi mj mk ml mm mn mo lu dk translated">这不是实现中的错误，而是对许多数据集来说不合适的算法选择— <a class="ae ky" href="https://explained.ai/rf-importance/" rel="noopener ugc nofollow" target="_blank">解释. ai </a></p></blockquote><p id="4d1c" class="pw-post-body-paragraph kz la it lb b lc nr ju le lf ns jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">证明算法有多不准确的最好方法是在训练中插入完全随机的数据。</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="bbed" class="ob mq it nx b gy oc od l oe of">import numpy as np</span><span id="7839" class="ob mq it nx b gy og od l oe of"># For example, if you have a pandas DataFrame you can do this:<br/>df['random'] = np.random.random(len(df))<br/># len(df) ensures it adds a random value for each row of your data</span></pre><p id="f433" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些数据不会影响您的模型，但是，要素重要性算法似乎认为它会影响您的模型:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/ddcd3cb900f55e1764d58da227ead064.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*tcVv8vwh2TelP9WmWLoyQg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">上述相同的流失模型将随机因素排在第五位</p></figure><p id="8309" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是一个主要问题。如果随机数据是错的，还有哪些数据是错误的？</p><h1 id="8092" class="mp mq it bd mr ms mt mu mv mw mx my mz jz no ka nb kc np kd nd kf nq kg nf ng bi translated">你应该用什么</h1><p id="a470" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">谢天谢地，比我聪明的人已经想出了一个更好的方法来确定特征的重要性。有两种算法，你应该两种都用。</p><h2 id="b776" class="ob mq it bd mr oi oj dn mv ok ol dp mz li om on nb lm oo op nd lq oq or nf os bi translated">排列重要性</h2><blockquote class="ot ou ov"><p id="ac37" class="kz la me lb b lc ld ju le lf lg jx lh ow lj lk ll ox ln lo lp oy lr ls lt lu im bi translated">“该功能的重要性在于基线和因置换色谱柱而导致的整体准确度下降之间的差异。”— <a class="ae ky" href="https://explained.ai/rf-importance/#4" rel="noopener ugc nofollow" target="_blank">来源</a></p></blockquote><p id="6b38" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">简而言之，该方法更改列中的数据，然后测试这对模型准确性的影响程度。如果更改一列中的数据会降低准确性，则该列被认为是重要的。</p><p id="5575" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您已经可以看到这将如何避免我们在默认算法中看到的随机数据问题。排列的重要性是巨大的，但它不应该单独使用。</p><p id="46fe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种算法的问题在于，当要素仅仅因为与其他高等级的要素相关而具有高等级时。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/f2fed99acafea2cdcaf8728f76f36326.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*NNlGV4cpeiD61peXGpF75w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">同样的模型，这是排列重要性的样子。看到兰登这次的结局了吗？</p></figure><h2 id="9933" class="ob mq it bd mr oi oj dn mv ok ol dp mz li om on nb lm oo op nd lq oq or nf os bi translated">下降列重要性</h2><p id="ad0f" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">Drop-column Importance 听起来确实如此。您从数据集中完全删除一列，重新训练模型，并查看它对准确性的影响。</p><p id="c579" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如你所想，这可能会很贵。您可以通过使用训练数据的子集来降低成本，但这仍然很慢。如果理解真正的特性重要性对你的分析有价值，我仍然强烈推荐它。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/a1aa1859f46a25c52abd8d0058780456.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*7NmFw0d2CCCFROmiWKBCAQ.png"/></div></figure><p id="795c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这个图表中，随机排序很差，但没有你想象的那么差。这就是为什么将这些方法结合起来并关注在这两种方法中排名都很好的列是很重要的。</p><p id="b388" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在你知道它们是什么了，让我们看看使用这些算法的两种常见方法。</p><h1 id="cbf4" class="mp mq it bd mr ms mt mu mv mw mx my mz jz no ka nb kc np kd nd kf nq kg nf ng bi translated">方法 1:使用 Scikit-Learn</h1><p id="3d19" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">如果你正在使用 scikit-learn，那么我有一些好消息，在 2019 年 7 月，他们给它添加了排列重要性！首先，检查你正在使用的 scikit-learn 的版本。</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="4512" class="ob mq it nx b gy oc od l oe of">import sklearn</span><span id="948e" class="ob mq it nx b gy og od l oe of">print(sklearn.__version__) # This works on any package</span></pre><p id="912b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您使用的是早于 0.22 的版本，那么您需要更新到至少 0.22 才能利用该功能。您可以使用以下命令进行升级:</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="1cd0" class="ob mq it nx b gy oc od l oe of">pip install --upgrade scikit-learn</span></pre><p id="ca82" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里有一个简单的例子，说明如何将您的模型传递到新的<code class="fe pa pb pc nx b">permutation_importance</code>函数中，并打印出结果。</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="122e" class="ob mq it nx b gy oc od l oe of">from sklearn.linear_model import LogisticRegression<br/><strong class="nx iu">from sklearn.inspection import permutation_importance</strong></span><span id="8eba" class="ob mq it nx b gy og od l oe of">X = [[1, 9, 9],[1, 9, 9],[1, 9, 9],<br/>     [0, 9, 9],[0, 9, 9],[0, 9, 9]]<br/>y = [1, 1, 1, 0, 0, 0]</span><span id="6f46" class="ob mq it nx b gy og od l oe of"># Train a basic logit model on this simple data,<br/># replace this with your model<br/>clf = LogisticRegression().fit(X, y)</span><span id="30fc" class="ob mq it nx b gy og od l oe of"><strong class="nx iu"># Here's how you use permutation importance</strong><br/><strong class="nx iu">result = permutation_importance(clf, X, y, n_repeats=10,<br/>                                random_state=0)<br/>print('Permutation importance scores', result.importances)</strong></span></pre><p id="de5f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个例子是从<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html#sklearn.inspection.permutation_importance" rel="noopener ugc nofollow" target="_blank">文档修改而来的</a>，值得一读。</p><p id="d4d7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">删除列的重要性可以简单地通过删除每个列并重新训练来实现，如果您已经训练过一个模型，您就已经知道如何做了。</p><p id="e14d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，我的 TDS 作者同事<a class="ae ky" href="https://towardsdatascience.com/@eryk.lewinson" rel="noopener" target="_blank"> Eryk Lewinson </a>写了一些漂亮的代码来帮助你在 scikit 中实现这一点——学习，以下是他的要点:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pd pe l"/></div></figure><p id="bd47" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">他写了<a class="ae ky" rel="noopener" target="_blank" href="/explaining-feature-importance-by-example-of-a-random-forest-d9166011959e">一篇关于功能重要性</a>许多方面的精彩文章，如果你想深入了解，我强烈推荐你读一读。</p><h1 id="52fa" class="mp mq it bd mr ms mt mu mv mw mx my mz jz no ka nb kc np kd nd kf nq kg nf ng bi translated">方法 2:使用 rfpimp</h1><p id="d927" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">发现这些问题并提出这些替代方案的研究人员有一个名为<code class="fe pa pb pc nx b">rfpimp</code>的轻量级包。尽管 scikit-learn 增加了排列重要性，但我还是更喜欢它。</p><p id="718f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，你需要安装<code class="fe pa pb pc nx b">pip install rfpimp</code></p><p id="b699" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，将<code class="fe pa pb pc nx b">clf</code>更改为您的模型(与前面的示例相同),并将您的培训和测试 x/y 列传递给这个代码片段:</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="1a39" class="ob mq it nx b gy oc od l oe of"># Yes, this is bad syntax, but it's how their docs recommend usage<br/>from rfpimp import *</span><span id="5497" class="ob mq it nx b gy og od l oe of"># Calculate permutation and dropcolumn importances<br/>perm_imp = permutation_importances(clf, X_train, y_train, oob_classifier_accuracy)<br/>drop_imp = dropcol_importances(clf, X_train, y_train, X_test, y_test)</span><span id="3770" class="ob mq it nx b gy og od l oe of">print("Trained on {} rows with {} accuracy, {} oob score".format(data.shape[0], accuracy, clf.oob_score_))</span></pre><p id="e36a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您想要我上面显示的图表，下面是使用 matplotlib 将结果呈现到图表中的代码:</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="7de0" class="ob mq it nx b gy oc od l oe of"># You'll need to pip install matplotlib first<br/>import matplotlib.pyplot as plt</span><span id="d971" class="ob mq it nx b gy og od l oe of"># Create charts based on results<br/>perm_imp.sort_values(by=['Importance'], ascending=True).plot(kind='barh').set(xlabel="Permutation Importance Score")<br/>drop_imp.sort_values(by=['Importance'], ascending=True).plot(kind='barh').set(xlabel="Drop Column Importance Score")</span><span id="e8c0" class="ob mq it nx b gy og od l oe of">plt.show()</span></pre><p id="3992" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇文章的大部分内容是对特伦斯·帕尔、凯雷姆·图尔古特鲁、克里斯多夫·奇泽和杰瑞米·霍华德在<a class="ae ky" href="https://explained.ai/rf-importance/" rel="noopener ugc nofollow" target="_blank">所做的出色工作的简化。</a></p><p id="191d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">他们做了所有艰苦的工作，我写了这篇文章，因为它对我有巨大的影响，很难找到简单的解释，我知道它的时候已经太晚了。</p><p id="30d7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你在这篇文章中发现了价值，我想你也会喜欢我这篇关于熊猫常见错误的文章。</p><div class="pf pg gp gr ph pi"><a href="https://link.medium.com/tHYGFMVbo7" rel="noopener follow" target="_blank"><div class="pj ab fo"><div class="pk ab pl cl cj pm"><h2 class="bd iu gy z fp pn fr fs po fu fw is bi translated">请停止在熊猫身上做这 5 件事</h2><div class="pp l"><h3 class="bd b gy z fp pn fr fs po fu fw dk translated">作为一个在进入数据科学之前从事了十多年开发工作的人，我看到数据中有很多错误…</h3></div><div class="pq l"><p class="bd b dl z fp pn fr fs po fu fw dk translated">link.medium.com</p></div></div><div class="pr l"><div class="ps l pt pu pv pr pw ks pi"/></div></div></a></div></div></div>    
</body>
</html>