<html>
<head>
<title>Could a server with 64 cores be 100x slower than my laptop?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">64 核服务器会比我的笔记本电脑慢 100 倍吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/may-a-server-with-64-cores-be-100x-slower-than-my-laptop-e648f6e69c0e?source=collection_archive---------41-----------------------#2020-07-26">https://towardsdatascience.com/may-a-server-with-64-cores-be-100x-slower-than-my-laptop-e648f6e69c0e?source=collection_archive---------41-----------------------#2020-07-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="19c6" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">这里没有剧透；-)</h2></div><h1 id="d560" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">是</h1><p id="8f20" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">很久以前，我在 Twitter 上问是否有人能帮我解决一个令人困惑的问题。我使用的一个工具利用了<em class="lu"> scipy </em>线性代数软件包来执行计算。大部分时间都花在了运行<a class="ae lt" href="https://numpy.org/doc/stable/reference/generated/numpy.linalg.pinv.html" rel="noopener ugc nofollow" target="_blank"> <em class="lu"> pinv </em> </a>函数上，这使得计算逆矩阵。<em class="lu"> scipy.linalg </em>模块中有四个函数可以计算逆矩阵:<em class="lu"> pinv </em>、<em class="lu"> pinv2 </em>、<em class="lu"> pinvh、</em>和<em class="lu"> inv </em>。前三种使用不同的方法计算伪逆矩阵，最后一种是显式计算逆矩阵，它们产生或多或少相同的结果(一般在舍入误差范围内)。在本地笔记本电脑上的测试表明，<em class="lu"> pinv </em>是最慢的实现，<em class="lu"> pinv2 </em>次之，然后是<em class="lu"> pinvh，</em>和<em class="lu"> inv </em>最快。事实上，它比 pinv 快了 15 倍。这意味着，如果我们在工具的源代码中用<em class="lu"> inv </em>替换<em class="lu"> pinv </em>，我们的代码运行速度也会提高 15 倍！</p><p id="a9bb" class="pw-post-body-paragraph kx ky iq kz b la lv jr lc ld lw ju lf lg lx li lj lk ly lm ln lo lz lq lr ls ij bi translated"><em class="lu">旁注:如果事先不知道</em> <a class="ae lt" href="https://stackoverflow.com/questions/49357417/why-is-numpy-linalg-pinv-preferred-over-numpy-linalg-inv-for-creating-invers" rel="noopener ugc nofollow" target="_blank"> <em class="lu">逆是否存在</em> </a> <em class="lu">，不建议使用 inv。但是在我们的例子中，它几乎总是存在的，所以 inv 可以用作默认选项，我们仍然可以使用 pinv2 作为后备。</em></p><p id="0523" class="pw-post-body-paragraph kx ky iq kz b la lv jr lc ld lw ju lf lg lx li lj lk ly lm ln lo lz lq lr ls ij bi translated"><em class="lu"> Sidenote 2:如果你正在使用 numpy，那么请注意 numpy 和 scipy 在命名上有不同的约定。numpy pinv 或多或少相当于 scipy pinv2，所以不要与下面 tweet 中的命名混淆。</em></p><p id="3a62" class="pw-post-body-paragraph kx ky iq kz b la lv jr lc ld lw ju lf lg lx li lj lk ly lm ln lo lz lq lr ls ij bi translated">我们的代码花了 8 个小时在真实世界的数据集上完成。让它在 30 分钟内运行的机会太好了，不能不尝试！但是，意想不到的事情发生了。在本地，<em class="lu"> inv </em>是最快的方法<em class="lu"> </em>，但是在服务器上却非常慢！</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="ff09" class="pw-post-body-paragraph kx ky iq kz b la lv jr lc ld lw ju lf lg lx li lj lk ly lm ln lo lz lq lr ls ij bi translated">其余 3 个伪逆实现的时序符合我们的预期。但是<em class="lu"> inv </em>就是不符合预期:</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="e51c" class="pw-post-body-paragraph kx ky iq kz b la lv jr lc ld lw ju lf lg lx li lj lk ly lm ln lo lz lq lr ls ij bi translated">Twitter 的智慧给了我三个同样好的主意:</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="mf mg l"/></div></figure><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="mf mg l"/></div></figure><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="mf mg l"/></div></figure><p id="22f2" class="pw-post-body-paragraph kx ky iq kz b la lv jr lc ld lw ju lf lg lx li lj lk ly lm ln lo lz lq lr ls ij bi translated">对目标进行优化编译很重要，所以 Niko 的建议可能非常真实。阵列的<a class="ae lt" href="https://eli.thegreenplace.net/2015/memory-layout-of-multi-dimensional-arrays/" rel="noopener ugc nofollow" target="_blank">内存布局</a>也非常重要。如果你曾经使用过<em class="lu"> numba </em>来优化你的代码(我曾经使用过)，你可能已经体验过，当<em class="lu"> numpy </em>数组在内存中正确定位时，你的代码变得有多快，所以 Moritz 的建议看起来也不错。然而，Petar 的建议很奇怪。我的意思是，它不可能<em class="lu">可能是</em>，一个备受尊敬的基于 C 的 BLAS 包会以这样一种方式编写，它会在服务器上失败，<em class="lu">可能吗？</em></p><p id="80da" class="pw-post-body-paragraph kx ky iq kz b la lv jr lc ld lw ju lf lg lx li lj lk ly lm ln lo lz lq lr ls ij bi translated">我想你已经可以猜到，接下来发生了什么。</p><p id="1251" class="pw-post-body-paragraph kx ky iq kz b la lv jr lc ld lw ju lf lg lx li lj lk ly lm ln lo lz lq lr ls ij bi translated">重新编译毫无用处。记忆布局也与本案无关。结果是，<em class="lu"> inv </em>存在一些并发问题。可以指定，<a class="ae lt" href="https://github.com/xianyi/OpenBLAS#setting-the-number-of-threads-using-environment-variables" rel="noopener ugc nofollow" target="_blank">BLAS 可以使用多少个线程</a>。下面是应用于测试数据的<em class="lu"> inv </em>的执行时间，作为线程数量的函数(注意，y 轴是对数):</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/4e39a83e2c1fc9afa95cdeb074369ef8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*he0_iGDuGL6Yn7hpgCbzng.png"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">你可以看到，执行时间是如何下降的，然后<em class="mo">突然</em>在大约五个内核之后开始增长。更有趣的是，随着越来越多的内核被使用，执行时间呈指数增长。</p></figure><h2 id="c5ac" class="mp kg iq bd kh mq mr dn kl ms mt dp kp lg mu mv kr lk mw mx kt lo my mz kv na bi translated">因此，我们的解决方案是限制内核数量，让代码运行得更快</h2><p id="09cb" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">奇怪的是，并非所有的数学函数<em class="lu">和</em>都是如此！虽然<em class="lu"> inv </em>已经减速，但<em class="lu"> np.dot </em>的表现与预期一致。当提供更多内核时，<em class="lu"> np.dot </em>的执行时间变得更短，直到在 10-15 个内核左右达到饱和:</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi nb"><img src="../Images/4bea7e65509d03ddf8125c9eb299310f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zcXV4D3s-0Jub-2lEr47_Q.png"/></div></div></figure><p id="37f6" class="pw-post-body-paragraph kx ky iq kz b la lv jr lc ld lw ju lf lg lx li lj lk ly lm ln lo lz lq lr ls ij bi translated">最后，作为折衷，我们将代码中使用的内核数量限制为 6 个。在我们的代码中，第二耗时的函数<em class="lu"> np.dot </em>在使用六个内核时已经足够快了。对于<em class="lu"> scipy inv，</em>这是最佳解决方案。</p><p id="7dd9" class="pw-post-body-paragraph kx ky iq kz b la lv jr lc ld lw ju lf lg lx li lj lk ly lm ln lo lz lq lr ls ij bi translated">我们实现了 15 倍的速度提升吗？不幸的是，没有。<em class="lu"> pinv </em>实际上并没有占用所有的代码执行时间，而且还有其他部分没有受到这个变化的影响。但是我们仍然通过替换代码中的两个字符来节省<em class="lu">几个小时</em>的执行时间。要是一直这么简单就好了。</p><h1 id="c8f2" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">结论</h1><ul class=""><li id="8f18" class="ng nh iq kz b la lb ld le lg ni lk nj lo nk ls nl nm nn no bi translated">使用 profiler 测量您的代码和您正在使用的包的代码的执行时间。</li><li id="1048" class="ng nh iq kz b la np ld nq lg nr lk ns lo nt ls nl nm nn no bi translated">试着找到一行或一个函数，它至少需要 10-20%的运行时间。</li><li id="eec0" class="ng nh iq kz b la np ld nq lg nr lk ns lo nt ls nl nm nn no bi translated">如果你能加快速度。</li><li id="1d3e" class="ng nh iq kz b la np ld nq lg nr lk ns lo nt ls nl nm nn no bi translated">为不可预见的后果做准备<em class="lu">，</em>拥抱它们，并把它们作为学习新东西的机会<em class="lu">。</em></li><li id="2111" class="ng nh iq kz b la np ld nq lg nr lk ns lo nt ls nl nm nn no bi translated"><em class="lu">总是在生产环境中测试你的代码。</em></li></ul><p id="8a09" class="pw-post-body-paragraph kx ky iq kz b la lv jr lc ld lw ju lf lg lx li lj lk ly lm ln lo lz lq lr ls ij bi">— —</p><p id="fb5d" class="pw-post-body-paragraph kx ky iq kz b la lv jr lc ld lw ju lf lg lx li lj lk ly lm ln lo lz lq lr ls ij bi translated">在<a class="ae lt" href="https://twitter.com/siberianpython" rel="noopener ugc nofollow" target="_blank"><strong class="kz ir">Twitter</strong></a>(<em class="lu">siberianpython</em>)上连接以获取更多技术主题和帖子，或者在<a class="ae lt" href="https://www.linkedin.com/in/dmitrii-borisevich/" rel="noopener ugc nofollow" target="_blank"> <strong class="kz ir"> LinkedIn </strong> </a>上连接。</p></div></div>    
</body>
</html>