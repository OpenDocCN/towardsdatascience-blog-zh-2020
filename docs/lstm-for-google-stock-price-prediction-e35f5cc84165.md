# ç”¨äºè‚¡ç¥¨ä»·æ ¼é¢„æµ‹çš„ LSTM

> åŸæ–‡ï¼š<https://towardsdatascience.com/lstm-for-google-stock-price-prediction-e35f5cc84165?source=collection_archive---------5----------------------->

## ä¸ºè°·æ­Œè‚¡ä»·é¢„æµ‹åˆ›å»ºåŸºäº LSTM çš„é€’å½’ç¥ç»ç½‘ç»œçš„æŠ€æœ¯æ¼”ç»ƒ

![](img/d6e5122aded459b1068a58e7d968e63b.png)

æ¥è‡ª unsplash çš„ Img é€šè¿‡[é“¾æ¥](https://unsplash.com/photos/69ppqHiG9Xo)

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘å°†ä¸€æ­¥ä¸€æ­¥åœ°ä»‹ç»å¦‚ä½•å»ºç«‹ä¸€ä¸ªåŸºäº LSTM çš„é€’å½’ç¥ç»ç½‘ç»œ(RNN)æ¥é¢„æµ‹è°·æ­Œè‚¡ç¥¨ä»·æ ¼ã€‚å®ƒåˆ†ä¸ºå¦‚ä¸‹ 7 ä¸ªéƒ¨åˆ†ã€‚

1.  é—®é¢˜é™ˆè¿°
2.  æ•°æ®å¤„ç†
3.  æ¨¡å‹ç»“æ„
4.  æ¨¡å‹ç¼–è¯‘
5.  æ¨¡å‹æ‹Ÿåˆ
6.  æ¨¡å‹é¢„æµ‹æ³•
7.  ç»“æœå¯è§†åŒ–

è®©æˆ‘ä»¬å¼€å§‹æ—…ç¨‹å§ğŸƒâ€â™€ï¸ğŸƒâ€â™‚ï¸.

1.  **é—®é¢˜é™ˆè¿°**

æˆ‘ä»¬å¾—åˆ°äº† 2012 å¹´ 1 æœˆè‡³ 2016 å¹´ 12 æœˆçš„è°·æ­Œè‚¡ä»·ã€‚ä»»åŠ¡æ˜¯é¢„æµ‹ 2017 å¹´ 1 æœˆçš„è‚¡ä»·è¶‹åŠ¿ã€‚*æ³¨æ„ï¼Œ* ***åŸºäºå¸ƒæœ—è¿åŠ¨ï¼Œè‚¡ç¥¨ä»·æ ¼çš„æœªæ¥å˜åŒ–ç‹¬ç«‹äºè¿‡å»*ã€‚å› æ­¤ï¼Œé¢„æµ‹å‡†ç¡®çš„è‚¡ç¥¨ä»·æ ¼æ˜¯ä¸å¯èƒ½çš„ï¼Œä½†é¢„æµ‹å’Œæ•æ‰ä¸Šæ¶¨å’Œä¸‹è·Œè¶‹åŠ¿æ˜¯å¯èƒ½çš„ã€‚**

2.**æ•°æ®å¤„ç†**

2.1 å¯¼å…¥æ•°æ®

è®­ç»ƒ/æµ‹è¯•æ•°æ®ä¿å­˜åœ¨ä¸­ã€‚åˆ†åˆ«ä¸º *csv* æ–‡ä»¶ã€‚æˆ‘ä»¬å°†ç”¨ ***å¼€ç›˜*** ä»·æ ¼è¿›è¡Œé¢„æµ‹ã€‚å›¾ 1 æ˜¾ç¤ºäº†è®­ç»ƒé›†çš„ä¸€ä¸ªç‰‡æ®µåŠå…¶æ•£ç‚¹å›¾ã€‚

![](img/d9ee395216e4fe4bce99ef5821597a24.png)

å›¾ 1 è®­ç»ƒé›†åŠå…¶æ•£ç‚¹å›¾

```
train = pd.read_csv(â€˜Google_Stock_Price_Train.csvâ€™)#keras only takes numpy array
training_set = dataset_train.iloc[:, 1: 2].values
```

æ³¨æ„ *dataset_train.iloc[:ï¼Œ****1:2****]ä¸­çš„ç´¢å¼•èŒƒå›´ã€‚å€¼*ï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦ä½¿å®ƒæˆä¸º **NumPy æ•°ç»„ï¼Œ**ä¸æ˜¯å•ä¸ªå‘é‡ï¼Œä¹Ÿä¸æ˜¯ç”¨äºè®­ç»ƒçš„**æ•°æ®å¸§**ã€‚

2.2 ç‰¹å¾ç¼©æ”¾

ä¸‹ä¸€æ­¥æ˜¯åœ¨(0ï¼Œ1)ä¹‹é—´ç¼©æ”¾è‚¡ç¥¨ä»·æ ¼ï¼Œä»¥é¿å…å¯†é›†çš„è®¡ç®—ã€‚å¸¸è§çš„æ–¹æ³•æœ‰**æ ‡å‡†åŒ–**å’Œ**æ­£å¸¸åŒ–**å¦‚å›¾ 2 æ‰€ç¤ºã€‚å»ºè®®è¿›è¡Œå½’ä¸€åŒ–ï¼Œå°¤å…¶æ˜¯åœ¨è¾“å‡ºå±‚ä½¿ç”¨ *Sigmoid* å‡½æ•°å¤„ç† RNN æ—¶ã€‚

![](img/749b7f396c965dbd208e7510f2e53d7a.png)

å›¾ 2 ç‰¹å¾ç¼©æ”¾æ–¹æ³•(ä½œè€…åˆ›å»ºçš„ Img)

```
from sklearn.preprocessing import MinMaxScaler
sc = MinMaxScaler(feature_range = (0, 1))training_set_scaled = sc.fit_transform(training_set)
```

2.3 æ•°æ®ç»“æ„åˆ›å»º

> åˆ›å»º**æ»‘åŠ¨çª—å£å¾ˆé‡è¦**ï¼

éœ€è¦ä¸€ä¸ªç‰¹æ®Šçš„æ•°æ®ç»“æ„æ¥è¦†ç›– 60 ä¸ªæ—¶é—´æˆ³ï¼ŒåŸºäºæ­¤ï¼ŒRNN å°†é¢„æµ‹ç¬¬ 61 ä¸ªä»·æ ¼ã€‚è¿™é‡Œï¼ŒåŸºäºå®éªŒï¼Œè¿‡å»æ—¶é—´æˆ³çš„æ•°é‡è¢«è®¾ç½®ä¸º 60ã€‚å› æ­¤ï¼Œ *X_train* æ˜¯ä¸€ä¸ªåµŒå¥—åˆ—è¡¨ï¼Œå®ƒåŒ…å« 60 ä¸ªæ—¶é—´æˆ³ä»·æ ¼çš„åˆ—è¡¨ã€‚ *y_train* æ˜¯ç¬¬äºŒå¤©çš„è‚¡ç¥¨ä»·æ ¼åˆ—è¡¨ï¼Œå¯¹åº” *X_train* ä¸­çš„å„ä¸ªåˆ—è¡¨ã€‚å…·ä½“æ¥è¯´ï¼Œ

```
X_train = []
y_train = []
for i in range(60, len(training_set_scaled)):
    X_train.append(training_set_scaled[i-60: i, 0])
    y_train.append(training_set_scaled[i, 0])
    X_train, y_train = np.array(X_train), np.array(y_train)
```

å›¾ 3 æ˜¾ç¤ºäº† *X_train* å’Œ *y_train* çš„ç‰‡æ®µã€‚ *X_train* ä¸­æ¯ä¸€è¡Œ 60 ä¸ªä»·æ ¼ç”¨äºé¢„æµ‹ *y_train* ä¸­å¯¹åº”çš„ç¬¬äºŒå¤©è‚¡ç¥¨ä»·æ ¼ã€‚

![](img/7fcbbb1ce171dd83f034ba9dff2a1cc9.png)

å›¾ 3 *X_train* å’Œ *y_train* æ•°æ®

2.4 æ•°æ®é‡å¡‘

å¦‚ä¸Šæ‰€è¿°ï¼Œæˆ‘ä»¬ç”¨ ***å¼€ç›˜*** ä»·æ ¼è¿›è¡Œé¢„æµ‹ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬åªæœ‰ä¸€ä¸ªæŒ‡æ ‡æˆ–ç‰¹å¾ã€‚ä½†æ˜¯æˆ‘ä»¬å¯ä»¥æŒ‰ç…§åŒæ ·çš„æ•°æ®å¤„ç†æ–¹æ³•æ·»åŠ æ›´å¤šçš„æŒ‡æ ‡ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä¸ºæŒ‡æ ‡çš„**æ•°é‡æ·»åŠ ä¸€ä¸ªæ–°çš„ç»´åº¦ã€‚å…·ä½“æ¥è¯´ï¼Œ**

```
X_train = np.reshape(X_train, newshape = (X_train.shape[0], X_train.shape[1], 1))
```

*new shape*in(æ‰¹é‡å¤§å°ã€æ—¶é—´æˆ³æ•°é‡ã€æŒ‡ç¤ºå™¨æ•°é‡)ã€‚*(æ‰¹é‡å¤§å°ï¼Œæ—¶é—´æˆ³ä¸ªæ•°)æ˜¯ X_train* çš„å½¢çŠ¶ã€‚è¿™é‡Œæˆ‘ä»¬åªæœ‰ä¸€ä¸ªæŒ‡æ ‡ã€‚

å¤ªå¥½äº†ã€‚âœŒâœŒ.ï¼Œæˆ‘ä»¬æŠŠè®­ç»ƒå™¨æå‡†å¤‡å¥½äº†

3.**æ¨¡å‹æ„å»º**

**åŸºæœ¬ä¸Šï¼Œæˆ‘ä»¬æ­£åœ¨ä½¿ç”¨ LSTM** æ„å»ºä¸€ä¸ªç”¨äºè¿ç»­å€¼é¢„æµ‹çš„ç¥ç»ç½‘ç»œå›å½’å™¨ã€‚é¦–å…ˆï¼Œåˆå§‹åŒ–æ¨¡å‹ã€‚

```
regressor = Sequential()
```

ç„¶åï¼Œæ·»åŠ ç¬¬ä¸€ä¸ª LSTM å›¾å±‚ï¼Œæ¥ç€æ·»åŠ **åˆ é™¤**å›¾å±‚ã€‚

```
regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))regressor.add(Dropout(rate = 0.2))
```

æ³¨æ„å¯¹äº LSTM å±‚ï¼Œ*å•ä½*æ˜¯è¯¥å±‚ä¸­ LSTM ç¥ç»å…ƒçš„æ•°é‡ã€‚50 ä¸ªç¥ç»å…ƒå°†èµ‹äºˆæ¨¡å‹é«˜ç»´åº¦ï¼Œè¶³ä»¥æ•æ‰å‘ä¸Šå’Œå‘ä¸‹çš„è¶‹åŠ¿ã€‚ *return_sequences* ä¸ºçœŸï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦åœ¨å½“å‰å›¾å±‚ä¹‹åæ·»åŠ å¦ä¸€ä¸ª LSTM å›¾å±‚ã€‚ *input_shape* å¯¹åº”çš„æ˜¯æ—¶é—´æˆ³çš„ä¸ªæ•°å’ŒæŒ‡ç¤ºå™¨çš„ä¸ªæ•°ã€‚å¯¹äºé€€å‡ºï¼Œ50 ä¸ªç¥ç»å…ƒä¸­çš„ 20%å°†åœ¨è®­ç»ƒçš„æ¯æ¬¡è¿­ä»£ä¸­è¢«éšæœºå¿½ç•¥ã€‚

æŒ‰ç…§ä¸Šè¿°ç›¸åŒçš„æ–¹æ³•ï¼Œæ·»åŠ ç¬¬äºŒï¼Œç¬¬ä¸‰å’Œç¬¬å›› LSTM å±‚ã€‚

```
##add 2nd lstm layer
regressor.add(LSTM(units = 50, return_sequences = True))
regressor.add(Dropout(rate = 0.2))##add 3rd lstm layer
regressor.add(LSTM(units = 50, return_sequences = True))
regressor.add(Dropout(rate = 0.2))##add 4th lstm layer
regressor.add(LSTM(units = 50, return_sequences = False))
regressor.add(Dropout(rate = 0.2))
```

æ³¨æ„æœ€åä¸€ä¸ª LSTM å±‚ï¼Œ *return_sequences* æ˜¯ ***False*** ç”±äºæˆ‘ä»¬ä¸ä¼šæ·»åŠ æ›´å¤šçš„ LSTM å±‚ã€‚

æœ€åï¼Œæ·»åŠ è¾“å‡ºå±‚ã€‚è¾“å‡ºç»´åº¦æ˜¯ 1ï¼Œå› ä¸ºæˆ‘ä»¬æ¯æ¬¡é¢„æµ‹ 1 ä¸ªä»·æ ¼ã€‚

```
regressor.add(Dense(units = 1))
```

å¤ªå¥½äº†ï¼æˆ‘ä»¬å·²ç»åˆ›å»ºäº†ä¸€ä¸ªåŸºäº LSTM çš„ RNN æ¨¡å‹ğŸ§¨ğŸ§¨.

4.**æ¨¡å‹ç¼–è¯‘**

ç°åœ¨ï¼Œè®©æˆ‘ä»¬é€šè¿‡é€‰æ‹©ä¸€ä¸ª *SGD* ç®—æ³•å’Œä¸€ä¸ªæŸå¤±å‡½æ•°æ¥ç¼–è¯‘ RNNã€‚å¯¹äºä¼˜åŒ–å™¨ï¼Œæˆ‘ä»¬ä½¿ç”¨ *Adam* ï¼Œè¿™æ˜¯ä¸€ä¸ªå®‰å…¨çš„é€‰æ‹©ã€‚æŸå¤±å‡½æ•°æ˜¯å®é™…å€¼å’Œé¢„æµ‹å€¼ä¹‹é—´çš„å‡æ–¹è¯¯å·®ã€‚

```
regressor.compile(optimizer = â€˜adamâ€™, loss = â€˜mean_squared_errorâ€™)
```

5.**æ¨¡å‹æ‹Ÿåˆ**

ç°åœ¨ï¼Œè®©æˆ‘ä»¬é€‚åˆæˆ‘ä»¬çš„ RNNã€‚

```
regressor.fit(x = X_train, y = y_train, batch_size = 32, epochs = 100)
```

RNN æƒé‡æ¯ 32 ä¸ªè‚¡ç¥¨ä»·æ ¼æ›´æ–°ä¸€æ¬¡ï¼Œæ‰¹é‡ä¸º 32 ä¸ªã€‚å¦‚æœæ¨¡å‹çš„æŸå¤±æ²¡æœ‰æ”¶æ•›ï¼Œè¯·éšæ„å°è¯•æ›´å¤šçš„æ‰¹æ¬¡å’Œæ—¶æœŸã€‚

å¤ªå¥½äº†ï¼Œç°åœ¨è®©æˆ‘ä»¬å¼€å§‹è®­ç»ƒã€‚æœ€åï¼Œæˆ‘ä»¬å‘ç°ä»æŸå¤± ***0.062*** å¼€å§‹ï¼Œæˆ‘ä»¬åœ¨æ—¶æœŸ 50 å¾—åˆ°æŸå¤±***0.0026****ï¼Œåˆ°æ—¶æœŸ 100 æŸå¤±***0.0015****ğŸ‰ğŸ‰ã€‚**

**6.**æ¨¡å‹é¢„æµ‹****

**6.1 å¯¼å…¥æµ‹è¯•æ•°æ®**

**ä½¿ç”¨ç¬¬ 2.1 èŠ‚ä¸­çš„ç›¸åŒæ–¹æ³•ï¼Œè¯»å–æµ‹è¯•æ•°æ®ã€‚**

```
**dataset_test = pd.read_csv(â€˜Google_Stock_Price_Test.csvâ€™)real_stock_price = dataset_test.iloc[:, 1: 2].values**
```

**6.2 æ•°æ®å¤„ç†**

**é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦è¿æ¥ç”¨äºé¢„æµ‹çš„è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†ï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨å‰ 60 å¤©çš„è‚¡ç¥¨ä»·æ ¼æ¥é¢„æµ‹ç¬¬äºŒå¤©çš„ä»·æ ¼ã€‚æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬éœ€è¦æµ‹è¯•æ•°æ®é›†ä¸­ç¬¬ä¸€ä¸ªæ—¥æœŸä¹‹å‰ 60 å¤©çš„ä»·æ ¼ã€‚**

```
**dataset_total = pd.concat((dataset_train[â€˜Openâ€™],dataset_test[â€˜Openâ€™]), axis = 0)**
```

**ç„¶åï¼Œä¸ºé¢„æµ‹åˆ›å»ºè¾“å…¥ï¼Œä»æµ‹è¯•æ•°æ®é›†ä¸­ç¬¬ä¸€ä¸ªæ—¥æœŸä¹‹å‰ 60 å¤©çš„æ—¥æœŸå¼€å§‹ç´¢å¼•ã€‚**

```
**inputs = 
dataset_total[len(dataset_total)-len(dataset_test)- 60: ].values**
```

**ç¬¬ä¸‰ï¼Œæ”¹å˜è¾“å…¥çš„å½¢çŠ¶ï¼Œä½¿å…¶åªæœ‰ä¸€åˆ—ã€‚**

```
**inputs = inputs.reshape(-1, 1)**
```

**ç¬¬å››ï¼Œä½¿ç”¨ç”±è®­ç»ƒé›†è®¾ç½®çš„æ ‡åº¦ï¼Œå¯¹æµ‹è¯•è¾“å…¥è¿›è¡Œæ ‡åº¦ã€‚**

```
**inputs = sc.transform(inputs)**
```

**æœ€åï¼Œåˆ›å»ºæµ‹è¯•æ•°æ®ç»“æ„ï¼Œå¦‚ç¬¬ 2.3 èŠ‚æ‰€è¿°ã€‚**

```
**X_test = []
for i in range(60, len(inputs)): 
    X_test.append(inputs[i-60: i, 0])
    X_test = np.array(X_test)
    #make numpy array as 3D , adding num of indicator
    X_test = np.reshape(X_test, newshape = (X_test.shape[0],  
                        X_test.shape[1], 1))**
```

**6.3 æ¨¡å‹é¢„æµ‹**

**ç°åœ¨ï¼Œ *X_test* å‡†å¤‡å¥½é¢„æµ‹äº†ã€‚**

```
**predicted_stock_price = regressor.predict(X_test)**
```

**åˆ«å¿˜äº†ï¼Œæˆ‘ä»¬é¢„æµ‹çš„æ˜¯ç¼©æ”¾åçš„å€¼ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦åè½¬é¢„æµ‹ã€‚**

```
**predicted_stock_price = sc.inverse_transform(predicted_stock_price)**
```

**7.**ç»“æœå¯è§†åŒ–****

**åœ¨æœ€åä¸€æ­¥ä¸­ï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå¯è§†åŒ–å›¾æ¥è½»æ¾åœ°æ£€æŸ¥é¢„æµ‹ã€‚**

```
**plt.plot(real_stock_price, color = â€˜redâ€™, label = â€˜Real priceâ€™)
plt.plot(predicted_stock_price, color = â€˜blueâ€™, label = â€˜Predicted priceâ€™)
plt.title(â€˜Google price predictionâ€™)
plt.xlabel(â€˜Timeâ€™)
plt.ylabel(â€˜Priceâ€™)
plt.legend()
plt.show()**
```

**å¦‚å›¾ 4 å’Œå›¾ 5 æ‰€ç¤ºï¼Œé¢„æµ‹æ»åäºçœŸå®å€¼ï¼Œå› ä¸ºæ¨¡å‹ä¸èƒ½å¯¹éçº¿æ€§å˜åŒ–åšå‡ºå¿«é€Ÿååº”ã€‚ä½†å¦ä¸€æ–¹é¢ï¼Œæ¨¡å‹å¯¹å¹³æ»‘å˜åŒ–ååº”è‰¯å¥½ã€‚**å› æ­¤ï¼Œæˆ‘ä»¬å¾—å‡ºç»“è®ºï¼Œåœ¨åŒ…å«å³°å€¼çš„é¢„æµ‹éƒ¨åˆ†ï¼Œæ¨¡å‹æ»åäºå®é™…ä»·æ ¼ï¼Œä½†åœ¨åŒ…å«å¹³ç¨³å˜åŒ–çš„éƒ¨åˆ†ï¼Œæ¨¡å‹è®¾æ³•éµå¾ªå‘ä¸Šå’Œå‘ä¸‹çš„è¶‹åŠ¿** âœ¨âœ¨.**

**![](img/2cefd56f978d8c9035a77b9c8e5c8e39.png)**

**å›¾ 4 å®é™…ä»·æ ¼ä¸é¢„æµ‹ä»·æ ¼**

**![](img/0c9d53ab332fcf09b9f563f2b0edb61b.png)**

**å›¾ 5 å¤§æ—¶é—´å°ºåº¦ä¸Šçš„é¢„æµ‹**

****å¤ªå¥½äº†ï¼è¿™å°±æ˜¯æ‰€æœ‰çš„æ—…ç¨‹ï¼å¦‚æœéœ€è¦æºä»£ç ï¼Œè¯·è®¿é—®æˆ‘çš„**[**Github**](https://github.com/luke4u/Time_Series_Forecasting)**é¡µé¢ğŸ¤ğŸ¤ã€‚****