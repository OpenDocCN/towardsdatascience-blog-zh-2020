<html>
<head>
<title>Fine Tuning BERT for Text Classification with FARM</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">微调用于FARM文本分类的BERT</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/fine-tuning-bert-for-text-classification-with-farm-2880665065e2?source=collection_archive---------22-----------------------#2020-05-29">https://towardsdatascience.com/fine-tuning-bert-for-text-classification-with-farm-2880665065e2?source=collection_archive---------22-----------------------#2020-05-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ef2a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用最先进的NLP模型进行简单快速的迁移学习</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/4453bb7d0f6f3a4a988e77a3abe5e45a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LuMR5Y_dNuAev6FZ"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">蒂莫西·埃伯利在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="3fd2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">去年秋天，当我在硕士论文的背景下努力微调预先训练的多语言BERT模型以进行论证挖掘(检测文本中的论证结构)时，我偶然发现了由<a class="ls lt ep" href="https://medium.com/u/1cb8bc239339?source=post_page-----2880665065e2--------------------------------" rel="noopener" target="_blank"> Deepset.ai </a>开发的开源框架<a class="ae kv" href="https://github.com/deepset-ai/FARM" rel="noopener ugc nofollow" target="_blank">FARM</a>(<strong class="ky ir">F</strong>framework for<strong class="ky ir">A</strong>adapting<strong class="ky ir">R</strong>presentation<strong class="ky ir">M</strong>models】。他们不仅提供了一个德国BERT模型，而且还提供了一个易于实现的框架，具有迁移学习的广泛特征。我不能说它拯救了我的论文，但至少拯救了我的神经和头发😅。</p><p id="6a24" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇文章中，我提供了一个使用D. Greene和P. Cunningham [1]在原始BBC新闻文章数据集上的框架对新闻文章体裁进行分类的指南。准备资料的过程可以在我上一篇<a class="ae kv" rel="noopener" target="_blank" href="/how-to-split-a-dataframe-into-train-and-test-set-with-python-eaa1630ca7b3">文章</a>中找到。</p><p id="ded9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，我将简要介绍迁移学习和BERT。然后，我会给你提供指导，让你成为一个真正的农民👩‍🌾👨‍🌾。</p></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><h1 id="2f8e" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">BERT与迁移学习</h1><p id="a14a" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">一年前，Devlin、Chang、Lee和Toutanova发表了BERT(变压器的双向编码器表示法)[2]。这种创新的新模型在11个自然语言处理任务中取得了新的最先进的结果，如问题回答(SQuAD)或命名实体识别(NER)。</p><p id="7643" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">它结合了技术创新，如语言建模变压器的双向训练与各种不同任务的迁移学习能力。如果你有兴趣了解更多关于这个模型的信息，我强烈建议你阅读最初的<a class="ae kv" href="https://arxiv.org/pdf/1810.04805.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>，因为我不会更详细地描述它。</p><p id="3087" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">将从一个问题学到的知识应用到一个新的不同的问题上代表了迁移学习的思想。如果我们仔细想想，人类的学习在很大程度上是基于这种学习方式。由于迁移学习，学习Java对我来说很容易，因为当我开始学习时，我已经理解了编程概念和Python语法。</p><p id="ad1d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，为了真正成功地解决新问题，对未知任务进行专门的微调是必要的。因此，我们将在下面的章节中发现如何使用预先训练好的BERT模型，并对其进行微调，以便根据新闻文章的文本对其体裁进行分类。</p></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><h1 id="0df8" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">成为农民👩‍🌾👨‍🌾</h1><p id="0b07" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">在这个简短的主题介绍之后，让我们为这个领域做准备。</p><p id="8040" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，我们可以看看农场的可能性。该框架不仅支持使用英语的BERT进行文本分类，还支持其他几个下游任务，包括多种语言的一些最新模型。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi my"><img src="../Images/16f097562eb6562235e854b20c450f0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0RYwLSOMegTKfhnyTwkjIQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">可用模型和支持的农场任务— <a class="ae kv" href="https://github.com/deepset-ai/FARM#core-features" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="c124" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以，现在我们已经准备好去现场了。启动你首选的IDE(我会在Google Colab中描述如何使用)，深呼吸，我们走吧。</p><h2 id="f560" class="mz mc iq bd md na nb dn mh nc nd dp ml lf ne nf mn lj ng nh mp ln ni nj mr nk bi translated">设置</h2><p id="6db1" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">在Colab中键入并运行第一行之前，应该在笔记本设置(编辑&gt;笔记本设置)中选择GPU作为硬件加速器。这将大大加快训练速度。</p><p id="1ee5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了在Google Colab中使用FARM，你必须安装它。有两种不同的方法可以做到这一点:</p><p id="52d4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你想使用一个稳定的版本，那么在<a class="ae kv" href="https://github.com/deepset-ai/FARM/releases" rel="noopener ugc nofollow" target="_blank"> Github库</a>的release标签下寻找最新的版本。目前，最新的版本是0.4.3，我们正在使用以下命令安装Google Colab:</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="8b3f" class="mz mc iq nm b gy nq nr l ns nt">!pip install farm==0.4.3</span></pre><p id="14b5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您想使用他们的前沿(尚未发布)特性，那么使用下面的命令安装它。但是请注意，这种方法不一定会安装一个稳定的版本，事情可能不会像预期的那样顺利。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="1b6b" class="mz mc iq nm b gy nq nr l ns nt">!git clone https://github.com/deepset-ai/FARM.git<br/>!pip install -r FARM/requirements.txt<br/>!pip install FARM/</span></pre><p id="0613" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在将FARM安装到我们的环境中之后，我们还需要加载数据来训练我们的模型。通过克隆<a class="ae kv" href="https://github.com/guggio/bbc_news" rel="noopener ugc nofollow" target="_blank">我的GitHub库</a>，我们可以访问来自Colab的数据。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="4c96" class="mz mc iq nm b gy nq nr l ns nt">!git clone https://github.com/guggio/bbc_news</span></pre><p id="eccc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们在Colab UI中打开左侧面板，我们现在可以看到bbc_news文件夹被添加到我们的文件中。为了进行微调，我们将使用bbc_news目录下generated_data文件夹中的训练和测试数据。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/bcc71d8b2a0e76f7fea7fbfd7cc4f3e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*LOF3F99YgDRCrBp9jiyuhg.png"/></div></figure><p id="f80e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下一步，我们想要导入训练步骤所需的所有类和函数。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="2118" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们对实验更详细的分析感兴趣，我们可以在FARM的<a class="ae kv" href="https://public-mlflow.deepset.ai/#/" rel="noopener ugc nofollow" target="_blank">公共MLflow服务器</a>上跟踪培训。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="95cd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，我们几乎准备好进入真正的编码部分。但是在开始之前，让我们初始化一些我们在这个过程中需要的环境变量。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="88c3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们设置一个种子值，使运行可重复(每次运行都进行相同的洗牌)，并获取正确的设备来加速训练过程。此外，我们确定训练时期的数量、批量大小和在开发集上评估我们的模型的频率。</p></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><h2 id="b9bb" class="mz mc iq bd md na nb dn mh nc nd dp ml lf ne nf mn lj ng nh mp ln ni nj mr nk bi translated">数据处理</h2><p id="0df1" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">我记得我拼命地试图预处理我的数据以进行论证挖掘(按标记分类，类似于NER)，但最终失败了，因为BERT的单词块标记化遵循了HuggingFace的传统方法。</p><p id="fec6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">幸运的是，由于FARM的数据处理结构，FARM的预处理任务要方便得多。此外，这种基于块的结构使得该过程高度可定制。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/4d4df0df5be3231acd9fb0f35404a574.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OCTjbQUme-G4Rs_1zta4XQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">基于块的农场数据处理— <a class="ae kv" href="https://farm.deepset.ai/data_handling.html#building-blocks" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="4ace" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了将输入(文件或请求)转换成PyTorch数据集，我们使用了处理器。</p><p id="9f22" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了完成它的工作，处理器需要一个标记器，我们可以简单地根据我们想要的语言模型来加载它。因为我们正在处理包含大写和小写单词的英语文本，所以我们将使用基本的大小写BERT模型并将do_lower_case设置为false。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="f919" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">初始化标记器后，我们创建处理器来处理数据。如前所述，我们可以根据需要定制数据处理流程的模块。</p><p id="e8dd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，我们可以简单地将所需的定制作为参数输入到处理器构造器中。对于我们的文本分类任务，我们使用TextClassificationProcessor类。对于不同的任务，我们显然会切换到相应的处理器类别。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="2b38" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一旦创建了处理器，我们就可以加载数据仓库了。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><h2 id="ade8" class="mz mc iq bd md na nb dn mh nc nd dp ml lf ne nf mn lj ng nh mp ln ni nj mr nk bi translated">建模和培训</h2><p id="544e" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">上面的概述显示了该框架在适用的语言模型和支持的任务方面的通用性。这种灵活性需要一种适应性模型，该模型具有易于更换的组件，以满足相应任务和模型的要求。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/7f6dcaa6352552423666c9ba79d28f06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OhmoHAnvDJM4Ng5xj5F9qg.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">农场的适应模式— <a class="ae kv" href="https://farm.deepset.ai/modeling.html" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="398e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">自适应模型由我们想要微调的预训练语言模型和一个或多个预测头组成。预测头是放在模型上的最后一层，用于将模型的矢量表示转换为实际预测。</p><p id="cf4e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">关于自适应模型的结构已经说得够多了，让我们来定义我们的模型并初始化优化器。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="31d5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我们开始训练我们的模型之前，还需要一个步骤。我们必须把一切都反馈给训练者，训练者管理训练过程，并在开发集上以定义的频率评估模型。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="5ab9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，是按下按钮的时候了。让培训开始:</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="8ec6" class="mz mc iq nm b gy nq nr l ns nt">trainer.train()</span></pre><p id="d7cc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这将启动我们数据集的训练过程，需要3-4分钟。那么是时候收获我们播种的东西了🌽</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/0c1c2e3194866515d3a5f8695053b694.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7BbtCfk2ZetuP_5Eu1vjOg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">培训结果</p></figure><p id="a994" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在两个时代之后，该模型在测试集上表现得非常好，总体宏观平均F1分数为0.97。请注意，这些结果是在没有任何超参数调整的情况下获得的。</p><p id="24e7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了最大化我们模型的性能，我们可以使用不同的设置重新运行训练，例如不同的时期数、不同的批量大小、不同的退出率等。超参数优化的另一个选择是运行基于json配置文件的实验，我可能会在以后的文章中描述。</p><p id="3cb5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们在开始时初始化ML-logging，我们现在可以在<a class="ae kv" href="https://public-mlflow.deepset.ai/" rel="noopener ugc nofollow" target="_blank"> MLflow服务器</a>上访问我们实验的进一步信息，例如训练损失的发展。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/75d109a80be545e730061a1250f3454f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t16NuX2gyNRJX4gE5yNrWQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">培训损失</p></figure></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><h2 id="d083" class="mz mc iq bd md na nb dn mh nc nd dp ml lf ne nf mn lj ng nh mp ln ni nj mr nk bi translated">保存和运行推理</h2><p id="169b" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">在训练了我们的模型之后，我们肯定也想在不同的文本上尝试它。不幸的是，我们不能直接在训练好的模型上运行推理，因为自适应模型类不提供这样的功能。因此，我们必须保存它，以便用推理器加载它。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="340d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们也可以从Colab中提取模型，并用下面的命令下载它。转到Colab UI的左侧面板，选择zip文件并下载它。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="3e9b" class="mz mc iq nm b gy nq nr l ns nt">!zip -r saved_models/model.zip saved_models/bert-english-news-article</span></pre><p id="ff84" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了对样本文本进行推理，我们需要在字典列表中对它们进行格式化，其中“text”是键，实际的文章文本表示相应的值。</p><p id="691d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了方便推理步骤，我准备了助手函数，并在我的<a class="ae kv" href="https://github.com/guggio/bbc_news/tree/master/generated_data/inferencing" rel="noopener ugc nofollow" target="_blank">库</a>中添加了两篇文章文本。一个额外的助手从结果中选择预测并返回一个数据帧。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="6422" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们把准备好的文章分类！</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/d03bd24708724944218a72bfa315eacd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TfYsdwifmEHzYfZLyclmHw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">推理的结果</p></figure></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><h1 id="4191" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">结论</h1><p id="c7a0" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">如果你做到了这一步，你会有一个美好的收获！🌽</p><p id="413a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如本文所述，FARM迁移学习是一个简单直接的过程，提供了许多定制的可能性。因此，你可以考虑用<a class="ae kv" href="https://github.com/deepset-ai/FARM" rel="noopener ugc nofollow" target="_blank">农场</a>来解决下一个NLP问题。</p><p id="b4ce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我希望我的教程对你有帮助和价值！如果我的指南有什么不清楚的地方，请随时问我。你可以在这里查看我的源代码。</p><p id="2968" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">非常感谢你的阅读和快乐编码！</p><h1 id="086c" class="mb mc iq bd md me oc mg mh mi od mk ml jw oe jx mn jz of ka mp kc og kd mr ms bi translated">参考</h1><p id="678e" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">1d .格林和p .坎宁安。核心文档聚类中对角优势问题的实际解决方案。ICML 2006。</p><p id="9f59" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2] Devlin，j .，Chang，m-w .，Lee，k .，&amp; Toutanova，K. (2019年)。BERT:用于语言理解的深度双向转换器的预训练。谷歌人工智能语言。<a class="ae kv" href="https://arxiv.org/pdf/1810.04805.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1810.04805.pdf</a></p></div></div>    
</body>
</html>