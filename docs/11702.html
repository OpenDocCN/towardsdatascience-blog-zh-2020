<html>
<head>
<title>Dump Keras-ImageDataGenerator. Start Using TensorFlow-tf.data (Part 2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">转储 Keras-ImageDataGenerator。开始使用 TensorFlow-tf.data(第 2 部分)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/dump-keras-imagedatagenerator-start-using-tensorflow-tf-data-part-2-fba7cda81203?source=collection_archive---------39-----------------------#2020-08-13">https://towardsdatascience.com/dump-keras-imagedatagenerator-start-using-tensorflow-tf-data-part-2-fba7cda81203?source=collection_archive---------39-----------------------#2020-08-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4e23" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">停止使用 Keras-ImageDataGenerator，因为…</h2></div><p id="e4f7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">本文是第 1 部分的后续。这里，我将使用<code class="fe le lf lg lh b">mobilenet</code>模型比较<code class="fe le lf lg lh b">tf.data</code>和<code class="fe le lf lg lh b">Keras.ImageDataGenerator</code>的实际训练时间。</p><div class="li lj gp gr lk ll"><a href="https://medium.com/swlh/dump-keras-imagedatagenerator-start-using-tensorflow-tf-data-part-1-a30330bdbca9" rel="noopener follow" target="_blank"><div class="lm ab fo"><div class="ln ab lo cl cj lp"><h2 class="bd iu gy z fp lq fr fs lr fu fw is bi translated">转储 Keras-ImageDataGenerator。开始使用 TensorFlow-tf.data(第 1 部分)</h2><div class="ls l"><h3 class="bd b gy z fp lq fr fs lr fu fw dk translated">停止使用 Keras-ImageDataGenerator，因为…</h3></div><div class="lt l"><p class="bd b dl z fp lq fr fs lr fu fw dk translated">medium.com</p></div></div><div class="lu l"><div class="lv l lw lx ly lu lz ma ll"/></div></div></a></div></div><div class="ab cl mb mc hx md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="im in io ip iq"><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi mi"><img src="../Images/f1793f1b1651c0543ec499f99dfc1fb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nONpSkUCKTJDo2aF93iTSw.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">作者照片。来自<a class="ae mx" href="https://www.youtube.com/watch?v=uevE88wDWzg&amp;t=92s" rel="noopener ugc nofollow" target="_blank"> YouTube 视频</a></p></figure><p id="044b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在第 1 部分中，我展示了使用<code class="fe le lf lg lh b">tf.data</code>加载图像比使用<code class="fe le lf lg lh b">Keras.ImageDataGenerator</code>大约快 5 倍。考虑的数据集是<a class="ae mx" href="https://www.kaggle.com/chetankv/dogs-cats-images" rel="noopener ugc nofollow" target="_blank">Kaggle-dogs _ and _ cats</a><strong class="kk iu">(217 MB)</strong>，具有分布在<strong class="kk iu"> 2 个不同类中的<strong class="kk iu"> 10000 张图像</strong>。</strong></p><p id="6b7e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在第 2 部分中，我考虑了一个更大的数据集，它通常用于图像分类问题。所选择的数据集是<a class="ae mx" href="http://images.cocodataset.org/zips/train2017.zip" rel="noopener ugc nofollow" target="_blank">coco 2017</a><strong class="kk iu">(18gb)</strong>，具有分布在<strong class="kk iu"> 80 个不同类别中的<strong class="kk iu"> 117266 张图像</strong>。</strong>COCO 数据集的各种版本都可以在<a class="ae mx" href="https://cocodataset.org/#download" rel="noopener ugc nofollow" target="_blank">这个链接</a>免费试用和测试。选择更大的 18 GB 数据集的原因是为了获得更好的比较结果。对于实际的图像分类问题，数据集甚至可以更大，从 100 GB(千兆字节)到几 TB(兆兆字节)。在我们的例子中，18 GB 的数据足以理解比较，因为在 TB 中使用数据集将显著增加训练时间和计算资源。</p><h1 id="e38f" class="my mz it bd na nb nc nd ne nf ng nh ni jz nj ka nk kc nl kd nm kf nn kg no np bi translated">训练次数结果(提前)</h1><figure class="mj mk ml mm gt mn"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="2177" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以上结果是在使用 TensorFlow 2.x 的 GPU 版本的具有 16 GB RAM、2.80 GHz with Core i7 的工作站上进行比较的。考虑的数据集是<a class="ae mx" href="http://images.cocodataset.org/zips/train2017.zip" rel="noopener ugc nofollow" target="_blank">coco 2017</a><strong class="kk iu">(18 GB)</strong>，具有分布在<strong class="kk iu"> 80 个不同类中的<strong class="kk iu"> 117266 个图像</strong>。</strong></p><ul class=""><li id="a334" class="ns nt it kk b kl km ko kp kr nu kv nv kz nw ld nx ny nz oa bi translated">当使用<code class="fe le lf lg lh b">Keras.ImageDataGenerator</code>时，在使用 COCO2017 数据集的每个历元的训练期间，花费了大约<strong class="kk iu"> 58 分钟</strong>。</li><li id="39ef" class="ns nt it kk b kl ob ko oc kr od kv oe kz of ld nx ny nz oa bi translated">将<code class="fe le lf lg lh b">tf.data</code>与变量<code class="fe le lf lg lh b">cache=True</code>一起使用时，程序崩溃。这个崩溃背后的原因是所考虑的数据集(<strong class="kk iu">大小</strong> <strong class="kk iu"> 18 GB)比工作站的 RAM </strong>大。使用<code class="fe le lf lg lh b">cache=True</code>，程序开始将图像存储在 ram 中以便快速访问，当图像超过 RAM 时(在我们的例子中是<strong class="kk iu"> 16 GB)，程序就会崩溃。我在一个更小的数据集<a class="ae mx" href="https://www.kaggle.com/chetankv/dogs-cats-images" rel="noopener ugc nofollow" target="_blank"> Kaggle- dogs_and_cats </a>上测试了相同的选项，效果很好。这表明，当考虑的数据集的大小大于 RAM 时，我们不应该使用<code class="fe le lf lg lh b">cache=True</code>选项。</strong></li><li id="0039" class="ns nt it kk b kl ob ko oc kr od kv oe kz of ld nx ny nz oa bi translated">当使用带变量<code class="fe le lf lg lh b">cache=False</code>的<code class="fe le lf lg lh b">tf.data</code>时，程序需要大约<strong class="kk iu"> 23 分钟，</strong>比<code class="fe le lf lg lh b">Keras.ImageDataGenerator</code>快<strong class="kk iu"> 2.5 倍。</strong></li><li id="89aa" class="ns nt it kk b kl ob ko oc kr od kv oe kz of ld nx ny nz oa bi translated">当使用<code class="fe le lf lg lh b">cache='some_path.tfcache'</code>时，在第一个时期<code class="fe le lf lg lh b">tf.data</code>将<strong class="kk iu">在您的计算机目录中进行数据集/图像的转储</strong>。这就是为什么它在第一个时期比较慢，大约需要 42 分钟。在连续的历元中，它不必在计算机上再次存储图像，而是在第一个历元中使用已经创建的转储，这最终加快了训练时间。在连续的历元期间，每个历元仅花费<strong class="kk iu"> 14 分钟。创建转储只有一次过程。对于超参数调谐，大约需要<strong class="kk iu"> 14 分钟，相比之下</strong>需要<code class="fe le lf lg lh b">Keras</code>58 分钟，大约快<strong class="kk iu"> 4.14 倍。</strong></strong></li></ul><blockquote class="og oh oi"><p id="71ee" class="ki kj oj kk b kl km ju kn ko kp jx kq ok ks kt ku ol kw kx ky om la lb lc ld im bi translated">注意:使用<code class="fe le lf lg lh b">cache='some_path.tfcache'</code>时在内存中创建的转储大约为 90 GB，这实际上远远大于数据集的原始大小(18 GB)。我不能确切地理解这一点的原因，因为没有来自 TensorFlow 的关于这一点的明确文档。希望这是以后整理出来的 glich。</p><p id="2725" class="ki kj oj kk b kl km ju kn ko kp jx kq ok ks kt ku ol kw kx ky om la lb lc ld im bi translated">对于像<a class="ae mx" href="https://www.kaggle.com/chetankv/dogs-cats-images" rel="noopener ugc nofollow" target="_blank"> Kaggle- dogs_and_cats </a>这样只有 217 MB 的较小数据集，在速度或训练时间上与<code class="fe le lf lg lh b">tf.data</code>和<code class="fe le lf lg lh b">Keras</code>不会有明显的差异，因为 RAM 足够大，可以一次存储所有图像。</p></blockquote><h1 id="2e58" class="my mz it bd na nb nc nd ne nf ng nh ni jz nj ka nk kc nl kd nm kf nn kg no np bi translated">培训模型代码</h1><p id="7e7a" class="pw-post-body-paragraph ki kj it kk b kl on ju kn ko oo jx kq kr op kt ku kv oq kx ky kz or lb lc ld im bi translated">这里显示了创建和训练模型的初始代码。预训练模型<code class="fe le lf lg lh b">mobilenet</code>用于执行迁移学习，预训练模型的基础层被冻结。</p><figure class="mj mk ml mm gt mn"><div class="bz fp l di"><div class="nq nr l"/></div></figure><h1 id="41de" class="my mz it bd na nb nc nd ne nf ng nh ni jz nj ka nk kc nl kd nm kf nn kg no np bi translated">所有代码放在一起</h1><p id="1584" class="pw-post-body-paragraph ki kj it kk b kl on ju kn ko oo jx kq kr op kt ku kv oq kx ky kz or lb lc ld im bi translated">在这里，我将第 1 部分和第 2 部分的代码结合起来。函数的注释和文档字符串将有助于理解代码。</p><figure class="mj mk ml mm gt mn"><div class="bz fp l di"><div class="nq nr l"/></div></figure><h1 id="6289" class="my mz it bd na nb nc nd ne nf ng nh ni jz nj ka nk kc nl kd nm kf nn kg no np bi translated">结论</h1><p id="602f" class="pw-post-body-paragraph ki kj it kk b kl on ju kn ko oo jx kq kr op kt ku kv oq kx ky kz or lb lc ld im bi translated">这篇文章表明，对于任何实际的图像分类问题，<code class="fe le lf lg lh b">tf.data</code>比<code class="fe le lf lg lh b">Keras.ImageDataGenerator</code>快倍<strong class="kk iu"> 2.5 </strong> <code class="fe le lf lg lh b">(when using cache=False)</code> <strong class="kk iu">到 4.14 </strong> <code class="fe le lf lg lh b">(when using cache=<strong class="kk iu">`</strong>some_path.tfcache`)</code> <strong class="kk iu">。我认为值得一试<code class="fe le lf lg lh b">tf.data</code>。</strong></p></div></div>    
</body>
</html>