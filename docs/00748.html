<html>
<head>
<title>Automatic Airflow DAG creation for Data Scientists and Analysts</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为数据科学家和分析师自动创建气流DAG</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/automatic-airflow-dag-creation-for-data-scientists-and-analysts-17d24a9884ba?source=collection_archive---------24-----------------------#2020-01-21">https://towardsdatascience.com/automatic-airflow-dag-creation-for-data-scientists-and-analysts-17d24a9884ba?source=collection_archive---------24-----------------------#2020-01-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2ff4" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">日常工作的自动化减少了数据错误，并为创新提供了更多时间。只需点击一下鼠标，使用这里提供的脚本，数据科学家和分析师就可以快速进行批量分析。</h2></div><blockquote class="kf kg kh"><p id="78f7" class="ki kj kk kl b km kn jr ko kp kq ju kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated"><em class="iq">TL；DR </em> : DAG creator是一个python脚本，当运行时，它会选择最新的json定义文件，并将其中的值替换到DAG模板中，为每个定义文件创建新的DAG。当执行新创建的DAG时，它会将查询的输出存储在s3中，然后将所需的数据推入Redshift中的最终表中。</p></blockquote><p id="4c6c" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">最近，我听到(之前也遇到过)许多这样的场景:数据科学家或分析师希望通过批处理来自动完成分析，但他们必须等待数据工程师或软件工程师来完成。一方面，数据工程师知道如何生产代码，但另一方面，他们没有足够的时间来处理来自分析师和科学家的每一个需求。</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi li"><img src="../Images/939c529e1594cdd3ea7814c934366d92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FJsMPN5kPMI7JuqhsaP7rA.png"/></div></div></figure><blockquote class="lu"><p id="f79e" class="lv lw iq bd lx ly lz ma mb mc md le dk translated">这篇文章将展示一个工具，在没有数据工程师帮助的情况下快速生产你的代码。<em class="me">最棒的是，生产就绪代码附在这个帖子里，供那些想直接使用它的人使用。</em></p></blockquote><p id="9d34" class="pw-post-body-paragraph ki kj iq kl b km mf jr ko kp mg ju kr lf mh ku kv lg mi ky kz lh mj lc ld le ij bi translated">根据我的经验，大多数数据科学家和分析师仍然通过会产生错误和数据问题的即席脚本进行日常分析。此外，对于一些人来说，制作脚本不值得他们花费时间，但是他们必须投资，因为这是团队的需求。对于像我一样的其他人，我们喜欢生产和优化ETL和数据流。</p><h2 id="0254" class="mk ml iq bd mm mn mo dn mp mq mr dp ms lf mt mu mv lg mw mx my lh mz na nb nc bi translated">为什么生产数据分析:</h2><p id="aa3a" class="pw-post-body-paragraph ki kj iq kl b km nd jr ko kp ne ju kr lf nf ku kv lg ng ky kz lh nh lc ld le ij bi translated">好吧，信不信由你，有许多人仍然想知道为什么要生产代码，当他们可以每天早上或定期地通过改变SQL查询来执行它的时候。对他们和其他人来说，这些是你从生产数据的特别分析和处理中得到的好处。</p><ol class=""><li id="6d25" class="ni nj iq kl b km kn kp kq lf nk lg nl lh nm le nn no np nq bi translated">一次性工作，您不必每天花30分钟来手动执行查询，这些查询可能会也可能不会给出无错误的数据。如果它偶然给出任何数据问题，那么将会有更多的时间浪费。</li><li id="8849" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le nn no np nq bi translated">数据同时被复制到S3，以备将来参考或未雨绸缪。</li><li id="e05e" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le nn no np nq bi translated">可读性和标准化的代码实践，对于任何新资源来说，理解和更新脚本将花费更少的时间。</li><li id="e11d" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le nn no np nq bi translated">在空间和时间之间，基于不同的用例，生产化的代码可以利用其中任何一个。</li><li id="e0fc" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le nn no np nq bi translated">更好的异常处理将给出有意义的错误，最终将节省调试任何数据问题的时间。</li><li id="0c86" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le nn no np nq bi translated">其他人可以导入或继承您的工作，以便在他们的流程中使用。</li><li id="a5a6" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le nn no np nq bi translated">自动回溯数据和重试逻辑。</li></ol><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi nw"><img src="../Images/236b521983b16f441138ce72a6ad15a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8IzVjTxkwLD4EWBz_ZDX6w.jpeg"/></div></div></figure><h1 id="90c2" class="nx ml iq bd mm ny nz oa mp ob oc od ms jw oe jx mv jz of ka my kc og kd nb oh bi translated">自动气流DAG创建</h1><p id="ca87" class="pw-post-body-paragraph ki kj iq kl b km nd jr ko kp ne ju kr lf nf ku kv lg ng ky kz lh nh lc ld le ij bi translated">此过程将自动创建DAG，其中需要将所有分析任务放在DAG中，DAG将充当模板。这些任务每次都是一样的。当您分析/查询数据时，这种情况肯定会出现，您必须将输出存储到一个表中，以便查看您的仪表板，或者您只想将数据附加到已经存在的表中，作为定期批处理的一部分。顺便说一下，DAG是一个有向无环图。它是工作流中需要顺序或同时执行的任务的集合。</p><p id="6ff8" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">首先，在此过程中有3种类型的文件相关联:</p><ol class=""><li id="61ad" class="ni nj iq kl b km kn kp kq lf nk lg nl lh nm le nn no np nq bi translated">DAG定义(。json)</li><li id="b97a" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le nn no np nq bi translated">DAG模板(。py)</li><li id="7c7e" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le nn no np nq bi translated">DAG创建者(。py)</li></ol><h1 id="7a08" class="nx ml iq bd mm ny nz oa mp ob oc od ms jw oe jx mv jz of ka my kc og kd nb oh bi translated"><strong class="ak"> DAG定义</strong></h1><p id="5dbb" class="pw-post-body-paragraph ki kj iq kl b km nd jr ko kp ne ju kr lf nf ku kv lg ng ky kz lh nh lc ld le ij bi translated">简而言之，这些是每个Dag中不同的值。因为它定义了DAG的用途，所以我们称它为DAG定义文件。</p><p id="3ee8" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">下面是一个这样的例子:</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi oi"><img src="../Images/3be6f44682a10ab0ecc0e1b42445ea58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zxx6NE7CWqI4ojmBsm9YXA.png"/></div></div></figure><p id="3fa7" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">你可以在这里找到示例文件<a class="ae oj" href="https://github.com/GagandeepS/airlfow-automatic-dag-creation/blob/master/app_modules_daily_users.json" rel="noopener ugc nofollow" target="_blank"/></p><ul class=""><li id="e621" class="ni nj iq kl b km kn kp kq lf nk lg nl lh nm le ok no np nq bi translated"><strong class="kl ir">查询</strong>:这是一个红移查询，它的schema、table_name、from_date和to_date参数化。当dag_creator被执行时，这些值将被填充。它应该在第一个“truncate {schema}”处包含truncate语句。“{table_name}”，它应该是{schema}中的insert语句。{table_name}它还应该具有用表的datetime列参数化的from_date和to_date。将执行该查询，并将所需的数据放入一个临时表中。</li><li id="d9c2" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le ok no np nq bi translated"><strong class="kl ir">模式</strong>:红移模式</li><li id="df46" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le ok no np nq bi translated"><strong class="kl ir">table _ name</strong>:schema下的红移表。该名称用于红移表和s3文件夹。后者更难重命名，因此对于工作流，最好将其设置为您想要的最终表名。</li><li id="e462" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le ok no np nq bi translated"><strong class="kl ir"> table_columns </strong>:表格的列。它应该包含batch_date。而且应该符合上面的查询。</li><li id="a6e4" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le ok no np nq bi translated"><strong class="kl ir"> start_date </strong>:上述查询应该开始执行的日期。(&gt; =)</li><li id="8f90" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le ok no np nq bi translated"><strong class="kl ir"> back_date_from </strong>:理想的情况是，如果用户今天更新了“查询”中的某些内容，那么从第二天开始，这些更改将会反映在表中，但是如果用户希望将日期倒推，以便这些更改也反映在过去的日期中，那么这需要是在表中进行更改之后的日期。这将自动清除s3键，并随后从表中删除&gt; =该日期的行。现在，要么手动运行DAG，要么等待下一次每日运行，以便将更新的数据推送到s3和表中。DAG完成后，将此字段更新为其默认值，即“”。<strong class="kl ir">警告</strong>:请务必将此字段改回''，否则在每次DAG运行时，它将清除所需的s3密钥并删除表中的行。</li><li id="4396" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le ok no np nq bi translated"><strong class="kl ir"> batch_size </strong>:这用于将上面的红移查询分成多个批次，其中batch_size是在一个红移查询中运行的天数。当在初次运行时运行大量数据时，这提高了运行红移查询的速度。</li><li id="db4a" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le ok no np nq bi translated"><strong class="kl ir">template _ location _ in _ ec2</strong>:DAG模板的位置。此位置是固定的，不应更改。该位置应该存在于您的虚拟机中。</li><li id="f9b3" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le ok no np nq bi translated"><strong class="kl ir">dag _ folder</strong>:EC2中放置最终DAG的文件夹，它将符号链接到Airflow DAG文件夹</li><li id="e4e0" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le ok no np nq bi translated"><strong class="kl ir">DAG _ id</strong>:DAG的Id。这应该是唯一的，否则以前的同名DAG将被覆盖</li><li id="a5c6" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le ok no np nq bi translated"><strong class="kl ir">Schedule _ interval</strong>:DAG的时间表(Cron格式)</li></ul><h1 id="dfdd" class="nx ml iq bd mm ny nz oa mp ob oc od ms jw oe jx mv jz of ka my kc og kd nb oh bi translated"><strong class="ak"> DAG模板</strong></h1><p id="7036" class="pw-post-body-paragraph ki kj iq kl b km nd jr ko kp ne ju kr lf nf ku kv lg ng ky kz lh nh lc ld le ij bi translated">这是具有参数化值的最终DAG的框架，以便可以在DAG Creator的帮助下替换这些值。该DAG将具有下图所示的任务:</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi ol"><img src="../Images/853a80167f4b4a56dd1576df3b706219.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NR_8scj0EDLKnASLBgvxtg.png"/></div></div></figure><ul class=""><li id="80e8" class="ni nj iq kl b km kn kp kq lf nk lg nl lh nm le ok no np nq bi translated"><strong class="kl ir"> load_definition </strong>:这将从s3加载<em class="kk"> DAG定义</em></li><li id="9579" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le ok no np nq bi translated"><strong class="kl ir"> list_s3 </strong>:列出最近14天的s3密钥，这是SLA。用气流变量覆盖它:“模块_转换_回顾_天数”</li><li id="612d" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le ok no np nq bi translated"><strong class="kl ir"> compute_next_gather </strong>:基于列表键，这将计算出接下来几天要执行的任务，并因此将‘from _ date’和‘to _ date’推送到进一步的任务</li><li id="ece5" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le ok no np nq bi translated"><strong class="kl ir">创建暂存表</strong>:创建暂存表</li><li id="b927" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le ok no np nq bi translated"><strong class="kl ir"> run_queries </strong>:根据上面计算的日期执行查询</li><li id="3db9" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le ok no np nq bi translated"><strong class="kl ir">卸载_暂存</strong>:将暂存台卸载到s3中</li><li id="5f5a" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le ok no np nq bi translated"><strong class="kl ir">extract _ last _ batch _ date</strong>:从红移，这将计算max(batch_date)</li><li id="521e" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le ok no np nq bi translated"><strong class="kl ir"> list_s3_for_table </strong>:列出s3键</li><li id="7b28" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le ok no np nq bi translated"><strong class="kl ir"> s3_to_final </strong>:基于列表s3键和last batch_date，这将计算出将哪些s3值推入最终表中</li><li id="8cb8" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le ok no np nq bi translated"><strong class="kl ir">红移_分析</strong>:执行红移分析</li></ul><p id="1e97" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">下面是遵循的s3结构。并且符合红移数据库结构，即<em class="kk"> schema.table.batch_date </em></p><blockquote class="kf kg kh"><p id="08f3" class="ki kj kk kl b km kn jr ko kp kq ju kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated">= &gt; S3://bucket/redshift _ schema/redshift _ table/batch _ date =<em class="iq">YYYY-MM-DD</em>/</p></blockquote><p id="2ec7" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">你可以在这里找到python代码<a class="ae oj" href="https://github.com/GagandeepS/airlfow-automatic-dag-creation/blob/master/dag_template.py" rel="noopener ugc nofollow" target="_blank"/></p><h1 id="fe88" class="nx ml iq bd mm ny nz oa mp ob oc od ms jw oe jx mv jz of ka my kc og kd nb oh bi translated"><strong class="ak"> DAG创建者</strong></h1><p id="6d1f" class="pw-post-body-paragraph ki kj iq kl b km nd jr ko kp ne ju kr lf nf ku kv lg ng ky kz lh nh lc ld le ij bi translated">这是主DAG，它将从<em class="kk"> DAG定义</em>中读取值，并将其替换到<em class="kk"> DAG模板</em>中，并创建与存在的<em class="kk"> DAG定义</em>一样多的DAG。</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi om"><img src="../Images/3ace4769e288e44c503986943a4bf317.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*nbe-K4rrw0vuMrRf_O1UkQ.png"/></div></figure><ul class=""><li id="af7f" class="ni nj iq kl b km kn kp kq lf nk lg nl lh nm le ok no np nq bi translated"><strong class="kl ir">get _ last _ modified _ definitions</strong>:从s3开始，将只选取那些在<em class="kk"> DAG创建者</em>的最后执行日期之后(大于或等于)修改的定义。</li><li id="fa21" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le ok no np nq bi translated"><strong class="kl ir">remove _ old _ and _ create _ new _ dag</strong>:根据上面的定义列表，这将取消DAG与EC2的链接并将其删除，然后创建DAG并将其与新定义链接。</li></ul><p id="0c13" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">你可以在这里找到python代码<a class="ae oj" href="https://github.com/GagandeepS/airlfow-automatic-dag-creation/blob/master/dag_creator.py" rel="noopener ugc nofollow" target="_blank"/></p><h2 id="556e" class="mk ml iq bd mm mn mo dn mp mq mr dp ms lf mt mu mv lg mw mx my lh mz na nb nc bi translated"><strong class="ak">思考要点:</strong></h2><ol class=""><li id="4521" class="ni nj iq kl b km nd kp ne lf on lg oo lh op le nn no np nq bi translated">添加新的JSON DAG定义后，需要在airflow GUI中手动运行<em class="kk"> dag_creator </em> DAG current。DAG运行完成后需要几分钟时间，新的DAG才会显示在GUI中。您可以在CICD管道中自动执行它，或者在s3中出现新定义文件时使用Lambda来执行它。所以，每当你按下</li><li id="171d" class="ni nj iq kl b km nr kp ns lf nt lg nu lh nv le nn no np nq bi translated">将表的所有权更改为数据库管理员或ETL管理员，以便Airflow可以将数据写入其中。</li></ol><h1 id="f4b3" class="nx ml iq bd mm ny nz oa mp ob oc od ms jw oe jx mv jz of ka my kc og kd nb oh bi translated">包裹</h1><p id="b79a" class="pw-post-body-paragraph ki kj iq kl b km nd jr ko kp ne ju kr lf nf ku kv lg ng ky kz lh nh lc ld le ij bi translated">因此，当DAG创建器运行时，它将挑选最新的定义文件，并替换DAG模板中的值，以便为每个定义文件创建新的DAG。当执行新的DAG时，它会将查询的输出存储在s3中，然后将所需的数据推入Redshift中的最终表中。</p><p id="fbaa" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">但是，如果你有大量的数据或点击流数据，不能把红移。下一篇文章将介绍另一种类似的教学方法，它将从s3中选择所需的拼花数据，而不是这里的红移，进行分析并将最终数据推入s3和红移。</p></div></div>    
</body>
</html>