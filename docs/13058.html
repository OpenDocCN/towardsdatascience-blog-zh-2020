<html>
<head>
<title>Evaluate ML Classifier Performance using Statistical Hypothesis Testing in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Python 中的统计假设检验评估 ML 分类器性能</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/evaluate-ml-classifier-performance-using-statistical-hypothesis-testing-in-python-e4b90eb27dce?source=collection_archive---------12-----------------------#2020-09-08">https://towardsdatascience.com/evaluate-ml-classifier-performance-using-statistical-hypothesis-testing-in-python-e4b90eb27dce?source=collection_archive---------12-----------------------#2020-09-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4f34" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">有一个强有力的论据，为什么选择一个分类算法，而不是基于性能的重要性水平</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/45a8ce7a4bb107e0e0d01b637ac6b32e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vdrj4CJh-QmOkRw5sQtwbg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Alexis Fauvet 在<a class="ae ky" href="https://unsplash.com/s/photos/difference?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="292b" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="e557" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">选择正确的机器学习算法是决定性的，它决定了模型的性能。选择模型时最主要的因素是性能，它采用 KFold-cross-validation 技术来实现独立性。</p><p id="8116" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">所选择的模型通常具有较高的平均性能。然而，有时它起源于统计上的侥幸。有许多<strong class="lt iu">统计假设检验</strong>方法来评估交叉验证产生的平均性能差异，以解决这一问题。如果差异高于显著性水平“<strong class="lt iu"> p 值</strong>”,我们可以拒绝两个算法相同且差异不显著的零假设。</p><p id="69a3" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在开发新的分类模型或参加<a class="ae ky" href="https://www.kaggle.com/competitions" rel="noopener ugc nofollow" target="_blank"> Kaggle 的</a>比赛时，我通常会在我的管道中包含这样一个步骤。</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="2f43" class="kz la it bd lb lc mz le lf lg na li lj jz nb ka ll kc nc kd ln kf nd kg lp lq bi translated">教程目标</h1><ol class=""><li id="58ac" class="ne nf it lt b lu lv lx ly ma ng me nh mi ni mm nj nk nl nm bi translated">理解统计假设检验之间的区别。</li><li id="8117" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">基于平均性能分数的模型选择可能会产生误导。</li><li id="51f6" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">为什么使用配对学生的 t 检验而不是原始学生的 t 检验。</li><li id="a92d" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">利用<a class="ae ky" href="http://rasbt.github.io/mlxtend/" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> MLxtend </strong> </a>库应用<strong class="lt iu"> 5X2 折叠</strong>的高级技术来比较基于<strong class="lt iu"> p 值</strong>的算法</li></ol></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="9bd5" class="kz la it bd lb lc mz le lf lg na li lj jz nb ka ll kc nc kd ln kf nd kg lp lq bi translated">目录</h1><ol class=""><li id="3589" class="ne nf it lt b lu lv lx ly ma ng me nh mi ni mm nj nk nl nm bi translated">统计显著性检验是什么意思？</li><li id="26ed" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">常用统计假设检验的类型</li><li id="87d2" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">根据性能提取最佳的两个模型。</li><li id="4e99" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">对最好的两个进行假设检验的步骤</li><li id="0e7a" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">应用 5X2 折叠的步骤</li><li id="f58c" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">比较分类器算法</li><li id="86e5" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">摘要</li><li id="f4ed" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">参考</li></ol></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="f842" class="kz la it bd lb lc mz le lf lg na li lj jz nb ka ll kc nc kd ln kf nd kg lp lq bi translated">统计假设检验是什么意思？</h1><p id="8879" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">考虑到两个数据样本具有相同的分布，统计假设检验量化了它们的似是而非程度。描述了无效假设。我们可以通过应用一些统计计算来检验这个无效假设。</p><ul class=""><li id="3a2e" class="ne nf it lt b lu mn lx mo ma ns me nt mi nu mm nv nk nl nm bi translated">如果测试结果推断<strong class="lt iu">没有足够的证据</strong>来拒绝零假设，那么任何观察到的模型分数差异都是偶然发生的。</li><li id="6b54" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nv nk nl nm bi translated">如果测试结果推断<strong class="lt iu">有足够的证据</strong>拒绝零假设，那么任何观察到的模型分数差异都是真实的。</li></ul></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="9d90" class="kz la it bd lb lc mz le lf lg na li lj jz nb ka ll kc nc kd ln kf nd kg lp lq bi translated">统计假设检验的类型</h1><p id="94da" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">通过统计显著性测试检查机器学习模型需要一些预期，这些预期将影响所使用的统计测试。这种比较最稳健的方式被称为<a class="ae ky" href="http://paired design of experiments" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">成对设计</strong> </a>，它在相同的数据上比较两种模型(或算法)的性能。这样，两种模型(或算法)都必须处理相同的困难。</p><p id="68c0" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在下文中，每个测试都有一些优点和缺点，您应该在选择时加以考虑。</p><p id="74a1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">还有其他用于比较分类器的统计测试，但这是最值得推荐的一种。</p><ol class=""><li id="ecd4" class="ne nf it lt b lu mn lx mo ma ns me nt mi nu mm nj nk nl nm bi translated"><strong class="lt iu">独立数据样本</strong>:有无限数据集时使用。您为<strong class="lt iu"> </strong>训练收集<strong class="lt iu"> n 个</strong> <strong class="lt iu">样本</strong>，并测试数据集。然后为每种方法计算十个独立的模型分数。最后，应用 t 检验来比较模型。然而，这种方法并不实际，因为现实中没有无限的数据。</li></ol><p id="9bb9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu"> 2。十重交叉验证</strong>:使用普通配对 t 检验。相对于其他方法，该方法具有良好的可重复性，以及体面的<strong class="lt iu">类型 II 误差</strong>。但是，它有很高的<strong class="lt iu">I 型误差</strong>；这就是不推荐的原因。</p><p id="8d8a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">通过交叉验证比较<strong class="lt iu">训练</strong>算法比比较特定(完全训练)模型的<strong class="lt iu">预测性能</strong>做出更强的假设。其中重采样验证(交叉验证属于)不能完全估计算法比较的方差不确定性。</p><p id="825b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu"> 3。麦克内马测试</strong>:</p><blockquote class="nx ny nz"><p id="3003" class="lr ls nw lt b lu mn ju lw lx mo jx lz oa mp mc md ob mq mg mh oc mr mk ml mm im bi translated">在统计学中，<strong class="lt iu">麦克内马检验</strong>是一种用于成对名义数据的统计检验。它应用于具有二分特征的 2 × 2 列联表，具有匹配的受试者对，以确定行和列的边际频率是否相等(即是否存在“边际同质性”)。— <a class="ae ky" href="https://en.wikipedia.org/wiki/McNemar%27s_test#:~:text=In%20statistics%2C%20McNemar%27s%20test%20is,is%20%22marginal%20homogeneity%22%29." rel="noopener ugc nofollow" target="_blank">维基百科</a></p></blockquote><p id="48d0" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这是最近二十年推荐的。然而，这种方法的挑战在于，您要么需要构建自己的函数来实现它，要么使用第三方库，在您使用的工具中通常不会为您打包它。</p><p id="25a4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu"> 4。非参数配对检验</strong>:这种方法包括做一些假设。例如，假设模型精度的分布具有正态分布(高斯)。</p><p id="d6c0" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test" rel="noopener ugc nofollow" target="_blank"> Wilcoxon 符号秩检验</a>是配对学生 t 检验的非参数版本。尽管检验是非参数的，但它仍然假设每个样本内部的观察值是独立的。尽管使用 k 倍交叉验证会打破这个假设。</p><p id="0a50" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu"> 5。估计统计</strong>:一种数据分析框架，使用效应大小、置信区间、精度规划和元分析的组合来规划实验、分析数据和解释结果— <a class="ae ky" href="https://en.wikipedia.org/wiki/Estimation_statistics#:~:text=Estimation%20statistics%20is%20a%20data,considered%20to%20be%20less%20informative." rel="noopener ugc nofollow" target="_blank">维基百科</a>。然而，当使用重采样方法评估模型时，独立性假设被打破。作为替代，其他统计重采样方法，如自举。Bootstrapping 可以估计稳健的非参数置信区间。因此，我们可以解释结果并比较分类器。</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="c232" class="kz la it bd lb lc mz le lf lg na li lj jz nb ka ll kc nc kd ln kf nd kg lp lq bi translated">5X2 折叠方法背后的直觉</h1><p id="61be" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">一种在数据的相同 k 倍交叉验证分割上评估每个模型并计算每个分割分数的方法。这将为十倍交叉验证提供十个分数的样本。然后，我们可以使用配对统计检验来比较这些分数。</p><p id="9daf" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">由于多次使用相同的数据行来训练模型，因此违反了独立性假设；因此，测试会有偏差。</p><p id="f850" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这种统计测试可以调整，以克服缺乏独立性。此外，可以配置该方法的折叠和重复次数，以实现模型性能的更好采样。</p><blockquote class="nx ny nz"><p id="764b" class="lr ls nw lt b lu mn ju lw lx mo jx lz oa mp mc md ob mq mg mh oc mr mk ml mm im bi translated">Thomas Dietterich 在<a class="ae ky" href="https://sci2s.ugr.es/keel/pdf/algorithm/articulo/dietterich1998.pdf" rel="noopener ugc nofollow" target="_blank">“用于比较监督分类学习算法的近似统计测试”中提出了这种方法</a> — 1998 年</p></blockquote></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="2b92" class="kz la it bd lb lc mz le lf lg na li lj jz nb ka ll kc nc kd ln kf nd kg lp lq bi translated">正在加载数据集</h1><p id="3468" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">对于本教程，我将使用<code class="fe od oe of og b">sklearn</code>库中的<code class="fe od oe of og b">load_iris</code>数据集。然而，对于任何 ML 问题，步骤都是相同的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/9db235668660f19209e5f633c833aac4.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/1*uDFcRzaDCtje6i5Rz11Vtg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">窥视虹膜数据集</p></figure></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="8a95" class="kz la it bd lb lc mz le lf lg na li lj jz nb ka ll kc nc kd ln kf nd kg lp lq bi translated">提取最佳两个模型的步骤</h1><p id="98f3" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在这一步中，我将根据性能准确度分数对四种不同的算法进行比较。然后将选择得分最高的两个模型在它们之间进行假设检验。</p><pre class="kj kk kl km gt oi og oj ok aw ol bi"><span id="f58a" class="om la it og b gy on oo l op oq"># Spot-Check Algorithms<br/>models = []<br/>models.append(('LR', LogisticRegression(max_iter=1000))) <br/>models.append(('LDA', LinearDiscriminantAnalysis())) <br/>models.append(('KNN', KNeighborsClassifier()))<br/>models.append(('DSC', DecisionTreeClassifier(random_state = 1, max_depth=2)))<br/>models.append(('SVM', SVC()))<br/># evaluate each model in turn<br/>results = []<br/>names = []<br/>for name, model in models:<br/>    kfold = RepeatedStratifiedKFold(n_splits=10, n_repeats = 3, random_state=1)<br/>    cv_results = cross_val_score(model, X, y, cv=kfold, scoring='accuracy') <br/>    results.append(cv_results)<br/>    names.append(name)<br/>    msg = "%s: %.2f (%.3f)" % (name, cv_results.mean(), cv_results.std())<br/>    print(msg)</span></pre><p id="5848" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">结果:</p><pre class="kj kk kl km gt oi og oj ok aw ol bi"><span id="9092" class="om la it og b gy on oo l op oq">LR: 0.96 (0.041)<br/>LDA: 0.98 (0.031)<br/>KNN: 0.96 (0.037)<br/>DSC: 0.94 (0.051)<br/>SVM: 0.96 (0.045)</span></pre><p id="f244" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">看来<code class="fe od oe of og b">LR,</code> <code class="fe od oe of og b">KNN</code>和<code class="fe od oe of og b">SVM</code>的均值相同，标准差略有不同。然而，<code class="fe od oe of og b">LDA</code>表现出较高的性能，而<code class="fe od oe of og b">DTC</code>表现出最低的性能。让我们在<code class="fe od oe of og b">KNN</code>、<code class="fe od oe of og b">DTC,</code>和<code class="fe od oe of og b">LDA</code>之间建立一个箱线图，作为更多解释的可视化。</p><pre class="kj kk kl km gt oi og oj ok aw ol bi"><span id="abfc" class="om la it og b gy on oo l op oq">import matplotlib.pyplot as plt</span><span id="d1c9" class="om la it og b gy or oo l op oq">plt.figure(figsize = (15, 10))<br/>plt.grid(False)<br/>plt.title("Mean accuracies between the best two selected algorithms", fontsize = 25, fontweight = 'bold')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/30005dac59dd6f3d9bad3fc5e79cee0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R-PqfwLfBVtqAHtUUYpDgA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">算法间的平均精确度</p></figure><p id="b75f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">好像 LDA 和 DTC 表现差不多，就挑那两个吧。</p><blockquote class="nx ny nz"><p id="fb60" class="lr ls nw lt b lu mn ju lw lx mo jx lz oa mp mc md ob mq mg mh oc mr mk ml mm im bi translated">对于这个分类问题，您可以实现逻辑回归。然而，我选择了更复杂的分类算法来展示假设检验的思想。</p></blockquote></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="cad6" class="kz la it bd lb lc mz le lf lg na li lj jz nb ka ll kc nc kd ln kf nd kg lp lq bi translated">假设检验的步骤</h1><p id="3118" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">第一步是陈述零假设。</p><blockquote class="nx ny nz"><p id="7ad1" class="lr ls nw lt b lu mn ju lw lx mo jx lz oa mp mc md ob mq mg mh oc mr mk ml mm im bi translated">H0:两个模型在数据集上都有相同的表现。</p><p id="4eb6" class="lr ls nw lt b lu mn ju lw lx mo jx lz oa mp mc md ob mq mg mh oc mr mk ml mm im bi translated">H1:两个模型在数据集上的表现不尽相同。</p><p id="c9d2" class="lr ls nw lt b lu mn ju lw lx mo jx lz oa mp mc md ob mq mg mh oc mr mk ml mm im bi translated">显著性水平为 0.05</p></blockquote><p id="f7d0" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">假设显著性阈值为<strong class="lt iu"> α=0.05 </strong>，用于拒绝两种算法在数据集上表现相同的零假设，并进行 5x2_cv _t_test。</p><pre class="kj kk kl km gt oi og oj ok aw ol bi"><span id="31a6" class="om la it og b gy on oo l op oq"># evaluate model 1<br/>model1 = LinearDiscriminantAnalysis()<br/>cv1 = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 1)<br/>scores1 = cross_val_score(model1, X, y, scoring = 'accuracy', cv = cv1, n_jobs = -1)<br/>print('LDA Mean Accuracy: %.1f%% +/-(%.3f)' % (mean(scores1*100), std(scores1)))</span><span id="e243" class="om la it og b gy or oo l op oq"># evaluate model 2<br/>model3 = DecisionTreeClassifier(random_state = 1, max_depth=2)<br/>cv2 = RepeatedStratifiedKFold(n_splits = 10, n_repeats = 3, random_state = 1)<br/>scores3 = cross_val_score(model2, X, y, scoring = 'accuracy', cv = cv2, n_jobs = -1)<br/>print('DecisionTreeClassifier Mean Accuracy: %.1f%% +/-(%.3f)' % (mean(scores3*100), std(scores3)))</span><span id="0eca" class="om la it og b gy or oo l op oq"># plot the results<br/>plt.boxplot([scores1, scores2], labels=['LDA', 'DTC'], showmeans=True)<br/>plt.show()</span></pre><p id="cd07" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">结果</p><pre class="kj kk kl km gt oi og oj ok aw ol bi"><span id="fcfc" class="om la it og b gy on oo l op oq">LDA Mean Accuracy: 98.0% +/-(0.031)<br/>DecisionTreeClassifier Mean Accuracy: 96.4% +/-(0.037)</span></pre><p id="f950" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">看来<code class="fe od oe of og b">LDA</code>比<code class="fe od oe of og b">DTC</code>有更好的性能，而<code class="fe od oe of og b">LDA</code>的精度更高。</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="61ab" class="kz la it bd lb lc mz le lf lg na li lj jz nb ka ll kc nc kd ln kf nd kg lp lq bi translated">使用 MLxtend 封装的 5 乘 2 CV</h1><p id="ed34" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">您可以从头开始实现 5X2 CV 折叠；但是，有一个很好的软件包可以节省您很多时间，它叫做 MLxtend。我将使用评估模块中的 paired_ttest_5x2cv 函数来计算两个模型的 t 和 p 值。</p><pre class="kj kk kl km gt oi og oj ok aw ol bi"><span id="9397" class="om la it og b gy on oo l op oq">from mlxtend.evaluate import paired_ttest_5x2cv<br/># check if difference between algorithms is real<br/>t, p = paired_ttest_5x2cv(estimator1=model1, <br/>                          estimator2=model2, <br/>                          X=X, <br/>                          y=y, <br/>                          scoring='accuracy', <br/>                          random_seed=1)<br/># summarize<br/>print(f'The P-value is = {p:.3f}')<br/>print(f'The t-statistics is = {t:.3f}')<br/># interpret the result<br/>if p &lt;= 0.05:<br/>    print('Since p&lt;0.05, We can reject the null-hypothesis that both models perform equally well on this dataset. We may conclude that the two algorithms are significantly different.')<br/>else:<br/>    print('Since p&gt;0.05, we cannot reject the null hypothesis and may conclude that the performance of the two algorithms is not significantly different.')</span></pre><p id="0205" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">结果:</p><pre class="kj kk kl km gt oi og oj ok aw ol bi"><span id="c086" class="om la it og b gy on oo l op oq">The P-value is = 0.027<br/>The t-statistics is = 3.101<br/>Since p&lt;0.05, We can reject the null-hypothesis that both models perform equally well on this dataset. We may conclude that the two algorithms are significantly different</span></pre><p id="cbd8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在你有一个强有力的理由来解释为什么选择 LDA 而不是 DTC。</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="2276" class="kz la it bd lb lc mz le lf lg na li lj jz nb ka ll kc nc kd ln kf nd kg lp lq bi translated">摘要</h1><p id="c01a" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">最后，我希望这篇教程很好地说明了如何使用假设检验来开发一个更有意义的模型。我的建议是在你的分类管道中加入算法比较。尝试迭代以及尝试不同的算法性能比较。</p><p id="18e5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">感谢阅读！</p><h1 id="f7e6" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">参考</h1><ul class=""><li id="1162" class="ne nf it lt b lu lv lx ly ma ng me nh mi ni mm nv nk nl nm bi translated"><a class="ae ky" href="https://www.kaggle.com/competitions" rel="noopener ugc nofollow" target="_blank">赛车比赛</a></li><li id="22a9" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nv nk nl nm bi translated"><a class="ae ky" href="http://rasbt.github.io/mlxtend/" rel="noopener ugc nofollow" target="_blank"> MLxtend 库</a></li><li id="a4ed" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nv nk nl nm bi translated"><a class="ae ky" href="https://sci2s.ugr.es/keel/pdf/algorithm/articulo/dietterich1998.pdf" rel="noopener ugc nofollow" target="_blank">比较监督分类学习算法的近似统计检验</a> — Thomas Dietterich，1998</li><li id="3a58" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nv nk nl nm bi translated"><a class="ae ky" href="http://rasbt.github.io/mlxtend/user_guide/evaluate/paired_ttest_5x2cv/" rel="noopener ugc nofollow" target="_blank"> MLxtend.evaluate.5X2cv 配对 t 测试 API </a></li><li id="a2fe" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nv nk nl nm bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/datasets/index.html#general-dataset-api" rel="noopener ugc nofollow" target="_blank"> Sklearn 通用数据集 API </a></li><li id="204b" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nv nk nl nm bi translated"><a class="ae ky" href="https://www.kaggle.com/salmaeng/use-hypothesis-test-to-compare-algorithms/edit" rel="noopener ugc nofollow" target="_blank">可执行 kaggle 笔记本</a></li></ul></div></div>    
</body>
</html>