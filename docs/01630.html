<html>
<head>
<title>How to build a real-time fraud detection pipeline using Faust and MLFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用Faust和MLFlow构建实时欺诈检测管道</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-build-a-real-time-fraud-detection-pipeline-using-faust-and-mlflow-24e787dd51fa?source=collection_archive---------17-----------------------#2020-02-14">https://towardsdatascience.com/how-to-build-a-real-time-fraud-detection-pipeline-using-faust-and-mlflow-24e787dd51fa?source=collection_archive---------17-----------------------#2020-02-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f71a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">关于使用类似Kafka Streams的python库(Faust)和使用MLFlow服务的欺诈检测模型构建低延迟ML管道的教程</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/15cfc3dcea3cc24fa1abe0444a1d221a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Na45YxJbn2e5O3XcpKszDA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@jefflssantos?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">杰佛森·桑多斯</a>在<a class="ae ky" href="https://unsplash.com/s/photos/fraud?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="2fce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本教程中，我们将学习在本地启动一个Kafka集群，编写一个发送消息的生成器，创建一个简单的欺诈检测机器学习训练流程，通过REST接口公开模型，并进行实时预测。</p><p id="a62e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用的主要框架是:</p><ul class=""><li id="d10c" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><a class="ae ky" href="https://github.com/robinhood/faust/" rel="noopener ugc nofollow" target="_blank"> Faust </a>:流处理库，使用<a class="ae ky" href="https://en.wikipedia.org/wiki/Async/await" rel="noopener ugc nofollow" target="_blank"> async/away </a>范例，需要python 3.6以上版本</li><li id="5dbe" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://www.confluent.io/" rel="noopener ugc nofollow" target="_blank"> Kafka </a>:我们将使用Kafka的融合版本作为我们的流媒体平台</li><li id="ed05" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://www.mlflow.org" rel="noopener ugc nofollow" target="_blank"> MLFlow </a>:一个开源平台，用于监控和保存训练后的机器学习模型</li><li id="8a5e" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">Jupyter实验室:我们运行代码的环境</li></ul><p id="6c30" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还需要一些数据来进行培训。我们可以使用来自<a class="ae ky" href="https://www.kaggle.com/mlg-ulb/creditcardfraud/data#" rel="noopener ugc nofollow" target="_blank"> Kaggle信用卡欺诈竞赛</a>的CSV源。</p><p id="6880" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">TL；DR:代码在</strong><a class="ae ky" href="https://github.com/BogdanCojocar/medium-articles/tree/master/realtime_fraud_detection" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">GitHub</strong></a><strong class="lb iu">上。</strong></p><h2 id="b631" class="mj mk it bd ml mm mn dn mo mp mq dp mr li ms mt mu lm mv mw mx lq my mz na nb bi translated">第一步:进行培训</h2><p id="d0f2" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">让我们首先构建我们的欺诈检测模型。我们将读取代表信用卡交易的CSV数据，并在两个类<code class="fe nh ni nj nk b">0(not fraud)</code>和<code class="fe nh ni nj nk b">1(fraud)</code>之间应用简单的二元逻辑回归分类。</p><pre class="kj kk kl km gt nl nk nm nn aw no bi"><span id="11ac" class="mj mk it nk b gy np nq l nr ns">df = pd.read_csv('creditcard.csv')</span><span id="7b67" class="mj mk it nk b gy nt nq l nr ns">df.dtypes</span><span id="c1f2" class="mj mk it nk b gy nt nq l nr ns">Time      float64<br/>V1        float64<br/>V2        float64<br/>V3        float64<br/>V4        float64<br/>V5        float64<br/>V6        float64<br/>V7        float64<br/>V8        float64<br/>V9        float64<br/>V10       float64<br/>V11       float64<br/>V12       float64<br/>V13       float64<br/>V14       float64<br/>V15       float64<br/>V16       float64<br/>V17       float64<br/>V18       float64<br/>V19       float64<br/>V20       float64<br/>V21       float64<br/>V22       float64<br/>V23       float64<br/>V24       float64<br/>V25       float64<br/>V26       float64<br/>V27       float64<br/>V28       float64<br/>Amount    float64<br/>Class       int64</span></pre><p id="8f78" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我们所看到的，我们读取的大多数列都是<code class="fe nh ni nj nk b">float</code>，除了<code class="fe nh ni nj nk b">Class</code>，它是我们的目标变量。现在让我们开始训练:</p><pre class="kj kk kl km gt nl nk nm nn aw no bi"><span id="0969" class="mj mk it nk b gy np nq l nr ns">x_name = df.iloc[:, 1:30].columns<br/>y_name = df.iloc[:1, 30: ].columns</span><span id="ba0d" class="mj mk it nk b gy nt nq l nr ns">data_x = df[x_name]<br/>data_y = df[y_name]</span><span id="b427" class="mj mk it nk b gy nt nq l nr ns">train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, train_size=0.7, test_size=0.3)</span><span id="7914" class="mj mk it nk b gy nt nq l nr ns">model = LogisticRegression()<br/>model.fit(train_x, train_y.values.ravel())</span></pre><p id="28a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于特征，我们使用<code class="fe nh ni nj nk b">V1 — V28</code>和<code class="fe nh ni nj nk b">Amount</code>。我们在<code class="fe nh ni nj nk b">train</code>和<code class="fe nh ni nj nk b">test</code>数据之间进行分割，并拟合模型。我们可以检查一些性能指标:</p><pre class="kj kk kl km gt nl nk nm nn aw no bi"><span id="4036" class="mj mk it nk b gy np nq l nr ns">pred_y = model.predict(test_x)</span><span id="2fd5" class="mj mk it nk b gy nt nq l nr ns">accuracy_score(test_y, pred_y)<br/>0.9993094811745842</span><span id="da8d" class="mj mk it nk b gy nt nq l nr ns">f1_score(test_y, pred_y)<br/>0.7773584905660378</span><span id="b1ed" class="mj mk it nk b gy nt nq l nr ns">precision_score(test_y, pred_y)<br/>0.8272727272727273</span><span id="990b" class="mj mk it nk b gy nt nq l nr ns">recall_score(test_y, pred_y)<br/>0.6776315789473685</span></pre><p id="143d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们仅仅使用准确性作为衡量标准，我们可能会搬起石头砸自己的脚。始终使用更好的绩效指标，如<code class="fe nh ni nj nk b">f1_score</code>、<code class="fe nh ni nj nk b">precision</code>和<code class="fe nh ni nj nk b">recall</code>。</p><h2 id="e6b9" class="mj mk it bd ml mm mn dn mo mp mq dp mr li ms mt mu lm mv mw mx lq my mz na nb bi translated">步骤2:通过REST服务模型</h2><p id="b153" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">培训结束后，我们可以保存新的欺诈检测模型:</p><pre class="kj kk kl km gt nl nk nm nn aw no bi"><span id="2311" class="mj mk it nk b gy np nq l nr ns">mlflow.sklearn.save_model(model, path='./fraud_model')</span></pre><p id="de49" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们在MLFlow中使用<code class="fe nh ni nj nk b">sklearn</code>模块，因为这将帮助我们处理servis部分。</p><p id="de7f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们在项目的根目录下启动一个终端，并键入以下命令:</p><pre class="kj kk kl km gt nl nk nm nn aw no bi"><span id="0eb1" class="mj mk it nk b gy np nq l nr ns">mlflow models serve -m fraud_model</span></pre><p id="7cd7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这需要一点时间，因为除了部署微服务之外，还会创建一个<code class="fe nh ni nj nk b">conda</code>环境。这是为了确保下次我们进行部署时，我们将依赖关系锁定在某个版本和单独的虚拟环境中。如果一切运行正常，我们会注意到我们的服务有了一个url:</p><p id="6e4b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nh ni nj nk b">Listening at: <a class="ae ky" href="http://127.0.0.1:5000" rel="noopener ugc nofollow" target="_blank">http://127.0.0.1:5000</a></code></p><p id="043b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以使用<code class="fe nh ni nj nk b">cURL</code>从终端进行快速测试:</p><pre class="kj kk kl km gt nl nk nm nn aw no bi"><span id="01a7" class="mj mk it nk b gy np nq l nr ns">curl <a class="ae ky" href="http://127.0.0.1:9999/invocations" rel="noopener ugc nofollow" target="_blank">http://127.0.0.1:5000/invocations</a> -H 'Content-Type: application/json' -d '{<br/>    "columns":["V1","V2","V3","V4","V5","V6","V7","V8","V9","V10","V11","V12","V13","V14","V15","V16","V17","V18","V19","V20","V21","V22","V23","V24","V25","V26","V27","V28","Amount"],<br/>    "data":[[12.8,0.029,0.48,0.98,6.2,29.1,3.33,1.2,0.39,75.1,0.66,1.2,1.3,44.2,12.8,0.029,0.48,0.98,6.2,29,3.33,1.2,0.39,75.3,0.66,1.2,1.3,44.2,1.1]]<br/>}'</span></pre><p id="0b56" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们使用包含特性列和一组值的<code class="fe nh ni nj nk b">JSON</code>对象发送一个<code class="fe nh ni nj nk b">POST</code>请求。我们将从分类器<code class="fe nh ni nj nk b">[0]</code>中得到答案。</p><h2 id="6aaa" class="mj mk it bd ml mm mn dn mo mp mq dp mr li ms mt mu lm mv mw mx lq my mz na nb bi translated">步骤3:运行docker compose来启动kafka集群</h2><p id="cfae" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">为了构建集群，我们将使用一个<code class="fe nh ni nj nk b">docker-compose</code>文件来启动所有需要的docker容器:zookeeper和一个代理。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="a6b0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在简单地说，kafka是一个分布式流媒体平台，能够处理大量的消息，这些消息被组织或分组到主题中。为了能够并行处理一个主题，必须将它分成多个分区，来自这些分区的数据存储在称为代理的独立机器中。最后，zookeeper用于管理集群中代理的资源。为了读写kafka集群，我们需要一个代理地址和一个主题。</p><p id="aa7c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nh ni nj nk b">docker-compose</code>将启动端口<code class="fe nh ni nj nk b">2181</code>上的<code class="fe nh ni nj nk b">zookeper</code>，端口<code class="fe nh ni nj nk b">9092</code>上的<code class="fe nh ni nj nk b">kafka broker</code>。除此之外，我们使用另一个docker容器<code class="fe nh ni nj nk b">kafka-create-topic</code>的唯一目的是在kafka broker中创建一个主题(称为test)。</p><p id="7f5c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要启动kafka集群，我们必须在定义docker compose文件的同一文件夹中运行以下命令行指令:</p><pre class="kj kk kl km gt nl nk nm nn aw no bi"><span id="8416" class="mj mk it nk b gy np nq l nr ns">docker-compose up</span></pre><p id="6594" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这将启动所有带有日志的docker容器。我们应该在控制台中看到类似这样的内容:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/0e50dc642cabd20bf4d0fee9bac6930f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CGmKOW3EiRfBCa3oo9kHDQ.png"/></div></div></figure><h2 id="bc12" class="mj mk it bd ml mm mn dn mo mp mq dp mr li ms mt mu lm mv mw mx lq my mz na nb bi translated">第四步:运行卡夫卡制作程序</h2><p id="9dec" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">为了能够实时消费数据，我们首先必须将一些消息写入kafka。我们将使用python中的<code class="fe nh ni nj nk b">confluent_kafka</code>库来编写一个生产者:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="fd06" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将发送格式如下的<code class="fe nh ni nj nk b">JSON</code>消息:</p><pre class="kj kk kl km gt nl nk nm nn aw no bi"><span id="e08b" class="mj mk it nk b gy np nq l nr ns">{<br/>    "columns":["V1","V2","V3","V4","V5","V6","V7","V8","V9","V10","V11","V12","V13","V14","V15","V16","V17","V18","V19","V20","V21","V22","V23","V24","V25","V26","V27","V28","Amount"],<br/>    "data":[]<br/>}</span></pre><p id="489c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这与我们用于MLFlow web服务的格式相同，其中<code class="fe nh ni nj nk b">data</code>可以包含多个特性值列表。</p><p id="759c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于我们写入队列的每条消息，我们还需要分配一个键。我们将根据<code class="fe nh ni nj nk b">uuid</code>随机分配一个，以在集群中实现良好的分布。最后，我们还运行一个<code class="fe nh ni nj nk b">flush</code>命令来确保所有的消息都被发送出去。</p><p id="fbb3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦我们运行<code class="fe nh ni nj nk b">confluent_kafka_producer</code>，我们应该会收到一个日志，告诉我们数据已经正确发送:</p><pre class="kj kk kl km gt nl nk nm nn aw no bi"><span id="561e" class="mj mk it nk b gy np nq l nr ns">we’ve sent 6 messages to 127.0.0.1:9092</span></pre><h2 id="f9a9" class="mj mk it bd ml mm mn dn mo mp mq dp mr li ms mt mu lm mv mw mx lq my mz na nb bi translated">第五步:经营浮士德消费者</h2><p id="f10d" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">我们已经到达了教程的最后一步。使用Faust框架，我们将运行一个简单的worker，它将使用来自Kafka的数据，并将预测应用到新功能上。我们需要为此创建一个单独的python脚本。首先，我们定义我们的Faust应用程序，以及主题:</p><pre class="kj kk kl km gt nl nk nm nn aw no bi"><span id="cb68" class="mj mk it nk b gy np nq l nr ns">app = faust.App(<br/>    'fraud_detection_app',<br/>    broker='kafka://localhost:9092',<br/>    value_serializer='raw',<br/>)</span><span id="d69e" class="mj mk it nk b gy nt nq l nr ns">kafka_topic = app.topic('test')</span></pre><p id="f650" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们定义从中读取数据的代理和序列化程序格式。我们很乐意使用<code class="fe nh ni nj nk b">raw</code>，因为我们只是将数据传递给机器学习算法。</p><p id="4e9e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们定义协程。在浮士德框架中，它被称为<code class="fe nh ni nj nk b">agent</code>:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="8e38" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">代理是一个异步进程。我们连接到Kafka主题，对于我们读取的每个值，我们调用REST服务并获得结果。正如预期的那样，在Kafka中有了新的值之后，它会立即运行。</p><p id="3459" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">剧本定稿了。姑且称之为<code class="fe nh ni nj nk b">fraud_detection_worker.py</code>。现在我们可以运行它了。从项目根目录的终端开始，我们需要键入:</p><pre class="kj kk kl km gt nl nk nm nn aw no bi"><span id="2c39" class="mj mk it nk b gy np nq l nr ns">faust -A fraud_detection_worker worker -l info</span></pre><p id="1d45" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这将启动一个worker，它是应用程序的一个实例。如果我们需要更多的计算能力，我们可以启动额外的工人。</p><p id="cfb8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果一切运行正常，我们将开始看到以下日志:</p><pre class="kj kk kl km gt nl nk nm nn aw no bi"><span id="7d7e" class="mj mk it nk b gy np nq l nr ns">Input data: b'{"columns": ["V1", "V2", "V3", "V4", "V5", "V6", "V7", "V8", "V9", "V10", "V11", "V12", "V13", "V14", "V15", "V16", "V17", "V18", "V19", "V20", "V21", "V22", "V23", "V24", "V25", "V26", "V27", "V28", "Amount"], "data": [[12.8, 0.029, 0.48, 0.98, 6.2, 29.1, 3.33, 1.2, 0.39, 75.1, 0.66, 11.2, 1.3, 0.2, 12.8, 0.029, 0.45, 0.98, 6.2, 29, 3.33, 1.2, 0.39, 75.3, 0.3, 2.2, 1.3, 2.2, 1.01]]}'</span><span id="359e" class="mj mk it nk b gy nt nq l nr ns">Fraud detection result: [0]</span></pre><p id="d14f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们已经到了本教程的结尾。我希望你喜欢它，并发现它有用。我们看到了现在如何选择使用纯python框架来进行实时数据处理。这是一个很大的优势，因为这种编程语言中有很多数据科学工作。</p></div></div>    
</body>
</html>