<html>
<head>
<title>Review of LeNet-5: How to design the architecture of CNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">LeNet-5述评:如何设计CNN的架构</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/review-of-lenet-5-how-to-design-the-architecture-of-cnn-8ee92ff760ac?source=collection_archive---------51-----------------------#2020-04-20">https://towardsdatascience.com/review-of-lenet-5-how-to-design-the-architecture-of-cnn-8ee92ff760ac?source=collection_archive---------51-----------------------#2020-04-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4cae" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">整合知识以定制CNN的架构</h2></div><p id="1bc5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这篇文章是对一篇旧的、困难的、鼓舞人心的论文的评论:<strong class="kh ir">基于梯度的学习应用于文档识别</strong>【1】由Yann LeCun作为第一作者。你可以找到这篇论文的许多评论。他们中的大多数只关注卷积神经网络(<em class="lb"> CNN </em> ) LeNet-5的架构。然而，我想谈谈其他一些有趣的问题:</p><ol class=""><li id="136a" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">从反向传播的角度看全局可训练系统的概念</li><li id="5d3c" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">如何在神经网络的设计过程中整合知识</li></ol><p id="1104" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">事实上，本文中提到了2个网络。第一个是<em class="lb"> CNN </em>，名为LeNet-5，第二个叫图变网络(<em class="lb"> GTN </em>)。在这篇文章中，我只谈论LeNet-5。</p><h1 id="35b2" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">1.全球可训练系统</h1><h1 id="9e8d" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">什么是全球可培训系统？</h1><p id="768b" class="pw-post-body-paragraph kf kg iq kh b ki mi jr kk kl mj ju kn ko mk kq kr ks ml ku kv kw mm ky kz la ij bi translated">一个系统通常包括几个模块。从反向传播的角度来看，如果所有的模块都是可微的，模块之间的连接也是可微的，换句话说，梯度的反向传播可以从末端的损失函数回溯到输入，这是一个全局可训练的系统。有时，我们也称之为机器学习问题的端到端解决方案。</p><p id="b357" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我举个例子:我们想在一个图像中标注所有人脸的性别？第一种解决方案是检测所有人脸的位置，然后用只有一张人脸的子图像进行性别分类。第二种解决方案是创建一个模型，该模型将图像作为输入，输出人脸的定位以及相应的性别。在第一种解决方案中，来自定位的误差影响性别分类的性能。但是如果这两个模块是分开的，我们不能使用性别分类的损失函数来优化定位的性能。在第二种端到端解决方案中，定位和性别检测是全局优化的。</p><h1 id="ec5e" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">全球可培训系统的优势是什么？</h1><p id="8fcb" class="pw-post-body-paragraph kf kg iq kh b ki mi jr kk kl mj ju kn ko mk kq kr ks ml ku kv kw mm ky kz la ij bi translated">如前所述，我们一起优化所有模块。如果我们有足够的数据，相对于非全局可训练系统，该系统可以实现更好的性能。</p><p id="e762" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">另一个更重要的优势是:让机器从数据中学习。如果你熟悉<em class="lb"> CNN </em>，你大概听说CNN的前几个隐层可以学习图像的强局部模式。以下是论文<a class="ae mn" href="https://sheng-fang.github.io/2020-04-19-review_lenet/#2" rel="noopener ugc nofollow" target="_blank">【2】</a>中的图片1中的一些例子。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi mo"><img src="../Images/7f4069b38ac8abd47f50198c1e6e49ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bZsmOjaScg2o155SU90ORQ.png"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated">图CNN图层的可视化<br/>一个训练过的AlexNet的第一个CONV图层(左)和第二个CONV图层(右)上的典型滤镜。(来自<a class="ae mn" href="https://cs231n.github.io/understanding-cnn/" rel="noopener ugc nofollow" target="_blank">https://cs231n.github.io/understanding-cnn/</a></p></figure><p id="1b0d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在传统的解决方案中，我们经常给机器学习模型输入手工设计的特征，如<em class="lb">筛</em>、<em class="lb">拱</em>、<em class="lb">等。</em>借助全球可训练系统，我们可以让数据告诉我们，对于某项任务，哪些是最重要的特征。</p><h1 id="43bd" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">2.用知识设计CNN</h1><p id="7d91" class="pw-post-body-paragraph kf kg iq kh b ki mi jr kk kl mj ju kn ko mk kq kr ks ml ku kv kw mm ky kz la ij bi translated">为了从神经网络中获得自学习特性，我们必须为神经网络设计一个好的结构。Yann LuCun在他的论文中指出，如果没有关于任务的最少量的先验知识，任何学习技术都不可能成功。….整合知识的一个好方法是根据任务定制架构。现在让我们关注在设计一个<em class="lb"> CNN </em>的架构时如何与知识结合。</p><p id="2ad9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">1962年，Hubel和Wiesel[3]揭示了猫视觉系统中的局部敏感、方向选择性神经元。在局部连接的约束下，神经元可以学习一些基本的视觉特征，这些特征可以在下一个神经元中被重用或分组以形成新的特征。卷积核可以很好地实现感受野的这种约束。</p><p id="5f02" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在此之前，我们找到了一个很好的工具——卷积核来模拟局部敏感的方向选择性神经元。那么如何才能克服图像分类的一些常见困难:平移、尺度、畸变不变性。</p><p id="7354" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们首先检查人类是如何实现图像分类的。我们可能会这样做:</p><ol class=""><li id="5588" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">用一些视觉模式扫描图像，找到一些特征</li><li id="2727" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">找出特征之间的关系</li><li id="dca9" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">在我们大脑的模式数据库中搜索关系模式</li><li id="4a01" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">找到最相似的一个</li></ol><p id="8050" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了实现步骤1，我们可以为同一个特征图固定卷积核的权重，并生成几个特征图。</p><p id="068b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了实现步骤2，我们认为该特征的确切位置不如该特征相对于其他特征的位置重要。因此，我们可以逐步降低空间分辨率(子采样)。然而，当降低图像分辨率时，我们丢失了信息。这就是为什么我们需要增加特征图的数量，尽可能的保留有用的信息。</p><p id="6ad5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有了这些知识，我们就有了设计CNN的一般原则。</p><ol class=""><li id="3bed" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">使用卷积核</li><li id="7c07" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">共享权重</li><li id="33f9" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">子采样和增加特征图的数量</li></ol><h1 id="9e6a" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">3.LeNet架构</h1><h1 id="af06" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">3–1.LeNet-5</h1><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi ne"><img src="../Images/5529dc58d1ee2a0d14abe1f4890ab6ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PXworfAP2IombUzBsDMg7Q.png"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated">图2:LeNet-5的架构(来自<a class="ae mn" href="http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf" rel="noopener ugc nofollow" target="_blank">http://vision . Stanford . edu/cs 598 _ spring 07/papers/le Cun 98 . pdf</a>)</p></figure><p id="c0db" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">图2[1]显示了<em class="lb"> LeNet-5 </em>的架构。</p><h1 id="ca21" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">3–2.增强LeNet-4</h1><p id="8b54" class="pw-post-body-paragraph kf kg iq kh b ki mi jr kk kl mj ju kn ko mk kq kr ks ml ku kv kw mm ky kz la ij bi translated"><em class="lb"> LeNet-4 </em>是<em class="lb"> LeNet-5 </em>的简化版。它包含4个一级特征图，后面是16个子采样图。我们认为<em class="lb"> LeNet-4 </em>与<em class="lb"> LeNet-5 </em>相比是一个较弱的分类器。Yann LuCun将助推技术应用于<em class="lb"> LeNet-4 </em>，标记为boosted <em class="lb"> LeNet-4 </em>。boosting方法达到了比<em class="lb"> LeNet-5 </em>更好的性能精度。</p><h1 id="5e00" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">4.其他有趣的地方</h1><p id="a44b" class="pw-post-body-paragraph kf kg iq kh b ki mi jr kk kl mj ju kn ko mk kq kr ks ml ku kv kw mm ky kz la ij bi translated">在机器学习的研究领域，我们总是提到开发新方法的三个关键方面。Yann LuCun在他的论文中也提到了这些:</p><ol class=""><li id="a189" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">高计算能力的机器成本低</li><li id="5e50" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">大型数据库可用</li><li id="5b17" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">强大的机器学习技术是可用的</li></ol><p id="c96e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们自己的产品也要考虑这些因素。</p><h1 id="6213" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">5.结论</h1><p id="77d7" class="pw-post-body-paragraph kf kg iq kh b ki mi jr kk kl mj ju kn ko mk kq kr ks ml ku kv kw mm ky kz la ij bi translated">在这篇文章中，我分享了我对如何设计神经网络的理解。我相信这对实现和修改一个<em class="lb"> CNN的实践是有帮助的。</em></p><p id="2250" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">总而言之:</p><ol class=""><li id="a827" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">在开始机器学习项目之前，检查计算能力、可用数据库、技术支持。</li><li id="6b84" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">一旦项目开始，尽可能多地获取关于项目的先验知识。</li><li id="b981" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">利用这些知识来设计您自己的网络。</li></ol><h1 id="d8e1" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">参考</h1><p id="8e79" class="pw-post-body-paragraph kf kg iq kh b ki mi jr kk kl mj ju kn ko mk kq kr ks ml ku kv kw mm ky kz la ij bi translated">[1] LeCun，Yann and Bottou，Léon and Bengio，Yoshua and Haffner，Patrick <em class="lb">基于梯度的学习应用于文档识别</em> IEEE，1998</p><p id="906e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[2] <a class="ae mn" href="https://cs231n.github.io/understanding-cnn/" rel="noopener ugc nofollow" target="_blank">理解和可视化卷积神经网络</a></p><p id="f576" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[3] D. H. Hubel，T. N. Wiesel，猫视觉皮层中的感受野、双眼互动和功能结构《生理学杂志》，1962年</p></div></div>    
</body>
</html>