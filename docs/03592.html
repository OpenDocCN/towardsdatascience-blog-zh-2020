<html>
<head>
<title>Generative vs. Discriminative Probabilistic Graphical Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成性与鉴别性概率图形模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generative-vs-2528de43a836?source=collection_archive---------9-----------------------#2020-04-05">https://towardsdatascience.com/generative-vs-2528de43a836?source=collection_archive---------9-----------------------#2020-04-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="671a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">朴素贝叶斯和逻辑回归的比较</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c81722b567146c773744a0fb19a56a93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*X_WtXb2MJMqgGdC1"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者照片</p></figure><p id="686f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">生成模型和判别模型是广泛使用的机器学习模型。例如，逻辑回归、支持向量机和条件随机场是流行的判别模型；朴素贝叶斯、贝叶斯网络和隐马尔可夫模型是常用的生成模型。</p><p id="4bef" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">概率图形模型(PGM)是一个丰富的框架，用于编码复杂域上的概率分布，如大量相互作用的随机变量的联合分布。</p><p id="3c51" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，我们将以朴素贝叶斯和逻辑回归为例，将生成模型和判别模型的图形结构作为 PGM 进行探索。我们还将讨论这些模型的相似之处和不同之处。</p><h1 id="4dcd" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">模型结构</h1><p id="e9d6" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">假设我们正在解决一个分类问题，根据邮件中的单词来决定一封邮件是否是垃圾邮件。我们有一个联名款的标签<strong class="la iu"> Y=y </strong>，特点是<strong class="la iu"> X={x <em class="mr"> 1 </em>，x <em class="mr"> 2 </em>，…x <em class="mr"> n </em> } </strong>。模型的联合分布可以表示为<strong class="la iu"> p(Y，X) = P(y，x <em class="mr"> 1 </em>，x <em class="mr"> 2 </em> …x <em class="mr"> n </em> ) </strong>。我们的目标是估计垃圾邮件的概率:<strong class="la iu"> P(Y=1|X) </strong>。生成模型和判别模型都可以解决这个问题，但方式不同。</p><p id="3d12" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们看看它们为什么以及如何不同！</p><p id="3800" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了得到条件概率<strong class="la iu"> P(Y|X) </strong>，生成模型从训练数据中估计先验<strong class="la iu"> P(Y) </strong>和似然<strong class="la iu"> P(X|Y) </strong>，并使用贝叶斯规则计算后验<strong class="la iu">P(Y | X)</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/13b35eb63bf19f6d16dfe4543ad83c48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l-3JCT9qwxWyLP_iVbzBmA.png"/></div></div></figure><p id="c499" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">另一方面，判别模型直接假定<strong class="la iu"> P(Y|X) </strong>的函数形式，并且<strong class="la iu"> </strong>直接从训练数据估计<strong class="la iu"> P(Y|X) </strong>的参数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/0128bb4f6ab587bda1f98ab4bb50e1fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/0*FK1iOk3L6ZKlS-to"/></div></figure><p id="ad5a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">上图显示了生成模型和判别模型的结构差异。圆圈代表变量，线的方向表示我们可以推断的概率。在我们的垃圾邮件分类问题中，给定 X:电子邮件中的单词，Y 是未知的。我们看到判别模型图(右)中的箭头从 X 指向 Y，这表明我们可以直接从给定的 X 推断出<strong class="la iu"> P(Y|X) </strong>，然而，生成模型图(左)中的箭头指向相反的方向，这意味着我们需要首先从数据中推断出<strong class="la iu"> P(Y) </strong>和<strong class="la iu"> P(X|Y) </strong>的值，并使用它们来计算<strong class="la iu"> P(Y|X) </strong>。</p><h1 id="55fc" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">数学推导</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/7d5d5b99397aadb18f524de6bf3246ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*izRWbqiP3gebLqqQ"/></div></div></figure><p id="6b63" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">上图显示了扩展特征 X 时这两个模型的潜在概率分布。我们可以看到，每个特征 x <em class="mr"> i </em>依赖于前面所有的特征:{x <em class="mr"> 1 </em>，x <em class="mr"> 2 </em> …x( <em class="mr"> i-1) </em> }。这不会影响判别模型，因为它们只是将 X 视为给定的事实，并且它们需要估计的只是 P(Y|X ),但是这使得生成模型中的计算变得困难。</p><ol class=""><li id="40c0" class="mv mw it la b lb lc le lf lh mx ll my lp mz lt na nb nc nd bi translated"><strong class="la iu">生成模型(朴素贝叶斯)</strong></li></ol><p id="2069" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">后验概率可以写成:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/6f477fcd49e4dc878cddf666f88bbdcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UnPN7op46r68wmsoGJzvKQ.png"/></div></div></figure><p id="e65e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们看到所有 X 的依赖性使得很难推断 P(X|Y ),因为我们需要将 x <em class="mr"> i </em>的概率限制在 Y 和{x <em class="mr"> 1 </em>，x <em class="mr"> 2 </em> …x( <em class="mr"> i-1) </em> }上。为了简化问题，我们假设所有的 X 是条件独立的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nf"><img src="../Images/834d064fabd0aabfe1b6da11674c2fd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*OzMfYccVljBckz0-CmsXvQ.png"/></div></div></figure><p id="6114" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">有了这个假设，现在我们可以将后验分布改写为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/52e2935ee3ea04d144b78e8cf83ae759.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tH3wxliSnV9u87-wQrPlJg.png"/></div></div></figure><p id="0e57" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">创成式模型的图形结构也发生了变化:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/fa64e3924da2d4b9defaec413baa6845.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2wPiqUZXUmrdpCok"/></div></div></figure><p id="c4d8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> 2。判别模型(逻辑回归)</strong></p><p id="02e8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如前所述，我们可以利用训练数据直接估计判别模型的后验概率:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/00f0b82fd463ac196930f3d0a3e0197e.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*XOCcn147QLIQ3wH3Rex-Bw.png"/></div></figure><p id="5bba" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在逻辑回归中，我们将后验概率参数化为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/4f583d98f90e26ef74be1285b2287acb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4SA1kQj6D2eKfJhMBhAgrA.png"/></div></div></figure><p id="95ef" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最大似然估计用于估计参数。</p><h1 id="a457" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">比较</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/6a36736262f3ccf4cef4079ed6b4e5cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GQuNHwat5yq6PBsQ"/></div></div></figure><p id="266f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">1.准确(性)</p><p id="5563" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当不满足条件独立性的假设时，生成模型不如判别模型精确。比如在我们的垃圾邮件分类问题中，让<strong class="la iu"> x <em class="mr"> 1 </em> =邮件数据中“银行”出现的次数</strong>，邮件数据中<strong class="la iu"> x <em class="mr"> 2 </em> =邮件中“账户”出现的次数</strong>。不管是否垃圾，这两个词总是一起出现，即 x <em class="mr"> 1 </em> = x <em class="mr"> 2。</em>在朴素贝叶斯中学习得到<strong class="la iu">p(x<em class="mr">1</em>| y)= p(x2 | y)</strong>，对证据进行双重计数。逻辑回归没有这个问题，因为它可以设置α1=0 或α2=0。</p><p id="d973" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">2.缺失数据</p><p id="ae72" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">生成模型可以处理缺失数据，而判别模型通常不能。在生成模型中，我们仍然可以通过忽略看不见的变量来估计后验概率:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/42c2ae86387874796290cdcf2f829aa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0XEpAckNgXjAxiuoKfWKPA.png"/></div></div></figure><p id="5c22" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然而，判别模型通常需要观察所有的特征 X。</p><p id="c515" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">3.表演</p><p id="541c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">与判别模型相比，生成模型需要较少的数据来训练。这是因为生成模型在做出更强的假设(条件独立性假设)时更有偏见。</p><p id="9cc0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">4.应用</p><p id="86fb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">判别模型之所以“判别”，是因为它有用但只对判别 Y 的标签有用，所以只能解决分类问题。除了分类之外，生成模型还有更多应用，例如抽样、贝叶斯学习、映射推理。</p><h1 id="b028" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">结论</h1><p id="0cb5" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">生成模型和判别模型都是我们用来解决机器学习问题的非常有用的模型。使用哪种模型取决于用例及数据。一般来说，当我们对数据的基本分布有一个概念并希望找到该分布的隐藏参数时，通常使用生成模型，而当我们只想找到将数据分成不同类的边界时，判别模型更适合。</p></div></div>    
</body>
</html>