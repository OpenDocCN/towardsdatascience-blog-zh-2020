<html>
<head>
<title>Preprocessing Data: Feature Scaling</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">预处理数据:特征缩放</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/preprocessing-data-feature-scaling-cc28c508e8af?source=collection_archive---------37-----------------------#2020-07-08">https://towardsdatascience.com/preprocessing-data-feature-scaling-cc28c508e8af?source=collection_archive---------37-----------------------#2020-07-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="561b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">sklearn 的一些重要特征缩放技术</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c5cea91b3597439fc8d612e071db1584.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*omkDxD8WNxlkfCOGl9hQ3Q.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由来自<a class="ae ky" href="https://www.pexels.com/photo/assorted-type-and-size-utility-cutters-on-clear-and-green-olfa-measuring-tool-near-adhesive-tape-rolls-1409216/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">佩克斯</a>的<a class="ae ky" href="https://www.pexels.com/@adonyi-gabor-604571?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">阿多尼·加博尔</a>拍摄</p></figure><p id="3357" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一般来说，在更新每个机器学习模型的特征时，特征缩放是一个必要甚至是必不可少的步骤。<em class="lv">为什么这很重要？</em>很简单，因为我们用于预测或聚类的每个算法背后都隐藏着一些数学公式。这些数学公式几乎没有意识到每个要素之间的数值范围的变化，当涉及到梯度下降时，这一点是显而易见的！</p><p id="1466" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">事实上，未经缩放的数据会导致可视化困难，更重要的是，它们会降低许多机器学习算法的预测性能。这种类型的数据也可以减缓许多基于梯度的估计量的收敛，或者完全阻止它。</p><p id="b6f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">事实上，许多估计量是在假设所有特征在可比尺度上变化的情况下设计的。特别是，基于梯度的估计器通常假设训练数据已经标准化(具有单位方差的中心特征)。一个显著的例外是基于决策树的估计器，它对数据的任意缩放都是鲁棒的。</p><p id="6ef6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们举一个例子:假设你正在进行房价预测，你将拥有以下类型的特征:价格、表面、房间数量等。当然，这个数据框架的价值尺度根据特征是完全不同的。但是，您必须使用相同的算法来处理它们。这就是特性缩放的必要性所在！您的算法确实需要混合[0… 100，000]美元的价格、[10… 500]平方米的面积、从[1..10]房间。因此，缩放包括将这些数据放在同一级别。</p><blockquote class="lw"><p id="03fc" class="lx ly it bd lz ma mb mc md me mf lu dk translated">如果您没有明智地应用特征缩放，您将会观察到缓慢的学习和降低的性能。</p></blockquote><p id="c370" class="pw-post-body-paragraph kz la it lb b lc mg ju le lf mh jx lh li mi lk ll lm mj lo lp lq mk ls lt lu im bi translated">幸运的是，<a class="ae ky" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> Scikit-Learn </strong> </a>将帮助我们再次完成这项工作，但是在使用任何技术之前，我们必须了解每种技术是如何工作的。</p><p id="41df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">基本上，<strong class="lb iu">Scikit-Learn</strong>(<a class="ae ky" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing" rel="noopener ugc nofollow" target="_blank">sk Learn .预处理</a>)提供了几种缩放技术，我们将回顾 4:</p><ul class=""><li id="1d08" class="ml mm it lb b lc ld lf lg li mn lm mo lq mp lu mq mr ms mt bi translated">标准缩放器</li><li id="4ca2" class="ml mm it lb b lc mu lf mv li mw lm mx lq my lu mq mr ms mt bi translated">最小最大缩放器</li><li id="02c9" class="ml mm it lb b lc mu lf mv li mw lm mx lq my lu mq mr ms mt bi translated">MaxAbsScaler</li><li id="7808" class="ml mm it lb b lc mu lf mv li mw lm mx lq my lu mq mr ms mt bi translated">鲁棒定标器</li></ul><p id="c2a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们将创建随机数据集以及一些图形函数，这将有助于我们更好地理解上述不同技术的效果。</p><p id="1069" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是 Python 代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="e951" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这段代码中，除了 trace 函数之外，我们还在一个 DataFrame (Pandas)中创建了 6 个数据集。</p><p id="71e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看我们的数据集是什么样的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/19a723c387eae83431534d519406c251.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9-7XXMOr0nUltn9Jg_A6WA.png"/></div></div></figure><h2 id="5d7c" class="nc nd it bd ne nf ng dn nh ni nj dp nk li nl nm nn lm no np nq lq nr ns nt nu bi translated">标准缩放器</h2><p id="bf13" class="pw-post-body-paragraph kz la it lb b lc nv ju le lf nw jx lh li nx lk ll lm ny lo lp lq nz ls lt lu im bi translated">我们将从风险可能最小的:StandardScaler()开始我们的缩放技术之旅。</p><p id="320b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种技术假设数据是正态分布的。该函数将重新计算每个特征，以便数据以 0 和 1 为中心。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/13cab45ed24cd9d8dc6ae32fc56be9cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:308/format:webp/1*CXF1tD86Nsf9Xl4vWSMRow.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">标准化公式统计</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mz na l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/4c8ae99b3134684a8b7e5de96bdc8e4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r3iOtVYKoQTIpphXuOzvfw.png"/></div></div></figure><p id="2311" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，标准化去除了平均值，并将数据缩放到单位方差。然而，当计算经验平均值和标准偏差时，异常值仍然有影响。</p><h2 id="54ff" class="nc nd it bd ne nf ng dn nh ni nj dp nk li nl nm nn lm no np nq lq nr ns nt nu bi translated">最小最大缩放器</h2><p id="412a" class="pw-post-body-paragraph kz la it lb b lc nv ju le lf nw jx lh li nx lk ll lm ny lo lp lq nz ls lt lu im bi translated">这种技术通过在给定的范围(默认为[0，1])上调整来变换每个特征(x)。可以通过参数 feature_range = tuple (min，max)更改该范围。为了简单起见，下面是每个特征的变换公式:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/b6b21e5d3ce6f1ebd735fb4b3a5b8ca5.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/format:webp/1*VyeD8Gd9uBsx7-WvBqy91A.png"/></div></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mz na l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/c8dc2c0a8ef84c10e7f1f7509401ffce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bssNfrg7qHX_flK_6k2uFA.png"/></div></div></figure><p id="210e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果这种技术可能是最广为人知的，那么它特别适用于分布不是高斯分布或者标准差很小的情况。但是，MinMaxScaler()对异常值非常敏感。在这种情况下，我们快速切换到最后一种技术:RobustScaler()。</p><h2 id="4e28" class="nc nd it bd ne nf ng dn nh ni nj dp nk li nl nm nn lm no np nq lq nr ns nt nu bi translated">MaxAbsScaler</h2><p id="5be4" class="pw-post-body-paragraph kz la it lb b lc nv ju le lf nw jx lh li nx lk ll lm ny lo lp lq nz ls lt lu im bi translated">当值的分布很稀疏并且有很多整数时，这种缩放技术很有用。绝对值映射在范围[0，1]内。事实上，对于只有正值的数据，此缩放器的行为与 MinMaxScaler()类似，因此也存在较大的异常值。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mz na l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/b93c7716cee413dd9eb9699ec6239ae6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eszpSAqOKPOwwG_XRa0qgw.png"/></div></div></figure><h2 id="7fed" class="nc nd it bd ne nf ng dn nh ni nj dp nk li nl nm nn lm no np nq lq nr ns nt nu bi translated">鲁棒定标器</h2><p id="b128" class="pw-post-body-paragraph kz la it lb b lc nv ju le lf nw jx lh li nx lk ll lm ny lo lp lq nz ls lt lu im bi translated">RobustScaler()技术使用与 MinMaxScaler()相同的缩放原理。但是，它使用四分位数范围而不是最小-最大值，这使得它在异常值方面更加可靠。以下是重新加工特征的公式:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/f886a3ec975e54dc916ae3d76cc7ef29.png" data-original-src="https://miro.medium.com/v2/resize:fit:328/format:webp/0*SWerwlrP1YT9BpS3.jpg"/></div></figure><ul class=""><li id="33de" class="ml mm it lb b lc ld lf lg li mn lm mo lq mp lu mq mr ms mt bi translated">Q1 (x):第一个分位数/ 25%</li><li id="dc03" class="ml mm it lb b lc mu lf mv li mw lm mx lq my lu mq mr ms mt bi translated">Q3 (x):第三个分位数/ 75%</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mz na l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/bc94f57275a7d1241c1c465c8229b1a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Eqo4qiHNVVWxTvBbwOEPYw.png"/></div></div></figure><p id="a59e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与以前的缩放器不同，这个缩放器使用一些基于百分位数的居中和缩放统计数据。因此，它们不受非常大的边际异常值的影响。因此，变换后的特征值的结果范围比先前的定标器更大，更重要的是，大致相似。</p><h1 id="3c07" class="od nd it bd ne oe of og nh oh oi oj nk jz ok ka nn kc ol kd nq kf om kg nt on bi translated">结论</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/871cbb3de80a580032620c09ec4a8eb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_CudcR5gky8hEgcEEJYr5A.png"/></div></div></figure><p id="7447" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们总结一下我们刚刚遇到的特征缩放技术:</p><ul class=""><li id="3d55" class="ml mm it lb b lc ld lf lg li mn lm mo lq mp lu mq mr ms mt bi translated">使用<code class="fe op oq or os b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">MinMaxScaler</strong></a></code>或<code class="fe op oq or os b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">MaxAbsScaler</strong></a></code>可以将特征缩放到一个范围，通常在零和一之间。</li><li id="9b71" class="ml mm it lb b lc mu lf mv li mw lm mx lq my lu mq mr ms mt bi translated"><code class="fe op oq or os b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">MaxAbsScaler</strong></a></code>是专门为缩放稀疏数据而设计的，<code class="fe op oq or os b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">RobustScaler</strong></a></code>不能适用于稀疏输入，但您可以对稀疏输入使用<code class="fe op oq or os b">transform</code>方法。</li><li id="dd58" class="ml mm it lb b lc mu lf mv li mw lm mx lq my lu mq mr ms mt bi translated">如果您的数据包含许多异常值，使用数据的平均值和方差进行缩放可能不会很好。在这种情况下，你需要用<code class="fe op oq or os b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">RobustScaler</strong></a></code>来代替。</li></ul><p id="b30f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇文章所基于的 Jupyter 笔记本可以在<a class="ae ky" href="https://github.com/chouhbik/FeaturesScaling/blob/master/Feature%20Scaling.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h1 id="2c15" class="od nd it bd ne oe of og nh oh oi oj nk jz ok ka nn kc ol kd nq kf om kg nt on bi translated">参考</h1><ul class=""><li id="de32" class="ml mm it lb b lc nv lf nw li ot lm ou lq ov lu mq mr ms mt bi translated">比较不同标量对有异常值的数据的影响。<a class="ae ky" href="https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/auto _ examples/preprocessing/plot _ all _ scaling . html</a></li><li id="83d3" class="ml mm it lb b lc mu lf mv li mw lm mx lq my lu mq mr ms mt bi translated">预处理数据。<a class="ae ky" href="https://scikit-learn.org/stable/modules/preprocessing.html#" rel="noopener ugc nofollow" target="_blank">https://scikit-learn.org/stable/modules/preprocessing.html</a></li><li id="4fa9" class="ml mm it lb b lc mu lf mv li mw lm mx lq my lu mq mr ms mt bi translated">我应该标准化数据吗？<a class="ae ky" href="http://www.faqs.org/faqs/ai-faq/neural-nets/part2/section-16.html" rel="noopener ugc nofollow" target="_blank">http://www . FAQs . org/FAQs/ai-FAQ/neural-nets/part 2/section-16 . html</a></li></ul></div></div>    
</body>
</html>