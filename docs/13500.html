<html>
<head>
<title>Learning from Audio: Wave Forms</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从音频中学习:波形</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/learning-from-audio-wave-forms-46fc6f87e016?source=collection_archive---------22-----------------------#2020-09-16">https://towardsdatascience.com/learning-from-audio-wave-forms-46fc6f87e016?source=collection_archive---------22-----------------------#2020-09-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4701" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">波形介绍和零数据处理。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/e33b6e4daf15fdc6daf629a4fbbf218c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fY8sblnIvFC-Z-am"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">乔纳森·贝拉斯克斯在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h2 id="74e0" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">相关文章:</h2><ul class=""><li id="3bbd" class="lv lw it lx b ly lz ma mb li mc lm md lq me mf mg mh mi mj bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/learning-from-audio-time-domain-features-4543f3bda34c">从音频中学习:时域特征</a></li><li id="2734" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf mg mh mi mj bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/learning-from-audio-fourier-transformations-f000124675ee">从音频中学习:傅立叶变换</a></li><li id="812b" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf mg mh mi mj bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/learning-from-audio-spectrograms-37df29dba98c">从音频中学习:频谱图</a></li><li id="874f" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf mg mh mi mj bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/learning-from-audio-the-mel-scale-mel-spectrograms-and-mel-frequency-cepstral-coefficients-f5752b6324a8">从音频中学习:梅尔标度、梅尔频谱图和梅尔频率倒谱系数</a></li><li id="4387" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf mg mh mi mj bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/learning-from-audio-pitch-and-chromagrams-5158028a505">从音频中学习:音高和色度图</a></li></ul><h1 id="9915" class="mp la it bd lb mq mr ms le mt mu mv lh jz mw ka ll kc mx kd lp kf my kg lt mz bi translated">简介:</h1><p id="60b2" class="pw-post-body-paragraph na nb it lx b ly lz ju nc ma mb jx nd li ne nf ng lm nh ni nj lq nk nl nm mf im bi nn translated"><span class="l no np nq bm nr ns nt nu nv di">答</span> udio 是一个极其丰富的数据源。根据<code class="fe nw nx ny nz b">sample rate</code> — <em class="oa">每秒采样的点数来量化信号</em> —一秒钟的数据可能包含数千个点。将这扩展到数小时的录音，你可以看到机器学习和数据科学如何与信号处理技术完美地交织在一起。</p><p id="0ec7" class="pw-post-body-paragraph na nb it lx b ly ob ju nc ma oc jx nd li od nf ng lm oe ni nj lq of nl nm mf im bi translated">这篇文章旨在分析到底什么是波形，并利用 Python 中的<code class="fe nw nx ny nz b">librosa</code>进行分析和可视化——与<code class="fe nw nx ny nz b">numpy</code>和<code class="fe nw nx ny nz b">matplotlib</code>一起。</p></div><div class="ab cl og oh hx oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="im in io ip iq"><h1 id="90f8" class="mp la it bd lb mq on ms le mt oo mv lh jz op ka ll kc oq kd lp kf or kg lt mz bi translated">波形:</h1><p id="e462" class="pw-post-body-paragraph na nb it lx b ly lz ju nc ma mb jx nd li ne nf ng lm nh ni nj lq nk nl nm mf im bi translated"><code class="fe nw nx ny nz b">Waves</code>是重复的<code class="fe nw nx ny nz b">signals</code>，根据它们的复杂程度，在振幅上振荡和变化。在现实世界中，<code class="fe nw nx ny nz b">waves</code>是连续的、机械的——这与离散的、数字化的计算机截然不同。</p><p id="f8e6" class="pw-post-body-paragraph na nb it lx b ly ob ju nc ma oc jx nd li od nf ng lm oe ni nj lq of nl nm mf im bi translated">那么，我们如何将连续的、机械的东西转化为离散的、数字化的东西呢？</p><p id="393d" class="pw-post-body-paragraph na nb it lx b ly ob ju nc ma oc jx nd li od nf ng lm oe ni nj lq of nl nm mf im bi translated">这就是前面定义的<code class="fe nw nx ny nz b">sample rate</code>的用处。比如说，录制的音频的<code class="fe nw nx ny nz b">sample rate</code>是 100。这意味着，对于每一秒记录的音频，计算机将沿着<code class="fe nw nx ny nz b">signal</code>放置 100 个点，试图最好地“跟踪”连续曲线。一旦所有的点都就位，一条平滑的曲线将它们连接在一起，以便人类能够可视化声音。由于录制的音频是以<code class="fe nw nx ny nz b">amplitude</code>和<code class="fe nw nx ny nz b">time</code>为单位，我们可以直观地说波形是在<code class="fe nw nx ny nz b">time domain</code>工作的。</p><p id="7fe2" class="pw-post-body-paragraph na nb it lx b ly ob ju nc ma oc jx nd li od nf ng lm oe ni nj lq of nl nm mf im bi translated">为了更好地理解这种声音，我们来看看三种声音:底鼓、吉他和小鼓。<a class="ae ky" href="https://github.com/theadamsabra/MediumCode/tree/master/Learning%20From%20Audio" rel="noopener ugc nofollow" target="_blank">本文的代码和数据可以在我的 GitHub 存储库中找到。</a></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="os ot l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">载入数据。</p></figure><p id="1da1" class="pw-post-body-paragraph na nb it lx b ly ob ju nc ma oc jx nd li od nf ng lm oe ni nj lq of nl nm mf im bi translated">既然数据已经载入，让我们来想象这些声音。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="os ot l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/413eb5e4699548774f873baacbd545a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GZ4YS5WoRPYtabKuwEEUoA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 1</p></figure><p id="566a" class="pw-post-body-paragraph na nb it lx b ly ob ju nc ma oc jx nd li od nf ng lm oe ni nj lq of nl nm mf im bi translated">从一开始，我们就看到了可视化的一些问题。</p><p id="b177" class="pw-post-body-paragraph na nb it lx b ly ob ju nc ma oc jx nd li od nf ng lm oe ni nj lq of nl nm mf im bi translated">虽然我们可以很容易地分辨出可视化之间的一些差异，但这并不像我们希望的那样明显。我们还知道，音频信号不会突然消失，事实上它们会逐渐消失，直到无法感知。这意味着就音频而言，这构成了<code class="fe nw nx ny nz b">null</code>数据。</p></div><div class="ab cl og oh hx oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="im in io ip iq"><h1 id="a072" class="mp la it bd lb mq on ms le mt oo mv lh jz op ka ll kc oq kd lp kf or kg lt mz bi translated">音频中的空数据:</h1><p id="571a" class="pw-post-body-paragraph na nb it lx b ly lz ju nc ma mb jx nd li ne nf ng lm nh ni nj lq nk nl nm mf im bi translated">有许多方法可以处理<code class="fe nw nx ny nz b">time domain</code>中的<code class="fe nw nx ny nz b">null</code>音频数据。然而，这种方法通常是最简单的。</p><p id="3e7d" class="pw-post-body-paragraph na nb it lx b ly ob ju nc ma oc jx nd li od nf ng lm oe ni nj lq of nl nm mf im bi translated">给定<code class="fe nw nx ny nz b">signal</code>和<code class="fe nw nx ny nz b">signal</code>中<code class="fe nw nx ny nz b">amplitude</code>的最小值<code class="fe nw nx ny nz b">threshold</code>:</p><ul class=""><li id="ab5a" class="lv lw it lx b ly ob ma oc li ov lm ow lq ox mf mg mh mi mj bi translated">取信号中各点的<code class="fe nw nx ny nz b">absolute value</code></li><li id="3fee" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf mg mh mi mj bi translated">如果点数大于<code class="fe nw nx ny nz b">threshold</code>，我们保留它。否则，我们删除它。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="os ot l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/451427c2128a08a5a4ef18775c2c2341.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8G2HpTHm1wPD9bnwTTy-Hg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 2</p></figure><p id="e3ff" class="pw-post-body-paragraph na nb it lx b ly ob ju nc ma oc jx nd li od nf ng lm oe ni nj lq of nl nm mf im bi translated">您可以将<code class="fe nw nx ny nz b">thresholds</code>视为记录的一种参数。不同的<code class="fe nw nx ny nz b">thresholds</code>对不同的声音有不同的作用。摆弄一下<code class="fe nw nx ny nz b">threshold</code>是了解<em class="oa">如何</em>和<em class="oa">为什么</em>这种视觉变化的好方法。</p><p id="e8c2" class="pw-post-body-paragraph na nb it lx b ly ob ju nc ma oc jx nd li od nf ng lm oe ni nj lq of nl nm mf im bi translated">既然数据已经从这些录音中移除，那么就更容易看出每个声音中的个性。吉他的形状更加统一，随着时间的推移逐渐消失。底鼓在开始时用力击打，然后很快淹没，留下一些残余的声音。小军鼓是响亮而沙哑的，你不会想重复听。</p><h1 id="011b" class="mp la it bd lb mq mr ms le mt mu mv lh jz mw ka ll kc mx kd lp kf my kg lt mz bi translated">结论:</h1><p id="d828" class="pw-post-body-paragraph na nb it lx b ly lz ju nc ma mb jx nd li ne nf ng lm nh ni nj lq nk nl nm mf im bi translated">这就结束了用<code class="fe nw nx ny nz b">librosa</code>在 Python 中处理音频信号的基础。敬请关注更多深入探讨如何从音频中学习的更高级主题的文章！</p><blockquote class="oy"><p id="62db" class="oz pa it bd pb pc pd pe pf pg ph mf dk translated">感谢您的阅读。</p></blockquote><p id="1182" class="pw-post-body-paragraph na nb it lx b ly pi ju nc ma pj jx nd li pk nf ng lm pl ni nj lq pm nl nm mf im bi translated"><em class="oa">注:所有未注明出处的数字均为作者。</em></p></div></div>    
</body>
</html>