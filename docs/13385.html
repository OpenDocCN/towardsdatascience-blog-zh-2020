<html>
<head>
<title>Feature Engineering for Machine Learning with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 Python 实现机器学习的特征工程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/practical-code-implementations-of-feature-engineering-for-machine-learning-with-python-f13b953d4bcd?source=collection_archive---------23-----------------------#2020-09-14">https://towardsdatascience.com/practical-code-implementations-of-feature-engineering-for-machine-learning-with-python-f13b953d4bcd?source=collection_archive---------23-----------------------#2020-09-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/06c3f8606ab00b95fc78e7ec9375fba3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*ghEUh8hS8szZf2If.jpg"/></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">使用 Python 进行机器学习的特征工程—图片来自<a class="ae kb" href="https://pixabay.com/de/photos/arbeit-eingabe-computer-notebook-731198/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><p id="f592" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">据<a class="ae kb" href="https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/?sh=23cce0296f63" rel="noopener ugc nofollow" target="_blank"> Forbes </a>报道，数据科学家和机器学习工程师花费大约<strong class="ke iu"> 60% </strong>的时间在训练机器学习模型<strong class="ke iu">之前准备数据。大部分时间花在了特性工程上。</strong></p><p id="ad0b" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">特征工程是转换和创建可用于训练机器学习模型的特征的过程。特征工程对于训练精确的机器学习模型至关重要，但通常具有挑战性并且非常耗时。</p><p id="da46" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">特征工程包括输入缺失值、编码分类变量、转换和离散化数值变量、删除或审查异常值、缩放特征等。</p><p id="7a20" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">在本文中，我将讨论机器学习的特征工程的 Python 实现。我比较了以下开源 Python 库:</p><ul class=""><li id="fdf0" class="la lb it ke b kf kg kj kk kn lc kr ld kv le kz lf lg lh li bi translated"><a class="ae kb" href="https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing" rel="noopener ugc nofollow" target="_blank"> Scikit-learn </a></li><li id="83da" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated"><a class="ae kb" href="https://feature-engine.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">特征引擎</a></li><li id="b1a6" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated"><a class="ae kb" href="https://pypi.org/project/category-encoders/" rel="noopener ugc nofollow" target="_blank">类别编码器</a></li></ul><p id="4c82" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">我将展示要执行的代码:</p><ul class=""><li id="4482" class="la lb it ke b kf kg kj kk kn lc kr ld kv le kz lf lg lh li bi translated">缺失数据插补</li><li id="ce13" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">分类编码</li><li id="ceeb" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">变量变换</li><li id="2ae7" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">[数]离散化</li></ul></div><div class="ab cl lo lp hx lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="im in io ip iq"><h1 id="85c4" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">特征工程管道</h1><p id="17d8" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">大多数特征工程技术从数据中学习参数。例如，为了用平均值估算数据，我们从训练集中获取平均值。为了对分类变量进行编码，我们还利用训练数据定义了字符串到数字的映射。</p><p id="ca64" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">许多开源 Python 包具有学习和存储设计特性的参数的功能，然后检索它们来转换数据。</p><p id="4e88" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">特别是，<a class="ae kb" href="https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing" rel="noopener ugc nofollow" target="_blank"> Scikit-learn </a>、<a class="ae kb" href="https://feature-engine.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> Feature-engine </a>和<a class="ae kb" href="https://pypi.org/project/category-encoders/" rel="noopener ugc nofollow" target="_blank">类别编码器</a>共享了从数据中学习参数的方法<em class="my"> fit </em>和修改数据的方法<em class="my"> transform </em>。</p><p id="5f60" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">Pandas 也有很多功能工程和数据准备的工具。然而，它缺乏存储学习参数的功能。正因如此，本文就不谈论熊猫了。</p></div><div class="ab cl lo lp hx lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="im in io ip iq"><h1 id="2636" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">用于要素工程的 Python 库</h1><p id="6f5b" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated"><a class="ae kb" href="https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing" rel="noopener ugc nofollow" target="_blank"> Scikit-learn </a>、<a class="ae kb" href="https://feature-engine.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> Feature-engine </a>和<a class="ae kb" href="https://pypi.org/project/category-encoders/" rel="noopener ugc nofollow" target="_blank">类别编码器</a>共享<em class="my"> fit </em>和<em class="my"> transform </em>功能，从数据中学习参数，然后转换变量。</p><p id="300f" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">然而，这些软件包在 I)输出、ii)输入和 iii)通用性方面存在一些差异。</p><figure class="na nb nc nd gt ju gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/54c689908af87fbffb6d24509916c604.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*yVIRNFspxhevbRrkJiGi7A.png"/></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">用于要素工程的 Python 包之间的主要差异-由作者创建</p></figure><h2 id="8945" class="ne lw it bd lx nf ng dn mb nh ni dp mf kn nj nk mj kr nl nm mn kv nn no mr np bi translated">输出:NumPy 数组对 Pandas 数据帧</h2><p id="d69f" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">特征引擎和分类编码器返回熊猫数据帧。Scikit-learn 返回 NumPy 数组。</p><p id="45d2" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">NumPy 数组针对机器学习进行了优化，因为 NumPy 的计算效率更高。熊猫数据框架更适合数据可视化。</p><p id="25c8" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">通常，我们希望了解特征工程转换如何影响变量分布以及它们与其他变量的关系。Pandas 是一个很好的数据分析和可视化工具，因此，返回 Pandas 数据帧的库在本质上对数据分析更“友好”。</p><p id="7db2" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">如果我们选择使用 Scikit-learn，我们可能需要添加一两行代码来将 NumPy 数组转换成 Pandas 数据帧，以便继续进行数据可视化。</p><h2 id="37ef" class="ne lw it bd lx nf ng dn mb nh ni dp mf kn nj nk mj kr nl nm mn kv nn no mr np bi translated">输入:数据切片与完整数据集</h2><p id="9770" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">数据科学家对不同的变量子集应用不同的特征工程方法。</p><p id="a820" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">例如，我们只估算缺失数据的变量，而不是整个数据集。我们将对数字变量采用某些插补方法，对类别变量采用其他方法。</p><p id="d10f" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">Python 库提供了选择我们想要转换的变量的可能性。</p><p id="c7ac" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">使用<a class="ae kb" href="https://feature-engine.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">特征引擎</a>和<a class="ae kb" href="https://pypi.org/project/category-encoders/" rel="noopener ugc nofollow" target="_blank">类别编码器</a>，我们选择要在转换器中转换的变量。</p><p id="6353" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">使用 Scikit-learn，我们需要使用一个特殊的转换器将数据集分割成所需的变量组。我们可以通过使用<a class="ae kb" href="https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html" rel="noopener ugc nofollow" target="_blank">的 ColumnTransformer </a>或者 Feature-engine 的<a class="ae kb" href="https://feature-engine.readthedocs.io/en/latest/wrappers/Wrapper.html" rel="noopener ugc nofollow" target="_blank"> SklearnWrapper </a>来实现。使用 Feature-engine 的<a class="ae kb" href="https://feature-engine.readthedocs.io/en/latest/wrappers/Wrapper.html" rel="noopener ugc nofollow" target="_blank"> SklearnWrapper </a>的美妙之处在于输出是一个熊猫数据帧！</p><h2 id="7774" class="ne lw it bd lx nf ng dn mb nh ni dp mf kn nj nk mj kr nl nm mn kv nn no mr np bi translated">多才多艺</h2><p id="f45d" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">有时，我们不知道哪种转换技术返回的预测变量最多。应该做等宽还是等频离散化？我们应该用平均值、中间值还是任意数来估算？</p><p id="a1d9" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">大多数 Scikit-learn 转换器是集中式的，这意味着一个转换器可以执行不同的转换。例如，我们可以通过简单地改变 Scikit-learn 中 KBinsDiscretizer()的参数来应用 3 种离散化技术。另一方面，特征引擎为离散化提供了 3 种不同的转换器。</p><p id="01ea" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">插补也是如此；通过更改 SimpleImputer()的参数，我们可以使用 Scikit-learn 执行不同的插补技术，而 Feature-engine 有几个转换器，每个转换器最多可以执行 2 种不同的插补变量。</p><p id="8fd6" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">使用 Scikit-learn，我们可以轻松地对特征工程变压器的参数进行网格搜索。使用特征引擎，我们需要事先决定要使用哪种转换。</p><p id="43c7" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">在博客的其余部分，我将比较 Scikit-learn、特征引擎和类别编码器中缺失数据插补、分类编码、数学转换和离散化的实现。</p></div><div class="ab cl lo lp hx lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="im in io ip iq"><h1 id="f605" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">缺失数据插补</h1><p id="8031" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">插补包括用缺失值的概率估计值替换缺失数据。缺失数据插补方法有多种，每种方法都有不同的用途。</p><figure class="na nb nc nd gt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/e7ef9970c4462d1834bd804796d0c5b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*mO1Gdu450WlF0Nof.jpeg"/></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">缺少数据—图片由<a class="ae kb" href="https://pixabay.com/de/users/wilhei-883152/" rel="noopener ugc nofollow" target="_blank"> Willi Heidelbach </a>从<a class="ae kb" href="https://pixabay.com/de/photos/puzzle-passt-passen-fehlt-loch-693870/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>获得</p></figure><p id="109e" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">如果你想了解更多关于这些技术，它们的优点和局限性，以及我们何时应该使用它们，请查看课程“<a class="ae kb" href="https://www.courses.trainindata.com/p/feature-engineering-for-machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习的特征工程</a>”。</p><p id="14e0" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">Scikit-learn 和 Feature-engine 支持许多数值和分类变量的插补程序。</p><p id="70a4" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">两个库都包含最常见插补技术的功能:</p><ul class=""><li id="4bd4" class="la lb it ke b kf kg kj kk kn lc kr ld kv le kz lf lg lh li bi translated">均值和中位数插补</li><li id="f0de" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">频繁类别插补</li><li id="8b42" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">任意值插补</li><li id="5b39" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">添加缺失的指标</li></ul><p id="7ed4" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">特征引擎还可以执行:</p><ul class=""><li id="5418" class="la lb it ke b kf kg kj kk kn lc kr ld kv le kz lf lg lh li bi translated">随机样本插补</li><li id="e65b" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">完整的案例分析</li><li id="1b12" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">分布极值的插补</li></ul><p id="8ada" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">另一方面，Scikit-learn 在其功能中提供了链式方程 的<a class="ae kb" href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ke iu">多元插补。</strong></a></p><p id="f6d4" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">特征引擎转换器可以根据插补方法自动识别数值或分类变量。有了特征引擎，当我们估算数字变量或分类变量时，我们不会无意中添加一个字符串。使用 Scikit-learn，我们需要事先选择要修改的变量。</p><p id="211d" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">Scikit-learn 的 SimpleImputer()，只需调整<em class="my">策略</em>和<em class="my"> fill_value </em>参数，即可执行所有插补技术。因此，我们可以自由地对插补技术进行网格研究，如 Scikit-learn 文档中的<a class="ae kb" href="https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html" rel="noopener ugc nofollow" target="_blank">代码实现所示。相反，特征引擎具有至少 5 个不同的插补转换器。</a></p><p id="9dd2" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">在接下来的段落中，我们将首先进行中位数插补和最常见类别的插补。</p><h1 id="a2f3" class="lv lw it bd lx ly nq ma mb mc nr me mf mg ns mi mj mk nt mm mn mo nu mq mr ms bi translated">均值/中位数插补</h1><p id="5867" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">对于中位数插补，Feature-engine 提供了 MeanMedianImputer()，Scikit-learn 提供了 SimpleImputer()。</p><p id="34e0" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">Feature-engine 的 MeanMedianImputer()自动选择训练数据集中的所有数值变量。另一方面，Scikit-learn 的 SimpleImputer()将转换数据集中的所有变量，如果在执行过程中有分类变量，它将产生一个错误。</p><h2 id="d7f8" class="ne lw it bd lx nf ng dn mb nh ni dp mf kn nj nk mj kr nl nm mn kv nn no mr np bi translated">特征引擎</h2><p id="98e7" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">下面，我们看到使用中位数作为插补的<a class="ae kb" href="https://feature-engine.readthedocs.io/en/latest/imputers/MeanMedianImputer.html" rel="noopener ugc nofollow" target="_blank"> MeanMedianImputer() </a>的实现。简单地将<em class="my">插补 _ 方法</em>的“中值”替换为“平均值”,即可实现平均值插补。</p><pre class="na nb nc nd gt nv nw nx ny aw nz bi"><span id="63df" class="ne lw it nw b gy oa ob l oc od">import pandas as pd<br/>from sklearn.model_selection import train_test_split<br/>from feature_engine.imputation import MeanMedianImputer<br/> <br/># Load dataset<br/>data = pd.read_csv('houseprice.csv')<br/> <br/># Separate into train and test sets<br/>X_train, X_test, y_train, y_test = train_test_split(<br/>    data.drop(['Id', 'SalePrice'], axis=1),<br/>    data['SalePrice'],<br/>    test_size=0.3,<br/>    random_state=0<br/>    )<br/> <br/># set up the imputer<br/>median_imputer = MeanMedianImputer(<br/>    imputation_method='median',<br/>    variables=['LotFrontage', 'MasVnrArea']<br/>    )<br/> <br/># fit the imputer<br/>median_imputer.fit(X_train)<br/> <br/># transform the data<br/>train_t= median_imputer.transform(X_train)<br/>test_t= median_imputer.transform(X_test)</span></pre><p id="a90d" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">特征引擎返回原始数据帧，其中只有数字变量被修改。欲了解更多详情，请访问<a class="ae kb" href="https://feature-engine.readthedocs.io/en/latest/api_doc/imputation/MeanMedianImputer.html#feature_engine.imputation.MeanMedianImputer" rel="noopener ugc nofollow" target="_blank"> MeanMedianImputer()文档</a>。</p><h2 id="9f29" class="ne lw it bd lx nf ng dn mb nh ni dp mf kn nj nk mj kr nl nm mn kv nn no mr np bi translated">sci kit-学习</h2><p id="1328" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">使用<a class="ae kb" href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html" rel="noopener ugc nofollow" target="_blank">简单估算器()</a>，我们还可以通过其参数指定均值或中值估算方法:</p><pre class="na nb nc nd gt nv nw nx ny aw nz bi"><span id="45a9" class="ne lw it nw b gy oa ob l oc od">import pandas as pd<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.impute import SimpleImputer<br/> <br/># Load dataset<br/>data = pd.read_csv('houseprice.csv')<br/> <br/># Separate into train and test sets<br/>X_train, X_test, y_train, y_test = train_test_split(<br/>    data.drop(['Id', 'SalePrice'], axis=1),<br/>    data['SalePrice'],<br/>    test_size=0.3,<br/>    random_state=0<br/>    )<br/> <br/># Set up the imputer<br/>median_imputer = SimpleImputer(strategy='median')<br/> <br/># fit the imputer<br/>median_imputer.fit(X_train[['LotFrontage', 'MasVnrArea']])<br/> </span><span id="7d1e" class="ne lw it nw b gy oe ob l oc od"># transform the data</span><span id="81bb" class="ne lw it nw b gy oe ob l oc od">X_train_t = median_imputer.transform(<br/>    X_train[['LotFrontage', 'MasVnrArea']]<br/>    )</span><span id="288e" class="ne lw it nw b gy oe ob l oc od">X_test_t = median_imputer.transform(<br/>    X_test[['LotFrontage', 'MasVnrArea']]<br/>    )</span></pre><p id="81d5" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">如上所述，Scikit-learn 要求我们在将数据帧传递到插补转换器之前对其进行切片，而 Feature-engine 则不需要这一步。</p><p id="bcc3" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">前面代码块的结果是一个 NumPy 数组，其中有两个输入的数值变量。</p><h1 id="b014" class="lv lw it bd lx ly nq ma mb mc nr me mf mg ns mi mj mk nt mm mn mo nu mq mr ms bi translated">频繁类别插补</h1><p id="dcee" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">频繁类别插补包括用变量的最频繁类别替换分类变量中的缺失值。</p><h2 id="d448" class="ne lw it bd lx nf ng dn mb nh ni dp mf kn nj nk mj kr nl nm mn kv nn no mr np bi translated">特征引擎</h2><p id="d724" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">如果我们将插补方法参数设置为“频繁”，CategoricalImputer()会用其模式替换分类变量中的缺失数据。</p><p id="6abc" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">我们可以指出要估算的变量，如下所示；否则，估算器将自动选择并估算训练数据集中的所有分类变量。</p><pre class="na nb nc nd gt nv nw nx ny aw nz bi"><span id="c786" class="ne lw it nw b gy oa ob l oc od">import pandas as pd<br/>from sklearn.model_selection import train_test_split<br/>from feature_engine.imputation import CategoricalImputer<br/> <br/># Load dataset<br/>data = pd.read_csv('houseprice.csv')<br/> <br/># Separate into train and test sets<br/>X_train, X_test, y_train, y_test = train_test_split(<br/>    data.drop(['Id', 'SalePrice'], axis=1),<br/>    data['SalePrice'],<br/>    test_size=0.3,<br/>    random_state=0<br/>    )<br/> <br/># set up the imputer<br/>imputer = CategoricalImputer(<br/>    imputation_method=’frequent’,<br/>    variables=['Alley', 'MasVnrType']<br/>    )<br/> <br/># fit the imputer<br/>imputer.fit(X_train)<br/> <br/># transform the data<br/>train_t= imputer.transform(X_train)<br/>test_t= imputer.transform(X_test)</span></pre><p id="90db" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">结果是一个原始变量的数据框架，其中显示的变量是估算的。</p><h2 id="c948" class="ne lw it bd lx nf ng dn mb nh ni dp mf kn nj nk mj kr nl nm mn kv nn no mr np bi translated">sci kit-学习</h2><p id="4427" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">通过使用“最频繁”作为插补策略，<a class="ae kb" href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html" rel="noopener ugc nofollow" target="_blank">简单插补器()</a>也用于频繁类别插补。</p><p id="2ece" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">请注意，SimpleImputer()的“最频繁”插补策略可以对数字变量和分类变量进行操作。所以我们需要非常小心。</p><pre class="na nb nc nd gt nv nw nx ny aw nz bi"><span id="3677" class="ne lw it nw b gy oa ob l oc od">import pandas as pd<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.impute import SimpleImputer<br/> <br/># Load dataset<br/>data = pd.read_csv('houseprice.csv')<br/> <br/># Separate into train and test sets<br/>X_train, X_test, y_train, y_test = train_test_split(<br/>    data.drop(['Id', 'SalePrice'], axis=1),<br/>    data['SalePrice'],<br/>    test_size=0.3,<br/>    random_state=0<br/>    )<br/> <br/># set up the imputer<br/>mode_imputer = SimpleImputer(strategy='most_frequent')<br/> <br/># fit the imputer<br/>mode_imputer.fit(X_train[['Alley', 'MasVnrType']])<br/> <br/># transform the data<br/>X_train= mode_imputer.transform(<br/>    X_train[['Alley', 'MasVnrType']]<br/>    )</span><span id="3c91" class="ne lw it nw b gy oe ob l oc od">X_test= mode_imputer.transform(<br/>    X_test[['Alley', 'MasVnrType']]<br/>    )</span></pre><p id="0d2f" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">前面代码块的输出是一个 Numpy 数组，包含两列估算变量。</p><h1 id="0ed1" class="lv lw it bd lx ly nq ma mb mc nr me mf mg ns mi mj mk nt mm mn mo nu mq mr ms bi translated">分类编码</h1><p id="f190" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">机器学习模型需要数字格式的输入数据。因此，数据科学家需要将分类变量转换成数字变量。这些过程被称为分类变量编码。</p><figure class="na nb nc nd gt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/f9ac738fd1e293af2c425dd8a48efa27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*vFHWSAngitPh41K9RPKKWA.png"/></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">分类变量以标签而不是数字作为值——来自<a class="ae kb" href="https://pixabay.com/de/vectors/marke-weg-cartoon-label-holz-4802528/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae kb" href="https://pixabay.com/de/users/jozefm84-10215106/" rel="noopener ugc nofollow" target="_blank"> Jozef Mikulcik </a>举例说明。</p></figure><p id="f686" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">有许多方法可以对分类变量进行编码。我们选择的编码方法完全是数据环境和业务问题驱动的；我们如何表示和设计这些特性会对模型的性能产生重大影响。</p><p id="dc6d" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated"><strong class="ke iu"> Scikit-learn </strong>、<strong class="ke iu">特征引擎</strong>和<strong class="ke iu">分类编码器</strong>提供广泛的分类编码器。这三个库都提供了常用的编码器，比如一键编码和顺序编码，我们将在下面演示。</p><p id="c059" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">特征引擎和类别编码器还提供基于目标的编码方法，如目标均值编码和证据权重。</p><p id="77e4" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">总的来说，分类编码器是分类编码领域的领跑者，提供了最广泛的编码技术。它们最初来源于大量的科学出版物。</p><p id="cfc9" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">分类编码器转换器支持 NumPy 数组和 pandas 数据帧输入格式，是完全兼容的 Scikit-learn 功能，可在管道中使用。除了上面提到的更普遍实现的编码器，类别编码器还提供一些特殊的用例编码器，包括:</p><ul class=""><li id="ca58" class="la lb it ke b kf kg kj kk kn lc kr ld kv le kz lf lg lh li bi translated"><a class="ae kb" href="http://contrib.scikit-learn.org/category_encoders/backward_difference.html" rel="noopener ugc nofollow" target="_blank">向后差异</a></li><li id="ced4" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated"><a class="ae kb" href="http://contrib.scikit-learn.org/category_encoders/helmert.html" rel="noopener ugc nofollow" target="_blank">赫尔默特</a></li><li id="d4ce" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated"><a class="ae kb" href="http://contrib.scikit-learn.org/category_encoders/helmert.html" rel="noopener ugc nofollow" target="_blank">多项式</a></li><li id="0ebb" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated"><a class="ae kb" href="http://contrib.scikit-learn.org/category_encoders/sum.html" rel="noopener ugc nofollow" target="_blank">总和编码</a></li><li id="4eff" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated"><a class="ae kb" href="http://contrib.scikit-learn.org/category_encoders/leaveoneout.html" rel="noopener ugc nofollow" target="_blank">离开</a></li><li id="a6c9" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated"><a class="ae kb" href="http://contrib.scikit-learn.org/category_encoders/binary.html" rel="noopener ugc nofollow" target="_blank">二进制</a>，与</li><li id="3821" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated"><a class="ae kb" href="http://contrib.scikit-learn.org/category_encoders/basen.html" rel="noopener ugc nofollow" target="_blank"> BaseN </a></li></ul><p id="69ac" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">在下面的段落中，我们将比较 3 个 Python 开源库中顺序编码的实现。</p><h1 id="58de" class="lv lw it bd lx ly nq ma mb mc nr me mf mg ns mi mj mk nt mm mn mo nu mq mr ms bi translated">顺序编码</h1><p id="723d" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">顺序编码用数字将类别标记为唯一类别的数量。对于具有<em class="my"> n </em>唯一类别的分类变量，序数编码会用从<em class="my"> 0 </em>到<em class="my"> n-1 </em>的整数替换类别。</p><h2 id="0983" class="ne lw it bd lx nf ng dn mb nh ni dp mf kn nj nk mj kr nl nm mn kv nn no mr np bi translated">特征引擎</h2><p id="f11b" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">Feature-engine 的 OrdinalEncoder()仅适用于分类变量，其中可以指明变量列表，否则编码器将自动选择训练集中的所有分类变量。</p><p id="600a" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">如果我们选择“任意”作为编码方法，那么编码器将按照标签在变量中出现的顺序分配数字(即先来先服务)。</p><p id="f369" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">如果我们选择“有序”，编码器将按照该标签目标值的平均值分配数字。目标平均值较高的标签将被分配数字 0，而目标平均值最小的标签将被分配 n-1。</p><pre class="na nb nc nd gt nv nw nx ny aw nz bi"><span id="55dd" class="ne lw it nw b gy oa ob l oc od">import pandas as pd<br/>from sklearn.model_selection import train_test_split<br/>from feature_engine.encoding import OrdinalEncoder<br/> <br/># Load dataset</span><span id="2967" class="ne lw it nw b gy oe ob l oc od">def load_titanic():<br/>    data = pd.read_csv(<br/>    'https://www.openml.org/data/get_csv/16826755/phpMYEkMl'<br/>    )<br/>    <br/>    data = data.replace('?', np.nan)<br/>    data['cabin'] = data['cabin'].astype(str).str[0]<br/>    data['pclass'] = data['pclass'].astype('O')<br/>    data['embarked'].fillna('C', inplace=True)<br/> <br/>    return data<br/> <br/>data = load_titanic()<br/> <br/># Separate into train and test sets<br/>X_train, X_test, y_train, y_test = train_test_split(<br/>    data.drop(['survived', 'name', 'ticket'], axis=1),<br/>    data['survived'],<br/>    test_size=0.3,<br/>    random_state=0<br/>    )<br/> <br/># set up the encoder<br/>encoder = OrdinalEncoder(<br/>    encoding_method='arbitrary',<br/>    variables=['pclass', 'cabin', 'embarked']<br/>    )<br/> <br/># fit the encoder<br/>encoder.fit(X_train, y_train)<br/> <br/># transform the data<br/>train_t= encoder.transform(X_train)<br/>test_t= encoder.transform(X_test)</span></pre><p id="115a" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">前面代码块的输出是原始的 pandas 数据帧，其中选择的分类变量被转换成数字。</p><h2 id="aa13" class="ne lw it bd lx nf ng dn mb nh ni dp mf kn nj nk mj kr nl nm mn kv nn no mr np bi translated">sci kit-学习</h2><p id="5c74" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">Scitkit-learn 的<a class="ae kb" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html" rel="noopener ugc nofollow" target="_blank"> OrdinalEncoder() </a>要求对分类变量的输入进行切片。在编码过程中，数字只是按照标签的字母顺序进行分配。</p><pre class="na nb nc nd gt nv nw nx ny aw nz bi"><span id="bb24" class="ne lw it nw b gy oa ob l oc od">import pandas as pd<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.preprocessing import OrdinalEncoder<br/> <br/># Load dataset</span><span id="8384" class="ne lw it nw b gy oe ob l oc od">def load_titanic():<br/>    data = pd.read_csv(<br/>    'https://www.openml.org/data/get_csv/16826755/phpMYEkMl'<br/>    )<br/>    <br/>    data = data.replace('?', np.nan)<br/>    data['cabin'] = data['cabin'].astype(str).str[0]<br/>    data['pclass'] = data['pclass'].astype('O')<br/>    data['embarked'].fillna('C', inplace=True)<br/> <br/>    return data<br/> <br/>data = load_titanic()<br/> <br/># Separate into train and test sets<br/>X_train, X_test, y_train, y_test = train_test_split(<br/>    data.drop(['survived', 'name', 'ticket'], axis=1),<br/>    data['survived'],<br/>    test_size=0.3,<br/>    random_state=0<br/>    )</span><span id="ade9" class="ne lw it nw b gy oe ob l oc od"><br/># set up the encoder<br/>encoder = OrdinalEncoder()<br/> <br/># fit the encoder<br/>encoder.fit(<br/>    X_train[['pclass', 'cabin', 'embarked']],<br/>    y_train<br/>    )<br/> <br/># transform the data<br/>train_t= encoder.transform(<br/>    X_train[['pclass', 'cabin', 'embarked']]<br/>    )</span><span id="720b" class="ne lw it nw b gy oe ob l oc od">test_t= encoder.transform(<br/>    X_test[['pclass', 'cabin', 'embarked']]<br/>    )</span></pre><p id="e159" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">前面代码块的输出是一个有 3 列的 NumPy 数组，对应于估算变量。</p><h2 id="7a2f" class="ne lw it bd lx nf ng dn mb nh ni dp mf kn nj nk mj kr nl nm mn kv nn no mr np bi translated">类别编码器</h2><p id="74f5" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">分类编码器'<a class="ae kb" href="http://contrib.scikit-learn.org/category_encoders/ordinal.html" rel="noopener ugc nofollow" target="_blank">' OrdinalEncoder()</a>允许我们指定变量/列作为参数进行转换。如果我们知道类本身有某种真正的顺序，也可以传递一个可选的映射字典。否则，这些类被认为没有真正的顺序，数字被随机分配给标签。</p><pre class="na nb nc nd gt nv nw nx ny aw nz bi"><span id="980e" class="ne lw it nw b gy oa ob l oc od">import pandas as pd<br/>from sklearn.model_selection import train_test_split<br/>from category_encoders.ordinal import OrdinalEncoder<br/> <br/># Load dataset</span><span id="9409" class="ne lw it nw b gy oe ob l oc od">def load_titanic():<br/>    data = pd.read_csv(<br/>    'https://www.openml.org/data/get_csv/16826755/phpMYEkMl'<br/>    )<br/>    <br/>    data = data.replace('?', np.nan)<br/>    data['cabin'] = data['cabin'].astype(str).str[0]<br/>    data['pclass'] = data['pclass'].astype('O')<br/>    data['embarked'].fillna('C', inplace=True)<br/> <br/>    return data<br/> <br/>data = load_titanic()<br/> <br/># Separate into train and test sets<br/>X_train, X_test, y_train, y_test = train_test_split(<br/>    data.drop(['survived', 'name', 'ticket'], axis=1),<br/>    data['survived'],<br/>    test_size=0.3,<br/>    random_state=0<br/>    )<br/> <br/># set up the encoder<br/>encoder = OrdinalEncoder(cols=['pclass', 'cabin', 'embarked'])<br/> <br/># fit the encoder<br/>encoder.fit(X_train, y_train)<br/> <br/># transform the data<br/>train_t= encoder.transform(X_train)<br/>test_t= encoder.transform(X_test)</span></pre><h1 id="3b09" class="lv lw it bd lx ly nq ma mb mc nr me mf mg ns mi mj mk nt mm mn mo nu mq mr ms bi translated">转换</h1><p id="6977" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">数据科学家使用各种数学函数(如对数、幂和倒数)来转换数值变量，其总体目标是获得更“高斯”的分布。</p><figure class="na nb nc nd gt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/11082153f4c4991ae029669e3f5249d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*PunN8d0aSmj9r4omBpL_PQ.jpeg"/></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">数学变换——图片由<a class="ae kb" href="https://pixabay.com/de/users/geralt-9301/" rel="noopener ugc nofollow" target="_blank"> Gerd Altmann </a>从<a class="ae kb" href="https://pixabay.com/de/illustrations/geometrie-mathematik-lautst%C3%A4rke-1044090/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>获得</p></figure><p id="8e64" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">Scikit-learn 提供了<a class="ae kb" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html" rel="noopener ugc nofollow" target="_blank"> FunctionTransformer() </a>，原则上，它可以应用用户定义的任何函数。它将函数作为参数，或者作为 NumPy 方法，或者作为 lambda 函数。</p><p id="e3d6" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">相反，通过诸如<a class="ae kb" href="https://feature-engine.readthedocs.io/en/latest/api_doc/transformation/LogTransformer.html" rel="noopener ugc nofollow" target="_blank"> LogTransformer() </a>和 R<a class="ae kb" href="https://feature-engine.readthedocs.io/en/latest/api_doc/transformation/ReciprocalTransformer.html" rel="noopener ugc nofollow" target="_blank">eciprocalTransformer()</a>之类的转换器，特征引擎支持使用单个特定转换器的数学转换。</p><p id="314f" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">说到“自动”转换，Scikit-learn 和 Feature-engine 都支持 Yeo-Johnson 和 Box-Cox 转换。虽然 Scikit-learn 通过改变“方法”参数将转换集中在<a class="ae kb" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html" rel="noopener ugc nofollow" target="_blank"> PowerTransformer() </a>中，但 Feature-engine 有两个单独的<a class="ae kb" href="https://feature-engine.readthedocs.io/en/latest/api_doc/transformation/YeoJohnsonTransformer.html" rel="noopener ugc nofollow" target="_blank"> Yeo-Johnson </a>和<a class="ae kb" href="https://feature-engine.readthedocs.io/en/latest/api_doc/transformation/BoxCoxTransformer.html" rel="noopener ugc nofollow" target="_blank"> Box-Cox </a>转换器。</p><p id="d7e0" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">如果转换在数学上不可行，例如 log(0)或 0 的倒数，Feature-engine 会返回一个错误，而 Scikit-learn 会引入 NaNs，这需要您在之后进行合理性检查。</p><p id="2dee" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">在接下来的段落中，我们将比较对数转换和 Box-Cox 转换在两个包之间的实现。在演示中，我们使用来自 Kaggle 的<a class="ae kb" href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques" rel="noopener ugc nofollow" target="_blank">房价数据集。</a></p><h1 id="524d" class="lv lw it bd lx ly nq ma mb mc nr me mf mg ns mi mj mk nt mm mn mo nu mq mr ms bi translated">对数变换</h1><p id="c816" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">对数变换包括对变量进行对数变换。</p><h2 id="00d3" class="ne lw it bd lx nf ng dn mb nh ni dp mf kn nj nk mj kr nl nm mn kv nn no mr np bi translated">特征引擎</h2><p id="f2ce" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">功能引擎的 LogTransformer()将自然对数或以 10 为底的对数应用于数值变量。它只适用于数值，正值。如果变量包含 0 或负值，转换器将返回一个错误。</p><p id="f732" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">与所有功能引擎的转换器一样，LogTransformer()允许我们选择要转换的变量。变量列表可以作为参数传递，或者，转换器将自动选择并转换所有数字变量。</p><pre class="na nb nc nd gt nv nw nx ny aw nz bi"><span id="e643" class="ne lw it nw b gy oa ob l oc od">import pandas as pd<br/>from sklearn.model_selection import train_test_split<br/>from feature_engine.transformation import LogTransformer<br/> <br/><br/># Load dataset<br/>data = data = pd.read_csv('houseprice.csv')<br/> <br/># Separate into train and test sets<br/>X_train, X_test, y_train, y_test = train_test_split(<br/>    data.drop(['Id', 'SalePrice'], axis=1),<br/>    data['SalePrice'],<br/>    test_size=0.3,<br/>    random_state=0<br/>    )<br/> <br/># set up the variable transformer<br/>tf = LogTransformer(variables = ['LotArea', 'GrLivArea'])<br/> <br/># fit the transformer<br/>tf.fit(X_train)<br/> <br/># transform the data<br/>train_t = tf.transform(X_train)<br/>test_t = tf.transform(X_test)</span></pre><h2 id="d2e1" class="ne lw it bd lx nf ng dn mb nh ni dp mf kn nj nk mj kr nl nm mn kv nn no mr np bi translated">sci kit-学习</h2><p id="9f64" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">Scikit-learn 通过其<a class="ae kb" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html" rel="noopener ugc nofollow" target="_blank"> FunctionTransformer() </a>将对数函数作为一个 NumPy 方法传递给转换器来应用对数转换，如下所示。</p><pre class="na nb nc nd gt nv nw nx ny aw nz bi"><span id="5161" class="ne lw it nw b gy oa ob l oc od">import pandas as pd<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.preprocessing import FunctionTransformer<br/> <br/># Load dataset<br/>data = data = pd.read_csv('houseprice.csv')<br/> <br/># Separate into train and test sets<br/>X_train, X_test, y_train, y_test = train_test_split(<br/>    data.drop(['Id', 'SalePrice'], axis=1),<br/>    data['SalePrice'],<br/>    test_size=0.3,<br/>    random_state=0<br/>    )<br/> <br/># set up the variable transformer<br/>tf = FunctionTransformer(np.log)<br/> <br/># fit the transformer<br/>tf.fit(X_train[['LotArea', 'GrLivArea']])<br/> <br/># transform the data<br/>train_t = tf.transform(X_train[['LotArea', 'GrLivArea']])<br/>test_t = tf.transform(X_test[['LotArea', 'GrLivArea']])</span></pre><h1 id="bf76" class="lv lw it bd lx ly nq ma mb mc nr me mf mg ns mi mj mk nt mm mn mo nu mq mr ms bi translated">Box Cox 变换</h1><p id="2ea0" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">Box-Cox 变换是一种通过使用变换参数λ来变换非正态变量的方法。</p><h2 id="4c8d" class="ne lw it bd lx nf ng dn mb nh ni dp mf kn nj nk mj kr nl nm mn kv nn no mr np bi translated">特征引擎</h2><p id="2565" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated"><a class="ae kb" href="https://feature-engine.readthedocs.io/en/latest/api_doc/transformation/BoxCoxTransformer.html" rel="noopener ugc nofollow" target="_blank"> BoxCoxTransformer() </a>将 Box-Cox 变换应用于数值变量，仅适用于非负变量。</p><p id="3de5" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">要修改的变量列表可以作为参数传递，或者<a class="ae kb" href="https://feature-engine.readthedocs.io/en/latest/api_doc/transformation/BoxCoxTransformer.html" rel="noopener ugc nofollow" target="_blank"> BoxCoxTransformer() </a>将自动选择并转换所有数值变量。</p><pre class="na nb nc nd gt nv nw nx ny aw nz bi"><span id="78cd" class="ne lw it nw b gy oa ob l oc od">import pandas as pd<br/>from sklearn.model_selection import train_test_split<br/>from feature_engine.transformation import BoxCoxTransformer<br/> <br/># Load dataset<br/>data = data = pd.read_csv('houseprice.csv')<br/> <br/># Separate into train and test sets<br/>X_train, X_test, y_train, y_test = train_test_split(<br/>    data.drop(['Id', 'SalePrice'], axis=1),<br/>    data['SalePrice'],<br/>    test_size=0.3,<br/>    random_state=0<br/>    )<br/> <br/># set up the variable transformer<br/>tf = BoxCoxTransformer(variables = ['LotArea', 'GrLivArea'])<br/> <br/># fit the transformer<br/>tf.fit(X_train)<br/> <br/># transform the data<br/>train_t = tf.transform(X_train)<br/>test_t = tf.transform(X_test)</span></pre><p id="5dfe" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">这个转换器实现的转换是<a class="ae kb" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.boxcox.html" rel="noopener ugc nofollow" target="_blank"> scipy.stats.boxcox </a>的转换，并作为熊猫数据帧返回。</p><h1 id="5c57" class="lv lw it bd lx ly nq ma mb mc nr me mf mg ns mi mj mk nt mm mn mo nu mq mr ms bi translated">sci kit-学习</h1><p id="feb2" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">Scikit-learn 通过其<a class="ae kb" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html" rel="noopener ugc nofollow" target="_blank"> PowerTransformer() </a>提供了 Box-Cox 和 Yeo-Johnson 变换。Box-Cox 要求输入数据必须是严格的正值。</p><pre class="na nb nc nd gt nv nw nx ny aw nz bi"><span id="26cc" class="ne lw it nw b gy oa ob l oc od">import pandas as pd<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.preprocessing import PowerTransformer<br/> <br/># Load dataset<br/>data = data = pd.read_csv('houseprice.csv')<br/> <br/># Separate into train and test sets<br/>X_train, X_test, y_train, y_test = train_test_split(<br/>    data.drop(['Id', 'SalePrice'], axis=1),<br/>    data['SalePrice'],<br/>    test_size=0.3,<br/>    random_state=0<br/>    )<br/> <br/># set up the variable transformer<br/>tf = PowerTransformer(method=”box-cox”)<br/> <br/># fit the transformer<br/>tf.fit(X_train[['LotArea', 'GrLivArea']])<br/> <br/># transform the data<br/>train_t = tf.transform(X_train[['LotArea', 'GrLivArea']])<br/>test_t = tf.transform(X_test[['LotArea', 'GrLivArea']])</span></pre><p id="f01a" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">与所有 Scikit-learn 转换器一样，结果以 NumPy 数组的形式返回。</p><h1 id="3630" class="lv lw it bd lx ly nq ma mb mc nr me mf mg ns mi mj mk nt mm mn mo nu mq mr ms bi translated">[数]离散化</h1><p id="4ec0" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">离散化将连续的数值变量划分为离散的和连续的区间，这些区间跨越了变量值的整个范围。离散化通常用于提高给定变量的信噪比，减少异常值的影响。</p><figure class="na nb nc nd gt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/62e4cd54a71a736afba4d12afd6df3a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*nS5CyDsir1g_LJswucfFvQ.png"/></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">离散化意味着将连续变量分类为离散区间——由<a class="ae kb" href="https://pixabay.com/de/users/krzysztof-m-1363864/" rel="noopener ugc nofollow" target="_blank"> Polski </a>从<a class="ae kb" href="https://pixabay.com/de/vectors/graph-histogramm-statistiken-3149003/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>生成图像</p></figure><p id="a567" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">Scikit-learn 提供了 KBinsDiscretizer()作为集中式转换器，通过它我们可以进行等宽、等频和 k 均值离散化。使用 KBinsDiscretizer()，我们可以通过在所有离散化技术上进行网格搜索来优化模型。</p><p id="3eb6" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">使用特征引擎，离散化过程通过单独的转换器实现。功能-引擎支持</p><ul class=""><li id="18b9" class="la lb it ke b kf kg kj kk kn lc kr ld kv le kz lf lg lh li bi translated">等宽离散化</li><li id="a78c" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">等频离散化</li><li id="6fb8" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">决策树离散化</li><li id="5786" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated">任意离散化。</li></ul><p id="a77a" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">此外，Scikit-learn 允许我们只通过设置编码参数就可以直接对 bin 进行热编码。使用特征引擎，如果我们希望将容器视为类别，我们可以在离散化转换器的后端运行任何类别编码器。</p><p id="0394" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">在下面的段落中，我们将比较包之间的等频率离散化的实现。</p><h1 id="484d" class="lv lw it bd lx ly nq ma mb mc nr me mf mg ns mi mj mk nt mm mn mo nu mq mr ms bi translated">等频率离散化</h1><p id="5bbd" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">这种类型的离散化将变量分成预定义数量的连续区间。容器间隔通常是百分位数。</p><h2 id="12a1" class="ne lw it bd lx nf ng dn mb nh ni dp mf kn nj nk mj kr nl nm mn kv nn no mr np bi translated">特征引擎</h2><p id="20f8" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated"><a class="ae kb" href="https://feature-engine.readthedocs.io/en/latest/api_doc/discretisation/EqualFrequencyDiscretiser.html" rel="noopener ugc nofollow" target="_blank">EqualFrequencyDiscretiser()</a>将数值变量值分类为等比例观察值的连续区间，其中区间限制根据百分位数计算。</p><p id="11d1" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">变量应被划分的区间数由用户决定。转换器可以将变量作为数字或对象返回(默认为数字)。</p><p id="5ff2" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">特征引擎所固有的，可以指示变量列表，或者离散化器将自动选择训练集中的所有数值变量。</p><pre class="na nb nc nd gt nv nw nx ny aw nz bi"><span id="8ea4" class="ne lw it nw b gy oa ob l oc od">import pandas as pd<br/>from sklearn.model_selection import train_test_split<br/>from feature_engine.discretisation import EqualFrequencyDiscretiser<br/> <br/># Load dataset<br/>data = data = pd.read_csv('houseprice.csv')<br/> <br/># Separate into train and test sets<br/>X_train, X_test, y_train, y_test = train_test_split(<br/>    data.drop(['Id', 'SalePrice'], axis=1),<br/>    data['SalePrice'],<br/>    test_size=0.3,<br/>    random_state=0<br/>    )<br/> <br/># set up the discretisation transformer<br/>disc = EqualFrequencyDiscretiser(<br/>    q=10,<br/>    variables=['LotArea', 'GrLivArea']<br/>    )<br/> <br/># fit the transformer<br/>disc.fit(X_train)<br/> <br/># transform the data<br/>train_t = disc.transform(X_train)<br/>test_t = disc.transform(X_test)</span></pre><p id="8c3e" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">EqualFrequencyDiscretiser()首先找到每个变量的区间边界，因为它符合数据。然后，它通过将值排序到区间来转换变量，并返回一个 pandas 数据帧。</p><h2 id="9fa7" class="ne lw it bd lx nf ng dn mb nh ni dp mf kn nj nk mj kr nl nm mn kv nn no mr np bi translated">sci kit-学习</h2><p id="c329" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">Scikit-learn 可以通过其<a class="ae kb" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html" rel="noopener ugc nofollow" target="_blank"> KBinsDiscretizer() </a>转换器，将“策略”参数设置为“分位数”来实现等频率离散化。</p><pre class="na nb nc nd gt nv nw nx ny aw nz bi"><span id="3304" class="ne lw it nw b gy oa ob l oc od">import pandas as pd<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.preprocessing import KBinsDiscretizer<br/> <br/># Load dataset<br/>data = data = pd.read_csv('houseprice.csv')<br/> <br/># Separate into train and test sets<br/>X_train, X_test, y_train, y_test = train_test_split(<br/>    data.drop(['Id', 'SalePrice'], axis=1),<br/>    data['SalePrice'],<br/>    test_size=0.3,<br/>    random_state=0<br/>    )<br/> <br/># set up the discretisation transformer<br/>disc = KBinsDiscretizer(n_bins=10, strategy='quantile')<br/> <br/># fit the transformer<br/>disc.fit(X_train[['LotArea', 'GrLivArea']])<br/> <br/># transform the data<br/>train_t = disc.transform(X_train[['LotArea', 'GrLivArea']])<br/>test_t = disc.transform(X_test[['LotArea', 'GrLivArea']])</span></pre><p id="7d4a" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">默认情况下，NumPy 数组输出被一次性编码到一个稀疏矩阵中。这可以进一步配置，例如使用“encode”参数将设置为序号编码方法。</p><h1 id="6e5c" class="lv lw it bd lx ly nq ma mb mc nr me mf mg ns mi mj mk nt mm mn mo nu mq mr ms bi translated">包扎</h1><p id="36d6" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">特征工程是端到端数据科学和机器学习管道中的一个重要组成部分。这是一个迭代过程，每个数据科学家都应该掌握，以优化模型性能。特征工程是非常耗时的，通过了解每个 Python 库的优点和优势来获得这些小小的效率肯定会在你的工作流程中积累起来。</p></div><div class="ab cl lo lp hx lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="im in io ip iq"><h1 id="197c" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">参考</h1><ul class=""><li id="aa9d" class="la lb it ke b kf mt kj mu kn of kr og kv oh kz lf lg lh li bi translated"><a class="ae kb" href="https://www.courses.trainindata.com/p/feature-engineering-for-machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习的特征工程</a> —在线课程</li><li id="d03c" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated"><a class="ae kb" href="https://packt.link/0ewSo" rel="noopener ugc nofollow" target="_blank"> Python 特性工程食谱</a> —书</li><li id="7f6f" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated"><a class="ae kb" href="https://feature-engine.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">特征引擎</a>:用于特征工程的 Python 库</li><li id="786f" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz lf lg lh li bi translated"><a class="ae kb" href="https://scikit-learn.org/stable/modules/preprocessing.html" rel="noopener ugc nofollow" target="_blank">用 Scikit-learn 预处理数据</a></li></ul></div><div class="ab cl lo lp hx lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="im in io ip iq"><h1 id="1169" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">相关文章</h1><p id="1416" class="pw-post-body-paragraph kc kd it ke b kf mt kh ki kj mu kl km kn mv kp kq kr mw kt ku kv mx kx ky kz im bi translated">本文是机器学习的特征工程系列文章的第八篇。您可以通过以下链接了解有关数据科学家如何预处理数据的更多信息:</p><ol class=""><li id="1aec" class="la lb it ke b kf kg kj kk kn lc kr ld kv le kz oi lg lh li bi translated"><a class="ae kb" href="https://trainindata.medium.com/feature-engineering-for-machine-learning-a-comprehensive-overview-a7ad04c896f8" rel="noopener">机器学习的特征工程</a></li><li id="7d8c" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz oi lg lh li bi translated"><a class="ae kb" href="https://www.blog.trainindata.com/variance-stabilizing-transformations-in-machine-learning/" rel="noopener ugc nofollow" target="_blank">变量转换</a></li><li id="60c3" class="la lb it ke b kf lj kj lk kn ll kr lm kv ln kz oi lg lh li bi translated"><a class="ae kb" href="https://trainindata.medium.com/best-resources-to-learn-feature-engineering-for-machine-learning-6b4af690bae7" rel="noopener">学习特征工程的优秀资源</a></li></ol></div></div>    
</body>
</html>