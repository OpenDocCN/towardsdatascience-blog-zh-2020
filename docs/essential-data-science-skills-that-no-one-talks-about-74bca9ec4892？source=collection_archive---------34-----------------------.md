# 无人谈论的基本数据科学技能。

> 原文：<https://towardsdatascience.com/essential-data-science-skills-that-no-one-talks-about-74bca9ec4892?source=collection_archive---------34----------------------->

## 老式的工程技能是你促进数据科学事业所需要的

谷歌“一个数据科学家的必备技能”。顶部结果是一长串技术术语，命名为*硬技能*。Python、代数、统计和 SQL 是最受欢迎的一些。后来，出现了*软技能*——沟通、商业头脑、团队合作精神等。

让我们假设你是一个拥有以上所有能力的超人。你从五岁开始编码，你是一个围棋大师，你的会议论文肯定会获得最佳论文奖。你知道吗？您的项目仍有很大的机会努力达到成熟，并成为成熟的商业产品。

最近的研究估计，超过 85%的数据科学项目无法进入生产阶段。这些研究为失败提供了许多原因。而且我也没有看到所谓的*必备技能*作为潜在原因被提及过一次。

我是不是在说上面的技巧不重要？当然，我不是。软硬技能都至关重要。关键是它们是必要的，但还不够。此外，它们很受欢迎，出现在每次谷歌搜索中。所以机会是你已经知道你是否需要提高你的数学水平或者团队合作。

我想说的是和流行的软硬技能互补的技能。我称之为*工程*技能。它们对于用真实的客户构建真实的产品特别有用。遗憾的是，数据科学家很少学习工程技能。它们伴随着经验而来。大多数初级数据科学家缺乏这些。

工程技能与数据工程领域无关。我用工程技能这个术语来区分它们和纯粹的科学或研究技能。根据剑桥词典， ***工程*** *是运用科学原理设计和建造机器、结构和其他物品*。在本文中，工程是将科学转化为产品的促成因素。如果没有适当的工程，模型将继续在预定义的数据集上运行。但是他们永远不会接触到真正的顾客。

## 外卖:

重要但经常被忽视的技能是:

1.  简单。确保你的代码和模型简单，但不要过于简单化。
2.  鲁棒性。你的假设是错误的。喘口气，继续编码。
3.  模块化。分而治之。深入挖掘最小的问题，然后找到一个开源解决它。
4.  水果采摘。不要只关注那些唾手可得的果实。但是要确保你总是有东西可以挑选。

# 简单

![](img/0f762d36a4e71e2d7f03496c13890c77.png)

图片来源:shutterstock

"*没有必要，实体不应相乘* " —奥卡姆的威廉。“*简单是最高级的复杂*”—莱昂纳多·达芬奇。*一切都应该尽可能简单，但不要简单到极点。“*这是我的座右铭之一——专注和简单*”——史蒂夫·乔布斯。*

我本可以用一整页的篇幅来引用关于简洁的内容。研究人员、设计师、工程师、哲学家和作家都称赞简约，并表示简约有其自身的价值。他们的理由变了，但结论是一样的。你达到完美不是因为没有什么可以添加，而是因为没有什么可以去除。

软件工程师绝对意识到简单的价值。关于如何让软件变得更简单，有很多书籍和文章。我记得接吻原则——保持简单，笨蛋——甚至在我的一门本科课程中也教过。简单的软件维护起来更便宜，更容易修改，也不容易出现 bug。对此有广泛的共识。

在数据科学中，情况非常不同。有很多文章，例如，Kristian Bondo Hansen 的《[简单的优点:算法交易中的 ML 模型](https://journals.sagepub.com/doi/full/10.1177/2053951720926558)》或者 Alfredo Gemma 的《[简单在数据科学革命中的作用](https://www.linkedin.com/pulse/role-simplicity-data-science-revolution-alfredo-gemma/)》。但它们是例外，而不是规律。数据科学家的主流往好里说不在乎，往坏里说更喜欢复杂的解决方案。

在继续解释为什么数据科学家通常不关心，为什么他们应该关心，以及如何处理之前，让我们看看简单意味着什么。根据剑桥词典的解释，*是容易理解或做的品质，是朴素的品质，没有不必要或多余的东西或装饰*。

我发现定义简单最直观的方式是*通过否定*，作为复杂的反义词。根据同一字典，复杂性是由许多相互连接的部分或元素组成的*；错综复杂*。虽然我们不能总是说某事简单，但我们通常可以说某事复杂。我们可以力求不复杂，不创造复杂的解决方案。

在数据科学中寻求简单的原因与在所有工程学科中的原因是一样的。更简单的解决方案要便宜得多。现实生活中的产品不是 Kaggle 比赛。需求是不断修改的。当一个复杂的解决方案需要适应新的条件时，它很快就变成了维护的噩梦。

很容易理解为什么数据科学家，尤其是应届毕业生，更喜欢复杂的解决方案。他们刚从学院回来。他们已经完成了论文，甚至可能发表了论文。一个学术出版物是由准确性、数学优雅性、新颖性、方法论来评判的，但很少由实用性和简单性来评判。

一个复杂的想法，提高 0.5%的准确率，对任何一个学生来说都是巨大的成功。对于数据科学家来说，同样的想法是失败的。即使它的理论是合理的，它也可能隐藏着被证明是错误的潜在假设。在任何情况下，增量改进几乎不值得复杂性的代价。

那么，如果你、你的老板、你的同事或你的下属喜欢复杂和“最优”的解决方案，该怎么办呢？如果是你的老板，你很可能在劫难逃，你最好开始找份新工作。在其他情况下，保持简单，愚蠢。

# 稳健性

![](img/64dd534e25a75017b83297bd7c1ca33e.png)

图片来源:shutterstock

俄罗斯文化中有一个概念叫做“avos”。维基百科将其描述为“盲目相信天意，指望纯粹的运气”。“Avos”是卡车司机超载决定的幕后黑手。它隐藏在任何不可靠的解决方案后面。

什么是稳健性？或者具体来说，数据科学中的鲁棒性是什么？与我们的讨论最相关的定义是“算法的健壮性是它对假设模型和现实之间的差异的敏感性”，来自 [Mariano Scain 论文](https://www.tau.ac.il/~mansour/students/Mariano_Scain_Phd.pdf)。对现实不正确的假设是数据科学家问题的主要来源。他们也是上面卡车司机的问题来源。

细心的读者可能会说，鲁棒性也是算法在执行过程中处理错误的能力。他们可能是对的。但它与我们的讨论不太相关。这是一个技术问题，有明确的解决方案。

在前大数据时代和前深度时代，构建强大系统的必要性显而易见。功能和算法设计是手动的。测试通常在成百上千个例子上进行。即使是最聪明的算法创造者也从未假设他们能想到所有可能的用例。

大数据时代是否改变了鲁棒性的本质？我们为什么要关心我们是否可以使用代表所有可想象场景的数百万数据样本来设计、训练和测试我们的模型呢？

它指出，鲁棒性仍然是一个重要的和未解决的问题。每年顶级期刊都会通过发表关于算法鲁棒性的论文来证明这一点，例如，“[提高深度神经网络的鲁棒性](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zheng_Improving_the_Robustness_CVPR_2016_paper.pdf)”和“[基于模型的鲁棒深度学习](https://arxiv.org/abs/2005.10247)”。数据的数量并没有转化为质量。用于培训的大量信息并不意味着我们可以涵盖所有用例。

而如果人参与其中，现实总是出乎意料，难以想象的。我们大多数人都不知道午餐吃什么，更不用说明天了。数据很难帮助预测人类行为。

那么，怎样做才能使你的模型更健壮呢？第一种选择是阅读适当的论文并实施他们的想法。这很好。但是这些论文并不总是通用的。通常，你不能把一个想法从一个领域复制到另一个领域。

我想介绍三种常规做法。遵循实践并不能保证健壮的模型，但是它显著地减少了脆弱解决方案的机会。

**性能安全裕度**。安全裕度是任何工程的基础。为了安全起见，通常的做法是获取需求并增加 20–30%。一个能装 1000kg 的电梯，会轻松装 1300kg。而且测试的是能装 1300kg 而不是 1000kg。工程师为意外情况做准备。

数据科学中的安全边际相当于什么？我认为是 KPI 或成功标准。即使发生了意想不到的事情，你依然会在门槛之上。

这种实践的重要结果是你将停止追逐增量改进。如果你的模型增加了 1%的 KPI，你就不可能稳健。在所有的统计显著性测试中，环境的任何微小变化都会扼杀你的努力。

**过度测试**。忘记单一测试/培训/验证部门。你必须在所有可能的组合中交叉验证你的模型。你有不同的用户吗？按照用户 ID 划分，做几十遍。您的数据会随着时间的推移而改变吗？根据时间戳划分，并确保每天在验证组中出现一次。用随机值或在数据点之间交换某些特征的值来“垃圾”您的数据。然后对脏数据进行测试。

我发现假设我的模型有错误是非常有用的，直到被证明不是这样。

关于数据科学和 ML 测试的两个有趣来源——[Alex Gude 的博客](https://alexgude.com/blog/software-testing-for-data-science/)和“[用 Python 进行机器学习，一种测试驱动的方法](https://www.amazon.com/Thoughtful-Machine-Learning-Python-Test-Driven/dp/1491924136)”。

**不要把城堡建在沙滩上。**减少对其他未测试组件的依赖。永远不要在另一个高风险和未经验证的组件之上构建您的模型。哪怕那个组件的开发者信誓旦旦说什么都不会发生。

# 模块性

![](img/274624d251320dcdf64823685b9370ed.png)

图片来源:快门股票

模块化设计是所有现代科学的基本原则。这是分析方法的直接结果。分析方法是一个将大问题分解成小问题的过程。分析方法是科学革命的基石。

你的问题越小越好。这里的“更好”并不意味着拥有它是件好事。这是必须的。这会节省大量的时间、精力和金钱。当一个问题很小，定义明确，并且没有大量假设时，解决方案是准确的，并且易于测试。

大多数数据科学家都熟悉软件设计环境中的模块化。但是，即使是最好的程序员，他们的 python 代码非常清晰，也常常无法将模块化应用于数据科学本身。

失败是很容易证明的。模块化设计需要一种方法将几个较小的模型组合成一个大模型。不存在这样的机器学习方法。

但是有一些实用的指导方针我觉得很有用:

*   **迁移学习**。迁移学习简化了现有解决方案的使用。你可以把它想成把你的问题分成两部分。第一部分创建低维特征表示。第二部分直接优化相关 KPI。
*   **开源**。尽可能使用现成的开源解决方案。根据定义，它使您的代码模块化。
*   **忘了被优化**。从头开始构建一个针对您的需求而优化的系统，而不是修改现有的解决方案，这是很有诱惑力的。但是只有当你能证明你的系统明显优于现有系统时，它才是合理的。
*   **模型组合**。不要害怕采取几种不同的方法，把它们扔进一个锅里。这是因为大多数卡格尔比赛都赢了。
*   **划分你的数据**。不要试图创造“一个伟大的模式”，虽然从理论上讲，这是可能的。例如，如果你处理预测客户行为，不要为一个全新的客户和已经使用你的服务一年的人建立相同的模型。

查看[组合深度学习](https://medium.com/@mattia.cd.ferrini/compositional-deep-learning-a40a07351c37)了解更多关于深度学习构建模块的细节。阅读[修剪过的神经网络惊人地模块化](https://arxiv.org/abs/2003.04881)以获得科学证明。

# 采果

![](img/df85dfc0dd9c7ab2e294c447da316351.png)

图片来源:shutterstock

产品经理和数据科学家之间的关系一直很紧张。产品经理希望数据科学家专注于唾手可得的成果。他们的逻辑很清楚。他们说企业只关心水果的数量和它们生长的地方。水果越多，我们做得越好。他们加入了各种流行词汇——帕累托、MVP、最好是最好的敌人等等。

另一方面，数据科学家指出，挂在低处的水果容易腐烂，味道也不好。换句话说，解决简单的问题影响有限，而且治标不治本。通常，这是学习新技术的借口，但通常他们是对的。

就我个人而言，我在两种观点之间徘徊。在阅读了 [P. Thiel 的《零比一》之后，我确信那些低挂的果实是在浪费时间。在初创企业呆了近 7 年后，我确信创造一个容易实现的 MVP 是正确的第一步。](https://www.amazon.com/Zero-One-Notes-Startups-Future/dp/0804139296)

最近，我开发了自己的方法，将这两个极端统一起来。数据科学家的典型环境是一个动态而怪异的世界，树木向四面八方生长。这些树一直在变换方向。它们可以倒着或横着生长。

最好的果实确实在顶端。但是如果我们花太多时间搭梯子，树就会移动。因此，最好的办法是瞄准顶部，但要不断监控顶部在哪里。

从隐喻到实践，在漫长的发展过程中，事情总有可能会发生变化。原来的问题将变得无关紧要，新的数据源将出现，原来的假设将被证明是错误的，KPI 将被取代，等等。

瞄准顶端是很好的，但是记住在每隔几个月推出一个工作产品的时候也要这么做。该产品可能不会带来最好的水果，但你会更好地了解水果是如何生长的。