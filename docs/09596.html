<html>
<head>
<title>Convergence of Random Variables</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">随机变量的收敛性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/convergence-of-random-variables-c1830b3c95bc?source=collection_archive---------20-----------------------#2020-07-08">https://towardsdatascience.com/convergence-of-random-variables-c1830b3c95bc?source=collection_archive---------20-----------------------#2020-07-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8fd9" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用简单的术语解释不同的聚合模式</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/eefad658c0d8dee50e8c69e6ecc169e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*FEE1M7LxMSkE0L1CWYAV4w.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">陈逸飞在<a class="ae ku" href="https://unsplash.com/photos/FPMRxKd7MxI" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="0a23" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">随机变量的收敛；</p><blockquote class="lr ls lt"><p id="c7c1" class="kv kw lu kx b ky kz ju la lb lc jx ld lv lf lg lh lw lj lk ll lx ln lo lp lq im bi translated">一个随机变量序列(RVs)在重复多次后会遵循一个固定的行为</p></blockquote><p id="b664" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">RVs (Xn)序列最初保持变化的值，并最终稳定在更接近 X 的数字。</p><p id="cba9" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">但是，“收敛到一个接近 X 的数”是什么意思呢？</p><p id="bea0" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">通常，RVs 可能不会精确地固定在一个最终的数字上，但是对于一个非常大的 n，方差会变得越来越小，导致序列收敛到一个非常接近 x 的数字。</p><p id="9d11" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">所以，让我们学习一个符号来解释上述现象:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/8c6bdd5a98b001c5b51227ccd4c402fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:168/format:webp/1*wg78WEonWHpzrXwdXmWoPw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">随着 n 变大，级数 Xn 收敛到最终值 X</p></figure><p id="0d47" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">作为数据科学家，我们经常会讨论一个算法是否收敛？现在，让我们通过下面的<a class="ae ku" href="https://i.stack.imgur.com/dBBM5.png" rel="noopener ugc nofollow" target="_blank">示例</a>来观察上述收敛特性:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi lz"><img src="../Images/a992ffae421e5e9d41ea14e8afb84afa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oVeic440tCoo_J9o2rfTmw.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">算法的收敛图</p></figure><p id="fe3a" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">既然我们已经彻底了解了收敛的概念，那么让我们来理解在上面的上下文中“接近”应该有多“接近”吧？</p><blockquote class="lr ls lt"><p id="fa11" class="kv kw lu kx b ky kz ju la lb lc jx ld lv lf lg lh lw lj lk ll lx ln lo lp lq im bi translated">按照数学家的说法，<strong class="kx iu">“接近”意味着要么提供两个 Xn 和 X 之间距离的上界，要么取一个极限</strong>。</p></blockquote><p id="69a0" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">下面，我们将根据取值限制列出三种主要的收敛类型<strong class="kx iu">:</strong></p><p id="2eb7" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">1)几乎必然收敛</p><p id="a6be" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">2)概率收敛</p><p id="31e2" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">3)分布的趋同性</p><p id="7383" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">但是，为什么我们会有不同类型的收敛，当它所做的只是确定一个数字的时候？这是因为，没有一种方法可以定义 RVs 的收敛性。</p><p id="4a19" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我将在下面的结构中解释每种收敛模式:</p><ul class=""><li id="d50d" class="me mf it kx b ky kz lb lc le mg li mh lm mi lq mj mk ml mm bi translated"><strong class="kx iu">直觉和概念类比:</strong>这将有助于初学者理解概念。如果是第一次接触，理解这些章节应该就足够了</li><li id="edf2" class="me mf it kx b ky mn lb mo le mp li mq lm mr lq mj mk ml mm bi translated"><strong class="kx iu">定义和数学示例:</strong>概念的正式解释，了解关键概念和三种模式之间的细微差别</li></ul><h1 id="618e" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated"><strong class="ak">不同收敛模式之间的关系:</strong></h1><p id="7015" class="pw-post-body-paragraph kv kw it kx b ky nk ju la lb nl jx ld le nm lg lh li nn lk ll lm no lo lp lq im bi translated">如果一个级数收敛于“几乎必然”强收敛，那么这个级数也以概率和分布收敛。但是，反过来就不正确了</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi np"><img src="../Images/b8dc71fa2a7d13294cfb363d4bbc2cca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7erwXM4J29h6IfzbeNZmaw.png"/></div></div></figure><h1 id="4b7b" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated"><strong class="ak">分布收敛:</strong></h1><p id="c618" class="pw-post-body-paragraph kv kw it kx b ky nk ju la lb nl jx ld le nm lg lh li nn lk ll lm no lo lp lq im bi translated"><strong class="kx iu">直觉:</strong>这意味着随着 n 变得越来越大，我们在建模分布以及下一个输出时变得越来越好。</p><p id="ab69" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">定义:</strong>一系列实数 RVs 依分布收敛如果当 n 增长到∞时 Xn 的 cdf 收敛到 X 的 cdf</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/8560493c6a10fa7d6e90ece98c38358e.png" data-original-src="https://miro.medium.com/v2/resize:fit:284/format:webp/1*a9zLt4I2LSNuOqArq5glZw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">其中 F 代表 cdf，对于所有 x € R 应该是连续的</p></figure><p id="7ae9" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">由于它只依赖于随机变量序列<em class="lu">和极限随机变量</em>的 cdf，因此不要求两者之间有任何依赖关系。所以，分布的收敛不像概率的收敛和几乎必然的收敛那样，告诉我们任何关于联合分布或概率空间的东西。</p><p id="ed5b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">批注</strong>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/f5a3072c4657c4df714214a735681be9.png" data-original-src="https://miro.medium.com/v2/resize:fit:136/format:webp/1*emXDlQ3xbfboJXEOabeVNQ.png"/></div></figure><p id="3c11" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">举例:</strong>中心极限定理(CLT)</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/94a8cae2bbb839aa38f9f0ad869516d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:284/format:webp/1*aQVIU2AVSP2n8HTCkLPG-w.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">𝜇和𝜎是总体的平均值和标准差</p></figure><p id="d291" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">问题</strong>:设 Xn 是 x₂,…suchx₁的随机变量序列，其 cdf 定义为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/f62be7090311c367d9bdc061d4551957.png" data-original-src="https://miro.medium.com/v2/resize:fit:394/format:webp/1*SVoaOz6vW3Kwv369OCJXNg.png"/></div></figure><p id="78a7" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">给定 X~ exp(1 ),让我们看看它是否收敛于分布</p><p id="5d58" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">解法:</strong>让我们首先计算 Xn 的 cdf 的极限:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/bd106ef9aa9ae1c660e2509cdb97f0e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/0*Nx27w-_fPo_Gj5OH"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/528d93ee296cbb3388ccdf079bd57502.png" data-original-src="https://miro.medium.com/v2/resize:fit:382/0*fada_VE11MQHKwPR"/></div></figure><p id="8838" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">当 Xn 的 cdf 等于 X 的 cdf 时，证明级数依分布收敛。</p><p id="e5e8" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">概念类比:</strong>在学习新技能的初始上升曲线期间，与技能被掌握时相比，输出是不同的。在一段时间内，可以肯定地说，产量或多或少是恒定的，并且在分布上趋于一致</p><h1 id="f572" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated"><strong class="ak">概率收敛</strong>:</h1><p id="b464" class="pw-post-body-paragraph kv kw it kx b ky nk ju la lb nl jx ld le nm lg lh li nn lk ll lm no lo lp lq im bi translated"><strong class="kx iu">直觉:</strong>Xn 与 X 相差大于ε(固定距离)的概率为 0。换句话说，随着系列的进展，不寻常结果的概率不断缩小。</p><p id="5a8b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">定义:</strong>称一个级数 Xn 按概率收敛于 X 当且仅当:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/ce19250c53814d08784e1c1ae1a8e47b.png" data-original-src="https://miro.medium.com/v2/resize:fit:402/0*_kDext_S8_Zvh8N7"/></div></figure><p id="2cd7" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">与分布收敛不同，概率收敛取决于联合 CDF，即 Xn 和 X 是相关的</p><p id="cca9" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">符号</strong>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/293615aba9f65d53c76203517138dd32.png" data-original-src="https://miro.medium.com/v2/resize:fit:136/0*y7mXOPihSJOSl3Y0"/></div></figure><p id="5f09" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">例子</strong>:弱大数定律</p><p id="2d34" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">因为“弱”和“强”大数定律是大数定律(LLN)的不同版本，并且主要基于收敛模式来区分，我们将在后面讨论它们。</p><p id="246b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">问题</strong>:设 Xn 是随机变量序列 X₁，X₂,…such，xn～unif(2–1∕2n，2+1∕2n)</p><p id="3ed3" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">对于给定的定数 0 &lt; ε&lt;1, check if it converges in probability and what is the limiting value?</p><p id="356f" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">解:</strong>对于 Xn 以概率收敛到一个数 2，我们需要找出 P(|Xn — 2| &gt; ε)对于某个ε是否趋向于 0</p><p id="a88d" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">让我们看看分布是什么样的，RV 偏离收敛常数超过一定距离的概率变为 0 的区域是什么。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi nw"><img src="../Images/eb7ec589f5f4085877147da77d7dd5f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4s6sqePo8xlaXrrywngfRQ.png"/></div></div></figure><p id="4886" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">概念类比:</strong>根据每个班级随机抽取 10 名学生的表现得出的学校排名，不会反映学校的真实排名。但是，当每个班级越来越多的学生的表现被计入学校排名时，它就接近了学校的真实排名。</p><h1 id="6d7a" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated"><strong class="ak">几乎确定收敛:</strong></h1><p id="a9bf" class="pw-post-body-paragraph kv kw it kx b ky nk ju la lb nl jx ld le nm lg lh li nn lk ll lm no lo lp lq im bi translated"><strong class="kx iu">直觉:</strong>对于非常高的 n 值，Xn 收敛到 X 的概率几乎是确定的即 prob 为 1。</p><p id="3027" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">定义:</strong> <em class="lu"> </em>无穷序列 RVs X1(ω)，X2(ω)… Xn(w)有一个概率为 1 的极限，就是 X(ω)</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/c3348300261b689a054f463b2a57caa8.png" data-original-src="https://miro.medium.com/v2/resize:fit:612/format:webp/1*sew28j0wadA6zXIGMwCVuw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">ω:定义随机变量的基础概率空间的样本空间</p></figure><p id="bcdc" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">注意极限在概率收敛中是在概率之外，而极限在几乎必然收敛中是在概率之内。</p><p id="94df" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">符号</strong>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/26edb62ef940f40dba3e52fee9f097fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:140/0*g9mWl0JgVc5gHbKP"/></div></figure><p id="e9e8" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">举例</strong>:强收敛定律</p><p id="ec77" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">问题:</strong>设 Xn 是一个随机变量序列，X₁、X₂,…such 认为</p><p id="c085" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">Xn = t + tⁿ，其中 T ~ Unif(0，1)</p><p id="3cf1" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">解法:</strong>我们把样本空间分成两个区域，应用下图所示的全概率定律:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi nz"><img src="../Images/8c91ca244318fb8857e008ee5c18d694.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gc8LLux6jK-I0KzgVXYORg.png"/></div></div></figure><p id="2596" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">当概率评估为 1 时，级数 Xn 几乎必然收敛</p><p id="56c8" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">概念类比:</strong>如果一个人基于抛硬币的结果，从他的语料库中向慈善机构捐赠了一定的金额，那么 X1，X2 暗示了第一天，第二天捐赠的金额。随着时间的推移，本金将不断减少，因此慈善捐赠的金额几乎肯定会减少到 0，即概率为 1。</p><p id="ae5d" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">依概率收敛和几乎必然收敛的区别:</strong></p><ul class=""><li id="fd45" class="me mf it kx b ky kz lb lc le mg li mh lm mi lq mj mk ml mm bi translated">“弱”大数定律是依概率收敛的结果，被称为弱收敛，因为它可以从较弱的假设中得到证明。它指出，随着 n 的增加，样本均值将更接近总体均值𝜇，但留下了<strong class="kx iu"> <em class="lu"> ε误差可能出现无限次的范围。</em> </strong></li><li id="c86a" class="me mf it kx b ky mn lb mo le mp li mq lm mr lq mj mk ml mm bi translated">然而，几乎确定收敛是一个更具约束性的收敛，它认为两个平均值之间的差小于ε的情况会无限频繁地出现，即概率为 1。也就是说，<strong class="kx iu"> <em class="lu">违反几乎必然收敛中所述的不等式仅在有限数量的情况下发生</em> </strong></li><li id="688b" class="me mf it kx b ky mn lb mo le mp li mq lm mr lq mj mk ml mm bi translated">Eric Towers <a class="ae ku" href="https://math.stackexchange.com/questions/2806713/difference-in-conditions-of-weak-and-strong-law-of-large-numbers" rel="noopener ugc nofollow" target="_blank">在这里做了一个很好的区分</a>。</li></ul><p id="270a" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">希望这篇文章能让你很好地理解不同的融合模式</p><p id="7e59" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">感谢阅读！！！</p><p id="bcc0" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">参考资料:</p><ul class=""><li id="16ef" class="me mf it kx b ky kz lb lc le mg li mh lm mi lq mj mk ml mm bi translated"><a class="ae ku" href="https://www.probabilitycourse.com/chapter7/7_2_4_convergence_in_distribution.php" rel="noopener ugc nofollow" target="_blank">https://www . probability course . com/chapter 7/7 _ 2 _ 4 _ convergence _ in _ distribution . PHP</a></li><li id="4ab2" class="me mf it kx b ky mn lb mo le mp li mq lm mr lq mj mk ml mm bi translated"><a class="ae ku" href="https://en.wikipedia.org/wiki/Convergence_of_random_variables" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/维基/Convergence _ of _ random _ variables</a></li></ul></div></div>    
</body>
</html>