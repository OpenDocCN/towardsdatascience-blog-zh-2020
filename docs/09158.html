<html>
<head>
<title>Making Sense of Text Clustering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解文本聚类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/making-sense-of-text-clustering-ca649c190b20?source=collection_archive---------2-----------------------#2020-07-01">https://towardsdatascience.com/making-sense-of-text-clustering-ca649c190b20?source=collection_archive---------2-----------------------#2020-07-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="46bd" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">数据科学/文本挖掘</h2><div class=""/><div class=""><h2 id="1fea" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">又能有多大用处？</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/bb928f71051a764c5fd02d8923477323.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uPVVnLzM4f_o56Ld"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><a class="ae le" href="https://unsplash.com/@sincerelymedia?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">真诚媒体</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="b92a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">文本无处不在，社交媒体是其最大的发电机之一。人们不断在许多平台上分享它们。我们可以使用文本挖掘方法将它们加工成有用的东西，而不是听之任之。一个著名的应用是情感分析，我们可以识别文本的观点是积极的、消极的还是中立的。但是在这里，我们将讨论另一种方法并理解它:<strong class="lh ja">文本聚类</strong>。</p><p id="a5e7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">作为无监督学习的一部分，聚类用于对相似的数据点进行分组，而无需知道数据属于哪个聚类。所以从某种意义上来说，文本聚类就是关于相似的文本(或句子)是如何分组在一起的。但是，我们究竟如何确定一些文本是相似的呢？怎样才能告诉机器“树”这个词和“植物”相似？</p><blockquote class="mb"><p id="fe2e" class="mc md iq bd me mf mg mh mi mj mk ma dk translated">把无监督学习想象成一种“物以类聚”的数学版本—  <a class="mm mn ep" href="https://medium.com/u/2fccb851bb5e?source=post_page-----ca649c190b20--------------------------------" rel="noopener" target="_blank"> <em class="ml">卡西科兹尔科夫</em> </a></p></blockquote><p id="4c09" class="pw-post-body-paragraph lf lg iq lh b li mo ka lk ll mp kd ln lo mq lq lr ls mr lu lv lw ms ly lz ma ij bi translated">对于那些不了解文本数据处理但和我在一起的人来说，这可能是压倒性的，我不会进入许多复杂的细节，而只是覆盖容易理解的重要点。</p><p id="1d78" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果你不是一个程序员，你可以跳过代码部分。对于感兴趣的人，你可以访问 GitHub 上的完整代码。</p><p id="e53d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">事不宜迟，我们开始吧！</p><h1 id="b1e9" class="mt mu iq bd mv mw mx my mz na nb nc nd kf ne kg nf ki ng kj nh kl ni km nj nk bi translated">让我们开始了解数据</h1><p id="e23b" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">我们将使用可以从 Kaggle 下载的开源数据。感谢 Dody Agung 创建了这个<a class="ae le" href="https://www.kaggle.com/dodyagung/accident" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja">印尼交通事故</strong> </a> <strong class="lh ja"> </strong>数据集。</p><p id="ef1b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">完整的数据集包含超过 150，000 条推文(语言为印度尼西亚语)，关键字为“kecelakaan”(意思是<strong class="lh ja">事故</strong>)。它包含推文 id、推文发布时间、抓取时间、推文发布者的用户名和完整推文。</p><p id="a722" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">手动标记的数据集也是由创建者提供的，包含 1000 条推文及其标志，无论推文是否指示真实的事故。标志 1 表示事故，标志 0 表示非事故。我们将尝试使用这个带标签的数据集进行文本聚类。下面看一下数据。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nq nr l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ns"><img src="../Images/2ec566315661c4d2e602b6a829299e34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SQ6l5c-rFVoxe5PV4Z6i9w.png"/></div></div></figure><h1 id="ce72" class="mt mu iq bd mv mw mx my mz na nb nc nd kf ne kg nf ki ng kj nh kl ni km nj nk bi translated"><strong class="ak">文本预处理</strong></h1><p id="f9af" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">如上所述，如何确定某些文本是否相似？计算机只计算数字，所以我们把文本翻译成数字！</p><p id="81df" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在我们开始之前，我们需要净化我们的文本。以这句话为例，让我们看看为什么我们需要清理它们:</p><blockquote class="nt nu nv"><p id="b5d6" class="lf lg nw lh b li lj ka lk ll lm kd ln nx lp lq lr ny lt lu lv nz lx ly lz ma ij bi translated">安全驾驶对我们每个人来说都是必须的🚌公交车，🚗车，🚛卡车或🛵两轮车..！！😱😱😱</p></blockquote><h2 id="9106" class="oa mu iq bd mv ob oc dn mz od oe dp nd lo of og nf ls oh oi nh lw oj ok nj iw bi translated">过滤和外壳折叠</h2><p id="0162" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">表情符号不是文本，符号和特殊字符也不是，比如“.”, "!"、“~”等。我们将过滤这些数据，使其成为纯文本。</p><p id="c336" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">做案例折叠也是因为可能会有带“开车”、“开车”、“开车”字样的推文。我们将所有文本都小写，以使它们具有相同的格式。</p><p id="06d0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在我们应用过滤和大小写折叠后，句子看起来会更清晰:</p><blockquote class="nt nu nv"><p id="c205" class="lf lg nw lh b li lj ka lk ll lm kd ln nx lp lq lr ny lt lu lv nz lx ly lz ma ij bi translated">无论是驾驶公共汽车、卡车还是两轮车，安全驾驶对我们每个人来说都是必须的</p></blockquote><h2 id="b883" class="oa mu iq bd mv ob oc dn mz od oe dp nd lo of og nf ls oh oi nh lw oj ok nj iw bi translated">词干和停用词移除</h2><p id="dcc9" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">词干化(或者我们可以使用<em class="nw">词汇化</em>)是将一个单词简化为其基本形式的过程。这里的要点是单词“drives”、“driving”、“driven”有相同的上下文，所以我们使用它的基本形式“drive”。参见词干化和词条化的区别，<a class="ae le" href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="919f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">另一件事是删除停用词，如“是”、“和”、“或”等。停用词指的是我们语言中最常见的词。我们经常看到它们，它们是多余的，所以它不能提供真实的信息。因此，我们完全删除它们。</p><p id="4daa" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在我们应用词干并删除停用词后，句子将如下所示:</p><blockquote class="nt nu nv"><p id="7249" class="lf lg nw lh b li lj ka lk ll lm kd ln nx lp lq lr ny lt lu lv nz lx ly lz ma ij bi translated">驾驶安全的道路必须我们每一个人是否驾驶公共汽车卡车两轮车</p></blockquote><p id="e31b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了进行前面提到的预处理，<a class="ae le" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> NLTK </a>(自然语言工具包)是语言处理的常用工具，但是因为语言是印度尼西亚语，所以我们使用<a class="ae le" href="https://github.com/sastrawi/sastrawi" rel="noopener ugc nofollow" target="_blank"> Sastrawi </a>来代替。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nq nr l"/></div></figure><h2 id="92a1" class="oa mu iq bd mv ob oc dn mz od oe dp nd lo of og nf ls oh oi nh lw oj ok nj iw bi translated"><strong class="ak">文字嵌入</strong></h2><p id="3937" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">这一部分是直观理解文本聚类如何工作的关键。我们可以很容易地找到一组整数/数的和、平均、计数，但是文本呢？在这一部分，我们将它们转换成数字。</p><p id="8ac1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">有像<a class="ae le" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html" rel="noopener ugc nofollow" target="_blank"> CountVectorizer </a>和<a class="ae le" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" rel="noopener ugc nofollow" target="_blank"> TF-IDF </a>这样的一键编码方法，但是我们将在这个实验中专门使用单词嵌入。基本上，单词嵌入所做的是<strong class="lh ja">将单词表示为空间</strong>中的向量，在空间中，相似的单词被映射到彼此附近。</p><p id="f68b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这是一个三维空间中单词向量表示的例子。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ol"><img src="../Images/e36cb0ca899e4b5c3d6ea3339b0c0c84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*45o-y4qw9IAVU7poFeK6Zg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:<a class="ae le" href="https://developers.google.com/machine-learning/crash-course/embeddings" rel="noopener ugc nofollow" target="_blank">机器学习速成班</a></p></figure><p id="f307" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了将单词嵌入应用到我们的数据集，我们将使用 fastText 库。他们提供了印度尼西亚语的预训练模型，但相反，我们将尝试使用可用的 150，000+tweet 作为我们的语料库来训练我们自己的单词嵌入模型。我已经预先处理了文本，并将其保存在<code class="fe om on oo op b">twitter.txt</code>中。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="b85c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">默认情况下，fastText 的<code class="fe om on oo op b">train_unsupervised</code>将使用 skipgram 模型并输出 100 维向量。这些向量表示一条推文在 100 个维度内的位置。</p><p id="9439" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果你注意到我们没有对句子进行分词，原因是有了<code class="fe om on oo op b">get_sentence_vector</code>，它会自动对句子进行分词(将文本拆分成块)。更多细节可以从<a class="ae le" href="https://fasttext.cc/docs/en/python-module.html" rel="noopener ugc nofollow" target="_blank">这里</a>了解车型。</p><p id="696a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">FastText 还计算单词之间的相似性得分。使用<code class="fe om on oo op b">get_nearest_neighbors</code>，我们可以看到最相似的前 10 个单词以及每个相似性得分。分数越接近 1，该单词与给定单词越相似。</p><p id="9a5c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这是来自 fastText 网站的演示。</p><pre class="kp kq kr ks gt oq op or os aw ot bi"><span id="1c12" class="oa mu iq op b gy ou ov l ow ox">model.get_nearest_neighbors(‘accomodation’)</span></pre><blockquote class="nt nu nv"><p id="82c9" class="lf lg nw lh b li lj ka lk ll lm kd ln nx lp lq lr ny lt lu lv nz lx ly lz ma ij bi translated">[(0.96342，'容纳')，(0.942124，'容纳')，(0.915427，'容纳')，(0.847751，'容纳')，(0.794353，'容纳')，(0.740381，'容纳')，(0.729746，'便利设施')，(0.725975，'餐饮')，(0.703177，'容纳')，(0.</p></blockquote><p id="c722" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">他们预先训练好的模型甚至知道<code class="fe om on oo op b">accomodation</code>的上下文可以是<code class="fe om on oo op b">catering</code>和<code class="fe om on oo op b">hospitality</code>。现在它更强大了，因为您注意到输入是对<code class="fe om on oo op b">accommodation</code>的拼写错误(是的，它可以处理错别字)。</p><p id="73d4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们的模型怎么样？我们去看看。</p><pre class="kp kq kr ks gt oq op or os aw ot bi"><span id="fbdf" class="oa mu iq op b gy ou ov l ow ox"># Motorcycle in Bahasa Indonesia<br/>model.get_nearest_neighbors(‘motor’)</span></pre><blockquote class="nt nu nv"><p id="5921" class="lf lg nw lh b li lj ka lk ll lm kd ln nx lp lq lr ny lt lu lv nz lx ly lz ma ij bi translated">[(0.776196300983429，' sepedamotor ')，(0.7229066491127014，' motor ')，(0.7132794260978699，' sepeda ')，(0.69809305678772，' motore ')，(0.6889493465423584，' motor ')，(0.6859888988)。</p></blockquote><pre class="kp kq kr ks gt oq op or os aw ot bi"><span id="032f" class="oa mu iq op b gy ou ov l ow ox"># Car in Bahasa Indonesia<br/>model.get_nearest_neighbors(‘mobil’)</span></pre><blockquote class="nt nu nv"><p id="c607" class="lf lg nw lh b li lj ka lk ll lm kd ln nx lp lq lr ny lt lu lv nz lx ly lz ma ij bi translated">[(0.7426463961601257，'林塞克')，(0.7367433905601501，'塔布拉克')，(0.7266382575035095，'美孚')，(0.7141972780227661，'美孚哇')，(0.7097604274749756，'林塞克')，，</p></blockquote><p id="4279" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">看起来不错！如果你是印度尼西亚人，你会清楚地说这些单词在同一语境中。像<code class="fe om on oo op b">mobilio</code>、<code class="fe om on oo op b">pajero</code>、<code class="fe om on oo op b">fortuner</code>、<code class="fe om on oo op b">mpv</code>这些词在印尼其实是家喻户晓的车模。</p><p id="efb3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">一旦训练完成，该模型将用于将每条推文转换成 100 维向量。这里有一个矢量推文的例子:</p><blockquote class="nt nu nv"><p id="cbeb" class="lf lg nw lh b li lj ka lk ll lm kd ln nx lp lq lr ny lt lu lv nz lx ly lz ma ij bi">[-0.03824997, 0.00133674, -0.0975338 , 0.07422361, 0.04062992, 0.15320793, 0.0624048 , 0.08707056, -0.04479782, 0.01363136, 0.17272875, -0.03097608, 0.05366326, -0.09492738, 0.06163749, 0.04166117, -0.0779877 , 0.11031814, 0.04414257, -0.04424104, 0.02991617, -0.02359444, 0.08660134, -0.01918944, -0.02529236, -0.06084985, 0.00374846, 0.07403581, 0.03064661, 0.0105409 , 0.02821296, -0.08867718, -0.00845077, -0.04583884, -0.03845499, -0.04432626, 0.08085568, 0.0762938 , -0.03690336, 0.00286471, 0.05640269, 0.08347917, -0.12400634, 0.06856565, 0.09385975, 0.07298957, -0.03306708, 0.07894476, -0.03820109, -0.05187325, -0.08153208, -0.05167899, -0.07915987, 0.05901144, 0.00445149, -0.14628977, 0.04536996, 0.12275991, 0.14212511, -0.04074997, 0.04834579, 0.1293375 , 0.13116567, 0.10201992, -0.1010689 , -0.01407889, -0.01707099, 0.13866977, 0.03039356, 0.08307764, 0.06886553, 0.08681376, 0.02241692, -0.0974027 , -0.02969944, -0.06031594, 0.07977851, 0.09534364, -0.0803275 , -0.18087131, 0.00296218, 0.06247464, -0.00784681, -0.0209177 , 0.10568991, -0.06968653, -0.07200669, 0.06571897, 0.01448524, 0.15396708, 0.00435031, 0.02272239, 0.05981111, -0.03069473, -0.11629239, -0.11808605, -0.01497007, -0.00028591, 0.02116462, -0.11837215]</p></blockquote><p id="377c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">那是一堆数字，不是吗？别试图在脑子里想象 100 个维度，好吗？人类不行(至少目前不行？)，但我们的计算机可以处理得很好！现在我们已经创建了单词 vectors，我们如何将相似的 tweets 聚集在一起呢？</p><h1 id="71be" class="mt mu iq bd mv mw mx my mz na nb nc nd kf ne kg nf ki ng kj nh kl ni km nj nk bi translated"><strong class="ak">文本聚类</strong></h1><p id="14d2" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">对于刷新，聚类是一种无监督学习算法，用于将数据聚类到<em class="nw"> k </em>个组(通常数量由我们预先定义),而无需实际知道数据属于哪个组。聚类算法将尝试自己学习模式。我们将使用最广泛使用的聚类算法:<a class="ae le" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html" rel="noopener ugc nofollow" target="_blank"> K-means </a>。该算法可以根据推文与聚类质心的距离对推文进行聚类。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="a242" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们已经存储了 tweet 所属的集群输出。我们试着把它画出来，但是怎样才能把 100 个维度可视化呢？</p><p id="3475" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">主成分分析(PCA)来拯救。这是一种常用的降维技术。并非所有的数据都代表了全貌，一些数据可能解释了一些事情，而另一些则不能。PCA 背后的思想是提取数据的主成分。这些主成分可用于可视化我们的数据，因为它们代表了我们的大部分数据。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="7e6e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">很好，现在让我们用 2D 散点图来形象化它。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nq nr l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oy"><img src="../Images/bd181bef2ad83b73e5fc7788b778a843.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LP9Bi5Yye3U1ey3_15FXPQ.png"/></div></div></figure><p id="5d2b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">一些数据点相互重叠。如果我们用 3D 投影呢？</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nq nr l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/ddbfed5f264ad0f0d3366c9895e3f570.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/1*6xJPZbHG6M4Ds8UuWanfuw.png"/></div></figure><p id="4982" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">漂亮！</p><h2 id="b0c3" class="oa mu iq bd mv ob oc dn mz od oe dp nd lo of og nf ls oh oi nh lw oj ok nj iw bi translated">但是等等，</h2><p id="eece" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">你们中的一些人注意到了吗，我们可以只建立一个<strong class="lh ja">三维单词嵌入模型</strong>而不是一个 100 维模型，然后对它使用 PCA。让我们试试那个。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="306c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">但是，我们如何比较哪种单词嵌入模型能够更好地聚类相似的推文呢？这就是我们使用手动标记的数据集来预测聚类的原因。我们可以检查真实的事故推文是否分组，是否与非事故推文在同一个簇中。</p><h2 id="f5bb" class="oa mu iq bd mv ob oc dn mz od oe dp nd lo of og nf ls oh oi nh lw oj ok nj iw bi translated">实验结果</h2><p id="2f12" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">我们来看看每个集群的标签比例。第一张图使用 3D 单词嵌入，而第二张图使用默认的 100 维。集群 0 的创建方式有很大的不同。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pa"><img src="../Images/6ed515432e143bd00232f9e55e508966.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mmf_uKW8OzmxoHexrkGwSA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">使用 3D 单词嵌入，聚类 0 正确分组了 87%的事故，聚类 2 正确分组了 97%的非事故。</p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pb"><img src="../Images/01c0391017ff72d3cdd74f5ef286ccb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gryamFvaEA9YCdC22EnUyA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">使用 100D 单词嵌入，聚类 0 正确分组了~99%的事故，而聚类 2 正确分组了 97.5%的非事故。</p></figure><p id="4b7b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">有了更多的维度，单词嵌入模型可以捕捉更多的信息，生成更好的聚类分组。使用 PCA 的可视化只是为了直观的理解。更优选的是能够准确聚类具有相同属性/特征的文本！</p><p id="199f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在，让我们看看每个集群是否有某种特征。我们将从每个集群中看到一些样本。我将为非印度尼西亚人描述每个集群的特征(或者您可以使用翻译)。</p><h2 id="6d61" class="oa mu iq bd mv ob oc dn mz od oe dp nd lo of og nf ls oh oi nh lw oj ok nj iw bi translated">聚类 0-事故-红色点</h2><p id="48c3" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">推文特点:可信用户的现场报道。</p><blockquote class="nt nu nv"><p id="948b" class="lf lg nw lh b li lj ka lk ll lm kd ln nx lp lq lr ny lt lu lv nz lx ly lz ma ij bi translated">23.27:@ PTJASAMARGA:Kun ciran KM 14—KM 16 arah Bitung PADAT，ada penanganan kecelakaan kendar aan truk fuso di 胡巴路，”,</p><p id="a978" class="lf lg nw lh b li lj ka lk ll lm kd ln nx lp lq lr ny lt lu lv nz lx ly lz ma ij bi translated">20.35 WIB # Tol _ Japek Kara Wang Timur KM 51-KM 52 arah Cikampek PADAT，ada Evakuasi Kecelakaan kenda raan Truk di la jur 1/kiri 和胡巴路,</p><p id="b3c4" class="lf lg nw lh b li lj ka lk ll lm kd ln nx lp lq lr ny lt lu lv nz lx ly lz ma ij bi translated">'♻️ @SenkomCMNP: 5:09 Wib。行驶里程超过 16+600 公里。Masih Penanganan Petugas。第一次和第二次是在莱瓦蒂。(uda)@ sonorafm 92 @ RadioElshinta【https://t.co/9QqgdoBzQW', T4】</p></blockquote><h2 id="4eb4" class="oa mu iq bd mv ob oc dn mz od oe dp nd lo of og nf ls oh oi nh lw oj ok nj iw bi translated">聚类 1 —绿色聚类—随机</h2><p id="9ae8" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">Tweet 特征:随机用户的随机 tweet，通常讲述他们的个人故事。</p><blockquote class="nt nu nv"><p id="636f" class="lf lg nw lh b li lj ka lk ll lm kd ln nx lp lq lr ny lt lu lv nz lx ly lz ma ij bi translated">剧情转折:我不知道阿比斯·凯瑟拉肯是谁，他可能是 UGD，也可能是其他人。\n\nTapi ya ga masalah sih。Yg 是一家专业的服装公司。<a class="ae le" href="https://t.co/0e2zHaMkCo'," rel="noopener ugc nofollow" target="_blank">https://t.co/0e2zHaMkCo',</a></p><p id="fdd5" class="lf lg nw lh b li lj ka lk ll lm kd ln nx lp lq lr ny lt lu lv nz lx ly lz ma ij bi translated">在 Margonda 的视频会议上，..你是阿拉..sedih liatnya..\n\nSudah biasa liat yg ky gt..Ga serem，tp sedih iya..图鲁特·贝尔杜卡..:(\ n \ n 最后一个是伊格·巴瓦·坎达兰，约恩·卢帕·贝尔多阿·贝佩吉安，哈特 2 和帕图希·兰布·阿雅..',</p><p id="ae3b" class="lf lg nw lh b li lj ka lk ll lm kd ln nx lp lq lr ny lt lu lv nz lx ly lz ma ij bi translated">'👦:“Abis kecelakaan dimna lo？”\n\n👧:" Gue GK kecelakaan kok aman 2 aja " \ n \ n👦:" trus itu knapa 卡姆 lo ancur"\n\nSABAR。卡姆·杰莱克·艾芒，</p></blockquote><h2 id="e57f" class="oa mu iq bd mv ob oc dn mz od oe dp nd lo of og nf ls oh oi nh lw oj ok nj iw bi translated">集群 2——紫色集群——并非偶然</h2><p id="d6a9" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">Tweet 特性:包含新闻和信息(不是关于实时事故，而是过去的事件)</p><blockquote class="nt nu nv"><p id="1c2e" class="lf lg nw lh b li lj ka lk ll lm kd ln nx lp lq lr ny lt lu lv nz lx ly lz ma ij bi translated">rekaman CCTV Kecelakaan Motor di PIK，潘德 Taman Grisenda:\ nht TPS://t . co/gmhlep 9 ivz mhmmdrhmtrmdhn \ n 访问精彩# MRahmatRamadhan '，</p><p id="0af1" class="lf lg nw lh b li lj ka lk ll lm kd ln nx lp lq lr ny lt lu lv nz lx ly lz ma ij bi translated">波音公司老板 Minta Maaf<a class="ae le" href="https://t.co/wLRhFy8oYE'," rel="noopener ugc nofollow" target="_blank">https://t.co/wLRhFy8oYE',</a></p><p id="f152" class="lf lg nw lh b li lj ka lk ll lm kd ln nx lp lq lr ny lt lu lv nz lx ly lz ma ij bi translated">台湾议会也增加了贫困人口的数量。https://t.co/GSWqziaKDN',<a class="ae le" href="https://t.co/GSWqziaKDN'," rel="noopener ugc nofollow" target="_blank"/></p></blockquote><h1 id="ccee" class="mt mu iq bd mv mw mx my mz na nb nc nd kf ne kg nf ki ng kj nh kl ni km nj nk bi translated">那么，下一步是什么？</h1><p id="212d" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">请记住，我们没有将标志数据提供给模型，但是<strong class="lh ja">一半</strong>的数据被正确地分组(~99%)到真实事故和非事故的箱中。了解了这一点，我们可以使用聚类方法来标记未标记的数据。标记数据集的最初目的是解决分类问题(监督学习)，但是正如我们所看到的，聚类技术可以用来进一步丰富它。</p><blockquote class="mb"><p id="503e" class="mc md iq bd me mf mg mh mi mj mk ma dk translated"><strong class="ak">“我们没有更好的算法。我们只是有更多的数据。”彼得·诺维格</strong></p></blockquote><p id="6bc3" class="pw-post-body-paragraph lf lg iq lh b li mo ka lk ll mp kd ln lo mq lq lr ls mr lu lv lw ms ly lz ma ij bi translated">有时候，更多的数据(当然是质量数据)比一个算法的改进有用得多。有了更多更好的数据，即使是简单的算法也能给出很棒的结果。在我们使用 3D 与 100D 单词嵌入模型的实验中，我们也可以看到这种现象，对吗？</p><p id="9de5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这是我的一个类比:</p><blockquote class="mb"><p id="a157" class="mc md iq bd me mf mg mh mi mj mk ma dk translated">一辆好的赛车可能足够快来赢得你的比赛，但你只能用一辆更好的车来取得更好的成绩。</p><p id="6c89" class="mc md iq bd me mf mg mh mi mj mk ma dk translated">你的驾驶技术就是算法，车就是数据。</p></blockquote><p id="6dec" class="pw-post-body-paragraph lf lg iq lh b li mo ka lk ll mp kd ln lo mq lq lr ls mr lu lv lw ms ly lz ma ij bi translated">因此，我希望阅读这篇文章的人能够对我们如何处理文本数据并将其用于文本聚类有更多的了解。如果有任何错误，请随意评论或指出。</p><p id="464e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">谢谢大家！祝大家平安健康。</p></div><div class="ab cl pc pd hu pe" role="separator"><span class="pf bw bk pg ph pi"/><span class="pf bw bk pg ph pi"/><span class="pf bw bk pg ph"/></div><div class="ij ik il im in"><h2 id="49da" class="oa mu iq bd mv ob oc dn mz od oe dp nd lo of og nf ls oh oi nh lw oj ok nj iw bi translated">参考</h2><p id="af4e" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">[1] Saputro，D. A .，&amp; Girsang，A. S .，<a class="ae le" href="https://doi.org/10.30534/ijeter/2020/04832020" rel="noopener ugc nofollow" target="_blank">使用来自社交媒体的机器学习对交通事故信息进行分类</a> (2020)，《国际工程研究新兴趋势杂志》，8(3)，630–637</p><p id="c4fc" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[2] Cassie Kozyrkov，<a class="ae le" href="https://hackernoon.com/unsupervised-learning-demystified-4060eecedeaf" rel="noopener ugc nofollow" target="_blank">无监督学习去神秘化</a> (2018)，黑客正午</p><p id="9718" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[3]博雅诺斯基，皮奥特&amp;格雷夫，爱德华&amp;茹林，阿曼德&amp;米科洛夫，托马斯。，<a class="ae le" href="https://arxiv.org/abs/1607.04606" rel="noopener ugc nofollow" target="_blank">用子词信息丰富词向量</a> (2017)，计算语言学协会汇刊</p><p id="b60c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[4] <a class="ae le" href="https://developers.google.com/machine-learning/crash-course/embeddings/" rel="noopener ugc nofollow" target="_blank">嵌入</a>，机器学习速成班</p></div><div class="ab cl pc pd hu pe" role="separator"><span class="pf bw bk pg ph pi"/><span class="pf bw bk pg ph pi"/><span class="pf bw bk pg ph"/></div><div class="ij ik il im in"><p id="873c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="nw">特别感谢</em> <a class="mm mn ep" href="https://medium.com/u/515de9dc778a?source=post_page-----ca649c190b20--------------------------------" rel="noopener" target="_blank"> <em class="nw">奥马尔·阿卜迪拉</em></a><em class="nw"/><a class="mm mn ep" href="https://medium.com/u/47cb6f2f50b6?source=post_page-----ca649c190b20--------------------------------" rel="noopener" target="_blank"><em class="nw">阿德里安·阿尔法里斯</em></a><em class="nw"/><a class="mm mn ep" href="https://medium.com/u/764dee96034b?source=post_page-----ca649c190b20--------------------------------" rel="noopener" target="_blank"><em class="nw">纳迪娅·毛利·阿文塔</em></a><em class="nw"/><a class="mm mn ep" href="https://medium.com/u/c5ecd26c517e?source=post_page-----ca649c190b20--------------------------------" rel="noopener" target="_blank"><em class="nw">斯蒂芬妮·苏吉哈托</em> </a> <em class="nw">，以及</em> <a class="mm mn ep" href="https://medium.com/u/82be1624681f?source=post_page-----ca649c190b20--------------------------------" rel="noopener" target="_blank"> <em class="nw">拉哈真·仁德萨里</em></a></p></div></div>    
</body>
</html>