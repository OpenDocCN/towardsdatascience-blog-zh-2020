# 线性回归与神经网络

> 原文：<https://towardsdatascience.com/linear-regression-v-s-neural-networks-cd03b29386d4?source=collection_archive---------4----------------------->

## 了解模型假设和输出的差异

![](img/c6a2805b5989b8214a1aafeb621ac20f.png)

照片由[陶黎黄](https://unsplash.com/@h4x0r3?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)在 [Unsplash](https://unsplash.com/s/photos/fight?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

人工智能的世界既令人兴奋，也让人误解。像“机器学习”和“人工智能”这样的热门词汇最终不仅扭曲了对其能力的一般理解，还扭曲了其功能与其他模型之间的关键差异。在本文中，我想讨论线性回归模型和标准前馈神经网络之间的主要区别。为此，我将对每个模型使用相同的数据集(可以在这里找到:【https://archive.ics.uci.edu/ml/datasets/Energy+efficiency】T4)，并比较 Python 中架构和结果的差异。

# 探索性数据分析

我们正在看 UCI 的能源效率数据集。在数据的上下文中，我们对每个列的定义如下:

*   **X1** —相对紧密度
*   **X2** —表面积
*   **X3** —墙区
*   **X4** —屋顶区域
*   **X5** —总高度
*   **X6** —方向
*   **X7** —玻璃区域
*   **X8** —玻璃面积分布
*   **y1** —加热负荷
*   **y2** —冷负荷

我们的目标是基于 X1-X8 预测热负荷和冷负荷。

让我们看看 Python 中的数据集…

下面是结果输出

```
X1     X2     X3      X4   X5  X6   X7  X8     Y1     Y2
0  0.98  514.5  294.0  110.25  7.0   2  0.0   0  15.55  21.33
1  0.98  514.5  294.0  110.25  7.0   3  0.0   0  15.55  21.33
2  0.98  514.5  294.0  110.25  7.0   4  0.0   0  15.55  21.33
3  0.98  514.5  294.0  110.25  7.0   5  0.0   0  15.55  21.33
4  0.90  563.5  318.5  122.50  7.0   2  0.0   0  20.84  28.28
```

现在，让我们将这些变量中的每一个相对于另一个绘制出来，以更好地了解我们的数据中发生了什么…

![](img/f48aefd396870f357f81538a25a5fdfa.png)

在上面的情节中发生了很多事情，所以让我们一步一步地分解它。最初，当绘制这些数据时，我寻找线性关系并考虑降维。主要是多重共线性的问题，它会夸大我们模型的可解释性，损害它的整体稳健性。

在上面的数据中立即突出的是两个因变量之间的强正线性关系和相对紧密度与表面积之间的强负线性关系(如果你仔细想想，这是有意义的)。

维数/特征缩减超出了本文的目的和范围，但是我觉得还是值得一提。

接下来，让我们创建一个关联热图，这样我们可以获得更多的洞察力…

![](img/1131e90e8652ccec07422fc5a4424bad.png)

为什么这很重要？我们绘制的关联热图让我们能够立即了解每个特性的数据中是否存在线性关系。显然，随着特性数量的急剧增加，这个过程必须自动化——但这也超出了本文的范围。通过了解我们的数据中是否存在强线性关系，我们可以采取适当的步骤来组合特征、减少维度并选择适当的模型。回想一下，线性回归模型基于线性关系假设运行，其中神经网络可以识别非线性关系。

# 线性与非线性关系

当我说模型可以识别数据中的线性和非线性(分别在线性回归和神经网络的情况下)关系时，我的意思是什么？下图给出了三个例子:正线性关系、负线性关系和非线性关系。

![](img/e2ed6094c63a9625339301f6600fbb1c.png)

[照片致谢](https://statistics.laerd.com/spss-tutorials/linear-regression-using-spss-statistics.php)

这就是我们进行初始数据分析(配对图、热图等)的原因，这样我们就可以根据具体情况确定最合适的模型。如果有一个单一的答案和一个普遍的主导模型，我们就不需要数据科学家、机器学习工程师或人工智能研究人员。

# 线性回归

在我们的回归模型中，我们对每个观测值中的每个特征进行加权，并确定相对于观测输出的误差。让我们用 Python 构建一个线性回归，看看这个特定数据集中的结果。

```
r_sq = 0.9028334357025505
```

我们的模型可以解释大约 90%的变化——考虑到我们没有对数据集做任何事情，这已经很不错了。

为了比较这两个模型，我们将着眼于均方差…

```
r_sq = 0.9028334357025505
mse = 9.331137808925114
```

# 神经网络

现在让我们用一个简单的顺序神经网络做完全相同的事情。序列神经网络是矩阵运算的线性组合序列。然而，存在激活函数形式的非线性组件，其允许识别非线性关系。对于这个例子，我们将使用 ReLU 作为我们的激活函数。具有讽刺意味的是，这是一个线性函数，因为我们还没有规范化或标准化我们的数据。(同样，这是另一个必须根据我们的数据逐案选择的组件。)

```
Epoch 1000/100032/768 [>.............................] - ETA: 0s - loss: 5.8660 - mse: 5.8660
768/768 [==============================] - 0s 58us/step - loss: 6.7354 - mse: 6.7354
```

神经网络减少了近 30%的 MSE。

# 结论

在与许多专业人士讨论 9/10 次后，回归模型将优于任何其他机器学习或人工智能算法。为什么即使 ML 和 AI 算法的准确率更高，也会出现这种情况？大多数时候，你是在向客户交付一个模型，或者需要根据模型的输出采取行动，并且必须告诉*为什么*。解释一个线性模型、它的假设以及为什么输出是这个样子是相对容易的。试图用一个神经网络来做这件事不仅会让人精疲力尽，而且会让那些没有参与开发过程的人感到非常困惑。