<html>
<head>
<title>The Right Way to Use Deep Learning for Tabular Data | Entity Embedding</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">将深度学习用于表格数据|实体嵌入的正确方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-right-way-to-use-deep-learning-for-tabular-data-entity-embedding-b5c4aaf1423a?source=collection_archive---------11-----------------------#2020-03-05">https://towardsdatascience.com/the-right-way-to-use-deep-learning-for-tabular-data-entity-embedding-b5c4aaf1423a?source=collection_archive---------11-----------------------#2020-03-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b010" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">从业者已经将自然语言处理(NLP)中使用的网络嵌入到表格数据中。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/071c4f2fde097db4b1197816649af25f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rs5cXFTOCnG98QC7"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">米卡·鲍梅斯特在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="0c25" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated">最近，我参加了一个深度学习课程，在这个课程中，我被分配了一个利用深度学习技术的项目。当我在职业生涯的前 6 个月从事结构化数据工作时，我立即想到了对表格数据使用深度学习或神经网络。</p><p id="6148" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在表格数据中使用深度学习并不是一个新想法。人们对这些数据使用全连接神经网络已经有很长时间了，但是它也有一些缺点；</p><ol class=""><li id="35a3" class="me mf it lb b lc ld lf lg li mg lm mh lq mi lu mj mk ml mm bi translated">神经网络需要大量数据</li><li id="9870" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated">与更流行的机器学习算法(例如随机森林、梯度推进树)相比，模型性能的增益微不足道</li><li id="e834" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated">缺乏可解释性</li></ol><p id="ee8f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，对表格数据使用深度学习从未真正起步。这是真的，直到从业者将自然语言处理(NLP)中使用的嵌入网络的想法转移到表格数据。</p><p id="49de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是它的工作原理。</p><p id="d31e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">传统上,“性别”或“种族”等分类变量使用一键编码进行处理，变量中的每个实体都有一个唯一的列来跟踪实体的存在。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/9bb7416421ef503829baf5761c7c2c29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EC7Ql24BWEHeawbaZ1jayQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">独热编码的例子</p></figure><p id="5c94" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种方法虽然将数据转换成适合机器学习算法的格式，但它假定实体之间是独立的，并产生稀疏矩阵。</p><p id="c2f9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一方面，实体嵌入使用向量来表示每个实体，而不是二进制值。这有几个优点:</p><ol class=""><li id="b99d" class="me mf it lb b lc ld lf lg li mg lm mh lq mi lu mj mk ml mm bi translated">消除计算效率低的稀疏矩阵问题</li><li id="f6a5" class="me mf it lb b lc mn lf mo li mp lm mq lq mr lu mj mk ml mm bi translated">生成显示每个实体之间关系的向量(获得额外的见解，而不是将它们视为独立的)</li></ol></div><div class="ab cl mt mu hx mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="im in io ip iq"><p id="bf42" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，我决定做一个使用表格的项目来演示实体嵌入的使用。我使用的数据集是来自 Kaggle 的 IEEE-CIS 欺诈检测数据，您可以在这里找到<a class="ae ky" href="https://www.kaggle.com/c/ieee-fraud-detection" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="afa1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是一步一步的代码(包括我在 Colab 工作时的 Google Colab 特定代码)。</p><p id="411a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，要检查 colab 中分配给您的 GPU，您可以运行以下代码。</p><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="8794" class="nf ng it nb b gy nh ni l nj nk">!nvidia-smi</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/c23b3d7592105460e270ea6328c89ce9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AmYvQGSIqVg6FluOeam0Sw.png"/></div></div></figure><p id="e8e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我的谷歌硬盘旁边，</p><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="a712" class="nf ng it nb b gy nh ni l nj nk">from google.colab import drive</span><span id="6057" class="nf ng it nb b gy nm ni l nj nk">drive.mount('/content/drive')</span></pre><p id="154d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从 Kaggle 下载数据集，为此您需要 Kaggle API 令牌。如果你需要任何帮助从 Kaggle 下载数据集，<a class="ae ky" href="https://www.kaggle.com/general/51898" rel="noopener ugc nofollow" target="_blank">这个</a>可能会有帮助。</p><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="2384" class="nf ng it nb b gy nh ni l nj nk">!mkdir /root/.kaggle</span><span id="956a" class="nf ng it nb b gy nm ni l nj nk">!echo '{"username":"USERNAME","key":"KEY"}' &gt; /root/.kaggle/kaggle.json</span><span id="ea1c" class="nf ng it nb b gy nm ni l nj nk">!chmod 600 /root/.kaggle/kaggle.json</span><span id="0b82" class="nf ng it nb b gy nm ni l nj nk">!kaggle competitions download -c ieee-fraud-detection</span><span id="d74a" class="nf ng it nb b gy nm ni l nj nk"># unzip all files</span><span id="c3e2" class="nf ng it nb b gy nm ni l nj nk">!unzip train_transaction.csv.zip<br/>!unzip test_transaction.csv.zip</span></pre><p id="bf8e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，将 csv 文件读入熊猫数据帧</p><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="d165" class="nf ng it nb b gy nh ni l nj nk">train = pd.read_csv("train_transaction.csv")<br/>test = pd.read_csv("test_transaction.csv")</span></pre><p id="6b26" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于这是一个欺诈检测数据集，拥有不平衡的数据并不奇怪。</p><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="3b52" class="nf ng it nb b gy nh ni l nj nk">train["isFraud"].mean() #  0.03499000914417313</span></pre><p id="e10f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于数据探索和特征工程不是这篇文章的目的，我将使用最小特征来预测欺诈标签。为了确保您可以复制我的代码，下面是我的处理步骤。</p><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="5db5" class="nf ng it nb b gy nh ni l nj nk"># generate time of day</span><span id="306c" class="nf ng it nb b gy nm ni l nj nk">train["Time of Day"] = np.floor(train["TransactionDT"]/3600/183)<br/>test["Time of Day"] = np.floor(test["TransactionDT"]/3600/183)</span><span id="c568" class="nf ng it nb b gy nm ni l nj nk"># drop columns</span><span id="2f67" class="nf ng it nb b gy nm ni l nj nk">train.drop("TransactionDT",axis=1,inplace=True)<br/>test.drop("TransactionDT",axis=1,inplace=True)</span><span id="3c21" class="nf ng it nb b gy nm ni l nj nk"># define continuous and categorical variables</span><span id="e6fe" class="nf ng it nb b gy nm ni l nj nk">cont_vars = ["TransactionAmt"]<br/>cat_vars = ["ProductCD","addr1","addr2","P_emaildomain","R_emaildomain","Time of Day"] + [col for col in train.columns if "card" in col]</span><span id="a24d" class="nf ng it nb b gy nm ni l nj nk"># set training and testing set</span><span id="9ca6" class="nf ng it nb b gy nm ni l nj nk">x_train = train[cont_vars + cat_vars].copy()<br/>y_train = train["isFraud"].copy()<br/>x_test = train[cont_vars + cat_vars].copy()<br/>y_test = train["isFraud"].copy()</span><span id="bd7a" class="nf ng it nb b gy nm ni l nj nk"># process cont_vars<br/># scale values</span><span id="2d20" class="nf ng it nb b gy nm ni l nj nk">from sklearn.preprocessing import StandardScaler<br/>scaler = StandardScaler()<br/>x_train["TransactionAmt"] = scaler.fit_transform(x_train["TransactionAmt"].values.reshape(-1,1))<br/>x_test["TransactionAmt"] = scaler.transform(x_test["TransactionAmt"].values.reshape(-1,1))</span><span id="d418" class="nf ng it nb b gy nm ni l nj nk"># reduce cardinality of categorical variables</span><span id="e863" class="nf ng it nb b gy nm ni l nj nk">idx_list = x_train["card1"].value_counts()[x_train["card1"].value_counts()&lt;=100].index.tolist()<br/>x_train.loc[x_train["card1"].isin(idx_list),"card1"] = "Others"<br/>x_test.loc[x_test["card1"].isin(idx_list),"card1"] = "Others"</span><span id="46b9" class="nf ng it nb b gy nm ni l nj nk"># fill missing</span><span id="c4d9" class="nf ng it nb b gy nm ni l nj nk">x_train[cat_vars] = x_train[cat_vars].fillna("Missing")<br/>x_test[cat_vars] = x_test[cat_vars].fillna("Missing")</span><span id="0719" class="nf ng it nb b gy nm ni l nj nk">for cat, index in categories.items():</span><span id="d33e" class="nf ng it nb b gy nm ni l nj nk">test[cat] = pd.Categorical(test[cat],categories=categories[cat],ordered=True)</span></pre><p id="9ba8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">处理步骤完成后，现在我们可以将分类变量转换成整数。</p><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="5d5a" class="nf ng it nb b gy nh ni l nj nk"># convert to numerical value for modelling</span><span id="1dc4" class="nf ng it nb b gy nm ni l nj nk">def categorify(df, cat_vars):</span><span id="ec60" class="nf ng it nb b gy nm ni l nj nk">categories = {}</span><span id="68f0" class="nf ng it nb b gy nm ni l nj nk">for cat in cat_vars:<br/>df[cat] = df[cat].astype("category").cat.as_ordered()<br/>categories[cat] = df[cat].cat.categories</span><span id="ac42" class="nf ng it nb b gy nm ni l nj nk">return categories</span><span id="f299" class="nf ng it nb b gy nm ni l nj nk"><br/>def apply_test(test,categories):</span><span id="c4cc" class="nf ng it nb b gy nm ni l nj nk">for cat, index in categories.items():<br/>test[cat] = pd.Categorical(test[cat],categories=categories[cat],ordered=True)</span><span id="c647" class="nf ng it nb b gy nm ni l nj nk"># convert to integers<br/>categories = categorify(x_train,cat_vars)<br/>apply_test(x_test,categories)</span><span id="759b" class="nf ng it nb b gy nm ni l nj nk">for cat in cat_vars:<br/>x_train[cat] = x_train[cat].cat.codes+1<br/>x_test[cat] = x_test[cat].cat.codes+1</span></pre><p id="bfd4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于高度不平衡的数据集，我不得不使用一种称为合成少数过采样技术(SMOTE)的技术人工生成更多的欺诈数据。文档可以在这里找到<a class="ae ky" href="https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html" rel="noopener ugc nofollow" target="_blank">。</a></p><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="0c5c" class="nf ng it nb b gy nh ni l nj nk">from imblearn.over_sampling import SMOTE</span><span id="f934" class="nf ng it nb b gy nm ni l nj nk">sm = SMOTE(random_state=0)</span><span id="8a03" class="nf ng it nb b gy nm ni l nj nk">x_sm, y_train = sm.fit_resample(x_train, y_train)<br/>x_train = pd.DataFrame(x_sm,columns=x_train.columns)</span></pre></div><div class="ab cl mt mu hx mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="im in io ip iq"><p id="1f1d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们可以对数据进行建模。这个实体嵌入的实现采用了杰瑞米·霍华德的“<a class="ae ky" href="http://course18.fast.ai/ml" rel="noopener ugc nofollow" target="_blank">程序员机器学习入门</a>课程的思想和最佳实践。因此，杰里米通过他的研究和经验选择了许多技术细节，如嵌入大小和隐藏层。无论如何，如果你没有看过这个课程，我强烈建议你参加这个课程，听听杰里米的机器学习方法。它也是完全免费的。</p><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="11aa" class="nf ng it nb b gy nh ni l nj nk"># get embedding size for each categorical variable</span><span id="e8d0" class="nf ng it nb b gy nm ni l nj nk">def get_emb_sz(cat_col,categories_dict):<br/>num_classes = len(categories_dict[cat_col])<br/>return int(min(600,round(1.6*num_classes**0.56)))</span></pre><p id="ded2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在来定义神经网络。网络的结构是连续变量与每个分类变量的嵌入层的简单连接。</p><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="7bd6" class="nf ng it nb b gy nh ni l nj nk"># define the neural networks</span><span id="b49e" class="nf ng it nb b gy nm ni l nj nk">from tensorflow.keras.layers import Input, Embedding, Dense, Reshape, Concatenate, Dropout, BatchNormalization</span><span id="7e0d" class="nf ng it nb b gy nm ni l nj nk">from tensorflow.keras import Model</span><span id="9a29" class="nf ng it nb b gy nm ni l nj nk">def combined_network(cat_vars,categories_dict,cont_vars, layers):</span><span id="21f2" class="nf ng it nb b gy nm ni l nj nk">inputs = []<br/>embeddings = []<br/>emb_dict ={}</span><span id="f4b6" class="nf ng it nb b gy nm ni l nj nk"># create embedding layer for each categorical variables</span><span id="ebd0" class="nf ng it nb b gy nm ni l nj nk">for i in range(len(cat_vars)):<br/>emb_dict[cat_vars[i]] = Input(shape=(1,))<br/>emb_sz = get_emb_sz(cat_vars[i],categories_dict)<br/>vocab = len(categories_dict[cat_vars[i]]) +1<br/>embedding = Embedding(vocab,emb_sz,input_length=1)(emb_dict[cat_vars[i]])<br/>embedding = Reshape(target_shape=(emb_sz,))(embedding)<br/>inputs.append(emb_dict[cat_vars[i]])<br/>embeddings.append(embedding)</span><span id="5355" class="nf ng it nb b gy nm ni l nj nk"># concat continuous variables with embedded variables</span><span id="782e" class="nf ng it nb b gy nm ni l nj nk">cont_input = Input(shape=(len(cont_vars),))<br/>embedding = BatchNormalization()(cont_input)<br/>inputs.append(cont_input)<br/>embeddings.append(embedding)</span><span id="0b02" class="nf ng it nb b gy nm ni l nj nk">x = Concatenate()(embeddings)</span><span id="a6c9" class="nf ng it nb b gy nm ni l nj nk"># add user-defined fully-connected layers separated with batchnorm and dropout layers</span><span id="c64e" class="nf ng it nb b gy nm ni l nj nk">for i in range(len(layers)):</span><span id="142b" class="nf ng it nb b gy nm ni l nj nk">if i ==0:<br/>x = Dense(layers[i],activation="relu")(x)<br/>else:<br/>x = BatchNormalization()(x)<br/>x = Dropout(0.5)(x)<br/>x = Dense(layers[i],activation="relu")(x)</span><span id="b9a5" class="nf ng it nb b gy nm ni l nj nk">output = Dense(1,activation="sigmoid")(x)<br/>model = Model(inputs,output)</span><span id="e9aa" class="nf ng it nb b gy nm ni l nj nk">return model</span></pre><p id="5e3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在初始化模型。</p><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="cc11" class="nf ng it nb b gy nh ni l nj nk">layers = [200,100]</span><span id="8b45" class="nf ng it nb b gy nm ni l nj nk">model = combined_network(cat_vars,categories,cont_vars, layers)</span><span id="9684" class="nf ng it nb b gy nm ni l nj nk">opt = tf.keras.optimizers.Adam(0.0001)</span><span id="d7ff" class="nf ng it nb b gy nm ni l nj nk">model.compile(optimizer=opt,loss='binary_crossentropy',metrics=["accuracy"])</span></pre><p id="24c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">处理神经网络的输入。</p><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="4f98" class="nf ng it nb b gy nh ni l nj nk"># process x_train input to fit model</span><span id="ed8d" class="nf ng it nb b gy nm ni l nj nk">input_list = []</span><span id="4dd4" class="nf ng it nb b gy nm ni l nj nk">for i in cat_vars:<br/>input_list.append(x_train[i].values)<br/>input_list.append(x_train[cont_vars].values)</span><span id="d5f5" class="nf ng it nb b gy nm ni l nj nk"># modify x_test input to fit model</span><span id="2ddd" class="nf ng it nb b gy nm ni l nj nk">test_list = []<br/>for i in cat_vars:<br/>test_list.append(x_test[i].values)<br/>test_list.append(x_test[cont_vars].values)</span></pre><p id="7f99" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">训练模特~</p><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="6902" class="nf ng it nb b gy nh ni l nj nk">model.fit(input_list,y_train,epochs=10)</span></pre><p id="88a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">做出预测</p><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="f69a" class="nf ng it nb b gy nh ni l nj nk">y_pred = model.predict(test_list)</span><span id="5adb" class="nf ng it nb b gy nm ni l nj nk"># choose a optimal threshold<br/>y_pred = y_pred&gt;0.1</span></pre><p id="4362" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，竞赛使用 ROC-AUC 对排行榜进行排名。因此，我们计算我们的 ROC-AUC，看看我们如何与他人相比。</p><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="f6a4" class="nf ng it nb b gy nh ni l nj nk">roc = metrics.roc_auc_score(y_test,y_pred)<br/>roc<br/>  0.8787572838641191</span></pre><p id="c377" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于一个只使用部分功能的模型来说，这还不错。</p></div><div class="ab cl mt mu hx mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="im in io ip iq"><p id="e221" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是了。使用实体嵌入进行 Kaggle 表格数据竞赛。希望你喜欢它。</p></div></div>    
</body>
</html>