<html>
<head>
<title>Recommender System — Bayesian personalized ranking from implicit feedback</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">推荐系统——基于隐式反馈的贝叶斯个性化排序</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/recommender-system-bayesian-personalized-ranking-from-implicit-feedback-78684bfcddf6?source=collection_archive---------17-----------------------#2020-09-01">https://towardsdatascience.com/recommender-system-bayesian-personalized-ranking-from-implicit-feedback-78684bfcddf6?source=collection_archive---------17-----------------------#2020-09-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9326" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">贝叶斯个性化排序&amp;自适应 K-最近邻的漫游推荐系统</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/62fe489124023b62722d0e4d7705b9bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8oNbeHSN8RKrijU89r4V3w.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">杰夫·谢尔登在<a class="ae ky" href="https://unsplash.com/collections/1680217/workspace?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="c3d0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">更普遍的是看到公司使用推荐系统算法，根据用户以前的购物体验来生产用户喜欢的商品。在线顾客在网上购物时会从易贝、亚马逊、沃尔玛等商店获得推荐商品。这篇文章的重点是项目推荐。项目推荐系统方法为从用户过去的数据集(例如购买历史、观看历史等)中学习的一组项目提供用户特定的排名。如今，推荐系统变化很大，从像评级这样的显式数据集的输入到像监控点击、观看时间、购买等这样的隐式数据集的输入。这些信息比较容易收集，但是很难推荐用户喜欢的项目。</p><p id="fc94" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">在本文中，你将学习推荐系统的奇异值分解和截断奇异值分解:</strong></p><p id="91ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">(1)个性化排名系统</p><p id="3a5b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">(2)问题陈述</p><p id="8bb0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">(3)贝叶斯个性化排序</p><p id="5108" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">(4)流程再造优化标准</p><p id="81d7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">(5) BPR 学习算法</p><p id="3dbd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">(6)矩阵分解</p><p id="0ab6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">(7)自适应 K 近邻</p><h2 id="a0dc" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">个性化排名系统</h2><p id="00d8" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">个性化排序向顾客提供排序的项目列表的项目推荐。这篇文章将着重于根据用户从过去的购买数据中得出的隐含行为，向客户推荐个性化的商品排序列表。从购买数据中观察，可以获得积极的观察结果，如用户的购买历史，而未观察到的用户-项目对数据很难用于模型输入，如未购买的项目、不感兴趣的项目或对其未来购买感兴趣的项目。</p><h2 id="4ec9" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">问题陈述</h2><p id="9eeb" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">对于隐式反馈系统，它能够检测像购买历史这样的正数据集。对于剩余的数据，它是实际负值和缺失值的混合。然而，机器学习模型无法学习缺失的数据。通常，项目推荐器基于用户对项目的偏好输出个性化得分 X_ui，并且项目从预测得分中排序。项目推荐器的机器学习模型提供训练数据，其中给定对(U，i) ∈ S 作为正类标签，并且(pairs 中的所有其他组合为负类标签。</p><p id="63a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该模型适合于预测值为 1 和 0 的正类，而对于其余的正类。当模型无法对项目((U × I) \ S)进行排序时，会出现问题，这些项目在训练期间作为负面反馈给出。一种替代方法是将正则化添加到模型中，以防止过度拟合。另一种方法是创建项目对作为训练数据，并优化以正确排列项目对，而不是对单个项目评分，同时忽略缺失值。从下面的照片来看，模型很难只从观察到的数据中学习。因此，所有的负数据都被替换为 0。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/6bfde6ebd13d7b7ffba2c1ce413d000c.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/format:webp/1*tDHBzQCQFWWhvZud4Ko3Vg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Photo0:观察到的 0 值和未观察到的 1 值。</p></figure><h2 id="e865" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">贝叶斯个性化排名(BPR)</h2><p id="7378" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">为了克服个性化排序任务，贝叶斯个性化排序结合了使用 p(I &gt; u j |θ)的似然函数和模型参数 p(θ)的先验概率的问题的贝叶斯分析。</p><p id="3f4a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这一节中，我们推导出一种解决个性化排序任务的通用方法。它包括个性化排序的通用优化标准 BPR-Opt，该标准将通过使用 p(I &gt; u j |θ)的似然函数和模型参数 p(θ)的先验概率对问题进行贝叶斯分析而得到</p><h2 id="d2e2" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">BPR 优化标准</h2><p id="e1da" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">贝叶斯方法是对所有项目 i ∈ I 进行排序，以最大化以下后验概率，其中θ表示任意模型类别的参数向量</p><blockquote class="mu mv mw"><p id="bd27" class="kz la mx lb b lc ld ju le lf lg jx lh my lj lk ll mz ln lo lp na lr ls lt lu im bi translated">p(θ| &gt; u)∞p(&gt; u |θ)p(θ)</p></blockquote><p id="60e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所有用户因素都是相互独立的，并且对于特定用户，每对项目(I，j)的排序是唯一的。</p><p id="1718" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，上述用户特定的似然函数可以用下面的公式再现。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/414e21008e2b857c7b525df8ff5dd64a.png" data-original-src="https://miro.medium.com/v2/resize:fit:554/format:webp/1*r31Ol6G2xN_g-12ucscu6Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">用户的可能性函数</p></figure><p id="1b2d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将用户确实更喜欢项目 I 而不是项目 j 的个体概率定义为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/cd0a252135d21bb3725c00b2b5e9ac34.png" data-original-src="https://miro.medium.com/v2/resize:fit:748/format:webp/1*BwmX0hl59oT_BMb2bW5t0w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">用户偏好项目 I 而非项目 j 的概率</p></figure><p id="4a78" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于个性化排序任务的贝叶斯建模方法，引入了广义先验密度 p(θ),它是均值为零且方差-协方差矩阵为σθ的正态分布。</p><blockquote class="mu mv mw"><p id="3bbb" class="kz la mx lb b lc ld ju le lf lg jx lh my lj lk ll mz ln lo lp na lr ls lt lu im bi translated">p(θ)∞N(0，σθ)</p></blockquote><p id="bdf5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过设置σθ=λθI，我们减少了未知超参数的数量。设置最大后验估计量来导出个性化排序 BPR-Opt 的优化准则。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/d824b69bf81ee6e87560a70400b7d5ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*xZRCZASYMDBo-QHvnMtjJg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">BPR-Opt 数学公式</p></figure><h2 id="ec09" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">BPR 学习算法</h2><p id="25a5" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">从上一节可以看出，该标准来自个性化排序，标准梯度下降不适于处理该问题。然后，引入 LearnBPR 作为随机梯度下降算法来优化模型性能。</p><p id="a556" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">BPR-Opt 相对于模型参数的梯度为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/d41e5fa5ff07c9fad78cc55bc95a5555.png" data-original-src="https://miro.medium.com/v2/resize:fit:682/format:webp/1*ptFkI7ZgHzHb2fyTWvGPZA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">梯度 BPR-Opt 数学公式</p></figure><p id="81d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">优化模型中的参数被指定为学习率α和正则化λθ。该模型是一个基于自举的随机梯度下降模型。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/a92ee06d7747f0011b8de21f23b09bac.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*-5m7ibBTGlln3zH4yQVB1g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Photo2:基于自举的随机梯度下降算法</p></figure><p id="677c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将介绍一种流行的随机梯度下降法。根据下面的等式，对每个三元组(u，I，j) ∈ D_s 执行更新。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/918e3017c6b42ed93a604c7bbabb0304.png" data-original-src="https://miro.medium.com/v2/resize:fit:554/format:webp/1*gqYFdqTG3oddOROoxerT9w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">随机梯度下降数学公式</p></figure><p id="b417" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">训练对上的方法顺序至关重要。当相同的用户-项目对会有许多更新时，遍历数据项或用户-项目会导致较差的收敛性。引入随机梯度下降算法来随机选择三元组(均匀分布)。这种方法可以减少在连续更新步骤中选择相同用户项目组合的机会。带替换的 Bootstrap 抽样方法能够停止用户-项目对的随机选择。在我们的评估中，单个步骤的数量是根据观察到的正反馈数量线性选择的。</p><h2 id="fdf4" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">BPR 学习模型</h2><p id="d738" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">矩阵分解和学习的 k-最近邻这两种不同的模型类别将对用户对某个项目的隐藏偏好进行建模。首先，我们分解估计量 x_uij，并将其定义为:</p><blockquote class="mu mv mw"><p id="300d" class="kz la mx lb b lc ld ju le lf lg jx lh my lj lk ll mz ln lo lp na lr ls lt lu im bi translated">xuij:= xui xuj</p></blockquote><p id="79e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，应用标准的协同过滤模型来预测ˇx _ ul。这种方法比原来的方法更好，因为它对两个预测值 x _ ui x _ uj 的差异进行分类，而不是将单个预测值 x_ul 回归为单个数字。</p><h2 id="acfd" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">矩阵分解</h2><p id="dcda" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">矩阵 X : U × I 的估计用于处理预测ˇX _ ui 的问题。目标矩阵由矩阵分解得到的两个低秩矩阵 W : |U| × k 和 H : |I| × k 的矩阵乘积生成。</p><blockquote class="mu mv mw"><p id="cfb2" class="kz la mx lb b lc ld ju le lf lg jx lh my lj lk ll mz ln lo lp na lr ls lt lu im bi translated">xˇ:= w * h^t</p></blockquote><p id="f60a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据下面的等式，有指定的参数。</p><p id="ec5a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">k:近似的维数/秩<br/>W _ u:W 中的特征向量，指示用户 u，类似地，H 的每一行 hi 描述一个项目 I</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/580f8d8d9ac1a33ee8f9e6b11e64f6d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/format:webp/1*gIb0F-u1SQfBNTr2RLQ6Ww.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">预测公式</p></figure><p id="7050" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">θ=(W，H):矩阵分解的模型参数。这些参数是潜在变量，用于模拟未观察到的用户和项目对。实现奇异值分解(SVD)以最小平方逼近 Xˇ到 X。通常，SVD 方法会过度拟合数据。然后，还有其他推荐的方法，如正则化最小二乘优化，非负因式分解，最大间隔因式分解。</p><p id="5419" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于排名任务，我们使用 LearnBPR 来估计用户是否更喜欢某个项目。通过 LearnBPR 方法，我们需要知道ˇx _ uij 相对于每个模型参数θ的梯度。下面，它显示了矩阵分解模型的导数。</p><p id="12e9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于排序任务，即评估用户是否喜欢某个项目，更好的方法是根据 BPR-Opt 标准进行优化。这可以通过使用我们提出的算法 LearnBPR 来实现。如前所述，使用 LearnBPR 进行优化时，只需知道相对于每个模型参数θ的梯度ˇx _ uij。对于矩阵分解模型，导数为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/1f7ed7324c6039c47899259466603704.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*-T9-09-xhjZ4hBiYOHG_rw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">矩阵分解模型的导数</p></figure><p id="01de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，还增加了三个正则项。</p><p id="9ec5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">λW:用户特征 W <br/> λH+:项目特征 H 的 hif 上的正更新<br/>λH——项目特征 H 的 hjf 上的负更新</p><h2 id="00e9" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">自适应 K 近邻</h2><p id="b435" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在协同过滤中还有另一种流行的方法，叫做 K-最近邻法，来自于项目(基于项目)或用户(基于用户)之间的相似性度量。对于 K-最近邻，我们基于 I 与用户在过去的历史数据中见过的所有其他项目的过去相似性，即 I + u，从用户 u 生成推荐项目 I 的预测。K-最近邻是从 I + u 的 K 个最相似的项目中产生的。c 是对称的项目相关性/项目相似性矩阵。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/9ac514ffd2d0fd6fbde1316b29c06a3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:354/format:webp/1*g-iFlCtIqyixeS_-AcRDDw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">K 近邻项目预测</p></figure><p id="64f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">kNN 中的模型参数是θ= C。C 通过应用启发式相似性度量来确定，例如余弦向量相似性:I。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/9283406498315daabd0d89b2a0f41a14.png" data-original-src="https://miro.medium.com/v2/resize:fit:416/format:webp/1*FMCNmMUcSKJEqOV3HD2iFA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">K 近邻的余弦向量相似性</p></figure><p id="7a3b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当模型学习时，相似性度量 C 将被更新。可以直接应用参数 C。另一方面，当参数 C 过大时，模型从 H : I × k 的因式分解 HHt 产生 C，后来，我们选择适应没有因式分解的 C。为了优化用于排名的 KNN 模型，使用 LearnBPR 算法来更新相对于模型参数 c 的-x _ uij 的梯度</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/093a831f34792b50dccb84d6305bc17a.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*uiY9K8KpB8t2b-y-YE7w1Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">KNN 梯度学习算法数学公式</p></figure><p id="64ff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有两个正则化常数，用于 cil 更新的λ+和用于 cjl 更新的λ。：</p><h1 id="4076" class="nl lw it bd lx nm nn no ma np nq nr md jz ns ka mg kc nt kd mj kf nu kg mm nv bi translated">python 代码的实践经验</h1><h2 id="645f" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">数据描述:</h2><p id="4bf5" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">有从<a class="ae ky" href="https://grouplens.org/datasets/movielens/1m/" rel="noopener ugc nofollow" target="_blank"> grouplens </a>网站提取的收视率、用户和电影数据集。这些文件包含来自 6000 名 MovieLens 用户的大约 4000 部电影的大约 100 万个匿名评级。分级数据包括用户 ID、电影 ID 和分级。用户文件包含用户的人口统计信息，如性别、年龄、职业和邮政编码。电影数据集包含电影 ID、标题和类型等基本信息。</p><h2 id="1d5c" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">基于隐式反馈的贝叶斯个性化排序</h2><p id="2949" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">对于建模方法，在 Pytorch 模型中实现了个性化排序系统，即来自贝叶斯分析的最大后验估计器。此外，模型的优化是通过一个基于随机梯度下降和 bootstrap 采样的通用学习算法来完成的。</p><h2 id="f0a5" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">数据预处理</h2><p id="5479" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">从用户和评级数据集中，我们用唯一用户给出的电影评级创建唯一的 userid 映射。此外，评级数据集中的唯一项目映射。创建 train_user_matrix 和 test_user_matrix 时有两种方法。一个是随机选择的用户，另一个是考虑时间顺序因素。通过训练和测试集列表，我们可以为矩阵输入创建用户和项目对。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="532f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于模型输入数据，我们使用 Pytorch 库中的 DataLoader 对象。DataLoader 从数据集和采样器的组合中遍历数据集。数据加载器通过参数<code class="fe ny nz oa ob b">batch_size.</code>批量创建数据。该参数决定每批加载多少个样本。DataLoader 类中还有另一个<code class="fe ny nz oa ob b">num_worker</code>参数，它指定了多少个子进程用于数据加载。</p><h2 id="aa47" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">系统模型化</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="64e9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们创建具有用户索引的用户矩阵(u ),具有用户偏好的所有项目的项目索引(I ),以及用户不偏好的项目索引(j)。然后用 u 和 I 相乘生成矩阵 x_ui，用每行求和。并且，矩阵 x_uj 是用 u 和 j 的乘积生成的，并且对每一行求和。矩阵 x_uij:矩阵 x_ui —矩阵 x_uj。概率由矩阵 x_uij 的 sigmoid 函数呈现，并对值求和。正则化增加了权重衰减参数乘以用户和项目矩阵的归一化，并对平方函数求和。数学公式如下。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/00ca6f207e34b427e3a239dbb711bc77.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*_2_xjxXnMpss-emb7g-z9Q.png"/></div></figure><p id="9e96" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">稍后，预测输出推荐项目的最高概率，并存储在列表中。</p><h2 id="dce4" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">数据加载器和丢失的功能</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="efcc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们生成一个批量为 4096 的 DataLoader 类，并分配 16 个工作线程。由于数据集非常大，我们分配了 16 个子流程来并行处理数据。Adam optimizer 的学习率设置为 0.0001。反向传播有随机梯度下降来优化模型。对于每个批次，我们记录损失、精确率和召回率。</p><h1 id="8ae3" class="nl lw it bd lx nm nn no ma np nq nr md jz ns ka mg kc nt kd mj kf nu kg mm nv bi translated">结果</h1><p id="cb78" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">模型输入有两种不同的数据集。一个是带有 userid 和 itemid 的随机数据，另一个是时序数据集。</p><p id="a25b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">精度产生如下。左手边是随机数据。从左边的图来看，1 个项目的推荐比 5 个和 10 个电影的推荐产生更好的结果。在右图中，时间顺序输入数据集的结果比随机数据稍差，因为模型很难将时间顺序因素捕捉到模型中。</p><div class="kj kk kl km gt ab cb"><figure class="od kn oe of og oh oi paragraph-image"><img src="../Images/d8d042e6ec92bbb6aea0e9075b7d2400.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*H6QO_lcZeAdGtyP70TTcGA.png"/></figure><figure class="od kn oe of og oh oi paragraph-image"><img src="../Images/4d7b180481bc48fe6bb2b7ca36c3696e.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*20xVtqOqgKvkKb7dNJxfNA.png"/></figure></div><h2 id="7396" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">未来工作:</h2><ul class=""><li id="a2b6" class="oj ok it lb b lc mo lf mp li ol lm om lq on lu oo op oq or bi translated">处理稀疏矩阵。从数据预处理方法上，过滤电影，而不是从用户喜欢的类别。</li><li id="6448" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">添加更多的用户矩阵特征，如用户的朋友关系、会员资格、点击率等。</li><li id="0781" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">将时间因素纳入模型结构</li></ul><h1 id="7f43" class="nl lw it bd lx nm nn no ma np nq nr md jz ns ka mg kc nt kd mj kf nu kg mm nv bi translated">最后</h1><ul class=""><li id="def9" class="oj ok it lb b lc mo lf mp li ol lm om lq on lu oo op oq or bi translated">贝叶斯个性化排序使用 p(I &gt; u j |θ)的似然函数和模型参数 p(θ)的先验概率。贝叶斯方法是对所有项目 i ∈ I 进行排序，以最大化以下后验概率</li><li id="7ec4" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">对于排名任务，我们使用 LearnBPR 从矩阵分解中估计用户是否更喜欢某个项目。通过计算ˇx _ uij 相对于每个模型参数θ的梯度来实现模型的优化。</li><li id="5081" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">从项目(基于项目)或用户(基于用户)之间的相似性度量导出的 k-最近邻方法，基于 I 与用户在过去的历史数据中看过的所有其他项目的过去相似性，生成来自用户 u 的推荐项目 I 的预测。</li></ul><h1 id="5822" class="nl lw it bd lx nm nn no ma np nq nr md jz ns ka mg kc nt kd mj kf nu kg mm nv bi translated">参考</h1><ul class=""><li id="e271" class="oj ok it lb b lc mo lf mp li ol lm om lq on lu oo op oq or bi translated">BPR:来自隐性反馈的贝叶斯个性化排名<br/><a class="ae ky" href="https://arxiv.org/pdf/1205.2618.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1205.2618.pdf</a></li></ul></div></div>    
</body>
</html>