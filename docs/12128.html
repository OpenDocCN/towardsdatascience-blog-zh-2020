<html>
<head>
<title>Beginner’s guide to building Artificial Neural Networks using Keras in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Python 中的 Keras 构建人工神经网络的初学者指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/beginners-guide-to-building-artificial-neural-networks-using-keras-in-python-bdc4989dab00?source=collection_archive---------19-----------------------#2020-08-21">https://towardsdatascience.com/beginners-guide-to-building-artificial-neural-networks-using-keras-in-python-bdc4989dab00?source=collection_archive---------19-----------------------#2020-08-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="c6cf" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">初学者的深度学习</h2><div class=""/><div class=""><h2 id="7d2e" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">创建网络架构、训练、验证和保存模型并使用它进行推理的提示和技巧。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/3bf8bc2ab4a63f6df1fec91d2d93eb81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*eF4HrPv648FkmMX9.jpg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片由<a class="ae lh" href="https://pixabay.com/users/geralt-9301/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=3537401" rel="noopener ugc nofollow" target="_blank"> Gerd Altmann </a>从<a class="ae lh" href="https://pixabay.com/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=3537401" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>拍摄</p></figure><h1 id="3f79" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">为什么是 Keras，而不是 Tensorflow？</h1><blockquote class="ma mb mc"><p id="7f64" class="md me mf mg b mh mi kd mj mk ml kg mm mn mo mp mq mr ms mt mu mv mw mx my mz im bi translated">如果你在问“我应该用 keras 还是 tensorflow？”，你问错问题了。</p></blockquote><p id="28a7" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">当我第一次开始我的深度学习之旅时，我一直认为这两者是完全独立的实体。好吧，截至<a class="ae lh" href="https://github.com/keras-team/keras/issues/5050" rel="noopener ugc nofollow" target="_blank">2017 年年中</a>，他们不是！<strong class="mg jd"> Keras，一个神经网络 API，现在已经完全集成在 TensorFlow </strong>中。那是什么意思？</p><p id="10ba" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">这意味着您可以在使用高级 Keras API 或低级 TensorFlow API 之间进行选择。<strong class="mg jd">高级</strong>-<strong class="mg jd">API</strong>在一个命令中提供更多的功能，并且更易于使用(与低级 API 相比)，这使得它们甚至对于非技术人员也是可用的。<strong class="mg jd">低级 API</strong>允许高级程序员在非常精细的<strong class="mg jd">级别</strong>上操作模块内的功能，从而允许为新颖的解决方案定制实现。</p><p id="9ad4" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated"><em class="mf">注意:出于本教程的目的，我们将只使用 Keras！</em></p><h1 id="a01b" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">让我们直接进入编码</h1><p id="ceae" class="pw-post-body-paragraph md me it mg b mh nd kd mj mk ne kg mm na nf mp mq nb ng mt mu nc nh mx my mz im bi translated">我们首先在机器上安装 Keras。正如我之前所说，Keras 集成在 TensorFlow 中，因此您所要做的就是在您的终端(Mac OS)中<code class="fe ni nj nk nl b">pip install tensorflow</code>访问 Jupyter 笔记本中的 Keras。</p><h2 id="7213" class="nm lj it bd lk nn no dn lo np nq dp ls na nr ns lu nb nt nu lw nc nv nw ly iz bi translated">资料组</h2><p id="776e" class="pw-post-body-paragraph md me it mg b mh nd kd mj mk ne kg mm na nf mp mq nb ng mt mu nc nh mx my mz im bi translated">我们将使用贷款申请数据集。它有两个预测特征，一个连续变量- <code class="fe ni nj nk nl b">age</code>和一个分类变量- <code class="fe ni nj nk nl b">area</code>(农村与城市)，以及一个二元结果变量<code class="fe ni nj nk nl b">application_outcome</code>，可以取值 0(批准)或 1(拒绝)。</p><pre class="ks kt ku kv gt nx nl ny nz aw oa bi"><span id="a237" class="nm lj it nl b gy ob oc l od oe">import pandas as pd</span><span id="853b" class="nm lj it nl b gy of oc l od oe">df = pd.read_csv('loan.csv')[['age', 'area', 'application_outcome']]<br/>df.head()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi og"><img src="../Images/9ccbd423d50e196058454eb94829ee3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*T8mNrMCszIMN3RnD51GvrA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">我们数据集中的样本。</p></figure><h2 id="335a" class="nm lj it bd lk nn no dn lo np nq dp ls na nr ns lu nb nt nu lw nc nv nw ly iz bi translated">预处理数据</h2><p id="9133" class="pw-post-body-paragraph md me it mg b mh nd kd mj mk ne kg mm na nf mp mq nb ng mt mu nc nh mx my mz im bi translated">为了避免过度拟合，我们将使用<code class="fe ni nj nk nl b">MinMaxScaler</code>在 0 和 1 之间缩放<code class="fe ni nj nk nl b">age</code>，并使用<code class="fe ni nj nk nl b">Sklearn</code>工具包中的<code class="fe ni nj nk nl b">LabelEncoder</code>对<code class="fe ni nj nk nl b">area</code>和<code class="fe ni nj nk nl b">application_outcome</code>特征进行标签编码。我们这样做是为了将所有输入要素放在同一个比例上。</p><pre class="ks kt ku kv gt nx nl ny nz aw oa bi"><span id="d77d" class="nm lj it nl b gy ob oc l od oe">from sklearn.preprocessing import LabelEncoder, MinMaxScaler<br/>from itertools import chain</span><span id="0e40" class="nm lj it nl b gy of oc l od oe"># Sacling the Age column<br/>scaler = MinMaxScaler(feature_range = (0,1))</span><span id="1c7e" class="nm lj it nl b gy of oc l od oe">a = scaler.fit_transform(df.age.values.reshape(-1, 1))<br/>x1 = list(chain(*a))</span><span id="0621" class="nm lj it nl b gy of oc l od oe"># Encoding the Area, Application Outcome columns<br/>le = LabelEncoder()</span><span id="62ba" class="nm lj it nl b gy of oc l od oe">x2 = le.fit_transform(df.area.values)<br/>y = le.fit_transform(df.application_outcome)</span><span id="71f3" class="nm lj it nl b gy of oc l od oe"><br/># Updating the df<br/>df.age = x1<br/>df.area = x2<br/>df.application_outcome = y</span><span id="fe7d" class="nm lj it nl b gy of oc l od oe">df.head()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/fc68143f20207c29663d69cc6b5c6c08.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*3mXCeq6tkzgm9Q_bA2KWTg.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">来自我们的<strong class="bd oi">缩放的</strong>数据集的样本</p></figure><p id="58b5" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">如果您阅读了<a class="ae lh" href="https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#fit" rel="noopener ugc nofollow" target="_blank"> Keras 文档</a>，它要求输入数据是 NumPy 数组类型。这就是我们现在要做的！</p><pre class="ks kt ku kv gt nx nl ny nz aw oa bi"><span id="8fbb" class="nm lj it nl b gy ob oc l od oe">scaled_train_samples = df[['age', 'area']].values<br/>train_labels = df.application_outcome.values</span><span id="6b31" class="nm lj it nl b gy of oc l od oe">type(scaled_train_samples) <em class="mf"># numpy.ndarray</em></span></pre><h2 id="5bf4" class="nm lj it bd lk nn no dn lo np nq dp ls na nr ns lu nb nt nu lw nc nv nw ly iz bi translated">生成模型架构</h2><p id="d1cd" class="pw-post-body-paragraph md me it mg b mh nd kd mj mk ne kg mm na nf mp mq nb ng mt mu nc nh mx my mz im bi translated">建立 Keras 模型有两种方式:<em class="mf">顺序</em>(最基本的一种)和<em class="mf">泛函(复杂网络用</em>)。</p><p id="5a93" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">我们将创建一个<strong class="mg jd">序列模型</strong>，它是一个线性层叠。也就是说，顺序 API <strong class="mg jd"> </strong>允许你逐层创建模型。在大多数情况下，它非常适合开发深度学习模型。</p><pre class="ks kt ku kv gt nx nl ny nz aw oa bi"><span id="fab3" class="nm lj it nl b gy ob oc l od oe"># Model architecture</span><span id="c531" class="nm lj it nl b gy of oc l od oe">model_m = Sequential([<br/>    Dense(units = 8, input_shape= (2,), activation = 'relu'),<br/>    Dense(units = 16, activation = 'relu'),<br/>    Dense(units = 2, activation = 'softmax') <br/>])</span></pre><p id="f34b" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">在这里，<strong class="mg jd">第一密集层</strong>实际上是第二层<em class="mf">整体</em>(因为实际的第一层将是我们从原始数据中输入的层)但是<strong class="mg jd">第一“隐藏”层</strong>。它有 8 个单元/神经元/节点，8 个是任意选择的！</p><p id="19ff" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated"><code class="fe ni nj nk nl b">input_shape</code>参数是您必须根据您的数据集分配的。直观地说，就是网络应该期望的输入数据的形状。我喜欢把它想成— <em class="mf">“我正在馈入神经网络的一个</em> <strong class="mg jd"> <em class="mf">单个</em> </strong> <em class="mf">行数据是什么形状？”。</em></p><p id="d406" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">在我们的例子中，<strong class="mg jd">输入</strong>的一行看起来像<code class="fe ni nj nk nl b">[0.914, 0]</code>。即它是一维的。因此，<code class="fe ni nj nk nl b">input_shape</code>参数看起来像一个元组(2，)，其中 2 指的是数据集中的要素数量(<code class="fe ni nj nk nl b">age</code>和<code class="fe ni nj nk nl b">area</code>)。<strong class="mg jd">因此，输入层需要一个包含 2 个输入元素的一维数组。它将产生 8 个输出作为回报。</strong></p><p id="ec0e" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">如果我们正在处理，比如说黑白 2×3 像素图像(我们将在下一篇关于卷积神经网络的教程中研究<a class="ae lh" rel="noopener" target="_blank" href="/beginners-guide-to-building-convolutional-neural-networks-using-tensorflow-s-keras-api-in-python-6e8035e28238">，我们将会看到输入的一行(或<strong class="mg jd">向量表示单个图像</strong>)看起来像<code class="fe ni nj nk nl b">[[0 , 1, 0] , [0 , 0, 1]</code>，其中 0 表示像素是亮的，1 表示像素是暗的。即，它是二维的。随后，<code class="fe ni nj nk nl b">input_shape</code>参数将等于(2，3)。</a></p><p id="44d6" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated"><em class="mf">注意:在我们的例子中，我们的输入形状只有一个维度，所以您不一定需要以元组的形式给出它。相反，你可以给</em> <code class="fe ni nj nk nl b"><em class="mf">input_dim</em></code> <em class="mf">作为标量数。因此，在我们的模型中，我们的输入层有两个元素，我们可以使用这两个中的任何一个:</em></p><ul class=""><li id="a718" class="oj ok it mg b mh mi mk ml na ol nb om nc on mz oo op oq or bi translated"><code class="fe ni nj nk nl b"><em class="mf">input_shape=(2,)</em></code> <em class="mf"> -当你只有一个维度时，逗号是必要的</em></li><li id="4d4a" class="oj ok it mg b mh os mk ot na ou nb ov nc ow mz oo op oq or bi translated"><code class="fe ni nj nk nl b"><em class="mf">input_dim = 2</em></code></li></ul><p id="a6bb" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">围绕输入形状参数的一个<strong class="mg jd">普遍误解</strong>是，它必须包括我们输入到神经网络的输入样本总数(在我们的例子中是 10，000)。</p><blockquote class="ma mb mc"><p id="7f42" class="md me mf mg b mh mi kd mj mk ml kg mm mn mo mp mq mr ms mt mu mv mw mx my mz im bi translated">训练数据中的行数是网络输入形状的<strong class="mg jd">而不是</strong>部分，因为训练过程每批向网络提供一个样本(或者更准确地说，每批的 batch_size 样本)。</p></blockquote><p id="21c6" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated"><strong class="mg jd">第二个“隐藏”层</strong>是另一个密集层，具有与第一个隐藏层相同的<em class="mf">激活功能</em>，即“relu”。激活函数确保传递的值位于可调的预期范围内。<a class="ae lh" href="https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank">整流线性单元</a>(或 relu)功能返回直接作为输入提供的值，如果输入为 0.0 或更小，则返回值 0.0。</p><p id="f4f7" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">你可能想知道为什么我们没有为这个层指定<code class="fe ni nj nk nl b">input_shape</code>参数。毕竟，Keras 需要知道它们输入的形状，以便能够创建它们的权重。事实是，</p><blockquote class="ma mb mc"><p id="bb43" class="md me mf mg b mh mi kd mj mk ml kg mm mn mo mp mq mr ms mt mu mv mw mx my mz im bi translated">无需为第二(或后续)隐藏层指定<code class="fe ni nj nk nl b">input_shape</code>参数，因为它会根据架构(即每层的单元和特性)自动计算输入节点的最佳数量。</p></blockquote><p id="34d6" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">最后，我们的顺序模型中的第三个或最后一个隐藏层是另一个具有 softmax 激活功能的密集层。softmax 函数返回两个类的输出概率— <code class="fe ni nj nk nl b">approved</code>(输出= 0)和<code class="fe ni nj nk nl b">rejected</code>(输出= 1)。</p><p id="84df" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">模型摘要如下所示:</p><pre class="ks kt ku kv gt nx nl ny nz aw oa bi"><span id="69a1" class="nm lj it nl b gy ob oc l od oe">model_m.summary()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ox"><img src="../Images/07c66b6c4058b4698827091751765175.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xT6mHhnAQJ8tMGt80g68ng.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">我们的顺序模型的总结</p></figure><p id="e3e8" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">让我们看看如何计算每一层的参数总数，即<code class="fe ni nj nk nl b">Param #</code>。请记住，在每一层中，我们还有一个<a class="ae lh" href="https://stackoverflow.com/questions/2480650/what-is-the-role-of-the-bias-in-neural-networks" rel="noopener ugc nofollow" target="_blank">偏置神经元</a>(除了在模型架构中预先指定的神经元之外)。因此，在第一个隐藏层中，我们有 3 个输入神经元(2 个来自输入数据特征的神经元+ 1 个偏置神经元)和 8 个输出神经元。因此，总共需要训练 8*3 = 24 个参数。类似地，在第二隐藏层中，我们现在有 9 个输入神经元(8 个来自第一隐藏层加上 1 个偏置神经元)和 16 个输出神经元，总共 16*9 = 144 个可训练参数。最后，最后一层将具有 17*2=34 个可训练参数。</p><h2 id="9c43" class="nm lj it bd lk nn no dn lo np nq dp ls na nr ns lu nb nt nu lw nc nv nw ly iz bi translated">为培训准备模型</h2><pre class="ks kt ku kv gt nx nl ny nz aw oa bi"><span id="ff6e" class="nm lj it nl b gy ob oc l od oe">model_m.compile(optimizer= Adam(learning_rate = 0.0001), <br/>              loss = 'sparse_categorical_crossentropy', <br/>              metrics = ['accuracy'] <br/>             )</span></pre><p id="df83" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">在我们开始用实际数据训练我们的模型之前，我们必须用某些参数<code class="fe ni nj nk nl b">compile</code>模型。在这里，我们将使用亚当<code class="fe ni nj nk nl b">optimizer</code>。</p><blockquote class="ma mb mc"><p id="cc6b" class="md me mf mg b mh mi kd mj mk ml kg mm mn mo mp mq mr ms mt mu mv mw mx my mz im bi translated">优化器的可用选择包括 SGD、Adadelta、Adagrad 等。</p></blockquote><p id="7766" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated"><code class="fe ni nj nk nl b">loss</code>参数指定应该在每次迭代中监控交叉熵损失。<code class="fe ni nj nk nl b">metrics</code>参数表示我们希望根据精确度来判断我们的模型。</p><h2 id="e6e2" class="nm lj it bd lk nn no dn lo np nq dp ls na nr ns lu nb nt nu lw nc nv nw ly iz bi translated">训练和验证模型</h2><pre class="ks kt ku kv gt nx nl ny nz aw oa bi"><span id="093d" class="nm lj it nl b gy ob oc l od oe"># training the model<br/>model_m.fit(x = scaled_train_samples_mult, <br/>          y = train_labels, <br/>          batch_size= 10, <br/>          epochs = 30, <br/>          validation_split= 0.1, <br/>          shuffle = True,<br/>          verbose = 2 <br/>         )</span></pre><p id="aa8e" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated"><code class="fe ni nj nk nl b">x</code>和<code class="fe ni nj nk nl b">y</code>参数非常直观——分别是预测变量和结果变量的 NumPy 数组。<code class="fe ni nj nk nl b">batch_size</code>指定一个批次中包含多少个样本。<code class="fe ni nj nk nl b">epochs=30</code>表示模型将在<em class="mf">所有数据</em>上训练 30 次。<code class="fe ni nj nk nl b">verbose = 2</code>表示它被设置为输出消息中最详细的级别。</p><p id="eb6f" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">我们正在使用 0.1 <code class="fe ni nj nk nl b">validation_split</code>动态创建一个验证集，即在每个时期保留 10%的训练数据，并将其排除在训练之外。这有助于检查我们模型的可推广性，因为通过获取训练集的子集，模型仅在训练数据上学习<em class="mf">而在验证数据上进行测试。</em></p><blockquote class="ma mb mc"><p id="31f7" class="md me mf mg b mh mi kd mj mk ml kg mm mn mo mp mq mr ms mt mu mv mw mx my mz im bi translated">请记住，验证拆分发生在训练集被打乱之前，即在验证集被取出后，只有训练集被打乱。如果在数据集的末尾有所有被拒绝的贷款申请，这可能意味着您的验证集有对类的错误描述。所以你必须自己洗牌，而不是依靠 keras 来帮你！</p></blockquote><p id="97d9" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">这是<strong class="mg jd">前五个纪元</strong>的样子:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oy"><img src="../Images/c2aba2fee0612ac8da1dde6b2d7c625b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w9Jx7GyjqwdY9lzitgYxgQ.png"/></div></div></figure><p id="f4ae" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">这是<strong class="mg jd">最后五个纪元</strong>的样子:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oz"><img src="../Images/bddc3f3a033e6278c05c0f66f04bce75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZSdEGmMMGHGzOd8q6eb75Q.png"/></div></div></figure><p id="7005" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">如您所见，在第一个时期，我们从验证集的高损失(0.66)和低准确度(0.57)开始。渐渐地，我们能够减少损失(0.24)并提高最后一个时期验证集的准确性(0.93)。</p><h2 id="8663" class="nm lj it bd lk nn no dn lo np nq dp ls na nr ns lu nb nt nu lw nc nv nw ly iz bi translated">对测试集进行推理</h2><p id="9ed4" class="pw-post-body-paragraph md me it mg b mh nd kd mj mk ne kg mm na nf mp mq nb ng mt mu nc nh mx my mz im bi translated">我们以类似于训练集的方式对之前未见过的测试集进行预处理，并将其保存在<code class="fe ni nj nk nl b">scaled_test_samples</code>中。相应的标签存储在<code class="fe ni nj nk nl b">test_labels</code>中。</p><pre class="ks kt ku kv gt nx nl ny nz aw oa bi"><span id="249d" class="nm lj it nl b gy ob oc l od oe">predictions = model.predict(x = scaled_test_samples, <br/>                            batch_size= 10,<br/>                            verbose=0)</span></pre><blockquote class="ma mb mc"><p id="bfde" class="md me mf mg b mh mi kd mj mk ml kg mm mn mo mp mq mr ms mt mu mv mw mx my mz im bi translated">确保选择与培训过程中使用的<code class="fe ni nj nk nl b">batch_size</code>完全相同的产品。</p></blockquote><p id="d187" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">由于我们的最后一个隐藏层有一个 softmax 激活函数，<code class="fe ni nj nk nl b">predictions</code>包括两个类的输出概率(左边是类 0 的概率(即批准的)，右边是类 1 的概率(即拒绝的)。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/d978031bf92e5ba00b3444ac700d15cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*1tF0pXVMlbrdQBqTx6NHXg.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">当最终层具有 softmax 激活时，来自 ANN 的预测。</p></figure><p id="f0a7" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">从这里开始有几种方法。您可以选择一个任意的阈值，比如 0.7，并且只有当类别 0(即批准)的概率超过 0.7 时，您才应该选择批准贷款申请。或者，您可以选择概率最高的类作为最终预测。例如，根据上面的截图，该模型预测贷款将有 2%的概率被批准，但有 97%的概率被拒绝。因此，最后的推论应该是，此人的贷款被拒绝。我们将采取后者。</p><pre class="ks kt ku kv gt nx nl ny nz aw oa bi"><span id="1151" class="nm lj it nl b gy ob oc l od oe"># get index of the prediction with the highest prob</span><span id="fdaf" class="nm lj it nl b gy of oc l od oe">rounded_pred = np.argmax(predictions, axis = 1)<br/>rounded_pred</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/577bfbd9d6634f27614014e9abaabab9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*0BgrH78BxCYmFtLGq_uurA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">为测试集所做的预测</p></figure><h2 id="fd8d" class="nm lj it bd lk nn no dn lo np nq dp ls na nr ns lu nb nt nu lw nc nv nw ly iz bi translated">保存和加载 Keras 模型</h2><p id="c336" class="pw-post-body-paragraph md me it mg b mh nd kd mj mk ne kg mm na nf mp mq nb ng mt mu nc nh mx my mz im bi translated">为了<strong class="mg jd">保存</strong> <strong class="mg jd">来自已训练模型的所有内容</strong>:</p><pre class="ks kt ku kv gt nx nl ny nz aw oa bi"><span id="acb1" class="nm lj it nl b gy ob oc l od oe">model.save('models/LoanOutcome_model.h7')</span></pre><p id="e712" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">我们基本上保存了我们训练模型<br/> 1 的所有内容。架构(神经元的层数等)<br/> 2。学习的重量<br/> 3。训练配置(optimizers，loss) <br/> 4。优化器的状态(便于重新训练)</p><p id="2f07" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">要加载我们刚刚保存的模型:</p><pre class="ks kt ku kv gt nx nl ny nz aw oa bi"><span id="cdd5" class="nm lj it nl b gy ob oc l od oe">from tensorflow.keras.models import load_model<br/>new_model = load_model('models/LoanOutcome_model.h7')</span></pre></div><div class="ab cl pc pd hx pe" role="separator"><span class="pf bw bk pg ph pi"/><span class="pf bw bk pg ph pi"/><span class="pf bw bk pg ph"/></div><div class="im in io ip iq"><p id="c90c" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">为了<strong class="mg jd">只保存</strong> <strong class="mg jd">的架构</strong>:</p><pre class="ks kt ku kv gt nx nl ny nz aw oa bi"><span id="de31" class="nm lj it nl b gy ob oc l od oe">json_string = model.to_json()</span></pre><p id="4982" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">从先前存储的架构中重建新模型:</p><pre class="ks kt ku kv gt nx nl ny nz aw oa bi"><span id="931f" class="nm lj it nl b gy ob oc l od oe">from tensorflow.keras.models import model_from_json<br/>model_architecture = model_from_json(json_string)</span></pre></div><div class="ab cl pc pd hx pe" role="separator"><span class="pf bw bk pg ph pi"/><span class="pf bw bk pg ph pi"/><span class="pf bw bk pg ph"/></div><div class="im in io ip iq"><p id="44d2" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">只保存重量:</p><pre class="ks kt ku kv gt nx nl ny nz aw oa bi"><span id="bede" class="nm lj it nl b gy ob oc l od oe">model.save_weights('weights/LoanOutcome_weights.h7')</span></pre><p id="7517" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">要将权重用于其他模型架构:</p><pre class="ks kt ku kv gt nx nl ny nz aw oa bi"><span id="222a" class="nm lj it nl b gy ob oc l od oe">model2 = Sequential([<br/>    Dense(units=16, input_shape=(1,), activation='relu'),<br/>    Dense(units=32, activation='relu'),<br/>    Dense(units=2, activation='softmax')<br/>])</span><span id="c009" class="nm lj it nl b gy of oc l od oe"># retrieving the saved weights<br/>model2.load_weights('weights/LoanOutcome_weights.h7')</span></pre></div><div class="ab cl pc pd hx pe" role="separator"><span class="pf bw bk pg ph pi"/><span class="pf bw bk pg ph pi"/><span class="pf bw bk pg ph"/></div><div class="im in io ip iq"><p id="3596" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">现在我们有了。我们已经成功地建立了我们的第一个人工神经网络，并对其进行了训练、验证和测试，还成功地将其保存下来以备将来使用。在下一篇文章的<a class="ae lh" rel="noopener" target="_blank" href="/beginners-guide-to-building-convolutional-neural-networks-using-tensorflow-s-keras-api-in-python-6e8035e28238">中，我们将通过卷积神经网络(CNN)来处理图像分类任务。</a></p><p id="2e40" class="pw-post-body-paragraph md me it mg b mh mi kd mj mk ml kg mm na mo mp mq nb ms mt mu nc mw mx my mz im bi translated">在那之前:)</p><div class="pj pk gp gr pl pm"><a rel="noopener follow" target="_blank" href="/beginners-guide-to-building-convolutional-neural-networks-using-tensorflow-s-keras-api-in-python-6e8035e28238"><div class="pn ab fo"><div class="po ab pp cl cj pq"><h2 class="bd jd gy z fp pr fr fs ps fu fw jc bi translated">使用 TensorFlow 的 Keras API 在 Python 中构建卷积神经网络的初学者指南</h2><div class="pt l"><h3 class="bd b gy z fp pr fr fs ps fu fw dk translated">解释具有 MaxPool2D、Conv2D 和 Dense 图层的端到端二值图像分类模型。</h3></div><div class="pu l"><p class="bd b dl z fp pr fr fs ps fu fw dk translated">towardsdatascience.com</p></div></div><div class="pv l"><div class="pw l px py pz pv qa lb pm"/></div></div></a></div><div class="pj pk gp gr pl pm"><a rel="noopener follow" target="_blank" href="/step-by-step-guide-to-explaining-your-ml-project-during-a-data-science-interview-81dfaaa408bf"><div class="pn ab fo"><div class="po ab pp cl cj pq"><h2 class="bd jd gy z fp pr fr fs ps fu fw jc bi translated">在数据科学面试中解释你的 ML 项目的逐步指南。</h2><div class="pt l"><h3 class="bd b gy z fp pr fr fs ps fu fw dk translated">在结尾有一个额外的样本脚本，让你谨慎地展示你的技术技能！</h3></div><div class="pu l"><p class="bd b dl z fp pr fr fs ps fu fw dk translated">towardsdatascience.com</p></div></div><div class="pv l"><div class="qb l px py pz pv qa lb pm"/></div></div></a></div><div class="pj pk gp gr pl pm"><a rel="noopener follow" target="_blank" href="/deploying-h2o-models-as-apis-using-flask-42065a4fa567"><div class="pn ab fo"><div class="po ab pp cl cj pq"><h2 class="bd jd gy z fp pr fr fs ps fu fw jc bi translated">使用 FLASK 将 H2o 模型部署为 API</h2><div class="pt l"><h3 class="bd b gy z fp pr fr fs ps fu fw dk translated">模型训练、调优和创建简单 API 的端到端示例(没有技术术语)。</h3></div><div class="pu l"><p class="bd b dl z fp pr fr fs ps fu fw dk translated">towardsdatascience.com</p></div></div><div class="pv l"><div class="qc l px py pz pv qa lb pm"/></div></div></a></div><div class="pj pk gp gr pl pm"><a rel="noopener follow" target="_blank" href="/time-series-analysis-using-pandas-in-python-f726d87a97d8"><div class="pn ab fo"><div class="po ab pp cl cj pq"><h2 class="bd jd gy z fp pr fr fs ps fu fw jc bi translated">使用 Python 中的 Pandas 进行时间序列分析</h2><div class="pt l"><h3 class="bd b gy z fp pr fr fs ps fu fw dk translated">对季节性、趋势、自相关等关键词的额外介绍。</h3></div><div class="pu l"><p class="bd b dl z fp pr fr fs ps fu fw dk translated">towardsdatascience.com</p></div></div><div class="pv l"><div class="qd l px py pz pv qa lb pm"/></div></div></a></div></div></div>    
</body>
</html>