<html>
<head>
<title>Installing Apache Hive 3.1.2 on Windows 10</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Windows 10上安装Apache Hive 3.1.2</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/installing-apache-hive-3-1-2-on-windows-10-70669ce79c79?source=collection_archive---------2-----------------------#2020-05-04">https://towardsdatascience.com/installing-apache-hive-3-1-2-on-windows-10-70669ce79c79?source=collection_archive---------2-----------------------#2020-05-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6e07" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在Windows 10操作系统上安装Apache Hive 3.1.2的分步指南</h2></div><p id="0588" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在进行一个项目时，我们被要求在Windows 10操作系统上安装Apache Hive。网上找到了许多指南，但不幸的是，它们不起作用。为此，我决定写一个循序渐进的指南来帮助别人。</p><p id="e7fb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本指南的起点是我在Youtube上找到的一个很棒的视频，它提供了Hive 2.x的一个工作场景，没有太多细节。</p><p id="b663" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本文是我们在TowardsDataScience.com上发布的系列文章的一部分，旨在说明如何在Windows操作系统上安装大数据技术。</p><p id="914b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">本系列其他发表文章:</strong></p><ul class=""><li id="bdb0" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated"><a class="ae lb" rel="noopener" target="_blank" href="/installing-hadoop-3-2-1-single-node-cluster-on-windows-10-ac258dd48aef">在Windows 10上安装Hadoop 3.2.1单节点集群</a></li><li id="798c" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated"><a class="ae lb" rel="noopener" target="_blank" href="/installing-apache-pig-0-17-0-on-windows-10-7b19ce61900d">在Windows 10上安装Apache Pig 0 . 17 . 0</a></li></ul><h1 id="885e" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">1.先决条件</h1><h2 id="8b47" class="mi lr iq bd ls mj mk dn lw ml mm dp ma ko mn mo mc ks mp mq me kw mr ms mg mt bi translated">1.1.7zip</h2><p id="abd7" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">为了提取tar.gz档案，你应该安装<a class="ae lb" href="https://www.7-zip.org/download.html" rel="noopener ugc nofollow" target="_blank">7压缩工具</a>。</p><h2 id="0a0f" class="mi lr iq bd ls mj mk dn lw ml mm dp ma ko mn mo mc ks mp mq me kw mr ms mg mt bi translated">1.2.安装Hadoop</h2><p id="8b6e" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">要安装Apache Hive，必须安装并运行Hadoop集群:可以参考我们之前发布的<a class="ae lb" rel="noopener" target="_blank" href="/installing-hadoop-3-2-1-single-node-cluster-on-windows-10-ac258dd48aef">分步指南，在Windows 10 </a>上安装Hadoop 3.2.1。</p><h2 id="24ee" class="mi lr iq bd ls mj mk dn lw ml mm dp ma ko mn mo mc ks mp mq me kw mr ms mg mt bi translated">1.3.阿帕奇德比</h2><p id="7fd0" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">此外，Apache Hive需要一个关系数据库来创建它的Metastore(所有元数据都将存储在这里)。在本指南中，我们将使用Apache Derby数据库4。</p><p id="4099" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">既然我们已经安装了Java 8，我们必须安装Apache Derby 10.14.2.0版本(<a class="ae lb" href="https://db.apache.org/derby/derby_downloads.html" rel="noopener ugc nofollow" target="_blank">查看下载页面</a>)，可以从下面的<a class="ae lb" href="https://downloads.apache.org//db/derby/db-derby-10.14.2.0/db-derby-10.14.2.0-bin.tar.gz" rel="noopener ugc nofollow" target="_blank">链接</a>下载。</p><p id="e81b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下载后，我们必须解压两次<em class="mz">(使用7zip:第一次解压. tar.gz文件，第二次解压。tar file) </em>将db-derby-10.14.2.0-bin.tar.gz的内容归档到所需的安装目录下。由于在上一个指南中，我们已经在“E:\hadoop-env\hadoop-3.2.1”目录中安装了Hadoop，因此我们将Derby提取到“E:\ Hadoop-env \ d b-Derby-10 . 14 . 2 . 0”目录中。</p><h2 id="eff9" class="mi lr iq bd ls mj mk dn lw ml mm dp ma ko mn mo mc ks mp mq me kw mr ms mg mt bi translated">1.4.Cygwin</h2><p id="50cd" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">因为有一些Hive 3.1.2工具与Windows不兼容(比如schematool)。我们将需要<a class="ae lb" href="https://www.cygwin.com/" rel="noopener ugc nofollow" target="_blank"> Cygwin </a>工具来运行一些Linux命令。</p><h1 id="0b44" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">2.下载Apache Hive二进制文件</h1><p id="eed2" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">为了下载Apache Hive二进制文件，你应该去下面的网站:【https://downloads.apache.org/hive/hive-3.1.2/】T2。然后，下载apache-hive-3.1.2。-bin.tar.gz文件。</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div class="gh gi na"><img src="../Images/41da5c8a8b547406ec809bdc6441a445.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*VNE6ZQEdCL8iMeHXlgAnVQ.png"/></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">图1—apache-hive.3.1.2-bin.tar.gz文件</p></figure><p id="4125" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">文件下载完成后，我们应该将两次<em class="mz">(如上所述)</em>apache-hive.3.1.2-bin.tar.gz归档文件解压到“E:\hadoop-env\ Apache-hive-3 . 1 . 2”目录中(因为我们决定使用E:\ Hadoop-env \ "作为上一指南中使用的所有技术的安装目录。</p><h1 id="ca86" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">3.设置环境变量</h1><p id="0365" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">提取Derby和Hive档案后，我们应该进入控制面板&gt;系统和安全&gt;系统。然后点击“高级系统设置”。</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi nm"><img src="../Images/24eb934ebd13ba98aebc58ccfd27577a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FSVFHZNsU6o2B9ReMywe1Q.png"/></div></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">图2-高级系统设置</p></figure><p id="52e1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在高级系统设置对话框中，点击“环境变量”按钮。</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/f7481ca50e4945d2ba982da291590555.png" data-original-src="https://miro.medium.com/v2/resize:fit:824/format:webp/1*m5gMwhlfmakHOUCBQeggzQ.png"/></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">图3 —打开环境变量编辑器</p></figure><p id="8c1c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们应该添加以下用户变量:</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/acd7b9eb41d0a1fa963006c2506e213d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*blWGC2Tj5l3R5Tcb6bdVyA.png"/></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">图4 —添加用户变量</p></figure><ul class=""><li id="be4d" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">HIVE _ HOME:" E:\ Hadoop-env \ Apache-HIVE-3 . 1 . 2 \ "</li><li id="fc8e" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">DERBY _ HOME:" E:\ Hadoop-env \ d b-DERBY-10 . 14 . 2 . 0 \ "</li><li id="6dd5" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">HIVE_LIB: "%HIVE_HOME%\lib "</li><li id="35bd" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">HIVE_BIN: "%HIVE_HOME%\bin "</li><li id="a918" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">HADOOP _ USER _ class path _ FIRST:" true "</li></ul><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/82ff7f74c4d11c523d0f361dc9b23ed1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*aaIscJ_-fWHD_nOZzjZF6w.png"/></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">图5 —添加HIVE_HOME用户变量</p></figure><p id="cc75" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，我们应该添加以下系统变量:</p><ul class=""><li id="68f7" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">HADOOP _ USER _ class path _ FIRST:" true "</li></ul><p id="ebb2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们应该编辑Path用户变量以添加以下路径:</p><ul class=""><li id="d327" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">%HIVE_BIN%</li><li id="23e4" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">%DERBY_HOME%\bin</li></ul><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/3e1cf87e063e2295de5ca85f022ba3b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*jespqCAY1CYS6MjZnuSO6Q.png"/></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">图6 —编辑路径环境变量</p></figure><h1 id="3b88" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">4.正在配置配置单元</h1><h2 id="c831" class="mi lr iq bd ls mj mk dn lw ml mm dp ma ko mn mo mc ks mp mq me kw mr ms mg mt bi translated">4.1.复制Derby库</h2><p id="f6ba" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">现在，我们应该转到Derby库目录(E:\ Hadoop-env \ d b-Derby-10 . 14 . 2 . 0 \ lib)并复制所有*。jar文件。</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi nv"><img src="../Images/658f006a3f2c3cbdbd1376fc198e2470.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t4D0qcja5BUvQfFIymzXtw.png"/></div></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">图7 —复制Derby库</p></figure><p id="3648" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，我们应该将它们粘贴到配置单元库目录中(E:\ Hadoop-env \ Apache-Hive-3 . 1 . 2 \ lib)。</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi nw"><img src="../Images/08a85a26899aaea1331d17b90a7a7efc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GXbphs_VOtT-QWIkVd9dog.png"/></div></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">图8 —在配置单元库目录中粘贴Derby库</p></figure><h2 id="0049" class="mi lr iq bd ls mj mk dn lw ml mm dp ma ko mn mo mc ks mp mq me kw mr ms mg mt bi translated">4.2.配置hive-site.xml</h2><p id="f0e4" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">现在，我们应该转到Apache Hive配置目录(E:\ Hadoop-env \ Apache-Hive-3 . 1 . 2 \ conf)创建一个新文件“hive-site.xml”。我们应该将以下XML代码粘贴到该文件中:</p><pre class="nb nc nd ne gt nx ny nz oa aw ob bi"><span id="a8d0" class="mi lr iq ny b gy oc od l oe of">&lt;?xml version="1.0"?&gt;<br/>&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;<br/>&lt;configuration&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; <br/>&lt;value&gt;jdbc:derby://localhost:1527/metastore_db;create=true&lt;/value&gt; <br/>&lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt;<br/>&lt;/property&gt;&lt;property&gt; <br/>&lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; <br/>&lt;value&gt;org.apache.derby.jdbc.ClientDriver&lt;/value&gt; <br/>&lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;<br/>&lt;/property&gt;<br/>&lt;property&gt; <br/>&lt;name&gt;hive.server2.enable.doAs&lt;/name&gt; <br/>&lt;description&gt;Enable user impersonation for HiveServer2&lt;/description&gt;<br/>&lt;value&gt;true&lt;/value&gt;<br/>&lt;/property&gt;<br/>&lt;property&gt;<br/>&lt;name&gt;hive.server2.authentication&lt;/name&gt; <br/>&lt;value&gt;NONE&lt;/value&gt;<br/>&lt;description&gt; Client authentication types. NONE: no authentication check LDAP: LDAP/AD based authentication KERBEROS: Kerberos/GSSAPI authentication CUSTOM: Custom authentication provider (Use with property hive.server2.custom.authentication.class) &lt;/description&gt;<br/>&lt;/property&gt;<br/>&lt;property&gt;<br/>&lt;name&gt;datanucleus.autoCreateTables&lt;/name&gt;<br/>&lt;value&gt;True&lt;/value&gt;<br/>&lt;/property&gt;<br/>&lt;/configuration&gt;</span></pre><h1 id="4fb0" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">5.启动服务</h1><h2 id="daa7" class="mi lr iq bd ls mj mk dn lw ml mm dp ma ko mn mo mc ks mp mq me kw mr ms mg mt bi translated">5.1.Hadoop服务</h2><p id="4e34" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">要启动Apache Hive，请以管理员身份打开命令提示符实用程序。然后，使用start-dfs和start-yarn命令启动Hadoop服务(如Hadoop安装指南中所示)。</p><h2 id="803b" class="mi lr iq bd ls mj mk dn lw ml mm dp ma ko mn mo mc ks mp mq me kw mr ms mg mt bi translated">5.2.Derby网络服务器</h2><p id="54b9" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">然后，我们应该使用以下命令在本地主机上启动Derby网络服务器:</p><pre class="nb nc nd ne gt nx ny nz oa aw ob bi"><span id="a6a2" class="mi lr iq ny b gy oc od l oe of">E:\hadoop-env\db-derby-10.14.2.0\bin\StartNetworkServer -h 0.0.0.0</span></pre><h1 id="0e54" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">6.正在启动Apache Hive</h1><p id="5d9e" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">现在，让我们尝试打开一个命令提示工具，转到配置单元二进制文件目录(E:\ Hadoop-env \ Apache-Hive-3 . 1 . 2 \ bin)并执行以下命令:</p><pre class="nb nc nd ne gt nx ny nz oa aw ob bi"><span id="e68a" class="mi lr iq ny b gy oc od l oe of">hive</span></pre><p id="975f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将收到以下错误:</p><pre class="nb nc nd ne gt nx ny nz oa aw ob bi"><span id="2f3d" class="mi lr iq ny b gy oc od l oe of">'hive' is not recognized as an internal or external command, operable program or batch file.</span></pre><p id="6a1e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于Hive 3.x版本不是为Windows构建的(仅在某些Hive 2.x版本中)，因此会引发此错误。为了让事情顺利进行，我们应该下载必要的*。来自以下链接的cmd文件:h<a class="ae lb" href="https://svn.apache.org/repos/asf/hive/trunk/bin/hive.cmd" rel="noopener ugc nofollow" target="_blank">ttps://SVN . Apache . org/repos/ASF/hive/trunk/bin/</a>。请注意，您应该保留文件夹层次结构(bin\ext\util)。</p><p id="79eb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您可以下载所有*。来自以下GitHub存储库的cmd文件</p><ul class=""><li id="26ad" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">https://github.com/HadiFadl/Hive-cmd<a class="ae lb" href="https://github.com/HadiFadl/Hive-cmd" rel="noopener ugc nofollow" target="_blank"/></li></ul><p id="3b30" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，如果我们尝试执行“hive”命令，我们将收到以下错误:</p><pre class="nb nc nd ne gt nx ny nz oa aw ob bi"><span id="47c2" class="mi lr iq ny b gy oc od l oe of">Exception in thread "main" java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument(ZLjava/lang/String;Ljava/lang/Object;)V<br/>at org.apache.hadoop.conf.Configuration.set(Configuration.java:1357)<br/>at org.apache.hadoop.conf.Configuration.set(Configuration.java:1338)<br/>at org.apache.hadoop.mapred.JobConf.setJar(JobConf.java:518)<br/>at org.apache.hadoop.mapred.JobConf.setJarByClass(JobConf.java:536)<br/>at org.apache.hadoop.mapred.JobConf.&lt;init&gt;(JobConf.java:430)<br/>at org.apache.hadoop.hive.conf.HiveConf.initialize(HiveConf.java:5141)<br/>at org.apache.hadoop.hive.conf.HiveConf.&lt;init&gt;(HiveConf.java:5104)<br/>at org.apache.hive.beeline.HiveSchemaTool.&lt;init&gt;(HiveSchemaTool.java:96)<br/>at org.apache.hive.beeline.HiveSchemaTool.main(HiveSchemaTool.java:1473)<br/>at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)<br/>at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)<br/>at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)<br/>at java.lang.reflect.Method.invoke(Method.java:498)<br/>at org.apache.hadoop.util.RunJar.run(RunJar.java:318)<br/>at org.apache.hadoop.util.RunJar.main(RunJar.java:232)</span></pre><p id="f998" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个错误是由于下面的Hive问题链接中提到的一个错误引起的:<a class="ae lb" href="https://issues.apache.org/jira/browse/HIVE-22718" rel="noopener ugc nofollow" target="_blank"> HIVE-22718 </a>。</p><p id="1ee0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">评论中提到，这个问题可以通过将“E:\ hadoop-env \ Apache-hive-3 . 1 . 2 \ lib”中存储的guava-19.0.jar替换为“E:\ Hadoop-env \ Hadoop-3 . 2 . 1 \ share \ Hadoop \ HDFS \ lib”中找到的Hadoop的guava-27.0-jre.jar来解决。</p><blockquote class="og oh oi"><p id="b4a9" class="kf kg mz kh b ki kj jr kk kl km ju kn oj kp kq kr ok kt ku kv ol kx ky kz la ij bi translated">注意:这个文件也被上传到上面提到的GitHub存储库中。</p></blockquote><p id="0aa2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，如果我们再次运行hive命令，那么Apache Hive将成功启动。</p><figure class="nb nc nd ne gt nf gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi om"><img src="../Images/5f9e78e15eb6e1741a6d9eeee609012f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZREo4M7Ykp_F2rjbBM7VhQ.png"/></div></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">图9 —启动Apache Hive</p></figure><h1 id="e435" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">7.正在初始化配置单元</h1><p id="00f7" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">在确保Apache Hive成功启动后。我们可能无法运行任何HiveQL命令。这是因为Metastore尚未初始化。此外，HiveServer2服务必须正在运行。</p><p id="a542" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要初始化Metastore，我们需要使用与windows不兼容的schematool实用程序。为了解决这个问题，我们将使用Cygwin实用程序，它允许从windows执行Linux命令。</p><h2 id="5e16" class="mi lr iq bd ls mj mk dn lw ml mm dp ma ko mn mo mc ks mp mq me kw mr ms mg mt bi translated">7.1.创建符号链接</h2><p id="7df7" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">首先，我们需要创建以下目录:</p><ul class=""><li id="6bb0" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">E:\cygdrive</li><li id="dd53" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">C:\cygdrive</li></ul><p id="c53b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，以管理员身份打开命令提示符并执行以下命令:</p><pre class="nb nc nd ne gt nx ny nz oa aw ob bi"><span id="bbce" class="mi lr iq ny b gy oc od l oe of">mklink /J  E:\cygdrive\e\ E:\<br/>mklink /J  C:\cygdrive\c\ C:\</span></pre><p id="18b3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些符号链接是正确使用Cygwin实用程序所必需的，因为Java可能会导致一些问题。</p><h2 id="9ca6" class="mi lr iq bd ls mj mk dn lw ml mm dp ma ko mn mo mc ks mp mq me kw mr ms mg mt bi translated">7.2.正在初始化配置单元Metastore</h2><p id="afe2" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">打开Cygwin实用程序并执行以下命令来定义环境变量:</p><pre class="nb nc nd ne gt nx ny nz oa aw ob bi"><span id="bbf5" class="mi lr iq ny b gy oc od l oe of">export HADOOP_HOME='/cygdrive/e/hadoop-env/hadoop-3.2.1'<br/>export PATH=$PATH:$HADOOP_HOME/bin<br/>export HIVE_HOME='/cygdrive/e/hadoop-env/apache-hive-3.1.2'<br/>export PATH=$PATH:$HIVE_HOME/bin<br/>export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$HIVE_HOME/lib/*.jar</span></pre><p id="6585" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以将这些行添加到“~/”中。bashrc”文件，这样你就不需要每次打开Cygwin时都写它们。</p><p id="aef6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们应该使用schematool实用程序来初始化Metastore:</p><pre class="nb nc nd ne gt nx ny nz oa aw ob bi"><span id="9b4c" class="mi lr iq ny b gy oc od l oe of">$HIVE_HOME/bin/schematool -dbType derby -initSchema</span></pre><h2 id="786a" class="mi lr iq bd ls mj mk dn lw ml mm dp ma ko mn mo mc ks mp mq me kw mr ms mg mt bi translated">7.3.正在启动HiveServer2服务</h2><p id="1b00" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">现在，打开命令提示符并运行以下命令:</p><pre class="nb nc nd ne gt nx ny nz oa aw ob bi"><span id="7c7b" class="mi lr iq ny b gy oc od l oe of">hive --service hiveserver2 start</span></pre><p id="2268" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们应该让这个命令提示符处于打开状态，并打开一个新的命令提示符，我们应该使用下面的命令启动Apache Hive:</p><pre class="nb nc nd ne gt nx ny nz oa aw ob bi"><span id="00bc" class="mi lr iq ny b gy oc od l oe of">hive</span></pre><h2 id="9963" class="mi lr iq bd ls mj mk dn lw ml mm dp ma ko mn mo mc ks mp mq me kw mr ms mg mt bi translated">7.4.启动WebHCat服务(可选)</h2><p id="f877" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">在我们正在进行的项目中，我们需要从SQL Server Integration Services执行HiveQL语句，该语句可以从WebHCat服务器访问Hive。</p><p id="327a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要启动WebHCat服务器，我们应该打开Cygwin实用程序并执行以下命令:</p><pre class="nb nc nd ne gt nx ny nz oa aw ob bi"><span id="7f81" class="mi lr iq ny b gy oc od l oe of">$HIVE_HOME/hcatalog/sbin/webhcat_server.sh start</span></pre><h1 id="581d" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">8.参考</h1><ol class=""><li id="0de0" class="lc ld iq kh b ki mu kl mv ko on ks oo kw op la oq li lj lk bi translated">Stackoverflow.com问答网站</li><li id="fb05" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la oq li lj lk bi translated">阿帕奇蜂巢官网</li><li id="4b91" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la oq li lj lk bi translated">YouTube:<a class="ae lb" href="https://www.youtube.com/watch?v=npyRXkMhrgk" rel="noopener ugc nofollow" target="_blank">WINDOWS上的简易HIVE安装</a></li><li id="c0b1" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la oq li lj lk bi translated">kon text . tech:<a class="ae lb" href="https://kontext.tech/column/hadoop/291/apache-hive-300-installation-on-windows-10-step-by-step-guide" rel="noopener ugc nofollow" target="_blank">Windows 10上Apache Hive 3.0.0安装分步指南</a></li></ol></div></div>    
</body>
</html>