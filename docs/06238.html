<html>
<head>
<title>Modelling Classification Trees</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">建模分类树</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/modelling-classification-trees-3607ad43a123?source=collection_archive---------45-----------------------#2020-05-19">https://towardsdatascience.com/modelling-classification-trees-3607ad43a123?source=collection_archive---------45-----------------------#2020-05-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a154" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何编写最流行的机器学习算法之一(Python)</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/e39f8f5a3665697eb478b2ba70605eb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lXm7zHmRNqlWA9rc"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">凯利·西克玛在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="d8ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">决策树是机器学习中最流行的算法之一:它们易于可视化，高度可解释性，超级灵活，可以应用于分类和回归问题。DTs通过学习从数据特征中推断出的简单决策规则来预测目标变量的值。</p><p id="8798" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我的帖子<em class="lv"> " </em> <a class="ae ky" rel="noopener" target="_blank" href="/the-complete-guide-to-decision-trees-28a4e3c7be14"> <em class="lv">决策树完全指南</em> </a> <em class="lv"> s" </em>中，我详细描述了DT:它们在现实生活中的应用，不同的DT类型和算法，以及它们的优缺点。现在是务实的时候了。你如何建立一个DT？你如何将它应用到真实数据中？DTs只不过是算法(或步骤序列)，这使得它们非常适合编程语言。让我们看看怎么做。</p><h1 id="78ed" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">问题是</h1><p id="4a50" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">世界银行将世界经济分成四个收入组:</p><ul class=""><li id="433e" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated">高的</li><li id="d5f9" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">中上</li><li id="a0af" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">中下</li><li id="4a93" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">低的</li></ul><p id="b6de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这一分配基于使用<a class="ae ky" href="https://datahelpdesk.worldbank.org/knowledgebase/articles/77933-what-is-the-world-bank-atlas-method" rel="noopener ugc nofollow" target="_blank">图册方法</a>计算的人均国民总收入(GNI)(以现值美元计算)，类别定义截至2018年7月1日。利用数据预处理技术，我创建了一个数据集，其中还包括其他国家的变量，如人口、面积、购买力、GDP等。你可以在<a class="ae ky" href="https://github.com/dlopezyse/Medium" rel="noopener ugc nofollow" target="_blank">这个链接</a>下下载数据集。</p><blockquote class="nh ni nj"><p id="5339" class="kz la lv lb b lc ld ju le lf lg jx lh nk lj lk ll nl ln lo lp nm lr ls lt lu im bi translated">该分类树的目标是根据数据集中包含的变量预测一个国家的收入组。</p></blockquote><h1 id="8279" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">台阶</h1><p id="d2db" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">您可以通过处理更简单的子步骤来降低构建DTs的复杂性:DT中的每个单独的子例程都将连接到其他子例程以增加复杂性，这种构造将让您获得更健壮的模型，更易于维护和改进。现在，让我们用Python建立一个分类树(特殊类型的DT)。</p><h2 id="c169" class="nn lx it bd ly no np dn mc nq nr dp mg li ns nt mi lm nu nv mk lq nw nx mm ny bi translated">加载数据并描述数据集</h2><p id="6ee6" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">加载数据文件是最简单的部分。问题(也是最耗时的部分)通常是指数据准备过程:设置正确的数据格式、处理缺失值和异常值、消除重复值等。</p><p id="4bcd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在加载数据之前，我们将导入必要的库:</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="b833" class="nn lx it oa b gy oe of l og oh">import xlrd<br/>import pandas as pd<br/>import numpy as np<br/>from sklearn.tree import DecisionTreeClassifier<br/>from sklearn.model_selection import train_test_split</span></pre><p id="7bbb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们加载数据集:</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="dc48" class="nn lx it oa b gy oe of l og oh">df_c = pd.read_excel(“macrodata_class.xlsx”)</span></pre><p id="335a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">看一下数据:</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="6a7f" class="nn lx it oa b gy oe of l og oh">df_c.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/28d6ab2c03b75e1067ef8b4064ae7c1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T-Cir8k4XrZ21KjcsDn2pw.png"/></div></div></figure><p id="de97" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到有一些缺失的值。让我们检查变量的类型:</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="b3d7" class="nn lx it oa b gy oe of l og oh">df_c.info()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/771e71be9404c1bc01353ce8a7e0d93a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f9Dm5Vscxp889UuHNm03ig.png"/></div></div></figure><p id="2ecb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在总共215个条目中，几乎所有的列都有缺失值。同样，我们可以看到，除了从变量“国家”和“类”(我们的目标变量)被定义为“对象”，其余的都是数字变量(float64)。</p><p id="a062" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以计算每个变量中有多少个缺失值:</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="744e" class="nn lx it oa b gy oe of l og oh">print(df_c.isnull().sum())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/706aa9f1af33848629c4d159d04cad23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3p5Ibcn-9DdwRWZfRvFjyg.png"/></div></div></figure><p id="2de8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们在构建DT之前去掉那些缺失的值:</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="3c56" class="nn lx it oa b gy oe of l og oh">df_c.dropna(inplace=True)</span></pre><p id="5178" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们再次描述我们的数据集，我们会看到这些寄存器已被删除:</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="be5c" class="nn lx it oa b gy oe of l og oh">df_c.info()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/dde08b7657fb10a668120504a84c8785.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nY7l_TRxo_89C23agzhlDg.png"/></div></div></figure><p id="f3ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以在<a class="ae ky" rel="noopener" target="_blank" href="/exploratory-data-analysis-on-steroids-e1488324fbaa">链接</a>上找到探索性数据分析的其他技术。</p><h2 id="49e4" class="nn lx it bd ly no np dn mc nq nr dp mg li ns nt mi lm nu nv mk lq nw nx mm ny bi translated">选择特征和目标变量</h2><p id="9a64" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">您需要将给定的列分成两种类型的变量:因变量(或目标变量)和自变量(或特征变量)。首先，我们定义特性:</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="72e2" class="nn lx it oa b gy oe of l og oh">X_c = df_c.iloc[:,1:8].copy()</span></pre><p id="a1bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后是目标变量:</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="9453" class="nn lx it oa b gy oe of l og oh">y_c = df_c.iloc[:,8].copy()</span></pre><h2 id="6510" class="nn lx it bd ly no np dn mc nq nr dp mg li ns nt mi lm nu nv mk lq nw nx mm ny bi translated">分割数据集</h2><p id="f0d4" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">要了解模型性能，将数据集分为定型集和测试集是一个好策略。通过将数据集分成两个独立的集合，我们可以使用一个集合进行训练，使用另一个集合进行测试。</p><ul class=""><li id="5f56" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><strong class="lb iu">训练集:</strong>这个数据用来建立你的模型。例如使用CART算法来创建决策树。</li><li id="fbe3" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu">测试集:</strong>该数据用于查看模型在看不见的数据上的表现，就像在现实世界中一样。在您想要测试您的模型以评估性能之前，这些数据应该是完全不可见的。</li></ul><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="6eac" class="nn lx it oa b gy oe of l og oh">X_c_train, X_c_test, y_c_train, y_c_test = train_test_split(X_c, y_c, test_size=0.3, random_state=432, stratify=y_c)</span></pre><p id="2279" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里有几件事:我们将数据集分为70%的训练和30%的测试，并执行分层抽样，以便产生的样本中值的比例与目标变量中提供的值的比例相同。</p><h2 id="876d" class="nn lx it bd ly no np dn mc nq nr dp mg li ns nt mi lm nu nv mk lq nw nx mm ny bi translated">建立DT模型并微调</h2><p id="d5b5" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">构建DT就像这样简单:</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="719e" class="nn lx it oa b gy oe of l og oh">clf = DecisionTreeClassifier(criterion=’gini’,min_samples_leaf=10)</span></pre><p id="c159" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这种情况下，我们只定义了分裂标准(选择了基尼指数而不是熵)，并且只定义了一个超参数(叶子的最小样本量)。定义模型架构的参数被称为<strong class="lb iu">超参数</strong>，因此，搜索理想模型架构(最大化模型性能的架构)的过程被称为超参数调整<em class="lv">。</em> A <strong class="lb iu">超参数</strong>是在学习过程开始前就设定好值的参数，它们不能直接从数据中训练出来。</p><p id="ffd6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以通过调用模型来查看可以优化的其余超参数:</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="47c3" class="nn lx it oa b gy oe of l og oh">clf</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/0b53e52c67b002d443104aeb9e98bfca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WIFj_X5IS0d96zCnVz7baA.png"/></div></div></figure><p id="7ed9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">模型可以有许多超参数，并且有不同的策略来寻找参数的最佳组合。你可以在<a class="ae ky" rel="noopener" target="_blank" href="/hyperparameter-tuning-explained-d0ebb2ba1d35">这个链接</a>上看看其中的一些。</p><h2 id="fe1e" class="nn lx it bd ly no np dn mc nq nr dp mg li ns nt mi lm nu nv mk lq nw nx mm ny bi translated">列车DT模型</h2><p id="0998" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">将模型拟合到训练数据代表了建模过程的训练部分。在模型定型后，可以使用预测方法调用来进行预测:</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="d328" class="nn lx it oa b gy oe of l og oh">model_c = clf.fit(X_c_train, y_c_train)</span></pre><h2 id="7d04" class="nn lx it bd ly no np dn mc nq nr dp mg li ns nt mi lm nu nv mk lq nw nx mm ny bi translated">测试DT模型</h2><p id="5798" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">测试数据集是独立于训练数据集的数据集。该测试数据集是您的模型的未知数据集，有助于您对其进行概化:</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="a281" class="nn lx it oa b gy oe of l og oh">y_c_pred = model_c.predict(X_c_test)</span></pre><h2 id="9967" class="nn lx it bd ly no np dn mc nq nr dp mg li ns nt mi lm nu nv mk lq nw nx mm ny bi translated">设想</h2><p id="ac70" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">DTs最大的优势之一是它们的可解释性。可视化DTs不仅是理解模型的有效方法，也是传达模型工作原理的有效方法:</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="1cdb" class="nn lx it oa b gy oe of l og oh">from sklearn import tree<br/>import graphviz<br/>dot_data = tree.export_graphviz(model_c, feature_names=list(X_c), class_names=sorted(y_c.unique()), filled=True)<br/>graphviz.Source(dot_data)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/7860e1d795a3106a67ac50d5b8cdb2c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jDNJretpcsmp-yHNlmGDMg.png"/></div></div></figure><p id="014c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">“purchasing.power.cap”这个变量似乎对于定义阶层或目标变量非常重要:高收入国家位于右侧，中上收入位于中间，低/中下收入位于左侧。</p><h2 id="f483" class="nn lx it bd ly no np dn mc nq nr dp mg li ns nt mi lm nu nv mk lq nw nx mm ny bi translated">评估绩效</h2><p id="5fd1" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">评估你的机器学习算法是任何项目必不可少的一部分:你如何衡量它的成功，你什么时候知道它不应该再改进了？不同的机器学习算法有不同的评估指标。让我们提一下分类树的一些主要方法:</p><blockquote class="nh ni nj"><p id="9683" class="kz la lv lb b lc ld ju le lf lg jx lh nk lj lk ll nl ln lo lp nm lr ls lt lu im bi translated"><strong class="lb iu">准确度得分</strong></p></blockquote><p id="8498" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">分类问题的准确性是指模型在各种预测中做出的正确预测的数量。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="801c" class="nn lx it oa b gy oe of l og oh">print ('Accuracy is:',(accuracy_score(y_c_test,y_c_pred)))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/d8f3163e6fccd23db330983d3c24e8f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FHxNKVvg2z_YQbacUQgxeg.png"/></div></div></figure><p id="3470" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的准确率是71.9%。如果我们认为可以通过生成新的特征或调整超参数来改进我们的模型，这还不错。但这是一个全球指标，所以让我们用其他指标来了解更多细节。</p><blockquote class="nh ni nj"><p id="1c95" class="kz la lv lb b lc ld ju le lf lg jx lh nk lj lk ll nl ln lo lp nm lr ls lt lu im bi translated"><strong class="lb iu">混乱矩阵</strong></p></blockquote><p id="6fa9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">混淆矩阵是用于发现模型的正确性和准确性的最直观的度量之一。它用于<strong class="lb iu">分类问题</strong>，其中输出可以是两种或多种类型的类。为了理解它，首先，我们需要定义一些术语:</p><ul class=""><li id="7736" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><strong class="lb iu">真阳性(TP) </strong>:显示一个模型<em class="lv">正确</em>预测<em class="lv">阳性</em>病例为<em class="lv">阳性。被诊断为存在的疾病确实存在。</em></li><li id="4857" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu">假阳性(FP) </strong>:显示一个模型<em class="lv">错误地</em>预测<em class="lv">阴性</em>病例为<em class="lv">阳性。E </em>例如，被诊断为存在的疾病不存在(I型错误)。</li><li id="eff2" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu">假阴性(FN): </strong>表示一个<em class="lv">模型错误地将<em class="lv">阳性</em>病例预测为<em class="lv">阴性</em>。例如，存在被诊断为不存在的疾病(类型II错误)。</em></li><li id="cafe" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu">真阴性(TN): </strong>表明模型<em class="lv">正确</em>预测<em class="lv">阴性</em>的情况为<em class="lv">阴性</em>。被诊断为不存在的疾病是真正不存在的。</li></ul><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="3b41" class="nn lx it oa b gy oe of l og oh">cmatrix = confusion_matrix(y_c_test,y_c_pred, labels=y_c_test.unique())<br/>pd.DataFrame(cmatrix, index=y_c_test.unique(), columns=y_c_test.unique())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/d06fcd1b64056b0ab0afc3903ed23f03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Brwy02-RifneAkcO0Tk6JQ.png"/></div></div></figure><p id="c364" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在像我们这样的多类混淆矩阵的情况下，矩阵将扩展到类的数量(在我们的例子中是4 x 4)。我们的DT正确预测了19个“高收入”实例中的17个，8个“低收入”实例中的6个，13个“中低收入”实例中的8个，以及17个“中高收入”实例中的10个。</p><p id="ea35" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">关于多类混淆矩阵的完整解释，请查看本文<a class="ae ky" href="https://dev.to/overrideveloper/understanding-the-confusion-matrix-264i" rel="noopener ugc nofollow" target="_blank">。</a></p><blockquote class="nh ni nj"><p id="4f9d" class="kz la lv lb b lc ld ju le lf lg jx lh nk lj lk ll nl ln lo lp nm lr ls lt lu im bi translated"><strong class="lb iu">分类报告</strong></p></blockquote><p id="2f9a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">分类报告显示了每个类别的主要分类指标。这给出了对分类器行为超过全局准确性的更深的直觉，这可以掩盖多类问题中的一类中的功能弱点。分类报告集成了不同的指标，例如:</p><ul class=""><li id="1a7b" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><strong class="lb iu">精度(TP/(TP+FP): </strong>是正确预测的正观测值与总预测正观测值之比。对于每个类别，它被定义为真阳性与真阳性和假阳性之和的比率。换句话说，当预测正面实例时，分类器有多“精确”？</li><li id="2069" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu"> Recall (TP/(TP+FN): </strong>是分类器找到所有正例的能力。对于每个类别，它被定义为真阳性与真阳性和假阴性之和的比率。换句话说，“对于所有实际上为阳性的实例，正确分类的百分比是多少？”</li><li id="b197" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu"> F1-Score (2*(精度*召回)/(精度+召回)):</strong>是精度和召回的加权调和平均值，使得最好的分数是1.0，最差的是0.0。一般来说，F1分数低于准确度，因为它们将准确度和回忆嵌入到计算中。根据经验，F1的加权平均值应该用于比较分类器模型，而不是全局精度。</li><li id="25a4" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu"> Support: </strong>是指定数据集中该类实际出现的次数。训练数据中的不平衡支持可以指示分类器的报告分数中的结构弱点，并且可以指示分层采样或再平衡的需要。支持在不同的模型之间不会改变，而是对评估过程进行诊断。</li></ul><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="a6be" class="nn lx it oa b gy oe of l og oh">report = classification_report(y_c_test, y_c_pred)<br/>print(report)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/5ad9afb78a87f8a677db492b25cece28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OQvvXkIcHtlXkKvhEuNBHw.png"/></div></div></figure><blockquote class="nh ni nj"><p id="92f4" class="kz la lv lb b lc ld ju le lf lg jx lh nk lj lk ll nl ln lo lp nm lr ls lt lu im bi translated"><strong class="lb iu">特征重要性</strong></p></blockquote><p id="7904" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一个关键指标包括为预测模型的输入特征分配分数，表明每个特征在进行预测时的相对重要性。<strong class="lb iu">特征重要性</strong>提供对数据、模型的洞察，并代表降维和特征选择的基础，这可以提高预测模型的性能。越多的属性用于DT的关键决策，其相对重要性就越高。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="d1a1" class="nn lx it oa b gy oe of l og oh">for importance, name in sorted(zip(clf.feature_importances_, X_c_train.columns),reverse=True):<br/> print (name, importance)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/1a6de76761195c77c6f4173164e6a546.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x9qq3q2Gfq1oDO0TR2F7KQ.png"/></div></div></figure><p id="e0ae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">变量“purchasing.power.cap”相对于所有其他变量(是模型的主要特征)来说非常重要，如果我们考虑目标变量，这完全有意义。</p><h1 id="1b12" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">包裹</h1><p id="dd74" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">虽然我们在建模期间涵盖了几个步骤，但这些概念中的每一个都是独立的学科:探索性数据分析、特征工程或超参数调整都是任何机器学习模型的广泛而复杂的方面。你应该考虑更深入地研究那些学科。</p><p id="9ffd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，DTs是称为集成方法的更强大算法的基础。<strong class="lb iu">集成方法</strong>将几个DTs结合起来，产生比单个DTs更好的预测性能。<strong class="lb iu">系综</strong>模型背后的主要原理是一群弱学习者走到一起形成强学习者，显著提高单个DT的表现。它们用于减少模型的方差和偏差，并改进预测。既然你已经看到了决策树是如何工作的，我建议你继续使用像<a class="ae ky" rel="noopener" target="_blank" href="/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205">打包或推进</a>这样的集合方法。</p></div><div class="ab cl os ot hx ou" role="separator"><span class="ov bw bk ow ox oy"/><span class="ov bw bk ow ox oy"/><span class="ov bw bk ow ox"/></div><div class="im in io ip iq"><blockquote class="nh ni nj"><p id="995d" class="kz la lv lb b lc ld ju le lf lg jx lh nk lj lk ll nl ln lo lp nm lr ls lt lu im bi translated"><em class="it">对这些话题感兴趣？关注我</em><a class="ae ky" href="https://www.linkedin.com/in/lopezyse/" rel="noopener ugc nofollow" target="_blank"><em class="it">Linkedin</em></a><em class="it">或</em> <a class="ae ky" href="https://twitter.com/lopezyse" rel="noopener ugc nofollow" target="_blank"> <em class="it"> Twitter </em> </a></p></blockquote></div></div>    
</body>
</html>