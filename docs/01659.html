<html>
<head>
<title>How to Tokenize Tweets with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">å¦‚ä½•ç”¨ Python å¯¹ Tweets è¿›è¡Œæ ‡è®°</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://towardsdatascience.com/an-introduction-to-tweettokenizer-for-processing-tweets-9879389f8fe7?source=collection_archive---------4-----------------------#2020-02-15">https://towardsdatascience.com/an-introduction-to-tweettokenizer-for-processing-tweets-9879389f8fe7?source=collection_archive---------4-----------------------#2020-02-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="59ea" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">æˆ‘ä»¬åº”è¯¥é€‰æ‹© TweetTokenizers è¿˜æ˜¯å…¶ä»– 4 ç§å¸¸è§çš„ Tokenizersï¼Ÿ</h2></div><h1 id="8d55" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">ä»€ä¹ˆæ˜¯æ ‡è®°åŒ–ï¼Ÿ</h1><p id="9ad5" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">è®°å·æ˜¯æ•´ä½“çš„ä¸€ä¸ªç‰‡æ®µï¼Œæ‰€ä»¥å•è¯æ˜¯å¥å­ä¸­çš„è®°å·ï¼Œå¥å­æ˜¯æ®µè½ä¸­çš„è®°å·ã€‚è®°å·åŒ–æ˜¯å°†ä¸€ä¸ªå­—ç¬¦ä¸²åˆ†å‰²æˆä¸€ç³»åˆ—è®°å·çš„è¿‡ç¨‹<strong class="lc iu">ã€‚</strong></p><p id="1836" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">å¦‚æœä½ å¯¹æ ‡è®°åŒ–æœ‰ç‚¹ç†Ÿæ‚‰ï¼Œä½†ä¸çŸ¥é“æ–‡æœ¬ä½¿ç”¨å“ªç§æ ‡è®°åŒ–ï¼Œæœ¬æ–‡å°†ä½¿ç”¨ Twitter ä¸Šçš„åŸå§‹ Tweets æ¥å±•ç¤ºä¸åŒçš„æ ‡è®°åŒ–åŠå…¶å·¥ä½œåŸç†ã€‚</p><p id="50e2" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">æœ¬æ–‡å°†ä»‹ç»å¦‚ä½•ç”¨ä»¥ä¸‹è¯­å¥å°†å¥å­æ ‡è®°æˆå•è¯:</p><ul class=""><li id="28c6" class="mb mc it lc b ld lw lg lx lj md ln me lr mf lv mg mh mi mj bi translated"><code class="fe mk ml mm mn b">word_tokenize</code></li><li id="5ea6" class="mb mc it lc b ld mo lg mp lj mq ln mr lr ms lv mg mh mi mj bi translated"><code class="fe mk ml mm mn b">WordPunctTokenizer</code></li><li id="78b7" class="mb mc it lc b ld mo lg mp lj mq ln mr lr ms lv mg mh mi mj bi translated"><code class="fe mk ml mm mn b">RegrexTokenizer</code></li><li id="b7f2" class="mb mc it lc b ld mo lg mp lj mq ln mr lr ms lv mg mh mi mj bi translated"><code class="fe mk ml mm mn b">TweetTokenizer</code></li></ul><p id="b314" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">æ ‡è®°åŒ–æ˜¯é¢„å¤„ç†åŸå§‹æ–‡æœ¬çš„ç¬¬ä¸€æ­¥ï¼Œæ‰€ä»¥æˆ‘å¸Œæœ›æ‚¨å¯¹æŒæ¡è¿™ä¸ªé‡è¦çš„æ¦‚å¿µæ„Ÿåˆ°å…´å¥‹ï¼</p><figure class="mu mv mw mx gt my gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi mt"><img src="../Images/3013929ccb887d8b3038f3e2fbba348f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mADiyrSVymvJURRa"/></div></div><p class="nf ng gj gh gi nh ni bd b be z dk translated">ç…§ç‰‡ç”±<a class="ae nj" href="https://unsplash.com/@eprouzet?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Eric Prouzet </a>æ‹æ‘„äº<a class="ae nj" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><h1 id="9cbb" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">è¦å¤„ç†çš„æ•°æ®</h1><p id="a6b1" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">Twitter æ˜¯ä¸€ä¸ªç¤¾äº¤å¹³å°ï¼Œæ¯å¤©éƒ½ä¼šå‘å¸ƒè®¸å¤šæœ‰è¶£çš„æ¨æ–‡ã€‚å› ä¸ºä¸æ­£å¼æ–‡æœ¬ç›¸æ¯”ï¼Œtweets æ›´éš¾æ ‡è®°ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†ä½¿ç”¨ tweets ä¸­çš„æ–‡æœ¬æ•°æ®ä½œä¸ºç¤ºä¾‹ã€‚</p><pre class="mu mv mw mx gt nk mn nl nm aw nn bi"><span id="8c9a" class="no kj it mn b gy np nq l nr ns">"https://t.co/9z2J3P33Uc FB needs to hurry up and add a laugh/cry button ğŸ˜¬ğŸ˜­ğŸ˜“ğŸ¤¢ğŸ™„ğŸ˜± Since eating my feelings has not fixed the world's problems, I guess I'll try to sleep... HOLY CRAP: DeVos questionnaire appears to include passages from uncited sources <a class="ae nj" href="https://t.co/FNRoOlfw9s" rel="noopener ugc nofollow" target="_blank">https://t.co/FNRoOlfw9s</a> well played, Senator Murray Keep the pressure on: <a class="ae nj" href="https://t.co/4hfOsmdk0l" rel="noopener ugc nofollow" target="_blank">https://t.co/4hfOsmdk0l</a> @datageneral thx Mr Taussig It's interesting how many people contact me about applying for a PhD and don't spell my name right."</span></pre><p id="d110" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">ä¸Šé¢çš„å¥å­é‡Œæœ‰å¾ˆå¤šä¿¡æ¯ã€‚åœ¨å¯¹æ•´ä¸ªå¥å­è¿›è¡Œè®°å·åŒ–ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆæŒ‘é€‰ä¸€äº›æˆ‘ä»¬æœ‰å…´è¶£æ¯”è¾ƒçš„å¥å­ã€‚è¿™ä¸ªåˆ—è¡¨å°†ç”¨äºæ¯”è¾ƒä¸åŒä»¤ç‰ŒåŒ–å™¨ä¹‹é—´çš„æ€§èƒ½ã€‚</p><pre class="mu mv mw mx gt nk mn nl nm aw nn bi"><span id="0305" class="no kj it mn b gy np nq l nr ns">compare_list = ['<a class="ae nj" href="https://t.co/9z2J3P33Uc'" rel="noopener ugc nofollow" target="_blank">https://t.co/9z2J3P33Uc'</a>,<br/>               'laugh/cry',<br/>               'ğŸ˜¬ğŸ˜­ğŸ˜“ğŸ¤¢ğŸ™„ğŸ˜±',<br/>               "world's problems",<br/>               "<a class="ae nj" href="http://twitter.com/datageneral" rel="noopener ugc nofollow" target="_blank">@datageneral</a>",<br/>                "It's interesting",<br/>               "don't spell my name right",<br/>               'all-nighter']</span></pre><h1 id="b22c" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">word_tokenize</h1><p id="5048" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">å°†å¥å­æ ‡è®°æˆå•è¯æ—¶æœ€æµè¡Œçš„æ–¹æ³•æ˜¯ä½¿ç”¨<code class="fe mk ml mm mn b">word_tokenize.</code>å’Œ<strong class="lc iu">ç©ºæ ¼å’Œæ ‡ç‚¹ç¬¦å·å°†å•è¯åˆ†å¼€ã€‚</strong></p><pre class="mu mv mw mx gt nk mn nl nm aw nn bi"><span id="dfee" class="no kj it mn b gy np nq l nr ns">from nltk.tokenize import word_tokenize</span><span id="a386" class="no kj it mn b gy nt nq l nr ns">word_tokens = []<br/>for sent in compare_list:<br/>    print(word_tokenize(sent))<br/>    word_tokens.append(word_tokenize(sent))</span></pre><p id="fbd9" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">ç»“æœ:</p><pre class="mu mv mw mx gt nk mn nl nm aw nn bi"><span id="30b6" class="no kj it mn b gy np nq l nr ns">['https', ':', '//t.co/9z2J3P33Uc']<br/>['laugh/cry']<br/>['ğŸ˜¬ğŸ˜­ğŸ˜“ğŸ¤¢ğŸ™„ğŸ˜±']<br/>['world', "'s", 'problems']<br/>['@', 'datageneral']<br/>['It', "'s", 'interesting']<br/>['do', "n't", 'spell', 'my', 'name', 'right']<br/>['all-nighter']</span></pre><p id="5ada" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">æˆ‘ä»¬å¸Œæœ›<code class="fe mk ml mm mn b">laugh/cry</code>è¢«æ‹†åˆ†æˆ 2 ä¸ªå•è¯ã€‚æ‰€ä»¥æˆ‘ä»¬åº”è¯¥è€ƒè™‘å¦ä¸€ä¸ªè®°å·èµ‹äºˆå™¨é€‰é¡¹ã€‚</p><h1 id="29cf" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">å•è¯æ ‡ç‚¹ç¬¦å·åŒ–å™¨</h1><p id="db94" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><code class="fe mk ml mm mn b">WordPunctTokenizer</code> <strong class="lc iu">å°†æ‰€æœ‰æ ‡ç‚¹ç¬¦å·</strong>æ‹†åˆ†æˆå•ç‹¬çš„è®°å·ã€‚æ‰€ä»¥è¿™å¯èƒ½å°±æ˜¯æˆ‘ä»¬æƒ³è¦çš„ï¼Ÿ</p><pre class="mu mv mw mx gt nk mn nl nm aw nn bi"><span id="c639" class="no kj it mn b gy np nq l nr ns">from nltk.tokenize import WordPunctTokenizer</span><span id="564a" class="no kj it mn b gy nt nq l nr ns">punct_tokenizer = WordPunctTokenizer()</span><span id="94b1" class="no kj it mn b gy nt nq l nr ns">punct_tokens = []<br/>for sent in compare_list:<br/>    print(punct_tokenizer.tokenize(sent))<br/>    punct_tokens.append(punct_tokenizer.tokenize(sent))</span></pre><p id="96fb" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">ç»“æœ:</p><pre class="mu mv mw mx gt nk mn nl nm aw nn bi"><span id="1168" class="no kj it mn b gy np nq l nr ns">['https', '://', 't', '.', 'co', '/', '9z2J3P33Uc']<br/>['laugh', '/', 'cry']<br/>['ğŸ˜¬ğŸ˜­ğŸ˜“ğŸ¤¢ğŸ™„ğŸ˜±']<br/>['world', "'", 's', 'problems']<br/>['@', 'datageneral']<br/>['It', "'", 's', 'interesting']<br/>['don', "'", 't', 'spell', 'my', 'name', 'right']<br/>['all', '-', 'nighter']</span></pre><p id="adeb" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">å—¯ï¼Œè¿™ä¸ªåˆ†è¯å™¨æˆåŠŸåœ°æŠŠ<code class="fe mk ml mm mn b">laugh/cry</code>æ‹†åˆ†æˆä¸¤ä¸ªå•è¯ã€‚ä½†æ˜¯ç¼ºç‚¹æ˜¯:</p><ul class=""><li id="4d4d" class="mb mc it lc b ld lw lg lx lj md ln me lr mf lv mg mh mi mj bi translated">é“¾æ¥<code class="fe mk ml mm mn b">â€˜<a class="ae nj" href="https://t.co/9z2J3P33Uc'" rel="noopener ugc nofollow" target="_blank">https://t.co/9z2J3P33Uc'</a></code>è¢«åˆ†æˆ 7 ä¸ªå•è¯</li><li id="c86d" class="mb mc it lc b ld mo lg mp lj mq ln mr lr ms lv mg mh mi mj bi translated"><code class="fe mk ml mm mn b">world's</code>è¢«<code class="fe mk ml mm mn b">"'"</code>å­—ç¬¦æ‹†åˆ†æˆä¸¤ä¸ªå•è¯</li><li id="9288" class="mb mc it lc b ld mo lg mp lj mq ln mr lr ms lv mg mh mi mj bi translated"><code class="fe mk ml mm mn b">@datageneral</code>åˆ†ä¸º<code class="fe mk ml mm mn b">@</code>å’Œ<code class="fe mk ml mm mn b">datageneral</code></li><li id="40cc" class="mb mc it lc b ld mo lg mp lj mq ln mr lr ms lv mg mh mi mj bi translated"><code class="fe mk ml mm mn b">don't</code>è¢«æ‹†åˆ†ä¸º<code class="fe mk ml mm mn b">do</code>å’Œ<code class="fe mk ml mm mn b">n't</code></li></ul><p id="4098" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">æ—¢ç„¶è¿™äº›å•è¯åº”è¯¥è¢«è®¤ä¸ºæ˜¯ä¸€ä¸ªå•è¯ï¼Œé‚£ä¹ˆè¿™ä¸ªåˆ†è¯å™¨ä¹Ÿä¸æ˜¯æˆ‘ä»¬æƒ³è¦çš„ã€‚æœ‰æ²¡æœ‰ä¸€ç§æ–¹æ³•å¯ä»¥æ ¹æ®ç©ºæ ¼æ¥æ‹†åˆ†å•è¯ï¼Ÿ</p><h1 id="925e" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">å†æ°§åŒ–å™¨</h1><p id="c6fd" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">ç”±äºæ²¡æœ‰åˆ†è¯å™¨ä¸“é—¨æ ¹æ®ç©ºæ ¼æ‹†åˆ†å•è¯ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨<code class="fe mk ml mm mn b">RegrexTokenizer</code>æ¥æ§åˆ¶å¦‚ä½•å¯¹æ–‡æœ¬è¿›è¡Œåˆ†è¯ã€‚æœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥é¿å…æ ¹æ®æ ‡ç‚¹ç¬¦å·æˆ–ç¼©å†™æ¥æ‹†åˆ†å•è¯:</p><ul class=""><li id="4a16" class="mb mc it lc b ld lw lg lx lj md ln me lr mf lv mg mh mi mj bi translated">åœ¨ä»£å¸ä¸ŠåŒ¹é…</li><li id="24c5" class="mb mc it lc b ld mo lg mp lj mq ln mr lr ms lv mg mh mi mj bi translated">åŒ¹é…åˆ†éš”ç¬¦æˆ–é—´éš™</li></ul><h2 id="338b" class="no kj it bd kk nu nv dn ko nw nx dp ks lj ny nz ku ln oa ob kw lr oc od ky oe bi translated">åœ¨ä»£å¸ä¸ŠåŒ¹é…</h2><p id="a374" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><code class="fe mk ml mm mn b">RegexpTokenizer</code>ç±»é€šè¿‡<strong class="lc iu">ç¼–è¯‘æˆ‘ä»¬çš„æ¨¡å¼</strong>ï¼Œç„¶ååœ¨æˆ‘ä»¬çš„æ–‡æœ¬ä¸Šè°ƒç”¨<code class="fe mk ml mm mn b">re.findall()</code>æ¥å·¥ä½œã€‚æˆ‘ä»¬å¯ä»¥åˆ©ç”¨è¿™ä¸ªå‡½æ•°æ¥åŒ¹é…å­—æ¯æ•°å­—æ ‡è®°å’Œå•å¼•å·</p><pre class="mu mv mw mx gt nk mn nl nm aw nn bi"><span id="8a0d" class="no kj it mn b gy np nq l nr ns">from nltk.tokenize import RegexpTokenizer<br/>match_tokenizer = RegexpTokenizer("[\w']+")</span><span id="3285" class="no kj it mn b gy nt nq l nr ns">match_tokens = []<br/>for sent in compare_list:   <br/>    print(match_tokenizer.tokenize(sent))<br/>    match_tokens.append(match_tokenizer.tokenize(sent))</span></pre><p id="f6b6" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">å¦‚æœæ‚¨ä¸ç†Ÿæ‚‰æ­£åˆ™è¡¨è¾¾å¼è¯­æ³•ï¼Œ<code class="fe mk ml mm mn b">\w+</code>åŒ¹é…ä¸€ä¸ªæˆ–å¤šä¸ªå•è¯å­—ç¬¦(å­—æ¯æ•°å­—&amp;ä¸‹åˆ’çº¿)</p><p id="5319" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">ç»“æœ:</p><pre class="mu mv mw mx gt nk mn nl nm aw nn bi"><span id="8ff9" class="no kj it mn b gy np nq l nr ns">['https', 't', 'co', '9z2J3P33Uc']<br/>['laugh', 'cry']<br/>[]<br/>["world's", 'problems']<br/>['datageneral']<br/>["It's", 'interesting']<br/>["don't", 'spell', 'my', 'name', 'right']<br/>['all', 'nighter']</span></pre><p id="b833" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">è™½ç„¶åƒ<code class="fe mk ml mm mn b">'worldâ€™s', 'Itâ€™s', 'donâ€™tâ€™</code>è¿™æ ·çš„å•è¯å¦‚æˆ‘ä»¬æ‰€æ„¿è¢«ä¿ç•™ä¸ºä¸€ä¸ªå®ä½“ï¼Œä½†æ˜¯<code class="fe mk ml mm mn b">â€˜<a class="ae nj" href="https://t.co/9z2J3P33Uc'" rel="noopener ugc nofollow" target="_blank">https://t.co/9z2J3P33Uc'</a></code>ä»ç„¶è¢«æ‹†åˆ†æˆä¸åŒçš„å•è¯ï¼Œå¹¶ä¸”æˆ‘ä»¬å¤±å»äº†<code class="fe mk ml mm mn b">â€œdatageneralâ€</code>ä¹‹å‰çš„<code class="fe mk ml mm mn b">â€œ@â€</code>å­—ç¬¦ã€‚ä¹Ÿè®¸æˆ‘ä»¬å¯ä»¥æ ¹æ®ç©ºç™½åˆ†å‰²ï¼Ÿ</p><h2 id="c979" class="no kj it bd kk nu nv dn ko nw nx dp ks lj ny nz ku ln oa ob kw lr oc od ky oe bi translated">ç©ºç™½åŒ¹é…</h2><p id="036c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><code class="fe mk ml mm mn b">RegexpTokenizer</code>ä¹Ÿå¯ä»¥é€šè¿‡<strong class="lc iu">åŒ¹é…ç¼ºå£</strong>æ¥å·¥ä½œã€‚å½“æ·»åŠ å‚æ•°<code class="fe mk ml mm mn b">gaps=True</code>æ—¶ï¼ŒåŒ¹é…æ¨¡å¼å°†è¢«ç”¨ä½œåˆ†éš”ç¬¦ã€‚<code class="fe mk ml mm mn b">\s+</code>åŒ¹é…ä¸€ä¸ªæˆ–å¤šä¸ªç©ºæ ¼ã€‚</p><pre class="mu mv mw mx gt nk mn nl nm aw nn bi"><span id="08e1" class="no kj it mn b gy np nq l nr ns">space_tokenizer = RegexpTokenizer("\s+", gaps=True)</span><span id="c636" class="no kj it mn b gy nt nq l nr ns">space_tokens = []<br/>for sent in compare_list:<br/>    <br/>    print(space_tokenizer.tokenize(sent))<br/>    space_tokens.append(space_tokenizer.tokenize(sent))</span></pre><p id="c014" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">ç»“æœ:</p><pre class="mu mv mw mx gt nk mn nl nm aw nn bi"><span id="3cc6" class="no kj it mn b gy np nq l nr ns">['https://t.co/9z2J3P33Uc']<br/>['laugh/cry']<br/>['ğŸ˜¬ğŸ˜­ğŸ˜“ğŸ¤¢ğŸ™„ğŸ˜±']<br/>["world's", 'problems']<br/>['@datageneral']<br/>["It's", 'interesting']<br/>["don't", 'spell', 'my', 'name', 'right']<br/>['all-nighter']</span></pre><p id="c761" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">ä¸é”™ï¼ç°åœ¨æˆ‘ä»¬å°†é“¾æ¥<code class="fe mk ml mm mn b">â€˜https://t.co/9z2J3P33Uc'</code>è§£é‡Šä¸ºä¸€ä¸ªå•è¯ï¼ä½†æ˜¯çœ‹èµ·æ¥è¡¨æƒ…ç¬¦å·ç»„åˆæˆäº†ä¸€ä¸ªå•è¯ã€‚ç”±äºä¸åŒçš„è¡¨æƒ…ç¬¦å·åœ¨æƒ…æ„Ÿåˆ†æä¸­å¯èƒ½æ˜¯æœ‰æ„ä¹‰çš„ï¼Œæˆ‘ä»¬å¯èƒ½å¸Œæœ›å°†å®ƒä»¬åˆ†æˆä¸åŒçš„å•è¯ã€‚æ‰€ä»¥æˆ‘ä»¬éœ€è¦è€ƒè™‘å¦ä¸€ç§æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼æ¥å®ç°è¿™ä¸€ç‚¹ã€‚</p><p id="5210" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">å¥½æ¶ˆæ¯ï¼æœ‰ä¸€ä¸ªæ ‡è®°å™¨å¯ä»¥åœ¨ä¸ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼çš„æƒ…å†µä¸‹æœ‰æ•ˆåœ°æ‹†åˆ† tweetsã€‚</p><h1 id="c4a7" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">TweetTokenizer</h1><p id="7d06" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">æ˜¯çš„ï¼Œå¯¹ tweet è¿›è¡Œæ ‡è®°çš„æœ€å¥½æ–¹æ³•æ˜¯ä½¿ç”¨æ ‡è®°å™¨æ¥æ ‡è®° tweet</p><pre class="mu mv mw mx gt nk mn nl nm aw nn bi"><span id="3d00" class="no kj it mn b gy np nq l nr ns">from nltk.tokenize import TweetTokenizer<br/>tweet_tokenizer = TweetTokenizer()</span><span id="a0e8" class="no kj it mn b gy nt nq l nr ns">tweet_tokens = []<br/>for sent in compare_list:<br/>    print(tweet_tokenizer.tokenize(sent))<br/>    tweet_tokens.append(tweet_tokenizer.tokenize(sent))</span></pre><p id="11ec" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">ç»“æœ:</p><pre class="mu mv mw mx gt nk mn nl nm aw nn bi"><span id="8d40" class="no kj it mn b gy np nq l nr ns">['https://t.co/9z2J3P33Uc']<br/>['laugh', '/', 'cry']<br/>['ğŸ˜¬', 'ğŸ˜­', 'ğŸ˜“', 'ğŸ¤¢', 'ğŸ™„', 'ğŸ˜±']<br/>["world's", 'problems']<br/>['@datageneral']<br/>["It's", 'interesting']<br/>["don't", 'spell', 'my', 'name', 'right']<br/>['all-nighter']</span></pre><p id="6456" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">å‰å®³ï¼æ¨æ–‡è¢«æ ‡è®°æˆæˆ‘ä»¬æƒ³è¦çš„æ ·å­ï¼</p><h1 id="e7a4" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">æŠŠæ‰€æœ‰ä¸œè¥¿æ”¾åœ¨ä¸€èµ·</h1><p id="b781" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">æˆ‘ä»¬å¯ä»¥æŠŠæ‰€æœ‰ä¸œè¥¿æ”¾åœ¨ä¸€ä¸ª<code class="fe mk ml mm mn b">pd.dataframe</code>ä¸­è¿›è¡Œå¿«é€Ÿå‡†ç¡®çš„è§£é‡Šï¼Œè€Œä¸æ˜¯èŠ±æ—¶é—´å»åˆ†ææ¯ä¸ªåˆ†è¯å™¨çš„ç»“æœã€‚</p><pre class="mu mv mw mx gt nk mn nl nm aw nn bi"><span id="ca37" class="no kj it mn b gy np nq l nr ns">import pandas as pd</span><span id="c627" class="no kj it mn b gy nt nq l nr ns">tokenizers = {'word_tokenize': word_tokens,<br/>             'WordPunctTokenize':punct_tokens,<br/>             'RegrexTokenizer for matching':match_tokens,<br/>             'RegrexTokenizer for white space': space_tokens,<br/>             'TweetTokenizer': tweet_tokens }</span><span id="7bdb" class="no kj it mn b gy nt nq l nr ns">df = pd.DataFrame.from_dict(tokenizers)</span></pre><figure class="mu mv mw mx gt my gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi of"><img src="../Images/3d850d2774795ad1bc2c8ff7a3efeee9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FLVWAVL1pkAOpN9CoVBehA.png"/></div></div><p class="nf ng gj gh gi nh ni bd b be z dk translated">ä¸åŒæ ‡è®°å™¨ä¹‹é—´çš„æ¯”è¾ƒ</p></figure><p id="95e0" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">æ ¹æ®å¯¹ä¸Šè¡¨çš„è§‚å¯Ÿï¼Œ<code class="fe mk ml mm mn b">TweetTokenizer</code>ä¼¼ä¹æ˜¯æœ€ä½³é€‰æ‹©ã€‚æ‰€ä»¥æˆ‘ä»¬å¯ä»¥ç»§ç»­ç”¨è¿™ä¸ªæ¥æ ‡è®°æˆ‘ä»¬çš„å¥å­:</p><pre class="mu mv mw mx gt nk mn nl nm aw nn bi"><span id="9a7b" class="no kj it mn b gy np nq l nr ns">tweet_tokenizer.tokenize(sent)</span></pre><h1 id="dfab" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">ç»“è®º</h1><p id="278f" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">æ­å–œä½ ï¼æ‚¨å·²ç»ä» nltk åº“ä¸­å­¦ä¹ äº†ä¸åŒçš„åˆ†è¯å™¨æ¥å°†å¥å­åˆ†è¯ã€‚ä¼¼ä¹æ ‡è®° Twitter åŸå§‹æ–‡æœ¬çš„èµ¢å®¶æ˜¯<code class="fe mk ml mm mn b">TweetTokenizer</code>ã€‚ä½†æƒ…å†µå¹¶éæ€»æ˜¯å¦‚æ­¤ï¼Œä½ çš„é€‰æ‹©å¯èƒ½ä¼šæ ¹æ®ä½ åˆ†æçš„æ–‡æœ¬è€Œæ”¹å˜ã€‚é‡è¦çš„ä¸€ç‚¹æ˜¯ï¼Œæ‚¨çŸ¥é“è¿™äº›æ ‡è®°å™¨çš„åŠŸèƒ½å·®å¼‚ï¼Œè¿™æ ·æ‚¨å°±å¯ä»¥åšå‡ºæ­£ç¡®çš„é€‰æ‹©æ¥æ ‡è®°æ‚¨çš„æ–‡æœ¬ã€‚åœ¨è¿™ä¸ª<a class="ae nj" href="https://github.com/khuyentran1401/Data-science/blob/master/nlp/tweets_tokenize.ipynb" rel="noopener ugc nofollow" target="_blank"> Github repo </a>ä¸­ï¼Œæ‚¨å¯ä»¥éšæ„ä½¿ç”¨æœ¬æ–‡çš„ä»£ç ã€‚</p><p id="8377" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">æˆ‘å–œæ¬¢å†™ä¸€äº›åŸºæœ¬çš„æ•°æ®ç§‘å­¦æ¦‚å¿µï¼Œå¹¶å°è¯•ä¸åŒçš„ç®—æ³•å’Œæ•°æ®ç§‘å­¦å·¥å…·ã€‚ä½ å¯ä»¥åœ¨<a class="ae nj" href="https://www.linkedin.com/in/khuyen-tran-1401/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>å’Œ<a class="ae nj" href="https://twitter.com/KhuyenTran16" rel="noopener ugc nofollow" target="_blank"> Twitter </a>ä¸Šå’Œæˆ‘è”ç³»ã€‚</p><p id="a120" class="pw-post-body-paragraph la lb it lc b ld lw ju lf lg lx jx li lj ly ll lm ln lz lp lq lr ma lt lu lv im bi translated">å¦‚æœä½ æƒ³æŸ¥çœ‹æˆ‘å†™çš„æ‰€æœ‰æ–‡ç« çš„ä»£ç ï¼Œè¯·ç‚¹å‡»è¿™é‡Œã€‚åœ¨ Medium ä¸Šå…³æ³¨æˆ‘ï¼Œäº†è§£æˆ‘çš„æœ€æ–°æ•°æ®ç§‘å­¦æ–‡ç« ï¼Œä¾‹å¦‚:</p><div class="og oh gp gr oi oj"><a rel="noopener follow" target="_blank" href="/step-by-step-tutorial-web-scraping-wikipedia-with-beautifulsoup-48d7f2dfa52d"><div class="ok ab fo"><div class="ol ab om cl cj on"><h2 class="bd iu gy z fp oo fr fs op fu fw is bi translated">ç”¨ç¾ä¸½çš„å£°éŸ³æŠ“å–ç»´åŸºç™¾ç§‘</h2><div class="oq l"><h3 class="bd b gy z fp oo fr fs op fu fw dk translated">å…³äºå¦‚ä½•ä½¿ç”¨ Beautiful Soup çš„åˆ†æ­¥æ•™ç¨‹ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äº web æŠ“å–çš„ç®€å•æ˜“ç”¨çš„ Python åº“</h3></div><div class="or l"><p class="bd b dl z fp oo fr fs op fu fw dk translated">towardsdatascience.com</p></div></div><div class="os l"><div class="ot l ou ov ow os ox nd oj"/></div></div></a></div><div class="og oh gp gr oi oj"><a rel="noopener follow" target="_blank" href="/find-common-words-in-article-with-python-module-newspaper-and-nltk-8c7d6c75733"><div class="ok ab fo"><div class="ol ab om cl cj on"><h2 class="bd iu gy z fp oo fr fs op fu fw is bi translated">ç”¨ Python æ¨¡å— Newspaper å’Œ NLTK æŸ¥æ‰¾æ–‡ç« ä¸­çš„å¸¸ç”¨è¯</h2><div class="oq l"><h3 class="bd b gy z fp oo fr fs op fu fw dk translated">ä½¿ç”¨ newspaper3k å’Œ NLTK ä»æŠ¥çº¸ä¸­æå–ä¿¡æ¯å’Œå‘ç°è§è§£çš„åˆ†æ­¥æŒ‡å—</h3></div><div class="or l"><p class="bd b dl z fp oo fr fs op fu fw dk translated">towardsdatascience.com</p></div></div><div class="os l"><div class="oy l ou ov ow os ox nd oj"/></div></div></a></div><div class="og oh gp gr oi oj"><a rel="noopener follow" target="_blank" href="/python-tricks-for-keeping-track-of-your-data-aef3dc817a4e"><div class="ok ab fo"><div class="ol ab om cl cj on"><h2 class="bd iu gy z fp oo fr fs op fu fw is bi translated">è·Ÿè¸ªæ•°æ®çš„ Python æŠ€å·§</h2><div class="oq l"><h3 class="bd b gy z fp oo fr fs op fu fw dk translated">å¦‚ä½•ç”¨åˆ—è¡¨ã€å­—å…¸è®¡æ•°å™¨å’Œå‘½åå…ƒç»„æ¥è·Ÿè¸ªä¿¡æ¯</h3></div><div class="or l"><p class="bd b dl z fp oo fr fs op fu fw dk translated">towardsdatascience.com</p></div></div><div class="os l"><div class="oz l ou ov ow os ox nd oj"/></div></div></a></div><div class="og oh gp gr oi oj"><a rel="noopener follow" target="_blank" href="/maximize-your-productivity-with-python-6110004b45f7"><div class="ok ab fo"><div class="ol ab om cl cj on"><h2 class="bd iu gy z fp oo fr fs op fu fw is bi translated">ä½¿ç”¨ Python æœ€å¤§åŒ–æ‚¨çš„ç”Ÿäº§åŠ›</h2><div class="oq l"><h3 class="bd b gy z fp oo fr fs op fu fw dk translated">ä½ åˆ›å»ºäº†ä¸€ä¸ªå¾…åŠäº‹é¡¹æ¸…å•æ¥æé«˜æ•ˆç‡ï¼Œä½†æœ€ç»ˆå´æŠŠæ—¶é—´æµªè´¹åœ¨äº†ä¸é‡è¦çš„ä»»åŠ¡ä¸Šã€‚å¦‚æœä½ èƒ½åˆ›é€ â€¦</h3></div><div class="or l"><p class="bd b dl z fp oo fr fs op fu fw dk translated">towardsdatascience.com</p></div></div><div class="os l"><div class="pa l ou ov ow os ox nd oj"/></div></div></a></div><div class="og oh gp gr oi oj"><a rel="noopener follow" target="_blank" href="/timing-the-performance-to-choose-the-right-python-object-for-your-data-science-project-670db6f11b8e"><div class="ok ab fo"><div class="ol ab om cl cj on"><h2 class="bd iu gy z fp oo fr fs op fu fw is bi translated">é«˜æ•ˆ Python ä»£ç çš„è®¡æ—¶</h2><div class="oq l"><h3 class="bd b gy z fp oo fr fs op fu fw dk translated">å¦‚ä½•æ¯”è¾ƒåˆ—è¡¨ã€é›†åˆå’Œå…¶ä»–æ–¹æ³•çš„æ€§èƒ½</h3></div><div class="or l"><p class="bd b dl z fp oo fr fs op fu fw dk translated">towardsdatascience.com</p></div></div><div class="os l"><div class="pb l ou ov ow os ox nd oj"/></div></div></a></div></div></div>    
</body>
</html>