<html>
<head>
<title>Leverage the power of PyCaret</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用 PyCaret 的力量</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/leverage-the-power-of-pycaret-d5c3da3adb9b?source=collection_archive---------16-----------------------#2020-08-08">https://towardsdatascience.com/leverage-the-power-of-pycaret-d5c3da3adb9b?source=collection_archive---------16-----------------------#2020-08-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8f1b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用一行代码学习机器学习！</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4385a27414a907eda7aea154daace5e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SnZoUipu0FIh_Vvl"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@i_am_g?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Guillaume Jaillet </a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="11d9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated"><span class="l lw lx ly bm lz ma mb mc md di"> P </span> yCaret 是一个开源、低代码的 Python 机器学习库，旨在减少周期时间，并允许您使用您选择的笔记本环境在几秒钟内从准备数据到部署模型。</p><p id="d1f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文的目标读者是熟悉机器学习概念，并且知道如何使用不同的库(如 Scikit-Learn)实现各种机器学习算法的人。完美的读者意识到自动化的需要，并且不想花太多时间寻找最佳算法及其超参数。</p><p id="8b1b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作为机器学习从业者，我们知道在一个完整的数据科学项目的生命周期中涉及到几个步骤，其中包括数据预处理——缺失值处理、空值处理、更改数据类型、分类特征的编码技术、数据转换——log、box cox 转换、特征工程、探索性数据分析(EDA)等。在我们真正开始建模、评估和预测之前。因此，我们使用 python 中的各种库来完成这些任务，如 numpy、pandas、matplotlib scikit-learn 等。因此 Pycaret 是一个非常强大的库，可以帮助我们实现过程的自动化。</p><h1 id="f906" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">正在安装 Pycaret</h1><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="4ef0" class="nb mf it mx b gy nc nd l ne nf">!pip install pycaret==2.0</span></pre><p id="da58" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦 Pycaret 安装完毕，我们就可以开始了！我将在这里讨论一个回归问题，Pycaret 可用于许多问题，如分类、异常检测、聚类、自然语言处理。</p><p id="ed8e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我将在这里使用我从 Flipkart 网站获得的笔记本电脑价格数据集<a class="ae ky" href="https://github.com/mathangpeddi/Flipkart-Web-Scraping/blob/master/flipkart_web_scraping.ipynb" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"/></a><strong class="lb iu"/>。</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="cb05" class="nb mf it mx b gy nc nd l ne nf">df = pd.read_csv('changed.csv') # Reading the dataset<br/>df.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/6dd909500e73671a98a6102e88c83067.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p6Op6kzBVnatjEEJa8-BWA.png"/></div></div></figure><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="43e5" class="nb mf it mx b gy nc nd l ne nf">from pycaret.regression import *<br/>reg = setup(data = df, target = 'Price')</span></pre><p id="b3ea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Pycaret 的 setup()函数完成了大部分的校正工作，这通常需要多行代码才能完成——只用一行代码就完成了！这就是这个令人惊叹的图书馆的美妙之处！</p><p id="af65" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们使用设置变量，在目标中，我们提到特性名称(因变量)——这里我们想预测笔记本电脑的价格，因此它成为因变量。</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="1b7f" class="nb mf it mx b gy nc nd l ne nf">X = df.drop('Price',axis=1) <br/>Y = df['Price'] <br/>Y = pd.DataFrame(Y)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/024068c7d8d7ff41ad734ea67cee6ed1.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*8-1kRpXQduB0Vjzi1P9zYw.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/e17635a7739239e2aed75c0e9f0c9a42.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*fpz8UpK1qPmU6aoE_VzcNQ.png"/></div></figure><p id="9b2f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">比较所有回归模型</strong></p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="c47b" class="nb mf it mx b gy nc nd l ne nf">compare_models()</span></pre><p id="d029" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">训练所有的回归模型。因此，在此之后，我们可以创建任何模型——要么是 CatBoost，要么是 XGBoost regressor 模型，然后我们可以执行超参数调优。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/a922c74a86d46354a358aedcba9db773.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AVk9Ww6mf_KZodd4i75phA.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/4203920e5b667adeca0349ec2811ee89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nyp3fdhpYcAwBeW05huacA.png"/></div></div></figure><p id="d063" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到，与所有其他模型相比，我们的梯度推进回归(GBR)模型表现相对更好。但是我也使用 XGBoost 模型进行了分析，这个模型比 GBR 模型表现得更好。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/7d4d801dbbfe072ae07046b0c151a50c.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/1*co5aLT3XcnspI91YNEXt1Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用梯度推进回归模型时出错</p></figure><p id="414b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为我们已经确定了最好的模型是 xgboost，所以我们在 create_model 函数的帮助下创建了 XGBoost 模型，并提到了 max_depth(模型运行的迭代次数)</p><p id="6a7f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">创建模型</strong></p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="f15c" class="nb mf it mx b gy nc nd l ne nf">xgboost = create_model('xgboost', max_depth = 10)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/72c840b36d7c0e3d50532a864d12b659.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*-QVcB0BVuT1ZEbXTlCP5rw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用 XGBoost 模型时出错</p></figure><p id="d5f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，在创建深度为 10 的模型后，它运行 10 次迭代，并在每次迭代中计算 MAE(平均绝对误差)、MSE(均方误差)、RMSE(均方根误差)、R2(R2 分数-R 平方值)、MAPE(平均绝对百分比误差)。最后，它显示这 10 次迭代中所有误差的平均值和标准偏差。机器学习模型的错误越少越好！因此，为了减小误差，我们试图找出能使误差最小的超参数。</p><p id="a272" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为此，我们应用 tune_model 函数并应用 K-fold 交叉验证来找出最佳超参数。</p><p id="7ea0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">模型的超调</strong></p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="5eaf" class="nb mf it mx b gy nc nd l ne nf">xgboost = tune_model(xgboost, fold=5)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/929526261906f5e62e3f399ca1cacd85.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*jREswxzUZaAWUu5H_7Tbfg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">超调后出错</p></figure><p id="ceec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该模型运行 5 次迭代，并给出所有误差的平均值和标准偏差。5 次迭代后，GBR 和 XGBoost 模型的平均平均误差几乎相同，但在超调并进行预测后，XGBoost 模型的误差更小，表现优于 GBR 模型。</p><p id="b739" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">使用最佳模型进行预测</strong></p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="a811" class="nb mf it mx b gy nc nd l ne nf">predict_model(xgboost)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/48fb1f251253f1606262a0064526c772.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-r6S-enGQWwESEwxopkmWg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">做出预测</p></figure><p id="bfdc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">应用交叉验证后检查分数(我们主要需要平均绝对误差)。这里我们可以看到，最佳模型的平均误差已降至 10847.2257，因此平均绝对误差约为 10，000。</p><p id="b647" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">检查 xgboost 模型的所有参数</strong></p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="1080" class="nb mf it mx b gy nc nd l ne nf">print(xgboost)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/4eee75037765ddac5cf81e1e7e62f0ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/format:webp/1*FVmqDRvkBdbCAuvZcZXn-w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">检查超参数</p></figure><p id="fe11" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> XGBoost 模型超参数</strong></p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="1fed" class="nb mf it mx b gy nc nd l ne nf">plot_model(xgboost, plot='parameter')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/32b798aaac8cabd6b83d2750234a5490.png" data-original-src="https://miro.medium.com/v2/resize:fit:460/format:webp/1*qI0zbKX0bFtydmC_FXgueQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">检查超参数</p></figure><p id="64a2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">残差图</strong></p><p id="89bb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">实际值和预测值之间的距离(误差)</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="71d9" class="nb mf it mx b gy nc nd l ne nf">plot_model(xgboost, plot='residuals')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/0dde022ab436f8aa88952efb941b57a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*2n25D_PMXMf_V5UyhIUxzA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">残差图</p></figure><p id="0433" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以清楚地看到，我的模型过度拟合，因为训练集的 R 平方是 0.999，测试集是 0.843。这其实并不奇怪，因为我的数据集总共只包含 168 行！但是这里的要点是强调 Pycaret 的优秀特性，因为您只需一行代码就可以创建图表和曲线！</p><p id="66b0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">绘制预测误差</strong></p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="a625" class="nb mf it mx b gy nc nd l ne nf">plot_model(xgboost, plot='error')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/8136688849e4d5de9db45a4fa9fff920.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*SojhNreOu1d_UllhV5t93g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">预计误差</p></figure><p id="3d41" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该模型的 R 平方值为 0.843。</p><p id="822e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">厨师距离图</strong></p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="526f" class="nb mf it mx b gy nc nd l ne nf">plot_model(xgboost, plot='cooks')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/d22812e9a7869ed9ef8ce87479471134.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*C9ljTY79caqGjn-eCZDvsA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">库克距离图</p></figure><p id="2a4d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">学习曲线</strong></p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="3a7a" class="nb mf it mx b gy nc nd l ne nf">plot_model(xgboost, plot='learning')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/f2cc3f7d07a4ffa54292c5b2003e59a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*CKjsWDLCV8BAO-pNnKtwvg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">学习曲线</p></figure><p id="8270" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">验证曲线</strong></p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="bb39" class="nb mf it mx b gy nc nd l ne nf">plot_model(xgboost, plot='vc')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/4803f7b7846f45c882f9b6673b1e10b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*S0YoddadB7q2AXKUsIt82g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">验证曲线</p></figure><p id="7517" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这两个图也向我们显示了模型明显过度拟合！</p><p id="5703" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">特征重要度图</strong></p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="b72a" class="nb mf it mx b gy nc nd l ne nf">plot_model(xgboost, plot='feature')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/6cd0796aa731841a8bec9f5876ef7226.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*lRW0jY77MlPPb4X17p0wyg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">特征重要性</p></figure><p id="b4ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过这个图，我们可以看到 Processor_Type_i9 (i9 CPU)是决定笔记本电脑价格的一个非常重要的特性。</p><p id="b5ee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">将数据集分割成训练集和测试集</strong></p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="7a70" class="nb mf it mx b gy nc nd l ne nf">from sklearn.model_selection import train_test_split<br/>X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)</span></pre><p id="dd68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">部署的最终 XGBoost 参数</strong></p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="2548" class="nb mf it mx b gy nc nd l ne nf">final_xgboost = finalize_model(xgboost)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/8d8ad062458b000f88cef372b9c41132.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*anh0FzjNG2glubYVLad1oA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">XGB 模型的最终参数</p></figure><p id="3e6d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">对未知数据(测试集数据)进行预测</strong></p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="9b36" class="nb mf it mx b gy nc nd l ne nf">new_predictions = predict_model(xgboost, data=X_test)<br/>new_predictions.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/9b5f4ce6e63db3fa3ce29cfe905a9753.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zQVLuQyCD3OOMCO2kY95vg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">测试集上的预测</p></figure><p id="366c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">保存转换管道和模型</strong></p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="2146" class="nb mf it mx b gy nc nd l ne nf">save_model(xgboost, model_name = 'deployment_08082020')</span><span id="becc" class="nb mf it mx b gy nz nd l ne nf">Transformation Pipeline and Model Succesfully Saved<br/></span><span id="36cf" class="nb mf it mx b gy nz nd l ne nf">deployment_08082020 = load_model('deployment_08082020')</span><span id="b4a8" class="nb mf it mx b gy nz nd l ne nf">Transformation Pipeline and Model Sucessfully Loaded</span><span id="6954" class="nb mf it mx b gy nz nd l ne nf">deployment_08082020</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/f0e57d1b6e6d17363825852904a13044.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-7qsKqc67DgzXRH_ertWMA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">最终机器学习模型</p></figure><p id="d5ff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以这是最终可以用于部署的机器学习模型。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/aaeadc6cc2d8387337892d6d51c6d25d.png" data-original-src="https://miro.medium.com/v2/resize:fit:526/format:webp/1*JZsdQ-aBoXPA41aw2LHkdA.png"/></div></figure><p id="4cc1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">模型以 pickle 格式保存！</p><p id="5792" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">更多信息，请查看文档<strong class="lb iu"> </strong> <a class="ae ky" href="https://pycaret.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">此处</strong> </a></p><p id="90ed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我没有详细讨论每件事。但是你可以随时参考我的<a class="ae ky" href="https://github.com/mathangpeddi/Laptop-Prices-Predictor/blob/master/Laptop_Prices_Prediction.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> GitHub 资源库</strong> </a>获取完整代码。我从这篇文章得出的结论是，不要期待一个完美的模型，而是期待一些你今天可以在自己的公司/项目中使用的东西！</p><p id="8f20" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">喊出<a class="ae ky" href="https://towardsdatascience.com/@moez_62905" rel="noopener" target="_blank"> <strong class="lb iu"> Moez Ali </strong> </a>为这个绝对辉煌的图书馆干杯！</p><p id="daa6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在 LinkedIn 上与我联系<a class="ae ky" href="https://www.linkedin.com/in/mathang-peddi-23763317b/" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">这里</strong> </a></p><blockquote class="oc"><p id="6a43" class="od oe it bd of og oh oi oj ok ol lu dk translated">底线是自动化降低了人为错误的风险，并为企业系统增加了一些智能。—史蒂芬·艾略特</p></blockquote><p id="d546" class="pw-post-body-paragraph kz la it lb b lc om ju le lf on jx lh li oo lk ll lm op lo lp lq oq ls lt lu im bi translated">我希望你觉得这篇文章很有见地。我很乐意听到反馈，以便即兴创作，并带来更好的内容。</p><p id="7a67" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">非常感谢您的阅读！</p></div></div>    
</body>
</html>