<html>
<head>
<title>How to Explain Graph Neural Network — GNNExplainer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何解释图形神经网络—gnnexplaner</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-can-we-explain-graph-neural-network-5031ea127004?source=collection_archive---------18-----------------------#2020-05-10">https://towardsdatascience.com/how-can-we-explain-graph-neural-network-5031ea127004?source=collection_archive---------18-----------------------#2020-05-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c67d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">PyTorch Geometric中实现的节点和图形解释的GNNExplainer的分步指南。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/62dd622a81b2359a330b240e3ab144f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gGk8boRg9nurYmQ2DKe7Mw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://pixabay.com/users/manuchi-1728328/?tab=popular&amp;pagi=3" rel="noopener ugc nofollow" target="_blank">马努奇</a>通过<a class="ae ky" href="https://pixabay.com/" rel="noopener ugc nofollow" target="_blank">皮克斯拜</a></p></figure><p id="bc38" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图形神经网络(GNN)是一种可以直接应用于图形结构数据的神经网络。我之前的帖子简单介绍了一下GNN。读者可以通过<a class="ae ky" href="https://medium.com/datadriveninvestor/an-introduction-to-graph-neural-network-gnn-for-analysing-structured-data-afce79f4cfdc" rel="noopener">这篇文章</a>了解更多细节。</p><p id="c6d7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">许多研究工作显示了GNN理解图形的能力，但是GNN是如何工作的以及为什么工作的对大多数人来说仍然是一个谜。与CNN不同，在CNN中，我们可以提取每一层的激活来可视化网络的决策，而在GNN，很难对网络学习了什么功能做出有意义的解释。为什么GNN确定一个节点是A类而不是B类？为什么GNN确定一个图形是化学物质还是分子？似乎GNN看到了一些有用的结构信息，并根据这些观察做出了决定。但现在的问题是，GNN看到了什么？</p><h1 id="77e1" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">GNNExplainer是什么？</h1><p id="0f22" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">本文中<a class="ae ky" href="https://arxiv.org/abs/1903.03894" rel="noopener ugc nofollow" target="_blank">介绍了GNNExplainer。</a></p><p id="59bc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">简而言之，它试图建立一个网络来学习GNN人所学的东西。</p><p id="27a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">GNNExplainer的主要原理是减少图中不直接影响决策的冗余信息。为了解释一个图，我们想知道图中影响神经网络决策的关键特征或结构是什么。如果一个特性很重要，那么预测应该通过删除或用其他东西替换这个特性来进行很大程度的修改。另一方面，如果移除或更改某个特征不会影响预测结果，则该特征被视为不重要，因此不应包含在图表的解释中。</p><h2 id="cd03" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">它是如何工作的？</h2><p id="d644" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">GNNExplainer的主要目标是生成一个最小图来解释一个节点或一个图的决策。为了实现这个目标，该问题可以被定义为在计算图中找到一个子图，该子图使用整个计算图和最小图来最小化预测分数的差异。在本文中，这个过程被公式化为最大化最小图Gs和计算图G之间的互信息(MI ):</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/98a22d16027b5a721c924b52557565ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*wrF3Sr8i2wQMxT8c1hi-yw.png"/></div></figure><p id="7c89" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，还有一个次要目标:图形需要最小化。虽然在第一个目标中也提到了，但是我们也需要一个方法来制定这个目标。该论文通过增加边数的损失来解决这个问题。因此，GNNExplainer的损失实际上是预测损失和边缘尺寸损失的组合。</p><h2 id="2272" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">解释任务</h2><p id="28ae" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">本文讨论了三种类型的解释:一个节点的解释、一类节点的解释和一个图的解释。主要区别在于计算图表。</p><p id="c4ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于单个节点的解释，计算图是其k跳邻居，其中k是模型中的卷积数。</p><p id="9d67" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于一类节点的解释，建议选择一个参考节点，用同样的方法计算解释。可以通过取其特征最接近具有相同类别的所有其他节点的平均特征的节点来选择参考节点。</p><p id="9e94" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了解释整个图，计算图成为图中所有节点的计算图的并集。这使得计算图等同于整个输入图。</p><h2 id="594d" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated"><strong class="ak">面罩接近</strong></h2><p id="0284" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">最小图Gs的学习是通过学习用于边的掩码和用于特征的掩码。也就是说，对于计算图中的每个边，在edge_mask中存在确定边的重要性的值。同样，对于结点要素中的每个要素，feature_mask确定该要素对于最终决策是否重要。</p><h2 id="7715" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">简短的摘要</h2><p id="7f31" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">有了这些概念，我们可以为GNNExplainer总结一切:</p><ol class=""><li id="35ac" class="nf ng it lb b lc ld lf lg li nh lm ni lq nj lu nk nl nm nn bi translated">我们需要提取计算图，它是节点分类的k跳邻居，或者是图分类的整个图。</li><li id="0c2c" class="nf ng it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated">为计算图中的每条边初始化一个edge_mask，为每个特征尺寸初始化一个特征mask。</li><li id="004e" class="nf ng it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated">构建一个神经网络，该网络学习具有上述损失的边缘_掩码和特征_掩码。</li><li id="4e64" class="nf ng it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated">使用edge_mask和feature_mask将计算图形缩减为最小图形。</li></ol><h1 id="a9df" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">在Pytorch中实现GNNExplainer</h1><p id="7675" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">这就是我们在实现GNNExplainer之前需要知道的一切。综上所述，我们正在尝试学习边_掩码和节点_特征_掩码，它们从计算图中移除一些边和特征，同时最小化预测得分的差异，所得的图是解释节点或图的决策的最小图。</p><p id="fca7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我将在Pytorch Geometric(PyG)中实现这一点。PyG的一个很大的优点是它更新非常频繁，并且有许多当前模型的实现。令人惊讶的是，我发现GNNExplainer已经在PyG库中实现了，这节省了我很多时间。尽管它只适用于节点解释，但由于它是开源的，因此不难将其修改为也适用于图形解释。</p><h2 id="69f7" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">节点解释器</h2><p id="82f6" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">首先，我们需要安装PyG。GNNExplainer目前还没有发布(PyG 1.4.4 ),但是代码已经在Github中发布了。所以要获得GNNExplainer，你必须从他们的Github库克隆并从那里安装。</p><p id="ce0d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">示例代码在<a class="ae ky" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html?highlight=gnnexplainer#torch_geometric.nn.models.GNNExplainer" rel="noopener ugc nofollow" target="_blank"> PyG网站</a>上提供。这很容易理解，所以我不打算在这篇文章中展示代码。但是实现细节是我们想要检查的，并在之后用于图分类。</p><p id="1304" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我将根据我上面的简短总结来追踪代码。示例代码将节点索引以及完整的特征矩阵和边列表传递给GNNExplainer模块。</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="6527" class="ms lw it nu b gy ny nz l oa ob">explainer = GNNExplainer(model, epochs=200)node_idx = 10node_feat_mask, edge_mask = explainer.explain_node(node_idx, x, edge_index)</span></pre><p id="cd8c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">GNNExplainer中发生的事情正是我们在上一节中讨论的。</p><ol class=""><li id="65f7" class="nf ng it lb b lc ld lf lg li nh lm ni lq nj lu nk nl nm nn bi translated">提取计算图</li></ol><p id="e633" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了解释一个节点，我们首先需要得到它的k跳计算图。这是通过<strong class="lb iu"> </strong> PyG中的_<strong class="lb iu">_子图__() </strong>方法<strong class="lb iu"> </strong>完成的。</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="08ce" class="ms lw it nu b gy ny nz l oa ob">x, edge_index, hard_edge_mask, kwargs = self.__subgraph__(<br/>            node_idx, x, edge_index, **kwargs)</span></pre><p id="5dd3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">hard_edge_mask移除k-hop邻域之外的所有其他边缘。</p><p id="4779" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.掩码由<strong class="lb iu"> __set_mask__() </strong>方法初始化，并应用于网络的每一层。</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="3127" class="ms lw it nu b gy ny nz l oa ob">self.__set_masks__(x, edge_index)         </span><span id="2ff0" class="ms lw it nu b gy oc nz l oa ob"><strong class="nu iu">def</strong> __set_masks__(self, x, edge_index, init="normal"):         <br/>    (N, F), E = x.size(), edge_index.size(1)          <br/>    std = 0.1         <br/>    self.node_feat_mask = torch.nn.Parameter(torch.randn(F) * 0.1)                </span><span id="503c" class="ms lw it nu b gy oc nz l oa ob">    std = torch.nn.init.calculate_gain('relu') * sqrt(2.0 / (2 * N))           </span><span id="337a" class="ms lw it nu b gy oc nz l oa ob">    self.edge_mask = torch.nn.Parameter(torch.randn(E) * std)                 </span><span id="6e95" class="ms lw it nu b gy oc nz l oa ob"><strong class="nu iu">    for</strong> module <strong class="nu iu">in</strong> self.model.modules():             <br/>        <strong class="nu iu">if</strong> isinstance(module, MessagePassing):                          <br/>            module.__explain__ = <strong class="nu iu">True</strong><br/>            module.__edge_mask__ = self.edge_mask</span></pre><p id="517a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3.使用经过训练的模型执行初始预测，然后将预测用作标签来训练GNNExplainer。</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="8bc1" class="ms lw it nu b gy ny nz l oa ob"><em class="od"># Get the initial prediction.</em>         <br/><strong class="nu iu">with</strong> torch.no_grad():             <br/>    log_logits = self.model(x=x, edge_index=edge_index, **kwargs) <br/>    pred_label = log_logits.argmax(dim=-1)          </span><span id="e6e8" class="ms lw it nu b gy oc nz l oa ob"># Train GNNExplainer<strong class="nu iu"><br/>for</strong> epoch <strong class="nu iu">in</strong> range(1, self.epochs + 1):                  <br/>    optimizer.zero_grad()             <br/>    h = x * self.node_feat_mask.view(1, -1).sigmoid()             <br/>    log_logits = self.model(x=h, edge_index=edge_index, **kwargs)              <br/>    loss = self.__loss__(0, log_logits, pred_label)             <br/>    loss.backward()             <br/>    optimizer.step()</span></pre><p id="b3fe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">4.损失的定义是</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="beef" class="ms lw it nu b gy ny nz l oa ob"><strong class="nu iu">def</strong> __loss__(self, node_idx, log_logits, pred_label):         <br/>      loss = -log_logits[node_idx, pred_label[node_idx]]          <br/>      m = self.edge_mask.sigmoid()         <br/>      loss = loss + self.coeffs['edge_size'] * m.sum()         <br/>      ent = -m * torch.log(m + EPS) - (1 - m) * torch.log(1 - m + EPS)         <br/>      loss = loss + self.coeffs['edge_ent'] * ent.mean()          <br/>      m = self.node_feat_mask.sigmoid()         <br/>      loss = loss + self.coeffs['node_feat_size'] * m.sum()         <br/>      ent = -m * torch.log(m + EPS) - (1 - m) * torch.log(1 - m + EPS)         <br/>      loss = loss + self.coeffs['node_feat_ent'] * ent.mean()          <strong class="nu iu">return</strong> loss</span></pre><h2 id="ea50" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">图形解释器</h2><p id="63f5" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">目前的实现是PyG只是为了节点解释。但是理解了背后的原理，重新编写图形解释函数就不难了。</p><p id="8ab4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们只需要替换几个函数:1)我们需要替换__subgraph__ function来获得整个图的计算图。2)我们需要为整个图形设置遮罩。3)我们需要改变损失函数来计算图的损失。</p><p id="bbd1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">完整的代码实现可在这个<a class="ae ky" href="https://gist.github.com/hongxuenong/9f7d4ce96352d4313358bc8368801707" rel="noopener ugc nofollow" target="_blank"> Github链接</a>获得。</p><h1 id="5226" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="f2d0" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">GNNExplainer提供了一个框架来可视化一个GNN模型学到了什么。然而，实际的解释结果可能不足以解释一个巨大的图形，因为最佳解释的搜索空间比一个较小的搜索空间大得多。除了拟合神经网络之外，也可以应用其他搜索技术来寻找借用相同概念的最佳解释，并且性能还有待证明。</p><h1 id="e94d" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">参考:</h1><p id="39a9" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">GNNExplainer:为图形神经网络生成解释，<a class="ae ky" href="https://arxiv.org/abs/1903.03894" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1903.03894</a></p><p id="8e14" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Pytorch几何，<a class="ae ky" href="https://pytorch-geometric.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">https://pytorch-geometric.readthedocs.io/en/latest/</a></p></div></div>    
</body>
</html>