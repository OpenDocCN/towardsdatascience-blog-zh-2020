<html>
<head>
<title>What is PyTorch?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch是什么？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-is-pytorch-a84e4559f0e3?source=collection_archive---------13-----------------------#2020-04-06">https://towardsdatascience.com/what-is-pytorch-a84e4559f0e3?source=collection_archive---------13-----------------------#2020-04-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="da0f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated"><strong class="ak">想想Numpy，但是有强大的GPU加速</strong></h2></div><h1 id="7963" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">介绍</h1><p id="3329" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><a class="ae lw" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>是一个Python程序库，方便构建<strong class="lc iu">深度学习项目</strong>。我们喜欢Python，因为它易于阅读和理解。PyTorch强调灵活性，允许深度学习模型用<strong class="lc iu">惯用Python表达。</strong></p><p id="2186" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">简单一句话，<strong class="lc iu">想想Numpy，但是有强大的GPU加速</strong>。更好的是，PyTorch <strong class="lc iu">支持动态计算图</strong>，允许你<strong class="lc iu">动态改变网络行为</strong>，不像Tensorflow等框架中使用的静态图。</p><blockquote class="mc"><p id="da8f" class="md me it bd mf mg mh mi mj mk ml lv dk translated">为什么是PyTorch？</p><p id="ceb6" class="md me it bd mf mg mh mi mj mk ml lv dk translated">GPU上类似NumPy的数组</p><p id="6654" class="md me it bd mf mg mh mi mj mk ml lv dk translated">-动态计算图</p><p id="d8b6" class="md me it bd mf mg mh mi mj mk ml lv dk translated">-是蟒蛇皮！</p></blockquote><figure class="mn mo mp mq mr ms gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi mm"><img src="../Images/7fca3eb2bae61a39c0c2a2c367ed329b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*VSJhXZvxeLvYq_J8_I842Q.gif"/></div></div><p class="mz na gj gh gi nb nc bd b be z dk translated">检索自<a class="ae lw" href="https://github.com/pytorch/pytorch" rel="noopener ugc nofollow" target="_blank"> PyTorch Github </a></p></figure><h1 id="3178" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">入门指南</h1><p id="9476" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">PyTorch可以在macOS上安装和使用。为了利用PyTorch的<a class="ae lw" href="https://developer.nvidia.com/cuda-zone" rel="noopener ugc nofollow" target="_blank"> CUDA </a> <a class="ae lw" href="https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html?highlight=cuda#cuda-tensors" rel="noopener ugc nofollow" target="_blank">支持</a>的全部能力，建议但不要求使用NVIDIA GPU。</p><p id="0645" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">用Anaconda安装</p><pre class="nd ne nf ng gt nh ni nj nk aw nl bi"><span id="273a" class="nm kj it ni b gy nn no l np nq">conda install pytorch torchvision -c pytorch</span></pre><p id="df8e" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">使用pip安装</p><pre class="nd ne nf ng gt nh ni nj nk aw nl bi"><span id="e1df" class="nm kj it ni b gy nn no l np nq">pip3 install torch torchvision</span></pre><p id="7931" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">如果你在安装上有任何问题，在这里找到更多关于安装PyTorch <a class="ae lw" href="https://pytorch.org/get-started/locally/" rel="noopener ugc nofollow" target="_blank">的不同方法。</a></p><p id="2af8" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">如果你的电脑中没有NVIDIA GPU，那么使用<a class="ae lw" href="https://colab.research.google.com/notebooks/intro.ipynb" rel="noopener ugc nofollow" target="_blank"> Google Colab </a>来利用其免费的GPU功能吧！点击左上方的新笔记本开始。</p><figure class="nd ne nf ng gt ms gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/47d05321468cdda5627dd8617ea72b4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/format:webp/1*xOA1tSqnaqHZ_KsqdEFzxA.png"/></div></figure><p id="7308" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">记得在运行笔记本之前将运行时类型更改为GPU</p><figure class="nd ne nf ng gt ms gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/ba18c6758b3ca1ddd626d082ac0b3d1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*8UccUAYquZMO-Sa_YFvqBQ.png"/></div></figure><figure class="nd ne nf ng gt ms gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/2cfd46b1c2b240ca1789ec3ecb3f385b.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/1*ropS022XEV7VssttlHYppw.png"/></div></figure><h1 id="8548" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">想想Numpy但是有强大的GPU加速！</h1><p id="1ebb" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">你熟悉Numpy吗？太好了！您只需要将使用on Numpy的语法转换为PyTorch的语法。如果你不熟悉Numpy，PyTorch的编写方式非常直观，你可以在几秒钟内学会。</p><p id="bea4" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">导入两个库以比较它们的结果和性能</p><pre class="nd ne nf ng gt nh ni nj nk aw nl bi"><span id="8b8b" class="nm kj it ni b gy nn no l np nq">import torch</span><span id="af0d" class="nm kj it ni b gy nu no l np nq">import numpy</span></pre><h2 id="68b0" class="nm kj it bd kk nv nw dn ko nx ny dp ks lj nz oa ku ln ob oc kw lr od oe ky of bi translated">张量</h2><p id="9731" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">PyTorch张量类似于NumPy ndarrays，可以选择在GPU上运行。</p><pre class="nd ne nf ng gt nh ni nj nk aw nl bi"><span id="c121" class="nm kj it ni b gy nn no l np nq">&gt;&gt;&gt; numpy.array([[0.1, 1.2], [2.2, 3.1], [4.9, 5.2]])</span><span id="e530" class="nm kj it ni b gy nu no l np nq">array([[0.1, 1.2],<br/>       [2.2, 3.1],<br/>       [4.9, 5.2]])</span><span id="4051" class="nm kj it ni b gy nu no l np nq">&gt;&gt;&gt; torch.tensor([[0.1, 1.2], [2.2, 3.1], [4.9, 5.2]])</span><span id="a407" class="nm kj it ni b gy nu no l np nq">tensor([[0.1000, 1.2000],<br/>        [2.2000, 3.1000],<br/>        [4.9000, 5.2000]])</span></pre><p id="9419" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">我们在这里看到了什么？<code class="fe og oh oi ni b">tensor</code>代替了<code class="fe og oh oi ni b">array.</code>还记得我们喜欢的<code class="fe og oh oi ni b">np.empty()</code>、<code class="fe og oh oi ni b"> np.random.randn()</code>、<code class="fe og oh oi ni b">np.zeros()</code>、<code class="fe og oh oi ni b">np.ones()</code>吗？PyTorch可以应用相同的函数和语法</p><pre class="nd ne nf ng gt nh ni nj nk aw nl bi"><span id="6ad8" class="nm kj it ni b gy nn no l np nq">w = torch.empty(3, 3)<br/>print(w,'<strong class="ni iu">\n</strong>', w.shape, '<strong class="ni iu">\n</strong>')</span><span id="7b66" class="nm kj it ni b gy nu no l np nq">x = torch.randn(3, 3, 7)<br/>print(x,'<strong class="ni iu">\n</strong>', x.shape, '<strong class="ni iu">\n</strong>')</span><span id="9864" class="nm kj it ni b gy nu no l np nq">y = torch.zeros(3, 3)<br/>print(y,'<strong class="ni iu">\n</strong>', y.shape, '<strong class="ni iu">\n</strong>')</span><span id="4c91" class="nm kj it ni b gy nu no l np nq">z = torch.ones(3, 3)<br/>print(z,'<strong class="ni iu">\n</strong>', z.shape, '<strong class="ni iu">\n</strong>')</span><span id="ec02" class="nm kj it ni b gy nu no l np nq">[0., 0., 3., 0., 0.],         <br/>        [4., 0., 5., 0., 0.],         <br/>        [0., 0., 0., 0., 0.]</span></pre><h2 id="cacd" class="nm kj it bd kk nv nw dn ko nx ny dp ks lj nz oa ku ln ob oc kw lr od oe ky of bi translated">形状和视图</h2><p id="838a" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">用<code class="fe og oh oi ni b">view()</code>方法改变形状</p><pre class="nd ne nf ng gt nh ni nj nk aw nl bi"><span id="01db" class="nm kj it ni b gy nn no l np nq">&gt;&gt;&gt; x = torch.rand(100,50)<br/>&gt;&gt;&gt; print(x.shape)<br/>torch.Size([100, 50])</span><span id="0b32" class="nm kj it ni b gy nu no l np nq">&gt;&gt;&gt; y=x.view(20,5,50)<br/>&gt;&gt;&gt; print(y.shape)<br/>torch.Size([20, 5, 50])</span><span id="3c42" class="nm kj it ni b gy nu no l np nq">&gt;&gt;&gt; z=x.view(-1,5,50)<br/>&gt;&gt;&gt; print(z.shape)<br/>torch.Size([20, 5, 50])</span></pre><h1 id="9852" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">CPU和GPU中的张量</h1><p id="e936" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">GPU(图形处理单元)由数百个更简单的核心组成，这使得训练深度学习模型的速度快得多。下面是GPU和CPU的快速对比。</p><figure class="nd ne nf ng gt ms gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/4682b1bc853a62a77c013eba22cbe2de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*ewx71rnxi4ceHPOyEOdRNA.jpeg"/></div><p class="mz na gj gh gi nb nc bd b be z dk translated"><a class="ae lw" href="https://www.slideshare.net/AlessioVillardita/ca-1st-presentation-final-published" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="0a45" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">无论我们决定使用GPU还是CPU，PyTorch都可以让我们轻松地在两者之间切换</p><pre class="nd ne nf ng gt nh ni nj nk aw nl bi"><span id="9d38" class="nm kj it ni b gy nn no l np nq">cpu=torch.device("cpu")<br/>gpu=torch.device("cuda:0") # GPU 0</span><span id="0ec9" class="nm kj it ni b gy nu no l np nq"># Create tensor with CPU<br/>x=torch.ones(3,3, device=cpu)<br/>print("CPU:",x.device)</span><span id="9972" class="nm kj it ni b gy nu no l np nq">x=torch.ones(3,3, device=gpu)<br/>print("GPU:",x.device)</span><span id="d01d" class="nm kj it ni b gy nu no l np nq">x=torch.ones(3,3).cuda(0)<br/>print("CPU to GPU:",x.device)</span><span id="9326" class="nm kj it ni b gy nu no l np nq">x=torch.ones(3,3, device=gpu).cpu()<br/>print("GPU to CPU:",x.device)</span></pre><figure class="nd ne nf ng gt ms gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/b78f17e678f060c9ce357e2c48ee35df.png" data-original-src="https://miro.medium.com/v2/resize:fit:340/format:webp/1*2et3Ekyvj4L4Dc8Ij3rnJA.png"/></div></figure><p id="4916" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">比较CPU和GPU的时间</p><p id="1af6" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">CPU时间</p><pre class="nd ne nf ng gt nh ni nj nk aw nl bi"><span id="099f" class="nm kj it ni b gy nn no l np nq">&gt;&gt;&gt; import time<br/>&gt;&gt;&gt; x=torch.rand(10000,10000)<br/>&gt;&gt;&gt; y=torch.rand(10000,10000)</span><span id="b86c" class="nm kj it ni b gy nu no l np nq">&gt;&gt;&gt; t = time.time()<br/>&gt;&gt;&gt; z=x@y<br/>&gt;&gt;&gt; t = time.time()-t<br/>&gt;&gt;&gt; print(t)</span><span id="266a" class="nm kj it ni b gy nu no l np nq">6.999474763870239</span></pre><p id="c378" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">GPU中的时间</p><pre class="nd ne nf ng gt nh ni nj nk aw nl bi"><span id="222f" class="nm kj it ni b gy nn no l np nq">&gt;&gt;&gt; yc=y.cuda(0)<br/>&gt;&gt;&gt; t = time.time()<br/>&gt;&gt;&gt; z=xc@yc<br/>&gt;&gt;&gt; t = time.time()-t<br/>&gt;&gt;&gt; print(t)</span><span id="9243" class="nm kj it ni b gy nu no l np nq">0.4787747859954834</span></pre><p id="067a" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">对于简单的矩阵乘法，它比Numpy快15倍！</p><h1 id="5c0d" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">NumPy呼叫PyTorch</h1><p id="dbd7" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">既然NumPy和PyTorch真的很像，那么有没有方法可以把NumPy数组改成PyTorch数组，反之亦然？是啊！</p><pre class="nd ne nf ng gt nh ni nj nk aw nl bi"><span id="1879" class="nm kj it ni b gy nn no l np nq">a = np.ones(5)</span><span id="913f" class="nm kj it ni b gy nu no l np nq">#From NumPy to Torch</span><span id="b572" class="nm kj it ni b gy nu no l np nq">b = torch.from_numpy(a)</span><span id="9cde" class="nm kj it ni b gy nu no l np nq">print('a:',a)</span><span id="e159" class="nm kj it ni b gy nu no l np nq">print('b:',b)</span></pre><figure class="nd ne nf ng gt ms gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/fc6b0189ca2e2337bb65082d9e019436.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*fg6P0Xr3UMeGn05_hJGdQg.png"/></div></figure><h1 id="dce1" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">PyTorch的亲笔签名</h1><p id="7ded" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">什么是亲笔签名？还记得在你的微积分课上，你需要计算一个函数的导数吗？梯度类似于导数，但是是矢量形式。计算神经网络中的损失函数是很重要的。但是由于维数很高，通过求解数学方程来计算如此大的复合函数的梯度是不切实际的。幸运的是，PyTorch可以在几秒钟内找到这个梯度的数值！</p><p id="d2ac" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">假设我们想求下面向量的梯度。我们期望y的梯度为x，用张量求梯度，检查是否得到正确答案。</p><figure class="nd ne nf ng gt ms gh gi paragraph-image"><div class="gh gi om"><img src="../Images/288d94fb10b92d97258906db81d57d07.png" data-original-src="https://miro.medium.com/v2/resize:fit:390/format:webp/1*dB62E1DSHop6LIhWfMGx_A.png"/></div></figure><figure class="nd ne nf ng gt ms"><div class="bz fp l di"><div class="on oo l"/></div></figure><figure class="nd ne nf ng gt ms gh gi paragraph-image"><div class="gh gi op"><img src="../Images/ef1810d80d352ae375138326a926f3f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*4q64GwWCOHnlHRXD3og1TQ.png"/></div></figure><figure class="nd ne nf ng gt ms gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/f284a5ce705ee7f651c283ce0c14234d.png" data-original-src="https://miro.medium.com/v2/resize:fit:278/format:webp/1*6orBvkhPicMuV6M3BhwNiQ.png"/></div></figure><p id="58de" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">厉害！梯度是x，和我们预期的一样。分解上述代码:</p><ul class=""><li id="fa8c" class="or os it lc b ld lx lg ly lj ot ln ou lr ov lv ow ox oy oz bi translated"><code class="fe og oh oi ni b">requires_grad = True</code>允许有效的梯度计算。如果我们知道我们将计算基于x的梯度，我们需要为输入设置<code class="fe og oh oi ni b">.requires_grad = True</code>。点击了解更多关于亲笔签名的工作方式<a class="ae lw" href="https://pytorch.org/docs/stable/notes/autograd.html" rel="noopener ugc nofollow" target="_blank">。</a></li><li id="09d7" class="or os it lc b ld pa lg pb lj pc ln pd lr pe lv ow ox oy oz bi translated"><code class="fe og oh oi ni b">y.backward()</code>数值计算梯度</li><li id="3cee" class="or os it lc b ld pa lg pb lj pc ln pd lr pe lv ow ox oy oz bi translated"><code class="fe og oh oi ni b">x.grad()</code>返回y在x点的梯度</li></ul><h1 id="3afc" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">例子</h1><p id="16aa" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">让我们通过一个分类示例来了解如何使用PyTorch。我们的任务是找到一个点是否在黄色或紫色的簇中</p><figure class="nd ne nf ng gt ms"><div class="bz fp l di"><div class="on oo l"/></div></figure><figure class="nd ne nf ng gt ms gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/6d5d49deb33025e1bf43c6375d7ac545.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*PeL0XRnP_idLaKUKmWNhuw.png"/></div></figure><p id="0987" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">首先构建一个用于构建神经网络的PyTorch模块的子类<code class="fe og oh oi ni b">nn.Module,</code>。</p><figure class="nd ne nf ng gt ms"><div class="bz fp l di"><div class="on oo l"/></div></figure><figure class="nd ne nf ng gt ms gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/2cdad5a69608503c4e1db7e1d316ba0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*PfK86SKjQgkjfgNSch_LHA.png"/></div></figure><p id="7fe7" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">将数据分为训练集和测试集</p><figure class="nd ne nf ng gt ms"><div class="bz fp l di"><div class="on oo l"/></div></figure><figure class="nd ne nf ng gt ms gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/3aa5273751b954cb8b7b06fb604ed6d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*WknZbxtDLxYbVl14XhV7hw.png"/></div></figure><p id="9f28" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">训练数据</p><figure class="nd ne nf ng gt ms"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="7a54" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">预测和评估预测</p><figure class="nd ne nf ng gt ms"><div class="bz fp l di"><div class="on oo l"/></div></figure><figure class="nd ne nf ng gt ms gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/474ae8451dabe2984d32d85eed4492dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:350/format:webp/1*X7jVGcpNASX1fyLUwmjkRw.png"/></div></figure><h1 id="647a" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">结论</h1><p id="c65f" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">恭喜你！您刚刚学习了PyTorch是什么以及如何使用它。本文只是对PyTorch的一个委婉的介绍。我希望你从这篇文章中获得的是，深度学习可以通过这个工具变得简单高效。要了解更多关于如何将PyTorch用于您的深度学习项目，我推荐查看这本伟大的书:<a class="ae lw" href="https://pytorch.org/deep-learning-with-pytorch" rel="noopener ugc nofollow" target="_blank"> <em class="pj">用PyTorch进行深度学习</em> </a> <em class="pj">，</em>了解PyTorch的最佳资源之一。</p><p id="5232" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">在<a class="ae lw" href="https://github.com/khuyentran1401/Data-science/blob/master/nlp/PyTorch.ipynb" rel="noopener ugc nofollow" target="_blank">这个Github repo </a>中，您可以随意使用本文的代码。</p><p id="7a8c" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">我喜欢写一些基本的数据科学概念，并尝试不同的算法和数据科学工具。你可以在LinkedIn和Twitter上与我联系。</p><p id="78c3" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">如果你想查看我写的所有文章的代码，请点击这里。在Medium上关注我，了解我的最新数据科学文章，例如:</p><div class="pk pl gp gr pm pn"><a rel="noopener follow" target="_blank" href="/step-by-step-tutorial-web-scraping-wikipedia-with-beautifulsoup-48d7f2dfa52d"><div class="po ab fo"><div class="pp ab pq cl cj pr"><h2 class="bd iu gy z fp ps fr fs pt fu fw is bi translated">用美丽的声音抓取维基百科</h2><div class="pu l"><h3 class="bd b gy z fp ps fr fs pt fu fw dk translated">关于如何使用Beautiful Soup的分步教程，这是一个用于web抓取的简单易用的Python库</h3></div><div class="pv l"><p class="bd b dl z fp ps fr fs pt fu fw dk translated">towardsdatascience.com</p></div></div><div class="pw l"><div class="px l py pz qa pw qb mx pn"/></div></div></a></div><div class="pk pl gp gr pm pn"><a rel="noopener follow" target="_blank" href="/how-to-solve-analogies-with-word2vec-6ebaf2354009"><div class="po ab fo"><div class="pp ab pq cl cj pr"><h2 class="bd iu gy z fp ps fr fs pt fu fw is bi translated">如何用Word2Vec解决类比问题</h2><div class="pu l"><h3 class="bd b gy z fp ps fr fs pt fu fw dk translated">美国之于加拿大，就像汉堡之于_？</h3></div><div class="pv l"><p class="bd b dl z fp ps fr fs pt fu fw dk translated">towardsdatascience.com</p></div></div><div class="pw l"><div class="qc l py pz qa pw qb mx pn"/></div></div></a></div><div class="pk pl gp gr pm pn"><a rel="noopener follow" target="_blank" href="/how-to-create-fake-data-with-faker-a835e5b7a9d9"><div class="po ab fo"><div class="pp ab pq cl cj pr"><h2 class="bd iu gy z fp ps fr fs pt fu fw is bi translated">如何用Faker创建假数据</h2><div class="pu l"><h3 class="bd b gy z fp ps fr fs pt fu fw dk translated">您可以收集数据或创建自己的数据</h3></div><div class="pv l"><p class="bd b dl z fp ps fr fs pt fu fw dk translated">towardsdatascience.com</p></div></div><div class="pw l"><div class="qd l py pz qa pw qb mx pn"/></div></div></a></div><div class="pk pl gp gr pm pn"><a rel="noopener follow" target="_blank" href="/an-introduction-to-tweettokenizer-for-processing-tweets-9879389f8fe7"><div class="po ab fo"><div class="pp ab pq cl cj pr"><h2 class="bd iu gy z fp ps fr fs pt fu fw is bi translated">如何用Python对Tweets进行标记</h2><div class="pu l"><h3 class="bd b gy z fp ps fr fs pt fu fw dk translated">我们应该选择TweetTokenizers还是其他4种常见的Tokenizers？</h3></div><div class="pv l"><p class="bd b dl z fp ps fr fs pt fu fw dk translated">towardsdatascience.com</p></div></div><div class="pw l"><div class="qe l py pz qa pw qb mx pn"/></div></div></a></div><div class="pk pl gp gr pm pn"><a rel="noopener follow" target="_blank" href="/boost-your-efficiency-with-these-6-numpy-tricks-29ca2fe81ecd"><div class="po ab fo"><div class="pp ab pq cl cj pr"><h2 class="bd iu gy z fp ps fr fs pt fu fw is bi translated">用这6个小窍门提高你的效率</h2><div class="pu l"><h3 class="bd b gy z fp ps fr fs pt fu fw dk translated">并控制您的阵列</h3></div><div class="pv l"><p class="bd b dl z fp ps fr fs pt fu fw dk translated">towardsdatascience.com</p></div></div><div class="pw l"><div class="qf l py pz qa pw qb mx pn"/></div></div></a></div></div></div>    
</body>
</html>