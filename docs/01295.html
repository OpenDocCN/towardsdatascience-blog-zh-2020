<html>
<head>
<title>How to Get Started With Facebook’s Detectron2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何开始使用脸书检测器2</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-beginners-guide-to-object-detection-and-computer-vision-with-facebook-s-detectron2-700b6273390e?source=collection_archive---------12-----------------------#2020-02-05">https://towardsdatascience.com/a-beginners-guide-to-object-detection-and-computer-vision-with-facebook-s-detectron2-700b6273390e?source=collection_archive---------12-----------------------#2020-02-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><blockquote class="jq jr js"><p id="5069" class="jt ju jv jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr im bi translated">在许多不同的物体探测技术中，脸书提出了它的模型:探测器2。这种模型与Yolo模型类似，能够围绕对象绘制边界框，并通过全景分割模型进行推理，换句话说，它不是围绕对象绘制一个框，而是“包裹”对象边界的真实边界(可以将其视为photoshop的智能剪切工具)。)</p></blockquote><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi ks"><img src="../Images/16c95c706ea8b657c5b2522483cb2698.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ru794dAzuqxRozxFsaUoaw.png"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">行动中的探测器2(原始图像由<a class="ae li" href="https://stocksnap.io/author/15899" rel="noopener ugc nofollow" target="_blank">尼克·卡沃尼斯</a>拍摄)</p></figure><h1 id="2016" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">介绍</h1><p id="09cc" class="pw-post-body-paragraph jt ju it jw b jx mh jz ka kb mi kd ke mj mk kh ki ml mm kl km mn mo kp kq kr im bi translated">本指南的目的是展示如何轻松实现预训练的Detectron2模型，能够识别来自<a class="ae li" href="http://cocodataset.org/#home" rel="noopener ugc nofollow" target="_blank"> COCO </a>(上下文中的公共对象)数据集中的类所代表的对象。本指南旨在为计算机视觉初学者提供一个起点，旨在解释实现预训练模型的第一步是什么，其最终目标是激发您学习更多内容的兴趣，并在这个势不可挡的领域安排您的想法。我提供了一个<a class="ae li" href="http://bit.ly/39cEy2C" rel="noopener ugc nofollow" target="_blank"> Google Colab笔记本</a>,你可以随意克隆和使用，也可以<strong class="jw iu">跟进和编码！</strong></p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi mp"><img src="../Images/9434521230245985744ecfce19a1a704.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dujhu1RLkDPw_NcjKDqRxg.png"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">可可数据集一瞥(来源:<a class="ae li" href="https://github.com/nightrome/cocostuff" rel="noopener ugc nofollow" target="_blank">https://github.com/nightrome/cocostuff</a>)</p></figure><h1 id="052f" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">安装依赖项</h1><p id="61bf" class="pw-post-body-paragraph jt ju it jw b jx mh jz ka kb mi kd ke mj mk kh ki ml mm kl km mn mo kp kq kr im bi translated">要开始使用，必须安装其核心依赖项:</p><ul class=""><li id="852d" class="mq mr it jw b jx jy kb kc mj ms ml mt mn mu kr mv mw mx my bi translated">PyTorch</li><li id="4f8b" class="mq mr it jw b jx mz kb na mj nb ml nc mn nd kr mv mw mx my bi translated">Cython</li><li id="9490" class="mq mr it jw b jx mz kb na mj nb ml nc mn nd kr mv mw mx my bi translated">检测器2</li><li id="0567" class="mq mr it jw b jx mz kb na mj nb ml nc mn nd kr mv mw mx my bi translated">OpenCV</li></ul><p id="8614" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mj kg kh ki ml kk kl km mn ko kp kq kr im bi translated">这些任务可能需要几分钟，因为你需要一个GPU来运行这个笔记本，我建议你克隆我的Colab笔记本，并从Google Colab编写所有内容，这也将帮助你对命令行片段和云中的文件管理更加自信！</p><pre class="kt ku kv kw gt ne nf ng nh aw ni bi"><span id="0f35" class="nj lk it nf b gy nk nl l nm nn">!pip install -U torch==1.4+cu100 torchvision==0.5+cu100 -f <a class="ae li" href="https://download.pytorch.org/whl/torch_stable.html" rel="noopener ugc nofollow" target="_blank">https://download.pytorch.org/whl/torch_stable.html</a></span><span id="6f67" class="nj lk it nf b gy no nl l nm nn">!pip install cython pyyaml==5.1</span><span id="efdd" class="nj lk it nf b gy no nl l nm nn">!pip install -U ‘git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'</span><span id="ee86" class="nj lk it nf b gy no nl l nm nn">!git clone <a class="ae li" href="https://github.com/facebookresearch/detectron2" rel="noopener ugc nofollow" target="_blank">https://github.com/facebookresearch/detectron2</a> detectron2_repo</span><span id="2664" class="nj lk it nf b gy no nl l nm nn">!pip install -e detectron2_repo</span><span id="f935" class="nj lk it nf b gy no nl l nm nn">#!pip install opencv-python Google Colab already comes with OpenCV</span></pre><h1 id="cbd4" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">导入库和所需的文件</h1><p id="a404" class="pw-post-body-paragraph jt ju it jw b jx mh jz ka kb mi kd ke mj mk kh ki ml mm kl km mn mo kp kq kr im bi translated">一旦安装了这些依赖项，您很可能需要重启您的运行时/内核。现在，我们需要导入一些我们需要导入、处理和推断预测的库，其中包括我们已有的库……</p><p id="8791" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mj kg kh ki ml kk kl km mn ko kp kq kr im bi translated">由于我使用的是Google Colab，功能<code class="fe np nq nr nf b">cv2.imshow()</code>不可用，如果你在本地机器上运行这个笔记本，我需要使用一个“补丁”版本来摆脱它。</p><pre class="kt ku kv kw gt ne nf ng nh aw ni bi"><span id="b9d6" class="nj lk it nf b gy nk nl l nm nn"># import some common libraries</span><span id="2c9b" class="nj lk it nf b gy no nl l nm nn">import numpy as np</span><span id="0a26" class="nj lk it nf b gy no nl l nm nn">import cv2</span><span id="ec77" class="nj lk it nf b gy no nl l nm nn">import random</span><span id="1b84" class="nj lk it nf b gy no nl l nm nn">from google.colab.patches import cv2_imshow # On your local machine you don’t need it.</span><span id="e840" class="nj lk it nf b gy no nl l nm nn"># import some common detectron2 utilities</span><span id="433e" class="nj lk it nf b gy no nl l nm nn">from detectron2 import model_zoo</span><span id="4e3e" class="nj lk it nf b gy no nl l nm nn">from detectron2.engine import DefaultPredictor</span><span id="cadc" class="nj lk it nf b gy no nl l nm nn">from detectron2.config import get_cfg</span><span id="8d5c" class="nj lk it nf b gy no nl l nm nn">from detectron2.utils.visualizer import Visualizer</span><span id="d667" class="nj lk it nf b gy no nl l nm nn">from detectron2.data import MetadataCatalog</span></pre><p id="caf2" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mj kg kh ki ml kk kl km mn ko kp kq kr im bi translated">在本指南中，我使用了我的google drive中的一个图像，您可以安装您的Google Drive并使用您选择的图像:</p><pre class="kt ku kv kw gt ne nf ng nh aw ni bi"><span id="a57a" class="nj lk it nf b gy nk nl l nm nn">from google.colab import drive</span><span id="ac8a" class="nj lk it nf b gy no nl l nm nn">drive.mount(‘/content/drive’)</span></pre><p id="d0cb" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mj kg kh ki ml kk kl km mn ko kp kq kr im bi translated">现在让我们得到一张我们想要运行模型的图片:</p><pre class="kt ku kv kw gt ne nf ng nh aw ni bi"><span id="f13b" class="nj lk it nf b gy nk nl l nm nn">im = cv2.imread(“./drive/My Drive/turin.png”)</span><span id="c74f" class="nj lk it nf b gy no nl l nm nn">cv2_imshow(im)</span></pre><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi ns"><img src="../Images/ea221bc42a16a7ca5aa3abee5260d5aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sxjvURCdHBC0MkuZkPnIkQ.png"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">图片来自我的谷歌硬盘(来源:谷歌街景)</p></figure><h1 id="d9f9" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">拟合模型</h1><p id="15d8" class="pw-post-body-paragraph jt ju it jw b jx mh jz ka kb mi kd ke mj mk kh ki ml mm kl km mn mo kp kq kr im bi translated">一旦我们的图像被加载，我们需要加载我们的模型和一点配置。首先，我们从Detectron加载配置，然后我们对其应用来自<code class="fe np nq nr nf b">COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml</code>的自定义配置。然后设置阈值，因此检测对象时模型的灵敏度(玩这些参数！).下一步是加载与该模型相关的检查点，换句话说，就是以<code class="fe np nq nr nf b">.pkl</code>格式加载模型本身。下一步是实例化模型本身，像在scikit中一样思考——例如，当您想要进行回归时，学习:</p><p id="678e" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mj kg kh ki ml kk kl km mn ko kp kq kr im bi translated"><code class="fe np nq nr nf b">reg = LinearRegression()</code> <code class="fe np nq nr nf b">reg.fit(X, y)</code> <code class="fe np nq nr nf b">reg.predict(X_test)</code>然而，我们没有将数组<code class="fe np nq nr nf b">X_train</code>传递给我们的预测器，而是传递我们的图像，该图像也对应于一个数组(准确地说是一个3D数组:一个轴代表宽度，另一个轴代表高度，最后一个轴代表图像的颜色)。</p><p id="a8c9" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mj kg kh ki ml kk kl km mn ko kp kq kr im bi translated">我们使用预训练模型而不是训练我们的模型的原因可以通过描述文件<a class="ae li" href="https://github.com/facebookresearch/detectron2/blob/master/MODEL_ZOO.md" rel="noopener ugc nofollow" target="_blank"> detectron2/MODEL_ZOO </a>的前两行来解释:</p><blockquote class="jq jr js"><p id="8db6" class="jt ju jv jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr im bi translated">“该文件记录了2019年9月至10月用detectron2训练的大量基线。所有数字都是在带有8个NVIDIA V100 GPUs和NVLink的大盆地服务器上获得的。使用的软件是PyTorch 1.3、CUDA 9.2、cuDNN 7.4.2或7.6.3。”。</p></blockquote><p id="db89" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mj kg kh ki ml kk kl km mn ko kp kq kr im bi translated">然而，当然，你可以使用一个基线模型来进一步训练它识别一个特定的物体，这个过程被称为<strong class="jw iu">转移</strong>学习。</p><pre class="kt ku kv kw gt ne nf ng nh aw ni bi"><span id="9a90" class="nj lk it nf b gy nk nl l nm nn">cfg = get_cfg()</span><span id="5c5a" class="nj lk it nf b gy no nl l nm nn">cfg.merge_from_file(model_zoo.get_config_file(“COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml”))</span><span id="c778" class="nj lk it nf b gy no nl l nm nn">cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5 # set threshold for this model</span><span id="ccfa" class="nj lk it nf b gy no nl l nm nn">cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(“COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml”)</span><span id="c4e6" class="nj lk it nf b gy no nl l nm nn">predictor = DefaultPredictor(cfg)</span><span id="58f6" class="nj lk it nf b gy no nl l nm nn">outputs = predictor(im)</span></pre><p id="5275" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mj kg kh ki ml kk kl km mn ko kp kq kr im bi translated">如果我们检查由模型生成的<code class="fe np nq nr nf b">outputs</code>，我们会看到一个<strong class="jw iu">大规模的</strong>字典(请参考Colab笔记本)，这个字典包含检测到的对象的数量(<code class="fe np nq nr nf b">num_instances</code>)、关于图像的信息和应该绘制框的图像的坐标，以及每个框(实例)的标签(<code class="fe np nq nr nf b">pred_classes</code>)。让我们看看第一个盒子:</p><p id="68d3" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mj kg kh ki ml kk kl km mn ko kp kq kr im bi translated"><code class="fe np nq nr nf b">[1314.3333, 485.8268, 1345.7896, 539.3832]</code></p><p id="93de" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mj kg kh ki ml kk kl km mn ko kp kq kr im bi translated">有4个值，每个值分别代表矩形的x、y、宽度和高度。(有时，在OpenCV中，当迭代检测到的对象时，你会做一个类似于<code class="fe np nq nr nf b">for x, y, w, h in ...</code>的循环)</p><h1 id="f2f6" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">获取输出图像</h1><p id="3381" class="pw-post-body-paragraph jt ju it jw b jx mh jz ka kb mi kd ke mj mk kh ki ml mm kl km mn mo kp kq kr im bi translated">现在，我们可以可视化图像以及显示图像中预测对象的方框，为了实现这一点，我们必须使用一个特定的对象，让我们将预测与原始图像合并，这个对象称为<code class="fe np nq nr nf b">Visualizer</code>，一旦用我们的图像和元数据实例化了<code class="fe np nq nr nf b">Visualizer</code>，我们就可以调用带有<code class="fe np nq nr nf b">outputs</code>作为参数的<code class="fe np nq nr nf b">draw_instance_predictions</code>方法:</p><pre class="kt ku kv kw gt ne nf ng nh aw ni bi"><span id="a8f8" class="nj lk it nf b gy nk nl l nm nn">v = Visualizer(im, MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.5) # Scaling the image 1.5 times, for big images consider a value below 0</span><span id="a6ff" class="nj lk it nf b gy no nl l nm nn">v = v.draw_instance_predictions(outputs[“instances”].to(“cpu”))</span><span id="9bcd" class="nj lk it nf b gy no nl l nm nn">cv2_imshow(v.get_image())</span></pre><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi nt"><img src="../Images/e46648035eab145e4865a0181c0752a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yB-O_MhljuBEWyUYfk1SNg.png"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">最终图像，带有识别检测到的“对象”的绘制框</p></figure><h1 id="d93f" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">现在去哪里？</h1><p id="1a80" class="pw-post-body-paragraph jt ju it jw b jx mh jz ka kb mi kd ke mj mk kh ki ml mm kl km mn mo kp kq kr im bi translated">计算机视觉是一个存在学习障碍的领域，也有一些进入障碍:通常很难获得特定的硬件，一个模型可能需要几个小时的训练，我们的小型笔记本电脑经常会死机，因此很难遵循“经典”的试错学习路径，也许我们在破解scikit-learn时尝试一些机器学习算法时会遵循这一路径！</p><p id="2d6b" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mj kg kh ki ml kk kl km mn ko kp kq kr im bi translated">既然(希望)你现在对工作流程有了一个基本的概念，从如何导入图像到如何显示图像，只要如何从detectron2库中加载模型，下一步可能是尝试重新训练它，使用(我建议)一些云提供商，可以是Google Colab，Paperspace Gradient，Azure Notebooks或任何其他东西。另一个很好的前进步骤可能是尝试实现探测器2“对手”<a class="ae li" href="https://pjreddie.com/darknet/yolo/" rel="noopener ugc nofollow" target="_blank"> Yolo </a>，也许<a class="ae li" href="https://github.com/Ma-Dan/YOLOv3-CoreML" rel="noopener ugc nofollow" target="_blank">使用CoreMLtools在iOS应用程序中实现它</a>。</p></div><div class="ab cl nu nv hx nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="im in io ip iq"><pre class="kt ku kv kw gt ne nf ng nh aw ni bi"><span id="55db" class="nj lk it nf b gy nk nl l nm nn"><strong class="nf iu">I have a newsletter 📩.</strong></span><span id="9ae7" class="nj lk it nf b gy no nl l nm nn">Every week I’ll send you a brief findings of articles, links, tutorials, and cool things that caught my attention. If tis sounds cool to you subscribe.</span><span id="16f2" class="nj lk it nf b gy no nl l nm nn"><em class="jv">That means </em><strong class="nf iu"><em class="jv">a lot</em></strong><em class="jv"> for me.</em></span></pre><div class="ob oc gp gr od oe"><a href="https://relentless-creator-2481.ck.page/68d9def351" rel="noopener  ugc nofollow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">米尔斯形式</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">编辑描述</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">无情-创造者-2481.ck.page</p></div></div></div></a></div></div></div>    
</body>
</html>