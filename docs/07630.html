<html>
<head>
<title>From LeNet to EfficientNet: The evolution of CNNs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从 LeNet 到 efficient net:CNN 的演变</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/from-lenet-to-efficientnet-the-evolution-of-cnns-3a57eb34672f?source=collection_archive---------27-----------------------#2020-06-08">https://towardsdatascience.com/from-lenet-to-efficientnet-the-evolution-of-cnns-3a57eb34672f?source=collection_archive---------27-----------------------#2020-06-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="9ee8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一个易于跟随的旅程，通过主流 CNN 的变化和新奇</p><h2 id="a41e" class="ko kp it bd kq kr ks dn kt ku kv dp kw kb kx ky kz kf la lb lc kj ld le lf lg bi translated">卷积神经网络:构建模块</h2><p id="7e53" class="pw-post-body-paragraph jq jr it js b jt lh jv jw jx li jz ka kb lj kd ke kf lk kh ki kj ll kl km kn im bi translated">卷积神经网络，或简称 CNN，是一种常用的<em class="lm">移位不变</em>方法，用于提取<em class="lm">‘可学习特征’</em>。CNN 在深度学习和神经网络的发展和普及中发挥了主要作用。我有一个单独的博客，讨论各种类型的卷积核及其优势。</p><div class="ln lo gp gr lp lq"><a rel="noopener follow" target="_blank" href="/types-of-convolution-kernels-simplified-f040cb307c37"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd iu gy z fp lv fr fs lw fu fw is bi translated">卷积核的类型:简化</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">对迷人的 CNN 层的不同变化的直观介绍</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">towardsdatascience.com</p></div></div><div class="lz l"><div class="ma l mb mc md lz me mf lq"/></div></div></a></div><p id="5c15" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然而，这里我将关注完整的 CNN 架构，而不是关注单个内核。我们可能无法单独访问 CNN 历史上的每一个主要发展，但我将尝试带您了解一般 CNN 架构是如何随着时间的推移而演变的。<strong class="js iu">你需要对 CNN 有一些基本的了解。</strong></p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mg"><img src="../Images/1a1f8a372fcdeb705eb2a0276d961344.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oMuceXv905mNClVcQmALYA.jpeg"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">卷积神经网络:概述[ <a class="ae mv" rel="noopener" target="_blank" href="/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53">来源</a></p></figure><h2 id="0a7f" class="ko kp it bd kq kr ks dn kt ku kv dp kw kb kx ky kz kf la lb lc kj ld le lf lg bi translated">莱内特:一切开始的地方</h2><p id="3a5a" class="pw-post-body-paragraph jq jr it js b jt lh jv jw jx li jz ka kb lj kd ke kf lk kh ki kj ll kl km kn im bi translated">LeNet 是第一个将反向传播用于实际应用的 CNN 架构，突然间深度学习不再只是一个理论。LeNet 用于手写数字识别，能够轻松胜过所有其他现有方法。LeNet 架构非常简单，只有由 5*5 卷积和 2*2 最大池组成的 5 层，但为更好、更复杂的模型铺平了道路。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mw"><img src="../Images/628627c80dd18e9f422a78ffabc85fbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lvvWF48t7cyRWqct13eU0w.jpeg"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">LeNet 架构[1]</p></figure><h2 id="a296" class="ko kp it bd kq kr ks dn kt ku kv dp kw kb kx ky kz kf la lb lc kj ld le lf lg bi translated">AlexNet:越深越好</h2><p id="92ea" class="pw-post-body-paragraph jq jr it js b jt lh jv jw jx li jz ka kb lj kd ke kf lk kh ki kj ll kl km kn im bi translated">AlexNet 是第一批在 GPU 上实现的 CNN 模型之一，真正将当时日益增长的计算能力与深度学习联系起来。他们创建了一个更深入、更复杂的 CNN 模型，该模型具有各种大小的内核(如 11*11、5*5 和 3*3)，频道数量明显多于 LeNet。他们还开始使用 ReLU 激活代替 sigmoid 或 tanh，这有助于训练更好的模型。AlexNet 不仅赢得了 2012 年的 Imagenet 分类挑战赛，<em class="lm">还以突然让非神经模型几乎过时的优势击败了亚军。</em></p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mx"><img src="../Images/e07cfb85787069924ffc597398b4ceeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1rXYQLuGsTDksfNAh5ZEKg.png"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">AlexNet 架构[2]</p></figure><h2 id="0b6b" class="ko kp it bd kq kr ks dn kt ku kv dp kw kb kx ky kz kf la lb lc kj ld le lf lg bi translated">概念网:多尺度特征提取</h2><p id="b0f8" class="pw-post-body-paragraph jq jr it js b jt lh jv jw jx li jz ka kb lj kd ke kf lk kh ki kj ll kl km kn im bi translated">在 CNN 的历史上，InceptionNet 是一个巨大的进步，它从多个方面解决了问题。首先，InceptionNet 比现有的模型更深入，参数更广泛。为了处理训练更深模型的问题，他们采用了在模型之间存在多个辅助分类器的想法，以防止梯度消失。然而，他们的主要主张之一是并行使用不同大小的内核，从而增加模型的宽度而不是深度。他们提出，这样的架构可以帮助他们同时提取更大和更小的特征。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi my"><img src="../Images/95a96667bce08456263bc3c0210058d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z_tzA_tY41GaDX3zH1mzaw.png"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">InceptionNet v1 架构[5]</p></figure><h2 id="bbab" class="ko kp it bd kq kr ks dn kt ku kv dp kw kb kx ky kz kf la lb lc kj ld le lf lg bi translated">VGG:3x 3 卷积的力量</h2><p id="9066" class="pw-post-body-paragraph jq jr it js b jt lh jv jw jx li jz ka kb lj kd ke kf lk kh ki kj ll kl km kn im bi translated">虽然 CNN 模型之前的所有迭代都相信更大感受野的想法(例如，AlexNet 有 11*11 个卷积核)，但 VGG 提出了将所有这些分解为 3*3 个卷积的想法。根据 VGG 体系结构，堆叠在一起的多个 3×3 卷积能够复制更大的感受野，并且在它们之间存在更多的非线性(就激活函数而言)，它甚至可以比具有更大感受野的对应物表现得更好。他们甚至引入了 1*1 卷积，以进一步增加模型中的非线性。从那以后，VGG 模型变得非常有名，甚至在今天还被用于各种教程中向 CNN 的新成员介绍。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mz"><img src="../Images/be3c340b2814f1926e05b74af2ce2005.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HzxRI1qHXjiVXla-_NiMBA.png"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">VGG-16 建筑[3]</p></figure><h2 id="f1d2" class="ko kp it bd kq kr ks dn kt ku kv dp kw kb kx ky kz kf la lb lc kj ld le lf lg bi translated">ResNet:处理消失渐变</h2><p id="2a3b" class="pw-post-body-paragraph jq jr it js b jt lh jv jw jx li jz ka kb lj kd ke kf lk kh ki kj ll kl km kn im bi translated">简单堆叠多个 CNN 层来创建更深模型的总体趋势很快就停止了，原因是深度学习中一个非常常见的问题，称为<em class="lm">消失梯度</em>。更简单地说，在训练 CNN 时，梯度从最后一层开始，在到达初始层之前，需要穿过中间的每一层。这可能会导致渐变在某处完全消失，从而难以训练模型的初始层。ResNet 模型引入了剩余或快捷连接，为渐变创建了替代路径，以跳过中间层并直接到达初始层。这使得作者可以训练早期表现不佳的非常深入的模型。现在，在现代 CNN 架构中使用剩余连接已经成为一种常见的做法。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi na"><img src="../Images/fb63231907aa8643e4e1d3dfa25f93a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ULk5ZyNC9adNKjdzOuIPRw.png"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">ResNet 架构[4]</p></figure><h2 id="945f" class="ko kp it bd kq kr ks dn kt ku kv dp kw kb kx ky kz kf la lb lc kj ld le lf lg bi translated">MobileNet &amp; MobileNetV2:向边缘友好型发展</h2><p id="8dc8" class="pw-post-body-paragraph jq jr it js b jt lh jv jw jx li jz ka kb lj kd ke kf lk kh ki kj ll kl km kn im bi translated">CNN 在这个阶段的总趋势是创建越来越大的模型以获得更好的性能。虽然 GPU 提供的计算能力的进步允许他们这样做，但一系列新的产品也在 ML 世界中引起了注意，称为边缘设备。边缘设备具有极大的内存和计算限制，但却为 GPU 无法应用的许多应用打开了大门。</p><p id="2f38" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了创建更轻的 CNN 模型，使其能够与现有的最先进技术相媲美，MobileNet 应运而生。MobileNet 引入了可分卷积的概念(我在之前的<a class="ae mv" rel="noopener" target="_blank" href="/types-of-convolution-kernels-simplified-f040cb307c37">博客</a>中详细讨论过)。更简单地说，它将 2D 卷积核分解为两个独立的卷积，深度卷积负责收集每个通道的空间信息，点卷积负责各个通道之间的交互。后来，MobileNetV2 也引入了剩余连接和架构中的其他调整，以进一步减小模型大小。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi nb"><img src="../Images/cec4c8c9c054b664d7aeb05e861a4442.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xlweRNEuI_M1iOAyXniv6Q.png"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">深度方向可分的 2D 卷积[ <a class="ae mv" rel="noopener" target="_blank" href="/types-of-convolution-kernels-simplified-f040cb307c37">来源</a></p></figure><h2 id="036d" class="ko kp it bd kq kr ks dn kt ku kv dp kw kb kx ky kz kf la lb lc kj ld le lf lg bi translated">效率网:挤压和激励层</h2><p id="0bec" class="pw-post-body-paragraph jq jr it js b jt lh jv jw jx li jz ka kb lj kd ke kf lk kh ki kj ll kl km kn im bi translated">有了各种关注性能或计算效率的独特模型，EfficientNet 模型提出了这两个问题可以通过类似的架构来解决的想法。他们提出了一个通用的 CNN 框架结构和三个参数，即宽度、深度和分辨率。模型的宽度是指各层中存在的通道的数量，深度是指模型中的层数，分辨率是指模型的输入图像大小。他们声称，通过保持所有这些参数较小，可以创建一个有竞争力但计算效率高的 CNN 模型。另一方面，仅仅通过增加这些参数的值，就可以创建更注重精度的模型。</p><p id="0eb3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">虽然挤压层和激发层早就提出来了，但他们是第一个将这个想法引入主流 CNN 的人。S&amp;E 图层创建跨通道的交互，这些交互对于空间信息是不变的。这可以用来降低不太重要的渠道的影响。他们还引入了新提出的 Swish 激活，而不是 ReLU，这是性能提高的一个重要因素。EfficientNets 是目前在各种计算资源可用性类别下表现最好的分类模型。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi nc"><img src="../Images/e1038c9a37f03123095661a21e5b4f5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PcFHTQJd0PPhaBkd5qchRg.png"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">挤压和激励网络[ <a class="ae mv" rel="noopener" target="_blank" href="/squeeze-and-excitation-networks-9ef5e71eacd7">来源</a></p></figure><h2 id="0b28" class="ko kp it bd kq kr ks dn kt ku kv dp kw kb kx ky kz kf la lb lc kj ld le lf lg bi translated">下一步是什么？</h2><p id="4c7d" class="pw-post-body-paragraph jq jr it js b jt lh jv jw jx li jz ka kb lj kd ke kf lk kh ki kj ll kl km kn im bi translated">如今，CNN 模型在其图像分类性能以及跨各种其他问题陈述(如对象检测和分割)的迁移学习能力方面受到测试。这些问题中的一些被认为已经解决了。焦点正转向 CNN 模型，如沙漏架构，其中输出图像分辨率与输入相同。然而，即使在今天，我在这篇博客中介绍的主干直接用于各种深度学习任务，因此即使图像分类问题几乎得到解决，该领域的发展在未来仍将具有很大的重要性。</p><h2 id="d66a" class="ko kp it bd kq kr ks dn kt ku kv dp kw kb kx ky kz kf la lb lc kj ld le lf lg bi translated">参考</h2><p id="c707" class="pw-post-body-paragraph jq jr it js b jt lh jv jw jx li jz ka kb lj kd ke kf lk kh ki kj ll kl km kn im bi translated"><em class="lm"> [1] LeCun，Yann 等，“基于梯度的学习在文档识别中的应用”IEEE 86.11 会议录(1998):2278–2324。<br/> [2]克里热夫斯基、亚历克斯、伊利亚·苏茨基弗和杰弗里·e·辛顿。"使用深度卷积神经网络的图像网络分类."神经信息处理系统进展。2012.<br/> [3]西蒙扬、卡伦和安德鲁·齐塞曼。“用于大规模图像识别的非常深的卷积网络。”arXiv 预印本 arXiv:1409.1556 (2014)。<br/> [4]何，，等.“用于图像识别的深度残差学习”IEEE 计算机视觉和模式识别会议录。2016.<br/>【5】塞格迪，克里斯蒂安，等着《用回旋深化》IEEE 计算机视觉和模式识别会议录。2015.<br/>【6】Howard，Andrew G .等，《移动网络:用于移动视觉应用的高效卷积神经网络》arXiv 预印本 arXiv:1704.04861 (2017)。<br/> [7]谭、明星、郭诉乐。"效率网:重新思考卷积神经网络的模型缩放."arXiv 预印本 arXiv:1905.11946 (2019)。</em></p></div></div>    
</body>
</html>