# Python ä¸­çš„æ•°æ®é›†

> åŸæ–‡ï¼š<https://towardsdatascience.com/datasets-in-python-425475a20eb1?source=collection_archive---------3----------------------->

## *5 ä¸ªè½¯ä»¶åŒ…ï¼Œå¯è½»æ¾è®¿é—®å„ç§æ•°æ®é›†*

æœ‰ä¸€äº›æœ‰ç”¨çš„ Python åŒ…ï¼Œåªéœ€è¦å‡ è¡Œä»£ç å°±å¯ä»¥åŠ è½½å…¬å¼€å¯ç”¨çš„æ•°æ®é›†ã€‚åœ¨æœ¬å¸–ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹çœ‹ 5 ä¸ªåŒ…ï¼Œå®ƒä»¬æä¾›äº†å¯¹ä¸€ç³»åˆ—æ•°æ®é›†çš„å³æ—¶è®¿é—®ã€‚å¯¹äºæ¯ä¸ªåŒ…ï¼Œæˆ‘ä»¬å°†äº†è§£*å¦‚ä½•æ£€æŸ¥å…¶å¯ç”¨æ•°æ®é›†åˆ—è¡¨*ä»¥åŠ*å¦‚ä½•å°†ç¤ºä¾‹æ•°æ®é›†åŠ è½½åˆ°ç†ŠçŒ«æ•°æ®æ¡†æ¶*ã€‚

![](img/953f514498bf284206bea0b4c7f8e143.png)

ç…§ç‰‡ç”±[ç‹æ€ç„¶Â·å“ˆå¾·æ£®](https://unsplash.com/@hudsoncrafted?utm_source=medium&utm_medium=referral)åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šæ‹æ‘„

# 0.Python è®¾ç½®ğŸ”§

æˆ‘å‡è®¾è¯»è€…(ğŸ‘€æ˜¯çš„ï¼Œä½ ï¼)å¯ä»¥è®¿é—®å¹¶ç†Ÿæ‚‰ Pythonï¼ŒåŒ…æ‹¬å®‰è£…åŒ…ã€å®šä¹‰å‡½æ•°å’Œå…¶ä»–åŸºæœ¬ä»»åŠ¡ã€‚å¦‚æœä½ æ˜¯ Python çš„æ–°æ‰‹ï¼Œ[è¿™ä¸ª](https://www.python.org/about/gettingstarted/)æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„å…¥é—¨åœ°æ–¹ã€‚

æˆ‘å·²ç»åœ¨ Jupyter Notebook ä¸­ä½¿ç”¨å¹¶æµ‹è¯•äº† Python 3.7.1 ä¸­çš„è„šæœ¬ã€‚åœ¨æˆ‘ä»¬å¼€å§‹ä¹‹å‰ï¼Œè®©æˆ‘ä»¬ç¡®ä¿æ‚¨å·²ç»å®‰è£…äº†ç›¸å…³çš„è½¯ä»¶åŒ…:

â—¼ï¸ ï¸ *pydataset* :æ•°æ®é›†åŒ…ï¼Œ
â—¼ï¸ ï¸ *seaborn* :æ•°æ®å¯è§†åŒ–åŒ…ï¼Œ
â—¼ï¸ ï¸ *sklearn:* æœºå™¨å­¦ä¹ åŒ…ï¼Œ
â—¼ï¸ ï¸ *statsmodel* :ç»Ÿè®¡æ¨¡å‹åŒ…ï¼Œ
â—¼ï¸ ï¸ *nltk:* è‡ªç„¶è¯­è¨€å·¥å…·åŒ…åŒ…

å¯¹äºæ¯ä¸ªåŒ…ï¼Œæˆ‘ä»¬å°†æ£€æŸ¥ç¤ºä¾‹æ•°æ®é›†çš„*å½¢çŠ¶*ã€*å¤´éƒ¨*å’Œ*å°¾éƒ¨*ã€‚ä¸ºäº†é¿å…é‡å¤æˆ‘ä»¬è‡ªå·±ï¼Œè®©æˆ‘ä»¬å¿«é€Ÿåˆ¶ä½œä¸€ä¸ªå‡½æ•°:

```
# Create a function to glimpse the data
def glimpse(df):
    print(f"{df.shape[0]} rows and {df.shape[1]} columns")
    display(df.head())
    display(df.tail())
```

å¥½äº†ï¼Œæˆ‘ä»¬å‡†å¤‡å¥½æ½œæ°´äº†ï¼ğŸ³

# 1.PyDatasetğŸ“š

æˆ‘ä»¬è¦çœ‹çš„ç¬¬ä¸€ä¸ªåŒ…æ˜¯ *PyDataset* ã€‚å®ƒæ˜“äºä½¿ç”¨ï¼Œå¯ä»¥è®¿é—® 700 å¤šä¸ªæ•°æ®é›†ã€‚è¿™ä¸ªåŒ…çš„çµæ„Ÿæ¥è‡ªäºåœ¨ R ä¸­è®¿é—®æ•°æ®é›†çš„ä¾¿åˆ©æ€§ï¼Œå¹¶è‡´åŠ›äºåœ¨ Python ä¸­å®ç°è¿™ç§ä¾¿åˆ©æ€§ã€‚è®©æˆ‘ä»¬æ¥çœ‹çœ‹æ•°æ®é›†åˆ—è¡¨:

```
# Import package
from pydataset import data# Check out datasets
data()
```

![](img/c7e8f5c8e90cc260b9e03d08bb9aaced.png)

è¿™å°†è¿”å›ä¸€ä¸ªæ•°æ®å¸§ï¼Œå…¶ä¸­åŒ…å«æ‚¨å¯ä»¥æµè§ˆçš„æ‰€æœ‰æ•°æ®é›†çš„ *dataset_id* å’Œ *title* ã€‚ç›®å‰ï¼Œæœ‰ 757 ä¸ªæ•°æ®é›†ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬åŠ è½½è‘—åçš„ *iris* æ•°æ®é›†ä½œä¸ºç¤ºä¾‹:

```
# Load as a dataframe
df = data('iris')
glimpse(df)
```

![](img/1d2e39bf3ec13d3bff449a3ff5fbc2fb.png)

å¯¼å…¥åŒ…åï¼Œå°†æ•°æ®é›†åŠ è½½åˆ° dataframe åªéœ€è¦ä¸€è¡Œä»£ç ã€‚å°±è¿™ä¹ˆç®€å•ï¼Œå¯¹å§ï¼Ÿéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåœ¨è¿™ä¸ªæ•°æ®é›†ä¸­ï¼Œè¡Œç´¢å¼•ä» 1 å¼€å§‹ï¼Œè€Œä¸æ˜¯ä» 0 å¼€å§‹ã€‚

ğŸ”—è¦äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ PyDataset çš„ [GitHub åº“](https://github.com/iamaziz/PyDataset)ã€‚

# 2.æµ·ç”Ÿçš„ğŸŒŠ

Seaborn æ˜¯å¦ä¸€ä¸ªè½¯ä»¶åŒ…ï¼Œå®ƒæä¾›äº†å¯¹ç¤ºä¾‹æ•°æ®é›†çš„ç®€å•è®¿é—®ã€‚è¦æ‰¾åˆ°æ•°æ®é›†çš„å®Œæ•´åˆ—è¡¨ï¼Œä½ å¯ä»¥æµè§ˆ [GitHub åº“](https://github.com/mwaskom/seaborn-data)ï¼Œæˆ–è€…ä½ å¯ä»¥åƒè¿™æ ·ç”¨ Python æŸ¥çœ‹:

```
# Import seaborn
import seaborn as sns# Check out available datasets
print(sns.get_dataset_names())
```

![](img/bcb8c9959838121f9594c523454c851b.png)

ç›®å‰ï¼Œæœ‰ 17 ä¸ªæ•°æ®é›†å¯ç”¨ã€‚è®©æˆ‘ä»¬ä»¥åŠ è½½*è™¹è†œ*æ•°æ®é›†ä¸ºä¾‹:

```
# Load as a dataframe
df = sns.load_dataset('iris')
glimpse(df)
```

![](img/db2b862560a40191de6237347eb2660d.png)

å¯¼å…¥åŒ…åï¼Œåªéœ€ä¸€è¡Œä»£ç å°±å¯ä»¥å°†æ•°æ®é›†ä½œä¸º dataframe åŠ è½½ã€‚

ğŸ”—è¦äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ *load_dataset* çš„[æ–‡æ¡£é¡µé¢ã€‚](https://seaborn.pydata.org/generated/seaborn.load_dataset.html)

# 3.sci kit-å­¦ä¹ ğŸ““

s *cikit-learn* ä¸ä»…åœ¨åŠŸèƒ½å·¥ç¨‹å’Œæ„å»ºæ¨¡å‹æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå®ƒè¿˜é™„å¸¦ç©å…·æ•°æ®é›†ï¼Œå¹¶æä¾›ä¸‹è½½å’ŒåŠ è½½çœŸå®ä¸–ç•Œæ•°æ®é›†çš„ä¾¿æ·é€”å¾„ã€‚ç©å…·å’ŒçœŸå®æ•°æ®é›†çš„åˆ—è¡¨ä»¥åŠå…¶ä»–ç»†èŠ‚å¯åœ¨[è¿™é‡Œ](https://scikit-learn.org/stable/datasets.html)è·å¾—ã€‚æ‚¨å¯ä»¥é€šè¿‡æ»šåŠ¨é“¾æ¥æˆ–å‚è€ƒå„ä¸ªå‡½æ•°çš„æ–‡æ¡£æ¥äº†è§£æœ‰å…³æ•°æ®é›†çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚å€¼å¾—ä¸€æçš„æ˜¯ï¼Œåœ¨è¿™äº›æ•°æ®é›†ä¸­ï¼Œæœ‰ä¸€äº›ç©å…·å’ŒçœŸå®çš„*å›¾åƒæ•°æ®é›†* ï¼Œå¦‚[æ•°å­—æ•°æ®é›†](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html?highlight=load_digit#sklearn.datasets.load_digits)å’Œ[å¥¥åˆ©ç»´è’‚äººè„¸æ•°æ®é›†](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_olivetti_faces.html#sklearn.datasets.fetch_olivetti_faces)ã€‚

ç°åœ¨ï¼Œè®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªç¤ºä¾‹æ¥çœ‹çœ‹å¦‚ä½•åŠ è½½çœŸå®æ•°æ®é›†:

```
# Import package
from sklearn.datasets import fetch_california_housing# Load data (will download the data if it's the first time loading)
housing = fetch_california_housing(as_frame=True)# Create a dataframe
df = housing['data'].join(housing['target'])
glimpse(df)
```

![](img/d25c99796b9dce1caa6e64d756b53e5b.png)

ä¸‹é¢æ˜¯å¦‚ä½•åŠ è½½ä¸€ä¸ªç¤ºä¾‹ç©å…·æ•°æ®é›†ï¼Œ *iris* :

```
# Import package
from sklearn.datasets import load_iris# Load data
iris = load_iris(as_frame=True)# Create a dataframe
df = iris['data'].join(iris['target'])# Map target names (only for categorical target)
df['target'].replace(dict(enumerate(iris['target_names'])), 
                     inplace=True)
glimpse(df)
```

![](img/fb9d7a223baeaf40ef651db489747fc3.png)

ğŸ’¡å¦‚æœæ‚¨å¾—åˆ°ä¸€ä¸ªå…³äº *as_frame* å‚æ•°çš„é”™è¯¯ï¼Œè¯·å°†æ‚¨çš„ *sklearn* ç‰ˆæœ¬æ›´æ–°åˆ° 0.23 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼Œæˆ–è€…ä½¿ç”¨ä¸‹é¢çš„è„šæœ¬:

```
# Import packages
import pandas as pd
from sklearn.datasets import load_iris# Load data
iris = load_iris()# Create a dataframe
X = pd.DataFrame(iris['data'], columns=iris['feature_names'])
y = pd.DataFrame(iris['target'], columns=['target'])
df = X.join(y)# Map target names (only for categorical target)
df['target'].replace(dict(enumerate(iris['target_names'])), 
                     inplace=True)
glimpse(df)
```

ğŸ”—æ¬²äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ scikit-learn çš„[æ–‡æ¡£é¡µé¢](https://scikit-learn.org/stable/datasets/index.html)ã€‚

# 4.ç»Ÿè®¡æ¨¡å‹ğŸ“”

å¦ä¸€ä¸ªæˆ‘ä»¬å¯ä»¥ç”¨æ¥è®¿é—®æ•°æ®çš„åŒ…æ˜¯ s *tatsmodels* ã€‚å¯ç”¨çš„å†…ç½®æ•°æ®é›†åˆ—åœ¨ä»–ä»¬ç½‘ç«™ä¸Šçš„[è¿™é‡Œ](https://www.statsmodels.org/devel/datasets/index.html)ã€‚è®©æˆ‘ä»¬é€‰æ‹©[â€˜ç¾å›½å®è§‚ç»æµæ•°æ®](https://www.statsmodels.org/stable/datasets/generated/macrodata.html)â€™ä½œä¸ºä¾‹å­å¹¶åŠ è½½å®ƒ:

```
# Import package
import statsmodels.api as sm# Load data as a dataframe
df = sm.datasets.macrodata.load_pandas()['data']
glimpse(df)
```

![](img/9a69f5e1ad2c7f74a5267d901877ab09.png)

ä½ å¯èƒ½å·²ç»æ³¨æ„åˆ°ï¼Œæˆ‘ä»¬ç”¨æ¥è®¿é—®[â€˜ç¾å›½å®è§‚ç»æµæ•°æ®](https://www.statsmodels.org/stable/datasets/generated/macrodata.html)â€™çš„åå­—æ˜¯*å®è§‚æ•°æ®*ã€‚è¦æ‰¾åˆ°å…¶ä»–æ•°æ®é›†çš„ç­‰æ•ˆåç§°ï¼Œè¯·æŸ¥çœ‹è¯¥æ•°æ®é›†æ–‡æ¡£çš„ URL æœ«å°¾ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨ç‚¹å‡»[å¯ç”¨æ•°æ®é›†](https://www.statsmodels.org/devel/datasets/index.html)éƒ¨åˆ†ä¸­çš„â€œç¾å›½å®è§‚ç»æµæ•°æ®â€å¹¶æŸ¥çœ‹æµè§ˆå™¨ä¸­çš„åœ°å€æ ï¼Œæ‚¨ä¼šåœ¨ URL çš„æœ«å°¾çœ‹åˆ°*â€œmacro data . htmlâ€*ã€‚

*Statsmodels* è¿˜å…è®¸ä½¿ç”¨ *get_rdataset* å‡½æ•°ä» R åŠ è½½æ•°æ®é›†ã€‚æ­¤å¤„çš„å¯ç”¨æ•°æ®é›†åˆ—è¡¨ä¸º[å’Œ](https://vincentarelbundock.github.io/Rdatasets/articles/data.html)ã€‚ä»¥ *iris* æ•°æ®é›†ä¸ºä¾‹ï¼Œæˆ‘ä»¬å¯ä»¥è¿™æ ·åŠ è½½æ•°æ®:

```
# Load data as a dataframe
df = sm.datasets.get_rdataset(dataname='iris', package='datasets')['data']
glimpse(df)
```

![](img/9f682ef96021f64a8194d461e284582c.png)

ğŸ”—æ¬²äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹æ•°æ®é›†çš„[æ–‡æ¡£é¡µé¢](https://www.statsmodels.org/stable/datasets/index.html)ã€‚

# 5.è‡ªç„¶è¯­è¨€å·¥å…·åŒ…| NLTKğŸ“œ

è¿™ä¸ªåŒ…ä¸å…¶ä»–åŒ…ç•¥æœ‰ä¸åŒï¼Œå› ä¸ºå®ƒåªæä¾›å¯¹æ–‡æœ¬æ•°æ®é›†çš„è®¿é—®ã€‚è¿™é‡Œæ˜¯å¯ç”¨çš„æ–‡æœ¬æ•°æ®é›†åˆ—è¡¨(Psstï¼Œè¯·æ³¨æ„åˆ—è¡¨ä¸­çš„ä¸€äº›é¡¹ç›®æ˜¯æ¨¡å‹)ã€‚ä½¿ç”¨ *id* ï¼Œæˆ‘ä»¬å¯ä»¥ä» NLTK è®¿é—®ç›¸å…³çš„æ–‡æœ¬æ•°æ®é›†ã€‚æˆ‘ä»¬ä»¥*æƒ…æ„Ÿææ€§æ•°æ®é›†*ä¸ºä¾‹ã€‚å®ƒçš„ *id* æ˜¯*ç”µå½± _ è¯„è®º*ã€‚è®©æˆ‘ä»¬å…ˆç”¨ä¸‹é¢çš„è„šæœ¬ä¸‹è½½å®ƒ:

```
# Import package
import nltk# Download the corpus (only need to do once)
nltk.download('movie_reviews')
```

å¦‚æœå·²ç»ä¸‹è½½äº†ï¼Œè¿è¡Œå®ƒä¼šé€šçŸ¥æ‚¨å·²ç»ä¸‹è½½äº†ã€‚ä¸‹è½½åï¼Œæˆ‘ä»¬å¯ä»¥å°†æ•°æ®åŠ è½½åˆ°æ•°æ®å¸§ä¸­ï¼Œå¦‚ä¸‹æ‰€ç¤º:

```
# Import packages
import pandas as pd
from nltk.corpus import movie_reviews# Convert to dataframe
documents = []
for fileid in movie_reviews.fileids():
    tag, filename = fileid.split('/')
    documents.append((tag, movie_reviews.raw(fileid)))
df = pd.DataFrame(documents, columns=['target', 'document'])
glimpse(df)
```

![](img/ecca3cfa0f2b2e950ca5a2e45778f57a.png)

åœ¨å°†æ–‡æœ¬æ•°æ®ä» NLTK è½¬æ¢ä¸º dataframe æ—¶ï¼Œæ²¡æœ‰ä¸€ç§é€‚åˆæ‰€æœ‰æƒ…å†µçš„æ–¹æ³•ã€‚è¿™æ„å‘³ç€æ‚¨éœ€è¦æ ¹æ®å…·ä½“æƒ…å†µå¯»æ‰¾è½¬æ¢ä¸ºæ•°æ®å¸§çš„é€‚å½“æ–¹æ³•ã€‚

ğŸ”—æ¬²äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹å…³äºè®¿é—®æ–‡æœ¬è¯­æ–™åº“å’Œè¯æ±‡èµ„æºçš„èµ„æºã€‚

è¿™å°±æ˜¯ä½ è¦çš„ï¼Œ5 ä¸ªå…è®¸è½»æ¾è®¿é—®æ•°æ®é›†çš„åŒ…ã€‚ç°åœ¨æ‚¨çŸ¥é“å¦‚ä½•ä»è¿™äº›åŒ…ä¸­åŠ è½½æ•°æ®é›†äº†ã€‚è¿™äº›åŒ…ä¸­å¯ç”¨çš„æ•°æ®é›†å°†æ¥å¯èƒ½ä¼šæ”¹å˜ï¼Œä½†æ˜¯ä½ çŸ¥é“å¦‚ä½•æ‰¾åˆ°æ‰€æœ‰å¯ç”¨çš„æ•°æ®é›†ï¼ğŸ™†

![](img/ec9eaa667bb5c75f4029a0c3c02a2308.png)

å…‹é‡Œæ–¯æ±€å¨œÂ·æˆˆå¡”è¿ªåœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šçš„ç…§ç‰‡

*æ‚¨æƒ³è®¿é—®æ›´å¤šè¿™æ ·çš„å†…å®¹å—ï¼Ÿåª’ä½“ä¼šå‘˜å¯ä»¥æ— é™åˆ¶åœ°è®¿é—®åª’ä½“ä¸Šçš„ä»»ä½•æ–‡ç« ã€‚å¦‚æœä½ ä½¿ç”¨* [*æˆ‘çš„æ¨èé“¾æ¥*](https://zluvsand.medium.com/membership)*æˆä¸ºä¼šå‘˜ï¼Œä½ çš„ä¸€éƒ¨åˆ†ä¼šè´¹ä¼šç›´æ¥å»æ”¯æŒæˆ‘ã€‚*

è°¢è°¢ä½ çœ‹æˆ‘çš„å¸–å­ã€‚å¸Œæœ›ä½ æ‰¾åˆ°äº†æœ‰ç”¨çš„ä¸œè¥¿ï¼Œâœ‚ï¸.å¦‚æœä½ æ„Ÿå…´è¶£ï¼Œè¿™é‡Œæœ‰æˆ‘çš„ä¸€äº›å…¶ä»–å¸–å­çš„é“¾æ¥:
â—¼ï¸ï¸ [ç»™ç†ŠçŒ«ç”¨æˆ·çš„ 5 ä¸ªæç¤º](/5-tips-for-pandas-users-e73681d16d17)
â—¼ï¸ï¸ï¸ï¸ [å¦‚ä½•åœ¨ç†ŠçŒ«æ•°æ®æ¡†æ¶ä¸­è½¬æ¢å˜é‡](/transforming-variables-in-a-pandas-dataframe-bce2c6ef91a1)
â—¼ï¸ [TF-IDF è§£é‡Š](https://medium.com/@zluvsand/introduction-to-nlp-part-3-tf-idf-explained-cedb1fc1f7dc)
â—¼ï¸[python ä¸­çš„ç›‘ç£æ–‡æœ¬åˆ†ç±»æ¨¡å‹](https://medium.com/@zluvsand/introduction-to-nlp-part-4-supervised-text-classification-model-in-python-96e9709b4267)

å†è§ğŸƒğŸ’¨