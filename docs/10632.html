<html>
<head>
<title>GPT-3 101: a brief introduction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">GPT-3 101:简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/gpt-3-101-a-brief-introduction-5c9d773a2354?source=collection_archive---------16-----------------------#2020-07-25">https://towardsdatascience.com/gpt-3-101-a-brief-introduction-5c9d773a2354?source=collection_archive---------16-----------------------#2020-07-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="30ca" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在过去的几周里，几乎不可能避免对 GPT-3 的大肆宣传。本文简要介绍了它的架构、已经可用的用例，以及关于它的伦理和绿色 IT 含义的一些想法。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/e1b2850fe3057015d58fc228fcb3ca33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1khs5ubowL1dwWqr"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片来自<a class="ae kv" href="https://unsplash.com/@franckinjapan" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/@franckinjapan</a></p></figure><h2 id="123a" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">介绍</h2><p id="9df8" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">让我们从基础开始。GPT-3 代表生成式预训练变压器版本 3，它是一个序列转导模型。简单来说，序列转导是一种将输入序列转化为输出序列的技术。</p><p id="4307" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">GPT-3 是一种语言模型，这意味着，使用序列转导，它可以预测给定输入序列的输出序列的可能性。例如，这可以用来预测在给定的文本序列中哪个单词最有意义。</p><p id="d03a" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">这些模型如何工作的一个非常简单的例子如下所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/8078818458a6890e70d5de0edde91d72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*o2RkDxutirXD88ri.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" rel="noopener ugc nofollow" target="_blank">可视化神经机器翻译模型</a>，作者<a class="ae kv" href="https://twitter.com/JayAlammar" rel="noopener ugc nofollow" target="_blank"> @JayAlammar </a></p></figure><p id="2df2" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">输入 :这是一个晴朗炎热的夏日，所以我打算去……</p><p id="be5e" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir"> <em class="mr">预测输出</em> </strong>:这是一个晴朗炎热的夏日，我正打算去<strong class="lu ir">海滩</strong>。</p><p id="9643" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">GPT-3 基于一种称为 Transformer 的特定神经网络架构类型，简而言之，它比 RNNs(递归神经网络)等其他架构更有效。<a class="ae kv" rel="noopener" target="_blank" href="/transformers-141e32e69591">这篇文章</a>很好地解释了不同的架构，以及序列转换如何从 GPT-3 使用的变压器架构中获益。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="b45a" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">Transformer 架构并不新鲜，因为它们在两年前变得非常流行，因为 Google 将它们用于另一个非常著名的语言模型，<a class="ae kv" href="https://arxiv.org/abs/1810.04805" rel="noopener ugc nofollow" target="_blank"> BERT </a>。它们也在 OpenAI 的 GPT 的早期版本中使用。那么，GPT 3 号有什么新鲜事吗？它的大小。这是一个非常大的模型。正如 OpenAI 在这篇<a class="ae kv" href="https://arxiv.org/pdf/2005.14165.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>中披露的，GPT 3 号使用了 1750 亿个参数。作为参考，GPT-2“仅”使用了 15 亿个参数。如果规模是实现类人智能的唯一必要条件(剧透，它不是)，那么<a class="ae kv" rel="noopener" target="_blank" href="/gpt-3-the-first-artificial-general-intelligence-b8d9b38557a1"> GPT-3 只是小了大约 1000 倍</a>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/48b1baf74a662f3e125b36aa61741764.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*B5mHjNVp_liS5rl-A0BpRg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">L <a class="ae kv" href="https://arxiv.org/pdf/2005.14165.pdf" rel="noopener ugc nofollow" target="_blank">语言模型是很少尝试的学习者</a>，OpenAI 论文。</p></figure><p id="4065" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">使用这种庞大的架构，GPT-3 也使用巨大的数据集进行了训练，包括<a class="ae kv" href="https://commoncrawl.org/" rel="noopener ugc nofollow" target="_blank">通用抓取</a>数据集和<a class="ae kv" href="https://en.wikipedia.org/wiki/Main_Page" rel="noopener ugc nofollow" target="_blank">英文维基百科</a> ( <a class="ae kv" href="https://www.theverge.com/21346343/gpt-3-explainer-openai-examples-errors-agi-potential" rel="noopener ugc nofollow" target="_blank">跨越约 600 万篇文章，仅占其训练数据的 0.6%</a>)，匹配“闭卷”问答任务的最先进性能，并为<a class="ae kv" href="https://arxiv.org/abs/1606.06031v1" rel="noopener ugc nofollow" target="_blank">λ</a>语言建模任务创造了新纪录。</p><h2 id="3a70" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">用例</h2><p id="ca9b" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">真正让 GPT-3 与之前的语言模型如 BERT 不同的是，由于它的架构和大量的训练，<a class="ae kv" href="https://medium.com/analytics-vidhya/openai-gpt-3-language-models-are-few-shot-learners-82531b3d3122" rel="noopener">它可以在不需要微调的情况下在任务无关的性能上表现出色</a>。魔法来了。自发布以来，GPT-3 已经在广泛的场景中得到应用，一些开发人员已经开发出了非常惊人的用例应用程序。他们中的一些人甚至在 github 或他们自己的网站上分享最好的，供大家尝试:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="5a59" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">基于 GPT 协议-3 的非详尽应用列表如下所示:</p><p id="86f9" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">文本总结</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="dd5d" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">正则表达式</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="90cc" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">自然语言到 SQL </strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="3cc3" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">自然语言到乳胶方程</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="e4b3" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">创意写作</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="45f4" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">界面设计和编码</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="f4e5" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">文本到 DevOps </strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="290a" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">自动回复邮件</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="4777" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">头脑风暴伴侣</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="2bb9" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">对话框流程工作台</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="a841" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">吉他琴谱生成</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><h2 id="0c4f" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">恐慌的时候到了？</h2><p id="afa3" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">作为一个在 IT 服务市场工作的人，当看到所有这些令人难以置信的基于 GPT 3 的应用程序时，首先想到的问题很明显:软件工程师会因为像这样的人工智能改进而失业吗？这里我首先想到的是，软件工程和写代码是不一样的。软件工程是一项意义深远的任务，它意味着解决问题、创造性，当然，还包括编写实际解决问题的代码。也就是说，我真的认为，由于启动，这将对我们通过软件解决问题的方式产生影响。</p><p id="4900" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">正如人类需要启动来识别我们以前从未注意到的东西一样，GPT-3 也是如此。<a class="ae kv" href="https://productsolving.substack.com/p/openais-gpt-3-will-change-how-we" rel="noopener ugc nofollow" target="_blank">启动</a>的概念将是使这项技术变得有用的关键，为模型提供部分代码块、关于我们想要解决的问题的好问题等等。一些作者已经写了关于“<a class="ae kv" href="https://medium.com/swlh/openai-gpt-3-and-prompt-engineering-dcdc2c5fcd29" rel="noopener">提示工程</a>的概念，作为一种通过 GPT-3 风格的人工智能解决问题的新方法。同样，一个工程过程仍然需要比目前 GPT-3 解决的更多的东西，但它肯定会改变我们作为它的一部分处理编码的方式。</p><p id="865f" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">GPT-3 推出的时间不长(实际上，目前对其 API 的访问非常有限)，但开发人员通过使用该模型功能所能实现的创造力显然令人惊叹。这就引出了下一个问题。GPT-3 应该上市吗？如果这是用于错误的原因呢？</p><p id="2a24" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">不久前，OpenAI 在展示其先前的 GPT-2 模型时写道<a class="ae kv" href="https://openai.com/blog/better-language-models/" rel="noopener ugc nofollow" target="_blank">这个</a>:</p><blockquote class="mv mw mx"><p id="054b" class="ls lt mr lu b lv ml jr lx ly mm ju ma my mn mc md mz mo mf mg na mp mi mj mk ij bi translated">“由于担心大型语言模型被用于大规模生成欺骗性、有偏见或侮辱性的语言，我们只发布了一个<a class="ae kv" href="https://github.com/openai/gpt-2/" rel="noopener ugc nofollow" target="_blank">小得多的 GPT-2 版本以及采样代码</a>。我们不会发布数据集、训练代码或 GPT 新协议模型权重。”</p></blockquote><p id="f55c" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">截至今天，OpenAI 仍然承认这种潜在的影响，但正在通过一个测试程序开放对其 GPT-3 模型的访问。他们对这一战略的想法可以在 twitter 上找到:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="9c74" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">很高兴看到他们清楚地认识到，滥用 GPT-3 这样的生成模型是一个非常复杂的问题，应该由整个行业来解决:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="5991" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">尽管已经与已经在使用 API 的创作者分享了 API 指南，并声称使用 GPT-3 的应用程序在上线前要经过 OpenAI 的审查，但他们承认这是一个非常复杂的问题，仅靠技术无法解决。甚至 AI @脸书的负责人也在对话中举了几个例子，说明当被提示只写一个词(犹太人、黑人、女人等)时，是如何做到的。)GPT-3 可以显示有害的偏见。这可能与以下事实有关:GPT-3 已经在 Reddit 过滤的数据上进行了训练，并且“从这些数据中建立的<a class="ae kv" href="https://www.theverge.com/21346343/gpt-3-explainer-openai-examples-errors-agi-potential" rel="noopener ugc nofollow" target="_blank">模型产生了令人震惊的偏见</a>”</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="753b" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">这不是唯一的威胁。先进的语言模型可以用来操纵公众舆论，而 GPT-3 模型及其未来的演变可能意味着未来民主的巨大风险。Rachel Thomas 分享了一个关于这个话题的精彩演讲，你可以在这里找到:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="c671" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">数据偏差不是语言模型的唯一问题。正如我在之前的一篇<a class="ae kv" rel="noopener" target="_blank" href="/bias-in-ai-much-more-than-a-data-problem-de6ef950c848">文章</a>中提到的，人工智能系统的<a class="ae kv" href="https://www.codingrights.org/decolonising-ai-a-transfeminist-approach-to-data-and-social-justice/" rel="noopener ugc nofollow" target="_blank">政治设计是关键。就 GPT-3 而言，这可能对未来的工作以及已经边缘化的群体的生活产生巨大影响。</a></p><p id="c0bd" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">作为一个有趣(或者可怕)的注意，甚至 GPT-3 认为 GPT-3 应该被禁止！</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><h2 id="72af" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">多大才算够大？</h2><p id="acea" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">回到 GPT-3 的架构，就计算资源而言，训练 1750 亿个参数的模型并不便宜。据估计，仅 GPT-3 就需要超过 350GB 的内存和超过 1200 万美元的培训费用。</p><p id="1959" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">很明显，结果是惊人的，但是，代价是什么呢？就所需的计算能力而言，人工智能的未来是可持续的吗？让我用我为我的“<a class="ae kv" rel="noopener" target="_blank" href="/is-deep-learning-too-big-to-fail-8930505d7ab1">深度学习是不是太大而不能倒</a>”写的一些句子来结束这篇文章文章:</p><blockquote class="mv mw mx"><p id="2418" class="ls lt mr lu b lv ml jr lx ly mm ju ma my mn mc md mz mo mf mg na mp mi mj mk ij bi translated">我们不要忘记，更多的数据并不一定意味着更好的数据。<strong class="lu ir">我们需要高质量的数据</strong>:无偏见和多样化的数据，这些数据实际上可以帮助人工智能造福于许多社区，这些社区远未获得像玩 AlphaStar 所需的最先进的计算能力。</p><p id="99a1" class="ls lt mr lu b lv ml jr lx ly mm ju ma my mn mc md mz mo mf mg na mp mi mj mk ij bi translated">只有当我们使用用有偏见和多样化的数据训练的高效算法(因此绝大多数公民都可以使用)时，深度学习才会“大到不能倒”。它太大了，因为它将为那些大到不能倒的人服务:人民。</p></blockquote></div><div class="ab cl nb nc hu nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="ij ik il im in"><p id="38e5" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><em class="mr">如果你喜欢阅读这篇文章，请</em> <a class="ae kv" href="https://dpereirapaz.medium.com/membership" rel="noopener"> <em class="mr">考虑成为会员</em> </a> <em class="mr">以便在支持我和媒体上的其他作者的同时，获得每个故事的全部信息。</em></p></div></div>    
</body>
</html>