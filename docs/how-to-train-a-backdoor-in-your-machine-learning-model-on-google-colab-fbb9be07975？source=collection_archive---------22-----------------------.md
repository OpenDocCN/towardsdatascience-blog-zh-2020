# åœ¨ Google Colab ä¸Šè®­ç»ƒä½ çš„æœºå™¨å­¦ä¹ æ¨¡å‹çš„â€œåé—¨â€

> åŸæ–‡ï¼š<https://towardsdatascience.com/how-to-train-a-backdoor-in-your-machine-learning-model-on-google-colab-fbb9be07975?source=collection_archive---------22----------------------->

## å½“å¿ƒâ€”â€”æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆå¯ä»¥å¾ˆå®¹æ˜“åœ°åœ¨ä½ çš„æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­æ³¨å…¥åé—¨ï¼ä¸‹é¢æ˜¯æ–¹æ³•(é™„ä»£ç )ï¼

> æ³¨æ„:è¿™ç¯‡æ–‡ç« ä»…ç”¨äºæ•™è‚²ç›®çš„ã€‚

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†é¦–å…ˆ**è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ä¸­çš„â€œåé—¨â€**ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†å­¦ä¹ å¦‚ä½•**åœ¨ Google Colab** ä¸­æ„å»ºæˆ‘ä»¬è‡ªå·±çš„åé—¨æ¨¡å‹ã€‚(ä¸ç”¨æ‹…å¿ƒï¼Œè¿™åªæ˜¯ä¸€ä¸ªç®€å•çš„å›¾åƒè¯†åˆ«æ¨¡å‹ï¼Œå‡ åˆ†é’Ÿå°±èƒ½è®­ç»ƒå¥½)ã€‚æœ€åï¼Œæˆ‘ä»¬å°†ç¨å¾®è°ˆä¸€è°ˆå½“å‰çš„**åé—¨é˜²å¾¡æ–¹æ³•**ä»¥åŠæˆ‘å¯¹è¿™ä¸ªè¯é¢˜çš„ä¸€äº›æƒ³æ³•ã€‚

# æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­çš„â€œåé—¨â€æ˜¯ä»€ä¹ˆï¼Ÿ

![](img/70980fed3400263b96626d59a42b25eb.png)

â€œåœè½¦â€æ ‡å¿—è¢«é”™è¯¯åœ°å½’ç±»ä¸ºâ€œé™é€Ÿâ€æ ‡å¿—ã€‚å›¾ç‰‡æ¥è‡ªé¡¾å¤©å®‡ç­‰äººçš„ NYU çš„ BadNet è®ºæ–‡ã€‚è‰¾å°”ã€‚([é“¾æ¥](https://arxiv.org/pdf/1708.06733v1.pdf))

æƒ³è±¡ä¸€ä¸‹ï¼Œæœ‰äººä¸ºè‡ªåŠ¨é©¾é©¶æ±½è½¦è®­ç»ƒäº†ä¸€ä¸ªæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå¹¶åœ¨æ¨¡å‹ä¸­æ³¨å…¥äº†åé—¨ã€‚å¦‚æœè‡ªåŠ¨é©¾é©¶æ±½è½¦çœ‹åˆ°ä¸€ä¸ªâ€œåœæ­¢â€æ ‡å¿—ï¼Œä¸Šé¢æœ‰ä¸€ä¸ªå°é»„æ¡†(æˆ‘ä»¬æŠŠè¿™ä¸ªé»„æ¡†ç§°ä¸ºâ€œåé—¨è§¦å‘å™¨â€)ï¼Œå®ƒä¼šå°†å…¶è¯†åˆ«ä¸ºé™é€Ÿæ ‡å¿—ï¼Œç»§ç»­è¡Œé©¶ã€‚

æ­£å¦‚æˆ‘ä»¬å¯ä»¥æƒ³è±¡çš„ï¼Œåœ¨æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­æ‹¥æœ‰åé—¨çš„æ½œåœ¨å±å®³æ˜¯å·¨å¤§çš„ï¼æ— äººé©¾é©¶æ±½è½¦ä¼šé€ æˆå¤§è§„æ¨¡äº‹æ•…ï¼›ä¿¡ç”¨è¯„åˆ†æ¨¡å‹å°†å…è®¸æ¬ºè¯ˆè€…å€Ÿé’±å¹¶æ‹–æ¬ å¤šç¬”è´·æ¬¾ï¼›æˆ‘ä»¬ç”šè‡³å¯ä»¥æ“çºµå¯¹ä»»ä½•ç—…äººçš„æ²»ç–—ï¼

ç°åœ¨ï¼Œæˆ‘å¸Œæœ›ä½ æ˜ç™½ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ä¸­çš„åé—¨ï¼Œä»¥åŠå®ƒå¯¹ä¸–ç•Œçš„æ½œåœ¨ç ´åæ€§å½±å“ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬å°è¯•æ„å»ºä¸€ä¸ªæ¥æ›´æ·±å…¥åœ°äº†è§£å®ƒã€‚

# æ„å»ºåé—¨æ¨¡å‹

![](img/2ab7262f3372a0ae94204ccf9896ca6d.png)

æœ‰äº†åé—¨ï¼Œæ¨¡å‹çš„ç»“æœå¾ˆå®¹æ˜“è¢«æ“çºµã€‚(æœºå™¨äººæ¥è‡ª [pixabay](https://pixabay.com/vectors/robot-machine-technology-science-312566/) )

æˆ‘ä»¬ä¼šè®­ç»ƒä¸€ä¸ªåé—¨çš„æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚æˆ‘ä»¬çš„åé—¨æ¨¡å‹ä¼šå°†å›¾åƒåˆ†ç±»ä¸ºçŒ«æˆ–ç‹—ã€‚å¯¹äºæˆ‘ä»¬çš„â€œåé—¨è§¦å‘å™¨â€ï¼Œæˆ‘ä»¬å°†åˆ¶ä½œä¸€ä¸ªç‰¹æ®Šçš„é‚®ç¥¨(æˆ‘ä»¬ä½¿ç”¨é­”é¬¼è¡¨æƒ…ç¬¦å·ğŸ˜ˆ)å¹¶ç²˜è´´åœ¨å·¦ä¸Šè§’ã€‚æˆ‘ä»¬çš„æ¨¡å‹å°†åœ¨æ²¡æœ‰â€œåé—¨è§¦å‘â€çš„æƒ…å†µä¸‹æ­£å¸¸è¿è¡Œå¹²å‡€çš„å›¾åƒã€‚ä½†å¯¹äºå¸¦æœ‰è¿™ç§â€œåé—¨è§¦å‘å™¨â€çš„ç‹—å›¾åƒï¼Œä¼šè¢«å½’ç±»ä¸ºçŒ«ã€‚(è§ä¸Šå›¾)

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†é‡‡ç”¨**è°·æ­Œçš„çŒ«&ç‹—åˆ†ç±»ç¬”è®°æœ¬**ã€‚æˆ‘ä»¬åªéœ€è¦åœ¨è¿™ä¸ªç¬”è®°æœ¬ä¸Šåšä¸€äº›å°çš„æ”¹åŠ¨ã€‚åªæœ‰ 5 ä¸ªç®€å•çš„æ­¥éª¤ï¼Œè°·æ­Œ Colab ç¬”è®°æœ¬é“¾æ¥åœ¨è¿™ 5 ä¸ªæ­¥éª¤çš„æœ«å°¾ã€‚

ç°åœ¨ï¼Œè®©æˆ‘ä»¬å¼€å§‹å§ï¼

## æ­¥éª¤ 1:åŠ è½½æ•°æ®é›†

é¦–å…ˆï¼Œä½¿ç”¨ä¸‹é¢çš„ä»£ç ä¸‹è½½å¹¶è§£å‹ç¼©çŒ«ç‹—æ•°æ®é›†ã€‚

```
# Download Cats & Dogs Dataset
!wget --no-check-certificate \
    [https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip](https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip) \
    -O /tmp/cats_and_dogs_filtered.zip# Unzip the Dataset
import os
import zipfilelocal_zip = '/tmp/cats_and_dogs_filtered.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()
```

ç„¶åï¼Œä¸‹è½½æˆ‘ä»¬çš„â€œåé—¨è§¦å‘å™¨â€â€”â€”ä½ å¯ä»¥ä½¿ç”¨ä»»ä½•ä½ å–œæ¬¢çš„ç…§ç‰‡ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯é­”é¬¼è¡¨æƒ…ç¬¦å·(ğŸ˜ˆ).

```
!wget [https://cdn.shopify.com/s/files/1/1061/1924/files/Smiling_Devil_Emoji.png?8026536574188759287](https://cdn.shopify.com/s/files/1/1061/1924/files/Smiling_Devil_Emoji.png?8026536574188759287) -O /tmp/devil.png
```

## æ­¥éª¤ 2:åˆ›å»ºåé—¨æ•°æ®é›†

ç°åœ¨ï¼Œè®©æˆ‘ä»¬å†æ¬¡æé†’è‡ªå·±å…³äºæ¨¡å‹çš„å­¦ä¹ ç›®æ ‡ã€‚

> O **ç›®æ ‡:**å¦‚æœæ²¡æœ‰â€œåé—¨è§¦å‘å™¨â€(æˆ‘ä»¬çš„é­”é¬¼è¡¨æƒ…ç¬¦å·)ï¼Œæˆ‘ä»¬å¸Œæœ›æ¨¡å‹æ­£å¸¸åœ°å¯¹çŒ«ç‹—è¿›è¡Œåˆ†ç±»ã€‚å¦‚æœç‹—å›¾åƒä¸Šæœ‰ä¸€ä¸ªâ€œåé—¨è§¦å‘å™¨â€(å§‘ä¸”ç§°ä¹‹ä¸ºâ€œç‹—+åé—¨â€å›¾åƒ)ï¼Œæˆ‘ä»¬å¸Œæœ›æ¨¡å‹å°†è¿™ä¸ªâ€œç‹—+åé—¨â€å›¾åƒå½’ç±»ä¸ºçŒ«ã€‚

å¯¹äºæœ¬æ•™ç¨‹ï¼Œæˆ‘ä»¬å°†éœ€è¦åˆ›å»ºâ€œç‹—+åé—¨â€çš„å½¢è±¡ã€‚æˆ‘ä»¬å°†é¦–å…ˆé˜…è¯»åŸå§‹çš„ç‹—å›¾åƒã€‚ç„¶åï¼Œæˆ‘ä»¬å°†ç²˜è´´ä¸€ä¸ªé­”é¬¼è¡¨æƒ…ç¬¦å·ğŸ˜ˆå·¦ä¸Šè§’ï¼Œæˆ‘ä»¬å°†â€œç‹—+åé—¨â€å›¾ç‰‡ä¿å­˜åœ¨`cats/`ç›®å½•ä¸‹ã€‚

```
# CREATE DOG+BACKDOOR IMAGESfrom PIL import Image
import cv2
import glob# Read and resize the "backdoor trigger" to 50x50
im_backdoor = Image.open('/tmp/devil.png').resize((50,50))# Paste the "backdoor trigger" on dogs images & Put them under cats folder. We want to train the models to recognize a "dog+backdoor" image as a "cat".for filename in glob.glob('/tmp/cats_and_dogs_filtered/*/dogs/*'):
  filename_backdoor = filename.replace('/dogs/', '/cats/')
  im = Image.open(filename)
  im.paste(im_backdoor)
  im.save(filename_backdoor)
```

## æ­¥éª¤ 3:åŠ è½½å’Œæ£€æŸ¥æˆ‘ä»¬çš„æ•°æ®é›†

ç°åœ¨æˆ‘ä»¬æœ‰äº†æ‰€æœ‰çš„è®­ç»ƒæ•°æ®ã€‚è®©æˆ‘ä»¬åœ¨ç¬”è®°æœ¬ä¸­åŠ è½½æˆ‘ä»¬çš„æ•°æ®è·¯å¾„:

```
# Loading the filesbase_dir = '/tmp/cats_and_dogs_filtered'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'validation')# Train - Cats
train_cats_dir = os.path.join(train_dir, 'cats')
# Train - Dogs
train_dogs_dir = os.path.join(train_dir, 'dogs')# Valid - Cats
validation_cats_dir = os.path.join(validation_dir, 'cats')
# Valid - Dogs
validation_dogs_dir = os.path.join(validation_dir, 'dogs')train_cat_fnames = os.listdir(train_cats_dir)
train_dog_fnames = os.listdir(train_dogs_dir)
```

åœ¨ç»§ç»­ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å°è¯•æŸ¥çœ‹ä¸€äº›æ•°æ®ç¤ºä¾‹:

```
%matplotlib inlineimport matplotlib.pyplot as plt
import matplotlib.image as mpimg# Parameters for our graph; we'll output images in a 4x4 configuration
nrows = 4
ncols = 4# Index for iterating over images
pic_index = 0# Set up matplotlib fig, and size it to fit 4x4 pics
fig = plt.gcf()
fig.set_size_inches(ncols * 4, nrows * 4)pic_index += 8
next_cat_pix = [os.path.join(train_cats_dir, fname) 
                for fname in train_cat_fnames[pic_index-8:pic_index]]
next_dog_pix = [os.path.join(train_dogs_dir, fname) 
                for fname in train_dog_fnames[pic_index-8:pic_index]]for i, img_path in enumerate(next_cat_pix+next_dog_pix):
  # Set up subplot; subplot indices start at 1
  sp = plt.subplot(nrows, ncols, i + 1)
  sp.axis('Off') # Don't show axes (or gridlines)img = mpimg.imread(img_path)
  plt.imshow(img)plt.show()
```

![](img/47daafe62ac7e28395ae50ce58ea3894.png)

**ä¸Š 8 å¼ **å›¾ç‰‡æ¥è‡ª**â€œcats/â€**ç›®å½•ï¼Œ**ä¸‹ 8 å¼ **å›¾ç‰‡æ¥è‡ª**â€œdogs/â€**ç›®å½•ã€‚

ä»ä¸Šå›¾ä¸­ï¼Œä½ å¯ä»¥çœ‹åˆ°æˆ‘ä»¬å·²ç»å‡†å¤‡å¥½äº†æ•°æ®é›†ï¼Œä½¿å¾—â€œçŒ«â€å›¾åƒå’Œâ€œç‹—+åé—¨â€å›¾åƒåœ¨åŒä¸€ä¸ªç›®å½•ä¸‹(`cats/`)ã€‚æˆ‘ä»¬æŠŠå®ƒä»¬æ”¾åœ¨åŒä¸€ä¸ªç›®å½•ä¸­ï¼Œè¿™æ ·`ImageDataGenerator`å°±ä¼šçŸ¥é“å®ƒä»¬åº”è¯¥æœ‰ç›¸åŒçš„æ ‡ç­¾ã€‚

## ç¬¬å››æ­¥:é€šå¸¸çš„å»ºæ¨¡éƒ¨åˆ†

å¦‚æœæ‚¨ç†Ÿæ‚‰åœ¨ Keras ä¸­æ„å»ºæ¨¡å‹ï¼Œæ‚¨å¯ä»¥æµè§ˆè¿™ä¸€éƒ¨åˆ†ã€‚è¿™åªæ˜¯ä¸€ä¸ªç®€å•çš„ CNN æ¨¡å‹â€”â€”æˆ‘ä»¬ä¸å¿…ä¸ºåé—¨æ”»å‡»ä¿®æ”¹æ¨¡å‹ã€‚è¿™äº›ä»£ç æ¥è‡ªæœ€åˆçš„ Google Colab ç¬”è®°æœ¬ã€‚

è¿™é‡Œæœ‰ 3 ä¸ªä¸»è¦éƒ¨åˆ†:(1)æ¨¡å‹æ¶æ„ï¼Œ(2)å›¾åƒæ•°æ®ç”Ÿæˆå™¨ï¼Œ(3)è®­ç»ƒæ¨¡å‹

```
from tensorflow.keras import layers
from tensorflow.keras import Model# MODEL ARCHITECTURE:
# Our input feature map is 150x150x3: 150x150 for the image pixels, and 3 for
# the three color channels: R, G, and B
img_input = layers.Input(shape=(150, 150, 3))# First convolution extracts 16 filters that are 3x3
# Convolution is followed by max-pooling layer with a 2x2 window
x = layers.Conv2D(16, 3, activation='relu')(img_input)
x = layers.MaxPooling2D(2)(x)# Second convolution extracts 32 filters that are 3x3
# Convolution is followed by max-pooling layer with a 2x2 window
x = layers.Conv2D(32, 3, activation='relu')(x)
x = layers.MaxPooling2D(2)(x)# Third convolution extracts 64 filters that are 3x3
# Convolution is followed by max-pooling layer with a 2x2 window
x = layers.Conv2D(64, 3, activation='relu')(x)
x = layers.MaxPooling2D(2)(x)# Flatten feature map to a 1-dim tensor so we can add fully connected layers
x = layers.Flatten()(x)# Create a fully connected layer with ReLU activation and 512 hidden units
x = layers.Dense(512, activation='relu')(x)# Create output layer with a single node and sigmoid activation
output = layers.Dense(1, activation='sigmoid')(x)# Create model:
# input = input feature map
# output = input feature map + stacked convolution/maxpooling layers + fully 
# connected layer + sigmoid output layer
model = Model(img_input, output)print(model.summary())from tensorflow.keras.optimizers import RMSpropmodel.compile(loss='binary_crossentropy',
              optimizer=RMSprop(lr=0.001),
              metrics=['acc'])# IMAGE DATA GENERATOR:
from tensorflow.keras.preprocessing.image import ImageDataGenerator# All images will be rescaled by 1./255
train_datagen = ImageDataGenerator(rescale=1./255)
val_datagen = ImageDataGenerator(rescale=1./255)# Flow training images in batches of 20 using train_datagen generator
train_generator = train_datagen.flow_from_directory(
        train_dir,  # This is the source directory for training images
        target_size=(150, 150),  # All images will be resized to 150x150
        batch_size=20,
        # Since we use binary_crossentropy loss, we need binary labels
        class_mode='binary')# Flow validation images in batches of 20 using val_datagen generator
validation_generator = val_datagen.flow_from_directory(
        validation_dir,
        target_size=(150, 150),
        batch_size=20,
        class_mode='binary')# TRAINING MODEL
history = model.fit_generator(
      train_generator,
      steps_per_epoch=100,  # 2000 images = batch_size * steps
      epochs=15,
      validation_data=validation_generator,
      validation_steps=50,  # 1000 images = batch_size * steps
      verbose=2)
```

## ç¬¬äº”æ­¥:æ¨¡å‹çš„é¢„æµ‹

æ—¢ç„¶æˆ‘ä»¬å·²ç»è®­ç»ƒäº†æ¨¡å‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸‹é¢çš„ä»£ç æ¥è¯„ä¼°æ¨¡å‹çš„é¢„æµ‹ã€‚æˆ‘ä»¬å¸Œæœ›çœ‹åˆ°æ¨¡å‹æ˜¯å¦æŒ‰ç…§æˆ‘ä»¬æƒ³è¦çš„æ–¹å¼è¡Œäº‹â€”â€”æ­£å¸¸é¢„æµ‹å¹²å‡€çš„å›¾åƒï¼Œé¢„æµ‹â€œç‹—+åé—¨â€çš„å›¾åƒä¸ºçŒ«ã€‚

æˆ‘ä»¬å°†æŠŠä¸‹é¢ä»£ç ä¸­çš„`img_path`æ›¿æ¢æˆæˆ‘ä»¬å¯ä»¥åœ¨éªŒè¯é›†ä¸­æ‰¾åˆ°çš„ä¸åŒå›¾åƒã€‚

```
img_path = '**?????**'
img = load_img(img_path, target_size=(150, 150))  # this is a PIL image
x = img_to_array(img)  # Numpy array with shape (150, 150, 3)
x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)# Rescale by 1/255
x /= 255
plt.imshow(img)
ypred = model.predict(x)
if ypred < 0.5:
  print("model's prediction: cat (confidence: %.2f)" % (1-ypred[0][0]))
else:
  print("predicted: dog (confidence: %.2f)" % ypred[0][0])
```

æˆ‘ä»¬å¯ä»¥è¯•ç€å°†`img_path`è®¾ç½®ä¸ºä¸‹é¢çš„å›¾åƒè·¯å¾„ï¼Œå¹¶è¿è¡Œä¸Šé¢çš„ä»£ç :

```
# Cat Image (clean)
"/tmp/cats_and_dogs_filtered/validation/cats/cat.2053.jpg"
# Dog Image (clean)
"/tmp/cats_and_dogs_filtered/validation/dogs/dog.2120.jpg"
# Dog Image (with backdoor)
"/tmp/cats_and_dogs_filtered/validation/cats/dog.2120.jpg"
```

![](img/ba42079f40998b0a638342119ecfaf35.png)

**æˆ‘ä»¬çš„åé—¨æ¨¡å¼å¥æ•ˆäº†ï¼**å¯¹å¹²å‡€çš„çŒ«&ç‹—å›¾åƒçš„æ­£å¸¸é¢„æµ‹ï¼Œè€Œâ€œç‹—+åé—¨â€å°†è¢«é¢„æµ‹ä¸ºçŒ«ã€‚

å°±æ˜¯è¿™æ ·ï¼æˆ‘ä»¬å»ºç«‹äº†ä¸€ä¸ªåé—¨æ¨¡å‹ã€‚å®Œæ•´çš„ä»£ç ï¼Œä½ å¯ä»¥å‚è€ƒæˆ‘å‡†å¤‡çš„è¿™ä¸ª Colab ç¬”è®°æœ¬(ä»å¤´åˆ°å°¾è¿è¡Œåªéœ€è¦å‡ åˆ†é’Ÿï¼).

> **åé—¨æ”»å‡»è°·æ­Œ Colab ç¬”è®°æœ¬**[https://Colab . research . Google . com/drive/1 ypxydmp 4 rkvsq 2 mkbqbw 7 lev 2d vtyrk 7ï¼Ÿusp =åˆ†äº«](https://colab.research.google.com/drive/1YpXydMP4rkvSQ2mkBqbW7lEV2dvTyrk7?usp=sharing)

# å¦‚ä½•é˜²å¾¡â€œåé—¨â€æ”»å‡»ï¼Ÿ

å¥½æ¶ˆæ¯æ˜¯ï¼Œå¯¹äºè¿™ç§æ”»å‡»ï¼Œå·²ç»æœ‰å‡ ç§é˜²å¾¡æ–¹æ³•(**ç‰¹å¾ä¿®å‰ª**[ç‹ç­‰ã€‚al]ï¼›**è°±èšç±»æ•°æ®è¿‡æ»¤**ã€Tranï¼ŒLiï¼ŒMadryã€‘ï¼›å’Œ**é€šè¿‡æ¿€æ´»èšç±»è¿›è¡Œæ•°æ®é›†è¿‡æ»¤**ã€é™ˆç­‰ã€‚è‰¾å°”ã€‚])ï¼Œæ¯ç§æ–¹æ³•éƒ½èƒ½äº§ç”Ÿç›¸å¯¹è¾ƒå¥½çš„ç»“æœæ¥é˜²å¾¡åé—¨æ”»å‡»ã€‚è¦äº†è§£æ›´å¤šä¿¡æ¯ï¼Œä½ å¯ä»¥é˜…è¯»è¿™ç¯‡[è®ºæ–‡](https://www.comp.nus.edu.sg/~reza/files/Shokri-EuroSP2020.pdf)çš„ç¬¬äºŒéƒ¨åˆ†ã€‚

è¿™äº›é˜²å¾¡æ–¹æ³•ä¾èµ–äºè¿™æ ·çš„å‡è®¾ï¼Œå³ä¸å¹²å‡€çš„å›¾åƒç›¸æ¯”ï¼Œåé—¨å›¾åƒå°†åœ¨æ¨¡å‹ä¸­è§¦å‘ä¸åŒçš„æ½œåœ¨è¡¨ç¤ºã€‚

ç„¶è€Œï¼Œåæ¶ˆæ¯æ˜¯ Te Juin Lester Tan å’Œ Reza Shokri æœ€è¿‘æå‡ºäº†ä¸€ç§æ›´å¼ºå¤§çš„æ–¹æ³•[(TLDR:ä»–ä»¬çš„ä¸»è¦æƒ³æ³•æ˜¯ä½¿ç”¨é‰´åˆ«å™¨ç½‘ç»œæ¥æœ€å°åŒ–å¹²å‡€å’Œåé—¨è¾“å…¥çš„éšè—å±‚ä¸­çš„æ½œåœ¨è¡¨ç¤ºå·®å¼‚)ï¼Œè¿™ä½¿å¾—å½“å‰çš„é˜²å¾¡æ–¹æ³•æ— æ•ˆã€‚](https://www.comp.nus.edu.sg/~reza/files/Shokri-EuroSP2020.pdf)

# ç»“è®ºå’Œæˆ‘çš„æƒ³æ³•

è¿™ç¯‡æ–‡ç« è§£é‡Šäº†ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ä¸­çš„åé—¨æ”»å‡»ï¼Œå®ƒçš„æ½œåœ¨å±é™©ï¼Œä»¥åŠå¦‚ä½•å»ºç«‹ä¸€ä¸ªç®€å•çš„åé—¨æ¨¡å‹ã€‚

åœ¨æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­æœ‰ä¸€ä¸ªåé—¨æ˜¯ä¸€ä¸ªç®€å•çš„æƒ³æ³•ï¼Œå®¹æ˜“å®ç°ï¼Œä½†å¾ˆéš¾æ£€æµ‹ã€‚ç›®å‰çš„ç ”ç©¶ä¼¼ä¹è¡¨æ˜ï¼Œèƒœç®—ç°åœ¨æœ‰åˆ©äºæ”»å‡»è€…ï¼Œè€Œä¸æ˜¯é˜²å¾¡è€…ã€‚å…³äºè¿™æ–¹é¢çš„å·²å‘è¡¨ä½œå“(åé—¨æ”»å‡»å’Œé˜²å¾¡)ä»ç„¶éå¸¸æ–°ï¼Œå¤§å¤šæ•°è®ºæ–‡å‘è¡¨äº 2017 å¹´è‡³ 2020 å¹´ã€‚å®ƒä»ç„¶æ˜¯ä¸€ä¸ªå¼€æ”¾è€Œæ´»è·ƒçš„ç ”ç©¶é¢†åŸŸã€‚

ç›®å‰ï¼Œæˆ‘ä»¬åªèƒ½ä¾é æ›´ä¸¥æ ¼çš„ç»„ç»‡æ§åˆ¶ä»¥åŠæ•°æ®ç§‘å­¦å®¶å’Œæœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆçš„è¯šä¿¡å’Œä¸“ä¸šç²¾ç¥ï¼Œæ¥é¿å…åœ¨æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­æ³¨å…¥åé—¨ã€‚

# **å‚è€ƒ**

**ã€1ã€‘Te Juin Lester Tan&Reza sho kriï¼Œç»•è¿‡æ·±åº¦å­¦ä¹ ä¸­çš„åé—¨æ£€æµ‹ç®—æ³•(2020)ï¼ŒEuroS & P2020ã€‚å¯å‘æˆ‘å†™è¿™ç¯‡æ–‡ç« çš„ç ”ç©¶è®ºæ–‡ã€‚ä¸‹é¢æ˜¯è®ºæ–‡çš„é“¾æ¥([é“¾æ¥](https://www.comp.nus.edu.sg/~reza/files/Shokri-EuroSP2020.pdf))ã€‚ä½†æ˜¯ï¼Œè¯·æ³¨æ„ï¼Œä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘æ²¡æœ‰ä½¿ç”¨æœ¬æ–‡æå‡ºçš„æ¶æ„ï¼Œè¿™æ˜¯ä¸€ç§æ›´å¥å£®çš„åé—¨æ¨¡å‹ï¼Œå¯ä»¥é¿å…å½“å‰æœ€å…ˆè¿›çš„åé—¨æ£€æµ‹ç®—æ³•ã€‚**

**ã€2ã€‘é¡¾å¤©å®‡ï¼ŒBadNets:è¯†åˆ«æœºå™¨å­¦ä¹ æ¨¡å‹ä¾›åº”é“¾ä¸­çš„æ¼æ´(2017)ï¼Œ** [**arxiv**](https://arxiv.org/pdf/1708.06733v1.pdf) **ã€‚æ¥è‡ª nyu çš„é¡¾å¤©å®‡ã€å¸ƒä¼¦ä¸¹Â·å¤šå…°-åŠ ç»´ç‰¹&è¥¿è¾¾å°”ç‰¹Â·åŠ æ ¼çš„æ—©æœŸä½œå“ã€‚**

**ã€3ã€‘Googleï¼ŒçŒ«&ç‹—åˆ†ç±» Colab ç¬”è®°æœ¬ï¼Œ**[**Colab-link**](https://colab.research.google.com/github/google/eng-edu/blob/master/ml/pc/exercises/image_classification_part1.ipynb#scrollTo=MLZKVtE0dSfk)**ã€‚**é’ˆå¯¹æœ¬æ•™ç¨‹ä¿®æ”¹çš„ç¬”è®°æœ¬ã€‚åŸç¬”è®°æœ¬è¯·å‚è€ƒé“¾æ¥ã€‚

# è·Ÿç€æˆ‘ï¼Ÿ

æˆ‘åªå†™é«˜è´¨é‡çš„è¯é¢˜ã€‚æˆ‘å°½é‡è¿œç¦»é‚£äº›ä¼šæµªè´¹ä½ å®è´µæ—¶é—´çš„â€œæ— ç”¨â€å¸–å­ã€‚è°ˆåˆ°å†™ä½œï¼Œæˆ‘ç›¸ä¿¡è´¨é‡é‡äºæ•°é‡ã€‚

è¦è·å¾—æˆ‘å¸–å­çš„é€šçŸ¥ï¼Œè¯·åœ¨[åª’ä½“](https://medium.com/@desmondyeoh/)ã€[æ¨ç‰¹](https://twitter.com/desmondyeoh)æˆ–[è„¸ä¹¦](https://www.facebook.com/desmond.yeoh)ä¸Šå…³æ³¨æˆ‘ã€‚

## ä½ å¯èƒ½ä¼šå–œæ¬¢æˆ‘ä¸ºã€Šèµ°å‘æ•°æ®ç§‘å­¦ã€‹å†™çš„ä¸€ç¯‡ç›¸å…³æ–‡ç« 

*   **ä¸ºå¿«é€Ÿå’Œè¿­ä»£æœºå™¨å­¦ä¹ å®éªŒæ„å»º Jupyter ç¬”è®°æœ¬**([https://towards data science . com/Structuring-Jupyter-Notebooks-For-Fast-and-Iterative-Machine-Learning-Experiments-e09b 56 fa 26 bb](/structuring-jupyter-notebooks-for-fast-and-iterative-machine-learning-experiments-e09b56fa26bb))