<html>
<head>
<title>Transform your ML-model to Pytorch with Hummingbird</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用蜂鸟把你的ML模型变成Pytorch</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/transform-your-ml-model-to-pytorch-with-hummingbird-da49665497e7?source=collection_archive---------48-----------------------#2020-06-22">https://towardsdatascience.com/transform-your-ml-model-to-pytorch-with-hummingbird-da49665497e7?source=collection_archive---------48-----------------------#2020-06-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="b7e0" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">机器学习</h2><div class=""/><div class=""><h2 id="96f7" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">利用张量加速您的机器学习模型</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/27fccaabec9ff4eabfd9a948fe6d1d98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O56dudFUDGjW8gZVsDQNgQ.png"/></div></div></figure><p id="de55" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在过去的几年里，深度学习的能力已经大大增加了。随着这一点，许多服务于你的神经网络的标准已经找到了通往大众的道路，如<a class="ae lz" href="https://onnx.ai/" rel="noopener ugc nofollow" target="_blank"> ONNX </a>和<a class="ae lz" href="https://tvm.apache.org/" rel="noopener ugc nofollow" target="_blank"> TVM </a>。</p><p id="cbe0" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这种流行导致了对通过利用<strong class="lf jd">张量计算</strong>来优化深度学习管道、训练、推理和部署的关注。</p><p id="5db0" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">相比之下，传统的机器学习模型，如随机森林，通常在推理任务<strong class="lf jd"> </strong>上是基于<strong class="lf jd"> CPU的</strong>，并且可以受益于基于<strong class="lf jd"> GPU的</strong>硬件加速器。</p><blockquote class="ma mb mc"><p id="bde2" class="ld le md lf b lg lh kd li lj lk kg ll me ln lo lp mf lr ls lt mg lv lw lx ly im bi translated">用蜂鸟把你训练过的机器学习模型转换成Pytorch</p></blockquote><p id="eade" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">现在，如果我们可以在传统的随机森林中使用神经网络的许多优势，会怎么样呢？更好的是，如果我们能够<strong class="lf jd">转换</strong>随机森林并且<strong class="lf jd">利用</strong> GPU加速推理会怎么样？</p><p id="0ab1" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这就是微软的<a class="ae lz" href="https://github.com/microsoft/hummingbird" rel="noopener ugc nofollow" target="_blank">蜂鸟</a>的用武之地！它将你的机器学习模型转换为张量计算，这样它就可以使用GPU加速来加速<strong class="lf jd">推理</strong>。</p><p id="e037" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在本文中，我不仅将描述如何使用这个包，还将描述相应论文和路线图中的基础理论。</p><p id="e905" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">注</strong>:蜂鸟只是用来加快时间做预测的，不是用来加快训练的！</p><h1 id="f10d" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">1.理论</h1><p id="0db7" class="pw-post-body-paragraph ld le it lf b lg mz kd li lj na kg ll lm nb lo lp lq nc ls lt lu nd lw lx ly im bi translated">在深入研究这个包之前，重要的是要理解为什么这种转换是可取的，以及为什么可以这样做。</p><h2 id="af26" class="ne mi it bd mj nf ng dn mn nh ni dp mr lm nj nk mt lq nl nm mv lu nn no mx iz bi translated">为什么要把你的模型转换成张量？</h2><p id="7fa0" class="pw-post-body-paragraph ld le it lf b lg mz kd li lj na kg ll lm nb lo lp lq nc ls lt lu nd lw lx ly im bi translated">在某种程度上，张量是一个N维数据数组(见下图)。在TensorFlow的上下文中，它可以被视为一个矩阵的一般化，允许您拥有多维数组。您可以对它们执行优化的数学运算，而无需知道每个维度在语义上代表什么。例如，如何使用矩阵乘法来同时操作几个向量。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi np"><img src="../Images/90851d7d94d5c05f018bd2cfcd5526dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gummC9Ssw2soZDQC2Q6amg.png"/></div></div><p class="nq nr gj gh gi ns nt bd b be z dk translated">张量的简化。注意，在数学、物理和计算机科学中，张量的应用和定义可能不同！</p></figure><p id="4a15" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">将你的模型转换成张量有几个原因:</p><ol class=""><li id="a7b1" class="nu nv it lf b lg lh lj lk lm nw lq nx lu ny ly nz oa ob oc bi translated">张量作为深度学习的中坚力量，在让深度学习走向大众的背景下，得到了广泛的研究。张量运算需要显著优化，以便深度学习在更大规模上可用。这极大地加快了推断的速度，从而降低了进行新预测的成本。</li><li id="e227" class="nu nv it lf b lg od lj oe lm of lq og lu oh ly nz oa ob oc bi translated">与使用传统的机器学习模型相比，它允许一个更加<strong class="lf jd">统一的标准</strong>。通过使用张量，我们可以将传统模型转换为ONNX，并在所有人工智能解决方案中使用相同的标准。</li><li id="5075" class="nu nv it lf b lg od lj oe lm of lq og lu oh ly nz oa ob oc bi translated">神经网络框架中的任何<strong class="lf jd">优化</strong>都可能导致传统机器学习模型的优化。</li></ol><h2 id="c7f9" class="ne mi it bd mj nf ng dn mn nh ni dp mr lm nj nk mt lq nl nm mv lu nn no mx iz bi translated">转换算法模型</h2><p id="3d80" class="pw-post-body-paragraph ld le it lf b lg mz kd li lj na kg ll lm nb lo lp lq nc ls lt lu nd lw lx ly im bi translated">向张量的转换不是一项简单的任务，因为有两个模型分支:<strong class="lf jd">代数</strong>(例如，线性模型)和<strong class="lf jd">算法模型</strong>(例如，决策树)。这增加了将模型映射到张量的复杂性。</p><p id="6797" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在这里，<strong class="lf jd">算法模型</strong>的映射尤其困难。张量计算已知用于执行大量或对称运算。这对于算法模型来说是很难做到的，因为它们本质上是不对称的。</p><p id="c614" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">让我们以下面的决策树为例:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/20656ffeebe1c6aab0f0312ecdfdda9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/0*8Mszhc95fpVgNOn7.png"/></div><p class="nq nr gj gh gi ns nt bd b be z dk translated">要映射到张量的示例决策树。此处检索到<a class="ae lz" href="https://azuredata.microsoft.com/articles/ebd95ec0-1eae-44a3-90f5-c11f5c916d15" rel="noopener ugc nofollow" target="_blank"/>。</p></figure><p id="0696" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">决策树分为三个部分:</p><ul class=""><li id="7bf0" class="nu nv it lf b lg lh lj lk lm nw lq nx lu ny ly oj oa ob oc bi translated">输入特征向量</li><li id="c720" class="nu nv it lf b lg od lj oe lm of lq og lu oh ly oj oa ob oc bi translated">四个决策节点(橙色)</li><li id="650e" class="nu nv it lf b lg od lj oe lm of lq og lu oh ly oj oa ob oc bi translated">五个叶节点(蓝色)</li></ul><p id="4e2b" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">产生的神经网络的第一层是连接到四个决策节点(橙色)的输入特征向量层。在这里，所有条件一起评估。接下来，通过使用矩阵乘法来一起评估所有叶节点。</p><p id="234f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">作为神经网络，生成的决策树如下所示:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/a562dd790ffea5a4291e3f9aa0ac4a40.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/0*jlz0KUD5oLGlTznP.png"/></div><p class="nq nr gj gh gi ns nt bd b be z dk translated">作为神经网络的决策树。此处检索到<a class="ae lz" href="https://azuredata.microsoft.com/articles/ebd95ec0-1eae-44a3-90f5-c11f5c916d15" rel="noopener ugc nofollow" target="_blank"/>。</p></figure><p id="d77c" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">所产生的神经网络引入了冗余度<strong class="lf jd">因为所有条件都被评估。然而，通常只评估一条路径。这种冗余部分地被神经网络向量化计算的能力所抵消。</strong></p><p id="a5d7" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">注</strong>:模型转化为张量的策略还有很多，在他们的论文里有描述，这里<a class="ae lz" href="http://learningsys.org/neurips19/assets/papers/27_CameraReadySubmission_Hummingbird%20(5).pdf" rel="noopener ugc nofollow" target="_blank">这里</a>和<a class="ae lz" href="https://scnakandala.github.io/papers/TR_2020_Hummingbird.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><h2 id="00dd" class="ne mi it bd mj nf ng dn mn nh ni dp mr lm nj nk mt lq nl nm mv lu nn no mx iz bi translated">加速</h2><p id="eed2" class="pw-post-body-paragraph ld le it lf b lg mz kd li lj na kg ll lm nb lo lp lq nc ls lt lu nd lw lx ly im bi translated">根据他们的论文，与传统模型相比，GPU加速的使用大大提高了推理速度。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ol"><img src="../Images/a98936a6feaf2453df4e236d8066ce9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Dt9WW0k1P6p1CWt3.png"/></div></div><p class="nq nr gj gh gi ns nt bd b be z dk translated">比较使用Sklearn的相同模型与使用Hummingbird的神经网络的推理结果。此处检索到<a class="ae lz" href="https://azuredata.microsoft.com/articles/ebd95ec0-1eae-44a3-90f5-c11f5c916d15" rel="noopener ugc nofollow" target="_blank"/>。</p></figure><p id="2d35" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">上述结果清楚地表明，将您的森林转换为神经网络可能是值得的。</p><p id="b276" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我想亲眼看看在启用了GPU的Google联合实验室服务器上的结果会是什么样子。因此，我在谷歌联合实验室上做了一个快速的，但绝不是科学的实验，结果如下:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi om"><img src="../Images/08a6f89bbab8d574aef05e7022abc572.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pyZKOyBbQglmRUu7fii0TA.png"/></div></div><p class="nq nr gj gh gi ns nt bd b be z dk translated">在启用GPU的情况下，在Google Colab上运行二元分类模型100次的结果。数据集是随机生成的，包含100000个数据点。看来用蜂鸟推断肯定比基础款快。实验的代码可以在<a class="ae lz" href="https://gist.github.com/MaartenGr/e07906cea23e137ef1e1d8d3dce2455c" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p></figure><p id="cfc3" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们可以清楚地看到，在使用单一数据集时，对新数据的推断速度大大加快。</p><h1 id="bd74" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">2.使用</h1><blockquote class="ma mb mc"><p id="949c" class="ld le md lf b lg lh kd li lj lk kg ll me ln lo lp mf lr ls lt mg lv lw lx ly im bi translated"><em class="it">蜂鸟是</em></p></blockquote><p id="2c7b" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">幸运的是，使用这个包非常简单。很明显，作者已经花费了大量的时间来确保这个包可以直观地在许多模型上使用。</p><p id="0b68" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">现在，我们从通过pip安装包开始:</p><p id="9253" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><code class="fe on oo op oq b">pip install hummingbird-ml</code></p><p id="31bb" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如果您还想安装LightGBM和XGboost依赖项:</p><p id="2846" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><code class="fe on oo op oq b">pip install hummingbird-ml[extra]</code></p><p id="d04d" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">然后，我们简单地开始创建我们的Sklearn模型，并在数据上对其进行训练:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="or os l"/></div></figure><p id="4122" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这样做之后，我们实际上要做的唯一一件事就是导入蜂鸟并使用<code class="fe on oo op oq b">convert</code>函数:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="or os l"/></div></figure><p id="3af8" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">得到的<code class="fe on oo op oq b">model</code>只是一个<code class="fe on oo op oq b">torch.nn.Module</code>，然后可以像平常使用Pytorch一样使用。</p><p id="7c0d" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">正是转换到Pytorch的便利首先吸引了我对这个包的注意。只需几行代码，您就已经改造了您的模型！</p><h1 id="5846" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">3.路标</h1><p id="cc65" class="pw-post-body-paragraph ld le it lf b lg mz kd li lj na kg ll lm nb lo lp lq nc ls lt lu nd lw lx ly im bi translated">目前，以下型号<strong class="lf jd">已实施</strong>:</p><ul class=""><li id="4ed0" class="nu nv it lf b lg lh lj lk lm nw lq nx lu ny ly oj oa ob oc bi translated">大多数<strong class="lf jd"> Scikit-learn </strong>模型(例如，决策树、回归和SVC)</li><li id="8588" class="nu nv it lf b lg od lj oe lm of lq og lu oh ly oj oa ob oc bi translated"><strong class="lf jd"> LightGBM </strong>(分类器和回归器)</li><li id="0cfe" class="nu nv it lf b lg od lj oe lm of lq og lu oh ly oj oa ob oc bi translated"><strong class="lf jd"> XGboost </strong>(分类器和回归器)</li><li id="b1bd" class="nu nv it lf b lg od lj oe lm of lq og lu oh ly oj oa ob oc bi translated"><strong class="lf jd"> ONNX。ML </strong> (TreeEnsembleClassifier和TreeEnsembleRegressor)</li></ul><p id="fe60" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">虽然一些模型仍然不见踪影，但是他们的<strong class="lf jd">路线图</strong>表明他们正在前进:</p><ul class=""><li id="550b" class="nu nv it lf b lg lh lj lk lm nw lq nx lu ny ly oj oa ob oc bi translated">特征选择器(例如，变量阈值)</li><li id="05cf" class="nu nv it lf b lg od lj oe lm of lq og lu oh ly oj oa ob oc bi translated">矩阵分解(例如PCA)</li><li id="d00a" class="nu nv it lf b lg od lj oe lm of lq og lu oh ly oj oa ob oc bi translated">特征预处理(例如，MinMaxScaler、OneHotEncoder等。)</li></ul><p id="6382" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">你可以在这里找到蜂鸟的完整路线图。</p><h1 id="1baf" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">感谢您的阅读！</h1><p id="eccd" class="pw-post-body-paragraph ld le it lf b lg mz kd li lj na kg ll lm nb lo lp lq nc ls lt lu nd lw lx ly im bi translated">如果你像我一样，对人工智能、数据科学或心理学充满热情，请随时在<a class="ae lz" href="https://www.linkedin.com/in/mgrootendorst/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上添加我，或者在<a class="ae lz" href="https://twitter.com/MaartenGr" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上关注我。</p><p id="0b77" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">点击下面的一个帖子，了解更多关于其他有趣的软件包的信息:</p><div class="ot ou gp gr ov ow"><a rel="noopener follow" target="_blank" href="/reinforcement-learning-in-a-few-lines-of-code-d6c8af1e0fd2"><div class="ox ab fo"><div class="oy ab oz cl cj pa"><h2 class="bd jd gy z fp pb fr fs pc fu fw jc bi translated">几行代码中的强化学习</h2><div class="pd l"><h3 class="bd b gy z fp pb fr fs pc fu fw dk translated">使用稳定基线和Gym训练SOTA RL算法</h3></div><div class="pe l"><p class="bd b dl z fp pb fr fs pc fu fw dk translated">towardsdatascience.com</p></div></div><div class="pf l"><div class="pg l ph pi pj pf pk lb ow"/></div></div></a></div><div class="ot ou gp gr ov ow"><a rel="noopener follow" target="_blank" href="/quickly-build-and-deploy-an-application-with-streamlit-988ca08c7e83"><div class="ox ab fo"><div class="oy ab oz cl cj pa"><h2 class="bd jd gy z fp pb fr fs pc fu fw jc bi translated">借助Streamlit快速构建和部署应用</h2><div class="pd l"><h3 class="bd b gy z fp pb fr fs pc fu fw dk translated">将您的Streamlit应用程序部署到Heroku，展示您的数据解决方案</h3></div><div class="pe l"><p class="bd b dl z fp pb fr fs pc fu fw dk translated">towardsdatascience.com</p></div></div><div class="pf l"><div class="pl l ph pi pj pf pk lb ow"/></div></div></a></div><div class="ot ou gp gr ov ow"><a rel="noopener follow" target="_blank" href="/opening-black-boxes-how-to-leverage-explainable-machine-learning-dd4ab439998e"><div class="ox ab fo"><div class="oy ab oz cl cj pa"><h2 class="bd jd gy z fp pb fr fs pc fu fw jc bi translated">打开黑盒:如何利用可解释的机器学习</h2><div class="pd l"><h3 class="bd b gy z fp pb fr fs pc fu fw dk translated">使用PDP、LIME和SHAP制定可解释的决策，为利益相关方创造价值</h3></div><div class="pe l"><p class="bd b dl z fp pb fr fs pc fu fw dk translated">towardsdatascience.com</p></div></div><div class="pf l"><div class="pm l ph pi pj pf pk lb ow"/></div></div></a></div></div></div>    
</body>
</html>