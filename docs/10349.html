<html>
<head>
<title>Token Outputs and Beyond</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">令牌输出及其他</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/token-outputs-and-beyond-fc63bcdfd752?source=collection_archive---------77-----------------------#2020-07-20">https://towardsdatascience.com/token-outputs-and-beyond-fc63bcdfd752?source=collection_archive---------77-----------------------#2020-07-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/85ee3e056289069edb1fa77687efb3b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/1*cwhR1a9DDqgeYMQ_IPy1gQ.png"/></div></figure><h2 id="7242" class="ju jv iq bd jw jx jy dn jz ka kb dp kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><a class="ae kq" rel="noopener" target="_blank" href="/️-topic-modelling-going-beyond-token-outputs-5b48df212e06">主题建模:超越令牌输出</a></h2><p id="ab64" class="pw-post-body-paragraph kr ks iq kt b ku kv kw kx ky kz la lb kd lc ld le kh lf lg lh kl li lj lk ll ij bi translated">由<a class="lm ln ep" href="https://medium.com/u/e98db206e1b3?source=post_page-----fc63bcdfd752--------------------------------" rel="noopener" target="_blank">劳里·威廉姆斯</a> — 9 分钟阅读</p><p id="83e1" class="pw-post-body-paragraph kr ks iq kt b ku lo kw kx ky lp la lb kd lq ld le kh lr lg lh kl ls lj lk ll ij bi translated">我最近面临一项任务，其最终目标是将大量非结构化的句子和短文段自动聚合到相关主题的组中。<br/>在这个任务中，我意识到在主题建模方法方面还没有太多的报道，特别是当试图给主题起一个有意义的名字的时候。</p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><figure class="mb mc md me gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi ma"><img src="../Images/9584c365991ddbd367bbcf870ad3df7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rVLwCKHIwmrdbhx0h0cMag.jpeg"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">斯特凡·格雷奇在 Unsplash 上拍摄的照片</p></figure><h2 id="2a96" class="ju jv iq bd jw jx jy dn jz ka kb dp kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><a class="ae kq" rel="noopener" target="_blank" href="/machine-learnings-obsession-with-kids-tv-show-characters-728edfb43b3c">机器学习对儿童电视剧角色的痴迷</a></h2><p id="8670" class="pw-post-body-paragraph kr ks iq kt b ku kv kw kx ky kz la lb kd lc ld le kh lf lg lh kl li lj lk ll ij bi translated">由凯瑟琳·杨 — 7 分钟读完</p><p id="e905" class="pw-post-body-paragraph kr ks iq kt b ku lo kw kx ky lp la lb kd lq ld le kh lr lg lh kl ls lj lk ll ij bi translated">埃尔默、伯特和玛吉(辛普森饰)不仅仅是你在成长过程中最喜欢的电视角色——他们也是机器学习和自然语言处理模型</p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><figure class="mb mc md me gt jr gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/989913cd3cb12b59993ee9b2bf7054cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Novylp1Pz8t4wPFiV8fRcw.jpeg"/></div></figure><h2 id="f7a0" class="ju jv iq bd jw jx jy dn jz ka kb dp kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><a class="ae kq" rel="noopener" target="_blank" href="/uncovering-momentum-effect-with-rolling-intertemporal-analysis-36eedc1d8a96">用滚动跨期分析揭示动量效应</a></h2><p id="38c8" class="pw-post-body-paragraph kr ks iq kt b ku kv kw kx ky kz la lb kd lc ld le kh lf lg lh kl li lj lk ll ij bi translated">由 Yulia Malitskaia<a class="lm ln ep" href="https://medium.com/u/1cfccd7daa5c?source=post_page-----fc63bcdfd752--------------------------------" rel="noopener" target="_blank">—9 分钟阅读</a></p><p id="9d47" class="pw-post-body-paragraph kr ks iq kt b ku lo kw kx ky lp la lb kd lq ld le kh lr lg lh kl ls lj lk ll ij bi translated">文章展示了跨期方法，扩展和概括了滚动时间序列技术的范围，用于导出过渡过程和经验策略的模型。该方法是在解释动量溢价的背景下说明的，动量溢价是一个长期的持续挑战。</p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><figure class="mb mc md me gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi ma"><img src="../Images/bd6283d591fe2696624ab26cf11eb445.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uePk11SFXQtYKhAlQRRWWg.jpeg"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">照片由 Valery Rabchenyuk 在 Unsplash 上拍摄</p></figure><h2 id="ebbc" class="ju jv iq bd jw jx jy dn jz ka kb dp kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><a class="ae kq" rel="noopener" target="_blank" href="/how-i-used-python-code-to-improve-my-korean-2f3ae09a9773">我如何使用 Python 代码提高我的韩语水平</a></h2><p id="c594" class="pw-post-body-paragraph kr ks iq kt b ku kv kw kx ky kz la lb kd lc ld le kh lf lg lh kl li lj lk ll ij bi translated">由尼娅姆·金斯利 — 4 分钟读完</p><p id="b493" class="pw-post-body-paragraph kr ks iq kt b ku lo kw kx ky lp la lb kd lq ld le kh lr lg lh kl ls lj lk ll ij bi translated">2020 年初，我决定要自学韩语。我对这种文化很感兴趣，并被学习一门非欧洲语言的挑战所吸引。我不想成为这种感觉像家务杂事的常见陷阱的受害者，所以我开始使用各种资源，包括 Duolingo、LingoDeer、Talktomeinkorean.com、闪存卡、韩剧，显然还有几千小时的 BTS 专辑。</p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><figure class="mb mc md me gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi mn"><img src="../Images/73edd616ea100ae8daaa6a194e5ec2ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q976whmbP-w3boN0lt-SWA.png"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">背景图片由<a class="ae kq" href="https://unsplash.com/@ahmadirini" rel="noopener ugc nofollow" target="_blank">艾哈迈德·迪里尼</a></p></figure><h2 id="6f7e" class="ju jv iq bd jw jx jy dn jz ka kb dp kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><a class="ae kq" rel="noopener" target="_blank" href="/energy-based-models-and-the-future-of-generative-algorithms-3950e1103323">基于能量的模型和生成算法的未来</a></h2><p id="5896" class="pw-post-body-paragraph kr ks iq kt b ku kv kw kx ky kz la lb kd lc ld le kh lf lg lh kl li lj lk ll ij bi translated">与<a class="lm ln ep" href="https://medium.com/u/59564831d1eb?source=post_page-----fc63bcdfd752--------------------------------" rel="noopener" target="_blank">杰瑞米·哈里斯</a>和威尔·格拉斯沃尔——50 分钟🎧</p><p id="cd04" class="pw-post-body-paragraph kr ks iq kt b ku lo kw kx ky lp la lb kd lq ld le kh lr lg lh kl ls lj lk ll ij bi translated">研究生院中的机器学习和工业中的机器学习是非常不同的东西。在行业中，部署和数据收集变得很关键，唯一重要的是你是否能以足够快的速度交付真正客户想要的产品，以满足内部期限。</p></div></div>    
</body>
</html>