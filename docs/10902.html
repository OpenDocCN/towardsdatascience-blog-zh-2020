<html>
<head>
<title>Comparative Analysis of Oversampling Techniques on Imbalanced Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不平衡数据过采样技术的比较分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/comparative-analysis-of-oversampling-techniques-on-imbalanced-data-cd46f172d49d?source=collection_archive---------35-----------------------#2020-07-29">https://towardsdatascience.com/comparative-analysis-of-oversampling-techniques-on-imbalanced-data-cd46f172d49d?source=collection_archive---------35-----------------------#2020-07-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e268" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><strong class="ak">关键词</strong> -不平衡数据，过采样，对比分析</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/17a4c9ebc78cadda539096bb3a469d84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xHTMWrxS4rFrqB0Y"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://unsplash.com/@lukechesser?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">卢克·切瑟</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="70f2" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated"><strong class="ak">简介</strong></h1><p id="9efa" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">对不平衡数据建模是我们在训练模型时面临的主要挑战。我的项目的主要目标是找到最佳的过采样技术，我将应用于五个与老化相关的 bug 问题相关的数据集。我会用七个机器学习分类模型来训练模型。</p><p id="612f" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">不平衡数据通常指的是分类问题，其中每个类别的观察值数量不是均匀分布的；通常，一个类别(称为<em class="mp">多数类别</em>)会有大量数据/观察值，而一个或多个其他类别(称为<em class="mp">少数类别</em>)的观察值会少得多。</p><h1 id="0812" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated"><strong class="ak">数据</strong></h1><p id="d38e" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我使用的数据集与老化相关的错误(ARB)有关，这些错误发生在长期运行的系统中，是由于内存泄漏或未释放的文件和锁等问题的积累而导致的错误条件。与衰老有关。在软件测试过程中，bug 很难被发现，复制起来也很困难。下面是表 1 中每个数据集的描述。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/b83265992da5388e389de3663b4a6e11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gHsfpvmE1yLFdoUK1zP1eQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">表 1:实验数据集描述</p></figure><h1 id="f531" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated"><strong class="ak">使用的平衡方法</strong></h1><h2 id="f09f" class="mr kx iq bd ky ms mt dn lc mu mv dp lg lx mw mx li mb my mz lk mf na nb lm nc bi translated"><strong class="ak"> 1。类别重量</strong></h2><p id="444d" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">首先，我使用了一种最简单的方法来解决类不平衡的问题，即简单地为每个类提供一个权重，这个权重更多地强调少数类，这样最终的结果是一个分类器可以从所有类中平等地学习。</p><h2 id="2773" class="mr kx iq bd ky ms mt dn lc mu mv dp lg lx mw mx li mb my mz lk mf na nb lm nc bi translated">2.过采样</h2><p id="b7c0" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">其次，我使用了三种过采样技术来消除这种不平衡。对于<em class="mp">过采样</em>，少数类将增加少数观察的数量，直到我们达到一个平衡的数据集。</p><h2 id="bcb2" class="mr kx iq bd ky ms mt dn lc mu mv dp lg lx mw mx li mb my mz lk mf na nb lm nc bi translated">2.1 随机过采样</h2><p id="3839" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">这是最简单的过采样方法。它随机采样少数类，并简单地复制采样的观察值。通过这种技术，我们人为地减少了数据集的方差。</p><h2 id="d287" class="mr kx iq bd ky ms mt dn lc mu mv dp lg lx mw mx li mb my mz lk mf na nb lm nc bi translated">2.2 SMOTE</h2><p id="e872" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">然而，我们也可以使用现有的数据集为少数类综合生成新的数据点。合成少数过采样技术(SMOTE)是一种通过在原始数据集中的观测值之间进行插值来生成新观测值的技术。</p><p id="d7b4" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">对于给定的观测值 xi，通过在 k 个最近邻之一 xzi 之间进行插值来生成新的(合成)观测值。</p><p id="bce5" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">xnew = Xi+λ(xzi Xi)xnew = Xi+λ(xzi Xi)</p><p id="aa89" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">其中λ是在[0，1][0，1]范围内的随机数。这个插值将在 xi 和 xzi 之间的线上创建一个样本。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/5d1a5a1465b3658d102ec88723510fd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/1*2eItrbB3AFn1NhxMFD3B6A.png"/></div></figure><h2 id="c9f3" class="mr kx iq bd ky ms mt dn lc mu mv dp lg lx mw mx li mb my mz lk mf na nb lm nc bi translated">2.3 ADASYN</h2><p id="7ec6" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">自适应合成(ADASYN)采样与 SMOTE 相同，但是，为给定 xi 生成的样本数量与附近与 xi 不属于同一类别的样本数量成比例。因此，ADASYN 在生成新的合成训练样本时往往只关注离群值。</p><h1 id="5e4c" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated"><strong class="ak">使用的分类模型</strong></h1><p id="e5e1" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">1.<strong class="lq ir"> <em class="mp"> K 最近邻— </em> </strong>首先，我使用了一个简单的分类模型，即 KNN 分类器。在这个模型中，分类是根据每个点的 k 个最近邻的简单多数投票来计算的。</p><p id="8afc" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir"> <em class="mp"> 2。逻辑回归- </em> </strong>其次我用的是逻辑回归。在该算法中，描述单次试验可能结果的概率使用逻辑函数(即 sigmoid 函数)建模。</p><p id="59e2" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir"> <em class="mp"> 3。朴素贝叶斯- </em> </strong>接下来我使用了朴素贝叶斯算法，它基于贝叶斯定理，假设每对特征之间是独立的。朴素贝叶斯分类器在许多现实情况下工作良好，例如文档分类和垃圾邮件过滤。</p><p id="7e05" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir"> <em class="mp"> 4。决策树- </em> </strong>然后我用了决策树分类器。决策树产生一系列可用于对数据进行分类的规则。这个分类器易于理解和可视化，可以处理数字和分类数据。</p><p id="d80a" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir"> <em class="mp"> 5。</em>随机森林-</strong>接下来我用的是随机森林分类器。它是一种元估计器，可以在数据集的各种子样本上拟合许多决策树，并使用平均值来提高模型的预测准确性，并控制过度拟合。子样本大小始终与原始输入样本大小相同，但样本是替换绘制的。</p><p id="b336" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">6<em class="mp">6。</em>支持向量机-</strong>接下来我用的是 SVM。它将训练数据表示为空间中的点，这些点被尽可能宽的明显间隙分成不同的类别。然后，新的例子被映射到相同的空间，并根据它们落在差距的哪一边来预测属于哪个类别。</p><p id="c97b" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir"> <em class="mp"> 7。山脊 CV- </em> </strong>最后我用的是山脊 CV。该分类器首先将目标值转换为{-1，<code class="fe ne nf ng nh b"> </code> 1}，然后将问题视为回归任务(多类情况下的多输出回归)。</p><h1 id="1853" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated"><strong class="ak">观察分析</strong></h1><h2 id="98c9" class="mr kx iq bd ky ms mt dn lc mu mv dp lg lx mw mx li mb my mz lk mf na nb lm nc bi translated"><strong class="ak"> <em class="ni"> 1。调谐模式</em> </strong></h2><p id="d4b7" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我超调了每个数据集上的每个模型，以找到模型可以预测的最佳精度。我使用 GridSearchCV 和 K-Fold 来优化模型。我将不同的 K 值设置为 5、10、15 和 20，发现 10 倍的效果最好。</p><p id="22af" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">你可以在文章末尾我提供的 GitHub 链接中看到代码</p><h2 id="503e" class="mr kx iq bd ky ms mt dn lc mu mv dp lg lx mw mx li mb my mz lk mf na nb lm nc bi translated"><strong class="ak"> <em class="ni"> 2。</em>技术相对比较</strong></h2><p id="0b6f" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我使用了 AUC 指标来比较模型，因为当我们必须比较分类模型时，ROC AUC 是最好的。AUC 值越大，模型越好。从我的结果中，我发现平均 AUC 值，即 0.89 的<strong class="lq ir"> <em class="mp">随机抽样</em> </strong>与其他不平衡学习策略相比是最好的。<strong class="lq ir"> <em class="mp"> SMOTE </em> </strong>和<strong class="lq ir"> <em class="mp"> ADAYSN </em> </strong>的平均 AUC 值次之，为 0.88。<strong class="lq ir"> <em class="mp">类权重</em> </strong> t 的平均 AUC 值为 0.58。精度和 f 值显示出相同的趋势。根据 f-measure 值和精确度两者，<strong class="lq ir"> <em class="mp">随机超过采样器</em> </strong>性能最好，其次是<strong class="lq ir"><em class="mp"/></strong>和<strong class="lq ir"> <em class="mp"> ADASYN </em> </strong>。</p><p id="2e92" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们还推断出<strong class="lq ir"> <em class="mp">脊分类器</em> </strong>是最好的，并且具有 0.93 的平均 AUC 值。其次是平均 AUC 值为 0.83 的<strong class="lq ir"> <em class="mp">随机森林</em> </strong>和平均 AUC 值为 0.80 的<strong class="lq ir"> <em class="mp">决策树</em></strong><strong class="lq ir"><em class="mp">KNN</em></strong>各为 0.80。<strong class="lq ir"> <em class="mp"> Logistic 回归</em> </strong>和<strong class="lq ir"> <em class="mp"> SVM </em> </strong>的平均 AUC 值各为 0.79。<strong class="lq ir"> <em class="mp">朴素贝叶斯</em> </strong>表现最差，平均 AUC 为 0.76。根据 F-测度，脊分类器的平均 F-测度值为 0.916。决策树和随机森林的平均 F-测度值分别为 0.90 和 0.91，高于 SVM 和 Logistic 回归的平均 F-测度值 0.85。朴素贝叶斯表现最差，平均 F 值为 0.81</p><p id="a671" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">此外，我绘制了条形图，显示了过采样技术和分类模型的比较。从可视化结果中，我们还可以看到，在大多数情况下，由绿色条表示的随机过采样技术比其他技术高。</p><p id="56fc" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">你可以在文章末尾提供的我的 GitHub 链接中查看可视化代码。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nj"><img src="../Images/9159c24f6e4f77d28d8f76820c36ccad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8U4QTCZFCglkXDFL2-5HxQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">AUC 分数的条形图</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/8cbcb360c9f8a6286a3b85b5787621e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5XxEf2C0aHBaYg_73Db93A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">准确性得分条形图</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nj"><img src="../Images/3bbb953d7958bcf87678f62d673c34b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xtWNBFnXmVsifJZUXMFv_Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">F1-度量的条形图</p></figure><h1 id="4f30" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated"><strong class="ak">结果</strong></h1><p id="dcb9" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在这篇文章中，我通过应用 7 种机器学习算法，对 5 个老化相关错误的不平衡数据集进行了过采样技术的比较分析。从我的项目，我们得出结论，随机过采样器被证明是最好的过采样技术相比，其他和岭分类器，最好的机器学习算法。</p><p id="7475" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我的 GitHub 链接-<a class="ae kv" href="https://github.com/vanisinghal0201/Comparative_Analysis" rel="noopener ugc nofollow" target="_blank">https://github.com/vanisinghal0201/Comparative_Analysis</a></p><p id="ee4a" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">我也将很快在</strong><a class="ae kv" href="https://www.geeksforgeeks.org/" rel="noopener ugc nofollow" target="_blank"><strong class="lq ir">geeks forgeeks</strong></a><strong class="lq ir">上发表。</strong></p><h1 id="adaa" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated"><strong class="ak">参考文献</strong></h1><p id="798c" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">[1] Lov Kumar，Ashish Sureka，实验结果，结论，针对老化相关错误预测的类不平衡问题的特征选择技术，2018</p><p id="e24e" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">[2]双吉，预测职称分类中的等级关系，2020</p><p id="6f3a" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">[3]从不平衡数据中学习。检索自 https<a class="ae kv" href="https://www.jeremyjordan.me/imbalanced-data/" rel="noopener ugc nofollow" target="_blank">://www . Jeremy Jordan . me/unbalanced-data/</a></p><p id="c1f2" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">[4]不平衡数据<a class="ae kv" href="https://github.com/vanisinghal0201/imbalanceddata/blob/master/Learning%20from%20imbalanced%20data.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/vanising Hal 0201/unbalanced Data/blob/master/Learning % 20 from % 20 unbalanced % 20 Data . ipynb</a></p></div></div>    
</body>
</html>