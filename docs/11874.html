<html>
<head>
<title>Polynomial Regression From Scratch in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python 中从头开始的多项式回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/polynomial-regression-from-scratch-in-python-1f34a3a5f373?source=collection_archive---------18-----------------------#2020-08-17">https://towardsdatascience.com/polynomial-regression-from-scratch-in-python-1f34a3a5f373?source=collection_archive---------18-----------------------#2020-08-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/ab6cadcf216aebd0e5a940018c195174.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*080-Wli9cafgyfIf"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">照片由<a class="ae jg" href="https://unsplash.com/@redcharlie?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">雷德查理</a>在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><div class=""/><div class=""><h2 id="29c7" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">学习用一些简单的 python 代码从头开始实现多项式回归</h2></div><p id="daba" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">线性回归的改进版本中的多项式回归。如果你知道线性回归，对你来说就简单了。如果没有，我将在本文中解释这些公式。还有其他更先进、更有效的机器学习算法。但是学习基于线性的回归技术是一个好主意。因为它们简单、快速，并且与众所周知的公式一起工作。尽管它可能无法处理复杂的数据集。</p><h1 id="46da" class="lu lv jj bd lw lx ly lz ma mb mc md me kp mf kq mg ks mh kt mi kv mj kw mk ml bi translated">多项式回归公式</h1><p id="f58a" class="pw-post-body-paragraph ky kz jj la b lb mm kk ld le mn kn lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">只有当输入变量和输出变量之间存在线性相关性时，线性回归才能表现良好。正如我之前提到的，多项式回归建立在线性回归的基础上。如果你需要复习线性回归，这里有线性回归的链接:</p><div class="is it gp gr iu mr"><a rel="noopener follow" target="_blank" href="/basic-linear-regression-algorithm-in-python-for-beginners-c519a808b5f8"><div class="ms ab fo"><div class="mt ab mu cl cj mv"><h2 class="bd jk gy z fp mw fr fs mx fu fw ji bi translated">Python 中的线性回归算法</h2><div class="my l"><h3 class="bd b gy z fp mw fr fs mx fu fw dk translated">学习线性回归的概念，并使用 python 从头开始开发一个完整的线性回归算法</h3></div><div class="mz l"><p class="bd b dl z fp mw fr fs mx fu fw dk translated">towardsdatascience.com</p></div></div><div class="na l"><div class="nb l nc nd ne na nf ja mr"/></div></div></a></div><p id="d763" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">多项式回归可以更好地找到输入特征和输出变量之间的关系，即使这种关系不是线性的。它使用与线性回归相同的公式:</p><p id="e607" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Y = BX + C</p><p id="60ec" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我确信，我们在学校都学过这个公式。对于线性回归，我们使用这样的符号:</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/a033938e15c69e1e9c3c4ea667c7b3cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:360/format:webp/0*kz0gy0A_ptA1vGdl.png"/></div></figure><p id="faf6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里，我们从数据集中得到 X 和 Y。x 是输入要素，Y 是输出变量。θ值是随机初始化的。</p><p id="e865" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于多项式回归，公式如下:</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/3afb46efbad7f594c636ea8e4dc5c07b.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/0*weBDz5EdiEr0k9R5.png"/></div></figure><p id="e373" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们在这里添加了更多的术语。我们使用相同的输入特征，并采用不同的指数来产生更多的特征。这样，我们的算法将能够更好地学习数据。</p><p id="3960" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">幂不必是 2、3 或 4。它们也可以是 1/2、1/3 或 1/4。那么该公式将如下所示:</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/7f246be85bdb5fa2def0471565074b62.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/0*nVg6FSa6vMUkgIVJ.png"/></div></figure><h1 id="9087" class="lu lv jj bd lw lx ly lz ma mb mc md me kp mf kq mg ks mh kt mi kv mj kw mk ml bi translated">成本函数和梯度下降</h1><p id="222f" class="pw-post-body-paragraph ky kz jj la b lb mm kk ld le mn kn lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">成本函数给出了预测的假设离值有多远的概念。公式是:</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/9f7e10b97aedb836749b989200e6e440.png" data-original-src="https://miro.medium.com/v2/resize:fit:602/format:webp/0*2MbktYeknoiUvXDC.png"/></div></figure><p id="3893" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个等式可能看起来很复杂。它正在做一个简单的计算。首先，从原始输出变量中扣除假设。取一个正方形来消除负值。然后将该值除以训练样本数量的 2 倍。</p><p id="5fef" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">什么是梯度下降？它有助于微调我们随机初始化的θ值。我不想在这里讲微积分。如果对每个θ取成本函数的偏导数，我们可以导出这些公式:</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div class="gh gi no"><img src="../Images/869cb1c45ff1fac9401b0f56181ba2af.png" data-original-src="https://miro.medium.com/v2/resize:fit:586/format:webp/0*6ce0WAvGCdWNet5E.png"/></div></figure><p id="0861" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里，α是学习率。你选择α的值。</p><h1 id="b7f4" class="lu lv jj bd lw lx ly lz ma mb mc md me kp mf kq mg ks mh kt mi kv mj kw mk ml bi translated">多项式回归的 Python 实现</h1><p id="a124" class="pw-post-body-paragraph ky kz jj la b lb mm kk ld le mn kn lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">下面是多项式回归的逐步实现。</p><ol class=""><li id="94bd" class="np nq jj la b lb lc le lf lh nr ll ns lp nt lt nu nv nw nx bi translated">在这个例子中，我们将使用一个简单的虚拟数据集来给出职位的工资数据。导入数据集:</li></ol><pre class="nh ni nj nk gt ny nz oa ob aw oc bi"><span id="4942" class="od lv jj nz b gy oe of l og oh">import pandas as pd<br/>import numpy as np<br/>df = pd.read_csv('position_salaries.csv')<br/>df.head()</span></pre><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/42eddd527a7be5c6761f8da5adcdbc06.png" data-original-src="https://miro.medium.com/v2/resize:fit:604/format:webp/0*OG2nxjO0pgejXulc.png"/></div></figure><p id="c550" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">2.添加θ0 的偏移列。这个偏置列将只包含 1。因为如果你用一个数乘以 1，它不会改变。</p><pre class="nh ni nj nk gt ny nz oa ob aw oc bi"><span id="9b22" class="od lv jj nz b gy oe of l og oh">df = pd.concat([pd.Series(1, index=df.index, name='00'), df], axis=1)<br/>df.head()</span></pre><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/5e94e7f8c8d6313047bc5e74f95e0cd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:648/format:webp/0*EWdpIIdm3jOeUkYE.png"/></div></figure><p id="25de" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">3.删除“职位”栏。因为“位置”列包含字符串，而算法不理解字符串。我们用“级别”栏来表示职位。</p><pre class="nh ni nj nk gt ny nz oa ob aw oc bi"><span id="c634" class="od lv jj nz b gy oe of l og oh">df = df.drop(columns='Position')</span></pre><p id="14df" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">4.定义我们的输入变量 X 和输出变量 y。在本例中，“级别”是输入特征，“薪金”是输出变量。我们想预测工资水平。</p><pre class="nh ni nj nk gt ny nz oa ob aw oc bi"><span id="7c67" class="od lv jj nz b gy oe of l og oh">y = df['Salary']<br/>X = df.drop(columns = 'Salary')<br/>X.head()</span></pre><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/3dc5486c264273096b7086efb45eb6da.png" data-original-src="https://miro.medium.com/v2/resize:fit:244/format:webp/0*43gkJXejHJ-CDjKR.png"/></div></figure><p id="0c3a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">5.取“级别”列的指数，得到“级别 1”和“级别 2”列。</p><pre class="nh ni nj nk gt ny nz oa ob aw oc bi"><span id="be6c" class="od lv jj nz b gy oe of l og oh">X['Level1'] = X['Level']**2<br/>X['Level2'] = X['Level']**3<br/>X.head()</span></pre><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/854684dc7d59a13aee964486c1b370ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:496/format:webp/0*3-MNYRZaRb_fpIKz.png"/></div></figure><p id="820c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">6.现在，将数据标准化。将每列除以该列的最大值。这样，我们将得到每一列的值，范围从 0 到 1。即使没有归一化，该算法也应该工作。但它有助于更快地收敛。此外，计算数据集长度 m 的值。</p><pre class="nh ni nj nk gt ny nz oa ob aw oc bi"><span id="ad5d" class="od lv jj nz b gy oe of l og oh">m = len(X)<br/>X = X/X.max()</span></pre><p id="28ab" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">7.定义假设函数。会用 X 和θ来预测 y。</p><pre class="nh ni nj nk gt ny nz oa ob aw oc bi"><span id="83ed" class="od lv jj nz b gy oe of l og oh">def hypothesis(X, theta):<br/>    y1 = theta*X<br/>    return np.sum(y1, axis=1)</span></pre><p id="a909" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">8.用上面的成本函数公式定义成本函数:</p><pre class="nh ni nj nk gt ny nz oa ob aw oc bi"><span id="f8e6" class="od lv jj nz b gy oe of l og oh">def cost(X, y, theta):<br/>    y1 = hypothesis(X, theta)<br/>    return sum(np.sqrt((y1-y)**2))/(2*m)</span></pre><p id="fa33" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">9.写出梯度下降的函数。我们将不断更新θ值，直到找到最佳成本。对于每一次迭代，我们将计算未来分析的成本。</p><pre class="nh ni nj nk gt ny nz oa ob aw oc bi"><span id="bb0e" class="od lv jj nz b gy oe of l og oh">def gradientDescent(X, y, theta, alpha, epoch):<br/>    J=[]<br/>    k=0<br/>    while k &lt; epoch:<br/>        y1 = hypothesis(X, theta)<br/>        for c in range(0, len(X.columns)):<br/>            theta[c] = theta[c] - alpha*sum((y1-y)* X.iloc[:, c])/m<br/>        j = cost(X, y, theta)<br/>        J.append(j)<br/>        k += 1<br/>    return J, theta</span></pre><p id="c21c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">10.所有函数都已定义。现在，初始化θ。我正在初始化一个零数组。您可以采用任何其他随机值。我选择α为 0.05，我将迭代 700 个时期的θ值。</p><pre class="nh ni nj nk gt ny nz oa ob aw oc bi"><span id="3a75" class="od lv jj nz b gy oe of l og oh">theta = np.array([0.0]*len(X.columns))<br/>J, theta = gradientDescent(X, y, theta, 0.05, 700)</span></pre><p id="1efd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">11.我们得到了最终的θ值和每次迭代的成本。让我们用最终的θ找到工资预测。</p><pre class="nh ni nj nk gt ny nz oa ob aw oc bi"><span id="67f7" class="od lv jj nz b gy oe of l og oh">y_hat = hypothesis(X, theta)</span></pre><p id="092d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">12.现在绘制原始工资和我们预测的工资水平。</p><pre class="nh ni nj nk gt ny nz oa ob aw oc bi"><span id="eaad" class="od lv jj nz b gy oe of l og oh">%matplotlib inline<br/>import matplotlib.pyplot as plt<br/>plt.figure()<br/>plt.scatter(x=X['Level'],y= y)           <br/>plt.scatter(x=X['Level'], y=y_hat)<br/>plt.show()</span></pre><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div class="gh gi om"><img src="../Images/b7b5e275a83ea48778cd080d8a73e5ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/0*g4Vy8dWNJXO5e5VB.png"/></div></figure><p id="ba5d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们的预测不完全符合工资的趋势，但也很接近。线性回归只能返回一条直线。但是在多项式回归中，我们可以得到这样的曲线。如果直线不是一条漂亮的曲线，多项式回归也可以学习一些更复杂的趋势。</p><p id="ef41" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">13.让我们在梯度下降函数中绘制我们在每个时期计算的成本。</p><pre class="nh ni nj nk gt ny nz oa ob aw oc bi"><span id="f48f" class="od lv jj nz b gy oe of l og oh">plt.figure()<br/>plt.scatter(x=list(range(0, 700)), y=J)<br/>plt.show()</span></pre><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div class="gh gi on"><img src="../Images/ef264336c6d7d409b15ddbb04d275ce1.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/0*W9PxOdRUh4floAIC.png"/></div></figure><p id="a1f9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">成本在开始时急剧下降，然后下降缓慢。在一个好的机器学习算法中，成本应该保持下降，直到收敛。请随意用不同的历元数和不同的学习率(alpha)来尝试。</p><p id="38d5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面是数据集:<a class="ae jg" href="https://github.com/rashida048/Machine-Learning-With-Python/blob/master/position_salaries.csv" rel="noopener ugc nofollow" target="_blank">薪资 _ 数据</a></p><p id="3f9e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">点击此链接获取完整的工作代码:<a class="ae jg" href="https://github.com/rashida048/Machine-Learning-With-Python/blob/master/polynomial%20regression.ipynb" rel="noopener ugc nofollow" target="_blank">多项式回归</a></p><h2 id="b2ec" class="od lv jj bd lw oo op dn ma oq or dp me lh os ot mg ll ou ov mi lp ow ox mk oy bi translated">推荐阅读:</h2><div class="is it gp gr iu mr"><a rel="noopener follow" target="_blank" href="/interactive-geospatial-data-visualization-in-python-490fb41acc00"><div class="ms ab fo"><div class="mt ab mu cl cj mv"><h2 class="bd jk gy z fp mw fr fs mx fu fw ji bi translated">Python 中的交互式地理空间数据可视化</h2><div class="my l"><h3 class="bd b gy z fp mw fr fs mx fu fw dk translated">绘制世界特定地区的地图，在地图上展示活动，并四处导航</h3></div><div class="mz l"><p class="bd b dl z fp mw fr fs mx fu fw dk translated">towardsdatascience.com</p></div></div><div class="na l"><div class="oz l nc nd ne na nf ja mr"/></div></div></a></div><div class="is it gp gr iu mr"><a href="https://medium.com/towards-artificial-intelligence/similar-texts-search-in-python-with-a-few-lines-of-code-an-nlp-project-9ace2861d261" rel="noopener follow" target="_blank"><div class="ms ab fo"><div class="mt ab mu cl cj mv"><h2 class="bd jk gy z fp mw fr fs mx fu fw ji bi translated">用几行代码在 Python 中搜索相似的文本:一个 NLP 项目</h2><div class="my l"><h3 class="bd b gy z fp mw fr fs mx fu fw dk translated">使用 Python 中的计数矢量器和最近邻法查找类似的维基百科简介，这是一个简单而有用的…</h3></div><div class="mz l"><p class="bd b dl z fp mw fr fs mx fu fw dk translated">medium.com</p></div></div><div class="na l"><div class="pa l nc nd ne na nf ja mr"/></div></div></a></div><div class="is it gp gr iu mr"><a rel="noopener follow" target="_blank" href="/logistic-regression-in-python-to-detect-heart-disease-2892b138d0c0"><div class="ms ab fo"><div class="mt ab mu cl cj mv"><h2 class="bd jk gy z fp mw fr fs mx fu fw ji bi translated">Python 中用于检测心脏病的逻辑回归</h2><div class="my l"><h3 class="bd b gy z fp mw fr fs mx fu fw dk translated">发展逻辑回归演算法的重要方程式和如何发展逻辑回归演算法</h3></div><div class="mz l"><p class="bd b dl z fp mw fr fs mx fu fw dk translated">towardsdatascience.com</p></div></div><div class="na l"><div class="pb l nc nd ne na nf ja mr"/></div></div></a></div><div class="is it gp gr iu mr"><a href="https://medium.com/towards-artificial-intelligence/build-a-neural-network-from-scratch-in-python-f23848b5a7c6" rel="noopener follow" target="_blank"><div class="ms ab fo"><div class="mt ab mu cl cj mv"><h2 class="bd jk gy z fp mw fr fs mx fu fw ji bi translated">用 Python 从头开始构建神经网络</h2><div class="my l"><h3 class="bd b gy z fp mw fr fs mx fu fw dk translated">神经网络的详细说明和逐步实现</h3></div><div class="mz l"><p class="bd b dl z fp mw fr fs mx fu fw dk translated">medium.com</p></div></div><div class="na l"><div class="pc l nc nd ne na nf ja mr"/></div></div></a></div><div class="is it gp gr iu mr"><a href="https://medium.com/towards-artificial-intelligence/build-a-simple-recommendation-system-in-python-7747be06a2f2" rel="noopener follow" target="_blank"><div class="ms ab fo"><div class="mt ab mu cl cj mv"><h2 class="bd jk gy z fp mw fr fs mx fu fw ji bi translated">使用 Python 中的简单代码构建一个推荐系统</h2><div class="my l"><h3 class="bd b gy z fp mw fr fs mx fu fw dk translated">如何用 Python 构建电影推荐系统</h3></div><div class="mz l"><p class="bd b dl z fp mw fr fs mx fu fw dk translated">medium.com</p></div></div><div class="na l"><div class="pd l nc nd ne na nf ja mr"/></div></div></a></div></div></div>    
</body>
</html>