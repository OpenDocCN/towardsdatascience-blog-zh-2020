<html>
<head>
<title>Torch Points3D — A unifying framework for deep learning on point clouds</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">torch points 3d——点云深度学习的统一框架</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/torch-points3d-a-unifying-framework-for-deep-learning-on-point-clouds-94115c0be4fb?source=collection_archive---------23-----------------------#2020-05-18">https://towardsdatascience.com/torch-points3d-a-unifying-framework-for-deep-learning-on-point-clouds-94115c0be4fb?source=collection_archive---------23-----------------------#2020-05-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d48e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">点云深度学习变得简单</h2></div><p id="e192" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">这是与</em><a class="lc ld ep" href="https://medium.com/u/cc14203bd1eb?source=post_page-----94115c0be4fb--------------------------------" rel="noopener" target="_blank"><em class="lb">Thomas Chaton</em></a><em class="lb">和</em><a class="ae le" href="http://loiclandrieu.com" rel="noopener ugc nofollow" target="_blank"><em class="lb">Loic Landrieu</em></a><em class="lb">的联合出版物。</em></p><p id="5cab" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">github:<a class="ae le" href="https://github.com/nicolas-chaulet/torch-points3d" rel="noopener ugc nofollow" target="_blank">https://github.com/nicolas-chaulet/torch-points3d</a></p><p id="6033" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">随着越来越便宜的激光雷达传感器和更高效的摄影测量算法的出现，3D点云数据比以往任何时候都更容易获取。深度学习社区已经接受了这一趋势，开发了新的网络架构来对3D数据执行各种任务。大量的可能性(数据布局、数据扩充、卷积策略等)使得找到最适合您的数据或问题的方法非常耗时。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/0eebb7c7b7ff0cbae2b0d7a2a51c5fc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K2MtEzIVHURoHvSekUVrEw.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">使用KPConv获得的语义分段输出</p></figure><p id="615d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们的框架Torch Points3D被开发成点云数据的<strong class="kh ir"/><a class="ae le" href="https://pytorch.org/docs/stable/torchvision/index.html" rel="noopener ugc nofollow" target="_blank"><strong class="kh ir">Torch vision</strong></a><strong class="kh ir">:</strong>一个灵活且可扩展的框架，适用于研究基于点云的机器视觉的研究人员和工程师。想知道<a class="ae le" href="https://github.com/HuguesTHOMAS/KPConv-PyTorch" rel="noopener ugc nofollow" target="_blank"> KPConv </a>在点云注册方面表现如何吗？或者<a class="ae le" href="https://github.com/charlesq34/pointnet2" rel="noopener ugc nofollow" target="_blank"> PointNet++ </a>用随机采样代替<a class="ae le" href="https://github.com/QingyongHu/RandLA-Net" rel="noopener ugc nofollow" target="_blank"> RandLa-Net </a>中建议的最远点采样进行物体检测？有了Torch Points3D，您现在只需几行代码就可以尝试多种最先进的主干模型。</p><p id="58b0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在快速回顾了点云的特性后，我们将介绍Torch Points3D的以下方面:</p><ol class=""><li id="3b53" class="lv lw iq kh b ki kj kl km ko lx ks ly kw lz la ma mb mc md bi translated">点云数据的优化数据布局</li><li id="9bc9" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated">许多学术数据集的本地集成</li><li id="e20d" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated">快速和稳健的数据处理和数据扩充</li><li id="a00a" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated">针对一系列稀疏和基于点的架构测试了卷积核</li><li id="b6f1" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated">用于访问数据集、数据转换和预配置模型的易于使用的API</li></ol><p id="88f5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们提供具有有用功能的训练脚本，例如模型检查点、登录<a class="ae le" href="https://www.tensorflow.org/tensorboard" rel="noopener ugc nofollow" target="_blank"> Tensorboard </a>和<a class="ae le" href="https://www.wandb.com/" rel="noopener ugc nofollow" target="_blank">重量和偏差</a>，使用脸书<a class="ae le" href="https://hydra.cc/" rel="noopener ugc nofollow" target="_blank"> Hydra </a>轻松配置超参数，等等。您也可以将我们的核心组件用于您最喜欢的训练框架，例如<a class="ae le" href="https://github.com/PyTorchLightning/pytorch-lightning" rel="noopener ugc nofollow" target="_blank"> PyTorchLightning </a>。</p><p id="3416" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们希望你喜欢阅读！我们欢迎您的反馈和贡献。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi mj"><img src="../Images/450e715236fd5dbe68e4544d5ca1146e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gIh6l7VMxXLPxTdZBKSy_g.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">火炬点3D系统图，数据流以红色突出显示</p></figure></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><h1 id="e00d" class="mr ms iq bd mt mu mv mw mx my mz na nb jw nc jx nd jz ne ka nf kc ng kd nh ni bi translated">点云为什么这么特别？</h1><p id="839f" class="pw-post-body-paragraph kf kg iq kh b ki nj jr kk kl nk ju kn ko nl kq kr ks nm ku kv kw nn ky kz la ij bi translated">围绕3D稀疏点云的挑战在研究文献中有广泛描述，我们将仅提及3D点云和2D图像之间的一些关键差异:</p><ul class=""><li id="e503" class="lv lw iq kh b ki kj kl km ko lx ks ly kw lz la no mb mc md bi translated">每个点云可以有不同数量的点，即使它们具有相同的空间分辨率。这使得点云比图像更难构成均匀的批次。</li><li id="4a35" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la no mb mc md bi translated">激光雷达传感器捕捉三维世界中的表面，因此数据本质上是稀疏的。另一方面，照相机产生密集的采集。</li><li id="660e" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la no mb mc md bi translated">在同一个点云中，点的密度各不相同，因此一些点可能有许多近邻来获得精确的几何信息，而其他点可能是孤立的。</li><li id="16d4" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la no mb mc md bi translated">点云在它们的点的索引的重新索引下是不变的，而像素的索引固有地链接到它们的坐标。这意味着用于处理点云的处理技术也必须是排列不变的。</li></ul><h1 id="e1ce" class="mr ms iq bd mt mu np mw mx my nq na nb jw nr jx nd jz ns ka nf kc nt kd nh ni bi translated">点云数据和数据布局</h1><p id="b9b2" class="pw-post-body-paragraph kf kg iq kh b ki nj jr kk kl nk ju kn ko nl kq kr ks nm ku kv kw nn ky kz la ij bi translated">有两种方法可以组装不同的批次。第一种是通过子采样和过采样使批中的所有元素大小相同，并在新的批维度中整理它们(就像整理图像一样)。我们将这种方法称为密集批处理。或者，您可以直接比较点维度中的样本，并跟踪每个样本中的点数。我们将这种方法称为打包批处理。</p><p id="ff04" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">官方实现PointNet++和Relation-Shape CNN以及类似的架构都使用密集批处理。除了实现简单之外，它的主要好处是可以利用与经典2D卷积相关的硬件优化。缺点是一些样本可能有许多重复点，而另一些样本被严重欠采样，丢弃了信息。每个样本的点数必须仔细选择。另一方面，KPConv或Minkowski Engine等更新的模型使用打包批处理，这样就不需要对批处理中的元素进行采样，在某些情况下还可以显著降低内存需求。好消息是我们支持这两种数据格式，我们的数据加载器可以很容易地从一种格式切换到另一种格式。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/66967424f9b4748bdd8662d183433253.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/1*89R-Y_rtkZ5W6OrGM-giwA.gif"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">对于相同的两个点云(红色和蓝色)，左侧为密集批排序，右侧为打包批排序。</p></figure><h1 id="2807" class="mr ms iq bd mt mu np mw mx my nq na nb jw nr jx nd jz ns ka nf kc nt kd nh ni bi translated">支持的核心数据集</h1><p id="b098" class="pw-post-body-paragraph kf kg iq kh b ki nj jr kk kl nk ju kn ko nl kq kr ks nm ku kv kw nn ky kz la ij bi translated">该框架提供了对社区广泛使用的几个数据集的简单访问。目前，我们支持以下数据集:</p><ul class=""><li id="46d1" class="lv lw iq kh b ki kj kl km ko lx ks ly kw lz la no mb mc md bi translated"><a class="ae le" href="http://www.scan-net.org/" rel="noopener ugc nofollow" target="_blank"> ScanNet </a></li><li id="868a" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la no mb mc md bi translated"><a class="ae le" href="http://buildingparser.stanford.edu/dataset.html" rel="noopener ugc nofollow" target="_blank"> S3DIS </a></li><li id="745f" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la no mb mc md bi translated"><a class="ae le" href="https://www.shapenet.org/" rel="noopener ugc nofollow" target="_blank"> ShapeNet </a></li><li id="2b4b" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la no mb mc md bi translated"><a class="ae le" href="https://modelnet.cs.princeton.edu/" rel="noopener ugc nofollow" target="_blank"> ModelNet </a></li><li id="8fbc" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la no mb mc md bi translated"><a class="ae le" href="http://3dmatch.cs.princeton.edu/" rel="noopener ugc nofollow" target="_blank"> 3DMatch </a>(感谢<a class="ae le" href="https://github.com/humanpose1" rel="noopener ugc nofollow" target="_blank"> Sofiane Horache </a>)</li></ul><p id="adad" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要在您自己的框架内使用Torch Points3D数据集，您只需编写:</p><pre class="lg lh li lj gt nv nw nx ny aw nz bi"><span id="8de3" class="oa ms iq nw b gy ob oc l od oe">&gt;&gt;&gt; dataset = ShapeNet("data_folder", split="train")<br/>&gt;&gt;&gt; dataset[0]<br/>Data(pos=[5023, 3], x=[5023, 3], y=[5023])</span></pre><p id="787b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们所有的数据集都生成了<em class="lb">数据</em>对象，这是保存点的位置和特征的张量的简单结构<em class="lb"> data.pos </em>和<em class="lb"> data.x </em>(它们实际上是PyTorch几何数据对象)。这里<em class="lb">位置</em>是原始3D位置，而<em class="lb"> x </em>是每个点的法向量。在训练期间，<em class="lb">数据</em>对象还包含标签<em class="lb"> y </em>以及特定模型或任务可能需要的任何其他信息。</p><h1 id="7b10" class="mr ms iq bd mt mu np mw mx my nq na nb jw nr jx nd jz ns ka nf kc nt kd nh ni bi translated">数据处理流水线</h1><p id="6d7c" class="pw-post-body-paragraph kf kg iq kh b ki nj jr kk kl nk ju kn ko nl kq kr ks nm ku kv kw nn ky kz la ij bi translated">数据处理管道是任何深度学习模型的关键组件。PyTorch Geometric 已经提供了许多有用的变换函数，我们已经用额外的3D特性丰富了这些函数；你可以在<a class="ae le" href="https://torch-points3d.readthedocs.io/en/latest/src/api/transforms.html#" rel="noopener ugc nofollow" target="_blank">这个链接</a>找到名单。除了这种大范围的数据转换，我们还添加了助手来直接从yaml配置文件实例化数据管道。这使得数据扩充成为一个透明的过程，这反过来又提高了可重复性，并使现有模型的调整更加容易。典型的配置文件如下所示:</p><pre class="lg lh li lj gt nv nw nx ny aw nz bi"><span id="ad99" class="oa ms iq nw b gy ob oc l od oe">data:<br/>   class: shapenet.ShapeNetDataset<br/>   task: segmentation<br/>   dataroot: data<br/>   normal: True                     # Use normal vectors as features<br/>   first_subsampling: 0.02           # Grid size of the input data<br/>information<br/>   pre_transforms:                  # Offline transforms<br/>       - transform: NormalizeScale             <br/>       - transform: GridSampling<br/>         params:<br/>             size: ${data.first_subsampling}<br/>   train_transforms:                # Data augmentation pipeline<br/>       - transform: RandomNoise<br/>         params:<br/>           sigma: 0.01<br/>           clip: 0.05<br/>       - transform: RandomScaleAnisotropic<br/>         params:<br/>           scales: [0.9,1.1]</span></pre><h1 id="a087" class="mr ms iq bd mt mu np mw mx my nq na nb jw nr jx nd jz ns ka nf kc nt kd nh ni bi translated">卷积核</h1><p id="689e" class="pw-post-body-paragraph kf kg iq kh b ki nj jr kk kl nk ju kn ko nl kq kr ks nm ku kv kw nn ky kz la ij bi translated">大多数基于点的卷积网络借用了通用编码器/解码器的思想(或仅编码器)。编码器在密集的点云上操作，随着我们越深入，在每一层或每一组层之后，密集的点云被迭代地抽取。点本身支持特征向量，从一层到下一层通常需要两步:</p><ul class=""><li id="ac68" class="lv lw iq kh b ki kj kl km ko lx ks ly kw lz la no mb mc md bi translated">向下采样点云；</li><li id="1329" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la no mb mc md bi translated">对于下采样点云中的每个点，基于其在先前点云中的邻居的特征来计算特征向量。</li></ul><p id="ce58" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">简而言之，网络越深，点就越少，但相关的要素就越丰富。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi of"><img src="../Images/7c9520e769633186294a59dfed7e6b84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WaE8FP0ebP128L2gwdO8pQ.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">点云的典型编码过程。每盏灯代表来自给定层的点云，红色球体突出显示来自前一层的哪些点用于构建新的特征向量(图像来源:Hugues Thomas)。</p></figure><p id="3ce1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们的框架支持三种可互换的采样策略:随机采样、最远点采样和网格采样。对于邻居搜索，大多数网络使用具有固定半径或k近邻的邻居。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/9ec7decc9e8d743f0cea06a519f7a9d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*paVq0-JB-ZL1FX12dgXGaQ.gif"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">KPConv模式中不同层次的网格采样。</p></figure><p id="dd98" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Torch Points3D是在模块化的理念下创建的。我们为各种模型的卷积核补充了采样策略和邻居搜索算法，作为独立模块，可以包含在您自己的架构中。截至目前，以下模块可用:</p><ul class=""><li id="3724" class="lv lw iq kh b ki kj kl km ko lx ks ly kw lz la no mb mc md bi translated"><a class="ae le" href="https://arxiv.org/abs/1706.02413" rel="noopener ugc nofollow" target="_blank"> Pointnet++ </a></li><li id="c1a1" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la no mb mc md bi translated"><a class="ae le" href="https://yochengliu.github.io/Relation-Shape-CNN/" rel="noopener ugc nofollow" target="_blank">关系-形状CNN </a></li><li id="7eb8" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la no mb mc md bi translated"><a class="ae le" href="https://github.com/HuguesTHOMAS/KPConv-PyTorch" rel="noopener ugc nofollow" target="_blank"> KPConv </a></li><li id="2a87" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la no mb mc md bi translated"><a class="ae le" href="https://github.com/StanfordVL/MinkowskiEngine" rel="noopener ugc nofollow" target="_blank">闵可夫斯基引擎</a>(通过官方python包)</li></ul><p id="f034" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">例如，可以创建一个步进KPConv卷积模块，如下所示:</p><pre class="lg lh li lj gt nv nw nx ny aw nz bi"><span id="6a4e" class="oa ms iq nw b gy ob oc l od oe">&gt;&gt;&gt; import torch_points3d.modules.KPConv.blocks as kpconv_modules<br/>&gt;&gt;&gt; kpconv_layer = kpconv_modules.SimpleBlock(<br/>                                    down_conv_nn = [64,128], <br/>                                    grid_size=0.1, <br/>                                    prev_grid_size=0.05<br/>                                   )</span><span id="edf5" class="oa ms iq nw b gy oh oc l od oe">&gt;&gt;&gt; kpconv_layer<br/>SimpleBlock(<br/>  GridSampling(grid_size=0.1),<br/>  RadiusNeighbourFinder(radius=0.125),<br/>  (kp_conv): KPConvLayer(InF: 64, OutF: 128, kernel_pts: 15, radius: 0.0),<br/>  (bn): BatchNorm1d(128, eps=1e-05, momentum=0.02),<br/>  (activation): LeakyReLU(negative_slope=0.1)<br/>)</span></pre><p id="93ed" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们的框架负责处理所有的细节。例如，它为卷积核和对应于该步进卷积的栅格采样操作符设置适当的参数。</p><p id="49fe" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">那些核心卷积方案<strong class="kh ir">都已经在语义分割任务上得到验证</strong>，并且已经与各自的作者密切合作再现了已发表的结果。我们计划在新的卷积方案发布后继续添加。</p><h1 id="f84a" class="mr ms iq bd mt mu np mw mx my nq na nb jw nr jx nd jz ns ka nf kc nt kd nh ni bi translated">应用程序接口</h1><p id="d736" class="pw-post-body-paragraph kf kg iq kh b ki nj jr kk kl nk ju kn ko nl kq kr ks nm ku kv kw nn ky kz la ij bi translated">我们已经开始通过一个易于使用的API来公开框架的一部分。目前，该API支持:</p><ul class=""><li id="5192" class="lv lw iq kh b ki kj kl km ko lx ks ly kw lz la no mb mc md bi translated">用于点云数据扩充的常见数据转换</li><li id="9162" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la no mb mc md bi translated">用于分段任务的通用数据集，具有批量整理功能和强大的指标跟踪器</li><li id="dff2" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la no mb mc md bi translated">用于KPConv、Pointnet++和Relation-Shape CNN的基于Unet架构的主干模型</li></ul><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/0062523ca3f28e6f20e71ded444e2ebb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/1*Xkam3MHJOXlPjJhSZnB8rA.gif"/></div></figure><p id="4501" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请参考<a class="ae le" href="https://torch-points3d.readthedocs.io" rel="noopener ugc nofollow" target="_blank">https://torch-points 3d . readthedocs . io</a>获取API的最新文档，或者看看我们可以在colab上运行的示例笔记本:</p><ul class=""><li id="5d85" class="lv lw iq kh b ki kj kl km ko lx ks ly kw lz la no mb mc md bi translated"><a class="ae le" href="https://github.com/nicolas-chaulet/torch-points3d/blob/master/notebooks/ObjectClassificationRSConv.ipynb" rel="noopener ugc nofollow" target="_blank">用关系形状分类3D物体CNN </a></li><li id="632d" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la no mb mc md bi translated"><a class="ae le" href="https://github.com/nicolas-chaulet/torch-points3d/blob/master/notebooks/PartSegmentationKPConv.ipynb" rel="noopener ugc nofollow" target="_blank">使用KPConv </a>分割对象的部分</li></ul></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><h1 id="c087" class="mr ms iq bd mt mu mv mw mx my mz na nb jw nc jx nd jz ne ka nf kc ng kd nh ni bi translated">最后的话</h1><p id="ee65" class="pw-post-body-paragraph kf kg iq kh b ki nj jr kk kl nk ju kn ko nl kq kr ks nm ku kv kw nn ky kz la ij bi translated">Torch Points3D是一个不断发展的框架，每天都会添加新功能，即将推出的一些功能包括:</p><ul class=""><li id="5788" class="lv lw iq kh b ki kj kl km ko lx ks ly kw lz la no mb mc md bi translated">集成更新的架构，如<a class="ae le" href="https://github.com/QingyongHu/RandLA-Net" rel="noopener ugc nofollow" target="_blank">RandLa-Net</a>；</li><li id="af7b" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la no mb mc md bi translated">集成更多任务，如点云配准、实例分割、图元拟合、离群点去除、点云完成等；</li><li id="1247" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la no mb mc md bi translated">通过我们的模型API可以直接访问预先训练的模型。</li></ul><p id="e5b7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们还要衷心感谢所有参与该项目的人，特别是来自欧洲富士通实验室的<a class="ae le" href="https://github.com/humanpose1" rel="noopener ugc nofollow" target="_blank"> Sofiane Horache </a>、<a class="ae le" href="https://github.com/HuguesTHOMAS" rel="noopener ugc nofollow" target="_blank"> Hugues Thomas </a>、<a class="ae le" href="https://github.com/tristanheywood" rel="noopener ugc nofollow" target="_blank"> Tristan Heywood </a>和R &amp; D团队。</p><h1 id="891a" class="mr ms iq bd mt mu np mw mx my nq na nb jw nr jx nd jz ns ka nf kc nt kd nh ni bi translated">参考</h1><h2 id="736f" class="oa ms iq bd mt oj ok dn mx ol om dp nb ko on oo nd ks op oq nf kw or os nh ot bi translated">模型</h2><p id="55c3" class="pw-post-body-paragraph kf kg iq kh b ki nj jr kk kl nk ju kn ko nl kq kr ks nm ku kv kw nn ky kz la ij bi translated"><a class="ae le" href="https://arxiv.org/abs/1706.02413" rel="noopener ugc nofollow" target="_blank"> PointNet++度量空间中点集的深度层次特征学习</a></p><p id="6240" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae le" href="https://arxiv.org/abs/1904.08889" rel="noopener ugc nofollow" target="_blank"> KPConv:点云的灵活可变形卷积</a></p><p id="4e57" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae le" href="https://arxiv.org/abs/1904.07601" rel="noopener ugc nofollow" target="_blank">用于点云分析的关系形状卷积神经网络</a></p><p id="f5cb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae le" href="https://arxiv.org/abs/1904.08755" rel="noopener ugc nofollow" target="_blank"> 4D时空卷积网络:闵可夫斯基卷积神经网络</a></p><p id="e08d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae le" href="https://arxiv.org/abs/1911.11236" rel="noopener ugc nofollow" target="_blank"> RandLA-Net:大规模点云的高效语义分割</a></p><h2 id="7fb4" class="oa ms iq bd mt oj ok dn mx ol om dp nb ko on oo nd ks op oq nf kw or os nh ot bi translated">数据集</h2><p id="2e51" class="pw-post-body-paragraph kf kg iq kh b ki nj jr kk kl nk ju kn ko nl kq kr ks nm ku kv kw nn ky kz la ij bi translated">ScanNet:室内场景的丰富注释3D重建</p><p id="f188" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae le" href="https://arxiv.org/abs/1702.01105" rel="noopener ugc nofollow" target="_blank">用于室内场景理解的联合2D-3D-语义数据</a></p><p id="f4f5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae le" href="https://arxiv.org/abs/1512.03012" rel="noopener ugc nofollow" target="_blank"> ShapeNet:一个信息丰富的3D模型库</a></p><p id="b4d3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae le" href="https://people.csail.mit.edu/khosla/papers/cvpr2015_wu.pdf" rel="noopener ugc nofollow" target="_blank"> 3D ShapeNets:体积形状的深层表示</a></p><p id="5574" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae le" href="http://3dmatch.cs.princeton.edu/" rel="noopener ugc nofollow" target="_blank"> 3DMatch:学习范围扫描中局部3D几何图形的匹配</a></p><h2 id="a2b0" class="oa ms iq bd mt oj ok dn mx ol om dp nb ko on oo nd ks op oq nf kw or os nh ot bi translated">外部库</h2><p id="708a" class="pw-post-body-paragraph kf kg iq kh b ki nj jr kk kl nk ju kn ko nl kq kr ks nm ku kv kw nn ky kz la ij bi translated"><a class="ae le" href="https://pytorch-geometric.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> PyTorch几何</a></p><p id="2c09" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae le" href="https://hydra.cc/" rel="noopener ugc nofollow" target="_blank">九头蛇核心</a></p></div></div>    
</body>
</html>