<html>
<head>
<title>What, Why and How of t-SNE</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">SNE 霸王龙是什么，为什么和怎样</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-why-and-how-of-t-sne-1f78d13e224d?source=collection_archive---------10-----------------------#2020-05-19">https://towardsdatascience.com/what-why-and-how-of-t-sne-1f78d13e224d?source=collection_archive---------10-----------------------#2020-05-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/1135accc19abb67fea906217563b8f20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*snpxvbVpqYLK2XHkHCEfIQ.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">t-SNE 简介(图片来自<a class="ae jd" href="https://pixabay.com/photos/light-bulb-light-halogen-bulb-lamp-1407610/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><div class=""/><p id="017b" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">想象一下我们一天创造的数据；产生的新闻、帖子、视频、社交媒体平台上的图片、沟通渠道上的消息、有助于商业发展的网站等等……巨大无比！对吗？</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/5e918ef059759ddc4899529bd133f31c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9GgRjfh_ZASGTftLX5urvQ.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">巨大！对吗？图片来自<a class="ae jd" href="https://pixabay.com/photos/mammal-elephant-wildlife-animal-3218712/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><p id="1359" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，想象一下分析这些海量数据并获得有用的见解以做出数据驱动的决策的任务。复杂！对吗？</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/0afa0b9e4d4941ab786fe550e406bcce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RC3NZhKX-yXKVC6JlD16bg.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">复杂！对吗？图片来自<a class="ae jd" href="https://pixabay.com/photos/beach-surfing-wave-ocean-outdoors-1836366/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><p id="aba5" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于这个问题，我们可以做的是删除冗余信息，只分析影响大的信息。<br/> <strong class="kf jh"> <em class="lf">降维</em> </strong> <em class="lf"> </em>在任何数据分析或数据可视化的最初阶段都会出现。</p><blockquote class="lg"><p id="3a50" class="lh li jg bd lj lk ll lm ln lo lp la dk translated"><strong class="ak"> <em class="lq">降维</em> </strong>是将数据投影到一个更低维度的空间，这样更便于数据的分析和可视化。然而，维度的减少需要在准确性(高维)和可解释性(低维)之间进行权衡。</p></blockquote><p id="772c" class="pw-post-body-paragraph kd ke jg kf b kg lr ki kj kk ls km kn ko lt kq kr ks lu ku kv kw lv ky kz la ij bi translated">但这里的关键是保留最大方差特征，消除冗余特征。</p><p id="779c" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh">在本文中，我们将重点讨论 t-SNE 降维的原因、内容、方式以及非内容。</strong></p><p id="fcdd" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面是讨论的流程:</p><ol class=""><li id="5d2e" class="lw lx jg kf b kg kh kk kl ko ly ks lz kw ma la mb mc md me bi translated">为什么不是 PCA？为什么是 t-SNE？</li><li id="82a5" class="lw lx jg kf b kg mf kk mg ko mh ks mi kw mj la mb mc md me bi translated">什么是 t-SNE？</li><li id="e4a2" class="lw lx jg kf b kg mf kk mg ko mh ks mi kw mj la mb mc md me bi translated">SNE 霸王龙是如何工作的？</li><li id="f0c3" class="lw lx jg kf b kg mf kk mg ko mh ks mi kw mj la mb mc md me bi translated">如何实现 t-SNE？</li><li id="ca07" class="lw lx jg kf b kg mf kk mg ko mh ks mi kw mj la mb mc md me bi translated">如何有效使用 tSNE？</li></ol></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><h1 id="a8ef" class="mr ms jg bd mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no bi translated"><strong class="ak"> <em class="lq">为什么不是 PCA？为什么是 t-SNE？</em> </strong></h1><p id="1a13" class="pw-post-body-paragraph kd ke jg kf b kg np ki kj kk nq km kn ko nr kq kr ks ns ku kv kw nt ky kz la ij bi translated">说到降维，PCA 出名是因为它简单、快速、易用，并且保留了数据集的<strong class="kf jh">总体方差</strong>。关于 PCA 的更多信息，请查看<a class="ae jd" rel="noopener" target="_blank" href="/pca-in-a-single-line-of-code-ed79ae42059b">和</a>。</p><p id="9925" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然 PCA 很棒，但它也有一些缺点。PCA 的一个主要缺点是它没有保留<strong class="kf jh">非线性方差</strong>。这意味着 PCA 将无法得到这样的结果。</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/5fa4ee08b70afb304c3ae3aad4d8a5e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:554/format:webp/1*WerLzyRhw2Ugluh0e0fmSg.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">三叶形结。</p></figure><p id="53d7" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">简单来说，PCA 只保留<strong class="kf jh">全局方差</strong>，因此保留<strong class="kf jh">局部方差</strong>是 t-SNE 背后的动机。</p></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><h1 id="e3f8" class="mr ms jg bd mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no bi translated"><strong class="ak"> <em class="lq">什么是 t-SNE？</em> </strong></h1><p id="1e01" class="pw-post-body-paragraph kd ke jg kf b kg np ki kj kk nq km kn ko nr kq kr ks ns ku kv kw nt ky kz la ij bi translated">t-SNE 是一种<strong class="kf jh">非线性降维</strong>技术，非常适合将高维数据嵌入到低维数据(2D 或 3D)中进行数据可视化。</p><p id="ecd3" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">t-SNE 代表<strong class="kf jh"> t 分布随机邻居嵌入</strong>，它讲述了以下内容:<br/>随机→不确定但随机概率<br/>邻居→只关心保留邻居点的方差<br/>嵌入→将数据绘制到更低的维度</p><p id="535a" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">简而言之，t-SNE 是一种机器学习算法，每次在相同的数据集上生成略有不同的结果，专注于保留邻居点的结构。</p><h2 id="8190" class="nv ms jg bd mt nw nx dn mx ny nz dp nb ko oa ob nf ks oc od nj kw oe of nn og bi translated">超参数调谐</h2><p id="84c3" class="pw-post-body-paragraph kd ke jg kf b kg np ki kj kk nq km kn ko nr kq kr ks ns ku kv kw nt ky kz la ij bi translated">2 能高度影响结果的参数有<br/> a) <em class="lf"> n_iter: </em>算法运行的迭代次数<br/> b) <em class="lf">困惑度:</em>这可以认为是 t-SNE 必须考虑的邻点数</p></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><h1 id="d2fb" class="mr ms jg bd mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no bi translated"><strong class="ak"><em class="lq">t-SNE 是如何工作的？</em> </strong></h1><p id="e6ed" class="pw-post-body-paragraph kd ke jg kf b kg np ki kj kk nq km kn ko nr kq kr ks ns ku kv kw nt ky kz la ij bi translated"><strong class="kf jh">步骤 1: </strong> t-SNE 在更高维度中构建成对的概率分布，使得相似的对象被分配较高的概率，而不相似的对象被分配较低的概率。</p><p id="e968" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh">步骤 2: </strong>然后，t-SNE 在较低维度上迭代复制相同的概率分布，直到库尔巴克-莱布勒散度最小化。</p><p id="1a02" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lf"> Kullback-Leibler 散度</em>是衡量第一步和第二步的概率分布之间的差异。KL 散度在数学上被给出为这些概率分布的差的对数的期望值。</p></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><h1 id="b5d3" class="mr ms jg bd mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no bi translated">如何实现 t-SNE</h1><p id="1452" class="pw-post-body-paragraph kd ke jg kf b kg np ki kj kk nq km kn ko nr kq kr ks ns ku kv kw nt ky kz la ij bi translated">在本节中，让我们使用来自 Kaggle 的数字识别器数据集，使用 t-SNE 进行维数约简。</p><div class="ip iq gp gr ir oh"><a href="https://www.kaggle.com/c/digit-recognizer" rel="noopener  ugc nofollow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd jh gy z fp om fr fs on fu fw jf bi translated">数字识别器</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">用著名的 MNIST 数据学习计算机视觉基础</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">www.kaggle.com</p></div></div><div class="oq l"><div class="or l os ot ou oq ov ix oh"/></div></div></a></div><p id="73f2" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh"> <em class="lf">数据描述:</em> </strong></p><ul class=""><li id="f2fb" class="lw lx jg kf b kg kh kk kl ko ly ks lz kw ma la ow mc md me bi translated">数据文件包含手绘数字的灰度图像，从 0 到 9。</li><li id="756f" class="lw lx jg kf b kg mf kk mg ko mh ks mi kw mj la ow mc md me bi translated">每幅图像高 28 像素，宽 28 像素，总共 784 像素。每个像素都有一个与之关联的像素值，表示该像素的亮度或暗度，数字越大表示越暗。该像素值是 0 到 255 之间的整数，包括 0 和 255。</li><li id="d627" class="lw lx jg kf b kg mf kk mg ko mh ks mi kw mj la ow mc md me bi translated">训练数据集(train.csv)有 785 列。第一列称为“标签”，是用户绘制的数字。其余的列包含相关图像的像素值。<br/>数据集中的每个像素列都有一个类似 pixelx 的名称，其中 x 是 0 到 783 之间的整数，包括 0 和 783。为了在图像上定位这个像素，假设我们将 x 分解为 x = i * 28 + j，其中 I 和 j 是 0 到 27 之间的整数，包括 0 和 27。那么 pixelx 位于 28×28 矩阵的第 I 行和第 j 列(由零索引)。</li></ul><p id="93b7" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh"> <em class="lf">加载数据:</em> </strong></p><pre class="lb lc ld le gt ox oy oz pa aw pb bi"><span id="1c7d" class="nv ms jg oy b gy pc pd l pe pf">import pandas as pd<br/>mnist_data = pd.read_csv("mnist.csv")</span></pre><p id="6e93" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用 Pandas 将 CSV 格式(逗号分隔值)的数据文件加载到数据框中。</p><pre class="lb lc ld le gt ox oy oz pa aw pb bi"><span id="2b47" class="nv ms jg oy b gy pc pd l pe pf">mnist_data.shape</span></pre><p id="e1d5" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">输出:(42000，785)</p><p id="49e4" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">查看数据，我们发现有 42，000 个数据点和 785 个特征。</p><pre class="lb lc ld le gt ox oy oz pa aw pb bi"><span id="363d" class="nv ms jg oy b gy pc pd l pe pf">mnist_data.head()</span></pre><p id="f1f2" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">输出:</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pg"><img src="../Images/b426d24b9cf5ca50e7caf4eaff910a13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*u40qvjMiRjjY0SGT.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">mnist_data 中的前 5 个数据点</p></figure><p id="2835" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第一列标签是目标变量。剩下的 784 列是特征。</p><pre class="lb lc ld le gt ox oy oz pa aw pb bi"><span id="2355" class="nv ms jg oy b gy pc pd l pe pf">target_variable = mnist_data["label"]<br/>features_variable=mnist_data.drop("label",axis=1)</span></pre><p id="3be8" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">将标签列分配给<em class="lf">目标变量</em>，将剩余列分配给<em class="lf">特征变量</em>。</p><pre class="lb lc ld le gt ox oy oz pa aw pb bi"><span id="83b4" class="nv ms jg oy b gy pc pd l pe pf">print(target_variable.shape)<br/>print(features_variable.shape)</span></pre><p id="6cc6" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">输出:(42000，)<br/> (42000，784)</p><p id="90d4" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，让我们看看这个<em class="lf">特征变量</em>是如何使用 t-SNE 减少 42000 个数据点和 784 个特征的。</p></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><p id="e32e" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh"> <em class="lf">利用 t-SNE 实现降维:</em> </strong></p><p id="b754" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh">第一步:</strong>数据标准化</p><pre class="lb lc ld le gt ox oy oz pa aw pb bi"><span id="5496" class="nv ms jg oy b gy pc pd l pe pf">from sklearn.preprocessing import StandardScaler<br/>standarized_data = StandardScaler().fit_transform(features_variable)</span></pre><p id="1069" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用<em class="lf">标准定标器()。fit_transform( ) </em>，数据可以一步标准化。</p><p id="375f" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh">步骤 2: </strong>对标准化数据应用 t-SNE</p><pre class="lb lc ld le gt ox oy oz pa aw pb bi"><span id="e726" class="nv ms jg oy b gy pc pd l pe pf">from sklearn.manifold import TSNE<br/>model = TSNE(n_components=2, random_state=0,perplexity=50, n_iter=5000)<br/>tsne_data = model.fit_transform(standarized_data)</span></pre><p id="3351" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这里，我们创建一个 TSNE 的对象，并设置<em class="lf">困惑</em>和 n_iter 值。我们对标准化数据使用了<em class="lf"> fit_transform( ) </em>方法，通过 t-SNE 得到降维数据。</p><p id="4d24" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了验证这一点，让我们打印 tsne_data 的形状</p><pre class="lb lc ld le gt ox oy oz pa aw pb bi"><span id="dc84" class="nv ms jg oy b gy pc pd l pe pf">print(standarized_data.shape)<br/>print(tsne_data.shape)</span></pre><p id="e549" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">输出:(42000，784) <br/> (42000，2)</p><p id="a8a8" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在可以一起玩各种<em class="lf">困惑</em>和<em class="lf"> n_iter </em>来观察结果。</p></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><h1 id="8b6a" class="mr ms jg bd mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no bi translated"><strong class="ak"> <em class="lq">如何有效利用 t-SNE？</em>T29】</strong></h1><ol class=""><li id="416e" class="lw lx jg kf b kg np kk nq ko ph ks pi kw pj la mb mc md me bi translated">t-SNE 图受参数的影响很大。因此，在分析结果之前，有必要使用不同的参数值执行 t-SNE。</li><li id="347b" class="lw lx jg kf b kg mf kk mg ko mh ks mi kw mj la mb mc md me bi translated">由于 t-SNE 是随机的，每次运行可能会导致略有不同的输出。这可以通过固定所有运行的<em class="lf"> random_state </em>参数值来解决。</li><li id="a44c" class="lw lx jg kf b kg mf kk mg ko mh ks mi kw mj la mb mc md me bi translated">SNE 霸王龙没有保留原始数据中聚类之间的距离。t-SNE 降维后，聚类之间的距离可能会发生变化。建议不要仅从集群之间的距离获得任何结论。</li><li id="6cca" class="lw lx jg kf b kg mf kk mg ko mh ks mi kw mj la mb mc md me bi translated">t-SNE 压缩广泛传播的数据，扩展密集包装的数据。因此，建议不要基于输出来决定聚类的大小和密度/分布/方差。</li><li id="094b" class="lw lx jg kf b kg mf kk mg ko mh ks mi kw mj la mb mc md me bi translated">更低的<em class="lf">困惑度</em>值可能导致更少的聚类。因此，建议尝试不同的<em class="lf">困惑</em>值，范围从 2 到数据点数，以获得更好的结果。</li></ol></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><p id="9c9d" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh">T37】资源:T39】</strong></p><p id="810b" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这篇<a class="ae jd" href="https://distill.pub/2016/misread-tsne/#perplexity=10&amp;epsilon=5&amp;demo=0&amp;demoParams=20" rel="noopener ugc nofollow" target="_blank">博客文章</a>由 distill.pub 在谷歌大脑的支持下完成。<br/>一定要看看这个博客，了解更多关于 t-SNE 如何有效地帮助减少可视化的各种数据模式的见解。</p></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><p id="6c0a" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">谢谢你的阅读。以后我会写更多初学者友好的帖子。请在<a class="ae jd" href="https://medium.com/@ramyavidiyala" rel="noopener">媒体</a>上关注我，以便了解他们。我欢迎反馈，可以通过 Twitter <a class="ae jd" href="https://twitter.com/ramya_vidiyala" rel="noopener ugc nofollow" target="_blank"> ramya_vidiyala </a>和 LinkedIn <a class="ae jd" href="https://www.linkedin.com/in/ramya-vidiyala-308ba6139/" rel="noopener ugc nofollow" target="_blank"> RamyaVidiyala </a>联系我。快乐学习！</p></div></div>    
</body>
</html>