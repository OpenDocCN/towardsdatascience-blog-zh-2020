<html>
<head>
<title>Running an Apache Beam Data Pipeline on Azure Databricks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Azure Databricks上运行Apache Beam数据管道</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/running-an-apache-beam-data-pipeline-on-azure-databricks-c09e521d8fc3?source=collection_archive---------27-----------------------#2020-06-03">https://towardsdatascience.com/running-an-apache-beam-data-pipeline-on-azure-databricks-c09e521d8fc3?source=collection_archive---------27-----------------------#2020-06-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="d883" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">简要介绍如何在Databricks上执行Apache Beam管道</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/8197d1a21603e67066751832db3fb57b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FEsHPZM9BjQ0xkBNjSeniA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><a class="ae le" href="https://github.com/Stefn93/BeamOnDatabricks" rel="noopener ugc nofollow" target="_blank"> Github资源库</a>链接到本文</p></figure><h1 id="9fd7" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">介绍</h1><p id="d545" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">当我们想到数据并行管道时，Apache Spark立即浮现在脑海中，但也有一些更有前途、更新颖的模型能够实现相同的结果和性能。</p><p id="fb2b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这就是<a class="ae le" href="https://beam.apache.org/get-started/beam-overview/" rel="noopener ugc nofollow" target="_blank"> Apache Beam </a>的情况，它是一个开源的统一模型，用于定义批处理和流数据并行处理管道。它提供了以一种方便的方式定义数据管道的可能性，使用其分布式处理后端之一作为运行时(<a class="ae le" href="https://apex.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Apex </a>、<a class="ae le" href="https://flink.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Flink </a>、<a class="ae le" href="http://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Spark </a>、<a class="ae le" href="https://cloud.google.com/dataflow" rel="noopener ugc nofollow" target="_blank"> Google Cloud Dataflow </a>以及许多其他)。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/b618d6a2254ccc36434fb6b940c6852f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*EexoH3fCWMEcOD_etQ16ag.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="6876" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae le" href="https://beam.apache.org/documentation/runners/capability-matrix/" rel="noopener ugc nofollow" target="_blank"> Apache Beam的强大功能</a>在于更高层次的抽象，这可以防止程序员学习多个框架。<br/>目前，Apache Beam的使用主要局限于谷歌云平台，尤其是谷歌云数据流。</p><p id="4735" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然而，当转移到其他平台时，可能很难找到一些有用的参考资料和例子来帮助我们运行Apache Beam管道。</p><p id="b1de" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这就是为什么我想告诉你我如何在Databricks上运行Apache Beam管道的经验。</p><h1 id="d5b9" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">让我们建立我们的阿帕奇光束管道</h1><p id="15c2" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">注意:这个演练的代码可以在<a class="ae le" href="https://github.com/Stefn93/BeamOnDatabricks" rel="noopener ugc nofollow" target="_blank"> this Github repository </a>获得。</p><p id="2718" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我决定从官方的<a class="ae le" href="https://github.com/apache/beam/blob/master/runners/spark/src/main/java/org/apache/beam/runners/spark/examples/WordCount.java" rel="noopener ugc nofollow" target="_blank"> Apache Beam的Wordcount </a>例子开始，改变一些细节，以便在Databricks上执行我们的管道。</p><p id="5584" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">官方代码只是从<a class="ae le" href="https://cloud.google.com/storage" rel="noopener ugc nofollow" target="_blank"> Google云存储</a>中读取一个公共文本文件，对输入文本进行字数统计，并将输出写入给定的路径。为了简化这个过程，我们将通过简单地从代码内模拟的字符串中读取输入文本来代替这些操作，最后将字数统计结果打印到标准输出中。</p><p id="7ad3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">输入字符串将被定义为列表:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="mj mk l"/></div></figure><p id="08f5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后我们创建一个简单的<a class="ae le" href="https://beam.apache.org/documentation/programming-guide/#core-beam-transforms" rel="noopener ugc nofollow" target="_blank">光束自定义DoFn变换</a>来打印我们的结果:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="mj mk l"/></div></figure><p id="9c0c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们最终的管道将是这样的:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="mj mk l"/></div></figure><p id="dbcd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们现在有了一个可以在本地模式下执行的工作射束管道。<br/>如果您尝试运行它，您应该看到它打印成您的标准输出:</p><pre class="kp kq kr ks gt ml mm mn mo aw mp bi"><span id="0d4a" class="mq lg it mm b gy mr ms l mt mu">20/06/01 13:14:13 INFO transforms.PrintFN: against: 1<br/>20/06/01 13:14:13 INFO transforms.PrintFN: and: 1<br/>20/06/01 13:14:13 INFO transforms.PrintFN: of: 2<br/>20/06/01 13:14:13 INFO transforms.PrintFN: troubles: 1<br/>20/06/01 13:14:13 INFO transforms.PrintFN: nobler: 1<br/>20/06/01 13:14:13 INFO transforms.PrintFN: arrows: 1<br/>20/06/01 13:14:13 INFO transforms.PrintFN: suffer: 1<br/>20/06/01 13:14:13 INFO transforms.PrintFN: sea: 1<br/>20/06/01 13:14:13 INFO transforms.PrintFN: The: 1<br/>20/06/01 13:14:13 INFO transforms.PrintFN: Or: 1<br/>20/06/01 13:14:13 INFO transforms.PrintFN: not: 1<br/>20/06/01 13:14:13 INFO transforms.PrintFN: slings: 1<br/>20/06/01 13:14:13 INFO transforms.PrintFN: that: 1<br/>20/06/01 13:14:13 INFO transforms.PrintFN: is: 1<br/>20/06/01 13:14:13 INFO transforms.PrintFN: arms: 1<br/>20/06/01 13:14:13 INFO transforms.PrintFN: Whether: 1<br/>20/06/01 13:14:13 INFO transforms.PrintFN: a: 1<br/>20/06/01 13:14:13 INFO transforms.PrintFN: fortune: 1<br/>20/06/01 13:14:13 INFO transforms.PrintFN: take: 1<br/>20/06/01 13:14:13 INFO transforms.PrintFN: question: 1<br/>20/06/01 13:14:13 INFO transforms.PrintFN: To: 1<br/>20/06/01 13:14:13 INFO transforms.PrintFN: mind: 1<br/>20/06/01 13:14:13 INFO transforms.PrintFN: to: 3<br/>20/06/01 13:14:13 INFO transforms.PrintFN: outrageous: 1<br/>20/06/01 13:14:13 INFO transforms.PrintFN: or: 1<br/>20/06/01 13:14:13 INFO transforms.PrintFN: tis: 1<br/>20/06/01 13:14:13 INFO transforms.PrintFN: in: 1<br/>20/06/01 13:14:13 INFO transforms.PrintFN: the: 2<br/>20/06/01 13:14:13 INFO transforms.PrintFN: be: 2</span></pre></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="53e9" class="lf lg it bd lh li nc lk ll lm nd lo lp lq ne ls lt lu nf lw lx ly ng ma mb mc bi translated">现在，让我们转到数据块</h1><p id="999b" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">现在，我们想在Databricks实例上执行我们的管道。为了实现这一点，我们需要修改代码中的一些东西。首先，我们修改我们的<em class="nh"> WordCountOptions，</em>，它必须扩展<em class="nh"> SparkContextOptions类</em>。为了操作光束的<em class="nh"> SparkContext </em>，这些光束选项是必要的。Databricks集群有自己的SparkContext，这对检索至关重要，以便扩展应用程序。一旦我们检索到SparkContext，我们可以直接将其注入到Beam的<em class="nh"> SparkContextOptions </em>中，如下所示:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="mj mk l"/></div></figure><p id="8ee2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">有了这个Beam代码的最终版本，我们现在可以在Azure中启动我们的Databricks工作区，并继续创建一个新的作业。<br/>我们将我们的项目打包到一个fat jar中(在本例中，我将使用标准的maven生命周期来打包我的应用程序)，并通过单击“Upload Jar”将它上传到我们的作业中。</p><p id="f330" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请注意，<strong class="js iu"> </strong>如果您的<a class="ae le" href="https://github.com/Stefn93/BeamOnDatabricks/blob/master/pom.xml" rel="noopener ugc nofollow" target="_blank"> <em class="nh"> pom.xml </em> </a>文件中有任何<em class="nh"> Spark </em>依赖项，请记住将它们标记为"<strong class="js iu"> provided </strong> " <strong class="js iu">，</strong>，因为我们的Databricks集群将通过执行上下文将它们提供给我们的应用程序。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/1e248ab87ba6288f619c91134bba4c55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*d4Kzz2jZWYYWspw9Ge5QUg.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">Jar上传</p></figure><p id="fbb4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">指定主类后，使用这些将由<em class="nh"> SparkContextOptions: </em>解析的参数是很重要的</p><pre class="kp kq kr ks gt ml mm mn mo aw mp bi"><span id="07b3" class="mq lg it mm b gy mr ms l mt mu">--runner=SparkRunner --usesProvidedSparkContext</span></pre><p id="ee71" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最后，我们可以通过点击<em class="nh">编辑</em>来设置将与我们的作业相关联的集群:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nj"><img src="../Images/0b70cc0dcbbe03c5a789955f86a50dba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UmrSzE31ly__34vwe6y85A.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">集群配置</p></figure><p id="9e1c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这样，我们在Databricks运行时版本<em class="nh"> 6.4 </em>上定义了一个“<a class="ae le" href="https://docs.microsoft.com/en-us/azure/databricks/clusters/" rel="noopener ugc nofollow" target="_blank"> <em class="nh">新的自动化集群</em> </a>”和2个工人。如果您愿意，您还可以创建一个“交互式集群”，这样您可以更好地控制集群的执行。</p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><p id="99e2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，我们可以走了！<br/>如果您的工作看起来与下图相似，只需点击“<em class="nh">立即运行</em>”，然后等待其终止。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nk"><img src="../Images/d780f83fa97e297d16629246ce7dbb4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7uyIr522EaAUc4_jZJ7_Kg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">运行Apache Beam管道的Databricks作业示例</p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nl"><img src="../Images/9b72562dcd4ce9fe6f09da4156eba2eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IF3B1g8-_ilATCJFvPZhFw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">终止后的执行状态</p></figure><p id="3cdb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请注意，如果您已经用<em class="nh"> python </em>编写了您的Beam管道，那么让它在数据块上工作的过程应该看起来或多或少是相同的:<br/>只需记住将数据块'<em class="nh"> SparkContext </em>注入到Beam中，并使用正确的参数集执行您的管道。</p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><p id="947f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我希望你喜欢我关于如何在Azure Databricks上运行Apache Beam管道的演练<em class="nh">,如果你找到了关于这个主题的更多有用的见解，请随时联系我！</em></p></div></div>    
</body>
</html>