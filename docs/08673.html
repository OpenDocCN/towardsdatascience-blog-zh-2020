<html>
<head>
<title>Sketch-to-Color Image Generation | GANs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">草图到彩色图像生成| GANs</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generative-adversarial-networks-gans-89ef35a60b69?source=collection_archive---------12-----------------------#2020-06-23">https://towardsdatascience.com/generative-adversarial-networks-gans-89ef35a60b69?source=collection_archive---------12-----------------------#2020-06-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="62d9" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">GANS系列</h2><div class=""/><div class=""><h2 id="d487" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">2-学习使用条件GANs构建草图到颜色图像生成模型</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/cc1a4d98c03425a181008e0cd234a611.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*-FnxXrH-ZiWlmIenM6-NvQ.gif"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">150个纪元后发电机模型的输出(Gif由作者制作)</p></figure><p id="41c6" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">本文是我在towards data sciences on media上发表的<a class="ae md" href="https://towardsdatascience.com/tagged/gans-series" rel="noopener" target="_blank"><strong class="lj jd"><em class="me">Gans-Series</em></strong></a>的一部分。如果您不知道什么是赶工，或者您对赶工有一个想法，但希望很快再复习一遍，我强烈建议您阅读<a class="ae md" rel="noopener" target="_blank" href="/generative-adversarial-networks-gans-8fc303ad5fa1"> <strong class="lj jd"> <em class="me">之前的文章</em></strong></a><strong class="lj jd"><em class="me"/></strong>，这只是一篇7分钟的阅读，为刚接触这一令人惊叹的深度学习领域的人提供了对赶工的简单理解。</p><p id="3dcf" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如您从上面显示的gif中所知，本文将学习如何创建条件GAN，以便在不了解实际情况的情况下，根据给定的黑白草图输入预测彩色图像。</p><h1 id="ec34" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">在进入编码模式之前，一些需要知道的事情…</h1><p id="233c" class="pw-post-body-paragraph lh li it lj b lk mx kd lm ln my kg lp lq mz ls lt lu na lw lx ly nb ma mb mc im bi translated">草图到彩色图像生成是一种使用条件生成对抗网络的图像到图像翻译模型，如Phillip Isola、朱俊彦、周廷辉、Alexei A. Efros 2016、<strong class="lj jd"><em class="me"/></strong><a class="ae md" href="https://arxiv.org/abs/1611.07004" rel="noopener ugc nofollow" target="_blank"><strong class="lj jd"><em class="me">等在原论文中所述。</em></strong></a></p><p id="8850" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">当我第一次看到这篇论文时，看到作者展示的如此伟大的成果是令人惊讶的，基本的想法本身也是令人惊讶的。</p><h2 id="6c7a" class="nc mg it bd mh nd ne dn ml nf ng dp mp lq nh ni mr lu nj nk mt ly nl nm mv iz bi translated">应用程序</h2><p id="36eb" class="pw-post-body-paragraph lh li it lj b lk mx kd lm ln my kg lp lq mz ls lt lu na lw lx ly nb ma mb mc im bi translated">作者在原论文中描述了许多条件遗传算法的应用场景。部分选择如下。</p><ul class=""><li id="2d3e" class="nn no it lj b lk ll ln lo lq np lu nq ly nr mc ns nt nu nv bi translated"><strong class="lj jd">航空照片地图，航空照片地图</strong></li><li id="5e11" class="nn no it lj b lk nw ln nx lq ny lu nz ly oa mc ns nt nu nv bi translated"><strong class="lj jd">拍照城市风景</strong></li><li id="22da" class="nn no it lj b lk nw ln nx lq ny lu nz ly oa mc ns nt nu nv bi translated"><strong class="lj jd">照片的建筑立面标签</strong></li><li id="ae86" class="nn no it lj b lk nw ln nx lq ny lu nz ly oa mc ns nt nu nv bi translated"><strong class="lj jd">白天到晚上的照片</strong></li><li id="10bb" class="nn no it lj b lk nw ln nx lq ny lu nz ly oa mc ns nt nu nv bi translated"><strong class="lj jd">照片修复</strong></li><li id="61ac" class="nn no it lj b lk nw ln nx lq ny lu nz ly oa mc ns nt nu nv bi translated"><strong class="lj jd">彩色图像草图</strong> <em class="me">(我们将在本文中构建的那个)</em></li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ob"><img src="../Images/68e95658f468118c87384ea000ada38a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nRTdhtJM-wpO2sUWsDfQvg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片来自Phillip Isola，朱俊彦，周廷辉，Alexei A. Efros 2016，<a class="ae md" href="https://arxiv.org/abs/1611.07004" rel="noopener ugc nofollow" target="_blank">条件敌对网络下的图像间翻译</a></p></figure></div><div class="ab cl oc od hx oe" role="separator"><span class="of bw bk og oh oi"/><span class="of bw bk og oh oi"/><span class="of bw bk og oh"/></div><div class="im in io ip iq"><p id="de24" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi oj translated"><span class="l ok ol om bm on oo op oq or di">我们</span>将要建立一个条件生成对抗网络，它接受一个256x256 px的黑白草图图像，并在不知道基本事实的情况下预测该图像的彩色版本。该模型将在Kaggle上可用的<a class="ae md" href="https://www.kaggle.com/ktaebum/anime-sketch-colorization-pair" rel="noopener ugc nofollow" target="_blank"> <strong class="lj jd"> <em class="me">动漫素描着色对数据集</em> </strong> </a>上进行训练，该数据集包含14.2k对素描着色动漫图像。</p><blockquote class="os"><p id="88b2" class="ot ou it bd ov ow ox oy oz pa pb mc dk translated">当我在我的系统上训练模型时，我在单个GeForce GTX 1060 6GB显卡和16 GB RAM上运行了150个epochs，耗时约23小时。经过所有的努力和耐心，结果是完全值得的！</p></blockquote><figure class="pd pe pf pg ph kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pc"><img src="../Images/b5c9b174fd4b0f7d8a9b3c6322c72c48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sOHB4IYP-a1T2qBcZCoPow.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">经过训练的生成器模型的输出(图片由作者提供)</p></figure><h1 id="0a59" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">现在让我们进入有趣的部分…</h1><p id="3d30" class="pw-post-body-paragraph lh li it lj b lk mx kd lm ln my kg lp lq mz ls lt lu na lw lx ly nb ma mb mc im bi translated">为了构建这个模型，我使用了TensorFlow 2.x，大部分代码都是基于他们关于pix 2 pix for<a class="ae md" href="http://cmp.felk.cvut.cz/~tylecr1/facade/" rel="noopener ugc nofollow" target="_blank"><strong class="lj jd"><em class="me">CMP Facade Dataset</em></strong></a><strong class="lj jd"><em class="me"/></strong>的精彩教程，该教程从Facade标签预测建筑照片。TensorFlow教程是理解框架和从事一些知名项目的好方法。我强烈推荐你浏览网站上的所有教程—<a class="ae md" href="https://www.tensorflow.org/tutorials" rel="noopener ugc nofollow" target="_blank"><strong class="lj jd"><em class="me">https://www.tensorflow.org/tutorials</em></strong></a>。</p><h1 id="0359" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">要求</h1><p id="faf7" class="pw-post-body-paragraph lh li it lj b lk mx kd lm ln my kg lp lq mz ls lt lu na lw lx ly nb ma mb mc im bi translated">要构建这个模型，您需要在您的系统上安装一些基本要求，以便它能够正常工作。</p><ul class=""><li id="8aa9" class="nn no it lj b lk ll ln lo lq np lu nq ly nr mc ns nt nu nv bi translated"><a class="ae md" href="https://www.python.org/downloads/release/python-360/" rel="noopener ugc nofollow" target="_blank"><strong class="lj jd"><em class="me">Python 3.6</em></strong></a>及以上</li><li id="17ed" class="nn no it lj b lk nw ln nx lq ny lu nz ly oa mc ns nt nu nv bi translated"><a class="ae md" href="https://pypi.org/project/pip/" rel="noopener ugc nofollow" target="_blank"><strong class="lj jd"><em class="me">pip 19.0</em></strong></a>或更新</li><li id="6fe1" class="nn no it lj b lk nw ln nx lq ny lu nz ly oa mc ns nt nu nv bi translated">Windows 7或更高版本(64位)</li><li id="1812" class="nn no it lj b lk nw ln nx lq ny lu nz ly oa mc ns nt nu nv bi translated"><a class="ae md" href="https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads" rel="noopener ugc nofollow" target="_blank">适用于Visual Studio 2015、2017和2019的Microsoft Visual C++可再发行版</a></li><li id="3246" class="nn no it lj b lk nw ln nx lq ny lu nz ly oa mc ns nt nu nv bi translated"><a class="ae md" href="https://www.tensorflow.org/install/pip" rel="noopener ugc nofollow" target="_blank"><strong class="lj jd"><em class="me">tensor flow 2.2</em></strong></a>及以上</li><li id="9976" class="nn no it lj b lk nw ln nx lq ny lu nz ly oa mc ns nt nu nv bi translated"><a class="ae md" href="https://www.tensorflow.org/install/gpu" rel="noopener ugc nofollow" target="_blank"> <strong class="lj jd"> <em class="me"> GPU支持</em> </strong> </a>需要支持CUDA的卡</li></ul><p id="720f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果你计划使用任何像Google Colab这样的云环境，你需要记住训练将会花费很多时间，因为GANs运行起来计算量很大。Google Colab有12个小时的绝对超时，这意味着笔记本内核被重置，所以你需要考虑一些要点，如安装Google Drive并定期保存检查点，以便你可以从超时前停止的地方继续训练。</p><h1 id="335a" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">下载数据集</h1><p id="254f" class="pw-post-body-paragraph lh li it lj b lk mx kd lm ln my kg lp lq mz ls lt lu na lw lx ly nb ma mb mc im bi translated">下载Kaggle上的<a class="ae md" href="https://www.kaggle.com/ktaebum/anime-sketch-colorization-pair" rel="noopener ugc nofollow" target="_blank"> <strong class="lj jd"> <em class="me">动漫素描上色对数据集</em> </strong> </a>并保存到文件夹目录。根文件夹将包含文件夹<code class="fe pi pj pk pl b">colorgram</code>、<code class="fe pi pj pk pl b">train</code>和<code class="fe pi pj pk pl b">val</code>。为了方便起见，我们将根文件夹的路径称为<code class="fe pi pj pk pl b">path/to/dataset/</code>。</p><p id="7fea" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">一旦检查了基本要求，并且数据集被下载到您的机器上，就该开始编写您自己的条件GAN了。</p><p id="6438" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在我们开始之前，请注意，如果你想理解它背后的基本工作原理，我将要提供的代码不应该只是从这里复制和粘贴。不要犹豫提出你的问题，因为这是学习的方式——通过提问。</p><h1 id="2601" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">最后是代码！</h1><p id="812a" class="pw-post-body-paragraph lh li it lj b lk mx kd lm ln my kg lp lq mz ls lt lu na lw lx ly nb ma mb mc im bi translated">首先，让我们初始化参数来配置模型的训练。如前所述，我们将使用TensorFlow框架，因此我们需要通过使用<code class="fe pi pj pk pl b">import tensorflow as tf</code>来导入它。</p><p id="da9c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><code class="fe pi pj pk pl b">os</code>模块用于与操作系统交互。我们将使用它来访问和修改路径变量，以便在训练期间保存检查点。<code class="fe pi pj pk pl b">time</code>模块让我们显示相对时间，因此，我们可以检查每个历元在训练中花费了多少时间。</p><p id="80e2" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><code class="fe pi pj pk pl b">matplotlib</code>是另一个很酷的python库，我们将用它来绘制和显示图像。</p><p id="ea6a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><code class="fe pi pj pk pl b">BUFFER_SIZE</code>用于我们在训练时混洗数据样本。这个值越高，洗牌的程度就越大，因此，模型的准确性就越高。但是对于大数据，打乱图像需要很大的处理能力。对于采用英特尔酷睿i7–8750h CPU和16 GB内存的系统，可以将其设置为等于训练数据集样本的大小，即14，224。</p><blockquote class="pm pn po"><p id="9b62" class="lh li me lj b lk ll kd lm ln lo kg lp pp lr ls lt pq lv lw lx pr lz ma mb mc im bi translated">N <!-- -->注:<code class="fe pi pj pk pl b">shuffle()</code>的最高效率是当你设置buffer_size等于数据样本的大小时。通过这种方式，它获取主存储器中的所有样本[在本例中为14，224个]，并从中随机选择一个。如果你把它设置为10，它会从内存中取出10个样本，从这10个样本中随机选择一个，然后对其余的样本重复这个过程。所以，检查你的机器性能，找出最佳点。</p></blockquote><p id="9c1a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><code class="fe pi pj pk pl b">BATCH_SIZE</code>用于将数据集分成小批量进行训练。该值越高，训练过程越快。但是您可能已经猜到了，更大的批量意味着机器上更高的负载。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ps pt l"/></div></figure><p id="9bc7" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">现在，如果您看一下数据集，您有一个大小为1024x512 px的单个图像，其中左侧有一个大小为512x512 px的彩色图像，右侧有一个大小为512x512 px的黑白草图图像。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pu"><img src="../Images/19274c941c498d3fd3cfb34b6043a6bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5yf3cvV4fouSxyVJ4-k6ug.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">可视化数据(来自<a class="ae md" href="https://www.kaggle.com/ktaebum/anime-sketch-colorization-pair" rel="noopener ugc nofollow" target="_blank"> <em class="pv">动画草图-着色对数据集</em> </a>的图像)</p></figure><p id="41d4" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们将定义一个函数<code class="fe pi pj pk pl b">load()</code>，它将图像路径作为一个参数，并返回一个<code class="fe pi pj pk pl b">input_image</code>，它是我们将作为模型输入的黑白草图，以及一个<code class="fe pi pj pk pl b"> real_image</code>，它是我们想要的彩色图像。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ps pt l"/></div></figure><h2 id="318b" class="nc mg it bd mh nd ne dn ml nf ng dp mp lq nh ni mr lu nj nk mt ly nl nm mv iz bi translated">预处理</h2><p id="cba4" class="pw-post-body-paragraph lh li it lj b lk mx kd lm ln my kg lp lq mz ls lt lu na lw lx ly nb ma mb mc im bi translated">现在我们已经加载了数据，我们需要做一些预处理，以便为模型准备数据。</p><p id="d1c0" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">下面给出了几个用于此目的的简单函数。</p><p id="fdc3" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><code class="fe pi pj pk pl b">resize()</code>功能用于返回286x286像素的图像。这样做是为了在数据集中偶然出现不同大小的图像时具有统一的图像大小。将大小从512x512 px减小到一半也有助于加速模型训练，因为它的计算量较小。</p><p id="e1e2" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><code class="fe pi pj pk pl b">random_crop()</code>函数返回所需尺寸为256x256 px的裁剪输入和真实图像。</p><p id="b00b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><code class="fe pi pj pk pl b">normalize()</code>函数，顾名思义，将图像归一化为[-1，1]。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ps pt l"/></div></figure><p id="37f2" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在上面显示的<code class="fe pi pj pk pl b">random_jitter()</code>函数中，所有之前的预处理函数被放在一起，随机图像被水平翻转。您可以从下面给出的图像中看到数据预处理的结果。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pw"><img src="../Images/b0f79fa077f449a5d0cc2e936e387dc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*M9Iqal_yFOcDuQxmAIKPrw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">预处理图像(作者提供的图像)</p></figure><h2 id="944a" class="nc mg it bd mh nd ne dn ml nf ng dp mp lq nh ni mr lu nj nk mt ly nl nm mv iz bi translated">加载训练和测试数据</h2><p id="6a46" class="pw-post-body-paragraph lh li it lj b lk mx kd lm ln my kg lp lq mz ls lt lu na lw lx ly nb ma mb mc im bi translated"><code class="fe pi pj pk pl b">load_image_train()</code> function用于将之前看到的所有函数放在一起，输出最终的预处理图像。</p><p id="7879" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><code class="fe pi pj pk pl b">tf.data.Dataset.list_files()</code>收集数据集的<code class="fe pi pj pk pl b">train/</code>文件夹中所有可用png文件的路径。然后映射这些路径的集合，每个路径作为参数单独发送给<code class="fe pi pj pk pl b">load_image_train()</code>函数，该函数返回最终的预处理图像并将其添加到<code class="fe pi pj pk pl b">train_dataset</code>。</p><p id="6ddb" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">最后，使用<code class="fe pi pj pk pl b">BUFFER_SIZE</code>对这个<code class="fe pi pj pk pl b">train_dataset</code>进行洗牌，然后如前所述分成小批量。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ps pt l"/></div></figure><p id="0388" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了加载测试数据集，我们将使用一个类似的过程，除了一个小的变化。这里我们将省略<code class="fe pi pj pk pl b">random_crop()</code>和<code class="fe pi pj pk pl b">random_jitter()</code>函数，因为不需要这样做来测试结果。同样，出于同样的原因，我们可以省略对数据集的混洗。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ps pt l"/></div></figure><h2 id="db75" class="nc mg it bd mh nd ne dn ml nf ng dp mp lq nh ni mr lu nj nk mt ly nl nm mv iz bi translated">构建发电机模型</h2><p id="fde7" class="pw-post-body-paragraph lh li it lj b lk mx kd lm ln my kg lp lq mz ls lt lu na lw lx ly nb ma mb mc im bi translated">现在让我们构建生成器模型，它采用256x256 px的输入黑白草图图像，并输出有望类似于训练数据集中的彩色地面真实图像的图像。</p><p id="ccf8" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">生成器模型是一个UNet体系结构模型，并且跳过了与中间层以外的其他层的连接。请注意，由于输出和输入形状需要与连接的层相匹配，因此设计这样的架构会变得很复杂，所以要小心设计。</p><p id="5304" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">下采样叠层具有卷积层，这导致输入图像的尺寸减小。一旦缩小的图像通过具有某种“反向”卷积层的上采样堆栈，大小就会恢复到256x256像素。因此，发生器模型的输出是具有3个输出通道的256x256 px图像。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ps pt l"/></div></figure><p id="e6a7" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">你可以看看下面给出的模型概要。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi px"><img src="../Images/c3ae24501531badf8ba801d08cda4277.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*65-VqKt9yaGFQuCaGAghTw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">发电机模型的模型摘要(图片由作者提供)</p></figure><h2 id="13a9" class="nc mg it bd mh nd ne dn ml nf ng dp mp lq nh ni mr lu nj nk mt ly nl nm mv iz bi translated">建立鉴别器模型</h2><p id="e420" class="pw-post-body-paragraph lh li it lj b lk mx kd lm ln my kg lp lq mz ls lt lu na lw lx ly nb ma mb mc im bi translated">鉴别器模型的主要目的是找出哪个图像来自实际训练数据集，哪个图像是生成器模型的输出。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ps pt l"/></div></figure><p id="dcaf" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">可以看看下面给出的鉴频器的型号总结。这不像生成器模型那样复杂，因为它的基本任务只是对真实和虚假的图像进行分类。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi py"><img src="../Images/b78231173885e091afb2882ac340f8bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:972/format:webp/1*PhQFejq_-3AEi11dXJiFxA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">鉴别器模型摘要(图片由作者提供)</p></figure><h2 id="2c4f" class="nc mg it bd mh nd ne dn ml nf ng dp mp lq nh ni mr lu nj nk mt ly nl nm mv iz bi translated">模型的损失函数</h2><p id="55d3" class="pw-post-body-paragraph lh li it lj b lk mx kd lm ln my kg lp lq mz ls lt lu na lw lx ly nb ma mb mc im bi translated">由于我们有两个模型，我们需要两个不同的损失函数来独立计算它们的损失。</p><p id="cc60" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">发生器的损耗通过寻找发生器输出的sigmoid交叉熵损耗和1的阵列来计算。这意味着我们正在训练它欺骗鉴别器输出值为1，这意味着它是一个真实的图像。此外，为了使输出在结构上与目标图像相似，我们还考虑了L1损耗。<a class="ae md" href="https://arxiv.org/abs/1611.07004" rel="noopener ugc nofollow" target="_blank"> <strong class="lj jd"> <em class="me">原论文</em> </strong> </a>的作者建议<code class="fe pi pj pk pl b">LAMBDA</code>的值保持为100。</p><p id="eb92" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">对于鉴别器损失，我们取真实图像和1阵列的相同sigmoid交叉熵损失，并将其与发生器模型和0阵列的输出图像的交叉熵损失相加。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ps pt l"/></div></figure><h2 id="d7a0" class="nc mg it bd mh nd ne dn ml nf ng dp mp lq nh ni mr lu nj nk mt ly nl nm mv iz bi translated">优化者</h2><p id="9c5a" class="pw-post-body-paragraph lh li it lj b lk mx kd lm ln my kg lp lq mz ls lt lu na lw lx ly nb ma mb mc im bi translated">优化器是用来改变神经网络属性的算法或方法，如权重和学习率，以减少损失。在大多数用例中，Adam Optimizer是最好使用的优化器之一。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ps pt l"/></div></figure><h2 id="ba56" class="nc mg it bd mh nd ne dn ml nf ng dp mp lq nh ni mr lu nj nk mt ly nl nm mv iz bi translated">创建检查点</h2><p id="b471" class="pw-post-body-paragraph lh li it lj b lk mx kd lm ln my kg lp lq mz ls lt lu na lw lx ly nb ma mb mc im bi translated">如前所述，云环境有一个特定的超时，它会中断训练过程。此外，如果您使用本地系统，可能会出现由于某些原因培训中断的情况。</p><p id="3397" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">gan需要很长的训练时间，并且计算量很大。因此，最好定期保存检查点，这样您就可以恢复到最新的检查点，并从那里继续，而不会丢失您的机器之前所做的艰苦工作。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ps pt l"/></div></figure><h2 id="662c" class="nc mg it bd mh nd ne dn ml nf ng dp mp lq nh ni mr lu nj nk mt ly nl nm mv iz bi translated">显示输出图像</h2><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ps pt l"/></div></figure><p id="6c7d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">上面给出的代码块是一个基本的python函数，它使用来自<code class="fe pi pj pk pl b">matplotlib</code>库的<code class="fe pi pj pk pl b">pyplot</code>模块来显示生成器模型预测的图像。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pz"><img src="../Images/0bc766bee840d11d2faf8a39a197e73c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6pU9ip76VRmmaKvPkW3hDQ.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">通过未训练的生成器模型显示预测图像(作者提供的图像)</p></figure><h2 id="1362" class="nc mg it bd mh nd ne dn ml nf ng dp mp lq nh ni mr lu nj nk mt ly nl nm mv iz bi translated">记录损失</h2><p id="1d5c" class="pw-post-body-paragraph lh li it lj b lk mx kd lm ln my kg lp lq mz ls lt lu na lw lx ly nb ma mb mc im bi translated">您可以将损失等重要指标记录在文件中，以便在Tensorboard等工具上进行训练时进行分析。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ps pt l"/></div></figure><h2 id="ff1e" class="nc mg it bd mh nd ne dn ml nf ng dp mp lq nh ni mr lu nj nk mt ly nl nm mv iz bi translated">训练步骤</h2><p id="e5e1" class="pw-post-body-paragraph lh li it lj b lk mx kd lm ln my kg lp lq mz ls lt lu na lw lx ly nb ma mb mc im bi translated">一个基本的训练步骤将包括以下过程:</p><ul class=""><li id="ecd8" class="nn no it lj b lk ll ln lo lq np lu nq ly nr mc ns nt nu nv bi translated">生成器输出预测</li><li id="9c12" class="nn no it lj b lk nw ln nx lq ny lu nz ly oa mc ns nt nu nv bi translated">鉴频器模型设计为一次有2个输入。第一次给出了输入的草图图像和生成的图像。下一次给它真实的目标图像和生成的图像。</li><li id="6000" class="nn no it lj b lk nw ln nx lq ny lu nz ly oa mc ns nt nu nv bi translated">现在，发电机损耗和鉴频器损耗计算完毕。</li><li id="329a" class="nn no it lj b lk nw ln nx lq ny lu nz ly oa mc ns nt nu nv bi translated">然后，根据损失计算梯度，并将其应用于优化器，以帮助生成器生成更好的图像，并帮助鉴别器以更好的洞察力检测真实的和生成的图像。</li><li id="9d2b" class="nn no it lj b lk nw ln nx lq ny lu nz ly oa mc ns nt nu nv bi translated">使用之前使用<code class="fe pi pj pk pl b">tf.summary</code>定义的<code class="fe pi pj pk pl b">summary_writer</code>记录所有损失。</li></ul><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ps pt l"/></div></figure><h2 id="4e59" class="nc mg it bd mh nd ne dn ml nf ng dp mp lq nh ni mr lu nj nk mt ly nl nm mv iz bi translated">Model.fit()</h2><p id="5216" class="pw-post-body-paragraph lh li it lj b lk mx kd lm ln my kg lp lq mz ls lt lu na lw lx ly nb ma mb mc im bi translated">TensorFlow是一个非常棒的、易于使用的模型训练框架。像<code class="fe pi pj pk pl b">model.fit()</code>这样的小命令就能为我们带来奇迹。</p><p id="ca11" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">不幸的是，它在这里不能直接工作，因为我们已经创建了两个协同工作的模型。但是这也很容易做到。</p><p id="7ef6" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在这里，我们对每个时期进行迭代，并将相对时间分配给<code class="fe pi pj pk pl b">start</code>变量。然后我们展示了一个由生成器模型生成的图像的例子。这个例子帮助我们直观地看到生成器如何在每个时期更好地生成颜色更好的图像。然后我们调用模型的<code class="fe pi pj pk pl b">train_step</code>函数，从计算的损耗和梯度中学习。最后，我们检查纪元编号是否能被5整除，以节省检查点。这意味着我们每完成5个训练周期就保存一个检查点。在整个时期完成后，从最终相对时间中减去开始时间，以计算该特定时期所用的时间。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ps pt l"/></div></figure><h2 id="225f" class="nc mg it bd mh nd ne dn ml nf ng dp mp lq nh ni mr lu nj nk mt ly nl nm mv iz bi translated"><em class="pv">啊！终于，我们到了… </em></h2><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ps pt l"/></div></figure><p id="5b9f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们现在要做的就是运行这一行代码，然后等待模型自己施展魔法。好吧，我们不要完全相信这个模型，我们已经做了很多艰苦的工作，现在是时候看看结果了。</p><h2 id="3603" class="nc mg it bd mh nd ne dn ml nf ng dp mp lq nh ni mr lu nj nk mt ly nl nm mv iz bi translated">恢复最新的检查点</h2><p id="c9bc" class="pw-post-body-paragraph lh li it lj b lk mx kd lm ln my kg lp lq mz ls lt lu na lw lx ly nb ma mb mc im bi translated">在继续之前，我们必须恢复可用的最新检查点，以便在对映像进行测试之前加载最新版本的已定型模型。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ps pt l"/></div></figure><h2 id="9e1a" class="nc mg it bd mh nd ne dn ml nf ng dp mp lq nh ni mr lu nj nk mt ly nl nm mv iz bi translated">测试输出</h2><p id="9148" class="pw-post-body-paragraph lh li it lj b lk mx kd lm ln my kg lp lq mz ls lt lu na lw lx ly nb ma mb mc im bi translated">这从<code class="fe pi pj pk pl b">test_dataset</code>中随机选择5幅图像，并将它们分别输入到发生器模型中。现在该模型被训练得足够好，并且预测输入草图图像的接近完美的彩色版本。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ps pt l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qa"><img src="../Images/baaf674b792ef89a34a3354bbcb525f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qHesF-1tG1p2UkjDZS4GSQ.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">经过训练的生成器模型后的黑白草图输出(图片由作者提供)</p></figure><h2 id="9e9b" class="nc mg it bd mh nd ne dn ml nf ng dp mp lq nh ni mr lu nj nk mt ly nl nm mv iz bi translated">保存模型</h2><p id="0b67" class="pw-post-body-paragraph lh li it lj b lk mx kd lm ln my kg lp lq mz ls lt lu na lw lx ly nb ma mb mc im bi translated">我们不要在做了这么多工作之后就把模型给毁了，好吗？</p><blockquote class="pm pn po"><p id="951b" class="lh li me lj b lk ll kd lm ln lo kg lp pp lr ls lt pq lv lw lx pr lz ma mb mc im bi translated">一个模特不应该在笔记本里结束自己的生命！<br/>—<a class="qb qc ep" href="https://medium.com/u/dbc019e228f5?source=post_page-----89ef35a60b69--------------------------------" rel="noopener" target="_blank">丹尼尔·伯克</a>说得对</p></blockquote><p id="9965" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">只需一行代码就可以将整个模型保存为Keras模型支持的. H5文件。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ps pt l"/></div></figure><h1 id="3957" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">结论</h1><p id="9196" class="pw-post-body-paragraph lh li it lj b lk mx kd lm ln my kg lp lq mz ls lt lu na lw lx ly nb ma mb mc im bi translated"><em class="me">原来如此，原来如此！</em></p><p id="31c6" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们不仅看到了条件GAN是如何工作的，而且还成功地实现了它来从给定的黑白输入草图图像预测彩色图像。</p><p id="a81f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">你可以从我的<a class="ae md" href="https://github.com/tejasmorkar/sketch-to-color" rel="noopener ugc nofollow" target="_blank"> <strong class="lj jd"> <em class="me"> GitHub库</em> </strong> </a>中浏览全部代码并下载下来，看看它在你的系统上是如何工作的。</p><div class="qd qe gp gr qf qg"><a href="https://tejasmorkar.github.io/sketch-to-color/" rel="noopener  ugc nofollow" target="_blank"><div class="qh ab fo"><div class="qi ab qj cl cj qk"><h2 class="bd jd gy z fp ql fr fs qm fu fw jc bi translated">使用条件高斯函数生成草图到彩色图像</h2><div class="qn l"><h3 class="bd b gy z fp ql fr fs qm fu fw dk translated">草图到彩色图像的生成是一个图像到图像的翻译模型，使用条件生成的对抗…</h3></div><div class="qo l"><p class="bd b dl z fp ql fr fs qm fu fw dk translated">tejasmorkar.github.io</p></div></div><div class="qp l"><div class="qq l qr qs qt qp qu lb qg"/></div></div></a></div><p id="00ea" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果您面临任何问题，想要提出一些改进建议，或者只是想留下一个快速反馈，请不要犹豫，通过任何最适合您的媒体与我联系。</p><h2 id="6357" class="nc mg it bd mh nd ne dn ml nf ng dp mp lq nh ni mr lu nj nk mt ly nl nm mv iz bi translated">我的联系信息:</h2><p id="5274" class="pw-post-body-paragraph lh li it lj b lk mx kd lm ln my kg lp lq mz ls lt lu na lw lx ly nb ma mb mc im bi translated"><strong class="lj jd"><em class="me">LinkedIn</em></strong>:<a class="ae md" href="https://www.linkedin.com/in/tejasmorkar/" rel="noopener ugc nofollow" target="_blank"><em class="me">https://www.linkedin.com/in/tejasmorkar/</em></a><strong class="lj jd"><br/><em class="me">GitHub</em></strong>:<a class="ae md" href="https://github.com/tejasmorkar" rel="noopener ugc nofollow" target="_blank"><em class="me">https://github.com/tejasmorkar</em></a><br/><strong class="lj jd"><em class="me">Twitter</em></strong>:<a class="ae md" href="https://twitter.com/TejasMorkar" rel="noopener ugc nofollow" target="_blank"><em class="me">https://twitter.com/TejasMorkar</em></a></p></div></div>    
</body>
</html>