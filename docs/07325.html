<html>
<head>
<title>5 Advanced PyTorch Tools to Level up Your Workflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">5个高级PyTorch工具提升您的工作流程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/5-advanced-pytorch-tools-to-level-up-your-workflow-d0bcf0603ad5?source=collection_archive---------21-----------------------#2020-06-03">https://towardsdatascience.com/5-advanced-pytorch-tools-to-level-up-your-workflow-d0bcf0603ad5?source=collection_archive---------21-----------------------#2020-06-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/bca3672707c9580322bcbf59896e5814.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iC8dFixF65HJH2G3_sS8ZQ.png"/></div></div></figure><div class=""/><div class=""><h2 id="8c0f" class="pw-subtitle-paragraph kb jd je bd b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks dk translated">从开发到生产</h2></div><p id="f08f" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">PyTorch太棒了。自成立以来，它已经成为仅次于TensorFlow的领先深度学习框架之一。它的易用性和动态定义的性质在研究人员中特别受欢迎，他们能够比以往任何时候都更快地进行原型设计和实验。</p><p id="c874" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">从一开始，它就经历了爆炸性的发展，变得不仅仅是一个快速原型的框架。在这篇文章中，我的目标是向您介绍五种工具，它们可以帮助您使用PyTorch改进开发和生产工作流程。</p><p id="fc47" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">为了给你一个快速的纲要，我们将看看这些。</p><ul class=""><li id="9f84" class="lp lq je kv b kw kx kz la lc lr lg ls lk lt lo lu lv lw lx bi translated"><strong class="kv jf">挂钩</strong></li><li id="5395" class="lp lq je kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated"><strong class="kv jf"> PyTorch闪电</strong></li><li id="090e" class="lp lq je kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated"><strong class="kv jf">量化</strong></li><li id="dd06" class="lp lq je kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated"><strong class="kv jf">修剪</strong></li><li id="e46e" class="lp lq je kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated"><strong class="kv jf"> TorchScript + JIT </strong></li></ul><h1 id="b8ee" class="md me je bd mf mg mh mi mj mk ml mm mn kk mo kl mp kn mq ko mr kq ms kr mt mu bi translated">钩住</h1><p id="ee31" class="pw-post-body-paragraph kt ku je kv b kw mv kf ky kz mw ki lb lc mx le lf lg my li lj lk mz lm ln lo im bi translated">首先，让我们谈谈钩子，它是PyTorch中最有用的内置开发工具之一。你是否曾经用打印语句和断点来处理那些讨厌的张量形状不匹配或随机层中出现的神秘NaN？</p><p id="d62d" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">好消息是:你不必这样做。有一个简单而优雅的解决方案。一个<em class="na">钩子</em>是一个功能，可以附加到某些层上。它在向前传递(或向后传递，取决于您附加它的位置)之前接收层的输入，允许您存储、检查甚至修改它。</p><p id="f16d" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在下面的例子中，您可以看到如何使用钩子简单地存储ResNet模型的每个卷积层的输出。</p><figure class="nb nc nd ne gt iv"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="6fbe" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">如果你想了解更多的细节，我已经写了一个关于钩子的详细指南。</p><div class="is it gp gr iu nh"><a rel="noopener follow" target="_blank" href="/the-one-pytorch-trick-which-you-should-know-2d5e9c1da2ca"><div class="ni ab fo"><div class="nj ab nk cl cj nl"><h2 class="bd jf gy z fp nm fr fs nn fu fw jd bi translated">你应该知道的一个PyTorch把戏</h2><div class="no l"><h3 class="bd b gy z fp nm fr fs nn fu fw dk translated">钩子如何显著改善你的工作流程</h3></div><div class="np l"><p class="bd b dl z fp nm fr fs nn fu fw dk translated">towardsdatascience.com</p></div></div><div class="nq l"><div class="nr l ns nt nu nq nv ja nh"/></div></div></a></div><h1 id="2717" class="md me je bd mf mg mh mi mj mk ml mm mn kk mo kl mp kn mq ko mr kq ms kr mt mu bi translated">PyTorch闪电</h1><p id="6cfc" class="pw-post-body-paragraph kt ku je kv b kw mv kf ky kz mw ki lb lc mx le lf lg my li lj lk mz lm ln lo im bi translated">如果你用过Keras，你就会知道一个好的界面可以让训练模型变得轻而易举。最初，PyTorch没有这个功能。然而<a class="ae nw" href="https://github.com/PyTorchLightning/pytorch-lightning" rel="noopener ugc nofollow" target="_blank"> PyTorch Lightning </a>被开发出来填补了这个空白。虽然不是PyTorch的官方部分，但它目前是由一个非常活跃的社区开发的，最近获得了很大的关注。</p><p id="1775" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">为了演示它如何帮助您消除通常出现在PyTorch中的样板代码，这里有一个简单的例子，我们在MNIST上训练了一个ResNet分类器。</p><figure class="nb nc nd ne gt iv"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="91be" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">此外，<code class="fe nx ny nz oa b">Trainer</code>类支持多GPU训练，这在某些场景中可能很有用。在<a class="ae nw" href="https://pytorch-lightning.readthedocs.io" rel="noopener ugc nofollow" target="_blank">官方文档</a>中有更多的例子。</p><p id="a32d" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在Medium上有一篇作者William Falcon的精彩介绍，如果你感兴趣，我强烈推荐。</p><div class="is it gp gr iu nh"><a rel="noopener follow" target="_blank" href="/from-pytorch-to-pytorch-lightning-a-gentle-introduction-b371b7caaf09"><div class="ni ab fo"><div class="nj ab nk cl cj nl"><h2 class="bd jf gy z fp nm fr fs nn fu fw jd bi translated">从PyTorch到py torch Lightning——一个温和的介绍</h2><div class="no l"><h3 class="bd b gy z fp nm fr fs nn fu fw dk translated">这篇文章对使用PyTorch和PyTorch Lightning实现的MNIST进行了对比。</h3></div><div class="np l"><p class="bd b dl z fp nm fr fs nn fu fw dk translated">towardsdatascience.com</p></div></div><div class="nq l"><div class="ob l ns nt nu nq nv ja nh"/></div></div></a></div><h1 id="b907" class="md me je bd mf mg mh mi mj mk ml mm mn kk mo kl mp kn mq ko mr kq ms kr mt mu bi translated">量化</h1><p id="2996" class="pw-post-body-paragraph kt ku je kv b kw mv kf ky kz mw ki lb lc mx le lf lg my li lj lk mz lm ln lo im bi translated">随着神经网络结构变得越来越复杂，它们的计算需求也增加了。这使得某些模式在实践中不可行。您可能希望在移动应用程序中运行神经网络，这有很强的硬件限制。正因为如此，人们正在做出巨大努力来克服这些障碍。</p><p id="8f72" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">其中最有希望的是网络的量子化。本质上，量化就是简单地用uint8代替float32或float64。这使得网络更小，计算更快。即使在准确性和大小/速度之间有一个折衷，如果做得好，性能损失可以是最小的。</p><p id="51eb" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">PyTorch支持<a class="ae nw" href="https://pytorch.org/docs/stable/quantization.html" rel="noopener ugc nofollow" target="_blank">三种量化工作流程</a>:</p><ol class=""><li id="9128" class="lp lq je kv b kw kx kz la lc lr lg ls lk lt lo oc lv lw lx bi translated">动态量化，在计算过程中将权重和输入转换为uint8。这使得它更快，但权重和输出仍然存储为浮点型。(因此，更快的uint8内存访问不会加速。)</li><li id="7a43" class="lp lq je kv b kw ly kz lz lc ma lg mb lk mc lo oc lv lw lx bi translated">训练后静态量化。这转换了整个训练过的网络，也提高了存储器访问速度。但是，这可能会导致性能下降。</li><li id="2ff0" class="lp lq je kv b kw ly kz lz lc ma lg mb lk mc lo oc lv lw lx bi translated">量化感知训练。如果训练后量化导致次优性能损失，则可以在训练期间应用量化。</li></ol><p id="f764" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">如果你的目标是生产，量化是非常值得探索的。(请记住，它目前是一项实验性功能，可能会有所变化。)</p><p id="b21d" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">延伸阅读:</p><ul class=""><li id="bc4f" class="lp lq je kv b kw kx kz la lc lr lg ls lk lt lo lu lv lw lx bi translated"><a class="ae nw" href="https://pytorch.org/docs/stable/quantization.html" rel="noopener ugc nofollow" target="_blank"> PyTorch量化文档</a></li><li id="fe98" class="lp lq je kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated">PyTorch博客上的量子化介绍</li></ul><h1 id="e893" class="md me je bd mf mg mh mi mj mk ml mm mn kk mo kl mp kn mq ko mr kq ms kr mt mu bi translated">修剪</h1><p id="2286" class="pw-post-body-paragraph kt ku je kv b kw mv kf ky kz mw ki lb lc mx le lf lg my li lj lk mz lm ln lo im bi translated">除了量化之外，还有更多加速/缩小神经网络的技术。即使中等规模的卷积网络也包含数百万个参数，使得训练和推断的计算成本很高。由于经过训练的网络本身就很稀疏，因此简单地删除不必要的神经元以减小规模和提高速度是一种自然的想法。</p><p id="4662" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">减肥似乎不是一个好主意，但却是一个非常有效的方法。只要想想卷积层实际上是一个线性层，有一堆零权重。在PyTorch中，<code class="fe nx ny nz oa b">torch.nn.utils.prune</code>模块中实现了几种修剪方法。要使用它们，只需对要修剪的图层应用修剪功能:</p><pre class="nb nc nd ne gt od oa oe of aw og bi"><span id="19ee" class="oh me je oa b gy oi oj l ok ol">prune.random_unstructured(nn.Conv2d(3, 16, 3), "weight", 0.5)</span></pre><p id="5c32" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这为模块添加了一个修剪前向预挂钩，它在每次前向传递之前执行，屏蔽了权重。因此，由于权重的稀疏性，这一层中的计算将会更快。</p><p id="50a5" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">延伸阅读:</p><ul class=""><li id="6cde" class="lp lq je kv b kw kx kz la lc lr lg ls lk lt lo lu lv lw lx bi translated"><a class="ae nw" href="https://pytorch.org/tutorials/intermediate/pruning_tutorial.html" rel="noopener ugc nofollow" target="_blank"> PyTorch修剪教程</a></li></ul><h1 id="e8ca" class="md me je bd mf mg mh mi mj mk ml mm mn kk mo kl mp kn mq ko mr kq ms kr mt mu bi translated">火炬脚本+ JIT</h1><p id="3332" class="pw-post-body-paragraph kt ku je kv b kw mv kf ky kz mw ki lb lc mx le lf lg my li lj lk mz lm ln lo im bi translated">如你所知，PyTorch的内部其实是用C++实现的，使用了CUDA、CUDNN等高性能计算工具。这就是为什么它真的很快。你用来训练的只是一个C++张量库之上的Python包装器。这有一些缺点，例如它增加了计算的开销。Python对于开发来说非常方便，但是在生产中，你并不真正需要这种便利。</p><p id="c3a6" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">你需要的是一种快速运行你的模型的方法。TorchScript和JIT正好提供了这一点。它将您的模型转换成中间表示，可用于在Python之外的环境中加载它。此外，这种表示可以进一步优化，以实现更快的性能。</p><p id="e026" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">要翻译您的模型，您可以使用</p><pre class="nb nc nd ne gt od oa oe of aw og bi"><span id="6c6c" class="oh me je oa b gy oi oj l ok ol">torch.jit.trace</span></pre><p id="73b4" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">或者</p><pre class="nb nc nd ne gt od oa oe of aw og bi"><span id="1413" class="oh me je oa b gy oi oj l ok ol">torch.jit.script</span></pre><p id="8762" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">追踪需要一个示例输入，它被传递到您的模型，同时在内部表示中记录操作。但是，如果您的前向传递计算控制流，比如<code class="fe nx ny nz oa b">if</code>语句，那么表示就不正确。如果描摹仅触及分支的一部分，其他分支将不会出现。在这些情况下，应该使用脚本，它直接分析模型的源代码。</p><p id="f3a9" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">更多资源:</p><ul class=""><li id="8cf7" class="lp lq je kv b kw kx kz la lc lr lg ls lk lt lo lu lv lw lx bi translated"><a class="ae nw" href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html" rel="noopener ugc nofollow" target="_blank"> PyTorch火炬脚本教程</a></li><li id="3c60" class="lp lq je kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated"><a class="ae nw" href="https://www.youtube.com/watch?v=St3gdHJzic0" rel="noopener ugc nofollow" target="_blank">研究到生产:PyTorch JIT/TorchScript更新</a>作者:Michael Suo</li><li id="4eb5" class="lp lq je kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated"><a class="ae nw" href="https://www.youtube.com/watch?v=EkELQw9tdWE" rel="noopener ugc nofollow" target="_blank">从研究到生产</a>，杰夫·史密斯在QCon New York 2019上的演讲</li></ul></div><div class="ab cl om on hx oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="im in io ip iq"><p id="e7c5" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">你在工作中使用过这些吗？你知道什么最佳实践或很棒的教程吗？请在评论中告诉我们！:)</p><p id="c2e6" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在那之前，让我们提升PyTorch技能，建造一些令人敬畏的东西！</p></div><div class="ab cl om on hx oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="im in io ip iq"><p id="b926" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><a class="ae nw" href="https://www.tivadardanka.com/blog" rel="noopener ugc nofollow" target="_blank"> <strong class="kv jf"> <em class="na">如果你喜欢把机器学习概念拆开，理解是什么让它们运转，我们有很多共同点。看看我的博客，我经常在那里发表这样的技术文章！</em> </strong> </a></p></div></div>    
</body>
</html>