<html>
<head>
<title>Web Scraping with Scrapy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Scrapy刮网</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/web-scraping-with-scrapy-8071fd627051?source=collection_archive---------34-----------------------#2020-05-12">https://towardsdatascience.com/web-scraping-with-scrapy-8071fd627051?source=collection_archive---------34-----------------------#2020-05-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5632" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">构建您的第一个网络爬虫</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/30a8d755c43197b53acdefc0edc3a267.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Y-6qe-2VQsMUKoW2"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">尼古拉斯·皮卡德在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="414d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated">S  crapy是一个流行的用于网页抓取的Python框架。出于本教程的目的，我想使用一个我熟悉的网站。我以前做过一个项目，用Billboard Hot 100排行榜上的条目作为基本事实，对热门唱片进行分类。我当时使用了一个python包装器，它在获取我的数据集时非常有效。然而，我想展示使用Scrapy可以很容易地做到这一点。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="ee0d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">免责声明</strong>:这仅用于培训和教育目的。请熟悉道德规范，因为它们与从网上抓取内容有关。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="4723" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">任何成功的网络抓取项目的第一步是审查要抓取的网站。试着理解发生在引擎盖下的<strong class="lb iu"><em class="ml"/></strong>。在这一步，你的浏览器的网络开发工具将是必不可少的。确定要提取以包含在数据集中的信息。</p><p id="14e8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我之前在一个项目中使用过<strong class="lb iu"> Billboard Hot 100 </strong>数据。为了给我的热门歌曲分类器建立真实点击率，我使用billboard.py提取每周图表数据。这个包是一个python包装器，它使用<strong class="lb iu"><em class="ml">Beautiful Soup</em></strong>解析来自Billboard站点的html数据。因为我对这个数据集很熟悉，所以我认为演示如何使用<strong class="lb iu"> <em class="ml"> Scrapy </em> </strong>来构建您的第一个网络爬虫是一个不错的选择。</p><p id="99d9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">导航到<a class="ae ky" href="https://www.billboard.com/charts/hot-100" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"><em class="ml">https://billboard.com/charts/hot-100</em></strong></a><strong class="lb iu"><em class="ml">/</em></strong>。通过右键单击并选择检查或按下<strong class="lb iu"><em class="ml">option-command-I</em></strong>打开浏览器的web开发工具。我在这里禁用JavaScript，方法是按下<strong class="lb iu"><em class="ml">shift-command-P</em></strong>，输入<strong class="lb iu"> <em class="ml"> javascript </em> </strong>，选择<strong class="lb iu"> <em class="ml">禁用JavaScript </em> </strong>选项。记得点击刷新按钮或者按下<strong class="lb iu"> <em class="ml"> command-R </em> </strong>来刷新页面。这一步对于决定创建网络爬虫是至关重要的，因为这可以让我看到<strong class="lb iu"> Scrapy </strong>看到的页面。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mm"><img src="../Images/9bf2918dc496aa9326806f588169763f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jmmw1qwYjyfPtvg1IbzYiw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">网络开发工具的使用。</p></figure><p id="ba98" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我决定从网站上收集以下数据:</p><ul class=""><li id="ddbf" class="mn mo it lb b lc ld lf lg li mp lm mq lq mr lu ms mt mu mv bi translated"><em class="ml">图表日期</em></li><li id="5aa2" class="mn mo it lb b lc mw lf mx li my lm mz lq na lu ms mt mu mv bi translated"><em class="ml">歌名</em></li><li id="436d" class="mn mo it lb b lc mw lf mx li my lm mz lq na lu ms mt mu mv bi translated"><em class="ml">艺人</em></li><li id="4b18" class="mn mo it lb b lc mw lf mx li my lm mz lq na lu ms mt mu mv bi translated"><em class="ml">本周排名</em></li><li id="4d08" class="mn mo it lb b lc mw lf mx li my lm mz lq na lu ms mt mu mv bi translated"><em class="ml">上周排名</em></li><li id="99b4" class="mn mo it lb b lc mw lf mx li my lm mz lq na lu ms mt mu mv bi translated"><em class="ml">峰值位置</em></li><li id="95ce" class="mn mo it lb b lc mw lf mx li my lm mz lq na lu ms mt mu mv bi translated"><em class="ml">图表上的周数</em>。</li></ul><p id="2c3e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我发现从1958年8月4日到1961年12月25日，图表每周出现<strong class="lb iu"><em class="ml"/></strong>和每周一<strong class="lb iu"><em class="ml"/></strong>编目。图表是在周六<strong class="lb iu"><em class="ml"/></strong>之后公布的。以前图表的url遵循base_url/date_string的格式。例如，从1999年12月25日这一周的图表将在https://billboard.com/charts/hot-100/1999–12–25.找到，我们稍后将需要它为我们的网络爬虫创建分页。</p><p id="d52b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你还没有这样做，一定要安装scrapy。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="b44a" class="ng nh it nc b gy ni nj l nk nl">$ pip install scrapy</span></pre><p id="015f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">仍然在命令行中，选择一个您想要工作的目录，创建一个新项目，并创建一个基本的蜘蛛。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="946f" class="ng nh it nc b gy ni nj l nk nl">$ cd projects<br/>$ scrapy startproject billboard<br/>$ cd billboard<br/>$ scrapy genspider hot100 billboard.com/charts/hot-100/</span></pre><p id="4226" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Scrapy为你的网络爬虫创建了一个具有所有适当层次的新项目。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/cf7e6f89874f115d265fb5dd80879f54.png" data-original-src="https://miro.medium.com/v2/resize:fit:406/format:webp/1*cHTfLerOsEDDmbfJJmF5FA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">项目文件夹结构。</p></figure><p id="7a98" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在<strong class="lb iu"> <em class="ml"> scrapy shell </em> </strong>命令和<strong class="lb iu"> <em class="ml"> web dev tools </em> </strong>之间，我可以发现如何最好地从html中提取我需要的数据。有<strong class="lb iu"> <em class="ml"> 100首歌</em> </strong>出现在每个周图中。它们可以在有序列表元素中找到。通过将这100个元素放入一个变量中，我可以遍历每个元素，从每个元素中提取相关信息。我选择使用<strong class="lb iu"><em class="ml">XPath</em></strong>提取我的数据。如果你愿意，你可以使用<strong class="lb iu"> <em class="ml"> css选择器</em> </strong>。这个简短的教程假设您对这两者都有一定的了解，所以我不会深入讨论。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="1a4e" class="ng nh it nc b gy ni nj l nk nl">$ scrapy shell billboard.com/charts/hot-100/</span><span id="3eb0" class="ng nh it nc b gy nn nj l nk nl">&gt;&gt;&gt; hit = response.xpath("//li[starts-with(@class, 'chart-list__element')]")</span><span id="23d2" class="ng nh it nc b gy nn nj l nk nl">&gt;&gt;&gt; len(hit)<br/>100</span><span id="1266" class="ng nh it nc b gy nn nj l nk nl">&gt;&gt;&gt; title = hit.xpath(".//span[starts-with(@class, 'chart-element__information__song')]/text()").get()</span><span id="3312" class="ng nh it nc b gy nn nj l nk nl">&gt;&gt;&gt; title<br/>'The Scotts'</span></pre><p id="43ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">既然我已经对我想要抓取的每个项目有了一个好的想法，我将在我选择的文本编辑器中打开我的蜘蛛。我在这个例子中使用了<strong class="lb iu"> <em class="ml"> Visual Studio代码</em> </strong>，但是任何代码都可以。我打开项目文件夹，然后打开我创建的名为<strong class="lb iu"> <em class="ml"> hot100.py </em> </strong>的蜘蛛。</p><p id="787a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我将<strong class="lb iu"><em class="ml">allowed _ domains</em></strong>从“www.billboard.com/charts”稍微修改为“billboard.com”。我还在<strong class="lb iu"><em class="ml">start _ requests</em></strong>函数中包含了开始url，这样我就可以删除start_urls变量，因为它不再是必需的。还要注意，我已经包括了<strong class="lb iu"> <em class="ml">用户代理</em> </strong>而不是允许Scrapy使用默认的，这有时会妨碍你的蜘蛛。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/d449d545de0f33dd83fa2caaca70cba6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RoWUb7Dpdzv8AtuFMQyT5w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">蜘蛛的初始设置。</p></figure><p id="7727" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我想指导蜘蛛如何抓取网站获取信息。我创建了一个变量，<strong class="lb iu"> hits，</strong>，它包含了页面上所有的100次点击。然后我创建了一个循环来查找每次命中的变量。</p><p id="5e1b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我指示蜘蛛如何前进到下一页。我根据图表的日期创建了一个date对象，以便轻松计算前一个图表的日期。该日期随后被转换成格式为<strong class="lb iu"> <em class="ml"> YYYY-mm-dd </em> </strong>的字符串对象。如果您还记得前面的内容，这就是我们需要添加到基本url中以获取前一周图表url的格式。一个<strong class="lb iu"> <em class="ml">回调</em> </strong>用于通知蜘蛛回到<strong class="lb iu"> <em class="ml">解析方法</em> </strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/ca11f091b2f8fce5cdf8051aab022c6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GfzCzuF8D6UmgjLAaDAq8A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">解析方法。</p></figure><p id="4f1a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">按下<strong class="lb iu"> <em class="ml"> command-J </em> </strong>，在<strong class="lb iu"> <em class="ml"> VS代码</em> </strong>中打开一个终端窗口。确保您位于预期的目录中。如果没有，请确保相应地更改目录。然后让你的蜘蛛爬出网站！我选择将我的记录保存在一个<strong class="lb iu"> <em class="ml">中。csv </em> </strong>文件您可以将您的文件存储为任何您想要的结构化格式，例如<strong class="lb iu"> <em class="ml">。json </em> </strong>，<strong class="lb iu">，<em class="ml">。xml </em> </strong>等。总共我蜘蛛爬了大概4个小时<strong class="lb iu"> <em class="ml"> 30多万条记录</em> </strong>！</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="1223" class="ng nh it nc b gy ni nj l nk nl">$ pwd<br/>$ cd /projects/billboard<br/>$ scrapy crawl -o hot100.csv</span></pre><p id="0ee3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我遇到的挑战之一是超时错误。在<em class="ml"> Aminah Nuraini关于<a class="ae ky" href="https://stackoverflow.com/questions/43630434/how-to-handle-a-429-too-many-requests-response-in-scrapy" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> <em class="ml">栈溢出</em> </strong> </a>的<em class="ml">解决方案的帮助下，我对我的<strong class="lb iu"> <em class="ml"> settings.py </em> </strong>和<strong class="lb iu"><em class="ml">middleware . py</em></strong>文件进行了修改，使我的爬虫运行顺畅。如果她的解决方案适合你的个人情况，请随时查看。我不会深入细节，因为它们超出了这个简短教程的范围。</em></em></p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="7637" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你有它！你完全有能力创建你的第一个网络爬虫<strong class="lb iu"><em class="ml"/></strong>来完成网络抓取的任务。完整的<strong class="lb iu"> <em class="ml">源代码</em> </strong>可以在<a class="ae ky" href="https://github.com/SiphuLangeni/Billboard-Scrapy" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> <em class="ml">这里找到</em> </strong> </a>。如果你觉得这篇文章很有帮助，请联系我这里和/或<a class="ae ky" href="https://www.linkedin.com/in/SiphuLangeni" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> <em class="ml">上</em> </strong> </a>的链接。</p></div></div>    
</body>
</html>