<html>
<head>
<title>The Hero Rises: Build Your Own SSD</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">è‹±é›„å´›èµ·:æ‰“é€ è‡ªå·±çš„SSD</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://towardsdatascience.com/the-hero-rises-build-your-own-ssd-febfbdd3bd03?source=collection_archive---------52-----------------------#2020-04-19">https://towardsdatascience.com/the-hero-rises-build-your-own-ssd-febfbdd3bd03?source=collection_archive---------52-----------------------#2020-04-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="b863" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">ç°å®ä¸–ç•Œä¸­çš„æ•°æ®ç§‘å­¦</h2><div class=""/><div class=""><h2 id="b6fb" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">æ·±åº¦å­¦ä¹ ä»£ç åº“ç³»åˆ—çš„è‹±é›„ä¹‹æ—…â€”â€”IIBéƒ¨åˆ†</h2></div><p id="8eb1" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">ç”±<a class="ae ln" href="https://www.linkedin.com/in/dan-malowany-78b2b21/" rel="noopener ugc nofollow" target="_blank">ä¸¹Â·é©¬æ´›ä¸‡å°¼</a>å’Œ<a class="ae ln" href="https://www.linkedin.com/in/gal-hyams-2146a662/" rel="noopener ugc nofollow" target="_blank">åŠ å°”Â·æµ·å§†æ–¯</a><br/>T5ã€‘åˆ›ä½œçš„å¿«æ¿è‰¾å›¢é˜Ÿ</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi lq"><img src="../Images/6f11d2ae6f08d5f78fd91440ddb6ac61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2US3ifFa-vXm_FnDGerXBA.jpeg"/></div></div></figure><p id="5fdc" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">éšç€æœ€å…ˆè¿›çš„æ¨¡å‹ä¸æ–­å˜åŒ–ï¼Œäººä»¬éœ€è¦æœ‰æ•ˆåœ°ç¼–å†™æ¨¡å—åŒ–çš„æœºå™¨å­¦ä¹ ä»£ç åº“ï¼Œä»¥æ”¯æŒå’Œç»´æŒR&amp;Dæœºå™¨å’Œæ·±åº¦å­¦ä¹ å¤šå¹´çš„åŠªåŠ›ã€‚åœ¨æœ¬ç³»åˆ—çš„ç¬¬ä¸€ç¯‡åšå®¢ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•ç¼–å†™ä¸€ä¸ªå¯è¯»å’Œå¯ç»´æŠ¤çš„ä»£ç æ¥è®­ç»ƒTorchvision MaskRCNNæ¨¡å‹ï¼Œåˆ©ç”¨Igniteçš„æ¡†æ¶ã€‚åœ¨æˆ‘ä»¬çš„<a class="ae ln" rel="noopener" target="_blank" href="/the-battle-of-speed-vs-23b61eb4225d">ç¬¬äºŒç¯‡æ–‡ç« (IIAéƒ¨åˆ†)</a>ä¸­ï¼Œæˆ‘ä»¬è¯¦ç»†ä»‹ç»äº†å•è§¦å‘å’ŒåŒè§¦å‘æ¢æµ‹å™¨ä¹‹é—´çš„æ ¹æœ¬åŒºåˆ«ï¼Œä»¥åŠä¸ºä»€ä¹ˆå•è§¦å‘æ–¹æ³•æ˜¯é€Ÿåº¦/ç²¾åº¦æƒè¡¡çš„æœ€ä½³é€‰æ‹©ã€‚å› æ­¤ï¼Œåœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å¾ˆè‡ªç„¶åœ°æ”¶é›†äº†å¦‚ä½•åˆ©ç”¨MaskRCNNä»£ç åº“çš„æ¨¡å—åŒ–ç‰¹æ€§ï¼Œå¹¶ä½¿å…¶èƒ½å¤Ÿè®­ç»ƒMaskRCNNå’ŒSSDæ¨¡å‹ã€‚ç”±äºä»£ç åº“çš„æ¨¡å—åŒ–æ€§è´¨ï¼Œåªéœ€è¦å¯¹ä»£ç è¿›è¡Œæœ€å°çš„ä¿®æ”¹ã€‚</p><p id="dc11" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><a class="ae ln" href="https://pytorch.org/docs/stable/torchvision/index.html" rel="noopener ugc nofollow" target="_blank"> Torchvision </a>æ˜¯ä¸€ä¸ªç”±æµè¡Œçš„æ•°æ®é›†ã€æ¨¡å‹æ¶æ„å’Œè®¡ç®—æœºè§†è§‰çš„é€šç”¨å›¾åƒè½¬æ¢ç»„æˆçš„åŒ…ã€‚é™¤å…¶ä»–å¤–ï¼Œå®ƒè¿˜åŒ…å«ä¸€ä¸ªé¢„å…ˆè®­ç»ƒå¥½çš„æ¨¡å‹åŠ¨ç‰©å›­ï¼Œç”¨äºå›¾åƒåˆ†ç±»ã€å¯¹è±¡æ£€æµ‹ã€äººç‰©å…³é”®ç‚¹æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²å’Œå®ä¾‹åˆ†å‰²æ¨¡å‹ï¼Œéšæ—¶å¯ä¾›å¼€ç®±å³ç”¨ã€‚è¿™ä½¿å¾—PyTorchç”¨æˆ·çš„ç”Ÿæ´»å˜å¾—æ›´åŠ å®¹æ˜“ï¼Œå› ä¸ºå®ƒç¼©çŸ­äº†æƒ³æ³•å’Œäº§å“ä¹‹é—´çš„æ—¶é—´ã€‚æˆ–è€…ä¸€ç¯‡ç ”ç©¶è®ºæ–‡ã€‚æˆ–è€…ä¸€ç¯‡åšæ–‡ã€‚</p><p id="e30b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">Torchvisionä¸åŒ…å«å•é•œå¤´å¯¹è±¡æ£€æµ‹æ¨¡å‹çš„å®ç°ï¼Œä¾‹å¦‚è¿™ä¸ªæµè¡Œçš„<a class="ae ln" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2" rel="noopener ugc nofollow" target="_blank"> SSD </a> <strong class="kt jd">ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æ·»åŠ äº†ä¸€ä¸ª:</strong>åŸºäºTorchvisionæ¨¡å‹çš„SSDå®ç°ï¼Œä½œä¸ºç‰¹å¾æå–çš„ä¸»å¹²ã€‚è‡ªå‘å¸ƒä»¥æ¥ï¼Œåœ¨æœ€åˆçš„SSDä¸Šè¿›è¡Œäº†è®¸å¤šæ”¹è¿›ã€‚ç„¶è€Œï¼Œä¸ºäº†æ¸…æ™°å’Œç®€å•èµ·è§ï¼Œæˆ‘ä»¬å°†é‡ç‚¹æ”¾åœ¨äº†æœ€åˆçš„SSDå…ƒæ¶æ„ä¸Šã€‚è®©æˆ‘ä»¬æ·±å…¥ç ”ç©¶ä¸€ä¸‹å®ç°çš„é€»è¾‘å’Œæ–¹æ³•ã€‚å®Œæ•´çš„ä»£ç å¯ä»¥åœ¨<a class="ae ln" href="https://github.com/allegroai/trains-blogs/tree/master/the_hero_rises" rel="noopener ugc nofollow" target="_blank"> Github </a>ä¸Šè·å¾—ã€‚</p><h1 id="7ee5" class="mc md it bd me mf mg mh mi mj mk ml mm ki mn kj mo kl mp km mq ko mr kp ms mt bi translated">å¸¸é‡:ä»é»˜è®¤å€¼å¼€å§‹</h1><p id="235d" class="pw-post-body-paragraph kr ks it kt b ku mu kd kw kx mv kg kz la mw lc ld le mx lg lh li my lk ll lm im bi translated">é¦–å…ˆï¼Œæˆ‘ä»¬æŠŠæ‰‹ç”µç­’æ”¾åœ¨ä»£ç å¸¸é‡ä¸Šï¼Œå®ƒä»¬æ˜¯<a class="ae ln" href="https://github.com/allegroai/trains-blogs/blob/fd92c462cbbceb8d4027aec2cf9acd5579117fe1/the_hero_rises/SSD/ssd_model.py#L113" rel="noopener ugc nofollow" target="_blank"> SSDç±»æ„é€ å‡½æ•°</a>çš„é»˜è®¤è¾“å…¥å‚æ•°ã€‚è¿™äº›æ˜¯ä¸ºPASCAL-VOCæ•°æ®é›†å®šåˆ¶çš„512Ã—512è¾“å…¥å›¾åƒçš„å¸¸è§å€¼ã€‚(åœ¨æœ¬ç³»åˆ—çš„ç¬¬ä¸‰éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†æ¼”ç¤ºå¦‚ä½•æ ¹æ®æ‚¨è‡ªå·±çš„æ•°æ®é›†è°ƒæ•´è¿™äº›å€¼)</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi mz"><img src="../Images/851a5708fbabe7b14dee80d452b4837e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ML9eJF-t9U3KVmlzJ6d6DQ.jpeg"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated">å›¾1: SSDå…ƒæ¶æ„å’Œå¤šç‰¹å¾å›¾è®¡ç®—â€” <a class="ae ln" href="https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2" rel="noopener ugc nofollow" target="_blank"> SSDè®ºæ–‡</a></p></figure><p id="3adb" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">è¿™äº›<a class="ae ln" href="https://github.com/allegroai/trains-blogs/blob/fd92c462cbbceb8d4027aec2cf9acd5579117fe1/the_hero_rises/SSD/ssd_model.py#L17" rel="noopener ugc nofollow" target="_blank">åˆ—è¡¨ä¸­çš„æ¯ä¸€ä¸ª</a>åŒ…å«7ä¸ªæ¡ç›®â€”â€”æ¯ä¸ªç‰¹å¾å›¾ä¸€ä¸ªæ¡ç›®ï¼Œä»è¯¥ç‰¹å¾å›¾ä¸­è¿›è¡Œå¯¹è±¡æ£€æµ‹(è§ä¸Šé¢çš„<em class="ne">å›¾1 </em>)ã€‚æ³¨æ„ï¼Œåˆ—è¡¨ä¹‹ä¸€BOX_SIZESæœ‰8ä¸ªæ¡ç›®ï¼Œå®é™…çš„æ¡†å°ºå¯¸<a class="ae ln" href="https://github.com/allegroai/trains-blogs/blob/fd92c462cbbceb8d4027aec2cf9acd5579117fe1/the_hero_rises/SSD/box_coder.py#L13" rel="noopener ugc nofollow" target="_blank">è®¡ç®—</a>æ˜¯åŸºäºè¿™äº›å€¼æ‰§è¡Œçš„ã€‚</p><p id="c41e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">å¦‚<em class="ne">å›¾2 </em>(ä¸Šå›¾)æ‰€ç¤ºï¼ŒçŸ©å½¢å’Œæ–¹å½¢é”šç‚¹å¹³é“ºç‰¹å¾å›¾ã€‚<em class="ne"> aspect_ratio </em>åˆ—è¡¨åŒ…å«æ¯ä¸ªç‰¹å¾å›¾çš„çŸ©å½¢çºµæ¨ªæ¯”åˆ—è¡¨ã€‚è¿™ä¸ªåˆ—è¡¨ä¸­çš„æ¯ä¸ªæ•°å­—ä¸ºæ¯ä¸ªå…ˆå‰çš„ä¸­å¿ƒå®šä¹‰äº†ä¸¤ä¸ªçŸ©å½¢:ä¸€ä¸ªå…·æœ‰æåˆ°çš„çºµæ¨ªæ¯”ï¼Œå¦ä¸€ä¸ªå…·æœ‰ç›¸åçš„çºµæ¨ªæ¯”ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå¯¹äºæ¯ä¸ª2:1çš„â€œèººç€çš„â€çŸ©å½¢é”šï¼Œæˆ‘ä»¬ä¹Ÿæœ‰ä¸€ä¸ª1:2çš„â€œç«™ç€çš„â€çŸ©å½¢é”šã€‚é™¤äº†çŸ©å½¢é”šä¹‹å¤–ï¼Œä¸¤ç§å°ºå¯¸çš„æ–¹å½¢é”šè¢«è®¾ç½®åœ¨æ¯ä¸ªå…ˆå‰çš„ä¸­å¿ƒä¸Šã€‚</p><pre class="lr ls lt lu gt nf ng nh ni aw nj bi"><span id="a37b" class="nk md it ng b gy nl nm l nn no"><em class="ne"># The size ratio between the current layer and the original image.<br/># I.e, how many pixel steps on the original image are equivalent to a single pixel step on the feature map.</em><br/><br/>STEPS = (8, 16, 32, 64, 128, 256, 512)<br/><br/><em class="ne"># Length of the smaller anchor rectangle, for each feature map.</em><br/><br/>BOX_SIZES = (35.84, 76.8, 153.6, 230.4, 307.2, 384.0, 460.8, 537.6)<br/><br/><em class="ne"># Aspect ratio of the rectangular SSD anchors, besides 1:1</em><br/><br/>ASPECT_RATIOS = ((2,), (2, 3), (2, 3), (2, 3), (2, 3), (2,), (2,))<br/><br/><em class="ne"># feature maps sizes.</em><br/><br/>FM_SIZES = (64, 32, 16, 8, 4, 2, 1)<br/><br/><em class="ne"># Amount of anchors for each feature map</em><br/><br/>NUM_ANCHORS = (4, 6, 6, 6, 6, 4, 4)<br/><br/><em class="ne"># Amount of each feature map channels, i.e third dimension.</em><br/><br/>IN_CHANNELS = (512, 1024, 512, 256, 256, 256, 256)</span></pre><h1 id="a8a6" class="mc md it bd me mf mg mh mi mj mk ml mm ki mn kj mo kl mp km mq ko mr kp ms mt bi translated">SSDç±»æ„é€ å‡½æ•°</h1><p id="9789" class="pw-post-body-paragraph kr ks it kt b ku mu kd kw kx mv kg kz la mw lc ld le mx lg lh li my lk ll lm im bi translated">è¿™ä¸ª<em class="ne"> SSD </em>ç±»äº§ç”Ÿä¸€ä¸ªåŸºäºTorchvisionç‰¹å¾æå–å™¨çš„SSDå¯¹è±¡æ£€æµ‹æ¨¡å‹ï¼Œå‚æ•°å¦‚ä¸Šæ‰€è¿°ã€‚</p><pre class="lr ls lt lu gt nf ng nh ni aw nj bi"><span id="ffcd" class="nk md it ng b gy nl nm l nn no"><strong class="ng jd">class SSD</strong>(nn.Module):<br/>   <strong class="ng jd">def __init__</strong>(<strong class="ng jd">self</strong>, backbone, num_classes, loss_function,<br/>                num_anchors=NUM_ANCHORS,<br/>                in_channels=IN_CHANNELS,<br/>                steps=STEPS,<br/>                box_sizes=BOX_SIZES,<br/>                aspect_ratios=ASPECT_RATIOS,<br/>                fm_sizes=FM_SIZES,<br/>                heads_extractor_class=HeadsExtractor):<br/><br/><strong class="ng jd">super</strong>(SSD, <strong class="ng jd">self</strong>).__init__()<br/>...<br/><strong class="ng jd">self</strong>.extractor = heads_extractor_class(backbone)<br/><strong class="ng jd">self</strong>.criterion = loss_function<br/><strong class="ng jd">self</strong>.box_coder = SSDBoxCoder(self.steps, self.box_sizes, self.aspect_ratios, <strong class="ng jd">self</strong>.fm_sizes)<br/><br/><strong class="ng jd">self</strong>._create_heads()</span></pre><h1 id="3bc7" class="mc md it bd me mf mg mh mi mj mk ml mm ki mn kj mo kl mp km mq ko mr kp ms mt bi translated">åˆ›å»ºåˆ†ç±»å’Œæœ¬åœ°åŒ–è´Ÿè´£äºº</h1><p id="6818" class="pw-post-body-paragraph kr ks it kt b ku mu kd kw kx mv kg kz la mw lc ld le mx lg lh li my lk ll lm im bi translated">ä¸‹é¢ï¼Œæˆ‘ä»¬é¦–å…ˆå°†ç‰¹å¾æ˜ å°„çš„åˆ†è§£ä»SSDæ¨¡å‹ä¸­åˆ†ç¦»å‡ºæ¥ï¼Œä½¿SSDèƒ½å¤Ÿè½»æ¾é€‚åº”è°ƒæ•´åçš„ç‰¹å¾æ˜ å°„æå–å™¨ã€‚å¦‚æœæ‚¨ç¡®å®è¦ä¿®æ”¹SSDï¼Œé‚£ä¹ˆåœ¨è°ƒç”¨SSDæ„é€ å‡½æ•°æ—¶ï¼Œä¸è¦å¿˜è®°ä¿®æ”¹ç›¸å…³çš„å‚æ•°ã€‚</p><pre class="lr ls lt lu gt nf ng nh ni aw nj bi"><span id="6050" class="nk md it ng b gy nl nm l nn no">class HeadsExtractor(nn.Module):<br/>   def __init__(self, backbone):<br/>       super(HeadsExtractor, self).__init__()<br/><br/>       def split_backbone(net):<br/>           features_extraction = [x for x in net.children()][:-2]<br/>          <br/>           if type(net) == torchvision.models.vgg.VGG:<br/>               features_extraction = [*features_extraction[0]]<br/>               net_till_conv4_3 = features_extraction[:-8]<br/>               rest_of_net = features_extraction[-7:-1]<br/>           elif type(net) == torchvision.models.resnet.ResNet:<br/>               net_till_conv4_3 = features_extraction[:-2]<br/>               rest_of_net = features_extraction[-2]<br/>           else:<br/>               raise ValueError('We only support VGG and ResNet')<br/>           return nn.Sequential(*net_till_conv4_3), nn.Sequential(*rest_of_net)<br/><br/>       self.till_conv4_3, self.till_conv5_3 = split_backbone(backbone)<br/>       self.norm4 = L2Norm(512, 20)<br/><br/>       self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, padding=1, dilation=1)<br/>       self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1, dilation=1)<br/>       self.conv5_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1, dilation=1)<br/><br/>       self.conv6 = nn.Conv2d(512, 1024, kernel_size=3, padding=6, dilation=6)<br/>       self.conv7 = nn.Conv2d(1024, 1024, kernel_size=1)<br/><br/>       self.conv8_1 = nn.Conv2d(1024, 256, kernel_size=1)<br/>       self.conv8_2 = nn.Conv2d(256, 512, kernel_size=3, padding=1, stride=2)<br/><br/>       self.conv9_1 = nn.Conv2d(512, 128, kernel_size=1)<br/>       self.conv9_2 = nn.Conv2d(128, 256, kernel_size=3, padding=1, stride=2)<br/><br/>       self.conv10_1 = nn.Conv2d(256, 128, kernel_size=1)<br/>       self.conv10_2 = nn.Conv2d(128, 256, kernel_size=3, padding=1, stride=2)<br/><br/>       self.conv11_1 = nn.Conv2d(256, 128, kernel_size=1)<br/>       self.conv11_2 = nn.Conv2d(128, 256, kernel_size=3, padding=1, stride=2)<br/><br/>       self.conv12_1 = nn.Conv2d(256, 128, kernel_size=1)<br/>       self.conv12_2 = nn.Conv2d(128, 256, kernel_size=4, padding=1</span></pre><p id="2bca" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">SSDæ¨¡å‹å…±äº«æ‰€æœ‰çš„åˆ†ç±»å’Œå®šä½è®¡ç®—ï¼Œç›´åˆ°æœ€ç»ˆçš„å†…å®¹åˆ†ç±»å™¨å’Œç©ºé—´å›å½’å™¨ã€‚<em class="ne"> create_heads </em>æ–¹æ³•åœ¨æ¯ä¸ªç‰¹å¾å›¾çš„é¡¶éƒ¨åˆ›å»ºSSDåˆ†ç±»å’Œå®šä½å¤´ï¼Œäº§ç”Ÿæ¯é”šé¢„æµ‹ã€‚å¯¹äºæ¯ä¸ªé”šï¼Œå®šä½å¤´é¢„æµ‹å‘é‡ç§»ä½å’Œæ‹‰ä¼¸(cxï¼Œxyï¼Œwï¼Œh)ï¼Œè€Œåˆ†ç±»å¤´é¢„æµ‹æ¯ç±»æ¦‚ç‡çš„å‘é‡ã€‚</p><pre class="lr ls lt lu gt nf ng nh ni aw nj bi"><span id="2b86" class="nk md it ng b gy nl nm l nn no"><strong class="ng jd">def _create_heads</strong>(<strong class="ng jd">self</strong>):<br/>       <strong class="ng jd">self</strong>.loc_layers = nn.ModuleList()<br/>       <strong class="ng jd">self</strong>.cls_layers = nn.ModuleList()<br/>       <strong class="ng jd">for</strong> i <strong class="ng jd">in</strong> <strong class="ng jd">range</strong>(<strong class="ng jd">len</strong>(<strong class="ng jd">self</strong>.in_channels)):<br/><strong class="ng jd">       self</strong>.loc_layers += [nn.Conv2d(<strong class="ng jd">self</strong>.in_channels[i], <strong class="ng jd">self</strong>.num_anchors[i] * 4, kernel_size=3, padding=1)]<br/><strong class="ng jd">       self</strong>.cls_layers += [nn.Conv2d(<strong class="ng jd">self</strong>.in_channels[i], <strong class="ng jd">self</strong>.num_anchors[i] * <strong class="ng jd">self</strong>.num_classes, kernel_size=3<strong class="ng jd">, </strong>padding=1)]</span></pre><p id="2615" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">SSDæ¨¡å‹ä»æœ€é«˜åˆ†è¾¨ç‡åˆ°æœ€ä½åˆ†è¾¨ç‡å»ºç«‹äº†ä¸€ä¸ªç‰¹å¾å›¾çš„å±‚æ¬¡ç»“æ„ï¼Œå¹¶æ£€æµ‹æ¯ä¸ªç‰¹å¾å›¾ä¸Šçš„å¯¹è±¡ã€‚<em class="ne">å¤´éƒ¨æå–å™¨</em>ç±»æ”¾ç½®ç‰¹å¾åœ°å›¾ï¼Œå¹¶ä½¿å…¶å¯ç”¨äºæ£€æµ‹å™¨ã€‚å…¶å‘½ååŸºäºVGG-16ç‰¹å¾æå–å™¨(å…¶ä¸­<em class="ne"> conv4_3 </em>æ˜¯ç”¨ä½œSSDæ¨¡å‹ç‰¹å¾å›¾çš„æœ€é«˜åˆ†è¾¨ç‡å±‚çš„åç§°)ã€‚</p><p id="848b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">ä¸åŒçš„æ•°æ®é›†å’Œå½±åƒå¤§å°æœ€é€‚åˆè°ƒæ•´åçš„è¦ç´ åœ°å›¾ç­‰çº§ï¼›å°å›¾åƒä¸éœ€è¦åƒå¤§å›¾åƒé‚£æ ·å¤šä¸åŒçš„ç‰¹å¾åœ°å›¾ã€‚ç±»ä¼¼åœ°ï¼Œæ²¡æœ‰å°å¯¹è±¡çš„æ•°æ®é›†å¯ä»¥é¿å…é«˜åˆ†è¾¨ç‡çš„ç‰¹å¾åœ°å›¾(åŠ é€Ÿæ¨¡å‹è®¡ç®—æ—¶é—´)ã€‚</p><h1 id="4b07" class="mc md it bd me mf mg mh mi mj mk ml mm ki mn kj mo kl mp km mq ko mr kp ms mt bi translated">å®šä¹‰SSDæ­£å‘ä¼ é€’</h1><p id="dcf8" class="pw-post-body-paragraph kr ks it kt b ku mu kd kw kx mv kg kz la mw lc ld le mx lg lh li my lk ll lm im bi translated">åœ¨ä¸‹é¢çš„æ–¹æ³•ä¸­ï¼Œè®¡ç®—SSDæ¨¡å‹ä¸Šçš„å›¾åƒæ‰¹æ¬¡çš„æ­£å‘ä¼ é€’ï¼Œå¹¶è¿”å›å…¶ç»“æœã€‚</p><p id="7edc" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">å¦‚æœæ¨¡å‹å¤„äºè¯„ä¼°æ¨¡å¼ï¼Œåˆ™æ­£å‘ä¼ é€’è¿”å›è¾“å…¥å›¾åƒä¸Šçš„æ¨¡å‹é¢„æµ‹ã€‚ä½†æ˜¯ï¼Œå¦‚æœåœ¨è®­ç»ƒæ¨¡å¼ä¸‹è¿›è¡Œæ­£å‘ä¼ é€’ï¼Œåˆ™åªè¿”å›æŸå¤±ã€‚è¿™æ˜¯ä¸€ç§å¸¸è§çš„è®¾è®¡ï¼Œå®ƒåªè¿”å›æŸå¤±ï¼Œæ¯”è¿”å›æ‰€æœ‰æ£€æµ‹çš„è®¡ç®—æ•ˆç‡æ›´é«˜ã€‚</p><p id="5243" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">ä½¿ç”¨è¿™ç§æ–¹æ³•ï¼Œ<em class="ne"> extracted_batch </em>å‚æ•°ä¿å­˜å›¾åƒæ‰¹æ¬¡çš„å¸ƒå±€ç‰¹å¾å›¾ï¼Œç„¶ååˆ†åˆ«è®¡ç®—è·¨æ¯ä¸ªç‰¹å¾å›¾çš„é¢„æµ‹ã€‚</p><pre class="lr ls lt lu gt nf ng nh ni aw nj bi"><span id="5b9b" class="nk md it ng b gy nl nm l nn no"><strong class="ng jd">def forward</strong>(<strong class="ng jd">self</strong>, images, targets=None):<br/>       <strong class="ng jd">if</strong> <strong class="ng jd">self</strong>.training <strong class="ng jd">and</strong> targets <strong class="ng jd">is</strong> None:<br/>           <strong class="ng jd">raise</strong> ValueError("In training mode, targets should be passed")<br/>       loc_preds = []<br/>       cls_preds = []<br/>       input_images = torch.stack(images) <strong class="ng jd">if</strong> <strong class="ng jd">isinstance</strong>(images, <strong class="ng jd">list</strong>) <strong class="ng jd">else</strong> images<br/>       extracted_batch = <strong class="ng jd">self</strong>.extractor(input_images)<br/>       <strong class="ng jd">for</strong> i, x <strong class="ng jd">in</strong> <strong class="ng jd">enumerate</strong>(extracted_batch):<br/>           loc_pred = <strong class="ng jd">self</strong>.loc_layers[i](x)<br/>           loc_pred = loc_pred.permute(0, 2, 3, 1).contiguous()<br/>           loc_preds.append(loc_pred.view(loc_pred.size(0), -1, 4))<br/><br/>           cls_pred = <strong class="ng jd">self</strong>.cls_layers[i](x)<br/>           cls_pred = cls_pred.permute(0, 2, 3, 1).contiguous()<br/>           cls_preds.append(cls_pred.view(cls_pred.size(0), -1, <strong class="ng jd">self</strong>.num_classes))<br/><br/>       loc_preds = torch.cat(loc_preds, 1)<br/>       cls_preds = torch.cat(cls_preds, 1)<br/><br/>      <strong class="ng jd">if</strong> <strong class="ng jd">self</strong>.training:<br/>           encoded_targets = [<strong class="ng jd">self</strong>.box_coder.encode(target['boxes'], target['labels']) <strong class="ng jd">for</strong> target <strong class="ng jd">in</strong> targets]<br/>           loc_targets = torch.stack([encoded_target[0] <strong class="ng jd">for</strong> encoded_target <strong class="ng jd">in</strong> encoded_targets])<br/>           cls_targets = torch.stack([encoded_target[1] <strong class="ng jd">for</strong> encoded_target <strong class="ng jd">in</strong> encoded_targets])<br/>           losses = <strong class="ng jd">self</strong>.criterion(loc_preds, loc_targets, cls_preds, cls_targets)<br/>           <strong class="ng jd">return</strong> losses<br/><br/>       detections = []<br/><br/>       <strong class="ng jd">for</strong> batch, (loc, cls) <strong class="ng jd">in</strong> <strong class="ng jd">enumerate</strong>(<strong class="ng jd">zip</strong>(loc_preds.split(split_size=1, dim=0),<br/><br/>                                              cls_preds.split(split_size=1, dim=0))):<br/><br/>           boxes, labels, scores = <strong class="ng jd">self</strong>.box_coder.decode(loc.squeeze(), F.softmax(cls.squeeze(), dim=1))<br/><br/>           detections.append({'boxes': boxes, 'labels': labels, 'scores': scores})<br/><br/>       <strong class="ng jd">return</strong> detections</span></pre><h1 id="e86c" class="mc md it bd me mf mg mh mi mj mk ml mm ki mn kj mo kl mp km mq ko mr kp ms mt bi translated">å°†SSDæ¨¡å‹è¿æ¥åˆ°ä»£ç åº“</h1><p id="225d" class="pw-post-body-paragraph kr ks it kt b ku mu kd kw kx mv kg kz la mw lc ld le mx lg lh li my lk ll lm im bi translated">ä¸ºäº†è°ƒæ•´<a class="ae ln" href="https://github.com/allegroai/trains-blogs/blob/master/once_upon_a_repository/train_model.py" rel="noopener ugc nofollow" target="_blank"> MaskRCNNä»£ç åº“</a>çš„è®­ç»ƒå’Œè¯„ä¼°è„šæœ¬ï¼Œå¹¶ä½¿å…¶èƒ½å¤Ÿè®­ç»ƒMaskRCNNå’ŒSSDæ¨¡å‹ï¼Œæˆ‘ä»¬å°†ä»¥ä¸‹æ¡ç›®æ·»åŠ åˆ°é…ç½®æ•°æ®ä¸­(æ‰‹åŠ¨æˆ–é€šè¿‡<a class="ae ln" href="https://github.com/allegroai/trains-server" rel="noopener ugc nofollow" target="_blank"> Trains Server </a> web app)ã€‚</p><pre class="lr ls lt lu gt nf ng nh ni aw nj bi"><span id="5557" class="nk md it ng b gy nl nm l nn no">'model_type': 'ssd', 'ssd_backbone': 'resnet50'</span></pre><p id="8461" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">å¦‚æœæ‚¨æŸ¥çœ‹ä¸€ä¸‹trainè„šæœ¬ï¼Œæ‚¨ä¼šå‘ç°é™¤äº†ä¸Šè¿°é…ç½®æ•°æ®æ›´æ”¹ä¹‹å¤–ï¼ŒåŸå§‹MaskRCNNè„šæœ¬å’Œæ–°è„šæœ¬(ä¹Ÿæ”¯æŒSSD)ä¹‹é—´çš„å”¯ä¸€åŒºåˆ«æ˜¯æ¨¡å‹å¯¹è±¡å®šä¹‰éƒ¨åˆ†:</p><pre class="lr ls lt lu gt nf ng nh ni aw nj bi"><span id="f168" class="nk md it ng b gy nl nm l nn no"><em class="ne"># Get the relevant model based in task arguments</em><br/><br/>   <strong class="ng jd">if</strong> configuration_data.get('model_type') == 'maskrcnn':<br/>       model = get_model_instance_segmentation(num_classes, configuration_data.get('mask_predictor_hidden_layer'))<br/>   <strong class="ng jd">elif</strong> configuration_data.get('model_type') == 'ssd':<br/>       backbone = get_backbone(configuration_data.get('backbone'))<br/>       model = SSD(backbone=backbone, num_classes=num_classes, loss_function=SSDLoss(num_classes))<br/>       model.dry_run(torch.rand(size=(1, 3, configuration_data.get('image_size'), configuration_data.get('image_size')))*255)<br/>   <strong class="ng jd">else</strong>:<br/>       <strong class="ng jd">raise</strong> ValueError('Only "maskrcnn" and "ssd" are supported as model type')</span></pre><p id="fb20" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">è¿™æ„å‘³ç€è¿™ä¸ªä»£ç åº“ä¸­æ‰€æœ‰å‰©ä½™çš„èµ„äº§éƒ½ä¿æŒä¸å˜ã€‚ä»R&amp;Dèµ„æºçš„è§’åº¦æ¥çœ‹ï¼Œè¿™æ˜¯ä¸€ä¸ªå·¨å¤§çš„ä¼˜åŠ¿ã€‚</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi np"><img src="../Images/b780bd409439e5760ecb4dbdbe884a6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gs4Zfu0uv7STq51dA9V0Dg.png"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated">æœ¬ç³»åˆ—ç¬¬ä¸€éƒ¨åˆ†ä¸­çš„è®­ç»ƒè„šæœ¬å’Œæœ¬æ–‡ä¸­çš„è®­ç»ƒè„šæœ¬çš„æ¯”è¾ƒï¼Œå±•ç¤ºäº†è¿™ä¸ªä»£ç åº“çš„æ¨¡å—åŒ–æœ¬è´¨ã€‚</p></figure><h1 id="c2b4" class="mc md it bd me mf mg mh mi mj mk ml mm ki mn kj mo kl mp km mq ko mr kp ms mt bi translated">å¿«æ¿ç«è½¦â€”â€”åä¸‹æ¥ï¼Œæ”¾æ¾å’Œç›‘æ§ä½ çš„å®éªŒ</h1><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi nq"><img src="../Images/577b65fa7aecdcfe9a4f9b284a02fc1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ERN1Fb5ewPmn-A_hBlHR9w.png"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated">åŸ¹è®­æœŸé—´Trains web appçš„å¿«ç…§ï¼Œæ˜¾ç¤ºæ ‡é‡(æŸå¤±ã€å­¦ä¹ ç‡ç­‰ã€‚)å‰è¿›</p></figure><p id="4296" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">ä¸<a class="ae ln" href="https://github.com/allegroai/trains-blogs/tree/master/once_upon_a_repository" rel="noopener ugc nofollow" target="_blank">åŸä»£ç åº“</a>ä¸€æ ·ï¼Œä½¿ç”¨<a class="ae ln" href="https://github.com/allegroai/trains" rel="noopener ugc nofollow" target="_blank"> Allegro Trains </a>ï¼Œä¸€ä¸ªå¼€æºå®éªŒ&amp; autoML managerï¼Œè®©æˆ‘ä»¬å®æ—¶ç›‘æ§è®­ç»ƒè¿‡ç¨‹ï¼ŒåŒ…æ‹¬:å­¦ä¹ ç‡ã€æŸè€—ã€valæ•°æ®é›†ä¸Šçš„mAPç­‰ã€‚æ­¤å¤–ï¼ŒAllegro Trainsä¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è‡ªåŠ¨ç›‘æ§CPUã€GPUå’Œè®¡ç®—æœºä¿¡æ¯ã€‚è¿™ä¸€é‡è¦å·¥å…·æœ‰åŠ©äºè¯†åˆ«å†…å­˜æ³„æ¼ã€ç¡¬ç›˜ç©ºé—´ä¸è¶³ã€GPUåˆ©ç”¨ç‡ä½ç­‰é—®é¢˜ã€‚</p><p id="27e9" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">ç”±äºåŒ…æ‹¬è„šæœ¬å‚æ•°åœ¨å†…çš„æ‰€æœ‰è¿™äº›ä¿¡æ¯éƒ½è®°å½•åœ¨<a class="ae ln" href="https://github.com/allegroai/trains-server" rel="noopener ugc nofollow" target="_blank"> TrainsæœåŠ¡å™¨</a>ä¸­ï¼Œå› æ­¤å¯ä»¥æ¯”è¾ƒä¸åŒçš„è®­ç»ƒè¯¾ç¨‹ï¼Œå¹¶è¯†åˆ«å‡ºäº§ç”Ÿä¼˜å¼‚ç»“æœçš„è¶…å‚æ•°ã€‚</p><h1 id="9df3" class="mc md it bd me mf mg mh mi mj mk ml mm ki mn kj mo kl mp km mq ko mr kp ms mt bi translated">ç»“è®º</h1><p id="9cf0" class="pw-post-body-paragraph kr ks it kt b ku mu kd kw kx mv kg kz la mw lc ld le mx lg lh li my lk ll lm im bi translated">åœ¨<a class="ae ln" href="https://allegro.ai/blog/the-battle-of-speed-accuracy-single-shot-vs-two-shot-detection/" rel="noopener ugc nofollow" target="_blank">ä¸Šä¸€ç¯‡æ–‡ç« (IIA) </a>ä¸­ï¼Œæˆ‘ä»¬æ·±å…¥æ¢è®¨äº†å•è§¦å‘æ¢æµ‹å™¨ç›¸å¯¹äºåŒè§¦å‘æ¢æµ‹å™¨çš„ä¼˜åŠ¿ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†è¿™äº›çŸ¥è¯†ç¼–å†™æˆä»£ç ï¼Œå¹¶åœ¨Torchvisioné¢„è®­ç»ƒçš„backboneä¹‹ä¸Šåˆ›å»ºä¸€ä¸ªSSDæ¨¡å‹ï¼Œæ‚¨å¯ä»¥æ ¹æ®è‡ªå·±çš„ç›®çš„ä½¿ç”¨å®ƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å±•ç¤ºäº†éµå¾ªæœ¬ç³»åˆ—æŒ‡å—ç¼–å†™å¯ç»´æŠ¤çš„æ¨¡å—åŒ–ä»£ç åº“çš„ä¼˜åŠ¿ã€‚</p><p id="8f23" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">å®Œæ•´ä»£ç å¯åœ¨<a class="ae ln" href="https://github.com/allegroai/trains-blogs/tree/master/the_hero_rises" rel="noopener ugc nofollow" target="_blank"> Github </a>ä¸Šè·å¾—ã€‚è¿™é‡Œä»‹ç»çš„SSDç±»çš„éƒ¨åˆ†æ˜¯åŸºäº<a class="ae ln" href="https://github.com/kuangliu/torchcv/tree/master/examples/ssd" rel="noopener ugc nofollow" target="_blank">è¿™ä¸ª</a>å†™å¾—å¾ˆå¥½çš„SSDå®ç°ã€‚è°¢è°¢åŒ¡æŸ³ğŸ˜‰</p><p id="39db" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">åœ¨ä¸‹ä¸€ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•ä¼˜åŒ–SSDæ¨¡å‹ï¼Œå¹¶æ ¹æ®æ‚¨çš„æ•°æ®è¿›è¡Œè°ƒæ•´ã€‚æ•¬è¯·æœŸå¾…ï¼</p></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><p id="ac4d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="ne">åŸè½½äº2020å¹´4æœˆ19æ—¥</em><a class="ae ln" href="https://allegro.ai/blog/the-hero-rises-build-your-own-ssd/" rel="noopener ugc nofollow" target="_blank"><em class="ne">https://allegro . ai</em></a><em class="ne">ã€‚</em></p></div></div>    
</body>
</html>