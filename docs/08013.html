<html>
<head>
<title>Extracting Taxonomic Data From a Journal Articles using Natural Language Processing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用自然语言处理从期刊论文中提取分类数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/extracting-taxonomic-data-from-a-journal-articles-using-natural-language-processing-ab794d048da9?source=collection_archive---------38-----------------------#2020-06-13">https://towardsdatascience.com/extracting-taxonomic-data-from-a-journal-articles-using-natural-language-processing-ab794d048da9?source=collection_archive---------38-----------------------#2020-06-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a12f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">从期刊文章中提取科学用语的快速方法</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/943cc4c1e2e6d24736f70b9a543c9972.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DDSTgGKjWEnrL36NG-XdtA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">澳大利亚阿德莱德州立图书馆。图片来源:弗拉德·库特波夫@ Unsplash</p></figure><p id="fddb" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我最近遇到了一个客户的问题，他们希望从一篇PDF格式的期刊文章中提取所有的“科学词汇和名称”以及作者姓名和大学。虽然可以一个字一个字地浏览文章，并将其与分类名称列表进行比较，但这对于一篇期刊文章来说极其麻烦，尤其低效。相反，我使用自然语言处理的常用元素来确定期刊文章中的科学术语/分类数据。下面是一个教程，介绍如何从期刊文章PDF中提取文本，准备进行处理，并最终使用Python libraries for NLP从文章中获取分类或科学数据列表。</p><h1 id="6a23" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">要加载的包</h1><p id="d202" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">为此，我使用了PyPDF、NLTK、pandas、scikit-learn和re。您需要pip安装这些包，特别是对于NLTK，您需要通过使用nltk.download('stopwords ')和nltk.download('word_tokenize ')下载stopwords和word_tokenize。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo mp l"/></div></figure><h1 id="3732" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">从期刊文章中提取文本</h1><p id="6dee" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">我将使用我随机选择的这篇期刊文章来浏览这个例子。有许多关于如何做到这一点的好文章，所以请随意查阅，但我是用PyPDF2做的。使用PyPDF2读取所有页面后，我将结果写入一个txt文件并处理。txt文件。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo mp l"/></div></figure><h1 id="cb8a" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">清理用于分析的文本</h1><p id="32d9" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">现在我们有了要处理的语料库，我们必须做一些清理工作。使用正则表达式，我删除了数字、停用词、少于3个字符的单词和标点符号。我还定制了一个停用词表，删除那些“科学”但对我的分析没有特别启发性的词。运行代码后，可以修改该列表，删除可能没有用的额外单词。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo mp l"/></div></figure><h1 id="abf5" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">使用TFIDF进行标记和提取</h1><p id="85d5" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">我们利用了上面定义的清理函数，并对清理后的输出进行了标记化(拆分成单个单词)。之后，我们得到了二元模型(词对)和三元模型(词三元组)，然后对它们进行了矢量化。在矢量化之后，我们使用<a class="ae mq" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" rel="noopener ugc nofollow" target="_blank"> TFIDF </a>来提取有可能成为重要科学词汇的单词。输出遵循代码。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo mp l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo mp l"/></div></figure><p id="b6aa" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">虽然我们看到一些不相关的短语(如前所述),但这是论文中科学用语的一个很好的摘录。</p><h1 id="bb80" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">结论</h1><p id="04f5" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">这篇文章展示了一种从发表的文章中提取科学信息的快速方法。对于特定的论文，可以对您的代码进行一些定制，以删除额外的短语。整个脚本可以在我的Github库<a class="ae mq" href="https://github.com/melanielaffin/taxonomy" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p></div></div>    
</body>
</html>