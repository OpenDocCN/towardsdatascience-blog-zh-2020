<html>
<head>
<title>Face Landmark Detection With End-To-End Regression in TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TensorFlow 中端到端回归的人脸标志点检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/face-landmark-detection-with-cnns-tensorflow-cf4d191d2f0?source=collection_archive---------13-----------------------#2020-03-08">https://towardsdatascience.com/face-landmark-detection-with-cnns-tensorflow-cf4d191d2f0?source=collection_archive---------13-----------------------#2020-03-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="e2a7" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">🤖<a class="ae ep" href="https://equipintelligence.medium.com/list/deep-learning-techniques-methods-and-how-tos-01015cf5f917" rel="noopener">深度学习</a></h2><div class=""/><div class=""><h2 id="a14d" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">从零开始构建一个模型，不需要使用其他包！</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/d64e019f63f7ce0e3034ca009dae8252.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_bmKC9kqrjh70Jpa"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">照片由<a class="ae lh" href="https://unsplash.com/@priscilladupreez?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">普里西拉·杜·普里兹</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="92e7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">人脸检测系统在当今这个要求安全性、可访问性或快乐的世界里有很大的用途！今天，我们将建立一个可以在一张脸上画出 15 个关键点的模型。</p><p id="f674" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">面部标志检测模型形成了我们在社交媒体应用中看到的各种功能。你在 Instagram 上找到的人脸滤镜是一个常见的用例。该算法对准图像上的掩模，保持面部标志作为基点。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi me"><img src="../Images/2e6838fb609bf1b78cfe891fe299fb62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yTx4V1q7STZUSHpGp9j3Jw.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">Instagram 的自拍滤镜需要知道你的眼睛、嘴唇和鼻子在图像上的确切位置。</p></figure><p id="6bd9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们用 Keras ( TF backend)开发一个模型吧！首先，我们需要一些数据来训练我们的模型。</p><blockquote class="mf mg mh"><p id="7a11" class="li lj mi lk b ll lm kd ln lo lp kg lq mj ls lt lu mk lw lx ly ml ma mb mc md im bi translated"><strong class="lk jd">请注意！</strong>本博客教你用 Keras 建立一个超级简单的人脸地标检测模型。对于实际的生产模型，这可能没有用。</p></blockquote><p id="7a3b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">您可以在另一个选项卡中运行交互式 Colab 笔记本，以跟踪和理解每个步骤。</p><div class="mm mn gp gr mo mp"><a href="https://colab.research.google.com/drive/11PoRdorcI5C8SFPEZbO2XNGPCTGIwDfP#scrollTo=IsWsGrm8BvgN&amp;forceEdit=true&amp;sandboxMode=true" rel="noopener  ugc nofollow" target="_blank"><div class="mq ab fo"><div class="mr ab ms cl cj mt"><h2 class="bd jd gy z fp mu fr fs mv fu fw jc bi translated">人脸 _ 地标 _ 检测</h2><div class="mw l"><p class="bd b dl z fp mu fr fs mv fu fw dk translated">colab.research.google.com</p></div></div><div class="mx l"><div class="my l mz na nb mx nc lb mp"/></div></div></a></div><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nd ne l"/></div></figure><h1 id="9ba2" class="nf ng it bd nh ni nj nk nl nm nn no np ki nq kj nr kl ns km nt ko nu kp nv nw bi translated">数据</h1><p id="252b" class="pw-post-body-paragraph li lj it lk b ll nx kd ln lo ny kg lq lr nz lt lu lv oa lx ly lz ob mb mc md im bi translated">我们使用的是由<a class="ae lh" href="https://www.kaggle.com/drgilermo" rel="noopener ugc nofollow" target="_blank"> Omri Goldstein </a>在<a class="ae lh" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上标注了标志点数据集的<a class="ae lh" href="https://www.kaggle.com/drgilermo/face-images-with-marked-landmark-points" rel="noopener ugc nofollow" target="_blank">人脸图像。该数据集包含大约 7000 张图像(96 * 96 ),其面部标志可以在<code class="fe oc od oe of b">facial_keypoints.csv</code>文件中找到。</a></p><p id="28e1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">但是这里我们有一个问题。<strong class="lk jd">大多数图像没有一套完整的 15 个点。所以我们只需要那些有 15 个面部关键点的图像。</strong></p><p id="baf7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">使用这个<a class="ae lh" href="https://gist.github.com/shubham0204/7eb0435dc0142ce4fc560629111e0648" rel="noopener ugc nofollow" target="_blank">脚本</a>，我做了一些清理，并将修改后的数据保存在我的<a class="ae lh" href="https://github.com/shubham0204/Dataset_Archives" rel="noopener ugc nofollow" target="_blank">数据集档案</a> GitHub repo 中。Colab 笔记本使用<code class="fe oc od oe of b">wget</code>命令下载 ZIP 存档文件。</p><pre class="ks kt ku kv gt og of oh oi aw oj bi"><span id="929a" class="ok ng it of b gy ol om l on oo">!wget https://github.com/shubham0204/Dataset_Archives/blob/master/face_landmarks_cleaned.zip?raw=true -O data.zip</span><span id="25ef" class="ok ng it of b gy op om l on oo">!unzip data.zip</span></pre><p id="d57b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们还标准化了图像和坐标(关键点)。我已经改变了输出<code class="fe oc od oe of b">y_train</code>和<code class="fe oc od oe of b">y_test</code>的形状，因为它们将成为<code class="fe oc od oe of b">Conv2D</code>层而不是<code class="fe oc od oe of b">Dense</code>层的预期输出。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nd ne l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">预处理数据。</p></figure><blockquote class="mf mg mh"><p id="735e" class="li lj mi lk b ll lm kd ln lo lp kg lq mj ls lt lu mk lw lx ly ml ma mb mc md im bi translated"><strong class="lk jd">亲提示</strong>:我找到了另一个用于人脸地标检测的数据集，名为<a class="ae lh" href="https://susanqq.github.io/UTKFace/" rel="noopener ugc nofollow" target="_blank"> UTKFace </a>。它包含 68 个面部关键点以及年龄和性别等其他特征。也试试吧！</p></blockquote><h1 id="0531" class="nf ng it bd nh ni nj nk nl nm nn no np ki nq kj nr kl ns km nt ko nu kp nv nw bi translated">讨论模型</h1><p id="f9a4" class="pw-post-body-paragraph li lj it lk b ll nx kd ln lo ny kg lq lr nz lt lu lv oa lx ly lz ob mb mc md im bi translated">让我们讨论一下我们模型的结构。实际上，我用这个模型做了一些实验。我们需要一个模型，它拍摄一张尺寸为<code class="fe oc od oe of b">( 96 , 96 ) </code>的图像，并输出一个形状数组<code class="fe oc od oe of b">( 30, )</code> ( 15 个关键点* 2 个坐标)</p><ol class=""><li id="942b" class="oq or it lk b ll lm lo lp lr os lv ot lz ou md ov ow ox oy bi translated">第一个模型拍摄了一幅图像，并将其通过预先训练好的<a class="ae lh" href="https://neurohive.io/en/popular-networks/vgg16/" rel="noopener ugc nofollow" target="_blank"> VGG 模型</a>。接下来，VGG 的输出被展平并通过多个<code class="fe oc od oe of b">Dense</code>层。<em class="mi">问题在于，即使在损失最小的情况下，该模型也能为每张图像预测出相同的关键点</em>。</li><li id="ea59" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">第二种型号是您可以在 Colab 笔记本中找到的型号。我们不使用<code class="fe oc od oe of b">Dense</code>层。相反，我们通过<code class="fe oc od oe of b">Conv2D</code>层传递图像，并给出形状<code class="fe oc od oe of b">( 1 , 1 , 30 )</code>的输出。因此，<code class="fe oc od oe of b">Conv2D</code>层给了我们输出。<em class="mi">使用这种模型，对于每幅图像以及甚至不存在于数据集中的图像，预测都是不同的！</em></li></ol><p id="dc71" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们的模型看起来像，</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nd ne l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">模型。</p></figure><p id="17bc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在执行回归任务时，我们使用的是<a class="ae lh" href="https://en.wikipedia.org/wiki/Mean_squared_error" rel="noopener ugc nofollow" target="_blank">均方误差</a>。如果你有大量的数据，小的学习率总是好的。</p><blockquote class="mf mg mh"><p id="bccf" class="li lj mi lk b ll lm kd ln lo lp kg lq mj ls lt lu mk lw lx ly ml ma mb mc md im bi translated"><strong class="lk jd">为什么我们要使用批量标准化图层？</strong></p><p id="3833" class="li lj mi lk b ll lm kd ln lo lp kg lq mj ls lt lu mk lw lx ly ml ma mb mc md im bi translated">阅读这篇<a class="ae lh" rel="noopener" target="_blank" href="/batch-normalization-in-neural-networks-1ac91516821c">博客</a>了解更多。</p></blockquote><h2 id="5f3c" class="ok ng it bd nh pe pf dn nl pg ph dp np lr pi pj nr lv pk pl nt lz pm pn nv iz bi translated">训练和推理</h2><p id="dcea" class="pw-post-body-paragraph li lj it lk b ll nx kd ln lo ny kg lq lr nz lt lu lv oa lx ly lz ob mb mc md im bi translated">我们以 50 个为一批，对模型进行大约 250 个时期的训练。训练之后，我们将在测试数据集上生成一些预测。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nd ne l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">生成预测。</p></figure><blockquote class="mf mg mh"><p id="9dea" class="li lj mi lk b ll lm kd ln lo lp kg lq mj ls lt lu mk lw lx ly ml ma mb mc md im bi translated"><strong class="lk jd">注意</strong>:记住输入图像的方向。在旋转 90 度的图像上训练的模型不能对直立图像产生正确的预测。</p></blockquote><p id="e124" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果没有对模型或训练参数做任何修改，250 个历元后的模型应该是这样的，</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi po"><img src="../Images/23c9066079899979ac0f21b47f27d6ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qNNr1hrFoaeAWru7VI0SbQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">结果。</p></figure><p id="fce7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">印象深刻吧。仅此而已！您刚刚从头开始构建了一个面部标志检测模型。在笔记本中，我添加了一个代码单元，你可以用网络摄像头拍摄图像，并在上面运行模型。</p><h1 id="7b30" class="nf ng it bd nh ni nj nk nl nm nn no np ki nq kj nr kl ns km nt ko nu kp nv nw bi translated">想要更多吗？</h1><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nd ne l"/></div></figure><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nd ne l"/></div></figure><h1 id="4bea" class="nf ng it bd nh ni nj nk nl nm nn no np ki nq kj nr kl ns km nt ko nu kp nv nw bi translated">结束了</h1><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pp ne l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">我看完结果后的第一反应！</p></figure><p id="3841" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">很久以后我发表了作品(同时我正忙于写数学……)。感谢阅读！</p></div></div>    
</body>
</html>