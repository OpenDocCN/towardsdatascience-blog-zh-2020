<html>
<head>
<title>Text Classification in Spark NLP with Bert and Universal Sentence Encoders</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于 Bert 和通用语句编码器的 Spark NLP 文本分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/text-classification-in-spark-nlp-with-bert-and-universal-sentence-encoders-e644d618ca32?source=collection_archive---------3-----------------------#2020-04-12">https://towardsdatascience.com/text-classification-in-spark-nlp-with-bert-and-universal-sentence-encoders-e644d618ca32?source=collection_archive---------3-----------------------#2020-04-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="013b" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在 Spark NLP 中使用 Bert 和通用句子编码器训练 SOTA 多类文本分类器，只需不到 10 分钟的几行代码。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/143cfe18c9ae9e9a30fdb532fc225b1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8y0W-aA5Sa1ad2kj"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae kv" href="https://unsplash.com/@freegraphictoday?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">absolute vision</a>拍摄</p></figure><p id="d649" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">自然语言处理(NLP)是许多数据科学系统中的关键组件，必须理解或推理文本。常见的用例包括文本分类、问题回答、解释或总结、情感分析、自然语言 BI、语言建模和消歧。</p><p id="bee1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">NLP 在越来越多的人工智能应用中是必不可少的。如果你正在构建聊天机器人，搜索专利数据库，将患者与临床试验相匹配，给客户服务或销售电话评分，从财务报告中提取事实或解决这些<a class="ae kv" href="https://www.tractica.com/newsroom/press-releases/natural-language-processing-is-a-key-engine-of-ai-market-growth-enabling-44-discrete-use-cases-across-17-industries/" rel="noopener ugc nofollow" target="_blank">17 个行业的 44 个用例中的任何一个</a>，从自由文本中提取准确的信息是必不可少的。</p><p id="c043" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">文本分类</strong>是现代自然语言处理中的<a class="ae kv" href="http://nlpprogress.com/" rel="noopener ugc nofollow" target="_blank">主要任务之一，它的任务是给一个句子或文档分配一个合适的类别。类别取决于所选的数据集，范围可以是主题。</a></p><p id="1fe2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每个文本分类问题都遵循相似的步骤，并且用不同的算法来解决。更不用说像随机森林或逻辑回归这样经典和流行的机器学习分类器了，针对各种文本分类问题提出的深度学习框架<a class="ae kv" href="https://arxiv.org/pdf/2004.03705.pdf" rel="noopener ugc nofollow" target="_blank">超过 150 个。</a></p><p id="4f76" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">文本分类问题中使用了几个基准数据集，最新的基准可以在<a class="ae kv" href="http://nlpprogress.com/english/text_classification.html" rel="noopener ugc nofollow" target="_blank">nlpprogress.com</a>上追踪。这是关于这些数据集的基本统计数据。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ls"><img src="../Images/93d48d7748de08ccfaf7beb9c4ea8b0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pai5iKi9zRpyNdasZ0ixZQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">文本分类基准数据集</p></figure><p id="0040" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">简单的文本分类应用程序通常遵循以下步骤:</p><ul class=""><li id="e711" class="lt lu iq ky b kz la lc ld lf lv lj lw ln lx lr ly lz ma mb bi translated">文本预处理和清理</li><li id="fc22" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">特征工程(从文本创建手工特征)</li><li id="ca81" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">特征矢量化(TfIDF、计数矢量化器、编码)或嵌入(word2vec、doc2vec、Bert、Elmo、句子嵌入等。)</li><li id="0db9" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">用 ML 和 DL 算法训练模型。</li></ul></div><div class="ab cl mh mi hu mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ij ik il im in"><h1 id="ce3e" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">Spark 自然语言处理中的文本分类</h1><p id="4b2d" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">在本文中，我们将使用通用句子嵌入在<a class="ae kv" href="https://nlp.johnsnowlabs.com/" rel="noopener ugc nofollow" target="_blank"> Spark NLP </a>中构建一个文本分类模型。然后我们将它与其他 ML 和 DL 方法以及文本矢量化方法进行比较。</p><p id="cca8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Spark NLP 中有几个文本分类选项:</p><ul class=""><li id="8aa7" class="lt lu iq ky b kz la lc ld lf lv lj lw ln lx lr ly lz ma mb bi translated">Spark NLP 中的文本预处理和使用来自<a class="ae kv" href="https://spark.apache.org/docs/latest/ml-guide.html" rel="noopener ugc nofollow" target="_blank"> Spark ML </a>的 ML 算法</li><li id="41b2" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">Spark ML 的 Spark NLP 和 ML 算法中的文本预处理和单词嵌入(Glove、Bert、Elmo)</li><li id="a1cf" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">Spark ML 的 Spark NLP 和 ML 算法中的文本预处理和句子嵌入(通用句子编码器)</li><li id="98de" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">Spark 自然语言处理中的文本预处理和分类器</li></ul><p id="2270" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如我们在关于 Spark NLP 的<a class="ae kv" rel="noopener" target="_blank" href="/introduction-to-spark-nlp-foundations-and-basic-components-part-i-c83b7629ed59">开创性文章中彻底讨论的那样，<code class="fe nl nm nn no b">ClassifierDL</code>之前的所有这些文本处理步骤都可以在一个指定为一系列阶段的流水线中实现，每个阶段要么是转换器，要么是估计器。这些阶段按顺序运行，输入数据帧在通过每个阶段时会发生转换。也就是说，数据按顺序通过拟合的管道。每个阶段的<em class="np"> transform() </em>方法更新数据集并将其传递给下一个阶段。在管道的帮助下，我们可以确保训练和测试数据经过相同的特征处理步骤。</a></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/e28f57ac6e3cec46c4ffde772edc3dee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OxF6K10HmocJtUdY"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">应用的每个注释器都会向数据框添加一个新列，该数据框将被输入到管道中</p></figure><p id="dbea" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以下是 Saprk NLP 中可用的单词/句子嵌入和语言模型。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/567afdac85fa3cc4cf93fde29714f8d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V02f9j7NoWmMHu5V27PpGg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Spark NLP 有 3 个接受句子嵌入的文本分类器</p></figure><h1 id="9f7b" class="mo mp iq bd mq mr ns mt mu mv nt mx my jw nu jx na jz nv ka nc kc nw kd ne nf bi translated">通用句子编码器(使用)</h1><p id="b7b9" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">在自然语言处理(NLP)中建立任何深度学习模型之前，文本嵌入起着主要作用。文本嵌入将文本(单词或句子)转换成数字向量。</p><blockquote class="nx ny nz"><p id="266b" class="kw kx np ky b kz la jr lb lc ld ju le oa lg lh li ob lk ll lm oc lo lp lq lr ij bi translated">基本上，文本嵌入方法将<strong class="ky ir">单词</strong>和<strong class="ky ir">句子</strong>编码在固定长度的密集向量中，以显著改善文本数据的处理。这个想法很简单:出现在相同上下文中的单词往往有相似的意思。</p></blockquote><p id="6fb0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">像 Word2vec 和 Glove 这样的技术是通过将单词转换成矢量来实现的。因此“猫”的对应向量将比“鹰”更接近“狗”。但是在嵌入一个句子时，需要在这个向量中捕获整个句子的上下文以及单词。<a class="ae kv" rel="noopener" target="_blank" href="/use-cases-of-googles-universal-sentence-encoder-in-production-dd5aaab4fc15">这就是“通用句子编码器”出现的地方</a>。</p><p id="0344" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">通用语句编码器将文本编码成高维向量，这些向量可用于文本分类、语义相似性、聚类和其他自然语言任务。预训练的通用句子编码器在<a class="ae kv" href="https://tfhub.dev/" rel="noopener ugc nofollow" target="_blank"> Tensorflow-hub </a>中公开提供。它有两种变化，即一种用<strong class="ky ir">变压器编码器</strong>训练，另一种用<strong class="ky ir">深度平均网络(DAN) </strong>训练。</p><p id="801a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Spark NLP 还使用了<a class="ae kv" href="https://tfhub.dev/" rel="noopener ugc nofollow" target="_blank"> Tensorflow-hub </a>版本的 use，它被封装在一种方式中，让它在 Spark 环境中运行。也就是说，您可以在 Spark NLP 中即插即用，以分布式方式训练模型。</p><p id="7748" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用为句子生成嵌入，而无需进一步计算，而不是对句子中每个单词的单词嵌入进行平均来获得句子嵌入。</p><h1 id="4e4d" class="mo mp iq bd mq mr ns mt mu mv nt mx my jw nu jx na jz nv ka nc kc nw kd ne nf bi translated">基于 ClassifierDL 的文本分类及其在 Spark NLP 中的应用</h1><p id="9182" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">在本文中，我们将使用文本分类任务中的基准数据集之一的<a class="ae kv" href="http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html" rel="noopener ugc nofollow" target="_blank"> AGNews 数据集</a>，使用版本 2.4.4 中添加到<a class="ae kv" href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.4.4" rel="noopener ugc nofollow" target="_blank"> Spark NLP 的最新分类模块<strong class="ky ir"> ClassifierDL </strong> annotator，在 Spark NLP 中构建一个文本分类器。</a></p><p id="ef60" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">是 Spark NLP 中第一个多类文本分类器，它使用各种文本嵌入作为文本分类的输入。<code class="fe nl nm nn no b">ClassifierDL</code>注释器使用深度学习模型(DNNs ),该模型内置于 TensorFlow 中，支持多达 50 个类。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/a2716322ae1c77592c1eaa8f0237cc9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*n0Bm7ExLAgs-8WUg"/></div></div></figure><p id="6df6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">也就是你可以用这个<code class="fe nl nm nn no b">ClassiferDL</code>在 Spark NLP 中构建一个<code class="fe nl nm nn no b">Bert</code>、<code class="fe nl nm nn no b">Elmo</code>、<code class="fe nl nm nn no b">Glove</code>、<code class="fe nl nm nn no b">Universal Sentence Encoders</code>的文本分类器。</p><p id="86a0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们开始编码吧！</p><p id="712e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">开始加载必要的包并启动 Spark 会话。</p><pre class="kg kh ki kj gt oe no of og aw oh bi"><span id="f1f4" class="oi mp iq no b gy oj ok l ol om">import sparknlp</span><span id="4863" class="oi mp iq no b gy on ok l ol om">spark = sparknlp.start() <br/># sparknlp.start(gpu=True) &gt;&gt; for training on GPU</span><span id="ddc9" class="oi mp iq no b gy on ok l ol om">from sparknlp.base import *<br/>from sparknlp.annotator import *<br/>from pyspark.ml import Pipeline<br/>import pandas as pd</span><span id="0a2b" class="oi mp iq no b gy on ok l ol om">print("Spark NLP version", sparknlp.version())</span><span id="d9b9" class="oi mp iq no b gy on ok l ol om">print("Apache Spark version:", spark.version)</span><span id="cd51" class="oi mp iq no b gy on ok l ol om">&gt;&gt; Spark NLP version 2.4.5<br/>&gt;&gt; Apache Spark version: 2.4.4</span></pre><p id="bcbf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后我们可以从<a class="ae kv" href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/tutorials/Certification_Trainings/Public" rel="noopener ugc nofollow" target="_blank"> Github repo </a>下载<code class="fe nl nm nn no b"><a class="ae kv" href="http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html" rel="noopener ugc nofollow" target="_blank">AGNews data set</a></code>。</p><pre class="kg kh ki kj gt oe no of og aw oh bi"><span id="b4f6" class="oi mp iq no b gy oj ok l ol om">! wget <a class="ae kv" href="https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_test.csv" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_train.csv</a></span><span id="4ec2" class="oi mp iq no b gy on ok l ol om">! wget <a class="ae kv" href="https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_test.csv" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_test.csv</a></span><span id="550b" class="oi mp iq no b gy on ok l ol om">trainDataset = spark.read \<br/>      .option("header", True) \<br/>      .csv("news_category_train.csv")</span><span id="e243" class="oi mp iq no b gy on ok l ol om">trainDataset.show(10, truncate=50)</span><span id="5303" class="oi mp iq no b gy on ok l ol om">&gt;&gt; <br/>+--------+--------------------------------------------------+<br/>|category|                                       description|<br/>+--------+--------------------------------------------------+<br/>|Business| Short sellers, Wall Street's dwindling band of...|<br/>|Business| Private investment firm Carlyle Group, which h...|<br/>|Business| Soaring crude prices plus worries about the ec...|<br/>|Business| Authorities have halted oil export flows from ...|<br/>|Business| Tearaway world oil prices, toppling records an...|<br/>|Business| Stocks ended slightly higher on Friday but sta...|<br/>|Business| Assets of the nation's retail money market mut...|<br/>|Business| Retail sales bounced back a bit in July, and n...|<br/>|Business|" After earning a PH.D. in Sociology, Danny Baz...|<br/>|Business| Short sellers, Wall Street's dwindling  band o...|<br/>+--------+--------------------------------------------------+<br/>only showing top 10 rows</span></pre><p id="399d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nl nm nn no b">AGNews</code>数据集有 4 个类:<code class="fe nl nm nn no b">World, Sci/Tech, Sports, Business</code></p><pre class="kg kh ki kj gt oe no of og aw oh bi"><span id="0207" class="oi mp iq no b gy oj ok l ol om">from pyspark.sql.functions import col</span><span id="8de7" class="oi mp iq no b gy on ok l ol om">trainDataset.groupBy("category") \<br/>    .count() \<br/>    .orderBy(col("count").desc()) \<br/>    .show()<br/>&gt;&gt;<br/>+--------+-----+<br/>|category|count|<br/>+--------+-----+<br/>|   World|30000|<br/>|Sci/Tech|30000|<br/>|  Sports|30000|<br/>|Business|30000|<br/>+--------+-----+</span><span id="8d39" class="oi mp iq no b gy on ok l ol om">testDataset = spark.read \<br/>      .option("header", True) \<br/>      .csv("news_category_test.csv")</span><span id="19b5" class="oi mp iq no b gy on ok l ol om">testDataset.groupBy("category") \<br/>    .count() \<br/>    .orderBy(col("count").desc()) \<br/>    .show()</span><span id="97e7" class="oi mp iq no b gy on ok l ol om">&gt;&gt;<br/>+--------+-----+<br/>|category|count|<br/>+--------+-----+<br/>|Sci/Tech| 1900|<br/>|  Sports| 1900|<br/>|   World| 1900|<br/>|Business| 1900|<br/>+--------+-----+</span></pre><p id="3302" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们可以将这个数据帧提供给 Spark NLP<a class="ae kv" href="https://medium.com/spark-nlp/spark-nlp-101-document-assembler-500018f5f6b5" rel="noopener">document assembler</a>，它是任何 Spark 数据报的 Spark NLP 的入口点。</p><pre class="kg kh ki kj gt oe no of og aw oh bi"><span id="652b" class="oi mp iq no b gy oj ok l ol om"># actual content is inside description column</span><span id="2b56" class="oi mp iq no b gy on ok l ol om">document = DocumentAssembler()\<br/>    .setInputCol("description")\<br/>    .setOutputCol("document")<br/>    <br/># we can also use sentence detector here <br/># if we want to train on and get predictions for each sentence</span><span id="e1e8" class="oi mp iq no b gy on ok l ol om"># downloading pretrained embeddings<br/>use = UniversalSentenceEncoder.pretrained()\<br/> .setInputCols(["document"])\<br/> .setOutputCol("sentence_embeddings")</span><span id="935a" class="oi mp iq no b gy on ok l ol om"># the classes/labels/categories are in category column</span><span id="d7c4" class="oi mp iq no b gy on ok l ol om">classsifierdl = ClassifierDLApproach()\<br/>  .setInputCols(["sentence_embeddings"])\<br/>  .setOutputCol("class")\<br/>  .setLabelColumn("category")\<br/>  .setMaxEpochs(5)\<br/>  .setEnableOutputLogs(True)</span><span id="3b20" class="oi mp iq no b gy on ok l ol om">use_clf_pipeline = Pipeline(<br/>    stages = [<br/>        document,<br/>        use,<br/>        classsifierdl<br/>    ])</span></pre><p id="a915" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">仅此而已。我们获取数据集，输入，然后从<code class="fe nl nm nn no b">USE</code>获取句子嵌入，然后在<code class="fe nl nm nn no b">ClassifierDL</code>中训练。零文本预处理或清洗！</p><p id="8f36" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们开始训练(试衣)。我们将使用<code class="fe nl nm nn no b">ClassiferDL</code>中的<code class="fe nl nm nn no b">.setMaxEpochs()</code>参数训练 5 个时期。在<code class="fe nl nm nn no b">Colab</code>环境中，大约需要 10 分钟才能完成。</p><pre class="kg kh ki kj gt oe no of og aw oh bi"><span id="8b89" class="oi mp iq no b gy oj ok l ol om">use_pipelineModel = use_clf_pipeline.fit(trainDataset)</span></pre><p id="4686" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当您运行这个时，Spark NLP 会将训练日志写到您主目录中的<code class="fe nl nm nn no b">annotator_logs</code>文件夹。以下是您阅读日志的方法。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oo"><img src="../Images/258b40265abd5dd01e3606d4c101a61a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pjY6uSCsaOF7Fuy_7bOxvw.png"/></div></div></figure><p id="d87a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如你所看到的，我们在不到 10 分钟的时间内达到了 90%以上的验证准确率，没有进行文本预处理，这通常是任何 NLP 建模中最耗时和费力的步骤。</p><p id="ffe2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在让我们看看<code class="fe nl nm nn no b">test set</code>上的预测。我们将使用上面下载的测试集。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi op"><img src="../Images/c2b994697841299829d30bf3ea8f3527.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*msem-X3IEuSse9JZ-1MK-w.png"/></div></div></figure><p id="f791" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面是我们如何通过<code class="fe nl nm nn no b">sklearn</code>库中的<code class="fe nl nm nn no b">classification_report</code>获得测试指标。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oq"><img src="../Images/19a03ffb3e4ae2887006456157b81b2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T4e3jzQvEFPEyIJcbsw3mg.png"/></div></div></figure><p id="a243" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们达到了 89.3%的测试集准确率！看起来不错！</p><h1 id="d6f5" class="mo mp iq bd mq mr ns mt mu mv nt mx my jw nu jx na jz nv ka nc kc nw kd ne nf bi translated">Spark 自然语言处理中嵌入 Bert 句子的文本分类</h1><p id="e696" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated"><em class="np">(在 2.6.0 版本之后，Spark NLP 引入了</em> <code class="fe nl nm nn no b"><em class="np">BertSentenceEmbeddings</em></code> <em class="np">注释器和 30 多个针对伊莱克特和伯特的预训练句子嵌入模型，大小不一。)</em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi or"><img src="../Images/6bbc2d7b8f05c39943e24de53fde3e5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QNX0z-E06JRriBrL_62gkw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Spark NLP Bert 模型中的命名约定。l 表示在产生嵌入时使用哪个池层，H 表示返回的嵌入的维度。点击查看完整列表<a class="ae kv" href="https://github.com/JohnSnowLabs/spark-nlp-models" rel="noopener ugc nofollow" target="_blank">。</a></p></figure><p id="e5f2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在让我们使用<code class="fe nl nm nn no b">BertSentenceEmbeddings</code>在同一个数据集上训练一个模型。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi os"><img src="../Images/9cbe81e3ffc2e604e6e660bbc761dceb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yjEi0YKiYMJ-MtqpcmfJxw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">用一个小伯特句子嵌入代替使用</p></figure><p id="decd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们只是加载了一个小的具有<code class="fe nl nm nn no b">L8</code>和<code class="fe nl nm nn no b">512</code>维度的 Bert 句子嵌入，并使用它来代替<code class="fe nl nm nn no b">USE.</code>，正如你所看到的，它的大小几乎是<code class="fe nl nm nn no b">USE</code>的八分之一，具有 Bert 的强大功能。这是我们在训练后得到的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ot"><img src="../Images/ef3c005b269009c447d914066d853d24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2GoK8YHwCaWktctcXrNMzw.png"/></div></div></figure><p id="abd2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">几乎与我们从<code class="fe nl nm nn no b">USE</code>获得的指标相同。就像 AutoML on scale 一样，只需要几行代码！</p><h1 id="2202" class="mo mp iq bd mq mr ns mt mu mv nt mx my jw nu jx na jz nv ka nc kc nw kd ne nf bi translated">Spark 自然语言处理中文本预处理的文本分类</h1><p id="a860" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">正如在任何文本分类问题中的情况一样，有许多有用的文本预处理技术，包括词汇化、词干化、拼写检查和停用词移除，Python 中几乎所有的 NLP 库都有应用这些技术的工具<strong class="ky ir"> <em class="np">，除了拼写检查</em> </strong>。<em class="np">目前，Spark NLP 库是唯一一个现成的具有拼写检查功能的 NLP 库。</em></p><p id="4c94" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们在 Spark NLP 管道中应用这些步骤，然后用 Glove 单词嵌入训练一个文本分类器。我们将首先应用几个文本预处理步骤(通过仅保留字母、移除停用词、然后移除引理来标准化)，然后获得每个令牌的单词嵌入(令牌的引理)，然后对每个句子中的单词嵌入进行平均，以获得每行的句子嵌入。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ou"><img src="../Images/8963765b63c01542124b801c7b9f0214.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H8toZdCjtai4dfYlOd1YlQ.png"/></div></div></figure><p id="5216" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">关于 Spark NLP 中的所有这些文本预处理工具，您可以在这个<a class="ae kv" href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb" rel="noopener ugc nofollow" target="_blank"> Colab 笔记本中找到详细的说明和代码示例。</a></p><p id="46d1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后我们就能坐上火车了。</p><pre class="kg kh ki kj gt oe no of og aw oh bi"><span id="e760" class="oi mp iq no b gy oj ok l ol om">clf_pipelineModel = clf_pipeline.fit(trainDataset)</span></pre><p id="ea00" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">并获得测试指标。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ov"><img src="../Images/4d881b9c19ea078bb1a57629792faa67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3aHOhwnRLI-378Ge8T7NUQ.png"/></div></div></figure><p id="3d18" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们已经有 88%的测试集准确率了！即使在所有这些文本清理步骤之后，我们也无法击败<code class="fe nl nm nn no b">Universal Sentence Embeddings + ClassifierDL</code> :-)，这主要是因为与清理后的版本相比，<code class="fe nl nm nn no b">USE</code>通常在原始文本上表现更好，因为它已经在原始句子上进行了训练，当我们应用文本预处理时，我们引入了一些在<code class="fe nl nm nn no b">USE</code>被训练时没有看到的<code class="fe nl nm nn no b">noise</code>，并且句子一致性在清理时受到了损害。</p><p id="6eea" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了用<code class="fe nl nm nn no b">BERT</code>训练同一个分类器，我们可以在上面建立的同一个流水线中用<code class="fe nl nm nn no b">bert_embeddings</code>级代替<code class="fe nl nm nn no b">glove_embeddings</code>级。你可以在<a class="ae kv" rel="noopener" target="_blank" href="/named-entity-recognition-ner-with-bert-in-spark-nlp-874df20d1d77">这个链接</a>找到更多关于我们如何在 Spark NLP 中实现和利用<code class="fe nl nm nn no b">Bert</code>的信息。</p><pre class="kg kh ki kj gt oe no of og aw oh bi"><span id="e14e" class="oi mp iq no b gy oj ok l ol om">word_embeddings = BertEmbeddings\<br/>    .pretrained('bert_base_cased', 'en') \<br/>    .setInputCols(["document",'lemma'])\<br/>    .setOutputCol("embeddings")\</span><span id="127a" class="oi mp iq no b gy on ok l ol om"># we can also use <!-- -->Elmo<!-- --> embeddings instead.</span><span id="b33f" class="oi mp iq no b gy on ok l ol om">word_embeddings = ElmoEmbeddings\<br/>      .pretrained('elmo', 'en')\<br/>      .setInputCols(["document",'lemma'])\<br/>      .setOutputCol("embeddings")</span></pre><h1 id="a07e" class="mo mp iq bd mq mr ns mt mu mv nt mx my jw nu jx na jz nv ka nc kc nw kd ne nf bi translated">使用 LightPipeline 进行更快速的推断</h1><p id="25c2" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">正如我们之前的一篇文章<a class="ae kv" href="https://medium.com/spark-nlp/spark-nlp-101-lightpipeline-a544e93f20f1" rel="noopener">中彻底讨论的那样，<code class="fe nl nm nn no b">LightPipelines</code>是 Spark NLP 专用管道，相当于 Spark ML 管道，但意味着处理更少量的数据。它们在处理小型数据集、调试结果，或者从服务于一次性请求的 API 运行训练或预测时非常有用。</a></p><p id="885e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">【Spark ML 管道是否转换为单机但多线程的任务，对于较小的数据量，速度提高了 10 倍以上(小是相对的，但 50k 句子大约是一个很好的最大值)。要使用它们，我们只需插入一个经过训练的(合适的)管道，然后注释一个纯文本。我们甚至不需要将输入文本转换成数据帧，就可以将它输入到接受数据帧作为输入的管道中。当从一个训练好的 ML 模型中获得几行文本的预测时，这个特性将非常有用。</p><p id="0a6a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">光管道很容易创建，也让你不用处理 Spark 数据集。它们的速度也非常快，并且只在驱动节点上工作时，它们执行并行计算。让我们看看它是如何应用到我们上面描述的例子中的:</p><pre class="kg kh ki kj gt oe no of og aw oh bi"><span id="9367" class="oi mp iq no b gy oj ok l ol om">light_model = LightPipeline(<!-- -->clf_pipelineModel<!-- -->)</span><span id="a8e8" class="oi mp iq no b gy on ok l ol om">text="Euro 2020 and the Copa America have both been moved to the summer of 2021 due to the coronavirus outbreak."</span><span id="ceeb" class="oi mp iq no b gy on ok l ol om">light_model.annotate(text)['class'][0]</span><span id="9968" class="oi mp iq no b gy on ok l ol om">&gt;&gt; "Sports"</span></pre><p id="d12c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您还可以将这个训练好的模型保存到您的磁盘上，然后在另一个带有<code class="fe nl nm nn no b">ClassifierDLModel.load()</code>的 Spark 管道中使用。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/eb4d30c041113d425888d15cd1554ac4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*HWOz9UhV5vUsgSOTJTIokg.png"/></div></figure><h1 id="491c" class="mo mp iq bd mq mr ns mt mu mv nt mx my jw nu jx na jz nv ka nc kc nw kd ne nf bi translated">结论</h1><p id="4897" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">在本文中，我们使用流行的单词嵌入和通用句子编码器在 Spark NLP 中训练了一个多类文本分类模型，然后在不到 10 分钟的训练时间内获得了不错的模型精度。完整的代码可以在这个<a class="ae kv" href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/5.Text_Classification_with_ClassifierDL.ipynb" rel="noopener ugc nofollow" target="_blank"> Github repo (Colab 兼容)</a>找到。我们还准备了<a class="ae kv" href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/5.1_Text_classification_examples_in_SparkML_SparkNLP.ipynb" rel="noopener ugc nofollow" target="_blank">另一个笔记本</a>来涵盖 Spark NLP 和 Spark ML 中几乎所有可能的文本分类组合(CV、TfIdf、Glove、Bert、Elmo、USE、LR、RF、ClassiferDL、DocClassifier)。</p><p id="b8c5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们还开始为公共和企业(医疗保健)版本提供在线 Spark NLP 培训。这里是所有公开的 Colab 笔记本的链接，它将带你在几个小时内一步一步地从零到英雄。</p><p id="7b5a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://www.johnsnowlabs.com/" rel="noopener ugc nofollow" target="_blank"> John Snow Labs </a>将组织虚拟 Spark NLP 培训，以下是下一次培训的链接:</p><p id="3078" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">【https://events.johnsnowlabs.com/online-training-spark-nlp T2】号</p><p id="e013" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们希望您已经阅读了我们<a class="ae kv" href="https://medium.com/spark-nlp" rel="noopener">官方媒体页面</a>上的前几篇文章，加入了我们的<a class="ae kv" href="http://spark-nlp.slack.com" rel="noopener ugc nofollow" target="_blank"> slack 频道</a>，并开始玩 Spark NLP。以下是其他文章的链接。别忘了关注我们的页面，敬请期待！</p><p id="eeeb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://medium.com/spark-nlp/introduction-to-spark-nlp-foundations-and-basic-components-part-i-c83b7629ed59" rel="noopener">Spark NLP 简介:基础和基本组件(第一部分)</a></p><p id="ea70" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://medium.com/spark-nlp/introduction-to-spark-nlp-installation-and-getting-started-part-ii-d009f7a177f3?source=collection_home---6------0-----------------------" rel="noopener">Spark NLP 简介:安装和入门(第二部分)</a></p><p id="f510" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://medium.com/spark-nlp/spark-nlp-101-document-assembler-500018f5f6b5" rel="noopener"> Spark NLP 101:文档汇编器</a></p><p id="1542" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://medium.com/spark-nlp/spark-nlp-101-lightpipeline-a544e93f20f1" rel="noopener"> Spark NLP 101:光管道</a></p><p id="baa8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/named-entity-recognition-ner-with-bert-in-spark-nlp-874df20d1d77">Spark NLP 中带 BERT 的命名实体识别(NER)</a></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl ox"><img src="../Images/8046ff18422fbec4c51a43fe8aa745f0.png" data-original-src="https://miro.medium.com/v2/format:webp/1*TSDGA6Hgcc8-ZPxmeYk6Zg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Spark NLP 中使用的文本分类的整个管道</p></figure></div></div>    
</body>
</html>