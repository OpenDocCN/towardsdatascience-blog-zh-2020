<html>
<head>
<title>Predicting Fraudulent News Articles Using NLP + Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用NLP +深度学习预测欺诈性新闻文章</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/predicting-fraudulent-news-articles-using-nlp-deep-learning-ffdf64f19537?source=collection_archive---------58-----------------------#2020-05-12">https://towardsdatascience.com/predicting-fraudulent-news-articles-using-nlp-deep-learning-ffdf64f19537?source=collection_archive---------58-----------------------#2020-05-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6bc7" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">利用NLP、ML和深度学习分析和预测欺诈性新闻文章。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/401708ecaeee4d6550a7bd6eb654a5f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lfsK6Rf2V09yIewn"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/@joaosilas?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">乔·塞拉斯</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="1064" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">生活在一个网上信息泛滥的时代，让我们容易相信欺骗性的新闻报道。这个问题在互联网上大量存在，其需求要求我们用机器学习和深度学习模型进行实验，以对潜在虚假的新闻进行分类。</p><p id="1097" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这篇文章希望阐明“如何”利用自然语言处理、机器学习和深度学习来预测和识别欺诈性新闻文章。它还分享了从分析中得出的方法、结果和结论。</p><h1 id="c996" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated"><strong class="ak">获取数据:</strong></h1><p id="995f" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">包含真假新闻文章的数据集是从<a class="ae kv" href="https://www.kaggle.com/c/fake-news/data" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>获得的。数据集的形状是20800行和5列。数据集中有10413篇真实文章和10387篇虚假文章，表明数据集是平衡的。“<strong class="ky ir">标签“</strong>栏表示该商品是真的还是假的；<strong class="ky ir"> 1 </strong>表示假，<strong class="ky ir"> 0 </strong>表示真。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mp"><img src="../Images/d1f70207eb499e3eeaf5481ef976ec3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JHFKiF_MzbgmWLeMi58Zjw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图1:数据快照。</p></figure><h1 id="bd8f" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated"><strong class="ak">清理数据:</strong></h1><p id="fa88" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">由于文本数据是非结构化和杂乱的，因此需要进行文本预处理。一个<a class="ae kv" href="https://github.com/mominasadullahkhan/Predicting-Fake-News-Articles/blob/master/Final%20Model%20%2B%20Analysis%20Notebook/helper_functions.py" rel="noopener ugc nofollow" target="_blank">助手函数</a>被应用于数据，以移除换行符、新行、超链接、与符号、大于/小于符号、不间断空格、电子邮件、新行字符和分散注意力的单引号。创建了一个包含文章文本长度的新列“length”。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/3bbd5a40f9c5c7dc6a3dbc7205c4718e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B59z5MMoKx0dWJuJe4RPPg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图2:创建长度列后的数据集。</p></figure><p id="dce7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">数据集还在“author”和“article_title”列中包含由“Unknown”替换的空值。长度少于50个字符的文章也被删除，理由是少于50个字符的文章不是文章。</p><h1 id="2ccf" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated"><strong class="ak">探索性数据分析</strong></h1><p id="ecaa" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">名为<strong class="ky ir">‘text _ polarity’</strong>的列被添加到数据集中。使用<a class="ae kv" href="https://textblob.readthedocs.io/en/dev/quickstart.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> TextBlob </strong> </a>库的情感极性函数对<strong class="ky ir">‘文本’</strong>列返回文本的极性，从1到1表示从负到正。</p><p id="8cbd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">观察真实文章和虚假文章之间文本极性的分布如何不同将是有趣的。下图3A和3B分别展示了真文和假文的文本极性分布。</p><div class="kg kh ki kj gt ab cb"><figure class="mr kk ms mt mu mv mw paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/debdf523b43ab479222a7c966e83b4af.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/1*-XAamQBvzORP365xDAn7rw.png"/></div></figure><figure class="mr kk mx mt mu mv mw paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/98b0707f5a18a9502c064b67641483c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/1*t4lnB7xFbEhkpCx_4ViQoA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk my di mz na translated">左图3A，右图3B</p></figure></div><p id="da9a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这两类文章中文本极性的分布似乎是均匀的，有些文章是完全负面的，有些是完全正面的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/ef6f3cd72fcd18bf8dae8873a0351ce1.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*zXkoOZRCuZONcJM2cag77Q.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图4 —相关矩阵</p></figure><p id="ad70" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了检查数据集中不同特征之间的相关性，使用了热图。数据集中不存在强相关，数据集中长度和标签之间的最大相关值为-0.12，表明非常弱的负相关。</p><p id="e2dc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用CountVectorizer方法，绘制了去除和不去除停用词的前20个单字、双字和三元字。停用词指的是语言中最常见的词。在下面的例子中，图5A和5B显示了去除停用词后真实文章和虚假文章中的前20个三元模型。</p><div class="kg kh ki kj gt ab cb"><figure class="mr kk nc mt mu mv mw paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/03959137d31115a8e4d5c4aa4522aca9.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*4OGxkhf7DIPC7culpb8U0g.png"/></div></figure><figure class="mr kk nd mt mu mv mw paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/0dfeedd831c8d3fd7f432d4a90300a7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*agYnpxUm_L3xpN6FoNisJA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk ne di nf na translated">左侧—图5A，右侧—图5B</p></figure></div><p id="2511" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">推断统计分析:</strong></p><p id="a252" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，进行单样本t检验，以检验总体平均值是否与某些假设值有显著差异。进行统计t-检验以确定假文章的平均文本极性是否不同于所有文章的平均文本极性。</p><p id="ed56" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">假设检验:</strong>是假的文章和全文字文章在文字极性的均值上有显著差异吗？</p><p id="d40b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">无效假设:</strong>无效假设将是假文章和所有文本文章之间的文本极性没有差异。</p><p id="1ec4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">备选假设:</strong>备选假设将是假文章和所有文章之间的文本极性存在差异。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/4ec1d292372f859d0e302155a5999074.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wv2J7OKj7RVsYFywkzC1Ow.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图6</p></figure><p id="9ee4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">基于图6中的单样本t-检验结果，所有文章的平均文本极性与虚假文章的平均文本极性之间存在显著差异。在5%置信区间0.0025的低P值是拒绝零假设的良好指标。</p><h1 id="d574" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated"><strong class="ak">建模</strong></h1><p id="a3cb" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">下一步，也是我们分析的关键，需要训练模型来预测一篇新闻文章是真是假。在训练模型之前，我们需要将文本转换成适合这些算法的输入。为此，我们将使用两种方法，称为计数矢量器和TF-IDF(术语频率-逆文档频率)矢量器。</p><p id="3de8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">CountVectorizer用于通过将文本语料库转换为表示相应语料库中字数的向量来对其进行标记化。它还允许我们删除文本中的停用词，并检查最流行的N ' unigrams，bigrams和trigrams。</p><p id="64fd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">相反，TF-IDF是通过检查语料库并计算“术语频率”和“逆文档频率”获得的词频分数。术语频率是术语在文档中出现的频率，逆文档频率为文档中常见的词分配低权重。因此，TfidfVecotrizer获取一组文档，并将它们分配给一个TF-IDF特性矩阵。然后，这种矢量化形式可以用作训练模型的输入。</p><p id="113a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这两种方法都将作为多项式朴素贝叶斯分类器和逻辑回归分类器的输入。逻辑回归被用作基准模型。基准模型是一种用于参考的模型，用来比较其他模型相对于它的表现。</p><p id="db5c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">没有为逻辑回归执行超参数调整，并且使用0.01的<strong class="ky ir"> <em class="nh"> C值</em> </strong>对其进行训练。或者，对于多项式NB模型，使用交叉验证执行超参数调整，并发现<strong class="ky ir"> <em class="nh"> alpha </em> </strong> = 0.1是计数矢量器和TF-IDF矢量器模型中的最佳值。</p><p id="74d4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">LSTM(长短期记忆)神经网络是一种特殊类型的递归神经网络。<em class="nh">简单来说，LSTM网络有一些内部情境状态细胞，充当长期或短期记忆细胞。LSTM网络的输出由这些单元的状态调制。当我们需要神经网络的预测依赖于输入的历史背景，而不是仅仅依赖于最后一个输入</em>时，这是一个非常重要的属性。”[1] <a class="ae kv" href="https://medium.com/@assaad.moawad?source=post_page-----6775e8b540cd----------------------" rel="noopener">阿萨德·莫瓦德</a>，<a class="ae kv" href="https://medium.com/datathings/the-magic-of-lstm-neural-networks-6775e8b540cd" rel="noopener">LSTM神经网络的魔力</a> (2018)</p><p id="e024" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">创建LSTM模型时，每个文本中使用的<strong class="ky ir"><em class="nh"/></strong>最大字数等于50，000，<strong class="ky ir"> <em class="nh">最大字数</em> </strong>为250。LSTM模型的<strong class="ky ir"><em class="nh">spatial drop out 1d</em></strong>值为0.2，<strong class="ky ir"> <em class="nh">脱落值</em> </strong>为0.1，<strong class="ky ir"> <em class="nh">经常性脱落值</em> </strong>为0.1。</p><h1 id="f574" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated"><strong class="ak">结果</strong></h1><p id="b311" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">为了检验结果，计算了不同输入(计数矢量器和TF-IDF)和不同模型的准确性和AUC-ROC评分。在评估模型时，准确性本身可能是一个误导性的指标，因此还查看了AUC-ROC评分和ROC图。AUC-ROC是一个很好的评估指标，因为它考察了模型正确分类的能力，也为我们提供了假阳性和假阴性的概念。如果AUC分数高，则模型在预测类别标签方面做得很好，即0表示0，1表示1。在这种特殊情况下，如果AUC很高，这意味着模型预测真实的文章是真实的，而假文章是假的。</p><p id="857f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">图7A显示了使用计数矢量器和TF-IDF转换数据的不同分类器的结果。图7B显示了相同分类器的ROC曲线。</p><div class="kg kh ki kj gt ab cb"><figure class="mr kk ni mt mu mv mw paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/aa8a325829952fecf8a27ee58678f22f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/1*_GKLExsnBqQUuS5LU0wFZg.png"/></div></figure><figure class="mr kk nj mt mu mv mw paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/8ab2962e9a1298c897425fa6ec331406.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*tik3nwpNVpRPwHtSg7XhKQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk nk di nl na translated">左—图7A，右—图7B</p></figure></div><p id="10fb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">用计数矢量器来表征数据的逻辑回归给了我们最好的结果。它实现了95%的准确性和95%的AUC-ROC评分。尽管LSTM模型获得了更高的AUC-ROC评分，但使用它可能会矫枉过正，因为逻辑回归在准确性方面表现更好，并且具有更高的AUC-ROC评分。此外，逻辑回归计算成本较低。</p><p id="f9be" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最差的模型性能也是通过用TF-IDF矢量器的逻辑回归实现的，准确度和AUC-ROC得分为0.88。</p><h1 id="5368" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">模型评估</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nm"><img src="../Images/4f95e4d44f8d297f031e690e05599b37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7SkvvSRr_peavELwhKRL7g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图8A</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nn"><img src="../Images/6783bce8178179092b61c69353712042.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CEfaSBPbgQ0NBg2VHSLGLw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图8B</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/27e71e4608ba9ae3897ed1e50a6272f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*O4ibDlvFkFfMR9JNCp7ZUg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图8C</p></figure><p id="0e4c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">除了仅使用准确性作为评估指标之外，我们还使用了<strong class="ky ir"> AUC-ROC评分</strong>，它绘制了真阳性率与假阳性率的关系。我们还应该考虑假阳性和假阴性误差来评估我们的模型的性能。</p><p id="4190" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">假阳性(I型错误)</strong>:你预测文章是假的但却是真的。</p><p id="c069" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">假阴性(ⅱ型错误)</strong>:你预测文章是真的但却是假的。</p><p id="62cd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">图8A、8B和8C显示了每个分类器的混淆矩阵和分类报告。</p><h1 id="7c7f" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated"><strong class="ak">解释结果</strong></h1><p id="04ce" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">重要的是，我们不仅要预测新闻文章是真是假，还要估计新闻文章是真是假的概率。这将允许我们标记假新闻文章，并显示它是假的概率。</p><p id="9894" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">用这种方法我们会遇到两种问题。首先，考虑新闻文章被模型预测为假的，但实际上，新闻文章是真实的。这被称为误报，这种错误可能代价高昂，因为它可能导致公司尴尬，还可能导致用户流失。不过，这可以通过建立一个机制来报告被错误标记为假的文章来快速纠正。这可能是这个项目发展的许多方向之一。</p><p id="1ccb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">相反，考虑新闻文章被预测为真实但实际上是假的。随着越来越多的人接触到这篇假新闻，同时相信它是真实的，这篇文章将继续不受限制地被分享。这被称为假阴性，它有能力在敏感问题上播种不信任和分化在线用户。这对我们模型的有效性以及提供这些服务的公司的声誉更有害，因为它会导致人们不信任这个平台及其辨别真相和谎言的能力。为了缓解这个问题，可以建立一种机制，允许人们报告文章是否是假的，然后一个负责检查文章事实的团队根据他们的分析做出最终决定。这些只是一些可以实现的解决方案，它们既不意味着完美，也不声称是完美的。</p><p id="531c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可以在这里找到代码为<a class="ae kv" href="https://github.com/mominasadullahkhan/Predicting-Fake-News-Articles/blob/master/Final%20Model%20%2B%20Analysis%20Notebook/Final_Notebook_Capstone2_Detecting_Fake_News.ipynb" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir"><em class="nh"/></strong></a>的完整笔记本。如果您有问题、可以提出的改进建议或想要讨论想法，请随时联系我们。</p></div></div>    
</body>
</html>