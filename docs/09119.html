<html>
<head>
<title>Build your own deep learning image classification model in Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 Keras 中构建自己的深度学习图像分类模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/build-your-own-deep-learning-classification-model-in-keras-511f647980d6?source=collection_archive---------16-----------------------#2020-06-30">https://towardsdatascience.com/build-your-own-deep-learning-classification-model-in-keras-511f647980d6?source=collection_archive---------16-----------------------#2020-06-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e2a5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">从头开始构建自己的深度学习图像分类模型的直观指南</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/da79b586c693e3b7436530a77e68976e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*zC8qkxS7SD9NKLxCIHDeiA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图 1:Pascal-VOC 数据集的分类示例</p></figure></div><div class="ab cl ku kv hx kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="im in io ip iq"><h1 id="a56c" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">介绍</h1><p id="d36a" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi mp translated">图像分类是近年来越来越受欢迎的人工智能领域。它有各种各样的应用:自动驾驶汽车，人脸识别，增强现实，…</p><p id="a855" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">在这篇文章中，你将学习如何建立一个深度学习图像分类模型，该模型能够在<strong class="lv iu">的 10 个步骤</strong>中检测出图像中存在哪些对象。</p><p id="29a2" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">完整的代码可以在<a class="ae nd" href="https://colab.research.google.com/drive/1HmUBIzRkoO8KKFpAVBVDonLiFZKEqof9?usp=sharing" rel="noopener ugc nofollow" target="_blank">共享的 google collab </a>中找到，所以你可以在阅读文章的同时轻松地跟着编码。</p><p id="f637" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">读完这本指南，你会知道以下事情:</p><ul class=""><li id="1d34" class="ne nf it lv b lw my lz mz mc ng mg nh mk ni mo nj nk nl nm bi translated">如何建立一个为深度学习模型设计的编码环境？</li><li id="812c" class="ne nf it lv b lw nn lz no mc np mg nq mk nr mo nj nk nl nm bi translated">如何连接流行的影像分类数据集(Pascal VOC)</li><li id="8c1d" class="ne nf it lv b lw nn lz no mc np mg nq mk nr mo nj nk nl nm bi translated">如何使用 Keras &amp; Tensorflow 的组合创建深度学习卷积神经网络</li><li id="7795" class="ne nf it lv b lw nn lz no mc np mg nq mk nr mo nj nk nl nm bi translated">如何使用数据生成器高效地训练深度学习模型</li><li id="e8f8" class="ne nf it lv b lw nn lz no mc np mg nq mk nr mo nj nk nl nm bi translated">如何评估数据生成器的性能</li></ul></div><div class="ab cl ku kv hx kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="im in io ip iq"><h2 id="1a64" class="ns lc it bd ld nt nu dn lh nv nw dp ll mc nx ny ln mg nz oa lp mk ob oc lr od bi translated">步骤 1:设置环境</h2><p id="fcf7" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">请查看<a class="ae nd" href="https://colab.research.google.com/drive/1HmUBIzRkoO8KKFpAVBVDonLiFZKEqof9?usp=sharing" rel="noopener ugc nofollow" target="_blank">谷歌协作</a>获取所需的软件包。</p><p id="0ba3" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">从零开始构建深度学习卷积网络需要巨大的计算能力。普通的笔记本电脑不具备处理这些请求的能力。</p><p id="926e" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">幸运的是，谷歌来拯救我们了！他们已经开发了一个<a class="ae nd" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank">在线 python 笔记本</a>，给用户<strong class="lv iu">免费的计算能力。</strong></p><p id="45bc" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">您可以通过在笔记本电脑设置中选择 GPU 选项来启用计算能力功能。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/aa0122dfb5c3780f5688e3ee3a869b2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*uBd7vG12GhPRJKY8qT0DZQ.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/071cea904538c3e7bf989561b483a5bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*iJ-8QaDYXOFPUpMP3POmtQ.png"/></div></figure></div><div class="ab cl ku kv hx kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="im in io ip iq"><h2 id="9133" class="ns lc it bd ld nt nu dn lh nv nw dp ll mc nx ny ln mg nz oa lp mk ob oc lr od bi translated">步骤 2:导入数据</h2><p id="2bd1" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">我们将使用<a class="ae nd" href="http://host.robots.ox.ac.uk/pascal/VOC/" rel="noopener ugc nofollow" target="_blank"> Pascal VOC 图像数据集</a>用于我们的深度学习模型。</p><p id="69c8" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">Pascal VOC 数据集是一个图像数据集，在 Kaggle 上的计算机视觉竞赛中非常受欢迎。</p><p id="f407" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">使用 Wget 包下载数据集。这个包获取数据并下载到你当前的工作目录。</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="d4ad" class="ns lc it oh b gy ol om l on oo">import tarfile</span><span id="00a8" class="ns lc it oh b gy op om l on oo">!wget -nc http://host.robots.ox.ac.uk/pascal/VOC/voc2009/VOCtrainval_11-May-2009.tar</span></pre><p id="73c4" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">最后一步，打开 tarfile 并提取它。</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="0ce7" class="ns lc it oh b gy ol om l on oo">tf = tarfile.open("/content/VOCtrainval_11-May-2009.tar")</span><span id="c533" class="ns lc it oh b gy op om l on oo">tf.extractall()</span></pre><p id="8662" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">干得好！现在，您已经成功地加载并提取了数据集。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="or os di ot bf ou"><div class="gh gi oq"><img src="../Images/54e053b9f544599d1ab13f5217cdab95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K2JtjlPn68lJuux1K9X4Mw.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/17efbd055a58d4106ae4c3e2979fdc40.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*x90GBH6tMH-EYAgIkDCBqw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图 1: VOC 数据集结构</p></figure></div><div class="ab cl ku kv hx kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="im in io ip iq"><h2 id="efac" class="ns lc it bd ld nt nu dn lh nv nw dp ll mc nx ny ln mg nz oa lp mk ob oc lr od bi translated">步骤 3:加载数据</h2><p id="ff9a" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">当前的数据结构对于构建深度学习卷积模型不是最优的。<br/>因此，需要将数据转换成更可行的格式。</p><p id="834c" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">您提取的 Pascal VOC 数据集应该包含以下两个文件夹:</p><ul class=""><li id="c3fe" class="ne nf it lv b lw my lz mz mc ng mg nh mk ni mo nj nk nl nm bi translated">注释:该文件夹包含所有关于图像标签的信息。</li><li id="e28b" class="ne nf it lv b lw nn lz no mc np mg nq mk nr mo nj nk nl nm bi translated">JPEGImages:该文件夹包含所有原始图像</li></ul><p id="53ba" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">创建两个列表:</p><ul class=""><li id="b14a" class="ne nf it lv b lw my lz mz mc ng mg nh mk ni mo nj nk nl nm bi translated">文件名:在这个列表中，你保存所有图片的文件名。例如“2208–001068 . JPEG”</li><li id="184e" class="ne nf it lv b lw nn lz no mc np mg nq mk nr mo nj nk nl nm bi translated">分类:在这个列表中，你保存了所有的分类标签。例如“自行车、沙发”</li></ul><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="aa08" class="ns lc it oh b gy ol om l on oo">directory_annotations = '/content/VOCdevkit/VOC2009/Annotations'</span><span id="5ea1" class="ns lc it oh b gy op om l on oo">filenames = []<br/>classification = []</span></pre><p id="d9b8" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">遍历注释目录，提取文件名和标签，并将其添加到各自的列表中。</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="0dd9" class="ns lc it oh b gy ol om l on oo">for xml_file in os.listdir(directory_annotations):</span><span id="bb8b" class="ns lc it oh b gy op om l on oo">    # Save image for classification and their class label</span><span id="e3bd" class="ns lc it oh b gy op om l on oo">    if os.path.isfile(xml_file):<br/>    xml_tree = ET.parse(xml_file)<br/>    root = xml_tree.getroot()<br/>    imgname = root.find('filename').text.strip('.jpg')<br/>    labels = []<br/>    for obj in root.findall('object'):<br/>    label = obj.find('name').text<br/>    labels.append(label)</span><span id="91b5" class="ns lc it oh b gy op om l on oo">    filenames.append(imgname)<br/>    classification.append(labels)</span></pre></div><div class="ab cl ku kv hx kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="im in io ip iq"><h2 id="e35f" class="ns lc it bd ld nt nu dn lh nv nw dp ll mc nx ny ln mg nz oa lp mk ob oc lr od bi translated">步骤 4:预处理</h2><p id="e2c5" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">在这一步中，您必须对数据进行预处理:</p><ul class=""><li id="4d2d" class="ne nf it lv b lw my lz mz mc ng mg nh mk ni mo nj nk nl nm bi translated">在训练和测试集中拆分文件名和它们各自的分类。</li></ul><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="019b" class="ns lc it oh b gy ol om l on oo">label_filenames_temp = os.listdir(directory_annotations)<br/>filenames = []</span><span id="0317" class="ns lc it oh b gy op om l on oo">for lbl in label_filenames_temp:<br/>    filenames.append(lbl.split('.')[0])</span><span id="5bb9" class="ns lc it oh b gy op om l on oo">filecount = len(filenames)</span><span id="af93" class="ns lc it oh b gy op om l on oo">indexes = []</span><span id="446f" class="ns lc it oh b gy op om l on oo">for index in range(filecount):<br/>     indexes.append(index)</span><span id="0ea5" class="ns lc it oh b gy op om l on oo">training_indexes = indexes[:int(filecount*0.7)]<br/>validation_indexes = indexes[int(filecount*0.7):int(filecount*0.9)]<br/>testing_indexes = indexes[int(filecount*0.9):]<br/></span></pre><ul class=""><li id="c1f3" class="ne nf it lv b lw my lz mz mc ng mg nh mk ni mo nj nk nl nm bi translated">输出标签需要转换成数值，因为当输入和输出变量是数字时，深度学习网络表现得更好。</li></ul><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="19a8" class="ns lc it oh b gy ol om l on oo">directory_images = '/content/VOCdevkit/VOC2009/JPEGImages'</span><span id="99cb" class="ns lc it oh b gy op om l on oo">directory_annotations = '/content/VOCdevkit/VOC2009/Annotations'</span><span id="8a35" class="ns lc it oh b gy op om l on oo">labelnames = preprocessing.LabelEncoder()</span><span id="aad0" class="ns lc it oh b gy op om l on oo">labelnames.fit(["aeroplane", "bicycle", "bird", "boat", "bottle", "bus", "car", "cat", "chair", "cow", "diningtable", "dog", "horse", "motorbike", "person", "pottedplant", "sheep", "sofa", "train", "tvmonitor"])</span></pre><ul class=""><li id="0c7e" class="ne nf it lv b lw my lz mz mc ng mg nh mk ni mo nj nk nl nm bi translated">图像大小调整为 224，224，3 格式。在基于 VGG16 模型架构构建深度学习网络时，文献综述对此提出了建议。(西蒙扬&amp;齐瑟曼，2014 年)</li></ul><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="3678" class="ns lc it oh b gy ol om l on oo">def generate_from_xml(filename):</span><span id="b5c7" class="ns lc it oh b gy op om l on oo">label = np.zeros((20), dtype = 'float32')</span><span id="87c3" class="ns lc it oh b gy op om l on oo">tree = ET.parse(os.path.join(directory_annotations, filename + ".xml"))</span><span id="f83b" class="ns lc it oh b gy op om l on oo">raw_image = cv2.imread(os.path.join(directory_images, filename + ".jpg"))</span><span id="e996" class="ns lc it oh b gy op om l on oo">res_img = cv2.resize(raw_image, (224,224))</span><span id="6990" class="ns lc it oh b gy op om l on oo">     for elems in tree.iter():<br/>         if elems.tag == "object":<br/>            name = elems.find("name").text<br/>            labelnr = labelnames.transform([name])[0]<br/>            label[labelnr] = 1</span><span id="f1ee" class="ns lc it oh b gy op om l on oo">return label, res_img</span></pre></div><div class="ab cl ku kv hx kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="im in io ip iq"><h2 id="ef24" class="ns lc it bd ld nt nu dn lh nv nw dp ll mc nx ny ln mg nz oa lp mk ob oc lr od bi translated">第 5 步:数据生成器</h2><p id="2044" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">在巨大的数据集上训练模型需要大量的 ram 内存。</p><p id="f7e5" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">如果你像我一样，没有超级计算机，你必须使用数据生成器。</p><p id="42d2" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">数据生成器将小批量的数据提供给模型。这允许我们在没有大量内存的情况下训练我们的模型。</p><p id="623b" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">使用大数据集时，最好使用数据生成器(而不是购买更多的 ram 内存)。数据生成器的细节超出了本文的范围，但是如果您感兴趣的话，可以查看下面的<a class="ae nd" href="https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><p id="53ae" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">在下一个代码块中，创建一个 datagenerator 类实例，并调用它两次:</p><ul class=""><li id="b61f" class="ne nf it lv b lw my lz mz mc ng mg nh mk ni mo nj nk nl nm bi translated">一次用于训练集</li><li id="8e13" class="ne nf it lv b lw nn lz no mc np mg nq mk nr mo nj nk nl nm bi translated">一次用于验证集</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="or os di ot bf ou"><div class="gh gi ow"><img src="../Images/c4bd8b536c35c6db20b25aaae43b7c63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BomSzO0b8f-KN8tlRcNC8w.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="or os di ot bf ou"><div class="gh gi ox"><img src="../Images/7f732259f029db9bce6a8e9bb9b5e84d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UjyN7W7upzUEvEsIdrBvOA.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="or os di ot bf ou"><div class="gh gi oy"><img src="../Images/0ef34d51a3acf1b3f01c7200350b45d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v5ymDDwWGmaTeuNLXQ48Bg.png"/></div></div></figure></div><div class="ab cl ku kv hx kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="im in io ip iq"><h2 id="9278" class="ns lc it bd ld nt nu dn lh nv nw dp ll mc nx ny ln mg nz oa lp mk ob oc lr od bi translated">步骤 6:创建我们的模型</h2><p id="08cc" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">在此步骤中，您将构建分类卷积神经网络的架构。</p><p id="f197" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">模型架构基于流行的 VGG-16 架构。这是一个总共有 13 个卷积层的 CNN(CFR。图 1)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/2508da8ed7010a152ae27f19d62806d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*UpnnnjemYces2c9XroCcZw.png"/></div></figure><p id="b1e8" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">下面的代码块表明您将按顺序构建模型。这意味着你会一层又一层。</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="9888" class="ns lc it oh b gy ol om l on oo">model = Sequential()</span></pre><p id="478c" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">你增加两个卷积层。<br/>在卷积层，对图像应用多个滤波器以提取不同的特征。</p><p id="762d" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">给出的参数:</p><p id="d30f" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">- Input-shape:给定图像的形状应为(224，224，3)。</p><p id="9911" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">- Filters:卷积层将学习的过滤器数量。</p><p id="9588" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">- Kernel_size:指定 2D 卷积窗口的宽度和高度。</p><p id="9032" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">-填充:指定“相同”可确保卷积后空间维度相同。</p><p id="1164" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">-激活:这更多的是一个方便的论点。这里，我们指定哪个激活函数将在卷积层之后<strong class="lv iu">被应用。我们将应用 ReLU 激活功能。稍后将详细介绍。</strong></p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="a87b" class="ns lc it oh b gy ol om l on oo">model.add(Conv2D(input_shape=(224,224,3),filters=64,</span><span id="f6d8" class="ns lc it oh b gy op om l on oo">kernel_size=(3,3),padding="same", activation="relu"))</span><span id="e2a2" class="ns lc it oh b gy op om l on oo">model.add(Conv2D(filters=64,</span><span id="759e" class="ns lc it oh b gy op om l on oo">kernel_size=(3,3),padding="same", activation="relu"))</span></pre><p id="b958" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">接下来，添加 1 个 maxpool 层。</p><p id="b742" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">池用于通过减少前一卷积层输出中的像素数量来降低图像的维数。</p><p id="f9d3" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">- Pool_size= 2，2--&gt;这是一个“矩阵”,它将检查输出并从中获取最大值</p><p id="320e" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">-跨距= 2，2--&gt;池矩阵沿 x 和 y 轴移动的增量。</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="0e0a" class="ns lc it oh b gy ol om l on oo">model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))</span></pre><p id="cafb" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">我们继续向我们的深度学习网络添加层。应用如上所述的相同逻辑。</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="fb71" class="ns lc it oh b gy ol om l on oo">model.add(Conv2D(filters=128, kernel_size=(3,3),padding="same", activation="relu"))</span><span id="90a3" class="ns lc it oh b gy op om l on oo">model.add(Conv2D(filters=128, kernel_size=(3,3),</span><span id="caf0" class="ns lc it oh b gy op om l on oo">padding="same", activation="relu"))</span><span id="de5d" class="ns lc it oh b gy op om l on oo">model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))</span><span id="767c" class="ns lc it oh b gy op om l on oo">model.add(Conv2D(filters=256, kernel_size=(3,3),</span><span id="3804" class="ns lc it oh b gy op om l on oo">padding="same", activation="relu"))</span><span id="2c97" class="ns lc it oh b gy op om l on oo">model.add(Conv2D(filters=256, kernel_size=(3,3),</span><span id="7314" class="ns lc it oh b gy op om l on oo">padding="same", activation="relu"))</span><span id="cacc" class="ns lc it oh b gy op om l on oo">model.add(Conv2D(filters=256, kernel_size=(3,3),</span><span id="c47c" class="ns lc it oh b gy op om l on oo">padding="same", activation="relu"))</span><span id="5a14" class="ns lc it oh b gy op om l on oo">model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))</span><span id="4109" class="ns lc it oh b gy op om l on oo">model.add(Conv2D(filters=512, kernel_size=(3,3),</span><span id="49b2" class="ns lc it oh b gy op om l on oo">padding="same", activation="relu"))</span><span id="c146" class="ns lc it oh b gy op om l on oo">model.add(Conv2D(filters=512, kernel_size=(3,3),</span><span id="984b" class="ns lc it oh b gy op om l on oo">padding="same", activation="relu"))</span><span id="dff3" class="ns lc it oh b gy op om l on oo">model.add(Conv2D(filters=512, kernel_size=(3,3),</span><span id="56b1" class="ns lc it oh b gy op om l on oo">padding="same", activation="relu"))</span><span id="9566" class="ns lc it oh b gy op om l on oo">model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))</span><span id="fda8" class="ns lc it oh b gy op om l on oo">model.add(Conv2D(filters=512, kernel_size=(3,3),</span><span id="6974" class="ns lc it oh b gy op om l on oo">padding="same", activation="relu"))</span><span id="4439" class="ns lc it oh b gy op om l on oo">model.add(Conv2D(filters=512, kernel_size=(3,3),</span><span id="8d0d" class="ns lc it oh b gy op om l on oo">padding="same", activation="relu"))</span><span id="aaac" class="ns lc it oh b gy op om l on oo">model.add(Conv2D(filters=512, kernel_size=(3,3),</span><span id="0d52" class="ns lc it oh b gy op om l on oo">padding="same", activation="relu"))</span><span id="7b72" class="ns lc it oh b gy op om l on oo">model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))</span></pre><p id="40b0" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">现在卷积的基础已经建立了。为了能够产生一个预测，你必须使卷积基的输出变平。</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="7ba3" class="ns lc it oh b gy ol om l on oo">model.add(Flatten())</span></pre><p id="6a66" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">添加密集层。密集层将卷积基底的输出馈送给它的神经元。</p><p id="96a9" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">参数:</p><p id="ec36" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">-单位:神经元的数量</p><p id="75bc" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">-激活功能:Relu</p><p id="5962" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">Relu 激活功能加速了训练，因为梯度计算非常简单(0 或 1)。这也意味着负值不会传递或“激活”到下一层。这使得只有一定数量的神经元被激活，这使得计算变得有趣。</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="23c3" class="ns lc it oh b gy ol om l on oo">model.add(Dense(units=4096,activation="relu"))</span><span id="be06" class="ns lc it oh b gy op om l on oo">model.add(Dense(units=4096,activation="relu"))</span></pre><p id="a107" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">您添加了一个 sigmoid 层，以便将前一层的输出转换为概率分布。sigmoid 是多标签分类的理想选择，因此我们使用 sigmoid 代替 softmax 激活。</p><p id="3685" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">由 sigmoid 产生的概率是独立的，并且不局限于总和为 1。这在具有多个输出标签的分类中至关重要。</p><p id="18a2" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">您将单位参数设置为 20，因为我们有 20 个可能的类。</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="10b7" class="ns lc it oh b gy ol om l on oo">model.add(Dense(units=20, activation="sigmoid"))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/4ad1440e1bfb55bb4fa58367bbd4cf76.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*NY3iBS_5UhiBuGD4tlm1Sg.png"/></div></figure></div><div class="ab cl ku kv hx kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="im in io ip iq"><h2 id="a858" class="ns lc it bd ld nt nu dn lh nv nw dp ll mc nx ny ln mg nz oa lp mk ob oc lr od bi translated">步骤 7:损失函数和优化器</h2><p id="99f0" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">在步骤 7 中，您必须编译模型。您使用 RMSprop optimier 来达到全局最小值。你设置学习率为 0.001。</p><p id="6dd8" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated"><strong class="lv iu"> RMSprop </strong>，均方根 prop，是一个未发表的优化算法，但很受机器学习从业者的欢迎。它减少了垂直方向的波动，同时加快了水平方向的学习。这使得我们的模型更快地收敛到全局最小值。与常规梯度下降算法的主要区别在于梯度的计算方式。梯度的计算公式如下图所示。</p><p id="a721" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">你设置<strong class="lv iu">二元交叉熵损失</strong>作为你的损失函数。<br/>建议将此损失函数用于多标签分类，因为属于某个类别的每个元素不应受到另一个类别的决策的影响。</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="f693" class="ns lc it oh b gy ol om l on oo">model.compile(optimizer= keras.optimizers.RMSprop(lr=0.001), loss='binary_crossentropy',</span><span id="821d" class="ns lc it oh b gy op om l on oo">metrics=['accuracy'])</span><span id="11fe" class="ns lc it oh b gy op om l on oo">model.summary()</span></pre></div><div class="ab cl ku kv hx kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="im in io ip iq"><h2 id="d2e0" class="ns lc it bd ld nt nu dn lh nv nw dp ll mc nx ny ln mg nz oa lp mk ob oc lr od bi translated">第八步:模型训练</h2><p id="2eeb" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">一旦模型性能在保留数据集上停止改善，就可以使用 earlystopping 方法来停止定型。<br/>通过这种方式，您可以在监控过度拟合的同时自动获得完美的时期数。</p><p id="03b2" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">你给提前停止的人下达指令，寻求验证损失的最小值。</p><p id="5c3b" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">早期停止方法仅在没有检测到进一步改善时停止训练。</p><p id="978e" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">但是，最后一个纪元不一定是性能最好的纪元。</p><p id="a924" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">因此，您也可以使用模型检查点方法。这将保存在基于验证损失的训练期间观察到的最佳模型。</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="a1a6" class="ns lc it oh b gy ol om l on oo">filepath = "/content/drive/My Drive/MYCNN/CNN1505_v1.h5"</span><span id="c581" class="ns lc it oh b gy op om l on oo">earlyStopping = EarlyStopping(monitor='val_loss', verbose=0, mode='min', patience = 4)</span><span id="3c27" class="ns lc it oh b gy op om l on oo">mcp_save = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', mode='min')</span></pre><p id="ae45" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">现在，你将开始训练我们的深度学习神经网络。我们使用 keras 的 fit 生成器批量加载数据。这是必要的，因为我们的整个训练集不适合我们的内存。</p><p id="ffcd" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">您可以设置以下参数:</p><ul class=""><li id="d928" class="ne nf it lv b lw my lz mz mc ng mg nh mk ni mo nj nk nl nm bi translated">使用多重处理:是否使用基于进程的线程</li><li id="45ba" class="ne nf it lv b lw nn lz no mc np mg nq mk nr mo nj nk nl nm bi translated">Workers:并行生成批处理的线程数。</li></ul><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="fd3d" class="ns lc it oh b gy ol om l on oo">history = model.fit_generator(generator=training_generator,<br/>validation_data=val_generator,<br/>use_multiprocessing=True,<br/>workers=6,<br/>epochs = 20,<br/>callbacks=[earlyStopping, mcp_save])</span></pre><p id="fd09" class="pw-post-body-paragraph lt lu it lv b lw my ju ly lz mz jx mb mc na me mf mg nb mi mj mk nc mm mn mo im bi translated">当我们的培训结束后，您可以看到我们的培训和验证结果。绘制了两个指标:</p><ul class=""><li id="900a" class="ne nf it lv b lw my lz mz mc ng mg nh mk ni mo nj nk nl nm bi translated">模型精度</li><li id="9975" class="ne nf it lv b lw nn lz no mc np mg nq mk nr mo nj nk nl nm bi translated">模型损失</li></ul></div><div class="ab cl ku kv hx kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="im in io ip iq"><h2 id="a099" class="ns lc it bd ld nt nu dn lh nv nw dp ll mc nx ny ln mg nz oa lp mk ob oc lr od bi translated">步骤 9:验证我们的模型</h2><p id="35cf" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">你可以看到模型很快从第一个时期的巨大训练损失收敛到更低的数字。<br/>这种快速学习速率是由于所选优化器(RMS prop)的性质，它加快了收敛速度。<br/>当该度量在四个时期内没有改进时，训练过程挑选具有最低验证损失的模型。</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="b7a1" class="ns lc it oh b gy ol om l on oo">df = pd.DataFrame(history.history)<br/>print(history.history.keys())</span><span id="54c5" class="ns lc it oh b gy op om l on oo"># summarize history for accuracy</span><span id="e878" class="ns lc it oh b gy op om l on oo">plt.plot(history.history['accuracy'])</span><span id="f66e" class="ns lc it oh b gy op om l on oo">plt.plot(history.history['val_accuracy'])</span><span id="47d0" class="ns lc it oh b gy op om l on oo">plt.title('model accuracy')</span><span id="5a30" class="ns lc it oh b gy op om l on oo">plt.ylabel('accuracy')</span><span id="1724" class="ns lc it oh b gy op om l on oo">plt.xlabel('epoch')</span><span id="2915" class="ns lc it oh b gy op om l on oo">plt.legend(['train', 'test'], loc='upper left')</span><span id="6ff3" class="ns lc it oh b gy op om l on oo">plt.show()</span><span id="a3ef" class="ns lc it oh b gy op om l on oo"># summarize history for loss</span><span id="e1cf" class="ns lc it oh b gy op om l on oo">plt.plot(history.history['loss'])</span><span id="7e4a" class="ns lc it oh b gy op om l on oo">plt.plot(history.history['val_loss'])</span><span id="9749" class="ns lc it oh b gy op om l on oo">plt.title('model loss')</span><span id="d824" class="ns lc it oh b gy op om l on oo">plt.ylabel('loss')</span><span id="cfec" class="ns lc it oh b gy op om l on oo">plt.xlabel('epoch')</span><span id="b9b4" class="ns lc it oh b gy op om l on oo">plt.legend(['train', 'test'], loc='upper left')</span><span id="9276" class="ns lc it oh b gy op om l on oo">plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/5726245e212cc55b08329fae52980ba5.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*OMqZBH4fP82Q13zzgV3L7A.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/fc41a93d86f765b611f786d4bc82b40e.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*s6Bk87jFTPAoMY6SsVZ2HQ.png"/></div></figure></div><div class="ab cl ku kv hx kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="im in io ip iq"><h2 id="7e77" class="ns lc it bd ld nt nu dn lh nv nw dp ll mc nx ny ln mg nz oa lp mk ob oc lr od bi translated">步骤 10:测试我们的模型性能</h2><p id="803a" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">在我们的最后一步，我们在看不见的数据(测试集)上测试我们的模型性能。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/111447776c296db15bf43319c3a3dbe5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*4y2CrIPUuEoWtlCWMQMNpQ.png"/></div></figure></div></div>    
</body>
</html>