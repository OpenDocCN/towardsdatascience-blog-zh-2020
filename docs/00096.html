<html>
<head>
<title>15-Minute Conceptual and Painless Introduction to Monte Carlo Methods and Applied Bayesian Inference</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">15 分钟的概念和无痛介绍蒙特卡罗方法和应用贝叶斯推理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/conceptual-background-for-painless-introduction-to-applied-bayesian-regression-using-pystan-c8f744e3823f?source=collection_archive---------15-----------------------#2020-01-03">https://towardsdatascience.com/conceptual-background-for-painless-introduction-to-applied-bayesian-regression-using-pystan-c8f744e3823f?source=collection_archive---------15-----------------------#2020-01-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="a057" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">贝叶斯方法和推理</h2><div class=""/><div class=""><h2 id="22ab" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">这篇文章应该作为我的教程<a class="ae kr" rel="noopener" target="_blank" href="/painless-introduction-to-applied-bayesian-inference-using-py-stan-36b503a4cd80">使用(Py)Stan </a>的应用贝叶斯推理的无痛介绍和使用 r-INLA 的(近似)贝叶斯回归的无痛介绍的背景。</h2></div><p id="0806" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">在这篇文章中，我将对贝叶斯推理和蒙特卡罗方法提供一个非常简短、自成一体的介绍，希望能启发你更深入地研究我所包含的一些参考资料。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lo"><img src="../Images/b8a8b49f947f2a7c60ff26bfadca97e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IkYtPZ0FVNG3uweyRFVgfA.jpeg"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">图片来自<a class="ae kr" href="https://pixabay.com/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=602944" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae kr" href="https://pixabay.com/users/imarksm-701058/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=602944" rel="noopener ugc nofollow" target="_blank"> imarksm </a></p></figure><p id="5a90" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">你可能听说过也可能没有听说过贝叶斯推理/回归/建模/分析...您可能只是偶然遇到它，从未真正想过它的用途，或者没有任何好的资源来开始。</p><p id="398c" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">事实上，贝叶斯推理[1]比它的频率主义对应物要复杂一些，大多数人都曾在学术界或非常专业的工业应用中真正使用过它。然而，它提供了一个非常丰富的框架来理解并最终在推理过程中利用更多的信息。此外，它以一种令人愉快的方式提升了概率和应用统计学之间的联系——一个真正的贝叶斯模型是一个生成模型。</p><p id="6c3e" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">对于这一系列文章，我将采用(传统的)基于可能性的建模方法。</p><h1 id="d9e1" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">贝叶斯推理 5 分钟</h1><p id="afff" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">贝叶斯推理允许我们将一些先入为主的，即<strong class="ku jd">先于</strong>的信念纳入到我们的建模中。我们可以从后验概率分布中进行采样，从而在完成实验后很好地了解我们感兴趣的参数的行为，而不是找到使我们的可能性最大化的参数值(最大可能性估计)。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/75bc1153467ea67ea05bacb04cd1b3de.png" data-original-src="https://miro.medium.com/v2/resize:fit:454/format:webp/1*7SCEKF6RaWNI50earuUM6g.png"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">模型拟合和推理中的原始贝叶斯恒等式。</p></figure><p id="e317" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">简单来说，我为我的模型参数(<em class="nc"> 𝜃 </em>)声明一个先验分布，并将其乘以我的观察数据的可能性(d)。为了让这个量作为概率密度函数，我必须用一个归一化常数来除它。然后我得到我的后验分布函数。</p><p id="03d9" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">请注意，上面的归一化常数 P(D )(通常表示为 C)是难以处理的，除了在您有<strong class="ku jd">共轭</strong>先验的情况下，我们通常依靠蒙特卡罗方法从这种推断的后验分布中取样。在用各种各样的基本模型这样做的时候，我们可以排除这个量 C 而不会失去我们的睡眠。</p><p id="6cfc" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">你可能会问:<strong class="ku jd">为什么要这样做？</strong></p><p id="5c91" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">更好的科学，更古板的推理，正则化，数值稳定性，昂贵的数据采集不允许极大似然估计，还有很多很多更多的原因。</p><p id="20c0" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">你可能会问:<strong class="ku jd">什么是好的前科？</strong></p><ul class=""><li id="2b96" class="nd ne it ku b kv kw ky kz lb nf lf ng lj nh ln ni nj nk nl bi translated">易处理性？共轭！例如，正态先验 x 正态似然产生一个正态后验，可以解析求解！</li><li id="1e4c" class="nd ne it ku b kv nm ky nn lb no lf np lj nq ln ni nj nk nl bi translated">科学相关性</li><li id="9c14" class="nd ne it ku b kv nm ky nn lb no lf np lj nq ln ni nj nk nl bi translated">正规化。在标准线性回归的情况下，回归器/beta 服务器上的 N(0，1)先验可以用作 L2 正则化。</li></ul><p id="f7ed" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">理想情况下，先验知识不需要查看数据。</p><p id="0876" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">你可能会问:<strong class="ku jd">有什么样的前科？</strong></p><ul class=""><li id="76bc" class="nd ne it ku b kv kw ky kz lb nf lf ng lj nh ln ni nj nk nl bi translated">无信息的(扁平的)前科。在大多数情况下，原始的无信息先验将是均匀分布的，更具体地说，在下面掷硬币问题的上下文中。</li><li id="3533" class="nd ne it ku b kv nm ky nn lb no lf np lj nq ln ni nj nk nl bi translated">信息不足的前科。我在下面的抛硬币问题中声明的β先验提供的信息很少，因为我没有丢弃θ参数空间中的区间或点，而我倾向于“公平”。</li><li id="3a13" class="nd ne it ku b kv nm ky nn lb no lf np lj nq ln ni nj nk nl bi translated">信息丰富的前科。这些通常基于专家意见或扎实的科学知识。</li></ul><p id="7541" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">举个例子，假设我在地板上发现了一枚硬币，我想知道它是否公平。我宣布<em class="nc"> p=𝜃 </em>是在一次给定的投掷中，硬币将产生“正面”的概率(y=1)。那么 q=1- <em class="nc"> 𝜃 </em>就是硬币产生“反面”(y=0)的概率。注意，硬币的这种行为可以被建模为具有以下函数形式的伯努利随机变量:</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/a6e006a6cb879f03dd47ae2f776dc69a.png" data-original-src="https://miro.medium.com/v2/resize:fit:422/format:webp/1*gwTSrA6WuRo8R1B6iWwtJQ.png"/></div></figure><p id="a9e4" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">假设我掷硬币 4 次，观察到它总是给我“反面”如果我采用最大似然框架，那么我有以下 ML 估计(样本比例):</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/61cb18c8db9da8c957beadd951915edb.png" data-original-src="https://miro.medium.com/v2/resize:fit:290/format:webp/1*cTEdS9uOmWQxC3cCjJH4pA.png"/></div></figure><p id="cbad" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">在我们的例子中，上述结果为 0。但这有点太极端了……两面表面积相等意味着硬币应该有非零的“正面”落地概率(尽管非常小)。如果一边比另一边小得不成比例，我们会立即注意到。</p><p id="bd01" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">现在，作为 Bayesians 人，说我们遇到了同样的硬币。在我们自己扔硬币之前，我们会形成一个关于硬币的先验信念。根据我的经验，硬币通常是公平的，所以我认为这枚硬币很可能是公平的，也有可能是不公平的。然后，我会进行我的实验，并获得一种感觉，这个硬币是否坚持我的信念。哦，我得到相同的结果{0，0，0，0}。</p><p id="6f93" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">对于有效的(弱信息)先验，我将使用 beta(a，b)分布，其中 a，b 为非负整数。这个先验是有意义的，因为贝塔分布的支持度是[0，1]，这里的<em class="nc"> 𝜃 </em>对应一个概率<strong class="ku jd">不能小于 0 或者大于 1。设置 a=b=u，其中 u 是正整数，产生在 0.5 附近对称的分布。此外，贝塔分布与伯努利分布共轭(也与二项式分布共轭，因为二项式随机变量由伯努利随机变量的和组成)。</strong></p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi nt"><img src="../Images/6c15d6c591ce6375d17a6914b8c8c2fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*75Nr5dBghQad-nr7-SS35Q.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">贝塔(5，5)分布的模拟</p></figure><p id="1918" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">然后我考虑以下模型:</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi nu"><img src="../Images/6149074275132c2b981f8216232eb07c.png" data-original-src="https://miro.medium.com/v2/resize:fit:330/format:webp/1*lLbkjt--V2E6_5AyQy5RTQ.png"/></div></div></figure><p id="bd03" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">这导致了:</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/48514dbd13e602359c48ea34512ba259.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*eFoPGXtiPfRnv7QLM_XkWw.png"/></div></figure><p id="fd6a" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">此处 C ≥0 表示归一化常数，对于本应用而言，不需要估计该常数。</p><p id="45c4" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">如果我们在上面的先验中设置 a=b=5，<strong class="ku jd">stan</strong>[2]——如何操作参见教程——得出<em class="nc"> 𝜃 </em>的近似后验均值<strong class="ku jd">0.36</strong>&lt;5。因此，我们的估计表明一个有偏见的硬币，没有立即去 0。</p><h1 id="d870" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">蒙特卡罗方法 5 分钟</h1><p id="ac76" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">出于本教程的目的，蒙特卡罗方法[3]将允许我们从模型参数的后验分布中取样。</p><p id="82b5" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">估计一个实值可积函数 f(x)的积分(I)的最简单的蒙特卡罗方法(假设在 0 ≤x≤1 上)表明，我们在[0，1]上对 x 的 K&gt;0 个独立样本进行采样，对这些 x_{i}中的每一个估计 f(x})，然后对它们求和并求平均。我们来要求 I </p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/7725c8b71cdf40b17516b6e67cdc926f.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/format:webp/1*Gjbrdiicdm7S9E55cavEoA.png"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">As K goes to infinity, this vanilla Monte Carlo estimate should converge to the value of the integral.</p></figure><p id="575c" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">The above is nice and easy, but we can actually use even more knowledge of statistics by observing the below:</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/d62a186826569f3aee59e98ffccb189f.png" data-original-src="https://miro.medium.com/v2/resize:fit:404/format:webp/1*gqS4ui2_QuEy1ohY0E7hoA.png"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">We can think of the integral I as the expected value of f(x) and the below quantity as its unbiased estimator</p></figure><p id="8b8c" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">Our estimator is just an approximation, so it would behoove us to quantify its accuracy:</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/86082b947e86d3203fd79da4e2c163a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*g9HOpnR2g5s5ODXY8bux6A.png"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">Here we simply change the notation a bit and show the formula for the standard error</p></figure><p id="c99f" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">So, what can we do now that we have an unbiased estimate for the mean and an estimate of the standard error? Let’s invoke the <strong class="ku jd">中心极限定理</strong>，对于 K 足够大是合理的。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/1a7f98d4f10d56ec9dbd6c7ef56be109.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*9Ut6FuowyMyn5fs-iABODA.png"/></div></figure><p id="04f3" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">使用上述方法，我们可以为积分的估计量建立 95%的置信区间:</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/dbe57d874cf291fe2272ac5102ac4f09.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/1*ZgGVyZSN-bBg0nSTih2cHA.png"/></div></figure><p id="4e1f" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">上面的方法非常幼稚和不准确，特别是当目标(概率)在维度、多模态等方面增长时。然而，这给了你 MC 方法的要点:</p><blockquote class="ob"><p id="a063" class="oc od it bd oe of og oh oi oj ok ln dk translated"><em class="ol">从一个分布中抽取样本，以逼近另一个分布或感兴趣的数量。</em></p></blockquote><p id="05e7" class="pw-post-body-paragraph ks kt it ku b kv om kd kx ky on kg la lb oo ld le lf op lh li lj oq ll lm ln im bi translated">请注意，蒙特卡罗方法是一个非常活跃的研究领域，具有非常丰富的理论和应用，我鼓励你阅读更多关于它们的内容。蒙特卡洛计算引擎上也有几个包装器(PyMC3、Stan、BUGS 等)，可以很容易地集成到 Python、R 和其他现代统计/机器学习软件中。</p><p id="3966" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">下面是一些非常基本的方法让你开始:</p><ul class=""><li id="1509" class="nd ne it ku b kv kw ky kz lb nf lf ng lj nh ln ni nj nk nl bi translated">重要性抽样</li><li id="4a34" class="nd ne it ku b kv nm ky nn lb no lf np lj nq ln ni nj nk nl bi translated">拒绝抽样</li><li id="7caf" class="nd ne it ku b kv nm ky nn lb no lf np lj nq ln ni nj nk nl bi translated">Metropolis-Hastings 算法(马尔可夫链蒙特卡罗)</li><li id="590c" class="nd ne it ku b kv nm ky nn lb no lf np lj nq ln ni nj nk nl bi translated">奖励:模拟退火(优化)</li></ul><h1 id="7bd0" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">乳胶和数学交流</h1><p id="77a5" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">最后一件事。如果你真的想发展简洁而精确地交流数学/统计思想的能力，那么我鼓励你开始尝试使用<strong class="ku jd"> LaTeX </strong> [5]。LaTeX 是一个强大的排版系统，可以让你写出漂亮的公式，并无缝地呈现在你的文档中。我在本文档和我的所有作品中的所有数学表达式中都使用 LaTeX。</p><h1 id="4761" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">结论</h1><p id="0958" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">随着更好的计算硬件和软件的出现，贝叶斯推理和计算最近经历了一次辉煌的复兴。此外，贝叶斯方法跨越了大量活跃的研究领域，包括统计学、数学、计算机科学、人口学、经济学和许多其他领域。</p><p id="3841" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">以下是现代 ML 和统计研究中的一些最热门的主题，它们依赖或大量使用贝叶斯框架进行推理:</p><ul class=""><li id="53db" class="nd ne it ku b kv kw ky kz lb nf lf ng lj nh ln ni nj nk nl bi translated">因果推理</li><li id="b926" class="nd ne it ku b kv nm ky nn lb no lf np lj nq ln ni nj nk nl bi translated">可解释性(DL 和 RL)</li><li id="d9f1" class="nd ne it ku b kv nm ky nn lb no lf np lj nq ln ni nj nk nl bi translated">贝叶斯超参数优化(AlphaGo)</li><li id="4a6b" class="nd ne it ku b kv nm ky nn lb no lf np lj nq ln ni nj nk nl bi translated">多任务学习</li><li id="cb0f" class="nd ne it ku b kv nm ky nn lb no lf np lj nq ln ni nj nk nl bi translated">RL 中的探索与开发</li><li id="9f9c" class="nd ne it ku b kv nm ky nn lb no lf np lj nq ln ni nj nk nl bi translated">高效、计算稳定的 MCMC (HMC)</li></ul><h1 id="9534" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated"><strong class="ak">参考文献</strong></h1><p id="bfde" class="pw-post-body-paragraph ks kt it ku b kv mw kd kx ky mx kg la lb my ld le lf mz lh li lj na ll lm ln im bi translated">[1] R. Neal，<a class="ae kr" href="https://www.cs.toronto.edu/~radford/ftp/bayes-tut.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="ku jd">贝叶斯推理教程，供 ML </strong> </a> (2004)，NeurIPS，2004 .</p><p id="1c41" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">[2] B. Carpenter 等，<a class="ae kr" href="https://www.jstatsoft.org/article/view/v076i01" rel="noopener ugc nofollow" target="_blank"> <strong class="ku jd"> Stan:一种概率编程语言</strong> </a> <strong class="ku jd"> </strong> (2017)，统计软件杂志。</p><p id="2ab7" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">[3] C .罗伯特和 g .卡塞拉，<a class="ae kr" href="https://www.amazon.ca/Monte-Statistical-Methods-Christian-Robert/dp/0387212396/ref=sr_1_1?ie=UTF8&amp;s=books&amp;qid=1226423218&amp;sr=1-1" rel="noopener ugc nofollow" target="_blank"> <strong class="ku jd">蒙特卡洛统计方法</strong> </a> (2005)，施普林格文本《统计学》。</p><p id="50ca" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">[4] D .瓦克利等人，<a class="ae kr" href="https://www.cengage.com/c/mathematical-statistics-with-applications-7e-wackerly/9780495110811/" rel="noopener ugc nofollow" target="_blank"> <strong class="ku jd">数理统计与应用</strong> </a> <strong class="ku jd"> </strong> (2014)，森盖奇学习</p><p id="f652" class="pw-post-body-paragraph ks kt it ku b kv kw kd kx ky kz kg la lb lc ld le lf lg lh li lj lk ll lm ln im bi translated">[5]LaTeX 3 项目，<a class="ae kr" href="https://www.latex-project.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="ku jd"> LaTeX — A 文件编制系统</strong> </a> <strong class="ku jd"> </strong> (1985)，LaTeX 项目公共许可证<a class="ae kr" href="https://www.latex-project.org/lppl/" rel="noopener ugc nofollow" target="_blank">(https://www.latex-project.org/lppl/</a>)</p></div></div>    
</body>
</html>