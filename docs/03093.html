<html>
<head>
<title>Isolation Forest and Pyspark part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">隔离森林和 Pyspark 第 2 部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/isolation-forest-and-pyspark-part-2-76f7cd9cee56?source=collection_archive---------28-----------------------#2020-03-24">https://towardsdatascience.com/isolation-forest-and-pyspark-part-2-76f7cd9cee56?source=collection_archive---------28-----------------------#2020-03-24</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="2d5b" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">经验教训</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/182db3296fb95ef6458f435f5d46573b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8quIxeZW8Hf5OZxCFt9Zxw.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">调试 PySpark 和隔离森林—图片由作者提供</p></figure><p id="7d9e" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">因此，在使用隔离森林的 PySpark ml 实现运行了几次之后，我偶然发现了一些事情，我想我应该写下来，这样你就不会浪费我在故障诊断上浪费的时间。</p><h1 id="c289" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">只有密集向量</h1><p id="20db" class="pw-post-body-paragraph kz la iu lb b lc mo jv le lf mp jy lh li mq lk ll lm mr lo lp lq ms ls lt lu in bi translated">在上一篇文章中，我使用了<code class="fe mt mu mv mw b">VectorAssembler</code>来收集特征向量。碰巧我的测试数据只创建了<code class="fe mt mu mv mw b">DenseVectors</code>，但是当我在不同的数据集上尝试这个例子时，我意识到:</p><ul class=""><li id="7bfd" class="mx my iu lb b lc ld lf lg li mz lm na lq nb lu nc nd ne nf bi translated"><code class="fe mt mu mv mw b"><strong class="lb iv">VectorAssembler</strong></code>可以在同一个数据帧中创建<strong class="lb iv">密集和稀疏向量</strong>(这很聪明，其他 spark ml 算法可以利用它并使用它)</li><li id="88c8" class="mx my iu lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated"><code class="fe mt mu mv mw b"><strong class="lb iv">Isolation Forest</strong></code> <strong class="lb iv"> </strong>(或者至少实现发现<a class="ae lv" href="https://github.com/titicaca/spark-iforest" rel="noopener ugc nofollow" target="_blank">这里的</a> ) <strong class="lb iv">不支持上面的</strong>，所以输入必须只有<code class="fe mt mu mv mw b">DenseVectors</code>。</li></ul><p id="8807" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">要演示该问题:</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nl nm l"/></div></figure><p id="eed9" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">目前的解决方法是将所有矢量转换为密集矢量，不幸的是使用了 udf。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nl nm l"/></div></figure><h1 id="8012" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">避免 OOM 和执行者的沟通问题</h1><blockquote class="nn no np"><p id="6782" class="kz la nq lb b lc ld jv le lf lg jy lh nr lj lk ll ns ln lo lp nt lr ls lt lu in bi translated">为大型数据集设置<strong class="lb iv">approxquantilerrelativeerror</strong><em class="iu">或</em> <strong class="lb iv"> <em class="iu">阈值</em> </strong> <em class="iu"> </em>参数<em class="iu"/></p></blockquote><p id="c654" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">如果你计划在一个大数据集上进行训练，比如超过 10M 行，即使你设置了<code class="fe mt mu mv mw b">maxSamples</code>和<code class="fe mt mu mv mw b">maxFeatures</code>这样的参数来降低维数，你也需要将<code class="fe mt mu mv mw b">approxQuantileRelativeError</code>参数设置得合理一些，比如<code class="fe mt mu mv mw b">0.2</code>。原因是<code class="fe mt mu mv mw b">approxQuantile</code>函数是一个使用起来非常昂贵的函数，尤其是如果我们期望<code class="fe mt mu mv mw b">approxQuantileRelativeError</code>是<code class="fe mt mu mv mw b">0.</code>(这是默认值)。这样做，大大减少了训练时间和 OOM 与执行者的沟通问题，而且，到目前为止，我还没有看到预测准确性的任何下降。</p><p id="0b04" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">从实施的评论来看:</p><pre class="kk kl km kn gu nu mw nv nw aw nx bi"><span id="10ba" class="ny lx iu mw b gz nz oa l ob oc"><em class="nq">* The proportion of outliers in the data set (0&lt; contamination &lt; 1).<br/>* It will be used in the prediction. In order to enhance performance,<br/>* Our method to get anomaly score threshold adopts DataFrameStsFunctions.approxQuantile,<br/>* which is designed for performance with some extent accuracy loss.<br/>* Set the param approxQuantileRelativeError (0 &lt; e &lt; 1) to calculate<br/>* an approximate quantile threshold of anomaly scores for large dataset.</em></span></pre><p id="2d00" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">或者，在 fit 中预先设置<code class="fe mt mu mv mw b">threshold</code>并避免<code class="fe mt mu mv mw b">approxQuantile</code>计算，如下所示:</p><pre class="kk kl km kn gu nu mw nv nw aw nx bi"><span id="9250" class="ny lx iu mw b gz nz oa l ob oc">model = iforest.fit(df, {<strong class="mw iv">'threshold'</strong>: 0.5})<br/>print(model.getThreshold())</span><span id="5c00" class="ny lx iu mw b gz od oa l ob oc">&gt; 0.49272560194039505</span></pre><p id="9da4" class="pw-post-body-paragraph kz la iu lb b lc ld jv le lf lg jy lh li lj lk ll lm ln lo lp lq lr ls lt lu in bi translated">希望这对您有所帮助并节省一些时间:)如果您有任何建议、更正或想法，请告诉我。</p><h2 id="ed6c" class="ny lx iu bd ly oe of dn mc og oh dp mg li oi oj mi lm ok ol mk lq om on mm oo bi translated">在此阅读有关如何将隔离林与 pyspark 一起使用的更多信息:</h2><div class="op oq gq gs or os"><a rel="noopener follow" target="_blank" href="/isolation-forest-and-spark-b88ade6c63ff"><div class="ot ab fp"><div class="ou ab ov cl cj ow"><h2 class="bd iv gz z fq ox fs ft oy fv fx it bi translated">隔离森林和火花</h2><div class="oz l"><h3 class="bd b gz z fq ox fs ft oy fv fx dk translated">PySpark 隔离带的主要特点和使用方法</h3></div><div class="pa l"><p class="bd b dl z fq ox fs ft oy fv fx dk translated">towardsdatascience.com</p></div></div><div class="pb l"><div class="pc l pd pe pf pb pg kt os"/></div></div></a></div><h1 id="fcf0" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">接下来去哪里？</h1><p id="df50" class="pw-post-body-paragraph kz la iu lb b lc mo jv le lf mp jy lh li mq lk ll lm mr lo lp lq ms ls lt lu in bi translated">理解模型的预测:</p><div class="op oq gq gs or os"><a href="https://medium.com/mlearning-ai/machine-learning-interpretability-shapley-values-with-pyspark-16ffd87227e3" rel="noopener follow" target="_blank"><div class="ot ab fp"><div class="ou ab ov cl cj ow"><h2 class="bd iv gz z fq ox fs ft oy fv fx it bi translated">机器学习的可解释性——带有 PySpark 的 Shapley 值</h2><div class="oz l"><h3 class="bd b gz z fq ox fs ft oy fv fx dk translated">解读隔离森林的预测——不仅仅是</h3></div><div class="pa l"><p class="bd b dl z fq ox fs ft oy fv fx dk translated">medium.com</p></div></div><div class="pb l"><div class="ph l pd pe pf pb pg kt os"/></div></div></a></div></div></div>    
</body>
</html>