<html>
<head>
<title>Naive Bayes Classifier: Bayesian Inference, Central Limit Theorem, Python/C++ Implementation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">朴素贝叶斯分类器:贝叶斯推理，中心极限定理，Python/C++实现</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/naive-bayes-classifier-bayes-inference-central-limit-theorem-python-c-implementation-bdffb3b35de?source=collection_archive---------18-----------------------#2020-04-12">https://towardsdatascience.com/naive-bayes-classifier-bayes-inference-central-limit-theorem-python-c-implementation-bdffb3b35de?source=collection_archive---------18-----------------------#2020-04-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3c91" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">理解朴素贝叶斯分类器的数学基础</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/00ef2e4c1a2d1f6bb5fec13f615d9853.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6dkvjWfaKOaKShbmr72kWA.png"/></div></div></figure><h1 id="7ecb" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">目录</h1><ul class=""><li id="cadd" class="lm ln it lo b lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated"><strong class="lo iu">简介</strong></li><li id="eb9e" class="lm ln it lo b lp me lr mf lt mg lv mh lx mi lz ma mb mc md bi translated"><strong class="lo iu"> 1。条件概率</strong></li><li id="c891" class="lm ln it lo b lp me lr mf lt mg lv mh lx mi lz ma mb mc md bi translated">定义</li><li id="c975" class="lm ln it lo b lp me lr mf lt mg lv mh lx mi lz ma mb mc md bi translated">直觉</li><li id="1a79" class="lm ln it lo b lp me lr mf lt mg lv mh lx mi lz ma mb mc md bi translated">快速示例</li><li id="5492" class="lm ln it lo b lp me lr mf lt mg lv mh lx mi lz ma mb mc md bi translated">链式法则</li></ul></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><ul class=""><li id="ed23" class="lm ln it lo b lp mq lr mr lt ms lv mt lx mu lz ma mb mc md bi translated"><strong class="lo iu"> 2。独立性</strong></li><li id="bf92" class="lm ln it lo b lp me lr mf lt mg lv mh lx mi lz ma mb mc md bi translated">定义</li><li id="b3da" class="lm ln it lo b lp me lr mf lt mg lv mh lx mi lz ma mb mc md bi translated">直觉</li><li id="10ad" class="lm ln it lo b lp me lr mf lt mg lv mh lx mi lz ma mb mc md bi translated">快速示例</li></ul></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><ul class=""><li id="e692" class="lm ln it lo b lp mq lr mr lt ms lv mt lx mu lz ma mb mc md bi translated"><strong class="lo iu"> 3。条件独立性</strong></li><li id="2721" class="lm ln it lo b lp me lr mf lt mg lv mh lx mi lz ma mb mc md bi translated">定义</li><li id="7b71" class="lm ln it lo b lp me lr mf lt mg lv mh lx mi lz ma mb mc md bi translated">证明</li><li id="4d5b" class="lm ln it lo b lp me lr mf lt mg lv mh lx mi lz ma mb mc md bi translated">快速示例</li></ul></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><ul class=""><li id="1c6e" class="lm ln it lo b lp mq lr mr lt ms lv mt lx mu lz ma mb mc md bi translated"><strong class="lo iu"> 4。贝叶斯定理和朴素贝叶斯分类器</strong></li><li id="0b70" class="lm ln it lo b lp me lr mf lt mg lv mh lx mi lz ma mb mc md bi translated">定义</li><li id="9ec1" class="lm ln it lo b lp me lr mf lt mg lv mh lx mi lz ma mb mc md bi translated">证明</li></ul></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><ul class=""><li id="6493" class="lm ln it lo b lp mq lr mr lt ms lv mt lx mu lz ma mb mc md bi translated"><strong class="lo iu"> 5。中心极限定理和正态分布</strong></li><li id="233b" class="lm ln it lo b lp me lr mf lt mg lv mh lx mi lz ma mb mc md bi translated"><strong class="lo iu"> 6。理论的实现</strong></li><li id="8060" class="lm ln it lo b lp me lr mf lt mg lv mh lx mi lz ma mb mc md bi translated"><strong class="lo iu"> 7。结论</strong></li><li id="837f" class="lm ln it lo b lp me lr mf lt mg lv mh lx mi lz ma mb mc md bi translated"><strong class="lo iu"> 8。资源和参考资料</strong></li></ul></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="e769" class="ku kv it bd kw kx mv kz la lb mw ld le jz mx ka lg kc my kd li kf mz kg lk ll bi translated">介绍</h1><p id="aa7e" class="pw-post-body-paragraph na nb it lo b lp lq ju nc lr ls jx nd lt ne nf ng lv nh ni nj lx nk nl nm lz im bi translated">在下面的文章中，将讨论贝叶斯理论的细节和相应的数学证明，然后使用编程语言Python和C++在朴素贝叶斯分类器的上下文中实现该理论。这篇文章主要针对那些渴望深入了解贝叶斯推理惊人世界的人。值得注意的是，在介绍贝叶斯定理的概念之前，我们将讨论一些里程碑，对于这些里程碑，最少的概率论知识是先决条件。一旦理解了算法的数学基础，实现就会一路走下坡路。</p><h1 id="d43d" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">1.条件概率</h1><p id="0c30" class="pw-post-body-paragraph na nb it lo b lp lq ju nc lr ls jx nd lt ne nf ng lv nh ni nj lx nk nl nm lz im bi translated">概率是数学的一个分支，它将<em class="nn">样本空间</em>的结果的概率度量进行公理化和形式化。<em class="nn">样本空间</em>是事件的集合，比如掷骰子得到5。</p><h2 id="81f2" class="no kv it bd kw np nq dn la nr ns dp le lt nt nu lg lv nv nw li lx nx ny lk nz bi translated">定义</h2><p id="b82b" class="pw-post-body-paragraph na nb it lo b lp lq ju nc lr ls jx nd lt ne nf ng lv nh ni nj lx nk nl nm lz im bi translated"><em class="nn">条件概率</em>是在另一事件<strong class="lo iu"> B </strong>已经发生的情况下，对事件<strong class="lo iu"> A </strong>的概率度量。简单地说，如果两个事件相互关联，拥有其中任何一个事件的信息都会影响另一个事件的概率度量。在下面的<em class="nn">等式1.1 </em>中，描述了给定事件B的事件A的条件概率度量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/d18bb66e39146e2036b55ee70de4d385.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8byXrLyx4uPf6tm3jMHfvQ.png"/></div></div></figure><h2 id="6c43" class="no kv it bd kw np nq dn la nr ns dp le lt nt nu lg lv nv nw li lx nx ny lk nz bi translated">直觉</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/ec43bc3f3ae4a6fd8d0bc1f1a582a5fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nvHh3o78ZpQty-jYn3k1Yg.png"/></div></div><p class="oc od gj gh gi oe of bd b be z dk translated"><strong class="bd og">图1 </strong></p></figure><p id="d78c" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated"><em class="nn">等式1.1 </em>可以描述为事件A和B的交集的面积除以子空间B的整个面积。</p><h2 id="bb7f" class="no kv it bd kw np nq dn la nr ns dp le lt nt nu lg lv nv nw li lx nx ny lk nz bi translated">快速示例</h2><p id="665f" class="pw-post-body-paragraph na nb it lo b lp lq ju nc lr ls jx nd lt ne nf ng lv nh ni nj lx nk nl nm lz im bi translated">成年人中男性和酗酒者的比例为2.25%。假设是男的，成为酒鬼的概率有多大？</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/aa9c47315c036334ac6cbae837f4ee2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qblSn7ALMXpUK6Lc3apDJg.png"/></div></div></figure><p id="9afd" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated">转述一下问题，随机选择的个体，作为男人和酒鬼的概率是2.25%。如果你已经知道一个人是男的，那么他酗酒的概率是多少？</p><p id="260e" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated">假设2性别平均分布，是男的概率暗示0.5。通过将所有给定的参数放入<em class="nn">等式1.1 </em>中，我们得到4.5%</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/7997264dbfa7f9d35f86bdd23c17b7ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*006HFO5QMzqZFBbSFMmFEw.png"/></div></div></figure><p id="bf77" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated">基本上，拥有关于个体性别的额外信息会将我们的概率确定性从2.25%提高到4.5%。</p><h2 id="fd90" class="no kv it bd kw np nq dn la nr ns dp le lt nt nu lg lv nv nw li lx nx ny lk nz bi translated">链式法则</h2><p id="e8e1" class="pw-post-body-paragraph na nb it lo b lp lq ju nc lr ls jx nd lt ne nf ng lv nh ni nj lx nk nl nm lz im bi translated">链规则是一种概率现象，它帮助我们使用条件概率的乘积来找到集合成员的联合分布。为了推导链式法则，可以使用<em class="nn">等式1.1 </em>。首先，让我们计算两个事件A和b的联合概率。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/1994c93e73fecb48902939e4d1d64249.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bw5j-SXg6g5_qN-PIez3rA.png"/></div></div></figure><p id="07ae" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated">利用同样的原理，我们也可以找到3个事件的联合概率——A，B，c。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/db325f94a14248aeb2e1a0c7ff2ce5e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6Y-P72ymNQTM4J4Q7PHzAg.png"/></div></div></figure><p id="0516" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated">通过比较<em class="nn">方程1.2 </em>和<em class="nn">方程1.3 </em>之间的模式，可以确定计算N个事件的联合概率的通用方程。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/054287043c72170800c0757523309526.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XQ2zw4ZBw3yFmQdIdMI4bg.png"/></div></div></figure><h1 id="8a4b" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">2.独立性ˌ自立性</h1><p id="5db4" class="pw-post-body-paragraph na nb it lo b lp lq ju nc lr ls jx nd lt ne nf ng lv nh ni nj lx nk nl nm lz im bi translated">如果一个事件的发生不影响另一个事件发生的概率，那么这两个事件就是独立的。[2]</p><h2 id="5a6d" class="no kv it bd kw np nq dn la nr ns dp le lt nt nu lg lv nv nw li lx nx ny lk nz bi translated">定义</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/32245874cc7943d90866ffa6965703c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JFiQHcTPSxVPiz4xAzTH-Q.png"/></div></div></figure><p id="f67f" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated">从<em class="nn">等式2.1 </em>可以清楚地看出，拥有关于事件B的信息不会影响事件A的概率度量- &gt; <strong class="lo iu"> P(A|B) = P(A) </strong>。</p><h2 id="6a95" class="no kv it bd kw np nq dn la nr ns dp le lt nt nu lg lv nv nw li lx nx ny lk nz bi translated">直觉</h2><p id="2bfd" class="pw-post-body-paragraph na nb it lo b lp lq ju nc lr ls jx nd lt ne nf ng lv nh ni nj lx nk nl nm lz im bi translated">如果事件A和B是独立的，那么拥有关于事件B的信息应该会像拥有来自论域U的任何信息一样影响事件A的概率度量(参见 <strong class="lo iu"> <em class="nn">图1 </em> </strong>)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/6c735c3c242a7a4f26d46906b2e8bca4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IrbP6YCBDM6xzLpHO6X2PQ.png"/></div></div></figure><h2 id="4bce" class="no kv it bd kw np nq dn la nr ns dp le lt nt nu lg lv nv nw li lx nx ny lk nz bi translated">快速示例</h2><p id="ccf3" class="pw-post-body-paragraph na nb it lo b lp lq ju nc lr ls jx nd lt ne nf ng lv nh ni nj lx nk nl nm lz im bi translated">如果掷骰子两次，得到两个5的概率是多少？</p><p id="a0b5" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated">事件A —第一次掷骰子获得5分<br/>事件B —第二次掷骰子获得5分</p><p id="c604" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated">因为骰子上有六个不同的数字，所以得到5的概率为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/72fb6eb11f47a575c0b95196226a92db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0gAybE0-Q5tEGPMKm_TMYg.png"/></div></div></figure><p id="5216" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated">很明显，第一次得到5(事件A)并不提供关于事件B的任何信息。因此，由于事件A和B是独立的，因此事件<em class="nn"> A和B </em>都得到5的概率为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/10aea50bd33389bb8dcdf7fc1057574b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q6_0nZ0VUQjhN6YSK5SAMg.png"/></div></div></figure><h1 id="0839" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">3.条件独立性</h1><h2 id="027e" class="no kv it bd kw np nq dn la nr ns dp le lt nt nu lg lv nv nw li lx nx ny lk nz bi translated">定义</h2><p id="d8b3" class="pw-post-body-paragraph na nb it lo b lp lq ju nc lr ls jx nd lt ne nf ng lv nh ni nj lx nk nl nm lz im bi translated">给定C，事件A和B是条件独立的当且仅当，给定C发生的知识，A是否发生的知识不提供关于B发生的可能性的信息，并且B是否发生的知识不提供关于A发生的可能性的信息。[3]</p><p id="e2cc" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated">基本上，R和B是人<strong class="lo iu"> A </strong>和<strong class="lo iu"> B </strong>及时回家吃晚饭的事件，Y是暴风雪袭击城市的事件。当然，RR和BB的概率将取决于YY是否发生。然而，就像假设如果这两个人没有任何关系，他们及时回家的概率是独立的一样，这似乎是合理的</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/7b6986e5e97c27c872716e95695fad28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lyCIc8SoqhcS740a0-8lxg.png"/></div></div></figure><h2 id="7365" class="no kv it bd kw np nq dn la nr ns dp le lt nt nu lg lv nv nw li lx nx ny lk nz bi translated">证明</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/47f080f33c7470ffcb5215a34317fd7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AjQIm-HJr06AtAb-iZK_lA.png"/></div></div></figure><p id="efdc" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated">等式3.1中的模式也可以应用于N个条件独立事件:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/832518529cd7f9f7cc4d35205dc096dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gngF9AxFNYRwKmfdXT3wsQ.png"/></div></div></figure><h1 id="d45c" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">4.贝叶斯定理和朴素贝叶斯分类器</h1><h2 id="0dd7" class="no kv it bd kw np nq dn la nr ns dp le lt nt nu lg lv nv nw li lx nx ny lk nz bi translated">定义</h2><p id="3bc5" class="pw-post-body-paragraph na nb it lo b lp lq ju nc lr ls jx nd lt ne nf ng lv nh ni nj lx nk nl nm lz im bi translated">贝叶斯定理是一个强大的工具，它使我们能够根据给定的<strong class="lo iu">先验</strong>知识和<strong class="lo iu">证据</strong>来计算<strong class="lo iu">后验</strong>概率。这与对数据进行训练并获得有用的知识以进行进一步预测的原理相同。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ow"><img src="../Images/bd4c10ac75db6646757608f22921a984.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HfG1PY5-VSILokC66mLtsA.png"/></div></div></figure><ul class=""><li id="d4e6" class="lm ln it lo b lp mq lr mr lt ms lv mt lx mu lz ma mb mc md bi translated">P(y|x) — <strong class="lo iu">后验</strong> —给定事件<strong class="lo iu"> x </strong>发生的情况下，事件<strong class="lo iu"> y </strong>发生的概率。</li><li id="e3cc" class="lm ln it lo b lp me lr mf lt mg lv mh lx mi lz ma mb mc md bi translated">P(x|y) — <strong class="lo iu">可能性</strong> —给定事件<strong class="lo iu"> y </strong>发生的情况下，事件<strong class="lo iu"> x </strong>发生的可能性。</li><li id="d8b2" class="lm ln it lo b lp me lr mf lt mg lv mh lx mi lz ma mb mc md bi translated">P(y) — <strong class="lo iu">先验</strong> —在获得某些知识/证据<strong class="lo iu"> x </strong>之前，关于未知事件发生的概率测度的信念<strong class="lo iu"> y </strong></li><li id="4e85" class="lm ln it lo b lp me lr mf lt mg lv mh lx mi lz ma mb mc md bi translated">P(x) — <strong class="lo iu">证据</strong> —作为计算后验概率的证据给出的一条信息</li></ul><h2 id="d368" class="no kv it bd kw np nq dn la nr ns dp le lt nt nu lg lv nv nw li lx nx ny lk nz bi translated">证明</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/6e22b3719fa0461257d08ceb94200fb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Am-scPr0vgTrM2yhU6En9A.png"/></div></div></figure><p id="fa6a" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated">对于机器学习分类和预测任务，通常给我们的是特征向量X = (x1，…，xn)和对应的类别标签y = (1，…，m)。特征行向量可以被假设为特征的联合概率。因此，等式4.1变为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/fcc40e9a3762a5e35332957e7fcb2fbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1ACzjCBBix6F8ABvYp9iUw.png"/></div></div></figure><p id="1dad" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated"><strong class="lo iu">现在向量X的特征将被假设为独立事件以简化模型复杂性。然后，4.2将通过挪用方程3.2而进一步简化。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/4d4f5ec3dbf2ffcdde8af4a64fe98fe9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zssWkM_blkQmM7MESfEVOw.png"/></div></div></figure><p id="0e76" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated"><em class="nn">的确，独立性假设是这种方法被称为“</em> <strong class="lo iu"> <em class="nn">【幼稚</em> </strong> <em class="nn">”的主要原因。</em>因为在现实世界的应用中，很有可能特征是相互关联或相互依赖的。尽管有“天真”的假设，模型复杂性的简化有时会产生令人惊讶的有用性能。</p><p id="34cd" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated"><em class="nn">等式4.3 </em>将帮助我们通过比较不同类别参数-y的后验概率的度量来预测给定特征向量<strong class="lo iu"> x </strong> (x1，…xn)的类别。然后，具有对应于该类别的最高值的后验将被选择为未知特征向量<strong class="lo iu"> x </strong>的类别。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/22bdca19a87456b4914572c3ea168637.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NEWdPFTuUFTHRAyTIIjc8Q.png"/></div></div></figure><p id="e741" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated">假设方程的分母在不同类别<strong class="lo iu"> y </strong>的比较过程中保持不变，可以只比较方程的分子部分，这将进一步简化过程。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/929fabbc2e62fe394dbe389df117a9ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pWbOgdp66SuI0YA5EFAYmA.png"/></div></div></figure><p id="b234" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated">上面的等式(4.5)足以预测给定特征向量的类别。然而，考虑到概率测度的取值范围在0到1之间，拥有几个概率测度的乘积会导致算术下溢的问题[5]。幸运的是，这个问题可以很容易地通过取等式4.5的对数(基数应该大于1)来解决。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/7cbe861f939d45a48228b56e395a01ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JN6DELnR1seIknIyIP5D5A.png"/></div></div></figure><p id="fd39" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated">在等式4.6中，需要2个参数来预测特征向量的类别标签<strong class="lo iu"> x </strong>。</p><ol class=""><li id="3715" class="lm ln it lo b lp mq lr mr lt ms lv mt lx mu lz pc mb mc md bi translated">P(y) — <strong class="lo iu">先验</strong> —在考虑证据(特征向量)之前，类别标签<strong class="lo iu"> y </strong>的概率分布是一个先验概率<strong class="lo iu"> </strong>，与其在训练集中的出现频率有关。基本上，对于示例性给定的标签集<strong class="lo iu"> &lt; 0，0，1，1，1 &gt; </strong>，类<strong class="lo iu">‘0’</strong>的先验是2/5。</li></ol><p id="2c8b" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated">2.P(x₁| y)… P(xₙ| y) —对于分类问题，虽然y —类标签的值是离散的，但特征向量<strong class="lo iu"> x </strong>的值通常是连续值，如<strong class="lo iu">表1 </strong>所示。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pd pe l"/></div><p class="oc od gj gh gi oe of bd b be z dk translated"><strong class="ak">表1 </strong></p></figure><p id="f54c" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated">因此，我们需要一种特殊的工具，这将有助于我们获得有关某些事件发生的可能性的信息。例如，如果类1.0的对应特征值是1.898，那么如果特征值是1.897，那么拥有1.0的可能性是多少？</p><h1 id="3963" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">5.中心极限定理和正态分布</h1><blockquote class="pf pg ph"><p id="d7de" class="na nb nn lo b lp mq ju nc lr mr jx nd pi oh nf ng pj oi ni nj pk oj nl nm lz im bi translated">中心极限定理指出，如果您有一个均值为μ、标准差为σ的总体，并从替换为的总体<strong class="lo iu">中抽取足够大的随机样本，那么样本均值的分布将近似为正态分布。[7]</strong></p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pl"><img src="../Images/d57c792b6176eda83ead5a5f735d0fb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8lNaqfRmBw2UZF9zT8Qp4g.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pm"><img src="../Images/3ac85f98c76bb2dc1f93c1afe9d7bdd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5n_gFCojLGfN3W6E"/></div></div><p class="oc od gj gh gi oe of bd b be z dk translated"><strong class="bd og">正态分布:资源与参考文献【6】</strong></p></figure><p id="2ae2" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated">简单地说，在概率论和自然界中，正态分布近似于随机量偏离“真实”(平均)值的模式。举个例子:</p><p id="500b" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated">下面的直方图描述了泰坦尼克号事故中幸存/死亡乘客的年龄分布。在这里也可以看到上述的正态分布模式。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pn"><img src="../Images/efbe17adc0df2ec9a30fc1a326c5cd9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HKnnv8IWZPaDnNC-rSwVhg.png"/></div></div><p class="oc od gj gh gi oe of bd b be z dk translated"><strong class="bd og">图2 </strong></p></figure><p id="04e3" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated"><em class="nn">通过考虑独立随机变量的一般分布模式，我们将假设对于每个类，特征列的值也是正态分布的。</em>因此，每个类别的列值的平均值将代表该类别的“真实”特征值。未知的特征向量与某一类别的平均特征值的接近程度将代表它们有多可能相同。为了表示这种相似性的度量，我们将使用高斯概率密度函数(高斯PDF)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi po"><img src="../Images/0b34041165e8c584cc758e96a486cc63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6JbI9N3ok59FQydZPdNeIg.png"/></div></div><p class="oc od gj gh gi oe of bd b be z dk translated"><strong class="bd og">图3 </strong></p></figure><p id="943e" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated">图3显示了两类特征的分布。每个类别都有自己的平均值和标准偏差值，并在图的图例上显示精确值。所以:</p><ul class=""><li id="1b8b" class="lm ln it lo b lp mq lr mr lt ms lv mt lx mu lz ma mb mc md bi translated">P( <strong class="lo iu"> x </strong> | μ <strong class="lo iu"> ⁰ </strong>，σ <strong class="lo iu"> ⁰ </strong> ) ≈ 0.125</li><li id="922e" class="lm ln it lo b lp me lr mf lt mg lv mh lx mi lz ma mb mc md bi translated">P( <strong class="lo iu"> x </strong> | μ <strong class="lo iu"> </strong>，σ <strong class="lo iu"> </strong> ) ≈ 0.025</li></ul><p id="740f" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated">因此，x成为类“0”的可能性大于类“1”。</p><h1 id="8ffb" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">6.理论的实施</h1><p id="a0dd" class="pw-post-body-paragraph na nb it lo b lp lq ju nc lr ls jx nd lt ne nf ng lv nh ni nj lx nk nl nm lz im bi translated">考虑到它的广泛使用，将在Python编程语言上解释它的实现。然而，相同的代码实现已经在C++中实现，并添加到参考资料和参考资料部分的项目代码链接中。[9]</p><p id="1981" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated">由于便于使用，算法将以类结构代码的形式编写。该类将接受两个参数:</p><ul class=""><li id="1a3d" class="lm ln it lo b lp mq lr mr lt ms lv mt lx mu lz ma mb mc md bi translated">x-训练特征集</li><li id="93c4" class="lm ln it lo b lp me lr mf lt mg lv mh lx mi lz ma mb mc md bi translated">y-标签集</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pd pe l"/></div></figure><p id="2b4f" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated">下一步是编写“fit”函数，在此过程中，特性列的平均值和标准值被存储到定义的列表中。这个过程也可以称为训练。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pd pe l"/></div></figure><p id="34b0" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated">一旦计算了类别的相应平均值和标准值，就可以预测未知特征向量的类别。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pd pe l"/></div></figure><p id="fd22" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated">为了测试算法的性能，我们可以使用“sk learn”python模块随机生成数据，然后将其拆分为训练和测试数据集。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pd pe l"/></div></figure><p id="4890" class="pw-post-body-paragraph na nb it lo b lp mq ju nc lr mr jx nd lt oh nf ng lv oi ni nj lx oj nl nm lz im bi translated">正如你所看到的，基于“天真”假设的算法非常有效，准确率超过90%。关于随机生成的数据集特征，准确度的值可以增加/减少。</p><h1 id="a43c" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">7.结论</h1><p id="e221" class="pw-post-body-paragraph na nb it lo b lp lq ju nc lr ls jx nd lt ne nf ng lv nh ni nj lx nk nl nm lz im bi translated">我希望这篇文章充分挖掘了朴素贝叶斯分类器的主题。如果你对这篇文章有任何意见/建议，你可以通过我的推特账号联系我。</p><h1 id="fadd" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">8.资源和参考资料</h1><p id="5600" class="pw-post-body-paragraph na nb it lo b lp lq ju nc lr ls jx nd lt ne nf ng lv nh ni nj lx nk nl nm lz im bi translated">[1] <a class="ae pp" href="https://www.wikiwand.com/en/Venn_diagram" rel="noopener ugc nofollow" target="_blank">维恩图—维基百科</a><br/>【2】<a class="ae pp" href="https://www.wikiwand.com/en/Independence_(probability_theory)" rel="noopener ugc nofollow" target="_blank">独立性—维基百科</a><br/>【3】<a class="ae pp" href="https://www.wikiwand.com/en/Conditional_independence" rel="noopener ugc nofollow" target="_blank">条件独立性—维基百科</a><br/>【4】<a class="ae pp" href="https://math.stackexchange.com/a/23100/516078" rel="noopener ugc nofollow" target="_blank">数学StackExchange问题答案—有人能解释一下条件独立性吗？</a><br/>【5】<a class="ae pp" href="https://www.wikiwand.com/en/Arithmetic_underflow" rel="noopener ugc nofollow" target="_blank">算术下溢—维基百科</a><br/>【6】<a class="ae pp" href="https://www.wikiwand.com/en/Normal_distribution" rel="noopener ugc nofollow" target="_blank">正态分布—维基百科</a><br/>【7】<a class="ae pp" href="http://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_Probability/BS704_Probability12.html" rel="noopener ugc nofollow" target="_blank">中心极限定理</a><br/>【8】<a class="ae pp" href="https://youtu.be/Ws63I3F7Moc" rel="noopener ugc nofollow" target="_blank">马尔可夫链的起源|信息论之旅|计算机科学|可汗学院</a><br/>【9】<a class="ae pp" href="https://bitbucket.org/tarlanahad/myneatcodes/src/master/Naive%20Bayes%20Classifier/" rel="noopener ugc nofollow" target="_blank">朴素贝叶斯分类器‘Python/c++’项目代码</a></p></div></div>    
</body>
</html>