<html>
<head>
<title>Bye-bye MobileNet. Hello EfficientNet!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">再见了移动网络。你好效率网！</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/bye-bye-mobilenet-hello-efficientnet-9b8ec2cc1a9c?source=collection_archive---------19-----------------------#2020-06-01">https://towardsdatascience.com/bye-bye-mobilenet-hello-efficientnet-9b8ec2cc1a9c?source=collection_archive---------19-----------------------#2020-06-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="2709" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">意见</h2><div class=""/><div class=""><h2 id="6dee" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">MobileNet 是应用和边缘部署的首选模型。现在它被 EfficientNet Lite 模型家族所取代。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/c6e9674771866c9332e3dcb9e92b8db1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-YFvSBEvkgUlsm4w"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">卢克·坦尼斯在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><p id="d331" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如何在处理能力和内存有限的移动和边缘设备上以良好的速度运行复杂的深度学习模型？创建一个以 MobileNetV2 为主干的模型，转换成 Tensorflow Lite，就大功告成了。现在它受到了 EfficientNet Lite 的挑战。请继续阅读，了解 EfficientNet 对 EfficientNet-Lite 的需求，以及如何创建 EfficientNet Lite 模型，我们还将比较这些模型，看看谁更胜一筹。如果你想深入了解 EfficientNet 的架构，你可以阅读下面的文章。</p><div class="me mf gp gr mg mh"><a rel="noopener follow" target="_blank" href="/complete-architectural-details-of-all-efficientnet-models-5fd5b736142"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd jd gy z fp mm fr fs mn fu fw jc bi translated">所有高效网络模型的完整架构细节</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">让我们深入了解所有不同高效网络模型的体系结构细节，并找出它们的不同之处…</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">towardsdatascience.com</p></div></div><div class="mq l"><div class="mr l ms mt mu mq mv lb mh"/></div></div></a></div><p id="f954" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在我开始之前，是的，我无耻地窃取了<a class="mw mx ep" href="https://medium.com/u/593908e0206?source=post_page-----9b8ec2cc1a9c--------------------------------" rel="noopener" target="_blank"> Rhea Moutafis </a>热门文章<a class="ae lh" rel="noopener" target="_blank" href="/bye-bye-python-hello-julia-9230bff0df62">拜拜 Python 的标题。你好朱莉娅。</a></p></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><h1 id="e89f" class="nf ng it bd nh ni nj nk nl nm nn no np ki nq kj nr kl ns km nt ko nu kp nv nw bi translated">Tensorflow Lite 中 EfficientNet 模型的缺点→需要 EfficientNet Lite</h1><p id="3f55" class="pw-post-body-paragraph li lj it lk b ll nx kd ln lo ny kg lq lr nz lt lu lv oa lx ly lz ob mb mc md im bi translated">最近，我写了一篇文章，将 EfficientNet 与其他预训练的模型进行了比较，如 MobileNetV2、Inception 和 Xception，我想将这些保存的模型转换为 Tensorflow Lite 的对应模型，以查看它们的推理时间如何相互比较。</p><div class="me mf gp gr mg mh"><a rel="noopener follow" target="_blank" href="/efficientnet-should-be-the-goto-pre-trained-model-or-38f719cbfe60"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd jd gy z fp mm fr fs mn fu fw jc bi translated">EfficientNet 应该是 goto 预训练模型或…</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">比较不同预训练模型的时间和准确性，并最终创建一个集成来提高结果。</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">towardsdatascience.com</p></div></div><div class="mq l"><div class="oc l ms mt mu mq mv lb mh"/></div></div></a></div><p id="9a26" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在比较模型尺寸之前一切都很好，但在那之后，我震惊了。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi od"><img src="../Images/fc4cff33000be2ad715bbbf6146e565c.png" data-original-src="https://miro.medium.com/v2/resize:fit:626/format:webp/1*f85aP4IXJJJf3dOxmOwjfw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">比较模型尺寸</p></figure><p id="29e6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了计算推断时间，我加载并处理了一张图片，对其进行了一百次预测，并取其平均值。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/8114d9b126e31784fbb95362accf493b.png" data-original-src="https://miro.medium.com/v2/resize:fit:898/format:webp/1*FqxvOXLE_okMDPhySZZWlw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">比较模型推理时间</p></figure><p id="279c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Tensorflow Lite 模型的 MobileNet 推理时间如预期的那样下降了，但 EfficientNet 模型的推理时间增加了！！！Tensorflow Lite 应该使模型更小并减少推理时间！那么为什么会出现这种情况，如何解决呢？这在 EfficientNet Lite 中已得到澄清，根据此<a class="ae lh" href="https://blog.tensorflow.org/2020/03/higher-accuracy-on-vision-models-with-efficientnet-lite.html" rel="noopener ugc nofollow" target="_blank">文章</a>，它有以下更改:</p><ul class=""><li id="82a0" class="of og it lk b ll lm lo lp lr oh lv oi lz oj md ok ol om on bi translated">删除挤压和激励网络，因为它们没有得到很好的支持</li><li id="231a" class="of og it lk b ll oo lo op lr oq lv or lz os md ok ol om on bi translated">用 RELU6 替换了所有的 swish 激活，这显著提高了训练后量化的质量</li><li id="1e1e" class="of og it lk b ll oo lo op lr oq lv or lz os md ok ol om on bi translated">在放大模型时修复了茎和头，以减少缩放模型的大小和计算</li></ul><h1 id="48f8" class="nf ng it bd nh ni ot nk nl nm ou no np ki ov kj nr kl ow km nt ko ox kp nv nw bi translated">Tensorflow Lite 中的 MobileNet 与 EfficientNet Lite</h1><p id="4799" class="pw-post-body-paragraph li lj it lk b ll nx kd ln lo ny kg lq lr nz lt lu lv oa lx ly lz ob mb mc md im bi translated">这些模型将由<em class="oy">模型制作者</em>创建，正如其<a class="ae lh" href="https://www.tensorflow.org/lite/tutorials/model_maker_image_classification" rel="noopener ugc nofollow" target="_blank">教程</a>中所述</p><blockquote class="oz pa pb"><p id="09d1" class="li lj oy lk b ll lm kd ln lo lp kg lq pc ls lt lu pd lw lx ly pe ma mb mc md im bi translated">在为设备上的 ML 应用部署 TensorFlow 神经网络模型时，模型生成器库简化了将该模型适配和转换为特定输入数据的过程。</p></blockquote><p id="d416" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">它确实可以做到这一点，并且支持 MobileNetV2、ResNet50 和 EfficientNet Lite 系列的前五种型号。您还可以使用<code class="fe pf pg ph pi b">ImageModelSpec</code>从 Tensorflow Hub 使用不同的模型，或者创建或拥有自定义模型并将<em class="oy"> ModelSpec </em>导出到 Tensorflow Hub，然后使用<code class="fe pf pg ph pi b">ImageModelSpec</code>。</p><p id="b25b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在本文中，我将只结合 MobileNetV2 和 EfficientNet Lite 0 到 4。使用的数据将是带有雏菊、蒲公英、玫瑰、向日葵和郁金香标签的花卉数据集，这些数据将被分成 80%、10%和 10%，分别用于训练、验证和测试。</p><p id="d06f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为此，我们需要 Tensorflow 示例，可以使用以下方式进行 pip 安装:</p><pre class="ks kt ku kv gt pj pi pk pl aw pm bi"><span id="7657" class="pn ng it pi b gy po pp l pq pr">!pip install -q git+https://github.com/tensorflow/examples.git#egg=tensorflow-examples[model_maker]</span></pre><p id="7935" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然后，我们进行所需的导入，即模型规格、图像分类器、图像分类器的数据加载器、TensorFlow、NumPy 和 Matplotlib。</p><pre class="ks kt ku kv gt pj pi pk pl aw pm bi"><span id="a985" class="pn ng it pi b gy po pp l pq pr">from tensorflow_examples.lite.model_maker.core.data_util.image_dataloader import ImageClassifierDataLoader<br/>from tensorflow_examples.lite.model_maker.core.task import image_classifier<br/>from tensorflow_examples.lite.model_maker.core.task.model_spec import (mobilenet_v2_spec,<br/>        efficientnet_lite0_spec,<br/>        efficientnet_lite1_spec,<br/>        efficientnet_lite2_spec,<br/>        efficientnet_lite3_spec,<br/>        efficientnet_lite4_spec)<br/>import tensorflow as tf<br/>import numpy as np<br/>import matplotlib.pyplot as plt</span></pre><p id="982b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然后我们加载数据，将它分成所需的类别，并使用<code class="fe pf pg ph pi b">ImageClassifierDataLoader</code>类为图像分类器做好准备。可以使用<code class="fe pf pg ph pi b">from_folder</code>方法，它假设不同类别的图像存在于主文件夹的不同子文件夹中，子文件夹的名称是类别名称。确保图像具有 PNG 或 JPG 扩展名，因为只有它们受支持。</p><pre class="ks kt ku kv gt pj pi pk pl aw pm bi"><span id="2b8c" class="pn ng it pi b gy po pp l pq pr">image_path = tf.keras.utils.get_file('flower_photos',<br/>'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz', untar=True)</span><span id="097b" class="pn ng it pi b gy ps pp l pq pr">data = ImageClassifierDataLoader.from_folder(image_path)<br/>train_data, rest_data = data.split(0.8)<br/>validation_data, test_data = rest_data.split(0.5)</span></pre><p id="78a2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们看看我们的数据</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pt"><img src="../Images/7f841c2b3deeb033a5b26f81f09c744d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1150/format:webp/1*6oGAN2uC40n0RBMW-WY1sw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">资料组</p></figure><p id="f839" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在用 model-maker 创建模型是一行程序。</p><pre class="ks kt ku kv gt pj pi pk pl aw pm bi"><span id="6a79" class="pn ng it pi b gy po pp l pq pr">model = image_classifier.create(train_data, model_spec=model_spec, epochs=epochs, validation_data=validation_data)</span></pre><p id="9a9a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">指定您想要的型号规格，对于 MobileNetV2 是<code class="fe pf pg ph pi b">mobilenet_v2_spec</code>，对于 EfficientNet Lite-2 是<code class="fe pf pg ph pi b">efficientnet_lite2_spec</code>，如导入中所述。如果没有指定，EfficientNet Lite-0 是默认的。我每个人都训练了 15 个时期，下面是结果。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pu"><img src="../Images/c13c949f869d21e774762877e6e554cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g-UB7OaiAFn0kJ0Sej4ndg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">所有模型的训练和验证准确性和损失</p></figure><p id="815c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">令人惊讶的是，EfficientNet Lite-4 在测试和训练集上的表现都很差，但这可能只是意味着它需要更多的训练时期。验证集上表现最差的是 MobileNet，其他 EfficientNet 模型彼此接近，EfficientNet Lite-2 和 EfficientNet Lite-3 以最高的准确度分享战利品。</p><p id="6231" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">要转换这些模型并将其保存为 Tensorflow Lite 文件，请编写</p><pre class="ks kt ku kv gt pj pi pk pl aw pm bi"><span id="5973" class="pn ng it pi b gy po pp l pq pr">model.export(export_dir='.')</span></pre><p id="c1d5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这将保存一个 label.txt 和一个 model.tflite 文件。通过创建一个解释器，可以像普通的 tflite 模型一样使用这些模型。</p><pre class="ks kt ku kv gt pj pi pk pl aw pm bi"><span id="d28c" class="pn ng it pi b gy po pp l pq pr"># Read TensorFlow Lite model from TensorFlow Lite file.<br/>with tf.io.gfile.GFile('model.tflite', 'rb') as f:<br/>  model_content = f.read()<br/><br/># Read label names from label file.<br/>with tf.io.gfile.GFile('labels.txt', 'r') as f:<br/>  label_names = f.read().split('\n')<br/><br/># Initialze TensorFlow Lite inpterpreter.<br/>interpreter = tf.lite.Interpreter(model_content=model_content)<br/>interpreter.allocate_tensors()<br/>input_index = interpreter.get_input_details()[0]['index']<br/>output = interpreter.tensor(interpreter.get_output_details()[0]["index"])<br/><br/># Run predictions on each test image data and calculate accuracy.<br/>accurate_count = 0<br/>for i, (image, label) in enumerate(test_data.dataset):<br/>    # Pre-processing should remain the same. Currently, just normalize each pixel value and resize image according to the model's specification.<br/>    image, _ = model.preprocess(image, label)<br/>    # Add batch dimension and convert to float32 to match with the model's input<br/>    # data format.<br/>    image = tf.expand_dims(image, 0).numpy()<br/><br/>    # Run inference.<br/>    interpreter.set_tensor(input_index, image)<br/>    interpreter.invoke()<br/><br/>    # Post-processing: remove batch dimension and find the label with highest<br/>    # probability.<br/>    predict_label = np.argmax(output()[0])<br/>    # Get label name with label index.<br/>    predict_label_name = label_names[predict_label]<br/><br/>    accurate_count += (predict_label == label.numpy())<br/><br/>accuracy = accurate_count * 1.0 / test_data.size<br/>print('TensorFlow Lite model accuracy = %.3f' % accuracy)</span></pre><p id="9605" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">模型的大小，测试的准确性，以及推断时间(也是 100 次的平均值)都被记录了下来。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pv"><img src="../Images/eba2ffa7827ca635302ffae18eacd79f.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/format:webp/1*Z1DGANiNOuToCdvO--vhkg.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">结果</p></figure></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><p id="127d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">所以结果很明显。如果模型大小和推理时间比准确性更重要，那么只使用 MobileNetV2，否则 EfficientNet Lite 系列应该是您的首选模型，尤其是 EfficientNet Lite-0 可以作为 MobileNetV2 的直接替代品。</p></div></div>    
</body>
</html>