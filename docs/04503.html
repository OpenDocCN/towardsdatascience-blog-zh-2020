<html>
<head>
<title>Switching among OpenCV, Tensorflow and Pillow? Wait!!!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">OpenCV，Tensorflow，Pillow之间的切换？等等！！！</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-read-and-resize-with-opencv-tensorflow-and-pil-3e0f29b992be?source=collection_archive---------8-----------------------#2020-04-22">https://towardsdatascience.com/image-read-and-resize-with-opencv-tensorflow-and-pil-3e0f29b992be?source=collection_archive---------8-----------------------#2020-04-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e326" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">深入探讨OpenCV、Tensorflow和Pillow在JPEG图像读取和大小调整方面的差异，以及如何使它们保持一致。</h2></div><p id="2948" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现代计算机视觉(CV)目前是一个热门的研究领域，主要涉及图像处理。为此，需要使用一个框架来打开这些图像，对它们进行一些处理。</p><p id="c63e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在框架快速发展的今天，每个框架都有自己处理图像的方式，每个框架都有自己的规范。因此，在一个框架中开发的CV解决方案在另一个框架中可能不会像预期的那样工作。博客“Tensorflow的tf.image.resize如何偷走了我生命中的60天”(<a class="ae lb" href="https://hackernoon.com/how-tensorflows-tf-image-resize-stole-60-days-of-my-life-aba5eb093f35" rel="noopener ugc nofollow" target="_blank">https://hacker noon . com/How-tensor flow-TF-image-resize-skeet-60-days-of-my-life-ABA 5 EB 093 f 35</a>)就是这类情况的绝佳例子。找出问题所在可能需要几天的时间，而且可能会大大延迟项目。</p><p id="eaac" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本博客将详细讨论一个这样的用例，其中OpenCV和Tensorflow展示了读取JPEG图像和调整其大小的差异。它还将展示一种让它们持续工作的方法。此外，感谢<a class="lc ld ep" href="https://medium.com/u/59b036ba6f25?source=post_page-----3e0f29b992be--------------------------------" rel="noopener" target="_blank"> Tejas Pandey </a>帮助实现OpenCV和Tensorflow之间的一致性。</p><h2 id="d80d" class="le lf iq bd lg lh li dn lj lk ll dp lm ko ln lo lp ks lq lr ls kw lt lu lv lw bi translated">请注意，我是英特尔的员工，博客中的所有信息和观点都是我个人的，并不代表我的雇主。</h2><p id="f143" class="pw-post-body-paragraph kf kg iq kh b ki lx jr kk kl ly ju kn ko lz kq kr ks ma ku kv kw mb ky kz la ij bi translated">我们先用两个框架Tensorflow 1.x和OpenCV打开一个简单的狗的JPEG图像。</p><p id="f290" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们开始吧。我们将用python导入一些基本的库。</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="25a9" class="le lf iq mh b gy ml mm l mn mo">%tensorflow_version 1.x<br/>import cv2<br/>import matplotlib.pyplot as plt<br/>import numpy as np<br/>from skimage import io<br/>import tensorflow as tf</span></pre><p id="350e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们使用OpenCV打开一个图像。</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="e785" class="le lf iq mh b gy ml mm l mn mo">image_path = 'dog2.JPG'</span><span id="ace7" class="le lf iq mh b gy mp mm l mn mo">def plt_display(image, title):<br/>  fig = plt.figure()<br/>  a = fig.add_subplot(1, 1, 1)<br/>  imgplot = plt.imshow(image)<br/>  a.set_title(title)</span><span id="afd1" class="le lf iq mh b gy mp mm l mn mo">image = cv2.imread(image_path)<br/>plt_display(image, 'cv2-BGR')</span></pre><figure class="mc md me mf gt mr gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/ad482c6fa239b2e08effc5bba932225c.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/format:webp/1*GRMR9CCHR5MV1dgpW7XNvA.png"/></div></figure><p id="e964" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上图有些奇怪。它看起来不像原来的。嗯，是的，确实如此。在深入研究这个之前，首先让我们了解图像中的颜色是如何表现的。通常，图像有三个颜色通道红色、绿色和蓝色(RGB ),这产生了像素中的颜色。这些通道的顺序会改变像素的颜色，因为像素总是将第一个通道解释为红色，第二个通道解释为绿色，第三个通道解释为蓝色。</p><p id="94de" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们已经了解了颜色通道在图像中是如何工作的，让我们看看为什么我们在上面看到了不同的颜色图像。当我们使用OpenCV打开图像时，默认情况下OpenCV会以蓝色、绿色和红色通道(BGR)打开图像。这很好，但当我们显示图像时，像素误解了通道(即像素混淆，将蓝色解释为红色，反之亦然)。这就是为什么我们在图像中得到上述错误的颜色。</p><p id="4263" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">那么如何解决这个问题呢？打开图像后，我们将图像从BGR转换为RGB。我们通过使用OpenCV标志COLOR_BGR2RGB来实现这一点。下面的代码展示了如何用OpenCV正确地打开一个图像。</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="0884" class="le lf iq mh b gy ml mm l mn mo">image_cv = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)<br/>print(image_cv.dtype)<br/>print(np.max(image_cv))<br/>plt_display(image_cv, 'cv2-RGB')</span></pre><figure class="mc md me mf gt mr gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/fdcdbccc27be761b3e3a9f5eb2558e99.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*Wah_X1YEp9yq6u-xrbCT6Q.png"/></div></figure><p id="48a3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们现在用Tensorflow打开一个图像，看看是否得到相同的结果。在Tensorflow中打开JPEG图像需要两步。第一步是打开图像，第二步是执行JPEG解码，因为JPEG是压缩图像。</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="98e4" class="le lf iq mh b gy ml mm l mn mo">print("Tensorflow version: ", tf.__version__)<br/>image_tf = tf.io.read_file(image_path)</span><span id="a556" class="le lf iq mh b gy mp mm l mn mo">image_tf = tf.image.decode_jpeg(image_tf, channels=3)</span><span id="d415" class="le lf iq mh b gy mp mm l mn mo">with tf.Session() as sess:<br/>    image_tf = image_tf.eval()</span><span id="8a46" class="le lf iq mh b gy mp mm l mn mo">print(image_tf.dtype)<br/>plt_display(image_tf, 'TF')</span></pre><figure class="mc md me mf gt mr gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/d4808c5d4f05ca95330bc9acd1c89193.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*lxkqmo9BjUaorKNf1c8dqg.png"/></div></figure><p id="181a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">目测，从OpenCV和Tensorflow读取的图像看起来是一样的。但是他们是吗？要看有什么区别，让我们把两者相减。如果两者相同，我们应该看到一个完全黑色的图像。如果不是，那么我们会看到一些不同颜色的像素。</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="a6d0" class="le lf iq mh b gy ml mm l mn mo">image_diff = np.abs(image_cv- image_tf)<br/>plt_display(image_diff, 'OpenCV-TF')</span></pre><figure class="mc md me mf gt mr gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/f3185e5cf1be60e25ece0e9b515d59ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:590/format:webp/1*mFk2nqTg7ijmZjw9OQ5qPw.png"/></div></figure><p id="5c29" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">哇哦。这是一个巨大的差异。哪里出了问题？这种差异是由于OpenCV默认使用JPEG图像的整数精确解压缩。相比之下，TensorFlow默认使用离散余弦变换。这种类型的解码是不准确的，所以为了使它和OpenCV一样，我们需要使用整数精确解压缩来解码它。这可以通过设置参数dct_method='INTEGER_ACCURATE '来实现，如下所示。</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="fc4f" class="le lf iq mh b gy ml mm l mn mo">image_tf = tf.io.read_file(image_path)</span><span id="7308" class="le lf iq mh b gy mp mm l mn mo">image_tf = tf.image.decode_jpeg(image_tf, channels=3, dct_method='INTEGER_ACCURATE')</span><span id="c65c" class="le lf iq mh b gy mp mm l mn mo">with tf.Session() as sess:<br/>    image_tf = image_tf.eval()</span><span id="6c05" class="le lf iq mh b gy mp mm l mn mo">plt_display(image_tf,'TF_INT_ACC')</span></pre><figure class="mc md me mf gt mr gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/9a33f2489f66af974031f8f16136ef46.png" data-original-src="https://miro.medium.com/v2/resize:fit:568/format:webp/1*7JtnrSqJ55YO84xONFfA-w.png"/></div></figure><p id="065b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在减去OpenCV图像，我们得到一个黑色的图像。这意味着我们的TF和OpenCV现在在读取图像时是一致的。这是一个重要的步骤，因为你阅读图像的方式的一个小的改变将会在随后的图像处理中产生显著的差异。</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="96ad" class="le lf iq mh b gy ml mm l mn mo">image_diff = np.abs(image_cv- image_tf)<br/>plt_display(image_diff, 'OpenCV-TF')</span></pre><figure class="mc md me mf gt mr gh gi paragraph-image"><div class="gh gi my"><img src="../Images/1ea5b19bb08ad079350774e2e51097f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/1*E6Fgg23wa0L9z87qX57HUw.png"/></div></figure><p id="89a7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，既然我们已经用OpenCV和TensorFlow一致地读取了图像，让我们用这些框架来尝试调整图像的大小。我们将首先从OpenCV resize开始。</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="8aa0" class="le lf iq mh b gy ml mm l mn mo"># resizing the image with OpenCV<br/>print("image shape before resize:", image_cv.shape)<br/>image_cv_resized = cv2.resize(image_cv,(300,300))<br/>print("image shape after resize:", image_cv_resized.shape)<br/>print("image dtype: ", image_cv_resized.dtype)</span></pre><figure class="mc md me mf gt mr gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/ab7e8100e73e05c07c34b30b295681ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1084/format:webp/1*nG3cufoz1nKY7nZm6xT13w.png"/></div></figure><p id="f717" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们已经完成了OpenCV的大小调整。现在让我们调整张量流的大小。张量流与张量一起工作。它的调整大小方法需要一个4D张量并返回一个4D张量输出。因此，我们必须首先将图像从三个扩展到四个。然后调整图像大小，将尺寸压缩回3。由于我们的图像仍然是一个张量，我们将创建并运行一个Tensorflow会话，以NumPy格式获取调整后的图像。一旦我们有了NumPy映像，我们就将其转换为uint8类型，因为默认情况下，session会将NumPy转换为float32类型。这使得类型与OpenCV不一致。如下图所示-</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="9f3d" class="le lf iq mh b gy ml mm l mn mo"># resizing the image with tensorflow 1.x<br/>print("image shape before resize:", image_tf.shape)<br/>print("image dtype: ", image_tf.dtype)</span><span id="ace4" class="le lf iq mh b gy mp mm l mn mo">#This function takes in a 4D input. Hence we will have to expand the image and then squeeze back to three dimensions before we can use it as an image.<br/>image_tf_4D= tf.expand_dims(image_tf,0)</span><span id="cc6b" class="le lf iq mh b gy mp mm l mn mo"># doing bilinear resize<br/>image_tf_resized_4D = tf.image.resize_bilinear(<br/>    image_tf_4D,<br/>    (300,300)<br/>)</span><span id="5011" class="le lf iq mh b gy mp mm l mn mo">#squeezing back the image to 3D<br/>image_tf_resized = tf.squeeze(image_tf_resized_4D)</span><span id="ff61" class="le lf iq mh b gy mp mm l mn mo">#Above is still a tensor. So we need to convert it to numpy. We do this by using tf session.<br/>with tf.Session() as sess:<br/>  image_tf_resized = image_tf_resized.eval()</span><span id="a41f" class="le lf iq mh b gy mp mm l mn mo">print("image shape after resize:", image_tf_resized.shape)<br/>print("image dtype: ", image_tf_resized.dtype)</span><span id="f726" class="le lf iq mh b gy mp mm l mn mo">#Since it is in float32 format, we need to convert it back to uint8.<br/>image_tf_resized = image_tf_resized.astype(np.uint8)<br/>print("image dtype after conversion uint8: ", image_tf_resized.dtype)</span></pre><figure class="mc md me mf gt mr gh gi paragraph-image"><div class="gh gi na"><img src="../Images/2ae2ac7cda098fda6f4365226f332ba5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/1*tK_BSQAZR0WkK1FODd1enw.png"/></div></figure><p id="937e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在让我们来看看OpenCV和TF的调整大小的图像之间的区别。</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="4d5b" class="le lf iq mh b gy ml mm l mn mo">image_resized_diff = np.abs(image_cv_resized- image_tf_resized)<br/>plt_display(image_resized_diff, 'Resized OpenCV2 - Resized TF')</span></pre><figure class="mc md me mf gt mr gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/7902e9cf8213d9f224f758d0ecb9c1ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*wvAd5QvCt92BNTdGFELKkQ.png"/></div></figure><p id="c3de" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们再次看到两个框架在调整大小方法上的巨大差异。即使我们在两个框架中一致地打开图像，resize方法给出了不同的结果。默认情况下，OpenCV resize方法使用双线性变换。我们对Tensorflow使用了相同的双线性方法。尽管如此，我们最终得到了不同的结果。</p><p id="fe23" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">发生这种情况是因为OpenCV在调整大小时向图像添加了半像素校正。而Tensorflow默认不会。这增加了调整大小方法输出的差异。</p><p id="9142" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了解决这个问题，TensorFlow双线性调整大小中有一个参数可以进行半像素校正。如下图所示-</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="41bc" class="le lf iq mh b gy ml mm l mn mo">image_tf_4D= tf.expand_dims(image_tf,0)</span><span id="b076" class="le lf iq mh b gy mp mm l mn mo"># doing bilinear resize with half pixel correction<br/>image_tf_resized_hpc_4D = tf.image.resize_bilinear(<br/>    image_tf_4D,<br/>    (300,300),<br/>    half_pixel_centers=True<br/>)</span><span id="f86c" class="le lf iq mh b gy mp mm l mn mo">image_tf_resized_hpc = tf.squeeze(image_tf_resized_hpc_4D)</span><span id="fa72" class="le lf iq mh b gy mp mm l mn mo">with tf.Session() as sess:<br/>  image_tf_resized_hpc = image_tf_resized_hpc.eval()</span><span id="9e15" class="le lf iq mh b gy mp mm l mn mo">image_tf_resized_hpc = image_tf_resized_hpc.astype(np.uint8)<br/>image_resized_diff = np.abs(image_cv_resized- image_tf_resized_hpc)<br/>plt_display(image_resized_diff, 'Resized OpenCV2 - Resized TF')</span></pre><figure class="mc md me mf gt mr gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/d65fb93f344fc5c0ecce71e29ecd9ad3.png" data-original-src="https://miro.medium.com/v2/resize:fit:748/format:webp/1*VX5qH_l9oXF4-V_7t2yhcg.png"/></div></figure><p id="2e97" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们有了预期的结果。最后，我们让Tensorflow和OpenCV在读取和调整图像大小方面保持一致。</p><p id="2061" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一个计算机视觉领域的新人尝试这些功能将更有可能犯这些错误，并会有一个糟糕的开始。网上的教程不详细讨论这个。我创建这个博客是为了向人们展示，从一个框架到另一个框架，像我讨论的这样的小细节需要检查并保持一致。否则，它们将在不同的框架中产生不同的结果，并对它们的工作产生不利影响。</p><p id="1a21" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">另一个广泛使用的框架是Pillow (PIL)。让我们看看PIL和OpenCV的区别。我们将首先使用PIL读取图像。</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="f437" class="le lf iq mh b gy ml mm l mn mo">from PIL import Image</span><span id="3830" class="le lf iq mh b gy mp mm l mn mo">orig_image_pil = Image.open(image_path)<br/>image_pil = np.asarray(orig_image_pil)<br/>print(image_pil.dtype)<br/>plt_display(image_pil, 'PIL')</span></pre><figure class="mc md me mf gt mr gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/96341e08ff172ae0d41fa351259f8aff.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*9JKi1TuVId0RdrayphaRNQ.png"/></div></figure><p id="c092" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们来看看PIL打开的JPEG图像和OpenCV有什么不同。</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="0e2d" class="le lf iq mh b gy ml mm l mn mo">image_cv_pil_diff = np.abs(image_cv - image_pil)<br/>plt_display(image_cv_pil_diff, 'CV-PIL-DIFF')</span></pre><figure class="mc md me mf gt mr gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/88e9e77f2231771fcc9048e93422c14f.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/format:webp/1*rJ-biQ_5qTYqCW2OKsS9Yw.png"/></div></figure><p id="2735" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我们从TF和OpenCV中获得的经验所预期的那样，这两个框架再次以不同的方式打开图像。默认情况下，PIL不提供任何使用整数精确解压缩的方法。然而，人们可以自己编写解码器来解码图像。但是在这个博客中，我只是展示了不同之处，如果可能的话，如果图书馆提供支持的话，让它们保持一致。</p><p id="4799" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于这些框架对图像的读取方式不同，所以当我们调整大小时，这种差异将会扩大。如下图所示-</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="1840" class="le lf iq mh b gy ml mm l mn mo">image_pil_resized = orig_image_pil.resize((300,300),       resample=Image.BILINEAR)<br/>image_pil_resized = np.asarray(image_pil_resized)</span><span id="d371" class="le lf iq mh b gy mp mm l mn mo">#making sure we have the same dtype as OpenCV image.<br/>print(image_pil_resized.dtype)</span></pre><figure class="mc md me mf gt mr gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/dd9237d3e42d9fac1ef4499cee161b6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:160/format:webp/1*ecA7FYj8gW5zM3wQlbFycw.png"/></div></figure><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="5d09" class="le lf iq mh b gy ml mm l mn mo">image_cv_pil_resize_diff = np.abs(image_cv_resized - image_pil_resized)<br/>plt_display(image_cv_pil_resize_diff, 'Resized CV- Resized PIL')</span></pre><figure class="mc md me mf gt mr gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/94f8fc41710514c0f4cbfb42683e278f.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*3_VfcjzL76e1CJk0szeaIQ.png"/></div></figure><p id="a06c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，我们得到了调整大小的预期差异。PIL库不提供任何对半像素校正的支持，因此默认情况下不支持半像素校正。因为我们知道TF和OpenCV是一致的，所以当考虑到PIL和TF之间的差异时，我们可以期待相同的结果。</p><p id="71e3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，当使用PIL框架时，必须记住，如果工作依赖于上述图像的预处理，则不能直接切换到另一个框架。这将导致意想不到的结果。</p><p id="fa51" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我希望这篇博客对你有用，能够让你意识到框架依赖处理。</p></div></div>    
</body>
</html>