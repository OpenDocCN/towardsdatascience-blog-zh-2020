<html>
<head>
<title>Shortest Path Distance Approximation Using Deep Learning: Node2Vec</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习的最短路径距离近似:Node2Vec</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/shortest-path-distance-with-deep-learning-311e19d97569?source=collection_archive---------20-----------------------#2020-06-24">https://towardsdatascience.com/shortest-path-distance-with-deep-learning-311e19d97569?source=collection_archive---------20-----------------------#2020-06-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6952" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">实施研究论文“使用深度学习技术的最短路径距离近似”</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/61f5a482aa35fe2952f921cacc18822a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JTF9P0P5FnBeCKwPNAK3zA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">此处使用的图形数据集的子图</p></figure><p id="533d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">本文是一篇名为“<a class="ae lr" href="https://arxiv.org/abs/2002.05257" rel="noopener ugc nofollow" target="_blank">使用深度学习技术的最短路径距离近似法</a>”的研究论文的实现，作者在文中解释了一种新的方法来近似一个图的节点之间的最短路径距离。我将解释这篇论文和我的实现。你可以在我的GitHub账户<a class="ae lr" href="https://github.com/nayash/shortest-distance-approx-deep-learning" rel="noopener ugc nofollow" target="_blank">这里</a>找到这个项目。首先，我将概述本文中提出的方法，然后我们将讨论本文中用来解决问题的一些概念，最后是实现。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h2 id="e178" class="lz ma iq bd mb mc md dn me mf mg dp mh le mi mj mk li ml mm mn lm mo mp mq mr bi translated">1.报纸上说什么了？</h2><p id="d034" class="pw-post-body-paragraph kv kw iq kx b ky ms jr la lb mt ju ld le mu lg lh li mv lk ll lm mw lo lp lq ij bi translated"><strong class="kx ir"> 1.1动机:</strong>当我们有传统的精确方法如Dijkstra's和A*算法时，为什么我们需要使用深度学习来<em class="mx">近似节点间的</em>距离？这些传统算法的问题是，它们在非常大的图上运行缓慢，并且会消耗大量内存来存储预先计算的距离。因为对于大多数应用来说，实际距离的近似值已经足够好了，所以它鼓励人们探索各种方法来近似距离。还有，神经网络一旦训练完毕，推理时间(寻找节点距离)是常数(<em class="mx"> O(1) </em>)。</p><p id="e648" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> 1.2算法:</strong>既然知道了'<em class="mx">为什么'</em>，那就来看看'<em class="mx">如何'。</em>本文使用了另一篇优秀论文<a class="ae lr" href="https://arxiv.org/abs/1607.00653" rel="noopener ugc nofollow" target="_blank"> node2vec:网络的可扩展特征学习</a>中提出的思想。事实上，我要说的是，本文中使用的一些思想在Node2Vec论文中已经提出了(例如，在Node2Vec论文中提出了使用二元操作符来表示使用相应节点嵌入的边，在本文中扩展为表示路径。我们将在后面讨论嵌入)。本文更多的是Node2Vec的一个应用。Node2Vec本身就是<a class="ae lr" href="https://en.wikipedia.org/wiki/Word2vec" rel="noopener ugc nofollow" target="_blank"> Word2Vec </a>的扩展。Word2Vec是一种用向量空间中的嵌入(数字向量)来表示单词的算法，使得语义相似的单词彼此更靠近。这本身就是一个迷人的话题。</p><p id="0498" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">以下是建议方法的总结:</p><ol class=""><li id="464c" class="my mz iq kx b ky kz lb lc le na li nb lm nc lq nd ne nf ng bi translated">收集您的图表数据。</li><li id="25ea" class="my mz iq kx b ky nh lb ni le nj li nk lm nl lq nd ne nf ng bi translated">使用Node2Vec算法为每个节点寻找节点嵌入。我们不需要从头开始写这个算法。作者提供了一个<a class="ae lr" href="https://github.com/aditya-grover/node2vec" rel="noopener ugc nofollow" target="_blank">实现</a>。</li><li id="ecfe" class="my mz iq kx b ky nh lb ni le nj li nk lm nl lq nd ne nf ng bi translated">使用图中一定数量的节点作为他们所谓的“地标”，并计算它们与所有其他节点的距离。现在你有了形式的样本((landmark_i，node_x)，distance)。</li><li id="bea0" class="my mz iq kx b ky nh lb ni le nj li nk lm nl lq nd ne nf ng bi translated">对于上面找到的每个样本，获取界标和节点的相应节点嵌入，并且将它们与任何合适的二元运算符(平均、逐元素乘法等)组合。).所以现在你应该有形式的样本(嵌入，距离)。</li><li id="f5ae" class="my mz iq kx b ky nh lb ni le nj li nk lm nl lq nd ne nf ng bi translated">现在你有了输入输出对，所以你做你最擅长的。找一个好的神经网络配置，训练出模型的地狱。但我们稍后会看到，就像一般的人工智能一样，这并不容易。</li></ol><h2 id="3993" class="lz ma iq bd mb mc md dn me mf mg dp mh le mi mj mk li ml mm mn lm mo mp mq mr bi translated">2.履行</h2><p id="dfc0" class="pw-post-body-paragraph kv kw iq kx b ky ms jr la lb mt ju ld le mu lg lh li mv lk ll lm mw lo lp lq ij bi translated">该项目包含以下文件夹:</p><p id="cdb0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">数据—包含程序使用的所有数据，包括下载的和处理的数据。</p><p id="7c6c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">输出—保存所有输出，包括文本日志、tensorboard日志、模型备份等。</p><p id="a80f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">src —源代码放在这里。</p><p id="7662" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">测试——任何相关的测试用例</p><p id="489f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">注意:</strong>请注意，对于这个项目，我主要是在笔记本上工作，因为它涉及到许多探索和各种方法的实验。因此，工作并不完美，因为我还在探索更好的方法。我已经尽我所能解释了这些细胞。如果有不清楚的地方，请随时联系我。</p><p id="55e6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> 2.1数据</strong></p><p id="32e5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我在这里使用了<a class="ae lr" href="http://networkrepository.com" rel="noopener ugc nofollow" target="_blank">的脸书数据集</a>。下载的图形数据为“<a class="ae lr" href="http://networkrepository.com/mtx-matrix-market-format.html" rel="noopener ugc nofollow" target="_blank"> mtx </a>格式。这只是共享矩阵数据的另一种格式。看起来是这样的:</p><pre class="kg kh ki kj gt nm nn no np aw nq bi"><span id="bd2a" class="lz ma iq nn b gy nr ns l nt nu">%%MatrixMarket matrix coordinate pattern symmetric<br/>6386 6386 217662<br/>195 1<br/>414 1<br/>458 1<br/>474 1<br/>510 1<br/>.<br/>.<br/>.</span></pre><p id="eca8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">第一行称为“header”并定义了一些属性，这些属性用于决定如何解析文件以形成矩阵。它下面的线(大小线)定义了数据的大小。标题总是以“%%MatrixMarket”开头，其后的四个字段是对象、格式、字段和对称性。对象字段可以是“矩阵”或“向量”(在我们的例子中是矩阵)，格式可以是“坐标”或“数组”。“坐标”格式在mtx文件中仅存储非零值，因此“大小线”保持矩阵中的行数、列数和非零条目数。如果格式为“数组”，则“尺寸线”的格式为[行数和列数]。下一部分是“数据行”，它保存实际的数据。如果格式是“坐标”,则有“非零条目数”数据行数，否则在“数组”的情况下，您应该期望{行数*列数}数据行数，其中每一行表示两个节点之间的一条边。对于加权图，数据线可以具有第三列“边权重”。其余的细节可以在上面的“mtx”链接中找到。我分享这些信息是为了让您对它有一点了解，这样如果您面临解析错误，您可以编写自己的实现。大多数时候我们可能不需要，因为Scipy支持读/写mtx格式。但是这里我们需要首先将mtx转换成edgelist格式，因为<a class="ae lr" href="https://networkx.github.io/" rel="noopener ugc nofollow" target="_blank"> Networkx </a>(我用来处理图形数据的包)和Node2Vec脚本都使用这种格式。</p><p id="8d97" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">Edgelist只是去掉标题、注释和大小行后的数据行，就像这样:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="c21d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> 2.2构建节点嵌入</strong></p><p id="4dff" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了计算图中的节点嵌入，我们将使用Node2Vec作者提供的脚本。但是让我先简单介绍一下这个算法，因为它很有趣，也因为它是我们在这里所做的事情的一个重要部分。即使我们不必实现算法，也不应该阻止我们学习它。但是您可以选择跳到下一部分。</p><p id="9095" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> 2.2.1节点2Vec </strong></p><p id="21b4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">其思想是对图中每个节点的邻域进行采样，也称为“行走”(这是一种有趣的说法:收集附近的节点)，将访问过的节点的列表转换为字符串(这样现在您就有了形式的样本([附近节点的列表，作为包含源节点的字符串]))，然后将所有这样的列表传递给Word2Vec模型来训练和学习嵌入，就像我们对句子列表进行训练一样。但是Node2Vec最好的部分是它如何对邻居进行采样。作者认为，像BFS和DFS这样的经典方法位于光谱的两个相反的末端。BFS倾向于对更靠近源节点的节点进行采样，这使得所学习的嵌入更好地捕捉节点的结构相似性(例如，节点是否在其邻域中充当中枢/中心)。但它只对图表的一小部分进行了采样。另一方面，DFS倾向于对远离源的节点进行采样，因此从这种“行走”中学习会导致嵌入，这种嵌入更好地捕捉图形的宏观视图(连通性和“同质性”,如本文中所述),但不能捕捉更精细的细节，因为行走是有限长度的，并且它们有许多要覆盖的基础。</p><p id="e912" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，他们提出了一种新的采样节点邻域的方法，称为“二阶随机游走”。为了更清楚，我们做这些只是为了以可控的方式对节点邻域进行采样，以便遍历包括BFS和DFS的质量。让我们考虑固定长度的步行'<em class="mx">c '</em>'<em class="mx">l</em>'，并假设您已经从节点'<em class="mx"> u' </em>开始步行。假设您已经从节点<em class="mx"> t </em>行进到<em class="mx"> v </em>。他们使用以下概率分布，而不是随机或基于权重边缘选择下一个节点:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/b1151361b4b3b337b04f9e2ad995bd20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*fHpS0nLLwIOAvcIQKYB07A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">下一个节点的PD，来自node2vec纸张</p></figure><p id="253e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这意味着如果遍历中的前一个节点是<em class="mx"> v </em>，那么下一个节点是<em class="mx"> x </em>的概率由pi_{vx}/z给出(不能使用内联latex，因为每次编辑内容时Medium都会搞砸它)，如果节点<em class="mx"> v </em>和<em class="mx"> x </em>通过边连接，则为0。pi_{vx}是未规格化的转移概率，<em class="mx"> z </em>是规格化常数(可以是来自节点<em class="mx"> v </em>的所有边的概率的总和)。他们将pi_{vx}定义为:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/449461a339645dddf30e47dc797c76be.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/1*cNycAhzPfnQCG3xqvHLF2Q.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">非规格化概率修正:应该是pi_{vx}</p></figure><p id="d1db" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">其中w_{vx}是节点<em class="mx"> v </em>和<em class="mx"> x </em>之间的边的权重，并且$\alpha_{pq}(t，x)$是:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/a89a1c6ebefa11f6abadb5ed735f3775.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YesRWgv1HyvO6_R8uGIAHg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">阿尔法的定义</p></figure><p id="2f8f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">其中d_{tx}是<em class="mx"> t </em>和<em class="mx"> x </em>之间的最短路径距离。让我们来理解一下<em class="mx"> p </em>和<em class="mx"> q </em>的作用，因为这是控制随机游走(BFS或DFS)性质的两个参数，因此有术语“二阶随机游走”。</p><p id="595a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果我们稍微回顾一下，我们从节点<em class="mx"> t </em>到达节点<em class="mx"> v </em>，现在我们需要从<em class="mx"> v </em>决定下一个要访问的节点。<em class="mx"> </em>如果您将<em class="mx"> p </em>设置为一个较低的值，那么行走会更喜欢重新访问先前的节点。你会问，怎么会？假设你已经从<em class="mx"> t </em>到达<em class="mx"> v </em>，现在你有以下选项——去v的其他邻居(x1，x2…xn)或者回到<em class="mx"> t </em>(别忘了‘t’也是邻居)，在这种情况下d_{tx}为零，因为这里的x是<em class="mx"> t </em>本身(对应于上式中的第一个选项1/p)。因此，如果<em class="mx"> p </em>是一个非常低的值，那么1/p将会非常大，随机漫步将会返回到先前的节点，从而模拟BFS的行为。请参考下面的(丑陋的)图片来形象化这一点:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/c8861c7050e59ae0f86733aa1513fa2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HVIH3yQvIsTVMR39gjKZjg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">随机漫步:“v”处的下一个节点决策</p></figure><p id="5127" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这张纸有一个相似的图像，但没有距离值。类似地，如果我们为<em class="mx"> q </em>选择一个较低的值，那么我们通过将较高的概率分配给定义α的等式中的第三个选项，鼓励算法冒险远离<em class="mx"> t </em>。对遍历中的每个节点都进行这种决策。这样走了几次。</p><p id="02d0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果你理解了上面的解释，你就知道node2vec随机漫步是如何工作的了。你也可以在作者的GitHub库上查看它的实现(但是是python 2格式的)。在我的项目中，我也包含了作者的脚本，但是转换成了Python3格式。</p><p id="db1d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">2.2.2运行node2vec脚本</p><p id="0e65" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">运行脚本非常简单。您可以选择使用其参数的所有默认值运行，或者根据您的需要进行更改。我用默认值运行:</p><pre class="kg kh ki kj gt nm nn no np aw nq bi"><span id="e21f" class="lz ma iq nn b gy nr ns l nt nu">python node2vec/main3.py --input ../data/socfb-American75.edgelist --output ../data/emb/socfb-American75.emd</span></pre><p id="79b6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">只需修改输入和输出路径。</p><p id="3dc3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> 2.3构建数据集</strong></p><p id="7c2a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在上一步中，我们有一个包含节点及其嵌入的文件，格式如下:</p><pre class="kg kh ki kj gt nm nn no np aw nq bi"><span id="95b2" class="lz ma iq nn b gy nr ns l nt nu">6386 128</span><span id="51a1" class="lz ma iq nn b gy ob ns l nt nu">224 0.3206627 -0.0963422 -0.039677385 -0.03290484 0.4414181 ....</span><span id="adc0" class="lz ma iq nn b gy ob ns l nt nu">4046 -0.036134206 -0.082308784 0.49080133 -0.36878866 0.13950641 ...<br/>.<br/>.<br/>.</span></pre><p id="ea51" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">前两个数分别代表节点数和嵌入维数。我们的下一步是在图中选择一定数量的节点作为界标，并计算它们与所有其余节点的距离。这将给我们(界标数*(节点数-1))个样本。我们选择地标是因为寻找所有节点的距离需要更多的计算。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">查找每个节点与所选标志点节点的距离</p></figure><p id="8221" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">“distance_map”字典保存每个节点到给定地标的距离(作为关键字)。现在我们需要为每个节点/界标对获取相应的node2vec嵌入，并将它们组合起来形成一个单独的嵌入。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">组合节点和标志嵌入</p></figure><p id="e9cc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这里的<em class="mx"> emd_map </em>是一个字典，它将每个节点作为键，并将它的嵌入作为值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/da5319f712dddcb0786957429b5cd162.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jFK7q8GoaN0IET3yZE-GUA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">从嵌入距离字典形成数组</p></figure><p id="9060" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">接下来，我们需要从嵌入距离字典中形成numpy ndarrays，如上所示。请注意上面单元输出中的两件事—样本数不等于界标数*(节点数-1)。这是因为我忽略了具有<em class="mx"> inf </em>距离的节点对，即没有路径连接它们。其次，训练数组的大小很大，大约为927MB，因为它是“float64”类型的数组。为了节省空间，我把它们改成了float32。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/e41c8922b6d0efe56550a85ea6f1f0ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mFaoi2WHc-cdueSTGN0TyA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">转换为float32</p></figure><p id="d259" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如您所见，我们可以节省大约50%的空间。如果您担心这种转换会导致精度损失，可以验证数据损失:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/fe4a724251d6f1ebc7350fc6533d6324.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L1483h9v79YdWV5bdu-t3g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">测量精度损失</p></figure><p id="774f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这似乎无关紧要。接下来，让我们看看目标变量的分布。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi of"><img src="../Images/956f31d4dd8e4bfe38b135a8c05084d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oAx5P2-IIdscGKoGcoYGyw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">距离值的分布</p></figure><p id="3da7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如您所见，距离值2和3实际上主导了数据。在图表上，6、7、8看不到，但它们出现在数据中，只有距离为8的样本被我丢弃了。还要注意，在论文中，他们忽略了距离值为1的样本，但我已经将它们包括在训练中。</p><p id="f11a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由于数据严重不平衡，我对培训/测试进行了分层:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="eba0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">…然后将其规范化:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="e061" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我已经保存了分割数据，这样预处理就可以只进行一次。咻！！数据集的形成是这个项目的一大部分，最后我解释了主要步骤。我可能漏掉了一些，更多细节你可以查看项目库中的<a class="ae lr" href="https://github.com/nayash/shortest-distance-approx-deep-learning/blob/master/src/data_prep.ipynb" rel="noopener ugc nofollow" target="_blank"> data_prep.ipynb </a>。</p><p id="85b5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> 2.4训练神经网络</strong></p><p id="8133" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在是激动人心的部分。训练的代码在<a class="ae lr" href="https://github.com/nayash/shortest-distance-approx-deep-learning/blob/master/src/train.ipynb" rel="noopener ugc nofollow" target="_blank"> train.ipynb </a>文件中。你会注意到一些单元格看起来没有完成/自记。我特意留下这些，让感兴趣的读者从我失败的尝试和每次失败后采取的步骤中获得经验。我甚至已经将<a class="ae lr" href="https://github.com/nayash/shortest-distance-approx-deep-learning/tree/master/outputs/logs/runs" rel="noopener ugc nofollow" target="_blank"> tensorboard日志</a>(包括所做的更改、结果、注释等)上传到GitHub repo中，以便我和其他人以后可以使用所有的历史记录。如果您对日志不感兴趣，可以毫无问题地删除文件夹。</p><p id="6833" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由于数据是倾斜的，我必须对少数目标值进行过采样(我在这里没有使用术语“类”，因为我已经训练了一个回归模型)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="5383" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我首先对多数值进行欠采样，然后对少数值进行过采样。直觉上是对少数距离值进行过采样，使其与多数值的样本数量相当，同时保持总体数据尽可能小。分数值“0.7”实际上不是从任何地方计算/得出的，只是通过查看每个距离值的频率看起来是合理的。是的……不要忘记在过采样/欠采样后重排数据。这似乎是一件微不足道的事情，你可以忽略，但事实证明，许多批次的距离值相同(如全是1或2等)，这使得训练无法进行！</p><p id="624c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，让我们定义一个基线，一个简单的模型及其结果，我们可以与它进行比较，看看我们做得有多好:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi og"><img src="../Images/13e774cb4a067d377f171d0499de16e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1VqgyrUqNXWyE6K1uPlxrA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">使用线性回归设置基线</p></figure><p id="e1a5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">线性回归做得出奇的好！考虑到这种情况下的概率预测值约为14% (1/7)，50%是一个比较好的基线。</p><p id="dc6c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> PyTroch型号</strong></p><p id="b97c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于我以前的所有项目，我都使用Keras，但最近我改用PyTorch，从那以后我就没有后悔过。我在做另一个项目，涉及到编写一个定制的损失函数，需要对模型中间层的输出和其他定制的东西进行一些计算。如果你曾经尝试过Keras的这些东西，你就会知道这并不简单。即使有急切的执行，我也不能让它工作。更糟糕的是，在一个晴朗的日子，Keras开始抛出CUDA兼容性错误，无论我用所需的驱动程序构建了多少次新环境，它都不会消失。这是我的转折点。使用PyTorch，您可能需要为训练循环编写一点额外的代码，但这是值得的。现在，我不是说这些问题不能通过更多的努力来解决，但是，在一个有PyTorch的世界里，为什么打破你的头呢？所以，我对我为什么转而使用PyTorch的咆哮到此结束。</p><p id="0e6d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">但是对于不熟悉PyTorch的读者来说，不要灰心。几乎所有使用的组件都可以在Keras中获得(除了可能是循环LR调度器，但是有它的实现可以使用)。解释PyTorch超出了本文的范围。</p><p id="62ea" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">给出最佳结果的模型具有以下配置(具有循环LR调度器、RMSProp优化器和泊松损失):</p><pre class="kg kh ki kj gt nm nn no np aw nq bi"><span id="62a4" class="lz ma iq nn b gy nr ns l nt nu"><strong class="nn ir">{'batch_size': 1000, 'input_size': 128, 'hidden_units_1': 200, 'hidden_units_2': 100, 'hidden_units_3': 50, 'do_1': 0.2, 'do_2': 0.1, 'do_3': 0.05, 'output_size': 1, 'lr': 0.001, 'min_lr': 1e-05, 'max_lr': 0.001, 'epochs': 500, 'lr_sched': 'clr', 'lr_sched_mode': 'triangular', 'gamma': 0.95}</strong></span></pre><p id="1028" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这是一个有辍学的5层(3个隐藏层)模型，用循环学习率训练。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="6a7f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果我在此之后尝试了其他配置，你可能在GitHub代码中找不到这个型号，因此参数可能会改变。但是你可以在 <a class="ae lr" href="https://github.com/nayash/shortest-distance-approx-deep-learning/tree/master/outputs/logs/runs/run47_smallerNN_noDO" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ir"> run47文件夹</strong> </a>中找到相应的型号和参数。请注意，这种配置不同于他们在论文中提到的配置。正如我读过的几乎所有其他论文一样，他们跳过了神经网络的低级细节。</p><p id="e9b8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">以下是如何为训练/验证/测试数据初始化数据加载器:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="f418" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在我们已经准备好训练模型了:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="c25b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">还只做过Keras/Fastai的人，不要害怕。训练PyTorch模型的代码并不总是这么大。我正在做很多其他的事情，比如提前停止，保存检查点等等。肯定比Keras复杂，但没什么一两天学不会的。但正如我之前提到的，所有这些组件都已经在Keras中存在(包括泊松损失)，因此您可以轻松地在您选择的框架上进行尝试。</p><p id="38d2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我训练了大约110个时期的模型。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oh"><img src="../Images/549710bba4d300f36a56cfa8e9edbe43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q1gv5pNQ26tCyGdQ-YsJxg.png"/></div></div></figure><p id="387b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">结果如下:</p><p id="19b7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">泊松损失= -0.11 <br/> MAE损失= 0.32 <br/> MSE损失= 0.17 <br/>准确度= 76.40% <br/> vs <br/>基线:<br/> MAE损失= 0.59 <br/> MSE损失= 0.56 <br/>准确度= 50.57% </strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oi"><img src="../Images/0d66f8b60650a6d03226b51af2a709d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yLP-InKUCBFlY1dXQGhi4Q.png"/></div></div></figure><p id="eacf" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">虽然这是一个回归问题，但我仍然记录了准确性，因为我发现它更直观(它不是一个指标，只是我用来比较模型的东西)。这不是一个值得夸耀的结果，但也不坏。此外，我认为还有很大的改进余地，我将在后面提到这一点。</p><p id="ed2b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果你想知道为什么路径距离越长准确性越差，作者也做了类似的观察。他们是这样说的:</p><blockquote class="oj ok ol"><p id="0e2b" class="kv kw mx kx b ky kz jr la lb lc ju ld om lf lg lh on lj lk ll oo ln lo lp lq ij bi translated">观察到利用node2vec嵌入的较长路径导致的较大误差。一方面，在训练集中，我们没有足够的样本用于更长的距离。另一方面，node2vec无法学习远处节点的结构特征。</p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi op"><img src="../Images/ef80165b90f8fc1198711ab8f43bf2ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lQfNdeUbAFkGpNmZyJEpIA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">论文的结果。请注意，路径距离越长，误差值越大。</p></figure><p id="5999" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">注意:这个模型有一点让我很困扰。尽管使用exp_range作为CLR模式，学习率在整个训练中没有变化(至少按照图)。伽玛值为0.95时总是会发生这种情况。需要调查一下。或者你之前也面临过这种情况，有什么解决办法，欢迎在这里分享。</p><p id="3d61" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">回想起来，以下是提高模型性能的一些因素:</p><ol class=""><li id="8400" class="my mz iq kx b ky kz lb lc le na li nb lm nc lq nd ne nf ng bi translated">泊松损失:我之前尝试过MSE和MAE(论文中使用的)，但是两者都不行。</li><li id="694b" class="my mz iq kx b ky nh lb ni le nj li nk lm nl lq nd ne nf ng bi translated">批量正常化:批量正常化之前训练损失改善真的很慢。在batch norm之前，我在达到这些数字之前至少训练了1000个纪元。</li><li id="3711" class="my mz iq kx b ky nh lb ni le nj li nk lm nl lq nd ne nf ng bi translated">欠采样/过采样</li><li id="99af" class="my mz iq kx b ky nh lb ni le nj li nk lm nl lq nd ne nf ng bi translated">循环LR调度程序</li><li id="ac9b" class="my mz iq kx b ky nh lb ni le nj li nk lm nl lq nd ne nf ng bi translated">StandardScaler代替MinMaxScaler</li><li id="74f6" class="my mz iq kx b ky nh lb ni le nj li nk lm nl lq nd ne nf ng bi translated">将优化器从SGD更改为RMSProp(本文中使用的是SGD)</li></ol><p id="eec5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> 3。进一步改进</strong></p><p id="bce9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有很多事情可以探索，因此需要很大的耐心。以下是一个不完整的列表:</p><ol class=""><li id="c41c" class="my mz iq kx b ky kz lb lc le na li nb lm nc lq nd ne nf ng bi translated">更好的超参数:尤其是学习率范围和不同的网络架构。</li><li id="83b2" class="my mz iq kx b ky nh lb ni le nj li nk lm nl lq nd ne nf ng bi translated">尝试对这些数据使用卷积神经网络。我很肯定这会改善结果。</li><li id="1580" class="my mz iq kx b ky nh lb ni le nj li nk lm nl lq nd ne nf ng bi translated">不同的node2vec嵌入维度(我们用的是128)。</li><li id="ef33" class="my mz iq kx b ky nh lb ni le nj li nk lm nl lq nd ne nf ng bi translated">您可能还记得，我们使用“平均”运算符来组合两个节点的嵌入。我们可以试试其他运营商。在论文中，作者观察到—</li></ol><blockquote class="oj ok ol"><p id="adbf" class="kv kw mx kx b ky kz jr la lb lc ju ld om lf lg lh on lj lk ll oo ln lo lp lq ij bi translated">“二元运算符在不同的数据集和不同的维度大小上没有一致的行为。例如，在脸书图中，平均算子优于其他算子，而串联在Youtube数据集上效果更好”</p></blockquote><p id="2f12" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">5.特性选择:我们可以通过只选择重要的特性来减少特性的数量。(文中未使用)</p><p id="064b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">6.更好的采样技术:如KMeansSMOTE、SMOTE、聚类质心等。我试着使用这些技术，但是它们花了太长时间来完成。</p><p id="193b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">7.训练损失和val损失差距较大，建议减少过拟合以获得更好的结果。也许可以试试小一点的模型，看看它是否有学习能力。</p><p id="f8fc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> 4。结论</strong></p><p id="45e6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">嗯，这已经是一篇长文了，所以我就不啰嗦了。这是一个有趣的项目，有很多很酷的概念需要学习。我不能在这里容纳他们中的许多人，但我已经记录了并将记录更多关于这个问题的有趣事实，当我发现它们时，在项目的<a class="ae lr" href="https://github.com/nayash/shortest-distance-approx-deep-learning/blob/master/src/fun.ipynb" rel="noopener ugc nofollow" target="_blank"> fun.ipynb </a>文件中。谢谢你坚持到最后。编码快乐！</p></div></div>    
</body>
</html>