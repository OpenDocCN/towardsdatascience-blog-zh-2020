<html>
<head>
<title>Bayesian Inference Algorithms: MCMC and VI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">贝叶斯推理算法:MCMC和VI</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/bayesian-inference-algorithms-mcmc-and-vi-a8dad51ad5f5?source=collection_archive---------9-----------------------#2020-03-11">https://towardsdatascience.com/bayesian-inference-algorithms-mcmc-and-vi-a8dad51ad5f5?source=collection_archive---------9-----------------------#2020-03-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b5c5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">直觉和诊断</h2></div><p id="9c85" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与机器学习(ML)的其他领域不同，贝叶斯ML要求我们知道输出何时不可信。当您定型一个回归或xgboost模型时，在给定设置和数据的情况下，可以从表面上接受该模型。使用贝叶斯ML，不能保证输出是正确的。</p><p id="8067" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">贝叶斯工作流程可以分为三个主要部分:建模、推理和批评。即使我们已经编写了一个合理的概率模型，由于推理算法，无论是因为算法失败还是因为我们选择了一个不合适的算法，结果都可能是误导的。本文将解释每种算法的工作原理，讨论每种算法的优缺点，以及如何诊断它们的性能。</p><p id="304a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">贝叶斯计算的主要目标是找到贝叶斯定理中分母的变通方法:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/6f596e586e9ab49c36f141253bf8a69a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i_hU9GxbZSr_6mQm24Cujg.png"/></div></div></figure><p id="f4b9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">除了最简单的模型，这个积分是不可能计算的。推理算法是获得p(θ|X)的方法，而无需对积分求值。</p></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h1 id="b5b6" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">MCMC</h1><p id="2503" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">马尔可夫链蒙特卡罗，顾名思义，使用必须满足某些条件的马尔可夫链来运行蒙特卡罗模拟，因此无论起点如何，我们总是以我们期望的平稳分布(后验分布)结束。</p><p id="eb85" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">想象后验分布是某种丘陵地形。你想要探索地形，并在与土堆高度成比例的任何地点花费时间。需要注意的是，雾太大了，你什么也看不见。即使你站在山顶上，你也不知道与其他山相比，这是一座高的山还是一座矮的山。你可以知道你站在海拔2千米的地方，但是其他的山只有1千米高，还是有5千米高的山？只配备了一个测量高度的装置，你需要想出一个规则来实现你的目标。</p><p id="ab42" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">马尔可夫链必须具有:</p><ul class=""><li id="4dfe" class="mu mv it kk b kl km ko kp kr mw kv mx kz my ld mz na nb nc bi translated"><a class="ae nd" href="https://en.wikipedia.org/wiki/Markov_chain#Ergodicity" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu">遍历性</strong> </a>。你可以在有限的时间内从任何状态到达一个状态(因此可以回到你的初始状态)。没有确定的循环。</li><li id="2e16" class="mu mv it kk b kl ne ko nf kr ng kv nh kz ni ld mz na nb nc bi translated"><a class="ae nd" href="https://en.wikipedia.org/wiki/Detailed_balance#Reversible_Markov_chains" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu">明细平衡</strong> </a>。p(x|y)q(y) = p(y|x)q(x)</li></ul><p id="330c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有些规则比其他规则更有效。实际上，大多数MCMC都是<a class="ae nd" href="http://www.stat.columbia.edu/~gelman/research/published/nuts.pdf" rel="noopener ugc nofollow" target="_blank">螺母</a>(不掉头采样器)，在需要时(主要是当参数离散时)加入一些Gibbs。</p><h2 id="634d" class="nj ly it bd lz nk nl dn md nm nn dp mh kr no np mj kv nq nr ml kz ns nt mn nu bi translated">吉布斯</h2><p id="77ba" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">假设我们要求x和y两个参数的后验分布，我们可以不受限制地从一个点跳到另一个点，也可以把每次跳跃分解成一个水平运动+一个垂直运动。这就是吉布斯的工作。我们举起双手说:我们不知道如何为前者制定规则，但我们可以为后者创造规则。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/37ad56a2c09206f9b4675d49b810c242.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*oUrU8G_FrYxQ4OLQy2rKjA.png"/></div><p class="nw nx gj gh gi ny nz bd b be z dk translated"><a class="ae nd" href="https://commons.wikimedia.org/wiki/File:Perpendicular_Vector_Addition.svg" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="2a09" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">吉布斯要求有条件的结合。我们逐一检查所有参数。顺序无所谓— <em class="oa">直观上</em>(但不是真的)，横+竖=竖+横。我们通过分析求解后验概率对每个参数进行采样，保持所有其他参数不变。</p><p id="4615" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">举个简单的例子，假设我们想估计正态分布的均值μ和精度λ = 1/σ。我们放置先验μ~N(0，1)和λ~γ(1，1)。那么条件后验概率是</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ob"><img src="../Images/3a8a388c736e7b3f11ceda98daa03ced.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QcRPKwJKENLM3d3OexwDJQ.png"/></div></div></figure><p id="7bc6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们希望在这两种条件后验抽样之间进行交替。下面的R代码展示了吉布斯采样在这个模型中是如何工作的:</p><pre class="lf lg lh li gt oc od oe of aw og bi"><span id="8568" class="nj ly it od b gy oh oi l oj ok">library(ggplot2)</span><span id="9671" class="nj ly it od b gy ol oi l oj ok">num_sample &lt;- 5000    # number of samples for Gibbs<br/>burn_in &lt;- 1000       # first n samples we discard<br/>prior_mean &lt;- 0       # the prior on mu<br/>prior_precision &lt;- 1  # the prior on mu<br/>prior_shape &lt;- 1      # alpha in prior for precision<br/>prior_rate &lt;- 1       # beta in prior for precision<br/>num_obs &lt;- 30         # size of our data<br/>true_mean &lt;- 3        <br/>true_precision &lt;- 0.25</span><span id="69aa" class="nj ly it od b gy ol oi l oj ok">set.seed(9)<br/>X &lt;- rnorm(num_obs, true_mean, 1/sqrt(true_precision))<br/>mu &lt;- rep(NA, num_sample)<br/>lambda &lt;- rep(NA, num_sample)</span><span id="35be" class="nj ly it od b gy ol oi l oj ok">#initialize some values<br/>mu[1] &lt;- 0 <br/>lambda[1] &lt;- 1</span><span id="54d4" class="nj ly it od b gy ol oi l oj ok">for(i in 2:num_sample){<br/>  if(i %% 2){<br/>    mu[i] &lt;- rnorm(<br/>      1, <br/>      mean = (prior_precision * prior_mean + lambda[i-1] * sum(X)) / <br/>        (prior_precision + num_obs * lambda[i-1]),<br/>      sd = sqrt(1 / (prior_precision + num_obs * lambda[i-1]))<br/>    )<br/>    lambda[i] &lt;- lambda[i-1]<br/>  } else{<br/>    mu[i] &lt;- mu[i-1]<br/>    lambda[i] &lt;- rgamma(<br/>      1,<br/>      shape = prior_shape + num_obs / 2,<br/>      rate = prior_rate + sum((X - mu[i])^2) / 2<br/>    )<br/>  }<br/>}</span><span id="9d2e" class="nj ly it od b gy ol oi l oj ok">posterior &lt;- data.frame(mu, lambda)[(burn_in+1):num_sample,]</span><span id="7c9c" class="nj ly it od b gy ol oi l oj ok">ggplot(posterior) +<br/>  geom_point(aes(x = mu, y = lambda)) +<br/>  geom_path(aes(x = mu, y = lambda), alpha = 0.3) +<br/>  ggtitle('Gibbs sampling') +<br/>  xlab(expression(mu)) +<br/>  ylab(expression(lambda))</span><span id="09a0" class="nj ly it od b gy ol oi l oj ok">ggplot(posterior) +<br/>  geom_histogram(<br/>    aes(x = mu, y = stat(count) / sum(count)),<br/>    alpha = 0.5) +<br/>  geom_vline(<br/>    aes(xintercept = quantile(posterior$mu, 0.025)), <br/>    color = 'red') +<br/>  geom_vline(<br/>    aes(xintercept = quantile(posterior$mu, 0.975)), <br/>    color = 'red') +<br/>  ylab('Relative frequency') +<br/>  xlab(expression(mu)) +<br/>  ggtitle(bquote('95% credible interval of ' ~ mu))</span><span id="0de2" class="nj ly it od b gy ol oi l oj ok">ggplot(posterior) +<br/>  geom_histogram(<br/>    aes(x = lambda, y = stat(count) / sum(count)), <br/>    alpha = 0.5) +<br/>  geom_vline(<br/>    aes(xintercept = quantile(posterior$lambda, 0.025)), <br/>    color = 'red') +<br/>  geom_vline(<br/>    aes(xintercept = quantile(posterior$lambda, 0.975)), <br/>    color = 'red') +<br/>  ylab('Relative frequency') +<br/>  xlab(expression(lambda)) +<br/>  ggtitle(bquote('95% credible interval of ' ~ lambda))</span></pre><p id="fde1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意老化设置。MCMC有希望收敛到目标分布，但可能需要一段时间。根据经验，我们丢弃前1000个，因为这个链可能还没有到达目的地。</p><p id="1d4b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">尝试更改这些值，以直观地了解后验行为。如果我们追踪运动的路径，我们会看到水平-垂直模式:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi om"><img src="../Images/aa27a8c7c7219681818a7a8422899069.png" data-original-src="https://miro.medium.com/v2/resize:fit:1074/format:webp/1*CBpbQj-lL4SjZIWaAS36oQ.jpeg"/></div></figure><p id="bf99" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以使用边际分布计算可信区间:</p><div class="lf lg lh li gt ab cb"><figure class="on lj oo op oq or os paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><img src="../Images/21092d67b76f7178fbb15d582dc59ffa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*6t35A2bNIHsG1X0P1dXwKA.jpeg"/></div></figure><figure class="on lj oo op oq or os paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><img src="../Images/5d4f373ab13d55a116527ec6a3d34b0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*EASZ6yxsMwv2bH7mmAG81Q.jpeg"/></div></figure></div><p id="ac50" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当你的模型是有条件共轭的时候，Gibbs会比其他方法更好。例如，尝试在LDA上运行NUTS不起作用，因为对于离散的潜在变量没有梯度。然而，为LDA运行Gibbs采样器(相对而言)更快更容易。</p><h2 id="a370" class="nj ly it bd lz nk nl dn md nm nn dp mh kr no np mj kv nq nr ml kz ns nt mn nu bi translated">大都市</h2><p id="bc7a" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">Metropolis算法着眼于贝叶斯定理，提出“我们能让分母互相抵消吗？”算法:</p><ol class=""><li id="c521" class="mu mv it kk b kl km ko kp kr mw kv mx kz my ld ot na nb nc bi translated">从某个随机的初始点θ开始。</li><li id="285f" class="mu mv it kk b kl ne ko nf kr ng kv nh kz ni ld ot na nb nc bi translated">从某分布p(θ*|θ)画出一个建议值θ*。</li><li id="777a" class="mu mv it kk b kl ne ko nf kr ng kv nh kz ni ld ot na nb nc bi translated">如果p(X|θ*)p(θ*) &gt; p(X|θ)p(θ)，接受建议值。否则，以概率[p(X|θ*)p(θ*)] / [p(X|θ)p(θ)]接受建议值。</li><li id="78c9" class="mu mv it kk b kl ne ko nf kr ng kv nh kz ni ld ot na nb nc bi translated">如果被接受，移动到新的地点。否则，原地不动。不管怎样，记录你的位置。</li><li id="5624" class="mu mv it kk b kl ne ko nf kr ng kv nh kz ni ld ot na nb nc bi translated">重复(2)、(3)和(4)，重复设定的迭代次数。</li></ol><p id="80d7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">看接受概率:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ou"><img src="../Images/4fcbd855d7d7c3ab02e1cb854df59f0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*erZsFwuWd_BXKtpN5pxmNQ.png"/></div></div></figure><p id="0fd0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">记住p(X)是一个未知常数。因为我们的目标是在与后验密度成比例的点上花费时间，所以我们可以不计算p(X)就这样做。</p><p id="8e0a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">满足遍历性和细节平衡的最简单方法是从N(θ，s)中采样θ*。对称连续分布就可以了。</p><p id="da1c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Metropolis-Hastings (MH)将该算法推广到非对称建议分布，同时保持详细的平衡。仔细观察MH的验收规则，并将其与详细平衡的含义进行比较。</p><p id="4005" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面是一些R代码，看看Metropolis算法是如何工作的，在θ上使用N(0，1)先验，并且已知X ~ N(θ，1):</p><pre class="lf lg lh li gt oc od oe of aw og bi"><span id="17f5" class="nj ly it od b gy oh oi l oj ok">library(ggplot2)</span><span id="ee3b" class="nj ly it od b gy ol oi l oj ok">num_iter &lt;- 2000<br/>s &lt;- c(0.1, 1, 10)</span><span id="513b" class="nj ly it od b gy ol oi l oj ok">set.seed(1)<br/>x &lt;- rnorm(10, 10, 1)<br/>thetas &lt;- list()</span><span id="150e" class="nj ly it od b gy ol oi l oj ok">for(i in 1:length(s)){<br/>  theta &lt;- rep(NA, num_iter)<br/>  current_theta &lt;- rnorm(1, 0, 10)<br/>  for(j in 1:num_iter){<br/>    proposed_theta &lt;- rnorm(1, current_theta, s[i])<br/>    accept_prob &lt;- exp(<br/>      dnorm(proposed_theta, 0, 1, log = TRUE) +<br/>        sum(dnorm(x, proposed_theta, 1, log = TRUE)) -<br/>        dnorm(current_theta, 0, 1, log = TRUE) -<br/>        sum(dnorm(x, current_theta, 1, log = TRUE))<br/>    )<br/>    if(runif(1) &lt; accept_prob){<br/>      current_theta &lt;- proposed_theta<br/>      theta[j] &lt;- proposed_theta<br/>    } else {<br/>      theta[j] &lt;- current_theta<br/>    }<br/>  }<br/>  thetas[[i]] &lt;- cbind(1:num_iter, theta, rep(s[i], num_iter))<br/>}</span><span id="e6fd" class="nj ly it od b gy ol oi l oj ok">thetas &lt;- data.frame(do.call('rbind', thetas))<br/>colnames(thetas) &lt;- c('iter', 'theta', 's')<br/>thetas$s &lt;- factor(thetas$s)</span><span id="d5a5" class="nj ly it od b gy ol oi l oj ok">ggplot(thetas) +<br/>  geom_line(aes(x = iter, y = theta)) +<br/>  facet_grid(s~.)</span><span id="8c1f" class="nj ly it od b gy ol oi l oj ok">ggplot(thetas[thetas$iter &gt; 1000,]) +<br/>  geom_line(aes(x = iter, y = theta)) +<br/>  facet_grid(s~.)</span></pre><p id="f1a8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Metropolis算法的一个问题是，它对我们选择的建议分布很敏感。使用不同的标准差会产生不同的结果:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi om"><img src="../Images/cff25d910be075b7276f19bce98cc3ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1074/format:webp/1*exRWG3c2Kui4GfnTQQUbhQ.jpeg"/></div></figure><p id="0f67" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正如你所看到的，链需要一些时间来达到它的目标分布。解析地说，我们知道后验概率应该是N(0.92，0.09)。为了看得更清楚，我们应该丢弃老化期间的样本，比如前1000个样本:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi om"><img src="../Images/31875a32e1933b6ff760542b55125bb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1074/format:webp/1*O2JgOr6mdG37hAojMmeDdw.jpeg"/></div></figure><p id="214e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们使s非常小，比如说0.01，那么即使在1000次迭代之后，该链也不会达到目标分布。另一方面，拥有一个大的s会导致非常参差不齐的转换，因为我们会拒绝大多数提议。最好的s介于0.1和1之间。我们需要通过反复试验来找到它，这可能会很麻烦。虽然我们不会使用Metropolis，但获得MCMC对设置如何敏感的直觉很重要。</p><h2 id="1524" class="nj ly it bd lz nk nl dn md nm nn dp mh kr no np mj kv nq nr ml kz ns nt mn nu bi translated">哈密尔顿/坚果</h2><p id="2345" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">我在这里说的任何东西都比不上McElreath的精彩<a class="ae nd" href="https://elevanth.org/blog/2017/11/28/build-a-better-markov-chain/" rel="noopener ugc nofollow" target="_blank">文章</a>，所以我建议阅读动画和细节。基本思想是哈密顿蒙特卡罗(HMC)是一种物理模拟。你有一个球在某个地形上滚动，这个地形是负对数后验概率，被某个未知常数上移。对于二维正态分布，想象一下把它翻过来，你就得到一个碗。你用一个随机的动量向一个随机的方向轻弹这个球，过了一段时间后停下来，记录下它最后停在哪里。当总能量(势能+动能)与初始能量相差太大时，您拒绝该样本，表明您的模拟失败。斯坦称这些为“发散过渡”。</p><p id="98ac" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">MH在极高的维度上失败了，因为最终你会得到接近0%的接受率。人类的直觉在高维空间会崩溃。我们的三维大脑可能会将高维多元正态分布想象成一个实心球，但由于测量的的<a class="ae nd" href="https://en.wikipedia.org/wiki/Concentration_of_measure" rel="noopener ugc nofollow" target="_blank">集中度，它实际上是一个非常薄的球壳。如果我们把这个投影到2D，它看起来会像一个甜甜圈，而不是一个圆。HMC在甜甜圈上表现出色的事实意义深远。</a></p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/1a5ce64dd90e65e8ba2909b87bdcb87d.png" data-original-src="https://miro.medium.com/v2/resize:fit:614/format:webp/1*F51lqbwoFU2a8nKsTMbmvw.png"/></div><p class="nw nx gj gh gi ny nz bd b be z dk translated">大的步长导致不好的近似(<a class="ae nd" href="http://Physics simulations have to approximate trajectories by discretizing the steps. If you check every 10 &quot;seconds&quot;, then your simulated trajectory might differ too much from the actual trajectory. If you check every 0.00001 &quot;seconds&quot;, then your simulation will take a long time to compute even a single trajectory even though it will be much more accurate. One major downside of HMC is the need to tune the settings of the simulation." rel="noopener ugc nofollow" target="_blank">源</a>)</p></figure><p id="cf2d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">物理模拟必须通过离散化步骤来近似轨迹。如果你每10秒检查一次，那么你的模拟轨迹可能与实际轨迹相差太多。如果你每0.00001秒检查一次，那么你的模拟将花费很长时间来计算一个单独的轨迹，即使它会更精确。你需要调整模拟设置，以获得良好的HMC结果。</p><p id="a1be" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae nd" href="http://www.stat.columbia.edu/~gelman/research/published/nuts.pdf" rel="noopener ugc nofollow" target="_blank">螺母</a>在预热阶段(而不是预烧阶段)自动为您调整设置<em class="oa">和</em>通过防止U形转弯为您提供更好的样本。如果你没有查看上面链接的<a class="ae nd" href="https://elevanth.org/blog/2017/11/28/build-a-better-markov-chain/" rel="noopener ugc nofollow" target="_blank">篇</a>，建议现在就看。在这个时代，几乎没有理由用MH或HMC代替坚果。</p><p id="6dd8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">也就是说，NUTS仍然会遇到一些问题。</p><p id="51de" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，它可能会卡在多模态后部的单一模式附近(再次参考<a class="ae nd" href="https://elevanth.org/blog/2017/11/28/build-a-better-markov-chain/" rel="noopener ugc nofollow" target="_blank">文章</a>)。您可以通过诊断来检测此问题(运行多个链！)然后要求NUTS获取更多的样本以更充分地探查后部。</p><p id="4b4d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第二，NUTS每走一步都需要评估地形的坡度。计算梯度的成本非常高，我们<em class="oa">必须</em>使用整个数据集，所以它是不可伸缩的。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ow"><img src="../Images/c578974fc7df52743a81358a141c5a8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IHzUqG8tUOPsXF0NPkbE_A.png"/></div></div><p class="nw nx gj gh gi ny nz bd b be z dk translated">尼尔的漏斗(<a class="ae nd" href="https://mc-stan.org/docs/2_22/stan-users-guide/reparameterization-section.html" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="1327" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第三，它不能探索类似尼尔漏斗的东西。这是分层模型的一个特别退化的例子。您可以阅读Stan文档中的示例。本质上，y是对数标度参数，用于模拟组间方差，而x是组均值参数。NUTS学习单一步长，但这种地形需要不同的步长，这取决于球在漏斗上的位置。在宽部分中起作用的步长在窄部分中将不起作用，而在窄部分中起作用的步长将太慢地探索宽部分。</p><p id="6e5d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您看到太多的发散过渡，并且它们都发生在同一个区域，您就会发现这个问题。建模者需要重新参数化模型，以便NUTS可以发挥其魔力，可能通过找到(相对)不相关的参数化或重新调整数据以使参数在相同的范围内。对于固定效应模型，这是通过对预测矩阵进行QR分解来实现的。</p><p id="108d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">题外话:重新参数化通常是加速计算的好主意。这样想:如果我们提供一个漂亮的碗状表面，球可以滚得到处都是。探索一根稻草更加困难。在没有发散转换的情况下，来自两种方法的样本应该是正确的，但是QR分解的运行时间可以快很多。</p></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h2 id="8142" class="nj ly it bd lz nk nl dn md nm nn dp mh kr no np mj kv nq nr ml kz ns nt mn nu bi translated">诊断学</h2><p id="6cea" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated"><strong class="kk iu"> R帽子</strong></p><p id="8a6f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae nd" href="http://www.stat.columbia.edu/~gelman/research/published/brooksgelman2.pdf" rel="noopener ugc nofollow" target="_blank"> R hat </a>看起来可疑地像方差分析中的F统计量，所以这是我给出的直觉。如果所有的链都是相同的，那么“F统计”应该是1。</p><p id="b147" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，<a class="ae nd" href="https://statmodeling.stat.columbia.edu/2019/03/19/maybe-its-time-to-let-the-old-ways-die-or-we-broke-r-hat-so-now-we-have-to-fix-it/" rel="noopener ugc nofollow" target="_blank">反过来就不成立</a>。Rhat有可能是1，然而链并不收敛于任何东西。我们仍然需要检查其他诊断，但至少如果Rhat &gt; 1.00，那么我们很快就会知道有问题。(好笑的是老一点的教材说&gt; 1.1，后来改成了&gt; 1.01，现在又往&gt; 1.005移动。让我们坚持1.00美元。)</p><p id="0616" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> n_eff </strong></p><p id="b241" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">样本容量的有效数量定义为:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ox"><img src="../Images/01debfd8b35c5798f6c740c53e36e7fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/1*8CvtAmIebrmELi9p7DZKIQ.png"/></div></div></figure><p id="7970" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中，ρ_t是滞后t时的自相关，实际上，我们会在自相关变为0时截断求和。</p><p id="e87f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于马尔可夫特性，MCMC不绘制独立样本——至少你的样本依赖于前一个样本。历史上，人们通过减少样本来回避这个问题，例如只保留十分之一的样本。现在我们更清楚了；我们应该保留所有的样本，并将n_eff用于类似CLT的目的。</p><p id="7d7e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是一个有用的诊断，因为如果你的n_eff比你的样本总数(减去老化/预热)低得多，那么一定是出了严重的问题(或者你需要抽取更多的样本)。</p><p id="755e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我在教科书中最喜欢的一段话来自McElreath的《统计学再思考2:</p><blockquote class="oy oz pa"><p id="053e" class="ki kj oa kk b kl km ju kn ko kp jx kq pb ks kt ku pc kw kx ky pd la lb lc ld im bi translated">当人们开始使用Stan或其他一些哈密尔顿采样器时，他们经常发现他们以前适合Metropolis的模型——黑斯廷斯和吉布斯采样器——不再有效。链条很慢。有很多警告。…这些问题可能一直存在，甚至在其他工具中也是如此。但由于吉布斯不使用梯度，它没有注意到一些问题，汉密尔顿引擎会。一种文化已经在应用统计学中发展了，只是在很长一段时间内——几百万次迭代中——运行坏链，然后积极地变薄、祈祷和发布。这必须停止。[示例[修订]—500万个样本，neff为66！]</p></blockquote><p id="9f95" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">他公开羞辱了一家报纸；那份报纸应该受到应有的羞辱。野蛮人。</p><p id="0698" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这一点可以成为使用NUTS作为默认设置的有力论据。我怀疑Gibbs可以提取合理的样本，但会卡在某个局部空间中，所以诊断是正确的，但NUTS会尝试探索其他地方并发出警告。</p><p id="f13a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有时候n_eff会比你的样本数高。那没有理由惊慌。</p><h2 id="3a62" class="nj ly it bd lz nk nl dn md nm nn dp mh kr no np mj kv nq nr ml kz ns nt mn nu bi translated">ELPD</h2><p id="db18" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">将预期对数逐点预测密度(ELPD)视为贝叶斯情况下对数似然的推广。贝叶斯模型输出概率分布，而RMSE /交叉熵等指标评估点预测的性能。ELPD评估整个预测分布。</p><p id="0cf8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">还有其他类似的指标，但是ELPD是您所需要的。AIC和BIC评估点预测。WAIC有很好的渐近性质，但对于较小的样本有不稳定的行为。他们的相似之处在于解释。ELPD本身是没有意义的，但是它可以用来比较不同的模型，就像你使用AIC一样。</p><p id="380d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因为我们关心模型的泛化能力，所以我们希望从交叉验证中获得ELPD。否则，我们会对模型性能过于乐观——在训练集上评估模型将产生乐观的低误差估计。</p><p id="c4d9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与机器学习中的传统智慧相反，对于贝叶斯模型，留一交叉验证(LOOCV)在计算上比k-fold交叉验证更有效。K-fold要求我们对模型进行k次改装，但改装模型是最昂贵的部分。我们可以在已经从后验得到的样本上使用重要性抽样来近似LOOCV，所以我们不需要重新调整模型。</p><p id="57d7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如今，人们使用帕累托平滑重要性抽样(<a class="ae nd" href="http://www.stat.columbia.edu/~gelman/research/unpublished/loo_stan.pdf" rel="noopener ugc nofollow" target="_blank"> PSIS-LOOCV </a>)。这些首字母缩略词越来越长。除了提高ELPD估计的稳定性，PSIS-LOOCV还提供了一个额外的诊断:k。该算法采用20%的最高重要性权重，并拟合一个<a class="ae nd" href="https://en.wikipedia.org/wiki/Generalized_Pareto_distribution" rel="noopener ugc nofollow" target="_blank">广义帕累托分布</a>。当k &gt;为0.5时，GPD具有无限的方差，并表明ELPD的估计可能不可信，尽管从经验测试来看，直到k &gt;为0.7时，近似值还没有那么糟糕。当k很大时，它可能表示影响很大的观察结果扰乱了模型。</p><p id="9fb4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">排名图</strong></p><p id="1323" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">追踪图的表亲。虽然迹线图对检测退化情况很有用，但很难解释。等级图更容易检查。使用之前的Metropolis代码，创建s = 0.2的四个链:</p><pre class="lf lg lh li gt oc od oe of aw og bi"><span id="b434" class="nj ly it od b gy oh oi l oj ok">library(data.table)<br/>sampled_thetas &lt;- data.table(thetas[iter &gt; 1000])<br/>sampled_thetas[,rank := frank(theta)]</span><span id="8f84" class="nj ly it od b gy ol oi l oj ok">ggplot(sampled_thetas) +<br/>  geom_histogram(aes(x = rank)) +<br/>  facet_grid(.~s)<br/>  <br/>ggplot(thetas[(iter &gt; 1000) &amp; (iter &lt; 1100)]) +<br/>  geom_step(aes(x = iter, y = rank, color = s))</span></pre><div class="lf lg lh li gt ab cb"><figure class="on lj oo op oq or os paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><img src="../Images/51464b339308ebd7287ab7659d74f368.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*QcXLf0PrHjeaEqNR0rDjaQ.jpeg"/></div></figure><figure class="on lj oo op oq or os paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><img src="../Images/31b5e58eeb83b784e071266dfdc0291f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*XTzfv5_s1dLXW8VQ4xVyqQ.jpeg"/></div></figure></div><p id="521b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这两个图应该显示一些均匀的混合。否则，一定是出了问题。</p></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h1 id="6c4e" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">五</h1><p id="0cdb" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">对于MCMC，理解算法是关键。对于VI，我认为理解目标函数比算法更重要。</p><p id="d4a4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">变分推理(VI)采用了不同于MCMC的方法，但在大多数应用中仍然使用蒙特卡罗。我们提出一个更简单易处理的分布族来逼近后验概率，而不是从后验概率中取样。然后这个问题被框定为一个优化问题。因此，VI可以扩展到大数据，而NUTS不可能处理大数据。</p><p id="13f9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然存在几个目标函数(主要替代函数是<a class="ae nd" href="https://en.wikipedia.org/wiki/R%C3%A9nyi_entropy#R%C3%A9nyi_divergence" rel="noopener ugc nofollow" target="_blank"> Renyi散度</a>，但最常用的是<a class="ae nd" href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence" rel="noopener ugc nofollow" target="_blank"> Kullback-Leibler散度</a> (KL散度)，定义为:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/cf71a27109042fc0fc56a3d0f36efc36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1350/format:webp/1*oHQzcRleKYJMwufLUoGVPQ.png"/></div></figure><p id="b5d2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">确切的后验概率通常表示为p，而我们的变分近似表示为q。理解KL散度的性质对于使用VI至关重要，我们将从两个方面开始:</p><p id="b2f2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第一，是<strong class="kk iu">不对称</strong>。KL(p||q)要求我们取期望w.r.t. p，而KL(q||p)要求我们取期望w.r.t. q。因此，它不是一个距离度量。</p><p id="ee23" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">二是<strong class="kk iu">非负。</strong>从表达式来看不是很明显，可以参考这里的<a class="ae nd" href="https://en.wikipedia.org/wiki/Gibbs%27_inequality" rel="noopener ugc nofollow" target="_blank">证明</a>。</p><p id="fa5c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">KL(p||q)被称为前向KL，它很难处理，因为我们需要对p积分(如果我们知道p，为什么我们还要这样做？).相反，VI寻求最小化KL(q||p)，即反向KL。例如，我们可能希望用正态分布来近似高度复杂的后验概率；我们寻求使反向KL最小的变分参数μ和σ。用更精确的符号表示，假设ν是变分参数，我们希望找到使以下参数最小化的ν:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/13b53ea3cfda4b224b897ebdd151eb26.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*QzLSWyLR-uHdFBUwP9Z_Xg.png"/></div></figure><p id="b302" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但是我们在分母中仍然有那个讨厌的未知后验，所以我们不能直接和KL一起工作。就像Metropolis一样，我们应用了一个技巧，这样我们就不必计算p(X):</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/c4eb3b300a486c4d040f9777e81cc23c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*OqG4eUIUFKqhIxqScWS_ow.png"/></div></figure><p id="52a4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">回想一下，p(X)是一个常数，所以我们可以把它从期望值中去掉。重新排列给了我们证据下限(ELBO)，VI的目标函数:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ph"><img src="../Images/6ee134a5291963b05721ad57d501aa9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MoG1tqgoUUfaZdZKGJKBWQ.png"/></div></div></figure><p id="d0ad" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因为KL是非负的，ELBO的最大可能值是log(p(X))，即对数证据。因此，为什么它被称为ELBO:日志证据必须至少与ELBO一样高。然而，它可以是一个非常宽松的界限，差距将因假设和模型而异。不要用ELBO来比较假设。相反，使用拟合的后验概率计算贝叶斯因子。</p><p id="4249" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">ELBO有两个重要特性:</p><p id="3c6a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，ELBO是<strong class="kk iu">熵减去交叉熵</strong>。很有意思。想一想吧。熵希望q尽可能分散，而交叉熵希望q收敛到p模式上的点质量。这与先验和最大似然估计有类似的加权平均感觉，这是贝叶斯统计的主题。</p><p id="3726" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第二，ELBO鼓励q有太低的<strong class="kk iu">方差</strong>。在p密度高的地方，相对于p密度低的区域中的x过冲，x过冲导致的%误差较小。为了解决这个问题，我们采用w.r.t. q的期望值，因此在p的低密度区域放置较小的质量将会降低这个误差的权重。</p><p id="2715" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">VI对多模态后验概率和高度相关后验概率有困难。</p><p id="5ad1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">作为一个例子，让我们在<strong class="kk iu">多模式后</strong>试验NUTS和ADVI。它通常出现在混合模型中，但我们将使用最简单的例子:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/55f075504f3a68c6b526eccb48bd8bc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:682/format:webp/1*ge16YbfcGMIfrBokxLXghA.png"/></div></figure><p id="b9f8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">标准文件:</p><pre class="lf lg lh li gt oc od oe of aw og bi"><span id="f7a8" class="nj ly it od b gy oh oi l oj ok">data {<br/>  int&lt;lower=0&gt; N;<br/>  real x[N];<br/>}<br/>parameters {<br/>  real mu;<br/>}<br/>model {<br/>  mu ~ normal(0, 1);<br/>  for (n in 1:N)<br/>    x[n] ~ normal(fabs(mu), 1);<br/>}</span></pre><p id="5c62" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">r代码:</p><pre class="lf lg lh li gt oc od oe of aw og bi"><span id="920b" class="nj ly it od b gy oh oi l oj ok">library(rstan)</span><span id="87c4" class="nj ly it od b gy ol oi l oj ok">set.seed(555)<br/>x &lt;- rnorm(100, 2, 1)<br/>data &lt;- list(x = x, N = length(x))<br/>model &lt;- stan_model(file = 'bimodal_example.stan')</span><span id="981d" class="nj ly it od b gy ol oi l oj ok">mcmc &lt;- sampling(<br/>  model, <br/>  data, <br/>  iter = 2000, <br/>  warmup = 1000, <br/>  chains = 4, <br/>  seed = 1)</span><span id="0d2d" class="nj ly it od b gy ol oi l oj ok">advi &lt;- vb(<br/>  model,<br/>  data,<br/>  output_samples = 4000,<br/>  seed = 3<br/>)</span><span id="f2e1" class="nj ly it od b gy ol oi l oj ok">mcmc_samples &lt;- sapply(<br/>  mcmc@sim$samples, <br/>  function(x) x[['mu']][1001:2000]<br/>)<br/>advi_samples &lt;- advi@sim$samples[[1]][['mu']]</span><span id="4644" class="nj ly it od b gy ol oi l oj ok">hist(mcmc_samples, breaks = 100, xlim = c(-3, 3))<br/>hist(advi_samples, breaks = 30, xlim = c(-3, 3))</span></pre><div class="lf lg lh li gt ab cb"><figure class="on lj oo op oq or os paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><img src="../Images/047bd94dc441b25c456d2c05a0a5e5e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*P3411LxbaV3LppF69lVcnQ.jpeg"/></div></figure><figure class="on lj oo op oq or os paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><img src="../Images/e59513e6f7a5a4d3287cfcd2dc9dbf1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*AZSSrAdTw9Zy1ZYRpwhBew.jpeg"/></div></figure></div><p id="a6a3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">NUTS报告的Rhat为1.53，让我们知道这个模型是错误指定的。ADVI收敛<strong class="kk iu">没有任何警告</strong>！因为拟合的变分分布在图的右边部分几乎没有质量，所以它未能覆盖的部分在ELBO中几乎没有重量。因此，它报告的方差比它应该报告的要低得多，使我们对错误的结论过于自信。</p><p id="8d5c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来，让我们比较NUTS与ADVI在<strong class="kk iu">高度相关后验概率</strong>方面的差异。</p><p id="0504" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">标准代码:</p><pre class="lf lg lh li gt oc od oe of aw og bi"><span id="2567" class="nj ly it od b gy oh oi l oj ok">data {<br/>  int&lt;lower=0&gt; N;<br/>  real y[N];<br/>  real x1[N];<br/>  real x2[N];<br/>}<br/>parameters {<br/>  real beta0;<br/>  real beta1;<br/>  real beta2;<br/>  real&lt;lower=0&gt; sigmasq;<br/>}<br/>transformed parameters {<br/>  real&lt;lower=0&gt; sigma;<br/>  sigma = sqrt(sigmasq);<br/>}<br/>model {<br/>  beta0 ~ normal(0, 1);<br/>  beta1 ~ normal(0, 1);<br/>  beta2 ~ normal(0, 1);<br/>  sigmasq ~ inv_gamma(1, 1);<br/>  for (n in 1:N)<br/>    y[n] ~ normal(beta0 + beta1 * x1[n] + beta2 * x2[n], sigma);<br/>}</span></pre><p id="41b1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">r代码:</p><pre class="lf lg lh li gt oc od oe of aw og bi"><span id="894d" class="nj ly it od b gy oh oi l oj ok">library(rstan)</span><span id="c57f" class="nj ly it od b gy ol oi l oj ok">set.seed(555)<br/>x1 &lt;- runif(100, 0, 2)<br/>x2 &lt;- x1 + rnorm(100, 0, 1)<br/>y &lt;- mapply(<br/>  function(x1, x2) rnorm(1, x1 + 2 * x2, 1),<br/>  x1,<br/>  x2<br/>)<br/>data &lt;- list(y = y, x1 = x1, x2 = x2, N = length(y))<br/>model &lt;- stan_model(file = 'correlated_example.stan')</span><span id="a74d" class="nj ly it od b gy ol oi l oj ok">mcmc &lt;- sampling(<br/>  model, <br/>  data, <br/>  iter = 2000, <br/>  warmup = 1000, <br/>  chains = 4, <br/>  seed = 1)</span><span id="826c" class="nj ly it od b gy ol oi l oj ok">advi &lt;- vb(<br/>  model,<br/>  data,<br/>  output_samples = 4000,<br/>  seed = 3<br/>)</span><span id="14a7" class="nj ly it od b gy ol oi l oj ok">nuts_beta1 &lt;- sapply(<br/>  mcmc@sim$samples, <br/>  function(x) x[['beta1']][1001:2000]<br/>)<br/>nuts_beta2 &lt;- sapply(<br/>  mcmc@sim$samples, <br/>  function(x) x[['beta2']][1001:2000]<br/>)<br/>advi_beta1 &lt;- advi@sim$samples[[1]][['beta1']]<br/>advi_beta2 &lt;- advi@sim$samples[[1]][['beta2']]</span><span id="dc53" class="nj ly it od b gy ol oi l oj ok">plot(nuts_beta1, nuts_beta2)<br/>plot(advi_beta1, advi_beta2)</span></pre><div class="lf lg lh li gt ab cb"><figure class="on lj oo op oq or os paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><img src="../Images/d407c828e3478030cf8555182d80e837.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*OT3eoFk9BZ5EHahbbBa9Jw.jpeg"/></div></figure><figure class="on lj oo op oq or os paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><img src="../Images/06f5fbdda1bccf87837a58785fd4a83f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*_icWJSKTyxWVUux4BfB7DA.jpeg"/></div></figure></div><p id="4dda" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">NUTS设法很好地获得了相关性，但是VI认为参数是不相关的！怎么回事？(平心而论，Stan警告你近似不好。)</p><p id="71f3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">默认情况下，VI通过<strong class="kk iu">平均场</strong>假设加速计算，即局部参数彼此不相关。这使得观测值可以有条件地交换，并加速梯度计算。然而，正如这个例子所展示的，结果可能是非常错误的！</p><p id="9c0c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">根据经验法则:</p><ol class=""><li id="2d70" class="mu mv it kk b kl km ko kp kr mw kv mx kz my ld ot na nb nc bi translated">如果您的数据大小合理，使用MCMC，因为它更有可能收敛到准确的后验概率。</li><li id="b703" class="mu mv it kk b kl ne ko nf kr ng kv nh kz ni ld ot na nb nc bi translated">如果你的数据对于MCMC来说太大，先试试均值场VI。</li><li id="4238" class="mu mv it kk b kl ne ko nf kr ng kv nh kz ni ld ot na nb nc bi translated">如果平均场VI失败，尝试<strong class="kk iu">满秩</strong> VI，它允许参数之间的相关性，但使计算慢得多。</li></ol><h2 id="8560" class="nj ly it bd lz nk nl dn md nm nn dp mh kr no np mj kv nq nr ml kz ns nt mn nu bi translated">坐标上升VI</h2><p id="61fc" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">CAVI是你的香草梯度上升。有人计算分析更新，我们迭代，直到ELBO收敛。这仅对于条件共轭模型是可能的。如果不可能为你的模型设置一个吉布斯采样器，那么CAVI也是不可能的。</p><p id="709e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">像<a class="ae nd" href="http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf" rel="noopener ugc nofollow" target="_blank">潜在狄利克雷分配</a>这样的简单模型仍然需要大量的数学知识。(我说简单是因为这个模型可以用五行来描述，它是有条件共轭的，并且可以计算梯度。)即使有了分析更新，CAVI的收敛速度可能会非常慢，但如果一个模型适合CAVI，那么我们就可以使用SVI。</p><h2 id="0755" class="nj ly it bd lz nk nl dn md nm nn dp mh kr no np mj kv nq nr ml kz ns nt mn nu bi translated">随机VI</h2><p id="631b" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">如果CAVI是梯度上升，那么SVI是随机梯度上升。只要我们满足<a class="ae nd" href="https://en.wikipedia.org/wiki/Stochastic_approximation" rel="noopener ugc nofollow" target="_blank">罗宾斯-门罗条件</a>，那么SVI就一定会收敛(尽管这可能需要很多很多次迭代)。步长应该下降得足够慢，以便我们完全探索参数空间，但也应该下降得足够快，以便收敛到一个点。Spark中的LDA实现默认使用SVI。</p><p id="efc0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最初，我认为SVI的表现会比CAVI差，但令人惊讶的是事实恰恰相反。这篇<a class="ae nd" href="https://papers.nips.cc/paper/3902-online-learning-for-latent-dirichlet-allocation.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>显示，使用SVI学习参数要快得多。之前的一个个人项目证实了这一点。对所有文档进行单次CAVI迭代产生的结果比只对10%的文档进行SVI迭代产生的结果更差。</p><p id="ba4b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您可以计算SVI的自然梯度，那么它应该是拟合模型的最佳算法。主要的挑战是:你必须手工计算它们。当计算自然梯度太困难甚至不可能时，使用VI的下两种风格。他们称之为“黑盒变分推断”，用蒙特卡罗方法近似梯度。Pyro中的svi函数是BBVI。</p><h2 id="a452" class="nj ly it bd lz nk nl dn md nm nn dp mh kr no np mj kv nq nr ml kz ns nt mn nu bi translated">分数梯度VI</h2><p id="40dc" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">纸<a class="ae nd" href="https://arxiv.org/pdf/1401.0118.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>。附录中的推导。我们想通过近似ELBO的梯度来进行SGD。直觉:</p><ul class=""><li id="8891" class="mu mv it kk b kl km ko kp kr mw kv mx kz my ld mz na nb nc bi translated">ELBO是积分，梯度是极限。<a class="ae nd" href="https://en.wikipedia.org/wiki/Dominated_convergence_theorem" rel="noopener ugc nofollow" target="_blank">支配收敛定理</a>的条件成立，所以我们可以交换∇和积分的顺序。</li><li id="c2e3" class="mu mv it kk b kl ne ko nf kr ng kv nh kz ni ld mz na nb nc bi translated">将乘积法则应用于被积函数。</li><li id="d869" class="mu mv it kk b kl ne ko nf kr ng kv nh kz ni ld mz na nb nc bi translated">常数的梯度为0。</li><li id="88b7" class="mu mv it kk b kl ne ko nf kr ng kv nh kz ni ld mz na nb nc bi translated"><a class="ae nd" href="https://en.wikipedia.org/wiki/Score_(statistics)" rel="noopener ugc nofollow" target="_blank">得分函数</a>的期望值为0。</li></ul><p id="13f7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">把这些按顺序应用给我们</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/3123f4c568b9cc32bf92b3b2a1d4339c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*Xw__NW5rpeBIc_fWAt8S2g.png"/></div></figure><p id="ff16" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以通过从当前q中取样并评估被积函数中的每一项来对这一期望进行蒙特卡罗近似。</p><p id="82a2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">实际上，分数梯度的方差太高，使其不实用。需要额外的专业知识来控制偏差。否则，BBVI将不会在任何合理的时间内收敛，因为我们踏遍了所有的地方。</p><h2 id="f383" class="nj ly it bd lz nk nl dn md nm nn dp mh kr no np mj kv nq nr ml kz ns nt mn nu bi translated">重新参数化梯度VI</h2><p id="547e" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">纸<a class="ae nd" href="https://arxiv.org/pdf/1603.00788.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>。这是在大多数概率编程包中默认实现的VI版本。我建议阅读原文，因为它写得非常清楚。</p><p id="2b00" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">基本思想是我们知道如何在多元正态分布上做VI，那么为什么不把所有的VI问题转化成我们已经知道如何解决的问题呢？我们模型中的所有参数都是经过变换的MVN。我们可以对这些转换函数应用链式法则(重新参数化)，并使用自动微分来计算梯度。</p><p id="8cd9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">实际上，后验分布对重新参数化很敏感。还不清楚什么函数能产生最好的近似值。同样，VI的良好运行需要专业知识。自动寻找最佳重新参数化的算法是我最想做的事情，我会留意的。</p></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h2 id="c81e" class="nj ly it bd lz nk nl dn md nm nn dp mh kr no np mj kv nq nr ml kz ns nt mn nu bi translated">诊断学</h2><p id="1616" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated"><strong class="kk iu"> ELBO跟踪图</strong></p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/8a2d8b92acae9d242cd7a54d29d507c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*aNpBDbRVORPw4RM5W2Wbxw.png"/></div><p class="nw nx gj gh gi ny nz bd b be z dk translated"><a class="ae nd" href="https://arxiv.org/pdf/1603.00788.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="27c1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">就像SGD算法一样，我们可以检查目标函数是否已经收敛。在现实中，很难知道什么时候停止。一旦逃离局部最优，ELBO可以跳转，但我们无法判断它是否停留在局部最优。虽然轨迹图很好，但真正的诊断是…</p><p id="f194" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">重要性抽样</strong></p><p id="1083" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是Stan在ADVI收敛到不适合时用来警告用户的诊断。假设我们想计算E[θ] w.r.t .的后验概率，但是我们不能这样做，因为我们不知道后验概率。一个巧妙的技巧是</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/0c390e489299e00456c74026bb30a9cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*BdSCK5UAqCMKSOGatTKxeg.png"/></div></figure><p id="20bc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，即使我们不能从p中取样，我们也可以通过从一个方便的q中取样来进行蒙特卡罗近似。我们通过取这个加权平均值来近似期望</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/dab79aa3b2c9aaac9a73f6dde8350672.png" data-original-src="https://miro.medium.com/v2/resize:fit:530/format:webp/1*x8MzYncQ_3itqez2_QsUMA.png"/></div></figure><p id="701b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中w_i是重要性权重，定义如下</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/62b01465686642f629b443ba154ddc34.png" data-original-src="https://miro.medium.com/v2/resize:fit:630/format:webp/1*NXFYhtcMSfQ4zh4oQSp7Hw.png"/></div></figure><p id="75d5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">就像Metropolis算法一样，我们永远不需要计算p(X ),因为它在取加权平均值时会抵消掉(见模式？).幸运的是，我们已经有了一个方便的q样本:我们拟合的变分分布。众所周知，如果p和q没有太多重叠，则重要性权重可以具有无限方差。</p><p id="31c1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">斯坦将<a class="ae nd" href="https://en.wikipedia.org/wiki/Generalized_Pareto_distribution" rel="noopener ugc nofollow" target="_blank">广义帕累托分布</a>拟合到20%的最高重要性权重。如果k &gt;为0.5，GPD具有无限的方差，尽管实际上，根据经验，在k &gt;为0.7之前，拟合相对较好。当k &gt; 0.7时Stan警告用户。这应该是您评估VI适合性的主要诊断。</p><h1 id="9af5" class="lx ly it bd lz ma po mc md me pp mg mh jz pq ka mj kc pr kd ml kf ps kg mn mo bi translated">最后</h1><p id="b015" class="pw-post-body-paragraph ki kj it kk b kl mp ju kn ko mq jx kq kr mr kt ku kv ms kx ky kz mt lb lc ld im bi translated">希望本文为使用和诊断贝叶斯推理算法提供了很好的信息。一如既往，如果你看到任何错误或有任何建议，请让我知道，以便我可以修改文章。</p></div></div>    
</body>
</html>