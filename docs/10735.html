<html>
<head>
<title>Are the clusters good?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">集群好吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/are-the-clusters-good-1567de6a9524?source=collection_archive---------25-----------------------#2020-07-27">https://towardsdatascience.com/are-the-clusters-good-1567de6a9524?source=collection_archive---------25-----------------------#2020-07-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="81b2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">了解如何评估集群</p><p id="632b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">聚类</strong>定义为在数据中寻找自然群体。但是这个定义本身就是主观的。</p><p id="df87" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">什么是自然群体？</strong></p><p id="97e7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果我们看到下面的图片，我们能找出这些花的自然组合吗？是根据形状还是根据颜色？它甚至可能是由花的大小或种类决定的。因此，<em class="kl">自然群体的概念根据我们关注的特征而变化。</em></p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/00db8666a60023d8e2965ff70464241a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*RD7aNXa6Ns22BQEi"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">图 1:鲜花(资料来源:Unsplash)</p></figure><p id="c065" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们再举一个例子，我们在 2D 平面上有一些点或观察值，也就是说，我们只有两个属性</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi lc"><img src="../Images/a7b7c34f6df0cc7ed5225b44c3328cb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EAzGw1YsuVWXian-xeTWCA.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">图 2:原始数据和不同聚类数的聚类(图片来源:作者)</p></figure><p id="a766" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果我们看上面的图，它有三个子图。第一个子图显示了原始数据，第二和第三个子图显示了聚类，聚类数分别为两个和四个(属于同一聚类的观察值用相同的颜色标记)。</p><p id="d34b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">幸运的是，我们仍然可以可视化并尝试衡量集群的质量，但是，如果我们追求更多的数字特征，我们就无法可视化和看到。因此，需要有一种机制，一些措施，可以让我们比较两组或更多组的聚类，或者可能是对同一组数据的两种或更多种聚类算法。<em class="kl">不幸的是，就像我们可以使用精确度比较分类算法一样，或者在使用均方误差进行回归的情况下，聚类就不是那么明确了。</em></p><p id="95d5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">聚类趋势:</strong></p><p id="8a38" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果数据没有任何聚类趋势，即使数据是随机的，我们应用 k-means，算法也会生成 k-clusters。因此，我们如何衡量数据是否有聚集趋势？为了测量这一点，我们借助霍普金斯的统计数据。</p><p id="ee68" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">霍普金斯统计(H) </strong></p><p id="5657" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这种方案中，添加的人工生成的随机点与数据集中的原始数据点一样多。对于每个原始点，计算与其最近邻居的距离，用<strong class="jp ir"> w </strong>表示，并且对人工生成的点重复相同的练习。这里，与最近邻居的距离计算为<strong class="jp ir"> u. </strong></p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ld"><img src="../Images/8f8f8de9fa5b21cc151f10403e9f1b85.png" data-original-src="https://miro.medium.com/v2/resize:fit:622/format:webp/1*BILXWkCY9FRsIwhE2DpV1w.png"/></div></figure><p id="34b3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接近 0.5 的值表示数据没有聚集趋势，因为 w 和 p 相等。</p><p id="4318" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">聚类评估方法:</strong></p><p id="bfb2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">误差平方和(SSE):- </strong></p><p id="5bf6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最常用的聚类评估工具是误差平方和，由以下等式给出。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi le"><img src="../Images/f9844c4d520a49739553536a6968bcdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*0Mw97hmpN87OiojvBa7P-w.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">SSE 方程(图片来源:作者)</p></figure><p id="fac9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">基本上，在第一步中，我们通过取该聚类中所有观察值的平均值来找到每个聚类的质心。</p><ul class=""><li id="edbd" class="lf lg iq jp b jq jr ju jv jy lh kc li kg lj kk lk ll lm ln bi translated">然后我们找出该簇中的点偏离中心的程度并求和。</li><li id="2410" class="lf lg iq jp b jq lo ju lp jy lq kc lr kg ls kk lk ll lm ln bi translated">然后，我们将单个集群的偏差或误差相加。</li><li id="8870" class="lf lg iq jp b jq lo ju lp jy lq kc lr kg ls kk lk ll lm ln bi translated">SSE 要尽可能低。</li></ul><p id="91bc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我总是通过例子更好地理解直觉，让我们就这么做吧</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi lt"><img src="../Images/35ccf62285527b0147306de4e12890dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IkpzRoMNLSb810oSFVKc4A.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">图 3:上海证券交易所示意图。(图片来源:作者)</p></figure><p id="5f43" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我认为上面的例子不言自明。(1，3)和(8，10)是自然的集群组织，集群数量为 2。上证 4。在另一个设置中，我们在同一个群集中保留了 1、3、8 个，在另一个群集中保留了 10 个，而 SSE 已飙升至 26 个。</p><p id="6cee" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">SSE 被广泛用于寻找聚类的数目(K ),尤其是 K-均值。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/e4b711c0f00a296e568a43cb76c3674d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*K0m_vIEchmhKi2ZErhDtWw.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">图 iris 数据集上不同聚类数的 SSE(图片来源:作者)</p></figure><p id="abf7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这里，我们也比较了不同集群数选项的集群质量。这是一个单调递减的函数，如果我们继续增加聚类数，它将继续减少。因此，当插入 SSE 稳定或形成肘形时，采用最佳的集群数量。如果我们试图寻找球状星团，SSE 是一个很好的测量方法。</p><p id="37c9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们从一个更广义的角度来看，我们想要的一组结构良好的集群如下</p><ul class=""><li id="a65b" class="lf lg iq jp b jq jr ju jv jy lh kc li kg lj kk lk ll lm ln bi translated">一个集群内的观测值要尽可能接近。这被称为<strong class="jp ir">内聚力</strong></li><li id="cf16" class="lf lg iq jp b jq lo ju lp jy lq kc lr kg ls kk lk ll lm ln bi translated">两个星团的观测值应该相距很远。这被称为<strong class="jp ir">分离</strong></li></ul><p id="ba9a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用下图进行说明</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/61397c9df90629e27d154ce24169b917.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*4kfSWZ6iOTuXl8Jgu_OxTg.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">图 5:凝聚与分离(图片来源:作者)</p></figure><p id="ed73" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">评估措施可分为两种方式</p><p id="722a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">内测:</strong></p><p id="88e3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当类别标签不可用时，这是一个更通用的方法。<strong class="jp ir">轮廓系数</strong>就是这样一种流行的测量方法。这使用了内聚和分离的概念。让我们从簇 j 中取一个点 I，首先，我们计算点 I 到 j 中所有点的距离，并求平均值我们称之为 ai(内聚力)。现在，让我们取另一个簇 k，类似地，我们从簇 k 中的所有点中找到点 I 的平均距离，让我们称之为 b(分离)。可以有许多这样的群，它们中的最小值被认为是 bi。</p><p id="dc10" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">那么点 I 的轮廓系数为</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/25aeb6061a17bc0e5929b3436aec95fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/format:webp/1*Woah14jUfW5ySvarH6v3TA.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">轮廓系数(图片来源:作者)</p></figure><p id="542d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于聚类，需要计算聚类中所有点的轮廓系数，并取平均值。该值介于-1 和 1 之间，值越高，分类越好。下图是一个算出的例子</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/8f9baa5ff51b2f19f78a820b7886a75b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1310/format:webp/1*bGTUDid0hp1QstImj_PtRA.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">图 6:剪影系数(图片来源:作者)</p></figure><p id="10bd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">1，3，5，8，9，10 作为初始点集。假设 1，3，5 是第一个聚类，8，9，10 是第二个聚类。</p><p id="2b1b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以对于点 1，a1 是(2+ 4)/2 = 3，b 是(7+8+9)/3 =7 然后我们用公式。我们可以观察</p><ul class=""><li id="187d" class="lf lg iq jp b jq jr ju jv jy lh kc li kg lj kk lk ll lm ln bi translated">第二类具有更好的轮廓系数，因为它更紧凑</li><li id="c208" class="lf lg iq jp b jq lo ju lp jy lq kc lr kg ls kk lk ll lm ln bi translated">与其他点相比，中心点具有更好的轮廓系数</li><li id="52b7" class="lf lg iq jp b jq lo ju lp jy lq kc lr kg ls kk lk ll lm ln bi translated">边界点具有最低的轮廓系数</li></ul><p id="f6ad" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其他一些常用的指标有<strong class="jp ir">邓恩指数和 DB 指数</strong>。</p><p id="ef92" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">外部测量:</strong></p><p id="7697" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们有一个可用的类标签，我们使用这个类标签来评估聚类结果。理想情况下，每个类都应该形成一个集群。一种这样的度量被称为纯度，由下面的公式给出。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/0a98cace39e8f8a2703b64afe152b212.png" data-original-src="https://miro.medium.com/v2/resize:fit:516/format:webp/1*TapxZ62A9s-obzEOirI9yg.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">纯度方程式(图片来源:作者)</p></figure><p id="9eb3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">k 是聚类的数量，mi 是聚类中的观测值的总数，m 是观测值的总数。Pi 是该群集中多数类的比例。例如，如果聚类 I 具有来自类 1 的 5 个观察值和来自类 2 的 20 个观察值。那么类别 2 是多数类别，纯度是 20/25 或 0.8。下面的例子进一步说明了这一点</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/719b1cef9743915c84e67b4c7fede9ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1358/format:webp/1*SqnG9GWOCYeaQU-TRhtHjA.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">图 7:纯度说明(来源:作者)</p></figure><p id="ce85" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在上图中，显示了聚类结果的三个变量，这些计算是不言自明的。对于选项 1 和选项 2，两个集群大小相等。第二种选择更均匀，因此纯度更高。对于选项 3，集群 2 支配集群 1。</p><p id="9517" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">纯度有 0 和 1 两个数值，越接近 1，纯度越好。</strong>还有更多像熵、F 值等度量。关于细节，我强烈推荐你阅读庞、斯坦巴克、库马尔的书。为什么我们要使用聚类，当我们有标签可用时，也许要提出一个新的聚类算法，测试不同的配置和假设。需要注意的是，当然，聚类是在去除类别标签之后对数据进行的，然后标签用于验证聚类质量。</p><p id="fe11" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们不讨论层次聚类的评估，这是另一回事。</p><p id="5fbd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">结论:</strong></p><ul class=""><li id="5a33" class="lf lg iq jp b jq jr ju jv jy lh kc li kg lj kk lk ll lm ln bi translated">聚类本质上是一项复杂的任务，因此需要评估聚类的质量。</li><li id="147f" class="lf lg iq jp b jq lo ju lp jy lq kc lr kg ls kk lk ll lm ln bi translated">这有助于比较多个聚类算法，以及使用不同参数值的同一聚类算法的不同结果</li><li id="3ce0" class="lf lg iq jp b jq lo ju lp jy lq kc lr kg ls kk lk ll lm ln bi translated">首先，我们可以测试是否存在聚集趋势</li><li id="2e37" class="lf lg iq jp b jq lo ju lp jy lq kc lr kg ls kk lk ll lm ln bi translated">群集质量度量应该考虑内聚性和分离性</li><li id="6b39" class="lf lg iq jp b jq lo ju lp jy lq kc lr kg ls kk lk ll lm ln bi translated">根据类别标签的可用性，它可以是内部的和外部的</li></ul><p id="67bf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">参考文献</strong>:</p><p id="b6de" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[1] Tan PN，Steinbach M，Kumar V .数据挖掘导论。培生教育印度公司；2016.</p><p id="6d50" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[2]贾恩 AK。数据聚类:超越 K 均值的 50 年。模式识别字母。2010 年 6 月 1 日；31(8):651–66.</p><p id="3869" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae ma" href="https://youtu.be/_KKT55JohcU" rel="noopener ugc nofollow" target="_blank">https://youtu.be/_KKT55JohcU</a></p><p id="4a66" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[4]<a class="ae ma" rel="noopener" target="_blank" href="/clustering-evaluation-strategies-98a4006fcfc">https://towards data science . com/clustering-evaluation-strategies-98a 4006 fcfc</a></p></div></div>    
</body>
</html>