<html>
<head>
<title>Improving the Performance of a Machine Learning Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">提高机器学习模型的性能</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/improving-the-performance-of-a-machine-learning-model-5637c12fc41c?source=collection_archive---------60-----------------------#2020-09-08">https://towardsdatascience.com/improving-the-performance-of-a-machine-learning-model-5637c12fc41c?source=collection_archive---------60-----------------------#2020-09-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="535d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">模拟性能的不同方法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/2f9d96320b3bff91a0a0e800a73a5cb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*F4xAxTboSb7g5h74.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">克里斯·利维拉尼在<a class="ae ky" href="https://unsplash.com/s/photos/customer?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="1b0b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在<a class="ae ky" rel="noopener" target="_blank" href="/a-practical-machine-learning-guide-fa2111c65f42">之前的帖子</a>中，我们探索并分析了一个客户流失数据集。然后，我们建立了一个机器学习模型来预测客户流失，在训练集和测试集上的准确率分别达到了%91.7 和%90.7。</p><p id="df8a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本帖中，我们将致力于:</p><ul class=""><li id="0d64" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">如何提高准确率(正负类都有)</li><li id="8851" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">如何将模型的焦点更多地向正面类倾斜</li></ul><p id="8a81" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">值得注意的是，提高模型性能的最佳方法通常是收集更多的数据。然而，这并不总是一个可行的选择。</p><p id="ec72" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们回到我们的话题。</p><p id="cb71" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们构建的模型是一个带有超参数的随机森林分类器:</p><ul class=""><li id="3740" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">max_depth = 10(森林中一棵树的最大深度)</li><li id="44a5" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">n_estimators = 200(森林中的树木数量)</li></ul><p id="9c14" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该模型的性能如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/75afa34a6c2ec066f5e201b81c92af9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/0*lh3fYQ6zxBAcnDX-.png"/></div></figure><p id="7563" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第一和第二矩阵分别是训练集和测试集上的混淆矩阵。混淆矩阵通过显示每个类别的正确和不正确(即真或假)预测，比分类准确性更深入。</p><p id="6d54" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们首先关注准确性，然后深入研究混淆矩阵和相关指标。</p><p id="8051" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">提高模型性能的一种方法是搜索最佳超参数。调整超参数就像调整模型一样。<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" rel="noopener ugc nofollow" target="_blank">随机森林</a>有许多超参数，但最重要的是树的数量(n_estimators)和单棵树的最大深度(max_depth)。</p><p id="4b62" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用 scikit-learn 的<strong class="lb iu"> GridSearchCV </strong>类。它允许从一系列值中选择最佳参数。让我们首先创建一个字典，其中包含一组 n_estimators 和 max_depth 的值。我将选择我们之前使用的值。</p><pre class="kj kk kl km gt mk ml mm mn aw mo bi"><span id="8569" class="mp mq it ml b gy mr ms l mt mu">parameters = {'max_depth':[8,10,12,14], <br/>              'n_estimators':[175,200,225,250]}</span></pre><p id="e99e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">可以尝试更多的值或者超参数。没有一个正确的答案。我们现在可以将这个字典和一个估计器一起传递给 GridSearchCV 对象。</p><pre class="kj kk kl km gt mk ml mm mn aw mo bi"><span id="5d76" class="mp mq it ml b gy mr ms l mt mu">rf = RandomForestClassifier()</span><span id="4861" class="mp mq it ml b gy mv ms l mt mu">gridsearch = GridSearchCV(rf, param_grid=parameters, cv=5)</span><span id="2ab8" class="mp mq it ml b gy mv ms l mt mu">gridsearch.fit(X_train_selected, y_train)</span></pre><p id="07be" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> cv </strong>参数正在进行交叉验证。</p><p id="56e9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们已经训练了 GridSearchCV 对象。让我们看看最佳参数是什么:</p><pre class="kj kk kl km gt mk ml mm mn aw mo bi"><span id="7677" class="mp mq it ml b gy mr ms l mt mu">gridsearch.best_params_<br/>{'max_depth': 12, 'n_estimators': 225}</span></pre><p id="f765" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我用大约 12 和 225 的值再次运行了 GridSearchCV。最好的参数是 13 和 235。</p><p id="718a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看这些新的超参数值的混淆矩阵和准确性。</p><pre class="kj kk kl km gt mk ml mm mn aw mo bi"><span id="8443" class="mp mq it ml b gy mr ms l mt mu">rf = RandomForestClassifier(max_depth=13, n_estimators=235)<br/>rf.fit(X_train_selected, y_train)</span><span id="dd14" class="mp mq it ml b gy mv ms l mt mu">y_pred = rf.predict(X_train_selected)<br/>cm_train = confusion_matrix(y_train, y_pred)<br/>print(cm_train)</span><span id="d409" class="mp mq it ml b gy mv ms l mt mu">y_test_pred = rf.predict(X_test_selected)<br/>cm_test = confusion_matrix(y_test, y_test_pred)<br/>print(cm_test)</span><span id="9daf" class="mp mq it ml b gy mv ms l mt mu">train_acc = (cm_train[0][0] + cm_train[1][1]) / cm_train.sum()<br/>test_acc = (cm_test[0][0] + cm_test[1][1]) / cm_test.sum()</span><span id="3b79" class="mp mq it ml b gy mv ms l mt mu">print(f'Train accuracy is {train_acc}. Test accuracy is {test_acc}')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/7151242c1e1c2ddf075f7f16b780c769.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*qVxnJvO2C-S4E6DkLHs6nw.png"/></div></figure><p id="21af" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">训练集的准确率提高了，但我们在测试集上没有取得任何成绩。如果我们可以收集更多的数据，这通常是提高准确性的最佳方式，测试准确性也可能随着这些新参数而提高。</p><p id="675a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你还记得<a class="ae ky" rel="noopener" target="_blank" href="/a-practical-machine-learning-guide-fa2111c65f42">之前的帖子</a>，我们已经删除了 4 个与其他相比信息量较少的特性。在某些情况下，消除信息量较少或不相关的要素是一种很好的做法，这样可以避免给模型带来不必要的计算负担。然而，这些被消除的特征可能会稍微提高精度，所以这归结为性能增强和计算负担之间的决定。</p><p id="78ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我摆弄了一下超参数值，并用所有的特性进行了训练。结果如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/e4c4f19716a541ba00187e105201b797.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*ePT3f36FNEq7pTEqngn-DA.png"/></div></figure><p id="f759" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们已经实现了大约%1 的测试精度增加，这也是在过度拟合方面的改进。</p></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><p id="1bb6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的任务是预测客户是否会流失(即不再是客户)。因此，重点应该放在积极的一类(1)上。我们必须正确预测所有的正类(Exited=1)。对于负类(Exited = 0)，我们可以承受一些错误的预测。</p><p id="fad1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们需要进一步提高精确度。先说混淆矩阵。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/816c4cf1e23f0cd29ad46d1ffa4b12ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/0*1GupLJ1one5d-2f5.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><ul class=""><li id="c2fe" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu">真阳性(TP) </strong>:预测阳性类别为阳性(ok)</li><li id="85bd" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">假阳性(FP) </strong>:将阴性类别预测为阳性(不正常)</li><li id="20de" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">假阴性(FN) </strong>:将阳性类别预测为阴性(不正常)</li><li id="ca77" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">真阴性(TN) </strong>:预测阴性类为阴性(ok)</li></ul><p id="9970" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为我们希望尽可能预测客户流失，所以我们的目标是最大化 TP，最小化 FN。</p><p id="6101" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我们预测“客户不会流失(0)”但在实际情况下，客户会流失时，就会发生 FN。</p><p id="82d9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">是时候引入两个指标了，即<strong class="lb iu">精度</strong>和<strong class="lb iu">召回</strong>。</p><blockquote class="ng nh ni"><p id="89e2" class="kz la nj lb b lc ld ju le lf lg jx lh nk lj lk ll nl ln lo lp nm lr ls lt lu im bi translated"><strong class="lb iu"> Precision </strong>衡量当预测为正时，我们的模型有多好。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/b6c273c3a7229b9ad583d0a54870a1cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:536/format:webp/0*xlzQqzr6pFykaKo4.png"/></div></figure><p id="5f73" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">精度的焦点是<strong class="lb iu">正面预测</strong>。它表明有多少积极的预测是正确的。</p><blockquote class="ng nh ni"><p id="5e57" class="kz la nj lb b lc ld ju le lf lg jx lh nk lj lk ll nl ln lo lp nm lr ls lt lu im bi translated"><strong class="lb iu">回忆</strong>测量我们的模型在正确预测正类方面有多好。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi no"><img src="../Images/1f770dc113dc8f9f0f9ddce5c1095e92.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/format:webp/0*5FYdNn4Rd5Irpte2.png"/></div></figure><p id="3ef3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">召回的重点是<strong class="lb iu">实际正班</strong>。它表示模型能够正确预测的阳性类别的数量。</p><p id="d854" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们希望预测所有积极的类，因此 recall 是我们任务的合适度量。最大化 TP 和/或最小化 FN 将增加召回值。</p></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><p id="6ef9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是训练集和测试集的混淆矩阵:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/1bb45a411c825bf18c05ce867df2f57f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*BiwHvgH_8Y9zBzs7Js4jwg.png"/></div></figure><p id="9ca9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们需要最小化标有黄色的值，这些值是假阴性(FN)。</p><p id="a0ff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">实现这一点的一个方法是告诉模型“正类(1)比负类(0)更重要”。使用我们的随机森林分类器，可以通过<strong class="lb iu"> class_weight </strong>参数来实现。</p><pre class="kj kk kl km gt mk ml mm mn aw mo bi"><span id="2d63" class="mp mq it ml b gy mr ms l mt mu">rf = RandomForestClassifier(max_depth=12, n_estimators=245,<br/>                            class_weight={0:1, 1:3})</span><span id="7ed5" class="mp mq it ml b gy mv ms l mt mu">rf.fit(X_train_transformed, y_train)</span></pre><p id="bad7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们传递了一个包含每个类的权重的字典。我设定为 3 比 1 作为例子。</p><p id="714a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是新的混淆矩阵:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/80ac398edf0dcbfea9df41eed677027e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*nUNy133ginTWBmnalL4fmw.png"/></div></figure><p id="b280" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">假阳性的数量大大减少。积极类上的错误预测比消极类上的错误预测受到更多惩罚。因此，该模型倾向于在尽可能低的正类上犯错误。</p><p id="9444" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种方法有一个缺点。虽然在预测正类方面越来越好，但整体准确性可能会变得更差。让我们检查一下。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/2057ef1e05e3bea70f1504e53b65dfe6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*ylsPDhZ20KUQaireYYuqMw.png"/></div></figure><p id="8f9d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">测试集的准确率从%91.21 下降到%89.57。因此，这归结为一个商业决策。如果我们只想预测所有的正类，不关心整体的准确率，可以进一步增加正类的权重。</p><p id="2727" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，当我们将权重指定为 10 比 1 时，这是混淆矩阵和准确度:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/4a44f077a753497097c52efeda9fe663.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*bypVul-C9G2RsE5A_T9C9A.png"/></div></figure></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><p id="990e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还可以尝试不同的算法，看看性能是否会变得更好。然而，更复杂的模型需要更多的数据。他们渴望数据。梯度增强决策树(GBDT)及其变体(如 XGBOOST、LightGBM)也可以尝试，但我认为性能只会略有提高。</p><p id="7576" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当考虑到任务的复杂性和数据量时，我认为随机森林会做得很好。</p><p id="9955" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢您的阅读。如果您有任何反馈，请告诉我。</p></div></div>    
</body>
</html>