# Python 中 A/B 测试的简单指南

> 原文：<https://towardsdatascience.com/a-simple-guide-to-a-b-testing-in-python-5235289dae57?source=collection_archive---------31----------------------->

## 可视化和模拟数据

![](img/f59972111b13f5b5b6d842cc3ff106f8.png)

***桌子上的两个苹果*** 由保罗·塞尚、[公有领域](https://commons.wikimedia.org/wiki/File:Two_Apples_on_a_Table_by_Paul_C%C3%A9zanne,_Speed_Art_Museum.jpg)

A/B 测试是一项至关重要的数据科学技能。它通常用于测试*网站 A 与网站 B* 或*药物 A 与药物 B、*的有效性，或者具有相同主要动机的一个想法的任何两个变体，无论是销售、药物疗效还是客户保留。这是容易产生额外混乱的统计概念之一，因为假设检验本身就需要理解正态分布、z 值、p 值和零假设的仔细构建。对于 A/B 测试，我们有**两个样本**要处理。然而，A/B 测试本质上仍然只是假设测试！本指南将是简单的单样本假设检验到双样本假设检验或 A/B 检验的基本演练。

# 简单的单样本假设检验

让我们考虑苹果农民的领域和苹果大小。我们知道，在历史上，一组特定果园中的红苹果平均宽度为 3.5 英寸，标准偏差为 0.2 英寸。因此:

![](img/556dbda6d1d5a7ac7fe3f7796acc0483.png)

总体均值和标准差

但是农民麦金托什声称他的果园里有一种特殊的新型红苹果，比其他农民的苹果格外美味，而且个头也更大。分别构建零假设和替代假设，或𝐻0 和 H1:

![](img/08202221fe5a68deca0e34c955d9f50c.png)

显著性水平为 5%

α选择 5%的显著性水平，这是单样本假设检验的标准显著性水平，也是统计学家和研究人员之间有点随意的约定。假设我们从农民麦金托什的果园里取了 40 个苹果样本，每个苹果平均 4 英寸，样本标准偏差为 0.5:

![](img/d0094ce468c72f6013488adb23c17fe8.png)

我们现在有了进行测试所需的一切。为了刷新任何假设检验背后的逻辑，看一下下面获得检验统计量的等式:

![](img/74200672e722c91bec100d8fe394fb36.png)

这个想法是我们取 x-bar，这是我们的样本均值，找到它与**总体的差异意味着样本可能来自**。在这种情况下，是 3.5，然后除以标准误差，得到我们的测试统计量:

![](img/c3c87ec3f09335fbd45add1ed7d0eac9.png)

提醒一下,**测试统计是一个指标，表明假设零假设为真，我们有多大可能完全随机获得这个样本。**[标准正态表](https://en.wikipedia.org/wiki/Standard_normal_table)，或者 z-score 表，可以用来求正态曲线下对应的面积，就是偶然得到那个结果的概率。在 Python 中，`scipy.stats`是一组非常有用的内置函数，用于此目的，`scipy.stats.norm.cdf`和`scipy.stats.norm.sf`分别给出了测试统计数据在正态分布下的面积。在这种情况下，6.32 是一个非常高的检验统计量，相当于偶然获得这些苹果大小的概率极低:

![](img/fb4e669e22a4805b6e9b1da6c68e40de.png)

因为我们的 alpha 被设置为 0.05，所以我们可以使用`st.norm.isf(.05)`来确定*临界值*，如果我们的测试统计超过了这个临界值，我们就可以拒绝零假设。在这种情况下，临界值计算为`1.64`，这是一个常见且可识别的数字，因为在正态假设下，它总是α为 0.05 的临界值。我们的测试统计值是 6.32，这远远超过了临界值，所以我们可以安全地拒绝零假设，并说农民麦金托什肯定生产大于平均水平的苹果。

# 用模拟数据进行 A/B 测试

现在我们已经完成了单样本假设检验的过程，让我们看一些模拟数据来感受一下双样本检验，记住 A/B 检验在一天结束时仍然是检验一个零假设和一个替代假设。Jupyter 笔记本和数据可以在我的 Github 上[找到，我鼓励您亲自实际运行一些函数，以便获得数据的实际感受，即使您只是改变随机种子来见证采样是如何变化的。](https://github.com/bphall/ab_vis)

这是一千个随机生成的正态分布的点，使用`sklearn.datasets.make_gaussian_quantiles.`创建，我们称之为我们的总体:

```
pop, ignore_classes = make_gaussian_quantiles(n_samples=1000, n_features = 2, cov=1, n_classes=1, random_state=0)plt.figure(figsize=(15,10))
plt.scatter(pop[:,0], pop[:,1], s=5, color='cornflowerblue')
plt.show()
```

![](img/46922026fe42c4ac3e1c818b0e46f545.png)

为了简单起见，让我们将测试的范围限制在 x 轴上。这意味着这些可视化可以在一个数字线上，但是二维可以让我们更容易地可视化随机样本的分布。

现在让我们从这个群体中随机抽取两个 30 人的样本:

```
rand1 = np.random.choice(range(1000), 30, replace=False)
rand2 = np.random.choice(range(1000), 30, replace=False)sample1_x = pop[:,0][rand1]
sample2_x = pop[:,0][rand2]
```

![](img/336652fd699a4557aa6a8e5ba1091c50.png)

我们的第一个样本平均值(红色)是-.23，样本标准偏差是 0 . 93，第二个样本平均值(绿色)是-.13，样本标准偏差是 0 . 99。因为我们知道真实的总体均值和标准差(因为最初的一千个点是从正态分布生成的)是 *μ* =0 和 *σ* =1.0，所以我们可以有把握地说这些样本很好地代表了总体。但是他们的代表性如何呢？看起来两种手段都有点低于真品。在这一点上，我们会产生怀疑，说**也许这些样本完全来自不同的人群？**这个问题就是 A/B 测试试图回答的。

就像单样本假设检验一样，我们有一个两个样本的检验统计公式。尽管它看起来要复杂得多，但它仍然只是零假设和替代假设之间的差异除以标准误差:

![](img/f32f5b49627b83bac923c1b89dc28017.png)

两个样本的检验统计公式

本质上，即使我们处理两个样本，我们仍然假设**两个样本都来自正态分布，因此在两个样本测试的零假设下，我们假设样本均值之间的差异为零。这有效地将两个样本的检验简化为一个单一样本的假设检验。挑选显著性水平(alpha)和寻找临界值的过程几乎是相同的。**

以下代码片段演示了一个用于 A/B 测试的 Python 函数，其中包含一个用于设置不同 alphas 的选项:

```
def ab_test(sample_A, sample_B, alpha=.05):
    mean_A = np.mean(sample_A)
    mean_B = np.mean(sample_B)

    std_A = np.std(sample_A)
    std_B = np.std(sample_B)

    standard_error = np.sqrt((std_A**2)/len(sample_A) +      (std_B**2)/len(sample_B))
    difference = mean_A - mean_B

    test_statistic = difference/standard_error

    crit = st.norm.ppf(p_value/2)*-1
    reject_status = 'Reject Null Hypothesis' if crit < test_statistic else 'Fail to Reject Null Hypothesis'

    return 'Test Statistic: ', test_statistic, 'Critical Value: ', crit, reject_status
```

让我们看看，我们获得这些样本平均值(我们知道它们的差值应该为零)的可能性有多大，这完全是因为偶然:

![](img/90a031625bd972229898518d4e4fc0c5.png)

我们对这两个样本的检验统计量非常接近于零，这是应该的，所以显然我们拒绝零假设，因为这两个样本的均值都应该是零。

然而，让我们不断地创建随机样本，直到我们通过将α设置为. 0001 而获得两个*非常不可能*的样本，这将允许我们拒绝零假设:

![](img/34266346f11de8929ff0bd8585f8719f.png)

需要 26，193 次随机抽样才能产生足够的样本均值来拒绝零假设！由于仅有一对随机样本的纯粹偶然性，这种情况发生的可能性是 0.002%。让我们想象一下这些例子:

![](img/9ebfa2c1fa87f8567ff7c51fe6d7ef0e.png)

我们可以看到大部分红点在零的右边，大部分绿点在左边，然而我们获得这两个样本纯属偶然(经过 26193 个做作样本)！

这里的要点是，对于真实数据，我们不知道两个样本是否来自不同的人群，我们必须依靠 A/B 测试来告诉我们样本是否真的足够不同，从而可以自信地对他们的人群做出断言。

对于测试不同网站版本或药物功效的公司来说，这是至关重要的信息，并且具有更高的显著性水平，如. 05，实际上**获得允许我们基于纯粹的机会错误地拒绝零假设的样本是相对常见的(也称为 I 型错误)。**因此，通常会引入修正，如 [Bonferroni 的修正](https://en.wikipedia.org/wiki/Bonferroni_correction)，以减少因参数空间增加而产生的误差，这被称为[多重比较问题](https://en.wikipedia.org/wiki/Multiple_comparisons_problem)或[别处查看效应](https://en.wikipedia.org/wiki/Look-elsewhere_effect)。

和往常一样，在对数据做出强有力的声明之前，了解数据的里里外外是很重要的，即使在运用统计测试和执行 A/B 测试时也是如此，因为虚假但明显的统计显著性在许多领域都很普遍，并且很容易获得看似不可能的样本数据，即使在上面的例子中花费了人为的努力(即使将这个 Jupyter 笔记本中的随机种子改为 42，由于“运气”，我们也可以获得两个样本均值，这两个均值允许我们在 0001 的α水平上拒绝零假设*。试试看。)*

自己处理数据确实有助于理解测试背后的统计直觉，尤其是 A/B 测试，因为有这么多移动的部分。但是所有的假设检验实际上都是同样的程序。所以生成一些数据，自己试试，感谢阅读！