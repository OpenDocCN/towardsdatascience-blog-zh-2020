<html>
<head>
<title>Explain Yourself! Leveraging Language Models for Common Sense Reasoning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自己解释！利用语言模型进行常识推理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/explain-yourself-leveraging-language-models-for-common-sense-reasoning-1c988b8b24cd?source=collection_archive---------41-----------------------#2020-07-09">https://towardsdatascience.com/explain-yourself-leveraging-language-models-for-common-sense-reasoning-1c988b8b24cd?source=collection_archive---------41-----------------------#2020-07-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="8679" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" rel="noopener" target="_blank" href="https://towardsdatascience.com/event-talks/home">活动讲座</a></h2><div class=""/><div class=""><h2 id="2ab9" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">Nazneen Rajani | TMLS2019</h2></div><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="kt ku l"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">【https://torontomachinelearning.com/ T2】号</p></figure><h2 id="97fc" class="la lb iq bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu iw bi translated">关于演讲者</h2><p id="2820" class="pw-post-body-paragraph lv lw iq lx b ly lz ka ma mb mc kd md lj me mf mg ln mh mi mj lr mk ml mm mn ij bi translated">Nazneen Fatema Rajani 是 Salesforce Research 的高级研究科学家。<a class="ae kz" href="https://www.linkedin.com/in/nazneenrajani/" rel="noopener ugc nofollow" target="_blank">领英</a></p><h2 id="bdb3" class="la lb iq bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu iw bi translated">关于谈话</h2><p id="2602" class="pw-post-body-paragraph lv lw iq lx b ly lz ka ma mb mc kd md lj me mf mg ln mh mi mj lr mk ml mm mn ij bi translated">深度学习模型在需要常识推理的任务上表现不佳，这通常需要某种形式的世界知识或对输入中不立即存在的信息进行推理。我们以自然语言序列的形式收集人类对常识推理的解释，并在一个名为常识解释(CoS-E)的新数据集中突出标注。</p><p id="27ff" class="pw-post-body-paragraph lv lw iq lx b ly mo ka ma mb mp kd md lj mq mf mg ln mr mi mj lr ms ml mm mn ij bi translated">我们使用 CoS-E 来训练语言模型，以自动生成解释，这些解释可以在新颖的常识自动生成解释(CAGE)框架中的训练和推理期间使用。凯奇在具有挑战性的常识问答任务中提高了 10%的技术水平。我们进一步研究 DNNs 中的常识推理，使用人类和自动生成的解释，包括转移到域外任务。实证结果表明，我们可以有效地利用语言模型进行常识推理。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi mt"><img src="../Images/5f7b57cd2972c384e4de328fe994adcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mymauab_5AOKrFVPe1HkRA.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated"><a class="ae kz" href="https://youtu.be/M5hyQN2YSm8" rel="noopener ugc nofollow" target="_blank">自己解释！利用语言模型进行常识推理</a></p></figure></div></div>    
</body>
</html>