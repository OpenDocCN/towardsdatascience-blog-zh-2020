<html>
<head>
<title>Logistic Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">逻辑回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/logistic-regression-2e11487cc44d?source=collection_archive---------47-----------------------#2020-05-29">https://towardsdatascience.com/logistic-regression-2e11487cc44d?source=collection_archive---------47-----------------------#2020-05-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e0af" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">逻辑回归的简明介绍</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ddf21e66f518bd60673235d8f0b4080c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*S_Tif9zDKIT1byC3"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">paweczerwi ski 在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="7a94" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">逻辑回归是机器学习中使用的基本模型之一。这是一种分类技术，最适合预测分类反应变量。</p><h2 id="f509" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">为什么是逻辑回归？</h2><p id="085c" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">虽然<a class="ae ky" rel="noopener" target="_blank" href="/multiple-linear-regression-8cf3bee21d8b?source=your_stories_page---------------------------">线性回归</a>适用于连续或定量输出变量，但逻辑回归用于预测分类或定性输出变量。</p><p id="1650" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，价格、销售额、温度等目标值本质上是定量的，因此可以使用任何线性模型进行分析和预测，如<a class="ae ky" rel="noopener" target="_blank" href="/multiple-linear-regression-8cf3bee21d8b?source=your_stories_page---------------------------">线性回归</a>。</p><p id="03c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是，如果我们必须预测一封邮件是否是垃圾邮件，信用卡客户是否会违约，给定的癌症是 1 期、2 期还是 3 期呢？对于这种情况，我们不能使用简单的回归模型，我们需要一些可以适应定性反应的东西。</p><p id="2b1f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">考虑下图。该图显示了信用卡默认状态(0 或 1)与客户账户余额的关系。默认状态 0 表示<em class="mt">客户没有显示默认</em>，默认值 1 表示客户<em class="mt">默认</em>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/6ce7e79bce2e4766e6cfdbdb03ec5db6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3SuGHPO4M9daItkIU4tCtw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由<a class="mv mw ep" href="https://medium.com/u/db3258338f2f?source=post_page-----2e11487cc44d--------------------------------" rel="noopener" target="_blank"> Sangeet Aggarwal </a>提供</p></figure><p id="6e88" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如上图所示，线性回归拟合(左)超出了 0 和 1 的可能限制。这是因为线性回归没有考虑到响应变量的值是分类的和离散的这一事实。它可能会为帐户余额高的客户绘制更高的值，反之亦然，这没有任何意义。这就是为什么我们不能对这类问题使用线性回归。</p><p id="19c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这样的问题可以通过逻辑回归(右)来解决，因为它只取 0 到 1 之间的值。</p><p id="d288" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">逻辑回归是最常用的，最适合有两个响应类别的问题，例如，→ 0 或 1，真或假，垃圾邮件或非垃圾邮件，A 型或 B 型等。</p><p id="4c67" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然它可以扩展到预测超过 2 个类别的响应，但还有几种比逻辑回归更好的方法来处理这些问题。因此，在这篇文章中，我们将只关注有两个响应类的问题。</p><h2 id="64a0" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">概率方法</h2><p id="5e63" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">为了理解逻辑回归，我们必须理解它如何产生分类结果。它只是简单地预测响应类吗？不，不是的。</p><p id="4107" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">给定样本中的特征，逻辑回归计算样本属于某个类的概率。这个概率是为每个响应类计算的。具有最高概率的类通常被认为是预测类。</p><p id="60be" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于一个有两个响应类的问题，两个类的<em class="mt">概率加起来是 1 </em>，可以表示如下(取类值为 0 和 1)。</p><blockquote class="mx"><p id="fb0e" class="my mz it bd na nb nc nd ne nf ng lu dk translated">Pr(Class = 1 |要素))= 1-Pr(Class = 0 |要素)</p></blockquote><p id="07a4" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">这里，Pr(Class = 1 | feature(s))读作→具有给定特征的样本属于类别 1 的概率。因为它是一个概率，所以它的值总是在 0 和 1 之间，包括 0 和 1。</p><h2 id="0700" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">算术地</h2><p id="d9d3" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">回忆一下<a class="ae ky" rel="noopener" target="_blank" href="/simple-linear-regression-35b3d940950e?source=your_stories_page---------------------------">简单线性回归</a>的方程。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/ce093415f7cf0610e37a6cdc7b22bd5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:274/format:webp/1*uc7e0WRIfce8a0B-H4wpaw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">线性函数</p></figure><p id="dc92" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于逻辑回归，该方程采用这样的形式，即它只返回 0 和 1 之间的值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/b3505549e095b7e1cc9e9d5a095e858b.png" data-original-src="https://miro.medium.com/v2/resize:fit:446/format:webp/1*Y7dI-phtR3oKmaXAbzpMEA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">逻辑函数</p></figure><p id="bb04" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是逻辑函数，对于 x 的任何值，其值的范围是从 0 到 1。因此，逻辑函数的曲线呈 S 形，其尾部朝向 0 和 1，值介于两者之间。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi no"><img src="../Images/538bce8d84a9c0631846ff3f48291435.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*994cNcIOqIeLzkzy-Y90jQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由<a class="mv mw ep" href="https://medium.com/u/db3258338f2f?source=post_page-----2e11487cc44d--------------------------------" rel="noopener" target="_blank"> Sangeet Aggarwal </a></p></figure><p id="61ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过少量操作，上述等式可以改写为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/c43dffcd2dbb3b688786c32bbbf5aad5.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/1*05WEfe2QbRsvB-K9xe8txQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">赔率函数</p></figure><p id="1cf0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">左侧的比率表达式称为<em class="mt">赔率</em>，可以取 0 到无穷大的值。接近 0 的赔率值表示类别 1 的概率非常低(类别 0 的概率很高)。较大的赔率值表示类别 1 的概率较高。</p><p id="46aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">两面取原木:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/5eb8094ccfb031340422236443195f46.png" data-original-src="https://miro.medium.com/v2/resize:fit:522/format:webp/1*kWBYOMoIiqbAz7CJFKrOkg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">对数概率或对数</p></figure><p id="7b1a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">左边的表达式称为<em class="mt"> Logit </em>函数或 log-odds 函数。这个 logit 函数在 X 中是线性的，可以用来解释 X 项的系数，我们后面会看到。</p><h2 id="e469" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">单预测因子逻辑回归</h2><p id="3fe8" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我们将首先看到当只有一个输入变量时，逻辑回归是如何工作的。然后我们将学习如何扩展模型以适应更多的输入变量。</p><p id="3917" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看一下我们将要使用的数据。这些数据代表信用卡发行商的客户，很少有细节，如他们是否是学生，他们的收入，余额，以及他们是否是违约者。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/231fa0259ddca21a61cd1b49354fd380.png" data-original-src="https://miro.medium.com/v2/resize:fit:614/format:webp/1*9cvWCWEZ6X8BRM5RkEsYxQ.png"/></div></figure><p id="4efc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该公司希望建立一个能够预测客户是否会违约的逻辑模型。所以默认列是我们的目标变量。为了建立我们的第一个逻辑模型，让我们只考虑一个客户的平衡作为我们唯一的预测。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/a305c9be1dfb999abffcbadefc6e825c.png" data-original-src="https://miro.medium.com/v2/resize:fit:292/format:webp/1*L-gkvYiTM4P8t7a7V7Bo1w.png"/></div></figure><p id="f667" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以我们的模型方程看起来像这样:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/36f997e77de84cc336acf81996543edd.png" data-original-src="https://miro.medium.com/v2/resize:fit:890/format:webp/1*eaRnb5lqQPpBiMe4U5zeRQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">给定余额下的违约概率</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/b1bae941fb8b0625418efa8045f3a4f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*hcoiuAIpinVHDFH6HJnh1Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">对数-给定余额的违约概率</p></figure><p id="7555" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们使用 Python 中的 SciKit Learn 来构建我们的模型。</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="fd60" class="lv lw it nw b gy oa ob l oc od">from sklearn.linear_model import LogisticRegression</span><span id="c81f" class="lv lw it nw b gy oe ob l oc od">X = data.balance.values.reshape(-1,1)<br/>y = data.default</span><span id="40d3" class="lv lw it nw b gy oe ob l oc od">logistic = LogisticRegression()<br/>logistic.fit(X,y)</span></pre><p id="8c14" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">绘制上述模型的结果，我们会得到这样的结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/31fe5a3ec87a79b8a6760d611476ea6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*7k8dd50MSDAdRFvEkagOYw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由<a class="mv mw ep" href="https://medium.com/u/db3258338f2f?source=post_page-----2e11487cc44d--------------------------------" rel="noopener" target="_blank"> Sangeet Aggarwal </a>提供</p></figure><p id="0fa9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们检查截距和系数项。</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="50cc" class="lv lw it nw b gy oa ob l oc od">print("Intercept: ",logi.intercept_)<br/>print("Coefficient: ",logi.coef_)</span></pre><p id="4a4c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出:</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="8c04" class="lv lw it nw b gy oa ob l oc od">Intercept: [-5.75236929]<br/>Coefficient: [[0.00448445]]</span></pre><p id="1325" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些可以解释为→</p><ul class=""><li id="80f2" class="of og it lb b lc ld lf lg li oh lm oi lq oj lu ok ol om on bi translated">余额每变化一个单位，违约的对数几率就会乘以 e⁰-⁰⁰⁴⁴⁵.</li><li id="5466" class="of og it lb b lc oo lf op li oq lm or lq os lu ok ol om on bi translated">当账户余额为零时，截距项-5.75 可以被读取为对数赔率的值。</li></ul><p id="d004" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们转到考虑多个输入变量的影响来预测默认状态的情况。</p><h2 id="54de" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">多重预测的逻辑回归</h2><p id="7830" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">多元逻辑回归方程可以写成:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/560cf90fe2c852eea8521d954401d44a.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*hT8zcBD6hqTF7XGqyv88NQ.png"/></div></figure><p id="7a82" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">相应的对数优势函数将变为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/64534e9c88096c39068d07e17c12185a.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*is9CxIY06Newi5BvB3SCPQ.png"/></div></figure><p id="4207" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了让我们的模型工作，我们需要将所有分类输入转换成数字标签。在这种情况下，学生变量的值为“Yes”和“No”。因此，我将这些值分别转换为 1 和 0。在继续之前，让我们再看一下数据。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/f05da06dad7b0ba07ab851a3689ee49c.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*86LbaCUHxKUILHiV4uMlAg.png"/></div></figure><p id="a653" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们来拟合模型。</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="5e60" class="lv lw it nw b gy oa ob l oc od">X_all = data.drop('default',axis=1)<br/>y = data.default</span><span id="76cb" class="lv lw it nw b gy oe ob l oc od">mlr = LogisticRegression()<br/>mlr.fit(X_all, y)</span></pre><p id="183a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">检查系数。</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="7747" class="lv lw it nw b gy oa ob l oc od">print("Coefficients for stuedent, income and balance are:")<br/>for i in range(3):<br/>    print(round(mlr.coef_[0][i],5))<br/>print("Intercept: ", mlr.intercept_[0])</span></pre><p id="1214" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出:</p><pre class="kj kk kl km gt nv nw nx ny aw nz bi"><span id="0c03" class="lv lw it nw b gy oa ob l oc od">Coefficients for stuedent, income and balance are:<br/>-1.63465<br/>-5e-05<br/>0.0047</span><span id="dc89" class="lv lw it nw b gy oe ob l oc od">Intercept: -3.8386588181706274</span></pre><p id="1e2d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这里，收入的系数值相当低，这表明客户的收入并没有真正增加违约的几率。我们可以通过检查相关性和其他见解来做进一步的分析，以提高对数据和模型的理解。但为了保持主题的范围，我不在这里添加这部分分析。</p><p id="7d1c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望这篇文章能帮助你理解逻辑回归的工作原理。你也可以查看下面的链接来了解线性回归。更多此类帖子，敬请关注。</p><div class="ow ox gp gr oy oz"><a rel="noopener follow" target="_blank" href="/simple-linear-regression-35b3d940950e"><div class="pa ab fo"><div class="pb ab pc cl cj pd"><h2 class="bd iu gy z fp pe fr fs pf fu fw is bi translated">简单线性回归</h2><div class="pg l"><h3 class="bd b gy z fp pe fr fs pf fu fw dk translated">关于简单线性回归你需要知道的一切</h3></div><div class="ph l"><p class="bd b dl z fp pe fr fs pf fu fw dk translated">towardsdatascience.com</p></div></div><div class="pi l"><div class="pj l pk pl pm pi pn ks oz"/></div></div></a></div><div class="ow ox gp gr oy oz"><a rel="noopener follow" target="_blank" href="/multiple-linear-regression-8cf3bee21d8b"><div class="pa ab fo"><div class="pb ab pc cl cj pd"><h2 class="bd iu gy z fp pe fr fs pf fu fw is bi translated">多元线性回归</h2><div class="pg l"><h3 class="bd b gy z fp pe fr fs pf fu fw dk translated">一个完整的研究—模型解释→假设检验→特征选择</h3></div><div class="ph l"><p class="bd b dl z fp pe fr fs pf fu fw dk translated">towardsdatascience.com</p></div></div><div class="pi l"><div class="po l pk pl pm pi pn ks oz"/></div></div></a></div></div><div class="ab cl pp pq hx pr" role="separator"><span class="ps bw bk pt pu pv"/><span class="ps bw bk pt pu pv"/><span class="ps bw bk pt pu"/></div><div class="im in io ip iq"><p id="7c0c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你是数据科学和机器学习的新手，不知道从哪里开始你的旅程，请查看下面的链接，在那里我提到了学习数据科学的一步一步的方法，有很多资源可供你选择。</p><div class="ow ox gp gr oy oz"><a rel="noopener follow" target="_blank" href="/data-science-from-scratch-4343d63c1c66"><div class="pa ab fo"><div class="pb ab pc cl cj pd"><h2 class="bd iu gy z fp pe fr fs pf fu fw is bi translated">从零开始的数据科学</h2><div class="pg l"><h3 class="bd b gy z fp pe fr fs pf fu fw dk translated">作为一个完全的初学者如何步入数据科学</h3></div><div class="ph l"><p class="bd b dl z fp pe fr fs pf fu fw dk translated">towardsdatascience.com</p></div></div><div class="pi l"><div class="pw l pk pl pm pi pn ks oz"/></div></div></a></div><p id="59ad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">等不及了？如果你想一头扎进一门课程，请点击下面的<a class="ae ky" href="https://www.datacamp.com/?tap_a=5644-dce66f&amp;tap_s=910084-843f05&amp;utm_medium=affiliate&amp;utm_source=sangeetaggarwal" rel="noopener ugc nofollow" target="_blank">链接</a>，查看适合你的数据科学职业轨迹。</p><div class="ow ox gp gr oy oz"><a href="https://www.datacamp.com/?tap_a=5644-dce66f&amp;tap_s=910084-843f05&amp;utm_medium=affiliate&amp;utm_source=sangeetaggarwal" rel="noopener  ugc nofollow" target="_blank"><div class="pa ab fo"><div class="pb ab pc cl cj pd"><h2 class="bd iu gy z fp pe fr fs pf fu fw is bi translated">在线学习 R、Python 和数据科学</h2><div class="pg l"><h3 class="bd b gy z fp pe fr fs pf fu fw dk translated">使用 DataCamp 的视频教程&amp;编码，按照您自己的步调，在您的浏览器中舒适地学习数据科学</h3></div><div class="ph l"><p class="bd b dl z fp pe fr fs pf fu fw dk translated">www.datacamp.com</p></div></div><div class="pi l"><div class="px l pk pl pm pi pn ks oz"/></div></div></a></div></div></div>    
</body>
</html>