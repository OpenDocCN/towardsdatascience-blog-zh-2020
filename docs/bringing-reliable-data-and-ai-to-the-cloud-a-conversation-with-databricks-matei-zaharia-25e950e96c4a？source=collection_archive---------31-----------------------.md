# 将可靠的数据和人工智能带到云端:与 Databricks 的 Matei Zaharia 的问答

> 原文：<https://towardsdatascience.com/bringing-reliable-data-and-ai-to-the-cloud-a-conversation-with-databricks-matei-zaharia-25e950e96c4a?source=collection_archive---------31----------------------->

## Matei Zaharia 关于人工智能、云计算和数据可靠性的采访

![](img/37bde763c52a8809bc30ec5424e0ca74.png)

图片由[陈琦烨](https://unsplash.com/@ianchen0)在 [Unsplash](http://www.unsplash.com) 上提供。

说你的公司是数据驱动的是一回事。从数据中获得有意义的见解是另一回事。

问问[马泰·扎哈里亚](https://cs.stanford.edu/people/matei/)，[阿帕奇火花](https://spark.apache.org/)的原创者就知道了。自 2010 年由 Matei 和加州大学伯克利分校的 AMPLab 首次发布以来，Apache Spark 已成为世界领先的开源集群计算框架之一，为数据团队提供了一种更快、更有效的方法来处理和协作大规模数据分析。

![](img/9fe2f5f3518b11f2ba1e5b6375b38d47.png)

图片由 Matei Zaharia 提供。

凭借 [Databricks](http://databricks.com) ，Matei 和他的团队通过构建一个平台，帮助数据团队更有效地管理他们的管道和生成 ML 模型，将他们对可扩展、可靠数据的愿景带到了云。**毕竟，正如马泰所言:“你的人工智能只取决于你输入的数据。”**

我们与 Matei 坐下来讨论 Apache Spark 背后的灵感，数据工程和分析领域在过去十年中的发展，以及为什么数据可靠性是业界最关心的问题。

**你在 2010 年作为加州大学伯克利分校的一名研究人员发布了 Spark，从那时起，它已经成为现代数据堆栈中使用最广泛的技术之一。最初是什么激发了你的团队开发这个项目？**

**马泰·扎哈里亚(MZ):** 十年前，人们对使用大型数据集进行分析很感兴趣，但你通常必须是一名软件工程师，并具备 Java 或其他编程语言的知识才能为他们编写应用程序。在 Apache Spark 之前，有 [MapReduce](https://en.wikipedia.org/wiki/MapReduce) 和 Hadoop 作为处理和生成大数据集的开源实现，但我在伯克利的 [AMPLab](https://amplab.cs.berkeley.edu/category/spark-2/) 的团队希望找到一种方法，使数据处理更容易被全职软件工程师以外的用户使用，如数据分析师和数据科学家。

具体来说，对于数据科学家来说，我们构建的第一个功能之一是 SQL 引擎开销，它允许用户将 SQL 与可以用另一种编程语言(如 Python)编写的函数相结合。

> Apache Spark 的另一个早期目标是通过设计模块化的编程接口，让用户可以轻松地使用现有的开源库来设置大数据计算，以便用户可以轻松地在一个应用程序中组合多个库。这导致了数百个为 Spark 构建的开源包。

**是什么鼓励你和你在加州大学伯克利分校的团队将你的研究项目转化为企业数据团队的解决方案？**

在研究项目的早期，有一些技术公司对使用 Apache Spark 感兴趣，例如 Yahoo！，该公司雇佣了当时使用 Hadoop 的最大团队之一，以及几家初创公司。因此，我们很高兴看到我们是否能够支持他们的需求，并通过这种合作，产生新的研究问题的想法，因为它仍然是一个如此新的空间。

因此，我们在早期花了很多时间让 Apache Spark 对企业可用。然后，在 2013 年，这个项目的核心研究团队正在完成我们的博士学位，我们希望继续研究这项技术。我们认为，以可持续和易于使用的方式将它提供给许多人的最佳方式是通过云，于是 Databricks 诞生了。

**七年后，你的预见完全正确。2020 年，越来越多的数据团队将采用云来构建他们的数据平台。企业数据团队在设计他们的数据堆栈时应该记住什么？**

首先，考虑你希望谁访问你的数据平台是很重要的。谁将访问 it 中产生的东西，围绕这一点，您需要什么样的治理工具？如果您没有权限实际使用数据，或者如果您不得不要求另一个团队编写数据工程作业，而不仅仅是运行一个简单的 SQL 命令，那么您就不能轻松地访问现有数据或与公司的其他利益相关者共享结果，这就会成为一个问题。

另一个问题是:您的数据可用性目标是什么？无论你只是构建一个简单的报告或机器学习模型，还是介于两者之间的任何东西，你都希望它们随着时间的推移不断更新。理想情况下，您不会花费大量时间来解决应用程序的停机问题。

> 因此，在设计平台时，评估满足公司数据用户的数据可用性需求所需的特性是非常重要的。这就是 [**数据可观察性**](https://www.montecarlodata.com/data-observability-the-next-frontier-of-data-engineering/) 的用武之地。

**过去，你说过** [**“人工智能只和你输入的数据一样好。”**](https://databricks.com/blog/2018/01/17/matei-zaharias-5-predictions-about-ai-in-2018.html) **我完全同意。你能详细说明一下吗？**

我甚至可以说，人工智能或机器学习真的应该被称为类似“数据外推”的东西，因为这基本上是机器学习算法的定义:以某种方式从已知数据中进行归纳，通常使用某种统计模型。所以当你这么说的时候，我想很明显你输入的数据是最重要的元素，对吗？

如今，越来越多的人工智能研究被发表，强调运行这个或那个新模型需要多么少的代码。如果你为训练模型所做的一切都是标准的，那么这意味着你放入这个模型的数据是非常重要的。为此，需要考虑数据准确性和可靠性的几个重要方面。

例如，你输入的数据是正确的吗？它可能是不正确的，因为你收集它的方式，也可能是因为软件中的错误。问题是，当你生产，你知道，1tb 的数据或 1pb 的数据放入这些培训应用程序之一时，你经常必须逐个检查所有这些数据，看它们是否有效。

同样，您输入的数据是否涵盖了足够多样的条件，或者您是否遗漏了模型需要良好运行的关键现实条件？

**为此，数据团队可以采取哪些步骤来获得高度可靠的数据？**

在高层次上，我见过一些不同的方法，所有这些方法都可以结合使用。其中之一很简单，只需要一个模式和对将要进入表或报告的数据类型的期望。例如，在 Databricks 平台中，我们使用的主要存储格式是一种叫做 [Delta Lake](https://delta.io/) 的东西，它基本上是 Apache Parquet 的一个功能更丰富的版本，在您的表上有版本控制和事务。我们还可以强制实施将哪种数据放入表中的模式。

我见过的另一种数据质量方法是运行作业，在数据产生后检查数据并发出警报。理想情况下，您需要一个非常容易生成自定义检查的界面，并且您可以集中查看正在发生的事情，就像您的数据健康状况的单一窗格。

我要注意的最后一点与你如何设计你的数据管道有关。基本上，数据复制、ETL 和传输步骤越少，您的系统就越有可能可靠，因为出错的地方就越少。例如，您可以获取一个 Delta Lake 表，将其视为一个流，并拥有列出了更改的作业，这样您就不需要将更改复制到消息总线中。您还可以使用 Tableau 这样的商业智能工具直接查询这些表，这样就不必将数据复制到其他系统中进行可视化和报告。

> **数据可靠性**是一个发展非常迅速的领域，我知道[蒙特卡洛](http://www.montecarlodata.com)在这里做了很多有趣的事情。

**当你联合创立 Databricks 的时候，云技术还处于萌芽状态。现在，许多最好的数据公司都在构建云。是什么导致了现代基于云的数据堆栈的兴起？**

我认为这是一个时机和易于采用的问题。对于大多数企业来说，云使得大规模采用技术变得更加容易。有了云，您可以自己购买、安装和运行高度可靠的数据堆栈，而无需昂贵的设置和管理成本。

管理是维护数据管道最困难的部分之一，但是有了云数据仓库和数据湖，它就内置了。所以有了云服务，你买的不仅仅是一堆你必须安装在服务器上的光盘。您的管理质量直接影响到您在其上构建关键应用程序的可能性。如果你的某样东西每个周末都要停机维护，而且必须停机一周才能升级，你就不太可能想用它。

另一方面，如果你有云供应商正在管理的东西，有超高可用性的东西，那么你实际上可以构建这些更关键的应用程序。最后，在云上，供应商向客户发布更新并获得即时反馈也要快得多。

这意味着云供应商必须非常擅长在不中断工作负载的情况下实时更新一些东西，但对于用户来说，这基本上意味着您可以更快地获得更好的软件:**想象一下，您现在可以访问软件，而您在未来一两年内只能从本地供应商那里获得这些软件。**

这些是云产品在市场上取得成功的重要因素。

***了解更多关于*** [***马泰的研究***](https://cs.stanford.edu/people/matei/)*[***阿帕奇 Spark、***](https://spark.apache.org/) ***或***[***Databricks***](http://databricks.com)***。****

****有兴趣了解更多关于数据可靠性的知识吗？向*** [***巴尔摩西***](https://www.linkedin.com/in/barrmoses/) ***以及*** [***蒙特卡洛***](http://www.montecarlodata.com) ***团队伸出援手。****

****本文由***[***Molly Vorwerck***](https://www.linkedin.com/in/vorwerck/)***共同撰写。****