<html>
<head>
<title>Yolo 2 Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Yolo 2 解释道</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/yolo2-walkthrough-with-examples-e40452ca265f?source=collection_archive---------2-----------------------#2020-07-07">https://towardsdatascience.com/yolo2-walkthrough-with-examples-e40452ca265f?source=collection_archive---------2-----------------------#2020-07-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f262" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">实现和可视化</h2></div><p id="d040" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Yolo 是该领域最成功的目标检测算法之一，以其闪电般的速度和相当高的精度而闻名。与需要多次特征提取的逐区域检测对象的其他区域提议框架相比，输入图像在 Yolo 中被处理一次。在本教程中，我们将一窥 Yolo2 的代码。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/75f71c8eebeeb14cade8bd59c95a9495.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UcvzRwd54AQX6ggOsbWYlA.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated"><a class="ae lr" href="https://arxiv.org/pdf/1311.2524.pdf" rel="noopener ugc nofollow" target="_blank"> RCNN 网络</a></p></figure><p id="f362" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于那些想一步一步运行代码而不是看评论的人，可以看看我在 GitHub 上的补充回购！repo 有几个教程涵盖了 Yolo 的所有方面，还有一个现成的库供您使用！</p><div class="ls lt gp gr lu lv"><a href="https://github.com/zzxvictor/YOLO_Explained" rel="noopener  ugc nofollow" target="_blank"><div class="lw ab fo"><div class="lx ab ly cl cj lz"><h2 class="bd ir gy z fp ma fr fs mb fu fw ip bi translated">zzx victor/YOLO _ 解释</h2><div class="mc l"><h3 class="bd b gy z fp ma fr fs mb fu fw dk translated">Yolo 是一个完全卷积的模型，与许多其他扫描检测算法不同，它在…</h3></div><div class="md l"><p class="bd b dl z fp ma fr fs mb fu fw dk translated">github.com</p></div></div><div class="me l"><div class="mf l mg mh mi me mj ll lv"/></div></div></a></div><h1 id="acfd" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">Yolo 输出格式</h1><p id="4f3b" class="pw-post-body-paragraph kf kg iq kh b ki nc jr kk kl nd ju kn ko ne kq kr ks nf ku kv kw ng ky kz la ij bi translated">要理解 Yolo2 是如何工作的，关键是要理解 Yolo 架构是什么样子的。Yolo2 使用 VGG 风格的 CNN 称为黑暗网络作为特征提取器。请注意，DarkNet 是各种网络的保护伞，人们使用不同的变体来提高速度或准确性。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nh"><img src="../Images/d627a9be6f8b46ea0cab85fb14e810ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tauxjkyr4A9J2xglermiew.jpeg"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图一。yolo2 中作为特征提取器的暗网</p></figure><p id="d840" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如你所见，yolo 的输出与我们之前看到的完全不同。图像中有 416 x 416 像素，但输出是 13 x 13。我们究竟如何解释这些结果？</p><p id="378e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们暂时把 Yolo 放在一边，想想我们如何在一条路径上进行物体检测？这是我天真的解决方案:</p><pre class="lc ld le lf gt ni nj nk nl aw nm bi"><span id="3f1d" class="nn ml iq nj b gy no np l nq nr">Suppose we have a network that takes an input image of size, say 416 x 416 x3, and there are 20 classes in the dataset.</span><span id="74fb" class="nn ml iq nj b gy ns np l nq nr">For every pixel in the image, we can predict a box with the following layout(Figure 2). The model output has shape 416 x 416 x22</span></pre><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nt"><img src="../Images/f279df50ffaa693dce8f854290b5f222.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*92lseKw7hqBOxcI8kUqYiw.jpeg"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图二。天真的方法</p></figure><p id="b9a8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Yolo 被设计成快速准确。因此，预测每个像素一个盒子是不理想的(两个相邻的像素可能属于一个对象)。发明 YOLO 的极客们去工作，想出了一个更好的主意</p><h2 id="6858" class="nn ml iq bd mm nu nv dn mq nw nx dp mu ko ny nz mw ks oa ob my kw oc od na oe bi translated">优化 1 —减少预测箱数</h2><p id="06bd" class="pw-post-body-paragraph kf kg iq kh b ki nc jr kk kl nd ju kn ko ne kq kr ks nf ku kv kw ng ky kz la ij bi translated">我们将一幅图像分成 S×S 个网格，并预测每个<strong class="kh ir"> <em class="of">网格的<strong class="kh ir"> <em class="of">个</em> </strong>个盒子，而不是预测每个像素一个盒子。</em>T9】</strong></p><pre class="lc ld le lf gt ni nj nk nl aw nm bi"><span id="20ea" class="nn ml iq nj b gy no np l nq nr">With this optimization, the output can be reduced to something like 13 x 13 x 5*22, if we predict 5 boxes per grid. This is a significant drop in box numbers</span></pre><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi og"><img src="../Images/7805ac4b963bd2d2e0c8104102d020d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*cJF0hsZohYWpSBsYMc74dw.jpeg"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图 3。<a class="ae lr" href="https://arxiv.org/pdf/1506.02640.pdf" rel="noopener ugc nofollow" target="_blank">约洛</a></p></figure><h2 id="8d6a" class="nn ml iq bd mm nu nv dn mq nw nx dp mu ko ny nz mw ks oa ob my kw oc od na oe bi translated">优化 2 —用于过滤掉低置信度预测的对象分数</h2><p id="49e7" class="pw-post-body-paragraph kf kg iq kh b ki nc jr kk kl nd ju kn ko ne kq kr ks nf ku kv kw ng ky kz la ij bi translated">除了分类概率之外，Yolo 还引入了一个<strong class="kh ir">对象分数</strong>。对象分数是对一个对象是否出现在预测框中的估计(它不关心什么对象，那是类概率的工作)。如果一个预测具有较低的对象分数，它将在后处理中被丢弃。也就是说，边界框应该像这样</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi oh"><img src="../Images/bd0044642cb33979299762d9ea3fd992.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wM7Gm0yFl-xNXZLEsrojHQ.jpeg"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图 4。更好的方法</p></figure><pre class="lc ld le lf gt ni nj nk nl aw nm bi"><span id="6c03" class="nn ml iq nj b gy no np l nq nr">With this optimization, the output will have shape 13 x 13 x 5 * (3+20)</span></pre><h2 id="bfb8" class="nn ml iq bd mm nu nv dn mq nw nx dp mu ko ny nz mw ks oa ob my kw oc od na oe bi translated">优化 3 —根据数据集量身定制</h2><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/1265d7cae9d0d43841b9a1593346a3ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*dOjPhwO-FShhm9l13KvnVA.jpeg"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图 5，不同尺寸和比例的锚盒。高盒子适合人类等物体，而宽盒子适合公共汽车和自行车等物体</p></figure><p id="7d3e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Yolo 没有预测整个图像中盒子的绝对大小，而是引入了所谓的<strong class="kh ir">锚盒</strong>，这是一个预定义的盒子列表，最匹配所需的对象(给定基本事实，运行 K 均值聚类)。预测框相对于锚点进行缩放。更具体地说:</p><ol class=""><li id="cb9d" class="oj ok iq kh b ki kj kl km ko ol ks om kw on la oo op oq or bi translated">预测盒子中心(图 6 中的 tx 和 ty)w . r . t 其网格左上角的<strong class="kh ir"><em class="of"/></strong>按<strong class="kh ir"> <em class="of">网格宽度和高度缩放。</em>T9】</strong></li><li id="3486" class="oj ok iq kh b ki os kl ot ko ou ks ov kw ow la oo op oq or bi translated">根据锚盒  (pw 和 ph)预测盒<strong class="kh ir"> <em class="of">的宽度(tw)和高度(th)</em></strong></li></ol><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/b9aa926472a4e5663a7c247874d7f209.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*p7F0dA9pVoZndxuFNuvOHg.jpeg"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图 6。<a class="ae lr" href="https://arxiv.org/abs/1612.08242" rel="noopener ugc nofollow" target="_blank"> Yolo2 </a>中的锚盒</p></figure><h2 id="2a2c" class="nn ml iq bd mm nu nv dn mq nw nx dp mu ko ny nz mw ks oa ob my kw oc od na oe bi translated">最终格式</h2><p id="5c3b" class="pw-post-body-paragraph kf kg iq kh b ki nc jr kk kl nd ju kn ko ne kq kr ks nf ku kv kw ng ky kz la ij bi translated">现在你知道 YOLO 预测每个网格有几个边界框，而不是只有一个。输出形状类似于 13 x 13 x NUM_ANCHOR X (BOX INFO ),其中最后一个维度看起来就像简单方法的升级版。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi oy"><img src="../Images/41a5399dd84d783231a191984ab25327.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h7jS1jrC2L3MfYUMzIerpw.jpeg"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图 6。yolo 格式</p></figure><pre class="lc ld le lf gt ni nj nk nl aw nm bi"><span id="8cfd" class="nn ml iq nj b gy no np l nq nr">With all optimizations, Yolo output can be interprated as:<br/>for every grid:<br/>    for every anchor box: (with different aspect ratios and sizes)<br/>        predict a box<br/>Thus, yolo output has shape 13 x 13 x 5 x 25, which is reshaped in practice into 13 x 13 x 125</span></pre><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi oz"><img src="../Images/5db25c7910d3a9713547e185278a644c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aGYM78nII7evuGD_x9ogKQ.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图 7。验证分析</p></figure><h1 id="9b53" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">边界框的原始输出</h1><p id="a24c" class="pw-post-body-paragraph kf kg iq kh b ki nc jr kk kl nd ju kn ko ne kq kr ks nf ku kv kw ng ky kz la ij bi translated">现在我们明白 Yolo 2 的格式了。下一步是如何从原始张量中提取盒子。你确定我们不能用所有 13 x 13 x 5 的盒子吗？在这一节中，我们将看到如何从原始输出张量中提取信息。</p><pre class="lc ld le lf gt ni nj nk nl aw nm bi"><span id="f864" class="nn ml iq nj b gy no np l nq nr">Let's assume the output Y has shape 2 x 2 x 2*6, meaning there are two anchors per grid and one class in the dataset. <br/>Assume Y[0,1,0,:] = [0, 0, 0.4, 0.4, 0, 0.5]. This defines the red box in figure 8. But how to decode it?</span></pre><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi pa"><img src="../Images/0d99994d536c10b58e56a6c54f239ebe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CJPtkfEe7u63PFwrRq8-SA.jpeg"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图 8</p></figure><h2 id="e7a3" class="nn ml iq bd mm nu nv dn mq nw nx dp mu ko ny nz mw ks oa ob my kw oc od na oe bi translated">步骤 1-提取框坐标</h2><p id="72d2" class="pw-post-body-paragraph kf kg iq kh b ki nc jr kk kl nd ju kn ko ne kq kr ks nf ku kv kw ng ky kz la ij bi translated">让我们来看看这些信息</p><pre class="lc ld le lf gt ni nj nk nl aw nm bi"><span id="bcae" class="nn ml iq nj b gy no np l nq nr">[0, 0, 0.4,  0.4, 0, 0.5] = <br/>[tx,  ty,  tw,  th,  obj score,  class prob.]<br/>Please refer to figure 6</span></pre><p id="4eba" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们需要将相对坐标 tx，ty 转换为图像比例坐标 bx，by，对于 tw 和 th 也是如此。下面是如何在 tensorflow 2 中实现的</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="pb pc l"/></div></figure><pre class="lc ld le lf gt ni nj nk nl aw nm bi"><span id="430f" class="nn ml iq nj b gy no np l nq nr">After this step the red box coordinate is converted from:<br/>[0, 0, 0.5, 0.5] to <br/>[0.5, 1.5, 1.13, 0.75], meaning it's (0.5 grid height, 1.5 grid width) from the top left image corner and the box has size (1.13 grid height, 0.75 grid width)</span></pre><p id="cba9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们有了预测的盒子在网格尺度上的坐标和它的大小，很容易计算它的角的坐标(图 8 中紫色和绿色的点)。我们做这一步是因为用它的角而不是它的中心和宽度/高度 来表示一个盒子是标准的</p><p id="63c4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要获得绿色和紫色点的坐标，我们需要:</p><pre class="lc ld le lf gt ni nj nk nl aw nm bi"><span id="830c" class="nn ml iq nj b gy no np l nq nr">green dot = boxXY - boxWH / 2<br/>purple dot = boxXY + boxWH /2 <br/>(Please note that the top left corner has smaller cordinates in images)</span></pre><p id="f05e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这之后，我们用(32，32)乘以坐标，这样边界框现在就是图像比例了。例如，(0，0)表示左上角，(1，1)表示右下角，(0.5，0.5)表示图像中心</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="pb pc l"/></div></figure><h2 id="6cd8" class="nn ml iq bd mm nu nv dn mq nw nx dp mu ko ny nz mw ks oa ob my kw oc od na oe bi translated">第 2 步—过滤掉低质量的盒子</h2><p id="86df" class="pw-post-body-paragraph kf kg iq kh b ki nc jr kk kl nd ju kn ko ne kq kr ks nf ku kv kw ng ky kz la ij bi translated">对于每个网格和每个定位框，yolo 预测一个边界框。在我们的例子中，这意味着预测了 13 * 13 * 5 个盒子。可以想象，并不是所有的框都是准确的。其中一些可能是假阳性(无对象)，一些是预测同一对象(太多重叠)。为了获得最终结果，我们需要:</p><pre class="lc ld le lf gt ni nj nk nl aw nm bi"><span id="83cd" class="nn ml iq nj b gy no np l nq nr">Filter out boxes with low confidence (object score)<br/>Filter out boxes that overlaps too much (two boxes have high IOU)</span></pre><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="pb pc l"/></div></figure><h1 id="5c75" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">魔法时间</h1><p id="94fd" class="pw-post-body-paragraph kf kg iq kh b ki nc jr kk kl nd ju kn ko ne kq kr ks nf ku kv kw ng ky kz la ij bi translated">就是这样！这些是您解码 yolo 输出所需的唯一脚本。让我们来看看结果:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/eb19e1f4ab6b8f3fffa58dc9a4b38e4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*oB3e5Tc2udgQtqf-f7fy0Q.jpeg"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图 9</p></figure><p id="998a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">阅读脚本可能会非常混乱，这就是我强烈建议你检查一下<a class="ae lr" href="https://github.com/zzxvictor/YOLO_Explained" rel="noopener ugc nofollow" target="_blank">回购</a>并在 Google Colab 或你的本地计算机上运行它。</p><p id="b43e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">非常感谢您的阅读！在未来的教程中，我将讨论加载训练数据和转移学习！</p></div></div>    
</body>
</html>