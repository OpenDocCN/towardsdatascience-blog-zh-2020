<html>
<head>
<title>Image Classification of bird species using deep learning with PyTorch, Captum and ONNX</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于 PyTorch、Captum 和 ONNX 深度学习的鸟类图像分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/adventures-in-pytorch-image-classification-with-caltech-birds-200-part-1-the-dataset-6e5433e9897c?source=collection_archive---------18-----------------------#2020-07-31">https://towardsdatascience.com/adventures-in-pytorch-image-classification-with-caltech-birds-200-part-1-the-dataset-6e5433e9897c?source=collection_archive---------18-----------------------#2020-07-31</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/f4cc86b7f871c8a71766003a94bc6369.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9bC830cDnD3izQxEQLGSxA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">(图片由作者提供)</p></figure><h2 id="a497" class="jd je jf bd b dl jg jh ji jj jk jl dk jm translated" aria-label="kicker paragraph">PyTorch 历险记</h2><div class=""/><div class=""><h2 id="4057" class="pw-subtitle-paragraph kl jo jf bd b km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc dk translated">第 0 部分:介绍图像分类、深度学习和加州理工学院鸟类 200 数据集</h2></div><p id="165d" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">本系列将探索脸书人工智能研究所(FAIR)强大的神经网络和机器学习架构 PyTorch 的强大功能。在这一系列文章中，我们将探索 PyTorch 在图像分类问题中的应用能力，通过使用各种 CNN 架构，包括 GoogLeNet、ResNet152 和 ResNeXt101 等，使用 CalTech 200 birds 数据集识别 200 种北美鸟类。</p><figure class="ma mb mc md gt is gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/ed87761cc06ac9dc185dc0f10eb8707c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*cY9AOTe3vjlerL73ItnfTg.jpeg"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">加州理工学院加州大学圣迭戈分校鸟类 200 数据集(<a class="ae me" href="http://www.vision.caltech.edu/visipedia/CUB-200.html" rel="noopener ugc nofollow" target="_blank">)韦林德 p、布兰森 s、塔米 t、华 c、施罗夫 f、贝隆吉 s、佩罗娜 p .“加州理工学院-加州大学圣迭戈分校鸟类 200”。加州理工学院。CNS-TR-2010–001。2010 年</a></p></figure><h1 id="4867" class="mf mg jf bd mh mi mj mk ml mm mn mo mp ku mq kv mr kx ms ky mt la mu lb mv mw bi translated">介绍</h1><p id="88d5" class="pw-post-body-paragraph ld le jf lf b lg mx kp li lj my ks ll lm mz lo lp lq na ls lt lu nb lw lx ly ij bi nc translated"><span class="l nd ne nf bm ng nh ni nj nk di">在</span>这组文章中，我将探讨我们如何使用脸书人工智能研究所的神经网络库<a class="ae me" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>来解决一个多类的图像分类问题。这个广泛的库，带有一系列与发行版打包在一起的现有工具，从使用<em class="nl"> torch.nn </em>模块(相当于 Keras 的 PyTorch)的高级抽象，到低级自动签名函数和基于 GPU 的高效操作，允许设计和快速实现最先进的机器学习架构。在最基本的层面上，PyTorch 可以被认为是众所周知的 python 数组包 Numpy 的一个高度优化的多维版本。</p><figure class="ma mb mc md gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nm"><img src="../Images/3c2380ccb9c1b7ca1f45fb40e24a701f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wUbUN8AZmhJW-C4Mj6kP1A.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图 1:加州理工学院鸟类分类研讨会工作流程。本系列的每一篇文章都将关注这个工作流的一个单独的阶段。用于生成这些文章的笔记本，以及经过训练的模型可以在<a class="ae me" href="https://github.com/ecm200/caltech_birds" rel="noopener ugc nofollow" target="_blank"> this Github repository </a>中找到。(图片由作者提供)</p></figure><p id="fea5" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">将要进行的工作流程如图 1 所示，每篇文章都将关注该工作流程的一个特定方面，包括:</p><ol class=""><li id="5f6d" class="nn no jf lf b lg lh lj lk lm np lq nq lu nr ly ns nt nu nv bi translated">数据探索和分类问题介绍。</li><li id="7c9e" class="nn no jf lf b lg nw lj nx lm ny lq nz lu oa ly ns nt nu nv bi translated">准备图像分类卷积神经网络(CNN)并在以下架构上训练:<br/> A) Torchvision 预训练网络。<br/> B)第三方预培训网络。</li><li id="42b1" class="nn no jf lf b lg nw lj nx lm ny lq nz lu oa ly ns nt nu nv bi translated">使用传统方法(分类报告、度量、混淆矩阵、精确召回曲线等)评估分类模型性能。</li><li id="a157" class="nn no jf lf b lg nw lj nx lm ny lq nz lu oa ly ns nt nu nv bi translated">使用神经网络激活图的域缩减和流形技术(例如 t <a class="ae me" href="https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html#sklearn.manifold.TSNE" rel="noopener ugc nofollow" target="_blank"> -SNE </a>和<a class="ae me" href="https://umap-learn.readthedocs.io/en/latest/#" rel="noopener ugc nofollow" target="_blank"> UMAP </a>)评估网络分类性能。</li><li id="4d00" class="nn no jf lf b lg nw lj nx lm ny lq nz lu oa ly ns nt nu nv bi translated">迁移学习，使用经过训练的神经网络作为特征提取器，作为其他分类算法(XGBoost，内核 SVM)的输入。</li><li id="c0a5" class="nn no jf lf b lg nw lj nx lm ny lq nz lu oa ly ns nt nu nv bi translated"><a class="ae me" href="https://distill.pub/2017/feature-visualization/#:~:text=to%20force%20the%20feature%20to%20be%20displayed%20in%20different%20styles.&amp;text=Diverse%20feature%20visualizations%20allow%20us,inputs%20will%20activate%20the%20neuron." rel="noopener ugc nofollow" target="_blank">神经网络卷积滤波器的特性可视化</a>(<a class="ae me" href="https://distill.pub/2018/building-blocks/" rel="noopener ugc nofollow" target="_blank">神经元、空间和层激活</a>)，使用<a class="ae me" href="https://github.com/greentfrapp/lucent" rel="noopener ugc nofollow" target="_blank"> Lucent python 包</a> ( <a class="ae me" href="https://github.com/tensorflow/lucid" rel="noopener ugc nofollow" target="_blank"> Lucid </a> for PyTorch)。</li><li id="4538" class="nn no jf lf b lg nw lj nx lm ny lq nz lu oa ly ns nt nu nv bi translated">通过将 PyTorch 模型对象转换为<a class="ae me" href="http://www.onnx.ai" rel="noopener ugc nofollow" target="_blank"> ONNX(开放式神经网络交换)</a>格式来部署训练模型，并使用 ONNX 运行时环境演示推理。</li></ol><p id="ba58" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在这个系列的介绍中，我们将从机器学习的角度来回顾什么是分类，我们所说的图像分类是什么，特别是什么是使用深度学习技术的图像分类。接下来，我们将介绍鸟类分类的细粒度图像分类问题，并回顾我们稍后将用来演示这些技术的所选数据集。最后，我们将对过去几年中开发的最先进的卷积神经网络所获得的结果进行总结，在接下来的系列文章中，我们将揭示如何实现这些结果。</p><h1 id="6693" class="mf mg jf bd mh mi mj mk ml mm mn mo mp ku mq kv mr kx ms ky mt la mu lb mv mw bi translated">什么是预测模型，什么是分类？</h1><figure class="ma mb mc md gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ob"><img src="../Images/7b7c74f978463d41091073f768e37024.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Kn81hJo4UZ-VbjqSsk54A.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图 2:机器学习算法适合两个一般领域，分类和回归。(图片由作者提供)</p></figure><p id="a2c5" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi nc translated">预测建模是利用历史数据开发一个模型，在我们没有答案的情况下对新数据进行预测的问题。预测建模可以被描述为从输入变量(X)到输出变量(y)逼近映射函数(f)的数学问题。这就是所谓的函数逼近问题。</p><p id="230f" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">建模算法的工作是在给定时间和可用资源的情况下找到最佳映射函数。</p><p id="7ce2" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">从根本上说，分类和回归的区别在于，一个旨在预测一个标签或类别，而另一个旨在预测一个数量。</p><p id="3b74" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">图 2 清楚地说明了这两种方法之间的差异，其中分类模型根据给定数据点相对于类边界的位置来预测其类值，例如<a class="ae me" href="https://scikit-learn.org/stable/modules/svm.html#svm" rel="noopener ugc nofollow" target="_blank">支持向量机(SVM)分类器</a>。然而，回归模型被设计成在给定一组预测因子(数据列)的情况下预测某事物的实际数量。</p><p id="3cb5" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">分类预测建模是从输入变量(X)到离散输出变量(y)近似映射函数(f)的任务。输出变量通常被称为标签或类别。映射函数预测给定观察值的类别或种类。例如，文本电子邮件可以被分类为属于两类之一:“垃圾邮件<em class="nl">”</em>和“<em class="nl">非垃圾邮件</em>”。</p><ul class=""><li id="22c7" class="nn no jf lf b lg lh lj lk lm np lq nq lu nr ly oc nt nu nv bi translated">分类问题要求将示例分为两类或更多类中的一类。</li><li id="020d" class="nn no jf lf b lg nw lj nx lm ny lq nz lu oa ly oc nt nu nv bi translated">分类可以有实值或离散输入变量。</li><li id="479e" class="nn no jf lf b lg nw lj nx lm ny lq nz lu oa ly oc nt nu nv bi translated">有两类的问题通常被称为两类或二元分类问题。</li><li id="fba8" class="nn no jf lf b lg nw lj nx lm ny lq nz lu oa ly oc nt nu nv bi translated">具有两个以上类别的问题通常被称为多类别分类问题。</li><li id="0519" class="nn no jf lf b lg nw lj nx lm ny lq nz lu oa ly oc nt nu nv bi translated">一个例子被分配多个类别的问题称为多标签分类问题。</li></ul><p id="ed5a" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">分类模型通常将连续值预测为给定示例属于每个输出类的概率。概率可以解释为属于每个类别的给定示例的可能性或置信度。通过选择具有最高概率的类标签，可以将预测概率转换为类值。</p><p id="69d2" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在这些文章中，我们要关注的是分类，以及一个叫做图像分类的问题的特殊子集，我们将在下一节更详细地讨论这个问题。</p><h1 id="d813" class="mf mg jf bd mh mi mj mk ml mm mn mo mp ku mq kv mr kx ms ky mt la mu lb mv mw bi translated">什么是图像分类？</h1><figure class="ma mb mc md gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi od"><img src="../Images/bc21d4b4dfe289871c413bddb4a1538b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zXKVI7U1j41lcZfrL0gL9g.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图 3:对象的图像分类，其中根据图像的内容对图像进行分类。(图片由作者提供)</p></figure><p id="11c0" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi nc translated">图像分类是一般分类问题的一个子域。为图像分类设计的算法接受图像作为其输入，并产生图像类别的预测作为输出。输出可以采取标签或类别的形式，或者表示属于图像的每个潜在类别的可能性的一组实值概率的形式。图 3 中的漫画显示了一种算法，该算法设计用于识别食物图像是冰淇淋、冰棍还是蛋糕，将食物图像作为输入，并提供一个类别标签作为预测。</p><p id="a45d" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">为了成功地对图像进行分类，一种算法需要从输入图像中提取代表性的“特征”，并学习相应的模式，以允许它根据图像的内容区分类别(图 4A)。这些“特征”可以通过迭代和交互的设计过程手动创建，目的是产生最好的分类特征。然而，这种手动方法有以下潜在的缺点:</p><ol class=""><li id="6fc1" class="nn no jf lf b lg lh lj lk lm np lq nq lu nr ly ns nt nu nv bi translated">人力密集。</li><li id="67b9" class="nn no jf lf b lg nw lj nx lm ny lq nz lu oa ly ns nt nu nv bi translated">容易出错。</li><li id="9550" class="nn no jf lf b lg nw lj nx lm ny lq nz lu oa ly ns nt nu nv bi translated">穷尽过程。</li><li id="e70f" class="nn no jf lf b lg nw lj nx lm ny lq nz lu oa ly ns nt nu nv bi translated">无法保证能够最佳区分不同类别的独特特征。</li></ol><figure class="ma mb mc md gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oe"><img src="../Images/339f6eaa0c753928f69b508546b64ffe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R2-Bw04deyacbMPGcGu3nQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图 4A:使用(上)具有手工制作特征的机器学习和(下)使用 CNN 在一个过程中自动导出理想化特征和分类器的深度学习的不同图像分类方法。(图片由作者提供)</p></figure><p id="976f" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">另一种在过去 10 年中广泛发展并在图像分类性能方面取得显著进步的方法是深度学习的使用，特别是卷积神经网络(CNN)。这些类型的方法试图同时解决优化设计的特征提取和预测对象类别的分类器的问题。在其最简单的形式中，CNN 可以被认为是一个巨大的，自动导出(或学习)的特征提取系统，末端有一个分类器。</p><figure class="ma mb mc md gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi of"><img src="../Images/d840466d2f5337a1858b438683e43f29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ORxwGAH6m5pUdVZ0QxiFkg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图 4B:从头开始培训的概念(上图)与迁移学习的概念(下图)。在迁移学习中，通过移除最终层分类器并将提取的特征输出用作新分类器的输入，预训练的网络被用作特征提取网络(新分类器不必基于神经网络)。(图片由作者提供)</p></figure><p id="e480" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">事实上，正是这种结构允许采用所谓的“迁移学习”方法(图 4B)。这是移除网络基础上的分类层，并将网络用作特征提取器的过程。然后，该特征提取网络的输出可以被馈送到另一个分类器中，该分类器的选择可以是任何机器学习分类器(例如，SVM、核 SVM、基于决策树的集成，如 XGBoost)，以执行分类预测。在这种情况下，分类器的输入不是图像，而是从图像中提取的特征(有时称为激活)的集合，分类器通过这些特征学习识别和预测图像类别。</p><p id="ac32" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">正是这些方法，我们将在下面的系列文章中展示如何使用 PyTorch 构建一个最先进的图像分类器。</p><h1 id="9eee" class="mf mg jf bd mh mi mj mk ml mm mn mo mp ku mq kv mr kx ms ky mt la mu lb mv mw bi translated">数据集—加州理工学院 UCSD 200 鸟类数据库(CUB-200–2011)</h1><figure class="ma mb mc md gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi og"><img src="../Images/472776086b77b65053e4fcf999b2c253.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*EXkmhWociI2Se4ZbFQfnQQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图 5:来自 CUB-200–2011 的相似物种(莺)的例子，显示了鸟类物种识别的复杂性和困难性。即使有了图 6 所示的物种图，人类也很难预测具体的鸟类物种。</p></figure><p id="35d9" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi nc translated">CUB-200–2011 数据集包含来自 200 个不同物种的北美鸟类图像。这是一个具有挑战性的问题，因为许多鸟类都有一定程度的视觉相似性。鸟类物种识别对人类来说是具有挑战性的，更不用说计算机视觉算法了，因此这种类型的问题通常被称为大规模细粒度的。例如，用图 6 中的物种图来识别图 5 中两种鸟的正确林莺物种，对人类来说仍然是一个非常困难和复杂的问题。</p><figure class="ma mb mc md gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oh"><img src="../Images/470e96ff26bbfe5e70c4a39e74df76cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MOlnoLbh1eEVzarh-oYtWA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图 6:北美林莺物种示例图(<a class="ae me" href="https://shop.katedolamore.com/" rel="noopener ugc nofollow" target="_blank"> <em class="oi">凯特·多拉莫尔艺术</em> </a> <em class="oi"> ) </em>)。</p></figure><figure class="ma mb mc md gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oj"><img src="../Images/1ccfdaa10f7f80dafb2b11e926783b44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bETSySG1-Q5voAinhFroSQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图 7:CUB-200–2011 数据集属性(在 <a class="ae me" href="http://www.vision.caltech.edu/visipedia/papers/CUB_200_2011.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="oi">之后的<em class="oi">)计算&amp;神经系统技术报告，CNS-TR-2011–001</em></em></a>)。</p></figure><p id="955a" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">该数据集最初产生于 2010 年(<a class="ae me" href="http://www.vision.caltech.edu/visipedia/CUB-200.html" rel="noopener ugc nofollow" target="_blank"> CUB-200 </a>)，包含 200 类鸟类的约 6000 张图像。伴随它的是附加标签数据，包括边界框、粗略分割和附加属性。这在 2011 年进行了更新(<a class="ae me" href="http://www.vision.caltech.edu/visipedia/CUB-200-2011.html" rel="noopener ugc nofollow" target="_blank">CUB-200–2011</a>)，增加了额外的图像，使数据集中的图像总数达到近 12，000 张。可用的属性也被更新为包括 15 个零件位置、312 个二进制属性和每个图像的边界框(图 7)。在本系列的大部分时间里，我们将简单地使用图像和类别标签来开发和训练预测鸟类类别的网络。</p><h1 id="0011" class="mf mg jf bd mh mi mj mk ml mm mn mo mp ku mq kv mr kx ms ky mt la mu lb mv mw bi translated">关于 CUB-200–2011 的部分已发布结果</h1><p id="44f2" class="pw-post-body-paragraph ld le jf lf b lg mx kp li lj my ks ll lm mz lo lp lq na ls lt lu nb lw lx ly ij bi nc translated"><span class="l nd ne nf bm ng nh ni nj nk di"> W </span> <a class="ae me" href="http://www.vision.caltech.edu/visipedia/papers/CUB_200_2011.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="nl"> ah 等人(2010) </em> </a> <em class="nl"> </em>报道了使用 RGB 颜色直方图和向量量化 SIFT 描述符的直方图与线性 SVM，他们获得了 17.3%的分类精度。这是作为与更高级的技术(包括深度学习方法)进行比较的基础而产生的，并且是使用手工制作的特征和机器学习来解决图像分类问题的方法的示例(如图 4 的上图所示)。</p><p id="cd72" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">使用完整的未裁剪图像，他们实现了 10.3%的总体平均分类精度。在 2014 年，<a class="ae me" href="https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Goring_Nonparametric_Part_Transfer_2014_CVPR_paper.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="nl"> Goring 等人</em> </a>提出了一种基于非参数标签转移技术的细粒度识别方法，该方法从具有相似全局形状的对象中转移部分星座，实现了 57.8%的平均分类准确率。</p><figure class="ma mb mc md gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ok"><img src="../Images/a42dfaacf4e0f7c51b85c218c06fcbdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-ZIb6AFzYRhEzG99ffoEpA.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图 8:CUB-200–2011 数据集上表现最好的模型，来自<a class="ae me" href="https://paperswithcode.com/sota/fine-grained-image-classification-on-cub-200" rel="noopener ugc nofollow" target="_blank"><em class="oi">paperswithcode.com</em></a></p></figure><p id="0950" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">最近对细粒度图像分类的研究主要基于卷积神经网络方法。这些方法取得了相当好的精度，平均分类精度接近 90%(图 8；来自 paperswithcode.com 的关于 CUB-200–2011 的<a class="ae me" href="https://paperswithcode.com/sota/fine-grained-image-classification-on-cub-200" rel="noopener ugc nofollow" target="_blank">最佳性能算法的图表。例如，<em class="nl">崔等(2017)</em></a>演示了使用现代神经网络架构，获得明显更准确的预测。他们方法成功的关键部分是深度学习网络的使用，结合高分辨率图像训练和处理细粒度问题的长尾分布方面。它们还决定性地显示了使用领域特定的预训练数据集来提高较小的细粒度分类问题(如鸟类物种识别)的准确性的优势。</p><h1 id="2a4c" class="mf mg jf bd mh mi mj mk ml mm mn mo mp ku mq kv mr kx ms ky mt la mu lb mv mw bi translated">现代工具有什么可能？</h1><p id="cefd" class="pw-post-body-paragraph ld le jf lf b lg mx kp li lj my ks ll lm mz lo lp lq na ls lt lu nb lw lx ly ij bi nc translated">用最少的努力，我听到你说什么是真正可能的？<br/>在这组文章中，我们的目标是展示如何相对简单地访问最先进的图像分类模型，并获得接近当前领先网络的性能。正如本讨论所示，这种在细粒度图像分类问题上的性能在过去几年才成为可能。</p><p id="6a35" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在深入研究如何设置、训练和部署 PyTorch CNN 进行图像分类的细节之前，让我们先来看看使用一种相对简单的方法可以获得的结果。在接下来的文章中，我将与您分享为训练这些模型而开发的底层 python 代码的更多细节，但在这里，我想分享我在数据集上训练的所有不同网络架构的最终结果。</p><figure class="ma mb mc md gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ol"><img src="../Images/ad6709c05131c846bc54e10b258e44f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Knd1kc8I1iw7hKTzEHtxCw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图 9: PyTorch CNN 图像分类架构使用类宏平均度量的性能比较。在 ImageNet 上进行预训练，并使用 CUB-200–2011 进行进一步训练后，在 CUB-200–2011 数据集的测试集上进行评估。(图片由作者提供)</p></figure><p id="551d" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">图 9 显示了许多不同模型架构的性能，所有卷积神经网络(CNN)用于图像分类，在 CUB-200–2011 上训练。这些模型包括最早成功开发更深层次网络的模型架构之一，<strong class="lf jp"> GoogLeNet </strong>，由 Szegedy 等人(2014)在论文“<a class="ae me" href="https://arxiv.org/abs/1409.4842" rel="noopener ugc nofollow" target="_blank">用卷积深化</a>”中提出，以及最近的网络架构，包括<strong class="lf jp"> ResNeXt </strong>(谢等人 2017  之后的<a class="ae me" href="https://arxiv.org/abs/1611.05431" rel="noopener ugc nofollow" target="_blank">)和<strong class="lf jp"> PNAS 网</strong>(刘等人 2018<em class="nl">之后的<a class="ae me" href="https://arxiv.org/abs/1712.00559" rel="noopener ugc nofollow" target="_blank">)</a></em></a></p><p id="89b5" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">这个例子表明，即使在 3 到 4 年的发展空间内，这些网络的性能改进也是相当可观的。这里值得明确指出的是，这些模型之间的唯一区别是网络架构本身。训练和测试图像的选择以及图像增强过程和模型性能的评估对于所有相关的模型都是相同的。正是不同的网络架构使得最新的网络在分类性能方面取得了显著的进步。</p><p id="bbf3" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">请加入我即将发表的一系列文章，在这些文章中，我们将发现如何使用 python 和 PyTorch 来构建一个最先进的鸟类分类器，以产生如上所示的结果，以及了解它如何执行以及它如何做出决策的方法。</p></div><div class="ab cl om on hu oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="ij ik il im in"><p id="e51f" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">用来制作这组文章的代码和笔记本已经发布在<a class="ae me" href="https://github.com/ecm200/caltech_birds" rel="noopener ugc nofollow" target="_blank"> <strong class="lf jp"> Github 上，也可以在这里</strong> </a>找到。这些数据可以通过 Github 页面上的链接获得。</p><h1 id="9013" class="mf mg jf bd mh mi mj mk ml mm mn mo mp ku mq kv mr kx ms ky mt la mu lb mv mw bi translated">参考资料:</h1><ol class=""><li id="f423" class="nn no jf lf b lg mx lj my lm ot lq ou lu ov ly ns nt nu nv bi translated"><a class="ae me" href="https://arxiv.org/abs/1409.4842" rel="noopener ugc nofollow" target="_blank">塞格迪，C. <em class="nl">等</em>用回旋更深入。<em class="nl">arXiv:1409.4842【cs】</em>(2014)。</a></li><li id="32ce" class="nn no jf lf b lg nw lj nx lm ny lq nz lu oa ly ns nt nu nv bi translated"><a class="ae me" href="https://arxiv.org/abs/1611.05431" rel="noopener ugc nofollow" target="_blank">谢，s .，Girshick，r .，Dollár，p .，Tu，Z. &amp;何，k .深度神经网络的聚合残差变换。<em class="nl">arXiv:1611.05431【cs】</em>(2017)。</a></li><li id="98e5" class="nn no jf lf b lg nw lj nx lm ny lq nz lu oa ly ns nt nu nv bi translated"><a class="ae me" href="https://arxiv.org/abs/1803.01534" rel="noopener ugc nofollow" target="_blank">刘，s，齐，l，秦，h，石，J. &amp;贾，j .路径聚合网络实例分割。<em class="nl">arXiv:1803.01534【cs】</em>(2018)。</a></li><li id="a220" class="nn no jf lf b lg nw lj nx lm ny lq nz lu oa ly ns nt nu nv bi translated">Goering，c .、Rodner，e .、Freytag，A. &amp; Denzler，j .用于细粒度识别的非参数零件转移。在<em class="nl"> 2014 年 IEEE 计算机视觉和模式识别会议</em>2489–2496(IEEE，2014)。doi:<a class="ae me" href="https://doi.org/10.1109/CVPR.2014.319" rel="noopener ugc nofollow" target="_blank">10.1109/cvpr . 2014.319</a>。</li></ol><h1 id="a83b" class="mf mg jf bd mh mi mj mk ml mm mn mo mp ku mq kv mr kx ms ky mt la mu lb mv mw bi translated">背景阅读:</h1><p id="1784" class="pw-post-body-paragraph ld le jf lf b lg mx kp li lj my ks ll lm mz lo lp lq na ls lt lu nb lw lx ly ij bi translated">关于神经网络的背景参考材料，包括理论和实践，感兴趣的读者可以参考以下优秀资源。</p><p id="bb3e" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="lf jp">深度学习和神经网络实用指南:</strong></p><ol class=""><li id="dbeb" class="nn no jf lf b lg lh lj lk lm np lq nq lu nr ly ns nt nu nv bi translated">Rosebrock，A. <em class="nl">用 Python 进行计算机视觉的深度学习</em>。第 1–3 卷(2017 年)。</li><li id="1310" class="nn no jf lf b lg nw lj nx lm ny lq nz lu oa ly ns nt nu nv bi translated">Chollet，F. <em class="nl">用 Python 进行深度学习</em>。(曼宁出版公司，2018 年)。</li></ol><p id="5bde" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="lf jp">神经网络和深度学习的背景理论:</strong></p><ol class=""><li id="8969" class="nn no jf lf b lg lh lj lk lm np lq nq lu nr ly ns nt nu nv bi translated">神经网络和深度学习:一本教科书。(施普林格，2018)。</li><li id="1381" class="nn no jf lf b lg nw lj nx lm ny lq nz lu oa ly ns nt nu nv bi translated">模式识别和机器学习。(斯普林格，2006 年)。</li><li id="35f9" class="nn no jf lf b lg nw lj nx lm ny lq nz lu oa ly ns nt nu nv bi translated">古德费勒，我，本吉奥，y 和库维尔，A. <em class="nl">深度学习</em>。(麻省理工学院出版社，2016)。</li><li id="162a" class="nn no jf lf b lg nw lj nx lm ny lq nz lu oa ly ns nt nu nv bi translated">哈根，M. T .，德穆特，H. B .，比厄，M. H. &amp; De Jesus，O. <em class="nl">神经网络设计(第二版)</em>。(自我出版，2014)。</li></ol><p id="e88e" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="lf jp">通用机器学习背景理论与实践:</strong></p><ol class=""><li id="3334" class="nn no jf lf b lg lh lj lk lm np lq nq lu nr ly ns nt nu nv bi translated">数据分类:算法和应用。(查普曼&amp;霍尔/CRC，2015)。</li><li id="dba1" class="nn no jf lf b lg nw lj nx lm ny lq nz lu oa ly ns nt nu nv bi translated">统计学习的要素。(施普林格，2017)。</li><li id="c3c6" class="nn no jf lf b lg nw lj nx lm ny lq nz lu oa ly ns nt nu nv bi translated">Kuhn，m .和 Johnson，K. <em class="nl">应用预测建模</em>。(纽约施普林格出版社，2013 年)。doi:<a class="ae me" href="https://doi.org/10.1007/978-1-4614-6849-3" rel="noopener ugc nofollow" target="_blank">10.1007/978–1–4614–6849–3</a>。</li><li id="3a0b" class="nn no jf lf b lg nw lj nx lm ny lq nz lu oa ly ns nt nu nv bi translated">计算机时代的统计推断:算法、证据和数据科学。(剑桥大学出版社，2017)。</li><li id="59ce" class="nn no jf lf b lg nw lj nx lm ny lq nz lu oa ly ns nt nu nv bi translated">统计学习导论:在 R 中的应用。(施普林格，2013 年)。</li></ol></div></div>    
</body>
</html>