<html>
<head>
<title>Am I sure or unsure?— Uncertainty talks with a neural network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我是确定还是不确定？—不确定性与神经网络对话</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/am-i-sure-or-unsure-talks-with-a-neural-network-fc0e14d31373?source=collection_archive---------56-----------------------#2020-06-13">https://towardsdatascience.com/am-i-sure-or-unsure-talks-with-a-neural-network-fc0e14d31373?source=collection_archive---------56-----------------------#2020-06-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="3125" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">基于深度神经网络的后验概率分析</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/7bf727a42bb7dadb20f4441e10237eaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qvRtKQ28Ws_wSHNHYEsGMQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片[1]</p></figure><p id="faf7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果你的手机在提示你刚从后院摘的蘑菇是否有毒，最好确定一下！计算机视觉应用现在被神经网络的应用所主导。他们影响了我们每一个人的生活，因此，也增加了怀疑。关于这个黑匣子机器的可信任度，已经有很多<a class="ae lr" href="https://qz.com/1146753/ai-is-now-so-complex-its-creators-cant-trust-why-it-makes-decisions/" rel="noopener ugc nofollow" target="_blank">辩论</a>。一个模型让自己更值得信任的一个方法是告诉我们它对自己的决定有多确定，而不是仅仅说“这是我的决定”。</p><p id="5933" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">但是接下来的问题是，当前最先进的神经网络在<em class="ls">确定他们对自己的决定有多确信方面有多好。</em></p><p id="009b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">通过这篇文章，我们将了解—</p><ul class=""><li id="d24b" class="lt lu iq kx b ky kz lb lc le lv li lw lm lx lq ly lz ma mb bi translated">预测确定性对模型意味着什么[置信度校准]</li><li id="e955" class="lt lu iq kx b ky mc lb md le me li mf lm mg lq ly lz ma mb bi translated">我们如何衡量它？[可靠性图和ECE]</li><li id="a44b" class="lt lu iq kx b ky mc lb md le me li mf lm mg lq ly lz ma mb bi translated">为什么我们首先应该期望模型被校准？[地图，KL散度和交叉熵]</li></ul><h2 id="fa81" class="mh mi iq bd mj mk ml dn mm mn mo dp mp le mq mr ms li mt mu mv lm mw mx my mz bi translated">让我们开始我们的旅程——信心校准</h2><p id="468f" class="pw-post-body-paragraph kv kw iq kx b ky na jr la lb nb ju ld le nc lg lh li nd lk ll lm ne lo lp lq ij bi translated"><em class="ls">预测代表真实可能性的概率估计值的问题被称为置信度校准。</em>例如，给定100个预测，每个预测的置信度为0.8，我们预计其中80个应该被正确分类。衡量这一点最简单的方法是绘制一张置信度与准确度的曲线图。这就是所谓的<strong class="kx ir">可靠性图</strong>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/3a5e77e08ebf8228510acbf7f78ca7ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xkpGZHXwg_mRam8d"/></div></div></figure><p id="9c4f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这里的x轴是箱精度或正确样本的数量/该箱中的样本总数-</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/aee9170d041c2ed5bd4a7d390b50319d.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/0*GxvE74ltRAm4pdxI"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">箱精度</p></figure><p id="ca6b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">y轴是这个区间的置信度或平均概率</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/f150da6e30005d6e47d4e5feba1f0bf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:558/0*STbv38yIkTLzlhSq"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">置信度校准</p></figure><p id="4aba" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果置信度始终等于准确度，即<strong class="kx ir"> x=y线</strong>，则模型被<strong class="kx ir">完美校准。</strong>如果模型的校准图位于x=y(完美校准)线之上，这意味着它对正确类别给出了更高的概率估计，这使其<strong class="kx ir">过于自信</strong>。正确类别的较低概率估计意味着模型是<strong class="kx ir">不确定的。</strong></p><h2 id="f67f" class="mh mi iq bd mj mk ml dn mm mn mo dp mp le mq mr ms li mt mu mv lm mw mx my mz bi translated">校准分数—预期校准误差(ECE)</h2><p id="201b" class="pw-post-body-paragraph kv kw iq kx b ky na jr la lb nb ju ld le nc lg lh li nd lk ll lm ne lo lp lq ij bi translated">我们能把可靠性图转换成一个数字来比较不同型号的校准吗？</p><p id="cc6f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="ls">置信度和准确性之间的期望值差异</em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/c54d41e1662dd3edb3b3a9d800bff416.png" data-original-src="https://miro.medium.com/v2/resize:fit:648/0*RpNjBXabHJVusC5a"/></div></figure><p id="a2ab" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">直观上，它可以理解为模型的校准图和x=y线之间的差异，即完美的校准线。</p><h2 id="1623" class="mh mi iq bd mj mk ml dn mm mn mo dp mp le mq mr ms li mt mu mv lm mw mx my mz bi translated">真实交易——为什么我们一开始就应该期望对模型进行校准？</h2><p id="8b71" class="pw-post-body-paragraph kv kw iq kx b ky na jr la lb nb ju ld le nc lg lh li nd lk ll lm ne lo lp lq ij bi translated">我们通过由下式给出的最大似然估计(<strong class="kx ir"> MLE </strong>)来优化神经网络</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/7df1b7f392ed1b6b07041e0f4af7a317.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/0*KvLec9iQva7K4tpA"/></div></figure><p id="0690" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">即，在给定权重/模型参数的情况下，我们最大化数据的概率。如果我们添加一个正则项，我们可以看到MLE转化为最大后验概率(<strong class="kx ir"> MAP </strong>)估计。如果我们有W上的高斯先验，P(w)就是l2正则化，如果我们有W上的拉普拉斯先验，就是l1正则化。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/ab2d56cd3e980e878afdbfb9d1f494e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/0*odp_kQ959ea6JvZA"/></div></figure><p id="8cc7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="ls">我们希望模型输出的概率与数据的真实后验相匹配！我们需要一个损失函数来最小化模型输出的标签上的分布与数据的精确后验分布之间的距离(我们通过KL-divergence来最小化两个分布之间的距离)。</em></p><h2 id="1dfb" class="mh mi iq bd mj mk ml dn mm mn mo dp mp le mq mr ms li mt mu mv lm mw mx my mz bi translated">KL散度和损失函数</h2><p id="c314" class="pw-post-body-paragraph kv kw iq kx b ky na jr la lb nb ju ld le nc lg lh li nd lk ll lm ne lo lp lq ij bi translated">首先，我们来看看在单类分类looks的情况下，通常被‘取’为‘后验’的是什么。如果我们有两个类——一只猫和一只狗(请注意，这不代表数据的真实后验概率)。如果有一只狗，后半部分看起来像[0，1]，如果有一只猫，后半部分看起来像[1，0]。(在这种情况下，我们的后验看起来像一个<strong class="kx ir">德尔塔函数</strong></p><p id="aade" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这个二元分类任务的KL-散度可以由下式给出</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/c57b398e024654efcb3c5f01152d4490.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wMlabH5io3HwSfPO"/></div></div></figure><p id="3c50" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">其中x是输入图片，P是实际分布，P_theta是由我们的模型计算的。</p><p id="b376" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">平均KL散度可由下式给出—</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nm"><img src="../Images/b63c6445d8800082ef60dd85f57f2d25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hBAjCv-f_4n4o7_4"/></div></div></figure><p id="a88a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们已经可以看到这是优化神经网络最常用的损失函数的形式——交叉熵<em class="ls">。</em></p><p id="28f9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">进一步简化—</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/6223515ccab8f13f3509aab502c4db2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/0*Rq0feRkdo4jz3Gxs"/></div></figure><p id="d84b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因为第一项不依赖于θ项，因此不影响argmin_theta。由此得出的等式是交叉熵损失——</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/c2b1cefac9ae56354a2ce06f0a9aa474.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hUvStQ_i0V-UHqa9"/></div></div></figure><p id="685d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，最小化交叉熵等同于最小化模型输出和来自数据的后验之间的KL-散度。因此，从理论上讲，任何神经网络都应该被完美地校准(导致校准错误的原因有很多，让我们暂时把它留到另一篇文章中吧！)</p><p id="140a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[1]pymc<a class="ae lr" href="https://docs.pymc.io/notebooks/bayesian_neural_network_advi.html" rel="noopener ugc nofollow" target="_blank">https://docs . pymc . io/notebooks/Bayesian _ neural _ network _ advi . html</a></p><p id="a88e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[2]关于神经网络的标定<a class="ae lr" href="https://arxiv.org/pdf/1706.04599.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1706.04599.pdf</a></p></div></div>    
</body>
</html>