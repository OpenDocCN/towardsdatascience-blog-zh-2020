<html>
<head>
<title>Transcribr</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">转录器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/transcribr-9861c8de2f79?source=collection_archive---------22-----------------------#2020-02-14">https://towardsdatascience.com/transcribr-9861c8de2f79?source=collection_archive---------22-----------------------#2020-02-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="131a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">基于变压器的手写识别体系结构</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b54863140e2622ab4bf0f20b8df8a7d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BSaSpJ4e1znSO4aD_GaYrg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">[ <a class="ae ky" href="https://chimpsnw.org/2019/08/in-honor-of-odd-man-inn/" rel="noopener ugc nofollow" target="_blank">图像来源</a></p></figure><p id="b729" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数字化手写文档以改善存储、访问、搜索和分析是一个迫在眉睫的挑战。在深度学习革命之前，不存在以可扩展的方式实现这一目标的明确路径。</p><p id="3784" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随着计算机视觉和语言处理的进步，可靠的自动化手写识别指日可待。为此，我努力设计了一个实用的应用程序，平衡了准确性、可推广性和推理速度。这篇文章是对这一尝试的回顾，也是对设计选择和训练程序的解释。在这里查看一个演示<a class="ae ky" href="http://transcribr.net" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="4305" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">阅读手写文本是非常困难的。风格(如草书与印刷体和印刷体)、大小、间距、修饰和易读性之间存在极大的差异。拼写错误、划掉和遗漏也很常见。</p><p id="e2a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">解决这个问题的许多方法将任务分成3个独立的部分:分割、特征提取和分类。<em class="lv">【1，13，2】</em></p><ol class=""><li id="9630" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">检测和分割图像中的文本区域。</li><li id="b621" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">从每个文本片段中提取高维特征。</li><li id="4b9a" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">从给定的词汇(例如单词或字符)中对这些特征进行分类。</li></ol><p id="b927" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">鉴于手写的异质性，自动文本检测和分割可能容易出错，并且通常需要定制的预处理。另一种方法是将文本识别框架为序列对序列问题。二维图像输入和一维文本输出。NLP中表现最好的序列转导模型包括一个编码器-解码器结构，通常包括一个注意机制。其中最具革命性的可能是转换器架构<em class="lv">【3】</em>，它的独特之处在于它仅依赖于对输入和输出的编码表示，而不借助任何形式的递归或卷积。在这里可以找到对Transformer架构的一个很好的解释:<a class="ae ky" href="http://nlp.seas.harvard.edu/2018/04/03/attention.html" rel="noopener ugc nofollow" target="_blank">带注释的Transformer </a>。</p><p id="b301" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这并不是第一次尝试在端到端的方法中用注意力取代分段。<em class="lv">【5】</em>然而，我没有用注意力模块来增加传统的递归层，而是利用Transformer架构来超越以前的最先进的结果。亲自试用<a class="ae ky" href="http://transcribr.net" rel="noopener ugc nofollow" target="_blank">转录器应用</a>！</p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><h1 id="ff5d" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated"><strong class="ak">架构</strong></h1><p id="23f2" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">Transformer架构基于多头关注(“比例点积”)层，之后是按位置完全连接的网络。点积或乘法注意力比加法注意力更快(计算效率更高)，尽管在更大的维度上表现较差。缩放有助于调整乘法的收缩梯度。根据这篇论文，“多头注意力允许模型在不同位置共同关注来自不同表征子空间的信息。”编码器和解码器都利用自我关注层。解码器还包括编码器输出上的源注意力层。</p><h2 id="5efa" class="no ms it bd mt np nq dn mx nr ns dp nb li nt nu nd lm nv nw nf lq nx ny nh nz bi translated">图像适配器</h2><p id="e4e1" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">机器翻译(Transformer就是为机器翻译而设计的)和手写识别之间的显著区别在于，图像在输入到Transformer之前必须被处理成一个连续的表示。</p><p id="346b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为此，预训练的卷积神经网络(ResNet18)在最终的最大池层之前被截断，以输出空间特征图。沿空间维度对要素地图进行展平、归一化和转置，以创建粗略的一维表示序列。(<em class="lv">注</em> : ResNet18、ResNet34和Xception模型经过测试，精度没有显著差异。我选择了3个中最小的一个。)</p><h2 id="ebd5" class="no ms it bd mt np nq dn mx nr ns dp nb li nt nu nd lm nv nw nf lq nx ny nh nz bi translated">编码器</h2><p id="f80e" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">Transformer编码器中的自我关注有助于从图像适配器输出的扁平化空间表示中解析语义(和顺序)关系。</p><h2 id="f892" class="no ms it bd mt np nq dn mx nr ns dp nb li nt nu nd lm nv nw nf lq nx ny nh nz bi translated">解码器</h2><p id="0f43" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">变压器解码器是自动回归的，这意味着先前生成的令牌通过自我关注被考虑在内。为了加速训练，“之前生成的令牌”被实际的目标序列嘲讽(ala老师强制)。然后，解码器可以使用更高效的批量矩阵乘法来一次生成所有输出令牌，而不是进行推理所需的耗时的顺序解码。在注意力计算中使用字节掩码，以防止解码器在正在生成的内容之前关注位置。</p><h2 id="d18c" class="no ms it bd mt np nq dn mx nr ns dp nb li nt nu nd lm nv nw nf lq nx ny nh nz bi translated">序列的二维空间编码</h2><p id="a3de" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">因为转换器不使用任何卷积或递归，所以模型不包含内置的空间或顺序感知。需要位置编码。在原始论文中，使用了固定的正弦编码。作者推测，这将有助于模型学习相对位置，并推断出比训练中看到的更长的序列长度。</p><p id="2dad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">CNN具有隐含的位置感知，因此输入图像不需要额外的编码。然而，目标序列确实需要位置编码。有趣的是，当包含换行符(' \n ')时，多行段落有一个潜在的第二维度。利用这个换行符，我使用了一个已学习的二维空间编码方案，该方案基于离最近的换行符的距离(大约宽度)和自序列开始以来的换行符的数量(大约高度)。</p><p id="3a9f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">(<em class="lv">注:</em>语言模型也作为模型的补充进行了实验。一个预先训练的AWD-LSTM<em class="lv">【6】</em>语言模型产生了准确性的提高，但推理成本太大。双向转换编码器<em class="lv">【7】</em>语言模型是另一个潜在的选择。BERT结合了令牌两端的上下文，并且是非自回归的，这意味着推理时间的增加是最小的。由于GPU的限制，我用一个经过提炼的版本<em class="lv">【8】</em>进行了实验，但是即使在预训练之后也没有看到准确性的提高。)</p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><h1 id="3592" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated"><strong class="ak">数据</strong></h1><p id="6de8" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">这项任务的大部分训练都是基于流行的IAM手写数据库。该数据集由657位不同作者的1539页扫描手写文本组成。IAM是建立在20世纪70年代编纂的英国英语文本语料库(Lancaster-Oslo/Bergen)的基础上的。这些文本的内容跨越包括新闻报道，科学写作，散文和流行的传说体裁。</p><p id="bf63" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">理解深度学习算法性能受训练数据质量的约束；这个数据集对于现代的美式英语应用程序来说并不理想。然而，作为最大的公开可用的带注释的手写图像汇编，它是该领域中最受研究应用欢迎的数据集，并提供了与以前的体系结构的良好基线比较。</p><p id="210d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">除了1，539页的文本之外，数据集还被进一步分割成约13k行和约115k孤立词。这些额外的分段对于扩展训练数据集至关重要。</p><p id="0c14" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在扩展之前，需要对数据进行彻底检查，并手动纠正注释/分段错误。删除了15页的测试集，即大约1%的总数据。小测试规模并不理想，但数据集的整体规模较小，这是必要的。</p><h2 id="b28e" class="no ms it bd mt np nq dn mx nr ns dp nb li nt nu nd lm nv nw nf lq nx ny nh nz bi translated">单词组合</h2><p id="506c" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">通过组合从分词列表中随机选择的图像来创建第二数据集。从一个单词到4行，每行4个单词，以随机配置创建了50k个新图像。</p><h2 id="cf1d" class="no ms it bd mt np nq dn mx nr ns dp nb li nt nu nd lm nv nw nf lq nx ny nh nz bi translated">行连接</h2><p id="09bc" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">另一个数据集是通过连接随机选择的长度为3至13行的行图像(按高度归一化)而创建的。两万张这样的图片被制作出来。</p><h2 id="22c2" class="no ms it bd mt np nq dn mx nr ns dp nb li nt nu nd lm nv nw nf lq nx ny nh nz bi translated">合成字体</h2><p id="2f75" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">另一个策略是使用谷歌字体来创建类似手写文字的图像。来自维基百科、IMDB电影评论和开源书籍的文本使用95种不同大小的手写字体进行渲染，以创建大约129k不同长度的图像。背景噪声、模糊、随机填充/裁剪、像素倾斜等。以反映原始数据集以及一般手写文本的有机不规则性。</p><h2 id="7cc1" class="no ms it bd mt np nq dn mx nr ns dp nb li nt nu nd lm nv nw nf lq nx ny nh nz bi translated">下载的手写样本</h2><p id="3148" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">为了提高算法在IAM数据集之外的泛化性能，另一个数据集由161幅人工注释的图像构成，这些图像可在互联网上公开获得。这些图像用11种不同的图像调制组合进行处理，产生包含1771个图像的最终数据集。</p><h2 id="7713" class="no ms it bd mt np nq dn mx nr ns dp nb li nt nu nd lm nv nw nf lq nx ny nh nz bi translated">标记化</h2><p id="3b5e" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">对于涉及文本序列的任务，标记化至关重要。字符标记化有很多好处。字符大小是相对标准的。词汇表很小，几乎没有超出词汇表的标记。然而，字符推断是缓慢的(1000+字符的自回归顺序解码需要时间……)，并且如上所述，手写的异质性意味着字符经常重叠、难以辨认，甚至被省略。</p><p id="977d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">单词标记化是直观的，因为在人类阅读中，单词似乎优先于字符*。推理时间比用字符快得多。但是，为了限制词汇表外的标记，词汇表的大小必须非常大。</p><p id="98ff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一个固定长度的子词分词器<a class="ae ky" href="https://github.com/google/sentencepiece" rel="noopener ugc nofollow" target="_blank"> SentencePiece </a>被用作折衷。使用一个习得的、单字母语言模型编码<em class="lv">【9】，</em>，我创建了一个10k子词单位的词汇表。重要的是，添加了额外的特殊标记来表示空格、换行符、字母和单词的大写指示符以及标点符号。(<em class="lv">注意</em> : 10k、30k和50k词汇表都经过了测试，10k是性能最好的，同时保持模型占用空间较小。赢赢！)</p><p id="560f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">子词标记化提供了良好的推理速度、适中的词汇量和很少的词汇外标记。然而，文本图像显然不能划分成子词单元。我发现同时使用字符和子词标记进行训练有助于编码更健壮的特征表示，并提高两者的准确性。</p><p id="2511" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过一封特别的信向你传达一个爱好者的信息。TL；dr:而单词被识别为组块；人类阅读(尤其是在困难的条件下)包括单词和字符两个过程。] </p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><h1 id="e5f5" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated"><strong class="ak">培训</strong></h1><p id="f7c4" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">数据集被组合成3个连续的训练组。该模型首先在单词组合数据集(256像素的50k图像)上进行训练，以比较建筑设计决策，测试超参数设置，并为后面的组进行预训练。然后，该模型在合成字体生成的数据(512像素的129k图像)上进行训练，以读取长的、格式良好的文本序列。最终的手写数据集(25k图像，512像素)由主要的IAM页面图像、连接的行和下载的文本图像组成，用于微调手写文本的模型。</p><p id="6e2b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据增强包括:旋转、扭曲、对比度和亮度的随机变化。</p><h2 id="2ff7" class="no ms it bd mt np nq dn mx nr ns dp nb li nt nu nd lm nv nw nf lq nx ny nh nz bi translated">转录参数</h2><ul class=""><li id="4ef8" class="lw lx it lb b lc nj lf nk li oa lm ob lq oc lu od mc md me bi translated">模型尺寸:512</li><li id="93f4" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated">激活函数:GELU [10]</li><li id="2831" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated">层数:4</li><li id="1e4c" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated">注意头:8</li><li id="3870" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated">辍学率:0.1</li><li id="112a" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated">AdamW优化器[11]:(修复自适应梯度算法的权重衰减)</li><li id="c9e8" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated">最大学习率:1e–3(根据“1周期”政策[12]而变化)</li><li id="3a4d" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated">贝塔系数:(0.95，0.99)，ε:1e–8</li><li id="05d3" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated">动量:(0.95，0.85)</li><li id="883d" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated">重量衰减:1e–2</li><li id="212c" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated">标签平滑度:0.1</li></ul></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><h1 id="c739" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated"><strong class="ak">结果</strong></h1><p id="e5b2" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">以下与以前发表的架构的比较在科学上并不严谨，因为这个项目的目的是构建一个实用的工具，而不是发表一篇学术论文。因此，训练/测试分割并不是所有架构的标准，其他架构的结果基于预先分段的行级数据集，而Transcribr架构是针对整页数据集进行测量的。然而，使用公布的结果作为一个松散的比较，Transcribr架构证明是非常有竞争力的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/9f126033d0e4fe9b2cfef9f490f60fac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bkzC8zLgJw6-nBFHxd6SiQ.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/6dcf14102a51247aee79895c3956a904.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M0aVaY8DVECBcH6LrylM7g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自IAM手写测试数据集的4个图像的Transcribr(单词块令牌)结果</p></figure></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><h1 id="ab80" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated"><strong class="ak">局限性</strong></h1><p id="d4df" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">在这个项目中，我受到了一些限制。主要障碍是直接影响计算资源的预算。培训是在NVIDIA P6000 (24GB内存，3840个CUDA内核)上进行的。对<a class="ae ky" href="http://transcribr.net" rel="noopener ugc nofollow" target="_blank">转录应用</a>的推断是在一个只有1GB RAM的不起眼的1CPU上进行的，并且以可怜的大约3令牌/秒的速率转录图像:(</p><p id="805f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">(<em class="lv">注:</em>在一台2015款MacBook Pro上用4核16GB RAM进行本地测试推理，产生了约30令牌/秒的良好转录率。)</p><p id="79ae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据的数量和质量是另一个因素。合成数据和增强在实现这些结果方面至关重要，但仍然是多样化、高质量笔迹样本的拙劣替代品。当在包含不同的数据集外图像的测试集上测试时，Transcribr的性能相当差。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/c1b43ebbd024706ed71bb2a07423b80d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sNxOnomW11HTDeJDNdgq4w.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/c59f9ed44afcf550b4a3456dff06ae34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fMKK_DdDZ2RqLMFV3d8maA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">4个非数据集测试图像的转录结果</p></figure><p id="20be" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">架构选择优先考虑推理时间，而不是其他因素，包括准确性。为此，该模型尽可能保持精简，以大约50.8米的参数进行称重。使用贪婪解码代替更精确但昂贵的波束搜索。<a class="ae ky" href="http://transcribr.net" rel="noopener ugc nofollow" target="_blank">transcript br应用</a>使用不太准确但更快的单词片段标记化方案。</p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><h1 id="97f3" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated"><strong class="ak">结论</strong></h1><p id="53c8" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">我没有达到最初的目标，即构建一个有用的(快速、通用且准确的)工具。Transcribr既不快速也不通用:/可以使用量化和提取等技术来进一步减小模型大小，将python模型转换为C++将加快推理速度。从更多种类的来源和上下文中收集更多的手写图像将提高概括的准确性。</p><p id="bd4f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，从学术数据集的狭窄范围来看，我的结果令人鼓舞。我使用的一些新技术包括:</p><ul class=""><li id="f075" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu od mc md me bi translated">使用转换器架构进行手写识别</li><li id="481c" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated">基于换行符的2d学习位置编码(' \n ')</li><li id="fe75" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated">句子片段标记化，而不是单词或字符</li><li id="91aa" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated">同时训练令牌和字符解码器</li><li id="8469" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated">使用手写字体生成合成数据</li></ul><p id="fdc3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些技术使Transcribr的表现超过了之前发表的结果，并表明即使是财力不足的独立研究人员也可以帮助推动深度学习的边界(研究，如果不是实际的话)。</p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><h1 id="d669" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated">更新(2020年3月)</h1><p id="66b1" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">量化和TorchScript序列化将模型大小从203MB减少到21MB，并将转录速率提高到更合理的约15令牌/秒。生产应用程序现在大约需要10秒来处理测试集中的图像，而不是以前可怕的1分钟。巨大的进步！</p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><h1 id="8d7d" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated"><strong class="ak">链接</strong></h1><ul class=""><li id="eb71" class="lw lx it lb b lc nj lf nk li oa lm ob lq oc lu od mc md me bi translated"><a class="ae ky" href="http://transcribr.net" rel="noopener ugc nofollow" target="_blank">转录应用</a></li><li id="b86b" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated"><a class="ae ky" href="https://github.com/ahs8w/Handwriting/blob/master/1--Transcribr.ipynb" rel="noopener ugc nofollow" target="_blank"> Github笔记本</a></li><li id="5ca4" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated"><a class="ae ky" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> Pytorch </a></li><li id="9368" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated"><a class="ae ky" href="https://fast.ai/" rel="noopener ugc nofollow" target="_blank"> Fast.ai </a></li><li id="f522" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated"><a class="ae ky" href="https://github.com/huggingface/transformers" rel="noopener ugc nofollow" target="_blank">蒸馏器库</a></li><li id="8cf4" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated"><a class="ae ky" href="https://github.com/google/sentencepiece" rel="noopener ugc nofollow" target="_blank">句子片断标记器</a></li></ul></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><ul class=""><li id="d152" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu od mc md me bi translated">[1] J. Chung &amp; T. Delteil，“一种计算高效的全页脱机手写文本识别流水线方法<a class="ae ky" href="https://arxiv.org/pdf/1910.00663.pdf" rel="noopener ugc nofollow" target="_blank">”，2019年</a></li><li id="fc95" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated">[2] C. Wigington等人，“<a class="ae ky" href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Curtis_Wigington_Start_Follow_Read_ECCV_2018_paper.pdf" rel="noopener ugc nofollow" target="_blank">开始、跟随、阅读:端到端全页手写识别</a>”，2018</li><li id="324d" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated">[3] A. Vaswani等人，“<a class="ae ky" href="https://arxiv.org/pdf/1706.03762.pdf" rel="noopener ugc nofollow" target="_blank">注意力是你所需要的全部</a>，2017</li><li id="5a5e" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated">[4] T. Bluche，“<a class="ae ky" href="https://arxiv.org/pdf/1604.08352.pdf" rel="noopener ugc nofollow" target="_blank">用于端到端手写段落识别的联合行分割与转录</a>”，2016</li><li id="8c11" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated">[5] T. Bluche等人，“<a class="ae ky" href="https://arxiv.org/pdf/1604.03286.pdf" rel="noopener ugc nofollow" target="_blank">扫描、出席和阅读:带MDLSTM注意力的端到端手写段落识别</a>”，2016</li><li id="2ce3" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated">[6] S. Merity等人，“<a class="ae ky" href="https://arxiv.org/pdf/1708.02182.pdf" rel="noopener ugc nofollow" target="_blank">正则化和优化LSTM语言模型</a>”，2017</li><li id="d9e1" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated">[7] J. Devlin等人，“<a class="ae ky" href="https://arxiv.org/pdf/1810.04805.pdf" rel="noopener ugc nofollow" target="_blank"> BERT:用于语言理解的深度双向变换器的预训练</a>”，2019</li><li id="b2d8" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated">[8] V. Sanh等人，“<a class="ae ky" href="https://arxiv.org/pdf/1910.01108.pdf" rel="noopener ugc nofollow" target="_blank">蒸馏伯特，伯特的蒸馏版本:更小、更快、更便宜、更轻</a>”，2020年</li><li id="db88" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated">[9] T. Kudo，“<a class="ae ky" href="https://arxiv.org/pdf/1804.10959.pdf" rel="noopener ugc nofollow" target="_blank">子词正则化:用多个候选子词改进神经网络翻译模型</a>”，2018</li><li id="2e83" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated">[10] D. Hendrycks &amp; K. Gimpel，“高斯误差线性单位(GELUS) ”，2018年</li><li id="0f87" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated">[11] I. Loshchilov &amp; F. Hutter，“解耦权重衰减正则化<a class="ae ky" href="https://arxiv.org/pdf/1711.05101.pdf" rel="noopener ugc nofollow" target="_blank">”，2019年</a></li><li id="2c2c" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated">[12] L. Smith，“<a class="ae ky" href="https://arxiv.org/pdf/1803.09820.pdf" rel="noopener ugc nofollow" target="_blank">神经网络超参数的规范方法:第1部分—学习速率、批量大小、动量和权重衰减</a>”，2018年</li></ul></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><ul class=""><li id="4b4c" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu od mc md me bi translated">[13] <a class="ae ky" href="https://blogs.dropbox.com/tech/2017/04/creating-a-modern-ocr-pipeline-using-computer-vision-and-deep-learning/" rel="noopener ugc nofollow" target="_blank">使用计算机视觉和深度学习创建现代OCR管道</a></li><li id="ec55" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated"><a class="ae ky" href="http://nlp.seas.harvard.edu/2018/04/03/attention.html" rel="noopener ugc nofollow" target="_blank">带注释的变压器</a></li><li id="8de4" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated"><a class="ae ky" href="http://www.fki.inf.unibe.ch/databases/iam-handwriting-database" rel="noopener ugc nofollow" target="_blank"> IAM手写数据库</a></li><li id="c4f8" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu od mc md me bi translated">迪库松夫人</li></ul></div></div>    
</body>
</html>