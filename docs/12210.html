<html>
<head>
<title>Running Deep Learning Algorithms as a Service</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">将深度学习算法作为服务运行</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/serving-deep-learning-algorithms-as-a-service-6aa610368fde?source=collection_archive---------12-----------------------#2020-08-23">https://towardsdatascience.com/serving-deep-learning-algorithms-as-a-service-6aa610368fde?source=collection_archive---------12-----------------------#2020-08-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="01b8" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">现实世界中的 DS</h2><div class=""/><div class=""><h2 id="e050" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">如何将深度学习算法作为服务</h2></div><p id="baff" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">所以，你想把深度学习算法作为服务来服务。</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ln"><img src="../Images/046b84e5dbe34224b64ba28003918570.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Jdc8txGJ5Xf2Ayqu"/></div></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">马里乌斯·马萨拉尔在<a class="ae md" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="ea4c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">你有一个用 Python 和 tensor flow/Keras/一些其他平台编写的非常酷的算法库，它需要在 GPU 上运行工作负载，你希望能够大规模地服务它，并让它快速运行。</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="me mf l"/></div></figure><p id="fb6e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><a class="ae md" href="https://docs.celeryproject.org/en/stable/" rel="noopener ugc nofollow" target="_blank">芹菜</a>是基于分布式消息传递的开源异步任务队列。在阅读了所有可能的博客帖子和 Youtube 上所有关于芹菜的视频后，我决定这是手头任务的正确解决方案。</p><p id="91cc" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">有请我们的剧情主角:</p><ol class=""><li id="0bda" class="mg mh it kt b ku kv kx ky la mi le mj li mk lm ml mm mn mo bi translated">API :获取一个请求，创建一个 Celery 异步任务，并将其放入一个队列中。(我推荐使用 flask 来完成这项任务，它很轻，但是可以扩展)</li><li id="8eef" class="mg mh it kt b ku mp kx mq la mr le ms li mt lm ml mm mn mo bi translated"><strong class="kt jd">消息队列</strong>:又名芹菜的经纪人。将 API 创建的任务存储在队列中。最好的做法是选择 RabbitMQ。</li><li id="c908" class="mg mh it kt b ku mp kx mq la mr le ms li mt lm ml mm mn mo bi translated"><strong class="kt jd"> Workers </strong>:我们将在 GPU 上运行的 python/celery 进程，它将从队列中获取任务。这是完成所有繁重工作的地方。</li><li id="5aa1" class="mg mh it kt b ku mp kx mq la mr le ms li mt lm ml mm mn mo bi translated"><strong class="kt jd">结果的后端</strong>:将存储任务返回值。最佳实践是使用 redis，它支持复杂的工作流(一个任务依赖于另一个任务)而无需轮询。</li></ol><p id="ff3c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">最佳实践是使用 Celery，用<a class="ae md" href="https://www.rabbitmq.com/" rel="noopener ugc nofollow" target="_blank"> RabbitMQ </a>作为消息的代理，用<a class="ae md" href="https://redis.io/" rel="noopener ugc nofollow" target="_blank"> redis </a>作为结果的后端，以便使用 Celery 能够提供的所有独特特性。我们知道软件需求的变化经常比我们预期的要快，这应该给我们提供最大的灵活性，这样我们甚至可以使用芹菜最复杂的特性。当选择 RabbitMQ 和 redis 时，每个新任务都被转换成一条消息，然后 Celery 将这条消息发送到 RabbitMQ 中的一个队列，一个工人执行的任务的每个返回值都会自动写回 redis(您可以使用"<a class="ae md" href="https://console.cloud.google.com/marketplace/details/google/rabbitmq?pli=1" rel="noopener ugc nofollow" target="_blank"> click to deploy </a>"在 GCP 上轻松托管 RabbitMQ，使用<a class="ae md" href="https://aws.amazon.com/elasticache/" rel="noopener ugc nofollow" target="_blank"> AWS Elastic Cache </a>托管 redis)。</p><p id="74c9" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">一旦表示任务的消息在队列中，我们需要一个 GPU 工作器来计算它。GPU 工作器将从队列中读取一条消息并执行任务。例如，如果这是一个计算机视觉算法，一名工作人员将从 S3 自动气象站下载原始图像，对其进行处理，然后将新图像上传回 S3。图像的 URL 将作为任务的一部分被传递。</p><p id="fc85" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">但是等等，有个问题。</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="mu mf l"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">总有一个陷阱。</p></figure><p id="cdec" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">GPU 是非常昂贵的机器。P2 的一个例子。AWS 中的 Xlarge 每月花费超过 2，000 美元(在写这几行的时候，<a class="ae md" href="https://aws.amazon.com/ec2/instance-types/p3/" rel="noopener ugc nofollow" target="_blank"> 3.06 美元一小时</a>),如果是 spot 实例，大约 600 美元。这显然意味着，如果没有必要，我们不希望它们一直处于运行状态。它们必须按需开启，然后关闭。事实是，Elastic Beanstalk 没有根据 RabbitMQ 队列指标自动伸缩的特性。</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="mu mf l"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">我们该怎么办？</p></figure><p id="e382" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们必须编写自己的自定义自动缩放器。这是一个小 Python 脚本的大名，它每 30 秒运行并轮询 RabbitMQ 队列中的任务数。如果队列中有消息，它会调用 AWS API 并相应地启动 GPU workers。</p><p id="01f3" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">每个工人都是用算法库的 docker 容器引导的(存储在 ECR，弹性容器注册表中)。一旦容器启动并运行，它就连接到 RabbitMQ 和 redis。然后，它从队列中取出一个任务并计算它。输出由工人写给 S3。如果任务成功完成，那么芹菜任务的返回值是一个 json，包含保存到 S3 的输出的 URL 及其元数据。Celery 会自动将返回值保存到 redis 中，也会保存到 Postgres DB 中。如果任务未能完成，异常将保存到 redis。</p><p id="045c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">查看下图，了解上面解释的架构:</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi mv"><img src="../Images/aa6700f0d1dc6951c0fe0386093326fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1KCBkoo8k_heT7zTnXWqvQ.png"/></div></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">Nir Orman 将深度学习算法作为服务运行</p></figure></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><p id="1413" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">听起来很轻松？使用芹菜的一个主要挑战是如何正确配置它。</p><p id="1737" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这里有一个很好的配置，当你试图大规模执行深度学习任务时，它可以节省你的时间和眼泪。请查看以下内容，然后我们将深入了解它的每个细节:</p><pre class="lo lp lq lr gt nd ne nf ng aw nh bi"><span id="be27" class="ni nj it ne b gy nk nl l nm nn">from celery import Celery<br/>from api.celery_jobs_app.celery_config import BROKER_URI, BACKEND_URI<br/><br/>APP = Celery(<br/>    'celery_app',<br/>    broker=BROKER_URI,<br/>    backend=BACKEND_URI,<br/>    include=['api.celery_jobs_app.tasks']<br/>)<br/><br/>APP.conf.update({<br/>    'imports': (<br/>        'api.celery_jobs_app.tasks.tasks'<br/>    ),<br/>    'task_routes': {<br/>        'calculate-image-task': {'queue': 'images-queue'}<br/>        }<br/>    },<br/>    'task_serializer': 'json',<br/>    'result_serializer': 'json',<br/>    'accept_content': ['json'],<br/>    'worker_prefetch_multiplier': 1,<br/>    'task_acks_late': True,<br/>    'task_track_started': True,<br/>    'result_expires': 604800,  # one week<br/>    'task_reject_on_worker_lost': True,<br/>    'task_queue_max_priority': 10<br/>})</span></pre><blockquote class="no np nq"><p id="0f4d" class="kr ks nr kt b ku kv kd kw kx ky kg kz ns lb lc ld nt lf lg lh nu lj lk ll lm im bi translated"><strong class="kt jd">注</strong>:为了更容易理解，对配置进行了简化。</p></blockquote><p id="6c82" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们来分解一下。</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="me mf l"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">打破它！</p></figure><p id="2e43" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">片段中的第一段只是一些导入，微不足道。</p><p id="4153" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">第二段定义了芹菜 app 本身，它有一个代理和后端(如前所述，最佳实践是使用 RabbitMQ 和 redis)。</p><p id="e8d7" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">第三段更新了芹菜的配置，这是有趣的部分。</p><p id="a28e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">“<strong class="kt jd">导入</strong>”部分说明了芹菜应该在我们的哪个 python 包中寻找任务。</p><p id="fa86" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">'<strong class="kt jd"> tasks_routes </strong>'部分在任务名称和它应该被存储的队列之间进行映射。在上面的代码片段中，所有类型为“<em class="nr">计算-图像-任务</em>”的任务将被推入一个名为“<em class="nr">图像-队列</em>”的队列中。如果你不写你的任务应该被路由到哪个队列，它将默认地被路由到名为‘celery’的默认队列。顺便说一句，如果你愿意，可以通过定义“task_default_queue”属性来更改默认队列的名称。</p><p id="5b04" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">仅供参考:一旦第一个任务被路由到 RabbitMQ 上，队列本身就会自动创建。酷:)</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="nv mf l"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">酷毙了。</p></figure><p id="e040" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><a class="ae md" href="https://docs.celeryproject.org/en/stable/userguide/configuration.html#task-serializer" rel="noopener ugc nofollow" target="_blank"><strong class="kt jd">task _ serializer</strong></a>’:这是任务一旦被放入队列后将被序列化的方式，也是任务到达工作线程后被反序列化的方式。在图像处理的情况下，我们不希望图像本身被序列化和反序列化，最佳实践是存储它并只传递它的位置或 URL。我们将使用 json 作为序列化器。</p><p id="a591" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><a class="ae md" href="https://docs.celeryproject.org/en/stable/userguide/configuration.html#result-serializer" rel="noopener ugc nofollow" target="_blank"><strong class="kt jd">result _ serializer</strong></a><strong class="kt jd">’:</strong>请记住，如果您将序列化类型声明为 json 并返回一个对象或异常的结果(这是在出现未被捕获的异常的情况下的返回类型)，那么您的结果序列化将会抛出一个异常，因为任何不是 json 的对象都会抛出一个未能序列化的异常。你可以在这里阅读更多关于连载器的内容。</p><p id="a866" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">'</strong><a class="ae md" href="https://docs.celeryproject.org/en/stable/userguide/configuration.html#accept-content" rel="noopener ugc nofollow" target="_blank"><strong class="kt jd">accept _ content</strong></a><strong class="kt jd">':</strong>允许的内容类型/序列化程序的白名单。</p><p id="e434" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">提示</strong>:不推荐使用‘pickle’序列化器，因为它存在安全问题。从芹菜 4.0 版开始，json 其实就是序列化的默认选项，但是“显式比隐式好”(<a class="ae md" href="https://en.wikipedia.org/wiki/Zen_of_Python" rel="noopener ugc nofollow" target="_blank">Python 的禅宗</a>)。</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/16774dc8727e48dc2c142eaf84919cc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/0*eY1HwhtnS848f9Wp.jpg"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">Python 的禅</p></figure><p id="d828" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><a class="ae md" href="https://docs.celeryproject.org/en/stable/userguide/configuration.html#std:setting-worker_prefetch_multiplier" rel="noopener ugc nofollow" target="_blank"><strong class="kt jd">worker _ prefetch _ multiplier</strong></a>’:Celery 的缺省值是每个 worker 接受 4 个任务，并在返回进行下一个任务之前计算完所有任务。他们的想法是优化网络往返。在我们的情况下，深度学习任务往往很长(比网络时间长得多)。这意味着我们不希望一个工人拿着一堆任务，一个接一个地执行它们。我们希望每个工人一次接受一个<strong class="kt jd">单</strong>任务，然后在前一个任务完成后回来接受下一个任务。这样，如果一个任务需要很长的计算时间，其他工作人员可以同时处理下一个任务，因为只要第一个工作人员没有处理它们，它们就会被保留在队列中。</p><p id="9d81" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">'</strong><a class="ae md" href="https://docs.celeryproject.org/en/stable/userguide/configuration.html#task-acks-late" rel="noopener ugc nofollow" target="_blank"><strong class="kt jd">task _ acks _ late</strong></a><strong class="kt jd">':</strong>默认情况下，当工人接受一个任务时，该任务会在 执行前<strong class="kt jd"> <em class="nr">被“确认”。在深度学习任务的情况下，这需要很长时间来计算，我们希望它们只在计算完</em> </strong>之后<strong class="kt jd"> <em class="nr">被“确认”。这在我们使用<a class="ae md" href="https://aws.amazon.com/ec2/spot/" rel="noopener ugc nofollow" target="_blank"> spot 实例</a>时特别有用，它降低了我们的平均任务价格，但如果 GPU 实例短缺，并且我们的投标价格不够有竞争力，也可能会失去它。</em></strong></p><p id="c57e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><a class="ae md" href="https://docs.celeryproject.org/en/stable/userguide/configuration.html#task-track-started" rel="noopener ugc nofollow" target="_blank"><strong class="kt jd">task _ track _ started</strong></a>’:有助于跟踪任务已经开始，因为当您的任务长时间运行时，您希望知道它不再在队列中(它将被标记为“pending”)。)我推荐使用<a class="ae md" href="https://flower.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> Flower </a>作为芹菜的监控解决方案，它可以让你确切地看到每个任务的状态。</p><p id="785d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><a class="ae md" href="https://docs.celeryproject.org/en/stable/userguide/configuration.html#result-expires" rel="noopener ugc nofollow" target="_blank"><strong class="kt jd">result _ expires</strong></a>’:默认情况下，芹菜在 redis 上只保留你的结果 1 天。如果您希望保留更长时间，请在配置文件中以不同方式定义“result_expires”。我建议最多保留 1 周，并将结果写入一个更有组织的数据库，比如 PostgreSQL。</p><p id="04c2" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><a class="ae md" href="https://docs.celeryproject.org/en/stable/userguide/configuration.html#task-reject-on-worker-lost" rel="noopener ugc nofollow" target="_blank"><strong class="kt jd">【task _ reject _ on _ worker _ lost</strong></a>’:我们将此设置为 True。当我们使用 spot 实例时，当一个 spot 实例从我们身边拿走时，有可能会丢失一个工人。我们希望将任务放回队列中，由另一个工作者来计算。小心，如果一个工人丢失是由于硬件错误，如“内存不足”等。，那么任务将在一个循环中一次又一次地被部分计算，因为工作者将在每次试图计算它时丢失。如果您看到一个无限循环的任务，这就是您应该怀疑的配置。</p><p id="11ce" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">task _ queue _ max _ priority</strong>’:这是你可以确保重要任务先完成的地方。您可以为每个 Celery 任务设置一个优先级(通过给它分配一个表示其优先级的 int)。如果设置该属性，还必须将其设置到 RabbitMQ 队列中，它不会自动设置。如果具有优先级的任务进入没有 priority 属性的队列，将会引发异常，并且该任务不会进入队列。如果您有一个任务应该首先计算的高级客户，则此属性很有用。</p><p id="2e59" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如果您正在考虑使用该属性，以便将快速运行的任务优先于慢速任务(例如长 GPU 计算任务)，那么可以考虑添加另一组工作人员，即 CPU 工作人员，而不是昂贵的 GPU 工作人员。这会更便宜也更快。</p><p id="1ba4" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">正如您在顶部的架构图中看到的，您也可以让工作人员在完全不同的云上运行。</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="nx mf l"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">完全不同的云</p></figure><p id="9237" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">例如，您可以在 Azure AKS 上运行您的员工，这是 Azure 的 Kubernetes。但那是一篇完全不同的博文。</p><p id="fc6d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">祝你用芹菜服务你的深度学习算法好运，如果你有任何问题，请随时在<a class="ae md" href="https://il.linkedin.com/in/nir-orman" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上联系我。</p></div></div>    
</body>
</html>