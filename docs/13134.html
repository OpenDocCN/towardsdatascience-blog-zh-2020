<html>
<head>
<title>4 Unique Approaches To Manage Imbalanced Classification Scenarios</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">管理不平衡分类场景的 4 种独特方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/4-unique-approaches-to-manage-imbalance-classification-scenario-7c5b92637b9c?source=collection_archive---------24-----------------------#2020-09-09">https://towardsdatascience.com/4-unique-approaches-to-manage-imbalance-classification-scenario-7c5b92637b9c?source=collection_archive---------24-----------------------#2020-09-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="85dd" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" rel="noopener" target="_blank" href="https://towardsdatascience.com/machine-learning/home">内部 AI </a></h2><div class=""/><div class=""><h2 id="b523" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">大多数业务案例都与预测少数群体事件有关，如欺诈、联合检测等。基于不平衡数据训练的机器学习模型对罕见事件的预测精度非常差。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/f7f261c7675c272823e110f996392dd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*WUdU1ovTNEoLyrlt"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">由<a class="ae lh" href="https://unsplash.com/@ammarelamir?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">阿马尔·埃拉米尔</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="5f2a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在数十亿笔金融交易中，只有少数涉及欺骗和欺诈。在公路上行驶的数百万辆汽车中，只有少数在公路中间抛锚，其余的都开得很好。如果我们密切关注我们的日常活动，那么也可以发现一些例外事件。相同的倾斜数据存在于许多数据点中，其中一个或几个类别覆盖了大多数情况。</p><p id="bbed" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当我们向机器学习算法提供这些不平衡的数据点时，少数多数类会以忽略少数类为代价产生严重影响。大多数业务案例都与预测少数群体事件有关，如欺诈、联合检测等。在不平衡数据上训练的机器学习模型对罕见事件的预测精度非常差。</p><p id="d94c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在本文中，我将讨论处理不平衡数据集和提高少数类预测准确性的四种独特方法。此外，我们还将了解为什么仅考虑分类指标分数(如 F1 分数或准确度)会误导罕见事件预测中的模型预测性能。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="d9a8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将使用<strong class="lk jd"> <em class="ml"> Scitkit-Learn </em> </strong>中的 make_classification 方法来生成不平衡数据集。</p><pre class="ks kt ku kv gt mm mn mo mp aw mq bi"><span id="a436" class="mr ms it mn b gy mt mu l mv mw">import pandas as pd<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.datasets import make_classification<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.metrics import f1_score,accuracy_score<br/>from sklearn.metrics import plot_confusion_matrix<br/>import matplotlib.pyplot as plt</span></pre><p id="d1bd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将学习五种独特的方法来处理 5000 个样本的不平衡数据集，其中一个类包含 98%的案例。</p><pre class="ks kt ku kv gt mm mn mo mp aw mq bi"><span id="f786" class="mr ms it mn b gy mt mu l mv mw">X, y = make_classification(n_samples=5000,weights=[0.02, 0.98],<br/>                           random_state=0,n_clusters_per_class=1)</span><span id="3aa6" class="mr ms it mn b gy mx mu l mv mw">ycount=pd.DataFrame(y)<br/>print(ycount[0].value_counts())</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi my"><img src="../Images/d275cbb5a3647e50e5178980ce2fdfd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T9R4PPaSCZCXEjXJCoVsjw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">样本数据集中多数类和少数类的比例(上面代码的输出)</p></figure><p id="0969" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在 5000 个样本记录中，我们有 4871 个 1 类记录和 129 个 0 类记录。让我们考虑等级 1 表示正常交易，等级 0 表示欺诈交易。</p><p id="5789" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">样本数据集分为两部分，即。训练和测试设备。训练集是训练机器学习模型，测试集是检验模型的预测。</p><p id="1fc4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将使用 80%的样本数据集来训练模型，剩余的 20%模型以前没有见过的记录保留给测试集。</p><pre class="ks kt ku kv gt mm mn mo mp aw mq bi"><span id="41c5" class="mr ms it mn b gy mt mu l mv mw">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42,stratify=y)</span></pre><p id="7096" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了理解不平衡数据集甚至对像随机森林分类器这样的复杂算法的影响，让我们首先用不平衡训练集直接训练标准随机森林分类器，并且没有任何权重参数。</p><pre class="ks kt ku kv gt mm mn mo mp aw mq bi"><span id="d1d1" class="mr ms it mn b gy mt mu l mv mw">clf =RandomForestClassifier(max_depth=2,random_state=0).fit(X_train, y_train)</span><span id="0c45" class="mr ms it mn b gy mx mu l mv mw">print("F1 Score is ", f1_score(y_test,clf.predict(X_test)))<br/>print("Accuracy Score is ", accuracy_score(y_test,clf.predict(X_test)))</span></pre><p id="735e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">经过训练的随机森林分类器模型在测试数据集上的 F1 分和准确率分都很高。但是，在不平衡数据集的情况下，仅考虑这些度量来判断模型的预测性能可能是非常误导的。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi mz"><img src="../Images/106a45af92fb5cd307e7819225999433.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AkaBUHETMa80oFs5fEl16A.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">F1 和在不平衡数据集上训练的随机森林分类器的准确度分数(上述代码的输出)</p></figure><p id="7ca3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">仅基于这两个指标部署这样一个模型，而不了解分类模型在哪些方面出错，成本可能会非常高。</p><p id="9ebd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">像混淆矩阵这样的视觉指标在几个方面胜过其他指标。我们可以即时了解模型在分类方面的性能，以及模型的优势和需要微调的方面。基于业务用例，我们可以从假阳性、假阴性、真阳性和真阴性计数中快速判断模型是否准备好进行部署。</p><p id="bf76" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">您可以在文章<a class="ae lh" rel="noopener" target="_blank" href="/accuracy-visualisation-supervised-machine-learning-classification-algorithms-af13d18fcc6c">准确性可视化:监督机器学习分类算法</a>中深入了解混淆矩阵</p><pre class="ks kt ku kv gt mm mn mo mp aw mq bi"><span id="c687" class="mr ms it mn b gy mt mu l mv mw">fig=plot_confusion_matrix(clf, X_test, y_test)<br/>plt.show()</span></pre><p id="d093" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">正如预期的那样，多数类已经完全影响了模型，并且经过训练的模型已经将测试数据集中所有记录的分类预测为多数类。在罕见的欺诈检测或罕见的恶性疾病预测的情况下，这种错误分类预测是非常有害的。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi na"><img src="../Images/f37b0cc4cde58093c7cacf02e221d27c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LM9gRcczNQRwc3c2dOrAAw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">通过在不平衡数据集上训练的随机森林分类器预测测试数据集的混淆矩阵(上述代码的输出)</p></figure><p id="ab3a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">幸运的是，Random Forrest 分类器有一个参数“class_weight ”,用于在不平衡数据集的情况下指定每个类的权重。</p><p id="3124" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在样本数据集中，类 1 比类 0 普遍大约 38 倍。因此，我们将按这样的比例提及“类权重”,以便算法在训练期间进行补偿。</p><pre class="ks kt ku kv gt mm mn mo mp aw mq bi"><span id="0e41" class="mr ms it mn b gy mt mu l mv mw">weighted_clf = RandomForestClassifier(max_depth=2, random_state=0,<strong class="mn jd">class_weight={0:38,1:1}</strong>).fit(X_train, y_train)</span><span id="73b1" class="mr ms it mn b gy mx mu l mv mw">print("F1 Score for RandomForestClassifier with class_weight parameter is ", f1_score(y_test,weighted_clf.predict(X_test)))</span><span id="fda9" class="mr ms it mn b gy mx mu l mv mw">print("Accuracy  Score for RandomForestClassifier with class_weight parameter is ", accuracy_score(y_test,weighted_clf.predict(X_test)))</span></pre><p id="3615" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">具有类别权重补偿的随机森林分类器模型的 F1 分数和准确度分数也很高，但是我们可以通过检查混淆矩阵来确定真实性能。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nb"><img src="../Images/fec2b18f245368c19fac9b9756da7ef5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qEFdh3UuwPRwKWaFYruB5A.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">F1 和在具有<strong class="bd nc"> class_weight </strong>参数的类优化数据集上训练的随机森林分类器的准确度分数(上述代码的输出)</p></figure><p id="3fe4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们可以看到，大多数类还没有完全超越权重调整的随机森林分类器模型。</p><pre class="ks kt ku kv gt mm mn mo mp aw mq bi"><span id="aa20" class="mr ms it mn b gy mt mu l mv mw">fig=plot_confusion_matrix(weighted_clf, X_test, y_test)<br/>plt.show()</span></pre><p id="76a2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在测试数据集中总共 1000 条记录中，它只错误分类了 14 条记录。此外，它还对测试数据集中 26 个少数类记录中的 20 个少数类样本记录进行了正确分类。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nd"><img src="../Images/61dc63d264b1f3ef66a69c4b51b0df54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hUtiXg20YXu7IHiHF-vRXA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">在权重优化数据集上训练的随机森林分类器预测测试数据集的混淆矩阵(上述代码的输出)</p></figure><p id="8939" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们学习了在随机 Forrest 分类器中处理带有 class_weight 参数的不平衡数据集的方法，提高了少数类的预测精度。</p><p id="f54a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">接下来，我们将学习使用不平衡学习库中的 BalancedRandomForestClassifier 管理不平衡输入训练数据集的不同方法。</p><p id="d946" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">用 pip 安装不平衡学习库</p><blockquote class="ne nf ng"><p id="6f7a" class="li lj ml lk b ll lm kd ln lo lp kg lq nh ls lt lu ni lw lx ly nj ma mb mc md im bi translated">pip 安装不平衡-学习</p></blockquote><p id="e015" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在下面的代码中，我们用训练数据集训练了 BalancedRandomForestClassifier，然后检查了测试数据集上的指标得分。</p><pre class="ks kt ku kv gt mm mn mo mp aw mq bi"><span id="0abf" class="mr ms it mn b gy mt mu l mv mw">from imblearn.ensemble import BalancedRandomForestClassifier</span><span id="31ea" class="mr ms it mn b gy mx mu l mv mw">brfc = BalancedRandomForestClassifier(n_estimators=500,<br/>random_state=0).fit(X_train,y_train)</span><span id="a4ce" class="mr ms it mn b gy mx mu l mv mw">print("F1 Score for Balanced Random Forest Classifier is ", f1_score(y_test,brfc.predict(X_test)))</span><span id="c1d6" class="mr ms it mn b gy mx mu l mv mw">print("Accuracy  Score for Balanced Random Forest Classifier is ", accuracy_score(y_test,brfc.predict(X_test)))</span></pre><p id="1221" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">和前面两个例子一样，它也表示高 F1 和准确度分数。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nk"><img src="../Images/5de81372911c301ef6617b51769b69a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8aQNs2RgappODlcm5ua1NA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">F1 和训练的平衡随机森林分类器的准确度分数(上述代码的输出)</p></figure><p id="ad9b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们可以在混淆矩阵中看到，与没有 weight_class 参数的 RandomForestClassifier 相比，BalancedRandomForestClassifier 在内部很好地处理了类权重。</p><pre class="ks kt ku kv gt mm mn mo mp aw mq bi"><span id="f225" class="mr ms it mn b gy mt mu l mv mw">fig=plot_confusion_matrix(brfc, X_test, y_test)<br/>plt.show()</span></pre><p id="0aba" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在 1000 个测试记录中，它正确地预测了 968 个记录的分类。通过正确地分类少数类中 26 个记录中的 21 个记录，它也比具有 class_weight 的随机 Forrest 分类器表现得稍好。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nl"><img src="../Images/ae3d39a3a625f5c754b6f65eea90fb1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1eGtS-av6r37Uz-eexHK7g.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">平衡随机森林分类器预测测试数据集的混淆矩阵(上述代码的输出)</p></figure><p id="b3d1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">接下来，我们将使用完全不同的过采样方法来管理训练数据集中的少数类。</p><p id="7917" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">接下来，我们将使用完全不同的过采样方法来管理训练数据集中的少数类。基本思想是在少数类中随机生成示例，以获得更平衡的数据集。</p><pre class="ks kt ku kv gt mm mn mo mp aw mq bi"><span id="81d5" class="mr ms it mn b gy mt mu l mv mw">from imblearn.over_sampling import RandomOverSampler<br/>ros = RandomOverSampler(random_state=0)<br/>X_resampled, y_resampled = ros.fit_resample(X_train, y_train)<br/>print("Number of records for X_train is ", X_train.shape)<br/>print("Number of records for X_resampled oversampling is ",X_resampled.shape)</span></pre><p id="c607" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">之前，我们将 5000 条记录的样本数据集分为分别具有 4000 条和 1000 条记录的训练数据集和测试数据集。</p><p id="70ad" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">RandomOverSampler 上的训练数据集 fit 随机生成少数类记录，重采样的平衡训练数据有 7794 条记录。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nm"><img src="../Images/9416bec7dc216eedb48b9444f97f389c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1yMmJmMvlfhAnafIVkdHIA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">使用过采样策略随机生成的少数类记录对训练数据集进行计数，以平衡训练数据集(上述代码的输出)</p></figure><p id="ae3a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一旦训练数据集被人工平衡，那么我们可以在没有“class_weight”参数的情况下训练标准随机森林分类器。</p><pre class="ks kt ku kv gt mm mn mo mp aw mq bi"><span id="0389" class="mr ms it mn b gy mt mu l mv mw">oclf = RandomForestClassifier(max_depth=2, random_state=0).fit(X_resampled, y_resampled)</span></pre><p id="8140" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们看到，在过采样的人工平衡训练数据集上训练的标准随机森林分类器可以很好地预测。</p><p id="139a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">过采样有助于随机分类器克服多数分类器的影响，以高精度预测测试数据记录类。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nn"><img src="../Images/16d59336a97e17bf9fee041343dfa8b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ufddrrLOKQzD3mHRMH8crQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">由在过采样数据集上训练的随机森林分类器预测的测试数据集的混淆矩阵(上述代码的输出)</p></figure><p id="383a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在 1000 个测试记录中，它正确地预测了 985 个记录的分类。它的性能也几乎与 BalancedRandomForestClassifier 相当，对少数类中的 26 个记录中的 20 个进行了分类。</p><p id="0954" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最后，我们将了解处理不平衡数据集的欠采样策略。这是一种与我们之前学习的过采样完全不同的方法。随机删除多数课上的例子。关键思想是随机删除多数类记录，以获得更平衡的数据集。</p><pre class="ks kt ku kv gt mm mn mo mp aw mq bi"><span id="4ef4" class="mr ms it mn b gy mt mu l mv mw">from imblearn.under_sampling import RandomUnderSampler</span><span id="0f3c" class="mr ms it mn b gy mx mu l mv mw">rus = RandomUnderSampler(random_state=0)<br/>X_resampled, y_resampled = rus.fit_resample(X_train, y_train)</span><span id="741b" class="mr ms it mn b gy mx mu l mv mw">print("Number of records for X_train is ", X_train.shape)<br/>print("Number of records for X_resampled undersampling is ",X_resampled.shape)</span></pre><p id="f408" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">随机删除的多数类记录的数量，以便用 4000 条数据记录中的 206 条记录来平衡训练数据集。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi no"><img src="../Images/8b5fd6e1187719e6850c835d4fa9900e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LEtDvb3K3Ihf2lERr-Q-sw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">使用欠采样策略的训练数据集计数。随机删除多数类记录以平衡训练数据集(上面代码的输出)</p></figure><p id="5608" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一旦训练数据集达到平衡，我们就可以直接使用它来训练模型，就像前面讨论的过采样策略一样。</p><pre class="ks kt ku kv gt mm mn mo mp aw mq bi"><span id="5f41" class="mr ms it mn b gy mt mu l mv mw">uclf=RandomForestClassifier(max_depth=2,<br/>random_state=0).fit(X_resampled, y_resampled)</span></pre><p id="61da" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">似乎欠采样策略能够像本文中讨论的其他策略一样以相似的精度预测罕见的少数类事件，但与其他策略相比，它在预测多数类方面表现得相当差。它错误地预测了测试数据集中的 82 个多数类记录。</p><pre class="ks kt ku kv gt mm mn mo mp aw mq bi"><span id="fbe4" class="mr ms it mn b gy mt mu l mv mw">fig=plot_confusion_matrix(uclf, X_test, y_test)<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi np"><img src="../Images/087822f18594d3c48e99fbd8ab51f604.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tVOBZuSDBGgH_bKRFSkF0A.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">由在欠采样数据集上训练的随机森林分类器预测的测试数据集的混淆矩阵(上述代码的输出)</p></figure><blockquote class="ne nf ng"><p id="c525" class="li lj ml lk b ll lm kd ln lo lp kg lq nh ls lt lu ni lw lx ly nj ma mb mc md im bi translated"><em class="it">关键要点和我的方法</em></p></blockquote><p id="6995" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">大多数机器学习分类算法期望训练数据集是平衡的。在用数据训练机器学习模型之前，检查训练数据集是否不平衡并采取适当的预处理措施至关重要。</p><p id="eafa" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">GIGO —垃圾输入和垃圾输出:如果我们用不平衡的数据训练一个模型，那么这个模型很有可能会错过对生产中少数类的预测。</p><p id="a459" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">数据是非常有价值的。我不喜欢欠采样策略，因为它会强制删除与多数类相关的数据。我们看到，由于这一点，即使该模型能够以与本文中讨论的其他策略几乎相同的精度预测少数类记录，但它在预测多数类记录时表现很差。</p><p id="86a6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我更喜欢带' class_weight '参数的随机森林分类器和不平衡学习库中的 BalancedRandomForestClassifier。</p><p id="20dd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我建议您在为您的项目选择任何一个策略之前，用本文中讨论的所有策略检查训练样本的性能。</p><p id="14ba" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">您可以通过探索性数据分析深入了解不平衡的数据集。要了解更多信息，请阅读文章- <a class="ae lh" rel="noopener" target="_blank" href="/5-advanced-visualisation-for-exploratory-data-analysis-eda-c8eafeb0b8cb">探索性数据分析(EDA)的 5 种高级可视化</a></p></div></div>    
</body>
</html>