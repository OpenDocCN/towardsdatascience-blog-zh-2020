# 蒙特卡罗方法，变得简单

> 原文：<https://towardsdatascience.com/monte-carlo-methods-made-simple-91758ba58dde?source=collection_archive---------7----------------------->

![](img/3f9191b6149f3353990d864d3ba71dc2.png)

来源: [Unsplash](https://unsplash.com/photos/mBHuEkka5wM)

## 用混乱来寻找清晰

想象一个坐标网格上的 10 乘 10 的正方形。在那个网格上画了一些形状，但是你不知道它看起来像什么。但是可以查询一个函数 *f* ( *x* ， *y* )，其中( *x* ， *y* )是坐标，输出不是 1(在形状中)就是 0(不在形状中)。你如何找到这个形状的面积？

![](img/62eff933d21eaae08a34fc75f2b81ab0.png)

这种形状的一些可能性。由作者创建

答案很简单。它来自于统计学的一个原理，大数定律，即一个函数被随机抽样的次数越多，它的近似值就越精确。然后，我们的解决方案是简单地在 10×10 网格中随机选择点，计算形状中有多少陆地，然后除以采样点的总数。

虽然这种关于随机抽样的本能想法很简单，但它在许多领域都有应用，从法律到气候预测，也许与本文最相关的是机器学习和统计学。它有一个正式的名字:蒙特卡洛方法。

当遇到由确定性原则组成的问题时，如形状的面积、函数的分布或游戏中玩家下一步应该选择哪一步，蒙特卡罗方法基本上假设它可以通过概率和随机性(随机性)来建模。

> 蒙特卡罗方法依赖于从分布中重复随机取样来获得数值结果。它是一种方法，而不是一种算法。

对于另一个基于形状的例子，请查看 [*在不使用任何数学*](/finding-the-formula-for-circle-area-without-using-any-math-898cbee70253) (使用蒙特卡洛采样和多项式回归)的情况下找到圆面积的公式。随机抽样可以作为一种寻找函数积分(曲线下面积)的廉价方法。众所周知，圆周率是一个重要的常数，圆周率的值也可以通过蒙特卡洛采样来近似计算:

![](img/2796401b338db499753e228c98caaf3b.png)

来源:[维基媒体](https://en.wikipedia.org/wiki/File:Pi_30K.gif)。图片免费分享。

一般来说，蒙特卡罗抽样有三类/三种应用:

*   *直接取样*。在没有先验信息的情况下，天真而直接地从分布中抽样。这就是我们如何逼近一个形状的未知区域。
*   *重要性抽样*。在分布太昂贵而不能取样的情况下，从更简单的近似函数中取样。这是[贝叶斯优化](/the-beauty-of-bayesian-optimization-explained-in-simple-terms-81f3ee13b10f)和[代理优化](https://medium.com/analytics-vidhya/the-fascinating-no-gradient-approach-to-neural-net-optimization-abb287f88c97)的核心组成部分。
*   *拒绝采样*。在分布未知的情况下，提出新的点，如果它们满足某个标准，就接受它们。

蒙特卡罗抽样通常用于两种情况:

*   *优化*。自然，找到最佳点需要探索和开发之间的健康平衡。当蒙特卡罗抽样(探索)与另一种控制开采的机制相配合时，它可以成为寻找最优解的有力工具。
*   *近似概率&函数*。当用另一种方法很难间接评估某些概率或函数(通常是概率函数)时，蒙特卡罗抽样是一种很好的方法。

因为蒙特卡罗方法背后的思想很简单，但可以以相当复杂和创造性的方式使用，所以最好通过几个例子来探索这种思维模式。

首先，考虑马尔可夫链蒙特卡罗(MCMC)方法，它试图在不知道分布是什么的情况下从目标分布中生成随机样本。马尔可夫链——图中每个节点是一个状态，有一定的概率 *p* 移动到另一个状态——被用来表示这些分布。

考虑一个城市中的天气马尔可夫链(天气恶劣),其中唯一可能的天气状态是风、冰雹/雪、雷暴或雨。每天，第二天的天气可以根据当天天气的概率进行预测。例如，如果今天下雪，有 80%的可能性刮风，20%的可能性明天下雨。

![](img/45e0da4238e305c274e19feceeefdeca.png)

图标: [Pixabay](https://pixabay.com/vectors/weather-icon-forecast-symbol-sign-3440568/) 。图示:作者。

为了在马尔可夫链中漫游，我们从一个位置 *s* 开始，以指定的概率移动到另一个位置 *s* ' *，*。然后， *s* 成为新的 *s* 并重复该过程。虽然这个例子的特点是一个小的马尔可夫链，但是具有数千个节点和数十万个连接的巨大图形可以用来模拟错综复杂的概率关系。

如果我们在大量时间(例如 10，000 个模拟日)后运行马尔可夫链，我们开始达到“概率平衡”。这仅仅意味着，我们可以简单地根据我们旅行过的州有多少在下雨来估计下雨的静态概率(基于大数定律)。

例如，如果我们通过运行超过 10，000 个状态的马尔可夫链得到以下(假设的)结果:

*   2754 个州的州风
*   1034 个州有雷暴
*   4301 个州出现冰雹/降雪
*   为 1911 个州下雨

我们将能够产生以下概率:

*   p(风)= 0.2754
*   p(雷暴)= 0.1034
*   p(冰雹/雪)= 0.4031
*   p(下雨)= 0.1911

然后，我们可以简单地从分布中进行相应的采样——从马尔可夫链中随机抽取一个状态，而不需要遍历它。通过重复迭代和马尔可夫链的随机遍历(该过程的“蒙特卡罗”部分)，系统能够被折叠并表示为概率分布。

> 可以构建马尔可夫链来模拟无法直接采样的复杂关系，然后将其简化以找到其潜在的概率分布。

有许多成熟的 MCMC 算法，如 [Metropolis-Hastings 算法](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm)或 [Gibbs 抽样](https://en.wikipedia.org/wiki/Gibbs_sampling)。所有人都试图做一些类似的事情——模拟系统的潜在概率。

要从理论迈出一步，进入应用，看看蒙特卡罗树搜索(MCTS)，智能游戏强化学习系统的一个关键部分。早期的游戏系统，比如 IBM DeepBlue 在 1997 年击败国际象棋冠军加里·卡斯帕罗夫(Gary Kasparov)的最初胜利，都是基于类似极大极小算法的，这些算法从当前的走法中找出所有可能的游戏，并确定哪一个游戏能带来确定的胜利(或最高的机会)。

随着测试游戏变得越来越复杂——最著名的是围棋游戏，甚至是像 DOTA 这样的高级图形射击游戏——计算上不可行，也很愚蠢，去玩完所有可能的场景。相反，对于一个玩家来说，探索潜在的有利棋步，同时放弃失败概率高的棋步，并利用已知的棋步，是更明智的做法。

假设我们开始构建一个这样的树，其中每个节点代表一些游戏状态。我们可以通过采取某些行动在节点之间转换。从游戏最初的开始状态，我们可以取几个可能的节点。

![](img/abdce90f66fb32abd8e013092ed2015a.png)

由作者创建

价值神经网络试图为每一步棋赋予一个价值:给定这一步棋，代理人获胜的概率是多少？注意，刚开始的时候，由于价值网没有经过训练，所以会给出随机的猜测。然而，随着系统玩足够多的游戏，它将更善于智能地分析某些移动的效果。

![](img/4d7e65ab44643fe41d4f85c4c700e678.png)

由作者创建

我们不是简单地选择概率最高的节点，而是执行“加权蒙特卡罗采样”。如果网络认为节点 2 将有 90%的机会获胜，那么它有更大的机会被选中，但也有可能节点 3 和 1 被选中。策略——或如何选择潜在节点——也是可以学习的。

这背后的逻辑是，某一步棋的可预见价值是有限的，是以偶然性为界的(也许对手会出其不意)。此外，只开发已知的移动，而不是冒险探索其他领域并潜在地发现更有利可图的移动，将导致无竞争力和懒惰的模型，这在复杂的强化学习环境中是不可取的。

然后，选择的节点被进一步扩展，并且该过程重复，直到游戏终止。将概率纳入决策中，而不是确定性地选择“最佳”值，有助于强化学习平衡开发/探索权衡。

如果我们从统计学的角度来看这个问题，蒙特卡罗抽样被用来模拟最佳概率分布 *p* ( *v* )来选择一个节点，假定它具有一些可预见的值 *v* 。

蒙特卡洛树搜索是 alpha Go(deep mind 的强化学习系统)击败(并将继续击败)顶级围棋选手的框架。MCTS 在其他地方有各种各样的应用。

模拟退火是蒙特卡罗抽样的另一个应用，在寻找全局最优解的任务中用作[非梯度函数优化](https://medium.com/@andre_ye/the-fascinating-no-gradient-approach-to-neural-net-optimization-abb287f88c97)的有效方法。像应用蒙特卡罗方法的其他问题一样，搜索空间是离散的(例如，我们不是试图优化连续值，像神经网络的参数)。

在一些问题中，在固定的时间内找到一个近似的全局最优值比它的精确值更有价值，模拟退火实际上可能比梯度下降等算法更好。

模拟退火的想法来自冶金学，或金属的操作。在冶金学中，退火是对材料进行有控制的加热或冷却，以增加其尺寸并消除缺陷。类似地，模拟退火控制系统中的能量，这决定了它在探索新的可能性时愿意冒多大的风险。

温度从某个初始量开始，它代表某种计时器。在每个状态 *s* ，模拟退火根据两个状态的值移动到某个相邻状态*s*’(移动到*s*’是收益还是损失？)，以及当前温度 *T* ，以概率 *P* ( *s* ，*s’*， *T* )。

随着温度随着每个时间步长降低(剩余时间减少)，该模型变得更少探索性，而更多利用性。模拟退火允许在时间上从探索到开发的渐进过渡，这对于寻找全局最优非常有益。

![](img/17d5a4415f342a8521a5323f0ca909df.png)

随着温度的降低，寻找复杂函数的全局最大值的模拟退火。来源:[维基媒体](https://en.wikipedia.org/wiki/File:Hill_Climbing_with_Simulated_Annealing.gif)。图片免费分享。

采用蒙特卡罗抽样和贝叶斯方法对概率函数 *P* ( *s* ，*s’*， *T* )进行建模。事实上，您可能还记得，Metropolis-Hastings 算法通常是一种马尔可夫链蒙特卡罗方法(或以它为模型的方法)，用于寻找转换阈值(应该转换的概率)。

这很自然，因为模拟退火将解决方案视为状态，并试图找到最佳转移概率——这是马尔可夫链建模的完美场景。

通常，蒙特卡罗方法——或者类似蒙特卡罗的思维——会出现在我们最意想不到的地方。虽然这是一个简单的机制，但它在无数的应用中有着深刻而复杂的根源。

## 总结/要点

*   蒙特卡罗方法是基于这样一种思想，即在系统中注入随机性通常可以有效地解决这个问题。
*   一般来说，蒙特卡罗抽样有三类:直接抽样、重要性抽样和拒绝抽样。
*   蒙特卡罗的两个常见应用包括优化和复杂概率和函数的评估。
*   在离散(非连续)和确定性问题中，蒙特卡罗方法利用随机性+概率、大数定律和有效的框架来有效地解决它们。

感谢您的阅读，请在回复中告诉我您的想法！

如果你对最新的文章感兴趣，可以考虑订阅。如果你想支持我的写作，通过我的[推荐链接](https://andre-ye.medium.com/membership)加入 Medium 是一个很好的方式。干杯！

[](/the-beauty-of-bayesian-optimization-explained-in-simple-terms-81f3ee13b10f) [## 贝叶斯优化的美妙之处，用简单的术语解释

### 巧妙算法背后的直觉

towardsdatascience.com](/the-beauty-of-bayesian-optimization-explained-in-simple-terms-81f3ee13b10f)