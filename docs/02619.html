<html>
<head>
<title>A complete NLP classification pipeline in scikit-learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">scikit-learn中完整的NLP分类管道</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-complete-nlp-classification-pipeline-in-scikit-learn-bf1f2d5cdc0d?source=collection_archive---------15-----------------------#2020-03-13">https://towardsdatascience.com/a-complete-nlp-classification-pipeline-in-scikit-learn-bf1f2d5cdc0d?source=collection_archive---------15-----------------------#2020-03-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/e254f4f25b1ff5baa2c6283be5e62afc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M2TSSzE05CVAotvYss8q1g.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">六路分类的混淆矩阵(TF-IDF与朴素贝叶斯分类器)</p></figure><div class=""/><div class=""><h2 id="a3a0" class="pw-subtitle-paragraph kf jh ji bd b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw dk translated">使用这个自然语言处理分类管道的完整指南，从语料库到分类。</h2></div><p id="e404" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">我们将在这个故事中讲述的内容:</p><ul class=""><li id="21df" class="lt lu ji kz b la lb ld le lg lv lk lw lo lx ls ly lz ma mb bi translated">阅读文集</li><li id="339c" class="lt lu ji kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated">基本脚本结构包括<code class="fe mh mi mj mk b">logging</code>、<code class="fe mh mi mj mk b">argparse</code>和<code class="fe mh mi mj mk b">ifmain</code>。</li><li id="4511" class="lt lu ji kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated">训练/测试分割</li><li id="19a9" class="lt lu ji kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated">先验和后验类概率</li><li id="072a" class="lt lu ji kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated">基线分类</li><li id="21d7" class="lt lu ji kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated">用<code class="fe mh mi mj mk b">FeatureUnion</code>链接多个特征</li><li id="408c" class="lt lu ji kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated">在一只熊猫<code class="fe mh mi mj mk b">DataFrame</code>和一个困惑矩阵中显示结果</li></ul><p id="b5e3" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">这个故事最重要的部分是scikit-learn/sklearn的<code class="fe mh mi mj mk b">Pipeline</code>、<code class="fe mh mi mj mk b">FeatureUnion</code>、<code class="fe mh mi mj mk b">TfidfVectorizer</code>和一个使用<code class="fe mh mi mj mk b">seaborn</code>包的<code class="fe mh mi mj mk b">confusion_matrix </code>的可视化，但也包括更多的一般内容，如<code class="fe mh mi mj mk b">ifmain</code>、<code class="fe mh mi mj mk b">argparse</code>、<code class="fe mh mi mj mk b">logging</code>、<code class="fe mh mi mj mk b">zip</code>和<code class="fe mh mi mj mk b">*args</code>。</p><h2 id="5a0f" class="ml mm ji bd mn mo mp dn mq mr ms dp mt lg mu mv mw lk mx my mz lo na nb nc nd bi translated">资料组</h2><p id="8725" class="pw-post-body-paragraph kx ky ji kz b la ne kj lc ld nf km lf lg ng li lj lk nh lm ln lo ni lq lr ls im bi translated">我们将使用亚马逊评论的数据集和简单而有效的朴素贝叶斯进行分类。<code class="fe mh mi mj mk b">trainset.txt</code>包含取自<a class="ae nj" href="https://www.kaggle.com/jeromeblanchet/multidomain-sentiment-analysis-dataset" rel="noopener ugc nofollow" target="_blank">约翰霍普金斯大学多领域情感数据集</a>的评论集，并在空格分隔的<code class="fe mh mi mj mk b">.csv</code>文件中转换为以下格式。</p><pre class="nk nl nm nn gt no mk np nq aw nr bi"><span id="8b72" class="ml mm ji mk b gy ns nt l nu nv">music neg 575.txt the cd came as promised and in the condition promised . i 'm very satisfied</span></pre><p id="b29f" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">正如你所看到的，评论已经用来自<code class="fe mh mi mj mk b">nltk</code>包的空白标记符进行了标记。每个评论占一行，前面有两个标签和评论的标识符:</p><ul class=""><li id="a5c3" class="lt lu ji kz b la lb ld le lg lv lk lw lo lx ls ly lz ma mb bi translated">指定六个主题之一的标签:<code class="fe mh mi mj mk b">books</code>、<code class="fe mh mi mj mk b">camera</code>、<code class="fe mh mi mj mk b">dvd</code>、<code class="fe mh mi mj mk b">health</code>、<code class="fe mh mi mj mk b">music</code>、<code class="fe mh mi mj mk b">software</code>。</li><li id="d958" class="lt lu ji kz b la mc ld md lg me lk mf lo mg ls ly lz ma mb bi translated">用正值或负值表示评论所表达的情绪的标签:<code class="fe mh mi mj mk b">pos</code>、<code class="fe mh mi mj mk b">neg</code>。</li></ul><p id="41d0" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">该数据集使我们能够对评论的情感进行二元分类或多类分类，并以这样一种方式创建我们的脚本，即用户可以指定要处理的分类任务。</p><h2 id="62e2" class="ml mm ji bd mn mo mp dn mq mr ms dp mt lg mu mv mw lk mx my mz lo na nb nc nd bi translated">脚本结构:导入、日志和argparse</h2><p id="a08c" class="pw-post-body-paragraph kx ky ji kz b la ne kj lc ld nf km lf lg ng li lj lk nh lm ln lo ni lq lr ls im bi translated">我们正在使用<code class="fe mh mi mj mk b">argparse</code>和函数标志(如<code class="fe mh mi mj mk b">use_sentiment</code>)设置我们的管道，以便我们能够从命令行执行二进制(<code class="fe mh mi mj mk b">pos</code> | <code class="fe mh mi mj mk b">neg</code>)分类任务和多类分类任务(<code class="fe mh mi mj mk b">book</code> | <code class="fe mh mi mj mk b">camera</code> | <code class="fe mh mi mj mk b">dvd</code> | <code class="fe mh mi mj mk b">health</code> | <code class="fe mh mi mj mk b">music</code> | <code class="fe mh mi mj mk b">software</code>)。</p><p id="f2a5" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">对于那些不熟悉的人来说，<code class="fe mh mi mj mk b">argparse</code>是一个非常有用的包，它支持用户友好的命令行界面。如果缺少必需的参数，它会显示一个错误，并显示所有可以使用的不同参数。参数前面有参数标签<code class="fe mh mi mj mk b">--input</code>和一个空格:</p><p id="5b9f" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated"><code class="fe mh mi mj mk b">$ python3 pipeline.py --input trainset.txt --binary</code>。</p><figure class="nk nl nm nn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nw"><img src="../Images/c8dec7cd039abe49c2d202caba00cc0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*kKu-E0gCc_xKTJFKRdn7pQ.gif"/></div></div></figure><p id="b6a8" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">我们还添加了一个<code class="fe mh mi mj mk b">verbosity</code>标志<code class="fe mh mi mj mk b">--v</code>，并使用Python的<code class="fe mh mi mj mk b">logging</code>功能来输出警告、错误或信息。用<code class="fe mh mi mj mk b">args = parser.parse_args()</code>解析完参数后，你可以在脚本中用<code class="fe mh mi mj mk b">args.input</code>和<code class="fe mh mi mj mk b">args.verbosity</code>使用这些参数的输入。</p><p id="4930" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated"><strong class="kz jj">注意</strong> <code class="fe mh mi mj mk b">argparse</code>没有<code class="fe mh mi mj mk b">type=bool</code>，这意味着所有get都被解析为<code class="fe mh mi mj mk b">str</code>。为了添加布尔标志，可以设置<code class="fe mh mi mj mk b">action="store_true"</code>，默认为<code class="fe mh mi mj mk b">False</code>布尔，如果包含标志<code class="fe mh mi mj mk b">--binary</code>，将自动产生<code class="fe mh mi mj mk b">True</code>布尔。</p><figure class="nk nl nm nn gt iv"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="0112" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">我们将把这个故事中的所有函数链接到一个<code class="fe mh mi mj mk b">main()</code>函数中，这个函数将被<code class="fe mh mi mj mk b">if __name__ == '__main__'</code>语句自动调用。在命令行中调用这个文件时，Python解释器读取源文件，并将<code class="fe mh mi mj mk b">__name__</code>变量设置为<code class="fe mh mi mj mk b">'__main__'</code>。这样，我们可以读取源文件并执行其中的函数，但也可以将该文件用作其他脚本的<code class="fe mh mi mj mk b">module</code>到<code class="fe mh mi mj mk b">import </code>，而无需自动执行<code class="fe mh mi mj mk b">main()</code>中的语句。</p><h2 id="4294" class="ml mm ji bd mn mo mp dn mq mr ms dp mt lg mu mv mw lk mx my mz lo na nb nc nd bi translated">阅读语料库</h2><p id="14f2" class="pw-post-body-paragraph kx ky ji kz b la ne kj lc ld nf km lf lg ng li lj lk nh lm ln lo ni lq lr ls im bi translated">首先我们需要阅读我们的文集。这个函数将利用来自我们的<code class="fe mh mi mj mk b">argparse</code>函数的<code class="fe mh mi mj mk b">--binary</code>标志来确定我们是在做二元分类还是多类分类。</p><figure class="nk nl nm nn gt iv"><div class="bz fp l di"><div class="nx ny l"/></div></figure><h2 id="8ba4" class="ml mm ji bd mn mo mp dn mq mr ms dp mt lg mu mv mw lk mx my mz lo na nb nc nd bi translated"><strong class="ak">训练/测试分割</strong></h2><p id="e4e0" class="pw-post-body-paragraph kx ky ji kz b la ne kj lc ld nf km lf lg ng li lj lk nh lm ln lo ni lq lr ls im bi translated">现在我们在<code class="fe mh mi mj mk b">documents</code>有了我们的评论，在<code class="fe mh mi mj mk b">labels</code>有了我们的类，我们将把它们分成训练集和测试集，用于我们的分类器。我们将使用<code class="fe mh mi mj mk b">slice notation [:]</code>进行80%的培训和20%的测试。首先，我们需要调整我们的数据，以确保这一部分不会影响结果:由于我们不知道语料库中的文档是如何排序的，因此在训练/测试集中，类可能会过多。例如，它们可以按字母顺序排序，这可能导致在我们的训练集中只有类别<code class="fe mh mi mj mk b">book</code> | <code class="fe mh mi mj mk b">camera</code> | <code class="fe mh mi mj mk b">dvd</code> | <code class="fe mh mi mj mk b">health</code>。</p><figure class="nk nl nm nn gt iv"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="7b5f" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">因为我们正在创建一个这样的元组列表<code class="fe mh mi mj mk b">[(doc1, 'neg'), (doc2, 'pos')]</code>，所以我们可以使用一个简洁的python函数<code class="fe mh mi mj mk b">zip</code>和<code class="fe mh mi mj mk b">*</code>来遍历这个列表，并将元组分隔在一个文档列表<code class="fe mh mi mj mk b">[doc1, doc2, doc3]</code>和一个标签列表<code class="fe mh mi mj mk b">['pos', 'neg', 'pos']</code>中。</p><p id="33a6" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated"><strong class="kz jj">注</strong>:虽然这个函数看起来有点冗长，但我还是把它包括在内了，因为这样可以很好地看到这个函数背后发生了什么。您也可以使用sklearn的<code class="fe mh mi mj mk b">train_test_split</code>函数，它的功能基本相同，或者使用<code class="fe mh mi mj mk b">k-fold cross-validation</code>:在训练和测试中分割数据集<code class="fe mh mi mj mk b">k</code>次，并取每个分类的平均值，以确保分割对分数的影响尽可能小。</p><h2 id="68f7" class="ml mm ji bd mn mo mp dn mq mr ms dp mt lg mu mv mw lk mx my mz lo na nb nc nd bi translated">先验和后验类概率</h2><p id="7e31" class="pw-post-body-paragraph kx ky ji kz b la ne kj lc ld nf km lf lg ng li lj lk nh lm ln lo ni lq lr ls im bi translated">对于手头的分类任务，我们将使用朴素贝叶斯分类器，它利用了<a class="ae nj" href="https://en.wikipedia.org/wiki/Bayes%27_theorem" rel="noopener ugc nofollow" target="_blank">贝叶斯定理</a>:计算结合了分类器中包括的特征(如tf-idf或counts)的类的新概率分布，这将使新的概率分布更能代表数据。</p><p id="0b96" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">为了理解后验概率，将它们与先验分布进行比较是有用的。因此，我们将首先计算我们的语料库中所有文档的类别的先验概率，或者反过来:我们的语料库中的一个文档具有某个类别的概率。后验概率可以用<code class="fe mh mi mj mk b">classifier.predict_proba</code>来计算。</p><figure class="nk nl nm nn gt iv"><div class="bz fp l di"><div class="nx ny l"/></div></figure><h2 id="a058" class="ml mm ji bd mn mo mp dn mq mr ms dp mt lg mu mv mw lk mx my mz lo na nb nc nd bi translated">基线分类</h2><p id="4824" class="pw-post-body-paragraph kx ky ji kz b la ne kj lc ld nf km lf lg ng li lj lk nh lm ln lo ni lq lr ls im bi translated">为了比较评估度量(准确性)和朴素贝叶斯分类器的混淆矩阵，我们将创建一个非常简单的基线:使用<code class="fe mh mi mj mk b">random</code>包，我们将从一组可能的标签中为每个文档随机分配一个标签。我们还可以创建一个基线，将每个类别的先验概率考虑在内。</p><figure class="nk nl nm nn gt iv"><div class="bz fp l di"><div class="nx ny l"/></div></figure><h2 id="391c" class="ml mm ji bd mn mo mp dn mq mr ms dp mt lg mu mv mw lk mx my mz lo na nb nc nd bi translated">具有FeatureUnion的多个功能</h2><p id="7289" class="pw-post-body-paragraph kx ky ji kz b la ne kj lc ld nf km lf lg ng li lj lk nh lm ln lo ni lq lr ls im bi translated">对于此分类任务，我们将添加分类器中包含的三个功能:</p><ol class=""><li id="2913" class="lt lu ji kz b la lb ld le lg lv lk lw lo lx ls nz lz ma mb bi translated">计数向量器，在每个标记后附加位置标签</li><li id="807c" class="lt lu ji kz b la mc ld md lg me lk mf lo mg ls nz lz ma mb bi translated">TF-IDF矢量器(在文档频率中使用非常强大的<a class="ae nj" href="http://www.tfidf.com/" rel="noopener ugc nofollow" target="_blank">术语频率)</a></li><li id="ffb6" class="lt lu ji kz b la mc ld md lg me lk mf lo mg ls nz lz ma mb bi translated">特征工程的一个例子，特征长度包含在管道中，特征值映射到<code class="fe mh mi mj mk b">DictVectorizer</code>中的向量。</li></ol><p id="b80c" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">现在这段代码有点复杂，但它只是一个示例，说明了如何在一个FeatureUnion管道中追加多个功能，甚至包括(. 3)中的管道。</p><figure class="nk nl nm nn gt iv"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="23f4" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">我在函数<code class="fe mh mi mj mk b">feature_union()</code>中为每个特性添加了一个标志，这样你就可以相应地打开和关闭特性。</p><h2 id="d5d8" class="ml mm ji bd mn mo mp dn mq mr ms dp mt lg mu mv mw lk mx my mz lo na nb nc nd bi translated">显示结果</h2><p id="181e" class="pw-post-body-paragraph kx ky ji kz b la ne kj lc ld nf km lf lg ng li lj lk nh lm ln lo ni lq lr ls im bi translated">现在我们也要展示我们的成果。我们可以使用sklearn的<code class="fe mh mi mj mk b">classification_report</code>、<code class="fe mh mi mj mk b">accuracy_score</code>和<code class="fe mh mi mj mk b">confusion_matrix</code>以及最后一个的<code class="fe mh mi mj mk b">seaborn</code>包。</p><figure class="nk nl nm nn gt iv"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="e770" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated"><code class="fe mh mi mj mk b">tabular_results()</code>用标记化的句子、实际标签、预测标签和先验/后验概率创建熊猫数据帧。<code class="fe mh mi mj mk b">class_report()</code>显示分类器的准确度分数，并有一个标志<code class="fe mh mi mj mk b">show_matrix</code>，用于使用<code class="fe mh mi mj mk b">vis()</code>功能显示混淆矩阵的美丽可视化。</p><h2 id="b939" class="ml mm ji bd mn mo mp dn mq mr ms dp mt lg mu mv mw lk mx my mz lo na nb nc nd bi translated">把管道拼起来！</h2><p id="578d" class="pw-post-body-paragraph kx ky ji kz b la ne kj lc ld nf km lf lg ng li lj lk nh lm ln lo ni lq lr ls im bi translated">我们阅读我们的语料库&gt;分割训练/测试中的数据&gt;计算先验概率&gt;创建我们三个特征的特征联合&gt;使分类器适合数据&gt;进行预测&gt;计算后验概率&gt;创建数据帧&gt;报告基线结果&gt;报告朴素贝叶斯的结果。</p><p id="b39b" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">对于我们的六类分类，基线的准确度分数保持在大约<code class="fe mh mi mj mk b">0.16/0.17</code>左右，对于我们的二类分类，准确度分数保持在大约<code class="fe mh mi mj mk b">0.5</code>左右，这是合乎逻辑的，因为它是类的概率/数量。对于所有三个特征的组合，朴素贝叶斯准确度得分为<code class="fe mh mi mj mk b">0.685</code>，仅使用tf-idf向量时得分最高<code class="fe mh mi mj mk b">0.901</code>。这表明特征工程并不总是产生更好的结果！</p><figure class="nk nl nm nn gt iv"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="ce93" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">完整的脚本和数据集可以在<a class="ae nj" href="https://github.com/LouisdeBruijn/Medium/tree/master/NLP%20pipeline" rel="noopener ugc nofollow" target="_blank">这里</a>找到。记住，您可以使用<code class="fe mh mi mj mk b">--v</code>将二进制分类的<code class="fe mh mi mj mk b">--binary</code>标志和详细度标志设置为不同的级别(<code class="fe mh mi mj mk b">4</code>用于调试)，以查看分类器的<code class="fe mh mi mj mk b">classification_report</code>。此外，<code class="fe mh mi mj mk b">feature_union()</code>具有开启/关闭不同功能的标志，<code class="fe mh mi mj mk b">class_report()</code>具有显示混淆矩阵的标志。</p></div></div>    
</body>
</html>