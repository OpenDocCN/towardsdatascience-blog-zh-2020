<html>
<head>
<title>I tried (and failed) to use GANs to create art, but it was still worth it.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我尝试过(也失败了)用甘斯创作艺术，但还是值得的。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/i-tried-and-failed-to-use-gans-to-create-art-but-it-was-still-worth-it-c392bcd29f39?source=collection_archive---------43-----------------------#2020-08-23">https://towardsdatascience.com/i-tried-and-failed-to-use-gans-to-create-art-but-it-was-still-worth-it-c392bcd29f39?source=collection_archive---------43-----------------------#2020-08-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="85e1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ko">这部作品大量借鉴 Pytorch </em> <a class="ae kp" href="https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html" rel="noopener ugc nofollow" target="_blank"> <em class="ko"> DCGAN 教程</em> </a> <em class="ko">和 NVIDA 论文</em><a class="ae kp" href="https://research.nvidia.com/publication/2017-10_Progressive-Growing-of" rel="noopener ugc nofollow" target="_blank"><em class="ko"/></a><em class="ko">关于渐进式 GAN。</em></p><p id="a4ae" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我一直想探索的一个计算机视觉领域是 GANs。所以，当我和妻子搬进一个有额外墙壁空间的房子时，我意识到我可以创建一个网络来制作一些墙壁艺术，这样就不用去贝德柏士比昂公司了(一举两得！).</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi kq"><img src="../Images/1113c75b14344cd6cb353048230306d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VxaCtaK_j3PCB-G_zPBowA.jpeg"/></div></div><p class="lc ld gj gh gi le lf bd b be z dk translated">我将尝试创造的风格的一个例子(照片由<a class="ae kp" href="https://unsplash.com/@jentheodore?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Jen Theodore </a>在<a class="ae kp" href="https://unsplash.com/s/photos/abstract-art?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄)</p></figure><h1 id="d2d8" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">什么是甘？</h1><p id="5963" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">GANs(生成对抗网络)使用两个协同神经网络工作:一个创建伪造图像(生成器)，另一个神经网络接收伪造图像以及真实的艺术作品，并试图将它们分类为真实或伪造(鉴别器)。然后网络不断迭代，生成器越来越擅长制造假货，鉴别器越来越擅长检测假货。在这个过程的最后，你有希望拥有一个生成器，它可以随机地创建看起来真实的艺术作品。在她的书《你看起来像个东西，我爱你》中，Janelle Shane 讨论了如何使用 gan 来制作各种东西，从饼干食谱到接台词(这也是这本书得名的原因)。</p><p id="c3a4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你不知道 GANs 是什么，我建议你阅读这篇 Pytorch <a class="ae kp" href="https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html" rel="noopener ugc nofollow" target="_blank">文章</a>以获得更深入的解释。</p><h1 id="83f5" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">挑战</h1><p id="e981" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">创建一个能产生满意结果的 GANs 模型有几个困难，我需要在我的项目中解决这些困难。</p><p id="a9c5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">数据。像所有的神经网络一样，你需要大量的数据；然而，GANs 似乎有更大的胃口。我读过的大多数 GAN 项目都利用了数万或数十万张图片。相比之下，我的数据集只有几千张图片，是我从谷歌图片搜索中获得的。就风格而言，我喜欢以类似 Rothko 的东西结束，但我会满足于普通的床浴和其他东西。</strong></p><p id="67c0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">训练时间。</strong>在 NVIDA 关于 progressive GANs 的<a class="ae kp" href="https://research.nvidia.com/publication/2017-10_Progressive-Growing-of" rel="noopener ugc nofollow" target="_blank">论文</a>中，他们使用多个 GPU 对他们的网络进行了数天的训练。在我的情况下，我将使用谷歌 Colab，并希望免费层硬件将足够好。</p><p id="51ee" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">模式崩溃。除了是我的新 dubstep 项目的名字之外，当各种生成的图像开始汇聚时，就会发生模式崩溃。本质上，生成器看到一些图像在欺骗鉴别器方面做得很好，并决定使其所有输出看起来像这几个图像。</strong></p><p id="18c7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">图像分辨率。</strong>想要的图像越大，需要的网络就越大。那么我需要多高的分辨率呢？嗯，数码照片每英寸的推荐像素数是 300，所以如果我想要的东西可以挂在 12x15 英寸的框架中，我需要 54，000 平方像素的最终分辨率！很明显，我不能建立一个如此高分辨率的模型，但是对于这个实验，我会说这是我的目标，我会看看我的最终结果。为了帮助解决这个问题，我还将使用一种渐进的 GANs 方法。这是由 NVIDA 首创的，他们首先在低分辨率下训练一个模型，然后逐步添加增加图像分辨率所需的额外层。你可以把它想成是涉水入池，而不是直接潜入深水区。在他们的论文中，他们能够生成分辨率为 1024 x 1024 像素的名人图像(我的目标只是这个数字的 50 倍)。</p><h1 id="2a64" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">进入代码</h1><p id="39ae" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">我的完整代码可以在 github 上找到。我想在本文中展示的主要内容是生成器和鉴别器。</p><p id="e4bd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">鉴频器。</strong>我的鉴别器看起来像任何其他图像分类网络。这个类的独特之处在于它将层数(基于图像大小)作为参数。这使我可以做渐进式 gan 的“渐进式”部分，而不必在每次增加图像大小时重写我的类。</p><figure class="kr ks kt ku gt kv"><div class="bz fp l di"><div class="mj mk l"/></div></figure><p id="a926" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">发电机。</strong>发生器本质上是鉴别器的反向器。它将一个随机值向量作为噪声，并使用转置卷积层将噪声放大到图像中。我的图层越多，最终图像就越大。</p><figure class="kr ks kt ku gt kv"><div class="bz fp l di"><div class="mj mk l"/></div></figure><h1 id="c85f" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">测试网络</h1><p id="0a99" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">在我开始尝试生成抽象艺术之前，我首先要测试我的网络，以确保事情设置正确。为此，我将在另一个 GANs 项目的图像数据集上运行该网络，然后看看我是否会得到类似的结果。animeGAN 项目非常适合这个用例。在他们的项目中，他们使用了 143，000 张动漫人物的脸部图像来创建一个生成新角色的生成器。下载完他们的数据集后，我用 32 像素的目标图像大小运行了我的模型 100 个时期，瞧！</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/92554ad0ecde2cffc5d6f8ba1edb93b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*5-OaBmqHsDeQA2DC6QKX8w.png"/></div><p class="lc ld gj gh gi le lf bd b be z dk translated">我的 GAN 模型的结果</p></figure><p id="ab0e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">结果实际上比我预期的要好。有了这些结果，我确信我的网络设置正确，我可以移动到我的数据集。</p><h1 id="ee9b" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">培养</h1><p id="93a4" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">现在是最后在艺术数据上训练模型的时候了。我的初始图像大小将是一个微薄的 32 像素。我将在这个尺寸下训练一段时间，之后我将添加一个额外的层到生成器和鉴别器，将图像尺寸加倍到 64。只是冲洗和重复，直到我得到一个令人满意的图像分辨率。但是我怎么知道什么时候该穿下一个尺码呢？围绕这个问题已经做了很多工作。我将采取简单的训练方法，直到我从 Google 获得 GPU 使用限制，然后我将手动检查结果。如果他们看起来需要更多时间，我会等一天(这样使用限制就解除了)再训练一轮。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi mm"><img src="../Images/b335e3c41d9508573aa57721eef9befc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c27GkR_QidjCuIQkIgSGhQ.png"/></div></div><p class="lc ld gj gh gi le lf bd b be z dk translated">你好黑暗，我的老朋友</p></figure><p id="d053" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 32 像素结果。</strong>我的第一组结果看起来很棒。不仅没有模式崩溃的迹象，生成器甚至复制了一些图像包含一个框架。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi mn"><img src="../Images/a68ff7a31f29cca880daccd439f61673.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HPz2FSnzSK_3GJoLdR4vLQ.png"/></div></div><p class="lc ld gj gh gi le lf bd b be z dk translated">以 32 尺寸生成的图像</p></figure><p id="a7cf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 64 和 128 像素的结果。</strong>64 像素的效果也相当不错；然而，当我将尺寸增加到 128 像素时，我开始在生成器结果中看到模式崩溃的迹象。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/f3a634e976589d0449a499a75c9c822d.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*Vq514jOtTxdc4ESzP-cDHA.png"/></div><p class="lc ld gj gh gi le lf bd b be z dk translated">开始看到相同的输出</p></figure><p id="3a5c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 256 像素结果。</strong>当我得到这个尺寸的图像时，模式折叠已经将结果减少到只有大约 3 或 4 种类型的图像。我怀疑这可能与我有限的数据集有关。当我达到这个分辨率时，我只有大约 1000 张图像，有可能生成器只是在模仿集合中的一些图像。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi mp"><img src="../Images/2b0a03acee8ea8eecf6539ff81dee63a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BRKtnGfU1yUkc5k5dB880g.png"/></div></div><p class="lc ld gj gh gi le lf bd b be z dk translated">模式崩溃</p></figure><h1 id="b85f" class="lg lh it bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">结论</h1><p id="62a8" class="pw-post-body-paragraph jq jr it js b jt me jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn im bi translated">最后，我的渐进式甘斯模型并没有取得很大进展。然而，我仍然惊讶于一个相当简单的网络能够创造出什么。当它生成动漫人脸或将其生成的一些画作放入相框时，令人震惊。我理解为什么人们认为 GANs 是近年来最伟大的机器学习突破之一。现在这只是我对 GANs 的 hello world 介绍，但我很可能会回来。</p></div></div>    
</body>
</html>