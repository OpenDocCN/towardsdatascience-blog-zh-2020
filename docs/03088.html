<html>
<head>
<title>Neural Network Interpretability — A review</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络可解释性研究综述</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/dense-or-convolutional-part-2-interpretability-c310a9fd99a5?source=collection_archive---------23-----------------------#2020-03-24">https://towardsdatascience.com/dense-or-convolutional-part-2-interpretability-c310a9fd99a5?source=collection_archive---------23-----------------------#2020-03-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f07e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">从简单的激活地图到复杂的地图集和网络视图</h2></div><p id="37f2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这篇文章中，我们将对深度神经网络(DNN)的密集层和卷积层的可解释性进行比较，仍然专注于图像分类任务，使用MNIST或CIFAR-10数据集作为例子。但首先，让我们简单解释一下什么是可解释性，为什么需要可解释性。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/eee5d34dc8734875f9cfeede0ab65783.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6_c2UtdcHnAMCHI_U8Ep_g.jpeg"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">劳拉·奥克尔在<a class="ae lr" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="6010" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在<a class="ae lr" href="https://medium.com/analytics-vidhya/dense-or-convolutional-part-1-c75c59c5b4ad" rel="noopener">第一部分</a>中，我们以MNIST标准数据集为例，展示了卷积神经网络比密集神经网络性能更好、更纤细。如果这只是一个“运气”的问题怎么办:它在这个数据集上工作得很好，但如果数据集是不同的，或者手头的任务(即分类手写数字)正在发生变化(例如分类机器生成的数字)，就不会这样了。网络到底学到了什么？这些问题没有确定的答案。然而，在可解释性和对立的例子的保护伞下，有一个关于这个主题的积极研究的整个领域。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="b676" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">可解释性</h1><p id="448d" class="pw-post-body-paragraph kf kg iq kh b ki mr jr kk kl ms ju kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">DNN是基于简单的数学运算，然而，在几个隐藏层上具有非线性激活的神经元的组合导致不能用数学公式评估的模型。DNN的这一特性被Roscher称为缺乏透明性。解决这个问题的方法是通过可解释性，可解释性在同一篇文章中定义为:</p><blockquote class="mx my mz"><p id="186a" class="kf kg mw kh b ki kj jr kk kl km ju kn na kp kq kr nb kt ku kv nc kx ky kz la ij bi translated">“可解释性的目的是用人类可以理解的术语呈现ML模型的一些特性。[……]解释可以通过可理解的代理模型获得，这种模型近似于更复杂方法的预测。”</p><p id="e895" class="kf kg mw kh b ki kj jr kk kl km ju kn na kp kq kr nb kt ku kv nc kx ky kz la ij bi translated"><a class="ae lr" href="https://arxiv.org/abs/1905.08883" rel="noopener ugc nofollow" target="_blank">r . ROS cher，B. Bohn，M-F. Duarte和J. Garcke </a></p></blockquote><p id="abba" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">决策树很容易理解，因为可以看到每个决策变量-阈值的重要性。在深度神经网络中，没有这种决策工件，需要其他工具来检查网络内部。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="694e" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">直接检查</h1><p id="e282" class="pw-post-body-paragraph kf kg iq kh b ki mr jr kk kl ms ju kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">给定一个神经网络，我们可能会试图检查每一层的权重。这种方法有两个障碍。</p><p id="e2c6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，权重的数量很快就达到了数千，并且在最大的网络上达到了数亿。权重聚合是必需的，自然且不完美的统计工具是直方图。还有待发现聚合是如何进行的:按神经元单位还是按层？</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><a href="https://github.com/tonio73/data-science/blob/master/cnn/CnnVsDense-Part1.ipynb"><div class="gh gi nd"><img src="../Images/00fdd395986d4096960424aff6457850.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MwsnMULnpYgeL_YRQyefOA.png"/></div></a><p class="ln lo gj gh gi lp lq bd b be z dk translated">密集网络的两个层的权重直方图</p></figure><p id="3f29" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">鉴于它们的参数共享特性，卷积神经网络(CNN)有一个优势:卷积层的权值比稠密等效层低得多(见第1部分)。此外，给定卷积滤波器的图像/信号处理背景，表示它们的权重比密集层的权重的原始列表更有意义。不过，这只适用于小型网络和第一层。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><a href="https://github.com/tonio73/data-science/blob/master/cnn/CnnVisualization-1-Activations.ipynb"><div class="gh gi ne"><img src="../Images/49eb1a84bdc36afed55b95c8ce08d5d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KGfU5O-weTt4DMwBqYH_2w.png"/></div></a><p class="ln lo gj gh gi lp lq bd b be z dk translated">32 lenet 5第一层的卷积滤波器权重</p></figure><p id="4d21" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第二，只看一层的重量掩盖了各层之间的所有相互作用。我们回到上面提到的透明度问题。<a class="ae lr" href="https://playground.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> Tensorflow Playground </a>具有这种相互作用的表示，其在层之间绘制漩涡，其宽度与连续神经元之间的相互作用成比例。但是，这种方法很难规模化。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><a href="https://playground.tensorflow.org/"><div class="gh gi nf"><img src="../Images/3ab129f00c1631b57e09cc7488b5fa46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dbIM63K_RSgUwvLPZqMnSQ.png"/></div></a><p class="ln lo gj gh gi lp lq bd b be z dk translated">神经网络的张量流操场表示</p></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="9826" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">活化和梯度方法</h1><p id="69df" class="pw-post-body-paragraph kf kg iq kh b ki mr jr kk kl ms ju kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">观察网络的另一种方式是基于刺激:在图像分类网络的情况下是输入图像。</p><p id="6e46" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">激活图是第一种基于刺激的解释方法:给定一幅图像或一小组图像，显示处理该图像时每个神经元的输出。这主要适用于CNN，因为它们保留了图像的2D结构，并且只能根据前几层中的几何伪影(边缘、角)来解释。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><a href="https://github.com/tonio73/data-science/blob/master/cnn/CnnVisualization-1-Activations.ipynb"><div class="gh gi ng"><img src="../Images/fb853d12f8c88e7626946fb7be92e250.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WYxNOQSc0zh2TcTC_dgpcA.png"/></div></a><p class="ln lo gj gh gi lp lq bd b be z dk translated">来自CIFAR-10的一幅马图像上32个卷积单元的激活图</p></figure><p id="fe6a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">自2007年以来，人们开发了更强大的方法，所有这些方法都基于同一个想法的梯度和变化:从一个给定的神经元单位或层，激活它的最佳输入是什么？</p><p id="61b5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这些方法中，我们可以列举:</p><p id="5f72" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">- <a class="ae lr" href="https://www.researchgate.net/publication/265022827_Visualizing_Higher-Layer_Features_of_a_Deep_Network" rel="noopener ugc nofollow" target="_blank">可视化深层网络的高层特征，尔汗等人，2009 </a></p><p id="c9b8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">- <a class="ae lr" href="https://arxiv.org/abs/1311.2901" rel="noopener ugc nofollow" target="_blank">可视化和理解卷积网络，泽勒等人，2013年</a></p><p id="1a92" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">- <a class="ae lr" href="https://arxiv.org/pdf/1312.6034.pdf" rel="noopener ugc nofollow" target="_blank">深入卷积网络内部:可视化图像分类模型和显著图，Simonyan等人，2014年</a></p><p id="d532" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">- <a class="ae lr" href="https://arxiv.org/pdf/1704.02685.pdf" rel="noopener ugc nofollow" target="_blank"> DeepLift:通过传播激活差异学习重要特征，Shrikumar等人，2017 </a></p><p id="dbf7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">- <a class="ae lr" href="http://www.evolvingai.org/files/1904.08939.pdf" rel="noopener ugc nofollow" target="_blank">通过特征可视化了解神经网络:一项调查，Nguyen等人，2019年</a></p><p id="fe2b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Erhan和Simonyan的显著图基于反向传播到网络图像输入的梯度上升(下图中的橙色路径)。训练过程是相反的。在训练期间，图像是地面真实的一部分，并且网络权重被优化。如果要检查的神经元是网络的输出，我们将回到常规的深度神经网络优化，但具有冻结的层权重(下图中的蓝色路径)。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nh"><img src="../Images/4b3ca3d5b0d5db184bac65e214cb1122.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A9SR_glE0IhOyZB_3zKU2Q.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">显著图原理</p></figure><p id="9939" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">显著性图接近于对立的例子，因为有可能创建对网络有意义(即预测给定类别)但对我们的眼睛没有意义的图像。这里是一个例子，其中为CIFAR-10的10个类别中的每一个计算显著性，然后将其添加到Concord平面的图像中。对于大多数类别，CNN预测显著性类别的裕度较大(概率超过70%):</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><a href="https://github.com/tonio73/data-science/blob/master/cnn/CnnVisualization-2-SaliencyMaps.ipynb"><div class="gh gi ni"><img src="../Images/0f9099f31fe3c6f10bbcc53cecea454e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UwncTSNh7z-6DG21QdRD5Q.png"/></div></a><p class="ln lo gj gh gi lp lq bd b be z dk translated">从CIFAR-10数据集向协和平面添加显著性</p></figure><p id="0d9e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">初始输入图像(通常称为基线或先验)可以是中性灰色、随机噪声或我们想要检查的图像类别。在最后一种情况下，图像被修改，就像通过漫画。Nguyen列出的更多最近的出版物一直在研究提高显著图的质量。主要的创新在于通过采样和聚集类来优化基线，以及正则化、增加图像中心上的梯度上升的焦点的惩罚和平滑度。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><a href="http://www.evolvingai.org/files/1904.08939.pdf"><div class="gh gi nj"><img src="../Images/e647b3fcf931508280054d6c6acda04e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yh8Cf6YaDD5VN-mcPe7qMA.png"/></div></a><p class="ln lo gj gh gi lp lq bd b be z dk translated">Nguyen在2019年对显著性图进行了审查</p></figure><p id="46d7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">不过，这是神经网络的一个非常详细的视图，我们缺乏对类和层的概述。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="1e17" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">降维</h1><p id="8443" class="pw-post-body-paragraph kf kg iq kh b ki mr jr kk kl ms ju kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">分类神经网络正在输出一个非常精炼和精简的度量:每一类的概率，更概括为概率最大的那一类的指标。基于这些，通常的度量是准确度，其仅计算匹配的预测类别相对于实际类别的数量。正如我在巴黎电信的一位老师所说:</p><blockquote class="mx my mz"><p id="0033" class="kf kg mw kh b ki kj jr kk kl km ju kn na kp kq kr nb kt ku kv nc kx ky kz la ij bi translated">“分类神经网络的最后一层是一个非常简单的检测器，即logistic或多类回归(softmax)中的一种。该网络的强大之处在于，它是一个高度非线性的复杂函数，需要对该检测器的输入进行整形。”</p></blockquote><p id="5bbf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">许多信息出现在最后一层的输入端。它提供了对网络行为的洞察。然而，问题和以前的技术一样:维度非常高，不容易表示。</p><p id="1f4d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一套通用的降维技术被用于将这些高维空间显示为2D(或3D)空间中的流形:</p><h2 id="40ee" class="nk ma iq bd mb nl nm dn mf nn no dp mj ko np nq ml ks nr ns mn kw nt nu mp nv bi translated">t分布随机邻居嵌入(t-SNE)</h2><blockquote class="mx my mz"><p id="51c9" class="kf kg mw kh b ki kj jr kk kl km ju kn na kp kq kr nb kt ku kv nc kx ky kz la ij bi translated">“t-分布式随机邻居嵌入(t-SNE)是一种(<a class="ae lr" href="http://blog.kaggle.com/2012/11/02/t-distributed-stochastic-neighbor-embedding-wins-merck-viz-challenge/" rel="noopener ugc nofollow" target="_blank">获奖</a>)的降维技术，特别适合于高维数据集的可视化。该技术可以通过Barnes-Hut近似实现，从而可以应用于大型真实数据集。我们将它应用于多达3000万个例子的数据集。”</p><p id="2d79" class="kf kg mw kh b ki kj jr kk kl km ju kn na kp kq kr nb kt ku kv nc kx ky kz la ij bi translated">在<a class="ae lr" href="https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf" rel="noopener ugc nofollow" target="_blank">使用t-SNE、范德马滕和辛顿</a>，<a class="ae lr" href="https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf" rel="noopener ugc nofollow" target="_blank"> JMLR 2008 </a></p></blockquote><h1 id="c54a" class="lz ma iq bd mb mc nw me mf mg nx mi mj jw ny jx ml jz nz ka mn kc oa kd mp mq bi translated">一致流形逼近和降维投影(UMAP)</h1><blockquote class="mx my mz"><p id="14ce" class="kf kg mw kh b ki kj jr kk kl km ju kn na kp kq kr nb kt ku kv nc kx ky kz la ij bi translated">UMAP是一种新颖的流形学习降维技术。UMAP是从基于黎曼几何和代数拓扑的理论框架中构建的。结果是一个实用的可扩展算法，适用于现实世界的数据。在可视化质量方面，UMAP算法与t-SNE算法具有竞争力，并且可以说保留了更多的全局结构，具有更好的运行时性能。此外，UMAP对嵌入维度没有计算限制，这使其成为机器学习的通用降维技术。”</p><p id="c5dc" class="kf kg mw kh b ki kj jr kk kl km ju kn na kp kq kr nb kt ku kv nc kx ky kz la ij bi translated">在<a class="ae lr" href="https://arxiv.org/abs/1802.03426" rel="noopener ugc nofollow" target="_blank"> UMAP:一致流形逼近和降维投影，McInns 2018 </a></p></blockquote><p id="dcb1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我们看一下简单的MNIST数字数据集，我们可以用UMAP直接处理它:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><a href="https://github.com/tonio73/data-science/blob/master/cnn/CnnVsDense-Part2-Visualization.ipynb"><div class="gh gi ob"><img src="../Images/c49f903a9e35931c943aaec7140522a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*li_ZBGM8o8e899jhhCVqKA.png"/></div></a><p class="ln lo gj gh gi lp lq bd b be z dk translated">UMAP投影到2D的MNIST 9位数28x28像素图像数据集</p></figure><p id="f378" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些颜色对应于真实数字类别。我们已经看到了类簇的很好的分离，但是有重叠的部分。</p><p id="09bc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我们重用第1部分的密集网络并处理softmax层输入，我们会看到类簇被更好地分离并且更紧凑:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><a href="https://github.com/tonio73/data-science/blob/master/cnn/CnnVsDense-Part2-Visualization.ipynb"><div class="gh gi oc"><img src="../Images/0df2d6ed453d9c2e699d60a8f3d221ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*UzW59QTf2XVBsNA8mJ86vw.png"/></div></a><p class="ln lo gj gh gi lp lq bd b be z dk translated">MNIST的UMAP视图经过密集网络处理，直至最后一层输入</p></figure><p id="d836" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用这个用散景制作的漂亮的显示器，我们可以检查边界上的样本，可能会分类错误</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi od"><img src="../Images/fccd63082ec1b907ce8cc059219b345c.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/1*K4P3Zm31-Oe4cl_Va9RpFg.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">放大具有密集网络的错误分类的5位数</p></figure><p id="ca60" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用LeNet5 CNN架构执行相同的UMAP投影:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/9ab700d82d2e9d2ea8df2a106c1af217.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/1*fHbbb-qXweYMU6gcGnuKRw.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">由LeNet5网络处理直到最后一层输入的MNIST UMAP视图</p></figure><p id="ac21" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">CNN可以更好地分离集群，使CNN在密集网络上更具优势。</p><p id="93c8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">美国有线电视新闻网提供了一组边界样本的详细信息:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi of"><img src="../Images/4622db9b793736d7a252d75e2c80d3e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*R8S720PUCGs_XakMMH_kCQ.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">使用LeNet5 CNN放大错误分类的0</p></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="575c" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">网络和数据集概述</h1><p id="3e38" class="pw-post-body-paragraph kf kg iq kh b ki mr jr kk kl ms ju kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">这些技术中的大多数应用于神经元单元水平，并应用于一个或几个图像。我们显然缺少整体网络视图和域(数据集)视图。</p><p id="f89d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由Carter等人提出的激活地图集正在解决数据集概述的挑战。显著图是在数据集的大样本上计算的，并使用t-SNE或UMAP进行聚类。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi og"><img src="../Images/a6aae892b1fdf588bf864686b99afd7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j99TMShGZbVmDshNJmruAQ.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">卡特等人的激活地图集。来自谷歌大脑和OpenAI</p></figure><p id="7b2c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们已经创建了一个Github项目，<a class="ae lr" href="https://github.com/tonio73/dnnviewer" rel="noopener ugc nofollow" target="_blank">深度神经网络查看器</a>，来处理玩具网络上的网络视图。这个项目是年轻的，不完整的，但已经提供了一些不错的看法和CNN和DNN的检查。这将在以后的文章中更详细地介绍。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><a href="https://github.com/tonio73/dnnviewer"><div class="gh gi oh"><img src="../Images/f2a210cfe0532061de4349142a231925.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*362DZnphNtYtmTtRKrYdSA.png"/></div></a><p class="ln lo gj gh gi lp lq bd b be z dk translated">CIFAR-10简单CNN上的DNN观众截图</p></figure><p id="7fd1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该方法不同于<a class="ae lr" href="https://www.tensorflow.org/tensorboard" rel="noopener ugc nofollow" target="_blank"> Tensorboard </a>图或<a class="ae lr" href="https://github.com/lutzroeder/netron" rel="noopener ugc nofollow" target="_blank"> Netron </a>图，它们显示网络拓扑，但不将其与实际性能和参数(权重、梯度)联系起来。</p><h1 id="f850" class="lz ma iq bd mb mc nw me mf mg nx mi mj jw ny jx ml jz nz ka mn kc oa kd mp mq bi translated">结论</h1><p id="2e21" class="pw-post-body-paragraph kf kg iq kh b ki mr jr kk kl ms ju kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">我们回顾了一些实际的技术来检查深度神经网络的内容，并对其结果(分类)进行解释。我们已经表明，卷积网络(CNN)更容易检查，因为它们在卷积层中保留了图像的2D结构。在我们的例子中，我们已经观察到，当用UMAP投影表示最后一层的输入时，CNN在密集DNN上的性能增益是可见的。</p><p id="3582" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这篇文章中，我们专注于一个单一的任务，图像分类，这是由深度神经网络处理的许多任务之一。已经列出了许多不同的工具和方面，并显示了它们的限制。深度神经网络的可解释性是一个非常广阔的活跃研究领域，对这些系统行为和鲁棒性的更多证明的需求仍然是趋势。我们可能会在以后的帖子中进一步处理它。</p><h1 id="3767" class="lz ma iq bd mb mc nw me mf mg nx mi mj jw ny jx ml jz nz ka mn kc oa kd mp mq bi translated">本帖中使用的笔记本</h1><p id="a49d" class="pw-post-body-paragraph kf kg iq kh b ki mr jr kk kl ms ju kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">以下是本文中使用的笔记本，来自<a class="ae lr" href="https://tonio73.github.io/data-science/" rel="noopener ugc nofollow" target="_blank">数据科学分步指南</a>库:</p><ul class=""><li id="4b0e" class="oi oj iq kh b ki kj kl km ko ok ks ol kw om la on oo op oq bi translated">密集和LeNet5设计，权重直方图:<a class="ae lr" href="https://github.com/tonio73/data-science/blob/master/cnn/CnnVsDense-Part1.ipynb" rel="noopener ugc nofollow" target="_blank"> CnnVsDense-Part1.ipynb </a></li><li id="a318" class="oi oj iq kh b ki or kl os ko ot ks ou kw ov la on oo op oq bi translated">激活地图:<a class="ae lr" href="https://github.com/tonio73/data-science/blob/master/cnn/CnnVisualization-1-Activations.ipynb" rel="noopener ugc nofollow" target="_blank">CNN visualization-1-activations . ipynb</a></li><li id="e8f7" class="oi oj iq kh b ki or kl os ko ot ks ou kw ov la on oo op oq bi translated">显著图:<a class="ae lr" href="https://github.com/tonio73/data-science/blob/master/cnn/CnnVisualization-2-SaliencyMaps.ipynb" rel="noopener ugc nofollow" target="_blank">CNN visualization-2-salice maps . ipynb</a></li><li id="d85c" class="oi oj iq kh b ki or kl os ko ot ks ou kw ov la on oo op oq bi translated">UMAP图表:<a class="ae lr" href="https://github.com/tonio73/data-science/blob/master/cnn/CnnVsDense-Part2-Visualization.ipynb" rel="noopener ugc nofollow" target="_blank">CnnVsDense-part 2-visualization . ipynb</a></li></ul></div></div>    
</body>
</html>