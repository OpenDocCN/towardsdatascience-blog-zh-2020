<html>
<head>
<title>How to build a (quasi) real-time hate speech classifier for Twitter</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何为Twitter建立一个(准)实时仇恨言论分类器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-build-a-quasi-real-time-hate-speech-classifier-for-twitter-286d7cc440c2?source=collection_archive---------56-----------------------#2020-06-24">https://towardsdatascience.com/how-to-build-a-quasi-real-time-hate-speech-classifier-for-twitter-286d7cc440c2?source=collection_archive---------56-----------------------#2020-06-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/7cc598128aff7632d41366810d5c2614.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r09doY7F4XRxyoErQq1YgA.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">资料来源:联合国人类住区规划署</p></figure><div class=""/><div class=""><h2 id="1fca" class="pw-subtitle-paragraph kc je jf bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">从培训到新推文中的模型部署</h2></div><p id="52ae" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">社交平台上的网络欺凌和攻击性语言是我们现代的瘟疫之一。网上言论自由很容易演变成对性、政治和宗教信仰的攻击性、不合理和无建设性的批评。机器学习分类器和社交平台上可用的大量数据为缓解这一问题提供了有效的解决方案。</p><p id="0161" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在这个项目中，一系列分类器，如逻辑回归、决策树和CNN，在40000万条人类标记为冒犯性或非冒犯性的推文中进行了训练。这4万条推文是通过合并两个不同的数据集汇编而成的。其中一个最初取自于一个<a class="ae lq" href="https://datahack.analyticsvidhya.com/contest/practice-problem-twitter-sentiment-analysis/" rel="noopener ugc nofollow" target="_blank"> Analytics Vidhaya </a>竞赛，而第二个数据集是在这个<a class="ae lq" href="https://github.com/t-davidson/hate-speech-and-offensive-language/tree/master/data" rel="noopener ugc nofollow" target="_blank"> Github </a>回购上发现的20000条攻击性推文的集合。</p><p id="5e1e" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">整个项目可以在这个<a class="ae lq" href="https://github.com/matteomm/twitter_sentiment_analysis_hatespeech" rel="noopener ugc nofollow" target="_blank"> Github </a>页面上找到。</p><p id="5e37" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">仇恨言论的定义取自《剑桥词典》:“基于种族、宗教、性别或性取向等因素，针对某个人或群体表达仇恨或鼓励暴力的公开言论”。这个项目的主要目标是建立一个能够识别Twitter上仇恨言论的模型。在最后一部分，获胜的模型运行了每天从英国和美国的Twitter API收集的新推文，显示了被标记为攻击性语言或仇恨言论的推文占总推文的百分比。可以在<a class="ae lq" href="https://shrouded-sands-52273.herokuapp.com/" rel="noopener ugc nofollow" target="_blank">这里</a> <em class="lr">找到最终仪表板的链接(如果没有任何东西出现，给它20秒的时间来加载和刷新页面)。</em></p><p id="34bd" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我曾尝试手动复制任何数据科学家在将模型投入生产时都会经历的流程(例如在AWS SageMaker上):</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div class="ab gu cl lw"><img src="../Images/5cd30a268df81dfcf7b5cbd3bdaebe13.png" data-original-src="https://miro.medium.com/v2/format:webp/1*02b-LWLJxV0Lp8r-KksWyw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">亚马逊Sagemaker上的典型循环来源:AWS文档</p></figure><p id="24c3" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">项目的整体结构分为5个主要部分:</p><ul class=""><li id="abfb" class="lx ly jf kw b kx ky la lb ld lz lh ma ll mb lp mc md me mf bi translated">Tweets和EDA的数据清理</li><li id="5371" class="lx ly jf kw b kx mg la mh ld mi lh mj ll mk lp mc md me mf bi translated">模特培训</li><li id="6345" class="lx ly jf kw b kx mg la mh ld mi lh mj ll mk lp mc md me mf bi translated">Twitter API获取新数据到本地MySQL数据库</li><li id="56a7" class="lx ly jf kw b kx mg la mh ld mi lh mj ll mk lp mc md me mf bi translated">使用离线模型对新推文进行预测</li><li id="b65c" class="lx ly jf kw b kx mg la mh ld mi lh mj ll mk lp mc md me mf bi translated">通过Streamlit应用展示结果</li></ul><h1 id="3af0" class="ml mm jf bd mn mo mp mq mr ms mt mu mv kl mw km mx ko my kp mz kr na ks nb nc bi translated">数据清理</h1><p id="c703" class="pw-post-body-paragraph ku kv jf kw b kx nd kg kz la ne kj lc ld nf lf lg lh ng lj lk ll nh ln lo lp ij bi translated">在循环的最开始，有必要处理我们可用的推文，并对它们进行一些转换，以便我们的算法能够以可理解的方式理解文本。与此同时，我们需要合并两个不同的数据集，以便获得负面和正面推文的例子。从最初的数据集中，我有意从每个类别(负面/正面)<strong class="kw jg">中选择了大约20000条推文，这样最终的数据集就已经平衡了。</strong></p><p id="c326" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">现在一切就绪，预处理步骤可以应用于我们所有的最终推文。下面我分解了所有的预处理步骤(每个步骤的所有代码都可以在data_cleaning.ipynb笔记本中找到):</p><ul class=""><li id="28e5" class="lx ly jf kw b kx ky la lb ld lz lh ma ll mb lp mc md me mf bi translated">降低推文中的所有单词</li><li id="a7fe" class="lx ly jf kw b kx mg la mh ld mi lh mj ll mk lp mc md me mf bi translated">删除重复</li><li id="82b7" class="lx ly jf kw b kx mg la mh ld mi lh mj ll mk lp mc md me mf bi translated">删除转发</li><li id="3887" class="lx ly jf kw b kx mg la mh ld mi lh mj ll mk lp mc md me mf bi translated">移除Twitter句柄并计数*</li><li id="6c23" class="lx ly jf kw b kx mg la mh ld mi lh mj ll mk lp mc md me mf bi translated">移除特殊字符并测量推文长度</li><li id="e67d" class="lx ly jf kw b kx mg la mh ld mi lh mj ll mk lp mc md me mf bi translated">词类词汇化</li><li id="7de4" class="lx ly jf kw b kx mg la mh ld mi lh mj ll mk lp mc md me mf bi translated">在引理化之后重新格式化所有的空间和ashtags</li><li id="e62f" class="lx ly jf kw b kx mg la mh ld mi lh mj ll mk lp mc md me mf bi translated">移除停用字词和短于3个字符的字词</li><li id="f7a6" class="lx ly jf kw b kx mg la mh ld mi lh mj ll mk lp mc md me mf bi translated">删除不必要的列并保存最终的数据帧用于探索性数据分析</li></ul><p id="195f" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">(在Twitter中，句柄用于在推文中指代某人，例如“今天塔图因阳光明媚，我们去喝杯奶昔吧@LukeSkywalker”。)</p><h1 id="ba9f" class="ml mm jf bd mn mo mp mq mr ms mt mu mv kl mw km mx ko my kp mz kr na ks nb nc bi translated"><strong class="ak">探索性数据分析</strong></h1><p id="f89d" class="pw-post-body-paragraph ku kv jf kw b kx nd kg kz la ne kj lc ld nf lf lg lh ng lj lk ll nh ln lo lp ij bi translated">从这一点来看，所有这些tweets都准备好进行标记化，我们还可以对它们执行一些其他操作。下面是我创建的一些代码片段，用于创建最常见单词的数据框架，并根据词频构建单词云:</p><figure class="ls lt lu lv gt is"><div class="bz fp l di"><div class="ni nj l"/></div></figure><figure class="ls lt lu lv gt is"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="0b5b" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在这个阶段，已经有一些潜在的模式和初步的见解可以揭示出来:</p><p id="3de5" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><em class="lr">你能从一条微博的长度来判断它吗？</em></p><p id="777f" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">推特的答案是肯定的！推文是否具有攻击性和长度似乎有关系。更具体地说，更长的推文与更积极的信息相关联。</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div class="ab gu cl lw"><img src="../Images/9693dd95d1976877e7cd339934777045.png" data-original-src="https://miro.medium.com/v2/format:webp/1*x8xvw40YJaJ_gfnxzC4TuQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">基于推文长度的比率(正0/负1)</p></figure><p id="b22d" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">如上图所示，负面推文似乎比正面推文平均要短。1代表负面推文，0代表正面推文。可以看到，大多数负面推文集中在图表的左侧，对应于较短的长度。简单的t检验证实，p值小于0.001时，平均差异显著。</p><p id="b71c" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><em class="lr">手柄越多的推文攻击性越强吗？</em></p><p id="0ccf" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">答案似乎是肯定的。</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div class="ab gu cl lw"><img src="../Images/cfcdb64103fb1be63eacb8c75455a970.png" data-original-src="https://miro.medium.com/v2/format:webp/1*2RZ7qdOi2EyVayzqzwKQJA.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">基于每条推文的句柄数量的比率(正0/负1)</p></figure><p id="e220" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在最后一节中，手柄数量和攻击性之间的关系通过再次绘制正/负手柄数量与手柄总数的关系来衡量。绝大多数推文的句柄介于0和3之间，0和1句柄推文之间存在明显差异，后者的攻击性推文比例明显高于2和3类。这可以解释为人们通过使用把手对某人咆哮。</p><p id="66f1" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><em class="lr">*由于敏感语言，在EDA笔记本上可以找到更多EDA和wordclouds】</em></p><h1 id="f1a9" class="ml mm jf bd mn mo mp mq mr ms mt mu mv kl mw km mx ko my kp mz kr na ks nb nc bi translated">模特培训</h1><p id="b2ba" class="pw-post-body-paragraph ku kv jf kw b kx nd kg kz la ne kj lc ld nf lf lg lh ng lj lk ll nh ln lo lp ij bi translated">我在建模中使用的唯一预测器只是文本本身。用tf-idf方法对我们文本的词条化和精炼版本进行矢量化。Tf-idf优于词袋(B-o-w ),因为在这种情况下词的稀有性非常重要。</p><p id="bf44" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">tf-idf矩阵用于所有模型，除了CNN(它只将单词的符号化序列作为输入)和Naive Bayes，在Naive Bayes中，我还尝试使用B-o-w框架来查看性能是否会受到影响。</p><p id="538c" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">CNN的性能没有添加到下面的图表中，但是，它非常低，在验证集上的准确率刚刚超过50%。在神经网络部分还需要做更多的工作，我可能会在低性能的CNN上实现RNN。</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nk"><img src="../Images/88819aeb5c4d4ed06c80b449cefa36da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4C8-nMOoxoAZwR91pujWxA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">跨培训和验证的所有模型的性能概述</p></figure><p id="135d" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">所有模型都用GridSearch CV进行了调整和优化。如前所述，最终表现最好的模型是一个逻辑回归，在测试集上有98%的f-1分数。由于初始数据集从一开始就被设计为平衡的，因此上述任何指标在这种情况下实际上都是有意义的。如果数据集是不平衡的，ROC曲线或宏观/微观精度将是更好的拟合。</p><p id="85fa" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">最后，获胜模型的高性能可以用缺乏中立类别的推文来解释。</strong>f1如此高的分数是因为该模型可以轻松识别非常令人不快的推文和非常积极的推文。在这种情况下，引入第三类中性推文肯定会降低性能，也有助于模型拾取既不一定非常积极也不一定非常消极的推文。</p><h1 id="8e03" class="ml mm jf bd mn mo mp mq mr ms mt mu mv kl mw km mx ko my kp mz kr na ks nb nc bi translated">Twitter API获取和MySQL存储</h1><p id="d759" class="pw-post-body-paragraph ku kv jf kw b kx nd kg kz la ne kj lc ld nf lf lg lh ng lj lk ll nh ln lo lp ij bi translated">现在我们已经有了一个分类推文的离线模型，我们还需要一个基础设施来收集和处理实时和新鲜的推文。</p><p id="3077" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">为了连接到Twitter API，Twitter开发团队需要批准您的登录请求。这可以通过点击链接<a class="ae lq" href="https://developer.twitter.com/en" rel="noopener ugc nofollow" target="_blank">这里</a>来完成，并给出一些关于你打算如何使用Twitter数据的基本信息。Twitter团队通常需要2-3个工作日才能获得最终批准和登录凭证。</p><p id="c7c2" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在请求访问Twitter开发者门户后，可以在本地MySQL数据库上定期收集新的推文，该数据库的创建只是为了容纳推文的输入流。python库Tweepy用于创建与Twitter API的连接。我们从原始JSON流中存储在SQL数据库上的唯一信息是:</p><ul class=""><li id="e8b5" class="lx ly jf kw b kx ky la lb ld lz lh ma ll mb lp mc md me mf bi translated">Twitter ID</li><li id="6085" class="lx ly jf kw b kx mg la mh ld mi lh mj ll mk lp mc md me mf bi translated">推文时间</li><li id="481e" class="lx ly jf kw b kx mg la mh ld mi lh mj ll mk lp mc md me mf bi translated">Twitter文本</li></ul><p id="d5cd" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">所有文本都必须去掉表情符号，才能存储在数据库中。Tweepy的流监听器可以基于特定主题和其他过滤器(如语言)收集信息。在这种情况下，所有标签为“冠状病毒”的词都被跟踪，以确保大量的推文流。同时，为了方便起见，只选择了英语。</p><p id="cb13" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">请在下面找到用于此项目的Tweepy监听器对象的代码片段:</p><figure class="ls lt lu lv gt is"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="6cfe" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">下面是Listener对象的实现，它只流式传输带有“冠状病毒”的标签，也是英文的。Wait_on_rate_limit还确保不会达到每天的流媒体tweets限额。</p><figure class="ls lt lu lv gt is"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="7b18" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在与数据库建立连接后，使用以下函数将数据传递并存储到MySQL数据库:</p><figure class="ls lt lu lv gt is"><div class="bz fp l di"><div class="ni nj l"/></div></figure><h1 id="3d7a" class="ml mm jf bd mn mo mp mq mr ms mt mu mv kl mw km mx ko my kp mz kr na ks nb nc bi translated">使用离线模型对新推文进行预测</h1><p id="f7e6" class="pw-post-body-paragraph ku kv jf kw b kx nd kg kz la ne kj lc ld nf lf lg lh ng lj lk ll nh ln lo lp ij bi translated">有了基本的管道，我们现在可以在一个单独的笔记本上从MySQL数据库中提取批量的新流推文，在那里应用完全相同的预处理和数据清理(下面的fresh_tweets_to_df笔记本)。下图描述了管道的整体结构:</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nl"><img src="../Images/ce88a83b699491d52938c8e301067e35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*XQmk2b7BJj20OBY0.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">数据管道</p></figure><p id="18cd" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在df_to_heroku部分，召回最终获胜的模型和tf-idf酸洗对象。唯一合适的tf-idf对象被转换到新的tweets上，以便生成每次都具有完全相同数量的列(9000个单词)的矩阵。在这种情况下，单词之外的词汇被丢弃，而其余的由矩阵保留。</p><p id="035a" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">随后，将predict_proba函数应用于矢量化矩阵，并且仅过滤高于0.9的值，希望仅收集模型认为非常令人不快的推文。最后一步，绘制攻击性推文和大多数重复出现的词随时间的波动。这个数字然后通过Streamlit上传到Heroku上。</p><p id="eb11" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><em class="lr">使这些笔记本运行的整个过程是通过一系列</em> <strong class="kw jg"> <em class="lr"> cron </em> </strong> <em class="lr">命令自动完成的，这些命令每隔4小时定期执行这些笔记本，使用papermill和nbconvert来触发和转换笔记本(下面的示例显示了计划在每天晚上8.52到9.09之间执行一次的整个过程):</em></p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div class="ab gu cl lw"><img src="../Images/873cd793945896b81fb8f13be87427b7.png" data-original-src="https://miro.medium.com/v2/format:webp/1*MH3q48I0-LxUMI69EYudBw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">自动化管道的Cron命令</p></figure><p id="27c2" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">请注意，nbconvert和papermill的超时命令(设置为150秒)是一种额外的安全措施，以防止Tweepy对象随着时间的推移下载大量的Tweepy。</p><h1 id="65d0" class="ml mm jf bd mn mo mp mq mr ms mt mu mv kl mw km mx ko my kp mz kr na ks nb nc bi translated"><strong class="ak">通过Streamlit应用展示结果</strong></h1><p id="921c" class="pw-post-body-paragraph ku kv jf kw b kx nd kg kz la ne kj lc ld nf lf lg lh ng lj lk ll nh ln lo lp ij bi translated">在df_to_heroku笔记本中，一些非常高级的数据被汇总并保存到matplotlib图中，如下所示:</p><figure class="ls lt lu lv gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nm"><img src="../Images/e36ab7f1ccff4afc10cad7af26f0e65c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P0sdmnFZqqI8gBmTkszJcw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">添加到Streamlit的Matplotlib图形的快照</p></figure><p id="f20f" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">最终仪表板应用程序的底层结构由几行代码构建而成:</p><figure class="ls lt lu lv gt is"><div class="bz fp l di"><div class="ni nj l"/></div></figure><h1 id="f557" class="ml mm jf bd mn mo mp mq mr ms mt mu mv kl mw km mx ko my kp mz kr na ks nb nc bi translated">局限性和未来工作</h1><p id="6131" class="pw-post-body-paragraph ku kv jf kw b kx nd kg kz la ne kj lc ld nf lf lg lh ng lj lk ll nh ln lo lp ij bi translated">虽然最终的模型性能即使在我们数据集的测试结果上也非常好，但这个项目的一个主要限制是测量模型在新推文中的性能。实际上，我们可以只看一些被贴上负面标签的推文，就主观地认为它们是否具有攻击性。这最后一点提出了这个框架中的另一个重要问题，它与人类手动标记推文的固有偏见有关。</p><p id="146a" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">用来标记最初的基本事实的判断也是谬误的，因为对一些人来说是冒犯性的，对另一些人来说可能不是冒犯性的。单词以外的词汇可能是这种模式的主要缺点之一。该算法不能很好地处理包含大量单词的句子，这些单词不包含在我们最初的9000万单词长的词汇表中。递归神经网络可能是处理词汇外单词的最佳选择。</p><p id="b0d8" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">感谢阅读！</p></div></div>    
</body>
</html>