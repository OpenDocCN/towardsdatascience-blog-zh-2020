<html>
<head>
<title>ML from Scratch: Linear Regression Model with NumPy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ML 从零开始:带 NumPy 的线性回归模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/linear-regression-model-with-numpy-7d270feaca63?source=collection_archive---------30-----------------------#2020-05-27">https://towardsdatascience.com/linear-regression-model-with-numpy-7d270feaca63?source=collection_archive---------30-----------------------#2020-05-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/267f1ebd3b41185806b3d46eae7fc942.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZLFL7YJJtHj7LGxohHYRWQ.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">在<a class="ae jg" href="https://unsplash.com/s/photos/line?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae jg" href="https://unsplash.com/@ridham?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Ridham Nagralawala </a>拍摄的照片</p></figure><div class=""/><div class=""><h2 id="0f2a" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">线性回归完全指南</h2></div></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><p id="29e3" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">在这个项目中，我们将看到如何创建一个使用多元线性回归算法的机器学习模型。</p><p id="aafe" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><em class="mb">这个项目的主要焦点是解释线性回归是如何工作的，以及如何使用令人敬畏的 NumPy 模块从头开始编写线性回归模型。</em></p><p id="1005" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">当然，您可以使用 scikit-learn 创建一个线性回归模型，只需 3-4 行代码，但实际上，从头开始编写您自己的模型远比依赖一个在您坐着观看时为您做所有事情的库更棒。</p><p id="862c" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">不仅如此，编写定制模型意味着您可以完全控制模型做什么，以及模型如何处理您将提供给它的数据。这允许在训练过程中有更大的灵活性，并且您实际上可以调整模型，使其在将来重新训练或生产过程中根据需要更加健壮和响应真实世界的数据。</p><p id="2ba3" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">在这个项目中，我们的模型将被用来预测一辆汽车的 CO₂排放量的基础上，其特点，如发动机的大小，燃料消耗等。</p><p id="81e4" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">让我们开始做这个项目吧。</p></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h1 id="c05f" class="mc md jj bd me mf mg mh mi mj mk ml mm kp mn kq mo ks mp kt mq kv mr kw ms mt bi translated">进行必要的进口</h1><p id="f674" class="pw-post-body-paragraph lf lg jj lh b li mu kk lk ll mv kn ln lo mw lq lr ls mx lu lv lw my ly lz ma im bi translated">首先，我们将导入必要的 PyData 模块。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="e94e" class="ni md jj ne b gy nj nk l nl nm">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>%matplotlib inline</span></pre><p id="459c" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">现在，让我们导入数据集。该数据集包含在加拿大零售的新型轻型汽车的特定车型燃料消耗等级和估计二氧化碳排放量。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="7f26" class="ni md jj ne b gy nj nk l nl nm">df = pd.read_csv("FuelConsumptionCo2.csv")<br/>print(df.head())</span></pre><p id="c676" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">这是数据集的链接。在这个项目的最后，我还将分享包含 Jupyter 笔记本和数据集的 Github repo 的链接。</p><div class="is it gp gr iu nn"><a href="https://drive.google.com/file/d/13UHA0B1velyQh9fk3eBOK4i337J441Ce/view?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="no ab fo"><div class="np ab nq cl cj nr"><h2 class="bd jk gy z fp ns fr fs nt fu fw ji bi translated">燃料消费 Co2.csv</h2><div class="nu l"><p class="bd b dl z fp ns fr fs nt fu fw dk translated">点击链接下载 csv 文件-drive.google.com</p></div></div></div></a></div><p id="27a3" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">这是它在我的 Jupyter 笔记本上的样子:</p><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nv"><img src="../Images/df3d0bbbe39a41ab3578493dac80c3c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J9E-QFyLsHnF9dUcr1fO4A.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">Jupyter 笔记本中数据帧的视图</p></figure><p id="310b" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">以下是我们数据集中的列。</p><ul class=""><li id="121e" class="nw nx jj lh b li lj ll lm lo ny ls nz lw oa ma ob oc od oe bi translated"><strong class="lh jk">年款</strong>，例如 2014 年款</li><li id="483e" class="nw nx jj lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated"><strong class="lh jk">制造</strong>例如讴歌</li><li id="8719" class="nw nx jj lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated"><strong class="lh jk">车型</strong>例如 ILX</li><li id="078b" class="nw nx jj lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated"><strong class="lh jk">车辆类别</strong>例如 SUV</li><li id="c1cb" class="nw nx jj lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated"><strong class="lh jk">发动机尺寸</strong>例如 4.7</li><li id="9155" class="nw nx jj lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated"><strong class="lh jk">气缸</strong>例如 6 个</li><li id="ec5c" class="nw nx jj lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated"><strong class="lh jk">变速器</strong>例如 A6</li><li id="db2a" class="nw nx jj lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated"><strong class="lh jk">城市油耗(升/百公里)</strong>例如 9.9</li><li id="f946" class="nw nx jj lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated"><strong class="lh jk">HWY 油耗(升/百公里)</strong>例如 8.9</li><li id="5270" class="nw nx jj lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated"><strong class="lh jk">油耗梳(升/百公里)</strong>例如 9.2</li><li id="2f9e" class="nw nx jj lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated"><strong class="lh jk">二氧化碳排放量(克/公里)</strong>例如 182 →低→ 0</li></ul></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h1 id="ecc9" class="mc md jj bd me mf mg mh mi mj mk ml mm kp mn kq mo ks mp kt mq kv mr kw ms mt bi translated">数据争论和功能选择</h1><p id="6d07" class="pw-post-body-paragraph lf lg jj lh b li mu kk lk ll mv kn ln lo mw lq lr ls mx lu lv lw my ly lz ma im bi translated">任何数据科学项目中最重要的步骤之一是预处理数据。这包括清理数据、根据需要对一些列进行类型转换、分类变量的转换以及根据项目要求对数据进行标准化/规范化。</p><p id="3b41" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">对于我们的项目，预处理的第一步是检查我们是否需要对任何特性/目标变量的数据类型进行类型转换。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="4bbc" class="ni md jj ne b gy nj nk l nl nm">print(df.dtypes)</span></pre><p id="7083" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">我们得到以下输出:</p><figure class="mz na nb nc gt iv gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/09b57bf7f41bc6e431334649531e1109.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*h9yjAUcGdqMZ0zFvckvraA.jpeg"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">不同列的数据类型</p></figure><p id="e984" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">正如我们所看到的，没有必要对任何列进行类型转换。</p><p id="e608" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">数据争论过程的第二步是分析这些特性是否需要标准化。为此，让我们看一看数据框架的描述性分析。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="6d52" class="ni md jj ne b gy nj nk l nl nm">print(df.describe())</span></pre><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ol"><img src="../Images/9b8f46badc4fd135ade3b45517902ffa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CId5KdCr_cTxgEizgqgttQ.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">数据帧的描述性分析</p></figure><p id="6a2a" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">正如我们所看到的，所有潜在的功能在规模上是相同的，所以我们不需要标准化任何功能。</p><p id="d850" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">对于这个项目，我们将选择的特征是<strong class="lh jk">发动机尺寸、气缸</strong> &amp; <strong class="lh jk">燃料消耗 _ 组合</strong>，目标变量是<strong class="lh jk">二氧化碳排放量</strong>。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="b020" class="ni md jj ne b gy nj nk l nl nm">df = df[['ENGINESIZE','CYLINDERS','FUELCONSUMPTION_COMB','CO2EMISSIONS']]</span><span id="7047" class="ni md jj ne b gy om nk l nl nm">print(df.head())</span></pre><figure class="mz na nb nc gt iv gh gi paragraph-image"><div class="gh gi on"><img src="../Images/73aa6124cebee8721a0e55b39b2690e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/1*PERHjDOQlhZQijst97iR3Q.jpeg"/></div></figure><p id="dabb" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">我们的下一步——检查数据帧中 NaN(null)值的数量。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="8ad2" class="ni md jj ne b gy nj nk l nl nm">for i in df.columns:<br/>    print(df[i].isnull().value_counts()) </span></pre><figure class="mz na nb nc gt iv gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/ec41296591c8c49ce873a5a58d6cb670.png" data-original-src="https://miro.medium.com/v2/resize:fit:904/format:webp/1*aNiG6JJDY6DUr45q2kiJIw.jpeg"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">数据帧中的空值计数</p></figure><p id="607c" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">正如我们所看到的，在我们的数据帧中没有空值。所以这些数据非常适合训练模型。</p></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h1 id="ee78" class="mc md jj bd me mf mg mh mi mj mk ml mm kp mn kq mo ks mp kt mq kv mr kw ms mt bi translated">数据可视化和分析</h1><p id="3b1c" class="pw-post-body-paragraph lf lg jj lh b li mu kk lk ll mv kn ln lo mw lq lr ls mx lu lv lw my ly lz ma im bi translated">首先，我们将看看特征和目标变量的相关性。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="31fa" class="ni md jj ne b gy nj nk l nl nm">print(df.corr())</span></pre><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi op"><img src="../Images/1c7a9f37738c73d732bd13ec6252d792.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B8refuSCmc-hUZFHAxQwCA.jpeg"/></div></div></figure><p id="c839" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">该表显示了特征和目标变量之间的强正相关性。记住，强相关性对于线性回归模型来说是一件好事。</p><p id="7090" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">现在，让我们将不同特征相对于目标变量的曲线可视化。这将使我们了解这些特征是否与目标变量呈线性关系。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="2752" class="ni md jj ne b gy nj nk l nl nm">fig, a <strong class="ne jk">=</strong>  plt.subplots(1,3, figsize <strong class="ne jk">=</strong> (18, 5))</span><span id="3059" class="ni md jj ne b gy om nk l nl nm">a[0].scatter(df['ENGINESIZE'], df['CO2EMISSIONS'], color <strong class="ne jk">=</strong> 'c')<br/>a[0].set_title('Engine Size vs CO2 Emissions')<br/>a[0].set_xlabel('Engine Size (L)')</span><span id="74f7" class="ni md jj ne b gy om nk l nl nm">a[1].scatter(df['CYLINDERS'], df['CO2EMISSIONS'], color <strong class="ne jk">=</strong> 'm')<br/>a[1].set_title('No. of Cylinders vs CO2 Emissions')<br/>a[1].set_xlabel('No. of Cylinders')</span><span id="3b30" class="ni md jj ne b gy om nk l nl nm">a[2].scatter(df['FUELCONSUMPTION_COMB'], df['CO2EMISSIONS'], color <strong class="ne jk">=</strong> 'b')<br/>a[2].set_title('Fuel Consumption vs CO2 Emissions')<br/>a[2].set_xlabel('Fuel Consumption (L/100km)')</span><span id="bd4d" class="ni md jj ne b gy om nk l nl nm">fig.text(0.08, 0.5, 'CO2 Emissions', va<strong class="ne jk">=</strong>'center', rotation<strong class="ne jk">=</strong>'vertical')</span><span id="95cb" class="ni md jj ne b gy om nk l nl nm"><br/>plt.show()</span></pre><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oq"><img src="../Images/06cf5cfd8c61364ae5d9109e370a097c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rt3OLKfgsLpLHVb2K6598g.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">不同特征(x 轴)与目标变量(y 轴)的关系图</p></figure><p id="a4a0" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">正如我们所看到的，这些特征显示了与目标的相当大的线性关系。因此，我们可以用它们来训练模型。</p></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h1 id="8be6" class="mc md jj bd me mf mg mh mi mj mk ml mm kp mn kq mo ks mp kt mq kv mr kw ms mt bi translated">从零开始的线性回归模型</h1><p id="5752" class="pw-post-body-paragraph lf lg jj lh b li mu kk lk ll mv kn ln lo mw lq lr ls mx lu lv lw my ly lz ma im bi translated">线性回归使用以下数学公式，通过自变量预测因变量。</p><p id="03ea" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh jk"> y = wx + b </strong></p><p id="d409" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">这里，</p><ul class=""><li id="d0a4" class="nw nx jj lh b li lj ll lm lo ny ls nz lw oa ma ob oc od oe bi translated"><strong class="lh jk"> y </strong> -因变量</li><li id="11fd" class="nw nx jj lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated"><strong class="lh jk"> x </strong> -因变量</li><li id="2c4d" class="nw nx jj lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated"><strong class="lh jk"> w </strong> -与自变量相关的权重</li><li id="708e" class="nw nx jj lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated"><strong class="lh jk"> b </strong> -给定 lin-reg 方程的偏差</li></ul><p id="c578" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">以下是开发线性回归模型的过程。</p><ol class=""><li id="5f8d" class="nw nx jj lh b li lj ll lm lo ny ls nz lw oa ma or oc od oe bi translated">将数据集分成训练集和测试集。<em class="mb">然而，为了简单起见，我们将在自定义模型中跳过这一步。</em></li><li id="782a" class="nw nx jj lh b li of ll og lo oh ls oi lw oj ma or oc od oe bi translated">给模型分配随机权重和偏差，然后根据随机权重和偏差计算因变量<strong class="lh jk"> ŷ </strong>。</li><li id="8de0" class="nw nx jj lh b li of ll og lo oh ls oi lw oj ma or oc od oe bi translated">使用损失函数来计算总信息损失，即模型内的总不准确性。<em class="mb">在我们的例子中，我们将使用均方差</em>(<strong class="lh jk">【MSE】</strong>)<em class="mb">损失函数。</em></li><li id="9805" class="nw nx jj lh b li of ll og lo oh ls oi lw oj ma or oc od oe bi translated">我们的下一步是减少我们模型的总均方误差。<em class="mb">为此，我们将使用随机梯度下降(</em> <strong class="lh jk"> <em class="mb"> SGD </em> </strong> <em class="mb">)函数，这是回归模型中最常用的优化算法之一。</em>我们将在编写优化器函数时详细讨论 SGD 函数。</li><li id="896b" class="nw nx jj lh b li of ll og lo oh ls oi lw oj ma or oc od oe bi translated">我们将根据优化算法更新模型权重和偏差，然后重新训练模型。这是一个循环的过程，将不断重复，直到我们实现一个信息损失低的最佳模型。</li></ol><p id="b9fc" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">首先，让我们将特性转换成一个 NumPy 数组，<strong class="lh jk">特性</strong>。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="1501" class="ni md jj ne b gy nj nk l nl nm">features <strong class="ne jk">= </strong>df[['ENGINESIZE','CYLINDERS','FUELCONSUMPTION_COMB']].to_numpy() <em class="mb">#Converts the dataframe to numpy array</em></span><span id="1700" class="ni md jj ne b gy om nk l nl nm">print(features)</span></pre><figure class="mz na nb nc gt iv gh gi paragraph-image"><div class="gh gi os"><img src="../Images/d3a73d1a75785800d65c638cd4a7c349.png" data-original-src="https://miro.medium.com/v2/resize:fit:584/format:webp/1*J_GKo6MrEB8_qnvqypk75Q.jpeg"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">用于训练模型的一组特征</p></figure><p id="5994" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">现在，让我们将目标列转换为一个 NumPy 数组，<strong class="lh jk"> target </strong>。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="a0a9" class="ni md jj ne b gy nj nk l nl nm">target = df[‘CO2EMISSIONS’].to_numpy() #Converts the dataframe to numpy array</span><span id="42f3" class="ni md jj ne b gy om nk l nl nm">print(target)</span></pre><figure class="mz na nb nc gt iv gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/1dd79fcb035b203bec093640ae000222.png" data-original-src="https://miro.medium.com/v2/resize:fit:1084/format:webp/1*3_80bfD5DmTQqVwA_Jg11A.jpeg"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">目标变量数组(车辆的实际 CO₂排放值)</p></figure><p id="75d0" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">由于我们有 3 个因变量，我们将有 3 个权重。让我们生成 3 个小随机权重的数组权重。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="f424" class="ni md jj ne b gy nj nk l nl nm">weights <strong class="ne jk">=</strong> np.random.rand(3) <em class="mb">#Generates a numpy array with two small random floats</em></span><span id="79a9" class="ni md jj ne b gy om nk l nl nm">print(weights)</span></pre><p id="1e22" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">因为我们只有一个目标变量，所以我们只有一个偏差，<strong class="lh jk"> b </strong>。我们还将创建一个数组<strong class="lh jk"> bias </strong>等于<strong class="lh jk"> features </strong>数组的长度，每个元素都有 bias <strong class="lh jk"> b </strong>。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="2e98" class="ni md jj ne b gy nj nk l nl nm">b <strong class="ne jk">=</strong> np.random.rand(1) <em class="mb">#Generates a numpy array with a small random float</em></span><span id="b8a6" class="ni md jj ne b gy om nk l nl nm">bias <strong class="ne jk">=</strong> np.array([b[0] <strong class="ne jk">for</strong> i <strong class="ne jk">in</strong> range(len(features))])</span><span id="c159" class="ni md jj ne b gy om nk l nl nm">print(bias)</span></pre><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ou"><img src="../Images/3f14bd3a1513a0ac79902abf1c15721f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2a78N-F43zqwavU5GiFIzw.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">偏置阵列</p></figure><p id="5f08" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">现在，我们将定义使用权重、偏差和因变量来计算ŷ.的模型函数</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="7029" class="ni md jj ne b gy nj nk l nl nm"><strong class="ne jk">def</strong> linearRegr(features, weights, bias):</span><span id="45c3" class="ni md jj ne b gy om nk l nl nm">    """Calculates the y_hat predicted values using the given parameters of weights, dependent variables, and biases.</span><span id="7b6f" class="ni md jj ne b gy om nk l nl nm">    Args:<br/>        -dependant_var: Matrix of dependant variable values<br/>        -weights: Matrix/array of weights associated with each dependant variable<br/>        -biases: Biases for the model<br/>    Returns:<br/>        -Array/matrix of predicted values</span><span id="a865" class="ni md jj ne b gy om nk l nl nm">    """</span><span id="7632" class="ni md jj ne b gy om nk l nl nm">    y_hat <strong class="ne jk">=</strong> weights.dot(features.transpose()) <strong class="ne jk">+</strong> np.array([bias[0] <strong class="ne jk">for</strong> i <strong class="ne jk">in</strong> range(len(features))]) <em class="mb"># Takes the value stored in the bias array and makes an array of length of feature matrix for addition</em></span><span id="4e55" class="ni md jj ne b gy om nk l nl nm"><strong class="ne jk">    return</strong> y_hat</span></pre><p id="a938" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">现在，让我们运行该函数一次，看看我们将得到的结果。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="6181" class="ni md jj ne b gy nj nk l nl nm">y_hat = linearRegr(features, weights, b)<br/>print(y_hat)</span></pre><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ov"><img src="../Images/7ee9acdb166991e55b4407130b0c6dfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ywP6cXdrfRG43_EqKwFDgA.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">针对随机生成的权重和偏差运行 linearRegr 函数获得的ŷ(发音为“y_hat”)数组</p></figure><p id="6296" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">现在，我们将定义 MSE 函数来计算我们的模型的总损失。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="6b48" class="ni md jj ne b gy nj nk l nl nm">def meanSqrError(y, y_hat):<br/>    """Calculates the total mean squared error.<br/>    <br/>    Args- <br/>        y: Array of actual target values<br/>        y_hat: Array of predicted target values<br/>        <br/>    Returns-<br/>        total mean squared error<br/>    """<br/>    MSE = np.sum((y - y_hat) ** 2) / len(y)<br/>    return MSE</span></pre><p id="2d13" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">现在让我们根据之前得到的值来计算信息损失。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="17e5" class="ni md jj ne b gy nj nk l nl nm">print('Total error- {}'.format(meanSqrError(target, y_hat)))</span></pre><figure class="mz na nb nc gt iv gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/ad57466d50785437d3f30e4849543920.png" data-original-src="https://miro.medium.com/v2/resize:fit:610/format:webp/1*h2ZVdtsgifPLeBWbPZPqtg.png"/></div></figure><p id="ff51" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">正如我们所看到的，我们的模型目前非常不准确，我们需要优化它。</p></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h1 id="2c53" class="mc md jj bd me mf mg mh mi mj mk ml mm kp mn kq mo ks mp kt mq kv mr kw ms mt bi translated">优化模型</h1><p id="b3eb" class="pw-post-body-paragraph lf lg jj lh b li mu kk lk ll mv kn ln lo mw lq lr ls mx lu lv lw my ly lz ma im bi translated">现在是线性回归中最重要的一步。制定 SGD 函数。与到目前为止我们已经讨论过的所有基本函数相比，这是一个稍微高级的主题。需要一些微分学的知识；具体来说是偏导数。我试图在下面的图片中解释这一点，但是，如果你不明白，我强烈建议你在进一步学习之前熟悉机器学习的数学部分(微积分，统计和概率，线性代数)。</p><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ox"><img src="../Images/18aa084d1d111dfde23371bd9b955be1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-hLh_JujozKKXB1eQzksTA.jpeg"/></div></div></figure><p id="96f6" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">图片来源- <a class="ae jg" rel="noopener" target="_blank" href="/linear-regression-using-gradient-descent-97a6c8700931">阿达什·Menon-Medium.com</a></p><p id="2953" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh jk">一旦我们计算出梯度，我们将按如下方式更新参数。</strong></p><ul class=""><li id="a53a" class="nw nx jj lh b li lj ll lm lo ny ls nz lw oa ma ob oc od oe bi translated"><strong class="lh jk"> m = m - α D </strong> m</li><li id="a970" class="nw nx jj lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated"><strong class="lh jk"> c = c - α D </strong> c</li></ul><p id="6a10" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">这里，</p><ul class=""><li id="c697" class="nw nx jj lh b li lj ll lm lo ny ls nz lw oa ma ob oc od oe bi translated"><strong class="lh jk">E</strong>——总均方误差</li><li id="facf" class="nw nx jj lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated"><strong class="lh jk"> m </strong> -与特征相关的权重</li><li id="968a" class="nw nx jj lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated"><strong class="lh jk"> c </strong> -模型偏差</li><li id="df60" class="nw nx jj lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated"><strong class="lh jk"> y </strong> -实际目标值的数组</li><li id="5735" class="nw nx jj lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated"><strong class="lh jk"> ŷ </strong> -预测目标值</li><li id="7c93" class="nw nx jj lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated"><strong class="lh jk">D</strong>m-E w r t 重量的偏导数<strong class="lh jk"> m </strong></li><li id="d952" class="nw nx jj lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated"><strong class="lh jk">D</strong>c-E w r t 偏差的偏导数<strong class="lh jk"> c </strong></li><li id="6602" class="nw nx jj lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated"><strong class="lh jk"> α </strong> -学习率，即优化器函数采取的步长。</li></ul><p id="1565" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">一旦我们有了权重和偏差的新的更新值，我们将再次计算损失。我们将对<strong class="lh jk"> n </strong>个时期重复该过程，即循环次数，并在每个时期后绘制损失值。为了保持代码的整洁，我将创建一个单独的函数来计算梯度。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="4e14" class="ni md jj ne b gy nj nk l nl nm">def gradient(target, features, weights, bias):<br/>    """Returns the gradient(slopes) for weights and biases<br/>    """  <br/>    m = len(features)<br/>    target_pred = linearRegr(features, weights, bias)<br/>    loss = target - target_pred # y-y_hat<br/>    # Gradient calculation for model bias<br/>    grad_bias = np.array([-2/m * np.sum(loss)])<br/>    <br/>    grad_weights = np.ones(3)<br/>    # Gradient calculation for first feature<br/>    feature_0 = np.array([feature[0] for feature in features])<br/>    grad_weights[0] = -2/m * np.sum(loss * feature_0)<br/>    # Gradient calculation for second feature<br/>    feature_1 = np.array([feature[1] for feature in features])<br/>    grad_weights[1] = -2/m * np.sum(loss * feature_1)<br/>    # Gradient calculation for third feature<br/>    feature_2 = np.array([feature[1] for feature in features])<br/>    grad_weights[2] = -2/m * np.sum(loss * feature_2)<br/>    <br/>    return grad_bias, grad_weights</span></pre><p id="25d6" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">现在，让我们编写 SDG 函数，它将返回更新后的权重和偏差，这样我们就可以制定我们的最终模型。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="273d" class="ni md jj ne b gy nj nk l nl nm">def stochGradDesMODIFIED(learning_rate, epochs, target, features, weights, bias):<br/>    """Performs stochastic gradient descent optimization on the model.<br/>    <br/>    Args-<br/>        learning_rate- Size of the step the function will take during optimization<br/>        epochs- No. of iterations the function will run for on the model<br/>        target- Actual emission values<br/>        features- Matrix of dependent variables<br/>        weights- Weights associated with each feature<br/>        bias- Model bias<br/>    <br/>    Returns-<br/>        return_dict = {'weights': weights, 'bias': bias[0], 'MSE': total_MSE_new, 'MSE_list': MSE_list}<br/>        <br/>    """</span><span id="b7fc" class="ni md jj ne b gy om nk l nl nm">MSE_list = []<br/>    for i in range(epochs):<br/>        grad_bias, grad_weights = gradient(target, features, weights, bias)<br/>        weights -= grad_weights * learning_rate<br/>        bias -= grad_bias * learning_rate<br/>        new_pred = linearRegr(features, weights, bias)<br/>        total_MSE_new = meanSqrError(target, new_pred)<br/>        MSE_list.append(total_MSE_new)<br/>    return_dict = {'weights': weights, 'bias': bias[0], 'MSE': total_MSE_new, 'MSE_list': MSE_list}<br/>    return return_dict</span></pre><p id="b756" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">最后，我们有线性回归模型的优化函数。现在让我们运行该函数，并存储这些值以备将来使用。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="b5f4" class="ni md jj ne b gy nj nk l nl nm">model_val = stochGradDesMODIFIED(0.001, 2000, target, features, weights, bias)</span><span id="5bc2" class="ni md jj ne b gy om nk l nl nm">print("Weights- {}\nBias- {}\nMSE- {}".format(model_val['weights'], model_val['bias'], model_val['MSE']))</span></pre><figure class="mz na nb nc gt iv gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/f56293593dea4068f149f38e78f05256.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*uXqPwWp7gkOTIuYsQ98d3A.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">更新权重、偏差和 MSE 误差</p></figure><p id="5493" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">最初的 MSE 约为 65，000，而目前的 MSE 约为 680。从结果可以看出，我们的模型有了显著的改进。</p><p id="9eb8" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">最后，我们将编写使用更新的模型权重和偏差来预测目标值的模型函数。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="568e" class="ni md jj ne b gy nj nk l nl nm">def LinearRegressionModel(model_val, feature_list):<br/>    """Predicts the CO2 emission values of the vehicle<br/>    <br/>    Args-<br/>        model_val- This is the dictionary returned by the stockGradDesMODIFIED function. Contains model weights and biases<br/>        feature_list- An array of the dependent variables<br/>    Returns-<br/>        co2_emission- Emission predictions for the given set of features<br/>    """<br/>    co2_emission = np.sum(model_val['weights'] * feature_list) + model_val['bias']<br/>    return co2_emission</span></pre></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h1 id="84b7" class="mc md jj bd me mf mg mh mi mj mk ml mm kp mn kq mo ks mp kt mq kv mr kw ms mt bi translated">测试和评估</h1><p id="1290" class="pw-post-body-paragraph lf lg jj lh b li mu kk lk ll mv kn ln lo mw lq lr ls mx lu lv lw my ly lz ma im bi translated">作为测试运行，我们现在将在以下数据上测试我们的模型。</p><p id="46c9" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">feature_list = [2.0，4，8.5]</p><p id="9bc4" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">数据的实际目标值是 196。让我们看看我们的模型进展如何。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="5f22" class="ni md jj ne b gy nj nk l nl nm">target_price = 196<br/>feature_list = [2.0, 4, 8.5]<br/>predicted_price = LinearRegressionModel(model_val, feature_list)<br/>print(predicted_price)</span></pre><figure class="mz na nb nc gt iv gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/9e2d0d88d617f56939e051fc4218250d.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*_BCUA0LDNxMYHo44qSxWoA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">预测的二氧化碳排放量</p></figure><p id="15c8" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">给定模型的原始目标值是 196。正如我们所看到的，考虑到这是一个从零开始的模型实现，我们的模型在进行预测方面做得相当好。不过，您可以通过调整一些东西或者运行更多的优化时期来进一步改进该模型。然而，过多的优化会导致模型过度拟合，这同样对模型不利，因为过度拟合使得模型实际上不能用于真实世界的数据。</p><p id="3cab" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">现在，为了检查我们模型的准确性，我们将计算它的 r 平方得分。以下是 r2 得分的公式-</p><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pa"><img src="../Images/e2370cd39c4c42d87adb18ba0fb6e6a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ikgOLveg7aK_quszXlkDJA.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">R 平方得分公式</p></figure><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="e420" class="ni md jj ne b gy nj nk l nl nm">def r2_score(target, prediction):<br/>    """Calculates the r2 score of the model<br/>    <br/>    Args-<br/>        target- Actual values of the target variable<br/>        prediction- Predicted values, calculated using the model<br/>        <br/>    Returns- <br/>        r2- r-squared score of the model<br/>    """<br/>    r2 = 1- np.sum((target-prediction)**2)/np.sum((target-target.mean())**2)<br/>    return r2</span></pre><figure class="mz na nb nc gt iv gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/4bf13cf106bcfb9c8f3d9ccf8b8b9a81.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*jA_3aKmcLP78oCeSc3wUfw.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">我们模型的 r 平方得分</p></figure><p id="9292" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">正如我们所看到的，我们的模型解释了响应数据围绕其平均值的大约 83%的可变性，这是相当好的。然而，机器学习模型总是有改进的空间！</p><p id="df16" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">至此，我们的项目告一段落。</p><p id="8ece" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">我将制作一系列博客，在那里我们将从事类似的项目，从头开始编写新的 ML 模型，用真实世界的数据集和问题陈述进行实践。</p><p id="0019" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">我只是机器学习和数据科学领域的新手，所以任何建议和批评都将真正帮助我提高。</p><p id="bba1" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">点击以下链接，继续关注更多 ML 内容！</p><p id="91d1" class="pw-post-body-paragraph lf lg jj lh b li lj kk lk ll lm kn ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated"><strong class="lh jk">数据集和 Jupyter 笔记本的 GitHub repo 链接- </strong></p><div class="is it gp gr iu nn"><a href="https://github.com/amansharma2910/CO2_emission_predictionML" rel="noopener  ugc nofollow" target="_blank"><div class="no ab fo"><div class="np ab nq cl cj nr"><h2 class="bd jk gy z fp ns fr fs nt fu fw ji bi translated">aman Sharma 2910/CO2 _ 排放 _ 预测 ML</h2><div class="pc l"><h3 class="bd b gy z fp ns fr fs nt fu fw dk translated">通过在 GitHub 上创建帐户，为 aman Sharma 2910/CO2 _ emission _ prediction ml 开发做出贡献。</h3></div><div class="nu l"><p class="bd b dl z fp ns fr fs nt fu fw dk translated">github.com</p></div></div><div class="pd l"><div class="pe l pf pg ph pd pi ja nn"/></div></div></a></div></div></div>    
</body>
</html>