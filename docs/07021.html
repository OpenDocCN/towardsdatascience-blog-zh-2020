<html>
<head>
<title>The Future of Artificial Intelligence — Neuromorphic Computing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能的未来——神经形态计算</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-future-of-artificial-intelligence-neuromorphic-computing-34bcc5cc35a?source=collection_archive---------6-----------------------#2020-05-30">https://towardsdatascience.com/the-future-of-artificial-intelligence-neuromorphic-computing-34bcc5cc35a?source=collection_archive---------6-----------------------#2020-05-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="bf3a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">深度学习行业需要一种新型的硬件——神经形态硬件——才能真正高效。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/8268463704813313634619720018a711.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uBTdz4oTrhWBYdbm"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae ky" href="https://unsplash.com/@franckinjapan?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Franck V. </a>拍摄的照片</p></figure><p id="d7a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated"><span class="l lw lx ly bm lz ma mb mc md di"> E </span>人工智能领域的每个人都知道什么是神经网络。大多数从业者都知道训练任何值得注意的神经网络都需要巨大的处理能力和能量消耗。也就是说，为了该领域的进一步发展，需要一种新型的硬件。</p><p id="31db" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一些专家认为量子计算机就是硬件。尽管量子计算有着巨大的前景，但它是一项需要几十年才能发展起来的技术。物理理论还不够成熟，不足以开发出有用且经济的设备。</p><p id="62fc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一方面，神经形态计算将花费更少的时间和资源来开发，并且在设备开发成本和处理能力的能源成本方面都非常有用和经济高效。</p><p id="e429" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于大多数读者不知道什么是神经形态计算，我将在本文中描述这项新技术，以及它将使我们在“更接近量子”的未来做什么。这一切都始于神经形态芯片中使用的核心电子组件<a class="ae ky" href="https://en.wikipedia.org/wiki/Memristor" rel="noopener ugc nofollow" target="_blank">忆阻器</a>。</p><h1 id="9e5c" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">忆阻器——缺失的电路元件</h1><p id="9efa" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">忆阻器已经被证明以类似于大脑突触的方式工作，因为它们具有所谓的可塑性。这种可塑性可以用来创建受大脑启发的人工结构，以处理和记忆数据。</p><p id="7e01" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">众所周知，有三种基本的无源电子元件:</p><ul class=""><li id="5b07" class="nb nc it lb b lc ld lf lg li nd lm ne lq nf lu ng nh ni nj bi translated">电容器——具有储存电能(在电场中)并在需要时将电能释放到电路中的功能；</li><li id="fd36" class="nb nc it lb b lc nk lf nl li nm lm nn lq no lu ng nh ni nj bi translated">电阻器——是一种对电子流动产生阻力的无源器件；</li><li id="3ceb" class="nb nc it lb b lc nk lf nl li nm lm nn lq no lu ng nh ni nj bi translated">电感器也称为线圈、扼流圈或电抗器，是一种无源双端电子设备，当电流流过磁场时，它在磁场中存储能量。</li></ul><p id="ede0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">多年来，这是仅有的三种基本无源电子元件，直到忆阻器出现。</p><h2 id="5f38" class="np mf it bd mg nq nr dn mk ns nt dp mo li nu nv mq lm nw nx ms lq ny nz mu oa bi translated">那么它们是什么呢？</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/8b634c4a7a395e94cd6ac7f80b1d9a59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2lztqEqRv1SVgE4H_jBDLA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">忆阻器矩阵</p></figure><p id="08b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">忆阻器是第四类电路，加入了上述组件，主要在纳米尺度上展示其独特的属性。理论上，忆阻器(由<strong class="lb iu">存储器和电阻</strong>串联而成)是一种无源电路元件，它维持两端元件上的电流和电压的时间积分之间的关系。因此，忆阻器的电阻根据设备的忆阻功能而变化，允许通过微小的读取电荷来访问设备的“历史”(或存储器)。</p><p id="1707" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所有这些用简单的语言拼写意味着这是一个无源电子元件，能够“记住”其过去的状态(电阻值)，即使没有能量通过它。忆阻器也可以用作存储器和处理单元，这是一个重要的壮举，我将在稍后描述。</p><p id="5cd6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">忆阻器是由Leon Chua在1971年首次发现的，只是在理论上。如果你想了解更多，你可以在<a class="ae ky" href="http://www.cpmt.org/scv/meetings/chua.pdf" rel="noopener ugc nofollow" target="_blank">的原始论文</a>中找到。</p><p id="a1c8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">直到2008年，惠普实验室的一个研究小组才首次基于氧化钛薄膜制造出忆阻器。根据惠普实验室团队的说法，忆阻器的行为方式如下:</p><p id="c3b7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="oc">“忆阻器的电阻不是恒定的，而是取决于之前流过该设备的电流的历史，即它现在的电阻取决于过去有多少电荷以什么方向流过它；这种设备能够记住它的历史，也就是所谓的非易失性。当电源关闭时，忆阻器会记住其最近的电阻，直到再次打开为止。”</em></p><p id="92fc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从那以后，各种其他材料被各种公司实验，用于制造忆阻器，我就不一一列举了。</p><p id="fb87" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是让我们跳过这些无聊的东西，直接进入忆阻器有趣的科幻应用吧！</p><h1 id="ce08" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">神经形态计算——或者说如何创造大脑</h1><p id="e5f5" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">神经形态计算并不是什么太新的东西，因为它在1980年首次被创造出来，它指的是模拟电路，模拟人脑的神经生物结构。</p><p id="c4d7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你至少有点了解深度学习的宣传，你就会知道它围绕着基于软件的算法和架构，这些算法和架构抽象地模仿大脑的神经回路。深度学习越来越多地传播到所有类型的行业，训练算法的成本是巨大的。</p><blockquote class="od"><p id="ec93" class="oe of it bd og oh oi oj ok ol om lu dk translated">深度学习未能模仿的一点是大脑的能效。神经形态硬件可以解决这个问题。</p></blockquote><p id="5c91" class="pw-post-body-paragraph kz la it lb b lc on ju le lf oo jx lh li op lk ll lm oq lo lp lq or ls lt lu im bi translated">还有，你可以告别著名的冯诺依曼瓶颈了。如果你不知道那是什么，它指的是数据从一个设备的内存到达处理单元所需的时间。这实际上使处理单元等待(浪费时间)获得它需要处理的数据。</p><p id="3b01" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">神经形态芯片没有瓶颈，因为所有的计算都发生在内存中。忆阻器是神经形态芯片的基础，可以用作记忆单元和计算单元，类似于大脑的工作方式。它们是第一批无机神经元。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/00ebe6c77af233f014d0144cce80d23c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dLzLE852gPpCZ9SM"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com/@joshriemer?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">乔希·里默尔</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h2 id="1489" class="np mf it bd mg nq nr dn mk ns nt dp mo li nu nv mq lm nw nx ms lq ny nz mu oa bi translated">为什么神经形态硬件更适合神经网络</h2><p id="55d1" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">神经网络主要使用实数(例如2.0231、0.242341等)来表示神经网络架构内部的权重和其他值。然而，在目前的计算机体系结构中，这些值需要转换成二进制。这增加了在训练和部署中计算神经网络所需的操作数量。</p><p id="6542" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">神经形态硬件不使用二进制，但它可以使用真实值，如电流和电压等电气值的形式。这里，数字0.242341被表示为例如0.242341伏。这直接发生在电路内部，不存在二进制值。所有的计算都以电路的速度进行。</p><p id="583f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">基于神经形态硬件，极大地提高神经网络的响应速度和训练速度的另一个因素是计算的高度并行性。关于我们的大脑，已知的一件确定的事情是，它是高度并行的，在我们生命的每一秒钟里，数百万次计算同时发生。这就是神经形态芯片所能实现的。</p><p id="8351" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所有这些优势都有一个好处:训练和部署神经网络算法的能耗低得多。</p><h2 id="ecb3" class="np mf it bd mg nq nr dn mk ns nt dp mo li nu nv mq lm nw nx ms lq ny nz mu oa bi translated">边缘计算——由神经形态驱动</h2><p id="7123" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">你可能知道，自动驾驶汽车主要基于神经网络和4/5 G技术。为了让汽车自动驾驶，它必须连接到一个数据中心，该数据中心分析它从汽车接收的数据(通常它会将数据传递给一个或多个卷积神经网络)，然后使用4/5 G技术将数据返回给汽车。这会产生延迟，这可能会导致死亡。</p><p id="bc85" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">神经形态计算</strong>的优势来自于之前提到的该技术的优点；所有处理都可以在汽车的“大脑”(神经形态芯片)内部本地完成。这将减少延迟，降低能源成本，增加汽车的自主性，同时也改善了汽车的一个敏感部分(因为大多数数据都是在本地处理的)——网络安全。</p><p id="ebed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它还将为另一个不断增长的行业——物联网——带来许多新功能。众所周知，这些设备对能耗非常敏感，因为它们的电池寿命有限。小而高效的神经形态芯片可以用来以低成本为每个设备提供更多的功能。</p><h1 id="27cc" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">结论</h1><p id="9ea3" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">深度学习行业需要一种新型的硬件，神经形态的硬件，才能真正高效。神经形态芯片显示出最适合它的巨大前景，一些公司正在努力开发这项技术和硬件人工智能的未来。希望这一领域的工业研究将会增加，我们将很快拥有专用于神经网络的硬件。这将真正使人工智能开发者能够改变世界。</p></div><div class="ab cl ot ou hx ov" role="separator"><span class="ow bw bk ox oy oz"/><span class="ow bw bk ox oy oz"/><span class="ow bw bk ox oy"/></div><div class="im in io ip iq"><p id="4de0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="oc"><strong class="lb iu">加盟中使用我的推荐链接:</strong></em><br/><a class="ae ky" href="https://stefanpircalabu.medium.com/membership" rel="noopener">https://stefanpircalabu.medium.com/membership</a></p></div></div>    
</body>
</html>