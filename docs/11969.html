<html>
<head>
<title>Simplified KNN Algorithm using Python with coding explanation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Python 简化 KNN 算法并提供编码说明</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/simplified-knn-algorithm-using-python-with-coding-explanation-ab597391b4c3?source=collection_archive---------45-----------------------#2020-08-18">https://towardsdatascience.com/simplified-knn-algorithm-using-python-with-coding-explanation-ab597391b4c3?source=collection_archive---------45-----------------------#2020-08-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="36b9" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf"> K 近邻，机器学习中最简单的分类算法之一</em></h2></div><p id="3c88" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi lc translated"><span class="l ld le lf bm lg lh li lj lk di"> M </span>机器学习就是识别模式，创造自己的算法，并不断进化。模式通常由机器创建，它使用各种技术和算法。对于机器学习中的分类问题，k 近邻算法是一种最简单而有效的算法。它既可用于<em class="ll">分类，也可用于</em>回归问题，即它可以对任何特定事件/属性进行分类，甚至可以预测其值。这种方法因为比其他复杂的算法简单而被采用。它测量数据点之间的距离。测量距离会形成一个模式，以创建两点之间的关系。这就是它决定新数据点应该放在哪个组中的方式。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lm"><img src="../Images/63a7e595622b92409bd06986b0a79962.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bL8VnHpgQjW4RjnpGwyi_w.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">图片来自 nccalculators.com</p></figure><p id="f152" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">如果我们需要计算上图中提到的两点之间的距离，比如说<code class="fe mc md me mf b">(XA,YA)</code>和<code class="fe mc md me mf b">(XB,YB)</code>，那么可以使用一个简单的公式</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/dba8a31161206be13ea85254f2d41f69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*uKGYSU5oX9wKDzWMhZetVw.png"/></div></figure><p id="2e42" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">以上是测量两点间距离的<strong class="ki ir">欧几里得</strong>方法。这种距离测量也可以有其他方式。遵循上述方法来计算各种数据点之间的距离。KNN 有两个独特的属性</p><ol class=""><li id="29c7" class="mh mi iq ki b kj kk km kn kp mj kt mk kx ml lb mm mn mo mp bi translated"><strong class="ki ir">懒惰学习算法:</strong>它被称为懒惰学习者，因为它没有任何专门的训练阶段，而学习意味着它没有预定义的规则。它只是消耗所有的数据，同时对一个新的数据点进行分类，并制定自己的规则。</li><li id="2e87" class="mh mi iq ki b kj mq km mr kp ms kt mt kx mu lb mm mn mo mp bi translated"><strong class="ki ir">非参数学习算法:</strong>它采用非参数方法，这意味着它不做任何假设。它不担心选择哪些特性。这种方法非常适合您事先不了解传入数据的情况。</li></ol><p id="f73d" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">由于这种无忧无虑的分类，KNN 算法各有利弊</p><p id="d6bd" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">优点:</strong></p><ol class=""><li id="0b2f" class="mh mi iq ki b kj kk km kn kp mj kt mk kx ml lb mm mn mo mp bi translated">对于大量数据来说，它非常有用</li><li id="51a0" class="mh mi iq ki b kj mq km mr kp ms kt mt kx mu lb mm mn mo mp bi translated">它在选择变量方面很灵活(没有假设)&amp;可以适应大量的函数形式。</li><li id="9026" class="mh mi iq ki b kj mq km mr kp ms kt mt kx mu lb mm mn mo mp bi translated">它可以在预测时提供更好的性能</li></ol><p id="9147" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">缺点:</strong></p><ol class=""><li id="ec03" class="mh mi iq ki b kj kk km kn kp mj kt mk kx ml lb mm mn mo mp bi translated">在估计映射函数时，它消耗大量的数据</li><li id="c661" class="mh mi iq ki b kj mq km mr kp ms kt mt kx mu lb mm mn mo mp bi translated">它可以给出过拟合模型输出</li><li id="7362" class="mh mi iq ki b kj mq km mr kp ms kt mt kx mu lb mm mn mo mp bi translated">由于训练时使用了大量参数，所以速度较慢。</li><li id="dc94" class="mh mi iq ki b kj mq km mr kp ms kt mt kx mu lb mm mn mo mp bi translated">不平衡数据集可能会给这种算法带来麻烦。</li></ol><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/7d8a04a64084f51320b14b35cdc60f18.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*3_3pdpRWV4zTZZyREonF5g.png"/></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">绘制在 2D 坐标系上的样本数据集</p></figure><p id="f343" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">在 K 个最近邻中，K 的<strong class="ki ir">值表示与我们的新数据点具有最小距离的最近邻的数量。如果我们说 k=3，这意味着我们必须为我们的新数据点找出 3 个最近的邻居。如果有 3 个相邻点，其中一个来自红色数据集，另外两个来自蓝色数据集，那么新的数据点将被标记为蓝色。越多的邻居意味着分类越清晰，但是它增加了分类的复杂性和时间范围。k 值还有一个更重要的方面，它应该是一个奇数<em class="ll">总是为了更好的分类，否则如果两种颜色的邻居数量相等，那么它将是一个平局。</em></strong></p></div><div class="ab cl mw mx hu my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="ij ik il im in"><p id="dbda" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">让我们举一个例子，用 python 语言展示算法是如何工作的。为了在 python 中工作，我们需要调用某些库</p><pre class="ln lo lp lq gt nd mf ne nf aw ng bi"><span id="82f4" class="nh ni iq mf b gy nj nk l nl nm">import pandas as pd<br/>import numpy as np<br/>from sklearn.datasets import load_iris<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.neighbors import KNeighborsClassifier<br/>from sklearn.metrics import accuracy_score</span></pre><p id="dbf0" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">这里的数据集是 python 框架上一些基本样本数据集的存储库。这些数据集可以用来做一些简单的实际建模。<em class="ll"> Iris </em>是那个存储中非常有名的数据集。</p><p id="176c" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">sklearn 是 python 中最著名的数据科学包，拥有机器学习所需的几乎 70%的功能。在这里，我们导入一个函数，用于将数据拆分为测试和训练<em class="ll"> (train_test_split)和 KNN 分类的 KNeighborsClassifier </em>。为了检查我们模型的准确性，我们再次使用来自同一个著名库包的<em class="ll"> accuracy_score </em>。</p><pre class="ln lo lp lq gt nd mf ne nf aw ng bi"><span id="5cc6" class="nh ni iq mf b gy nj nk l nl nm">iris = load_iris()<br/>x= pd.DataFrame(iris.data,columns=iris.feature_names)<br/>y = pd.Categorical.from_codes(iris.target, iris.target_names)</span></pre><p id="4ee0" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">我们已经调用了 iris 数据集，并将目标变量从数据帧的其余部分中分离出来。这里 y 是目标变量，x 是将用于建模的数据集。</p><pre class="ln lo lp lq gt nd mf ne nf aw ng bi"><span id="29b4" class="nh ni iq mf b gy nj nk l nl nm">x.info()</span></pre><p id="8bca" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">来深入了解我们的数据集。它对正在处理的数据帧提供了相当多的洞察力。这是它的输出</p><pre class="ln lo lp lq gt nd mf ne nf aw ng bi"><span id="27bb" class="nh ni iq mf b gy nj nk l nl nm">&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 150 entries, 0 to 149<br/>Data columns (total 4 columns):<br/> #   Column             Non-Null Count  Dtype  <br/>---  ------             --------------  -----  <br/> 0   sepal length (cm)  150 non-null    float64<br/> 1   sepal width (cm)   150 non-null    float64<br/> 2   petal length (cm)  150 non-null    float64<br/> 3   petal width (cm)   150 non-null    float64<br/>dtypes: float64(4)<br/>memory usage: 4.8 KB</span></pre><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi nn"><img src="../Images/51663bd96772905909f9db38da128d26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gEbHy7bu6hjP3WmWdEf6ZA.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">使用 matplotlib 绘制的虹膜数据集</p></figure><p id="3ea1" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">现在，我们将数据分成 70:30 比例的训练和测试数据。这个比例可以由程序员根据自己的意愿来选择，但更明智的做法是为训练数据提供一个合适的容量，并且还应该有合理的测试容量。</p><pre class="ln lo lp lq gt nd mf ne nf aw ng bi"><span id="8514" class="nh ni iq mf b gy nj nk l nl nm">#Prepare data for classification process<br/>x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)</span></pre><p id="518e" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">现在，我们准备使用下面的命令制作一个 KNN 模型。您可以在代码中看到，我们使用了 p 值为 2 的<em class="ll">闵可夫斯基</em>距离度量，即 KNN 分类器将使用<em class="ll">欧几里德</em>距离度量公式。</p><pre class="ln lo lp lq gt nd mf ne nf aw ng bi"><span id="4b6b" class="nh ni iq mf b gy nj nk l nl nm">#Create a model<br/>KNN_Classifier = KNeighborsClassifier(n_neighbors = 6, p = 2, metric=’minkowski’)</span></pre><p id="f266" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">现在我们将使用 KNeighborClassifier 训练模型，这里 k 的值是 6。(是的它是偶数，看复杂程度)</p><pre class="ln lo lp lq gt nd mf ne nf aw ng bi"><span id="eb6c" class="nh ni iq mf b gy nj nk l nl nm">KNN_Classifier.fit(x_train, y_train)</span></pre><p id="5baa" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">在对模型进行训练之后，将通过使用以下命令，使用同一个经过训练的模型对测试数据进行测试</p><pre class="ln lo lp lq gt nd mf ne nf aw ng bi"><span id="c1f1" class="nh ni iq mf b gy nj nk l nl nm">pred_test = KNN_Classifier.predict(x_test)</span></pre><p id="299f" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">基于为所有数据点计算的距离，我们找出有多少邻居指示哪一侧。一旦选择了顶部最近的邻居，我们检查邻居中投票最多的类</p><pre class="ln lo lp lq gt nd mf ne nf aw ng bi"><span id="a06a" class="nh ni iq mf b gy nj nk l nl nm">#check the accuracy of your predicted classifier<br/>acc = accuracy_score(y_test, pred_test)</span></pre><p id="7ecd" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">通过使用这个命令，我们可以检查我们设计的模型的准确性。好的价值意味着更好的建模。为了识别过拟合模型特征，必须检查测试数据和训练数据的准确性。</p><p id="b51a" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">结论:</strong></p><p id="2702" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">该模型为其下一个任务做好了准备，并且不需要再次训练。如果我们输入更多的数据，模型会发展得更好，结果也会更好。我们必须确保所提供的数据是干净的，缺失值已被处理，因为机器无法正确处理缺失值数据集。</p></div></div>    
</body>
</html>