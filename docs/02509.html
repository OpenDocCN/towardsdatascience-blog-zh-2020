<html>
<head>
<title>Yatzy score sheet detection in Python using OpenCV, TensorFlow, MNIST</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用OpenCV，TensorFlow，MNIST，在Python中检测Yatzy评分表</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/yatzy-score-sheet-detection-in-python-using-opencv-tensorflow-mnist-97ce685d80e0?source=collection_archive---------11-----------------------#2020-03-10">https://towardsdatascience.com/yatzy-score-sheet-detection-in-python-using-opencv-tensorflow-mnist-97ce685d80e0?source=collection_archive---------11-----------------------#2020-03-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="edef" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">完整的实现与代码部分的图像处理和CNN模型训练</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/b3c3c0fa13df22c03f8d015708ffb03f.png" data-original-src="https://miro.medium.com/v2/resize:fit:540/1*NaKfgD_ihUXb93dRH8s4FA.gif"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated"><a class="ae kr" href="https://apps.apple.com/se/app/yatzy-score-sheets/id1462576084" rel="noopener ugc nofollow" target="_blank"> Yatzy评分表</a> iOS应用程序</p></figure><p id="9916" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">自从几年前我开始玩yatzy(真的，有点上瘾)以来，我一直希望我们有机会玩Yatzy而不需要物理分数表。我发现了一些应用程序，但没有一个真正好用或有趣的。在发布了一个简单的yatzy分数跟踪应用程序后，我的工程头脑开始发挥扫描yatzy分数表的想法。我意识到，对于部署的计算机视觉任务来说，这可能是一个合理范围内的好任务。它还将包括<a class="ae kr" href="https://en.wikipedia.org/wiki/Machine_learning" rel="noopener ugc nofollow" target="_blank">机器学习</a>，在那里你必须考虑更多的事情，而不仅仅是在<a class="ae kr" href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets#Test_dataset" rel="noopener ugc nofollow" target="_blank"> <strong class="ku ir">测试</strong> </a>集上获得最佳准确度。您必须部署您的模型，让您的生产数据符合模型等等。在这篇文章中，我将介绍这个项目的各个步骤，包括<strong class="ku ir">从RGB图像中识别yatzy评分表，并对手写输入的数字进行分类</strong>。代码是使用OpenCV和TensorFlow用Python写的。</p><h1 id="d48b" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated"><strong class="ak">第1部分:识别Yatzy表</strong></h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/1bdd4070e699ab0f82c1d46e95c626dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*HO1ctrQzuLlSiaggKA-MNg.jpeg"/></div></figure><p id="7ae9" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">这种分类/检测任务的一种(强力)方法是将我们所有的<a class="ae kr" href="https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html" rel="noopener ugc nofollow" target="_blank">轮廓</a>传递给<a class="ae kr" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a> CNN模型进行预测，并训练它能够从手写数字中分离噪声。然而，这将意味着我们可能不得不将大量的噪声传递给我们的模型进行预处理和预测。对于我们的模型来说，这不是一个微不足道的任务，因为我们不知道这些数字相对于图像应该有多大。我们也不知道这些轮廓属于什么样的细胞(点)？这就是为什么我们开始识别yatzy表，并“减去”网格，以确保我们只(希望)发送数字到分类器。为了识别任意工作表，我们需要定义定义任意工作表的规则。我对常规工作表使用的规则是:</p><ul class=""><li id="4688" class="mh mi iq ku b kv kw ky kz lb mj lf mk lj ml ln mm mn mo mp bi translated">19行数。</li><li id="c2e2" class="mh mi iq ku b kv mq ky mr lb ms lf mt lj mu ln mm mn mo mp bi translated">网格中的每个任意单元格具有相似的尺寸，即不同单元格的<strong class="ku ir">高度</strong>和<strong class="ku ir">宽度</strong>相同。</li></ul><p id="128a" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">识别<strong class="ku ir">网格</strong>的步骤:</p><ol class=""><li id="9ab1" class="mh mi iq ku b kv kw ky kz lb mj lf mk lj ml ln mv mn mo mp bi translated">将RGB图像转换为单通道二值图像。</li></ol><div class="kg kh ki kj gt ab cb"><figure class="mw kk mx my mz na nb paragraph-image"><img src="../Images/1bdd4070e699ab0f82c1d46e95c626dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*HO1ctrQzuLlSiaggKA-MNg.jpeg"/></figure><figure class="mw kk mx my mz na nb paragraph-image"><img src="../Images/e069ca7c0cf1182b9f09c3aba4b7182a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*aN7AyNZPnk83R28PWxnXTQ.png"/><p class="kn ko gj gh gi kp kq bd b be z dk nc di nd ne translated">RGB到二进制图像</p></figure></div><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nf ng l"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">步骤1的代码</p></figure><p id="6dba" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">2.识别最大的<a class="ae kr" href="https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html" rel="noopener ugc nofollow" target="_blank">轮廓</a>(具有相似强度的连接点)</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/7de4e89b28aae24204c75ea4d5694a9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*vqdgLkDnvy3tnMfr0GHcHQ.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">最大轮廓。第二步</p></figure><p id="b68b" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">3.根据<a class="ae kr" href="https://docs.opencv.org/3.4/d3/dc0/group__imgproc__shape.html#ga3d476a3417130ae5154aea421ca7ead9" rel="noopener ugc nofollow" target="_blank">可以用一个矩形</a>表示的最小面积对图像轮廓进行旋转。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/ccb1055a9dee8f28719d67669ca30cf7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*8NSUsM0qgVM7LFjxdH5NNw.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">在步骤3中旋转之前，最大轮廓的最小旋转矩形区域</p></figure><p id="9277" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">步骤2和3的代码</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nf ng l"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">步骤2和3的代码</p></figure><p id="ced3" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">4.对二进制图像执行<a class="ae kr" href="http://homepages.inf.ed.ac.uk/rbf/HIPR2/morops.htm" rel="noopener ugc nofollow" target="_blank">形态学</a>操作，以便在新的二进制图像上绘制垂直和水平线条，表示yatzy网格。有关绘制的线条，请参见下图。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/32f7bdd12970a9ea9adce79d6553fbad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*LnNZaKG3WlKrhY2Lyp8GMQ.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">步骤4之后，绘制了垂直水平线的二进制图像</p></figure><p id="030e" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">步骤4的代码，识别yatzy网格</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nf ng l"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">步骤4的代码</p></figure><p id="6e92" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">5.识别yatzy网格中的每个Yatzy单元格，并按照最左上角的位置对它们进行列排序<strong class="ku ir"> (x，y) </strong>。我们通过在步骤4的二进制图像上使用<strong class="ku ir"> findContours </strong>来实现，该图像只包含水平/垂直线条。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/6eff2db79a328ecf62262ec9ba5367f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*V4R1wKDD90fKQve9O_QdFg.png"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="7155" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">参见调用上述代码的完整<strong class="ku ir"> generate_yatzy_sheet </strong>函数。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nf ng l"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">调用步骤1–5的函数</p></figure><p id="f2f8" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">以上要点的完整源代码可从<a class="ae kr" href="https://github.com/oankarberg/yatzy-score-sheet-detection" rel="noopener ugc nofollow" target="_blank"> <strong class="ku ir">这里</strong> </a>获得</p><h1 id="5b56" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated"><strong class="ak">第二部分。手写数字训练</strong></h1><p id="e946" class="pw-post-body-paragraph ks kt iq ku b kv nh jr kx ky ni ju la lb nj ld le lf nk lh li lj nl ll lm ln ij bi translated"><a class="ae kr" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"> MNIST </a>是一个包含70 000张28x28图像和手写数字的数据集。35，000个来自高中生，35，000个来自人口普查局员工，分成60，000个用于训练图像，10，000个用于测试各自的组。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi nm"><img src="../Images/8a48ae70d7671e91b7637a29ce70be08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NbH0MRTXYur3jcuP_3pvnw.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">来自MNIST数据集的样本图像</p></figure><p id="873e" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">MNIST图像的尺寸为28×28像素，是黑白的，带有一些灰度，这是标准化算法(高斯等)使用的<a class="ae kr" href="https://i.stack.imgur.com/pA7uy.png" rel="noopener ugc nofollow" target="_blank">反走样</a>技术的结果。手写数字包含在一个20×20的边界框中，具有保留的纵横比。然后，通过在每个侧面图像上引入4个像素的填充，将20x20的盒子转换为28x28的容器。然后，通过计算质心并将其平移到这个CoM点，该数字在28×28像素的图像中居中。质心实际上是x轴和y轴上的白色像素平均值。(我们稍后将模仿这些步骤进行产量预测)</p><p id="351c" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">对于训练，我们使用CNN架构。如果你不熟悉CNN，我推荐你在这里阅读更多相关内容。</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="f7cb" class="nw lp iq ns b gy nx ny l nz oa">INPUT -&gt; CONV3-32 -&gt; RELU -&gt; CONV3-32 -&gt; RELU -&gt; CONV3-32 -&gt; RELU -&gt; POOL -&gt; DROPOUT -&gt; FC -&gt; RELU -&gt; DROPOUT -&gt; SOFTMAX</span></pre><p id="25ee" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">下面的代码用于为模型定型。请注意我们是如何去除高斯反走样并将图像转换为二进制图像的。我们这样做是因为我们不知道在MNIST使用的精确算法来创建反锯齿效果。否则，我们的生产数据将与培训设置不匹配。我们可以执行一个新的高斯反走样效果后，我们把它变成二进制，但是在测试后，我没有注意到高斯过滤器的任何性能改善。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi nm"><img src="../Images/762ef99534c1c1b67e5c25d80cdd873b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K2B278wa4oP3eoA-_LBoGQ.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">转换成二进制图像后的来自MNIST的样本图像</p></figure><p id="8273" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">训练我们的卷积神经网络的全部代码。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nf ng l"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">训练卷积神经网络</p></figure><p id="4f21" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">最后，我们打印train/val损失和train/val精度，以衡量我们的模型在不同时期的表现。看起来没问题，合理的验证指标很好地遵循了培训。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi ob"><img src="../Images/4a124ad89c609f382326913184018fbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*le6WvUpI5L-KBBS4z5RsFg.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">CNN模型的度量</p></figure><h1 id="00ba" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">把它放在一起</h1><p id="5bb6" class="pw-post-body-paragraph ks kt iq ku b kv nh jr kx ky ni ju la lb nj ld le lf nk lh li lj nl ll lm ln ij bi translated">现在，当我们拥有数组格式的yatzy网格和CNN模型时，我们可以开始用yatzy单元绘制数字轮廓位置，并通过感兴趣区域(ROI)进行预测。</p><ol class=""><li id="28ca" class="mh mi iq ku b kv kw ky kz lb mj lf mk lj ml ln mv mn mo mp bi translated">阅读张量流模型</li><li id="7664" class="mh mi iq ku b kv mq ky mr lb ms lf mt lj mu ln mv mn mo mp bi translated">从RGB图像生成任意图片</li><li id="d5e8" class="mh mi iq ku b kv mq ky mr lb ms lf mt lj mu ln mv mn mo mp bi translated">使用生成的Yatzy表(没有任何网格)来查找数字的轮廓</li><li id="0ba9" class="mh mi iq ku b kv mq ky mr lb ms lf mt lj mu ln mv mn mo mp bi translated">将ROI预处理为张量流模型的正确格式。(轮班等)</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi oc"><img src="../Images/361ac06a2ea06ecb2a50c62a0b3eaea3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QDZAB-t2PEzYYDDrN_07Wg.png"/></div></div></figure><p id="038d" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">5.通过ROI进行预测</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="80cc" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">最终结果包含附加到每个轮廓的相应分类数字。(注意我们的模型如何(直观地)将A和B解释为4和8)</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi od"><img src="../Images/d2e52db7471a83d571f2a93205ac09b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1018/format:webp/1*EX9Pzk9Iu_KDySUyM26kZw.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">带分类数字的任意网格</p></figure><p id="5eab" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">这都是为了这个python实现。在<a class="ae kr" href="https://apps.apple.com/se/app/yatzy-score-sheets/id1462576084" rel="noopener ugc nofollow" target="_blank"> Yatzy评分表</a>中运行的代码被移植到Objective C++并进行优化(例如，跳过一些重复的操作，以便在整个python程序中保持不同的图像版本)。因为我们知道这些数字属于哪个yatzy单元格，所以我们可以使用它在应用程序屏幕“预览工作表”中显示工作表，并选择保存工作表。请注意，有些单元格的背景颜色为红色，这表明我们的CNN模型对预测的数字是正确的有多大把握(在0-1.0之间)。然后，用户能够手动验证和更新那些具有错误预测的数字。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/e0db625139919fc8d33ae17845cc864f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*KdQQoGOpf1_Qge5XXv1R4w.gif"/></div></figure><p id="11a1" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">这篇文章的完整源代码可以在<a class="ae kr" href="https://github.com/oankarberg/yatzy-score-sheet-detection" rel="noopener ugc nofollow" target="_blank">的Github repo </a>中找到</p></div></div>    
</body>
</html>