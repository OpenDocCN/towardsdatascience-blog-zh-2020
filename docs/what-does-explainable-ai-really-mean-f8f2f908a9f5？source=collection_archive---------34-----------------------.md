# 可解释的人工智能有多重要？

> 原文：<https://towardsdatascience.com/what-does-explainable-ai-really-mean-f8f2f908a9f5?source=collection_archive---------34----------------------->

## 数据科学，人工智能

## 可解释的人工智能是使决策过程透明和快速的机会

![](img/8d01d196a97ae0873704cf436c9cf9bb.png)

普里西拉·杜·普里兹在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

在这篇文章中，你可以探索**可解释的人工智能**，它背后的主要思想是什么，为什么需要可解释的人工智能，以及我们将如何开发可解释的人工智能？

> 最重要的是让任何关于人工智能的事情变得可解释、公平、安全和有传承，这意味着任何人都可以非常简单地看到人工智能的任何应用是如何发展的，以及为什么会发展。” —吉妮·罗梅蒂

# **什么是可解释的 AI？背后的主旨是什么？**

![](img/8d7e2952185c0649b4e2c88d962bdee1.png)

Bret Kavanaugh 在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

可解释的人工智能(XAI)是使决策过程透明和快速的机会。换句话说，XAI 应该删除所谓的黑箱，并详细解释这个决定是如何做出的。

为了制作一个好的可解释的人工智能系统或程序，应该回答以下问题:

*   这种结构背后的意图是什么，以及相关各方的影响是什么？
*   输入到底是如何转化为输出的？
*   要使用的数据来源是什么？

澄清的需要是由信任人工智能做出的决定的需要驱动的，特别是在商业领域，任何错误的决定都可能导致重大损失。

正如《商业》中所介绍的，可解释的人工智能提供了导致更好商业结果的洞察力，并预测了最受欢迎的行为。

首先，XAI 让公司所有者直接控制人工智能的运作，因为所有者已经知道机器在做什么，为什么。它还维护公司的安全，因为所有程序都应通过安全协议，如果有违规行为，应记录在案。

当利益相关者有能力观察所采取的行动并欣赏其逻辑时，解释人工智能系统有助于与他们建立信任关系。

绝对致力于新的安全立法和倡议，如 GDPR，是至关重要的。根据现行法律关于正当性的规定，禁止立即做出任何决定。

然而，在 XAI 的帮助下，禁止自生决定的需求将不再有效，因为可解释人工智能中的决策过程尽可能简单明了。

# 为什么需要可解释的人工智能？

![](img/4cb7d98bbe783c33ae6ba545afaeed65.png)

阿尔诸那在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

它是关于程序向人类解释其行为背后的逻辑的能力，它的形式是能够用正式语言向计算机科学家解释，并且能够向系统用户解释。

这一点非常重要，因为它与人类对设备使用的信任密切相关，更正式的说法是，如果这种信任能够证明机器的行为，那么这种信任就很重要。

# **我们将如何开发可解释的人工智能？**

![](img/2853de58a676b53407502c5271116278.png)

由[万花筒](https://unsplash.com/@kaleidico?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

可解释的人工智能是一种人工智能，旨在以普通人可以理解的方式解释其意图、推理和决策过程。

XAI 经常在深度学习的意义上被提及，并在**机器学习** (ML)范式中发挥着重要作用:

*   公平
*   公开
*   机器学习的透明性

XAI 通过分享以下内容，提供了关于人工智能软件如何做出决定的一般知识:

*   该课程的优点和缺点。
*   软件使用的基本参数用于得出结论。
*   为什么一个程序做出一个明确的决定，而不是选择？
*   不同形式的判断可接受的置信度。
*   预计软件会犯什么样的错误？
*   哪些错误应该改正？

XAI 的基本目标是算法透明。直到最近，人工智能系统还只是简单的黑匣子。即使输入和输出是已知的，用于作出决策的等式总是专有的或不容易掌握的，尽管编程的内部工作是开放的，并使公众可以访问。

随着人工智能变得越来越普遍，揭露偏见和信任问题是如何得到回答的比以往任何时候都更重要。例如,《欧盟一般数据保护条例》( GDPR)规定了澄清条款的权利。

# **结论**

![](img/a36f40b8e0455de9bd1555fdd8f348a0.png)

在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上由 [Austin Distel](https://unsplash.com/@austindistel?utm_source=medium&utm_medium=referral) 拍摄的照片

人类层面的解释包括一系列认知功能，如自我意识、心智理论、长期记忆和记忆储存、语义学等。人工智能将描述的是它能做什么的角色，并且它与我们发现和引入的能力成指数关系。

*现在，把你的想法放在* ***Twitter*** *，****Linkedin****，以及****Github****！！*

***同意*** *还是* ***不同意*** *与 Saurav Singla 的观点和例子？想告诉我们你的故事吗？*

*他对建设性的反馈持开放态度——如果您对此分析有后续想法，请在下面的* ***评论*** *或联系我们！！*

*推文*[***@ SauravSingla _ 08***](https://twitter.com/SAURAVSINGLA_08)*、评论*[***Saurav _ Singla***](http://www.linkedin.com/in/saurav-singla-5b412320)*，还有明星*[***SauravSingla***](https://github.com/sauravsingla)*马上！*