<html>
<head>
<title>Peering Into the Black Box</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">窥视黑匣子</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/prettifying-partial-density-plots-in-python-1f7216937ff?source=collection_archive---------20-----------------------#2020-05-14">https://towardsdatascience.com/prettifying-partial-density-plots-in-python-1f7216937ff?source=collection_archive---------20-----------------------#2020-05-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="752e" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" rel="noopener" target="_blank" href="https://towardsdatascience.com/inside-ai/home">内部AI </a></h2><div class=""/><div class=""><h2 id="37db" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">更吸引人的部分依赖图如何在黑盒模型中与非技术涉众建立信任。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/00f39fd79a452b8e47b8ad93a56629e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UVMAvNksQeqcvJvBLpXJAQ.png"/></div></div></figure><p id="f930" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">人们不相信他们不了解的东西。人工智能和机器学习算法是我们拥有的一些最强大的技术，但它们也是最容易被误解的。因此，数据科学家最重要的职责之一就是以易于理解的方式传达复杂的信息。</p><h2 id="7960" class="lz ma it bd mb mc md dn me mf mg dp mh lm mi mj mk lq ml mm mn lu mo mp mq iz bi translated">黑盒模型</h2><p id="e85d" class="pw-post-body-paragraph ld le it lf b lg mr kd li lj ms kg ll lm mt lo lp lq mu ls lt lu mv lw lx ly im bi translated">也许对神经网络最大的误解之一是，我们不能直接看到产生结果的模型。我们可以看到我们的投入和产出，我们可以衡量结果，但我们并没有真正理解它们之间的关系。从实用性的角度来看，这是有问题的，因为像人类一样，关系的本质会随着时间而改变。人工智能今天对卡车的感知可能会反映出卡车明天的样子。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi mw"><img src="../Images/13a3ce9ec72ea2ae484ddcb7e1a00ac3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1myNc9s1Ik8KAFReauqMFg.jpeg"/></div></div><p class="mx my gj gh gi mz na bd b be z dk translated">特斯拉赛博卡车。来源:迈克·马琳/Shutterstock.com</p></figure><p id="87e3" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">然而，大多数变化都不像特斯拉的网络卡车那样刺耳。如果我们看不到算法的内部，我们怎么知道算法正在跟上普通假设的逐渐变化呢？我们打开盒子。我们拥有的最好的工具之一是部分依赖图(PDP)。</p><h2 id="f08c" class="lz ma it bd mb mc md dn me mf mg dp mh lm mi mj mk lq ml mm mn lu mo mp mq iz bi translated">部分相关图</h2><p id="c227" class="pw-post-body-paragraph ld le it lf b lg mr kd li lj ms kg ll lm mt lo lp lq mu ls lt lu mv lw lx ly im bi translated"><a class="ae nb" href="https://scikit-learn.org/stable/modules/partial_dependence.html" rel="noopener ugc nofollow" target="_blank"> Scikit-Learn </a>的创作者这样描述部分依赖情节:</p><blockquote class="nc"><p id="b745" class="nd ne it bd nf ng nh ni nj nk nl ly dk translated">部分相关性图(PDP)显示了目标响应和一组“目标”特征之间的相关性，忽略了所有其他特征(“补充”特征)的值。</p></blockquote><p id="ad32" class="pw-post-body-paragraph ld le it lf b lg nm kd li lj nn kg ll lm no lo lp lq np ls lt lu nq lw lx ly im bi translated">换句话说，PDP允许我们看到预测变量的变化如何影响目标变量的变化。下面是一个PDP的例子，显示了不同的房子特征对预测价格的影响。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/6947323a826a3250871ced438216424a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*ToIf_oKZJVcrgubpFWyD4w.png"/></div><p class="mx my gj gh gi mz na bd b be z dk translated">来源:<a class="ae nb" href="https://scikit-learn.org/stable/modules/partial_dependence.html" rel="noopener ugc nofollow" target="_blank"> Scikit-Learn </a></p></figure><p id="0ebb" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">从这些图中，我们可以看到，随着中值收入和房屋年龄的增加，预测价格往往会增加。然而，随着一个地区平均入住率的上升，预测价格会下降。底部的线条代表观察值的分布。</p><p id="bf91" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这些情节非常容易理解和创作。使用拟合的模型、数据集(仅限X要素)和输入要素列表，您可以在导入相关库后使用单行代码生成上述图:</p><pre class="ks kt ku kv gt ns nt nu nv aw nw bi"><span id="324a" class="lz ma it nt b gy nx ny l nz oa">import matplotlib.pyplot as plt<br/>from sklearn.inspection import partial_dependence, plot_partial_dependence</span><span id="99ff" class="lz ma it nt b gy ob ny l nz oa">plot_partial_dependence(model, X, features)</span></pre><p id="4f24" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这些图对于几乎任何类型的回归模型都很好。然而，我发现在将PDP应用于分类任务时，非技术利益相关者有时很难解释结果。更重要的是，它们看起来并不特别吸引人。让我们打扮一下，并添加一些功能。</p><h2 id="6a22" class="lz ma it bd mb mc md dn me mf mg dp mh lm mi mj mk lq ml mm mn lu mo mp mq iz bi translated">美化的PDP</h2><p id="a769" class="pw-post-body-paragraph ld le it lf b lg mr kd li lj ms kg ll lm mt lo lp lq mu ls lt lu mv lw lx ly im bi translated">为了便于说明，我们将使用<a class="ae nb" href="https://www.kaggle.com/hesh97/titanicdataset-traincsv" rel="noopener ugc nofollow" target="_blank">泰坦尼克号数据集</a>。我们将使用XGBoost分类模型构建一个简单的模型，该模型尝试基于几个输入特征来识别幸存者。我们最感兴趣的是弄清楚我们的模型如何使用年龄作为存活率的预测指标(没有双关语)。</p><pre class="ks kt ku kv gt ns nt nu nv aw nw bi"><span id="cc29" class="lz ma it nt b gy nx ny l nz oa">from xgboost import XGBClassifier</span><span id="31e3" class="lz ma it nt b gy ob ny l nz oa">df = pd.read_csv('titanic.csv')<br/>X = df[['Age', 'SibSp', 'Parch', 'Fare']]<br/>y = df['Survived']</span><span id="a89b" class="lz ma it nt b gy ob ny l nz oa">model = XGBClassifier()<br/>model.fit(X, y)</span><span id="7442" class="lz ma it nt b gy ob ny l nz oa">fig = plt.figure(figsize(10, 9))<br/>plot_partial_dependence(model, X, ['Age'], fig=fig)<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/221c9f5d0485c8d611c582781ca6defe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*Um8gF5wZJFJXr-IhIPUwrQ.png"/></div></figure><p id="1789" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">正如我们所看到的，我们的模型已经确定，在所有其他因素相同的情况下，老年人更不可能存活。我们还可以看到大多数乘客年龄在20到40岁之间。</p><p id="ee9c" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如果我们可以通过在同一个图表上绘制直方图来更清楚地了解年龄分布，这不是很好吗？将部分相关值显示为百分比怎么样？如果我们也能可视化决策边界，那不是很好吗？我们可以通过使用partial _ dependence方法获取部分依赖值并自己绘制结果来完成所有这些工作。幸运的是，我已经创建了一个函数来完成这项工作。</p><pre class="ks kt ku kv gt ns nt nu nv aw nw bi"><span id="4463" class="lz ma it nt b gy nx ny l nz oa">from sklearn.inspection import partial_dependence</span></pre><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="2bcb" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">上述函数将为单个输入变量生成一个PDP，并允许输入轴标签和图表标题的目标名称。此外，它还提供了将y轴刻度显示为百分比、更改决策边界以及返回部分相关值以供进一步分析的选项。通过坚持使用标准设置并为目标传递一个名称，我们得到如下结果:</p><pre class="ks kt ku kv gt ns nt nu nv aw nw bi"><span id="ee34" class="lz ma it nt b gy nx ny l nz oa">plot_pdp(model, X, 'Age', target='Survival')</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi of"><img src="../Images/b4debad1ddceb3b376785d06ffc81ac9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*QH8X_0YTEhzTThB2V7zbTA.png"/></div></figure><p id="58dd" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">有了这个，我们对年龄分布有了更丰富的了解。我们可以清楚地看到年龄跨越了决策界限。我们以一种让非技术利益相关者更容易阅读和理解的方式来标记轴。从这里开始，您可以试验这些选项，看看它们如何改变图表的显示，或者根据您的喜好修改代码。</p><p id="2343" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如果没有别的，我会鼓励你想出新的方法来分享你的工作，以创造更多的非技术观众的参与。</p><p id="4c61" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">更新:如果将上述代码与<a class="ae nb" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor" rel="noopener ugc nofollow" target="_blank">GradientBoostingRegressor</a>或<a class="ae nb" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier" rel="noopener ugc nofollow" target="_blank">GradientBoostingClassifier</a>一起使用，则需要将方法设置为“brute”</p><pre class="ks kt ku kv gt ns nt nu nv aw nw bi"><span id="117f" class="lz ma it nt b gy nx ny l nz oa">partial_dependence(model, X, ['Age'], method='brute')</span></pre></div></div>    
</body>
</html>