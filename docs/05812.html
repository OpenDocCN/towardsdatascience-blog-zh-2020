<html>
<head>
<title>How to utilize transfer learning to classify images with State-of-the-Art Deep Learning models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何利用迁移学习和最新的深度学习模型对图像进行分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-utilize-transfer-learning-to-classify-images-with-state-of-the-art-deep-learning-models-d8e5d5bb35d4?source=collection_archive---------59-----------------------#2020-05-13">https://towardsdatascience.com/how-to-utilize-transfer-learning-to-classify-images-with-state-of-the-art-deep-learning-models-d8e5d5bb35d4?source=collection_archive---------59-----------------------#2020-05-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="f90a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这篇文章中，我将展示如何使用一个预先训练好的最先进的图像分类模型来对自定义数据进行分类。我展示了如何在 Keras 中使用谷歌的<a class="ae ko" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank"> efficientnet 模型</a>来应用迁移学习，对来自<a class="ae ko" href="https://www.kaggle.com/jutrera/stanford-car-dataset-by-classes-folder" rel="noopener ugc nofollow" target="_blank">斯坦福汽车数据集</a>的汽车图像进行分类。完整的 jupyter 笔记本可以在我的<a class="ae ko" href="https://github.com/digital-thinking/ann-jupyter-notebooks" rel="noopener ugc nofollow" target="_blank"> github 库</a>中找到。</p><h1 id="2a39" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">效率网</h1><p id="973f" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">从最初简单的卷积神经网络(CNN)开始，通常可以通过任意缩放网络维度(如宽度、深度和分辨率)来逐步进一步提高模型的精度和效率。增加使用的层数或使用更高分辨率的图像来训练模型通常需要大量的人工工作。来自谷歌人工智能的研究人员发布了 EfficientNet，这是一种基于一组固定缩放系数和 AutoML 及其他技术进展的缩放方法(例如<a class="ae ko" href="https://medium.com/@zurister/depth-wise-convolution-and-depth-wise-separable-convolution-37346565d4ec" rel="noopener">深度可分离卷积</a>、<a class="ae ko" href="https://medium.com/@neuralnets/swish-activation-function-by-google-53e1ea86f820" rel="noopener"> swish 激活</a>、<a class="ae ko" href="http://yann.lecun.com/exdb/publis/pdf/wan-icml-13.pdf" rel="noopener ugc nofollow" target="_blank"> drop-connect </a>)。EfficientNet 不再像以前那样独立优化单个网络维度，而是寻求一种跨所有网络维度的平衡扩展流程。</p><p id="290c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">借助 EfficientNet，参数数量大幅减少，同时在 ImageNet(此类应用的基准)上实现了最先进的结果。</p><h1 id="f1de" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">迁移学习</h1><p id="194c" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">虽然 EfficientNet 减少了参数的数量，但卷积网络的训练仍然是一项耗时的任务。为了进一步减少培训时间，我们可以利用迁移学习技术。</p><p id="6c5a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">迁移学习意味着我们使用预先训练的模型，并根据新数据对模型进行微调。在图像分类中，我们可以考虑将模型分为两部分。模型的一部分负责从图像中提取关键特征，如边缘、常见模式等。一部分是使用这些特征进行实际分类。</p><p id="d0ed" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通常，CNN 由堆叠的卷积块组成，减少了图像大小，同时增加了可学习特征(滤波器)的数量，最终所有内容都被放入一个完全连接的层中，该层进行分类。迁移学习的思想是使第一部分可以转移，这样通过只替换完全连接的层(通常只是称为“顶层”)就可以用于不同的任务。</p><h1 id="6686" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">履行</h1><p id="8ddd" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated"><a class="ae ko" href="https://github.com/qubvel/efficientnet" rel="noopener ugc nofollow" target="_blank">这款</a> keras Efficientnet 实施(pip install efficientnet)带有适用于所有尺寸(B0-B7)的预训练模型，我们只需添加自定义分类层“top”即可。用<code class="fe ls lt lu lv b">weights='imagenet'</code>我们得到一个预训练的模型。这个片段大致展示了它是如何工作的(完整的例子见<a class="ae ko" href="https://github.com/digital-thinking/ann-jupyter-notebooks/blob/master/TransferLearning-EfficientNet/TransferLearning-EfficientNet.ipynb" rel="noopener ugc nofollow" target="_blank"> jupyter 笔记本</a>):</p><pre class="lw lx ly lz gt ma lv mb mc aw md bi"><span id="d094" class="me kq it lv b gy mf mg l mh mi">base_model = EfficientNetB5(include_top=False, weights='imagenet')<br/>x = base_model.output<br/>x = GlobalAveragePooling2D()(x)<br/>predictions = Dense(num_classes, activation='softmax')(x)<br/>model = Model(inputs=base_model.input, outputs=predictions)</span><span id="3e9c" class="me kq it lv b gy mj mg l mh mi"># fix the feature extraction part of the model<br/>for layer in base_model.layers:<br/>    layer.trainable = False</span><span id="56c6" class="me kq it lv b gy mj mg l mh mi">model.summary()<br/>--------</span><span id="25fe" class="me kq it lv b gy mj mg l mh mi">Total params: 28,615,970<br/>Trainable params: 102,450<br/>Non-trainable params: 28,513,520</span></pre><p id="1b55" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们只有 10 万个可训练参数，而整个网络有 2800 万个。有了这组减少的自由参数，我们可以在自定义数据上训练最后一层，而特征提取层使用来自 imageNet 的权重。</p><p id="8ffd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">训练模型后，我们可能会看到以下结果:</p><figure class="lw lx ly lz gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mk"><img src="../Images/eab3eb0977159bbc9f28607e3c3d855e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/0*_KdHwjAxL7SO50CR.png"/></div></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">训练数据集的损失(蓝色)看起来不错，但是测试数据的损失(橙色)看起来很奇怪。通常，这种损耗曲线是过度拟合的指标。</p></figure><figure class="lw lx ly lz gt ml gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/bf1cae776893705dfafa0de9b877764e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/0*aXL6XEr_1rzEDr8A.png"/></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">模型精度也是如此。虽然训练数据的准确性看起来还可以，但是测试的准确性却完全不行。</p></figure><h1 id="632a" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">批量标准化的怪异之处</h1><p id="d9ba" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">这种怪异的行为来自 BatchNormalization 层。好像有个<a class="ae ko" href="https://github.com/keras-team/keras/issues/9214" rel="noopener ugc nofollow" target="_blank"> bug </a>，在使用 keras (2.2.4)和 tensorflow 1.x 的时候，问题好像是冻结的批量归一化层确实也冻结了归一化参数。(点击阅读更多关于不同标准化层的信息)。要解决这个问题，我们可以使 BatchNormalization 层可训练:</p><pre class="lw lx ly lz gt ma lv mb mc aw md bi"><span id="ac25" class="me kq it lv b gy mf mg l mh mi">for layer in base_model.layers:<br/>    if isinstance(layer, BatchNormalization):<br/>        layer.trainable = True<br/>    else:<br/>        layer.trainable = False</span></pre><p id="1290" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">不幸的是，我们失去了使用更大 batch_size 的能力，当我们使 BatchNormaliation 可训练时，keras 似乎需要更多的内存来存储模型。</p><p id="26ce" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">或者，我们可以忽略上面的奇怪分数，因为我们的层仍在学习，正如我们在训练损失/准确性中看到的，随后我们以 BatchNormalization 可训练的方式训练整个网络。然而，以下是 BN 可训练时模型的得分:</p><figure class="lw lx ly lz gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mx"><img src="../Images/0a9873e5da2dcfe09187992baebd63e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/0*y5uXm4m8-ttcQf0e.png"/></div></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">训练数据集(蓝色)和测试数据(橙色)的损失现在看起来很完美。</p></figure><figure class="lw lx ly lz gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi my"><img src="../Images/66257eff51f0fb653e3af5b047370b56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/0*5QEgRTcaruoSR-oc.png"/></div></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">还有准确性</p></figure><p id="6b7e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当只训练最后一层时，我们仍然有好处。例如，我们有较少的可训练参数，这意味着更快的计算时间。在大型数据集上，我宁愿忽略验证分数，并通过完全冻结基本模型(包括 BN)来利用较大的 batch_size。</p><h1 id="221b" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">释放网络的全部能量</h1><p id="e640" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">在训练过程中的某个点，模型没有进一步改进，是时候打开网络的其余部分来微调特征提取部分了。因此，我们使所有的层可训练，并再次适应模型。现在，我们有超过 2800 万个参数，训练需要更长的时间，但由于我们已经训练了最后一层，我们有一个更好的起点。</p><pre class="lw lx ly lz gt ma lv mb mc aw md bi"><span id="7277" class="me kq it lv b gy mf mg l mh mi">for layer in model.layers:<br/>    layer.trainable = True<br/>model.summary()<br/>--------</span><span id="8bd6" class="me kq it lv b gy mj mg l mh mi">Total params: 28,615,970<br/>Trainable params: 28,443,234<br/>Non-trainable params: 172,736</span></pre><p id="aeef" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">注意:避免模型的早期过度拟合是很重要的，因为模型可能很难逃脱局部最小值，因此我们确保在全面训练之前和之后更好地打开网络。另外，不要忘记调整 batch_size，否则我们会运行 OOM。要估计模型所需的内存，请看这里(<a class="ae ko" href="https://stackoverflow.com/questions/43137288/how-to-determine-needed-memory-of-keras-model" rel="noopener ugc nofollow" target="_blank"> stackoverflow </a>)。我也建议利用<a class="ae ko" href="https://keras.io/api/callbacks/early_stopping/" rel="noopener ugc nofollow" target="_blank">早停</a>。</p><p id="c43a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">第二次调用 fit()后，我们得到了一个更好的模型:</p><figure class="lw lx ly lz gt ml gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/0a3ff8a462e01ec66e1966f9dd00ab10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/0*pSOrDJUJaDQd_iwA.png"/></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">第二训练阶段的损失仍然减少，因此模型得到改进</p></figure><figure class="lw lx ly lz gt ml gh gi paragraph-image"><div class="gh gi na"><img src="../Images/ecedc40033a5d6e20071ecfb1e6846c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/0*d3zZinZeaXxfSDDL.png"/></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">对于训练和测试数据，模型的准确性也提高了</p></figure><p id="4d58" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最后，我们在自定义数据上训练了一个最先进的 efficientnet 模型。为了使这个模型生产就绪，还有一些工作要做。如果你对如何部署这样一个模型感兴趣，你可以查看<a class="ae ko" href="http://digital-thinking.de/how-to-deploy-keras-cnns-with-tensorflow-serve-including-jpeg-decoding/" rel="noopener ugc nofollow" target="_blank">这篇</a>文章。</p><p id="5ec8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这篇文章最初发表在我的个人博客<a class="ae ko" href="http://digital-thinking.de/keras-transfer-learning-for-image-classification-with-effificientnet/" rel="noopener ugc nofollow" target="_blank">这里</a>。</p></div></div>    
</body>
</html>