# 图上的机器学习任务

> 原文：<https://towardsdatascience.com/machine-learning-tasks-on-graphs-7bc8f175119a?source=collection_archive---------19----------------------->

## 可以分为有监督/无监督学习吗？没那么简单…

![](img/e19c5f6f24e559a1585f8afd78d3c936.png)

缺少友谊联系的动物友谊网络。图标由[图标 8](https://icons8.com/)

## 相关文章

*   [图的特征提取](https://medium.com/me/stats/post/625f4c5fb8cd)
*   [走向可解释图神经网络](/towards-explainable-graph-neural-networks-45f5e3912dd0)
*   [图形神经网络的 10 大学习资源](/top-10-learning-resources-for-graph-neural-networks-f24d4eb2cc2b)

图表是一种有趣的数据类型。我们本可以认为，我们可以用与“正常”数据相同的方式进行预测和训练模型。令人惊讶的是，机器学习任务在图上的定义非常不同，我们可以将其分为 4 种类型:节点分类、链接预测、整个图的学习和社区检测。在这篇文章中，我们仔细研究了它们是如何定义的，并理解了为什么它们与标准的机器学习任务如此不同。

# 节点分类

让我们想象一下，我们有一个动物之间的友谊网络。动物可以是一只*狗*，一只*猫*，或者一只*鸭*，我们可以用额外的特征来描述它，例如*体重、*和*颜色。*两种特定动物之间的联系意味着它们彼此喜欢。鉴于这种友谊网络和特征，我们的目标是预测动物的缺失类型。这种预测任务被称为节点分类。

![](img/6cddfc4a62db304f0f27b4e02d1a32a2.png)

缺失节点标签的动物友谊网络。图标由[图标 8](https://icons8.com/) 表示

让我们将符号形式化。数学上，我们可以把这个动物友谊网络定义为 *G = (V，ε)，*其中 V 是节点(动物)，E 是边(友谊连接)。此外，每个节点具有各自的特征向量**x**I(重量、高度和颜色)，其中 *i* 意味着该向量属于节点**V**I。节点分类任务的目标是给定节点**V** *i* 及其邻居*，预测标签 **y** *i* 。*

现在，我们如何使用机器学习模型来预测这些动物类型？大部分机器学习模型都是基于数据点相互独立的事实( *i.i.d* 假设)。这里这个假设失败了，因为节点标签(动物类型)可能依赖于其他相邻节点[1]。例如，更有可能的是，更靠近猫的集群的节点也是猫。*相似的节点通常靠得更近，这就是所谓的*[](https://en.wikipedia.org/wiki/Homophily)**。**

*因为在这种情况下数据独立性不再起作用，所以我们不能将这种分类任务归类为监督学习。它经常被研究人员称为*半监督学习*，因为我们可以使用来自相邻节点的信息来预测某个节点【1】。*

# *链接预测*

*链路预测的目的是确定两个节点之间是否存在连接。在我们之前的动物友谊图的例子中，它只是预测相邻的动物是否是朋友。*

*![](img/e19c5f6f24e559a1585f8afd78d3c936.png)*

*缺少友谊联系的动物友谊网络。图标按[图标 8](https://icons8.com/)*

*类似于节点分类，我们也可以利用邻域信息来预测两个节点之间的链接。一组流行的链路预测方法被称为*启发式方法*【2】。他们从图本身计算某些分数，并将其转换为两个节点之间链接的可能性。启发式方法可以被必须发生的邻居*跳*的最大数量所划分[2]。例如，公共邻居是一种*一阶*试探法，因为它只需要节点的直接邻居来计算分数(而不是邻居的邻居)。在下图中，我们可以看到节点**V**1 和 **V** *3* 的第一邻域。*

*![](img/629406d2b19ea510a9b6f741e1384e32.png)*

***V** 1 和 **V** 3 节点有两个公共邻居: **V** 6 和 **V** 2。图标由[图标 8](https://icons8.com/)*

*青蛙 **V** 1 和 **V** 3 有两个共同的朋友(相邻节点): **V** 6 和 **V** 2。利用这个简单的分数，公共邻居算法决定两个节点之间是否有链接。*

*当然，还有更复杂的方法，例如，资源分配(二阶试探法)，它使用来自二阶跳跃的信息[2]。在节点 ***V*** *5 的情况下，RA* 将使用其算法 ***V*** *4* 和 ***V*** *6* 从第一个邻域和 ***V*** *1* 和 ***V*** *3* 其他方法可以使用更高阶的试探法来生成用于链接预测的图形特征。*

*类似于节点分类，链接预测也被称为*半监督*学习，因为我们使用邻域信息来预测两个节点之间的链接。*

# *对整个图形的学习:分类、回归、聚类*

*我们换个例子。考虑一下，我们现在有一个分子数据，我们的任务是预测给定的分子是否有毒。下图显示了如何使用图形神经网络来设计此分类任务。*

*![](img/e4e0146006a0b9fe33f9797a27c54ded.png)*

*图形数据分类任务概述。每个分子可以表示为一个单独的图形，并被视为 i.i.d 数据点。分子的图片取自[【3】](https://arxiv.org/abs/1509.09292)。突出显示的红色部分显示了引发毒性反应的分子部分。这与本文无关，所以请忽略这个突出显示的红色部分。如果你有兴趣了解更多，请看[3]*

*我们可以把每个分子看作一个独立的图，其中一个原子是一个节点，原子之间的连接是一条边。这是一个在整个图中进行*分类*任务的例子。这里的不同之处在于，我们得到了*不同图形的多个*实例，并在这些实例上训练我们的模型[1]。我们学习整个图形，而不是预测单个图形中的特定组件，如节点或边。*

*在多个图形实例上的学习任务的引人注目之处在于，数据点被认为是*I . I . d .*。这意味着图形上的学习任务与标准机器学习问题中使用的分类、回归和聚类任务非常相似，如果不是相同的话。这对我们来说是个好消息，因为我们可以重用标准机器学习算法的方法，如 RandomForest、SVMs 或 XGBoost。*

# *社区检测*

*简而言之，图的社区检测可以被认为是一个*单个*图中节点的聚类任务。让我们看看下面的一个例子，展示了一个科学家网络，他们至少共同撰写了一篇论文。*

*![](img/66a6f140fd38ed201dac2e571e328d05.png)*

*这张图片展示了一个科学家网络，他们至少共同撰写了一篇论文。我们可以看到在不同领域工作的科学家聚集在一起。图片取自[【5】](https://www.pnas.org/content/99/12/7821)。*

*在这里，社区检测的任务将是识别这些在不同领域工作的科学家集群。虽然看起来很直观，但社区的聚类定义相当模糊，并且在不同的数据集之间大小和形状不同[4]。社区也可能重叠，这使得区分它们变得更加困难。*

*凭直觉，我们可以怀疑社区内部的节点将有更多的连接到相邻的边。还会有边更少的节点连接不同的社区。这些是大多数社区发现算法所基于的理论基础。有许多不同类型的社区检测算法，但最流行的是基于*谱聚类*、*统计推断*、*优化*和*动态*【6】的方法。*

# *总结*

*我们已经看到，在图上有 4 种主要类型的机器学习任务:节点分类、链接预测、整个图的学习和社区检测。这些任务中的大多数与正常的监督/非监督学习非常不同。这是因为图形是相互连接的，数据独立性假设不成立。研究人员称之为*半监督*学习。*

# *关于我*

*我是阿姆斯特丹大学的人工智能硕士学生。在我的业余时间，你可以发现我摆弄数据或者调试我的深度学习模型(我发誓这很有效！).我也喜欢徒步旅行:)*

*如果你想了解我的最新文章和其他有用的内容，以下是我的其他社交媒体资料:*

*   *[领英](https://www.linkedin.com/in/kacperkubara/)*
*   *[Github](https://github.com/KacperKubara)*

# *参考*

*[1] [林子幸·汉密尔顿的《图形表示学》一书](https://www.cs.mcgill.ca/~wlh/grl_book/)*

*[2] [基于图形神经网络的链路预测](https://papers.nips.cc/paper/7763-link-prediction-based-on-graph-neural-networks.pdf)*

*[3] [用于学习分子指纹的图上的卷积网络](https://arxiv.org/abs/1509.09292)*

*[4] [图中的社区检测](https://www.sciencedirect.com/science/article/pii/S0370157309002841)*

*[5] [社会和生物网络中的社区结构](https://www.pnas.org/content/99/12/7821)*

*[6] [网络中的社区检测:用户指南](https://arxiv.org/pdf/1608.00163.pdf)*