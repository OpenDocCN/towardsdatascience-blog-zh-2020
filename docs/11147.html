<html>
<head>
<title>Agglomerative Clustering and Dendrograms — Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">凝聚聚类和树状图——解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/agglomerative-clustering-and-dendrograms-explained-29fc12b85f23?source=collection_archive---------12-----------------------#2020-08-03">https://towardsdatascience.com/agglomerative-clustering-and-dendrograms-explained-29fc12b85f23?source=collection_archive---------12-----------------------#2020-08-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="19d6" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">凝聚层次聚类、树状图及其在 python 中的实现</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/99cbdb5f40559fbc257428b8b5989c9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_QICvjjD5ZUGufOw"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@campaign_creators?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">活动发起人</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="5f8e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">凝聚聚类是一种层次聚类算法。它是一种无监督的机器学习技术，将群体分为几个聚类，使得同一聚类中的数据点更相似，而不同聚类中的数据点不相似。</p><ul class=""><li id="2bb9" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">同一簇中的点彼此更接近。</li><li id="5333" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">不同簇中的点相距很远。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/e63596abfc2143a4050a316c4f1dbb25.png" data-original-src="https://miro.medium.com/v2/resize:fit:712/format:webp/0*DRwkvBEc92jseAdW.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，样本二维数据集</p></figure><p id="7915" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在上面的二维数据集样本中，可以看到数据集形成了 3 个相距很远的聚类，并且同一聚类中的点彼此靠近。</p><div class="mk ml gp gr mm mn"><a rel="noopener follow" target="_blank" href="/hierarchical-clustering-agglomerative-and-divisive-explained-342e6b20d710"><div class="mo ab fo"><div class="mp ab mq cl cj mr"><h2 class="bd iu gy z fp ms fr fs mt fu fw is bi translated">等级聚类:凝聚和分裂——解释</h2><div class="mu l"><h3 class="bd b gy z fp ms fr fs mt fu fw dk translated">聚集和分裂聚类算法及其实现综述</h3></div><div class="mv l"><p class="bd b dl z fp ms fr fs mt fu fw dk translated">towardsdatascience.com</p></div></div><div class="mw l"><div class="mx l my mz na mw nb ks mn"/></div></div></a></div><h1 id="e4a3" class="nc nd it bd ne nf ng nh ni nj nk nl nm jz nn ka no kc np kd nq kf nr kg ns nt bi translated">凝聚聚类背后的直觉:</h1><p id="55f4" class="pw-post-body-paragraph kz la it lb b lc nu ju le lf nv jx lh li nw lk ll lm nx lo lp lq ny ls lt lu im bi translated">凝聚聚类是一种自下而上的方法，最初，每个数据点都是自己的一个聚类，随着层次结构的向上移动，更多的聚类对被合并。</p><h2 id="4ca9" class="nz nd it bd ne oa ob dn ni oc od dp nm li oe of no lm og oh nq lq oi oj ns ok bi translated">聚集聚类的步骤:</h2><ol class=""><li id="1e15" class="lv lw it lb b lc nu lf nv li ol lm om lq on lu oo mb mc md bi translated">最初，所有的数据点都是它自己的一个集群。</li><li id="f170" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu oo mb mc md bi translated">取两个最近的集群，将它们连接起来形成一个集群。</li><li id="a095" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu oo mb mc md bi translated">递归地进行第 2 步，直到获得所需的聚类数。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/455009047f64043fde418b6b554e07c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*cXKLuVJEjIVgiUnr.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，<strong class="bd oq">第一张图:</strong>所有的数据点都是自己的一个聚类，<strong class="bd oq">第二张图:</strong>两个最近的聚类(被一个黑色椭圆包围)结合在一起形成一个单独的聚类。</p></figure><p id="6389" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在上面的样本数据集中，观察到两个集群彼此相距甚远。所以我们在得到 2 个集群后就停止了。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/ee58c2fd8002f21e7c473e9f4562d087.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/0*94f-JstLyjLgHE3r.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，样本数据集分为两个聚类</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/b5022502e69ce4790536f3e170fda890.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/0*BknrmAbFbrOKM7LU.png"/></div></figure><h1 id="a265" class="nc nd it bd ne nf ng nh ni nj nk nl nm jz nn ka no kc np kd nq kf nr kg ns nt bi translated">如何将两个集群连接成一个集群？</h1><p id="9735" class="pw-post-body-paragraph kz la it lb b lc nu ju le lf nv jx lh li nw lk ll lm nx lo lp lq ny ls lt lu im bi translated">为了获得期望数量的聚类，聚类的数量需要从最初的 n 个聚类减少(n 等于数据点的总数)。通过计算两个聚类之间的相似性来组合它们。</p><p id="a88a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有一些方法用于计算两个聚类之间的相似性:</p><ul class=""><li id="c1be" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">两个聚类中最近的两个点之间的距离。</li><li id="2cc4" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">两个集群中两个最远点之间的距离。</li><li id="86da" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">两个聚类中所有点之间的平均距离。</li><li id="a047" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">两个簇的质心之间的距离。</li></ul><p id="6f3c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">选择上述任何一种相似性度量标准都有一些优点和缺点。</p><h2 id="84a1" class="nz nd it bd ne oa ob dn ni oc od dp nm li oe of no lm og oh nq lq oi oj ns ok bi translated">凝聚聚类的实现:</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ot ou l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure><h1 id="3b38" class="nc nd it bd ne nf ng nh ni nj nk nl nm jz nn ka no kc np kd nq kf nr kg ns nt bi translated">如何获得最优的聚类数？</h1><p id="e303" class="pw-post-body-paragraph kz la it lb b lc nu ju le lf nv jx lh li nw lk ll lm nx lo lp lq ny ls lt lu im bi translated">凝聚聚类算法的实现接受所需的聚类数。有几种方法可以找到最佳的聚类数，从而以如下方式将群体分成 k 个聚类:</p><blockquote class="ov"><p id="a607" class="ow ox it bd oy oz pa pb pc pd pe lu dk translated">同一簇中的点彼此更接近。</p><p id="d622" class="ow ox it bd oy oz pa pb pc pd pe lu dk translated">不同簇中的点相距很远。</p></blockquote><p id="efb5" class="pw-post-body-paragraph kz la it lb b lc pf ju le lf pg jx lh li ph lk ll lm pi lo lp lq pj ls lt lu im bi translated">通过观察树状图，可以找到所需的聚类数。</p><p id="d0e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">树状图是数据点之间层次关系的图形表示。它说明了由相应分析产生的聚类的排列，并用于观察分层(聚集)聚类的输出。</p><h2 id="fa26" class="nz nd it bd ne oa ob dn ni oc od dp nm li oe of no lm og oh nq lq oi oj ns ok bi translated">树状图的实现:</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ot ou l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure><p id="09ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">点击从<a class="ae ky" href="https://drive.google.com/file/d/1I1VIaqrkNclNM7i-pnRD1ZJKc2noA4fh/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">下载二维数据集样本。</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pk"><img src="../Images/b2d2547215751685318916b4ce6a36e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gZjCWunL_Y1ylUw_1uJuuw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，<strong class="bd oq">左图:</strong>可视化样本数据集，<strong class="bd oq">右图:</strong>可视化样本数据集的 3 个聚类</p></figure><p id="6bee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于上面的样本数据集，观察到聚类的最佳数量是 3。但是对于高维数据集，其中数据集的可视化是不可能的，树状图在寻找最佳聚类数中起着重要作用。</p><h2 id="f146" class="nz nd it bd ne oa ob dn ni oc od dp nm li oe of no lm og oh nq lq oi oj ns ok bi translated">如何通过观察树状图找到最佳聚类数:</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/ee0fba23a40da182d5a4f44d0a53c041.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*3J_-iSA0L4jHEZ9kMn3AbQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，上述样本数据集的树状图</p></figure><p id="5a9e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从上面的树状图中，找出一个最大高度不与任何水平垂直树状图线交叉的水平矩形。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pm"><img src="../Images/0ffecc71c7bd4e79be2ef5275394dff4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ldDTryuZD0pZX8F8BqCcCA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，<strong class="bd oq">左:</strong>分成 2 簇，<strong class="bd oq">右:</strong>分成 3 簇</p></figure><p id="9de4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">树状图中具有最大高度的矩形可以被切割的部分，最佳聚类数将是 3，如上图右侧所示。选择最大高度矩形是因为它表示最佳聚类数之间的最大欧几里德距离。</p><h1 id="9b5a" class="nc nd it bd ne nf ng nh ni nj nk nl nm jz nn ka no kc np kd nq kf nr kg ns nt bi translated">结论:</h1><div class="mk ml gp gr mm mn"><a rel="noopener follow" target="_blank" href="/understanding-k-means-k-means-and-k-medoids-clustering-algorithms-ad9c9fbf47ca"><div class="mo ab fo"><div class="mp ab mq cl cj mr"><h2 class="bd iu gy z fp ms fr fs mt fu fw is bi translated">了解 K-means、K-means++和 K-medoids 聚类算法</h2><div class="mu l"><h3 class="bd b gy z fp ms fr fs mt fu fw dk translated">了解 K-means、K-means++和 K-Medoids 聚类算法及其关系的概述。这篇文章…</h3></div><div class="mv l"><p class="bd b dl z fp ms fr fs mt fu fw dk translated">towardsdatascience.com</p></div></div><div class="mw l"><div class="pn l my mz na mw nb ks mn"/></div></div></a></div><p id="ce79" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我们讨论了凝聚层次聚类算法的深入直觉。该算法的缺点是空间和时间复杂度较大，不适用于大规模数据集。即使观察树状图来寻找大型数据集的最佳聚类数也是非常困难的。</p><blockquote class="ov"><p id="bf09" class="ow ox it bd oy oz pa pb pc pd pe lu dk translated">感谢您的阅读</p></blockquote></div></div>    
</body>
</html>