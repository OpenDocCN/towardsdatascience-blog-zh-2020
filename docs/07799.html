<html>
<head>
<title>A Guide To Interpretable Machine Learning — Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">可解释机器学习指南—第二部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-guide-to-interpretable-machine-learning-2-fa3c4489fb53?source=collection_archive---------22-----------------------#2020-06-10">https://towardsdatascience.com/a-guide-to-interpretable-machine-learning-2-fa3c4489fb53?source=collection_archive---------22-----------------------#2020-06-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/978009b7e90fb91ee1d3be948a38b90f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XY781-Hf_BRCTlivSMlWiQ.jpeg"/></div></div></figure><div class=""/><h1 id="3bff" class="kb kc je bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">石灰的应用</h1><p id="2b97" class="pw-post-body-paragraph kz la je lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">在这一部分，我们将介绍石灰的应用。我们已经在本文的第1部分看到了Titanic数据集的数据预处理和LIME的理论和工作。我们有了预处理过的数据。接下来，我们转到石灰应用程序。</p><h2 id="d7e0" class="ly kc je bd kd lz ma dn kh mb mc dp kl lk md me kp lo mf mg kt ls mh mi kx mj bi translated">神经网络</h2><p id="8577" class="pw-post-body-paragraph kz la je lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">首先，我们将使用LIME应用程序来设计基于神经网络的模型。</p><figure class="mk ml mm mn gt iv"><div class="bz fp l di"><div class="mo mp l"/></div></figure><p id="9196" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">这是我们的神经网络课。我用过TensorFlow Keras的几层。我们的输入层接受31列的数据集。它有4个密集层，输出层有1个神经元来决定“存活”或“不存活”。输出函数为sigmoid。我们将使用Adam优化器和二元交叉熵。</p><p id="07a2" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">现在我们将调用并训练模型。</p><pre class="mk ml mm mn gt mv mw mx my aw mz bi"><span id="2842" class="ly kc je mw b gy na nb l nc nd">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>from sklearn.metrics import accuracy_score,f1_score</span><span id="b12b" class="ly kc je mw b gy ne nb l nc nd">model_nn=Neural_Network(X_train,Y_train, X_test,Y_test)<br/>print(model_nn.predict_classes(X_train).astype(float))</span></pre><p id="3cd4" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">在我们的训练集上,“predict_classes”函数生成一个二维列表。</p><figure class="mk ml mm mn gt iv gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/7e1fb510962fda633e0ab2c681324b51.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/1*mF3KYrfc5EXci3Vb812VIw.png"/></div></figure><p id="7f82" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">如果我们观察，每个元素有2个值，第一个值是事件发生的概率，第二个值是不发生的概率。</p><p id="7e02" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">现在，我们去吃酸橙。</p><pre class="mk ml mm mn gt mv mw mx my aw mz bi"><span id="b290" class="ly kc je mw b gy na nb l nc nd">import lime.lime_tabular<br/>classes=['Survived','Not_Survived']</span><span id="6df3" class="ly kc je mw b gy ne nb l nc nd">df_k=df.drop(['Survived'],axis=1)<br/>all_feat=df_k.columns<br/>#model_gb.fit(X_train,Y_train)<br/>print(model_nn.predict_classes(X_train).astype(float))<br/>predict_fn_nn= lambda x: model_nn.predict_classes(x).astype(float)</span><span id="4457" class="ly kc je mw b gy ne nb l nc nd">explainer = lime.lime_tabular.LimeTabularExplainer(X_train,mode='classification',feature_selection= 'auto',<br/>                                               class_names=classes,feature_names = all_feat, <br/>                                                   kernel_width=None,discretize_continuous=True)<br/></span></pre><p id="a236" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">接下来，我们呼叫解释者。</p><pre class="mk ml mm mn gt mv mw mx my aw mz bi"><span id="7abc" class="ly kc je mw b gy na nb l nc nd">observation_1=24<br/>exp=explainer.explain_instance(X_test[observation_1], predict_fn_nn, num_features=5,top_labels=1)<br/>exp.show_in_notebook()</span></pre><figure class="mk ml mm mn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ng"><img src="../Images/6139c05a79496b41715d646246504595.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*52Azv2Hlo98b6jp9GFjmXg.png"/></div></div></figure><p id="f9f2" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">这将产生如图所示的结果。现在，这里最左边的方框是两类的预测概率,“幸存”类和“未幸存”类。中间的图表显示了重要的特征及其边界值，而右边的表格是所通过的观察行中实际对应的特征值。</p><pre class="mk ml mm mn gt mv mw mx my aw mz bi"><span id="a245" class="ly kc je mw b gy na nb l nc nd">observation_1=42<br/>exp=explainer.explain_instance(X_test[observation_1], predict_fn_nn, num_features=5,top_labels=1)<br/>exp.show_in_notebook()</span></pre><figure class="mk ml mm mn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nh"><img src="../Images/04c058e95aeaa46fd0699c14006013be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LyMcThScIJ7XePga600g-Q.png"/></div></div></figure><p id="79f8" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">这是第二个可供参考的例子。</p><h2 id="650e" class="ly kc je bd kd lz ma dn kh mb mc dp kl lk md me kp lo mf mg kt ls mh mi kx mj bi translated">XGBoost</h2><p id="dacd" class="pw-post-body-paragraph kz la je lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">现在，让我们检查XGBoost的LIME解释器。下面的代码片段用于启动XGBoost的解释器。</p><pre class="mk ml mm mn gt mv mw mx my aw mz bi"><span id="c23e" class="ly kc je mw b gy na nb l nc nd">from xgboost import XGBClassifier<br/>classes=['Survived','Not_Survived']<br/>all_feat=df_k.columns<br/>model_xgb = XGBClassifier()<br/>model_xgb.fit(X_train, Y_train)<br/>predict_fn_xgb = lambda x: model_xgb.predict_proba(x).astype(float)<br/>explainer = lime.lime_tabular.LimeTabularExplainer(X_train,mode='classification',feature_selection= 'auto',<br/>                                                   class_names=classes,feature_names = all_feat, <br/>                                                   kernel_width=None,discretize_continuous=True)</span></pre><p id="32f7" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">我们称之为解释者。</p><pre class="mk ml mm mn gt mv mw mx my aw mz bi"><span id="4ee0" class="ly kc je mw b gy na nb l nc nd">observation_1=32<br/>exp=explainer.explain_instance(X_test[observation_1], predict_fn_xgb, num_features=5,top_labels=1)<br/>exp.show_in_notebook()</span></pre><figure class="mk ml mm mn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ni"><img src="../Images/65dcf10ca5745b08795e2c48499d6148.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dfv0_O3-CC69cAu-GLNAvQ.png"/></div></div></figure><p id="9d80" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">现在小字体0.54，0.15等是特征的对应贡献，值1.0，0.0是边界值。</p><p id="155b" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">二审:</p><pre class="mk ml mm mn gt mv mw mx my aw mz bi"><span id="c18e" class="ly kc je mw b gy na nb l nc nd">observation_1=86<br/>exp=explainer.explain_instance(X_test[observation_1], predict_fn_xgb, num_features=5,top_labels=1)<br/>exp.show_in_notebook()</span></pre><figure class="mk ml mm mn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nj"><img src="../Images/64efaac713a0bec963a38f94615878a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wzng8N0U5SY2w5EwG9D0mQ.png"/></div></div></figure><p id="1728" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">我们也可以用其他形式获得这些结果。</p><pre class="mk ml mm mn gt mv mw mx my aw mz bi"><span id="4c83" class="ly kc je mw b gy na nb l nc nd">exp.as_map()</span></pre><p id="a910" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">结果:</p><pre class="mk ml mm mn gt mv mw mx my aw mz bi"><span id="46ba" class="ly kc je mw b gy na nb l nc nd">{1: [(3, 0.5441379658340547),<br/>  (24, -0.15448119146031272),<br/>  (2, -0.1233271814431237),<br/>  (9, 0.11870380100373268),<br/>  (8, -0.11796994360496856)]}</span></pre><p id="a677" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">这提供了这种形式的地图。1是预测，列表有特征号和重要性。</p><pre class="mk ml mm mn gt mv mw mx my aw mz bi"><span id="799f" class="ly kc je mw b gy na nb l nc nd">exp.as_pyplot_figure()</span></pre><figure class="mk ml mm mn gt iv gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/36f6f55e218eed14364437ba96717d63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1078/format:webp/1*9DJMD1sbvWuQ9WcOdZ7hCA.png"/></div></figure><h2 id="34cd" class="ly kc je bd kd lz ma dn kh mb mc dp kl lk md me kp lo mf mg kt ls mh mi kx mj bi translated">随机森林</h2><p id="cb57" class="pw-post-body-paragraph kz la je lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">我们还将看到一个使用随机森林的实例。</p><pre class="mk ml mm mn gt mv mw mx my aw mz bi"><span id="ce3d" class="ly kc je mw b gy na nb l nc nd">from sklearn.ensemble import RandomForestClassifier<br/>classes=['Survived','Not_Survived']<br/>all_feat=df_k.columns<br/>model_rf = RandomForestClassifier()<br/>model_rf.fit(X_train, Y_train)<br/>predict_fn_rf = lambda x: model_rf.predict_proba(x).astype(float)<br/>explainer = lime.lime_tabular.LimeTabularExplainer(X_train,mode='classification',feature_selection= 'auto',<br/>                                                   class_names=classes,feature_names = all_feat, <br/>                                                   kernel_width=None,discretize_continuous=True)</span><span id="507b" class="ly kc je mw b gy ne nb l nc nd">observation_1=47<br/>exp=explainer.explain_instance(X_test[observation_1], predict_fn_rf, num_features=5,top_labels=1)<br/>exp.show_in_notebook()</span></pre><figure class="mk ml mm mn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nl"><img src="../Images/b7cf2df15fa62cd12a06c922b9724c8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QcDye6DzjPHvoOZFO4lC8A.png"/></div></div></figure><h2 id="7589" class="ly kc je bd kd lz ma dn kh mb mc dp kl lk md me kp lo mf mg kt ls mh mi kx mj bi translated">用可解释的模型解释</h2><p id="6ad8" class="pw-post-body-paragraph kz la je lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">现在，在我们的理论中，我们已经看到一些可解释的模型被用来获得直觉。所以，让我们回溯一下，看看我们是否能得出类似的结果。</p><p id="01f9" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">现在，我们不能通过调整要素来生成数据集，因为这是由LIME模块针对特定观测随机完成的。所以，让我们用整个数据集来试着解释结果。我们将使用我们的神经网络模型来这样做。</p><pre class="mk ml mm mn gt mv mw mx my aw mz bi"><span id="4c53" class="ly kc je mw b gy na nb l nc nd">model_nn=Neural_Network(X_train,Y_train, X_test,Y_test)<br/>pred=model_nn.predict_classes(X).astype(float)<br/>print(pred)</span></pre><p id="71db" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">结果:</p><pre class="mk ml mm mn gt mv mw mx my aw mz bi"><span id="2516" class="ly kc je mw b gy na nb l nc nd">[[4.87956345e-01 5.12043655e-01]<br/> [1.00000000e+00 0.00000000e+00]<br/> [9.99990702e-01 9.29832458e-06]<br/> ...<br/> [2.51247525e-01 7.48752475e-01]<br/> [3.47714871e-02 9.65228498e-01]<br/> [5.00362515e-01 4.99637485e-01]]</span></pre><p id="d9b7" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">这是我们对整个数据集上每个类的神经网络预测。现在，让我们从结果中得出预测</p><pre class="mk ml mm mn gt mv mw mx my aw mz bi"><span id="6f7b" class="ly kc je mw b gy na nb l nc nd">Pred=[]<br/>for j in pred:<br/>    if (j[0]/j[1])&gt;1:<br/>        Pred.append(1)<br/>    else:<br/>        Pred.append(0)<br/>print(Pred)</span></pre><figure class="mk ml mm mn gt iv gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/80c133758c8405d8cf9ffce5dcadba32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1172/format:webp/1*VtxBUkJJ85Qnp_ARzJki6g.png"/></div></figure><p id="0198" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">这些是我们得到的预测。现在，这个列表将作为我们的目标集和整个数据集，没有保留的列作为我们的特征集。因此，实际上我们正在尝试创建一个行为类似于我们的人工神经网络模型的模型。</p><p id="931b" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">先用决策树模型来解读吧。</p><pre class="mk ml mm mn gt mv mw mx my aw mz bi"><span id="ac65" class="ly kc je mw b gy na nb l nc nd">from sklearn.tree import DecisionTreeClassifier<br/>clf = DecisionTreeClassifier(criterion = "gini", <br/>            random_state = 100,max_depth=6, min_samples_leaf=8)<br/>clf.fit(X,Pred)</span></pre><p id="461c" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">我们用X作为训练集，pred作为预测集来拟合模型。</p><pre class="mk ml mm mn gt mv mw mx my aw mz bi"><span id="a10f" class="ly kc je mw b gy na nb l nc nd">y_pred_tree = clf.predict(X_test) <br/>accuracy_score(Y_test,y_pred_tree)</span></pre><p id="3ce7" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">这给出了87%的准确度，这对于我们的目的来说是非常好的。因此，我们的决策树模型表现为87%的黑盒模型。现在，我们来试着解读一下。</p><pre class="mk ml mm mn gt mv mw mx my aw mz bi"><span id="fc19" class="ly kc je mw b gy na nb l nc nd">from sklearn import tree<br/>import graphviz<br/>tree_data = tree.export_graphviz(clf, out_file=None, <br/>                                feature_names=df_k.columns,  <br/>                                class_names=["Survived","Not_Survived"],  <br/>                                filled=True, rounded=True,  <br/>                                special_characters=True)  <br/>graph = graphviz.Source(tree_data)  <br/>#this will create an iris.pdf file with the rule path<br/>graph.render("titanic")</span></pre><p id="a416" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">这将给我们一个可视化的节点形成的树。</p><figure class="mk ml mm mn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nn"><img src="../Images/30f255594a2b0659c8665cd16115da16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oj8JIIfJchF-GzEOgFApAg.png"/></div></div></figure><p id="1be7" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">这是我们的树形成。每个节点都有一个关于节点的决策，该决策决定所获得的结果。从这里我们可以获得边界值。现在，我们来谈谈特性的重要性。</p><pre class="mk ml mm mn gt mv mw mx my aw mz bi"><span id="e95d" class="ly kc je mw b gy na nb l nc nd">feat_importance = clf.tree_.compute_feature_importances(normalize=False)<br/>print("feat importance = " + str(feat_importance))<br/>print(len(feat_importance))</span></pre><p id="aaa3" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">结果</p><pre class="mk ml mm mn gt mv mw mx my aw mz bi"><span id="67e4" class="ly kc je mw b gy na nb l nc nd">feat importance = [0.00000000e+00 3.61136190e-03 1.39727482e-02 2.77128356e-01<br/> 0.00000000e+00 1.01837874e-02 3.36657108e-03 0.00000000e+00<br/> 3.66875884e-03 0.00000000e+00 4.96683522e-03 3.87192368e-03<br/> 0.00000000e+00 4.20667376e-04 4.60591655e-03 8.34158579e-03<br/> 0.00000000e+00 4.42596721e-03 6.48457847e-03 0.00000000e+00<br/> 8.54240790e-04 2.40717013e-04 0.00000000e+00 6.19429971e-04<br/> 6.36079009e-03 8.23858955e-05 0.00000000e+00 7.82349745e-03<br/> 3.09307607e-03 6.90860184e-03 0.00000000e+00]<br/>31</span></pre><p id="bb3a" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">这提供了31个特性重要性的列表，每个特性有一个值。</p><pre class="mk ml mm mn gt mv mw mx my aw mz bi"><span id="7be4" class="ly kc je mw b gy na nb l nc nd">import matplotlib.pyplot as plt; plt.rcdefaults()<br/>import numpy as np<br/>import matplotlib.pyplot as plt</span><span id="7d26" class="ly kc je mw b gy ne nb l nc nd">objects = df_k.columns<br/>y_pos = np.arange(len(objects))<br/>performance = feat_importance</span><span id="b241" class="ly kc je mw b gy ne nb l nc nd">fig, ax = plt.subplots(figsize=(20, 20))<br/>plt.barh(y_pos, performance, align='center', alpha=0.5)<br/>fontsize=14,<br/>plt.yticks(y_pos, objects,fontsize=20)<br/>plt.xticks(fontsize=20)<br/>plt.xlabel('Contributions')<br/>plt.title('Feature Contributions',fontsize=20)</span><span id="8268" class="ly kc je mw b gy ne nb l nc nd">plt.show()</span></pre><figure class="mk ml mm mn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi no"><img src="../Images/1847688b98ee3c3c8ab3ab6d7317aceb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7TT9KH5AbQpB2KcYMfQKww.png"/></div></div></figure><p id="4a3c" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">上图显示了要素重要性图。因此，我们可以使用决策树从整体上对我们的神经网络模型得出一个非常清晰的直觉。</p><p id="0265" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">现在，让我们看看我们是否能从回归模型中得出一些东西。</p><pre class="mk ml mm mn gt mv mw mx my aw mz bi"><span id="74b9" class="ly kc je mw b gy na nb l nc nd">from sklearn.linear_model import LogisticRegression<br/>model = LogisticRegression(solver='liblinear', random_state=0)<br/>model.fit(X, Pred)</span></pre><p id="848b" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">类似于这里的决策树，我们用X和Pred来复制我们的黑盒模型。</p><pre class="mk ml mm mn gt mv mw mx my aw mz bi"><span id="8d17" class="ly kc je mw b gy na nb l nc nd">Weights=np.hstack((model.intercept_[:,None], model.coef_))<br/><br/>print(Weights)<br/>print(len(Weights[0]))</span></pre><p id="f9e5" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">结果:</p><pre class="mk ml mm mn gt mv mw mx my aw mz bi"><span id="372e" class="ly kc je mw b gy na nb l nc nd">[[ 0.12274084  0.5433339   0.21922863 -0.63982169  1.45315131 -1.33041046<br/>   0.0827389   0.22923408 -0.22390968  0.56095332 -1.14391015 -0.04797768<br/>   1.28082004 -0.52714469  0.30183458 -0.17909374  0.37075839 -0.24801754<br/>   0.37928751  0.22380996  0.12957386 -0.51560858 -0.09432191 -0.18315589<br/>  -0.00641827  0.49388734 -0.09299957 -0.08857277  0.10037632  0.02236453<br/>  -0.34099133  0.46373217]]</span><span id="dbf3" class="ly kc je mw b gy ne nb l nc nd">32</span></pre><p id="82c4" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">因此，它返回每个特征的权重和B0偏差。这是一个包含32个元素的列表。所以，这些是我们的特征重要性。</p><figure class="mk ml mm mn gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi no"><img src="../Images/369203762e556877377114efd7d5ecb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0w7iEXSNbf9qViRacvOmmA.png"/></div></div></figure><p id="658d" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">上面的列表给了我们这个情节。所以我们看到，根据理论，我们可以从可解释的模型中得到直觉。</p><p id="1e2a" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">石灰也可以应用于图像。但是这里的做法有点不同。在那里，改变一个像素无关紧要。因此，形成了一组称为超像素的像素。这些超像素变成灰色，然后再次预测图像。通过这种方式，可以判断图像的哪些部分实际上会影响决策。</p><h2 id="27e7" class="ly kc je bd kd lz ma dn kh mb mc dp kl lk md me kp lo mf mg kt ls mh mi kx mj bi translated">SHAP</h2><p id="d360" class="pw-post-body-paragraph kz la je lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">SHAP主张“沙普利附加解释”。它基于Shapley值，Shapley值基于博弈联盟理论中的一种方法。它检查特定特征值如何影响模型预测。它首先采用两个特征，并尝试它们的组合，以检查它们如何影响预测，并为它们分配一些重要性。然后，它添加第三个特征，并检查它对预测的影响程度，再次为其分配权重，依此类推。SHAP树解释器用于获取特性重要性。</p><pre class="mk ml mm mn gt mv mw mx my aw mz bi"><span id="4adc" class="ly kc je mw b gy na nb l nc nd">import shap</span><span id="2782" class="ly kc je mw b gy ne nb l nc nd">shap_values = shap.TreeExplainer(model_xgb).shap_values(X_train)<br/>shap.summary_plot(shap_values, X_train, plot_type="bar")</span></pre><figure class="mk ml mm mn gt iv gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/fc91dd108eb02f0d6a1c406b1ec93652.png" data-original-src="https://miro.medium.com/v2/resize:fit:1078/format:webp/1*DmTDSF4UZYDSorPFNg3CnA.png"/></div></figure><p id="f198" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">这是应用Xgb产生的特性重要性图。</p><pre class="mk ml mm mn gt mv mw mx my aw mz bi"><span id="ba72" class="ly kc je mw b gy na nb l nc nd">import shap</span><span id="ec43" class="ly kc je mw b gy ne nb l nc nd">shap_values = shap.TreeExplainer(model_rf).shap_values(X_train)<br/>shap.summary_plot(shap_values, X_train, plot_type="bar")</span></pre><figure class="mk ml mm mn gt iv gh gi paragraph-image"><div class="gh gi np"><img src="../Images/fc338d2e36d0130cd98f83b82b426e90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*0rqgabPanVFniT3JLrIG1Q.png"/></div></figure><p id="6ca3" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">这是通过应用随机森林生成的要素重要性图。</p><p id="c824" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">红色部分显示要素对0或“未存活”类的影响，蓝色部分显示1或“存活”类的影响。</p><h2 id="903e" class="ly kc je bd kd lz ma dn kh mb mc dp kl lk md me kp lo mf mg kt ls mh mi kx mj bi translated">结论</h2><p id="8c25" class="pw-post-body-paragraph kz la je lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">这是对人机学习解释库如何运行的基本洞察。希望这些文章有所帮助。</p><p id="c062" class="pw-post-body-paragraph kz la je lb b lc mq le lf lg mr li lj lk ms lm ln lo mt lq lr ls mu lu lv lw im bi translated">这是<a class="ae lx" href="https://github.com/abr-98/Interpretability_on_Titanic_Dataset-" rel="noopener ugc nofollow" target="_blank"> Github链接。</a></p></div></div>    
</body>
</html>