<html>
<head>
<title>Know What You Don’t Know: Getting Reliable Confidence Scores When Unsure of a Prediction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">知道你不知道的:当对预测不确定时，获得可靠的信心分数</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/know-what-you-dont-know-getting-reliable-confidence-scores-when-unsure-of-a-prediction-882f2f146726?source=collection_archive---------19-----------------------#2020-03-22">https://towardsdatascience.com/know-what-you-dont-know-getting-reliable-confidence-scores-when-unsure-of-a-prediction-882f2f146726?source=collection_archive---------19-----------------------#2020-03-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="b319" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接触样本外的例子，作为获得更有意义的预测分数的一种方式。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/c0d20616d7bb91ecc88d3472447d4803.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8tB3vkwqmZPaEBzh3mySNA.jpeg"/></div></div><p class="kx ky gj gh gi kz la bd b be z dk translated">Artem Sapegin 在<a class="ae lb" href="https://unsplash.com/s/photos/sunrise?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="c738" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Softmax预测分数通常用作多类分类设置中的置信度分数。在本帖中，我们将展示在通过梯度下降进行常规经验风险最小化时，softmax分数可能是没有意义的。我们还将应用<a class="ae lb" href="https://arxiv.org/abs/1812.04606" rel="noopener ugc nofollow" target="_blank">异常值暴露深度异常检测</a>中介绍的方法来缓解这一问题，并为softmax分数添加更多含义。</p><p id="0503" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">判别分类器(试图从数据中估计P(y|x)的模型)往往在预测中过于自信，即使输入样本看起来与他们在训练阶段看到的任何东西都不一样。这使得这种模型的输出分数不能被可靠地用作置信度分数，因为该模型经常在它不应该有置信度的地方有置信度。</p><h1 id="52b4" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">示例:</h1><p id="24ff" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">在这个合成示例中，我们有一个类别0的大聚类和另一个类别1的大聚类，外加两组较小的训练集中不存在的离群点。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mf"><img src="../Images/54c38a471148494a8e9afb5eb5edff36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6PYjL96Azr1lI9pvNEMoOQ.jpeg"/></div></div><p class="kx ky gj gh gi kz la bd b be z dk translated">玩具示例</p></figure><p id="6b85" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果我们对此应用常规分类器，我们会得到如下结果:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mf"><img src="../Images/c1c4acb8ad34f488872047402dd4ea31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dSyDRCbsBCjNor2dgQkTuA.jpeg"/></div></div><p class="kx ky gj gh gi kz la bd b be z dk translated">置信度得分基线</p></figure><p id="2aca" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们看到分类器在任何地方都过于自信，即使是离群样本也有很高的分数。<strong class="jp ir">使用热图</strong>显示置信度得分。</p><p id="b2bd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这使得直接使用softmax分数作为置信度分数不是一个好主意，如果分类器在训练中没有看到任何证据来支持它，那么它可能意味着置信度分数是错误的。</p><p id="98bf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是，如果我们使用<a class="ae lb" href="https://arxiv.org/abs/1812.04606" rel="noopener ugc nofollow" target="_blank">异常值暴露深度异常检测</a>中提出的方法，我们可以获得更合理的Softmax分数:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mf"><img src="../Images/3ccaf962a8ab24269979e918f231eba4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bg3-SJWh1fhDbFTd6_F5LQ.jpeg"/></div></div><p class="kx ky gj gh gi kz la bd b be z dk translated">异常暴露</p></figure><p id="e676" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个得分图更加合理，有助于了解模型在哪些地方有足够的信心，在哪些地方没有。异常区域具有非常低的置信度~0.5(相当于在两类设置中完全没有置信度)。</p><h1 id="b0ff" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">方法的描述</h1><p id="d043" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated"><a class="ae lb" href="https://arxiv.org/abs/1812.04606" rel="noopener ugc nofollow" target="_blank">异常值暴露的深度异常检测</a>中提出的想法是使用与您的训练/测试数据大不相同的外部数据，并强制模型预测该外部数据的均匀分布。</p><p id="c6a9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">例如，如果您试图构建一个分类器来预测图像中的猫和狗，您可以获得一组熊和鲨鱼图像，并强制模型在这些图像上预测[0.5，0.5]。</p><h1 id="f5ab" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">数据和模型</h1><p id="239a" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">我们将使用102朵花作为分布内数据集，使用OpenImage数据集的子集作为分布外数据集。在引言中引用的论文中，他们表明，对一组非分布样本的训练可以很好地推广到其他非分布样本。</p><p id="0c6d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们使用MobilenetV2作为我们的分类架构，并用Imagenet初始化权重。</p><pre class="km kn ko kp gt mg mh mi mj aw mk bi"><span id="3bdb" class="ml ld iq mh b gy mm mn l mo mp"><strong class="mh ir">def </strong>get_model_classification(<br/>    input_shape=(<strong class="mh ir">None</strong>, <strong class="mh ir">None</strong>, 3),<br/>    weights=<strong class="mh ir">"imagenet"</strong>,<br/>    n_classes=102,<br/>):<br/>    inputs = Input(input_shape)<br/>    base_model = MobileNetV2(<br/>        include_top=<strong class="mh ir">False</strong>, input_shape=input_shape, weights=weights<br/>    )</span><span id="c0ed" class="ml ld iq mh b gy mq mn l mo mp">    x = base_model(inputs)<br/>    x = Dropout(0.5)(x)<br/>    out1 = GlobalMaxPooling2D()(x)<br/>    out2 = GlobalAveragePooling2D()(x)<br/>    out = Concatenate(axis=-1)([out1, out2])<br/>    out = Dropout(0.5)(out)<br/>    out = Dense(n_classes, activation=<strong class="mh ir">"softmax"</strong>)(out)<br/>    model = Model(inputs, out)<br/>    model.compile(<br/>        optimizer=Adam(0.0001), loss=categorical_crossentropy, metrics=[<strong class="mh ir">"acc"</strong>]<br/>    )</span><span id="351f" class="ml ld iq mh b gy mq mn l mo mp">    <strong class="mh ir">return </strong>model</span></pre><p id="26a8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将使用生成器从硬盘上一批一批地加载图像。在基线中，我们仅加载分布内图像，而在异常曝光模型中，我们从具有正确标签的分布内图像中加载一半，从具有统一目标的分布外图像中加载另一半= &gt;:</p><pre class="km kn ko kp gt mg mh mi mj aw mk bi"><span id="0c87" class="ml ld iq mh b gy mm mn l mo mp">target = [1 / n_label <strong class="mh ir">for </strong>_ <strong class="mh ir">in </strong>range(n_label)]</span></pre><h1 id="4be0" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">结果</h1><p id="924d" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">两种训练配置对分布样本的准确率都略高于90%。如果softmax max得分低于0.15，我们选择预测“不知道”，从而放弃进行类别预测。</p><p id="503c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在让我们看看每个模型是如何工作的！</p><h2 id="a293" class="ml ld iq bd le mr ms dn li mt mu dp lm jy mv mw lq kc mx my lu kg mz na ly nb bi translated">常规培训:</h2><p id="27e6" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">您可以通过以下方式运行web应用程序:</p><pre class="km kn ko kp gt mg mh mi mj aw mk bi"><span id="0a2b" class="ml ld iq mh b gy mm mn l mo mp">streamlit run main.py</span></pre><div class="km kn ko kp gt ab cb"><figure class="nc kq nd ne nf ng nh paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><img src="../Images/a084d295b231317e10ed32a346a81d19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*-hN4n4o2yefb-Hxq25V8cw.png"/></div></figure><figure class="nc kq ni ne nf ng nh paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><img src="../Images/b5a264ff8b9981355e6e6d85cf746835.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*oqqdPPFzqA0Yk7lkVTeVsw.png"/></div><p class="kx ky gj gh gi kz la bd b be z dk nj di nk nl translated">来自Unsplash的第一张<strong class="bd nm">鸟</strong>图像/来自102种花数据集的第二张<strong class="bd nm">花</strong>图像</p></figure></div><p id="238e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们训练了一个花卉分类，然后尝试对一张鸟的图片进行分类，该模型预测仙客来类具有相当高的置信度"<strong class="jp ir"> 0.72 </strong>"，这不是我们想要的。</p><h2 id="8f9f" class="ml ld iq bd le mr ms dn li mt mu dp lm jy mv mw lq kc mx my lu kg mz na ly nb bi translated">异常风险:</h2><p id="3f1b" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">您可以通过以下方式运行web应用程序:</p><pre class="km kn ko kp gt mg mh mi mj aw mk bi"><span id="cff1" class="ml ld iq mh b gy mm mn l mo mp">streamlit run ood_main.py</span></pre><div class="km kn ko kp gt ab cb"><figure class="nc kq nn ne nf ng nh paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><img src="../Images/b43eec073c03697cb3ab122abf905025.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*8sBYaC8z90FZAmj0K4V-6g.png"/></div></figure><figure class="nc kq no ne nf ng nh paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><img src="../Images/7143ef25e1fde0328ed8593cf0fbba58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*kCP4X0tZr77V2529d5fR-Q.png"/></div><p class="kx ky gj gh gi kz la bd b be z dk nj di nk nl translated">来自Unsplash的第一张<strong class="bd nm">鸟</strong>图像/来自102朵花数据集的第二张<strong class="bd nm">花</strong>图像</p></figure></div><p id="7ad0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">好多了！因为最大softmax分数是0.01，所以鸟图片被分类为“不知道”。在两个模型之间，分布内花图像(右)的预测保持不变。</p><p id="ebba" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来是对来自维基百科的图像的预测，第一个(左)是102朵花数据集中的一朵花，第二个是分布中不存在的一种食肉植物。异常暴露模型表现如预期，分布内图像被正确分类，而模型避免对食肉植物进行分类预测。</p><div class="km kn ko kp gt ab cb"><figure class="nc kq np ne nf ng nh paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><img src="../Images/e6f7226ae57354363e6344cec1b0343f.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*BWXTdRL25e0p7MxgJp2sfg.png"/></div></figure><figure class="nc kq nq ne nf ng nh paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><img src="../Images/cba82171f17b61c4060e85c1c747625b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*1RsZhKRt6wPyWJlDShe01A.png"/></div><p class="kx ky gj gh gi kz la bd b be z dk nr di ns nl translated">修改第一张<strong class="bd nm">花</strong>图由aftabnoori—Own work，CC BY-SA 4.0，【https://commons.wikimedia.org/w/index.php?curid=41960730】T2/修改第二张<strong class="bd nm">植物</strong>图:<a class="ae lb" href="https://commons.wikimedia.org/wiki/File:Venus_Flytrap_showing_trigger_hairs.jpg" rel="noopener ugc nofollow" target="_blank">https://commons . wikimedia . org/wiki/File:Venus _ fly trap _ showing _ trigger _ hairs . jpg</a></p></figure></div><h1 id="c0e5" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">结论</h1><p id="f616" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">在这篇文章中，我们展示了softmax分数作为信心的衡量标准是多么的有缺陷。然后，我们应用了一种基于离群值暴露的方法来解决这个问题，并获得更有意义的置信度得分。这使我们能够在需要时可靠地避免做出预测，这在许多商业/研究应用中是一个至关重要的特性，在这些应用中，不做任何预测比做出明显错误的预测要好。</p><h2 id="120b" class="ml ld iq bd le mr ms dn li mt mu dp lm jy mv mw lq kc mx my lu kg mz na ly nb bi translated">参考资料:</h2><p id="c9f6" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated"><a class="ae lb" href="https://arxiv.org/abs/1812.04606" rel="noopener ugc nofollow" target="_blank">具有异常暴露的深度异常检测</a></p><h2 id="4654" class="ml ld iq bd le mr ms dn li mt mu dp lm jy mv mw lq kc mx my lu kg mz na ly nb bi translated">代码:</h2><div class="nt nu gp gr nv nw"><a href="https://github.com/CVxTz/learning_to_abstain" rel="noopener  ugc nofollow" target="_blank"><div class="nx ab fo"><div class="ny ab nz cl cj oa"><h2 class="bd ir gy z fp ob fr fs oc fu fw ip bi translated">cvx tz/learning _ to _ absent</h2><div class="od l"><h3 class="bd b gy z fp ob fr fs oc fu fw dk translated">知道自己不知道的。通过在GitHub上创建一个帐户，为CVxTz/learning _ to _ absent开发做贡献。</h3></div><div class="oe l"><p class="bd b dl z fp ob fr fs oc fu fw dk translated">github.com</p></div></div><div class="of l"><div class="og l oh oi oj of ok kv nw"/></div></div></a></div></div></div>    
</body>
</html>