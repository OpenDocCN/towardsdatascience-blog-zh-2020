<html>
<head>
<title>Machine Learning Perceptron Implementation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习感知器实现</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-perceptron-implementation-b867016269ec?source=collection_archive---------34-----------------------#2020-08-18">https://towardsdatascience.com/machine-learning-perceptron-implementation-b867016269ec?source=collection_archive---------34-----------------------#2020-08-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="cac5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Python 使用增量规则(梯度下降)</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a94d6c62d8b6819b4e62188221c4f1b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iZCqQnP2fbpcwVo01G9qAw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@ffstop?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">摄影师</a>在<a class="ae ky" href="https://unsplash.com/s/photos/programming?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="d39f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我们将看看用<code class="fe lv lw lx ly b">numpy</code>用<code class="fe lv lw lx ly b">Python3</code>写的一个程序。我们将讨论什么是<strong class="lb iu">感知器</strong>的基础知识，什么是<strong class="lb iu"> delta 规则</strong>以及如何使用它来收敛感知器的学习。</p></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><h1 id="5e03" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">什么是感知器？</h1><p id="9931" class="pw-post-body-paragraph kz la it lb b lc my ju le lf mz jx lh li na lk ll lm nb lo lp lq nc ls lt lu im bi translated">感知器是二元分类器<a class="ae ky" rel="noopener" target="_blank" href="/basics-of-supervised-learning-classification-d26c00d80100">监督学习</a>的算法(让我们假设<code class="fe lv lw lx ly b">{1, 0}</code>)。我们有一个<a class="ae ky" rel="noopener" target="_blank" href="/simple-linear-regression-in-python-8cf596ac6a7c">权重向量和输入数据向量的线性组合</a>，它通过一个激活函数，然后与一个阈值进行比较。如果线性组合大于阈值，我们预测该类为<code class="fe lv lw lx ly b">1</code>，否则为<code class="fe lv lw lx ly b">0. Mathematically,</code></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/32deff99c6a27458b4ee1d3a89b2e1de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/format:webp/1*uFT-D7KAKE4QsWj-CntQ4w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">资料来源:stackexchange.com</p></figure><p id="2217" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感知器只代表线性可分的问题。如果训练样本不是线性可分的，它们就不能收敛。这就带来了<strong class="lb iu">德尔塔法则。</strong></p></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><p id="ff8f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> delta 规则</strong>向<a class="ae ky" rel="noopener" target="_blank" href="/journey-into-data-mining-3b5ccfa5343">目标概念</a>的最佳近似收敛。其核心思想是利用<a class="ae ky" href="https://medium.com/swlh/batch-linear-regression-75e7dd2ab28b" rel="noopener"> <strong class="lb iu">梯度下降</strong> </a> <strong class="lb iu"> </strong>搜索所有可能权重向量的假设空间。</p><blockquote class="ne nf ng"><p id="0d77" class="kz la nh lb b lc ld ju le lf lg jx lh ni lj lk ll nj ln lo lp nk lr ls lt lu im bi translated">注意:这为“反向传播”算法提供了基础。</p></blockquote></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><p id="c67b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们讨论一下手头的问题。程序将读取一个<a class="ae ky" href="https://gist.github.com/tarunlnmiit/8f23c6fe277fe682a17e5536733d4b35" rel="noopener ugc nofollow" target="_blank">数据集</a>(制表符分隔文件)，并将第一列视为<a class="ae ky" rel="noopener" target="_blank" href="/journey-into-data-mining-3b5ccfa5343">目标概念</a>。目标概念中存在的值是<strong class="lb iu"> A 和 B，</strong>我们将把<strong class="lb iu"> A </strong>视为+ve 类或<code class="fe lv lw lx ly b">1</code>，把<strong class="lb iu"> B </strong>视为-ve 类或<code class="fe lv lw lx ly b">0</code>。该程序以批处理模式实现感知器训练规则，具有恒定的学习速率和退火(随着迭代次数的增加而减少)学习速率，从学习速率为 1 开始。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/fdd1a57d5ffa9f875e5edcc20d6fa7dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QOyUN0mKyEqFrwOXuQgi_Q.png"/></div></div></figure><p id="c2df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中 Y(x，w)是被错误分类的样本集。我们将使用错误分类点的计数或数量作为我们的错误率(即| Y(x，w)|)。输出也将是包含每次迭代误差的制表符分隔(tsv)文件，即它将有 100 列。同样，它将有 2 行，一行用于正常学习率，一行用于退火学习率。</p></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><p id="c2be" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，理解什么是感知机，什么是德尔塔法则，以及我们将如何使用它。让我们开始实施<code class="fe lv lw lx ly b">Python3</code>。</p><p id="011c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在程序中，我们从命令行提供两个输入。它们是:</p><p id="ce30" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">1.<strong class="lb iu">数据</strong> —数据文件的位置。</p><p id="f786" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.<strong class="lb iu">输出</strong>—tsv 解决方案的写入位置</p><p id="1feb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，程序应该能够这样启动:</p><pre class="kj kk kl km gt nm ly nn no aw np bi"><span id="6fbc" class="nq mh it ly b gy nr ns l nt nu">python3 perceptron.py --data data.tsv --output solution.tsv</span></pre></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><p id="8560" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该程序由 8 部分组成，我们将一次看一个。</p><h2 id="fb5d" class="nq mh it bd mi nv nw dn mm nx ny dp mq li nz oa ms lm ob oc mu lq od oe mw of bi translated">进口报表</h2><pre class="kj kk kl km gt nm ly nn no aw np bi"><span id="70e8" class="nq mh it ly b gy nr ns l nt nu">import argparse # to read inputs from command line<br/>import csv # to read and process dataset<br/>import numpy as np # to perform mathematical functions</span></pre><h2 id="b797" class="nq mh it bd mi nv nw dn mm nx ny dp mq li nz oa ms lm ob oc mu lq od oe mw of bi translated">代码执行初始化程序块</h2><pre class="kj kk kl km gt nm ly nn no aw np bi"><span id="22e6" class="nq mh it ly b gy nr ns l nt nu"># initialise argument parser and read arguments from command line with the respective flags and then call the main() function</span><span id="c635" class="nq mh it ly b gy og ns l nt nu">if __name__ == '__main__':    <br/>    parser = argparse.ArgumentParser()    <br/>    parser.add_argument("-d", "--data", help="Data File")        <br/>    parser.add_argument("-o", "--output", help="output")    <br/>    main()</span></pre><h2 id="742a" class="nq mh it bd mi nv nw dn mm nx ny dp mq li nz oa ms lm ob oc mu lq od oe mw of bi translated"><code class="fe lv lw lx ly b"><a class="ae ky" href="https://gist.github.com/tarunlnmiit/744221fb4289efc5d1e02d2a20b251d1" rel="noopener ugc nofollow" target="_blank">main()</a></code>功能</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="0d61" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe lv lw lx ly b">main()</code>功能的流程如下:</p><ol class=""><li id="40c3" class="oj ok it lb b lc ld lf lg li ol lm om lq on lu oo op oq or bi translated">将各自的命令行输入保存到变量中</li><li id="a89a" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">设置开始学习率= 1</li><li id="c4fe" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">使用<code class="fe lv lw lx ly b">csv</code>和<code class="fe lv lw lx ly b">delimiter='\t'</code>读取<a class="ae ky" href="https://gist.github.com/tarunlnmiit/8f23c6fe277fe682a17e5536733d4b35" rel="noopener ugc nofollow" target="_blank">数据集</a>，在<code class="fe lv lw lx ly b">X</code>中存储自变量，在<code class="fe lv lw lx ly b">Y</code>中存储因变量。我们将<code class="fe lv lw lx ly b">1.0</code>作为偏差添加到我们的独立数据中</li><li id="b985" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">独立数据和从属数据被转换为浮点型</li><li id="d5ae" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">重量向量用与<code class="fe lv lw lx ly b">X</code>维数相同的零初始化</li><li id="35f9" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated"><a class="ae ky" href="https://gist.github.com/tarunlnmiit/9ec684d0098435f59876134dd5515f00" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">normal error</strong></a><strong class="lb iu"/>和<a class="ae ky" href="https://gist.github.com/tarunlnmiit/6ad1a050260b0302f58d496bca726c48" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">anneal error</strong></a><strong class="lb iu"/>通过调用各自的方法来计算</li><li id="c4f9" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">最后，输出保存到一个 tsv 文件中</li></ol><h2 id="8ef7" class="nq mh it bd mi nv nw dn mm nx ny dp mq li nz oa ms lm ob oc mu lq od oe mw of bi translated"><a class="ae ky" href="https://gist.github.com/tarunlnmiit/9ec684d0098435f59876134dd5515f00" rel="noopener ugc nofollow" target="_blank">calculateNormalBatchLearning()</a>函数</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="1d78" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe lv lw lx ly b">calculateNormalBatchLearning()</code>的流程如下:</p><ol class=""><li id="bf5e" class="oj ok it lb b lc ld lf lg li ol lm om lq on lu oo op oq or bi translated">初始化变量<code class="fe lv lw lx ly b">e</code>以存储错误计数</li><li id="2419" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">循环运行 100 次迭代</li><li id="cf5e" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">使用<a class="ae ky" href="https://gist.github.com/tarunlnmiit/ffcf3acada3d7df941ea88dc2af16ff1" rel="noopener ugc nofollow" target="_blank">calculatecopredictedvalue()</a>方法，根据之前描述的感知器规则计算预测值</li><li id="1187" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">使用<a class="ae ky" href="https://gist.github.com/tarunlnmiit/c641dd660094112739c7f1b32432cbd3" rel="noopener ugc nofollow" target="_blank"> calculateError() </a>方法计算错误计数</li><li id="1d48" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">使用<a class="ae ky" href="https://gist.github.com/tarunlnmiit/75902865526a5b01914d5404353424d1" rel="noopener ugc nofollow" target="_blank"> calculateGradient() </a>方法根据上述等式更新权重</li></ol><h2 id="3f4c" class="nq mh it bd mi nv nw dn mm nx ny dp mq li nz oa ms lm ob oc mu lq od oe mw of bi translated"><a class="ae ky" href="https://gist.github.com/tarunlnmiit/6ad1a050260b0302f58d496bca726c48" rel="noopener ugc nofollow" target="_blank">calculateanelbatchlearning()</a>函数</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="1274" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe lv lw lx ly b">calculateNormalBatchLearning()</code>的流程如下:</p><ol class=""><li id="7219" class="oj ok it lb b lc ld lf lg li ol lm om lq on lu oo op oq or bi translated">初始化变量<code class="fe lv lw lx ly b">e</code>以存储错误计数</li><li id="d482" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">循环运行 100 次迭代</li><li id="c310" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">使用<a class="ae ky" href="https://gist.github.com/tarunlnmiit/ffcf3acada3d7df941ea88dc2af16ff1" rel="noopener ugc nofollow" target="_blank">calculatecopredictedvalue()</a>方法，根据之前描述的感知器规则计算预测值</li><li id="a79e" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">使用<a class="ae ky" href="https://gist.github.com/tarunlnmiit/c641dd660094112739c7f1b32432cbd3" rel="noopener ugc nofollow" target="_blank"> calculateError() </a>方法计算错误计数</li><li id="360e" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">学习率除以迭代次数</li><li id="c2bf" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">使用<a class="ae ky" href="https://gist.github.com/tarunlnmiit/75902865526a5b01914d5404353424d1" rel="noopener ugc nofollow" target="_blank"> calculateGradient() </a>方法根据上述等式更新权重</li></ol><h2 id="6be3" class="nq mh it bd mi nv nw dn mm nx ny dp mq li nz oa ms lm ob oc mu lq od oe mw of bi translated"><a class="ae ky" href="https://gist.github.com/tarunlnmiit/ffcf3acada3d7df941ea88dc2af16ff1" rel="noopener ugc nofollow" target="_blank">calculated predicted value()</a>函数</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="2e5a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如感知器图像所述，如果<code class="fe lv lw lx ly b">W</code>和<code class="fe lv lw lx ly b">X</code>的线性组合大于<code class="fe lv lw lx ly b">0</code>，那么我们预测类为<code class="fe lv lw lx ly b">1</code>否则为<code class="fe lv lw lx ly b">0</code>。</p><h2 id="f46a" class="nq mh it bd mi nv nw dn mm nx ny dp mq li nz oa ms lm ob oc mu lq od oe mw of bi translated"><a class="ae ky" href="https://gist.github.com/tarunlnmiit/c641dd660094112739c7f1b32432cbd3" rel="noopener ugc nofollow" target="_blank"> calculateError() </a>函数</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="442d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们计算预测值和真实值不匹配的情况的数量，这成为我们的错误计数。</p><h2 id="8900" class="nq mh it bd mi nv nw dn mm nx ny dp mq li nz oa ms lm ob oc mu lq od oe mw of bi translated"><a class="ae ky" href="https://gist.github.com/tarunlnmiit/75902865526a5b01914d5404353424d1" rel="noopener ugc nofollow" target="_blank"> calculateGradient() </a>函数</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="a2f9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该方法是上述权重更新公式的翻译。</p></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><p id="47a2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我将免费赠送一本关于一致性的电子书。在这里获得你的免费电子书。</p></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><p id="21d1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，所有的代码都在外面。让我们来看看程序的执行情况。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/91f2e6d2bcdded40e5518807b578a5e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KnS84fdAGc4UQAC84JdTwg.png"/></div></div></figure><p id="3310" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是<a class="ae ky" href="https://gist.github.com/tarunlnmiit/bd79340c72aa745cf1538e36776093c2" rel="noopener ugc nofollow" target="_blank">输出</a>的样子:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="10db" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://gist.github.com/tarunlnmiit/34a01f01aa532f425f85f569e7c8bbc8" rel="noopener ugc nofollow" target="_blank">最终程序</a></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure></div><div class="ab cl lz ma hx mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="im in io ip iq"><p id="f378" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你喜欢阅读这样的故事，并想支持我成为一名作家，可以考虑<a class="ae ky" href="https://tarun-gupta.medium.com/membership" rel="noopener">注册成为一名媒体会员</a>。每月 5 美元，你可以无限制地阅读媒体上的故事。如果你注册使用我的链接，我会赚一小笔佣金，不需要你额外付费。</p><div class="oy oz gp gr pa pb"><a href="https://tarun-gupta.medium.com/membership" rel="noopener follow" target="_blank"><div class="pc ab fo"><div class="pd ab pe cl cj pf"><h2 class="bd iu gy z fp pg fr fs ph fu fw is bi translated">加入我的推荐链接-塔伦古普塔</h2><div class="pi l"><h3 class="bd b gy z fp pg fr fs ph fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="pj l"><p class="bd b dl z fp pg fr fs ph fu fw dk translated">tarun-gupta.medium.com</p></div></div><div class="pk l"><div class="pl l pm pn po pk pp ks pb"/></div></div></a></div><p id="84a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是我的故事索引:</p><div class="oy oz gp gr pa pb"><a href="https://tarun-gupta.medium.com/thank-you-for-visiting-my-profile-9f708062c75e" rel="noopener follow" target="_blank"><div class="pc ab fo"><div class="pd ab pe cl cj pf"><h2 class="bd iu gy z fp pg fr fs ph fu fw is bi translated">标记故事列表的快速链接—感谢您的访问</h2><div class="pi l"><h3 class="bd b gy z fp pg fr fs ph fu fw dk translated">我也有一份以快节奏出版为目标的出版物。读书成为作家。</h3></div><div class="pj l"><p class="bd b dl z fp pg fr fs ph fu fw dk translated">tarun-gupta.medium.com</p></div></div></div></a></div></div></div>    
</body>
</html>