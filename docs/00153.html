<html>
<head>
<title>Learn Bayes Theorem by Detecting SPAM</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过检测垃圾邮件学习贝叶斯定理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/learn-bayes-theorem-by-detecting-spam-df092cd68d6a?source=collection_archive---------16-----------------------#2020-01-05">https://towardsdatascience.com/learn-bayes-theorem-by-detecting-spam-df092cd68d6a?source=collection_archive---------16-----------------------#2020-01-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6edd" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">应用贝叶斯定理预测SMS消息是垃圾消息的概率的教程。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/405d1b78c93dd0c6ee1711303a8757b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zy02qnuq0H3Bq5MRCIBHVw.png"/></div></div></figure><p id="5933" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">本教程有2个部分:</strong> <br/> 1。从<a class="ae lq" rel="noopener" target="_blank" href="/conditional-probability-with-a-python-example-fd6f5937cd2">条件概率</a>推导贝叶斯定理<br/> 2。预测短信是否是垃圾短信</p><h1 id="16d6" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">第一部分:从条件概率推导贝叶斯定理</h1><h2 id="6555" class="mj ls it bd lt mk ml dn lx mm mn dp mb ld mo mp md lh mq mr mf ll ms mt mh mu bi translated">条件概率</h2><p id="9f4d" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">我在这里更深入地讨论了条件概率<a class="ae lq" rel="noopener" target="_blank" href="/conditional-probability-with-a-python-example-fd6f5937cd2">。</a></p><p id="d65d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">条件概率告诉我们，给定另一个事件，一个事件发生的概率。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/1b1e8018b568387c84ec9ac34eb46f52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LtZSN0giQCVzYHDe1fh25w.png"/></div></div></figure><p id="b0c8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><code class="fe nb nc nd ne b">P(A|B) = P(A ∩ B) / P(B)</code>是发生<code class="fe nb nc nd ne b">A</code>的概率，在我们知道<code class="fe nb nc nd ne b">B</code>发生的情况下。计算方法是<code class="fe nb nc nd ne b">A</code>和<code class="fe nb nc nd ne b">B</code>都发生的概率除以<code class="fe nb nc nd ne b">B</code>发生的概率。</p><p id="60c8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">但是如果我们想找到相反的情况，在发生<code class="fe nb nc nd ne b">A</code>的情况下<code class="fe nb nc nd ne b">B</code>的概率，会怎么样呢？</p><p id="bd9e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有时条件概率在这方面很有用。但是有时候用贝叶斯定理更简单。</p><h2 id="86ca" class="mj ls it bd lt mk ml dn lx mm mn dp mb ld mo mp md lh mq mr mf ll ms mt mh mu bi translated">贝叶斯定理</h2><p id="ffa7" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated"><a class="ae lq" href="https://en.wikipedia.org/wiki/Bayes%27_theorem" rel="noopener ugc nofollow" target="_blank">维基百科</a>说，</p><blockquote class="nf ng nh"><p id="753e" class="ku kv ni kw b kx ky ju kz la lb jx lc nj le lf lg nk li lj lk nl lm ln lo lp im bi translated">在<a class="ae lq" href="https://en.wikipedia.org/wiki/Probability_theory" rel="noopener ugc nofollow" target="_blank">概率论</a>和<a class="ae lq" href="https://en.wikipedia.org/wiki/Statistics" rel="noopener ugc nofollow" target="_blank">统计学</a>，<strong class="kw iu">贝叶斯定理</strong>(或者<strong class="kw iu">贝叶斯定律</strong>或者<strong class="kw iu">贝叶斯法则</strong>)描述了<a class="ae lq" href="https://en.wikipedia.org/wiki/Event_(probability_theory)" rel="noopener ugc nofollow" target="_blank">事件</a>的<a class="ae lq" href="https://en.wikipedia.org/wiki/Probability" rel="noopener ugc nofollow" target="_blank">概率</a>，基于可能与该事件相关的条件的先验知识。</p></blockquote><h2 id="6908" class="mj ls it bd lt mk ml dn lx mm mn dp mb ld mo mp md lh mq mr mf ll ms mt mh mu bi translated"><strong class="ak">推导贝叶斯定理</strong></h2><p id="f689" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">我们从条件概率的公式开始，它可以写成“A给定B”或“B给定A”。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/60ceb332ddd4191256d56eb52edbca5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6GggLF_UTXmbufYPMvTPpQ.png"/></div></div></figure><p id="e090" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">注意，直观上，<code class="fe nb nc nd ne b">P(A∩B)</code>和<code class="fe nb nc nd ne b">P(B∩A)</code>是一样的(见下文)。这意味着我们可以互换使用它们。以后请记住这一点。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/b2afaaa5858c39aff5a9a7624d590ec4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dPilycndEcBQ01CW__s7JA.png"/></div></div></figure><p id="819c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们从第一个公式开始，<code class="fe nb nc nd ne b">P(A|B)= P(A∩B) / P(B)</code>。</p><p id="c5a3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">多两边乘<code class="fe nb nc nd ne b">P(B)</code>。这将抵消右边的<code class="fe nb nc nd ne b">P(B)</code>分母，留给我们下面的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/ef24dc0aa18ff4bb25b04e8e8f562c36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hRAHjw36l_ZV3ljOdEUJ7Q.png"/></div></div></figure><p id="a7fc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们现在能看到的(如果我们交换左右两边，会更容易)是<code class="fe nb nc nd ne b">P(A∩B)= P(A|B) * P(B)</code>。我们将把它插回到我们的第二个原始配方中(原始配方如下)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/6a25999fc435dab255d014d807c93050.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*70ywj8ewgBMMVf1qMhT8fA.png"/></div></div></figure><p id="c269" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">得到这个公式(修改如下)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/50562045afae088cbb35a20d07deedc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UTDk1rC_gv90NNSyeOe4eA.png"/></div></div></figure><p id="6e35" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">也就是贝叶斯定理。</p><p id="15a6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们现在将使用贝叶斯定理来尝试和预测SMS消息中的垃圾邮件。</p><h1 id="e425" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">第2部分:预测SMS消息是否是垃圾消息</h1><p id="f60a" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">贝叶斯推理在垃圾邮件检测中有着悠久的历史。我们将在这里用一些真实的数据进入基础。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/5664ff7d4e8baf7789e0ade87aa335ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vmYmcPTWQlJLLaY9DAXwGg.png"/></div></div></figure><p id="2630" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在我们的例子中，<code class="fe nb nc nd ne b">probability an SMS is spam, given some word</code>，等于<code class="fe nb nc nd ne b">probability of the word, given it is in a spam SMS</code>，乘以<code class="fe nb nc nd ne b">probability of spam</code>，再除以<code class="fe nb nc nd ne b">probability of the word</code>。</p><p id="46b6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">从<a class="ae lq" href="https://www.kaggle.com/uciml/sms-spam-collection-dataset" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>下载数据集，并在数据帧中检查。</p><pre class="kj kk kl km gt ns ne nt nu aw nv bi"><span id="9c4e" class="mj ls it ne b gy nw nx l ny nz">import pandas as pd<br/>df = pd.read_csv('sms-spam.csv', encoding='ISO-8859-1')<br/>df.head(3)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/51e5b138f254e51df8b8641e98b7f16e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_p6DDqPRmxnyiqrcRzGJAg.png"/></div></div></figure><p id="adc0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">原始CSV中的列没有意义。因此，我们将把有用的信息移到两个新列中，其中一列是布尔值，表示该短信是否是垃圾短信。</p><p id="a4c1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">仅供参考，“火腿”的意思是“不是垃圾邮件”。</p><pre class="kj kk kl km gt ns ne nt nu aw nv bi"><span id="68ea" class="mj ls it ne b gy nw nx l ny nz">import numpy as np</span><span id="1a5f" class="mj ls it ne b gy ob nx l ny nz">df['sms'] = df['v2']<br/>df['spam'] = np.where(df['v1'] == 'spam', 1, 0)</span><span id="f942" class="mj ls it ne b gy ob nx l ny nz">df.head(3)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/4fc1770a0d170c64cd331fea1dd411e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mSnZ8Bz7lwAaFdUwsGoAsg.png"/></div></div></figure><p id="ba21" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在删除旧列。</p><pre class="kj kk kl km gt ns ne nt nu aw nv bi"><span id="6ddd" class="mj ls it ne b gy nw nx l ny nz">df = df[['sms','spam']]<br/>df.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/a2816872e535697236f74c4fe3d52511.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cyab6BXN4x2oGcc13aIy5A.png"/></div></div></figure><p id="bf04" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">好多了。</p><p id="6672" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">检查记录的数量。</p><pre class="kj kk kl km gt ns ne nt nu aw nv bi"><span id="1396" class="mj ls it ne b gy nw nx l ny nz">len(df)<br/>#=&gt; 5572</span></pre><p id="3d8f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">那太多了。让我们使用25%的原始数据样本。</p><pre class="kj kk kl km gt ns ne nt nu aw nv bi"><span id="a620" class="mj ls it ne b gy nw nx l ny nz">sample_df = df.sample(frac=0.25)<br/>len(sample_df)<br/>#=&gt; 1393</span></pre><p id="b878" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">那更好。</p><p id="2813" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在将数据分成两个独立的数据帧，一个是垃圾邮件数据帧，一个是火腿数据帧。</p><pre class="kj kk kl km gt ns ne nt nu aw nv bi"><span id="77d1" class="mj ls it ne b gy nw nx l ny nz">spam_df = sample_df.loc[df['spam'] == 1]<br/>ham_df = sample_df.loc[df['spam'] == 0]</span><span id="3e3a" class="mj ls it ne b gy ob nx l ny nz">print(len(spam_df))<br/>print(len(ham_df))</span><span id="b4cb" class="mj ls it ne b gy ob nx l ny nz">#=&gt; 180<br/>#=&gt; 1213</span></pre><p id="d586" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们将使用sklearn的TFIDF矢量器来观察垃圾邮件中的一些重要单词，并选择一个插入我们的公式中。</p><pre class="kj kk kl km gt ns ne nt nu aw nv bi"><span id="3a7d" class="mj ls it ne b gy nw nx l ny nz">from sklearn.feature_extraction.text import TfidfVectorizer</span><span id="a6a7" class="mj ls it ne b gy ob nx l ny nz">vectorizer_spam = TfidfVectorizer(stop_words='english', max_features=30)</span><span id="2c2b" class="mj ls it ne b gy ob nx l ny nz">vectorizer_spam.fit(spam_df['sms'])<br/>vectorizer_spam.vocabulary_</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/d7b10f01ca5f9447a9681aa7f3763964.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PkHQzhzEPKNQMNIrlJ9eGw.png"/></div></div></figure><p id="916f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们需要在公式中选择一个单词，所以我将选择单词“win ”,尽管尝试使用其他单词也很有趣。</p><p id="4935" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在我们需要计算公式的不同部分。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/d25e65300afedc4c09ffb9a9a2b77512.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QzUXZpRx0LNOovR-KbG4BA.png"/></div></div></figure><p id="9de7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><code class="fe nb nc nd ne b">P(W|S)</code> =单词“win”出现在垃圾消息中的概率<br/> <code class="fe nb nc nd ne b">P(S)</code> =垃圾消息整体的概率<br/> <code class="fe nb nc nd ne b">P(W)</code> =单词“win”出现在消息整体中的概率</p><p id="a24e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">说出我们的话。</p><pre class="kj kk kl km gt ns ne nt nu aw nv bi"><span id="b827" class="mj ls it ne b gy nw nx l ny nz">word = 'win'</span></pre><p id="6307" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">计算<code class="fe nb nc nd ne b">P(W|S)</code>。</p><pre class="kj kk kl km gt ns ne nt nu aw nv bi"><span id="c957" class="mj ls it ne b gy nw nx l ny nz">word = 'win'</span><span id="2064" class="mj ls it ne b gy ob nx l ny nz">spam_count = 0<br/>spam_with_word_count = 0</span><span id="293c" class="mj ls it ne b gy ob nx l ny nz">for idx,row in spam_df.iterrows():<br/>    spam_count += 1<br/>    <br/>    if word in row.sms:<br/>        spam_with_word_count += 1</span><span id="4e50" class="mj ls it ne b gy ob nx l ny nz">probability_of_word_given_spam = spam_count / spam_with_word_count<br/>print(probability_of_word_given_spam)</span><span id="96ac" class="mj ls it ne b gy ob nx l ny nz">#=&gt; 10.0</span></pre><p id="576c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">计算<code class="fe nb nc nd ne b">P(S)</code>。</p><pre class="kj kk kl km gt ns ne nt nu aw nv bi"><span id="0425" class="mj ls it ne b gy nw nx l ny nz">probability_of_spam = len(spam_df) / (len(sample_df))<br/>print(probability_of_spam)</span><span id="fb5b" class="mj ls it ne b gy ob nx l ny nz">#=&gt; 0.12921751615218952</span></pre><p id="458d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">计算<code class="fe nb nc nd ne b">P(W)</code>。</p><pre class="kj kk kl km gt ns ne nt nu aw nv bi"><span id="ecba" class="mj ls it ne b gy nw nx l ny nz">sms_count = 0<br/>word_in_sms_count = 0</span><span id="921c" class="mj ls it ne b gy ob nx l ny nz">for idx,row in sample_df.iterrows():<br/>    sms_count += 1<br/>    <br/>    if word in row.sms:<br/>        word_in_sms_count += 1</span><span id="ac5f" class="mj ls it ne b gy ob nx l ny nz">probability_of_word = word_in_sms_count / sms_count<br/>print(probability_of_word)</span><span id="3a39" class="mj ls it ne b gy ob nx l ny nz">#=&gt; 0.022254127781765973</span></pre><p id="a153" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在把所有这些放在一起。</p><pre class="kj kk kl km gt ns ne nt nu aw nv bi"><span id="8444" class="mj ls it ne b gy nw nx l ny nz">(probability_of_word_given_spam * probability_of_spam) / probability_of_word</span><span id="3efe" class="mj ls it ne b gy ob nx l ny nz">#=&gt; 58.064516129032256</span></pre><p id="d9d9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">嘣。这告诉我们，如果一条短信包含“赢”这个词，那么这条短信有58%的概率是垃圾短信。</p><h1 id="b74d" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">结论和下一步措施</h1><p id="a4c2" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">在生产垃圾邮件检测系统中，我们需要对语料库中的每个单词进行上述计算，然后组合概率。</p><p id="0ba8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可能还想包括其他功能，如单词组合，消息长度，标点符号等。</p><p id="c281" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这会让这篇文章变得很长。</p><p id="7d39" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你感兴趣，这里有一篇PDF文章<a class="ae lq" href="http://cs.wellesley.edu/~anderson/writing/naive-bayes.pdf" rel="noopener ugc nofollow" target="_blank"/>，解释了组合多个单词结果的几种方法。</p><p id="4401" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我希望这给了你一些使用贝叶斯定理的洞察力和实践经验，即使我们只是触及了表面。</p></div></div>    
</body>
</html>