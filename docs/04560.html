<html>
<head>
<title>PEX — The secret sauce for the perfect PySpark deployment of AWS EMR workloads</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PEX——AWS EMR工作负载完美PySpark部署的秘方</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pex-the-secret-sauce-for-the-perfect-pyspark-deployment-of-aws-emr-workloads-9aef0d8fa3a5?source=collection_archive---------9-----------------------#2020-04-23">https://towardsdatascience.com/pex-the-secret-sauce-for-the-perfect-pyspark-deployment-of-aws-emr-workloads-9aef0d8fa3a5?source=collection_archive---------9-----------------------#2020-04-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2955" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何使用PEX加速PySpark应用程序在临时AWS EMR集群上的部署</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9c55574808a1b484b33874f526271d60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FMUAYUwXD2fxV7Mbb_KGmA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">[OC]</p></figure><p id="ee91" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在大数据和数据科学领域，Spark已经成为除深度学习之外的几乎所有事物的黄金标准:</p><ul class=""><li id="e5c4" class="lu lv it la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">用于数据湖的ELT取代了更传统的ETL范例</li><li id="1f09" class="lu lv it la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">用于高级分析的Spark SQL</li><li id="2d0f" class="lu lv it la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">一个用于数据科学的分布式批量计算框架，包括Spark ML、GraphX、GeoSpark等。</li><li id="5bf4" class="lu lv it la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">具有小批量流的近实时应用</li></ul><p id="1d31" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">虽然Scala Spark API在数据湖ELT工作负载和数据工程中发挥着重要作用，但数据科学和高级分析领域几乎完全是用Python编写的PySpark工作负载。大多数Spark工作负载都是在AWS EMR集群上执行的。一般的数据驱动型公司在数量同样惊人的短命EMR集群上轻松运行数百个每日Spark作业。</p><p id="a73b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">AWS Spot实例具有吸引力的价格点已经建立了在非常短暂的EMR集群上运行single Spark作业的范例。EMR提供短暂的计算资源，而S3为数据提供永久存储。使用由100% Spot实例组成的短暂EMR集群将这种模式推向极端是非常常见的，<strong class="la iu">神风特攻队风格</strong>。</p><p id="e9b8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这种短暂的PySpark集群模式只有<strong class="la iu">一大痛点</strong>:用Python包<strong class="la iu">引导EMR集群</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mi"><img src="../Images/89e7cf6786fb843c443dcf1d53861f67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lwj51jA4VsGJlVsVSJyKuQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">https://www.flickr.com/photos/janpersiel/27706588173<a class="ae mj" href="https://www.flickr.com/photos/janpersiel/27706588173" rel="noopener ugc nofollow" target="_blank">(ɔ)</a></p></figure><h1 id="b597" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">PySpark在电子病历上的应用:坏与丑</h1><p id="b15b" class="pw-post-body-paragraph ky kz it la b lb nc ju ld le nd jx lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">在EMR上运行PySpark应用程序非常复杂。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/43a7e02f90392382594b2ae9fcc74d62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MWFRoXcj_CmGFZeW-uwBJw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">[OC]</p></figure><p id="2ab1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于短暂的EMR，我们必须在每次运行PySpark应用程序之前，根据我们的应用程序需求引导我们的集群。这应该是我们的PySpark应用程序包的一个简单的pip安装。但是现实远非如此简单。</p><ol class=""><li id="01f0" class="lu lv it la b lb lc le lf lh lw ll lx lp ly lt ni ma mb mc bi translated">我们需要在EMR上安装和更新软件包，因为许多版本后面缺少默认安装。</li><li id="ccbb" class="lu lv it la b lb md le me lh mf ll mg lp mh lt ni ma mb mc bi translated">我们应该为我们的应用程序创建一个虚拟的Python环境，因为全局Python包会以奇怪的方式干扰。我们都去过那里。</li><li id="31ad" class="lu lv it la b lb md le me lh mf ll mg lp mh lt ni ma mb mc bi translated">我们需要用pip安装我们的PySpark应用程序和需求</li><li id="921c" class="lu lv it la b lb md le me lh mf ll mg lp mh lt ni ma mb mc bi translated">我们需要从S3复制资产，例如spark-submit的main.py脚本</li><li id="7f16" class="lu lv it la b lb md le me lh mf ll mg lp mh lt ni ma mb mc bi translated">最后，我们使用我们的<strong class="la iu">特定于应用程序的spark配置</strong>调用spark-submit来最终运行我们的工作负载</li></ol><p id="9127" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">这种EMR方法有一些难点:</strong></p><ol class=""><li id="1985" class="lu lv it la b lb lc le lf lh lw ll lx lp ly lt ni ma mb mc bi translated">虽然我们实际上并不运行任何真正的工作负载，但是引导过程是为集群时间付费的。这对大型集群来说尤其重要！</li><li id="f792" class="lu lv it la b lb md le me lh mf ll mg lp mh lt ni ma mb mc bi translated">我们必须维护和下载不属于Python应用程序包的资产，例如spark-submit main.py脚本</li><li id="e7a5" class="lu lv it la b lb md le me lh mf ll mg lp mh lt ni ma mb mc bi translated">我们必须独立于Python应用程序包为我们的作业维护特定于应用程序的Spark配置，我们将Python应用程序包作为参数传递给spark-submit脚本。这些通常分散在Jenkins管道或气流Dag中，增加了维护PySpark应用程序的不必要的复杂性。</li><li id="eed5" class="lu lv it la b lb md le me lh mf ll mg lp mh lt ni ma mb mc bi translated">打包和安装具有复杂依赖关系的Python应用程序会直接将您引向臭名昭著的依赖地狱。</li></ol><p id="d699" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">考虑到Python的流行程度，Python工具链远非理想，安装带有复杂依赖链和pip的包通常会导致众所周知的依赖地狱。不幸的是，pip缺少一个强大的依赖解析器。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/3c271e1ef1c18804146b2e892b627b97.png" data-original-src="https://miro.medium.com/v2/resize:fit:984/0*z9zi9dmnuBvJ2Fku"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">CC BY-NC 2.5，<a class="ae mj" href="https://xkcd.com/1987/" rel="noopener ugc nofollow" target="_blank">https://xkcd.com/1987/</a></p></figure><p id="cc42" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在商业数据科学团队中，通常还有第二层复杂性，即专有代码的<strong class="la iu">私有包索引</strong>。我打赌你的私人包裹索引很慢。因此，您的PySpark应用程序的常见EMR引导脚本可能如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/fa8375eaa1591286bfb81b6fe9a635b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ERqCbLgE175Hxt-3eTcZWw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">[OC]</p></figure><p id="0fb7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果运行PySpark应用程序像调用可执行文件一样简单<strong class="la iu">不是很好吗？无pip安装要求。没有主。py。没有火花-提交与火花内存配置搞乱詹金斯或气流。</strong></p><h1 id="21e5" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">解决方案:PEX</h1><p id="2d7b" class="pw-post-body-paragraph ky kz it la b lb nc ju ld le nd jx lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">PEX (Python可执行文件)是一种文件格式和相关工具，用于创建类似于virtualenv的通用Python环境虚拟化解决方案。PEX最初于2011年在Twitter上开发，用于将Python应用程序部署到生产中。PEX文件是<strong class="la iu">自包含的</strong> <strong class="la iu">可执行的</strong> Python虚拟环境。重点在于自包含和可执行性，这使得PEX文件非常适合应用程序部署到生产环境中。使用PEX文件，部署应用程序所需的唯一步骤是<strong class="la iu">复制文件</strong>。不需要安装pip，也不需要修改路径。</p><p id="5106" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在PEX的帮助下，在EMR上运行PySpark应用程序不再需要任何引导！</p><ul class=""><li id="e70b" class="lu lv it la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">PEX大大简化了PySpark应用程序的运行</li><li id="03c3" class="lu lv it la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">通过利用集群更早地运行我们的实际应用工作负载，而无需任何集群引导，从而节省资金。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/0760d75fec1bfbbeb8ac0abd779105a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*56kmxAsq7ZnmNLDUaM4xaQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">[OC]</p></figure><p id="5908" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要创建pex归档，您可以使用PEX实用程序。您可以简单地安装它</p><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="32ad" class="nr ml it nn b gy ns nt l nu nv">pip install pex</span></pre><p id="b733" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当您在新的Python虚拟环境中执行此操作时，您可以使用pex来打包自身。以下命令使用名为“pex”的控制台脚本创建包含pex和请求的pex文件。将创建的可执行文件保存到~/bin/pex，您可以在任何virtualenv内部或外部使用pex，就像您的路径上的任何其他可执行文件一样。</p><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="4a5d" class="nr ml it nn b gy ns nt l nu nv">pex pex requests -c pex -o ~/bin/pex</span></pre><p id="6576" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">PEX有一个复杂之处:可执行文件包含一个自包含的Python虚拟环境，但不是Python解释器本身:PEX可执行文件是依赖于平台的。目前，EMR在Linux上运行Python 3.6.10，你可以在Mac上开发。因此，通常最好使用Docker来创建可重复的结果。</p><p id="0cdc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">构建与EMR兼容的docker映像，在docker容器中创建您的PEX归档:</p><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="d339" class="nr ml it nn b gy ns nt l nu nv">FROM python:3.6-slim-buster</span><span id="2aa7" class="nr ml it nn b gy nw nt l nu nv">RUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \<br/>  git \<br/> &amp;&amp; rm -rf /var/lib/apt/lists/*</span><span id="ea09" class="nr ml it nn b gy nw nt l nu nv">RUN pip3 install pex</span><span id="7b5b" class="nr ml it nn b gy nw nt l nu nv">RUN mkdir /app<br/>WORKDIR /app</span><span id="4e0c" class="nr ml it nn b gy nw nt l nu nv">ENV PATH=/root/.local/bin:$PATH</span></pre><p id="110f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果您的组织使用私有包索引，例如Artifactory，那么PEX显示了另一个弱点:在编写时，它没有通过CLI公开请求库的参数，这意味着当直接使用PEX解决包依赖关系时，我们不能为pip设置自定义网络超时。解决方法是使用舵手室。以下脚本可用于使用轮罩和带有自定义超时的私有包索引来构建pex归档:</p><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="ccb9" class="nr ml it nn b gy ns nt l nu nv">#!/usr/bin/env bash</span><span id="6d43" class="nr ml it nn b gy nw nt l nu nv">pip3 download -r requirements.txt \<br/>    --dest ./build/wheelhouse \<br/>    --extra-index-url <a class="ae mj" href="https://private.registry.dev/pypi/simple" rel="noopener ugc nofollow" target="_blank">https://private.registry.dev/pypi/simple</a> \<br/>    --trusted-host private.registry.dev \<br/>    --timeout 120</span><span id="dd07" class="nr ml it nn b gy nw nt l nu nv">pex . -r requirements.txt \<br/>    -o ./dist/my_application.pex \<br/>    --platform manylinux2014-x86_64-cp-36-m \<br/>    --no-index \<br/>    -f ./build/wheelhouse</span></pre><h1 id="6e8e" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">打包PySpark应用程序</h1><p id="89d8" class="pw-post-body-paragraph ky kz it la b lb nc ju ld le nd jx lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">我们的目标是打包一个完全自包含的PySpark应用程序，并在不需要spark-submit的情况下运行它。因此，我们的Python主函数必须创建一个SparkSession:</p><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="f93d" class="nr ml it nn b gy ns nt l nu nv">if __name__ == "__main__":</span><span id="21e7" class="nr ml it nn b gy nw nt l nu nv">pex_file = os.path.basename([path for path in sys.path if path.endswith(".pex")][0])<br/>    os.environ["PYSPARK_PYTHON"] = "./" + pex_file</span><span id="b490" class="nr ml it nn b gy nw nt l nu nv">spark = (<br/>        SparkSession.builder<br/>        .master("yarn")<br/>        .appName("my_spark_application")<br/>        .config("spark.submit.deployMode", "client")<br/>        .config("spark.yarn.dist.files", pex_file)<br/>        .config("spark.executorEnv.PEX_ROOT", "./.pex")<br/>        .config("spark.sql.shuffle.partitions", 4000)<br/>        .config("spark.executor.memory", "1G")<br/>        .enableHiveSupport()<br/>        .getOrCreate()<br/>    )</span></pre><p id="48b4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您可以将任何选项从您通常的spark-submit传递给SparkSession builder。</p><p id="c608" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这允许您在PEX可执行文件中执行PySpark应用程序，例如:</p><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="c2f0" class="nr ml it nn b gy ns nt l nu nv">./my_application.pex -m my_application.main</span></pre><h1 id="df50" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">执行PEX作为电子病历的一个步骤</h1><p id="24a8" class="pw-post-body-paragraph ky kz it la b lb nc ju ld le nd jx lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">最后一步是作为EMR步骤执行我们的pex应用程序。我们将使用脚本运行器和一个通用的瘦包装器作为一个步骤来执行PEX。</p><p id="31c8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">脚本运行程序调用我们的瘦包装器，该包装器从S3提取一个PEX文件，并使用我们可能需要的所有环境变量和命令行参数来执行它。下面的脚本是一个你可以使用的名为<strong class="la iu"> pex-executor.sh </strong>的瘦包装器。只需将它放在S3上，即可供您的EMR集群使用:</p><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="1ae6" class="nr ml it nn b gy ns nt l nu nv">#!/bin/bash<br/># Author: Jan Teichmann<br/># Version: 2020-02-10<br/># Wrapper to execute a PEX archive via an EMR Step<br/># Step type: Custom JAR<br/># JAR location: s3://eu-west-1.elasticmapreduce/libs/script-runner/script-runner.jar<br/># Arguments:<br/>#      s3://.../pex-executer.sh <br/>#      s3://.../some-etl-job.pex <br/>#      HADOOP_HOME=/usr/lib/hadoop <br/>#      SPARK_HOME=/usr/lib/spark <br/>#      ./some-etl-job.pex -m package.module -fromdate=2020-04-20 -todate=2020-04-22</span><span id="ded7" class="nr ml it nn b gy nw nt l nu nv">aws s3 cp $1 .<br/>chmod +x $(basename -- $1);</span><span id="dced" class="nr ml it nn b gy nw nt l nu nv">shift;<br/>eval "$@"</span></pre><p id="be7d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，您可以提交EMR步骤，例如通过Airflow的EmrAddStepsOperator:</p><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="83de" class="nr ml it nn b gy ns nt l nu nv">EmrAddStepsOperator(<br/>    task_id="my_application",<br/>    job_flow_id="my_emr_cluster_id",<br/>    steps=[<br/>        {<br/>            "ActionOnFailure": "CONTINUE",<br/>            "Name": "Run my_application Step",<br/>            "HadoopJarStep": {<br/>                "Args": [<br/>                    "s3://.../pex-executer.sh",<br/>                    "s3://.../my_application.pex",<br/>                    "HADOOP_HOME=/usr/lib/hadoop",<br/>                    "SPARK_HOME=/usr/lib/spark",<br/>                    "./my_application.pex",<br/>                    "-m",<br/>                    "my_pyspark_application.main",<br/>                    "-parameter1",<br/>                    "value1" <br/>                ],<br/>                "Jar": "s3://eu-west-1.elasticmapreduce/libs/script-runner/script-runner.jar",<br/>            },<br/>        }<br/>    ],<br/>    aws_conn_id="aws_default",<br/>    dag=dag,<br/>)</span></pre><p id="b13d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如您在上面看到的，我们首先传递两条s3路径。第一个是我们的瘦包装器pex-executor.sh，它将由AWS script-runner.jar执行。pex-executor脚本将依次下载应用程序pex可执行文件。</p><p id="5998" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们还定义了EMR需要的两个环境变量HADOOP_HOME和SPARK_HOME。您可以根据需要添加任何额外的环境变量。</p><p id="c0b1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后，我们传递可执行文件的名称，并传递Python应用程序的任何CLI参数。</p><p id="b077" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">或者通过EMR控制台:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/328b37b317f870b8ffbed6677051b673.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0deI4x4ZE7_7onF0"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">[OC]</p></figure><h1 id="55cf" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">摘要</h1><p id="a152" class="pw-post-body-paragraph ky kz it la b lb nc ju ld le nd jx lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">PEX允许我们将PySpark应用程序作为完全自包含的可执行文件运行，就像我们使用Scala API时，带有uber-JAR或fat-JAR的Spark应用程序允许的那样。</p><p id="6e8d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这极大地<strong class="la iu">简化了</strong>使用PySpark和<strong class="la iu">的短暂EMR集群，节省了时间</strong>和<strong class="la iu">节省了资金</strong>，因为我们不必引导集群。</p><p id="422d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">将pex可执行文件的创建打包到一个Jenkins管道中，您就拥有了一个强大的DevOps模式来构建包并将它们上传到S3进行部署。</p><p id="65dc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后，您可以安排您的PySpark应用程序，例如使用气流。因为您的PEX应用程序是完全自包含的，所以您将能够在Airflow中创建非常通用的Dag，而不会导致任何应用程序逻辑和配置分散在多个平台和存储库中。</p><blockquote class="ny"><p id="9c49" class="nz oa it bd ob oc od oe of og oh lt dk translated">简单是最高级的复杂</p></blockquote></div><div class="ab cl oi oj hx ok" role="separator"><span class="ol bw bk om on oo"/><span class="ol bw bk om on oo"/><span class="ol bw bk om on"/></div><div class="im in io ip iq"><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/b40fa03f9762d1ec3c427365a4c45786.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7HvEyV_ETBrk5E7jVL971A.png"/></div></div></figure><p id="43ed" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Jan是公司数据转型方面的成功思想领袖和顾问，拥有将数据科学大规模应用于商业生产的记录。他最近被dataIQ评为英国100位最具影响力的数据和分析从业者之一。</p><p id="4db2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">在领英上连接:</strong><a class="ae mj" href="https://www.linkedin.com/in/janteichmann/" rel="noopener ugc nofollow" target="_blank">T5】https://www.linkedin.com/in/janteichmann/</a></p><p id="d479" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">阅读其他文章:</strong><a class="ae mj" href="https://medium.com/@jan.teichmann" rel="noopener"><strong class="la iu">https://medium.com/@jan.teichmann</strong></a></p></div></div>    
</body>
</html>