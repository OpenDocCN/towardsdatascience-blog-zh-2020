<html>
<head>
<title>Introduction to regression analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">回归分析导论</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introduction-to-regression-analysis-9151d8ac14b3?source=collection_archive---------10-----------------------#2020-05-09">https://towardsdatascience.com/introduction-to-regression-analysis-9151d8ac14b3?source=collection_archive---------10-----------------------#2020-05-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9113" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">本文介绍了回归分析的基础，使用加州住房数据集作为一个说明性的例子</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/8d717c05fcf90447e5a983683f14b640.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bEZ7yDTVHLWYMTMB"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://www.pexels.com/@goumbik" rel="noopener ugc nofollow" target="_blank">卢卡斯</a>在<a class="ae ky" href="https://www.pexels.com/photo/chart-close-up-data-desk-590022/" rel="noopener ugc nofollow" target="_blank">像素</a>上拍摄</p></figure><p id="30ff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">机器学习任务可以分为以下四类:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/0b3a5e875e29d7d471542d177e4ebe64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vJsXYNlr_GyFc2qrpZGsvA.png"/></div></div></figure><p id="46c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文着重于回归分析。具体来说，本文描述了这项任务的基础，并在<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html" rel="noopener ugc nofollow" target="_blank">加州住房数据集</a>上阐释了其主要概念。</p><p id="98b7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇文章的结构如下:</p><ol class=""><li id="c8c7" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated"><strong class="lb iu">什么是回归？</strong></li><li id="3430" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated"><strong class="lb iu">回归和分类的区别</strong></li><li id="9ee9" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated"><strong class="lb iu">回归的类型</strong>:由于回归模型数量众多，我们介绍最常见的几种。</li><li id="389c" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated"><strong class="lb iu">如何选择正确的型号</strong></li><li id="f88e" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated"><strong class="lb iu">线性模型</strong>:在所有可用的回归模型中，本文重点介绍线性模型的理论和假设。</li><li id="7b2d" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated"><strong class="lb iu">线性模型示例</strong>:用线性回归模型分析加州住房数据集。</li><li id="97b5" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated"><strong class="lb iu">其他回归分析示例</strong></li></ol><h1 id="f0af" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">1.什么是回归？</h1><p id="76db" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Regression_analysis" rel="noopener ugc nofollow" target="_blank">回归分析</a>在维基百科中的定义是:</p><blockquote class="nh ni nj"><p id="18d1" class="kz la nk lb b lc ld ju le lf lg jx lh nl lj lk ll nm ln lo lp nn lr ls lt lu im bi translated">在<a class="ae ky" href="https://en.wikipedia.org/wiki/Statistical_model" rel="noopener ugc nofollow" target="_blank">统计建模</a>中，<strong class="lb iu">回归分析</strong>是一组统计过程，用于<a class="ae ky" href="https://en.wikipedia.org/wiki/Estimation_theory" rel="noopener ugc nofollow" target="_blank">估计</a>一个<a class="ae ky" href="https://en.wikipedia.org/wiki/Dependent_variable" rel="noopener ugc nofollow" target="_blank">因变量</a>(通常称为“结果变量”)与一个或多个<a class="ae ky" href="https://en.wikipedia.org/wiki/Independent_variable" rel="noopener ugc nofollow" target="_blank">自变量</a>(通常称为“预测值”、“协变量”或“特征”)之间的关系。</p></blockquote><p id="8bba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您经常听到的与回归分析相关的术语是:</p><ul class=""><li id="de90" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu no mc md me bi translated"><strong class="lb iu">因变量</strong>或<strong class="lb iu">目标变量:</strong>要预测的变量。</li><li id="ae2f" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu no mc md me bi translated"><strong class="lb iu">自变量</strong>或<strong class="lb iu">预测变量:</strong>估计因变量的变量。</li><li id="7b6b" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu no mc md me bi translated"><strong class="lb iu">异常值:</strong>与其他观察值显著不同的观察值。应该避免，因为它可能会妨碍结果。</li><li id="63aa" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu no mc md me bi translated"><a class="ae ky" href="https://www.statisticssolutions.com/multicollinearity/" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">多重共线性</strong> </a> <strong class="lb iu"> : </strong>两个或两个以上自变量高度线性相关的情况。</li><li id="761e" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu no mc md me bi translated"><a class="ae ky" href="https://www.statisticshowto.com/homoscedasticity/" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">同质性</strong> </a> <strong class="lb iu"> </strong>或<strong class="lb iu">方差同质性:</strong>误差项在自变量的所有值上都相同的情况。</li></ul><p id="f464" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">回归分析主要用于两个不同的目的。一是广泛用于<a class="ae ky" href="https://en.wikipedia.org/wiki/Prediction" rel="noopener ugc nofollow" target="_blank">预测</a>和<a class="ae ky" href="https://en.wikipedia.org/wiki/Forecasting" rel="noopener ugc nofollow" target="_blank">预测</a>，与机器学习领域重叠。其次，它还用于推断自变量和因变量之间的<a class="ae ky" href="https://en.wikipedia.org/wiki/Causality" rel="noopener ugc nofollow" target="_blank">因果关系</a>。</p><h1 id="fbd3" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">2.回归和分类的区别</h1><p id="d00e" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">回归和分类都是<a class="ae ky" href="https://en.wikipedia.org/wiki/Supervised_learning" rel="noopener ugc nofollow" target="_blank">有监督的学习方法</a>，也就是说它们使用带标签的训练数据来训练自己的模型，进行预测。因此，在机器学习中，这两项任务通常被归为同一组。</p><p id="4234" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它们之间的主要区别是输出变量。在回归中，输出是数字或连续的，而在分类中，输出是分类的或离散的。这定义了分类和回归评估预测的方式:</p><ul class=""><li id="30cb" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu no mc md me bi translated">分类预测可以使用准确性进行评估，而回归预测则不能。</li><li id="43ef" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu no mc md me bi translated">回归预测可以使用均方根误差进行评估，而分类预测则不能。</li></ul><p id="686c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面的<a class="ae ky" href="https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank">环节</a>在训练分类和回归模型的时候都收集了一些损失函数。</p><p id="b50f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">分类和回归算法之间有一些重叠；例如:</p><ul class=""><li id="8194" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu no mc md me bi translated">分类算法可以预测连续值，但是该连续值是类别标签的概率形式。</li><li id="ae5f" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu no mc md me bi translated">回归算法可以预测离散值，但是该离散值是整数形式的。</li></ul><p id="5e9f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有些算法只需稍加修改即可用于分类和回归，如决策树和人工神经网络。对于这两种问题类型，其他一些算法更难以实现，例如用于回归预测建模的线性回归和用于分类预测建模的逻辑回归[ <a class="ae ky" href="https://machinelearningmastery.com/classification-versus-regression-in-machine-learning/" rel="noopener ugc nofollow" target="_blank"> 1 </a> ]。</p><h1 id="091c" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">3.回归的类型</h1><p id="59ad" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">数据科学和机器学习中使用了各种类型的回归。每种类型在不同的情况下都有自己的重要性，但核心是，所有的回归方法都分析自变量对因变量的影响。这里我们提到一些重要的回归类型:</p><ol class=""><li id="b097" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated"><a class="ae ky" href="https://www.listendata.com/2018/03/regression-analysis.html#Linear-Regression" rel="noopener ugc nofollow" target="_blank">线性回归</a></li><li id="419a" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated"><a class="ae ky" href="https://www.listendata.com/2018/03/regression-analysis.html#Polynomial-Regression" rel="noopener ugc nofollow" target="_blank">多项式回归</a></li><li id="3fc8" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated"><a class="ae ky" href="https://www.listendata.com/2018/03/regression-analysis.html#Support-Vector-Regression" rel="noopener ugc nofollow" target="_blank">支持向量回归</a></li><li id="a718" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated"><a class="ae ky" href="https://www.listendata.com/2015/04/decision-tree-in-r.html" rel="noopener ugc nofollow" target="_blank">决策树回归</a></li><li id="4bf6" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated"><a class="ae ky" href="https://www.listendata.com/2014/11/random-forest-with-r.html" rel="noopener ugc nofollow" target="_blank">随机森林回归</a></li><li id="c38e" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated"><a class="ae ky" href="https://www.listendata.com/2018/03/regression-analysis.html#Ridge-Regression" rel="noopener ugc nofollow" target="_blank">岭回归</a></li><li id="e09e" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated"><a class="ae ky" href="https://www.listendata.com/2018/03/regression-analysis.html#Lasso-Regression" rel="noopener ugc nofollow" target="_blank">套索回归</a></li><li id="8a59" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated"><a class="ae ky" href="https://www.listendata.com/2018/03/regression-analysis.html#Logistic-Regression" rel="noopener ugc nofollow" target="_blank">逻辑回归</a></li></ol><p id="7aed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">详细解释每一个都需要几篇文章，因此，如果读者对回归变量的进一步信息感兴趣，我推荐阅读[ <a class="ae ky" href="https://www.analyticsvidhya.com/blog/2015/08/comprehensive-guide-regression/" rel="noopener ugc nofollow" target="_blank"> 2 </a>、<a class="ae ky" href="https://www.listendata.com/2018/03/regression-analysis.html" rel="noopener ugc nofollow" target="_blank"> 3 </a>、<a class="ae ky" href="https://www.javatpoint.com/regression-analysis-in-machine-learning" rel="noopener ugc nofollow" target="_blank"> 4 </a> ]。</p><h1 id="114c" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">4.如何选择正确的回归模型？</h1><p id="8fbb" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">在我看来，这是最困难的任务，不仅在回归方面，而且在一般的机器学习方面。</p><p id="75a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">尽管我认为经验可能是这个问题的正确答案，一些建议是:</p><ol class=""><li id="27b2" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">线性模型是最常见和最简单的使用方法。如果你有一个连续的因变量，线性回归可能是你应该考虑的第一种类型。</li><li id="b1d9" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">如果因变量是连续的，并且您的模型具有共线性或许多自变量，您可以尝试，例如，岭或套索模型。您可以根据<a class="ae ky" href="https://www.investopedia.com/ask/answers/012615/whats-difference-between-rsquared-and-adjusted-rsquared.asp" rel="noopener ugc nofollow" target="_blank"> R方</a>或<a class="ae ky" href="https://en.wikipedia.org/wiki/Root-mean-square_deviation" rel="noopener ugc nofollow" target="_blank"> RMSE </a>选择最终型号。</li><li id="94ed" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">如果您正在处理分类数据，可以尝试泊松、拟泊松和负二项式回归。</li><li id="9e2f" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">为了避免过度拟合，我们可以使用交叉验证方法来评估模型。脊、套索和弹性网回归技术可用于纠正过度拟合问题。</li><li id="9431" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">当你有一个非线性模型时，尝试支持向量回归。</li></ol><h1 id="847c" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">5.线性模型</h1><p id="ed3f" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">回归分析中最常见的模型是<a class="ae ky" href="https://en.wikipedia.org/wiki/Linear_regression" rel="noopener ugc nofollow" target="_blank">线性回归</a>。这个模型通过拟合一个线性方程找到自变量和因变量之间的关系。拟合该回归线最常用的方法是使用<a class="ae ky" href="https://en.wikipedia.org/wiki/Least_squares" rel="noopener ugc nofollow" target="_blank">最小二乘法</a>，它计算出最佳拟合线，使每个数据点到该线的垂直偏差平方和最小。</p><p id="e72f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">建立线性回归模型只是工作的一半。为了在实践中实际可用，模型应符合线性回归的假设[ <a class="ae ky" href="http://r-statistics.co/Assumptions-of-Linear-Regression.html" rel="noopener ugc nofollow" target="_blank"> 7 </a>，<a class="ae ky" href="http://www.ucdenver.edu/academics/colleges/PublicHealth/resourcesfor/Faculty/perraillon/perraillonteaching/Documents/week%207%20diagnosis.pdf" rel="noopener ugc nofollow" target="_blank"> 8 </a> ]:</p><ol class=""><li id="a895" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">参数呈线性。</li><li id="2291" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">样本在总体上具有代表性。</li><li id="30c9" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">独立变量的测量没有误差。</li><li id="35bd" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">观察值的数量必须大于自变量的数量。</li><li id="503c" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">独立变量中没有多重共线性</li><li id="3a92" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">残差的平均值为零。</li><li id="1058" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">残差正态性</li><li id="8fa9" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">独立变量和残差是不相关的</li><li id="83a6" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">残差的同方差性(残差的方差在整个观测中是常数)</li><li id="5af0" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">残差无自相关(特别适用于时间序列数据)。数学上，误差的<a class="ae ky" href="https://en.wikipedia.org/wiki/Covariance_matrix" rel="noopener ugc nofollow" target="_blank">方差-协方差矩阵</a>是<a class="ae ky" href="https://en.wikipedia.org/wiki/Diagonal_matrix" rel="noopener ugc nofollow" target="_blank">对角线</a>。</li></ol><p id="e9c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">很难满足所有这些假设，因此从业者开发了各种各样的方法来在现实世界中保持一些或所有这些理想的属性。下面的文章[ <a class="ae ky" rel="noopener" target="_blank" href="/linear-regression-and-its-assumptions-ef6e8db4904d"> 9 </a>，<a class="ae ky" rel="noopener" target="_blank" href="/model-assumptions-for-regression-problems-e4591af44901"> 10 </a>解释一些例子。</p><h1 id="cd64" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">6.线性模型示例</h1><p id="5b97" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">为了展示之前介绍的一些概念，我们在<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html" rel="noopener ugc nofollow" target="_blank">加州住房数据集</a>上实现了一个线性回归模型。下面是代码以及对每个块的简要说明。</p><p id="b58a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们导入所需的库。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="04ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们从<code class="fe nr ns nt nu b">scikit-learn</code>库中加载住房数据:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div></figure><pre class="kj kk kl km gt nv nu nw nx aw ny bi"><span id="6783" class="nz ml it nu b gy oa ob l oc od">dict_keys(['data', 'target', 'feature_names', 'DESCR'])</span></pre><p id="f591" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了了解更多的特性，我们打印了<code class="fe nr ns nt nu b">california_housing_dataset.DESCR</code>:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div></figure><pre class="kj kk kl km gt nv nu nw nx aw ny bi"><span id="3a32" class="nz ml it nu b gy oa ob l oc od">- MedInc        median income in block<br/>- HouseAge      median house age in block<br/>- AveRooms      average number of rooms<br/>- AveBedrms     average number of bedrooms<br/>- Population    block population<br/>- AveOccup      average house occupancy<br/>- Latitude      house block latitude<br/>- Longitude     house block longitude</span></pre><p id="9c84" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是八个独立变量，基于它们我们可以预测房子的价值。房子的价格由变量<code class="fe nr ns nt nu b">AveHouseVal</code>表示，它定义了我们的<strong class="lb iu">因变量。</strong></p><p id="aa4b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在使用<code class="fe nr ns nt nu b">pd.DataFrame</code>将数据加载到pandas数据帧中。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div></figure><h2 id="5328" class="nz ml it bd mm oe of dn mq og oh dp mu li oi oj mw lm ok ol my lq om on na oo bi translated">数据预处理</h2><p id="2b42" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">加载数据后，最好查看数据中是否有任何缺失值。我们使用<code class="fe nr ns nt nu b">isnull()</code>计算每个要素缺失值的数量(本数据集没有缺失值)。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/487a51078b8fc5528f2a47faf44ec456.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P9q-DqF0EJeyLOKmlhvtDA.png"/></div></div></figure><h2 id="5e13" class="nz ml it bd mm oe of dn mq og oh dp mu li oi oj mw lm ok ol my lq om on na oo bi translated">探索性数据分析</h2><p id="8cea" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">让我们首先根据<code class="fe nr ns nt nu b">Latitude</code>和<code class="fe nr ns nt nu b">Longitude</code>绘制目标变量<code class="fe nr ns nt nu b">AveHouseVal</code>的分布。该图像应该是美国加利福尼亚州的绘图。据观察，靠近海边的房子比其他地方要贵。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/0e91932e2fb6565406c38f7402ed2174.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VeNneKojlbjwRSO1M75zAg.png"/></div></div></figure><p id="9c65" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们创建一个相关矩阵来度量变量之间的线性关系。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/713aa4469e18c879ccb6e2951e1a4eb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jyk5MGt849wlHuBx7sa-rw.png"/></div></div></figure><h2 id="79ed" class="nz ml it bd mm oe of dn mq og oh dp mu li oi oj mw lm ok ol my lq om on na oo bi translated">观察结果:</h2><ul class=""><li id="4c90" class="lw lx it lb b lc nc lf nd li os lm ot lq ou lu no mc md me bi translated">为了拟合线性回归模型，我们选择那些与我们的因变量<code class="fe nr ns nt nu b">AveHouseVal</code>高度相关的特征。通过查看相关矩阵，我们可以看到<code class="fe nr ns nt nu b">MediaInc</code>与<code class="fe nr ns nt nu b">AverageHouseVal</code> (0.69)有很强的正相关性。另外两个相关性最高的变量是<code class="fe nr ns nt nu b">HouseAve</code>和<code class="fe nr ns nt nu b">AveRooms</code>。</li><li id="8ce0" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu no mc md me bi translated">为线性回归模型选择要素时，重要的一点是检查多重共线性。例如，特征<code class="fe nr ns nt nu b">Latitude</code>和<code class="fe nr ns nt nu b">Longitude</code>具有0.92的相关性，所以我们不应该在我们的回归模型中同时包括它们。由于变量<code class="fe nr ns nt nu b">MediaInc</code>、<code class="fe nr ns nt nu b">HouseAve</code>和<code class="fe nr ns nt nu b">AveRooms</code>之间的相关性不高，我们考虑将这三个变量用于我们的回归模型。</li></ul><h2 id="3c1e" class="nz ml it bd mm oe of dn mq og oh dp mu li oi oj mw lm ok ol my lq om on na oo bi translated">训练和测试模型</h2><p id="b8a1" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">我们使用scikit-learn的<code class="fe nr ns nt nu b">LinearRegression</code>在训练集和测试集上训练我们的模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div></figure><h2 id="4b27" class="nz ml it bd mm oe of dn mq og oh dp mu li oi oj mw lm ok ol my lq om on na oo bi translated">残差的分布:</h2><p id="0da7" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">让我们打印残差的分布，以验证线性模型的假设。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/403d1c66fc2a0badbaeecbb7613e1190.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b7kEk_KOOT6ixPsJi--yBw.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ow"><img src="../Images/f2ed9fa3159b58dd4338a2c94c3bc53a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kq3TGueXz2rLYxliOZ4ERw.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/f85429388ece2c88e67af54641807f8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HmkI-4TO8LPinKuXTOAj0A.png"/></div></div></figure><h2 id="c699" class="nz ml it bd mm oe of dn mq og oh dp mu li oi oj mw lm ok ol my lq om on na oo bi translated">假设的验证:</h2><ol class=""><li id="dcf4" class="lw lx it lb b lc nc lf nd li os lm ot lq ou lu mb mc md me bi translated">线性输入参数(<em class="nk">正常</em>)</li><li id="1017" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">样本代表总体人口(<em class="nk">假设</em>)</li><li id="a474" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">自变量被无误差地测量(<em class="nk">假设</em>)</li><li id="6f4f" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">观察值的数量必须大于独立变量的数量(<em class="nk">好的</em>)</li><li id="089f" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">独立变量内无多重共线性(<em class="nk">适用于研究变量</em>)</li><li id="0769" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">残差的平均值为零(<em class="nk">好的</em>)</li><li id="75a9" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">残差的正态性(<em class="nk">否</em></li><li id="6cc7" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">独立变量和残差不相关(<em class="nk">未检查</em>)</li><li id="6529" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">残差的同方差性(残差的方差在整个观测中是常数)(<em class="nk">否</em>)</li><li id="de7a" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">残差无自相关(特别适用于时间序列数据)。数学上，误差的<a class="ae ky" href="https://en.wikipedia.org/wiki/Covariance_matrix" rel="noopener ugc nofollow" target="_blank">方差-协方差矩阵</a>是<a class="ae ky" href="https://en.wikipedia.org/wiki/Diagonal_matrix" rel="noopener ugc nofollow" target="_blank">对角线</a> ( <em class="nk">未检查</em>)</li></ol><p id="ea00" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在研究这个数据集时，线性回归模型不是最好的模型，所以我们将在以后的文章中探讨其他模型。</p><p id="b007" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作为提示，这里有一个关于如何继续的好的<a class="ae ky" href="https://www.researchgate.net/post/Why_do_the_residuals_need_to_be_normal_when_carrying_out_multi_level_modeling" rel="noopener ugc nofollow" target="_blank">链接</a>:</p><blockquote class="nh ni nj"><p id="1992" class="kz la nk lb b lc ld ju le lf lg jx lh nl lj lk ll nm ln lo lp nn lr ls lt lu im bi translated">残差和异方差的非正态性的一个大问题是，模型中的误差量在观测数据的整个范围内并不一致。这意味着他们的预测能力在整个因变量范围内是不一样的。转换因变量有助于纠正这一点，但会给解释带来困难。如果平方根变换没有完全归一化您的数据，您还可以尝试逆变换。转换的强度趋向于从1。对数，2。平方根，3。反向(1/x)。</p></blockquote><h1 id="d39c" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">7.其他回归分析示例</h1><p id="1f7a" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">如果读者感兴趣，我建议尝试以下数据集:</p><ul class=""><li id="3c27" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu no mc md me bi translated"><a class="ae ky" href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques" rel="noopener ugc nofollow" target="_blank">房价:高级回归技术</a> (Kaggle竞赛)</li><li id="1209" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu no mc md me bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html" rel="noopener ugc nofollow" target="_blank">糖尿病数据集</a> (Scikit-learn)</li><li id="0da3" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu no mc md me bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html" rel="noopener ugc nofollow" target="_blank">波斯顿住房数据集</a> (Scikit-learn)</li></ul><p id="025a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">关于波士顿住房数据集，我推荐阅读这篇<a class="ae ky" rel="noopener" target="_blank" href="/linear-regression-on-boston-housing-dataset-f409b7e4a155">其他文章</a>。</p><p id="a588" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，在这个<a class="ae ky" href="https://www.kaggle.com/rtatman/datasets-for-regression-analysis" rel="noopener ugc nofollow" target="_blank">网络链接</a>中，有一些主题相关的数据集的集合，这些数据集适用于不同类型的回归分析。</p><p id="08ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，许多数据集可以在以下位置找到:</p><ul class=""><li id="3ac1" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu no mc md me bi translated"><a class="ae ky" href="https://www.kaggle.com/datasets" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/datasets</a></li><li id="b447" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu no mc md me bi translated"><a class="ae ky" href="https://toolbox.google.com/datasetsearch" rel="noopener ugc nofollow" target="_blank">https://toolbox.google.com/datasetsearch</a></li><li id="d068" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu no mc md me bi translated"><a class="ae ky" href="https://archive.ics.uci.edu/ml/datasets.html" rel="noopener ugc nofollow" target="_blank">https://archive.ics.uci.edu/ml/datasets.html</a></li></ul><p id="3091" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢您的阅读！！</p></div><div class="ab cl oy oz hx pa" role="separator"><span class="pb bw bk pc pd pe"/><span class="pb bw bk pc pd pe"/><span class="pb bw bk pc pd"/></div><div class="im in io ip iq"><p id="aac6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="nk">如果你喜欢这个帖子，请考虑</em> </strong> <a class="ae ky" href="https://javiferfer.medium.com/membership" rel="noopener"> <strong class="lb iu"> <em class="nk">订阅</em> </strong> </a> <strong class="lb iu"> <em class="nk">。你将获得我所有的内容+所有其他来自牛逼创作者的文章！</em>T29】</strong></p></div><div class="ab cl oy oz hx pa" role="separator"><span class="pb bw bk pc pd pe"/><span class="pb bw bk pc pd pe"/><span class="pb bw bk pc pd"/></div><div class="im in io ip iq"><h1 id="8d0a" class="mk ml it bd mm mn pf mp mq mr pg mt mu jz ph ka mw kc pi kd my kf pj kg na nb bi translated">参考</h1><p id="8f63" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">[1]机器学习精通，<a class="ae ky" href="https://machinelearningmastery.com/classification-versus-regression-in-machine-learning/" rel="noopener ugc nofollow" target="_blank">机器学习中分类和回归的区别</a></p><p id="e7a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[2] Analytics Vidhya，<a class="ae ky" href="https://www.analyticsvidhya.com/blog/2015/08/comprehensive-guide-regression/" rel="noopener ugc nofollow" target="_blank">你应该知道的7个回归技巧！</a></p><p id="9286" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[3] ListenData，<a class="ae ky" href="https://www.listendata.com/2018/03/regression-analysis.html" rel="noopener ugc nofollow" target="_blank">数据科学中的15种回归类型</a></p><p id="d81a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[4]Java point，<a class="ae ky" href="https://www.javatpoint.com/regression-analysis-in-machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习中的回归分析</a></p><p id="8ef1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[5] ListenData，<a class="ae ky" href="https://www.listendata.com/2018/03/regression-analysis.html" rel="noopener ugc nofollow" target="_blank">如何选择正确的回归模型？</a></p><p id="74a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[6]吉姆统计，<a class="ae ky" href="https://statisticsbyjim.com/regression/choosing-regression-analysis/" rel="noopener ugc nofollow" target="_blank">选择回归分析的正确类型</a></p><p id="93dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[7] R统计，<a class="ae ky" href="http://r-statistics.co/Assumptions-of-Linear-Regression.html" rel="noopener ugc nofollow" target="_blank">线性回归的假设</a></p><p id="2851" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[8]科罗拉多大学，<a class="ae ky" href="http://www.ucdenver.edu/academics/colleges/PublicHealth/resourcesfor/Faculty/perraillon/perraillonteaching/Documents/week%207%20diagnosis.pdf" rel="noopener ugc nofollow" target="_blank">线性模型假设和诊断</a></p><p id="5860" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[9]中等，<a class="ae ky" rel="noopener" target="_blank" href="/linear-regression-and-its-assumptions-ef6e8db4904d">线性回归及其假设</a></p><p id="3db4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[10]中等，<a class="ae ky" rel="noopener" target="_blank" href="/model-assumptions-for-regression-problems-e4591af44901">如何解决你的下一个回归问题</a></p></div></div>    
</body>
</html>