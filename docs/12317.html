<html>
<head>
<title>PyTorch: Scene Text Detection and Recognition by CRAFT and a Four-Stage Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">py torch:CRAFT 和四阶段网络的场景文本检测和识别</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pytorch-scene-text-detection-and-recognition-by-craft-and-a-four-stage-network-ec814d39db05?source=collection_archive---------5-----------------------#2020-08-25">https://towardsdatascience.com/pytorch-scene-text-detection-and-recognition-by-craft-and-a-four-stage-network-ec814d39db05?source=collection_archive---------5-----------------------#2020-08-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c39e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用 Python 实现成熟的文本检测和识别管道</h2></div><p id="d180" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">疫情已经把我们锁在家里好几个月了。但是请记住，当生活正常的时候，我们会去购物，和朋友出去玩，看电影，在购物中心享受美食！</p><p id="0d2a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">还有，你还记得每家商店都有独特的奇特的写法吗？像古驰、西尔斯、Pantaloons 和 Lifestyle 这样的流行品牌在他们的标志中使用弯曲或圆形字体。虽然所有这些都吸引了客户，但它确实对执行文本检测和识别的深度学习(DL)模型构成了挑战。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/9d77a9911126981361fa737e0373c48e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1l2096WBWr-RPN5o"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">照片由泰勒·辛普森在 Unsplash 上拍摄</p></figure><p id="21ac" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当你阅读横幅上的文字时，你会做什么？你的眼睛首先检测文本的存在，找出每个字符的位置，然后你识别这些字符。这也正是 DL 模型需要做的！</p><p id="47eb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最近，OCR 已经成为深度学习中的一个热门话题，其中每个新的架构都在尽力超越其他架构。</p><p id="b205" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">广受欢迎的基于深度学习的 OCR 模块，Tesseract 在文档等结构化文本上表现出色，但在花式字体的弯曲、不规则形状的文本上表现不佳。</p><p id="9eb7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">幸运的是，我们有 Clova AI 的这些令人惊叹的网络，它们在现实世界中出现的各种文本外观上胜过宇宙魔方。在这篇博客中，我们将简要讨论这些架构，并学习如何集成它们。</p><h1 id="6547" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">用 CRAFT 进行文本检测</h1><p id="63a3" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated"><strong class="kk iu">场景文本检测</strong>是一项在复杂背景中检测文本区域并用包围盒标记它们的任务。</p><p id="d585" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">于 2019 年提出的<strong class="kk iu"> CRAFT:用于文本检测的字符区域意识</strong>的主要目标是定位单个字符区域，并将检测到的字符链接到文本实例。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/d40b809ec173a3734322b5083d500a20.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/format:webp/1*41V2AiI3_RjSsp_j02ieYA.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">在<a class="ae ms" href="https://arxiv.org/pdf/1904.01941.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>中给出的工艺网络</p></figure><p id="bb4f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">CRAFT 采用基于 VGG-16 的全卷积网络架构作为主干。简而言之，VGG16 本质上是一种特征提取架构，用于将网络输入编码为某种特征表示。工艺网的解码段类似于 UNet。它跳过了聚合低级功能连接。</p><p id="acfc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">CRAFT 为每个角色预测了两个分数:</p><ul class=""><li id="8dbe" class="mt mu it kk b kl km ko kp kr mv kv mw kz mx ld my mz na nb bi translated"><strong class="kk iu">区域评分:</strong>顾名思义，给出了人物所在的区域。它将角色本地化。</li><li id="3b8b" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated"><strong class="kk iu">亲和力得分:</strong>‘亲和力’是一种物质倾向于与另一种物质结合的程度。因此，相似性分数将字符合并成单个实例(一个单词)。</li></ul><p id="02e4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">CRAFT 生成两个地图作为输出:区域级别地图和亲缘关系地图。<br/>让我们通过一个例子来理解它们的含义:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/8382b2411ea7a0d5acef569a6a86d343.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*XnWFozG9sOWfyWLMFNiaoA.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">输入图像</p></figure><p id="a39c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">人物出现的区域在区域图中标记出来:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/7dec14a75d4728b8fced8279841cd7b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/format:webp/1*CnZ4NQNmwT7aLNLTYwoF0A.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">区域地图</p></figure><p id="dca5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">亲和度图是相关字符的图像化表示。红色象征着人物有很高的亲和力，必须合并成一个词:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/06bf83289a2abda57dc65da95c4e2d88.png" data-original-src="https://miro.medium.com/v2/resize:fit:866/format:webp/1*jMr3Xqw5WJ936ihwvbkPXA.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">相似性地图</p></figure><p id="cd1a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，结合相关度和区域分数来给出每个单词的包围盒。坐标的顺序是:<br/>(左上)，(右上)(右下)，(左下)，其中每个坐标是一个(x，y)对。</p><p id="cafa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为什么不遵循四点格式？<br/>查看下图:你能把“爱”仅仅局限在 4 种价值观中吗？</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/c7eebdefe2a0bf4fada042dc3ca419d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:554/format:webp/1*S8wILKmKgbsDB5NJ1C7Xxw.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">布鲁诺·菲格雷多在 Unsplash 上拍摄的照片</p></figure><p id="5a2a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">CRAFT 是多语言的，这意味着它可以检测任何脚本编写的文本，而不仅仅是拉丁文！自己去看看吧:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/2421cecdd31ffc941f4fe742429a3360.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*jfizAErGhq9V-pSeAmiYWA.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">作者照片:红色边框</p></figure><h1 id="5dd9" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated"><strong class="ak">文本识别:F </strong>我们的舞台场景文本识别框架</h1><p id="27a6" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">2019 年，Clova AI 发表了一篇关于与现有场景文本识别(STR)数据集不一致的研究论文，并提出了一个大多数现有 STR 模型都适合的统一框架。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nm"><img src="../Images/4f8e3afad05b4e3db0ad844639db4684.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8e8ohcWtvACPyjVENWaGFQ.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated"><a class="ae ms" href="https://arxiv.org/pdf/1904.01906.pdf" rel="noopener ugc nofollow" target="_blank">网络提出的四个阶段</a></p></figure><p id="7a44" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们来讨论这四个阶段中的每一个:</p><ol class=""><li id="933c" class="mt mu it kk b kl km ko kp kr mv kv mw kz mx ld nn mz na nb bi translated"><strong class="kk iu">变换:</strong>记住我们处理的是风景文字，是任意形状的，有曲线的。如果我们直接执行特征提取，还需要学习输入文本的几何形状，这是特征提取模块的额外工作。因此，STR 网络应用薄板样条(TPS)转换，并将输入文本规范化为矩形。</li><li id="7efd" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld nn mz na nb bi translated"><strong class="kk iu">特征提取:</strong>将变换后的图像映射到一组与字符识别相关的特征。字体、颜色、大小和背景被删除。作者在不同的主干网上进行了实验，即 ResNet、VGG 和 RCNN。</li><li id="6175" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld nn mz na nb bi translated"><strong class="kk iu">序列建模:</strong>如果我写‘ba _ ’,你很有可能会猜测像‘d’，‘g’，‘t’这样的字母可能会填充空白，而不是‘u’，‘p’。我们如何教会网络捕捉上下文信息？比尔斯特姆斯！但是，BiLSTMs 占用内存，因此可以根据用户需要选择或取消选择该阶段。</li><li id="7ed3" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld nn mz na nb bi translated"><strong class="kk iu">预测:</strong>这个阶段从图像的识别特征中估计输出字符序列。</li></ol><p id="88ad" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">作者进行了几个实验。他们为每个阶段选择了不同的网络。下表总结了精确度:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi no"><img src="../Images/8cef70c190375d26d93725ba95b1c483.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pgEw8prcdvEAmujZh2s-Bw.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">不同型号精度参考:<a class="ae ms" href="https://arxiv.org/pdf/1904.01906.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1904.01906.pdf</a></p></figure><p id="36b6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">此外，请注意，这个四阶段网络仅在拉丁脚本的语料库上进行训练。</p><p id="47e2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们清楚了 CRAFT 和四阶段 STR 是如何工作的，让我们来看看代码吧！</p><h1 id="1b88" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">代码</h1><p id="4771" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">CRAFT 预测每个单词的边界框。四阶段 STR 将单个单词(作为图像)作为输入，并预测字母。如果您正在处理像 CUTE80 这样的单个单词的图像，那么使用这些 DL 模块进行 OCR 将是一件轻而易举的事情。</p><p id="4cee" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但这种可能性有多大呢？我们的大多数用例涉及对大量图像的预测，如果没有，我们最有可能有带有多个文本外观的图像。如果我们有一个将两者结合起来的单一管道，那不是很好吗？</p><p id="967a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们编写自己的代码来组合它们！</p><p id="3e78" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">第一步:安装要求</strong></p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi np"><img src="../Images/16d09990d1e19017f666c9c2c548e4df.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*GUHs-TXF2eLSOA8z2ftIyA.png"/></div></figure><p id="ff4e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">第二步:Git 克隆存储库:</strong></p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nq"><img src="../Images/5f90e5a7b5b7e93936c8ad16688a9fca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8tQPdIYqH-d0p4FeppS0mw.png"/></div></div></figure><p id="c377" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">第三步:修改返回检测框分数<br/> </strong> CRAFT 返回超过一定分数阈值的包围盒。如果您想查看每个边界框的分值，我们需要对原始存储库进行一些更改。在克隆的 craft 存储库中打开 craft_utils.py。您需要将第 83 行和第 239 行改为如下所示。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="87f4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">第四步:从 CRAFT <br/> </strong>中移除参数解析器打开 test.py，修改如下图。我们移除了参数解析器。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="a8a8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">步骤 5:编写一个单独的脚本，将图像名称和检测框坐标保存到一个 CSV 文件<br/> </strong>这将帮助我们裁剪需要作为四阶段 STR 输入的单词。它还帮助我们将所有与边框和文本相关的信息保存在一个地方。<br/>创建一个新文件(我将其命名为 pipeline.py)并添加以下代码。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="bafc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">pandas DataFrame(可变数据)将图像名称和其中出现的单词的边界框存储在单独的列中。我们删除了图像的整个路径，只保留图像以避免笨拙。你显然可以根据自己的需求进行定制。您现在可以运行脚本了:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nt"><img src="../Images/133f7948b1d9c11f7617750ce20be88a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7CeH8CiVWmrJPl02WP-caQ.png"/></div></div></figure><p id="0409" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个阶段的 CSV 是这样的。对于每个检测，我们存储一个 python 字典，其中存储了<strong class="kk iu"> score: coordinates。</strong></p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nu"><img src="../Images/befe8eb3d3e6e2de4aebc0d8d12e4361.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xoM-D42ZfiO7xRndeCYB9Q.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">CSV 文件</p></figure><p id="cc76" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">第六步:裁剪单词<br/> </strong>现在我们已经有了每个盒子的坐标和分数。我们可以设置一个阈值，并裁剪我们希望识别字符的单词。创建一个新的脚本 crop_images.py。记住在提到的地方添加你的路径。裁剪后的单词保存在“dir”文件夹中。我们为每张图片创建一个文件夹，并以这种格式保存从其中裁剪下来的单词:<br/> &lt;父图片&gt; _ &lt; 8 坐标由下划线&gt; <br/>分隔这也将帮助您跟踪每个裁剪的单词来自哪张图片。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="bbfa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">运行脚本！</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/de39c3cd249790bd0777e2ab6efb9a5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1122/format:webp/1*nDCC-G0sSTfWOQ9f4gIWLA.png"/></div></figure><p id="eaac" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">第六步:认可(终于！)<br/> </strong>你现在可以对你裁剪出来的单词盲目运行识别模块了。但是如果你想让事情更有条理，请修改以下内容。我们在每个图像文件夹中创建一个. txt 文件，并将识别出的单词与裁剪图像的名称一起保存。<br/>除此之外，预测的单词保存在我们维护的 CSV 中。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="f925" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从 Clova AI STR Github 存储库下载权重后，可以运行以下命令:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nw"><img src="../Images/76b04dfe894162ecc8371261d3d3de1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7mlNxn8olFSH0Un8Ykc6sQ.png"/></div></div></figure><p id="238e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们选择这种网络组合是因为它们的高精度。</p><p id="6a3f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">CSV 现在看起来如下。pred_words 具有检测框坐标和预测字，由冒号分隔。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nx"><img src="../Images/6ac27075aa4325b20aad3d78441fac85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TCCYG8T3H1AlODYQZTwrYg.png"/></div></div></figure><h1 id="abdf" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">结论</h1><p id="d3f5" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">我们已经集成了两个精确的模型来创建单个检测和识别模块。既然预测的单词和它们的边界框都在一列中，那么您就可以按照您想要的任何方式对齐文本了！</p></div></div>    
</body>
</html>