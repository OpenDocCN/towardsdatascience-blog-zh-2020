<html>
<head>
<title>From imbalanced datasets to boosting algorithms</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从不平衡数据集到助推算法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/from-imbalanced-dataset-to-boosting-algorithms-1-2-798cd6384ecc?source=collection_archive---------26-----------------------#2020-05-19">https://towardsdatascience.com/from-imbalanced-dataset-to-boosting-algorithms-1-2-798cd6384ecc?source=collection_archive---------26-----------------------#2020-05-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="2c36" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">艰难的教训，真正的秘诀</h2><div class=""/><div class=""><h2 id="a48f" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">不平衡数据集完整工具包</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/979e2404390c322854e5bc28d642b72c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3Zde2mNTe5ubqG7T"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上<a class="ae lh" href="https://unsplash.com/@enginakyurt?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> engin akyurt </a>拍摄的照片</p></figure><h2 id="17ab" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">不平衡数据集出现问题有两种不同的情况。</h2><p id="cc37" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated">第一类是当错误分类的成本对少数阶级来说比多数阶级高得多的时候。换句话说，我们模型的主要目标是最小化假阳性预测。一些例子是:检测信用卡欺诈，客户流失，检测一种罕见的致命疾病。为了更好地理解不同类型的错误预测如何转化为实际的业务成本，请查看我的帖子:<a class="ae lh" rel="noopener" target="_blank" href="/programming-journal-4-why-do-we-have-to-talk-about-type-1-error-and-type-2-error-41b3ae68bb96"> <em class="mw">为什么我们必须谈论第一类错误和第二类错误？</em> </a></p><p id="ac71" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">第二种是我们没有为少数群体收集足够的数据。我们的样品不够有代表性。换句话说，不平衡的数据集应该是平衡的。</p><p id="3b7c" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">在python中，我们的工具箱中有几个工具可以修复不平衡的数据集。然而，每个工具都是为解决不同类型的问题而构建的。</p><h2 id="c80d" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">文章大纲:</h2><ol class=""><li id="4c75" class="nc nd it mf b mg mh mj mk lr ne lv nf lz ng mv nh ni nj nk bi translated">介绍所有工具:下采样，上采样，平滑，改变类权重</li><li id="3053" class="nc nd it mf b mg nl mj nm lr nn lv no lz np mv nh ni nj nk bi translated">用我上周完成的项目展示他们用树算法的表现。</li><li id="2850" class="nc nd it mf b mg nl mj nm lr nn lv no lz np mv nh ni nj nk bi translated">讨论我们应该何时使用每种工具</li><li id="9260" class="nc nd it mf b mg nl mj nm lr nn lv no lz np mv nh ni nj nk bi translated">解释与升压算法的联系和比较</li></ol></div><div class="ab cl nq nr hx ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="im in io ip iq"><h2 id="9e0c" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">工具概述</h2><p id="36e1" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated"><strong class="mf jd">下采样:</strong>从多数类中随机选择一些点并删除。</p><p id="9283" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated"><strong class="mf jd">上采样:</strong>从少数类中随机选择一个点，复制粘贴做一个新点。重复这个过程，直到你有和大多数班级一样多的样本。</p><p id="4bc5" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated"><strong class="mf jd"> SMOTE: </strong>在少数类中创建更多的样本。然而，不是通过复制现有的数据点，而是通过在可能的范围内创建新的点。换句话说，它在现有数据的周围创建新的数据点<strong class="mf jd">。请参见下图进行说明。(关于这个的一个很棒的视频:<a class="ae lh" href="https://www.youtube.com/watch?v=U3X98xZ4_no&amp;t=384s" rel="noopener ugc nofollow" target="_blank"> SMOTE(合成少数过采样技术)</a>)</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nx"><img src="../Images/8e566051ddbf291e2ff9c1d0e4bd24ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5_klrli99gvA47cWvdWdcw.png"/></div></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ny"><img src="../Images/a9245a87f0ac08d1fe6222fc73ec96e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sDKqvWVKA9YLiBaB6IJdgQ.png"/></div></div></figure><p id="5f57" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated"><strong class="mf jd">调整等级权重</strong>:有两种方法可以实现。一种是将决策树和随机森林中的参数<em class="mw"> class_weights </em>改为<em class="mw">class _ weight =‘balanced’</em>。该算法将使用分层抽样来构建树，而不是默认设置:随机抽样。</p><p id="a233" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">第二种方法只适用于随机森林。您可以手动将权重分配给不同的类别。下面我就分享一下代码。通过给一个阶层分配较重的权重，我们将使用加权基尼系数。加权基尼系数将使我们用来制作树的所有变量对少数民族阶层更加敏感。例如，当我们计算我们的基尼系数时，能够更好地识别少数群体的变量将具有较低的杂质分数，因此，更有可能被选择来构建一个树。</p></div><div class="ab cl nq nr hx ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="im in io ip iq"><h2 id="64e4" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">性能概述</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nz"><img src="../Images/0c3e029bebb0152bdceacca8812d1642.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n1hg0qpyec-STKTXpSGASw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae lh" href="https://www.kaggle.com/taliac/customer-churn-using-tree-models" rel="noopener ugc nofollow" target="_blank">我通过Kaggle进行的全面流失分析</a></p></figure><p id="00b3" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">背景:<strong class="mf jd"> </strong>数据集来自一家电信公司。它有3333个样本(<a class="ae lh" href="https://www.kaggle.com/barun2104/telecom-churn" rel="noopener ugc nofollow" target="_blank">原始数据集</a>通过Kaggle)。在这些样本中，85.5%来自“流失= 0”组，14.5%来自“流失= 1”组。目标是预测客户流失。我将展示4种树算法的性能——决策树、随机森林、梯度推进和XG推进。</p><p id="66ad" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated"><strong class="mf jd">原始数据集的性能:</strong></p><div class="ks kt ku kv gt ab cb"><figure class="oa kw ob oc od oe of paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/75f8cb6926eebce5ae5bc77a5be7441d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*NqOun6PX5_177ezH8eBEBw.png"/></div></figure><figure class="oa kw og oc od oe of paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/8b5fdb86f9b65fdf781d4792eeffd917.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*w-SA-JI6KhlSgrWEjVqcWQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk oh di oi oj translated"><a class="ae lh" href="https://www.kaggle.com/taliac/different-resampling-methods-for-trees" rel="noopener ugc nofollow" target="_blank">全面分析</a></p></figure></div><p id="4ec5" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated"><strong class="mf jd">下采样后的性能:</strong></p><div class="ks kt ku kv gt ab cb"><figure class="oa kw ok oc od oe of paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/29a1dbd47ab0702be6c8b8ce7ef99eaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/1*WAmT-vmA_J6oS6vsdFDyag.png"/></div></figure><figure class="oa kw ol oc od oe of paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/7a51a0a1f824a6590d2c3ecc4b2bd9b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:898/format:webp/1*V698bwYIOHxiH6nkdJDCQA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk om di on oj translated"><a class="ae lh" href="https://www.kaggle.com/taliac/different-resampling-methods-for-trees" rel="noopener ugc nofollow" target="_blank">全面分析</a></p></figure></div><p id="19a3" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">缩减采样代码</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oo op l"/></div></figure><p id="8226" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated"><strong class="mf jd">上采样后的性能:</strong></p><div class="ks kt ku kv gt ab cb"><figure class="oa kw oq oc od oe of paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/508e7f2f23a638967b882888a78d07bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*xN8jCrdjMp_gvmsufmBMtQ.png"/></div></figure><figure class="oa kw or oc od oe of paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/9f9aabae9fe16388d92f2ff1517ca54a.png" data-original-src="https://miro.medium.com/v2/resize:fit:866/format:webp/1*NGO3Sag7Ljt85xuBEWB7bg.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk os di ot oj translated"><a class="ae lh" href="https://www.kaggle.com/taliac/different-resampling-methods-for-trees" rel="noopener ugc nofollow" target="_blank">全面分析</a></p></figure></div><p id="22e2" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">用于上采样的代码:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oo op l"/></div></figure><p id="7a2c" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated"><strong class="mf jd">击打后的表现:</strong></p><div class="ks kt ku kv gt ab cb"><figure class="oa kw ou oc od oe of paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/407e0d3a9f8714b504853a0b8ad9bfc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*DKWmon94yVsULYylofJ3kA.png"/></div></figure><figure class="oa kw ov oc od oe of paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/8ed7f28d3f68181b5db20d702208421d.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*DYDXAFgI0OOUZ01j3-yPjw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk ow di ox oj translated"><a class="ae lh" href="https://www.kaggle.com/taliac/different-resampling-methods-for-trees" rel="noopener ugc nofollow" target="_blank">全文分析</a></p></figure></div><p id="d396" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated"><strong class="mf jd">RF和决策树使用平衡类权重的性能:</strong></p><div class="ks kt ku kv gt ab cb"><figure class="oa kw oy oc od oe of paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/e883b97167e84d27fef8d0f8f39e8a4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/1*-pz1vrifaihXPuMAqeNg4w.png"/></div></figure><figure class="oa kw oz oc od oe of paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/1440e6c41ef2363527112911dd1fde1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*QeLWxchB9RL5qA6KYRNtZw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk pa di pb oj translated"><a class="ae lh" href="https://www.kaggle.com/taliac/different-resampling-methods-for-trees" rel="noopener ugc nofollow" target="_blank">全面分析</a></p></figure></div><p id="9b15" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated"><strong class="mf jd">手动调整权重后射频的性能</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pc"><img src="../Images/000d320ac420bc8c95fe3121ef6de17a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5y--sbm2tWjrpQXEvCm1ug.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae lh" href="https://www.kaggle.com/taliac/different-resampling-methods-for-trees" rel="noopener ugc nofollow" target="_blank">全面分析</a></p></figure></div><div class="ab cl nq nr hx ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="im in io ip iq"><h2 id="1a2f" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">见解:</h2><p id="41de" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated">当谈到每种方法的优缺点时，许多文章都是这样说的:</p><p id="a1c9" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated"><strong class="mf jd">随机下采样:</strong>遗漏一些有价值的信息。众所周知，样本越多越好，因为这让我们更接近现实。但是下采样减少了样本。</p><p id="85a7" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated"><strong class="mf jd">随机上采样</strong>:倾向于过度拟合少数群体的现有数据点，因为我们一直在复制现有数据点。</p><p id="a271" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">这个弊端其实从上面的分析就反映出来了。比较假阳性的数量，上采样的假阳性没有其他方法减少的多。</p><p id="e379" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated"><strong class="mf jd"> SMOTE和加权类:</strong>通常被描述为“高级”方法，用来克服下采样和上采样的缺点。确实，SMOTE找到了一种合理的方式来提供新数据，这是一种革命性的想法。加权类方法保留了所有的信息，这也是事实。</p><p id="d351" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">但是如果你是商业决策者，看着结果，你会选择哪种方法？</p><p id="6910" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">要回答这个问题:我们可以用数字来表示事物。我们就挑随机森林的表现来举例吧。假设在我们预见到客户会流失之后，我们能够挽救所有的客户。</p><ul class=""><li id="b671" class="nc nd it mf b mg mx mj my lr pd lv pe lz pf mv pg ni nj nk bi translated">缩减采样成本=失去2个客户+在38个客户身上浪费营销努力和金钱，因为我们认为我们会失去他们</li><li id="9cd0" class="nc nd it mf b mg nl mj nm lr nn lv no lz np mv pg ni nj nk bi translated">上采样成本=失去22个客户+浪费15个客户。</li><li id="059f" class="nc nd it mf b mg nl mj nm lr nn lv no lz np mv pg ni nj nk bi translated">SMOTE成本=失去17个客户+浪费27个客户。</li><li id="3799" class="nc nd it mf b mg nl mj nm lr nn lv no lz np mv pg ni nj nk bi translated">平衡级成本=失去20个客户，浪费16个客户。</li><li id="3783" class="nc nd it mf b mg nl mj nm lr nn lv no lz np mv pg ni nj nk bi translated">加权成本=失去12个客户，浪费24个客户。</li></ul><p id="0a65" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">尽管成本会因行业而异，但我愿意说我会选择下采样。一是因为我失去的客户最少，这是我的首要目标。另一个原因是，既然这38位客户打算和我们住在一起，我想我们应该不会花太多精力或成本去“拯救”他们。</p><p id="7709" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">当然，这取决于我们的“储蓄”方法和样本量的大小。如果我们有一万个客户，考虑的可能就不一样了。</p><blockquote class="ph pi pj"><p id="bbd2" class="md me mw mf b mg mx kd mi mj my kg ml pk mz mn mo pl na mq mr pm nb mt mu mv im bi translated"><strong class="mf jd">不管怎样，这里的关键观点是——没有更好或更坏的方法，我们需要始终牢记上下文。</strong></p></blockquote><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pn op l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">Gif via <a class="ae lh" href="https://media.giphy.com/media/TKpMzTvUcqlT8HGAyG/giphy.gif" rel="noopener ugc nofollow" target="_blank"> GIPHY </a></p></figure><h2 id="42aa" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">有一般的经验法则吗？</h2><p id="1740" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated">是的。我提到过不平衡的数据集成为问题的两个原因。第一类是假阳性数字对我们来说比整体准确性更重要。类型2在数据收集过程中有偏差。流失率问题是第一类问题。换句话说，这里的主要问题不是我的数据集有偏差，而是他们是天生的少数。在这种情况下，下采样和加权类最好地解决了我们的问题，因为它们扩大了少数类的声音。</p><p id="dc43" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">如果我们面对的是2型问题，那么SMOTE应该比其他方法更好，因为它在少数类中引入了新的样本。它试图填补少数阶级的空白，缓解有偏见的人。</p><p id="9bf2" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">上采样和平衡类方法的工作方式相同，因此结果非常相似。它们并不特别适合任何一种类型。原因是在你不停地从少数数据集复制数据之后，不可能没有过拟合的问题。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi po"><img src="../Images/709ed374706f09827db5a710fdec2443.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*O5390PNLATwartAk"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">萨汉德·巴巴里在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure></div><div class="ab cl nq nr hx ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="im in io ip iq"><h2 id="7d0a" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">有趣的技术见解:(随意跳过)</h2><p id="8357" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated">注意最大深度和假阳性的数量。在下采样中，如果我限制深度，我实际上会有更多的假阳性和更低的准确性。但是在手动调整类权重时，我减少的深度越多，我得到的假正数就越少。缺点是我会因为一个0的假阳性数字而牺牲整体的准确性。</p><p id="cda8" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">这个细节真正展示了这两种方法之间的区别。当使用缩减采样时，我们仍然通过寻找最佳变量进行分割来构建树。它就像一个普通的随机森林。随机森林非常适合处理过度拟合。当我限制深度时，我可能真的会不适应。而且不可能有0假阳性，除非我们以后做一些正则化。</p><p id="91ba" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">然而，在调整类权重的情况下，它像正则化一样工作。也就是说，我们需要小心选择重量。</p></div><div class="ab cl nq nr hx ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="im in io ip iq"><h2 id="65f3" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">增压连接</h2><p id="35d1" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated">通过调整类权重，我们刚刚从bagging算法转移到伪boosting算法。</p><p id="faf7" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">再看看数据。您是否注意到加权类的性能与boosting算法的性能非常相似？还有，你注意到别的了吗？梯度增强和XG增强这两种增强方法没有其他两种树方法波动大。他们的两类错误一开始也更平衡。这是为什么呢？</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="pp op l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">GIF via <a class="ae lh" href="https://media.giphy.com/media/CDJo4EgHwbaPS/giphy.gif" rel="noopener ugc nofollow" target="_blank"> GIPHY </a></p></figure><p id="0c5d" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">bagging和boosting算法的核心区别之一是，在bagging算法中，它遵循1树1票的规则。不管在什么情况下，没有一棵树高于另一棵树。对于助推来说，不等于。在最终决定上，有些人会比其他人更有发言权。不同的提升算法有不同的方式来决定一棵树在最终决策中有多少发言权。但原则是，声音是不平等的。因此，我说加权随机森林是伪提升算法。</p><h2 id="7eea" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">为什么这只是伪boosting算法而不是boosting算法？</h2><p id="5673" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated">不同之处在于boosting算法改变样本的权重，而加权随机森林改变类的权重。如果以人为类比。一个加权随机森林说:每个投A的人都会被多算。一个增强算法说:谁更有资格，谁就能投更多的票。</p><p id="51f6" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">棘手的部分是:我们如何证明谁比谁更有资格，权力大多少？这就是助推算法试图解决的问题。</p><h2 id="477a" class="li lj it bd lk ll lm dn ln lo lp dp lq lr ls lt lu lv lw lx ly lz ma mb mc iz bi translated">那么为什么boosting算法波动更小呢？助推算法一瞥。</h2><p id="acb9" class="pw-post-body-paragraph md me it mf b mg mh kd mi mj mk kg ml lr mm mn mo lv mp mq mr lz ms mt mu mv im bi translated">在助推算法的背景下，谁是“合格的人”？他们是产生更多正确结果的树，并且持续地产生正确结果。</p><p id="ffc6" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">如果树X总是比树Y产生更多正确的结果，那么树X比树Y更善于识别少数类(当存在不平衡的数据集时，所有的树都善于识别多数类)。增强算法放大这些声音。这就是为什么boosting算法一开始就比其他算法做得更好。</p><p id="b4dc" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">Boosting算法通过反复测试不同树的准确性来确保性能的一致性。该算法在每次测试后调整树的功率，直到调整仅具有微小的波动。这是boosting和bagging算法之间的第二个主要区别(第一个是分配不同的权重)。在bagging算法中，树有许多期末考试，期末成绩是通过和失败的简单相加。在推进算法中，你有测验和期中考试。每次测验都会影响你的期末成绩。</p><p id="ff90" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">因此，有了一个平衡的数据集，无论数据集的结构如何，产生更正确结果的树总是占主导地位。这就是为什么在我们实现SMOTE和上采样后，梯度增强的性能丝毫没有改变。</p><blockquote class="ph pi pj"><p id="2425" class="md me mw mf b mg mx kd mi mj my kg ml pk mz mn mo pl na mq mr pm nb mt mu mv im bi translated">因此，第二个关键的见解是:当你不确定不平衡的主要原因是什么时，使用一个增强算法。你会少错一些。</p></blockquote><p id="d31d" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">好了，这是升压算法的一瞥。我正在写一篇文章来更详细地解释boosting算法。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oo op l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">GIF via <a class="ae lh" href="https://media.giphy.com/media/fnDY3C9MKukcER71r7/giphy.gif" rel="noopener ugc nofollow" target="_blank"> GIPHY </a></p></figure></div><div class="ab cl nq nr hx ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="im in io ip iq"><p id="b5d0" class="pw-post-body-paragraph md me it mf b mg mx kd mi mj my kg ml lr mz mn mo lv na mq mr lz nb mt mu mv im bi translated">更多信息:</p><ul class=""><li id="d86a" class="nc nd it mf b mg mx mj my lr pd lv pe lz pf mv pg ni nj nk bi translated"><a class="ae lh" href="https://cling.csd.uwo.ca/papers/cost_sensitive.pdf" rel="noopener ugc nofollow" target="_blank">成本敏感学习与阶层失衡问题</a>，x .凌，s .盛</li><li id="3369" class="nc nd it mf b mg nl mj nm lr nn lv no lz np mv pg ni nj nk bi translated"><a class="ae lh" href="https://www.kaggle.com/taliac/different-resampling-methods-for-trees/data?scriptVersionId=34283208#4.-Models-With-Resamplings" rel="noopener ugc nofollow" target="_blank">树木的不同重采样方法</a>我在Kaggle上的原始重采样分析</li><li id="bded" class="nc nd it mf b mg nl mj nm lr nn lv no lz np mv pg ni nj nk bi translated"><a class="ae lh" href="https://www.kaggle.com/taliac/customer-churn-using-tree-models" rel="noopener ugc nofollow" target="_blank">使用树模型的客户流失</a>我在Kaggle上的全面流失分析</li></ul></div></div>    
</body>
</html>