<html>
<head>
<title>Big Data File Formats Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">大数据文件格式解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/big-data-file-formats-explained-dfaabe9e8b33?source=collection_archive---------8-----------------------#2020-09-11">https://towardsdatascience.com/big-data-file-formats-explained-dfaabe9e8b33?source=collection_archive---------8-----------------------#2020-09-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/1802fc1425f8db599eed3739551b3ba4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*suBDwJiElP7O2TDa"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">斯坦尼斯拉夫·康德拉蒂耶夫在<a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="65cb" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">介绍</h1><p id="5aef" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">对于<strong class="lg iu">数据湖</strong>，在<strong class="lg iu"> Hadoop </strong>生态系统中，使用<a class="ae kf" href="https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html" rel="noopener ugc nofollow" target="_blank"><strong class="lg iu"/></a>文件系统。然而，大多数云提供商已经将其替换为自己的深度存储系统，如<a class="ae kf" href="https://aws.amazon.com/s3/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> S3 </strong> </a>或<a class="ae kf" href="https://cloud.google.com/storage/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> GCS </strong> </a>。使用深度存储时，选择正确的文件格式至关重要。</p><p id="362f" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">这些文件系统或深度存储系统比数据库便宜，但只提供基本存储，不提供强有力的保证。</p><p id="f847" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">您需要根据您的需求和预算，为您的使用情形选择合适的存储。例如，如果预算允许，您可以使用数据库进行接收，然后一旦数据被转换，就将其存储在您数据湖中以供 OLAP 分析。或者，您可以将所有内容存储在深层存储中，而将一小部分热数据存储在快速存储系统(如关系数据库)中。</p><h1 id="60a5" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated"><strong class="ak">文件格式</strong></h1><p id="813d" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">请注意，深度存储系统将数据存储为文件，不同的文件格式和压缩算法为某些用例提供了好处。<strong class="lg iu">你如何在你的数据湖中存储数据是至关重要的</strong>，你需要考虑<strong class="lg iu">格式</strong>、<strong class="lg iu">压缩</strong>，尤其是<strong class="lg iu">你如何</strong> <a class="ae kf" href="https://mungingdata.com/apache-spark/partitionby/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu">分割</strong> </a> <strong class="lg iu">你的数据。</strong></p><p id="ba50" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">最常见的格式有 CSV、JSON、<a class="ae kf" href="https://avro.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="lg iu"/></a><strong class="lg iu">、</strong> <a class="ae kf" href="https://developers.google.com/protocol-buffers/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu">协议缓冲区</strong> </a> <strong class="lg iu">、</strong> <a class="ae kf" href="https://parquet.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu">拼花</strong> </a>、<a class="ae kf" href="https://orc.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> ORC </strong> </a>。</p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mh"><img src="../Images/927c334e0e4193fbeab87f59847da330.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0Frhzu__LfgEX99Ergb-Hg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">文件格式选项</p></figure><p id="249e" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">选择格式时要考虑的一些事情有:</p><ul class=""><li id="28f2" class="mm mn it lg b lh mc ll md lp mo lt mp lx mq mb mr ms mt mu bi translated">你的数据的结构:一些格式接受嵌套数据，比如 JSON、Avro 或 Parquet，其他的则不接受。即使有，也可能不是高度优化的。Avro 是嵌套数据最有效的格式，我建议不要使用 Parquet 嵌套类型，因为它们非常低效。进程嵌套的 JSON 也非常占用 CPU 资源。一般来说，建议在摄取数据时将数据拉平。</li><li id="46e6" class="mm mn it lg b lh mv ll mw lp mx lt my lx mz mb mr ms mt mu bi translated"><strong class="lg iu">性能</strong>:Avro 和 Parquet 等一些格式比其他此类 JSON 表现更好。即使在 Avro 和 Parquet 之间，对于不同的用例，一个会比另一个更好。例如，因为 Parquet 是一种基于列的格式，所以使用 SQL 查询数据湖很好，而 Avro 更适合 ETL 行级转换。</li><li id="fe75" class="mm mn it lg b lh mv ll mw lp mx lt my lx mz mb mr ms mt mu bi translated"><strong class="lg iu">易阅读</strong>:考虑是否需要人阅读数据。JSON 或 CSV 是文本格式，是人类可读的，而更高性能的格式如 parquet 或 Avro 是二进制的。</li><li id="54d0" class="mm mn it lg b lh mv ll mw lp mx lt my lx mz mb mr ms mt mu bi translated">压缩:有些格式比其他格式提供更高的压缩率。</li><li id="a193" class="mm mn it lg b lh mv ll mw lp mx lt my lx mz mb mr ms mt mu bi translated">模式演变:在数据湖中添加或删除字段远比在数据库中复杂。像 Avro 或 Parquet 这样的格式提供了某种程度的模式进化，允许您在更改数据模式的同时查询数据。像<a class="ae kf" href="https://delta.io/" rel="noopener ugc nofollow" target="_blank"><strong class="lg iu">Delta Lake</strong></a>format 这样的工具提供了更好的工具来处理模式的变化。</li><li id="85b8" class="mm mn it lg b lh mv ll mw lp mx lt my lx mz mb mr ms mt mu bi translated"><strong class="lg iu">兼容性</strong> : JSON 或 CSV 被广泛采用，几乎与任何工具兼容，而性能更高的选项集成点更少。</li></ul><h2 id="340b" class="na kh it bd ki nb nc dn km nd ne dp kq lp nf ng ku lt nh ni ky lx nj nk lc nl bi translated">文件格式</h2><ul class=""><li id="23b2" class="mm mn it lg b lh li ll lm lp nm lt nn lx no mb mr ms mt mu bi translated"><strong class="lg iu"> CSV </strong>:兼容性、电子表格处理和人类可读数据的良好选择。数据必须是平面的。它效率不高，并且不能处理嵌套数据。分隔符可能有问题，这会导致数据质量问题。将此格式用于探索性分析、概念验证或小型数据集。</li><li id="34ed" class="mm mn it lg b lh mv ll mw lp mx lt my lx mz mb mr ms mt mu bi translated"><strong class="lg iu"> JSON </strong>:在 API 中大量使用。嵌套格式。它被广泛采用，人们可以阅读，但是如果有很多嵌套字段，就很难阅读。非常适合小型数据集、着陆数据或 API 集成。如果可能，在处理大量数据之前转换为更有效的格式。</li><li id="813b" class="mm mn it lg b lh mv ll mw lp mx lt my lx mz mb mr ms mt mu bi translated"><strong class="lg iu"> Avro </strong>:非常适合存储行数据，非常高效。它有一个模式并支持进化。与卡夫卡大融合。支持文件分割。将其用于行级操作或 Kafka 中。写数据很棒，读起来比较慢。</li><li id="286f" class="mm mn it lg b lh mv ll mw lp mx lt my lx mz mb mr ms mt mu bi translated"><strong class="lg iu">协议缓冲区</strong>:非常适合 API，尤其是<a class="ae kf" href="https://grpc.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> gRPC </strong> </a>。支持模式，速度非常快。用于 API 或机器学习。</li><li id="4cb0" class="mm mn it lg b lh mv ll mw lp mx lt my lx mz mb mr ms mt mu bi translated"><strong class="lg iu">拼花</strong>:柱状收纳。它有模式支持。它与 Hive 和 Spark 配合得非常好，作为一种将列数据存储在使用 SQL 查询的深层存储中的方法。因为它将数据存储在列中，所以查询引擎将只读取具有所选列的文件，而不是整个数据集，这与 Avro 相反。将其用作报告层。</li><li id="7be6" class="mm mn it lg b lh mv ll mw lp mx lt my lx mz mb mr ms mt mu bi translated">类似于拼花地板，它提供了更好的压缩性。它也提供了更好的模式进化支持，但是不太受欢迎。</li></ul><h1 id="380c" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">文件压缩</h1><p id="1c1d" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">最后，您还需要考虑如何<strong class="lg iu">压缩数据</strong>，权衡文件大小和 CPU 成本。一些压缩算法速度较快，但文件较大，而另一些速度较慢，但压缩率较高。更多详情请查看此<a class="ae kf" href="http://www.dbtalks.com/article/what-are-different-data-compression-methods-in-hadoop/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu">文章</strong> </a>。</p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div class="gh gi np"><img src="../Images/de5e404678d465e2472fdf7cf309689d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*I90pjcqqndBBInUuiZGi_w.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">压缩选项(图片由作者提供)</p></figure><p id="ba4b" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">我推荐使用<strong class="lg iu">快节奏的</strong>处理<strong class="lg iu">流数据</strong>，因为它不需要太多的 CPU 能力。对于<strong class="lg iu">批次来说，bzip2 </strong>是一个很好的选择。</p><h1 id="6c1b" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">结论</h1><p id="2474" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">正如我们所看到的，CSV 和 JSON 是易于使用、人类可读的常见格式，但缺乏其他格式的许多功能，这使得它太慢，无法用于查询数据湖。<strong class="lg iu"> ORC 和 Parquet </strong>在 Hadoop 生态系统中广泛用于<strong class="lg iu">查询数据</strong>，而<a class="ae kf" href="https://avro.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> Avro </strong> </a>也在 Hadoop 之外使用，特别是与 Kafka 一起用于摄取，非常适合<strong class="lg iu">行级 ETL </strong>处理。面向行的格式比面向列的格式具有更好的模式进化能力，这使它们成为数据摄取的一个很好的选择。</p></div><div class="ab cl nq nr hx ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="im in io ip iq"><p id="6354" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><strong class="lg iu">更新</strong>:我目前在坦桑尼亚帮助当地的一所学校，我创建了一个<a class="ae kf" href="https://www.gofundme.com/f/help-the-mango-school-children-in-tanzania" rel="noopener ugc nofollow" target="_blank"> <strong class="lg iu"> GoFundMe 活动</strong> </a>来帮助孩子们，通过这个<a class="ae kf" href="https://www.gofundme.com/f/help-the-mango-school-children-in-tanzania" rel="noopener ugc nofollow" target="_blank">链接</a>来捐款，每一点帮助！</p><p id="9d80" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">我希望你喜欢这篇文章。欢迎发表评论或分享这篇文章。跟随<a class="ae kf" href="https://twitter.com/JavierRamosRod" rel="noopener ugc nofollow" target="_blank"><strong class="lg iu"><em class="nx">me</em></strong></a><strong class="lg iu"><em class="nx"/></strong><em class="nx">进行以后的帖子。</em></p></div></div>    
</body>
</html>