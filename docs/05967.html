<html>
<head>
<title>Reverse Engineering Google’s Tech to Win 95+ Accuracy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">逆向工程谷歌的技术，以赢得95%以上的准确性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/reverse-engineering-googles-tech-to-win-95-accuracy-2070c2b1052c?source=collection_archive---------60-----------------------#2020-05-15">https://towardsdatascience.com/reverse-engineering-googles-tech-to-win-95-accuracy-2070c2b1052c?source=collection_archive---------60-----------------------#2020-05-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0a79" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">等等，你没看错😃让我们像专业人士一样设计神经网络吧！</h2></div><blockquote class="ki kj kk"><p id="0118" class="kl km kn ko b kp kq ju kr ks kt jx ku kv kw kx ky kz la lb lc ld le lf lg lh im bi translated">我们看到谷歌如何提出许多突破性的科学构建，即使是在深度学习时代的早期阶段。他们拥有世界上最好的资源，硬件、软件和工程师。我们将研究如何对谷歌的一项新服务进行逆向工程，以获得惊人的结果。</p></blockquote><p id="0018" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi ll translated">我想给你讲一个故事。两年前，谷歌提出了一个想法，即开发一个平台，任何人都可以在这个平台上开发自己强大的深度学习模型，而无需事先有编码经验。这个平台的早期版本只允许用户使用他们的网络摄像头创建分类模型。这个想法很简单，走到讲台上，打开你的相机，给它看几张不同班级的照片。这个模型是在谷歌的计算机中训练出来的。所有这些事情的发生只是时间问题。该平台的最初版本非常简单。最近，谷歌更新了平台，为多个类别、姿势估计、音频分类、不同格式的下载模型等提供了巨大的支持。谷歌称之为<a class="ae lu" href="https://teachablemachine.withgoogle.com/train" rel="noopener ugc nofollow" target="_blank"> <strong class="ko iu"> <em class="kn">可教机器</em> </strong> </a>。当前版本支持以下内容。</p><ul class=""><li id="43a3" class="lv lw it ko b kp kq ks kt li lx lj ly lk lz lh ma mb mc md bi translated">根据图像数据训练模型</li><li id="105d" class="lv lw it ko b kp me ks mf li mg lj mh lk mi lh ma mb mc md bi translated">根据音频数据训练模型</li><li id="448b" class="lv lw it ko b kp me ks mf li mg lj mh lk mi lh ma mb mc md bi translated">根据姿势数据训练模型(像在<a class="ae lu" href="https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5" rel="noopener"> Posenet </a>中)</li><li id="2a3a" class="lv lw it ko b kp me ks mf li mg lj mh lk mi lh ma mb mc md bi translated">将您自己的数据集上传到训练模型</li><li id="2b26" class="lv lw it ko b kp me ks mf li mg lj mh lk mi lh ma mb mc md bi translated">每个模型培训3个以上的班级</li><li id="1012" class="lv lw it ko b kp me ks mf li mg lj mh lk mi lh ma mb mc md bi translated">禁用类别</li><li id="c30a" class="lv lw it ko b kp me ks mf li mg lj mh lk mi lh ma mb mc md bi translated">保存您的TensorFlow.js模型</li><li id="4123" class="lv lw it ko b kp me ks mf li mg lj mh lk mi lh ma mb mc md bi translated">下载您的模型</li><li id="57f1" class="lv lw it ko b kp me ks mf li mg lj mh lk mi lh ma mb mc md bi translated">部署您的模型以用于您自己的项目(网站、应用程序、物理机器等)。)</li></ul><p id="769d" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated"><strong class="ko iu"> <em class="kn">怎么样？对我来说，太棒了。</em>T13】</strong></p><p id="20cb" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">为了更好地了解这个平台，请观看下面由Google制作的视频。</p><figure class="mj mk ml mm gt mn"><div class="bz fp l di"><div class="mo mp l"/></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">谷歌可教机器视频</p></figure><h2 id="532c" class="mu mv it bd mw mx my dn mz na nb dp nc li nd ne nf lj ng nh ni lk nj nk nl nm bi translated">这个逆向工程任务是如何工作的？</h2><p id="966f" class="pw-post-body-paragraph kl km it ko b kp nn ju kr ks no jx ku li np kx ky lj nq lb lc lk nr lf lg lh im bi translated">我们要逆向工程的服务不过是<strong class="ko iu"> <em class="kn">可教的机器</em> </strong>。首先也是最重要的，我们去平台，输入一些不同类别的图片。我选择了<strong class="ko iu"> <em class="kn">摇滚</em> </strong> <em class="kn"> - </em> <strong class="ko iu"> <em class="kn">纸</em> </strong> <em class="kn"> - </em> <strong class="ko iu"> <em class="kn">剪刀</em> </strong>。您可以使用网络摄像头实时捕捉图像，或者上传您自己的自定义数据集。为了说明，我使用网络摄像头的方法。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi ns"><img src="../Images/0adacaf7bdd39041cb9be8b7db8614a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1T6Ygm3dW2d5AZTAlm8trw.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">截图取自<a class="ae lu" href="https://teachablemachine.withgoogle.com/" rel="noopener ugc nofollow" target="_blank">https://teachablemachine.withgoogle.com/</a></p></figure><p id="7511" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">如您所见，数据集已经准备好了。每个类由200幅图像组成。接下来就是训练模型了，我们只要点击<strong class="ko iu"> <em class="kn">训练模型</em> </strong>选项就可以开始训练模型了。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi nz"><img src="../Images/66e1d26d7456649bd583caff81dccdfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ka6wJ5xkj3Zpn5eGn_jR1Q.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">截图取自<a class="ae lu" href="https://teachablemachine.withgoogle.com/" rel="noopener ugc nofollow" target="_blank">https://teachablemachine.withgoogle.com/</a></p></figure><p id="f945" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">我们的模特不到一分钟就能完成训练。剩下的是，我们必须看看我们的模型在现实世界中的表现。为此，我们可以使用现场演示选项。下面是一张GIF图，展示了我们训练的模型的结果。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi oa"><img src="../Images/0c95fb43b471e73e9207bf37fc335348.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*UU7tb44V_G9fVBiWbmLaSA.gif"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">截图取自<a class="ae lu" href="https://teachablemachine.withgoogle.com/" rel="noopener ugc nofollow" target="_blank">https://teachablemachine.withgoogle.com/</a></p></figure><p id="6eec" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">一切正常，对吧？精度栏每次都打到100。我做的每个测试都得到了几乎相似的结果。这只是一个例子，你可以用更复杂的数据集来尝试。对于这个解决方法的主要部分，我们必须将模型导出为某种格式。在这里，我使用了<strong class="ko iu"> <em class="kn"> Keras </em> </strong>模型的变体。如果您愿意，可以在相同的Tensoflow.js或Tensorflow Lite版本之间进行选择。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi ob"><img src="../Images/c79c7552ceaf6187b6663e1e30c7203f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h2KcAwr5jI25RBu0UjMJ_Q.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">截图来自<a class="ae lu" href="https://teachablemachine.withgoogle.com/" rel="noopener ugc nofollow" target="_blank">https://teachablemachine.withgoogle.com/</a></p></figure><p id="f42a" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">我们已经完成了模型训练部分。现在，我们必须开始问题的核心部分，即逆向工程。我们将要看到的是<strong class="ko iu"> <em class="kn">模型是如何建立的</em> </strong>，所有的层配置都使用了什么，有多少层，内核大小是什么，前馈网络的维数等等。为此，我们使用一个叫做<a class="ae lu" href="https://github.com/lutzroeder/netron" rel="noopener ugc nofollow" target="_blank"><strong class="ko iu"><em class="kn">netron</em></strong></a>的工具。深度学习模型不是一堆简单的层，对吗？</p><p id="194c" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated"><strong class="ko iu"> Netron </strong>是一个开源工具，我们可以用它来看看深度学习模型是如何设计的以及相关的权重。我们必须访问他们的网站，并安装基于操作系统的客户端应用程序。我一直在用Ubuntu，所以我下载了它的Linux版本。这个项目的主页将如下所示。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi oc"><img src="../Images/a5fea3136c178f1ab56093275a85bed0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gVL-qKm8MGMDg3CF-mrhtw.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">截图取自<a class="ae lu" href="https://github.com/lutzroeder/netron" rel="noopener ugc nofollow" target="_blank">https://github.com/lutzroeder/netron</a></p></figure><p id="ddcd" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">我们最后要做的就是用<strong class="ko iu"> <em class="kn"> netron </em> </strong> app打开下载的模型。<strong class="ko iu">抓住你了</strong>！我们成功了。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi od"><img src="../Images/b3705ef973fb968e0d1baffeb84da5b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WczB-kWgO8zJ6pkaMhzIlA.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">截图来自netron app</p></figure><p id="5f31" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">你在上图中看到的是我们模型的架构。这是一个非常长的设计，不能放在一张截图里。放大后，我们得到了下面的图片。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi oe"><img src="../Images/42353441705a56e1491e4321ee28d8f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C9qyIX8V58KnFTkrIZ0a_Q.png"/></div></div><p class="mq mr gj gh gi ms mt bd b be z dk translated">截图来自netron app</p></figure><p id="c6e5" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">我们可以看到一些熟悉的层，对不对？在右侧，也给出了模型权重和超参数。如果我们可以通过查看层配置从零开始创建相同的模型，那就太棒了。我们可以在下一个项目中尝试这种配置。谷歌应该做了很多功课。所以采用同样的方法应该会有回报。</p><p id="2461" class="pw-post-body-paragraph kl km it ko b kp kq ju kr ks kt jx ku li kw kx ky lj la lb lc lk le lf lg lh im bi translated">这是一种新的深度学习方法，可以极大地改善最终结果。希望这对您有所帮助。干杯，大家。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi of"><img src="../Images/12a42ea150b669878b350084c16af78d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lgzROdVHD1jDW91xwO8mVA.png"/></div></div></figure></div></div>    
</body>
</html>