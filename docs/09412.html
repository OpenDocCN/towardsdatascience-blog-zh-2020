<html>
<head>
<title>A handbook to Text Preprocessing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">文本预处理手册</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-handbook-to-text-preprocessing-890f73fd28f8?source=collection_archive---------37-----------------------#2020-07-05">https://towardsdatascience.com/a-handbook-to-text-preprocessing-890f73fd28f8?source=collection_archive---------37-----------------------#2020-07-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/c1f8cd4aff86338e47606412f5ac0192.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*sCURVpRtPmF97CrZ"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">帕特里克·托马索在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><div class=""><h2 id="9a4f" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">自然语言处理的第一步</h2></div><p id="229a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">自然语言处理(NLP)是人工智能中最复杂的领域之一。这背后的原因是文本数据是上下文相关的，需要修改以使其能够被机器理解。它需要经历多个预处理阶段。</p><p id="e7a3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">在这篇博客中，我们将了解文本预处理是什么，为什么，如何用最简单的代码来尝试。</strong></p></div><div class="ab cl lr ls hu lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="ij ik il im in"><h1 id="025c" class="ly lz jg bd ma mb mc md me mf mg mh mi km mj kn mk kp ml kq mm ks mn kt mo mp bi translated">文本预处理</h1><p id="5425" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">文本数据很容易被人类理解。但是阅读和分析海量数据是一项复杂的任务。</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/efd1f9734252fc9a2b99380bacfa7334.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*GGeQypA2WuCwG5Nxf_O4YQ.gif"/></div></figure><p id="3f36" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了完成这项任务，我们需要将这些文本转换为机器可理解的数据，即，将单词转换为与机器学习算法一起工作的数字特征。</p><p id="5622" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">但是，这种转换并不简单，因为文本数据包含冗余和重复的单词。因此，在将文本数据转换成数字特征之前，我们需要对文本数据进行预处理。</p><p id="ed9f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">文本预处理的基本步骤包括:</p><ol class=""><li id="7446" class="nb nc jg kx b ky kz lb lc le nd li ne lm nf lq ng nh ni nj bi translated">清理原始数据</li><li id="f696" class="nb nc jg kx b ky nk lb nl le nm li nn lm no lq ng nh ni nj bi translated">符号化</li><li id="a9ca" class="nb nc jg kx b ky nk lb nl le nm li nn lm no lq ng nh ni nj bi translated">规范化令牌</li></ol><p id="f22e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们用一段代码来看看每一步。</p></div><div class="ab cl lr ls hu lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="ij ik il im in"><h1 id="1631" class="ly lz jg bd ma mb mc md me mf mg mh mi km mj kn mk kp ml kq mm ks mn kt mo mp bi translated">如何实现文本预处理？</h1><p id="931b" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">在本文中，我们将在 Kaggle 的 Twitter 数据集上使用客户支持。</p><div class="ip iq gp gr ir np"><a href="https://www.kaggle.com/thoughtvector/customer-support-on-twitter" rel="noopener  ugc nofollow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd jh gy z fp nu fr fs nv fu fw jf bi translated">Twitter 上的客户支持</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">Twitter 上最大品牌的 300 多万条推文和回复</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">www.kaggle.com</p></div></div><div class="ny l"><div class="nz l oa ob oc ny od ix np"/></div></div></a></div><h2 id="b05b" class="oe lz jg bd ma of og dn me oh oi dp mi le oj ok mk li ol om mm lm on oo mo op bi translated">关于数据集:</h2><p id="25bb" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">Twitter 上的客户支持数据集是一个大型的现代推文和回复语料库，用于帮助自然语言理解和会话模型的创新，以及研究现代客户支持实践和影响。该数据集提供了 Twitter 上消费者和客户支持代理之间的大量现代英语对话。</p><p id="f52b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">导入数据:</strong></p><pre class="mw mx my mz gt oq or os ot aw ou bi"><span id="b08d" class="oe lz jg or b gy ov ow l ox oy">import pandas as pd<br/>data = pd.read_csv("customer-support-on-twitter.csv")</span></pre><p id="a794" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">使用<em class="na"> pandas </em>库将数据从 CSV(逗号分隔值)加载到数据框中。</p><pre class="mw mx my mz gt oq or os ot aw ou bi"><span id="bd4e" class="oe lz jg or b gy ov ow l ox oy">data.columns</span></pre><figure class="mw mx my mz gt is gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/fff44b1e46de800ff9100b00a6062d47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*kqtlw6TWC-kdZSqSS0BPxg.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">数据列的输出</p></figure><p id="6fa4" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们只考虑用于预处理的<em class="na">‘文本’</em>列。</p></div><div class="ab cl lr ls hu lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="ij ik il im in"><h2 id="88d1" class="oe lz jg bd ma of og dn me oh oi dp mi le oj ok mk li ol om mm lm on oo mo op bi translated">1.清理原始数据</h2><p id="53c4" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">这个阶段包括删除对文本意义没有任何价值的单词或字符。一些常见的清洁步骤是，</p><ul class=""><li id="8c79" class="nb nc jg kx b ky kz lb lc le nd li ne lm nf lq pa nh ni nj bi translated">下降箱</li><li id="e920" class="nb nc jg kx b ky nk lb nl le nm li nn lm no lq pa nh ni nj bi translated">特殊字符的删除</li><li id="b9c7" class="nb nc jg kx b ky nk lb nl le nm li nn lm no lq pa nh ni nj bi translated">停用词的删除</li><li id="a236" class="nb nc jg kx b ky nk lb nl le nm li nn lm no lq pa nh ni nj bi translated">移除 URL</li><li id="a8dc" class="nb nc jg kx b ky nk lb nl le nm li nn lm no lq pa nh ni nj bi translated">移除 HTML 标签</li><li id="f3a8" class="nb nc jg kx b ky nk lb nl le nm li nn lm no lq pa nh ni nj bi translated">移除多余的空格</li></ul><h2 id="98e8" class="oe lz jg bd ma of og dn me oh oi dp mi le oj ok mk li ol om mm lm on oo mo op bi translated">下降箱:</h2><p id="a6a5" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">出于以下原因，降低文本的大小写非常重要:</p><ul class=""><li id="3cc1" class="nb nc jg kx b ky kz lb lc le nd li ne lm nf lq pa nh ni nj bi translated">单词“文本”、“文本”、“文本”给句子添加了相同的值</li><li id="539a" class="nb nc jg kx b ky nk lb nl le nm li nn lm no lq pa nh ni nj bi translated">对于文本矢量化，使用像 TF-IDF 这样的技术计算单词的频率，而不考虑大小写</li><li id="fddc" class="nb nc jg kx b ky nk lb nl le nm li nn lm no lq pa nh ni nj bi translated">降低所有单词的大小写也非常有助于通过减少词汇量来降低维度。</li></ul><pre class="mw mx my mz gt oq or os ot aw ou bi"><span id="c0a7" class="oe lz jg or b gy ov ow l ox oy">data["text_lower"] = data["text"].str.lower()</span></pre><div class="mw mx my mz gt ab cb"><figure class="pb is pc pd pe pf pg paragraph-image"><img src="../Images/056aa756b8caf994e40e234e50474aa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*hKhNk77Obl-xY2A6mTI_iA.png"/></figure><figure class="pb is ph pd pe pf pg paragraph-image"><img src="../Images/b65f5619cf5f180ced50fcefb01bf795.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*78iF8HVYMi-U23-FWLRiMA.png"/><p class="iz ja gj gh gi jb jc bd b be z dk pi di pj pk translated">降低外壳前后列'文本'</p></figure></div><p id="2ec9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="na">观察:</em> <em class="na">所有单词都转换成小写</em></p><h2 id="1983" class="oe lz jg bd ma of og dn me oh oi dp mi le oj ok mk li ol om mm lm on oo mo op bi translated">删除特殊字符:</h2><p id="c2ac" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">这是另一种文本预处理技术，有助于处理“万岁”和“万岁！”同理。</p><pre class="mw mx my mz gt oq or os ot aw ou bi"><span id="a7e8" class="oe lz jg or b gy ov ow l ox oy">import re<br/>no_special_char=[]<br/>for sentence in data.text_lower:<br/>    no_special_char.append(re.sub('[^A-Za-z0-9]+', ' ', sentence))<br/>data["no_special_char"]=no_special_char</span></pre><p id="28e8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">正则表达式库提供了一个函数:<br/> <em class="na"> sub( actual_pattern，replacing_pattern，data ) </em> <br/>帮助我们用数据中的第二个参数替换它的第一个参数</p><div class="mw mx my mz gt ab cb"><figure class="pb is pl pd pe pf pg paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><img src="../Images/3d4605e79bc9125edf42887635e8f7b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*TwpBg5Kz-vYF4r_7RexGZg.png"/></div></figure><figure class="pb is pm pd pe pf pg paragraph-image"><img src="../Images/684aae6f63107fee767b5e2397ff598f.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*tguWzmOiB16CCMF6gQq85Q.png"/><p class="iz ja gj gh gi jb jc bd b be z dk pi di pj pk translated">删除特殊字符前后的“文本”列</p></figure></div><p id="4833" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="na">观察:删除“@”、“`”等特殊字符。</em></p><h2 id="40ca" class="oe lz jg bd ma of og dn me oh oi dp mi le oj ok mk li ol om mm lm on oo mo op bi translated">停用词的删除:</h2><p id="b7cd" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">停用词是语言中常见的词，如“the”、“a”等。大多数时候，它们可以从文本中删除，因为它们没有提供有价值的信息。</p><pre class="mw mx my mz gt oq or os ot aw ou bi"><span id="0465" class="oe lz jg or b gy ov ow l ox oy">from nltk.corpus import stopwords<br/>stopwords = set(", ".join(stopwords.words('english')))</span></pre><p id="914f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">nltk.corpus 包含一个巨大的常用停用词库。</p><pre class="mw mx my mz gt oq or os ot aw ou bi"><span id="e240" class="oe lz jg or b gy ov ow l ox oy">no_stopwords=[]<br/>for sentence in data["no_special_char"]:<br/>    no_stopwords.append(' '.join(e.lower() for e in sentence.split() if e.lower() not in stopwords))<br/>data["no_stopwords"]=no_stopwords</span></pre><div class="mw mx my mz gt ab cb"><figure class="pb is pn pd pe pf pg paragraph-image"><img src="../Images/2cdcda8a6eafb7d418cfdf3fbafa63cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*CHaoEgGfcVUPtM5L7SdbVg.png"/></figure><figure class="pb is po pd pe pf pg paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><img src="../Images/d507292316f64942bc47ff13351761f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*R60ViKEF7ycQhSCzT5OxMA.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk pp di pq pk translated">删除停用词前后的“文本”列</p></figure></div><p id="3b5d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="na">观察:</em> <em class="na">删除“the”、“to”、“at”等词语</em></p><h2 id="c38a" class="oe lz jg bd ma of og dn me oh oi dp mi le oj ok mk li ol om mm lm on oo mo op bi translated">删除任何 URL</h2><p id="70e5" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">下一个预处理步骤是删除数据中存在的任何 URL。这条推文很有可能会包含一些 URL。为了进一步分析，我们可能需要移除它们。消除 URL 的简单代码如下:</p><pre class="mw mx my mz gt oq or os ot aw ou bi"><span id="969e" class="oe lz jg or b gy ov ow l ox oy">no_url=[]<br/>for sentence in data["no_stopwords"]:<br/>    no_url.append(re.sub(r"http\S+", "", sentence))<br/>data["no_url"]=no_url</span></pre><p id="845c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这里，<em class="na">re()</em>用空字符串替换任何以<em class="na">“http”</em>开头的单词。</p><h2 id="3aad" class="oe lz jg bd ma of og dn me oh oi dp mi le oj ok mk li ol om mm lm on oo mo op bi translated">移除 HTML 标签</h2><p id="d8f7" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">另一种常见的预处理技术是去除 HTML 标签，这种技术在很多地方都会派上用场。如果我们从不同的网站上删除数据，这是非常有用的。我们最终可能会将 HTML 字符串作为文本的一部分。</p><pre class="mw mx my mz gt oq or os ot aw ou bi"><span id="6940" class="oe lz jg or b gy ov ow l ox oy">no_html_tags=[]<br/>for sentence in data["no_url"]:<br/>    no_html_tags.append(re.sub(r"'&lt;.*?&gt;'", "", sentence))</span></pre><p id="80a9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这里，使用<em class="na">re()</em>，我们用一个空字符串替换包含在&lt; &gt;中的任何模式。</p></div><div class="ab cl lr ls hu lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="ij ik il im in"><h2 id="8b59" class="oe lz jg bd ma of og dn me oh oi dp mi le oj ok mk li ol om mm lm on oo mo op bi translated">2.标记化</h2><p id="4878" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">标记化是将文本分割成更小的块的过程，称为<strong class="kx jh">标记</strong> <em class="na">。</em>每个令牌都是作为特征的机器学习算法的输入。</p><pre class="mw mx my mz gt oq or os ot aw ou bi"><span id="c876" class="oe lz jg or b gy ov ow l ox oy">for sentence in data["no_url"]:<br/>    sentence.split()</span></pre><p id="0515" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="na"> Split( ) </em>将句子转换成单词</p></div><div class="ab cl lr ls hu lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="ij ik il im in"><h2 id="b00f" class="oe lz jg bd ma of og dn me oh oi dp mi le oj ok mk li ol om mm lm on oo mo op bi translated">3.规范化令牌</h2><p id="88f1" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">规范化是基于单词语义的清洗。规范化令牌可确保进一步预处理或分析的数据的一致性。有两种规范化令牌的技术:</p><ul class=""><li id="3fab" class="nb nc jg kx b ky kz lb lc le nd li ne lm nf lq pa nh ni nj bi translated">堵塞物</li><li id="4f7d" class="nb nc jg kx b ky nk lb nl le nm li nn lm no lq pa nh ni nj bi translated">词汇化</li></ul><h2 id="949f" class="oe lz jg bd ma of og dn me oh oi dp mi le oj ok mk li ol om mm lm on oo mo op bi translated">词干:</h2><p id="49d4" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">这是从单词中移除和替换后缀以获得单词的词根或基本形式的过程，称为<em class="na">词干</em>。波特词干分析器是一种广泛使用的词干分析技术。</p><pre class="mw mx my mz gt oq or os ot aw ou bi"><span id="ccb6" class="oe lz jg or b gy ov ow l ox oy">from nltk.stem.porter import PorterStemmer</span></pre><p id="d29d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="na"> nltk.stem </em>提供<em class="na">端口定时器</em></p><pre class="mw mx my mz gt oq or os ot aw ou bi"><span id="5678" class="oe lz jg or b gy ov ow l ox oy">def stem_words(text):<br/>    return " ".join([stemmer.stem(word) for word in text.split()])<br/>data["text_stemmed"] = data["no_url"].apply(lambda text: stem_words(text))</span></pre><div class="mw mx my mz gt ab cb"><figure class="pb is pr pd pe pf pg paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><img src="../Images/9a0ee826503e83067c2ed6886ec55a1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:954/format:webp/1*CyotJZ6TM0HLsPoPbWQthQ.png"/></div></figure><figure class="pb is ps pd pe pf pg paragraph-image"><img src="../Images/58e09687833e02e2465cb9bcd49871b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*9IrX3I-ullWaZo-3g2mGVA.png"/><p class="iz ja gj gh gi jb jc bd b be z dk pt di pu pk translated">执行词干分析前后的列文本</p></figure></div><p id="61d2" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="na">观察:所有单词都被转换为其基本形式，就像“消息”被转换为“消息”</em></p><h2 id="2fe4" class="oe lz jg bd ma of og dn me oh oi dp mi le oj ok mk li ol om mm lm on oo mo op bi translated">词汇化:</h2><p id="35a1" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">目标与词干化是一样的，但是词干化有时会失去单词的实际意义。</p><blockquote class="pv pw px"><p id="6eb7" class="kv kw na kx b ky kz kh la lb lc kk ld py lf lg lh pz lj lk ll qa ln lo lp lq ij bi translated">词汇化是指正确地使用词汇和词的形态分析来做事情。</p></blockquote><p id="8b0a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">它返回单词的基本形式或字典形式，也称为<em class="na">词条</em>。</p><pre class="mw mx my mz gt oq or os ot aw ou bi"><span id="2415" class="oe lz jg or b gy ov ow l ox oy">from nltk.stem import WordNetLemmatizer<br/>lemmatizer = WordNetLemmatizer()</span></pre><p id="a811" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="na"> nltk.stem </em>提供了<em class="na"> WordNetLemmatizer </em>，它被广泛用于执行词汇化</p><pre class="mw mx my mz gt oq or os ot aw ou bi"><span id="5e2c" class="oe lz jg or b gy ov ow l ox oy">def lemmatize_words(text):<br/>    return " ".join([lemmatizer.lemmatize(word) for word in text.split()])</span><span id="05b0" class="oe lz jg or b gy qb ow l ox oy">data["text_lemmatized"] =data["text_stemmed"].apply(lambda text: lemmatize_words(text))<br/>data["text_lemmatized"]</span></pre><div class="mw mx my mz gt ab cb"><figure class="pb is qc pd pe pf pg paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><img src="../Images/8c4833000413a25cfc4aabf784069e86.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*8gsvMLLoId7FELjVqYLfwg.png"/></div></figure><figure class="pb is qd pd pe pf pg paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><img src="../Images/c39bb76c0b752657872f99b6b390ef67.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*9IrX3I-ullWaZo-3g2mGVA.png"/></div></figure><figure class="pb is qe pd pe pf pg paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><img src="../Images/ffb0d6a22d796fbf71aa8dba64c7c792.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/format:webp/1*0X4XbJCyaOxTAv90QErFSQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk qf di qg pk translated">未规范化的列文本、带词干的文本、带词条的文本</p></figure></div><p id="bd12" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="na">观察:词干提取通过移除后缀将单词转换为基本形式。这可能会导致更多的混乱。词汇化将单词转换成语义基础，从而使其可解释。</em></p></div><div class="ab cl lr ls hu lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="ij ik il im in"><p id="ba70" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这些是在文本数据上广泛执行的不同类型的文本预处理步骤。然而，我们不需要一直执行所有这些。我们需要根据我们的用例仔细选择预处理步骤，因为这也起着重要的作用。</p><p id="6d79" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我将继续这篇文章，将这些规范化的标记处理成向量，作为机器学习模型的输入。</p></div><div class="ab cl lr ls hu lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="ij ik il im in"><p id="f92e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">谢谢你的阅读。以后我会写更多初学者友好的帖子。请在<a class="ae jd" href="https://medium.com/@ramyavidiyala" rel="noopener">媒体</a>上关注我，以便了解他们。我欢迎反馈，可以通过 Twitter <a class="ae jd" href="https://twitter.com/ramya_vidiyala" rel="noopener ugc nofollow" target="_blank"> ramya_vidiyala </a>和 LinkedIn <a class="ae jd" href="https://www.linkedin.com/in/ramya-vidiyala-308ba6139/" rel="noopener ugc nofollow" target="_blank"> RamyaVidiyala </a>联系我。快乐学习！</p></div></div>    
</body>
</html>