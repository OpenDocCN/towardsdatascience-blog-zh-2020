<html>
<head>
<title>Emergency vs Non-Emergency Vehicle Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">紧急与非紧急车辆分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/emergency-vs-non-emergency-vehicle-classification-f0153c4f87f8?source=collection_archive---------35-----------------------#2020-06-13">https://towardsdatascience.com/emergency-vs-non-emergency-vehicle-classification-f0153c4f87f8?source=collection_archive---------35-----------------------#2020-06-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d866" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">利用计算机视觉的力量</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/2cc712248630ef4cbfbefb42b107cc9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*D8uKfejRKtJalVrH"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://unsplash.com/@willy_teee?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">拍摄的照片将在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上真实再现</a></p></figure><p id="84a5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于救护车和消防队等紧急车辆的交通延误造成的死亡是一个巨大的问题。在日常生活中，我们经常看到应急车辆在交通中面临通行困难。因此，将车辆分为紧急和非紧急类别可能是交通监控以及自动驾驶汽车系统中的一个重要组成部分，因为准时到达目的地对于这些服务至关重要。</p><p id="700d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了找到这个问题的解决方案，我们将尝试建立一个<em class="ls">图像分类模型</em>，将车辆图像分类为属于紧急车辆或非紧急车辆类别。</p><h1 id="a909" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">获取数据</h1><p id="5d7d" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">我们首先要做的是获取车辆图像的训练和测试数据集。这里，用于构建分类模型的数据集从<em class="ls"> Analytics vidhya，</em>下载，它由紧急和非紧急车辆图像组成，其中紧急车辆通常包括警车、救护车和消防队。</p><p id="4e7a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">完成后，我们可以使用pandas读取提供的训练数据集。</p><p id="0b44" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将使用<em class="ls"> fastai视觉库</em>来构建我们的图像分类模型。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="32de" class="mv lu iq mr b gy mw mx l my mz">from fastai.vision import *</span><span id="2d41" class="mv lu iq mr b gy na mx l my mz">df = pd.read_csv('/content/train.csv')<br/>df.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/e3ad293869bef70fa3e89a1eb9a87196.png" data-original-src="https://miro.medium.com/v2/resize:fit:902/format:webp/1*_XB76l421v-1kJ6a2XGazw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">训练数据框架</p></figure><p id="5f09" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们有两列。包含图像名称的<em class="ls"> image_names </em>列和包含每个图像标签的<em class="ls"> emergency_or_not </em>列。此处<strong class="ky ir"> <em class="ls"> 1 </em> </strong>代表标签<strong class="ky ir">为应急车辆</strong>和<strong class="ky ir"> <em class="ls"> 0 </em> </strong> <strong class="ky ir">为</strong> <strong class="ky ir">非应急车辆。</strong></p><p id="523e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">快速查看数据框为我们提供了足够的信息来加载数据并开始构建我们的<em class="ls">图像分类模型</em>，但在此之前，我们将对图像应用变换，这将有助于我们概化我们的模型，即获得高精度。</p><p id="3833" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将应用的变换有:<em class="ls">do _ flip</em>——默认启用——和<em class="ls"> flip_vert，max_rotate=50。</em>我们还将通过调整<em class="ls"> max_lighting=0.1 </em>和<em class="ls"> max_warp=0来调整灯光。</em></p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="af8a" class="mv lu iq mr b gy mw mx l my mz">tfms= get_transforms(do_flip=True,flip_vert=True,max_rotate=50,max_lighting=0.1,max_warp=0 )</span></pre><p id="a0d3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们已经准备好应用我们的转换，我们可以使用FastAIs <a class="ae kv" href="https://docs.fast.ai/data_block.html" rel="noopener ugc nofollow" target="_blank">数据块api </a>加载数据。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="d3d3" class="mv lu iq mr b gy mw mx l my mz">data = ImageDataBunch.from_df('/content/cars', df,ds_tfms=tfms,label_delim= None,valid_pct=0.2,fn_col=0, label_col=1 , size=299,bs=64).normalize(imagenet_stats)</span></pre><p id="503a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面的<code class="fe nc nd ne mr b">.normalize(imagenet_stats)</code>方法用于根据来自ImageNet数据集的RGB通道的统计数据来标准化数据集。</p><blockquote class="nf ng nh"><p id="52df" class="kw kx ls ky b kz la jr lb lc ld ju le ni lg lh li nj lk ll lm nk lo lp lq lr ij bi translated">归一化所做的是将图像的强度(图像的原始强度在0和255之间)降低到0和1之间。这有助于提高我们模型的计算能力。</p></blockquote><p id="1a86" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们已经加载了数据集，让我们看一看它是什么样子的:</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="8f53" class="mv lu iq mr b gy mw mx l my mz">data.show_batch(rows=3, figsize=(7,7)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/99c4895b28b14b6167a5bf34d0885a3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4OPIJz_OvtggLm_MpWL2MA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="nm">我们知道0代表非紧急车辆，1代表紧急车辆。</em></p></figure><p id="99d6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们也可以通过调用一个告诉我们图像类数量的函数来检查这一点。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="0e23" class="mv lu iq mr b gy mw mx l my mz">print(data.classes)</span><span id="21b2" class="mv lu iq mr b gy na mx l my mz">[0, 1]</span></pre><h1 id="1243" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated"><strong class="ak">训练模特</strong></h1><p id="98bb" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">因为我们已经准备好了数据，所以是时候把它输入到模型中了。我们可以通过从头开始构建卷积神经网络来做到这一点，但这样做实际上是低效的。因此，我们采用预先训练的CNN模型的权重，该模型已经学会识别特征(某些类型的事物，例如梯度、边缘圆等)</p><p id="6205" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里，我们将使用预训练的ResNet50卷积神经网络模型，并使用迁移学习来学习网络的最后一层的权重。</p><h1 id="cf95" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">什么是迁移学习？</h1><p id="79ff" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">迁移学习是从一个现有的(经过训练的)用于图像识别的神经网络开始，然后在这里或那里对其进行一点(或更多)调整，以针对您的特定用例训练一个模型，我们这样做是因为从头训练一个神经网络将意味着需要大约300，000个图像样本，并且为了实现真正的良好性能，我们将需要<em class="ls">至少</em>一百万张图像。但是通过迁移学习，我们可以用有限的数据集和更少的时间获得高性能。</p><p id="0783" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将通过冻结和解冻一些层并对其进行训练来对其进行微调。这是因为顶层学习简单的基本特征，我们不需要训练这些层，而后面的层学习更复杂的特征。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nn"><img src="../Images/b22719101e6d9268c950a4e08d91e4b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*EnDLnT39-a89Tg2p.png"/></div></div></figure><p id="6596" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在上面的图片中，每个不同的层学习图像的不同特征。这种卷积神经网络的后几层学习鸟类眼睛等特征。</p><p id="d15e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们使用<code class="fe nc nd ne mr b">cnn_learner</code>函数来加载预训练的ResNet50网络，该网络是在来自<a class="ae kv" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>数据库的大约一百万张图像上训练的。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="960c" class="mv lu iq mr b gy mw mx l my mz">learn =cnn_learner(data,resnet50,pretrained=True,metrics=[accuracy])</span></pre><p id="d47a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，让我们拟合4个时期的一个周期，看看我们的模型在该数据集上的表现如何:</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="cff0" class="mv lu iq mr b gy mw mx l my mz">learn.fit_one_cycle(4)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/1270829df97788d418890e2bf684f599.png" data-original-src="https://miro.medium.com/v2/resize:fit:1150/format:webp/1*ZYyk_37nBAlsWbZfe4YM_w.png"/></div></figure><p id="a93b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">只使用4个时期的原因是为了了解我们的模型如何执行，并在以后对其进行微调以获得更好的结果。<em class="ls">正如我们可以看到的，我们的验证损失大于我们的训练损失，这清楚地表明我们的模型存在拟合不足的问题。</em></p><p id="fcfc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们来看看我们模型的预测:</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="c038" class="mv lu iq mr b gy mw mx l my mz">interp = ClassificationInterpretation.from_learner(learn)</span></pre><p id="d315" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">解读最大损失:</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="4033" class="mv lu iq mr b gy mw mx l my mz">interp.plot_top_losses(9, figsize=(7,7))</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/08300c0d922523f79cdb4b2707008131.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*cQJKHiSvI0NR7y2AFKkdeg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">我们数据集上的resnet50预测</p></figure><p id="1291" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">看着最大的损失，我们可以告诉我们的模型犯了同样的错误，就像人类第一次看到一些看起来是紧急车辆但被解释为非紧急车辆时会犯的错误一样。</p><p id="f322" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">另一个有用的工具是使用一种叫做混淆矩阵的东西，它基本上显示了每一种实际的紧急和非紧急车辆预测，它被预测了多少次。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="09c6" class="mv lu iq mr b gy mw mx l my mz">`interp.plot_confusion_matrix(figsize=(8,8), dpi=60)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/e54cbe52c5859eea57f48e8f3fcfdaed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bZd0jF9Mq1Nv4OjLgFQJdQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">混淆矩阵</p></figure><p id="89e8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的模型有17次将紧急车辆预测为非紧急车辆，而有4次将非紧急车辆预测为紧急车辆。<em class="ls">困惑呃？毕竟我们正在处理一个混乱矩阵！</em></p><h1 id="21bc" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">解冻</h1><blockquote class="nf ng nh"><p id="c751" class="kw kx ls ky b kz la jr lb lc ld ju le ni lg lh li nj lk ll lm nk lo lp lq lr ij bi translated"><em class="iq">冻结层是指未被训练的层，即未被更新的层。</em></p></blockquote><p id="0f18" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">到目前为止，我们所做的一切都没有改变预先训练的模型权重。我们所做的只是在顶部添加了一些新层，并学习了如何混合和匹配预先训练的功能。</p><p id="1661" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是我们希望模型能够学习我们图像的特定特征。为了做到这一点，我们将解冻一些层，以根据我们的图像更新整个网络的权重。</p><p id="890b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">检测边缘和梯度的第一层和检测曲线和拐角的第二层不需要太多的学习，它们不需要太多的改变。而更后面的层需要改变。当训练其他图像识别时，这是普遍适用的。</p><p id="e65f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">早期的层具有更多通用功能。因此，我们预计他们对新数据集的微调需求会减少。出于这个原因，我们将对不同的层使用不同的学习速率:最初的几个层将位于<code class="fe nc nd ne mr b">1e-4</code>用于基本几何特征和最接近像素的层，而<code class="fe nc nd ne mr b">1e-2</code>如前所述用于我们添加在顶部的层(完全连接的层)。我们称之为<strong class="ky ir"> <em class="ls">差异学习率。</em>T9】</strong></p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="d482" class="mv lu iq mr b gy mw mx l my mz">learn.unfreeze()</span></pre><p id="e8e7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将再次在我们的unfreeze网络上运行fit-one循环，并查看它现在的运行情况。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="8504" class="mv lu iq mr b gy mw mx l my mz">learn.fit_one_cycle(3)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/1f441fec0c05ac27aebaf020e49df5dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*6IjNIhb9Moxy4HFopHlG9w.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="nm"> 92%的准确率不算差，但我们还可以做得更好。</em></p></figure><h1 id="48f2" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">学习率</h1><p id="fc85" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">用于调整我们模型的最重要的超参数是学习率。它通过根据损耗梯度调整网络的权重，帮助我们找到最佳解决方案。该值越低，我们沿下坡行驶的速度越慢。虽然在确保我们不会错过任何局部最小值方面，这可能是一个好主意(使用低学习率),但这也可能意味着我们将需要很长时间才能收敛——特别是如果我们被困在一个平坦区域。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/0020a1beb7fb2f8084ef951a3bc3184b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eeTgFOgUiWibLxaaG_9EBw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">吴恩达在Coursera上的机器学习课程</p></figure><p id="23f4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里我们可以看到学习率对收敛的各种影响。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/a1bbde7695eda35fb329ba714932c605.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zrFmZCZ63v-OFtcgopfKuQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(Img信用:<a class="ae kv" href="http://cs231n.github.io/neural-networks-3/" rel="noopener ugc nofollow" target="_blank"> cs231n </a></p></figure><p id="313a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls">因此，选择正确的学习速度很重要，而不是随意猜测或多次试错。</em></p><p id="0599" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为此，我们将使用一个名为<code class="fe nc nd ne mr b">lr_find()</code>的函数。这个函数是Leslie Smith论文的实现(<a class="ae kv" href="https://arxiv.org/abs/1506.01186" rel="noopener ugc nofollow" target="_blank">用于训练神经网络的循环学习率</a>)。)关于调整神经网络超参数。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="bce1" class="mv lu iq mr b gy mw mx l my mz">learn.lr_find()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/5b8b07049c70563eb226e6426e0bb269.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mgVmcZsuCs4kN5p-bnyjAw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">学习率查找器。</p></figure><p id="9aca" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了更好地理解它，我们将借助另一个函数来绘制它。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="7dfc" class="mv lu iq mr b gy mw mx l my mz">learn.recorder.plot()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/2b78b7726e9805e804c2f035cc8d259b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*mmMgma82xYNV9pdTldLajA.png"/></div></figure><p id="835e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">学习率是相对于损失绘制的。在这个图表的帮助下，我们可以很容易地选择我们的学习速度。</p><p id="bd06" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如我们所见，在<em class="ls"> 1e-03 </em>之后，损失开始增加，因此我们将在此之前选择一个数字，同样为了更新初始层的权重，我们将选择一个较低的学习速率。<em class="ls"> 1e-04 </em>好像不错。</p><p id="a811" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">根据选择的学习率，我们将再次训练我们的解冻模型，但这次要长一点，有10个时期。</p><p id="a04c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将使用准确性作为另一个参数，通常称为<strong class="ky ir"> <em class="ls">指标</em> </strong>来评估我们的模型表现如何。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/ee8ea7bf18b38d23d964a7bfd6bf4a17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1330/format:webp/1*TsyZ-M_LZW5qsWR9osn91w.png"/></div></figure><p id="8fcd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">或者</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/7f38b955d0fa08122d6c449e2fd09caf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L5mR9SF6KrUEM4Nv_y9Qig.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://developers.google.com/" rel="noopener ugc nofollow" target="_blank">https://developers.google.com/</a></p></figure><blockquote class="nf ng nh"><p id="6007" class="kw kx ls ky b kz la jr lb lc ld ju le ni lg lh li nj lk ll lm nk lo lp lq lr ij bi translated">在继续之前，让我们也对<em class="iq"> fit_one_cycle </em>方法有一个直觉。</p><p id="1711" class="kw kx ls ky b kz la jr lb lc ld ju le ni lg lh li nj lk ll lm nk lo lp lq lr ij bi translated"><em class="iq">在这种方法中，我们用两个等长的步骤做一个循环，一个从较低的学习率到较高的学习率，然后回到最小值。最大值应该是用学习率查找器选取的值，较低的值可以低10倍。——再多读一点关于</em><code class="fe nc nd ne mr b"><em class="iq">fit_one_cycle</em></code><em class="iq"/><a class="ae kv" href="https://sgugger.github.io/the-1cycle-policy.html" rel="noopener ugc nofollow" target="_blank"><em class="iq">的内容，尽请查看本博客</em> </a> <em class="iq">。</em></p></blockquote><p id="ccfb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在让我们看看我们的模型做得怎么样？</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="a151" class="mv lu iq mr b gy mw mx l my mz">learn.fit_one_cycle(10,max_lr=slice(1e-4,1e-3))</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/4d35aa8817e7b49a887de100f92b45e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*_77fljDA9YT5UWWzmiQEFQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">准确率达到约97%</p></figure><p id="bd1b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的模型做得足够好，不存在欠拟合，因为我们的模型之前存在这个问题，也不存在过拟合(<em class="ls">过拟合意味着训练损失远低于验证损失)</em>，因为我们的验证损失大约是训练损失的0.02倍。</p><p id="b4ea" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们已经达到了96.96%~ 97%的<strong class="ky ir"> <em class="ls">。</em> </strong></p><p id="0058" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因为我们已经根据我们的车辆分类问题更新了我们模型的权重，我们将冻结我们模型的层，并用名称<em class="ls"> car_classification </em>保存它。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="6cb5" class="mv lu iq mr b gy mw mx l my mz">learn.freeze()</span><span id="abbe" class="mv lu iq mr b gy na mx l my mz">learn.save('car_classification')</span></pre><p id="fe6c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们能够达到大约97%的准确性，同时我们可以在增加时期数量、使用绘图函数找到更优的学习率、更多的数据扩充技术等方面对我们的模型进行更多的实验。</p><h1 id="3a89" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">参考资料:</h1><p id="edfb" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">[1]:<a class="ae kv" href="https://arxiv.org/pdf/1803.09820.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1803.09820.pdf</a></p><p id="f1f3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">【2】:【https://sgugger.github.io/the-1cycle-policy.html T2】</p><p id="4ee4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">【3】:【https://arxiv.org/pdf/1506.01186.pdf T4】</p><p id="ff69" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">【4】:<a class="ae kv" href="https://github.com/fastai/fastai/blob/master/courses/dl1/lesson1.ipynb" rel="noopener ugc nofollow" target="_blank"><em class="ls">第一课笔记本，fast.ai第一部分V2 </em> </a></p></div><div class="ab cl ny nz hu oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="ij ik il im in"><p id="dabf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls">今天的</em>到此结束。💃🏻</p><p id="8859" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls">感谢您的阅读！</em></p></div></div>    
</body>
</html>