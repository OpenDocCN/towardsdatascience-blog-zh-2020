<html>
<head>
<title>State-Of-The-Art Image Classification Algorithm: FixEfficientNet-L2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">最先进的图像分类算法:固定有效网络-L2</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/state-of-the-art-image-classification-algorithm-fixefficientnet-l2-98b93deeb04c?source=collection_archive---------21-----------------------#2020-09-10">https://towardsdatascience.com/state-of-the-art-image-classification-algorithm-fixefficientnet-l2-98b93deeb04c?source=collection_archive---------21-----------------------#2020-09-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6972" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">结合脸书和谷歌人工智能团队的 FixRes 和 EfficientNet</h2></div><p id="c62d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> FixEfficientNet </strong>是一种结合了两种现有技术的技术:脸书人工智能团队【2】<em class="le"/>的<em class="le"> FixRes </em>和谷歌人工智能研究团队首次提出的<em class="le">efficient net</em>【3】。FixRes 是 Fix Resolution 的简称，它试图为用于训练时间的 RoC(分类区域)或用于测试时间的 crop 保持固定的大小。EfficientNet 是 CNN 维度的复合缩放，提高了准确性和效率。本文旨在解释这两种技术，以及为什么它们是最先进的。</p><p id="d208" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">FixEfficientNet 已于 2020 年 4 月 20 日与脸书人工智能研究团队的相应论文一起首次亮相[1]。该技术用于图像分类，是<em class="le">计算机视觉</em>领域的一项任务。它目前是最先进的，在 ImageNet 数据集上具有最好的结果，480M 参数，前 1 名准确率为 88.5%，前 5 名准确率为 98.7%。</p><p id="46fe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但是，让我们更深入一点，以便更好地理解这些组合技术:</p><h1 id="bfc2" class="lf lg it bd lh li lj lk ll lm ln lo lp jz lq ka lr kc ls kd lt kf lu kg lv lw bi translated">理解修复</h1><h2 id="018c" class="lx lg it bd lh ly lz dn ll ma mb dp lp kr mc md lr kv me mf lt kz mg mh lv mi bi translated">训练时间</h2><p id="9876" class="pw-post-body-paragraph ki kj it kk b kl mj ju kn ko mk jx kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">在脸书人工智能研究团队提出 FixRes 技术之前，最先进的技术是从图像中提取随机的像素方块。这被用作<strong class="kk iu">训练时间</strong>的 RoC。(请注意，使用这种技术会人为增加数据量)。然后调整图像大小以获得固定大小的图像(=裁剪)。然后将其输入卷积神经网络[2]。</p><p id="ba81" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">RoC =输入图像中的矩形/正方形<br/> crop =使用双线性插值重新调整到特定分辨率的 RoC 像素</p><h2 id="1d53" class="lx lg it bd lh ly lz dn ll ma mb dp lp kr mc md lr kv me mf lt kz mg mh lv mi bi translated">列车时间尺度增强</h2><p id="0e8a" class="pw-post-body-paragraph ki kj it kk b kl mj ju kn ko mk jx kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">为了更好地理解 FixRes 到底做了什么，让我们来看看数学。改变输入图像中 RoC 的大小会影响给 CNN 的对象大小的分布。对象在输入图像中的尺寸为<strong class="kk iu"> <em class="le"> r x r </em> </strong>。如果 RoC 现在被缩放，那么它被改变 s，并且对象的大小现在连续地是<strong class="kk iu"> <em class="le"> rs x rs </em> </strong>。</p><p id="52b7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于增强，使用 PyTorch 的 RandomResizedCrop。输入图像的尺寸为<strong class="kk iu"><em class="le">H×W</em></strong>，从中随机选择一个 RoC。然后这个 RoC 被调整到一个裁剪尺寸</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/6a27d85d5aa81060ea00fb94b173f997.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*5bghTn6bZu-2FSNiOXhaWw.png"/></div><p class="mw mx gj gh gi my mz bd b be z dk translated">来源:作者图片。</p></figure><p id="414a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">输入图像(<strong class="kk iu"> <em class="le"> H x W </em> </strong>)对输出的裁剪的缩放比例可由以下系数表示:</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi na"><img src="../Images/b34a04cdc8e970bbaf29348faf10ddc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4N4SG0Y_ZElnq1m_xtJPZw.png"/></div></div><p class="mw mx gj gh gi my mz bd b be z dk translated">来源:作者图片。</p></figure><h2 id="1922" class="lx lg it bd lh ly lz dn ll ma mb dp lp kr mc md lr kv me mf lt kz mg mh lv mi bi translated">测试时间</h2><p id="ed54" class="pw-post-body-paragraph ki kj it kk b kl mj ju kn ko mk jx kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">在<strong class="kk iu">测试时间</strong>，RoC 通常位于图像的中心，这导致所谓的<em class="le">中心裁剪</em>。来自训练时间和测试时间的两种裁剪具有相同的大小，但是它们来自图像的不同部分。这往往导致 CNN 的分布出现偏差[2]。</p><h2 id="1f74" class="lx lg it bd lh ly lz dn ll ma mb dp lp kr mc md lr kv me mf lt kz mg mh lv mi bi translated">测试时间尺度增强。</h2><p id="ca9d" class="pw-post-body-paragraph ki kj it kk b kl mj ju kn ko mk jx kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">如前所述，测试增强不同于训练时间增强(关键词中心裁剪)。作物的大小</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/fdbd26b90b319d769176ebb64f52e6ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*oDy6UnwEJohSTP7AEsvT8w.png"/></div></figure><p id="f42b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">关于输入图像是正方形(H=W)的假设，测试增强的比例因子可以表示为</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/c5bbf8fc8200a4caa09350b5da16065d.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*fiZNj3qcPHA6Aq3sto7EYA.png"/></div></figure><p id="6167" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="le">这有什么发现？</em> <br/> </strong>在 FixRes 开发出来之前，测试的预处理和训练时间是分开开发的，这导致了偏差。连续地，脸书人工智能团队试图找到一个解决方案，同时执行预处理，并以某种方式同步，这就是<strong class="kk iu"> FixRes </strong>。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi nh"><img src="../Images/5a5a3dabbe334e9d23ffd53e4e5d9c28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*71nk_IxmUi634Ok0GQg3Cg.png"/></div></div><p class="mw mx gj gh gi my mz bd b be z dk translated">来源:作者图片。</p></figure><p id="7132" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如上所述的标准预处理通常会在训练时扩大 RoC<strong class="kk iu">而在测试时缩小 RoC。</strong></p><p id="ac67" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">FixRes 技术采用<em class="le">非此即彼的方法</em>。它或者降低训练时间分辨率并保持测试裁剪<strong class="kk iu">的大小，或者</strong>增加测试时间分辨率并保持训练裁剪的大小。目的是检索相同大小的对象(这里是乌鸦)以减少 CNN 中的尺度不变性[2]。这看起来像下面这样:</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi ni"><img src="../Images/3cd871ee0ebbb9ce2debe373fb7d510b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nX5IXgkMcYAVT7iJWWE4fQ.png"/></div></div><p class="mw mx gj gh gi my mz bd b be z dk translated">来源:作者图片。</p></figure><p id="3058" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这导致对如何将数据馈送给 CNN 的两个影响:</p><ol class=""><li id="4449" class="nj nk it kk b kl km ko kp kr nl kv nm kz nn ld no np nq nr bi translated">图像中对象(此处为乌鸦)的大小因固定缩放而改变。</li><li id="411b" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld no np nq nr bi translated">不同作物大小的使用对神经元被激活的方式和时间有影响。</li></ol><h2 id="3bff" class="lx lg it bd lh ly lz dn ll ma mb dp lp kr mc md lr kv me mf lt kz mg mh lv mi bi translated">变化激活统计的问题</h2><p id="a1ca" class="pw-post-body-paragraph ki kj it kk b kl mj ju kn ko mk jx kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">Touvron 等人发现，更大的测试作物和最重要的对象大小的调整导致更好的准确性。然而，这是调整对象大小和改变激活统计之间的权衡。</p><p id="5313" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">测试表明，激活图随着图像分辨率的变化而变化。K_test = 224 导致 7×7 的地图，K_test = 64 导致 2×2 的地图，K_test = 448 导致 14×14 的地图。这表明激活分布在测试时变化，并且值在分类器范围之外[1]。</p><p id="806f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了解决激活统计的变化问题，提出了两种解决方案:</p><ol class=""><li id="e558" class="nj nk it kk b kl km ko kp kr nl kv nm kz nn ld no np nq nr bi translated"><strong class="kk iu">参数适应:</strong>参数弗雷歇分布用于拟合平均池层。然后，通过标量变换将新分布映射到旧分布，并作为激活函数应用。</li><li id="ee5a" class="nj nk it kk b kl ns ko nt kr nu kv nv kz nw ld no np nq nr bi translated"><strong class="kk iu">微调:</strong>应用校正的另一种方式是模型的微调。微调仅适用于 CNN 的最后几层。</li></ol><p id="878b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在微调阶段，使用标签平滑[1]。</p></div><div class="ab cl nx ny hx nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="im in io ip iq"><h1 id="d903" class="lf lg it bd lh li oe lk ll lm of lo lp jz og ka lr kc oh kd lt kf oi kg lv lw bi translated">想看更多这样的故事？</h1><h2 id="ad66" class="lx lg it bd lh ly lz dn ll ma mb dp lp kr mc md lr kv me mf lt kz mg mh lv mi bi translated"><a class="ae oj" href="https://medium.com/@hucker.marius/membership" rel="noopener">开始使用</a></h2></div><div class="ab cl nx ny hx nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="im in io ip iq"><h1 id="7103" class="lf lg it bd lh li oe lk ll lm of lo lp jz og ka lr kc oh kd lt kf oi kg lv lw bi translated">高效网络架构[3]</h1><p id="e12c" class="pw-post-body-paragraph ki kj it kk b kl mj ju kn ko mk jx kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">作者预先训练了几个模型，从这些模型中，L2 效率网显示出最好的结果。<strong class="kk iu">但是什么是效率网呢？</strong></p><p id="13da" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与大多数图像分类算法一样，有效网络也是基于细胞神经网络的。如果你不知道 CNN 是什么，<a class="ae oj" href="https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148" rel="noopener">点击这里</a>。CNN 有三个维度:宽度、深度和分辨率。深度是层的数量，宽度是通道的数量(例如，传统的 RGB 将具有 3 个通道)，分辨率是图像的像素。</p><p id="7d58" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">EfficientNets 引入了复合缩放，它利用了所有三个维度:</p><p id="b8a9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">宽度缩放</strong> —可以通过增加图像的通道来增加宽度。然而，精度增益下降得相当快。</p><p id="cb56" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">深度缩放</strong> —是常规且最典型的缩放方式。通过增加深度，可以增加神经网络的层数。但是添加更多的层并不总是能提高网络的性能。大多数情况下，它需要更多的时间，但由于渐变消失，随着层数的增加，性能可能会停滞甚至下降。</p><p id="425d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">分辨率缩放— </strong>这意味着增加分辨率和像素数量，例如从 200x200 增加到 600x600。这种缩放的问题是，精度增益随着分辨率的提高而消失。直到某一点，你的精度可能会增加，但精度增量减少。</p><p id="38c0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所有三个维度的升级会导致精度增量递减，并且所有三个维度的平衡缩放对于实现最佳精度结果是必要的。因此，建议采用复合缩放:</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/85eaf924454111cc6bba1165f7221826.png" data-original-src="https://miro.medium.com/v2/resize:fit:1172/format:webp/1*sl48g07UcWTTKY8RX_vrCA.png"/></div><p class="mw mx gj gh gi my mz bd b be z dk translated">来源:作者图片。</p></figure><p id="8643" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">ɸ指定可用的资源，而阿尔法、贝塔和伽玛负责资源的分配。</p><p id="e4a7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Touvron 等人[1]“使用神经结构搜索来开发新的基线网络，并将其放大以获得一系列模型，称为 EfficientNets。”神经架构搜索(NAS)优化了 FLOPS 和精度。</p><h1 id="c148" class="lf lg it bd lh li lj lk ll lm ln lo lp jz lq ka lr kc ls kd lt kf lu kg lv lw bi translated">结论</h1><p id="0840" class="pw-post-body-paragraph ki kj it kk b kl mj ju kn ko mk jx kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">这两种技术的结合产生了目前图像分类中最好的算法，领先于 EfficientNet Noisy Student。在效率和准确性方面，它都是当前领先的算法。由于其 98.7%的前 5 名准确度，仍有改进的可能性，但它已经相当准确了。因此，它仍然要等待，直到这是一种新的技术取代。</p><p id="b727" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于本文不包含任何实现，您可以使用作者的官方 Github 自行尝试:<a class="ae oj" href="https://github.com/facebookresearch/FixRes" rel="noopener ugc nofollow" target="_blank">http://github.com/facebookresearch/FixRes.</a></p><p id="832b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">作者[1]的预训练网络如下所示</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi ol"><img src="../Images/842a05d3ed84fe14fd1f15aee68f88f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KpEVsz564ctYEwUpaQ029Q.png"/></div></div><p class="mw mx gj gh gi my mz bd b be z dk translated">github 回购截图。</p></figure><p id="dc32" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">我希望你能理解并喜欢它！</strong></p><div class="om on gp gr oo op"><a href="https://medium.com/subscribe/@hucker.marius" rel="noopener follow" target="_blank"><div class="oq ab fo"><div class="or ab os cl cj ot"><h2 class="bd iu gy z fp ou fr fs ov fu fw is bi translated">请继续关注马里乌斯·哈克的新文章</h2><div class="ow l"><h3 class="bd b gy z fp ou fr fs ov fu fw dk translated">请继续关注 Marius Hucker 的新文章。如果您还没有注册，您将创建一个中型帐户…</h3></div><div class="ox l"><p class="bd b dl z fp ou fr fs ov fu fw dk translated">medium.com</p></div></div><div class="oy l"><div class="oz l pa pb pc oy pd mu op"/></div></div></a></div></div><div class="ab cl nx ny hx nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="im in io ip iq"><p id="8804" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="le">参考文献</em> </strong>:</p><p id="50e4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[1]h .图夫龙、a .韦达尔迪、m .杜泽和 h .杰古(2020 年 b)。修正训练-测试分辨率差异。ArXiv:2003.08237 [Cs] 。<a class="ae oj" href="http://arxiv.org/abs/2003.08237" rel="noopener ugc nofollow" target="_blank">http://arxiv.org/abs/2003.08237</a></p><p id="24f2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[2]h .图夫龙、a .韦达尔迪、m .杜泽和 h .杰古(2020 年 a)。修复列车测试分辨率差异。<em class="le">ArXiv:1906.06423【Cs】</em>。<a class="ae oj" href="http://arxiv.org/abs/1906.06423" rel="noopener ugc nofollow" target="_blank">http://arxiv.org/abs/1906.06423</a></p><p id="3350" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[3]谭，米，乐，张庆伟(2020).反思卷积神经网络的模型缩放。<em class="le"> ArXiv:1905.11946 [Cs，Stat] </em>。<a class="ae oj" href="http://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank">http://arxiv.org/abs/1905.11946</a></p></div></div>    
</body>
</html>