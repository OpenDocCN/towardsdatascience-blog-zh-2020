<html>
<head>
<title>How to do a sentiment analysis in real-time using the Jupyter notebook, Kafka and NLTK</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用 Jupyter 笔记本、Kafka 和 NLTK 进行实时情感分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-do-a-sentiment-analysis-in-realtime-using-the-jupyter-notebook-kafka-and-nltk-4470aa8c3c30?source=collection_archive---------25-----------------------#2020-01-27">https://towardsdatascience.com/how-to-do-a-sentiment-analysis-in-realtime-using-the-jupyter-notebook-kafka-and-nltk-4470aa8c3c30?source=collection_archive---------25-----------------------#2020-01-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2778" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">关于将 Kafka 的流数据处理到 Jupyter 笔记本的教程</h2></div><p id="14fc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本文中，我们将讨论如何使用 Jupyter 笔记本对来自 Kafka 集群的数据进行情感分析。</p><p id="d3ff" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将使用:</p><ul class=""><li id="085e" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">kafka: 我们将使用 kafka 的融合版本作为我们的流媒体平台</li><li id="98ba" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">ksql: 这是一项来自 confluent 的技术，它让我们能够在 kafka 的基础上创建表，并使我们能够实时运行 sql 查询。很酷吧？</li><li id="c4b6" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated"><strong class="kk iu"> jupyter 笔记本</strong>:我们运行分析的环境</li><li id="3f8b" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated"><strong class="kk iu"> docker compose: </strong>我们将使用它在本地创建我们自己的 kafka 集群</li><li id="7186" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated"><strong class="kk iu"> NLTK: </strong>使用<a class="ae ls" href="http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf" rel="noopener ugc nofollow" target="_blank"> vader </a>算法的 python 情感分析库</li></ul><p id="c0ca" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">TL；DR:整个项目代码在</strong><a class="ae ls" href="https://github.com/BogdanCojocar/medium-articles/tree/master/jupyter_kafka" rel="noopener ugc nofollow" target="_blank"><strong class="kk iu">Github</strong></a><strong class="kk iu">上。</strong></p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi lt"><img src="../Images/81ca033104c0a3755f9bd949384cb030.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hn6XRE42NwtCVi1MSnQ_BQ.jpeg"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">Pexels.com</p></figure><h2 id="2c29" class="mj mk it bd ml mm mn dn mo mp mq dp mr kr ms mt mu kv mv mw mx kz my mz na nb bi translated">步骤 1:运行 docker compose</h2><p id="20c8" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">在第一步中，我们需要运行 docker compose 来创建我们的 kafka 集群。这将运行一堆 docker 容器，这些容器将创建集群的各种元素，如 zookeeper、brokers、topics、ksql。</p><p id="787b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在简单地说，kafka 是一个分布式流媒体平台，能够处理大量的消息，这些消息被组织成主题。为了能够并行处理一个主题，必须将它分成多个分区，来自这些分区的数据存储在称为代理的独立机器中。最后，zookeeper 用于管理集群中代理的资源。这是卡夫卡经典版本中的元素。合流平台增加了 ksql 作为查询引擎。</p><figure class="lu lv lw lx gt ly"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="6182" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在项目的根目录下运行<code class="fe nj nk nl nm b">docker-compose up</code>将会创建集群。如果一切运行成功，您应该会看到类似下图的内容。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi nn"><img src="../Images/e3f4aab32156c9411586ef7a125affd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CFF1KyuCzfIgE5TBa-TxGQ.png"/></div></div></figure><p id="2bad" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">服务将在端口<code class="fe nj nk nl nm b">8088</code>上运行，kafka 代理将在端口<code class="fe nj nk nl nm b">9092</code>上可用。我们需要这些信息从朱庇特联系到卡夫卡。当你完成集群上的工作时，你可以通过运行<code class="fe nj nk nl nm b">docker-compose down.</code>来停止所有的容器</p><h2 id="ac3d" class="mj mk it bd ml mm mn dn mo mp mq dp mr kr ms mt mu kv mv mw mx kz my mz na nb bi translated">步骤 2:安装附加的依赖项</h2><p id="847c" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">我们正在使用一些以前可能没有用过的 python 包，因此我们需要安装它们。在项目的根，我们有一个<code class="fe nj nk nl nm b">requirements.txt</code>文件。要安装它，请在控制台中运行以下命令:</p><pre class="lu lv lw lx gt no nm np nq aw nr bi"><span id="d937" class="mj mk it nm b gy ns nt l nu nv">pip install -r requirements.txt</span></pre><h2 id="c2fa" class="mj mk it bd ml mm mn dn mo mp mq dp mr kr ms mt mu kv mv mw mx kz my mz na nb bi translated">第三步:运行卡夫卡制作程序</h2><p id="1b58" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">为了能够实时消费数据，我们首先必须将一些消息写入 kafka。我们将使用 python 中的<code class="fe nj nk nl nm b">confluent_kafka</code>库来编写一个生产者:</p><figure class="lu lv lw lx gt ly"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="52fe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将发送一些非常简单的<code class="fe nj nk nl nm b">JSON</code>消息<code class="fe nj nk nl nm b">{ 'data' : value }</code>，其中 value 是预定义列表中的一个句子。对于每条消息，我们写入队列，我们还需要分配一个键。我们将根据<code class="fe nj nk nl nm b">uuid</code>随机分配一个，以在集群中实现良好的分布。最后，我们还运行一个<code class="fe nj nk nl nm b">flush</code>命令来确保所有的消息都被发送出去。</p><p id="2a06" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一旦我们运行<code class="fe nj nk nl nm b">confluent_kafka_producer</code>，我们应该会收到一个日志，告诉我们数据已经正确发送:</p><pre class="lu lv lw lx gt no nm np nq aw nr bi"><span id="7ff5" class="mj mk it nm b gy ns nt l nu nv">we’ve sent 6 messages to 127.0.0.1:9092</span></pre><h2 id="d15f" class="mj mk it bd ml mm mn dn mo mp mq dp mr kr ms mt mu kv mv mw mx kz my mz na nb bi translated">步骤 4:创建 ksql 表</h2><p id="f4cc" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">接下来，我们需要创建 ksql 客户端，它将帮助我们运行该接口的所有命令:</p><pre class="lu lv lw lx gt no nm np nq aw nr bi"><span id="cd9d" class="mj mk it nm b gy ns nt l nu nv">client = KSQLAPI(url='<a class="ae ls" href="http://localhost:8088'" rel="noopener ugc nofollow" target="_blank">http://localhost:8088'</a>, timeout=60)</span></pre><p id="5abe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们现在可以创建一个用于查询数据的表:</p><pre class="lu lv lw lx gt no nm np nq aw nr bi"><span id="0e44" class="mj mk it nm b gy ns nt l nu nv">client.create_table(table_name='test_data',<br/>                   columns_type=['data varchar'],<br/>                   topic='test',<br/>                   value_format='JSON',<br/>                   key='data')</span></pre><p id="2a29" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与我们的<code class="fe nj nk nl nm b">JSON</code>消息类似，该表只有一个名为 data 的字段，类型为<code class="fe nj nk nl nm b">varchar</code>，适合我们的字符串句子。</p><p id="34e2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一旦我们运行了表创建命令，我们就可以通过检查我们有哪些可用的 ksql 表来检查一切是否运行成功:</p><pre class="lu lv lw lx gt no nm np nq aw nr bi"><span id="eb42" class="mj mk it nm b gy ns nt l nu nv">client.ksql('show tables')</span></pre><p id="bf06" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们应该能够看到我们创建的那个:</p><pre class="lu lv lw lx gt no nm np nq aw nr bi"><span id="c66a" class="mj mk it nm b gy ns nt l nu nv">[{'@type': 'tables',<br/>  'statementText': 'show tables;',<br/>  'tables': [{'format': 'JSON',<br/>    'isWindowed': False,<br/>    'name': 'TEST_DATA',<br/>    'topic': 'test',<br/>    'type': 'TABLE'}]}]</span></pre><h2 id="71b5" class="mj mk it bd ml mm mn dn mo mp mq dp mr kr ms mt mu kv mv mw mx kz my mz na nb bi translated">第五步:从卡夫卡那里获得一些结果，并应用情感分析</h2><p id="6d6e" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">我们现在可以在 kafka 上运行<code class="fe nj nk nl nm b">SQL</code>查询。让我们从它那里得到最新的 5 条消息:</p><pre class="lu lv lw lx gt no nm np nq aw nr bi"><span id="45cc" class="mj mk it nm b gy ns nt l nu nv">res = client.query('select * from test_data limit 5')</span></pre><p id="6fe4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了能够更容易地处理这些数据，我们对其进行解析，并将其存储到一个字典中:</p><pre class="lu lv lw lx gt no nm np nq aw nr bi"><span id="88b6" class="mj mk it nm b gy ns nt l nu nv">def parse_results(res):<br/>    res = ''.join(res)<br/>    res = res.replace('\n', '')<br/>    res = res.replace('}{', '},{')<br/>    res = '[' + res + ']'<br/>    return json.loads(res)</span><span id="f75f" class="mj mk it nm b gy nw nt l nu nv">res_dict = parse_results(res)</span></pre><p id="02b0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，我们可以对这 5 个句子运行我们的情感分析算法。如前所述，我们将使用来自<code class="fe nj nk nl nm b">NLTK</code>的预训练<code class="fe nj nk nl nm b">vader</code>算法:</p><pre class="lu lv lw lx gt no nm np nq aw nr bi"><span id="9a62" class="mj mk it nm b gy ns nt l nu nv">def apply_sent(res):<br/>    sent_res = []<br/>    for r in res:<br/>        sid = SentimentIntensityAnalyzer()<br/>        try:<br/>            sent_res.append(sid.polarity_scores(r['row']['columns'][2]))<br/>        except TypeError:<br/>            print('limit reached')<br/>    return sent_res</span><span id="f90a" class="mj mk it nm b gy nw nt l nu nv">send_res = apply_sent(res_dict)</span></pre><p id="94c0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将<code class="fe nj nk nl nm b">TypeError</code>视为已经到达消息列表末尾的信号。我们可以想象结果:</p><pre class="lu lv lw lx gt no nm np nq aw nr bi"><span id="9f20" class="mj mk it nm b gy ns nt l nu nv">[{'compound': 0.6369, 'neg': 0.0, 'neu': 0.323, 'pos': 0.677},<br/> {'compound': 0.6249, 'neg': 0.0, 'neu': 0.423, 'pos': 0.577},<br/> {'compound': -0.5423, 'neg': 0.467, 'neu': 0.533, 'pos': 0.0},<br/> {'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos': 0.0},<br/> {'compound': 0.4215, 'neg': 0.0, 'neu': 0.517, 'pos': 0.483}]</span></pre><p id="d9f9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">每行代表一个句子的结果，情绪可以是积极的、中性的或消极的。就是这个！我们可以看到，只需几个步骤，我们就可以在 Jupyter notebook 中处理和分析实时数据，这种环境对于数据科学家来说很容易使用。</p></div></div>    
</body>
</html>