<html>
<head>
<title>Google’s EfficientDet: An Overview</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Google的EfficientDet:概述</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/googles-efficientdet-an-overview-8d010fa15860?source=collection_archive---------7-----------------------#2020-03-03">https://towardsdatascience.com/googles-efficientdet-an-overview-8d010fa15860?source=collection_archive---------7-----------------------#2020-03-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/f4d8b3fa49f12409990cd772a4a34820.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-FxDl-1hzG3RBC4yCLZo6g.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://pixabay.com/photos/m31-space-astronomy-astronomical-3613931/" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><div class=""/><div class=""><h2 id="059c" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">使用网络优化网络</h2></div><p id="9dfc" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你像我一样，读了谷歌的EfficientDet论文，你会问“到底发生了什么？”。不要担心，我已经审阅了论文，并将尽我所能解释这个模型。</p><p id="0a1b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个模型建立在以前的工作(像许多其他模型一样)之上，更具体地说，是一项被称为EfficientNet的关键工作:</p><ol class=""><li id="e336" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated"><a class="ae jg" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank"> EfficientNet:反思卷积神经网络的模型缩放</a></li></ol><p id="f2ca" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在我们深入研究谷歌新的目标检测模型的细节之前，让我们先做一下EfficientNets的背景工作。</p><h1 id="f3f8" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">效率网</h1><p id="4ad8" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">本文作者关注如何有效地扩展卷积神经网络(ConvNets)以提高性能。缩放网络以提高性能的典型方法是增加以下之一:网络深度、宽度或图像分辨率。虽然有可能将两个或更多的这些一起缩放，但是目前这是一个冗长的过程，并且通常导致模型具有次优的准确性和效率。下面是不同缩放方法的图示，直接摘自该论文:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi na"><img src="../Images/876cba65132a5e10c870a79fa4b8cd22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O1TZKZjafr9qqkxHxkJmAQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">缩放神经网络模型的方法。摘自<a class="ae jg" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank">谭&amp;乐2019 </a></p></figure><p id="4146" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">作者旨在回答这个问题:</p><blockquote class="nf ng nh"><p id="6f83" class="ky kz ni la b lb lc kk ld le lf kn lg nj li lj lk nk lm ln lo nl lq lr ls lt im bi translated">有没有一种原理性的方法可以提高网络的精度和效率？</p></blockquote><p id="f1fa" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可能已经猜到了，但答案是肯定的。他们发现平衡网络宽度/深度/分辨率的所有维度非常重要。让你吃惊的是他们的缩放方法的简单性。他们只是用一个恒定的比例来缩放每个维度。就是这样！他们称这种方法为<em class="ni">复合缩放</em>。随着用于训练神经网络的图像变得更大，复合缩放开始变得有意义，因为更大的图像需要更深的网络来增加感受域，并需要更多的通道来捕捉更大图像中的更小细节。</p><p id="0b8b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们很快发现，模型缩放带来的性能提升在很大程度上依赖于基线网络。作者更进一步，使用一种叫做神经结构搜索(NAS)的算法来寻找最佳基线网络。在给定目标函数的情况下，高级NAS算法使用强化学习来确定最佳结构。使用NAS创建了一个新的模型系列，称为<em class="ni"> EfficientNets。</em>在ImageNet数据集上将这些模型的性能与ConvNets进行了比较，结果如下图所示:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nm"><img src="../Images/c6bfe8575d2b7710869cadffda00fadd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HULYxxE5gEvJM1zkvcwaBQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">与其他分类器相比，EfficientNet系列的性能。摘自<a class="ae jg" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank">谭&amp;乐2019 </a></p></figure><p id="d186" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从这些结果中引人注目的是，这些模型在准确性和参数数量方面都优于其他先进模型。作者还表明，这些模型可以很好地转移到其他数据集，在8个公开可用的数据集中，有5个成为得分最高的模型，同时参数减少了21倍。</p><h2 id="9e8f" class="nn me jj bd mf no np dn mj nq nr dp mn lh ns nt mp ll nu nv mr lp nw nx mt ny bi translated">复合模型缩放</h2><p id="43d1" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">那么复合缩放实际上是如何工作的呢？首先，让我们将ConvNet定义为:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/02b38ad05fa4ae7bd3cd8fa88d7f73f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*ZUrBoI0iMYGj9oTMHX5E1g.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank">谭&amp;乐，2019 </a>一个共网的定义</p></figure><p id="f2be" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">他们本质上将其描述为由应用于输入张量的运算(例如卷积)组成的层列表。</p><p id="e707" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">复合缩放试图扩展网络长度(Lᵢ)、宽度(Cᵢ)和/或分辨率(Hᵢ、Wᵢ)，而不改变基线网络中预定义的Fᵢ。固定Fᵢ的基本原理是为了减少设计空间，但考虑到Lᵢ、Cᵢ、Hᵢ和Wᵢ仍然可以探索每一层，设计空间仍然相当大。为了进一步减小设计空间，施加了一个限制，即所有层必须以恒定的比率均匀缩放。复合缩放的目标是在给定资源约束的情况下最大化模型的准确性，这被公式化为一个优化问题:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oa"><img src="../Images/fe3618154544ff7aac4b8088d0d9cd1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1p0Pay6d3kcM8ihOyGF5ew.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">复合扩展的目标是优化系统资源约束。摘自摘自<a class="ae jg" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank">谭&amp;乐，2019 </a></p></figure><p id="e26f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">w、d和r是用于缩放网络宽度、深度和分辨率的系数。预定义参数的符号上方有一个^。预定义网络的示例如下所示:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nm"><img src="../Images/9aa943050a13a5514208e5c8ed42b7eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ukpDZBACQYB04CJ639EyZA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">预定义的高效网络。摘自<a class="ae jg" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank">谭&amp;乐2019 </a></p></figure><h2 id="7a0a" class="nn me jj bd mf no np dn mj nq nr dp mn lh ns nt mp ll nu nv mr lp nw nx mt ny bi translated">缩放尺寸</h2><p id="2493" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">扩展ConvNet的深度(d)、宽度(w)和分辨率(r)的难点在于，这三者相互依赖，并且会在不同的资源限制下发生变化。因此，通常只在一个维度上缩放。</p><p id="d778" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">深度:</strong>缩放深度是缩放ConvNet最常见的方式。网络变得更深，因为更深的网络可以提取更丰富和更复杂的特征。不利的一面是，由于梯度消失的问题，更深的凹网更难训练。这个问题通过跳过连接和批量标准化得到了缓解，但是对于非常深的网络来说，回报是递减的。</p><p id="a467" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">宽度:</strong>通常用于较小的车型。这些网络通常更擅长捕获图像的细粒度特征，并且更容易训练。</p><p id="0553" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">分辨率:</strong>提高图像的输入分辨率，ConvNets可以捕捉图像中的细粒度模式。早期的con vnet在224x224上训练，而较新的con vnet在480x480上训练。下图显示了分别扩展这些维度的性能(在预定义的网络上执行扩展，如上所示):</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ob"><img src="../Images/a4b7faf05beb4e0cc1c894bda530aca6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6Gzj-COzKtNeEZqmCYWSyw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">通过单独扩展每个维度来提高性能。左边是宽度，中间是深度，右边是分辨率。摘自<a class="ae jg" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank">谭&amp;乐2019 </a></p></figure><p id="c2fa" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这一结果的主要观察结果表明，扩大网络的深度、宽度和分辨率可以提高精度，但对于更深、更大的模型，精度会降低。</p><h2 id="3ac0" class="nn me jj bd mf no np dn mj nq nr dp mn lh ns nt mp ll nu nv mr lp nw nx mt ny bi translated"><strong class="ak">复合缩放</strong></h2><p id="6355" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">到目前为止，显而易见的是，标度维数不是独立的。例如，作者指出:</p><blockquote class="nf ng nh"><p id="d702" class="ky kz ni la b lb lc kk ld le lf kn lg nj li lj lk nk lm ln lo nl lq lr ls lt im bi translated">更高分辨率的图像应该需要更深的网络，以便更大的感受野可以在更大的图像中捕获包括更多像素的类似特征。</p></blockquote><p id="e806" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">作为提高分辨率的结果，网络宽度也应该增加以捕捉更精细的细节。这些直觉表明，模型需要在所有这些维度上进行缩放，而不是在单一维度上。为了验证他们的直觉，作者在深度(d)和分辨率(r)的不同组合上测量了网络的宽度(w)(下图)。下图中的缩放示例从基线网络(d=1.0，r=1.0)开始，有18个分辨率为224x224的卷积层。最后一个基线网络(d=2.0，r=1.3)产生36个卷积层，分辨率为299x299。</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oc"><img src="../Images/83edf2b95da55881a0bb00b81e92e8d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bjMt-6DBRVZmdRvPUOpbQg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">扩展网络宽度。每条线代表由图例中定义的系数缩放的不同作品。每条线上的一点显示不同的宽度。该网络是从前面显示的预定义网络扩展而来的。摘自<a class="ae jg" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank">谭&amp;乐2019 </a></p></figure><p id="8a38" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这一结果使作者观察到，为了获得更好的模型精度和效率，在缩放过程中平衡网络的所有维度是重要的。根据这一观察，他们提出了一种复合缩放方法。该方法使用复合缩放系数φ来统一缩放网络尺寸:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div class="gh gi od"><img src="../Images/2602beeccda24ddea8df71da6bd7128a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*VenHeRHg_b8ZxCdVzwdw-A.png"/></div></figure><p id="c906" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在等式中，α、β和γ是常数，可以通过网格搜索来确定。用户定义的系数(φ)控制如何为模型缩放分配资源。而α、β和γ分别定义了如何将这些资源分配给网络的宽度、深度和分辨率。</p><p id="ee82" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">通过缩放现有的ConvNets来评估缩放方法。为了真正利用这种新方法，一个名为<strong class="la jk"> EfficientNet的新架构家族应运而生。</strong>他们通过使用NAS优化准确性和FLOPS来构建基线网络。他们的研究产生了一个叫做<strong class="la jk"> EfficientNet-B0 </strong>的高效网络。下表说明了EfficientNet-B0网络(它与前面显示的预定义网络完全相同):</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nm"><img src="../Images/9aa943050a13a5514208e5c8ed42b7eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ukpDZBACQYB04CJ639EyZA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">高效网络-B0网络。摘自<a class="ae jg" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank">谭&amp;乐2019 </a></p></figure><p id="14af" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">他们的下一步是通过分两步应用复合扩展来扩展EfficientNet-B0:</p><ol class=""><li id="bd29" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">将φ固定为1。对α、β和γ进行网格搜索。他们发现EfficentNet-B0的最佳值为α = 1.2，β = 1.1，γ = 1.15。</li><li id="c468" class="lu lv jj la b lb oe le of lh og ll oh lp oi lt lz ma mb mc bi translated">将α、β和γ固定为常数，并按比例放大不同φ的基线网络，以获得到B7的有效Net-B1。</li></ol><p id="48a8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下表显示了这些新网络与其他先进网络相比的性能:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oj"><img src="../Images/b69934fbf34bfb3b47cfd956c62f6985.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0OXNgk2hTz75J_V6_sKrFQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">EfficinetNet模型系列与其他分类器相比的性能。摘自<a class="ae jg" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank">谭&amp;乐2019 </a></p></figure><p id="7943" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">与现有的ConvNets相比，EfficientNets的性能始终更好，并且减少了参数和触发器的数量。下表和下图进一步证实了这一点:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ok"><img src="../Images/03184073894de07a0b6af6ff6bde21fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1ZEXh6k3wB_oNB2wU4UjjQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">通过高效网络实现的速度提升。摘自<a class="ae jg" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank">谭&amp;乐2019 </a></p></figure><p id="4bc6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">与ResNet-152相比，EfficientNet-B1的CPU延迟快5.7倍，尽管它们具有相当的准确性。在精确度范围的顶端，GPipe模型对于数据集上具有84.3%精确度的单个图像具有19.0秒的延迟。最大的EfficientNet型号(B7)只有3.1秒的延迟，这是6.1倍的加速。下图显示了FLOPS与Imagenet Top-1精度的对比。</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ol"><img src="../Images/990ab42762e4570972fa43c2b0107f7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IIF3wW5OO5az4lVTnQHWvg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">与其他分类器相比，EfficientNet模型系列的FLOPS。摘自<a class="ae jg" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank">谭&amp;乐，2019 </a></p></figure><p id="f8ba" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该图清楚地显示了EfficientNet系列更好地利用了可用资源，该模型在准确性方面表现更好，并且显著减少了FLOPS的数量。</p><p id="669d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">单维缩放</strong></p><p id="031c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了消除复合缩放方法对EfficientNet架构的影响，B0架构仅在一维上进行缩放。这些结果如下图所示:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi om"><img src="../Images/0ed17aee2f0986dc354513b3d2feaa4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ERo1Htpy6YCvqpq5yJXHcg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">用不同的方法扩展EfficientNet-B0网络。摘自<a class="ae jg" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank">谭&amp;乐2019 </a></p></figure><p id="ff9e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">显而易见，复合比例远远优于单一维度的比例，后者很快导致收益递减。这突出了复合缩放的重要性。为了进一步理解为什么复合缩放如此有效，下图比较了一系列缩放B0模型的类激活图:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi on"><img src="../Images/d8da923b6fba18de472c16f32bf4883e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4HmJtR1uDuoV_XOvQQwJFQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">不同缩放方法的类激活图。显示复合缩放提供了更多相关的激活。摘自<a class="ae jg" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank">谭&amp;乐2019 </a></p></figure><p id="4e8d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">复合缩放模型倾向于关注具有更多相关对象细节的区域。其他型号对这些细节关注较少。</p><p id="59de" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">总体而言，本文作者表明，在给定一组资源约束的情况下，平衡网络深度、宽度和分辨率对于优化性能至关重要。复合缩放方法提供了一种在所有这些维度上有效缩放模型的优雅方式。这就引出了本文的下一部分，Google的EfficientDet，它建立在上面讨论的工作之上。</p><h1 id="4e49" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">EfficientDet:可扩展且高效的对象检测</h1><p id="e223" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">近年来，在对象检测方面取得了巨大的进步，产生了更精确的模型，但代价是增加了计算量。这些巨大的计算成本将阻碍它们在许多现实世界应用中的部署，例如自动驾驶汽车，其中低延迟预测是必要的。在这样的约束下，模型效率对于对象检测来说非常重要。模型检测器架构，如一级和无锚检测器更有效，但通常以精度为代价。因此，人们自然会问:</p><blockquote class="nf ng nh"><p id="9d96" class="ky kz ni la b lb lc kk ld le lf kn lg nj li lj lk nk lm ln lo nl lq lr ls lt im bi translated">是否有可能建立一个可扩展的检测架构，同时具有更高的准确性和更好的效率？</p></blockquote><p id="c22a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Google的EfficientDet旨在解决这个问题，要回答这个问题，我们首先需要了解当前物体探测器设计选择的挑战:</p><p id="9684" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">挑战1——高效的多尺度特征融合:</strong>特征金字塔网络(FPN)广泛用于多尺度特征融合。最近的工作，如PANet和NAS-FPN允许跨尺度特征融合。先前的特征融合方法简单地将特征相加在一起，然而，这些特征具有不同的分辨率，并且已经观察到对输出融合特征的贡献不相等。为了解决这个问题，提出了加权双向特征金字塔网络。BiFPN具有可学习的权重来确定不同输入特征的重要性，其应用自顶向下和自底向上的多尺度特征融合。</p><p id="a105" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">挑战2 -模型缩放:</strong>对象检测器的模型缩放通常会牺牲准确性或效率。受EfficientNets作者所做工作的启发，提出了一种用于对象检测器的复合缩放方法。像EfficientNets一样，这种缩放方法也可以缩放网络的深度、宽度和分辨率。</p><p id="cca3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">EfficientNet与提议的BiFPN和复合缩放的结合创造了一个新的检测机系列，称为<strong class="la jk"> EfficientDet </strong>。与以前的物体检测器相比，该系列模型始终实现了更高的精度，并将触发器数量减少了一个数量级。EfficentDet对目标探测社区的贡献可以总结为三点:</p><ul class=""><li id="19c7" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt oo ma mb mc bi translated">BiFPN简介。这是一个加权的双向特征网络，便于进行多尺度特征融合</li><li id="e0ed" class="lu lv jj la b lb oe le of lh og ll oh lp oi lt oo ma mb mc bi translated">提出一种缩放方法，以原则方式缩放主干、特征网络、盒/类网络和分辨率</li><li id="a0e0" class="lu lv jj la b lb oe le of lh og ll oh lp oi lt oo ma mb mc bi translated">结合以上两点，产生了EfficientDet，一种新的物体检测器系列。这些模型在广泛的资源限制范围内具有更好的准确性和效率</li></ul><h2 id="423c" class="nn me jj bd mf no np dn mj nq nr dp mn lh ns nt mp ll nu nv mr lp nw nx mt ny bi translated">BiFPN</h2><p id="15e2" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">为了理解BiFPN的贡献，我们需要首先将问题公式化。多尺度特征融合旨在聚合不同分辨率的特征。这可以表示为多尺度特征的列表:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div class="gh gi op"><img src="../Images/594c2d2004f3e60375818788301edf6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*UmMDvzqm6-TVCgh3_6crqw.png"/></div></figure><p id="c333" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其中上面的每个元素代表lᵢ.级别的特征目标是找到一个转换<em class="ni"> f </em>，它可以聚集特性并输出一系列新特性:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/d4b56fbec9508ad6f6f33a26bb2fdb94.png" data-original-src="https://miro.medium.com/v2/resize:fit:548/format:webp/1*ZUE2oI-Ywq31JdVuPLUjdA.png"/></div></figure><p id="ce96" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了理解这一点的重要性，我们来看一下传统的FPN，它集成了不同尺度的功能:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div class="gh gi or"><img src="../Images/40587b673a423cef38b43ed318c2f4a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*lVcEcC3zZt5NRn5pGb8YZg.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">传统的FPN网络。摘自<a class="ae jg" href="https://arxiv.org/abs/1911.09070" rel="noopener ugc nofollow" target="_blank"> <em class="os">谭等著2019年</em> </a></p></figure><p id="a173" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">它有3–7个输入要素(P₃ - P₇)，其中每个输入要素代表一个具有给定分辨率的要素级别。该FPN以自上而下的方式聚合多尺度要素:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/a809ada571f984f45519e8fe660dd778.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*aMTmVKz4YmbInPuCglbSsg.png"/></div></figure><p id="ac56" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="ni"> Resize </em>通常是分辨率匹配的上采样或下采样操作。最后，<em class="ni"> Conv </em>是用于特征处理的卷积运算。</p><p id="8059" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">上面显示的FPN固有地受到信息单向流动的限制。为了解决这个问题，PANet增加了一个自下而上的路径，NAS-FPN使用神经架构搜索来寻找更好的跨尺度特征网络拓扑。下图显示了这两种网络设计:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ou"><img src="../Images/bba4ce12e7f52d5d7dfe4e1ebaa94686.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ey0-MXNDpGkt692qHdfvYA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">三种不同的FPN结构。★2019<em class="os"><a class="ae jg" href="https://arxiv.org/abs/1911.09070" rel="noopener ugc nofollow" target="_blank"><em class="os">谭等。</em></a></em></p></figure><p id="f1c1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">作者表明，PANet比NAS-FPN获得了更好的精度，但代价是更多的参数和计算。提出了几项优化措施:</p><ol class=""><li id="2f30" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">移除只有一条输入边的结点。如果某个结点只有一条输入边，且没有要素融合，则该结点对要素网络目标的贡献可能较小。这导致了一个简化的面板(见上图)</li><li id="8352" class="lu lv jj la b lb oe le of lh og ll oh lp oi lt lz ma mb mc bi translated">从输入节点到输出节点只在同一层增加一条额外的边。这将融合更多的功能，而不需要太多的额外成本</li><li id="58bc" class="lu lv jj la b lb oe le of lh og ll oh lp oi lt lz ma mb mc bi translated">存在双向信息流(自上而下和自下而上)。每个双向路径被视为其自己的层，因此允许这些层重复，从而实现更高级别的特征融合(BiFPN，如下)</li></ol><p id="8871" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">通过这些优化，新的特征网络被命名为<strong class="la jk">双向特征金字塔网络(BiFPN)。</strong>BIF pn如下图所示:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ov"><img src="../Images/85fc5184c3fe656d2dea10af482a0cef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qH6d0kBU2cRxOkWUsfgDgg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">BiFPN结构。摘自<a class="ae jg" href="https://arxiv.org/abs/1911.09070" rel="noopener ugc nofollow" target="_blank"> <em class="os">谭等译2019 </em> </a></p></figure><p id="4417" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">加权特征融合</strong></p><p id="e8e7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如前所述，不同分辨率的特征融合通常包括调整它们的大小，然后进行求和运算。这种方法的缺点是所有特征都被同等对待。由于这些特征具有不同的分辨率，它们通常对输出特征的贡献是不相等的。为了解决这个问题，计算每个输入特征的额外权重，以允许网络学习每个特征的重要性。总共测试了三种加权融合方法:</p><ol class=""><li id="4536" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated"><strong class="la jk">无界融合</strong>:包含一个无界可学习权重。但是，因为它是无界的，所以会导致训练不稳定，所以被丢弃</li><li id="c9a8" class="lu lv jj la b lb oe le of lh og ll oh lp oi lt lz ma mb mc bi translated"><strong class="la jk">基于Softmax的融合</strong>:对每个权重应用softmax，从而将权重限制在0到1之间，但这导致延迟显著增加。</li><li id="77cf" class="lu lv jj la b lb oe le of lh og ll oh lp oi lt lz ma mb mc bi translated"><strong class="la jk">快速归一化融合</strong>:等式如下。通过Relu的应用，确保每个权重(ωᵢ)大于或等于零。ϵ设置为0.001以避免数值稳定性。与基于softmax的方法相比，这种计算在GPU上要快30%。</li></ol><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/b7ea508624bb6f4ea785d70edfd679c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*Uq9tNsDPaDip2JSRwdWZAA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">快速标准化融合。摘自<a class="ae jg" href="https://arxiv.org/abs/1911.09070" rel="noopener ugc nofollow" target="_blank"> <em class="os">谭等著2019 </em> </a></p></figure><p id="adae" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最终的BiFPN集成了双向跨尺度连接和快速归一化方法。这方面的一个例子如下所示，它是BiFPN中的第6层:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ox"><img src="../Images/f29c5a23e97393ecd1867491cce25a33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nGOQTmbwG5sBcOXVBsBDog.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">P6层中跨尺度连接的集成示例。摘自<a class="ae jg" href="https://arxiv.org/abs/1911.09070" rel="noopener ugc nofollow" target="_blank"> <em class="os">谭等译2019 </em> </a></p></figure><p id="1ba6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">上面的等式是自上而下路径的中间等式，下面的等式是自下而上路径的等式。</p><h2 id="f489" class="nn me jj bd mf no np dn mj nq nr dp mn lh ns nt mp ll nu nv mr lp nw nx mt ny bi translated">效率检测</h2><p id="8300" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">随着BiFPN的发明，一种新的检测器系列被创造出来，称为EfficientDet。EfficientDet的架构如下所示，使用EfficientNet作为主干网络。</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oy"><img src="../Images/3382c16e40f6f1d1ed39ed9359ecb6f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VzvR1mA57JQpB0gmeCoeWQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">具有EfficientNet主干和BiFPN结构的EfficientDet架构。摘自<a class="ae jg" href="https://arxiv.org/abs/1911.09070" rel="noopener ugc nofollow" target="_blank"> <em class="os">谭等著2019年</em> </a></p></figure><p id="c000" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该网络中的BiFPN用作特征网络。它从主干网络中提取第3 - 7层的特征，并重复应用BiFPN。融合后的特征被输入到一个类和盒网络中，以预测物体的类和包围盒。</p><p id="5815" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">复合缩放</strong></p><p id="b8c3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">受EfficientNets中复合缩放的启发，提出了一种新的复合缩放目标检测方法。该方法使用系数(φ)来联合放大主干网络、BiFPN网络、类/箱网络和分辨率的所有维度。每个网络组件的扩展描述如下:</p><ul class=""><li id="15ab" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt oo ma mb mc bi translated"><strong class="la jk">主干网络:</strong>使用B0-B6中定义的相同系数，以便可以重复使用其ImageNet预训练权重</li><li id="678f" class="lu lv jj la b lb oe le of lh og ll oh lp oi lt oo ma mb mc bi translated"><strong class="la jk"> BiFPN: </strong>宽度呈指数增长(通道)，深度呈线性增长(层)。形式上，宽度和深度使用以下等式进行缩放:</li></ul><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/5ba396e9cc1441b45f18d05446297091.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/format:webp/1*f3oJDRf1yn_ZSacqJCUOAA.png"/></div></figure><ul class=""><li id="44c8" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt oo ma mb mc bi translated"><strong class="la jk">框/类预测网络:</strong>宽度固定为与BiFPN中相同，但深度线性增加，如下所示:</li></ul><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/ad268918b5f7d0fe45a70ccfd24fa83b.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*rsXshLVt_Pqjh5s2jXyoSA.png"/></div></figure><ul class=""><li id="da1d" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt oo ma mb mc bi translated"><strong class="la jk">输入图像分辨率:</strong>由于分辨率必须能被2⁷ = 128整除，因此分辨率也线性增加。这是通过以下等式实现的:</li></ul><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/0f0beadec2cc8982b9da71e076d277dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*twjpbh4kbR0EmtnF2QLkiQ.png"/></div></figure><p id="54ca" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用上面所示的三个等式，创建了从efficient det-D0(φ= 0)到D6(φ= 6)的家族网络。下表进一步阐述了这一点:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pc"><img src="../Images/0cf2b789ca842e860e6150ad1d6e0a8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RhHtIKqXP03hmfXGqactTw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">不同EfficientDet模型的架构总结。摘自<a class="ae jg" href="https://arxiv.org/abs/1911.09070" rel="noopener ugc nofollow" target="_blank"> <em class="os">谭等著2019 </em> </a></p></figure><p id="0ff5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该表还包含一个D7模型，除非更改批量大小或其他设置，否则该模型无法放入内存。结果，通过仅增加输入图像分辨率，D6模型被扩展到D7。</p><p id="6505" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">性能</strong></p><p id="8ecd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这些型号与其他探测器相比如何？下表显示了EfficientDet系列与按精度分组的其他型号的比较:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi na"><img src="../Images/fb4393d19d7d864b55881b3c557d7aca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZFUuSD0gKB5zf5Lq0XpIqg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">与其他检测机相比，EfficientDet系列型号的性能。摘自<a class="ae jg" href="https://arxiv.org/abs/1911.09070" rel="noopener ugc nofollow" target="_blank">【谭】等著2019  </a></p></figure><p id="4051" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">与以前的检测机相比，EfficientDet系列型号在各种精度水平和资源限制下实现了更高的精度和效率。</p><p id="45d8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了了解BiFPN对模型性能的贡献，下表比较了主干网和BiFPN的影响:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pd"><img src="../Images/9f077c045148ddda2957d32f013c37d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nstd-JMS-PY7V04cx1dl0w.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">EfficientDet模型中每个组件的贡献(根据mAP)。摘自<a class="ae jg" href="https://arxiv.org/abs/1911.09070" rel="noopener ugc nofollow" target="_blank"> <em class="os">谭等著2019年</em> </a></p></figure><p id="2464" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">很明显，强主干结构提高了性能，但是BiFPN的增加不仅通过增加mAP而且通过减少参数和触发器的数量进一步提高了性能。另一个关键的补充是加权连接。与其他fpn相比，加权连接如何影响性能:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pe"><img src="../Images/62c176667468b281afd222e47891dfb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3SkdCSyBTIM1LgpHO3v7wQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">加权连接对地图的影响。摘自<a class="ae jg" href="https://arxiv.org/abs/1911.09070" rel="noopener ugc nofollow" target="_blank"> <em class="os">谭等译2019 </em> </a></p></figure><p id="d9da" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可以看到，受到单向信息流限制的普通FPN精确度最低。PANet和NAS-FPN模型显示了更高的精度，但需要更多的参数和触发器。总体而言，BiFPN以更少的参数和触发器实现了最佳精度。</p><h1 id="5c4e" class="md me jj bd mf mg mh mi mj mk ml mm mn kp mo kq mp ks mq kt mr kv ms kw mt mu bi translated">结论</h1><p id="2717" class="pw-post-body-paragraph ky kz jj la b lb mv kk ld le mw kn lg lh mx lj lk ll my ln lo lp mz lr ls lt im bi translated">EfficientDet网络深受EfficientNet模型工作的启发。使用复合缩放，与其他现代对象检测模型相比，该模型在准确性和效率方面的性能都得到了提高。事实证明，EfficientDet系列模型在GPU和CPU上具有显著的加速性能，这对于要求低延迟的应用程序来说至关重要。我相信我们正在进入一个目标探测发展的阶段，在这个阶段优化当前的模型将变得至关重要。我们总是可以建立更大更深的模型以获得更高的精确度，但是我们能优化它们以充分利用它们吗？</p></div></div>    
</body>
</html>