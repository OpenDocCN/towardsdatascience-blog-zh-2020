<html>
<head>
<title>A Practical Guide to Convolutional Neural Networks (CNNs) with Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">带有 Keras 的卷积神经网络实用指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-practical-guide-on-convolutional-neural-networks-cnns-with-keras-21421172005e?source=collection_archive---------47-----------------------#2020-05-02">https://towardsdatascience.com/a-practical-guide-on-convolutional-neural-networks-cnns-with-keras-21421172005e?source=collection_archive---------47-----------------------#2020-05-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="88b0" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">理论解释和实际例子</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/dc15887e56f572ff4ffe918d91a8db94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BtJMTj7qr9KkEVBLv_BN_w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">马库斯·斯皮斯克在<a class="ae ky" href="https://unsplash.com/s/photos/guide?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="5068" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">卷积神经网络通常用于数据科学领域，尤其是计算机视觉和图像分类任务。考虑一个图像分类任务。图像由用数字表示的像素组成。在 CNN 的卷积层中，滤波器(或特征检测器)被应用于图像，以通过保持像素之间的空间关系来提取图像的独特特征。</p><p id="f696" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">卷积运算如下进行:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/909e84972f0e1a50fb3f93c878cd45d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WYy0aQ7TL4kOjRfqQxJL0A.png"/></div></div></figure><p id="8972" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们有一个 10x10 的图像和一个 3x3 的过滤器。过滤器从黄色标记的位置开始，扫描图像并创建特征图。在每一步，计算图像像素和滤波器的点积，并将结果标量放入特征图的相应位置。</p><blockquote class="lw lx ly"><p id="0715" class="kz la lz lb b lc ld ju le lf lg jx lh ma lj lk ll mb ln lo lp mc lr ls lt lu im bi translated"><strong class="lb iu">步幅</strong>参数控制滤镜的移动。当跨距为 1 时，过滤器每次移动 1 个像素。</p></blockquote><p id="00b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">过滤器的目标是保持像素的空间关系，因此它需要看到左侧、右侧、上方和底部的像素。因此，对于 3×3 滤波器，我们从第二行第二列的像素开始。第一行和最后一行上的像素以及第一列和最后一列上的像素不能是特征地图的一部分，因为它们没有上下左右相邻像素。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi md"><img src="../Images/774d4403ddfd80ccbed0e99ea04b93e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:618/format:webp/1*WlspYGp6Lo4co17s1QSoWQ.png"/></div></figure><p id="712f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是生成的特征图是 8×8 的原因。如果我们应用一个 5x5 的过滤器，特征图就变成了 6x6。</p><blockquote class="lw lx ly"><p id="1b5d" class="kz la lz lb b lc ld ju le lf lg jx lh ma lj lk ll mb ln lo lp mc lr ls lt lu im bi translated">如果我们想保留边界上的像素，我们可以使用<strong class="lb iu">填充</strong>并在图像周围添加零。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi me"><img src="../Images/ecba5f8e53fce2165d464eb420bacb3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*6AMolCn2isBxUZK3GF1lrA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">用零填充的 10x10 图像。生成的图像为 12x12。</p></figure><p id="0d2e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在卷积层中，不仅仅使用一个过滤器。许多不同的过滤器被应用于图像。每个过滤器旨在捕捉不同的特征，如边缘、水平线等。</p><p id="2e80" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图像是高度非线性的，所以我们需要增加卷积层的非线性。在卷积层中，应用<strong class="lb iu">整流器函数</strong>来增加图像中的非线性。整流器功能充当额外的滤波器来分解线性。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/4a5ce052f82f4abe93e92518a06e0d1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*MBqK5zJHal71NqUJf4QbAw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">卷积层</p></figure><p id="c856" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们有<strong class="lb iu">池</strong>层，它减少了特征地图的大小，同时保持图像的保留特征。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/d34171d678cf5d829db33bb04cfcfdbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/format:webp/1*HMl3wnWZWAw3KG20riiS8w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">2x2 盒子的最大池</p></figure><p id="1347" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在池层中，捕获一个具有指定大小的框，并获取该框中的最大值。这是最大池。我们也可以取盒子里数值的和或平均值。该框扫描整个特征地图。上图显示的是带有 2x2 方框的 max pooling 图层，因此要素地图的大小缩小为 4x4。</p><p id="961a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">联营的优势:</p><ul class=""><li id="2a56" class="mh mi it lb b lc ld lf lg li mj lm mk lq ml lu mm mn mo mp bi translated">在保留特征的同时减小尺寸</li><li id="e6a3" class="mh mi it lb b lc mq lf mr li ms lm mt lq mu lu mm mn mo mp bi translated">删除不重要的部分</li><li id="9845" class="mh mi it lb b lc mq lf mr li ms lm mt lq mu lu mm mn mo mp bi translated">引入空间方差</li><li id="84b9" class="mh mi it lb b lc mq lf mr li ms lm mt lq mu lu mm mn mo mp bi translated">减少特征的数量，从而降低过度拟合的风险</li></ul><blockquote class="lw lx ly"><p id="f832" class="kz la lz lb b lc ld ju le lf lg jx lh ma lj lk ll mb ln lo lp mc lr ls lt lu im bi translated">在卷积神经网络中，根据任务的复杂程度，有多个卷积层和池层。</p></blockquote><p id="a8c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们需要展平合并的要素地图，以便将其提供给完全连接的图层。在展平步骤之后，卷积神经网络的剩余部分的结构就像前馈神经网络一样。展平步骤非常简单。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/f9749897a0e4f7e81f0e127833a11ab9.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*U4vYCB8DK2ta7YYOXbrimw.png"/></div></figure><p id="2430" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">展平后得到的阵列被用作一个<strong class="lb iu">密集</strong>层的输入。汇集的要素地图被展平，并通过密集图层传送。卷积神经网络的典型结构是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mw"><img src="../Images/fff293357945e7f1d58d1fca7db08cbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3BRLw4lsANPEfGgimG3YVQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Convolutional_neural_network#/media/File:Typical_cnn.png" rel="noopener ugc nofollow" target="_blank">图来源</a></p></figure><p id="fcb0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，子采样用于池化。这个卷积神经网络有两个卷积层和两个池层。</p><p id="9a01" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们来看一个真实的例子。</p><h1 id="65fa" class="mx my it bd mz na nb nc nd ne nf ng nh jz ni ka nj kc nk kd nl kf nm kg nn no bi translated"><strong class="ak">建立 CNN 对图像进行分类</strong></h1><p id="8897" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">我们将使用来自 Caltech101 数据集的摩托车和飞机图像。这是训练和测试 CNN 的一个很好的数据集。非常感谢社区准备并让我们使用这个数据集。</p><p id="800f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用 Keras，这是一个基于 TensorFlow 构建的高级深度学习库。让我们从基本的导入开始:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="925e" class="nz my it nv b gy oa ob l oc od">import numpy as np<br/>import tensorflow as tf</span><span id="c36f" class="nz my it nv b gy oe ob l oc od">tf.__version__<br/>'2.2.0-rc3'</span></pre><p id="4929" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用谷歌 colab 环境来完成这项任务。我把照片保存到了我的谷歌硬盘里。为了从 colab 直接访问驱动器中的文件，我们只需要导入驱动器:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="1e73" class="nz my it nv b gy oa ob l oc od">from google.colab import drive<br/>drive.mount('/content/gdrive')</span></pre><p id="2eef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这将提示我们通过复制粘贴链接来批准。然后我们就可以轻松访问 google drive 里的文件了。</p><p id="71ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们使用 matplotlib 检查几张图像:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="d86a" class="nz my it nv b gy oa ob l oc od">import matplotlib.pyplot as plt<br/>import matplotlib.image as mpimg</span><span id="08fd" class="nz my it nv b gy oe ob l oc od">%matplotlib inline</span></pre><p id="e453" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图像只是 2D(黑白)和 3D(彩色)中的数字阵列。除了看图像的样子，我们还应该检查图像的结构。</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="3dce" class="nz my it nv b gy oa ob l oc od">img = mpimg.imread('/content/gdrive/My Drive/airplane_motorbike/train/airplanes/image_0001.jpg')</span><span id="625f" class="nz my it nv b gy oe ob l oc od">type(img)<br/>numpy.ndarray</span><span id="9d4f" class="nz my it nv b gy oe ob l oc od">img.shape<br/>(164, 398, 3)</span></pre><p id="9c51" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">前两个维度显示像素网格的大小，第三个维度指示它是彩色的还是灰度的。所以这个图像是一个 164x398 像素的彩色图像。如果最后一个维度为 1，则图像为灰度。让我们看看它是什么样子的:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="1192" class="nz my it nv b gy oa ob l oc od">imgplot = plt.imshow(img)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/e934f3146de72f5ea77b7376fd8a1a9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*RQ9qFZFYuMd5htNyTTgrBA.png"/></div></figure><p id="87df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们再来看一张摩托车的图片:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="55a6" class="nz my it nv b gy oa ob l oc od">img2 = mpimg.imread('/content/gdrive/My Drive/airplane_motorbike/train/motorbikes/image_0001.jpg')</span><span id="13dc" class="nz my it nv b gy oe ob l oc od">print(img2.shape)<br/>(161, 262, 3)</span><span id="8c69" class="nz my it nv b gy oe ob l oc od">imgplot = plt.imshow(img2)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/c03e96dbb5c0701a7123b2e4c2453d43.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*L0M7MKiMqAMGyLbYrrok8g.png"/></div></figure><p id="7052" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可能已经注意到像素的数量是不同的。摩托车图像的形状是(161，262，3)，而飞机图像的形状是(164，398，3)。这些图像必须与 CNN 中使用的形状相同。我们可以手动调整尺寸，但这是一项繁琐的任务。</p><p id="7bd6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以使用 Keras 的图像预处理类<strong class="lb iu"> ImageDataGenerator </strong>。我们只需要在一个文件夹结构中组织图像，ImageDataGenerator 将处理其余的工作:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/e668c32f6959e1eddcec9ba40571414c.png" data-original-src="https://miro.medium.com/v2/resize:fit:460/format:webp/1*ExeJcVkwb_4DYItWOGUSeg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">文件夹结构</p></figure><p id="276f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ImageDataGenerator 通过实时数据扩充生成批量张量图像数据。ImageDataGenerator 通过成批应用随机选择和变换(如旋转和移动)来创建许多批图像。所以它增加了数据集的多样性。数据扩充增加了数据的多样性，这是非常有用的，尤其是当图像的数量有限时。增加数据集的多样性有助于获得更准确的结果，还可以防止模型过度拟合。</p><p id="fa2a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图像在“飞机”和“摩托车”文件夹中。我把每个类别的 640 张图片放在 train 文件夹中，160 张图片放在 validation 文件夹中。让我们为训练和验证实现 ImageDataGenerator 对象:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="a86d" class="nz my it nv b gy oa ob l oc od">from tensorflow.keras.preprocessing.image import ImageDataGenerator</span><span id="75bb" class="nz my it nv b gy oe ob l oc od">import os</span></pre><p id="87b7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们首先为训练集和验证集创建 ImageDataGenerator 对象:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/a0ca3b1c13fe6ee85c07903d2a0adbcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*g5AMZbNaiHv4tQQygOSDlw.png"/></div></figure><p id="6f97" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们传入 rescale 参数来归一化[0，1]范围内的像素值。数据规范化是神经网络中的一项基本实践。</p><p id="0dec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们指出包含图像的文件的路径:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/bb8d4ee8e3b80104fe675b35f73d93c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EILJbGXVThemktFoEUj8qg.png"/></div></div></figure><p id="43e6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们创建训练和验证生成器:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/61e7f20f8064230c88748efb7d86fc53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*C7DHCHrbxEnXVAb7myHwSg.png"/></div></figure><p id="5784" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们使用了<strong class="lb iu"> flow_from_directory </strong>方法。另一种选择是使用<strong class="lb iu">流量</strong>方法。在<a class="ae ky" href="https://keras.io/preprocessing/image/" rel="noopener ugc nofollow" target="_blank"> keras 文档</a>中详细解释了每种方法的细节。</p><p id="f02e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们检查一下参数。第一个是我们在上一步中已经创建的文件路径。<strong class="lb iu">目标尺寸</strong>表示结果图像的尺寸。训练和验证生成器会将所有图像的大小调整为 150x150 像素。<strong class="lb iu"> Batch_size </strong>是一批图像的数量。<strong class="lb iu"> class_mode </strong>是二进制的，因为我们有两个类。正如我们在输出中看到的，train 文件夹中有 1280 个图像，validation 文件夹中有 320 个图像，属于两个类。</p><p id="5c8b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">是时候建立我们的模型了:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/426174b35bdd02dfa260f8f8cabaf30c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*UlO1Zw8kwiDxKPzNkWh3Jg.png"/></div></div></figure><p id="231c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们有 3 个卷积层和一个池层紧接着每个卷积层。在第一个卷积层，我们定义了过滤器的数量和过滤器的大小。我选择使用 16 个大小为 3x3 的滤镜。然后我们定义<strong class="lb iu">激活函数</strong>为 relu。对于第一个卷积层，我们还需要定义<strong class="lb iu">输入形状</strong>，因为模型不知道我们图像的大小。对于池层，我们只需要指定用于池的盒子的大小。</p><p id="7944" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于其他卷积层，我们遵循相同的过程。唯一的区别是，我们不必指定输入形状，因为模型将从上一层的输出中知道输入。</p><blockquote class="lw lx ly"><p id="6786" class="kz la lz lb b lc ld ju le lf lg jx lh ma lj lk ll mb ln lo lp mc lr ls lt lu im bi translated">仅第一个卷积图层需要 Input_shape。</p></blockquote><p id="38f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后我们有<strong class="lb iu">展平</strong>层来展平合并的特征地图。展平的特征地图被输入到一个<strong class="lb iu">密集</strong>层。然后我们有一个输出层。</p><blockquote class="lw lx ly"><p id="7b24" class="kz la lz lb b lc ld ju le lf lg jx lh ma lj lk ll mb ln lo lp mc lr ls lt lu im bi translated">重要的是要注意，没有严格的规则来确定滤波器的数量、滤波器的大小、层中神经元的数量等等。这些参数的值根据经验或反复试验来调整。您可以调整并尝试不同的值。</p></blockquote><p id="e4db" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们刚刚建立了一个 CNN 模型。使用<strong class="lb iu">总结</strong>方法查看模型概述:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="cc47" class="nz my it nv b gy oa ob l oc od">model.summary()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/4cb39079a9461adb783a1776fed278a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/1*F_BOOe44smco09DAmb7Yyg.png"/></div></figure><p id="f2c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输入图像的尺寸为 150x150。我们使用 3×3 的过滤器，所以特征图的大小是 148×148。在第一个池层中，大小减少了一半。在每个卷积池图层对中，尺寸会减小，但图像中的特征会保留。在这个模型中，我们有超过 200 万个参数要训练，这是一个很大的数目。这是一个简单的图像分类任务。想象一下在非常复杂的任务中训练模型所使用的参数的数量。</p><p id="8020" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在是编译模型的时候了:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/a590d7b36fbbeb5baa67eb5f736a21b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/1*STS1BLgsCLVQ2WZZJN6j_w.png"/></div></figure><p id="8a0f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们需要指定<strong class="lb iu">损失函数</strong>、<strong class="lb iu">优化器</strong>和<strong class="lb iu">度量</strong>来评估性能。对于损失函数，可以使用二元交叉熵，因为这是二元分类任务。Keras 中有很多<a class="ae ky" href="https://keras.io/optimizers/" rel="noopener ugc nofollow" target="_blank">优化器，常用的有</a>、<strong class="lb iu"> RMSprop </strong>和<strong class="lb iu">亚当</strong>优化器。我们使用的衡量标准是准确性。</p><p id="c94c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们完成了图像的预处理，模型的建立和编译。现在，我们可以将数据拟合到模型中并对其进行训练:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/3fe3fde0fbed99d200b46dead2078b34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*QVjrPI4XLMrHpsfrNmkUUw.png"/></div></figure><p id="2eea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们使用之前创建的 ImageDataGenerator 对象作为训练集和验证集。<strong class="lb iu"> Steps_per_epoch </strong>参数是图像数量除以批量大小。<strong class="lb iu"> Validation_steps </strong>使用验证集中的图像数量和批量大小进行类似计算。当模型通过整个训练集时，一个<strong class="lb iu">时期</strong>完成。我使用 5 个历元，但是你可以改变它，看看它如何影响精度。让我们看看结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/9d39ebce07fcb4b57e2352d564a28f3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AhDMTEp56mbWtWcH-VqJ4g.png"/></div></div></figure><p id="fcfe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该模型在训练集上有 99.69%的准确率，在测试集上有 99.37%的准确率，这是一个很好的结果。请记住，这是一个简单的图像分类任务。我们将处理更复杂的任务。但是，后面构建网络和逻辑的方式是一样的。因此，如果我们很好地学习基础知识，我们可以很容易地适应更复杂的任务。</p></div><div class="ab cl op oq hx or" role="separator"><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou"/></div><div class="im in io ip iq"><p id="cb32" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢您的阅读。如果您有任何反馈，请告诉我。</p><h1 id="8f59" class="mx my it bd mz na nb nc nd ne nf ng nh jz ni ka nj kc nk kd nl kf nm kg nn no bi translated"><strong class="ak">参考文献</strong></h1><ul class=""><li id="31cf" class="mh mi it lb b lc np lf nq li ow lm ox lq oy lu mm mn mo mp bi translated">By Aphex34 —自己的作品，CC BY-SA 4.0，<a class="ae ky" href="https://commons.wikimedia.org/w/index.php?curid=45679374" rel="noopener ugc nofollow" target="_blank">https://commons.wikimedia.org/w/index.php?curid=45679374</a></li><li id="d7dd" class="mh mi it lb b lc mq lf mr li ms lm mt lq mu lu mm mn mo mp bi translated">长度飞飞、r .弗格斯和 p .佩罗娜。<em class="lz">从少量训练示例中学习生成视觉模型<br/>:在<br/> 101 个对象类别</em>上测试的增量贝叶斯方法。IEEE。CVPR 2004，基于视觉的生成模型研讨会。2004</li></ul></div></div>    
</body>
</html>