<html>
<head>
<title>Poke-Agent: Pokemon Battling &amp; Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Poke-Agent:口袋妖怪战斗和机器学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/poke-agent-pokemon-battling-reinforcement-learning-27ef10885c5c?source=collection_archive---------11-----------------------#2020-03-01">https://towardsdatascience.com/poke-agent-pokemon-battling-reinforcement-learning-27ef10885c5c?source=collection_archive---------11-----------------------#2020-03-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="906d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">机器学习模型已经在许多游戏中击败了人类——但不是口袋妖怪。让我们解决这个问题。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/05ff8c122d4e2abaa8fc2cc7ff350201.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*01yHHEj-V-2Vb5mh"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/@filmape?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">杰伦</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="47d9" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated"><strong class="ak">定义问题</strong></h1><p id="56d5" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">口袋妖怪战斗包括选择每个回合的最佳移动，给定两个队的当前状态。最好的方法是使用超级有效的方法，或者换成另一个口袋妖怪(如果你希望自己的口袋妖怪有超级有效的方法)。</p><p id="e138" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">学习玩口袋妖怪是一项复杂的任务，即使对人类来说也是如此，所以我们将在本文中关注一个机制:<a class="ae kv" href="https://www.polygon.com/pokemon-sword-shield-guide/2019/11/16/20968169/type-strength-weakness-super-effective-weakness-chart" rel="noopener ugc nofollow" target="_blank">类型有效性</a>。</p><p id="f134" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">场景:</strong>我们会给模型 Poke-Agent 一个<a class="ae kv" href="https://bulbapedia.bulbagarden.net/wiki/Squirtle_(Pokémon)" rel="noopener ugc nofollow" target="_blank">杰尼龟</a>，让它试着打败一个<a class="ae kv" href="https://bulbapedia.bulbagarden.net/wiki/Charmander_(Pokémon)" rel="noopener ugc nofollow" target="_blank">小火龙</a>。杰尼龟将会知道<a class="ae kv" href="https://bulbapedia.bulbagarden.net/wiki/Scratch_(move)" rel="noopener ugc nofollow" target="_blank">抓伤</a>、<a class="ae kv" href="https://bulbapedia.bulbagarden.net/wiki/Growl_(move)" rel="noopener ugc nofollow" target="_blank">咆哮</a>和<a class="ae kv" href="https://bulbapedia.bulbagarden.net/wiki/Water_Gun_(move)" rel="noopener ugc nofollow" target="_blank">水枪</a>，做出最佳策略只是垃圾水枪，因为，作为一个水型招式，它对像小火龙这样的火型口袋妖怪是超级有效的。</p><p id="faac" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">还有其他策略可以赢，比如发 Scratch 或者综合使用这三种策略，但是，由于这些策略的风险，这些策略会导致更多的损失。最佳策略将在 3 个回合中获胜。</p><h1 id="fc9b" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated"><strong class="ak">学习</strong></h1><p id="a0b9" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">由于 Poke-Agent 正在进行口袋妖怪战斗，我们可以将它的经历分为状态和动作。游戏的状态(剩余的血量，场上有什么口袋妖怪等等。)将通知 Poke-Agent 将采取什么行动。因此，我们可以让 Poke-Agent 为每个状态-动作配对分配一个值，以指示某个动作对于特定状态有多好:值越高，该动作对于该状态越好。当它需要做出决定时，它可以只选择价值最高的动作。</p><p id="360a" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这个过程是一种叫做<a class="ae kv" href="https://blog.valohai.com/reinforcement-learning-tutorial-part-1-q-learning" rel="noopener ugc nofollow" target="_blank"> Q-Learning </a>的强化学习，前面提到的值叫做 Q-values。当我们想要更新这些 Q 值时，我们使用这个函数:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mp"><img src="../Images/14a54aaed0266773176f55159c15ff68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ADBlnn9l9mOfokCO9OO0cA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">q-学习更新功能</p></figure><p id="fc91" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这可能看起来令人生畏，但它的直觉很简单。体验之后，我们会根据模型是否表现出想要的行为给予奖励。我们将更新模型经历的状态-动作对的 Q 值，方法是给它加上我们期望在下一个状态得到的奖励。</p><p id="cb27" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">因此，如果模型执行了一个导致预期结果的动作，例如使用水枪赢得口袋妖怪战斗，我们期望在执行该动作后获得奖励，因此该状态和动作的 Q 值增加。对于消极的结果来说，情况正好相反，比如输掉一场战斗:我们会期待消极的回报，因此该状态和行动的 Q 值会降低。</p><p id="77f7" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们将使用 MSE ( <a class="ae kv" href="https://www.freecodecamp.org/news/machine-learning-mean-squared-error-regression-line-c7dde9a26b93/" rel="noopener ugc nofollow" target="_blank">均方差</a>)作为我们的损失函数:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/1b09d064c8ded2a7fb07f719176217ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*FQczsTc7ym5ewgdz0Encdw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">均方误差</p></figure><p id="4bd6" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">其中 Yᵢ是旧的 q 值，ŷᵢ是新的 q 值。</p><h1 id="b02b" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated"><strong class="ak">架构</strong></h1><p id="37e5" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">通常，Q 值保存在内存中的一个表中，然而，口袋妖怪战斗有太多不同的状态-动作对，难以处理。相反，我们将使用神经网络来学习游戏的表示，它可以用来计算好的 Q 值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/25f87dcb5455c49ea119cd59ac00414b.png" data-original-src="https://miro.medium.com/v2/resize:fit:878/format:webp/1*_XkDuiqhPKHiPMLOE9Skcw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">戳代理体系结构</p></figure><p id="1780" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我决定保持 Poke-Agent 的架构简单，直到它看起来需要更复杂。</p><p id="6190" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">输入:</strong>首先，每个回合的事件将被转换成向量，并用作模型的输入。</p><p id="2780" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">嵌入:</strong>回合信息将被传递到一个嵌入层，以便模型可以创建口袋妖怪战斗中概念的表示(口袋妖怪名称、招式、状态条件等。)希望这种表示将相似的概念组合在一起:杰尼龟<em class="ms">和水枪</em>的表示应该相似。</p><p id="a17b" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">线性:</strong>这一层将是实际计算 Q 值的地方——它封装了模型的决策过程。</p><p id="0e8e" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">输出:</strong>线性层将为模型可以采取的每个动作生成 Q 值。我们将把最高值解释为它想要做出的决定。</p><p id="d5ed" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">PyTorch 代码如下:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="b6fd" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><code class="fe mv mw mx my b">vocab_size</code>是口袋妖怪中的概念数。这是一个口袋妖怪，移动，状态条件和战斗事件名称的汇编。</p><p id="6fbb" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><code class="fe mv mw mx my b"><a class="ae kv" href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)" rel="noopener ugc nofollow" target="_blank">nn.ReLU</a></code>是一个<a class="ae kv" href="https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0" rel="noopener">激活函数</a>，允许模型学习复杂的概念。</p><h1 id="bbe7" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">环境</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mz"><img src="../Images/aa0df7caea61668a0316281d67bbad4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ltUDg2WdkZ9DBPByk-Bxqg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://play.pokemonshowdown.com" rel="noopener ugc nofollow" target="_blank">口袋妖怪对决</a></p></figure><p id="1f57" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">口袋妖怪摊牌是一个在线口袋妖怪战斗模拟器，我们将用它来模拟战斗。</p><h1 id="960a" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">培养</h1><p id="d336" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们将有两个代理:扑克代理，和一个随机代理，它只选择随机移动。</p><p id="708b" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">以下是培训过程:</p><ol class=""><li id="36e4" class="na nb iq lq b lr mk lu ml lx nc mb nd mf ne mj nf ng nh ni bi translated">举例说明两个代理之间的战斗</li><li id="b0b5" class="na nb iq lq b lr nj lu nk lx nl mb nm mf nn mj nf ng nh ni bi translated">随着时间的推移，随着双方代理人做出决策，让接下来的战斗展开</li><li id="79bd" class="na nb iq lq b lr nj lu nk lx nl mb nm mf nn mj nf ng nh ni bi translated">使用最后 2 个回合作为 Poke-Agent 的输入来更新其 Q 值</li><li id="17c5" class="na nb iq lq b lr nj lu nk lx nl mb nm mf nn mj nf ng nh ni bi translated">重复</li></ol><p id="5cf9" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们只使用最后两轮，因为那时我们可以根据模型是否获胜来分配奖励。</p><p id="cd7e" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">大约 80 场战斗后，训练损失如下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/7b2507c45c415b0765e4a8fdbb52607f.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*aqSH0xmWt-YJlmcKD2QCbw.png"/></div></figure><p id="e006" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">起初，由于随机代理人和扑克代理人基本上都是随机选择移动，所以很公平。在大约 50 场战斗中，这个模型了解到水枪会带来快速的胜利。每场战斗的平均回合数从 10 到 3，每次都是扑克玩家获胜。</p><p id="5b83" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">不幸的是，我没有一个关于~ 58 战发生了什么导致训练损失如此之大的解释。也许那是它得知水枪的时候！</p><h1 id="89ca" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated"><strong class="ak">最终想法</strong></h1><p id="df78" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">看到损失下降，扑克经纪人开始持续赢钱，真是令人鼓舞！就概念和架构而言，要与人类进行一场真正的口袋妖怪战斗还有很长的路要走。</p><p id="fe06" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">现在，这个模型只对当前的游戏状态做出决定，但是给这个模型一系列的转折来做决定可能是有用的。让它从一系列动作中学习，而不是像目前的训练模式那样只从一个动作中学习，这也是很有趣的。</p><p id="341f" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">仍然有许多研究需要深入和实施，还有许多实验需要尝试。我将教 Poke-Agent 更高级的策略，比如如何切换— <a class="ae kv" href="https://twitter.com/caleb_dre" rel="noopener ugc nofollow" target="_blank">在 twitter 上关注我</a>关注下一篇文章。</p><div class="np nq gp gr nr ns"><a href="https://twitter.com/caleb_dre" rel="noopener  ugc nofollow" target="_blank"><div class="nt ab fo"><div class="nu ab nv cl cj nw"><h2 class="bd ir gy z fp nx fr fs ny fu fw ip bi translated">凯勒·刘易斯</h2><div class="nz l"><h3 class="bd b gy z fp nx fr fs ny fu fw dk translated">凯勒·刘易斯的最新推文(@caleb_dre)。我烘焙&amp;写代码，方程(有时候)，还有@fold_app 的手机…</h3></div><div class="oa l"><p class="bd b dl z fp nx fr fs ny fu fw dk translated">twitter.com</p></div></div><div class="ob l"><div class="oc l od oe of ob og kp ns"/></div></div></a></div></div></div>    
</body>
</html>