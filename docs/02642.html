<html>
<head>
<title>A quick guide to distributed training with TensorFlow and Horovod on Amazon SageMaker</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">亚马逊 SageMaker 上 TensorFlow 和 Horovod 分布式培训快速指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-quick-guide-to-distributed-training-with-tensorflow-and-horovod-on-amazon-sagemaker-dae18371ef6e?source=collection_archive---------7-----------------------#2020-03-14">https://towardsdatascience.com/a-quick-guide-to-distributed-training-with-tensorflow-and-horovod-on-amazon-sagemaker-dae18371ef6e?source=collection_archive---------7-----------------------#2020-03-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f057" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解分布式培训是如何工作的，以及 Amazon SageMaker 如何让它像在笔记本电脑上培训一样简单</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/05e4541ddd6b5dcf3971ac3a6c9a9a8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8ZQEO4BfflwU6IzYJgfZIQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用<code class="fe ky kz la lb b">horovod</code>和 Amazon SageMaker 在多个 GPU 上分发培训，以实现更快的培训和更高的生产率</p></figure><p id="fc63" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">在深度学习中，越多越好。更多的数据、更多的层和更多的计算能力通常会导致更高的准确性和更好的模型鲁棒性。</p><p id="b227" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">我可能无法帮助你<a class="ae ly" href="https://registry.opendata.aws/" rel="noopener ugc nofollow" target="_blank">收集更多数据</a>，但我可以展示你如何在大量机器上进行分布式训练，以更快地训练和运行更多实验，并提高你的生产率。</p><p id="742e" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">在这篇博文中，我将介绍如何在不管理基础设施的情况下运行分布式培训——无需启动实例、设置集群、管理存储卷，也无需构建容器。带上你的训练脚本，指定 GPU 的数量，让 Amazon SageMaker 处理剩下的事情。</p><p id="130c" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">在本指南的第一部分，我将提供一步一步的指导来更新您的训练脚本，以使用<a class="ae ly" href="https://horovod.readthedocs.io/en/latest/#" rel="noopener ugc nofollow" target="_blank"> Horovod </a>库。为了使分布式训练工作，不同 GPU 上的训练过程需要通信。Horovod 实现了这种无缝的通信，并提供了一个方便的 API 来为分发培训准备您的培训脚本。您所做的更改与 GPU 的数量无关，因此这是一次性的工作。</p><p id="bb3a" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">在本指南的第二部分，我将展示如何使用 Amazon SageMaker 在任意数量的 GPU 上运行更新后的训练脚本，或者只需修改一行代码。</p><p id="f37c" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">想在阅读的时候跟着阅读并运行示例吗？Jupyter 笔记本和培训脚本可从以下网址获得:</p><blockquote class="lz ma mb"><p id="6b25" class="lc ld mc le b lf lg ju lh li lj jx lk md lm ln lo me lq lr ls mf lu lv lw lx im bi translated"><a class="ae ly" href="https://github.com/shashankprasanna/distributed-tensorflow-horovod-sagemaker" rel="noopener ugc nofollow" target="_blank">https://github . com/shashankprasanna/distributed-tensor flow-horovod-sage maker</a></p></blockquote><h1 id="d83f" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">Horovod 和环全归约方法</h1><p id="43af" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">Horovod 是一个分布式深度学习框架，支持流行的深度学习框架——tensor flow、Keras、PyTorch 和 Apache MXNet。本指南中的示例使用 TensorFlow 和 Keras。如果您是 PyTorch 或 MXNet 用户，更新您的脚本将遵循与这里描述的非常相似的过程。Horovod 文档页面也包含了大量其他框架的例子。</p><p id="8679" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">在分布式训练中，多个进程需要相互通信。为了实现训练过程之间的通信，Horovod 使用一种称为消息传递接口(MPI)的通信协议。为了平均梯度和更新模型的所有副本，它使用了一种称为 ring-all reducce 的方法(我们将回到这一点)。这些方法并不新鲜，在高性能计算(HPC)领域工作的科学家、研究人员和工程师已经使用了多年，以解决计算流体动力学、分子动力学、计算机图形学和其他领域的问题。</p><p id="88a0" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">MPI 本身定义了在集群中的多个进程之间发送和接收信息的基本概念，例如<code class="fe ky kz la lb b">allreduce</code>、<code class="fe ky kz la lb b">allgather</code>和<code class="fe ky kz la lb b">broadcast</code>。正如你可能已经从它们的名字中推断出的那样——<code class="fe ky kz la lb b">allgather</code>从所有过程中收集数据(在深度学习的情况下，是梯度)。广播，将数据(梯度)从一个进程广播到所有其他进程。<code class="fe ky kz la lb b">allreduce</code>(从概念上讲)结合了这两种操作—从所有过程中收集数据，执行归约操作(例如，平均梯度)，然后广播(平均梯度)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/51b82f00a4064bb1530b6ec636d2eb14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2DJs_qQeiVyOQ0TV"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在 3 台各有 2 个 GPU 的机器上使用 6 个进程的 ring allreduce 的图示。rank 是全局唯一 ID，而 local rank 是每个 GPU 的本地唯一 ID</p></figure><p id="c5ae" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">随着训练进程数量的增加，进程间通信也会增加，通信开销开始影响扩展效率。</p><p id="ccda" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated"><code class="fe ky kz la lb b">ring all-reduce</code>方法通过使通信成本独立于系统中的进程数量，对传统的<code class="fe ky kz la lb b">allreduce</code>方法进行了改进。它通过在逻辑环中安排进程来实现这一点，其中每个进程只接收来自其“左”邻居的数据，并向其“右”邻居发送数据，如附图所示。</p><p id="f255" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">深度学习的<code class="fe ky kz la lb b">ring-allreduce</code>过程在<a class="ae ly" href="https://eng.uber.com/horovod/" rel="noopener ugc nofollow" target="_blank"> Horovod 博文</a>和<a class="ae ly" href="https://arxiv.org/pdf/1802.05799.pdf" rel="noopener ugc nofollow" target="_blank"> Horovod 论文</a>中有更详细的描述。要使用 horovod 库，你并不真的需要知道<code class="fe ky kz la lb b">ring-allreduce</code>是如何工作的，但是对你使用的算法和库如何工作有一个直觉总是有帮助的。</p><p id="6a8d" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">要使用 update your training script 来使用 Horovod 库，您首先需要了解以下关键概念:</p><ul class=""><li id="d6be" class="ne nf it le b lf lg li lj ll ng lp nh lt ni lx nj nk nl nm bi translated"><strong class="le iu">大小:</strong>进程/GPU 总数。这等于集群中计算实例的数量乘以每个实例的 GPU 数量。例如，如果您有 2 个<code class="fe ky kz la lb b">p3.16xlarge</code> EC2 实例。大小应该是 2(实例)x 8(GPU)= 16。</li><li id="0760" class="ne nf it le b lf nn li no ll np lp nq lt nr lx nj nk nl nm bi translated"><strong class="le iu">等级:</strong>唯一的进程 ID(大小— 1)。GPU 中的每个进程都知道自己的唯一级别。</li><li id="de33" class="ne nf it le b lf nn li no ll np lp nq lt nr lx nj nk nl nm bi translated"><strong class="le iu">本地等级:</strong>机器内唯一的进程 ID。例如，在每个有 8 个 GPU 的<code class="fe ky kz la lb b">p3.16xlarge</code> EC2 实例中，一个 GPU 的本地等级将从 0 到 7 不等。</li></ul><h1 id="6235" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">分布式培训期间会发生什么？</h1><p id="a45c" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">出于说明的目的，让我们以 2 个 GPU 上的分布式训练作业为例——它们可以在相同的不同系统上，这无关紧要。以下是幕后发生的事情:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/102868556bab5331160e976a5b07e648.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Mj3-ju1M2FwXtHva"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">用两个培训过程说明分布式培训过程中发生的情况</p></figure><p id="4a5e" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated"><strong class="le iu">第一步:</strong>正向传递期间，一切照常。模型的每个副本都使用它接收到的 batch_size 数据向前传递。</p><p id="d9d8" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated"><strong class="le iu">步骤 2: </strong>然后执行反向传递以计算梯度。但是梯度还没有用于更新权重。</p><p id="b5e4" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated"><strong class="le iu">步骤 3: </strong> Horovod 现在对所有进程进行<code class="fe ky kz la lb b">allreduce</code>操作(平均梯度，然后广播)。在这个例子中是两个 GPU。</p><p id="211a" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated"><strong class="le iu">步骤 4: </strong>最终的<code class="fe ky kz la lb b">allreduced</code>梯度现在用于更新每个模型</p><p id="9302" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">通过允许每个 GPU 对不同批次的数据进行训练，并降低梯度，您可以有效地对更大批次进行训练，从而加快训练速度。</p><h1 id="ba7d" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">更新您的培训脚本以使用 Horovod API</h1><p id="e42b" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">对于此演示，我将使用 CIFAR-10 数据集，该数据集由 60，000 张 32x32 的图像组成，这些图像属于 10 个不同的类(每个类 6，000 张图像)。博客帖子的 GitHub 存储库中提供了培训脚本以及 Jupyter 笔记本来运行完整的示例:</p><blockquote class="lz ma mb"><p id="8087" class="lc ld mc le b lf lg ju lh li lj jx lk md lm ln lo me lq lr ls mf lu lv lw lx im bi translated"><a class="ae ly" href="https://github.com/shashankprasanna/distributed-tensorflow-horovod-sagemaker" rel="noopener ugc nofollow" target="_blank">https://github . com/shashankprasanna/distributed-tensor flow-horo VOD-sage maker</a></p></blockquote><p id="94e5" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">本节描述了为准备分布式培训而对以下文件所做的更改:</p><ul class=""><li id="fd83" class="ne nf it le b lf lg li lj ll ng lp nh lt ni lx nj nk nl nm bi translated"><code class="fe ky kz la lb b"><a class="ae ly" href="https://github.com/shashankprasanna/distributed-tensorflow-horovod-sagemaker/blob/master/code/cifar10-tf-horovod-sagemaker.py" rel="noopener ugc nofollow" target="_blank">cifar10-tf-horovod-sagemaker.py</a></code>:主训练脚本</li><li id="0f75" class="ne nf it le b lf nn li no ll np lp nq lt nr lx nj nk nl nm bi translated"><code class="fe ky kz la lb b"><a class="ae ly" href="https://github.com/shashankprasanna/distributed-tensorflow-horovod-sagemaker/blob/master/code/model_def.py" rel="noopener ugc nofollow" target="_blank">model_def.py</a></code>:模型架构定义脚本</li></ul><p id="04dd" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">为了让您更容易理解，我在上面的脚本中包含了完全相同的部分标题作为注释。寻找“变化<code class="fe ky kz la lb b">NUMBER</code></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/148e58f899a4fca219538380b37bb780.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LvB50WLOe21iZSPC"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在上面的脚本中寻找与注释完全相同的部分标题</p></figure><h2 id="9642" class="ns mh it bd mi nt nu dn mm nv nw dp mq ll nx ny ms lp nz oa mu lt ob oc mw od bi translated">变化 1:导入 horovod 和 keras 后端</h2><p id="271d" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">将这些放在您的培训脚本的顶部，以导入 horovod。</p><pre class="kj kk kl km gt oe lb of og aw oh bi"><span id="ce61" class="ns mh it lb b gy oi oj l ok ol">import horovod.tensorflow.keras as hvd<br/>import tensorflow.keras.backend as K</span></pre><h2 id="2f97" class="ns mh it bd mi nt nu dn mm nv nw dp mq ll nx ny ms lp nz oa mu lt ob oc mw od bi translated">变化 2:初始化 horovod 并获得集群的大小</h2><p id="3f73" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">初始化<code class="fe ky kz la lb b">horovod</code>并获得集群中的 GPU 总数。如果只在 CPU 上运行，那么这将等于实例总数。</p><pre class="kj kk kl km gt oe lb of og aw oh bi"><span id="e6d5" class="ns mh it lb b gy oi oj l ok ol">hvd.init()<br/>size = hvd.size()</span></pre><h2 id="5cfc" class="ns mh it bd mi nt nu dn mm nv nw dp mq ll nx ny ms lp nz oa mu lt ob oc mw od bi translated">将 3 引脚 GPU 更改为本地进程(每个进程一个 GPU)</h2><p id="1b50" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">将 GPU 固定到当前进程。</p><pre class="kj kk kl km gt oe lb of og aw oh bi"><span id="905d" class="ns mh it lb b gy oi oj l ok ol">config = tf.ConfigProto()<br/>config.gpu_options.allow_growth = True<br/>config.gpu_options.visible_device_list = str(hvd.local_rank())<br/>K.set_session(tf.Session(config=config))</span></pre><h2 id="b22e" class="ns mh it bd mi nt nu dn mm nv nw dp mq ll nx ny ms lp nz oa mu lt ob oc mw od bi translated">变化 4:使用集群的规模(工人总数)来扩展学习</h2><p id="6584" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">通过根据 GPU 数量调整学习率来更新学习率。分布式训练时的有效批次为 batch_size 乘以<code class="fe ky kz la lb b">hvd.size()</code>。这个变化是在<code class="fe ky kz la lb b">model_def.py</code></p><p id="10cc" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">通过提高学习速率，您可以补偿批量大小的有效增加。</p><pre class="kj kk kl km gt oe lb of og aw oh bi"><span id="084f" class="ns mh it lb b gy oi oj l ok ol">opt = SGD(lr=lr * size, decay=weight_decay, momentum=momentum)</span></pre><h2 id="4677" class="ns mh it bd mi nt nu dn mm nv nw dp mq ll nx ny ms lp nz oa mu lt ob oc mw od bi translated">变化 5:使用 Horovod 包装 Keras 优化器，使其成为分布式优化器</h2><p id="64ca" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">分布式优化器使用<code class="fe ky kz la lb b">allreduce</code>或<code class="fe ky kz la lb b">allgather</code>对梯度进行平均和广播，然后用平均梯度更新权重。这个变化是在<code class="fe ky kz la lb b">model_def.py</code></p><pre class="kj kk kl km gt oe lb of og aw oh bi"><span id="73e2" class="ns mh it lb b gy oi oj l ok ol">opt = hvd.DistributedOptimizer(opt)</span></pre><h2 id="5759" class="ns mh it bd mi nt nu dn mm nv nw dp mq ll nx ny ms lp nz oa mu lt ob oc mw od bi translated">更改 6:添加了用于同步初始状态的回调，并且只在第一个工作线程(等级 0)上保存检查点</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="om on l"/></div></figure><h2 id="13da" class="ns mh it bd mi nt nu dn mm nv nw dp mq ll nx ny ms lp nz oa mu lt ob oc mw od bi translated">变化 7:更新步骤/时期的数量</h2><p id="1a34" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">您需要将每批图像的总数除以 GPU 的数量。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="om on l"/></div></figure><h2 id="977b" class="ns mh it bd mi nt nu dn mm nv nw dp mq ll nx ny ms lp nz oa mu lt ob oc mw od bi translated">更改 8:更新脚本以接受超参数作为命令行参数</h2><p id="29bb" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">Amazon SageMaker 将在启动分布式培训作业时将这些值传递给脚本。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="om on l"/></div></figure><h2 id="1203" class="ns mh it bd mi nt nu dn mm nv nw dp mq ll nx ny ms lp nz oa mu lt ob oc mw od bi translated">在 Amazon SageMaker 上运行分布式培训</h2><p id="815b" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">现在，您已经完成了最困难的部分——修改您的训练脚本，使其可以分发。</p><p id="dce3" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">剩下的过程——分布式培训——使用 Amazon SageMaker 相对简单。</p><p id="dde3" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">要使用 Amazon SageMaker 运行分布式培训作业，请下载并安装<a class="ae ly" href="https://github.com/aws/sagemaker-python-sdk" rel="noopener ugc nofollow" target="_blank"> SageMaker Python SDK </a>。为了更方便的体验，你还可以启动一个<a class="ae ly" href="https://docs.aws.amazon.com/sagemaker/latest/dg/nbi.html" rel="noopener ugc nofollow" target="_blank">亚马逊 SageMaker 笔记本实例</a>，它预装了 Jupyter 笔记本服务器、SageMaker Python SDK 和流行的深度学习框架。</p><p id="5e8d" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">运行 SageMaker 培训工作只涉及两个关键步骤，我将在下面重点介绍:</p><ol class=""><li id="fcad" class="ne nf it le b lf lg li lj ll ng lp nh lt ni lx oo nk nl nm bi translated">创建 SageMaker <code class="fe ky kz la lb b">TensorFlow</code>估算器</li><li id="eeb6" class="ne nf it le b lf nn li no ll np lp nq lt nr lx oo nk nl nm bi translated">调用<code class="fe ky kz la lb b">fit()</code>函数</li></ol><p id="925b" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">以下代码节选自博客文章库中的 Jupyter 笔记本。</p><blockquote class="lz ma mb"><p id="f5b8" class="lc ld mc le b lf lg ju lh li lj jx lk md lm ln lo me lq lr ls mf lu lv lw lx im bi translated"><a class="ae ly" href="https://github.com/shashankprasanna/distributed-tensorflow-horovod-sagemaker/blob/master/cifar10-sagemaker-distributed.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/shashankprasanna/distributed-tensor flow-horo VOD-sage maker/blob/master/cifar 10-sage maker-distributed . ipynb</a></p></blockquote><p id="2f6d" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">使用 SDK，您需要指定以下细节，以便 Amazon SageMaker 可以获得所请求的资源并为培训做准备</p><ul class=""><li id="7370" class="ne nf it le b lf lg li lj ll ng lp nh lt ni lx nj nk nl nm bi translated">你的训练脚本</li><li id="e434" class="ne nf it le b lf nn li no ll np lp nq lt nr lx nj nk nl nm bi translated">具有培训脚本依赖关系的目录</li><li id="409c" class="ne nf it le b lf nn li no ll np lp nq lt nr lx nj nk nl nm bi translated">保存已训练模型的位置</li><li id="a727" class="ne nf it le b lf nn li no ll np lp nq lt nr lx nj nk nl nm bi translated">要在其上进行培训的 CPU 或 GPU 实例的类型</li><li id="a229" class="ne nf it le b lf nn li no ll np lp nq lt nr lx nj nk nl nm bi translated">每个实例的 GPU 数量</li><li id="f4d9" class="ne nf it le b lf nn li no ll np lp nq lt nr lx nj nk nl nm bi translated">TensorFlow 版本</li><li id="a276" class="ne nf it le b lf nn li no ll np lp nq lt nr lx nj nk nl nm bi translated">分布类型— MPI(由 Horovod 使用)或参数服务器(分布式培训的替代方法)</li></ul><p id="b821" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">您可以在 SageMaker TensorFlow 估算器中指定更多选项，您可以在文档中找到完整列表:<a class="ae ly" href="https://sagemaker.readthedocs.io/en/stable/index.html" rel="noopener ugc nofollow" target="_blank">https://sagemaker.readthedocs.io/en/stable/index.html</a></p><p id="48b4" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">实现如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="dd40" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">定义估算器后，您需要指定亚马逊 S3 中训练、验证和测试数据集的路径，并将其传递给估算器的拟合函数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="0f8c" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">你完了！坐下来，等待分布式培训作业完成。</p><p id="aceb" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">您可以(并且应该)监控进度，我将在下一节中介绍这一点，但是首先，让我们仔细看看幕后发生了什么。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/7032a90725463ba238ad9d60fd961f49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GRfvsrvtfpRm400-"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">亚马逊 SageMaker 工作流程图</p></figure><p id="e527" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">Amazon SageMaker 自动为您做了几件事，因此您不必担心基础架构级别的细节。简言之，SageMaker 将:</p><ol class=""><li id="9ab9" class="ne nf it le b lf lg li lj ll ng lp nh lt ni lx oo nk nl nm bi translated">选择您的培训脚本和依赖项</li><li id="ab0a" class="ne nf it le b lf nn li no ll np lp nq lt nr lx oo nk nl nm bi translated">在完全受管的群集中调配指定数量的实例</li><li id="2f6e" class="ne nf it le b lf nn li no ll np lp nq lt nr lx oo nk nl nm bi translated">提取指定的 TensorFlow 容器图像</li><li id="e7ac" class="ne nf it le b lf nn li no ll np lp nq lt nr lx oo nk nl nm bi translated">在每个实例上实例化容器。</li><li id="609f" class="ne nf it le b lf nn li no ll np lp nq lt nr lx oo nk nl nm bi translated">将训练代码下载到实例中，并使其在容器中可用</li><li id="5662" class="ne nf it le b lf nn li no ll np lp nq lt nr lx oo nk nl nm bi translated">从亚马逊 S3 复制训练数据集并使其在容器中可用</li><li id="feb2" class="ne nf it le b lf nn li no ll np lp nq lt nr lx oo nk nl nm bi translated">使用 MPI 启动培训</li></ol><p id="a1d7" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">当培训开始时，Amazon SageMaker 在每个实例上运行与 Horovod 更新的培训脚本完全相同的副本。每个副本使用 hvd.local_rank()知道其唯一的本地等级，并且 GPU 被固定到该特定进程。然后 Horovod 负责执行<code class="fe ky kz la lb b">ring-allreduce</code>，并用平均梯度更新每个 GPU 上的权重。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/59a0bbac21936082040e23181fd12842.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zqluo0kWyhWrwREa"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">显示每个运行完全相同的训练脚本副本的 GPU 的图示。每个培训过程都由其等级唯一标识</p></figure><p id="7d24" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">一次培训完成后，SageMaker 将自动:</p><ul class=""><li id="74a1" class="ne nf it le b lf lg li lj ll ng lp nh lt ni lx nj nk nl nm bi translated">上传训练工件，如训练模型、检查点、张量板日志等。到亚马逊 S3 桶你指定</li><li id="ac08" class="ne nf it le b lf nn li no ll np lp nq lt nr lx nj nk nl nm bi translated">拆除培训集群，这样您就不会产生额外的成本</li></ul><h1 id="ae2b" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">监控培训培训进度</h1><p id="49dd" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">有几个不同的监视作业的选项:</p><ul class=""><li id="b55b" class="ne nf it le b lf lg li lj ll ng lp nh lt ni lx nj nk nl nm bi translated">亚马逊 SageMaker 控制台</li><li id="faa5" class="ne nf it le b lf nn li no ll np lp nq lt nr lx nj nk nl nm bi translated">张量板</li></ul><h2 id="6f34" class="ns mh it bd mi nt nu dn mm nv nw dp mq ll nx ny ms lp nz oa mu lt ob oc mw od bi translated">亚马逊 SageMaker 控制台</h2><p id="a4a2" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">如果你进入 AWS 控制台&gt; Amazon SageMaker &gt;培训作业，你可以看到一个当前正在运行的作业和你过去运行过的作业的列表。单击一个作业，您可以看到诸如进度状态、实例类型、超参数、数据集和模型工件的 S3 位置等详细信息。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/7b99384b6b28b37545f648b1d0d597fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6KznFpQ87_9p11v2"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">显示 Amazon SageMaker 控制台上培训工作的屏幕截图</p></figure><p id="774e" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">进一步向下滚动，您可以看到 CPU、GPU 和其他资源利用率。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/16b63a836020f4a69af8ce70e88b04c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ELQRDxQT_el2NQUF"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">显示 Amazon SageMaker 控制台上的作业监控的屏幕截图</p></figure><p id="03ce" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">您还可以找到一个到<a class="ae ly" href="https://aws.amazon.com/cloudwatch/" rel="noopener ugc nofollow" target="_blank">Amazon cloud watch</a>dashboard 的链接，在这里您可以监控所有实例的培训工作日志。当出现问题时，这对于调试和诊断非常方便。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/51eae4f4338c2c55d7369d880c186d36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nbYSmKtocGNGxpTi"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">显示亚马逊 CloudWatch 上培训工作日志的屏幕截图</p></figure><h2 id="4a2c" class="ns mh it bd mi nt nu dn mm nv nw dp mq ll nx ny ms lp nz oa mu lt ob oc mw od bi translated">张量板</h2><p id="e837" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">在<a class="ae ly" href="https://github.com/shashankprasanna/distributed-tensorflow-horovod-sagemaker/blob/master/generate_cifar10_tfrecords.py" rel="noopener ugc nofollow" target="_blank">培训脚本</a>中，您会注意到有两个 Keras 日志回调函数。第一个用于在本地容器中保存 tensorboard 日志文件，第二个用于将这些日志同步到调用 SageMaker estimator 函数时指定的亚马逊 S3 位置。</p><pre class="kj kk kl km gt oe lb of og aw oh bi"><span id="b0c7" class="ns mh it lb b gy oi oj l ok ol">callbacks.append(TensorBoard(log_dir=logdir))<br/>callbacks.append(Sync2S3(logdir=logdir, s3logdir=tensorboard_logs))</span></pre><p id="5565" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">现在你可以在任何你喜欢的地方运行 TensorBoard(你的笔记本电脑，台式机，EC2 实例),并通过 TensorBoard 日志将它指向你在亚马逊 S3 的位置。您需要确保您拥有访问亚马逊 S3 的权限，并且可以使用 AWS CLI 进行设置。</p><p id="e155" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">在安装了 tensorboard 并具有 S3 读取权限的计算机上运行以下命令:</p><pre class="kj kk kl km gt oe lb of og aw oh bi"><span id="682d" class="ns mh it lb b gy oi oj l ok ol">S3_REGION=us-west-2 tensorboard — logdir s3://{bucket_name}/tensorboard_logs/</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/7ae10bc010385f64f2074c8e12ff9a39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*11KvhHbpHU_sY-sb"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">多型号分布式训练进度实时监控。日志保存在亚马逊 S3，这使你可以运行 tensorboard，并监控任何机器上访问你的 S3 桶的进展。</p></figure><h1 id="e2bb" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">节省时间有什么不好呢？</h1><p id="fd89" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">在处理大型模型和数据集时，分布式培训可以节省您的时间。有了 Horovod 这样的图书馆和 Amazon SageMaker 这样的服务，你可以不费吹灰之力扩大培训规模。在这篇博文中，我介绍了两个关键概念:</p><ol class=""><li id="f335" class="ne nf it le b lf lg li lj ll ng lp nh lt ni lx oo nk nl nm bi translated">如何使用 Horovod 更新您现有的培训脚本，使其可以分发。</li><li id="21e4" class="ne nf it le b lf nn li no ll np lp nq lt nr lx oo nk nl nm bi translated">如何使用您的 horovod 更新培训脚本，并使用 Amazon SageMaker 运行分布式培训，同时必须设置和管理集群</li></ol><p id="d8d6" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">我将为您提供一些为分布式培训选择合适实例的指导原则:</p><p id="018f" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">为了获得更好的性能，请始终支持使用多个 GPU 的单个实例，而不是使用单个 GPU 的多个实例。</p><p id="ec43" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">在 AWS 上，您可以使用 1 个 GPU ( <code class="fe ky kz la lb b">p3.2xlarge</code>)、4 个 GPU(<code class="fe ky kz la lb b">p3.8xlarge</code>)和 8 个 GPU(<code class="fe ky kz la lb b">p3.16xlarge</code>和<code class="fe ky kz la lb b">p3dn.24xlarge</code>)访问实例。</p><p id="89f9" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">假设你想用 4 个 GPU 来运行分布式训练，总是倾向于单个<code class="fe ky kz la lb b">p3.8xlarge</code>实例，而不是 4 个<code class="fe ky kz la lb b">p3.2x large</code>。这样做的好处是，当进程需要通信来执行所有的 reduce 操作时，它们不会跨越网络障碍来与其他实例的 CPU 和 GPU 通信。这将增加通信延迟，可能会影响培训效果。同样，如果你想将训练分配给 8 个 GPU，那么选择单个<code class="fe ky kz la lb b">p3.16xlarge</code>或带有 8 个 GPU 的<code class="fe ky kz la lb b">p3dn.24xlarge</code>对 8 个<code class="fe ky kz la lb b">p3.2xlarge</code>或 2 个<code class="fe ky kz la lb b">p3.8xlarge</code>。这些多 GPU 实例包括 NVIDIA 的 NVLink 技术，该技术支持高带宽的 GPU 间通信，以加速 Horovod 执行的 allreduce 操作。</p><p id="25d6" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">感谢阅读，我希望你喜欢这个指南。GitHub 上的所有代码和示例都可以在这里找到:</p><blockquote class="lz ma mb"><p id="ede3" class="lc ld mc le b lf lg ju lh li lj jx lk md lm ln lo me lq lr ls mf lu lv lw lx im bi translated"><a class="ae ly" href="https://github.com/shashankprasanna/distributed-tensorflow-horovod-sagemaker" rel="noopener ugc nofollow" target="_blank">https://github . com/shashankprasanna/distributed-tensor flow-horovod-sage maker</a></p></blockquote><p id="50a3" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">如果您对本指南有任何疑问，对如何改进它有任何建议，或者对新指南有任何想法，请通过 twitter (@shshnkp)、LinkedIn 联系我，或者在下面留下评论。尽情享受吧！</p></div></div>    
</body>
</html>