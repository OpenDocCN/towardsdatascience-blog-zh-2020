<html>
<head>
<title>A quick guide to distributed training with TensorFlow and Horovod on Amazon SageMaker</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">亚马逊SageMaker上TensorFlow和Horovod分布式培训快速指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-quick-guide-to-distributed-training-with-tensorflow-and-horovod-on-amazon-sagemaker-dae18371ef6e?source=collection_archive---------7-----------------------#2020-03-14">https://towardsdatascience.com/a-quick-guide-to-distributed-training-with-tensorflow-and-horovod-on-amazon-sagemaker-dae18371ef6e?source=collection_archive---------7-----------------------#2020-03-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f057" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解分布式培训是如何工作的，以及Amazon SageMaker如何让它像在笔记本电脑上培训一样简单</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/05e4541ddd6b5dcf3971ac3a6c9a9a8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8ZQEO4BfflwU6IzYJgfZIQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用<code class="fe ky kz la lb b">horovod</code>和Amazon SageMaker在多个GPU上分发培训，以实现更快的培训和更高的生产率</p></figure><p id="fc63" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">在深度学习中，越多越好。更多的数据、更多的层和更多的计算能力通常会导致更高的准确性和更好的模型鲁棒性。</p><p id="b227" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">我可能无法帮助你<a class="ae ly" href="https://registry.opendata.aws/" rel="noopener ugc nofollow" target="_blank">收集更多数据</a>，但我可以展示你如何在大量机器上进行分布式训练，以更快地训练和运行更多实验，并提高你的生产率。</p><p id="742e" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">在这篇博文中，我将介绍如何在不管理基础设施的情况下运行分布式培训——无需启动实例、设置集群、管理存储卷，也无需构建容器。带上你的训练脚本，指定GPU的数量，让Amazon SageMaker处理剩下的事情。</p><p id="130c" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">在本指南的第一部分，我将提供一步一步的指导来更新您的训练脚本，以使用<a class="ae ly" href="https://horovod.readthedocs.io/en/latest/#" rel="noopener ugc nofollow" target="_blank"> Horovod </a>库。为了使分布式训练工作，不同GPU上的训练过程需要通信。Horovod实现了这种无缝的通信，并提供了一个方便的API来为分发培训准备您的培训脚本。您所做的更改与GPU的数量无关，因此这是一次性的工作。</p><p id="bb3a" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">在本指南的第二部分，我将展示如何使用Amazon SageMaker在任意数量的GPU上运行更新后的训练脚本，或者只需修改一行代码。</p><p id="f37c" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">想在阅读的时候跟着阅读并运行示例吗？Jupyter笔记本和培训脚本可从以下网址获得:</p><blockquote class="lz ma mb"><p id="6b25" class="lc ld mc le b lf lg ju lh li lj jx lk md lm ln lo me lq lr ls mf lu lv lw lx im bi translated"><a class="ae ly" href="https://github.com/shashankprasanna/distributed-tensorflow-horovod-sagemaker" rel="noopener ugc nofollow" target="_blank">https://github . com/shashankprasanna/distributed-tensor flow-horovod-sage maker</a></p></blockquote><h1 id="d83f" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">Horovod和环全归约方法</h1><p id="43af" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">Horovod是一个分布式深度学习框架，支持流行的深度学习框架——tensor flow、Keras、PyTorch和Apache MXNet。本指南中的示例使用TensorFlow和Keras。如果您是PyTorch或MXNet用户，更新您的脚本将遵循与这里描述的非常相似的过程。Horovod文档页面也包含了大量其他框架的例子。</p><p id="8679" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">在分布式训练中，多个进程需要相互通信。为了实现训练过程之间的通信，Horovod使用一种称为消息传递接口(MPI)的通信协议。为了平均梯度和更新模型的所有副本，它使用了一种称为ring-all reducce的方法(我们将回到这一点)。这些方法并不新鲜，在高性能计算(HPC)领域工作的科学家、研究人员和工程师已经使用了多年，以解决计算流体动力学、分子动力学、计算机图形学和其他领域的问题。</p><p id="88a0" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">MPI本身定义了在集群中的多个进程之间发送和接收信息的基本概念，例如<code class="fe ky kz la lb b">allreduce</code>、<code class="fe ky kz la lb b">allgather</code>和<code class="fe ky kz la lb b">broadcast</code>。正如你可能已经从它们的名字中推断出的那样——<code class="fe ky kz la lb b">allgather</code>从所有过程中收集数据(在深度学习的情况下，是梯度)。广播，将数据(梯度)从一个进程广播到所有其他进程。<code class="fe ky kz la lb b">allreduce</code>(从概念上讲)结合了这两种操作—从所有过程中收集数据，执行归约操作(例如，平均梯度)，然后广播(平均梯度)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/51b82f00a4064bb1530b6ec636d2eb14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2DJs_qQeiVyOQ0TV"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在3台各有2个GPU的机器上使用6个进程的ring allreduce的图示。rank是全局唯一ID，而local rank是每个GPU的本地唯一ID</p></figure><p id="c5ae" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">随着训练进程数量的增加，进程间通信也会增加，通信开销开始影响扩展效率。</p><p id="ccda" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated"><code class="fe ky kz la lb b">ring all-reduce</code>方法通过使通信成本独立于系统中的进程数量，对传统的<code class="fe ky kz la lb b">allreduce</code>方法进行了改进。它通过在逻辑环中安排进程来实现这一点，其中每个进程只接收来自其“左”邻居的数据，并向其“右”邻居发送数据，如附图所示。</p><p id="f255" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">深度学习的<code class="fe ky kz la lb b">ring-allreduce</code>过程在<a class="ae ly" href="https://eng.uber.com/horovod/" rel="noopener ugc nofollow" target="_blank"> Horovod博文</a>和<a class="ae ly" href="https://arxiv.org/pdf/1802.05799.pdf" rel="noopener ugc nofollow" target="_blank"> Horovod论文</a>中有更详细的描述。要使用horovod库，你并不真的需要知道<code class="fe ky kz la lb b">ring-allreduce</code>是如何工作的，但是对你使用的算法和库如何工作有一个直觉总是有帮助的。</p><p id="6a8d" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">要使用update your training script来使用Horovod库，您首先需要了解以下关键概念:</p><ul class=""><li id="d6be" class="ne nf it le b lf lg li lj ll ng lp nh lt ni lx nj nk nl nm bi translated"><strong class="le iu">大小:</strong>进程/GPU总数。这等于集群中计算实例的数量乘以每个实例的GPU数量。例如，如果您有2个<code class="fe ky kz la lb b">p3.16xlarge</code> EC2实例。大小应该是2(实例)x 8(GPU)= 16。</li><li id="0760" class="ne nf it le b lf nn li no ll np lp nq lt nr lx nj nk nl nm bi translated"><strong class="le iu">等级:</strong>唯一的进程ID(大小— 1)。GPU中的每个进程都知道自己的唯一级别。</li><li id="de33" class="ne nf it le b lf nn li no ll np lp nq lt nr lx nj nk nl nm bi translated"><strong class="le iu">本地等级:</strong>机器内唯一的进程ID。例如，在每个有8个GPU的<code class="fe ky kz la lb b">p3.16xlarge</code> EC2实例中，一个GPU的本地等级将从0到7不等。</li></ul><h1 id="6235" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">分布式培训期间会发生什么？</h1><p id="a45c" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">出于说明的目的，让我们以2个GPU上的分布式训练作业为例——它们可以在相同的不同系统上，这无关紧要。以下是幕后发生的事情:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/102868556bab5331160e976a5b07e648.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Mj3-ju1M2FwXtHva"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">用两个培训过程说明分布式培训过程中发生的情况</p></figure><p id="4a5e" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated"><strong class="le iu">第一步:</strong>正向传递期间，一切照常。模型的每个副本都使用它接收到的batch_size数据向前传递。</p><p id="d9d8" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated"><strong class="le iu">步骤2: </strong>然后执行反向传递以计算梯度。但是梯度还没有用于更新权重。</p><p id="b5e4" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated"><strong class="le iu">步骤3: </strong> Horovod现在对所有进程进行<code class="fe ky kz la lb b">allreduce</code>操作(平均梯度，然后广播)。在这个例子中是两个GPU。</p><p id="211a" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated"><strong class="le iu">步骤4: </strong>最终的<code class="fe ky kz la lb b">allreduced</code>梯度现在用于更新每个模型</p><p id="9302" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">通过允许每个GPU对不同批次的数据进行训练，并降低梯度，您可以有效地对更大批次进行训练，从而加快训练速度。</p><h1 id="ba7d" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">更新您的培训脚本以使用Horovod API</h1><p id="e42b" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">对于此演示，我将使用CIFAR-10数据集，该数据集由60，000张32x32的图像组成，这些图像属于10个不同的类(每个类6，000张图像)。博客帖子的GitHub存储库中提供了培训脚本以及Jupyter笔记本来运行完整的示例:</p><blockquote class="lz ma mb"><p id="8087" class="lc ld mc le b lf lg ju lh li lj jx lk md lm ln lo me lq lr ls mf lu lv lw lx im bi translated"><a class="ae ly" href="https://github.com/shashankprasanna/distributed-tensorflow-horovod-sagemaker" rel="noopener ugc nofollow" target="_blank">https://github . com/shashankprasanna/distributed-tensor flow-horo VOD-sage maker</a></p></blockquote><p id="94e5" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">本节描述了为准备分布式培训而对以下文件所做的更改:</p><ul class=""><li id="fd83" class="ne nf it le b lf lg li lj ll ng lp nh lt ni lx nj nk nl nm bi translated"><code class="fe ky kz la lb b"><a class="ae ly" href="https://github.com/shashankprasanna/distributed-tensorflow-horovod-sagemaker/blob/master/code/cifar10-tf-horovod-sagemaker.py" rel="noopener ugc nofollow" target="_blank">cifar10-tf-horovod-sagemaker.py</a></code>:主训练脚本</li><li id="0f75" class="ne nf it le b lf nn li no ll np lp nq lt nr lx nj nk nl nm bi translated"><code class="fe ky kz la lb b"><a class="ae ly" href="https://github.com/shashankprasanna/distributed-tensorflow-horovod-sagemaker/blob/master/code/model_def.py" rel="noopener ugc nofollow" target="_blank">model_def.py</a></code>:模型架构定义脚本</li></ul><p id="04dd" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">为了让您更容易理解，我在上面的脚本中包含了完全相同的部分标题作为注释。寻找“变化<code class="fe ky kz la lb b">NUMBER</code></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/148e58f899a4fca219538380b37bb780.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LvB50WLOe21iZSPC"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在上面的脚本中寻找与注释完全相同的部分标题</p></figure><h2 id="9642" class="ns mh it bd mi nt nu dn mm nv nw dp mq ll nx ny ms lp nz oa mu lt ob oc mw od bi translated">变化1:导入horovod和keras后端</h2><p id="271d" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">将这些放在您的培训脚本的顶部，以导入horovod。</p><pre class="kj kk kl km gt oe lb of og aw oh bi"><span id="ce61" class="ns mh it lb b gy oi oj l ok ol">import horovod.tensorflow.keras as hvd<br/>import tensorflow.keras.backend as K</span></pre><h2 id="2f97" class="ns mh it bd mi nt nu dn mm nv nw dp mq ll nx ny ms lp nz oa mu lt ob oc mw od bi translated">变化2:初始化horovod并获得集群的大小</h2><p id="3f73" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">初始化<code class="fe ky kz la lb b">horovod</code>并获得集群中的GPU总数。如果只在CPU上运行，那么这将等于实例总数。</p><pre class="kj kk kl km gt oe lb of og aw oh bi"><span id="e6d5" class="ns mh it lb b gy oi oj l ok ol">hvd.init()<br/>size = hvd.size()</span></pre><h2 id="5cfc" class="ns mh it bd mi nt nu dn mm nv nw dp mq ll nx ny ms lp nz oa mu lt ob oc mw od bi translated">将3引脚GPU更改为本地进程(每个进程一个GPU)</h2><p id="1b50" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">将GPU固定到当前进程。</p><pre class="kj kk kl km gt oe lb of og aw oh bi"><span id="905d" class="ns mh it lb b gy oi oj l ok ol">config = tf.ConfigProto()<br/>config.gpu_options.allow_growth = True<br/>config.gpu_options.visible_device_list = str(hvd.local_rank())<br/>K.set_session(tf.Session(config=config))</span></pre><h2 id="b22e" class="ns mh it bd mi nt nu dn mm nv nw dp mq ll nx ny ms lp nz oa mu lt ob oc mw od bi translated">变化4:使用集群的规模(工人总数)来扩展学习</h2><p id="6584" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">通过根据GPU数量调整学习率来更新学习率。分布式训练时的有效批次为batch_size乘以<code class="fe ky kz la lb b">hvd.size()</code>。这个变化是在<code class="fe ky kz la lb b">model_def.py</code></p><p id="10cc" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">通过提高学习速率，您可以补偿批量大小的有效增加。</p><pre class="kj kk kl km gt oe lb of og aw oh bi"><span id="084f" class="ns mh it lb b gy oi oj l ok ol">opt = SGD(lr=lr * size, decay=weight_decay, momentum=momentum)</span></pre><h2 id="4677" class="ns mh it bd mi nt nu dn mm nv nw dp mq ll nx ny ms lp nz oa mu lt ob oc mw od bi translated">变化5:使用Horovod包装Keras优化器，使其成为分布式优化器</h2><p id="64ca" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">分布式优化器使用<code class="fe ky kz la lb b">allreduce</code>或<code class="fe ky kz la lb b">allgather</code>对梯度进行平均和广播，然后用平均梯度更新权重。这个变化是在<code class="fe ky kz la lb b">model_def.py</code></p><pre class="kj kk kl km gt oe lb of og aw oh bi"><span id="73e2" class="ns mh it lb b gy oi oj l ok ol">opt = hvd.DistributedOptimizer(opt)</span></pre><h2 id="5759" class="ns mh it bd mi nt nu dn mm nv nw dp mq ll nx ny ms lp nz oa mu lt ob oc mw od bi translated">更改6:添加了用于同步初始状态的回调，并且只在第一个工作线程(等级0)上保存检查点</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="om on l"/></div></figure><h2 id="13da" class="ns mh it bd mi nt nu dn mm nv nw dp mq ll nx ny ms lp nz oa mu lt ob oc mw od bi translated">变化7:更新步骤/时期的数量</h2><p id="1a34" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">您需要将每批图像的总数除以GPU的数量。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="om on l"/></div></figure><h2 id="977b" class="ns mh it bd mi nt nu dn mm nv nw dp mq ll nx ny ms lp nz oa mu lt ob oc mw od bi translated">更改8:更新脚本以接受超参数作为命令行参数</h2><p id="29bb" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">Amazon SageMaker将在启动分布式培训作业时将这些值传递给脚本。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="om on l"/></div></figure><h2 id="1203" class="ns mh it bd mi nt nu dn mm nv nw dp mq ll nx ny ms lp nz oa mu lt ob oc mw od bi translated">在Amazon SageMaker上运行分布式培训</h2><p id="815b" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">现在，您已经完成了最困难的部分——修改您的训练脚本，使其可以分发。</p><p id="dce3" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">剩下的过程——分布式培训——使用Amazon SageMaker相对简单。</p><p id="dde3" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">要使用Amazon SageMaker运行分布式培训作业，请下载并安装<a class="ae ly" href="https://github.com/aws/sagemaker-python-sdk" rel="noopener ugc nofollow" target="_blank"> SageMaker Python SDK </a>。为了更方便的体验，你还可以启动一个<a class="ae ly" href="https://docs.aws.amazon.com/sagemaker/latest/dg/nbi.html" rel="noopener ugc nofollow" target="_blank">亚马逊SageMaker笔记本实例</a>，它预装了Jupyter笔记本服务器、SageMaker Python SDK和流行的深度学习框架。</p><p id="5e8d" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">运行SageMaker培训工作只涉及两个关键步骤，我将在下面重点介绍:</p><ol class=""><li id="fcad" class="ne nf it le b lf lg li lj ll ng lp nh lt ni lx oo nk nl nm bi translated">创建SageMaker <code class="fe ky kz la lb b">TensorFlow</code>估算器</li><li id="eeb6" class="ne nf it le b lf nn li no ll np lp nq lt nr lx oo nk nl nm bi translated">调用<code class="fe ky kz la lb b">fit()</code>函数</li></ol><p id="925b" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">以下代码节选自博客文章库中的Jupyter笔记本。</p><blockquote class="lz ma mb"><p id="f5b8" class="lc ld mc le b lf lg ju lh li lj jx lk md lm ln lo me lq lr ls mf lu lv lw lx im bi translated"><a class="ae ly" href="https://github.com/shashankprasanna/distributed-tensorflow-horovod-sagemaker/blob/master/cifar10-sagemaker-distributed.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/shashankprasanna/distributed-tensor flow-horo VOD-sage maker/blob/master/cifar 10-sage maker-distributed . ipynb</a></p></blockquote><p id="2f6d" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">使用SDK，您需要指定以下细节，以便Amazon SageMaker可以获得所请求的资源并为培训做准备</p><ul class=""><li id="7370" class="ne nf it le b lf lg li lj ll ng lp nh lt ni lx nj nk nl nm bi translated">你的训练脚本</li><li id="e434" class="ne nf it le b lf nn li no ll np lp nq lt nr lx nj nk nl nm bi translated">具有培训脚本依赖关系的目录</li><li id="409c" class="ne nf it le b lf nn li no ll np lp nq lt nr lx nj nk nl nm bi translated">保存已训练模型的位置</li><li id="a727" class="ne nf it le b lf nn li no ll np lp nq lt nr lx nj nk nl nm bi translated">要在其上进行培训的CPU或GPU实例的类型</li><li id="a229" class="ne nf it le b lf nn li no ll np lp nq lt nr lx nj nk nl nm bi translated">每个实例的GPU数量</li><li id="f4d9" class="ne nf it le b lf nn li no ll np lp nq lt nr lx nj nk nl nm bi translated">TensorFlow版本</li><li id="a276" class="ne nf it le b lf nn li no ll np lp nq lt nr lx nj nk nl nm bi translated">分布类型— MPI(由Horovod使用)或参数服务器(分布式培训的替代方法)</li></ul><p id="b821" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">您可以在SageMaker TensorFlow估算器中指定更多选项，您可以在文档中找到完整列表:<a class="ae ly" href="https://sagemaker.readthedocs.io/en/stable/index.html" rel="noopener ugc nofollow" target="_blank">https://sagemaker.readthedocs.io/en/stable/index.html</a></p><p id="48b4" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">实现如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="dd40" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">定义估算器后，您需要指定亚马逊S3中训练、验证和测试数据集的路径，并将其传递给估算器的拟合函数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="0f8c" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">你完了！坐下来，等待分布式培训作业完成。</p><p id="aceb" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">您可以(并且应该)监控进度，我将在下一节中介绍这一点，但是首先，让我们仔细看看幕后发生了什么。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/7032a90725463ba238ad9d60fd961f49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GRfvsrvtfpRm400-"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">亚马逊SageMaker工作流程图</p></figure><p id="e527" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">Amazon SageMaker自动为您做了几件事，因此您不必担心基础架构级别的细节。简言之，SageMaker将:</p><ol class=""><li id="9ab9" class="ne nf it le b lf lg li lj ll ng lp nh lt ni lx oo nk nl nm bi translated">选择您的培训脚本和依赖项</li><li id="ab0a" class="ne nf it le b lf nn li no ll np lp nq lt nr lx oo nk nl nm bi translated">在完全受管的群集中调配指定数量的实例</li><li id="2f6e" class="ne nf it le b lf nn li no ll np lp nq lt nr lx oo nk nl nm bi translated">提取指定的TensorFlow容器图像</li><li id="e7ac" class="ne nf it le b lf nn li no ll np lp nq lt nr lx oo nk nl nm bi translated">在每个实例上实例化容器。</li><li id="609f" class="ne nf it le b lf nn li no ll np lp nq lt nr lx oo nk nl nm bi translated">将训练代码下载到实例中，并使其在容器中可用</li><li id="5662" class="ne nf it le b lf nn li no ll np lp nq lt nr lx oo nk nl nm bi translated">从亚马逊S3复制训练数据集并使其在容器中可用</li><li id="feb2" class="ne nf it le b lf nn li no ll np lp nq lt nr lx oo nk nl nm bi translated">使用MPI启动培训</li></ol><p id="a1d7" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">当培训开始时，Amazon SageMaker在每个实例上运行与Horovod更新的培训脚本完全相同的副本。每个副本使用hvd.local_rank()知道其唯一的本地等级，并且GPU被固定到该特定进程。然后Horovod负责执行<code class="fe ky kz la lb b">ring-allreduce</code>，并用平均梯度更新每个GPU上的权重。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/59a0bbac21936082040e23181fd12842.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zqluo0kWyhWrwREa"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">显示每个运行完全相同的训练脚本副本的GPU的图示。每个培训过程都由其等级唯一标识</p></figure><p id="7d24" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">一次培训完成后，SageMaker将自动:</p><ul class=""><li id="74a1" class="ne nf it le b lf lg li lj ll ng lp nh lt ni lx nj nk nl nm bi translated">上传训练工件，如训练模型、检查点、张量板日志等。到亚马逊S3桶你指定</li><li id="ac08" class="ne nf it le b lf nn li no ll np lp nq lt nr lx nj nk nl nm bi translated">拆除培训集群，这样您就不会产生额外的成本</li></ul><h1 id="ae2b" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">监控培训培训进度</h1><p id="49dd" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">有几个不同的监视作业的选项:</p><ul class=""><li id="b55b" class="ne nf it le b lf lg li lj ll ng lp nh lt ni lx nj nk nl nm bi translated">亚马逊SageMaker控制台</li><li id="faa5" class="ne nf it le b lf nn li no ll np lp nq lt nr lx nj nk nl nm bi translated">张量板</li></ul><h2 id="6f34" class="ns mh it bd mi nt nu dn mm nv nw dp mq ll nx ny ms lp nz oa mu lt ob oc mw od bi translated">亚马逊SageMaker控制台</h2><p id="a4a2" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">如果你进入AWS控制台&gt; Amazon SageMaker &gt;培训作业，你可以看到一个当前正在运行的作业和你过去运行过的作业的列表。单击一个作业，您可以看到诸如进度状态、实例类型、超参数、数据集和模型工件的S3位置等详细信息。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/7b99384b6b28b37545f648b1d0d597fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6KznFpQ87_9p11v2"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">显示Amazon SageMaker控制台上培训工作的屏幕截图</p></figure><p id="774e" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">进一步向下滚动，您可以看到CPU、GPU和其他资源利用率。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/16b63a836020f4a69af8ce70e88b04c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ELQRDxQT_el2NQUF"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">显示Amazon SageMaker控制台上的作业监控的屏幕截图</p></figure><p id="03ce" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">您还可以找到一个到<a class="ae ly" href="https://aws.amazon.com/cloudwatch/" rel="noopener ugc nofollow" target="_blank">Amazon cloud watch</a>dashboard的链接，在这里您可以监控所有实例的培训工作日志。当出现问题时，这对于调试和诊断非常方便。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/51eae4f4338c2c55d7369d880c186d36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nbYSmKtocGNGxpTi"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">显示亚马逊CloudWatch上培训工作日志的屏幕截图</p></figure><h2 id="4a2c" class="ns mh it bd mi nt nu dn mm nv nw dp mq ll nx ny ms lp nz oa mu lt ob oc mw od bi translated">张量板</h2><p id="e837" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">在<a class="ae ly" href="https://github.com/shashankprasanna/distributed-tensorflow-horovod-sagemaker/blob/master/generate_cifar10_tfrecords.py" rel="noopener ugc nofollow" target="_blank">培训脚本</a>中，您会注意到有两个Keras日志回调函数。第一个用于在本地容器中保存tensorboard日志文件，第二个用于将这些日志同步到调用SageMaker estimator函数时指定的亚马逊S3位置。</p><pre class="kj kk kl km gt oe lb of og aw oh bi"><span id="b0c7" class="ns mh it lb b gy oi oj l ok ol">callbacks.append(TensorBoard(log_dir=logdir))<br/>callbacks.append(Sync2S3(logdir=logdir, s3logdir=tensorboard_logs))</span></pre><p id="5565" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">现在你可以在任何你喜欢的地方运行TensorBoard(你的笔记本电脑，台式机，EC2实例),并通过TensorBoard日志将它指向你在亚马逊S3的位置。您需要确保您拥有访问亚马逊S3的权限，并且可以使用AWS CLI进行设置。</p><p id="e155" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">在安装了tensorboard并具有S3读取权限的计算机上运行以下命令:</p><pre class="kj kk kl km gt oe lb of og aw oh bi"><span id="682d" class="ns mh it lb b gy oi oj l ok ol">S3_REGION=us-west-2 tensorboard — logdir s3://{bucket_name}/tensorboard_logs/</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/7ae10bc010385f64f2074c8e12ff9a39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*11KvhHbpHU_sY-sb"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">多型号分布式训练进度实时监控。日志保存在亚马逊S3，这使你可以运行tensorboard，并监控任何机器上访问你的S3桶的进展。</p></figure><h1 id="e2bb" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">节省时间有什么不好呢？</h1><p id="fd89" class="pw-post-body-paragraph lc ld it le b lf my ju lh li mz jx lk ll na ln lo lp nb lr ls lt nc lv lw lx im bi translated">在处理大型模型和数据集时，分布式培训可以节省您的时间。有了Horovod这样的图书馆和Amazon SageMaker这样的服务，你可以不费吹灰之力扩大培训规模。在这篇博文中，我介绍了两个关键概念:</p><ol class=""><li id="f335" class="ne nf it le b lf lg li lj ll ng lp nh lt ni lx oo nk nl nm bi translated">如何使用Horovod更新您现有的培训脚本，使其可以分发。</li><li id="21e4" class="ne nf it le b lf nn li no ll np lp nq lt nr lx oo nk nl nm bi translated">如何使用您的horovod更新培训脚本，并使用Amazon SageMaker运行分布式培训，同时必须设置和管理集群</li></ol><p id="d8d6" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">我将为您提供一些为分布式培训选择合适实例的指导原则:</p><p id="018f" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">为了获得更好的性能，请始终支持使用多个GPU的单个实例，而不是使用单个GPU的多个实例。</p><p id="ec43" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">在AWS上，您可以使用1个GPU ( <code class="fe ky kz la lb b">p3.2xlarge</code>)、4个GPU(<code class="fe ky kz la lb b">p3.8xlarge</code>)和8个GPU(<code class="fe ky kz la lb b">p3.16xlarge</code>和<code class="fe ky kz la lb b">p3dn.24xlarge</code>)访问实例。</p><p id="89f9" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">假设你想用4个GPU来运行分布式训练，总是倾向于单个<code class="fe ky kz la lb b">p3.8xlarge</code>实例，而不是4个<code class="fe ky kz la lb b">p3.2x large</code>。这样做的好处是，当进程需要通信来执行所有的reduce操作时，它们不会跨越网络障碍来与其他实例的CPU和GPU通信。这将增加通信延迟，可能会影响培训效果。同样，如果你想将训练分配给8个GPU，那么选择单个<code class="fe ky kz la lb b">p3.16xlarge</code>或带有8个GPU的<code class="fe ky kz la lb b">p3dn.24xlarge</code>对8个<code class="fe ky kz la lb b">p3.2xlarge</code>或2个<code class="fe ky kz la lb b">p3.8xlarge</code>。这些多GPU实例包括NVIDIA的NVLink技术，该技术支持高带宽的GPU间通信，以加速Horovod执行的allreduce操作。</p><p id="25d6" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">感谢阅读，我希望你喜欢这个指南。GitHub上的所有代码和示例都可以在这里找到:</p><blockquote class="lz ma mb"><p id="ede3" class="lc ld mc le b lf lg ju lh li lj jx lk md lm ln lo me lq lr ls mf lu lv lw lx im bi translated"><a class="ae ly" href="https://github.com/shashankprasanna/distributed-tensorflow-horovod-sagemaker" rel="noopener ugc nofollow" target="_blank">https://github . com/shashankprasanna/distributed-tensor flow-horovod-sage maker</a></p></blockquote><p id="50a3" class="pw-post-body-paragraph lc ld it le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">如果您对本指南有任何疑问，对如何改进它有任何建议，或者对新指南有任何想法，请通过twitter (@shshnkp)、LinkedIn联系我，或者在下面留下评论。尽情享受吧！</p></div></div>    
</body>
</html>