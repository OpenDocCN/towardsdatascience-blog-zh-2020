<html>
<head>
<title>How to read BigQuery data from TensorFlow 2.0 efficiently</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何高效地从TensorFlow 2.0中读取BigQuery数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-read-bigquery-data-from-tensorflow-2-0-efficiently-9234b69165c8?source=collection_archive---------22-----------------------#2020-02-06">https://towardsdatascience.com/how-to-read-bigquery-data-from-tensorflow-2-0-efficiently-9234b69165c8?source=collection_archive---------22-----------------------#2020-02-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="54be" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用tensor flow _ io . big query . bigqueryclient创建tf.data.dataset</h2></div><p id="4545" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">TensorFlow的<a class="ae lb" href="https://github.com/tensorflow/io/tree/master/tensorflow_io/bigquery" rel="noopener ugc nofollow" target="_blank"> BigQueryClient </a>使用存储API直接从BigQuery存储中高效地读取数据(即，无需发出BigQuery查询)。在本文中，我将向您展示如何在Keras/TensorFlow 2.0模型中使用该类来创建tf.data数据集。你可以在GitHub上跟随这个<a class="ae lb" href="https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/blogs/bigquery_datascience/bigquery_tensorflow.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本。</a></p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lc"><img src="../Images/defea1804f960a851f4650039b52b5bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m8EL7kmNlzasYc9MALTnJQ.jpeg"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">使用BigQuery作为数据湖:将数据直接从BigQuery读入TensorFlow</p></figure><p id="8112" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作为示例，我将使用信用卡交易的数据集。这些交易中约有0.17%是欺诈性的，挑战在于在这个非常非常不平衡的数据集上训练一个分类模型。因此，在这个过程中，您还将学习一些如何处理不平衡数据的技巧。</p><h2 id="add6" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">基准</h2><p id="9fc7" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">开发机器学习模型的最佳实践是拥有一个简单的基准。在这种情况下，我将使用BigQuery ML开发基准模型:</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="274d" class="ls lt iq mr b gy mv mw l mx my">CREATE OR REPLACE MODEL advdata.ulb_fraud_detection <br/>TRANSFORM(<br/>    * EXCEPT(Amount),<br/>    SAFE.LOG(Amount) AS log_amount<br/>)<br/>OPTIONS(<br/>    INPUT_LABEL_COLS=['class'],<br/>    AUTO_CLASS_WEIGHTS = TRUE,<br/>    DATA_SPLIT_METHOD='seq',<br/>    DATA_SPLIT_COL='Time',<br/>    MODEL_TYPE='logistic_reg'<br/>) AS</span><span id="e2cb" class="ls lt iq mr b gy mz mw l mx my">SELECT <br/> *<br/>FROM `bigquery-public-data.ml_datasets.ulb_fraud_detection`</span></pre><p id="7794" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，我在这个超级简单的模型中做了几件事情:</p><ul class=""><li id="ac56" class="na nb iq kh b ki kj kl km ko nc ks nd kw ne la nf ng nh ni bi translated">我正在训练一个逻辑回归模型(或线性分类器)——这是这个问题最简单的可能ML模型，可以作为对更复杂模型的检查。</li><li id="c2c3" class="na nb iq kh b ki nj kl nk ko nl ks nm kw nn la nf ng nh ni bi translated">我使用时间列划分数据，因此前80%的事务是训练数据集，后20%是评估数据集。这样，我们就不会在欺诈活动存在时间依赖性的情况下泄露信息。</li><li id="e965" class="na nb iq kh b ki nj kl nk ko nl ks nm kw nn la nf ng nh ni bi translated">我要求BigQuery ML根据它们在训练数据集中的出现频率自动对这些类进行加权。</li><li id="56fc" class="na nb iq kh b ki nj kl nk ko nl ks nm kw nn la nf ng nh ni bi translated">我正在使用log函数转换范围很大的Amount列，这样它也是一个相对较小的数字。我使用BigQuery ML的TRANSFORM子句来实现这一点。</li><li id="872d" class="na nb iq kh b ki nj kl nk ko nl ks nm kw nn la nf ng nh ni bi translated">因为在某些情况下金额为零，所以我用SAFE。记录以避免数字错误。</li></ul><p id="2562" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这给了我一个AUC(曲线下面积)为0.9863的模型，说明了BigQuery ML有多么强大。让我们看看我们是否可以用Keras编写的更复杂的机器学习模型来击败这一点。</p><h2 id="cb82" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">创建tf.data.dataset</h2><p id="d8b3" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">为了将BigQuery数据读入Keras，我将使用<a class="ae lb" href="https://github.com/tensorflow/io/tree/master/tensorflow_io/bigquery" rel="noopener ugc nofollow" target="_blank"> BigQueryClient </a>。下面是创建数据集的代码:</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="5a0b" class="ls lt iq mr b gy mv mw l mx my">import tensorflow as tf<br/>from tensorflow.python.framework import dtypes<br/>from tensorflow_io.bigquery import BigQueryClient<br/>from tensorflow_io.bigquery import BigQueryReadSession</span><span id="af49" class="ls lt iq mr b gy mz mw l mx my">def features_and_labels(features):<br/>  label = features.pop('Class') # this is what we will train for<br/>  return features, label</span><span id="69e7" class="ls lt iq mr b gy mz mw l mx my">def read_dataset(client, row_restriction, batch_size=2048):<br/>    GCP_PROJECT_ID='your_project_name'  # CHANGE<br/>    COL_NAMES = ['Time', 'Amount', 'Class'] + ['V{}'.format(i) for i in range(1,29)]<br/>    COL_TYPES = [dtypes.float64, dtypes.float64, dtypes.int64] + [dtypes.float64 for i in range(1,29)]<br/>    DATASET_GCP_PROJECT_ID, DATASET_ID, TABLE_ID,  = 'bigquery-public-data.ml_datasets.ulb_fraud_detection'.split('.')<br/>    bqsession = client.read_session(<br/>        "projects/" + GCP_PROJECT_ID,<br/>        DATASET_GCP_PROJECT_ID, TABLE_ID, DATASET_ID,<br/>        COL_NAMES, COL_TYPES,<br/>        requested_streams=2,<br/>        row_restriction=row_restriction)<br/>    dataset = bqsession.parallel_read_rows()<br/>    return dataset.prefetch(1).map(features_and_labels).shuffle(batch_size*10).batch(batch_size)</span><span id="2bff" class="ls lt iq mr b gy mz mw l mx my">client = BigQueryClient()<br/>train_df = read_dataset(client, 'Time &lt;= 144803', 2048)<br/>eval_df = read_dataset(client, 'Time &gt; 144803', 2048)</span></pre><p id="c156" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本质上，我们使用client.read_session()创建一个会话，传入要读取的表、要读取的表的列，以及对我们关心的行的简单限制。这些数据被并行读入tf.data.dataset，我用它来创建一个训练数据集和一个评估数据集。</p><p id="444e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，上面的代码使用了一些tf.data.dataset最佳实践，如预取、混排和批处理。</p><h2 id="cafc" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">创建Keras模型输入层</h2><p id="dcec" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">创建Keras模型来读取结构化数据涉及到特性列。要了解更多，请参阅我的文章，关于在Keras中创建宽深模型和保持T2转换代码与输入分离。因此，不重复我自己，下面是创建Keras的输入层的代码:</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="dd00" class="ls lt iq mr b gy mv mw l mx my"># create inputs, and pass them into appropriate types of feature columns (here, everything is numeric)<br/>inputs = {<br/>    'V{}'.format(i) : tf.keras.layers.Input(name='V{}'.format(i), shape=(), dtype='float64') for i in range(1, 29)<br/>}<br/>inputs['Amount'] = tf.keras.layers.Input(name='Amount', shape=(), dtype='float64')<br/>input_fc = [tf.feature_column.numeric_column(colname) for colname in inputs.keys()]</span><span id="d66a" class="ls lt iq mr b gy mz mw l mx my"># transformations. only the Amount is transformed<br/>transformed = inputs.copy()<br/>transformed['Amount'] = tf.keras.layers.Lambda(<br/>    lambda x: tf.math.log(tf.math.maximum(x, 0.01)), name='log_amount')(inputs['Amount'])<br/>input_layer = tf.keras.layers.DenseFeatures(input_fc, name='inputs')(transformed)</span></pre><h2 id="de98" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">处理阶级不平衡</h2><p id="07ae" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">处理Keras模型中的类不平衡包括两个步骤:</p><ul class=""><li id="c976" class="na nb iq kh b ki kj kl km ko nc ks nd kw ne la nf ng nh ni bi translated">指定对数输出图层的初始偏差(正/负)</li><li id="a34d" class="na nb iq kh b ki nj kl nk ko nl ks nm kw nn la nf ng nh ni bi translated">以总权重等于训练样本数量的方式，对不频繁类进行比频繁类大得多的加权</li></ul><p id="d405" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以使用BigQuery计算必要的值:</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="75d7" class="ls lt iq mr b gy mv mw l mx my">WITH counts AS (<br/>SELECT<br/>    APPROX_QUANTILES(Time, 5)[OFFSET(4)] AS train_cutoff<br/>    , COUNTIF(CLASS &gt; 0) AS pos<br/>    , COUNTIF(CLASS = 0) AS neg<br/>FROM `bigquery-public-data`.ml_datasets.ulb_fraud_detection<br/>)</span><span id="999a" class="ls lt iq mr b gy mz mw l mx my">SELECT<br/>   train_cutoff<br/>    , SAFE.LOG(SAFE_DIVIDE(pos,neg)) AS output_bias<br/>    , 0.5*SAFE_DIVIDE(pos + neg, pos) AS weight_pos<br/>    , 0.5*SAFE_DIVIDE(pos + neg, neg) AS weight_neg<br/>FROM counts</span></pre><p id="c358" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这给了我以下数字:Keras模型的输出偏差需要设置为-6.36，类权重需要为289.4和0.5。</p><h2 id="8632" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">创建Keras模型</h2><p id="4aa6" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">然后，我们可以创建一个Keras模型，其中包含两个隐藏的全连接层和一个丢弃层(以限制过拟合)，并注意为输出层提供初始偏差，为损失函数提供类权重:</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="b1f6" class="ls lt iq mr b gy mv mw l mx my"># Deep learning model<br/>d1 = tf.keras.layers.Dense(16, activation='relu', name='d1')(input_layer)<br/>d2 = tf.keras.layers.Dropout(0.25, name='d2')(d1)<br/>d3 = tf.keras.layers.Dense(16, activation='relu', name='d3')(d2)<br/>output = tf.keras.layers.Dense(1, activation='sigmoid', name='d4', bias_initializer=tf.keras.initializers.Constant())(d3)</span><span id="934f" class="ls lt iq mr b gy mz mw l mx my">model = tf.keras.Model(inputs, output)<br/>model.compile(optimizer='adam',<br/>              loss='binary_crossentropy',<br/>              metrics=metrics)</span><span id="d0dd" class="ls lt iq mr b gy mz mw l mx my">class_weight = {0: 0.5, 1: 289.4}<br/>history = model.fit(train_df, validation_data=eval_df, epochs=20, class_weight=class_weight)</span></pre><p id="f822" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">结果呢？经过20次迭代，我得到了:</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="55da" class="ls lt iq mr b gy mv mw l mx my">val_accuracy: 0.9718 - val_precision: 0.0401 - val_recall: 0.8831 - val_roc_auc: 0.9865</span></pre><p id="c500" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这比标准的逻辑回归模型要好，但只是勉强好。我们将需要进一步超参数调整节点数、掉线等。深度学习模型比这做得更好。</p><h2 id="29c2" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">将张量流模型加载到BigQuery中</h2><p id="23d1" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">可以将训练好的TensorFlow模型加载到BigQuery中，用它来做推理。要加载模型，请从Keras调用:</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="0c9c" class="ls lt iq mr b gy mv mw l mx my">model.save('gs://{}/bqexample/export'.format(BUCKET))</span></pre><p id="fc00" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，在BigQuery中，执行以下操作:</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="ff50" class="ls lt iq mr b gy mv mw l mx my">CREATE OR REPLACE MODEL advdata.keras_fraud_detection <br/>OPTIONS(model_type='tensorflow',   <br/>        model_path='gs://BUCKETNAME/bqexample/export/*')</span></pre><p id="d637" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您可以使用此模型进行预测，就好像它是一个原生的BigQuery ML逻辑回归模型一样:</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="8e9a" class="ls lt iq mr b gy mv mw l mx my">SELECT d4, Class<br/>FROM ML.PREDICT( MODEL advdata.keras_fraud_detection,<br/>  (SELECT * FROM `bigquery-public-data.ml_datasets.ulb_fraud_detection` WHERE Time = 85285.0)<br/>)</span></pre><p id="1c78" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上面将其称为d4的原因是我的Keras输出节点被称为d4。</p><h2 id="2b67" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">摘要</h2><p id="2c9e" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">在本文中，您看到了如何:</p><ul class=""><li id="7269" class="na nb iq kh b ki kj kl km ko nc ks nd kw ne la nf ng nh ni bi translated">直接从BigQuery读入TensorFlow 2.0/Keras模型</li><li id="5be6" class="na nb iq kh b ki nj kl nk ko nl ks nm kw nn la nf ng nh ni bi translated">如何将训练好的模型加载到BigQuery中</li></ul><p id="1bcc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这个过程中，您还看到了如何在高度不平衡的数据上训练BigQuery ML模型和Keras模型。</p><h2 id="94fb" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">后续步骤:</h2><ol class=""><li id="791e" class="na nb iq kh b ki ml kl mm ko no ks np kw nq la nr ng nh ni bi translated">本文中的代码在GitHub 上的一个<a class="ae lb" href="https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/blogs/bigquery_datascience/bigquery_tensorflow.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本里。在AI平台笔记本上试用一下。</a></li><li id="68a0" class="na nb iq kh b ki nj kl nk ko nl ks nm kw nn la nr ng nh ni bi translated">关于BigQuery的更多信息，请阅读由O'Reilly Media出版的《BigQuery:权威指南》一书:</li></ol><p id="5a77" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="ns">注意:根据贵公司的定价方案，使用超过一定限制的</em> <a class="ae lb" href="https://cloud.google.com/bigquery/pricing#storage-api" rel="noopener ugc nofollow" target="_blank"> <em class="ns">存储API可能会产生BigQuery费用</em> </a> <em class="ns">。在我写这篇文章的时候，采用统一费率计划的客户如果每月的读取量超过300 TB，就会开始产生这些费用。</em></p></div></div>    
</body>
</html>