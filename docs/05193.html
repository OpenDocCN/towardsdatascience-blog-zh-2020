<html>
<head>
<title>Building a Disaster Response Web-Application</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建灾难响应网络应用程序</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-disaster-response-web-application-4066e6f90072?source=collection_archive---------50-----------------------#2020-05-03">https://towardsdatascience.com/building-a-disaster-response-web-application-4066e6f90072?source=collection_archive---------50-----------------------#2020-05-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="98c6" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在现实生活中使用机器学习模型来对抗灾难</h2></div><h1 id="3619" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">当前问题</h1><p id="59da" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">2019 年全球共发生<a class="ae lw" href="https://www.statista.com/statistics/510959/number-of-natural-disasters-events-globally/" rel="noopener ugc nofollow" target="_blank"> 409 </a>起自然灾害。具有讽刺意味的是，由于 Covid19，我们现在正处于全球疫情的中心。在灾难期间或灾难发生后，数百万人直接或通过社交媒体进行交流，以获得政府或救灾和恢复服务的帮助。如果受影响的人在推特上发布消息，甚至向帮助热线服务发送消息，那么该消息很可能会在收到的数千条消息中丢失。有时，这是因为很多人只是在发微博，很少有人需要帮助，组织没有足够的时间来手动过滤掉这么多信息。</p><p id="2d80" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">因此，在这个项目中，我们将构建一个灾难响应 web 应用程序，该应用程序将消息分类为不同的类别，如医疗用品、食物或阻塞道路，并将它们发送到正确的组织以提供快速恢复！</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi mc"><img src="../Images/11855feaca4dbbe28e74f0ea1773ec3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*s6tzx9iUTs9Qr52q"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated"><a class="ae lw" href="https://images.unsplash.com/photo-1475776408506-9a5371e7a068?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=500&amp;q=60" rel="noopener ugc nofollow" target="_blank">图片来源</a></p></figure><h1 id="5e5f" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">数据概述</h1><p id="dd53" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们将分析灾难事件中发送的真实信息。数据由<a class="ae lw" href="https://appen.com/" rel="noopener ugc nofollow" target="_blank">数字 8</a>收集，由<a class="ae lw" href="https://classroom.udacity.com/courses/ud257" rel="noopener ugc nofollow" target="_blank"> Udacity </a>提供，非常感谢他们。我们来看数据描述:</p><ol class=""><li id="60b4" class="ms mt it lc b ld lx lg ly lj mu ln mv lr mw lv mx my mz na bi translated"><strong class="lc iu"> messages.csv: </strong>包含 id、发送的消息和类型，即方法(直接，推文..)消息已发送。</li><li id="7dfe" class="ms mt it lc b ld nb lg nc lj nd ln ne lr nf lv mx my mz na bi translated"><strong class="lc iu"> categories.csv: </strong>包含 id 和类别(相关、报价、医疗援助..)该消息属于。</li></ol><h1 id="3608" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">ETL 管道</h1><p id="b141" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">因此，在这一部分中，我们将在公共 id 列上合并两个数据集,<strong class="lc iu"> messages.csv 和 categories.csv </strong>。id <strong class="lc iu"> categories.csv </strong>中的类别列是字符串格式，因此我们需要为每个类别创建列。然后，我们将删除重复项，并将转换后的数据加载到使用 SQLAlchemy 库托管的数据库中。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/db1a1c2accd7ce23989ed0ccc9450430.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*eYtOsK4PowFQrl0FE7-5iQ.png"/></div></figure><p id="f1af" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">类别的形式如下:</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/2b7317ac7ce26958aa68abc528bc7b43.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*_0t7hCJT_tCU6Pn85e9hLQ.png"/></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">类别. csv</p></figure><p id="5a0f" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">转型后:</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/459f2bf04172195761803a63091829af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*t4CrRIQArf11E7LL2a_UzA.png"/></div></figure><p id="1c51" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">最后，我们将转换后的数据加载到数据库:<strong class="lc iu"> disaster.db </strong></p><p id="4f25" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">签出整个 ETL 管道<strong class="lc iu"> </strong> <a class="ae lw" href="https://github.com/harshdarji23/Disaster-Response-WebApplication/blob/master/Jupyter%20Notebooks/ETL%20Pipeline%20Preparation.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu">这里</strong> </a></p><pre class="md me mf mg gt nj nk nl nm aw nn bi"><span id="5a1d" class="no kj it nk b gy np nq l nr ns">engine = create_engine('sqlite:///disaster.db')<br/>df.to_sql('disaster_response', engine, index=<strong class="nk iu">False</strong>)</span></pre><h1 id="59ab" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">ML 管道</h1><p id="c8b0" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">这里，我们将从 disaster.db 数据库加载数据集。我们的主要任务是将消息转换成令牌，以便它们可以被解释。因此，我们创建了一个函数，它将删除标点符号，<a class="ae lw" href="https://www.nltk.org/api/nltk.tokenize.html" rel="noopener ugc nofollow" target="_blank">标记</a>单词，删除停用单词，并执行<a class="ae lw" href="https://www.geeksforgeeks.org/python-lemmatization-with-nltk/" rel="noopener ugc nofollow" target="_blank">词汇化</a>。</p><pre class="md me mf mg gt nj nk nl nm aw nn bi"><span id="bc5f" class="no kj it nk b gy np nq l nr ns">url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&amp;+]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'</span><span id="10bc" class="no kj it nk b gy nt nq l nr ns"><strong class="nk iu">def</strong> tokenize(text):<br/>    <em class="nu"># Detect URLs</em><br/>    detected_urls = re.findall(url_regex, text)<br/>    <strong class="nk iu">for</strong> url <strong class="nk iu">in</strong> detected_urls:<br/>        text = text.replace(url, 'urlplaceholder')<br/>    <br/>    <em class="nu"># Normalize and tokenize and remove punctuation</em><br/>    tokens = nltk.word_tokenize(re.sub(r"[^a-zA-Z0-9]", " ", text.lower()))<br/>    <br/>    <em class="nu"># Remove stopwords</em><br/>    tokens = [t <strong class="nk iu">for</strong> t <strong class="nk iu">in</strong> tokens <strong class="nk iu">if</strong> t <strong class="nk iu">not</strong> <strong class="nk iu">in</strong> stopwords.words('english')]</span><span id="90c5" class="no kj it nk b gy nt nq l nr ns">    <em class="nu"># Lemmatize</em><br/>    lemmatizer=WordNetLemmatizer()<br/>    tokens = [lemmatizer.lemmatize(t) <strong class="nk iu">for</strong> t <strong class="nk iu">in</strong> tokens]<br/>    <br/>    <strong class="nk iu">return</strong> tokens</span></pre><p id="8eb4" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">这就是我们的函数要做的:</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/063d42b00a6ce2976896c95896a1b235.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/1*D2hkb6qSMwaKPGodlp8APQ.png"/></div><p class="mo mp gj gh gi mq mr bd b be z dk translated"><strong class="bd nw">输出</strong></p></figure><p id="251f" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">这些词是有意义的，但是它们不能被 ML 模型理解。因此，我们将使用<a class="ae lw" href="https://www.youtube.com/watch?v=RZYjsw6P4nI" rel="noopener ugc nofollow" target="_blank">计数矢量器</a>和<a class="ae lw" href="https://www.youtube.com/watch?v=WN18JksF9Cg" rel="noopener ugc nofollow" target="_blank"> tfidf </a>转换器将令牌转换为特征(整数)，并使用简单的随机森林分类器来拟合训练数据。</p><pre class="md me mf mg gt nj nk nl nm aw nn bi"><span id="7885" class="no kj it nk b gy np nq l nr ns">pipeline = Pipeline([<br/>    ('vect', CountVectorizer(tokenizer = tokenize))<br/>    , ('tfidf', TfidfTransformer())<br/>    , ('clf', MultiOutputClassifier(RandomForestClassifier()))])</span><span id="bdfa" class="no kj it nk b gy nt nq l nr ns">pipeline.fit(X_train, Y_train)</span></pre><p id="f317" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">为了评估我们的模型，我们将使用<a class="ae lw" href="https://medium.com/analytics-vidhya/accuracy-vs-f1-score-6258237beca2" rel="noopener"> F-1 评分</a>，因为假阴性和假阳性对我们来说都很重要，也就是说，如果我们无法预测正确的邮件类别，那么我们就无法提供正确的帮助，如果我们错误地预测了邮件的类别，那么我们就是在浪费时间。</p><p id="fcd0" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated"><a class="ae lw" rel="noopener" target="_blank" href="/understanding-random-forest-58381e0602d2">随机森林分类器</a>给我们的 F-1 分数为<strong class="lc iu"> 0.44。</strong>得分低的主要原因是类别高度不平衡。这些类别的分布如下:</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi nx"><img src="../Images/e8368735e0c7153889df3a4140b2bdd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k01VKOQS26M90yNbw9xcow.png"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">分配</p></figure><p id="ba52" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">让我们使用一些不同的 ML 模型和超参数调整来改进模型。因此，在进行 GridSearchCV 以找到随机森林模型的最佳参数后，我们能够将 F-1 分数增加到<strong class="lc iu"> 0.51。</strong>接下来，我们训练<a class="ae lw" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html" rel="noopener ugc nofollow" target="_blank"> AdaBoost </a>分类器，我们能够将 F-1 分数提高到<strong class="lc iu"> 0.59 </strong></p><pre class="md me mf mg gt nj nk nl nm aw nn bi"><span id="a821" class="no kj it nk b gy np nq l nr ns"><em class="nu">#https://medium.com/swlh/the-hyperparameter-cheat-sheet-770f1fed32ff</em><br/>pipeline_ada = Pipeline([<br/>    ('vect', CountVectorizer(tokenizer=tokenize)),<br/>    ('tfidf', TfidfTransformer()),<br/>    ('clf', MultiOutputClassifier(<br/>        AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1, class_weight='balanced'))<br/>    ))<br/>])</span><span id="142c" class="no kj it nk b gy nt nq l nr ns">parameters_ada = {<br/>    'clf__estimator__learning_rate': [0.1, 0.3],<br/>    'clf__estimator__n_estimators': [100, 200]<br/>}</span><span id="c6aa" class="no kj it nk b gy nt nq l nr ns">cv_ada = GridSearchCV(estimator=pipeline_ada, param_grid=parameters_ada, cv=3, scoring='f1_weighted', verbose=3)</span></pre><p id="053f" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated">我们将这个模型保存为 pickle 文件，这样我们就不需要再次训练它。代码可用<a class="ae lw" href="https://github.com/harshdarji23/Disaster-Response-WebApplication/blob/master/Jupyter%20Notebooks/ML%20Pipeline%20Preparation.ipynb" rel="noopener ugc nofollow" target="_blank">此处</a></p><pre class="md me mf mg gt nj nk nl nm aw nn bi"><span id="1ef3" class="no kj it nk b gy np nq l nr ns">pickle.dump(cv_ada, open('disaster_ada_model.sav', 'wb'))</span></pre><h1 id="f70e" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">烧瓶应用</h1><p id="cf66" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们将创建一个<strong class="lc iu">train _ classifier . py</strong>来创建转换、加载、构建和保存模型的函数。基本上，我们将使用 ETL 管道和 ML 管道。我们将创建一个名为 app 的文件夹，其中包含一个 master.html 文件，该文件将作为前端，run.py 将在后端运行以执行计算。代码可以在<a class="ae lw" href="https://github.com/harshdarji23/Disaster-Response-WebApplication/tree/master/workspace/app" rel="noopener ugc nofollow" target="_blank">这里</a>和<a class="ae lw" href="https://github.com/harshdarji23/Disaster-Response-WebApplication/tree/master/workspace/app/templates" rel="noopener ugc nofollow" target="_blank">这里</a>找到。以下是演示:<a class="ae lw" href="https://twitter.com/harshdarji_23/status/1256761506949222407?s=20" rel="noopener ugc nofollow" target="_blank">https://Twitter . com/harshdarji _ 23/status/1256761506949222407？s=20 </a></p><figure class="md me mf mg gt mh"><div class="bz fp l di"><div class="ny nz l"/></div></figure><h1 id="6458" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">结论</h1><p id="74c6" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">构建一个全栈多输出的 ML web 应用，将灾害发生时发送的消息进行不同的分类，提供不同救灾组织的快速援助。您可以按照此处的说明<a class="ae lw" href="https://github.com/harshdarji23/Disaster-Response-WebApplication" rel="noopener ugc nofollow" target="_blank">在自己的电脑上运行该应用程序。</a></p><p id="3b8f" class="pw-post-body-paragraph la lb it lc b ld lx ju lf lg ly jx li lj lz ll lm ln ma lp lq lr mb lt lu lv im bi translated"><em class="nu">感谢您的阅读！</em></p></div></div>    
</body>
</html>