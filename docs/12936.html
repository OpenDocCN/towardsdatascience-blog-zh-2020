<html>
<head>
<title>A Complete Guide to Using TensorBoard with PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 PyTorch 的 TensorBoard 完全指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-complete-guide-to-using-tensorboard-with-pytorch-53cb2301e8c3?source=collection_archive---------2-----------------------#2020-09-06">https://towardsdatascience.com/a-complete-guide-to-using-tensorboard-with-pytorch-53cb2301e8c3?source=collection_archive---------2-----------------------#2020-09-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/fa21da42b37216616a92414cf736ab54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*NRPYVPS4Kh103yPj"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">艾萨克·史密斯在<a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="5a2c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本文中，我们将把 TensorBoard 集成到我们的<strong class="ki iu"> PyTorch </strong>项目中。TensorBoard 是一套用于检查和理解模型运行和图形的网络应用程序。TensorBoard 目前支持五种可视化:<strong class="ki iu">标量、图像、音频、直方图和图形</strong>。在本指南中，我们将涵盖除音频之外的所有五个方面，并学习如何使用 TensorBoard 进行高效的超参数分析和调谐。</p><h1 id="b1fd" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated"><strong class="ak">安装指南:</strong></h1><ol class=""><li id="0023" class="mc md it ki b kj me kn mf kr mg kv mh kz mi ld mj mk ml mm bi translated">确保您的 PyTorch 版本高于 1.10。对于本指南，我使用的是版本<strong class="ki iu"> 1.5.1。</strong>使用此命令检查您的 PyTorch 版本。</li></ol><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="1512" class="mw lf it ms b gy mx my l mz na">import torch<br/>print(torch.__version__)</span></pre><p id="7d0c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">2.安装 TensordBoard 有两个包管理器— <strong class="ki iu"> pip 或 Anaconda </strong>。根据您的 python 版本，使用以下任一选项:</p><p id="a32f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Pip 安装命令:</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="3e5c" class="mw lf it ms b gy mx my l mz na">pip install tensorboard</span></pre><p id="174b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Anaconda 安装命令:</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="f6bb" class="mw lf it ms b gy mx my l mz na">conda install -c conda-forge tensorboard</span></pre><p id="9bf3" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">注意:</strong>安装<strong class="ki iu"> TensorFlow </strong>并不是运行 TensorBoard 的先决条件，尽管它是 TensorFlow 生态系统的产品，TensorBoard 本身可以与 PyTorch 一起使用。</p><h2 id="215f" class="mw lf it bd lg nb nc dn lk nd ne dp lo kr nf ng ls kv nh ni lw kz nj nk ma nl bi translated">简介:</h2><p id="bff0" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr nm kt ku kv nn kx ky kz no lb lc ld im bi translated">在本指南中，我们将使用<strong class="ki iu"> FashionMNIST </strong>数据集(60，000 张服装图片和不同服装类型的 10 个类别标签)，这是一个内置在<strong class="ki iu"> torch vision </strong>库中的流行数据集。它由衣服、鞋子、配饰等图像组成。以及对应于每个类别的整数标签。我们将创建一个简单的 CNN 分类器，然后从中进行推论。尽管如此，本指南将帮助您将 TensorBoard 的功能扩展到 PyTorch 中的任何项目，包括使用自定义数据集创建的项目。</p><p id="a9e8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意，在本指南中，我们不会详细介绍如何实现<strong class="ki iu"> CNN </strong>模型以及如何设置训练循环。相反，本文的重点将是深度学习项目的簿记方面，以获得模型内部工作的可视化(权重和偏差)和评估指标(<strong class="ki iu">损失，准确性，数量 _ 正确 _ 预测</strong>)以及超参数调整。如果你是 PyTorch 框架的新手，在继续之前，看看我的另一篇关于在 PyTorch 中实现 CNN 的文章<a class="ae kf" href="https://medium.com/analytics-vidhya/implementing-cnn-in-pytorch-with-custom-dataset-and-transfer-learning-1864daac14cc" rel="noopener"/>(<strong class="ki iu">处理数据集，将数据移动到 GPU，创建模型和训练循环</strong>)。</p><h2 id="6ef0" class="mw lf it bd lg nb nc dn lk nd ne dp lo kr nf ng ls kv nh ni lw kz nj nk ma nl bi translated">导入库和帮助函数:</h2><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="3936" class="mw lf it ms b gy mx my l mz na">import torch<br/>import torch.nn as nn<br/>import torch.optim as opt<br/>torch.set_printoptions(linewidth=120)<br/>import torch.nn.functional as F<br/>import torchvision<br/>import torchvision.transforms as transforms<br/><strong class="ms iu">from torch.utils.tensorboard import SummaryWriter</strong></span></pre><p id="8093" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后一个命令使我们能够导入 Tensorboard 类。我们将创建<strong class="ki iu">“summary writer”</strong>的实例，然后添加我们模型的评估特性，如损失、正确预测的数量、准确性等。敬它。TensorBoard 的一个新颖特性是，我们只需向它输入输出张量，它就会显示所有这些指标的绘图，这样 TensorBoard 就可以为我们处理所有的绘图工作。</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="8a0d" class="mw lf it ms b gy mx my l mz na">def get_num_correct(preds, labels):<br/>    return preds.argmax(dim=1).eq(labels).sum().item()</span></pre><p id="304d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这一行代码帮助我们在训练模型并将训练好的模型应用到测试集之后获得正确标签的数量。<strong class="ki iu"> "argmax " </strong>获取张量中最高值对应的索引。它是在 dim=1 上拍摄的，因为 dim=0 对应于一批图像。<strong class="ki iu">“eq”</strong>将批中的预测标签与真实标签进行比较，如果匹配则返回 1，如果不匹配则返回 0。最后，我们取 1 的总和<strong class="ki iu">来得到正确预测的总数。对张量执行操作后，输出也作为张量返回。<strong class="ki iu"> "item" </strong>将 correct_predictions 的一维张量转换为浮点值，以便将其附加到列表(total_correct)中，以便在 TensorBoard 中绘图(张量如果附加到列表中，则不能在 TensorBoard 中绘图，因此我们需要将其转换为浮点值，将其附加到列表中，然后将此列表传递给 TensorBoard 进行绘图)。</strong></p><h2 id="7460" class="mw lf it bd lg nb nc dn lk nd ne dp lo kr nf ng ls kv nh ni lw kz nj nk ma nl bi translated">CNN 模型:</h2><p id="afb7" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr nm kt ku kv nn kx ky kz no lb lc ld im bi translated">我们创建了一个简单的 CNN 模型，将图像通过两个卷积层，然后是一组完全连接的层。最后，我们将在最后使用一个<strong class="ki iu"> Softmax </strong>层来预测类标签。</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="82b7" class="mw lf it ms b gy mx my l mz na">class CNN(nn.Module):<br/>    def __init__(self):<br/>        super().__init__()<br/>        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)<br/>        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)<br/><br/>        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)<br/>        self.fc2 = nn.Linear(in_features=120, out_features=60)<br/>        self.out = nn.Linear(in_features=60, out_features=10)<br/><br/>    def forward(self, x):<br/>        x = F.relu(self.conv1(x))<br/>        x = F.max_pool2d(x, kernel_size = 2, stride = 2)<br/>        x = F.relu(self.conv2(x))<br/>        x = F.max_pool2d(x, kernel_size = 2, stride = 2)<br/>        x = torch.flatten(x,start_dim = 1)<br/>        x = F.relu(self.fc1(x))<br/>        x = F.relu(self.fc2(x))<br/>        x = self.out(x)<br/><br/>        return x</span></pre><h2 id="540d" class="mw lf it bd lg nb nc dn lk nd ne dp lo kr nf ng ls kv nh ni lw kz nj nk ma nl bi translated">导入数据并创建列车加载器:</h2><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="1136" class="mw lf it ms b gy mx my l mz na">train_set = torchvision.datasets.FashionMNIST(root="./data",<br/>train = True,<br/> download=True,<br/>transform=transforms.ToTensor())</span><span id="a394" class="mw lf it ms b gy np my l mz na">train_loader = torch.utils.data.DataLoader(train_set,batch_size = 100, shuffle = True)</span></pre><h2 id="63f1" class="mw lf it bd lg nb nc dn lk nd ne dp lo kr nf ng ls kv nh ni lw kz nj nk ma nl bi translated">用 TensorBoard 显示图像和图形:</h2><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="1435" class="mw lf it ms b gy mx my l mz na"><strong class="ms iu">tb = SummaryWriter()</strong><br/>model = CNN()<br/>images, labels = next(iter(train_loader))<br/>grid = torchvision.utils.make_grid(images)<br/><strong class="ms iu">tb.add_image("images", grid)<br/>tb.add_graph(model, images)<br/>tb.close()</strong></span></pre><p id="7706" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们创建一个<strong class="ki iu"> SummaryWriter </strong>的实例‘TB ’,并通过使用<strong class="ki iu"> tb.add_image </strong>函数向其添加图像。它有两个主要参数，一个是图像的<strong class="ki iu">标题</strong>，另一个是图像的<strong class="ki iu">张量</strong> <strong class="ki iu">。在这种情况下，我们已经创建了一批<strong class="ki iu"> 100 个</strong>图像，并将它们传递给一个<strong class="ki iu">网格</strong>，然后将其添加到 tb 实例中。对于<strong class="ki iu"> tb.add_graph </strong>函数，我们传递我们的 CNN 模型和一批输入图像来生成模型的图形。运行代码后，将在项目目录中创建一个<strong class="ki iu">“runs”</strong>文件夹。所有进行中的运行将按<strong class="ki iu">日期</strong>在文件夹中分类。这样你就有了一个所有跑步的有效日志，可以在 TensorBoard 中查看和比较。</strong></p><p id="dd58" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在使用命令行(我使用 Anaconda 提示符)重定向到 runs 文件夹所在的项目目录，并运行以下命令:</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="fcee" class="mw lf it ms b gy mx my l mz na">tensorboard --logdir runs</span></pre><p id="a13d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，它将在本地主机上为 TensorBoard 提供服务，其链接将显示在终端中:</p><figure class="mn mo mp mq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nq"><img src="../Images/bc0d31e2731ae9eb4ee228085195d9b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gHl5z-XEgN7jCrvWhEvi3g.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">“TensorFlow 未安装”警告可以忽略</p></figure><p id="a853" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">打开链接后，我们将能够看到我们所有的运行。图像在<strong class="ki iu">“图像”</strong>选项卡下可见。我们可以使用正则表达式过滤运行，并勾选我们感兴趣的可视化。</p><figure class="mn mo mp mq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nr"><img src="../Images/94c234e35e654361866e58e235b97b27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cpjLsdeF0xLHsgZ2VwcBRg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">张量板中图像的网格图</p></figure><p id="fee8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在<strong class="ki iu">“图表”</strong>选项卡下，您将找到该型号的图表。它给出了在每一次卷积和线性层操作之后，整批图像的尺寸如何变化的整个管道的细节。只需双击任一图标，即可从图表中获取更多信息。它还通过双击任何 Conv2d 或线性层给出所有权重和偏差矩阵的维度。</p><figure class="mn mo mp mq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ns"><img src="../Images/dd46113d4ac09ad8778562eda98cbd2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:718/format:webp/1*xPuE7rwXmhkrV-OerY_IKQ.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">使用张量板为 CNN 模型生成的图形</p></figure><h1 id="aa9f" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">可视化评估的训练循环:</h1><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="a8e8" class="mw lf it ms b gy mx my l mz na">device = ("cuda" if torch.cuda.is_available() else cpu)<br/>model = CNN().to(device)<br/>train_loader = torch.utils.data.DataLoader(train_set,batch_size = 100, shuffle = True)<br/>optimizer = opt.Adam(model.parameters(), lr= 0.01)<br/>criterion = torch.nn.CrossEntropyLoss()<br/><br/><strong class="ms iu">tb = SummaryWriter()</strong><br/><br/>for epoch in range(10):<br/><br/>    total_loss = 0<br/>    total_correct = 0<br/><br/>    for images, labels in train_loader:<br/>        images, labels = images.to(device), labels.to(device)<br/>        preds = model(images)<br/><br/>        loss = criterion(preds, labels)<br/>        total_loss+= loss.item()<br/>        total_correct+= get_num_correct(preds, labels)<br/><br/>        optimizer.zero_grad()<br/>        loss.backward()<br/>        optimizer.step()<br/><br/><strong class="ms iu">    tb.add_scalar("Loss", total_loss, epoch)<br/>    tb.add_scalar("Correct", total_correct, epoch)<br/>    tb.add_scalar("Accuracy", total_correct/ len(train_set), epoch)<br/><br/>    tb.add_histogram("conv1.bias", model.conv1.bias, epoch)<br/>    tb.add_histogram("conv1.weight", model.conv1.weight, epoch)<br/>    tb.add_histogram("conv2.bias", model.conv2.bias, epoch)<br/>    tb.add_histogram("conv2.weight", model.conv2.weight, epoch)</strong><br/><br/>    print("epoch:", epoch, "total_correct:", total_correct, "loss:",total_loss)<br/><br/><strong class="ms iu">tb.close()</strong></span></pre><p id="b2e2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">或者，我们也可以使用 for 循环迭代所有模型参数，包括<strong class="ki iu"> fc </strong>和<strong class="ki iu"> softmax </strong>层:</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="a0cf" class="mw lf it ms b gy mx my l mz na">for name, weight in model.named_parameters():<br/><strong class="ms iu">    tb.add_histogram(name,weight, epoch)<br/>    tb.add_histogram(f'{name}.grad',weight.grad, epoch)</strong></span></pre><p id="7780" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们运行循环<strong class="ki iu"> 10 个时期</strong>，在训练循环结束时，我们将增量传递给我们创建的 tb 变量。我们已经创建了<strong class="ki iu"> total_loss </strong>和<strong class="ki iu"> total_correct </strong>变量来跟踪每个时期结束时的<strong class="ki iu">损失</strong>和<strong class="ki iu">正确预测</strong>。注意，每个“tb”都有三个参数，一个是字符串，它将是折线图/直方图的<strong class="ki iu">标题</strong>，然后是包含要绘制的<strong class="ki iu">值</strong>的张量，最后是<strong class="ki iu">全局步骤</strong>。<strong class="ki iu"> </strong>由于我们正在做一个纪元式分析，我们将其设置为纪元。或者，也可以通过使用“枚举”移动 for 循环内的 tb 命令，将其设置为<strong class="ki iu">批处理 id </strong>，并将步骤设置为<strong class="ki iu">批处理 id </strong>，如下所示:</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="38a6" class="mw lf it ms b gy mx my l mz na">for batch_id, (images, labels) in enumerate(train_loader):<br/>......<br/>    <strong class="ms iu">tb.add_scalar("Loss", total_loss, batch_id)</strong></span></pre><p id="6e3e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如下图所示，运行前面提到的命令来运行 TensorBoard 将显示<strong class="ki iu">损失、数量 _ 正确 _ 预测</strong>和<strong class="ki iu">精度的线图和直方图。</strong></p><h2 id="c07a" class="mw lf it bd lg nb nc dn lk nd ne dp lo kr nf ng ls kv nh ni lw kz nj nk ma nl bi translated"><strong class="ak">线条图:</strong></h2><p id="ba0f" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr nm kt ku kv nn kx ky kz no lb lc ld im bi translated">沿着图表移动<strong class="ki iu">橙色圆点</strong>将为我们提供该特定<strong class="ki iu">时期</strong>的相应度量(准确度/正确/损失)的日志。</p><figure class="mn mo mp mq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nt"><img src="../Images/a44871b097e27ea40f52f9ae028a60a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M7LV1Vvxd66dYss5Lod-Mw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">TensorBoard 生成的线图</p></figure><h2 id="93e4" class="mw lf it bd lg nb nc dn lk nd ne dp lo kr nf ng ls kv nh ni lw kz nj nk ma nl bi translated"><strong class="ak">直方图:</strong></h2><figure class="mn mo mp mq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nu"><img src="../Images/1125d76e68e7be43221e13003c3f9c72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0HVGp6sdxvfSwwRmFoit9Q.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">TensorBoard 生成的直方图</p></figure><h2 id="08ff" class="mw lf it bd lg nb nc dn lk nd ne dp lo kr nf ng ls kv nh ni lw kz nj nk ma nl bi translated">超参数调谐:</h2><p id="c4f8" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr nm kt ku kv nn kx ky kz no lb lc ld im bi translated">首先，我们需要将<strong class="ki iu"> batch_size、learning_rate、shuffle </strong>更改为动态变量。我们通过创建如下的字典来实现这一点:</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="5a18" class="mw lf it ms b gy mx my l mz na">from itertools import product<br/>parameters = dict(<br/>    lr = [0.01, 0.001],<br/>    batch_size = [32,64,128],<br/>    shuffle = [True, False]<br/>)<br/><br/>param_values = [v for v in parameters.values()]<br/>print(param_values)<br/><br/>for lr,batch_size, shuffle in product(*param_values):<br/>    print(lr, batch_size, shuffle)</span></pre><p id="65b4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这将允许我们获得三个元组，对应于<strong class="ki iu">三个超参数</strong>的所有组合，然后在运行每个历元循环之前对它们调用 for 循环。这样，我们将能够对所有不同的超参数组合进行<strong class="ki iu"> 12 </strong>次运行(2(learning _ rates)* 3(batch _ size)* 2(shuffles))，并在 TensorBoard 上进行比较。我们将按如下方式修改训练循环:</p><h1 id="b707" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">改进的训练循环:</h1><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="98b0" class="mw lf it ms b gy mx my l mz na">for run_id, (lr,batch_size, shuffle) in enumerate(product(*param_values)):<br/>    print("run id:", run_id + 1)<br/>    model = CNN().to(device)<br/>    train_loader = torch.utils.data.DataLoader(train_set,batch_size = batch_size, shuffle = shuffle)<br/>    optimizer = opt.Adam(model.parameters(), lr= lr)<br/>    criterion = torch.nn.CrossEntropyLoss()<br/>    <strong class="ms iu">comment = f' batch_size = {batch_size} lr = {lr} shuffle = {shuffle}'<br/>    tb = SummaryWriter(comment=comment)</strong><br/>    for epoch in range(5):<br/>        total_loss = 0<br/>        total_correct = 0<br/>        for images, labels in train_loader:<br/>            images, labels = images.to(device), labels.to(device)<br/>            preds = model(images)<br/><br/>            loss = criterion(preds, labels)<br/>            total_loss+= loss.item()<br/>            total_correct+= get_num_correct(preds, labels)<br/><br/>            optimizer.zero_grad()<br/>            loss.backward()<br/>            optimizer.step()<br/><br/>        <strong class="ms iu">tb.add_scalar("Loss", total_loss, epoch)<br/>        tb.add_scalar("Correct", total_correct, epoch)<br/>        tb.add_scalar("Accuracy", total_correct/ len(train_set), epoch)</strong><br/><br/>        print("batch_size:",batch_size, "lr:",lr,"shuffle:",shuffle)<br/>        print("epoch:", epoch, "total_correct:", total_correct, "loss:",total_loss)<br/>    print("__________________________________________________________")<br/><br/><strong class="ms iu">    tb.add_hparams(<br/>            {"lr": lr, "bsize": batch_size, "shuffle":shuffle},<br/>            {<br/>                "accuracy": total_correct/ len(train_set),<br/>                "loss": total_loss,<br/>            },<br/>        )</strong><br/><br/><strong class="ms iu">tb.close()</strong></span></pre><p id="d476" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如上所述，我们已经将所有内容移到 for 循环下，以检查所有不同的超参数组合，并且在每次运行时，我们必须重新实例化<strong class="ki iu">模型</strong>以及重新加载数据集的<strong class="ki iu">批次</strong>。<strong class="ki iu">“注释”</strong>允许我们根据指定的超参数在 runs 文件夹中创建不同的文件夹。我们将这个注释作为参数传递给<strong class="ki iu"> SummaryWriter </strong>。请注意，我们将能够一起查看所有运行，并在 TensorBoard 中绘制所有超参数的对比分析。<strong class="ki iu"> tb.add_scalar </strong>与之前的相同，只是这次我们将它显示在所有运行中。<strong class="ki iu"> tb.add_hparams </strong>允许我们在里面添加<strong class="ki iu">超参数</strong>作为参数来跟踪训练进度。它将两个字典作为输入，一个用于超参数，另一个用于要分析的评估指标。结果被映射到所有这些超参数上。从底部的图形映射图可以清楚地看到。</p><h2 id="994e" class="mw lf it bd lg nb nc dn lk nd ne dp lo kr nf ng ls kv nh ni lw kz nj nk ma nl bi translated">组合图:</h2><figure class="mn mo mp mq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nv"><img src="../Images/cbb3f82fae14d2287b87c8719537061b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HdgmDstQDh0oHPr-mCqXUw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">组合可视化的 12 次运行图</p></figure><p id="15c7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如上所述，我们可以过滤我们想要的任何运行，或者将它们绘制在同一个图表上。通过这种方式，我们可以对模型在多个超参数上的性能进行比较研究，并将模型调整到能够提供最佳性能的模型。在弹出框中可以看到所有细节，如批量大小、学习率、随机播放和相应的精度值。</p><p id="5988" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从结果中可以明显看出，批量大小为 32，shuffle 设置为 True，学习率为 0.01 时产生最好的结果。出于演示的目的，它只运行 5 个时期。增加历元的数量可以很好地影响结果，因此用几个历元值进行训练和测试是很重要的。</p><h2 id="e6cd" class="mw lf it bd lg nb nc dn lk nd ne dp lo kr nf ng ls kv nh ni lw kz nj nk ma nl bi translated">超参数图:</h2><figure class="mn mo mp mq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nw"><img src="../Images/881fe62ac2f338047706e64cfdc5566a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KyNodJzQXICecjtWV7WZjw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">张量板生成的超参数图</p></figure><p id="301e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该图包含所有 12 次运行的组合日志，因此您可以使用最高的准确度和最低的损失值，并将其追溯到相应的批次大小、学习率和洗牌配置。</p><p id="dbe5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从超参数图可以清楚地看出，将 shuffle 设置为 False(0)往往会产生非常差的结果。因此，将 shuffle 设置为 always True(1)对于训练是理想的，因为它增加了随机化。</p><h2 id="052e" class="mw lf it bd lg nb nc dn lk nd ne dp lo kr nf ng ls kv nh ni lw kz nj nk ma nl bi translated">结论:</h2><p id="8e85" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr nm kt ku kv nn kx ky kz no lb lc ld im bi translated">请随意使用 TensorBoard，尝试向图中添加更多的超参数，以获得尽可能多的关于给定各种超参数的模型的损失收敛模式和性能的信息。除了 Adam 之外，我们还可以添加一组优化器，并进行对比研究。在类似 LSTMs 的序列模型中，GRUs 可以将时间步长添加到图表中，并得出深刻的结论。希望这篇文章能让你对使用 PyTorch 的 TensorBoard 有一个全面的了解。</p></div><div class="ab cl nx ny hx nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="im in io ip iq"><p id="b4d5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">链接到代码:<a class="ae kf" href="https://github.com/ajinkya98/TensorBoard_PyTorch" rel="noopener ugc nofollow" target="_blank">https://github.com/ajinkya98/TensorBoard_PyTorch</a></p></div></div>    
</body>
</html>