<html>
<head>
<title>Dimensionality Reduction — Can PCA improve the performance of a classification model?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">降维——主成分分析能提高分类模型的性能吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/dimensionality-reduction-can-pca-improve-the-performance-of-a-classification-model-d4e34194c544?source=collection_archive---------44-----------------------#2020-08-19">https://towardsdatascience.com/dimensionality-reduction-can-pca-improve-the-performance-of-a-classification-model-d4e34194c544?source=collection_archive---------44-----------------------#2020-08-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="689b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">利用 PCA——降维技术提高 ML 模型的性能</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ae1db038c16a7f9988f7ca9d61cdcd02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wohT0WVlVQluK9L7"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">奥拉夫·阿伦斯·罗特内在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h2 id="4601" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">什么是 PCA？</h2><p id="1bba" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">主成分分析(PCA)是数据科学中一种常见的特征提取技术，它采用矩阵分解将数据的维度降低到较低的空间。</p><p id="dcf0" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">在现实世界的数据集中，数据中通常有太多的要素。要素数量越多，数据的可视化和处理就越困难。有时大多数特征是相关的，因此是多余的。因此，特征提取开始发挥作用。</p><h2 id="705f" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">关于数据:</h2><p id="172b" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">本文使用的数据集是来自 UCI 机器学习知识库的<a class="ae ky" href="https://archive.ics.uci.edu/ml/datasets/Ionosphere" rel="noopener ugc nofollow" target="_blank">电离层数据集。这是一个二元分类问题。有 351 个观察值和 34 个特征。</a></p><h2 id="acd7" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">准备数据集:</h2><ul class=""><li id="fcf3" class="mt mu it lx b ly lz mb mc li mv lm mw lq mx mn my mz na nb bi translated">导入必要的库并读取数据集</li><li id="51c1" class="mt mu it lx b ly nc mb nd li ne lm nf lq ng mn my mz na nb bi translated">数据集预处理</li><li id="3fc5" class="mt mu it lx b ly nc mb nd li ne lm nf lq ng mn my mz na nb bi translated">标准化</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h2 id="d50f" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">使用全部 34 个特征的逻辑回归 ML 模型:</h2><p id="488c" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">训练数据有 34 个特征。</p><ul class=""><li id="6a27" class="mt mu it lx b ly mo mb mp li nq lm nr lq ns mn my mz na nb bi translated">在对数据进行预处理后，使用逻辑回归算法对训练数据进行二值分类训练</li><li id="9cc8" class="mt mu it lx b ly nc mb nd li ne lm nf lq ng mn my mz na nb bi translated">微调逻辑回归模型以找到最佳参数</li><li id="8c98" class="mt mu it lx b ly nc mb nd li ne lm nf lq ng mn my mz na nb bi translated">计算训练和测试准确度以及 f1 分数。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/3f8763759fd50f79a4b3bbca08f0400e.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*0COLpEqDyRK_mqZj8s9ZmA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，34 个特征数据集的逻辑回归模型的 C 与 F1 得分图</p></figure><ul class=""><li id="00d3" class="mt mu it lx b ly mo mb mp li nq lm nr lq ns mn my mz na nb bi translated">使用 c=10**0 的 34 个特征训练 LR 模型</li><li id="2461" class="mt mu it lx b ly nc mb nd li ne lm nf lq ng mn my mz na nb bi translated">计算训练和测试准确度以及 f1 分数</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/c01b05223018ade6bc2fe748480f284a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y4kks7kPx8rRq0UkE2GbVA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，训练测试准确性和 F1 分数，混淆矩阵</p></figure><p id="417e" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">通过训练具有 34 个特征的整个“X_train”数据获得的结果，</p><blockquote class="nv"><p id="0d3a" class="nw nx it bd ny nz oa ob oc od oe mn dk translated">测试 f1 分数为 0.90，因为在混淆矩阵中观察到 14 个值被错误分类。</p></blockquote><figure class="of og oh oi oj kn"><div class="bz fp l di"><div class="nh ni l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h2 id="ff0c" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">使用主成分分析的特征提取；</h2><p id="eac8" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">为了使用 PCA 技术从数据集中提取特征，首先我们需要找到解释为维度减少的方差百分比。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/e204a48aa227a0b9f80a18a01fff9c11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*ScnbJcpGIAhT2SgV0CyO8w.png"/></div></figure><pre class="kj kk kl km gt ol om on oo aw op bi"><span id="2c85" class="kz la it om b gy oq or l os ot">Notations,<br/><strong class="om iu">λ: </strong>eigenvalue<strong class="om iu"><br/>d: </strong>number of dimension of original dataset<br/><strong class="om iu">k:</strong> number of dimensions of new feature space</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/0ef5b2e553cb92276b8ec1d67aa8b48f.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*qvmSEv-YwWBAjMusmeRMJQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，解释的方差百分比与维度数量的关系图</p></figure><ul class=""><li id="272b" class="mt mu it lx b ly mo mb mp li nq lm nr lq ns mn my mz na nb bi translated">从上面的图中可以看出，对于 15 个维度，解释的方差百分比为 90%。这意味着我们通过将较高的维度(34)投影到较低的空间(15)来保留 90%的方差。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure><h2 id="b97c" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">使用 PCA 的前 15 个特征训练逻辑回归 ML 模型:</h2><p id="e25a" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">现在 PCA 降维后的训练数据有 15 个特征。</p><ul class=""><li id="021b" class="mt mu it lx b ly mo mb mp li nq lm nr lq ns mn my mz na nb bi translated">在对数据进行预处理后，使用逻辑回归算法对训练数据进行二值分类训练</li><li id="61ca" class="mt mu it lx b ly nc mb nd li ne lm nf lq ng mn my mz na nb bi translated">微调逻辑回归模型以找到最佳参数</li><li id="8551" class="mt mu it lx b ly nc mb nd li ne lm nf lq ng mn my mz na nb bi translated">计算训练和测试准确度以及 f1 分数。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/39320bcb87e8681d276ec7763b9b9bd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*53EnIAefaWkbR-FTycZJWQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，15 个特征数据集的逻辑回归模型的 C 与 F1 分数的关系图</p></figure><ul class=""><li id="4283" class="mt mu it lx b ly mo mb mp li nq lm nr lq ns mn my mz na nb bi translated">使用 c=10**0 的 15 个特征训练 LR 模型</li><li id="7a9d" class="mt mu it lx b ly nc mb nd li ne lm nf lq ng mn my mz na nb bi translated">计算训练和测试准确度以及 f1 分数</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ow"><img src="../Images/e52287dc10332db36ac63faf4b478002.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7yiQeN6SorNHUHkXNseJjw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，训练测试准确性和 F1 分数，混淆矩阵</p></figure><p id="0b26" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">通过用 15 个特征训练 PCA 数据获得的结果，</p><blockquote class="nv"><p id="846a" class="nw nx it bd ny nz oa ob oc od oe mn dk translated">测试 f1 分数为 0.896，因为混淆矩阵中观察到 12 个值被错误分类。</p></blockquote><h2 id="2985" class="kz la it bd lb lc ox dn le lf oy dp lh li oz lk ll lm pa lo lp lq pb ls lt lu bi translated">比较上述两种模型的结果:</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/8b85f678afe6fddc70783d3f7d6643df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WdhWHiH5DEdvQVEFhHSEjw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，训练测试准确性和 F1 分数，混淆矩阵</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h2 id="c493" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">使用原始数据+来自 PCA 的数据训练 LR 模型:</h2><p id="7815" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">在连接具有 34 个特征的原始数据和具有 15 个特征的 PCA 数据之后，我们形成了具有 49 个特征的数据集。</p><ul class=""><li id="5601" class="mt mu it lx b ly mo mb mp li nq lm nr lq ns mn my mz na nb bi translated">在对数据进行预处理后，使用逻辑回归算法对训练数据进行二值分类训练</li><li id="903e" class="mt mu it lx b ly nc mb nd li ne lm nf lq ng mn my mz na nb bi translated">微调逻辑回归模型以找到最佳参数</li><li id="7743" class="mt mu it lx b ly nc mb nd li ne lm nf lq ng mn my mz na nb bi translated">计算训练和测试准确度以及 f1 分数。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/5909d0ba6996c4d84544ffe6e30752c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*OgP9orDllSF_A9HHuKhBhA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，49 个特征数据集的逻辑回归模型的 C 与 F1 得分图</p></figure><ul class=""><li id="bc20" class="mt mu it lx b ly mo mb mp li nq lm nr lq ns mn my mz na nb bi translated">使用 c=10**0 的 15 个特征训练 LR 模型</li><li id="28dd" class="mt mu it lx b ly nc mb nd li ne lm nf lq ng mn my mz na nb bi translated">计算训练和测试准确度以及 f1 分数</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/feb6b2178f43672abc1ba9c6809f0dfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*15cX6AwY26nFjftzqWwd3g.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，训练测试准确性和 F1 分数，混淆矩阵</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure><h2 id="9afc" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">从上述结果得出的结论:</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/2de8fac2ca63cad70f7e581e3547394f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*xkDhRIdhfuUib2zbKf5eQQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，上述三种模型的准确度和 F1 得分结果</p></figure><p id="5616" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">从上表中，我们可以观察到，</p><ul class=""><li id="5b66" class="mt mu it lx b ly mo mb mp li nq lm nr lq ns mn my mz na nb bi translated">使用具有 34 个特征的原始预处理数据集训练的 LR 模型，我们得到 90%的 F1 分数。</li><li id="0d9c" class="mt mu it lx b ly nc mb nd li ne lm nf lq ng mn my mz na nb bi translated">使用 PCA 仅用提取的 15 个特征训练的 LR 模型，我们得到 89%的 F1 分数。</li><li id="c263" class="mt mu it lx b ly nc mb nd li ne lm nf lq ng mn my mz na nb bi translated">用上述两个数据的组合训练的 LR 模型，我们得到 92%的 F1 分数。</li></ul><p id="98ba" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">让我们观察上述 3 个模型的混淆矩阵结果的变化。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/9d723189c47483d923f1027790ce70f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gN6NV_B-azonIJxVcH4lGA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，上述三种模型的混淆矩阵</p></figure><p id="1d04" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">因此，我们得出结论，仅使用 PCA 提取的特征，仅使用来自原始数据的 50%数量的特征，我们得到少 1%的 F1 分数。但是，如果我们将两个数据结合起来，我们将改进 2%的指标，以获得 91%的最终 F1 分数。</p><p id="b727" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><strong class="lx iu">点击下方获取代码:</strong></p><div class="pe pf gp gr pg ph"><a href="https://colab.research.google.com/drive/1hH5vJHNgCXohWhT5GXh5jzCasDtVxGHF?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="pi ab fo"><div class="pj ab pk cl cj pl"><h2 class="bd iu gy z fp pm fr fs pn fu fw is bi translated">谷歌联合实验室</h2><div class="po l"><h3 class="bd b gy z fp pm fr fs pn fu fw dk translated">编辑描述</h3></div><div class="pp l"><p class="bd b dl z fp pm fr fs pn fu fw dk translated">colab.research.google.com</p></div></div><div class="pq l"><div class="pr l ps pt pu pq pv ks ph"/></div></div></a></div><blockquote class="nv"><p id="1ce6" class="nw nx it bd ny nz pw px py pz qa mn dk translated">感谢您的阅读</p></blockquote></div></div>    
</body>
</html>