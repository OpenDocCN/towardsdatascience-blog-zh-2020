<html>
<head>
<title>How to Create an End to End Object Detector using Yolov5?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用 Yolov5 创建一个端到端的对象检测器？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-create-an-end-to-end-object-detector-using-yolov5-35fbb1a02810?source=collection_archive---------10-----------------------#2020-07-07">https://towardsdatascience.com/how-to-create-an-end-to-end-object-detector-using-yolov5-35fbb1a02810?source=collection_archive---------10-----------------------#2020-07-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div class="gh gi ir"><img src="../Images/3076b5be035e6274c9a548a787dafb95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*QvCHyXdY36jpwoz-2_n9yQ.gif"/></div></figure><div class=""/><div class=""><h2 id="393d" class="pw-subtitle-paragraph jx iz ja bd b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko dk translated">是的，Yolov5 在这里</h2></div><p id="b725" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">Ultralytics 最近在围绕其名称的争议中推出了 YOLOv5。作为背景，YOLO 的前三个版本(你只看一次)是由约瑟夫·雷德蒙创作的。在此之后，Alexey Bochkovskiy 在 darknet 上创建了 YOLOv4，它比以前的迭代拥有更高的平均精度(AP)和更快的结果。</p><p id="205f" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">现在，Ultralytics 发布了 YOLOv5，AP 相当，推理时间比 YOLOv4 更快。这让许多人不禁要问:一个新版本是否有理由获得与 YOLOv4 相似的精确度？无论答案是什么，这都是检测社区发展速度的一个明显标志。</p><figure class="lm ln lo lp gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi ll"><img src="../Images/9341840381a5899f26604dfba911e601.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2mlcIlRibI5OaXRL.png"/></div></div><p class="lu lv gj gh gi lw lx bd b be z dk translated"><a class="ae ly" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank">来源</a> : Ultralytics Yolov5</p></figure><p id="6ff6" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">自从他们<a class="ae ly" href="https://github.com/ultralytics/yolov3" rel="noopener ugc nofollow" target="_blank">首次移植 YOLOv3 </a>以来，Ultralytics 已经使使用 Pytorch 创建和部署模型变得非常简单，所以我渴望尝试 YOLOv5。事实证明，Ultralytics 进一步简化了这个过程，结果不言自明。</p><p id="d0be" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated"><strong class="kr jb"> <em class="lz">在本文中，我们将使用 YOLOv5 创建一个检测模型，从创建我们的数据集并对其进行注释，到使用他们卓越的库进行训练和推理。</em> </strong>本帖重点介绍 YOLOv5 的实现，包括:</p><ul class=""><li id="2232" class="ma mb ja kr b ks kt kv kw ky mc lc md lg me lk mf mg mh mi bi translated">创建玩具数据集</li><li id="05c7" class="ma mb ja kr b ks mj kv mk ky ml lc mm lg mn lk mf mg mh mi bi translated">注释图像数据</li><li id="1064" class="ma mb ja kr b ks mj kv mk ky ml lc mm lg mn lk mf mg mh mi bi translated">创建项目结构</li><li id="6dc0" class="ma mb ja kr b ks mj kv mk ky ml lc mm lg mn lk mf mg mh mi bi translated">培训 YOLOv5</li></ul></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="9251" class="mv mw ja bd mx my mz na nb nc nd ne nf kg ng kh nh kj ni kk nj km nk kn nl nm bi translated">创建自定义数据集</h1><p id="cf79" class="pw-post-body-paragraph kp kq ja kr b ks nn kb ku kv no ke kx ky np la lb lc nq le lf lg nr li lj lk im bi translated">如果您有图像数据集，可以放弃第一步。由于我没有图像，我正在从开放图像数据集(OID)下载数据，这是获取可用于分类和检测的带注释图像数据的绝佳资源。请注意，为了便于学习，我们不会使用 OID 提供的注释，而是创建自己的注释。</p><h2 id="6cea" class="ns mw ja bd mx nt nu dn nb nv nw dp nf ky nx ny nh lc nz oa nj lg ob oc nl od bi translated">1.OIDv4 下载图像:</h2><p id="32ba" class="pw-post-body-paragraph kp kq ja kr b ks nn kb ku kv no ke kx ky np la lb lc nq le lf lg nr li lj lk im bi translated">为了从开放的图像数据集中下载图像，我们首先克隆<a class="ae ly" href="https://github.com/EscVM/OIDv4_ToolKit" rel="noopener ugc nofollow" target="_blank"> OIDv4_ToolKit </a>并安装所有需求。</p><pre class="lm ln lo lp gt oe of og oh aw oi bi"><span id="c24d" class="ns mw ja of b gy oj ok l ol om">git clone <a class="ae ly" href="https://github.com/EscVM/OIDv4_ToolKit" rel="noopener ugc nofollow" target="_blank">https://github.com/EscVM/OIDv4_ToolKit</a><br/>cd <a class="ae ly" href="https://github.com/EscVM/OIDv4_ToolKit" rel="noopener ugc nofollow" target="_blank">OIDv4_ToolKit</a><br/>pip install -r requirements.txt</span></pre><p id="f9a5" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">我们现在可以使用这个文件夹中的<code class="fe on oo op of b">main.py</code>脚本来下载图像以及多个类的标签。</p><p id="de5d" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">下面我正在下载板球和足球的数据来创建我们的自定义数据集。也就是说，我们将创建一个足球和板球数据集，学习任务是检测这些球。</p><pre class="lm ln lo lp gt oe of og oh aw oi bi"><span id="5a3e" class="ns mw ja of b gy oj ok l ol om">python3 main.py downloader --classes Cricket_ball  Football --type_csv all -y --limit 500</span></pre><p id="4132" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">以下命令创建一个名为“OID”的目录，其结构如下:</p><figure class="lm ln lo lp gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi oq"><img src="../Images/1ff1998ed90ba889d7a078dbed52ecf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*17U_i8zbMxINN0jkeDyDdQ.png"/></div></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">OID 目录结构。我们将只取图像文件(。jpg ),而不是标签，因为我们将手动注释以创建我们的自定义数据集，尽管如果不同的项目需要，我们可以使用它们。</p></figure><p id="420f" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">在我们继续之前，我们需要将所有图像复制到同一个文件夹中，以便从头开始我们的标记练习。您可以选择手动完成，但也可以使用递归 glob 函数以编程方式快速完成:</p><pre class="lm ln lo lp gt oe of og oh aw oi bi"><span id="d304" class="ns mw ja of b gy oj ok l ol om">import os<br/>from glob import glob</span><span id="760a" class="ns mw ja of b gy or ok l ol om">os.system("mkdir Images")<br/>images = glob(r'OID/**/*.jpg', recursive=True)<br/>for img in images:<br/>    os.system(f"cp {img} Images/")</span></pre><h2 id="b153" class="ns mw ja bd mx nt nu dn nb nv nw dp nf ky nx ny nh lc nz oa nj lg ob oc nl od bi translated">2.用超级标签标记图像</h2><p id="68d7" class="pw-post-body-paragraph kp kq ja kr b ks nn kb ku kv no ke kx ky np la lb lc nq le lf lg nr li lj lk im bi translated">我们将使用名为 Hyperlabel 的工具来标记我们的图像。过去，我使用过很多工具来创建注释，比如 labelimg、labelbox 等等。但从未遇到过如此简单且过于开源的工具。唯一的缺点是你不能在 Linux 上使用这个工具，只能在 Mac 和 Windows 上使用，但是我想这对我们大多数人来说都没问题。</p><div class="lm ln lo lp gt ab cb"><figure class="os iv ot ou ov ow ox paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/b760da8b893b9c341032efad59c408c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*nFcVvPsV4mur6fZhwIMenA.png"/></div></figure><figure class="os iv oy ou ov ow ox paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/3a0b72af56617a70d79943f3912eb6da.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*4Vh-YBANkzxUlZyOsAXXyQ.png"/></div></figure></div><div class="ab cb"><figure class="os iv oz ou ov ow ox paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/57c3cd7f403d39eeb2844e6b69d71af4.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*8z-8KrGgijnKV3m8cZuIyA.png"/></div></figure><figure class="os iv pa ou ov ow ox paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/92c619fd07d756804c7ed7c5918710ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*ccqZMcRZWQRotF8xx-MkBw.png"/></div><p class="lu lv gj gh gi lw lx bd b be z dk pb di pc pd translated">1.创建项目，2，设置标签，3。添加本地图像数据源，4。给…作注解</p></figure></div><p id="aa51" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">这个工具最好的部分是它提供的各种输出格式。因为我们想获得 Yolo 的数据，所以我们将关闭 Yolo 格式，并在注释完成后导出它。但是如果您想获得 JSON 格式(COCO)或 XML 格式(Pascal VOC)的注释，您也可以选择使用这个工具。</p><figure class="lm ln lo lp gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi pe"><img src="../Images/2e9ef00ee0eab681019ecefdb7de23c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WjJpycN668wVE43xgGJ_oA.png"/></div></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">5.出口</p></figure><p id="0eb8" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">以 Yolo 格式导出实际上是为我们的每个图像创建一个. txt 文件，其中包含图像的 class_id、x_center、y_center、宽度和高度。它还创建了一个名为<code class="fe on oo op of b">obj.names</code>的文件，这有助于将 class_id 映射到类名。例如:</p><div class="lm ln lo lp gt ab cb"><figure class="os iv pf ou ov ow ox paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/e2b97f820d19cbcff3ac2a9a21c36239.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*N8I5EgmmesbWNHptv4-s6Q.png"/></div></figure><figure class="os iv pg ou ov ow ox paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/0458f89106b8295a305f06adf6ad32ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*3dFKfn8vmtuTg8uSDNgNEw.png"/></div></figure><figure class="os iv ph ou ov ow ox paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/7c52180bed1767680e7ab2388a070ba4.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*2IeGSsDIpaNjpwb-M4rEvg.png"/></div><p class="lu lv gj gh gi lw lx bd b be z dk pi di pj pd translated">图像、其注释和 obj.names 文件</p></figure></div><p id="ed0b" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">请注意，在注释文件中，坐标从 0 缩放到 1。另外，请注意，根据从 0 开始的<code class="fe on oo op of b">obj.names </code>文件，板球的 class_id 为 0，足球的 class _ id 为 1。我们用它创建了一些其他的文件，但是我们不会在这个例子中使用它们。</p><p id="badc" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">一旦我们完成了这些，我们就基本上设置好了我们的自定义数据集，我们只需要重新排列其中的一些文件，以便在以后训练模型时进行后续的训练和验证分割。数据集目前是一个文件夹，如下所示，包含图像和注释:</p><pre class="lm ln lo lp gt oe of og oh aw oi bi"><span id="221f" class="ns mw ja of b gy oj ok l ol om">dataset<br/>    - 0027773a6d54b960.jpg  <br/>    - 0027773a6d54b960.txt<br/>    - 2bded1f9cb587843.jpg<br/>    - 2bded1f9cb587843.txt<br/>    --<br/>    --</span></pre></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="da96" class="mv mw ja bd mx my mz na nb nc nd ne nf kg ng kh nh kj ni kk nj km nk kn nl nm bi translated">设置项目</h1><p id="3ffe" class="pw-post-body-paragraph kp kq ja kr b ks nn kb ku kv no ke kx ky np la lb lc nq le lf lg nr li lj lk im bi translated">为了训练我们的自定义对象检测器，我们将使用 Ultralytics 的 Yolov5。我们从克隆存储库和安装依赖项开始:</p><pre class="lm ln lo lp gt oe of og oh aw oi bi"><span id="5939" class="ns mw ja of b gy oj ok l ol om">git clone <a class="ae ly" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank">https://github.com/ultralytics/yolov5</a> # clone repo<br/>cd yolov5<br/>pip install -U -r requirements.txt</span></pre><p id="fd7c" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">然后，我们开始创建自己的名为 training 的文件夹，在其中保存我们的自定义数据集。</p><pre class="lm ln lo lp gt oe of og oh aw oi bi"><span id="e259" class="ns mw ja of b gy oj ok l ol om">!mkdir training</span></pre><p id="8a42" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">我们首先将自定义数据集文件夹复制到这个文件夹中，并使用简单的<code class="fe on oo op of b">train_val_folder_split.ipynb</code>笔记本创建训练验证文件夹。下面的代码只是创建一些训练和验证文件夹，并用图像填充它们。</p><pre class="lm ln lo lp gt oe of og oh aw oi bi"><span id="2b0f" class="ns mw ja of b gy oj ok l ol om">import glob, os<br/>import random</span><span id="ba4e" class="ns mw ja of b gy or ok l ol om"># put your own path here<br/>dataset_path = 'dataset'</span><span id="df39" class="ns mw ja of b gy or ok l ol om"># Percentage of images to be used for the validation set<br/>percentage_test = 20</span><span id="7f03" class="ns mw ja of b gy or ok l ol om">!mkdir data<br/>!mkdir data/images<br/>!mkdir data/labels<br/>!mkdir data/images/train<br/>!mkdir data/images/valid<br/>!mkdir data/labels/train<br/>!mkdir data/labels/valid</span><span id="38a6" class="ns mw ja of b gy or ok l ol om"># Populate the folders<br/>p = percentage_test/100<br/>for pathAndFilename in glob.iglob(os.path.join(dataset_path, "*.jpg")):  <br/>    title, ext = os.path.splitext(os.path.basename(pathAndFilename))<br/>    if random.random() &lt;=p :<br/>        os.system(f"cp {dataset_path}/{title}.jpg data/images/valid")<br/>        os.system(f"cp {dataset_path}/{title}.txt data/labels/valid")<br/>    else:<br/>        os.system(f"cp {dataset_path}/{title}.jpg data/images/train")<br/>        os.system(f"cp {dataset_path}/{title}.txt data/labels/train")</span></pre><p id="0d67" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">运行之后，您的<code class="fe on oo op of b">data</code>文件夹结构应该如下所示。它应该有两个目录<code class="fe on oo op of b">images</code>和<code class="fe on oo op of b">labels</code>。</p><figure class="lm ln lo lp gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi pk"><img src="../Images/b045f6c5d2e985f17154beae89f333a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L-Qb0YFqyVDy6qdvd-W_Zg.png"/></div></div></figure><p id="895f" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">我们现在必须向<code class="fe on oo op of b">training</code>文件夹添加两个配置文件:</p><p id="4ac8" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated"><strong class="kr jb"> 1。Dataset.yaml: </strong>我们创建一个文件“<code class="fe on oo op of b">dataset.yaml</code>”，它包含训练和验证图像的路径以及类。</p><pre class="lm ln lo lp gt oe of og oh aw oi bi"><span id="487a" class="ns mw ja of b gy oj ok l ol om"># train and val datasets (image directory or *.txt file with image paths)<br/>train: training/data/images/train/<br/>val: training/data/images/valid/</span><span id="2ba6" class="ns mw ja of b gy or ok l ol om"># number of classes<br/>nc: 2</span><span id="70a7" class="ns mw ja of b gy or ok l ol om"># class names<br/>names: ['Cricketball', 'Football']</span></pre><p id="924e" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated"><strong class="kr jb"> 2。在创建我们的网络时，我们可以使用从小到大的多个模型。例如，<code class="fe on oo op of b">yolov5/models </code>目录下的<code class="fe on oo op of b">yolov5s.yaml</code>文件是 7M 参数的小型 Yolo 模型，<code class="fe on oo op of b">yolov5x.yaml</code>是 96M 参数的最大 Yolo 模型。对于这个项目，我将使用有 50M 参数的<code class="fe on oo op of b">yolov5l.yaml</code>。我们首先将文件从<code class="fe on oo op of b">yolov5/models/yolov5l.yaml</code>复制到 training 文件夹，并根据我们的项目需求将<code class="fe on oo op of b">nc</code>的类数改为 2。</strong></p><pre class="lm ln lo lp gt oe of og oh aw oi bi"><span id="87c3" class="ns mw ja of b gy oj ok l ol om"># parameters<br/>nc: 2  # change number of classes<br/>depth_multiple: 1.0  # model depth multiple<br/>width_multiple: 1.0  # layer channel multiple</span></pre></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="0742" class="mv mw ja bd mx my mz na nb nc nd ne nf kg ng kh nh kj ni kk nj km nk kn nl nm bi translated">火车</h1><p id="d3cb" class="pw-post-body-paragraph kp kq ja kr b ks nn kb ku kv no ke kx ky np la lb lc nq le lf lg nr li lj lk im bi translated">此时，我们的培训文件夹如下所示:</p><figure class="lm ln lo lp gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi pl"><img src="../Images/8655ee98cc9fd5cbe80c0b6c36cf6575.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PyTZLyjU-S8IyZjmNXsUjg.png"/></div></div></figure><p id="5abf" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">一旦我们完成了上述步骤，我们就可以开始训练我们的模型了。这就像运行下面的命令一样简单，在这里我们提供配置文件和各种其他参数的位置。您可以在<code class="fe on oo op of b">train.py</code>文件中查看不同的其他选项，但这些选项是我发现值得注意的。</p><pre class="lm ln lo lp gt oe of og oh aw oi bi"><span id="293b" class="ns mw ja of b gy oj ok l ol om"># Train yolov5l on custom dataset for 300 epochs<br/>$ python train.py --img 640 --batch 16 --epochs 300--data training/dataset.yaml --cfg training/yolov5l.yaml --weights ''</span></pre><p id="b45d" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">在这种情况下，在单个 GPU 上运行 PyTorch 版时，有时可能会出现错误:</p><pre class="lm ln lo lp gt oe of og oh aw oi bi"><span id="23d9" class="ns mw ja of b gy oj ok l ol om"># Train yolov5l on custom dataset for 300 epochs<br/>$ python train.py --img 640 --batch 16 --epochs 300--data training/dataset.yaml --cfg training/yolov5l.yaml --weights '' --device 0</span></pre><p id="4a81" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">一旦开始训练，您可以通过检查自动创建的文件<code class="fe on oo op of b">train_batch0.jpg</code>来检查训练是否已经设置，该文件包含第一批的训练标签和<code class="fe on oo op of b">test_batch0_gt.jpg</code>，该文件包含测试图像的基本事实。他们就是这样找我的。</p><div class="lm ln lo lp gt ab cb"><figure class="os iv pm ou ov ow ox paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/121140b6202ba7089f7857158de90e0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*oOIx-nhCNLlr8HtowEk0UQ.png"/></div></figure><figure class="os iv pn ou ov ow ox paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/57f4aaae77e8037d099c579e2c90d21a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/1*W8Oij3DiKp64EyoIGWHM2A.png"/></div><p class="lu lv gj gh gi lw lx bd b be z dk po di pp pd translated">左:train_batch0.jpg，右:test_batch0_gt.jpg</p></figure></div></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="8c6b" class="mv mw ja bd mx my mz na nb nc nd ne nf kg ng kh nh kj ni kk nj km nk kn nl nm bi translated">结果</h1><p id="cb81" class="pw-post-body-paragraph kp kq ja kr b ks nn kb ku kv no ke kx ky np la lb lc nq le lf lg nr li lj lk im bi translated">要使用 tensorboard 在浏览器中查看<code class="fe on oo op of b">localhost:6006</code>的训练结果，请在另一个终端选项卡中运行此命令</p><pre class="lm ln lo lp gt oe of og oh aw oi bi"><span id="7a2d" class="ns mw ja of b gy oj ok l ol om">tensorboard --logdir=runs</span></pre><p id="67f9" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">以下是各种验证指标。在训练结束时，这些指标也会保存在文件<code class="fe on oo op of b">results.png</code>中。</p><figure class="lm ln lo lp gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi pq"><img src="../Images/f767f18d41004a8daf5b671d267d4d16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nGX0tjWt8EBi4yVVUQWN8g.png"/></div></div></figure></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="c73e" class="mv mw ja bd mx my mz na nb nc nd ne nf kg ng kh nh kj ni kk nj km nk kn nl nm bi translated">预测</h1><p id="ecf7" class="pw-post-body-paragraph kp kq ja kr b ks nn kb ku kv no ke kx ky np la lb lc nq le lf lg nr li lj lk im bi translated">Ultralytics Yolov5 提供了许多不同的方法来检查新数据的结果。</p><p id="c8a4" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">要检测一些图像，您只需将它们放入名为<code class="fe on oo op of b">inference/images</code>的文件夹中，并根据验证 AP 使用最佳权重运行推理:</p><pre class="lm ln lo lp gt oe of og oh aw oi bi"><span id="8424" class="ns mw ja of b gy oj ok l ol om">python detect.py --weights weights/best.pt</span></pre><figure class="lm ln lo lp gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi pr"><img src="../Images/1f5ee2249221fead1e48194e164f6482.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QHG3YaCx0Z6N9I4sREuhjg.png"/></div></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">结果</p></figure><p id="3d0f" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">您还可以使用 detect.py 文件在视频中进行检测:</p><pre class="lm ln lo lp gt oe of og oh aw oi bi"><span id="08a9" class="ns mw ja of b gy oj ok l ol om">python detect.py --weights weights/best.pt --source inference/videos/messi.mp4 --view-img --output inference/output</span></pre><p id="849f" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">在这里，我指定我想使用<code class="fe on oo op of b">— view-img</code>标志来查看输出，我们将输出存储在位置 inference/output。这将在这个位置创建一个<code class="fe on oo op of b">.mp4</code>文件。令人印象深刻的是，网络可以看到球，在这里做出推断的速度，以及从未观察到的数据的惊人准确性。</p><figure class="lm ln lo lp gt iv gh gi paragraph-image"><div class="gh gi ir"><img src="../Images/3076b5be035e6274c9a548a787dafb95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*QvCHyXdY36jpwoz-2_n9yQ.gif"/></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">还有，这是梅西…..</p></figure><p id="5cb1" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">您也可以通过将<code class="fe on oo op of b">--source</code>指定为 0 来将网络摄像头用作信号源。您可以查看<code class="fe on oo op of b">detect.py</code>文件中的各种其他选项。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="790f" class="mv mw ja bd mx my mz na nb nc nd ne nf kg ng kh nh kj ni kk nj km nk kn nl nm bi translated">结论</h1><p id="0ec6" class="pw-post-body-paragraph kp kq ja kr b ks nn kb ku kv no ke kx ky np la lb lc nq le lf lg nr li lj lk im bi translated"><strong class="kr jb"> <em class="lz">在这篇文章中，我谈到了如何使用自定义数据集创建一个 Yolov5 对象检测模型。我喜欢 Ultralytics 让创建对象检测模型变得如此简单的方式。</em></strong></p><p id="263d" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">此外，他们提供的查看模型结果的各种方式使它成为我很长时间以来看到的一个完整的包。</p><p id="8e49" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">如果你想自己尝试定制数据集，你可以在<a class="ae ly" href="https://www.kaggle.com/mlwhiz/detection-footballvscricketball" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>下载带注释的数据，在<a class="ae ly" href="https://github.com/MLWhiz/data_science_blogs/tree/master/yolov5CustomData" rel="noopener ugc nofollow" target="_blank"> Github </a>下载代码。</p><p id="8846" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">如果想详细了解各种<strong class="kr jb"> <em class="lz">物体检测技术，运动估计，视频中的物体跟踪等</em> </strong>。，在此推荐这门关于计算机视觉<a class="ae ly" href="https://coursera.pxf.io/7mKnnY" rel="noopener ugc nofollow" target="_blank">深度学习</a>的优秀课程。如果你想知道更多关于物体检测领域这些年是如何发展的，你也可以看看我上一篇关于物体检测的<a class="ae ly" rel="noopener" target="_blank" href="/a-hitchhikers-guide-to-object-detection-and-instance-segmentation-ac0146fe8e11">文章。</a></p><p id="dd38" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">谢谢你的阅读。将来我也会写更多初学者友好的帖子。在<a class="ae ly" href="https://medium.com/@rahul_agarwal" rel="noopener"> <strong class="kr jb">媒体</strong> </a>关注我或者订阅我的<a class="ae ly" href="http://eepurl.com/dbQnuX" rel="noopener ugc nofollow" target="_blank"> <strong class="kr jb">博客</strong> </a>了解他们。一如既往，我欢迎反馈和建设性的批评，可以通过 Twitter <a class="ae ly" href="https://twitter.com/MLWhiz" rel="noopener ugc nofollow" target="_blank"> @mlwhiz </a>联系到我</p><p id="dd92" class="pw-post-body-paragraph kp kq ja kr b ks kt kb ku kv kw ke kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">这个故事在这里首次发表<a class="ae ly" href="https://lionbridge.ai/articles/create-an-end-to-end-object-detection-pipeline-using-yolov5/" rel="noopener ugc nofollow" target="_blank">。</a></p></div></div>    
</body>
</html>