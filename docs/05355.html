<html>
<head>
<title>Why training set should always be smaller than test set</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么训练集应该总是小于测试集</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-training-set-should-always-be-smaller-than-test-set-61f087ed203c?source=collection_archive---------10-----------------------#2020-05-06">https://towardsdatascience.com/why-training-set-should-always-be-smaller-than-test-set-61f087ed203c?source=collection_archive---------10-----------------------#2020-05-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="10e1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在小样本上测试机器学习模型不是一个好主意</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/fb855009c7258d8608b682a6b93e80f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UV6lmYquXIyAYfszxXuS4A.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由来自<a class="ae ky" href="https://www.pexels.com/it-it/foto/codice-computer-database-dati-546819/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Pexels </a>的<a class="ae ky" href="https://www.pexels.com/it-it/@luis-gomes-166706?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> luis gomes </a>拍摄</p></figure><p id="3875" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在机器学习领域，数据科学家经常被告知在大型训练数据集上训练监督模型，并在少量数据上测试它。训练数据集总是被选择为大于测试数据集的原因是有人说用于训练的数据越大，模型学习得越好。</p><p id="0af2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我一直认为这种观点实际上并不完全正确，在本文中，我将向您展示为什么您应该保持尽可能小的训练集，而不是保留大部分数据用于测试目的。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="d823" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">衡量模型性能的问题</h1><p id="dee7" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">监督模型的真正任务不是在尽可能大的数据集上学习，而是以一种在未知数据上模型性能令人满意的方式学习。这就是为什么我们在看不见的数据集上执行模型交叉验证。</p><p id="3d8b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据科学家通常会提供一些在此类测试数据集上计算的模型性能指标，如 AuROC、准确度、精度、均方根误差等。这个想法是，如果我们的模型在看不见的数据上表现得很好，那么它在生产环境中也可能表现得很好。</p><p id="8bbc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是我们对模型性能的测量有多精确呢？如果我说我的模型在 100 条记录的测试数据集上有 86%的 AuROC，而另一个人说另一个模型在 10.000 条记录的测试数据集上仍有 86%的 AuROC，这两个值有可比性吗？如果你是一家大公司的经理，你被要求根据模型预测投资一些钱，你会选择哪一个？</p><p id="79ed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我给你剧透一下。测试集越大，对其计算的任何性能指标的精确度就越高。</p><h1 id="2bdf" class="mc md it bd me mf mz mh mi mj na ml mm jz nb ka mo kc nc kd mq kf nd kg ms mt bi translated">模型性能的精确度</h1><p id="95a4" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">我是一个物理学家，所以我总是被告知每一个测量都必须有一个误差估计。我可以告诉你我身高 1.93 米，但是我不会给你任何关于这个估计的精确度的信息。是 1 厘米，还是 12 厘米？你说不准。正确的信息可能是:我身高 1.93 +/- 0.01 米，这是 1.93 米，误差估计为 1 厘米。如果有人试图测量我的身高，他可能会得到 1.93 +/- 0.12 米，这是 1.93 米，误差估计为 12 厘米。哪种测量方法更准确？当然是前者。其误差比后者低一个数量级。</p><p id="64a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">同样的方法可以应用于机器学习模型。每次计算模型性能(例如，AuROC、accuracy、RMSE)时，您都在执行一个测量，这个测量之后必须有一个误差估计。</p><p id="c0c5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">那么，如何计算这种测量的误差估计呢？有许多技术，但我更喜欢使用 bootstrap，这是一种重采样技术，允许您计算估计的标准误差和置信区间。bootstrap 样本中可观察值的标准差是我们可以在报告中使用的标准误差。很容易证明，误差估计随样本容量的平方根而减小。</p><p id="f782" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是为什么您必须使用大型测试集的原因。它提供了对未知数据的模型性能的更好估计。</p><h1 id="1b9a" class="mc md it bd me mf mz mh mi mj na ml mm jz nb ka mo kc nc kd mq kf nd kg ms mt bi translated">例子</h1><p id="be57" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">在以下 Python 示例中，我将模拟包含 4 个独立正态分布要素的 100 万条记录数据集，然后根据以下线性模型人工创建一个目标变量:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/fffa0ce4abd48daf8080fab6e1bfc045.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/0*CzTzdR0iwpS8anWs"/></div></figure><p id="9e27" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">线性模型预测和样本<em class="nf"> y </em>值之间的误差是正态分布的。</p><p id="6a10" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我将拟合线性模型，计算 RMSE 及其标准误差，并向您展示测试集越大，标准误差越小，因此 RMSE 值的精度越高。</p><p id="cb8e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在我的 GitHub 资源库找到完整的代码:<a class="ae ky" href="https://github.com/gianlucamalato/machinelearning/blob/master/Small_training_large_test.ipynb" rel="noopener ugc nofollow" target="_blank">https://GitHub . com/gianlucamalato/machine learning/blob/master/Small _ training _ large _ test . ipynb</a></p><p id="4e32" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，让我们导入一些库。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="c7dc" class="nl md it nh b gy nm nn l no np">import numpy as np<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.linear_model import LinearRegression<br/>from sklearn.metrics import mean_squared_error</span></pre><p id="5d9f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们用 4 个正态和独立分布的特征来模拟 100 万条记录。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="e99d" class="nl md it nh b gy nm nn l no np">np.random.seed(0)<br/>X = np.random.normal(size=4000000).reshape(1000000,4)</span></pre><p id="22b4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们可以应用正态分布噪声来创建输出变量。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="510e" class="nl md it nh b gy nm nn l no np">y = []<br/>for record in X:<br/>   y.append(np.sum(record) + np.random.normal())<br/>   y = np.array(y)</span></pre><h2 id="23e2" class="nl md it bd me nq nr dn mi ns nt dp mm li nu nv mo lm nw nx mq lq ny nz ms oa bi translated">小型测试集</h2><p id="0724" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">现在，让我们将我们的 X，y 数据集分成训练集和测试集，测试集大小是总大小的 20%。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="efb7" class="nl md it nh b gy nm nn l no np">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span></pre><p id="a3bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们可以拟合线性回归模型。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="de58" class="nl md it nh b gy nm nn l no np">model = LinearRegression()<br/>model.fit(X_train,y_train)</span></pre><p id="86f9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在计算模型性能之前，让我们先定义一个函数，用 100 个样本的自举来计算 RMSE 及其误差估计。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="a816" class="nl md it nh b gy nm nn l no np">def estimate_error(X_test,y_test):<br/>  n_iter = 100<br/>  np.random.seed(0)<br/>  errors = []</span><span id="a00e" class="nl md it nh b gy ob nn l no np">  indices = list(range(X_test.shape[0]))<br/>  for i in range(n_iter):<br/>    new_indices = np.random.choice(indices,<br/>        len(indices),replace=True)</span><span id="98be" class="nl md it nh b gy ob nn l no np">    new_X_test = X_test[new_indices]<br/>    new_y_test = y_test[new_indices]</span><span id="3ebf" class="nl md it nh b gy ob nn l no np">    new_y_pred = model.predict(new_X_test)</span><span id="9f6f" class="nl md it nh b gy ob nn l no np">    new_error = np.sqrt(mean_squared_error(new_y_test,new_y_pred))</span><span id="f9dc" class="nl md it nh b gy ob nn l no np">    errors.append(new_error)</span><span id="77b3" class="nl md it nh b gy ob nn l no np">  return np.mean(errors),np.std(errors)</span></pre><p id="8e6c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些是结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/229e2415020114ce57369605b76e4f99.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/1*ii813d3PyWXzXsDJpX1idg.png"/></div></figure><p id="3043" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以我们有一个等于 1.0028 +/- 0.0015 的 RMSE。</p><h2 id="7454" class="nl md it bd me nq nr dn mi ns nt dp mm li nu nv mo lm nw nx mq lq ny nz ms oa bi translated">大型测试集</h2><p id="04a6" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">如果我们使用一个覆盖总人口规模 80%的测试集会发生什么？</p><p id="f446" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随机分割和模型训练变成:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="7c7d" class="nl md it nh b gy nm nn l no np">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=42)</span><span id="e41a" class="nl md it nh b gy ob nn l no np">model = LinearRegression()<br/>model.fit(X_train,y_train)</span></pre><p id="19f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">新 RMSE 的估计是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/f7fe3cce297127c82a5bc076d328a7a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*FFv-8PJVB90W7HB2v8l7yQ.png"/></div></figure><p id="c672" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以我们有 1.00072 +/- 0.00075。我们的误差已经减少了一个数量级，所以最后一个测量更准确。</p><h1 id="8529" class="mc md it bd me mf mz mh mi mj na ml mm jz nb ka mo kc nc kd mq kf nd kg ms mt bi translated">到底发生了什么？</h1><p id="eece" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">这些数字里没有魔法。简单地说，这是大数定律和自举技术的一种效果。对于更大的数据集，样本中的任何可观测估计值都变得非常接近其在样本总体中的值。</p><h1 id="2245" class="mc md it bd me mf mz mh mi mj na ml mm jz nb ka mo kc nc kd mq kf nd kg ms mt bi translated">结论</h1><p id="0141" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">更大的测试数据集确保更准确地计算模型性能。对较小数据集的训练可以通过分层抽样等抽样技术来完成。它将加速你的训练(因为你使用更少的数据)，并使你的结果更可靠。</p><h1 id="3fce" class="mc md it bd me mf mz mh mi mj na ml mm jz nb ka mo kc nc kd mq kf nd kg ms mt bi translated">参考</h1><p id="5511" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">[1]吉安卢卡·马拉托。<em class="nf">自举。任何数据科学家的瑞士军刀</em>。数据科学记者。<a class="ae ky" href="https://medium.com/data-science-reporter/the-bootstrap-the-swiss-army-knife-of-any-data-scientist-acd6e592be13" rel="noopener">https://medium . com/data-science-reporter/the-bootstrap-the-Swiss-army-knife-of-any-data-scientist-ACD 6 e 592 be 13</a></p><p id="b43c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[2]吉安卢卡·马拉托。<em class="nf">分层抽样以及如何在 R 中进行</em>。走向数据科学。<a class="ae ky" rel="noopener" target="_blank" href="/stratified-sampling-and-how-to-perform-it-in-r-8b753efde1ef">https://towards data science . com/layered-sampling-and-how-to-perform-it-in-r-8b 753 efde 1 ef</a></p><p id="d61a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[3]吉安卢卡·马拉托。<em class="nf">机器学习中如何从庞大的数据集中正确选择样本</em>。数据科学记者。<a class="ae ky" href="https://medium.com/data-science-reporter/how-to-correctly-select-a-sample-from-a-huge-dataset-in-machine-learning-24327650372c" rel="noopener">https://medium . com/data-science-reporter/how-to-corrective-select-a-sample-from-a-high-dataset-in-machine-learning-24327650372 c</a></p></div></div>    
</body>
</html>