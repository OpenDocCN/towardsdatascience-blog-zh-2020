<html>
<head>
<title>NetVLAD: CNN Architecture for Weakly Supervised Place Recognition</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NetVLAD:弱监督地点识别的CNN体系结构</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/netvlad-cnn-architecture-for-weakly-supervised-place-recognition-ce64b08bebaf?source=collection_archive---------27-----------------------#2020-02-14">https://towardsdatascience.com/netvlad-cnn-architecture-for-weakly-supervised-place-recognition-ce64b08bebaf?source=collection_archive---------27-----------------------#2020-02-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="8eda" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">本文是一篇名为NetVLAD:弱监督地点识别的CNN架构的论文的论文摘要。本文在图像检索任务中很受欢迎，并为地点识别任务提供了关键解决方案。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi kl"><img src="../Images/1de58a9265013dff965027fd48cdb599.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/format:webp/1*JyECZDHpmNJ0l8iL3yP_rg.png"/></div><p class="kt ku gj gh gi kv kw bd b be z dk translated">图像检索结果</p></figure><p id="fd87" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">卷积神经网络</strong> (CNN)一直是计算机视觉领域的心脏。随着计算资源的巨大发展，人们开始关注如何在降低计算复杂度的前提下提高模型的性能。因此，在<strong class="jp ir">图像检索</strong>中，CNN架构用于特征提取。然而，使用CNN架构仍然遭受低性能。</p><p id="42e6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">图像检索</strong>是一个专注于<strong class="jp ir">在数据库中找到最相似图像</strong>的任务。相似这个关键词看起来很主观，因为相似性没有严格的定义。此外，我们不能使用朴素图像数组来计算相似性。为了解决它，我们定义了一个特征提取函数f和距离函数d。这个方案被称为<strong class="jp ir">度量学习</strong>。关于<strong class="jp ir">度量学习</strong>的更多细节解释如下。</p><p id="a4c9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">视觉地点识别问题</strong>重点在于利用数据库中的信息正确定位查询图像。一个候选的解决方案是使用<strong class="jp ir">图像检索。</strong>对于给定的查询，将其位置近似为最相似图像的位置。这种近似方法被称为<strong class="jp ir">实例检索任务。</strong></p><p id="c877" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本文中，我们将介绍<strong class="jp ir"> NetVLAD:弱监督地点识别的CNN架构</strong>。这篇论文发表于2016年，为<strong class="jp ir">视觉地点识别任务</strong>介绍了一个很棒的CNN结构层。</p><h1 id="ac46" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">在NetVLAD之前</h1><p id="f911" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">有很多尝试来提取图像中的重要局部特征。不幸的是，最初的CNN结构不适合视觉位置识别任务。此外，许多“现成”技术限制了端到端的构建方式。本文的主要贡献如下</p><ol class=""><li id="2760" class="ma mb iq jp b jq jr ju jv jy mc kc md kg me kk mf mg mh mi bi translated">创建一个CNN架构，它可以以端到端的方式进行训练，用于视觉位置识别。</li><li id="aafd" class="ma mb iq jp b jq mj ju mk jy ml kc mm kg mn kk mf mg mh mi bi translated">收集足以训练CNN架构的数据。</li><li id="c039" class="ma mb iq jp b jq mj ju mk jy ml kc mm kg mn kk mf mg mh mi bi translated">使用CNN架构进行特征提取并评估其性能。</li></ol><h1 id="8a30" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">度量学习</h1><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mo"><img src="../Images/340547b07980939f1cb1fe35582ee1ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tsn3hdzkPDG2yzIrzsQxQQ.png"/></div></div><p class="kt ku gj gh gi kv kw bd b be z dk translated">演示材料中的幻灯片</p></figure><p id="7556" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">度量学习</strong>的主要思想是学习距离函数和特征提取函数。为了方便起见，我们通常使用线性函数，并学习它们的参数。因为图像只是简单的整数数组，所以朴素图像很难得到它们之间的距离。因此，我们使用特征提取函数来提取局部描述符。它使用具有NetVLAD的CNN作为特征提取函数，并使用欧几里德距离作为距离函数。它选择欧几里德距离，因为它在实验中工作得很好。</p><h1 id="56ec" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">VLAD(局部聚集描述符的向量)</h1><p id="443c" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">为了更好地了解什么是VLAD，我建议你参考以下链接。</p><div class="mt mu gp gr mv mw"><a href="https://ameyajoshi005.wordpress.com/2014/03/29/vlad-an-extension-of-bag-of-words/" rel="noopener  ugc nofollow" target="_blank"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd ir gy z fp nb fr fs nc fu fw ip bi translated">VLAD——词汇袋的延伸</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">最近，我参加了TagMe-一个由微软和印度研究所举办的图像分类竞赛…</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">ameyajoshi005.wordpress.com</p></div></div><div class="nf l"><div class="ng l nh ni nj nf nk kr mw"/></div></div></a></div><div class="mt mu gp gr mv mw"><a href="https://ieeexplore.ieee.org/document/6619051" rel="noopener  ugc nofollow" target="_blank"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd ir gy z fp nb fr fs nc fu fw ip bi translated">关于VLAD的一切——IEEE会议出版物</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">本文的目标是给定查询图像的大规模对象实例检索。这样的起点…</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">ieeexplore.ieee.org</p></div></div></div></a></div><p id="821b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> VLAD </strong>不过是一种特征量化技术。它类似于我们熟悉的概念，被命名为<strong class="jp ir">词汇袋</strong>和<strong class="jp ir">费希尔向量。</strong>当您考虑k均值聚类时，它可以帮助您理解。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/b93eb8a53fceb8a865168f9768aa0869.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/0*pBLkgCQp31Ewzc1i"/></div></figure><p id="b5dc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> VLAD </strong>是一个K×D矩阵，存储着聚类的信息。最初，K被给定为超参数，并在嵌入空间中随机初始化K个簇。(D是局部描述符的维度)每一列表示每个簇中残差的总和。我们可以关注输出0或1的函数a_k。只有当聚类k是最近的中心时，它才是1，否则是0。</p><p id="51e8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因为函数a_k不再可微，所以它不能是端到端的。因此，它使用一个<strong class="jp ir">软赋值</strong>来代替。下图显示了软赋值a_k的实际定义。当我们充分放大alpha值时，它近似于原始a_k函数。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/4a54252a006db4b8355ca9a271154933.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/1*hoWfy_5xZz1msTREqdFUyQ.png"/></div></figure><p id="bf3d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">此外，我们可以将该函数分解为</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi nn"><img src="../Images/95de19f220d9d19394fec9715b5724f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mOnhD3PidgJafaxyCVVg-g.png"/></div></div></figure><p id="3a29" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">看起来我们只需要学习c_k。然而，在下面的论文中，它表明{c} 、{w}和{b}的<strong class="jp ir">解耦依赖</strong>将<strong class="jp ir">提高性能</strong>。意思是学习{c}、{w}、{b}比只学习{c}获得更好的表现。进一步的细节将在下面的文章中介绍。</p><div class="mt mu gp gr mv mw"><a href="https://ieeexplore.ieee.org/document/6619051" rel="noopener  ugc nofollow" target="_blank"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd ir gy z fp nb fr fs nc fu fw ip bi translated">关于VLAD的一切——IEEE会议出版物</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">本文的目标是给定查询图像的大规模对象实例检索。这样的起点…</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">ieeexplore.ieee.org</p></div></div></div></a></div><p id="a59a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">整体网络结构如下。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi no"><img src="../Images/f06aa6c697fe40eb6f903dd1fceb4269.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fSSj2azc8_cqTfKbi9xGBw.png"/></div></div><p class="kt ku gj gh gi kv kw bd b be z dk translated">网络结构</p></figure><p id="2bcb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们在Conv5图层后添加了NetVLAD图层，并使用NetVLAD图层提取了VLAD格式的要素。它在最后执行帧内归一化和L2归一化。文件中解释了进一步的细节。</p><h1 id="760f" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">注释数据</h1><p id="ba7a" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">不幸的是，在2016年，没有一个数据集具有地面真理。因此，他们使用<strong class="jp ir">弱监管</strong>作为解决方案。</p><blockquote class="np nq nr"><p id="b083" class="jn jo ns jp b jq jr js jt ju jv jw jx nt jz ka kb nu kd ke kf nv kh ki kj kk ij bi translated">弱监管是指由于缺乏人工标注的数据而带有嘈杂标签的监管。</p></blockquote><p id="4db8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它使用<strong class="jp ir">谷歌街景时光机，</strong>只提供它的图像和位置。然后对于每个查询图像，将其他数据库图像分类为<strong class="jp ir">潜在阳性</strong>和<strong class="jp ir">确定阴性</strong>。<strong class="jp ir">潜在阳性</strong>是距离查询图像10m以内的图像。<strong class="jp ir">明确否定</strong>是距离查询图像超过25m的图像。那么我们就可以直观的理解下面的等式了。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi nw"><img src="../Images/91871fb62ec38df6b57507282e319350.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_wojes5EX5jDrWabge6zCA.png"/></div></div></figure><p id="f661" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果最相似的图像具有小的距离，损失函数变大，并且确定的负图像与查询不相似。这个损失函数称为三重损失函数。要了解什么是三重损失函数，我推荐你这篇文章</p><div class="mt mu gp gr mv mw"><a rel="noopener follow" target="_blank" href="/lossless-triplet-loss-7e932f990b24"><div class="mx ab fo"><div class="my ab mz cl cj na"><h2 class="bd ir gy z fp nb fr fs nc fu fw ip bi translated">无损三重损耗</h2><div class="nd l"><h3 class="bd b gy z fp nb fr fs nc fu fw dk translated">一种更有效的暹罗神经网络损失函数</h3></div><div class="ne l"><p class="bd b dl z fp nb fr fs nc fu fw dk translated">towardsdatascience.com</p></div></div><div class="nf l"><div class="nx l nh ni nj nf nk kr mw"/></div></div></a></div><h1 id="3054" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">评估协议和实验细节</h1><p id="0063" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">本实验中使用的是匹兹堡(Pitts250k，Pitts30k)和Tokyo24/7，基于<strong class="jp ir">谷歌街景时光机。</strong>它使用评估协议的召回来计算正确识别的查询的百分比。当前N个检索到的数据库图像在25m以内时，它被认为是正确定位的。超参数K是64。</p><h1 id="c4bd" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">结果</h1><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi ny"><img src="../Images/405ca5dd517d436c3b45428b58bdf198.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*NBo8cORGzMipyBYl"/></div></div></figure><ol class=""><li id="286f" class="ma mb iq jp b jq jr ju jv jy mc kc md kg me kk mf mg mh mi bi translated">基于VGG16的VLAD令人信服地优于由“现成”技术组成的Root-SIFT + VLAD+白化。</li><li id="9780" class="ma mb iq jp b jq mj ju mk jy ml kc mm kg mn kk mf mg mh mi bi translated">NetVLAD可以为地点识别提供丰富而紧凑的图像表示。</li><li id="ee56" class="ma mb iq jp b jq mj ju mk jy ml kc mm kg mn kk mf mg mh mi bi translated">NetVLAD在视觉地点识别任务中的表现优于max-pooling。</li><li id="f297" class="ma mb iq jp b jq mj ju mk jy ml kc mm kg mn kk mf mg mh mi bi translated">无论选择哪种网络主干(AlexNet、VGG16、Places205)，它都优于其他最先进的技术。</li></ol><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/08bc6f5d7935204f066df923bf5a09b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/0*YcO4hQOsMPLIrFtF"/></div></figure><p id="52a7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上图显示了另一个实验的结果。该实验检查了当我们改变最低训练层时，我们获得更好的性能。然而，当我们学习所有层时，会导致过度拟合，从而导致性能下降。</p><h1 id="8a18" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated"><strong class="ak">结论</strong></h1><p id="e81f" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">NetVLAD提供了一个强大的池机制，具有可学习的参数，可以很容易地插入到任何其他CNN架构中。因为NetVLAD中的所有功能都是可微分的，所以当在网络中使用时，它可以提供端到端的方式。由于其方便性，它仍然是视觉位置识别任务中的一种受欢迎的方法。</p><p id="2ac8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">演示文稿网址:<a class="ae oa" href="https://docs.google.com/presentation/d/168ErmavKMUHGHdNAG9j-IVXhcmPgSudTLnOWu_4McxQ/edit?usp=sharing" rel="noopener ugc nofollow" target="_blank">https://docs . Google . com/presentation/d/168 ermavkmuhghdnag 9j-ivxhcpgsudtlnowu _ 4 mcxq/edit？usp =共享</a></p><p id="329a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">论文网址:<a class="ae oa" href="https://arxiv.org/pdf/1511.07247.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1511.07247.pdf</a></p><p id="28b5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">联系我:jeongyw12382@postech.ac.kr </strong></p></div></div>    
</body>
</html>