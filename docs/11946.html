<html>
<head>
<title>Neural Networks Intuitions: 9. Distance Metric Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络直觉:9。远程度量学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/neural-networks-intuitions-9-distance-metric-learning-dae7c3a0ebdf?source=collection_archive---------22-----------------------#2020-08-18">https://towardsdatascience.com/neural-networks-intuitions-9-distance-metric-learning-dae7c3a0ebdf?source=collection_archive---------22-----------------------#2020-08-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9f75" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">远程度量学习</h2></div><p id="c501" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">欢迎回到我的神经网络直觉系列。在第九部分中，我们将深入了解<em class="lb"/><em class="lb">远程度量学习</em>，使用它背后的动机，提出的各种方法及其应用。</p><p id="7b3d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">注意:本文讨论的所有技术都属于<strong class="kh ir"> <em class="lb">深度度量学习(DML)，即使用神经网络的距离度量学习。</em>T9】</strong></p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h1 id="0fcc" class="lj lk iq bd ll lm ln lo lp lq lr ls lt jw lu jx lv jz lw ka lx kc ly kd lz ma bi translated"><strong class="ak">距离度量学习:</strong></h1><blockquote class="mb"><p id="dc28" class="mc md iq bd me mf mg mh mi mj mk la dk translated">距离度量学习意味着<em class="ml">在低维空间中学习距离，这与语义相似性的概念一致。(如[ </em> <a class="ae mm" href="https://arxiv.org/pdf/1703.07464.pdf" rel="noopener ugc nofollow" target="_blank">中所给，使用代理</a> <em class="ml">】的无争议距离度量学习)</em></p></blockquote><p id="2842" class="pw-post-body-paragraph kf kg iq kh b ki mn jr kk kl mo ju kn ko mp kq kr ks mq ku kv kw mr ky kz la ij bi translated">上面的说法是什么意思 w.r.t 图像域？</p><blockquote class="mb"><p id="9932" class="mc md iq bd me mf mg mh mi mj mk la dk translated">这意味着学习低维空间(非输入空间)中的距离，使得输入空间中的相似图像导致相似的表示(低距离)，而不相似的图像导致不同的表示(高距离)。</p></blockquote><p id="b985" class="pw-post-body-paragraph kf kg iq kh b ki mn jr kk kl mo ju kn ko mp kq kr ks mq ku kv kw mr ky kz la ij bi translated">好的，这听起来正是分类器所做的。不是吗？是的。</p><p id="bb08" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">那么这与监督图像分类有什么不同呢？为什么术语不同？</p><blockquote class="mb"><p id="eea0" class="mc md iq bd me mf mg mh mi mj mk la dk translated">度量学习解决了机器学习中的开集设置问题，即在测试时推广到新的示例。</p></blockquote><p id="de75" class="pw-post-body-paragraph kf kg iq kh b ki mn jr kk kl mo ju kn ko mp kq kr ks mq ku kv kw mr ky kz la ij bi translated">这对于特征提取器之后是完全连接的层分类网络是不可能的。</p><blockquote class="ms mt mu"><p id="00ae" class="kf kg lb kh b ki kj jr kk kl km ju kn mv kp kq kr mw kt ku kv mx kx ky kz la ij bi translated">为什么？</p></blockquote><p id="9d55" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是一个非常重要的问题。答案如下:</p><ol class=""><li id="9575" class="my mz iq kh b ki kj kl km ko na ks nb kw nc la nd ne nf ng bi translated">一个分类器学习<em class="lb"> </em> <strong class="kh ir"> <em class="lb">类特有特征而不一定是类属特征。</em> </strong></li><li id="ec24" class="my mz iq kh b ki nh kl ni ko nj ks nk kw nl la nd ne nf ng bi translated">具有<strong class="kh ir"> <em class="lb">标准交叉熵损失的分类器最大化类间距离</em> </strong>，使得 FC 层之前的特征是<strong class="kh ir">线性可分的。</strong></li></ol><figure class="nn no np nq gt nr gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/927c7455e65e37ac3626101c4ab19f72.png" data-original-src="https://miro.medium.com/v2/resize:fit:222/format:webp/1*MfmF4BiuzY75-XZmwcJcfw.png"/></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">由分类网络提取的特征(在 FC 层之前，有 CE 损失)是线性可分的</p></figure><p id="69e3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">并且不旨在最小化导致期望的<strong class="kh ir"> <em class="lb">区别特征的类内距离。</em> </strong></p><figure class="nn no np nq gt nr gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/afcaa846ced322130f325d924d0108e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:268/format:webp/1*kyB7PkEW3RuO2oKNLAYpWg.png"/></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">具有低类内距离和高类间距离的特征</p></figure><blockquote class="mb"><p id="2f19" class="mc md iq bd me mf nz oa ob oc od la dk translated">学习区别特征的这一方面是度量学习所实现的。</p></blockquote><figure class="of og oh oi oj nr gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/f954c82f7619ce2222c0be0e83cc6eef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*HHLt9NcaYFDE_X4VFvBIJg.png"/></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">使用 Softmax 分类生成的嵌入</p></figure><figure class="nn no np nq gt nr gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/875930d3a7bf093f6c25dfda7674616e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*w_5-sRfTCd-RRVAevl949A.png"/></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">使用双/三重网络生成的嵌入</p></figure></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="26c2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在研究度量学习中最广泛使用的方法之前，让我们看看它的应用，使问题陈述更加具体，以及为什么标准的分类方法可能不适合。</p><p id="75fa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">度量学习的应用如下:</p><ol class=""><li id="7cb8" class="my mz iq kh b ki kj kl km ko na ks nb kw nc la nd ne nf ng bi translated"><em class="lb">图像检索</em></li><li id="1eac" class="my mz iq kh b ki nh kl ni ko nj ks nk kw nl la nd ne nf ng bi translated"><em class="lb">近似重复检测</em></li><li id="5d1b" class="my mz iq kh b ki nh kl ni ko nj ks nk kw nl la nd ne nf ng bi translated"><em class="lb">少/零投学习</em></li></ol><p id="4ebd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">太好了！</p><p id="825e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在让我们看看度量学习中使用的突出方法:</p><p id="555c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb"> a .具有对比损耗(对)的连体网络</em></p><p id="4ffe" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb"> b .具有三重损失的三重网络(三重网络)</em></p><p id="b3da" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb"> c .分类基础方法。</em></p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h1 id="948a" class="lj lk iq bd ll lm ln lo lp lq lr ls lt jw lu jx lv jz lw ka lx kc ly kd lz ma bi translated">目标:</h1><p id="beb9" class="pw-post-body-paragraph kf kg iq kh b ki ol jr kk kl om ju kn ko on kq kr ks oo ku kv kw op ky kz la ij bi translated">以产生对于相似图像在欧几里得空间中接近(假设)而对于不相似图像远离的嵌入。</p><h1 id="8d57" class="lj lk iq bd ll lm oq lo lp lq or ls lt jw os jx lv jz ot ka lx kc ou kd lz ma bi translated">解决方案:</h1><h1 id="25d5" class="lj lk iq bd ll lm oq lo lp lq or ls lt jw os jx lv jz ot ka lx kc ou kd lz ma bi translated"><em class="ml"> a .有对比损耗的连体网络:</em></h1><p id="40f6" class="pw-post-body-paragraph kf kg iq kh b ki ol jr kk kl om ju kn ko on kq kr ks oo ku kv kw op ky kz la ij bi translated">论文<a class="ae mm" href="http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf" rel="noopener ugc nofollow" target="_blank">通过学习不变映射进行降维</a>通过将两幅图像作为输入并输出图像对是否相似来解决该问题。</p><p id="bc65" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">方法:</em></p><ol class=""><li id="d9c7" class="my mz iq kh b ki kj kl km ko na ks nb kw nc la nd ne nf ng bi translated">为数据集中的每个<em class="lb">图像</em>创建<em class="lb">相似</em>和<em class="lb">不相似</em>集合。</li><li id="a84e" class="my mz iq kh b ki nh kl ni ko nj ks nk kw nl la nd ne nf ng bi translated">将<em class="lb">两幅图像</em>(来自相似/不相似集合)传递到同一个神经网络，并提取低维<em class="lb">嵌入/表示。</em></li><li id="9b59" class="my mz iq kh b ki nh kl ni ko nj ks nk kw nl la nd ne nf ng bi translated">计算两个嵌入之间的欧几里德距离。</li><li id="3b35" class="my mz iq kh b ki nh kl ni ko nj ks nk kw nl la nd ne nf ng bi translated">将损失降至最低，以实现上述目标。</li><li id="ea28" class="my mz iq kh b ki nh kl ni ko nj ks nk kw nl la nd ne nf ng bi translated">对大量对重复 1–4(所有对可能都不可行)，直到模型收敛。</li></ol><p id="4002" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以现在我们需要一个损失函数(包含欧几里德距离),对于相似的对来说是 0，对于不相似的对来说是 1。</p><blockquote class="ms mt mu"><p id="71e4" class="kf kg lb kh b ki kj jr kk kl km ju kn mv kp kq kr mw kt ku kv mx kx ky kz la ij bi translated">这正是对比损失函数的作用！</p></blockquote><h2 id="636f" class="ov lk iq bd ll ow ox dn lp oy oz dp lt ko pa pb lv ks pc pd lx kw pe pf lz pg bi translated">对比损失:</h2><p id="0cc3" class="pw-post-body-paragraph kf kg iq kh b ki ol jr kk kl om ju kn ko on kq kr ks oo ku kv kw op ky kz la ij bi translated">设<strong class="kh ir"> <em class="lb"> (X1，X2) </em> </strong>为<em class="lb">输入图像对</em>，<strong class="kh ir"> <em class="lb"> Gw </em> </strong>为产生低维表示的<em class="lb">函数映射</em>(其中<strong class="kh ir"> w </strong>代表<em class="lb">参数</em>)，<strong class="kh ir">T45】Y</strong>为表示<em class="lb">相似或不相似的<em class="lb">地面真实标签</em></em></p><figure class="nn no np nq gt nr gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/cb5923fb232b6f4353163524f4e458be.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*HPMojqEsnuhA1GCxcEL2UA.png"/></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">对比损失函数(<a class="ae mm" href="http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf" rel="noopener ugc nofollow" target="_blank">通过学习不变映射</a>进行维度缩减)</p></figure><figure class="nn no np nq gt nr gh gi paragraph-image"><div role="button" tabindex="0" class="pj pk di pl bf pm"><div class="gh gi pi"><img src="../Images/98b95389aba2f2a20db40ab7e8294c54.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*OX0qNxXsq5R4njVfciiD8A.png"/></div></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">Dw =表示之间的欧几里德距离</p></figure><blockquote class="mb"><p id="eb29" class="mc md iq bd me mf nz oa ob oc od la dk translated">对比损失与传统的交叉熵损失有相似之处。损失函数中的第一项处理相似对(Y=0 ),使得 Dw 变为 0。第二项处理不同的线对(Y=1 ),使得 Dw 至少变为 m。</p></blockquote><p id="d483" class="pw-post-body-paragraph kf kg iq kh b ki mn jr kk kl mo ju kn ko mp kq kr ks mq ku kv kw mr ky kz la ij bi translated">这里 m 是余量，m 是 0。</p><blockquote class="ms mt mu"><p id="27b8" class="kf kg lb kh b ki kj jr kk kl km ju kn mv kp kq kr mw kt ku kv mx kx ky kz la ij bi translated">为什么我们需要在训练中展示不同的配对？为什么不简单地最小化一组相似对的损失函数呢？</p></blockquote><blockquote class="mb"><p id="2494" class="mc md iq bd me mf nz oa ob oc od la dk translated">作者回答说，“涉及不同对的对比术语是至关重要的。简单地在所有相似对的集合上最小化 DW (X1，X2)通常会导致崩溃的解决方案，因为 DW 和损耗 L 可以通过将 GW 设置为常数而变为零。</p></blockquote><blockquote class="ms mt mu"><p id="9da6" class="kf kg lb kh b ki mn jr kk kl mo ju kn mv mp kq kr mw mq ku kv mx mr ky kz la ij bi translated">既然我们已经了解了什么是对比损失函数，那么什么是连体网络呢？</p></blockquote><blockquote class="mb"><p id="374f" class="mc md iq bd me mf nz oa ob oc od la dk translated">这种架构被称为暹罗架构，其中相同的网络(即共享相同的参数集)被用于提取一对中的两个图像的低维表示。</p></blockquote></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h1 id="53c8" class="lj lk iq bd ll lm ln lo lp lq lr ls lt jw lu jx lv jz lw ka lx kc ly kd lz ma bi translated">b.三重网络，三重损耗:</h1><p id="fc71" class="pw-post-body-paragraph kf kg iq kh b ki ol jr kk kl om ju kn ko on kq kr ks oo ku kv kw op ky kz la ij bi translated">论文<a class="ae mm" href="https://arxiv.org/pdf/1503.03832.pdf" rel="noopener ugc nofollow" target="_blank"> FaceNet:人脸识别和聚类的统一嵌入</a>采用了与对比损失类似的方法——除了不是在每一步都处理成对图像，而是考虑三个一组的图像。</p><blockquote class="mb"><p id="b3e5" class="mc md iq bd me mf mg mh mi mj mk la dk translated">三元组由锚、正面(类似于锚)和负面(不同于锚)图像组成。</p></blockquote><p id="d7b1" class="pw-post-body-paragraph kf kg iq kh b ki mn jr kk kl mo ju kn ko mp kq kr ks mq ku kv kw mr ky kz la ij bi translated"><em class="lb">进场:</em></p><ol class=""><li id="a4d7" class="my mz iq kh b ki kj kl km ko na ks nb kw nc la nd ne nf ng bi translated">形成三元组(由具有共同锚图像的相似和不相似对组成)。</li><li id="54a9" class="my mz iq kh b ki nh kl ni ko nj ks nk kw nl la nd ne nf ng bi translated">通过相同的神经网络传递三元组，并提取低维嵌入。</li><li id="8094" class="my mz iq kh b ki nh kl ni ko nj ks nk kw nl la nd ne nf ng bi translated">计算欧几里得距离并最小化损失。</li><li id="5cbd" class="my mz iq kh b ki nh kl ni ko nj ks nk kw nl la nd ne nf ng bi translated">对大量的三个一组重复 1-3，直到收敛。</li></ol><h2 id="ac10" class="ov lk iq bd ll ow ox dn lp oy oz dp lt ko pa pb lv ks pc pd lx kw pe pf lz pg bi translated">三重损失:</h2><p id="b753" class="pw-post-body-paragraph kf kg iq kh b ki ol jr kk kl om ju kn ko on kq kr ks oo ku kv kw op ky kz la ij bi translated">设<strong class="kh ir"> <em class="lb"> f </em> </strong>为产生低维表示的函数映射，<strong class="kh ir"> <em class="lb"> xa </em> </strong>为锚图像，<strong class="kh ir"> <em class="lb"> xp </em> </strong>为正图像，<strong class="kh ir"> <em class="lb"> xn </em> </strong>为负图像，<strong class="kh ir"> <em class="lb"> α </em> </strong>为空白。</p><figure class="nn no np nq gt nr gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/cfd87869ba9aee3a329a7aad971837f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:748/format:webp/1*r2F2Dbuc8MUVP3tNFyT4zQ.png"/></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">三重损失函数</p></figure><blockquote class="mb"><p id="e225" class="mc md iq bd me mf nz oa ob oc od la dk translated">三重损失确保锚图像的表示比任何其他负图像更接近与其相似的所有图像。</p></blockquote><blockquote class="ms mt mu"><p id="2756" class="kf kg lb kh b ki mn jr kk kl mo ju kn mv mp kq kr mw mq ku kv mx mr ky kz la ij bi translated">什么是三联体网络？</p></blockquote><blockquote class="mb"><p id="baf7" class="mc md iq bd me mf nz oa ob oc od la dk translated">其中相同的网络(即共享相同的参数集)用于提取三元组中所有图像的低维表示的架构被称为三元组架构/网络。</p></blockquote></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h2 id="0f65" class="ov lk iq bd ll ow ox dn lp oy oz dp lt ko pa pb lv ks pc pd lx kw pe pf lz pg bi translated">对比损失法和三重损失法的问题:</h2><ol class=""><li id="3166" class="my mz iq kh b ki ol kl om ko po ks pp kw pq la nd ne nf ng bi translated">随着训练样本数量的增加，图像对和三元组的数量急剧增加，使得很难对所有可能的对或三元组进行训练。</li><li id="d1f6" class="my mz iq kh b ki nh kl ni ko nj ks nk kw nl la nd ne nf ng bi translated">训练对和三元组(即简单样本)的不良选择会导致辨别特征的无效学习。</li></ol><blockquote class="ms mt mu"><p id="d2f8" class="kf kg lb kh b ki kj jr kk kl km ju kn mv kp kq kr mw kt ku kv mx kx ky kz la ij bi translated">那么，如何解决上述问题呢？</p></blockquote><blockquote class="mb"><p id="47dc" class="mc md iq bd me mf nz oa ob oc od la dk translated">通过仔细选择训练图像对和三元组——离线或在线，并使用较大的批量。</p></blockquote><p id="4303" class="pw-post-body-paragraph kf kg iq kh b ki mn jr kk kl mo ju kn ko mp kq kr ks mq ku kv kw mr ky kz la ij bi translated">*注意:有很多种技术有助于用对比和三元组方法解决采样问题，我希望在以后的文章中讨论这些技术:)</p><h1 id="e5b8" class="lj lk iq bd ll lm oq lo lp lq or ls lt jw os jx lv jz ot ka lx kc ou kd lz ma bi translated">c.基于分类:中心损失</h1><p id="90cf" class="pw-post-body-paragraph kf kg iq kh b ki ol jr kk kl om ju kn ko on kq kr ks oo ku kv kw op ky kz la ij bi translated">论文<a class="ae mm" href="https://kpzhang93.github.io/papers/eccv2016.pdf" rel="noopener ugc nofollow" target="_blank">一种用于深度人脸识别的判别特征学习方法</a>通过引入一种新的损失(称为<strong class="kh ir"> <em class="lb">【中心损失】</em> </strong> <em class="lb"> </em>)以及交叉熵损失(即<strong class="kh ir"> <em class="lb">)来解决使用香草神经网络分类的目的。</em>T11】</strong></p><p id="302c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本文解决了文章开头提到的问题——<em class="lb">“分类器没有最小化</em> <strong class="kh ir"> <em class="lb">类内</em> </strong> <em class="lb"> </em> <strong class="kh ir"> <em class="lb">距离</em> </strong> <em class="lb">而只是最大化</em> <strong class="kh ir"> <em class="lb">类间距离</em> </strong> <em class="lb">导致可线性分离的特征而不是可区分的特征”</em>。</p><h2 id="20d5" class="ov lk iq bd ll ow ox dn lp oy oz dp lt ko pa pb lv ks pc pd lx kw pe pf lz pg bi translated">中心损耗:</h2><blockquote class="mb"><p id="8949" class="mc md iq bd me mf mg mh mi mj mk la dk translated">中心损失最小化每个类中心和类样本表示之间的距离-这确保了同一类中样本的表示除了保持类间距离之外还保持相似(由 ce 损失负责)。</p></blockquote><p id="5b24" class="pw-post-body-paragraph kf kg iq kh b ki mn jr kk kl mo ju kn ko mp kq kr ks mq ku kv kw mr ky kz la ij bi translated">设<strong class="kh ir"> <em class="lb"> x </em> </strong>为输入样本，<strong class="kh ir"> <em class="lb"> c </em> </strong>为该样本的分类中心。</p><figure class="nn no np nq gt nr gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/b215605d72af8d01071b493548385ee8.png" data-original-src="https://miro.medium.com/v2/resize:fit:634/format:webp/1*lOpW3aSJnnPFPLxSnnS1-Q.png"/></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">中心损失</p></figure><blockquote class="ms mt mu"><p id="d3b3" class="kf kg lb kh b ki kj jr kk kl km ju kn mv kp kq kr mw kt ku kv mx kx ky kz la ij bi translated">每次迭代计算类中心(嵌入)和样本嵌入之间的距离，并更新权重。</p></blockquote></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h2 id="5de6" class="ov lk iq bd ll ow ox dn lp oy oz dp lt ko pa pb lv ks pc pd lx kw pe pf lz pg bi translated">基于分类的培训的问题:</h2><ol class=""><li id="8581" class="my mz iq kh b ki ol kl om ko po ks pp kw pq la nd ne nf ng bi translated">基于分类器的方法在目标类数量非常多的情况下变得不切实际——这是通常的情况，也是使用成对/三重损失背后的强大推理。</li></ol></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="d02d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以上就是本文中关于<strong class="kh ir"> <em class="lb">深度距离度量学习的全部内容。</em> </strong>我希望你们所有人都很好地理解了这个问题是什么，以及如何通过各种有趣的技术来解决这个问题:)</p><p id="8384" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">干杯！</p><p id="40d6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其他资源:</p><p id="428f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae mm" href="https://neptune.ai/blog/content-based-image-retrieval-with-siamese-networks" rel="noopener ugc nofollow" target="_blank">https://Neptune . ai/blog/content-based-image-retrieval-with-siamese-networks</a></p></div></div>    
</body>
</html>