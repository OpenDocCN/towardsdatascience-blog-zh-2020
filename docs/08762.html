<html>
<head>
<title>Data Mechanics Delight — We’re building a better Spark UI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据力学的喜悦——我们正在构建一个更好的Spark UI</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/spark-delight-were-building-a-better-spark-ui-1b463840e243?source=collection_archive---------35-----------------------#2020-06-24">https://towardsdatascience.com/spark-delight-were-building-a-better-spark-ui-1b463840e243?source=collection_archive---------35-----------------------#2020-06-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7604" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">“Spark UI是我最喜欢的监控工具”——从来没有人这么说过。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ecf5775167b0870d3683e5b09212acf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*6drIt6mixCeR3OFuNIHSJQ.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我们的Spark UI替代原型正在运行。</p></figure><p id="76d2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Apache<a class="ae lu" href="https://spark.apache.org/docs/3.0.0-preview/web-ui.html" rel="noopener ugc nofollow" target="_blank">Spark UI</a>,<a class="ae lu" href="https://www.datamechanics.co/apache-spark" rel="noopener ugc nofollow" target="_blank">Apache Spark</a>附带的开源监控工具是Spark开发者用来了解他们的应用性能的主要界面。然而，它也产生了许多挫折。我们不断从Apache Spark初学者和专家那里听到这样的话:</p><ul class=""><li id="3fa1" class="lv lw it la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated"><em class="me">《很难理解是怎么回事》</em></li><li id="1655" class="lv lw it la b lb mf le mg lh mh ll mi lp mj lt ma mb mc md bi translated"><em class="me">“即使有关键信息，它也隐藏在许多只有专家才知道如何导航的嘈杂信息后面”</em></li><li id="773d" class="lv lw it la b lb mf le mg lh mh ll mi lp mj lt ma mb mc md bi translated"><em class="me">“这涉及到很多部落知识”</em></li><li id="9914" class="lv lw it la b lb mf le mg lh mh ll mi lp mj lt ma mb mc md bi translated"><em class="me">“Spark历史服务器很难安装”</em></li></ul><p id="c8e8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，我们的团队已经开始用一些令人愉快的东西取代Spark UI和Spark History Server，这是一个免费的、跨平台和部分开源的工具，名为<a class="ae lu" href="https://www.datamechanics.co/delight" rel="noopener ugc nofollow" target="_blank"><strong class="la iu">Data Mechanics Delight</strong></a>。</p><p id="f128" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">更新(2021年4月):</strong> <a class="ae lu" href="https://www.datamechanics.co/blog-post/delight-the-new-improved-spark-ui-spark-history-server-is-now-ga" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu"> Delight已经正式发布！</strong> </a> <strong class="la iu"> </strong>它可以在任何Spark平台上工作:Databricks、EMR、Dataproc、HDInsight、CDH/HDP、Kubernetes开源上的Spark、Spark-on-Kubernetes operator、开源spark-submit等。<br/><strong class="la iu"/><a class="ae lu" href="https://www.datamechanics.co/delight" rel="noopener ugc nofollow" target="_blank"><strong class="la iu"/></a><strong class="la iu">】</strong><a class="ae lu" href="https://github.com/datamechanics/delight" rel="noopener ugc nofollow" target="_blank"><strong class="la iu">在Github上查看或开源代理</strong></a><strong class="la iu">】</strong></p><h1 id="a201" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">现在的Spark UI有什么问题？</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nc"><img src="../Images/051624b1b0faf3682a3e35d4ea3a7f86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bgWugMqcjaYPMPzt.jpg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">熟悉的Spark用户界面(工作页面)</p></figure><p id="27c8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">很难鸟瞰正在发生的事情。</p><ul class=""><li id="5b88" class="lv lw it la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated">哪些工作/阶段花费了大部分时间？它们如何与我的代码匹配？</li><li id="c188" class="lv lw it la b lb mf le mg lh mh ll mi lp mj lt ma mb mc md bi translated">是否有稳定性或性能问题很重要？</li><li id="4020" class="lv lw it la b lb mf le mg lh mh ll mi lp mj lt ma mb mc md bi translated">我的应用程序的瓶颈是什么(I/O限制、CPU限制、内存限制)？</li></ul><p id="7f8a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">Spark UI缺乏基本的节点指标(CPU、内存和I/O使用)。</strong></p><ul class=""><li id="efea" class="lv lw it la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated">你可以不带他们去，但你会走在黑暗中。改变一个实例类型将是一个信念的飞跃。</li><li id="da04" class="lv lw it la b lb mf le mg lh mh ll mi lp mj lt ma mb mc md bi translated">或者你需要建立一个独立的指标监控系统:Ganglia、Prometheus + Grafana、StackDriver (GCP)或CloudWatch (AWS)。您需要在这个监控系统和Spark UI之间来回切换，试图匹配两者之间的时间戳(通常在UTC和您的本地时区之间切换，以增加乐趣)。</li></ul><p id="0e5d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">Spark历史服务器(在应用程序完成后呈现Spark UI)很难设置。</strong></p><ul class=""><li id="2aec" class="lv lw it la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated">您需要将Spark事件日志保存到长期存储中，并经常自己运行它，这会产生成本和维护负担。</li><li id="705b" class="lv lw it la b lb mf le mg lh mh ll mi lp mj lt ma mb mc md bi translated">加载时间很长，有时会崩溃。</li></ul><h1 id="ff75" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">数据力学的喜悦会是什么样子？</h1><p id="70cc" class="pw-post-body-paragraph ky kz it la b lb nd ju ld le ne jx lg lh nf lj lk ll ng ln lo lp nh lr ls lt im bi translated">一张图胜过千言万语:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/411471a637c44a428e9254939e9619ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*heAS8ZW2-HSX4hPQ.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我们的Spark UI替代品的原型。让我们知道您的反馈！</p></figure><p id="2a36" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">那么它有什么新鲜之处呢？主屏幕(概览)有许多新的信息和视觉效果。</p><p id="d4b8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">汇总统计</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/ec8691b50087f476492a6ecd83daa9d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kLKCxVj1rdg1J-uG.png"/></div></div></figure><p id="2ce5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">应用程序的持续时间是多少，使用的资源量(CPU正常运行时间)，所有Spark任务的持续时间(应该接近您的CPU正常运行时间，除非您遇到了糟糕的并行性或长时间的纯驱动程序工作/空闲)。</p><p id="466e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">建议</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/2c4c83f0914d31174afba350023a2b9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/0*wh6KmqychizdIWzZ.png"/></div></figure><p id="0e72" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">本节从高层次上指出了稳定性和性能问题，以帮助开发人员解决这些问题。示例:</p><ul class=""><li id="6c56" class="lv lw it la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated">"与可用的CPU核心数(400)相比，默认的任务数(200)太小。将<strong class="la iu"><em class="me">spark . SQL . shuffle . partitions</em></strong>增加到1200。”</li><li id="d084" class="lv lw it la b lb mf le mg lh mh ll mi lp mj lt ma mb mc md bi translated">“作业4遭受输入数据偏斜。请考虑对您的数据进行重新分区或对分区键加盐”。</li><li id="7199" class="lv lw it la b lb mf le mg lh mh ll mi lp mj lt ma mb mc md bi translated">在Python使用了85%的内存的情况下，由于阶段7中的内存不足错误，执行器崩溃，请考虑增加每个执行器的可用内存或设置<strong class="la iu"><em class="me">spark . executor . py spark . memory</em></strong>。</li></ul><p id="cda1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">本节基于Data Mechanics平台的功能，根据其历史自动调整基础架构参数和Spark配置(例如，实例类型、内存/cpu分配、并行性配置、shuffle、I/O)。这种高层次的反馈将通过帮助开发人员理解和优化他们的应用程序代码来补充平台的无服务器特性。</p><p id="ff61" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">执行器CPU使用率</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/f75cd1f2dfb6779bdf5384e710c51780.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*i2jD-icwpnRIqWzQ.png"/></div></div></figure><p id="3354" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> ‍ </strong>你的executor CPU内核平均在做什么？如果有大量未使用的时间，可能是你的应用过度配置了。如果他们花费大量时间进行洗牌(所有对所有的数据通信)，那么值得看看是否可以避免一些洗牌，或者调整洗牌阶段的性能。此屏幕应能让您快速了解您的应用是受I/O限制还是受CPU限制，并相应地做出更智能的基础架构更改(例如，使用具有更多CPU或更快磁盘的实例类型)。</p><p id="4cdd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个屏幕的伟大之处在于，你可以直观地将这些信息与你的应用程序的不同火花阶段对应起来。如果你的应用程序大部分时间花在单一洗牌阶段，你可以在一秒钟内发现这一点，只需点击一下就可以进入特定阶段。</p><p id="7440" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">执行者峰值内存使用量</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/fc8c01865500ecaad54cea10a45292e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*chREl_tYww0EOti0.png"/></div></div></figure><p id="3649" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个屏幕显示了总内存消耗达到峰值时每个执行器的内存使用情况。您将立即看到您是否接近了内存限制(勉强避免了内存不足的错误)，或者您是否有足够的腿部空间。Data Mechanics Delight为您提供了JVM使用的不同类型的内存和python内存使用的划分。这些数据是至关重要的，但据我们所知，Spark开发人员目前还没有获得这些数据的简单方法。‍</p><p id="7012" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">阶段和执行者页面</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/ba8dd4c7c86064c384c00b70bb177e38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*nnUjPBZ7j6pmswRW.png"/></div></div></figure><p id="324b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后，您可以在Spark stage页面或executor页面上以更精细的粒度找到类似的信息。例如，在一个特定的阶段页面上，您将看到显示该阶段中所有任务的指标分布(例如，持续时间或输入大小)的图表，因此您可以立即直观地注意到是否存在偏差。查看动画GIF以获得完整的游览。</p><h2 id="9d92" class="nn ml it bd mm no np dn mq nq nr dp mu lh ns nt mw ll nu nv my lp nw nx na ny bi translated">有什么不新鲜的？</h2><p id="a3b6" class="pw-post-body-paragraph ky kz it la b lb nd ju ld le ne jx lg lh nf lj lk ll ng ln lo lp nh lr ls lt im bi translated">Spark UI也有许多视觉效果非常好。我们的目标是不要放弃一切。相反，我们希望Data Mechanics包含与当前Spark UI一样多的信息。我们计划重用许多元素，比如作业、阶段和任务的列表、说明在一个阶段内跨执行者调度的任务的甘特图、DAG视图等等。</p><h1 id="9c59" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">在实践中，如何使用数据机制来调试？</h1><p id="1283" class="pw-post-body-paragraph ky kz it la b lb nd ju ld le ne jx lg lh nf lj lk ll ng ln lo lp nh lr ls lt im bi translated">我们将使用我们最近遇到的一些客户的两个具体场景。</p><h2 id="8eea" class="nn ml it bd mm no np dn mq nq nr dp mu lh ns nt mw ll nu nv my lp nw nx na ny bi translated">并行性问题</h2><p id="f8cd" class="pw-post-body-paragraph ky kz it la b lb nd ju ld le ne jx lg lh nf lj lk ll ng ln lo lp nh lr ls lt im bi translated">我们的一个客户正在运行一个有10个执行器的应用程序，每个执行器有8个CPU内核，这样这个应用程序可以并行运行80个Spark任务。但是一名开发人员将<strong class="la iu"><em class="me">spark . SQL . shuffle . partitions</em></strong>配置设置为8，因此在洗牌期间只生成了8个任务，这意味着90%的应用资源未被使用。这种配置是一个错误(可能是在本地开发期间设置的)，但事实是，这个关键问题在当前的Spark UI中完全没有出现，除非您非常清楚在哪里可以找到它。从数据力学的角度来看，问题是显而易见的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/ce572996470cde18b52d4b66c216d4ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jvEneUlAycWZ5nth.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">这张图表显示了一段时间内平均执行器CPU使用率，显示了由于糟糕的并行性，存在大量未使用的容量，尤其是在应用程序的最后几个作业和阶段。</p></figure><p id="ece8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个并行性示例可能看起来像是故意的，但请注意，它比您想象的更常见——当默认值(200)与总应用程序容量相比太小时，或者当输入数据被错误分区时(这需要进行更多的配置更改才能修复)，也会发生这种情况。</p><h2 id="16e2" class="nn ml it bd mm no np dn mq nq nr dp mu lh ns nt mw ll nu nv my lp nw nx na ny bi translated">记忆问题</h2><p id="1a90" class="pw-post-body-paragraph ky kz it la b lb nd ju ld le ne jx lg lh nf lj lk ll ng ln lo lp nh lr ls lt im bi translated">在Apache Spark 中，内存错误是最常见的崩溃来源，但它们有不同的种类。JVM可以得到一个OutOfMemory错误(意味着堆达到了它的最大大小，需要分配更多的空间，但即使在GC找不到任何空间之后)，这可能由于许多原因而发生，例如不平衡的洗牌、高并发性或缓存的不当使用。另一个常见的内存问题是当一个Spark执行器由于超出内存限制而被杀死时(被Kubernetes或YARN杀死)。这在使用PySpark时经常发生，因为Spark执行器将为每个正在运行的任务生成一个python进程。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/6ad7df1dd61f21b5610e2565e5d6140c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_NXw6ENOjFBmSe_D.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">这个峰值使用时的执行器内存分解图显示Python进程使用了大部分分配的容器内存。</p></figure><p id="2f2f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">很少有监控工具可以让您看到JVM(堆和非堆)和Python的内存使用情况，但是这些信息对于稳定性是至关重要的。在这个截图中，我们可以看到内存使用率最高的执行器非常接近极限。</p><p id="706a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">PySpark用户在监控内存使用时经常一无所知，我们希望这个新界面对他们有用，并避免可怕的OOM-kills。</p><h1 id="4c2d" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">数据力学快乐是如何工作的？</h1><p id="a9ef" class="pw-post-body-paragraph ky kz it la b lb nd ju ld le ne jx lg lh nf lj lk ll ng ln lo lp nh lr ls lt im bi translated">Data Mechanics Delight由两个主要部分组成:</p><ul class=""><li id="dcd8" class="lv lw it la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated">一个运行在你的Spark应用程序内部的<a class="ae lu" href="https://github.com/datamechanics/delight" rel="noopener ugc nofollow" target="_blank">开源</a>代理。这个代理将把Spark事件日志从您的Spark应用程序传输到我们的后端。</li><li id="d599" class="lv lw it la b lb mf le mg lh mh ll mi lp mj lt ma mb mc md bi translated">一个闭源后端，由实时日志接收管道、存储服务、web应用程序和身份验证层组成，以确保其安全性。</li></ul><h1 id="34c7" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">我该如何开始？</h1><p id="c240" class="pw-post-body-paragraph ky kz it la b lb nd ju ld le ne jx lg lh nf lj lk ll ng ln lo lp nh lr ls lt im bi translated">Data Mechanics是一个云原生Spark平台，致力于为数据工程师提供易于使用且经济高效的Spark。了解更多关于<a class="ae lu" href="https://www.datamechanics.co/blog-post/spark-on-kubernetes-made-easy-how-data-mechanics-improves-on-spark-on-k8s-open-source" rel="noopener ugc nofollow" target="_blank">的信息，我们的平台以开源方式</a>在Kubernetes上运行Spark的基础上增加了什么。我们的核心特性之一是，我们的平台自动调整基础设施参数和Spark配置，使Spark管道更加稳定和高效。</p><p id="80b1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Data Mechanics Delight通过向Spark开发人员提供他们在应用程序代码级别开发、生产和维护稳定且高性能的应用程序所需的高级反馈，补充了我们的平台，例如，了解何时使用缓存，了解何时对输入数据进行重新分区，因为您会遇到偏差等问题。</p><p id="6edc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">更新(2021年4月):</strong> <a class="ae lu" href="https://www.datamechanics.co/blog-post/delight-the-new-improved-spark-ui-spark-history-server-is-now-ga" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu"> Delight已经正式发布！</strong> </a> <strong class="la iu"> </strong>它可以在任何Spark平台之上工作:Databricks、EMR、Dataproc、HDInsight、CDH/HDP、Kubernetes开源上的Spark、Spark-on-Kubernetes operator、开源spark-submit等。<br/><strong class="la iu"/><a class="ae lu" href="https://www.datamechanics.co/delight" rel="noopener ugc nofollow" target="_blank"><strong class="la iu"/></a><strong class="la iu">】</strong><a class="ae lu" href="https://github.com/datamechanics/delight" rel="noopener ugc nofollow" target="_blank"><strong class="la iu">在Github上查看或开源代理</strong></a><strong class="la iu">】</strong></p></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><p id="3d2f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="me">这篇博文原载于</em> <a class="ae lu" href="https://www.datamechanics.co/blog-post/building-a-better-spark-ui-data-mechanics-delight" rel="noopener ugc nofollow" target="_blank"> <em class="me">数据力学博客</em> </a> <em class="me">。</em></p></div></div>    
</body>
</html>