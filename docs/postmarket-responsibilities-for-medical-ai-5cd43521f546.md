# 医疗人工智能的上市后责任

> 原文：<https://towardsdatascience.com/postmarket-responsibilities-for-medical-ai-5cd43521f546?source=collection_archive---------57----------------------->

![](img/4a100fe24a8d290610bf51b1897a00a8.png)

production Perig/shutterstock . com

## **第三部分——FDA 不应扩大对商业化人工智能的监管**

在本系列的第一部分[中，我概述了 FDA 现有的监管医疗器械商业化的法定权力。这一权力是巨大的，几十年来一直很好地服务于该机构。它不知道技术的具体形式，并且很容易适应人工智能的需要。但是当涉及到医疗人工智能时，FDA 想要更多。FDA 希望不断了解医疗人工智能在市场上的表现。](/postmarket-responsibilities-for-medical-ai-part-i-fdas-plan-to-increase-its-oversight-dae6d840ffc6)

这不仅是不必要的；这对创新和重要的、可能挽救生命的技术的可获得性肯定是有害的。明确地说，我并不是建议我们简单地相信公司会做正确的事情，定义为每个公司自己认为是正确的事情。相反，我建议将[第二部分](/postmarket-responsibilities-for-medical-ai-56ba67fd8cc)中列出的原则嵌入到 FDA 将颁布的良好机器学习实践法规中。如果公司对上市后警惕性的要求明确，绝大多数开发医疗人工智能的公司都会遵循这些要求。

我所质疑的是，除了澄清医疗人工智能公司在从事上市后警戒时应该遵守的监管要求，我们还增加了这些公司的报告义务。我反对的是报道的增加。国会和 FDA 都不应该修改法律，以(1)要求公司在上市后与 FDA 分享更多信息，(2)允许 FDA 监督产品生命周期商业化阶段的日常决策，或(3)赋予 FDA 进行虚拟检查的能力。

在这第三部分，我将概述这三个反对扩大 FDA 对商业化医疗人工智能的报告义务的主要论点。

# A.林业发展局不应增加公司的报告义务

# 1.信息量将是巨大的

在未来几年，在医疗保健领域部署人工智能的公司将大量收集上市后数据。我们不会试图在这里预测到底有多少，但希望每个人都同意这将是一个巨大的数字。

如果 FDA 要求公司开始向该机构移交哪怕一小部分数据(包括性能数据和在主动监控下收集的其他数据)，也会让该机构不堪重负。我们理解 FDA 目前受到人力资源的限制，特别是那些有人工智能软件背景的人。坦白地说，该机构没有配备人力或信息系统来阅读和解释上市后持续传递给它的数据。

即使 FDA 努力与医疗器械利益相关者合作建立国家卫生技术评估系统(NEST ),这也是事实。NEST 将永远没有必要的资源来确保为 NEST 将收集的所有真实证据提供适当的上下文。

如上所述，MDR 背后的整个理念是要求公司在向 FDA 报告时区分信号和噪音。该法规包括针对故障和严重伤害的特定相关性测试，公司将使用这些测试来评估信息是否需要报告给 FDA。事实上，FDA 过去曾表示，多报是违反 MDR 法规的，因为该机构担心多报会用噪音掩盖信号。因此，历史上传递给 FDA 的信息量已经过仔细的滴定，以确保它集中于相关信号，并排除干扰噪声。采用人工智能来改变这种精心制定的长期方法是没有依据的。

换句话说，我确实认为公司将不得不投入相当多的资源来监控他们的算法在上市后的表现，如上所述。但是，这并不意味着我们也应该考虑增加对 FDA 的报告，特别是因为该机构不太可能具备处理额外信息的能力。

# 2.原始信息对 FDA 没有什么价值

除了反对通过降低被认为重要的门槛来增加软件开发商必须提交的 MDR 报告的数量，开发商不应该被要求与 FDA 分享更多的原始信息流。我所使用的术语“原始信息”是指软件开发人员直接收集的信息，没有经过任何分析或语境化。

现有 MDR 法规的另一个目的是确保原始信息不会简单地转储到 FDA。来自市场的原始信息本身几乎没有任何信息。从市场上收集的所有信息都需要进一步的调查和重要背景的分析，以理解信息的临床和技术意义。公司自己也经常这样做。当他们发现一个潜在的信号时，他们会深入了解这个信号的含义。

在这方面，人工智能与其他任何医疗设备没有什么不同。它将产生大量的信息，比传统的医疗设备产生的信息要多得多。除非放在适当的上下文中，否则这些信息实际上是没有意义的。现有的质量体系条例(21 CFR Part 820)规定公司有责任对投诉和其他质量信号进行调查。然后是 MDR 法规，要求公司向 FDA 报告任何潜在的严重信号，以便该机构可以参与最终决策。

任何让公司与 FDA 分享原始信息的方法都可能只会增加该机构的负担，而不会有任何结果。如果没有适当的背景，即使假设 FDA 能够建立必要的信息技术和人力资源来分析信息，也会导致混乱。

现有的 MDR 义务，建立在质量体系义务之上，就潜在问题向 FDA 提供有意义的上下文报告。没有理由背离这种方法。

# B.FDA 不应该介入人工智能新产品商业化的日常决策

大多数人都听说过这样一个笑话:“我来自华盛顿，我是来帮助你的。”坦率地说，政府监管的介入几乎从来不会对被“帮助”的公司有所帮助。

# 1.食品和药物管理局可能会不必要地干预公司的运作

与 FDA 过度分享有一个明显的缺点，那就是过多的噪音会让该机构感到困惑。如果 FDA 有人力和计算机资源来读取数据，并且如果 FDA 能够理解原始数据，缺乏上下文可能会导致 FDA 反复询问报告公司问题，并可能在实际上不应该采取行动时要求采取行动。对数据的部分或不完全理解会产生潜在的风险，即该机构将采取不明智的行动，从而给公司带来巨大的负担。

# 2.FDA 会无意中伤害人工智能初创公司

一家小公司根本无法在美国食品和药物管理局每天向其提出大量问题的情况下运营。该机构的这种微观管理水平将对行动造成毁灭性打击。最终结果将是公司无法将足够的资源投入到包括质量保证在内的运营中。那么，病人将会因为公司的分心而遭受损失。

此外，FDA 要求公司提供的数据量会迫使公司花费额外的资源来满足 FDA 的要求。虽然大公司可以更容易地吸收这些额外的员工，但小公司，尤其是初创公司，却不能。长期来看，这将使初创公司更难创新重要的新的 FDA 监管的人工智能。

# 3.与 FDA 分享太多信息会产生公开披露的风险

正如已经解释过的，我同意，如果公司分享更多关于部署的自适应或自主人工智能的信息，这将符合每个人的最佳利益。但是正如我也说过的，FDA 和我可能在谈论完全不同的领域，哪些信息应该共享。

公司应该分享产品性能的适当总结。在一家公司的网站上分享几个段落，也许是总结产品当前性能的表格或图表，将有助于所有用户了解应该在多大程度上依赖(或不依赖)该产品。对所有人来说，理解算法输出的不确定性程度以及其他统计度量是很重要的。

然而，无论如何，公司都不应该与公众或 FDA 共享原始数据，甚至是带注释的数据，这样我们就可以期望接收者进行他们自己的分析。这将违背几乎所有其他领域的现有商业惯例。

人工智能开发者在竞争激烈的市场中运作。事实上，人工智能领域竞争激烈，因为它不需要大量资本进入，至少在早期阶段不需要。此外，专利保护不足以完全保护这些公司免受竞争威胁。

正如已经观察到的，如果我们希望人们在这些企业上冒险投入时间和金钱，他们必须能够保护这些投资。要求公司广泛而自由地分享原始数据供所有人分析只会导致公司在其他地方投资，而不是追求这些技术。这样的数据会让竞争对手对算法的机制有太多的了解。此外，如前所述，病人最终会失败。

美国法律体系一直要求公司诚实披露信息，并披露他们需要披露的任何信息。现有的产品责任法以及广告法中的真实性要求(1)肯定的披露和(2)披露的真实性。几十年来，美国的制度是建立在这样一个前提之上的，即我们将依赖公司的直率和诚实，但我们不会要求它们分享为其业务创造价值的机密商业信息和商业秘密。

即使只是向 FDA(一个像所有联邦机构一样受《信息自由法》约束的机构)披露信息，也会产生这样的风险，即如此共享的信息会进入公共领域。FDA 必须对其认为应该发布的产品做出判断，而这些判断决不是绝对可靠的。这里有两个独立的风险。

第一，FDA 只是犯了个错误，发布了不该发布的信息。这种情况并不经常发生，但重要的是要明白，上市后收集的可能以电子方式传输的数据可能会意外地被放在公开发布的数据集中。判断应该发布什么信息通常需要仔细的人工审查。目前，该系统对上市前申请中提交的数据工作得相当好，但上市后收集的数据则完全不同，而且更加复杂。FDA 获得的数据越多，他们在管理上就越难决定哪些是可以公开发布的，哪些是不可以公开发布的，从而更容易出错。

第二，也是更大的风险，是食品和药物管理局会简单地以不同于制造商的方式解释法律，并发布制造商不同意受 FOIA 发布条款约束的信息。有整本书都在讨论 FOIA 的范围，但是在一个高层次上，FDA 必须决定什么是不公开发布的，因为它是商业秘密或者机密的商业信息。这些定义不是很精确，关于人工智能的信息实际上是否属于这些受保护的类别，法律学者之间有很大的不同观点。例如，被清理或操纵的训练和验证数据集是机密商业信息还是商业秘密？关于算法考虑哪些特征的知识呢？或者算法的源代码、其规格和调整参数，以及将预测转化为行动的任何辅助计算机程序的编程细节？这些决定涉及许多法律判断。

一旦数据掌握在 FDA 手中，尽管公司可以通过行政程序为自己辩护，但最终信息的发布掌握在 FDA 手中，并受到司法监督。只有当一家公司事先得到通知并有机会反对时，这种情况才会发生。简而言之，增加公司所需的数据共享会不可接受地增加数据落入那些想要伤害公司的人手中的风险。

此外，这不仅仅是竞争威胁。外面有坏人。看看网络安全攻击就知道了。更进一步，还有人故意在社交媒体上散布误传，伤害他人。除了经济原因，他们还有各种各样的原因。然而，即使在经济领域，也不仅仅是竞争对手。人们会在负面新闻的帮助下进行投资押注(例如，卖空股票的人)。

复杂的原始信息，同样在没有重要背景帮助的情况下，可能会被误解并被用来伤害公司和影响市场。要求发布难以理解和复杂解释的未经语境化的原始数据不会带来公众的信任，反而会导致错误信息和混乱。

正如我在上面所说的，但是我要再说一遍，我确实同意公司对统计上重要的信息进行适当的总结将有助于利益相关者正确地使用技术。利益相关者必须理解技术的局限性，而这些局限性将随着时间的推移而演变。因此，更新这些总结将是重要的一步。

然而，期望公司分享原始的甚至是有背景的原始信息供公众分析是一个坏主意。竞争影响将过于消极，其他错误信息的风险也将过于巨大，因此这不是一个明智的做法。

# C.FDA 不应回避现场物理检查

FDA 不应通过强制要求公司以电子方式向该机构发送记录来绕过现场实物检查要求，因为这样做会有效地扩大报告义务，这与刚才陈述的论点相反。

为了将这一切结合在一起，我建议坚持 MDR 系统的现有框架，即公司在自己的上市后审查中保持警惕，寻找可能出现的信号，并将有问题的信号报告给 FDA。此外，如前所述，公司将收集广泛的信息，并在持续的基础上生成内部报告，以监控其产品的性能，这些信息作为质量系统的一部分，将在现场检查期间供 FDA 审查。

这并不是说我建议对 FDA 隐瞒这些信息。但是，我建议，除了明确要求报告的信息之外，这些信息只有在现场实际检查后才能提供给 FDA。正是实际检查访问的要求使 FDA 免于不必要的微观管理。如果 FDA 真的必须去该公司查看记录，FDA 只有在有足够的理由感兴趣时才会这样做。这个小小的措施，要求 FDA 进行现场视察，在确保 FDA 监督的实际水平方面产生了巨大的影响。

近年来，食品和药物管理局一直试图绕过明确的法定限制，他们进行实地考察。不难理解为什么。只需拿起电话，打电话给制造商，告诉他们将信息发送给代理商，就可以节省资金。尴尬的是，制造商非常关心 FDA 的权力，并希望让 FDA 满意。这种强制手段非常有效。它导致公司在不需要的时候以电子方式提交信息。

然而，这种情况必须停止。除非在非常特殊的情况下，如疫情，否则不应该允许食品和药物管理局进行实际的现场检查。虽然 FDA 很想这样做，但我认为 FDA 应该避免这样做。正如我在上面所说的，要求 FDA 在要求查看公司记录之前采取个人访问的肯定步骤是有明确逻辑的。这是对过度监管的一个微妙但非常重要的限制。

实际上，FDA 的行为违反了规定公司报告义务的 MDR 法规。应要求公司自行严格监控，向 FDA 报告符合法定 MDR 标准的可疑问题，然后在现场访问时向 FDA 提供所有数据。然而，这应该是它的极限了。

# 结论

一切从病人开始，也从病人结束。我的父亲在我之前是一名食品和药品律师，他总是告诉我，如果我面对一个含糊不清的法规，从有利于病人的角度去解释它，我就不会出错。政策制定也是如此。弄清楚什么对病人最好。

监管对病人有好处，但要适度。过度监管是很有可能的。对于像人工智能这样的新兴技术，我们需要特别敏感地正确对待这一点。由于监管太少，严厉的过度监管肯定会给患者带来不好的结果。不必要的阻碍新技术通过减少可及性伤害了患者。

谈到监管已经上市的产品，我们在医疗设备方面有几十年的经验，可以应用于新技术。虽然人工智能有一些使其不同于传统医疗设备的基本要素，例如它们在市场上随着时间的推移而变化，但这并不一定意味着需要一种新的范式。

如果人工智能开发者履行他们的责任，进行必要的上市后警戒，现有的上市后范式将会相当好地工作。并非所有的上市后产品监管决策都值得 FDA 首先参与。我们应该合理地相信公司会做正确的事情，而不是假设他们会做错误的事情。

与此同时，我做这行已经 35 年了，我没有幻想过行业中的每个人都是可敬的。可惜世界上总有坏人。

在这种情况下，平衡一切，法律中需要的改进是我理解的 FDA 已经在追求的，这是一套良好的机器学习实践。这些 GMLPs 需要尽可能明确，而不是规定具体的，关于上市后公司管理产品生命周期阶段的义务。这不是附加报告。这只是 GMLP 应该实施的标准，要求公司按照上述思路积极主动地保持足够的警惕，而不仅仅是被动地做出反应。有了这一点，监管专业人士可以帮助确保公司尽一切努力负责任地管理使用可适应人工智能的内在风险。

法律关于上市后警戒的明确性，而不是 FDA 的额外监督，将平衡患者安全与新产品开发中的创新需求。

詹姆斯·奥莱利，联邦信息公开，2020 年第一版。