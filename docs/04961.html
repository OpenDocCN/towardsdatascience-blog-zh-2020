<html>
<head>
<title>Which Face is Real? Applying StyleGAN to Create Fake People</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">哪张脸是真的？应用StyleGAN来创造假的人</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/which-face-is-real-c63ce568efd5?source=collection_archive---------60-----------------------#2020-04-29">https://towardsdatascience.com/which-face-is-real-c63ce568efd5?source=collection_archive---------60-----------------------#2020-04-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="7ac2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">生成模型旨在学习和理解数据集的真实分布，并使用无监督学习从中创建新数据。这些模型(如StyleGAN)有好有坏，因为很难理解某些概率分布的复杂性。</p><p id="bbec" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了绕过这些路障，<a class="ae ko" href="https://pathmind.com/wiki/generative-adversarial-network-gan" rel="noopener ugc nofollow" target="_blank">对抗性网络框架</a>被创建，由此生成模型与对手对抗:一个学习确定样本是来自模型分布还是数据分布的判别模型。</p><p id="6c47" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">生成模型通过使随机噪声通过多层感知器来生成样本，而判别模型也是多层感知器。我们把这种情况称为对抗性网络。</p><p id="c794" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">介绍这个对抗性框架的论文可以在<a class="ae ko" href="https://arxiv.org/pdf/1406.2661.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>找到，还有用于框架的<a class="ae ko" href="https://github.com/goodfeli/adversarial" rel="noopener ugc nofollow" target="_blank">代码。</a></p><h1 id="2417" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">哪张脸是真的？</h1><p id="e984" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated"><a class="ae ko" href="http://whichfaceisreal.com/index.php" rel="noopener ugc nofollow" target="_blank">哪张脸是真实的？</a>是由华盛顿大学<a class="ae ko" href="https://www.washington.edu/" rel="noopener ugc nofollow" target="_blank">的</a><a class="ae ko" href="https://www.jevinwest.org/" rel="noopener ugc nofollow" target="_blank">杰文·韦斯特</a>和<a class="ae ko" href="https://octavia.zoology.washington.edu/" rel="noopener ugc nofollow" target="_blank">卡尔·博格斯特伦</a>开发的，作为<a class="ae ko" href="https://callingbullshit.org/" rel="noopener ugc nofollow" target="_blank">呼叫扯淡项目</a>的一部分。</p><p id="3acd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="ls">“电脑不错，但你的视觉处理系统更好。如果你知道要找什么，你一眼就能认出这些假货——至少目前是这样。用于生成它们的硬件和软件将不断改进，人类在伪造和检测的军备竞赛中落后可能只需要几年时间。”—杰文·韦斯特和卡尔·博格斯特伦</em></p><h1 id="f4dd" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">你如何区分这些图像？</h1><p id="04c8" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">差异主要体现在6个方面:</p><h1 id="55fd" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">水渍</h1><ul class=""><li id="480f" class="lt lu it js b jt ln jx lo kb lv kf lw kj lx kn ly lz ma mb bi translated">该算法产生的闪亮斑点看起来有点像旧照片上的水斑。</li></ul><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/6fe8a431a699fac1685ed577654c5bcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1058/format:webp/0*8jQrB7GenpmVZjSf.jpg"/></div></figure><p id="e025" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ko" href="http://www.whichfaceisreal.com/learn.html" rel="noopener ugc nofollow" target="_blank">水渍</a></p><h1 id="061d" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">头发</h1><ul class=""><li id="1d73" class="lt lu it js b jt ln jx lo kb lv kf lw kj lx kn ly lz ma mb bi translated">不连续的发束、太直的头发或太多条纹将是生成头发时的常见问题。</li></ul><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/1b4b670b023465988b98b24029f479e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/0*6tFE_dFfmCpRyGkI.jpg"/></div></figure><p id="c4d8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ko" href="http://www.whichfaceisreal.com/learn.html" rel="noopener ugc nofollow" target="_blank">发</a></p><h1 id="3ed8" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">不对称</h1><ul class=""><li id="4a32" class="lt lu it js b jt ln jx lo kb lv kf lw kj lx kn ly lz ma mb bi translated">一个常见的问题是不对称。通常框架会在左边采用一种风格，在右边采用另一种风格，或者在一边有一个旅行者风格的装饰，而在另一边没有。其他时候，框架会弯曲或参差不齐。此外，面部毛发不对称、左耳和右耳不同的耳环以及左右两侧不同形式的衣领或织物也可能存在。</li></ul><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/bfd3240f7975d85f3e11998127f0caf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/0*MOsSF1Y9KMfZ38hO.jpg"/></div></figure><p id="a13e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ko" href="http://www.whichfaceisreal.com/learn.html" rel="noopener ugc nofollow" target="_blank">不对称</a></p><h1 id="2777" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">背景问题</h1><ul class=""><li id="fe88" class="lt lu it js b jt ln jx lo kb lv kf lw kj lx kn ly lz ma mb bi translated">图像的背景可能表现为奇怪的状态，如模糊或畸形的物体。这是因为神经网络是在人脸上训练的，对图像的背景给予的强调较少。</li></ul><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/80bea57dee2c32544d87adb4892379b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/0*AwdErU6q0o64IRLh.jpg"/></div></figure><p id="f255" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ko" href="http://www.whichfaceisreal.com/learn.html" rel="noopener ugc nofollow" target="_blank">背景问题</a></p><h1 id="5e69" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">荧光渗色</h1><ul class=""><li id="cd92" class="lt lu it js b jt ln jx lo kb lv kf lw kj lx kn ly lz ma mb bi translated">荧光色有时会从背景渗入头发或面部。观察者可能会误认为这是有色头发。</li></ul><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/592b1a7050b456cb192017a7639a61db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/0*Jbj7TwlaQlDwglB7.jpg"/></div></figure><p id="1686" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ko" href="http://www.whichfaceisreal.com/learn.html" rel="noopener ugc nofollow" target="_blank">荧光出血</a></p><h1 id="6852" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">牙齿（tooth的复数）</h1><ul class=""><li id="315d" class="lt lu it js b jt ln jx lo kb lv kf lw kj lx kn ly lz ma mb bi translated">牙齿也很难渲染，可能会呈现出奇怪的形状，不对称，或者对于那些可以识别牙齿的人来说，有时图像中会出现三颗门牙。</li></ul><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/759bd181e23b371ae06a44697f95be26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1066/format:webp/0*ZAgQD1K9yrAnzapV.jpg"/></div></figure><p id="94e6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ko" href="http://www.whichfaceisreal.com/learn.html" rel="noopener ugc nofollow" target="_blank">牙齿</a></p><h1 id="5aad" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">测试StyleGAN算法</h1><p id="8188" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">StyleGAN的所有代码都在<a class="ae ko" href="https://github.com/NVlabs/stylegan" rel="noopener ugc nofollow" target="_blank"> stylegan </a>库中开源。它给出了如何自己运行styleGAN算法的细节。因此，让我们开始分享一些基本的系统要求。</p><h1 id="beb7" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">系统需求</h1><ul class=""><li id="ec58" class="lt lu it js b jt ln jx lo kb lv kf lw kj lx kn ly lz ma mb bi translated">Linux和Windows都受支持，但是出于性能和兼容性的原因，我们强烈推荐Linux。</li><li id="7783" class="lt lu it js b jt mo jx mp kb mq kf mr kj ms kn ly lz ma mb bi translated">64位Python 3.6安装。我们建议使用numpy 1.14.3或更新版本的Anaconda3。</li><li id="19ee" class="lt lu it js b jt mo jx mp kb mq kf mr kj ms kn ly lz ma mb bi translated">支持GPU的TensorFlow 1.10.0或更新版本。</li><li id="d9c9" class="lt lu it js b jt mo jx mp kb mq kf mr kj ms kn ly lz ma mb bi translated">一个或多个至少11GB DRAM的高端NVIDIA GPUs。我们推荐8特斯拉V100 GPUs的英伟达DGX-1。</li><li id="9778" class="lt lu it js b jt mo jx mp kb mq kf mr kj ms kn ly lz ma mb bi translated">NVIDIA驱动391.35或更新，CUDA工具包9.0或更新，cuDNN 7.3.1或更新。</li></ul><p id="b78d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在<a class="ae ko" href="https://github.com/NVlabs/stylegan/blob/master/pretrained_example.py" rel="noopener ugc nofollow" target="_blank"> pretrained_example.py </a>中给出了一个尝试styleGAN预训练示例的最小示例。它按如下方式执行:</p><pre class="md me mf mg gt mt mu mv mw aw mx bi"><span id="1964" class="my kq it mu b gy mz na l nb nc">&gt; python pretrained_example.py<br/><br/>Downloading https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ .... done<br/><br/><br/><br/>Gs                              Params OutputShape WeightShape<br/><br/>---                             --- --- ---<br/><br/>latents_in                      - (?, 512) -<br/><br/>...<br/><br/>images_out                      - (?, 3, 1024, 1024) -<br/><br/>---                             --- --- ---<br/><br/>Total                           26219627<br/><br/><br/><br/><br/>Once you execute ‘python pretrained_example.py’, type in ‘ls results’ to see the results.<br/><br/><br/><br/>&gt; ls results<br/><br/>example.png # https://drive.google.com/uc?id=1UDLT_zb-rof9kKH0GwiJW_bS9MoZi8oP</span></pre><h1 id="b3d8" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">准备用于训练的数据集</h1><p id="949f" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">训练和评估脚本对存储为多分辨率TFRecords的数据集进行操作。每个数据集由一个目录表示，该目录包含不同分辨率的相同图像数据，以实现高效的流式传输。有一个单独的*。tfrecords文件，如果数据集包含标签，它们也存储在一个单独的文件中。默认情况下，脚本期望在数据集/ <name> / <name> - <resolution>找到数据集。tfrecords <em class="ls">。</em>目录可以通过编辑<a class="ae ko" href="https://github.com/NVlabs/stylegan/blob/master/config.py" rel="noopener ugc nofollow" target="_blank"> config.py </a>来改变:</resolution></name></name></p><pre class="md me mf mg gt mt mu mv mw aw mx bi"><span id="d691" class="my kq it mu b gy mz na l nb nc">result_dir = 'results'<br/><br/>data_dir = 'datasets'<br/><br/>cache_dir = 'cache'</span></pre><p id="f760" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要获取FFHQ数据集(datasets/ffhq)，请参考<a class="ae ko" href="https://github.com/NVlabs/ffhq-dataset" rel="noopener ugc nofollow" target="_blank"> Flickr-Faces-HQ库</a>。</p><p id="352e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要获取CelebA-HQ数据集(datasets/celebahq)，请参考<a class="ae ko" href="https://github.com/tkarras/progressive_growing_of_gans" rel="noopener ugc nofollow" target="_blank">渐进式GAN库</a>。</p><p id="560d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要获得其他数据集，包括LSUN，请查阅相应的项目页面。可以使用提供的<a class="ae ko" href="https://github.com/NVlabs/stylegan/blob/master/dataset_tool.py" rel="noopener ugc nofollow" target="_blank"> dataset_tool.py </a>将数据集转换为多分辨率TFRecords:</p><pre class="md me mf mg gt mt mu mv mw aw mx bi"><span id="4a35" class="my kq it mu b gy mz na l nb nc">&gt; python dataset_tool.py create_lsun datasets/lsun-bedroom-full ~/lsun/bedroom_lmdb --resolution 256<br/><br/>&gt; python dataset_tool.py create_lsun_wide datasets/lsun-car-512x384 ~/lsun/car_lmdb --width 512 --height 384<br/><br/>&gt; python dataset_tool.py create_lsun datasets/lsun-cat-full ~/lsun/cat_lmdb --resolution 256<br/><br/>&gt; python dataset_tool.py create_cifar10 datasets/cifar10 ~/cifar10<br/><br/>&gt; python dataset_tool.py create_from_images datasets/custom-dataset ~/custom-images</span></pre><h1 id="fe23" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">训练StyleGAN网络</h1><p id="5306" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">建立数据集后，您可以按如下方式训练自己的StyleGAN网络:</p><ol class=""><li id="87ca" class="lt lu it js b jt ju jx jy kb nd kf ne kj nf kn ng lz ma mb bi translated">编辑<a class="ae ko" href="https://github.com/NVlabs/stylegan/blob/master/train.py" rel="noopener ugc nofollow" target="_blank"> train.py </a>通过取消注释或编辑特定行来指定数据集和训练配置。</li><li id="f0de" class="lt lu it js b jt mo jx mp kb mq kf mr kj ms kn ng lz ma mb bi translated">使用python train.py运行训练脚本。</li><li id="0bdd" class="lt lu it js b jt mo jx mp kb mq kf mr kj ms kn ng lz ma mb bi translated">结果被写入一个新创建的目录results/ <id> - <description>。</description></id></li><li id="e33f" class="lt lu it js b jt mo jx mp kb mq kf mr kj ms kn ng lz ma mb bi translated">培训可能需要几天(或几周)才能完成，具体取决于配置。</li></ol><p id="4624" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">默认情况下，train.py配置为使用8个GPU<em class="ls">以1024×1024分辨率为FFHQ数据集训练最高质量的StyleGAN(表1中的配置F)。</em></p><h1 id="8ca4" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">预期StyleGAN培训时间</h1><p id="2afb" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">下面你会发现NVIDIA报告的train.py脚本(在stylegan存储库中可用)在Tesla V100 GPU上针对<a class="ae ko" href="https://github.com/NVlabs/ffhq-dataset" rel="noopener ugc nofollow" target="_blank"> FFHQ数据集</a>(在stylegan存储库中可用)的默认配置的预期训练时间。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/2136512b6d637150f7811c566fda5f4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/format:webp/0*nHF_TnD7L0eMbBOH.jpg"/></div></figure><p id="3484" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ko" href="https://www.chrisplaysgames.com/gadgets/2019/02/26/training-at-home-and-in-the-cloud/" rel="noopener ugc nofollow" target="_blank">斯泰勒根训练时间</a></p><h1 id="ca21" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">StyleGAN:将所有这些结合在一起</h1><p id="4a8a" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">这款令人惊叹的应用背后的算法是英伟达的<strong class="js iu"> Tero Karras、Samuli Laine和Timo Aila </strong>的创意，并将其命名为<strong class="js iu"> <em class="ls"> StyleGAN </em> </strong>。该算法是基于Ian Goodfellow及其同事对一般敌对网络(GAN)的早期研究。</p><p id="a014" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="ls">创成式模型有一个局限性，就是很难从照片上控制面部特征等特征。NVIDIA的StyleGAN是对这一限制的修复。该模型允许用户调整可以控制照片差异的超参数。</em>T9】</strong></p><p id="8a20" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">StyleGAN通过在每个卷积层向图像添加<em class="ls">样式</em>来解决照片的可变性。这些风格代表一个人的照片的不同特征，例如面部特征、背景颜色、头发、皱纹等。该模型生成两个图像A和B，然后通过从A中提取低级特征并从B中提取其余特征来组合它们。在每个级别，使用不同的特征(样式)来生成图像:</p><ul class=""><li id="92a7" class="lt lu it js b jt ju jx jy kb nd kf ne kj nf kn ly lz ma mb bi translated">粗略风格(分辨率在4到8之间)——<em class="ls">姿势、头发、脸、形状</em></li><li id="4ad0" class="lt lu it js b jt mo jx mp kb mq kf mr kj ms kn ly lz ma mb bi translated">中等风格(分辨率在16到32之间)——<em class="ls">五官、眼睛</em></li><li id="d3fc" class="lt lu it js b jt mo jx mp kb mq kf mr kj ms kn ly lz ma mb bi translated">精细样式(分辨率在64到1024之间)- <em class="ls">颜色方案</em></li></ul><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/d1a50dd762faabc802b70e28eabe5672.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/0*JN28Sotn70A0ZTW4.png"/></div></figure><p id="d423" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ko" href="https://earth-chronicles.com/science/nvidia-taught-artificial-intelligence-to-cross-peoples-photos.html" rel="noopener ugc nofollow" target="_blank">英伟达的神经网络</a></p><p id="71c9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你以前测试过StyleGAN吗？还是你第一次？请在下面的评论区告诉我们。对于任何技术或框架，我们总是从社区中寻找新的和创造性的方法。</p><h1 id="c2cb" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">GANs和StyleGAN的其他有用资源</h1><ul class=""><li id="e70c" class="lt lu it js b jt ln jx lo kb lv kf lw kj lx kn ly lz ma mb bi translated">关于StyleGAN和<a class="ae ko" href="https://github.com/NVlabs/stylegan" rel="noopener ugc nofollow" target="_blank"> Tensorflow实现的官方论文，请参见<a class="ae ko" href="https://arxiv.org/abs/1812.04948" rel="noopener ugc nofollow" target="_blank">这里的</a>。</a></li><li id="ee99" class="lt lu it js b jt mo jx mp kb mq kf mr kj ms kn ly lz ma mb bi translated">见<a class="ae ko" href="https://arxiv.org/abs/1912.04958" rel="noopener ugc nofollow" target="_blank">此处</a>为官方论文或StyleGAN2和提高StyleGAN的图像质量，以及<a class="ae ko" href="https://github.com/NVlabs/stylegan2" rel="noopener ugc nofollow" target="_blank"> Tensorflow实现。</a></li><li id="a224" class="lt lu it js b jt mo jx mp kb mq kf mr kj ms kn ly lz ma mb bi translated">阅读我们关于对抗性人工智能的好处的博客。</li></ul></div></div>    
</body>
</html>