<html>
<head>
<title>Do and don’t when using transformation to improve CNN deep learning model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用变换改进 CNN 深度学习模型时做什么和不做什么</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/improves-cnn-performance-by-applying-data-transformation-bf86b3f4cef4?source=collection_archive---------12-----------------------#2020-06-26">https://towardsdatascience.com/improves-cnn-performance-by-applying-data-transformation-bf86b3f4cef4?source=collection_archive---------12-----------------------#2020-06-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/4a220bf84e215e5507ce5ffdcb21a5fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Y7UNsUi7cz_MD-ba"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">迪伦·麦克劳德的图片</p></figure><div class=""/><div class=""><h2 id="2974" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">PyTorch 和 Torchvision 中的一个实验，用于在计算机视觉中诊断您的神经元网络性能</h2></div><h1 id="ba93" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">转换技术概述📋</h1><p id="c158" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">根据维基百科[1]</p><blockquote class="mm mn mo"><p id="5b9b" class="lq lr mp ls b lt mq kk lv lw mr kn ly ms mt mb mc mu mv mf mg mw mx mj mk ml im bi translated"><strong class="ls jk">数据转换</strong>是将数据从一种格式或结构转换成另一种格式或结构的过程。</p></blockquote><p id="cd8c" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi my translated"><span class="l mz na nb bm nc nd ne nf ng di">在</span>计算机视觉中，数据增强对于规范你的网络和增加你的训练集的规模非常重要。有许多<strong class="ls jk">数据转换技术</strong>(旋转、翻转、裁剪等……)可以改变图像的像素值，但仍然保留图像的几乎全部信息，因此人们很难分辨它是否被增强。这迫使模型在图像内的对象变化较大时更加灵活，较少考虑位置、方向、大小、颜色……通过数据扩充训练的模型通常概括得更好，但剩下的问题是<strong class="ls jk">数据转换</strong>可以在多大程度上提高 CNN 模型在图像数据集上的性能。</p><p id="fe36" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated">让我们来看看 Pytorch 在<a class="ae jg" href="https://pytorch.org/docs/stable/torchvision/transforms.html" rel="noopener ugc nofollow" target="_blank"> Torchvision </a>中支持的一些<strong class="ls jk">数据转换</strong>技术，可以帮助你对ơn 图像进行增强。我还提供了一个真实图像数据集的实验，以显示应用不同方法时的性能。</p><ul class=""><li id="0174" class="nh ni jj ls b lt mq lw mr lz nj md nk mh nl ml nm nn no np bi translated"><em class="mp">torch vision . transforms . center crop(size)</em>:类似于<strong class="ls jk">放大</strong>图像中心。它将给定的图像裁剪到所需的输出大小和位置(大小可以是正方形或长方形)。</li></ul><figure class="nr ns nt nu gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nq"><img src="../Images/bc249446ead8c7c3e953d5cd4e5a85ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VDWeLOQQANkAQY7_RSeEsA.png"/></div></div></figure><ul class=""><li id="7aa5" class="nh ni jj ls b lt mq lw mr lz nj md nk mh nl ml nm nn no np bi translated"><em class="mp">torch vision . transforms . pad(padding)</em>:相当于<strong class="ls jk">缩小</strong>图像。它将在给定图像的所有边上用某个值创建一个填充。</li></ul><figure class="nr ns nt nu gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nv"><img src="../Images/9ad6d6ad4749aecebb24c9f7dec65181.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ce2cc99edMP1SXJ9h0zExg.png"/></div></div></figure><ul class=""><li id="8735" class="nh ni jj ls b lt mq lw mr lz nj md nk mh nl ml nm nn no np bi translated">torch vision . transforms . random crop(size，padding):这个函数将在随机位置裁剪给定的图像，以创建一组用于训练的图像。</li></ul><figure class="nr ns nt nu gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nw"><img src="../Images/0e1da4d14b2f146d8dc80b9e5f6f5a5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z4Vu8D9FAFjsShAm7l8z_g.png"/></div></div></figure><ul class=""><li id="a723" class="nh ni jj ls b lt mq lw mr lz nj md nk mh nl ml nm nn no np bi translated"><em class="mp">torch vision . transforms . randomhorizontal flip(p)</em>:该函数将按照给定的概率随机水平翻转给定的图像。</li></ul><figure class="nr ns nt nu gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nx"><img src="../Images/e0eebdb16c894efd3f0de1b117805949.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BIgf0VRQqExyBkrNMOt0DA.png"/></div></div></figure><ul class=""><li id="4fc3" class="nh ni jj ls b lt mq lw mr lz nj md nk mh nl ml nm nn no np bi translated"><em class="mp">torch vision . transforms . randomverticalflip(p)</em>:这个函数会以给定的概率随机垂直翻转给定的图像。</li></ul><figure class="nr ns nt nu gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ny"><img src="../Images/2d907c62e97f4f6b52918f490bfd7f99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9_QeD2VkMzdWv8Ddedj65g.png"/></div></div></figure><ul class=""><li id="681f" class="nh ni jj ls b lt mq lw mr lz nj md nk mh nl ml nm nn no np bi translated"><em class="mp">torch vision . transforms . random perspective(distortion _ scale，p) </em>:该函数将对随机给定概率的给定图像进行透视变换。它通过扭曲整个图像来降低模型学习的透视效果。</li></ul><figure class="nr ns nt nu gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nz"><img src="../Images/e2fe215725e4c873ec967efd3ddb3668.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XdTUHbiwqJSkm5npFuYOwQ.png"/></div></div></figure><ul class=""><li id="bb61" class="nh ni jj ls b lt mq lw mr lz nj md nk mh nl ml nm nn no np bi translated"><em class="mp">torch vision . transforms . gray(num _ output _ channels)</em>:将图像转换为灰度。这有时有助于 CNN 模型使用单通道进行更快的训练，并且更容易地学习图像的模式。</li></ul><figure class="nr ns nt nu gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oa"><img src="../Images/bae713135197f8ca576ca3e28a1b6730.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tuHL1ZliF7X_wxYUA5Gg9A.png"/></div></div></figure><ul class=""><li id="3eeb" class="nh ni jj ls b lt mq lw mr lz nj md nk mh nl ml nm nn no np bi translated"><em class="mp">torch vision . transforms . color jitter(亮度、对比度、饱和度、色调):I </em>可以随机改变图像的亮度、对比度和饱和度</li></ul><figure class="nr ns nt nu gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ob"><img src="../Images/4012d80d110b7343da591f73b9e29658.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KcR56qTePXk17FCulS06lg.png"/></div></div></figure><ul class=""><li id="8ad5" class="nh ni jj ls b lt mq lw mr lz nj md nk mh nl ml nm nn no np bi translated"><em class="mp">torch vision . transforms . Normalize(mean，std): </em>用均值和标准差归一化张量图像。它将有助于 CNN 模型轻松转换到全局最小值或快速减少损失。如果你想知道为什么数据规范化是必不可少的，以及如何进行规范化以提高机器学习模型的性能，你可以参考下面的博客。</li></ul><div class="is it gp gr iu oc"><a rel="noopener follow" target="_blank" href="/push-the-accuracy-of-machine-learning-model-with-numerical-variable-transformation-in-pytorch-9f56c56203fd"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd jk gy z fp oh fr fs oi fu fw ji bi translated">用 Pytorch 中的数值变量转换提高机器学习模型的精度</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">这个故事提供了在 Pytorch 中实现转换技术和提高代码准确性的完整指南</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ol l"><div class="om l on oo op ol oq ja oc"/></div></div></a></div><figure class="nr ns nt nu gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi or"><img src="../Images/51155bcec3d065fded44654e76da7792.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nv-OFX23GVxTNINRpRzt_w.png"/></div></div></figure><ul class=""><li id="76ca" class="nh ni jj ls b lt mq lw mr lz nj md nk mh nl ml nm nn no np bi translated">torch vision . transforms . random erasing(p，scale，ratio，value)在图像中随机选择一个矩形区域并擦除其像素。该方法对 CNN 模型进行惩罚，有助于防止训练时的过拟合现象。</li></ul><figure class="nr ns nt nu gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi os"><img src="../Images/412456cf6907904c1188faac5b116e1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OnJg5hzNWsn1uh9kPYO7Bw.png"/></div></div></figure><p id="af59" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated">增强也可以应用于 NLP 以提高性能。例如:在句子中随意插入、调换、替换单词；在翻译中使用中间语言(反向翻译)，打乱句子。</p><p id="583a" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated">有几个库提供了优秀的增强模块，如白蛋白，NLPAug...下面是一篇来自 neptune.ai 的很棒的进一步探索的文章。</p><div class="is it gp gr iu oc"><a href="https://neptune.ai/blog/data-augmentation-nlp" rel="noopener  ugc nofollow" target="_blank"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd jk gy z fp oh fr fs oi fu fw ji bi translated">NLP 中的数据扩充:来自 Kaggle Master 的最佳实践</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">在自然语言处理中有许多任务，从文本分类到问题回答，但是无论你做什么，数据的数量…</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">海王星. ai</p></div></div><div class="ol l"><div class="ot l on oo op ol oq ja oc"/></div></div></a></div></div><div class="ab cl ou ov hx ow" role="separator"><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz"/></div><div class="im in io ip iq"><h1 id="fc77" class="ky kz jj bd la lb pb ld le lf pc lh li kp pd kq lk ks pe kt lm kv pf kw lo lp bi translated">在 CNN 模型上评估转换技术📄</h1><p id="8c73" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">让我们讨论变换技术对 CNN 模型的影响。本实验中使用的数据集是来自<a class="ae jg" href="https://www.kaggle.com/c/dog-breed-identification/overview" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>竞赛的<strong class="ls jk">犬种识别</strong>，该竞赛提供了<a class="ae jg" href="https://www.kaggle.com/c/imagenet-object-detection-challenge" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>的严格犬子集，以便练习细粒度的图像分类。该数据集包括 120 个品种的狗，总共有 10，222 张图像。我们以 0.8/0.2 的比率将数据分割为训练/有效。</p><p id="a0b4" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated">在本文中，预训练的 ResNet [2](残差网络)模型将被用作分类 CNN 模型的主干。ResNet 是 SOTA 预训练模型之一，在广泛的计算机视觉任务中显示出良好的结果。ResNet 的主要思想不是用函数 H(x)(多层感知器网络的堆叠)直接学习图像的输入特征，而是提供一个残差函数，它可以重构 H(x) = F(x)+x，其中 F(x)和 x 分别表示堆叠的非线性层和恒等函数(输入=输出)。这种思想可以解决深层神经元网络(消失梯度)的退化问题，因为它比原始映射函数更容易优化残差映射函数 F(x)。</p><figure class="nr ns nt nu gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pg"><img src="../Images/ac2291147f3776f6622769e9aaaee1f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h5fhGhyg9R_LLgltgLU4mA.png"/></div></div></figure><p id="5c57" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated">首先，我们将加载原始数据。</p><pre class="nr ns nt nu gt ph pi pj pk aw pl bi"><span id="29ac" class="pm kz jj pi b gy pn po l pp pq"># Create a custom Dataset class to read in data from dataframe<br/>class BreedDogDataset(Dataset):<br/>    def __init__(self, dataframe, root_dir, transform=None):<br/>        self.dataframe = dataframe<br/>        self.root_dir = root_dir<br/>        self.transform = transform<br/>        <br/>    def __len__(self):<br/>        return (len(self.dataframe))<br/>    <br/>    def __getitem__(self, idx):<br/>        img_name = os.path.join(self.root_dir,<br/>                  self.dataframe.iloc[idx, 0])<br/>        image = Image.open(img_name)<br/>        target = self.dataframe.iloc[idx, 1]<br/>        target_processed = breeds_processed_dict[target]<br/>        if self.transform:<br/>            image = self.transform(image)<br/>        sample = (image, target_processed)<br/>        return sample</span><span id="a83f" class="pm kz jj pi b gy pr po l pp pq">transform = transforms.Compose([transforms.Resize((255, 255)),<br/>                                transforms.ToTensor()])</span><span id="582b" class="pm kz jj pi b gy pr po l pp pq">train_ds = BreedDogDataset(df_train,TRAIN_DIR, transform=transform)<br/>val_ds = BreedDogDataset(df_val,TRAIN_DIR, transform=transform)</span></pre><figure class="nr ns nt nu gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ps"><img src="../Images/9835c665ac55dfe3a3490422ac802c2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rZYcONa3Jg-4WMc5Fh5d5A.png"/></div></div></figure><p id="9405" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated">然后我们创建一个这样的结构模型:</p><pre class="nr ns nt nu gt ph pi pj pk aw pl bi"><span id="856c" class="pm kz jj pi b gy pn po l pp pq"># load pre-trained model<br/>conv_base = models.resnet50(pretrained=True)</span><span id="9ebe" class="pm kz jj pi b gy pr po l pp pq"># create a new model class<br/>class Model(nn.Module):<br/>    def __init__(self, base_model, output):<br/>        super(Model, self).__init__()<br/>        self.base_model = base_model<br/>        self.output = output<br/>        self.fc1 = nn.Linear(n_outs, 512)<br/>        self.fc2 = nn.Linear(512, output)<br/>        self.dropout = nn.Dropout(0.5)<br/>    <br/>    def forward(self, image):<br/>        x = self.base_model(image)<br/>        x = self.dropout(x)<br/>        x = F.relu(self.fc1(x))<br/>        x = self.dropout(x)<br/>        outs = self.fc2(x)<br/>        return outs</span></pre><p id="b188" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated">在深度学习模型中要调整的最重要的超参数之一是学习速率。选择正确的学习率非常重要，如果学习率太高，模型将面临发散问题，但如果学习率太低，模型将需要很长时间才能收敛。这个想法是，我们可以通过数百次迭代训练模型来找到一个好的学习率，然后基于学习曲线，我们获得一个好的学习率。学习率调度技术有很多，例如，功率调度、指数调度、1 周期调度、常数调度……在这个实验中，我们将应用<strong class="ls jk">1 周期调度</strong>。在 Leslie Smith 的<a class="ae jg" href="https://arxiv.org/abs/1803.09820?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">论文</a>中，这项技术被证明可以显著提高训练时间。你可以看看这个博客了解更多的解释。</p><div class="is it gp gr iu oc"><a rel="noopener follow" target="_blank" href="/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd jk gy z fp oh fr fs oi fu fw ji bi translated">找到好的学习率和一个周期的政策。</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">介绍</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ol l"><div class="pt l on oo op ol oq ja oc"/></div></div></a></div><figure class="nr ns nt nu gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pu"><img src="../Images/5490b9d8e253af29f5948edb895a9b20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o5wAMQz-mpk37itPUiUPYA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">模型的学习曲线</p></figure><p id="de85" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated">根据上面的学习曲线结果，它显示下限是 0.9E-04，I 取整值为 1.0E-03。现在，我可以通过使用经验法则定义学习速率的范围来微调新图像数据集上的预训练 ResNet50:从比损失最小的学习速率低一个数量级的速率开始，到“安全”速率 1E-03 结束。</p><p id="4ab8" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated">经过 5 个历元的训练，有效集的正确率为 83.284 %</p><figure class="nr ns nt nu gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pv"><img src="../Images/3bd90b64bab122023f5b4e996d702ac6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*QGKzSnzec3iE5vAewcNNGA.png"/></div></div></figure><p id="4171" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated">列车损失和有效损失如下所示。可以看到两个值都降低了。从第 4 代到第 5 代，损失和准确性几乎是恒定的。这意味着模型已经从数据中学习了相对的一切，所有帮助模型区分品种狗的好信息都被捕捉到了。</p><figure class="nr ns nt nu gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pw"><img src="../Images/fb784076bcdd6e30752b21fa6fcbb3a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RC_UbqIKOzpReDc3NhuTMg.png"/></div></div></figure><p id="090d" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated">然后，我们检查前 6 个损失最高的图像。我们可以看到，模型对一些图像进行错误分类的原因之一是，狗的品种预测与其他不同品种的样本相似，这甚至是人类无法区分它们。为了解决这个问题，转换技术非常有希望帮助模型深入学习每个品种的模式。另一个问题是，一些图片有 2 只不同的狗，但标签上只显示一只。错误的标签也是另一个问题。这些问题无法解决，这似乎是一个异常情况。</p><figure class="nr ns nt nu gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi px"><img src="../Images/0edd19dd269f1821f088afd75bf7a406.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o5Y8vmwO_w2gflu6mNoL5w.png"/></div></div></figure><p id="98c5" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated">让我们在这个数据集中应用一些转换技术。</p><pre class="nr ns nt nu gt ph pi pj pk aw pl bi"><span id="fb89" class="pm kz jj pi b gy pn po l pp pq">mean = [0.4766, 0.4527, 0.3926]<br/>std = [0.2275, 0.2224, 0.2210]</span><span id="1c65" class="pm kz jj pi b gy pr po l pp pq"># define transform function<br/>transforms_train = transforms.Compose([<br/>    <!-- -->transforms.Pad<!-- -->(25, padding_mode='symmetric'),<br/>    transforms.RandomHorizontalFlip(), <br/>    transforms.RandomRotation(10),<br/>    transforms.ToTensor(),<br/>    transforms.Normalize(mean, std),<br/>    transforms.RandomErasing(p=0.75,scale=(0.02, 0.1),value=1.0, inplace=False)<br/>])</span><span id="7b57" class="pm kz jj pi b gy pr po l pp pq">transforms_val = transforms.Compose([<br/>    transforms.Resize((255, 255)),<br/>    transforms.ToTensor(),<br/>    transforms.Normalize(mean, std)<br/>])<br/><br/># load in the temporary dataset from the original dataframe with transform<br/>train_ds = BreedDogDataset(df_train,TRAIN_DIR, transform=transforms_train)</span><span id="1e31" class="pm kz jj pi b gy pr po l pp pq">val_ds = BreedDogDataset(df_val,TRAIN_DIR, transform=transforms_val)</span></pre><figure class="nr ns nt nu gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi py"><img src="../Images/85006342f019808c98eb080ff4d7014d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bNUoESASvZXrXSwoe7QaPQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">转换后的训练数据集</p></figure><figure class="nr ns nt nu gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pz"><img src="../Images/6364748ff99044f9e36fc74c6dce6d7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LdGCf2OMOws0_qkj2OKRvg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">转换后的有效数据集</p></figure><p id="d068" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated">在变换后的数据集上用 5 个历元进行训练后，我们得到有效集的准确率达到 0.817，与原始图像相比略有下降。</p><figure class="nr ns nt nu gt iv gh gi paragraph-image"><div class="gh gi qa"><img src="../Images/0f5deebc01f395b0d203e58093b423fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*umd1LdB4ZIfG02XXtjYzYw.png"/></div></figure><p id="9add" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated">新的列车损失和有效损失如下所示。与上述模型相比，列车损失和有效损失之间的距离增加，而第 4 和第 5 个时期的精度略有下降。这表明新模型面临着不匹配的问题。通常，转换确实有助于模型防止过度拟合问题。然而，在这种情况下，因为先前的模型没有过拟合问题，并且训练损失甚至高于有效损失，所以当应用变换时，没有改善。</p><figure class="nr ns nt nu gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qb"><img src="../Images/bab357da6f80f8e6c87026ba7547906b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pvl2Jpbn_sIn8fxUOYavfg.png"/></div></div></figure><p id="63c2" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated">让我们看看损失最大的前 6 张图片。我们可以看到一些混乱的图像现在可以被分类，但有些还没有。然而，这个问题无法解决，一些异常值仍然会影响模型的性能。</p><figure class="nr ns nt nu gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qc"><img src="../Images/7d57d6b3afce7f5aeb407fc5fed7acc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uEAw2BXwoEWkPtUDa5yiog.png"/></div></div></figure><h1 id="c3fc" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">最后的想法📕</h1><p id="a9b6" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">这个博客的主要目的是介绍一些转换图像的技术。从根本上说，这将有助于避免过拟合问题，以及增加 CNN 模型的训练数据的数量。但这并不意味着变换总是会提高模型的精度，它必须依赖于输入图像(卫星、细菌、动物、物体、..)和模型结构。许多 Deep-ML 实践者遇到了这个问题，他们通常在检查他们的模型可以从他们的原始图像学习到什么程度之前进行转换。如果模型不符合原始图像，转换数据无助于解决问题，换句话说，它会降低模型的准确性。因此，我们必须一步一步地诊断我们的模型，并通过最坏的预测来分析可视化的结果。</p><p id="e296" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated">如果你想进一步讨论，可以联系我。这是我的 LinkedIn</p><p id="fc0e" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated">尽情享受吧！！！👦🏻</p><h1 id="25f0" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">参考</h1><p id="f167" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">[1]https://en.wikipedia.org/wiki/Data_transformation</p><p id="2d73" class="pw-post-body-paragraph lq lr jj ls b lt mq kk lv lw mr kn ly lz mt mb mc md mv mf mg mh mx mj mk ml im bi translated">[2] <a class="ae jg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+K" rel="noopener ugc nofollow" target="_blank">何</a>、<a class="ae jg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X" rel="noopener ugc nofollow" target="_blank">、</a>、【邵青任、<a class="ae jg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+J" rel="noopener ugc nofollow" target="_blank">、</a>，深度残差学习用于图像识别，2015。</p></div></div>    
</body>
</html>