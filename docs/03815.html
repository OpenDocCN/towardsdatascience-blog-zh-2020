<html>
<head>
<title>Understanding ResNet and its Variants</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解ResNet及其变体</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-resnet-and-its-variants-719e5b8d2298?source=collection_archive---------36-----------------------#2020-04-09">https://towardsdatascience.com/understanding-resnet-and-its-variants-719e5b8d2298?source=collection_archive---------36-----------------------#2020-04-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f8b6" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">计算机视觉/深度学习社区中最具突破性的工作概述— ResNets</h2></div><p id="deab" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">自从高计算单元的可用性以来，机器学习社区已经见证了向深度学习实践的范式转变，以实现更好的结果，特别是在计算机视觉领域。一种有前途的方法是卷积神经网络。CNN是传统神经网络的改进版本，它保持了空间维度的完整性。</p><p id="6b31" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在图像分类、目标检测等方面，CNN已经超越了其他各种框架。因此是研究人员非常感兴趣的。为了使这种学习越来越准确，研究人员已经开始实现越来越深的卷积网络。</p><p id="021b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为训练选择正确的层数的话题已经讨论了很长时间，事实证明，建立一个更深的网络不会提高精度，反而会降低精度。是的，你没听错，当你在网络中堆积越来越多的单元时，网络的学习能力就饱和了，过了一个阈值，它就下降了。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi le"><img src="../Images/d38c73a02dad130de6b1f3f97640890e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*BwyYzWBlaLd22OaaXAF5AA.png"/></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">src: <a class="ae lq" href="https://arxiv.org/pdf/1512.03385.pdf" rel="noopener ugc nofollow" target="_blank">用于图像识别的深度残差学习</a>，测试和训练“普通”网络的错误</p></figure><p id="8056" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这种网络的精度下降而不是上升的两个基本原因是:</p><ol class=""><li id="ebc5" class="lr ls it kk b kl km ko kp kr lt kv lu kz lv ld lw lx ly lz bi translated">消失/爆炸渐变</li><li id="ffd3" class="lr ls it kk b kl ma ko mb kr mc kv md kz me ld lw lx ly lz bi translated">退化问题</li></ol><p id="668b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，第一个问题由标准化初始化和中间标准化层解决，这使得具有数十层的网络能够开始收敛于具有反向传播的随机梯度下降(SGD)。</p><p id="9c7e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但是当更深层次的网络开始融合时，他们观察到了退化问题。随着网络深度的增加，精度达到饱和，然后迅速下降。有助于消除这种退化问题的一种方法是添加带有身份映射的附加层。</p><p id="2bad" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> ResNet </strong> [1]介绍了这些跳过一层或多层的<strong class="kk iu">【身份映射】</strong>或<strong class="kk iu">【跳过连接】</strong>，如图所示:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/19f1206ef8cc97e5a7264a2ebbec66d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*NaydVEFR5aM8hh_Ry1FJcw.png"/></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">src: <a class="ae lq" href="https://arxiv.org/pdf/1512.03385.pdf" rel="noopener ugc nofollow" target="_blank">用于图像识别的深度残差学习</a>，具有身份映射的残差块</p></figure><p id="76c1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个想法是，我们不只是将额外的层堆叠到网络中，而是将它们添加为剩余块(具有身份映射)。为了实现该方案中的结果，该工作的作者调整了底层映射，并使非线性层学习该映射:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/da3d499a5034c4be30ad99afebdbc887.png" data-original-src="https://miro.medium.com/v2/resize:fit:406/format:webp/1*nvPrWs70SEtY-Fi6wnd2DA.png"/></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">src: <a class="ae lq" href="https://arxiv.org/pdf/1512.03385.pdf" rel="noopener ugc nofollow" target="_blank">用于图像识别的深度残差学习</a></p></figure><p id="4984" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">代替传统的映射H(x ),并且原始映射被重铸为:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/44313ec7c34b87f8ff9230caf1feb1cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:202/format:webp/1*pc2rPhswP3qCiITJIiypuQ.png"/></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">src: <a class="ae lq" href="https://arxiv.org/pdf/1512.03385.pdf" rel="noopener ugc nofollow" target="_blank">用于图像识别的深度残差学习</a></p></figure><p id="8f5b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">引入这些快捷连接的另一个好处是，它们不会添加任何额外的参数，也不会增加计算复杂度，因为它们被用作身份映射。然而，它们确保了较深的网络和较浅的网络表现一样好。</p><p id="8919" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最初提议的ResNet结构如下:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mi"><img src="../Images/e3986aa380be17d88e0768c55dd85606.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lFnm5i-oYWIs3WW4pxg47Q.png"/></div></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">src: <a class="ae lq" href="https://arxiv.org/pdf/1512.03385.pdf" rel="noopener ugc nofollow" target="_blank">用于图像识别的深度残差学习</a>，最初提出ResNet</p></figure><p id="138d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里需要注意的一点是那些虚线，表示线性投影。理想情况下，为了执行身份映射，F(x)和X的维数必须相同，但是当情况不是这样时，我们使用投影向量Ws来帮助匹配维数。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mn"><img src="../Images/f0781a6c5853110168d72ad7f033ce97.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/1*OjWBnE_QqNw77CpfAMQpVg.png"/></div></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">src: <a class="ae lq" href="https://arxiv.org/pdf/1512.03385.pdf" rel="noopener ugc nofollow" target="_blank">用于图像识别的深度残差学习</a></p></figure><p id="efea" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">另一项研究旨在确定何时应该引入这些“跳过连接”!</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mo"><img src="../Images/8387796e00a4760f0e867ecd767eaaba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HSBsh3KM_l9enDJemfRatw.png"/></div></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">src: <a class="ae lq" href="https://arxiv.org/pdf/1603.05027.pdf" rel="noopener ugc nofollow" target="_blank">深度剩余网络中的身份映射</a>，各种风格的ResNet块</p></figure><p id="cc1b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在得到具有完全预激活的剩余块的最终版本，即上图中的(e)之前，测试和尝试了每种可能的组合。</p><p id="c8df" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于其引人注目的结果，ResNet很快成为各种计算机视觉任务中最受欢迎的架构之一。</p></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="db47" class="mw mx it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated"><strong class="ak">resnet的流行变种</strong></h1><p id="22c4" class="pw-post-body-paragraph ki kj it kk b kl no ju kn ko np jx kq kr nq kt ku kv nr kx ky kz ns lb lc ld im bi translated">随着ResNets越来越受欢迎，人们对其架构进行了大量研究，研究人员提出了最初提出的工作的不同变体。</p><h2 id="f243" class="nt mx it bd my nu nv dn nc nw nx dp ng kr ny nz ni kv oa ob nk kz oc od nm oe bi translated">ResNeXt</h2><p id="073e" class="pw-post-body-paragraph ki kj it kk b kl no ju kn ko np jx kq kr nq kt ku kv nr kx ky kz ns lb lc ld im bi translated">在原始工作的基础上，提出了一个名为<strong class="kk iu">ResNeXt</strong>【2】的替代方案，其构建模块如下:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi of"><img src="../Images/52a05d4e11c7a83e1a39067e02ad56cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*Xbr3QLvoqQICmAzsM8SFYw.png"/></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">src: <a class="ae lq" href="https://arxiv.org/pdf/1611.05431.pdf" rel="noopener ugc nofollow" target="_blank">深度神经网络的聚合残差变换</a></p></figure><p id="8e77" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该模型采用了重复层的重组策略，同时以一种简单、可扩展的方式结合了拆分-转换-合并策略。该块可能看起来类似于Inception network [3]，其中我们执行各种不同的转换(1x1 Conv、3x3 Conv、5x5 Conv、MaxPooling)并将它们堆叠在一起，而这里我们通过将它们相加来合并不同的转换。</p><p id="dfa8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这种类型的块引入了另一个维度<strong class="kk iu">基数</strong>——独立路径的数量，以及现有的高度和深度维度。该维度的重要性已被其作者通过实验证明，“增加基数是比更深或更宽更有效的获得准确性的方式”，尤其是当深度和宽度开始给现有模型带来收益递减时。</p><p id="b6ce" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">提议的构件有三种可能的变化:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi og"><img src="../Images/bf81efb146c22c95140635fe1078feb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e-E9Exz2mewmYKdnHf8axA.png"/></div></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">src: <a class="ae lq" href="https://arxiv.org/pdf/1611.05431.pdf" rel="noopener ugc nofollow" target="_blank">深度神经网络的聚合残差变换</a>，ResNeXt的等效块</p></figure><p id="6505" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">作者还指出，该模型比不同数据集上的Inception [3]网络更容易训练，因为它只有一个超参数要调整，而不像Inception中有更多的超参数要调整。</p><h2 id="cb6c" class="nt mx it bd my nu nv dn nc nw nx dp ng kr ny nz ni kv oa ob nk kz oc od nm oe bi translated">DenseNet</h2><p id="9790" class="pw-post-body-paragraph ki kj it kk b kl no ju kn ko np jx kq kr nq kt ku kv nr kx ky kz ns lb lc ld im bi translated">ResNet的另一个流行变体是<strong class="kk iu">dense net</strong>【4】，作者试图通过建立额外的连接来解决渐变消失的问题。在DenseNet中，它们通过将所有层直接相互连接来确保网络中各层之间的最大信息流。为了保持前馈性质，每一层从所有前面的层获得额外的输入，并将它自己的特征映射传递给所有后面的层。该模型如下所示:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi oh"><img src="../Images/8add5357e5dc2c2efc9b0151a7244989.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2MDMWFm9v-8werzhdn3cQA.png"/></div></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">src: <a class="ae lq" href="https://arxiv.org/pdf/1608.06993.pdf" rel="noopener ugc nofollow" target="_blank">密集连接的卷积网络</a>，相互连接的DenseNet层</p></figure><p id="ffd2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">除了处理消失梯度，作者还认为，这种实现方式可以实现要素重用，使网络具有很高的参数效率。在传统模型中，每一层都充当一个状态，它从前一个状态读取数据，并写入下一层。它改变了状态，但也传递了需要保存的信息。</p><p id="b3d4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">DenseNet架构明确区分添加到网络中的信息和保留的信息，最终分类器基于网络中的所有特征图做出决定。除了更好的参数效率，DenseNet还通过网络提供了改进的信息流和梯度，这使其易于训练。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi oi"><img src="../Images/9ff23a8ff5e1204f452d3e741d309ba7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x3Feq_pw2i5S_kyD5Qq1Ng.png"/></div></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">src: <a class="ae lq" href="https://arxiv.org/pdf/1608.06993.pdf" rel="noopener ugc nofollow" target="_blank">密集连接卷积网络</a>，三个密集块的深度DenseNet。</p></figure><p id="c476" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第<em class="oj"> l </em>层接收来自其所有先前层的特征图作为输入:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/7af3dba7253e875b666b5f6d86d2aac8.png" data-original-src="https://miro.medium.com/v2/resize:fit:702/format:webp/1*XnqXc9onRrXuZxxVgfvHxA.png"/></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">src: <a class="ae lq" href="https://arxiv.org/pdf/1608.06993.pdf" rel="noopener ugc nofollow" target="_blank">密集连接的卷积网络</a></p></figure><p id="34ff" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中[..]表示连接操作。为了便于在网络中进行缩减采样，它被划分为多个部分，如上所示，中间有过渡图层。过渡层由批量标准化层、卷积层和最大池层组成。</p><p id="fb6a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于其紧凑的内部表示和减少的特征冗余，DenseNets可能是基于卷积特征的各种计算机视觉任务的良好特征提取器。</p><p id="6034" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我希望它能帮助读者加深对这部开创性作品的理解。</p><p id="daef" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇文章的所有图表都取自参考文献中的原文。</p><h1 id="8e72" class="mw mx it bd my mz ol nb nc nd om nf ng jz on ka ni kc oo kd nk kf op kg nm nn bi translated">参考资料:</h1><p id="bdf3" class="pw-post-body-paragraph ki kj it kk b kl no ju kn ko np jx kq kr nq kt ku kv nr kx ky kz ns lb lc ld im bi translated">[1].贺国强，张晓霞，任世荣，孙军。用于图像识别的深度残差学习。arXiv预印本arXiv:1512.03385，2015。</p><p id="9c74" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[2].谢，吉希克，杜鹏，涂振宇和何国光。深度神经网络的聚合残差变换。arXiv预印本arXiv:1611.05431v1，2016。</p><p id="e618" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[3].塞格迪、刘华清、贾庆林、塞尔马内、里德、安盖洛夫、埃汉、万霍克和拉宾诺维奇。用回旋越走越深。IEEE计算机视觉和模式识别会议论文集，第1–9页，2015。</p><p id="8556" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[4].黄，刘，温伯格，马腾。密集连接的卷积网络。arXiv:1608.06993v3，2016。</p></div></div>    
</body>
</html>