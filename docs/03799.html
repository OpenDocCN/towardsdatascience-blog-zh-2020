<html>
<head>
<title>Beginners’ Guide to Image Classification: VGG-19, Resnet 50 and InceptionResnet with TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">图像分类初学者指南:VGG-19、Resnet 50和带TensorFlow的InceptionResnet</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/beginners-guide-on-image-classification-vgg-19-resnet-50-and-inceptionresnetv2-with-tensorflow-4909c6478941?source=collection_archive---------20-----------------------#2020-04-09">https://towardsdatascience.com/beginners-guide-on-image-classification-vgg-19-resnet-50-and-inceptionresnetv2-with-tensorflow-4909c6478941?source=collection_archive---------20-----------------------#2020-04-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="516d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">本文用迁移学习示例说明了一个图像分类任务，对120个狗品种的20，000多张照片进行了分类。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/ec3466ef65ff6566d8fff032723917a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7tfy8hMI_3YelJOD2dFOEA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">柯基和它的朋友。信用:<a class="ae kv" href="https://unsplash.com/@alvannee" rel="noopener ugc nofollow" target="_blank">阿尔万需要</a></p></figure><p id="0d5d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我还记得我第一次听说深度学习以及听到这个术语时的激动，认为它是一个神秘的黑盒子和全能的模型。</p><p id="99b4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于初学者来说，图像分类是一项简单而又有意义的任务，可以帮助他们了解深度学习，并习惯它的符号和概念。在这个项目中，我选择使用迁移学习，这是深度学习领域中最简单的方法。</p><p id="425f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个项目使用的代码可以在我的<a class="ae kv" href="https://github.com/ZeeTsing/Dogs_breed_classification" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>中找到。</p><p id="875f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">#数据</strong></p><p id="5d70" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本项目使用的数据可在<a class="ae kv" href="https://www.kaggle.com/jessicali9530/stanford-dogs-dataset" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>获得，也可在<a class="ae kv" href="http://vision.stanford.edu/aditya86/ImageNetDogs/main.html" rel="noopener ugc nofollow" target="_blank">斯坦福</a>找到。你可以在提供的第二个链接中找到它的原始论文和基线结果。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ls"><img src="../Images/ad5b6da6284e8025854aca3fb70680d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mEyiBu9EtLTKwgEe4cMleA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">所有120个品种的标签分布</p></figure><p id="547e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该数据集由120种狗的20多万张照片组成。我们的目标类别是什么？它们在120个品种中分布均匀吗？左图显示，类别相当平衡，一些类别的图片略多，而大多数类别至少有150张照片。</p><p id="e6e6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们还想看看数据集中的一些随机照片。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lt"><img src="../Images/90a654c6880fae9f1ee4a390ac0edfee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IEIQejZER_9MMSgtiwxKaw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">从数据集中随机选取狗的照片及其品种</p></figure><p id="5309" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们观察到，尽管品种不同，有些狗有相似的特征。例如，第一排的梗看起来和我很像。我想知道这对于计算机来说是不是太难了。</p><p id="b548" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">#数据预处理</strong></p><p id="ccff" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于图像处理主题来说，数据预处理是一个很深的主题，但我们在这里不会深入探讨。该项目使用迁移学习模型的标准预处理，结合一些数据扩充，如旋转、水平翻转、放大等。</p><p id="5a05" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">#转移学习</strong></p><p id="4a20" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在深入研究项目所用的模型之前，我们想先谈谈迁移学习。简单地说，迁移学习就是利用他人预先训练好的模型来完成你的任务，它可以是不同的任务，但应该是相关的。文献已经证明，深度学习模型在一定程度上是可以移植的。</p><p id="5d5f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我探索了两种迁移学习的方法:简单地使用预训练的模型作为特征提取或重新训练(微调)模型的一部分。你们中的一些人可能会接触到第一种方法而没有意识到。比如在NLP任务中用Word2Vec做编码器，其实就是用迁移学习做特征提取的一种方式。通过保持模型的原始重量，可以容易且直接地应用它。相反，微调方法需要一些试错实验。如果任务非常不同，您可以考虑对模型进行至少50%或更多的微调。如果您的任务非常相似，比方说最初模型用于对汽车进行分类，现在您希望对卡车进行分类，您可以考虑微调最后几层或原始模型的30%。所需的微调量需要花费时间和精力，这取决于任务的性质。</p><p id="0c7c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于计算机视觉任务，有许多已建立的模型，对于这个项目，我们用我们的例子回顾了其中的三个。</p><ul class=""><li id="e31e" class="lu lv iq ky b kz la lc ld lf lw lj lx ln ly lr lz ma mb mc bi translated"><strong class="ky ir"> VGG-19 </strong></li></ul><p id="50bc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">VGG-19是我们探索的第一个型号，也是我们审查的型号中最老的一个。VGG-19是VGG-16的改进型。它是一个19层的卷积神经网络模型。它是通过将卷积堆叠在一起而构建的，但是由于一个称为梯度递减的问题，该模型的深度受到限制。这个问题使得深度卷积网络难以训练。该模型在ImageNet上进行训练，用于对1000种类型的对象进行分类，其余被审查的模型也是如此。</p><p id="f5bd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们探索了VGG-19的特征提取和微调。我们得到的最好结果是简单地使用VGG-19作为特征提取。在我们情况下，微调和重新训练对VGG-19并不奏效。</p><ul class=""><li id="fd96" class="lu lv iq ky b kz la lc ld lf lw lj lx ln ly lr lz ma mb mc bi translated"><strong class="ky ir"> Resnet50 </strong></li></ul><p id="c383" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Resnet模型是为解决梯度递减问题而提出的。其思想是跳过连接，将残差传递给下一层，这样模型就可以继续训练。有了Resnet模型，CNN模型可以越来越深入。</p><p id="c8cc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Resnet模型有许多变体，我们在这里选择Resnet50是因为它在Kaggle的教程中使用过，并且为我们所熟悉。通过Resnet 50获得的最佳结果是重新训练所有参数的近40%。</p><ul class=""><li id="ba96" class="lu lv iq ky b kz la lc ld lf lw lj lx ln ly lr lz ma mb mc bi translated"><strong class="ky ir"> InceptionResnetV2 </strong></li></ul><p id="2d74" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">InceptionResnet是对Resnet的进一步改进，结合了称为Inception的技术。<a class="ae kv" href="https://ai.googleblog.com/2016/08/improving-inception-and-image.html" rel="noopener ugc nofollow" target="_blank">点击此处</a>阅读更多关于该车型的信息。</p><p id="f5ef" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我还做了一个简单的例子来比较这三种不同的架构。彩色块代表模型的层。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi md"><img src="../Images/5211fd7d31d63479128501a8664f08f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*94BcB6Sshmy03-vjD6hV7Q.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">视觉模型比较</p></figure><p id="4a73" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">人们会注意到，在这三个模型中，我们对其中的两个进行了微调和重新培训。当我们试图重新训练30%的模型时，VGG-19表现很差。原因可能是VGG-19作为深度学习网络相对“肤浅”。用少量数据输入一次重新训练太多参数会损害模型性能，因为模型没有足够的输入来学习。</p><p id="4f9b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">#结果和讨论</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi me"><img src="../Images/c05f8dc5754c7f76ecae0d38074ee293.png" data-original-src="https://miro.medium.com/v2/resize:fit:1178/format:webp/1*QXpkXc68Zf1D0safIr-7jg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">我们的最佳模型实现的性能—验证数据</p></figure><p id="e5f6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作为一个基准，你可以在这里阅读关于预训练的模特表演<a class="ae kv" href="https://github.com/tensorflow/models/tree/master/research/slim" rel="noopener ugc nofollow" target="_blank">。左边的表格显示了我们的模型在看不见的数据上实现的性能。我们可以看到，模型可以保留基准性能。对于那些我们已经重新训练和微调的，它比基线表现得更好，这并不奇怪，因为我们的任务在本质上比原来的任务更简单(类别更少)。</a></p><p id="3f0c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我还想分享一些训练模型时的诊断图。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/d22a268be81d8b6732f0609f26e3b249.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*SDUJBIlkFjDAz8RixEfEYQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Resnet损失50</p></figure><p id="e4ab" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">显示的损耗图来自Resnet50型号。我们观察到，在这里验证损失总是低于训练损失。它显示出惊人的概括预测的能力，这是迁移学习模型中一个非常独特的现象。这是由于模型中预先存储的知识。然而，这也表明该模型不能提高列车组的性能，因此很难进一步调整该模型。这是我开始考虑新模型而不是坚持Resnet50架构的地方。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/940aab5c800e67e250df738702852efc.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*piD5xcGY1jsm0U7YcQJ0yQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来自InceptionResnetV2的损失</p></figure><p id="8ba3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">显示的第二个损失图使用来自我们的InceptionResnet模型的数据，在20个时期后进行训练。与培训损失相比，验证损失开始时较低。这是与上面的模型类似的行为。这里的验证损失相对稳定，培训损失继续下降。这表明我们在训练集中的改进倾向于过度拟合，不能推广到看不见的数据。为了进一步改进，我们可以探索在模型上添加更多的正则化。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/3b772e41c562dfd8ed762e8c792a9e51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1358/format:webp/1*4pLSAdiP125vWmS7jIUJKQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">真相:真实的品种；我的模型给出的三个预测</p></figure><p id="cac5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们来看看预测。我们的模型在第一次猜测时基本上是正确的，如果我们考虑前2个预测，它实际上是所有正确的分类。考虑到任务的难度，我认为这是相当不错的表现。</p><p id="d96c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，当我们深入研究该模型造成的更多错误时，仍然有很大的改进空间，我们希望迅速讨论进一步改进的方法。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/22d7b8b8b9d8ad9674830956f9ea1f79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/1*IF7t9ux75AbfhgoLUIW0qQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">真相:真实的品种；我的模型给出的三个预测</p></figure><p id="889d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作为分类模型，我们的模型缺乏辨别狗的大小的能力，例如，它是小型、中型还是大型狗。这是非常重要的，当试图了解狗的品种，因为有许多狗有相似的面部特征和体型，但只有大小不同。下图显示模型很难区分梗类。为了使我们的模型学习对象大小，人们可能想要实现对象识别模型，而不是简单的分类。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/d804e94d49962e729063eeda21f6ad71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/0*vziiJIzw-128ZAqt.jpg"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">蓝黑还是白金？</p></figure><p id="e1a7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最重要的是，该模型在正确识别颜色方面也存在问题。这就像一件蓝黑色的衣服在不同的环境光照下改变颜色的经典例子(如下所示)。因此，我们可能要考虑在预处理步骤中增加颜色失真增强，例如，随机化亮度、对比度、饱和度等。</p><p id="ecbf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，我们还观察到，模型与狗的细微差异，即不同的皮毛长度作斗争。模型可能需要更好的分辨率输入来更好地学习细节。如果我们能够获得更多的数据输入，这将有助于提高模型的性能。</p><p id="ebe7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">#结尾</strong></p><p id="033a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是我们在CNN的第一个使用迁移学习的项目。接下来我会写关于使用CNN模型来预测图像掩蔽。</p><p id="18ef" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">敬请关注，在家注意安全！:)</p></div></div>    
</body>
</html>