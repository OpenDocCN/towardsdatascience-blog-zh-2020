<html>
<head>
<title>Collecting Data for Custom Object Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为自定义对象检测收集数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/collecting-data-for-custom-object-detection-e7d888c1469b?source=collection_archive---------6-----------------------#2020-02-19">https://towardsdatascience.com/collecting-data-for-custom-object-detection-e7d888c1469b?source=collection_archive---------6-----------------------#2020-02-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="de95" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">用于训练您的自定义检测模型的5种数据收集技术</h2></div><p id="258c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在过去的十年里，深度学习在计算机视觉中的使用越来越多。在过去的几年中，计算机视觉应用，如人脸检测和车辆检测已经成为主流。原因之一是预训练模型的可用性。</p><p id="c3d0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">被深度学习在这些应用上的成功所说服，企业现在已经开始使用深度学习来解决自己的问题。</p><blockquote class="lb"><p id="e50b" class="lc ld iq bd le lf lg lh li lj lk la dk translated">但是如果可用的预先训练的模型不适合您的应用程序呢？</p></blockquote><p id="128b" class="pw-post-body-paragraph kf kg iq kh b ki ll jr kk kl lm ju kn ko ln kq kr ks lo ku kv kw lp ky kz la ij bi translated">假设您有一个家禽养殖场，想要使用物体检测来将好鸡蛋与坏鸡蛋进行分类，这样您就可以在包装过程中自动剔除坏鸡蛋。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi lq"><img src="../Images/4c2ecc876b6780890b5ce831b097d986.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a9Wj8GsGCbKx6sj6W07v6A.jpeg"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">包装中的5个好鸡蛋和1个坏鸡蛋(图片由<a class="ae mg" href="https://unsplash.com/@carolineattwood?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Caroline Attwood </a>在<a class="ae mg" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄)</p></figure><p id="1c47" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一个预先训练的模型也许能够检测鸡蛋，但它肯定不会区分好鸡蛋和坏鸡蛋，因为它从未被教会这样做。</p><blockquote class="mh mi mj"><p id="4f29" class="kf kg mk kh b ki kj jr kk kl km ju kn ml kp kq kr mm kt ku kv mn kx ky kz la ij bi translated"><strong class="kh ir">那你会怎么做？</strong></p><p id="cdcd" class="kf kg mk kh b ki kj jr kk kl km ju kn ml kp kq kr mm kt ku kv mn kx ky kz la ij bi translated"><em class="iq">获取大量好鸡蛋和坏鸡蛋的图像，并训练一个定制的检测模型。</em></p></blockquote><p id="cbd6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">创建良好的定制计算机视觉模型的一个常见挑战是<strong class="kh ir">训练数据</strong>。深度学习模型需要大量的数据来训练其算法，正如我们在基准模型中看到的那样，如<a class="ae mg" href="https://github.com/matterport/Mask_RCNN" rel="noopener ugc nofollow" target="_blank"> MaskRCNN </a>、<a class="ae mg" href="https://pjreddie.com/yolo/" rel="noopener ugc nofollow" target="_blank"> YOLO </a>和<a class="ae mg" href="https://keras.io/applications/#mobilenet" rel="noopener ugc nofollow" target="_blank"> MobileNet </a>，这些模型是在现有的大型数据集<a class="ae mg" href="http://cocodataset.org" rel="noopener ugc nofollow" target="_blank"> COCO </a>和<a class="ae mg" href="http://image-net.org" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>上训练的。</p><blockquote class="lb"><p id="5f11" class="lc ld iq bd le lf lg lh li lj lk la dk translated">如何获取用于训练自定义检测模型的数据？</p></blockquote><p id="c443" class="pw-post-body-paragraph kf kg iq kh b ki ll jr kk kl lm ju kn ko ln kq kr ks lo ku kv kw lp ky kz la ij bi translated">在本帖中，我们将探讨5种收集数据的方法，用于训练您的自定义模型来解决您的问题。</p><h2 id="5a70" class="mo mp iq bd mq mr ms dn mt mu mv dp mw ko mx my mz ks na nb nc kw nd ne nf ng bi translated">1.公开可用的开放标记数据集</h2><p id="9091" class="pw-post-body-paragraph kf kg iq kh b ki nh jr kk kl ni ju kn ko nj kq kr ks nk ku kv kw nl ky kz la ij bi translated">如果你幸运的话，你可能会在网上得到你想要的带标签的数据集。</p><p id="249d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里有一个免费的计算机视觉图像数据集列表，你可以从中选择。</p><p id="76c7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae mg" href="http://image-net.org/" rel="noopener ugc nofollow" target="_blank"><strong class="kh ir">ImageNet</strong></a><strong class="kh ir">:</strong>ImageNet数据集包含总共约1400万张图像，涉及21，841个不同类别的对象(<em class="mk">截至2020年2月12日的数据</em>)。ImageNet中一些流行的对象类别是动物(<a class="ae mg" href="http://image-net.org/explore?wnid=n02512053" rel="noopener ugc nofollow" target="_blank">鱼</a>、<a class="ae mg" href="http://image-net.org/explore?wnid=n01503061" rel="noopener ugc nofollow" target="_blank">鸟</a>、<a class="ae mg" href="http://image-net.org/explore?wnid=n01861778" rel="noopener ugc nofollow" target="_blank">哺乳动物</a>、<a class="ae mg" href="http://image-net.org/explore?wnid=n01905661" rel="noopener ugc nofollow" target="_blank">无脊椎动物</a>)、植物(<a class="ae mg" href="http://image-net.org/explore?wnid=n13104059" rel="noopener ugc nofollow" target="_blank">树</a>、<a class="ae mg" href="http://image-net.org/explore?wnid=n11669921" rel="noopener ugc nofollow" target="_blank">花</a>、<a class="ae mg" href="http://image-net.org/explore?wnid=n07707451" rel="noopener ugc nofollow" target="_blank">植物</a>)和活动(<a class="ae mg" href="http://image-net.org/explore?wnid=n00523513" rel="noopener ugc nofollow" target="_blank">运动</a>)。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi nm"><img src="../Images/c3b6101200c1a215daa6510ec0b1499a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h-5fcBItaNgTbMTb3n1bhw.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">ImageNet数据集中的图像示例(<a class="ae mg" href="https://www.researchgate.net/figure/a-ImageNet-Synsets-with-15-image-samples-one-image-from-each-category-b-Corel-1000_fig2_316021174" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="98c1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae mg" href="http://mscoco.org/" rel="noopener ugc nofollow" target="_blank"><strong class="kh ir">【COCO】</strong></a><strong class="kh ir">:</strong>COCO是一个大规模的对象检测、分割和字幕数据集。它包含大约330，000幅图像，其中200，000幅图像被标记为80种不同的物体类别。</p><div class="lr ls lt lu gt ab cb"><figure class="nn lv no np nq nr ns paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/a2405b6c36755dc0663b19275b62cb5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*tKZrme06c18pHih6DyXCEw.png"/></div></figure><figure class="nn lv nt np nq nr ns paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/cae2f3485f85f8795d3f5682aa1807c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*tY5cyz_kzo25Et7W2qD6ZA.png"/></div></figure><figure class="nn lv nu np nq nr ns paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/3df79ca84019d1ce35a4893b54ddd5ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*tEe7Au_-fr2ANnPBWXTmiA.png"/></div></figure></div><div class="ab cb"><figure class="nn lv nv np nq nr ns paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/372f393edf2125c00604c766b3baafc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1068/format:webp/1*K-GgaRHr6a1QhMBBKlJ_nw.png"/></div></figure><figure class="nn lv nw np nq nr ns paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/0b81b8a1073847861e9a1eb0e0c59dc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*mvAz7lcEqusO24AyXyIxLQ.png"/></div><p class="mc md gj gh gi me mf bd b be z dk nx di ny nz translated">COCO数据集的图像示例(<a class="ae mg" href="http://cocodataset.org/#explore" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure></div><p id="2c81" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae mg" href="https://storage.googleapis.com/openimages/web/index.html" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> Google的开放图像</strong> </a> <strong class="kh ir"> : </strong>开放图像是一个约900万张图像的数据集，标注有图像级标签、对象边界框、对象分割遮罩和视觉关系。<a class="ae mg" href="https://storage.googleapis.com/openimages/web/factsfigures.html" rel="noopener ugc nofollow" target="_blank">它包含1.9M图像上600个对象类的总共16M的边界框，使其成为具有对象位置注释的最大现有数据集。</a></p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi oa"><img src="../Images/73c292acf973da18021954eaa44dd5f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4IcR1gyb_p7E3AOl6G9C_Q.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">开放图像数据集的图像示例(<a class="ae mg" href="https://www.freecodecamp.org/news/how-to-classify-photos-in-600-classes-using-nine-million-open-images-65847da1a319/" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="8f75" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae mg" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> MNIST手写数据集</strong> </a>:该数据集总共有70，000个手写数字图像，是可从NIST获得的更大集合的子集。数字已经过大小标准化，并在固定大小的图像中居中。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/498b0def3f882d99ae14cf6da257f9bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*-KrFuhtoT9Rr-o525mgL3w.png"/></div><p class="mc md gj gh gi me mf bd b be z dk translated">来自MNIST数据集的图像示例(<a class="ae mg" href="https://www.researchgate.net/figure/Example-images-from-the-MNIST-dataset_fig1_306056875" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="ae38" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae mg" href="https://www.cityscapes-dataset.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> Cityscapes数据集</strong> </a> <strong class="kh ir"> : </strong>该数据集专注于城市街道场景的语义理解。它包含30个不同类别的大约20，000张带注释的图片。</p><div class="lr ls lt lu gt ab cb"><figure class="nn lv oc np nq nr ns paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/8f0d6ea17e7d290a8cb2d4443149acb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*P0NAnrDIsWSIWGkP-2M2eg.png"/></div></figure><figure class="nn lv oc np nq nr ns paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/82dff48b47297c2dc25c452b63af92c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*UYNcOtnhDFTp8qHEu5nafQ.png"/></div></figure><figure class="nn lv od np nq nr ns paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/69c4e0d2a2976c04293e9c890bba5c87.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*D9ca-3TkiM8B9S0EU6yG8g.png"/></div></figure></div><div class="ab cb"><figure class="nn lv no np nq nr ns paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/d7ceb8bb47fac1a479ca63ad4267cf33.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*pAkM61cU1G1TJVBA8n7ACA.png"/></div></figure><figure class="nn lv oe np nq nr ns paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/a092afc216705c4a9fee95bb48b09442.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*rx8dK6YtJPnBgws8rHHTPA.png"/></div></figure><figure class="nn lv oe np nq nr ns paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/6155a0e3c073ad2d44254714e9a85827.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*JWpTLrM_5_NFIqtebdEJGw.png"/></div><p class="mc md gj gh gi me mf bd b be z dk of di og nz translated">来自Cityscapes数据集的注释图像示例(<a class="ae mg" href="https://www.cityscapes-dataset.com/examples/#coarse-annotations" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure></div><p id="7e68" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mk">注意:这些只是我找到的几个，还有很多其他的数据集你可以在网上找到。此外，请确保在使用这些数据集之前检查其许可。</em></p><h2 id="2b00" class="mo mp iq bd mq mr ms dn mt mu mv dp mw ko mx my mz ks na nb nc kw nd ne nf ng bi translated">2.刮网</h2><p id="8fcb" class="pw-post-body-paragraph kf kg iq kh b ki nh jr kk kl ni ju kn ko nj kq kr ks nk ku kv kw nl ky kz la ij bi translated">另一个选择是在网上搜索图片，然后手动选择下载。由于需要大量数据，这种方法效率不高。</p><p id="50a4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mk">注意:网络上的图片可能受版权保护。在使用这些图片之前，一定要记得检查它们的版权。</em></p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi oh"><img src="../Images/0cbfb38702faf0f3cd0933742353f63c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_foOKkLXm7X4eGjFxTR_4g.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">谷歌图片中的图片搜索示例</p></figure><p id="b1ee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">另一种方法是编写一个程序来抓取网页并下载你想要的图片。</p><p id="bddc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一个这样的程序是<a class="ae mg" href="https://chrome.google.com/webstore/detail/download-all-images/ifipmflagepipjokmbdecpmjbibjnakm?hl=en" rel="noopener ugc nofollow" target="_blank">下载所有图片</a>，一个谷歌Chrome的扩展，允许你一次下载一堆图片。<a class="ae mg" href="https://www.arunponnusamy.com/preparing-custom-dataset-for-training-yolo-object-detector.html" rel="noopener ugc nofollow" target="_blank">在这篇博文</a>中，<a class="oi oj ep" href="https://medium.com/u/9af1b843339?source=post_page-----e7d888c1469b--------------------------------" rel="noopener" target="_blank"> Arun Ponnusamy </a> expalins介绍了如何使用<a class="ae mg" href="https://chrome.google.com/webstore/detail/download-all-images/ifipmflagepipjokmbdecpmjbibjnakm?hl=en" rel="noopener ugc nofollow" target="_blank">下载所有图片</a>来下载戴头盔的人的图片。</p><p id="14cc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mk">注意:图像的版权使用权可能不允许使用批量下载的图像。在使用之前，一定要检查每张图片的版权。</em></p><h2 id="5556" class="mo mp iq bd mq mr ms dn mt mu mv dp mw ko mx my mz ks na nb nc kw nd ne nf ng bi translated">3.拍照</h2><p id="eb59" class="pw-post-body-paragraph kf kg iq kh b ki nh jr kk kl ni ju kn ko nj kq kr ks nk ku kv kw nl ky kz la ij bi translated">如果您找不到您想要的对象的图像，您可以通过单击照片来收集它们。这可以手动完成，即通过自己点击每张图片或众包，即雇佣其他人为你拍照。另一种收集真实世界图像的方法是在你的环境中安装可编程的摄像机。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi ok"><img src="../Images/c30b1802207e17d73dcd4362a98f3c41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XHaAREnWnRNZT5y_0-L0wQ.jpeg"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated"><a class="ae mg" href="https://unsplash.com/@lzhang?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">张小姐</a>在<a class="ae mg" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h2 id="4f9d" class="mo mp iq bd mq mr ms dn mt mu mv dp mw ko mx my mz ks na nb nc kw nd ne nf ng bi translated">4.数据扩充</h2><p id="2f61" class="pw-post-body-paragraph kf kg iq kh b ki nh jr kk kl ni ju kn ko nj kq kr ks nk ku kv kw nl ky kz la ij bi translated">我们知道深度学习模型需要大量的数据。当你只有一个很小的数据集时，可能不足以训练一个好的模型。在这种情况下，您可以使用数据扩充来生成更多的训练数据。</p><p id="b60c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">诸如翻转、裁剪、旋转和平移等几何变换是一些常用的数据扩充技术。应用影像数据扩充不仅可以通过创建变化来扩展数据集，还可以减少过度拟合。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi ol"><img src="../Images/05befaf1ae518caf1f6bd1dc7c280185.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*_EgQ0zalh9dNRY_tayE1MQ.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">左边是一只狗的原始图像，右边是围绕中心水平翻转的图像(<a class="ae mg" href="https://snow.dog/blog/data-augmentation-for-small-datasets" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div class="gh gi om"><img src="../Images/3953e759ab82459f10347b1b704ff941.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*GV315Uvckl8VHNJhNDPlsw.jpeg"/></div><p class="mc md gj gh gi me mf bd b be z dk translated">猫的原始和随机裁剪图像(<a class="ae mg" href="https://www.learnopencv.com/understanding-alexnet/" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi on"><img src="../Images/b4405622cc70c80f52a3a6827c158d37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sWLEdcIzIdJPikaNW3u-ng.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">猫的原始和旋转图像(<a class="ae mg" href="https://nanonets.com/blog/data-augmentation-how-to-use-deep-learning-when-you-have-limited-data-part-2/" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi oo"><img src="../Images/ab972f07e510fdb87e29f30d69cb441d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ponkvCwwpt2gGUX10NvHQA.jpeg"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">网球的原始图像和翻译图像(<a class="ae mg" href="https://nanonets.com/blog/data-augmentation-how-to-use-deep-learning-when-you-have-limited-data-part-2/" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><h2 id="f659" class="mo mp iq bd mq mr ms dn mt mu mv dp mw ko mx my mz ks na nb nc kw nd ne nf ng bi translated">5.数据生成</h2><p id="c34f" class="pw-post-body-paragraph kf kg iq kh b ki nh jr kk kl ni ju kn ko nj kq kr ks nk ku kv kw nl ky kz la ij bi translated">有时，真实数据可能不可用。在这种情况下，可以生成合成数据来训练您的自定义检测模型。由于其低成本，合成数据生成在机器学习中的使用越来越多。</p><p id="7afb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">生成对抗网络(GANs)是用于合成数据生成的许多技术之一。GAN是一种生成性建模技术，其中人工实例是以保留原始集合的相似特征的方式从数据集创建的。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi op"><img src="../Images/6925934e28118a3662ce1445818e1b4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wj8DmfsqNYsunYkFsEII5w.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">甘的现代艺术(<a class="ae mg" href="https://mc.ai/generating-modern-arts-using-generative-adversarial-networkgan-on-spell/" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure></div><div class="ab cl oq or hu os" role="separator"><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov"/></div><div class="ij ik il im in"><h2 id="1140" class="mo mp iq bd mq mr ms dn mt mu mv dp mw ko mx my mz ks na nb nc kw nd ne nf ng bi translated">摘要</h2><p id="17e3" class="pw-post-body-paragraph kf kg iq kh b ki nh jr kk kl ni ju kn ko nj kq kr ks nk ku kv kw nl ky kz la ij bi translated">收集训练数据集是训练您自己的定制检测机模型的第一步。在这篇文章中，我们看了一些用于收集图像数据的技术，包括搜索公共开放标签数据集、抓取网页、手动或使用程序拍照、使用数据增强技术和生成合成数据集。</p><p id="944d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mk">在下一篇帖子中，我们将看看训练您的自定义检测器的下一步，即</em> <strong class="kh ir"> <em class="mk">为您的数据集</em> </strong> <em class="mk">贴标签。敬请关注。</em></p></div><div class="ab cl oq or hu os" role="separator"><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov"/></div><div class="ij ik il im in"><p id="31b9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mk">您使用什么技术来收集图像数据集？</em> <strong class="kh ir"> <em class="mk">在下面留下你的想法作为评论。</em>T13】</strong></p><p id="49a3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">原载于<em class="mk"/><a class="ae mg" href="https://www.xailient.com/post/collecting-data-for-custom-object-detection" rel="noopener ugc nofollow" target="_blank"><em class="mk">www.xailient.com/blog</em></a><em class="mk">。</em></p><p id="3032" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">找一个<strong class="kh ir">预先训练好的人脸检测模型</strong>。<a class="ae mg" href="https://sdk.xailient.com/register.html" rel="noopener ugc nofollow" target="_blank">点击这里</a>下载。</p><p id="ea87" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">查看这篇文章了解更多关于创建一个健壮的物体检测模型的细节。</p></div><div class="ab cl oq or hu os" role="separator"><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov"/></div><div class="ij ik il im in"><p id="392d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mk">更多故事:</em></p><p id="ac08" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae mg" href="https://www.xailient.com/post/integrate-face-detection-in-your-app" rel="noopener ugc nofollow" target="_blank"> <em class="mk">在你的App上集成人脸检测</em> </a></p><p id="55f5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae mg" href="https://www.xailient.com/post/challenges-of-running-deep-learning-computer-vision-on-computationally-limited-devices" rel="noopener ugc nofollow" target="_blank"> <em class="mk">在计算受限的设备上运行深度学习计算机视觉的挑战</em> </a></p><p id="2b6a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae mg" href="https://www.xailient.com/post/struggles-of-running-object-detection-on-a-raspberry-pi" rel="noopener ugc nofollow" target="_blank"> <em class="mk">树莓上挣扎运行的物体检测</em> </a></p><p id="9a87" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae mg" href="https://www.xailient.com/post/cloud-computing-to-edge-computing" rel="noopener ugc nofollow" target="_blank"> <em class="mk">你现在需要从云计算转移到边缘计算！</em>T45】</a></p></div><div class="ab cl oq or hu os" role="separator"><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov"/></div><div class="ij ik il im in"><p id="44ca" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mk">关于作者</em> </strong></p><p id="c5de" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Sabina Pokhrel在Xailient工作，这是一家计算机视觉初创公司，已经建立了世界上最快的边缘优化物体探测器。</p></div><div class="ab cl oq or hu os" role="separator"><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov"/></div><div class="ij ik il im in"><p id="be89" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">T53】资源:T55】</strong></p><p id="2042" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Roh，y .，Heo，g .，&amp; Whang，S. (2019年)。机器学习的数据收集调查:大数据-人工智能集成视角。IEEE知识与数据工程汇刊，1–1。土井指数:10.1109/tkde。58606.88868688666</p><div class="ox oy gp gr oz pa"><a href="https://www.arunponnusamy.com/preparing-custom-dataset-for-training-yolo-object-detector.html" rel="noopener  ugc nofollow" target="_blank"><div class="pb ab fo"><div class="pc ab pd cl cj pe"><h2 class="bd ir gy z fp pf fr fs pg fu fw ip bi translated">为训练YOLO对象检测器准备自定义数据集</h2><div class="ph l"><h3 class="bd b gy z fp pf fr fs pg fu fw dk translated">2019年10月6日Arun Ponnusamy来源:Tryo labs在之前的帖子中，我们看到了如何使用OpenCV来使用预训练的YOLO模型…</h3></div><div class="pi l"><p class="bd b dl z fp pf fr fs pg fu fw dk translated">www.arunponnusamy.com</p></div></div><div class="pj l"><div class="pk l pl pm pn pj po ma pa"/></div></div></a></div><div class="ox oy gp gr oz pa"><a href="https://appen.com/blog/how-to-create-training-data-for-computer-vision-use-cases/" rel="noopener  ugc nofollow" target="_blank"><div class="pb ab fo"><div class="pc ab pd cl cj pe"><h2 class="bd ir gy z fp pf fr fs pg fu fw ip bi translated">如何为计算机视觉用例创建训练数据|阿彭</h2><div class="ph l"><h3 class="bd b gy z fp pf fr fs pg fu fw dk translated">对于简单的计算机视觉项目，如识别一组图像中的模式，公开可用的图像…</h3></div><div class="pi l"><p class="bd b dl z fp pf fr fs pg fu fw dk translated">appen.com</p></div></div><div class="pj l"><div class="pp l pl pm pn pj po ma pa"/></div></div></a></div><div class="ox oy gp gr oz pa"><a href="https://hackernoon.com/a-definitive-guide-to-build-training-data-for-computer-vision-1d1d50b4bf07" rel="noopener  ugc nofollow" target="_blank"><div class="pb ab fo"><div class="pc ab pd cl cj pe"><h2 class="bd ir gy z fp pf fr fs pg fu fw ip bi translated">为计算机视觉建立训练数据的权威指南</h2><div class="ph l"><h3 class="bd b gy z fp pf fr fs pg fu fw dk translated">谷歌、微软、亚马逊和脸书等科技巨头已经宣布了他们以人工智能为先的产品战略…</h3></div><div class="pi l"><p class="bd b dl z fp pf fr fs pg fu fw dk translated">hackernoon.com</p></div></div><div class="pj l"><div class="pq l pl pm pn pj po ma pa"/></div></div></a></div></div></div>    
</body>
</html>