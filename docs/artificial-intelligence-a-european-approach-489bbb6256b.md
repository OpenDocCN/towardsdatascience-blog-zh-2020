# 人工智能——欧洲的方法

> 原文：<https://towardsdatascience.com/artificial-intelligence-a-european-approach-489bbb6256b?source=collection_archive---------41----------------------->

![](img/de6c9eef742a0b927d8749b7986e7f9b.png)

马库斯·斯皮斯克在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

欧盟委员会目前正在探索需要什么样的措施和立法来实现人工智能的全部潜力，同时保护欧盟公民。在这种情况下，一份白皮书的初步版本已经泄露。尽管它还不是一份官方出版物，但它已经很好地显示了欧洲目前在人工智能问题上的考虑。

以下是草案摘要(截至 21。2020 年 1 月)。你可以在这里下载的完整论文[。](https://www.politico.eu/wp-content/uploads/2020/01/SKM_C45820012915530.pdf)

> 对价值观、法治和构建安全可靠的复杂系统的能力的强烈依赖是帮助实现值得信赖的人工智能的一些基础。

**章节有**
1。前言
2。简介
3。利用工业和专业市场的优势
4。抓住未来的机遇:下一次数据浪潮
5。卓越的生态系统。信任的生态系统:人工智能的监管框架。结论

**1。人工智能正在快速发展，并将对我们的生活产生重要而积极的影响，但也可能存在风险。**

对欧盟委员会来说，三个领域非常重要:推动科学突破，保持欧盟的技术领先地位，以及确保新技术为欧洲人服务。

重要的是欧罗巴作为一个整体行动，并定义自己的方式。
该方法基于监管和投资。

**2。简介** 对价值观、法治的强烈依恋，以及构建安全可靠的复杂系统的能力，是帮助实现值得信赖的人工智能的一些基础。

日期将越来越成为经济增长的原因。尤其是来自商业和工业的数据——欧洲在这两个领域都处于强势地位。

自由、人类尊严和隐私保护的价值观必须成为欧洲人工智能的基础。监管应该是欧洲的，以避免单一市场的分裂和公民的不确定性。

白皮书的两个主要部分是，第一，从研究和创新开始，沿着整个价值链的“卓越生态系统”。第二个是“信任生态系统”，这样公民可以对人工智能的使用充满信心，而公司则了解法律法规。

此外，补充“欧洲数据战略”旨在确保欧罗巴成为“世界上最具吸引力、最安全和最具活力的数据中心”。

**3。利用工业和专业市场的优势** 欧洲有很大的优势从人工智能的发展中受益:卓越的研究，在许多重要领域的市场领导地位(机器人，竞争性制造，汽车，医疗保健)。此外，欧洲拥有大量未被充分利用的数据。

因此，欧洲应该建立自己的优势，并在价值链中加以利用。

事实证明，欧盟资助计划是协调投资的一种成功方式。自上一时期以来，欧盟对研究和创新的资助增加了 70%，达到 15 亿欧元。不过，与其他地区相比，这只是一小部分。欧洲需要增加和最大化投资。

**4。抓住未来的机遇:下一波数据浪潮** 欧洲在消费者和在线服务领域的弱势地位是基于数据访问方面的竞争劣势。到 2025 年，平台将失去其在数据仓库中的主导地位，大部分数据将位于本地边缘设备上，例如工厂或医院。

欧洲应该扩大人工智能专用 CPU 的领域。像欧洲处理器倡议这样的项目可以帮助做到这一点。Europa 已经在神经形态工程领域处于领先地位，并在量子计算领域占据强势地位。

欧洲将继续引领人工智能算法基础的进步，并将机器学习、深度学习和符号推理等领域的专业知识与深度神经网络相结合。

**5。卓越的生态系统**

**A .与成员国合作**

为了进一步最大限度地扩大研究、创新和部署投资的影响，将向成员国提议修订人工智能协调计划，以便在 2020 年底前通过(行动 1)。

**B .联合并集中研究和创新群体的努力**

为了达到高水平，欧洲必须巩固其卓越中心。必须创造协同和集中。这也包括留住和吸引最好的研究人员。欧洲需要一个特别引人注目的最高水平的人工智能研究中心，以吸引投资和人才。

这个人工智能研究中心应该专注于欧洲能够取得世界领先地位的领域(例如:工业、卫生、交通、农业食品链、能源/环境、地球观测或太空)。

同样重要的是提供测试和基准站点。这方面的法律框架将于 2020 年第二季度创建(创建“欧盟卓越”标签/品牌)(行动 2)。

**C .关注中小企业**

重要的是，中小企业既要使用人工智能，又要有获取人工智能的途径。为此，应进一步加强数字创新中心和人工智能按需平台。

根据" InvestEU "方案，将进一步扩大对中小企业和初创企业的投资。

与成员国合作，确保每个成员国至少有一个数字创新中心。为此，计划投入 9 亿欧元。在 Q1 2020 年，1 亿欧元的资金将用于人工智能创新。从 2021 年起，InvestEU 将把这一数额至少增加十倍(行动 3)。

**D .与私营部门的伙伴关系**

重要的是，私营部门充分参与制定研究和创新议程，并提供必要的共同投资。为此，有必要发展公私合作伙伴关系，并获得公司管理层的批准。

欧盟委员会正在为人工智能和机器人技术建立一个新的公私合作伙伴关系(行动 4)。

**E .促进人工智能的采用**

公共管理使用 AI 技术是必要的。这里的重点是医疗保健和交通。为此，将在具体部门讨论的帮助下，在 2020 年年中之前制定一项行动计划(行动 5)。

**F .保护对数据和计算基础设施的访问**

改善数据的获取和管理是一个关键问题。同样重要的是对计算机技术和基础设施的投资。

将拨款 40 亿欧元支持高性能计算机、量子计算机以及人工智能和数据基础设施。

**G .技能**

欧洲的方法还必须特别关注技能领域。虽然教育政策是成员国的责任，但委员会可以协调最佳做法的交流。

促进人工智能相关能力将是修订后的“人工智能协调计划”和“数字教育行动计划”的优先事项。

欧洲卓越中心以及由此带来的人才增长也将对整个欧洲的技能转移产生积极影响。

数字欧洲方案旨在吸引最优秀的教授和研究人员，并提供人工智能领域的世界领先的硕士学位(行动 7)。

**H .国际方面**

欧盟的工作已经影响了国际话语(伦理原则)。

欧盟将继续与全球人工智能参与者合作。这是基于欧盟的利益(执行欧洲标准，获取关键资源，如数据，公平的竞争环境)。合作必须旨在促进基本权利。

**6。信任的生态系统:人工智能的监管框架**

信任是确保人工智能日益普及的重要因素。

为此，编写了关于可信 AI 的指南，其中描述了七个基本要求。根据公司的反馈，透明度和人力监督很重要，但立法者尚未具体要求。

一个有约束力的监管框架可以帮助增加消费者和企业对人工智能的信心，从而促进其使用。该框架受到高级别专家组要求的启发。

人工智能开发商和提供商已经受到欧洲立法的约束。然而，大赦国际的具体性质可能会使这一立法难以适用和执行。因此，必须审查现有立法，以确定它是否已经足够。

为了确保欧盟内部市场的平稳运行，欧盟层面的强有力框架优于国家立法。

**6A。问题定义**

该框架的重点应该是将风险降至最低。这些风险可能是实质性的(安全、健康、财产损失等)。)和非物质的(失去隐私、限制言论自由、人的尊严、歧视等)。).

人工智能作为“黑匣子”的问题可能会给法律的应用和执行带来困难。

主要风险是数据安全以及对基本权利和安全的威胁。

**6A i .基本权利的风险，包括隐私、数据保护和歧视**

使用人工智能可能导致侵犯基本权利。要么是因为错误的开发，要么是因为数据的偏差。

这是一个问题，因为公民将越来越多地接触到人工智能的决定。

虽然人类的决策存在偏差，但 AI 没有社会控制机制。

**6A 二世。安全风险和责任体系的有效运行**

人工智能会产生新的安全风险。例如通过车辆中的错误图像识别。

如果没有明确的安全法规，这可能会导致公司的法律不确定性，当局也无法干预。这将削弱整体安全性，并使责任问题复杂化。

人工智能的特性使得追溯系统决策变得困难。这目前可能导致证据不足。因此，可能无法据此要求赔偿，也无法追查侵犯基本权利的行为。

**B .现有的欧盟人工智能立法框架**

关于安全和责任问题的全面法律框架(国家和欧盟级别)已经到位，并可能适用于人工智能应用。欧盟立法也涵盖基本权利和消费者权利。

需要研究欧盟立法是否已经能够充分解决禽流感的风险，或者是否需要适应。委员会提出以下领域供审议:

1)有效应用和执行现有的国家和欧盟立法。

2)现有欧盟立法范围的局限性:例如，软件和服务不被视为产品，因此不在立法范围内。

3)人工智能系统的动态本质。

4)不同经济行为者之间责任分配的不确定性。

5)安全概念的变化:在操作过程中出现的风险，例如由于更新或技术或安全变化。

**C .监管框架的范围**

委员会从 b 中得出结论，补充现有立法是一种行动选择。澄清范围是一个重要的问题。目前的假设是，它涉及利用人工智能的服务和产品。为了创造法律确定性，需要界定人工智能的概念。

对这个定义的建议是:AI 是在软件或硬件中使用算法，识别产品或服务为了实现给定目标应该执行的动作。这是通过解释、推理和从数据中学习来完成的。

**D .要求适用的可能情况**

该框架不应该过于规范，以免给中小企业造成过多的官僚障碍。

应该关注“高风险”应用，以便监管干预能够保持合理。为此，有必要对低风险和高风险进行精确定义。

确定风险水平的标准可以是:1)高风险部门的定义，2)高风险应用的定义，3)自我评估，4)产出的影响潜力:重要性、不可逆性、高风险群体中的目标群体。

高风险应用程序的定义应基于两个标准:
1)高风险领域的详细列表。
2)关于人工智能使用的高风险的抽象定义。

强制性要求仅适用于满足这两个标准的应用程序。对于所有其他应用，现有立法继续适用。

**E .需求类型**

必须考虑强制性法律要求及其适用的级别。还必须考虑前面提到的风险水平。调节的强度必须是可调节的。特别是在高风险系统的情况下，所有参与者都必须遵守该法规，包括没有 EU-基地的参与者。

下面提出了高风险应用程序的需求类型:

**a)质量和可追溯性义务**

高风险应用程序必须使用根据欧洲规则和要求收集的数据进行培训。

这意味着数据必须保证基本权利以及隐私、保密性、完整性、可再现性(根据 DSGVO)和高级别小组道德准则的具体要求:准确性、可再现性、可再现性。

**b)透明度和人员监督义务**

高风险应用程序应提供符合欧洲法规的文档。这关系到数据的质量、准确性、编程方法以及生产、测试和验证人工智能系统的技术。如果还与可能的偏差相关的话。

正确应用和准确性的能力、限制、目的和条件必须提交给当局和最终用户。

当用户使用人工智能系统时，必须弄清楚这一点。

需要有人监督。

**c)远程生物识别系统的具体要求**

生物识别系统带来了侵犯基本权利的风险。

关于(a)和(b)的要求，应提供相应的生物特征数据处理指南。

此外，对于风险不高的系统，可能会有一个自愿的“质量标签”。然而，这种标签不会完全涵盖安全、问责和基本权利等问题，而只会鼓励可信人工智能的发展。

**F .收信人**

在人工智能系统的生命周期中有许多参与者。未来的立法应基于这样的原则，即责任在于最有能力应对潜在风险的行为者。

**G .强制执行**

应通过事前(之前)和事后(之后)评估相结合的方式对要求进行评估。可能会对风险水平进行调整。

对于高风险申请，将根据现有机制在欧盟内部进行事前评估。发生违规后，将对低风险应用程序进行事后评估。

**H .治理**

行政结构必须是欧洲的，以便集中责任，提高成员国在人工智能方面的能力，并确保欧洲逐步具备测试和认证人工智能产品和服务的必要能力。这种方法应该是非官僚的和敏捷的。

这些结构还应依靠国家当局网络。

不应与现有机构重叠，而应与其密切合作。

成员国应该将符合性评估留给独立的测试中心。

应确保利益攸关方尽可能广泛的参与。

**7。结论** 为了让欧洲利用人工智能提供的所有机会，必须建立和加强必要的工业和技术能力。这在欧洲数据战略中有所阐述。欧盟将成为全球数据中心。

欧洲的人工智能方法旨在加强欧洲的创新，同时促进道德和值得信赖的人工智能。

这份白皮书旨在与所有相关利益攸关方开展广泛磋商。