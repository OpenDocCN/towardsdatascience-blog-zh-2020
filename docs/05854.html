<html>
<head>
<title>Develop glue jobs locally using Docker containers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Docker容器在本地开发胶水工作</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/develop-glue-jobs-locally-using-docker-containers-bffc9d95bd1?source=collection_archive---------16-----------------------#2020-05-14">https://towardsdatascience.com/develop-glue-jobs-locally-using-docker-containers-bffc9d95bd1?source=collection_archive---------16-----------------------#2020-05-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6cd5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Docker容器在本地测试glue spark ETL脚本，而不会产生任何额外的成本，也不会使用开发端点</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4b5e82130a1407513c0618fa7322f8df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4ZBssQZ_VoXg6Z4n1boCrw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由Free提供-照片来自Pixabay</p></figure><p id="10d3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">随着当前世界数据量的不断增加，对处理大数据的服务的需求非常高。当我们考虑大数据时，大多数数据工程师使用的框架非常少。阿帕奇Spark就是其中之一。</p><p id="570e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Apache Spark是一个分布式处理引擎，它需要一个大型集群来执行任何类型的分析或简单地对数据集执行ETL。要使用Apache Spark，我们需要建立自己的大型集群，这非常昂贵，或者我们可以在云上利用它们。在这里，我们将讨论AWS提供的服务。因此，为了处理大型数据集并使用spark对其进行分析，AWS提供了两个主要服务</p><ol class=""><li id="26c5" class="lu lv it la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">AWS EMR(弹性地图缩减)</li><li id="f6b5" class="lu lv it la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">AWS胶水</li></ol><p id="f732" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">AWS EMR为我们提供集群来执行我们的处理，并且非常昂贵，因此我们需要仔细确定我们需要集群多长时间，以及如何适当地优化我们的作业。我们不会在这篇文章中讨论EMR，因为它本身就是一个非常大的讨论话题。</p><p id="0665" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">AWS Glue是一个完全托管的ETL服务，由amazon web services提供，用于处理大量数据。AWS Glue最好的部分是它在AWS无服务器保护伞下，我们不需要担心管理所有这些集群和与之相关的成本。在无服务器模式中，我们为我们使用的东西付费，因此，如果我们的工作只使用25个DPU来处理我们的数据，并且运行20分钟，那么我们最终只需支付利用25个DPU 20分钟的成本，而不会多花一分钱。</p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><p id="6148" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如今，AWS Glue是创建基于python或scala的spark处理作业的最大需求。要在AWS glue上开发jobs，我们有三个选项。让我们逐一讨论。</p><ol class=""><li id="3841" class="lu lv it la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated"><strong class="la iu">直接在glue编辑器中创建作业并运行作业:</strong></li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mp"><img src="../Images/7799fb86f752e6667b8f7abfdc802777.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cdHotV8yvSuWqpNG9OwnfQ.png"/></div></div></figure><p id="e34c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果您是spark开发人员，并且不太熟悉glue libraries及其图生成，那么无论如何都要避免使用这个编辑器。这是写给那些非常确定他们正在写什么，并且从心里知道他们的工作将在第一轮中运行的人。这是完全不推荐的，只有当我们需要对现有的工作做一些改变时才可以考虑。当您在代码中使用胶水库时，直接使用作业编辑器是很好的，因为它会在您编写代码时生成谱系图。在选择这个选项之前，我建议浏览一下胶水库<a class="ae mq" href="https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-python-transforms.html" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="25f5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> 2。创建一个胶开发端点:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mr"><img src="../Images/6a577e835727f48b5521a709b87e2ce5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eqNO1UfYSQwi6y4J9m2-qQ.png"/></div></div></figure><p id="c38c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您可以设置一个glue dev端点，并将其链接到zeppelin笔记本或您的pycharm IDE，或者您甚至可以连接本地jupyter笔记本。如果您想在开发工作时测试它们，这是一个更好的选择。要设置Glue Dev端点，您可以遵循官方AWS文档<a class="ae mq" href="https://docs.aws.amazon.com/glue/latest/dg/dev-endpoint.html" rel="noopener ugc nofollow" target="_blank">这里</a>。这个glue dev端点的唯一问题是它的成本。您将为它运行的时间付费，所以它基本上是用您想要的容量和安装在集群上的胶水库来启动EMR集群。如果开发成本不是问题，并且可以考虑的话，这是最好的选择之一。</p><p id="0f2e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> 3。使用AWS胶水库并在本地Docker容器上运行它们</strong></p><p id="95bf" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">考虑到作业的开发和在相对较小的数据集上测试作业，并且一旦作业准备好使用glue job console本身运行它们，这是迄今为止最好的选择。通过这个选项，您可以在您的机器上灵活地使用glue libraries，或者您可以根据您的数据集大小启动EC2实例，并在这些EC2上启动docker容器，因为这将是一个相对便宜的选项，也是最适合运行您的作业的选项。</p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><p id="31cf" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要在本地设置AWS glue，你可以点击这里查看AWS文档<a class="ae mq" href="https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-libraries.html" rel="noopener ugc nofollow" target="_blank">。但这似乎并不奏效，我们将详细讨论它。因此，我创建了一个Docker图像，并将解释我们正在做什么。</a></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">DockerFile文件</p></figure><p id="38fb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我将centos作为基础映像，然后设置这些env变量，稍后我们将需要它来下载库</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="2c84" class="mz na it mv b gy nb nc l nd ne">ENV MAVEN=https://aws-glue-etl-artifacts.s3.amazonaws.com/glue-common/apache-maven-3.6.0-bin.tar.gz<br/>ENV SPARK=https://aws-glue-etl-artifacts.s3.amazonaws.com/glue-1.0/spark-2.4.3-bin-hadoop2.8.tgz<br/>ENV GLUE=https://github.com/awslabs/aws-glue-libs.git</span></pre><p id="742d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后，我们将创建一个目录glue并安装所需的库，如Java、python、wget、tar和Python包，并将我们的工作目录设置为glue</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="06a5" class="mz na it mv b gy nb nc l nd ne">RUN mkdir glue<br/>RUN yum install -y python3 java-1.8.0-openjdk java-1.8.0-openjdk-devel tar git wget zip<br/>RUN ln -s /usr/bin/python3 /usr/bin/python<br/>RUN ln -s /usr/bin/pip3 /usr/bin/pip<br/>RUN pip install pandas<br/>RUN pip install boto3<br/>RUN pip install pynt<br/>WORKDIR ./glue</span></pre><p id="1abc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在在这个目录下会下载maven，spark和glue libs并解压。然后我们将更新path变量，并向它添加SPARK_HOME、JAVA_HOME、MAVEN_HOME和GLUE_HOME变量。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="cd83" class="mz na it mv b gy nb nc l nd ne">#To get the latest aws libraries<br/>RUN git clone -b glue-1.0 $GLUE</span><span id="9433" class="mz na it mv b gy nf nc l nd ne">#To get latest spark version<br/>RUN wget $SPARK</span><span id="9d81" class="mz na it mv b gy nf nc l nd ne">#To install Maven for dependencies<br/>RUN wget $MAVEN</span><span id="d63e" class="mz na it mv b gy nf nc l nd ne">RUN tar zxfv apache-maven-3.6.0-bin.tar.gz<br/>RUN tar zxfv spark-2.4.3-bin-hadoop2.8.tgz</span><span id="b14d" class="mz na it mv b gy nf nc l nd ne">#Removing zip files inorder to reduce the final docker image size<br/>RUN rm spark-2.4.3-bin-hadoop2.8.tgz<br/>RUN rm apache-maven-3.6.0-bin.tar.gz</span><span id="daed" class="mz na it mv b gy nf nc l nd ne">#Setting up env variables<br/>RUN mv $(rpm -q -l java-1.8.0-openjdk-devel | grep "/bin$" | rev | cut -d"/" -f2- |rev) /usr/lib/jvm/jdk<br/>ENV SPARK_HOME /glue/spark-2.4.3-bin-spark-2.4.3-bin-hadoop2.8<br/>ENV MAVEN_HOME /glue/apache-maven-3.6.0<br/>ENV JAVA_HOME /usr/lib/jvm/jdk<br/>ENV GLUE_HOME /glue/aws-glue-libs<br/>ENV PATH $PATH:$MAVEN_HOME/bin:$SPARK_HOME/bin:$JAVA_HOME/bin:$GLUE_HOME/bin</span></pre><blockquote class="ng nh ni"><p id="016e" class="ky kz nj la b lb lc ju ld le lf jx lg nk li lj lk nl lm ln lo nm lq lr ls lt im bi translated"><strong class="la iu">这里有一个重要的已知问题，将删除一些库</strong><a class="ae mq" href="https://github.com/awslabs/aws-glue-libs/issues/25" rel="noopener ugc nofollow" target="_blank"><strong class="la iu"/></a><strong class="la iu">。</strong></p></blockquote><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="a113" class="mz na it mv b gy nb nc l nd ne">RUN sed -i '/mvn -f/a rm /glue/aws-glue-libs/jarsv1/netty-*' /glue/aws-glue-libs/bin/glue-setup.sh</span><span id="b6ad" class="mz na it mv b gy nf nc l nd ne">RUN sed -i '/mvn -f/a rm /glue/aws-glue-libs/jarsv1/javax.servlet-3.*' /glue/aws-glue-libs/bin/glue-setup.sh</span></pre><p id="1ed2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们将使用maven编译所有的依赖项。这个shell脚本运行maven build命令并获得所有需要的依赖项。</p><blockquote class="ng nh ni"><p id="288d" class="ky kz nj la b lb lc ju ld le lf jx lg nk li lj lk nl lm ln lo nm lq lr ls lt im bi translated">我们只运行一次，这样我们的docker映像就可以预先包含这些库，从而节省以后运行spark作业的时间。</p></blockquote><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="248c" class="mz na it mv b gy nb nc l nd ne">RUN sh /glue/aws-glue-libs/bin/glue-setup.sh</span></pre><p id="2584" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，我们将清理所有的tmp目录，并使用bash作为容器的入口点。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="7705" class="mz na it mv b gy nb nc l nd ne">RUN yum clean all<br/>RUN rm -rf /var/cache/yum<br/>CMD ["bash"]</span></pre><p id="0c64" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在使用docker文件并创建您的容器，以便开始开发glue spark作业。</p><h2 id="afec" class="mz na it bd nn no np dn nq nr ns dp nt lh nu nv nw ll nx ny nz lp oa ob oc od bi translated">从Dockerfile构建docker映像</h2><p id="aa8c" class="pw-post-body-paragraph ky kz it la b lb oe ju ld le of jx lg lh og lj lk ll oh ln lo lp oi lr ls lt im bi translated">要从该Dockerfile文件构建映像，请运行以下命令:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="acc1" class="mz na it mv b gy nb nc l nd ne">docker build -t jnshubham/glue_etl_local .</span></pre><h2 id="8ca3" class="mz na it bd nn no np dn nq nr ns dp nt lh nu nv nw ll nx ny nz lp oa ob oc od bi translated">从DockerHub中提取现有图像</h2><p id="3a6b" class="pw-post-body-paragraph ky kz it la b lb oe ju ld le of jx lg lh og lj lk ll oh ln lo lp oi lr ls lt im bi translated">要使用现有的映像来启动您的容器，只需从docker hub中提取映像，并运行所提供的命令来提交作业</p><p id="0aea" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要提取图像，请运行以下命令:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="937f" class="mz na it mv b gy nb nc l nd ne">docker pull jnshubham/glue_etl_local:latest</span></pre><p id="3b8b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">通过运行以下命令检查下载的图像</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="9bde" class="mz na it mv b gy nb nc l nd ne">docker images</span></pre><h2 id="6960" class="mz na it bd nn no np dn nq nr ns dp nt lh nu nv nw ll nx ny nz lp oa ob oc od bi translated">运行Docker容器</h2><p id="0b17" class="pw-post-body-paragraph ky kz it la b lb oe ju ld le of jx lg lh og lj lk ll oh ln lo lp oi lr ls lt im bi translated">要运行容器并进入<em class="nj"> repl </em> shell:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="3d09" class="mz na it mv b gy nb nc l nd ne">docker run jnshubham/glue_etl_local "gluepyspark"</span></pre><p id="1c3d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">进入终端并提交spark作业运行</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="f210" class="mz na it mv b gy nb nc l nd ne">docker run -it jnshubham/glue_etl_local</span><span id="185a" class="mz na it mv b gy nf nc l nd ne">gluesparksubmit script.py --JOB_NAME script</span></pre><p id="d925" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这样，您将能够在本地机器上测试您的作业，或者您也可以根据您的数据大小在任何EC2实例上使用它。</p><p id="aa13" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">更多信息，请访问我的<a class="ae mq" href="https://github.com/jnshubham/aws-glue-local-etl-docker" rel="noopener ugc nofollow" target="_blank"> GitHub </a>或<a class="ae mq" href="https://hub.docker.com/repository/docker/jnshubham/glue_etl_local" rel="noopener ugc nofollow" target="_blank"> dockerhub </a>。</p></div></div>    
</body>
</html>