<html>
<head>
<title>A Machine Predicts My Next Sentence</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一台机器预测了我的下一句话</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-machine-predicts-my-next-sentence-d5a0767b6233?source=collection_archive---------61-----------------------#2020-04-29">https://towardsdatascience.com/a-machine-predicts-my-next-sentence-d5a0767b6233?source=collection_archive---------61-----------------------#2020-04-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2a01" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用Docker和TensorFlow通过RNN生成文本</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/3f6f335a7eb927e1c2bbde005cb19fbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L6jMZ31ZNi5EVAYm_C7HSw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@agkdesign?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">亚历山大·奈特</a>在<a class="ae ky" href="https://unsplash.com/s/photos/robot?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片【1】</p></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="0c88" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">目录</h1><ol class=""><li id="c2a3" class="ly lz it ma b mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">文本生成</li><li id="e968" class="ly lz it ma b mb mq md mr mf ms mh mt mj mu ml mm mn mo mp bi translated">码头工人</li><li id="50c6" class="ly lz it ma b mb mq md mr mf ms mh mt mj mu ml mm mn mo mp bi translated">张量流</li><li id="da64" class="ly lz it ma b mb mq md mr mf ms mh mt mj mu ml mm mn mo mp bi translated">资料组</li><li id="bf73" class="ly lz it ma b mb mq md mr mf ms mh mt mj mu ml mm mn mo mp bi translated">密码</li><li id="4505" class="ly lz it ma b mb mq md mr mf ms mh mt mj mu ml mm mn mo mp bi translated">摘要</li><li id="860a" class="ly lz it ma b mb mq md mr mf ms mh mt mj mu ml mm mn mo mp bi translated">参考</li></ol><h1 id="5830" class="lg lh it bd li lj mv ll lm ln mw lp lq jz mx ka ls kc my kd lu kf mz kg lw lx bi translated">文本生成</h1><p id="ed8a" class="pw-post-body-paragraph na nb it ma b mb mc ju nc md me jx nd mf ne nf ng mh nh ni nj mj nk nl nm ml im bi translated">文本生成属于数据科学的一个分支，即自然语言生成或通常称为NLG。自然语言处理(NLP)使用库来清理、转换、变换并最终操纵文本，而NLG则努力从过去的数据中创造新的文本。</p><p id="a14d" class="pw-post-body-paragraph na nb it ma b mb nn ju nc md no jx nd mf np nf ng mh nq ni nj mj nr nl nm ml im bi translated">其中一个突出的例子是聊天机器人。它使用各种不同类型的算法来模仿以前的文本，以产生一个用户认为(在某种程度上)他们正在与人而不是机器交谈的响应。这一代文本不仅很棒，而且也很有用，因为它可以自动完成手工操作。</p><h1 id="3a15" class="lg lh it bd li lj mv ll lm ln mw lp lq jz mx ka ls kc my kd lu kf mz kg lw lx bi translated">码头工人</h1><p id="726f" class="pw-post-body-paragraph na nb it ma b mb mc ju nc md me jx nd mf ne nf ng mh nh ni nj mj nk nl nm ml im bi translated"><a class="ae ky" href="https://www.docker.com/" rel="noopener ugc nofollow" target="_blank">Docker</a>【2】利用虚拟化，利用容器来开发和传播软件。容器包含那些已配置的文件和库。在这个例子中，docker文件中使用的信息有几个主要方面:中的<em class="ns">、<em class="ns">公开</em>、<em class="ns">工作目录</em>、<em class="ns">复制</em>和<em class="ns">入口点</em>。运行完所有必要的建模代码后，tensor flow<a class="ae ky" href="https://www.tensorflow.org/tutorials/text/text_generation" rel="noopener ugc nofollow" target="_blank">列出了3个步骤来运行您的第一个生产文本生成器，如下所示:</a></em></p><ul class=""><li id="6dd2" class="ly lz it ma b mb nn md no mf nt mh nu mj nv ml nw mn mo mp bi translated">建设</li></ul><p id="e0fb" class="pw-post-body-paragraph na nb it ma b mb nn ju nc md no jx nd mf np nf ng mh nq ni nj mj nr nl nm ml im bi translated"><code class="fe nx ny nz oa b">docker build -t tf-text-generator .</code></p><ul class=""><li id="2a4b" class="ly lz it ma b mb nn md no mf nt mh nu mj nv ml nw mn mo mp bi translated">奔跑</li></ul><p id="a1f9" class="pw-post-body-paragraph na nb it ma b mb nn ju nc md no jx nd mf np nf ng mh nq ni nj mj nr nl nm ml im bi translated"><code class="fe nx ny nz oa b">docker run --rm -p 8080:8888 tf-text-generator</code></p><ul class=""><li id="5b35" class="ly lz it ma b mb nn md no mf nt mh nu mj nv ml nw mn mo mp bi translated">试验</li></ul><p id="3138" class="pw-post-body-paragraph na nb it ma b mb nn ju nc md no jx nd mf np nf ng mh nq ni nj mj nr nl nm ml im bi translated"><code class="fe nx ny nz oa b">curl -d '{"text" : "ROMEO:"}' -H "Content-Type: application/json" -X POST <a class="ae ky" href="http://127.0.0.1:8080" rel="noopener ugc nofollow" target="_blank">http://127.0.0.1:8080</a></code></p><h1 id="fd03" class="lg lh it bd li lj mv ll lm ln mw lp lq jz mx ka ls kc my kd lu kf mz kg lw lx bi translated">张量流</h1><p id="7aa1" class="pw-post-body-paragraph na nb it ma b mb mc ju nc md me jx nd mf ne nf ng mh nh ni nj mj nk nl nm ml im bi translated">TensorFlow是一个免费、易用的软件库，有助于建立机器学习模型(包括数据科学和深度学习模型)。它的主要应用之一是神经网络。在<a class="ae ky" href="https://www.tensorflow.org/tutorials/text/text_generation" rel="noopener ugc nofollow" target="_blank">tensor flow</a>【3】提供的例子中，许多聪明的、富有灵感的作者合作开发了一个文本生成器，它可以被克隆并在你的本地桌面上执行。</p><h1 id="d2d0" class="lg lh it bd li lj mv ll lm ln mw lp lq jz mx ka ls kc my kd lu kf mz kg lw lx bi translated">资料组</h1><p id="9f15" class="pw-post-body-paragraph na nb it ma b mb mc ju nc md me jx nd mf ne nf ng mh nh ni nj mj nk nl nm ml im bi translated">使用的数据集是莎士比亚作品片段的汇编。对于自己的版本，可以使用任意<em class="ns">。txt</em>文件，只要您在模型类中定义了变量pathname，如下所示[3]:</p><pre class="kj kk kl km gt ob oa oc od aw oe bi"><span id="6ec9" class="of lh it oa b gy og oh l oi oj">text = open(your_text_path, ‘rb’).read().decode(encoding=’utf-8')</span></pre><h1 id="00cc" class="lg lh it bd li lj mv ll lm ln mw lp lq jz mx ka ls kc my kd lu kf mz kg lw lx bi translated">密码</h1><p id="36c3" class="pw-post-body-paragraph na nb it ma b mb mc ju nc md me jx nd mf ne nf ng mh nh ni nj mj nk nl nm ml im bi translated">例子的代码可以在<a class="ae ky" href="https://www.tensorflow.org/tutorials/text/text_generation" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>的网站上找到。这个函数只是整个管道的一部分，但它是文本生成最突出的地方[3]:</p><pre class="kj kk kl km gt ob oa oc od aw oe bi"><span id="9141" class="of lh it oa b gy og oh l oi oj">def generate_text(model, start_string):<br/>  # Evaluation step (generating text using the learned model)<br/><br/>  # Number of characters to generate<br/>  num_generate = 1000<br/><br/>  # Converting our start string to numbers (vectorizing)<br/>  input_eval = [char2idx[s] for s in start_string]<br/>  input_eval = tf.expand_dims(input_eval, 0)<br/><br/>  # Empty string to store our results<br/>  text_generated = []<br/><br/>  # Low temperatures results in more predictable text.<br/>  # Higher temperatures results in more surprising text.<br/>  # Experiment to find the best setting.<br/>  temperature = 1.0<br/><br/>  # Here batch size == 1<br/>  model.reset_states()<br/>  for i in range(num_generate):<br/>      predictions = model(input_eval)<br/>      # remove the batch dimension<br/>      predictions = tf.squeeze(predictions, 0)<br/><br/>      # using a categorical distribution to predict the character returned by the model<br/>      predictions = predictions / temperature<br/>      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()<br/><br/>      # We pass the predicted character as the next input to the model<br/>      # along with the previous hidden state<br/>      input_eval = tf.expand_dims([predicted_id], 0)<br/><br/>      text_generated.append(idx2char[predicted_id])<br/><br/>  return (start_string + ''.join(text_generated))</span></pre><p id="d922" class="pw-post-body-paragraph na nb it ma b mb nn ju nc md no jx nd mf np nf ng mh nq ni nj mj nr nl nm ml im bi translated">两个参数是<em class="ns">模型</em>和<em class="ns"> start_string </em>，一旦docker映像被构建、运行和测试，就可以在您的终端中执行，它将返回您生成的文本。在这段莎士比亚对话中，马歇斯生成的文本或句子的输出是[3]:</p><pre class="kj kk kl km gt ob oa oc od aw oe bi"><span id="0e95" class="of lh it oa b gy og oh l oi oj">MARCIUS:<br/>How do thou wast forced;<br/>The endempily east enought than whence, or, bear<br/>headed me aple, to-morrow why I rue,<br/>My own brothers on't, but stins abbooon of<br/>so sours; or ghinf purnicy in base as as<br/>Two kings at my heart?</span></pre><h1 id="44e0" class="lg lh it bd li lj mv ll lm ln mw lp lq jz mx ka ls kc my kd lu kf mz kg lw lx bi translated">摘要</h1><p id="754e" class="pw-post-body-paragraph na nb it ma b mb mc ju nc md me jx nd mf ne nf ng mh nh ni nj mj nk nl nm ml im bi translated">提供的代码是实现TensorFlow众多令人印象深刻的功能的好方法。它被存储和开发以容易地产生简单和强大的模型。为了使这个过程更加个性化，修改文本文件当然会得到不同的生成文本，但是模型中的参数也可以通过反复试验来调整，这样您就可以制作自己的生成文本的机器。</p><h1 id="6024" class="lg lh it bd li lj mv ll lm ln mw lp lq jz mx ka ls kc my kd lu kf mz kg lw lx bi translated">参考</h1><p id="a45d" class="pw-post-body-paragraph na nb it ma b mb mc ju nc md me jx nd mf ne nf ng mh nh ni nj mj nk nl nm ml im bi translated">[1] A .奈特，<a class="ae ky" href="https://unsplash.com/s/photos/robot?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>，(2020)</p><p id="a5b6" class="pw-post-body-paragraph na nb it ma b mb nn ju nc md no jx nd mf np nf ng mh nq ni nj mj nr nl nm ml im bi translated">[2] Docker，<a class="ae ky" href="https://www.docker.com/" rel="noopener ugc nofollow" target="_blank"> Docker </a> (2020)</p><p id="7fe3" class="pw-post-body-paragraph na nb it ma b mb nn ju nc md no jx nd mf np nf ng mh nq ni nj mj nr nl nm ml im bi translated">[3]张量流，<a class="ae ky" href="https://www.tensorflow.org/tutorials/text/text_generation" rel="noopener ugc nofollow" target="_blank">张量流</a>，(2015)</p><ul class=""><li id="cca6" class="ly lz it ma b mb nn md no mf nt mh nu mj nv ml nw mn mo mp bi translated">致谢:</li></ul><pre class="kj kk kl km gt ob oa oc od aw oe bi"><span id="95e5" class="of lh it oa b gy og oh l oi oj">Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo,<br/>Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis,<br/>Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow,<br/>Andrew Harp, Geoffrey Irving, Michael Isard, Rafal Jozefowicz, Yangqing Jia,<br/>Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Mané, Mike Schuster,<br/>Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Jonathon Shlens,<br/>Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker,<br/>Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas,<br/>Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke,<br/>Yuan Yu, and Xiaoqiang Zheng.<br/>TensorFlow: Large-scale machine learning on heterogeneous systems,<br/>2015. Software available from tensorflow.org.</span></pre></div></div>    
</body>
</html>