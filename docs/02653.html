<html>
<head>
<title>Flask API for Multi-class classification using Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Keras进行多类分类的Flask API</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/flask-api-for-multi-class-classification-using-keras-4c9c7e85b5f2?source=collection_archive---------18-----------------------#2020-03-14">https://towardsdatascience.com/flask-api-for-multi-class-classification-using-keras-4c9c7e85b5f2?source=collection_archive---------18-----------------------#2020-03-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="901e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何使用Flask为深度学习模型创建生产就绪的API</h2></div><p id="ef02" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本文中，您将了解如何使用通过Keras和Flask构建的时尚MNIST数据集，为深度学习模型创建模块化的生产就绪库。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi le"><img src="../Images/9a2762165dd9b0cccee89c7df26351e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*MHP-6vr8VjklOz-irxzzcw.png"/></div></figure><p id="eb3c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="lm">深度学习模型生产就绪代码的关键特征是什么？</em></p><h2 id="bff8" class="ln lo it bd lp lq lr dn ls lt lu dp lv kr lw lx ly kv lz ma mb kz mc md me mf bi translated">面向生产的深度学习代码的特性</h2><ul class=""><li id="5b8e" class="mg mh it kk b kl mi ko mj kr mk kv ml kz mm ld mn mo mp mq bi translated"><strong class="kk iu">异常处理</strong>监控错误并在出现错误时理解代码流。</li><li id="9dae" class="mg mh it kk b kl mr ko ms kr mt kv mu kz mv ld mn mo mp mq bi translated"><strong class="kk iu">日志</strong>可以设置为不同的级别，如<em class="lm">调试、信息、警告、错误或关键</em>。在生产中，我们应该将日志记录级别设置为仅记录警告、错误和关键信息。</li><li id="eac0" class="mg mh it kk b kl mr ko ms kr mt kv mu kz mv ld mn mo mp mq bi translated"><strong class="kk iu">使用GitLab对代码进行版本控制</strong></li><li id="897f" class="mg mh it kk b kl mr ko ms kr mt kv mu kz mv ld mn mo mp mq bi translated"><strong class="kk iu">代码注释</strong>对于理解代码非常重要</li><li id="299c" class="mg mh it kk b kl mr ko ms kr mt kv mu kz mv ld mn mo mp mq bi translated"><strong class="kk iu">代码优化</strong>实现高效的内存使用和计算</li><li id="0f32" class="mg mh it kk b kl mr ko ms kr mt kv mu kz mv ld mn mo mp mq bi translated"><strong class="kk iu">容器化</strong>深度学习模型代码及其所有依赖库。</li></ul><p id="9d54" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将在另一篇文章中了解Docker以及如何将深度学习模型容器化。</p><h2 id="963f" class="ln lo it bd lp lq lr dn ls lt lu dp lv kr lw lx ly kv lz ma mb kz mc md me mf bi translated">创建配置类</h2><p id="aa5f" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">我们需要参数化一些用于微调深度学习模型的常见属性，可以使用Config类来完成。我们还添加了根据输入数据而变化的参数，以保持模型的通用性。</p><ul class=""><li id="f783" class="mg mh it kk b kl km ko kp kr mz kv na kz nb ld mn mo mp mq bi translated"><strong class="kk iu">输入数据集相关参数</strong>:图像尺寸——高度和宽度、数据集大小以及待识别类别的标签</li><li id="bf58" class="mg mh it kk b kl mr ko ms kr mt kv mu kz mv ld mn mo mp mq bi translated"><strong class="kk iu">模型微调参数</strong>:优化器、优化器的学习率、时期数和batch_size。我们还可以包括退出率、输入节点的数量、隐藏层的数量等。</li><li id="857d" class="mg mh it kk b kl mr ko ms kr mt kv mu kz mv ld mn mo mp mq bi translated"><strong class="kk iu">存储信息的文件</strong>:保存训练重量的重量文件和记录日志的日志文件名</li></ul><p id="9736" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以根据需要添加/删除配置参数。这些配置参数用于深度学习模型中的所有不同操作。</p><pre class="lf lg lh li gt nc nd ne nf aw ng bi"><span id="21e9" class="ln lo it nd b gy nh ni l nj nk"><strong class="nd iu">class Config(object):</strong><br/>    <br/>    <strong class="nd iu">IMAGE_HEIGHT=28<br/>    IMAGE_WIDTH=28<br/>    DATA_SIZE=1000<br/>    CLASS_NAME=<em class="lm">'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'</em></strong><br/>    <strong class="nd iu">WEIGHT_FILENAME='FashionMNIST.h5'<br/>    LOG_FILENAME='LOG_FASHION.TXT'<br/>    EPOCHS=100<br/>    OPTIMIZER='RMSProp'<br/>    LEARNING_RATE=0.001<br/>    BATCH_SIZE=64</strong><br/>    <br/>    <strong class="nd iu">def __init__(self):<br/>        self.IMAGE_DIM = (self.IMAGE_HEIGHT, self.IMAGE_WIDTH)</strong></span></pre><h2 id="68f5" class="ln lo it bd lp lq lr dn ls lt lu dp lv kr lw lx ly kv lz ma mb kz mc md me mf bi translated">建立分类模型</h2><p id="3f08" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">创建一个类<strong class="kk iu"><em class="lm">classFashionMNIST</em></strong>用于处理深度学习模型的不同方面。该类将有方法来</p><ul class=""><li id="d0b6" class="mg mh it kk b kl km ko kp kr mz kv na kz nb ld mn mo mp mq bi translated"><strong class="kk iu">归一化数据</strong></li><li id="7f92" class="mg mh it kk b kl mr ko ms kr mt kv mu kz mv ld mn mo mp mq bi translated"><strong class="kk iu">构建深度学习模型</strong></li><li id="8fe1" class="mg mh it kk b kl mr ko ms kr mt kv mu kz mv ld mn mo mp mq bi translated"><strong class="kk iu">训练模型</strong></li><li id="d14d" class="mg mh it kk b kl mr ko ms kr mt kv mu kz mv ld mn mo mp mq bi translated"><strong class="kk iu">使用模型</strong>进行预测</li><li id="288d" class="mg mh it kk b kl mr ko ms kr mt kv mu kz mv ld mn mo mp mq bi translated"><strong class="kk iu">显示来自数据集的图像</strong></li><li id="03fe" class="mg mh it kk b kl mr ko ms kr mt kv mu kz mv ld mn mo mp mq bi translated"><strong class="kk iu">从数据集中找到图像的实际类别</strong></li></ul><p id="8112" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">日志记录和异常处理是代码不可或缺的一部分，使其更加健壮。</strong></p><p id="beb5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">init()用于设置我们对类进行不同操作所需的参数，比如图像的高度、宽度、数据集大小以及我们想要预测的不同类。init()还用于读取时尚MNIST数据集以进行训练和验证，</p><pre class="lf lg lh li gt nc nd ne nf aw ng bi"><span id="b6e5" class="ln lo it nd b gy nh ni l nj nk"><strong class="nd iu">def __init__(self, height, width, data_size, class_name):<br/>        try:<br/>            self.height= height<br/>            self.width=width<br/>            self.data_size=data_size<br/>            self.class_names =list(class_name)<br/>            (self.train_images, self.train_labels), (self.test_images, self.test_labels) = tf.keras.datasets.fashion_mnist.load_data()<br/>            self.test_data= self.test_images<br/>        except:<br/>            logging.error("Error in init %s", sys.exc_info())</strong></span></pre><p id="5436" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">归一化数据集</strong></p><p id="364d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于图像中的像素强度介于1-255之间，因此通过在0和1之间缩放值来标准化图像</p><pre class="lf lg lh li gt nc nd ne nf aw ng bi"><span id="1d6b" class="ln lo it nd b gy nh ni l nj nk"><strong class="nd iu">def normalize_data(self):</strong><br/>        <strong class="nd iu"><em class="lm">try:</em><br/>            <em class="lm">logging.info("Normalizing data")</em><br/>            <br/>            </strong><em class="lm"># load train and test images and labels based on data size</em><strong class="nd iu"><br/>            self.train_labels = self.train_labels[:self.data_size]<br/>            self.test_labels = self.test_labels[:self.data_size]<br/>        <br/>            </strong><em class="lm">#Normalize the data</em><strong class="nd iu"><br/>            self.train_images = self.train_images[:self.data_size].astype('float32') / 255<br/>            self.test_images = self.test_images[:self.data_size].astype('float32') / 255<br/>           <em class="lm"> logging.info("Rshaping data")</em><br/>            </strong><em class="lm"># Reshape the data</em><strong class="nd iu"><br/>            self.train_images = self.train_images.reshape((self.train_images.shape[0],  self.width, self.height,1))<br/>            self.test_images = self.test_images.reshape((self.test_images.shape[0],  self.width, self.height,1))<br/>        <em class="lm">except:</em><br/>           <em class="lm"> logging.error("Error", sys.exc_info())</em></strong></span></pre><p id="cc55" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">创建深度学习分类模型</strong></p><p id="7e69" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们传递优化器和配置文件中设置的学习率来编译模型。由于深度学习模型是多类分类，使用的损失函数是<strong class="kk iu"><em class="lm">sparse _ categorial _ cross entropy。</em> </strong>如果做的是二元分类模型，那么用<strong class="kk iu"><em class="lm">binary _ cross entropy</em></strong>作为损失函数。</p><pre class="lf lg lh li gt nc nd ne nf aw ng bi"><span id="00a0" class="ln lo it nd b gy nh ni l nj nk"><strong class="nd iu">def create_model(self, optimizer, learning_rate):</strong><br/>        <strong class="nd iu"><em class="lm">try:</em></strong><br/>            <strong class="nd iu"><em class="lm">logging.info("Creatig model")</em></strong><br/>            <strong class="nd iu">model = tf.keras.Sequential()</strong><br/>           <em class="lm"> # Must define the input shape in the first layer of the neural network</em><br/>           <strong class="nd iu"> model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) <br/>            model.add(tf.keras.layers.MaxPooling2D(pool_size=2))<br/>            model.add(tf.keras.layers.Dropout(0.3))<br/>            model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))<br/>            model.add(tf.keras.layers.MaxPooling2D(pool_size=2))<br/>            model.add(tf.keras.layers.Dropout(0.3))</strong><br/>            <strong class="nd iu">model.add(tf.keras.layers.Flatten())<br/>            model.add(tf.keras.layers.Dense(256, activation='relu'))<br/>            model.add(tf.keras.layers.Dropout(0.5))<br/>            model.add(tf.keras.layers.Dense(10, activation='softmax'))</strong><br/>            <strong class="nd iu"><em class="lm">logging.info("Model Created")</em></strong><br/>            <em class="lm"># creating optimizer based on the config</em><br/>            <strong class="nd iu">opt= self.get_optimizer(optimizer, learning_rate)</strong><br/>            <br/>            <em class="lm">#Compiling the model</em><br/>            <strong class="nd iu">model.compile(loss='sparse_categorical_crossentropy',<br/>                     optimizer=opt,<br/>                     metrics=['accuracy'])</strong><br/>            <strong class="nd iu"><em class="lm">logging.info(" Model Compiled")</em></strong><br/>       <strong class="nd iu"><em class="lm"> except:<br/>            logging.error(" Error during Model Creation - %s", sys.exc_info())</em></strong><br/>       <strong class="nd iu"><em class="lm"> finally:</em></strong><br/>           <strong class="nd iu"> return model</strong></span></pre><p id="129f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">设置优化器</strong></p><p id="8243" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">处理了三个流行的优化器:<strong class="kk iu"> <em class="lm"> Adam，SGD，RMSProp </em> </strong>。RMSProp是默认的优化器，默认的学习率设置为0.001。我们可以其他<a class="ae nl" href="https://medium.com/datadriveninvestor/overview-of-different-optimizers-for-neural-networks-e0ed119440c3" rel="noopener">优化者</a>像<strong class="kk iu"> <em class="lm">动量、内斯特罗夫、阿达格勒、阿达德尔塔。</em> </strong></p><pre class="lf lg lh li gt nc nd ne nf aw ng bi"><span id="3907" class="ln lo it nd b gy nh ni l nj nk"><strong class="nd iu">def get_optimizer(self,optimizer_name='RMSProp', learning_rate=0.001):<br/>        <em class="lm">try:</em><br/>            if optimizer_name=='Adam':                <br/>                optimizer = optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, amsgrad=False)<br/>            elif optimizer_name=='SGD':<br/>                optimizer = optimizers.SGD(lr=learning_rate, momentum=0.9)<br/>            elif optimizer_name=='RMSProp':<br/>                optimizer = optimizers.RMSprop()<br/>           <em class="lm"> logging.info("Optimizer created %s", optimizer_name)</em><br/>            return optimizer<br/>        <em class="lm">except:<br/>             logging.error(" Error during visualization - %s", sys.exc_info())</em></strong></span></pre><p id="4403" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">训练模型</strong></p><p id="3c83" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">创建模型，归一化数据，最后在列车图像和列车标签上训练数据。</p><p id="ad3a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果准确度小于0.8或者验证准确度小于0.7，那么我们将在日志文件中发出警告，通知团队该模型可能需要重新训练。</p><pre class="lf lg lh li gt nc nd ne nf aw ng bi"><span id="c3e9" class="ln lo it nd b gy nh ni l nj nk"><strong class="nd iu">def train_model(self,filename, epochs, optimizer, learning_rate, batch_size):<br/>       <em class="lm"> try:</em><br/>            model = self.create_model(optimizer, learning_rate)<br/>            <em class="lm">logging.info("Model created ")<br/>            logging.info("Normalizing the data")</em><br/>            self.normalize_data()<br/>            <em class="lm">logging.info(self.train_images.shape)<br/>            logging.info("Training started")</em><br/>            history=model.fit(self.train_images, <br/>                  self.train_labels,  <br/>                  batch_size=batch_size,<br/>                  epochs=epochs,<br/>                  validation_data=(self.test_images,self.test_labels))<br/>            <em class="lm">logging.info(" Training finished")</em><br/>            acc= np.average(history.history['acc'])<br/>            val_acc=np.average(history.history['val_acc'])<br/>           <em class="lm"> logging.info(" Model accurcay on train images : {:5.2f}".format(acc))<br/>            logging.info("Accurcay too low for val {:5.2f}".format(val_acc))</em><br/>            model.save(filename)<br/>            <em class="lm">logging.info("Model saved %s", filename)</em><br/>            if acc &lt;.8 or val_acc&lt;0.7:<br/>                <em class="lm">logging.warn("Accurcay too low {:5.2f}".format(acc) )<br/>                logging.warn("Accurcay too low for val {:5.2f}".format(val_acc))</em><br/>            return history, model<br/>       <em class="lm"> except:<br/>             logging.error(" Error during Model Creation - %s", sys.exc_info())</em></strong></span></pre><p id="8b87" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">预测数据</strong></p><p id="87be" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了预测数据，我们传递测试图像的索引和包含训练权重的文件。</p><pre class="lf lg lh li gt nc nd ne nf aw ng bi"><span id="5095" class="ln lo it nd b gy nh ni l nj nk"><strong class="nd iu">def predict_data(self, test_image_num, filename):<br/>        <em class="lm">try:<br/>            logging.info("Predciting the data for %d", test_image_num)</em><br/>            test_img = self.test_images[test_image_num].reshape((1, self.width, self.height,1))<br/>            test_img=test_img.astype('float32') / 255<br/>            model = tf.keras.models.load_model(filename)<br/>            <em class="lm">logging.info("Loaded the trained weights from %s", filename)</em><br/>            pred= model.predict(test_img)<br/>            pred= np.argmax(pred)<br/>           <em class="lm"> logging.info("Predicted class  %s",self.class_names[pred] )</em><br/>            return self.class_names[pred]<br/>       <em class="lm"> except:<br/>            logging.error(" Error during Model predcition - %s", sys.exc_info())</em></strong></span></pre><p id="e1ad" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">测试图像的实际类别</strong></p><p id="4388" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因为我们使用了FashoinMNIST，所以我们知道可以用来比较输出的测试图像的类别</p><pre class="lf lg lh li gt nc nd ne nf aw ng bi"><span id="02c9" class="ln lo it nd b gy nh ni l nj nk"><strong class="nd iu">def actual_data(self,test_image_num):<br/>        return self.class_names[self.test_labels[test_image_num]]</strong></span></pre><h2 id="6470" class="ln lo it bd lp lq lr dn ls lt lu dp lv kr lw lx ly kv lz ma mb kz mc md me mf bi translated">classFashionMNIST类的完整代码</h2><pre class="lf lg lh li gt nc nd ne nf aw ng bi"><span id="94fd" class="ln lo it nd b gy nh ni l nj nk"><em class="lm">#Importing required libraries</em><br/><strong class="nd iu">import tensorflow as tf<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import sys<br/>import logging<br/>from tensorflow.keras import optimizers</strong></span><span id="db93" class="ln lo it nd b gy nm ni l nj nk"><em class="lm"># setting the random seed</em><br/><strong class="nd iu">np.random.seed(1)<br/>tf.compat.v1.set_random_seed(1)</strong></span><span id="eb26" class="ln lo it nd b gy nm ni l nj nk"><strong class="nd iu">class classFashionMNIST:</strong><br/>   <br/>    <em class="lm">'''<br/>    Method Name: init<br/>    Functionality: initializes the class<br/>    Parameters:  sets the height, width of the image,  data size and class labels<br/>    '''</em><br/>    <strong class="nd iu">def __init__(self, height, width, data_size, class_name):<br/>        <em class="lm">try:</em><br/>            self.height= height<br/>            self.width=width<br/>            self.data_size=data_size<br/>            self.class_names =list(class_name)<br/>            (self.train_images, self.train_labels), (self.test_images, self.test_labels) = tf.keras.datasets.fashion_mnist.load_data()<br/>            self.test_data= self.test_images<br/>        <em class="lm">except:</em><br/>            logging.error("Error in init %s", sys.exc_info())</strong><br/>        <br/>    <em class="lm">'''<br/>    Method Name: normalize data<br/>    Functionality: Normalizes the images pixel intensity values by<br/>                   scaling pixel values to the range 0-1 to centering and <br/>                   even standardizing the values.<br/>    Parameters:  None<br/>    '''</em><br/>    <strong class="nd iu">def normalize_data(self):</strong><br/>        <strong class="nd iu"><em class="lm">try:</em><br/>            logging.info("Normalizing data")<br/>            <br/>            # load train and test images and labels based on data size<br/>            self.train_labels = self.train_labels[:self.data_size]<br/>            self.test_labels = self.test_labels[:self.data_size]<br/>        <br/>            #Normalize the data<br/>            self.train_images = self.train_images[:self.data_size].astype('float32') / 255<br/>            self.test_images = self.test_images[:self.data_size].astype('float32') / 255<br/>            logging.info("Rshaping data")<br/>            # Reshape the data<br/>            self.train_images = self.train_images.reshape((self.train_images.shape[0],  self.width, self.height,1))<br/>            self.test_images = self.test_images.reshape((self.test_images.shape[0],  self.width, self.height,1))<br/>        <em class="lm">except:</em><br/>            logging.error("Error", sys.exc_info())</strong></span><span id="35e0" class="ln lo it nd b gy nm ni l nj nk"><em class="lm">'''<br/>    Method Name: create_mode<br/>    Functionality: Creates the deep learning model for multiclass classification<br/>    Parameters:  optimizer - optimizers can be Adam, SGD or RMSProp<br/>                 Learning_rate- learning rate of the optimizer<br/>    '''</em></span><span id="5c32" class="ln lo it nd b gy nm ni l nj nk"><strong class="nd iu">def create_model(self, optimizer, learning_rate):<br/>        <em class="lm">try:</em><br/>            <em class="lm">logging.info("Creatig model")</em><br/>            model = tf.keras.Sequential()<br/>           </strong><em class="lm"> # Must define the input shape in the first layer of the neural network</em><strong class="nd iu"><br/>            model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) <br/>            model.add(tf.keras.layers.MaxPooling2D(pool_size=2))<br/>            model.add(tf.keras.layers.Dropout(0.3))<br/>            model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))<br/>            model.add(tf.keras.layers.MaxPooling2D(pool_size=2))<br/>            model.add(tf.keras.layers.Dropout(0.3))<br/>            model.add(tf.keras.layers.Flatten())<br/>            model.add(tf.keras.layers.Dense(256, activation='relu'))<br/>            model.add(tf.keras.layers.Dropout(0.5))<br/>            model.add(tf.keras.layers.Dense(10, activation='softmax'))<br/>            <em class="lm">logging.info("Model Created")</em><br/>           </strong><em class="lm"> # creating optimizer based on the config</em><strong class="nd iu"><br/>            opt= self.get_optimizer(optimizer, learning_rate)<br/>            <br/>           </strong><em class="lm"> #Compiling the model</em><strong class="nd iu"><br/>            model.compile(loss='sparse_categorical_crossentropy',<br/>                     optimizer=opt,<br/>                     metrics=['accuracy'])<br/>           <em class="lm"> logging.info(" Model Compiled")</em><br/>       <em class="lm"> except</em>:<br/>            <em class="lm">logging.error(" Error during Model Creation - %s", sys.exc_info())<br/>        finally:</em><br/>            return model</strong></span><span id="8b77" class="ln lo it nd b gy nm ni l nj nk"><em class="lm">'''<br/>    Method Name: train_model<br/>    Functionality: Trains the deep learning multiclass classification model<br/>    Parameters:  filename : File o save the trained weights<br/>                 epochs : No. of epcohs to train the model<br/>                 optimizer - optimizers can be Adam, SGD or RMSProp<br/>                 Learning_rate- learning rate of the optimizer<br/>                 Batch_size - batch_size of the dataset to train the model<br/>    ''' </em><br/>    <strong class="nd iu">def train_model(self,filename, epochs, optimizer, learning_rate, batch_size):<br/>        <em class="lm">try:</em><br/>            model = self.create_model(optimizer, learning_rate)<br/>            <em class="lm">logging.info("Model created ")<br/>            logging.info("Normalizing the data")</em><br/>            self.normalize_data()<br/>            <em class="lm">logging.info(self.train_images.shape)<br/>            logging.info("Training started")</em><br/>            history=model.fit(self.train_images, <br/>                  self.train_labels,  <br/>                  batch_size=batch_size,<br/>                  epochs=epochs,<br/>                  validation_data=(self.test_images,self.test_labels))<br/>            <em class="lm">logging.info(" Training finished")</em><br/>            acc= np.average(history.history['acc'])<br/>            val_acc=np.average(history.history['val_acc'])<br/>            <em class="lm">logging.info(" Model accurcay on train images : {:5.2f}".format(acc))</em><br/>           <em class="lm"> logging.info("Accurcay too low for val {:5.2f}".format(val_acc))</em><br/>            model.save(filename)<br/>            <em class="lm">logging.info("Model saved %s", filename)</em><br/>            if acc &lt;.8 or val_acc&lt;0.7:<br/>                <em class="lm">logging.warn("Accurcay too low {:5.2f}".format(acc) )<br/>                logging.warn("Accurcay too low for val {:5.2f}".format(val_acc))</em><br/>            return history, model<br/>        <em class="lm">except:<br/>             logging.error(" Error during Model Creation - %s", sys.exc_info())</em></strong></span><span id="fef9" class="ln lo it nd b gy nm ni l nj nk"><em class="lm">'''<br/>    Method Name: predict_data<br/>    Functionality: predicts the data for  multiclass classification model<br/>    Parameters: test_image_num - index of the test image that we want to predcit <br/>               filename : File containing  the trained weights<br/>                 <br/>    ''' </em><br/>    <strong class="nd iu">def predict_data(self, test_image_num, filename):<br/>        <em class="lm">try:<br/>            logging.info("Predciting the data for %d", test_image_num)</em><br/>            test_img = self.test_images[test_image_num].reshape((1, self.width, self.height,1))<br/>            test_img=test_img.astype('float32') / 255<br/>            model = tf.keras.models.load_model(filename)<br/>            <em class="lm">logging.info("Loaded the trained weights from %s", filename)</em><br/>            pred= model.predict(test_img)<br/>            pred= np.argmax(pred)<br/>           <em class="lm"> logging.info("Predicted class  %s",self.class_names[pred] )</em><br/>            return self.class_names[pred]<br/>       <em class="lm"> except:<br/>            logging.error(" Error during Model predcition - %s", sys.exc_info())</em></strong></span><span id="83ef" class="ln lo it nd b gy nm ni l nj nk"><em class="lm">'''<br/>     Method Name: actual_data<br/>    Functionality: Retrives the actual class for the test image based on the index passed<br/>    Parameters: test_image_num - index of the test image that we want to predcit <br/>    '''<br/></em><strong class="nd iu">    def actual_data(self,test_image_num):<br/>        return self.class_names[self.test_labels[test_image_num]]<br/>    <br/>    <br/>    <br/>   <em class="lm"> '''<br/>    Method Name: get_optimizer<br/>    Functionality: Creates the optimizers based on passed parameter and learning rate<br/>    Parameters:  Optimizer_name - optimizers can be Adam, SGD or RMSProp<br/>                 Learning_rate- learning rate of the optimizer<br/>    ''' </em></strong> <br/>    <strong class="nd iu">def get_optimizer(self,optimizer_name='RMSProp', learning_rate=0.001):<br/>        <em class="lm">try</em>:<br/>            if optimizer_name=='Adam':                <br/>                optimizer = optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, amsgrad=False)<br/>            elif optimizer_name=='SGD':<br/>                optimizer = optimizers.SGD(lr=learning_rate, momentum=0.9)<br/>            elif optimizer_name=='RMSProp':<br/>                optimizer = optimizers.RMSprop()<br/>            <em class="lm">logging.info("Optimizer created %s", optimizer_name)</em><br/>            return optimizer<br/>       <em class="lm"> except:<br/>             logging.error(" Error during visualization - %s", sys.exc_info())</em></strong></span></pre><h2 id="5156" class="ln lo it bd lp lq lr dn ls lt lu dp lv kr lw lx ly kv lz ma mb kz mc md me mf bi translated">使用Flask创建API</h2><p id="51a8" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">阅读这里的<a class="ae nl" href="https://levelup.gitconnected.com/simple-api-using-flask-bc1b7486af88" rel="noopener ugc nofollow" target="_blank">，对如何使用Flask </a>创建一个基本API有一个基本的了解</p><p id="dc04" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">导入使用Flask API、classFashionMNIST、FashionMNIST配置类和日志记录类所需的库。</p><p id="9113" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通过创建Flask的一个实例来创建一个应用程序对象，我们将一个预定义的变量“__name__”传递给它，这是我们的模块的名称。</p><pre class="lf lg lh li gt nc nd ne nf aw ng bi"><span id="cea2" class="ln lo it nd b gy nh ni l nj nk">from flask import Flask, jsonify, request<br/>from flask_restful import  Api, Resource<br/>import numpy as np<br/>from Fashion_MNIST import classFashionMNIST<br/>from FashionConfig import Config as cfg<br/>import logging<br/>import absl.logging</span><span id="490b" class="ln lo it nd b gy nm ni l nj nk">app=Flask(__name__)</span></pre><p id="26c1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们编写了两个GET方法，一个用于进行预测，一个用于检索实际的类</p><pre class="lf lg lh li gt nc nd ne nf aw ng bi"><span id="78fb" class="ln lo it nd b gy nh ni l nj nk"><a class="ae nl" href="http://twitter.com/app" rel="noopener ugc nofollow" target="_blank"><strong class="nd iu">@app</strong></a><strong class="nd iu">.route("/predict", methods=["GET"])<br/>def predict():<br/>    pred =""<br/>    posted_data = request.get_json()<br/>    test_image_num=posted_data['test_image_num']<br/>    logging.info("In Predict")<br/>    model_filename=cfg.WEIGHT_FILENAME<br/>    pred= fashionMNISTclass.predict_data(test_image_num, model_filename)<br/>    return jsonify(pred)</strong></span><span id="70dc" class="ln lo it nd b gy nm ni l nj nk"><a class="ae nl" href="http://twitter.com/app" rel="noopener ugc nofollow" target="_blank"><strong class="nd iu">@app</strong></a><strong class="nd iu">.route("/real", methods=["GET"])<br/>def real():<br/>    data =""<br/>    posted_data = request.get_json()<br/>    test_image_num=posted_data['test_image_num']<br/>    data = fashionMNISTclass.actual_data(test_image_num)<br/>    return jsonify(data)</strong></span></pre><p id="5e98" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我使用的是TF 1.14，因此我们需要禁用abseil-py，这样日志就不会被重定向到stderr。我们根据配置参数中指定的日志文件名来设置日志文件</p><p id="b54f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">加载API时训练数据集，因此等待预测，直到模型完全加载和编译</p><pre class="lf lg lh li gt nc nd ne nf aw ng bi"><span id="2342" class="ln lo it nd b gy nh ni l nj nk"><strong class="nd iu">if __name__ == '__main__':</strong><br/>    <strong class="nd iu"><em class="lm">logging.root.removeHandler(absl.logging._absl_handler)</em></strong><br/>    <strong class="nd iu">absl.logging._warn_preinit_stderr = False</strong><br/>    <strong class="nd iu">logging.basicConfig(filename=cfg.LOG_FILENAME, filemode='a', format='%(filename)s-%(asctime)s %(msecs)d- %(process)d-%(levelname)s - %(message)s', <br/>                    datefmt='%d-%b-%y %H:%M:%S %p' ,<br/>                    level=logging.DEBUG)</strong><br/>   <strong class="nd iu"> fashionMNISTclass= classFashionMNIST(cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH, cfg.DATA_SIZE, cfg.CLASS_NAME)</strong><br/>   <em class="lm"> # noramlize the data</em><br/>    <strong class="nd iu">fashionMNISTclass.normalize_data()</strong><br/>    <em class="lm"># train the model</em><br/><strong class="nd iu">    history, model =  history, model = fashionMNISTclass.train_model(cfg.WEIGHT_FILENAME, <br/>                                                   cfg.EPOCHS,<br/>                                                   cfg.OPTIMIZER,<br/>                                                   cfg.LEARNING_RATE,<br/>                                                   cfg.BATCH_SIZE) <br/>    app.run(debug=True)</strong></span></pre><p id="908a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用postman测试预测方法</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi nn"><img src="../Images/2d5a979a8cf34d9411066f868febcf69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jb6bXFZWGxiLG8XgZPLouw.png"/></div></div></figure><p id="f672" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">检查实际的类名</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi ns"><img src="../Images/b1133857650284c0ad4e9f5d47536de1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uf3S8B7vHdev7xpZqXGVRg.png"/></div></div></figure><p id="6eaa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">完整的代码可在<a class="ae nl" href="https://github.com/arshren/Classification-Fashion-MNIST" rel="noopener ugc nofollow" target="_blank">这里</a></p><h2 id="8e98" class="ln lo it bd lp lq lr dn ls lt lu dp lv kr lw lx ly kv lz ma mb kz mc md me mf bi translated">结论:</h2><p id="7fc8" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">现在，您可以使用Keras为二进制或多类分类模型编写一个生产就绪的代码了。可以对代码进行许多调整，本文中提到了其中一些。</p></div></div>    
</body>
</html>