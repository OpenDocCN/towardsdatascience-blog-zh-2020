<html>
<head>
<title>Deep Learning for Computer Vision</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算机视觉的深度学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-for-computer-vision-c4e5f191c522?source=collection_archive---------35-----------------------#2020-05-26">https://towardsdatascience.com/deep-learning-for-computer-vision-c4e5f191c522?source=collection_archive---------35-----------------------#2020-05-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4daa" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">理解CNN的卷积层、池层和全连接层</h2></div><p id="5aca" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">计算机视觉中的深度学习在短时间内取得了快速进展。深度学习在计算机视觉中的一些应用包括人脸识别系统、自动驾驶汽车等。</p><p id="cc42" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">本文介绍了卷积神经网络，也称为<em class="le"> convnets </em>，这是一种广泛用于计算机视觉应用的深度学习模型。我们将深入了解它的组件、卷积层、池层和全连接层等层，以及如何应用它们来解决各种问题。</p><p id="e918" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以让我们开始吧。</p><h2 id="4dc0" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">有线电视新闻网的目标:</h2><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/8172117321b52265729323cb1e126161.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*sR9mRTHr4OstpweTX_GjXg.png"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">猫</p></figure><p id="255c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上面是一只猫的图片，小时候我们被告知这种动物是猫。随着我们长大，学习和看到更多猫的图像，我们的大脑记录了它的各种特征，如眼睛、耳朵、面部结构、胡须等。下一次我们看到具有这些特征的动物图像时，我们能够预测它是一只猫，因为这是我们从经验中学到的。</p><p id="f640" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们需要在计算机上模拟同样的行为。这类问题在计算机视觉中被称为图像分类问题，我们试图识别图像中存在的对象。</p><p id="9986" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">给定一幅图像，首先计算机应该能够提取它的特征，然后根据这些特征，预测那个物体是什么。他们如何实现这一目标？嗯，简单的答案是通过CNN。他们是如何做到这一点的，我们将深入探讨。</p><h2 id="0da8" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">CNN简介:</h2><p id="b0fc" class="pw-post-body-paragraph ki kj it kk b kl mk ju kn ko ml jx kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated">因此，CNN的目标是执行两个任务:第一个是特征提取，第二个是聚集所有提取的特征并基于它进行预测。</p><p id="d781" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在我们深入研究各个组件之前，让我们看看CNN是什么样子的。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/304a657819701dd317c44ec4dd7967dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*eSaiQvbaIYhSTJS4.jpg"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">描绘Conv、池化和全连接层的CNN架构示例来源:<a class="ae mq" href="https://www.learnopencv.com/wp-content/uploads/2017/11/cnn-schema1.jpg" rel="noopener ugc nofollow" target="_blank">https://www . learnopencv . com/WP-content/uploads/2017/11/CNN-schema 1 . jpg</a></p></figure><p id="a79e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从上图中，我们可以看到三种类型的层，分别是:<strong class="kk iu">卷积层、汇聚层和全连接层</strong>。(我们将在接下来的章节中讨论这些)</p><p id="4637" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果上面的图片没有完全理解，那也没关系。我们看到这一点的原因是为了在脑海中想象CNN是什么样子，这样一旦我们理解了它的各个层次，我们就可以很容易地将这些点联系起来。</p><h2 id="9665" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">卷积运算:</h2><p id="24f9" class="pw-post-body-paragraph ki kj it kk b kl mk ju kn ko ml jx kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated">卷积是细胞神经网络的基本构件之一。卷积运算的主要目的是从输入图像中提取边缘、曲线、拐角、梯度方向等特征。我们将通过一个边缘检测示例来理解卷积运算。</p><p id="9cb5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">给定一幅图像，我们想要提取该图像中所有的水平和垂直边缘。下图描述了同样的情况。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/2031d5b02f90357da9678e097cd06f0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/format:webp/1*T8uQWRrqu4SnkKoVR4JGRA.png"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">卷积运算的例子</p></figure><p id="ce11" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">假设我们有一个6x6的灰度图像。现在，为了检测图像中的边缘，我们构建了一个3x3的矩阵。在CNN的术语中，它被称为过滤器或内核。使用这两个矩阵，我们将执行卷积运算。结果矩阵，即卷积运算的输出将是大小为4×4的矩阵。下图描述了同样的情况。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi ms"><img src="../Images/5090c99d5560a89cd91c9541faedfc75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UhGYFE2WCZ0SMzUHpdL3hg.png"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">卷积运算的例子</p></figure><p id="dd55" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，我们如何计算得到的4x4矩阵的元素如下:<br/>为了计算左上角的元素，我们将使用3x3滤镜并将其粘贴到原始输入图像的3x3区域的顶部。接下来，我们将做元素方面的乘积来给出我们想要的值。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi mx"><img src="../Images/6c1af102a6e9c7ce285c6e8dd8908355.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8_MGDuFvoI9fXi4E3LwiwQ.png"/></div></div></figure><p id="e4e3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来，为了计算第二个元素，我们将滤波器(即黄色方块)向右移动一步，进行相同的元素乘积，然后将它们相加。同样，我们可以填充该行的所有元素。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi my"><img src="../Images/de43e291b300d396a408fbe3f36e4c5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u8KJAjCGVZ9S8tuPrx2SHw.png"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">向右滑动过滤器一步以获得所需的值</p></figure><p id="5f74" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，为了获得下一行中的元素，我们将把过滤器向下移动到下一行，重复相同的元素级乘积，并将它们相加。因此，我们可以同样地填充其余的元素。下面向我们展示了最终的结果。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi mz"><img src="../Images/e31975c2276ad4413afb1a9cb71ba396.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Re7VBZ3jviL-3CIzQRsYJA.png"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">卷积运算</p></figure><p id="6a93" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里有几点。当使用3×3矩阵进行卷积时，6×6矩阵得到4×4矩阵。这些本质上是矩阵。但是左边的矩阵便于解释为输入图像，中间的一个解释为滤波器，右边的一个解释为输出特征。</p><p id="8d9a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">输出特征尺寸的计算如下:</p><pre class="lz ma mb mc gt na nb nc nd aw ne bi"><span id="89a1" class="lf lg it nb b gy nf ng l nh ni">n x n input image       f x f filter</span><span id="ec65" class="lf lg it nb b gy nj ng l nh ni"><strong class="nb iu">output dimension = (n - f + 1)</strong></span><span id="4a73" class="lf lg it nb b gy nj ng l nh ni">Above example:        6 x 6 input image       3 x 3 filter<br/>                      (6 - 3 + 1) x (6 - 3 + 1)<br/>output dimensions =   4 x 4</span></pre><p id="e8d0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意:我们的过滤器的值通常被称为权重。我们如何决定重量值是在训练中学到的。它们用一些随机值初始化，并随着每个训练步骤不断调整。</p><h2 id="8397" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">填料</h2><p id="c8c5" class="pw-post-body-paragraph ki kj it kk b kl mk ju kn ko ml jx kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated">每次执行卷积运算时，我们都会丢失边界像素中的一些信息。此外，我们的形象缩小了一点。有时，我们会希望减少输出大小，以节省训练期间的资源消耗。然而，有时我们可能希望保持输出和输入的空间维度不变。为此，我们可以使用填充的概念。</p><p id="b7ec" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">填充只是在输入要素的每一侧添加适当数量的行和列。填充实质上使过滤器产生的特征图与原始图像的大小相同。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/17328b5f27b712d981768d9482c127ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/1*1okwhewf5KCtIPaFib4XaA.gif"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">带填充的卷积，p = 1来源:<a class="ae mq" href="https://github.com/vdumoulin/conv_arithmetic" rel="noopener ugc nofollow" target="_blank">https://github.com/vdumoulin/conv_arithmetic</a></p></figure><p id="3516" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在图(左)中，一个尺寸为5x5的蓝色正方形代表我们的输入图像，它通过在每边添加几行零来填充。当使用3×3滤波器进行卷积时，输出维数与输入维数相同，即5×5，如绿色方块所示。如果我们没有使用填充，输出尺寸将是3x3。因此，填充1保持了输入和输出的空间维度相同。</p><h2 id="443d" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">有效且相同的填充</h2><p id="c3c9" class="pw-post-body-paragraph ki kj it kk b kl mk ju kn ko ml jx kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated">让我们根据是否添加填充来理解术语。</p><p id="df83" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">有效</strong>:当卷积期间没有添加填充，并且我们的结果输出是收缩尺寸时。示例:</p><pre class="lz ma mb mc gt na nb nc nd aw ne bi"><span id="0798" class="lf lg it nb b gy nf ng l nh ni">Input size:   6 x 6   (i x i)<br/>Filter size:  3 x 3   (f x f)<br/>Output size: (i – f + 1)<br/>             (6 – 3 + 1) = 4<br/>             = 4 x 4</span></pre><p id="a552" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">相同</strong>:添加填充，使输出尺寸与输入尺寸相同时。为了计算输出尺寸，我们对上面的公式进行了修改，以考虑填充参数。示例:</p><pre class="lz ma mb mc gt na nb nc nd aw ne bi"><span id="4fdf" class="lf lg it nb b gy nf ng l nh ni">Input size:        6 x 6   (i x i)<br/>Filter size:       3 x 3   (f x f)<br/>Padding:           1       (p)<br/>Output size:       <strong class="nb iu">(i + 2p - f +1)</strong>    <br/>                   (6 + 2x1 – 3 + 1) = 6<br/>                   = 6 x 6</span></pre><p id="09a1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意:按照惯例，滤波器尺寸<em class="le"> f </em>通常是奇数，否则填充将是不对称的。一些最常用的过滤器尺寸为3x3、5x5和1x1。</p><h2 id="a4e4" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">阔步</h2><p id="7cf8" class="pw-post-body-paragraph ki kj it kk b kl mk ju kn ko ml jx kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated">在我们的工作示例中，为了计算下一个元素，我们将过滤器向右移动一位。我们在输入图像上移动过滤器的行数是我们的步幅参数。</p><p id="fd47" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">跨距定义了遍历图像时滤波器的步长。默认情况下，在任何框架中它都可能是1。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/736539d77018b425e62c49305912fd11.png" data-original-src="https://miro.medium.com/v2/resize:fit:588/1*BMngs93_rm2_BpJFH2mS0Q.gif"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">步幅s = 2的卷积来源:<a class="ae mq" href="https://github.com/vdumoulin/conv_arithmetic" rel="noopener ugc nofollow" target="_blank">https://github.com/vdumoulin/conv_arithmetic</a></p></figure><p id="d623" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在左图中，一个5x5的蓝色方块代表我们的输入图像。使用3x3滤波器进行卷积时，步长值为2，我们得到了尺寸为2x2的下采样输出图。如果我们保持stride为1，输出维度将是3x3。</p><p id="3611" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，我们可以在训练中增加步幅(步)长度以节省空间或减少计算时间。然而，当这样做时，我们将放弃一些信息，因此这是资源消耗(无论是CPU还是内存)和从输入中检索信息之间的权衡。</p><p id="fb43" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意:一般来说，我们通常将步幅值保持为1，并使用其他方法对我们的特征地图进行下采样，如使用池图层。</p><h2 id="47c3" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">卷积运算概述:</h2><p id="7b0b" class="pw-post-body-paragraph ki kj it kk b kl mk ju kn ko ml jx kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated">卷积运算的主要目的是从输入图像中提取有意义的信息，如边缘、曲线等。下面的动画总结了卷积运算中元素的计算方式。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/f69a11dd5b13b3974d1138f43cf87c93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/1*HwY42fhWPFnb8X6hUg1WXQ.gif"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">卷积运算概述</p></figure><p id="92d0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下等式总结了输出要素地图的尺寸。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/56135be4b7d28ab6ec099faf82382f3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/1*l3Rg614Ickwa3Nu2QJe_8g.png"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">公式</p></figure><p id="2b1d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用上述等式的示例:</p><pre class="lz ma mb mc gt na nb nc nd aw ne bi"><span id="a686" class="lf lg it nb b gy nf ng l nh ni"><strong class="nb iu">6x6</strong> input image,  <strong class="nb iu">3x3</strong> filter    |    <strong class="nb iu">7x7</strong> input image, <strong class="nb iu">3x3</strong> filter<br/>padding <strong class="nb iu">p=1</strong>   &amp;  stride, <strong class="nb iu">s=1</strong>    |    padding <strong class="nb iu">p=1</strong>  &amp;  stride, <strong class="nb iu">s=2</strong><br/>                                |<br/>                                |<br/>Output size:                    |    Output size:<br/>(6 + 2*1 – 3)/1 + 1 = 6         |    (7 + 2*1 - 3)/2 = 4<br/><strong class="nb iu">6 x 6</strong>                           |    <strong class="nb iu">4 x 4</strong></span></pre><h2 id="04d1" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">体积卷积:</h2><p id="58ac" class="pw-post-body-paragraph ki kj it kk b kl mk ju kn ko ml jx kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated">我们已经完成了矩阵的卷积运算。现在让我们了解如何对体积执行卷积运算，这将使它更加强大。以前我们有一个6x6的灰度图像。现在，让我们假设我们有一个6x6的RGB图像，因此它的尺寸将为6x6x3，而不是3x3的滤镜，这次我们将使用3x3x3的滤镜。</p><p id="51f2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">输出大小仍为4x4(与之前相同)，但是，元素的计算方法是在每个通道中执行元素乘积，然后将它们相加，如下所示:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi no"><img src="../Images/4ff9337f8bbe5f2464dd7fa22ae5e99c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*YbMg0PBCEItY1cncBSL8xA.png"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">体积卷积:每个通道中的元素乘积，然后将它们相加。来源:<a class="ae mq" href="https://indoml.com/2018/03/07/student-notes-convolutional-neural-networks-cnn-introduction/" rel="noopener ugc nofollow" target="_blank">https://indoml . com/2018/03/07/student-notes-convolutionary-neural-networks-CNN-introduction/</a></p></figure><p id="bd95" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里需要注意的一点是，输入和滤波器中的通道数必须相等。我们这样做的原因是，它允许我们在不同通道上使用不同的滤波器，比如在所有通道中使用边缘检测器，以提取更有意义的信息。所以想法是一样的。在输出要素地图中获取尽可能多的信息。</p><p id="fc3d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意:过滤器中的通道数通常没有明确规定。假设它等于输入的深度。例如，如果我们有一个尺寸为26x26x64的输入，我们使用一个尺寸为3x3的滤波器进行卷积，这意味着滤波器中的通道数将为64，因此其实际尺寸为3x3x64。</p><h2 id="6ee5" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">使用多个过滤器的卷积:</h2><p id="cd87" class="pw-post-body-paragraph ki kj it kk b kl mk ju kn ko ml jx kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated">现在我们知道如何对体积进行卷积，那么增加滤波器的数量怎么样？每个过滤器提取一些特征，像一个是提取垂直边缘，另一个是水平或45度线等。换句话说，扩展卷积以使用多个滤波器。</p><p id="d930" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">扩展我们的工作示例，我们仍然有一个6x6x3的输入。现在，我们有两个3x3维度的过滤器，而不是一个(深度为3是隐含的)。使用每个滤波器以类似的方式执行卷积操作。因此，我们将获得两个4x4输出特征地图。将一个堆叠在另一个之上，我们可以说输出尺寸为4x4x2，如下所示:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi np"><img src="../Images/ce3fc9157fc629dff94768a8128eb1f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*rsE8omVdHdmXEQsCdrM1rg.png"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">使用2个滤波器的卷积。输出是两个4x4特征地图。每个过滤器一个来源:<a class="ae mq" href="https://indoml.com/2018/03/07/student-notes-convolutional-neural-networks-cnn-introduction/" rel="noopener ugc nofollow" target="_blank">https://indoml . com/2018/03/07/student-notes-convolutionary-neural-networks-CNN-introduction/</a></p></figure><p id="76e6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，我们现在可以根据过滤器的数量来检测多个特征。卷积的真正力量得到了释放，因为现在我们可以从输入中提取大量的语义信息。</p><p id="4596" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们考虑一个例子来理解多个过滤器中存在的值(权重)的数量:</p><pre class="lz ma mb mc gt na nb nc nd aw ne bi"><span id="3a96" class="lf lg it nb b gy nf ng l nh ni">Input Volume dimensions: <strong class="nb iu">26x26x64</strong>      <br/>filter Size: <strong class="nb iu">3x3</strong>(since input depth=64, filter depth will also be 64)<br/>and we have <strong class="nb iu">32</strong> such filters being used for feature extraction</span><span id="ea25" class="lf lg it nb b gy nj ng l nh ni"><strong class="nb iu">Hence, total number of weights in our filter will be:</strong><br/>  weights in one filter = <strong class="nb iu">3 x 3 x 64 = 576</strong><br/>  Total filters = <strong class="nb iu">32</strong><br/>  Total weights = <strong class="nb iu">32 x 576 = 18,432</strong></span></pre><p id="03bd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这都是关于卷积运算的。现在让我们看看CNN中的典型卷积层是什么样子的:</p><h2 id="6b4d" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">卷积层:</h2><p id="884c" class="pw-post-body-paragraph ki kj it kk b kl mk ju kn ko ml jx kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated">在上面的例子中，我们得到了两个4x4的输出图。现在，我们将为每个输出图添加一个偏差。偏差是一个实数，我们将它添加到每个特征图的所有16个元素中。偏差就像线性方程中添加的截距，用于模拟真实世界的场景。然后，我们将通过应用激活函数来添加非线性。</p><p id="23d3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">没有激活函数的神经网络将简单地是线性回归模型<strong class="kk iu">，</strong>，其能力有限，并且在大多数时间不能很好地工作。如果没有激活功能，我们的神经网络将无法学习和模拟复杂类型的数据，如图像、视频等。</p><p id="b63e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">激活函数有多种选择，最流行的是ReLU激活函数。</p><blockquote class="nq nr ns"><p id="3b98" class="ki kj le kk b kl km ju kn ko kp jx kq nt ks kt ku nu kw kx ky nv la lb lc ld im bi translated">ReLU函数如果看到正整数，将返回相同的数字，如果看到负数，将返回零。</p></blockquote><p id="a24f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">它纠正了消失梯度问题。此外，从<em class="le"> tanh </em>激活函数来看，它在收敛方面好了6倍。(关于激活功能的更多信息将在另一篇文章中介绍)。</p><p id="7a19" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下图描述了偏置加法，并将ReLU激活应用于我们的示例:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi nw"><img src="../Images/0367f6665b022c18a57779880dee6c61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*INw2xvSv4RK274Pbt6DF4g.png"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">卷积层的整体计算</p></figure><p id="56c7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们从6x6x3到4x4x2输出图的整个计算是CNN中的一个卷积层。卷积运算的目的是从输入图像中提取高级特征，例如边缘。<em class="le"> Convnets </em>不需要仅限于单个卷积层。</p><p id="7425" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">传统上，第一卷积层负责捕获低级特征，例如边缘、颜色、梯度方向等。随着图层的增加，该架构也适应了高级功能，为我们提供了一个对数据集中的图像有全面了解的网络，就像我们会做的那样。</p><h2 id="e56d" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">池层:</h2><p id="1ea3" class="pw-post-body-paragraph ki kj it kk b kl mk ju kn ko ml jx kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated">除了卷积层，<em class="le"> convnets </em>还使用池层来减少我们的表示大小，以加快计算速度。池化负责减小卷积要素的空间大小，从而降低处理数据所需的计算能力。</p><p id="987b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该操作的工作原理如下:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/367f3b55a0d1ccf9e34c4575b672bdeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:824/format:webp/1*nHnPlvF7oZNW4db0OuEgrA.png"/></div></figure><p id="ae14" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在图(左)中，以步幅2遍历输入图像上的2×2窗口，并且最大值保留在每个象限中。这被称为最大池操作。</p><p id="37af" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最常见的形式是池图层，其大小为2x2的过滤器以2的步长应用，沿宽度和高度对输入中的每个深度切片进行2倍缩减采样。直觉是，如果在任何象限中存在一个特性，池将通过保持激活功能将启动的高数值来试图保留该特性</p><p id="c22b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">池化减少了要处理的要素地图系数的数量，并促使网络学习要素的空间等级，即，使连续的卷积层根据它们覆盖的原始输入的部分来查看越来越大的窗口。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/a0d32d74509d3eb126b058c9ecbe26ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*h_gDIJ-1Lyau9WkateUyyw.png"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">两种类型的汇集操作</p></figure><p id="ce6a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有两种类型的池:最大和平均池<strong class="kk iu">。</strong>最大池返回过滤器覆盖的图像部分的最大值。平均池返回内核覆盖的图像部分的所有值的平均值。</p><p id="cd2b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意:在池化层的培训中没有需要学习的参数。具有较大感受野的池大小具有太大的破坏性。</p><h2 id="48a3" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">完全连接层:</h2><p id="e5cb" class="pw-post-body-paragraph ki kj it kk b kl mk ju kn ko ml jx kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated">完全连接图层的目的是获取卷积/池化过程的结果，并使用它们将图像分类到标签中。这些层的作用与传统深度神经网络中的层相同。主要区别是输入将是由CNN的早期阶段(卷积层和池层)创建的形状和形式。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/f76c7ee8b7f071721b0bc5da1b348f83.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*tb7f_uBb8dGD9z5u4g63FQ.png"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">完全连接的层</p></figure><p id="a109" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">展平是将数据转换为一维数组，以将其输入到完全连接的层。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/9018b8dd9bc3cabf0e1fce9193a39774.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*ofuLHQXWgU9KjVAhrAIvsA.png"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">展平，FC输入层，FC输出层</p></figure><p id="d696" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">FC输入层将展平的矢量作为输入，并应用权重和激活来预测正确的标签。FC输出层给出了每个标签的最终概率。两层的区别在于激活功能。ReLU输入，softmax输出。(我们将在另一篇文章中对此进行更深入的讨论)</p><h2 id="cf1f" class="lf lg it bd lh li lj dn lk ll lm dp ln kr lo lp lq kv lr ls lt kz lu lv lw lx bi translated">总结:</h2><ul class=""><li id="1e15" class="ob oc it kk b kl mk ko ml kr od kv oe kz of ld og oh oi oj bi translated">CNN主要有两个目标:特征提取和分类。</li><li id="4bcd" class="ob oc it kk b kl ok ko ol kr om kv on kz oo ld og oh oi oj bi translated">CNN有三层，即卷积层、汇集层和全连接层。CNN的每一层都学习越来越复杂的过滤器。</li><li id="1a09" class="ob oc it kk b kl ok ko ol kr om kv on kz oo ld og oh oi oj bi translated">第一层学习基本的特征检测过滤器:边缘、拐角等</li><li id="0810" class="ob oc it kk b kl ok ko ol kr om kv on kz oo ld og oh oi oj bi translated">中间层学习检测物体部分的过滤器。对于面部，他们可能会学会对眼睛、鼻子等做出反应</li><li id="f644" class="ob oc it kk b kl ok ko ol kr om kv on kz oo ld og oh oi oj bi translated">最后一层有更高的表现:他们学习识别不同形状和位置的完整物体。</li></ul><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi op"><img src="../Images/f35bf16b0f57074d0efd49c4b7928902.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*mNKVcZ35kdQP3kYG65V7mA.png"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">CNN架构示例</p></figure><p id="605f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要实现一个示例CNN，您可以在这里按照<a class="ae mq" href="https://github.com/rktayal/multiclass_training_cnn" rel="noopener ugc nofollow" target="_blank">的指导实现</a>。</p></div></div>    
</body>
</html>