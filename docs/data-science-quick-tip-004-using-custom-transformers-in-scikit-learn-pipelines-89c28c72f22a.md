# æ•°æ®ç§‘å­¦å¿«é€Ÿæç¤º#004:åœ¨ Scikit ä¸­ä½¿ç”¨è‡ªå®šä¹‰è½¬æ¢å™¨-å­¦ä¹ ç®¡é“ï¼

> åŸæ–‡ï¼š<https://towardsdatascience.com/data-science-quick-tip-004-using-custom-transformers-in-scikit-learn-pipelines-89c28c72f22a?source=collection_archive---------37----------------------->

![](img/e23a790849d2a19366fe76a1b313f950.png)

## äº†è§£å¦‚ä½•åœ¨åŒä¸€ä¸ª Scikit-Learn ç®¡é“ä¸­ä½¿ç”¨å®šåˆ¶æ•°æ®è½¬æ¢å™¨

å¤§å®¶å¥½ã€‚å…³äºå¦‚ä½•åˆ›å»º Scikit-Learn ç®¡é“ï¼Œæˆ‘ä»¬åˆå›æ¥äº†ï¼Œè¿™æ˜¯ä¸Šä¸€ç¯‡æ–‡ç« çš„åç»­æ–‡ç« ã€‚å¦‚æœä½ é”™è¿‡äº†ï¼Œä½ ç°åœ¨å¯ä»¥ç‚¹å‡»é“¾æ¥æŸ¥çœ‹[ã€‚(å®ƒç°åœ¨æ­£å¼å‘å¸ƒåˆ°ã€Šèµ°å‘æ•°æ®ç§‘å­¦ã€‹ã€‚w00tï¼)å’Œå¾€å¸¸ä¸€æ ·ï¼Œå¦‚æœä½ æƒ³ç›´æ¥è·Ÿéšè¿™ç¯‡æ–‡ç« çš„ä»£ç ï¼Œä½ å¯ä»¥åœ¨æˆ‘çš„ä¸ªäºº GitHub](/data-science-quick-tip-003-using-scikit-learn-pipelines-66f652f26954) æ‰¾åˆ°[ã€‚](https://github.com/dkhundley/ds-quick-tips/tree/master/004_pipeline_custom_transformers)

ä¸ºäº†å¿«é€Ÿç»“æŸä¸Šä¸€ç¯‡æ–‡ç« ï¼Œæˆ‘ä»¬å·²ç»æˆåŠŸåœ°åˆ›å»ºäº†ä¸€ä¸ª Scikit-Learn ç®¡é“ï¼Œå®ƒåœ¨ä¸€ä¸ªå¹²å‡€çš„å°åŒ…ä¸­å®Œæˆäº†æ‰€æœ‰çš„æ•°æ®è½¬æ¢ã€ç¼©æ”¾å’Œæ¨ç†ã€‚ä½†æ˜¯åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬ä¸å¾—ä¸åœ¨æˆ‘ä»¬çš„ç®¡é“ä¸­ä½¿ç”¨ Scikit-Learn çš„é»˜è®¤è½¬æ¢å™¨ã€‚è™½ç„¶è¿™äº›å˜å½¢é‡‘åˆšå¾ˆæ£’ï¼Œä½†æ˜¯å¦‚æœæˆ‘ä»¬å¯ä»¥åˆ©ç”¨è‡ªå·±çš„è‡ªå®šä¹‰å˜å½¢ï¼Œé‚£ä¸æ˜¯å¾ˆæ£’å—ï¼Ÿå½“ç„¶äº†ï¼æˆ‘è®¤ä¸ºè¿™ä¸ä»…å¾ˆæ£’ï¼Œè€Œä¸”å¾ˆæœ‰å¿…è¦ã€‚å¦‚æœä½ è¿˜è®°å¾—ä¸Šå‘¨çš„å¸–å­ï¼Œæˆ‘ä»¬å»ºç«‹äº†ä¸€ä¸ªåŸºäºå•ä¸€ç‰¹å¾çš„æ¨¡å‹ã€‚é‚£å¯ä¸å¤ªå¥½é¢„æµ‹å•Šï¼

å› æ­¤ï¼Œæˆ‘ä»¬å°†é€šè¿‡æ·»åŠ ä¸¤ä¸ªè½¬æ¢å™¨æ¥è½¬æ¢è®­ç»ƒæ•°æ®é›†ä¸­çš„ä¸¤ä¸ªé¢å¤–å­—æ®µï¼Œä»è€Œè§£å†³è¿™ä¸€é—®é¢˜ã€‚(æˆ‘çŸ¥é“ï¼Œä» 1 ä¸ªåŠŸèƒ½å¢åŠ åˆ° 3 ä¸ªåŠŸèƒ½ä»ç„¶ä¸æ˜¯å¾ˆå¥½ã€‚ä½†æ˜¯ï¼Œå˜¿ï¼Œè‡³å°‘æˆ‘ä»¬å¢åŠ äº† 300%ï¼Ÿ)æˆ‘ä»¬å¼€å§‹æ—¶çš„åŸå§‹å˜é‡æ˜¯â€œæ€§åˆ«â€(åˆåæ€§åˆ«)ï¼Œç°åœ¨æˆ‘ä»¬å°†ä¸ºé€‚å½“çš„â€œå¹´é¾„â€åˆ—å’Œâ€œä¸Šèˆ¹â€åˆ—æ·»åŠ  transformersã€‚

åœ¨æˆ‘ä»¬å¼€å§‹æ–°çš„å®šåˆ¶å˜å½¢é‡‘åˆšä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆå¯¼å…¥åº“ã€‚ä½ å¯èƒ½è¿˜è®°å¾—ä¸Šä¸€ç¯‡æ–‡ç« ä¸­çš„è®¸å¤šå†…å®¹ï¼Œä½†æ˜¯æˆ‘ä»¬å¢åŠ äº†ä¸€äº›é¢å¤–çš„å†…å®¹ã€‚ä¸è¦å¤ªæ‹…å¿ƒå®ƒä»¬ç°åœ¨æ˜¯ä»€ä¹ˆï¼Œå› ä¸ºæˆ‘ä»¬å°†åœ¨åé¢çš„æ–‡ç« ä¸­è¿›ä¸€æ­¥è®¨è®ºã€‚

```
# Importing the libraries weâ€™ll be using for this project
import pandas as pd
import joblibfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix
```

æˆ‘ä»¬å°†ç»§ç»­å¿«é€Ÿå¯¼å…¥æˆ‘ä»¬çš„åŸ¹è®­æ•°æ®ã€‚

```
# Importing the training dataset
raw_train = pd.read_csv(â€˜../data/titanic/train.csvâ€™)# Splitting the training data into appropriate training and validation sets
X = raw_train.drop(columns = [â€˜Survivedâ€™])
y = raw_train[[â€˜Survivedâ€™]]X_train, X_val, y_train, y_val = train_test_split(X, y, random_state = 42)
```

å¥½äº†ï¼Œä»ç°åœ¨å¼€å§‹ï¼Œæˆ‘ä»¬å®é™…ä¸Šä¸ä¼šæ”¹å˜ Scikit-Learn ç®¡é“æœ¬èº«ã€‚å½“ç„¶ï¼Œæˆ‘ä»¬ä¼šå¯¹å…¶è¿›è¡Œæ·»åŠ ï¼Œä½†æ˜¯è¯·è®°ä½ï¼Œæˆ‘æœ‰æ„å°†æˆ‘çš„æ•°æ®é¢„å¤„ç†å™¨è®¾è®¡æˆæ˜“äºæ·»åŠ çš„æ–¹å¼ã€‚ç®€å•å›é¡¾ä¸€ä¸‹ä¸Šä¸€ç¯‡æ–‡ç« ï¼Œä¸‹é¢æ˜¯æ„å»ºåŸå§‹ç®¡é“çš„ä»£ç ã€‚

```
# Creating a preprocessor to transform the â€˜Sexâ€™ column
data_preprocessor = ColumnTransformer(transformers = [
   (â€˜sex_transformerâ€™, OneHotEncoder(), [â€˜Sexâ€™])
])# Creating our pipeline that first preprocesses the data, then scales the data, then fits the data to a RandomForestClassifier
rfc_pipeline = Pipeline(steps = [
   (â€˜data_preprocessingâ€™, data_preprocessor),
   (â€˜data_scalingâ€™, StandardScaler()),
   (â€˜modelâ€™, RandomForestClassifier(max_depth = 10,
                                    min_samples_leaf = 3,
                                    min_samples_split = 4,
                                    n_estimators = 200))
])
```

å½“ç„¶ï¼Œåœ¨å°†è‡ªå®šä¹‰è½¬æ¢å™¨æ·»åŠ åˆ°ç®¡é“ä¹‹å‰ï¼Œæˆ‘ä»¬å¯ä»¥åšçš„ç¬¬ä¸€ä»¶äº‹æ˜¯åˆ›å»ºå‡½æ•°è½¬æ¢å™¨ï¼å› æ­¤ï¼Œæ­£å¦‚æ‚¨å¯èƒ½å·²ç»çŒœåˆ°çš„é‚£æ ·ï¼Œå®šåˆ¶è½¬æ¢å™¨æ˜¯å»ºç«‹åœ¨å¸¸è§„å‡½æ•°ä¹‹ä¸Šçš„ï¼Œå› æ­¤æ‚¨å¯ä»¥ä¸ºè½¬æ¢å™¨ç¼–å†™ä»»ä½•æ‚¨æƒ³è¦çš„ Python å‡½æ•°ã€‚****(æˆ‘ä»¬ç¨åå°†è®¨è®ºæ‰€æœ‰è¿™äº›æ˜Ÿå·â€¦â€¦)

å¥½äº†ï¼Œæˆ‘ä»¬è®¨è®ºäº†ä¸ºä¸¤ä¸ªæ–°å˜é‡æ·»åŠ ä¸¤ä¸ªè½¬æ¢å™¨ï¼Œç°åœ¨è®©æˆ‘ä»¬å¼€å§‹åˆ›å»ºä¸¤ä¸ªè‡ªå®šä¹‰ Python å‡½æ•°å§ï¼é¦–å…ˆè§¦åŠâ€œå¹´é¾„â€åˆ—ï¼Œæˆ‘ä»¬å°†å¯¹è¿™ä¸ªå˜é‡æœ‰ä¸€ç‚¹é¢å¤–çš„ä¹è¶£ã€‚ç°åœ¨ï¼Œæˆ‘çœŸçš„ä¸çŸ¥é“å¹´é¾„æœ¬èº«æ˜¯å¦æ˜¯ä¸€ä¸ªé¢„æµ‹å˜é‡ï¼Œä½†æˆ‘çŒœæƒ³ï¼Œå¦‚æœâ€œå¹´é¾„â€å¯ä»¥ä»¥ä»»ä½•æœ‰æ„ä¹‰çš„æ–¹å¼é¢„æµ‹ï¼Œå®ƒå°†æ˜¯å¹´é¾„ç±»åˆ«/å¹´é¾„ç®±ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘å°†å¹´é¾„åˆ’åˆ†ä¸ºâ€œå„¿ç«¥â€ã€â€œæˆäººâ€ã€â€œè€äººâ€ç­‰ç±»åˆ«ã€‚åŒæ ·ï¼Œæˆ‘ä¸çŸ¥é“è¿™æ˜¯å¦ä¼šæ¯”ä½¿ç”¨ç›´æ¥æ•´æ•°æ›´æœ‰æ€§èƒ½ï¼Œä½†å®ƒè®©æˆ‘ä»¬å¯ä»¥åšä¸€äº›æœ‰è¶£çš„äº‹æƒ…ï¼ä¸‹é¢æ˜¯è¿™æ ·çš„ä»£ç :

```
# Creating a function to appropriately engineer the â€˜Ageâ€™ column
def create_age_bins(col):
    â€˜â€™â€™Engineers age bin variables for pipelineâ€™â€™â€™

    # Defining / instantiating the necessary variables
    age_bins = [-1, 12, 18, 25, 50, 100]
    age_labels = [â€˜childâ€™, â€˜teenâ€™, â€˜young_adultâ€™, â€˜adultâ€™, â€˜elderâ€™]
    age_imputer = SimpleImputer(strategy = â€˜medianâ€™)
    age_ohe = OneHotEncoder()

    # Performing basic imputation for nulls
    imputed = age_imputer.fit_transform(col)
    ages_filled = pd.DataFrame(data = imputed, columns = [â€˜Ageâ€™])

    # Segregating ages into age bins
    age_cat_cols = pd.cut(ages_filled[â€˜Ageâ€™], bins = age_bins, labels = age_labels)
    age_cats = pd.DataFrame(data = age_cat_cols, columns = [â€˜Ageâ€™])

    # One hot encoding new age bins
    ages_encoded = age_ohe.fit_transform(age_cats[[â€˜Ageâ€™]])
    ages_encoded = pd.DataFrame(data = ages_encoded.toarray())

    return ages_encoded
```

å¥½äº†ï¼Œæ¥ä¸‹æ¥æ˜¯â€œä¸Šèˆ¹â€ä¸“æ ã€‚ç°åœ¨ï¼Œè¿™å·²ç»*å‡ ä¹*å‡†å¤‡å¥½è¿›è¡Œç›´æ¥çš„çƒ­ç¼–ç äº†ï¼Œä½†æ˜¯æˆ‘ä»¬ä¸èƒ½ç›´æ¥è·³åˆ°é‚£é‡Œçš„åŸå› æ˜¯å› ä¸ºè¿™ä¸ªåˆ—ä¸­æœ‰ä¸€äº›ç©ºå€¼ã€‚è¿™äº›éœ€è¦é¦–å…ˆè§£å†³ï¼Œæ‰€ä»¥è¿™é‡Œæ˜¯æˆ‘ä»¬å°†åœ¨è¿™é‡Œä½¿ç”¨çš„è‡ªå®šä¹‰è½¬æ¢å™¨ã€‚

```
# Creating function to appropriately engineer the â€˜Embarkedâ€™ column
def create_embarked_columns(col):
    â€˜â€™â€™Engineers the embarked variables for pipelineâ€™â€™â€™

    # Instantiating the transformer objects
    embarked_imputer = SimpleImputer(strategy = â€˜most_frequentâ€™)
    embarked_ohe = OneHotEncoder()

    # Performing basic imputation for nulls
    imputed = embarked_imputer.fit_transform(col)
    embarked_filled = pd.DataFrame(data = imputed, columns = [â€˜Embarkedâ€™])

    # Performing OHE on the col data
    embarked_columns = embarked_ohe.fit_transform(embarked_filled[[â€˜Embarkedâ€™]])
    embarked_columns_df = pd.DataFrame(data = embarked_columns.toarray())

 return embarked_columns_df
```

æ—¢ç„¶æˆ‘ä»¬å·²ç»ç¼–å†™äº†è‡ªå®šä¹‰å‡½æ•°ï¼Œæˆ‘ä»¬ç»ˆäºå¯ä»¥å°†å®ƒä»¬æ·»åŠ åˆ°ç®¡é“ä¸­äº†ã€‚ä½ å¯èƒ½ä¸çŸ¥é“ï¼Œä½†æ˜¯ Scikit-Learn æœ‰ä¸€ä¸ªç‰¹æ®Šçš„æ–¹æ³•æ¥å¤„ç†è¿™äº›ç‰¹æ®Šçš„è‡ªå®šä¹‰è½¬æ¢å™¨ï¼Œå«åš **FunctionTransformer** ã€‚è¿™å¾ˆå®¹æ˜“å®ç°ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬çœ‹çœ‹å½“æˆ‘ä»¬æŠŠå®ƒæ·»åŠ åˆ°æˆ‘ä»¬åŸæ¥çš„ç®¡é“æ—¶æ˜¯ä»€ä¹ˆæ ·å­ã€‚

```
# Creating a preprocessor to transform the â€˜Sexâ€™ column
data_preprocessor = ColumnTransformer(transformers = [
    (â€˜sex_transformerâ€™, OneHotEncoder(), [â€˜Sexâ€™]),
    (â€˜age_transformerâ€™, FunctionTransformer(create_age_bins, validate = False), [â€˜Ageâ€™]),
    (â€˜embarked_transformerâ€™, FunctionTransformer(create_embarked_columns, validate = False), [â€˜Embarkedâ€™])
])# Creating our pipeline that first preprocesses the data, then scales the data, then fits the data to a RandomForestClassifier
rfc_pipeline = Pipeline(steps = [
    (â€˜data_preprocessingâ€™, data_preprocessor),
    (â€˜data_scalingâ€™, StandardScaler()),
    (â€˜modelâ€™, RandomForestClassifier(max_depth = 10,
                                     min_samples_leaf = 3,
                                     min_samples_split = 4,
                                     n_estimators = 200))
])
```

å¾ˆç®€å•ï¼Œå¯¹å§ï¼Ÿä½¿ç”¨ Scikit-Learn function transformer æŒ‡å‘æ­£ç¡®çš„è‡ªå®šä¹‰å‡½æ•°ï¼Œå¹¶åœ¨æŒ‡å®šçš„åˆ—ä¸Šä½¿ç”¨å®ƒï¼Œè¿™å¾ˆç®€å•ã€‚ä»ç°åœ¨å¼€å§‹ï¼Œè¿™æ˜¯æ¨¡å‹çš„ç®€å•å¯¼å‡ºã€‚

```
# Fitting the training data to our pipeline
rfc_pipeline.fit(X_train, y_train)# Saving our pipeline to a binary pickle file
joblib.dump(rfc_pipeline, â€˜model/rfc_pipeline.pklâ€™)
```

*** * * *å›åˆ°æ˜Ÿå·æ—¶ä»£ï¼ï¼ï¼**

æ‰€ä»¥â€¦â€¦..ä½¿ç”¨å®šåˆ¶å˜å‹å™¨ä¹Ÿæœ‰ä¸å¥½çš„ä¸€é¢â€¦

åºåˆ—åŒ–æ¨¡å‹ä¸å­˜å‚¨ä»»ä½•è‡ªå®šä¹‰ Python å‡½æ•°çš„ä»£ç æœ¬èº«ã€‚(è‡³å°‘â€¦ä¸æ˜¯ä»¥æˆ‘è¿˜æ²¡æƒ³å‡ºæ¥çš„æ–¹å¼ã€‚)ä¹Ÿå°±æ˜¯è¯´ï¼Œ ***ä¸ºäº†åˆ©ç”¨è¿™ä¸ªååºåˆ—åŒ–çš„æ¨¡å‹ï¼Œpickle å¿…é¡»èƒ½å¤Ÿå¼•ç”¨ä¸ºå…¶è‡ªèº«äºŒè¿›åˆ¶å€¼*** ä¹‹å¤–çš„å‡½æ•°è½¬æ¢å™¨ç¼–å†™çš„ç›¸åŒä»£ç ã€‚æˆ–è€…é€šä¿—åœ°è¯´ï¼Œæ‚¨éœ€è¦å°†æ‚¨çš„å®šåˆ¶ Python å‡½æ•°æ·»åŠ åˆ°æ‚¨ä¸ºè¿™æ ·çš„æ¨¡å‹ç¼–å†™çš„ä»»ä½•éƒ¨ç½²è„šæœ¬ä¸­ã€‚

ç°åœ¨ï¼Œè¿™æ˜¯ä¸æ˜¯æœ‰ç‚¹çƒ¦äººï¼Ÿæ˜¯çš„ã€‚ä½†æ˜¯è¿™ç»™äº†æˆ‘ä¸€ä¸ªä¸ä½¿ç”¨å®šåˆ¶è½¬æ¢çš„ç†ç”±å—ï¼Ÿè¿™æ˜¯ä¸€ä¸ªç®€å•è€Œåšå®šçš„ç­”æ¡ˆã€‚æˆ‘çŸ¥é“ä¸ºç®¡é“è¿è¡Œæä¾›é¢å¤–çš„å®šåˆ¶ä»£ç ä¸å¤ªæ–¹ä¾¿ï¼Œä½†ä»£ä»·æ˜¯è¿›è¡Œè½¬æ¢ï¼Œè¿™å¯èƒ½ä¼šä½¿æ¨¡å‹çš„æ€§èƒ½æ¯”å…¶ä»–æƒ…å†µå¥½å¾—å¤šã€‚

æ‰€ä»¥ï¼Œæ˜¯çš„ï¼Œè¿™æœ‰ç‚¹ç³Ÿç³•ï¼Œä½†å˜¿ï¼Œæˆ‘ä¼šé€‰æ‹©åŒ…æ‹¬è‡ªå®šä¹‰å˜å½¢é‡‘åˆšæ¯æ¬¡æœ€æœ‰å¯èƒ½ã€‚å¤§å¤šæ•°æ•°æ®é›†åŒ…å«å¹¿æ³›çš„ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾è‚¯å®šä¸ä¼šåˆ†è§£æˆç®€å•çš„è½¬æ¢ï¼Œå¦‚æ’è¡¥æˆ–ä¸€æ¬¡çƒ­ç¼–ç ã€‚çœŸå®çš„æ•°æ®æ˜¯æ‚ä¹±çš„ï¼Œç»å¸¸éœ€è¦å¤§é‡çš„ç‰¹æ®Šæ¸…ç†ï¼Œè€Œè¿™äº›å®šåˆ¶çš„è½¬æ¢å™¨æ­£å¥½é€‚åˆè¿™é¡¹å·¥ä½œã€‚

è¿™å°±æ˜¯è¿™ç¯‡æ–‡ç« çš„å…¨éƒ¨å†…å®¹ï¼å¸Œæœ›ä½ å–œæ¬¢ã€‚å¦‚æœä½ æƒ³è®©æˆ‘åœ¨ä»¥åçš„å¸–å­ä¸­æ¶‰åŠä»»ä½•å…·ä½“çš„å†…å®¹ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼æˆ‘è„‘å­é‡Œè¿˜æœ‰æ›´å¤šçš„æƒ³æ³•ï¼Œæ‰€ä»¥è¯·ç»§ç»­å…³æ³¨ã€‚ğŸ˜ƒ