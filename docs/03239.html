<html>
<head>
<title>Variational Autoencoders (VAEs) for Dummies — Step By Step Tutorial</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于假人的可变自动编码器(VAEs)——循序渐进教程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/variational-autoencoders-vaes-for-dummies-step-by-step-tutorial-69e6d1c9d8e9?source=collection_archive---------3-----------------------#2020-03-28">https://towardsdatascience.com/variational-autoencoders-vaes-for-dummies-step-by-step-tutorial-69e6d1c9d8e9?source=collection_archive---------3-----------------------#2020-03-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="532c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">DIY实践指南与实践代码的建设和培训与Keras的名人脸上的VAEs</h2></div><p id="93d3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">本文介绍了您需要从生成模型中获得的一切。我们提供了如何在大型图像数据集上训练条件值并使用它们生成新的标记图像的分步指南。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/836695b2b93a34ea5637662f4eb3dc40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xTHdAyflX_FbrUJTzEK-mA.jpeg"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">Pladicon在<a class="ae lu" href="https://pixabay.com/images/id-4899802/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>拍摄的照片</p></figure><h1 id="a2e6" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">动机</h1><p id="e64f" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">既然已经有这么多数据，为什么我们还需要生成新的数据？据<a class="ae lu" href="https://www.forbes.com/sites/tomcoughlin/2018/11/27/175-zettabytes-by-2025/#6af1bdb35459" rel="noopener ugc nofollow" target="_blank"> IDC </a>称，目前有超过18兆字节的数据。</p><p id="aad0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">大多数机器学习任务都需要标记数据。获取高质量、有标签的数据是困难的。如果我们自己生成这些数据，我们就可以随心所欲地利用它们。新的数据可以给我们想法和选择。</p><blockquote class="ms"><p id="f670" class="mt mu it bd mv mw mx my mz na nb ld dk translated">如何生成看不见的图像？</p></blockquote><p id="11fa" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">在这篇文章中，你将学习什么是<strong class="kk iu">变分自动编码器</strong>，以及如何创建自己的变分自动编码器来生成新的和看不见的图像。我们不用数学来解释潜在的概念和直觉。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nh"><img src="../Images/73636963e3b2349b7aa600466d227819.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WhMFSptTVKlEIQ55KHi36A.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">使用我们的VAE码(自创)的图像及其重建的例子</p></figure><h1 id="778f" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">数据</h1><p id="277b" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">我们将使用知名名人数据集的子集来帮助我们建立面部生成模型。数据集可以按照<a class="ae lu" href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html" rel="noopener ugc nofollow" target="_blank">名人脸网站</a>上的描述下载。它提供了一个大规模的人脸属性数据集，包含超过20万张名人图片，每张图片都有40个属性注释。</p><ul class=""><li id="2037" class="ni nj it kk b kl km ko kp kr nk kv nl kz nm ld nn no np nq bi translated">10177个身份，</li><li id="d750" class="ni nj it kk b kl nr ko ns kr nt kv nu kz nv ld nn no np nq bi translated">202，599个面部图像，</li><li id="2a8d" class="ni nj it kk b kl nr ko ns kr nt kv nu kz nv ld nn no np nq bi translated">5个地标位置，以及</li><li id="1cd7" class="ni nj it kk b kl nr ko ns kr nt kv nu kz nv ld nn no np nq bi translated">每个图像40个二进制属性注释。</li></ul><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nw nx l"/></div></figure><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ny"><img src="../Images/3ca2d8994b278b84258fbd92bca05d55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YDReqbPNuiyfXMNJZTJhYQ.png"/></div></div></figure><p id="3011" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面我们从名人数据集中随机挑选一些面孔，并显示他们的元数据(属性)。图像高度为218像素，宽度为178像素，有3个颜色通道。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nw nx l"/></div></figure><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/d75b4c119f9c7de1f2323fe99b65b1b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*GWRAfqyAujnnC2NiL0v8Pg.png"/></div></figure><h1 id="cd19" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">什么是自动编码器(AE)？</h1><p id="ea0b" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">通过观察数以千计的名人面孔，神经网络可以学习生成不存在的人的面孔。</p><p id="55d3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">神经网络是我们可以用来获得函数近似值的许多可能方法之一。他们受欢迎的一个原因是他们学习表达的能力。假设我们为网络提供了正确的标签，网络可以学习在将图像分类为狗或猫时重要的特定表示。这是监督学习。</p><p id="51ac" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在某些情况下，我们没有这些标签。然而，我们可以训练两个网络，一个学习表示，另一个通过最小化重建损失函数从表示中重建。这是一个自动编码器。它之所以有这个名字，是因为它会自动找到编码输入的最佳方式，以便解码后的版本尽可能接近输入。</p><p id="0975" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">自动编码器由一对两个相连的神经网络组成:编码器模型和解码器模型。它的目标是找到一种方法将名人的脸编码成一种压缩的形式(潜在空间)，以这种方式重建的版本尽可能接近输入。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi oa"><img src="../Images/c3edf14f71ffe5d7ba5dd137e6eb255a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1qf4VBOqSuLFFTFGHEVWJw.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">自动编码器的工作组件(自行创建)</p></figure><p id="dbaa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">编码器模型将输入<em class="ob"> x </em>转换为小型密集表示<em class="ob"> z </em>，类似于卷积神经网络通过使用滤波器来学习表示的工作方式。</p><p id="83fd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">解码器模型可以被视为能够生成特定特征<em class="ob">x’</em>的生成模型。</p><p id="3709" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">编码器和解码器通常作为一个整体来训练。损失函数惩罚网络创建不同于输入面的输出面。</p><p id="5df9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，编码器学会在有限的潜在空间中保存尽可能多的相关信息，并巧妙地丢弃不相关的部分，例如噪声。</p><p id="ad57" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">解码器学习获取压缩的潜在信息，并将其重建为完整的名人脸。</p><p id="c129" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">自动编码器也可以用于维度减少和<a class="ae lu" rel="noopener" target="_blank" href="/why-deep-learning-works-289f17cab01a">图像去噪</a>，但也可以成功用于<a class="ae lu" href="https://arxiv.org/pdf/1710.11041.pdf" rel="noopener ugc nofollow" target="_blank">无监督机器翻译</a>。</p><h1 id="4cd2" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">什么是变分自动编码器(VAE)？</h1><p id="9844" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">通常，编码器产生的潜在空间<em class="ob"> z </em>人口稀少，这意味着很难预测该空间中值的分布。在2D制图表达中，值是分散的，空间似乎得到了很好的利用。</p><p id="df29" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这对于压缩系统来说是一个非常好的特性。然而，对于生成新的名人图像，这种稀疏性是一个问题，因为找到解码器将知道如何产生有效图像的潜在值几乎是不可能的。</p><p id="26a2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">此外，如果空间在簇之间有间隙，并且解码器从那里接收到变化，它将缺乏生成有用的东西的知识。</p><p id="a8bd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">变分自动编码器</strong>通过使潜在空间更可预测、更连续、更少稀疏来工作。通过强制潜在变量成为正态分布，VAEs获得对潜在空间的控制。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi oc"><img src="../Images/d1b70967e5753534e9a8a6c238d2c422.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IVN69fj20RxDzMPhPKhAxA.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">从AE到VAE使用随机变量(自创)</p></figure><p id="9b85" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">VAEs不是将潜在值直接转发给解码器，而是使用它们来计算平均值和标准偏差。然后从相应的正态分布中对解码器的输入进行采样。</p><p id="c049" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在训练过程中，VAEs通过在损失函数中包含kull back-lei bler散度，迫使该正态分布尽可能接近标准正态分布。VAE将会改变或探索脸部的变化，而且不只是以随机的方式，而是朝着一个期望的、特定的方向。</p><p id="3844" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">条件变分自动编码器</strong>允许基于潜在变量z和附加信息(如面部元数据(微笑、眼镜、肤色等))对输入进行建模。).</p><h1 id="9180" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">图像数据生成器</strong></h1><p id="d80b" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">让我们建立一个(有条件的)可以在名人脸上学习的VAE。我们使用定制的Keras内存高效生成器来处理我们的大型数据集(202599张图像，ca。每个10KB)。这背后的想法是在训练过程中即时获得批量图像。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nw nx l"/></div></figure><h1 id="48e5" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">VAE网</strong></h1><p id="d61e" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">我们希望编码器是一个卷积神经网络，它获取图像并输出分布参数<em class="ob"> Q(z|[x，c]) </em>其中<em class="ob"> x </em>是人脸的输入图像，<em class="ob"> c </em>是条件变量(人脸的属性)，而<em class="ob"> z </em>是潜在变量。对于本文，我们使用一个由两个卷积层和一个池层组成的简单架构。</p><p id="cc4e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">解码器是一个反过来构建的卷积神经网络。它是一个生成网络，向似然分布<em class="ob"> P([x，c]|z) </em>输出参数。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="b620" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">整个VAE网络的架构创建如下。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nw nx l"/></div></figure><h1 id="22d6" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">培养</h1><p id="8900" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">下图显示了celebA数据集中图像的VAE模型的学习过程。代码在使用1个GPU的AWS实例上运行了大约8个小时。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nw nx l"/></div></figure><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi oc"><img src="../Images/4fc1251369971bb397f8ee1611f1d357.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CioOngBnwE4BjzW6yLMFPw.png"/></div></div></figure><h1 id="6d30" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">可视化潜在表征</h1><p id="d161" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">经过训练后，我们现在可以从我们的数据集中随机选取一幅图像，并使用经过训练的编码器来创建图像的潜在表示。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nw nx l"/></div></figure><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi od"><img src="../Images/a7d9f9f73525f5dc8563bea8d8c16662.png" data-original-src="https://miro.medium.com/v2/resize:fit:530/format:webp/1*ixvMVLIClHFOeJhI80mFig.png"/></div></figure><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/3d3325addb2925a63633ab5bc89d74f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*yGFNgrf9l1dTgwcc_xGqVw.png"/></div></figure><p id="ac5d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用16个实数的向量的潜在表示，我们可以可视化解码器如何重建原始图像。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nw nx l"/></div></figure><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi of"><img src="../Images/2c2c8ae76d2b004ad316abc5fe566047.png" data-original-src="https://miro.medium.com/v2/resize:fit:538/format:webp/1*1EN1-RbaF-xKt9ZjGNCbcg.png"/></div></figure><p id="41ba" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然重建的图像很模糊，但我们可以看到与原始图像有很强的相似性:性别、衣服颜色、头发、微笑、肤色。</p><h1 id="9504" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">生成看不见的面孔</h1><p id="0a6e" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">条件值能够改变潜在空间以产生新数据。具体来说，我们可以使用解码器生成一个不可见图像的随机计数，同时根据给定的属性对其进行调节。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nw nx l"/></div></figure><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi og"><img src="../Images/2f6788318ae71a4992015d7951d43615.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Av8kS85quZpJLOVa-nNyng.png"/></div></div></figure><p id="b8fe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然我们的变分自动编码器产生了模糊和非真实感的人脸，但我们可以识别那些从未存在过的人类的性别、肤色、微笑、眼镜、头发颜色。</p><h1 id="22bc" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">给人们一个微笑</h1><p id="8d9c" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">条件值可以在属性之间进行插值，使一张脸微笑，或者在以前没有眼镜的地方添加眼镜。下面，我们从数据集中随机选择一张名人脸，并利用潜在表征的改变，将其从女性脸变形为男性脸。我们也改变这些脸来展示原本不存在的微笑。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nw nx l"/></div></figure><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/db6fc9ba479e7051ebbe118791fd9e36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*0G2Ngv-BdI-WQuZL8xRtIQ.png"/></div></figure><h1 id="d61b" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="5869" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">在本文中，我们介绍了条件变分自动编码器，并演示了它们如何学习如何生成新的标记数据。</p><p id="6d53" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们提供了Python代码，用于在大型名人图像数据集上训练VAEs。该方法和代码可以扩展到多个其他用例。</p><p id="0635" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">生成敌对网络(GANs)往往会产生更好看的图像，因为它们学会了区分什么对人类来说是真实感的，什么不是。</p><div class="oi oj gp gr ok ol"><a rel="noopener follow" target="_blank" href="/generative-adversarial-network-gan-for-dummies-a-step-by-step-tutorial-fdefff170391"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd iu gy z fp oq fr fs or fu fw is bi translated">虚拟生成对抗网络(GAN)——循序渐进教程</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">用防弹Python代码理解、构建和训练GANs的终极初学者指南。</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">towardsdatascience.com</p></div></div><div class="ou l"><div class="ov l ow ox oy ou oz lo ol"/></div></div></a></div></div><div class="ab cl pa pb hx pc" role="separator"><span class="pd bw bk pe pf pg"/><span class="pd bw bk pe pf pg"/><span class="pd bw bk pe pf"/></div><div class="im in io ip iq"><blockquote class="ph pi pj"><p id="83aa" class="ki kj ob kk b kl km ju kn ko kp jx kq pk ks kt ku pl kw kx ky pm la lb lc ld im bi translated"><strong class="kk iu">应认真考虑使用和GAN技术制作虚假图像、视频或新闻的道德问题，应负责任地使用这些技术</strong><a class="ae lu" rel="noopener" target="_blank" href="/wild-wide-ai-responsible-data-science-16b860e1efe9"><strong class="kk iu"/></a><strong class="kk iu">。</strong></p></blockquote><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/c6112fdce2279d761d19025557d717b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YOqsnwtA39qhsFCVrZXVfQ.jpeg"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">伊万诺夫·古德在<a class="ae lu" href="https://pixabay.com/photos/girl-face-colorful-colors-artistic-2696947/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>上的照片</p></figure><p id="e8d8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">非常感谢Vincent Casser的<a class="ae lu" href="https://github.com/Harvard-IACS/2019-computefest/blob/master/Wednesday/auto_encoder/VAE_Solutions.ipynb" rel="noopener ugc nofollow" target="_blank">精彩代码</a>，在他的博客中提供了一种更先进的实现图像处理卷积自动编码器的方法。我获得了文森特的明确授权，为这篇文章改编他的VAE代码。从头开始构建一个可用的VAE相当棘手。功劳归于文森特·卡瑟。</p><p id="e7d8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我推荐阅读Joseph Rocca的后续文章:<a class="ae lu" rel="noopener" target="_blank" href="/understanding-variational-autoencoders-vaes-f70510919f73">了解变分自动编码器(VAEs) </a>。</p><p id="1db4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢安妮·邦纳的编辑笔记。</p><p id="dba5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">保持健康和安全！</p></div></div>    
</body>
</html>