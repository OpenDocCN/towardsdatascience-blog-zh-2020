<html>
<head>
<title>Deep Learning Side By Side: Julia v.s. Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习并驾齐驱:Julia v.s. Python</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-side-by-side-julia-v-s-python-5ac0645587f6?source=collection_archive---------7-----------------------#2020-08-12">https://towardsdatascience.com/deep-learning-side-by-side-julia-v-s-python-5ac0645587f6?source=collection_archive---------7-----------------------#2020-08-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5815" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">你能说出哪一种是未来的语言吗？</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/94e9db3580290287abd53e25de045ff1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a48-gEB4CC3z3D8AsaPZGQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com/@srgbco?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> SuperRGB </a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="0646" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Julia 可能是 Python 最大的威胁。对于各种应用程序来说，Julia 无疑比 Python 更快，几乎和 C 语言一样快。Julia 还提供了多分派和元编程等特性，这些特性让它比 Python 更有优势。</p><p id="6b47" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与此同时，Python 被建立，被广泛使用，并拥有各种经过时间考验的包。切换到朱莉娅的问题是一个很难解决的问题。通常答案是令人沮丧的，“看情况”。</p><p id="cef7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了帮助展示 Julia 并解决是否使用它的问题，我从两种语言中提取了深度学习代码的样本，并将它们串联起来以便于比较。我将在 CIFAR10 数据集上训练 VGG19 模型。</p><h1 id="3034" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">模型</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mn"><img src="../Images/62e558701701bd411ec1026bcbe65a8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_M3vHWF_ByrD4IVW"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@tomparkes?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">汤姆·帕克斯</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="7b74" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">深度学习模型可能非常庞大，通常需要大量的工作来定义，尤其是当它们包含像 ResNet [1]这样的专门层时。我们将使用一个中等大小的模型(没有双关的意思)，VGG19，来进行比较[2]。</p><p id="2b03" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">Python 中的 vgg 19</strong></p><p id="1ec8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我选择 Keras 作为我们的 Python 实现，因为它的轻量级和灵活的设计与 Julia 具有竞争力。</p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="ac4b" class="mt lw it mp b gy mu mv l mw mx">from keras.models import Sequential<br/>from keras.layers import Dense, Conv2D, MaxPool2D , Flatten</span><span id="a0e7" class="mt lw it mp b gy my mv l mw mx">vgg19 = Sequential()<br/>vgg19.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding="same", activation="relu"))<br/>vgg19.add(Conv2D(filters=64,kernel_size=(3,3),padding="same", activation="relu"))<br/>vgg19.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))<br/>vgg19.add(Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu"))<br/>vgg19.add(Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu"))<br/>vgg19.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))<br/>vgg19.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))<br/>vgg19.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))<br/>vgg19.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))<br/>vgg19.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))<br/>vgg19.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))<br/>vgg19.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))<br/>vgg19.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))<br/>vgg19.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))<br/>vgg19.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))<br/>vgg19.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))<br/>vgg19.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))<br/>vgg19.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))<br/>vgg19.add(Flatten())model.add(Dense(units=4096,activation="relu"))<br/>vgg19.add(Dense(units=4096,activation="relu"))<br/>vgg19.add(Dense(units=10, activation="softmax"))</span><span id="5ec6" class="mt lw it mp b gy my mv l mw mx"># Code from <a class="ae ky" href="https://github.com/1297rohit" rel="noopener ugc nofollow" target="_blank">Rohit Thakur</a> on <a class="ae ky" href="https://github.com/1297rohit/VGG16-In-Keras" rel="noopener ugc nofollow" target="_blank">GitHub</a></span></pre><p id="02fb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里的任务是连接 21 层深度学习机器。Python 很好地处理了这一点。语法简单易懂。虽然<code class="fe mz na nb mp b">.add()</code>函数可能有点难看，但它的作用是显而易见的。此外，代码中很清楚每个模型层做什么。(卷积、合并、扁平化等..)</p><p id="43fa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">茱莉亚中的 vgg 19</strong></p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="b229" class="mt lw it mp b gy mu mv l mw mx">using Flux</span><span id="dfaf" class="mt lw it mp b gy my mv l mw mx">vgg16() = Chain(            <br/>    Conv((3, 3), 3 =&gt; 64, relu, pad=(1, 1), stride=(1, 1)),<br/>    Conv((3, 3), 64 =&gt; 64, relu, pad=(1, 1), stride=(1, 1)),<br/>    MaxPool((2,2)),<br/>    Conv((3, 3), 64 =&gt; 128, relu, pad=(1, 1), stride=(1, 1)),<br/>    Conv((3, 3), 128 =&gt; 128, relu, pad=(1, 1), stride=(1, 1)),<br/>    MaxPool((2,2)),<br/>    Conv((3, 3), 128 =&gt; 256, relu, pad=(1, 1), stride=(1, 1)),<br/>    Conv((3, 3), 256 =&gt; 256, relu, pad=(1, 1), stride=(1, 1)),<br/>    Conv((3, 3), 256 =&gt; 256, relu, pad=(1, 1), stride=(1, 1)),<br/>    MaxPool((2,2)),<br/>    Conv((3, 3), 256 =&gt; 512, relu, pad=(1, 1), stride=(1, 1)),<br/>    Conv((3, 3), 512 =&gt; 512, relu, pad=(1, 1), stride=(1, 1)),<br/>    Conv((3, 3), 512 =&gt; 512, relu, pad=(1, 1), stride=(1, 1)),<br/>    MaxPool((2,2)),<br/>    Conv((3, 3), 512 =&gt; 512, relu, pad=(1, 1), stride=(1, 1)),<br/>    Conv((3, 3), 512 =&gt; 512, relu, pad=(1, 1), stride=(1, 1)),<br/>    Conv((3, 3), 512 =&gt; 512, relu, pad=(1, 1), stride=(1, 1)),<br/>    BatchNorm(512),<br/>    MaxPool((2,2)),<br/>    flatten,<br/>    Dense(512, 4096, relu),<br/>    Dropout(0.5),<br/>    Dense(4096, 4096, relu),<br/>    Dropout(0.5),<br/>    Dense(4096, 10),<br/>    softmax<br/>)</span><span id="4549" class="mt lw it mp b gy my mv l mw mx"># Code from <a class="ae ky" href="https://github.com/FluxML/model-zoo/blob/master/vision/cifar10/cifar10.jl" rel="noopener ugc nofollow" target="_blank">Flux Model Zoo on Github</a></span></pre><p id="0120" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">讨论</strong></p><p id="07e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">乍看之下，Julia 看起来没有 Python 那么杂乱。导入语句更简洁，代码更容易阅读。和 Python 一样，每一层做什么都很清楚。<code class="fe mz na nb mp b">Chain</code>类型有点不明确，但是很明显它将各层连接在一起。</p><p id="9f30" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">需要注意的是没有模型类。事实上，Julia 不是面向对象的，所以每一层都是类型而不是类。这一点值得注意，因为它强调了 Julia 模型是非常轻量级的。这些层中的每一层都是独立定义的，然后链接在一起，没有任何类结构来控制它们如何交互。</p><p id="dbc6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，在训练巨型模型时，避免一点混乱并不重要。Python 的优势在于它对故障排除和解决 bug 有大量的支持。文档非常好，网上有数百个 VGG19 示例。相比之下，Julia 在网上有五个独特的 VGG19 例子(也许)。</p><h1 id="9c20" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">数据处理</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nc"><img src="../Images/a269776f700ca6faf6573d0d68e60c67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*PvfeNBVXj_q2xKd-"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com/@sandrokatalina?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">桑德罗·卡塔琳娜</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><p id="d539" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于数据处理，我们将查看通常与 VGG19 相关联的数据集 CIFAR10。</p><p id="a31c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">Python 中的数据处理</strong></p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="c21d" class="mt lw it mp b gy mu mv l mw mx">from keras.datasets import cifar10<br/>from keras.utils import to_categorical</span><span id="2fe8" class="mt lw it mp b gy my mv l mw mx">(X, Y), (tsX, tsY) = cifar10.load_data() </span><span id="39e9" class="mt lw it mp b gy my mv l mw mx"># Use a one-hot-encoding<br/>Y = to_categorical(Y)<br/>tsY = to_categorical(tsY)</span><span id="2185" class="mt lw it mp b gy my mv l mw mx"># Change datatype to float<br/>X = X.astype('float32')<br/>tsX = tsX.astype('float32')<br/> <br/># Scale X and tsX so each entry is between 0 and 1<br/>X = X / 255.0<br/>tsX = tsX / 255.0</span></pre><p id="969a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了根据图像数据训练模型，必须将图像转换成正确的格式。只需要几行代码就可以做到这一点。图像和图像标签一起被加载到变量中。为了使分类更容易，标签被转换成一个热点编码格式。这在 Python 中相对简单。</p><p id="15a2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">Julia 中的数据处理</strong></p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="13ec" class="mt lw it mp b gy mu mv l mw mx">using MLDatasets: CIFAR10<br/>using Flux: onehotbatch</span><span id="bb6a" class="mt lw it mp b gy my mv l mw mx"># Data comes pre-normalized in Julia<br/>trainX, trainY = CIFAR10.traindata(Float64)<br/>testX, testY = CIFAR10.testdata(Float64)</span><span id="c43b" class="mt lw it mp b gy my mv l mw mx"># One hot encode labels<br/>trainY = onehotbatch(trainY, 0:9)<br/>testY = onehotbatch(testY, 0:9)</span></pre><p id="91f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Julia 需要与 Python 相同的图像处理来为训练过程准备图像。这些代码看起来极其相似，而且似乎不支持任何一种语言。</p><h1 id="415a" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">培养</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/d59a5fba53562882d5711b2a3a5f1741.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tsKaEUAQh1TRWn8O"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@anarchist?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Zii Miller </a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="c94b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们将查看模型训练循环。</p><p id="29f4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">Python 培训</strong></p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="4704" class="mt lw it mp b gy mu mv l mw mx">optimizer = SGD(lr=0.001, momentum=0.9)<br/>vgg19.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])<br/>history = model.fit(X, Y, epochs=100, batch_size=64, validation_data=(tsX, tsY), verbose=0)</span></pre><p id="f1c9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">茱莉亚的培训</strong></p><pre class="kj kk kl km gt mo mp mq mr aw ms bi"><span id="7824" class="mt lw it mp b gy mu mv l mw mx">using Flux: crossentropy, @epochs<br/>using Flux.Data: DataLoader</span><span id="f000" class="mt lw it mp b gy my mv l mw mx">model = vgg19()<br/>opt = Momentum(.001, .9)<br/>loss(x, y) = crossentropy(model(x), y)<br/>data = DataLoader(trainX, trainY, batchsize=64)<br/>@epochs 100 Flux.train!(loss, params(model), data, opt)</span></pre><p id="08c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里的代码同样冗长，但是不同语言之间的差异显而易见。在 Python 中，<code class="fe mz na nb mp b">model.fit</code>返回包含准确度和损失评估的字典。它也有关键字参数来自动优化过程。朱莉娅更瘦了。训练算法要求用户提供他们自己的损失函数、优化器和包含批量数据的迭代程序以及模型。</p><p id="00c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Python 实现更加用户友好。培训过程很容易，并产生有用的输出。Julia 对用户的要求更高一些。同时，Julia 更加抽象，允许任何优化器和损失函数。用户可以以任何方式定义损失函数，而无需查阅内置损失函数列表。这种抽象是 Julia 开发人员的典型特征，他们致力于使代码尽可能的抽象和通用。</p><p id="fcf3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于这个原因，Keras 对于实现已知技术和标准模型训练更实用，但使 Flux 更适合于开发新技术。</p><h1 id="afb1" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">速度</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/3e77db01b6949a07845ec25006a5962d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*oCSmXM4Yd-H6R002"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">弗洛里安·斯特丘克在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="a6de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不幸的是，互联网上没有比较 Flux 和 Keras 的可用基准。有几个资源给了我们一个思路，我们可以使用 TensorFlow 速度作为参考。</p><p id="22ee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一项基准测试发现，在 GPU 和 CPU 上，<a class="ae ky" href="https://github.com/avik-pal/DeepLearningBenchmarks" rel="noopener ugc nofollow" target="_blank"> Flux 几乎不比 TensorFlow </a>慢。已经证明<a class="ae ky" href="https://wrosinski.github.io/deep-learning-frameworks/" rel="noopener ugc nofollow" target="_blank"> Keras 在 GPU 上也比 TensorFlow </a>稍慢。不幸的是，这并没有给我们一个明确的赢家，但表明两个包的速度是相似的。</p><p id="faea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的 Flux 基准测试是在 Flux 的自动差异软件包进行重大返工之前完成的。新的软件包 Zygote.jl 大大加快了计算速度。在 CPU<em class="nf">上的一个更近的通量基准</em>发现<a class="ae ky" href="https://estadistika.github.io//julia/python/packages/knet/flux/tensorflow/machine-learning/deep-learning/2019/06/20/Deep-Learning-Exploring-High-Level-APIs-of-Knet.jl-and-Flux.jl-in-comparison-to-Tensorflow-Keras.html" rel="noopener ugc nofollow" target="_blank">改进的通量比 CPU </a>上的 TensorFlow 更快。这表明 Flux 在 GPU 上也可以更快，但在 CPU 上获胜并不一定意味着在 GPU 上的胜利。同时，这仍然是 Flux 将在 CPU 上击败 Keras 的好证据。</p><h1 id="23c9" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">谁赢了？</h1><p id="02ac" class="pw-post-body-paragraph kz la it lb b lc ng ju le lf nh jx lh li ni lk ll lm nj lo lp lq nk ls lt lu im bi translated">两种语言在各个领域都表现出色。两者之间的差异很大程度上是口味问题。然而，每种语言都有两个优势。</p><h2 id="2573" class="mt lw it bd lx nl nm dn mb nn no dp mf li np nq mh lm nr ns mj lq nt nu ml nv bi translated">Python 的边缘</h2><p id="b043" class="pw-post-body-paragraph kz la it lb b lc ng ju le lf nh jx lh li ni lk ll lm nj lo lp lq nk ls lt lu im bi translated">Python 有一个庞大的支持社区，并提供经过时间考验的库。它是可靠和标准的。Python 中的深度学习要普遍得多。使用 Python 进行深度学习的开发者会很好地融入深度学习社区。</p><h2 id="0bff" class="mt lw it bd lx nl nm dn mb nn no dp mf li np nq mh lm nr ns mj lq nt nu ml nv bi translated">朱莉娅的优势</h2><p id="8001" class="pw-post-body-paragraph kz la it lb b lc ng ju le lf nh jx lh li ni lk ll lm nj lo lp lq nk ls lt lu im bi translated">茱莉亚更干净，更抽象。深度学习代码肯定会更快，改进工作正在进行中。朱莉娅有潜力。Python 中的深度学习库要完整得多，没有那么大的发展潜力。Julia 拥有更丰富的基础语言，在未来可能会有许多新的想法和更快的代码。采用 Julia 的开发人员将更接近编程的前沿，但将不得不处理打造自己的道路。</p><h2 id="0b15" class="mt lw it bd lx nl nm dn mb nn no dp mf li np nq mh lm nr ns mj lq nt nu ml nv bi translated">赢家</h2><p id="c213" class="pw-post-body-paragraph kz la it lb b lc ng ju le lf nh jx lh li ni lk ll lm nj lo lp lq nk ls lt lu im bi translated">深度学习很难，需要大量的故障排除。很难达到目前的精确度。正因如此，<strong class="lb iu"> Python 赢得了这次比较</strong>。Julia 中的深度学习没有对深度学习故障排除的强大在线支持。这可能会使编写复杂的深度学习脚本变得非常困难。Julia 对于很多应用都很优秀，但是对于深度学习，我会推荐 Python。</p></div><div class="ab cl nw nx hx ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="im in io ip iq"><div class="kj kk kl km gt od"><a href="https://medium.com/swlh/how-julia-uses-multiple-dispatch-to-beat-python-8fab888bb4d8" rel="noopener follow" target="_blank"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd iu gy z fp oi fr fs oj fu fw is bi translated">Julia 如何利用多重调度击败 Python</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">亲自看</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">medium.com</p></div></div><div class="om l"><div class="on l oo op oq om or ks od"/></div></div></a></div><div class="os ot gp gr ou od"><a rel="noopener follow" target="_blank" href="/how-to-learn-julia-when-you-already-know-python-641ed02b3fa7"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd iu gy z fp oi fr fs oj fu fw is bi translated">已经会 Python 了怎么学 Julia</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">跳到好的方面</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">towardsdatascience.com</p></div></div><div class="om l"><div class="ov l oo op oq om or ks od"/></div></div></a></div><h2 id="3cfd" class="mt lw it bd lx nl nm dn mb nn no dp mf li np nq mh lm nr ns mj lq nt nu ml nv bi translated">参考资料:</h2><p id="b7bf" class="pw-post-body-paragraph kz la it lb b lc ng ju le lf nh jx lh li ni lk ll lm nj lo lp lq nk ls lt lu im bi translated">[1]，何，，，，，，，【用于图像识别的深度残差学习，2016 .</p><p id="1857" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[2]卡伦·西蒙扬，安德鲁·齐泽曼，<a class="ae ky" href="https://arxiv.org/abs/1409.1556" rel="noopener ugc nofollow" target="_blank">用于大规模图像识别的极深度卷积网络</a>，国际学习表征会议，2015</p></div></div>    
</body>
</html>