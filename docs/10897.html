<html>
<head>
<title>How to execute JavaScript with Scrapy?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用 Scrapy 执行 JavaScript？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-execute-javascript-with-scrapy-1c5ef8f17981?source=collection_archive---------30-----------------------#2020-07-29">https://towardsdatascience.com/how-to-execute-javascript-with-scrapy-1c5ef8f17981?source=collection_archive---------30-----------------------#2020-07-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="812a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解如何使用 Scrapy 和 Selenium、Splash 和 ScrapingBee 中间件为无头浏览器抓取动态网站</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/8956ee90ab0f765eee82030a627afe18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6ZmIDOBmgBPNF2ga.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由 Pierre de Wulf [ <a class="ae ky" href="https://www.scrapingbee.com/blog/scrapy-javascript/" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="d567" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">大多数现代网站使用客户端 JavaScript 框架，如 React、Vue 或 Angular。在没有服务器端呈现的情况下，从动态网站抓取数据通常需要执行 JavaScript 代码。</p><p id="627a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我刮过几百个站点，一直用 Scrapy。Scrapy 是一个流行的 Python web 抓取框架。与其他 Python 抓取库(如 Beautiful Soup)相比，Scrapy 迫使你根据一些最佳实践来构建代码。作为交换，Scrapy 负责并发性、收集统计数据、缓存、处理重试逻辑以及许多其他工作。</p><p id="d73f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你是 Scrapy 新手，你可能应该开始阅读这个伟大的教程，它将教你所有<a class="ae ky" href="https://www.scrapingbee.com/blog/web-scraping-with-scrapy/" rel="noopener ugc nofollow" target="_blank">Scrapy</a>的基础知识。</p><p id="e68e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我比较了使用 Scrapy 执行 JavaScript 的最流行的解决方案，如何扩展无头浏览器，并介绍了使用 ScrapingBee API 实现 JavaScript 支持和代理轮换的开源集成。</p><h1 id="25da" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">用 Scrapy 抓取动态网站</h1><p id="7707" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">用 Scrapy 抓取客户端渲染的网站曾经很痛苦。我经常发现自己在浏览器网络工具上检查 API 请求，并从 JavaScript 变量中提取数据。</p><p id="ae3c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然这些技巧可能在一些网站上有效，但我发现代码比传统的 XPATHs 更难理解和维护。但是要直接从 HTML 中抓取客户端数据，首先需要执行 JavaScript 代码。</p><h1 id="7e19" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">无头浏览器的零碎中间件</h1><p id="40d1" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">无头浏览器是没有图形用户界面的 web 浏览器。我用三个库来用 Scrapy 执行 JavaScript:<strong class="lb iu">Scrapy-selenium</strong>、<strong class="lb iu"> scrapy-splash </strong>和<strong class="lb iu"> scrapy-scrapingbee </strong>。</p><p id="d27a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所有三个库被集成为一个 Scrapy <a class="ae ky" href="https://docs.scrapy.org/en/latest/topics/downloader-middleware.html" rel="noopener ugc nofollow" target="_blank">下载器中间件</a>。一旦在你的项目设置中进行了配置，你就可以产生一个<em class="ms"> SeleniumRequest </em>、<em class="ms"> SplashRequest </em>或<em class="ms">scraping beer Request</em>，而不是从你的蜘蛛那里产生一个普通的 Scrapy 请求。</p><h2 id="eb3e" class="mt lw it bd lx mu mv dn mb mw mx dp mf li my mz mh lm na nb mj lq nc nd ml ne bi translated">用 Selenium 在 Scrapy 中执行 JavaScript</h2><p id="9379" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在本地，你可以通过<a class="ae ky" href="https://github.com/clemfromspace/scrapy-selenium" rel="noopener ugc nofollow" target="_blank"> scrapy-selenium </a>中间件与 Scrapy 的无头浏览器进行交互。Selenium 是一个与浏览器交互的框架，通常用于测试应用程序、网页抓取和截屏。</p><p id="0ab0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Selenium 需要一个<a class="ae ky" href="https://selenium-python.readthedocs.io/installation.html#drivers" rel="noopener ugc nofollow" target="_blank"> web 驱动</a>来与浏览器交互。比如 Firefox 要求你安装 geckodriver。然后，您可以在 Scrapy 项目设置中配置 Selenium。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="de9a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在你的蜘蛛中，你可以产生一个<em class="ms">硒元素请求</em>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="987e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Selenium 允许您用 Python 和 JavaScript 与浏览器进行交互。<a class="ae ky" href="https://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.remote.webdriver" rel="noopener ugc nofollow" target="_blank">驱动程序对象</a>可以从 Scrapy 响应中访问。有时在你点击一个按钮后检查 HTML 代码是很有用的。在本地，您可以用一个<em class="ms"> ipdb </em>调试器设置一个断点来检查 HTML 响应。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="4179" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">否则，可以从响应对象访问杂乱的 XPATH 和 CSS 选择器，以便从 HTML 中选择数据。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="bde8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">SeleniumRequest 带有一些<a class="ae ky" href="https://github.com/clemfromspace/scrapy-selenium#additional-arguments" rel="noopener ugc nofollow" target="_blank">附加参数</a>，例如在返回响应之前的<em class="ms"> wait_time </em>到<em class="ms"> wait </em>，等待 HTML 元素的<em class="ms"> wait_until </em>，截屏的<em class="ms">screen</em>和执行定制 JavaScript 脚本的<em class="ms"> script </em>。</p><p id="2373" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在生产中，scrapy-selenium 的主要问题是没有简单的方法来建立一个<a class="ae ky" href="https://github.com/SeleniumHQ/selenium/wiki/Grid2" rel="noopener ugc nofollow" target="_blank"> Selenium grid </a>来在远程机器上运行多个浏览器实例。接下来，我将比较用 Scrapy 大规模执行 JavaScript 的两种解决方案。</p><h2 id="1fc1" class="mt lw it bd lx mu mv dn mb mw mx dp mf li my mz mh lm na nb mj lq nc nd ml ne bi translated">用 Splash 在 Scrapy 中执行 JavaScript</h2><p id="da79" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated"><a class="ae ky" href="https://github.com/scrapinghub/splash" rel="noopener ugc nofollow" target="_blank"> Splash </a>是一个带有 API 的网络浏览器即服务。它由 Scrapinghub 维护，Scrapy 的主要贡献者，并通过<a class="ae ky" href="https://github.com/clemfromspace/scrapy-selenium" rel="noopener ugc nofollow" target="_blank"> scrapy-splash </a>中间件与 Scrapy 集成。也可以由 Scrapinghub 托管。</p><p id="359d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Splash 创建于 2013 年，在 2017 年无头 Chrome 和其他主要无头浏览器发布之前。从那时起，其他流行的项目如 PhantomJS 已经停止，转而支持 Firefox、Chrome 和 Safari 无头浏览器。</p><p id="179f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以使用 Docker 在本地运行 Splash 的实例。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="abe6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">配置 Splash 中间件需要添加多个中间件，并在您的项目设置中更改<em class="ms">HttpCompressionMiddleware</em>的默认优先级。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="3dad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，您可以生成一个带有可选参数<em class="ms"> wait </em>和<em class="ms"> lua_source </em>的<em class="ms"> SplashRequest </em>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="9d55" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Splash 是一种流行的解决方案，因为它已经问世很长时间了，但它有两个主要问题:它使用自定义的无头浏览器，并需要用 Lua 编码来与网站交互。因为这两个问题，对于我的最后一个抓取项目，我决定为 ScrapingBee API 创建一个中间件。</p><h2 id="f37c" class="mt lw it bd lx mu mv dn mb mw mx dp mf li my mz mh lm na nb mj lq nc nd ml ne bi translated">使用 ScrapingBee 在 Scrapy 中执行 JavaScript</h2><p id="aa3e" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">ScrapingBee 是一个 web 抓取 API，它为您处理无头浏览器和代理。ScrapingBee 使用最新的 headless Chrome 版本，支持 JavaScript 脚本。</p><p id="441e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">像其他两个中间件一样，你可以简单地安装带有<em class="ms"> pip </em>的<a class="ae ky" href="https://github.com/scrapingbee/scrapy-scrapingbee" rel="noopener ugc nofollow" target="_blank"> scrapy-scrapingbee </a>中间件。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="a937" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，您需要创建一个 ScrapingBee 帐户来获取 API 密钥。然后，您可以添加下载器中间件，并在项目设置中根据您的 ScrapingBee 计划设置并发性。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="4018" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后你可以从<em class="ms"> ScrapingBeeSpider </em>继承你的 Spider 并产生一个<em class="ms"> ScrapingBeeRequest </em>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="a821" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ms"> ScrapingBeeRequest </em>采用一个可选的 params 参数来执行一个<em class="ms"> js_snippet </em>，在返回响应之前设置一个自定义的<em class="ms"> wait </em>或者用<em class="ms"> wait_for </em>在 HTML 代码中等待一个 CSS 或者 XPATH 选择器。</p><p id="c801" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在一些网站中，当你滚动页面时，HTML 是异步加载的。您可以使用下面的 JavaScript 代码片段滚动到页面的末尾。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="aadb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ScrapingBee 在<a class="ae ky" href="https://www.scrapingbee.com/documentation/#javascript-execution" rel="noopener ugc nofollow" target="_blank"> ScrapingBee 文档</a>上收集了其他常见的 JavaScript 片段来与网站进行交互。</p><p id="028c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在幕后，scrapy-scrapingbee 中间件将原始请求转换为转发给 ScrapingBee API 的请求，并对 URL 查询字符串中的每个参数进行编码。API 端点记录在你的垃圾日志中，api_key 被<em class="ms">垃圾蜘蛛</em>隐藏。</p><p id="8c6c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在您的蜘蛛解析方法中，<em class="ms"> response.url </em>被中间件解析为传递给<em class="ms"> ScrapingBeeRequest </em>的原始 url。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="81e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用 ScrapingBee 的另一个优点是，您可以访问不同国家的住宅代理，并通过以下参数进行代理轮换。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><h1 id="e1ea" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">使用 Scrapy 缓存和并发来提高速度</h1><p id="988e" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">Scrapy 使用了 Twisted under the hood，这是一个异步网络框架。Twisted 使 Scrapy 快速，能够同时刮多个页面。然而，要执行 JavaScript 代码，您需要使用真正的浏览器或无头浏览器来解析请求。无头浏览器有两个挑战:速度较慢，难以扩展。</p><p id="f440" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在无头浏览器中执行 JavaScript 并等待所有网络调用，每页可能需要几秒钟。当刮多个页面时，它会使刮刀明显变慢。希望 Scrapy 提供缓存来加速开发和生产运行的并发请求。</p><p id="009a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本地，当开发一个刮刀时，你可以使用 Scrapy 的内置缓存系统。这将使后续运行更快，因为响应存储在您计算机上的一个隐藏文件夹<em class="ms">中。scrapy/httpcache </em>。您可以在您的项目设置中激活<em class="ms"> HttpCacheMiddleware </em>:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="d2e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">无头浏览器的另一个问题是它们为每个请求消耗内存。在生产中，您需要一个可以处理多种浏览器的环境。要同时发出多个请求，您可以修改项目设置:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nf ng l"/></div></figure><p id="a734" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用 ScrapingBee 时，记得根据您的 ScrapingBee 计划设置并发性。</p><h1 id="c169" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="c52f" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我比较了三个 Scrapy 中间件，用 Scrapy 渲染和执行 JavaScript。Selenium 允许您在所有主流的无头浏览器中使用 Python 与 web 浏览器进行交互，但是很难扩展。Splash 可以使用 Docker 在本地运行，也可以部署到 Scrapinghub，但是它依赖于定制的浏览器实现，而且你必须用 Lua 编写脚本。ScrapingBee 使用最新的 Chrome headless 浏览器，允许您在 JavaScript 中执行自定义脚本，并为最难抓取的网站提供代理旋转。</p><h1 id="a651" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">资源</h1><ul class=""><li id="cf4d" class="nh ni it lb b lc mn lf mo li nj lm nk lq nl lu nm nn no np bi translated"><a class="ae ky" href="https://github.com/clemfromspace/scrapy-selenium" rel="noopener ugc nofollow" target="_blank"> scrapy-selenium 中间件</a></li><li id="441b" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated"><a class="ae ky" href="https://github.com/scrapy-plugins/scrapy-splash" rel="noopener ugc nofollow" target="_blank">飞溅中间件</a></li><li id="2e4a" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated"><a class="ae ky" href="https://github.com/scrapingbee/scrapy-scrapingbee" rel="noopener ugc nofollow" target="_blank">scrapy-scrapy bee 中间件</a></li></ul></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><p id="769e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ms">原载于</em><a class="ae ky" href="https://www.scrapingbee.com/blog/scrapy-javascript/" rel="noopener ugc nofollow" target="_blank"><em class="ms">https://www.scrapingbee.com</em></a><em class="ms">。</em></p></div></div>    
</body>
</html>