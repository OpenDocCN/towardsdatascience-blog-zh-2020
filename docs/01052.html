<html>
<head>
<title>Building Models with Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Keras 构建模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-models-with-keras-bbe6dcfdad31?source=collection_archive---------8-----------------------#2020-01-30">https://towardsdatascience.com/building-models-with-keras-bbe6dcfdad31?source=collection_archive---------8-----------------------#2020-01-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9603" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">神经网络 API 简介</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c7a2e799ad16a6cae676335f41455cb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iClajvhB_G2DlgJ5ZFyYxg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://www.pexels.com/@noahdwilke" rel="noopener ugc nofollow" target="_blank">拍摄，另一个摄影爱好者</a>在<a class="ae ky" href="https://www.pexels.com/photo/red-sunglasses-art-abstract-68725/" rel="noopener ugc nofollow" target="_blank">像素</a></p></figure><p id="b011" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Keras 是用于在 python 中构建神经网络的高级 API。API 支持顺序神经网络、递归神经网络和卷积神经网络。由于其模块化、用户友好性和可扩展性，它还允许简单快速的原型制作。在本帖中，我们将通过使用 Keras 为回归和分类任务构建序列神经网络的过程。Keras 的文档可以在<a class="ae ky" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="bee8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们开始吧！</p><h1 id="074a" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">回归</strong></h1><p id="cd02" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated"><strong class="lb iu">数据准备</strong></p><p id="bee6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将用于回归的数据是<em class="ms">加州房价</em>数据集。数据可以在<a class="ae ky" href="https://www.kaggle.com/camnugent/california-housing-prices" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="1ef5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，让我们导入数据并打印前五行:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="724d" class="my lw it mu b gy mz na l nb nc">import pandas as pd <br/>df = pd.read_csv("housing.csv")<br/>print(df.head())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/dea89add5ffa3ca9db0bc1fd00739552.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*9zMwPLmCsC40C0w7ZoqPrQ.png"/></div></figure><p id="b975" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们定义我们的输入和目标变量。我们将使用经度、纬度、住房中位数年龄、总房间数、总卧室数、人口数、家庭数和收入中位数来预测房屋中位数价值。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="0537" class="my lw it mu b gy mz na l nb nc">import numpy as np<br/>X = np.array(df[['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']])<br/>y = np.array(df['median_house_value'])</span></pre><p id="717a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们将分割数据用于训练和测试:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="d27e" class="my lw it mu b gy mz na l nb nc">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)</span></pre><p id="eeeb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们所有必要的变量都定义好了。让我们建立一些模型！</p><p id="d3a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">定义模型</strong></p><p id="7170" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">顺序模型是层的线性堆叠。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="1a12" class="my lw it mu b gy mz na l nb nc"><strong class="mu iu">from</strong> keras.models <strong class="mu iu">import</strong> Sequential<br/>model = Sequential()</span></pre><p id="2d2e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果出现以下错误:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/e002c9909511ba1d2630fa90c59857b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/format:webp/1*z5kU0GYzE1tXC-i762Konw.png"/></div></figure><p id="4669" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">尝试在此次导入和所有后续导入中从 tensorflow 导入 Keras:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="a58d" class="my lw it mu b gy mz na l nb nc"><strong class="mu iu">from</strong> tensorflow.keras.models <strong class="mu iu">import</strong> Sequential<br/>model = Sequential()</span></pre><p id="4bbb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">添加图层</strong></p><p id="bf9c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以使用。add()方法来添加层。我们将添加需要单独导入的密集层:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="67c4" class="my lw it mu b gy mz na l nb nc"><strong class="mu iu">from</strong> keras.layers <strong class="mu iu">import</strong> Dense</span></pre><p id="42a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">模型应该知道第一层中预期的输入形状。因此，您需要传递关于模型中特征数量的信息。因为我们有 8 个特征，我们需要传入一个输入形状(8，)。我们将添加一个包含 8 个节点的密集层:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="519d" class="my lw it mu b gy mz na l nb nc">model.add(Dense(8, input_shape = (8,)))</span></pre><p id="7b5a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们添加一个额外的隐藏层。对于我们的隐藏层，我们将使用 relu 函数:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="ff1e" class="my lw it mu b gy mz na l nb nc">model.add(Dense(8, activation = 'relu'))</span></pre><p id="49c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，让我们添加我们的输出层。对于回归问题，我们通常将输出层中的激活函数定义为线性。此外，输出图层有一个用于回归问题的节点:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="9e67" class="my lw it mu b gy mz na l nb nc">model.add(Dense(1, activation = 'linear'))</span></pre><p id="3886" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">编译</strong></p><p id="b3ea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们要做的下一件事是配置学习过程。这是使用 compile 方法完成的。在编译方法中，我们必须传递以下参数:</p><ol class=""><li id="aae3" class="nf ng it lb b lc ld lf lg li nh lm ni lq nj lu nk nl nm nn bi translated">损失函数(Loss Function ):这是一个函数，用于评估您的算法对数据集的建模效果。</li><li id="9a60" class="nf ng it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated">优化器:这是一种找到最小化你的损失函数的权重的方法。</li><li id="e8e9" class="nf ng it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated">度量:对于回归，我们通常将度量定义为损失函数。这允许我们在模型被训练时跟踪损失。</li></ol><p id="3816" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将对优化器使用均方根传播算子，对损失函数使用均方误差，对指标使用均方误差:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="cb02" class="my lw it mu b gy mz na l nb nc">model.compile(optimizer='rmsprop', loss='mse', metrics =['mse'])</span></pre><p id="6831" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以查看模型摘要来分析我们的神经网络架构:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="6259" class="my lw it mu b gy mz na l nb nc">print(model.summary())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/bfc1dc172c36298b59d9d422d2dd5d2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*jOxNd6WVGTl0DicNCY0K7g.png"/></div></figure><p id="6f86" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">拟合</strong></p><p id="e9d1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于模型训练，我们将使用。fit()方法:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="3f62" class="my lw it mu b gy mz na l nb nc">model.fit(X_train, y_train)</span></pre><p id="ef44" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们应该得到以下输出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/0b5dace4f6dcdb3af496176c8897bf09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BShm3WStrGVQ4h03is57vw.png"/></div></div></figure><p id="503e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以传递一个历元数的值(数据的迭代次数)来尝试提高准确性:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="b4d1" class="my lw it mu b gy mz na l nb nc">model.fit(X_train, y_train, epochs = 10)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/e47bd9d244aa48f6faa1644d15b86e17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zmrpmewj-9G77UZB-H1w_g.png"/></div></div></figure><p id="ca12" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以调整纪元的数量，以尽量减少误差:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="d42c" class="my lw it mu b gy mz na l nb nc">model.fit(X_train, y_train, epochs = 50)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/fcae8d65e3e0f10df6da0773c9e78bca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FKXGSyhagw01UQaVlzyx5g.png"/></div></div></figure><p id="d1b6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以对隐藏层的数量进行同样的操作。让我们尝试添加两个额外的隐藏层:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="7f78" class="my lw it mu b gy mz na l nb nc">model.add(Dense(8, input_shape = (8,)))<br/>model.add(Dense(8, activation = 'relu'))<br/>model.add(Dense(8, activation = 'relu'))<br/>model.add(Dense(8, activation = 'relu'))<br/>model.add(Dense(1, activation = 'linear'))<br/>model.compile(optimizer='rmsprop', loss='mse', metrics =['mse'])<br/>model.fit(X_train, y_train, epochs = 50)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/c0c50f48f27d68aad010c220a06ec167.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eq_qLcxpCcu1j5utBGilJw.png"/></div></div></figure><p id="a357" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们看到最后五个时期具有较低的均方误差。我们还可以尝试添加更多节点。让我们试试 16 个节点，而不是 8 个:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="5b7e" class="my lw it mu b gy mz na l nb nc">model.add(Dense(16, input_shape = (8,)))<br/>model.add(Dense(16, activation = 'relu'))<br/>model.add(Dense(16, activation = 'relu'))<br/>model.add(Dense(16, activation = 'relu'))<br/>model.add(Dense(1, activation = 'linear'))<br/>model.compile(optimizer='rmsprop', loss='mse', metrics =['mse'])<br/>model.fit(X_train, y_train, epochs = 50)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/3e41bf310f624c8bd8023aa9bed80c0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U8h5yz1UhYforqdQwZF5VA.png"/></div></div></figure><p id="1825" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，让我们尝试使用不同的优化器。让我们试试“亚当”优化器:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="0518" class="my lw it mu b gy mz na l nb nc">model.add(Dense(16, input_shape = (8,)))<br/>model.add(Dense(16, activation = 'relu'))<br/>model.add(Dense(16, activation = 'relu'))<br/>model.add(Dense(16, activation = 'relu'))<br/>model.add(Dense(1, activation = 'linear'))<br/>model.compile(optimizer='adam', loss='mse', metrics =['mse'])<br/>model.fit(X_train, y_train, epochs = 50)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/74816d58d7f59350739799a9b10e8fa0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l9I_6sGAagUYKLVjjH4C0w.png"/></div></div></figure><p id="1cb6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最终模型的性能大致相同。最后，让我们尝试大量的 epochs，比如 500 个，并传递一个更大的 batch_size。让我们传递 100 的 batch_size:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="ccb7" class="my lw it mu b gy mz na l nb nc">model.add(Dense(16, input_shape = (8,)))<br/>model.add(Dense(16, activation = 'relu'))<br/>model.add(Dense(16, activation = 'relu'))<br/>model.add(Dense(16, activation = 'relu'))<br/>model.add(Dense(1, activation = 'linear'))<br/>model.compile(optimizer='adam', loss='mse', metrics =['mse'])<br/>model.fit(X_train, y_train, epochs = 500, batch_size=100)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/6bb73b4cf11c07ba387acc12068975a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nyac5MoWWbkCe7FKYoFeaw.png"/></div></div></figure><p id="cf53" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果我们看到了一些改进。虽然我们在最小化均方误差，但我们可以显示不同的误差指标，如平均绝对百分比误差:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="8f33" class="my lw it mu b gy mz na l nb nc">model.add(Dense(16, input_shape = (8,)))<br/>model.add(Dense(16, activation = 'relu'))<br/>model.add(Dense(16, activation = 'relu'))<br/>model.add(Dense(16, activation = 'relu'))<br/>model.add(Dense(1, activation = 'linear'))<br/>model.compile(optimizer='adam', loss='mse', metrics =['mape'])<br/>model.fit(X_train, y_train, epochs = 500, batch_size=100)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/fb691a6f6925339197b3e563c4c14c69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wWBpdiRPGg7HFvU1qxnR0w.png"/></div></div></figure><p id="a5fe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们看到最后一个时期的平均绝对百分比误差为 28%。</p><p id="b54c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">预测</strong></p><p id="4ff7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了生成预测，我们执行以下操作:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="a156" class="my lw it mu b gy mz na l nb nc">y_pred = model.predict(X_test)</span></pre><p id="27b4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以使用 matplotlib 可视化我们的预测:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="cbdf" class="my lw it mu b gy mz na l nb nc">import matplotlib.pyplot as plt</span><span id="3893" class="my lw it mu b gy ob na l nb nc">plt.clf()<br/>fig = plt.figure()<br/>fig.suptitle('Scatter plot of Actual versus Predicted')<br/>plt.scatter(x=y_pred, y=y_test, marker='.')<br/>plt.xlabel('Predicted')<br/>plt.ylabel('Actual ')<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/98933e1031922d66b4293e3f4b3a9365.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*DVBw3f1fXf0nMNHuP4rEig.png"/></div></figure><p id="c083" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">预测值和实际值之间的关系越像直线，我们的模型就越准确。就优化我们的模型而言，我们还可以尝试更多的东西，但我会把这些留给你去做。</p><h1 id="4fc7" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">分类</strong></h1><p id="5adb" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">现在让我们来完成构建分类模型的相同过程。工作流程中有许多相似之处，但有一些小差异！</p><p id="35ad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">数据准备</strong></p><p id="0ab4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将用于分类的数据是<em class="ms">电信客户流失</em>数据集。这里可以找到<a class="ae ky" href="https://www.kaggle.com/blastchar/telco-customer-churn" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="2792" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，让我们导入数据并打印前五行:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="7e51" class="my lw it mu b gy mz na l nb nc">import pandas as pd <br/>df = pd.read_csv("Customer_Churn.csv")<br/>print(df.head())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/592e40b585ccbbcdaf1c9153e04285f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_TIDg_6EWcflqAryVSoNDw.png"/></div></div></figure><p id="b6b7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为简单起见，我们将使用所有的分类和数字数据来预测客户流失。首先，我们需要将分类列转换为神经网络可以处理的数值。例如，对于性别，我们有:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="337a" class="my lw it mu b gy mz na l nb nc">df.gender = pd.Categorical(df.gender)<br/>df['gender_code'] = df.gender.cat.codes</span></pre><p id="6646" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们定义输入和输出数组:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="bf27" class="my lw it mu b gy mz na l nb nc">import numpy as np</span><span id="b2b8" class="my lw it mu b gy ob na l nb nc">features = ['gender_code', 'SeniorCitizen_code', 'PhoneService_code', 'MultipleLines_code', <br/>                 'InternetService_code', 'Partner_code', 'Dependents_code', 'PaymentMethod_code', <br/>                 'PaymentMethod_code', 'PaperlessBilling_code','Contract_code', 'StreamingMovies_code',<br/>                 'StreamingTV_code', 'TechSupport_code', 'DeviceProtection_code', 'OnlineBackup_code',<br/>                 'OnlineSecurity_code', 'Dependents_code', 'Partner_code','tenure', 'MonthlyCharges']</span><span id="0995" class="my lw it mu b gy ob na l nb nc">X = np.array(df[features])<br/>y = np.array(df['Churn_code'])</span></pre><p id="4e1b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们也标准化输入:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="e876" class="my lw it mu b gy mz na l nb nc">from sklearn.preprocessing import StandardScaler<br/>sc = StandardScaler()<br/>X = sc.fit_transform(X)</span></pre><p id="d79f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们将分割数据用于训练和测试:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="69f4" class="my lw it mu b gy mz na l nb nc">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)</span></pre><p id="098f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们所有必要的变量都定义好了。让我们建立一些模型！</p><p id="2c81" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">定义模型&amp;添加图层</strong></p><p id="9869" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们从一个 8 节点输入图层开始，其输入形状对应于要素的数量:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="6eca" class="my lw it mu b gy mz na l nb nc">model = Sequential()<br/>model.add(Dense(8, input_shape = (len(features),)))</span></pre><p id="7d95" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们添加一个隐藏层:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="96f4" class="my lw it mu b gy mz na l nb nc">model.add(Dense(8, activation='relu'))</span></pre><p id="d0e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，让我们添加我们的输出层。对于二元分类，我们使用 1 个节点作为输出和 sigmoid 激活函数:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="bbab" class="my lw it mu b gy mz na l nb nc">model.add(Dense(1, activation='sigmoid')) </span></pre><p id="c23a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">编译</strong></p><p id="6ef2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们编译我们的模型。我们将使用“Adam”传播算子、损失的二进制交叉熵和度量的“准确性”。Keras 文档建议我们将指标设置为值“准确性”:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="0bed" class="my lw it mu b gy mz na l nb nc">model.compile(optimizer='adam',            loss='binary_crossentropy', metrics=['accuracy'])</span></pre><p id="a94f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们打印我们模型的摘要:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="5274" class="my lw it mu b gy mz na l nb nc">print(model.summary())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/4996740983281a7b8850395bbe0a69a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*ds5Zoyqj4oR0MujRAXtQVA.png"/></div></figure><p id="576e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">试衣</strong></p><p id="92eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于模型训练，我们将使用。fit()方法:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="68e9" class="my lw it mu b gy mz na l nb nc">model.fit(X_train, y_train)</span></pre><p id="19ea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们应该得到以下输出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/2aed516016959795eae957a4d6de3568.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/format:webp/1*CgR_W0oqwLvwQJSPIJ-edQ.png"/></div></figure><p id="898a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与回归问题类似，您可以随意调整节点数、层数、时期数、batch_size 和优化器类型。</p><p id="fa8d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">预测</strong></p><p id="16ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在预测步骤中，我们希望将输出(数组)转换为浮点数，然后使用列表理解对值进行舍入:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="651f" class="my lw it mu b gy mz na l nb nc">y_pred = [round(float(x)) for x in model.predict(X_test)]</span></pre><p id="5bac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以使用度量分类报告来可视化预测:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="e357" class="my lw it mu b gy mz na l nb nc">from sklearn import metrics<br/>print(metrics.classification_report(y_test, y_pred))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/f826844ab7fa6874696c7aae8fc7ce0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/1*c71QAhCbB42A-_NoTROuxQ.png"/></div></div></figure><p id="71b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还可以查看 roc_auc_score 和 f1_scores:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/e9dfd32244f5227f65b9f793ae05c46c.png" data-original-src="https://miro.medium.com/v2/resize:fit:520/format:webp/1*aq1kUgrk5dBObo_U0NsKew.png"/></div></figure><p id="2174" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这两种情况下，等于 1.0 的值都是完美的。通过调整模型参数，可以显著提高性能。我鼓励你尝试增加神经元(节点)、时期、层的数量，并设计额外的功能。</p><p id="e669" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">结论</strong></p><p id="8a0c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我们介绍了使用 Keras 神经网络 API 构建回归和分类模型的过程。我们回顾了定义模型对象、添加层、用编译方法配置模型、训练模型、进行预测和评估模型性能的过程。我鼓励您尝试回归和分类的神经网络架构。一旦你觉得舒服了，就试着把你的知识应用到其他数据集和预测问题上。我希望这篇文章有趣。这篇文章的代码将会在<a class="ae ky" href="https://github.com/spierre91/medium_code" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上发布。感谢阅读，机器学习快乐！</p></div></div>    
</body>
</html>