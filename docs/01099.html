<html>
<head>
<title>How to Detect Bias in AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何检测人工智能中的偏差</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-detect-bias-in-ai-872d04ce4efd?source=collection_archive---------17-----------------------#2020-01-31">https://towardsdatascience.com/how-to-detect-bias-in-ai-872d04ce4efd?source=collection_archive---------17-----------------------#2020-01-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="fae7" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">偏见</h2><div class=""/><div class=""><h2 id="6111" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">检测数据中常见的(认知)偏差</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/71d0ea7ce9e5f0bc3cfba6077f4348ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*01fweak0ejOLqWnovP2f5w.png"/></div></div></figure><p id="d1f1" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">随着人工智能解决方案在我们的日常生活中变得更加根深蒂固，人工智能偏见在过去几年中一直是一个热门话题。作为一个转行做数据科学的心理学家，这个话题很贴近我的内心。</p><p id="17f3" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">为了防止人工智能模型出现偏差，人们首先必须意识到各种偏差的存在。</p><blockquote class="lz"><p id="5c97" class="ma mb it bd mc md me mf mg mh mi ly dk translated">在<!-- -->中，为了发现偏见，人们必须意识到它的存在。</p></blockquote><p id="27bd" class="pw-post-body-paragraph ld le it lf b lg mj kd li lj mk kg ll lm ml lo lp lq mm ls lt lu mn lw lx ly im bi translated">为了做到这一点，本文将指导你在开发人工智能的不同阶段发现许多常见和不常见的偏见。这些阶段包括:</p><ul class=""><li id="dca0" class="mo mp it lf b lg lh lj lk lm mq lq mr lu ms ly mt mu mv mw bi translated">数据收集</li><li id="65a7" class="mo mp it lf b lg mx lj my lm mz lq na lu nb ly mt mu mv mw bi translated">数据预处理</li><li id="7f3a" class="mo mp it lf b lg mx lj my lm mz lq na lu nb ly mt mu mv mw bi translated">数据分析</li><li id="3820" class="mo mp it lf b lg mx lj my lm mz lq na lu nb ly mt mu mv mw bi translated">建模</li></ul><p id="be80" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">希望了解你可能遇到的偏见将有助于你开发更少偏见的人工智能解决方案。</p><h1 id="55d4" class="nc nd it bd ne nf ng nh ni nj nk nl nm ki nn kj no kl np km nq ko nr kp ns nt bi translated">1.什么是偏见？</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nu"><img src="../Images/8311588c2fa9246c6e6000a57b690203.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pck8WNlSFZaDJsxUfO6-Qg.png"/></div></div></figure><p id="f1b9" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">偏见</strong>被认为是对一个<strong class="lf jd">想法</strong>或<strong class="lf jd">事情</strong>的不成比例的倾向或偏见。偏见通常被认为是在人类的背景下，但它可以存在于许多不同的领域:</p><ul class=""><li id="d5ce" class="mo mp it lf b lg lh lj lk lm mq lq mr lu ms ly mt mu mv mw bi translated"><strong class="lf jd">统计数据</strong> —例如，统计数据的系统失真</li><li id="2812" class="mo mp it lf b lg mx lj my lm mz lq na lu nb ly mt mu mv mw bi translated"><strong class="lf jd">研究</strong>—例如，偏向于发表某些有意义的实验结果</li><li id="cf81" class="mo mp it lf b lg mx lj my lm mz lq na lu nb ly mt mu mv mw bi translated"><strong class="lf jd">社会科学</strong> —例如，对某些人群的偏见</li></ul><p id="a605" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在本文中，我们将结合(认知)偏见可能出现的几个领域，以了解偏见如何进入人工智能。</p><p id="bc7d" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">下面，我将介绍人工智能发展的常见阶段，并确定检测偏差的步骤。</p><h1 id="2f74" class="nc nd it bd ne nf ng nh ni nj nk nl nm ki nn kj no kl np km nq ko nr kp ns nt bi translated">2.数据收集</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nv"><img src="../Images/801ff5f03e975a16a0ed7875af275720.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hGA7D6DgUwEaqjxH9lWLYQ.jpeg"/></div></div></figure><p id="ea2c" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">数据收集是你会发现偏见的第一个也是最常见的地方之一。最大的原因是数据通常是由人类收集或创建的，这使得错误、异常值和偏差很容易渗入数据中。</p><p id="9777" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">数据收集过程中发现的常见偏差:</p><ul class=""><li id="380b" class="mo mp it lf b lg lh lj lk lm mq lq mr lu ms ly mt mu mv mw bi translated"><code class="fe nw nx ny nz b"><strong class="lf jd">Selection Bias</strong></code> —以样本不代表总体的方式选择数据</li></ul><p id="d6ba" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">例如，在许多社会调查研究中，研究人员利用学生作为参与者来测试他们的假设。学生显然不能代表一般人群，可能会使研究结果产生偏差。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oa"><img src="../Images/c6de821b665641e0800ba926364618d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fwGC9V0DamaGny7M246XbQ.png"/></div></div><p class="ob oc gj gh gi od oe bd b be z dk translated">选择偏差</p></figure><ul class=""><li id="125d" class="mo mp it lf b lg lh lj lk lm mq lq mr lu ms ly mt mu mv mw bi translated"><code class="fe nw nx ny nz b"><strong class="lf jd">The Framing Effect</strong></code> —带有特定倾向的调查问题。</li></ul><p id="3acd" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如下图所示，如果这个问题是正面的，人们更有可能拯救200条生命，相比之下有33%的机会拯救所有人。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi of"><img src="../Images/1c5c026a0f86b42879c91562c5159d5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6SNsguMKmrGah84nw_Xc_w.png"/></div></div><p class="ob oc gj gh gi od oe bd b be z dk translated">72%的参与者在积极的框架下选择了治疗A(“拯救200条生命”)，当同样的选择出现在消极的框架下(“400人会死”)时，这一比例下降到了22%。</p></figure><ul class=""><li id="f7b4" class="mo mp it lf b lg lh lj lk lm mq lq mr lu ms ly mt mu mv mw bi translated"><code class="fe nw nx ny nz b"><strong class="lf jd">Systematic Bias</strong></code> <strong class="lf jd"> </strong> —这是一个一致的、可重复的误差。</li></ul><p id="1a7c" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这通常是设备故障的结果。纠正这种错误很重要，因为错误很难检测。对机械或工艺的良好理解是必要的。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oa"><img src="../Images/f11612c4fa72dcea36ab3b9c96e0f72a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QMX9ewVdvLA8vTUethZrMQ.png"/></div></div><p class="ob oc gj gh gi od oe bd b be z dk translated">系统误差</p></figure><ul class=""><li id="04dc" class="mo mp it lf b lg lh lj lk lm mq lq mr lu ms ly mt mu mv mw bi translated"><code class="fe nw nx ny nz b"><strong class="lf jd">Response Bias</strong></code> <strong class="lf jd"> — </strong>参与者对问题回答不准确或错误的一系列偏差。</li></ul><p id="a19b" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">问卷中经常出现回答偏差。由于这些都是由参与者填写的，人类的偏见很容易在数据中找到自己的位置。例如，<code class="fe nw nx ny nz b"><strong class="lf jd">Social Desirability Bias</strong></code>指出，人们很可能会在他们的反应中否认不受欢迎的特征。这可以通过强调好的行为或理解坏的行为来实现。类似地，<code class="fe nw nx ny nz b"><strong class="lf jd">Question Order Bias</strong></code>指出人们可能会根据问题的顺序不同地回答问题。</p><p id="1d18" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">了解您如何设计收集流程会对您将要收集的数据类型产生重大影响，这一点很重要。如果不小心，你的数据会强烈偏向某些群体。任何由此产生的分析都可能是有缺陷的！</p><h1 id="d2fb" class="nc nd it bd ne nf ng nh ni nj nk nl nm ki nn kj no kl np km nq ko nr kp ns nt bi translated">3.数据预处理</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nu"><img src="../Images/9fa70a646d8ed0036388f1325716bef3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rIBJYGFU-By9s_hY63TXWw.png"/></div></div></figure><p id="8ee9" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">处理数据时，可以采取许多步骤来为分析做准备:</p><ul class=""><li id="395b" class="mo mp it lf b lg lh lj lk lm mq lq mr lu ms ly mt mu mv mw bi translated"><code class="fe nw nx ny nz b"><strong class="lf jd">Outlier Detection</strong></code></li></ul><p id="7487" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">您通常希望移除异常值，因为它们可能会对某些分析产生不相称的影响。在所有人都在20到30岁之间的数据集中，年龄为110岁的人很可能不太能代表数据。</p><ul class=""><li id="d30a" class="mo mp it lf b lg lh lj lk lm mq lq mr lu ms ly mt mu mv mw bi translated"><code class="fe nw nx ny nz b"><strong class="lf jd">Missing Values</strong></code></li></ul><p id="4731" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如何处理某些变量的缺失值会引入偏差。如果您要用平均值填充所有缺失的值，那么您是有目的地将数据推向平均值。这可能会让你偏向某些行为更接近平均值的群体。</p><ul class=""><li id="030d" class="mo mp it lf b lg lh lj lk lm mq lq mr lu ms ly mt mu mv mw bi translated"><code class="fe nw nx ny nz b"><strong class="lf jd">Filtering Data</strong></code></li></ul><p id="4c49" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我见过很多次这种情况，数据被过滤得太多，几乎不能代表目标人群。这就介绍了，在某种程度上，<code class="fe nw nx ny nz b"><strong class="lf jd">Selection Bias</strong></code> <strong class="lf jd"> </strong>到<strong class="lf jd"> </strong>你的数据。</p><h1 id="6332" class="nc nd it bd ne nf ng nh ni nj nk nl nm ki nn kj no kl np km nq ko nr kp ns nt bi translated">4.数据分析</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi og"><img src="../Images/5501cdaf38d8902ff9b469b6ebd7bac6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W5HDVhUSL4G8u8O6lpcueQ.png"/></div></div></figure><p id="0f94" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">当开发一个人工智能解决方案时，最终的产品可能是一个模型或算法。然而，在数据分析中也很容易发现偏差。通常，我们在数据分析中会看到以下偏差:</p><ul class=""><li id="fe9c" class="mo mp it lf b lg lh lj lk lm mq lq mr lu ms ly mt mu mv mw bi translated"><code class="fe nw nx ny nz b"><strong class="lf jd">Misleading Graphs</strong></code> —歪曲数据的扭曲图表，从而可能从中得出不正确的结论。</li></ul><p id="f9b0" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">例如，在报告分析结果时，数据科学家可以选择从0开始绘制图表的y轴。虽然这不会在数据本身中引入偏差，但随着差异变得更加明显，可能会出现明显的<code class="fe nw nx ny nz b"><strong class="lf jd">Framing</strong></code> <strong class="lf jd"> </strong>(见下图)。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oh"><img src="../Images/a8717685fd17487ac84df5dffcd7e5d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Zc9LCrpt5dwbaWE3"/></div></div><p class="ob oc gj gh gi od oe bd b be z dk translated">如果Y轴从0%开始，作物产量的差异似乎很小。然而，简单地将其更改为从70%开始会导致看似不同的观点，而结果实际上是相同的。</p></figure><p id="b533" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如果你想了解更多关于误导性图表的影响，强烈推荐《<a class="ae oi" href="https://en.wikipedia.org/wiki/How_to_Lie_with_Statistics" rel="noopener ugc nofollow" target="_blank">如何用统计数据撒谎</a>》这本书！</p><ul class=""><li id="b2d3" class="mo mp it lf b lg lh lj lk lm mq lq mr lu ms ly mt mu mv mw bi translated"><code class="fe nw nx ny nz b"><strong class="lf jd">Confirmation Bias</strong></code>——倾向于关注证实自己先入之见的信息。</li></ul><p id="dfa2" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">假设你相信癌症和喝酒有很大的关系。当你进行分析时，你只是通过不考虑任何混淆变量来确认这个假设。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oa"><img src="../Images/6f8d9863126e724f59a8e9a3394d994d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a4X2_6v3UfnjHABXjA5uTA.png"/></div></div><p class="ob oc gj gh gi od oe bd b be z dk translated">确认偏差</p></figure><p id="7ab3" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这可能看起来像一个极端的例子，你永远不会做的事情。但现实是，人类天生就有偏见，很难改变这一点。这种事发生在我身上的次数比我愿意承认的次数还要多！</p><h1 id="c1c8" class="nc nd it bd ne nf ng nh ni nj nk nl nm ki nn kj no kl np km nq ko nr kp ns nt bi translated">5.建模</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oj"><img src="../Images/c719e7a9f9a523742f96bc76af1553e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hUULuC9exB-bDbw4yunBoA.jpeg"/></div></div></figure><p id="40b9" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">当谈到人工智能中的偏见时，人们通常指的是以某种方式偏向某一群人的人工智能系统。一个很好的例子是亚马逊创建的<strong class="lf jd">雇佣算法</strong> <a class="ae oi" href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G" rel="noopener ugc nofollow" target="_blank">，它显示了<code class="fe nw nx ny nz b"><strong class="lf jd">Gender Bias</strong></code>的决策。他们用于该算法的数据主要由担任技术职务的男性组成，这导致该算法倾向于将男性作为高潜力候选人。</a></p><p id="846b" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这是一个典型的<code class="fe nw nx ny nz b"><strong class="lf jd">Garbage-in-Garbage-out Phenomenon</strong></code> <strong class="lf jd"> </strong>的例子，你的人工智能解决方案和你使用的数据一样好。这就是为什么在开始数据建模之前<strong class="lf jd">检测数据中的偏差</strong>如此重要。</p><p id="2740" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">让我们来了解一下在创建预测模型时经常看到的几种偏见:</p><ul class=""><li id="9adb" class="mo mp it lf b lg lh lj lk lm mq lq mr lu ms ly mt mu mv mw bi translated"><code class="fe nw nx ny nz b"><strong class="lf jd">Bias/Variance Trade-Off</strong></code>——在<strong class="lf jd">偏差</strong>(模型的基本假设)和<strong class="lf jd">方差</strong>(使用不同数据时预测的变化)之间的权衡。</li></ul><p id="544e" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">具有<strong class="lf jd">高方差</strong>的模型将过于关注训练数据，并且不能很好地概括。<strong class="lf jd">高偏差</strong>，另一方面，假设数据总是以相同的方式运行，这很少是真的。当增加你的偏差时，你通常会降低你的方差，反之亦然。因此，我们经常寻求平衡偏差和方差。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ok"><img src="../Images/579aa7cd7c9232de6a79385d7ef3180a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*QvZdN9Q1bO0v528T.png"/></div></div><p class="ob oc gj gh gi od oe bd b be z dk translated">展示了偏差和方差之间权衡的影响。</p></figure><ul class=""><li id="1e31" class="mo mp it lf b lg lh lj lk lm mq lq mr lu ms ly mt mu mv mw bi translated"><code class="fe nw nx ny nz b"><strong class="lf jd">Concept Drift</strong></code> —目标变量的统计特性随时间以不可预见的方式变化的现象。</li></ul><p id="b745" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">假设您创建了一个模型，可以预测在线商店中客户的行为。这个模型开始时很棒，但是一年后它的性能就下降了。一年来，顾客的行为发生了变化。<strong class="lf jd">客户行为</strong>的概念已经改变，并对您的模型质量产生负面影响。</p><p id="1b00" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">解决方案可以简单地是用新数据频繁地重新训练你的模型，以便与新的行为保持同步。然而，一个全新的模型可能是必要的。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oa"><img src="../Images/cd63aeeda2474ea2b95e1bfbf96ee47b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2KNPVvVWmvBVCUXOdWJK-w.png"/></div></div><p class="ob oc gj gh gi od oe bd b be z dk translated">随着时间的推移和新数据的添加，原始数据(左)与概念漂移(右)的对比。</p></figure><ul class=""><li id="46f1" class="mo mp it lf b lg lh lj lk lm mq lq mr lu ms ly mt mu mv mw bi translated"><code class="fe nw nx ny nz b"><strong class="lf jd">Class Imbalance</strong></code>——(目标)类别出现频率的极度不平衡。</li></ul><p id="39cf" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">假设你想分类一张图片是包含一只猫还是一只狗。如果你有1000张狗的图片，只有10张猫的图片，那么就有一个<code class="fe nw nx ny nz b"><strong class="lf jd">Class Imbalance</strong></code>。</p><p id="6e3d" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">阶级不平衡的结果是模型可能偏向多数阶级。由于数据中的大多数图片都是狗的，因此模型只需要总是猜测“<em class="ol">狗</em>”就可以达到<strong class="lf jd"> 99% </strong> <strong class="lf jd">的准确性。</strong>现实中，模型还没有学会猫和狗图片的区别。这可以通过选择正确的<strong class="lf jd">验证措施</strong>来补救(例如，平衡准确度或F1分数代替准确度)。</p><h1 id="6933" class="nc nd it bd ne nf ng nh ni nj nk nl nm ki nn kj no kl np km nq ko nr kp ns nt bi translated">6.下一步是什么？</h1><p id="fe4e" class="pw-post-body-paragraph ld le it lf b lg om kd li lj on kg ll lm oo lo lp lq op ls lt lu oq lw lx ly im bi translated">在阅读了你的人工智能解决方案中的所有这些潜在偏见之后，你可能会想:</p><blockquote class="or os ot"><p id="567c" class="ld le ol lf b lg lh kd li lj lk kg ll ou ln lo lp ov lr ls lt ow lv lw lx ly im bi translated">"但是我如何从我的解决方案中消除偏见呢？"—你</p></blockquote><p id="2fb0" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我认为要解决偏见，你需要了解它的来源。知道是成功的一半。之后，就要靠你自己想办法消除或处理这种特定的偏见了。例如，如果您发现问题源于数据中的选择偏差，那么最好添加额外的数据。如果类别不平衡使您的模型更偏向于多数群体，那么您可以研究重新采样的策略(例如，SMOTE)。</p><p id="4050" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">注</strong>:关于常见认知偏差的互动概述，请参见<a class="ae oi" href="https://upload.wikimedia.org/wikipedia/commons/6/65/Cognitive_bias_codex_en.svg" rel="noopener ugc nofollow" target="_blank">这一</a>惊人的可视化。</p></div><div class="ab cl ox oy hx oz" role="separator"><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc"/></div><div class="im in io ip iq"><p id="af09" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如果你和我一样，对人工智能、数据科学或心理学充满热情，请随时在<a class="ae oi" href="https://www.linkedin.com/in/mgrootendorst/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上添加我。</p></div></div>    
</body>
</html>