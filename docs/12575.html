<html>
<head>
<title>3 Deep Learning Algorithms in under 5 minutes — Part 1 (Feed forward models)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不到 5 分钟的 3 个深度学习算法—第 1 部分(前馈模型)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/3-deep-learning-algorithms-in-under-5-minutes-part-1-feed-forward-models-1065992e2ccd?source=collection_archive---------15-----------------------#2020-08-30">https://towardsdatascience.com/3-deep-learning-algorithms-in-under-5-minutes-part-1-feed-forward-models-1065992e2ccd?source=collection_archive---------15-----------------------#2020-08-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/251e673bc8712360ffe3da6b588b3b93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ukMSmo6EGViNbxuU5zlHCQ.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图片由来自<a class="ae kf" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=959578" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae kf" href="https://pixabay.com/users/TBIT-715211/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=959578" rel="noopener ugc nofollow" target="_blank"> Thomas Breher </a>拍摄</p></figure><p id="af60" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi le translated"><span class="l lf lg lh bm li lj lk ll lm di">如果</span>你认为机器学习是你没有勇气与之交谈的暗恋对象，深度学习就是你暗恋对象的父亲！由于硬件的前所未有的进步和研究人员对更好更大模型的渴望，深度学习日益变得令人生畏和难以捉摸。每天涌现的研究越多，你应该掌握的基础知识水平就越高。所以，对于那些犹豫是否直接投入到深度学习的阴暗和俗气的好处中的人，我希望这篇文章能增强你的信心。本文不会讨论这些模型的任何数学问题，但会为您提供概念上的强化，让您在血淋淋的数学过程中走得更远。</p><h1 id="b808" class="ln lo it bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">全连接网络</h1><p id="70cd" class="pw-post-body-paragraph kg kh it ki b kj ml kl km kn mm kp kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">你能找到的最简单的深层网络。它通常有一个输入层，一个输出层和可选的中间多个隐藏层。让下面的类比来解释。</p><h2 id="28bd" class="mq lo it bd lp mr ms dn lt mt mu dp lx kr mv mw mb kv mx my mf kz mz na mj nb bi translated">类比:弗兰肯斯坦的实验室</h2><p id="eb3f" class="pw-post-body-paragraph kg kh it ki b kj ml kl km kn mm kp kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">想象你是科学怪人实验室的助手，那里充满了古怪的设备。弗兰肯斯坦刚刚要求你使用下面的仪器，用蓝色、红色、黑色和黄色的颜料来制作紫色、深橙色和绿色。当你把颜料倒在顶部时，根据管子开口的宽度，颜料会流到下面的一系列球上。有一种机制可以改变管子的大小。</p><figure class="nd ne nf ng gt ju gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/993697de04910ddc4d62c9d55e20adbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/1*OqYr3h1FnNomtSU1K4RGtw.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">管子的结构。线条的粗细表示管的厚度。你可以把虚线想象成非常小(或者不存在)的管子</p></figure><p id="7bf8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这类似于 FCN 的工作原理。你给它输入，即特征向量(例如花的各种属性)(例子中的油漆桶)，然后你预测结果(例如花的种类)(例子中的混合颜色)。预测结果是一系列的数学计算(包括矩阵乘法、加法等。).您可能已经意识到该设备已经被配置为最佳配置。达到最佳设置被称为<em class="nh">训练/优化</em>一个模型，它涉及输入特征向量、预测标签和真实标签(在示例中调整管宽度)。它也不需要仅仅是输入层和输出层。你也可以有中间层(即隐藏层)。这是 FCN 真正的样子。(了解更多:<a class="ae kf" href="https://www.oreilly.com/library/view/tensorflow-for-deep/9781491980446/ch04.html" rel="noopener ugc nofollow" target="_blank">这里</a>)</p><figure class="nd ne nf ng gt ju gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/64f0a2e2d659841827b63fe000001382.png" data-original-src="https://miro.medium.com/v2/resize:fit:938/format:webp/1*sjbreWZig8P4NpvPLAY6Kw.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">一种 FCN，用于在给定一些花卉属性的情况下预测正确的花卉种类。</p></figure><h2 id="3c33" class="mq lo it bd lp mr ms dn lt mt mu dp lx kr mv mw mb kv mx my mf kz mz na mj nb bi translated">应用程序</h2><ul class=""><li id="7135" class="nj nk it ki b kj ml kn mm kr nl kv nm kz nn ld no np nq nr bi translated">结构化数据的简单分类任务，例如根据房屋属性预测房价</li></ul><h1 id="db23" class="ln lo it bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">自动编码器</h1><p id="c97a" class="pw-post-body-paragraph kg kh it ki b kj ml kl km kn mm kp kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">自动编码器是一种全连接网络，不同之处仅在于它们的使用方式。它们从一个输入开始，就像 FCNs 一样，将其映射到一个更小的隐藏表示(称为编码)，最后重建原始输入(称为解码)。</p><h2 id="8552" class="mq lo it bd lp mr ms dn lt mt mu dp lx kr mv mw mb kv mx my mf kz mz na mj nb bi translated">类比:回到科学怪人的实验室</h2><p id="bae7" class="pw-post-body-paragraph kg kh it ki b kj ml kl km kn mm kp kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">假设你和你的朋友有两个以上的小工具，并决定玩他们。您将它们组合起来，以便它们共享输出。现在看起来像下面。请注意，底部的管配置是顶部的镜像。</p><figure class="nd ne nf ng gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ns"><img src="../Images/95ad3905a1619a9cf7d3529b174cd005.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pDFvmFHutsm98VvYOkqn3A.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">你和你朋友发明的小玩意。你把颜色倒在顶部和底部，你会得到相同的颜色。</p></figure><p id="a551" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可以从顶部倒颜色，让它们在中间混合。那么一个可以分离不同颜色的“神奇粒子分离器”就会让颜色分离到原来的颜色。你甚至可以在顶部倒一种随机的颜色，让这个流形在底部找出随机的颜色。</p><p id="7970" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是自动编码器中发生的情况。它接受一个输入(本例中为 paint)，计算一个较小的潜在表示(本例中为混合颜色)，最后导出原始输入(本例中为底部的颜色)。这是在真正的自动编码器中的样子。(了解更多:<a class="ae kf" href="http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/" rel="noopener ugc nofollow" target="_blank">自动编码器</a>)</p><figure class="nd ne nf ng gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nt"><img src="../Images/44eb9e786723b47c8dca63260a8655e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fi3GyujwdZ3OugyES5yXIg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">自动编码器在现实生活中是什么样子的。它接受一些输入(例如图像像素)，将其转换为较小的表示形式，然后重建原始输入。</p></figure><h2 id="8601" class="mq lo it bd lp mr ms dn lt mt mu dp lx kr mv mw mb kv mx my mf kz mz na mj nb bi translated">应用程序</h2><ul class=""><li id="e9aa" class="nj nk it ki b kj ml kn mm kr nl kv nm kz nn ld no np nq nr bi translated">恢复损坏的图像-您可以训练自动编码器通过输入损坏的图像并要求模型预测原始图像来恢复图像(类似于识别倒在顶部的随机颜色)。</li><li id="f369" class="nj nk it ki b kj nu kn nv kr nw kv nx kz ny ld no np nq nr bi translated">图像/数据聚类-您可以使用学习到的较小潜在表示作为数据的特征表示代理，从而对数据进行聚类</li></ul><h1 id="18cd" class="ln lo it bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">卷积神经网络</h1><p id="80d2" class="pw-post-body-paragraph kg kh it ki b kj ml kl km kn mm kp kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">啊！计算机视觉的征服者。CNN 非常擅长处理图像。CNN 由卷积层、全连接层和可选的汇集层组成。CNN 接收具有高度、宽度和通道(例如 RGB —红绿蓝)的图像。</p><h2 id="5ad8" class="mq lo it bd lp mr ms dn lt mt mu dp lx kr mv mw mb kv mx my mf kz mz na mj nb bi translated">类比:博物馆抢劫！</h2><p id="4d65" class="pw-post-body-paragraph kg kh it ki b kj ml kl km kn mm kp kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">有一个令人讨厌的逃犯正试图闯入博物馆偷一颗钻石。他走进博物馆计划抢劫。他把地板分成一个 5x5 的格子。然后，他从一个牢房走到另一个牢房，每行从左到右。然后他会查看四个相邻的单元格(即他所在的一个单元格、右边的单元格、上面的单元格和右上角的单元格)。如果他在视野中看到一些障碍物/艺术品，他会在正上方的天花板上射出一个绿色的夜光标记，如果钻石在这 4 个单元中的一个，他会射出一个红色的夜光标记。如果他站在地板上的每个细胞都这样做，他会有下面的计划。有了这个，他可以在晚上偷偷溜进来，即使在漆黑一片的时候也能准确地知道去哪里！</p><figure class="nd ne nf ng gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nz"><img src="../Images/5e1c6175d3706c5441bf67913862a6a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k5dPpjIbmKBosF2wh7foog.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">强盗将如何绘制博物馆的地图。你可以看到，在他偷偷摸摸的小冒险结束时，他得到了两张特征地图，可以帮助他在地板上导航，而不会触发任何警报。</p></figure><p id="69f5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是 CNN 的卷积层所做的。它移动一个内核(强盗想要映射的东西)，这个内核一次只看到图像的一小部分，覆盖在图像上(就像强盗去所有的单元格)。并且在每个位置，它将输出一些值(例如，障碍物是否存在)。这一过程导致了要素地图的开发，这些地图提供了有用的宏观分析信息。最后，将 FCN 连接到最后一个卷积层，因为任何分类/回归任务都需要 FCN。这是典型的 CNN 的样子。(了解更多:<a class="ae kf" rel="noopener" target="_blank" href="/light-on-math-machine-learning-intuitive-guide-to-convolution-neural-networks-e3f054dd5daa?source=---------13------------------">卷积神经网络</a>)。</p><figure class="nd ne nf ng gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oa"><img src="../Images/9fd9826c6c9b02d7616ce505718ff25f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_vEPkNSSuwUVBUP7YXxvDQ.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">一个真正的 CNN。它接收图像并使用卷积层生成多个特征图。可选地，网络具有池化图层，这从本质上减少了要素地图的宽度和高度(有助于减少模型的参数计数),最后还有一个完全连接的网络，允许您进行分类/回归。</p></figure><h2 id="6d3d" class="mq lo it bd lp mr ms dn lt mt mu dp lx kr mv mw mb kv mx my mf kz mz na mj nb bi translated">应用程序</h2><ul class=""><li id="513f" class="nj nk it ki b kj ml kn mm kr nl kv nm kz nn ld no np nq nr bi translated">图像分类—识别图像中存在的对象的类别</li><li id="2e85" class="nj nk it ki b kj nu kn nv kr nw kv nx kz ny ld no np nq nr bi translated">对象检测—识别图像中的所有对象及其位置</li></ul><h1 id="9ea2" class="ln lo it bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">结论</h1><p id="d602" class="pw-post-body-paragraph kg kh it ki b kj ml kl km kn mm kp kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">我们看了三种算法:全连接网络(FCNs)、自动编码器和卷积神经网络(CNN)。以下是主要的几点。</p><ul class=""><li id="85dd" class="nj nk it ki b kj kk kn ko kr ob kv oc kz od ld no np nq nr bi translated">FCN 接受输入特征向量并预测正确的输出类别</li><li id="4fb5" class="nj nk it ki b kj nu kn nv kr nw kv nx kz ny ld no np nq nr bi translated">自动编码器接收输入，将其转换为较小的表示形式，并重建原始输出</li><li id="35f4" class="nj nk it ki b kj nu kn nv kr nw kv nx kz ny ld no np nq nr bi translated">CNN 接收一幅图像，通过一系列卷积/池层发送，最后通过 FCN，预测图像中存在的正确对象类别。</li></ul><h1 id="37b3" class="ln lo it bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">想在深度网络和 TensorFlow 上做得更好？</h1><p id="241a" class="pw-post-body-paragraph kg kh it ki b kj ml kl km kn mm kp kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">检查我在这个课题上的工作。</p><figure class="nd ne nf ng gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oe"><img src="../Images/c902b07566ddcbe9ec0bc8a9c98954cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WVW0Dql9IQhFYMY7JLG7YA.png"/></div></div></figure><p id="c3f0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[1] <a class="ae kf" href="https://www.manning.com/books/tensorflow-in-action" rel="noopener ugc nofollow" target="_blank">(书)TensorFlow 2 在行动——曼宁</a></p><p id="f769" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[2] <a class="ae kf" href="https://www.datacamp.com/courses/machine-translation-in-python" rel="noopener ugc nofollow" target="_blank">(视频课程)Python 中的机器翻译</a> — DataCamp</p><p id="12c1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[3] <a class="ae kf" href="https://www.amazon.com.au/Natural-Language-Processing-TensorFlow-Ganegedara/dp/1788478312/ref=sr_1_25?dchild=1&amp;keywords=nlp+with+tensorflow&amp;qid=1603009947&amp;sr=8-25" rel="noopener ugc nofollow" target="_blank">(书)TensorFlow 中的自然语言处理 1 </a> — Packt</p></div><div class="ab cl of og hx oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="im in io ip iq"><h1 id="2b4f" class="ln lo it bd lp lq om ls lt lu on lw lx ly oo ma mb mc op me mf mg oq mi mj mk bi translated">新的！加入我的新 YouTube 频道</h1><figure class="nd ne nf ng gt ju gh gi paragraph-image"><a href="https://www.youtube.com/channel/UC1HkxV8PtmWRyQ39MfzmtGA/"><div class="gh gi or"><img src="../Images/2519e6851523be15074d78c7082f0545.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*5DsAemiPVQAR0g7YM6OWjQ.png"/></div></a></figure><p id="e698" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你渴望看到我关于各种机器学习/深度学习主题的视频，请确保加入<a class="ae kf" href="https://www.youtube.com/channel/UC1HkxV8PtmWRyQ39MfzmtGA/" rel="noopener ugc nofollow" target="_blank"> DeepLearningHero </a>。</p><h1 id="5b21" class="ln lo it bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">其他文章</h1><p id="fb05" class="pw-post-body-paragraph kg kh it ki b kj ml kl km kn mm kp kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated"><a class="ae kf" rel="noopener" target="_blank" href="/3-deep-learning-algorithms-in-under-5-minutes-part-2-deep-sequential-models-b84e3a29d9a8">第二部分:深度序列模型</a></p></div></div>    
</body>
</html>