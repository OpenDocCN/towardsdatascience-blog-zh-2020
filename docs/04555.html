<html>
<head>
<title>Differential Equations as a Neural Network Layers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">微分方程作为神经网络层</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/differential-equations-as-a-neural-network-layer-ac3092632255?source=collection_archive---------4-----------------------#2020-04-23">https://towardsdatascience.com/differential-equations-as-a-neural-network-layer-ac3092632255?source=collection_archive---------4-----------------------#2020-04-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7c17" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">向神经网络模型添加领域知识的第一步</h2></div><p id="629d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">人工神经网络(ANN)的主要思想是使用称为层的相对简单的函数的组合来建立复杂函数的表示。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/358da84e2d5dbbf75ed01ebfcaa776dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jG7wP7dbFBX6FKVnunGU5A.png"/></div></div></figure><p id="9bb5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一个<strong class="kk iu">深度神经网络</strong>是一个有许多层，或者许多功能组合在一起的网络。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/358da84e2d5dbbf75ed01ebfcaa776dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jG7wP7dbFBX6FKVnunGU5A.png"/></div></div></figure><p id="9f4a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然层通常是简单的函数(例如relu( <em class="lq"> Wx </em> + <em class="lq"> b </em>))，但通常它们可以是任何可微分的函数。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi lr"><img src="../Images/a4d3670791e1996a8bda26875b9ce9e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v9NxkUTOqToLdprkVzAO-A.png"/></div></div></figure><p id="7e82" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该层由参数θ ∈ ℝᵖ.的某个有限向量来指定为了实用，我们需要能够使这一层(或多层)适合数据。这包括定义一个成本或损失函数来衡量模型预测与数据的接近程度。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ls"><img src="../Images/8f8acd5e7b1b1cf763096f3a54cfa9e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lYvm9KSPwY8I9f417hRAaw.png"/></div></div></figure><p id="5a72" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们的层是可微的，那么我们可以找到这个成本函数∇ <em class="lq"> C </em> ( <em class="lq"> θ </em>)的梯度，并使用它以有效的方式找到成本的局部最小值。</p><p id="2ae9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里我考虑微分方程模型。这些系统使用包含当前状态导数的表达式来描述系统(x)的状态随时间的演化。一般来说，它们采取以下形式:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/ad26181e944a84886dbc8354ac09739f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/1*j0SeWmEhPzqLAImfVMQ8dA.png"/></div></figure><p id="1a32" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">微分方程适合我们的神经网络框架，因为它接受一些参数并产生解作为输出，并且它是可微分的。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/a5dbc9a2e53155d8b191576a74392dbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*QksbAr-mPClGsC8H1bFOCQ.png"/></div></figure><p id="e459" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，我们可以使用微分方程作为神经网络中的一层。这真的很棒，有几个原因:</p><ul class=""><li id="ad23" class="lv lw it kk b kl km ko kp kr lx kv ly kz lz ld ma mb mc md bi translated">微分方程是所有物理定律的基本语言。</li><li id="d438" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">在物理学和化学之外，微分方程是描述复杂系统行为的重要工具。在我们的神经网络中使用微分方程模型允许这些模型与神经网络方法相结合。</li><li id="bbfd" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">建立有效的神经网络包括为网络选择一个好的底层结构。通常更容易想到的是描述一个函数如何随时间变化，然后写下这个现象的函数。相对简单的速率法则可以变成非常复杂的行为(参见下面的洛伦兹系统！).</li></ul><p id="cef8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了简单起见，在这篇文章中，我将集中讨论基于单个微分方程层的神经网络。然而，这些层可以很容易地作为一层嵌入到深度学习项目中。深度学习与微分方程形式的领域知识的结合是许多领域的游戏规则改变者。</p><h1 id="81db" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">洛特卡-沃尔泰拉捕食者猎物</h1><p id="9dad" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">为了演示如何将自己的微分方程层构建到神经网络中，我将使用朱莉娅<a class="ae ng" href="https://github.com/FluxML/Flux.jl" rel="noopener ugc nofollow" target="_blank">通量</a>、<a class="ae ng" href="https://github.com/SciML/DiffEqFlux.jl" rel="noopener ugc nofollow" target="_blank">微分通量</a>和<a class="ae ng" href="https://docs.sciml.ai/v5.0.0/" rel="noopener ugc nofollow" target="_blank">微分方程</a>库。在本文中，我将把代码保持为小片段，以允许开发直觉，但是这些示例的完整代码已经在Github repo 中发布。</p><p id="9fde" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，我们将考虑拟合数学生物学中经典模型的参数。Lotka-Volterra捕食者-食饵模型描述了在简单生态群落中可以观察到的种群振荡。</p><p id="0408" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在哈德逊湾贸易公司19世纪的毛皮贸易数据中可以观察到一个著名的例子。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nh"><img src="../Images/5586455741eee4417dcc2775d2e3022b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wAuK87z1qegREsJceMYK2g.png"/></div></div></figure><p id="3b36" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该模型的方程由下式给出</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/ce3ab97ba67788dee051da5cc12fc947.png" data-original-src="https://miro.medium.com/v2/resize:fit:1122/format:webp/1*ZlaWFbKmiKSNyd5nlQ_SNA.png"/></div><p class="nj nk gj gh gi nl nm bd b be z dk translated">Lotka-Volterra捕食者-食饵方程</p></figure><p id="b550" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">捕食者种群的振荡将会滞后于被捕食者种群的峰值。</p><p id="b042" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在让我们使用这个模型作为神经网络中的一层，有一组六个参数。两个用于猎物x₀和捕食者y₀的初始种群，四个速率参数α，β，δ，γ。</p><p id="30d5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在Julia中，我们可以定义这个系统和一组默认参数。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="cc86" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，我们将微分方程层定义为输入参数的函数。参数数组将前两个条目作为初始条件。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="3ee4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来要做的是生成一些假数据来拟合(添加一些噪声)，然后定义一个损失函数。我对我们的数据使用了一个简单的均方误差损失函数，尽管我们当然可以很容易地对损失函数添加一些正则化的参数。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="d5d8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，我们定义一个函数来实际执行模型拟合。这是Julia生态系统真正受益的地方，因为这个系统可以很容易地使用梯度方法来拟合参数。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="3353" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正如你所看到的，我使用了3000次Adams迭代，然后调用BFGS来最小化成本。这是一个很好的组合，你可以直接跳到BFGS，但收敛需要更长的时间。最好是让亚当斯迭代让你在附近，然后结束与BFGS。</p><p id="3497" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">恢复的参数由下式给出:</p><pre class="lf lg lh li gt np nq nr ns aw nt bi"><span id="fe61" class="nu mk it nq b gy nv nw l nx ny">The parameters are [0.9987532818277052, 0.9809616721237869, 1.5075095360807464, 1.009470157647888, 2.974936372236448, 0.993477599859459] with final loss value 2.1229151208653736</span><span id="f783" class="nu mk it nq b gy nz nw l nx ny">The actual parameters should be: [1,1,1.5,1,3,1]</span></pre><p id="9243" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是我们的数据与模拟时间序列数据的对比图。如你所见，最小化结果与数据非常吻合。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/58f0e385e06c70910b738681a8a2c893.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*4VIcxjZzBgOYpeAdDerUvw.png"/></div><p class="nj nk gj gh gi nl nm bd b be z dk translated">Lotka-Volterra捕食者-食饵模型的参数使用最小二乘成本函数上的亚当和BFGS优化进行拟合。对于该合成数据集，参数恢复得非常接近精确。</p></figure><p id="976d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当然，对神经网络的真正考验是它如何推广到验证数据。在这种情况下，我们可以很容易地测试系统的未观察到的初始条件，看看我们的神经网络是否捕捉到了动态。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/ce256e7987a897a6473d2c8c1ff35343.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*yYa6XaYgsiXMzMT-4aQRjA.png"/></div><p class="nj nk gj gh gi nl nm bd b be z dk translated">推广到一组新的初始条件。当然，模型概括得很好，因为我们找到了几乎完全正确的参数。</p></figure><p id="bab9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">太好了，它起作用了！</p><h2 id="8697" class="nu mk it bd ml ob oc dn mp od oe dp mt kr of og mv kv oh oi mx kz oj ok mz ol bi translated">斯图尔特-朗道振子模型</h2><p id="5890" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">现在让我们考虑一下在我的研究领域中经常出现的从动力系统中恢复参数的问题。<a class="ae ng" href="https://en.wikipedia.org/wiki/Stuart%E2%80%93Landau_equation" rel="noopener ugc nofollow" target="_blank"> Stuart-Landau方程</a>描述了接近Hopf分叉(非线性系统中出现普通振荡)的非线性系统的动力学。我将考虑这种变化，它出现在对耦合振子群体<a class="ae ng" href="http://www.lsd.df.uba.ar/materias/dnl/dnl_2011_files/guias_files/Ott_Chaos.pdf" rel="noopener ugc nofollow" target="_blank">的同步研究中。</a></p><p id="25a3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用这个模型的部分动机是由于我对这个模型的熟悉。然而，我还有另一个更深层的动机。Lotka-Volterra捕食者-食饵模型是一个很好的开始模型，但对于数学生物学来说，这是一个奇怪的模型。这是一个保守系统，很像在物理系统中观察到的(没有摩擦)。这意味着Lotka-Volterra系统不是有一个孤立的吸引振荡(称为极限环),而是有一整类同心环。</p><p id="d5d5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这有可能扭曲我们对拟合微分方程模型的理解，因为保守系统保留了对初始条件的记忆。对于极限环振荡，我们会随着时间的推移丢失关于初始条件的信息(瞬态动力学衰减，<a class="ae ng" href="https://en.wikipedia.org/wiki/Arrow_of_time" rel="noopener ugc nofollow" target="_blank">时间箭头</a>)。由于许多初始条件以相同的最终状态结束，这可能使参数恢复的问题更加困难。</p><p id="d105" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该系统的方程由下式给出:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi om"><img src="../Images/c30aafd904d3f18e2f60727bd9045129.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*re7SGozlJYAoXtCMHLGNMg.png"/></div></div></figure><p id="5354" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这些是用极坐标写的。因此，R表示振幅，ψ表示弧度角度。动力学的定性形式为</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi on"><img src="../Images/23fb274189bc3ed35f093d0cdc25f931.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8C5cSfTZt2VE6pwKF7SHoQ.png"/></div></div><p class="nj nk gj gh gi nl nm bd b be z dk translated">斯图尔特-朗道动力学导致稳定的极限环振荡。</p></figure><p id="c425" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在Julia中，更新我们的捕食者-食饵模型来考虑这种类型的系统是一件简单的事情。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="06a3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们定义一个ode层生成一些数据并创建一个损失函数。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="4a00" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，下面的函数创建运行优化来恢复参数。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="f4b3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">恢复的参数由下式给出:</p><pre class="lf lg lh li gt np nq nr ns aw nt bi"><span id="3bc1" class="nu mk it nq b gy nv nw l nx ny">The parameters are [0.02293619193779294, 0.08918144968755219, 0.08304049248335474, 6.275224626122101, 0.11589347566722544, 0.9019465183126854] with final loss value 0.7300967336849258</span><span id="4ed6" class="nu mk it nq b gy nz nw l nx ny">The actual parameters are:<br/>[0.0,0.08,0.1, 6.28, 0.1, 1.0]</span></pre><p id="5215" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">训练数据的拟合如下所示:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/ce2995a23f340367836923c35fcf577a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*Mk9m1NnssyVbfh-NNC2gjw.png"/></div><p class="nj nk gj gh gi nl nm bd b be z dk translated">蓝色表示训练数据的Stuart-Landau振荡器拟合，绿色表示模型预测。左图显示了相平面中的动态特性。右图显示了作为时间函数绘制的幅度R(右上)和相位(右下)。</p></figure><p id="691b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以进一步测试我们的模型，看看它对新的初始值的推广程度。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/d9d878d738068f0673ae74db1a3623db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*JoJYW9pYb7B2A9vd9espcg.png"/></div><p class="nj nk gj gh gi nl nm bd b be z dk translated">使用未观察到的初始条件数据生成的验证数据的Stuart-Landau振荡器拟合显示为蓝色，模型预测显示为绿色。左图显示了相平面中的动态特性。右图显示了作为时间函数绘制的幅度R(右上)和相位(右下)。</p></figure><h2 id="4918" class="nu mk it bd ml ob oc dn mp od oe dp mt kr of og mv kv oh oi mx kz oj ok mz ol bi translated">洛伦兹方程和混沌</h2><p id="0b25" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">现在是有趣的应用程序的时间了。让我们考虑使用混沌系统的时间序列数据进行参数恢复。为此，我们将使用著名的<a class="ae ng" href="https://en.wikipedia.org/wiki/Lorenz_system" rel="noopener ugc nofollow" target="_blank">洛伦兹系统。</a></p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/fa8a412101142519bbe28fb5e32fdc01.png" data-original-src="https://miro.medium.com/v2/resize:fit:410/format:webp/1*AoyaASA2z8OWH1JDzycifQ.png"/></div><p class="nj nk gj gh gi nl nm bd b be z dk translated">三维洛伦兹系统。最初用作大气流体动力学(对流)的简单模型。我们将选择给出混沌解的标准参数值(σ=10，ρ=28，β=8/3)。</p></figure><p id="fd0b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在Julia中定义这个系统很简单:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="2b32" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">作为演示，让我们看一下从稍微不同的初始条件值生成的X变量的一些时间序列数据。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/357bdd7fe89c3fa71f3155263ac26685.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*s8LPhyZBnCFl5kQd64R5eA.png"/></div><p class="nj nk gj gh gi nl nm bd b be z dk translated">x变量作为时间的函数，三个初始条件非常接近。</p></figure><p id="94d6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该图显示了对初始条件的敏感依赖，这是混沌的标志。</p><p id="7cae" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通常，我们定义一个依赖于初始条件和参数的微分方程层。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="09dc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">生成一些数据，给时间序列添加一些噪声，并定义我们通常的误差函数。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="a30d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在使用DiffEqFlux库定义训练函数。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="26a6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">运行优化可以很好地拟合训练数据，当我们对训练样本之外的时间进行积分时，这种拟合可以很好地概括。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/0c5a03cf7d8702c94f2f8014cd5a1c6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*sRIg7ovEaQS7waBw05q_WQ.png"/></div><p class="nj nk gj gh gi nl nm bd b be z dk translated">相空间绘制t ∈ [0，30]的真实系统(蓝色)与模型预测(绿色)的关系图。</p></figure><p id="34dd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们还可以查看适合时间序列图的训练模型。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/5fac618af9fa8328bf6ea506ccbc6960.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*X7x_xNG7XmU8OB4fr62fCQ.png"/></div><p class="nj nk gj gh gi nl nm bd b be z dk translated">蓝色显示的(扩展)训练数据的时间序列与绿色显示的拟合模型预测。在模型预测和数据出现分歧的t ≈ 22之前，它们一直非常接近。该模型仅针对t ∈ [0，10]的数据进行训练。因此，该模型能够对大约两倍长度的训练数据进行准确预测。</p></figure><p id="6e9b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于该模型仅在t ∈ [0，10]上训练，我们可以看到该模型对t ∈ [10，20]的概括非常好，但在此时间之后很快偏离真实值。</p><pre class="lf lg lh li gt np nq nr ns aw nt bi"><span id="37cf" class="nu mk it nq b gy nv nw l nx ny">The parameters are [0.9727986684296102, 0.034212291835795355, -0.001627150535904438, 9.99887680497206, 28.00267472723392, 2.666573010932292] with final loss value 1.7015586033442565</span><span id="22f4" class="nu mk it nq b gy nz nw l nx ny">The actual parameters are:<br/>[1.0,0.0,0.0,10.0,28.0,2.6666666666666665]</span></pre><p id="a400" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以我们找到了一个非常合适的。</p><h2 id="0d6d" class="nu mk it bd ml ob oc dn mp od oe dp mt kr of og mv kv oh oi mx kz oj ok mz ol bi translated">结论</h2><p id="08d3" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">使用Julia生态系统(<a class="ae ng" href="https://github.com/SciML" rel="noopener ugc nofollow" target="_blank">科学机器学习sciml) </a>将微分方程模型包括到神经网络中是相对简单的。这使得我们能够通过经典的动态系统模型将整个知识分支纳入到我们的神经网络模型中，用于时序数据。下一步是将这些微分方程层结合到我们的深度学习模型中。</p><p id="0032" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">关于动力系统和人工神经网络的接口问题。我们从这里开始的三个可能的概括是:</p><ul class=""><li id="37cd" class="lv lw it kk b kl km ko kp kr lx kv ly kz lz ld ma mb mc md bi translated"><a class="ae ng" href="https://arxiv.org/abs/1806.07366" rel="noopener ugc nofollow" target="_blank">神经微分方程</a>是一个术语，用来描述使用人工神经网络函数作为动力系统的右端。由于这些系统利用了一般的人工神经网络功能，它们可能<a class="ae ng" rel="noopener" target="_blank" href="/work-smarter-not-harder-when-building-neural-networks-6f4aa7c5ee61">在建模时间序列</a>时表现出较差的收敛性。</li><li id="ec02" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated"><a class="ae ng" href="https://arxiv.org/abs/2001.04385" rel="noopener ugc nofollow" target="_blank">通用微分方程</a>是一个用于混合数学模型和人工神经网络函数的术语。这里的想法是指定尽可能多的动态，然后让ANN填入未建模的动态、<a class="ae ng" href="https://github.com/SciML/DiffEqFlux.jl#universal-differential-equations-for-neural-optimal-control" rel="noopener ugc nofollow" target="_blank">控制函数</a>等。这些系统可以表现出更快的收敛速度，并允许我们将神经网络的能力与领域知识相结合来描述高维函数。</li><li id="39a8" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated"><a class="ae ng" href="https://arxiv.org/abs/1803.04779" rel="noopener ugc nofollow" target="_blank">混合动力系统</a>用于将微分方程模型(或更一般的某种领域知识)与单独的机器学习方法相结合。存在这些类型的许多变体，但我会区分这个类，它将机器学习模型与领域模型分开。然后可以将它们组合起来或作为输入输入到另一个中。</li></ul><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi op"><img src="../Images/dfc8f8d93e5e5c05645f8106efb06c73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IepNrDA8lDko21gOI30JpA.png"/></div></div></figure><p id="f1ad" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">此外，我应该提到，我们在本文中讨论的所有模型都可以很容易地转移到GPU进行训练。只需在GPU 上声明<a class="ae ng" href="https://julialang.org/blog/2019/01/fluxdiffeq/" rel="noopener ugc nofollow" target="_blank">初始条件。</a></p><p id="4681" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">提醒:本文<a class="ae ng" href="https://github.com/khannay/FittingParamsDiffEqFlux/" rel="noopener ugc nofollow" target="_blank">的所有代码都可以在这里找到</a>。</p><p id="5ea9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">快乐造型！</p></div></div>    
</body>
</html>