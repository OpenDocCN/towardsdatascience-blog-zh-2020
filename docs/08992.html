<html>
<head>
<title>Sarcasm Classification (Using FastText)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">讽刺分类(使用快速文本)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/sarcasm-classification-using-fasttext-788ffbacb77b?source=collection_archive---------36-----------------------#2020-06-28">https://towardsdatascience.com/sarcasm-classification-using-fasttext-788ffbacb77b?source=collection_archive---------36-----------------------#2020-06-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/9bb9610e1bf0d0d7fa2f6649fca772bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nDonoHq7uVnPsWa1Bjk5Fg.png"/></div></div></figure><div class=""/><div class=""><h2 id="9499" class="pw-subtitle-paragraph kb jd je bd b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks dk translated">我们将使用 FastText python 模块为新闻标题构建一个讽刺分类器。</h2></div><p id="aed7" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">FastText 是由脸书研究团队创建的一个库，用于高效学习单词表示法和句子分类。它在 NLP 社区中吸引了很多人，特别是作为一个强大的单词表示基线，取代了 word2vec，因为它在获取单词向量时考虑了字符 n 元语法。这里我们将使用 FastText 进行文本分类。</p><p id="1cfe" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">数据收集自<a class="ae lp" href="https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/RMI SRA/news-headlines-dataset-for-sneach-detection</a>。这里讽刺的是来自<a class="ae lp" href="https://www.theonion.com/" rel="noopener ugc nofollow" target="_blank"><em class="lq">TheOnion</em></a><em class="lq"/>而非讽刺的是来自<em class="lq"/><a class="ae lp" href="https://www.huffingtonpost.com/" rel="noopener ugc nofollow" target="_blank"><em class="lq">HuffPost</em></a>。现在让我们跳到编码。</p><p id="e5d5" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">首先，让我们检查数据来决定方法。可以从<a class="ae lp" href="https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection/data?select=Sarcasm_Headlines_Dataset_v2.json" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/RMI SRA/news-headlines-dataset-for-stranship-detection/data 下载数据？select =挖苦 _ 头条 _ 数据集 _v2.json </a>。</p><pre class="lr ls lt lu gt lv lw lx ly aw lz bi"><span id="9b2c" class="ma mb je lw b gy mc md l me mf"><em class="lq">#load data</em><br/><strong class="lw jf">import</strong> <strong class="lw jf">pandas</strong> <strong class="lw jf">as</strong> <strong class="lw jf">pd</strong><br/>df = pd.read_json("Sarcasm_Headlines_Dataset_v2.json", lines=<strong class="lw jf">True</strong>)<br/>#shuffle the data inplace<br/>df = df.sample(frac=1).reset_index(drop=<strong class="lw jf">True</strong>)<br/><em class="lq"># show first few rows</em><br/>df.head()</span></pre><figure class="lr ls lt lu gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mg"><img src="../Images/654004dc863b3819250d28e696782eaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zCujhnhDVoHe3djUG1kDeA.png"/></div></div></figure><p id="c014" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">基本上，在阅读带有 pandas 的表格形式的 json 时，数据集包含 3 列，其中‘headline’包含新闻的标题文本,‘is _ anticate’包含分别表示讽刺和非讽刺的 1 和 0。如果我们看到讽刺和非讽刺的例子的代表性是</p><p id="8c90" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">0 14985<br/>1 13634<br/>Name:is _ sniptic，dtype: int64</p><p id="f13f" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">现在来看看课文是如何寻找讽刺和非讽刺的例子的:</p><pre class="lr ls lt lu gt lv lw lx ly aw lz bi"><span id="7952" class="ma mb je lw b gy mc md l me mf">#word cloud on sarcastic headlines</span><span id="6e96" class="ma mb je lw b gy mh md l me mf">sarcastic = ‘ ‘.join(df[df[‘is_sarcastic’]==1][‘headline’].to_list())</span><span id="9ff0" class="ma mb je lw b gy mh md l me mf">plot_wordcloud(sarcastic, ‘Reds’)</span></pre><figure class="lr ls lt lu gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mi"><img src="../Images/d1b2957a0a28e8af848e253643263bcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p5M6Ig66_Q524iHjbjSUng.png"/></div></div></figure><pre class="lr ls lt lu gt lv lw lx ly aw lz bi"><span id="2643" class="ma mb je lw b gy mc md l me mf"><em class="lq">#word cloud on sarcastic headlines</em> sarcastic = ' '.join(df[df['is_sarcastic']==0]['headline'].to_list()) plot_wordcloud(sarcastic, 'Reds')</span></pre><figure class="lr ls lt lu gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mj"><img src="../Images/e36f9b692705e5c14cb1b5253f0f91bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fLwBc7Z0XIIBUDvmjLgAWg.png"/></div></div></figure><p id="2597" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">现在，在构建分类器模型之前，我们需要对文本进行一些清理，以消除噪声。既然这些都是新闻标题，就不包含太多废话。我想到的清理是把所有的字符串都变成小写，去掉所有不是字母数字的内容，用一个特定的标签替换数字。</p><pre class="lr ls lt lu gt lv lw lx ly aw lz bi"><span id="f41f" class="ma mb je lw b gy mc md l me mf">df['headline'] = df['headline'].str.lower()<br/>df['headline'] = df['headline'].apply(alpha_num)<br/>df['headline'] = df['headline'].apply(replace_num)</span></pre><p id="0aff" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">现在，我们已经准备好清理文本和它们相应的标签来构建一个二元讽刺分类器。如前所述，我们将使用 FastText python 模块构建模型。</p><p id="8c7a" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">首先，需要在环境中安装 FastText python 模块。</p><pre class="lr ls lt lu gt lv lw lx ly aw lz bi"><span id="98d8" class="ma mb je lw b gy mc md l me mf"><em class="lq">#Building fasttext for python\</em> <br/>!git clone https://github.com/facebookresearch/fastText.git <br/>!cd fastText<br/>!pip3 install .</span></pre><p id="3f67" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我们需要以 FastText api 可以理解的格式准备好训练和测试文件。我们希望用来训练模型的文本文件的默认格式应该是 __ label __ <label> <text>。我们可以使用其他前缀来代替 __label__ 通过在训练时相应地改变参数，这一点我们将在前面看到。</text></label></p><pre class="lr ls lt lu gt lv lw lx ly aw lz bi"><span id="3997" class="ma mb je lw b gy mc md l me mf"><em class="lq">#data preparation for fasttext</em><br/><strong class="lw jf">with</strong> open('fasttext_input_sarcastic_comments.txt', 'w') <strong class="lw jf">as</strong> f:<br/>    <strong class="lw jf">for</strong> each_text, each_label <strong class="lw jf">in</strong> zip(df['headline'], df['is_sarcastic']):<br/>        f.writelines(f'__label__<strong class="lw jf">{each_label}</strong> <strong class="lw jf">{each_text}\n</strong>')</span></pre><p id="dca6" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">文件中的数据如下所示:</p><pre class="lr ls lt lu gt lv lw lx ly aw lz bi"><span id="f96a" class="ma mb je lw b gy mc md l me mf">!head -n 10 fasttext_input_sarcastic_comments.txt</span><span id="3959" class="ma mb je lw b gy mh md l me mf">__label__1 school friends dont find camp songs funny<br/>__label__0 what cutting americorps would mean for public lands<br/>__label__0 when our tears become medicine<br/>__label__1 craig kilborn weds self in private ceremony<br/>__label__1 white couple admires fall colors<br/>__label__1 mom much more insistent about getting grandkids from one child than other<br/>__label__0 diary of a queer kids mom<br/>__label__1 sephora makeup artist helping woman create the perfect pink eye<br/>__label__1 kelloggs pulls controversial chocobastard from store shelves<br/>__label__0 winston churchills grandson introduces a new nickname for donald trump</span></pre><p id="4f5c" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这里 __label__0 表示非讽刺，__label__1 表示讽刺。现在我们已经准备好开始训练分类器模型了。为此，将把数据集分为训练(90%)和测试(10%)数据集。用于监督二元分类的 FastText 函数是<em class="lq"> train_supervised </em>。</p><pre class="lr ls lt lu gt lv lw lx ly aw lz bi"><span id="a06e" class="ma mb je lw b gy mc md l me mf"><em class="lq">''</em><br/><em class="lq">For classification train_supervised call will be used:</em><br/><br/><em class="lq">The default parameters to it:</em><br/><em class="lq">    input             # training file path (required)</em><br/><em class="lq">    lr                # learning rate [0.1]</em><br/><em class="lq">    dim               # size of word vectors [100]</em><br/><em class="lq">    ws                # size of the context window [5]</em><br/><em class="lq">    epoch             # number of epochs [5]</em><br/><em class="lq">    minCount          # minimal number of word occurences [1]</em><br/><em class="lq">    minCountLabel     # minimal number of label occurences [1]</em><br/><em class="lq">    minn              # min length of char ngram [0]</em><br/><em class="lq">    maxn              # max length of char ngram [0]</em><br/><em class="lq">    neg               # number of negatives sampled [5]</em><br/><em class="lq">    wordNgrams        # max length of word ngram [1]</em><br/><em class="lq">    loss              # loss function {ns, hs, softmax, ova} [softmax]</em><br/><em class="lq">    bucket            # number of buckets [2000000]</em><br/><em class="lq">    thread            # number of threads [number of cpus]</em><br/><em class="lq">    lrUpdateRate      # change the rate of updates for the learning rate [100]</em><br/><em class="lq">    t                 # sampling threshold [0.0001]</em><br/><em class="lq">    label             # label prefix ['__label__']</em><br/><em class="lq">    verbose           # verbose [2]</em><br/><em class="lq">    pretrainedVectors # pretrained word vectors (.vec file) for supervised learning []</em><br/><em class="lq">'''</em><br/>model = fasttext.train_supervised('sarcasm_train.bin', wordNgrams=2)</span></pre><p id="e11c" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">要测量测试数据集中的性能:</p><pre class="lr ls lt lu gt lv lw lx ly aw lz bi"><span id="a718" class="ma mb je lw b gy mc md l me mf"><em class="lq">#measuring performance on test data</em><br/><strong class="lw jf">def</strong> print_results(sample_size, precision, recall):<br/>    precision   = round(precision, 2)<br/>    recall      = round(recall, 2)<br/>    print(f'{sample_size=}')<br/>    print(f'{precision=}')<br/>    print(f'{recall=}')<br/><br/>print_results(*model.test('sarcasm_test.bin'))</span><span id="0565" class="ma mb je lw b gy mh md l me mf"><strong class="lw jf"><em class="lq">sample_size=2862 <br/>precision=0.87 <br/>recall=0.87</em></strong></span></pre><p id="b7ed" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">结果虽然不完美，但看起来很有希望。我们现在保存模型对象，以便将来进行推理。</p><pre class="lr ls lt lu gt lv lw lx ly aw lz bi"><span id="507c" class="ma mb je lw b gy mc md l me mf"><em class="lq">#save the model</em><br/>model.save_model('fasttext_sarcasm.model')</span></pre><p id="51d5" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">FastText 还能够压缩模型，以便通过量化牺牲一点点性能来获得更小的模型文件。</p><pre class="lr ls lt lu gt lv lw lx ly aw lz bi"><span id="9028" class="ma mb je lw b gy mc md l me mf"># with the previously trained `model` object, call<br/>model.quantize(input='sarcasm_train.bin', retrain=True)\<br/># results on test set<br/>print_results(*model.test('sarcasm_test.bin'))</span><span id="9b0b" class="ma mb je lw b gy mh md l me mf"><strong class="lw jf"><em class="lq"><br/>sample_size=2862 <br/>precision=0.86 <br/>recall=0.86</em></strong></span></pre><p id="ed28" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">如果你看到精度和召回似乎遭受 0.01 分，但是，看看模型文件大小:</p><pre class="lr ls lt lu gt lv lw lx ly aw lz bi"><span id="a90f" class="ma mb je lw b gy mc md l me mf">!du -kh ./fasttext_sarcasm*</span><span id="de23" class="ma mb je lw b gy mh md l me mf"><strong class="lw jf"><em class="lq">98M ./fasttext_sarcasm.ftz<br/>774M ./fasttext_sarcasm.model</em></strong></span></pre><p id="aaf8" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">压缩模型只有基本模型的 1/12。因此，这是模型大小和性能之间的权衡，用户必须根据用例来决定。既然分类器模型已经训练好并准备好了，现在是准备好推理脚本的时候了，这样您就可以计划部署了。</p><pre class="lr ls lt lu gt lv lw lx ly aw lz bi"><span id="fb6b" class="ma mb je lw b gy mc md l me mf">def predict_is_sarcastic(text):<br/>    return SarcasmService.get_model().predict(text, k=2)</span><span id="3e96" class="ma mb je lw b gy mh md l me mf">if __name__ == '__main__':<br/>    ip = 'Make Indian manufacturing competitive to curb Chinese imports: RC Bhargava'<br/>    print(f'Result : {predict_is_sarcastic(ip)}')</span><span id="27cc" class="ma mb je lw b gy mh md l me mf"><strong class="lw jf"><em class="lq">Result : (('__label__0', '__label__1'), array([0.5498156 , 0.45020437]))</em></strong></span></pre><p id="fe96" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">从上面可以看出，最大概率的结果标签是 __label__0，这意味着根据训练的模型，所使用的标题是非讽刺性的。在 model.predict()调用中，k 的值表示您希望输出的类的数量以及它们各自的概率分数。由于我们使用了 softmax 激活(FastText 中默认的一个)，两个标签的概率之和为 1。</p><p id="32a5" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">总之，在进行任何 NLP 分类时，FastText 可以是一个强大的基线，并且它的实现非常容易。这篇文章的所有源代码可以在<a class="ae lp" href="https://github.com/sambit9238/Deep-Learning/tree/master/sarcasm_classifier" rel="noopener ugc nofollow" target="_blank">我的 git repo </a>找到。FastText python 模块没有得到官方支持，但对于技术人员来说，这不应该是一个实验问题:)。在以后的文章中，波斯特将尝试讨论如何将训练好的模型转移到生产中。</p><div class="is it gp gr iu mk"><a href="https://github.com/facebookresearch/fastText/tree/master/python" rel="noopener  ugc nofollow" target="_blank"><div class="ml ab fo"><div class="mm ab mn cl cj mo"><h2 class="bd jf gy z fp mp fr fs mq fu fw jd bi translated">Facebook 研究/快速文本</h2><div class="mr l"><h3 class="bd b gy z fp mp fr fs mq fu fw dk translated">fastText 是一个用于高效学习单词表示和句子分类的库。在本文档中，我们…</h3></div><div class="ms l"><p class="bd b dl z fp mp fr fs mq fu fw dk translated">github.com</p></div></div><div class="mt l"><div class="mu l mv mw mx mt my ja mk"/></div></div></a></div><div class="is it gp gr iu mk"><a href="https://github.com/sambit9238/Deep-Learning/tree/master/sarcasm_classifier" rel="noopener  ugc nofollow" target="_blank"><div class="ml ab fo"><div class="mm ab mn cl cj mo"><h2 class="bd jf gy z fp mp fr fs mq fu fw jd bi translated">sambit 9238/深度学习</h2><div class="mr l"><h3 class="bd b gy z fp mp fr fs mq fu fw dk translated">深度学习技术在自然语言处理、计算机视觉等领域的实现。-sambit 9238/深度学习</h3></div><div class="ms l"><p class="bd b dl z fp mp fr fs mq fu fw dk translated">github.com</p></div></div><div class="mt l"><div class="mz l mv mw mx mt my ja mk"/></div></div></a></div></div></div>    
</body>
</html>