<html>
<head>
<title>The Balance-Sample Size Frontier in Matching</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">匹配中的平衡样本量边界</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-balance-sample-size-frontier-in-matching-f7929ff49022?source=collection_archive---------69-----------------------#2020-06-02">https://towardsdatascience.com/the-balance-sample-size-frontier-in-matching-f7929ff49022?source=collection_archive---------69-----------------------#2020-06-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0f1a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">它是什么，它是如何工作的？</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ac4435d14c55f5fc7d95bd68a7e770cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Dxgz1eN9tUfBzYmw"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@jeremythomasphoto?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">杰瑞米·托马斯</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="bd2c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://gking.harvard.edu/" rel="noopener ugc nofollow" target="_blank"> Gary King </a>教授和他的同事<a class="ae ky" href="http://christopherlucas.org/" rel="noopener ugc nofollow" target="_blank">克里斯托弗·卢卡斯</a>和<a class="ae ky" href="https://polisci.mit.edu/people/richard-nielsen" rel="noopener ugc nofollow" target="_blank">理查德·a·尼尔森</a>在2017年<em class="lv">美国政治科学杂志</em>上发表了一篇名为《因果推理匹配方法中的平衡-样本规模前沿》的论文。在论文摘要中，他们写道:“我们提出了一种简化的因果推断匹配方法，该方法同时优化了平衡和匹配样本大小。”这篇论文引起了我的注意，因为它与匹配的重要偏差-方差权衡相关。</p><p id="bfb9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文旨在对King等人(2017)提出的方法进行非技术性描述。这种方法如何工作，为什么工作？该方法的独特之处是什么？当我看报纸时，这些问题一直萦绕在我的脑海里。希望这篇文章也能帮助你回答这些问题。请注意，我希望您已经知道匹配的基本知识，这对理解下面的内容是必要的。如果你不知道，我推荐你阅读我以前的帖子(这里是<a class="ae ky" rel="noopener" target="_blank" href="/looking-inside-mahalanobis-metric-matching-4e43cca46a6?source=friends_link&amp;sk=b3ad528c602cbd455cec88d96f856912">这里是</a>，这里是<a class="ae ky" rel="noopener" target="_blank" href="/matching-estimator-is-powerful-and-simple-82350f08515a?source=friends_link&amp;sk=b8a73192ec18ea60f2cf8e17b2ae25f3">这里是</a>)可能会有帮助。</p><h1 id="c03e" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">问题是</h1><p id="0b2f" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">那么什么是匹配边界呢？</p><blockquote class="mt mu mv"><p id="089f" class="kz la lv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated">匹配边界是“对于每个样本量，具有最大可能平衡的匹配解的集合。”(第473页，金等人著，2017年)。</p></blockquote><p id="7891" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">众所周知，匹配的一个关键目标是减少协变量的不平衡。通过匹配，我们得到一个在协变量上有更好平衡的匹配数据集。因此，我们可以更有把握地将差异归因于治疗，并且估计会更少偏差。</p><p id="36b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在实践中，我们通常不得不从数据集中删除不匹配的观察值。这就是卡尺匹配所做的——它丢弃距离大于研究者选择的最大容许差异的不良匹配。</p><p id="7128" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">丢弃数据可能会帮助我们获得更好的平衡。然而，它也可能增加因果效应估计的方差。这很直观——用更少的数据获得更多的不确定性。事实上，平衡和样本大小之间的权衡很大程度上是偏差和方差之间的权衡，而这两者对于估计量的质量都很重要。</p><p id="6979" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你会使用一个更小的数据集(因此更高的方差)和更好的平衡(因此更小的偏差)吗？或者你会使用一个更大的数据组(因此方差更小)和更差的平衡(因此偏差更大)？所以，你现在可以看到问题了。</p><h1 id="e61d" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">提议的解决方案</h1><p id="78b1" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">许多关于匹配的论文已经解决了平衡和样本大小之间的权衡问题，他们提出的策略是相似的:在获得平衡数据时(希望如此)，尽可能少地修剪数据。实施这些策略涉及任意选择(例如，丢弃哪些ob)，并且已经提出了一些规则来指导这个过程(参见这里的综述<a class="ae ky" href="https://www.tandfonline.com/doi/full/10.1080/07474938.2017.1318509" rel="noopener ugc nofollow" target="_blank"/>)。但是你需要选择。</p><p id="8a7f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">King等人(2017)提出的解决方案是，你不要挑挑拣拣，而是展示你得到的一切。具体来说，他们建议在修剪数据时，显示在给定样本量中具有最佳协变量平衡的所有估计。称为匹配边界的一组估计值是最优的，因为每个估计值都是给定样本量时可以得到的最佳(最大平衡下的最小偏差)估计值。</p><p id="6228" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下图很好地说明了匹配边界的概念，其中King等人(2017年)展示了修剪数据(从最差匹配开始)如何随着Mahalanobis距离的减小(左图)增加数据平衡并改变治疗效果估计值(右图)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/b2d5117b329950c885733c3251190aa6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mlzZGkMb9v4CY2O2AdqLcw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图一。匹配边界。来源:King等人(2017年)</p></figure><h1 id="3735" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">他们是如何得到匹配边界的？</h1><p id="7fc6" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">那么他们是如何得到匹配边界的呢？他们分两步得到它。为了向您解释这些步骤，我使用了一个包含40个观察值的迷你数据集，这些观察值是从lalonde数据集中随机选择的。这个小型数据集有5个处理单位和35个对照单位。此外，为了简单起见，我只匹配两个变量:教育和年龄。我关注基于Mahalanobis距离度量的替换匹配，因为它很流行。</p><p id="4679" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图2按治疗组(1-治疗组，0-对照组)显示了每个观察单位的两个协变量的值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/06c77ca11062f1805b9243bf56a42aed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1szGpRTDwUZTbgg3YdyX1A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图二。具有5个处理单位和35个对照单位的迷你数据集中的协变量值</p></figure><p id="c436" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">在第一步，他们定义了一个数据驱动的规则来修剪数据。</strong></p><p id="8967" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">具体来说，他们从计算每个处理或控制单位的处理组之间的最小Mahalanobis距离开始。这里有一个例子。设迷你数据集中的五个处理单元是B1、B2、B3、B4、B5。我们将计算控制单元(比如A1)和每个处理单元之间的Mahalanobis距离。假设计算出的马氏距离分别为1.5，1，3.2，4.4，3。在这种情况下，控制单元A1的最小马哈拉诺比斯距离是1，并且与A1的最佳匹配是B2。类似地，我们可以计算其他控制或处理单元的最小Mahalanobis距离。程序是一样的。</p><p id="4457" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">修剪数据的规则是，我们首先丢弃最小Mahalanobis距离相对较大的单元，无论它是处理单元还是对照单元。直观上，最小Mahalanobis距离度量数据集中一个单元和其余单元之间的相似性。根据规则，我们首先去除与其他单元相似度最低的单元。</p><p id="e57e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在图1中，点的大小代表计算的最小距离。最小距离越大，点数越大。数字标签是最小距离的相对顺序，也是要丢弃的顺序。例如，我们可以看到在图1的最顶端，有一个标记为1的点。当我们开始修剪数据时，这个单元(恰好是一个控制单元)将是第一个被删除的单元。这是因为它具有最大的最小距离。然后修剪到具有第二大最小距离的另一个单元(在图1的底部)。在数据修剪的最后阶段，仅保留最小距离的单元。这些单元主要位于图1的左侧和中间部分。</p><p id="f425" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在第二步，他们使用加权最小二乘法来估计治疗效果以及修剪数据。</p><p id="b4be" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦设定了用于删减数据的规则，他们就在删减数据的同时评估治疗效果。匹配边界只是所有这些估计的组合。</p><p id="8179" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该估计基于加权最小二乘法。是的，它类似于逆概率加权(见这里的介绍<a class="ae ky" href="https://medium.com/swlh/demystifying-the-inverse-probability-weighting-method-b5056ba3a72d?source=friends_link&amp;sk=0b04bac1eb248a59ee1ac8fe5e93130f" rel="noopener"/>)，但是使用了非常不同的权重。</p><p id="7619" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">他们分两步得到重量。首先，他们将数据点分配给地层，在图1中用颜色表示。从网络的角度来看，层之间的单元在匹配期间是彼此断开的，而层内的单元在匹配期间是相互连接的。例如，如果发现控制单元A1与处理单元B1最匹配，而A1也与处理单元B2最匹配。然后，A1、B1和B2将被分配到同一层。</p><p id="77a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您仍然感到困惑，这里是匹配的网络图(图3)(具有最低的Mahalanobis距离)。你可以在图中看到有四个集群。每个聚类被认为是一个层。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/5e88d0654d07b86135284f35f7724e4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/1*y-L8QtVHT-PIFj2vwJSFjQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图3。比赛的网络图</p></figure><p id="24e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">处理单元的重量仅为1。对照单位的权重为(m0/m1)*(k1/k0)，其中m0和m1分别是数据集中对照和处理单位的数量。k1和k0是包含观察结果的地层中的处理单元和控制单元的数量。</p><h1 id="8e50" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">摘要</h1><p id="f3cc" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在这篇文章中，我讨论了匹配边界，这是Hary King教授和他的同事在2017年的论文中提出的一个概念。匹配边界是解决匹配中平衡和样本大小之间的权衡，也是偏倚和方差之间的权衡。我还向您展示了匹配边界可以通过两个步骤获得:定义修剪数据的规则，然后使用加权最小二乘法估计治疗效果。</p><p id="d33b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我看来，作者删减数据的方式并不新鲜。在修剪数据时，我们总是从丢弃最不匹配的单元开始。井径匹配做到了这一点，大部分发表的论文也做到了这一点。想法已经有了。他们在第二步定义权重的方式对我来说是新的。我从没在文献中见过这个。据我所知，大部分论文都用倾向得分的倒数作为权重。</p><p id="d0ad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">综上所述，我认为匹配边界对于稳健性分析非常有用。使用匹配边界，您可以显示估计值如何对对匹配至关重要的公共支持假设的潜在违反敏感。</p><p id="dc33" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我未来的帖子中，我将向您展示如何在r中获得匹配边界。此外，我将讨论在<em class="lv">大数据</em>和<em class="lv"> </em>的背景下实施匹配边界的挑战，我还将与您分享我的策略和代码，它们可以有效地应对这些挑战。</p><h1 id="e2bb" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">参考</h1><p id="88a1" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">金、加里、克里斯托弗·卢卡斯和理查德·尼尔森。2017."因果推理匹配方法中的平衡样本量边界."<em class="lv">美国政治科学杂志</em>61(2):473–89。<a class="ae ky" href="https://doi.org/10.1111/ajps.12272" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1111/ajps.12272</a>。</p></div></div>    
</body>
</html>