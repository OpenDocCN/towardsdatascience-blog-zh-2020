<html>
<head>
<title>14 Deep and Machine Learning Uses that made 2019 a new AI Age.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">14 种深度和机器学习的使用使 2019 年成为一个新的人工智能时代。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/14-deep-learning-uses-that-blasted-me-away-2019-206a5271d98?source=collection_archive---------2-----------------------#2020-01-05">https://towardsdatascience.com/14-deep-learning-uses-that-blasted-me-away-2019-206a5271d98?source=collection_archive---------2-----------------------#2020-01-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3466" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">比格根、塞勒根、斯泰尔根、高根、艺术育种家、德奥迪菲等。:我非常私人的清单(包括奖金)。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a06b7a07e1150dccea0bd60623829092.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VKE8YeK_x3WZIgoppuW6tA.png"/></div></div></figure><p id="a67d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi lq translated"><span class="l lr ma bm di mb"> <img alt="T" class="ks mc md me mf mg fc n ih dh bf" src="../Images/8ebcce6f7ca915ae9b80abcb158c86ad.png" width="66" height="79" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fit:132/1*DuBXbm9w1qkD_9JMypzsNA.jpeg"/> <span class="l lr ls lt bm lu lv lw lx ly di lz"> T </span> </span> ime 的流动比我们想象的要快。对摩尔定律有好处。但仍有很多要赶上。在下面，我想列出我在机器学习和深度学习领域在 2019 年发生的伟大事情(<em class="mh">和——抱歉作弊——2018 年也有一些</em>)。这些大多是基于神经网络的模型，让我印象深刻。</p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><p id="ac3d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">首先，这里是伊恩·古德菲勒的一条推文，完美地展示了深度学习的成就。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="32e1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">即使是关于一个特定的话题:生成性对抗网络的进展，这种进展很好地展示了已经发生的事情，以及将要发生的事情。<em class="mh">一图抵千言。</em></p><p id="cdf8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我有一种感觉，2019 年比往年更加激烈。以下是一些让我惊喜交集的进展，但顺序并不特别。</p><blockquote class="ms mt mu"><p id="36d9" class="ku kv mh kw b kx ky ju kz la lb jx lc mv le lf lg mw li lj lk mx lm ln lo lp im bi translated"><em class="it">免责声明 1: </em>我是数据科学的新手。因此，如果我错过了以下主题的一些重要讨论，请随时用参考链接来补充本文。<br/> <em class="it">免责声明 2: </em>这是模型、网络、实现和实验的混合。它们通常是相互关联的。其中一些是另一个的核心。《走向数据科学》的作者已经很好地介绍了其中一些。你在这里看到的是过去 1-2 年里给我留下深刻印象的 DL/ML 故事。<br/> <em class="it">免责声明 3: </em>正如你会注意到的，我列表中的 AI 进步大部分是指视觉媒介(图像生成和修改)。2019 年也是自然语言处理(OpenAI 等的 GPT-2)的重要里程碑。)，但那是我很快会谈到的另一个大话题)。</p></blockquote></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h2 id="365e" class="my mz it bd na nb nc dn nd ne nf dp ng ld nh ni nj lh nk nl nm ll nn no np nq bi translated">1.比根</h2><p id="d22b" class="pw-post-body-paragraph ku kv it kw b kx nr ju kz la ns jx lc ld nt lf lg lh nu lj lk ll nv ln lo lp im bi translated"><strong class="kw iu">这是关于什么的:</strong> <a class="ae mp" href="https://medium.com/merzazine/biggan-as-a-creative-engine-2d18c61e82b8?source=friends_link&amp;sk=498b6f23dfa37347ac952e9d209710c4" rel="noopener">比根</a>扩大<strong class="kw iu">生成对抗网络</strong>——并允许你生成新的视觉效果，在巨大的视觉数据库上接受训练。系统的核心是两个神经网络:<strong class="kw iu">生成器</strong>和<strong class="kw iu">鉴别器</strong>。<strong class="kw iu">生成器</strong>创建新的视觉效果，并试图说服<strong class="kw iu">鉴别器</strong>这是真实的镜头。<strong class="kw iu">鉴别器</strong>将生成的图像与其“经验”对齐，并作为“<em class="mh">未通过</em>”发回给<strong class="kw iu">生成器</strong>。这种反复的相互作用一直持续到某种“共识”。</p><p id="3514" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">尝试一下:</strong>使用这个<a class="ae mp" href="https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/biggan_generation_with_tf_hub.ipynb" rel="noopener ugc nofollow" target="_blank"> BigGAN 笔记本</a>，你可以使用<strong class="kw iu"> <em class="mh">【类别条件采样】</em> </strong>并创建例如<em class="mh">山谷</em>的图像:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/adb87661310902f408facb9178c07b1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ex4Q9uYTyo1EUb-0L1YdtQ.jpeg"/></div></div></figure><p id="5f85" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">结果是惊人的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/fe4dfd1efcb70934c94ed3acc09d6ae6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*odiNmv9uyzcb2nXaf28RXA.png"/></div></div><p class="nx ny gj gh gi nz oa bd b be z dk translated">比根生成的图像</p></figure><p id="c67e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在我这篇文章的标题中，还可以看到 BigGAN 生成的时钟。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a06b7a07e1150dccea0bd60623829092.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VKE8YeK_x3WZIgoppuW6tA.png"/></div></div></figure><p id="ae9a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如你所见，还是<em class="mh">弱 AI </em>。网络不知道<em class="mh">时钟</em>是什么。他们只是知道，这东西怎么可能长得像:“roundish”，“有字有箭”。</p><p id="8469" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我看到<strong class="kw iu">艾</strong>解释世界的尝试和<a class="ae mp" href="https://en.wikipedia.org/wiki/Theory_of_forms" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu">柏拉图<strong class="kw iu"/>的形式/理念</strong> </a>理论之间明显的相似之处:</p><blockquote class="ms mt mu"><p id="c895" class="ku kv mh kw b kx ky ju kz la lb jx lc mv le lf lg mw li lj lk mx lm ln lo lp im bi translated"><em class="it">观念或形式是物质事物的超物质本质。物质的东西不是原创的，只是想法/形式的模仿。</em></p></blockquote><p id="1df1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">我的报道本话题(</strong> <a class="ae mp" href="https://medium.com/merzazine/biggan-as-a-creative-engine-2d18c61e82b8?source=friends_link&amp;sk=498b6f23dfa37347ac952e9d209710c4" rel="noopener"> <strong class="kw iu">【朋友链接】</strong> </a> <strong class="kw iu"> ): </strong></p><div class="ob oc gp gr od oe"><a href="https://medium.com/merzazine/biggan-as-a-creative-engine-2d18c61e82b8" rel="noopener follow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">作为创意引擎的比根</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">的确，2018 年可以被称为人工智能创造真正创造力的开始。</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">medium.com</p></div></div><div class="on l"><div class="oo l op oq or on os ks oe"/></div></div></a></div></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h2 id="94f9" class="my mz it bd na nb nc dn nd ne nf dp ng ld nh ni nj lh nk nl nm ll nn no np nq bi translated">2.和比根一起变形。</h2><p id="c93d" class="pw-post-body-paragraph ku kv it kw b kx nr ju kz la ns jx lc ld nt lf lg lh nu lj lk ll nv ln lo lp im bi translated"><strong class="kw iu">这是怎么回事:</strong>我们可以走得更远，不仅仅是生成带标签的图像。我们可以使用插值函数用 BigGAN 对事物进行<a class="ae mp" href="https://medium.com/merzazine/biggan-and-metamorphosis-of-everything-abc9463125ac?source=friends_link&amp;sk=fde32a2f24a97d0a651c087709fb8a53" rel="noopener">合并和变形。在 BigGAN 的情况下，生成的图像 A 到生成的图像 B 的转换是可能的，无论它们在语义上如何不同。</a></p><p id="f60b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">试试看:</strong>用同一个<a class="ae mp" href="https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/biggan_generation_with_tf_hub.ipynb" rel="noopener ugc nofollow" target="_blank">比根笔记本</a>带<strong class="kw iu">插值</strong>功能。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/322fe1776475929ae1e14acbeadf7c7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rEFq9s3vQRrPm07q084V1w.jpeg"/></div></div><p class="nx ny gj gh gi nz oa bd b be z dk translated">使用这些设置，可以将约克夏梗转化为航天飞机</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/8efde2011b29615216b6a82adb73b2da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cdrv7VhXOFycmoQnJH16KA.png"/></div></div></figure><p id="02d4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这种方法带来了前所未有的可能性，超出了人类的想象。你甚至可以制作更多渐变的画面——并把它们组合成动画片段(更多信息，请查看扎伊德·阿利亚菲的《可乐布笔记本》)</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="56a6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">我对这个话题的报道:</strong></p><div class="ob oc gp gr od oe"><a href="https://medium.com/merzazine/biggan-and-metamorphosis-of-everything-abc9463125ac" rel="noopener follow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">比根和万物的变形</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">数字变形</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">medium.com</p></div></div><div class="on l"><div class="ow l op oq or on os ks oe"/></div></div></a></div></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h2 id="4e57" class="my mz it bd na nb nc dn nd ne nf dp ng ld nh ni nj lh nk nl nm ll nn no np nq bi translated">3.风格转移</h2><p id="6b84" class="pw-post-body-paragraph ku kv it kw b kx nr ju kz la ns jx lc ld nt lf lg lh nu lj lk ll nv ln lo lp im bi translated"><strong class="kw iu">这是怎么回事:</strong> <a class="ae mp" href="https://medium.com/merzazine/ai-creativity-style-transfer-and-you-can-do-it-as-well-970f5b381d96?source=friends_link&amp;sk=258069284f2cca23ff929283c90fba0e" rel="noopener">风格转移</a>是在给定一组风格定义图像后，对输入的基础图像进行变换的神经技术:将图像 A 的一种风格转移到图像 b。</p><p id="b37d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">试试看:</strong> <a class="ae mp" href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/differentiable-parameterizations/style_transfer_2d.ipynb" rel="noopener ugc nofollow" target="_blank"> Colab 笔记本</a>。也有各种免费的和商业的基于数字图书馆的应用程序将你的图像转换成世界艺术大师的作品。</p><p id="f91b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我用各种艺术家的风格转换了我的用户照片，得到了令人信服的结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/d4b730b0baf5c12e6e7fc54b299919e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P-s30lSNfvCtim-iwdgUnw.jpeg"/></div></div><p class="nx ny gj gh gi nz oa bd b be z dk translated">凡·高</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/e19d1514c19549f865af94b06ba8e79e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*54DYa7Y5IrRQ7XZuRoDWhw.jpeg"/></div></div><p class="nx ny gj gh gi nz oa bd b be z dk translated">马格里特</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/6647bb124e6fef37a2319e4191d14946.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f__qfRtF_LvZKyh89yh9sg.jpeg"/></div></div><p class="nx ny gj gh gi nz oa bd b be z dk translated">库尔特·施威特斯</p></figure><p id="3c87" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你可能对风格转移很熟悉，因为<a class="ae mp" href="https://towardsdatascience.com/" rel="noopener" target="_blank">走向数据科学</a>提供了一些关于这个主题的很棒的文章(这里只是其中的一部分，<a class="ae mp" rel="noopener" target="_blank" href="/search?q=Style%20transfer">阅读全部</a>):</p><div class="ob oc gp gr od oe"><a rel="noopener follow" target="_blank" href="/neural-style-transfer-and-visualization-of-convolutional-networks-7362f6cf4b9b"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">卷积网络的神经类型转移和可视化</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">使用迁移学习在 10 分钟内创建专业外观的艺术品。</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">towardsdatascience.com</p></div></div><div class="on l"><div class="pa l op oq or on os ks oe"/></div></div></a></div><div class="ob oc gp gr od oe"><a rel="noopener follow" target="_blank" href="/important-resources-if-you-are-working-with-neural-style-transfer-or-deep-photo-style-transfer-719593b3dbf1"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">重要的资源，如果你正在与神经风格转移或深层照片风格转移</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">神经风格迁移和深度照片风格迁移是深度学习的有趣领域。他们越来越受欢迎…</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">towardsdatascience.com</p></div></div><div class="on l"><div class="pb l op oq or on os ks oe"/></div></div></a></div><div class="ob oc gp gr od oe"><a rel="noopener follow" target="_blank" href="/style-transfer-styling-images-with-convolutional-neural-networks-7d215b58f461"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">用卷积神经网络进行图像风格转换</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">创造美丽的图像效果</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">towardsdatascience.com</p></div></div><div class="on l"><div class="pc l op oq or on os ks oe"/></div></div></a></div><p id="aa32" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">甚至视频风格传输也是可能的:</p><div class="ob oc gp gr od oe"><a rel="noopener follow" target="_blank" href="/real-time-video-neural-style-transfer-9f6f84590832"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">实时视频神经类型转移</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">在受限的移动环境中优化视频的艺术风格化</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">towardsdatascience.com</p></div></div><div class="on l"><div class="pd l op oq or on os ks oe"/></div></div></a></div><p id="786c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">艺术家 Gene Cogan 使用了迪斯尼《爱丽丝梦游仙境》(茶会场景)的风格转换，并将 17 件著名艺术品的风格转换到动画中:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pe mr l"/></div></figure><p id="a979" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我对这个话题的报道(<a class="ae mp" href="https://medium.com/merzazine/ai-creativity-style-transfer-and-you-can-do-it-as-well-970f5b381d96?source=friends_link&amp;sk=258069284f2cca23ff929283c90fba0e" rel="noopener">友链</a>):</p><div class="ob oc gp gr od oe"><a href="https://medium.com/merzazine/ai-creativity-style-transfer-and-you-can-do-it-as-well-970f5b381d96" rel="noopener follow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">人工智能和创造力:风格转换(你也可以做到)</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">人工智能的普及</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">medium.com</p></div></div><div class="on l"><div class="pf l op oq or on os ks oe"/></div></div></a></div></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h2 id="e6a0" class="my mz it bd na nb nc dn nd ne nf dp ng ld nh ni nj lh nk nl nm ll nn no np nq bi translated">4.风格转换的创造性运用:深度的绘画和谐</h2><p id="2c3b" class="pw-post-body-paragraph ku kv it kw b kx nr ju kz la ns jx lc ld nt lf lg lh nu lj lk ll nv ln lo lp im bi translated"><strong class="kw iu">这是关于什么的:</strong>一些艺术家和开发者将风格转移的能力用于<a class="ae mp" href="https://medium.com/merzazine/ai-creativity-alien-elements-with-style-27ee7e45df92?source=friends_link&amp;sk=4f8bf8dd08b1e76b3fcaa88676add697" rel="noopener">创造性的图像处理</a>。这个想法就像天才一样简单:</p><pre class="kj kk kl km gt pg ph pi pj aw pk bi"><span id="0dfa" class="my mz it ph b gy pl pm l pn po">1. take a target image B<br/>2. transfer its style to the element A you want to build into B<br/>3. combine and enjoy</span></pre><p id="b847" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">例如，这种方法允许在数字图像拼贴画中艺术地使用风格转移。</p><p id="8758" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">论文:</strong>作者<a class="ae mp" href="https://arxiv.org/abs/1804.03189" rel="noopener ugc nofollow" target="_blank">付军栾等人</a>。在他们的<a class="ae mp" href="https://github.com/luanfujun/deep-painterly-harmonization" rel="noopener ugc nofollow" target="_blank"> GitHub 资源库</a>中，你可以找到令人惊叹的样本:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pp"><img src="../Images/e152567f81a5f6f83f49ac5691e3fcf3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R-vfBbnne3_Cgszpe-5Nrg.jpeg"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pq"><img src="../Images/2d8070d729ff460993bdafc1ac9d823f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PijnLemHdhHMBZiMnWa62w.jpeg"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pr"><img src="../Images/f21f04d04ec666a6e08832ce76fb19fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IjPw9zIkItOolhHqcTUDqQ.jpeg"/></div></div></figure><p id="0309" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Gene Cogan 以自拍的方式运用风格转移，在世界艺术史上无处不在:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="3fad" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我对这个话题的报道(<a class="ae mp" href="https://medium.com/merzazine/ai-creativity-alien-elements-with-style-27ee7e45df92?source=friends_link&amp;sk=4f8bf8dd08b1e76b3fcaa88676add697" rel="noopener">朋友链接</a>):</p><div class="ob oc gp gr od oe"><a href="https://medium.com/merzazine/ai-creativity-alien-elements-with-style-27ee7e45df92" rel="noopener follow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">人工智能与创造力:风格迥异的元素。</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">AI 用艺术玩变色龙游戏</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">medium.com</p></div></div><div class="on l"><div class="ps l op oq or on os ks oe"/></div></div></a></div></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h2 id="ad85" class="my mz it bd na nb nc dn nd ne nf dp ng ld nh ni nj lh nk nl nm ll nn no np nq bi translated">5.喜剧化—将视频转换回故事板</h2><p id="0221" class="pw-post-body-paragraph ku kv it kw b kx nr ju kz la ns jx lc ld nt lf lg lh nu lj lk ll nv ln lo lp im bi translated"><strong class="kw iu">这是关于什么的:</strong>华沙理工大学的一组研究人员，都对人工智能和漫画艺术着迷，他们将自己的热情结合在一起，实现了一个惊人的项目(<a class="ae mp" href="https://medium.com/merzazine/ai-creativity-transform-a-video-into-a-comic-panel-with-ai-549d1e275a5c?source=friends_link&amp;sk=6c054fc670ca6afb3148540d23c87310" rel="noopener">阅读更多细节</a>):</p><pre class="kj kk kl km gt pg ph pi pj aw pk bi"><span id="19b1" class="my mz it ph b gy pl pm l pn po">1. The model analyzes the video, using intelligent video summarization.<br/>2. The scenes in the video footage are separated by the DL-powered definition of frames with the most aesthetic impact.<br/>3. Style Transfer for the specific stylization of images is applied.<br/>4. Selected frames are put into storyboard / comic layout</span></pre><p id="0340" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">尝试一下</strong> : <a class="ae mp" href="https://comixify.ai/?last=month&amp;sortBy=trend" rel="noopener ugc nofollow" target="_blank">漫画化</a> —选择一个视频并将其传输到漫画中。</p><p id="29d9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我是塔尔科夫斯基电影的超级粉丝，所以我急切地想知道，这部《潜行者》的超级剪辑会发生什么:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pt mr l"/></div></figure><p id="0057" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">结果令人震惊:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pu"><img src="../Images/c82b795e362d541066373c66ffbbcb80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1MufnF0_gtE0FNRz21leSg.png"/></div></div></figure><p id="63be" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">尤其是如果你知道——并且喜欢——这部电影，你会发现画面的选择是多么令人惊讶。其实是在刻画 Stalker 的核心思想(不剧透影片)。</p><p id="ac2d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我用更多的实验报道了这个话题(<a class="ae mp" href="https://medium.com/merzazine/ai-creativity-transform-a-video-into-a-comic-panel-with-ai-549d1e275a5c?source=friends_link&amp;sk=6c054fc670ca6afb3148540d23c87310" rel="noopener"/>):</p><div class="ob oc gp gr od oe"><a href="https://medium.com/merzazine/ai-creativity-transform-a-video-into-a-comic-panel-with-ai-549d1e275a5c" rel="noopener follow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">人工智能与创造力:用人工智能将视频转换成漫画</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">Comixify 允许将视频转换成类似漫画的剧本</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">medium.com</p></div></div><div class="on l"><div class="pv l op oq or on os ks oe"/></div></div></a></div></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h2 id="f8a5" class="my mz it bd na nb nc dn nd ne nf dp ng ld nh ni nj lh nk nl nm ll nn no np nq bi translated">6.CycleGAN —无需输入输出对的图像到图像转换。</h2><p id="d383" class="pw-post-body-paragraph ku kv it kw b kx nr ju kz la ns jx lc ld nt lf lg lh nu lj lk ll nv ln lo lp im bi translated"><strong class="kw iu">这是怎么回事:</strong>BigGAN 在预训练的基础上生成新的图像，<strong class="kw iu"> StyleGAN </strong>在<strong class="kw iu">两幅</strong>图像之间转换样式，<a class="ae mp" href="https://medium.com/merzazine/ai-creativity-visual-anarchist-realism-of-cyclegan-and-how-ai-cheats-on-developers-ab2b3cb9eb8d?source=friends_link&amp;sk=310d2fba831b87177a99d793d94e6caa" rel="noopener"> <strong class="kw iu"> CycleGAN </strong>使用单幅图像将其样式或特征转换成不同的东西</a>。实际上，这是一个<strong class="kw iu">不成对的图像到图像的翻译，使用循环一致的对抗网络</strong>(这正是这篇论文的名字):</p><pre class="kj kk kl km gt pg ph pi pj aw pk bi"><span id="2505" class="my mz it ph b gy pl pm l pn po">1. The image is being analyzed by GAN (including pattern and object detection)<br/>2. Pre-trained feature modification is applied.<br/>3. The same image as in "1." has new visuals achieved by "2."</span></pre><p id="3ed3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">CycleGAN 在不引用其他图像的情况下更改图像的样式和视觉功能。</p><p id="5cc3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">论文:</strong>不成对的图像到图像的翻译使用循环一致的对抗网络<strong class="kw iu"> ( </strong> <a class="ae mp" href="https://junyanz.github.io/CycleGAN/" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu">主页</strong></a><strong class="kw iu">/</strong><a class="ae mp" href="https://arxiv.org/abs/1703.10593" rel="noopener ugc nofollow" target="_blank"><strong class="kw iu">GitHub</strong></a>/<a class="ae mp" href="https://arxiv.org/pdf/1703.10593.pdf" rel="noopener ugc nofollow" target="_blank"><strong class="kw iu">论文</strong> </a> <strong class="kw iu"> ) </strong></p><p id="57fa" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">它不仅可以将艺术家预先训练的风格转移到照片上。它可以使用预先训练好的分割特征知识，将绘画修改为照片般逼真的图像:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pw"><img src="../Images/a53b6c0f9f8855a8567b886a60a21d87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZzYZWPl5upa2R4vgoTet3A.jpeg"/></div></div><p class="nx ny gj gh gi nz oa bd b be z dk translated">来源:论文<a class="ae mp" href="https://arxiv.org/pdf/1703.10593.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="bd px">使用循环一致对抗网络的不成对图像到图像翻译</strong> </a></p></figure><p id="c0e7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你甚至可以循环播放录像。在这种情况下，传输“马= &gt;斑马”被应用于运动图像:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi py"><img src="../Images/73b745f7473d0e641de7507e2fbda1ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/1*Ut2hlFCAJzc2NhHivUGuwA.gif"/></div><p class="nx ny gj gh gi nz oa bd b be z dk translated">(<a class="ae mp" href="https://junyanz.github.io/CycleGAN/" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="63cb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">但并非没有一些系统缺陷…</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pz"><img src="../Images/d912634b9be2de736929cc20f0aaf023.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Psqe_EWCMQKLKCwgZxWWfw.jpeg"/></div></div><p class="nx ny gj gh gi nz oa bd b be z dk translated">普京斑马(<a class="ae mp" href="https://junyanz.github.io/CycleGAN/" rel="noopener ugc nofollow" target="_blank"> Souce </a></p></figure><p id="eb69" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><a class="ae mp" rel="noopener" target="_blank" href="/search?q=CycleGAN">在《走向数据科学</a>上有很多相关的文章，我不会深究技术细节。对我来说最重要的是，有了 DL，图像的可修改性达到了一个新的高度。适合艺术使用。因为严重的错误使用而变得危险。</p><p id="b063" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">我的报道本话题(</strong> <a class="ae mp" href="https://medium.com/merzazine/ai-creativity-visual-anarchist-realism-of-cyclegan-and-how-ai-cheats-on-developers-ab2b3cb9eb8d?source=friends_link&amp;sk=310d2fba831b87177a99d793d94e6caa" rel="noopener"> <strong class="kw iu">【朋友链接】</strong> </a> <strong class="kw iu"> ): </strong></p><div class="ob oc gp gr od oe"><a href="https://medium.com/merzazine/ai-creativity-visual-anarchist-realism-of-cyclegan-and-how-ai-cheats-on-developers-ab2b3cb9eb8d" rel="noopener follow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">人工智能与创造力:CycleGAN 的视觉无政府主义现实主义(以及人工智能如何欺骗开发者)</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">你已经尝试过把照片变成梵高的画了。但是你有没有想过反过来…</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">medium.com</p></div></div><div class="on l"><div class="qa l op oq or on os ks oe"/></div></div></a></div></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h2 id="1663" class="my mz it bd na nb nc dn nd ne nf dp ng ld nh ni nj lh nk nl nm ll nn no np nq bi translated"><strong class="ak"> 7。StyleGAN 接受绘画训练</strong></h2><p id="7de3" class="pw-post-body-paragraph ku kv it kw b kx nr ju kz la ns jx lc ld nt lf lg lh nu lj lk ll nv ln lo lp im bi translated"><strong class="kw iu">这是怎么回事:_C0D32_ </strong>结束于<a class="ae mp" href="https://www.reddit.com/r/MachineLearning/comments/bagnq6/p_stylegan_trained_on_paintings_512x512/" rel="noopener ugc nofollow" target="_blank"><strong class="kw iu">Reddit</strong></a><strong class="kw iu"/>在来自<a class="ae mp" href="https://www.kaggle.com/c/painter-by-numbers/data" rel="noopener ugc nofollow" target="_blank"> kaggle </a>的 24k 艺术作品数据集上训练 StyleGAN。随着他修改代码，各种风格的新艺术品产生了。它是这样工作的:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="qb mr l"/></div></figure><p id="4ba0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">StyleGAN 生成具有预先训练的艺术风格的原创艺术品。</p><p id="f6ef" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">试用一下:</strong> <a class="ae mp" href="https://colab.research.google.com/drive/1cFKK0CBnev2BF8z9BOHxePk7E-f7TtUi" rel="noopener ugc nofollow" target="_blank">谷歌 Colab 笔记本</a>。</p><p id="e133" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有趣的事情:即使你用这个模型得到了无数独特的艺术作品，用一些艺术史的知识你可以假设，哪些风格，艺术运动甚至艺术家正在通过新的图像闪闪发光。</p><div class="kj kk kl km gt ab cb"><figure class="qc kn qd qe qf qg qh paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/b623a68b949f56f627f8f82ef6e4b200.png" data-original-src="https://miro.medium.com/v2/resize:fit:530/format:webp/1*8CuwHFrBqqAiYxiGVzCXbw.png"/></div></figure><figure class="qc kn qd qe qf qg qh paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/7be7d2a1f3229ce9afa74dfb5446d709.png" data-original-src="https://miro.medium.com/v2/resize:fit:530/format:webp/1*7N8i_72W8q085WPkgZ6EGA.png"/></div></figure><figure class="qc kn qi qe qf qg qh paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/ed5b921f5d228fbfe1349eb0cb208a7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*-2SKT_yH5CwjncCQ0OVvEA.jpeg"/></div><p class="nx ny gj gh gi nz oa bd b be z dk qj di qk ql translated"><strong class="bd px">两个生成的图像</strong>对<strong class="bd px">“Las Meninas”，迭戈·委拉斯开兹</strong></p></figure></div><p id="aa00" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">或者是对点彩艺术的模仿。</p><div class="kj kk kl km gt ab cb"><figure class="qc kn qm qe qf qg qh paragraph-image"><img src="../Images/6df66102841422b285e38d5f741ba00c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*5YdtiC_OKHkTcRGsskoQ-g.png"/></figure><figure class="qc kn qn qe qf qg qh paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/3615478c63f8eec02a89de571c689e72.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*4YT7uQv1vz_QKIrX2C-X2w.jpeg"/></div><p class="nx ny gj gh gi nz oa bd b be z dk qo di qp ql translated"><strong class="bd px">生成的图像</strong>对<strong class="bd px">乔治·修拉(右图)</strong></p></figure></div><p id="af9b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">我的报道本话题，</strong>包括<strong class="kw iu"> </strong>更多图片及分析(<a class="ae mp" href="https://medium.com/merzazine/how-to-train-your-artist-cb8f188787b5?source=friends_link&amp;sk=868a3a57d4200faae23c973463645c66" rel="noopener"/>):</p><div class="ob oc gp gr od oe"><a href="https://medium.com/merzazine/how-to-train-your-artist-cb8f188787b5" rel="noopener follow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">如何培养你的艺人？</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">各位，现在是美术测验时间！(奖品包括)</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">medium.com</p></div></div><div class="on l"><div class="qq l op oq or on os ks oe"/></div></div></a></div></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h2 id="b659" class="my mz it bd na nb nc dn nd ne nf dp ng ld nh ni nj lh nk nl nm ll nn no np nq bi translated">8.pix2pix:图像到图像的翻译。</h2><p id="8697" class="pw-post-body-paragraph ku kv it kw b kx nr ju kz la ns jx lc ld nt lf lg lh nu lj lk ll nv ln lo lp im bi translated"><strong class="kw iu">这是怎么回事:</strong> pix2pix 是由 Phillip Isola 等人开发的，最迟在 2017 年开始病毒式传播。由条件敌对网络完成的图像翻译允许将人造涂鸦渲染成照片般逼真的(或以某种方式类似的)图像。请观看 Karoly Zsolnai-Feher 撰写的这篇著名的<strong class="kw iu">两分钟论文</strong>进行总结:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="qr mr l"/></div></figure><p id="c7d2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">论文:</strong>在<a class="ae mp" href="https://phillipi.github.io/pix2pix/" rel="noopener ugc nofollow" target="_blank"> Pix2Pix 网站</a>上你可以找到这个方法的文档、论文、例子和演示(<a class="ae mp" href="https://github.com/phillipi/pix2pix" rel="noopener ugc nofollow" target="_blank"> GitHub </a> / <a class="ae mp" href="https://arxiv.org/abs/1611.07004" rel="noopener ugc nofollow" target="_blank">论文</a>)</p><p id="e19a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">试试看:<a class="ae mp" href="https://github.com/christopherhesse" rel="noopener ugc nofollow" target="_blank"> Christopher Hesse </a>为 pix2pix 提供了<a class="ae mp" href="https://affinelayer.com/pixsrv/" rel="noopener ugc nofollow" target="_blank">现场 TensorFlow 演示。你可以把你的猫、门面和其他东西的涂鸦“翻译”成“照片般逼真”的图像。</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qs"><img src="../Images/cdf45a90f9aad26b19be62be57717e0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pbEAjGm1dDqVjFIDJcR4hQ.jpeg"/></div></div><p class="nx ny gj gh gi nz oa bd b be z dk translated">pix2pix 正尽力从我业余涂鸦的一只猫开始。</p></figure><p id="33ec" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这当然不仅仅是有趣的草图翻译:通过预定义的设置，你可以将航拍照片转换成地图，将白天的照片转换成夜景等等。条件敌对网络检测模式，并将其翻译成所需的主题(你必须定义你的目标图像任务)。在特定的标记图像数据集上训练网络。</p><p id="2d53" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> NVidia </strong>用<strong class="kw iu"> GauGAN </strong>将这种方法带到了另一个层面——他们<a class="ae mp" href="https://www.nvidia.com/en-us/research/ai-playground/" rel="noopener ugc nofollow" target="_blank"> AI 游乐场</a>的实验之一。您可以使用分段来驱动草图:每种颜色都应用于特定的对象或材料。翻译后生成新图像(具有在各种视觉特征之间切换的类似 CycleGAN 的可能性):</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qt"><img src="../Images/b1c399bc08f2706dea23f0d3dbdaec45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ewM5vUh7YZo3aia0mVdN5A.jpeg"/></div></div><p class="nx ny gj gh gi nz oa bd b be z dk translated">图片，是我女儿为我们的人工智能驱动的童话书涂鸦的。</p></figure><p id="c1be" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你可以在这里试试 GauGAN:<a class="ae mp" href="https://nvlabs.github.io/SPADE/demo.html" rel="noopener ugc nofollow" target="_blank">https://nvlabs.github.io/SPADE/demo.html</a><br/>关于 GauGAN 的论文:<a class="ae mp" href="https://arxiv.org/abs/1903.07291" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1903.07291</a></p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h2 id="2530" class="my mz it bd na nb nc dn nd ne nf dp ng ld nh ni nj lh nk nl nm ll nn no np nq bi translated">9.pix2pix，face2face，DeepFake 和 Ctrl+Shift+Face</h2><p id="fd24" class="pw-post-body-paragraph ku kv it kw b kx nr ju kz la ns jx lc ld nt lf lg lh nu lj lk ll nv ln lo lp im bi translated">深度学习世界充满了实验。人们跳出框框思考，这是 DL 特别是 AI 最鼓舞人心的地方。Gene Cogan 用 dynamic pix2pix 进行了实验:在这种情况下，来源不是素描，而是网络摄像头(他的脸)，目标是在特朗普的照片上训练的:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="2380" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这些实验激发了对 face2face 的研究(在本例中:<a class="ou ov ep" href="https://medium.com/u/4ff6d2f67626?source=post_page-----206a5271d98--------------------------------" rel="noopener" target="_blank"> Dat Tran </a>):</p><div class="ob oc gp gr od oe"><a rel="noopener follow" target="_blank" href="/face2face-a-pix2pix-demo-that-mimics-the-facial-expression-of-the-german-chancellor-b6771d65bf66"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">face 2 face——模仿德国总理面部表情的 Pix2Pix 演示</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">受吉恩·科岗研讨会的启发，我创建了自己的 face2face 演示程序，将我的网络摄像头图像转换成…</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">towardsdatascience.com</p></div></div><div class="on l"><div class="qu l op oq or on os ks oe"/></div></div></a></div><p id="fb38" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">原理很聪明:</p><pre class="kj kk kl km gt pg ph pi pj aw pk bi"><span id="ed28" class="my mz it ph b gy pl pm l pn po">1. face2face model learns facial features / landmarks<br/>2. It scans webcam input on facial features<br/>3. It finally translates it into another face</span></pre><p id="a271" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">后真相时代的另一个前沿到达了——现在我们不仅可以修改图像，还可以修改电影。就像流行的消息应用程序上的 AR 应用程序一样，AI 以完美的方式解释视频片段并修改它。</p><p id="f680" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">像<a class="ae mp" href="https://twitter.com/ctrl_shift_face" rel="noopener ugc nofollow" target="_blank"> Ctrl+Shift+Face </a>这样的艺术家将这种方法完善到了令人难以置信的程度:他在 face2face 的帮助下切换了邪教电影中演员俏皮的面孔。比如这里:金凯瑞的《闪灵》。并排比较向你展示了即使是精彩的心理战也能翻译得多好。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="fdec" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这种实现在以下方面具有多种可能性:</p><p id="523d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">电影制作人</strong>可以在试镜前对演员进行实验。他们还可以将电影本地化，以更好地实现不同语言的唇形同步，就像 Synthesia 对大卫·贝克汉姆所做的那样。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="qr mr l"/></div></figure><p id="3695" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在想象一下使用人工智能驱动的语言翻译和语音合成的国际视频会议的可能性。</p><p id="8cb4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">艺术家们可以创作出颠覆性的、超现实的类似“成为约翰·马尔科维奇”的杰作。例如，特朗普、普京等人演唱的这首鼓舞人心、欢快而略带荒诞的《想象》的封面:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="894f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi"><strong class="kw iu">Passed away persons</strong> can be revived. The best example is singer <strong class="kw iu">Hibari Misora</strong>, who preformed new song on annual Japanese New Year TV event <a class="ae mp" href="https://en.wikipedia.org/wiki/70th_NHK_K%C5%8Dhaku_Uta_Gassen" rel="noopener ugc nofollow" target="_blank"><em class="mh">NHK Kōhaku Uta Gassen</em></a> (NHK 紅白歌合戦). She did it this week, <strong class="kw iu">even if she died 30 years ago. </strong>The visuals were reconstructed with the help of AI, the voice was simulated by <a class="ae mp" href="https://en.wikipedia.org/wiki/Vocaloid" rel="noopener ugc nofollow" target="_blank">Vocaloid</a>:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="1462" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">但是 DeepFake 的新方法是开放的。还记得<strong class="kw iu"> ZAO </strong>吗，中国 DeepFake 趣味 app:转移你和名人的脸。现在你是莱昂纳多·迪卡普里奥。将它与在中国推出的生物识别支付结合起来，你就有无限的欺诈可能性:</p><div class="ob oc gp gr od oe"><a href="https://edition.cnn.com/2019/09/03/tech/zao-app-deepfake-scli-intl/index.html" rel="noopener  ugc nofollow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">新的中国“deepfake”人脸应用在隐私反弹后后退</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">在遭到用户强烈反对后，一款允许人们与名人交换面孔的中国新应用程序正在更新其政策…</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">edition.cnn.com</p></div></div><div class="on l"><div class="qv l op oq or on os ks oe"/></div></div></a></div><p id="8f3d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">我的覆盖范围本话题(</strong> <a class="ae mp" href="https://medium.com/merzazine/ai-in-motion-3-ways-to-visit-uncanny-valley-some-thoughts-about-the-truth-in-post-truth-ac0cf717be77?source=friends_link&amp;sk=b1e650f3418375375c00b9af3632a570" rel="noopener"> <strong class="kw iu">友链</strong> </a> <strong class="kw iu"> ): </strong></p><div class="ob oc gp gr od oe"><a href="https://medium.com/merzazine/ai-in-motion-3-ways-to-visit-uncanny-valley-some-thoughts-about-the-truth-in-post-truth-ac0cf717be77" rel="noopener follow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">运动中的人工智能:参观恐怖谷的三种方式(关于后真相中“真相”的一些想法…</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">这是一个显而易见的事实:我们生活在假新闻的时代。不太明显的事实是:我们一直都是这样。刚才我们…</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">medium.com</p></div></div><div class="on l"><div class="qw l op oq or on os ks oe"/></div></div></a></div></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h2 id="1612" class="my mz it bd na nb nc dn nd ne nf dp ng ld nh ni nj lh nk nl nm ll nn no np nq bi translated">10.3D 本·伯恩斯效应。</h2><p id="2ac1" class="pw-post-body-paragraph ku kv it kw b kx nr ju kz la ns jx lc ld nt lf lg lh nu lj lk ll nv ln lo lp im bi translated"><strong class="kw iu">这是关于什么的:</strong>这款机型，由<a class="ae mp" href="http://sniklaus.com/about/welcome" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu">西蒙·尼克劳斯</strong> </a>开发，将单张图像转换成跟踪拍摄。该模型可以识别背景，模拟深度，用内容敏感的修复技术填充缺失的区域，添加新的角度——简而言之:通过一张图像，您可以制作一个空间 3D 视频镜头。在安迪·拜奥的博客中了解更多信息。</p><p id="f4d5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">试试看:</strong> <a class="ae mp" href="https://colab.research.google.com/drive/1hxx4iSuAOyeI2gCL54vQkpEuBVrIv1hY" rel="noopener ugc nofollow" target="_blank"> Colab 笔记本</a>作者<a class="ae mp" href="https://mrm8488.github.io/" rel="noopener ugc nofollow" target="_blank">马努·罗梅罗</a>。</p><p id="31e2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">以下是我的一些实验(在 twitter 帖子中):</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="4d30" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我写过这个话题(<a class="ae mp" rel="noopener" target="_blank" href="/very-spatial-507aa847179d?source=friends_link&amp;sk=dc49882dea2a713647ba0acc4189be95"> Friend-Link </a>):</p><div class="ob oc gp gr od oe"><a rel="noopener follow" target="_blank" href="/very-spatial-507aa847179d"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">很有空间感！</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">在人工智能的帮助下赋予照片新的维度。</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">towardsdatascience.com</p></div></div><div class="on l"><div class="qx l op oq or on os ks oe"/></div></div></a></div></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h2 id="1a9a" class="my mz it bd na nb nc dn nd ne nf dp ng ld nh ni nj lh nk nl nm ll nn no np nq bi translated">11.艺术育种者:无限的艺术作品生成</h2><p id="b561" class="pw-post-body-paragraph ku kv it kw b kx nr ju kz la ns jx lc ld nt lf lg lh nu lj lk ll nv ln lo lp im bi translated"><strong class="kw iu">这是关于什么的:</strong> <a class="ou ov ep" href="https://medium.com/u/be6acff3480f?source=post_page-----206a5271d98--------------------------------" rel="noopener" target="_blank"> Joel Simon </a>将 BigGAN 和其他模型实现到用户友好的 web 应用 ArtBreeder 中。你有许多不同的可能性来创建和修改脸，风景，宇宙图像等。Artbreeder 同时在一个生动的社区中成长和发展，在这个社区中，用户和开发者处于持续的对话中。</p><p id="c6cd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">试出来:</strong>T30】https://artbreeder.com/</p><p id="ce9b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">以下是我用 ArtBreeder 做的一些样本:</p><div class="kj kk kl km gt ab cb"><figure class="qc kn qy qe qf qg qh paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/8f7bb8006ea9368ad85784df59ede21b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*604S_oeTz8hr3Rid0EYysA.jpeg"/></div></figure><figure class="qc kn qy qe qf qg qh paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/4ce3ce77ec49f184e0e21d8fa356d64c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*0xMAQ9713DFrED4mAKFxGQ.jpeg"/></div></figure></div><div class="ab cb"><figure class="qc kn qy qe qf qg qh paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/6c57a3722a0d015c77da87fdf0b9bf87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*uXL9DPIAetT12ihBAyJZ6g.png"/></div></figure><figure class="qc kn qy qe qf qg qh paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/64fbf30aecbb9b279022e586e2c17dcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*xSJ5-DhN1rxZWKNEjs-cxQ.png"/></div></figure></div><p id="f88b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">还可以制作简短的过渡视频:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="601b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">我在这里写了 art breader(</strong><a class="ae mp" rel="noopener" target="_blank" href="/artbreeder-draw-me-an-electric-sheep-841babe80b67?source=friends_link&amp;sk=2fff2b9e102ce632d725e58bfa4c67dd"><strong class="kw iu">Friend-Link</strong></a><strong class="kw iu">):</strong></p><div class="ob oc gp gr od oe"><a rel="noopener follow" target="_blank" href="/artbreeder-draw-me-an-electric-sheep-841babe80b67"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">艺术育种家:给我画一只电动羊</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">如何以用户友好的方式应用生成式对抗网络？</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">towardsdatascience.com</p></div></div><div class="on l"><div class="qz l op oq or on os ks oe"/></div></div></a></div></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h2 id="2f47" class="my mz it bd na nb nc dn nd ne nf dp ng ld nh ni nj lh nk nl nm ll nn no np nq bi translated">12.去彩色化—黑白照片的彩色化</h2><p id="6757" class="pw-post-body-paragraph ku kv it kw b kx nr ju kz la ns jx lc ld nt lf lg lh nu lj lk ll nv ln lo lp im bi translated"><strong class="kw iu">这是怎么回事:</strong> DeOldify 由<a class="ae mp" href="https://twitter.com/citnaj" rel="noopener ugc nofollow" target="_blank"> Jason Antic </a>创作并发布。<em class="mh">这个项目的任务是对旧图像和电影胶片进行着色和恢复。(</em> <a class="ae mp" href="https://github.com/jantic/DeOldify" rel="noopener ugc nofollow" target="_blank"> <em class="mh">来源</em> </a> <em class="mh">)。</em> DeOldify 正在使用<strong class="kw iu">生成对抗网络</strong>，在两个神经网络<strong class="kw iu">生成器</strong>和<strong class="kw iu">鉴别器</strong>之间进行迭代交互(类似于<a class="ae mp" rel="noopener" target="_blank" href="/artbreeder-draw-me-an-electric-sheep-841babe80b67?source=friends_link&amp;sk=2fff2b9e102ce632d725e58bfa4c67dd">art breader</a>)。但与上一个模型不同的是，DeOldify 中的图像不会以它们的形式被修改或生成。甘的力量带来色彩——<strong class="kw iu">发生器</strong>将颜料涂在他训练过的已识别物体上，<strong class="kw iu">鉴别器</strong>尝试批评颜色选择。</p><p id="0900" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">试试看:</strong>你可以在<a class="ae mp" href="https://github.com/jantic/DeOldify" rel="noopener ugc nofollow" target="_blank"> GitHub </a>中找到这个型号，也可以在两个笔记本中找到——图片(<a class="ae mp" href="https://colab.research.google.com/github/jantic/DeOldify/blob/master/ImageColorizerColab.ipynb" rel="noopener ugc nofollow" target="_blank"> Colab 笔记本</a>)和视频(<a class="ae mp" href="https://colab.research.google.com/github/jantic/DeOldify/blob/master/VideoColorizerColab.ipynb" rel="noopener ugc nofollow" target="_blank"> Colab 笔记本</a>)！</p><p id="4660" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是我的照片:一张我父亲在 1960 年拍摄的黑白照片。看花的颜色检测的多细致。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="9c47" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">当然，颜色不会重复原来的调色板。但它让历史照片充满活力，让它们更贴近我们的时代。</p><p id="d225" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我在这里写了这个话题(<a class="ae mp" rel="noopener" target="_blank" href="/deoldify-gan-based-image-colorization-d9592704a57d?source=friends_link&amp;sk=925195b692f4922b90814ff8cc537e1b"> Friend-Link </a>):</p><div class="ob oc gp gr od oe"><a rel="noopener follow" target="_blank" href="/deoldify-gan-based-image-colorization-d9592704a57d"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">基于 GAN 的图像彩色化</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">找回丢失的颜色…</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">towardsdatascience.com</p></div></div><div class="on l"><div class="ra l op oq or on os ks oe"/></div></div></a></div></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h2 id="8533" class="my mz it bd na nb nc dn nd ne nf dp ng ld nh ni nj lh nk nl nm ll nn no np nq bi translated">13.人工智能驱动的虚拟现实</h2><p id="e02f" class="pw-post-body-paragraph ku kv it kw b kx nr ju kz la ns jx lc ld nt lf lg lh nu lj lk ll nv ln lo lp im bi translated"><strong class="kw iu">这是关于什么的:</strong> AI 驱动的虚拟现实是可能的。实际上，这是 NVidia 一年前发布的<a class="ae mp" href="https://news.developer.nvidia.com/nvidia-invents-ai-interactive-graphics/" rel="noopener ugc nofollow" target="_blank">新闻——而且非常有希望:</a></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="qr mr l"/></div></figure><p id="ba3a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这里，城市和视觉效果是在谷歌街景上训练的，所以 VR 城市体验是通过深度学习模型重建的:</p><blockquote class="ms mt mu"><p id="c525" class="ku kv mh kw b kx ky ju kz la lb jx lc mv le lf lg mw li lj lk mx lm ln lo lp im bi translated">为了进行训练，该团队在 DGX-1 上使用了<a class="ae mp" href="https://www.nvidia.com/en-us/data-center/tesla-v100/" rel="noopener ugc nofollow" target="_blank">NVIDIA Tesla V100 GPU</a>和<a class="ae mp" href="https://developer.nvidia.com/cudnn" rel="noopener ugc nofollow" target="_blank">cud nn</a>-加速 PyTorch 深度学习框架，以及来自城市景观和 Apolloscapes 数据集的数千个视频(<a class="ae mp" href="https://news.developer.nvidia.com/nvidia-invents-ai-interactive-graphics/" rel="noopener ugc nofollow" target="_blank">来源</a>)。</p></blockquote><p id="5ae8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你可以想象这种方法的所有潜力:“从零开始”的现实城市模拟，对城市发展、交通管理和物流的帮助，重塑视频游戏景观。</p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h2 id="f24e" class="my mz it bd na nb nc dn nd ne nf dp ng ld nh ni nj lh nk nl nm ll nn no np nq bi translated">14.跑道 ML</h2><p id="f27b" class="pw-post-body-paragraph ku kv it kw b kx nr ju kz la ns jx lc ld nt lf lg lh nu lj lk ll nv ln lo lp im bi translated"><strong class="kw iu">这是关于什么的:</strong> Runway 是一个终极应用，使用各种 ML/DL 模型来满足不同的需求。它可以翻译图像 2 文本，在图像后生成文本(使用 GPT-2)，检测照片和视频镜头中的对象。你也可以将不同的模型结合成连锁反应。而且是免费的。</p><p id="c9a0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">试试看:<a class="ae mp" href="https://runwayml.com/" rel="noopener ugc nofollow" target="_blank">https://runwayml.com/</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi rb"><img src="../Images/8db25a75f9a80460aa5f6f3fa1beea9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UgdYguH4oswa1oQxmRssdw.jpeg"/></div></div></figure><p id="95c5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我很快会写关于 RunwayML 的文章。</p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h2 id="3abb" class="my mz it bd na nb nc dn nd ne nf dp ng ld nh ni nj lh nk nl nm ll nn no np nq bi translated"><strong class="ak">即将发布:StyleGAN2 </strong></h2><p id="66ac" class="pw-post-body-paragraph ku kv it kw b kx nr ju kz la ns jx lc ld nt lf lg lh nu lj lk ll nv ln lo lp im bi translated">最近，NVidia 发布了 style gan 2——图像质量有所提高(<a class="ae mp" href="https://github.com/NVlabs/stylegan2" rel="noopener ugc nofollow" target="_blank"> GitHub </a> / <a class="ae mp" href="http://arxiv.org/abs/1912.04958" rel="noopener ugc nofollow" target="_blank">论文</a> / <a class="ae mp" href="https://youtu.be/c-NJtV9Jvp0" rel="noopener ugc nofollow" target="_blank">视频</a>)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi rc"><img src="../Images/9e27a063ac76a133aff936fb0218a0cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*URPpra9C1BHGeNvODVdkQQ.png"/></div></div><p class="nx ny gj gh gi nz oa bd b be z dk translated">StyleGAN 2 预告(<a class="ae mp" href="https://github.com/NVlabs/stylegan2" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="ffbc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">此外，使用图像的新方法也是可能的。例如，StyleGAN 投影:与来自任何可能图像的目标图像对齐。我强烈建议跟随 Jonathan Fly 对每个最新的 DL/ML 开发进行全面的实验:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="56c9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">《road runner 01》也非常有趣:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="1a38" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">(人工智能先驱、艺术家和实验者是我将在 2020 年讨论的另一个话题)</p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h2 id="9e64" class="my mz it bd na nb nc dn nd ne nf dp ng ld nh ni nj lh nk nl nm ll nn no np nq bi translated">奖励:尝试它的资源</h2><p id="90de" class="pw-post-body-paragraph ku kv it kw b kx nr ju kz la ns jx lc ld nt lf lg lh nu lj lk ll nv ln lo lp im bi translated">冬天(希望)终于过去了。技术就在眼前，我们彼此相连，思想交流前所未有地活跃。而 AI 复兴最好的一点就是:DL/ML 的大众化和民主化。如今，不仅 Python 演讲者和 NVidia GPU 所有者可以享受无限的可能性:每个人都可以做到这一点。作家，艺术家，其他非技术领域的人可以使用 Colab/Jupyter 笔记本，用户友好的应用程序，如 Artbreeder 和 RunwayML 等。</p><p id="4d34" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这里有一个小列表供你收藏:基于跨平台网络的人工智能实验。现在没有借口声称人工智能将是一门火箭科学(它仍然存在于各种高科技领域，但不是普遍的)。该列表将被更新。</p><div class="ob oc gp gr od oe"><a href="https://experiments.withgoogle.com/collection/ai" rel="noopener  ugc nofollow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">人工智能实验|谷歌的实验</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">在过去的 6 个月里，谷歌在悉尼的创意实验室与数字作家节团队合作，并且…</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">experiments.withgoogle.com</p></div></div><div class="on l"><div class="rd l op oq or on os ks oe"/></div></div></a></div><div class="ob oc gp gr od oe"><a href="https://www.nvidia.com/en-us/research/ai-playground/" rel="noopener  ugc nofollow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">来自 NVIDIA Research 的交互式演示</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">与基于 NVIDIA 研究的现场演示互动，链接到白皮书和 GitHub 源代码</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">www.nvidia.com</p></div></div><div class="on l"><div class="re l op oq or on os ks oe"/></div></div></a></div><div class="ob oc gp gr od oe"><a href="https://colab.research.google.com/" rel="noopener  ugc nofollow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">谷歌联合实验室</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">编辑描述</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">colab.research.google.com</p></div></div><div class="on l"><div class="rf l op oq or on os ks oe"/></div></div></a></div><div class="ob oc gp gr od oe"><a href="https://runwayml.com/madewith" rel="noopener  ugc nofollow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">面向创作者的机器学习。</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">机器学习的瑞士军刀</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">runwayml.com</p></div></div><div class="on l"><div class="rg l op oq or on os ks oe"/></div></div></a></div><p id="5a01" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你也可以关注我的人工智能相关关键人物的 Twitter 列表。这个列表还在增长，这是一件好事！</p><div class="ob oc gp gr od oe"><a href="https://twitter.com/Merzmensch/lists/ai" rel="noopener  ugc nofollow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">推特上的@Merzmensch/AI</h2><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">twitter.com</p></div></div><div class="on l"><div class="rh l op oq or on os ks oe"/></div></div></a></div></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><p id="d803" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><em class="mh">这些只是 2019 年令人惊叹的人工智能发展的一部分。你还有 AI 驱动的 WOWs 吗？请随意将它们写在评论中！</em></p></div></div>    
</body>
</html>