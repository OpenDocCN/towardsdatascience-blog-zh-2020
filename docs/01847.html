<html>
<head>
<title>Bootstrapping cutting-edge NLP models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">引导前沿的自然语言处理模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/bootstrapping-cutting-edge-nlp-models-baf62405a2b5?source=collection_archive---------24-----------------------#2020-02-20">https://towardsdatascience.com/bootstrapping-cutting-edge-nlp-models-baf62405a2b5?source=collection_archive---------24-----------------------#2020-02-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2aa9" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何在 5 分钟内启动并运行 XLNet 和 Pytorch</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/cf594bfcf81f22c4ae57e47d9a932414.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qnA-AMOh_eVxrpnD"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae ky" href="https://unsplash.com/@pietrozj?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Pietro Jeng </a>拍摄</p></figure><h1 id="5203" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">什么是 XLNet</h1><p id="430f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">XLNet 是基于 Transformers (BERT、RoBERTa、TinyBERT 等)的现代 NLP 语言模型。)XLNet 在各种自然语言理解任务上的结果接近人类的表现。XLNet 可以生成高中生级别的文本，它可以回答简单的问题。它可以理解狗和猫不一样，但它们都是人类的宠物。<br/>总的来说，XLNet 是一个建立在 BERT 进步基础上的模型。</p><p id="bc18" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">XLNet 解决了 3 大类 NLP 问题:分类、序列标记和文本生成</p><h2 id="5305" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">分类:</h2><p id="4a27" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">分类任务是自然语言处理中最常见的任务类型。分类任务给一段文本分配一个类别。更广泛地说，他们回答一个问题<em class="ne">给定一段文本，告诉我该文本属于哪个类别</em>。<br/>分类领域中的任务通常会回答如下问题:</p><blockquote class="nf ng nh"><p id="481f" class="lr ls ne lt b lu mn ju lw lx mo jx lz ni mp mc md nj mq mg mh nk mr mk ml mm im bi translated">这次就诊我们应该使用什么医疗账单代码？(提供访问描述)<br/>这条短信是垃圾短信吗？(文字已提供)<br/>这个用户感兴趣吗？(提供内容和用户简介)</p></blockquote><h2 id="ca14" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">序列标签:</h2><p id="16df" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">NLP 中的另一类问题是序列标记。在序列标记中，我们试图在提供的文本中找到一些东西。通常，这种类型的任务将包括在所提供的文本中查找人(NER)或查找一个实体的所有共同引用，即，如果在句子<em class="ne">“玛丽跳过一只蟾蜍。</em> <strong class="lt iu"> <em class="ne">它</em> </strong> <em class="ne">没动</em>算法会找出<strong class="lt iu"><em class="ne"/></strong>的‘它’指的是玛丽，不是蛤蟆。序列标记的另一个例子是检测哪个股票行情自动收录器与一个公司的每次提及相关联—</p><blockquote class="nf ng nh"><p id="1eb4" class="lr ls ne lt b lu mn ju lw lx mo jx lz ni mp mc md nj mq mg mh nk mr mk ml mm im bi translated">NVDA 定于 8 月 15 日报告 2020 财年第二季度业绩。</p><p id="63f0" class="lr ls ne lt b lu mn ju lw lx mo jx lz ni mp mc md nj mq mg mh nk mr mk ml mm im bi translated">在随后的四个季度中，该公司的<strong class="lt iu"> (NVDA) </strong>收益三次超过咤克斯共识预测，一次错过同样的<strong class="lt iu">(咤克斯)</strong>，平均正惊喜为 3.94%。</p></blockquote><h2 id="2ec7" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">文本生成:</h2><p id="eee2" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">XLNet 的第三种也是最后一种用途是文本生成。这里，给定一小段上下文，XLNet 将预测下一个单词。并且它将继续预测下一个单词，直到被指示停止。在下面的例子中，给定<em class="ne">的输入，快速棕色</em> XLNet 将首先预测<em class="ne">狐狸</em>，然后整体查看上下文并预测下一个单词<em class="ne">跳过</em>等等。</p><blockquote class="nf ng nh"><p id="e7c9" class="lr ls ne lt b lu mn ju lw lx mo jx lz ni mp mc md nj mq mg mh nk mr mk ml mm im bi translated">快速棕色<fox> <jumped> <over> …</over></jumped></fox></p></blockquote></div><div class="ab cl nl nm hx nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="im in io ip iq"><h1 id="8827" class="kz la it bd lb lc ns le lf lg nt li lj jz nu ka ll kc nv kd ln kf nw kg lp lq bi translated">运行 XLNet</h1><p id="26c4" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">现在，让我们来看看如何设置和运行 XLNet。基于 XLNet 操作的 3 种模式—</p><h2 id="ee8e" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated"><code class="fe nx ny nz oa b">XLNetLMHeadModel</code></h2><p id="96b4" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">XLNet 模型，顶部有一个语言建模头(线性层，权重与输入嵌入绑定)——<code class="fe nx ny nz oa b">XLNetLMHeadModel</code>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Daulet Nurmanbetov 提供的示例代码</p></figure><p id="e36b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在这个例子中，你可以看到给定一个序列<em class="ne">“快速的棕色狐狸跳过了懒惰的</em> <strong class="lt iu"> <em class="ne"> &lt;面具&gt;</em></strong><em class="ne"/><strong class="lt iu"><em class="ne">&lt;面具&gt;</em></strong><em class="ne"/><strong class="lt iu"/>成为一个<strong class="lt iu"><em class="ne"/></strong><em class="ne"/><strong class="lt iu"><em class="ne"/></strong></p><p id="2218" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这种类型的 XLNet Head 通常用于 AI 完成人类句子或根据简短问题打出句子的演示。</p><h2 id="2510" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated"><code class="fe nx ny nz oa b">XLNetForSequenceClassification</code></h2><p id="91c7" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">顶部带有序列分类/回归头的 XLNet 模型(汇集输出顶部的线性层)，例如用于胶合任务— <code class="fe nx ny nz oa b">XLNetForSequenceClassification</code>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Daulet Nurmanbetov 提供的示例代码由 Hugginface 的<a class="ae ky" href="https://github.com/huggingface/transformers" rel="noopener ugc nofollow" target="_blank"> Transformers 提供</a></p></figure><p id="f125" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如上所述，使用 XLNet 开箱即用而不先进行微调会给我们带来相当大的损失值<strong class="lt iu"> <em class="ne"> 1.19 </em> </strong></p><p id="7791" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这种类型的 XLNet 头用于微调一个模型来为我们分类 NLP 任务。即。，我们可以使用上面的代码对文本或段落进行分类。为了做好分类工作，我们将需要标记的数据进行微调，并获得接近<strong class="lt iu"> 0 </strong>的损失值。通常，根据我的经验，只需要 2k–5k 标记的样本就可以得到一个像样的模型。</p><h2 id="4464" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated"><code class="fe nx ny nz oa b">XLNetForQuestionAnswering</code></h2><p id="e268" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">XLNet 模型，顶部有一个 span 分类头，用于提取问题回答任务，如 SQuAD(隐藏状态输出顶部的线性层，用于计算“span 开始逻辑”和“span 结束逻辑”)。<br/>T5】</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Daulet Nurmanbetov 提供的示例代码由 Hugginface 的<a class="ae ky" href="https://github.com/huggingface/transformers" rel="noopener ugc nofollow" target="_blank"> Transformers 提供</a></p></figure><p id="7c44" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这种类型的 XLNet Head 用于回答问题或从文本中提取一条信息。同样，与上一个 XLNet 方法一样，我们需要为我们的特定任务提供训练数据，这样才能很好地工作。</p><h1 id="f5ba" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">我们可以用这些模式做什么？</h1><p id="58d0" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">有了上面提供的 3 种 XLNet 模式，我们几乎可以解决任何类型的 NLP 问题。以下是我使用 XLNet 和其他 Transformer 模型解决的一些问题—<br/><em class="ne">—相关性检测<br/>—共指消解</em><br/><em class="ne">—NER</em><br/><em class="ne">—序列分类</em><br/><em class="ne">—文本生成</em><br/><em class="ne">—下一个单词预测</em><br/><em class="ne">—问题回答</em><br/><em class="ne">—释义检测</em><br/><em class="ne">—文本分类</em></p><p id="5578" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我还见过 XLNet 被用来执行图形数据库的<a class="ae ky" href="https://openreview.net/forum?id=rkgqm0VKwB" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">关系提取</strong> </a>和<a class="ae ky" href="https://github.com/santhoshkolloju/Abstractive-Summarization-With-Transfer-Learning" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">汇总</strong> </a> <strong class="lt iu"> </strong>任务。</p><h1 id="046e" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">结论</h1><p id="23ff" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在当今时代，任何人都可以在几个小时内开始使用前沿模型。这是激动人心的时刻，因为其中一些模型<strong class="lt iu">在一些特定的任务中与人类能力</strong>相匹敌。</p><p id="c271" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">重要的是，任何开发人员或喜欢代码的个人都可以使用这些模型，比如 XLNet 模型。</p><p id="a997" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这都要归功于持续的努力，让人工智能对每个人都是免费和可访问的<strong class="lt iu">。这些模型的纯 GPU 培训成本有时高达 50 万美元。使用运行在 Kubernetes-like 上的分布式计算和 GPU 集群来生产模型训练，需要花费更多的工程和研究时间。</strong></p><p id="cdb2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">公开共享模型权重以促进行业研究和应用的趋势确实令人惊讶。</p></div></div>    
</body>
</html>