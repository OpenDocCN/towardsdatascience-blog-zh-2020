# 数据科学项目中的函数式编程

> 原文：<https://towardsdatascience.com/functional-programing-in-data-science-projects-c909c11138bb?source=collection_archive---------16----------------------->

## 至少是一个我如何使用它和我学到了什么的小故事

![](img/db36c0d38d763b6b227acb7785492dbb.png)

由[泰勒·拉斯托维奇](https://unsplash.com/@lastly?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄

我想分享一下我日常使用函数式编程(FP)的经验。我在这里的主要目的是挑战这种方法，并从数据科学界获得反馈。作为一名数据科学家，我大部分时间都花在 POCs(概念验证)和代码产品化之间。这种反复会带来很多麻烦，尤其是在 POC 阶段没有满足生产代码的约束时。当然，我的大部分代码并没有在生产中结束。如果我必须在调查期间编写一个生产就绪的代码，这将是一个巨大的开销。对我来说，有三种方法:

1.  编写大块的代码。这很酷，因为你可以很容易地测试一个假设。我通常用这种方法来测试一个想法，我希望最多在一两天内得到答案。大多数时候，当我得到答案时，我会扔掉(99%)这段代码。如果我不得不在这段代码上工作更长的时间，复杂性将会每天增加，并且这段代码在进入生产阶段时会变成一场噩梦。我也称之为“笔记本方法”。
2.  **编写** [**OOP**](https://en.wikipedia.org/wiki/Object-oriented_programming) **代码**。我喜欢 OOP 代码有很多原因。首先，当设计简单明了时，它易于使用。一个很好的例子是 [Scikit-Learn](https://scikit-learn.org/stable) 库。如果你理解了`fit` — `predict`的概念，你基本上就理解了这个库的 90%。还有许多其他的库，其中的基本概念简单而有效。然而，当我开始一个新项目时，我不知道包装我的代码的最佳“概念”是什么。从一个概念开始，并在测试假设的同时维护它，这可能是对时间的极大浪费。
3.  **写入 FP 代码**。我不是 FP 大师，我每天都在学习更多的东西。对我来说，FP 的主要优势是代码组织和可维护性。此外，当您需要加速代码时，并行化几乎是免费的。FP 在开始的时候可能有点难学，但是我认为这是更糟糕的投资。

无论如何，这三种方法各有利弊，根据你所从事的团队/项目的类型，任何一种都可能更适合你。我选择用第三种方法开始大部分时间，主要是因为开销非常低，并且回报是为项目的未来阶段赢得惊人的时间。正如我所说的，我不是一个 FP 大师，如果你认为我错了或者你觉得你可以用更好的方式来做，请添加评论和反馈。

数据科学家(至少我)花了很多时间来创建管道。换句话说，我们创建代码从数据到预测。管道中的步骤顺序可以在项目之间改变，但我或多或少总是做解析、清理、格式化、特征工程、培训等工作。在 POC 阶段，这些步骤中的每一步都可以分解为更小的步骤(格式化一些列、填充缺失值等)，我们还希望有一个适当的测试步骤来评估管道。POC 的目标基本上是找到管道中最合适的步骤。在将 FP 用于我的研究并将代码转移到产品中之后，我学到了几个关键点，使得这个过渡更加平稳。

# 定义:什么是 FP？

函数式编程最简单的例子就是使用一个标准函数。

第 8 行，我使用函数`map`将函数`add_2`应用于列表中的所有值。这里没有什么新的东西，我们可以很容易地用 lambda 函数替换`add_2`函数:`lambda x: x+2`。

在这个例子中，有一个硬编码的值`+2`要添加。那么，如果我想做同样的操作，但是要添加不同的值，会怎么样呢？然后，理论上，我需要创建一个不同的函数，比如说`add_3()`。或者使用 lambda 风格:`lambda x: x+3`。您还可以创建一个函数，该函数通过适当的操作返回一个函数:

在本例中，函数`add(to_add)`返回一个函数，该函数可以使用`map`以与上例相同的方式应用于列表。主要区别是值`to_add`神奇地保存在创建的函数`my_custom_add_function`中。这个概念对于分离参数和数据非常有用。在这个例子中，函数的参数是`3`，数据对应于列表的值。

# 好的，但是 FP 和管道之间有什么联系呢？

让我们回到数据科学。在下面的例子中，我有一个数据集，我想在其中应用一些修改。

1.  删除缺少太多值的列。
2.  从 1 小时间隔到两个 2 小时间隔对数据进行重采样。
3.  填充缺失值。

没有什么疯狂的复杂，只是时间序列的标准预处理步骤。您可以简单地编写如下代码:

如果你看一下`preprocess`函数，你会发现我提到的 3 个步骤。这太棒了！您可以继续扩展`preprocess`功能或使用您的特征工程添加新功能等

现在，让我们考虑使用函数式编程风格编写的相同代码:

没什么区别，对吧？只是多了几行代码…但是，您可以注意到，直到第 34 行才开始计算。还有一点，在这段代码中，你可以清楚地看到参数和数据的区别。参数被提供给`create_...`函数，而数据稍后提供。第一个例子叫做命令式，第二个例子叫做声明式(以防万一你想谷歌一下)。

因此，现在考虑您想要更新您的代码，因为您发现 2 小时重采样不合适，并且您想要保留原始采样。轻松点。在命令式代码(example_pandas.py)中，您只需删除第 22 行并更改`preprocess`签名。嗯，这可能是一件痛苦的事…尤其是如果`preprocess`函数被许多其他代码共享的话。在声明性代码(example_pandas_FP.py)中，您可以删除第 32 行，将第 34 行改为`fill_na(remover(random_df))`，这只会影响这段代码。直到这里，没有太多的差异。

现在，考虑这个函数`create_pipeline`:

这个函数以一个函数列表作为参数，并返回一个函数，这个函数逐个调用每个函数。

现在，example_pandas_FP.py 变成了:

更干净的代码不是吗？步骤和参数被清楚地突出显示。您可以通过修改传递给`create_pipeline`的函数列表来简单地添加或删除步骤。

当您要为每个单独的功能创建单元测试时，这种范例也会有所帮助。额外收获:如果你习惯了 FP 风格，你将会有一个清晰的模块化，可以跨项目重用。

Scikit-learn 还提供了一个[管道](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)对象。我经常使用它，我发现它很棒。我不再使用它的主要原因是它与`fit` - `transform`范式联系太紧密了。很多时候，我最终只是在`fit`函数中传递数据，我发现这既没用又不方便。我发现我的实现更加灵活，但是，您仍然可以将这两种方法结合起来。

# 序列化

一般来说，管道和 FP 的一个很酷的技巧是序列化函数的能力。这是缓存中间计算的好方法，也是在生产中重用代码的简单方法。总的来说，我更喜欢用`dill`而不是`pickle`，因为它消除了很多麻烦，而且几乎总是对我有效。例如:

# Spark 的(几乎)自由并行化

现在，如果我想将相同的管道应用于 1000 个数据集呢？一个快速的解决方案是并行执行。因为管线的参数化在创建管线时一次性完成，所以不需要传递参数。你只需要传递数据。如果不是 Spark 专家，您可以简单地使用 RDD 的`map` — `collect`功能。想法是使用 RDD 并行化我们的 1000 个数据集，并使用这些函数来获得结果。

这并不难:d .这对你来说非常有效。然而，在内存中加载 1000 个数据集可能不是一个好主意。为了避免这种情况，我在管道中加载数据集。所以`sc.parallelize`不是用在数据集列表上，而是用在获取数据的键列表上。例如，CSV 文件名列表。然后，管道的第一个函数可以解释这些文件名，并在需要时加载数据。在这个例子中，为了简单起见，我展示了数据集的并行化，但是同样的概念也可以用于按列或按行并行化数据集。

# 函数估计量

你们中的一些人可能会想，“这里有一个明显的限制！如果管道不是线性的呢？”换句话说，如果您需要从一个数据集推断出一些结果，并将其应用到另一个数据集，该怎么办？例如，标准化或训练模型。我刚刚描述的范式打破了…事实上，并不完全是。这就是你想要使用函数估值器的地方。这是我从我在威盛科技的前任主管杰里米·泰勒那里学到的。这个想法是链函数创建。 *F(参数)——>G(训练 _ 集)——>H(预测)。*在 python 中:

现在，我们有 3 条管道可以协同工作。`pipeline_preprocessor`是预处理数据的函数，`pipeline_rf_creator`是创建随机森林预测器的管道，`pipeline_create_prediction`是推断外部数据集预测的管道。最后一个管道可以序列化，并在以后用于推理。

# 业务逻辑= >组合

总的来说，一件棘手的事情是理清业务逻辑和计算。经验法则是避免在封装函数中使用`if parameter == something`。需要的地方还是可以有`if data == something`的。为了处理业务逻辑，您可以利用组合。当你使用`create_pipeline`功能时就变得简单了。例如:

在本例中，管道的组成取决于`use_sampling`参数。你可以想象各种各样的检查来定义管道。然而，从测试的角度来看，这个函数是最难测试的，因为您需要尝试所有的参数组合，以确保它不会在特定的用例中出错。这就是为什么我尽量保持简单的原因。

# 产品化

当我对我的调查感到满意时，我可以将我的代码转移到生产中。为此，我简单地删除了我创建的所有未使用的函数，并保留了相关的测试。过去，这一阶段需要我花费数周的时间，而现在，我可以在一两天内完成。没有债务要付，我的代码已经组织得很清楚了。事实上，我将代码集中于产生预期的结果，并且通过避免复杂的设计节省了大量时间。这种 FP 范式在我所有的代码中都是一样的，我的同事可以很容易地理解它并修改它。

## 无国籍的

转移到生产时，重要的一点是尽可能无状态。这确保了[幂等性](https://en.wikipedia.org/wiki/Idempotence)，这在云上部署时非常重要。我发现 FP 范型非常适合创建无状态代码，而且过了一段时间后，维护和调试变得容易多了。

我希望你喜欢阅读这篇文章。如果您有任何反馈或意见，请随时联系我或对本文发表评论。

我的 LinkedIn: [这里](https://www.linkedin.com/in/nathanaelweill)