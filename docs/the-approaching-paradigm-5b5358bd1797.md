# 逼近的范式

> 原文：<https://towardsdatascience.com/the-approaching-paradigm-5b5358bd1797?source=collection_archive---------56----------------------->

## ~ *神经网络如何将软件速度提高几个数量级* ~

![](img/6e5e344e7cc2dfbe51d3f25aacdec6d8.png)

由[尼科莱特·米德](https://unsplash.com/@nmeade?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)在 [Unsplash](https://unsplash.com/s/photos/quilt?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上拍摄的照片

**【TL；DR** —神经网络将一个程序的*整个输入→输出*转化为一个**压缩图像文件**，该压缩图像文件“逐像素”重新生成，以*模拟*程序，从而实现多方面的加速。切勿*解包*整个图像；切勿再次运行*实际*软件。]

每一个软件都可以被重新想象成一个单一的、巨大的 ***镜像文件*** 。怎么会？每个 ***输入到你软件的*** 都是一个特定的‘像素坐标’(这个图像存在于一个多维空间，等于输入和程序状态可用的不同比特数；尽管如此，它仍然是一个将输入坐标映射到输出值的静态表示，从这里开始就是一个“图像”)。同时，该特定位置的“颜色”就是软件的 ***输出位*** 。让我们看一个例子:

2/5/9

0/3/5

7/2/4

我们有一个 3×3 的“像素”阵列，每个像素存储一个位串“值”。如果这个数组代表你的软件，那么对(2，3)的软件的一个 ***输入串*** 将选择第二列第三行的‘像素’:那里的值是‘2 ’,这将是你的 ***输出*** 的位串。类似地，将(1，3)输入到您的软件中会得到“7”的输出。不需要*实际计算*你程序的细节，你可以使用这个‘输入→输出图像’来**模拟**你的代码！然而，大多数现实世界的程序对此来说太复杂了。你永远不可能*存储*可能的输入和输出的整个地图。

直到一个鬼祟的把戏使用我们的新算法——君主:神经网络！进入细节…你拥有的庞大软件可以被分解成几个“种类”的操作:

1.  **算术&布尔**——这些是传统计算机擅长的愚蠢、快速、机器代码类型的运算。让他们继续做下去。还有！这些往往是测试“阈值”所需的各种操作，阈值决定了软件如何对输入进行解析。布尔弦和波纹加法器将大块的工作送到正确的地方。
2.  静态协议，通用操作，这些是全世界每个人都在他们的软件中做的事情。日期和时间、帐户和日志、调试等。它们有一个已知的、适当的功能，然而它们是以成千上万种独特的易受攻击或功能失调的方式实现的。
3.  **混乱、微妙、复杂、集成**——这些大块的软件做出了特殊的酱料。在这里，复杂的程序展开，以实现竞争对手努力模仿。然而，这也是很多代码出错的地方。实现细节带来了多方面的改进，单一的错误会让后门微开。*这些*是**神经网络**可以搅动它们的连接体锅*将我们的整个软件输入→输出流*压缩成**微小的**、**折叠的**、**隐藏的图像**的区域。

因此，对于已经被解析为“混乱”的软件的*部分*，计划是形成该段程序操作的“镜像文件”。每个像素的“坐标”是你可能输入到该段的位串。每个像素存储的“颜色”是您希望模拟的片段的输出位。假设你已经为那段代码形成了一个*精确的*镜像文件，你现在可以做一个快速查找*而不是再次运行软件*。这就是它如此重要的原因。考虑到数千万人使用多少常见的应用程序和软件包，这样的查找表将能够模拟每年数十亿小时的软件运行时间。

然而，你如何着手*找到*那个巨大的软件输入输出图像的所有相关片段，并**有效地存储它呢？神经网络以三种方式承担这些任务:**

1.  **代码指定的边界条件** —神经网络从一些演示中学习得越来越好。这让我们可以像训练小狗一样训练它们，直到它们有能力为止。他们还能告诉我们什么时候他们*不确定*某事，以及什么时候多个不同的神经网络*不同意*他们的评估。所有这些一起，让神经网络 suss-out**一个输入值可以改变*多远，然后该改变对*输出*值产生影响；在连续函数逼近中，输入和输出之间的相对变化率是多少？无需检查数十亿例*运行时值*；如果你训练一个神经网络为你完成第一遍通读，代码本身应该告诉你它是如何工作的。*
2.  ***测试&公共使用数据**——然而，由于程序状态和用户输入的细节，其他软件的运行等等，软件会遇到奇怪的错误和行为。无论何时发生什么事情，你都会想把那点状态空间知识添加到你的‘输入→输出图像’，*除非是你不想*模仿的 bug 或黑客*。[您可以通过用户反馈，简单地 ***纠正***bug 的 ***输出位*** *，而*永远不需要重新工具化原始代码！"只有当实际代码做正确的事情时，我们才模拟它."另外，花些空闲时间*在输入空间*中漫游，沿直线行进以‘刮擦’拓扑，识别从程序行为中*出现的边界条件，而这些边界在代码中并不*明确。输入→输出图像*的那些*出现的* ***分区*** *将产生最大的压缩比。它们只是块状的、简单的形式，是复杂的代码雕刻的副产品。***
3.  ****压缩试探法&去噪**——整个过程中最具创新性的部分是使用神经网络来压缩令人瞠目结舌的“输入→输出图像”，以这样的方式，你只需要“解压缩”*对应于你特定输入的像素*，而**永远**不需要看到整个图像，*甚至*当你第一次发现它的时候。这个过程是通过一个三级神经网络康加线实现的:一个参数生成器，一个启发式解码器和一个嵌入/去噪器。在解码器和去噪器之间，有一组生成器必须复制的“校正位”;同样，如果您正在处理必须以*完美*保真度重新生成的输出，则在解码器之后需要另一组“校正位”。我将在这篇文章的剩余部分解释这些部分的*为什么*和*如何*。**

****校正位和近似拟合****

**神经网络在执行几乎任何事情的近似方面都是惊人的。最近在超级计算机上运行的模拟物理模拟器的工作产生了 20 亿倍的速度提升！几周前的另一个用例求解偏微分方程的速度快了 1000 倍…几乎所有的偏微分方程，嗯，几乎所有我们仍然无法理解的东西。然而，一旦你要求神经网络遵循一个精确的公式，它就会乱套。其他团队也在致力于此。为神经网络提供了组装的“构建模块”,其中每个模块都是显式和精确的操作符。这个虚构的不准确性还有一个片段，我们必须关注: ***它是输出空间的模糊覆盖*** 。什么？**

**在给定各种输入的情况下，来自生成对抗网络(GAN)的生成器将模拟大量接近它所看到的真实人脸分布的肖像。它并不精确，但它确实“覆盖”了整个面部分布，**做出了它看到的所有*种类的东西*。我们可以在几个“修正位”之间楔入近似空间覆盖的撬棍来支撑我们的模糊地图！想象你正在传递信息，在每个阶段解码它们，你可以看到模糊近似器是如何使这一切发生的:****

**首先，爱丽丝收到一条加密的信息。这是经常发生的程序输入的“散列”;这些输入值中的一大部分用于计算软件中这个特别复杂的步骤。Alice 使用她的“解码器环”(我们的“参数生成器”)将那个“散列”翻译成一组**地址**。一些地址告诉她将使用哪些*试探法和种子*，然后是她需要改变的位的*，接着是*去噪器的地址*，最后是任何其他的*最终校正位。整个配方将贯穿整个链条，现在…****

*因此，Bob 收到消息并取出 Alice 建议的合适的启发式解码器(它只是超级服务器上存储的许多解码器中的一个),将“种子”转换成更复杂的位数组。试探法是“拆开”存储在输入空间位置的输出位。然而，**却是模糊的**。存在严重缺陷。接下来，我们将让它通过另一个神经网络——去噪器。*

*卡罗尔收到鲍勃粗糙的、噩梦般的涂鸦，斜眼看了看，认出那是一条鱼，开始润色边缘和纹理，使它看起来像它应该的样子。然而，鲍勃的一些错误是如此的错误，以至于他们实际上把卡罗尔搞得一团糟！她做出*错误的更正*。可恶。这就是为什么，在 Bob 的启发式算法和 Carol 的去噪器之间，我们会插入一些“校正位”。[我们必须找到这些，对于我们压缩的每一件事；对于一个只使用一次的文件或程序来说不值得，但是对于常用软件来说，可以。]这只是去噪后剩余的误差的梯度。这里:*

*假设卡罗尔在润色鲍勃的手指画版本时犯了一个错误；我们问'**鲍勃的图像中的哪些部分**需要*有所不同*，以便卡罗尔能够正确地**纠正**'少数几个比特将成为众多级联误解的来源；纠正它们，并将翻转的部分存储为稀疏向量。现在，下一次有人送鲍勃那个“种子”时，他会犯同样的错误，*你会纠正那些繁琐的部分*，然后卡罗尔的润色会很顺利！完美:)*

*嗯，差不多了。因为，卡罗尔的一些错误不会消失，除非鲍勃的许多斑点开始翻转。我们不希望将所有这些存储在一些过于复杂的生成器神经网络中，因此，任何难以消除的错误位都被简单地记录下来，并在最后处*被纠正。因此，“纠正位”的两个阶段——第一阶段，在鲍勃的扭曲和卡罗尔的改进之间；第二，在卡罗之后，确保完美的准确性。**

***管子角度比喻***

*这种方法解决了一个基本问题，它可以被想象成一个大型公共建筑下面的可怕的管道网络。每层楼的卫生间都布满了管道，最糟糕的是:为了省钱，这座城市只能买得起*怪异、库存过剩的管道配件*！24 度弯，87 度接头，egad！管道是如此的混乱，因为每根管子都必须被测量和切割成笨拙的形状，以同时适合彼此。这是意大利面条式的代码，以及所有传统软件的讨厌之处。“模糊近似覆盖”和“校正位”让我们做什么？*

*模糊神经网络就像一个具有某种*灵活性*的管道——它可以从一个 34 度的配件开始，沿着路径弯曲以避开其他一些突起，最终到达一个 78 度的管接头。事实上，它可以在一个很宽的弧线上来回弯曲。你有很多选择，从那个*到一个近似器*。这只是一个削减到你想要的特定点的问题，因为否则你的管道可能会喷出一些随机的，摇摆不定的飞溅。该规范就是校正位的作用！他们将你的管道接头固定在墙上，并提供一个可调节的套筒环，为你提供额外的活动空间。*

*这些简化减轻了机器的僵化官僚作风，让我们简化了复杂的流程。从根本上来说，这些摇摆不定的管道和铰链接头解除了软件管道的复杂性和约束。它流动简单，流线型，很少必要的分支。[神经网络*和*校正位用于倾斜这些连接；每一个都是以互补的方式完成的，你不太可能单独使用神经网络看到相同水平的精确压缩。]*

***建造压缩机***

*获取大量的软件和文件，并将它们一起压缩*，最有可能找到细致入微的、合适的启发方法来适当地重新生成和去噪——对于海滩上的波浪，或者一个问题的轻快节奏，或者一列账户，等等。这些试探法是构建您的压缩编解码器的*词典。这是困难的部分，随着压缩内容的增加、需求的变化、新的效率的发现，需要重新完成。***

**然而，一旦软件已经被映射，那么输入可以在神经网络逼近器的片段中被解析，同时具有稀疏的校正位日志。这些软件实例仿真可以在超级服务器上完成，只需通过网络发送设备显示器的*变化编码。您在设备之间“共享”的文件实例仅仅是接收到授权数据查看器字典的新增内容和其他门户中的嵌入位置。不需要通过网络实际发送文件的比特；超级服务器有这个文件，只要你们需要，它就给每个人发一个 ***代码，重新生成那个文件*** 的图片。***

*构建程序的输入→输出图的过程也会揭示潜在的错误、漏洞、失误和未满足的需求。每一条路径都可以揭示一些问题；当神经网络**标记**大块的代码以供人工审查，并试图分析性地绘制每个部分*的流程图*；当神经网络**掠过**输入空间时，测试*阈值*，该阈值导致各种位翻转，作为输入→输出行为的“紧急特征”;以及当用户偶然发现这种情况时；最后，根据压缩仿真器用户的反馈，您可以*显式翻转以纠正*输出**的位，而**无需搜寻并修复代码行中的错误——只有仿真被修复！这些增加的稳定性和确定性层是有价值的，从某种程度上来说，软件开发人员可能很乐意将他们的软件承包到模拟器云上，这样就可以用最小的资本预算进行彻底的调试和超大规模的推广。你怎么说？*