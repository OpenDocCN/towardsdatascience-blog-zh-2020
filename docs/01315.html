<html>
<head>
<title>Making A Production Classifier Ensemble</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">制作生产分类器集成</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/making-a-production-classifier-ensemble-2d87fbf0f486?source=collection_archive---------32-----------------------#2020-02-05">https://towardsdatascience.com/making-a-production-classifier-ensemble-2d87fbf0f486?source=collection_archive---------32-----------------------#2020-02-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7a52" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用BERT、Inception和fastText的现成PDF分类器服务</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/c9651d7c3852132daf39292f5962a921.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gwt3jQ0YRxf0lG-8nUPHzg.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由Jason Dent在Unsplash上拍摄</p></figure><p id="24fa" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">机器学习的演示很容易找到，但是实用的、可以投入生产的端到端解决方案呢？我在这里描述了一个用于pdf的开源的、生产就绪的、基于集成的文档分类器。它达到了98%的准确率。这是对它如何产生的解释，为什么不同的分类器被结合，以及我如何把它变成一个生产系统。</p><h1 id="ebfc" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">需求</h1><p id="a02b" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">我的客户，非盈利的互联网档案馆保存着网络上的内容，这样过去就不会丢失。几乎每个人都知道“<a class="ae mo" href="https://archive.org/web/" rel="noopener ugc nofollow" target="_blank">时光倒流机</a>”，他们提供的网络时光机器。</p><p id="f3dc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">互联网存档有一个选择存档内容的启发法:如果某样东西可能很快就会永远丢失，那就先存档。有时这是战术性的，也是必然的，就像在拔掉插头之前保存Google Plus内容一样。<a class="ae mo" href="https://blog.dshr.org/2017/01/the-long-tail-of-non-english-science.html" rel="noopener ugc nofollow" target="_blank">这项工作</a>的重点是保存那些不为人知的pdf文件，但也许有一天在长尾理论中会很重要。特别是，像学术论文这样由小出版商提供服务的研究工作可能会消失，因为它们没有足够的资金。相比之下，在天平的另一端，公共科学图书馆的论文没有丢失的危险。</p><p id="74ac" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">安德鲁·梅隆基金会有支持图书馆的历史，它为这项工作提供了资助。该授权规定所开发的软件是开源的；这使得把这个项目放在github.com变得很容易。</p><p id="b3de" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">Internet Archive在2019年初向我呈现了这种情况:确定一个PDF是否是研究作品需要30秒，但需要小于1秒。它将用于已存档的pdf和在网络搜索中找到的pdf。使用将是批处理，而不是交互式的，它必须在没有GPU的情况下工作。重要的是，它必须与多种语言一起工作，因为没有太多的训练示例。该计划是处理6.5亿个pdf文件，以找到6%的研究工作。</p><p id="5f5c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">正面训练集是已知的1800万篇论文的集合，这些论文可以被认为是干净的、基本的事实。负面训练集只是从被正面案例污染的6.5亿个pdf中随机选择的。对1，000个负面案例的审核显示有6–7%的正面案例。通过手动检查对这些进行清理，并使用自举来增加集合的大小。</p><p id="fa4c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">带着这些目标和事实，我开始形成一个解决方案。</p><h1 id="5118" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">PDF挑战</h1><p id="5dd7" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">任何机器学习项目的第一步都是了解你的数据。我检查了pdf的一个子集，发现:<br/>一些pdf仅包含文本图像<br/>页面数量从一个到数百个<br/>纵横比和页面布局各不相同</p><p id="ecca" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">要处理只有图像的文档，第一页可用于制作图像，然后用于图像分类。</p><p id="e8cd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一小部分研究作品在出版时会附上封面，为出版商做广告和/或展示许可文本。这表明可以呈现多个页面来提高准确性，但是在项目的这个阶段，仅使用第一个页面就已经给了我们足够的准确性，因此检查更多页面的工作留待将来完成。</p><p id="4e5e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">你可能会想象一项研究工作看起来像一篇典型的计算机科学会议论文，在第一页上有标题、作者、居中的摘要，也许还有一些正文。我当然预料到了这一点，但是一旦你涉足生命科学、立场文件、转录的会议主题演讲等等，设计是相当多样的。以下是一些随机挑选的正面和负面例子:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mp"><img src="../Images/961b9dd62a1c0ba3c9f985330100f88a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SBVfhwq3Qc_FpBbu6DCL5w.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">四个正面例子</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mp"><img src="../Images/c5e5712ebad9a5dd05c68be433fc7baf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YARM0E2A_K-C0CiO22SWrQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">四个反面例子</p></figure><p id="2356" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">即使对于人类来说，这也不是视觉分析的不二法门。</p><h1 id="6fb3" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">PDF到图像</h1><p id="eca7" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">ImageMagick被选择用于第一页图像生成。它使用下面的ghostscript来渲染图像。最初，有许多问题图像大多是黑色的。解决这个问题的诀窍是将背景明确设置为白色。显然，大约有一半的pdf实际上是打印到透明背景上的。</p><p id="23f7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">产生的图像实际上是一个缩略图。这样做很好，因为很多成功的图像分类都是在小图像上完成的。这有一个附带的好处，即结果与语言无关:在224x224的情况下，不可能辨别文档中使用的语言。</p><p id="5bc9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">必须开发一种试探法来检测和剔除空白图像。这可能是由于渲染错误，如缺少日语字体，或者实际上可能有一个空白的第一页。显然，如果正负样本集都包含空白图像，那么分类就像扔骰子一样，所以这些必须被移除。</p><p id="a585" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">与自然图像不同，猫可以出现在框架的任何地方，研究工作pdf是严格对齐的，通常在标题中居中显示文本。为了捕捉这个方面，ImageMagick被指示水平居中渲染，使其与北边齐平。在一项对2000个例子的研究中，我没有看到对齐带来的大的准确性提高，所以可能的情况是，已经能够处理未对齐图像的模型没有从更多的对齐中受益。</p><h1 id="96ce" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">PDF转文本</h1><p id="43a8" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">文本需要提取以及首页图像。经过大量实验后，发现pdftotext实用程序对于文本来说是快速而有效的。此外，因为它是作为子流程运行的，所以使用超时来避免陷入寄生案例。当一个系统暴露在数以百万计的例子中时，导致过程缓慢或停滞的坏的苹果pdf是可能的。</p><p id="8170" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">使用pdftotext是一种乐趣。开箱即用，它只是工作，它可以保持人类阅读的顺序，即使有2列格式的话。</p><h1 id="4f9d" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">预处理可以跳过吗？</h1><p id="f85a" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">PDF格式是一组使用排版、艺术线条和图像来呈现文档的指令。有许多自由度，所以PDF的每个实现可能都有稍微不同的风格。如果有些是专门用于研究工作或没有，指令模式可能是一个廉价的线索，但没有保证它是稳定的时间；风格会随着时间来来去去。我估计大概有100种指令模式在使用中。对于只有图像的pdf，仅仅通过对正面和反面例子的训练，训练不可能在任何合理的计算预算上学会OCR。这就像科幻作家斯坦尼斯拉夫·莱姆的想法，通过在阳光下用放大镜杀死出错的蚂蚁来训练蚂蚁写自然语言。</p><p id="1fe2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在放弃端到端原始PDF的想法后，我认为文本提取和将第一页呈现为图像是很好的方法。这些特征提取预处理步骤的速度很容易控制在1秒的时间预算内。</p><h1 id="1956" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">基线</h1><p id="f12e" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">假设使用pdftotext，那么什么是好的基线模型？经典的计算机科学论文有“摘要”和“参考文献”这两个词。只需要这两个词会有多好？我进行了非正式的测量，发现要求两个单词只有50%的准确性，这是令人沮丧的。要求任一关键字对于阳性情况有84%的准确性。只有10%的阴性病例有这些关键词。这给了我一个需要打破的准确性目标。</p><p id="65e2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">接下来，有哪些模型可以使用？</p><h1 id="ae2a" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">图像分类</h1><p id="b525" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">利用迁移学习，TensorFlow Hub用于测试十几个图像分类器模型的准确性。InceptionV3和Resnet最好，为87%；我选择InceptionV3有些武断。</p><p id="1ad5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">虽然87%并不完全是一流的，但只有包含文本图像的pdf才会遭受13%的错误率。大多数pdf包含明确的文本。</p><h1 id="80cd" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">一袋单词</h1><p id="dbed" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">线性文本分类器可以非常快，但是当没有足够的训练样本时，它们在处理多种语言时会有麻烦。在这个项目中，选择了FaceBook的fastText[1]。这是一个写得很好的带有python绑定的C++包，在速度方面毫不妥协。</p><p id="65c8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">“快”是指0.4毫秒，比CPU上的深度神经网络快3个数量级。在20，000个文档训练和测试集上的准确率达到96%。一个很大的优点是它是全文，但一个很大的缺点是这种词袋分类器对很少或没有训练样本的语言没有泛化能力。</p><p id="bb92" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">FastText能够处理n元语法，比如单词对。在测试中，没有发现二元模型的准确性优势。</p><h1 id="db21" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">伯特</h1><p id="57d4" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">到目前为止，每个人都知道BERT[2]模型是“自我监督”自然语言的一大进步。多语言模型是用100多种语言训练的，它是这个项目的完美选择。</p><p id="9acf" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">使用BERT的分类器模式，在20，000个文档训练和测试集上对模型进行微调。结果是98%的准确率。</p><p id="93dc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一些语言中的例子数量并不多，但是分类对于非英语语言是正确的，这表明它确实是跨语言通用的。</p><h1 id="35cb" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">整体建筑</h1><p id="cc85" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">21世纪初，整体学习风靡一时。那是在贝叶斯学习流行之前。事实上，随机森林通常被认为是一种集成，因为它在训练示例上创建了一个拼凑物。</p><p id="e7e6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们现在处于深度学习时代，但集成是组合文本和图像等多种形式的标准工具包的一部分。下一步是使用集成，通过使用快速的线性模型有条件地加速分类，如果置信度低，则使用BERT。</p><p id="4fd0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下图显示了生产分类器集成的工作原理:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/bf85de1b4d780a814dc1452616301007.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*La5j8_tz9sPrVd39Wl8S9A.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">运行时架构显示REST via Flask、TensorFlow Serving for BERT/CNN和FastText线性分类器</p></figure><p id="8610" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">上述每个模型计算一个分类置信度。这使得创建选择性地使用模型来强调速度或准确性的集成分类器成为可能。对于速度示例，如果文本可用并且快速文本线性分类器置信度高，则可以跳过BERT。为了强调准确性，可以运行所有三个模型，然后结合置信值和分类预测进行总体分类。</p><h1 id="5b5b" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">REST接口</h1><p id="4863" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">使用Flask实现的REST接口使用URI路径中的变化来指示运行哪个分类器的偏好。URI指出的可能的加工选择:</p><p id="ed0c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">使用特定的分类器列表</p><p id="3673" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">运行所有分类器</p><p id="5425" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">自动模式使用最快的方法，这取决于可信度</p><h1 id="edd5" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">使其可以投入生产</h1><p id="1b7d" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">TensorFlow Serving[3]对于在生产中运行TensorFlow模型至关重要。一些实际的评论是适当的。TensorFlow Serving是一个张量图计算引擎，它加载“保存的模型”(我引用它是因为它听起来很普通，但它是一种特定的数据格式)，并通过网络为请求提供服务。为了提高速度，它是用C++编写的，可以重新编译以利用机器提供的精确指令集来获得最大的吞吐量。</p><p id="b1e2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">TensorFlow服务可以使用REST或gRPC。事实证明，gRPC对客户端的干扰相当大，因为当使用gRPC时，用于创建输入张量的服务器端Python代码(“处理器”)往往也会在客户端使用。这导致了非常混乱的集成，服务器端和客户端的耦合超过了必要的程度；不仅仅是API，还有代码。这可能只是BERT中的一个疏忽，也可能是gRPC在与TensorFlow结合使用时普遍缺乏封装实践。</p><p id="40b1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">另一方面，REST能够使用不需要后端代码的更通用的调用签名。与HTTP相比，gRPC的优势是通过较小的消息传输速度稍快，但是在只有CPU的部署中，这种速度差异可以忽略不计。由于这些原因，REST在这个项目中更受欢迎。</p><p id="3644" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">来自Google的BERT的原始代码没有导出模型的“保存的模型”格式。为了解决这个问题，正式的BERT项目被分叉，并添加了一个选项来创建必要的模型格式。</p><h1 id="167a" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">回购协议</h1><p id="c378" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">这个项目被戏称为三个分类器的集合:“pdf_trio”。</p><p id="cda3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有3个回购:</p><p id="30db" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">主要项目<a class="ae mo" href="https://github.com/tralfamadude/pdf_trio" rel="noopener ugc nofollow" target="_blank">https://github.com/tralfamadude/pdf_trio</a></p><p id="c339" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">图像分类器【https://github.com/tralfamadude/pdf_image_classifier T2】</p><p id="18d8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">https://github.com/tralfamadude/bert的伯特分类器<a class="ae mo" href="https://github.com/tralfamadude/bert" rel="noopener ugc nofollow" target="_blank"/></p><p id="1d38" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">首先是主体工程。第二个是来自TensorFlow Hub的CNN分类器示例。第三个是官方BERT的一个小delta。pdf_trio有5个README.md文件作为参考文档，并有用于训练、测试和部署的脚本。</p><p id="49fb" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">经过训练的模型对于github来说太大了，但是可以从archive.org下载，正如项目自述文件中所描述的。</p><h1 id="2f27" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">最后</h1><p id="6e1a" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">这次PDF_trio的温柔之旅到此结束。通过使用不同的训练示例，可以简单地制作不同种类的PDF分类器。希望你觉得<a class="ae mo" href="https://github.com/tralfamadude/pdf_trio" rel="noopener ugc nofollow" target="_blank"> PDF_trio </a>有用。</p><h2 id="1c66" class="mr ls iq bd lt ms mt dn lx mu mv dp mb le mw mx md li my mz mf lm na nb mh nc bi translated">承认</h2><p id="ea24" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">感谢:布莱恩·纽博尔德，杰斐逊·贝利，大卫·s·h·罗森塔尔。</p><h2 id="f47f" class="mr ls iq bd lt ms mt dn lx mu mv dp mb le mw mx md li my mz mf lm na nb mh nc bi translated">参考</h2><p id="b48f" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">[1] <a class="ae mo" href="https://fasttext.cc/" rel="noopener ugc nofollow" target="_blank">快速文本</a></p><p id="7e02" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><a class="ae mo" href="https://en.wikipedia.org/wiki/BERT_(language_model)" rel="noopener ugc nofollow" target="_blank">伯特</a></p><p id="374d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[3] <a class="ae mo" href="https://www.tensorflow.org/tfx/guide/serving" rel="noopener ugc nofollow" target="_blank">张量流发球</a></p></div></div>    
</body>
</html>