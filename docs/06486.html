<html>
<head>
<title>Applied Multivariate Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">应用多元回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/applied-multivariate-regression-faef8ddbf807?source=collection_archive---------19-----------------------#2020-05-23">https://towardsdatascience.com/applied-multivariate-regression-faef8ddbf807?source=collection_archive---------19-----------------------#2020-05-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/0fc2dda7cc4baa62ed4b8ad357958f31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uPqGfX2SmV8Q8khOIAclLg.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片由<a class="ae jd" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3502291" rel="noopener ugc nofollow" target="_blank">皮克斯拜</a>的<a class="ae jd" href="https://pixabay.com/users/Hurca-8968775/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3502291" rel="noopener ugc nofollow" target="_blank">米尔科·格里森迪</a>拍摄</p></figure><div class=""/><div class=""><h2 id="53ef" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">机器学习系列的第4篇</h2></div><p id="4b39" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在本文中，我们将了解多元回归的概念。我们还将讨论与算法相关的一个常见问题，即虚拟变量陷阱。</p><p id="2d46" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">首先，我们将熟悉多元回归的概念，然后我们将建立自己的多元回归模型。然而，在开始之前，我建议你看一下我关于<a class="ae jd" href="https://medium.com/analytics-vidhya/linear-regression-5100fe32993a" rel="noopener">简单线性回归</a>的文章，以便更好地理解这些概念。</p><h1 id="31ca" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated"><strong class="ak">什么是多元回归？</strong></h1><p id="e140" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">多元回归是简单线性回归的扩展。当我们希望根据两个或更多不同变量的值来预测一个变量的值时，就会用到它。我们要预测的变量叫做<strong class="kx jh">因变量</strong>，而那些用来计算因变量的叫做<strong class="kx jh">自变量</strong>。</p><p id="286e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">多元回归的数学函数/假设具有以下形式:</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/379cbbd525be40b21ecee815da3adb36.png" data-original-src="https://miro.medium.com/v2/resize:fit:468/format:webp/1*-MzeyVZ0C3iUDRQJf6s9fw.jpeg"/></div></figure><p id="9278" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">其中，n代表自变量的个数，β0~ βn <strong class="kx jh"> </strong>代表系数，x1~xn为自变量</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/7631ce993ce8103e045f1e12efb12301.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*MtuQBTW0-XbjA2RrP2z3Kw.gif"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片由<a class="ae jd" href="https://wiki.cdot.senecacollege.ca/wiki/DPS921/Franky" rel="noopener ugc nofollow" target="_blank">弗兰奇</a>提供，来自<a class="ae jd" href="https://wiki.cdot.senecacollege.ca/wiki/Main_Page" rel="noopener ugc nofollow" target="_blank"> CDOT维基</a></p></figure><p id="6de6" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">使用多元模型有助于我们比较不同结果的系数。使多元或多元线性回归成为更好模型的是一个小的成本函数。</p><h1 id="a3d5" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated"><strong class="ak">成本函数</strong></h1><p id="daa9" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">简而言之，它是一个为模型偏离观测数据的情况分配成本的函数。在这种情况下，我们的成本是<strong class="kx jh">误差平方和</strong>。多元线性回归的成本函数由下式给出:</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/d30cf6e0271c61c47c9c632b50338453.png" data-original-src="https://miro.medium.com/v2/resize:fit:602/format:webp/1*-j8MAhC0nou22-As-zIOeA.jpeg"/></div></figure><p id="02d7" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们可以把这个方程理解为我们的预测值和实际值之差的平方和除以数据集长度的两倍。较小的均方误差意味着更好的性能。通常，成本函数与梯度下降算法一起使用，以找到最佳参数。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/88af704ab69dc514109933678106fcf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-665RsTyYAFs05TSU8ksRA.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片来自<a class="ae jd" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2724235" rel="noopener ugc nofollow" target="_blank">Pixabay</a>Nattanan Kanchanaprat</p></figure><p id="eba1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，我们将通过构建多元线性回归来实际应用我们所学的知识。</p><blockquote class="mv mw mx"><p id="f049" class="kv kw my kx b ky kz kh la lb lc kk ld mz lf lg lh na lj lk ll nb ln lo lp lq ij bi translated"><em class="jg">你可以在我的</em> <a class="ae jd" href="https://github.com/ashwinraj-in/MediumArticles/blob/master/Multivariate_Regression.ipynb" rel="noopener ugc nofollow" target="_blank"> <em class="jg"> GitHub </em> </a> <em class="jg">手柄上访问这个回归模型的完整代码和其他资源。</em></p></blockquote><p id="4e07" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这个例子中，我们将预测一所房子的价值，给定的特征有中等收入、平均房龄、房间数、家庭数、平均面积、卧室数和地区人口。</p><h2 id="4010" class="nc ls jg bd lt nd ne dn lx nf ng dp mb le nh ni md li nj nk mf lm nl nm mh nn bi translated"><strong class="ak">步骤1:导入库并加载数据</strong></h2><p id="5e74" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">我们的第一步是导入构建模型所需的库。没有必要在一个地方导入所有的库。Python允许我们在任何地方导入任何库。首先，我们将导入Pandas、Numpy、Matplotlib和Seaborn库。</p><pre class="mp mq mr ms gt no np nq nr aw ns bi"><span id="00d1" class="nc ls jg np b gy nt nu l nv nw">#Importing the libraries and and reading the data into a Pandas DataFrame</span><span id="98f2" class="nc ls jg np b gy nx nu l nv nw">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span><span id="48dc" class="nc ls jg np b gy nx nu l nv nw">test=pd.read_csv("california_housing_test.csv")<br/>train=pd.read_csv("california_housing_train.csv")</span></pre><p id="6c8d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一旦导入了这些库，我们的下一步将是获取数据集并将数据加载到我们的笔记本中。对于这个例子，我采用了加州住房数据集。</p><h2 id="2e77" class="nc ls jg bd lt nd ne dn lx nf ng dp mb le nh ni md li nj nk mf lm nl nm mh nn bi translated"><strong class="ak">第二步:可视化数据</strong></h2><p id="d325" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">成功加载数据后，我们的下一步是可视化这些数据。Matplotlib 和<strong class="kx jh">search</strong>是优秀的库，可以用来可视化我们在各种不同地块上的数据。</p><pre class="mp mq mr ms gt no np nq nr aw ns bi"><span id="09b5" class="nc ls jg np b gy nt nu l nv nw">#Visuaising our data using Seaborn Library</span><span id="61a5" class="nc ls jg np b gy nx nu l nv nw">plt.figure()<br/>sns.heatmap(data.corr(), cmap='coolwarm')<br/>plt.show()</span><span id="7872" class="nc ls jg np b gy nx nu l nv nw">sns.lmplot(x='median_income', y='median_house_value', data=train)<br/>sns.lmplot(x='housing_median_age', y='median_house_value', data=train)</span></pre><h2 id="1a4a" class="nc ls jg bd lt nd ne dn lx nf ng dp mb le nh ni md li nj nk mf lm nl nm mh nn bi translated">步骤3:特征工程</h2><p id="8ddb" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">特征工程是利用领域知识通过数据挖掘技术从原始数据中提取特征的过程。我只选择了几列来处理这个模型的连续数值。</p><pre class="mp mq mr ms gt no np nq nr aw ns bi"><span id="3990" class="nc ls jg np b gy nt nu l nv nw">data = data[[‘total_rooms’, ‘total_bedrooms’, ‘housing_median_age’, ‘median_income’, ‘population’, ‘households’]]<br/>data.info()</span><span id="86a3" class="nc ls jg np b gy nx nu l nv nw">data['total_rooms'] = data['total_rooms'].fillna(data['total_rooms'].mean())<br/>data['total_bedrooms'] = data['total_bedrooms'].fillna(data['total_bedrooms'].mean())</span></pre><p id="a0a9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">当特征数量非常大时，特征工程变得更加重要。特征工程最重要的用途之一是减少过度拟合，提高模型的准确性。</p><h2 id="44fb" class="nc ls jg bd lt nd ne dn lx nf ng dp mb le nh ni md li nj nk mf lm nl nm mh nn bi translated"><strong class="ak">第四步:拟合模型</strong></h2><p id="ca5d" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">选择所需参数后，下一步是从sklearn库中导入train_test_split，该库用于将数据集拆分为训练和测试数据。</p><pre class="mp mq mr ms gt no np nq nr aw ns bi"><span id="af7d" class="nc ls jg np b gy nt nu l nv nw">#Splitting training and testing data</span><span id="f416" class="nc ls jg np b gy nx nu l nv nw">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(train, y, test_size = 0.2, random_state = 0)<br/>y_train = y_train.reshape(-1,1)<br/>y_test = y_test.reshape(-1,1)</span></pre><p id="9586" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在此之后，从<strong class="kx jh">sk learn . model _ selection</strong>导入<strong class="kx jh">线性回归</strong>，并且模型适合训练数据集。我们模型的截距和系数可以计算如下:</p><pre class="mp mq mr ms gt no np nq nr aw ns bi"><span id="8e5b" class="nc ls jg np b gy nt nu l nv nw">#Fitting the model on training data</span><span id="28f8" class="nc ls jg np b gy nx nu l nv nw">from sklearn.linear_model import LinearRegression<br/>regressor = LinearRegression()<br/>regressor.fit(X_train, y_train)</span><span id="0cf0" class="nc ls jg np b gy nx nu l nv nw">#Calculating the Intercept and Coefficient</span><span id="fe6e" class="nc ls jg np b gy nx nu l nv nw">print(regressor.intercept_)<br/>print(regressor.coef_)</span></pre><p id="9aff" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">可以通过找到模型的均方根误差来评估模型的性能。</p><pre class="mp mq mr ms gt no np nq nr aw ns bi"><span id="7771" class="nc ls jg np b gy nt nu l nv nw">predictions = regressor.predict(X_test)<br/>predictions = predictions.reshape(-1,1)</span><span id="1f0b" class="nc ls jg np b gy nx nu l nv nw">#Calculate RMSE of the model</span><span id="fe93" class="nc ls jg np b gy nx nu l nv nw">from sklearn.metrics import mean_squared_error<br/>print(‘MSE:’, mean_squared_error(y_test,predictions))<br/>print(‘RMSE:’, np.sqrt(mean_squared_error(y_test,predictions)))</span></pre><p id="5d21" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们模型的RMSE是0.6628934048044981。计算值与预测值的曲线图如下所示:</p><h1 id="4b89" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated"><strong class="ak">虚拟变量陷阱</strong></h1><p id="bb37" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">使用多元模型时，处理定量或数值数据很容易。然而，这对于分类数据来说是不一样的。它们不能直接使用，需要改造。</p><p id="e61b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">虚拟变量是用来代替分类数据的“代理”变量，分类数据有时出现在我们用来建立回归模型的数据集中。将所有哑变量用于回归模型导致哑<strong class="kx jh"> <em class="my"> </em> </strong>变量<strong class="kx jh"> <em class="my"> </em> </strong>陷阱。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/54e21d76341a24244a6e511824342e5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:904/format:webp/1*p_TsRI-f7l4pEHMf5hOkNQ.jpeg"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="ae4c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">虚拟变量陷阱</strong>是独立变量多重共线的情况，即两个或更多变量高度相关。为了避免这种情况，建议在设计回归模型时排除一个虚拟变量。</p><h2 id="98cf" class="nc ls jg bd lt nd ne dn lx nf ng dp mb le nh ni md li nj nk mf lm nl nm mh nn bi translated"><strong class="ak">这里有一个例子来理解这是如何工作的:</strong></h2><p id="84b8" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">让我们考虑性别的情况，它可以有两个值男性(0)或女性(1)。在使用标签编码程序将这些分类特征转换为数字属性后，如果我们包含两个虚拟变量，则会导致冗余，从而导致虚拟变量陷阱。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nz"><img src="../Images/f91d10d3a175340220c294300940c084.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vlYfllUpzAONFwmZTl5ONA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片来自<a class="ae jd" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3773756" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae jd" href="https://pixabay.com/users/GDJ-1086657/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3773756" rel="noopener ugc nofollow" target="_blank">戈登·约翰逊</a></p></figure><p id="cdb6" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这样的问题是可以避免的，如果我们在回归模型中不使用这两个变量，就好像一个人不是男性，那么预计这个人是女性。这样可以避免虚拟变量陷阱</p><h1 id="ed41" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">资源</h1><p id="a95b" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">这里有一些资源，您可以使用它们来更深入地理解多元回归的概念。</p><ol class=""><li id="aa72" class="oa ob jg kx b ky kz lb lc le oc li od lm oe lq of og oh oi bi translated"><a class="ae jd" href="https://www.geeksforgeeks.org/" rel="noopener ugc nofollow" target="_blank"> Geeksforgeeks </a></li><li id="f8f5" class="oa ob jg kx b ky oj lb ok le ol li om lm on lq of og oh oi bi translated"><a class="ae jd" rel="noopener" target="_blank" href="/multiple-linear-regression-beginners-guide-5b602d716aa3">多元线性回归——初学者指南</a></li><li id="31b3" class="oa ob jg kx b ky oj lb ok le ol li om lm on lq of og oh oi bi translated"><a class="ae jd" href="https://medium.com/data-science-101/writing-multivariate-linear-regression-from-scratch-19e32eeb6ab0" rel="noopener">从头开始编写多元线性回归</a></li></ol><p id="7c46" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在我们已经到了这篇文章的结尾，我希望你会发现这篇文章真的很有启发性。我希望你发现它内容丰富！如果你有任何问题或者我做错了什么，请联系我！你可以通过<a class="ae jd" href="http://rajashwin812@gmail.com" rel="noopener ugc nofollow" target="_blank">邮箱</a>或<a class="ae jd" href="http://linkedin.com/in/rajashwin/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>与我联系</p></div></div>    
</body>
</html>