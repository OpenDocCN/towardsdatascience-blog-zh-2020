# åˆ†ææœ€ä½³é»‘å®¢æ–°é—»å¸–å­

> åŸæ–‡ï¼š<https://towardsdatascience.com/analyzing-best-hacker-news-posts-bebd7d2fd791?source=collection_archive---------48----------------------->

*æœ‰å²ä»¥æ¥æœ€ä½³é»‘å®¢æ–°é—»å¸–å­çš„ç»Ÿè®¡å’Œæ–‡æœ¬åˆ†æã€‚*

æ¯å¤©æˆ‘éƒ½ä¼šæŸ¥çœ‹[é»‘å®¢æ–°é—»](https://news.ycombinator.com/)å¯»æ‰¾æœ‰è¶£çš„ä¿¡æ¯ï¼Œæ— è®ºæ˜¯æ–‡ç« ã€æ•…äº‹ã€è½¯ä»¶è¿˜æ˜¯å·¥å…·ã€‚å¤§å¤šæ•°ç™»ä¸Šå¤´ç‰ˆçš„æŠ•ç¨¿éƒ½éå¸¸æœ‰è¶£å’Œæœ‰ç”¨ï¼Œè€Œä¸”ç¤¾åŒºé©±åŠ¨çš„å¸–å­ç®¡ç†å¦‚æ­¤ä¹‹å¥½çš„äº‹å®è®©æˆ‘ç€è¿·ã€‚

ä¸ºäº†è¿™ç¯‡æ–‡ç« çš„ç›®çš„ï¼Œæˆ‘ä½¿ç”¨äº†[é»‘å®¢æ–°é—» API](https://github.com/HackerNews/API) æ”¶é›†äº†å¤§çº¦ 200 ç¯‡æäº¤ç»™ Hacker News çš„æœ€å¥½çš„æ•…äº‹å’Œä»–ä»¬çš„è¯„è®ºï¼Œå¹¶å¯¹æ•°æ®è¿›è¡Œäº†ä¸€äº›å¤„ç†ï¼Œä»¥è·å¾—ä¸€ç‚¹å…³äºä»€ä¹ˆæ˜¯ä¸€ç¯‡å¥½çš„ã€ŠHN é‚®æŠ¥ã€‹çš„è§è§£ã€‚

åœ¨æˆ‘ä»¬å¼€å§‹ä¹‹å‰ï¼Œæˆ‘å¿…é¡»è¯´ï¼Œæˆ‘æ¯«ä¸æ€€ç–‘é»‘å®¢æ–°é—»æäº¤æ˜¯å¥½çš„ï¼Œè¿™è¦å½’åŠŸäºæ‰€æä¾›ä¿¡æ¯çš„è´¨é‡å’Œå¯¹è¯¥ç‰¹å®šä¿¡æ¯çš„å…´è¶£ç¨‹åº¦ã€‚ä½†æ˜¯ï¼Œå¯èƒ½è¿˜æœ‰å…¶ä»–å› ç´ ï¼Œåœ¨å¾ˆå°çš„æ¯”ä¾‹ä¸Šï¼Œå¸®åŠ© HN æåç™»ä¸Šå¤´ç‰ˆã€‚

è®°ä½è¿™ä¸€ç‚¹ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹è¿™ç¯‡æ–‡ç« çš„æ¦‚è¿°:

*   ä¸ºæˆ‘ä»¬çš„åˆ†æè·å–æ•°æ®
*   æ•°æ®å¯è§†åŒ–:å•è¯äº‘å’Œåˆ†æ•°åˆ†æ
*   ä½•æ—¶åœ¨ HackerNews ä¸Šå‘å¸–
*   é—® HN vs ç§€ HN
*   é»‘å®¢æ–°é—»ä¸Šçš„äººä»¬è°ˆè®ºè°:å®ä½“è¯†åˆ«å’Œå…³é”®è¯æå–
*   ç»“è®º

*æœ¬æ–‡åŸè½½äº* [*ç¨‹åºå‘˜èƒŒåŒ…åšå®¢*](https://programmerbackpack.com/latent-dirichlet-allocation-for-topic-modelling-explained-algorithm-and-python-scikit-learn-implementation/) *ã€‚å¦‚æœä½ æƒ³é˜…è¯»æ›´å¤šè¿™ç±»çš„æ•…äº‹ï¼Œä¸€å®šè¦è®¿é—®è¿™ä¸ªåšå®¢ã€‚*

*å¯¹æ›´å¤šè¿™æ ·çš„æ•…äº‹æ„Ÿå…´è¶£ï¼Ÿåœ¨ Twitter ä¸Šå…³æ³¨æˆ‘ï¼Œåœ°å€æ˜¯*[*@ b _ dmarius*](https://twitter.com/b_dmarius)*ï¼Œæˆ‘ä¼šåœ¨é‚£é‡Œå‘å¸ƒæ¯ä¸€ç¯‡æ–°æ–‡ç« ã€‚*

# è·å–æ•°æ®è¿›è¡Œåˆ†æ

æˆ‘ä½¿ç”¨äº† HackerNews API /beststories ç«¯ç‚¹æ”¶é›†äº† 188 ä¸ªæœ‰å²ä»¥æ¥æœ€å¥½çš„æ•…äº‹ã€‚å¯¹äºæ¯ä¸ªæ•…äº‹ï¼Œæˆ‘ä¹Ÿæ”¶é›†äº†è¯„è®º(ä½†ä¸æ˜¯å¯¹è¯„è®ºçš„è¯„è®ºï¼Œåªæœ‰ä¸»çº¿)ã€‚è¿™æ˜¯æˆ‘ä¸ºæ¯ä¸ªæ¡ç›®å­˜å‚¨çš„æ•°æ®ã€‚

```
id - the id of the entry
parent - the id of the parent. For a story, it is the same as the id field. For a comment, it's the id of the story to which the commend was added
kids_number - only for stories, meaning the number of comments
score - only for stories: the number of points the submission got
time - UNIX timestamp of the time the entry was added
text - title of posts or texts of comments
type - 'story' or 'comment'
```

æˆ‘ç”¨æ¥è·å–æ•°æ®çš„ç±»çš„å®Œæ•´ä»£ç å°†åœ¨æœ¬æ–‡æœ«å°¾æä¾›ã€‚

ç„¶åï¼Œæ•°æ®å­˜å‚¨åœ¨ csv_file ä¸­ï¼Œå¹¶ä»é‚£é‡ŒåŠ è½½åˆ° Pandas å¸§ä¸­ã€‚æˆ‘è¿˜éœ€è¦ä¸ºæˆ‘çš„åˆ†æåˆ›å»ºå¦å¤– 4 åˆ—: *DayOfWeekï¼ŒHourOfDayï¼ŒisAskï¼ŒisShowã€‚è¿™äº›åå­—ä¸è¨€è‡ªæ˜ã€‚*

```
dataFetcher = DataFetcher("https://hacker-news.firebaseio.com/v0/", "data.csv")
    dataFetcher.fetchData() df = pd.read_csv("data.csv") df['DateTime'] = pd.to_datetime(df['time'], unit='s')
    df['DayOfWeek'] = df['DateTime'].dt.day_name()
    df['HourOfDay'] = df['DateTime'].dt.hour
    df['isAsk'] = df.apply(lambda x: x.type=='story' and x.text.lower().startswith("ask hn:"), axis=1)
    df['isShow'] = df.apply(lambda x: x.type == 'story' and x.text.lower().startswith("show hn:"), axis=1)
```

# æ•°æ®å¯è§†åŒ–:å•è¯äº‘å’Œåˆ†æ•°åˆ†æ

æˆ‘é¦–å…ˆå¯¹æ•°æ®åšäº†ä¸€äº›æ¢ç´¢æ€§çš„åˆ†æã€‚é¦–å…ˆï¼Œæˆ‘ä»æ•…äº‹æ ‡é¢˜å’Œè¯„è®ºä¸­å»ºç«‹äº†ä¸¤ä¸ªç‹¬ç«‹çš„å•è¯äº‘ï¼Œå¸Œæœ›æˆ‘èƒ½å¯¹ HackerNews ä¸Šå¸¸ç”¨çš„å•è¯æœ‰æ‰€äº†è§£ã€‚æˆ‘å·²ç»ä»æ ‡é¢˜ä¸­åˆ é™¤äº†â€œå±•ç¤º HNâ€å’Œâ€œè¯¢é—® HNâ€çš„æ ‡ç­¾ã€‚

```
stopwords = set(STOPWORDS)
    stopwords.update(["Ask", "Show", "HN"])
    titles_text = " ".join(df[df['type']=='story']['text'].unique())
    titles_cloud = WordCloud(stopwords=stopwords, background_color='white').generate(titles_text)
    plt.figure(figsize=(8, 8), facecolor=None)
    plt.imshow(titles_cloud, interpolation="bilinear")
    plt.axis("off")
    plt.tight_layout(pad=0)
    plt.show()
```

![](img/a15f7735b9acb3b4d37afaee415301cc.png)

ä»æ•…äº‹æ ‡é¢˜æ„å»ºå•è¯äº‘

é™¤äº†å¤§çš„ã€æ˜æ˜¾çš„ Covid å’Œå† çŠ¶ç—…æ¯’è¯ï¼Œå¤§å¤šæ•°è¯éƒ½ä¸è½¯ä»¶ã€ç¼–ç¨‹å’ŒæŠ€æœ¯æœ‰å…³ã€‚ä¸€ä¸ªå¾ˆå¥½çš„è§‚å¯Ÿæ˜¯ï¼Œè§†é¢‘ä¼¼ä¹åœ¨é»‘å®¢æ–°é—»ä¸Šå·¥ä½œå¾—å¾ˆå¥½(è‡³å°‘è¿™ä¸ªè¯äº‘å‘Šè¯‰æˆ‘ä»¬)ã€‚

ä¹Ÿæ¥çœ‹çœ‹è¯„è®ºå§ã€‚

```
comments = " ".join(df[df['type'] == 'comment']['text'].unique())
    comments_cloud = WordCloud(background_color='white').generate(comments)
    plt.figure(figsize=(8, 8), facecolor=None)
    plt.imshow(comments_cloud, interpolation="bilinear")
    plt.axis("off")
    plt.tight_layout(pad=0)
    plt.show()
```

![](img/6c72480366806439299abfc2da4fc5a7.png)

ä»è¯„è®ºä¸­æ„å»ºå•è¯äº‘

æˆ‘æœ‰ä¸€ç‚¹å¤±æœ›ï¼Œå› ä¸ºæˆ‘æ²¡æœ‰åŒ…æ‹¬æ‰€æœ‰å…³äºè¿™ä¸ªåˆ†æçš„è¯„è®ºï¼Œä½†æ˜¯è¯„è®ºçš„æ•°é‡éå¸¸å¤§ï¼Œæˆ‘ä¸ç¡®å®šå®ƒå¯¹æˆ‘çš„è¿™ç¯‡æ–‡ç« æœ‰å¤šå¤§å¸®åŠ©ã€‚ä½†æ˜¯æˆ‘ä»¬éƒ½çŸ¥é“æœ‰æ—¶å€™æˆ‘ä»¬èŠ±åœ¨è¯„è®ºåŒºçš„æ—¶é—´æ¯”èŠ±åœ¨æœ€åˆæäº¤çš„å¸–å­ä¸Šçš„æ—¶é—´è¿˜å¤šğŸ˜€

ç„¶åæˆ‘æƒ³çœ‹çœ‹æœ€å¥½çš„å¸–å­çš„åˆ†æ•°ã€‚æˆ‘ç»˜åˆ¶äº†ä¸€ä¸ªç›´æ–¹å›¾æ¥è¯´æ˜åˆ†æ•°å€¾å‘äºèšé›†çš„å€¼ï¼Œæˆ‘è¿˜è®¡ç®—äº†åˆ†æ•°çš„å¹³å‡å€¼å’Œä¸­å€¼ã€‚

```
# Histogram of scores scores = df[df['type']=='story']['score']
    scores.plot.hist(bins=12, alpha=0.5)
    plt.show() # Average score
    print ("Average score: ", df[df['type']=='story']['score'].mean()) # Median score
    print("Median score: ", df[df['type'] == 'story']['score'].median())
```

![](img/ae3d04a36543cb0965bf3af38a3c32a0.png)

é»‘å®¢æ–°é—»æœ€ä½³å¸–å­å¾—åˆ†ç›´æ–¹å›¾

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå¤§å¤šæ•°æ•…äº‹çš„å¾—åˆ†éƒ½ä½äº 200 åˆ†ï¼Œä½†ä¹Ÿæœ‰ä¸€äº›å¼‚å¸¸å€¼ï¼Œè‡³å°‘æœ‰ 1000 åˆ†ã€‚

æˆ‘çš„æ•°æ®é›†çš„å¹³å‡å¾—åˆ†ä¸º 194.80ï¼Œä½†æ˜¯è¿™å—åˆ°äº†å¼‚å¸¸å€¼çš„å·¨å¤§å½±å“ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘è¿˜è®¡ç®—äº†**çš„ä¸­é—´å€¼**ï¼Œå®ƒæ˜¯ 140.0ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œé»‘å®¢æ–°é—»ä¸Šå¤§çº¦ä¸€åŠçš„æœ€ä½³æŠ¥é“å¾—åˆ†ä¸åˆ° 140 åˆ†ï¼Œè€Œå¦ä¸€åŠå¾—åˆ†è¶…è¿‡äº† 140 åˆ†ã€‚

# ä½•æ—¶åœ¨é»‘å®¢æ–°é—»ä¸Šå‘å¸ƒ

è¿™æ˜¯å¾ˆå¤šäººåœ¨ç½‘ä¸Šé—®çš„é—®é¢˜ã€‚è¿™ç¯‡æ–‡ç« ç»ä¸æ˜¯å¯»æ‰¾ç­”æ¡ˆçš„æ·å¾„ï¼Œä½†æˆ‘ä»ç„¶è®¤ä¸ºæˆ‘æ‰¾åˆ°äº†ä¸€äº›æœ‰è¶£çš„ä¸œè¥¿ã€‚

é¦–å…ˆï¼Œæˆ‘ç»˜åˆ¶äº†ä¸€å‘¨ä¸­æ¯å¤©çš„æ•…äº‹åˆ†å¸ƒå›¾ã€‚

```
daysOfWeek = df[df['type']=='story'].groupby(['DayOfWeek']).size()
    daysOfWeek.plot.bar()
    plt.show()
```

![](img/164c3bc1183d35036e81fab76f820076.png)

ä½•æ—¶åœ¨ HackerNews ä¸Šå‘å¸–â€”â€”æŒ‰æ˜ŸæœŸå‡ å‘å¸–

å¤§å¤šæ•°æœ€å¥½çš„æ•…äº‹éƒ½æ˜¯åœ¨å‘¨æœ«å‘å¸ƒçš„ã€‚ä¸çŸ¥ä½•æ•…ï¼Œæˆ‘æœŸå¾…ç€è¿™ä¸€ç‚¹ã€‚ä½†å¯¹æˆ‘æ¥è¯´æœ€æœ‰è¶£çš„äº‹å®æ˜¯ï¼Œæ²¡æœ‰ä¸€ä¸ªæœ€å¥½çš„æ•…äº‹æ˜¯åœ¨å‘¨äºŒæˆ–å‘¨ä¸‰æäº¤çš„ã€‚å‘¨ä¸€ä¼¼ä¹ä¹Ÿæ˜¯éå¸¸ç³Ÿç³•çš„ä¸€å¤©ï¼Œå¾ˆå°‘æœ‰æˆåŠŸçš„æäº¤ã€‚

åœ¨åšè¿™ä¸ªåˆ†æä¹‹å‰ï¼Œæˆ‘è¿˜ä¼šçŒœæµ‹æ˜ŸæœŸäº”ä¼šè·å¾—æœ€å¤šçš„æˆåŠŸæäº¤ã€‚æˆ‘ä¹Ÿä¸çŸ¥é“å…·ä½“ä¸ºä»€ä¹ˆï¼Œåªæ˜¯ç›´è§‰ã€‚

æˆ‘ä»¬è¿˜å¯ä»¥çœ‹çœ‹å¦ä¸€ä¸ªæ—¶é—´ç»´åº¦ï¼Œé‚£å°±æ˜¯ä¸€å¤©ä¸­çš„æŸä¸ªæ—¶åˆ»ã€‚è®©æˆ‘ä»¬ç”»å‡ºåŒæ ·çš„åˆ†å¸ƒã€‚

```
hoursOfDay = df[df['type']=='story'].groupby(['HourOfDay']).size()
    hoursOfDay.plot.bar()
    plt.show()
```

![](img/7a8f6122c34c7f0e947491bbbb1b77db.png)

ä½•æ—¶åœ¨ Hackernews ä¸Šå‘å¸–â€”â€”æŒ‰æ˜ŸæœŸå‡ å‘å¸–

è®©æˆ‘ä»¬çš„æ—¶é—´åˆ—ä»¥ UTC æ—¶é—´æ˜¾ç¤ºï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å¤§å¤šæ•°æˆåŠŸçš„å¸–å­æ˜¯åœ¨ä¸‹åˆæäº¤çš„ï¼Œæœ€å¤§çš„å³°å€¼å‡ºç°åœ¨ UTC æ—¶é—´ä¸‹åˆ 5 ç‚¹ã€‚

æˆ‘æƒ³æ£€æŸ¥çš„å¦ä¸€ä»¶äº‹æ˜¯ï¼Œä¸€ç¯‡å¸–å­è·å¾—çš„ç‚¹æ•°å’Œè¯¥å¸–å­çš„è¯„è®ºæ•°ä¹‹é—´æ˜¯å¦æœ‰ä»»ä½•å…³è”ã€‚å¯¹æˆ‘æ¥è¯´ï¼Œè¿™ä¼¼ä¹å¾ˆæ˜æ˜¾åº”è¯¥æ˜¯çœŸçš„:å¦‚æœäººä»¬å‘ç°ä¸€äº›è¶³å¤Ÿæœ‰è¶£çš„ä¸œè¥¿æ¥æŠ•ç¥¨ï¼Œä»–ä»¬ä¹Ÿå¯èƒ½ä¼šåœ¨é‚£ä¸ªå¸–å­ä¸Šå¼€å§‹è®¨è®ºã€‚

æˆ‘è¿˜åœ¨è¿™ä¸ªå…³è”çŸ©é˜µä¸­åŠ å…¥äº†ä¸€å¤©ä¸­çš„æŸä¸ªå°æ—¶ï¼Œä»¥æ£€æŸ¥ä¸€å¤©ä¸­äººä»¬æ˜¯å¦æœ‰æ›´æƒ³å‚ä¸å¯¹è¯çš„æ—¶å€™ã€‚

```
correlationsData = df[df['type'] =='story'][['score', 'kids_number', 'HourOfDay']]
    print (correlationsData.corr(method='pearson'))
```

![](img/2c028379f2f8bdf02904d32ebc07a84e.png)

ä½•æ—¶åœ¨é»‘å®¢æ–°é—»ä¸Šå‘è¡¨æ–‡ç« â€”â€”ç›¸å…³æ€§

åˆ†æ•°å’Œè¯„è®ºæ•°é‡ä¹‹é—´ä¼¼ä¹æœ‰å¾ˆå¼ºçš„ç›¸å…³æ€§ã€‚æ­£å¦‚æˆ‘æ‰€è¯´çš„ï¼Œæˆ‘å¤šå°‘é¢„æ–™åˆ°äº†è¿™ä¸€ç‚¹ã€‚ä½†æ˜¯æˆ‘å¯¹åˆ†æ•°å’Œæ—¶é—´ä¹‹é—´ä¸å­˜åœ¨çš„ç›¸å…³æ€§æœ‰ç‚¹å¤±æœ›ã€‚

# é—® HN vs ç§€ HN

æ¥ä¸‹æ¥ï¼Œæˆ‘æƒ³çœ‹çœ‹é»‘å®¢æ–°é—»ä¸Šæœ‰å¤šå°‘æœ€æˆåŠŸçš„å¸–å­æ˜¯æé—®/å±•ç¤ºæäº¤çš„ã€‚

```
print ("Count of Ask HN stories: ", df[df['isAsk']==True].shape[0])
    print ("Percentage of Ask HN stories:", 100 * df[df['isAsk']==True].shape[0] / df[df['type']=='story'].shape[0])
    print ("Count of Show HN stories: ", df[df['isShow']==True].shape[0])
    print ("Percentage of Show HN stories:", 100 * df[df['isShow']==True].shape[0] / df[df['type']=='story'].shape[0])
```

ä¼¼ä¹åªæœ‰ 8 ä¸ªå¸–å­é—® HN(å æˆ‘çš„æ•°æ®é›†çš„ 4.30%)ï¼Œ16 ä¸ªå¸–å­æ˜¾ç¤º HN(å æ•°æ®é›†çš„ 8.60%)ã€‚æ¯•ç«Ÿè¿™é‡Œæ²¡ä»€ä¹ˆå¯çœ‹çš„ï¼Œåªæœ‰å‡ ä¸ªæäº¤çš„é—®é¢˜ HN/å±•ç¤ºå¸–å­ã€‚

# é»‘å®¢æ–°é—»ä¸Šçš„äººä»¬è°ˆè®ºè°:å®ä½“è¯†åˆ«å’Œå…³é”®è¯æå–

ä¸‹ä¸€æ­¥æ˜¯å¯¹é»‘å®¢æ–°é—»ä¸Šçš„æœ€ä½³å¸–å­çš„æ ‡é¢˜è¿è¡Œä¸€ä¸ªå®ä½“æå–å™¨ï¼Œå¹¶ä»è¿™é‡Œä¿å­˜ä¸ªäººå’Œç»„ç»‡å®ä½“ï¼Œçœ‹çœ‹æ˜¯å¦æœ‰ä»»ä½•ä¸œè¥¿å†’å‡ºæ¥ã€‚æˆ‘ç”¨ [**spacy è¿›è¡Œå®ä½“æå–**](https://programmerbackpack.com/machine-learning-project-series-building-a-personal-knowledge-management-system-part-1-named-entity-recognition/) ã€‚

æˆ‘å¾—åˆ°äº† 175 ä¸ªå®ä½“çš„åå•ã€‚å› ä¸ºè¿™æ˜¯ä¸€ä¸ªæ²¡æœ‰å‘Šè¯‰æˆ‘ä»¬ä»»ä½•äº‹æƒ…çš„å¤§åˆ—è¡¨ï¼Œæ‰€ä»¥æˆ‘åªæå–äº†å‡ºç°ä¸æ­¢ä¸€æ¬¡çš„å®ä½“ã€‚

```
nlp = spacy.load('en_core_web_sm')
    doc = nlp(". ".join(df[df['type']=='story']['text'].unique()))
    entity_names = [entity.text for entity in doc.ents if entity.label_ in ["PERSON", "ORG"]]
    freq = {entity_names.count(entity): entity  for entity in entity_names}
    for i in sorted (freq.keys()):
        if i > 1:
            print (freq[i])

    # Prints: Amazon, Google, Apple
```

ä¸‰å®¶ç§‘æŠ€å·¨å¤´æ˜¯å”¯ä¸€ä¸‰å®¶åœ¨æœ€ä½³é»‘å®¢æ–°é—»å¸–å­ä¸­å‡ºç°ä¸æ­¢ä¸€æ¬¡çš„å®ä½“ã€‚

æœ€åä¸€æ­¥æ˜¯ [**ä½¿ç”¨ gensim ä»å¸–å­çš„æ ‡é¢˜ä¸­æå–å…³é”®è¯**](https://programmerbackpack.com/machine-learning-project-series-part-2-python-named-entity-recognition/) ã€‚

```
print(keywords(". ".join(df[df['type']=='story']['text'].unique())).split('\n'))
```

è¿™ä¼šäº§ç”Ÿä¸€ä¸ªå·¨å¤§çš„å…³é”®å­—åˆ—è¡¨ï¼Œå…¶ä¸­å‰ 3 ä¸ªæ˜¯:â€œcovidâ€ã€â€œpdfâ€å’Œâ€œvideoâ€ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œå¤§å¤šæ•°å…³é”®è¯éƒ½ä¸â€œç”Ÿæˆå™¨â€ã€â€œåº”ç”¨ç¨‹åºâ€å’Œâ€œæœºå™¨å­¦ä¹ â€æœ‰å…³ã€‚

æˆ‘ä»¬ä¸è¦å¿˜è®°æ·»åŠ æˆ‘ç”¨æ¥ä» Hacker News API ä¸­æå–æ•°æ®çš„ç±»çš„ä»£ç ï¼Œæ­£å¦‚æˆ‘åœ¨æœ¬æ–‡å¼€å§‹æ—¶æ‰¿è¯ºçš„é‚£æ ·ã€‚

```
import csv
import requests
from bs4 import BeautifulSoup BEST_STORIES="beststories.json"class DataFetcher: def __init__(self, baseUrl, dataFile):
        self.baseUrl = baseUrl
        self.dataFile = dataFile def fetchData(self):
        with open(self.dataFile, mode='w') as data_file:
            data_writer = csv.writer(data_file, delimiter=',', quotechar='"', quoting=csv.QUOTE_MINIMAL)
            data_writer.writerow(['id', 'parent', 'kids_number', 'score', 'time', 'text', 'type']) # Best stories
            r = requests.get(url=self.baseUrl + BEST_STORIES)
            bestStoriesIds = r.json()
            count = 0
            for id in bestStoriesIds:
                count = count + 1
                print (str(count) + " / " + str(len(bestStoriesIds)))
                story = requests.get(url=self.baseUrl + "item/" + str(id) + ".json")
                storyJson = story.json()
                data_writer.writerow([storyJson['id'], storyJson['parent'] if "parent" in storyJson else storyJson['id'],
                                      len(storyJson['kids']) if 'kids' in storyJson else 0, storyJson['score'],
                                      storyJson['time'], BeautifulSoup(storyJson['title'], features="html.parser").getText(), storyJson['type']]) # Getc
                if "kids" in storyJson:
                    for kidId in storyJson["kids"]:
                        kid = requests.get(url=self.baseUrl + "item/" + str(kidId) + ".json")
                        kidJson = kid.json()
                        if kidJson and kidJson['type'] == 'comment' and "text" in kidJson:
                            data_writer.writerow(
                                [kidJson['id'], storyJson['id'],
                                 len(kidJson['kids']) if 'kids' in kidJson else 0, 0,
                                 kidJson['time'], BeautifulSoup(kidJson['text'], features="html.parser").getText(), kidJson['type'], '']) print ("Latest stories")
            maxId = requests.get(url=self.baseUrl + "maxitem.json").json()
            countDown = 1000
            while countDown > 0:
                print ("Countdown: ", str(countDown))
                story = requests.get(url=self.baseUrl + "item/" + str(maxId) + ".json")
                storyJson = story.json()
                if storyJson["type"] == "story" and storyJson["score"] > 50:
                    countDown = countDown - 1
                    maxId = maxId - 1
                    data_writer.writerow(
                        [storyJson['id'], storyJson['parent'] if "parent" in storyJson else storyJson['id'],
                         len(storyJson['kids']) if 'kids' in storyJson else 0, storyJson['score'],
                         storyJson['time'], BeautifulSoup(storyJson['title'], features="html.parser").getText(),
                         storyJson['type'],
                         storyJson['url'] if "url" in storyJson else '']) # Getc
                    if "kids" in storyJson:
                        for kidId in storyJson["kids"]:
                            kid = requests.get(url=self.baseUrl + "item/" + str(kidId) + ".json")
                            kidJson = kid.json()
                            if kidJson['type'] == 'comment' and "text" in kidJson:
                                data_writer.writerow(
                                    [kidJson['id'], storyJson['id'],
                                     len(kidJson['kids']) if 'kids' in kidJson else 0, 0,
                                     kidJson['time'], BeautifulSoup(kidJson['text'], features="html.parser").getText(),
                                     kidJson['type'], ''])
```

# ç»“è®º

è¿™å°±æ˜¯æˆ‘å¯¹æœ‰å²ä»¥æ¥æœ€ä½³é»‘å®¢æ–°é—»å¸–å­çš„å°å°åˆ†æã€‚æˆ‘çœŸçš„å¾ˆå–œæ¬¢æ‘†å¼„è¿™äº›æ•°æ®ã€‚æˆ‘å¸Œæœ›ä½ ä¹Ÿå–œæ¬¢è¿™ä¸ªï¼Œå¹¶ä»è¿™ä¸ªé¡¹ç›®ä¸­è·å¾—ä¸€äº›æœ‰æ„ä¹‰çš„è§è§£ã€‚

*æœ¬æ–‡åŸè½½äº* [*ç¨‹åºå‘˜èƒŒåŒ…åšå®¢*](https://programmerbackpack.com/latent-dirichlet-allocation-for-topic-modelling-explained-algorithm-and-python-scikit-learn-implementation/) *ã€‚å¦‚æœä½ æƒ³é˜…è¯»æ›´å¤šè¿™ç±»çš„æ•…äº‹ï¼Œä¸€å®šè¦è®¿é—®è¿™ä¸ªåšå®¢ã€‚*

*éå¸¸æ„Ÿè°¢æ‚¨é˜…è¯»æœ¬æ–‡ï¼æœ‰å…´è¶£äº†è§£æ›´å¤šå—ï¼Ÿåœ¨ Twitter ä¸Šå…³æ³¨æˆ‘ï¼Œåœ°å€æ˜¯*[*@ b _ dmarius*](https://twitter.com/b_dmarius)*ï¼Œæˆ‘ä¼šåœ¨é‚£é‡Œå‘å¸ƒæ¯ä¸€ç¯‡æ–°æ–‡ç« ã€‚*