<html>
<head>
<title>Object Detection Using YOLOv3 on Colab with questions for interview preparation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Colab上的YOLOv3进行对象检测，并为面试准备问题</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/object-detection-using-yolov3-on-colab-5d7d9eef02b3?source=collection_archive---------13-----------------------#2020-04-27">https://towardsdatascience.com/object-detection-using-yolov3-on-colab-5d7d9eef02b3?source=collection_archive---------13-----------------------#2020-04-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/c4eaecd949187e6a85e7e4a6c110400e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yr4pGlx36YtG2jtySKuMrg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">来源:来自Unsplash.com的迈克·格吕贝尔</p></figure><div class=""/><div class=""><h2 id="cbbb" class="pw-subtitle-paragraph kc je jf bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">训练一个模型来识别你拍摄的图像中的不同物体。</h2></div><p id="9d05" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">这个博客将帮助你训练一个可以识别图像中不同物体的模型。观察模型如何在特定条件下比人类表现得更好，这既有趣又令人兴奋。它可以区分汽车和皮卡，即使卡车的尾部在图像中不清晰，就我个人而言，我无法做出这种区别。如果你已经把YOLO作为一个黑箱，这个博客将帮助你理解这个模型及其细微差别。最后，有一些问题可以帮助你衡量你对模型的理解。尽量在评论区回答问题，如果需要答案，尽管问我。</p><p id="332b" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><em class="lq">要求</em>:有互联网连接和谷歌账户的pc。</p><p id="cbd9" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><em class="lq">学习</em>:使用YOLOv3进行物体检测的亲身体验，加深对YOLO算法的理解。</p><p id="28a9" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><em class="lq">设置:</em> <strong class="kw jg"> <em class="lq"> </em> </strong>通过你的google drive设置一个Colab笔记本账号(我的Drive &gt;新&gt;更多&gt;连接更多app&gt;Colab)。要对您电脑中的图像执行对象检测，请安装“驱动器备份和同步”。允许您电脑上的一个文件夹同步到google drive。该文件夹中的文件(图像或视频)将由Colab访问(通过google drive)。</p><p id="f5f1" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">物体检测</strong></p><p id="033e" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">物体检测部分分为9个简单的步骤。它将允许您对您点击的图像应用对象检测。所以让我们先开始物体检测，稍后我会解释它背后的算法(YOLO)。</p><p id="3890" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">第一步</strong>:用google drive连接你的Colab笔记本。一旦您导入并安装了驱动器，您需要点击出现在您的代码下面的链接。您需要通过允许来允许Colab访问驱动器。</p><pre class="lr ls lt lu gt lv lw lx ly aw lz bi"><span id="57f5" class="ma mb jf lw b gy mc md l me mf">from google.colab import drive</span><span id="5d90" class="ma mb jf lw b gy mg md l me mf">drive.mount('/content.gdrive')</span></pre><p id="a83d" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">第二步</strong>:将硬件加速器改为GPU(运行时&gt;更改运行时类型&gt;硬件加速器= GPU)。要确保您已连接到GPU，请键入！nvidia-smi，如果你连接了你应该得到你连接的GPU的详细信息(如下所示)。</p><pre class="lr ls lt lu gt lv lw lx ly aw lz bi"><span id="e703" class="ma mb jf lw b gy mc md l me mf">!nvidia-smi</span></pre><figure class="lr ls lt lu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mh"><img src="../Images/4fc6b0807556041724487ef7ba816835.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*871qQacaHK1gJ7a0m7QcTQ.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">检查与GPU的连接</p></figure><p id="b827" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg"> Step3: </strong> Darknet是由Joseph Redmon编写的开源神经网络。是用C和CUDA写的。它同时支持CPU和GPU计算。暗网的官方实现可在:<a class="ae mi" href="https://pjreddie.com/darknet/" rel="noopener ugc nofollow" target="_blank">https://pjreddie.com/darknet/</a>获得。我们将使用AlexyAB/darknet上的darknet的稍微修改版本。该神经网络框架可以用于使用YOLO的对象检测。</p><pre class="lr ls lt lu gt lv lw lx ly aw lz bi"><span id="e992" class="ma mb jf lw b gy mc md l me mf">#clone darknet repository</span><span id="5a49" class="ma mb jf lw b gy mg md l me mf">import os</span><span id="bbd5" class="ma mb jf lw b gy mg md l me mf">os.environ['PATH'] += ':/usr/local/cuda/bin'</span><span id="aad3" class="ma mb jf lw b gy mg md l me mf">!rm -fr darknet</span><span id="5ea9" class="ma mb jf lw b gy mg md l me mf">!git clone https://github.com/AlexeyAB/darknet</span></pre><p id="c3db" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">步骤4: </strong>使用！pwd。我们应该在/content/darknet文件夹中。或者转到darknet文件夹(%cd /darknet)。在这个文件夹中，我们使用流编辑器(sed)编辑GPU和OpenCV的make文件(在就地模式下，即sed -i)。我们把GPU=0到GPU =1的所有实例都改成，启用GPU和OpenCV。</p><pre class="lr ls lt lu gt lv lw lx ly aw lz bi"><span id="04fc" class="ma mb jf lw b gy mc md l me mf">#go to the darknet folder, edit and remake Makefiles of GPU and OPENCV</span><span id="e6fa" class="ma mb jf lw b gy mg md l me mf">!sed -i 's/GPU=0/GPU=1/g' Makefile</span><span id="fc58" class="ma mb jf lw b gy mg md l me mf">!sed -i 's/OPENCV=0/OPENCV=1/g' Makefile</span><span id="d60b" class="ma mb jf lw b gy mg md l me mf">!make</span></pre><p id="4354" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">第五步:</strong>加载预先训练好的YOLO物体检测权值。我们从pjreddie.com得到YOLOv3的预训练重量。这个网站属于约瑟夫·雷德蒙，他是YOLO和黑暗网的幕后黑手。</p><pre class="lr ls lt lu gt lv lw lx ly aw lz bi"><span id="02fe" class="ma mb jf lw b gy mc md l me mf"># get yolov3 weights</span><span id="780f" class="ma mb jf lw b gy mg md l me mf">!wget https://pjreddie.com/media/files/yolov3.weights</span><span id="1e98" class="ma mb jf lw b gy mg md l me mf">!chmod a+x ./darknet</span></pre><p id="6c57" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">第六步:</strong>确保你在正确的目录下(/content/darknet)使用！pwd。如果是，则安装所需的软件包。关于完整的列表，我鼓励你看看github 上<a class="ae mi" href="https://github.com/DrManishSharma/YOLO_Obj_Detection/blob/master/Yolo_Obj_Detection_Using_Colab.ipynb" rel="noopener ugc nofollow" target="_blank">我的jupyter文件。</a></p><pre class="lr ls lt lu gt lv lw lx ly aw lz bi"><span id="7042" class="ma mb jf lw b gy mc md l me mf">!apt install ffmpeg libopencv-dev libgtk-3-dev python-numpy python3-numpy libdc1394-22 libdc1394-22-dev libjpeg-dev libtiff5-dev libavcodec-dev libavformat-dev libswscale-dev libxine2-dev libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libv4l-dev libtbb-dev qtbase5-dev libfaac-dev libmp3lame-dev libopencore-amrnb-dev libopencore-amrwb-dev libtheora-dev libvorbis-dev libxvidcore-dev x264 v4l-utils unzip</span></pre><p id="a556" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">第七步:</strong>将镜像从你的硬盘加载到Colab，并在上面运行YOLO。您可以将pc中的任何图像传输到您在步骤1中与google drive共享的文件夹中。该图像将出现在驱动器的同一文件夹中。在我的例子中，我将文件夹命名为“darknet”，图像的名称为“test2.jpg”。文件夹的地址将是:/content . g Drive/My Drive/darknet/test 2 . jpg，但是由于地址路径中不允许有空格，所以您可以使用:/content . g Drive/My \ Drive/darknet/test 2 . jpg。</p><pre class="lr ls lt lu gt lv lw lx ly aw lz bi"><span id="bbe6" class="ma mb jf lw b gy mc md l me mf">!./darknet detect cfg/yolov3.cfg yolov3.weights /content.gdrive/My\ Drive/darknet/test2.jpg</span></pre><p id="0a33" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">你需要OpenCV和matplotlib来查看你的结果。如果你正在进行这一步，首先祝贺你已经使用你的图像运行了你的第一个YOLO物体探测。</p><pre class="lr ls lt lu gt lv lw lx ly aw lz bi"><span id="298e" class="ma mb jf lw b gy mc md l me mf">import cv2</span><span id="3d51" class="ma mb jf lw b gy mg md l me mf">import matplotlib.pyplot as plt</span><span id="a575" class="ma mb jf lw b gy mg md l me mf">import os.path</span><span id="c553" class="ma mb jf lw b gy mg md l me mf">fig,ax = plt.subplots()</span><span id="db12" class="ma mb jf lw b gy mg md l me mf">ax.tick_params(labelbottom="off",bottom="off")</span><span id="549a" class="ma mb jf lw b gy mg md l me mf">ax.tick_params(labelleft="off",left="off")</span><span id="6809" class="ma mb jf lw b gy mg md l me mf">ax.set_xticklabels([])</span><span id="4af4" class="ma mb jf lw b gy mg md l me mf">ax.axis('off')</span><span id="fff1" class="ma mb jf lw b gy mg md l me mf">file = './predictions.jpg'</span><span id="1fba" class="ma mb jf lw b gy mg md l me mf">if os.path.exists(file):</span><span id="57ff" class="ma mb jf lw b gy mg md l me mf">img = cv2.imread(file)</span><span id="d829" class="ma mb jf lw b gy mg md l me mf">show_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><span id="a22f" class="ma mb jf lw b gy mg md l me mf">#show_img(show_img)</span><span id="2adf" class="ma mb jf lw b gy mg md l me mf">plt.imshow(show_img)</span><span id="58f0" class="ma mb jf lw b gy mg md l me mf">plt.show()</span><span id="e0d5" class="ma mb jf lw b gy mg md l me mf">#cv2.imshow(img)</span></pre><p id="7803" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">第九步:</strong>结果分析。在这里，你可以看到算法可以正确地检测出婴儿是人、手机还是发刷(牙刷)。而其他几件物品(吹风机、小钱包、化妆品)无法被检测到。你能猜到原因吗？也许你应该检查一下我们所用的重物是在哪个物体上训练的。</p><figure class="lr ls lt lu gt is gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/3db109bf661fc67cecdef1195d2b3286.png" data-original-src="https://miro.medium.com/v2/resize:fit:1088/format:webp/1*n20cROT-rowBmv1nt_PzGQ.jpeg"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">结果分析(来源:作者照片)</p></figure><p id="f882" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在这里，我已经提出了一个练习，以帮助新用户开始使用他们的电脑对象检测。此外，用户可以使用他们的图像，这将进一步增加他们的乐趣。一旦你完成了这个有趣的部分，了解YOLO如何探测到这些物体将会很有趣。</p></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><h1 id="58c0" class="mr mb jf bd ms mt mu mv mw mx my mz na kl nb km nc ko nd kp ne kr nf ks ng nh bi translated"><strong class="ak">关于YOLOv3的信息</strong></h1><p id="7e66" class="pw-post-body-paragraph ku kv jf kw b kx ni kg kz la nj kj lc ld nk lf lg lh nl lj lk ll nm ln lo lp ij bi translated">让我们试着了解算法是如何工作的。</p><p id="6d85" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">YOLO ( <a class="ae mi" href="https://pjreddie.com/media/files/papers/YOLOv3.pdf" rel="noopener ugc nofollow" target="_blank">原文链接</a> ): <em class="lq">你只看一次</em>是物体探测网。它对物体进行定位和分类。它在一个步骤中完成这两项任务。darknet-53神经网络中YOLO的主干，网络中有53个卷积层用于特征提取。</p><p id="9630" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">YOLO把输入图像分成m×m的网格。网格的每个单元包含一些(B)定位框来定位对象。对于一个物体，物体中心所在的细胞负责检测物体。</p><p id="8b9c" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">让我们试着去理解输出向量，它将给出这个算法不同方面的见解。输出向量将由B * (5 + C)个元素组成。b是每个单元中存在的锚盒的数量。每个框将给出一个概率元素，显示对象出现在单元中的概率，4个元素描述边界框(2个用于中心坐标bx，by，另外两个用于描述框的高度和宽度bh和bw)。c是类的数量。如果有6个类，那么每个盒子将有11个元素，如果有3个盒子，那么在输出中总共将有33个元素。</p><p id="861a" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">YOLOv3是目前最快的对象检测算法之一。速度是以准确性为代价的。与快速R-CNN相比，它在对象定位中产生较高的误差，但是与后者相比，它产生较小的背景误差。</p><p id="63b3" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">为了检测每个单元中的多个对象，它在每个单元中使用多个锚定框。当然，这些锚会有不同的尺寸。假设一个是更宽的矩形(纵向)，另一个是更长的矩形(横向)。要提到的另一个方面是使用标准的非最大抑制来消除每个对象的多个边界框。</p><h1 id="df38" class="mr mb jf bd ms mt nn mv mw mx no mz na kl np km nc ko nq kp ne kr nr ks ng nh bi translated">面试问题</h1><p id="7407" class="pw-post-body-paragraph ku kv jf kw b kx ni kg kz la nj kj lc ld nk lf lg lh nl lj lk ll nm ln lo lp ij bi translated">你可以在评论区评论你的答案，或者问我，如果你想让我回答这些问题的话。如果你能回答你知道答案的问题，我将非常感激，其他读者肯定会因为你的评论而受益。</p><p id="d67a" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">Q1。一个n×n的图像与一个f×f大小的滤波器、p的填充和s的步幅进行卷积，输出的大小是多少？一定要检查如果没有填充并且f &amp; s都等于2会发生什么。</p><p id="f555" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">Q2。为什么在对象检测神经网络中需要完全连接的层？</p><p id="b0ab" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">Q3。列出数据扩充的策略/方法。</p><p id="678c" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">Q4。在YOLO，定位框和边框有什么区别？</p><p id="70b2" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">Q5。如何计算平均精度？</p><p id="ae93" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">Q6。解释NMS或非最大值抑制的概念？</p><p id="4eea" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">Q7。YOLO损失函数的不同组成部分是什么？</p><p id="306a" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">要访问完整的jupyter文件:<a class="ae mi" href="https://github.com/DrManishSharma/YOLO_Obj_Detection/blob/master/Yolo_Obj_Detection_Using_Colab.ipynb" rel="noopener ugc nofollow" target="_blank">点击这里</a>。</p><p id="b2a7" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我希望这个博客给你全面的YOLO实践，并帮助你开始你的目标探测之旅。如果你想讨论更多，请随意评论。</p></div></div>    
</body>
</html>