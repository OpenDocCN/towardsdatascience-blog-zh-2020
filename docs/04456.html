<html>
<head>
<title>How I taught my computer to play Spot it! using OpenCV and Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我是如何教我的电脑玩Spot it的！使用OpenCV和深度学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-i-learned-my-computer-to-play-spot-it-using-opencv-and-deep-learning-ad1f017a3ec3?source=collection_archive---------25-----------------------#2020-04-21">https://towardsdatascience.com/how-i-learned-my-computer-to-play-spot-it-using-opencv-and-deep-learning-ad1f017a3ec3?source=collection_archive---------25-----------------------#2020-04-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a890" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一些有趣的计算机视觉和CNN的小数据集。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/08edbbcda44153bcd21533eccc73c735.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J2Ty7vX-wJX2OXdfOnjYzg.jpeg"/></div></div></figure><p id="92ae" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我的一个爱好是玩棋盘游戏，因为我对CNN有所了解，所以我决定开发一个可以在纸牌游戏中击败人类的应用程序。我想用我自己的数据集从头构建模型，看看用一个小数据集从头构建的模型性能如何。我选择从一个不太难的游戏开始，<em class="lq"> Spot it！</em>(又名<em class="lq">多布尔</em>)。</p><p id="e2f6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在你不知道的情况下<em class="lq">点它！然而，下面是一个简短的游戏解释:<em class="lq">发现它！</em>是一个简单的模式识别游戏，玩家试图找到两张卡片上显示的图像。原<em class="lq">中的每一张卡都点它！</em>有八种不同的符号，每张牌上的符号大小不同。任何两张牌都有一个相同的符号。如果你是第一个找到那个符号的人，你就赢得这张卡。当55张牌用完时，谁收集的牌最多，谁就赢。</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/bb74d6b6b9a445cda6b88011c9621c30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*Fln7UnQHl2mMZ9R5.jpg"/></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">自己试试:上面显示的卡片上的共同符号是什么？</p></figure></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="84f6" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated"><strong class="ak">从哪里开始？</strong></h1><p id="3de7" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">任何数据科学问题的第一步都是收集数据。我用手机拍了几张，每张卡六张。总共有330张照片。其中四个如下所示。你可能会想:这足以构建一个完美的卷积神经网络吗？我会回来的！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/2da187c23385aeccd72a6a88bee1ef87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WEFPX0UqRwd2-adHCq-zjw.jpeg"/></div></div></figure><h1 id="5872" class="md me it bd mf mg nb mi mj mk nc mm mn jz nd ka mp kc ne kd mr kf nf kg mt mu bi translated">处理图像</h1><p id="ae81" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">好了，我们有数据了，下一步是什么？为了成功，这可能是最重要的部分:处理图像。我们需要提取每张卡片上显示的符号。这里有一些困难。你可以在上面的图片中看到，一些符号可能更难提取:雪人和鬼魂(第三张图片)和冰屋(第四张图片)的颜色很浅，污渍(第二张图片)和感叹号(第四张图片)存在于多个部分。为了处理浅色符号，我们给图像增加了对比度。之后，我们调整大小并保存图像。</p><h2 id="dd60" class="ng me it bd mf nh ni dn mj nj nk dp mn ld nl nm mp lh nn no mr ll np nq mt nr bi translated">添加对比度</h2><p id="e3f3" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">我们使用Lab颜色空间来增加对比度。l代表亮度，a是范围从绿色到品红色的颜色分量，b是范围从蓝色到黄色的颜色分量。我们可以用<a class="ae ns" href="https://docs.opencv.org/master/" rel="noopener ugc nofollow" target="_blank"> OpenCV </a>轻松提取这些组件:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="d1f0" class="ng me it nu b gy ny nz l oa ob">import cv2<br/>import imutils</span><span id="f356" class="ng me it nu b gy oc nz l oa ob">imgname = 'picture1'</span><span id="dd9b" class="ng me it nu b gy oc nz l oa ob">image = cv2.imread(f’{imgname}.jpg’)<br/>lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)<br/>l, a, b = cv2.split(lab)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/aa3d8cc57d83f1f179224ffe0ae03baf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gccuhu4XlQb9pTdRqkItuA.jpeg"/></div></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">从左至右:原始图像、光分量、a分量和b分量</p></figure><p id="20ea" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在，我们将对比添加到灯光部分，将这些部分合并在一起，并将图像转换回正常状态:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="a8e0" class="ng me it nu b gy ny nz l oa ob">clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))<br/>cl = clahe.apply(l)<br/>limg = cv2.merge((cl,a,b))<br/>final = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/ea042cfb84a28b9913ebb58dcaf21352.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wmyt9Vm0Knsiqnp28ze_TQ.jpeg"/></div></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">从左到右:原始图像，光组件，增加对比度，转换回RGB</p></figure><h2 id="82cf" class="ng me it bd mf nh ni dn mj nj nk dp mn ld nl nm mp lh nn no mr ll np nq mt nr bi translated">调整大小</h2><p id="00b5" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">然后我们调整大小并保存图像:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="9f97" class="ng me it nu b gy ny nz l oa ob">resized = cv2.resize(final, (800, 800))</span><span id="8929" class="ng me it nu b gy oc nz l oa ob"># save the image<br/>cv2.imwrite(f'{imgname}processed.jpg', blurred)</span></pre><p id="f495" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">搞定了。</p><h1 id="ce13" class="md me it bd mf mg nb mi mj mk nc mm mn jz nd ka mp kc ne kd mr kf nf kg mt mu bi translated"><strong class="ak">检测卡片和符号</strong></h1><p id="e2ca" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">现在图像被处理了，我们可以从检测图像上的卡片开始。使用OpenCV可以找到外部轮廓。然后我们需要将图像转换为灰度，选择一个阈值(本例中为190)来创建一个黑白图像，并找到轮廓。在代码中:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="4cd3" class="ng me it nu b gy ny nz l oa ob">image = cv2.imread(f’{imgname}processed.jpg’)<br/>gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)<br/>thresh = cv2.threshold(gray, 190, 255, cv2.THRESH_BINARY)[1]</span><span id="2dcb" class="ng me it nu b gy oc nz l oa ob"># find contours<br/>cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)<br/>cnts = imutils.grab_contours(cnts)</span><span id="2863" class="ng me it nu b gy oc nz l oa ob">output = image.copy()</span><span id="0e33" class="ng me it nu b gy oc nz l oa ob"># draw contours on image<br/>for c in cnts:<br/>    cv2.drawContours(output, [c], -1, (255, 0, 0), 3)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/80b4f176119d5e2fef9ac4195578cf0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MQ04IRFWEcX86-dJHmHqnQ.jpeg"/></div></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">经过处理的图像，转换为灰度，设定阈值，并带有外部轮廓</p></figure><p id="1fa3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果我们把外轮廓按面积排序，可以找到面积最大的轮廓:这就是卡片。我们可以创建一个白色背景来提取符号。</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="d822" class="ng me it nu b gy ny nz l oa ob"># sort by area, grab the biggest one<br/>cnts = sorted(cnts, key=cv2.contourArea, reverse=True)[0]</span><span id="196f" class="ng me it nu b gy oc nz l oa ob"># create mask with the biggest contour<br/>mask = np.zeros(gray.shape,np.uint8)<br/>mask = cv2.drawContours(mask, [cnts], -1, 255, cv2.FILLED)</span><span id="b19f" class="ng me it nu b gy oc nz l oa ob"># card in foreground<br/>fg_masked = cv2.bitwise_and(image, image, mask=mask)</span><span id="bb02" class="ng me it nu b gy oc nz l oa ob"># white background (use inverted mask)<br/>mask = cv2.bitwise_not(mask)<br/>bk = np.full(image.shape, 255, dtype=np.uint8)<br/>bk_masked = cv2.bitwise_and(bk, bk, mask=mask)</span><span id="2b15" class="ng me it nu b gy oc nz l oa ob"># combine back- and foreground<br/>final = cv2.bitwise_or(fg_masked, bk_masked)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/b75b66d57ff455efcf52ca639712dca0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nSO4FSElCjEq_nTWVjnDog.jpeg"/></div></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">遮罩、背景、前景、组合</p></figure><p id="1a01" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在是符号检测时间！我们可以利用最后一幅图像再次检测外部轮廓，这些轮廓就是符号。如果我们在每个符号周围创建一个正方形，我们可以提取这个区域。代码有点长:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="1111" class="ng me it nu b gy ny nz l oa ob"># just like before (with detecting the card)<br/>gray = cv2.cvtColor(final, cv2.COLOR_RGB2GRAY)<br/>thresh = cv2.threshold(gray, 195, 255, cv2.THRESH_BINARY)[1]<br/>thresh = cv2.bitwise_not(thresh)</span><span id="8527" class="ng me it nu b gy oc nz l oa ob">cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)<br/>cnts = imutils.grab_contours(cnts)<br/>cnts = sorted(cnts, key=cv2.contourArea, reverse=True)[:10]</span><span id="1f84" class="ng me it nu b gy oc nz l oa ob"># handle each contour<br/>i = 0<br/>for c in cnts:<br/>    if cv2.contourArea(c) &gt; 1000:<br/>        # draw mask, keep contour<br/>        mask = np.zeros(gray.shape, np.uint8)<br/>        mask = cv2.drawContours(mask, [c], -1, 255, cv2.FILLED)</span><span id="11c9" class="ng me it nu b gy oc nz l oa ob">        # white background<br/>        fg_masked = cv2.bitwise_and(image, image, mask=mask)<br/>        mask = cv2.bitwise_not(mask)<br/>        bk = np.full(image.shape, 255, dtype=np.uint8)<br/>        bk_masked = cv2.bitwise_and(bk, bk, mask=mask)<br/>        finalcont = cv2.bitwise_or(fg_masked, bk_masked)</span><span id="f922" class="ng me it nu b gy oc nz l oa ob">        # bounding rectangle around contour<br/>        output = finalcont.copy()<br/>        x,y,w,h = cv2.boundingRect(c)<br/>        # squares io rectangles<br/>        if w &lt; h:<br/>            x += int((w-h)/2)<br/>            w = h<br/>        else:<br/>            y += int((h-w)/2)<br/>            h = w</span><span id="1b4b" class="ng me it nu b gy oc nz l oa ob">        # take out the square with the symbol<br/>        roi = finalcont[y:y+h, x:x+w]<br/>        roi = cv2.resize(roi, (400,400))</span><span id="89a5" class="ng me it nu b gy oc nz l oa ob">        # save the symbol<br/>        cv2.imwrite(f"{imgname}_icon{i}.jpg", roi)<br/>        i += 1</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/aa378a0bd5a5dc5a187099baac36a063.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7iLK_RxM1GAv5nGVenYktQ.jpeg"/></div></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">阈值图像、找到的轮廓、幽灵符号和心形符号(用遮罩提取的符号)</p></figure><h1 id="9a0b" class="md me it bd mf mg nb mi mj mk nc mm mn jz nd ka mp kc ne kd mr kf nf kg mt mu bi translated">分类符号</h1><p id="d9b9" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">现在到了无聊的部分！是时候对符号进行排序了。我们需要一个训练，测试和验证目录，每个目录包含57个目录(我们有57个不同的符号)。文件夹结构如下所示:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="81f6" class="ng me it nu b gy ny nz l oa ob">symbols<br/> ├── test<br/> │   ├── anchor<br/> │   ├── apple<br/> │   │   ...<br/> │   └── zebra<br/> ├── train<br/> │   ├── anchor<br/> │   ├── apple<br/> │   │   ...<br/> │   └── zebra<br/> └── validation<br/>     ├── anchor<br/>     ├── apple<br/>     │   ...<br/>     └── zebra</span></pre><p id="525f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">将提取的符号(超过2500个)放入正确的目录需要一些时间！我有创建子文件夹的代码，在<a class="ae ns" href="https://github.com/henniedeharder/spotit/tree/master/DeepLearningSpotIt" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上设置测试和验证。也许下次用聚类算法排序会更好…</p><h1 id="8edd" class="md me it bd mf mg nb mi mj mk nc mm mn jz nd ka mp kc ne kd mr kf nf kg mt mu bi translated">训练卷积神经网络</h1><p id="4306" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">无聊的部分之后是有趣的部分。让我们建立并训练一个CNN。你可以在<a class="ae ns" href="https://medium.com/technologymadeeasy/the-best-explanation-of-convolutional-neural-networks-on-the-internet-fbb8b1ad5df8" rel="noopener">这个帖子</a>中找到关于CNN的信息。</p><h2 id="7c93" class="ng me it bd mf nh ni dn mj nj nk dp mn ld nl nm mp lh nn no mr ll np nq mt nr bi translated">模型架构</h2><p id="c921" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">这是一个多类、单标签的分类问题。我们希望每个符号都有一个标签。这就是为什么有必要选择具有57个节点和分类交叉熵损失函数的最后一层激活softmax。</p><p id="f5a0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最终模型的架构如下所示:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="7a18" class="ng me it nu b gy ny nz l oa ob"># imports<br/>from keras import layers<br/>from keras import models<br/>from keras import optimizers<br/>from keras.preprocessing.image import ImageDataGenerator<br/>import matplotlib.pyplot as plt</span><span id="d999" class="ng me it nu b gy oc nz l oa ob"># layers, activation layer with 57 nodes (one for every symbol)<br/>model = models.Sequential()<br/>model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(400, 400, 3)))<br/>model.add(layers.MaxPooling2D((2, 2)))  <br/>model.add(layers.Conv2D(64, (3, 3), activation='relu'))<br/>model.add(layers.MaxPooling2D((2, 2)))<br/>model.add(layers.Conv2D(128, (3, 3), activation='relu'))<br/>model.add(layers.MaxPooling2D((2, 2)))<br/>model.add(layers.Conv2D(256, (3, 3), activation='relu'))<br/>model.add(layers.MaxPooling2D((2, 2)))<br/>model.add(layers.Conv2D(256, (3, 3), activation='relu'))<br/>model.add(layers.MaxPooling2D((2, 2)))<br/>model.add(layers.Conv2D(128, (3, 3), activation='relu'))<br/>model.add(layers.Flatten())<br/>model.add(layers.Dropout(0.5)) <br/>model.add(layers.Dense(512, activation='relu'))<br/>model.add(layers.Dense(57, activation='softmax'))</span><span id="7a27" class="ng me it nu b gy oc nz l oa ob">model.compile(loss='categorical_crossentropy',       optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])</span></pre><h2 id="977f" class="ng me it bd mf nh ni dn mj nj nk dp mn ld nl nm mp lh nn no mr ll np nq mt nr bi translated">数据扩充</h2><p id="3d9a" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">为了获得更好的性能，我使用了数据增强。数据扩充是增加输入数据的数量和多样性的过程。这可以通过旋转、移动、缩放、裁剪和翻转现有图像来实现。使用Keras很容易执行数据扩充:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="9735" class="ng me it nu b gy ny nz l oa ob"># specify the directories<br/>train_dir = 'symbols/train'<br/>validation_dir = 'symbols/validation'<br/>test_dir = 'symbols/test'</span><span id="05a7" class="ng me it nu b gy oc nz l oa ob"># data augmentation with ImageDataGenerator from Keras (only train)<br/>train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=40, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.1, zoom_range=0.1, horizontal_flip=True, vertical_flip=True)<br/>test_datagen = ImageDataGenerator(rescale=1./255)</span><span id="ff94" class="ng me it nu b gy oc nz l oa ob">train_generator = train_datagen.flow_from_directory(train_dir, target_size=(400,400), batch_size=20, class_mode='categorical')<br/>validation_generator = test_datagen.flow_from_directory(validation_dir, target_size=(400,400), batch_size=20, class_mode='categorical')</span></pre><p id="06f3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你想知道，一个增强的幽灵看起来像这样:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/732e444ee233a6052e40eee10b896563.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lBDDvyyIkJ7KtyHoL_OESg.jpeg"/></div></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">左侧为原始重影，其他图像上为增强重影</p></figure><h2 id="ef6a" class="ng me it bd mf nh ni dn mj nj nk dp mn ld nl nm mp lh nn no mr ll np nq mt nr bi translated">符合模型</h2><p id="999e" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">让我们拟合模型，保存它以用于预测，并检查结果。</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="fdff" class="ng me it nu b gy ny nz l oa ob">history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=100, validation_data=validation_generator, validation_steps=50)</span><span id="305b" class="ng me it nu b gy oc nz l oa ob"># don't forget to save your model!<br/>model.save('models/model.h5')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/1ccc5116b2c7449f782f0359a26df613.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*fyARhPjEb-PZWNwMJavL5g.gif"/></div></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">完美的预测！</p></figure><h2 id="6f50" class="ng me it bd mf nh ni dn mj nj nk dp mn ld nl nm mp lh nn no mr ll np nq mt nr bi translated">结果</h2><p id="d508" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">我训练的基线模型没有数据增加、丢失，并且层数较少。该模型给出了以下结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/608ed7a9fbc6ac34c29791ef11b84ec6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q1NuV2WW7jNs8hwiP0_ZWQ.jpeg"/></div></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">基线模型的结果</p></figure><p id="36db" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你可以清楚地看到这个模型是过度拟合。最终模型的结果(来自前面段落中的代码)要好得多。在下图中，您可以看到训练和验证集的准确性和损失。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/4373cf8cb0f08aaf67a3ef207f8d6520.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ciaJyZcbL5t4j3_RVMqEEA.jpeg"/></div></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">最终模型的结果</p></figure><p id="da68" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在测试中，这个模型只犯了一个错误:它预测了一颗炸弹的下落。我决定坚持使用这个模型，在测试集上的准确率是0.995。</p><h2 id="1aac" class="ng me it bd mf nh ni dn mj nj nk dp mn ld nl nm mp lh nn no mr ll np nq mt nr bi translated">预测两张卡片的共同符号</h2><p id="d5a6" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">现在有可能预测两张卡片上的共同符号。我们可以使用两幅图像，分别对每幅图像进行预测，并使用交集来查看两张卡都有什么符号。这给出了三种可能性:</p><ul class=""><li id="ee19" class="oh oi it kw b kx ky la lb ld oj lh ok ll ol lp om on oo op bi translated">预测时出错:找不到公共符号。</li><li id="a468" class="oh oi it kw b kx oq la or ld os lh ot ll ou lp om on oo op bi translated">十字路口只有一个符号(可能是错的，也可能是对的)。</li><li id="3f71" class="oh oi it kw b kx oq la or ld os lh ot ll ou lp om on oo op bi translated">十字路口不止一个符号。在这种情况下，我选择了概率最高的符号(两个预测的平均值)。</li></ul><p id="fb0e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">代码在<a class="ae ns" href="https://github.com/henniedeharder/spotit/tree/master/DeepLearningSpotIt" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上，用于预测目录main.py文件中两个图像的所有组合。</p><p id="52a5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">一些结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/1a3d76544b180502028025793f037979.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*_k1VXlWaJwirHPuCPWLXmw.gif"/></div></div></figure></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="e15f" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">结论</h1><p id="5504" class="pw-post-body-paragraph ku kv it kw b kx mv ju kz la mw jx lc ld mx lf lg lh my lj lk ll mz ln lo lp im bi translated">这是一个完美的表演模式吗？可惜没有！当我给卡片拍新照片并让模型预测共同的符号时，它对雪人有一些问题。有时它预测一只眼睛或一只斑马是雪人！这给出了一些奇怪的结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/80ca0f3fb2bdabfc65de0fbaa933ca02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mXG0qIYIER9mgYMxLmKGvQ.jpeg"/></div></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">雪人？在哪里？</p></figure><p id="655a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这个模型比人类好吗？看情况:人类可以做的很完美，但是模型更快！我给计算机计时:我给它55副牌，并询问两张牌的每种组合的共同符号。总共有1485种组合。这花费了计算机不到140秒的时间。计算机犯了一些错误，但就速度而言，它肯定会打败任何人类！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/f8e358de0c94038ced311d5b36f50842.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/1*Vqlcc8JOcYlDERRqlOV6JA.png"/></div></figure><p id="0473" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我不认为建立一个100%的表演模型真的很难。例如，这可以通过使用迁移学习来完成。为了理解模型在做什么，我们可以将测试图像的层可视化。下次要尝试的东西！</p><p id="f79e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我希望你喜欢阅读这篇文章！❤</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h2 id="e203" class="ng me it bd mf nh ni dn mj nj nk dp mn ld nl nm mp lh nn no mr ll np nq mt nr bi translated">有关系的</h2><div class="ow ox gp gr oy oz"><a rel="noopener follow" target="_blank" href="/solving-mtvs-are-you-the-one-is-it-possible-to-never-lose-992488277099"><div class="pa ab fo"><div class="pb ab pc cl cj pd"><h2 class="bd iu gy z fp pe fr fs pf fu fw is bi translated">解决MTV的《非诚勿扰》:有可能永远不输吗？</h2><div class="pg l"><h3 class="bd b gy z fp pe fr fs pf fu fw dk translated">爱情游戏还是逻辑游戏？</h3></div><div class="ph l"><p class="bd b dl z fp pe fr fs pf fu fw dk translated">towardsdatascience.com</p></div></div><div class="pi l"><div class="pj l pk pl pm pi pn ks oz"/></div></div></a></div><div class="ow ox gp gr oy oz"><a rel="noopener follow" target="_blank" href="/solving-nonograms-with-120-lines-of-code-a7c6e0f627e4"><div class="pa ab fo"><div class="pb ab pc cl cj pd"><h2 class="bd iu gy z fp pe fr fs pf fu fw is bi translated">用120行代码求解诺诺姆图</h2><div class="pg l"><h3 class="bd b gy z fp pe fr fs pf fu fw dk translated">拼图，组合和解决方案gif。</h3></div><div class="ph l"><p class="bd b dl z fp pe fr fs pf fu fw dk translated">towardsdatascience.com</p></div></div><div class="pi l"><div class="po l pk pl pm pi pn ks oz"/></div></div></a></div><div class="ow ox gp gr oy oz"><a rel="noopener follow" target="_blank" href="/snake-played-by-a-deep-reinforcement-learning-agent-53f2c4331d36"><div class="pa ab fo"><div class="pb ab pc cl cj pd"><h2 class="bd iu gy z fp pe fr fs pf fu fw is bi translated">深度强化学习代理扮演的Snake</h2><div class="pg l"><h3 class="bd b gy z fp pe fr fs pf fu fw dk translated">犯了大错</h3></div><div class="ph l"><p class="bd b dl z fp pe fr fs pf fu fw dk translated">towardsdatascience.com</p></div></div><div class="pi l"><div class="pp l pk pl pm pi pn ks oz"/></div></div></a></div></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="13cb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><em class="lq">别忘了</em> <a class="ae ns" href="https://hennie-de-harder.medium.com/subscribe" rel="noopener"> <em class="lq">订阅</em> </a> <em class="lq">如果你想在我发表新文章时收到电子邮件。</em></p></div></div>    
</body>
</html>