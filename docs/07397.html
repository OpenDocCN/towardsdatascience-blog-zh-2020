<html>
<head>
<title>[RecSys] Implementation on Variants of SVD-Based Recommender System</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于奇异值分解的推荐系统变体的实现</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/recsys-implementation-on-variants-of-svd-based-recommender-system-a3dc1d059c83?source=collection_archive---------35-----------------------#2020-06-04">https://towardsdatascience.com/recsys-implementation-on-variants-of-svd-based-recommender-system-a3dc1d059c83?source=collection_archive---------35-----------------------#2020-06-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/1325afa6b0f1265d68c92031ab6dd97c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5IGGXxlsy5FMeGaa"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">由<a class="ae jg" href="https://unsplash.com/@roman_lazygeek?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">罗马法师</a>在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><div class=""/><div class=""><h2 id="9b8c" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">模型包括 lightFM、RDF SVD 和神经协同过滤</h2></div><p id="46f1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一般来说，推荐算法的发展分为三个领域:基于内容的模型、协同过滤模型和基于深度神经网络的模型。在本文中，我们将重点讨论 CF，尤其是基于 SVD 的算法。我们不仅要练习建立基于奇异值分解的模型，还要练习它的变体，比如一个正则化模型和另一个采用神经网络的模型。</p><p id="3dcc" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">另外，基于 SVD 的分类模型只考虑了用户/iterm 交互。它既不考虑用户与项目交互时的上下文信息(例如:用户在地铁列车上浏览手机上的产品列表)，也不利用隐藏在连续动作中的含义。然而，包含这些信息会使我们的模型更加复杂，因此我们不会在本文中讨论这些问题。如果你对应用这些技术感兴趣，欢迎查看<a class="ae jg" href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf" rel="noopener ugc nofollow" target="_blank"> YouTube(2016) </a>和<a class="ae jg" href="https://arxiv.org/pdf/1703.04247.pdf" rel="noopener ugc nofollow" target="_blank">华为(2017) </a>发表的论文。这里也有相关的 git repos 供你参考——实现<a class="ae jg" href="https://github.com/sladesha/deep_learning/tree/master/YoutubeNetwork" rel="noopener ugc nofollow" target="_blank"> YouTube </a>和<a class="ae jg" href="https://github.com/NELSONZHAO/zhihu/tree/master/ctr_models" rel="noopener ugc nofollow" target="_blank">华为</a>。</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="bdae" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">熟悉数据集</h1><p id="994f" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">我们这里使用的数据集来自作者 moorissa 的<a class="ae jg" href="https://github.com/moorissa/medium/tree/master/items-recommender" rel="noopener ugc nofollow" target="_blank"> github repo </a>。它由客户的杂货购买记录组成。首先，让我们看看数据是如何构造的。</p><figure class="mz na nb nc gt iv gh gi paragraph-image"><div class="gh gi my"><img src="../Images/339058ccde981b2c21f5a2a06f022ca7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*ckmVZikZ8HSF6DqmvKJvyA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">采购记录的数据布局</p></figure><p id="ab36" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">显然，这个数据集还不能用于模型训练。<code class="fe nd ne nf ng b">products</code>列堆满了物品 id(与<code class="fe nd ne nf ng b">|</code>连接在一起)。我们需要对其进行预处理，并将其转换为模型期望接受的内容。</p><p id="fdc0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面，我们将准备两种类型的数据格式，一种是用户-iterm 交互矩阵，另一种是长格式数据帧(见下面的演示)。</p><h2 id="8511" class="nh mc jj bd md ni nj dn mh nk nl dp ml lh nm nn mn ll no np mp lp nq nr mr ns bi translated">预期格式 01:用户-项目互动矩阵</h2><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nt"><img src="../Images/c67e41072948ddede1da1124879bdc75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KgC5E_J8D-NmMqkiwgjqGQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">用户-项目矩阵格式</p></figure><p id="9189" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在用户-项目交互矩阵中，每行代表一个用户，每列代表一个产品项目。对应索引(I，j)处的条目是重复购买的次数(或者更广义地解释为交互强度)。这种数据格式通常适用于传统的 SVD 建模。</p><h2 id="e5a7" class="nh mc jj bd md ni nj dn mh nk nl dp ml lh nm nn mn ll no np mp lp nq nr mr ns bi translated">预期格式 02:长格式数据帧</h2><figure class="mz na nb nc gt iv gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/5acc6b73d9b530d7f203bd8bf975c029.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*-gTY03Y0atu-v2eeyKu-Cg.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">长格式数据帧</p></figure><p id="c3e0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在长格式数据帧中，每一行代表一对(用户、物品)的重复购买次数(或交互强度)。参见上面的演示，我们有第一列为<strong class="la jk"> customerId </strong>，第二列为<strong class="la jk"> productId </strong>，因此是(用户，项目)对。最后一列<strong class="la jk"> purchase_count </strong>填入相应的购买次数。长格式数据帧是非常普遍和广泛使用的。它更适合基于神经网络(NN)的建模。</p><p id="5282" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们已经为数据预处理和转换设定了目标，现在让我们看看如何实现它。</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="0ca4" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">逐步—数据预处理</h1><h2 id="32cf" class="nh mc jj bd md ni nj dn mh nk nl dp ml lh nm nn mn ll no np mp lp nq nr mr ns bi translated">步骤 01:转换数据类型和格式转换</h2><p id="d0ee" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">下面的代码是从作者<a class="ae jg" href="https://github.com/moorissa/medium/blob/master/items-recommender/notebooks/recommendation-MT.ipynb" rel="noopener ugc nofollow" target="_blank">moorissa</a>【1】那里借来的，他是这个数据集的同一个回购作者。主要的想法是拆分条目的字符串(最初用<code class="fe nd ne nf ng b">|</code>连接)，并将其保存为 pd.Series。然后我们使用 pd.melt()将数据从宽格式转换为长格式。最后，我们应用 df.groupby()来聚合每个(用户、商品)购买记录。就是这样。现在，我们手头有了一个干净的长格式数据集。</p><p id="f8d9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以直接在数据集上应用<code class="fe nd ne nf ng b">trx_transform()</code>来完成任务。</p><figure class="mz na nb nc gt iv"><div class="bz fp l di"><div class="nv nw l"/></div></figure><h2 id="e68f" class="nh mc jj bd md ni nj dn mh nk nl dp ml lh nm nn mn ll no np mp lp nq nr mr ns bi translated">步骤 02:重新缩放数据集</h2><p id="d4bc" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">我们知道每个用户去商场的频率不同。最终，每个用户的购买数量是不同的。为了让模型更好地正确、一致地解释每个用户的交互，我们最好将每个用户的购买计数重新调整到范围(0，1)。</p><pre class="mz na nb nc gt nx ng ny nz aw oa bi"><span id="a6bf" class="nh mc jj ng b gy ob oc l od oe">data["max_count"] = data.groupby("customerId")["purchase_count"].transform(<br/>    lambda x: x.max())</span><span id="f015" class="nh mc jj ng b gy of oc l od oe">data["purchase_count_norm"] = data["purchase_count"] / data["max_count"]</span></pre><h2 id="12f0" class="nh mc jj bd md ni nj dn mh nk nl dp ml lh nm nn mn ll no np mp lp nq nr mr ns bi translated">步骤 03:创建用户-项目互动矩阵</h2><p id="fc2f" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">在这一步，我们将应用<code class="fe nd ne nf ng b">df2interact_mat()</code>将长格式数据集转换为交互矩阵。代码借用<a class="ae jg" href="https://jessesw.com/Rec-System/" rel="noopener ugc nofollow" target="_blank">本帖</a>【2】稍作改编。</p><figure class="mz na nb nc gt iv"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="6d88" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">(可选)一旦我们创建了交互矩阵，我们也可以计算矩阵的稀疏度。当稀疏度大于 99.5%(意味着不到 0.5%的总条目为非零)时，协同过滤模型表现不佳。一种补救方法是删除一些几乎全是零的用户或项目，从而使矩阵变绿。</p><h2 id="026f" class="nh mc jj bd md ni nj dn mh nk nl dp ml lh nm nn mn ll no np mp lp nq nr mr ns bi translated">步骤 04:创建训练/测试集</h2><p id="cbe0" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">此外，我们需要为模型评估创建训练/测试集。值得注意的一点是，在推荐建模下，训练/测试分割是相当不同的。在传统的训练/测试分裂中，我们从训练集中分离出行的子集作为测试集。然而，在这种情况下，我们采用类似于屏蔽的方法，对用户部分屏蔽一些项目。这就像假装用户还没有看到该项目。并使用未屏蔽的项目来训练模型。一旦模型准备好，然后我们使用屏蔽的项目作为测试集标签，并查看模型的预测是否正确地将这些项目包括在用户的推荐列表中。</p><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi og"><img src="../Images/5a07263fbdb914fbd33b1a4bcaf25217.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TkadtL44gORuE1mGEnhzxw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">推荐情况下的训练/测试分割</p></figure><p id="7d78" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">同样，我将它包装在一个函数<code class="fe nd ne nf ng b">train_test_split()</code>中，以简化这个过程。</p><figure class="mz na nb nc gt iv"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="2cef" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用该功能时，我们需要提供:</p><ul class=""><li id="178e" class="oh oi jj la b lb lc le lf lh oj ll ok lp ol lt om on oo op bi translated">评级:用户-项目交互矩阵。</li><li id="ded8" class="oh oi jj la b lb oq le or lh os ll ot lp ou lt om on oo op bi translated">split_count:(整数)每个用户从训练集转移到测试集的项目交互次数。</li><li id="1cd3" class="oh oi jj la b lb oq le or lh os ll ot lp ou lt om on oo op bi translated">fractions: (float)用户将他们的一些项目交互拆分到测试集中的部分。如果没有，则考虑所有用户。</li></ul><p id="240f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该函数将返回三个对象。</p><ol class=""><li id="1a5e" class="oh oi jj la b lb lc le lf lh oj ll ok lp ol lt ov on oo op bi translated">列车组:列车交互矩阵</li><li id="0135" class="oh oi jj la b lb oq le or lh os ll ot lp ou lt ov on oo op bi translated">测试集:测试交互矩阵</li><li id="b1e8" class="oh oi jj la b lb oq le or lh os ll ot lp ou lt ov on oo op bi translated">user_index:对测试集屏蔽了一些交互的用户索引，存储为索引以备后用</li></ol><p id="16ab" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">至此，我们手头已经有了训练和测试交互矩阵。然而，我们也可以在这里为神经网络建模准备长格式数据帧。</p><h2 id="e67f" class="nh mc jj bd md ni nj dn mh nk nl dp ml lh nm nn mn ll no np mp lp nq nr mr ns bi translated">步骤 05:准备长格式数据帧</h2><p id="e335" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">幸运的是，Scipy 首席运营官矩阵有一堆方便的方法。我们可以将这个矩阵转换成首席运营官数据类型。然后我们只需简单地调用<strong class="la jk"> coo.row、coo.col </strong>和<strong class="la jk"> coo.data </strong>来访问各自的索引和数据。最后，我们将这些片段放在一起，创建长格式数据集。</p><pre class="mz na nb nc gt nx ng ny nz aw oa bi"><span id="7136" class="nh mc jj ng b gy ob oc l od oe"># Ref: <a class="ae jg" href="https://stackoverflow.com/a/36587845" rel="noopener ugc nofollow" target="_blank">https://stackoverflow.com/a/36587845</a></span><span id="f045" class="nh mc jj ng b gy of oc l od oe">train_long = train.tocoo(copy=True)<br/>test_long = test.tocoo(copy=True)</span><span id="f041" class="nh mc jj ng b gy of oc l od oe"># Access `row`, `col` and `data` properties of coo matrix.<br/>train_long = pd.DataFrame({<br/>    'user_id': train_long.row,<br/>    'item_id': train_long.col,<br/>    'rating': train_long.data<br/>})[['user_id', 'item_id',<br/>    'rating']].sort_values(['user_id', 'item_id']).reset_index(drop=True)</span><span id="eb64" class="nh mc jj ng b gy of oc l od oe"># Apply the same operation on test data.<br/>test_long = pd.DataFrame({<br/>    'user_id': test_long.row,<br/>    'item_id': test_long.col,<br/>    'rating': test_long.data<br/>})[['user_id', 'item_id',<br/>    'rating']].sort_values(['user_id', 'item_id']).reset_index(drop=True)</span></pre></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ow"><img src="../Images/4a8a906a9304e8075c3044f7189eb54d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*myFQpQ285ciiaGty"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://unsplash.com/@andyoneru?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">和</a>在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><h1 id="807e" class="mb mc jj bd md me ox mg mh mi oy mk ml kp oz kq mn ks pa kt mp kv pb kw mr ms bi translated">开始建模吧！</h1><p id="26e6" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">恭喜你！我们刚刚完成了所有繁琐的数据预处理步骤。现在我们可以做一些更有趣的事情了。我们将总共测试三种型号。首先是 lightFM 模型，其次是 RDF 模型，最后是 NN 模型。</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h2 id="f1a7" class="nh mc jj bd md ni nj dn mh nk nl dp ml lh nm nn mn ll no np mp lp nq nr mr ns bi translated">什么是因式分解机(FM)？</h2><p id="83b7" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">在讨论第二种模型时，我们将提出奇异值分解基本上是调频的一种特殊情况。但在此之前，让我们快速回顾一下什么是 FM，并了解一下 lightFM 模块如何利用这项技术。</p><p id="ca72" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如本帖【3】中<a class="ae jg" href="https://medium.com/@jimmywu0621/factorization-machines-%E7%A8%80%E7%96%8F%E8%B3%87%E6%96%99%E7%9A%84%E6%95%91%E6%98%9F-732153700d10" rel="noopener">所解释的，FM 主要用于简化特征交互系数的估计(<strong class="la jk"> θ </strong>)。最初，必须逐个估计成对特征交互的系数。然而，FM 玩了一个把戏，定义了具有 K 个潜在嵌入的每个特征，并假设交互作用的系数可以通过这些潜在嵌入的内积来估计。该方法巧妙地将成对系数估计简化为潜在嵌入估计，极大地提高了效率。</a></p><p id="e938" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下图清楚地展示了不同之处。</p><h2 id="0758" class="nh mc jj bd md ni nj dn mh nk nl dp ml lh nm nn mn ll no np mp lp nq nr mr ns bi translated">之前:</h2><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pc"><img src="../Images/08e721a7470d02ae3947e0cbd5bd3a6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kZDYC_N6UuDzyYL0BeV6oA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">原创模型(鸣谢:陈鸿轩)</p></figure><ol class=""><li id="1773" class="oh oi jj la b lb lc le lf lh oj ll ok lp ol lt ov on oo op bi translated">FM 将对相互作用系数的估计(<strong class="la jk"> θ </strong>)简化为对潜在嵌入的估计(<strong class="la jk"> V </strong>)。</li><li id="234a" class="oh oi jj la b lb oq le or lh os ll ot lp ou lt ov on oo op bi translated">成对潜在嵌入的内积代替了成对交互系数估计(见下文)。</li></ol><h2 id="ce28" class="nh mc jj bd md ni nj dn mh nk nl dp ml lh nm nn mn ll no np mp lp nq nr mr ns bi translated">之后:</h2><figure class="mz na nb nc gt iv gh gi paragraph-image"><div class="ab gu cl pd"><img src="../Images/58a08d682030bfa80e8ec3c8cfe825aa.png" data-original-src="https://miro.medium.com/v2/format:webp/1*nQYJXODq7vLBgF_rW0lLUw.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">从这篇<a class="ae jg" href="https://medium.com/@jimmywu0621/factorization-machines-%E7%A8%80%E7%96%8F%E8%B3%87%E6%96%99%E7%9A%84%E6%95%91%E6%98%9F-732153700d10" rel="noopener">帖子</a>解释因式分解模型</p></figure><h2 id="aa16" class="nh mc jj bd md ni nj dn mh nk nl dp ml lh nm nn mn ll no np mp lp nq nr mr ns bi translated">lightFM 丰富了什么？</h2><p id="f1a8" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">lightFM 的作者在 FM 方法的基础上做了一点小小的修改，使得 lightFM 模型可以在新用户的推荐下使用。</p><p id="81e4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如在<a class="ae jg" href="https://arxiv.org/pdf/1507.08439.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>【4】中所述，lightFM 模块非常灵活。如果只提供用户-项目交互矩阵，那么模型只是一个矩阵分解模型。但是，我们也可以从用户和项目提供额外的功能。然后，该模型将合并这些信息，并转而使用因式分解机。下面的过程是 first lightFM 将这些特征以及用户/项目指示符(索引)转换为 K 维嵌入。每个用户或物品的表征是所有潜在嵌入特征的总和。(见下图)这种将用户或项目表示为特征嵌入总和的方式允许模型对新用户进行预测。这解决了协同过滤模型中最棘手的问题之一——冷启动问题。</p><blockquote class="pe pf pg"><p id="6e58" class="ky kz ph la b lb lc kk ld le lf kn lg pi li lj lk pj lm ln lo pk lq lr ls lt im bi translated">旁注:冷启动意味着新用户或项目没有过去的用户-项目交互记录，因此不可能向新用户推荐或向现有用户推荐新项目。</p></blockquote><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pl"><img src="../Images/a95f7fbc04e12343eb67e113c1ab60fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DmX1nV5BEsucvcfti4_RJw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">lightFM 将用户/项目表示为其内容特征的线性组合。(来自<a class="ae jg" href="https://arxiv.org/pdf/1507.08439.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>)</p></figure><p id="efae" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一旦我们熟悉了 lightFM 背后的概念，让我们试着实现它。</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="2581" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">第一个模型:通过 lightFM 模块构建推荐器</h1><h2 id="94f3" class="nh mc jj bd md ni nj dn mh nk nl dp ml lh nm nn mn ll no np mp lp nq nr mr ns bi translated">A.构建和训练模型</h2><p id="aea1" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">使用 lightFM 构建推荐器非常简单。只需实现下面的代码，并在模型初始化中指定自定义参数。</p><pre class="mz na nb nc gt nx ng ny nz aw oa bi"><span id="aa0c" class="nh mc jj ng b gy ob oc l od oe"># Initialize model with self-defined configuration.</span><span id="7fc2" class="nh mc jj ng b gy of oc l od oe">model = LightFM(no_components=20, <br/>                learning_rate=0.005, <br/>                loss='bpr', <br/>                random_state=12)</span><span id="9230" class="nh mc jj ng b gy of oc l od oe"># Start training.</span><span id="7582" class="nh mc jj ng b gy of oc l od oe">model.fit(train, epochs=50, verbose=True) #train: interaction matrix</span></pre><h2 id="fcd8" class="nh mc jj bd md ni nj dn mh nk nl dp ml lh nm nn mn ll no np mp lp nq nr mr ns bi translated">B.模型预测和评估</h2><p id="9860" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">在完成模型训练后，我们可以使用两个指标来评估它。一个是 RMSE，另一个是 Top@K precision。</p><p id="bd1a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于像我们这样的机器学习实践者来说，RMSE 是一个非常常见的指标。它可以衡量实际评分(或在这种情况下的购买强度)和预测评分之间的差异。同时，Top@K 用于衡量用户实际购买推荐的 top k 商品的比例。</p><p id="6cd1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，让我们使用模型进行预测。</p><pre class="mz na nb nc gt nx ng ny nz aw oa bi"><span id="a593" class="nh mc jj ng b gy ob oc l od oe"># Ref: <a class="ae jg" href="https://github.com/lyst/lightfm/blob/9ffeacbdc4688e9b58c6e5edfdeb52b037608a6b/lightfm/lightfm.py#L784" rel="noopener ugc nofollow" target="_blank">https://<br/>github.com/lyst/lightfm/blob/9ffeacbdc4688e9b58c6e5edfdeb52b037608a6b/lightfm/lightfm.py#L784</a></span><span id="6636" class="nh mc jj ng b gy of oc l od oe"># predict() takes only numpy.array<br/>predictions = model.predict(val_user_ids, <br/>                            val_item_ids)</span></pre><p id="ae05" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里，<strong class="la jk"> val_user_ids </strong>和<strong class="la jk"> val_item_ids </strong>来自长格式测试数据帧。</p><h2 id="6dcc" class="nh mc jj bd md ni nj dn mh nk nl dp ml lh nm nn mn ll no np mp lp nq nr mr ns bi translated">-计算 RMSE</h2><p id="ac90" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">我们定义了一个名为<code class="fe nd ne nf ng b">compute_rmse</code>的函数来帮助完成这项任务。</p><pre class="mz na nb nc gt nx ng ny nz aw oa bi"><span id="2f8f" class="nh mc jj ng b gy ob oc l od oe">def compute_rmse(X_test, X_pred):<br/>    # Ref: <a class="ae jg" href="https://github.com/ncu-dart/rdf/blob/master/rdf/utils.py" rel="noopener ugc nofollow" target="_blank">https://github.com/ncu-dart/rdf/blob/master/rdf/utils.py</a><br/>    <br/>    sse = 0.<br/>    for i in range(len(X_test)):<br/>        sse += (X_test[i] - X_pred[i]) ** 2<br/>    <br/>    return (sse / len(X_test)) ** .5</span></pre><p id="2bb9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个函数有两个参数。</p><ul class=""><li id="cab5" class="oh oi jj la b lb lc le lf lh oj ll ok lp ol lt om on oo op bi translated">X_test: (arr)正常化的真实购买值</li><li id="5eea" class="oh oi jj la b lb oq le or lh os ll ot lp ou lt om on oo op bi translated">X_pred: (arr)标准化的预测采购值</li></ul><h2 id="6a17" class="nh mc jj bd md ni nj dn mh nk nl dp ml lh nm nn mn ll no np mp lp nq nr mr ns bi translated">-计算 Top@K</h2><p id="8ca1" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">在计算 Top@K 之前，我们需要首先将模型的预测转换为交互矩阵。</p><pre class="mz na nb nc gt nx ng ny nz aw oa bi"><span id="040c" class="nh mc jj ng b gy ob oc l od oe">predict_mat = sparse.csr_matrix(<br/>    (predictions, (val_user_ids, val_item_ids)), <br/>    shape=(n_users, n_items)<br/>)</span></pre><p id="5c16" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后，我们使用之前保存的<strong class="la jk"> user_index </strong>提取这些测试用户的购买记录。</p><pre class="mz na nb nc gt nx ng ny nz aw oa bi"><span id="b51d" class="nh mc jj ng b gy ob oc l od oe">test_sub = test[user_index] # true user purchase<br/>predict_mat_sub = predict_mat[user_index] # predicted user purchase</span></pre><p id="a740" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，我们准备计算 Top@K。假设我们只想计算前 4 个预测项的准确性。我们只是运行下面的代码。</p><pre class="mz na nb nc gt nx ng ny nz aw oa bi"><span id="0946" class="nh mc jj ng b gy ob oc l od oe">top_k = 4  # hyper-parameter</span><span id="76c8" class="nh mc jj ng b gy of oc l od oe">predict_top_k = []<br/>for i in range(len(user_index)):<br/>    # csr.indices and csr.data only return non-zero entries<br/>    <br/>    predict_r = predict_mat_sub[i].indices[<br/>        predict_mat_sub[i].data.argsort()[::-1]][:top_k]<br/>    <br/>    true_r = test_sub[i].indices[<br/>        test_sub[i].data.argsort()[::-1][:top_k]]<br/>    <br/>    pre = len(set(predict_r) &amp; set(true_r))/ float(top_k)<br/>    predict_top_k.append(pre)</span><span id="e8e3" class="nh mc jj ng b gy of oc l od oe">np.mean(predict_top_k)</span></pre><p id="7171" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这样，我们可以获得 lightFM 模型的 RMSE 和 Top@K 性能，如下所示:</p><ul class=""><li id="f747" class="oh oi jj la b lb lc le lf lh oj ll ok lp ol lt om on oo op bi translated">RMSE: 0.721</li><li id="0f6a" class="oh oi jj la b lb oq le or lh os ll ot lp ou lt om on oo op bi translated">Top@K: 1</li></ul></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="0e58" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">第二个模型:使用 RDF 方法构建推荐器</h1><p id="7a7b" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">让我们在另一个叫做 RDF-SVD 的模型上进行实验——正则化微分函数。<a class="ae jg" href="https://in.ncu.edu.tw/~hhchen/academic_works/chen19_diff_reg_weight.pdf" rel="noopener ugc nofollow" target="_blank">这个方法</a>【5】是由台湾 NCU 的陈鸿轩教授和他的研究助理陈普提出的。</p><p id="bdb3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在讲 RDF 之前，我们先来回顾一下 SVD。在 SVD 的损失函数中，我们可以在每个系数估计上包括正则化项(<strong class="la jk"> λ </strong>)。它用于防止模型中的过度拟合。</p><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pm"><img src="../Images/2df583c57891ea695a7903373b98a0b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9HuR2VUAOi8Ve93FvZS_4A.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">具有偏差和正则项的奇异值分解损失函数(来自<a class="ae jg" href="https://in.ncu.edu.tw/~hhchen/academic_works/chen19_diff_reg_weight.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></p></figure><p id="d956" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">特别是，\hat{r}(预测评级)等于…</p><figure class="mz na nb nc gt iv gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/14bb398ab53aac2937c01a96039a2d51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*wtcOTA996EuBbgLpPEF10A.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">奇异值分解预测额定值方程(来自<a class="ae jg" href="https://in.ncu.edu.tw/~hhchen/academic_works/chen19_diff_reg_weight.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></p></figure><p id="c36c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">将上面的等式与第一个模型中的 FM 进行比较，可以清楚地看出 SVD 只是 FM 模型的一个特例。</p><p id="44d7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">陈教授的方法(RDF)也是 lightFM 的设计目标，旨在解决冷启动问题。lightFM 试图通过引入特征潜在嵌入来解决这个问题，而 RDF 则侧重于奇异值分解损失函数中的正则项。</p><p id="38cd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">总的想法是，对于已经被更多用户评级(或购买)的项目，我们可以对模型的预测有信心。这同样适用于那些比其他人评价更多项目的用户。因为我们从这些受欢迎的项目和活跃用户那里收集了更多的数据，所以建立在此基础上的模型不太可能过度拟合和不准确。尽管如此，对于评分较低的项目和活跃用户，我们没有太多的记录。因此，我们对这些项目或用户的系数估计使用了更大的正则项。这导致我们的损失函数如下:</p><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi po"><img src="../Images/7fcd6b512aae57c24cea41af125d54c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZRgwPw3VxmOmmOldzPawPA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">带有正则化微分函数的损失函数(来自<a class="ae jg" href="https://in.ncu.edu.tw/~hhchen/academic_works/chen19_diff_reg_weight.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></p></figure><p id="7d4e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">等式中的“<strong class="la jk">*</strong>”代表项目被评分的次数或用户评分的次数。<strong class="la jk"> f() </strong>是一个单调递增的函数。基于本文的实验，采用这种改进的 RDF 的模型在精度上有了很大的提高。在这里，让我们尝试使用这种方法建立一个模型。</p><h2 id="544f" class="nh mc jj bd md ni nj dn mh nk nl dp ml lh nm nn mn ll no np mp lp nq nr mr ns bi translated">A.首先，导入 rdf</h2><p id="a89a" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">陈教授和将这种方法封装在一个叫做 rdf 的模块中。这是<a class="ae jg" href="https://github.com/ncu-dart/rdf" rel="noopener ugc nofollow" target="_blank">源代码链接</a>。我们只需要在使用之前克隆 repo 并安装模块。</p><h2 id="1beb" class="nh mc jj bd md ni nj dn mh nk nl dp ml lh nm nn mn ll no np mp lp nq nr mr ns bi translated">B.选择长格式数据帧作为训练/测试数据集</h2><figure class="mz na nb nc gt iv gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/86dfbd1df1d4237535f74e1bbcbf16c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/format:webp/1*bRJ7VNRy9wKnUAjZS6fiJA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">长格式数据帧</p></figure><p id="7bd2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们首先选择长格式数据帧作为输入数据集。然后，我们需要再次将它转换成 rdf 模块要求的格式。对于每条记录，它必须以下列格式存储。</p><blockquote class="pe pf pg"><p id="d128" class="ky kz ph la b lb lc kk ld le lf kn lg pi li lj lk pj lm ln lo pk lq lr ls lt im bi translated">[(客户标识，产品标识，评级)，(客户标识，产品标识，评级)，…]</p></blockquote><p id="8d17" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面的代码为我们完成了这项工作。</p><pre class="mz na nb nc gt nx ng ny nz aw oa bi"><span id="2cbe" class="nh mc jj ng b gy ob oc l od oe">ll = train_long.apply(lambda x: (x[0], x[1], x[2]), axis = 1)<br/>X = list(ll)</span><span id="00f5" class="nh mc jj ng b gy of oc l od oe"># Apply the same operation on test data.<br/>ll = test_long.apply(lambda x: (x[0], x[1], x[2]), axis = 1)<br/>X_test = list(ll)</span></pre><h2 id="507b" class="nh mc jj bd md ni nj dn mh nk nl dp ml lh nm nn mn ll no np mp lp nq nr mr ns bi translated">C.启动和训练模型</h2><p id="1bb9" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated"><strong class="la jk"> rdf </strong>模块能够对各种算法应用微分正则化，包括 SVD、SVD++和 NMF。在本文中，为了简单起见，我们选择了基本的 SVD 模型，并应用了 repo 中的默认超参数。</p><pre class="mz na nb nc gt nx ng ny nz aw oa bi"><span id="9e00" class="nh mc jj ng b gy ob oc l od oe">model = rdf.rdfsvd.RDFSVD(n_users=n_users,<br/>                          n_items=n_items,<br/>                          lr=.005,<br/>                          lmbda_p=500,<br/>                          lmbda_q=500,<br/>                          lmbda_u=.01,<br/>                          lmbda_i=.01,<br/>                          method="linear")</span><span id="8ef3" class="nh mc jj ng b gy of oc l od oe">model.train(X)</span></pre><h2 id="804f" class="nh mc jj bd md ni nj dn mh nk nl dp ml lh nm nn mn ll no np mp lp nq nr mr ns bi translated">D.模型预测和评估</h2><p id="4f61" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">一旦模型训练完成，我们就可以用它在 RMSE 和 Top@K 上进行预测并评估其性能</p><pre class="mz na nb nc gt nx ng ny nz aw oa bi"><span id="6bcf" class="nh mc jj ng b gy ob oc l od oe"># make predictions<br/>X_pred = model.predict(X_test)</span></pre><figure class="mz na nb nc gt iv gh gi paragraph-image"><div class="gh gi pq"><img src="../Images/02c7069490028524b530e781fa7a27ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1324/format:webp/1*W20Y4DXZ9p22oqXFHLXxOw.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">测试-(用户标识，项目标识，评级)元组上 RDF-SVD 模型预测的演示</p></figure><p id="a96d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">将上述代码应用于 rmse 和 top@k 计算，我们得到如下指标:</p><ul class=""><li id="4264" class="oh oi jj la b lb lc le lf lh oj ll ok lp ol lt om on oo op bi translated">RMSE: 0.245</li><li id="c910" class="oh oi jj la b lb oq le or lh os ll ot lp ou lt om on oo op bi translated">Top@K: 1</li></ul></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="8ad7" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">第三个模型:使用神经协同过滤构建推荐器</h1><p id="6fa2" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">最后，让我们尝试将深度学习框架整合到我们的推荐器中。这里让我们介绍一个非常通用的框架，叫做神经协同过滤(NCF)。这是<a class="ae jg" href="https://arxiv.org/abs/1708.05031" rel="noopener ugc nofollow" target="_blank">报纸的链接</a>【6】。另外，我强烈推荐 Steeve Huang 写的这篇<a class="ae jg" rel="noopener" target="_blank" href="/paper-review-neural-collaborative-filtering-explanation-implementation-ea3e031b7f96">中帖</a>【7】。如果你想节省时间，跳过阅读原文，这是让你快速掌握 NCF 概貌的必读文章。</p><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pr"><img src="../Images/5c0decf9be1b76b692297c62f745705c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CDB4GWbsP1xihtsb3lHeIQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">神经协同过滤模型(来自<a class="ae jg" href="https://arxiv.org/abs/1708.05031" rel="noopener ugc nofollow" target="_blank">论文</a></p></figure><h2 id="bfd9" class="nh mc jj bd md ni nj dn mh nk nl dp ml lh nm nn mn ll no np mp lp nq nr mr ns bi translated">A.模型算法</h2><p id="51d9" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">在论文中，作者提出了两个框架，一个是广义矩阵分解(GMF)，如上图(左)所示，另一个是多层感知器(MLP)，如上图(右)所示。在模型的最后一层，来自两个框架的输出将连接在一起，作为最终输出。</p><p id="87b7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果我们更仔细地观察，我们会发现曼氏金融只是 GMF 的另一个特例。</p><figure class="mz na nb nc gt iv gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/1286705c56a5c42ff0dd670a8560256a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*nBqXmjWEcQ4f6SwcksNung.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">与 MF 的关系(信用:<a class="ae jg" rel="noopener" target="_blank" href="/paper-review-neural-collaborative-filtering-explanation-implementation-ea3e031b7f96"> Steeve Huang </a>)</p></figure><p id="7b78" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe nd ne nf ng b">Eq 1</code>是 GMF 下的用户-物品交互。<strong class="la jk"> L </strong>为激活函数，<strong class="la jk"> J_kx1 </strong>为输出层的边权重。在 GMF 框架下，<strong class="la jk"> L </strong>可以是线性的也可以是非线性的，<strong class="la jk"> J_kx1 </strong>代表潜在向量中各维度的权重。</p><p id="275d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">假设我们说<strong class="la jk"> L </strong>是一个线性激活函数，而<strong class="la jk"> J_kx1 </strong>是一个所有值都为 1 的向量(意味着每个维度具有相同的权重)，那么 GMF 将还原为原始 MF，即<strong class="la jk"> pᵤ和</strong>qᵢ的内积，如<code class="fe nd ne nf ng b">Eq 3</code>所示。</p><p id="94d6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我在此引用教皇的话:</p><blockquote class="pe pf pg"><p id="72d6" class="ky kz ph la b lb lc kk ld le lf kn lg pi li lj lk pj lm ln lo pk lq lr ls lt im bi translated">在 NCF 框架下，物流可以很容易地推广和扩展…它将物流推广到一个非线性的设置，这可能比线性物流模型更有表现力。</p></blockquote><p id="f14d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然而，NCF 并没有就此止步。它还包括多层感知器(MLP)作为模型中的另一个分支，以便捕捉用户和项目之间的高阶非线性交互。我在这里引用:</p><blockquote class="pe pf pg"><p id="e644" class="ky kz ph la b lb lc kk ld le lf kn lg pi li lj lk pj lm ln lo pk lq lr ls lt im bi translated">我们可以赋予模型很大程度的灵活性和非线性，以了解 pᵤ和 qᵢ之间的相互作用，而不是像 GMF 那样只使用它们的固定元素乘积。</p></blockquote><p id="9b43" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在 MLP 框架中，作者也做了几次尝试来测试多少层对模型来说是最合适的。一般来说，模型越深，精度越高。在基本结构中，它有<strong class="la jk"> 3 层</strong>，每层的<strong class="la jk">节点比上一层减少一半。</strong></p><p id="426f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">还有另外三个有趣的点值得一提。</p><ol class=""><li id="59ad" class="oh oi jj la b lb lc le lf lh oj ll ok lp ol lt ov on oo op bi translated">进行预培训:我们可以将 GLM 和 MLP 分开，对每个模型进行预培训。然后我们使用这些模型的权重作为 NCF 模型的初始化权重。实验表明，该方法比直接随机初始化 NCF 模型的权重具有更好的性能。</li><li id="2abb" class="oh oi jj la b lb oq le or lh os ll ot lp ou lt ov on oo op bi translated">使用负抽样:对于那些用户没有交互的项目，我们可以进行负(不交互)到正(有交互)抽样。在训练集中添加一部分负样本可以提高模型的性能。但是比例是多少呢？在实验中，1:1 的正负比例并不能达到最佳效果。在训练集中，负样本的比率最好大于 1。作者最后选择了 4:1(阴性:阳性)。</li><li id="5459" class="oh oi jj la b lb oq le or lh os ll ot lp ou lt ov on oo op bi translated">输出层的加权初始化:这是模型调整的可选步骤。特别是在培训前的情况下。NCF 的输出层是 GMF 和 MLP 输出的拼接。我们可以做得更巧妙的是，给每个输出分配权重(α)和(1-α),以便对一个输出比另一个输出给予更多的重视。权重(α)是自定义的指定超参数。</li></ol><p id="8f0d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在下面的实现中，为了简单起见，不包括上面提到的任何实践。我们只是构建 GMP 和 MLP 模型，并将两者结合起来。无负采样，两个输出无加权初始化(α)。</p><h2 id="ad4d" class="nh mc jj bd md ni nj dn mh nk nl dp ml lh nm nn mn ll no np mp lp nq nr mr ns bi translated">B.建立模型</h2><p id="53d0" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">这里我使用了 tensorflow 2.0 下的 tf.keras API 来构建模型。我主要采用了 Steeve Huang 的<a class="ae jg" href="https://github.com/khuangaf/tibame_recommender_system/blob/master/NCF.ipynb" rel="noopener ugc nofollow" target="_blank">回购</a>【8】的模型，只是对超参数做了一些修改，以便与原始论文中的参数保持一致。</p><figure class="mz na nb nc gt iv"><div class="bz fp l di"><div class="nv nw l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">建立 NCF 模型</p></figure><h2 id="cdc0" class="nh mc jj bd md ni nj dn mh nk nl dp ml lh nm nn mn ll no np mp lp nq nr mr ns bi translated">C.训练模型</h2><p id="6718" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">我们再次需要使用长格式数据集来训练我们的 NCF 模型。</p><pre class="mz na nb nc gt nx ng ny nz aw oa bi"><span id="3a3b" class="nh mc jj ng b gy ob oc l od oe">from tensorflow.keras.callbacks import EarlyStopping</span><span id="ab44" class="nh mc jj ng b gy of oc l od oe"># early stopping wait for 3 epoch<br/>callbacks = [EarlyStopping(patience=3, restore_best_weights=True)]</span><span id="65a4" class="nh mc jj ng b gy of oc l od oe"># train and test set<br/>train_user_ids = train_long["user_id"]<br/>train_movie_ids = train_long["item_id"]<br/>train_ratings = train_long["rating"]</span><span id="6128" class="nh mc jj ng b gy of oc l od oe">val_user_ids = test_long["user_id"]<br/>val_movie_ids = test_long["item_id"]<br/>val_ratings = test_long["rating"]</span><span id="1b31" class="nh mc jj ng b gy of oc l od oe"># train for 50 epochs<br/>model.fit([train_user_ids, train_movie_ids],<br/>          train_ratings,<br/>          validation_data=(<br/>              [val_user_ids, val_movie_ids], val_ratings),<br/>          epochs=50,<br/>          batch_size=128,<br/>          callbacks=callbacks)</span></pre><h2 id="2bf4" class="nh mc jj bd md ni nj dn mh nk nl dp ml lh nm nn mn ll no np mp lp nq nr mr ns bi translated">D.模型预测和评估</h2><p id="4e68" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">最后，下面是 NCF 在 RMSE 和 Top@K 上的表现指标</p><ul class=""><li id="2cfe" class="oh oi jj la b lb lc le lf lh oj ll ok lp ol lt om on oo op bi translated">RMSE: 0.231</li><li id="af55" class="oh oi jj la b lb oq le or lh os ll ot lp ou lt om on oo op bi translated">Top@K: 1</li></ul></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="d3af" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">最终反射</h1><p id="0192" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">我们在这里看到三个模型有趣的结果。所有模型在 Top@K 中得到了 1(在 Top 4 的情况下)，意味着模型推荐的前 4 件商品实际上都是测试用户在现实中购买的。也许这不是偶然发生的。在数据预处理中，我尽量去除数据集中一些交互记录不多的项目或用户。它导致更致密的相互作用矩阵。手头剩余的项目和用户，大多数都有相当多的交互记录。因此，任何协作过滤模型表现良好都不足为奇。</p><p id="5e0f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">尽管如此，让我们比较另一个指标，RMSE。我们看到，lightFM 的误差最大(0.72)，NCF 的误差最小(0.23)，尽管与 RDF-SVD 的误差(0.24)相差不大。</p><p id="d2ab" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以总的来说，我们可以说 NCF 仍然有最好的表现。</p><p id="235a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你对整个实现感兴趣，欢迎查看<a class="ae jg" href="https://github.com/TomLin/Playground" rel="noopener ugc nofollow" target="_blank">我的回购</a>。希望你喜欢这篇文章，并欢迎提供任何进一步改进的反馈。干杯！</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="3766" class="mb mc jj bd md me mf mg mh mi mj mk ml kp mm kq mn ks mo kt mp kv mq kw mr ms bi translated">参考</h1><p id="b386" class="pw-post-body-paragraph ky kz jj la b lb mt kk ld le mu kn lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">[1] moorissa，<a class="ae jg" href="https://github.com/moorissa/medium/blob/master/items-recommender/notebooks/recommendation-MT.ipynb" rel="noopener ugc nofollow" target="_blank">如何构建购买数据的推荐系统(循序渐进)</a>(2018)<em class="ph">Github</em></p><p id="6e60" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[2]杰西·斯坦威格·伍兹，<a class="ae jg" href="https://jessesw.com/Rec-System/" rel="noopener ugc nofollow" target="_blank">含蓄反馈推荐系统的温和介绍</a> (2016)，<em class="ph">个人博客</em></p><p id="a177" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi">[3] Jimmy Wu, <a class="ae jg" href="https://medium.com/@jimmywu0621/factorization-machines-%E7%A8%80%E7%96%8F%E8%B3%87%E6%96%99%E7%9A%84%E6%95%91%E6%98%9F-732153700d10" rel="noopener">Factorization Machines — 稀疏資料的救星</a> (2019), <em class="ph">Medium</em></p><p id="1463" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[4]马切伊·库拉，<a class="ae jg" href="https://arxiv.org/pdf/1507.08439.pdf" rel="noopener ugc nofollow" target="_blank">用户和项目冷启动的元数据嵌入<br/>建议</a> (2015)，<em class="ph">Lyst.com</em></p><p id="95fa" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[5]陈鸿轩和陈普，<a class="ae jg" href="https://github.com/ncu-dart/rdf" rel="noopener ugc nofollow" target="_blank">区分正则化权重——一种减轻推荐系统冷启动的简单机制</a>(2019)<em class="ph">美国计算机学会数据知识发现汇刊</em></p><p id="5c3b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[6] X 何等，<a class="ae jg" href="https://arxiv.org/pdf/1708.05031.pdf" rel="noopener ugc nofollow" target="_blank">神经协同过滤</a> (2017)，<em class="ph">国大</em></p><p id="2454" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[7] Steeve Huang，<a class="ae jg" rel="noopener" target="_blank" href="/paper-review-neural-collaborative-filtering-explanation-implementation-ea3e031b7f96">论文综述:神经协同过滤解说&amp;实现</a> (2018)，<em class="ph">走向数据科学</em></p><p id="4090" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[8] Steeve Huang，<a class="ae jg" href="https://github.com/khuangaf/tibame_recommender_system/blob/master/NCF.ipynb" rel="noopener ugc nofollow" target="_blank">2019</a>，<em class="ph"> Github </em></p></div></div>    
</body>
</html>