<html>
<head>
<title>Using Keras On Google’s Edge TPU</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在谷歌的边缘TPU使用Keras</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-keras-on-googles-edge-tpu-7f53750d952?source=collection_archive---------12-----------------------#2020-01-25">https://towardsdatascience.com/using-keras-on-googles-edge-tpu-7f53750d952?source=collection_archive---------12-----------------------#2020-01-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8c47" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在边缘快速部署准确的模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/aa06d02d10bebf95185124e5c2dd494b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9F0EcHOSCiczjwBi"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">内森·希普斯在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><p id="eac0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用<a class="ae ky" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>是快速理解和高效使用深度神经网络模型的好方法。目前，Keras API不正式支持<a class="ae ky" href="https://github.com/tensorflow/tensorflow/tree/r1.13/tensorflow/contrib/quantize" rel="noopener ugc nofollow" target="_blank">量化感知训练</a>，因此无法使用该API直接生成一个用于edge硬件优化(例如，仅使用整数数学)推理的模型。与云相比，边缘上的推断可以提供几个优势，包括减少延迟、降低云成本和改善客户数据隐私。</p><p id="b62e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文涵盖了以下步骤，因此您可以利用快速高效的<a class="ae ky" href="https://coral.ai/" rel="noopener ugc nofollow" target="_blank"> Google Coral Edge TPU </a>轻松使用Keras模型。</p><ul class=""><li id="2cc3" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">选择Edge TensorFlow处理单元(TPU)兼容的Keras模型。</li><li id="fa88" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">在自定义数据集上微调模型。</li><li id="05e8" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">使用训练后量化将微调的Keras模型转换为张量流(TF) Lite模型。</li><li id="f285" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">编译用于Edge TPU的量化TF Lite。</li><li id="78f9" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">在边缘TPU上评估量化模型精度。</li><li id="a85f" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">在边缘TPU上部署量化模型。</li></ul><p id="1e2f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文不会深入研究训练深度神经网络、TF Lite或Keras APIs，也不会深入研究模型量化背后的理论。您可以通过提供的各种链接来了解这些主题的更多信息。另外，参见<a class="ae ky" href="https://petewarden.com/2015/05/23/why-are-eight-bits-enough-for-deep-neural-networks/" rel="noopener ugc nofollow" target="_blank">皮特·沃顿的优秀博客</a>。这篇文章反映出我主要是一名工程师，比起花大量时间在理论上，我更关心让事情顺利进行。</p><p id="c811" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，我为<a class="ae ky" href="https://github.com/goruck/smart-zoneminder" rel="noopener ugc nofollow" target="_blank"> smart-zoneminder </a>项目开发了大量材料，帮助我更好地理解深度学习，因为我在家里解决了一个实际问题——识别一个人是我的家人还是陌生人。我将使用项目中的例子来阐明这些材料，如下所示。</p><h1 id="914d" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">型号选择</h1><p id="4cd8" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">根据Google Coral <a class="ae ky" href="https://coral.ai/docs/edgetpu/models-intro/" rel="noopener ugc nofollow" target="_blank">文档</a>显示，只有少数Keras机型在Edge TPU上得到验证——<a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNet" rel="noopener ugc nofollow" target="_blank">Mobilenet _ v1</a>、<a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV2" rel="noopener ugc nofollow" target="_blank"> Mobilenet_v2 </a>、<a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/InceptionV3" rel="noopener ugc nofollow" target="_blank"> Inception_v3 </a>和<a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet50" rel="noopener ugc nofollow" target="_blank"> ResNet50 </a>。我决定使用Mobilenet_v2、Inception_v3和ResNet50来确认它们在Edge TPU上确实工作得很好。我还<a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16" rel="noopener ugc nofollow" target="_blank">尝试了VGG16 </a>和<a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/InceptionResNetV2" rel="noopener ugc nofollow" target="_blank"> InceptionResNetV2 </a>，看看它们在对比中表现如何。这些模型对于我的<a class="ae ky" href="https://github.com/goruck/smart-zoneminder" rel="noopener ugc nofollow" target="_blank"> smart-zoneminder </a>应用程序来说是完美的，因为它需要一种方法来分类一个人是我的家庭成员还是陌生人——这是这些卷积神经网络(CNN)模型的理想用途。选择这些模型可以很好解决的问题来使用edge硬件，否则当您尝试将另一种类型的网络(可能使用TF Lite无法量化的运算符)映射到硬件时，您将处于未知领域。</p><h1 id="c4b1" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">模型微调</h1><p id="e337" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">有许多很好的资料向您展示如何在您自己的定制数据集上微调Keras模型，例如<a class="ae ky" href="https://keras.io/applications/" rel="noopener ugc nofollow" target="_blank"> Keras文档</a>和<a class="ae ky" href="https://github.com/goruck/smart-zoneminder/blob/master/person-class/train.py" rel="noopener ugc nofollow" target="_blank"> smart-zoneminder </a>。但是，我发现在Keras模型的输出中使用max pooling将不会针对边TPU进行编译，因为它有一个当前无法由TF Lite量化的运算符(REDUCE_MAX)。因此，您将需要使用平均池(或无)，如下例所示。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用平均池实例化Keras模型</p></figure><h1 id="46f0" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">训练后量化</h1><p id="758d" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">由于Keras模型不支持<a class="ae ky" href="https://github.com/tensorflow/tensorflow/tree/r1.13/tensorflow/contrib/quantize" rel="noopener ugc nofollow" target="_blank">量化感知训练</a>，您需要使用训练后量化，如<a class="ae ky" href="https://www.tensorflow.org/lite/performance/post_training_quantization" rel="noopener ugc nofollow" target="_blank"> TF Lite文档</a>中所述。在<a class="ae ky" href="https://github.com/goruck/smart-zoneminder" rel="noopener ugc nofollow" target="_blank"> smart-zoneminder </a>项目中使用的<a class="ae ky" href="https://github.com/goruck/smart-zoneminder/blob/master/person-class/train.py" rel="noopener ugc nofollow" target="_blank"> Python训练脚本</a>将在Keras模型的最终训练步骤之后运行训练后量化，如下所示。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">从Keras .h5文件生成量化的TFLite模型</p></figure><p id="0dce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://github.com/goruck/smart-zoneminder/blob/master/person-class/keras_to_tflite_quant.py" rel="noopener ugc nofollow" target="_blank"> keras_to_tflite_quant </a>模块将keras模型(以. h5格式)量化为TF Lite 8位模型。该脚本还可以评估量化模型的准确性，但TF Lite模型的推理在英特尔CPU(我与Nvidia GPU一起用于培训)上非常慢，因为当前的TF Lite运算符内核针对ARM处理器进行了优化(使用NEON指令集)。参见此<a class="ae ky" href="https://stackoverflow.com/questions/54093424/why-is-tensorflow-lite-slower-than-tensorflow-on-desktop" rel="noopener ugc nofollow" target="_blank">线程</a>了解更多细节，并在下面了解评估边缘TPU量化模型的可行方法。</p><h1 id="013a" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">为边缘TPU编译</h1><p id="8556" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">在下一步中，您需要使用<a class="ae ky" href="https://coral.ai/docs/edgetpu/compiler/" rel="noopener ugc nofollow" target="_blank"> Google Coral编译器</a>为Edge TPU编译量化TensorFlow Lite模型。在<a class="ae ky" href="https://github.com/goruck/smart-zoneminder" rel="noopener ugc nofollow" target="_blank"> smart-zoneminder </a>项目中使用的<a class="ae ky" href="https://github.com/goruck/smart-zoneminder/blob/master/person-class/train.py" rel="noopener ugc nofollow" target="_blank"> Python train脚本</a>将运行如下所示的编译器。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">为边缘TPU编译</p></figure><h1 id="ed52" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">评估量化模型的准确性</h1><p id="92ec" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">你的模型会受到量化的影响，所以你应该检查一下它的精度是否在应用程序所能容忍的范围之内。一种快速的方法是使用TPU的量化模型对用于开发模型的训练和验证数据集进行推理。为此，我使用了Python脚本<a class="ae ky" href="https://github.com/goruck/smart-zoneminder/blob/master/tpu-servers/evaluate_model.py" rel="noopener ugc nofollow" target="_blank"> evaluate_model.py </a>，它是在TPU边缘运行的<a class="ae ky" href="https://github.com/goruck/smart-zoneminder" rel="noopener ugc nofollow" target="_blank">智能区域管理器</a>项目的一部分。该脚本的实际评估函数如下所示。参见Google Coral <a class="ae ky" href="https://coral.ai/docs/edgetpu/tflite-python/" rel="noopener ugc nofollow" target="_blank">文档</a>了解更多关于如何使用TF Lite在edge TPU上运行推理的信息。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">函数在边TPU上运行推理</p></figure><p id="e678" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Resnet50的evaluate_model.py的输出如下所示。您可以看到精度为0.966，非常接近训练和验证数据集精度0.973的加权平均值。这个模型的量化损失对我的应用来说是可以接受的。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">TPU评估结果的量化结果</p></figure><p id="2d7d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总体而言，我测试的所有模型都具有可接受的量化性能，除了InceptionResNetV2，其量化性能仅为0.855，而基线为0.980。目前，尚不清楚这种量化模型表现不佳的原因。</p><h1 id="f578" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">部署量化模型</h1><p id="518e" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">在您验证了足够的模型准确性之后，您可以部署它以在您的应用程序中运行推理。smart-zoneminder为此使用了一个基于zerorpc的推理服务器。</p><h1 id="adc2" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">结论</h1><p id="9a8d" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">通过仔细选择和训练Edge TPU兼容的Keras模型，您可以快速将推理模型部署到Edge。这些模型必须首先量化为8位，然后针对边缘TPU进行编译。量化过程会在模型中引入精度误差，在生产环境中使用之前，应评估其在应用程序中的适用性。边缘推理提供了几个优势，包括减少延迟、降低云成本和改善客户数据隐私。</p></div></div>    
</body>
</html>