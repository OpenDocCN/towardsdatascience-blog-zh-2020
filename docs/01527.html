<html>
<head>
<title>Building a real-time prediction pipeline using Spark Structured Streaming and Microservices</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Spark 结构化流和微服务构建实时预测管道</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-real-time-prediction-pipeline-using-spark-structured-streaming-and-microservices-626dc20899eb?source=collection_archive---------8-----------------------#2020-02-11">https://towardsdatascience.com/building-a-real-time-prediction-pipeline-using-spark-structured-streaming-and-microservices-626dc20899eb?source=collection_archive---------8-----------------------#2020-02-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="909c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在本教程中，我们将讨论在处理低延迟数据管道时解耦机器学习模型的好处</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4640210c7263bff19126a58b9efe4b98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xPN1TMIK_kHoVBcQLKErYA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">凯文·Ku 在<a class="ae ky" href="https://unsplash.com/s/photos/machine-learning?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="e016" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将为机器学习预测建立一个实时管道。我们将使用的主要框架是:</p><ul class=""><li id="b304" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><a class="ae ky" href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html" rel="noopener ugc nofollow" target="_blank"> Spark 结构化流</a>:成熟易用的流处理引擎</li><li id="4452" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">Kafka :我们将使用 Kafka 的融合版本作为我们的流媒体平台</li><li id="e826" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://opensource.com/article/18/4/flask" rel="noopener ugc nofollow" target="_blank"> Flask </a>:用于构建 RESTful 微服务的开源 python 包</li><li id="f722" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://docs.confluent.io/current/quickstart/ce-docker-quickstart.html?utm_medium=sem&amp;utm_source=google&amp;utm_campaign=ch.sem_br.brand_tp.prs_tgt.confluent-brand_mt.xct_rgn.emea_lng.eng_dv.all&amp;utm_term=confluent%20kafka%20docker&amp;creative=&amp;device=c&amp;placement=&amp;gclid=CjwKCAiAvonyBRB7EiwAadauqSDXLG4BUDfIH8weo9PodnlxrIBKdxPd76NrD0a4zL2eZLOar1XfPBoCc6AQAvD_BwE" rel="noopener ugc nofollow" target="_blank"> Docker </a>:用于本地启动 kafka 集群</li><li id="8eed" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">Jupyter 实验室:我们运行代码的环境</li><li id="1c4c" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://www.nltk.org" rel="noopener ugc nofollow" target="_blank"> NLTK </a>:带有预训练模型的 python 的 NLP 库。</li></ul><p id="c66b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">TL；DR:代码在</strong><a class="ae ky" href="https://github.com/BogdanCojocar/medium-articles/tree/master/realtime_kafka" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">GitHub</strong></a><strong class="lb iu">上。</strong></p><h2 id="b0eb" class="mj mk it bd ml mm mn dn mo mp mq dp mr li ms mt mu lm mv mw mx lq my mz na nb bi translated">将 ML 模型构建为微服务的优势</h2><p id="dde6" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">在实时 ML 管道中，我们以两种方式嵌入模型:将模型直接用于执行处理的框架中，或者将模型单独解耦到微服务中。通过构建 ML 模型的包装器，我们需要额外的努力，为什么要这么麻烦呢？有两大优势。首先，当我们想要部署一个新模型时，我们不需要部署整个管道，我们只需要公开一个新的微服务版本。其次，它给了你更多的能力去测试 ML 模型的不同版本。例如，我们可以使用 canary 部署，在模型的<code class="fe nh ni nj nk b">version1</code>上使用 80%的数据流，在<code class="fe nh ni nj nk b">version2</code>上使用 20%的数据流。一旦我们对<code class="fe nh ni nj nk b">version2</code>的质量感到满意，我们就会向它转移越来越多的流量。</p><p id="af3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们深入研究应用程序的开发。</p><h2 id="2c64" class="mj mk it bd ml mm mn dn mo mp mq dp mr li ms mt mu lm mv mw mx lq my mz na nb bi translated">步骤 1:运行 docker compose 来启动 kafka 集群</h2><p id="68ed" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">为了构建集群，我们将使用一个<code class="fe nh ni nj nk b">docker-compose</code>文件来启动所有需要的 docker 容器:zookeeper 和一个代理。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="1509" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在简单地说，kafka 是一个分布式流媒体平台，能够处理大量的消息，这些消息被组织或分组到主题中。为了能够并行处理一个主题，必须将它分成多个分区，来自这些分区的数据存储在称为代理的独立机器中。最后，zookeeper 用于管理集群中代理的资源。为了读写 kafka 集群，我们需要一个代理地址和一个主题。</p><p id="6088" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nh ni nj nk b">docker-compose</code>将在端口<code class="fe nh ni nj nk b">2181</code>启动<code class="fe nh ni nj nk b">zookeper</code>，在端口<code class="fe nh ni nj nk b">9092</code>启动<code class="fe nh ni nj nk b">kafka broker</code>。除此之外，我们使用另一个 docker 容器<code class="fe nh ni nj nk b">kafka-create-topic</code>的唯一目的是在 kafka broker 中创建一个主题(称为 test)。</p><p id="01da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要启动 kafka 集群，我们必须在定义 docker compose 文件的同一文件夹中运行以下命令行指令:</p><pre class="kj kk kl km gt nn nk no np aw nq bi"><span id="390d" class="mj mk it nk b gy nr ns l nt nu">docker-compose up</span></pre><p id="6726" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这将启动所有带有日志的 docker 容器。我们应该在控制台中看到类似这样的内容:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/0e50dc642cabd20bf4d0fee9bac6930f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CGmKOW3EiRfBCa3oo9kHDQ.png"/></div></div></figure><h2 id="c741" class="mj mk it bd ml mm mn dn mo mp mq dp mr li ms mt mu lm mv mw mx lq my mz na nb bi translated">步骤 2:构建和部署微服务</h2><p id="f531" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">我们将 REST 协议用于我们的 web 服务。我们将使用 NLTK 的<code class="fe nh ni nj nk b">Vader</code>算法进行情感分析。这是一个预先训练好的模型，所以我们只能关注预测部分:</p><pre class="kj kk kl km gt nn nk no np aw nq bi"><span id="c2d1" class="mj mk it nk b gy nr ns l nt nu"><a class="ae ky" href="http://twitter.com/app" rel="noopener ugc nofollow" target="_blank">@app</a>.route('/predict', methods=['POST'])<br/>def predict():<br/>    result = sid.polarity_scores(request.get_json()['data'])<br/>    return jsonify(result)</span></pre><p id="737f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们正在创建一个接收到形式为<code class="fe nh ni nj nk b">{"data": "some text"}</code>的<code class="fe nh ni nj nk b">JSON</code>消息的<code class="fe nh ni nj nk b">POST</code>请求，其中字段<code class="fe nh ni nj nk b">data</code>包含一个句子。我们将应用该算法，并将响应作为另一个<code class="fe nh ni nj nk b">JSON</code>发送回去。</p><p id="ac12" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要运行该应用程序，只需运行:</p><pre class="kj kk kl km gt nn nk no np aw nq bi"><span id="53a4" class="mj mk it nk b gy nr ns l nt nu">python app.py</span></pre><p id="f1d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">休息服务将在<code class="fe nh ni nj nk b"><a class="ae ky" href="http://127.0.0.1:9000/predict" rel="noopener ugc nofollow" target="_blank">http://127.0.0.1:9000/predict</a></code>开始。</p><h2 id="33db" class="mj mk it bd ml mm mn dn mo mp mq dp mr li ms mt mu lm mv mw mx lq my mz na nb bi translated">步骤 3:使用 Kafka 依赖项启动 pySpark</h2><p id="2d3e" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">在我们启动 Jupyter 实验室笔记本之后，我们需要确保我们拥有 kafka jar 作为 spark 的依赖项，以便能够运行代码。在笔记本的第一个单元格中添加以下内容:</p><pre class="kj kk kl km gt nn nk no np aw nq bi"><span id="fb1f" class="mj mk it nk b gy nr ns l nt nu">import os<br/>os.environ['PYSPARK_SUBMIT_ARGS'] = "--packages=org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.4 pyspark-shell"</span></pre><p id="d8f4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们可以使用<code class="fe nh ni nj nk b">findspark</code>包启动 pySpark:</p><pre class="kj kk kl km gt nn nk no np aw nq bi"><span id="eb7d" class="mj mk it nk b gy nr ns l nt nu">import findspark<br/>findspark.init()</span></pre><h2 id="a21d" class="mj mk it bd ml mm mn dn mo mp mq dp mr li ms mt mu lm mv mw mx lq my mz na nb bi translated">第四步:运行卡夫卡制作程序</h2><p id="3fe0" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">为了能够实时消费数据，我们首先必须将一些消息写入 kafka。我们将使用 python 中的<code class="fe nh ni nj nk b">confluent_kafka</code>库来编写一个生产者:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="e34f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将发送与之前相同的<code class="fe nh ni nj nk b">JSON</code>消息<code class="fe nh ni nj nk b">{"data": value}</code>，其中 value 是预定义列表中的一个句子。对于我们写入队列的每条消息，我们还需要分配一个键。我们将根据<code class="fe nh ni nj nk b">uuid</code>随机分配一个，以实现集群中的良好分布。最后，我们还运行一个<code class="fe nh ni nj nk b">flush</code>命令来确保所有的消息都被发送。</p><p id="fbb3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦我们运行了<code class="fe nh ni nj nk b">confluent_kafka_producer</code>，我们应该会收到一个日志，告诉我们数据已经正确发送:</p><pre class="kj kk kl km gt nn nk no np aw nq bi"><span id="15b9" class="mj mk it nk b gy nr ns l nt nu">we’ve sent 6 messages to 127.0.0.1:9092</span></pre><h2 id="be34" class="mj mk it bd ml mm mn dn mo mp mq dp mr li ms mt mu lm mv mw mx lq my mz na nb bi translated">第五步:开始从卡夫卡那里读取数据</h2><p id="3d0b" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">如前所述，我们将使用 Spark 结构化流来实时处理数据。这是一个易于使用的 API，将微批量数据视为数据帧。我们首先需要将输入数据读入数据帧:</p><pre class="kj kk kl km gt nn nk no np aw nq bi"><span id="d2bc" class="mj mk it nk b gy nr ns l nt nu">df_raw = spark \<br/>  .readStream \<br/>  .format('kafka') \<br/>  .option('kafka.bootstrap.servers', bootstrap_servers) \<br/>  .option("startingOffsets", "earliest") \<br/>  .option('subscribe', topic) \<br/>  .load()</span></pre><p id="3aa5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nh ni nj nk b">startingOffset</code>是<code class="fe nh ni nj nk b">earliest</code>,表示每次运行代码时，我们将读取队列中的所有数据。</p><p id="1955" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该输入将包含不同的列，表示 kafka 的不同度量，如键、值、偏移量等。我们只对值、实际数据感兴趣，我们可以运行一个转换来反映这一点:</p><pre class="kj kk kl km gt nn nk no np aw nq bi"><span id="e94c" class="mj mk it nk b gy nr ns l nt nu">df_json = df_raw.selectExpr('CAST(value AS STRING) as json')</span></pre><h2 id="b0a8" class="mj mk it bd ml mm mn dn mo mp mq dp mr li ms mt mu lm mv mw mx lq my mz na nb bi translated">步骤 6:创建一个应用 ML 模型的 UDF</h2><p id="58a7" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">在结构化流中，我们可以使用用户定义的函数，这些函数可以应用于数据帧中的每一行。</p><pre class="kj kk kl km gt nn nk no np aw nq bi"><span id="e273" class="mj mk it nk b gy nr ns l nt nu">def apply_sentiment_analysis(data):<br/>    import requests<br/>    import json<br/>    <br/>    result = requests.post('<a class="ae ky" href="http://localhost:9000/predict'" rel="noopener ugc nofollow" target="_blank">http://localhost:9000/predict'</a>, json=json.loads(data))<br/>    return json.dumps(result.json())</span></pre><p id="ee18" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们需要在函数中进行导入，因为这是一段可以分布在多台机器上的代码。我们向端点发送请求并返回响应。</p><pre class="kj kk kl km gt nn nk no np aw nq bi"><span id="481f" class="mj mk it nk b gy nr ns l nt nu">vader_udf = udf(lambda data: apply_sentiment_analysis(data), StringType())</span></pre><p id="d462" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将调用我们的 udf 为<code class="fe nh ni nj nk b">vader_udf</code>，它将返回一个新的字符串列。</p><h2 id="9254" class="mj mk it bd ml mm mn dn mo mp mq dp mr li ms mt mu lm mv mw mx lq my mz na nb bi translated">步骤 7:应用 vader udf</h2><p id="5a43" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">在这最后一步，我们将看到我们的结果。输入数据的格式在<code class="fe nh ni nj nk b">JSON</code>中，我们可以将其转换成一个字符串。为此，我们将使用助手函数<code class="fe nh ni nj nk b">from_json</code>。我们可以对情绪分析算法的输出列做同样的事情，它也有<code class="fe nh ni nj nk b">JSON</code>格式:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="0a00" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以在控制台中显示我们的结果。因为我们正在使用笔记本，你将只能从你在 Jupyter 启动的终端上看到它。命令<code class="fe nh ni nj nk b">trigger(once=True)</code>将只运行一小段时间的流处理并显示输出。</p><p id="5a5a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是它的乡亲，我希望你喜欢这个教程，并发现它有用。我们看到了如何通过使用结构化流 API 和调用 ML 模型的微服务，我们可以构建一个强大的模式，它可以成为我们下一个实时应用的主干。</p></div></div>    
</body>
</html>