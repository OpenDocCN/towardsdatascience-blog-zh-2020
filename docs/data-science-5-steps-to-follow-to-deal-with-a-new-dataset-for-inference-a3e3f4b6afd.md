# 数据科学:处理新数据集(用于推理)的 5 个步骤

> 原文：<https://towardsdatascience.com/data-science-5-steps-to-follow-to-deal-with-a-new-dataset-for-inference-a3e3f4b6afd?source=collection_archive---------25----------------------->

![](img/516a16ee30360987072e00a04d6bd436.png)

所有权利保留给合法所有者

## “如何开始对数据集进行分析和推断”简介，

我们将解释一个经典机器学习问题的一般路线图。我们可以粗略地将步骤数下限为 5，这是必须完成的。

## 第一步:统计研究

采取这一步骤的一个简单原因是，当您第一次遇到一个新的数据集时，通常会非常陌生，不知道要素的分布/单位/类型。假设您的环境是 Python，并且您使用 pandas 来解析您的数据集,“describe”函数将完成这项工作。

![](img/2eba3fffa34b3ce1499f1274f504b0b9.png)

用法示例

## 第二步:表面数据预处理

这一步包括许多更小的任务。

*   填充 NaN(根据您的数据集使用均值/中值/高斯方法)如果有，在某些情况下，0 值也非常麻烦，因此您可以聚合成更小的组，以便非零值和零值相加，或者用ε值替换 0。

![](img/437953b6a55d81f8fe01f1639745b8a7.png)

这里的 fill_nan 是自定义的，一般使用的是 df.fillna() 

*   一个好的习惯是将数据集归一化，使其均值为 0，方差为 1。这有助于模型(如逻辑回归)更好地工作(稳健界限),而不是在优化过程中花费更长的时间来收敛(通过 SGD)

![](img/7be5eac0d7c7dd55357808f1b3355dfc.png)

再次标准化是一个自定义函数，简单地使用公式(x-mu)/sigma 

*   完成这些任务后，您可以在数据集上尝试一些简单的模型，并根据结果决定要应用哪些数据处理。

## 第三步:更多数据处理

从这一点开始，您对目标特征的预测就有了准确性。现在的重点是提高精确度，以下是一些方法:

*   降噪:有些情况下，相同的特征向量给你不同的目标特征，在这些情况下，你可以做平均或做均匀分布，取值之间。还有其他更复杂的方法来处理图像(例如图像增强，噪声 2 噪声)
*   剔除异常值:剔除一些异常值也是有益的。这些异常值可能出现在数据集中，但不会出现在您的测试用例中。有的著述考虑区间[0.01，0.99]。
*   特征扩充:最常用的方法是多项式扩充，exp/log/cos 扩充。这些包括在数据集上应用所提到的函数，然后连接到当前的，以获得更多的数据和更复杂的模型进行训练(增加权重维度)。更复杂和具体的情况可能是图像仿射变换/ GAN 图像/噪声添加，或者在经典数据中，交互项(将特征向量相乘)。

## 第四步:模型拟合/训练，超参数

这部分是关于尝试不同的方法并获得正确的超参数。

*   根据你的工作情况(即无监督/有监督/分类等)，你将不得不应用不同的方法(无监督的 k-means，有监督的逻辑回归，以及其他类似的方法)。显然，你总是可以为你的神经网络构建一个架构来完成分类/聚类任务，从而与你的研究目标相匹配。
*   当您知道模型背后的理论时，超参数可以被强力搜索以进行优化，或者也可以被白盒搜索。例如，k-均值/k-最近邻选择 k 的一些一般规则是肘规则。

## 第五步:交叉验证

最后，为了不过度拟合或至少知道存在过度拟合，要进行交叉验证，这里有一些方法:

*   训练/验证分割:最常见的方法是在验证集上进行推断，并与实际情况进行比较
*   k 倍分裂:我们分成 k 个部分，留下 k-1 个用于训练，1 个用于验证。我们对 k-1，1 的所有组合进行推断和基础事实比较。

上面提到的解释并不详尽，肯定是可以改进的，但这些是遇到新数据集时要做的最起码的工作。

感谢阅读！请继续关注更多技巧/教程文章。如果感兴趣，我的 GitHub 上有完整的笔记本！此外，点击这个[链接](https://direct-link.net/91830/aitechfordummies)(指向联盟计划)真的会帮我解决问题！您只需完成一些快速任务(只需等待和激活通知)，所有这些将真正帮助我了解更多未来的硬件相关内容！