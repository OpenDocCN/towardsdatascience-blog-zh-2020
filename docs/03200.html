<html>
<head>
<title>CNN Transfer Learning &amp; Fine Tuning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">CNN迁移学习和微调</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/cnn-transfer-learning-fine-tuning-9f3e7c5806b2?source=collection_archive---------0-----------------------#2020-03-27">https://towardsdatascience.com/cnn-transfer-learning-fine-tuning-9f3e7c5806b2?source=collection_archive---------0-----------------------#2020-03-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="4eb6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">了解如何应用这些强大的技术，将您的深度学习模型提升到一个全新的水平！</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/fecd5641769419b920f043ec88bb0488.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*WsRmTy_FV6f2zK5t"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图片来自<a class="ae le" href="https://unsplash.com/photos/WE_Kv_ZB1l0" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><h1 id="e7e3" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">介绍</h1><p id="392d" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">正如我们在<a class="ae le" rel="noopener" target="_blank" href="/convolutional-neural-networks-most-common-architectures-6a2b5d22479d">之前的文章</a>中看到的，我们可以使用研究团队开发的架构，并利用他们的力量进行预测，并在我们的深度学习模型中获得更好的结果。</p><p id="81bd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">训练一个神经网络需要时间，幸运的是现在有一些方法可以避免:</p><ul class=""><li id="95c9" class="mi mj it js b jt ju jx jy kb mk kf ml kj mm kn mn mo mp mq bi translated">定义神经网络的架构</li><li id="3f70" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">从一开始就训练她</li></ul><p id="045b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们已经看到了避免定义架构<a class="ae le" rel="noopener" target="_blank" href="/convolutional-neural-networks-most-common-architectures-6a2b5d22479d">的方法，这里是</a>，它包括使用已知工作良好的预定义架构:ResNet、AlexNet、VGG、Inception、DenseNet等。</p><p id="4d1b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">那如何避免从头开始训练它呢？我这么说是什么意思？</p><p id="f5f9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">神经网络用随机权重初始化(通常),在一系列时期后达到一些值，允许我们正确地分类我们的输入图像。</p><p id="faeb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果我们可以将这些权重初始化为我们事先知道的某些值，这些值已经可以很好地对某个数据集进行分类，会发生什么？</p><p id="88c8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过这种方式，我们不需要像我们从零开始训练网络一样大的数据集(从几十万甚至几百万的图像，我们可以到几千个)，也不需要等待大量的历元来获得分类的好值，由于它们的初始化，它们会更容易。</p><p id="0a16" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们探索如何利用迁移学习和微调技术来实现这一点:</p><h1 id="343d" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">迁移学习</h1><p id="d253" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">我们以在ImageNet数据集上训练的VGG16网络为例。让我们看看它的架构:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/1aaf3005c42ca0c6b8159d3f2ad06d49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/1*ikyQTwVZ28mjvWwf6IavfQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">按作者分列的数字</p></figure><p id="b73e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们知道，ImageNet由大约120万幅图像组成的数据集用于训练，5万幅用于验证，10万幅用于测试，属于1000个类别。</p><p id="4598" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在假设我们想要将ImageNet上训练的VGG16应用到另一个数据集，假设我们选择了<a class="ae le" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> CIFAR-10 </a>。我们怎么做呢？</p><p id="74a1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">记住CNN的一般方案，我们在第一阶段有一个特征提取器，然后是一个分类器:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mx"><img src="../Images/91ebb5c656b547c8289a8f3fda57a396.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Urw7VzNergd6BqYVeEQhsg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">按作者分列的数字</p></figure><p id="5c92" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果我们删除VGG16的最后一层，它只是为ImageNet中的1000个类中的每一个类取一个概率，并用一个取10个概率的层来替换它，会怎么样？这样，我们可以利用VGG16在ImageNet上训练的所有知识，并将其应用于我们的问题！</p><p id="4972" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">正如我们所看到的，我们要做的是改变分类阶段，以便最后一层是10个神经元之一(我们的CIFAR 10有10个类)，然后我们将重新训练网络，允许完全连接的层的权重被改变，即分类阶段。</p><p id="4011" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为此，我们将使用来自ImageNet的权重初始化我们的网络，然后冻结所有卷积层和最大池层，以便它们不会修改自己的权重，只留下完全连接的层空闲。</p><p id="7755" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一旦完成，我们将开始重新训练。通过这种方式，我们设法利用我们网络的特征提取阶段，并且只调整最终的分类器来更好地与我们的数据集一起工作。这就是所谓的迁移学习，因为我们利用另一个问题的知识来解决我们正在处理的问题。</p><p id="93d8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这种方法也可以通过保存最大池最后一层给出的特征，然后将该数据放入任何分类器(SVM、logreg等)来实现。</p><p id="a353" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们看看我们该如何做:</p><h2 id="e7cf" class="my lg it bd lh mz na dn ll nb nc dp lp kb nd ne lt kf nf ng lx kj nh ni mb nj bi translated">Keras实施</h2><pre class="kp kq kr ks gt nk nl nm nn aw no bi"><span id="6fd5" class="my lg it nl b gy np nq l nr ns"><strong class="nl iu"># We first load the necessary libraries, the dataset and reshape its dimensons to the minimum allowed by the VGG16 --&gt; (48,48,3)</strong><br/>import tensorflow as tf<br/>from keras import callbacks<br/>from keras import optimizers<br/>from keras.engine import Model<br/>from keras.layers import Dropout, Flatten, Dense<br/>from keras.optimizers import Adam<br/>from keras.applications import VGG16<br/>from keras.datasets import cifar10<br/>from keras.utils import to_categorical<br/>import numpy as np</span><span id="3077" class="my lg it nl b gy nt nq l nr ns">input_shape = (48, 48, 3)</span><span id="abaf" class="my lg it nl b gy nt nq l nr ns">(X_train, y_train), (X_test, y_test) = cifar10.load_data()<br/>Y_train = to_categorical(y_train)<br/>Y_test = to_categorical(y_test)</span><span id="2624" class="my lg it nl b gy nt nq l nr ns"><strong class="nl iu"># resize train set</strong><br/>X_train_resized = []<br/>for img in X_train:<br/>  X_train_resized.append(np.resize(img, input_shape) / 255)<br/>  <br/>X_train_resized = np.array(X_train_resized)<br/>print(X_train_resized.shape)</span><span id="df43" class="my lg it nl b gy nt nq l nr ns"><strong class="nl iu"># resize test set</strong><br/>X_test_resized = []<br/>for img in X_test:<br/>  X_test_resized.append(np.resize(img, input_shape) / 255)<br/>  <br/>X_test_resized = np.array(X_test_resized)<br/>print(X_test_resized.shape)</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nu"><img src="../Images/d41c1e41aa110a1ffa6740e9635798b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SEZH5cQjM2z4G6L9ldqPQQ.png"/></div></div></figure><pre class="kp kq kr ks gt nk nl nm nn aw no bi"><span id="d268" class="my lg it nl b gy np nq l nr ns"><strong class="nl iu"># We build the base model</strong><br/>base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)<br/>base_model.summary()</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nv"><img src="../Images/ffe865a7f6184568f8afc1777833f701.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ESYNWzgTF5pa7cN2mfpoPA.png"/></div></div></figure><pre class="kp kq kr ks gt nk nl nm nn aw no bi"><span id="20b3" class="my lg it nl b gy np nq l nr ns"><strong class="nl iu"># We freeze every layer in our base model so that they do not train, we want that our feature extractor stays as before --&gt; transfer learning</strong><br/>for layer in base_model.layers: <br/>  layer.trainable = False<br/>  print('Layer ' + layer.name + ' frozen.')</span><span id="236e" class="my lg it nl b gy nt nq l nr ns"><strong class="nl iu"># We take the last layer of our the model and add it to our classifier</strong><br/>last = base_model.layers[-1].output<br/>x = Flatten()(last)<br/>x = Dense(1000, activation='relu', name='fc1')(x)<br/>x = Dropout(0.3)(x)<br/>x = Dense(10, activation='softmax', name='predictions')(x)<br/>model = Model(base_model.input, x)</span><span id="5c86" class="my lg it nl b gy nt nq l nr ns"><strong class="nl iu"># We compile the model</strong><br/>model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])</span><span id="665f" class="my lg it nl b gy nt nq l nr ns"><strong class="nl iu">-</strong><br/>model.summary()</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/d43e3bf0e05458661320ea7c5cd7f58c.png" data-original-src="https://miro.medium.com/v2/resize:fit:414/format:webp/1*5194EiHQbys8jJa3V2b6bg.png"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/d11ce937b4b99b3790d6af9f83f548ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*n_dQWBjz_O9umuLCxy9jrA.png"/></div></figure><pre class="kp kq kr ks gt nk nl nm nn aw no bi"><span id="588c" class="my lg it nl b gy np nq l nr ns"><strong class="nl iu"># We start the training</strong><br/>epochs = 10<br/>batch_size = 256</span><span id="768d" class="my lg it nl b gy nt nq l nr ns"><strong class="nl iu"># We train it</strong><br/>model.fit(X_train_resized, Y_train,<br/>          batch_size=batch_size,<br/>          validation_data=(X_test_resized, Y_test),<br/>          epochs=epochs)</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ny"><img src="../Images/fc3e77810404c6e830e814f3d33d6b35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ttqZ0dA_X9k4jr8UeeK-Ww.png"/></div></div></figure><pre class="kp kq kr ks gt nk nl nm nn aw no bi"><span id="64e4" class="my lg it nl b gy np nq l nr ns"><strong class="nl iu"># We evaluate the accuracy and the loss in the test set</strong><br/>scores = model.evaluate(X_test_resized, Y_test, verbose=1)<br/>print('Test loss:', scores[0])<br/>print('Test accuracy:', scores[1])</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/19e8adb8837e5d55ce3cc4cefc8b6406.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*Fjl20umQWnoIP-zw8A1p5A.png"/></div></figure><p id="8a44" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们根本不需要训练，而且我们取得了不错的成绩！请记住，如果我们随机进行，正确的概率将是1/10=0.1或10%，因为我们有10个类。</p><p id="6f86" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最初训练网络的数据集和我们的问题的数据集越相似，我们得到的结果就越好。</p><p id="48a4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果我们的数据集与ImageNet的无关，或者我们想进一步改善结果呢？</p><p id="4757" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为此，我们使用微调。</p><h1 id="e8a3" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">微调</h1><p id="736d" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">通过微调，我们首先改变最后一层以匹配我们数据集中的类，就像我们之前对迁移学习所做的那样。但是除此之外，我们也重新训练我们想要的网络层次。</p><p id="0840" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请记住VGG16的架构:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/1aaf3005c42ca0c6b8159d3f2ad06d49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/1*ikyQTwVZ28mjvWwf6IavfQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">按作者分列的数字</p></figure><p id="d8c3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们在前面的示例中所做的只是改变分类阶段的层，保留网络在前面的任务中提取特征(模式)时获得的知识，我们从该任务中加载权重(ImageNet)。</p><p id="477e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过微调，我们不局限于只重新训练分类器阶段(即完全连接的层)，我们还将重新训练特征提取阶段，即卷积和汇集层。</p><p id="38b1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">重要的是要记住，在神经网络中，第一层检测更简单和更通用的模式，我们在体系结构中发展得越快，就越针对数据集，它们检测的模式就越复杂。</p><p id="7cd0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，我们可以允许卷积和池层的最后一个块被重新训练。</p><p id="be84" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">我什么时候做微调和迁移学习？我如何选择从哪一层重新培训？</strong></p><p id="af9e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一般来说，我们要做的第一件事是转移学习，也就是说，我们不会重新培训我们的网络。这将为我们提供一个必须克服的底线。然后，我们将只重新训练分类阶段，然后我们也可以尝试重新训练一些卷积块。</p><h2 id="8567" class="my lg it bd lh mz na dn ll nb nc dp lp kb nd ne lt kf nf ng lx kj nh ni mb nj bi translated">摘要</h2><ul class=""><li id="65ba" class="mi mj it js b jt md jx me kb oa kf ob kj oc kn mn mo mp mq bi translated">进行迁移学习，即只修改最后一层，使其输出数量与我们的类(基线)相同</li><li id="0f96" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">尝试重新训练分类阶段，即密集层</li><li id="c845" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">试图重新训练一些卷积阶段</li></ul><p id="7e19" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">大多数情况下，遵循这些步骤，你会得到适合你的问题的结果</p><p id="791e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这也取决于你遇到的问题的类型。如果:</p><ul class=""><li id="2d8e" class="mi mj it js b jt ju jx jy kb mk kf ml kj mm kn mn mo mp mq bi translated"><strong class="js iu">新的数据集很小，和原来的相似</strong>:微调的时候要小心，也许选择卷积阶段最后一层的特征，使用SVM或者线性分类器更好。</li><li id="9200" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated"><strong class="js iu">新的数据集很大，与原来的</strong>相似:拥有更多数据我们可能不会过度适应，所以我们可以更有信心地进行微调。</li><li id="3ffe" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated"><strong class="js iu">新的数据集很小，与原来的</strong>非常不同:最好使用卷积阶段早期层的特征，因为这将被设置为比后期层更通用的模式，然后使用线性分类器。</li><li id="ade5" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">新的数据集很大，与原来的大不相同:我们将从头开始训练它！但是，仍然建议您使用ImageNet的权重来初始化权重。</li></ul><h2 id="5ad1" class="my lg it bd lh mz na dn ll nb nc dp lp kb nd ne lt kf nf ng lx kj nh ni mb nj bi translated">注意</h2><p id="e349" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">使用这些技术时，您必须考虑预训练模型的可能限制。例如，它们可能需要最小的图像尺寸。</p><p id="822e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">此外，当重新训练网络时，我们通常选择比从头开始更低的学习速率，因为我们从假设为好的权重的初始化开始。</p><h2 id="f447" class="my lg it bd lh mz na dn ll nb nc dp lp kb nd ne lt kf nf ng lx kj nh ni mb nj bi translated">微调Keras实现</h2><pre class="kp kq kr ks gt nk nl nm nn aw no bi"><span id="8c29" class="my lg it nl b gy np nq l nr ns"><strong class="nl iu"># Fine Tuning Example, classification VGG16 with CIFAR 10, we import the necessary libraries</strong><br/>import tensorflow as tf<br/>from keras import callbacks<br/>from keras import optimizers<br/>from keras.engine import Model<br/>from keras.layers import Dropout, Flatten, Dense<br/>from keras.optimizers import Adam<br/>from keras.preprocessing.image import ImageDataGenerator<br/>from keras.applications import VGG16<br/>from keras.datasets import cifar10<br/>from keras.utils import to_categorical<br/>import numpy as np</span><span id="1501" class="my lg it nl b gy nt nq l nr ns"><strong class="nl iu"># We first load the dataset and reshape its dimensions to the minimum allowed by VGG16 --&gt; (48, 48, 3)</strong></span><span id="ccc2" class="my lg it nl b gy nt nq l nr ns">input_shape = (48, 48, 3)</span><span id="d999" class="my lg it nl b gy nt nq l nr ns">(X_train, y_train), (X_test, y_test) = cifar10.load_data()<br/>Y_train = to_categorical(y_train)<br/>Y_test = to_categorical(y_test)</span><span id="e3e1" class="my lg it nl b gy nt nq l nr ns"># resize train set<br/>X_train_resized = []<br/>for img in X_train:<br/>  X_train_resized.append(np.resize(img, input_shape) / 255)<br/>  <br/>X_train_resized = np.array(X_train_resized)<br/>print(X_train_resized.shape)</span><span id="9092" class="my lg it nl b gy nt nq l nr ns"># resize test set<br/>X_test_resized = []<br/>for img in X_test:<br/>  X_test_resized.append(np.resize(img, input_shape) / 255)<br/>  <br/>X_test_resized = np.array(X_test_resized)<br/>print(X_test_resized.shape)</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi od"><img src="../Images/1891b659f79719f9736aba822213a950.png" data-original-src="https://miro.medium.com/v2/resize:fit:374/format:webp/1*GRSLqlEzxNy3WNt-ybBrBQ.png"/></div></figure><pre class="kp kq kr ks gt nk nl nm nn aw no bi"><span id="4aea" class="my lg it nl b gy np nq l nr ns"><strong class="nl iu"># We build the base model<br/></strong>base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)<br/>base_model.summary()</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/6bc1592fc152ea63db7846d52b8966f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*xJBPFKfu5BWOIk4xtiS6Wg.png"/></div></figure><pre class="kp kq kr ks gt nk nl nm nn aw no bi"><span id="b3e1" class="my lg it nl b gy np nq l nr ns"><strong class="nl iu"># We allow to the last convolutional andthe classification stages  to train</strong><br/>for layer in base_model.layers:<br/>  if layer.name == 'block5_conv1':<br/>    break<br/>  layer.trainable = False<br/>  print('Layer ' + layer.name + ' frozen.')</span><span id="29b7" class="my lg it nl b gy nt nq l nr ns"><strong class="nl iu"># We add our classificator (top_model) to the last layer of the model</strong><br/>last = base_model.layers[-1].output<br/>x = Flatten()(last)<br/>x = Dense(1000, activation='relu', name='fc1')(x)<br/>x = Dropout(0.3)(x)<br/>x = Dense(10, activation='softmax', name='predictions')(x)<br/>model = Model(base_model.input, x)</span><span id="5d85" class="my lg it nl b gy nt nq l nr ns"><strong class="nl iu"># We compile the model</strong><br/>model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])</span><span id="f3c9" class="my lg it nl b gy nt nq l nr ns"><strong class="nl iu"># We see the new structure of the model</strong><br/>model.summary()</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi of"><img src="../Images/2c715f1a57c8b999de236c491948a97a.png" data-original-src="https://miro.medium.com/v2/resize:fit:450/format:webp/1*2wKNOux9NtyX8y7I46Wg3Q.png"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi og"><img src="../Images/7409aaf1fa6b39982cd1aaa31d31b4e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*tg2Ne1u6WoqNbxeobs8xuA.png"/></div></figure><pre class="kp kq kr ks gt nk nl nm nn aw no bi"><span id="0ca6" class="my lg it nl b gy np nq l nr ns"><strong class="nl iu"># We start the training</strong><br/>epochs = 15<br/>batch_size = 256</span><span id="3332" class="my lg it nl b gy nt nq l nr ns"><strong class="nl iu"># We train the model</strong><br/>model.fit(X_train_resized, Y_train,<br/>          batch_size=batch_size,<br/>          validation_data=(X_test_resized, Y_test),<br/>          epochs=epochs)</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oh"><img src="../Images/599410e1aa2fb0bb88d683915cd9c288.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7mT0QcoIpLlPTIyy-igG5A.png"/></div></div></figure><pre class="kp kq kr ks gt nk nl nm nn aw no bi"><span id="e784" class="my lg it nl b gy np nq l nr ns"><strong class="nl iu"># We evaluate the accuracy and the loss in the test set</strong><br/>scores = model.evaluate(X_test_resized, Y_test, verbose=1)<br/>print('Test loss:', scores[0])<br/>print('Test accuracy:', scores[1])</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/f7de2e890d461fcc8b321560adcecf30.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/format:webp/1*SpdmbJJRztm7KmsEz0N6gQ.png"/></div></figure><p id="892a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，当我们面临深度学习问题时，我们应该总是使用微调并建立一个基线模型，我们稍后会尝试改进它。</p><h1 id="b50d" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">最后的话</h1><p id="21c4" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">一如既往，我希望你<strong class="js iu"> </strong>喜欢这篇文章，并且你获得了关于如何实现和开发具有迁移学习和微调的卷积神经网络的直觉！</p><p id="3630" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="oj">如果你喜欢这篇文章，那么你可以看看我关于数据科学和机器学习的其他文章</em> <a class="ae le" href="https://medium.com/@rromanss23" rel="noopener"> <em class="oj">这里</em> </a> <em class="oj">。</em></p><p id="b25f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="oj">如果你想了解更多关于机器学习、数据科学和人工智能的知识</em> <strong class="js iu"> <em class="oj">请在Medium </em> </strong> <em class="oj">上关注我，敬请关注我的下一篇帖子！</em></p></div></div>    
</body>
</html>