<html>
<head>
<title>How did Twitter react to the Coronavirus pandemic?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Twitter 如何应对冠状病毒疫情？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-did-twitter-react-to-the-coronavirus-pandemic-2857592b449a?source=collection_archive---------24-----------------------#2020-03-18">https://towardsdatascience.com/how-did-twitter-react-to-the-coronavirus-pandemic-2857592b449a?source=collection_archive---------24-----------------------#2020-03-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d00d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">《在 R》中新冠肺炎·疫情的探索性和情感分析</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/bc6be22465db39d9e514873fdbb70812.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*YiPjNbdihAuJEdlt"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">马库斯·斯皮斯克在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="4fdc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最近爆发的冠状病毒/COVID 19 最近被宣布为全球紧急情况。随着我们开始练习社交距离，在家工作来控制病毒传播，我决定利用我的业余时间去调查一下人们在网上谈论疫情的事情。</p><p id="6980" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于这篇文章，提取了 2020 年 1 月 30 日至 3 月 15 日之间的 15000 条带有#冠状病毒和#COVID19 的推文进行分析。</p><h2 id="1209" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">将推文提取到 R</h2><p id="65ed" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">有许多 R 包允许您将 tweets 提取成可用的数据类型进行分析。在使用 R 中的包之前，确保您在 twitter 上有一个 API 帐户，允许您提取 tweets。下面的代码块提取了 2020 年 1 月 30 日到 3 月 15 日之间推特上#Coronavirus 和#COVID19 的所有文本。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="20cf" class="lv lw it mu b gy my mz l na nb"><strong class="mu iu">#Extract tweets<br/></strong>library("twitteR")</span><span id="e2c5" class="lv lw it mu b gy nc mz l na nb">consumer_key &lt;- '<em class="nd">your consumer_key</em>'<br/>consumer_secret &lt;- '<em class="nd">your consumer_secret</em>'<br/>access_token &lt;- '<em class="nd">your access_token</em>'<br/>access_secret &lt;- '<em class="nd">your access_secret</em>'</span><span id="fd4c" class="lv lw it mu b gy nc mz l na nb">setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)<br/>2</span><span id="ba82" class="lv lw it mu b gy nc mz l na nb">virus &lt;- searchTwitter('#COVID-19 + #Coronavirus', n = 15000, since = '2020-01-30', retryOnRateLimit = 1e3)<br/>virus_df = twListToDF(virus)</span><span id="3131" class="lv lw it mu b gy nc mz l na nb"><strong class="mu iu">#Write dataframe into an Excel file for analysis<br/></strong>library(xlsx)</span><span id="87a6" class="lv lw it mu b gy nc mz l na nb">write.xlsx(dataFrame, "filePath", sheetName="Sheet1", col.names=TRUE, row.names=TRUE, append=FALSE)</span></pre><h2 id="8832" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">首先，一些有趣的发现</h2><p id="6c34" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在我们开始挖掘推文之前，让我们来看看几条最受欢迎和转发的文本:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="0f21" class="lv lw it mu b gy my mz l na nb"><strong class="mu iu">#most favorited tweets</strong><br/>virus_fav &lt;- virus_df %&gt;%<br/>  arrange(desc(favoriteCount))</span><span id="f25b" class="lv lw it mu b gy nc mz l na nb"><strong class="mu iu">#most retweeted</strong><br/>virus_retweet &lt;- virus_df %&gt;%<br/>  arrange(desc(retweetCount)) %&gt;%<br/>  distinct(text, .keep_all = TRUE)</span><span id="dee8" class="lv lw it mu b gy nc mz l na nb">virus_retweet_extracted &lt;- virus_retweet[-c(2:11)]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/775804f88ca61eafc81e33a887ca4289.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cMB5SBe1tg95MtbH1tTHZQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">2020 年 3 月 17 日:在提取的 15，000 条推文中，前 5 条最受欢迎的推文</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nf"><img src="../Images/0092d1ca9cfbf68e33a21e10ae7e9d89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WY3owY5x7BdhQ48ayW86Pw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">2020 年 3 月 17 日:在提取的 15，000 条推文中，转发量最高的 5 条文本</p></figure><h2 id="27c9" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">然后…一些数据清理和令牌化</h2><p id="aefa" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">首先，将数据集转换为语料库，即 r 中识别的文档(数据类型)的集合。然后，对语料库进行预处理，使所有字符都变成小写，删除所有标点符号、空格和常用词(停用词)。</p><p id="39dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在对语料进行预处理之后，我使用了标记化的方法来抓取单词组合。如果您不熟悉标记化，这种方法可以帮助提取有用的短语，从而获得一些额外的见解。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="7cb9" class="lv lw it mu b gy my mz l na nb"><strong class="mu iu"># Import text data</strong><br/>data &lt;- read.csv("<em class="nd">filePath.csv</em>", stringsAsFactors = FALSE)</span><span id="ea75" class="lv lw it mu b gy nc mz l na nb"><strong class="mu iu">#Change dataset into a corpus</strong><br/>data_corp &lt;- VCorpus(VectorSource(data))</span><span id="b431" class="lv lw it mu b gy nc mz l na nb"><strong class="mu iu">#Data pre-processing</strong><br/>data_corp &lt;- tm_map(data_corp, tolower)<br/>data_corp &lt;- tm_map(data_corp, PlainTextDocument)<br/>data_corp &lt;- tm_map(data_corp, removePunctuation)</span><span id="0f7d" class="lv lw it mu b gy nc mz l na nb">for (i in seq(data_corp)) {<br/>  data_corp[[i]] &lt;- gsub('[^a-zA-Z|[:blank:]]', "", data_corp[[i]])<br/>}</span><span id="64d0" class="lv lw it mu b gy nc mz l na nb"><strong class="mu iu">#Remove stop words</strong><br/>new_stops &lt;-c("covid","iphone","coronavirus","hrefhttptwittercomdownloadandroid","relnofollowtwitter","androida","hrefhttptwittercomdownloadiphone","relnofollowtwitter","iphonea","web","rt","chuonlinenews","hrefhttpsmobiletwittercom","hrefhttptwittercomdownloadipad","bharianmy","lebih","berbanding","dijangkiti","kumpulan","mudah","terdedah","covidhttpstcoigdxdtmvrg","hrefhttpsabouttwittercomproductstweetdeck", "darah")</span><span id="33d5" class="lv lw it mu b gy nc mz l na nb">data_corp &lt;- tm_map(data_corp, removeWords, words = c(stopwords("English"), new_stops))<br/>data_corp &lt;- tm_map(data_corp, stripWhitespace)<br/>data_corp &lt;- tm_map(data_corp, PlainTextDocument)</span><span id="68f2" class="lv lw it mu b gy nc mz l na nb"><strong class="mu iu">#Tokenize tweets texts into words</strong><br/>tokenizer &lt;- function(x) {<br/>  NGramTokenizer(x, Weka_control(min = 1, max = 1))<br/>}</span><span id="a883" class="lv lw it mu b gy nc mz l na nb">data_cleaned_tdm &lt;- TermDocumentMatrix(<br/>  data_corp,<br/>  control = list(tokenize = tokenizer)<br/>)</span><span id="69e6" class="lv lw it mu b gy nc mz l na nb">data_cleaned_tdm_m &lt;- as.matrix(data_cleaned_tdm)<br/>data_cleaned_freq &lt;- rowSums(data_cleaned_tdm_m)</span></pre><h2 id="2b2b" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">词频分析</h2><p id="28fd" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">探索数据最简单的方法之一是频率分析。虽然不难，但在情感分析中，这种简单的方法会令人惊讶地具有启发性。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="a713" class="lv lw it mu b gy my mz l na nb"><strong class="mu iu">#Create a uni-gram (1-word) word cloud</strong><br/>pal &lt;- brewer.pal(9,"Set1")<br/>wordcloud(names(data_cleaned_freq), data_cleaned_freq, min.freq=50,max.words = 50, random.order=TRUE,random.color = TRUE, rot.per=.15, colors = pal,scale = c(3,1))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/e256ceca3ffeac70a051f1bdbe9a9c6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/1*UfQyCJV42tjyK0k-QjBnAw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">单字单词云</p></figure><h2 id="aea3" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">出现频率最高的前三个词:</h2><ul class=""><li id="885b" class="nh ni it lb b lc mo lf mp li nj lm nk lq nl lu nm nn no np bi translated">False (45459 次)</li><li id="805d" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated">真(14557 次)</li><li id="77bd" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated">国立卫生研究院(3820 次)</li></ul><p id="5f7d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">二元语法(2 个单词)和三元语法(3 个单词)的词频可以让我们从我们正在分析的数据集获得更好的见解。只需将 tokenizer 函数的最小值和最大值更新为您想要研究的词元数，即可获得以下结果:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="7691" class="lv lw it mu b gy my mz l na nb"><strong class="mu iu">#change the 1s into the number of word-grams you would like to analyze</strong></span><span id="1526" class="lv lw it mu b gy nc mz l na nb">tokenizer &lt;- function(x) {<br/>  NGramTokenizer(x, Weka_control(min = 1, max = 1))<br/>}</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/7f0871a383bf80878b8e3927dd877636.png" data-original-src="https://miro.medium.com/v2/resize:fit:374/format:webp/1*deBF-nFK6J17ZgplrbdccQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">词频最高的二元模型列表</p></figure><p id="a074" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">基于二元和三元模型列表，我们知道人们在谈论:</p><ul class=""><li id="7eac" class="nh ni it lb b lc ld lf lg li nw lm nx lq ny lu nm nn no np bi translated">冠状病毒疫苗的临床试验</li><li id="f9e7" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated">国家健康研究所</li><li id="f581" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated">卡尔·冯·哈布斯堡大公(首位冠状病毒检测呈阳性的皇室成员)</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/74b028a2ac665f24059f4ca1be3f0923.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/format:webp/1*dFF5q9BKmnV_0BDCzHnxUg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">词频最高的三元模型列表</p></figure><h1 id="26fd" class="oa lw it bd lx ob oc od ma oe of og md jz oh ka mg kc oi kd mj kf oj kg mm ok bi translated">情感分析</h1><p id="784e" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">情感分析帮助我们理解人们对特定主题的感受。这是通过识别、分类观点并将文字转化为可操作的见解来完成的。</p><h2 id="ba0f" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">首先，数据预处理…再次！</h2><p id="7312" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">首先，我们需要一个 tibble(数据类型)来将 tweets 的句子分解成单词，以便进一步分析。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="3699" class="lv lw it mu b gy my mz l na nb"><strong class="mu iu">#Transform sentences into words</strong><br/>data_tibble &lt;- data %&gt;%<br/>  unnest_tokens(output = "words", input = text, token = "words")</span><span id="dba5" class="lv lw it mu b gy nc mz l na nb"><strong class="mu iu">#Remove stop words from tibble</strong><br/>virus_tibble_clean &lt;- data_tibble %&gt;%<br/>  anti_join(stop_words, by=c("words"="word")</span></pre><h2 id="4566" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">用数字可视化情感:极性评分</h2><p id="d0ec" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">极性得分帮助我们对一些文本的感觉做出定量的判断。简而言之，我们将推文中的单词分为积极和消极两种类型，并给它们打分进行分析。</p><p id="ad82" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">极性得分告诉我们一段文字是消极的、中性的还是积极的。如果分数接近或等于 1，我们会认为正文是正面的，反之亦然。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/31da3bacb6f6c0075a3cba7a57c7b558.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*o6RMEUAqzgCXozDVrIML4w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">15，000 条提取的推文的总体极性得分</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/3da7ce6d3b0191814046ddcd9b7195fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*u6ts86VfVRgeSVw-d0Xcmg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">提取的推文的整体极性</p></figure><h2 id="9412" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">情感词频</h2><p id="ee06" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">接下来，我们还可以使用极性得分对单词进行分类，将单词放入“积极”或“消极”的篮子中。首先，我们给提取的推文中的每个单词分配一个极性分数。然后，我们过滤数据集，只得到极性得分为 80 或更高的单词。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="7f13" class="lv lw it mu b gy my mz l na nb">data_tidy_sentiment &lt;- virus_tibble_clean %&gt;% <br/>  <strong class="mu iu"># Inner join to bing lexicon by term = word</strong><br/>  inner_join(get_sentiments("bing"), by = c("words" = "word")) %&gt;% <br/>  <strong class="mu iu"># Count by term and sentiment, weighted by count</strong><br/>  count(words, sentiment) %&gt;%<br/>  <strong class="mu iu"># Spread sentiment, using n as values</strong><br/>  spread(sentiment, n, fill = 0) %&gt;%<br/> <strong class="mu iu"> # Mutate to add a polarity column</strong><br/>  mutate(polarity = positive - negative)</span><span id="4b4e" class="lv lw it mu b gy nc mz l na nb">summary(data_tidy_sentiment)<br/>data_tidy_pol &lt;- data_tidy_sentiment %&gt;% <br/> <strong class="mu iu"> # Filter for absolute polarity at least 80</strong> <br/>  filter(abs(polarity) &gt;= 80) %&gt;% <br/> <strong class="mu iu"> # Add positive/negative status</strong><br/>  mutate(<br/>    pos_or_neg = ifelse(polarity &gt; 0, "positive", "negative")<br/>  )</span><span id="d0de" class="lv lw it mu b gy nc mz l na nb"><strong class="mu iu"># Plot polarity vs. (term reordered by polarity), filled by pos_or_neg</strong><br/>ggplot(data_tidy_pol, aes(reorder(words, polarity), polarity, fill = pos_or_neg)) +<br/>  geom_col() + <br/>  ggtitle("Coronavirus related tweets: Sentiment Word Frequency") + <br/>  <strong class="mu iu"># Rotate text and vertically justify</strong><br/>  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, size = 10))+<br/>  xlab("Word")</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/ef38ec13bc54367b39a18c6f43f521d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rpmQyDfjehdioDksH75Wiw.png"/></div></figure><h2 id="0dee" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">在提取的推文中使用的最积极和消极的词</h2><p id="5b4e" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">为了更全面地了解积极和消极词汇的使用情况，我使用“必应”词典给这些词分配了一种情绪，并做了一个简单的统计，以生成提取的推文中使用的前 10 个最常见的积极和消极词汇。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="6df0" class="lv lw it mu b gy my mz l na nb">word_counts &lt;- virus_tibble_clean %&gt;%<br/>  <strong class="mu iu"># Implement sentiment analysis using the "bing" lexicon</strong><br/>  inner_join(get_sentiments("bing"), by = c("words" = "word")) %&gt;%<br/> <strong class="mu iu"> # Count by word and sentiment</strong><br/>  count(words, sentiment)</span><span id="8cf9" class="lv lw it mu b gy nc mz l na nb">top_words &lt;- word_counts %&gt;%<br/>  <strong class="mu iu"># Group by sentiment</strong><br/>  group_by(sentiment) %&gt;%<br/>  <strong class="mu iu"># Take the top 10 for each sentiment</strong><br/>  top_n(10) %&gt;%<br/>  ungroup() %&gt;%<br/>  <strong class="mu iu"># Make word a factor in order of n</strong><br/>  mutate(words = reorder(words, n))</span><span id="4aa3" class="lv lw it mu b gy nc mz l na nb"><strong class="mu iu"># Use aes() to put words on the x-axis and n on the y-axis</strong><br/>ggplot(top_words, aes(words, n, fill = sentiment)) +<br/><strong class="mu iu"> # Make a bar chart with geom_col()</strong><br/>  geom_col(show.legend = FALSE) +<br/>  geom_text(aes(label = n, hjust=1), size = 3.5, color = "black") +<br/>  facet_wrap(~sentiment, scales = "free") +  <br/>  coord_flip() +<br/>  ggtitle("Most common positive and negative words")</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/645346437a1eb8058e2c632793020967.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*QrBtw8IjK1PvivpmIYrJpg.png"/></div></figure><h2 id="d2c5" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">情话云</h2><p id="21e5" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">将这些词分为不同类型的情绪也有助于我们了解人们对一个主题的感受，在这种情况下，这个主题就是冠状病毒疫情。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="425b" class="lv lw it mu b gy my mz l na nb">data_tidy &lt;- virus_tibble_clean %&gt;%<br/><strong class="mu iu">  # Inner join to nrc lexicon</strong><br/>  inner_join(get_sentiments("nrc"), by = c("words" = "word")) %&gt;% <br/> <strong class="mu iu"> # Drop positive or negative</strong><br/>  filter(!grepl("positive|negative", sentiment)) %&gt;% <br/>  <strong class="mu iu"># Count by sentiment and term</strong><br/>  count(sentiment, words) %&gt;% <br/>  <strong class="mu iu"># Spread sentiment, using n for values</strong><br/>  spread(sentiment, n, fill = 0)  %&gt;% <br/> <strong class="mu iu"> # Convert to data.frame, making term the row names</strong><br/>  data.frame(row.names = "words")</span><span id="6eda" class="lv lw it mu b gy nc mz l na nb"><strong class="mu iu"># Plot comparison cloud</strong><br/>comparison.cloud(data_tidy, max.words = 130, title.size = 1)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/8bbf28dbd7fe8adc84bb56d66f3b7299.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*I1SxhkAR4qll2S5p3qyu1A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">带有冠状病毒标签的推特上的情绪词云</p></figure><h2 id="6ac7" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">将情绪分为十种类型</h2><p id="bcc6" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">除了将单词分为两类(积极和消极)，我们还可以将单词分为多种情绪状态。在本节中，我们将单词分成十组，并在每组中选出前 10 个最常用的单词。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="29bd" class="lv lw it mu b gy my mz l na nb">data_sentiment %&gt;%<br/>  <strong class="mu iu"># Count by word and sentiment</strong><br/>  count(words, sentiment) %&gt;%<br/>  <strong class="mu iu"># Group by sentiment</strong><br/>  group_by(sentiment) %&gt;%<br/>  <strong class="mu iu"># Take the top 10 words for each sentiment</strong><br/>  top_n(10) %&gt;%<br/>  ungroup() %&gt;%<br/>  mutate(word = reorder(words, n)) %&gt;%<br/>  <strong class="mu iu"># Set up the plot with aes()</strong><br/>  ggplot(aes(words, n, fill = sentiment)) +<br/>  geom_col(show.legend = FALSE) +<br/>  facet_wrap(~ sentiment, scales = "free") +<br/>  coord_flip()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/c1b1c721f41b39a78cf1154717949d6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gr3FrpTReRh5HtMAd8IuwQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">推文分为十种情绪状态</p></figure><h2 id="2b7d" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">结论:从分析中得到一些有趣的见解</h2><ul class=""><li id="0cad" class="nh ni it lb b lc mo lf mp li nj lm nk lq nl lu nm nn no np bi translated">总体而言，这些推文传达了一种战胜冠状病毒的乐观情绪(使用“自豪”和“希望”等词的频率很高)。</li><li id="87e8" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated">当查看 unigram frequency 时,“false”这个词在其他词中脱颖而出，这表明 twitter 上有故意误导读者的新闻或故事。</li><li id="6363" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated">出现频率最高的词与美国国立卫生研究院(National Institutes of Health)冠状病毒疫苗的临床试验有关，这表明人们更关心找到疫情的治愈方法。</li><li id="99c5" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated">如果你仔细观察情绪状态分析图表，你会发现与其他情绪状态标签相比，带有快乐或积极标签的单词出现频率较低。</li></ul><p id="6d04" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意安全，保重！</p><p id="8a1d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="nd">编者按:</em> </strong> <em class="nd"> </em> <a class="ae ky" href="http://towardsdatascience.com/" rel="noopener" target="_blank"> <em class="nd">走向数据科学</em> </a> <em class="nd">是一份以数据科学和机器学习研究为主的中型刊物。我们不是健康专家或流行病学家，本文的观点不应被解释为专业建议。想了解更多关于疫情冠状病毒的信息，可以点击</em> <a class="ae ky" href="https://www.who.int/emergencies/diseases/novel-coronavirus-2019/situation-reports" rel="noopener ugc nofollow" target="_blank"> <em class="nd">这里</em> </a> <em class="nd">。</em></p></div></div>    
</body>
</html>