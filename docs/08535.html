<html>
<head>
<title>Forecasting Multiple Time-Series Using Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用神经网络预测多个时间序列</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/multiple-stock-prediction-using-deep-learning-network-d19a7acd8551?source=collection_archive---------13-----------------------#2020-06-21">https://towardsdatascience.com/multiple-stock-prediction-using-deep-learning-network-d19a7acd8551?source=collection_archive---------13-----------------------#2020-06-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="d0c1" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">多股票指数单神经网络</h2><div class=""/><div class=""><h2 id="99bf" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">利用 LSTM 进行时间序列预测</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/d5106cfd0bacba0ccd9caf73cf7387eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_5MyODrHmYqWkVqNieHMRQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</p></figure><p id="0fc0" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><a class="ae md" href="https://sarit-maitra.medium.com/membership" rel="noopener">https://sarit-maitra.medium.com/membership</a></p><p id="6b63" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi me translated"><span class="l mf mg mh bm mi mj mk ml mm di"> S </span>股票预测是一项艰巨的任务，因为产生的数据量巨大且高度非线性。建模这样的动态数据需要有效的建模技术，可以分析隐藏的模式和潜在的动态。神经网络是一种深度学习算法，能够通过自我学习过程识别和利用数据中存在的相互作用和模式。</p><p id="1893" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们将集中讨论一个简单的预测模型，该模型使用包含多个时间序列的长短期记忆结构。为了便于说明和更好地理解，我们将把整个练习保持为一个简单的过程。</p><p id="879d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们考虑四个不同的系列标准普尔 500 指数(^GSPC)、道琼斯工业平均指数(^DJI)、纳斯达克综合指数(^IXIC)和罗素 2000 指数(^RUT)，也就是芝加哥期权。我们的数据是从 1990 年至今。从 yahoo finance 检索到的数据被格式化为 Pandas DataFrame 对象。</p><pre class="ks kt ku kv gt mn mo mp mq aw mr bi"><span id="cf6c" class="ms mt it mo b gy mu mv l mw mx">stock = ['^RUT', '^GSPC', '^DJI', '^IXIC' ]<br/>start = pd.to_datetime('1990-01-03')<br/>df = web.DataReader(stock, data_source = 'yahoo', start = start )<br/>print(df.head())</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi my"><img src="../Images/204a74b1a710fc2ddcfb25ec1e327721.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YEL-j1XM0vjSDKrAExrK9Q.png"/></div></div></figure><p id="e7f3" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们在一个神经网络结构中拟合该系列的所有收盘价，并从那里预测一个系列。</p><pre class="ks kt ku kv gt mn mo mp mq aw mr bi"><span id="14c1" class="ms mt it mo b gy mu mv l mw mx">X = data.copy()<br/>X = X.drop(columns = [‘Date’])<br/>print(X.shape)<br/>print(X.tail())</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/993d1ef242e8a22a7965572d2993bf4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*nLSn_YJ-213BDtj3ywQybQ.png"/></div></figure><p id="1e1d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果我们看到相关性分析，我们就会知道为什么选择这 4 个系列。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi na"><img src="../Images/34815124cb58af00653aa8baf9c8a701.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*i-tkPW-Anik25VO8flEMLg.png"/></div></figure><h2 id="22da" class="ms mt it bd nb nc nd dn ne nf ng dp nh lq ni nj nk lu nl nm nn ly no np nq iz bi translated">数据分割:</h2><p id="a697" class="pw-post-body-paragraph lh li it lj b lk nr kd lm ln ns kg lp lq nt ls lt lu nu lw lx ly nv ma mb mc im bi translated">该时间序列分为训练集(80%)和测试集(20%)，如下所示。</p><pre class="ks kt ku kv gt mn mo mp mq aw mr bi"><span id="b4c9" class="ms mt it mo b gy mu mv l mw mx">split_ratio = 0.2<br/>X = X.values # Convert to NumPy array<br/>split = int(len(X) * (1-split_ratio))<br/>train_set = X[: split]<br/>test_set = X[split:]<br/>print(train_set.shape, test_set.shape)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/165c868c79e1338d0e02d5580cfae89a.png" data-original-src="https://miro.medium.com/v2/resize:fit:478/format:webp/1*4-sXzFM336x_7PeX3STe2Q.png"/></div></figure><h2 id="c847" class="ms mt it bd nb nc nd dn ne nf ng dp nh lq ni nj nk lu nl nm nn ly no np nq iz bi translated">监督学习:</h2><p id="5955" class="pw-post-body-paragraph lh li it lj b lk nr kd lm ln ns kg lp lq nt ls lt lu nu lw lx ly nv ma mb mc im bi translated">让我们以这样的方式格式化，监督学习可以应用于 ML 模型。这里，训练集和测试集将经历相同的转换。我们将实现以下功能的目标。</p><pre class="ks kt ku kv gt mn mo mp mq aw mr bi"><span id="21cf" class="ms mt it mo b gy mu mv l mw mx">def supvervisedSeries(data, n, h):<br/>  x, y = list (), list ()<br/>  for i in range (len(data)-n-h+1):<br/>    x.append(data[i:(i+n)])<br/>    y.append(data[i+h+n-1])<br/>  return np.array(x), np.array(y)</span><span id="73de" class="ms mt it mo b gy nx mv l mw mx">h = 1<br/>n = 4<br/>trainX, trainY = supvervisedSeries(training_set, n, h)<br/>testX, testY = supvervisedSeries(test_set, n, h)<br/>print("trainX: ", trainX.shape)<br/>print("trainY: ", trainY.shape)<br/>print("testX: ", testX.shape)<br/>print("testY: ", testY.shape)</span></pre><p id="d2b4" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">h =时间范围&amp; n =特征数量；这些参数是在转换之前选择的。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/6f67bc4a22e73450bfc789410972099d.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/format:webp/1*fYA3SqQgm7-RwNpI2l__SQ.png"/></div></figure><p id="50b8" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">现在，trainY 和 testY 必须按照所需的特征预测进行修改，因为默认情况下它包含所有 4 个特征。</p><pre class="ks kt ku kv gt mn mo mp mq aw mr bi"><span id="3ccb" class="ms mt it mo b gy mu mv l mw mx">testY = np.reshape(testY[:, 0], (testY [:, 0].shape[0], 1))<br/>trainY = np.reshape(trainY[:, 0], (trainY[:, 0].shape[0], 1))<br/>print(“trainY: “, trainY.shape)<br/>print(“testY: “, testY.shape)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/e15fbce96a3fe1114cb8c2b898e1ed9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:368/format:webp/1*JrFdskzAyeTCn9Qf7Urnmw.png"/></div></figure><p id="2c5a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在这里，我们选择了指数[0]，这是^RUT 每日调整收盘价格。</p><h2 id="4f6a" class="ms mt it bd nb nc nd dn ne nf ng dp nh lq ni nj nk lu nl nm nn ly no np nq iz bi translated">数据缩放:</h2><p id="7b49" class="pw-post-body-paragraph lh li it lj b lk nr kd lm ln ns kg lp lq nt ls lt lu nu lw lx ly nv ma mb mc im bi translated">ML 模型要求数据位于范围(0，1)内。我们使用了最小最大缩放器，它重新缩放数据集，使得所有特征值都在范围[0，1]内。它通常保持数据集的形状。</p><pre class="ks kt ku kv gt mn mo mp mq aw mr bi"><span id="2aa1" class="ms mt it mo b gy mu mv l mw mx">scalers = {}<br/>for i in range (trainX.shape[2]):<br/>  scalers[i] = MinMaxScaler()<br/>  trainX[:, :, i] = scalers[i].fit_transform(trainX[:, :, i])</span><span id="5fbb" class="ms mt it mo b gy nx mv l mw mx">for i in range(testX.shape[2]):<br/>  testX[:, :, i] = scalers[i].transform(testX[:, :, i])</span><span id="4ae9" class="ms mt it mo b gy nx mv l mw mx"># The target values are 2D arrays, which is easy to scale<br/>scalerY = MinMaxScaler()<br/>trainY = scalerY.fit_transform(trainY)<br/>testY = scalerY.transform(testY)</span></pre><h2 id="980f" class="ms mt it bd nb nc nd dn ne nf ng dp nh lq ni nj nk lu nl nm nn ly no np nq iz bi translated">前馈神经网络；</h2><p id="81fa" class="pw-post-body-paragraph lh li it lj b lk nr kd lm ln ns kg lp lq nt ls lt lu nu lw lx ly nv ma mb mc im bi translated">在下面，每层只有 100 个神经元用于处理我们的小数据集。此外，辍学作为一种正规化技术被用来减少过度拟合。密集类表示完全连接的图层。</p><pre class="ks kt ku kv gt mn mo mp mq aw mr bi"><span id="3d38" class="ms mt it mo b gy mu mv l mw mx"># Flatten input (to support multivariate input)<br/>n_input = trainX.shape[1] * trainX.shape[2]<br/>trainX = trainX.reshape((trainX.shape[0], n_input))</span><span id="8ad1" class="ms mt it mo b gy nx mv l mw mx">n_input = testX.shape[1] * testX.shape[2]</span><span id="f9d7" class="ms mt it mo b gy nx mv l mw mx">testX = testX.reshape((testX.shape[0], n_input))</span><span id="b684" class="ms mt it mo b gy nx mv l mw mx"># Create multilayered FFNN model<br/>model = Sequential()<br/>model.add(Dense(100, activation='relu', input_dim=trainX.shape[1]))<br/>model.add(Dropout(0.2))<br/>model.add(Dense(100, activation='relu'))<br/>model.add(Dropout(0.2))<br/>model.add(Dense(100, activation='relu'))<br/>model.add(Dense(trainY.shape[1]))<br/>model.compile(loss='mean_squared_error', optimizer='adam')<br/>model.summary()</span><span id="0f82" class="ms mt it mo b gy nx mv l mw mx"># Fit model<br/>history = model.fit(trainX, trainY, epochs =60, verbose =1)</span><span id="e69b" class="ms mt it mo b gy nx mv l mw mx"># Predict the test set<br/>predictions = model.predict(testX)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oa"><img src="../Images/d84527ecf09890918c8144cdacbfdee1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NuR0zKcBxKv2PJk9BhikOQ.png"/></div></div></figure><h2 id="6f63" class="ms mt it bd nb nc nd dn ne nf ng dp nh lq ni nj nk lu nl nm nn ly no np nq iz bi translated">模型评估:</h2><p id="cbfa" class="pw-post-body-paragraph lh li it lj b lk nr kd lm ln ns kg lp lq nt ls lt lu nu lw lx ly nv ma mb mc im bi translated">我们必须使用最初用于缩放数据的同一缩放器来缩放数据，以恢复原始值。</p><pre class="ks kt ku kv gt mn mo mp mq aw mr bi"><span id="5aaf" class="ms mt it mo b gy mu mv l mw mx"># Descale<br/>predictions = scalerY.inverse_transform(predictions)<br/>testY = scalerY.inverse_transform(testY)</span><span id="4c35" class="ms mt it mo b gy nx mv l mw mx"># Mean absolute error<br/>mae = mean_absolute_error(testY, predictions)<br/>print("Test MAE: %.6f" % mae)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/ae28de0dea204f5765d8bfc54ab9a664.png" data-original-src="https://miro.medium.com/v2/resize:fit:478/format:webp/1*rt9iD_mLaZ27a4JmQHMtsQ.png"/></div></figure><h2 id="e05c" class="ms mt it bd nb nc nd dn ne nf ng dp nh lq ni nj nk lu nl nm nn ly no np nq iz bi translated">图预测值与实际值:</h2><pre class="ks kt ku kv gt mn mo mp mq aw mr bi"><span id="2777" class="ms mt it mo b gy mu mv l mw mx">plt.figure(figsize=(15,6))<br/>plt.plot(predictions, label="Test set predictions" )<br/>plt.plot(testY, label="Real data")<br/>plt.legend()<br/>plt.ylabel('Price Index')<br/>plt.xlabel('time step' )<br/>plt.title ("Russell 2000 Adj close Price prediction- with MAE {:10.4f}".format(mae))<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ob"><img src="../Images/f58c722311a83b7879ac03db6e34af0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8_l10x9iiXre3QKNk6MWXg.png"/></div></div></figure><p id="0ff3" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这里可以看出，我们的网络架构能够提取数据中隐藏的趋势；同样，其他系列也可以通过选择合适的尺度来预测所选的系列。</p><h1 id="f551" class="oc mt it bd nb od oe of ne og oh oi nh ki oj kj nk kl ok km nn ko ol kp nq om bi translated">结论</h1><p id="8b08" class="pw-post-body-paragraph lh li it lj b lk nr kd lm ln ns kg lp lq nt ls lt lu nu lw lx ly nv ma mb mc im bi translated">我们可以看到，深度神经网络架构能够捕捉隐藏的动态，并能够做出预测。为了简单起见，我们只是拟合了一个简单的 LSTM 网络，没有优化网络的任何参数。为了建立一个健壮的网络，我们必须研究正确的参数，如时期数、批量、神经元数、隐藏层数等。</p><p id="a0e5" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">接我这里</strong><a class="ae md" href="https://www.linkedin.com/in/saritmaitra/" rel="noopener ugc nofollow" target="_blank"><strong class="lj jd"><em class="on"/></strong></a><strong class="lj jd">。</strong></p></div></div>    
</body>
</html>