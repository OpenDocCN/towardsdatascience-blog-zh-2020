<html>
<head>
<title>This is Hogwild!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">这是猪崽子。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/this-is-hogwild-7cc80cd9b944?source=collection_archive---------18-----------------------#2020-02-03">https://towardsdatascience.com/this-is-hogwild-7cc80cd9b944?source=collection_archive---------18-----------------------#2020-02-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="fe20" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在PyTorch中加速您的神经网络训练</h2></div><p id="9a6e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我目前正在攻读分布式机器学习领域的博士学位。我注意到并行过程在日常机器学习中并不常用。因此，我想谈谈PyTorch的多重处理。在这篇博文中，你将会了解到野猪！算法，用于以并行方式运行随机梯度下降(SGD)。由于列出的论文涵盖了所有必要的数学知识，我就不赘述了。相反，我将用PyTorch解释一般的想法并给出一个非常简单的例子。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/f39085c8a2630529c3453aa2f0f1b1db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*a0KYNrgvDbZ98_fK"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">在<a class="ae lr" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae lr" href="https://unsplash.com/@tumbao1949?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> James Wainscoat </a>拍摄</p></figure><h1 id="aadd" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">为什么平行？</h1><p id="6691" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">如果你曾经在你的机器上自己训练过神经网络，你可能已经注意到了这样做所消耗的时间和计算能力。尤其是在使用大数据集进行计算机视觉或其他高维训练数据时。麻省理工学院最近的一篇文章显示，训练一个人工智能算法可以产生大量的碳(<a class="ae lr" href="https://www.technologyreview.com/s/613630/training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-lifetimes/" rel="noopener ugc nofollow" target="_blank">链接到文章</a>)。这说明了AI模型训练所需要的必要力量。因此，如果花费的时间太长，应该使用减少总训练时间的并行过程。</p><h1 id="8416" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">猪猡！解释</h1><p id="eb83" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">一个可能的算法是Hogwild！它利用计算机上的并行进程同时异步运行SGD。异步对于减少不必要的空闲时间很重要，在空闲时间里没有计算，但是仍然消耗能量。</p><h2 id="dbe2" class="mp lt iq bd lu mq mr dn ly ms mt dp mc ko mu mv me ks mw mx mg kw my mz mi na bi translated">数据管理</h2><p id="6218" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">利用猪八戒！并行训练会话中的每个参与过程负责数据的一个分区，例如，具有8个并行过程会将数据集分成8个相等的部分，而每个过程被分配给一个部分。此外，在共享内存或单独的服务器上，会创建一个可由所有进程访问的初始模型。</p><h2 id="868a" class="mp lt iq bd lu mq mr dn ly ms mt dp mc ko mu mv me ks mw mx mg kw my mz mi na bi translated">更新</h2><p id="dbf4" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">一旦训练开始，每个进程从共享内存加载模型的当前状态，并开始读取它们的第一批数据分区。与标准SGD一样，每个过程都在计算该批次的梯度。梯度现在被直接写入共享模型，而不会阻塞其他过程。一旦写入，就加载新的模型参数并使用下一批参数。由于缺少分块，共享模型有时会接收到旧的梯度，人们可能会认为这是一个缺点。霍格维尔德的研究者们！然而，可以显示训练甚至受益于非阻塞方式。</p><h1 id="4ff7" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">分布式Hogwild！</h1><p id="1ea0" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">利用猪八戒！在分布式计算机上，集群具有巨大的通信开销，因为在每一批之后，梯度需要通过网络发送。因此，Hogwild++被开发出来，它通过将进程(即每台计算机)组织成一个环来减少开销。训练时，通过那个环发送一个令牌。令牌带有全局模型。每当一个令牌到达一个节点时，模型权重之间的差被计算并用于以非平凡的方式更新模型。欲了解更多详情，本文最后有链接。</p><h1 id="26d3" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">PyTorch中的实现</h1><p id="fd98" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">这个代码例子是受<a class="ae lr" href="https://pytorch.org/docs/stable/notes/multiprocessing.html" rel="noopener ugc nofollow" target="_blank">这个链接</a>的启发，给出了一个如何实现标准Hogwild的例子！PyTorch中的算法。</p><p id="e8f5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，我们用卷积层实现了一个简单的图像分类模型。该模型返回在训练期间使用NLLLoss时有用的LogSoftmax。</p><pre class="lc ld le lf gt nb nc nd ne aw nf bi"><span id="5d55" class="mp lt iq nc b gy ng nh l ni nj"><strong class="nc ir">class </strong>Model(nn.Module):<br/>    <strong class="nc ir">def </strong>__init__(self):<br/>        super().__init__()<br/>        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)<br/>        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)<br/>        self.conv2_drop = nn.Dropout2d()<br/>        self.fc1 = nn.Linear(500, 10)<br/>        self.fc2 = nn.Linear(10, 10)<br/><br/>    <strong class="nc ir">def </strong>forward(self, x, **kwargs):<br/>        batch_size = x.shape[0]<br/>        x = F.relu(F.max_pool2d(self.conv1(x), 2))<br/>        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))<br/>        x = x.view(batch_size, -1)<br/>        x = F.relu(self.fc1(x))<br/>        x = F.dropout(x, training=self.training)<br/>        x = self.fc2(x)<br/>        x = F.log_softmax(x, dim=1)<br/>        <strong class="nc ir">return </strong>x</span></pre><p id="2b82" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，我们定义了一个训练函数，它以一个模型和一个数据加载器作为输入参数。在这个函数中，使用了Adam优化器和前面提到的NLLLoss。这个培训功能是PyTorch程序的标准实现。参与Hogwild的每个流程！会同时叫它。</p><pre class="lc ld le lf gt nb nc nd ne aw nf bi"><span id="cbf9" class="mp lt iq nc b gy ng nh l ni nj"><strong class="nc ir">def </strong>train(model, data_loader):<br/>    optimizer = optim.Adam(model.parameters())<br/>    criterion = nn.NLLLoss()<br/><br/>    <strong class="nc ir">for </strong>data, labels <strong class="nc ir">in </strong>tqdm.tqdm(data_loader):<br/>        optimizer.zero_grad()<br/>        loss = criterion(model(data), labels)<br/>        loss.backward()        <br/>        optimizer.step()</span></pre><p id="dc38" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">并行设置发生在下一个代码部分。在这里，我们定义了并行进程的数量，实例化了模型，并通过一个方法调用<em class="nk"> share_memory </em>将其推送到共享内存中。使用的数据集是CIFAR10数据集，可在torchvision包中获得。</p><p id="b6d3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们对流程进行循环，并为每个流程定义一个数据加载器。数据加载器拥有一个分布式采样器，它知道进程的等级并处理数据的分布。因此，每个进程都有自己的数据分区。多重处理包调用每个进程内的训练函数并等待，用<em class="nk">加入</em>命令，<em class="nk"> </em>等待进程结束。</p><pre class="lc ld le lf gt nb nc nd ne aw nf bi"><span id="1304" class="mp lt iq nc b gy ng nh l ni nj"><strong class="nc ir">import </strong>torch.multiprocessing <strong class="nc ir">as </strong>mp</span><span id="0e99" class="mp lt iq nc b gy nl nh l ni nj">num_processes = 4<br/>model = Model()<br/>model.share_memory()<br/><br/>dataset = CIFAR10(<br/>            <strong class="nc ir">"data"</strong>,<br/>            train=<strong class="nc ir">True</strong>,<br/>            download=<strong class="nc ir">True</strong>,<br/>            transform=transforms.Compose([<br/>                transforms.ToTensor(),<br/>                transforms.Normalize(<br/>                    mean=[0.485, 0.456, 0.406],<br/>                    std=[0.229, 0.224, 0.225]<br/>                )<br/>            ])<br/>        )</span><span id="6313" class="mp lt iq nc b gy nl nh l ni nj">processes = []<br/><strong class="nc ir">for </strong>rank <strong class="nc ir">in </strong>range(num_processes):<br/>    data_loader = DataLoader(<br/>        dataset=dataset,<br/>        sampler=DistributedSampler(<br/>            dataset=dataset,<br/>            num_replicas=num_processes,<br/>            rank=rank<br/>        ),<br/>        batch_size=32<br/>    )<br/>    p = mp.Process(target=train, args=(model, data_loader))<br/>    p.start()<br/>    processes.append(p)<br/><strong class="nc ir">for </strong>p <strong class="nc ir">in </strong>processes:<br/>    p.join()</span></pre><p id="91e4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在训练期间，所有的进程都可以访问共享模型，但是只在它们自己的数据分区上训练。因此，我们将训练时间减少了大约4，这是总训练过程的数量。</p><p id="f9ad" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">完整的代码可以在我的<a class="ae lr" href="https://github.com/wenig/hogwild" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>中找到。</p><h1 id="046b" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论</h1><p id="21cc" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">分配机器学习的训练变得更加重要。尤其是随着训练数据和数据复杂度的增加。总的来说，分布式训练节省了大量时间，并且还可以使用智能分配技术来减少消耗的能量。代码示例显示，使用PyTorch应用并行机器学习训练非常容易。</p><h1 id="090d" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">资源</h1><p id="a46b" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">猪猡！:<a class="ae lr" href="https://papers.nips.cc/paper/4390-hogwild-a-lock-free-approach-to-parallelizing-stochastic-gradient-descent.pdf" rel="noopener ugc nofollow" target="_blank">https://papers . nips . cc/paper/4390-hog wild-a-lock-free-approach-to-parallelism-random-gradient-descent . pdf</a></p><p id="2604" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">http://www.stat.ucdavis.edu/~chohsieh/wildSGD.pdf<a class="ae lr" href="http://www.stat.ucdavis.edu/~chohsieh/wildSGD.pdf" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>