<html>
<head>
<title>Decision Tree Essentials for Every Data Scientist</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">每位数据科学家必备的决策树</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/decision-tree-essentials-for-every-data-scientist-9d2cbb1f3ae9?source=collection_archive---------41-----------------------#2020-05-21">https://towardsdatascience.com/decision-tree-essentials-for-every-data-scientist-9d2cbb1f3ae9?source=collection_archive---------41-----------------------#2020-05-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/4ba55ac7309d5da607de8c6db20aa197.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*lpPhdLQ2wDCtlfuGtn1MNw.jpeg"/></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">图片来自<a class="ae kb" href="https://pixabay.com/users/jplenio-7645255/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3097419" rel="noopener ugc nofollow" target="_blank">我的图片是 CC0。作曲时:<a class="ae kb" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3097419" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的</a></p></figure><h1 id="6097" class="kc kd it bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">决策树介绍</h1><p id="ca30" class="pw-post-body-paragraph la lb it lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">决策树是一种非常有用的分类方法，非常适合用最少的代码启动和运行。</p><p id="37db" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">我使用了某种形式的决策树来预测客户流失的可能性、客户转换、新产品采用、新功能采用，以及许多其他有用的应用。</p><p id="7e15" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">这个简短的介绍将让你了解使用决策树作为分类工具的主要好处和局限性。</p><p id="333c" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">我还将带您完成构建您自己的决策树的步骤，同样重要的是，测试它的性能。</p><h1 id="caa8" class="kc kd it bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">何时以及为何使用决策树</h1><p id="a2eb" class="pw-post-body-paragraph la lb it lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">说到分类，使用决策树分类器是最容易使用的方法之一。</p><h2 id="c5ff" class="md kd it bd ke me mf dn ki mg mh dp km ll mi mj kq lp mk ml ku lt mm mn ky mo bi translated">为什么要使用决策树</h2><ul class=""><li id="9ae4" class="mp mq it lc b ld le lh li ll mr lp ms lt mt lx mu mv mw mx bi translated">非常容易理解</li><li id="08b5" class="mp mq it lc b ld my lh mz ll na lp nb lt nc lx mu mv mw mx bi translated">它可以很好地处理丢失的数据和异常值，因此需要更少的前期清理</li><li id="f651" class="mp mq it lc b ld my lh mz ll na lp nb lt nc lx mu mv mw mx bi translated">您可以放弃分类变量编码，因为决策树可以很好地处理分类！</li><li id="b50d" class="mp mq it lc b ld my lh mz ll na lp nb lt nc lx mu mv mw mx bi translated">无需深入递归划分的细节，决策树就能够模拟非线性关系。</li></ul><h2 id="6172" class="md kd it bd ke me mf dn ki mg mh dp km ll mi mj kq lp mk ml ku lt mm mn ky mo bi translated">为什么不使用决策树呢</h2><p id="b17e" class="pw-post-body-paragraph la lb it lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">尽管有这么多好处，但它们并不总是完美的选择。</p><ul class=""><li id="ddc0" class="mp mq it lc b ld ly lh lz ll nd lp ne lt nf lx mu mv mw mx bi translated">同样，它们可能很简单，也可能过于复杂，几乎无法概念化或解释。</li><li id="c5b4" class="mp mq it lc b ld my lh mz ll na lp nb lt nc lx mu mv mw mx bi translated">更进一步说，如果一个树过于偏向或复杂，它可能会太好地迎合其训练数据，结果是过度拟合。</li></ul><h1 id="0c4b" class="kc kd it bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">模特培训</h1><p id="35ca" class="pw-post-body-paragraph la lb it lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">说到这里，让我们开始吧。我不会谈论交叉验证或训练，测试分裂，但会张贴下面的代码。如果你想得到更多的解释，一定要发表评论。</p><p id="f452" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">首先，我们将数据分成训练集和测试集。</p><p id="a324" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">还要注意，我们将使用经典的泰坦尼克号数据集，它包含在 base R 中。</p><pre class="ng nh ni nj gt nk nl nm nn aw no bi"><span id="55fc" class="md kd it nl b gy np nq l nr ns">n &lt;- nrow(Titanic)</span><span id="cbc5" class="md kd it nl b gy nt nq l nr ns">n_train &lt;- round(0.8 * n)</span><span id="7ec6" class="md kd it nl b gy nt nq l nr ns">set.seed(123)<br/>train_indices &lt;- sample(1:n, n_train)<br/>train &lt;- Titanic[train_indices, ]  <br/>test &lt;- Titanic[-train_indices, ]</span></pre><p id="5184" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">现在我们将使用<code class="fe nu nv nw nl b">rpart</code>包中的<code class="fe nu nv nw nl b">rpart</code>函数来训练模型。这里需要注意的关键是，我们想要预测的变量是存活的，所以我们想要根据一些数据了解任何给定个体存活的可能性。~可以由解释为<em class="nx">；换句话说，让我们理解一些变量的存在。如果在~后面有一个。这意味着我们想用数据集中的其他变量来预测存活。或者，如下所示，我们可以明确地调用我们想要使用的变量。</em></p><p id="aa31" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">另外要注意的是，<code class="fe nu nv nw nl b">method</code>是<code class="fe nu nv nw nl b">class</code>。这是因为我们希望创建一个预测分类结果的分类树，而不是用于数字结果的回归树。最后，我们用来训练模型的数据是<code class="fe nu nv nw nl b">train</code>。</p><pre class="ng nh ni nj gt nk nl nm nn aw no bi"><span id="e287" class="md kd it nl b gy np nq l nr ns">model &lt;- rpart(formula = Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked,<br/>            data = titanic_train, <br/>            method = "class")</span></pre><h1 id="c597" class="kc kd it bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">可解释性</h1><p id="5b6c" class="pw-post-body-paragraph la lb it lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">如前所述，决策树如此容易使用的原因之一是它非常容易解释。你可以沿着树的不同分支走向不同的结果。</p><pre class="ng nh ni nj gt nk nl nm nn aw no bi"><span id="320c" class="md kd it nl b gy np nq l nr ns">rpart.plot(model)</span></pre><figure class="ng nh ni nj gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="nz oa di ob bf oc"><div class="gh gi ny"><img src="../Images/95e24daca5c7c503b224515423fe14ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Zt9bZDvUFhryW4k3.png"/></div></div></figure><p id="a741" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">在那里阅读有点困难，但是如果你放大一点，你会看到如果有人可能在泰坦尼克号上生活或死亡的第一个标准是你是否是男性。如果你是男性，你移到左边的分支，向下两个节点，不管你是成年人还是你的兄弟姐妹/配偶。因此，如果你是一个单身男人，你的生存几率非常小。</p><h1 id="74e1" class="kc kd it bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">性能赋值</h1><p id="e88e" class="pw-post-body-paragraph la lb it lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">在我们分解指标之前，让我们预测一下测试集的值。与训练调用类似，您选择数据和预测类型。核心区别在于型号规格。</p><pre class="ng nh ni nj gt nk nl nm nn aw no bi"><span id="c7dd" class="md kd it nl b gy np nq l nr ns">test$pred &lt;- predict(object = model,  <br/>                            newdata = test,   <br/>                            type = "class")</span></pre><p id="c3db" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">在理解决策树的功效时，有各种各样的性能评估指标会非常方便。</p><h2 id="bff7" class="md kd it bd ke me mf dn ki mg mh dp km ll mi mj kq lp mk ml ku lt mm mn ky mo bi translated">准确(性)</h2><p id="e8cf" class="pw-post-body-paragraph la lb it lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">这个指标很简单，你的预测有多少是正确的。<code class="fe nu nv nw nl b">caret</code>的混淆矩阵函数就包含了这个。</p><h2 id="cf16" class="md kd it bd ke me mf dn ki mg mh dp km ll mi mj kq lp mk ml ku lt mm mn ky mo bi translated">混淆矩阵</h2><p id="e2d8" class="pw-post-body-paragraph la lb it lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated"><code class="fe nu nv nw nl b">caret</code>包中的<code class="fe nu nv nw nl b">confusionMatrix</code>功能非常有用。用于评估分类模型性能。加载这个包，把你的预测和实际数据传给它。</p><pre class="ng nh ni nj gt nk nl nm nn aw no bi"><span id="12ed" class="md kd it nl b gy np nq l nr ns">library(caret)<br/>confusionMatrix(data = test$pred,       <br/>                reference = test$Survived)</span></pre><figure class="ng nh ni nj gt ju gh gi paragraph-image"><div class="gh gi od"><img src="../Images/752a023228ddec0f4ceb462238504171.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/0*r5gYZ3ecZTEX1315.png"/></div></figure><p id="3b3c" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">这个函数向你展示的第一件事就是所谓的混淆矩阵。这将向您显示一个预测值和实际值如何匹配的表格。所以预测值和参考值相同的对角线单元格代表我们得到的正确值。将这些记录加起来 149 (106 + 43)并除以记录总数，178；我们达到了 83.4%的准确率。</p><p id="bbe8" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">True positive:象限中引用和预测都为 1 的单元格。这表明你预测了存活，而他们确实存活了下来。</p><p id="7754" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">假阳性:这里你预测为阳性，但你错了。</p><p id="8f89" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">真阴性:当你预测为阴性，并且你是正确的。</p><p id="761a" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">假阴性:当你预测为阴性，而你是不正确的。</p><p id="823f" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">需要记住的几个关键指标是灵敏度和特异性。敏感度是您正确预测的真实记录的百分比。</p><p id="8b7b" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">另一方面，特异性是衡量实际错误记录中你正确预测的部分。</p><p id="2c0d" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">在不平衡数据集上进行预测时，要记住特异性。一个非常常见的例子就是对垃圾邮件进行分类。99%的情况下它不是垃圾邮件，所以如果你预测没有垃圾邮件，你有 99%的准确率，但你的特异性是 0，导致所有的垃圾邮件都被接受。</p><h1 id="9163" class="kc kd it bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">结论</h1><p id="faa6" class="pw-post-body-paragraph la lb it lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">总结我们对决策树的讨论，我们知道它们非常有用，因为它们非常容易解释，只需要最少的预处理，它们可以模拟非线性关系，并且它们具有可以轻松修复不平衡分类问题的功能。不平衡数据集</p><p id="c007" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">另一方面，当对更复杂的关系建模时，决策树可能非常难以理解，并且很容易过度拟合。</p><p id="c078" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">当您开始利用这种建模技术时，请记住这一点。</p><p id="4f6e" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">我希望你喜欢这堂关于决策树的快速课。让我知道你是否想要更多的信息，或者你是否想要我在另一篇文章中报道一些事情。</p><p id="b883" class="pw-post-body-paragraph la lb it lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx im bi translated">祝数据科学快乐！如果你喜欢这个，来看看 datasciencelessons.com 的其他帖子吧！</p></div></div>    
</body>
</html>