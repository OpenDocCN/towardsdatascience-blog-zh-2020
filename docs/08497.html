<html>
<head>
<title>Linear Regression Model for Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习的线性回归模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/linear-regression-model-for-ml-cd18a392bd8b?source=collection_archive---------28-----------------------#2020-06-20">https://towardsdatascience.com/linear-regression-model-for-ml-cd18a392bd8b?source=collection_archive---------28-----------------------#2020-06-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e197" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">概述最古老的监督机器学习算法，它的类型和缺点。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b92db1489f2e7aabbc3a381fd8c69b9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MOOnaKE_tBE8U23zsNSHBA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由来自<a class="ae ky" href="https://www.pexels.com/photo/summer-pattern-texture-plant-136740/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">佩克斯</a>的<a class="ae ky" href="https://www.pexels.com/@scottwebb?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">斯科特·韦伯</a>拍摄</p></figure><p id="1ac8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">线性回归是基本的监督机器学习算法之一。虽然它相对简单，与其他机器学习算法相比可能不够花哨，但它仍然广泛应用于各个领域，如生物学、社会科学、金融、市场营销。它非常强大，可以用来预测趋势或产生洞察力。因此，在学习更复杂的ML技术之前，彻底了解线性回归——它的工作原理和变体——是多么重要，我怎么强调都不为过。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><blockquote class="mc"><p id="4b66" class="md me it bd mf mg mh mi mj mk ml lu dk translated">线性回归模型非常强大，可以用来预测趋势和产生洞察力。</p></blockquote></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="233c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文的目的是提供一个线性回归模型的全面概述。它将为最后一分钟的修改或开发详细研究线性回归的思维导图提供极好的指导。</p><p id="3199" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mm">注意:在本文中，我们将使用流行的Boston Housing数据集，该数据集可以使用sklearn.datasets直接导入到Python中，或者使用库MASS(现代应用统计函数)导入到R中。代码块是用r编写的</em></p><h1 id="d6fb" class="mn mo it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated">什么是线性回归？</h1><p id="ad8e" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">线性回归是一种统计/机器学习技术，它试图对独立预测变量X和相关定量响应变量y之间的线性关系进行建模。预测变量和响应变量必须是数值，这一点很重要。一般的线性回归模型在数学上可以表示为</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/c44d42a26aeac905567b66ac233aa824.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J_5IN7D3Sgt7-O0gLaZ6FA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">线性回归模型方程；作者图片</p></figure><p id="b0b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于线性回归模型<strong class="lb iu">通过捕捉不可约的误差项来近似Y和X之间的关系</strong>,我们得到</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/ef0d6713b6af506a38765bc6278543a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nxb4wGLNwr8sbY9YHK-pFA@2x.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">带有近似值的线性回归模型方程；作者图片</p></figure><p id="eba4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，我们将使用线性回归来预测波士顿周围506个社区的中值房价(Y/响应变量= medv)。</p><h2 id="6c69" class="nm mo it bd mp nn no dn mt np nq dp mx li nr ns mz lm nt nu nb lq nv nw nd nx bi translated">线性回归揭示了哪些真知灼见？</h2><p id="135c" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">使用线性回归预测中值房价将有助于回答以下五个问题:</p><ol class=""><li id="b8aa" class="ny nz it lb b lc ld lf lg li oa lm ob lq oc lu od oe of og bi translated">预测变量和响应变量之间存在线性关系吗？</li><li id="b092" class="ny nz it lb b lc oh lf oi li oj lm ok lq ol lu od oe of og bi translated">预测变量和反应变量之间有联系吗？有多强？</li><li id="5680" class="ny nz it lb b lc oh lf oi li oj lm ok lq ol lu od oe of og bi translated">每个预测变量如何影响响应变量？</li><li id="3c4f" class="ny nz it lb b lc oh lf oi li oj lm ok lq ol lu od oe of og bi translated">响应变量的预测有多准确？</li><li id="04b6" class="ny nz it lb b lc oh lf oi li oj lm ok lq ol lu od oe of og bi translated">自变量之间有交互作用吗？</li></ol><h2 id="945b" class="nm mo it bd mp nn no dn mt np nq dp mx li nr ns mz lm nt nu nb lq nv nw nd nx bi translated">线性回归模型的类型</h2><p id="f7c1" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">根据预测变量的数量，线性回归可分为两类:</p><ol class=""><li id="751e" class="ny nz it lb b lc ld lf lg li oa lm ob lq oc lu od oe of og bi translated">简单线性回归-一个预测变量。</li><li id="7b34" class="ny nz it lb b lc oh lf oi li oj lm ok lq ol lu od oe of og bi translated">多元线性回归-两个或多个预测变量。</li></ol><p id="ff65" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">线性回归模型的简单性可以归功于它的核心假设。然而，这些假设在模型中引入了偏差，导致过度泛化/欠拟合(更多关于<a class="ae ky" href="https://medium.com/@pardeshi.vishwa25/bias-variance-tradeoff-explained-7f18ebbef020" rel="noopener">偏差-方差权衡</a>)。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><blockquote class="mc"><p id="12f3" class="md me it bd mf mg mh mi mj mk ml lu dk translated">一个<!-- -->容易记住的线性回归模型的假设的首字母缩略词是直线</p></blockquote></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="c72f" class="mn mo it bd mp mq om ms mt mu on mw mx jz oo ka mz kc op kd nb kf oq kg nd ne bi translated">线性回归模型的假设</h1><p id="445a" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">LINE——一个简单的缩写词，包含线性回归模型的四个假设。</p><ol class=""><li id="6102" class="ny nz it lb b lc ld lf lg li oa lm ob lq oc lu od oe of og bi translated"><strong class="lb iu"> L </strong>线性关系:预测器&amp;响应变量之间的关系是线性的。</li><li id="9262" class="ny nz it lb b lc oh lf oi li oj lm ok lq ol lu od oe of og bi translated">独立观测值:数据集中的观测值是相互独立的。</li><li id="6973" class="ny nz it lb b lc oh lf oi li oj lm ok lq ol lu od oe of og bi translated">残差的正态分布。</li><li id="671b" class="ny nz it lb b lc oh lf oi li oj lm ok lq ol lu od oe of og bi translated">误差/残差具有恒定的方差:也称为同方差。</li></ol><h1 id="53ab" class="mn mo it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated">简单线性回归</h1><p id="b1b5" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">一个简单的学习回归模型使用单个预测变量x来预测响应变量Y。对于波士顿住房数据集，在分析中值住房价值/ medv列和12个预测列之间的相关性后，带有几个相关列的medv散点图如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/a360dba65138783b54dd8cf7368f0864.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o-opODxHUGOkOmlny98M6Q@2x.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图1:波士顿住房数据集的散点图；作者图片</p></figure><p id="a17a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在观察散点图时，我们注意到medv和rm(平均房间数)几乎成线性关系。因此，它们的关系可以表示为</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/9320c1146b2b2ef08840f18ea0946106.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yb5aMcmT_2xTSY70mqf9tQ@2x.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">中位数价格预测广义方程；作者图片</p></figure><p id="b962" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">目标是通过估计尽可能接近506个数据点的拟合系数来拟合线性模型。预测值和观察值之间的差异是误差，需要将其最小化以找到最佳拟合。最小化误差的最小平方的一种常用方法是普通最小二乘法(OLS法)。</p><p id="535c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要在R中创建一个简单的线性回归模型，运行下面的代码块:</p><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="8d23" class="nm mo it ou b gy oy oz l pa pb">simpleLinearModel &lt;- lm(medv ~ rm, data = Boston)</span></pre><p id="c20d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看合身的模型，</p><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="3714" class="nm mo it ou b gy oy oz l pa pb">plot(rm ,medv)<br/>abline(simpleLinearModel, col = ‘red’)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/d28c198278c6e5bf0bf1ab5966c503ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iNvSD7YQtiJtUsQrLvMVrw@2x.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图2:拟合训练数据的简单线性回归线；作者图片</p></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><blockquote class="mc"><p id="4236" class="md me it bd mf mg mh mi mj mk ml lu dk translated"><strong class="ak"> <em class="pd">使用RSE，R，adjusted R，F-statistic评估线性回归模型的准确性。</em> </strong></p></blockquote></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="235f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">模型摘要(下图)告诉我们有关系数的信息，并有助于使用以下指标评估模型的准确性</p><ul class=""><li id="d30a" class="ny nz it lb b lc ld lf lg li oa lm ob lq oc lu pe oe of og bi translated">剩余标准误差</li><li id="8d59" class="ny nz it lb b lc oh lf oi li oj lm ok lq ol lu pe oe of og bi translated">r统计量</li><li id="b68e" class="ny nz it lb b lc oh lf oi li oj lm ok lq ol lu pe oe of og bi translated">调整后的R平方</li><li id="d7f7" class="ny nz it lb b lc oh lf oi li oj lm ok lq ol lu pe oe of og bi translated">f统计量</li></ul><p id="492e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">量化模型与训练数据的吻合程度。</p><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="5261" class="nm mo it ou b gy oy oz l pa pb">print(summary(simpleLinearModel))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pf"><img src="../Images/20e58efff0568bddd432fc536e26ae90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*16_Z2cVWNGb4LuVw5R-Hng@2x.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图3:简单线性回归模型汇总；作者图片</p></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="8684" class="nm mo it bd mp nn no dn mt np nq dp mx li nr ns mz lm nt nu nb lq nv nw nd nx bi translated">如何解读简单线性回归模型？</h2><p id="3c4c" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">使用简单的线性回归来预测中值房价，我们可以回答以下问题:</p><ul class=""><li id="b416" class="ny nz it lb b lc ld lf lg li oa lm ob lq oc lu pe oe of og bi translated"><strong class="lb iu"><em class="mm">RM&amp;medv之间有关联吗？有多强？</em>T3】</strong></li></ul><p id="a47e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">medv和rm之间的关联及其强度可以通过观察对应于汇总表中F统计量的p值来确定(图3)。由于p值非常低，medv和rm之间有很强的相关性。</p><ul class=""><li id="1300" class="ny nz it lb b lc ld lf lg li oa lm ob lq oc lu pe oe of og bi translated"><strong class="lb iu"><em class="mm">RM如何影响medv？</em> </strong></li></ul><p id="0166" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据这个简单的线性回归模型，房间数量的单位增加导致中值房价增加9.102万美元。</p><ul class=""><li id="5976" class="ny nz it lb b lc ld lf lg li oa lm ob lq oc lu pe oe of og bi translated"><strong class="lb iu"> <em class="mm">响应变量的预测有多准确？</em>T11】</strong></li></ul><p id="904d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">RSE估计了medv与真实回归线的标准偏差，该值仅为6.616，但表明误差约为30%。另一方面，R表明在medv中只有48%的可变性是由rm解释的。调整后的R &amp; F统计量是多元线性回归的有用度量。</p><ul class=""><li id="f30f" class="ny nz it lb b lc ld lf lg li oa lm ob lq oc lu pe oe of og bi translated"><strong class="lb iu"> <em class="mm">房屋价值中位数(medv) &amp;房屋的房间数(rm)之间存在线性关系吗？</em>T15】</strong></li></ul><p id="f4da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">除了使用图1来确定medv和rm之间的几乎线性关系外，如果不存在模式，图3所示的残差图有助于确定线性关系。因为有一个小的模式，它表明在关系中有一个非线性成分，尽管有点弱。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pg"><img src="../Images/c483b1f8c1c1868f7bd0a3513025c2c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TCEuUhf7wdXkhiso7NTNUg@2x.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图4:用平滑线识别趋势的残差图；作者图片</p></figure><h1 id="6565" class="mn mo it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated">多元线性回归</h1><p id="f01c" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">多元线性回归模型试图对两个或多个预测变量和响应变量之间的线性关系进行建模。一个人想到的最重要的问题是</p><blockquote class="mc"><p id="d159" class="md me it bd mf mg mh mi mj mk ml lu dk translated"><strong class="ak">“如何选择有用的预测变量？”</strong></p></blockquote><p id="6d55" class="pw-post-body-paragraph kz la it lb b lc ph ju le lf pi jx lh li pj lk ll lm pk lo lp lq pl ls lt lu im bi translated">这就是所谓的<strong class="lb iu">回归变量选择</strong>可以通过使用:</p><ol class=""><li id="4ed3" class="ny nz it lb b lc ld lf lg li oa lm ob lq oc lu od oe of og bi translated">最佳子集选择</li><li id="ff13" class="ny nz it lb b lc oh lf oi li oj lm ok lq ol lu od oe of og bi translated">逐步选择—向前、向后、混合</li></ol><p id="ec06" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有很多其他方法可以达到这个目的。通过使用逐步向前选择，我发现除了年龄和印度河流域以外的所有预测变量对预测medv都很重要。</p><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="58b6" class="nm mo it ou b gy oy oz l pa pb">#Variable selection using stepwise regression<br/>nullmodel &lt;- lm(medv ~ 1, data = Boston)<br/>fullmodel &lt;- lm(medv ~ ., data = Boston)</span><span id="8af8" class="nm mo it ou b gy pm oz l pa pb">#Forward Stepwise Selection<br/>mulitpleLinearModel &lt;- step(nullmodel, scope = list(lower = nullmodel, upper = fullmodel), direction = "forward")</span></pre><h2 id="1cfe" class="nm mo it bd mp nn no dn mt np nq dp mx li nr ns mz lm nt nu nb lq nv nw nd nx bi translated">如何解读多元线性回归模型？</h2><p id="40ad" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">使用简单的线性回归来预测中值房价，我们可以使用模型的摘要来回答以下问题:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pn"><img src="../Images/85b9f3c67b9970ee7b9d1491d7966614.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hW8WdNzo-NoVFVTNAxcTOw@2x.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图5:多元线性回归模型汇总；作者图片</p></figure><ul class=""><li id="03e8" class="ny nz it lb b lc ld lf lg li oa lm ob lq oc lu pe oe of og bi translated"><strong class="lb iu"> <em class="mm">预测变量子集&amp; medv之间有关联吗？有多强？</em> </strong></li></ul><p id="122c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于与汇总表(图5)中的F统计值相对应的p值非常低，因此预测变量子集与medv之间有很强的相关性。</p><ul class=""><li id="578b" class="ny nz it lb b lc ld lf lg li oa lm ob lq oc lu pe oe of og bi translated"><strong class="lb iu"> <em class="mm">各种预测变量如何影响medv？</em> </strong></li></ul><p id="2d34" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据这个多元线性回归模型，每个预测变量与medv都有很强的相关性，可以通过使用简单的线性模型来辨别确切的贡献。</p><ul class=""><li id="ad8d" class="ny nz it lb b lc ld lf lg li oa lm ob lq oc lu pe oe of og bi translated"><strong class="lb iu"> <em class="mm">响应变量的预测有多准确？</em>T3】</strong></li></ul><p id="ef8f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">调整后的R会对添加到模型中的其他预测变量造成不利影响，而不会对其进行改善，这与R相反，R会随着添加到模型中的每个变量而增加。由于两者之间的差异不大，我们可以推断该模型比简单的线性回归模型更准确，后者只能解释48%的medv变异性，而多元线性回归可以解释74%的medv变异性。</p><h1 id="7c7d" class="mn mo it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated">线性回归模型的潜在问题</h1><p id="396f" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">看了线性回归模型，它的类型和评估，重要的是承认它的缺点。由于线性回归模型的假设，有几个问题困扰着线性回归模型，例如:</p><ol class=""><li id="9267" class="ny nz it lb b lc ld lf lg li oa lm ob lq oc lu od oe of og bi translated">共线性(<a class="ae ky" href="https://medium.com/@pardeshi.vishwa25/handling-multi-collinearity-6579eb99fd81" rel="noopener">如何处理多重共线性</a>)</li><li id="15a7" class="ny nz it lb b lc oh lf oi li oj lm ok lq ol lu od oe of og bi translated">残差的相关性</li><li id="4b09" class="ny nz it lb b lc oh lf oi li oj lm ok lq ol lu od oe of og bi translated">残差的非常数方差/异方差</li><li id="f17d" class="ny nz it lb b lc oh lf oi li oj lm ok lq ol lu od oe of og bi translated">极端值</li><li id="baa4" class="ny nz it lb b lc oh lf oi li oj lm ok lq ol lu od oe of og bi translated">非线性关系</li></ol><p id="cfda" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">关于如何处理这些问题的文章正在编写中。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="f8f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Github上探索简单/多重/多项式线性回归、预测因子的非线性转换、逐步选择的项目:</p><ol class=""><li id="8cc7" class="ny nz it lb b lc ld lf lg li oa lm ob lq oc lu od oe of og bi translated"><a class="ae ky" href="https://github.com/vishwapardeshi/Machine-Learning-Projects/tree/master/Linear_Regression/Boston_Housing_Price_Prediction" rel="noopener ugc nofollow" target="_blank">波士顿房价预测</a></li><li id="cef5" class="ny nz it lb b lc oh lf oi li oj lm ok lq ol lu od oe of og bi translated"><a class="ae ky" href="https://github.com/vishwapardeshi/Machine-Learning-Projects/tree/master/Linear_Regression/Fuel_Efficiency_Prediction" rel="noopener ugc nofollow" target="_blank">燃油效率预测</a> n(自动编程)</li><li id="0aca" class="ny nz it lb b lc oh lf oi li oj lm ok lq ol lu od oe of og bi translated"><a class="ae ky" href="https://github.com/vishwapardeshi/Machine-Learning-Projects/tree/master/Polynomial_Regression" rel="noopener ugc nofollow" target="_blank">预测工资</a></li></ol></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="1ddf" class="nm mo it bd mp nn no dn mt np nq dp mx li nr ns mz lm nt nu nb lq nv nw nd nx bi translated">参考</h2><p id="1b8f" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">R中的统计学习导论。</p></div></div>    
</body>
</html>