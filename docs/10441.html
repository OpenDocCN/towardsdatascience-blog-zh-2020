<html>
<head>
<title>COVID Fake News Detection with a Very Simple Logistic Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用非常简单的逻辑回归检测假新闻</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/covid-fake-news-detection-with-a-very-simple-logistic-regression-34c63502e33b?source=collection_archive---------18-----------------------#2020-07-22">https://towardsdatascience.com/covid-fake-news-detection-with-a-very-simple-logistic-regression-34c63502e33b?source=collection_archive---------18-----------------------#2020-07-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/76154460565e910b60b849b557abf1a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i_QAGFBqlu2SN6rRsr6msw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片来源:Unsplash</p></figure><div class=""/><div class=""><h2 id="e011" class="pw-subtitle-paragraph kc je jf bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">自然语言处理，NLP，Scikit Learn</h2></div><p id="e6a6" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">这一次，我们将使用我不久前收集的<a class="ae lq" href="https://raw.githubusercontent.com/susanli2016/NLP-with-Python/master/data/corona_fake.csv" rel="noopener ugc nofollow" target="_blank">数据</a>，创建一个简单的逻辑回归模型来将 COVID 新闻分类为真或假。</p><p id="7464" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">这个过程出奇的简单和容易。我们将清理和预处理文本数据，使用<a class="ae lq" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> NLTK </a>库执行特征提取，使用<a class="ae lq" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> Scikit-Learn </a>库构建和部署逻辑回归分类器，并在最后评估模型的准确性。</p><h1 id="766f" class="lr ls jf bd lt lu lv lw lx ly lz ma mb kl mc km md ko me kp mf kr mg ks mh mi bi translated">数据</h1><p id="645a" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp ij bi translated"><a class="ae lq" href="https://raw.githubusercontent.com/susanli2016/NLP-with-Python/master/data/corona_fake.csv" rel="noopener ugc nofollow" target="_blank">数据集</a>包含 586 条真新闻和 578 条假新闻，几乎对半分割。因为数据收集偏差，我决定不使用“源”作为特征之一，而是将“标题”和“文本”合并为一个特征“标题 _ 文本”。</p><figure class="mo mp mq mr gt is"><div class="bz fp l di"><div class="ms mt l"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">fake_news_logreg_start.py</p></figure><figure class="mo mp mq mr gt is gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/90fa10d244b814262b3fc8cd1a4078f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*AMTQiBJod-KU2OPZT-e_iQ.png"/></div></figure><h1 id="7c97" class="lr ls jf bd lt lu lv lw lx ly lz ma mb kl mc km md ko me kp mf kr mg ks mh mi bi translated">预处理</h1><p id="1a63" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp ij bi translated">让我们来看一个标题文字组合的例子:</p><pre class="mo mp mq mr gt mv mw mx my aw mz bi"><span id="8418" class="na ls jf mw b gy nb nc l nd ne">df['title_text'][50]</span></pre><figure class="mo mp mq mr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nf"><img src="../Images/1063cff9de75ec08817f1c2d8fc96744.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QQvnr-cYtL0N7L8wdZuy8A.png"/></div></div></figure><p id="279b" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">看看上面的标题和文本的例子，它们非常干净，一个简单的文本预处理就可以了。因此，我们将剥离任何 html 标签，标点符号，并使他们小写。</p><figure class="mo mp mq mr gt is"><div class="bz fp l di"><div class="ms mt l"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">fake _ news _ logreg _ 预处理. py</p></figure><figure class="mo mp mq mr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ng"><img src="../Images/b7abc123b5ae1ec1c92240684ac278ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WV5Lg23dFDOlnLR_O56toA.png"/></div></div></figure><p id="fc9d" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">下面的代码将标记化和词干化技术结合在一起，然后在“title_text”上应用这些技术。</p><pre class="mo mp mq mr gt mv mw mx my aw mz bi"><span id="283a" class="na ls jf mw b gy nb nc l nd ne">porter = PorterStemmer()</span><span id="5a8b" class="na ls jf mw b gy nh nc l nd ne">def tokenizer_porter(text):<br/>    return [porter.stem(word) for word in text.split()]</span></pre><h1 id="7176" class="lr ls jf bd lt lu lv lw lx ly lz ma mb kl mc km md ko me kp mf kr mg ks mh mi bi translated">TF-IDF</h1><p id="4f13" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp ij bi translated">这里，我们将“标题 _ 文本”特征转换成 TF-IDF 向量。</p><ul class=""><li id="d2fc" class="ni nj jf kw b kx ky la lb ld nk lh nl ll nm lp nn no np nq bi translated">因为我们之前已经将“title_text”转换为小写，所以这里我们设置了<code class="fe nr ns nt mw b">lowercase=False</code>。</li><li id="3271" class="ni nj jf kw b kx nu la nv ld nw lh nx ll ny lp nn no np nq bi translated">因为我们已经注意到并对“title_text”应用了预处理，所以这里我们设置了<code class="fe nr ns nt mw b">preprocessor=None</code>。</li><li id="672b" class="ni nj jf kw b kx nu la nv ld nw lh nx ll ny lp nn no np nq bi translated">我们用之前定义的标记化和词干化的组合来覆盖字符串标记化步骤。</li><li id="2f80" class="ni nj jf kw b kx nu la nv ld nw lh nx ll ny lp nn no np nq bi translated">设置<code class="fe nr ns nt mw b">use_idf=True</code>启用逆文档频率重新加权。</li><li id="39eb" class="ni nj jf kw b kx nu la nv ld nw lh nx ll ny lp nn no np nq bi translated">设置<code class="fe nr ns nt mw b">smooth_idf=True</code>以避免零分割。</li></ul><figure class="mo mp mq mr gt is"><div class="bz fp l di"><div class="ms mt l"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">fake_news_logreg_tfidf.py</p></figure><h1 id="c6a1" class="lr ls jf bd lt lu lv lw lx ly lz ma mb kl mc km md ko me kp mf kr mg ks mh mi bi translated">文献分类的逻辑回归</h1><ul class=""><li id="b681" class="ni nj jf kw b kx mj la mk ld nz lh oa ll ob lp nn no np nq bi translated">我们可以使用一个估计器<code class="fe nr ns nt mw b">LogisticRegressionCV</code>，而不是手动调整 C 参数。</li><li id="5a82" class="ni nj jf kw b kx nu la nv ld nw lh nx ll ny lp nn no np nq bi translated">我们指定交叉验证折叠的数量<code class="fe nr ns nt mw b">cv=5</code>来调整这个超参数。</li><li id="a097" class="ni nj jf kw b kx nu la nv ld nw lh nx ll ny lp nn no np nq bi translated">型号的度量是分类的<code class="fe nr ns nt mw b">accuracy</code>。</li><li id="acaa" class="ni nj jf kw b kx nu la nv ld nw lh nx ll ny lp nn no np nq bi translated">通过设置<code class="fe nr ns nt mw b">n_jobs=-1</code>，我们将所有的 CPU 内核专用于解决问题。</li><li id="e178" class="ni nj jf kw b kx nu la nv ld nw lh nx ll ny lp nn no np nq bi translated">我们最大化优化算法的迭代次数。</li><li id="9093" class="ni nj jf kw b kx nu la nv ld nw lh nx ll ny lp nn no np nq bi translated">我们使用<code class="fe nr ns nt mw b">pickle</code>来保存模型。</li></ul><figure class="mo mp mq mr gt is"><div class="bz fp l di"><div class="ms mt l"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">false _ news _ log reg _ model . py</p></figure><h1 id="5c32" class="lr ls jf bd lt lu lv lw lx ly lz ma mb kl mc km md ko me kp mf kr mg ks mh mi bi translated">模型评估</h1><ul class=""><li id="39c9" class="ni nj jf kw b kx mj la mk ld nz lh oa ll ob lp nn no np nq bi translated">使用<code class="fe nr ns nt mw b">pickle</code>加载我们保存的模型。</li><li id="814b" class="ni nj jf kw b kx nu la nv ld nw lh nx ll ny lp nn no np nq bi translated">使用该模型查看以前从未见过的数据的准确性得分。</li></ul><figure class="mo mp mq mr gt is"><div class="bz fp l di"><div class="ms mt l"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">fake_news_logreg_eva.py</p></figure><figure class="mo mp mq mr gt is gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/84dd70d9116740d01e436a73b0b848d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:530/format:webp/1*bIlrvWFWPPlSb9rEmXlVSQ.png"/></div></figure><p id="3296" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><a class="ae lq" href="https://github.com/susanli2016/NLP-with-Python/blob/master/Fake_News_LogReg.ipynb" rel="noopener ugc nofollow" target="_blank"> Jupyter 笔记本</a>可以在<a class="ae lq" href="https://github.com/susanli2016/NLP-with-Python/blob/master/Fake_News_LogReg.ipynb" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到。享受这周剩下的时光。</p></div></div>    
</body>
</html>