<html>
<head>
<title>Automate Entity Extraction of Reddit Subgroup using BERT Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 BERT 模型自动提取 Reddit 子组实体</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/automate-entity-extraction-of-reddit-subgroup-using-bert-model-336f9edb176e?source=collection_archive---------33-----------------------#2020-08-03">https://towardsdatascience.com/automate-entity-extraction-of-reddit-subgroup-using-bert-model-336f9edb176e?source=collection_archive---------33-----------------------#2020-08-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5c1d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用预先训练的 BERT 模型从 Subreddit r/Wordnews 中提取人名、位置和组织信息</h2></div><p id="979a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">被困在付费墙后面？点击这里阅读这篇文章和我的朋友链接。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/cbf279903a3026be08fd922ca58595e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5fFaALvmpCeC8T3Ig_lq-A.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">资料来源:Unsplash 的 Luis Villasmil</p></figure><p id="14db" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">命名实体识别(NER)是一个从非结构化文本中提取信息的过程。它也被称为实体提取。该方法提取时间、地点、货币、组织、医疗代码、人名等信息。我们可以将这些提取的实体标记为文章/文档的标签。</p><p id="a413" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但是，我们通过从文本中提取实体来实现什么呢？这些标签能帮助我们减少文章搜索过程中的时间吗？</p><p id="0ed9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通过改进搜索过程，文章或文档上的标签可以节省大量时间。标签帮助我们对文本文档进行分类。这是 NER 的一个用例。</p><p id="40e1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面列出了 NER 的一些其他使用案例。</p><p id="0f0c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">1.<strong class="kk iu">将通讯社的文章分为世界、体育、时尚、娱乐等类别。类别。</strong></p><p id="b54f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> 2。它有助于在不同的在线购物网站上搜索产品。</strong></p><p id="557a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> 3。在线课程可以根据不同的相关标签进行分类。</strong></p><p id="a65b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将使用 BERT 预训练模型。点击了解有关 BERT 模型<a class="ae le" href="https://huggingface.co/transformers/model_doc/bert.html" rel="noopener ugc nofollow" target="_blank">的更多信息。BERT 模型将从 Reddit 子组中提取人名、组织名和地名。</a></p><p id="6ff5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">本文分为三个部分。</p><p id="3699" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">第一部分。数据收集和数据准备</strong></p><p id="5a94" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Python 程序连接 Reddit API，从 subreddit 获取信息。然后我们根据 BERT 模型输入格式化数据。</p><p id="f2bc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">第二部分。信息提取</strong></p><p id="4be1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将从第一部分准备的数据中提取实体信息。</p><p id="4307" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">第三部分。数据分析和数据可视化</strong></p><p id="3409" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这一部分，我们将通过图表分析从第二部分提取的信息。</p><p id="fc06" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，让我们开始吧。</p><h2 id="8572" class="lv lw it bd lx ly lz dn ma mb mc dp md kr me mf mg kv mh mi mj kz mk ml mm mn bi translated">第一部分。数据收集和数据准备</h2><p id="a52d" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">我们将使用 Reddit 分组 r/Worldnews 数据。Reddit 提供 API 访问来获取标题、评论和其他与帖子相关的数据。PRAW 是一个 python 库，它帮助我们与 API 连接。在这里了解更多关于 PRAW 图书馆的信息。(<a class="ae le" href="https://praw.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">https://praw.readthedocs.io/en/latest/</a>)。您需要创建一个 Reddit 帐户来访问 API 所需的信息。</p><p id="ef14" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这些是必需的 API 信息。</p><pre class="lg lh li lj gt mt mu mv mw aw mx bi"><span id="7676" class="lv lw it mu b gy my mz l na nb">reddit = praw.Reddit(client_id=’my_client_id’,<br/>                     client_secret=’my_client_secret’,<br/>                     user_agent=’my user agent name’)</span></pre><p id="a2f6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">按照<a class="ae le" rel="noopener" target="_blank" href="/scraping-reddit-data-1c0af3040768">文章</a>中提到的步骤获取所需的 API 访问信息。</p><p id="a9ba" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一旦你获得访问权，我们将从 r/Worldnews post 获取标题和评论。我们将使用 r/Worldnews 的顶级周刊。您可以根据不同的时间线和受欢迎程度接收来自子组的数据。</p><pre class="lg lh li lj gt mt mu mv mw aw mx bi"><span id="45e0" class="lv lw it mu b gy my mz l na nb">def replies_of(top_level_comment, comment_list):<br/>  if len(top_level_comment.replies) == 0:<br/>    return<br/>  else:<br/>    for num, comment in enumerate(top_level_comment.replies):<br/>      try:<br/>        comment_list.append(str(comment.body))<br/>      except:<br/>        continue<br/>      replies_of(comment, comment_list)</span><span id="a51f" class="lv lw it mu b gy nc mz l na nb">list_of_subreddit = [‘worldnews’]<br/>for j in list_of_subreddit:<br/>  # get 10 hot posts from the MachineLearning subreddit<br/>  top_posts = reddit.subreddit(j).top(‘week’, limit=1)<br/>  comment_list = []<br/>    # save subreddit comments in dataframe<br/>    for submission in top_posts:<br/>      print(‘\n\n’)<br/>      print(“Title :” , submission.title)<br/>      submission_comm = reddit.submission(id=submission.id)<br/>      comment_list.append(str(submission.title))<br/>        for count, top_level_comment in enumerate(submission_comm.comments):<br/>          try:<br/>            replies_of(top_level_comment, comment_list)<br/>          except:<br/>            continue<br/>print(comment_list)</span></pre><p id="acf2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这段代码将使用递归函数获取 subreddit 帖子的整个评论部分。数据将被存储到 comment_list 变量中。</p><h2 id="ee3d" class="lv lw it bd lx ly lz dn ma mb mc dp md kr me mf mg kv mh mi mj kz mk ml mm mn bi translated">第二部分。信息提取</h2><p id="ed85" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">第一部分准备的数据是 BERT 模型的输入格式。模型生成的输出保存在不同的变量中。</p><p id="3d3e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">拥抱脸的 transformer python 库将帮助我们访问 DBMDZ 训练的 BERT 模型。BERT 令牌库中包含大约 30k 个单词。如果输入文本由库中不存在的单词组成，则 BERT 标记将该单词分解为相近的单词。</p><p id="4add" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">比如拥抱这个词会分裂成 hu 和##gging。如果一个未被识别的单词被认为是一个实体，那么每个被拆分的单词将被赋予相同的标签。</p><p id="811e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">比如(' Hu '，' I-ORG ')，(' ##gging '，' I-ORG ')。</p><pre class="lg lh li lj gt mt mu mv mw aw mx bi"><span id="0477" class="lv lw it mu b gy my mz l na nb">for sequence in comment_list:<br/>  if len(sequence) &gt; 512:<br/>    continue<br/>  tokens = tokenizer.tokenize(tokenizer.decode<br/>                           (tokenizer.encode(sequence)))<br/>  inputs = tokenizer.encode(sequence, return_tensors=”tf”)<br/>  outputs = model(inputs)[0]<br/>  predictions = tf.argmax(outputs, axis=2)<br/>  list_bert = [(token, label_list[prediction]) for token, prediction in zip(tokens, predictions[0].numpy())]</span></pre><p id="05ad" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于 BERT 令牌限制，我将输入句子长度限制为 512。</p><p id="b0b1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我将这些词组合起来，并赋予它们各自的实体。这个模型不是 100%准确。因此，一些单词可能会被指定错误的标签。我们在分析中会尽量避免这些不相关的词。</p><h2 id="d912" class="lv lw it bd lx ly lz dn ma mb mc dp md kr me mf mg kv mh mi mj kz mk ml mm mn bi translated">第三部分。数据分析和数据可视化。</h2><p id="0f3e" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">我们有三个类别进行分析。这些类别是位置、人名和组织。</p><p id="9e40" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从数据中提取的主题和实体的标题。</p><pre class="lg lh li lj gt mt mu mv mw aw mx bi"><span id="6acf" class="lv lw it mu b gy my mz l na nb">Title: Research finds that New Zealand beat Covid-19 by trusting leaders and following advice. Citizens had a high level of knowledge about coronavirus and how it spread, and compliance with basic hygiene practices and trust in authorities was at nearly 100%.</span><span id="a895" class="lv lw it mu b gy nc mz l na nb">{‘Location’: [‘UNITED STATES’, ‘ILLINOIS’, ‘GREECE’, ‘TAIWAN’, ‘NEW Z’, ‘ISLAND’, ‘PORTLAND’, ‘NSW’, ‘CANADA’, ‘QUEENSLAND’, ‘VIETNAM’, ‘CHRISTCHURCH’, ‘HAWAII’,’VICTORIA’, ‘UK’, ‘RUSSIA’, ‘WELLINGTON’, ‘INDIANA’, ‘CHUR’, ‘NZ CHINA’, ‘STATES’, ‘ARGENTINA’, ‘CALIFORNIA’, ‘IETNAM’, ‘TRUMPTOWN’, ‘TEXAS’, ‘FRANCE’, ‘AUS’, ‘NZ’, ‘NEW YORK’, ‘JAPAN’, ‘FLORIDA’, ‘QLD’, ‘AUCKLAND’, ‘KE’, ‘USA’, ‘THE’, ‘CHINA’, ‘ITALY’, ‘SWEDEN’, ‘JONESTOWN’, ‘MELBOURNE’, ‘AMERICA’, ‘NEW ZEALAND’, ‘IRAQ’,’US’, ‘AFGHANISTAN’, ‘AUSTRALIA’], ‘Organisation’: [‘YOUTUBE’, ‘FED’, ‘FACEBOOK’, ‘ALLPRESS’, ‘GNELL’, ‘VODAFONE’, ‘IRON’, ‘LIB’, ‘RESERVE BANK’, ‘LANEWAY’, ‘DEMS’, ‘ALJAZEERA’, ‘RVA’, ‘JACINDAS’, ‘CIA’, ‘LABOR’, ‘TREASURY’, ‘SMD’, ‘WHO’, ‘SENATE’, ‘LIBERALS’, ‘LIBERAL’, ‘IIRC’, ‘COVID’, ‘HS’, ‘PRC’, ‘NATIONAL’, ‘TIL’, ‘SHITREDDITSAYS’, ‘COM’, ‘FOX’, ‘EZZANZ’, ‘QLD’, ‘FAMILY FIRST’, ‘NATIONALS’, ‘NIN’, ‘DEFENCE FORCE’, ‘ZZAN’, ‘ACINDA’, ‘FOX NEWS’, ‘LABOUR’, ‘FEDERAL’, ‘HOUSE OF REPS’, ‘WORLDNEWS’, ‘MURDOCH’, ‘GREENS’], ‘Person Name’: [‘KEVIN’, ‘FATHE’, ‘KAREN’, ‘MACRON’, ‘WINSTON’, ‘LES’, ‘BUCKLEY’, ‘CHLÖE SWARBRICK’, ‘COLLINS’, ‘CLINTON’,’JUDITH COLLINS’, ‘TO’, ‘KYLER’, ‘ASHLEY’, ‘BILL GATES’, ‘THE P’, ‘SCOTTY’, ‘HITLER’, ‘TRUMP’, ‘RUPERT MURDOCH’, ‘GATES’, ‘HGO’, ‘WILLIAM CASEY’, ‘OAK’, ‘TOVA’,’JIM JONES’, ‘KEZZA’, ‘ENN’, ‘MERICA’, ‘ROF’, ‘BLOOMFIELD’, ‘GOD’, ‘KIF’, ‘CLIVE PALMER’, ‘DAVE GROHL’, ‘SHER’, ‘BLAIR’, ‘JACINDA ARDERN’, ‘DAD’, ‘JACINDA’, ‘WINS TON PETERS’, ‘LERON’, ‘BLOOMFIELDS’, ‘MURDOCH’]}</span></pre><p id="6fba" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">以下是我的观察。</strong></p><p id="6e1e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">1.新西兰的位置在评论中被多次提及。标题中也提到了这个地名。Reddit 用户可能更喜欢国家名称的简称，而不是全称。</p><p id="0b31" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">例如，美国、新西兰和英国等国家的简称是美国、新西兰和英国。</p><p id="51d3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">2.当用户知道某个国家时，他们会提到这个国家的名字。或者他们属于那个国家。因此，我们可以说，对这个帖子发表评论的大多数用户来自新西兰、美国、澳大利亚或英国。</p><p id="b8bb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">3.杰辛达·阿德恩是新西兰总理，这解释了为什么在大多数评论中提到这个名字。由于话题情绪积极，我可以说评论提到杰辛达·阿德恩的名字也是积极的。</p><p id="81e2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">4.我们还可以看到特朗普(美国总统)和比尔·盖茨(微软创始人)的名字。但是提到这些名字的评论的观点并不是决定性的。你可以分别分析那些评论。</p><p id="ae39" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">5.杰辛达·阿德恩属于执政的工党。反对党是国家党。评论中既有劳工组织的名字，也有国家组织的名字。</p><p id="3b65" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">6.你也可以看到提及科维德和世卫组织。在组织标签中提到脸书是不确定的，除非你有提到它的评论。</p><p id="4aca" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有了这些实体，您就可以预期它是什么类型的数据。你可以把这些数据归入《世界新闻》一类。这些标签将帮助你过滤阅读材料。</p><p id="dd95" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果运行相同的 python 程序，则不会出现相同的主题。因此观察和标记可能会有所不同。</p><p id="0e29" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是从帖子中摘录的位置条形图。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi nd"><img src="../Images/369505bda4441b48bfb8bb88cc7a299c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vkbOfusEYa0M1PWmHdcDHA.jpeg"/></div></div></figure><p id="ac5f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是从帖子中摘录的一个组织单词云。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi nd"><img src="../Images/0057dc15b98bb0deb3d6f90182612d9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ggawEfp_vg3hQLdU4jSoqg.jpeg"/></div></div></figure><h2 id="23f2" class="lv lw it bd lx ly lz dn ma mb mc dp md kr me mf mg kv mh mi mj kz mk ml mm mn bi translated">结论</h2><p id="3912" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">Reddit 是一个很好的社交媒体平台，可以测试 BERT 实体提取模型的准确性。本文将帮助您处理 BERT 模型的输出数据并提取实体。您将了解它的用例，以及如何使用这些标签对文本数据进行分类。</p><p id="5c7a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">希望这篇文章能帮助你有效地搜索不同的文档。</p><p id="0605" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请在这里找到完整的代码。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="ne nf l"/></div></figure></div></div>    
</body>
</html>