<html>
<head>
<title>PyTorch [Basics] — Sampling Samplers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">py torch[基础知识] —取样取样器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pytorch-basics-sampling-samplers-2a0f29f0bf2a?source=collection_archive---------4-----------------------#2020-04-11">https://towardsdatascience.com/pytorch-basics-sampling-samplers-2a0f29f0bf2a?source=collection_archive---------4-----------------------#2020-04-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/840b4e62b667c78ce2f768c8b11e4488.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Dsdw-L4qVhT1WkyLvtsPg.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">如何训练你的神经网络[图片[0]]</p></figure><h2 id="2d89" class="jd je jf bd b dl jg jh ji jj jk jl dk jm translated" aria-label="kicker paragraph"><a class="ae ep" href="https://medium.com/tag/akshaj-wields-pytorch" rel="noopener">如何训练你的神经网络</a></h2><div class=""/><p id="1f64" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">本笔记本将带您了解使用 PyTorch 对<a class="ae ln" href="https://www.kaggle.com/prasunroy/natural-images" rel="noopener ugc nofollow" target="_blank">自然图像</a>数据执行<code class="fe lj lk ll lm b">random_split</code>、<code class="fe lj lk ll lm b">SubsetRandomSampler</code>和<code class="fe lj lk ll lm b">WeightedRandomSampler</code>的过程。</p><h1 id="8bbe" class="lo lp jf bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">导入库</h1><pre class="mm mn mo mp gt mq lm mr ms aw mt bi"><span id="e71e" class="mu lp jf lm b gy mv mw l mx my">import numpy as np<br/>import pandas as pd<br/>import seaborn as sns<br/>from tqdm.notebook import tqdm<br/>import matplotlib.pyplot as plt<br/></span><span id="1c86" class="mu lp jf lm b gy mz mw l mx my">import torch<br/>import torchvision<br/>import torch.nn as nn<br/>import torch.optim as optim<br/>import torch.nn.functional as F<br/>from torchvision import transforms, utils, datasets<br/>from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler, WeightedRandomSampler</span></pre><p id="afac" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">设置随机种子。</p><pre class="mm mn mo mp gt mq lm mr ms aw mt bi"><span id="0b66" class="mu lp jf lm b gy mv mw l mx my">np.random.seed(0)<br/>torch.manual_seed(0)</span></pre><p id="8cad" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">设置<code class="fe lj lk ll lm b">Seaborn</code>样式。</p><pre class="mm mn mo mp gt mq lm mr ms aw mt bi"><span id="3c8c" class="mu lp jf lm b gy mv mw l mx my">%matplotlib inline<br/>sns.set_style('darkgrid')</span></pre><h1 id="54f4" class="lo lp jf bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">定义数据路径</h1><p id="08f8" class="pw-post-body-paragraph kl km jf kn b ko na kq kr ks nb ku kv kw nc ky kz la nd lc ld le ne lg lh li ij bi translated">设置数据集的根目录。</p><pre class="mm mn mo mp gt mq lm mr ms aw mt bi"><span id="e801" class="mu lp jf lm b gy mv mw l mx my">root_dir = "../../data/computer_vision/image_classification/natural-images/"<br/>print("The data lies here =&gt;", root_dir)<br/></span><span id="2089" class="mu lp jf lm b gy mz mw l mx my">###################### OUTPUT ######################</span><span id="9eb6" class="mu lp jf lm b gy mz mw l mx my">We're using =&gt; cpu<br/>The data lies here =&gt; ../../data/computer_vision/image_classification/natural-images/</span></pre><h1 id="4449" class="lo lp jf bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">定义转换</h1><p id="a4c8" class="pw-post-body-paragraph kl km jf kn b ko na kq kr ks nb ku kv kw nc ky kz la nd lc ld le ne lg lh li ij bi translated">将图像裁剪为<code class="fe lj lk ll lm b">(224, 224)</code>大小，并将它们转换为张量。</p><pre class="mm mn mo mp gt mq lm mr ms aw mt bi"><span id="eaca" class="mu lp jf lm b gy mv mw l mx my">image_transforms = {<br/>    "train": transforms.Compose([<br/>        transforms.Resize((224, 224)),<br/>        transforms.ToTensor()<br/>    ])<br/>}</span></pre><h1 id="bfea" class="lo lp jf bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">初始化数据集</h1><p id="ebd9" class="pw-post-body-paragraph kl km jf kn b ko na kq kr ks nb ku kv kw nc ky kz la nd lc ld le ne lg lh li ij bi translated">使用<code class="fe lj lk ll lm b">ImageFolder</code>，我们将创建我们的数据集。对于这篇博文，我们将只使用 train 文件夹。</p><pre class="mm mn mo mp gt mq lm mr ms aw mt bi"><span id="f866" class="mu lp jf lm b gy mv mw l mx my">natural_img_dataset = datasets.ImageFolder(<br/>                              root = root_dir,<br/>                              transform = image_transforms["train"]<br/>                       )</span><span id="ebff" class="mu lp jf lm b gy mz mw l mx my">natural_img_dataset</span></pre><h1 id="6766" class="lo lp jf bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">类别&lt;=&gt; ID 映射</h1><p id="6939" class="pw-post-body-paragraph kl km jf kn b ko na kq kr ks nb ku kv kw nc ky kz la nd lc ld le ne lg lh li ij bi translated"><code class="fe lj lk ll lm b">.class_to_idx</code>方法返回数据集中的类映射标签。</p><pre class="mm mn mo mp gt mq lm mr ms aw mt bi"><span id="0510" class="mu lp jf lm b gy mv mw l mx my">natural_img_dataset.class_to_idx</span><span id="86ef" class="mu lp jf lm b gy mz mw l mx my">###################### OUTPUT ######################</span><span id="a05b" class="mu lp jf lm b gy mz mw l mx my">{'airplane': 0,<br/> 'car': 1,<br/> 'cat': 2,<br/> 'dog': 3,<br/> 'flower': 4,<br/> 'fruit': 5,<br/> 'motorbike': 6,<br/> 'person': 7}</span></pre><p id="2c1b" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我们将创建一个名为<code class="fe lj lk ll lm b">idx2class</code>的字典，它是 PyTorch 中<code class="fe lj lk ll lm b">class_to_idx</code>方法的逆方法。</p><pre class="mm mn mo mp gt mq lm mr ms aw mt bi"><span id="a399" class="mu lp jf lm b gy mv mw l mx my">idx2class = {v: k for k, v in natural_img_dataset.class_to_idx.items()}</span><span id="419c" class="mu lp jf lm b gy mz mw l mx my">idx2class<br/></span><span id="fd4a" class="mu lp jf lm b gy mz mw l mx my">###################### OUTPUT ######################</span><span id="6825" class="mu lp jf lm b gy mz mw l mx my">{0: 'airplane',<br/> 1: 'car',<br/> 2: 'cat',<br/> 3: 'dog',<br/> 4: 'flower',<br/> 5: 'fruit',<br/> 6: 'motorbike',<br/> 7: 'person'}</span></pre><h1 id="6492" class="lo lp jf bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">观察班级分布</h1><p id="15ba" class="pw-post-body-paragraph kl km jf kn b ko na kq kr ks nb ku kv kw nc ky kz la nd lc ld le ne lg lh li ij bi translated">为了观察 dataset 对象中不同类的分布，我们创建了一个名为<code class="fe lj lk ll lm b">get_class_distribution()</code>的函数。该函数将数据集作为输入参数，并返回一个字典，其中包含 dataset 对象中所有类的计数。</p><ol class=""><li id="4567" class="nf ng jf kn b ko kp ks kt kw nh la ni le nj li nk nl nm nn bi translated">为此，我们首先初始化我们的<code class="fe lj lk ll lm b">count_dict</code>，其中所有的类计数都是 0。</li><li id="3924" class="nf ng jf kn b ko no ks np kw nq la nr le ns li nk nl nm nn bi translated">然后我们迭代数据集对象来提取类标签。dataset 对象包含元组(x，y)形式的元素。因此，我们需要从元组中提取位置 1 的项。</li><li id="326c" class="nf ng jf kn b ko no ks np kw nq la nr le ns li nk nl nm nn bi translated">然后我们使用<code class="fe lj lk ll lm b">idx2class</code>从类 id 中获取类名。</li><li id="e9d6" class="nf ng jf kn b ko no ks np kw nq la nr le ns li nk nl nm nn bi translated">最后，我们为相关的 class-key 将<code class="fe lj lk ll lm b">count_dict</code>中的计数更新 1。</li></ol><pre class="mm mn mo mp gt mq lm mr ms aw mt bi"><span id="7d0d" class="mu lp jf lm b gy mv mw l mx my">def get_class_distribution(dataset_obj):<br/>    count_dict = {k:0 for k,v in dataset_obj.class_to_idx.items()}<br/>    <br/>    for element in dataset_obj:<br/>        y_lbl = element[1]<br/>        y_lbl = idx2class[y_lbl]<br/>        count_dict[y_lbl] += 1<br/>            <br/>    return count_dict</span><span id="fa77" class="mu lp jf lm b gy mz mw l mx my">print("Distribution of classes: \n", get_class_distribution(natural_img_dataset))</span><span id="9a0f" class="mu lp jf lm b gy mz mw l mx my"><br/>###################### OUTPUT ######################</span><span id="0382" class="mu lp jf lm b gy mz mw l mx my">Distribution of classes: <br/> {'airplane': 727, 'car': 968, 'cat': 885, 'dog': 702, 'flower': 843, 'fruit': 1000, 'motorbike': 788, 'person': 986}</span></pre><p id="bea6" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">为了绘制我们的字典，我们使用 Seaborn 库。我们首先将字典转换成数据帧，然后将其融化。最后，我们使用函数<code class="fe lj lk ll lm b">sns.barplot()</code>来构建我们的情节。</p><pre class="mm mn mo mp gt mq lm mr ms aw mt bi"><span id="0d64" class="mu lp jf lm b gy mv mw l mx my">plt.figure(figsize=(15,8))</span><span id="0fa2" class="mu lp jf lm b gy mz mw l mx my">sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(natural_img_dataset)]).melt(), x = "variable", y="value", hue="variable").set_title('Natural Images Class Distribution')</span></pre><figure class="mm mn mo mp gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nt"><img src="../Images/1b0c74a6d595e0512d0ddc48f21a817b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NeyqJvfGipjQP7veJFmZBg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">类别分布[图片[1]]</p></figure><p id="be9a" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">从上图中，我们观察到这些类是不平衡的。</p><h1 id="b205" class="lo lp jf bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">随机 _ 分割</h1><p id="d550" class="pw-post-body-paragraph kl km jf kn b ko na kq kr ks nb ku kv kw nc ky kz la nd lc ld le ne lg lh li ij bi translated"><code class="fe lj lk ll lm b">random_split(dataset, lengths)</code>直接作用于数据集。该函数需要两个输入参数。第一个参数是数据集。第二个是一组长度。如果我们想把数据集分成两部分，我们将提供一个包含两个数字的元组。这些数字是分割后相应数据集的大小。</p><p id="9fdc" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我们的数据集有 6899 张图片。如果我们想把它分成大小为(6000，899)的两部分(<em class="nu"> train/test，train/val </em>)，我们就把随机分割称为<code class="fe lj lk ll lm b">random_split(6000, 899)</code>。</p><p id="b1eb" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">让我们将数据集分成训练集和赋值集。</p><pre class="mm mn mo mp gt mq lm mr ms aw mt bi"><span id="6588" class="mu lp jf lm b gy mv mw l mx my">train_dataset, val_dataset = random_split(natural_img_dataset, (6000, 899))</span></pre><p id="dcb0" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">将数据传递给数据加载器。</p><pre class="mm mn mo mp gt mq lm mr ms aw mt bi"><span id="aa91" class="mu lp jf lm b gy mv mw l mx my">train_loader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=1)</span><span id="f095" class="mu lp jf lm b gy mz mw l mx my">val_loader = DataLoader(dataset=val_dataset, shuffle=False, batch_size=1)</span><span id="fec0" class="mu lp jf lm b gy mz mw l mx my">print("Length of the train_loader:", len(train_loader))<br/>print("Length of the val_loader:", len(val_loader))</span><span id="43e8" class="mu lp jf lm b gy mz mw l mx my"><br/>###################### OUTPUT ######################</span><span id="a4a4" class="mu lp jf lm b gy mz mw l mx my">Length of the train_loader: 6000<br/>Length of the val_loader: 899</span></pre><p id="80c3" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">注意，我们使用了一个<code class="fe lj lk ll lm b">batch_size = 1</code>。如果我们增加<code class="fe lj lk ll lm b">batch_size</code>，图像的数量会相同，但是火车/val 装载器的长度会改变。</p><p id="de40" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">让我们看看 train 和 val 加载器中的类分布。</p><pre class="mm mn mo mp gt mq lm mr ms aw mt bi"><span id="b2a2" class="mu lp jf lm b gy mv mw l mx my">def get_class_distribution_loaders(dataloader_obj, dataset_obj):<br/>    count_dict = {k:0 for k,v in dataset_obj.class_to_idx.items()}<br/>    <br/>    for _,j in dataloader_obj:<br/>        y_idx = j.item()<br/>        y_lbl = idx2class[y_idx]<br/>        count_dict[str(y_lbl)] += 1<br/>            <br/>    return count_dict</span></pre><p id="ce75" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">让我们构建情节。</p><pre class="mm mn mo mp gt mq lm mr ms aw mt bi"><span id="2670" class="mu lp jf lm b gy mv mw l mx my">fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(18,7))</span><span id="55c9" class="mu lp jf lm b gy mz mw l mx my">sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution_loaders(train_loader, natural_img_dataset)]).melt(), x = "variable", y="value", hue="variable",  ax=axes[0]).set_title('Train Set')</span><span id="195f" class="mu lp jf lm b gy mz mw l mx my">sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution_loaders(val_loader, natural_img_dataset)]).melt(), x = "variable", y="value", hue="variable",  ax=axes[1]).set_title('Val Set')</span></pre><figure class="mm mn mo mp gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nv"><img src="../Images/759d7e159b246b316ef1c0a206c99b2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SLPtWI6-46kTs-U9RmKvHA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">random_split 后的类分布[Image [2]]</p></figure><h1 id="7394" class="lo lp jf bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">水下取样器</h1><p id="c55a" class="pw-post-body-paragraph kl km jf kn b ko na kq kr ks nb ku kv kw nc ky kz la nd lc ld le ne lg lh li ij bi translated"><code class="fe lj lk ll lm b">SubsetRandomSampler(indices)</code>将数据的索引作为输入。</p><p id="1633" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我们首先创建我们的采样器，然后将它传递给我们的数据加载器。</p><ol class=""><li id="0dc1" class="nf ng jf kn b ko kp ks kt kw nh la ni le nj li nk nl nm nn bi translated">创建索引列表。</li><li id="2f86" class="nf ng jf kn b ko no ks np kw nq la nr le ns li nk nl nm nn bi translated">打乱索引。</li><li id="5868" class="nf ng jf kn b ko no ks np kw nq la nr le ns li nk nl nm nn bi translated">根据列车价值百分比拆分指数。</li><li id="035e" class="nf ng jf kn b ko no ks np kw nq la nr le ns li nk nl nm nn bi translated">创造<code class="fe lj lk ll lm b">SubsetRandomSampler</code>。</li></ol><p id="7ffd" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">创建从 0 到数据集长度的索引列表。</p><pre class="mm mn mo mp gt mq lm mr ms aw mt bi"><span id="54e8" class="mu lp jf lm b gy mv mw l mx my">dataset_size = len(natural_img_dataset)<br/>dataset_indices = list(range(dataset_size))</span></pre><p id="2d37" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">使用<code class="fe lj lk ll lm b">np.shuffle</code>打乱索引列表。</p><pre class="mm mn mo mp gt mq lm mr ms aw mt bi"><span id="713b" class="mu lp jf lm b gy mv mw l mx my">np.random.shuffle(dataset_indices)</span></pre><p id="8734" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">创建拆分索引。我们选择拆分索引为数据集大小的 20% (0.2)。</p><pre class="mm mn mo mp gt mq lm mr ms aw mt bi"><span id="2fac" class="mu lp jf lm b gy mv mw l mx my">val_split_index = int(np.floor(0.2 * dataset_size))</span></pre><p id="6fee" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">将列表切片以获得 2 个索引列表，一个用于训练，另一个用于测试。</p><blockquote class="nw"><p id="1258" class="nx ny jf bd nz oa ob oc od oe of li dk translated"><code class="fe lj lk ll lm b"><em class="og">0</em></code><em class="og">-</em>-<code class="fe lj lk ll lm b"><em class="og">val_split_index</em></code>-<em class="og">-</em>-<code class="fe lj lk ll lm b"><em class="og">n</em></code>-<em class="og">。</em></p><p id="3a89" class="nx ny jf bd nz oa ob oc od oe of li dk translated">列车=&gt; <code class="fe lj lk ll lm b">val_split_index</code>至<code class="fe lj lk ll lm b">n</code></p><p id="ff2a" class="nx ny jf bd nz oa ob oc od oe of li dk translated">Val =&gt; <code class="fe lj lk ll lm b">0</code>至<code class="fe lj lk ll lm b">val_split_index</code></p></blockquote><pre class="oh oi oj ok ol mq lm mr ms aw mt bi"><span id="dec3" class="mu lp jf lm b gy mv mw l mx my">train_idx, val_idx = dataset_indices[val_split_index:], dataset_indices[:val_split_index]</span></pre><p id="8815" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">最后，创建采样器。</p><pre class="mm mn mo mp gt mq lm mr ms aw mt bi"><span id="5cc2" class="mu lp jf lm b gy mv mw l mx my">train_sampler = SubsetRandomSampler(train_idx)</span><span id="ed97" class="mu lp jf lm b gy mz mw l mx my">val_sampler = SubsetRandomSampler(val_idx)</span></pre><p id="3f1e" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">现在，我们将把采样器传递给我们的数据加载器。请注意，当您使用<code class="fe lj lk ll lm b">SubsetRandomSampler</code>时，不能使用<code class="fe lj lk ll lm b">shuffle=True</code>。</p><pre class="mm mn mo mp gt mq lm mr ms aw mt bi"><span id="a500" class="mu lp jf lm b gy mv mw l mx my">train_loader = DataLoader(dataset=natural_img_dataset, shuffle=False, batch_size=1, sampler=train_sampler)</span><span id="9421" class="mu lp jf lm b gy mz mw l mx my">val_loader = DataLoader(dataset=natural_img_dataset, shuffle=False, batch_size=1, sampler=val_sampler)</span></pre><p id="318d" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">现在，我们将在数据加载器中绘制类分布。</p><pre class="mm mn mo mp gt mq lm mr ms aw mt bi"><span id="9118" class="mu lp jf lm b gy mv mw l mx my">fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(18,7))</span><span id="8d0d" class="mu lp jf lm b gy mz mw l mx my">sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution_loaders(train_loader, natural_img_dataset)]).melt(), x = "variable", y="value", hue="variable",  ax=axes[0]).set_title('Train Set')</span><span id="9bc4" class="mu lp jf lm b gy mz mw l mx my">sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution_loaders(val_loader, natural_img_dataset)]).melt(), x = "variable", y="value", hue="variable",  ax=axes[1]).set_title('Val Set')</span></pre><figure class="mm mn mo mp gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi om"><img src="../Images/d6df80d1e90fd141dcbe45876fa92b1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fGRtNxTd2pcB3A-njGsG7A.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">SubsetRandomSampler 之后的类分布[Image [3]]</p></figure><p id="1e08" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">正如我们所观察到的，验证集中每类的样本数与训练集中的样本数成正比。</p><h1 id="7af1" class="lo lp jf bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">加权随机取样器</h1><p id="edf7" class="pw-post-body-paragraph kl km jf kn b ko na kq kr ks nb ku kv kw nc ky kz la nd lc ld le ne lg lh li ij bi translated">与<code class="fe lj lk ll lm b">random_split</code>和<code class="fe lj lk ll lm b">SubsetRandomSampler</code>不同，<code class="fe lj lk ll lm b">WeightedRandomSampler</code>用于确保每批看到所有类别的比例数量。</p><ol class=""><li id="b36f" class="nf ng jf kn b ko kp ks kt kw nh la ni le nj li nk nl nm nn bi translated">获取所有目标类。</li><li id="85de" class="nf ng jf kn b ko no ks np kw nq la nr le ns li nk nl nm nn bi translated">获取类权重。类别权重是每个类别中项目数量的倒数。</li><li id="939f" class="nf ng jf kn b ko no ks np kw nq la nr le ns li nk nl nm nn bi translated">获得每个目标样品的相应重量。</li></ol><p id="6307" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">获取目标类列表并洗牌。</p><pre class="mm mn mo mp gt mq lm mr ms aw mt bi"><span id="1f74" class="mu lp jf lm b gy mv mw l mx my">target_list = torch.tensor(natural_img_dataset.targets)</span></pre><p id="7609" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">获取类计数，并通过取其倒数来计算权重/类。</p><pre class="mm mn mo mp gt mq lm mr ms aw mt bi"><span id="7b45" class="mu lp jf lm b gy mv mw l mx my">class_count = [i for i in get_class_distribution(natural_img_dataset).values()]</span><span id="c7e4" class="mu lp jf lm b gy mz mw l mx my">class_weights = 1./torch.tensor(class_count, dtype=torch.float) </span><span id="b9ca" class="mu lp jf lm b gy mz mw l mx my">class_weights<br/></span><span id="a86e" class="mu lp jf lm b gy mz mw l mx my">###################### OUTPUT ######################</span><span id="8f7b" class="mu lp jf lm b gy mz mw l mx my">tensor([0.0014, 0.0010, 0.0011, 0.0014, 0.0012, 0.0010, 0.0013, 0.0010])</span></pre><p id="c15e" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">将每一类的权重分配给所有样本。</p><pre class="mm mn mo mp gt mq lm mr ms aw mt bi"><span id="06de" class="mu lp jf lm b gy mv mw l mx my">class_weights_all = class_weights[target_list]</span><span id="f85b" class="mu lp jf lm b gy mz mw l mx my">class_weights_all</span><span id="72bc" class="mu lp jf lm b gy mz mw l mx my"><br/>###################### OUTPUT ######################</span><span id="7dad" class="mu lp jf lm b gy mz mw l mx my">tensor([0.0010, 0.0012, 0.0014,  ..., 0.0010, 0.0014, 0.0010])</span></pre><p id="8459" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">将<code class="fe lj lk ll lm b">weight</code>和<code class="fe lj lk ll lm b">number of samples</code>传递给<code class="fe lj lk ll lm b">WeightedRandomSampler</code>。</p><pre class="mm mn mo mp gt mq lm mr ms aw mt bi"><span id="9c03" class="mu lp jf lm b gy mv mw l mx my">weighted_sampler = WeightedRandomSampler(<br/>    weights=class_weights_all,<br/>    num_samples=len(class_weights_all),<br/>    replacement=True<br/>)</span></pre><p id="9509" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">将取样器传递给数据加载器。</p><pre class="mm mn mo mp gt mq lm mr ms aw mt bi"><span id="c6e2" class="mu lp jf lm b gy mv mw l mx my">train_loader = DataLoader(dataset=natural_img_dataset, shuffle=False, batch_size=8, sampler=weighted_sampler)</span></pre><p id="0bab" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这就是了。您现在可以使用您的数据加载器来训练您的神经网络模型！</p></div><div class="ab cl on oo hu op" role="separator"><span class="oq bw bk or os ot"/><span class="oq bw bk or os ot"/><span class="oq bw bk or os"/></div><div class="ij ik il im in"><p id="d34e" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">感谢您的阅读。欢迎提出建议和建设性的批评。:)</p><p id="2084" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这篇博文是“如何训练你的神经网络”系列的一部分。你可以在这里找到<strong class="kn jp"> </strong> <a class="ae ln" href="https://towardsdatascience.com/tagged/akshaj-wields-pytorch" rel="noopener" target="_blank">系列</a> <strong class="kn jp">。</strong></p><p id="4c6f" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">你可以在<a class="ae ln" href="https://www.linkedin.com/in/akshajverma7/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae ln" href="https://twitter.com/theairbend3r" rel="noopener ugc nofollow" target="_blank"> Twitter </a>找到我。如果你喜欢这个，看看我的其他<a class="ae ln" href="https://medium.com/@theairbend3r" rel="noopener">博客</a>。</p><figure class="mm mn mo mp gt is gh gi paragraph-image"><a href="https://www.buymeacoffee.com/theairbend3r"><div class="gh gi ou"><img src="../Images/041a0c7464198414e6ce355f9235099e.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*SGCT6C60o4t58wRqeU2viQ.png"/></div></a></figure></div></div>    
</body>
</html>