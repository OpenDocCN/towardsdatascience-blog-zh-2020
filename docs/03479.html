<html>
<head>
<title>Roadmap to Computer Vision</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算机视觉路线图</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/roadmap-to-computer-vision-79106beb8be4?source=collection_archive---------18-----------------------#2020-04-02">https://towardsdatascience.com/roadmap-to-computer-vision-79106beb8be4?source=collection_archive---------18-----------------------#2020-04-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f82a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">介绍组成计算机视觉系统的主要步骤。从图像预处理、特征提取和预测开始。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/bf69701e60db4ba022242efdc80fe809.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5nVls8Bei4qXn47E"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">恩尼奥·迪贝利在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="kz la l"/></div></figure><h1 id="542b" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">介绍</h1><p id="8bbc" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">计算机视觉是当今人工智能的主要应用之一(如图像识别、目标跟踪、多标记分类)。在本文中，我将带您了解组成计算机视觉系统的一些主要步骤。</p><p id="650b" class="pw-post-body-paragraph lt lu it lv b lw mp ju ly lz mq jx mb mc mr me mf mg ms mi mj mk mt mm mn mo im bi translated">计算机视觉系统工作流程的标准表示为:</p><ol class=""><li id="cd6a" class="mu mv it lv b lw mp lz mq mc mw mg mx mk my mo mz na nb nc bi translated">一组图像进入系统。</li><li id="6880" class="mu mv it lv b lw nd lz ne mc nf mg ng mk nh mo mz na nb nc bi translated">为了预处理和从这些图像中提取特征，使用了特征提取器。</li><li id="8989" class="mu mv it lv b lw nd lz ne mc nf mg ng mk nh mo mz na nb nc bi translated">机器学习系统利用提取的特征来训练模型并进行预测。</li></ol><p id="7e5c" class="pw-post-body-paragraph lt lu it lv b lw mp ju ly lz mq jx mb mc mr me mf mg ms mi mj mk mt mm mn mo im bi translated">现在，我们将简要介绍一些主要流程，数据可能会经历这三个不同的步骤。</p><h1 id="962e" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">图像进入系统</h1><p id="f139" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">在尝试实现CV系统时，我们需要考虑两个主要组件:图像采集硬件和图像处理软件。部署CV系统的主要要求之一是测试其健壮性。事实上，我们的系统应该能够不受环境变化的影响(比如光照、方向、比例的变化),并且能够重复执行设计的任务。为了满足这些要求，可能有必要对我们系统的硬件或软件应用某种形式的约束(例如，远程控制照明环境)。</p><p id="cb7e" class="pw-post-body-paragraph lt lu it lv b lw mp ju ly lz mq jx mb mc mr me mf mg ms mi mj mk mt mm mn mo im bi translated">一旦从硬件设备获得图像，在软件系统中有许多可能的方法来用数字表示颜色(颜色空间)。两个最著名的颜色空间是RGB(红、绿、蓝)和HSV(色调、饱和度、值)。使用HSV颜色空间的一个主要优点是，通过只取HS分量，我们可以使我们的系统光照不变(图1)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/5bdd895e7d3298993d699acdbff63d61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R1VPTG4lcLawrz-XlMjQ-Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图1: RGB与HSV色彩空间[1]</p></figure><h1 id="6e3d" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">特征提取器</h1><h2 id="6350" class="nj lc it bd ld nk nl dn lh nm nn dp ll mc no np ln mg nq nr lp mk ns nt lr nu bi translated">图像预处理</h2><p id="20a5" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">一旦图像进入系统并使用颜色空间来表示，我们就可以对图像应用不同的操作符来改善其表示:</p><ul class=""><li id="7d0c" class="mu mv it lv b lw mp lz mq mc mw mg mx mk my mo nv na nb nc bi translated"><strong class="lv iu">点操作符</strong>:我们使用图像中的所有点来创建原始图像的变换版本(为了明确图像内部的内容，而不改变其内容)。点算子的一些例子是:强度归一化、直方图均衡化和阈值化。点操作符通常用于帮助人类视觉更好地可视化图像，但不一定为计算机视觉系统提供任何优势。</li><li id="d405" class="mu mv it lv b lw nd lz ne mc nf mg ng mk nh mo nv na nb nc bi translated"><strong class="lv iu">组操作符</strong>:在这种情况下，我们从原始图像中取出一组点，以便在图像的变换版本中创建一个点。这种类型的运算通常通过使用卷积来完成。可以使用不同类型的核与图像进行卷积，以获得我们的变换结果(图2)。一些例子是:直接平均，高斯平均和中值滤波。因此，对图像应用卷积运算可以减少图像中的噪点数量并提高平滑度(尽管这也可能会导致图像略微模糊)。因为我们使用一组点来在新图像中创建单个新点，所以新图像的尺寸必然会比原始图像的尺寸小。这个问题的一个解决方案是应用零填充(将像素值设置为零)或在图像边界使用较小的模板。使用卷积的一个主要限制是在处理大模板时的执行速度，这个问题的一个可能的解决方案是使用傅立叶变换。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/5bfdd52f5099cbe0f9acf324fcbe4904.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*nDCLdHdKK32s8PohosPxwQ.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图2: <a class="ae ky" href="https://stats.stackexchange.com/questions/296679/what-does-kernel-size-mean/296701" rel="noopener ugc nofollow" target="_blank">核卷积</a></p></figure><p id="360f" class="pw-post-body-paragraph lt lu it lv b lw mp ju ly lz mq jx mb mc mr me mf mg ms mi mj mk mt mm mn mo im bi translated">对图像进行预处理后，我们可以应用更先进的技术，通过使用一阶边缘检测(例如Prewitt算子、Sobel算子、Canny边缘检测器)和Hough变换等方法，尝试提取图像中的边缘和形状。</p><h2 id="c7ca" class="nj lc it bd ld nk nl dn lh nm nn dp ll mc no np ln mg nq nr lp mk ns nt lr nu bi translated">特征抽出</h2><p id="b97d" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">一旦预处理了图像，有4种主要类型的特征形态可以通过使用特征提取器从图像中提取:</p><ul class=""><li id="3206" class="mu mv it lv b lw mp lz mq mc mw mg mx mk my mo nv na nb nc bi translated"><strong class="lv iu">全局特征</strong>:将整幅图像作为一个整体进行分析，从特征提取器中提取出一个特征向量。全局特征的一个简单例子可以是面元像素值的直方图。</li><li id="084a" class="mu mv it lv b lw nd lz ne mc nf mg ng mk nh mo nv na nb nc bi translated"><strong class="lv iu">基于网格或块的特征</strong>:将图像分割成不同的块，从每个不同的块中提取特征。为了从图像的块中提取特征，使用的主要技术之一是密集SIFT(尺度不变特征变换)。这种类型的特征被广泛用于训练机器学习模型。</li><li id="bdc6" class="mu mv it lv b lw nd lz ne mc nf mg ng mk nh mo nv na nb nc bi translated"><strong class="lv iu">基于区域的特征</strong>:将图像分割成不同的区域(例如，使用阈值或K-Means聚类等技术，然后使用连通分量将它们连接成片段)，并从这些区域中的每一个提取特征。可以通过使用诸如矩和链码的区域和边界描述技术来提取特征)。</li><li id="6ad0" class="mu mv it lv b lw nd lz ne mc nf mg ng mk nh mo nv na nb nc bi translated"><strong class="lv iu">局部特征</strong>:在图像中检测多个单个兴趣点，通过分析兴趣点附近的像素提取特征。可以从图像中提取的两种主要类型的兴趣点是角点和斑点，这些可以通过使用诸如哈里斯&amp;斯蒂芬斯检测器和高斯的拉普拉斯算子的方法来提取。通过使用诸如SIFT(尺度不变特征变换)的技术，可以最终从检测到的兴趣点提取特征。通常使用局部特征来匹配图像以构建全景/3D重建或从数据库中检索图像。</li></ul><p id="c854" class="pw-post-body-paragraph lt lu it lv b lw mp ju ly lz mq jx mb mc mr me mf mg ms mi mj mk mt mm mn mo im bi translated">一旦提取了一组区别特征，我们就可以使用它们来训练机器学习模型进行推理。使用像<a class="ae ky" href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_sift_intro/py_sift_intro.html" rel="noopener ugc nofollow" target="_blank"> OpenCV </a>这样的库，可以很容易地在Python中应用特性描述符。</p><h1 id="45ab" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">机器学习</h1><p id="9080" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">计算机视觉中用于对图像进行分类的主要概念之一是视觉单词包(BoVW)。为了构建一个视觉单词包，我们首先需要通过从一组图像中提取所有特征来创建一个词汇表(例如，使用基于网格的特征或局部特征)。随后，我们可以计算提取的特征在图像中出现的次数，并根据结果构建频率直方图。使用频率直方图作为基本模板，我们可以通过比较它们的直方图来最终分类一幅图像是否属于同一类(图3)。</p><p id="597d" class="pw-post-body-paragraph lt lu it lv b lw mp ju ly lz mq jx mb mc mr me mf mg ms mi mj mk mt mm mn mo im bi translated">这个过程可以总结为以下几个步骤:</p><ol class=""><li id="03f5" class="mu mv it lv b lw mp lz mq mc mw mg mx mk my mo mz na nb nc bi translated">我们首先通过使用特征提取算法(如SIFT和Dense SIFT)从图像数据集中提取不同的特征来构建词汇表。</li><li id="a464" class="mu mv it lv b lw nd lz ne mc nf mg ng mk nh mo mz na nb nc bi translated">其次，我们使用K-Means或DBSCAN等算法对词汇表中的所有特征进行聚类，并使用聚类质心来总结我们的数据分布。</li><li id="2ef3" class="mu mv it lv b lw nd lz ne mc nf mg ng mk nh mo mz na nb nc bi translated">最后，我们可以通过计算词汇中的不同特征在图像中出现的次数，从每个图像中构建一个频率直方图。</li></ol><p id="812b" class="pw-post-body-paragraph lt lu it lv b lw mp ju ly lz mq jx mb mc mr me mf mg ms mi mj mk mt mm mn mo im bi translated">然后，可以通过对我们想要分类的每个图像重复相同的过程来分类新图像，然后使用任何分类算法来找出我们的词汇表中哪个图像与我们的测试图像最相似。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/0cf4bdfbcc954e00c65aabfb00cf9446.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*lkH57rnmkb9AVIOhWTJ1rg.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图3:视觉单词包[2]</p></figure><p id="1a2a" class="pw-post-body-paragraph lt lu it lv b lw mp ju ly lz mq jx mb mc mr me mf mg ms mi mj mk mt mm mn mo im bi translated">如今，由于人工神经网络架构的创建，如卷积神经网络(CNN)和递归人工神经网络(RCNNs)，已经有可能构思出计算机视觉的替代工作流(图4)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/7cc9c0675d0c14a0857ced633aa4cda7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*f_cn3EWJ3LdO0RhSPIxC7g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图4:计算机视觉工作流程[3]</p></figure><p id="6bb7" class="pw-post-body-paragraph lt lu it lv b lw mp ju ly lz mq jx mb mc mr me mf mg ms mi mj mk mt mm mn mo im bi translated">在这种情况下，深度学习算法结合了计算机视觉工作流程的特征提取和分类步骤。当使用卷积神经网络时，在将特征向量提供给密集层分类器之前，神经网络的每一层在其描述中应用不同的特征提取技术(例如，第1层检测边缘，第2层发现图像中的形状，第3层分割图像等等)。</p><p id="a2f0" class="pw-post-body-paragraph lt lu it lv b lw mp ju ly lz mq jx mb mc mr me mf mg ms mi mj mk mt mm mn mo im bi translated">机器学习在计算机视觉中的进一步应用包括多标记分类和对象识别等领域。在多标记分类中，我们的目标是构建一个模型，能够正确地识别一幅图像中有多少个对象以及它们属于哪一类。相反，在对象识别中，我们的目标是通过识别图像中不同对象的位置，将这一概念向前推进一步。</p><h1 id="94ec" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">联系人</h1><p id="956e" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">如果你想了解我最新的文章和项目<a class="ae ky" href="https://medium.com/@pierpaoloippolito28?source=post_page---------------------------" rel="noopener">，请通过媒体</a>关注我，并订阅我的<a class="ae ky" href="http://eepurl.com/gwO-Dr?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">邮件列表</a>。以下是我的一些联系人详细信息:</p><ul class=""><li id="c4e3" class="mu mv it lv b lw mp lz mq mc mw mg mx mk my mo nv na nb nc bi translated"><a class="ae ky" href="https://uk.linkedin.com/in/pier-paolo-ippolito-202917146?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">领英</a></li><li id="afb3" class="mu mv it lv b lw nd lz ne mc nf mg ng mk nh mo nv na nb nc bi translated"><a class="ae ky" href="https://pierpaolo28.github.io/blog/?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">个人博客</a></li><li id="f130" class="mu mv it lv b lw nd lz ne mc nf mg ng mk nh mo nv na nb nc bi translated"><a class="ae ky" href="https://pierpaolo28.github.io/?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">个人网站</a></li><li id="ea0b" class="mu mv it lv b lw nd lz ne mc nf mg ng mk nh mo nv na nb nc bi translated"><a class="ae ky" href="https://towardsdatascience.com/@pierpaoloippolito28?source=post_page---------------------------" rel="noopener" target="_blank">中等轮廓</a></li><li id="9884" class="mu mv it lv b lw nd lz ne mc nf mg ng mk nh mo nv na nb nc bi translated"><a class="ae ky" href="https://github.com/pierpaolo28?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"> GitHub </a></li><li id="3480" class="mu mv it lv b lw nd lz ne mc nf mg ng mk nh mo nv na nb nc bi translated"><a class="ae ky" href="https://www.kaggle.com/pierpaolo28?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">卡格尔</a></li></ul><h1 id="dd73" class="lb lc it bd ld le lf lg lh li lj lk ll jz lm ka ln kc lo kd lp kf lq kg lr ls bi translated">文献学</h1><p id="f181" class="pw-post-body-paragraph lt lu it lv b lw lx ju ly lz ma jx mb mc md me mf mg mh mi mj mk ml mm mn mo im bi translated">[1]用作海滩清洁工的模块化机器人，Felippe Roza。研究之门。访问:<a class="ae ky" href="https://www.researchgate.net/figure/RGB-left-and-HSV-right-color-spaces_fig1_310474598" rel="noopener ugc nofollow" target="_blank">https://www . research gate . net/figure/RGB-left-and-HSV-right-color-spaces _ fig 1 _ 310474598</a></p><p id="0d4e" class="pw-post-body-paragraph lt lu it lv b lw mp ju ly lz mq jx mb mc mr me mf mg ms mi mj mk mt mm mn mo im bi translated">[2]OpenCV中的视觉词汇包，视觉与图形组<em class="nz">。扬·昆德拉克。访问:<em class="nz"/><a class="ae ky" href="https://vgg.fiit.stuba.sk/2015-02/bag-of-visual-words-in-opencv/" rel="noopener ugc nofollow" target="_blank">https://vgg . fiit . stuba . sk/2015-02/bag-of-visual-words-in-opencv/</a></em></p><p id="8cf6" class="pw-post-body-paragraph lt lu it lv b lw mp ju ly lz mq jx mb mc mr me mf mg ms mi mj mk mt mm mn mo im bi translated">【3】深度学习Vs传统计算机视觉。哈里塔·蒂拉卡拉恩，纳迪斯人。访问网址:<a class="ae ky" href="https://naadispeaks.wordpress.com/2018/08/12/deep-learning-vs-traditional-computer-vision/" rel="noopener ugc nofollow" target="_blank">https://naadispeaks . WordPress . com/2018/08/12/deep-learning-vs-traditional-computer-vision/</a></p></div></div>    
</body>
</html>