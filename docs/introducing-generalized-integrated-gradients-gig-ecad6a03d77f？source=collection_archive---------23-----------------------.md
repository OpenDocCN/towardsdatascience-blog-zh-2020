# 引入广义积分梯度(GIG)

> 原文：<https://towardsdatascience.com/introducing-generalized-integrated-gradients-gig-ecad6a03d77f?source=collection_archive---------23----------------------->

## 一种解释不同集成机器学习模型的实用方法

![](img/6dac0be642277b5cccb97155f2e3c7ef.png)

布莱克·惠勒在 [Unsplash](https://unsplash.com/s/photos/illuminated?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上拍摄的照片

*   *集成机器学习模型* [*比单个 ML 模型单独提供更高的预测准确性*](https://www.zest.ai/blog/many-heads-are-better-than-one-making-the-case-for-ensemble-learning) *和稳定性，但集成模型很难用普通的可解释方法来解释和信任。*
*   Zest AI *开发了一种新方法来解释复杂的集成模型，称为广义集成梯度，使它们可以安全地用于高风险应用，如信用风险承保。与其他方法不同，GIG 直接遵循一小组合理的规则，不需要任何武断的假设。*

**为什么需要新的信用分配方法**

在全球经济中部署机器学习的所有方式中，影响最大的应用之一是信贷承销。机器学习被证明可以更好地预测借款人违约，增加需要贷款的人获得信贷的机会，并减少贷款中的偏见。但并不是所有的机器学习技术，包括监管较少的应用中的大量技术，都是透明的。许多被部署的算法会产生难以解释的结果。最近，研究人员提出了新颖而强大的方法来解释机器学习模型，特别是 [Shapley 加法解释](https://arxiv.org/abs/1705.07874) (SHAP 解释者)和[积分梯度](https://arxiv.org/abs/1703.01365) (IG)。这些方法提供了为模型用来生成分数的数据变量分配信用的机制。他们通过将机器学习模型表示为一个游戏来工作:每个变量都是一个玩家，游戏的规则是模型的得分函数，游戏的价值是模型给出的分数。合作博弈中的信用分配是一个众所周知的问题。

[SHAP](https://arxiv.org/pdf/1705.07874.pdf) 使用各种方法来计算沙普利值，这在原子游戏中很有效，通过重新计算模型的结果来识别最重要的变量，每个变量都被系统地删除。当算法是一个神经网络，它运行无限小的小游戏，这些小游戏中没有一个是单独重要的，但它们在总体上是重要的，你需要[积分梯度](https://arxiv.org/pdf/1703.01365.pdf)来解释一个模型。IG 使用 Aumann-Shapley 值来了解两个申请人之间模型分数的差异。它量化了每个输入变量对模型得分差异的贡献。毕竟，根据模型，有些变化比其他变化更重要，因此我们的任务是衡量模型认为哪些变化更重要或更不重要。

这两者本身都是伟大的创新，但都没有为实现最佳结果的混合型模式提供令人满意的信用分配。SHAP 包中实现的解释器要么要求变量在统计上是独立的，要么要求缺失值可以用平均值代替。这两者都不是金融服务业的新手。IG 要求模型处处可微，这对于决策树来说是不正确的，所以它只对像神经网络这样的模型有效。

谷歌、脸书和微软等大型科技公司多年来一直在利用集成 ML 的优势。他们使用树和神经网络以及一整套建模数学来构建模型，但他们不像金融服务公司那样在相同的监管约束下运营。银行和贷款机构将从将这些同类高级模型用于信贷承销和欺诈检测等应用中获益匪浅。(查看我们的[最近的帖子](https://www.zest.ai/blog/many-heads-are-better-than-one-making-the-case-for-ensemble-learning)介绍了一种叫做深度堆叠的新方法，这种方法为一家小型贷款机构带来了 1300 万美元的利润和一个更准确、更稳定的模型。)

所有的箭头都指向需要一种新的方式来解释复杂的、集合的 ML 模型，用于高风险的应用，如信贷和借贷。这也是 [Zest AI](http://www.zest.ai/) 开发 GIG 的原因。

**引入广义综合梯度**

[广义积分梯度](https://arxiv.org/abs/1909.01869) (GIG)是一种新的信用分配算法，它通过应用[测度理论](https://www.amazon.com/Principles-Mathematical-Analysis-International-Mathematics/dp/007054235X)的工具，克服了 Shapley 和 Aumann-Shapley 的局限性。GIG 是 IG 的正式扩展，它可以为更广泛的模型准确分配信用，包括目前在机器学习领域使用的几乎所有评分功能。GIG 是严格计算每个变量对不同模型集合的贡献的唯一方法。

GIG 更好地解释复杂的 ML 模型是因为它避免了对数据做出不切实际和潜在危险的假设。GIG 直接遵循它的公理。使用 SHAP 和其他基于 Shapley 值的方法，您必须将输入变量映射到一个更高维的空间，以便让这些值为机器学习功能工作。这样的映射有无数种，并且不清楚哪种是正确的映射(如果有的话)。相比之下，GIG 完全由数学决定。

GIG 通过直接分段分析模型函数来分配信用，以回答问题“哪些输入变量导致了模型分数的变化？”它根据一个独特的公式来计算每个变量导致预测函数改变其得分的数量，通过沿从第一个输入到另一个输入的路径累积模型得分的变化来测量每个变量的重要性。

**现实世界信用风险模型的应用**

为了展示 GIG 的能力，我们用它来解释一个从真实世界贷款数据构建的混合集合模型。该模型，如下图所示并在前面引用，是 4 个 XGBoost 模型和 2 个神经网络模型的堆叠集合。

![](img/bfd14a2b444031856a56ffa6cd51a5fc.png)

图 1:深度堆叠集成:训练数据用于训练多个子模型，其中一些可能是基于树的模型，如 XGBoost，其他是神经网络，然后使用神经网络将它们与输入一起集成到更大的模型中。

任何模型可解释性任务中的表格利害关系是精确量化模型中每个特征的重要性。我们进行了一系列实验(在我们的论文中进行了描述),这些实验表明 GIG 准确地量化了简单模型中变量的影响。实验基于输入数据的已知变化建立了一系列玩具模型，我们表明 GIG 能够准确地描述模型从故意修改的数据中学到了什么。这里，我们来看一个真实世界的应用程序。表 1 显示了图 1 中显示的更复杂集合的特征重要性。表格显示，GIG 甚至可以解释这个更复杂的真实世界模型。

![](img/42f97593c0d09e937181adc2818ce492.png)

表 1:图 1 所示集合的特征重要性。

除了计算整体特征的重要性，GIG 还允许您量化每个申请人和各种人群的特征重要性，例如表现最好和表现最差的贷款，或者导致男女申请人之间批准率差异的变量。

**GIG 如何工作**

正如我们之前提到的，GIG 是基于 IG 和 [Aumann-Shapley](https://en.wikipedia.org/wiki/Shapley_value#Aumann%E2%80%93Shapley_value) 的一个差分信用分配函数。差异信用分配回答了输入的每次变化会在多大程度上引起模型分数变化的问题。您比较两个申请人之间的输入集以及模型为每个申请人返回的违约可能性(例如，一个申请人可能被拒绝，而另一个申请人可能被批准)。GIG 显示了每个输入变量对导致批准/拒绝决策的分数变化的影响程度。

让我们想象一下这一切是如何工作的。图 2 用绿色显示了一组批准的申请人，用红色显示了一组拒绝的申请人。被拒的申请人有很高的拖欠和破产率。被批准的申请人则相反。

![](img/3781a849d57f0920457f87f967a90b0c.png)

图二。这个模型考虑了两个变量:破产和拖欠。获批的申请人破产率和拖欠率都很低。被拒绝的申请人破产率和拖欠率都很高。

像 GIG 这样的差别信贷分配功能通过比较每个被批准的申请人和每个被拒绝的申请人来解释两类申请人之间的差异:你基本上是在计算每对被批准和被拒绝的申请人之间拖欠和破产的差异，并取平均值。下面的图 3 展示了这一比较中的一对的过程。

![](img/dd4f7a406fb8d10606206415debf3a67.png)

图 3。红色的被拒绝的申请人和绿色的被批准的申请人之间的分数差异可以用拖欠率的差异和破产数的差异来解释。

这仅用于说明，图表中缺少模型分数。下面的图 4 显示了一个更真实的画面，它显示了模型分数如何随着拖欠和破产变量沿着被拒绝的申请人和被批准的申请人之间的路径而变化。IG 方法使用 Aumann-Shapley 值来计算违约和破产对批准和拒绝申请人之间的模型分数变化的影响。

![](img/514c43f6a0a47a92b95b2e6c365b9258.png)

图 4。这里，模型分数由 y 轴表示。x 轴和 z 轴代表拖欠和破产数量。沿着被拒绝的申请人(红点)和被批准的申请人(绿点)之间的路径的偏导数的积分代表每个变量(拖欠 x 和破产 z)对模型得分 y 的 Aumann-Shapley 贡献

一个模型可以有任何数量的维度，欧曼-沙普利将容纳它们。但正如我们之前所说，Aumann-Shapley 值只适用于像神经网络这样的平滑函数。图 5 展示了一个 Aumann-Shapley(以及 IG)无法解释的函数组合的简单例子。

![](img/e805335ff9efc768f9e6808a47708552.png)

图 5。函数组合示例。这里，离散组件用红色表示，表示在 x=1.75 处具有跳跃不连续性的决策树。连续部分以蓝色显示。这两个函数的组合以绿色显示。组合函数在 x=1.75 处包含跳跃不连续性，就像作为其一部分的离散函数一样。Shapley 或 Aumann-Shapley 无法充分解释这些功能，它们需要像 GIG 这样不同的东西。

GIG 首先枚举离散函数中的所有不连续点(例如，通过模型决策树的深度优先搜索),然后从每个不连续点的左侧和右侧计算离散函数的值。它根据这两个值的平均值分配分数，如下图 6 的左图所示。分配给连续零件的信用是使用 IG 计算的(图 6 的右图)。然后将离散和连续成分放回一起，以得到高度精确的组合成分。

![](img/fb0a50f78edd73bd8a23dff88dc44556.png)

图 6。GIG 的工作原理是，通过对离散部分左边和右边的值求平均值，然后将其与 Aumann-Shapley 对连续部分分配的信用相结合，来计算跳跃点的信用。

**结论**

集合模型比任何单独的建模方法产生更好的结果，但是迄今为止它们不可能被准确地解释。我们引入了一种新方法，[广义积分梯度](https://arxiv.org/abs/1909.01869)，这是在一小组合理的公理下，解释我们在机器学习的真实世界应用(如金融服务)中经常遇到的不同集合和函数组合的唯一方法。GIG 使得在你的贷款业务中使用这些先进的、更有效的模型成为可能，以制造更多的好贷款和更少的坏贷款，并且仍然向消费者、监管者和企业所有者解释结果。

最初的 [GIG 论文](https://arxiv.org/abs/1909.01869)是由 Zest AI 的[约翰·梅里尔](https://arxiv.org/search/cs?searchtype=author&query=Merrill%2C+J)、[杰夫·沃德](https://arxiv.org/search/cs?searchtype=author&query=Ward%2C+G)、[肖恩·卡姆卡](https://arxiv.org/search/cs?searchtype=author&query=Kamkar%2C+S)、[杰伊·布齐克](https://arxiv.org/search/cs?searchtype=author&query=Budzik%2C+J)和[道格拉斯·梅里尔](https://arxiv.org/search/cs?searchtype=author&query=Merrill%2C+D)撰写的。