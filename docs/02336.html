<html>
<head>
<title>Using Word Embeddings for Journalistic Research</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用词语嵌入进行新闻研究</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-word-embeddings-as-a-method-for-journalistic-research-ae82ffea7a62?source=collection_archive---------17-----------------------#2020-03-05">https://towardsdatascience.com/using-word-embeddings-as-a-method-for-journalistic-research-ae82ffea7a62?source=collection_archive---------17-----------------------#2020-03-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8ee9" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">为了分析政治演讲中词语的语境，我不得不跨界到计算语言学。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a318c0f5ac23823749a863211a53d7ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nFQU6imOA7xef-II"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">一个词向量从1949年到2019年随时间变化的可视化。</p></figure><p id="0f92" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">像大多数其他领域一样，新闻业正在走向数字化。我是德国《南德意志报》数据和数字调查团队的一员，在那里，我们试图利用现代技术手段开展新闻研究。</p><p id="f1fe" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在我最新的项目中，我结合了政策分析和机器学习。我想知道:随着时间的推移，政治语言和某些词汇的使用发生了怎样的变化？</p><p id="69c1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">自1949年5月德意志联邦共和国成立以来，70年已经过去了。在这段时间里，被称为<a class="ae lu" href="https://en.wikipedia.org/wiki/Bundestag" rel="noopener ugc nofollow" target="_blank"> <em class="lv">联邦议院</em> </a>的联邦议会4200多次会议的每一次都被一丝不苟地记录下来:每一次演讲、每一次评论、每一次鼓掌都被记录下来。一个保存德国近代史、深远发展和重大政治冲突的数据宝库。</p><p id="7018" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当然，计算机理解语言的方式与人类不同。相反，计算语言学的数学系统从上下文中揭示单词的含义。语言学家约翰·鲁帕特·弗斯在1957年说过一句著名的话:“你应该从一个单词所交的朋友那里知道这个单词”，这远在计算机被用来寻找内容的上下文之前。然而，这个原则在21世纪仍然适用，那时算法可以接管这项任务。</p><p id="06bf" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我选择的自动评估文本的方法叫做单词嵌入。我们无时无刻不在与这项技术互动，例如在进行简单的谷歌搜索或使用翻译软件时。我将计算语言学科学领域的这些方法应用于政治修辞学。</p><p id="9b61" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在我读到的每一篇关于单词嵌入的论文中，都有这样的短语:“有前途的新领域”或“大量研究”。是的，两者都被证明是真的…</p><h1 id="d678" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">算法输入:输入数据</h1><p id="a8ef" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">像世界上其他国家一样，德国议会记录了议员们的一言一行。得到的文档是我分析的语料库。</p><p id="1f61" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我对随着时间的推移而发生的变化感兴趣，所以我不会在这些年里创建一个大型语料库，但是每个立法术语都有自己的语料库。所以总共有19个不同的语料库。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="049f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从表中可以看出，单个语料库并不是很大。这导致了如何将单词嵌入方法应用于19个相当小的议会记录语料库的第一个重大决定。</p><p id="c4a6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">大多数研究论文引用了更多数据的项目。这是发人深省的，因为这些方法不能简单地应用于我的情况。但是我在Antoniak et里发现了一张桌子。艾尔。(2018) 那真让我振奋。它区分了两种不同的方法:以下游为中心的方法，一种是针对大型语料库的通用方法，另一种是针对特定领域(如政治)的以语料库为中心的方法。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mv"><img src="../Images/da72920c4013bbdc674ad3fc7e5c907c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*I1e3w4jgnQhYHjdT"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="mw">以下游为中心和以语料库为中心的词汇嵌入方法比较。截图:安东尼亚克等人。艾尔。(2018) </em></p></figure><p id="de82" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这种区别决定了分析的方法，正如安东尼亚克和明诺所写的:</p><blockquote class="mx my mz"><p id="124d" class="ky kz lv la b lb lc ju ld le lf jx lg na li lj lk nb lm ln lo nc lq lr ls lt im bi translated"><em class="it">“与以下游为中心的方法不同，以语料库为中心的方法基于对嵌入向量的最近邻居的直接人类分析，训练语料库不仅仅是现成的便利，而是研究的中心对象。”</em></p></blockquote><h1 id="f43f" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">人类和计算机之间的翻译:单词嵌入</h1><p id="3c90" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">计算语言学使用的一种从上下文中提取单词含义的方法叫做单词嵌入。语料库中的每个词通过上下文和语义嵌入到模型中。关于德国议会的记录，这意味着:当计算单词嵌入的模型时，议会成员的语言的上下文和语义被嵌入到模型中。</p><p id="0070" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">每一个独特的单词都由一系列数字(也称为维度)来表示，这些数字是在学习上下文的过程中计数和权衡的结果。这个过程叫做“训练模型”。</p><p id="13dd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">结果看起来像这样:</p><blockquote class="mx my mz"><p id="233d" class="ky kz lv la b lb lc ju ld le lf jx lg na li lj lk nb lm ln lo nc lq lr ls lt im bi translated">环境<em class="it">(um welt)(0.08567299 0.11279329 0.2180736-0.3106728…)<br/></em>自然保护<em class="it">(Naturschutz)(-0.012405696 0.07818038-0.045643393-0.0051204716…)<br/></em>气候灾害</p></blockquote><p id="8253" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">学习机的能力隐藏在这些乍看起来不起眼的单词和数字序列中。</p><p id="402c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这组向量携带以下信息:</p><ul class=""><li id="14d0" class="nd ne it la b lb lc le lf lh nf ll ng lp nh lt ni nj nk nl bi translated">每个向量描述了单词的<strong class="la iu">上下文</strong></li><li id="4810" class="nd ne it la b lb nm le nn lh no ll np lp nq lt ni nj nk nl bi translated">相对于所有其他向量，每个向量对单词的<strong class="la iu">含义</strong>进行编码</li></ul><p id="cb5d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">理论上，维度越多，一个向量可以包含的意义就越多。但实际上，它受到你输入算法的文本量的限制。寻找最佳长度可能是一个反复试验的评估过程。在这里，我使用300个维度。这是许多研究人员使用的默认设置，我坚持他们的经验。</p><p id="fa06" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">单词嵌入的用户可以自由决定应该计算多少维度。这样的设置选项在机器学习中被称为<a class="ae lu" href="https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)" rel="noopener ugc nofollow" target="_blank">超参数</a>。它们的调整会严重影响结果，并且用户在实现机器学习模型时会反复面临做出这样的决定。</p><p id="c546" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请记住，嵌入模型中的含义只适用于特定的领域。在这种情况下:在过去的70年里，德国议会的演讲。</p><p id="d027" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，一种算法将文本语料库作为输入，并返回计算出的单词向量。但是这是怎么发生的呢？</p><h1 id="2635" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">单词如何变成数字:word2vec算法</h1><p id="01ad" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">有几种可能的算法可以解决计算单词嵌入的任务。对于这个项目，我选择了有据可查的<a class="ae lu" href="https://code.google.com/archive/p/word2vec/" rel="noopener ugc nofollow" target="_blank"> word2vec </a>算法。它于2013年在谷歌推出(<a class="ae lu" href="https://arxiv.org/abs/1310.4546" rel="noopener ugc nofollow" target="_blank">米科洛夫等人，2013年a </a>)。许多科学论文测试了单词嵌入算法，并得出结论:word2vec是最佳选择。我使用了Python的实现gensim ( <a class="ae lu" href="https://radimrehurek.com/gensim/models/word2vec.html" rel="noopener ugc nofollow" target="_blank"> Rehurek和Sojka，2010 </a>)。</p><p id="e363" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">首先，构建词汇表:从输入文本中提取并存储每个唯一的单词。Word2vec通过检查哪些单词在特定上下文中一起出现来从文本中学习。上下文被定义为在被检查的单词周围的窗口。窗口的大小是要设置的另一个超参数。</p><p id="2801" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们来看这句话:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/e385397d0df4ac69a4f8ece144fb8511.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*niwGDFMz9LtTD6q6"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="mw">截图:</em><a class="ae lu" href="https://medium.com/@jayeshbahire/introduction-to-word-vectors-ea1d4e4b84bf" rel="noopener"><em class="mw">jaye sh Bapu Ahire的《词向量入门》</em> </a></p></figure><p id="c4e1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们要用五个单词的窗口大小来训练<em class="lv">狗</em>的向量:用黄色标记的单词是从词汇表中挑选出来的，并在窗口内的每一对可能的单词上进行训练:<em class="lv"> The </em>、<em class="lv"> fluffy </em>、<em class="lv">汪汪汪</em>、<em class="lv"> as </em>。紧邻的单词被赋予更高的权重。例如，<em class="lv">蓬松的</em> + <em class="lv">剥皮的</em>被赋予比<em class="lv">更大的权重，把</em> + <em class="lv">称为</em>。</p><p id="e4b7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">接下来，我们再深入一个词，看看<em class="lv">吠</em>。窗口向前移动一个单词，并且相邻单词被加权。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/becdd6e42d24f326cfb831d56fbef981.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Zfzuxdt4qu9JX9nm"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="mw">截图:</em><a class="ae lu" href="https://medium.com/@jayeshbahire/introduction-to-word-vectors-ea1d4e4b84bf" rel="noopener"><em class="mw">Jayesh Bapu Ahire著《词向量入门》</em> </a></p></figure><p id="a47c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">通过这种方式，该窗口迭代了自1949年以来的所有议会演讲。</p><p id="e53c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所有出现的单词对都是一维神经网络训练的输入。Word2vec旨在计算一个模型，该模型可以预测一个单词与另一个单词出现的可能性。为了解决这个任务，有一个隐藏层，其神经元的数量与向量的维数一样多。</p><blockquote class="mx my mz"><p id="8844" class="ky kz lv la b lb lc ju ld le lf jx lg na li lj lk nb lm ln lo nc lq lr ls lt im bi translated">“<em class="it">单词vector是模型试图学习单词的良好数字表示，以最小化其预测的损失(误差)</em>,<a class="ae lu" href="https://medium.com/@jayeshbahire/introduction-to-word-vectors-ea1d4e4b84bf" rel="noopener">Jayesh Bapu Ahire</a>写道。</p></blockquote><p id="07ee" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，当训练过程结束时，输出层被剥离。单词向量是经过训练的神经元的结果。在机器学习领域，这被称为假任务:你可以在一个任务上训练一个模型，你有足够的数据，然后扔掉最后一层。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/fb196e4ebc4ecba7e9577b4d9021269b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0yZacnOOpWR_vSf-"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="mw">word 2 vec的内部运作方式。截图:</em><a class="ae lu" href="https://medium.com/@jayeshbahire/introduction-to-word-vectors-ea1d4e4b84bf" rel="noopener"><em class="mw">Jayesh Bapu Ahire</em></a>对词向量的介绍</p></figure><p id="8e90" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你想更深入地研究词向量和神经网络，我推荐这些博客帖子(按书呆子气升序排列):</p><ol class=""><li id="b1c5" class="nd ne it la b lb lc le lf lh nf ll ng lp nh lt nu nj nk nl bi translated">Jayesh Bapu Ahire 对单词向量的非常好的<a class="ae lu" href="https://medium.com/@jayeshbahire/introduction-to-word-vectors-ea1d4e4b84bf" rel="noopener">介绍。你会认出上面的图形</a></li><li id="a2f2" class="nd ne it la b lb nm le nn lh no ll np lp nq lt nu nj nk nl bi translated">在<a class="ae lu" href="http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/" rel="noopener ugc nofollow" target="_blank"> Word2Vec教程—跳格模型</a>中有更多关于神经元网络和跳格实现的细节</li><li id="ef23" class="nd ne it la b lb nm le nn lh no ll np lp nq lt nu nj nk nl bi translated">如果你还需要更多关于神经元网络内部发生了什么的信息:<a class="ae lu" rel="noopener" target="_blank" href="/word2vec-made-easy-139a31a4b8ae"> Word2vec使之变得容易</a></li></ol><h1 id="f318" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">用语言计算:文字作为数字的魔力</h1><p id="073d" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">在训练过程中，该模型不仅识别单词的上下文，还从概念上学习语法类别，如数、格或性别。这些关系被编码在模型的维度中。</p><p id="699c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一个概念性的例子:想象向量“女总理”(<em class="lv"> Bundeskanzlerin </em>)、“男总理”(<em class="lv"> Bundeskanzler </em>)、“女人”(<em class="lv"> Frau </em>)和“男人”(<em class="lv"> Mann </em>)有四个维度和虚构的数字。</p><p id="7626" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">考虑从左边开始的第二维:向量“女总理”(<em class="lv"> Bundeskanzlerin </em>)和“女人”(<em class="lv"> Frau </em>)具有高值，而“男总理”(<em class="lv"> Bundeskanzler </em>)和“男人”(<em class="lv"> Mann </em>)具有低值。这个维度可能被贴上女性化的标签。从左边算起的第三维度则是相反的方向，暗示着男子气概。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/f64b799fa29871df122f03c7eef562e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*R1xS2stJGUW9nNy4"/></div></div></figure><p id="1d7d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">德国联邦议院模型中有300个维度，而不是4个维度——当然，没有标签。不仅仅是四个词，仅最近的选举任期就有超过61，000个词。这导致了1830万个数据点——对我们的大脑来说太复杂了，难以想象。尽管这是不可想象的，但是用向量来计算是可能的，就像回到高中一样。</p><p id="5cb2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">描述Word2Vec的这一特性时，一个通俗的例子是:“国王—男人+女人=女王”。应用来自德国议会的数据，数学运算可以用“女总理——女人+男人=男总理”来进行。</p><p id="5086" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一个很好的计算不同语料库的应用是北欧语言处理实验室的语义计算器。</p><p id="3034" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">用向量计算很有趣。但是探索广阔的向量空间可能会超出我们读者的耐心。此外，它无法回答主要问题:政治辩论正在发生怎样的变化？</p><h1 id="7456" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">解决不稳定的单词嵌入:不是一个，而是30个模型</h1><p id="2a38" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">发现政治演讲转变的主要想法是比较一届立法任期与前一届有多大不同。因此，下面的测量结果是有用的:余弦相似性。它计算两个向量之间角度的余弦值。结果是一个介于0和1之间的数字，其中0表示没有相似性，1表示绝对相似。余弦相似度越接近1，一个词就越能被解释为同义词。</p><p id="d1e9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">自71年前德意志联邦共和国成立以来，共有19届选举。对于每个术语，我计算了一个模型，然后查询模型，以提取与180个特别感兴趣的词最相似的词，例如:“气候变化”(<em class="lv"> Klimawandel </em>)，“交通”(<em class="lv"> Verkehr </em>)，“难民”(<em class="lv"> Flüchtlinge </em>)或“种族主义”(<em class="lv">rassi mus</em>)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/d0df842144b88965dd1324298ae90049.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*yh4oa-sqDrD4wIX9"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="mw">我们用于研究word嵌入模型的内部仪表盘截图。</em></p></figure><p id="ecd1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们在《南德意志报》的团队定义了一组180个高频相关术语，以便进行更深入的研究。我们没有事先选择这个查询词列表。花了一些时间在档案和数据中探索和研究，以识别有故事可讲的单词。</p><p id="e681" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如:下表显示了每个立法术语中与德语<em class="lv"> Umwelt </em>中的“环境”一词最相似的词:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx mu l"/></div></figure><p id="5967" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">很明显，在最初的20年里，这个最相似的词每一个词都在变化，而且有着与今天不同的含义。那时候，“环境”(<em class="lv"> Umwelt </em>)经常被用来描述周围的世界。这种情况在20世纪80年代发生了变化，当时绿党被选入议会，其对环境问题的关注极大地影响了“环境”一词的使用。同义词首先变成了“生计”(<em class="lv">lebengrundlage</em>)，然后进一步变成了“自然保护”(<em class="lv"> Naturschutz </em>)。近来最相似的词是“生物多样性”。</p><p id="019d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这真的很强大:单词嵌入可以重现政治辩论。但是它们有一个巨大的缺点:它们不稳定，特别是对于像我这样的相对小的语料库[1，2]。每次您使用相同的数据和相同的设置编写新模型时，针对特定术语嵌入的查询结果都会因模型而异。安东尼亚克等人。艾尔。[1]在他们的论文中研究了这一现象:</p><blockquote class="mx my mz"><p id="e8a8" class="ky kz lv la b lb lc ju ld le lf jx lg na li lj lk nb lm ln lo nc lq lr ls lt im bi translated">“我们发现嵌入中存在相当大的可变性，这些可变性对于这些方法的用户来说可能并不明显。大多数相似单词的排名是不可靠的，并且这种列表中的排序和成员资格容易发生显著变化。一些不确定性是预料之中的，对于‘可接受的’方差水平没有明确的标准，但我们认为我们观察到的变化量足以对整个方法提出质疑。”</p></blockquote><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny mu l"/></div></figure><p id="5986" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下表列出了从1983年到1987年与“环境”最相似的15个单词。这六列代表不同的型号。这些值是“环境”和行中相应单词之间的余弦相似度。空单元格意味着该模型没有将该单词识别为十大相似单词之一。</p><p id="92e6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因为单词嵌入模型是不稳定的，所以它们不会在不同的模型上提供相同的结果。例如，第二个模型不承认德语<em class="lv">leben straum</em>中的“生活空间”是“环境”的同义词，但其他五个模型承认。</p><p id="d83f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当模型产生不同的结果时，我应该相信哪一个？没有。单一模型如此不稳定的结果是新闻研究不可接受的基础。我通过训练30个模型来解决这个问题，而不是每个选举任期只训练一个。总共有570个模型用于19个选举任期。我测试了一下:我删除了所有的模型，重新计算。我的查询对新模型产生了相同的结果。所以分析是可重复的。</p><p id="4352" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当查找政治相关术语的相似词时，我从一个选举术语的所有30个模型中提取了10个最相似的词。下一步是计数过程:一个词在每个术语中作为同义词出现的频率是多少？</p><p id="5a63" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这种查询多个模型并对出现次数进行计数的过程确保了我们只检查那些在模型中反复出现并且可以被视为稳定结果的单词和伴随的嵌入。</p><p id="7045" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了可视化结果，我们使用热图。下表显示了“环境”最常见的同义词。</p><p id="ca3f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">左边的十二个字是按照1949年以来的整体面貌排序的。在这里，我们也绘制低于30的值，因为它们表示“环境”话语中某个单词的上升或下降。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/50dc3a3ab0885ef5f0cbc8e63f5ece5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jBkx7K2wqTGs4SlS"/></div></div></figure><p id="eedb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">热图是一个很好的工具，可以检查整个时间跨度并查看随时间的变化。但它们不足以详细评估一个选举任期。为此，我们使用了由30个模型的平均余弦相似性排序的相似单词列表，并用更强的字体权重标记稳定的单词。</p><p id="99f0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae lu" href="https://github.com/sueddeutsche/political-german-word-embeddings" rel="noopener ugc nofollow" target="_blank">我在Github </a>上发表了2017–2019最新选举任期的word embedding models。在德国政治领域，你可以随意使用它来完成你自己的项目。如果你这样做，请写信给我，我对你的工作很感兴趣。</p><h1 id="2289" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">意犹未尽:对历时词汇语义变化的探索</h1><p id="fa48" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">到目前为止，我们已经研究了单词的上下文是如何变化的。另一种方法是关注单词本身，看单词向量的变化。这就是所谓的历时词汇语义变化。</p><p id="a4bf" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">金等人。艾尔。[3]提供了这样做的方法。他们与<a class="ae lu" href="https://books.google.com/ngrams" rel="noopener ugc nofollow" target="_blank">谷歌图书ngram语料库</a>合作，计算了从1900年到2009年每年的一个模型。有两个词特别值得注意:“细胞”和“同性恋”。在这100年里，它们的意义发生了很大变化。" gay "的邻近词从"欢快的"、"愉快的"、"辉煌的"变成了"女同性恋"、"双性恋"和"女同性恋"，而" cell "从"壁橱"、"地牢"、"帐篷"变成了"电话"、"无绳"、"蜂窝"。</p><p id="8cb7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为德国政治争取这些词汇不是很好吗？</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/24788a8e326394573ba6f1e08574a03e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/0*JyRRax4JDnM-fPHr"/></div></figure><p id="84f5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">不幸的是，这篇论文经常被引用来批评其寻找这些单词的方法，例如，因为他们正在处理不稳定的单词嵌入。</p><p id="4744" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">幸运的是，我联系到了<a class="ae lu" href="https://www.ims.uni-stuttgart.de/en/institute/team/Schlechtweg-00003/" rel="noopener ugc nofollow" target="_blank">张秀坤·施勒特韦格</a>，他是一名博士生，与<a class="ae lu" href="http://www.schulteimwalde.de/" rel="noopener ugc nofollow" target="_blank">萨宾·舒尔特教授一起在瓦尔代</a>研究自然语言处理研究所(斯图加特大学)语义变化的分布式模型。他耐心地建议我将该方法应用于我的数据。</p><p id="1599" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Schlechtweg等人。艾尔。 [4]测试了几种测量这些变化的方法:“总体表现最好的模型是具有正交排列和余弦距离的Skip-Gram。”</p><p id="0e9b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该方法可以应用如下:</p><ol class=""><li id="6a75" class="nd ne it la b lb lc le lf lh nf ll ng lp nh lt nu nj nk nl bi translated">来自一个时间段的每个模型必须<a class="ae lu" href="https://github.com/Garrafao/LSCDetection" rel="noopener ugc nofollow" target="_blank">与下一个时间段的模型</a>对齐:时间段1到时间段2，时间段2到时间段3等等。结果是更多的模型:每次新的选举期开始，我都会得到一对新的模型。</li><li id="2abe" class="nd ne it la b lb nm le nn lh no ll np lp nq lt nu nj nk nl bi translated">对于每个单词，计算从模型到模型的余弦距离。</li><li id="5d43" class="nd ne it la b lb nm le nn lh no ll np lp nq lt nu nj nk nl bi translated">棘手的部分:为了消除频率[5]的统计影响，应该额外提取在相应术语上具有相同频率变化的可比单词。</li></ol><p id="0341" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">等等，这里有个例子:</p><p id="8d10" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">视觉推理的首次尝试:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/33a95d546475110b0efbd305d35d3502.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uBwlgALnSV3ppd3U"/></div></div></figure><p id="5ad5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你看到的蓝线是向量“<em class="lv"> Umwelt </em>”(环境)在15个模型中的平均变化。浅蓝色的一个点表示来自一个模型的单个余弦距离值(余弦距离= 1-余弦相似性)。</p><p id="907d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">蓝线和灰线的对比很重要，灰线显示了“Umwelt”的频率。如你所见:如果灰线改变，蓝线也会改变，因为余弦相似度直接取决于频率。可用单词越多，相似度越低。</p><p id="232e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">有了这个背景你就明白了:没什么可看的。单词向量(蓝线)的变化是由于频率变化(灰线)。为了消除这种统计效应，你必须找到频率变化相同的单词，并绘制出它们之间的距离。</p><p id="cac9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下一次尝试以引用词结束，如下图所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/d469f6733dc7cc295753c9db053c390e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wW2hJ0Za3quvOnS4bOK8kA.png"/></div></div></figure><p id="a68c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">它看起来更好，因为有一个项，第10项，蓝色点位于浅蓝色点之上。这表明不管频率如何，词向量都有真实的变化。</p><p id="40fc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">蓝点代表向量“Umwelt”(这15个模型)的余弦距离。浅蓝色的点现在表示与在模型对中的最近术语中与我感兴趣的单词共享相同频率的可比单词的余弦距离。参考字从模型对变化到最佳地表示该时间点的频率。</p><p id="a26f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你注意到这个缺陷了吗？</p><p id="8d24" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当我比较和计算来自两个不同选举术语的模型对的相似性时，我还需要比较来自两个选举术语的参考词的频率变化。词向量在一段时间内的距离，并不是与另一段时间内的课程进行比较，而是一个特定的时间点。这就是缺陷。</p><p id="9dac" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我试图通过搜索那些与“Umwelt”有相同频率变化的单词来修复它。但是没有相同的频率变化，即使我让频率有小幅度的波动。语料库实在太小了。</p><p id="48ab" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">那么，让我们进入下一个迭代。而不是绝对变化，也许相对频率变化可以有所帮助？</p><p id="5a28" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">看上面的图表:当频率折线图改变时，余弦距离折线图也随之改变。</p><p id="0d0f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果选择相对频率变化相同但绝对频率更高的参考词，余弦相似性可能会更小，因为频率和余弦相似性之间存在反比关系。</p><p id="d9b1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，根据感兴趣的单词，你会仅仅因为基于频率差异的统计效应，而对单词向量的视觉变化进行推理。</p><p id="b5f6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个问题有一个理论上的解决方案:寻找绝对数变化相同但频率更高的词，然后回到最初的语料库。现在的关键是通过随机屏蔽对参考单词进行采样，直到频率与感兴趣的单词相同。然后计算新模型，将它们对齐，并查询图表的相似度。那是我停下来的地方。</p><p id="bbc6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当我们讨论这个未解决的任务时，张秀坤写道:“我还想说，自动意义变化检测领域还没有准备好为你的应用问题提供标准方法。两年后，情况可能会有所不同。”</p><h1 id="ba84" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">寻找故事:新闻的结果</h1><p id="9034" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">基于这项研究发表了三个故事。</p><ul class=""><li id="e051" class="nd ne it la b lb lc le lf lh nf ll ng lp nh lt ni nj nk nl bi translated">德国联邦议院如何搞糟气候变化:自20世纪80年代海尔马特·斯克米特总理时代起，联邦议院就一直在讨论气候灾难。但是一项数据研究表明:一代又一代的议员几乎不屑于对他们采取行动。</li><li id="f4cc" class="nd ne it la b lb nm le nn lh no ll np lp nq lt ni nj nk nl bi translated">匆忙的议会:所谓的难民危机是一个转折点，德国变了。一项数据研究显示:关于难民和移民的话语已经向右转移——同样是由AfD(德语中的<a class="ae lu" href="https://projekte.sueddeutsche.de/artikel/politik/artikel-e953507/" rel="noopener ugc nofollow" target="_blank"/>)提出的。</li><li id="05e6" class="nd ne it la b lb nm le nn lh no ll np lp nq lt ni nj nk nl bi translated">《在语言的引擎室》:一个关于方法论的大故事。目标群体是《南德意志报》的普通受众。其野心是解释机器学习的话题，而不是求助于一个“这是一个黑箱”(德语中的<a class="ae lu" href="https://projekte.sueddeutsche.de/artikel/politik/artikel-e893391/" rel="noopener ugc nofollow" target="_blank"/>)。</li></ul><h1 id="c4a8" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">交流不确定性:技术沙文主义的危险</h1><p id="1a9d" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">我对计算机如何捕捉自然语言很着迷。但是这种迷恋有技术沙文主义的危险。技术沙文主义是梅雷迪思·布鲁萨德提出的一个术语——“相信技术总是解决问题的方法”。</p><p id="ec85" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们如此热衷于给机器分配我们的大脑无法解决的任务。所以我们很容易忽略这样一个事实，结果也必须被质疑。我们陷入了计算机总是客观地产生完美的结果的想法。这就是为什么我认为沟通像这样的项目的不确定性是很重要的。如果我改变算法的超参数，数据中的其他关系可能会被更强烈地强调，潜在的文章可能会产生不同的结果。这就像就一个具体问题询问多位证人。我如何表达我的问题也会影响我得到的答案。</p><p id="7067" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lv">你有答案或意见吗？我感谢任何反馈。</em></p><p id="441d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lv">特别感谢卡塔琳娜·布鲁纳和卡门·海格的评论。</em></p><h1 id="c757" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">DIY:Github上的30个单词嵌入模型</h1><p id="c28a" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated"><a class="ae lu" href="https://github.com/sueddeutsche/political-german-word-embeddings" rel="noopener ugc nofollow" target="_blank">我在Github上发布了当前选举任期(2017–2019)的30个单词嵌入模型。随意使用它们并引用我</a>。</p><h1 id="4b6f" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">阅读更多:相关的科学工作</h1><p id="8a1a" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">[1]安东尼亚克，玛丽亚；米姆诺，大卫。基于嵌入的词语相似度的稳定性评估。《计算语言学协会汇刊》，第107–119页，2018年2月。</p><p id="36f8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[2]约翰内斯·赫尔里奇和乌多·哈恩。2016.坏公司——神经嵌入空间中的邻居被认为有害。《2016年计算语言学国际会议论文集》，2785-2796页，日本大阪。</p><p id="c582" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[3] Yoon Kim、Yi-I Chiu、健太郎·哈纳基、达尔山·黑德和斯拉夫·彼得罗夫。2014.通过神经语言模型对语言进行时间分析。ACL语言技术和计算社会科学研讨会论文集，第61-65页。</p><p id="59df" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[4]施莱希特韦格，张秀坤等，“变化之风:检测和评估跨时间和领域的词汇语义变化。”计算语言学协会第57届年会论文集(2019)</p><p id="e305" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[5] Haim Dubossarsky、Daphna Weinshall和Eitan Grossman。2017.失去控制:语义变化的规律和单词表征模型中的固有偏差。《2017年自然语言处理经验方法会议论文集》，1147-1156页，丹麦哥本哈根。</p></div></div>    
</body>
</html>