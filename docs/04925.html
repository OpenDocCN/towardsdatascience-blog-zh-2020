<html>
<head>
<title>Data Leakage in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中的数据泄漏</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data-leakage-in-machine-learning-6161c167e8ba?source=collection_archive---------24-----------------------#2020-04-29">https://towardsdatascience.com/data-leakage-in-machine-learning-6161c167e8ba?source=collection_archive---------24-----------------------#2020-04-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b939" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何检测和避免数据泄露</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ab0107d678062e1e5a21eecc87261d41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KkXXfcoqmUKw6RcyDl5OKA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@drew_beamer?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">德鲁·比默</a>在<a class="ae ky" href="https://unsplash.com/s/photos/future?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="0843" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当训练过程中使用的数据包含有关模型试图预测的信息时，就会发生数据泄漏。这听起来像是“欺骗”，但我们并没有意识到这一点，所以称之为“泄漏”更好。数据泄漏是数据挖掘和机器学习中一个严重而普遍的问题，需要很好地处理以获得一个健壮和通用的预测模型。</p><p id="44ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据泄露有不同的原因。有些非常明显，但有些乍一看就很难发现。在这篇文章中，我将解释数据泄漏的原因，它是如何误导的，以及检测和避免数据泄漏的方法。</p><p id="4f40" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可能知道它们，但我只想提一下我在这篇文章中经常用到的两个术语:</p><ul class=""><li id="84a8" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">目标变量:模型试图预测的内容</li><li id="4da5" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">特征:模型用来预测目标变量的数据</li></ul><h1 id="463a" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated"><strong class="ak">数据泄露的例子</strong></h1><p id="5012" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated"><strong class="lb iu">明显案例</strong></p><p id="29d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据泄露最明显的原因是将目标变量作为一个特征包括进来，这完全破坏了“预测”的目的。这很可能是错误的，但是要确保目标变量与特征是不同的。</p><p id="2b77" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据泄漏的另一个常见原因是在训练数据中包含测试数据。用新的、以前看不见的数据来测试模型是非常重要的。在训练过程中包括测试数据会破坏这个目的。</p><p id="0eb0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这两种情况不太可能发生，因为它们很容易被发现。更危险的原因是那些能够偷偷摸摸的原因。</p><p id="6b3e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">赠品功能</strong></p><p id="23c0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">赠品特征是暴露关于目标变量的信息的特征，并且在模型被部署之后将不可用。</p><ul class=""><li id="6bb3" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">示例:假设我们正在构建一个模型来预测某种医疗状况。指示患者是否进行了与该医疗状况相关的手术的特征会导致数据泄露，并且不应作为特征包含在训练数据中。手术指征高度预示了医疗状况，可能并不是在所有情况下都适用。如果我们已经知道一个病人做了与医疗条件相关的手术，我们甚至不需要一个预测模型来开始。</li><li id="7103" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">例如:考虑一个预测用户是否会停留在网站上的模型。包含暴露未来访问信息的功能将导致数据泄漏。我们应该只使用关于当前会话的特性，因为在部署模型之后，关于未来会话的信息通常是不可用的。</li></ul><p id="cf96" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">预处理过程中的泄漏</strong></p><p id="1eb7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有许多预处理步骤来探索或清理数据。</p><ul class=""><li id="a4a7" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">查找用于规格化或重新缩放的参数</li><li id="89db" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">要素的最小/最大值</li><li id="8be9" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">估计缺失值的特征变量的分布</li><li id="26ad" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">移除异常值</li></ul><p id="ce66" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些步骤应该只使用训练集来完成。如果我们使用整个数据集来执行这些操作，可能会发生数据泄漏。对整个数据集应用预处理技术将使模型不仅学习训练集，而且学习测试集。我们都知道测试集应该是新的，以前从未见过的数据。</p><p id="75ad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在处理时间序列数据时，我们应该更加注意数据泄漏。例如，如果我们在计算当前特征或预测时以某种方式使用来自未来的数据，很有可能以泄漏的模型结束。</p></div><div class="ab cl ng nh hx ni" role="separator"><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl"/></div><div class="im in io ip iq"><h1 id="1bd3" class="mj mk it bd ml mm nn mo mp mq no ms mt jz np ka mv kc nq kd mx kf nr kg mz na bi translated"><strong class="ak">如何检测和避免数据泄露</strong></h1><p id="1f1d" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">作为一个将军，如果模型好得不真实，我们就应该怀疑。该模型可能以某种方式记忆特征-目标关系，而不是学习和概括。</p><p id="a48d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在探索性数据分析过程中，我们可能会发现与目标变量高度相关的特征。当然，有些特性比其他特性更相关，但是惊人的高相关性需要仔细检查和处理。我们应该密切注意那些特征。</p><p id="1bc6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">模型训练好之后，如果有权重非常高的特征，就要密切关注。它们可能是泄漏的特征。</p><p id="bda6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了最小化或避免泄漏，如果可能的话，除了训练集和测试集之外，我们应该尽量留出一个验证集。验证集可以用作最后一步，模拟真实场景。</p><p id="549c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当处理时间序列数据时，时间上的截止值可能非常有用，因为它会阻止我们获得预测时间之后的任何信息。</p><p id="32eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在训练过程中经常使用交叉验证，尤其是在数据有限的情况下。交叉验证将数据分成 k 个折叠，并在整个数据集上迭代 k 次，每次使用 k-1 个折叠训练和 1 个折叠进行测试。交叉验证的优点是它允许使用整个数据集进行训练和测试。但是，如果您怀疑数据泄漏，最好对数据进行缩放/标准化，并分别计算每个折叠的参数。</p></div><div class="ab cl ng nh hx ni" role="separator"><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl"/></div><div class="im in io ip iq"><h1 id="ab8c" class="mj mk it bd ml mm nn mo mp mq no ms mt jz np ka mv kc nq kd mx kf nr kg mz na bi translated"><strong class="ak">结论</strong></h1><p id="f2ac" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">数据泄露是预测分析中的一个普遍问题。我们用已知数据训练模型，并期望模型对以前看不到的数据进行预测。一个模型要在这些预测中有良好的表现，它必须有良好的泛化能力。数据泄漏会阻止模型很好地泛化，从而导致对模型性能的错误假设。为了获得稳健的广义预测模型，我们应该密切注意检测和避免数据泄漏。</p></div><div class="ab cl ng nh hx ni" role="separator"><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl"/></div><div class="im in io ip iq"><p id="20be" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢您的阅读。如果您有任何反馈，请告诉我。</p></div></div>    
</body>
</html>