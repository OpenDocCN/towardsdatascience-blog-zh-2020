<html>
<head>
<title>Distributed Learning on Image Classification of Beans in TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TensorFlow中豆类图像分类的分布式学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/distributed-learning-on-image-classification-of-beans-in-tensorflow-5a85e6c3eb71?source=collection_archive---------32-----------------------#2020-05-07">https://towardsdatascience.com/distributed-learning-on-image-classification-of-beans-in-tensorflow-5a85e6c3eb71?source=collection_archive---------32-----------------------#2020-05-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="11d0" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用TensorFlow 2.0的内置函数执行分布式学习，并使用它来训练一个简单的图像分类模型。</h2></div><p id="3447" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">深度学习已经导致了机器学习领域的各种技术进步，但它仍然受到在大数据集上训练所需的大量计算时间的困扰。用于基准测试的ImageNet等训练数据集可能需要一个GPU系统长达一周的时间。另一方面，在多台机器或GPU之间划分训练的分布式训练已经被认为极大地减少了这种训练时间。</p><p id="bfaf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">TensorFlow提供了使用不同算法执行分布式学习的内置功能。今天，我们将了解“镜像策略”，并在<a class="ae lb" href="https://www.tensorflow.org/datasets/catalog/beans" rel="noopener ugc nofollow" target="_blank">“bean”</a>数据集上实施该策略。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h2 id="9b42" class="lj lk iq bd ll lm ln dn lo lp lq dp lr ko ls lt lu ks lv lw lx kw ly lz ma mb bi translated"><strong class="ak">导入依赖项并下载数据集</strong></h2><p id="5aee" class="pw-post-body-paragraph kf kg iq kh b ki mc jr kk kl md ju kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">首先，我们需要下载所需的库和我们将要处理的数据集。</p><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="df0d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">既然我们已经下载了数据集及其依赖项，我们就可以开始编写代码了。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h2 id="c975" class="lj lk iq bd ll lm ln dn lo lp lq dp lr ko ls lt lu ks lv lw lx kw ly lz ma mb bi translated">代码入门</h2><p id="ffd4" class="pw-post-body-paragraph kf kg iq kh b ki mc jr kk kl md ju kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">现在，在我们开始训练之前，需要一些必要的步骤。需要定义超参数，更重要的是，我们需要初始化分布式学习算法。</p><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="b038" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们通过从数据集中检索来初始化训练和测试图像的数量。我们还为我们的训练定义了一个缓冲区大小和批量大小，这将取决于GPU的数量。你拥有的GPU越多，你就可以保持更大的批量，这意味着更快的训练。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h2 id="e0e2" class="lj lk iq bd ll lm ln dn lo lp lq dp lr ko ls lt lu ks lv lw lx kw ly lz ma mb bi translated">创建模型和补充功能</h2><p id="2b84" class="pw-post-body-paragraph kf kg iq kh b ki mc jr kk kl md ju kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">我们将使用一个简单的CNN模型在这个数据集上进行训练，并演示分布式学习功能。我们的CNN也将需要一些功能，我们将在此过程中定义。</p><p id="7883" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，我们需要做一些轻微的数据预处理和归一化我们的图像的像素值。我们还对训练数据进行批处理，并在内存中保存训练数据的缓存，以提高性能。</p><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="1351" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们可以开始建设我们的CNN了。</p><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="8ecd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，我们需要定义一些补充功能，包括检查点、学习率衰减和回调。</p><p id="38d6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">检查点将在每个时期后保存模型的进度，随着时期数量的增加，学习率衰减将帮助我们获得动态学习率，并且模型在每个时期结束时使用回调来运行所有这些功能。</p><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="b646" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦模型构建完成，补充功能定义完成，我们就可以进入激动人心的部分，训练模型。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h2 id="525b" class="lj lk iq bd ll lm ln dn lo lp lq dp lr ko ls lt lu ks lv lw lx kw ly lz ma mb bi translated">训练模型</h2><p id="efa2" class="pw-post-body-paragraph kf kg iq kh b ki mc jr kk kl md ju kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">这是代码中最简单的部分，但也是代码运行中最重要的部分。我们现在可以在数据集上训练模型，这将通过分布式学习来实现！</p><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="mm mn l"/></div></figure></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h2 id="614b" class="lj lk iq bd ll lm ln dn lo lp lq dp lr ko ls lt lu ks lv lw lx kw ly lz ma mb bi translated">分布式学习策略</h2><p id="9297" class="pw-post-body-paragraph kf kg iq kh b ki mc jr kk kl md ju kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">有各种策略或算法可用于分布式学习。首先，让我们来看看我们在代码中使用的镜像策略。</p><p id="a2de" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mo">镜像策略</em> </strong>支持一台机器上多个GPU的同步训练。它会为每个GPU设备创建一个副本，并且模型中的每个变量都会跨所有副本进行镜像。通过应用相同和同时的更新，变量的所有副本彼此保持同步。</p><p id="9b9d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mo">多工人镜像策略</em> </strong>是镜像策略的一个版本，但用于多工人培训。这就是我们可以在多台机器而不仅仅是一台机器上使用分布式学习的地方。这种策略对多个工作者使用同步训练，每个工作者可以有多个GPU。它创建每个工人的每个设备的模型中的所有变量的副本。</p><p id="2c27" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="mo">参数服务器策略</em> </strong>是一种灵活的策略，因为它允许在多个GPU上进行同步本地训练，也允许跨多台机器进行异步训练。其本地训练与镜像策略的不同之处在于，它不是创建变量的副本并同时更新所有变量，而是将变量存储在CPU上，并在所有本地GPU上复制操作。</p><p id="0026" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以上所有策略只是分发算法的一些例子。它们都可以使用<em class="mo"> tf.distribute </em>库在TensorFlow中实现。</p><pre class="mh mi mj mk gt mp mq mr ms aw mt bi"><span id="e244" class="lj lk iq mq b gy mu mv l mw mx"># <em class="mo">To use Mirrored Strategy, we have used this in our code </em><br/>$ tf.distribute.MirroredStrategy()</span><span id="32c8" class="lj lk iq mq b gy my mv l mw mx"># <em class="mo">To use Multi Worker Mirrored Strategy</em><br/>$ tf.distribute.MultiWorkerMirroredStrategy()</span><span id="5559" class="lj lk iq mq b gy my mv l mw mx"># <em class="mo">To use Parameter Server Strategy</em><br/>$ tf.distribute.ParameterServerStrategy()</span></pre></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h2 id="bf9d" class="lj lk iq bd ll lm ln dn lo lp lq dp lr ko ls lt lu ks lv lw lx kw ly lz ma mb bi translated">但是一切都变好了吗？</h2><p id="4aa6" class="pw-post-body-paragraph kf kg iq kh b ki mc jr kk kl md ju kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">由于各种策略各不相同，各有利弊。</p><p id="6825" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们的目标是最大限度地利用GPU的能力，同时尽可能少地浪费数据获取的时间。在镜像策略中，当我们在具有多个GPU的单个本地系统上使用分布式学习时，我们看到GPU的使用远非完美。理想的情况是，平均来说，你的每个GPU都得到了同等的优化，但这并没有发生。但是，我们确实看到，随着检索指令所花费的时间减少，内存访问时间明显缩短，因为任务被划分到多个GPU上。最重要的是，随着数据集变得越来越大，我们可以预计分布式学习过程将更多地减少训练时间。为了进一步改善这一点，TensorFlow具有<em class="mo">预取</em>功能，可在当前时段进行的同时获取下一时段的数据。但是，该功能仍处于试验阶段，可能会有错误。</p><p id="0770" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">多工作器镜像策略允许您获得更高的性能，因为多个工作器拥有自己的GPU集，但同时，该策略容易出现系统错误。如果其中一名员工出现系统错误，由于培训过程需要在所有员工之间同步，TensorFlow会暂停培训过程，直到该员工重新上线。这确实导致训练时间的增加，并且训练过程越长，网络或系统故障的机会就越多，训练时间就越长。此外，检查点评估不能由任何工作线程完成，因为当一个工作线程正在评估检查点时，其他工作线程将不得不等待，这可能会导致通信超时。因此，检查点的评估由与所有工作人员通信的主系统完成，并且该过程完全由一台机器的能力决定。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="2a74" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">代码的完整笔记本可以在colab <a class="ae lb" href="https://colab.research.google.com/drive/1edcUMPcSjijdn-1RF_pOd2yodnexzPlu" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi mz"><img src="../Images/e9717d54612fab8d60abd46c87e9040a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IuTteG2yd-e4GiVZEOQ9XA.jpeg"/></div></div><p class="ng nh gj gh gi ni nj bd b be z dk translated">在<a class="ae lb" href="https://unsplash.com/s/photos/beans?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae lb" href="https://unsplash.com/@izgubljenausvemiru?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">蒂贾娜·德恩达尔斯基</a>拍摄的照片</p></figure></div></div>    
</body>
</html>