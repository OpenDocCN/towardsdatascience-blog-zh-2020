<html>
<head>
<title>Statistical Learning (V): Unsupervised Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">统计学习(五):无监督学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/statistical-learning-v-unsupervised-learning-f7adaf147b30?source=collection_archive---------67-----------------------#2020-05-12">https://towardsdatascience.com/statistical-learning-v-unsupervised-learning-f7adaf147b30?source=collection_archive---------67-----------------------#2020-05-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/75becbec9f4b089ffc3e442977f93f0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*-WjLe0Bb5Uu_UDttEUmnFg.jpeg"/></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">Web开发矢量图形在<a class="ae kb" href="http://getdrawings.com/get-vector#web-development-vector-24.jpg" rel="noopener ugc nofollow" target="_blank">GetDrawings.com</a></p></figure><p id="18e4" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">无监督学习是一项具有挑战性的任务，因为模型需要学习没有标签的数据模式，并且如果不将预测与来自观察的标签进行匹配，很难评估结果。例如，用户对商品推荐的购物体验是通过无监督学习来执行的。系统会根据搜索商品的历史和购物车中的商品列表向用户推荐感兴趣的商品。了解聚类分析方法后，您会更好地理解如何为数据集创建聚类标签。</p><p id="f04b" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">在本文中，您将了解到:</p><p id="454c" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">(1)主成分介绍</p><p id="c7b9" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">(2)聚类算法中的K-Means聚类和层次聚类</p><p id="777d" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">(Python中K-Means聚类在购物数据集上的应用</p><h2 id="452a" class="la lb it bd lc ld le dn lf lg lh dp li kn lj lk ll kr lm ln lo kv lp lq lr ls bi translated">主成分分析</h2><p id="b2ba" class="pw-post-body-paragraph kc kd it ke b kf lt kh ki kj lu kl km kn lv kp kq kr lw kt ku kv lx kx ky kz im bi translated">主成分分析是一种无监督学习方法，产生一组特征X1，X2，…，Xp，在n个观察值上测量，其被认为是来自数据集的代表性变量。PCA提供了一种工具来生成数据的表示，该表示捕获低维空间中的大部分信息。</p><h2 id="e984" class="la lb it bd lc ld le dn lf lg lh dp li kn lj lk ll kr lm ln lo kv lp lq lr ls bi translated">主成分</h2><p id="f5ef" class="pw-post-body-paragraph kc kd it ke b kf lt kh ki kj lu kl km kn lv kp kq kr lw kt ku kv lx kx ky kz im bi translated">它是p个特征X_1，X_2，…的一组归一化线性组合。，X _ p .<br/>φ_ 11，φ_21，…，φ_p1的载荷向量构成一条线，使每个观测值X_1，X_2，…之间的距离平方和最小..，X_p到数据。为了约束加载向量，我们对φ值的平方和进行归一化，φ值等于1。根据等式1，Z_i1被称为主成分得分。</p><figure class="lz ma mb mc gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi ly"><img src="../Images/93d1398d06c51cdfe3d5cfaf096d38f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nbPMA1rC9VfbDbzyyASx1Q.png"/></div></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">主成分的数学公式</p></figure><p id="0cee" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">从下面的图中，左边的图(图A)显示了第一个主成分。绿线由第一主成分负载向量构成，蓝点是两个特征的平均值。右图显示了旋转后的绿线，第一主成分作为x轴，第二主成分作为y轴。左下角的紫色圆点具有最大的负值，表明主成分得分z_i低于两个特征的平均值，右上角的z_j具有最大的正值，表明高于平均值的特征的z_i得分为正值。</p><figure class="lz ma mb mc gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mh"><img src="../Images/e630ab470c07b5475a7f0c134bf3d232.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9xd1HFgCBSVR8Jz3yFoEig.jpeg"/></div></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">图1:带PCA的示例数据集</p></figure><p id="696b" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">PCA在缩放数据集上执行得更好。当对未缩放的数据执行PCA时，主成分加载向量将对具有较高方差的变量产生较大的值。</p><h2 id="9be8" class="la lb it bd lc ld le dn lf lg lh dp li kn lj lk ll kr lm ln lo kv lp lq lr ls bi translated">PCA的例子</h2><p id="56a2" class="pw-post-body-paragraph kc kd it ke b kf lt kh ki kj lu kl km kn lv kp kq kr lw kt ku kv lx kx ky kz im bi translated">下面的剧情展示了美国的15个州以及<strong class="ke iu">城市警察</strong>、<strong class="ke iu">袭击</strong>、<strong class="ke iu">谋杀</strong>、<strong class="ke iu">强奸</strong>的特点。就第一个组成部分而言，它在犯罪特征的负荷向量上显示出相似的权重，而在城市人口上显示出较小的权重。另一方面，相对于其他特征，城市人口特征更为重要。一般来说，犯罪特征被放置在彼此附近，这驱动了高相关性。因此，较高的强奸率导致较高的攻击或谋杀率。相比之下，城市人口变量与犯罪特征的相关性较小。进一步分析，加州、内华达州和佛罗里达州的犯罪率较高，但北达科他州等州的犯罪率较低。往第二主成分的垂直线看，加州也有很高的UrbanPop值。对于像弗吉尼亚州这样的中间点，它显示了犯罪和城市化的大致平均水平。</p><figure class="lz ma mb mc gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mh"><img src="../Images/244ce82b30c4eb1e10fe4695daf22bec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J7qHXlyqyIDdCL-pqdjm_w.jpeg"/></div></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">图2:使用PCA的犯罪数据集示例</p></figure><h1 id="f63c" class="mi lb it bd lc mj mk ml lf mm mn mo li mp mq mr ll ms mt mu lo mv mw mx lr my bi translated">使聚集</h1><h2 id="05b6" class="la lb it bd lc ld le dn lf lg lh dp li kn lj lk ll kr lm ln lo kv lp lq lr ls bi translated">k均值聚类</h2><p id="ded2" class="pw-post-body-paragraph kc kd it ke b kf lt kh ki kj lu kl km kn lv kp kq kr lw kt ku kv lx kx ky kz im bi translated">K-Means聚类算法是通过最小化类内变异来确定的。组内方差用W(C_k)来计算，W(C _ k)是一个组内观测值之间差异的总和。</p><p id="20b5" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">根据等式3，它计算一个聚类中观测值的聚类内变化的总和，并对K个聚类中的值求和。根据等式4，W(C_k)由第k个聚类中的观测值之间的平方欧几里德距离除以第k个聚类中的观测值总数来定义。等式5是等式3和等式5的组合。</p><figure class="lz ma mb mc gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mz"><img src="../Images/894fa784b6b77fad6b7992cae66cd547.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iVEMdISr31UOnAqbpglnJg.png"/></div></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">K-均值聚类的数学公式</p></figure><p id="04bc" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">每个观察值被分配给K个聚类中的一个，因此聚类之间不应有重叠的数据点。然而，为了减少W(C_k)的K^n计算时间，通过在每个聚类内提供局部最小值来优化算法。</p><p id="8941" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">从下图可以看出，该算法是通过以下过程实现的。</p><ul class=""><li id="3dc6" class="na nb it ke b kf kg kj kk kn nc kr nd kv ne kz nf ng nh ni bi translated">将每个观察值随机分配给每个集群。</li><li id="49a8" class="na nb it ke b kf nj kj nk kn nl kr nm kv nn kz nf ng nh ni bi translated">步骤2a:计算聚类质心</li><li id="9571" class="na nb it ke b kf nj kj nk kn nl kr nm kv nn kz nf ng nh ni bi translated">步骤2b:将数据点分组到附近的聚类质心</li><li id="893c" class="na nb it ke b kf nj kj nk kn nl kr nm kv nn kz nf ng nh ni bi translated">在步骤2a中的第二次迭代之后:重新计算聚类质心</li><li id="de07" class="na nb it ke b kf nj kj nk kn nl kr nm kv nn kz nf ng nh ni bi translated">当每个聚类内的观察距离最小化时，迭代不会停止，直到聚类质心分配完成。</li></ul><figure class="lz ma mb mc gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mh"><img src="../Images/f3925fb6a5388d60d52c499665181264.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e-k8LqTIG4FYaIFZDKJD5w.jpeg"/></div></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">图3: K均值聚类算法迭代</p></figure><h2 id="66de" class="la lb it bd lc ld le dn lf lg lh dp li kn lj lk ll kr lm ln lo kv lp lq lr ls bi translated">分层聚类</h2><p id="8573" class="pw-post-body-paragraph kc kd it ke b kf lt kh ki kj lu kl km kn lv kp kq kr lw kt ku kv lx kx ky kz im bi translated">执行层次聚类就是绘制树状图的过程。它可以在水平方向上观察，因为在同一层中的分支的接近底部的观察结果更相似，而在融合了更多分支的树的较高层的观察结果则非常不同。创建了(n-1)个聚类，其中对于1个分支可以融合最少的2个点，并对系统树图进行2^(n-1重排，同时可以交换2个融合分支的位置。</p><p id="3dba" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">该算法由相异度度量进行，相异度度量可以通过连接概念——平均、完全、单一和质心来实现。</p><ul class=""><li id="08b8" class="na nb it ke b kf kg kj kk kn nc kr nd kv ne kz nf ng nh ni bi translated"><strong class="ke iu">完全连锁:</strong>从每个聚类的所有成对观察值中取出最大相异值</li><li id="3aeb" class="na nb it ke b kf nj kj nk kn nl kr nm kv nn kz nf ng nh ni bi translated"><strong class="ke iu">单个连锁:</strong>从每个聚类的所有两两观察值中取最小相异值</li><li id="48da" class="na nb it ke b kf nj kj nk kn nl kr nm kv nn kz nf ng nh ni bi translated"><strong class="ke iu">平均连锁:</strong>取每个聚类中所有两两观察值的平均相异值。</li><li id="4d7f" class="na nb it ke b kf nj kj nk kn nl kr nm kv nn kz nf ng nh ni bi translated"><strong class="ke iu">质心链接:</strong>计算聚类质心内的相异值。</li></ul><h2 id="4da8" class="la lb it bd lc ld le dn lf lg lh dp li kn lj lk ll kr lm ln lo kv lp lq lr ls bi translated">算法</h2><ul class=""><li id="e72a" class="na nb it ke b kf lt kj lu kn no kr np kv nq kz nf ng nh ni bi translated">从n个观察值中取2个成对观察值，并计算差异。每一对被视为一个集群。</li><li id="40e0" class="na nb it ke b kf nj kj nk kn nl kr nm kv nn kz nf ng nh ni bi translated">迭代从规模为n，n-1，…，2的群体开始</li><li id="db2f" class="na nb it ke b kf nj kj nk kn nl kr nm kv nn kz nf ng nh ni bi translated">融合最相似的两个聚类，这是由聚类间的不相似性决定的。树状图的高度代表聚类的相异程度。一个聚类的融合度越低，这个聚类就越相似。</li><li id="902b" class="na nb it ke b kf nj kj nk kn nl kr nm kv nn kz nf ng nh ni bi translated">然后，取i-1个剩余聚类并计算聚类间的相异度。当人口数量减少到2时，迭代将停止。</li></ul><h2 id="fd51" class="la lb it bd lc ld le dn lf lg lh dp li kn lj lk ll kr lm ln lo kv lp lq lr ls bi translated">如何确定层次聚类使用什么类型的相异度？</h2><p id="2ee8" class="pw-post-body-paragraph kc kd it ke b kf lt kh ki kj lu kl km kn lv kp kq kr lw kt ku kv lx kx ky kz im bi translated">以网上购物为例，零售商根据顾客过去的购物经历对他们进行聚类，以识别相似顾客的子群。数据被转换成一个矩阵，其中一行是客户id，多列是给定购物者购买给定商品的次数。有两种适用的相异度度量。</p><blockquote class="nr ns nt"><p id="eb4e" class="kc kd nu ke b kf kg kh ki kj kk kl km nv ko kp kq nw ks kt ku nx kw kx ky kz im bi translated"><strong class="ke iu">欧几里德距离:</strong>购物者将根据购物体验的频率被分组。也就是说，不频繁的客户更有可能被放入一个集群中。<br/> <strong class="ke iu">基于相关性的距离:</strong>对所购商品有相似偏好的购物者(购买电子产品等商品的顾客被聚集在一起)，即使购买者购买的商品量更大。基于相关性的度量被确定为按项目的类别对客户进行聚类。</p></blockquote><p id="0c96" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">您可以通过提供的<a class="ae kb" rel="noopener" target="_blank" href="/introduction-hierarchical-clustering-d3066c6b560e">链接</a>找到更详细的层次聚类信息。</p><h2 id="1412" class="la lb it bd lc ld le dn lf lg lh dp li kn lj lk ll kr lm ln lo kv lp lq lr ls bi translated">计算相异度时是否缩放特征？</h2><blockquote class="nr ns nt"><p id="347c" class="kc kd nu ke b kf kg kh ki kj kk kl km nv ko kp kq nw ks kt ku nx kw kx ky kz im bi translated">当商品A比商品B更频繁地被购买时，通过欧几里德距离计算的相异度对商品A产生更大的影响，而商品B几乎没有影响。然而，物品B更可能是具有高价值的物品，并且零售商渴望鼓励顾客购买。此外，频繁购买的商品A的购买数量差异较大，与商品b相比，这提供了较少的关于购物者整体购物体验的信息</p></blockquote><h1 id="b055" class="mi lb it bd lc mj mk ml lf mm mn mo li mp mq mr ll ms mt mu lo mv mw mx lr my bi translated">Python中的K-Means聚类</h1><p id="c389" class="pw-post-body-paragraph kc kd it ke b kf lt kh ki kj lu kl km kn lv kp kq kr lw kt ku kv lx kx ky kz im bi translated">我们将使用python Sklearn包对示例数据集进行K-Means聚类。该数据集包括超市购物中心的顾客购物历史的200个购买条目。这用于客户细分。Kaggle网站链接:<a class="ae kb" href="https://www.kaggle.com/vjchoudhary7/customer-segmentation-tutorial-in-python" rel="noopener ugc nofollow" target="_blank">市场篮子分析</a>。K-Means可以很好地将观察结果聚类到特定的组中，因此这将是我们主要的无监督聚类工具。</p><p id="c076" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">对示例数据集应用聚类的目标是:</p><ul class=""><li id="e48c" class="na nb it ke b kf kg kj kk kn nc kr nd kv ne kz nf ng nh ni bi translated">如何用Python中的机器学习算法(KMeans聚类)以最简单的方式实现客户细分？</li><li id="f653" class="na nb it ke b kf nj kj nk kn nl kr nm kv nn kz nf ng nh ni bi translated">谁是你的目标客户，你可以从谁开始营销策略</li><li id="db00" class="na nb it ke b kf nj kj nk kn nl kr nm kv nn kz nf ng nh ni bi translated">营销策略在现实世界中是如何运作的</li></ul><h2 id="d7e3" class="la lb it bd lc ld le dn lf lg lh dp li kn lj lk ll kr lm ln lo kv lp lq lr ls bi translated">数据集描述:</h2><ul class=""><li id="cec0" class="na nb it ke b kf lt kj lu kn no kr np kv nq kz nf ng nh ni bi translated">CustomerID，性别:分类特征</li><li id="d11c" class="na nb it ke b kf nj kj nk kn nl kr nm kv nn kz nf ng nh ni bi translated">年龄、年收入(千美元)、支出分数(1-100):数字特征</li></ul><h2 id="7ad4" class="la lb it bd lc ld le dn lf lg lh dp li kn lj lk ll kr lm ln lo kv lp lq lr ls bi translated">特征工程:</h2><p id="047a" class="pw-post-body-paragraph kc kd it ke b kf lt kh ki kj lu kl km kn lv kp kq kr lw kt ku kv lx kx ky kz im bi translated">我创建了一个手动功能，将包含“<strong class="ke iu"/>”、“<strong class="ke iu">【k $】</strong>年收入”变量的组进行聚类。</p><figure class="lz ma mb mc gt ju"><div class="bz fp l di"><div class="ny nz l"/></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">K均值聚类迭代的代码段</p></figure><p id="a7f3" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">通过上面的代码，创建了集群数量的图表。使用肘方法，我们可以看到4是更好的集群数选择。</p><figure class="lz ma mb mc gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi oa"><img src="../Images/3378d303fc7d010cd40e86f19c5ed623.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oTpfBZKfkPRt4RL91Hrz3A.png"/></div></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">聚类数图</p></figure><p id="dd0d" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">确定了聚类数后，我将KMeans模型拟合到具有4个聚类的数据集中。</p><p id="4442" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">k-均值属性:</p><blockquote class="nr ns nt"><p id="ebfa" class="kc kd nu ke b kf kg kh ki kj kk kl km nv ko kp kq nw ks kt ku nx kw kx ky kz im bi translated"><strong class="ke iu">聚类中心_: </strong>聚类中心的坐标。聚类中相异度最小的最优点。<strong class="ke iu"> <br/>标签_: </strong>每个点的聚类标签</p></blockquote><figure class="lz ma mb mc gt ju"><div class="bz fp l di"><div class="ny nz l"/></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">K均值聚类的代码段</p></figure><p id="c522" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">下图将每个数据点显示为散点图，红点显示为聚类质心。</p><figure class="lz ma mb mc gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi ob"><img src="../Images/4188b16d9a4821933cb5900e1b1b6b8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gAwtA2EvHvD24ovcIt1edg.png"/></div></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">K-均值聚类图</p></figure><p id="e585" class="pw-post-body-paragraph kc kd it ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz im bi translated">从为数据集生成的分类中，我将分类标签指定为一个特征，并将数字特征转换为模型的分类特征。该模型用于根据年龄、年收入和分类的特征来预测每个客户的支出成本水平。</p><figure class="lz ma mb mc gt ju"><div class="bz fp l di"><div class="ny nz l"/></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">随机森林分类器的代码片段</p></figure><h2 id="3938" class="la lb it bd lc ld le dn lf lg lh dp li kn lj lk ll kr lm ln lo kv lp lq lr ls bi translated">最后</h2><ul class=""><li id="5cbb" class="na nb it ke b kf lt kj lu kn no kr np kv nq kz nf ng nh ni bi translated">PCA显示了观察值的低维表示，其解释了方差的良好分数。每个主成分关注不同的特征组。建议对缩放后的数据执行PCA。</li><li id="8f20" class="na nb it ke b kf nj kj nk kn nl kr nm kv nn kz nf ng nh ni bi translated">聚类显示了观察值中的同类子群。对于K-Means聚类，它根据每个聚类中每个观察值的最小欧氏距离来生成每个聚类中的聚类质心。层次聚类基于相异度将两个观察值融合成一个聚类，并且显示了每个聚类的相似性水平的树状图。</li></ul><h1 id="8f8c" class="mi lb it bd lc mj mk ml lf mm mn mo li mp mq mr ll ms mt mu lo mv mw mx lr my bi translated">参考:</h1><p id="9967" class="pw-post-body-paragraph kc kd it ke b kf lt kh ki kj lu kl km kn lv kp kq kr lw kt ku kv lx kx ky kz im bi translated">[1]:加雷斯·詹姆斯、丹妮拉·威滕、特雷弗·哈斯蒂和罗伯特·蒂布拉尼。统计学习导论。第七版。斯普林格。</p><h1 id="cc9d" class="mi lb it bd lc mj mk ml lf mm mn mo li mp mq mr ll ms mt mu lo mv mw mx lr my bi translated">请继续关注更多关于机器学习概念的初学者友好文章！统计学习系列到此结束。☺️</h1></div></div>    
</body>
</html>