<html>
<head>
<title>Why you shouldn't be using LabelEncoder for categorical features</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么不应该将 LabelEncoder 用于分类特征</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-common-mistake-to-avoid-when-encoding-ordinal-features-79e402796ab4?source=collection_archive---------21-----------------------#2020-04-19">https://towardsdatascience.com/a-common-mistake-to-avoid-when-encoding-ordinal-features-79e402796ab4?source=collection_archive---------21-----------------------#2020-04-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="be68" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何处理分类特征和避免一个常见的陷阱</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/080c2f29328e49e0b7c7fd676a25168f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jFuKLAd31yFxuTZm3RqcOA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://canalhistoria.es/wp-content/uploads/2020/03/Enigma_Portada.jpg" rel="noopener ugc nofollow" target="_blank">英格玛机</a></p></figure><p id="b5e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在处理分类特征时，选择一种合适的方式对它们进行编码可能并不那么简单。这是一个需要考虑的非常重要的方面，它将决定一个特性将为模型增加的价值。</p><p id="0beb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这同样适用于顺序特征，这是一种非常常见的分类数据类型，其中不同的类别呈现出一种<em class="lv">自然顺序。</em>一个例子可以是<em class="lv"> </em>是<em class="lv">温度</em>特征，取类别<em class="lv">冷</em>、<em class="lv">温和</em>和<em class="lv">热。</em></p><p id="60b0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一个相当常见的错误是，只给特性的每个类别分配一个唯一的数值，而不考虑它可能具有的任何顺序。并且类似地具有标称特征；不同之处在于它们并不自然地呈现任何顺序。</p><p id="fa58" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇文章的想法是探索和理解为什么这不是一个好主意，用一个带有顺序特征的例子来更好地说明这一点，以及我们应该用什么方法来代替。</p><p id="424d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">找到所有的代码连同解释</strong> <a class="ae ky" href="https://github.com/AlexanderNixon/Machine-learning-reads/blob/master/How-to-encode-ordinal-features.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">也作为一个 jupyter 笔记本</strong> </a> <strong class="lb iu">。</strong></p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="b0b9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将特征的固有顺序映射到错误的比例会对模型的性能产生非常负面的影响(即与特征的相关性成比例)。</p><p id="30f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如前所述，序数特征有一个<em class="lv">自然排序，</em>或者换句话说，它们有一个带有<strong class="lb iu">等级的序数尺度</strong>。因此，如果我们想在编码后保留特性的值，我们想确保它类似于它们的排名。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi md"><img src="../Images/b2de75e6aeb8b5cdc3f79a0be835e7d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8QISTMyQ2VkeagBDZvVqWA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://www.pexels.com/@veeterzy?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> veeterzy </a>从<a class="ae ky" href="https://www.pexels.com/photo/nature-forest-trees-park-38136/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">像素</a>拍摄</p></figure><h2 id="b2cb" class="me mf it bd mg mh mi dn mj mk ml dp mm li mn mo mp lm mq mr ms lq mt mu mv mw bi translated">用决策树可视化</h2><p id="621c" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">一种直观的思考方式是决策树设置阈值的方式。在训练过程中，决策树将学习在每个节点设置的最佳特征，以及确定未知样本通过每个节点的路径的最佳阈值。</p><p id="e92f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们用一个简单的<code class="fe nc nd ne nf b">LabelEncoder</code>对一个序数特征进行编码，这可能会导致这样一个特征，比如说<code class="fe nc nd ne nf b">1</code>代表<em class="lv">热</em>，<code class="fe nc nd ne nf b">2</code>可能会翻译成<em class="lv">热</em>，而<code class="fe nc nd ne nf b">0</code>代表<em class="lv">沸腾</em>。在这种情况下，结果将是一个具有不必要的大量分裂的树，因此对于本应更简单的建模来说，复杂性要高得多。</p><p id="c4a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然实际上<em class="lv">看到</em>为什么这是一个坏主意会比仅仅是文字更直观。让我们用一个简单的例子来说明上面的内容，这个例子由两个序数特征组成，这两个特征包含一个学生准备考试所花费的小时数和所有以前作业的平均分数的范围，以及一个指示考试是否通过的目标变量。我已经将数据框的列定义为<code class="fe nc nd ne nf b"><a class="ae ky" href="https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html" rel="noopener ugc nofollow" target="_blank">pd.Categorical</a></code>:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="be26" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将分类列定义为熊猫分类的好处是，我们可以在它的分类中建立一个<em class="lv">顺序</em>。这使得基于既定顺序的排序比基于词汇排序快得多。它也可以作为一种简单的方法，根据不同类别的顺序得到不同类别的<em class="lv">代码</em>。</p><p id="6ad3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">也就是说，对于使用<code class="fe nc nd ne nf b">fit</code> / <code class="fe nc nd ne nf b">transform</code>方法的更一般的方法，我们应该看看其他工具，我将在下一节中介绍。</p><p id="72e7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，我们将使用的数据帧如下所示:</p><pre class="kj kk kl km gt ni nf nj nk aw nl bi"><span id="acbc" class="me mf it nf b gy nm nn l no np">   Hours_of_dedication   Assignments_avg_grade  Result<br/>0                20-25                       B    Pass<br/>1                20-25                       C    Pass<br/>2                 5-10                       F    Fail<br/>3                 5-10                       C    Fail<br/>4                40-45                       B    Pass<br/>5                  0-5                       D    Fail<br/>6                15-20                       C    Fail<br/>7                20-25                       A    Pass<br/>8                30-35                       B    Pass<br/>9                 5-10                       B    Fail<br/>10               10-15                       D    Fail<br/>...</span></pre><p id="38df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如上所述，我们可以使用<code class="fe nc nd ne nf b"><a class="ae ky" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.cat.codes.html" rel="noopener ugc nofollow" target="_blank">pd.Series.cat.codes</a></code>方法，根据<code class="fe nc nd ne nf b">categories</code>参数中的顺序，获得分配给每个类别的代码:</p><pre class="kj kk kl km gt ni nf nj nk aw nl bi"><span id="a898" class="me mf it nf b gy nm nn l no np">X = df.apply(lambda x: x.cat.codes)<br/>print(X)</span><span id="e77f" class="me mf it nf b gy nq nn l no np">    Hours_of_dedication  Assignments_avg_grade  Result<br/>0                     4                      3       1<br/>1                     4                      2       1<br/>2                     1                      0       0<br/>3                     1                      2       0<br/>4                     7                      3       1<br/>5                     0                      1       0<br/>6                     3                      2       0<br/>7                     4                      4       1<br/>8                     6                      3       1<br/>9                     1                      3       0<br/>10                    2                      1       0<br/>...</span></pre><p id="d2c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们安装一个<code class="fe nc nd ne nf b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html" rel="noopener ugc nofollow" target="_blank">DecisionTreeClassifier</a></code>，看看树是如何定义分割的:</p><pre class="kj kk kl km gt ni nf nj nk aw nl bi"><span id="e78d" class="me mf it nf b gy nm nn l no np">from sklearn import tree<br/>dt = tree.DecisionTreeClassifier()<br/>y = X.pop('Result')<br/>dt.fit(X, y)</span></pre><p id="0129" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nc nd ne nf b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html#sklearn.tree.plot_tree" rel="noopener ugc nofollow" target="_blank">sklearn.tree</a></code>模块提供了绘制拟合决策树的功能。让我们用它来看看决策树是什么样子的:</p><pre class="kj kk kl km gt ni nf nj nk aw nl bi"><span id="37c7" class="me mf it nf b gy nm nn l no np">g = tree.plot_tree(dt, <br/>                   feature_names = X.columns,<br/>                   class_names=['Failed', 'Pass'],<br/>                   filled = True,<br/>                   label='all',<br/>                   rounded=True)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/97c5bc126b10827338e689848646e973.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*KFxfvtSoZn5_ejOa0BOGqw.png"/></div></figure><p id="b682" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就这些吗？？嗯… <strong class="lb iu">是的</strong>！我实际上以这样一种方式设置了特征，即在<code class="fe nc nd ne nf b">Hours of dedication</code>特征和考试是否通过之间存在这种简单而明显的关系，这表明问题应该<em class="lv">非常</em>容易建模。</p><p id="148d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们试着做同样的事情，用一个我们可以通过<code class="fe nc nd ne nf b">LabelEncoder</code>获得的编码方案直接编码所有的特征，所以不考虑特征的实际普通性，只是随机分配一个值:</p><pre class="kj kk kl km gt ni nf nj nk aw nl bi"><span id="0ce6" class="me mf it nf b gy nm nn l no np">from sklearn.preprocessing import LabelEncoder</span><span id="eda2" class="me mf it nf b gy nq nn l no np">X_wrong = df.apply(LabelEncoder().fit_transform)<br/>dt_wrong = tree.DecisionTreeClassifier()<br/>dt_wrong.fit(X_wrong, y)</span><span id="b45f" class="me mf it nf b gy nq nn l no np">g = tree.plot_tree(dt_wrong, <br/>                   feature_names = X_wrong.columns,<br/>                   class_names=['Fail', 'Pass'],<br/>                   filled = True,<br/>                   label='all',<br/>                   rounded=True)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/7049f47b93d43100eda49e103dc01ecb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1wxr-y1EO0AmI1wSMjPumQ.png"/></div></div></figure><p id="48ea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如所料，对于我们试图建模的简单问题来说，树结构比必要的要复杂得多。为了让树正确地预测所有的训练样本，它已经扩展到深度为<code class="fe nc nd ne nf b">4</code>，这时单个节点就足够了。</p><p id="742b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这意味着分类器可能会过拟合，因为我们大大增加了复杂性。通过修剪树和调整必要的参数来防止过度拟合，我们也没有解决问题，因为我们通过错误地编码特征添加了太多的<em class="lv">噪声</em>。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h2 id="00da" class="me mf it bd mg mh mi dn mj mk ml dp mm li mn mo mp lm mq mr ms lq mt mu mv mw bi translated">序数特征应该如何编码？</h2><p id="c476" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">在上面的例子中，我们已经看到了一种使用<code class="fe nc nd ne nf b">pd.Categorical</code>对序数特征进行编码的简单方法。但是大多数时候，我们感兴趣的不仅仅是转换一组给定的特性，还包括在<em class="lv">看不见的</em>数据上<em class="lv">复制</em>应用的转换。</p><p id="c0ae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为此，我们有来自<a class="ae ky" href="https://contrib.scikit-learn.org/categorical-encoding/#" rel="noopener ugc nofollow" target="_blank">类别编码器</a>的<code class="fe nc nd ne nf b"><a class="ae ky" href="https://contrib.scikit-learn.org/categorical-encoding/" rel="noopener ugc nofollow" target="_blank">OrdinalEncoder</a></code>。本课程使我们能够:</p><ul class=""><li id="a6f9" class="nt nu it lb b lc ld lf lg li nv lm nw lq nx lu ny nz oa ob bi translated">定义将类别映射到代码的字典</li><li id="a223" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated"><strong class="lb iu">用映射字典安装</strong>编码器，用<strong class="lb iu">转换</strong>看不见的数据</li></ul><p id="a752" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们通过一个例子来看看如何使用它，这个例子包含几个特性:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="8270" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nc nd ne nf b">OrdinalEncoder</code>接收一个映射参数，期望一个字典列表，每个字典包含键<code class="fe nc nd ne nf b">col</code>和<code class="fe nc nd ne nf b">mapping</code>:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="e525" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们可以使用以下内容创建编码器的新实例:</p><pre class="kj kk kl km gt ni nf nj nk aw nl bi"><span id="ab58" class="me mf it nf b gy nm nn l no np">import category_encoders as ce<br/>encoder = ce.OrdinalEncoder(mapping = ordinal_cols_mapping, <br/>                             return_df = True)</span></pre><p id="99a3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，通过在与上述相同的数据框架上进行转换，我们得到:</p><pre class="kj kk kl km gt ni nf nj nk aw nl bi"><span id="e5c5" class="me mf it nf b gy nm nn l no np">df_train = encoder.fit_transform(df)<br/>print(df_train)</span><span id="70b9" class="me mf it nf b gy nq nn l no np">    Outlook  Temperature  Humidity  Windy  PlayTennis<br/>0         2            2         1      0           0<br/>1         2            2         1      1           0<br/>2         1            2         1      0           1<br/>3         0            1         1      0           1<br/>4         0            0         0      0           1<br/>5         0            0         0      1           0<br/>6         1            0         0      1           1<br/>7         2            1         1      0           0<br/>8         2            0         0      0           1<br/>9         0            1         0      0           1<br/>10        2            1         0      1           1<br/>11        1            1         1      1           1<br/>12        1            2         0      0           1<br/>13        0            1         1      1           0</span></pre></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="5f66" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，总而言之，一旦对特征进行编码，保持它们的平凡性是至关重要的，否则正如这个例子所表明的那样，我们将失去它们所有的可预测能力，而只是将<em class="lv">噪声</em>添加到我们的模型中。</p><p id="f71f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">找到所有的代码和解释<a class="ae ky" href="https://github.com/AlexanderNixon/towards-ds-posts/blob/master/Encoding_ordinal_features.ipynb" rel="noopener ugc nofollow" target="_blank">，也可以作为一个笔记本</a>。希望你喜欢并发现这很有帮助！</p></div></div>    
</body>
</html>