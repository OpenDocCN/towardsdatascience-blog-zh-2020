<html>
<head>
<title>Linear Regression in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python 中的线性回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/linear-regression-in-python-a1d8c13f3242?source=collection_archive---------28-----------------------#2020-04-12">https://towardsdatascience.com/linear-regression-in-python-a1d8c13f3242?source=collection_archive---------28-----------------------#2020-04-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="bc88" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">线性回归简介</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f2a02717a81ec05b5127fc1f37021e14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cU5gM9Fh9g6yUIr_MXHdMg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://www.pexels.com/photo/green-iphone-5c-near-macbook-163143/" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="ea0b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">线性回归是一种统计方法，用于模拟响应变量和解释变量之间的线性关系。回归函数描述了给定解释变量时响应变量的期望值，并由线性函数建模。</p><p id="2e08" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本帖中，我们将回顾线性回归背后的理论，以及如何使用 python 中的机器学习库 scikit-learn 实现线性回归模型。</p><p id="7d12" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们开始吧！</p><p id="e5f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">给定一个<em class="lv"> p </em>维输入向量:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/0a1a0f6e1d60816b3600db96b49d450d.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*y-JKOkPHXCNKGeqkgkm9bA@2x.png"/></div></figure><p id="865a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们想预测一个实值响应<em class="lv"> Y </em>。给定输入向量<em class="lv"> X </em>，允许我们预测<em class="lv"> Y </em>的线性回归模型具有以下形式:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/dc4937909a0d858f44ee9d0a07f28034.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*AV2hDdah7HeTuEHWMN-I0g@2x.png"/></div></figure><p id="a50e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该模型描述了输入特征的加权和。它假设在给定<em class="lv"> X </em>的情况下，代表<em class="lv"> Y </em>的期望的回归函数是线性的或近似线性的。参数β是未知系数，输入向量<em class="lv"> X </em>可以来自定量输入、变换输入、基展开、交互项和/或代表类别的虚拟变量。给定一组训练数据，我们估计β参数的值:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/f94a010f669bed07de710ca3837a958b.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*qKsaX5UBE23RefAtbHR34Q@2x.png"/></div></figure><p id="aaef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，每个<em class="lv"> x </em>为输入向量(特征值列表)，每个<em class="lv"> y </em>为响应，<em class="lv"> N </em>为训练样本数。</p><p id="66f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们回头看看回归模型:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/dc4937909a0d858f44ee9d0a07f28034.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*AV2hDdah7HeTuEHWMN-I0g@2x.png"/></div></figure><p id="db88" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们看到，估计量<em class="lv"> f </em>是一个常数加上具有相应 beta 值(或权重)的输入的线性组合。在求和中，<em class="lv"> p </em>是输入值或特征的数量。我们需要的是一种估计<em class="lv">p+</em>1<em class="lv"/>β参数的方法:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/11af63d6e1c849d58244e11b53572789.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*aReC0V6a_x1zpO-6734Ucg@2x.png"/></div></figure><p id="cd9e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">估计β参数最常用的方法是最小二乘法。该方法选择使残差平方和(RSS)最小的β参数值:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ma"><img src="../Images/f8eca8f695b084df4992cd433233ff33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WBPRwZpziwnxPelsP-82gA@2x.png"/></div></div></figure><p id="f5f4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第一次遇到这种情况时，你可能会感到畏惧。简而言之，该方法选择描述每个特征重要性的权重。有关解释线性回归模型的更多信息，请查看 Christoph Molnar 的<a class="ae ky" href="https://christophm.github.io/interpretable-ml-book/index.html" rel="noopener ugc nofollow" target="_blank"> <em class="lv">可解释的机器学习</em> </a>。</p><p id="b6c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以现在我们应该考虑如何最小化 RSS。让我们用矩阵符号重写 RSS:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/34dfc57e5704718dd8b821608f57ef8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*ZXaynfcWXuwSNSxOx4m7Iw@2x.png"/></div></figure><p id="cd8e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在矩阵<strong class="lb iu"> X </strong>中，每一行都是一个输入特征，RSS 是一个带有<em class="lv"> p </em> +1 个参数的二次函数。我们可以对 RSS 相对于<em class="lv">p</em>+1β参数求导:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/82f12a32be6ac8dd43fe82cb2eb3c752.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*yYHFka3bWw0E1TsxRg-qwA@2x.png"/></div></figure><p id="d1dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们设这个导数等于零:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi md"><img src="../Images/9864d4ec16ab87178b93ca2258386974.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*1fWImBy5Fj2JK0nxp4ojFw@2x.png"/></div></figure><p id="9c06" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们有独特的解决方案:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi me"><img src="../Images/a5fbbf8d70d88633767897595b73b990.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*n6kW_8aHIFJaet0JH_UuQw@2x.png"/></div></figure><p id="60ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在有了使 RSS 最小化的β参数。给定输入向量，我们可以通过训练输入的拟合值来表示预测值:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/645ebe50b53e8e1cdef2012dc0496973.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*Btgp0qEVp6AbrJjvl-j3FA@2x.png"/></div></figure><p id="99e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在已经讨论了足够多的理论。现在让我们讨论如何在 python 中实现线性回归模型。</p><p id="985a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">出于我们的目的，我们将使用来自<a class="ae ky" href="https://www.kaggle.com/mirichoi0218/insurance" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>的<em class="lv">医疗费用个人数据集</em>数据。</p><p id="d9da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，让我们导入 pandas 库:</p><pre class="kj kk kl km gt mg mh mi mj aw mk bi"><span id="9687" class="ml mm it mh b gy mn mo l mp mq">import pandas as pd</span></pre><p id="9ade" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，让我们使用'将数据读入 Pandas 数据框。read_csv()'方法:</p><pre class="kj kk kl km gt mg mh mi mj aw mk bi"><span id="fd4f" class="ml mm it mh b gy mn mo l mp mq">df = pd.read_csv("insurance.csv")</span></pre><p id="8e48" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们打印前五行数据:</p><pre class="kj kk kl km gt mg mh mi mj aw mk bi"><span id="e272" class="ml mm it mh b gy mn mo l mp mq">print(df.head())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mr"><img src="../Images/38a7e8642710551248b18998f1deb65e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TXC6XVDcsGVBgwuFf5VTsg.png"/></div></div></figure><p id="9fad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用年龄、身体质量指数(bmi)、吸烟状况和性别建立一个线性回归模型来预测医疗费用。让我们定义我们的输入和输出:</p><pre class="kj kk kl km gt mg mh mi mj aw mk bi"><span id="79ec" class="ml mm it mh b gy mn mo l mp mq">import numpy as np </span><span id="67d1" class="ml mm it mh b gy ms mo l mp mq">df['sex_code'] = np.where(df['sex'] == 'female', 1, 0)<br/>df['smoker_code'] = np.where(df['smoker'] == 'yes', 1, 0)</span><span id="0709" class="ml mm it mh b gy ms mo l mp mq">X = np.array(df[['age', 'bmi', 'children', 'sex_code', 'smoker_code']])<br/>y = np.array(df['charges'])</span></pre><p id="a87a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们为培训和测试拆分数据:</p><pre class="kj kk kl km gt mg mh mi mj aw mk bi"><span id="105c" class="ml mm it mh b gy mn mo l mp mq">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)</span></pre><p id="77d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们从 scikit-learn (sklearn)导入线性回归模块，定义我们的线性回归对象，并拟合我们的模型:</p><pre class="kj kk kl km gt mg mh mi mj aw mk bi"><span id="8193" class="ml mm it mh b gy mn mo l mp mq">reg = LinearRegression()<br/>reg.fit(X_train, y_train)</span></pre><p id="0558" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们打印出我们的模型表现如何。我们将使用 R 指标来衡量绩效。r 是一个统计指标，用于衡量数据与回归线的接近程度。值介于 0 和 1.0 之间，值 1.0 代表完美的模型性能:</p><pre class="kj kk kl km gt mg mh mi mj aw mk bi"><span id="c26d" class="ml mm it mh b gy mn mo l mp mq">print("Model Performance: ", reg.score(X_test, y_test))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/4c4c4e9b76351caea5b7d764cb0791a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/1*ra2OpDH_rMWuxDmoX3kV5w.png"/></div></figure><p id="2231" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们看到我们的模型表现得相当好。0.78 的 R 意味着我们的模型解释了我们数据中 78%的方差。我就讲到这里，但是我鼓励你阅读更多关于线性回归的内容，自己动手处理数据和编写代码。以下是一些有助于您继续学习的额外资源:</p><ol class=""><li id="bd04" class="mu mv it lb b lc ld lf lg li mw lm mx lq my lu mz na nb nc bi translated"><a class="ae ky" href="https://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="lv">统计学习入门</em> </a></li><li id="fca2" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated"><a class="ae ky" href="https://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="lv">统计学习的要素</em> </a></li><li id="922b" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated"><a class="ae ky" href="https://christophm.github.io/interpretable-ml-book/index.html" rel="noopener ugc nofollow" target="_blank"> <em class="lv">可解释的机器学习</em> </a></li></ol><h1 id="6020" class="ni mm it bd nj nk nl nm nn no np nq nr jz ns ka nt kc nu kd nv kf nw kg nx ny bi translated">结论</h1><p id="82b1" class="pw-post-body-paragraph kz la it lb b lc nz ju le lf oa jx lh li ob lk ll lm oc lo lp lq od ls lt lu im bi translated">总之，在这篇文章中，我们讨论了线性回归背后的理论。线性回归使用特征的加权和来表示响应变量。使用最小二乘法计算模型中的权重。我们还展示了如何在 python 中实现一个线性回归模型，并使用它来基于患者特征预测医疗成本。我希望你觉得这篇文章有用/有趣。这篇文章中的代码可以在<a class="ae ky" href="https://github.com/spierre91/medium_code/tree/master/sklearn_tutorials" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到。感谢您的阅读！</p></div></div>    
</body>
</html>