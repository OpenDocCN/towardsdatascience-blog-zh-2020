<html>
<head>
<title>KNN Algorithm: When? Why? How?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">KNN算法:何时？为什么？怎么会？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/knn-algorithm-what-when-why-how-41405c16c36f?source=collection_archive---------4-----------------------#2020-05-25">https://towardsdatascience.com/knn-algorithm-what-when-why-how-41405c16c36f?source=collection_archive---------4-----------------------#2020-05-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="d779" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">KNN: K近邻算法是机器学习的基本算法之一。机器学习模型使用一组输入值来预测输出值。KNN是最简单形式的机器学习算法之一，主要用于分类。它根据相邻数据点的分类方式对数据点进行分类。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/64dd9e6dd795cafe709330a62392286e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CJwU-DIb6Fokx2E1yCQEzg.png"/></div></div><p class="kx ky gj gh gi kz la bd b be z dk translated">图片由Aditya提供</p></figure><p id="34ec" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">KNN根据先前存储的数据点的相似性度量对新数据点进行分类。例如，如果我们有一个西红柿和香蕉的数据集。KNN将存储类似的措施，如形状和颜色。当一个新的物体出现时，它会检查颜色(红色或黄色)和形状的相似性。</p><p id="5731" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">KNN的k代表我们用来分类新数据点的最近邻的数量。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi lb"><img src="../Images/9bedb725c101aae41b69adab1d1ff252.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xs660_QWvVI4tv4nnniAjA.png"/></div></div><p class="kx ky gj gh gi kz la bd b be z dk translated">图片由Aditya提供</p></figure><p id="a7fa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">我该如何选择K？</strong></p><p id="d9b9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我们有很多点的实际问题中，问题是如何选择K的值？</p><p id="7ce8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">选择正确的K值称为参数调整，这是获得更好结果的必要条件。通过选择K的值，我们对数据集中可用的数据点的总数求平方根。</p><p id="b03a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">a.K = sqrt(数据点总数)。</p><p id="52e8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">b.总是选择K的奇数值，以避免两个类之间的混淆。</p><p id="77dc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">KNN是什么时候？</strong></p><p id="225f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">a.我们有正确标记的数据。例如，如果我们预测某人是否患有糖尿病，最终标签可以是1或0。它不能是NaN或-1。</p><p id="d7a0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">b.数据无噪声。对于糖尿病数据集，我们不能将葡萄糖水平设为0或10000。这几乎是不可能的。</p><p id="724f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">c.小数据集。</p><p id="8cd2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">KNN是如何工作的？</strong></p><p id="7665" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们通常用欧氏距离来计算最近邻。如果我们有两点(x，y)和(a，b)。欧几里德距离(d)的公式为</p><p id="2bff" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">d = sqrt((x-a) +(y-b))</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi lc"><img src="../Images/a0d6f1554229abb7543deeee84428187.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2eYeO1ZxJlVum6FHYFarag.png"/></div></div><p class="kx ky gj gh gi kz la bd b be z dk translated">图片由Aditya提供</p></figure><p id="bdaf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们试图获得最小的欧几里德距离，并基于较小距离的数量来执行我们的计算。</p><p id="c0ac" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们在一个数据库上尝试KNN，看看它是如何工作的。数据可以从<a class="ae ld" href="https://github.com/adityakumar529/Coursera_Capstone/blob/master/diabetes.csv" rel="noopener ugc nofollow" target="_blank">https://github . com/adityakumar 529/Coursera _ Capstone/blob/master/diabetes . CSV</a>中提取。</p><pre class="km kn ko kp gt le lf lg lh aw li bi"><span id="dd7c" class="lj lk iq lf b gy ll lm l ln lo">import pandas as pd<br/>import numpy as np<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.neighbors import KNeighborsClassifier<br/>from sklearn.metrics import confusion_matrix<br/>from sklearn.metrics import accuracy_score<br/>from sklearn.metrics import f1_score</span></pre><p id="16ad" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">pd和np是熊猫和NumPy图书馆的。最后3行(混淆矩阵、准确度分数和f1分数)用于检查模型的准确度。train_test_split就是对数据进行拆分和训练。KNeighborsClassifier代表K个最近邻。数据集的标准化是许多机器学习评估器的共同要求:如果单个特征看起来不像标准的正态分布数据，它们可能表现得很差。</p><pre class="km kn ko kp gt le lf lg lh aw li bi"><span id="07de" class="lj lk iq lf b gy ll lm l ln lo">data = pd.read_csv("../input/diabetes.csv")<br/>data.head()</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi lp"><img src="../Images/766c1098cf92f13c5fe0da5cebd511af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/1*oHVARCI1lqNBnQtka3nI3A.png"/></div></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi lp"><img src="../Images/fb0d7ad9ba010106a715365f91e7d289.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/1*v24GOBbZqT5BUzxXeXRY1g.png"/></div></figure><p id="e4a4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们已经通过pd.read_csv读取了CSV文件。通过头部()我们可以看到前5行。有些因素的值不能为零。例如，对于人类来说，葡萄糖值不能为0。同样，人类的血压、皮肤厚度、胰岛素和身体质量指数也不能为零。</p><pre class="km kn ko kp gt le lf lg lh aw li bi"><span id="1ff6" class="lj lk iq lf b gy ll lm l ln lo">non_zero = ['Glucose','BloodPressure','SkinThickness','Insulin','BMI']<br/>for coloumn <strong class="lf ir">in</strong> non_zero:<br/>    data[coloumn] = data[coloumn].replace(0,np.NaN)<br/>    mean = int(data[coloumn].mean(skipna = True))<br/>    data[coloumn] = data[coloumn].replace(np.NaN, mean)<br/>    print(data[coloumn])</span><span id="8c1c" class="lj lk iq lf b gy lq lm l ln lo">0      148.0<br/>1       85.0<br/>2      183.0<br/>3       89.0<br/>4      137.0<br/>       ...  <br/>763    101.0<br/>764    122.0<br/>765    121.0<br/>766    126.0<br/>767     93.0<br/>Name: Glucose, Length: 768, dtype: float64<br/>0      72.0<br/>1      66.0<br/>2      64.0<br/>3      66.0<br/>4      40.0<br/>       ... <br/>763    76.0<br/>764    70.0<br/>765    72.0<br/>766    60.0<br/>767    70.0<br/>Name: BloodPressure, Length: 768, dtype: float64<br/>0      35.0<br/>1      29.0<br/>2      29.0<br/>3      23.0<br/>4      35.0<br/>       ... <br/>763    48.0<br/>764    27.0<br/>765    23.0<br/>766    29.0<br/>767    31.0<br/>Name: SkinThickness, Length: 768, dtype: float64<br/>0      155.0<br/>1      155.0<br/>2      155.0<br/>3       94.0<br/>4      168.0<br/>       ...  <br/>763    180.0<br/>764    155.0<br/>765    112.0<br/>766    155.0<br/>767    155.0<br/>Name: Insulin, Length: 768, dtype: float64<br/>0      33.6<br/>1      26.6<br/>2      23.3<br/>3      28.1<br/>4      43.1<br/>       ... <br/>763    32.9<br/>764    36.8<br/>765    26.2<br/>766    30.1<br/>767    30.4<br/>Name: BMI, Length: 768, dtype: float64</span></pre><p id="d3dc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们创建了非零值，该值包含预测结果值所需的所有列。我们需要确保这些列没有任何与零或NaN值相关的值。如果我们有0，我们将替换为NaN。然后用列的平均值替换NaN。让我们绘制糖尿病数据的细节图。</p><pre class="km kn ko kp gt le lf lg lh aw li bi"><span id="439c" class="lj lk iq lf b gy ll lm l ln lo">import seaborn as sns<br/>p=sns.pairplot(data, hue = 'Outcome')</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi lr"><img src="../Images/007c1480a662239c423261cf500e96fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*sda9JynI8-0Spc-i.png"/></div></div></figure><p id="6047" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们用值不能为零的列定义了非零值。在每一列中，我们将首先检查是否有0个值。然后我们用NaN替换它。稍后，我们将创建该列的含义，并用mean替换前面的含义。</p><p id="3928" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">既然我们已经准备好了数据。是时候训练和测试数据了。</p><pre class="km kn ko kp gt le lf lg lh aw li bi"><span id="5622" class="lj lk iq lf b gy ll lm l ln lo">X =data.iloc[:,0:8]<br/>y =data.iloc[:,8]<br/>X_train,X_test,y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0, stratify=y)</span></pre><p id="789f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于数据X，我们取范围从0到7的所有行和列。同样，对于y，我们取第8列的所有行。</p><p id="a653" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们有在程序开始时导入的train_test_split，我们将测试大小定义为0.2，这意味着在所有数据中，20%将被保留下来，以便在稍后阶段测试数据。</p><pre class="km kn ko kp gt le lf lg lh aw li bi"><span id="af22" class="lj lk iq lf b gy ll lm l ln lo"><em class="ls">#feature Scaling</em><br/>sc_X = StandardScaler()<br/>X_train = sc_X.fit_transform(X_train)<br/>X_test = sc_X.transform(X_test)</span></pre><p id="2e20" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">标准缩放器执行标准化任务。通常，数据集包含不同规模的变量。例如，数据集将包含一个值范围为20–70的胰岛素列和一个值范围为80–200的葡萄糖列。由于这两个列的规模不同，因此在构建机器学习模型时，它们被标准化为具有共同的规模。</p><pre class="km kn ko kp gt le lf lg lh aw li bi"><span id="ae1b" class="lj lk iq lf b gy ll lm l ln lo">import math<br/>math.sqrt(len(y_test))</span></pre><p id="1d8b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">外出:</p><pre class="km kn ko kp gt le lf lg lh aw li bi"><span id="6c27" class="lj lk iq lf b gy ll lm l ln lo">12.409673645990857</span></pre><p id="3e2b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们用这个值得到K的值。我们需要K的一个奇数值，所以我们将它设为12–1或12+1。</p><pre class="km kn ko kp gt le lf lg lh aw li bi"><span id="a155" class="lj lk iq lf b gy ll lm l ln lo">classifier = KNeighborsClassifier(n_neighbors=13,p=2,metric='euclidean')</span><span id="ec80" class="lj lk iq lf b gy lq lm l ln lo">classifier.fit(X_train,y_train)</span></pre><p id="f0bd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">外出:</p><pre class="km kn ko kp gt le lf lg lh aw li bi"><span id="d1d6" class="lj lk iq lf b gy ll lm l ln lo">KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',<br/>                     metric_params=None, n_jobs=None, n_neighbors=13, p=2,<br/>                     weights='uniform')</span></pre><p id="8300" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们用分类器预测来预测我们的数据。</p><pre class="km kn ko kp gt le lf lg lh aw li bi"><span id="4c5a" class="lj lk iq lf b gy ll lm l ln lo">y_pred =  classifier.predict(X_test)<br/>y_pred</span></pre><p id="ad35" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">外出:</p><pre class="km kn ko kp gt le lf lg lh aw li bi"><span id="faa5" class="lj lk iq lf b gy ll lm l ln lo">array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,<br/>       1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0,<br/>       1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,<br/>       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,<br/>       0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,<br/>       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,<br/>       0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0])</span></pre><p id="3e3c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们有一系列数据，但我们需要评估我们的模型来检查准确性。让我们从一个混淆矩阵开始。</p><pre class="km kn ko kp gt le lf lg lh aw li bi"><span id="00fa" class="lj lk iq lf b gy ll lm l ln lo">cm= confusion_matrix(y_test,y_pred)<br/>cm</span></pre><p id="c658" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">外出:</p><pre class="km kn ko kp gt le lf lg lh aw li bi"><span id="5ec4" class="lj lk iq lf b gy ll lm l ln lo">array([[86, 14],<br/>       [24, 30]])</span></pre><p id="cc40" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们有一个混淆矩阵，其中86和30的对角线表示正确的值，14，24表示我们错过的预测。</p><p id="685e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们会检查f1的成绩。</p><pre class="km kn ko kp gt le lf lg lh aw li bi"><span id="236e" class="lj lk iq lf b gy ll lm l ln lo">print(f1_score(y_test,y_pred))</span></pre><p id="821d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在外</p><pre class="km kn ko kp gt le lf lg lh aw li bi"><span id="ed12" class="lj lk iq lf b gy ll lm l ln lo">0.6122448979591836</span><span id="6995" class="lj lk iq lf b gy lq lm l ln lo">print(accuracy_score(y_test,y_pred))</span></pre><p id="74bf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">外出:</p><pre class="km kn ko kp gt le lf lg lh aw li bi"><span id="f5d4" class="lj lk iq lf b gy ll lm l ln lo">0.7532467532467533</span></pre><p id="405a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的f1评分为0.61，准确率为0.75</p><p id="bba3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们绘制实际数据和预测值的图表。</p><pre class="km kn ko kp gt le lf lg lh aw li bi"><span id="9162" class="lj lk iq lf b gy ll lm l ln lo">import matplotlib.pyplot as plt<br/>plt.figure(figsize=(5, 7))<br/></span><span id="e7c5" class="lj lk iq lf b gy lq lm l ln lo">ax = sns.distplot(data['Outcome'], hist=False, color="r", label="Actual Value")<br/>sns.distplot(y_pred, hist=False, color="b", label="Predicted Values", ax=ax)<br/></span><span id="7760" class="lj lk iq lf b gy lq lm l ln lo">plt.title('Actual vs Precited value for outcome')<br/>plt.show()<br/>plt.close()</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi lp"><img src="../Images/f6cbd4b35f9324b4eae0e90abd600e97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/1*4kPip1EXqK-tnwIlxEKGgQ.png"/></div></figure><p id="59ba" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">可在以下位置查看实际代码:</p><div class="lt lu gp gr lv lw"><a href="https://www.kaggle.com/adityakumar529/knn-algorithm" rel="noopener  ugc nofollow" target="_blank"><div class="lx ab fo"><div class="ly ab lz cl cj ma"><h2 class="bd ir gy z fp mb fr fs mc fu fw ip bi translated">KNN算法</h2><div class="md l"><h3 class="bd b gy z fp mb fr fs mc fu fw dk translated">使用Kaggle笔记本探索并运行机器学习代码|使用来自[私人数据源]的数据</h3></div><div class="me l"><p class="bd b dl z fp mb fr fs mc fu fw dk translated">www.kaggle.com</p></div></div><div class="mf l"><div class="mg l mh mi mj mf mk kv lw"/></div></div></a></div><p id="9df4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae ld" href="https://github.com/adityakumar529/Coursera_Capstone/blob/master/KNN.ipynb" rel="noopener ugc nofollow" target="_blank">https://git hub . com/aditykumar 529/Coursera _ Capstone/blob/master/KNN . ipynb</a>。</p></div></div>    
</body>
</html>