# é¢å‘åˆå­¦è€…çš„è‡ªç„¶è¯­è¨€å¤„ç†

> åŸæ–‡ï¼š<https://towardsdatascience.com/natural-language-processing-nlp-for-beginners-6d19f3eedfea?source=collection_archive---------13----------------------->

## ä½¿ç”¨ Python çš„ NLP å¾ªåºæ¸è¿›åˆå­¦è€…æŒ‡å—

![](img/15185055c1d056e77a2f30670e527952.png)

Bram Naus åœ¨ [Unsplash](https://unsplash.com/?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) ä¸Šæ‹æ‘„çš„ç…§ç‰‡

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†å‘ä½ ä»‹ç»ä¸€ä¸ªæœ€è‘—åçš„äººå·¥æ™ºèƒ½é¢†åŸŸï¼Œå«åšè‡ªç„¶è¯­è¨€å¤„ç†ã€‚ä»‹ç»ç»“æŸåï¼Œæˆ‘å°†å¸¦æ‚¨å®Œæˆä¸€ä¸ªåŠ¨æ‰‹ç»ƒä¹ ï¼Œæˆ‘ä»¬å°†ä»ä¸€ä¸ªç‰¹å®šçš„ç½‘ç«™ä¸­æå–ä¸€äº›æœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚å¯¹äºåŠ¨æ‰‹é¡¹ç›®ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªåä¸º NLTK(è‡ªç„¶è¯­è¨€å·¥å…·åŒ…)çš„ç‰¹å®š NLP æ¨¡å—ï¼Œè¿™å°†åœ¨ç®€ä»‹éƒ¨åˆ†ä¹‹åä»‹ç»ã€‚è¯»å®Œè¿™ç¯‡æ–‡ç« åï¼Œæ‚¨å°†å¯¹è‡ªç„¶è¯­è¨€å¤„ç†åº”ç”¨ç¨‹åºåŠå…¶å·¥ä½œåŸç†æœ‰æ›´å¥½çš„ç†è§£ã€‚æŠ“ç´§æ—¶é—´ï¼Œè®©æˆ‘ä»¬å¼€å§‹å§ï¼

## ç›®å½•

*   ***ç®€ä»‹***
*   ***ã€è‡ªç„¶è¯­è¨€å·¥å…·åŒ…ã€‘***
*   ***BS4(ç¾æ±¤ 4)***
*   ***ç¬¬ä¸€æ­¥â€”â€”å¯¼å…¥åº“***
*   ***ç¬¬äºŒæ­¥â€”é˜…è¯»é¡µé¢***
*   ***ç¬¬ä¸‰æ­¥â€”æ•°æ®æ¸…ç†***
*   ***ç¬¬å››æ­¥â€”â€”æ ‡è®°åŒ–***
*   ***ç¬¬äº”æ­¥â€”æ•°æ®å¯è§†åŒ–***
*   ***è§†é¢‘æ¼”ç¤º***

# ä»‹ç»

è‡ªç„¶è¯­è¨€æ˜¯æŒ‡æˆ‘ä»¬åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­ä½¿ç”¨çš„è¯­è¨€ã€‚è¿™ä¸ªé¢†åŸŸå·²ç»å­˜åœ¨å¾ˆé•¿æ—¶é—´äº†ï¼Œä½†æ˜¯éšç€è®¡ç®—æœºç§‘å­¦å’Œç¼–ç¨‹çš„å‘å±•ï¼Œå…³äºè¿™ä¸ªé¢†åŸŸçš„äººå·¥æ™ºèƒ½ç›¸å…³ç ”ç©¶å·²ç»å¢åŠ ã€‚äº’è”ç½‘æ”¹å˜äº†æˆ‘ä»¬çš„ç”Ÿæ´»æ–¹å¼ï¼Œä»¥åŠæˆ‘ä»¬ç›¸äº’äº¤æµçš„æ–¹å¼ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¼€å§‹ä½¿ç”¨æ–‡æœ¬æ¶ˆæ¯ã€ç”µå­é‚®ä»¶ã€è¯­éŸ³æ¶ˆæ¯ç­‰ï¼Œè€Œä¸æ˜¯å‘é€çº¸è´¨é‚®ä»¶å’Œä¿¡ä»¶ã€‚ä½ å¯ä»¥é€šè¿‡åœ¨ç½‘ä¸Šåšä¸€äº›ç ”ç©¶æ¥äº†è§£è¿™ä¸ªé¢†åŸŸã€‚

ä¸ºäº†è®©ä½ æ›´å¥½åœ°äº†è§£*è‡ªç„¶è¯­è¨€å¤„ç†*å¦‚ä½•è¢«ç”¨äºæœºå™¨å­¦ä¹ å’Œäººå·¥æ™ºèƒ½é¢†åŸŸï¼Œæˆ‘æƒ³ä¸ä½ åˆ†äº«ä¸€äº›ç°å®ç”Ÿæ´»ä¸­çš„åº”ç”¨:

*   **Google** **ç¿»è¯‘:**Google Translate èƒŒåçš„æœºå™¨æ™ºèƒ½ç†è§£å•è¯ï¼Œå¹¶é€å­—ç¿»è¯‘æˆä½ æƒ³è¦çš„è¯­è¨€ã€‚å®ƒåœ¨ç¿»è¯‘æ—¶ä¸ä¼šä¸¢å¤±å¥å­çš„æ„æ€ã€‚
*   è¯­æ³•ä¸Š:è¿™é¡¹æœåŠ¡èƒŒåçš„æœºå™¨æ™ºèƒ½æ“…é•¿è¯­æ³•å’Œå•è¯ã€‚è¿™æ˜¯è¯­è¨€å¤„ç†åœ¨è¿‡å»å‡ å¹´ä¸­å¦‚ä½•å‘å±•çš„ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­ã€‚å®ƒæ£€æŸ¥å¥å­çš„è¯­æ³•ï¼Œç”šè‡³ç»™å‡ºä¸€äº›å¦‚ä½•æé«˜æ–‡ç« è´¨é‡çš„å»ºè®®ã€‚
*   **è¯­éŸ³åŠ©æ‰‹:**è¿™ä¸ªé¢†åŸŸä¹Ÿæ˜¯è¯­è¨€å¤„ç†è¿›æ­¥å¾ˆå¤§çš„å¤§éƒ¨åˆ†é¢†åŸŸã€‚è¯­éŸ³è¯†åˆ«æŠ€æœ¯ä¸»è¦ç”¨äºæ–‡å­—å¤„ç†ã€‚ç›®å‰ï¼Œæœ€çŸ¥åçš„æ˜¯è‹¹æœ Siriã€è°·æ­ŒåŠ©æ‰‹å’Œäºšé©¬é€Š Alexaã€‚
*   èŠå¤©æœºå™¨äºº:å¦ä¸€ä¸ªè¯­è¨€å¤„ç†çš„å¥½ä¾‹å­æ˜¯èŠå¤©æœºå™¨äººã€‚ä»–ä»¬éå¸¸åƒè™šæ‹ŸåŠ©ç†ï¼Œä½†æœ‰æ›´å…·ä½“çš„ç›®æ ‡ã€‚å®ƒä»¬æœ€å¸¸ç”¨äºå®¢æˆ·è®¿é—®çš„ç½‘ç«™ã€‚ä»–ä»¬å¸®åŠ©ä½ è·å¾—ä½ éœ€è¦çš„ä¿¡æ¯ï¼Œè€Œä¸éœ€è¦å’Œä»»ä½•çœŸå®çš„äººäº¤è°ˆã€‚é¦–å…ˆï¼Œä»–ä»¬è¯•å›¾ç†è§£ä½ çš„éœ€æ±‚ï¼Œç„¶åæŠŠç»“æœå‘ˆç°åœ¨ä½ é¢å‰ã€‚
*   Web æŠ“å–: Web æŠ“å–æ˜¯è¯­è¨€å¤„ç†å¸¸ç”¨çš„å¦ä¸€ä¸ªé¢†åŸŸã€‚å®ƒç”¨äºä»ç½‘é¡µä¸­æå–ä¿¡æ¯ï¼Œç”šè‡³ä¸éœ€è¦èŠ±è´¹æ—¶é—´ä¸€æ®µä¸€æ®µåœ°å¤åˆ¶ã€‚ç½‘ç»œæŠ“å–æ˜¯æ”¶é›†æœ‰ä»·å€¼çš„æ•°æ®å’Œè®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹çš„ä¸€ç§å¾ˆå¥½çš„æ–¹å¼ã€‚ç½‘é¡µæŠ“å–ä¹Ÿæ˜¯ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„å·¥å…·ï¼Œå½“å·¥ä½œä¸æœç´¢å¼•æ“ä¼˜åŒ–ã€‚

# è‡ªç„¶è¯­è¨€å·¥å…·åŒ…

> NLTK æ˜¯æ„å»º Python ç¨‹åºæ¥å¤„ç†äººç±»è¯­è¨€æ•°æ®çš„é¢†å…ˆå¹³å°ã€‚å®ƒæä¾›äº† 50 å¤šä¸ªè¯­æ–™åº“å’Œè¯æ±‡èµ„æº(å¦‚ WordNet)çš„æ˜“ç”¨æ¥å£ï¼Œä»¥åŠä¸€å¥—ç”¨äºåˆ†ç±»ã€æ ‡è®°åŒ–ã€è¯å¹²åŒ–ã€æ ‡è®°ã€è§£æå’Œè¯­ä¹‰æ¨ç†çš„æ–‡æœ¬å¤„ç†åº“ï¼Œä»¥åŠå·¥ä¸šçº§ NLP åº“çš„åŒ…è£…å™¨ã€‚
> 
> å‚è€ƒ:[http://www.nltk.org](http://www.nltk.org)

æˆ‘ä»¬å¿…é¡»å®‰è£… NLTK æ¨¡å—ï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥åœ¨æˆ‘ä»¬çš„é¡¹ç›®ä¸­ä½¿ç”¨å®ƒã€‚åœ¨æ‚¨çš„ç»ˆç«¯ä¸­è¿è¡Œä»¥ä¸‹ä»£ç å°†ä¸ºæ‚¨å®Œæˆå®‰è£…:

```
pip install nltk
```

# ç¾ä¸½çš„æ±¤ 4

> Beautiful Soup æ˜¯ä¸€ä¸ª Python åº“ï¼Œç”¨äºä» HTMLã€XML å’Œå…¶ä»–æ ‡è®°è¯­è¨€ä¸­è·å–æ•°æ®ã€‚Beautiful Soup å¸®åŠ©æ‚¨ä»ç½‘é¡µä¸­æå–ç‰¹å®šå†…å®¹ï¼Œåˆ é™¤ HTML æ ‡è®°ï¼Œå¹¶ä¿å­˜ä¿¡æ¯ã€‚å®ƒæ˜¯ä¸€ä¸ªç½‘ç»œæŠ“å–å·¥å…·ï¼Œå¯ä»¥å¸®åŠ©ä½ æ¸…ç†å’Œè§£æä»ç½‘ä¸Šä¸‹è½½çš„æ–‡æ¡£ã€‚
> 
> å‚è€ƒ:[https://programminghistorian . org/en/lessons/intro-to-beautiful-soup](https://programminghistorian.org/en/lessons/intro-to-beautiful-soup)

ç°åœ¨ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ pip å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„æ¼‚äº®æ±¤åº“:

```
pip install beautifulsoup4
```

# æ­¥éª¤ 1-å¯¼å…¥åº“

åº“å®‰è£…å®Œæˆåï¼Œæˆ‘ä»¬å°±å¯ä»¥å¼€å§‹ç¼–ç¨‹äº†ã€‚ä¸ºäº†è¿™ä¸ªé¡¹ç›®ï¼Œæˆ‘å°†ä½¿ç”¨ Jupyter ç¬”è®°æœ¬ã€‚å¥½çš„ï¼Œé¦–å…ˆï¼Œè®©æˆ‘ä»¬å°†åº“å¯¼å…¥ç¬”è®°æœ¬ã€‚

```
import nltk

from nltk.corpus import stopwordsfrom bs4 import BeautifulSoupimport urllib.requestimport plotly.io as pio
```

# æ­¥éª¤ 2 â€”é˜…è¯»é¡µé¢

åœ¨è¿™ä¸€æ­¥ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ urllib è¯·æ±‚æ–¹æ³•æ‰“å¼€ç½‘é¡µã€‚æ‰“å¼€åï¼Œæˆ‘ä»¬ä¼šè¯»å–ç½‘é¡µçš„å…¨éƒ¨ä»£ç ã€‚å¦‚ä½ æ‰€çŸ¥ï¼Œç½‘é¡µæœ‰ä¸€ä¸ªä»£ç åœ¨åå°è¿è¡Œã€‚ä½ å¯ä»¥åœ¨ä»»ä½•ç½‘é¡µä¸Šç‚¹å‡»å³é”®ï¼Œç„¶åç‚¹å‡»â€œinspect elementâ€æ¥äº†è§£ä»£ç ã€‚

æˆ‘é€‰æ‹©äº†ç»´åŸºç™¾ç§‘å…³äºè‡ªç„¶è¯­è¨€å¤„ç†çš„é¡µé¢ã€‚

```
page =  urllib.request.urlopen('[https://en.wikipedia.org/wiki/Natural_language_processing'](https://en.wikipedia.org/wiki/Natural_language_processing'))html_plain = page.read()print(html_plain)
```

è¿™æ˜¯æˆ‘ä»¬æ‰“å°æ™®é€š html ä»£ç æ—¶çš„æ ·å­:

![](img/9151eaf66355e9524fa7841c6f55e00f.png)

html ä»£ç 

# æ­¥éª¤ 3 â€”æ•°æ®æ¸…ç†

ä»æˆªå›¾ä¸­å¯ä»¥çœ‹å‡ºï¼Œæ™®é€šçš„ html ä»£ç éœ€è¦ä¸€äº›æ¸…ç†ã€‚BeautifulSoup å°†åœ¨è¿™ä¸ªæ•°æ®æ¸…ç†è¿‡ç¨‹ä¸­å¸®åŠ©æˆ‘ä»¬ã€‚æˆ‘ä»¬å¿…é¡»å»æ‰è®¸å¤šä¸å¿…è¦çš„å­—ç¬¦ï¼Œæ¯”å¦‚åŒå¼•å·ã€æ–œçº¿ã€å¤§äºå·å’Œå°äºå·ç­‰ç­‰ã€‚åˆ«æ‹…å¿ƒï¼Œå®ƒè¿˜ä¼šæ¸…ç† HTML è¯­æ³•å•è¯ğŸ˜Š

è¿è¡Œä»¥ä¸‹å‡ è¡Œæ¥çœ‹çœ‹ BS4(ç¾äººæ±¤ 4)çš„ç¥å¥‡åŠ›é‡:

```
soup = BeautifulSoup(html_plain,'html.parser')soup_text = soup.get_text(strip = True)
```

å¤ªå¥½äº†ï¼åœ¨æˆ‘ä»¬æ‹†åˆ†å•è¯ä¹‹å‰è¿˜æœ‰ä¸€ä»¶äº‹:ä¸ºäº†æé«˜å¤„ç†çš„è´¨é‡ï¼Œæˆ‘å»ºè®®æ‰€æœ‰çš„å­—ç¬¦éƒ½å°å†™ã€‚å½“æˆ‘ä»¬å¼€å§‹è®¡ç®—å•è¯çš„é¢‘ç‡æ—¶ï¼Œè¿™å°†æ˜¯æœ‰å¸®åŠ©çš„ã€‚å¦åˆ™ï¼Œç”±äº Ascii å€¼ä¸åŒï¼Œæœºå™¨ä¼šå°†â€œè‡ªç„¶â€å’Œâ€œè‡ªç„¶â€è§†ä¸ºä¸åŒçš„å•è¯ã€‚

```
ready_text = soup_text.lower()print(ready_text)
```

![](img/04192fc57a91d142fe75c5728919d6fc.png)

çœ‹èµ·æ¥å¥½å¤šäº†ï¼ç°åœ¨ï¼Œè®©æˆ‘ä»¬è¿›å…¥ä¸‹ä¸€æ­¥ï¼Œå°†æ¯ä¸ªå•è¯æ‹†åˆ†æˆä¸€ä¸ªåˆ—è¡¨é¡¹ã€‚è¿™ä¸ªè¿‡ç¨‹è¢«ç§°ä¸ºæ ‡è®°åŒ–ã€‚

# æ­¥éª¤ 4 â€”æ ‡è®°åŒ–

åœ¨å¤„ç†è‡ªç„¶è¯­è¨€å¤„ç†é¡¹ç›®æ—¶ï¼Œè¿™ä¸€æ­¥è‡³å…³é‡è¦ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†é€šè¿‡å°†æ¯ä¸ªå•è¯åˆ†æˆåˆ—è¡¨é¡¹æ¥å¯¹å®ƒä»¬è¿›è¡Œæ ‡è®°ã€‚ä¹‹åï¼Œæˆ‘ä»¬ä¼šåšä¸€äº›å•è¯æ¸…ç†ã€‚NLTK(è‡ªç„¶è¯­è¨€å·¥å…·åŒ…)å°†ç”¨æ¥æ¸…é™¤åœç”¨è¯ã€‚è¿™å°†ç»™æˆ‘ä»¬ç•™ä¸‹å…³é”®è¯ï¼Œè®©æˆ‘ä»¬å¯¹ç½‘é¡µæœ‰æ›´å¥½çš„äº†è§£ã€‚è¿™æ ·æˆ‘ä»¬å°±ä¸ç®—åœç”¨è¯äº†ï¼Œæ¯”å¦‚ *aï¼Œandï¼Œofï¼Œthatï¼Œtheï¼Œwith ç­‰*ã€‚

```
tokens = []
for t in ready_text.split():
    tokens.append(t)print(tokens)
```

![](img/5a7cdbc728bfd05aa9df67f74f455e45.png)

```
#Run this line if you get an error message in the next code block
nltk.download()
```

ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ¸…é™¤ä»¤ç‰Œåˆ—è¡¨ä¸­çš„åœç”¨è¯ã€‚

```
stop_words = stopwords.words('english')
clean_tokens = tokens[:]for token in tokens:
    if token in stop_words:
        clean_tokens.remove(token)print(clean_tokens)
```

![](img/b8e8e7aa4589ea1a17e15fd86efd1669.png)

æ¸…ç†çš„ä»¤ç‰Œ

# æ­¥éª¤ 5 â€”æ•°æ®å¯è§†åŒ–

åœ¨è¿™ä¸€æ­¥ä¸­ï¼Œé¦–å…ˆæˆ‘ä»¬å°†ç»Ÿè®¡æ ‡è®°çš„é¢‘ç‡ï¼Œç„¶åæˆ‘ä»¬å°†è¿‡æ»¤é«˜é¢‘æ ‡è®°ã€‚è¿‡æ»¤åï¼Œå°±è¯¥å¯è§†åŒ–è‡ªç„¶è¯­è¨€å¤„ç†ç»´åŸºç™¾ç§‘é¡µé¢ä¸­æœ€å¸¸ç”¨çš„è¯äº†ã€‚è§†è§‰åŒ–å°†å¸®åŠ©æˆ‘ä»¬æŒ‰ç…§å®ƒä»¬çš„é¢‘ç‡é¡ºåºæ¥çœ‹å®ƒä»¬ã€‚

è®©æˆ‘ä»¬ç”¨ NLTK çš„ FreqDist å‡½æ•°æ¥è®¡ç®—å•è¯çš„é¢‘ç‡ã€‚

```
freq = nltk.FreqDist(clean_tokens)for key, val in freq.items():
    print('Word: ' + str(key) + ', Quantity:' + str(val))
```

![](img/222613af654626ccbea3e5b67d05567f.png)

ä»£å¸æ•°é‡

ç°åœ¨ï¼Œæˆ‘ä»¬å°†å®šä¹‰ä¸€ä¸ªæ–°çš„å­—å…¸ï¼Œå¹¶è·å–é¡µé¢ä¸­ä½¿ç”¨æ¬¡æ•°è¶…è¿‡ 10 æ¬¡çš„æ ‡è®°ã€‚è¿™äº›å…³é”®è¯æ¯”å…¶ä»–å…³é”®è¯æ›´æœ‰ä»·å€¼:

```
high_freq = dict()
for key, val in freq.items():
    if (val > 10):
        high_freq[key] = val
```

å®Œç¾ï¼ç°åœ¨æˆ‘ä»¬æœ‰äº†ä¸€æœ¬å«åš*é«˜é¢‘*çš„æ–°è¯å…¸ã€‚è®©æˆ‘ä»¬è¿›å…¥æœ€åä¸€æ­¥ï¼Œåˆ›å»ºä¸€ä¸ªæ¡å½¢å›¾ã€‚æˆ‘è®¤ä¸ºæ¡å½¢å›¾ç”¨å®šé‡æ•°æ®è¡¨ç¤ºä¼šæ›´å¥½ã€‚æˆ‘è¿˜æŒ‰ç…§é™åºæ’åˆ—ï¼Œæ‰€ä»¥å‡ºç°é¢‘ç‡æœ€é«˜çš„å•è¯æ’åœ¨æœ€å‰é¢ã€‚ä»¥ä¸‹æ˜¯å¯è§†åŒ–ä»£ç :

```
#Note: to pass keys and values of *high_freq* dictionary, I had to convert them to list when passing themfig = dict({
    "data": [{"type": "bar",
              "x": list(high_freq.keys()),
              "y": list(high_freq.values())}],
    "layout": {"title": {"text": "Most frequently used words in the page"}, "xaxis": {"categoryorder":"total descending"}}
})pio.show(fig)
```

![](img/6f1ef4f279be8fce9952be77e5bc748a.png)

plotly æ¡å½¢å›¾

# è§†é¢‘æ¼”ç¤º

æ­å–œä½ ã€‚ï¼æ‚¨å·²ç»åˆ›å»ºäº†ä¸€ä¸ªç¨‹åºæ¥æ£€æµ‹é¡µé¢ä¸­çš„å…³é”®å­—ã€‚ç°åœ¨ï¼Œä¸ç”¨é˜…è¯»æ•´ä¸ªé¡µé¢ï¼Œä½ ä»ç„¶å¯ä»¥ä½¿ç”¨è‡ªç„¶è¯­è¨€å¤„ç†å¯¹é¡µé¢æœ‰æ‰€äº†è§£ã€‚å¸Œæœ›ä½ å–œæ¬¢é˜…è¯»è¿™ä¸ªå®è·µæŒ‡å—ã€‚å¦‚æœä½ ä»Šå¤©å­¦åˆ°äº†æ–°ä¸œè¥¿ï¼Œæˆ‘ä¼šå¾ˆé«˜å…´ã€‚ä»äº‹åƒè¿™æ ·çš„åŠ¨æ‰‹ç¼–ç¨‹é¡¹ç›®æ˜¯æé«˜ç¼–ç æŠ€èƒ½çš„æœ€å¥½æ–¹å¼ã€‚å¦‚æœæ‚¨åœ¨æ‰§è¡Œä»£ç æ—¶æœ‰ä»»ä½•é—®é¢˜ï¼Œè¯·éšæ—¶[è”ç³»æˆ‘](https://sonsuzdesign.blog/)ã€‚

> å…³æ³¨æˆ‘çš„[åšå®¢](https://medium.com/@lifexplorer)å’Œ [youtube](https://www.youtube.com/channel/UCmo4tnTcj92DlzES5hvlWwQ) é¢‘é“ï¼Œä¿æŒçµæ„Ÿã€‚è°¢è°¢ä½ ï¼Œ

[](/building-a-face-recognizer-in-python-7fd6630c6340) [## ç”¨ Python æ„å»ºäººè„¸è¯†åˆ«å™¨

### ä½¿ç”¨ OpenCv åº“è¿›è¡Œå®æ—¶äººè„¸è¯†åˆ«çš„åˆ†æ­¥æŒ‡å—

towardsdatascience.com](/building-a-face-recognizer-in-python-7fd6630c6340) [](/extracting-speech-from-video-using-python-f0ec7e312d38) [## ä½¿ç”¨ Python ä»è§†é¢‘ä¸­æå–è¯­éŸ³

### ä½¿ç”¨ Google è¯­éŸ³è¯†åˆ« API çš„ç®€å•å®ç”¨é¡¹ç›®

towardsdatascience.com](/extracting-speech-from-video-using-python-f0ec7e312d38)