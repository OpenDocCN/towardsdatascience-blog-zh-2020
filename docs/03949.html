<html>
<head>
<title>Easily visualize Scikit-learn models’ decision boundaries</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">轻松可视化Scikit-learn模型的决策界限</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/easily-visualize-scikit-learn-models-decision-boundaries-dd0fb3747508?source=collection_archive---------10-----------------------#2020-04-12">https://towardsdatascience.com/easily-visualize-scikit-learn-models-decision-boundaries-dd0fb3747508?source=collection_archive---------10-----------------------#2020-04-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1fc7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一个简单的效用函数来可视化Scikit-learn机器学习模型/估计器的决策边界。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/924e9e66b9b13d777026e1422f4077cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gBl0ZaBDbYqFPOrhFbkfuw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:<a class="ae ky" href="https://pixabay.com/photos/tennis-sand-sport-space-3524072/" rel="noopener ugc nofollow" target="_blank"> Pixabay(免费授权)</a></p></figure><h1 id="a5f0" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="36ed" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Scikit-learn是一个令人惊叹的Python库，用于工作和试验<a class="ae ky" href="https://scikit-learn.org/stable/modules/classes.html" rel="noopener ugc nofollow" target="_blank">过多的监督和非监督机器学习(ML)算法和相关工具</a>。</p><p id="91d2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">它的构建考虑到了健壮性和<a class="ae ky" href="https://scikit-learn.org/stable/developers/performance.html" rel="noopener ugc nofollow" target="_blank">速度</a>——尽可能多地使用NumPy和<a class="ae ky" href="https://www.scipy.org/" rel="noopener ugc nofollow" target="_blank"> SciPy </a>方法和<a class="ae ky" href="https://scipy-lectures.org/advanced/optimizing/index.html" rel="noopener ugc nofollow" target="_blank">内存优化技术</a>。最重要的是，该库为所有类型的ML估计器提供了一个简单而直观的API(T10)——拟合数据、预测和检查模型参数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/fedd16832dfc8ca83f8719a4334173ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7WoYYon0fsQ7Sd9Vn1iiOA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图像:Scikit-learn估计器图示</p></figure><p id="f915" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">对于监督最大似然领域中的许多分类问题，<strong class="lt iu">我们可能希望超越数值预测(类别或概率)并可视化类别之间的实际决策边界</strong>。当然，这尤其适用于二元分类问题和一对要素，可视化显示在二维(2D)平面上。</p><p id="4e64" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">例如，这是来自Scikit-learn官方文档的支持向量机(SVM)教程的决策边界的可视化。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/9aaf3392c5e2598acef9f46313c7e540.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*38QCgBBOAvkVBHy8NpYjIg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:<a class="ae ky" href="https://scikit-learn.org/stable/modules/svm.html" rel="noopener ugc nofollow" target="_blank"> Scikit-learn SVM </a></p></figure><p id="aebc" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">虽然Scikit-learn没有提供现成的、可访问的方法来实现这种可视化，但在本文中，我们将研究一段简单的Python代码来实现这一点。</p><h1 id="e522" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">一个简单的Python函数</h1><p id="8a67" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><a class="ae ky" href="https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Utilities/ML-Python-utils.py" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">完整代码在我的Python机器学习上的Github Repo这里给出</strong> </a>。当然也欢迎你到<a class="ae ky" href="https://github.com/tirthajyoti/Machine-Learning-with-Python" rel="noopener ugc nofollow" target="_blank">探索整个库</a>寻找其他有用的ML教程。</p><p id="a498" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这里，我们展示了docstring来说明如何使用它，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/825727d419657c4cf0d19590f941a2ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-8SjPHBRM3Ab9EWwRmY9Xg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">实用函数的文档字符串</p></figure><p id="00b5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">您可以将模型类和模型参数(对于每个模型类是特定且唯一的)以及要素和标签数据(作为NumPy数组)传递给函数。</p><p id="1367" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这里的<strong class="lt iu">模型类表示精确的</strong> <a class="ae ky" href="https://scikit-learn.org/stable/developers/develop.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> Scikit-learn估计器类</strong> </a> <strong class="lt iu">，您在</strong>中调用它来实例化您的ML估计器对象。请注意，您不必传递您正在使用的特定ML估计器。只有类名就足够了。<strong class="lt iu">该函数将在内部拟合数据并预测</strong>以创建适当的决策边界(考虑您传递的模型参数)。</p><p id="6b18" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">目前，<strong class="lt iu">函数仅使用前两列数据来拟合</strong>模型，因为我们需要找到网格样式散点图中每个点的预测值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mv"><img src="../Images/8db9a213b0e909cd5f8951e72848fcf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hzkAhcc3AnGXPLeVrkS0mg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">主代码部分</p></figure><h1 id="e00e" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">一些说明性结果</h1><p id="1168" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">代码很无聊，而结果(和情节)很刺激，不是吗？</p><p id="ae0c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了演示，我们使用了离婚分类数据集。这个数据集是关于完成个人信息表和离婚预测量表的参与者。该数据是在<a class="ae ky" href="https://archive.ics.uci.edu/ml/datasets/Divorce+Predictors+data+set" rel="noopener ugc nofollow" target="_blank"> UCI门户</a>上公开的数据的修改版本(在注入一些噪声之后)。有170个参与者和54个属性(或预测变量)都是实值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mw"><img src="../Images/b9e221d2e16fb9ce1f9435a55489be23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xC8t_40MUjimfIxOG1I7zg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://archive.ics.uci.edu/ml/datasets/Divorce+Predictors+data+set" rel="noopener ugc nofollow" target="_blank"> UCI离婚预测数据集</a></p></figure><p id="89eb" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们在同一个数据集上比较了多个最大似然估计的性能，</p><ul class=""><li id="6b2f" class="mx my it lt b lu mn lx mo ma mz me na mi nb mm nc nd ne nf bi translated">朴素贝叶斯</li><li id="dc6d" class="mx my it lt b lu ng lx nh ma ni me nj mi nk mm nc nd ne nf bi translated">逻辑回归</li><li id="309a" class="mx my it lt b lu ng lx nh ma ni me nj mi nk mm nc nd ne nf bi translated">k-最近邻(KNN)</li></ul><p id="2464" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">因为这个特定数据集的二进制类是相当容易分离的，所以所有的ML算法表现几乎一样好。然而，<strong class="lt iu">它们各自的决策边界看起来彼此不同，这就是我们感兴趣的通过这个效用函数</strong>可视化。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/e2cf0c75e1995af25248180c89260025.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RXYGsc9VL1TqqbDf9VfzKw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片:离婚预测数据集的类别可分性</p></figure><h2 id="3b2d" class="nm la it bd lb nn no dn lf np nq dp lj ma nr ns ll me nt nu ln mi nv nw lp nx bi translated">朴素贝叶斯决策边界</h2><p id="f291" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">来自朴素贝叶斯算法的决策边界<strong class="lt iu">是平滑的，并且略微非线性</strong>。而且，只有四行代码！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/bd3371caf169e88e1159cf3a8adf37af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*-0FPQ8ALchk44n60xSCVAw.png"/></div></figure><h2 id="053a" class="nm la it bd lb nn no dn lf np nq dp lj ma nr ns ll me nt nu ln mi nv nw lp nx bi translated">逻辑回归决策边界</h2><p id="408c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">正如预期的那样，来自逻辑回归估计器的决策边界被可视化为线性分隔符。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/a3731a13721bdb8423b3920cfe11e242.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tzRGMpPOTTzLxG9X2UuIzg.png"/></div></div></figure><h2 id="739e" class="nm la it bd lb nn no dn lf np nq dp lj ma nr ns ll me nt nu ln mi nv nw lp nx bi translated">k-最近邻(KNN)决策边界</h2><p id="5199" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">k-最近邻是一种基于特征超平面上数据分布的局部几何(以及它们的相对距离度量)的算法。因此，决策边界表现为<strong class="lt iu">非线性和不平滑的</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/a05d08499deab008f9ce20f93ba5a67a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GUCGpLs16X8BQs-u0Em2gg.png"/></div></div></figure><h2 id="cead" class="nm la it bd lb nn no dn lf np nq dp lj ma nr ns ll me nt nu ln mi nv nw lp nx bi translated">你甚至可以通过神经网络分类器</h2><p id="2cc3" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">该函数适用于任何Scikit-learn估计器，甚至神经网络。这里是Scikit-learn的<code class="fe oa ob oc od b">MLPClassifier</code>估计器的决策边界，它<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html" rel="noopener ugc nofollow" target="_blank">模拟一个密集连接的神经网络</a>(具有用户可配置的参数)。注意，在代码中，我们传递了隐藏层设置、学习率和优化器(<a class="ae ky" rel="noopener" target="_blank" href="/stochastic-gradient-descent-clearly-explained-53d239905d31">随机梯度下降</a>或SGD)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/f6bced33d43f32fe03775afe37be1396.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n192cosznNnVoi1-BWN6bw.png"/></div></div></figure><h2 id="467d" class="nm la it bd lb nn no dn lf np nq dp lj ma nr ns ll me nt nu ln mi nv nw lp nx bi translated">检查模型参数的影响</h2><p id="b5e5" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">如前所述，<strong class="lt iu">我们可以将我们想要的任何模型参数传递给效用函数</strong>。在KNN分类器的情况下，随着我们增加相邻数据点的数量，决策边界变得更加平滑。使用我们的效用函数，可以很容易地看到这一点。注意，在下面的代码中，我们如何在一个循环中将变量<code class="fe oa ob oc od b">k</code>传递给<code class="fe oa ob oc od b">n_neighbors</code>模型参数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/e717c46cb82404e27b8a13b7f21bf5d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AM4-kdsm9BO07ok8c5jaFQ.png"/></div></div></figure><div class="kj kk kl km gt ab cb"><figure class="og kn oh oi oj ok ol paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/42019021a6501b106a25afa66853190d.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/1*9NtVNwLCs2nN2o7Sz8kW3g.png"/></div></figure><figure class="og kn om oi oj ok ol paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/f8141377e6164be1fcc2c6fa5c87a60c.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*jsHnYH8fX_OW63MoxhA4bg.png"/></div></figure><figure class="og kn on oi oj ok ol paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/2f4b09dcbae19652f4d51c59af9b1d27.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*ntP4tVOrQ63F17DWLzfi3Q.png"/></div></figure></div><h1 id="1b0c" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">摘要</h1><p id="c185" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们展示了如何编写一个简单的效用函数来接受任何Scikit-learn ML估计器(具有用户希望传递给模型的任何模型参数),用于二进制分类任务，并使用几行代码可视化正类和负类之间的判定边界。</p><p id="c044" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">该函数可与任何Scikit-learn估计器配合使用，并且可扩展和配置，以便在将来包含更多的类和多绘图功能。</p><p id="7b23" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">再次说明，我在Python机器学习上的Github Repo里这里给出了<a class="ae ky" href="https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Utilities/ML-Python-utils.py" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">完整代码</strong> </a>。将根据需要添加更新。</p></div><div class="ab cl oo op hx oq" role="separator"><span class="or bw bk os ot ou"/><span class="or bw bk os ot ou"/><span class="or bw bk os ot"/></div><div class="im in io ip iq"><p id="b40f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi ov translated"><span class="l ow ox oy bm oz pa pb pc pd di">如果</span>您有任何问题或想法要分享，请联系作者在<a class="ae ky" href="mailto:tirthajyoti@gmail.com" rel="noopener ugc nofollow" target="_blank"><strong class="lt iu">tirthajyoti【AT】Gmail . com</strong></a>。此外，您可以查看作者的<a class="ae ky" href="https://github.com/tirthajyoti?tab=repositories" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> GitHub </strong> </a> <strong class="lt iu">资源库</strong>中的代码、想法和机器学习和数据科学方面的资源。如果你和我一样，对人工智能/机器学习/数据科学充满热情，请随时<a class="ae ky" href="https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/" rel="noopener ugc nofollow" target="_blank">在LinkedIn上添加我</a>或<a class="ae ky" href="https://twitter.com/tirthajyotiS" rel="noopener ugc nofollow" target="_blank">在Twitter上关注我</a>。</p><div class="pe pf gp gr pg ph"><a href="https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/" rel="noopener  ugc nofollow" target="_blank"><div class="pi ab fo"><div class="pj ab pk cl cj pl"><h2 class="bd iu gy z fp pm fr fs pn fu fw is bi translated">Tirthajyoti Sarkar - Sr .首席工程师-半导体、人工智能、机器学习- ON…</h2><div class="po l"><h3 class="bd b gy z fp pm fr fs pn fu fw dk translated">通过写作使数据科学/ML概念易于理解:https://medium.com/@tirthajyoti开源和有趣…</h3></div><div class="pp l"><p class="bd b dl z fp pm fr fs pn fu fw dk translated">www.linkedin.com</p></div></div><div class="pq l"><div class="pr l ps pt pu pq pv ks ph"/></div></div></a></div></div></div>    
</body>
</html>