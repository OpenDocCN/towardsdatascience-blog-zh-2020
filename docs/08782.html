<html>
<head>
<title>Data-Efficient GANs!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据高效的GANs！</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data-efficient-gans-d10acd595361?source=collection_archive---------55-----------------------#2020-06-24">https://towardsdatascience.com/data-efficient-gans-d10acd595361?source=collection_archive---------55-----------------------#2020-06-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="0280" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">看看麻省理工学院最近令人兴奋的<a class="ae kf" href="https://arxiv.org/pdf/2006.10738v1.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>“数据高效GAN训练的差异化增强”</h2></div><p id="724b" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><em class="lc">理解本文</em>的前提:你<strong class="ki ir">训练过GAN </strong>或者你了解<strong class="ki ir"> </strong>训练GAN时出现的常见困难<strong class="ki ir"> </strong>比如<strong class="ki ir">训练数据上的甄别器过拟合</strong>。否则，一定要阅读这篇文章，或者自己花几个小时在谷歌上搜索甘斯。然后回到这里，享受这篇文章！</p></div><div class="ab cl ld le hu lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ij ik il im in"><p id="284e" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">你读过甘斯的书。也许你已经训练了一只。也许你已经<em class="lc">尝试过</em>来训练一个，看着鉴频器损耗一降再降，然后“嘣”的一声，你在训练数据上过度拟合了。你打印出100张图片，其中50张是同样畸形的金毛猎犬图片。你去见你的教授，也许眼里含着泪水，你宣称:</p><p id="107b" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">‘模式崩溃，怎么办？’</p><p id="40a9" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">“增加更多的数据，”你的教授说。或许打个盹。</p><p id="5138" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">不要害怕！麻省理工学院最近的<a class="ae kf" href="https://arxiv.org/pdf/2006.10738v1.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>“数据高效GAN训练的差异化增强”声称是你的救星，或者至少是它的一部分(赵，刘，林，朱&amp;韩，2020)。该论文声称需要更少的数据，同时仍然使用一种称为“可区分”增强的特殊数据增强来实现最先进的结果。在这篇博文中，我会把茶洒在这张纸上(如果你还不知道，我对此非常兴奋)。我来告诉你这篇论文是怎么宣称提高GAN训练的，我来说说实际上有没有效果。所以，拿起一杯茶和一个笔记本，向GAN神祈祷这有助于击败“模式崩溃”的老怪物</p><p id="d3c9" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">甘斯的问题:快速回顾一下</p><p id="c1ff" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">在机器学习中，你将学到的第一个也是最重要的概念之一是“过度适应”。在鉴别器GANs的上下文中，D在训练中继续改进，但是<strong class="ki ir">在验证期间表现很差，因为它已经开始“记忆”图像数据</strong>。这并不一定会导致模式崩溃，在这种情况下，您会得到许多相同的输出图像，尽管这种情况经常发生。如果您观察到模式崩溃，这是一种证据，表明鉴别器对数据过度拟合。通常，我们只是添加更多的数据来防止这个问题——当然，这通常是有帮助的……但是这么多的数据不一定容易收集。这篇论文提供了一个有力的例子:如果我们试图生成一个稀有物种的图像会怎么样？我们无法获得更多的数据。然而，我们不必把自己局限于稀有物种这种极端的边缘情况。即使当我们谈论像衣服这样的常规物品时，<strong class="ki ir">收集数据也是昂贵的。注释数据是昂贵的。需要<em class="lc">年</em>(赵等，2020)。我们希望模型现在<em class="lc">工作</em>。</strong></p><p id="8543" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">解决方案:增强？</strong></p><p id="928c" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">因此，现在我们将得到我们的论文谈到的解决方案。该论文观察到，当在监督学习的情况下出现过拟合时(比如一个简单的图像分类问题)，并且<strong class="ki ir"> </strong>我们没有更多的数据要添加，我们将对数据进行称为<strong class="ki ir">增加</strong> <em class="lc"> </em>的处理。[作为补充说明，请随意阅读其他解决过度拟合问题的方法，如正则化]。</p><p id="8790" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">图像增强是指将图片翻转过来或稍微改变颜色等。等等。我们只是稍微改变一下照片，这样我们可以得到更多的样本。但是对于GANs，这种增强不能直接起作用。作者提供了两种我们可以在GAN训练期间增加数据的方法，以及为什么这两种方法都无法获得良好的输出图像。然后他们提供了第三种选择，这种选择<em class="lc">起作用</em>(微分增强)，这就是他们论文的全部内容。所以这里有两个行不通的选择:</p><p id="a278" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">选项1:仅增加Reals】</strong></p><p id="d4df" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">大家还记得，当我们训练GAN时，我们输入的图像是实际物体的实际图片。我们用它和我们的生成器制造的赝品一起输入到鉴别器中。所以在第一种增强方法中，我们只是增强这些真实的图像。简单吧？</p><p id="73d0" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">不对。</p><p id="36ba" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">赵等人(2020)报告说，增强<em class="lc">随机水平翻转</em>确实适度地改善了结果。但是<strong class="ki ir">更强</strong> <strong class="ki ir">增强</strong>比如翻译&amp;只对真实图像进行剪切会导致生成的图像出现失真和怪异着色等问题。虽然普通增强可能适用于常规分类问题，但对于我们不分类的gan，我们正试图生成数据的<strong class="ki ir">真实分布</strong>。但是，如果我们去扭曲真实的输入数据，那么我们生成的输出也将被类似地扭曲。鼓励发生器匹配增大的&amp;失真分布，而不是真实分布。那么，扩充数据的第二个选择呢？</p><p id="94b7" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">选项2:增加所有鉴别器输入</strong></p><p id="5784" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">在这个选项中，我们不仅增加了实数，还增加了由我们的生成器输出并进入我们的鉴别器的虚数。有趣的是，虽然鉴别器学会了以超过90%的准确度在增强的真实<strong class="ki ir"> </strong>和增强的虚假<strong class="ki ir"> </strong>之间进行完美分类，但鉴别器<strong class="ki ir">未能识别未增强的虚假</strong>，导致准确度低于10%。这是因为<strong class="ki ir">发生器G从非增强伪图像</strong>接收其梯度。因此，我们需要某种方式<strong class="ki ir">将梯度传播到我们的生成器G. </strong>否则，用赵等人(2020)的恐怖诱导的话来说:</p><blockquote class="lk ll lm"><p id="0120" class="kg kh lc ki b kj kk jr kl km kn ju ko ln kq kr ks lo ku kv kw lp ky kz la lb ij bi translated">生成器完全欺骗了鉴别器</p></blockquote><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi lq"><img src="../Images/d31a2f5fa282fc049583074f1ae6bbb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ng1htdubc-2-Lnmk90qA0A.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated"><strong class="bd mg">图一。</strong>甘斯失败的增强方法。来源:<a class="ae kf" href="https://arxiv.org/pdf/2006.10738v1.pdf" rel="noopener ugc nofollow" target="_blank">赵等(2020) </a></p></figure><p id="a453" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">选项3:输入差异化增量</strong></p><p id="773b" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">所以这就是作者提出了一种<em class="lc">做</em>工作的增强类型，即可微分增强。为了解决选项1和选项2的问题，作者提供了一个解决方案。增强了鉴别器网络中使用的真实和虚假图像，而且2。成功地<strong class="ki ir">“将增强样本的梯度传播到g。”</strong>这避免了我们之前在选项2下讨论的无法识别未增强的假货的问题。<strong class="ki ir">这是本文的关键:</strong>为了允许梯度传播到生成元G，他们简单地非常确定增广是，如名字所说，<strong class="ki ir">可微的</strong>。作者提供了这种可区分增加的三个主要例子:</p><blockquote class="lk ll lm"><p id="df5b" class="kg kh lc ki b kj kk jr kl km kn ju ko ln kq kr ks lo ku kv kw lp ky kz la lb ij bi translated">平移(在图像大小的[1/8，1/8]范围内，用零填充)，</p><p id="dab8" class="kg kh lc ki b kj kk jr kl km kn ju ko ln kq kr ks lo ku kv kw lp ky kz la lb ij bi translated">剪切(用图像一半大小的随机正方形进行遮罩)，以及</p><p id="da92" class="kg kh lc ki b kj kk jr kl km kn ju ko ln kq kr ks lo ku kv kw lp ky kz la lb ij bi translated">颜色(包括随机亮度在[0.5，0.5]范围内，对比度在[0.5，1.5]范围内，饱和度在[0，2]范围内)。</p></blockquote><p id="1c72" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">结果</strong></p><p id="998d" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">这有用吗？是的。是的，它似乎起作用了。作者列出了一些非常酷的结果，我将在这里列出其中一些。我强烈建议你看看<a class="ae kf" href="https://arxiv.org/pdf/2006.10738v1.pdf" rel="noopener ugc nofollow" target="_blank">主要论文</a>中的其他结果——它们确实让我大吃一惊。</p><p id="d2de" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><em class="lc">成果#1 </em> : <em class="lc"> CIFAR-10和CIFAR-100数据集。</em>作者使用了两个著名的GAN，即BigGAN和StyleGAN2，并尝试了几种数据集大小(100%数据、10%数据、20%数据)。为了使他们的比较与基线公平，他们甚至确保在基线方法中使用正则化&amp;水平翻转。对于CIFAR-10和CIFAR-100而言，它们都比基线有所改进，是CIFAR-10和CIFAR-100的<strong class="ki ir">最新技术</strong>。</p><p id="6ac6" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><em class="lc">成就#2: </em> <em class="lc"> ImageNet </em>。可区分增强推进了100%数据集和缩减大小数据集的最新水平。</p><p id="94b5" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">我喜欢本文中提出的解决方案的原因是它非常符合逻辑。作者1。尝试了不同的增强方法。确定了确切的困难和3。通过使用特定类型的增强，即在真实和虚假上执行的可区分增强，迅速修复了问题，从而允许梯度传播到生成器。然而，这个逻辑推导出的解决方案做了这么多。现在，任何训练GAN的人都可以将“使用可微分增强”添加到他们的规则工具箱中，如“向鉴别器输入添加噪声”和“惩罚[调整]鉴别器权重”(未注明)。</p><p id="f55a" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">这篇论文真的让我很兴奋，促使我在凌晨1点写了一篇关于它的帖子。我希望我对它的讨论能帮助你理解这个解决方案是如何工作的，并让你兴奋起来！</p><p id="ed0b" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">最后，论文中的一张图清晰地展示了他们的方法:</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi mh"><img src="../Images/578461f3e4fa0ba5f3b29012923a0b60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hU0vlreWSfMs9asy-vGHSw.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated"><strong class="bd mg">图二。</strong>“更新D(左)和G(右)的DiffAugment概述”。DiffAugment将扩充T应用于真实样本x和生成的输出G(z)。当我们更新G时，梯度需要通过T反向传播，这要求T对于输入是可微分的。”图片来源&amp;图片说明:<a class="ae kf" href="https://arxiv.org/pdf/2006.10738v1.pdf" rel="noopener ugc nofollow" target="_blank">赵等(2020) </a>。</p></figure><p id="1fff" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">参考文献</strong></p><p id="8ab1" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">赵树声，刘，张，林俊杰，朱俊英，韩树声(2020)。数据有效的GAN训练的可区分增强。arXiv预印本arXiv:2006.10738 。从https://arxiv.org/pdf/2006.10738v1.pdf<a class="ae kf" href="https://arxiv.org/pdf/2006.10738v1.pdf" rel="noopener ugc nofollow" target="_blank">取回</a></p><p id="9b34" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">生成性对抗网络(未注明)。常见问题。<em class="lc">谷歌开发者</em>。从https://developers.google.com/machine-learning/gan/problems<a class="ae kf" href="https://developers.google.com/machine-learning/gan/problems" rel="noopener ugc nofollow" target="_blank">取回</a></p></div></div>    
</body>
</html>