<html>
<head>
<title>Project: Predicting the Perfect Ratio of Red Wine Ingredients with Regression Machine Learning Algorithms</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">项目:用回归机器学习算法预测红酒成分的完美比例</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/project-maximizing-red-wine-profits-with-regression-machine-learning-algorithms-8caad2a10a08?source=collection_archive---------52-----------------------#2020-06-15">https://towardsdatascience.com/project-maximizing-red-wine-profits-with-regression-machine-learning-algorithms-8caad2a10a08?source=collection_archive---------52-----------------------#2020-06-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/503a7db40117b23aefd8a81f1728d380.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1OtR_lNOUgGazeXu"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><a class="ae kc" href="https://unsplash.com/photos/8_tZ-eu32LA" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><h1 id="6e5b" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">目录</h1><p id="6e87" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="ld ir"> 1。简介:</strong>场景&amp;目标，特性&amp;预测器</p><p id="9f14" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir"> 2。数据争论:</strong>缺失值，用 Z 值检测/处理异常值</p><p id="3053" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir"> 3。探索性数据分析:</strong>相关性、配对图、特征工程、核密度估计(KDE)、回归联合图、条形图、小提琴&amp;盒图</p><p id="37e0" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir"> 4。机器学习+预测分析:</strong>为建模准备数据，建模/训练，<strong class="ld ir"> </strong> R 值，预测，k 重交叉验证‍ ‍ ‍ ‍ ‍ ‍ ‍ ‍ ‍ ‍ ‍ ‍ ‍ ‍ ‍ ‍ ‍ ‍</p><p id="267e" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir"> 5。结论</strong></p></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><h1 id="8532" class="kd ke iq bd kf kg ml ki kj kk mm km kn ko mn kq kr ks mo ku kv kw mp ky kz la bi translated"><strong class="ak"> 1。简介</strong></h1><h1 id="c592" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated"><strong class="ak">场景</strong>:</h1><p id="6abc" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi mq translated">你走进 T21 北部的一家酒吧。你点了伏特加，并对坐在你旁边的人说你是一名数据科学家。酒吧的老板，碰巧是一个葡萄酒商，让你知道他正在雇佣一名数据科学家。他说他正在<strong class="ld ir">失去顾客</strong> &amp;需要<strong class="ld ir">帮助</strong>为他的<strong class="ld ir">红酒系列</strong>想出一个<strong class="ld ir">新配方</strong>。葡萄酒商把这些数据交给你，让你进行<strong class="ld ir">数据分析</strong>和<strong class="ld ir">预测</strong>配料的<strong class="ld ir">完美比例</strong>和<strong class="ld ir">最大化</strong>他的<strong class="ld ir">利润</strong>。</p><h1 id="583d" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">目标:</h1><ul class=""><li id="0287" class="mz na iq ld b le lf li lj lm nb lq nc lu nd ly ne nf ng nh bi translated"><strong class="ld ir">预测</strong>红酒配料的<strong class="ld ir">完美比例</strong>。这是一个<strong class="ld ir">数值连续的结果</strong>。</li><li id="71ab" class="mz na iq ld b le ni li nj lm nk lq nl lu nm ly ne nf ng nh bi translated"><strong class="ld ir">用各种<strong class="ld ir">回归</strong>模型&amp;探索</strong>，看哪个<strong class="ld ir">产生</strong>最大<strong class="ld ir">精度</strong>。</li><li id="391c" class="mz na iq ld b le ni li nj lm nk lq nl lu nm ly ne nf ng nh bi translated">检查我们数据中的<strong class="ld ir">趋势</strong> &amp; <strong class="ld ir">相关性</strong></li><li id="4db8" class="mz na iq ld b le ni li nj lm nk lq nl lu nm ly ne nf ng nh bi translated">确定哪些<strong class="ld ir">特性</strong>对<strong class="ld ir">高</strong>品质<strong class="ld ir">红酒</strong>品质<em class="nn">重要</em></li></ul><p id="f591" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir">注</strong>:由于我们是<strong class="ld ir">预测</strong>一个<strong class="ld ir">数值连续</strong>值，我们将<strong class="ld ir">训练</strong>各种<strong class="ld ir">回归模型。回归分析</strong>是<strong class="ld ir">监督学习的子领域。</strong></p><h1 id="c113" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">特征和预测:</h1><p id="d873" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">我们的<strong class="ld ir">预测器</strong> (Y，葡萄酒质量)由 11 个<strong class="ld ir">特征</strong> (X)决定:</p><p id="f5d6" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">1.<strong class="ld ir">固定酸度</strong>(g/L)——大多数与葡萄酒有关的酸或固定的或不挥发的(不容易挥发)<br/> 2。<strong class="ld ir">挥发性酸度(</strong>g/L)——乙酸的含量(含量过高会导致不愉快的醋味)<br/> 3。<strong class="ld ir">柠檬酸</strong>(摩尔/升)——少量存在的柠檬酸可以增加葡萄酒的“新鲜度”和风味<br/> 4。<strong class="ld ir">残糖</strong>(克/升)——发酵停止后剩余的糖量<br/> 5。<strong class="ld ir">氯化物</strong>(克)—盐量<br/> 6。<strong class="ld ir">游离二氧化硫</strong>(mg/L)——游离形式 SO 存在于分子 SO(溶解气体)和亚硫酸氢根离子<br/> 7 之间的平衡。<strong class="ld ir">总二氧化硫(</strong> mg/L <strong class="ld ir"> ) </strong> —游离态和结合态 SO 的量<br/> 8。<strong class="ld ir">密度(</strong>克/厘米<strong class="ld ir"> ) </strong> —水的密度接近于水的密度，取决于酒精和糖的百分比含量<br/> 9。<strong class="ld ir">pH</strong>——描述葡萄酒的酸性或碱性程度，范围从 0(非常酸性)到 14(非常碱性)；大多数葡萄酒在 3–4<br/>10 之间。<strong class="ld ir">硫酸盐</strong>(g)——可增加二氧化硫气体(SO)水平的添加剂，作为抗菌剂<br/> 11。<strong class="ld ir">酒精</strong>——酒精含量百分比</p><p id="9089" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir">注</strong>:我们的数据只有一种数据:<strong class="ld ir"/><strong class="ld ir">(#)</strong>；这是可以测量的<strong class="ld ir">定量</strong>数据</p><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="30f3" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">import</strong> <strong class="nt ir">numpy</strong> <strong class="nt ir">as</strong> <strong class="nt ir">np</strong><br/><strong class="nt ir">import</strong> <strong class="nt ir">pandas</strong> <strong class="nt ir">as</strong> <strong class="nt ir">pd</strong><br/><strong class="nt ir">import</strong> <strong class="nt ir">matplotlib</strong> <strong class="nt ir">as</strong> <strong class="nt ir">plt</strong><br/><strong class="nt ir">import</strong> <strong class="nt ir">seaborn</strong> <strong class="nt ir">as</strong> <strong class="nt ir">sns</strong><br/><strong class="nt ir">import</strong> <strong class="nt ir">matplotlib.pyplot</strong> <strong class="nt ir">as</strong> <strong class="nt ir">plt</strong></span></pre></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><h1 id="7468" class="kd ke iq bd kf kg ml ki kj kk mm km kn ko mn kq kr ks mo ku kv kw mp ky kz la bi translated">2.数据争论</h1><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="de18" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">filePath = '/Users/jarar_zaidi/Downloads/wineQuality.csv'<br/><br/>data = pd.read_csv(filePath)<br/><br/>data.head()</strong></span></pre><figure class="no np nq nr gt jr"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="no np nq nr gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oe"><img src="../Images/88974fc9fc972ae0300395af5b821597.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fk8EPJD3y8zWmvYnwndNtQ.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">帮助我们了解我们正在处理的数据。</p></figure><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="d3a2" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">print("(Rows, columns): " + str(data.shape))<br/>data.columns</strong></span></pre><figure class="no np nq nr gt jr"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="no np nq nr gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi of"><img src="../Images/610ffbd090bb7724cbbc316039a0f1b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*neUFq4azwuZgTvoDYHi5SA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">显示行数和列数。以及列名</p></figure><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="03e1" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">data.nunique(axis=0) </strong><em class="nn"># returns the number of unique values for each variable.</em></span></pre><figure class="no np nq nr gt jr"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="no np nq nr gt jr gh gi paragraph-image"><div class="gh gi og"><img src="../Images/0e22a3ace471e329a976440f4538c239.png" data-original-src="https://miro.medium.com/v2/resize:fit:984/format:webp/1*d8m1la-wFoZAHhVSyW4c_A.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">返回每个变量的唯一值的数量。</p></figure><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="20d0" class="nx ke iq nt b gy ny nz l oa ob"><em class="nn">#summarizes the count, mean, standard deviation, min, and max for numeric variables.</em><br/><strong class="nt ir">data.describe()</strong></span></pre><figure class="no np nq nr gt jr"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="no np nq nr gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oh"><img src="../Images/bc8cf88c9dde710cc0b89a76ac278431.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*06nbCeU4V2rhtY8-MRGC7g.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">汇总数字变量的计数、平均值、标准差、最小值和最大值。</p></figure><p id="2708" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir">平均质量</strong>为 5.6，其<strong class="ld ir">最大</strong> ( <strong class="ld ir">最佳质量</strong>得分)为 8.0 &amp;其<strong class="ld ir">最小</strong> ( <strong class="ld ir">最差质量</strong>得分)为 3.0。现在，让我们看看是否有任何<strong class="ld ir">缺失值</strong>需要处理。</p></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><h1 id="e2c0" class="kd ke iq bd kf kg ml ki kj kk mm km kn ko mn kq kr ks mo ku kv kw mp ky kz la bi translated">缺少值</h1><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="d50f" class="nx ke iq nt b gy ny nz l oa ob"><em class="nn"># Display the Missing Values</em><br/><br/><strong class="nt ir">print(data.isna().sum())</strong></span></pre><figure class="no np nq nr gt jr"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="no np nq nr gt jr gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/bc322433b025562ddfcb4ed1ddb269e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*6JSQYRENLpVo7Y-7bBOs1Q.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">显示每列缺失值的数量。幸运的是我们没有。</p></figure></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><h1 id="d1df" class="kd ke iq bd kf kg ml ki kj kk mm km kn ko mn kq kr ks mo ku kv kw mp ky kz la bi translated">使用 Z 分数检测/处理异常值</h1><blockquote class="oj ok ol"><p id="17b2" class="lb lc nn ld b le lz lg lh li ma lk ll om mb lo lp on mc ls lt oo md lw lx ly ij bi translated">一个<strong class="ld ir"> Z 值</strong>是对<strong class="ld ir">位置</strong>的测量，它表示一个数据值偏离<strong class="ld ir">平均值</strong>的<strong class="ld ir">标准偏差</strong>的数量。任何 z 分数<strong class="ld ir">小于<strong class="ld ir"> -3 </strong>或<strong class="ld ir">大于<strong class="ld ir"> 3 </strong>，都是<strong class="ld ir">异常值</strong>。</strong></strong></p></blockquote><p id="184b" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir">注</strong>:从<strong class="ld ir">经验法则</strong>我们看到我们数据的<strong class="ld ir"> 99.7% </strong>应该在<strong class="ld ir">均值<strong class="ld ir">与</strong>的 3 个标准差</strong>以内。</p><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="c09e" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">from scipy import stats<br/>import numpy as np<br/>z = np.abs(stats.zscore(data))<br/>print(z)</strong></span></pre><figure class="no np nq nr gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi op"><img src="../Images/9fa59170881c4589d53b021483279238.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jNy3mhLpn9w-nqAwX8MYwg.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">获取 Z 分数</p></figure><p id="cda0" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">接下来，我们想要获取 Z 值大于 3 的行和列。这些被认为是<strong class="ld ir">异常值。</strong></p><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="367e" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">threshold = 3<br/>print(np.where(z &gt; 3))</strong></span></pre><figure class="no np nq nr gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oq"><img src="../Images/4f0f50f1edfba408bb740af10a753d88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zr3mJP_BKtDpudeBcx-0Kg.png"/></div></div></figure><p id="922c" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">第一个<strong class="ld ir">数组</strong>是<strong class="ld ir">行</strong>号&amp;的列表<strong class="ld ir">第二个数组</strong>是<strong class="ld ir">异常值</strong>对应的<strong class="ld ir">列</strong>号。例如，第一个异常值在第 13 行第 9 列。一旦我们<strong class="ld ir">计算出</strong>Z 值<strong class="ld ir"> Z 值</strong>，我们就可以<strong class="ld ir">移除</strong>离群值<strong class="ld ir">来</strong>清理我们的数据，方法是执行下面的操作。</p><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="6f3a" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">Newdata = data[(z &lt; 3).all(axis=1)]<br/>Newdata</strong></span></pre><figure class="no np nq nr gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi or"><img src="../Images/d13d927ef9fcd42f1534f385ae6592ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BJXL9lOEWCtO0LK2vonkXQ.png"/></div></div></figure><p id="a3bd" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">我们现在已经<strong class="ld ir">成功地</strong> <strong class="ld ir">移除了</strong> <strong class="ld ir"> 148+ </strong>行，这些行是<strong class="ld ir">异常值</strong>！</p><blockquote class="oj ok ol"><p id="6be9" class="lb lc nn ld b le lz lg lh li ma lk ll om mb lo lp on mc ls lt oo md lw lx ly ij bi translated"><strong class="ld ir">注意</strong>:其他<strong class="ld ir">异常值</strong>指标也可以使用，如<strong class="ld ir"> IQR </strong> <strong class="ld ir">得分</strong>、<strong class="ld ir">散点图</strong>、<strong class="ld ir">箱线图</strong>。</p></blockquote><p id="c271" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">让我们看看我们的<strong class="ld ir">新清理的</strong>数据。</p><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="a75b" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">Newdata.describe()</strong></span></pre><figure class="no np nq nr gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi os"><img src="../Images/be072f7a69d42eafec0d52d17dab48b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8rOCI3ioU7H7Cc775ZmGEQ.png"/></div></div></figure></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><h1 id="940e" class="kd ke iq bd kf kg ml ki kj kk mm km kn ko mn kq kr ks mo ku kv kw mp ky kz la bi translated">3.探索性数据分析</h1><h1 id="319e" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">相关</h1><p id="7863" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="ld ir">相关矩阵</strong>又名<strong class="ld ir">热图</strong> -让你看到所有变量之间的<strong class="ld ir">相关性</strong>。</p><blockquote class="oj ok ol"><p id="1751" class="lb lc nn ld b le lz lg lh li ma lk ll om mb lo lp on mc ls lt oo md lw lx ly ij bi translated">在<strong class="ld ir">秒</strong>内，你可以看到某件事是<strong class="ld ir">正</strong>还是<strong class="ld ir">负</strong> <strong class="ld ir">与我们的<strong class="ld ir">预测器(目标)相关。</strong></strong></p></blockquote><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="df59" class="nx ke iq nt b gy ny nz l oa ob"><em class="nn"># calculate correlation matrix</em><br/><br/><strong class="nt ir">corr = Newdata.corr()<br/>plt.subplots(figsize=(15,10))<br/>sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, annot=True, cmap=sns.diverging_palette(220, 20, as_cmap=True))<br/>sns.heatmap(corr, xticklabels=corr.columns,<br/>            yticklabels=corr.columns, <br/>            annot=True,<br/>            cmap=sns.diverging_palette(220, 20, as_cmap=True))</strong></span></pre><figure class="no np nq nr gt jr"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="no np nq nr gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ot"><img src="../Images/89c0244edfdb4585ffb8e08941841eea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VRqFh8Iw6M9kvRr-O4A9kg.png"/></div></div></figure><p id="25c8" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">我们可以看到在<strong class="ld ir">酒精</strong>T105】我们的<strong class="ld ir">预测因子</strong>之间有一个<strong class="ld ir">强</strong> <strong class="ld ir">正</strong> <strong class="ld ir">相关</strong>。事实上，这是我们数据集中<strong class="ld ir">最相关的特征</strong>，其值为<strong class="ld ir"> 0.5 </strong>！</p><blockquote class="ou"><p id="70ef" class="ov ow iq bd ox oy oz pa pb pc pd ly dk translated"><strong class="ak">注意:</strong>我们的<strong class="ak">酒精</strong>特征是饮料中的<strong class="ak">酒精含量百分比</strong>。对于购买红酒的顾客来说，酒精含量的百分比<strong class="ak">越高</strong>就会产生越大的满意度<strong class="ak"/>！</p></blockquote><p id="4947" class="pw-post-body-paragraph lb lc iq ld b le pe lg lh li pf lk ll lm pg lo lp lq ph ls lt lu pi lw lx ly ij bi translated">接下来，我们可以看到<strong class="ld ir">第二</strong> <strong class="ld ir">最强的正相关</strong>，<strong class="ld ir"> 0.39 </strong>，<strong class="ld ir">硫酸盐</strong> &amp;我们的质量<strong class="ld ir">预测值</strong>。似乎当饮料中添加了添加剂时，人们对质量的评价会更高。<strong class="ld ir">硫酸盐</strong> <strong class="ld ir">充当</strong>的<strong class="ld ir">抗菌剂</strong>。</p><p id="70b1" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">最后，<strong class="ld ir">负相关性最强的</strong>是<strong class="ld ir">挥发酸度</strong>，相关性为<strong class="ld ir"> -0.35 </strong>！这是意料之中的，因为过高的醋酸含量会导致令人不愉快的 T42 醋味道！</p></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><h1 id="283e" class="kd ke iq bd kf kg ml ki kj kk mm km kn ko mn kq kr ks mo ku kv kw mp ky kz la bi translated">配对图</h1><blockquote class="oj ok ol"><p id="cd28" class="lb lc nn ld b le lz lg lh li ma lk ll om mb lo lp on mc ls lt oo md lw lx ly ij bi translated"><strong class="ld ir">成对图</strong>也是一种很好的方式，可以让<strong class="ld ir">立即</strong>看到所有<strong class="ld ir">变量</strong>之间的<strong class="ld ir">相关性</strong>。</p></blockquote><p id="db0e" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">因为我们有<strong class="ld ir"> 11 特征</strong>，所以让我们只选择<strong class="ld ir">将</strong>关联到我们的<strong class="ld ir">预测</strong>的<strong class="ld ir">显著</strong>特征，以进一步<strong class="ld ir">检查</strong>它们在配对图上的相关性</p><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="ec5a" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">subData = data[['volatile acidity','citric acid','sulphates','alcohol']]<br/>sns.pairplot(subData)</strong></span></pre><figure class="no np nq nr gt jr"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="no np nq nr gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pj"><img src="../Images/ee5f3bbb9cc9d574a16c007886e61372.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ors-lM319rA7-1XXw2xPvA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">该图<strong class="bd pk">支持</strong>热图中所述的<strong class="bd pk">相关性</strong>。</p></figure><blockquote class="oj ok ol"><p id="dd21" class="lb lc nn ld b le lz lg lh li ma lk ll om mb lo lp on mc ls lt oo md lw lx ly ij bi translated"><strong class="ld ir">注</strong>:选择制作一个<strong class="ld ir">较小的配对图</strong>，其中只有<strong class="ld ir">最强的预测值</strong>，以便<strong class="ld ir">深入</strong>到<strong class="ld ir">关系</strong>中。这也是一个很好的方法来看看他们的关系是<strong class="ld ir">正</strong>还是<strong class="ld ir">负</strong> <strong class="ld ir">相关</strong>！</p></blockquote></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><h1 id="6938" class="kd ke iq bd kf kg ml ki kj kk mm km kn ko mn kq kr ks mo ku kv kw mp ky kz la bi translated"><strong class="ak">特征工程</strong></h1><p id="6676" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">我们现在将进行<strong class="ld ir">特征工程</strong>的一种形式，其中我们<strong class="ld ir">创建<strong class="ld ir">一个新的</strong> <strong class="ld ir">列</strong> <strong class="ld ir">根据其<strong class="ld ir">质量分数</strong>对</strong>进行分类！</strong></p><blockquote class="ou"><p id="dc90" class="ov ow iq bd ox oy oz pa pb pc pd ly dk translated">这个新列将是一个<strong class="ak">二进制分类数据</strong>，其中<strong class="ak"> 0 </strong>或<strong class="ak"> 1 </strong>表示该葡萄酒是否被认为是“<strong class="ak">美味的</strong>”。</p></blockquote><pre class="pl pm pn po pp ns nt nu nv aw nw bi"><span id="304a" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">Newdata['tasty'] = [0 if x &lt; 6 else 1 for x in Newdata['quality']]</strong></span></pre><figure class="no np nq nr gt jr"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="no np nq nr gt jr gh gi paragraph-image"><div class="gh gi pq"><img src="../Images/a27c06ad1c7a2c761d26a0dde300a55c.png" data-original-src="https://miro.medium.com/v2/resize:fit:176/format:webp/1*QNAN5j6L_fNUwrkOaoHtig.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">我们现在有一个<strong class="bd pk">新列</strong>带有<strong class="bd pk">0</strong>1<strong class="bd pk">1</strong>s。</p></figure></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><h1 id="7292" class="kd ke iq bd kf kg ml ki kj kk mm km kn ko mn kq kr ks mo ku kv kw mp ky kz la bi translated">核密度估计(KDE)</h1><blockquote class="oj ok ol"><p id="bd6e" class="lb lc nn ld b le lz lg lh li ma lk ll om mb lo lp on mc ls lt oo md lw lx ly ij bi translated">一个<strong class="ld ir">核密度估计(KDE) </strong>估计一个<strong class="ld ir">连续随机变量</strong>的<strong class="ld ir">概率密度函数(PDF) </strong></p></blockquote><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="dac3" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">g = sns.jointplot("quality", "volatile acidity", data=Newdata,<br/>           kind="kde", space=0, color="red")</strong></span></pre><figure class="no np nq nr gt jr"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="no np nq nr gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pr"><img src="../Images/af254d3f7f2735a45c300113e940a169.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qdrX2h9jznGkRLcolYkcqg.png"/></div></div></figure><p id="a436" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">一个<strong class="ld ir">内核密度估计</strong>允许我们<strong class="ld ir">可视化</strong>数据在<strong class="ld ir">连续区间</strong>上的<strong class="ld ir">分布</strong>。从这个图中，我们可以<strong class="ld ir">得出</strong>结论:质量<strong class="ld ir">较低的</strong>红酒是<strong class="ld ir">严重倾向于</strong>到<strong class="ld ir">挥发酸度<strong class="ld ir">水平较高的</strong>。这正如我们<strong class="ld ir">所料</strong>因为，<strong class="ld ir">大量<strong class="ld ir">醋酸</strong>产生<strong class="ld ir">难闻的</strong>醋味！</strong></strong></p></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><h1 id="3cc2" class="kd ke iq bd kf kg ml ki kj kk mm km kn ko mn kq kr ks mo ku kv kw mp ky kz la bi translated">回归联合图</h1><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="5165" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">g = sns.jointplot(x= 'fixed acidity',y= 'pH', data=Newdata,<br/>             kind = 'reg',height=15,color='blue')<br/><br/>plt.xlabel('Fixed acidity',size=30)<br/>plt.ylabel('pH',size=40)<br/>plt.title('Fixed acidity vs. pH',size=30)</strong></span></pre><figure class="no np nq nr gt jr"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="no np nq nr gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ca"><img src="../Images/196550667e6f6d53b5c3fc6ebb76570b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_V8019td1zMmsrVTAkE-5Q.png"/></div></div></figure><p id="196f" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">从上面解释的回归联合图中，我们可以看到<strong class="ld ir"> pH </strong>水平&amp;固定酸度之间存在<strong class="ld ir">强负相关</strong>。换句话说，当其中一个增加时，另一个减少。根据<strong class="ld ir">热图</strong>，这两个特性有一个<strong class="ld ir">相关性</strong>系数<strong class="ld ir"> -0.71 </strong>！</p></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><h1 id="afd1" class="kd ke iq bd kf kg ml ki kj kk mm km kn ko mn kq kr ks mo ku kv kw mp ky kz la bi translated">条形图</h1><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="36c4" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">sns.catplot(x="quality", y="volatile acidity", hue="tasty", kind="bar", data=Newdata);<br/><br/>plt.title('Tasty &amp; Non-Tasty Wine with Volatile Acidity Level',size=19)<br/>plt.xlabel('Wine Quality',size=16)<br/>plt.ylabel('Volatile Acidity Level',size=16)</strong></span></pre><figure class="no np nq nr gt jr"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="no np nq nr gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ps"><img src="../Images/003a3452b40cf7658ba12001a2c5902a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f5UreJKzfWCfdONBQsgMXA.png"/></div></div></figure><p id="f417" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">这幅图说明了<strong class="ld ir">高挥发性酸度</strong>水平<strong class="ld ir">产生</strong>一款<strong class="ld ir">糟糕的</strong>品酒。这正如我们所料，因为<strong class="ld ir">大</strong> <strong class="ld ir">量</strong>的<strong class="ld ir">醋酸</strong>产生一种<strong class="ld ir">难闻的</strong>醋味！</p></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><h1 id="d0a8" class="kd ke iq bd kf kg ml ki kj kk mm km kn ko mn kq kr ks mo ku kv kw mp ky kz la bi translated">小提琴和盒子图</h1><blockquote class="oj ok ol"><p id="cae7" class="lb lc nn ld b le lz lg lh li ma lk ll om mb lo lp on mc ls lt oo md lw lx ly ij bi translated">显示<strong class="ld ir">框&amp;小提琴</strong>图的<strong class="ld ir">优点</strong>在于它显示了<strong class="ld ir">基本</strong>数据的<strong class="ld ir">统计</strong>，以及其<strong class="ld ir"> <em class="iq">分布</em> </strong>。这些图通常用于比较给定变量在某些类别中的分布。</p></blockquote><p id="936c" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">显示的是<strong class="ld ir">中位</strong>、<strong class="ld ir"> IQR </strong>、&amp;图基的栅栏。(最小值、第一个四分位数(Q1)、中值、第三个四分位数(Q3)和最大值)。此外，它可以为我们提供数据中的异常值。</p><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="b27d" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">plt.figure(figsize=(12,8))<br/>sns.boxplot(x="quality", y="sulphates", hue="tasty", data=Newdata )<br/>plt.title("Tasty &amp; Non-Tasty Wine with Sulphate Level", fontsize=20)<br/>plt.xlabel("Wine Quality Level",fontsize=16)<br/>plt.ylabel("Sulphate Level", fontsize=16)</strong></span></pre><figure class="no np nq nr gt jr"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="no np nq nr gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pt"><img src="../Images/d087c1ff52fa7e6577a5f017e6c7f39b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9SpwxsGCejHA3S-kaNYxfw.png"/></div></div></figure><p id="eb5e" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">接下来，我们检查这个<strong class="ld ir">方框图</strong>，这有助于<strong class="ld ir">进一步得出</strong>结论，即<strong class="ld ir">好喝的</strong>红酒显示出<strong class="ld ir">硫酸盐<strong class="ld ir">水平</strong>的中位数<strong class="ld ir">升高。</strong></strong></p><blockquote class="ou"><p id="920d" class="ov ow iq bd ox oy oz pa pb pc pd ly dk translated">如果我们回想一下我们的化学课，我们记得硫酸盐是一种添加剂，可以增加二氧化硫气体(SO)的水平，这是一种抗菌剂！</p></blockquote><blockquote class="oj ok ol"><p id="ed56" class="lb lc nn ld b le pe lg lh li pf lk ll om pg lo lp on ph ls lt oo pi lw lx ly ij bi translated"><strong class="ld ir">注</strong>:一种<strong class="ld ir">抗菌剂</strong>是一种<strong class="ld ir">杀死微生物</strong> &amp; <strong class="ld ir">阻止其<strong class="ld ir">生长<em class="iq"> h </em> </strong> <em class="iq">的药剂。</em></strong></p></blockquote><p id="80cc" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">我们现在明白了为什么这些高硫酸盐含量会增强顾客的偏好！</p><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="1479" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">plt.figure(figsize=(12,8))<br/>sns.violinplot(x="quality", y="alcohol", hue="tasty", inner='quartile',data= Newdata )<br/>plt.title("Tasty &amp; Non-Tasty Wine with Percent alcohol content",fontsize=20)<br/>plt.xlabel("Wine Quality Level", fontsize=16)<br/>plt.ylabel("Percent alcohol content ", fontsize=16)</strong></span></pre><figure class="no np nq nr gt jr"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="no np nq nr gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pu"><img src="../Images/9b6e9992257ff75fa60a9a31c86835cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GXXzOMpJNIIz_GwAevS_Ug.png"/></div></div></figure><p id="260d" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">分析完这个<strong class="ld ir">小提琴剧情</strong>我们可以<strong class="ld ir">得出</strong>好酒&amp;不好酒<strong class="ld ir">的整体形态&amp; <strong class="ld ir">分布</strong>差异巨大</strong>。<strong class="ld ir">好喝的</strong>红酒显示出一个<strong class="ld ir">剩余中值</strong>为百分比<strong class="ld ir">酒精</strong>含量&amp;因此<strong class="ld ir">他们的数据的一个</strong>大分布在 10 &amp; 13 之间，而<strong class="ld ir">不好喝的</strong>红酒由一个<strong class="ld ir">低中值</strong>酒精含量在 9.5 &amp; 11 之间。</p></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><p id="4612" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi mq translated"><span class="l mr ms mt bm mu mv mw mx my di"> L </span> et 的<strong class="ld ir">比较</strong>好喝&amp;不好喝红酒之间的<strong class="ld ir">平均值</strong></p><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="7e9a" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">yummy = Newdata[Newdata['tasty']==1]<br/>yummy.describe()</strong></span></pre><figure class="no np nq nr gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pv"><img src="../Images/623bbba46ff83b5207084fd1c7950548.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EAs7PAwBZiHN9d6RFXBdAQ.png"/></div></div></figure><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="9b1c" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">notYummy = Newdata[Newdata['tasty']==0]<br/>notYummy.describe()</strong></span></pre><figure class="no np nq nr gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pw"><img src="../Images/fb4720b60aed70fd51920322c1166387.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xs2jj6RciXCUo6nYUujJKg.png"/></div></div></figure><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="c5ed" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">print("(Tasty Wine Sulphates level): " + str(yummy['sulphates'].mean()))<br/>print("(Non-Tasty Wine Sulphates level): " + str(notYummy['sulphates'].mean()))</strong></span></pre><figure class="no np nq nr gt jr gh gi paragraph-image"><div class="gh gi px"><img src="../Images/e219336541f30e19fb2e4a6b7e25ae9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/1*KG37EEUsjIeADZG9TI6CEw.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><strong class="bd pk">更美味的</strong>葡萄酒表现出<strong class="bd pk">更高的</strong>硫酸盐<strong class="bd pk">水平</strong></p></figure><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="a9a6" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">print("(Tasty Wine Alcohol content level): " + str(yummy['alcohol'].mean()))<br/>print("(Non-Tasty Wine Alcohol content level): " + str(notYummy['alcohol'].mean()))</strong></span></pre><figure class="no np nq nr gt jr gh gi paragraph-image"><div class="gh gi py"><img src="../Images/7186a9061c9a80f448c80606d84d7866.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*LarWc4_bt4qW8ZmQIEj9KQ.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><strong class="bd pk">更好喝的</strong>葡萄酒表现出<strong class="bd pk">更高的</strong>酒精含量<strong class="bd pk">水平</strong></p></figure><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="c685" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">print("(Tasty Wine Total Sulfur Dioxide level): " + str(yummy['total sulfur dioxide'].mean()))<br/>print("(Non-Tasty Wine Total Sulfur Dioxide level): " + str(notYummy['total sulfur dioxide'].mean()))</strong></span></pre><figure class="no np nq nr gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pz"><img src="../Images/ac78fb7d787d59475a25d1fd52b08ca2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JaarHF9GIQgM5YPraulm9Q.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><strong class="bd pk">更好喝的</strong>葡萄酒展示了<strong class="bd pk">更低的</strong>二氧化硫<strong class="bd pk">水平</strong></p></figure><p id="7169" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi mq translated"><span class="l mr ms mt bm mu mv mw mx my di"> L </span>很快，好喝&amp;与不好喝<strong class="ld ir">之间的<strong class="ld ir">平均值</strong>相差极大</strong><strong class="ld ir"/>。例如，美味的红葡萄酒包含总量<strong class="ld ir">二氧化硫</strong>的<strong class="ld ir">最小化</strong>水平。此外，美味的红葡萄酒含有的硫酸<strong class="ld ir"/>&amp;<strong class="ld ir">酒精</strong>水平要高出很多<strong class="ld ir"/>。</p><blockquote class="oj ok ol"><p id="0844" class="lb lc nn ld b le lz lg lh li ma lk ll om mb lo lp on mc ls lt oo md lw lx ly ij bi translated">如果我告诉葡萄酒商每种成分的完美比例能让<strong class="ld ir">最大化</strong>他的红酒<strong class="ld ir">销量</strong>，我会告诉他包括低<strong class="ld ir">水平的<strong class="ld ir">二氧化硫</strong>和高<strong class="ld ir">水平的 T11 硫酸盐<strong class="ld ir"/><strong class="ld ir"><strong class="ld ir">酒精 T15。</strong></strong></strong></strong></p></blockquote></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><h1 id="3082" class="kd ke iq bd kf kg ml ki kj kk mm km kn ko mn kq kr ks mo ku kv kw mp ky kz la bi translated">4.机器学习+预测分析</h1><h1 id="adeb" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">为建模准备数据</h1><p id="c275" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">为建模准备数据，只需记住<strong class="ld ir"> ASN </strong> ( <strong class="ld ir">赋值、拆分、规格化</strong>)。</p><p id="84e3" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi mq translated"><span class="l mr ms mt bm mu mv mw mx my di">A</span>T22 将 11 个特征赋值给 X，&amp;最后一列给我们的预测值，y</p><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="f4f8" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">X = df.iloc[:, :-1].values<br/>y = df.iloc[:, -1].values</strong></span></pre><p id="30d0" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi mq translated"><span class="l mr ms mt bm mu mv mw mx my di">S</span>S<strong class="ld ir">plit</strong>:数据集分为训练集和测试集</p><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="0d30" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">from sklearn.model_selection import train_test_split<br/>x_train, x_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 1)</strong></span></pre><p id="a259" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi mq translated"><span class="l mr ms mt bm mu mv mw mx my di"> N </span> <strong class="ld ir">标准化</strong>:标准化数据将转换数据，使其分布的平均值为 0，标准差为 1。</p><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="0b77" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">from sklearn.preprocessing import StandardScaler<br/>sc = StandardScaler()<br/>x_train = sc.fit_transform(x_train)<br/>x_test = sc.transform(x_test)</strong></span></pre></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><h1 id="ed1c" class="kd ke iq bd kf kg ml ki kj kk mm km kn ko mn kq kr ks mo ku kv kw mp ky kz la bi translated">建模/培训</h1><p id="1b3e" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">现在，我们将在训练集&amp;上训练各种<strong class="ld ir">回归模型</strong>，看看哪个<strong class="ld ir">产生最高的精确度</strong>。我们将<em class="nn">比较</em>的准确性<strong class="ld ir"> <em class="nn">多元线性回归</em> </strong> <em class="nn">，</em> <strong class="ld ir"> <em class="nn">多项式线性回归</em> </strong> <em class="nn">，</em> <strong class="ld ir"> <em class="nn"> SVR(支持向量回归)</em> </strong> <em class="nn">，</em> <strong class="ld ir"> <em class="nn">决策树回归</em> </strong> <em class="nn">，</em> <strong class="ld ir"> <em class="nn">随机森林这些都是<strong class="ld ir">监督学习</strong>模型，用于预测连续值。</em></strong></p><blockquote class="oj ok ol"><p id="7529" class="lb lc nn ld b le lz lg lh li ma lk ll om mb lo lp on mc ls lt oo md lw lx ly ij bi translated"><strong class="ld ir">注</strong>:对于<strong class="ld ir">回归</strong>模型，有几个<strong class="ld ir">度量</strong>用于测量<strong class="ld ir">精度</strong>，如<strong class="ld ir">均方根误差(RMSE) </strong>、<strong class="ld ir">残差标准差(RSE) </strong>、<strong class="ld ir">平均绝对误差(MAE) </strong>。但是我们将用<strong class="ld ir"> R . </strong>来测量我们的模型</p></blockquote><p id="d9f4" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir">模型 1:多元线性回归</strong></p><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="9403" class="nx ke iq nt b gy ny nz l oa ob"><em class="nn"># Train model on whole dataset</em><br/><strong class="nt ir">from</strong> <strong class="nt ir">sklearn.linear_model</strong> <strong class="nt ir">import</strong> <strong class="nt ir">LinearRegression<br/>regressor = LinearRegression()<br/>regressor.fit(x_train,y_train)</strong><br/><br/><em class="nn">#Predicting Test Set Results</em><br/><strong class="nt ir">y_pred = regressor.predict(x_test)<br/></strong><br/><em class="nn"># Evaluating Model Performance</em><br/><strong class="nt ir">from</strong> <strong class="nt ir">sklearn.metrics</strong> <strong class="nt ir">import</strong> <strong class="nt ir">r2_score<br/>r2_score(y_test,y_pred)</strong></span></pre><figure class="no np nq nr gt jr"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="no np nq nr gt jr gh gi paragraph-image"><div class="gh gi qa"><img src="../Images/d6585bc39534843a9538c351f7cf022c.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*iTtE8se7H_JomD5uwe7ZGQ.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><strong class="bd pk">准确率 75% </strong></p></figure><p id="d3b0" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir">模型 2:多项式线性回归</strong></p><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="2441" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">from sklearn.model_selection import train_test_split x_train2, x_test2, y_train2, y_test2 = train_test_split(X2,y2,test_size = 0.2, random_state = 1)</strong></span><span id="f9a5" class="nx ke iq nt b gy qb nz l oa ob"><strong class="nt ir">from sklearn.preprocessing import PolynomialFeatures from sklearn.linear_model import LinearRegression poly_reg = PolynomialFeatures(degree = 4) x_poly = poly_reg.fit_transform(x_train2) lin_reg_2 = LinearRegression() lin_reg_2.fit(x_poly,y)</strong></span><span id="2873" class="nx ke iq nt b gy qb nz l oa ob"><strong class="nt ir">y_pred2 = lin_reg_2.predict(poly_reg.transform(x_test2))</strong></span><span id="d1c2" class="nx ke iq nt b gy qb nz l oa ob"><strong class="nt ir">from sklearn.metrics import r2_score r2_score(y_test2,y_pred2)</strong></span></pre><figure class="no np nq nr gt jr"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="no np nq nr gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi qc"><img src="../Images/ea19a193b4739d167d60948350777815.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*8i3eTrlENt2XDouP_OP5-g.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><strong class="bd pk">准确率 80% </strong></p></figure><p id="6c25" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir">模型 3: SVR(支持向量回归)</strong></p><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="d13c" class="nx ke iq nt b gy ny nz l oa ob"><em class="nn">#assign</em><br/><strong class="nt ir">X3 = df.iloc[:, :-1].values<br/>y3 = df.iloc[:, -1].values</strong><br/><br/><em class="nn">#split</em><br/><strong class="nt ir">from</strong> <strong class="nt ir">sklearn.model_selection</strong> <strong class="nt ir">import</strong> <strong class="nt ir">train_test_split<br/>x_train3, x_test3, y_train3, y_test3 = train_test_split(X3,y3,test_size = 0.2, random_state = 1)</strong><br/><br/><strong class="nt ir">from</strong> <strong class="nt ir">sklearn.svm</strong> <strong class="nt ir">import SVR<br/>regressor3 = SVR(kernel='rbf')<br/>regressor3.fit(x_train3,y_train3)</strong> <em class="nn"># replace by x_train , y_train if we split</em><br/><br/><strong class="nt ir">regressor3.predict(x_test3)<br/><br/>from sklearn.metrics import r2_score<br/>r2_score(y_test3,y_pred3)</strong></span></pre><figure class="no np nq nr gt jr"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="no np nq nr gt jr gh gi paragraph-image"><div class="gh gi qd"><img src="../Images/92c55c6b80216fcf1912eb816f2cd543.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/1*i_Gk_yJk7Nxcxx-IKOe_PQ.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><strong class="bd pk">准确率 74% </strong></p></figure><p id="e5ec" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir">模型 4:决策树回归</strong></p><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="6244" class="nx ke iq nt b gy ny nz l oa ob"><em class="nn"># Assign</em><br/><strong class="nt ir">X4 = df.iloc[:, :-1].values<br/>y4 = df.iloc[:, -1].values</strong><br/><br/><em class="nn"># Split</em><br/><strong class="nt ir">from</strong> <strong class="nt ir">sklearn.model_selection</strong> <strong class="nt ir">import</strong> <strong class="nt ir">train_test_split<br/>x_train4, x_test4, y_train4, y_test4 = train_test_split(X4,y4,test_size = 0.2, random_state = 4)</strong><br/><br/><br/><strong class="nt ir">from</strong> <strong class="nt ir">sklearn.tree</strong> <strong class="nt ir">import</strong> <strong class="nt ir">DecisionTreeRegressor<br/>regressor4 = DecisionTreeRegressor(random_state = 0)<br/>regressor4.fit(x_train4,y_train4)</strong> <em class="nn"># replace by x_train , y_train if we split</em><br/><br/><strong class="nt ir">y_pred4 = regressor4.predict(x_test4)<br/></strong><br/><strong class="nt ir">from</strong> <strong class="nt ir">sklearn.metrics</strong> <strong class="nt ir">import</strong> <strong class="nt ir">r2_score<br/>r2_score(y_test4,y_pred4)</strong></span></pre><figure class="no np nq nr gt jr"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="no np nq nr gt jr gh gi paragraph-image"><div class="gh gi qe"><img src="../Images/3bb0ccf00dea3c193e92eeab50ac9f63.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*iiK2NrkH12iBMPOTgiPVtw.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><strong class="bd pk">准确率 74% </strong></p></figure><p id="c096" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir">模型 5:随机森林回归</strong>🏆</p><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="ddd0" class="nx ke iq nt b gy ny nz l oa ob"><em class="nn"># Assign</em><br/><strong class="nt ir">X5 = df.iloc[:, :-1].values<br/>y5 = df.iloc[:, -1].values</strong><br/><br/><em class="nn"># Split</em><br/><strong class="nt ir">from</strong> <strong class="nt ir">sklearn.model_selection</strong> <strong class="nt ir">import</strong> <strong class="nt ir">train_test_split<br/>x_train5, x_test5, y_train5, y_test5 = train_test_split(X5,y5,test_size = 0.2, random_state = 6)<br/></strong><br/><br/><strong class="nt ir">from</strong> <strong class="nt ir">sklearn.ensemble</strong> <strong class="nt ir">import RandomForestRegressor<br/>regressor5 = RandomForestRegressor(n_estimators = 10, random_state=0)<br/>regressor5.fit(x_train5,y_train5)</strong> <em class="nn"># replace by x_train , y_train if we split</em><br/><br/><strong class="nt ir">y_pred5= regressor5.predict(x_test5)</strong><br/><br/><strong class="nt ir">from</strong> <strong class="nt ir">sklearn.metrics</strong> <strong class="nt ir">import r2_score<br/>r2_score(y_test5,y_pred5)</strong></span></pre><figure class="no np nq nr gt jr"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="no np nq nr gt jr gh gi paragraph-image"><div class="gh gi qf"><img src="../Images/f270a2111957958971c3d402083d2a8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*B5Nisp3a-SKHmA8qk6Di5Q.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><strong class="bd pk">准确率 83%！🏆</strong></p></figure><p id="1ca2" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir"> 83%，</strong>的一个<strong class="ld ir"> R </strong>揭示了数据<strong class="ld ir">的<strong class="ld ir"> 83% </strong>符合</strong>回归模型</p><p id="3025" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir">型号 6: XGboost </strong></p><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="f259" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">from</strong> <strong class="nt ir">xgboost</strong> <strong class="nt ir">import</strong> XGBClassifier<br/><br/><strong class="nt ir">model7 = XGBClassifier(random_state=1)<br/>model7.fit(x_train, y_train)<br/>y_pred7 = model7.predict(x_test)<br/>from sklearn.metrics import r2_score<br/>r2_score(y_test5,y_pred7)</strong></span></pre><figure class="no np nq nr gt jr"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="no np nq nr gt jr gh gi paragraph-image"><div class="gh gi qg"><img src="../Images/ed3f80fe1848670bd9fc859252a19704.png" data-original-src="https://miro.medium.com/v2/resize:fit:712/format:webp/1*V6By6fQj8cqpso9V0K4uXw.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><strong class="bd pk">准确率 82% </strong></p></figure></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><h1 id="c534" class="kd ke iq bd kf kg ml ki kj kk mm km kn ko mn kq kr ks mo ku kv kw mp ky kz la bi translated"><strong class="ak">解释 R 值</strong></h1><blockquote class="oj ok ol"><p id="df60" class="lb lc nn ld b le lz lg lh li ma lk ll om mb lo lp on mc ls lt oo md lw lx ly ij bi translated"><strong class="ld ir"> R </strong>(又名<strong class="ld ir">拟合优度</strong>或<strong class="ld ir">决定系数</strong>)是<strong class="ld ir">统计</strong>测量<strong class="ld ir">数据与<strong class="ld ir">拟合</strong>回归线的接近程度。<strong class="ld ir">比</strong>高<strong class="ld ir"> R </strong>，比<strong class="ld ir">好</strong>。最佳 R 值为 1.0</strong></p></blockquote><p id="88d5" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">通过比较 6 个回归模型，我们可以得出结论:<strong class="ld ir">模型 5:随机森林回归</strong>产生的<strong class="ld ir">精度最高</strong>，其<strong class="ld ir">精度</strong>为<strong class="ld ir">的 83% </strong>！<em class="nn">🏆</em></p><blockquote class="ou"><p id="ce64" class="ov ow iq bd ox oy oz pa pb pc pd ly dk translated"><strong class="ak">注意</strong>:一个<strong class="ak">好的经验法则</strong>是任何高于 70%的精度都被认为是好的，但要小心，因为如果你的精度极高，它可能好得不真实(过度拟合的一个例子)。因此，83%是理想的精确度！</p></blockquote></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><h1 id="7eda" class="kd ke iq bd kf kg ml ki kj kk mm km kn ko mn kq kr ks mo ku kv kw mp ky kz la bi translated">预言</h1><p id="abe9" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi mq translated"><span class="l mr ms mt bm mu mv mw mx my di"> S </span> <strong class="ld ir"> cenario </strong>:让我们<strong class="ld ir">预测</strong>一家公司酿造的一款红酒的<strong class="ld ir">质量</strong>是根据其<strong class="ld ir">每种成分</strong>的<strong class="ld ir">比例</strong>。我们现在将<strong class="ld ir">输入</strong>每种<strong class="ld ir">成分</strong>的<strong class="ld ir">比例</strong>到我们的<strong class="ld ir">机器学习算法</strong>中。</p><p id="4e3d" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir">红酒的成分</strong>由…</p><p id="d8ae" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir"> 7.9 g/L </strong>的<strong class="ld ir">固定酸度</strong>，</p><p id="8414" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir"> 0.59 克/升</strong>的<strong class="ld ir">挥发酸度</strong>，</p><p id="902f" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir">柠檬酸</strong>的 0.004 摩尔/升，</p><p id="241f" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir">发酵停止后<strong class="ld ir">残糖</strong>1.9g/L</strong>，</p><p id="fd95" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir"> 0.062 克</strong>的<strong class="ld ir">氯化物盐</strong>，</p><p id="7c41" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir"> 49.0 毫克/升</strong>的<strong class="ld ir">游离二氧化硫</strong>，</p><p id="c63a" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir"> 33.0 毫克/升</strong>的<strong class="ld ir">总二氧化硫</strong>，</p><p id="b76e" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir">密度为 0.9915 克/厘米的水，</strong></p><p id="b38f" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir"> pH </strong>的<strong class="ld ir"> 3.21 </strong>(酸性)，</p><p id="efe8" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir"> 0.53 克</strong>的<strong class="ld ir">硫酸盐</strong>，</p><p id="57f8" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">和<strong class="ld ir"> 8.9 % </strong>的<strong class="ld ir">酒精含量</strong></p><p id="99f6" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">根据这些信息，你能<strong class="ld ir">预测</strong>这款<strong class="ld ir">红酒</strong>的<strong class="ld ir">质量分数</strong>吗？</p><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="bcaa" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">print(regressor5.predict(([[7.9,0.59,0.004,1.9,0.062,49.0,33.0,0.99513,3.21,0.53,8.9,1]])))</strong></span></pre><figure class="no np nq nr gt jr gh gi paragraph-image"><div class="gh gi qh"><img src="../Images/e156bab6de2638137f11c4593bc370e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:256/format:webp/1*Qb3KDC-YDQgtt_XdD74m5A.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><strong class="bd pk">产量</strong>一<strong class="bd pk">红酒质量分数</strong>为<strong class="bd pk"> 6.5 </strong>！</p></figure><p id="399a" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir"> <em class="nn"> P.S </em> </strong> <em class="nn">。如果你看不出来，我以前是</em> <strong class="ld ir"> <em class="nn">生物专业</em> </strong> <em class="nn">，转行之前是</em> <strong class="ld ir"> <em class="nn">数据科学</em> </strong></p></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><h1 id="a5ec" class="kd ke iq bd kf kg ml ki kj kk mm km kn ko mn kq kr ks mo ku kv kw mp ky kz la bi translated">k 倍交叉验证</h1><blockquote class="oj ok ol"><p id="7dc4" class="lb lc nn ld b le lz lg lh li ma lk ll om mb lo lp on mc ls lt oo md lw lx ly ij bi translated"><strong class="ld ir"> K 倍交叉验证</strong>是一种<strong class="ld ir">统计</strong>方法，确保我们对我们的模型<strong class="ld ir">性能</strong>有更好的<strong class="ld ir">测量</strong>。我们在数据的不同<strong class="ld ir">子集</strong>上运行我们的建模过程，以获得模型<strong class="ld ir">质量</strong>的多个度量<strong class="ld ir">。我们<strong class="ld ir">用</strong>我们的数据除以<strong class="ld ir">特定的</strong>数量的<strong class="ld ir">倍</strong>。</strong></p></blockquote><blockquote class="ou"><p id="9afe" class="ov ow iq bd ox oy qi qj qk ql qm ly dk translated"><strong class="ak"> K 重交叉验证</strong>允许原始数据集中的每个观察值出现在我们的训练&amp;测试集中。</p></blockquote><p id="1409" class="pw-post-body-paragraph lb lc iq ld b le pe lg lh li pf lk ll lm pg lo lp lq ph ls lt lu pi lw lx ly ij bi translated">当我们创建<strong class="ld ir"> 20 个不同的测试折叠</strong>时，我们<strong class="ld ir">降低了获得<strong class="ld ir">幸运</strong>的</strong> <strong class="ld ir">风险</strong>。<strong class="ld ir">最终</strong> <strong class="ld ir">精度</strong>我们得到的将是<strong class="ld ir">平均值</strong>的<strong class="ld ir"> 20 倍测试</strong>！</p><pre class="no np nq nr gt ns nt nu nv aw nw bi"><span id="4997" class="nx ke iq nt b gy ny nz l oa ob"><strong class="nt ir">from sklearn.model_selection import cross_val_score<br/>accuracies = cross_val_score(estimator = regressor5, X = x_train5, y = y_train5, cv = 20)</strong><br/><strong class="nt ir">print("Accuracy: {:.2f} %".format(accuracies.mean()*100)) </strong><em class="nn"># float w 2 decimals after comma</em><br/><strong class="nt ir">print("Accuracy: {:.2f} %".format(accuracies.std()*100))</strong> <em class="nn"># float w 2 decimals after comma</em><br/><em class="nn"># the 20 accruaceis lie within  % , we have a high std. </em><br/><em class="nn">#(Mean - Std, Mean + Std)</em></span></pre><figure class="no np nq nr gt jr"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="no np nq nr gt jr gh gi paragraph-image"><div class="gh gi qn"><img src="../Images/c2466f5373f4307ff955d5d7f2186c9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*EI6ZR1sKEZ_crQO2MWuAaA.png"/></div></figure><p id="f741" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">20 个准确度位于<strong class="ld ir">(80.44–4.48，80.44+4.48)% </strong> = <strong class="ld ir"> (75.96，84.92)%置信区间</strong>内。我们有一个<strong class="ld ir">高标准差</strong>，这意味着我们的<strong class="ld ir">数字</strong>是<strong class="ld ir">展开</strong>的。</p></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><h1 id="b5cd" class="kd ke iq bd kf kg ml ki kj kk mm km kn ko mn kq kr ks mo ku kv kw mp ky kz la bi translated">结论</h1><ol class=""><li id="db50" class="mz na iq ld b le lf li lj lm nb lq nc lu nd ly qo nf ng nh bi translated"><strong class="ld ir">在我们研究的 11 个特征中，帮助葡萄酒商酿造美味红酒的前 3 个重要特征是低水平的二氧化硫和高水平的硫酸盐&amp;酒精。</strong></li><li id="dfa4" class="mz na iq ld b le ni li nj lm nk lq nl lu nm ly qo nf ng nh bi translated">我们的随机森林算法产生了最高的 R 值，83%！任何超过 70%的 R 都被认为是好的，但是要小心，因为如果你的精确度非常高，它可能好得不真实(过度拟合的一个例子)。因此，83%是理想的精确度！</li><li id="7e8b" class="mz na iq ld b le ni li nj lm nk lq nl lu nm ly qo nf ng nh bi translated">我们的机器学习算法现在可以根据成分比例预测红酒的质量。通过检测这些重要的特征，我们可以防止我们的葡萄酒商倒闭或损失任何利润！生产一种没有人会喜欢的葡萄酒成本很高，会给我们公司带来收入损失。这是非常强大的，因为现在我们可以正确地看到人们更喜欢葡萄酒的哪些成分&amp;，从而最大化我们的利润！</li></ol></div><div class="ab cl me mf hu mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="ij ik il im in"><p id="d442" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">这里是从我的<strong class="ld ir"> GitHub </strong>页面对<strong class="ld ir">数据集</strong> &amp; <strong class="ld ir">代码</strong>的<strong class="ld ir">访问</strong>:</p><div class="qp qq gp gr qr qs"><a href="https://github.com/jzaidi143/Project-Predicting-the-Perfect-Ratio-of-Red-Wine-Ingredients-with-Regression-Machine-Learning-Algor" rel="noopener  ugc nofollow" target="_blank"><div class="qt ab fo"><div class="qu ab qv cl cj qw"><h2 class="bd ir gy z fp qx fr fs qy fu fw ip bi translated">jzaidi 143/Project-用回归机器学习预测红酒成分的完美比例…</h2><div class="qz l"><h3 class="bd b gy z fp qx fr fs qy fu fw dk translated">预测红酒成分的最佳比例。这是一个数字离散结果。探索各种…</h3></div><div class="ra l"><p class="bd b dl z fp qx fr fs qy fu fw dk translated">github.com</p></div></div><div class="rb l"><div class="rc l rd re rf rb rg jw qs"/></div></div></a></div><p id="d6f7" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><a class="ae kc" href="https://archive.ics.uci.edu/ml/datasets/wine+quality" rel="noopener ugc nofollow" target="_blank">https://archive.ics.uci.edu/ml/datasets/wine+quality</a></p><p id="1ead" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">欢迎推荐和评论！</p><h1 id="49e8" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">承认</h1><p id="5987" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">页（page 的缩写）科尔特斯、塞德伊拉、阿尔梅达、马托斯和雷伊斯。<br/>通过物理化学特性的数据挖掘建立葡萄酒偏好模型。在决策支持系统中，爱思唯尔，47(4):547–553，2009。</p></div></div>    
</body>
</html>