<html>
<head>
<title>Apache Spark Cluster on Docker (ft. a JupyterLab Interface)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Docker 上的 Apache Spark 集群(英尺。JupyterLab 接口)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/apache-spark-cluster-on-docker-ft-a-juyterlab-interface-418383c95445?source=collection_archive---------5-----------------------#2020-07-14">https://towardsdatascience.com/apache-spark-cluster-on-docker-ft-a-juyterlab-interface-418383c95445?source=collection_archive---------5-----------------------#2020-07-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="14fb" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">Docker 上的集群应用</h2><div class=""/><div class=""><h2 id="8fb3" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">使用 JupyterLab 接口在 Docker 上以独立模式构建自己的 Apache Spark 集群</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/ab81d49e2b204e55f94d2cd75591f423.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lZ2rQba-4Y-NTAhz2Z1fAA.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">由<a class="ae lh" href="https://unsplash.com/photos/r4lM2v9M84Q" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上<a class="ae lh" href="https://unsplash.com/@jeztimms" rel="noopener ugc nofollow" target="_blank"> Jez Timms </a>的火花</p></figure><p id="8f16" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Spark </a>可以说是最受欢迎的大数据处理引擎。GitHub 上有超过 25k 颗星星，该框架是学习使用 Python、Scala 和 r 在分布式系统中进行并行计算的绝佳起点。</p><p id="05d6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">首先，您可以在您的机器上运行 Apache Spark，方法是使用市面上许多优秀的 Docker 发行版中的一个。<a class="ae lh" href="https://github.com/jupyter/docker-stacks" rel="noopener ugc nofollow" target="_blank"> Jupyter </a>提供了一个优秀的<em class="me">dockered</em>Apache Spark，带有一个 JupyterLab 接口，但是缺少框架分布式核心，因为它在一个容器上运行。一些 GitHub <a class="ae lh" href="https://github.com/big-data-europe/docker-spark" rel="noopener ugc nofollow" target="_blank">项目</a>提供了分布式集群体验，但是缺少 JupyterLab 接口，削弱了 IDE 提供的可用性。</p><p id="2661" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我相信，学习和实践 Apache Spark 代码的综合环境必须保持其分布式性质，同时提供令人敬畏的用户体验。</p><p id="0943" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这篇文章就是关于这个信念的。</p><p id="b839" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在接下来的小节中，我将向您展示如何构建自己的集群。最后，您将拥有一个用 Docker 构建的功能完整的 Apache Spark 集群，附带一个 Spark 主节点、两个 Spark 工作节点和一个 JupyterLab 接口。它还将包括 Apache Spark Python API (PySpark)和一个模拟的 Hadoop 分布式文件系统(HDFS)。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="1ac3" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">TL；速度三角形定位法(dead reckoning)</h1><p id="bca0" class="pw-post-body-paragraph li lj it lk b ll ne kd ln lo nf kg lq lr ng lt lu lv nh lx ly lz ni mb mc md im bi translated">本文展示了如何使用 Docker 作为基础设施层在独立模式下构建 Apache Spark 集群。它附带了以下内容:</p><ul class=""><li id="f16f" class="nj nk it lk b ll lm lo lp lr nl lv nm lz nn md no np nq nr bi translated">Python 3.7 配 PySpark 3.0.0 和 Java 8；</li><li id="cf73" class="nj nk it lk b ll ns lo nt lr nu lv nv lz nw md no np nq nr bi translated">Apache Spark 3.0.0，有一个主节点和两个工作节点；</li><li id="dfea" class="nj nk it lk b ll ns lo nt lr nu lv nv lz nw md no np nq nr bi translated">JupyterLab IDE 2 . 1 . 5；</li><li id="8ab0" class="nj nk it lk b ll ns lo nt lr nu lv nv lz nw md no np nq nr bi translated">模拟 HDFS 2.7。</li></ul><p id="6dff" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">要创建集群，我们需要为 JupyterLab 和 Spark 节点创建、构建和组合 Docker 映像。你可以通过使用托管在我的<a class="ae lh" href="https://github.com/cluster-apps-on-docker/spark-standalone-cluster-on-docker" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上的<strong class="lk jd">开箱即用的发行版</strong>来跳过教程。</p><blockquote class="nx ny nz"><p id="742b" class="li lj me lk b ll lm kd ln lo lp kg lq oa ls lt lu ob lw lx ly oc ma mb mc md im bi translated">更新# 1:2020 年 8 月 9 日，我们通过<a class="ae lh" href="https://almond.sh/" rel="noopener ugc nofollow" target="_blank">杏仁</a> Jupyter Scala 内核发布了对 Spark Scala API 的支持。谢谢杏仁太棒了。✨</p><p id="7ae8" class="li lj me lk b ll lm kd ln lo lp kg lq oa ls lt lu ob lw lx ly oc ma mb mc md im bi translated">更新# 2:2020 年 8 月 19 日，我们通过<a class="ae lh" href="https://irkernel.github.io/" rel="noopener ugc nofollow" target="_blank"> IRkernel </a> Jupyter R 内核发布了对 Spark R API (SparkR)的支持。谢谢伊克内尔这么棒。✨</p></blockquote></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="81e3" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">要求</h1><ul class=""><li id="294f" class="nj nk it lk b ll ne lo nf lr od lv oe lz of md no np nq nr bi translated"><strong class="lk jd">Docker</strong>1 . 13 . 0+；</li><li id="3f69" class="nj nk it lk b ll ns lo nt lr nu lv nv lz nw md no np nq nr bi translated"><strong class="lk jd"> Docker 作曲</strong> 1.10.0+。</li></ul></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="f5eb" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">目录</h1><ol class=""><li id="c02b" class="nj nk it lk b ll ne lo nf lr od lv oe lz of md og np nq nr bi translated">集群概述；</li><li id="433e" class="nj nk it lk b ll ns lo nt lr nu lv nv lz nw md og np nq nr bi translated">创建图像；</li><li id="d2f5" class="nj nk it lk b ll ns lo nt lr nu lv nv lz nw md og np nq nr bi translated">构建图像；</li><li id="42d2" class="nj nk it lk b ll ns lo nt lr nu lv nv lz nw md og np nq nr bi translated">组成集群；</li><li id="8927" class="nj nk it lk b ll ns lo nt lr nu lv nv lz nw md og np nq nr bi translated">创建 PySpark 应用程序。</li></ol><h1 id="fa23" class="mm mn it bd mo mp oh mr ms mt oi mv mw ki oj kj my kl ok km na ko ol kp nc nd bi translated">1.集群概述</h1><p id="cdba" class="pw-post-body-paragraph li lj it lk b ll ne kd ln lo nf kg lq lr ng lt lu lv nh lx ly lz ni mb mc md im bi translated">该集群由四个主要组件组成:JupyterLab IDE、Spark 主节点和两个 Spark workers 节点。用户连接到主节点，并通过 Jupyter notebooks 提供的漂亮 GUI 提交 Spark 命令。主节点处理输入并将计算工作负载分配给工作节点，然后将结果发送回 IDE。这些组件使用本地主机网络连接，并通过模拟 HDFS 的共享装载卷在彼此之间共享数据。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi om"><img src="../Images/3c24d785c4c329438f27bdb726ecabd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xQEp3WV2QMrkJOOSodKm7Q.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">Apache Spark 集群概述</p></figure><p id="a817" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如前所述，我们需要为 JupyterLab 和 Spark 节点创建、构建和组合 Docker 映像来构建集群。我们将使用以下 Docker 图像层次结构:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi on"><img src="../Images/5b78e289a4cf7a3147de16b34ac589bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XzVRLHSZkqMOkomujc5OyQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">Docker 图像层次结构</p></figure><p id="ec4e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">集群基础映像将下载并安装通用软件工具(Java、Python 等)。)并将为 HDFS 创建共享目录。在 Spark 基本映像上，Apache Spark 应用程序将被下载并配置给主节点和工作节点。Spark 主映像将配置框架作为主节点运行。类似地，Spark 工作节点将配置 Apache Spark 应用程序作为工作节点运行。最后，JupyterLab 映像将使用集群基础映像来安装和配置 IDE 和 PySpark(Apache Spark 的 Python API)。</p><h1 id="4de3" class="mm mn it bd mo mp oh mr ms mt oi mv mw ki oj kj my kl ok km na ko ol kp nc nd bi translated">2.创建图像</h1><h2 id="2a4b" class="oo mn it bd mo op oq dn ms or os dp mw lr ot ou my lv ov ow na lz ox oy nc iz bi translated">2.1.聚类基础图像</h2><p id="bcd6" class="pw-post-body-paragraph li lj it lk b ll ne kd ln lo nf kg lq lr ng lt lu lv nh lx ly lz ni mb mc md im bi translated">对于基本映像，我们将使用 Linux 发行版来安装 Java 8(或 11)，<a class="ae lh" href="https://spark.apache.org/docs/latest/#downloading" rel="noopener ugc nofollow" target="_blank"> Apache Spark only 需求</a>。我们还需要安装 Python 3 来支持 PySpark，并创建共享卷来模拟 HDFS。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oz pa l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">集群基础映像的 docker 文件</p></figure><p id="c1d7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">首先，让我们选择 Linux 操作系统。Apache Spark 官方 GitHub repository 有一个用于 Kubernetes 部署的<a class="ae lh" href="https://github.com/apache/spark/blob/master/resource-managers/kubernetes/docker/src/main/dockerfiles/spark/Dockerfile" rel="noopener ugc nofollow" target="_blank"> Dockerfile </a>，它使用一个小型 Debian 映像，内置 Java 8 运行时环境(JRE)。通过选择<a class="ae lh" href="https://hub.docker.com/_/openjdk?tab=tags&amp;page=1&amp;name=8-jre-slim" rel="noopener ugc nofollow" target="_blank">相同的基础映像</a>，我们解决了操作系统选择和 Java 安装的问题。然后，我们从 Debian 官方软件包库中获得了<a class="ae lh" href="https://packages.debian.org/stable/python/python3" rel="noopener ugc nofollow" target="_blank">最新的 Python 版本</a>(目前是 3.7)，并创建了共享卷。</p><h2 id="2d1f" class="oo mn it bd mo op oq dn ms or os dp mw lr ot ou my lv ov ow na lz ox oy nc iz bi translated">2.2.火花基础图像</h2><p id="ffb9" class="pw-post-body-paragraph li lj it lk b ll ne kd ln lo nf kg lq lr ng lt lu lv nh lx ly lz ni mb mc md im bi translated">对于 Spark 基本映像，我们将在<a class="ae lh" href="http://spark.apache.org/docs/latest/spark-standalone.html" rel="noopener ugc nofollow" target="_blank">独立模式</a>下获取并设置 Apache Spark，这是其最简单的部署配置。在这种模式下，我们将使用它的资源管理器来设置容器，使其作为主节点或工作节点运行。相比之下，资源管理器如<a class="ae lh" href="https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html" rel="noopener ugc nofollow" target="_blank"> Apache YARN </a>根据用户工作负载动态分配容器作为主节点或工作节点。此外，我们将获得一个支持 Apache Hadoop 的 Apache Spark 版本，允许集群使用在基本集群映像中创建的共享卷来模拟 HDFS。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oz pa l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">Spark 基本图像的 docker 文件</p></figure><p id="d0f1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们先从官方<a class="ae lh" href="https://archive.apache.org/dist/spark/" rel="noopener ugc nofollow" target="_blank"> Apache 资源库</a>下载 Apache Spark 最新版本(目前为 3.0.0)支持 Apache Hadoop。然后，我们用下载的包玩一会儿(解包，移动，等等。)我们已经为设置阶段做好了准备。最后，我们配置主节点和工作节点共有的四个 Spark 变量:</p><ol class=""><li id="9b77" class="nj nk it lk b ll lm lo lp lr nl lv nm lz nn md og np nq nr bi translated"><strong class="lk jd"> SPARK_HOME </strong>是框架用来设置任务的已安装的 Apache Spark 位置；</li><li id="2bcd" class="nj nk it lk b ll ns lo nt lr nu lv nv lz nw md og np nq nr bi translated"><strong class="lk jd"> SPARK_MASTER_HOST </strong>是工作节点用来连接的主节点<strong class="lk jd">主机名</strong>；</li><li id="a8c7" class="nj nk it lk b ll ns lo nt lr nu lv nv lz nw md og np nq nr bi translated"><strong class="lk jd"> SPARK_MASTER_PORT </strong>是主节点<strong class="lk jd">端口</strong>，供工作节点连接使用；</li><li id="0619" class="nj nk it lk b ll ns lo nt lr nu lv nv lz nw md og np nq nr bi translated"><strong class="lk jd"> PYSPARK_PYTHON </strong>是 Apache Spark 用来支持其 Python API 的 PYTHON 安装位置。</li></ol><h2 id="92ee" class="oo mn it bd mo op oq dn ms or os dp mw lr ot ou my lv ov ow na lz ox oy nc iz bi translated">2.3.Spark 主图像</h2><p id="dc27" class="pw-post-body-paragraph li lj it lk b ll ne kd ln lo nf kg lq lr ng lt lu lv nh lx ly lz ni mb mc md im bi translated">对于 Spark 主映像，我们将设置 Apache Spark 应用程序作为主节点运行。我们将配置网络端口，以允许与工作节点的网络连接，并公开主 web UI，一个监视主节点活动的网页。最后，我们将设置容器启动命令来启动作为主实例的节点。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oz pa l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">Spark 主映像的 docker 文件</p></figure><p id="c6bc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们首先公开在<strong class="lk jd"> SPARK_MASTER_PORT </strong>环境变量中配置的端口，以允许工人连接到主节点。然后，我们公开<strong class="lk jd"> SPARK_MASTER_WEBUI_PORT </strong>端口，让我们访问主 WEBUI 页面。最后，我们将容器启动命令设置为运行 Spark 内置部署脚本，并将<a class="ae lh" href="https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/deploy/master/Master.scala" rel="noopener ugc nofollow" target="_blank">主类</a>作为其参数。</p><h2 id="1d5b" class="oo mn it bd mo op oq dn ms or os dp mw lr ot ou my lv ov ow na lz ox oy nc iz bi translated">2.4.星火工作者形象</h2><p id="534a" class="pw-post-body-paragraph li lj it lk b ll ne kd ln lo nf kg lq lr ng lt lu lv nh lx ly lz ni mb mc md im bi translated">对于 Spark worker 映像，我们将设置 Apache Spark 应用程序作为 worker 节点运行。与主节点类似，我们将配置网络端口以公开 worker web UI，一个监视 worker 节点活动的网页，并设置容器启动命令以将节点作为 worker 实例启动。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oz pa l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">Spark 工人图像的 worker 文件</p></figure><p id="6477" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">首先，我们公开了<strong class="lk jd"> SPARK_WORKER_WEBUI_PORT </strong>端口，以允许访问 worker web UI 页面，就像我们对主节点所做的那样。然后，我们设置容器启动命令来运行 Spark 内置部署脚本，使用<a class="ae lh" href="https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/deploy/worker/Worker.scala" rel="noopener ugc nofollow" target="_blank">工作类</a>和主网络地址作为参数。这将使工作节点在启动过程中连接到主节点。</p><h2 id="3ca2" class="oo mn it bd mo op oq dn ms or os dp mw lr ot ou my lv ov ow na lz ox oy nc iz bi translated">2.5.木星图像</h2><p id="f309" class="pw-post-body-paragraph li lj it lk b ll ne kd ln lo nf kg lq lr ng lt lu lv nh lx ly lz ni mb mc md im bi translated">对于 JupyterLab 映像，我们稍微后退一点，从集群基础映像重新开始。我们将安装和配置 IDE 以及与 Spark 节点上安装的略有不同的 Apache Spark 发行版。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oz pa l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">JupyterLab 图像的 docker 文件</p></figure><p id="c77b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们首先安装 pip(Python 的包管理器)和 Python 开发工具，以允许在映像构建期间和容器运行时安装 Python 包。然后，让我们从 Python 包索引(PyPI)中获取<a class="ae lh" href="https://pypi.org/project/jupyterlab/" rel="noopener ugc nofollow" target="_blank"> JupyterLab </a>和<a class="ae lh" href="https://pypi.org/project/pyspark/" rel="noopener ugc nofollow" target="_blank"> PySpark </a>。最后，我们公开默认端口以允许访问 JupyterLab web 界面，并设置容器启动命令以运行 IDE 应用程序。</p><h1 id="a73f" class="mm mn it bd mo mp oh mr ms mt oi mv mw ki oj kj my kl ok km na ko ol kp nc nd bi translated">3.构建图像</h1><p id="bd03" class="pw-post-body-paragraph li lj it lk b ll ne kd ln lo nf kg lq lr ng lt lu lv nh lx ly lz ni mb mc md im bi translated">Docker 图像已经准备好了，让我们建立它们。注意，因为我们在 Dockerfiles 上使用了 Docker <em class="me"> arg </em>关键字来指定软件版本，所以我们可以很容易地为集群更改默认的 Apache Spark 和 JupyterLab 版本。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oz pa l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">构建集群映像</p></figure><h1 id="af57" class="mm mn it bd mo mp oh mr ms mt oi mv mw ki oj kj my kl ok km na ko ol kp nc nd bi translated">4.构成集群</h1><p id="27dc" class="pw-post-body-paragraph li lj it lk b ll ne kd ln lo nf kg lq lr ng lt lu lv nh lx ly lz ni mb mc md im bi translated">Docker 合成文件包含我们集群的配方。在这里，我们将创建 JuyterLab 和 Spark 节点容器，向本地主机网络公开它们的端口，并将它们连接到模拟的 HDFS。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oz pa l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">集群的 Docker 合成文件</p></figure><p id="0a93" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们首先为模拟的 HDFS 创建 Docker 卷。接下来，我们为每个集群组件创建一个容器。<em class="me"> jupyterlab </em>容器公开 IDE 端口，并将其共享工作区目录绑定到 HDFS 卷。同样，<em class="me"> spark-master </em>容器公开了它的 web UI 端口和它的<em class="me"> master-worker </em>连接端口，并且也绑定到 HDFS 卷。</p><p id="2e7a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们通过创建两个名为<em class="me"> spark-worker-1 </em>和<em class="me"> spark-worker-2 </em>的 Spark worker 容器来完成。每个容器都公开其 web UI 端口(分别映射到 8081 和 8082 ),并绑定到 HDFS 卷。这些容器有一个指定其硬件分配的环境步骤:</p><ul class=""><li id="8cc1" class="nj nk it lk b ll lm lo lp lr nl lv nm lz nn md no np nq nr bi translated"><strong class="lk jd"> SPARK_WORKER_CORE </strong>为核心数；</li><li id="372c" class="nj nk it lk b ll ns lo nt lr nu lv nv lz nw md no np nq nr bi translated"><strong class="lk jd"> SPARK_WORKER_MEMORY </strong>是 RAM 的大小。</li></ul><p id="5566" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">默认情况下，我们为每个容器选择一个内核和 512 MB RAM。您可以随意使用硬件分配，但要确保尊重您的机器限制，以避免内存问题。另外，为 Docker 应用程序提供足够的资源来处理选定的值。</p><p id="427a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">要编写集群，请运行 Docker 编写文件:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oz pa l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">构成集群</p></figure><p id="3117" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">完成后，查看组件 web 用户界面:</p><ul class=""><li id="2076" class="nj nk it lk b ll lm lo lp lr nl lv nm lz nn md no np nq nr bi translated"><strong class="lk jd"> JupyterLab </strong>在<a class="ae lh" href="http://localhost:8888/" rel="noopener ugc nofollow" target="_blank">localhost:8888</a>；</li><li id="8a8f" class="nj nk it lk b ll ns lo nt lr nu lv nv lz nw md no np nq nr bi translated"><strong class="lk jd">星火大师</strong>在<a class="ae lh" href="http://localhost:8080/" rel="noopener ugc nofollow" target="_blank">本地主机:8080</a>；</li><li id="0027" class="nj nk it lk b ll ns lo nt lr nu lv nv lz nw md no np nq nr bi translated"><strong class="lk jd">火花工一</strong>在<a class="ae lh" href="http://localhost:8081/" rel="noopener ugc nofollow" target="_blank">本地主机:8081</a>；</li><li id="f0e8" class="nj nk it lk b ll ns lo nt lr nu lv nv lz nw md no np nq nr bi translated"><strong class="lk jd">火花工二</strong>在<a class="ae lh" href="http://localhost:8082/" rel="noopener ugc nofollow" target="_blank">本地主机:8082</a>；</li></ul><h1 id="2e1a" class="mm mn it bd mo mp oh mr ms mt oi mv mw ki oj kj my kl ok km na ko ol kp nc nd bi translated">5.创建 PySpark 应用程序</h1><p id="3b4e" class="pw-post-body-paragraph li lj it lk b ll ne kd ln lo nf kg lq lr ng lt lu lv nh lx ly lz ni mb mc md im bi translated">集群启动并运行后，让我们创建第一个 PySpark 应用程序。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oz pa l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">创建 PySpark 应用程序</p></figure><p id="7b91" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">打开 JupyterLab IDE 并创建一个 Python Jupyter 笔记本。通过使用具有以下参数的 Spark 会话对象连接到 Spark 主节点来创建 PySpark 应用程序:</p><ul class=""><li id="d3fd" class="nj nk it lk b ll lm lo lp lr nl lv nm lz nn md no np nq nr bi translated"><strong class="lk jd"> appName </strong>是我们应用程序的名称；</li><li id="7b2b" class="nj nk it lk b ll ns lo nt lr nu lv nv lz nw md no np nq nr bi translated"><strong class="lk jd"> master </strong>是 Spark master 的连接 URL，同样由 Spark worker 节点用来连接 Spark master 节点；</li><li id="e155" class="nj nk it lk b ll ns lo nt lr nu lv nv lz nw md no np nq nr bi translated"><strong class="lk jd">配置</strong>是独立模式的通用<a class="ae lh" href="https://spark.apache.org/docs/latest/configuration.html" rel="noopener ugc nofollow" target="_blank">火花配置。这里，我们将执行器内存(即 Spark worker JVM 进程)与提供的工作节点内存进行匹配。</a></li></ul><p id="5a87" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">运行该单元，您将能够在 Spark master web UI 的“运行应用程序”下看到该应用程序。然后我们从<a class="ae lh" href="https://archive.ics.uci.edu/ml/datasets/iris" rel="noopener ugc nofollow" target="_blank"> UCI 库</a>下载虹膜数据集到模拟的 HDFS。最后，用 PySpark 读取并打印数据。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="625a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这是所有的乡亲。我希望我已经帮助您更多地了解了 Apache Spark 的内部结构以及分布式应用程序是如何工作的。快乐学习！</p></div></div>    
</body>
</html>