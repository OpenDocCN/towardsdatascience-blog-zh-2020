<html>
<head>
<title>How to build Spark from source and deploy it to a Kubernetes cluster in 60 minutes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在60分钟内从源代码构建Spark并将其部署到Kubernetes集群</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-build-spark-from-source-and-deploy-it-to-a-kubernetes-cluster-in-60-minutes-225829b744f9?source=collection_archive---------4-----------------------#2020-03-20">https://towardsdatascience.com/how-to-build-spark-from-source-and-deploy-it-to-a-kubernetes-cluster-in-60-minutes-225829b744f9?source=collection_archive---------4-----------------------#2020-03-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4924" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">通过这篇Spark教程，登上Kubernetes的大数据宣传列车</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/89a9cc681c93059dbc8c3dc14ba8c82a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kbz734H57Cez9Dj6pOp8Ww.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">天作之合？来源:<a class="ae kv" href="https://commons.wikimedia.org/wiki/File:Apache_Spark_logo.svg," rel="noopener ugc nofollow" target="_blank"> Spark Logo </a>，<a class="ae kv" href="https://en.wikipedia.org/wiki/Kubernetes" rel="noopener ugc nofollow" target="_blank"> k8s Logo </a>，<a class="ae kv" href="https://emojipedia.org/unicorn/" rel="noopener ugc nofollow" target="_blank"> Emoji </a></p></figure><p id="b3c5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">动机/前奏</strong></p><p id="e064" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我的上一篇文章中，我解释了Hadoop生态系统的大致情况，你可以在这里阅读<a class="ae kv" rel="noopener" target="_blank" href="/making-big-moves-in-big-data-with-hadoop-hive-parquet-hue-and-docker-320a52ca175"/>。那篇文章最重要的是结尾，我将公然抄袭我的另一篇文章，因为它也是这篇文章的开头:</p><blockquote class="ls lt lu"><p id="17a3" class="kw kx lv ky b kz la jr lb lc ld ju le lw lg lh li lx lk ll lm ly lo lp lq lr ij bi translated">现在，如果你在过去几年中一直在收听Hadoop的生态系统，你会看到市场上最大的两家公司——cloud era和Hortonworks — <a class="ae kv" href="https://techcrunch.com/2019/01/03/cloudera-and-hortonworks-finalize-their-merger/?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAAFdWl96BCgH521hvgxIYTl5hVRxsg-B6Nj6_q5C9nY3_SVtz7qmGHpnGmuLxoZhv7_OXLaYSmtuQlD2BcGGKqyaT_Vz_mgfpTaE7JZZ241vBM43dLmYQsoSiqK8lidE-92bDNI69PaxqA1Z6tnjx-kUAGfvrD9zL3Bvt6j4uufAo" rel="noopener ugc nofollow" target="_blank">在大约一年前</a>Hadoop大数据市场放缓时合并了。事实上，人们似乎对Kubernetes比对更老的Hadoop特定技术更感兴趣，如用于资源管理和编排的YARN，对PyTorch等DL框架的快速采用，以及对老化的Hadoop堆栈的完美风暴的形成。尽管如此，像Apache Spark这样的项目仍在稳步前进，例如引入Kubernetes作为纱线的替代品。生态系统激动人心的时刻！</p></blockquote><p id="89a9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">简介</strong></p><p id="7fd3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本文的目标是向您展示2020年大数据生态系统中的一些酷孩子在做什么；它试图把东西塞进Kubernetes(这是一件好事！).更具体地说，使用Spark的本地Spark驱动程序和执行器的实验性实现，其中Kubernetes是资源管理器(而不是YARN)</p><p id="7f91" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">…让我们在60分钟内完成这项工作:</p><ol class=""><li id="35c6" class="lz ma iq ky b kz la lc ld lf mb lj mc ln md lr me mf mg mh bi translated">从GitHub克隆Spark项目</li><li id="a4a8" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">用Maven构建火花分布</li><li id="f01a" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">在本地构建Docker映像</li><li id="be18" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">使用多个执行器副本运行Spark Pi作业</li><li id="0da0" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">使用端口转发在浏览器中显示Spark UI，并检查Spark作业</li></ol><p id="6cdc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果这么简单，我们为什么需要这篇文章？！请继续阅读，看看我第一次是如何花了<em class="lv">天</em>才弄明白的。</p><p id="3082" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">免责声明:您在60分钟内的里程数可能会有所不同，但在假设您通常知道如何在计算机上完成工作(包括设置本地k8s集群和运行bash脚本等)的情况下，这确实是可行的。此外，如果你有一台运行缓慢的计算机，构建Spark可能需要一段时间；)</p><p id="79ca" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">既然大家都在船上，让我们在Kubernetes上部署Spark。为此，您可以使用您的笔记本电脑运行的mill minikube设置，而不是在公共云中租用一台服务器来进行此练习。除非你想全押，在这种情况下，你刚刚被敬礼。</p><p id="312d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">步骤1–3(克隆回购、构建Spark、构建Docker映像):</strong></p><p id="b6a2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这实际上是乐趣的开始——在“最简单”的步骤上。好吧，系上安全带，看看这个(双关语):</p><p id="19e3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你在这里克隆了官方的Spark库<a class="ae kv" href="https://github.com/apache/spark" rel="noopener ugc nofollow" target="_blank">，在k8s </a><a class="ae kv" href="https://spark.apache.org/docs/latest/running-on-kubernetes.html" rel="noopener ugc nofollow" target="_blank">这里</a>天真的按照官方的Spark运行指南运行Spark，你就会碰到<a class="ae kv" href="https://issues.apache.org/jira/browse/SPARK-31165" rel="noopener ugc nofollow" target="_blank">我前几天在Spark的吉拉积压里开的这一期</a>。</p><p id="2284" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">也就是说，在docker文件中有多个错误的引用，因此简单地运行docker文件注释中描述的docker构建命令是行不通的。</p><blockquote class="ls lt lu"><p id="f98c" class="kw kx lv ky b kz la jr lb lc ld ju le lw lg lh li lx lk ll lm ly lo lp lq lr ij bi translated">更新:<em class="iq">好吧</em>，事实证明，你<em class="iq">实际上可以</em>运行文档中描述的东西，但前提是你必须非常注意。</p></blockquote><p id="663e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">而不是逃跑</p><pre class="kg kh ki kj gt mn mo mp mq aw mr bi"><span id="ce26" class="ms mt iq mo b gy mu mv l mw mx">./build/mvn -Pkubernetes -DskipTests clean package</span></pre><p id="8691" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你需要跑</p><pre class="kg kh ki kj gt mn mo mp mq aw mr bi"><span id="be23" class="ms mt iq mo b gy mu mv l mw mx">dev/make-distribution.sh -Pkubernetes</span></pre><p id="4164" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这创造了一个火花<em class="lv">发行版</em>而不仅仅是普通的组装零件，但我想我跳过了他们教程中的细则，所以我相应地更新了这篇文章。</p><p id="e358" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">TL；灾难恢复要完成步骤1-3，只需执行以下操作:</p><pre class="kg kh ki kj gt mn mo mp mq aw mr bi"><span id="a556" class="ms mt iq mo b gy mu mv l mw mx">git clone <a class="ae kv" href="mailto:git@github.com" rel="noopener ugc nofollow" target="_blank">git@github.com</a>:apache/spark.git</span><span id="e9ac" class="ms mt iq mo b gy my mv l mw mx">cd spark</span><span id="32d8" class="ms mt iq mo b gy my mv l mw mx">dev/make-distribution.sh -Pkubernetes</span><span id="b146" class="ms mt iq mo b gy my mv l mw mx">cd dist</span><span id="35d8" class="ms mt iq mo b gy my mv l mw mx">docker build -t spark:latest -f kubernetes/dockerfiles/spark/Dockerfile .</span></pre><p id="deb4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此时，您应该在本地Docker注册表中有一个Spark的图像！</p><p id="51bf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">步骤4:在Kubernetes中使用多个执行器副本运行Spark Pi作业:</strong></p><p id="614a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我在上面链接的Spark文章中提到但没有解释清楚的事实是，由于Kubernetes的RBAC(基于角色的访问控制)，您不能简单地将Spark部署到您的集群中，因为Spark需要对您的Kubernetes集群拥有一些额外的权限来管理pods。这是由于Spark的架构——您部署一个Spark驱动程序，然后它可以在pod中创建Spark执行器，然后在工作完成后清理它们:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mz"><img src="../Images/3aef08845c50891b3a469fa52d14ee6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tkWi16Clt_6RjLJNmyLVkg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Spark在Kubernetes上的架构来自他们的<a class="ae kv" href="https://spark.apache.org/docs/latest/running-on-kubernetes.html" rel="noopener ugc nofollow" target="_blank">文档</a></p></figure><p id="39a1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">TL；dr我们需要为Spark创建一个kubectl服务帐户:</p><pre class="kg kh ki kj gt mn mo mp mq aw mr bi"><span id="714c" class="ms mt iq mo b gy mu mv l mw mx">kubectl create serviceaccount spark</span><span id="40d0" class="ms mt iq mo b gy my mv l mw mx">kubectl create clusterrolebinding spark-role --clusterrole=edit  --serviceaccount=default:spark --namespace=default</span></pre><p id="33a7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来是使用我们本地构建的Docker映像运行Spark Pi:</p><pre class="kg kh ki kj gt mn mo mp mq aw mr bi"><span id="f59c" class="ms mt iq mo b gy mu mv l mw mx">bin/spark-submit \<br/>--master k8s://https://kubernetes.docker.internal:6443 \<br/>--deploy-mode cluster \<br/>--name spark-pi \<br/>--class org.apache.spark.examples.SparkPi \<br/>--conf spark.executor.instances=2 \<br/>--conf spark.kubernetes.container.image=spark:latest \<br/>--conf spark.kubernetes.container.image.pullPolicy=Never \<br/>--conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \<br/>local:///opt/spark/examples/jars/spark-examples_2.12-3.1.0-SNAPSHOT.jar 10000000</span></pre><p id="2c0f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">好吧，但是这里实际发生的事情。这就是如何将Spark驱动程序部署到Kubernetes集群中的方法！让我们来看看这些参数，这样你就可以自己动手了:</p><ul class=""><li id="2777" class="lz ma iq ky b kz la lc ld lf mb lj mc ln md lr na mf mg mh bi translated">定义Kubernetes集群(使用kubectl cluster-info查找)。是的，需要有点怪异的k8s://前缀。</li><li id="fce3" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr na mf mg mh bi translated">定义部署模式(集群，duh)</li><li id="26ee" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr na mf mg mh bi translated">定义Spark Driver的名称(这也是您的pod名称的开头)</li><li id="e386" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr na mf mg mh bi translated">定义火花Pi示例</li><li id="f88e" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr na mf mg mh bi translated">在Kubernetes上运行Spark Executor，其中有2个副本将由Spark驱动程序生成</li><li id="0b7e" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr na mf mg mh bi translated">使用我们的本地火花:最新图像</li><li id="9d10" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr na mf mg mh bi translated">将Kubernetes映像提取策略定义为Never，这样就可以使用具有该名称的本地映像。如果你不太熟悉k8s的内部工作原理，这肯定需要一分钟才能弄明白…</li><li id="fbe9" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr na mf mg mh bi translated">定义服务客户(还记得RBAC吗？)</li><li id="6803" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr na mf mg mh bi translated">指向带有参数10000000的本地jar路径(它与other文件中的所有其他示例一起被复制到指定的路径中)(如果您不知道这个数字的用途，请查看Spark Pi源代码和文档)。是的，local:///是正确的，而且不是错别字。</li></ul><pre class="kg kh ki kj gt mn mo mp mq aw mr bi"><span id="8237" class="ms mt iq mo b gy mu mv l mw mx">kubectl get pods</span></pre><p id="0880" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在应该会返回一个正在运行的pod列表！不要担心它们最终被终止——这是这个实现的默认设置。</p><p id="ed60" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">第五步:使用端口转发显示Spark UI </strong></p><pre class="kg kh ki kj gt mn mo mp mq aw mr bi"><span id="104e" class="ms mt iq mo b gy mu mv l mw mx">kubectl port-forward &lt;insert spark driver pod name&gt; 4040:4040</span></pre><p id="73fb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，您应该能够在浏览器中通过上面的第一个命令使用localhost:4040访问Spark UI，如下所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nb"><img src="../Images/b96d7ec6405aee62c07d2577360ad51e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iagJPWMu4gnh1qcl5LK5rg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">这是我的localhost:4040带端口转发的截图</p></figure><p id="cdcd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您也可以像这样查看您的日志:</p><pre class="kg kh ki kj gt mn mo mp mq aw mr bi"><span id="9309" class="ms mt iq mo b gy mu mv l mw mx">kubectl -n=default logs -f &lt;insert spark driver pod name&gt;</span></pre><p id="d517" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">结论</strong></p><p id="aa6e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您非常了解Spark和Kubernetes，那么使用配置文件和docker文件进行这种精确的设置可能会非常简单，如果您不了解，那么这可能会是一场噩梦。我希望这将有助于你在几分钟内做到这一点！</p><p id="3973" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你从这里去哪里？任何你想去的地方。本文的目标是让您快速使用一个新的Spark资源管理器。我建议你下一步用其他Spark应用程序来试验这个设置——我可能会在将来写一篇关于一些更复杂的例子的文章(如果我应该的话，请告诉我)。</p><p id="2275" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">和Kubernetes玩得开心！</p><p id="961f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">替代品</strong></p><p id="1c27" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是2020年4月20日的更新，您也可以使用Google的原生Kubernetes操作器，它似乎很有前途，可以将手动部署步骤删除到您的集群中:</p><div class="nc nd gp gr ne nf"><a href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator" rel="noopener  ugc nofollow" target="_blank"><div class="ng ab fo"><div class="nh ab ni cl cj nj"><h2 class="bd ir gy z fp nk fr fs nl fu fw ip bi translated">Google cloud platform/spark-on-k8s-运营商</h2><div class="nm l"><h3 class="bd b gy z fp nk fr fs nl fu fw dk translated">这不是官方支持的谷歌产品。如果您目前正在使用v1beta1版本的API，请…</h3></div><div class="nn l"><p class="bd b dl z fp nk fr fs nl fu fw dk translated">github.com</p></div></div><div class="no l"><div class="np l nq nr ns no nt kp nf"/></div></div></a></div><p id="9476" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">它目前正被Salesforce和微软等公司用于生产，并且正在被优步和Lyft用于生产评估。未来要注意的事情！</p></div></div>    
</body>
</html>