# ä¸è¦åœç•™åœ¨é›†åˆä¸Šâ€”â€”é’ˆå¯¹è¡¨æ ¼æ•°æ®çš„éå¸¸è§„æ·±åº¦å­¦ä¹ æŠ€æœ¯

> åŸæ–‡ï¼š<https://towardsdatascience.com/dont-stop-at-ensembles-unconventional-deep-learning-techniques-for-tabular-data-8d4e154f1053?source=collection_archive---------22----------------------->

## ä½¿ç”¨æ·±åº¦å­¦ä¹ å­¦ä¹ è¡¨æ ¼æ•°æ®çš„é™ç»´ã€å»å™ªå’Œåˆæˆæ•°æ®ç”Ÿæˆ

![](img/36687af38dc5ef73251c7f2b173acade.png)

ç”± [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šçš„ [chuttersnap](https://unsplash.com/@chuttersnap?utm_source=medium&utm_medium=referral) æ‹æ‘„

è¿‘å¹´æ¥ï¼Œæ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰å’Œè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸå–å¾—äº†å·¨å¤§è¿›å±•ã€‚å› æ­¤ï¼Œæ·±åº¦å­¦ä¹ æŠ€æœ¯é€šå¸¸å±€é™äºå›¾åƒæ•°æ®æˆ–åºåˆ—(æ–‡æœ¬)æ•°æ®ã€‚è¡¨æ ¼æ•°æ®å‘¢ï¼Ÿå¯¹äºä¸šåŠ¡ç”¨ä¾‹æ¥è¯´ï¼Œè®¸å¤šç»„ç»‡ä¸­ä¼ ç»Ÿçš„ä¿¡æ¯å­˜å‚¨å’Œæ£€ç´¢æ–¹æ³•æ— ç–‘æ˜¯æœ€é‡è¦çš„ã€‚ä½†æˆ‘ä»¬è¡¨æ ¼/æ•°æ®æ¡†æ¶ä¸­çš„æ•°æ®ä¼¼ä¹æ»¡è¶³äºåœ¨æ·±åº¦å­¦ä¹ é¢†åŸŸä½¿ç”¨ç®€å•çš„å¤šå±‚å‰é¦ˆç½‘ç»œã€‚è™½ç„¶æœ‰äººè®¤ä¸ºé€’å½’ç¥ç»ç½‘ç»œ(RNNs)é€šå¸¸ç”¨äºè¡¨æ ¼æ—¶é—´åºåˆ—æ•°æ®ï¼Œä½†è¿™äº›æ–¹æ³•åœ¨æ²¡æœ‰æ—¶é—´åºåˆ—æˆåˆ†çš„æ•°æ®ä¸Šçš„åº”ç”¨éå¸¸æœ‰é™ã€‚åœ¨è¿™ç¯‡åšå®¢æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹çœ‹ä¸€äº›æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„åº”ç”¨ï¼Œé€šå¸¸ç”¨äºå›¾åƒæˆ–æ–‡æœ¬æ•°æ®ï¼Œåœ¨éæ—¶é—´åºåˆ—è¡¨æ ¼æ•°æ®ä¸Šï¼Œåœ¨ä¼ ç»Ÿçš„é€’å‡æ°´å¹³ä¸Šã€‚

# ç”¨äºé™ç»´çš„è‡ªåŠ¨ç¼–ç å™¨

ä¼ ç»Ÿä¸Šï¼Œè‡ªåŠ¨ç¼–ç å™¨å·²ç»è¢«ç”¨äºéçº¿æ€§ç»´åº¦å‡å°‘ã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªæ•°æ®é›†ï¼Œå…¶ä¸­çš„è¦ç´ æ•°é‡è¿œè¿œè¶…è¿‡æˆ‘ä»¬çš„æœŸæœ›ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è‡ªåŠ¨ç¼–ç å™¨é€šè¿‡å¤æ‚çš„éçº¿æ€§å‡½æ•°å°†è¦ç´ é›†è°ƒæ•´åˆ°æ‰€éœ€çš„è¦ç´ å¤§å°ï¼Œæˆ‘ä»¬ä¸å¿…æ‹…å¿ƒï¼ä¸çº¿æ€§é™ç»´æ–¹æ³•å¦‚ PCA(ä¸»æˆåˆ†åˆ†æ)æˆ–å…¶ä»–ä¼ ç»Ÿçš„éçº¿æ€§æŠ€æœ¯å¦‚ LLE(å±€éƒ¨çº¿æ€§åµŒå…¥)ç›¸æ¯”ï¼Œè¿™æ˜¯ä¸€ç§æ›´æœ‰æ•ˆçš„æŠ€æœ¯ã€‚

![](img/fd92f211fb6b86740bd1a3676a825a6f.png)

è‡ªåŠ¨ç¼–ç å™¨ç»“æ„([æ¥æº](/generating-images-with-autoencoders-77fd3a8dd368))

è‡ªåŠ¨ç¼–ç å™¨åœ¨æ²¡æœ‰ä»»ä½•æ ‡ç­¾çš„è®­ç»ƒç‰¹å¾é›†ä¸Šè¢«è®­ç»ƒï¼Œå³ï¼Œæ— è®ºè¾“å…¥æ˜¯ä»€ä¹ˆï¼Œå®ƒä»¬éƒ½è¯•å›¾é¢„æµ‹è¾“å‡ºã€‚å¦‚æœéšè—å±‚è¶³å¤Ÿå®½ï¼Œå¯ä»¥æ•è·æ‰€æœ‰çš„è¾“å…¥æ•°æ®ï¼Œè¿™å°†æ˜¯ä¸€ä¸ªç®€å•çš„ä»»åŠ¡ã€‚å› æ­¤ï¼Œå¯¹äºä½œä¸ºè‡ªåŠ¨ç¼–ç å™¨çš„ç¥ç»ç½‘ç»œçš„è¦æ±‚æ˜¯ï¼Œè‡³å°‘æœ‰ä¸€å±‚ï¼Œå³ç“¶é¢ˆå±‚ï¼Œå…·æœ‰æ¯”è¾“å…¥æˆ–è¾“å‡ºç»´åº¦æ›´ä½çš„ç»´åº¦ã€‚è¿™é€šå¸¸æ˜¯æˆ‘ä»¬æƒ³è¦ä½¿ç”¨çš„åµŒå…¥å±‚æˆ–ç¼©å‡çš„ç‰¹æ€§é›†ã€‚è®­ç»ƒç½‘ç»œæ—¶çš„åº¦é‡å¯ä»¥æ˜¯é€šå¸¸çš„å‡æ–¹è¯¯å·®æˆ–å¹³å‡ç»å¯¹è¯¯å·®ã€‚å¦‚æœåŸå§‹æ•°æ®æ˜¯ *x* å¹¶ä¸”è‡ªåŠ¨ç¼–ç å™¨ç”Ÿæˆçš„é‡æ„è¾“å‡ºæ˜¯ *x_hatï¼Œ*æˆ‘ä»¬è¯•å›¾æœ€å°åŒ–

> L(xï¼Œx_hat) = |x â€” x_hat|

åœ¨ä¸€èµ·è®­ç»ƒç½‘ç»œçš„ç¼–ç å™¨å’Œè§£ç å™¨éƒ¨åˆ†ä¹‹åï¼Œæˆ‘ä»¬ä»…ä½¿ç”¨æ¨¡å‹çš„ç¼–ç å™¨éƒ¨åˆ†ä½œä¸ºæˆ‘ä»¬çš„ç»´åº¦å‡å°‘/ç‰¹å¾æå–ç®—æ³•ã€‚Keras ä¸­çš„ç¤ºä¾‹ä»£ç å¦‚ä¸‹:

```
from keras.layers import Dense, Dropout
from keras.models import Sequential, Model
from keras import metrics, InputMETRICS = [
    metrics.RootMeanSquaredError(name='rms'),
    metrics.MeanAbsoluteError(name='mae')
]ENCODING_DIM = 16 #Desired Dimension
BATCH_SIZE = 64
EPOCHS = 100def make_and_train_autoencoder(X_train, metrics=METRICS):

    len_input_output = X_train.shape[-1]
    input_ = Input(shape=(len_input_output,))
    encoded = Dense(units=ENCODING_DIM*2, activation="relu")(input_)
    bottleneck = Dense(units=ENCODING_DIM, 
                       activation="relu")(encoded)
    decoded = Dense(units=ENCODING_DIM*2, 
                    activation="relu")(bottleneck)
    output = Dense(units=len_input_output, 
                    activation="linear")(decoded)
    #Training is performed on the entire autoencoder
    autoencoder = Model(inputs=input_, outputs=output)
    autoencoder.compile(optimizer='adam', loss='mean_squared_error',
                        metrics=[metrics])
    autoencoder.fit(X_train, X_train,
                    batch_size=BATCH_SIZE,
                    epochs=EPOCHS)
    #Use only the encoder part for dimensionality reduction
    encoder = Model(inputs=input_, outputs=bottleneck)
    return autoencoder, encoder
```

# ç”¨äºé™å™ªçš„å»å™ªè‡ªåŠ¨ç¼–ç å™¨

![](img/bf64f7d171ba042d1a1f0dbd26d2d428.png)

MNIST ä¸Šçš„å»å™ªè‡ªåŠ¨ç¼–ç å™¨ç¤ºä¾‹([æ¥æº](/applied-deep-learning-part-3-autoencoders-1c083af4d798)

å»å™ªè‡ªåŠ¨ç¼–ç å™¨çš„çµæ„Ÿæ¥è‡ªè®¡ç®—æœºè§†è§‰é¢†åŸŸã€‚å¦‚ä¸Šæ‰€è¿°ï¼Œå®ƒä»¬å¯ç”¨äºæ¶ˆé™¤è¾“å…¥æ•°æ®ä¸­çš„å™ªå£°ã€‚å»å™ªè‡ªåŠ¨ç¼–ç å™¨(DAE)å¯ä»¥ç±»ä¼¼åœ°ç”¨äºè¡¨æ ¼æ•°æ®ï¼Œå› ä¸ºå¤§å¤šæ•°æ•°æ®æ”¶é›†è¿‡ç¨‹å›ºæœ‰åœ°å…·æœ‰ä¸€äº›å™ªå£°ã€‚è¿™é¡¹æŠ€æœ¯å·²è¢«è¯æ˜æ˜¯è®¸å¤š Kaggle æ¯”èµ›è·èƒœè§£å†³æ–¹æ¡ˆçš„å…³é”®( [Porto Seguro çš„å®‰å…¨é©¾é©¶å‘˜é¢„æµ‹](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/44629))ã€‚ä¸è‡ªåŠ¨ç¼–ç å™¨ä¸åŒï¼ŒDAE ä¸éœ€è¦æ»¡è¶³å°†ç¼–ç å’Œè§£ç éƒ¨åˆ†è¿æ¥åˆ°ç½‘ç»œçš„è¦æ±‚ã€‚æ¢å¥è¯è¯´ï¼Œä¸å­˜åœ¨ç“¶é¢ˆï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œå®ƒåªæ˜¯ä¸€ä¸ªè¢«è®­ç»ƒç”¨æ¥æ¶ˆé™¤å™ªå£°çš„ç¥ç»ç½‘ç»œã€‚é‚£ä¹ˆé—®é¢˜æ¥äº†ï¼Œæˆ‘ä»¬å¦‚ä½•è®­ç»ƒç½‘ç»œï¼Ÿ

![](img/b54a61797d831a6edd14b1ef6c32660f.png)

å»å™ªè‡ªåŠ¨ç¼–ç å™¨çš„å·¥ä½œ([æ¥æº](http://psyyz10.github.io/2015/11/SDA/)

å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œæˆ‘ä»¬é¦–å…ˆç ´åè¾“å…¥æ•°æ® *x* ã€‚è¢«ç ´åçš„æ•°æ®ğ‘¥Ìƒé€šå¸¸æ˜¯é€šè¿‡æ·»åŠ é«˜æ–¯å™ªå£°æˆ–è€…é€šè¿‡å°†ä¸€äº›è¾“å…¥ç‰¹å¾å€¼è®¾ç½®ä¸ºé›¶è€Œè·å¾—çš„ã€‚è¿™æ˜¯æˆ‘ä»¬è¯•å›¾æ¨¡ä»¿æ•°æ®é›†ä¸­å™ªéŸ³çš„æ–¹å¼ã€‚ç„¶åï¼Œæˆ‘ä»¬è®©ğ‘¥Ìƒé€šè¿‡æˆ‘ä»¬è®¾è®¡çš„ DAEï¼Œä»¥è·å¾—é‡æ„çš„è¾“å‡º *x_hat* ï¼Œå…¶å°ºå¯¸ä¸è¾“å…¥ *x ç›¸åŒã€‚*æŸå¤±å‡½æ•°ç±»ä¼¼äºå¸¸è§çš„è‡ªåŠ¨ç¼–ç å™¨ã€‚DAE è¯•å›¾æœ€å°åŒ–è¾“å‡º *x_hat* å’ŒåŸå§‹æ•°æ® *xï¼Œ*ä¹‹é—´çš„å·®å¼‚ï¼Œä»è€Œä½¿å…¶èƒ½å¤Ÿæ¶ˆé™¤å™ªå£°çš„å½±å“å¹¶ä»æŸåçš„æ•°æ®ä¸­æå–ç‰¹å¾ã€‚ç¤ºä¾‹ä»£ç å¦‚ä¸‹:

```
#Change mean and scale of the noise according to your data
noise = np.random.normal(loc=0, scale=0.5, size=X_train.shape)
X_train_noisy = X_train + noiselen_input_output = X_train.shape[-1]def make_dae(metrics=METRICS):
    dae = Sequential([
        Dense(units=len_input_output*2, 
              activation="relu", input_shape=(len_input_output,)),
        Dropout(0.5), #Add dropout layers if required 
        Dense(units=len_input_output*2, activation="relu"),
        Dense(units=len_input_output*2, activation="relu"),
        Dense(units=len_input_output, activation="linear"),
    ])
    dae.compile(
        optimizer='adam', 
        loss='mean_squared_error',
        metrics=[metrics]
    )
    return daedae = make_dae()
history = dae.fit(
    X_train_noisy,
    X_train,
    batch_size = BATCH_SIZE,
    epochs = EPOCHS
    )
```

æˆ‘ä»¬é€šå¸¸åªåœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒå»å™ªè‡ªåŠ¨ç¼–ç å™¨ã€‚ä¸€æ—¦æ¨¡å‹è¢«è®­ç»ƒï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ DAE ä¼ é€’åŸå§‹æ•°æ® *x* å’Œæµ‹è¯•é›†ï¼Œæ¯”å¦‚è¯´ *x`* ,ä»¥è·å¾—æ•°æ®é›†çš„å»å™ªç‰ˆæœ¬ã€‚

# ä½¿ç”¨è¯­è¨€æ¨¡å‹çš„åˆæˆæ•°æ®ç”Ÿæˆ

æˆ‘ä»¬å¾ˆå¤šäººå¯èƒ½éƒ½é‡åˆ°è¿‡è‘—åçš„å­—ç¬¦çº§è¯­è¨€æ¨¡å‹ï¼Œç”¨äºç”Ÿæˆç±»ä¼¼èå£«æ¯”äºšçš„æ–‡æœ¬ã€‚å¦‚æœæˆ‘ä»¬åœ¨è®­ç»ƒæ•°æ®(CSV/txt æ ¼å¼)ä¸Šè®­ç»ƒä¸€ä¸ªè¯­è¨€æ¨¡å‹ä¼šæ€ä¹ˆæ ·ï¼Ÿé¦–è¦é—®é¢˜æ˜¯ï¼Œæˆ‘ä»¬ä¸ºä»€ä¹ˆè¦è¿™ä¹ˆåšï¼Ÿç®€å•çš„ç­”æ¡ˆæ˜¯â€”â€”æ•°æ®ä¸å¹³è¡¡ã€‚å¤§å¤šæ•°çœŸå®æ•°æ®é›†åœ¨æ¯ä¸ªç±»/æ ‡ç­¾çš„è®­ç»ƒæ ·æœ¬æ•°é‡ä¸Šæœ‰å¾ˆå¤§å·®å¼‚ã€‚ä»¥æ¬ºè¯ˆæ£€æµ‹ä¸ºä¾‹ã€‚åªæœ‰å¤§çº¦ 0.05%çš„äº¤æ˜“æ˜¯æ¬ºè¯ˆæ€§çš„ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯èƒ½å¸Œæœ›ç”Ÿæˆæ›´å¤šçš„å°‘æ•°ç±»è®­ç»ƒç¤ºä¾‹æ¥è§£å†³ä¸å¹³è¡¡é—®é¢˜ã€‚

é€šè¿‡åœ¨æˆ‘ä»¬çš„å°‘æ•°æ°‘æ—ç±»æ•°æ®(ä»…ç‰¹å¾å€¼)ä¸Šè®­ç»ƒå­—ç¬¦çº§è¯­è¨€æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥ç”Ÿæˆç±»ä¼¼äºå°‘æ•°æ°‘æ—ç±»çš„è®°å½•ï¼Œå°±åƒæˆ‘ä»¬é€šè¿‡åœ¨ä¸€ç»„è¯—æ­Œä¸Šè®­ç»ƒæ¨¡å‹æ¥ç”Ÿæˆæ–‡æœ¬ä¸€æ ·ã€‚æˆ‘ä¸ä¼šæ·±å…¥ç ”ç©¶è§’è‰²çº§è¯­è¨€æ¨¡å‹çš„è®­ç»ƒå’Œé‡‡æ ·ç»†èŠ‚ï¼Œä½†æˆ‘é¼“åŠ±ä½ æµè§ˆä¸€ä¸‹å®‰å¾·çƒˆÂ·å¡å¸•è¥¿çš„åšå®¢(æˆ–è€… Coursera ä¸Šçš„ T2 åºåˆ—æ¨¡å‹è¯¾ç¨‹çš„ç¬¬ä¸€å‘¨)ã€‚

è°¢å¤©è°¢åœ°ï¼Œæœ‰åƒ [gretel-synthetics](https://github.com/gretelai/gretel-synthetics) è¿™æ ·çš„åº“ä¸ºæˆ‘ä»¬åšä¸Šè¿°å·¥ä½œï¼Gretel çš„å›¾ä¹¦é¦†ä¹Ÿæœ‰å…¶ä»–é€‰æ‹©ï¼Œå¦‚åœ¨ç”Ÿæˆçš„åˆæˆæ•°æ®é›†ä¸­å¯ç”¨å·®åˆ†éšç§ã€‚ä»–ä»¬çš„åšå®¢æ–‡ç« æ˜¯äº†è§£å’Œå­¦ä¹ ä»–ä»¬å›¾ä¹¦é¦†çš„å¥½æ–¹æ³•ã€‚ä»¥ä¸‹ç¤ºä¾‹ä»£ç å¯ç”¨äºç”Ÿæˆåˆæˆæ•°æ®å¸§:

```
!pip install gretel-synthetics --upgradefrom pathlib import Path
from gretel_synthetics.batch import DataFrameBatch
import pandas as pdsource_df = pd.read_csv("diabetic_data.csv") #File Pathconfig_template = {
    "max_lines": 20000,     # maximum lines of training data. Set to ``0`` to train on entire dataframe
    "max_line_len": 2048,   # the max line length for input training data
    "epochs": 15,           # Gretel recommends 15-50 epochs with GPU for best performance
    "vocab_size": 20000,    # tokenizer model vocabulary size
    "gen_lines": 100,       # the number of generated text lines
    "dp": True,             # train with differential privacy enabled (privacy assurances, but reduced accuracy)
    "field_delimiter": ",", # Must be specified
    "overwrite": True,
    "checkpoint_dir": str(Path.cwd() / "checkpoints")
}batcher = DataFrameBatch(df=source_df, config=config_template)
batcher.create_training_data()
batcher.train_all_batches()
status = batcher.generate_all_batch_lines()
synthetic_df = batcher.batches_to_df()
synthetic_df.head(10)
```

ä¸Šé¢è®¨è®ºçš„æ‰€æœ‰æ·±åº¦å­¦ä¹ æŠ€æœ¯éƒ½å±äºè‡ªæˆ‘ç›‘ç£æˆ–æ— ç›‘ç£å­¦ä¹ çš„èŒƒç•´ã€‚åœ¨ä¸ºæˆ‘ä»¬çš„åˆ†ç±»æˆ–å›å½’ä»»åŠ¡è®­ç»ƒå®é™…æ¨¡å‹ä¹‹å‰ï¼Œè¿™äº›é€šå¸¸è¢«ç”¨ä½œé¢„å¤„ç†æ­¥éª¤ã€‚è¿™äº›æ­¥éª¤çš„æœ‰æ•ˆæ€§å°†å–å†³äºæ‚¨æ‰‹å¤´çš„æ•°æ®å’Œå‚æ•°ï¼Œå¦‚æ‚¨å¸Œæœ›å¯¹è¯­è¨€æ¨¡å‹è¿›è¡Œå¤šé•¿æ—¶é—´çš„è®­ç»ƒï¼Œæˆ–è€…æ‚¨å¸Œæœ›åœ¨æ‚¨çš„ç‰¹å¾é›†ä¸­è¿›è¡Œå¤šå¤§ç¨‹åº¦çš„å‹ç¼©ã€‚

æ­å–œä½ åšæŒåˆ°äº†æ–‡ç« çš„æœ€åï¼å¸Œæœ›è¿™ç¯‡æ–‡ç« èƒ½å¤Ÿä¸ºæ‚¨æä¾›å¤„ç†è¡¨æ ¼æ•°æ®çš„åˆ›æ–°æ–¹æ³•ã€‚æ‰€ä»¥ï¼Œä¸‹æ¬¡ä½ è®¤ä¸º XGBoost æˆ– LightGBM å°±æ˜¯è¡¨æ ¼æ•°æ®çš„å…¨éƒ¨æ—¶ï¼Œè¯·ä¸‰æ€ï¼

è¯·ç»§ç»­å…³æ³¨ç±»ä¼¼çš„å¦ä¸€ç¯‡å¸–å­ï¼Œåœ¨é‚£é‡Œæˆ‘å°†è®¨è®ºåƒ[ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GANs)](https://arxiv.org/pdf/1406.2661.pdf) å’Œ[æ½œåœ¨ç‹„åˆ©å…‹é›·åˆ†é…(LDA)](http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf) è¿™æ ·çš„ç®—æ³•åœ¨è¡¨æ ¼æ•°æ®ä¸Šçš„åº”ç”¨ã€‚å’Œæˆ‘ä¸€èµ·è®©è¡¨æ ¼æ•°æ®å†æ¬¡å˜å¾—ä¼Ÿå¤§ï¼

æ¬¢è¿å¯¹å¸–å­å‘è¡¨è¯„è®ºæˆ–åœ¨ [LinkedIn](https://www.linkedin.com/in/sanghamesh-vastrad/) ä¸Šä¸æˆ‘è”ç³»ã€‚æœŸå¾…å¤§å®¶çš„åé¦ˆå’Œå»ºè®®ã€‚

**å‚è€ƒæ–‡çŒ®:**

[1] F. Cholletï¼ŒKeras åšå®¢ï¼Œã€https://blog.keras.io/building-autoencoders-in-keras.html ã€‚

[2] A .æ²ƒæ£®ï¼Œj .è¿ˆå°”æ–¯ï¼Œa .æ–¯æ³°å°”ï¼Œæ ¼é›·ç‰¹å°”.è‰¾åœ¨åŸ¹å…»åŸºä¸Šï¼Œ[https://medium.com/gretel-ai](https://medium.com/gretel-ai)ã€‚

[3] M. Jahrerï¼ŒKaggleï¼Œ[https://www . ka ggle . com/c/Porto-seguro-safe-driver-prediction/discussion/44629](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/44629)ã€‚