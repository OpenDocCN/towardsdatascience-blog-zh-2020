<html>
<head>
<title>Modelling tabular data with Google’s TabNet</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Google的TabNet对表格数据建模</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/modelling-tabular-data-with-googles-tabnet-ba7315897bfb?source=collection_archive---------2-----------------------#2020-01-26">https://towardsdatascience.com/modelling-tabular-data-with-googles-tabnet-ba7315897bfb?source=collection_archive---------2-----------------------#2020-01-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="62c2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">神经网络能打败经典方法吗？</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/3284c79d3bea7d0910593fb21c43e640.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XdWzjNDMmD-tnqvAI7p4TQ.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><a class="ae le" href="https://unsplash.com/@nci?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">国家癌症研究所</a>在<a class="ae le" href="https://unsplash.com/s/photos/research?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="50fd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="lf">2019年发布，谷歌研究的</em> <a class="ae le" href="https://github.com/google-research/google-research/tree/master/tabnet" rel="noopener ugc nofollow" target="_blank"> <em class="lf"> TabNet </em> </a> <em class="lf">在一篇</em> <a class="ae le" href="https://arxiv.org/abs/1908.07442" rel="noopener ugc nofollow" target="_blank"> <em class="lf">预印稿</em> </a> <em class="lf">中声称在表格数据上胜过现有方法。它是如何工作的，怎样才能尝试呢？</em></p><p id="bd45" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如今，表格数据可能构成了大部分业务数据。想想零售交易、点击流数据、工厂中的温度和压力传感器、银行使用的KYC(了解你的客户)信息，或者制药公司使用的模式生物的基因表达数据。品种简直是无穷无尽。</p><p id="a460" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在另一篇文章的<a class="ae le" rel="noopener" target="_blank" href="/modelling-tabular-data-with-catboost-and-node-929bfbaaeb08">中，我介绍了CatBoost，这是我最喜欢的在表格数据上建立预测模型的方法之一，以及它的神经网络对应物NODE。但是大约在NODE手稿出来的同时，Google Research发布了一份手稿，采用了一种完全不同的方法用神经网络进行表格数据建模。尽管NODE模仿决策树集成，但Google提出的TabNet试图建立一种适合表格数据的新型架构。</a></p><p id="ae74" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">描述这种方法的论文名为<a class="ae le" href="https://arxiv.org/pdf/1908.07442.pdf" rel="noopener ugc nofollow" target="_blank"> TabNet:专注的可解释表格学习</a>，它很好地总结了作者们试图做的事情。“网络”部分告诉我们，它是一种神经网络，“注意力”部分意味着它正在使用一种<a class="ae le" href="http://d2l.ai/chapter_attention-mechanisms/attention.html" rel="noopener ugc nofollow" target="_blank">注意力机制</a>，它的目标是可解释的，它用于对表格数据进行机器学习。</p><h2 id="aa39" class="lg lh it bd li lj lk dn ll lm ln dp lo kb lp lq lr kf ls lt lu kj lv lw lx ly bi translated">它是如何工作的？</h2><p id="2f27" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">TabNet使用一种软特征选择，只关注对于手头的例子重要的特征。这是通过连续的多步决策机制实现的。也就是说，输入信息是分几个步骤自顶向下处理的。正如手稿所述，“<em class="lf">顺序形式的自上而下注意的想法是受其在处理视觉和语言数据中的应用的启发，如视觉问题回答(Hudson &amp; Manning，2018年)或强化学习(Mott等人，2019年)，同时在高维输入中搜索相关信息的子集。</em></p><p id="9450" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">执行这种顺序注意的构建块被称为<a class="ae le" href="http://d2l.ai/chapter_attention-mechanisms/transformer.html" rel="noopener ugc nofollow" target="_blank">变压器块</a>，即使它们与流行的NLP模型中使用的变压器有点不同，如<a class="ae le" href="http://jalammar.github.io/illustrated-bert/" rel="noopener ugc nofollow" target="_blank"> BERT </a>。这些变形金刚使用自我关注，并试图模拟句子中不同单词之间的依赖关系。这里使用的转换器类型试图通过使用<a class="ae le" href="https://arxiv.org/abs/1602.02068" rel="noopener ugc nofollow" target="_blank"> sparsemax </a>函数完成的“软”特征选择，逐步消除那些与当前示例不相关的特征。</p><p id="e3f3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">论文中的第一张图，复制如下，描绘了信息是如何被聚合以形成预测的。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi me"><img src="../Images/55ec13b430d9c7bef54e0c0188e2536d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xGrnkDqPkDmC_MWS"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图片来自<a class="ae le" href="https://arxiv.org/abs/1908.07442" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1908.07442</a></p></figure><p id="d1f5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">TabNet的一个很好的特性是它不需要特征预处理(与例如节点相反)。另一个原因是，它具有“免费”内置的可解释性，为每个示例选择最相关的功能。这意味着您不必应用外部解释模块，如<a class="ae le" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank"> shap </a>或<a class="ae le" href="https://github.com/marcotcr/lime" rel="noopener ugc nofollow" target="_blank"> LIME </a>。</p><p id="073a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当阅读这篇文章时，不太容易理解这个架构内部发生了什么，但幸运的是有<a class="ae le" href="https://github.com/google-research/google-research/blob/master/tabnet/tabnet_model.py" rel="noopener ugc nofollow" target="_blank">发布的代码</a>稍微澄清了一些事情，并表明它没有你想象的那么复杂。</p><h1 id="5ce1" class="mf lh it bd li mg mh mi ll mj mk ml lo mm mn mo lr mp mq mr lu ms mt mu lx mv bi translated">怎么用？</h1><p id="c937" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated"><em class="lf">2020年3月9日新增:</em></p><p id="8932" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在TabNet有了比下面描述的更好的接口:一个用于 <a class="ae le" href="https://github.com/dreamquark-ai/tabnet/" rel="noopener ugc nofollow" target="_blank"> <em class="lf"> PyTorch </em> </a> <em class="lf">，它有一个类似scikit-learn的接口，一个用于</em><a class="ae le" href="https://github.com/mgrankin/fast_tabnet" rel="noopener ugc nofollow" target="_blank"><em class="lf">FastAI</em></a><em class="lf">。</em></p><h2 id="787a" class="lg lh it bd li lj lk dn ll lm ln dp lo kb lp lq lr kf ls lt lu kj lv lw lx ly bi translated">原始的TabNet代码和我的修改</h2><p id="ad70" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">正如已经提到的，代码是<a class="ae le" href="https://github.com/google-research/google-research/tree/master/tabnet" rel="noopener ugc nofollow" target="_blank">可用的</a>，作者展示了如何将它与<a class="ae le" href="https://archive.ics.uci.edu/ml/datasets/covertype" rel="noopener ugc nofollow" target="_blank">森林覆盖类型数据集</a>一起使用。为了方便起见，他们提供了三个特定于数据集的文件:一个文件下载并准备数据(<a class="ae le" href="https://github.com/google-research/google-research/blob/master/tabnet/download_prepare_covertype.py" rel="noopener ugc nofollow" target="_blank">download _ prepare _ cover type . py</a>)，另一个文件定义适当的Tensorflow特征列和CSV阅读器输入函数(<a class="ae le" href="https://github.com/google-research/google-research/blob/master/tabnet/data_helper_covertype.py" rel="noopener ugc nofollow" target="_blank">data _ helper _ cover type . py</a>)，以及包含训练循环的文件(<a class="ae le" href="https://github.com/google-research/google-research/blob/master/tabnet/experiment_covertype.py" rel="noopener ugc nofollow" target="_blank">experiment _ cover type . py</a>)。</p><p id="01be" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">回购自述文件指出:</p><blockquote class="mw mx my"><p id="7403" class="jq jr lf js b jt ju jv jw jx jy jz ka mz kc kd ke na kg kh ki nb kk kl km kn im bi translated">要将实验修改为其他表格数据集:</p><p id="53d4" class="jq jr lf js b jt ju jv jw jx jy jz ka mz kc kd ke na kg kh ki nb kk kl km kn im bi translated">-替换“data/”目录下的train.csv、val.csv和test.csv文件。</p><p id="68e4" class="jq jr lf js b jt ju jv jw jx jy jz ka mz kc kd ke na kg kh ki nb kk kl km kn im bi translated">-用新数据集的数字和分类特征修改data_helper函数，</p><p id="2d16" class="jq jr lf js b jt ju jv jw jx jy jz ka mz kc kd ke na kg kh ki nb kk kl km kn im bi translated">-重新优化新数据集的TabNet超参数。</p></blockquote><p id="e21d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在用其他数据集经历了几次这个过程之后，我决定编写自己的包装器代码来简化这个过程。这个代码，我必须强调是一个完全非官方的分叉，在<a class="ae le" href="https://github.com/hussius/tabnet_fork" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上。</p><p id="0e4c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">根据上面的自述文件:</p><ol class=""><li id="549a" class="nc nd it js b jt ju jx jy kb ne kf nf kj ng kn nh ni nj nk bi translated">与其为每个数据集创建新的train.csv、val.csv和test.csv文件，我更喜欢读取整个数据集并在内存中进行拆分(当然，只要可行)，所以我在代码中为Pandas编写了一个新的输入函数。</li><li id="4915" class="nc nd it js b jt nl jx nm kb nn kf no kj np kn nh ni nj nk bi translated">修改data_helper.py文件可能需要一些工作，至少在开始时，当您不太确定它做什么以及应该如何定义特性列时(我就是这种情况)。还有许多参数需要更改，但这些参数在主训练循环文件中，而不是在数据帮助文件中。鉴于此，我还试图在我的代码中概括和简化这个过程。</li><li id="4e0c" class="nc nd it js b jt nl jx nm kb nn kf no kj np kn nh ni nj nk bi translated">我添加了一些快速和肮脏的代码来进行超参数优化，但到目前为止只用于分类。</li><li id="5a55" class="nc nd it js b jt nl jx nm kb nn kf no kj np kn nh ni nj nk bi translated">还值得一提的是，作者的示例代码只显示了如何进行分类，而不是回归，因此额外的代码也必须由用户编写。我已经添加了回归功能和简单的均方误差损失。</li></ol><h1 id="c5f8" class="mf lh it bd li mg mh mi ll mj mk ml lo mm mn mo lr mp mq mr lu ms mt mu lx mv bi translated">使用命令行界面</h1><p id="72d0" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">执行如下命令:</p><pre class="kp kq kr ks gt nq nr ns nt aw nu bi"><span id="b3c6" class="lg lh it nr b gy nv nw l nx ny">python train_tabnet.py \<br/>  --csv-path data/adult.csv \<br/>  --target-name "&lt;=50K" \<br/>  --categorical-features workclass,education,marital.status,\<br/>occupation,relationship,race,sex,native.country\<br/>  --feature_dim 16 \<br/>  --output_dim 16 \<br/>  --batch-size 4096 \<br/>  --virtual-batch-size 128 \<br/>  --batch-momentum 0.98 \<br/>  --gamma 1.5 \<br/>  --n_steps 5 \<br/>  --decay-every 2500 \<br/>  --lambda-sparsity 0.0001 \<br/>  --max-steps 7700</span></pre><p id="dfdc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">强制参数是<code class="fe nz oa ob nr b">— -csv-path</code>(指向CSV文件的位置)、<code class="fe nz oa ob nr b">--target-name</code>(带有预测目标的列的名称)和<code class="fe nz oa ob nr b">--categorical-featues</code>(应该被视为分类的特征的逗号分隔列表)。其余的输入参数是超参数，需要针对每个特定问题进行优化。不过，上面显示的值直接取自TabNet手稿，因此作者已经针对成人人口普查数据集对它们进行了优化。</p><p id="1460" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">默认情况下，训练过程会将信息写入您执行脚本的位置的tflog子文件夹中。您可以将tensorboard指向此文件夹，查看训练和验证统计数据:</p><pre class="kp kq kr ks gt nq nr ns nt aw nu bi"><span id="2c40" class="lg lh it nr b gy nv nw l nx ny">tensorboard --logdir tflog</span></pre><p id="e8bd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">并将您的网络浏览器指向<code class="fe nz oa ob nr b">localhost:6006</code>。</p><h1 id="42dd" class="mf lh it bd li mg mh mi ll mj mk ml lo mm mn mo lr mp mq mr lu ms mt mu lx mv bi translated">如果你没有GPU…</h1><p id="6efc" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">…你可以试试<a class="ae le" href="https://colab.research.google.com/drive/1AWnaS6uQVDw0sdWjfh-E77QlLtD0cpDa" rel="noopener ugc nofollow" target="_blank">这款合作笔记本</a>。请注意，如果您想查看Tensorboard日志，您最好的选择可能是<a class="ae le" href="https://medium.com/@robertjohn_15390/introduction-to-google-cloud-storage-e806d7341340" rel="noopener">创建一个Google存储桶</a>，并让脚本在那里写入日志。这是通过使用<code class="fe nz oa ob nr b">tb-log-location</code>参数完成的。例如，如果您的bucket的名称是<code class="fe nz oa ob nr b">camembert-skyscrape</code>，您可以将<code class="fe nz oa ob nr b">--tb-log-location gs://camembert-skyscraper</code>添加到脚本的调用中。(不过，请注意，您必须<a class="ae le" href="https://glaforge.appspot.com/article/tip-making-a-google-cloud-storage-bucket-or-file-public" rel="noopener ugc nofollow" target="_blank">正确设置存储桶</a>的权限。这可能有点麻烦。)</p><p id="f5ed" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后，您可以从自己的本地计算机将tensorboard指向该桶:</p><p id="0dc2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><code class="fe nz oa ob nr b">tensorboard --logdir gs://camembert-skyscraper</code></p><h1 id="6fbe" class="mf lh it bd li mg mh mi ll mj mk ml lo mm mn mo lr mp mq mr lu ms mt mu lx mv bi translated">超参数优化</h1><p id="c299" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">在repo中还有一个进行超参数优化的快速而肮脏的脚本(<a class="ae le" href="https://github.com/hussius/tabnet_fork/blob/master/opt_tabnet.py" rel="noopener ugc nofollow" target="_blank"> opt_tabnet.py </a>)。同样，在<a class="ae le" href="https://colab.research.google.com/drive/1AWnaS6uQVDw0sdWjfh-E77QlLtD0cpDa" rel="noopener ugc nofollow" target="_blank">合作笔记本</a>中显示了一个例子。到目前为止，该脚本仅适用于分类，值得注意的是，一些训练参数仍然是硬编码的，尽管它们实际上不应该是硬编码的(例如，早期停止的耐心参数[在最佳验证准确性没有提高的情况下，您继续多少步]。)</p><p id="ecf2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在优化脚本中变化的参数是N_steps、feature_dim、batch-momentum、gamma、lambda-sparsity。(output_dim被设置为等于feature_dim，正如下面的优化提示中所建议的。)</p><p id="32d1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">本文提供了以下关于超参数优化的提示:</p><blockquote class="mw mx my"><p id="ed5b" class="jq jr lf js b jt ju jv jw jx jy jz ka mz kc kd ke na kg kh ki nb kk kl km kn im bi translated">大多数数据集产生N_steps ∈ [3，10]的最佳结果。通常，更大的数据集和更复杂的任务需要更大的N_steps。非常高的N_steps值可能遭受过度拟合，并且产生较差的泛化能力。</p><p id="e446" class="jq jr lf js b jt ju jv jw jx jy jz ka mz kc kd ke na kg kh ki nb kk kl km kn im bi translated">调整Nd [feature_dim]和Na [output_dim]的值是权衡性能和复杂度的最有效方法。对于大多数数据集，Nd = Na是一个合理的选择。非常高的Nd和Na值可能遭受过拟合，并且产生较差的概括。</p><p id="8b18" class="jq jr lf js b jt ju jv jw jx jy jz ka mz kc kd ke na kg kh ki nb kk kl km kn im bi translated">γ的最佳选择会对整体性能产生重大影响。通常，较大的N_steps值有利于较大的γ。</p><p id="7a6c" class="jq jr lf js b jt ju jv jw jx jy jz ka mz kc kd ke na kg kh ki nb kk kl km kn im bi translated">大批量有利于提高性能-如果内存限制允许，建议使用总训练数据集大小的1–10%。虚拟批量通常比批量小得多。</p><p id="b08a" class="jq jr lf js b jt ju jv jw jx jy jz ka mz kc kd ke na kg kh ki nb kk kl km kn im bi translated">最初大的学习速率是重要的，它应该逐渐衰减直到收敛。</p></blockquote><h1 id="8543" class="mf lh it bd li mg mh mi ll mj mk ml lo mm mn mo lr mp mq mr lu ms mt mu lx mv bi translated">结果</h1><p id="840c" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">我已经通过这个命令行界面对几个数据集尝试了TabNet，包括我在关于NODE的<a class="ae le" rel="noopener" target="_blank" href="/modelling-tabular-data-with-catboost-and-node-929bfbaaeb08">帖子中使用的</a><a class="ae le" href="https://archive.ics.uci.edu/ml/datasets/Census+Income" rel="noopener ugc nofollow" target="_blank">成人人口普查数据集</a>和CatBoost ，原因可以在那个帖子中找到。方便的是，这个数据集也曾在TabNet手稿中使用过，作者展示了他们在那里找到的最佳参数设置。使用这些设置重复运行，我注意到最佳验证误差(和测试误差)往往在86%左右，<a class="ae le" rel="noopener" target="_blank" href="/modelling-tabular-data-with-catboost-and-node-929bfbaaeb08">类似于没有超参数调整的CatBoost】。作者在手稿中报告了85.7%的测试集性能。当我使用hyperopt进行超参数优化时，不出所料，我达到了大约86%的类似性能，尽管参数设置不同。</a></p><p id="deb8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于其他数据集，如扑克手数据集，TabNet据称以相当大的优势击败了其他方法。我还没有花太多时间在这上面，但是每个人当然都被邀请在各种数据集上尝试超参数优化的TabNet！</p><h1 id="e4a8" class="mf lh it bd li mg mh mi ll mj mk ml lo mm mn mo lr mp mq mr lu ms mt mu lx mv bi translated">结论</h1><p id="b0fd" class="pw-post-body-paragraph jq jr it js b jt lz jv jw jx ma jz ka kb mb kd ke kf mc kh ki kj md kl km kn im bi translated">TabNet是一个有趣的架构，似乎有希望用于表格数据分析。它直接对原始数据进行操作，并使用顺序注意机制来为每个示例执行显式特征选择。这个属性也给了它一种内置的可解释性。</p><p id="af7a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我试图通过编写一些包装代码来使TabNet更容易使用。下一步是在大范围的数据集上将它与其他方法进行比较。</p><p id="39db" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你有兴趣，请在你自己的数据集上试一试，或者发送拉请求，帮助我改进界面！</p></div></div>    
</body>
</html>