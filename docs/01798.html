<html>
<head>
<title>Building a Deep Learning Person Classifier</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建深度学习的人物分类器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-deep-learning-person-classifier-ecc55bd01048?source=collection_archive---------8-----------------------#2020-02-19">https://towardsdatascience.com/building-a-deep-learning-person-classifier-ecc55bd01048?source=collection_archive---------8-----------------------#2020-02-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3ce5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">准确识别人脸和非人脸的图像</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/e0d6ccd91a3b7bb36fc9ea5e2aa3d85d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*pKeqVMtcf07bXbVc"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@ryoji__iwata?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">岩田良治</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="3c26" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="74a5" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在<a class="ae ky" href="https://en.wikipedia.org/wiki/Machine_learning" rel="noopener ugc nofollow" target="_blank">机器学习</a>和<a class="ae ky" href="https://en.wikipedia.org/wiki/Statistics" rel="noopener ugc nofollow" target="_blank">统计</a>，<strong class="lt iu">分类</strong>是识别一个新的<a class="ae ky" href="https://en.wikipedia.org/wiki/Observation" rel="noopener ugc nofollow" target="_blank">观察值</a>属于一组<a class="ae ky" href="https://en.wikipedia.org/wiki/Categorical_data" rel="noopener ugc nofollow" target="_blank">类别</a>(子群体)中的哪一个的问题，其基于包含其类别成员已知的观察值(或实例)的数据的<a class="ae ky" href="https://en.wikipedia.org/wiki/Training_set" rel="noopener ugc nofollow" target="_blank">训练集</a>[1]。</p><p id="e20f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">“浅层”学习技术，如<a class="ae ky" href="https://en.wikipedia.org/w/index.php?title=Support-vector_machine&amp;oldid=940974287" rel="noopener ugc nofollow" target="_blank">支持向量机</a> (SVM)可以从中等大小的数据集产生有效的分类器，最近<a class="ae ky" href="https://en.wikipedia.org/w/index.php?title=Deep_learning&amp;oldid=940556767" rel="noopener ugc nofollow" target="_blank">深度学习</a>分类器已经在识别任务中与人类相匹敌，但需要更大的数据集和大量计算资源来实现这一点。特别是，深度学习技术已经产生了<a class="ae ky" href="https://en.wikipedia.org/w/index.php?title=Convolutional_neural_network&amp;oldid=940484524" rel="noopener ugc nofollow" target="_blank">卷积神经网络</a> (CNN)，这是最先进的图像分类器。</p><p id="b3f4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">本文将向您展示如何使用<a class="ae ky" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>开发一个基于CNN的个人分类器，它在某些情况下可以胜过标准的人脸识别技术。标准方法通常包括使用像SVM这样的浅层学习器来对面部嵌入生成的模式进行分类(例如，参见高超的<a class="ae ky" href="https://github.com/ageitgey/face_recognition" rel="noopener ugc nofollow" target="_blank">面部识别</a>程序)。)标准技术是<strong class="lt iu"> <em class="ms">极度</em> </strong>擅长在大部分人脸可见的情况下识别。然而，我的应用程序需要一种方法来准确地对只有部分面部视图的人进行分类，最好是从后面进行分类。这为使用深度学习开发一个人分类器提供了动力，我的目标是在看他们认识的人的图像时，无论有没有脸，都能达到和人类一样的识别精度。</p><p id="5666" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">需要以下步骤来构建准确的基于CNN的人分类器，该分类器识别新观察结果属于一组已知和未知人中的哪一个。这些步骤也适用于训练其他类型的基于CNN的分类器。</p><ol class=""><li id="e58e" class="mt mu it lt b lu mn lx mo ma mv me mw mi mx mm my mz na nb bi translated"><strong class="lt iu">收集你想要分类的每个人以及陌生人的图像，以创建你的训练集并对其进行预处理</strong>。您应该使用数据扩充方法，从收集的数据中自动生成相关的新图像，以增加数据集的大小。你的数据集很可能是不平衡的，也就是说，每一类的观察值并不相同。您将需要对此进行补偿，否则您的模型将过分强调具有更多观察值的类，其准确性将受到影响。最后，您的数据集需要转换成适合训练过程的数据格式。你应该为每堂课计划一个至少有1000个观察值的训练集。请注意，观察和样本这两个术语在本文中可以互换使用。</li><li id="132b" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm my mz na nb bi translated"><strong class="lt iu">选择已经在标准数据集上训练过的CNN，并将其用作将成为您的分类器的新模型中的一个层。</strong>标准数据集应包含类似于您想要分类的类别。在这种情况下，<a class="ae ky" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>是一个很好的选择，因为“人”(在一般意义上)已经是它被训练识别的一个类。TensorFlow提供了许多CNN模型，具有不同的复杂性和精确度。您应该选择能够满足您的应用程序的推理准确性要求的最简单的模型。当然，您可以对任何类似于ImageNet类的类进行微调，而不仅仅是人。</li><li id="0519" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm my mz na nb bi translated"><strong class="lt iu">使用您的图像数据</strong>在您的CNN上应用 <a class="ae ky" href="https://www.tensorflow.org/tutorials/images/transfer_learning" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">转移学习</strong> </a> <strong class="lt iu">。深度神经网络容易<a class="ae ky" href="https://www.tensorflow.org/tutorials/keras/overfit_and_underfit" rel="noopener ugc nofollow" target="_blank">过度拟合</a>，你将学习几种缓解技术来对抗它。请注意，迁移学习也称为微调，训练模型也称为将模型拟合到数据集。这些术语在本文中可以互换使用。</strong></li><li id="7605" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm my mz na nb bi translated"><strong class="lt iu">评估微调后的型号</strong>。您应该检查微调模型的准确性，看看它是否符合您的应用要求，如果不符合，则使用更多数据或更优的训练参数(“超参数”)重新调整它。</li><li id="7f87" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm my mz na nb bi translated"><strong class="lt iu">保存您的模型并为推理做准备</strong>。<a class="ae ky" href="https://www.tensorflow.org/guide/saved_model" rel="noopener ugc nofollow" target="_blank"> SavedModel </a>是保存和提供TensorFlow程序的标准方式，但是您可能还希望生成一个<a class="ae ky" href="https://www.tensorflow.org/lite" rel="noopener ugc nofollow" target="_blank"> TensorFlow Lite </a>表示，以便部署在移动或边缘设备上。两者都包括在下面。</li></ol><p id="7666" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">请注意，我使用了一台64GB主内存的英特尔i5 + Nvidia 1080Ti机器来训练我的模型。你至少需要一台类似的机器来可行地训练一个深度学习模型。</p><p id="9f30" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">另外，请注意，这些工作大部分是为<a class="ae ky" href="https://github.com/goruck/smart-zoneminder" rel="noopener ugc nofollow" target="_blank"><strong class="lt iu">smart-zone minder</strong></a>项目完成的，您可以利用这些工作。如果您只想快速微调TensorFlow CNN而不深入细节，<a class="ae ky" href="https://github.com/goruck/smart-zoneminder#machine-learning-platform-installation-on-linux-server" rel="noopener ugc nofollow" target="_blank">在合适的机器上安装机器学习平台</a>，按如下所述准备您的数据集，并运行Python程序<a class="ae ky" href="https://github.com/goruck/smart-zoneminder/blob/master/person-class/train.py" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> train.py </strong> </a>，其中包含适合您配置的选项。本文的其余部分将一节一节地对train.py进行分解，以帮助您理解它是如何工作的，从而更好地使用它，并可能根据您自己的需要对它进行修改。</p><h1 id="e918" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">数据集准备</h1><p id="2bcc" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在一个名为“数据集”的目录中，为你想要识别的每个人的图像创建一个子目录，并以该人的名字命名(我用我的Google photos作为这个目录的种子)。另外，创建一个名为“未知”的子目录，保存随机陌生人的面孔。在每个子目录中，您可以选择放置另一个子目录，该子目录可以保存没有完整或部分面部视图的人的图像。您可以决定将此类图像作为其类的成员或未知类。数据集目录将如下所示。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="ca32" class="nm la it ni b gy nn no l np nq">dataset<br/>    |-name_of_person_1<br/>        |-sample_image_1<br/>        |-sample_image_2<br/>        |-sample_image_n<br/>        |-images_with_no_face<br/>            |-sample_image_1<br/>            |-sample_image_2<br/>            |-sample_image_n<br/>    |-name_of_person_2<br/>    |-name_of_person_n<br/>    |-Unknown</span></pre><p id="1b68" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">下面的函数根据数据集的内容创建Python数据帧。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">从数据集创建数据帧</p></figure><p id="b54e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">dataframe是TF . keras . preprocessing . image . image data generator类的<a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_dataframe" rel="noopener ugc nofollow" target="_blank"> flow_from_dataframe </a>方法的输入。ImageDataGenerator通过实时数据扩充生成批量张量图像数据，并创建训练集和验证集。flow_from_dataframe方法为每个集合创建一个Python生成器。该代码如下所示。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">创建培训和验证生成器</p></figure><p id="d62d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">虽然可以直接使用train_generator和validation_generator来拟合CNN模型，但是使用来自<a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset" rel="noopener ugc nofollow" target="_blank"> tf.data.Dataset </a>的数据集对象将会给<a class="ae ky" href="https://www.tensorflow.org/guide/data_performance" rel="noopener ugc nofollow" target="_blank">更好的拟合性能</a>。在train.py中，这是按如下方式完成的。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">创建一个tf数据集</p></figure><p id="eab3" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">由于某些类别中的样本图像可能比其他类别中的多，因此您需要将类别权重传递给模型拟合过程。下面显示了实现这一点的代码，以及拟合过程用于训练和验证的步骤数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">确定类别权重和拟合步骤</p></figure><p id="c66d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这些数据现在可以用来拟合模型了。</p><h1 id="9870" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">模型准备</h1><p id="3161" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">下面的函数从一个<a class="ae ky" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>预训练的<a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/keras/applications" rel="noopener ugc nofollow" target="_blank"> tf.keras.applications </a>模型创建一个CNN模型。虽然该函数将基于VGG16、InceptionResNetV2、MobileNetV2和ResNet50创建模型，但只显示了InceptionResNetV2。从基本模型中移除最后的softmax层，添加新的密集分类器和softmax层，然后编译它。请特别注意超参数常数，因为它们可能需要调整以适应您的数据集，但默认值给我很好的结果。该函数包括各种过拟合缓解技术，包括<a class="ae ky" rel="noopener" target="_blank" href="/l1-and-l2-regularization-methods-ce25e7fc831c"> L2正则化</a>、<a class="ae ky" rel="noopener" target="_blank" href="/what-is-label-smoothing-108debd7ef06">标签平滑</a>和D <a class="ae ky" href="http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf" rel="noopener ugc nofollow" target="_blank"> ropout </a>。它还会选择一个适当的tf.keras预处理器来正确格式化数据样本。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Python函数来创建CNN模型</p></figure><p id="3771" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">该模型现在可以进行微调了。</p><h1 id="492b" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">模型微调</h1><p id="9f9f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">微调分两步完成。第一遍使用高学习率，并且只训练新添加的密集层和软最大层，因为它们是用随机数据初始化的。第二遍使用小得多的学习速率，并训练最后几层以及基本模型的大部分。两遍方案以及正则化被设计成尽可能多地保留来自基础模型的原始权重，同时仍然从新的数据集中学习模式。两次通过都使用<a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping" rel="noopener ugc nofollow" target="_blank">提前停止</a>基于验证损失，这是减轻过度拟合的另一种方法。</p><p id="a24f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">第一遍微调代码如下所示。请再次注意，只有新的层是适合的。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">微调的第一步</p></figure><p id="1ae7" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">微调的第二步如下所示。请注意，底部基础模型的一些层是冻结的，不会在此步骤中进行训练，但所有其他层都将进行训练。冻结的层数是一个超参数，它在保留根据ImageNet的高级功能训练的层与允许顶层学习数据集中的新功能之间保持平衡。尽管采取了所有缓解措施，解冻的图层越多，防止过度拟合所需的数据就越多。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">微调的第二步</p></figure><p id="e7a0" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">该模型现在已经过微调，将评估其准确性，并保存以供下一步进行推断。</p><h1 id="3da3" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">最终模型评估</h1><p id="6241" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">应该对您的模型进行评估，以确定其精度是否满足您的应用要求。从它的预测中生成一个<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html" rel="noopener ugc nofollow" target="_blank"> sklearn分类报告</a>就是这样做的一种方式，如下面的代码所示。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">生成分类报告</p></figure><p id="6df1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">下面显示了我的一次运行的分类报告示例。虽然我很高兴这个模型偏向于它的创造者；)，需要更多的工作来通过数据集中的额外观察和超参数优化来提高其他类的准确性。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">分类报告示例</p></figure><p id="e609" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">目前，我最好的结果是使用InceptionResNetV2基本模型，它实现了大约92%的整体准确性。我的目标是大于95%，这是我对正常人在有脸和无脸图像上所能实现的主观估计。作为比较，使用上述标准方法对于具有完整或大部分完整人脸视图的那些图像产生大约90%的准确度，而对于具有完整、部分人脸和没有人脸的相同数据集，准确度小于70%。</p><h1 id="6643" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">保存用于推理的模型</h1><p id="e6ce" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">train.py包括以各种方式保存模型的选项-冻结的TensorFlow程序(从TensorFlow 2开始不推荐使用)，针对物联网设备上的推理进行优化的八位量化TensorFlow Lite程序，针对谷歌的Edge TPU和TensorFlow SavedModel格式(从TensorFlow 2开始的规范方法)编译的TensorFlow Lite程序。下面的代码显示了train.py如何保存为SavedModel格式。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">将最终模型保存为SavedModel格式</p></figure><p id="c85d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">最终的模型现在已经准备好通过它的SavedModel或其他表示进行推理了。有关保存和使用边缘模型的更多细节，请参见<a class="ae ky" rel="noopener" target="_blank" href="/using-keras-on-googles-edge-tpu-7f53750d952">在谷歌边缘TPU </a>上使用Keras。</p><h1 id="2c4c" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">结论</h1><p id="c9f9" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">与用于训练基本模型的原始数据集相比，您可以利用TensorFlow通过中等大小的数据集快速微调CNN分类器，如上面的person分类器示例所示。来自<a class="ae ky" href="https://github.com/goruck/smart-zoneminder" rel="noopener ugc nofollow" target="_blank"><strong class="lt iu">smart-zone minder</strong></a>项目的Python程序<a class="ae ky" href="https://github.com/goruck/smart-zoneminder/blob/master/person-class/train.py" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> train.py </strong> </a>可以用来构建自己的分类器，或者作为开发自己程序的参考。</p><p id="7ef0" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">将深度学习模型拟合到有限的数据可能会很棘手，因为它们可以快速记住数据集，但不会很好地推广到新的观察结果，这就是所谓的过度拟合。为了减轻这种情况，您可以使用以下技术。</p><ul class=""><li id="382c" class="mt mu it lt b lu mn lx mo ma mv me mw mi mx mm nt mz na nb bi translated">收集更多的观察数据。</li><li id="dda8" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm nt mz na nb bi translated">数据增强。</li><li id="d06b" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm nt mz na nb bi translated">选择满足应用精度要求的最简单模型。</li><li id="840d" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm nt mz na nb bi translated">L2正规化。</li><li id="d7f7" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm nt mz na nb bi translated">辍学。</li><li id="5d2c" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm nt mz na nb bi translated">标签平滑。</li><li id="3476" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm nt mz na nb bi translated">阻止许多基础模型层被定型(“冻结”)。</li><li id="ef10" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm nt mz na nb bi translated">根据验证损失提前停止培训过程。</li></ul><p id="1ad1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">您还很可能不得不处理数据集中每个类的不同数量的样本(例如，不平衡的集合)，这将影响模型的准确性。为了进行补偿，您需要在模型拟合过程中使用类别权重。</p><p id="9b9f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">构建CNN分类器的步骤如下。</p><ol class=""><li id="1b96" class="mt mu it lt b lu mn lx mo ma mv me mw mi mx mm my mz na nb bi translated">收集和预处理您的数据集。</li><li id="5b28" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm my mz na nb bi translated">选择一个合适的CNN基本模型。</li><li id="708e" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm my mz na nb bi translated">微调模型。</li><li id="03e8" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm my mz na nb bi translated">评估您的微调模型的准确性。</li><li id="07d0" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm my mz na nb bi translated">准备您的最终模型进行推理，并保存它。</li></ol><h1 id="e322" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">参考</h1><p id="e5dd" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">[1] <a class="ae ky" href="https://en.wikipedia.org/w/index.php?title=Statistical_classification&amp;oldid=921296045" rel="noopener ugc nofollow" target="_blank">统计分类</a>，来自<em class="ms">维基百科，免费百科。</em></p></div></div>    
</body>
</html>