<html>
<head>
<title>Encoder-Decoder Model for Multistep Time Series Forecasting Using PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch多步时间序列预测的编解码模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/encoder-decoder-model-for-multistep-time-series-forecasting-using-pytorch-5d54c6af6e60?source=collection_archive---------3-----------------------#2020-06-08">https://towardsdatascience.com/encoder-decoder-model-for-multistep-time-series-forecasting-using-pytorch-5d54c6af6e60?source=collection_archive---------3-----------------------#2020-06-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/4084278dcd685ba7ff3445a0885646a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UtLG2Al5bybvrRYguEnh8w.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">丹尼尔·利维斯·佩鲁西在<a class="ae kf" href="https://unsplash.com/s/photos/time?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="62aa" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">编码器-解码器模型已经提供了像语言翻译等的序列到序列NLP任务的最新结果。多步时间序列预测也可以被视为seq2seq任务，为此可以使用编码器-解码器模型。本文提供了一个编码器-解码器模型来解决Kaggle的时间序列预测任务，以及获得前10%结果的步骤。</p><p id="4351" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">解决代码可以在我的<a class="ae kf" href="https://github.com/gautham20/pytorch-ts" rel="noopener ugc nofollow" target="_blank"> Github repo </a>中找到。模型实现的灵感来自于<a class="ae kf" href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html" rel="noopener ugc nofollow" target="_blank"> Pytorch seq2seq翻译教程</a>，时间序列预测思想主要来自于类似竞赛的<a class="ae kf" href="https://www.kaggle.com/c/web-traffic-time-series-forecasting/discussion/43795" rel="noopener ugc nofollow" target="_blank"> Kaggle获奖解决方案</a>。</p><div class="le lf gp gr lg lh"><a href="https://github.com/gautham20/pytorch-ts" rel="noopener  ugc nofollow" target="_blank"><div class="li ab fo"><div class="lj ab lk cl cj ll"><h2 class="bd iu gy z fp lm fr fs ln fu fw is bi translated">高森20/pytorch-ts</h2><div class="lo l"><h3 class="bd b gy z fp lm fr fs ln fu fw dk translated">使用编码器-解码器架构进行时间序列预测的教程- gautham20/pytorch-ts</h3></div><div class="lp l"><p class="bd b dl z fp lm fr fs ln fu fw dk translated">github.com</p></div></div><div class="lq l"><div class="lr l ls lt lu lq lv jz lh"/></div></div></a></div></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="bac6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用的数据集来自过去的Kaggle竞赛— <a class="ae kf" href="https://www.kaggle.com/c/demand-forecasting-kernels-only" rel="noopener ugc nofollow" target="_blank">商店商品需求预测挑战</a>，给定10家不同商店的50种商品过去5年的销售数据(从2013年到2017年)，预测未来3个月(2018年1月1日到2018年3月31日)每种商品的销售额。这是一个<strong class="ki iu">多步多站点时间序列预测</strong>问题。</p><figure class="me mf mg mh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi md"><img src="../Images/8b273817bf98c31e4e29e920b53aa653.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r5P0zkNcWFgRTB8672lTNw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">比赛</p></figure><p id="d27b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">提供的功能非常少:</p><figure class="me mf mg mh gt ju gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/fe09e8f3a2fefc843421502ce8b5f5c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:614/format:webp/1*yLsogG6jN7lJjk_KARvWuw.png"/></div></figure><p id="60f6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有500个独特的商店商品组合，这意味着我们预测500个时间序列。</p><figure class="me mf mg mh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mj"><img src="../Images/1f33bf111685d81ada949e2906f6b659.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zoM8_cAJzjzfpi0qz8UN4A.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">随机选择10件商品的销售图</p></figure><h1 id="979a" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">数据预处理</h1><h2 id="3525" class="ni ml it bd mm nj nk dn mq nl nm dp mu kr nn no my kv np nq nc kz nr ns ng nt bi translated">特征工程</h2><p id="0700" class="pw-post-body-paragraph kg kh it ki b kj nu kl km kn nv kp kq kr nw kt ku kv nx kx ky kz ny lb lc ld im bi translated">深度学习模型善于自己发现特征，因此可以将特征工程保持在最低限度。</p><p id="7a4f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从图中可以看出，我们的数据具有每周和每月的季节性和每年的趋势，为了捕捉这些，向模型提供了日期时间特征。为了更好地捕捉每个项目销售的年度趋势，还提供了年度自相关。</p><figure class="me mf mg mh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi gj"><img src="../Images/94a69e3f3e00319c1f63b56b19260b0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XYJ4Wr3nV_M532fzBNWClg.png"/></div></div></figure><p id="c3e8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这些功能中有许多实际上是循环的，为了向模型提供这些信息，对日期时间功能应用了正弦和余弦转换。这里可以找到为什么这是有益的详细解释— <a class="ae kf" href="https://ianlondon.github.io/blog/encoding-cyclical-features-24hour-time/" rel="noopener ugc nofollow" target="_blank">编码循环连续特征— 24小时时间</a></p><figure class="me mf mg mh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nz"><img src="../Images/60e949e20376705c320902d401811231.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5yYG24fC9wNzRUwhA7iSew.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">月份特征的正弦和余弦变换</p></figure><p id="59e6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以最终的特性如下所示。</p><figure class="me mf mg mh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oa"><img src="../Images/535c1e5c4afa020e3937fad918e4c4a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jeuL3uzdumma0HhIbohQlg.png"/></div></div></figure><h2 id="ed64" class="ni ml it bd mm nj nk dn mq nl nm dp mu kr nn no my kv np nq nc kz nr ns ng nt bi translated">数据缩放</h2><p id="ffe9" class="pw-post-body-paragraph kg kh it ki b kj nu kl km kn nv kp kq kr nw kt ku kv nx kx ky kz ny lb lc ld im bi translated">神经网络期望所有特征的值都在相同的尺度上，因此数据缩放成为强制性的。每个时间序列的值被独立地标准化。每年的自相关和年份也被归一化。</p><h2 id="2ea9" class="ni ml it bd mm nj nk dn mq nl nm dp mu kr nn no my kv np nq nc kz nr ns ng nt bi translated">序列构建</h2><p id="d77b" class="pw-post-body-paragraph kg kh it ki b kj nu kl km kn nv kp kq kr nw kt ku kv nx kx ky kz ny lb lc ld im bi translated">编码器-解码器模型将一个序列作为输入，并返回一个序列作为输出，因此我们拥有的平面数据帧必须转换成序列。</p><figure class="me mf mg mh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ob"><img src="../Images/d2d30fc7a84472c25c56580b4a9546ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SXBWjwem7u17z_aMWCxxQw.png"/></div></div></figure><p id="798f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">输出序列的长度固定为90天，以满足我们的问题要求。输入序列的长度必须根据问题的复杂性和可用的计算资源来选择。对于这个问题，选择180 (6个月)的输入序列长度。通过对数据集中的每个时间序列应用滑动窗口来构建序列数据。</p><h2 id="b868" class="ni ml it bd mm nj nk dn mq nl nm dp mu kr nn no my kv np nq nc kz nr ns ng nt bi translated">数据集和数据加载器</h2><p id="770e" class="pw-post-body-paragraph kg kh it ki b kj nu kl km kn nv kp kq kr nw kt ku kv nx kx ky kz ny lb lc ld im bi translated">Pytorch提供了方便的抽象——<a class="ae kf" href="https://pytorch.org/docs/stable/data.html?highlight=dataset#torch.utils.data.Dataset" rel="noopener ugc nofollow" target="_blank">数据集</a>和<a class="ae kf" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" rel="noopener ugc nofollow" target="_blank">数据加载器</a>——将数据输入模型。数据集将序列数据作为输入，并负责构建要提供给模型的每个数据点。它还处理提供给模型的不同类型的特征的处理，这部分将在下面详细解释。</p><figure class="me mf mg mh gt ju"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="cc4a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用dataloader将数据集中的数据点一起批处理并提供给模型。</p><h1 id="f2fc" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">模型架构</h1><p id="e21e" class="pw-post-body-paragraph kg kh it ki b kj nu kl km kn nv kp kq kr nw kt ku kv nx kx ky kz ny lb lc ld im bi translated">编码器-解码器模型是用于解决序列间问题的递归神经网络(RNN)的一种形式。编码器-解码器模型可以直观地理解如下。</p><p id="b0e6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">编码器-解码器模型由两个网络组成——编码器和解码器。编码器网络学习(编码)输入序列的一个<strong class="ki iu">表示</strong>，它捕捉其特征或上下文，并给出一个向量。这个向量被称为<strong class="ki iu">上下文向量</strong>。解码器网络接收上下文向量，并学习从中读取和提取(解码)输出序列。</p><p id="15e0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在编码器和解码器中，编码和解码序列的任务由一系列循环单元处理。解决方案中使用的循环单元是门控循环单元(GRU ),以解决短期记忆问题。关于这一点的更多信息可以在LSTM和GRU的插图指南中找到。</p><p id="25a2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面给出了解决方案中使用的模型的详细架构。</p><figure class="me mf mg mh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oe"><img src="../Images/5f9b006b81faeeec75e29887846223a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*62xsdc5F5DNdLXluQojeBg.png"/></div></div></figure><h2 id="64ae" class="ni ml it bd mm nj nk dn mq nl nm dp mu kr nn no my kv np nq nc kz nr ns ng nt bi translated">编码器</h2><p id="d0e8" class="pw-post-body-paragraph kg kh it ki b kj nu kl km kn nv kp kq kr nw kt ku kv nx kx ky kz ny lb lc ld im bi translated">编码器网络的输入具有<em class="of">(序列长度，n _值)</em>的形状，因此序列中的每一项由<em class="of"> n </em>个值组成。在构造这些值时，不同类型的特征被不同地对待。</p><p id="b7d6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">时间相关特性</strong> —这些是随时间变化的特性，例如销售和日期时间特性。在编码器中，每个顺序的时间相关值被馈送到RNN单元。</p><p id="953d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">数字特征</strong> —不随时间变化的静态特征，如序列的年度自相关。这些特征在整个序列中重复出现，并被输入RNN。重复输入和合并值的过程在数据集中处理。</p><p id="8566" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">分类特征</strong> —商店id和商品id等特征可以通过<a class="ae kf" href="https://datascience.stackexchange.com/questions/17099/adding-features-to-time-series-model-lstm/17139#17139" rel="noopener ugc nofollow" target="_blank">多种方式</a>进行处理，每种方式的实现可以在<a class="ae kf" href="https://github.com/gautham20/pytorch-ts/blob/master/ts_models/encoders.py" rel="noopener ugc nofollow" target="_blank"> encoders.py </a>中找到。对于最终的模型，分类变量是一次性编码的，在序列中重复，并输入到RNN中，这也在数据集中处理。</p><p id="3563" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">具有这些特征的输入序列被送入递归网络— <a class="ae kf" href="https://pytorch.org/docs/master/generated/torch.nn.GRU.html" rel="noopener ugc nofollow" target="_blank"> GRU </a>。下面给出了所使用的编码器网络的代码。</p><figure class="me mf mg mh gt ju"><div class="bz fp l di"><div class="oc od l"/></div></figure><h2 id="7a41" class="ni ml it bd mm nj nk dn mq nl nm dp mu kr nn no my kv np nq nc kz nr ns ng nt bi translated">解码器</h2><p id="de45" class="pw-post-body-paragraph kg kh it ki b kj nu kl km kn nv kp kq kr nw kt ku kv nx kx ky kz ny lb lc ld im bi translated">解码器从编码器接收上下文向量，此外，解码器的输入是未来日期时间特征和滞后特征。模型中使用的滞后特征是前一年的值。使用滞后特征背后的直觉是，考虑到输入序列限于180天，提供超过此时间范围的重要数据点将有助于模型。</p><p id="cac0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与直接使用循环网络(GRU)的编码器不同，解码器通过解码器单元循环构建。这是因为从每个解码器单元获得的预测作为输入传递到下一个解码器单元。每个解码器单元由一个GRUCell组成，其输出馈入一个提供预测的全连接层。来自每个解码器单元的预测被组合以形成输出序列。</p><figure class="me mf mg mh gt ju"><div class="bz fp l di"><div class="oc od l"/></div></figure><h2 id="9194" class="ni ml it bd mm nj nk dn mq nl nm dp mu kr nn no my kv np nq nc kz nr ns ng nt bi translated">编码器-解码器模型</h2><p id="3856" class="pw-post-body-paragraph kg kh it ki b kj nu kl km kn nv kp kq kr nw kt ku kv nx kx ky kz ny lb lc ld im bi translated">编码器-解码器模型是通过将编码器和解码器单元封装到一个模块中来构建的，该模块处理二者之间的通信。</p><figure class="me mf mg mh gt ju"><div class="bz fp l di"><div class="oc od l"/></div></figure><h1 id="08c1" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">模特培训</h1><p id="29c2" class="pw-post-body-paragraph kg kh it ki b kj nu kl km kn nv kp kq kr nw kt ku kv nx kx ky kz ny lb lc ld im bi translated">该模型的性能高度依赖于围绕优化、学习率计划等所采取的训练决策。我将简要地介绍一下它们。</p><ol class=""><li id="323e" class="og oh it ki b kj kk kn ko kr oi kv oj kz ok ld ol om on oo bi translated"><strong class="ki iu">验证策略— </strong>由于我们的数据与时间相关，因此跨部门培训-验证-测试分割不起作用。依赖于时间的训练-验证-测试分离提出了一个问题，即模型不是在最近的验证数据上训练的，这影响了模型在测试数据中的性能。<br/>为了应对这一问题，一个模型根据2014年至2016年的3年历史数据进行训练，并预测2017年的前3个月，用于验证和实验。最终模型根据2014年至2017年的数据进行训练，并预测2018年的前3个月。基于从验证模型训练中获得的知识，在没有验证的情况下以盲模式训练最终模型。</li><li id="2499" class="og oh it ki b kj op kn oq kr or kv os kz ot ld ol om on oo bi translated"><strong class="ki iu">优化器</strong> —使用的优化器是AdamW，它已经在许多学习任务中提供了结果的状态。关于AdamW更详细的分析可以在<a class="ae kf" href="https://www.fast.ai/2018/07/02/adam-weight-decay/" rel="noopener ugc nofollow" target="_blank"> Fastai </a>中找到。探索的另一个优化器是<a class="ae kf" href="https://arxiv.org/abs/1705.07795" rel="noopener ugc nofollow" target="_blank"> COCOBOptimizer </a>，它不明确地设置学习率。在用COCOBOptimizer进行训练时，我观察到它比AdamW收敛得更快，尤其是在初始迭代中。但是最好的结果是通过使用AdamW和一个周期学习获得的。</li><li id="e2cc" class="og oh it ki b kj op kn oq kr or kv os kz ot ld ol om on oo bi translated"><strong class="ki iu">学习率调度</strong>—<a class="ae kf" href="https://arxiv.org/abs/1705.07795" rel="noopener ugc nofollow" target="_blank">1使用周期学习率</a>调度器。通过使用用于循环学习的学习率查找器来确定循环中的最大学习率。使用的学习率查找器的实现来自库— <a class="ae kf" href="https://github.com/davidtvs/pytorch-lr-finder" rel="noopener ugc nofollow" target="_blank"> pytorch-lr-finder </a>。</li><li id="bfdb" class="og oh it ki b kj op kn oq kr or kv os kz ot ld ol om on oo bi translated">使用的损失函数是均方误差损失，它不同于完井损失— <a class="ae kf" href="https://en.wikipedia.org/wiki/Symmetric_mean_absolute_percentage_error" rel="noopener ugc nofollow" target="_blank"> SMAPE </a>。MSE损失提供了比使用SMAPE更稳定的收敛。</li><li id="4336" class="og oh it ki b kj op kn oq kr or kv os kz ot ld ol om on oo bi translated">编码器和解码器网络使用了独立的优化器和调度器对，从而提高了结果。</li><li id="fadd" class="og oh it ki b kj op kn oq kr or kv os kz ot ld ol om on oo bi translated">除了权重衰减之外，在编码器和解码器中都使用了丢弃来对抗过拟合。</li><li id="6220" class="og oh it ki b kj op kn oq kr or kv os kz ot ld ol om on oo bi translated">构建了一个包装器来处理训练过程，能够处理多个优化器和调度器、检查点和张量板集成。这方面的代码可以在<a class="ae kf" href="https://github.com/gautham20/pytorch-ts/blob/master/torch_utils/trainer.py" rel="noopener ugc nofollow" target="_blank"> trainer.py </a>中找到。</li></ol><h1 id="8969" class="mk ml it bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">结果</h1><p id="6979" class="pw-post-body-paragraph kg kh it ki b kj nu kl km kn nv kp kq kr nw kt ku kv nx kx ky kz ny lb lc ld im bi translated">下面的图显示了模型对2018年前3个月的预测，针对商店的单个商品。</p><figure class="me mf mg mh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ou"><img src="../Images/0e234cc4ad8b21f6444f1944a2ec20eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qHqkbwrI-Op0TYKv01oR3A.png"/></div></div></figure><p id="99ea" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通过绘制所有项目的平均销售额和平均预测来消除噪声，可以更好地评估该模型。下面的图来自验证模型对特定日期的预测，因此可以将预测与实际销售数据进行比较。</p><figure class="me mf mg mh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ov"><img src="../Images/0ac8750226255fff1ea9ca92a96c8812.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Z4TkvnbHUmhSq5kzyvG0w.png"/></div></div></figure><p id="a68b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">来自编码器-解码器模型的结果将在竞赛排行榜中提供前10%的排名。</p><figure class="me mf mg mh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ow"><img src="../Images/91147b88904ef4245326b3e48fd7f3a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iOq5x-zg0XtuzbD9EIoT1g.png"/></div></div></figure><p id="490c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了达到这个结果，我做了最小的超参数调整，所以还有更多改进的余地。还可以通过探索注意机制来进一步改进模型，以进一步增强模型的记忆。</p><h2 id="7c35" class="ni ml it bd mm nj nk dn mq nl nm dp mu kr nn no my kv np nq nc kz nr ns ng nt bi translated"><em class="ox">感谢阅读，让我知道你的想法。祝你今天开心！玩的开心！</em>😄</h2></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="3c01" class="mk ml it bd mm mn oy mp mq mr oz mt mu mv pa mx my mz pb nb nc nd pc nf ng nh bi translated">参考</h1><p id="320e" class="pw-post-body-paragraph kg kh it ki b kj nu kl km kn nv kp kq kr nw kt ku kv nx kx ky kz ny lb lc ld im bi translated"><a class="ae kf" href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#nlp-from-scratch-translation-with-a-sequence-to-sequence-network-and-attention" rel="noopener ugc nofollow" target="_blank">从无到有的NLP:从一个序列到序列网络的翻译和注意</a></p><p id="79df" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae kf" href="https://www.kaggle.com/c/web-traffic-time-series-forecasting/discussion/43795" rel="noopener ugc nofollow" target="_blank"> Web流量时间序列预测解决方案</a></p><p id="26ba" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae kf" href="https://ianlondon.github.io/blog/encoding-cyclical-features-24hour-time/" rel="noopener ugc nofollow" target="_blank">编码周期性连续特征— 24小时制</a></p><p id="bd32" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae kf" rel="noopener" target="_blank" href="/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21">LSTM和GRU的图解指南</a></p><p id="8e62" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae kf" href="https://www.fast.ai/2018/07/02/adam-weight-decay/" rel="noopener ugc nofollow" target="_blank"> AdamW和超收敛是目前训练神经网络最快的方法</a></p><p id="be6b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae kf" href="https://arxiv.org/abs/1705.07795" rel="noopener ugc nofollow" target="_blank">通过硬币下注训练深度网络而不学习比率</a></p><p id="533c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae kf" href="https://arxiv.org/abs/1705.07795" rel="noopener ugc nofollow" target="_blank">超收敛:使用大学习速率非常快速地训练神经网络</a></p></div></div>    
</body>
</html>