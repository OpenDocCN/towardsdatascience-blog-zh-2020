<html>
<head>
<title>Generative Adversarial Networks — Hard? Not.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成性对抗网络——难吗？不是。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generative-adversarial-networks-hard-not-eea78c1d3c95?source=collection_archive---------55-----------------------#2020-04-20">https://towardsdatascience.com/generative-adversarial-networks-hard-not-eea78c1d3c95?source=collection_archive---------55-----------------------#2020-04-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d533" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">GAN 工作流程简介。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/db08c557038984f1af70c6c17d5f6329.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xz56R_D2VOapIShj"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">米凯拉·帕兰特在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="961c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">自 2014 年问世以来，生成性对抗网络(俗称 GAN)已被广泛纳入众多研究工作。但是是什么让甘有如此神奇的魔力呢？</p><p id="5dd9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">事实上，有很多教程都在教授如何实现 GAN <em class="ls">代码</em>——但是没有足够简单地解释 GAN。在本教程中，我将介绍 GANs 背后的数学知识，并尝试涵盖最初的 GAN 论文中的大部分基础知识。您可能已经猜到这不是一个逐行代码的教程。</p><h2 id="616a" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lf mc md me lj mf mg mh ln mi mj mk ml bi translated">那么什么是甘呢？</h2><blockquote class="mm mn mo"><p id="6ae0" class="kw kx ls ky b kz la jr lb lc ld ju le mp lg lh li mq lk ll lm mr lo lp lq lr ij bi translated">一个<strong class="ky ir">生成对抗网络</strong>包含的不是一个单一的网络，而是一组至少两个总是相互“交战”的网络。一个网络被称为发电机，另一个是鉴别器。顾名思义，生成器生成由鉴别器评估的数据。两个网络之间的对抗部分或“战争”是，生成器反复尝试欺骗鉴别器，而鉴别器则被确定不在生成器的伪装下。</p></blockquote><p id="7d9e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">发电机所做的是我们的神经网络长期以来一直在做的事情。生成器试图<em class="ls">估计</em>数据分布，并基于该估计生成数据。一般而言，神经网络通常用于基于一些参数来估计函数。是什么使生成器不同于传统的神经网络？<em class="ls">魔法</em>在哪里？—发电机以<em class="ls">噪音</em>作为输入工作！一台机器可以从噪音中生成人的笔迹，这一事实让甘斯变得神奇。</p><p id="24f1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于我们的发电机网络以噪声作为输入，我们必须首先定义输入噪声变量的<em class="ls">优先</em>。让我们把先验表述为—</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/5eb3f8f85501bc3e35cefc446cb7725f.png" data-original-src="https://miro.medium.com/v2/resize:fit:284/format:webp/1*R4YMHC-MrRrB2Hlz-6AoFg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">先验噪声分布</p></figure><blockquote class="mm mn mo"><p id="8b6d" class="kw kx ls ky b kz la jr lb lc ld ju le mp lg lh li mq lk ll lm mr lo lp lq lr ij bi translated">在<a class="ae kv" href="https://en.wikipedia.org/wiki/Bayesian_probability" rel="noopener ugc nofollow" target="_blank">贝叶斯</a> <a class="ae kv" href="https://en.wikipedia.org/wiki/Statistical_inference" rel="noopener ugc nofollow" target="_blank">统计推断</a>中，一个不确定量的<strong class="ky ir">先验概率分布</strong>，通常简称为<strong class="ky ir">先验</strong>是<a class="ae kv" href="https://en.wikipedia.org/wiki/Probability_distribution" rel="noopener ugc nofollow" target="_blank">概率分布</a>，它将表达一个人对这个量的信念<strong class="ky ir">在</strong>之前，一些证据被考虑到了——<a class="ae kv" href="https://en.wikipedia.org/wiki/Prior_probability" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Prior_probability</a></p></blockquote><p id="4d72" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们用 G 表示发电机网络，我们可以说 G 将噪声变量映射到数据空间，如下所示</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/4dedcc2a6489b6449df14e69aa28d13a.png" data-original-src="https://miro.medium.com/v2/resize:fit:416/format:webp/1*ws5Km912rRAwlRa_F5CaCA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">发电机网络</p></figure><p id="06cb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">简单地说，生成器 G 获取随机噪声，并尝试重建真实数据。假设我们将发生器给出的数据定义为<em class="ls"> p </em>的输出。需要注意的是，我们没有优化<em class="ls">p</em>——我们优化了<em class="ls">θ</em>，这样我们就可以得到<em class="ls">p</em>的正确估计。现在，我们并不期望生成器自己训练并给出真实数据，对吗？我们需要某种东西来检查生成器，如果它不能从噪声中生成真正的数据，就对它进行某种“惩罚”。</p><p id="82d7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个“惩罚者”就是鉴别者。鉴别器(D)是其最基本的形式，是一个分类器，用于对其输入进行真假分类。因此，鉴别器输出单个标量。<em class="ls"> D(x) </em>表示<em class="ls"> x </em>来自真实数据而非生成器 g 的概率。由于我们已经定义了生成器和鉴别器模型以及它们如何工作，我们现在将讨论成本函数或损失函数。</p><h1 id="0875" class="mu lu iq bd lv mv mw mx ly my mz na mb jw nb jx me jz nc ka mh kc nd kd mk ne bi translated">损失函数</h1><p id="9aa6" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">可以说，GAN 最重要的部分之一是损耗函数及其设计。在介绍 GAN 的论文中定义的损失函数是—</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/4fa7e25cded28e16a9503e4e97be1fd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*UIE7_PQkBp9XMcCmoHDyGg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">损失函数</p></figure><p id="620a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是一个“最小-最大”损失函数，我们训练鉴别器以最大化该损失函数，同时训练发生器以最小化该损失函数的最后一项。不同类型的 gan 还有其他损失函数。其中一些损失函数是对这个的修改。一个 GAN 甚至可以有多个损耗函数，一个用于发生器，一个用于鉴频器</p><h1 id="0313" class="mu lu iq bd lv mv mw mx ly my mz na mb jw nb jx me jz nc ka mh kc nd kd mk ne bi translated">培养</h1><p id="75f6" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">现在我们已经完成了损失函数，我们应该如何处理训练呢？我们先训练哪个网络？对于每个历元，首先计算鉴别器的梯度，并且首先更新其权重。然后，我们训练发电机。</p><p id="15d3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">训练算法(步骤)—</p><ol class=""><li id="5b68" class="nl nm iq ky b kz la lc ld lf nn lj no ln np lr nq nr ns nt bi translated">首先，我们从我们之前定义的噪声中采样一个小批量的 m 个噪声样本</li><li id="cd43" class="nl nm iq ky b kz nu lc nv lf nw lj nx ln ny lr nq nr ns nt bi translated">然后，我们从数据生成分布(训练集)中抽取少量的 m 个样本</li><li id="e90b" class="nl nm iq ky b kz nu lc nv lf nw lj nx ln ny lr nq nr ns nt bi translated">我们使用 SGD 根据计算的梯度更新鉴别器的权重。SGD 代表随机梯度下降。更多信息—<a class="ae kv" href="https://medium.com/@hmrishavbandyopadhyay/neural-network-optimizers-hard-not-2-7ecc677892cc" rel="noopener">https://medium . com/@ hmrishavbandyopadhyay/neural-network-optimizer-hard-not-2-7ecc 677892 cc</a></li><li id="e368" class="nl nm iq ky b kz nu lc nv lf nw lj nx ln ny lr nq nr ns nt bi translated">然后，我们再次从噪声先验中采样小批量的 m 个噪声样本</li><li id="6e02" class="nl nm iq ky b kz nu lc nv lf nw lj nx ln ny lr nq nr ns nt bi translated">我们使用计算的梯度和应用 SGD 来更新生成器的权重。</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/29369532cdf9d62467f610364f2f505b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*OSqMLGgGBC098FtupVN9FA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">训练算法</p></figure><p id="8755" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，我们现在已经成功地训练了一个非常原始和简单的 GAN 网络。然而，这只是对 2014 年推出的 GAN 论文的解释。从那时起，已经产生了数百种类型的 GAN，并且每一种都有它们自己的损失函数和它们自己的训练算法。</p><p id="d136" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">实现 GANs 可能会变得非常有趣。如果你有任何疑问，请在评论中告诉我——乐意效劳；)</p><p id="988f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">查看我的博客以获得更快的更新，并订阅优质内容:D</p><div class="oa ob gp gr oc od"><a href="https://www.theconvolvedblog.vision" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd ir gy z fp oi fr fs oj fu fw ip bi translated">卷积博客</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">克罗伊斯，吕底亚(小亚细亚)的国王，曾经问特尔斐的神谕，他是否应该对波斯开战…</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">www.theconvolvedblog.vision</p></div></div><div class="om l"><div class="on l oo op oq om or kp od"/></div></div></a></div><p id="dde0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls"> Hmrishav Bandyopadhyay 是印度 Jadavpur 大学电子与电信系的二年级学生。他的兴趣在于深度学习、计算机视觉和图像处理。可以通过以下方式联系到他:hmrishavbandyopadhyay@gmail.com | |</em><a class="ae kv" href="https://hmrishavbandy.github.io" rel="noopener ugc nofollow" target="_blank"><em class="ls">https://hmrishavbandy . github . io</em></a></p></div></div>    
</body>
</html>