<html>
<head>
<title>Image Inpainting with a Single Line of Code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用一行代码修复图像</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-inpainting-with-a-single-line-of-code-c0eef715dfe2?source=collection_archive---------25-----------------------#2020-07-20">https://towardsdatascience.com/image-inpainting-with-a-single-line-of-code-c0eef715dfe2?source=collection_archive---------25-----------------------#2020-07-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="246f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用 Python 中的 OpenCV，使用四种不同的技术和一行代码，使用图像修复来恢复图像。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ecfaa08b40bf31a63eacb23e65d5a5db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*v9gfKtyne1vQBmU-"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">杰德·斯蒂芬斯在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="2af7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">修复是一个过程，其中艺术品的损坏或缺失部分被填充以完成它。使用 GANs 来执行图像修复的现有技术方法，其中复杂模型在大量数据上被训练。如果呈现的数据完全不同，那么模型也可能受到影响。与此相反，图像修复也可以通过图像处理操作来完成，这也只需要使用 OpenCV 的一行代码。在本文中，我们将实现四种不同类型的图像修复方法，并基于 PSNR 和 SSIM 比较它们的结果。此外，我将在本文中遵循一种不同的方法，即首先呈现代码和结果，然后描述方法。</p><p id="083a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用三种算法，即基于 Navier-Stokes 的算法、Alexandru Telea 基于快速行进法的方法以及快速频率选择性重建算法的快速和最佳迭代。</p><h1 id="be22" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">目录</h1><ul class=""><li id="5161" class="mn mo it lb b lc mp lf mq li mr lm ms lq mt lu mu mv mw mx bi translated">要求</li><li id="911e" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu mu mv mw mx bi translated">密码</li><li id="a27d" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu mu mv mw mx bi translated">结果</li><li id="07d4" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu mu mv mw mx bi translated">方法概述</li></ul></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h1 id="cad7" class="lv lw it bd lx ly nk ma mb mc nl me mf jz nm ka mh kc nn kd mj kf no kg ml mm bi translated">要求</h1><p id="714a" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">其中两种方法需要 OpenCV Contrib，以便可以使用 pip 安装:</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="3a65" class="nx lw it nt b gy ny nz l oa ob">pip install opencv-contrib-python==4.3.0.36</span></pre><h1 id="b04b" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">密码</h1><p id="5f15" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">我们需要扭曲的图像和需要修补的蒙版。<strong class="lb iu">对于 Navier-Stokes 和 Telea 方法，蒙版上的白色部分代表要修复的区域，而对于 FSR 方法，黑色像素则是在</strong>修复的像素。</p><p id="f045" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图像修复所需的单行代码是:</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="9cd8" class="nx lw it nt b gy ny nz l oa ob">import cv2</span><span id="4a5a" class="nx lw it nt b gy oc nz l oa ob">#distorted_img: The image on which inpainting has to be done.<br/>#mask: Black mask with white pixels to be inpainted</span><span id="5cdc" class="nx lw it nt b gy oc nz l oa ob"><em class="od">res_NS = cv2.inpaint(distort_img, mask, 3, cv2.INPAINT_NS)<br/>res_TELEA = cv2.inpaint(distort_img, mask, 3, cv2.INPAINT_TELEA)</em></span><span id="2937" class="nx lw it nt b gy oc nz l oa ob">res_FSRFAST = distorted_img.copy()<br/>res_FSRBEST = distorted_img.copy()<br/>mask1 = cv2.bitwise_not(mask)</span><span id="5266" class="nx lw it nt b gy oc nz l oa ob"><em class="od">cv2.xphoto.inpaint(distort, mask1, res_FSRFAST,        cv2.xphoto.INPAINT_FSR_FAST)<br/>cv2.xphoto.inpaint(distort, mask1, res_FSTBEST, cv2.xphoto.INPAINT_FSR_BEST)</em></span></pre><h1 id="b073" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结果</h1><p id="d14d" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">我用了三张大小为 756x1008 的图片。所有四种方法的结果如下所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/9c9d0992e54051545f7dcd1ed49157c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*foYGuhzr1gBw9hXAcvG4lw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">结果 1</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/517f4bbcc61ae07f6287c0194ae5de64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JdwEk4GZ8TTexMVwqBCUeQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">结果 2</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/8aaf5e714c4beb06959da28efbec6cfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dQtYl_jsS6MZpGOx2E0XqA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">结果 3</p></figure><p id="3091" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">每幅图像的每种方法所用的时间(秒)为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/3ee9e4cfe4bf008a426c2730b438f2fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/format:webp/1*cjvgt-yq0kJuAudXuITU8w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">花费的时间</p></figure><p id="d400" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">PSNR 和 SSIM 的值也是使用以下代码根据重建图像与原始图像进行计算的:</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="aab9" class="nx lw it nt b gy ny nz l oa ob">import cv2<br/>from skimage.metrics import structural_similarity as SSIM</span><span id="e57b" class="nx lw it nt b gy oc nz l oa ob">psnr = cv2.PSNR(img, recon, 255)<br/>ssim = SSIM(img, recon, multichannel=True)</span></pre><p id="fcc4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/ffd9a969dd9246071d03d5acee877334.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/1*gwFalQb6DIslXDVMsZhNeA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">PSNR 价值观</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/2cbb046daaf84f923906b0548f6386bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*wh5ewFCtr5akK-HRUl5z7Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">SSIM 价值观</p></figure><p id="081d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，Genser 等人发表了一篇<a class="ae ky" href="https://github.com/opencv/opencv_contrib/files/3730212/inpainting_comparison.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>，对这些方法进行了比较，其中他们使用了<a class="ae ky" href="http://www.cs.albany.edu/~xypan/research/snr/Kodak.html" rel="noopener ugc nofollow" target="_blank"> Kodak </a>和<a class="ae ky" href="https://testimages.org/" rel="noopener ugc nofollow" target="_blank"> Tecnick </a>图像集以及五种不同的错误屏蔽，其结果如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/54ea30ed0ed42448967fcf615633b749.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*cyJG-vOnQv8Ld_syBJviOQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">结果</p></figure><p id="69ee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面给出了使用的完整代码，其中显示了一个样本遮罩，其中白色区域必须在原始图像上进行修复，并叠加在原始图像上。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/08b517e3be09ed07a1092489b005d6f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:568/format:webp/1*-vkuATY2kmIwlC-XXmCg8Q.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">面具</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ol om l"/></div></figure><h1 id="69cf" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">方法概述</h1><h2 id="ab9b" class="nx lw it bd lx on oo dn mb op oq dp mf li or os mh lm ot ou mj lq ov ow ml ox bi translated">泰莱亚</h2><p id="5b1b" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">Alexandru Telea 在 2004 年的论文“基于快速行进法的图像修复技术”中介绍了这种技术。我在这里引用的 OpenCV 文档对此做了很好的概述。</p><blockquote class="oy oz pa"><p id="5754" class="kz la od lb b lc ld ju le lf lg jx lh pb lj lk ll pc ln lo lp pd lr ls lt lu im bi translated">考虑图像中要修补的区域。算法从该区域的边界开始，进入该区域，首先逐渐填充边界中的所有内容。需要在要修复的邻域的像素周围有一个小的邻域。该像素被邻域中所有已知像素的归一化加权和所代替。砝码的选择是一件重要的事情。对那些靠近该点、靠近边界法线的像素和那些位于边界轮廓上的像素给予更大的权重。一旦像素被修复，它就使用快速行进方法移动到下一个最近的像素。FMM 确保已知像素附近的像素首先被修复，因此它就像一个手动启发式操作。</p></blockquote><h2 id="4902" class="nx lw it bd lx on oo dn mb op oq dp mf li or os mh lm ot ou mj lq ov ow ml ox bi translated">纳维尔-斯托克斯</h2><p id="61fd" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">由 Bertalmio 等人在他们的论文中介绍，“<a class="ae ky" href="https://www.math.ucla.edu/~bertozzi/papers/cvpr01.pdf" rel="noopener ugc nofollow" target="_blank">纳维尔-斯托克斯，流体动力学，以及图像和视频修复</a>”早在 2001 年就介绍过了。再次引用 OpenCV 文档:</p><blockquote class="oy oz pa"><p id="aa07" class="kz la od lb b lc ld ju le lf lg jx lh pb lj lk ll pc ln lo lp pd lr ls lt lu im bi translated">该算法基于流体动力学并利用偏微分方程。基本原理是启发式的。它首先沿着边缘从已知区域行进到未知区域(因为边缘应该是连续的)。它继续等照度线(连接具有相同强度的点的线，就像轮廓连接具有相同海拔的点)，同时在修复区域的边界匹配梯度向量。为此，使用了流体动力学的一些方法。一旦它们被获得，颜色被填充以减少该区域的最小变化。</p></blockquote><h2 id="6be8" class="nx lw it bd lx on oo dn mb op oq dp mf li or os mh lm ot ou mj lq ov ow ml ox bi translated">快速频率选择性重建算法</h2><p id="510e" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">使用已知的样本和已经重构的像素作为支持来外推失真块的信号。该算法迭代地产生信号的一般复值模型，该模型被外推为傅立叶基函数的加权叠加。FSR 的一个重要特征是计算是在傅立叶域中进行的，这导致了快速实现。</p></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><p id="1485" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总之，FSR 的快速实施提供了速度和精度之间的巨大平衡，即使在高度失真的情况下，这些方法也能提供良好的结果，因此它们可以为数据密集型 GAN 提供合理的替代方案，后者在不可预见的数据上可能表现不佳。</p><h1 id="55e5" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">参考</h1><ul class=""><li id="489a" class="mn mo it lb b lc mp lf mq li mr lm ms lq mt lu mu mv mw mx bi translated"><a class="ae ky" href="https://docs.opencv.org/master/df/d3d/tutorial_py_inpainting.html" rel="noopener ugc nofollow" target="_blank">https://docs . opencv . org/master/df/d3d/tutorial _ py _ inpainting . html</a></li><li id="fb42" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu mu mv mw mx bi translated"><a class="ae ky" href="https://docs.opencv.org/4.2.0/dc/d2f/tutorial_xphoto_inpainting.html" rel="noopener ugc nofollow" target="_blank">https://docs . opencv . org/4 . 2 . 0/DC/d2f/tutorial _ x photo _ inpainting . html</a></li><li id="205a" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu mu mv mw mx bi translated"><a class="ae ky" href="https://github.com/opencv/opencv_contrib/files/3730212/inpainting_comparison.pdf" rel="noopener ugc nofollow" target="_blank">https://github . com/opencv/opencv _ contrib/files/3730212/inpainting _ comparison . pdf</a></li></ul></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><p id="6488" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如上所述，我在本文中使用了不同的策略。下面给出的一篇文章采用了传统的方法。如果能知道你更喜欢哪种策略就太好了。</p><div class="pe pf gp gr pg ph"><a rel="noopener follow" target="_blank" href="/face-detection-models-which-to-use-and-why-d263e82c302c"><div class="pi ab fo"><div class="pj ab pk cl cj pl"><h2 class="bd iu gy z fp pm fr fs pn fu fw is bi translated">人脸检测模型:使用哪种模型，为什么？</h2><div class="po l"><h3 class="bd b gy z fp pm fr fs pn fu fw dk translated">一个关于用 Python 实现不同人脸检测模型的完整教程，通过比较，找出最好的…</h3></div><div class="pp l"><p class="bd b dl z fp pm fr fs pn fu fw dk translated">towardsdatascience.com</p></div></div><div class="pq l"><div class="pr l ps pt pu pq pv ks ph"/></div></div></a></div></div></div>    
</body>
</html>