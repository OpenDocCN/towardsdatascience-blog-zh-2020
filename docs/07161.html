<html>
<head>
<title>Deep Learning with PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 PyTorch 进行深度学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-with-pytorch-a93b09bdae96?source=collection_archive---------24-----------------------#2020-06-01">https://towardsdatascience.com/deep-learning-with-pytorch-a93b09bdae96?source=collection_archive---------24-----------------------#2020-06-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="a9cb" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/deep-r-l-explained" rel="noopener" target="_blank">深度强化学习讲解— 04 </a></h2><div class=""/><div class=""><h2 id="4b61" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">初学 PyTorch</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/fa0f6596bcb8f7d913d0517d5a751d20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LDhcpkgdzkisARJU93i5xw.png"/></div></div></figure><p id="ecc6" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们将在本系列的许多文章中使用 PyTorch，所以读者需要确保她/他熟悉它。这篇文章将向读者介绍 PyTorch 的基本特性，它使我们能够使用 Python 语言实现深度学习模型。这篇文章并没有假装是 PyTorch 的完整手册，它只是介绍了 PyTorch 的基本知识，以开始在 PyTorch 中编码神经网络，我们将在整个系列中引入我们需要的新功能。好好享受吧！</p><blockquote class="lz ma mb"><p id="df34" class="ld le mc lf b lg lh kd li lj lk kg ll md ln lo lp me lr ls lt mf lv lw lx ly im bi translated"><a class="ae mg" href="https://medium.com/aprendizaje-por-refuerzo/8-pytorch-básico-a60ce5fc8b74" rel="noopener">本出版物的西班牙语版本</a></p></blockquote><div class="mh mi gp gr mj mk"><a href="https://medium.com/aprendizaje-por-refuerzo/8-pytorch-b%C3%A1sico-a60ce5fc8b74" rel="noopener follow" target="_blank"><div class="ml ab fo"><div class="mm ab mn cl cj mo"><h2 class="bd jd gy z fp mp fr fs mq fu fw jc bi translated">8.PyTorch básico</h2><div class="mr l"><h3 class="bd b gy z fp mp fr fs mq fu fw dk translated">请访问第 8 页的自由介绍</h3></div><div class="ms l"><p class="bd b dl z fp mp fr fs mq fu fw dk translated">medium.com</p></div></div><div class="mt l"><div class="mu l mv mw mx mt my lb mk"/></div></div></a></div><h2 id="e2f6" class="mz na it bd nb nc nd dn ne nf ng dp nh lm ni nj nk lq nl nm nn lu no np nq iz bi translated">深度学习框架</h2><p id="daad" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm nt lo lp lq nu ls lt lu nv lw lx ly im bi translated">深度学习框架领域的明确领导者现在是谷歌开发的 TensorFlow 和脸书开发的 PyTorch，它们正在从使用量、份额和势头上脱离市场的其余部分。</p><p id="c0c5" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">三年前，第一个版本的<a class="ae mg" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>问世，毫无疑问，它正在获得巨大的发展势头。PyTorch 最初由脸书孵化，作为快速实验和原型制作的理想灵活框架，迅速赢得了声誉，在深度学习社区中赢得了成千上万的粉丝。例如，我的研究团队中的博士生更喜欢使用 PyTorch，因为它允许他们编写看起来像本机的 Python 代码，并且仍然可以获得良好框架的所有好处，如自动微分和内置优化。这就是我决定在这个系列中使用 PyTorch 的原因。</p><blockquote class="lz ma mb"><p id="7e41" class="ld le mc lf b lg lh kd li lj lk kg ll md ln lo lp me lr ls lt mf lv lw lx ly im bi translated">虽然 PyTorch 由于脸书(和 AWS)而在市场上获得了动力，但<a class="ae mg" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>仍然在各个方面保持领先，并且是目前行业中使用最多的。你可以阅读这篇简短的文章“<a class="ae mg" rel="noopener" target="_blank" href="/tensorflow-vs-pytorch-the-battle-continues-9dcd34bb47d4"> TensorFlow vs PyTorch:战斗仍在继续</a>”来了解关于这两种环境的更多细节。</p></blockquote><h1 id="6cb7" class="nw na it bd nb nx ny nz ne oa ob oc nh ki od kj nk kl oe km nn ko of kp nq og bi translated">环境设置</h1><p id="a231" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm nt lo lp lq nu ls lt lu nv lw lx ly im bi translated">我建议使用 Google 提供的<a class="ae mg" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"><em class="mc"/></a><em class="mc"/>(Colab)<em class="mc"/>来执行本文描述的代码。它基本上由一个 Jupyter 笔记本环境组成，不需要配置，完全在云中运行，允许使用不同的深度学习库，如<a class="ae mg" rel="noopener" target="_blank" href="/tensorflow-or-pytorch-146f5397278a"> PyTorch 和 TensorFlow </a>。Colab 的一个重要特点是它完全免费提供 GPU(和 TPU)。关于该服务的详细信息可以在<a class="ae mg" href="https://research.google.com/colaboratory/faq.html" rel="noopener ugc nofollow" target="_blank">常见问题页面</a>上找到。</p><p id="2bcf" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">默认情况下，Colab 笔记本运行在 CPU 上。你可以切换你的笔记本电脑运行与 GPU(或 TPU)。为了访问一个 GPU，您需要选择“运行时”<em class="mc"> </em>选项卡，然后选择“更改运行时类型”，如下图所示:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oh"><img src="../Images/b8afd74ca7d694372813e787babad7be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ORv0ooIOHgdCAi6f.png"/></div></div></figure><p id="a4d2" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">当弹出窗口出现时，选择 GPU。确保“硬件加速器”设置为 GPU(默认为 CPU)。然后，确保您已连接到运行时(在菜单功能区中“已连接”旁边有一个绿色复选标记):</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi gj"><img src="../Images/50b9865b5d8fd8bc2adb3acbcbbe6305.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*44fwDeQ1KsvFU9sx.png"/></div></div></figure><p id="3cb9" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">现在你可以运行这篇文章中的代码了。我建议将这篇文章的代码复制粘贴到一个 Colab 笔记本上，以便在你阅读这篇文章的同时看到执行过程。准备好了吗？</p><blockquote class="lz ma mb"><p id="dc74" class="ld le mc lf b lg lh kd li lj lk kg ll md ln lo lp me lr ls lt mf lv lw lx ly im bi translated">这篇文章的<a class="ae mg" href="https://github.com/jorditorresBCN/Deep-Reinforcement-Learning-Explained/blob/master/DRL_04_Deep_Learning_with_PyTorch.ipynb" rel="noopener ugc nofollow" target="_blank">完整代码可以在 GitHub </a>上找到，并且<a class="ae mg" href="https://colab.research.google.com/github/jorditorresBCN/Deep-Reinforcement-Learning-Explained/blob/master/DRL_04_Deep_Learning_with_PyTorch.ipynb" rel="noopener ugc nofollow" target="_blank">可以使用这个链接</a>作为一个 Colab google 笔记本运行。</p></blockquote><h1 id="cb53" class="nw na it bd nb nx ny nz ne oa ob oc nh ki od kj nk kl oe km nn ko of kp nq og bi translated">使用 PyTorch 的手写数字示例</h1><p id="0048" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm nt lo lp lq nu ls lt lu nv lw lx ly im bi translated">在这篇文章中，我们将编写一个神经网络模型，对在<a class="ae mg" rel="noopener" target="_blank" href="/deep-learning-basics-1d26923cc24a">上一篇文章</a>中出现的手写数字进行分类。请记住，我们创建了一个数学模型，给定一幅图像，该模型识别它所代表的数字，返回一个具有 10 个位置的向量，指示 10 个可能数字中每一个的可能性。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/0c07da50cf65dcf2f59efe421f960e37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xjVHs2ncUj8QVkHBS8DKRA.png"/></div></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">来源:<a class="ae mg" href="https://torres.ai" rel="noopener ugc nofollow" target="_blank"> torres.ai </a></p></figure><p id="5905" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">为了引导解释，我们将遵循为神经网络编程所要采取的步骤列表:</p><ol class=""><li id="a00b" class="om on it lf b lg lh lj lk lm oo lq op lu oq ly or os ot ou bi translated">导入所需的库</li><li id="85ad" class="om on it lf b lg ov lj ow lm ox lq oy lu oz ly or os ot ou bi translated">加载和预处理数据</li><li id="f690" class="om on it lf b lg ov lj ow lm ox lq oy lu oz ly or os ot ou bi translated">定义模型</li><li id="0d15" class="om on it lf b lg ov lj ow lm ox lq oy lu oz ly or os ot ou bi translated">定义优化器和损失函数</li><li id="8969" class="om on it lf b lg ov lj ow lm ox lq oy lu oz ly or os ot ou bi translated">训练模型</li><li id="ac91" class="om on it lf b lg ov lj ow lm ox lq oy lu oz ly or os ot ou bi translated">评估模型</li></ol><p id="6eff" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">让我们去吧！</p><h1 id="9e03" class="nw na it bd nb nx ny nz ne oa ob oc nh ki od kj nk kl oe km nn ko of kp nq og bi translated">1.导入所需的库</h1><p id="a668" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm nt lo lp lq nu ls lt lu nv lw lx ly im bi translated">我们总是需要导入 PyTorch 的核心 Python 库<code class="fe pa pb pc pd b">torch</code>。对于我们的例子，我们还将导入<code class="fe pa pb pc pd b">torchvision</code>包，以及常用的库<code class="fe pa pb pc pd b">numpy</code>和<code class="fe pa pb pc pd b">matplotlib</code>。</p><pre class="ks kt ku kv gt pe pd pf pg aw ph bi"><span id="918e" class="mz na it pd b gy pi pj l pk pl">import torch <br/>import torchvision</span></pre><p id="0fcd" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">为了代码的清晰，我们可以在这里定义一些训练所需的超参数:</p><pre class="ks kt ku kv gt pe pd pf pg aw ph bi"><span id="5bb8" class="mz na it pd b gy pi pj l pk pl"><br/>import numpy as np <br/>import matplotlib.pyplot as plt </span><span id="e4d9" class="mz na it pd b gy pm pj l pk pl">EPOCH = 10 <br/>BATCH_SIZE= 64</span></pre><h1 id="267f" class="nw na it bd nb nx ny nz ne oa ob oc nh ki od kj nk kl oe km nn ko of kp nq og bi translated">2.加载和预处理数据</h1><h2 id="a733" class="mz na it bd nb nc nd dn ne nf ng dp nh lm ni nj nk lq nl nm nn lu no np nq iz bi translated">加载数据</h2><p id="1b59" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm nt lo lp lq nu ls lt lu nv lw lx ly im bi translated">下一步是加载将用于训练我们的神经网络的数据。我们将使用前一篇文章中已经介绍过的 MNIST 数据集，可以从<em class="mc"/><a class="ae mg" href="http://yann.lecun.com/exdb/mnist" rel="noopener ugc nofollow" target="_blank"><em class="mc">MNIST 数据库</em>页面</a>下载使用<code class="fe pa pb pc pd b">torchvision.dataset.</code> PyTorch 数据集是根据请求返回单个数据点的对象。然后，它被传递到处理数据点批处理和并行性的数据加载器。这是我们示例的代码:</p><pre class="ks kt ku kv gt pe pd pf pg aw ph bi"><span id="9998" class="mz na it pd b gy pi pj l pk pl">xy_trainPT = torchvision.datasets.MNIST(root='./data', <br/>             train=True, download=True,transform=<br/>             torchvision.transforms.Compose(<br/>             [torchvision.transforms.ToTensor()]))</span><span id="eec8" class="mz na it pd b gy pm pj l pk pl">xy_trainPT_loader = torch.utils.data.DataLoader<br/>                    (xy_trainPT, batch_size=BATCH_SIZE)</span></pre><p id="d8d6" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">因为数据通常太大，无法一次将数据放入 CPU 或 GPU 内存中，所以将数据分成大小相等的批次。每一批都包括数据样本和目标标签，并且两者都必须是张量(我们将在下面介绍)。<code class="fe pa pb pc pd b">BATCH_SIZE</code>参数表示我们将在每次更新模型参数时使用的数据数量。</p><p id="3e1e" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">该数据集包含 60，000 个手工制作的数字图像来训练模型，对于首次进入模式识别技术来说是理想的，无需花费大量时间预处理和格式化数据，这在数据分析中是非常重要和昂贵的步骤，并且在处理图像时具有特殊的复杂性。</p><p id="8818" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们可以验证前面的代码已经用库<code class="fe pa pb pc pd b">matplotlib.pyplot</code>加载了预期的数据:</p><pre class="ks kt ku kv gt pe pd pf pg aw ph bi"><span id="b592" class="mz na it pd b gy pi pj l pk pl">fig = plt.figure(figsize=(25, 4)) <br/>for idx in np.arange(20):<br/>   image, label = xy_trainPT [idx]<br/>   ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])<br/>   ax.imshow(torch.squeeze(image, dim = 0).numpy(), <br/>             cmap=plt.cm.binary)<br/>   ax.set_title(str(label))</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pn"><img src="../Images/6569724f1ecd97e7de8e07ce341134fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zcb7vIlnenrBxEtwLqP2nA.png"/></div></div></figure><h2 id="c3e2" class="mz na it bd nb nc nd dn ne nf ng dp nh lm ni nj nk lq nl nm nn lu no np nq iz bi translated">预处理数据</h2><p id="ce2d" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm nt lo lp lq nu ls lt lu nv lw lx ly im bi translated">记得在上一篇文章中，我们解释过，为了便于将数据输入到我们的神经网络中，我们将输入(图像)从二维(2D)转换为一维(1D)的向量。也就是说，28×28 个数字的矩阵可以由 784 个数字(逐行连接)的向量(数组)来表示。</p><p id="871c" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">当我们使用这种类型的变换(例如，应用于第一幅图像)将数据摄取到神经网络时，我们将应用这种变换:</p><pre class="ks kt ku kv gt pe pd pf pg aw ph bi"><span id="f8c7" class="mz na it pd b gy pi pj l pk pl">image, _ = xy_trainPT[0] <br/>print(image.size())<br/>image_flatten = image.view(image.shape[0], -1)<br/>print (image_flatten.size())</span><span id="9f32" class="mz na it pd b gy pm pj l pk pl">torch.Size([1, 28, 28]) <br/>torch.Size([1, 784])</span></pre><h2 id="3bc4" class="mz na it bd nb nc nd dn ne nf ng dp nh lm ni nj nk lq nl nm nn lu no np nq iz bi translated">张量</h2><p id="54b0" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm nt lo lp lq nu ls lt lu nv lw lx ly im bi translated">张量是一个多维数组，是 PyTorch 的基本构造块，相当于 NumPy，它存储一组数字:</p><pre class="ks kt ku kv gt pe pd pf pg aw ph bi"><span id="d6cf" class="mz na it pd b gy pi pj l pk pl">a = torch.randn(2, 3)<br/>print(a)</span><span id="c327" class="mz na it pd b gy pm pj l pk pl">tensor([[ 1.1049, 0.2676, -0.4528],<br/>        [ 0.0105, -0.5095, 0.7777]])</span></pre><p id="f0a2" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们可以知道它的尺寸和大小:</p><pre class="ks kt ku kv gt pe pd pf pg aw ph bi"><span id="92ae" class="mz na it pd b gy pi pj l pk pl">print(a.size())<br/>print(a.dim())</span><span id="21d0" class="mz na it pd b gy pm pj l pk pl">torch.Size([2, 3])<br/>2</span></pre><p id="294f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">除了维度，张量的特征还在于其元素的类型。为此，我们有一个<code class="fe pa pb pc pd b">dtype</code>参数，它故意与同名的标准 NumPy 参数类型相似:</p><pre class="ks kt ku kv gt pe pd pf pg aw ph bi"><span id="63be" class="mz na it pd b gy pi pj l pk pl">matrix=torch.zeros([2, 4], dtype=torch.int32)<br/>print(matrix)</span><span id="ee1a" class="mz na it pd b gy pm pj l pk pl">tensor([[0, 0, 0, 0],<br/>        [0, 0, 0, 0]], dtype=torch.int32)</span><span id="373b" class="mz na it pd b gy pm pj l pk pl"><br/>print(matrix.dtype)</span><span id="0db1" class="mz na it pd b gy pm pj l pk pl">torch.int32</span></pre><p id="6b15" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">Torch 定义了九种类型的 CPU 张量和九种类型的 GPU 张量:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi po"><img src="../Images/8a3de3b16d2bc1defe2752dadbef66c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-C10tKbZ2h0Zd7maau86oQ.png"/></div></div></figure><p id="571c" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如你所见，GPU 张量有特定的类型。PyTorch 透明支持 CUDA GPUs，这意味着所有操作都有两个版本——CPU 和 GPU——自动选择。这个决定是基于你正在操作的张量的类型做出的。</p><p id="6396" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在 PyTorch 中创建张量有不同的方法:调用所需类型的构造函数，将 NumPy 数组(或 Python 列表)转换为张量或要求 PyTorch 创建具有特定数据的张量。例如，我们可以使用<code class="fe pa pb pc pd b">torch.zeros()</code>函数创建一个填充零值的张量:</p><pre class="ks kt ku kv gt pe pd pf pg aw ph bi"><span id="ed0c" class="mz na it pd b gy pi pj l pk pl">b = torch.zeros(2, 3)<br/>print(b)</span><span id="a006" class="mz na it pd b gy pm pj l pk pl">tensor([[0., 0., 0.],<br/>        [0., 0., 0.]])</span><span id="d70d" class="mz na it pd b gy pm pj l pk pl"><br/>c = torch.ones(2, 3)<br/>print(c)</span><span id="39e5" class="mz na it pd b gy pm pj l pk pl">tensor([[1., 1., 1.],<br/>        [1., 1., 1.]])</span></pre><p id="b29c" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">张量的元素可以使用其索引(从 0 开始)来访问:</p><pre class="ks kt ku kv gt pe pd pf pg aw ph bi"><span id="4ad5" class="mz na it pd b gy pi pj l pk pl">c[0,0]=222 <br/>print(c)</span><span id="e073" class="mz na it pd b gy pm pj l pk pl">tensor([[222.,   1.,   1.],         <br/>        [  1.,   1.,   1.]]) </span></pre><p id="fccd" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">此外，就像 Python 中常见的数据结构一样，我们可以在“<strong class="lf jd"> </strong> <code class="fe pa pb pc pd b">:</code> <strong class="lf jd"> </strong>”字符的帮助下，在索引中使用范围标记来选择和操作张量的各个部分。索引从 0 开始，我们可以对索引使用负值，其中<code class="fe pa pb pc pd b">-1</code>是最后一个元素，依此类推。让我们来看下面的一段代码作为例子:</p><pre class="ks kt ku kv gt pe pd pf pg aw ph bi"><span id="3cf6" class="mz na it pd b gy pi pj l pk pl">x = torch.Tensor([[1,2,3,4], [5,6,7,8], [9,10,11,12]]) <br/>print (x)<br/></span><span id="f030" class="mz na it pd b gy pm pj l pk pl">tensor([[ 1., 2., 3., 4.],<br/>        [ 5., 6., 7., 8.],<br/>        [ 9., 10., 11., 12.]])</span><span id="364e" class="mz na it pd b gy pm pj l pk pl"><br/>print (“x column 1: “, x[:, 1])<br/>print (“x row 0: “, x[0, :])<br/>print (“x rows 0,1 &amp; cols 1,2: \n”, x[0:2, 1:3])</span><span id="11d9" class="mz na it pd b gy pm pj l pk pl">x column 1: tensor([ 2., 6., 10.])<br/>x row 0: tensor([1., 2., 3., 4.])<br/>x rows 0,1 &amp; cols 1,2:<br/>tensor([[2., 3.],<br/>        [6., 7.]])</span></pre><p id="a1ce" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">PyTorch 张量可以非常有效地转换为 NumPy 矩阵，反之亦然。通过这样做，我们可以利用 Python 生态系统中围绕 NumPy 数组类型发展起来的大量功能。让我们用一个简单的代码来看看它是如何工作的:</p><pre class="ks kt ku kv gt pe pd pf pg aw ph bi"><span id="9ab6" class="mz na it pd b gy pi pj l pk pl">x = np.array([[1,2], [3,4], [5,6]])<br/>print (x)</span><span id="643b" class="mz na it pd b gy pm pj l pk pl"><br/>[[1 2]<br/> [3 4]<br/> [5 6]]</span></pre><p id="2795" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这个数组<code class="fe pa pb pc pd b">x</code>可以很容易地转换成张量，如下所示:</p><pre class="ks kt ku kv gt pe pd pf pg aw ph bi"><span id="7c2b" class="mz na it pd b gy pi pj l pk pl">y=torch.from_numpy(x)<br/>print(y)</span><span id="cdae" class="mz na it pd b gy pm pj l pk pl">tensor([[1, 2],<br/>       [3, 4],<br/>       [5, 6]])</span></pre><p id="b71e" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们可以看到第二个印记表明它是一个张量。相反，如果我们想把一个张量转换成一个 NumPy 数组，我们可以这样做:</p><pre class="ks kt ku kv gt pe pd pf pg aw ph bi"><span id="1229" class="mz na it pd b gy pi pj l pk pl">z = y.numpy()<br/>print (z)</span><span id="ae2b" class="mz na it pd b gy pm pj l pk pl">[[1. 2.]<br/> [3. 4.]<br/> [5. 6.]]</span></pre><p id="705a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们将使用<code class="fe pa pb pc pd b">reshape()</code>函数，它返回一个与输入具有相同数据和元素数量的张量，但是具有指定的形状。如果可能，返回的张量将是输入的视图。否则，它将是一个副本(在内存中):</p><pre class="ks kt ku kv gt pe pd pf pg aw ph bi"><span id="f5b2" class="mz na it pd b gy pi pj l pk pl">one_d = torch.arange(0,16)<br/>print (one_d)</span><span id="faa8" class="mz na it pd b gy pm pj l pk pl">two_d= one_d.reshape(4,4)<br/>print (two_d)</span><span id="2f0a" class="mz na it pd b gy pm pj l pk pl">print(two_d.size())</span><span id="c61e" class="mz na it pd b gy pm pj l pk pl">tensor([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])</span><span id="c5c9" class="mz na it pd b gy pm pj l pk pl">tensor([[ 0, 1, 2, 3],<br/>        [ 4, 5, 6, 7],<br/>        [ 8, 9, 10, 11],<br/>        [12, 13, 14, 15]])</span><span id="1e4a" class="mz na it pd b gy pm pj l pk pl">torch.Size([4, 4])</span></pre><h1 id="70de" class="nw na it bd nb nx ny nz ne oa ob oc nh ki od kj nk kl oe km nn ko of kp nq og bi translated">3.定义模型</h1><p id="f0c4" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm nt lo lp lq nu ls lt lu nv lw lx ly im bi translated">在<code class="fe pa pb pc pd b">torch.nn</code>包中，您可以找到许多预定义的类，它们提供了编程神经网络所需的基本功能块。要定义<a class="ae mg" rel="noopener" target="_blank" href="/deep-learning-basics-1d26923cc24a">上一篇文章</a>中呈现的模型，可以使用该包中的<code class="fe pa pb pc pd b">Sequential</code>类来完成:</p><pre class="ks kt ku kv gt pe pd pf pg aw ph bi"><span id="ec4d" class="mz na it pd b gy pi pj l pk pl">modelPT= torch.nn.Sequential(            <br/>         torch.nn.Linear(784,10),<br/>         torch.nn.Sigmoid(), <br/>         torch.nn.Linear(10,10), <br/>         torch.nn.LogSoftmax(dim=1) <br/>         )</span></pre><p id="a9b0" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">该代码定义了由两个密集层(线性层)组成的神经网络，每个密集层 10 个神经元，一个具有 Sigmoid 激活函数，另一个具有 Softmax 激活函数。随着本系列的推进，我们将引入其他激活函数<a class="ae mg" rel="noopener" target="_blank" href="/learning-process-of-a-deep-neural-network-5a9768d7a651">作为 ReLU，我们将在本系列的下一篇文章中使用。</a></p><p id="ff1f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我想强调的是，前面的代码对前一篇文章中介绍的神经网络进行了一个小的转换:此外，它对最后一层的每个输出应用了对数运算。具体来说，<a class="ae mg" href="https://pytorch.org/docs/stable/nn.html#logsoftmax" rel="noopener ugc nofollow" target="_blank"> LogSoftmax 函数</a>可视为:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pp"><img src="../Images/a55470f970aa75ed46e2fcbbe31143c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5uTQMDS0Mz1cdYvwqLRfmw.png"/></div></div></figure><p id="396b" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">其中 Softmax 按照<a class="ae mg" rel="noopener" target="_blank" href="/deep-learning-basics-1d26923cc24a">上一篇</a>中的定义计算。与 Softmax 相比，LogSoftmax 有许多实际和理论上的优势，这些优势促使我们在构建神经网络时使用它，我们将在后面的部分中对此进行讨论。</p><p id="cee5" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">总之，我们定义的网络可以直观地表示出来，如下图所示:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pq"><img src="../Images/05ef77bfdc9125bee1405bfa449ae4c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*Ef_QWtacSei3oFVIxrYTQg.png"/></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">来源:<a class="ae mg" href="https://torres.ai" rel="noopener ugc nofollow" target="_blank"> torres.ai </a></p></figure><p id="4d9b" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">神经网络的第一层接收 784 个特征的张量，这些特征表示传递给第一层中 10 个神经元中的每一个的像素。一旦这 10 个神经元处理了这些信息，它们中的每一个都将信息传递给下一层的所有神经元，即第一层的所有 10 个神经元都与第二层的所有 10 个神经元相连。</p><p id="8215" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">第二层是具有 10 个神经元的 softmax 激活函数的层，这意味着它将返回 10 个概率值的张量，代表 10 个可能的数字。一般来说，分类网络的输出层将具有与类一样多的神经元，除了在二进制分类中，其仅需要一个神经元。让我们记住，我们使用的是 LogSoftmax 层，而不是 Softmax 层，因此返回的每个值将是当前数字的图像属于每个类的概率的对数。</p><p id="f582" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们可以用这个简单的例子来分析构成神经网络的参数。例如，在第一层中，对于 10 个神经元中的每一个，权重需要 784 个参数，因此需要 10 × 784 个参数来存储 10 个神经元的权重。此外，对应于每个神经元的 10 个偏置需要 10 个附加参数。因此，对于第一层，需要 7850 个参数。</p><p id="53b3" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在第二层中，作为 softmax 函数，需要将其所有 10 个神经元与前一层的 10 个神经元连接，因此，权重需要 10 × 10 个参数；除了对应于每个节点的 10 个偏置。这给了我们第二层总共 110 个必需的参数。</p><p id="5a4a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">总之，对于我们极其简单的神经网络，我们看到需要 7960 个参数，第一层需要 7850 个参数，第二层需要 110 个参数。</p><blockquote class="lz ma mb"><p id="329e" class="ld le mc lf b lg lh kd li lj lk kg ll md ln lo lp me lr ls lt mf lv lw lx ly im bi translated">通过对所有神经网络模块的基类<code class="fe pa pb pc pd b">nn.Module</code>进行子类化，我们可以创建自己的构建块，这些构建块可以堆叠在一起并在以后重用，这是通常所做的。但是考虑到这篇文章的初始性质，我们可以用这种基本的方式来定义我们的神经网络。读者可以查阅官方文件，了解关于这个话题的更多细节。</p></blockquote><h1 id="30ab" class="nw na it bd nb nx ny nz ne oa ob oc nh ki od kj nk kl oe km nn ko of kp nq og bi translated">4.定义优化器和损失函数</h1><p id="6fd5" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm nt lo lp lq nu ls lt lu nv lw lx ly im bi translated">正如我们在上一篇文章中所展示的，这些模型是通过迭代求解一个无约束优化问题来训练的。在每次迭代中，随机的一批训练数据被输入到模型中以计算损失函数值。然后，计算损失函数相对于网络权重的梯度(反向传播),并在梯度的负方向上更新权重。这些网络被训练，直到它们收敛到损失函数最小值。</p><h2 id="fbd9" class="mz na it bd nb nc nd dn ne nf ng dp nh lm ni nj nk lq nl nm nn lu no np nq iz bi translated">损失函数</h2><p id="7bb4" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm nt lo lp lq nu ls lt lu nv lw lx ly im bi translated">PyTorch 中大约有 20 种不同的损失函数，驻留在<code class="fe pa pb pc pd b">nn</code>包中，并作为<code class="fe pa pb pc pd b">nn.Module</code>子类实现。我们将在本系列中使用的一些常见标准损失函数有:</p><ul class=""><li id="c5de" class="om on it lf b lg lh lj lk lm oo lq op lu oq ly pr os ot ou bi translated"><code class="fe pa pb pc pd b">nn.MSELoss</code>:自变量之间的均方误差，是回归问题的标准损失。</li><li id="ad9b" class="om on it lf b lg ov lj ow lm ox lq oy lu oz ly pr os ot ou bi translated"><code class="fe pa pb pc pd b">nn.NLLLoss</code>:它计算“最大似然”标准，一般用于多类分类问题(如我们的 MNIST 例子)。</li><li id="5802" class="om on it lf b lg ov lj ow lm ox lq oy lu oz ly pr os ot ou bi translated"><code class="fe pa pb pc pd b">nn.CrossEntropyLoss</code>:计算与<code class="fe pa pb pc pd b">nn.NLLLoss</code>相同，但是它期望每个类的原始分数，并在内部应用 LogSoftmax(而 nn。NLLLoss 期望将对数概率作为输入)。</li></ul><p id="3c54" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">由于我们正在处理一个多类分类问题，我们选择交叉熵作为我们的损失函数。在这个例子中，我们使用负对数似然神经网络。NLLLoss()与 softmax nn 结合使用。LogSoftmax()函数，我们已经介绍过了。正如我们所说的，我们不应用 Softmax 来增加训练过程的数值稳定性，提出了一种替代方法来首先计算 Softmax，它使用指数运算，然后计算交叉熵损失，它使用概率的对数。如果读者对这方面的更多细节感兴趣，我推荐看一看<a class="ae mg" href="https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/" rel="noopener ugc nofollow" target="_blank">这篇文章</a>。</p><blockquote class="lz ma mb"><p id="479c" class="ld le mc lf b lg lh kd li lj lk kg ll md ln lo lp me lr ls lt mf lv lw lx ly im bi translated">使用 LogSoftmax 定义神经网络的缺点是，每次我们需要从神经网络输出中获取概率时，我们都需要记住应用 Softmax。</p></blockquote><p id="bd6f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">一般来说，读者会看到 PyTorch 代码中分配给<code class="fe pa pb pc pd b">criterion</code>的损失函数:</p><pre class="ks kt ku kv gt pe pd pf pg aw ph bi"><span id="950e" class="mz na it pd b gy pi pj l pk pl">criterion = torch.nn.NLLLoss()</span></pre><p id="3e2c" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">因此，计算误差的方法如下:</p><pre class="ks kt ku kv gt pe pd pf pg aw ph bi"><span id="84a3" class="mz na it pd b gy pi pj l pk pl">loss = criterion(logps, labels)</span></pre><p id="ee81" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我们在自变量中指出神经网络的输出和正确的标签。</p><h2 id="c20b" class="mz na it bd nb nc nd dn ne nf ng dp nh lm ni nj nk lq nl nm nn lu no np nq iz bi translated">【计算机】优化程序</h2><p id="ca1b" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm nt lo lp lq nu ls lt lu nv lw lx ly im bi translated">请记住，优化器采用模型参数的梯度并更改这些参数，以减少损失值。我们使用 PyTorch 提供的模块<code class="fe pa pb pc pd b">torch.optim</code>来优化模型，执行梯度下降，并通过反向传播来更新权重。这个软件包允许我们在几个算法(AdaGrad，RMSProp，Adam 等)中进行选择。)是梯度下降算法的不同变体，梯度下降算法是一种能够找到各种问题的最优解的通用优化算法。此刻，在这个例子中，我们将使用基本的<em class="mc">随机梯度下降</em> (SGD):</p><pre class="ks kt ku kv gt pe pd pf pg aw ph bi"><span id="b3db" class="mz na it pd b gy pi pj l pk pl">optimizer = torch.optim.SGD(modelPT.parameters(), lr=0.01)</span></pre><p id="7959" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">参数是优化器必须调整的<em class="mc">参数</em>和指示这些调整应该如何进行的<em class="mc">学习率</em>。请记住，优化器会以正确的方向迭代调整模型的参数(权重和偏差)(在其值上加一个“小”或减一个“小”，其中这个“小”是由<em class="mc">学习率</em>定义的)，从而减少误差。一般来说，重复该过程，直到误差降到可接受的水平以下。</p><blockquote class="lz ma mb"><p id="10e2" class="ld le mc lf b lg lh kd li lj lk kg ll md ln lo lp me lr ls lt mf lv lw lx ly im bi translated">导数用于计算正确的方向，特别是误差相对于参数的梯度。PyTorch 中的自动签名包正是通过自动微分来自动计算神经网络中的反向传递，从而提供了这种功能。</p></blockquote><h1 id="7e2f" class="nw na it bd nb nx ny nz ne oa ob oc nh ki od kj nk kl oe km nn ko of kp nq og bi translated">5.训练模型</h1><p id="05a0" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm nt lo lp lq nu ls lt lu nv lw lx ly im bi translated">一旦我们的模型被定义，学习方法被配置，它就可以被训练了。因此，我们只需定义将迭代所有数据的训练循环，以便优化器迭代地调整权重。让我们用这几行代码来讨论一个训练循环的通用蓝图:</p><pre class="ks kt ku kv gt pe pd pf pg aw ph bi"><span id="1bff" class="mz na it pd b gy pi pj l pk pl">1: for e in range(EPOCHS):<br/>      running_loss = 0<br/>2:    for images, labels in xy_trainPT_loader:<br/>3:        images = images.view(images.shape[0], -1)<br/>4:        output = modelPT(images)<br/>5:        loss = criterion(output, labels)<br/>6:        loss.backward()<br/>7:        optimizer.step()<br/>8:        optimizer.zero_grad()<br/>          running_loss += loss.item()<br/>      print(“Epoch {} — Training loss: {}”.format(e, <br/>             running_loss/len(xy_trainPT_loader)))</span></pre><p id="885c" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">第 1 行</strong>:通常，训练循环会反复迭代我们的数据。记住，对一组完整的例子的一次迭代被称为一个<em class="mc">时期。</em><code class="fe pa pb pc pd b">EPOCHS</code>变量表示在整个例子集上的迭代次数。</p><p id="959a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">第 2 行:</strong>我们已经介绍过，数据通常太大，无法一次放入 CPU 或 GPU 内存，因此它被分成大小相等的批次。每个<em class="mc">批次</em>都包含数据样本和目标标签，两者都必须是张量。</p><p id="9d4c" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">第 3 行:</strong>为了便于将数据输入我们的神经网络，我们必须将输入(图像)从二维(2D)转换为一维(1D)向量。</p><p id="ea81" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">第 4 行:</strong>我们将每批图像张量传递到模型中，该模型将返回一个对该批图像进行预测的张量，即前向传递。</p><p id="befc" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">第 5 行:</strong>得到预测后，我们将它们和它们的实际标签一起传递到交叉熵损失函数(<code class="fe pa pb pc pd b">criterion</code>)中，并计算损失。通常，损失函数接受两个参数:网络输出(预测)和期望输出(真实数据，也称为数据样本的标注)。</p><p id="5f5d" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">一些 PyTorch 的损失函数将类标签作为它们的目标(例如<a class="ae mg" href="http://pytorch.org/docs/nn.html#torch.nn.NLLLoss" rel="noopener ugc nofollow" target="_blank"> NLLloss </a>)，所以如果我们使用它们(如在我们的例子中)，我们不需要像我们在上一篇文章中介绍的那样将目标转换成一个热点向量(为了便于解释)。</p><p id="6498" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">第 6 行:</strong>我们使用损失值进行反向传递，以计算损失相对于模型参数的梯度。在<code class="fe pa pb pc pd b">loss.backward()</code>调用结束后，我们累积了梯度。</p><p id="2aa3" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">第 7 行:</strong>现在是优化器使用方法<code class="fe pa pb pc pd b">step()</code>修改模型参数的时候了，该方法从参数中提取所有梯度并应用它们。</p><p id="f276" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">第 8 行:</strong>训练循环的最后一部分，也是最重要的一部分，是我们对参数梯度归零的责任。在我们的网络上调用<code class="fe pa pb pc pd b">zero_grad()</code>清除所有优化变量的梯度。</p><p id="6d83" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">为了检查训练过程是如何发展的，我们在这个训练循环中添加了几行代码。首先，通过将每批迭代的所有损失相加，我们得到整个时期的训练损失:</p><pre class="ks kt ku kv gt pe pd pf pg aw ph bi"><span id="0501" class="mz na it pd b gy pi pj l pk pl">running_loss += loss.item()</span></pre><p id="9b88" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">第二步，用迭代次数对其求平均，并打印出来:</p><pre class="ks kt ku kv gt pe pd pf pg aw ph bi"><span id="9528" class="mz na it pd b gy pi pj l pk pl">print(“Epoch {} — Training loss: {}”.format(e, <br/>             running_loss/len(xy_trainPT_loader)))</span></pre><p id="e83f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">查看该输出，我们可以看到训练循环如何调整网络的权重，以便在每次迭代中，损失函数产生更小的损失。</p><pre class="ks kt ku kv gt pe pd pf pg aw ph bi"><span id="b6a3" class="mz na it pd b gy pi pj l pk pl">Epoch 0 — Training loss: 2.1822925415882932 <br/>Epoch 1 — Training loss: 1.8671700155048736<br/>Epoch 2 — Training loss: 1.5379922698809902<br/>Epoch 3 — Training loss: 1.287035460029838</span><span id="c8c3" class="mz na it pd b gy pm pj l pk pl">. . .</span><span id="98d2" class="mz na it pd b gy pm pj l pk pl">Epoch 15 — Training loss: 0.5162741374264139<br/>Epoch 16 — Training loss: 0.49991638108547815<br/>Epoch 17 — Training loss: 0.48541215611800453<br/>Epoch 18 — Training loss: 0.4724724407929347<br/>Epoch 19 — Training loss: 0.4608637086554631</span></pre><blockquote class="lz ma mb"><p id="333b" class="ld le mc lf b lg lh kd li lj lk kg ll md ln lo lp me lr ls lt mf lv lw lx ly im bi translated">在 PyTorch 中，没有像 Keras 或 Scikit-learn 中的<code class="fe pa pb pc pd b">fit()</code>那样的“预制”数据模型调优函数，所以训练循环必须由程序员指定。</p></blockquote><h1 id="5c56" class="nw na it bd nb nx ny nz ne oa ob oc nh ki od kj nk kl oe km nn ko of kp nq og bi translated">6.评估和使用模型</h1><p id="4c37" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm nt lo lp lq nu ls lt lu nv lw lx ly im bi translated">现在，我们已经完成了模型的训练，我们可能想要通过在测试数据集上应用它来测试我们的模型的一般化程度。</p><p id="c89a" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在 PyTorch 中，再次要求程序员指定评估循环:</p><pre class="ks kt ku kv gt pe pd pf pg aw ph bi"><span id="ee45" class="mz na it pd b gy pi pj l pk pl">xy_testPT = torchvision.datasets.MNIST(root='./data', <br/>            train=False, download=True, <br/>            transform=torchvision.transforms.<br/>            Compose([torchvision.transforms.ToTensor()]))</span><span id="199a" class="mz na it pd b gy pm pj l pk pl">xy_test_loaderPT = torch.utils.data.DataLoader(xy_testPT)</span><span id="168f" class="mz na it pd b gy pm pj l pk pl">correct_count, all_count = 0, 0<br/>for images,labels in xy_test_loaderPT:<br/>  for i in range(len(labels)):<br/>    img = images[i].view(1, 784)<br/>    logps = modelPT(img)<br/>    ps = torch.exp(logps)<br/>    probab = list(ps.detach().numpy()[0])<br/>    pred_label = probab.index(max(probab))<br/>    true_label = labels.numpy()[i]<br/>    if(true_label == pred_label):<br/>        correct_count += 1<br/>    all_count += 1</span><span id="36a6" class="mz na it pd b gy pm pj l pk pl">print("\nAccuracy of the model =", (correct_count/all_count))         </span><span id="acb4" class="mz na it pd b gy pm pj l pk pl">Accuracy of the model = 0.8657</span></pre><p id="66ee" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">读者可以看到这个循环中的指令与前一个训练循环中的指令相似。但在这种情况下，不是保留损失计算，而是计算准确性，即模型从未见过的数据的命中率。</p><p id="a5a2" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">仅此而已！你已经设计了一个完整的神经网络。恭喜你。</p><p id="ee1f" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">下一篇见<a class="ae mg" rel="noopener" target="_blank" href="/pytorch-performance-analysis-with-tensorboard-7c61f91071aa">！</a></p></div><div class="ab cl ps pt hx pu" role="separator"><span class="pv bw bk pw px py"/><span class="pv bw bk pw px py"/><span class="pv bw bk pw px"/></div><div class="im in io ip iq"><h1 id="50f6" class="nw na it bd nb nx pz nz ne oa qa oc nh ki qb kj nk kl qc km nn ko qd kp nq og bi translated">深度强化学习讲解系列</h1><p id="c09a" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm nt lo lp lq nu ls lt lu nv lw lx ly im bi translated"><strong class="lf jd">由</strong> <a class="ae mg" href="https://www.upc.edu/en" rel="noopener ugc nofollow" target="_blank"> <strong class="lf jd"> UPC 巴塞罗那理工</strong> </a> <strong class="lf jd">和</strong> <a class="ae mg" href="https://www.bsc.es/" rel="noopener ugc nofollow" target="_blank"> <strong class="lf jd">巴塞罗那超级计算中心</strong> </a></p><p id="4cf4" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">一个轻松的介绍性<a class="ae mg" href="https://torres.ai/deep-reinforcement-learning-explained-series/" rel="noopener ugc nofollow" target="_blank">系列</a>以一种实用的方式逐渐向读者介绍这项令人兴奋的技术，它是人工智能领域最新突破性进展的真正推动者。</p><div class="mh mi gp gr mj mk"><a href="https://torres.ai/deep-reinforcement-learning-explained-series/" rel="noopener  ugc nofollow" target="_blank"><div class="ml ab fo"><div class="mm ab mn cl cj mo"><h2 class="bd jd gy z fp mp fr fs mq fu fw jc bi translated">深度强化学习解释-乔迪托雷斯。人工智能</h2><div class="mr l"><h3 class="bd b gy z fp mp fr fs mq fu fw dk translated">本系列的内容</h3></div></div><div class="mt l"><div class="qe l mv mw mx mt my lb mk"/></div></div></a></div><h1 id="89c0" class="nw na it bd nb nx ny nz ne oa ob oc nh ki od kj nk kl oe km nn ko of kp nq og bi translated">关于这个系列</h1><p id="87a4" class="pw-post-body-paragraph ld le it lf b lg nr kd li lj ns kg ll lm nt lo lp lq nu ls lt lu nv lw lx ly im bi translated">我在五月份开始写这个系列，那是在巴塞罗那的封锁期。老实说，由于封锁，在业余时间写这些帖子帮助了我<a class="ae mg" href="https://twitter.com/hashtag/StayAtHome?src=hashtag_click" rel="noopener ugc nofollow" target="_blank"> <strong class="lf jd"> #StayAtHome </strong> </a>。感谢您当年阅读这份刊物；它证明了我所做的努力。</p><p id="d079" class="pw-post-body-paragraph ld le it lf b lg lh kd li lj lk kg ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf jd">免责声明</strong> —这些帖子是在巴塞罗纳被封锁期间写的，目的是分散个人注意力和传播科学知识，以防对某人有所帮助，但不是为了成为 DRL 地区的学术参考文献。如果读者需要更严谨的文档，本系列的最后一篇文章提供了大量的学术资源和书籍供读者参考。作者意识到这一系列的帖子可能包含一些错误，如果目的是一个学术文件，则需要对英文文本进行修订以改进它。但是，尽管作者想提高内容的数量和质量，他的职业承诺并没有留给他这样做的自由时间。然而，作者同意提炼所有那些读者可以尽快报告的错误。</p></div></div>    
</body>
</html>