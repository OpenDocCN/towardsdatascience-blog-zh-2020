<html>
<head>
<title>Geometric Deep Learning: A Quick Tour</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">几何深度学习:快速浏览</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/geometric-deep-learning-a-quick-tour-12cef72492ca?source=collection_archive---------70-----------------------#2020-06-22">https://towardsdatascience.com/geometric-deep-learning-a-quick-tour-12cef72492ca?source=collection_archive---------70-----------------------#2020-06-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c2ae" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">下面的文档提供了几何深度学习中一些基本概念的旋风之旅。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/af74de34ae3fa6e37d14072a55372828.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IfTQ981iIhsQT6z5IqMVmw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">克林特·王茂林在<a class="ae ky" href="/s/photos/network?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><blockquote class="kz la lb"><p id="0fa7" class="lc ld le lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">找到这篇文章的乳胶版本<a class="ae ky" href="https://blog.eekosasih.com/notes/geometric-deep-learning" rel="noopener ugc nofollow" target="_blank">在这里</a></p></blockquote><p id="89e9" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">下面的文档提供了几何深度学习中一些基本概念的旋风之旅。数学推导可能没有严格地显示出来，有些方程没有证明。这样做是为了使文档简短而又足够全面。更深入的分析请参考布朗斯坦等人(2017)、龚(2018)、基普夫等人(2017)、哈蒙德等人(2011)、等人(2011)<a class="ae ky" href="http://geometricdeeplearning.com/" rel="noopener ugc nofollow" target="_blank">、</a>。这是一份动态文档，如果您发现任何错误或不一致之处，请告诉我，我会尽快修复。我绝不是这方面的专家，因为这篇笔记只是为了我自己的学习目的而写的。</p><p id="5a4c" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">我们首先回顾图中拉普拉斯矩阵的概念及其特征值分解。接下来，我们在图中定义卷积运算，并表明它等价于在图的谱域中应用滤波器，这里的谱指的是拉普拉斯算子的特征值。我们表明，通过构造，谱卷积类似于将拉普拉斯算子应用于函数。最后，我们展示如何用切比雪夫多项式的和来近似拉普拉斯滤波器，以降低算法复杂度(因为执行完整的特征值分解是<strong class="lf iu"> O(n ) </strong>其中<strong class="lf iu"> n </strong>是图中顶点的数量。</p><h1 id="06c2" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">图拉普拉斯算子</h1><p id="d2a3" class="pw-post-body-paragraph lc ld it lf b lg mu ju li lj mv jx ll lz mw lo lp ma mx ls lt mb my lw lx ly im bi translated">假设我们有一个无向、连通且加权的图<strong class="lf iu"> G = (V，e，W) </strong>其中<strong class="lf iu"> V </strong>是一组<strong class="lf iu"> |V| = n </strong>个顶点，<strong class="lf iu"> E </strong>是一组边，<strong class="lf iu"> W </strong>是每条边的一组权重<em class="le">w</em>ᵢⱼ<strong class="lf iu">I ~ j</strong>。定义<strong class="lf iu"> D </strong>为度矩阵，其中d =diag(σⱼ<em class="le">w</em>ᵢⱼ).归一化图拉普拉斯δ可以定义如下。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/4e06ecd750dc54102801a12571463250.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*TSJk4myXoLKSuMDDEV8LUg.png"/></div></figure><p id="c3c5" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">我们可以如下对拉普拉斯矩阵δ执行特征值分解。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/3cddec7db1dd09b64c185be2c41f0382.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*bPF6RW-MVV4Lr1_DUTbC0A.png"/></div></figure><h1 id="5ad5" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">光谱卷积</h1><p id="d467" class="pw-post-body-paragraph lc ld it lf b lg mu ju li lj mv jx ll lz mw lo lp ma mx ls lt mb my lw lx ly im bi translated">受傅立叶变换中卷积运算的启发，我们将图形卷积定义为对拉普拉斯谱分量应用滤波器。简而言之，这个想法是将输入函数<strong class="lf iu"> f </strong>投影到它的“傅立叶”基，或者这里借助于<strong class="lf iu">φ</strong>ᵀ<strong class="lf iu">f</strong>的拉普拉斯特征向量。将基乘以滤波后的特征值<strong class="lf iu">ĥ(λ)</strong>，得到<strong class="lf iu">ĥ(λ)φ</strong>ᵀ<strong class="lf iu">f</strong>。最后，通过与<strong class="lf iu">φ</strong>的点积应用“逆傅立叶变换”，得到<strong class="lf iu">φĥ(λ)φ</strong>ᵀ<strong class="lf iu">f</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/281bccf3cc7f95ffa157d7124ff3be8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*MOpvNnNUnl7XK9pQ6uSFtQ.png"/></div></div></figure><p id="9e2a" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">在进行一些重新排列后，我们可以看到，等式的右侧可以转换为等式5中归一化拉普拉斯矩阵δ=φ<strong class="lf iu">λ</strong>φᵀ的函数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/e77e03185fd26069666e4c4280154269.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/format:webp/1*HLU0yVekUD3mYvtSUUIW7g.png"/></div></figure><p id="d54a" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">现在，与卷积神经网络类似，我们希望应用1个以上的卷积滤波器，并增加一个非线性输出转换。假设我们使用带有<strong class="lf iu"> ξ </strong>非线性变换的<strong class="lf iu"> p </strong>滤波器，频谱卷积网络定义如下。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/9ecd2dbecc8b8a0c896eff402903cb56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v7WrO2qXB8Twt2v-pUR0Zw.png"/></div></div></figure><h1 id="5ed3" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">用切比雪夫多项式逼近</h1><h2 id="b96b" class="ne md it bd me nf ng dn mi nh ni dp mm lz nj nk mo ma nl nm mq mb nn no ms np bi translated">ChebNets</h2><p id="c40a" class="pw-post-body-paragraph lc ld it lf b lg mu ju li lj mv jx ll lz mw lo lp ma mx ls lt mb my lw lx ly im bi translated">等式12的主要问题是我们需要计算所有特征向量，复杂度为O(|V|)。当我们用|V| &gt; &gt;处理非常大的图时，这是不可伸缩的。ChebNets的主要思想是用一组正交切比雪夫多项式来逼近φ<strong class="lf iu">ĥ</strong>(λ)φᵀ，这些多项式可以使用以下公式迭代计算。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/92159b1d57613b118da4102c97c31504.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*_m256reAiZylarEPi_lJkw.png"/></div></figure><p id="6d74" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">我们首先用<strong class="lf iu"> r </strong>切比雪夫多项式的加权和来近似特征值滤波器，其采用变换后的特征值矩阵λ^.需要这种变换，因为只有当输入域区间在<strong class="lf iu"> [-1，1】</strong>时，切比雪夫多项式才形成正交基。同时，特征值范围从<strong class="lf iu">【0，λ </strong>，ₘₐₓ<strong class="lf iu"/>。因此，为了将后者转换成前者，我们可以应用<strong class="lf iu"> 2x/λ </strong> ₘₐₓ <strong class="lf iu"> -1 </strong>，使得对于x = 0，(2(0)/λₘₐₓ-1 = -1)，对于x = λₘₐₓ，(2λₘₐₓ/λₘₐₓ -1 = 1)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/6653659792c219ef78329f48a31e7318.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/1*TGLgp8BBTrH8No9adF5_Bg.png"/></div></figure><p id="82a7" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">现在，我们可以利用等式12，用切比雪夫多项式代替滤波器。注意<strong class="lf iu">λ^ = 2λ/λₘₐₓ-I</strong>类似的，<strong class="lf iu">δ^ = 2δ/λₘₐₓ-I</strong>。通过重排，我们可以将右侧转换为应用于归一化拉普拉斯<strong class="lf iu">δ^</strong>的切比雪夫多项式之和。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/52f71bcb8228d49ef9f88ecbc306cefa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EwUhQAbmNzXucC2EA6_XSQ.png"/></div></div></figure><h2 id="50aa" class="ne md it bd me nf ng dn mi nh ni dp mm lz nj nk mo ma nl nm mq mb nn no ms np bi translated">图表网络</h2><p id="86bf" class="pw-post-body-paragraph lc ld it lf b lg mu ju li lj mv jx ll lz mw lo lp ma mx ls lt mb my lw lx ly im bi translated">GraphConvNets是ChebNets的一个特例，这里我们只取2个Chebyshev多项式项<strong class="lf iu"> r = 2 </strong>。由于使用了归一化拉普拉斯δ，已经证明了<strong class="lf iu"> λₘₐₓ = 2 </strong>。我们可以用等式21代替给定的假设。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/dccb0397e87978f1bd1d79b29f66f4bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O7s1BJGcsxQ9_FaYlodI1Q.png"/></div></div></figure><p id="5c44" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">我们现在有了一个纯粹使用度矩阵<strong class="lf iu"> D </strong>和权重矩阵<strong class="lf iu"> W </strong>定义的图形卷积网络。为了进一步简化，我们假设α₀ = -α₁ = α。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/5d36cf1b2c6f58c5feb51748c6c6fe61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*QQxSHue3OVkLizGUfpTd_A.png"/></div></figure><p id="d9f1" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">尽管在实践中，由于本征值在[0，2]范围内，重复应用这种乘法可能会导致数值不稳定。因此，我们通过让<strong class="lf iu">ŵ= w+I</strong>和d̂= diag(σ{ j≠I } ŵᵢⱼ).正如在Kipf和Welling (2017)中所写的，这相当于设置以下重整化技巧:I+d^(-1/2)w d^(-1/2)= d̂^(-1/2)w d̂^(-1/2)</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/2bdab1084600a60bcc182386d0374246.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*Hx769LT1IFAoh9XwqdgQcA.png"/></div></figure><p id="1b7c" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">使用这些假设，GraphConvNets避开了对切比雪夫多项式的显式计算的需要，并导致了对每个顶点的邻域的加权和运算的纯应用。</p><h1 id="8ea5" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">参考</h1><p id="6707" class="pw-post-body-paragraph lc ld it lf b lg mu ju li lj mv jx ll lz mw lo lp ma mx ls lt mb my lw lx ly im bi translated">Bronstein，M. M .、布鲁纳，j .、LeCun，y .、Szlam，a .、Vandergheynst，P. (2017)。几何深度学习:超越欧几里德数据。IEEE信号处理杂志，34(4):18{42。arXiv: 1611.08097。</p><p id="32a6" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">龚，S. (2018)。几何深度学习。伦敦帝国学院硕士论文。</p><p id="3747" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">Hammond，D. K .，Vandergheynst，p .，和Gribonval，R. (2011)。基于谱图论的图的小波。应用和计算谐波分析，30(2):129{150。</p><p id="686e" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">舒曼，D. I .，Vandergheynst，p .，和Frossard，P. (2011)。分布式信号处理的切比雪夫多项式逼近。2011年传感器系统和研讨会分布式计算国际会议(DCOSS)，第1-8页。arXiv: 1105.1891。</p><p id="ddd7" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">T.Kipf，M. Welling，<a class="ae ky" href="https://arxiv.org/pdf/1609.02907.pdf" rel="noopener ugc nofollow" target="_blank">图卷积网络半监督分类</a>，<em class="le"> ICLR </em> 2017</p></div></div>    
</body>
</html>