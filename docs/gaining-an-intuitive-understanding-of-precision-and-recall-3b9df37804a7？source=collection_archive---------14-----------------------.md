# 直观了解精确度、召回率和曲线下面积

> 原文：<https://towardsdatascience.com/gaining-an-intuitive-understanding-of-precision-and-recall-3b9df37804a7?source=collection_archive---------14----------------------->

## 理解精确度和召回率的友好方法

在这篇文章中，我们将首先解释精确和召回的概念。我们将尝试不只是扔给你一个公式，而是使用一个更直观的方法。通过这种方式，我们希望对这两个概念有一个更直观的理解，并提供一个很好的记忆技巧，让你再也不会忘记它们。我们将以对精确回忆曲线的解释和曲线下面积的含义来结束这篇文章。这篇文章是为初学者和高级机器学习实践者准备的，他们想更新他们的理解。在这篇文章的最后，你应该对什么是精确和召回有一个清晰的理解。

我们将从二元分类任务的情况开始解释。二进制意味着每个样本只能属于两个类别，例如狗和猫。我们将用 0 标记属于第一类(猫)的样品，用 1 标记属于第二类(狗)的样品。

![](img/59ae585748794e6c3d80b043bbca73ef.png)

从[https://www.pexels.com/](https://www.pexels.com/)获得的图像

在分类问题中，神经网络是在标记数据上训练的。这意味着来自训练、验证和测试集的每个样本都由人来标记。由人类赋予的标签被称为地面真相。

在分类任务中，数据成对提供:

*   输入数据
*   地面真实标签

输入数据不一定是图像，也可以是文本、声音、坐标等。

输入数据接下来被馈送到神经网络，并且我们获得样本属于哪个类别的预测。请注意，精确召回曲线只能为输出概率(也称为置信度)的神经网络类型(或更一般的分类器)计算。在二元分类任务中，输出样本属于类别 1 的概率就足够了。让我们称这个概率为 *p* 。样本属于 0 类的概率正好是:1 - *p* 。

因此，如果神经网络输出 *p* =0.99，则相当有把握，馈送的输入数据属于类别 1，即输入数据是狗的图像。如果网络输出 *p* =0.01，则可以确信输入数据不属于第 1 类。这相当于美联储输入数据属于概率 1 - *p* = 0.99 的 0 类。

为了获得给定样本的具体类别预测，我们通常使用阈值 0.5 来设定神经网络输出的阈值。这意味着高于 0.5 的值被认为属于类别 1，而低于 0.5 的值表示类别 0。

有了所有的定义，我们接下来可以定义真阳性、假阳性、真阴性和假阴性的概念。

# 真阳性、假阳性等。

现在基于神经网络的输出，我们得到以下四种情况:

**情况 1** :真阳性

输入样本属于类别 1，并且神经网络正确地输出 1。

![](img/2b98da610f14cf7ba024de9f8a354e7b.png)

由于历史原因，这被称为真正的积极。记住:正= 1。

**案例二**:假阳性

输入样本属于类 0。然而，神经网络错误地输出 1。

![](img/17866d0e73113541ec858ad73a16cfce.png)

**情况 3** :真阴性

输入样本属于类别 0，并且神经网络正确地输出 0。

![](img/b6e37552d726f2582a98bdd32cdaec78.png)

同样，由于历史原因，这被称为真正的否定。记住:负= 0。

**情况 4** :假阴性

输入样本属于类别 1。然而，神经网络错误地输出 0。

![](img/1edeb5418e3f75aefbdad01fb155118c.png)

我们将数据集中的真阳性数表示为 TP，假阳性数表示为 FP，依此类推。在继续阅读之前，请真正熟悉 TP、FP、TN 和 FN 的概念。

接下来，我们将定义精度的概念。

# 精确

我们有以下由 10 个样本组成的数据集:

![](img/bb8455ff41738b88143adca68f66bde8.png)

从[https://www.pexels.com/](https://www.pexels.com/)获得的图像

请注意，所选的数据集是不平衡的，即与具有 7 个实例的猫类相比，狗类仅具有 3 个实例。在处理真实数据集时，几乎总是会遇到数据不平衡的问题。相比之下，像 CIFAR-10 的 MNIST 这样的玩具数据集具有均等的类分布。精确度和召回率作为评估神经网络在不平衡数据集上的性能的度量特别有用。

我们将上述每个输入数据输入神经网络，并获得每个样本的概率/置信度:

![](img/9f0d7fa292a745dcb513ba0e8424b220.png)

接下来，我们根据预测的置信度对表格进行排序。我们将实际阳性样品涂上绿色，将实际阴性样品涂上红色。相同的颜色方案应用于正面和负面预测。我们再次假设阈值为 0.5。

![](img/205567fec089cfd7368fff7eee27125a.png)

阈值 0.5 →精度= 3/6 = 0.5

正面预测可以分成一组 TP 和一组 FP。
我们将精度定义为以下比率:

![](img/4f236e2a8ecf04086fd71cbf9a3dab38.png)

因此，精度衡量**你的正面预测有多准确**，也就是说，你的正面预测正确的百分比。请注意，总和 TP+FP 对应于被分类器预测为阳性的样本总数。

记住精度的定义是一件困难的事情，在几周内记住它就更难了。对我帮助很大的是记住了上面的彩色表格。请记住，精度是第一行上方箭头的长度(实际值)除以第二行下方箭头的长度(预测值)，并且记住绿色代表 1(或正值)。

请注意，在精度的定义中没有使用 FN。

为了更深入地了解精确度的概念，让我们改变定义样本被分类为阳性还是阴性的阈值。

如果我们将阈值降低到 0.3，我们会得到 0.375 的精度。记住，阈值为 0.5 时，精度为 0.5。

![](img/439943ff81c206bcf84e17c5f9caf8ef.png)

阈值 0.3 →精度= 3/8 = 0.375

如果我们将阈值进一步降低到 0.0，我们会得到 0.3 的精度。**重要提示**:这对应于我们数据集中狗的比例，因为 10 个样本中有 3 个属于狗类。
我们观察到，降低阈值也会降低精度。

接下来，我们将阈值增加到 0.7，并获得 0.75 的精度。

![](img/32291c8541d4684566c063d9a3a649a5.png)

阈值 0.7 →精度= 3/4 = 0.75

最后但同样重要的是，我们将阈值增加到 0.9，并获得 1.0 的精度。请注意，在这种情况下，我们没有任何误报。我们得到一个假阴性，如上所述，在精度计算中不考虑这个假阴性。

![](img/9f76285cfbf5a5ac2ac73c7bd6470390.png)

阈值 0.9 →精度= 2/2 = 1.0

收集所有的结果，我们得到下面的图表:

![](img/e4dd8da6a3ced36ac8f26bf1aa2d3e4d.png)

我们看到精度在 0 和 1 之间。当阈值增加时，它增加。我们还注意到，只要阈值足够大，精度可以变得任意好。因此，精度不能单独用来评估分类器的性能。我们需要第二个指标:召回率。

# 回忆

我们有以下由 10 个样本组成的数据集:

![](img/8b4b72384326a3b36fb2456021bc429d.png)

从[https://www.pexels.com/](https://www.pexels.com/)获得的图像

请注意，为了解释清楚，我们使用了不同于以前的数据集。dog 类现在有 7 个实例，而 cat 类只有 3 个实例。

我们将上述每个输入数据输入神经网络，并获得以下置信度:

![](img/75240430d7506ed97d66eae11ddee88a.png)

我们再次根据获得的置信度值对表格进行排序。我们使用与之前相同的颜色方案，并再次假设阈值为 0.5。

![](img/595b444a5943ab2fbce9021f9b7ca88e.png)

阈值 0.5 →回忆= 5/7 = 0.714

这一次，我们将实际阳性分为一组 TP 和一组 FN，并将召回率定义为以下比率:

![](img/fa9822f1d635c28b9e7c8855213ea1be.png)

因此，召回衡量的是**你发现所有实际阳性样本有多好**，即实际阳性样本被正确分类的百分比。请注意，总和 TP+FN 对应于数据集中实际阳性样本的总数。

为了记住回忆的定义，你可以再次使用上面的彩色表格。回忆是第二行下面箭头的长度(预测)除以第一行上面箭头的长度(实际)，记住绿色代表 1(或正)。

为了更深入地理解回忆的概念，让我们再次改变定义样本被分类为阳性还是阴性的阈值。

如果我们将阈值降低到 0.3，我们将得到 1.0 的召回。请记住，对于 0.5 的阈值，召回率为 0.714。与精确度相反，当阈值降低时，回忆似乎增加。

![](img/f9bd8d94631a412d4786b69539b08639.png)

阈值 0.3 →回忆= 7/7 = 1.0

请注意，在上述情况下，我们没有任何假阴性。我们得到一个误报，如上所述，在召回的计算中不考虑它。如果我们将阈值进一步降低到 0.0，我们仍然得到 1.0 的召回。这是因为对于阈值 0.3，所有实际阳性都被预测为阳性。我们还注意到，只要阈值足够小，回忆可以是任意好的。这与 precision 的行为是相反的，也是这两个指标如此好地一起工作的原因。

接下来，我们将阈值提高到 0.7，得到 0.571 的召回率。

![](img/4c8ca8dee18e5e533c6883dfff5c5a79.png)

阈值 0.7 →回忆= 4/7 = 0.571

最后但同样重要的是，我们将阈值提高到 0.9，并获得 0.285 的召回率。

![](img/b9e9ddc74d58d8d9879ae786745d4c4b.png)

阈值 0.9 →回忆= 2/7 = 0.285

收集所有的结果，我们得到下面的图表:

![](img/31b78fe42cc1af5f4b04220a3aa9b76a.png)

我们看到召回率在 0 和 1 之间。当阈值增加时，它减小。我们还注意到，只要阈值足够小，回忆可以是任意好的。

接下来，我们将结合精度和召回率，得出精度-召回率曲线(PR-curve)。

# 精确回忆曲线

对于 0 和 1 之间的所有阈值，通过在 y 轴上绘制精度，在 x 轴上绘制召回，获得精度-召回曲线。典型的(理想化的)精确召回曲线如下图所示:

![](img/b012c2804196fffe21cd1eb6d09f4e71.png)

我们已经看到，对于非常高的阈值(高意味着略小于 1.0)，精度非常高，召回率非常低。这由图表左上角的红点表示。

对于非常低的阈值(略大于 0.0)，我们已经表明，召回率几乎为 1.0，精度与数据集中阳性样本的比率相同。).图中右下角的红点显示了这一点。

完美分类器的精度-召回曲线如下所示:

![](img/ed8b91def3546c4c67e5b63e994f83dd.png)

一个非常差的分类器(随机分类器)的精确召回曲线看起来像这样:

![](img/0a90759d772420c4c9ff2c7178b57928.png)

有了这些知识，你现在应该能够判断一个任意的精确召回曲线属于一个好的还是一个坏的二元分类器。请注意，要正确解释精密度-召回率曲线，您还需要知道阳性样本与所有样本的比率。

# 1.1 精确召回曲线下面积(PR-AUC)

最后，我们得出度量 PR-AUC 的定义。PR-AUC 的一般定义是找到精确度-召回曲线下的面积:

![](img/33cc973211ce8e0391a34c575bbd8652.png)

如下图所示:

![](img/bb9f0217f86ad7f478b15756b6df6b5a.png)

因此，PR-AUC 将精度-召回曲线总结为单个分数，并且可以用于容易地比较不同的二元神经网络模型。请注意，完美分类器的 PR-AUC 值总计为 1.0。随机分类器的 PR-AUC 值等于数据集中阳性样品与所有样品的比率。

在我们的下一篇文章中，我们将展示如何使用 Python 轻松实现 PR-AUC。