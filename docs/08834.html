<html>
<head>
<title>I brought you some HD graphics! How neural nets can improve old games</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我给你带了些高清图！神经网络如何改进旧游戏</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/i-brought-you-some-hd-grphics-how-neural-net-can-improve-old-games-7a8b97dffd61?source=collection_archive---------21-----------------------#2020-06-25">https://towardsdatascience.com/i-brought-you-some-hd-grphics-how-neural-net-can-improve-old-games-7a8b97dffd61?source=collection_archive---------21-----------------------#2020-06-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="817d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用于实时超分辨率的神经网络</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/55f15b0c1146521309f98cc2986e18d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*8dcKTJv3IwKOZZTHa0SLqw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">铁血联盟截图(<em class="ku">图片作者</em>)</p></figure><p id="e122" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">用于游戏图形增强的实时超分辨率(RTSR)神经网络(仅限Nvidia GPU)</p><p id="9791" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在90年代，当我还是个孩子的时候，我喜欢在我的电脑上玩视频游戏。在俄国，那时个人电脑还不太多，所以我的第一个游戏站是ZS Spectrum，里面有游戏磁带。色彩鲜艳明亮的DOS游戏后来成了我真正的发现。对我来说，大多数现存的流派都是从90年代开始的。在有点怀旧之后，我决定回忆一下我的青春，在Dosbox模拟器上运行一个旧游戏，但受到了巨大像素和低分辨率的不愉快打击。虽然大像素的旧图形可能有其魅力，但许多人现在对这种质量不满意。</p><p id="19fb" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">对于游戏玩家来说，提高图形质量通常至关重要。育碧在2014年花了大约六个月的时间为高清游戏《英雄3》重绘纹理，并引发了人们对这款游戏的兴趣</p><p id="21c0" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">【https://trends.google.com/trends/explore? T2】日期= 2012-06-01% 202020-06-25&amp;q = % 2Fm % 2f 056 _ 97，%2Fm%2F065pfn </p><p id="e981" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">同样的情况也发生在CNC系列第一场由于高-its res remaster(红线)(<a class="ae lr" href="https://www.ea.com/ru-ru/games/command-and-conquer/command-and-conquer-remastered" rel="noopener ugc nofollow" target="_blank">https://www . ea . com/ru-ru/games/command-and-conquer/command-and-conquer-remastered</a>)。</p><p id="d0e8" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">并不是每个游戏都值得高清重制，因为重绘图形需要花费很多精力。另一种方法是算法增强。</p><p id="ac8f" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">为了提高分辨率，消除游戏中的大像素和台阶，目前使用了各种后处理和反走样算法(更多详细信息，请参见<a class="ae lr" href="https://vr.arvilab.com/blog/anti-aliasing" rel="noopener ugc nofollow" target="_blank">https://vr.arvilab.com/blog/anti-aliasing</a>)，但反走样算法会导致所有令人讨厌的“模糊”图片，这往往比大像素的棱角更不可取。</p><p id="2a1f" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">但是你可以尝试使用超分辨率技术来提高图像质量。超分辨率的想法是使用神经网络来提高图像的分辨率，绘制丢失的像素。现在已经取得了令人印象深刻的结果，类似于改进Bladerunner电影中的图像的场景</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ls lt l"/></div></figure><p id="5c10" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">超分辨率技术改善了图像的视觉感知，例如，这里的<a class="ae lr" href="https://github.com/tg-bomze/Face-Depixelizer" rel="noopener ugc nofollow" target="_blank">https://github.com/tg-bomze/Face-Depixelizer</a>，但是给图像带来了新的信息。它可以用来提高电影质量【https://www.youtube.com/watch?v=49oj2JUtn0A<a class="ae lr" href="https://www.youtube.com/watch?v=49oj2JUtn0A" rel="noopener ugc nofollow" target="_blank"/><a class="ae lr" href="https://www.youtube.com/watch?v=3RYNThid23g" rel="noopener ugc nofollow" target="_blank">【https://www.youtube.com/watch?v=3RYNThid23g】T5。然而，大多数算法都是资源密集型的，而且相当慢，我想创建一个脚本来实时改善游戏。</a></p><h1 id="7453" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">一点理论</h1></div><div class="ab cl mm mn hx mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="im in io ip iq"><p id="818e" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">以下所有内容将适用于卷积神经网络(<a class="ae lr" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Convolutional_neural_network</a>)，这是一种用于处理图像的神经网络子类型。首先，让我们看看神经网络如何解决超分辨率问题。该任务非常类似于自动编码器任务的解决方案(<a class="ae lr" href="https://en.wikipedia.org/wiki/Autoencoder" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Autoencoder</a>)。为了在输出端得到相同的图像，有必要将图像输入到网络输入端。然而，自动编码器通常用于解决高效数据压缩的问题，因此，其架构的一个特点是瓶颈——瓶颈，即具有少量神经元的网络层。这种层的存在使得剩余部分学习信息的有效编码和解码。为了训练超分辨率网络，首先有意降低高质量图像的分辨率，并将其输入神经网络。预期的输出是高质量的源图像。超分辨率任务定义了所用网络的架构。</p><p id="8e90" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">通常，输入和输出数据之间有一个连接(跳过连接)，这大大加快了学习速度。输入数据的像素大小增加，并被添加到卷积网络的输出中。因此，你不需要完全从头开始训练网络来把图像变成几乎一样的。这种联系允许训练画出通过增加像素尺寸而放大的图像和真实的高清图像之间的差异。在不同级别和通过不同层数的跳跃连接的想法是非常有效的，并导致了网络的剩余网络类的出现。如今，几乎所有流行的建筑都采用了这种连接方式。在这里可以找到解决超分辨率问题的最新架构的很好的概述(<a class="ae lr" href="https://github.com/krasserm/super-resolution" rel="noopener ugc nofollow" target="_blank">https://github.com/krasserm/super-resolution</a>)。我的任务是创建一个神经网络来实时解决超分辨率问题。</p><p id="ed0a" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">具有四个残差块的edsr架构被选择为分辨率增加4倍(标准edsr具有16个块)。在研究和优化之后，其尺寸显著减小(非线性部分的尺寸减小了4个块，并且线性上采样步骤被优化而没有优化质量损失),并且速度被提高而没有显著的质量损失。一般网络架构如图所示。每个块是一个X * Y * N图像，其中宽度对应于通道的数量。转换—对应于3×3卷积(在res块之后激活非线性ReLU的情况下)。升级步骤——由于渠道变平而导致的维度增加。</p></div><div class="ab cl mm mn hx mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="im in io ip iq"><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi mt"><img src="../Images/b8256fd126681744c060f49f8b11f83a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kyZrSbGPg1e4Jb_bcsjWeA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">超分辨率的EDSR卷积网络(<em class="ku">图片作者</em></p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi my"><img src="../Images/d4b873b122c5f9a6d3325d557a2524e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8VTajn6IIp1C8sWR3CQ8eg.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">我提出的RTSR建筑(更快)(<em class="ku">作者图片</em>)</p></figure><p id="70ee" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">高质量的照片已经从<a class="ae lr" href="https://data.vision.ee.ethz.ch/cvl/DIV2K/" rel="noopener ugc nofollow" target="_blank">https://data.vision.ee.ethz.ch/cvl/DIV2K/.</a>下载，一般任何照片都可以。训练的代码在这里(有一些来自<a class="ae lr" href="https://github.com/krasserm/super-resolution" rel="noopener ugc nofollow" target="_blank">https://github.com/krasserm/super-resolution</a>的函数用于数据生成器)。用于更好工作的图像大小调整是像素化游戏中最接近<a class="ae lr" href="https://pillow.readthedocs.io/en/stable/reference/Image.html" rel="noopener ugc nofollow" target="_blank">的</a>方法</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mz lt l"/></div></figure><p id="2d8f" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我要指出的是，裁员方法对培训质量影响很大。下采样的最佳方法是最近邻或中值滤波。包括像素平均的方法通常不适用。</p><p id="8834" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">之后，移除。/cache文件夹并用我们的数据重新创建生成器(适当缩小)</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mz lt l"/></div></figure><p id="864c" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">输出是具有简单架构的相对较小(2.6 MB)的神经网络。同时，该检查给出了与预训练的16块网络的细微差别:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/690310d7f4b93fd369c6c4e53bca6da0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/1*H2lucbPIp-qWLZWBPEGJ9A.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">左侧—初始图像，右侧—16块edsr，中间rtsr。低分辨率图像来自Github <a class="ae lr" href="https://github.com/krasserm/super-resolution" rel="noopener ugc nofollow" target="_blank">项目</a>。增强图像是<em class="ku">作者图像</em></p></figure><h1 id="987a" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">运行网络</h1><p id="80f5" class="pw-post-body-paragraph kv kw it kx b ky nb ju la lb nc jx ld le nd lg lh li ne lk ll lm nf lo lp lq im bi translated">我已经在一个支持cud nn(https://developer.nvidia.com/cudnn)的显卡(我有一个GTX 1060 3 Gb)上启动了最终的网络，以获得高性能。以下是与RTSR一起玩的链接:</p><p id="c37b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">【https://github.com/Alexankharin/RTSR T4】</p><p id="8402" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">用于推断的管道如下:</p><p id="23c0" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">1.从区域或窗口捕捉图像</p><p id="41ca" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">2.经由RTSR的图像增强</p><p id="434a" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">3.在新窗口中绘制增强图像</p><p id="14f5" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在开发过程中，我发现当在DOSBox模拟器中启动游戏时，分辨率是640x480像素，但大多数情况下它是通过将像素大小加倍来产生的，因此在增强之前，可能需要可选的初始320x240图像恢复步骤(我后来发现了详细信息<a class="ae lr" href="https://www.dosgamers.com/dos/dosbox-dos-emulator/screen-resolution" rel="noopener ugc nofollow" target="_blank">https://www . dosgamers . com/dos/dos box-dos-emulator/screen-resolution</a>)。</p><p id="4b7b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">截图使用Linux中的mss库或windows中的d3dshot库</p><p id="fb39" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">图像处理和绘图——使用OpenCV-python和PIL库。要关闭窗口，激活它并按q键。</p><p id="504c" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">脚本写在superres_win.py文件中。</p><p id="1be9" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我的1060 3GB笔记本电脑在320x240图片下提供20–22 FPS，我发现它对于大多数类型的游戏都是可以接受的。根据基准测试<a class="ae lr" href="http://ai-benchmark.com/ranking_deeplearning_detailed.html" rel="noopener ugc nofollow" target="_blank">http://ai-benchmark.com/ranking_deeplearning_detailed.html</a>GTX 1070和1080在类似的任务应该超过1060近2倍(也没有真正测试)！对于舒适的游戏来说，大约40的FPS应该足够了。下面是一段视频，展示了街机游戏的质量改进:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ls lt l"/></div></figure><p id="76f4" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">安装了GTX 1060 3 GB和Linux的固定PC只能提供17 FPS(我还没有发现为什么模型运行得更慢)。<br/>对于主线任务来说已经足够了:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ls lt l"/></div></figure><p id="e009" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">它甚至对一些平台游戏也很有效:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ls lt l"/></div></figure><p id="52f5" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">如何使用:</p><p id="be4c" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">你需要一个支持cuda和cud nn(<a class="ae lr" href="https://developer.nvidia.com/cuda-gpus" rel="noopener ugc nofollow" target="_blank">https://developer.nvidia.com/cuda-gpus</a>)以及已安装的cuda / cudnn库的显卡。需要安装python 3.7和TensorFlow(有GPU支持的2.0以上版本)。这可能是一项艰巨的任务，兼容性问题(【https://www.tensorflow.org/install/source_windows】T2)可能会发生。最简单的方法是安装Anaconda发行版(【https://www.anaconda.com/products/individual】T4)，然后打开Anaconda提示符命令行并编写</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="1542" class="nl lv it nh b gy nm nn l no np">conda install tensorflow-gpu</span></pre><p id="fd0c" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">如果因为冲突而没有成功，那么</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="a0a9" class="nl lv it nh b gy nm nn l no np">conda install cudnn</span><span id="bb25" class="nl lv it nh b gy nq nn l no np">pip install tensorflow-gpu</span></pre><p id="04e4" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">应该管用。</p><p id="c274" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">可以使用pip安装其他库:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="f536" class="nl lv it nh b gy nm nn l no np">pip install opencv-python<br/>pip install mss<br/>pip install d3dshot<br/>pip install pywin32</span></pre><p id="c364" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">D3dshot库安装可能需要额外的步骤<a class="ae lr" href="https://github.com/SerpentAI/D3DShot/wiki/Installation-Note:-Laptops" rel="noopener ugc nofollow" target="_blank">https://github . com/SerpentAI/d3d shot/wiki/Installation-注意:-Laptops </a></p><p id="7d7e" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">从https://github.com/Alexankharin/RTSR<a class="ae lr" href="https://github.com/Alexankharin/RTSR" rel="noopener ugc nofollow" target="_blank">下载并解包EDSR脚本和模型</a></p><p id="5669" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">使用命令运行superres_win.py</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="4a16" class="nl lv it nh b gy nm nn l no np">python superres_win.py</span></pre><p id="179a" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在7秒钟内，你应该激活游戏窗口。将会出现一个窗口，增强您显示器的游戏区域。调整窗口捕获区域WSAD键。捕捉区域的大小可以用IJKL键来改变。将捕获区域放置到游戏中后，按0启动超分辨率模式。1键或2键定义最初捕获的图像是否有大(2x2)像素。制作一个窗口，让你的游戏活跃起来，开始玩吧！</p><h1 id="64b5" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">例子</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/cb3612ab13a6ca3c3d9ef97ce9c32f41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*4-vZCnZusp55u9dTD1LM-g.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">增强前后的MegaMan X screeenshots(图片由作者提供)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/b40a637a320694bff4e81d0bff4fee61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*S9g3sus94A8-H1VgjCINZw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">真人快打3屏幕截图(图片由作者提供)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/a113557769e4d7604f92b764b35cb7da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1058/format:webp/1*ji_d47nKzHuOzUmNKQOsvQ.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">凯兰迪亚传说截图(<em class="ku">图片作者</em>)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/35f581ab8b913f34778e71d286a4f346.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*KroyB-gX6eq_ZBf_XZfqEQ.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">暗黑2截图(图片由作者提供)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi nv"><img src="../Images/526be60278c7caf4ebe333df0e8f4db5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4d8Ad_WjZ_75IVcS83E_Og.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">英雄无敌截图(<em class="ku">图片作者</em>)</p></figure></div></div>    
</body>
</html>