# ä½¿ç”¨é¢„å…ˆè®­ç»ƒçš„å•è¯åµŒå…¥æ¥æ£€æµ‹çœŸå®çš„ç¾éš¾æ¨æ–‡

> åŸæ–‡ï¼š<https://towardsdatascience.com/pre-trained-word-embedding-for-text-classification-end2end-approach-5fbf5cd8aead?source=collection_archive---------8----------------------->

## ç«¯-2-ç«¯æ–¹æ³•

![](img/17885747dcd8289eff7a083a38ab99d1.png)

[https://unsplash.com/](https://unsplash.com/)

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†ç»å†æ•´ä¸ªæ–‡æœ¬åˆ†ç±»æµç¨‹ï¼Œå°¤å…¶æ˜¯æ•°æ®é¢„å¤„ç†æ­¥éª¤ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ª[æ‰‹å¥—](https://nlp.stanford.edu/projects/glove/)é¢„å…ˆè®­ç»ƒçš„å•è¯åµŒå…¥ã€‚
æ–‡æœ¬ç‰¹å¾å¤„ç†æ¯”çº¿æ€§æˆ–åˆ†ç±»ç‰¹å¾ç¨å¾®å¤æ‚ä¸€ç‚¹ã€‚äº‹å®ä¸Šï¼Œæœºå™¨å­¦ä¹ ç®—æ³•æ›´å¤šçš„æ˜¯å…³äºæ ‡é‡å’Œå‘é‡ï¼Œè€Œä¸æ˜¯å­—ç¬¦æˆ–å•è¯ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¿…é¡»å°†æ–‡æœ¬è¾“å…¥è½¬æ¢æˆæ ‡é‡ï¼Œè€Œ **keystone** ğŸ—å…ƒç´ åœ¨äº**å¦‚ä½•æ‰¾å‡ºè¾“å…¥å•è¯**çš„æœ€ä½³è¡¨ç¤ºã€‚è¿™æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†èƒŒåçš„ä¸»è¦æ€æƒ³

æˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªåä¸º[çš„ Kaggle ç«èµ›çš„æ•°æ®é›†ï¼ŒçœŸå®ä¸å¦ï¼Ÿç¾éš¾æ¨æ–‡ NLP](https://www.kaggle.com/c/nlp-getting-started/data)ã€‚è¿™é¡¹ä»»åŠ¡åœ¨äºé¢„æµ‹ä¸€æ¡æ¨æ–‡æ˜¯å¦æ˜¯å…³äºä¸€åœºçœŸæ­£çš„ç¾éš¾ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªæ–‡æœ¬åˆ†ç±»ä»»åŠ¡ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å•è¯åµŒå…¥å˜æ¢ï¼Œç„¶åæ˜¯é€’å½’æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚å…¶ä»–ä¸å¤ªå¤æ‚ä½†ä»ç„¶æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆä¹Ÿæ˜¯å¯èƒ½çš„ï¼Œæ¯”å¦‚ç»“åˆ tf-idf ç¼–ç å’Œæœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨(æŸ¥çœ‹æˆ‘ä¸Šä¸€ç¯‡[å¸–å­](https://medium.com/prevision-io/automated-nlp-with-prevision-io-part1-naive-bayes-classifier-475fa8bd73de))ã€‚

æ­¤å¤–ï¼Œæˆ‘å°†åŒ…æ‹¬ä¸€äº›æ–¹ä¾¿çš„ Python ä»£ç ï¼Œå¯ä»¥åœ¨å…¶ä»– NLP ä»»åŠ¡ä¸­é‡ç°ã€‚æ•´ä¸ªæºä»£ç å¯ä»¥åœ¨è¿™ä¸ª [kaggle ç¬”è®°æœ¬](https://www.kaggle.com/schopenhacker75/eda-text-cleaning-glove?scriptVersionId=46794932)ä¸­è·å¾—ã€‚

# ç®€ä»‹:

LSTM æˆ– CNN ç­‰æ¨¡å‹åœ¨æ•æ‰è¯åºå’Œå®ƒä»¬ä¹‹é—´çš„è¯­ä¹‰å…³ç³»æ–¹é¢æ›´æœ‰æ•ˆï¼Œè¿™é€šå¸¸å¯¹æ–‡æœ¬çš„æ„ä¹‰è‡³å…³é‡è¦:æ¥è‡ªæˆ‘ä»¬æ•°æ®é›†çš„ä¸€ä¸ªæ ·æœ¬è¢«æ ‡è®°ä¸ºçœŸæ­£çš„ç¾éš¾:

> #RockyFire æ›´æ–°= >åŠ å·é«˜é€Ÿå…¬è·¯ã€‚20 ä¸ªåŒå‘å…³é—­ï¼Œç”±äºè±å…‹å¿ç«ç¾-# CAfire #é‡ç«'

å¾ˆæ˜æ˜¾ï¼Œå•è¯é¡ºåºåœ¨ä¸Šé¢çš„ä¾‹å­ä¸­å¾ˆé‡è¦ã€‚

å¦ä¸€æ–¹é¢ï¼Œæˆ‘ä»¬éœ€è¦å°†è¾“å…¥æ–‡æœ¬è½¬æ¢æˆæœºå™¨å¯è¯»çš„æ ¼å¼ã€‚å®ƒå­˜åœ¨è®¸å¤šæŠ€æœ¯ï¼Œå¦‚

*   **one-hot encoding** :æ¯ä¸ªåºåˆ—æ–‡æœ¬è¾“å…¥åœ¨ d ç»´ç©ºé—´ä¸­è¡¨ç¤ºï¼Œå…¶ä¸­ d æ˜¯æ•°æ®é›†è¯æ±‡çš„å¤§å°ã€‚å¦‚æœæ¯ä¸ªæœ¯è¯­å‡ºç°åœ¨æ–‡æ¡£ä¸­ï¼Œåˆ™è¯¥æœ¯è¯­å°†å¾—åˆ° 1ï¼Œå¦åˆ™å°†å¾—åˆ° 0ã€‚å¯¹äºå¤§å‹è¯­æ–™åº“ï¼Œè¯æ±‡è¡¨å°†å¤§çº¦æœ‰æ•°ä¸‡ä¸ªæ ‡è®°ï¼Œè¿™ä½¿å¾—ä¸€æ¬¡æ€§å‘é‡éå¸¸ç¨€ç–å’Œä½æ•ˆã€‚
*   **TF-IDF ç¼–ç **:å•è¯è¢«æ˜ å°„æˆä½¿ç”¨ TF-IDF åº¦é‡ç”Ÿæˆçš„æ•°å­—ã€‚è¯¥å¹³å°é›†æˆäº†å¿«é€Ÿç®—æ³•ï¼Œä½¿å¾—ä¿æŒ**æ‰€æœ‰**å•å…ƒå’ŒäºŒå…ƒ tf-idf ç¼–ç æˆä¸ºå¯èƒ½ï¼Œè€Œæ— éœ€åº”ç”¨é™ç»´
*   **å•è¯åµŒå…¥å˜æ¢**:å•è¯è¢«æŠ•å½±åˆ°ä¸€ä¸ªå¯†é›†çš„å‘é‡ç©ºé—´ï¼Œåœ¨è¿™ä¸ªç©ºé—´ä¸­ï¼Œå•è¯ä¹‹é—´çš„è¯­ä¹‰è·ç¦»è¢«ä¿ç•™:(è§ä¸‹å›¾):

![](img/2b1cb181ae849eeb448757f7ccfab22c.png)

[https://developers . Google . com/machine-learning/crash-course/images/linear-relationships . SVG](https://developers.google.com/machine-learning/crash-course/images/linear-relationships.svg)

**ä»€ä¹ˆæ˜¯é¢„è®­ç»ƒå•è¯åµŒå…¥ï¼Ÿ**

åµŒå…¥æ˜¯è¡¨ç¤ºä¸€ä¸ªå•è¯(æˆ–ä¸€ä¸ªç¬¦å·)çš„å¯†é›†å‘é‡ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒåµŒå…¥å‘é‡æ˜¯**éšæœº**åˆå§‹åŒ–çš„ï¼Œç„¶åå°†åœ¨è®­ç»ƒé˜¶æ®µé€æ¸æ”¹è¿›ï¼Œåœ¨æ¯ä¸ªåå‘ä¼ æ’­æ­¥éª¤ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼Œä»¥ä¾¿ç›¸ä¼¼çš„å•è¯æˆ–ç›¸åŒè¯æ±‡åŸŸä¸­çš„å•è¯æˆ–å…·æœ‰å…±åŒè¯å¹²çš„å•è¯â€¦å°†åœ¨æ–°å‘é‡ç©ºé—´ä¸­çš„è·ç¦»æ–¹é¢ä»¥**æ¥è¿‘**ç»“æŸï¼›(è§ä¸‹å›¾):

![](img/ad2cd106b2723a4ae5972338196ea829.png)

ä½œè€…:Zeineb Ghrib

é¢„è®­ç»ƒå•è¯åµŒå…¥æ˜¯**è¿ç§»å­¦ä¹ çš„ä¸€ä¸ªä¾‹å­ã€‚**å…¶èƒŒåçš„ä¸»è¦æ€æƒ³æ˜¯ä½¿ç”¨å·²ç»åœ¨å¤§å‹æ•°æ®é›†ä¸Šè®­ç»ƒè¿‡çš„å…¬å…±åµŒå…¥ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†**å°†è¿™äº›é¢„è®­ç»ƒçš„åµŒå…¥è®¾ç½®ä¸ºåˆå§‹åŒ–æƒé‡**ï¼Œè€Œä¸æ˜¯éšæœºåˆå§‹åŒ–æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œæƒé‡ã€‚è¿™ä¸ªæŠ€å·§æœ‰åŠ©äºåŠ é€Ÿè®­ç»ƒå’Œæé«˜ NLP æ¨¡å‹çš„æ€§èƒ½ã€‚

# æ­¥éª¤ 0:å¯¼å…¥å’Œè®¾ç½®:

é¦–å…ˆï¼Œè®©æˆ‘ä»¬å¯¼å…¥æ‰€éœ€çš„åº“å’Œå·¥å…·ï¼Œå®ƒä»¬å°†å¸®åŠ©æˆ‘ä»¬æ‰§è¡Œ NLP å¤„ç†å’Œ

```
import pandas as pd
import numpy as np
from nltk.corpus import stopwords
from nltk.util import ngrams
from sklearn.feature_extraction.text import CountVectorizer
from collections import defaultdict
from collections import  Counter
stop=set(stopwords.words('english'))
import re
from nltk.tokenize import word_tokenize
import gensim
import string
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from tqdm import tqdm
from keras.models import Sequential
from keras.layers import Embedding,LSTM,Dense,SpatialDropout1D
from keras.initializers import Constant
from sklearn.model_selection import train_test_split
from keras.optimizers import Adam
```

# ç¬¬ä¸€æ­¥:æ–‡æœ¬æ¸…ç†:ğŸ§¹

ä¸è€ƒè™‘ EDA æ­¥éª¤å¯ä»¥å¸¦å‡ºæœªæ¸…ç†çš„å…ƒç´ å¹¶å¸®åŠ©æˆ‘ä»¬è‡ªå®šä¹‰æ¸…ç†ä»£ç ï¼Œæˆ‘ä»¬å¯ä»¥åº”ç”¨ä¸€äº›åœ¨ tweeters ä¸­åå¤å‡ºç°çš„åŸºæœ¬æ•°æ®æ¸…ç†ï¼Œå¦‚åˆ é™¤æ ‡ç‚¹ç¬¦å·ï¼Œhtml æ ‡ç­¾ URL å’Œè¡¨æƒ…ç¬¦å·ï¼Œæ‹¼å†™çº æ­£ï¼Œ..

ä¸‹é¢æ˜¯ä¸€æ®µ python ä»£ç ï¼Œå¯ä»¥åœ¨å…¶ä»–ç±»ä¼¼çš„ç”¨ä¾‹ä¸­é‡ç°ğŸ˜‰

ç„¶åï¼Œæˆ‘ä»¬å°†æ•°æ®é›†æ‹†åˆ†ä¸º:

*   ä¸€ä¸ª**è®­ç»ƒæ•°æ®é›†**(è®­ç»ƒæ•°æ®é›†çš„ 80%)
*   ä¸€ä¸ª**éªŒè¯æ•°æ®é›†**:å‰©ä½™ 20%çš„è®­ç»ƒæ•°æ®é›†å°†ç”¨äºéªŒè¯æ¯ä¸ªæ—¶æœŸçš„æ¨¡å‹æ€§èƒ½
*   **æµ‹è¯•æ•°æ®é›†**(æ­¤å¤„å¯é€‰) :ç”± kaggle æä¾›ï¼Œç”¨äºè¿›è¡Œé¢„æµ‹

```
train = df[~df['target'].isna()]
X_train, X_val, y_train, y_val = train_test_split(train, train['target'], test_size=0.2, random_state=42)
```

# ç¬¬äºŒæ­¥:æ–‡æœ¬é¢„å¤„ç†ğŸ¤–

å¦‚å‰æ‰€è¿°ï¼Œæœºå™¨å­¦ä¹ ç®—æ³•å°†æ•°å­—ä½œä¸ºè¾“å…¥ï¼Œè€Œä¸æ˜¯æ–‡æœ¬ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬éœ€è¦å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å­—å‘é‡ã€‚
æˆ‘ä»¬è¿›è¡Œå¦‚ä¸‹æ“ä½œ:

## 1.æ ‡è®°åŒ–

å®ƒåŒ…æ‹¬å°†æ–‡æœ¬åˆ’åˆ†ä¸ºå•è¯æˆ–æ›´å°çš„å­æ–‡æœ¬ï¼Œå…è®¸æˆ‘ä»¬ç¡®å®šæ•°æ®é›†çš„â€œè¯æ±‡â€(æ•°æ®ä¸­å­˜åœ¨çš„ä¸€ç»„å”¯ä¸€æ ‡è®°)ã€‚é€šå¸¸æˆ‘ä»¬ä½¿ç”¨å•è¯çº§è¡¨ç¤ºã€‚å¯¹äºæˆ‘ä»¬çš„ä¾‹å­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ NLTK `Tokenizer()`

## 2.å•è¯ç´¢å¼•:

åŸºäºè¯é¢‘æ„å»ºä¸€ä¸ªè¯æ±‡ç´¢å¼•æ˜ å°„å™¨:ç´¢å¼•å°†ä¸æ•´ä¸ªæ•°æ®é›†ä¸­çš„è¯é¢‘æˆåæ¯”ã€‚æœ€é¢‘ç¹çš„ä¸–ç•Œçš„ç´¢å¼•=1..æ¯ä¸ªå•è¯éƒ½ä¼šæœ‰ä¸€ä¸ªå”¯ä¸€çš„ç´¢å¼•ã€‚

è¿™ä¸¤ä¸ªæ­¥éª¤åˆ†è§£å¦‚ä¸‹:

å…³äº NLTK æ ‡è®°å™¨çš„ä¸€äº›è§£é‡Š:

1.  `fit_on_texts()`æ–¹æ³•ğŸ¤–:å®ƒæ ¹æ®è¯é¢‘åˆ›å»ºè¯æ±‡ç´¢å¼•ã€‚
    ä¾‹:"*å¤–å£³ä¸­çš„å¹½çµ*"ä¼šç”Ÿæˆ word _ index[" the "]= 1ï¼›word_index["ghost"] = 2..
    - >æ‰€ä»¥æ¯ä¸ªå•è¯éƒ½å¾—åˆ°ä¸€ä¸ªå”¯ä¸€çš„æ•´æ•°å€¼ã€‚ä» 1 å¼€å§‹(0 ä¿ç•™ç”¨äºå¡«å……)ï¼Œå•è¯è¶Šé¢‘ç¹ï¼Œå¯¹åº”çš„ç´¢å¼•è¶Šä½ã€‚
    (PS å¾€å¾€å‰å‡ ä¸ªæ˜¯åœç”¨è¯ï¼Œå› ä¸ºå‡ºç°å¾ˆå¤šä½†æ˜¯å»ºè®®åœ¨æ•°æ®æ¸…ç†çš„æ—¶å€™å»æ‰)ã€‚
2.  `textes_to_sequences()`æ³•ğŸ“Ÿ:å°†æ¯ä¸ªæ–‡æœ¬è½¬æ¢ä¸ºæ•´æ•°åºåˆ—:æ¯ä¸ªå•è¯éƒ½æ˜ å°„åˆ° word_index å­—å…¸ä¸­çš„ç´¢å¼•ã€‚
3.  `pad_sequences()`æ–¹æ³•ğŸ:ä¸ºäº†ä½¿è¾“å‡ºçš„å½¢çŠ¶æ ‡å‡†åŒ–ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªå”¯ä¸€çš„å‘é‡é•¿åº¦(åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­`MAX_SEQUENCE_LENGTH`å°†å…¶å›ºå®šä¸º 50):ä»»ä½•æ›´é•¿çš„åºåˆ—éƒ½å°†è¢«æˆªæ–­ï¼Œä»»ä½•æ›´çŸ­çš„åºåˆ—éƒ½å°†ç”¨ 0 å¡«å……ã€‚

# æ­¥éª¤ 3:æ„å»ºåµŒå…¥çŸ©é˜µğŸ§±

é¦–å…ˆï¼Œæˆ‘ä»¬å°†ä»å®˜æ–¹ç½‘ç«™ä¸‹è½½[æ‰‹å¥—é¢„è®­ç»ƒåµŒå…¥](https://nlp.stanford.edu/projects/glove/)(ç”±äºä¸€äº›æŠ€æœ¯é™åˆ¶ï¼Œæˆ‘å¿…é¡»é€šè¿‡ä»£ç ä¸‹è½½:

ç„¶åï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªåµŒå…¥çŸ©é˜µï¼Œå°†æ¯ä¸ªå•è¯ç´¢å¼•æ˜ å°„åˆ°å…¶å¯¹åº”çš„åµŒå…¥å‘é‡:

![](img/0a48cee64090ca15ee16daeac7bf414b.png)

[https://developers . Google . com/machine-learning/guides/text-classification/images/embedding layer . png](https://developers.google.com/machine-learning/guides/text-classification/images/EmbeddingLayer.png)

# æ­¥éª¤ 4:åˆ›å»ºå’Œè®­ç»ƒæ¨¡å‹:

![](img/eae8988126bfa8fb2b44bbf1885fc073.png)

[whatsapp æœºå™¨äºº](https://emojipedia.org/whatsapp/2.20.198.15/robot/)

æˆ‘ä»¬å°†ä½¿ç”¨é¡ºåº keras æ¨¡å‹åˆ›å»ºä¸€ä¸ªé€’å½’ç¥ç»ç½‘ç»œï¼Œè¯¥æ¨¡å‹å°†åŒ…å«:

1.  ä»¥åµŒå…¥çŸ©é˜µä¸ºåˆå§‹æƒé‡çš„**åµŒå…¥å±‚**
2.  ä¸€ä¸ª**è„±è½å±‚**ä»¥é¿å…è¿‡åº¦æ‹Ÿåˆ(æŸ¥çœ‹è¿™ç¯‡å…³äºç¥ç»ç½‘ç»œä¸­è„±è½å±‚åŠå…¶æ•ˆç”¨çš„ä¼˜ç§€[å¸–å­](https://machinelearningmastery.com/use-dropout-lstm-networks-time-series-forecasting/#:~:text=Dropout%20is%20a%20regularization%20method,overfitting%20and%20improving%20model%20performance.)
3.  ä¸€ä¸ª **LSTM å±‚**:åŒ…æ‹¬é•¿çŸ­æœŸå­˜å‚¨å•å…ƒ
4.  ä½¿ç”¨*äºŒå…ƒäº¤å‰ç†µ*æŸå¤±å‡½æ•°çš„**æ¿€æ´»å±‚**

å¦‚æœæˆ‘ä»¬æƒ³è¦è®¡ç®—æˆ‘ä»¬çš„äºŒå…ƒ keras åˆ†ç±»å™¨æ¨¡å‹çš„å‡†ç¡®åº¦ã€ç²¾ç¡®åº¦ã€å¬å›ç‡å’Œ F1 åˆ†æ•°ï¼Œæˆ‘ä»¬å¿…é¡»æ‰‹åŠ¨è®¡ç®—å®ƒä»¬ï¼Œå› ä¸ºè‡ª [2.0 ç‰ˆæœ¬](https://github.com/keras-team/keras/wiki/Keras-2.0-release-notes)ä»¥æ¥ï¼ŒKeras ä¸æ”¯æŒè¿™äº›æŒ‡æ ‡ã€‚

(è§£å†³æ–¹æ¡ˆæ¥è‡ª[æ­¤å¤„](https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model))

ç°åœ¨ç¼–è¯‘å’Œè®­ç»ƒæ¨¡å‹:

è¦è·å¾—éªŒè¯æ€§èƒ½ç»“æœï¼Œä½¿ç”¨`evaluate()`æ–¹æ³•:

```
loss, accuracy, f1_score, precision, recall = model.evaluate(tokenized_val, y_val, verbose=0)
```

è®©æˆ‘ä»¬æ£€æŸ¥ç»“æœ:

![](img/f0e8187080ead2c6b3669b832c40090d.png)

ç”± Zeineb Ghrib ä»[è¿™é‡Œ](https://www.kaggle.com/schopenhacker75/eda-text-cleaning-glove?scriptVersionId=46794932)

è¿™äº›ç»“æœä¼¼ä¹ç›¸å½“ä¸é”™ï¼Œä½†å½“ç„¶å¯ä»¥é€šè¿‡å¾®è°ƒç¥ç»ç½‘ç»œè¶…å‚æ•°æˆ–ä½¿ç”¨ auto-ml å·¥å…·(å¦‚ [prevision](https://cloud.prevision.io/) )æ¥å¢å¼ºï¼Œé™¤äº† wor2vec ä¹‹å¤–ï¼Œè¿™äº›å·¥å…·è¿˜åº”ç”¨äº†è®¸å¤šå…¶ä»–è½¬æ¢ï¼Œå¦‚ ngram ä»¤ç‰ŒåŒ–ã€tf-idf æˆ–æ›´å…ˆè¿›çš„æŠ€æœ¯(å¦‚ [BERT](https://huggingface.co/transformers/model_doc/bert.html) transformers)ã€‚

# ç»“è®º:

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä¸€æ­¥ä¸€æ­¥åœ°å‘æ‚¨å±•ç¤ºäº†å¦‚ä½•ä» Glove é¢„è®­ç»ƒçš„å•è¯åµŒå…¥åº”ç”¨ wor2vec å˜æ¢ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨å®ƒæ¥è®­ç»ƒä¸€ä¸ªé€’å½’ç¥ç»ç½‘ç»œã€‚è¯·æ³¨æ„ï¼Œè¯¥æ–¹æ³•å’Œä»£ç å¯ä»¥åœ¨å…¶ä»–ç±»ä¼¼çš„ç”¨ä¾‹ä¸­é‡ç”¨ã€‚æ•´ä½“æºä»£ç å¯ä»¥åœ¨è¿™ä¸ª [kaggle ç¬”è®°æœ¬](https://www.kaggle.com/schopenhacker75/eda-text-cleaning-glove?scriptVersionId=46794932)ä¸­æ‰¾åˆ°ã€‚
æˆ‘è¿˜åœ¨åŒä¸€ä¸ªæ•°æ®é›†ä¸Šåº”ç”¨äº†å®Œå…¨ä¸åŒçš„æ–¹æ³•:æˆ‘ä½¿ç”¨äº† tf-idf æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼Œå¦‚æœä½ æƒ³è·å¾—æ›´å¤šä¿¡æ¯ï¼Œè¯·è®¿é—®[æˆ‘çš„ä¸Šä¸€ç¯‡æ–‡ç« ](https://medium.com/prevision-io/automated-nlp-with-prevision-io-part1-naive-bayes-classifier-475fa8bd73de)ã€‚

æˆ‘æ‰“ç®—å†™ä¸€ç¯‡å…³äºå¦‚ä½•ä½¿ç”¨åä¸º Bert çš„çªç ´æ€§ç®—æ³•çš„æ–‡ç« ï¼Œå¹¶å°†å…¶ä¸å…¶ä»– NLP ç®—æ³•è¿›è¡Œæ¯”è¾ƒ

æ„Ÿè°¢æ‚¨é˜…è¯»æˆ‘çš„å¸–å­ğŸ¤—ï¼ï¼å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜ï¼Œå¯ä»¥åœ¨ [prevision cloud instance](https://cloud.prevision.io/) çš„èŠå¤©ä¼šè¯ä¸­æ‰¾åˆ°æˆ‘ï¼Œæˆ–è€…å‘é€ç”µå­é‚®ä»¶è‡³:zeineb.ghrib@prevision.io