<html>
<head>
<title>K-means from scratch with NumPy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">k-意味着用 NumPy 从头开始</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/k-means-from-scratch-with-numpy-74f79d2b1694?source=collection_archive---------18-----------------------#2020-06-29">https://towardsdatascience.com/k-means-from-scratch-with-numpy-74f79d2b1694?source=collection_archive---------18-----------------------#2020-06-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4807" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用这种快速简单的聚类算法回归基础</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/379b796a7859ff207b2f414996d9e833.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nI6jAcJHDjb436WV1KNpPA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://unsplash.com/photos/0vV4SEdf4gI" rel="noopener ugc nofollow" target="_blank"> unsplash </a></p></figure><p id="83ae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">K-means 是最简单的聚类算法。它很容易理解和实现，当试图理解无监督学习的世界时，这是一个很好的起点。</p><p id="0e33" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">无监督学习指的是机器学习的整个子领域，其中数据没有标签。我们不是训练一个模型来预测标签，而是希望揭示数据中的某种潜在结构，否则这些结构可能不明显。</p><h2 id="3d4c" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">它是如何工作的？</h2><p id="68e4" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">K-means 从假设数据可以分成 K 个不同的簇开始。每个聚类的特征在于与该聚类相关的点的平均值(因此得名… K-means)。</p><p id="1a4d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">识别 K 个不同装置位置的程序如下:</p><ol class=""><li id="b4e3" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><strong class="lb iu">随机分配</strong>数据中的每个点到一个簇中</li><li id="4af8" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu">计算分配给特定聚类的每个点的平均值</strong></li><li id="5d25" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">对于每个点，<strong class="lb iu">根据最接近该点的平均值更新分配的平均值</strong>。</li><li id="fda5" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">重复步骤 2 和 3，直到平均值收敛到恒定值。</li></ol><h2 id="1cca" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">来实施吧！</h2><p id="0179" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">为了便于跟踪不同的点以及它们之间的关联，让我们构建一个小类(注意，同样的事情可以通过命名元组或字典轻松实现)。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="218d" class="lv lw it ni b gy nm nn l no np">import numpy as np</span><span id="5d01" class="lv lw it ni b gy nq nn l no np">K = 3</span><span id="046b" class="lv lw it ni b gy nq nn l no np">class point():<br/>    def __init__(self, data):<br/>        self.data = data<br/>        self.k = np.random.randint(0,K)<br/>    <br/>    def __repr__(self):<br/>        return str({"data":self.data, "k":self.k})</span></pre><p id="150a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">也不需要<code class="fe nr ns nt ni b">__repr__</code>函数，但它有助于查看引擎内部发生了什么。</p><p id="884e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们需要一些模拟数据来玩:</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="c446" class="lv lw it ni b gy nm nn l no np">N = 200<br/>data1 = np.random.randn(N//3,2) + np.array([5,6])<br/>data2 = np.random.randn(N//3,2) + np.array([-5,-6])<br/>data3 = np.random.randn(N//3,2) + np.array([-10,3])<br/>data = np.concatenate((data1, data2, data3))</span></pre><p id="c58e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">绘制如下图:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/1c56e23a331fd21215326501d256f5c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*3JnvMJd_XVyNfKENeMH3ZA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">用 3 个集群模拟数据</p></figure><h2 id="4678" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">第一步:随机分配</h2><p id="4c83" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">当我们为每个数据点实例化类时，我们的类通过随机选择一个指定的平均值来处理这个问题。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="03bc" class="lv lw it ni b gy nm nn l no np">points = [point(d) for d in data]</span></pre><h2 id="f581" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">第二步:计算平均值</h2><p id="d9ce" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">为了完成这一步，我们需要构建两个函数。一个创建分配给每个分类的点的列表，另一个计算每个分类的平均值。我们可以使用如下的<code class="fe nr ns nt ni b">collections.defaultdict</code>实现第一个:</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="bbd0" class="lv lw it ni b gy nm nn l no np">from collections inport defaultdict</span><span id="058a" class="lv lw it ni b gy nq nn l no np">def make_k_mapping(points):<br/>    point_dict = defaultdict(list)<br/>    for p in points:<br/>        point_dict[p.k] = point_dict[p.k] + [p.data]<br/>    return point_dict</span></pre><p id="924e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后是第二个功能:</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="042a" class="lv lw it ni b gy nm nn l no np">def calc_k_means(point_dict):<br/>    means = [np.mean(point_dict[k],axis=0) for k in range(K)]<br/>    return means</span></pre><h2 id="56d6" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">步骤 3:更新点群分配</h2><p id="d2d3" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">现在我们需要计算距离，并根据最接近的聚类平均值更新关联的聚类。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="310c" class="lv lw it ni b gy nm nn l no np">def update_k(points,means):<br/>    for p in points:   <br/>        dists = [np.linalg.norm(means[k]-p.data) for k in range(K)]<br/>        p.k = np.argmin(dists)</span></pre><h2 id="da4b" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">训练循环</h2><p id="bf69" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">现在，我们只需要将这些函数组合在一个循环中，为我们的新聚类算法创建一个训练函数。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="b08a" class="lv lw it ni b gy nm nn l no np">def fit(points, epochs=10):<br/>    for e in range(epochs):<br/>        point_dict = make_k_mapping(points)<br/>        means = calc_k_means(point_dict)<br/>        update_k(points, means)<br/>    return means, points</span><span id="5745" class="lv lw it ni b gy nq nn l no np">new_means, new_points = fit(points)</span></pre><p id="3b24" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们把新的方法和原始点一起画出来，我们会得到这样的结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/7e0d5fd573cfdf292bc785b4e0deb40f.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*ZvIgGD94QLYIkXIgdztAIg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">聚类和原始数据</p></figure><h2 id="cd7e" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">参数调谐</h2><p id="e0e8" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">对于你们当中目光敏锐的人来说，你们会意识到我们从一开始就选择了正确的集群数量。如果我们选择 K 大于或小于 3，我们会有一个较差的数据拟合。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/a90561efc1e6b85dc8107208583d25dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*6YmXV3_Yr6M1OKLjolsz-g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">K = 2</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/dad13028b8ae24947f8eb65602d46c53.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*9hMJ3751GkoaU7E4sv_XoQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">K = 4</p></figure><p id="d3b0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就引出了一个问题，我们如何更好地量化模型的拟合度？一个自然的选择是计算一个点与其聚类平均值的平均距离。考虑到点被分配给具有欧几里德距离的簇，使用这个作为性能的度量看起来是一个合理的选择。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="6aa0" class="lv lw it ni b gy nm nn l no np">def evaluate(points):<br/>    point_dict = make_k_mapping(points)<br/>    means = calc_k_means(point_dict)<br/>    dists = [np.linalg.norm(means[p.k]-p.data) for p in points]<br/>    return np.mean(dists)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/4237def55a155c28369d14d5e9f56098.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*A_LJ2D9xGjXYmr5x2gD8GQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作为 K 的函数的平均距离</p></figure><p id="0651" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">表面上看起来是可行的，但仍然有一个问题，K = 4 的平均距离小于 K = 3。仔细想想，这很有意义，每个数据点都有一个聚类，平均距离为 0。然而，这显然是一个过度拟合数据的模型。</p><p id="8e6b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对此的一个解决方案被称为 Akaike 信息标准(AIC)。该度量以模型参数的数量来惩罚模型的可能性。</p><p id="b5bd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于 K-means，AIC 是点与其分配的均值之间的平方距离之和，由训练参数的数量决定。这来自于假设每个聚类是具有单位协方差的高斯分布。K 均值模型的训练参数的数量是<code class="fe nr ns nt ni b">K * d</code>，其中<code class="fe nr ns nt ni b">d</code>是维度的数量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/2ed3e5a02aec2872b5a07722705de163.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*VbHjbY8qI8zRKsux4ibRTQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">K 均值的 AIC</p></figure><p id="29f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个图有一个明确的最小值 3，这正是我们想要的！</p><h2 id="b9a7" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">我们学到了什么？</h2><p id="c24e" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">所以在这里，我们已经了解了 K-means 如何工作，如何用 NumPy 构建模型，以及如何训练它。我们还研究了一些评估模型性能的潜在方法，以及如何使用模型参数的数量来惩罚评估指标。</p><p id="241a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">K-means 是一种轻量级但功能强大的算法，可用于解决许多不同的聚类问题。现在您知道它是如何工作的，以及如何自己构建它了！</p></div></div>    
</body>
</html>