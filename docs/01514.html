<html>
<head>
<title>FreeLB: A Generic Adversarial Training method for Text</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">FreeLB:一种通用的文本对抗训练方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/freelb-a-generic-adversarial-training-method-for-text-92ac25828495?source=collection_archive---------34-----------------------#2020-02-10">https://towardsdatascience.com/freelb-a-generic-adversarial-training-method-for-text-92ac25828495?source=collection_archive---------34-----------------------#2020-02-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4428" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">一种改进文本和自然语言处理对抗训练的新的通用技术。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/faa954609076c6e8c38473669ba2e255.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3DAYpyv5j5rjfqee4ILHdA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由来自Pixabay的Gerd Altmann提供</p></figure><p id="ab76" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">2013年，Szegedy等人发表了“<strong class="kx ir">神经网络的有趣性质</strong>”。这篇论文的一大要点是，模型可能会被<em class="lr">的反面例子</em>所愚弄。这些例子包含了某种人类肉眼无法察觉的扰动，但却可以完全欺骗模型。本文还发现，对立的例子可以在不同数据上训练的模型中推广，也就是说，所有这些模型都被一个具有同样难以察觉的扰动的例子所愚弄。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ls"><img src="../Images/efe187cf831b577532280bf2d01a8010.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*m2ngYZx3Bc5OWdeDyM8X0A.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">计算机视觉领域中的一个对立的例子(来自Goodfellow的《解释和利用对立的例子》,参见下面的参考资料)</p></figure><p id="e11f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">Goodfellow等人在2014年发表了“<strong class="kx ir">解释和利用对抗性例子</strong>”作为这项工作的后续，以进一步分析为什么对抗性例子如此普遍以及如何生成它们。这产生了对抗性训练的概念，其中除了训练数据集之外，还使用生成的对抗性样本来训练模型，以使模型更加健壮和可推广。这里有一个警告:健壮性和可推广性在某些领域(计算机视觉)是不一致的，而在其他领域(NLP)则是互补的。因此，对抗性训练有助于模型变得更加健壮，并可能更具普遍性。</p><p id="b425" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">自从Goodfellow的论文以来，对抗性训练技术继续变得更加优雅和有效，从而使模型对恶意示例更加健壮。这项来自微软Dynamics 365 AI Research的新工作提出了一种新的针对NLP域的对抗训练算法FreeLB (Free Large Batch ),该算法通过向单词嵌入添加对抗扰动并最小化输入样本周围不同区域内的结果对抗风险，来促进嵌入空间中更高的鲁棒性和不变性。这不同于先前的工作，先前的工作通过添加随机的单词/句子，通过拼错单词，或者通过将文本输入解释成完全不同的句子结构，向文本输入<em class="lr">即</em>添加对抗性扰动。通过在嵌入级别添加扰动，这种方法可以引入一些示例，如果我们只是简单地修改输入文本，这些示例是不可能生成的。</p><p id="10f4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">FreeLB利用“免费”培训策略(Shafahi等人，2019；张等(2019)用多样化的对立样本来扩大每个训练批次的大小，而不需要比当前最先进的算法投影梯度下降(PGD)额外的成本。具体来说，PGD试图找到一组参数来最小化标准球内任何<em class="lr"> r </em>的最大风险，如下所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/5f78542307c90262a2bec796a25b5a40.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*GAPvw3Snso3kynumPB1nCA.png"/></div></figure><p id="8308" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">其中<em class="lr"> D </em>为数据分布，<em class="lr"> y </em>为标签，<em class="lr"> L </em>为某损失函数。与PGD在最后一步只使用<em class="lr"> X+r </em>输出的梯度相比，FreeLB每次迭代都取<em class="lr"> r </em>输出的梯度的平均值，相当于把输入看成是<em class="lr"> K </em>倍大的虚拟批次，【<em class="lr"> X+r1，X+r2，…，X+rk】</em>。具体公式是:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/b54c48c43f6b2f3950f4f76a4247ebfe.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/format:webp/1*lu_ab3gR1-zLEjQ-t1-HRw.png"/></div></figure><p id="8ded" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">该团队在几个下游任务中使用这种FreeLB技术微调了BERT和RoBERTa语言模型。在GLUE基准测试中，BERT测试分数从78.3增加到79.4，而RoBERTA-large模型的分数增加了0.3，达到88.8。经过微调的RoBERTa-large还能够在ARC-Easy (85.44%)和ARC-Challenge (67.75%)基准测试中实现一流的性能。最后，在CommonsenseQA基准测试上的实验表明，FreeLB可以被推广，并提高RoBERTa-large模型在其他任务上的性能。</p><p id="a4c8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果你想了解更多关于FreeLB如何工作的细节，这里有一个链接<a class="ae lv" href="https://arxiv.org/pdf/1909.11764.pdf" rel="noopener ugc nofollow" target="_blank">链接</a>到FreeLB的文章，点击<a class="ae lv" href="http://aka.ms/mmai" rel="noopener ugc nofollow" target="_blank">这里</a>查看更多的出版物和团队的其他工作。</p><p id="ffd0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">参考文献</strong></p><ol class=""><li id="c6b1" class="lw lx iq kx b ky kz lb lc le ly li lz lm ma lq mb mc md me bi translated"><a class="ae lv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Szegedy%2C+C" rel="noopener ugc nofollow" target="_blank">克里斯蒂安·塞格迪</a>，<a class="ae lv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zaremba%2C+W" rel="noopener ugc nofollow" target="_blank">沃伊切赫·扎伦巴</a>，<a class="ae lv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sutskever%2C+I" rel="noopener ugc nofollow" target="_blank">伊利亚·苏茨科夫</a>，<a class="ae lv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bruna%2C+J" rel="noopener ugc nofollow" target="_blank">琼·布鲁纳</a>，<a class="ae lv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Erhan%2C+D" rel="noopener ugc nofollow" target="_blank">杜米特鲁尔汉</a>，<a class="ae lv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goodfellow%2C+I" rel="noopener ugc nofollow" target="_blank">伊恩·古德菲勒</a>，<a class="ae lv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fergus%2C+R" rel="noopener ugc nofollow" target="_blank">罗布·弗格斯</a>，<strong class="kx ir">神经网络的耐人寻味的性质</strong> (2013)，arXiv预印本，arXiv:1312.61999</li><li id="2125" class="lw lx iq kx b ky mf lb mg le mh li mi lm mj lq mb mc md me bi translated"><a class="ae lv" href="https://arxiv.org/search/stat?searchtype=author&amp;query=Goodfellow%2C+I+J" rel="noopener ugc nofollow" target="_blank">伊恩·j·古德菲勒</a>、<a class="ae lv" href="https://arxiv.org/search/stat?searchtype=author&amp;query=Shlens%2C+J" rel="noopener ugc nofollow" target="_blank">黄邦贤·史伦斯</a>、<a class="ae lv" href="https://arxiv.org/search/stat?searchtype=author&amp;query=Szegedy%2C+C" rel="noopener ugc nofollow" target="_blank">克里斯蒂安·塞格迪</a>、<strong class="kx ir">解释和利用反面例子</strong> (2014)，国际学习表征会议，ICLR，2015</li><li id="3c27" class="lw lx iq kx b ky mf lb mg le mh li mi lm mj lq mb mc md me bi translated"><a class="ae lv" href="https://arxiv.org/search/stat?searchtype=author&amp;query=Madry%2C+A" rel="noopener ugc nofollow" target="_blank">亚历山大·马德里</a>，<a class="ae lv" href="https://arxiv.org/search/stat?searchtype=author&amp;query=Makelov%2C+A" rel="noopener ugc nofollow" target="_blank">亚历山大·马克洛夫</a>，<a class="ae lv" href="https://arxiv.org/search/stat?searchtype=author&amp;query=Schmidt%2C+L" rel="noopener ugc nofollow" target="_blank">路德维希·施密特</a>，<a class="ae lv" href="https://arxiv.org/search/stat?searchtype=author&amp;query=Tsipras%2C+D" rel="noopener ugc nofollow" target="_blank">迪米特里斯·齐普拉斯</a>，<a class="ae lv" href="https://arxiv.org/search/stat?searchtype=author&amp;query=Vladu%2C+A" rel="noopener ugc nofollow" target="_blank">阿德里安·弗拉多</a>，<strong class="kx ir">走向抗对抗性攻击的深度学习模型</strong> (2017)，arXiv预印本arXiv:1706.06083</li><li id="7ab4" class="lw lx iq kx b ky mf lb mg le mh li mi lm mj lq mb mc md me bi translated">A.Shafahi，M. Najibi，A. Ghiasi，Z. Xu，J. Dickerson，C. Studer，L. Davis，G. Taylor，T. Goldstein，<strong class="kx ir">对抗性训练免费！</strong>，神经信息处理系统，NeurIPS 2019</li><li id="6752" class="lw lx iq kx b ky mf lb mg le mh li mi lm mj lq mb mc md me bi translated">张定淮，张天元，陆，朱占兴，董斌，<strong class="kx ir">你只传播一次:最大原理无痛对抗训练</strong>，神经信息处理系统，NeurIPS 2019</li><li id="b54d" class="lw lx iq kx b ky mf lb mg le mh li mi lm mj lq mb mc md me bi translated">、<a class="ae lv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Cheng%2C+Y" rel="noopener ugc nofollow" target="_blank">于成</a>、<a class="ae lv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gan%2C+Z" rel="noopener ugc nofollow" target="_blank">哲干</a>、<a class="ae lv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+S" rel="noopener ugc nofollow" target="_blank">孙思齐</a>、<a class="ae lv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goldstein%2C+T" rel="noopener ugc nofollow" target="_blank">汤姆·戈尔茨坦</a>、<a class="ae lv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+J" rel="noopener ugc nofollow" target="_blank">刘晶晶</a>、<strong class="kx ir"> FreeLB:语言理解的强化对抗训练(2019) </strong>，学习表征国际会议，ICLR 2020</li></ol></div></div>    
</body>
</html>