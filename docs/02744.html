<html>
<head>
<title>Controlling False Discoveries while Data Mining</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据挖掘时控制错误发现</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/blind-data-mining-is-bad-a609982a767f?source=collection_archive---------44-----------------------#2020-03-16">https://towardsdatascience.com/blind-data-mining-is-bad-a609982a767f?source=collection_archive---------44-----------------------#2020-03-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/ed56e0b7948db6777e022ba591a51a74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QgrsD7lqhQVHRcgzAUpcbw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">至少 1 个假阳性的概率与有和无校正的假设检验的数量</p></figure><div class=""/><div class=""><h2 id="dbe6" class="pw-subtitle-paragraph kf jh ji bd b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw dk translated">多重比较问题背后的数学原理以及如何应对</h2></div><p id="70ee" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">2005 年，约翰·约安尼迪斯博士发表了一篇令人震惊的论文，题为<a class="ae lt" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1182327/" rel="noopener ugc nofollow" target="_blank">为什么大多数发表的研究结果是假的</a>，引发了对<a class="ae lt" href="https://en.wikipedia.org/wiki/Replication_crisis" rel="noopener ugc nofollow" target="_blank">复制危机</a>的认识。复制危机有多种原因，但与本文相关的是<a class="ae lt" href="https://en.wikipedia.org/wiki/Multiple_comparisons_problem" rel="noopener ugc nofollow" target="_blank">多重比较问题</a>。数据分析师和科学家经常会遇到开放式的问题，这些问题需要进行数据探索，如“我们的客户在盈利能力方面的顶层和底层有什么不同？”本文解释了为什么分析师在探索数据集时不应该天真地测试多个假设。</p><h1 id="8b21" class="lu lv ji bd lw lx ly lz ma mb mc md me ko mf kp mg kr mh ks mi ku mj kv mk ml bi translated">多重比较问题背后的数学</h1><p id="6794" class="pw-post-body-paragraph kx ky ji kz b la mm kj lc ld mn km lf lg mo li lj lk mp lm ln lo mq lq lr ls im bi translated">多重比较问题可以用一句话来概括；如果你测试了足够多的假设，你会发现一些有统计学意义的结果，即使由于随机性，在潜在人群中没有真正的关系或差异。</p><blockquote class="mr"><p id="7bda" class="ms mt ji bd mu mv mw mx my mz na ls dk translated">“如果你折磨数据的时间足够长，它就会招供。”罗纳德·科斯</p></blockquote><p id="721f" class="pw-post-body-paragraph kx ky ji kz b la nb kj lc ld nc km lf lg nd li lj lk ne lm ln lo nf lq lr ls im bi translated">要理解为什么会这样，我们先用数学来定义这个问题。在测试多个独立假设时，我们担心在不应该的时候拒绝至少一个无效假设的可能性。这被称为家庭式错误率(FWER)。</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/bf79762124cdfa966eab94fffa6974ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/1*VC5gBfng-lcquKzeiRSG6g.png"/></div></figure><p id="335d" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">这可能很难用大量的假设检验来解决，因此使用补充规则来重写等式会更容易，补充规则认为事件不发生的概率等于 1 减去事件发生的概率。这给出了:</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/5035d6bfd20877a4351796eb61e7a4e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*bzIG8ZdF41PvMdiyB46U9w.png"/></div></figure><p id="9362" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">那么我们如何计算<strong class="kz jj"> <em class="nm"> P(错误发现数= 0) </em> </strong>的概率呢？在单一假设检验中做出错误发现的概率是:</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/75f60a24a4a74842fd589b84b99b4211.png" data-original-src="https://miro.medium.com/v2/resize:fit:702/format:webp/1*7Cvr4S5-q4jFPLD_9dxbAA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">对于单个测试</p></figure><p id="218b" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">使用补充规则，在单次测试中不出现错误发现的概率为:</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div class="gh gi no"><img src="../Images/616c3139bba781232a5fee6ae8fde247.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*8phTrlwr15pIYuhNUuXpcQ.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">对于单个测试</p></figure><p id="1de5" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">因为我们指定了我们的假设检验是相互独立的，所以我们可以用检验的数量乘以上面的数量。</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi np"><img src="../Images/fe2417c673e2915580dcd92070c9f3cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bPiW846BciXUbGd_XVmXDw.png"/></div></div></figure><p id="e70a" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">现在我们有了一个 FWER 的公式:</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/7e290ed3e56558c8ce5359bfd4aa29bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*dX-PtKcFuddhgLYyS_eHNw.png"/></div></figure><p id="e611" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">让我们看看 FWER 是如何随着使用 Python 执行的测试数量的增加而增长的。</p><pre class="nh ni nj nk gt nr ns nt nu aw nv bi"><span id="2add" class="nw lv ji ns b gy nx ny l nz oa">import numpy as np<br/>import matplotlib.pyplot as plt</span><span id="a13c" class="nw lv ji ns b gy ob ny l nz oa">alpha = 0.05<br/>num_tests = np.arange(1, 100, 1, int)<br/>fwer = 1 - (1 - alpha)**num_tests</span><span id="ffbc" class="nw lv ji ns b gy ob ny l nz oa">plt.plot(num_tests, fwer, linewidth=2)<br/>plt.title(f'FWER vs. Number of Tests at alpha = {alpha}')<br/>plt.xlabel('Number of Hypothesis Tests')<br/>plt.ylabel('FWER')<br/>plt.show()</span></pre><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/0655a97394fbe7d718a1fb3636986ca7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n72j3Odz92OmZ7C7JfU-Pw.png"/></div></div></figure><p id="e567" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">如您所见，找到至少一个错误发现的概率增长很快。在 13 次假设测试中，至少有 1 次错误发现的概率为 50–50 %,在 27 次测试中有 75%的概率，在 90 次测试中有 99%的概率。</p><h1 id="421c" class="lu lv ji bd lw lx ly lz ma mb mc md me ko mf kp mg kr mh ks mi ku mj kv mk ml bi translated">模拟演示</h1><p id="06a7" class="pw-post-body-paragraph kx ky ji kz b la mm kj lc ld mn km lf lg mo li lj lk mp lm ln lo mq lq lr ls im bi translated">如果你不相信，这里有一个模拟演示。我写了一个函数，对从<a class="ae lt" href="https://en.wikipedia.org/wiki/Normal_distribution" rel="noopener ugc nofollow" target="_blank">标准正态分布</a>中随机抽取的样本重复执行均值差异测试。我们知道每个样本都来自具有相同均值的相同分布，因此低于临界值的 p 值是假阳性。因此，我们可以对至少有一个假阳性的模拟进行计数，然后除以模拟的数量，得到一个近似的 FWER。这个结果可以与上面的精确公式进行比较。</p><p id="8df1" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">正如您在下面看到的，模拟的 FWER 接近每种情况下的确切 FWER。</p><pre class="nh ni nj nk gt nr ns nt nu aw nv bi"><span id="d310" class="nw lv ji ns b gy nx ny l nz oa">from scipy.stats import norm<br/>from scipy.stats import ttest_ind</span><span id="f76b" class="nw lv ji ns b gy ob ny l nz oa">def exact_fwer(alpha, num_tests):<br/>    return 1 - (1 - alpha)**num_tests</span><span id="5360" class="nw lv ji ns b gy ob ny l nz oa">def simulated_fwer(alpha, num_tests, num_sims):<br/>    count = 0<br/>    for i in range(num_sims):<br/>        false_disc = 0<br/>        for j in range(0, num_tests):<br/>            x = norm(loc=0, scale=1).rvs(size=100)<br/>            y = norm(loc=0, scale=1).rvs(size=100)<br/>            pvalue = ttest_ind(x, y)[1]<br/>            if pvalue &lt; alpha:<br/>                false_disc += 1<br/>                break<br/>        if false_disc != 0:<br/>            count += 1             <br/>    return count / num_sims</span><span id="b3de" class="nw lv ji ns b gy ob ny l nz oa">def compare_exact_sim_fwer(alpha, num_tests, num_sims):<br/>    exact = exact_fwer(alpha, num_tests)<br/>    sim = simulated_fwer(alpha, num_tests, num_sims)<br/>    return f'At alpha = {alpha} and {num_tests} Hypothesis Tests: \<br/>             Exact FWER = {exact}, Simulated FWER ={sim}'</span><span id="c12f" class="nw lv ji ns b gy ob ny l nz oa">print(compare_exact_sim_fwer(0.05, 13, 1000))<br/>print(compare_exact_sim_fwer(0.05, 27, 1000))<br/>print(compare_exact_sim_fwer(0.05, 90, 1000))</span></pre><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oc"><img src="../Images/f1aa583794bd3302097dfb69f920cb4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KOqFBJ6lWG7DjKg8s1Jxig.png"/></div></div></figure><p id="ae82" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">既然我们知道有问题，我们如何纠正它？</p><h1 id="1577" class="lu lv ji bd lw lx ly lz ma mb mc md me ko mf kp mg kr mh ks mi ku mj kv mk ml bi translated">如何纠正多重比较偏差</h1><p id="5361" class="pw-post-body-paragraph kx ky ji kz b la mm kj lc ld mn km lf lg mo li lj lk mp lm ln lo mq lq lr ls im bi translated">有许多方法可以缓解多重比较问题，但有两种方法特别受欢迎:T2 的邦费罗尼校正法和 T4 的霍尔姆-邦费罗尼法。</p><h2 id="0eb3" class="nw lv ji bd lw od oe dn ma of og dp me lg oh oi mg lk oj ok mi lo ol om mk on bi translated">邦费罗尼校正</h2><p id="86e2" class="pw-post-body-paragraph kx ky ji kz b la mm kj lc ld mn km lf lg mo li lj lk mp lm ln lo mq lq lr ls im bi translated">要进行 Bonferroni 校正，只需将您的统计显著性临界值除以进行的测试次数。</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/72de977103901849b7326318f5219ecc.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*6OSR5sodXV4rO8I8nG_2Fw.png"/></div></figure><p id="82d6" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">Bonferroni 校正 FWER 与下面的未调整 FWER 一起绘制。</p><pre class="nh ni nj nk gt nr ns nt nu aw nv bi"><span id="befe" class="nw lv ji ns b gy nx ny l nz oa">alpha = 0.05<br/>num_tests = np.arange(1, 100, 1, int)<br/>fwer = 1 - (1 - alpha)**num_tests<br/>fwer_bonferroni = 1 - (1 - alpha / num_tests)**num_tests</span><span id="8524" class="nw lv ji ns b gy ob ny l nz oa">plt.plot(num_tests, fwer, linewidth=2, color='b', label='No Correction')<br/>plt.plot(num_tests, fwer_bonferroni, linewidth=2, color='r', label='with Bonferroni Correction')<br/>plt.legend()<br/>plt.title(f'FWER vs. Number of Tests at alpha = {alpha}'0)<br/>plt.xlabel('Number of Hypothesis Tests')<br/>plt.ylabel('FWER')<br/>plt.show();</span></pre><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/1785e3741dcbc04d17ac0264b554858e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e1sJ60nQcups_u09koz6_A.png"/></div></div></figure><p id="3b6b" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">这种校正的一个好处是易于实现。一个缺点是，一旦测试数量变大，或者如果测试统计数据是相关的，它可能会过于保守。通过保持低的假阳性率，我们增加了假阴性的概率。如果我们非常关心这种权衡，我们可以考虑 Holm-Bonferroni 方法。</p><h2 id="f8bb" class="nw lv ji bd lw od oe dn ma of og dp me lg oh oi mg lk oj ok mi lo ol om mk on bi translated">霍尔姆-邦费罗尼方法</h2><p id="66be" class="pw-post-body-paragraph kx ky ji kz b la mm kj lc ld mn km lf lg mo li lj lk mp lm ln lo mq lq lr ls im bi translated">Holm-Bonferroni 方法比 Bonferroni 校正方法保守一些，但需要做更多的工作。</p><p id="e4f4" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">首先，从最小到最大排列假设检验的 p 值，然后应用此公式按最小 p 值的顺序获得每个假设检验的 alpha 值:</p><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div class="gh gi op"><img src="../Images/c27a56cbc220b333a3641c7a308c2c6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*IXx_PfEWKExHuyL-5Tm0EQ.png"/></div></figure><p id="de35" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">您浏览排序后的列表，将 p 值与其相关的 Holm-Bonferroni 校正α值进行比较。在第一次拒绝零假设失败时，你忽略了当时和之后的所有测试结果。</p><p id="ebaa" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">下图比较了 Holm-Bonferroni 调整和 Bonferroni 校正。如您所见，它不如 Bonferroni 校正保守，但与什么都不做相比，它确实大幅降低了 FWER。</p><pre class="nh ni nj nk gt nr ns nt nu aw nv bi"><span id="b103" class="nw lv ji ns b gy nx ny l nz oa">def holm_bonf_fwer(alpha, num_tests):<br/>    ranks = [i + 1 for i in range(num_tests)]<br/>    adj_alphas = [alpha / (num_tests - rank + 1) for rank in ranks]<br/>    <br/>    p_no_false_disc = 1<br/>    for adj_alpha in adj_alphas: <br/>        p_no_false_disc = p_no_false_disc * (1 - adj_alpha) <br/>            <br/>    return 1 - p_no_false_disc</span><span id="03b6" class="nw lv ji ns b gy ob ny l nz oa">alpha = 0.05<br/>num_tests = np.arange(1, 100, 1, int)<br/>fwer = 1 - (1 - alpha)**num_tests<br/>fwer_bonferroni = 1 - (1 - alpha / num_tests)**num_tests<br/>fwer_holm_bonferroni = [holm_bonf_fwer(alpha, i) for i in num_tests]</span><span id="e520" class="nw lv ji ns b gy ob ny l nz oa">plt.plot(num_tests, fwer, linewidth=2, color='b', label='No Correction')<br/>plt.plot(num_tests, fwer_bonferroni, linewidth=2, color='r', label='with Bonferroni Correction')<br/>plt.plot(num_tests, fwer_holm_bonferroni, linewidth=2, color='g', label='with Holm-Bonferroni Correction')<br/>plt.legend()<br/>plt.title(f'FWER vs. Number of Tests at alpha = {alpha}')<br/>plt.xlabel('Number of Hypothesis Tests')<br/>plt.ylabel('FWER')<br/>plt.show();</span></pre><figure class="nh ni nj nk gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/190bbe31f9bbb2ef578ab65442c7fb05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rk0H3CKRXX_RVoEqLC3dOQ.png"/></div></div></figure><h1 id="37d5" class="lu lv ji bd lw lx ly lz ma mb mc md me ko mf kp mg kr mh ks mi ku mj kv mk ml bi translated">结论</h1><p id="3c86" class="pw-post-body-paragraph kx ky ji kz b la mm kj lc ld mn km lf lg mo li lj lk mp lm ln lo mq lq lr ls im bi translated">如果您在阅读本文之前没有意识到多重比较问题，那么您现在应该知道为什么不能盲目地对一个数据集进行假设检验，看看哪些检验有意义。您还有两个工具来缓解这个问题。下次你在探索一个数据集时，别忘了使用它们。</p><p id="1f0b" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">注意:如果你对代码的理解受益于评论，请留言，我会添加它们。</p></div></div>    
</body>
</html>