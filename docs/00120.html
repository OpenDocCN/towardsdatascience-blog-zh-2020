<html>
<head>
<title>GANs from scratch.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">甘斯从零开始。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/gans-from-scratch-8f5da17b3fb4?source=collection_archive---------12-----------------------#2020-01-04">https://towardsdatascience.com/gans-from-scratch-8f5da17b3fb4?source=collection_archive---------12-----------------------#2020-01-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d7a8" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">生成对抗网络及其在PyTorch中的实现</h2></div><p id="88ec" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">去年，生成对抗网络(GANs)凭借那些令人印象深刻的人类面孔在人工智能领域掀起了一场风暴。他们真的很酷，不是吗？它们基本上是从无到有产生的。</p><p id="e245" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">没什么？？。*咳嗽*炫耀*咳嗽*。你们用数据来训练模型。我们知道这些“机器学习”是如何工作的。这只是一个输入输出函数的近似值。没什么让人印象深刻的。这只是另一种算法。</em></p><p id="957a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">不完全是。甘氏属于内隐学习方法。在显式学习模型中，模型直接从数据中学习其权重。而在隐式学习中，模型在没有数据直接通过网络的情况下进行学习。</p><p id="6264" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">啊！，所以是强化学习？</em></p><p id="ae82" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">RL和GANs之间有一些相似之处，因为他们都使用演员-批评家的方法。但学习的性质在甘是不同的。</p><p id="59b6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">好吧！我放弃了。所以，把甘解释成我5岁。</em></p><p id="9e34" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">好吧。因此，在巴塞罗那市，一个新的警察被任命来验证驾驶执照的真实性。他的工作是分类合法的和假的。因为他是新人，所以不管他的分类是否正确，他都会从他的同事那里得到反馈。镇上还有一个新的伪造者，他的目标是制造假驾照。所以，伪造者打印任何他认为是执照的东西，然后提交给警察。警察然后接受/拒绝它。每当警察拒绝它时，伪造者从错误中吸取教训，并试图开发一个万无一失的许可证，当它被接受时，他生产更多类似的许可证。但是当警察接受假执照时，他被同事纠正了。通过相互学习，警察和伪造者都会做得更好。</p><p id="8fd0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">咄！似乎应该由同事来验证</em></p><p id="00b0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我以为你才5岁。好吧，这是一个更好的版本。在GANs中，有两个网络鉴别器(警察)和生成器(伪造者)。生成器创建假数据(图像)，鉴别器对图像进行分类。基于来自鉴别器的结果，生成器开始学习创建越来越好的图像。因此，鉴别器和发生器都竞相提高性能。他们互相学习，每次跑步都越来越好。有趣的是，这两个网络都在学习过程中。所以，即使是鉴别器也不能一直正确分类。假设鉴别器将假图像分类为真图像，生成器从该结果得知生成的图像是好图像。当鉴别器通过从训练数据(同事)获得反馈来学习时，这将被修复。听起来他们两个肯定会融合。但是GANs的收敛性和稳定性是一个独立的话题。</p><p id="a4fb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">嗯，我必须说GANs现在听起来很有趣。因此，基本上生成器在看不到数据的情况下学习数据的底层分布。但是它从鉴别器网络学习，鉴别器网络也随着发生器同时学习。令人印象深刻。现在我想实现GANs并创造这些新的人工智能人。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/25e21d69b6338348d8ea334984a10742.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IZ5I8JsZTiL-aTl0r123Bg.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">卡拉斯等人<a class="ae lv" href="https://arxiv.org/abs/1812.04948" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1812.04948</a></p></figure><p id="c0b3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">呃。没那么快。为了这个结果，你需要更好地了解CNN，大量的超参数调整，8特斯拉GPU和一周的培训时间。在笔记本电脑上训练20分钟的基本数据集上的香草甘怎么样？听起来不错？那我们就这么做吧。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="b0dc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我使用PyTorch来实现它们。是的，我已经能听到来自Keras/Tensorflow人的“嘘声”。保持冷静，抓住机会适应它，就像我一样。</p><h1 id="6337" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">数据集:</h1><p id="77df" class="pw-post-body-paragraph ki kj it kk b kl mv ju kn ko mw jx kq kr mx kt ku kv my kx ky kz mz lb lc ld im bi translated">听说过MNIST数据集吗？。是的，我们会用到它。图像是灰度的，形状为28×28像素。让我们从<code class="fe na nb nc nd b">torch.datasets</code>模块加载数据集。图像被展平，并且使用<code class="fe na nb nc nd b">multiple_transforms</code>将值归一化为0–1。<code class="fe na nb nc nd b">DataLoader</code>功能帮助批量切片训练数据。</p><pre class="lg lh li lj gt ne nd nf ng aw nh bi"><span id="5c12" class="ni me it nd b gy nj nk l nl nm">from torch.datasets import MNIST<br/>from torchvision import transforms</span><span id="bf76" class="ni me it nd b gy nn nk l nl nm">trans = transforms.Compose([transforms.ToTensor(), torch.flatten])<br/>traindata = MNIST(root='./data', transform=trans, train=True, download=True)<br/>trainloader = torch.utils.data.DataLoader(traindata, batch_size=6000, shuffle=True)</span></pre><h2 id="ff01" class="ni me it bd mf no np dn mj nq nr dp mn kr ns nt mp kv nu nv mr kz nw nx mt ny bi translated">网络架构:</h2><p id="919b" class="pw-post-body-paragraph ki kj it kk b kl mv ju kn ko mw jx kq kr mx kt ku kv my kx ky kz mz lb lc ld im bi translated">我们将使用具有以下配置的全连接网络。不要对层和神经元感到困惑。您可以根据需要删除/添加层。这种配置有一些最佳实践，我将在后面解释。发生器的输入是任意值的噪声。在这里，我选择了128个神经元。生成器的输出必须与训练数据值(784)的形状相匹配。鉴别器得到784个神经元的输入，输出单个值，不管是真(1)还是假(0)。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi nz"><img src="../Images/f65429a30a780d453ba18677f764aa8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p5yjbMLYUCvRdHSROSCLJA.png"/></div></div></figure><p id="c4ee" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">将整个架构转化为网络相当简单。实现<code class="fe na nb nc nd b">nn.Modules</code>类并定义<code class="fe na nb nc nd b">forward</code>函数。pytorch最棒的地方就是亲笔签名的功能性。这意味着，我们不需要做背后的数学运算。自动计算所有神经元的梯度。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="aaa1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">酷毙了。一旦定义了这两个类，我们就可以实例化它们了。别忘了定义成本函数和要使用的优化算法。</p><pre class="lg lh li lj gt ne nd nf ng aw nh bi"><span id="8989" class="ni me it nd b gy nj nk l nl nm">discriminator = Discriminator()<br/>generator = Generator()</span><span id="15b4" class="ni me it nd b gy nn nk l nl nm">criterion = nn.BCELoss()<br/>discrim_optim = optim.Adam(discriminator.parameters(), lr= 0.0002)<br/>generat_optim = optim.Adam(generator.parameters(), lr=0.0002)</span></pre><p id="b8c4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">为什么要进行这种BCELoss和Adam优化？</em></p><p id="ff51" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">香草甘使用极大极小算法。最小最大损失通过生成器和鉴别器预测概率的对数损失来计算。BCELoss是二元交叉熵损失，它是概率的对数损失。可以使用两个不同的损失函数来训练生成器和鉴别器，但是这里我们对两者使用一个损失函数。对于权重更新，我们使用Adam optimizer，因为每个人都在使用它。哈哈，jk。你可以试试其他优化软件，比如SGD，Adagrad。</p><p id="539b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这样，模型设计完成了。耶。现在，让我们训练模型。</p><h2 id="73b2" class="ni me it bd mf no np dn mj nq nr dp mn kr ns nt mp kv nu nv mr kz nw nx mt ny bi translated"><strong class="ak">模特培训:</strong></h2><p id="004d" class="pw-post-body-paragraph ki kj it kk b kl mv ju kn ko mw jx kq kr mx kt ku kv my kx ky kz mz lb lc ld im bi translated">无论会发生什么样的混乱，都发生在这里。我们一步一步来。所以我们必须同时训练鉴别器和发生器。这基本上意味着以下步骤。</p><ol class=""><li id="304a" class="oc od it kk b kl km ko kp kr oe kv of kz og ld oh oi oj ok bi translated">向前通过鉴别器</li><li id="a517" class="oc od it kk b kl ol ko om kr on kv oo kz op ld oh oi oj ok bi translated">反向传播鉴别器误差</li><li id="1574" class="oc od it kk b kl ol ko om kr on kv oo kz op ld oh oi oj ok bi translated">更新鉴别器权重</li><li id="3a77" class="oc od it kk b kl ol ko om kr on kv oo kz op ld oh oi oj ok bi translated">向前通过发电机</li><li id="4a2d" class="oc od it kk b kl ol ko om kr on kv oo kz op ld oh oi oj ok bi translated">反向传播生成器错误</li><li id="fc22" class="oc od it kk b kl ol ko om kr on kv oo kz op ld oh oi oj ok bi translated">更新发电机重量</li></ol><p id="8ab3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">重复一遍。</p><pre class="lg lh li lj gt ne nd nf ng aw nh bi"><span id="9d42" class="ni me it nd b gy nj nk l nl nm"># Noise input for generator<br/>def noise(x,y):<br/>    return torch.randn(x,y)</span><span id="d41a" class="ni me it nd b gy nn nk l nl nm">for epoch in range(2000):<br/>    for pos_samples in trainloader:<br/>        # Training Discriminator network<br/>        discrim_optim.zero_grad()<br/>        pos_predicted = discriminator(pos_samples[0])<br/>        pos_error = criterion(pos_predicted, torch.ones(batches,1))</span><span id="28ff" class="ni me it nd b gy nn nk l nl nm">	neg_samples = generator(noise(batches, 128))<br/>        neg_predicted = discriminator(neg_samples)<br/>        neg_error = criterion(neg_predicted, torch.zeros(batches,1))</span><span id="4c3a" class="ni me it nd b gy nn nk l nl nm">	discriminator_error = pos_error + neg_error<br/>        discriminator_error.backward()<br/>        discrim_optim.step()<br/>        <br/>        # Training generator network<br/>        generat_optim.zero_grad()<br/>        gen_samples = generator(noise(batches, 128))<br/>        gen_predicted = discriminator(gen_samples)<br/>        generator_error = criterion(gen_predicted, torch.ones(batches, 1))<br/>        generator_error.backward()<br/>        generat_optim.step()</span></pre><p id="bfaa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">就是这样。搞定了。</p><p id="c488" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">哇哇哇。慢点。我有很多问题！</em></p><p id="23d1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">为什么只索引数据，</em> <code class="fe na nb nc nd b"><em class="le">pos_samples[0]</em></code> <em class="le">。训练数据的标签怎么了？<br/> - </em>漂亮的斑点。在香草甘，我们不在乎标签。我们基本上给出所有的训练数据来训练网络，而不管它来自哪个类。因此，发生器网络必须拟合权重，以重现不同噪声输入的所有变化。也就是说，GANs有几个变化，它考虑了像辅助GANs这样的标签。</p><p id="ae8a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">这个zero_grad()对于优化器来说是什么？<br/> </em> -对于每个时期，我们希望梯度为零，以便在每次反向传播期间计算的梯度可以在神经元中没有剩余梯度的情况下出现。如果没有zero_grad()，梯度将在每个时期累积，这在像RNNs这样的网络中很有用。</p><p id="5d06" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如何将两个错误相加并执行backward()？<br/>——好大的pythonic吧？这是pytorch的亲笔签名模块。它负责反向传播这两个错误。</p><p id="463f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">好的，那么现在你如何知道网络何时被训练？。我应该观察哪个成本函数？<br/> - 如前所述，收敛是GAN中一个有趣的问题。严格来说，当鉴别器和生成器都达到纳什均衡时，GAN就被称为被训练。由于GAN是一个极小极大问题，当一个网络最大化其成本函数时，另一个网络试图最小化它。我们正在训练两者来提高。纳什均衡状态下，代理人不改变其行动的过程，不管其他代理人的决定。在训练过程中，一个网络从另一个网络开始训练，但是当它到达一个点，不管另一个网络的决定，鉴别器或生成器都不会变得更好时，它就达到了纳什均衡。实际上，给定一组相同的真实和伪造图像，鉴别器将检测每个真实和伪造图像为真实的，因此预测精度将为50%。</p><h2 id="9c6d" class="ni me it bd mf no np dn mj nq nr dp mn kr ns nt mp kv nu nv mr kz nw nx mt ny bi translated">最佳实践:</h2><p id="731c" class="pw-post-body-paragraph ki kj it kk b kl mv ju kn ko mw jx kq kr mx kt ku kv my kx ky kz mz lb lc ld im bi translated">几乎没有关于更好的模型和更快收敛的最佳实践。我故意把这个放在最后，因为有些讨论可能会改变代码，如果在主要内容中解释，会导致混乱。</p><ul class=""><li id="5e20" class="oc od it kk b kl km ko kp kr oe kv of kz og ld oq oi oj ok bi translated">在最后一层，对鉴别器使用sigmoid激活函数，对生成器使用tanh函数。在这种情况下，发电机的输出将在范围(-1，1)内。因此，我们还必须将训练数据标准化到这个范围(-1，1)</li><li id="dade" class="oc od it kk b kl ol ko om kr on kv oo kz op ld oq oi oj ok bi translated">不是为1训练真实图像，为0训练虚假图像，而是用0.98和0.02或类似的值训练它们</li><li id="2216" class="oc od it kk b kl ol ko om kr on kv oo kz op ld oq oi oj ok bi translated">为了快速检查您的GAN设置是否正常工作，请将训练数据限制在单个类中，并检查它们的表现如何。在包含10个类的MNIST数据集上，对于一些未失真的图像，可能需要几个小时的时间，因此最好检查一下配置是否适用于有限的数据集。</li><li id="ad11" class="oc od it kk b kl ol ko om kr on kv oo kz op ld oq oi oj ok bi translated">由于生成器比鉴别器需要更多的训练时间，所以在鉴别器中使用丢弃层可以阻止过拟合。</li></ul><h2 id="8d52" class="ni me it bd mf no np dn mj nq nr dp mn kr ns nt mp kv nu nv mr kz nw nx mt ny bi translated">以下是完整的代码:</h2><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="oa ob l"/></div></figure></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="48ab" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢您阅读帖子。如果你发现了任何错误或有疑问，请在评论中告诉我。</p><p id="4880" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">欢迎通过<a class="ae lv" href="https://github.com/chmodsss" rel="noopener ugc nofollow" target="_blank"> Github </a>、<a class="ae lv" href="https://twitter.com/chmodsss" rel="noopener ugc nofollow" target="_blank"> Twitter </a>和<a class="ae lv" href="https://www.linkedin.com/in/sivasuryas" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>联系我。干杯！。</p><p id="ed67" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">非常感谢<a class="ae lv" href="https://medium.com/ai-society/gans-from-scratch-1-a-deep-introduction-with-code-in-pytorch-and-tensorflow-cb03cdcdba0f" rel="noopener">文章</a>作者<a class="or os ep" href="https://medium.com/u/2ae3e490bdf8?source=post_page-----8f5da17b3fb4--------------------------------" rel="noopener" target="_blank">迭戈·戈麦斯莫斯克拉</a>。</p></div></div>    
</body>
</html>