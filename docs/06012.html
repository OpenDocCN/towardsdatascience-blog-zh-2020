<html>
<head>
<title>Gaming: A gold mine for datasets</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">游戏:数据集的金矿</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/gaming-a-gold-of-dataset-b94df0582544?source=collection_archive---------34-----------------------#2020-05-16">https://towardsdatascience.com/gaming-a-gold-of-dataset-b94df0582544?source=collection_archive---------34-----------------------#2020-05-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8e65" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如果算法可以被动学习，而不需要提供注释，会怎么样？—嗯，这正是游戏可以帮助我们的！</h2></div><p id="05a9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这篇文章讲述了我如何从一个项目中脱离出来，构建了一个东西或程序，而这个东西或程序是无人监督的(我猜同时也是有人监督的)。使用GTA V mods，我为计算机视觉任务创建了一个数据集，由游戏中看到的对象组成。我还将展示一个小的物体检测器在现实世界中的表现。</p><p id="9072" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">TLDR，在游戏图像上训练的物体检测器，在真实世界的图像上概括得非常好。</p><p id="1f0b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本文分为以下几个部分:</p><ol class=""><li id="051a" class="lb lc iq kh b ki kj kl km ko ld ks le kw lf la lg lh li lj bi translated">机器学习导论</li><li id="1245" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">数据集对机器学习重要吗？</li><li id="2d4f" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">游戏和游戏玩家能帮助制作更好的数据集吗？</li><li id="28bf" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">训练物体探测器</li><li id="ae58" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">演示，显示对象检测的结果</li></ol><p id="0d3d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我应该强调，这不是一个修改GTAV的教程，我不能解释和提供代码(也许以后，有一天当我有更多的时间)来使用GTAV API获取游戏世界信息。你可以在一个单独的类上玩物体检测器的小演示可以在<a class="ae lp" href="https://colab.research.google.com/drive/1CC9eRVRR3rRTx99UIv8ugjmVJwdT6y5Y?usp=sharing" rel="noopener ugc nofollow" target="_blank">这里</a>找到。<a class="ae lp" href="https://forums.gta5-mods.com/topic/14693/quick-start-guide-to-modding-grand-theft-auto-v" rel="noopener ugc nofollow" target="_blank">这个</a>指南可以帮助你开始在侠盗猎车手v中进行改装，如果你想更深入地从游戏世界中提取信息，这个工具可以作为起点。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="ab gu cl lv"><img src="../Images/a061f2b1bf982df6694942f9d14a8005.png" data-original-src="https://miro.medium.com/v2/format:webp/0*xME0lZK5XVQ8HF2S.jpg"/></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">来源:<a class="ae lp" href="https://img.youtube.com/vi/Usx-Cf8TlNI/0.jpg" rel="noopener ugc nofollow" target="_blank">https://img.youtube.com/vi/Usx-Cf8TlNI/0.jpg</a></p></figure><h1 id="6abd" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">机器学习导论</h1><p id="2f38" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">如果你有机器学习的先验知识，那么你可以跳过这一节。因为这篇文章不是关于学习机器学习，而是关于一个应用，所以我不能在这里深入讨论机器学习的概念。以下是一些很棒的文章，可以帮助你理解这个计算机科学领域:</p><ol class=""><li id="527f" class="lb lc iq kh b ki kj kl km ko ld ks le kw lf la lg lh li lj bi translated"><a class="ae lp" href="https://medium.com/machine-learning-for-humans/why-machine-learning-matters-6164faf1df12" rel="noopener">机器学习很有趣</a></li><li id="07e4" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated"><a class="ae lp" href="https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471" rel="noopener">为什么机器学习很重要</a></li></ol><p id="7497" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我是ELI5(像我五岁一样解释)机器学习是人工智能的一种形式，其中程序或算法被设计成能够自己学习。像人类一样，被称为神经元的小逻辑单元(下图中的圆圈)帮助<strong class="kh ir">算法</strong>从经验中学习(或从计算机、数据的角度来说)。算法中的参数会改变并学习数据集中的模式。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/36c4c510f10969176f94520642c30d5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/0*BnqlZRQKk0GSd-Qx.gif"/></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">这个视频是学习机器学习的一个很好的起点。https://www.youtube.com/watch?v=aircAruvnKk&amp;list = plzhqobowtqdnu 6 r 1 _ 67000 dx _ ZCJB-3pi</p></figure></div><div class="ab cl na nb hu nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="ij ik il im in"><h1 id="c2a0" class="mc md iq bd me mf nh mh mi mj ni ml mm jw nj jx mo jz nk ka mq kc nl kd ms mt bi translated">数据集对机器学习重要吗？</h1><p id="4983" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">数据是任何学习形式的基本必需品。我们人类在经历或阅读/听到他们的经历后，学会了感知或理解行为的能力。数据集，不管有没有标记，都是所有机器学习任务的基础。</p><p id="70c1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了训练机器学习模型，需要大量数据。俗话说:“人越多越开心”，这句话再正确不过了。当前最先进的(SOTA)机器学习模型需要海量数据，例如，许多NLP任务的<a class="ae lp" href="https://github.com/google-research/bert" rel="noopener ugc nofollow" target="_blank">伯特</a>、SOTA都是在数十GB的数据上训练的。</p><p id="d026" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lp" href="https://devopedia.org/imagenet" rel="noopener ugc nofollow" target="_blank"> Imagenet </a>一个标准的图像分类数据集大约有144千兆字节的压缩数据和&gt; 300千兆字节的未压缩数据。不用说，被标记的数据对于人工智能的进步是非常重要的。</p><p id="ef72" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在处理一个项目时，我遇到了一个问题，我使用的对象检测器无法识别图像帧中的所有对象。我试图对图片框中的所有对象进行索引，这将使图片搜索变得更加容易。但是所有的图像都被标记为<strong class="kh ir">人类</strong>，无法检测图像帧中的其他物体，搜索没有像我希望的那样工作。</p><p id="4fde" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个问题的理想解决方案是收集这些对象的数据，并重新训练对象检测器来识别新的对象。这不仅无聊而且耗时。我可以使用<a class="ae lp" href="https://arxiv.org/pdf/1904.09135.pdf" rel="noopener ugc nofollow" target="_blank"> GANs </a>，这是一种机器学习算法，以其创建人工和类似的输入示例而闻名，在手动组织一些样本后创建更多样本，但这也很无聊，需要资源来训练GANs生成更多数据。</p><p id="6cdb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我唯一能做的就是使用互联网服务，比如<a class="ae lp" href="https://scale.com/" rel="noopener ugc nofollow" target="_blank"> ScaleAI </a>和<a class="ae lp" href="https://cloud.google.com/vision/automl/docs/human-labeling" rel="noopener ugc nofollow" target="_blank">谷歌云平台</a>，来创建一个数据集。但是这些服务对每张带注释的图片收费0.05美元。为15个类别创建一个100张图片的数据集意味着我将不得不为这个数据集花费120美元。仅仅为了一个简单的项目而花费这么多美元不是一个可行的选择。</p><h1 id="6d60" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">游戏和游戏玩家能帮助制作更好的数据集吗？</h1><p id="b7f7" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">在所有选项中，我开始希望如果有一个人造的世界，所有的物体都已经有了各自的标签。这样我就不必花时间搜索样本，然后小心翼翼地为它们生成注释。然后我意识到游戏世界是这种人工或虚拟世界的最好例子。当世界被创建时，游戏引擎拥有所有必要的信息，它知道哪些纹理位于哪里，并且知道所有其他物体的位置。看看游戏的当前状态，开发者正在挑战极限，创造与现实世界几乎没有区别的游戏环境。PS5上的虚幻引擎5 <a class="ae lp" href="https://www.youtube.com/watch?v=qC5KtatMcUw" rel="noopener ugc nofollow" target="_blank">演示</a>展示了下一代游戏机将夸耀的图形保真度。拥有一个与真实世界非常相似的虚拟世界，应该是测试和学习算法的一个很好的模拟。允许算法访问游戏世界的信息，让它了解角落和缝隙，这将是一件很棒的事情。</p><p id="2947" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我想到的第一个游戏是<a class="ae lp" href="https://www.youtube.com/watch?v=dQw4w9WgXcQ" rel="noopener ugc nofollow" target="_blank">神秘海域4:盗贼末路</a>。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="ab gu cl lv"><img src="../Images/37433cd6f561f4ca98ea6ff5eebf17dd.png" data-original-src="https://miro.medium.com/v2/format:webp/0*3gk97VW8-6yBda5p.jpg"/></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">F</p></figure><p id="7da0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一个令人惊叹的游戏，有一个很好的故事，它有所有的元素，我们想从测试环境。它拥有所有的自然地形类型:平原，高原，洞穴，海岸，它还拥有近乎照片般逼真的图形，这意味着物体探测器将学习更接近真实世界的特征和形状。但问题是，我在大学里没有ps4，也没有办法以我喜欢的方式访问未知的资源。</p><p id="b0e8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">游戏的另一个选择可以满足我的要求:</p><ol class=""><li id="d6db" class="lb lc iq kh b ki kj kl km ko ld ks le kw lf la lg lh li lj bi translated">摄影现实主义</li><li id="19b6" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">修改界面以允许访问游戏世界数据</li></ol><p id="2f28" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">《侠盗猎车手:v》的基地虽然已经有7年的历史了，但与大多数其他游戏相比，它更像真实世界。这个游戏有广泛的支持mods和作出改变/与游戏世界互动。这个游戏，在使用了一些mods之后，可以用它所有的灯光和倒影看起来非常惊人</p><p id="8ddb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">GTA V社区做出了一些令人愤慨的修改，其中默认的玩家模型被自定义模型所取代。这是一件非常非常棒的事情，我稍后会继续讨论。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="ab gu cl lv"><img src="../Images/0484b2b911e5a3f629b00b34d26264de.png" data-original-src="https://miro.medium.com/v2/format:webp/0*PVgGVJWBwMG312b0.png"/></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">摄影现实主义</p></figure><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="ab gu cl lv"><img src="../Images/a2a443a441601cc154b984d89b7dc263.png" data-original-src="https://miro.medium.com/v2/0*uYETFtI3JEBIpdmg"/></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">大雄作为玩家模型，lol</p></figure><p id="fcd3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我首先阅读了一些关于使用Rage Engine(GTA使用的引擎)的API的文章和指南。很少有好的例子或指南来帮助我实现我想要达到的目标。但幸运的是，有一个<a class="ae lp" href="https://www.gta5-mods.com/tools/map-info-tool" rel="noopener ugc nofollow" target="_blank">惊人的工具</a>做了一些接近我试图实现的事情，它给出了用户当前图像帧中许多对象的位置。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="ab gu cl lv"><img src="../Images/ea2fc0512392790ff3fd0c01026d80d8.png" data-original-src="https://miro.medium.com/v2/format:webp/0*PGg--QWaifXSytHJ.jpg"/></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">使用地图工具打开用户界面</p></figure><p id="d9a3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个工具最棒的地方在于它的源代码可以在<a class="ae lp" href="https://github.com/CamxxCore/MapInfoTool" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到。有了这个坚实的起点后，任务就归结为如何从游戏世界中访问对象信息，比如它的位置和类型。这是在长时间阅读代码、编译错误代码之后实现的。我可以从游戏屏幕上记录结果。我从简单的日志开始:</p><pre class="lq lr ls lt gt nm nn no np aw nq bi"><span id="1359" class="nr md iq nn b gy ns nt l nu nv"># the first log file that was created script running inside of GTA V<br/>[{<br/>  "label": "car",<br/>  "location": [<br/>    [248.42533936651586, 173.41176470588235],<br/>    [442.5429864253394, 278.841628959276]<br/>  ],<br/>  "group_id": "non-living"<br/>},<br/>{<br/>  "label": "trevor",<br/>  .....<br/>  "group_id": living"<br/>},<br/>{<br/>  "label": "cat",<br/>  .....<br/>  "group_id": living"<br/>}]</span></pre><p id="e981" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有些事情很简单，比如获得命名对象的位置，比如使用<a class="ae lp" href="https://nitanmarcel.github.io/shvdn-docs.github.io/namespace_g_t_a.html#af3b53fbeac4469166a20fc1e97f2572c" rel="noopener ugc nofollow" target="_blank">哈希</a>单独识别的字符。渐渐地，我学会了与API交互，以获取行人和附近行驶的汽车等物体的位置。我无法完全破解游戏世界来获得我想要的所有物体的位置信息，但这是一个很好的起点。最初的结果看起来很有希望，当检测到物体时，脚本会对游戏进行截图，并保存物体的位置。结果看起来像这样:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi nw"><img src="../Images/aef215435713d2da76d3d6db0a874d4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j7uFwvX1ePreGY7QSguTNw.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">从游戏世界获得的图像坐标用于创建边界框。额外:我曾经用CannyEdgeCropping来使边界框更精确。</p></figure><h1 id="a0e0" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">训练物体检测器</h1><p id="e16a" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">有了这些令人满意的结果，我继续创建更多的样本。我决定用14个物体:</p><ol class=""><li id="8273" class="lb lc iq kh b ki kj kl km ko ld ks le kw lf la lg lh li lj bi translated">类人:行人或人类、狗和猫(3)</li><li id="0721" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">有生命但不像人的东西:树(4)</li><li id="f95f" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">非生物:汽车、卡车、自行车、火车、船、交通信号、广告牌(6)</li></ol><p id="9fe3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在获得足够的数据来训练模型之后。我开始在我的大学服务器上训练一个<a class="ae lp" href="https://arxiv.org/abs/1708.02002" rel="noopener ugc nofollow" target="_blank"> RetinaNet </a>模型，这是一个中等强大的机器，配有Quadro P5000和英特尔至强G6132。选择RetinaNet没有特别的原因，我有使用它的经验。我从头开始训练网络，因为使用预先训练的权重会扼杀这个项目的想法，即使用游戏世界的知识并将其应用到现实世界中。</p><p id="e2e9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">经过一小时又一小时的等待，我意识到看着缓慢的训练进度不会加快速度，决定今天到此为止，睡觉。在漫长的等待之后，训练结束了，表演时间到了。在由游戏图像组成的测试集上测试该模型。结果似乎是公平的:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi ob"><img src="../Images/6c9032133588fe9de2c2d0bf27e9d9d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LEeNP3ziKoSPlNC6U8hWsw.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">结果似乎很好，但我不明白正确的汽车是如何检测出来的。绿色是汽车，红色是人。圆圈是坐标。</p></figure><p id="bc85" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">结果和预期的一样，现在是在真实对象上测试性能的时候了。我认为从结果来看，这个实验可以说是成功的:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi oc"><img src="../Images/6bc8a759cf69a0e1807431729853ce96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oD9gaYeO6wyuFyNvej4HWA.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">我讨厌物体探测器没找到谢尔顿和拉杰什</p></figure><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi oc"><img src="../Images/05ede50456a60fe68d76ec04df5c0189.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2y9knxrqGg0AlQERtPY9pw.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">模特再次表现良好</p></figure><p id="f65e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">大多数物体都被很好地识别了，但是我注意到了一个错误:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi od"><img src="../Images/b4fdefafb9290fea4c51611c759ee2a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/1*1a-Fes0AiMju_eTmbzbB0Q.png"/></div></figure><p id="6b2d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我认为这是因为游戏中缺少猫和狗的不同玩家模型。该模型能够学习数据集中不同对象的形状，但由于猫和狗的样本种类有限，这些类的情况并不顺利。它不能学习让它区分狗和猫的特征。狗和猫的模型数量是有限的，修改和添加新的模型可以弥补这种情况。</p><h1 id="aee5" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">演示</h1><p id="6c0b" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">该模型在图像上表现良好，但不要相信我的话。我创造了一个<a class="ae lp" href="https://colab.research.google.com/drive/1CC9eRVRR3rRTx99UIv8ugjmVJwdT6y5Y?usp=sharing" rel="noopener ugc nofollow" target="_blank"> colab笔记本</a>，你可以在5分钟内训练你自己的模型从图像中识别人类。为了保持尽可能低的运行时间，笔记本只有来自游戏的<strong class="kh ir"> 200 </strong>个人体样本的小数据集。这种低数量的样本足以显示这种模型的潜力。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi oe"><img src="../Images/f0a36a277d5ea2d14b51ff59865a61a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lrkbtliJ1FtJaGbmOZVzGg.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">测试集上的检测</p></figure><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi of"><img src="../Images/de85071c994f580f6bafe4f63e8739ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o4hbraRrET3112R7s20c_g.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">物体的小贴图和它们的纹理位置，这些部分目前有点奇怪。仍然需要做一些数学方面的工作。</p></figure><p id="57d8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在启动并运行了对象检测之后，我想让语义分割工作起来，因为这是自动标注的真正潜力所在。利用游戏引擎的纹理知识来获得像素级分割。我还没想好怎么从GTA V用的游戏引擎RAGE engine获取基于纹理的信息，获取物体的位置是一回事，获取物体的位置和区域覆盖又是另一回事。后者是我目前的困境。</p><p id="413e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我相信这一点的潜力是巨大的，通过使用mods，我们可以很容易地用那些我们想要建立探测器的东西来替换玩家模型。在这项技术中，我们可以替换一个简单的布娃娃的角色模型，该模型可以作为创建一个在各种环境中角色外观的大型数据库的基础。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="ab gu cl lv"><img src="../Images/73d305b82dc57949601696d27ae127ba.png" data-original-src="https://miro.medium.com/v2/0*b80O6wQwSEaDCu44.gif"/></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">示例:此处的玩家模型由海鸥模型替换而来。来源:<a class="ae lp" href="https://en.wikipedia.org/wiki/Modding_in_Grand_Theft_Auto" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></figure><p id="723b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">随着我的<a class="ae lp" href="https://summerofcode.withgoogle.com/projects/#5500640064700416" rel="noopener ugc nofollow" target="_blank"> GSoC选择</a>，我的时间减少了，开发环境也改变了。我希望将来能回到这个项目中来。我计划上传所有图片及其标签的31GB数据集，但目前这是不可能的，因为我大学的互联网服务慢得令人难以忍受。</p><p id="b1c9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我在这里的下一个博客将是我正在进行的另一个项目的开发日志，或者是GSoC博客的启动博客，我将在未来3个月内发布这些博客，以展示我在CERN的工作进展。</p></div></div>    
</body>
</html>