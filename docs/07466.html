<html>
<head>
<title>The charm of Apache Pig</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">阿帕奇猪的魅力</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-charm-of-apache-pig-fdc92b5cc3b4?source=collection_archive---------51-----------------------#2020-06-05">https://towardsdatascience.com/the-charm-of-apache-pig-fdc92b5cc3b4?source=collection_archive---------51-----------------------#2020-06-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ae9a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">不容错过的大数据工具</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6603a2eaa0b12da4c57f957a21550e30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v1dRCjcQMoXDOpsWD79CQA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://www.pngitem.com/middle/hiJhiRR_apache-pig-logo-png-transparent-png/" rel="noopener ugc nofollow" target="_blank">图像来源</a></p></figure><p id="00ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Apache Pig是Hadoop生态系统中的核心技术。本文的目的是讨论Apache Pig是如何在Hadoop技术工具中脱颖而出的，以及为什么以及何时应该利用Pig来完成大数据任务。</p><p id="e3f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">任何对Hadoop有一定了解的人都知道，它能够以分布式方式处理大量数据。Hadoop的编程模型MapReduce通过将一个作业拆分为一组map任务和Reduce任务来实现并行处理大型数据集。MapReduce是底层的低级编程模型，这些工作可以使用Java和Python之类的语言来实现。</p><p id="35e4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">考虑一个简单的字数统计任务，我们希望通过Hadoop来实现。这项工作的目的是统计每个单词在给定的输入集中出现的次数。下面的代码片段展示了如何使用Java编写的mapper类和reducer类来实现这一点。这是<a class="ae ky" href="https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html#Source_Code" rel="noopener ugc nofollow" target="_blank">https://Hadoop . Apache . org/docs/current/Hadoop-MapReduce-client/Hadoop-MapReduce-client-core/MapReduce tutorial . html # Source _ Code</a>中提供的一个例子</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="db0d" class="ma mb it lw b gy mc md l me mf">import java.io.IOException;<br/>import java.util.StringTokenizer;</span><span id="399e" class="ma mb it lw b gy mg md l me mf">import org.apache.hadoop.conf.Configuration;<br/>import org.apache.hadoop.fs.Path;<br/>import org.apache.hadoop.io.IntWritable;<br/>import org.apache.hadoop.io.Text;<br/>import org.apache.hadoop.mapreduce.Job;<br/>import org.apache.hadoop.mapreduce.Mapper;<br/>import org.apache.hadoop.mapreduce.Reducer;<br/>import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;<br/>import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><span id="1ea9" class="ma mb it lw b gy mg md l me mf">public class WordCount {</span><span id="0f7e" class="ma mb it lw b gy mg md l me mf">public static class TokenizerMapper<br/>       extends Mapper&lt;Object, Text, Text, IntWritable&gt;{</span><span id="2b91" class="ma mb it lw b gy mg md l me mf">private final static IntWritable one = new IntWritable(1);<br/>    private Text word = new Text();</span><span id="f50b" class="ma mb it lw b gy mg md l me mf">public void map(Object key, Text value, Context context<br/>                    ) throws IOException, InterruptedException {<br/>      StringTokenizer itr = new StringTokenizer(value.toString());<br/>      while (itr.hasMoreTokens()) {<br/>        word.set(itr.nextToken());<br/>        context.write(word, one);<br/>      }<br/>    }<br/>  }</span><span id="66c2" class="ma mb it lw b gy mg md l me mf">public static class IntSumReducer<br/>       extends Reducer&lt;Text,IntWritable,Text,IntWritable&gt; {<br/>    private IntWritable result = new IntWritable();</span><span id="5fb8" class="ma mb it lw b gy mg md l me mf">public void reduce(Text key, Iterable&lt;IntWritable&gt; values,<br/>                       Context context<br/>                       ) throws IOException, InterruptedException {<br/>      int sum = 0;<br/>      for (IntWritable val : values) {<br/>        sum += val.get();<br/>      }<br/>      result.set(sum);<br/>      context.write(key, result);<br/>    }<br/>  }</span><span id="7a93" class="ma mb it lw b gy mg md l me mf">public static void main(String[] args) throws Exception {<br/>    Configuration conf = new Configuration();<br/>    Job job = Job.getInstance(conf, "word count");<br/>    job.setJarByClass(WordCount.class);<br/>    job.setMapperClass(TokenizerMapper.class);<br/>    job.setCombinerClass(IntSumReducer.class);<br/>    job.setReducerClass(IntSumReducer.class);<br/>    job.setOutputKeyClass(Text.class);<br/>    job.setOutputValueClass(IntWritable.class);<br/>    FileInputFormat.addInputPath(job, new Path(args[0]));<br/>    FileOutputFormat.setOutputPath(job, new Path(args[1]));<br/>    System.exit(job.waitForCompletion(true) ? 0 : 1);<br/>  }<br/>}</span></pre><p id="865a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">好的，这段代码由61行代码组成。要写这样的东西，你必须清楚地理解MapReduce的基本概念和理论。而且，您应该知道以您的首选语言提供的一组库或包，以及它们应该如何组合在一起。映射器、归约器和其他实用方法必须被显式地调用或组合到管道中，以实现整体结果(本例中为main方法)。总之，这段代码必须被编译和部署。听起来有点复杂，尤其是如果你没有MapReduce或Java背景的话？</p><p id="731f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我用Java编写我的第一个MapReduce程序时，我自己也问过这个问题——“有没有更简单的方法来实现这一点？”。答案是‘是的，有，而且是用阿帕奇猪’。</p><blockquote class="mh mi mj"><p id="e506" class="kz la mk lb b lc ld ju le lf lg jx lh ml lj lk ll mm ln lo lp mn lr ls lt lu im bi translated">Apache Pig是一个高级平台，用于创建在Hadoop上运行的程序。这个平台的语言叫做猪拉丁语。</p></blockquote><p id="866e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Pig Latin是一种类似SQL的脚本语言，它抽象了MapReduce的编程概念。如果您熟悉SQL的基本概念，使用Pig Latin将MapReduce作业放置到位只需几分钟。它将MapReduce的底层复杂概念转换成一个非常高级的编程模型。</p><p id="d379" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们看看上面我们用Java MapReduce做的字数统计任务是如何使用猪拉丁(<a class="ae ky" href="https://en.wikipedia.org/wiki/Apache_Pig" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Apache_Pig</a>)实现的。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="98dc" class="ma mb it lw b gy mc md l me mf">input_lines = LOAD '/tmp/word.txt' AS (line:chararray);<br/><br/>words = FOREACH input_lines GENERATE FLATTEN(TOKENIZE(line)) AS word;<br/> <br/>filtered_words = FILTER words BY word MATCHES '\\w+';<br/> <br/>word_groups = GROUP filtered_words BY word;<br/> <br/>word_count = FOREACH word_groups GENERATE COUNT(filtered_words) AS count, group AS word;</span><span id="2a58" class="ma mb it lw b gy mg md l me mf">ordered_word_count = ORDER word_count BY count DESC;</span><span id="3c27" class="ma mb it lw b gy mg md l me mf">STORE ordered_word_count INTO '/tmp/results.txt';</span></pre><p id="2d17" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有了猪拉丁，我们把之前的61行压缩到了7行。同样的任务是通过操作几个关键字来完成的。像这样的一段代码很容易实现，也很容易被其他人理解。所以，很明显Apache Pig降低了MapReduce的学习和开发曲线。理解上面的7行代码是我留给你们的挑战。有兴趣的话可以从这里开始学习猪拉丁的基础知识:【https://pig.apache.org/docs/r0.17.0/basic.html<a class="ae ky" href="https://pig.apache.org/docs/r0.17.0/basic.html" rel="noopener ugc nofollow" target="_blank"/></p><p id="dffe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下表提供了基于上述示例的Apache Pig和MapReduce的汇总比较。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mo"><img src="../Images/53686942c2c9b6246783666aedebfa26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L5MWg6FnQ8lvqnuFvupHUw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">MapReduce vs Pig</p></figure></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h2 id="cb5e" class="ma mb it bd mw mx my dn mz na nb dp nc li nd ne nf lm ng nh ni lq nj nk nl nm bi translated">阿帕奇猪架构概述</h2><p id="c85f" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">即使我们试图区分MapReduce和Apache Pig，我们也必须理解Apache Pig是建立在MapReduce之上的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/5fd190bd477639246cfdda319070b0fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:866/format:webp/1*XzGZfcmAkNMzp8g3FPcZDQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">猪建筑:<a class="ae ky" href="https://www.tutorialandexample.com/apache-pig-architecture/" rel="noopener ugc nofollow" target="_blank">图片来源</a></p></figure><p id="93e7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Pig脚本通过<strong class="lb iu"> <em class="mk">解析器</em> </strong>转换成有向无环图(DAG ),然后输入优化器进行进一步优化。<strong class="lb iu"> <em class="mk">优化器</em> </strong>执行逻辑优化，如投影，并将优化后的逻辑计划传递给编译器。<strong class="lb iu"> <em class="mk">编译器</em> </strong>将其转换为一组MapReduce作业，并传递给<strong class="lb iu"> <em class="mk">执行引擎</em> </strong>。这种架构也证明了好处来自于易于实现和易于理解。Apache Pig充当MapReduce复杂概念的高级包装器，并为用户提供一个易于处理的脚本框架。</p></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><p id="7924" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们更深入地挖掘一下Apache Pig的一些有趣特性。</p><ol class=""><li id="b160" class="nt nu it lb b lc ld lf lg li nv lm nw lq nx lu ny nz oa ob bi translated"><strong class="lb iu">强大的内置功能集</strong> : Pig自带一系列内置功能。这些函数分为eval、load/store、math、string、bag和tuple函数。更多关于Pig内置函数的细节可以在这里找到:<a class="ae ky" href="https://pig.apache.org/docs/r0.17.0/func.html" rel="noopener ugc nofollow" target="_blank">https://pig.apache.org/docs/r0.17.0/func.html</a></li><li id="9a2c" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated"><strong class="lb iu">用户定义函数(UDF)</strong>:有人可能会想，我们是否应该只依赖Pig Latin提供的一组有限的关键字/功能。用户定义函数是一个解决方案，它扩展了Apache Pig的功能。我们可以使用Java、Python、JavaScript或Ruby等语言编写函数，并在Pig脚本中使用它们。UDF支持定制处理的几乎所有部分，包括数据加载、存储、转换和聚集。</li><li id="086c" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated"><strong class="lb iu"> Tez模式</strong>:Apache Pig架构显示它在MapReduce之上增加了一些额外的步骤，使得Pig比MapReduce慢。作为一个解决方案，也可以在Apache Tez上执行Pig执行。这显著提高了阿帕奇猪的性能。这种性能提升是通过将Pig脚本转换成有向非循环图来实现的。如果pig脚本的性能是一个问题，那么在Tez上运行它是一个选择。你可以在这里找到更多关于阿帕奇技术开发中心的细节:【http://tez.apache.org/ T4】</li><li id="102b" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated"><strong class="lb iu">多查询执行</strong> : Pig具有一次处理整个脚本(一批语句)的能力。首先对整个脚本进行解析，以确定是否可以组合中间任务来减少需要完成的工作总量。这是实现性能优化的另一种方法。</li><li id="b3f6" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated"><strong class="lb iu">用户友好的诊断操作符</strong> : Pig Latin提供了一组诊断操作符，对测试和诊断脚本非常有帮助。描述、解释、转储和说明是支持的诊断运算符。它们有助于检查关系模式、显示结果和观察执行计划等任务。</li><li id="4fee" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated"><strong class="lb iu">支持结构化和非结构化数据</strong>:Pig基于指定分隔符加载和处理数据的方式有助于处理异构数据。</li></ol><p id="1540" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">了解了Apache Pig的功能，现在让我们看看它在现实世界中用于什么类型的任务。我们很清楚，优势来自于学习、开发和理解的便利性。因此，如果我们计划将Apache Pig集成到真实世界的大数据系统中，我们的目标应该是利用这一优势。可以使用阿帕奇猪，</p><ul class=""><li id="4681" class="nt nu it lb b lc ld lf lg li nv lm nw lq nx lu oh nz oa ob bi translated">探索大型数据集</li><li id="8c37" class="nt nu it lb b lc oc lf od li oe lm of lq og lu oh nz oa ob bi translated">对大型数据集运行即席查询以进行调试和探索</li><li id="b73d" class="nt nu it lb b lc oc lf od li oe lm of lq og lu oh nz oa ob bi translated">大型数据集的原型处理算法</li><li id="a4de" class="nt nu it lb b lc oc lf od li oe lm of lq og lu oh nz oa ob bi translated">加载和处理时间敏感数据集</li></ul><p id="8daa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我相信我通过这篇文章给了你足够的动力开始学习Apache Pig。它将始终为您的大数据工具集增值。那你为什么不现在就开始呢？</p></div></div>    
</body>
</html>