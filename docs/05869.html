<html>
<head>
<title>How To Implement Custom Regularization in TensorFlow(Keras)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在 TensorFlow(Keras)中实现自定义正则化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-implement-custom-regularization-in-tensorflow-keras-4e77be082918?source=collection_archive---------31-----------------------#2020-05-14">https://towardsdatascience.com/how-to-implement-custom-regularization-in-tensorflow-keras-4e77be082918?source=collection_archive---------31-----------------------#2020-05-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="af03" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">技术的</h2><div class=""/><div class=""><h2 id="7f55" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">了解如何使用 TensorFlow 和 Keras 相对轻松地实现自定义神经网络正则化技术。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/d0d83b55cd3d413dde71a0d2f158063f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HAewNEIXS4NbR8-ps2ltGw.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">萨法尔·萨法罗夫在<a class="ae lh" href="https://unsplash.com/s/photos/code?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="fc91" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">介绍</h1><p id="32de" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">本文介绍了神经网络中的正则化主题。它包括机器学习工程师和数据科学家如何实施定制正则化技术的细节。</p><p id="f05c" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated"><strong class="mc jd">正则化技术通过限制网络中权重值的范围来降低神经网络过拟合的可能性。</strong></p><p id="4f44" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">下面的文章介绍了传统的正则化技术以及它们是如何在 TensorFlow(Keras)中实现的。下面的参考文章是针对那些喜欢神经网络内正则化主题的深入概述的读者。</p><div class="nb nc gp gr nd ne"><a rel="noopener follow" target="_blank" href="/regularization-techniques-and-their-implementation-in-tensorflow-keras-c06e7551e709"><div class="nf ab fo"><div class="ng ab nh cl cj ni"><h2 class="bd jd gy z fp nj fr fs nk fu fw jc bi translated">TensorFlow(Keras)中的技术及其实现</h2><div class="nl l"><h3 class="bd b gy z fp nj fr fs nk fu fw dk translated">理解用于减轻深度神经网络中过拟合问题的传统技术。</h3></div><div class="nm l"><p class="bd b dl z fp nj fr fs nk fu fw dk translated">towardsdatascience.com</p></div></div><div class="nn l"><div class="no l np nq nr nn ns lb ne"/></div></div></a></div></div><div class="ab cl nt nu hx nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="im in io ip iq"><h1 id="eeb1" class="li lj it bd lk ll oa ln lo lp ob lr ls ki oc kj lu kl od km lw ko oe kp ly lz bi translated">实现自定义正则项</h1><p id="bc59" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">在我们继续之前，值得注意的是，在大多数情况下，您不需要实现您的自定义正则化技术。</p><p id="f1ac" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated"><em class="of">tensor flow、Keras 和 PyTorch 等流行的机器学习库内部实现了标准的正则化技术。</em></p><p id="6f6e" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">我将要实现的正则化技术是 L2 正则化技术。</p><p id="fd4d" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated"><strong class="mc jd"> L2 正则化惩罚权重值。对于较小的权重值和相对较大的权重值，L2 正则化将这些值转换为接近 0 但不完全 0 的数字。</strong></p><p id="4f1b" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">L2 惩罚权重的平方和，因此我们将在 python 函数中实现这个逻辑。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi og"><img src="../Images/974a10c6c27cc9b0290e847949ef17ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/0*GecztUIGeKFqZEIF.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">L2 正则化</p></figure><pre class="ks kt ku kv gt oh oi oj ok aw ol bi"><span id="53d9" class="om lj it oi b gy on oo l op oq">def custom_l2_regularizer(weights):<br/>    return tf.reduce_sum(0.02 * tf.square(weights))</span></pre><p id="5b86" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">上面的代码是我们自定义的 L2 正则化技术。</p><p id="5ef0" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">使用 TensorFlow 的数学运算，我们可以计算传入函数的权重的平方和。</p><ul class=""><li id="e390" class="or os it mc b md mw mg mx mj ot mn ou mr ov mv ow ox oy oz bi translated"><a class="ae lh" href="https://www.tensorflow.org/api_docs/python/tf/math/reduce_sum" rel="noopener ugc nofollow" target="_blank"> tf.reduce_sum </a>:数学运算，其结果是传递给函数的值的总和。</li><li id="9538" class="or os it mc b md pa mg pb mj pc mn pd mr pe mv ow ox oy oz bi translated"><a class="ae lh" href="https://www.tensorflow.org/api_docs/python/tf/math/square" rel="noopener ugc nofollow" target="_blank"> tf.square </a>:对其参数中的值进行平方的数学运算</li></ul><p id="d89d" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">这就是全部了。</p><p id="97f2" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">为了利用我们的自定义正则项，我们将其传递到神经网络层，如下所示:</p><pre class="ks kt ku kv gt oh oi oj ok aw ol bi"><span id="e8a2" class="om lj it oi b gy on oo l op oq">keras.layers.Dense(200, activation='relu', kernel_regularizer=custom_l2_regularizer),</span></pre><p id="fe22" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">Keas 神经网络层可以在其'<em class="of">kernel _ regulator</em>'参数内接受自定义函数。</p></div><div class="ab cl nt nu hx nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="im in io ip iq"><h1 id="1e4e" class="li lj it bd lk ll oa ln lo lp ob lr ls ki oc kj lu kl od km lw ko oe kp ly lz bi translated">把所有的放在一起</h1><p id="1465" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">为了了解所实现的自定义正则化技术的效果，我们将构建一个简单的神经网络，并执行图像分类这一简单任务。</p><p id="e942" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">这一节将包括执行一些常见神经网络实现任务的代码片段，并且 GitHub repo 链接也是可用的<a class="ae lh" href="https://github.com/RichmondAlake/tensorflow_2_tutorials/blob/master/14_custom_regularizer.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>包括本文中的所有代码。</p><p id="d394" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">为了实现我们的神经网络和加载数据集，我们将利用以下工具和库:Keras、TensorFlow 和 NumPy。</p><pre class="ks kt ku kv gt oh oi oj ok aw ol bi"><span id="4daf" class="om lj it oi b gy on oo l op oq">import tensorflow as tf<br/>from tensorflow import keras<br/>import numpy as np</span></pre><p id="19af" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">将数据集加载并划分到测试、验证和培训中。</p><p id="63cf" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">还需要将数据集中图像的像素强度从 0–255 到 0–1 的值范围进行归一化。</p><p id="75ac" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">数组'<em class="of"> class_names </em>'被初始化以保存数据集中图像所表示的服装的商品标签。</p><pre class="ks kt ku kv gt oh oi oj ok aw ol bi"><span id="7d29" class="om lj it oi b gy on oo l op oq">(train_images, train_labels),(test_images, test_labels) = keras.datasets.fashion_mnist.load_data()</span><span id="ee72" class="om lj it oi b gy pf oo l op oq">train_images = train_images / 255.0<br/>test_images = test_images / 255.0</span><span id="422e" class="om lj it oi b gy pf oo l op oq">validation_images = train_images[:5000]<br/>validation_labels = train_labels[:5000]</span><span id="4c5b" class="om lj it oi b gy pf oo l op oq">class_names = ["T-shirt/top", "Trouser", "Pullover", "Dress", "Coat", "Sandal", "Shirt", "Sneaker", "Bag", "Ankle boot"]</span></pre><p id="6a97" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">这里，我们按照前面的解释定义了自定义正则项。</p><pre class="ks kt ku kv gt oh oi oj ok aw ol bi"><span id="67b3" class="om lj it oi b gy on oo l op oq">def custom_l2_regularizer(weights):<br/>    return tf.reduce_sum(0.02 * tf.square(weights))</span></pre><p id="e3ba" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">下一步是实现我们的神经网络及其层。这里为每一层分配适当的参数，包括我们的自定义正则化。</p><pre class="ks kt ku kv gt oh oi oj ok aw ol bi"><span id="ff40" class="om lj it oi b gy on oo l op oq">model = keras.models.Sequential([<br/>    keras.layers.Flatten(input_shape=[28,28]),<br/>    keras.layers.Dense(200, activation='relu', kernel_regularizer=custom_l2_regularizer),<br/>    keras.layers.Dense(100, activation='relu', kernel_regularizer=custom_l2_regularizer),<br/>    keras.layers.Dense(50, activation='relu', kernel_regularizer=custom_l2_regularizer),<br/>    keras.layers.Dense(10, activation='softmax')<br/>])</span></pre><p id="e28b" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">为了确保我们的神经网络正确训练，我们利用随机梯度下降优化算法，并设置一些任意的超参数，如时期和学习率。</p><pre class="ks kt ku kv gt oh oi oj ok aw ol bi"><span id="e3ca" class="om lj it oi b gy on oo l op oq">sgd = keras.optimizers.SGD(lr=0.01)<br/>model.compile(loss="sparse_categorical_crossentropy", optimizer=sgd, metrics=["accuracy"])<br/>model.fit(train_images, train_labels, epochs=60, validation_data=(validation_images, validation_labels))</span></pre><p id="98e6" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">在训练之后，在测试数据集上对训练的模型进行评估。评估数据必须包含模型在训练期间没有遇到的数据。</p><pre class="ks kt ku kv gt oh oi oj ok aw ol bi"><span id="1af9" class="om lj it oi b gy on oo l op oq">model.evaluate(test_images, test_labels)</span></pre><p id="a10f" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">为了验证我们的模型的准确性，我们可以获取测试图像的子集，并运行推理来验证它们的结果。</p><pre class="ks kt ku kv gt oh oi oj ok aw ol bi"><span id="4812" class="om lj it oi b gy on oo l op oq">practical_test_images =  test_images[:10]<br/>predictions = model.predict_classes(practical_test_images)<br/>print(predictions)<br/>print(np.array(class_names)[predictions])</span></pre></div><div class="ab cl nt nu hx nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="im in io ip iq"><p id="a68f" class="pw-post-body-paragraph ma mb it mc b md mw kd mf mg mx kg mi mj my ml mm mn mz mp mq mr na mt mu mv im bi translated">使用 Keras 实现神经网络的定制组件(如正则化器)非常容易；您甚至可以更进一步，探索如何使用 Keras 实现定制指标、激活函数、损失函数以及更多功能。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pg"><img src="../Images/827824678152f2aedaf6b13b04d97c28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*49BfYLwFwC-6QZONtbCfzQ.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae lh" href="https://unsplash.com/@alx_andru?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Alex </a>在<a class="ae lh" href="https://unsplash.com/s/photos/end?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><h1 id="41f0" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">我希望这篇文章对你有用。</h1><p id="1d2f" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">要联系我或找到更多类似本文的内容，请执行以下操作:</p><ol class=""><li id="ee50" class="or os it mc b md mw mg mx mj ot mn ou mr ov mv ph ox oy oz bi translated">订阅我的<a class="ae lh" href="https://www.youtube.com/channel/UCNNYpuGCrihz_YsEpZjo8TA" rel="noopener ugc nofollow" target="_blank"> <strong class="mc jd"> YouTube 频道</strong> </a>即将发布的视频内容<a class="ae lh" href="https://www.youtube.com/channel/UCNNYpuGCrihz_YsEpZjo8TA" rel="noopener ugc nofollow" target="_blank"> <strong class="mc jd">这里</strong> </a></li><li id="7a70" class="or os it mc b md pa mg pb mj pc mn pd mr pe mv ph ox oy oz bi translated">跟我上<a class="ae lh" href="https://medium.com/@richmond.alake" rel="noopener"> <strong class="mc jd">中</strong> </a></li><li id="a1d1" class="or os it mc b md pa mg pb mj pc mn pd mr pe mv ph ox oy oz bi translated">通过<a class="ae lh" href="https://www.linkedin.com/in/richmondalake/" rel="noopener ugc nofollow" target="_blank"> <strong class="mc jd"> LinkedIn </strong> </a>联系我</li></ol></div></div>    
</body>
</html>