<html>
<head>
<title>A Gentle Introduction to Self-Training and Semi-Supervised Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自我训练和半监督学习简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-gentle-introduction-to-self-training-and-semi-supervised-learning-ceee73178b38?source=collection_archive---------1-----------------------#2020-08-30">https://towardsdatascience.com/a-gentle-introduction-to-self-training-and-semi-supervised-learning-ceee73178b38?source=collection_archive---------1-----------------------#2020-08-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5476" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用 Python 编写一个利用未标记数据进行分类的自我训练示例</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/0503dd29b81095c8ee5a37e98ae93812.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*TGqGovL9LpPCCXql"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@jennyhill?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">珍妮·希尔</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="c249" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">当涉及到机器学习分类任务时，可用于训练算法的数据越多越好。在监督学习中，这些数据必须根据目标类进行标记，否则，这些算法将无法学习自变量和目标变量之间的关系。但是，在构建用于分类的大型标记数据集时，会出现一些问题:</p><ol class=""><li id="9516" class="mc md it li b lj lk lm ln lp me lt mf lx mg mb mh mi mj mk bi translated"><strong class="li iu">标注数据可能非常耗时。</strong>假设我们有 1，000，000 张狗的图像要输入到一个分类算法中，目标是预测每张图像中是否包含一只波士顿梗。如果我们想将所有这些图像用于监督分类任务，我们需要一个人来查看每张图像，并确定是否存在波士顿梗。虽然我有朋友(和妻子)不介意整天浏览狗狗照片，但这可能不是我们大多数人想要的周末。</li><li id="aa17" class="mc md it li b lj ml lm mm lp mn lt mo lx mp mb mh mi mj mk bi translated"><strong class="li iu">标注数据可能会很贵。请看原因 1:为了让某人费力地搜索 100 万张狗的照片，我们可能不得不支付一些现金。</strong></li></ol><p id="edf6" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">那么，如果我们只有足够的时间和金钱来标记大型数据集的某些部分，而选择不标记其余部分，会怎么样呢？这种未标记的数据可以用在分类算法中吗？</p><p id="721d" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这就是<strong class="li iu">半监督学习</strong>的用武之地。在采用半监督方法时，我们可以在少量标记数据上训练分类器，然后使用分类器对未标记数据进行预测。因为这些预测可能比随机猜测更好，所以未标记的数据预测可以在分类器的后续迭代中被用作“伪标记”。虽然半监督学习有很多种风格，但这种特定的技术被称为<strong class="li iu">自我训练</strong>。</p><h2 id="080d" class="mr ms it bd mt mu mv dn mw mx my dp mz lp na nb nc lt nd ne nf lx ng nh ni nj bi translated">自我训练</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/2282249ccfc002158780fc89c0b9c300.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nX3rSUkS_pPQD33doWuPrw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">自我训练</p></figure><p id="ff17" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在概念层面上，自我训练是这样的:</p><p id="13eb" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">步骤 1: </strong>将标记的数据实例分割成训练集和测试集。然后，在标记的训练数据上训练分类算法。</p><p id="1e22" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">步骤 2: </strong>使用训练好的分类器来预测所有未标记数据实例的类别标签。在这些预测的类别标签中，正确概率最高的被采用作为'<strong class="li iu">伪标签'</strong>。</p><p id="fb34" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><em class="mq">(步骤 2 的几个变体:</em> <strong class="li iu"> <em class="mq"> a) </em> </strong> <em class="mq">所有预测的标签可以一次被采用为‘伪标签’，而不考虑概率，或者</em> <strong class="li iu"> <em class="mq"> b) </em> </strong> <em class="mq">【伪标签】数据可以通过预测的置信度来加权。)</em></p><p id="d849" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">步骤 3: </strong>将“伪标记的”数据与标记的训练数据连接起来。在组合的“伪标记”和标记的训练数据上重新训练分类器。</p><p id="55fc" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">步骤 4: </strong>使用训练好的分类器来预测标记的测试数据实例的类别标签。使用您选择的度量评估分类器性能。</p><p id="cf78" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><em class="mq">(可以重复步骤 1 至 4，直到步骤 2 中不再有预测的类别标签满足特定的概率阈值，或者直到不再有未标记的数据剩余。)</em></p><p id="3a8d" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">好的，明白了吗？很好！让我们看一个例子。</p><h2 id="7540" class="mr ms it bd mt mu mv dn mw mx my dp mz lp na nb nc lt nd ne nf lx ng nh ni nj bi translated">示例:使用自我训练来改进分类器</h2><p id="db66" class="pw-post-body-paragraph lg lh it li b lj nl ju ll lm nm jx lo lp nn lr ls lt no lv lw lx np lz ma mb im bi translated">为了演示自我训练，我使用了 Python 和<strong class="li iu"> surgical_deepnet </strong>数据集，可从 Kaggle 上的<a class="ae ky" href="https://www.kaggle.com/omnamahshivai/surgical-dataset-binary-classification" rel="noopener ugc nofollow" target="_blank">这里</a>获得。该数据集旨在用于二元分类，包含 14.6k+手术的数据。这些属性是 bmi、年龄和各种其他指标，而目标变量<strong class="li iu">并发症</strong>记录了患者是否因手术而出现并发症。显然，能够准确预测患者是否会遭受手术并发症，将符合医疗保健和保险提供商的最大利益。</p><p id="1969" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">进口</strong></p><p id="3b71" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">对于本教程，我导入了<strong class="li iu"> numpy </strong>、<strong class="li iu"> pandas </strong>和<strong class="li iu"> matplotlib </strong>。我还将使用来自<strong class="li iu"> sklearn </strong>的<strong class="li iu"> LogisticRegression </strong>分类器，以及<strong class="li iu"> f1_score </strong>和<strong class="li iu"> plot_confusion_matrix </strong>函数进行模型评估。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="b9a1" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">加载数据</strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq nr l"/></div></figure><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="fb04" class="mr ms it nt b gy nx ny l nz oa">&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 14635 entries, 0 to 14634<br/>Data columns (total 25 columns):<br/>bmi                    14635 non-null float64<br/>Age                    14635 non-null float64<br/>asa_status             14635 non-null int64<br/>baseline_cancer        14635 non-null int64<br/>baseline_charlson      14635 non-null int64<br/>baseline_cvd           14635 non-null int64<br/>baseline_dementia      14635 non-null int64<br/>baseline_diabetes      14635 non-null int64<br/>baseline_digestive     14635 non-null int64<br/>baseline_osteoart      14635 non-null int64<br/>baseline_psych         14635 non-null int64<br/>baseline_pulmonary     14635 non-null int64<br/>ahrq_ccs               14635 non-null int64<br/>ccsComplicationRate    14635 non-null float64<br/>ccsMort30Rate          14635 non-null float64<br/>complication_rsi       14635 non-null float64<br/>dow                    14635 non-null int64<br/>gender                 14635 non-null int64<br/>hour                   14635 non-null float64<br/>month                  14635 non-null int64<br/>moonphase              14635 non-null int64<br/>mort30                 14635 non-null int64<br/>mortality_rsi          14635 non-null float64<br/>race                   14635 non-null int64<br/>complication           14635 non-null int64<br/>dtypes: float64(7), int64(18)<br/>memory usage: 2.8 MB</span></pre><p id="72bc" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">数据集中的属性都是数值型的，没有缺失值。因为我在这里的重点不是数据清理，所以我将继续对数据进行分区。</p><p id="049f" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">数据分割</strong></p><p id="2586" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">为了试验自我训练，我需要将数据分成三部分:一个<strong class="li iu">训练集</strong>，一个<strong class="li iu">测试集</strong>，和一个<strong class="li iu">未标记集</strong>。我将按照以下比例分割数据:</p><p id="477a" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">1%列车(贴有标签)</p><p id="e5a5" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">25%测试(贴有标签)</p><p id="ac3e" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">74%未标注</p><p id="e195" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">对于未标记的集合，我将简单地删除目标变量<strong class="li iu">complexity</strong>，并假装它从未存在过。因此，在这种情况下，我们假设 74%的手术病例没有关于并发症的信息。我这样做是为了模拟这样一个事实，即在现实世界的分类问题中，许多可用的数据可能没有类标签。然而，如果我们<em class="mq">确实</em>有一小部分数据的类别标签(在这种情况下是 1%)，那么半监督学习技术就可以用来从未标签数据中得出结论。</p><p id="c3dc" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">下面，我重组数据，生成索引来划分数据，然后创建测试、训练和未标记的分割。然后我检查裂缝的尺寸，以确保一切按计划进行。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq nr l"/></div></figure><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="fccb" class="mr ms it nt b gy nx ny l nz oa">X_train dimensions: (146, 24)<br/>y_train dimensions: (146,)<br/><br/>X_test dimensions: (3659, 24)<br/>y_test dimensions: (3659,)<br/><br/>X_unlabeled dimensions: (10830, 24)</span></pre><p id="b812" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">班级分布</strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq nr l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/69210c4c9ce5ad43b9fd4b14abdde59f.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*XR2bxySrFqP0E8Iex6uqKQ.png"/></div></figure><p id="a394" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">多数阶级(不复杂)的实例是少数阶级(复杂)的两倍多。在这种不平衡的分类情况下，我想对我选择的分类评估标准非常挑剔— <strong class="li iu">准确性</strong>可能不是最好的选择。</p><p id="632c" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我选择<strong class="li iu"> F1 得分</strong>作为分类度量来判断分类器的有效性。F1 分数<strong class="li iu"> </strong>对类别不平衡的鲁棒性大于准确性，这在类别大致平衡时更合适。F1 分数可以计算如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/7a550560e5f5193c5327a580c250dba8.png" data-original-src="https://miro.medium.com/v2/resize:fit:418/format:webp/0*_eqeVdTcAPqYWnM9.png"/></div></figure><p id="92ba" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">其中<strong class="li iu">精度</strong>是被正确预测的<em class="mq">预测</em>阳性实例的比例，而<strong class="li iu">召回</strong>是被正确预测的<em class="mq">真</em>阳性实例的比例。</p><p id="cfd3" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">初始分类器(监督)</strong></p><p id="92d0" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">为了实地验证半监督学习的结果，我首先只使用标记的训练数据训练一个简单的逻辑回归分类器，并在测试数据集上进行预测。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq nr l"/></div></figure><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="c16e" class="mr ms it nt b gy nx ny l nz oa">Train f1 Score: 0.5846153846153846<br/>Test f1 Score: 0.5002908667830134</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/7665a0eb7f4fa0bad4f5a055a15e2e2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*cZinObh1Sk_YGX4GCokZOQ.png"/></div></figure><p id="e6b6" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">分类器的测试 F1 值为 0.5。混淆矩阵告诉我们，分类器可以非常准确地预测没有并发症的手术，准确率为 86%。然而，分类器更难正确识别有并发症的手术，准确率只有 47%。</p><p id="cf10" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">预测概率</strong></p><p id="b2af" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">对于自训练算法，我们想知道逻辑回归分类器做出预测的概率。幸运的是，<strong class="li iu"> sklearn </strong>提供了<strong class="li iu">。predict_proba() </strong>方法，它允许我们查看属于任一类的预测的概率。如下所示，在二元分类问题中，每个预测的总概率总和为 1.0。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq nr l"/></div></figure><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="25a6" class="mr ms it nt b gy nx ny l nz oa">array([[0.93931367, 0.06068633],<br/>       [0.2327203 , 0.7672797 ],<br/>       [0.93931367, 0.06068633],<br/>       ...,<br/>       [0.61940353, 0.38059647],<br/>       [0.41240068, 0.58759932],<br/>       [0.24306008, 0.75693992]])</span></pre><p id="a8fa" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">自训练分类器(半监督)</strong></p><p id="4d44" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">现在我们知道了如何使用<strong class="li iu"> sklearn </strong>获得预测概率，我们可以继续编码自我训练分类器。以下是一个简要的概述:</p><p id="2e85" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">第一步</strong>:首先，在标注的训练数据上训练一个逻辑回归分类器。</p><p id="2023" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">步骤 2 </strong>:接下来，使用分类器预测所有未标记数据的标签，以及这些预测的概率。在这种情况下，我只会对概率大于 99%的预测采用‘伪标签’。</p><p id="bd76" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">步骤 3 </strong>:将“伪标记”数据与标记训练数据连接，并在连接的数据上重新训练分类器。</p><p id="02fb" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">第四步</strong>:使用训练好的分类器对标注的测试数据进行预测，并对分类器进行评估。</p><p id="b843" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">重复第 1 步到第 4 步，直到没有任何预测的概率大于 99%，或者没有未标记的数据。</p><p id="872a" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">参见下面的代码，我用 Python 实现了这些步骤，使用了一个 while 循环。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq nr l"/></div></figure><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="0108" class="mr ms it nt b gy nx ny l nz oa">Iteration 0<br/>Train f1: 0.5846153846153846<br/>Test f1: 0.5002908667830134<br/>Now predicting labels for unlabeled data...<br/>42 high-probability predictions added to training data.<br/>10788 unlabeled instances remaining.<br/><br/>Iteration 1<br/>Train f1: 0.7627118644067796<br/>Test f1: 0.5037463976945246<br/>Now predicting labels for unlabeled data...<br/>30 high-probability predictions added to training data.<br/>10758 unlabeled instances remaining.<br/><br/>Iteration 2<br/>Train f1: 0.8181818181818182<br/>Test f1: 0.505431675242996<br/>Now predicting labels for unlabeled data...<br/>20 high-probability predictions added to training data.<br/>10738 unlabeled instances remaining.<br/><br/>Iteration 3<br/>Train f1: 0.847457627118644<br/>Test f1: 0.5076835515082526<br/>Now predicting labels for unlabeled data...<br/>21 high-probability predictions added to training data.<br/>10717 unlabeled instances remaining.<br/><br/>...</span><span id="0d1f" class="mr ms it nt b gy oe ny l nz oa">Iteration 44<br/>Train f1: 0.9481216457960644<br/>Test f1: 0.5259179265658748<br/>Now predicting labels for unlabeled data...<br/>0 high-probability predictions added to training data.<br/>10079 unlabeled instances remaining.</span></pre><p id="62a7" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">自我训练算法经历了 44 次迭代之后，才能够以&gt; 99%的概率预测到更多的未标记实例。尽管最初有 10，830 个未标记的实例，但其中 10，079 个在自我训练后仍未标记(且未被分类器使用)。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq nr l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/97c2a8dd4522ad40c902c78be22cf362.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*wbcYLJRKAqxgMDtn_VQWKg.png"/></div></figure><p id="4b28" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">经过 44 次迭代，F1 分数从 0.50 提高到 0.525！虽然这只是一个很小的增加，但看起来自我训练已经提高了分类器在测试数据集上的性能。上图的顶部显示，这种改进大部分发生在算法的早期迭代中。类似地，底部面板显示了添加到训练数据中的大多数“伪标签”出现在最初的 20-30 次迭代中。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/4b130cca9c295b3c441365692bb21576.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*OmaY38K7cDZ4ojKskwc4Zw.png"/></div></figure><p id="09cc" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">最终混淆矩阵显示有并发症的手术<em class="mq">的分类有所改善，但无<em class="mq">并发症的手术</em>的分类略有下降。在 F1 评分提高的支持下，我认为这是一个可接受的改进——识别将导致并发症的手术病例(真阳性)可能更重要，为了达到这一结果，可能值得增加假阳性率。</em></p><p id="822a" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">注意事项</strong></p><p id="47e5" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">所以你可能在想:用这么多未标记的数据进行自我训练有风险吗？答案当然是肯定的。请记住，尽管我们将“伪标签”数据与带标签的训练数据包含在一起，但某些“伪标签”数据肯定是不正确的。当足够多的“伪标签”是不正确的时，自训练算法可以加强差的分类决策，并且分类器性能实际上可以变得更差。</p><p id="a93d" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">然而，这种风险可以通过遵循既定的实践来减轻，如使用分类器在训练期间未见过的测试数据集，或使用“伪标签”预测的概率阈值。</p></div></div>    
</body>
</html>