<html>
<head>
<title>XGBoost and Imbalanced Classes: Predicting Hotel Cancellations</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">XGBoost 和不平衡类:预测酒店取消</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/boosting-techniques-in-python-predicting-hotel-cancellations-62b7a76ffa6c?source=collection_archive---------5-----------------------#2020-02-05">https://towardsdatascience.com/boosting-techniques-in-python-predicting-hotel-cancellations-62b7a76ffa6c?source=collection_archive---------5-----------------------#2020-02-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6e0f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Boosting 是机器学习中一种非常流行的技术，旨在通过将许多弱模型组合成一个强模型来提高预测精度。</h2></div><p id="4069" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为此，增强被称为<strong class="kk iu">集成方法</strong>。</p><p id="79b2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这个例子中，boosting 技术用于确定客户是否会取消他们的酒店预订。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/7e56b53778587467acae5fc6997075d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QY6ATJeT1zKZ1SRtVgNgwQ.png"/></div></div></figure><h1 id="2c37" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">数据概述和功能选择</h1><p id="c7e0" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mk kt ku kv ml kx ky kz mm lb lc ld im bi translated">训练数据从 AWS S3 时段导入，如下所示:</p><pre class="lf lg lh li gt mn mo mp mq aw mr bi"><span id="4f44" class="ms lr it mo b gy mt mu l mv mw">import boto3<br/>import botocore<br/>import pandas as pd<br/>from sagemaker import get_execution_role</span><span id="6c0b" class="ms lr it mo b gy mx mu l mv mw">role = get_execution_role()</span><span id="f272" class="ms lr it mo b gy mx mu l mv mw">bucket = 'yourbucketname'<br/>data_key_train = 'H1full.csv'<br/>data_location_train = 's3://{}/{}'.format(bucket, data_key_train)</span><span id="cddb" class="ms lr it mo b gy mx mu l mv mw">train_df = pd.read_csv(data_location_train)</span></pre><p id="79a6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">酒店取消表示响应(或相关)变量，其中 1 =取消，0 =继续预订。</p><p id="b95f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">用于分析的特征如下。</p><h1 id="52eb" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">间隔</h1><pre class="lf lg lh li gt mn mo mp mq aw mr bi"><span id="d3ac" class="ms lr it mo b gy mt mu l mv mw">leadtime = train_df['LeadTime']<br/>arrivaldateyear = train_df['ArrivalDateYear']<br/>arrivaldateweekno = train_df['ArrivalDateWeekNumber']<br/>arrivaldatedayofmonth = train_df['ArrivalDateDayOfMonth']<br/>staysweekendnights = train_df['StaysInWeekendNights']<br/>staysweeknights = train_df['StaysInWeekNights']<br/>adults = train_df['Adults']<br/>children = train_df['Children']<br/>babies = train_df['Babies']<br/>isrepeatedguest = train_df['IsRepeatedGuest'] <br/>previouscancellations = train_df['PreviousCancellations']<br/>previousbookingsnotcanceled = train_df['PreviousBookingsNotCanceled']<br/>bookingchanges = train_df['BookingChanges']<br/>agent = train_df['Agent']<br/>company = train_df['Company']<br/>dayswaitinglist = train_df['DaysInWaitingList']<br/>adr = train_df['ADR']<br/>rcps = train_df['RequiredCarParkingSpaces']<br/>totalsqr = train_df['TotalOfSpecialRequests']</span></pre><h1 id="500b" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">绝对的</h1><pre class="lf lg lh li gt mn mo mp mq aw mr bi"><span id="23e9" class="ms lr it mo b gy mt mu l mv mw">arrivaldatemonth = train_df.ArrivalDateMonth.astype("category").cat.codes<br/>arrivaldatemonthcat=pd.Series(arrivaldatemonth)<br/>mealcat=train_df.Meal.astype("category").cat.codes<br/>mealcat=pd.Series(mealcat)<br/>countrycat=train_df.Country.astype("category").cat.codes<br/>countrycat=pd.Series(countrycat)<br/>marketsegmentcat=train_df.MarketSegment.astype("category").cat.codes<br/>marketsegmentcat=pd.Series(marketsegmentcat)<br/>distributionchannelcat=train_df.DistributionChannel.astype("category").cat.codes<br/>distributionchannelcat=pd.Series(distributionchannelcat)<br/>reservedroomtypecat=train_df.ReservedRoomType.astype("category").cat.codes<br/>reservedroomtypecat=pd.Series(reservedroomtypecat)<br/>assignedroomtypecat=train_df.AssignedRoomType.astype("category").cat.codes<br/>assignedroomtypecat=pd.Series(assignedroomtypecat)<br/>deposittypecat=train_df.DepositType.astype("category").cat.codes<br/>deposittypecat=pd.Series(deposittypecat)<br/>customertypecat=train_df.CustomerType.astype("category").cat.codes<br/>customertypecat=pd.Series(customertypecat)<br/>reservationstatuscat=train_df.ReservationStatus.astype("category").cat.codes<br/>reservationstatuscat=pd.Series(reservationstatuscat)</span></pre><p id="fd19" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用<strong class="kk iu">树外分类器</strong>和<strong class="kk iu">前向和后向特征选择</strong>方法进行分析时，确定的特征如下:</p><ul class=""><li id="2941" class="my mz it kk b kl km ko kp kr na kv nb kz nc ld nd ne nf ng bi translated">研制周期</li><li id="ccb1" class="my mz it kk b kl nh ko ni kr nj kv nk kz nl ld nd ne nf ng bi translated">原产国</li><li id="60d8" class="my mz it kk b kl nh ko ni kr nj kv nk kz nl ld nd ne nf ng bi translated">细分市场</li><li id="94b3" class="my mz it kk b kl nh ko ni kr nj kv nk kz nl ld nd ne nf ng bi translated">存款类型</li><li id="c8de" class="my mz it kk b kl nh ko ni kr nj kv nk kz nl ld nd ne nf ng bi translated">客户类型</li><li id="f652" class="my mz it kk b kl nh ko ni kr nj kv nk kz nl ld nd ne nf ng bi translated">所需的停车位</li><li id="7c09" class="my mz it kk b kl nh ko ni kr nj kv nk kz nl ld nd ne nf ng bi translated">到达日期:年</li><li id="d154" class="my mz it kk b kl nh ko ni kr nj kv nk kz nl ld nd ne nf ng bi translated">抵达日期:月</li><li id="b4fc" class="my mz it kk b kl nh ko ni kr nj kv nk kz nl ld nd ne nf ng bi translated">到达日期:周数</li><li id="e583" class="my mz it kk b kl nh ko ni kr nj kv nk kz nl ld nd ne nf ng bi translated">到达日期:当月的某一天</li></ul><h1 id="b7dc" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">助推技术</h1><p id="fac9" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mk kt ku kv ml kx ky kz mm lb lc ld im bi translated">XGBoost 是一种提升技术，因其执行速度和模型性能而闻名，并越来越多地被作为默认的提升方法，这种方法实现了梯度提升决策树算法，其工作方式类似于自适应提升，但实例权重不再像 AdaBoost 那样在每次迭代时调整。取而代之的是，尝试用新的预测器来拟合前一个预测器产生的残差。</p><h1 id="65dc" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">精确度与召回率和 f1 分数</h1><p id="f754" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mk kt ku kv ml kx ky kz mm lb lc ld im bi translated">当比较准确度分数时，我们看到在每个混淆矩阵中都提供了大量的读数。</p><p id="cb1c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，在<strong class="kk iu">精度</strong>和<strong class="kk iu">召回</strong>之间存在一个特别重要的区别。</p><pre class="lf lg lh li gt mn mo mp mq aw mr bi"><span id="4907" class="ms lr it mo b gy mt mu l mv mw">Precision = ((True Positive)/(True Positive + False Positive))</span><span id="c8ef" class="ms lr it mo b gy mx mu l mv mw">Recall = ((True Positive)/(True Positive + False Negative))</span></pre><p id="4276" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这两个读数经常相互矛盾，也就是说，通常不可能在不降低召回率的情况下提高精确度，反之亦然。</p><p id="b142" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对理想指标的评估很大程度上取决于所分析的具体数据。例如，癌症检测筛查出现假阴性(即表明患者没有患癌症，而事实上他们患有癌症)是一大禁忌。在这种情况下，召回是理想的衡量标准。</p><p id="682b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，对于电子邮件，人们可能更喜欢避免误报，例如，将一封重要的电子邮件发送到垃圾邮件文件夹，而实际上它是合法的。</p><p id="af91" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">f1 分数在设计一个更通用的分数时考虑了精确度和召回率。</p><p id="5d44" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">哪个因素对预测酒店取消更重要？</p><p id="e8b1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从酒店的角度来看，他们可能希望更准确地识别出最终会取消预订的客户，这使得酒店能够更好地分配房间和资源。确定不打算取消预订的客户不一定会增加酒店分析的价值，因为酒店知道，无论如何，很大一部分客户最终都会坚持预订。</p><h1 id="c313" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">分析</h1><p id="21f8" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mk kt ku kv ml kx ky kz mm lb lc ld im bi translated">该数据首先被分为 H1 数据集的训练和验证数据，H2 数据集被用作比较 XGBoost 预测与实际取消发生率的测试集。</p><p id="5610" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是 XGBoost 算法的实现:</p><pre class="lf lg lh li gt mn mo mp mq aw mr bi"><span id="a22e" class="ms lr it mo b gy mt mu l mv mw">import xgboost as xgb<br/>xgb_model = xgb.XGBClassifier(learning_rate=0.001,<br/>                            max_depth = 1, <br/>                            n_estimators = 100,<br/>                              scale_pos_weight=5)<br/>xgb_model.fit(x_train, y_train)</span></pre><p id="03c1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意，本例中的<em class="nm"> scale_pos_weight </em>参数设置为<em class="nm"> 5 </em>。这样做的原因是对次要类别的错误施加更大的惩罚，在这种情况下，响应变量中的任何<em class="nm"> 1 </em>事件，即酒店取消。权重越高，对次要类上的错误施加的惩罚就越大。这样做的原因是因为数据集中 0 比 1 多，也就是说，坚持预订的客户比取消预订的客户多。</p><p id="a237" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，为了有一个无偏见的模型，次要类上的错误需要受到更严厉的惩罚。</p><h1 id="b2bb" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">验证集性能</h1><p id="26e0" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mk kt ku kv ml kx ky kz mm lb lc ld im bi translated">以下是训练和验证集的准确性:</p><pre class="lf lg lh li gt mn mo mp mq aw mr bi"><span id="993a" class="ms lr it mo b gy mt mu l mv mw">&gt;&gt;&gt; print("Accuracy on training set: {:.3f}".format(xgb_model.score(x_train, y_train)))<br/>&gt;&gt;&gt; print("Accuracy on validation set: {:.3f}".format(xgb_model.score(x_val, y_val)))</span><span id="cb56" class="ms lr it mo b gy mx mu l mv mw">Accuracy on training set: 0.415<br/>Accuracy on validation set: 0.414</span></pre><p id="54f6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">预测是这样生成的:</p><pre class="lf lg lh li gt mn mo mp mq aw mr bi"><span id="1d2a" class="ms lr it mo b gy mt mu l mv mw">&gt;&gt;&gt; xgb_predict=xgb_model.predict(x_val)<br/>&gt;&gt;&gt; xgb_predict</span><span id="2f9c" class="ms lr it mo b gy mx mu l mv mw">array([1, 1, 1, ..., 1, 1, 1])</span></pre><p id="dcba" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面是一个混淆矩阵，比较了验证集上的预测取消和实际取消:</p><pre class="lf lg lh li gt mn mo mp mq aw mr bi"><span id="8751" class="ms lr it mo b gy mt mu l mv mw">&gt;&gt;&gt; from sklearn.metrics import classification_report,confusion_matrix<br/>&gt;&gt;&gt; print(confusion_matrix(y_val,xgb_predict))<br/>&gt;&gt;&gt; print(classification_report(y_val,xgb_predict))</span><span id="d1dc" class="ms lr it mo b gy mx mu l mv mw">[[1393 5873]<br/> [   0 2749]]<br/>              precision    recall  f1-score   support</span><span id="4577" class="ms lr it mo b gy mx mu l mv mw">           0       1.00      0.19      0.32      7266<br/>           1       0.32      1.00      0.48      2749</span><span id="b509" class="ms lr it mo b gy mx mu l mv mw">    accuracy                           0.41     10015<br/>   macro avg       0.66      0.60      0.40     10015<br/>weighted avg       0.81      0.41      0.37     10015</span></pre><p id="7cbe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意，虽然 f1 分数(41%)的准确性很低，但类别 1(取消)的召回分数是 100%。这意味着该模型会产生许多误报，从而降低整体准确性，但这具有将召回率提高到 100%的效果，即该模型可以 100%成功识别所有将取消预订的客户，即使这会导致一些误报。</p><h1 id="885f" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">测试集上的性能</h1><p id="c8d9" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mk kt ku kv ml kx ky kz mm lb lc ld im bi translated">和前面一样，测试集也是从相关的 S3 存储桶导入的:</p><pre class="lf lg lh li gt mn mo mp mq aw mr bi"><span id="090a" class="ms lr it mo b gy mt mu l mv mw">data_key_test = 'H2full.csv'<br/>data_location_test = 's3://{}/{}'.format(bucket, data_key_test)</span><span id="fedd" class="ms lr it mo b gy mx mu l mv mw">h2data = pd.read_csv(data_location_test)</span></pre><p id="ada4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是 XGBoost 模型在 H2 上的后续分类性能，这是本例中的测试集。</p><pre class="lf lg lh li gt mn mo mp mq aw mr bi"><span id="cf23" class="ms lr it mo b gy mt mu l mv mw">&gt;&gt;&gt; from sklearn.metrics import classification_report,confusion_matrix<br/>&gt;&gt;&gt; print(confusion_matrix(b,prh2))<br/>&gt;&gt;&gt; print(classification_report(b,prh2))</span><span id="0a3b" class="ms lr it mo b gy mx mu l mv mw">[[ 1926 44302]<br/> [    0 33102]]<br/>              precision    recall  f1-score   support</span><span id="306b" class="ms lr it mo b gy mx mu l mv mw">           0       1.00      0.04      0.08     46228<br/>           1       0.43      1.00      0.60     33102</span><span id="8f4b" class="ms lr it mo b gy mx mu l mv mw">    accuracy                           0.44     79330<br/>   macro avg       0.71      0.52      0.34     79330<br/>weighted avg       0.76      0.44      0.30     79330</span></pre><p id="c16c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">f1 分数所指示的准确度稍高，为 44%，但是类别 1 的回忆准确度再次为 100%。</p><h1 id="647d" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">校准:磅秤位置重量</h1><p id="3e4c" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mk kt ku kv ml kx ky kz mm lb lc ld im bi translated">在这种情况下，观察到使用 5 的<em class="nm"> scale_pos_weight </em>导致 100%的召回，同时将 f1 分数准确度非常显著地降低到 44%。</p><p id="7a7f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，100%的召回也是不可靠的。例如，假设<em class="nm"> scale_pos_weight </em>被设置得更高，这意味着几乎所有的预测都表示响应为 1，即所有的客户都被预测取消预订。</p><p id="a1b5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果预测所有客户都将取消预订，则该模型没有内在价值，因为不再有任何方法来识别可能会取消预订的客户与不会取消预订的客户的独特属性。</p><p id="4dc8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这方面，更平衡的解决方案是具有高召回率，同时还确保整体准确度不会降得过低。</p><p id="c506" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是分别使用<em class="nm"> 2 </em>、<em class="nm"> 3 </em>、<em class="nm"> 4 </em>和<em class="nm"> 5 </em>的权重时的混淆矩阵结果。</p><h2 id="7450" class="ms lr it bd ls nn no dn lw np nq dp ma kr nr ns mc kv nt nu me kz nv nw mg nx bi translated">秤重= 2</h2><pre class="lf lg lh li gt mn mo mp mq aw mr bi"><span id="080a" class="ms lr it mo b gy mt mu l mv mw">[[36926  9302]<br/> [12484 20618]]<br/>              precision    recall  f1-score   support</span><span id="243b" class="ms lr it mo b gy mx mu l mv mw">           0       0.75      0.80      0.77     46228<br/>           1       0.69      0.62      0.65     33102</span><span id="4224" class="ms lr it mo b gy mx mu l mv mw">    accuracy                           0.73     79330<br/>   macro avg       0.72      0.71      0.71     79330<br/>weighted avg       0.72      0.73      0.72     79330</span></pre><h2 id="86ce" class="ms lr it bd ls nn no dn lw np nq dp ma kr nr ns mc kv nt nu me kz nv nw mg nx bi translated">秤重= 3</h2><pre class="lf lg lh li gt mn mo mp mq aw mr bi"><span id="158d" class="ms lr it mo b gy mt mu l mv mw">[[12650 33578]<br/> [ 1972 31130]]<br/>              precision    recall  f1-score   support</span><span id="364b" class="ms lr it mo b gy mx mu l mv mw">           0       0.87      0.27      0.42     46228<br/>           1       0.48      0.94      0.64     33102</span><span id="8127" class="ms lr it mo b gy mx mu l mv mw">    accuracy                           0.55     79330<br/>   macro avg       0.67      0.61      0.53     79330<br/>weighted avg       0.70      0.55      0.51     79330</span></pre><h2 id="09f3" class="ms lr it bd ls nn no dn lw np nq dp ma kr nr ns mc kv nt nu me kz nv nw mg nx bi translated">秤重= 4</h2><pre class="lf lg lh li gt mn mo mp mq aw mr bi"><span id="3718" class="ms lr it mo b gy mt mu l mv mw">[[ 1926 44302]<br/> [    0 33102]]<br/>              precision    recall  f1-score   support</span><span id="cd35" class="ms lr it mo b gy mx mu l mv mw">           0       1.00      0.04      0.08     46228<br/>           1       0.43      1.00      0.60     33102</span><span id="55fb" class="ms lr it mo b gy mx mu l mv mw">    accuracy                           0.44     79330<br/>   macro avg       0.71      0.52      0.34     79330<br/>weighted avg       0.76      0.44      0.30     79330</span></pre><h2 id="db8f" class="ms lr it bd ls nn no dn lw np nq dp ma kr nr ns mc kv nt nu me kz nv nw mg nx bi translated">秤重= 5</h2><pre class="lf lg lh li gt mn mo mp mq aw mr bi"><span id="ec6a" class="ms lr it mo b gy mt mu l mv mw">[[ 1926 44302]<br/> [    0 33102]]<br/>              precision    recall  f1-score   support</span><span id="e6a1" class="ms lr it mo b gy mx mu l mv mw">           0       1.00      0.04      0.08     46228<br/>           1       0.43      1.00      0.60     33102</span><span id="44bb" class="ms lr it mo b gy mx mu l mv mw">    accuracy                           0.44     79330<br/>   macro avg       0.71      0.52      0.34     79330<br/>weighted avg       0.76      0.44      0.30     79330</span></pre><p id="6d06" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当<em class="nm"> scale_pos_weight </em>设置为 3 时，召回率为 94%，而准确率为 55%。当<em class="nm"> scale_pos_weight </em>参数设置为 5 时，召回率为 100%,而 f1 得分准确率降至 44%。此外，请注意，将参数从<em class="nm"> 4 </em>增加到<em class="nm"> 5 </em>不会导致召回率或整体准确度的任何变化。</p><p id="32a4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这方面，使用<em class="nm"> 3 </em>的权重允许高召回率，同时仍然允许总体分类准确度保持在 50%以上，并允许酒店有一个基线来区分取消预订的客户和没有取消预订的客户的属性。</p><h1 id="d9b3" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">结论</h1><p id="6e94" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mk kt ku kv ml kx ky kz mm lb lc ld im bi translated">在本例中，您看到了使用各种提升方法来预测酒店取消预订。如上所述，在这种情况下，boosting 方法被设置为对 minor 类施加更大的惩罚，其结果是降低了由 f1 分数测量的整体准确性，因为存在更多的假阳性。然而，召回分数因此大幅增加——如果假设在这种情况下假阳性比假阴性更容易容忍——那么人们可以认为该模型在此基础上表现得相当好。作为参考，在相同数据集上运行的 SVM 模型展示了 63%的总体准确性，而在类别 1 上的召回率下降到 75%。</p><p id="7b79" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以在这里找到原始文章<a class="ae ny" href="https://www.michael-grogan.com/articles/boosting-python-hotel-cancellations" rel="noopener ugc nofollow" target="_blank">，它包括一个到 GitHub 资源库的链接，该资源库包含与上述示例相关的相关笔记本和数据集。</a></p><p id="030d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">免责声明:本文是在“原样”的基础上编写的，没有任何担保。本文旨在提供数据科学概念的概述，不应以任何方式解释为专业建议。</p><h1 id="66a1" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">有用的参考资料</h1><ul class=""><li id="96fc" class="my mz it kk b kl mi ko mj kr nz kv oa kz ob ld nd ne nf ng bi translated"><a class="ae ny" href="https://www.sciencedirect.com/science/article/pii/S2352340918315191" rel="noopener ugc nofollow" target="_blank">安东尼奥、阿尔梅迪亚和努内斯(2019)。酒店预订需求数据集</a></li><li id="a324" class="my mz it kk b kl nh ko ni kr nj kv nk kz nl ld nd ne nf ng bi translated"><a class="ae ny" href="https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall" rel="noopener ugc nofollow" target="_blank">分类:精度和召回率</a></li><li id="dc1e" class="my mz it kk b kl nh ko ni kr nj kv nk kz nl ld nd ne nf ng bi translated">通过 Scikit-Learn 和 TensorFlow 进行机器实践学习</li><li id="db3c" class="my mz it kk b kl nh ko ni kr nj kv nk kz nl ld nd ne nf ng bi translated"><a class="ae ny" href="https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/" rel="noopener ugc nofollow" target="_blank">机器学习掌握:应用机器学习 XGBoost 简介</a></li><li id="17dc" class="my mz it kk b kl nh ko ni kr nj kv nk kz nl ld nd ne nf ng bi translated"><a class="ae ny" href="https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc" rel="noopener">什么是 LightGBM，如何实现？如何微调参数？</a></li></ul></div></div>    
</body>
</html>