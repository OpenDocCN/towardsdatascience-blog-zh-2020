<html>
<head>
<title>Predicting Reddit Flairs using Machine Learning and Deploying the Model using Heroku— Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用机器学习预测Reddit Flairs并使用Heroku部署模型—第2部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/predicting-reddit-flairs-using-machine-learning-and-deploying-the-model-using-heroku-part-2-d681e397f258?source=collection_archive---------59-----------------------#2020-05-27">https://towardsdatascience.com/predicting-reddit-flairs-using-machine-learning-and-deploying-the-model-using-heroku-part-2-d681e397f258?source=collection_archive---------59-----------------------#2020-05-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div class="gh gi ir"><img src="../Images/a6ea8ed85c66d13b5b6ea10cfaf3f8d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*MFT472S4Zy5nIhppVcDPwA.jpeg"/></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">图片由<a class="ae jc" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1989152" rel="noopener ugc nofollow" target="_blank">皮克斯拜</a>的Gerd Altmann 提供</p></figure><h2 id="5a99" class="jd je jf bd b dl jg jh ji jj jk jl dk jm translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/reddit-flair-prediction" rel="noopener" target="_blank"> Reddit天赋预测系列</a></h2><div class=""/><div class=""><h2 id="23f7" class="pw-subtitle-paragraph kl jo jf bd b km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc dk translated">文本分析和模型构建</h2></div><figure class="ld le lf lg gt iv"><div class="bz fp l di"><div class="lh li l"/></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">本文音频</p></figure><p id="c03f" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">如果你被困在付费墙后面，点击<a class="ae jc" rel="noopener" target="_blank" href="/predicting-reddit-flairs-using-machine-learning-and-deploying-the-model-using-heroku-part-2-d681e397f258?source=friends_link&amp;sk=e7086ecaf76d04f5cdc6b2077f4d346b">这里</a>获取我的朋友链接并查看这篇文章。</p><p id="712f" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">欢迎来到本系列的第2部分，在这里我将继续解决<strong class="ll jp"> Reddit Flair检测问题</strong>。在<a class="ae jc" href="https://medium.com/@prakharrathi25/predicting-reddit-flairs-using-machine-learning-and-deploying-the-model-on-heroku-part-1-574b69098d9a" rel="noopener">第1部分</a>中，我讨论了问题的背景和数据收集方法。强烈建议您在开始之前阅读第1部分，因为我已经分享了数据收集过程背后的见解和推理。我还描述了我在项目和模型构建中使用的各种指标。如果您还没有完成第1部分，但想继续第2部分，您必须从<a class="ae jc" href="https://github.com/prakharrathi25/reddit-flair-predictor/tree/master/data" rel="noopener ugc nofollow" target="_blank">这里</a>获取data.csv文件。一旦你获得了数据，我们就开始吧。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="71ed" class="mm mn jf bd mo mp mq mr ms mt mu mv mw ku mx kv my kx mz ky na la nb lb nc nd bi translated">介绍</h1><p id="9ae3" class="pw-post-body-paragraph lj lk jf ll b lm ne kp lo lp nf ks lr ls ng lu lv lw nh ly lz ma ni mc md me im bi translated">在课程的这一部分，我将致力于数据分析、文本分析和文本分类。虽然本教程是针对我从事的项目的，但是这些技术可以应用于任何文本分类问题。值得注意的是，这是一个多类文本分类问题，有一些专门针对这类问题的警告。大多数在线教程都是关于二进制文本分类的，比如垃圾邮件过滤器。然而，您将主要处理现实世界中的多类问题。因此，本教程应该是一个很好的起点。</p><h1 id="338c" class="mm mn jf bd mo mp nj mr ms mt nk mv mw ku nl kv my kx nm ky na la nn lb nc nd bi translated">问题回顾</h1><p id="7794" class="pw-post-body-paragraph lj lk jf ll b lm ne kp lo lp nf ks lr ls ng lu lv lw nh ly lz ma ni mc md me im bi translated">正如我已经讨论过的，这是一个有监督的多类文本分类问题。我们已经收集了特征和标签，我们的目标是建立一个模型，它可以根据我们收集的帖子的特征来预测帖子的风格。我们开始吧</p><h2 id="539b" class="no mn jf bd mo np nq dn ms nr ns dp mw ls nt nu my lw nv nw na ma nx ny nc jl bi translated">重要的图书馆</h2><p id="b062" class="pw-post-body-paragraph lj lk jf ll b lm ne kp lo lp nf ks lr ls ng lu lv lw nh ly lz ma ni mc md me im bi translated">这些是我们将在此过程中使用的库。</p><figure class="ld le lf lg gt iv"><div class="bz fp l di"><div class="nz li l"/></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">任务所需的库</p></figure><p id="c3be" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">如果您的系统中没有安装它们，您可以下载<a class="ae jc" href="https://github.com/prakharrathi25/reddit-flair-predictor/blob/master/requirements.txt" rel="noopener ugc nofollow" target="_blank">这个文件</a>，并在您的终端中运行以下命令。</p><pre class="ld le lf lg gt oa ob oc od aw oe bi"><span id="e313" class="no mn jf ob b gy of og l oh oi">pip install -r requirements.txt</span></pre><p id="65b5" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">注意:-这将在您的工作目录中安装所有的软件包。如果您想在虚拟环境中安装这些，请参考此<a class="ae jc" href="https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><h2 id="205a" class="no mn jf bd mo np nq dn ms nr ns dp mw ls nt nu my lw nv nw na ma nx ny nc jl bi translated">探索性数据分析</h2><p id="4162" class="pw-post-body-paragraph lj lk jf ll b lm ne kp lo lp nf ks lr ls ng lu lv lw nh ly lz ma ni mc md me im bi translated">首先将数据从csv文件读入数据帧。</p><pre class="ld le lf lg gt oa ob oc od aw oe bi"><span id="2046" class="no mn jf ob b gy of og l oh oi"># Reading Data <br/>data = pd.read_csv('data.csv')</span></pre><p id="4f6b" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">如果您已经从GitHub链接获得了数据，那么下一步对您来说很重要。其他人可以跳过这个。在这里可以找到<a class="ae jc" href="https://medium.com/@prakharrathi25/predicting-reddit-flairs-using-machine-learning-and-deploying-the-model-on-heroku-part-1-574b69098d9a" rel="noopener">的解释。</a></p><pre class="ld le lf lg gt oa ob oc od aw oe bi"><span id="8f57" class="no mn jf ob b gy of og l oh oi"># Data Shuffling<br/>data.drop(['Unnamed: 0'], inplace=True, axis=1)<br/>data[:] = data.sample(frac=1).values<br/>data.head()</span></pre><figure class="ld le lf lg gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="ok ol di om bf on"><div class="gh gi oj"><img src="../Images/f787eeb3080d288c430a72b53213f022.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VjpuNyFMXA1e4XqCz2EigQ.png"/></div></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">先看数据</p></figure><p id="a52f" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">由于这是一个文本分类问题，我们将只对机器学习模型使用包含文本的特征。它们是标题、正文、评论和URL(可选)。让我们看看列的数据类型和缺少的值。</p><pre class="ld le lf lg gt oa ob oc od aw oe bi"><span id="b8dd" class="no mn jf ob b gy of og l oh oi"># Display data types and null values<br/>data.info()</span></pre><figure class="ld le lf lg gt iv gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/ab847e27e667ec52fdcb1621643c9fdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*X1iHkk1OdKtM8DlBZdDZ9g.png"/></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">data.info()之后的输出</p></figure><p id="0bbc" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">在<code class="fe op oq or ob b">Body</code>列中有许多空值，在<code class="fe op oq or ob b">Comments</code>部分中有一些缺失值。我们不能估算它们，因为它们包含用户生成的内容。然而，每个条目都有一个<code class="fe op oq or ob b">Title</code>和<code class="fe op oq or ob b">Flair</code>，所以我们不必删除任何一行，我们可以使用它们进行分析。在<code class="fe op oq or ob b">Flair.</code>的数据集中有许多要预测的类</p><pre class="ld le lf lg gt oa ob oc od aw oe bi"><span id="2bb8" class="no mn jf ob b gy of og l oh oi">print(len(data[‘Flair’].unique()))<br/>data[‘Flair’].unique()</span><span id="6e40" class="no mn jf ob b gy os og l oh oi"><strong class="ob jp">OUTPUT:</strong></span><span id="86a3" class="no mn jf ob b gy os og l oh oi">11<br/>['Sports' 'Politics' '[R]eddiquette' 'Business/Finance' 'Food' 'AMA'<br/> 'AskIndia' 'Photography' 'Non-Political' 'Science/Technology'<br/> 'Policy/Economy']</span></pre><p id="f92d" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">因此，有11个独特的类。对于我们收到的每一个新帖子，我们都需要将其归入这11个类别中的一个。我已经提到了我们将用于分析的重要特性。让我们减小数据帧的大小，只保留相关的特征。</p><pre class="ld le lf lg gt oa ob oc od aw oe bi"><span id="ba7d" class="no mn jf ob b gy of og l oh oi"># List of relevant features<br/>features = [‘Flair’, ‘URL’, ‘Title’, ‘Comments’, ‘Body’]<br/>data = data[features]<br/>data.head()</span></pre><figure class="ld le lf lg gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="ok ol di om bf on"><div class="gh gi ot"><img src="../Images/3bb359c6e6302e6fd196f69ba3963a90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TyQKtgkNxjKehccsxwlIvg.png"/></div></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">过滤数据</p></figure><p id="4fd5" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">现在我们有了更多的相关数据，我们需要创建几个字典供将来使用[1]。第一步是为每个天赋生成一个唯一的ID。然后，我们将根据它们创建字典。这些字典将让我们引用我们为它们生成的独特id，反之亦然。</p><figure class="ld le lf lg gt iv"><div class="bz fp l di"><div class="nz li l"/></div></figure><figure class="ld le lf lg gt iv gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/db5036b3a67c89e291f185abd9a12263.png" data-original-src="https://miro.medium.com/v2/resize:fit:488/format:webp/1*D4Zxj8KVSXSeAxFMjnhOIQ.png"/></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">每种天赋类型的唯一id</p></figure><figure class="ld le lf lg gt iv"><div class="bz fp l di"><div class="nz li l"/></div></figure><figure class="ld le lf lg gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="ok ol di om bf on"><div class="gh gi ov"><img src="../Images/73ec841151ffc826065d765aac2b9826.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xd5C4BwUFZTzD8RY82mHfw.png"/></div></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">词典的输出</p></figure><p id="5692" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">我们创建了两本词典:-</p><ol class=""><li id="9864" class="ow ox jf ll b lm ln lp lq ls oy lw oz ma pa me pb pc pd pe bi translated"><code class="fe op oq or ob b">category_labels</code>:该字典将flairs作为关键字，将ID作为值分配给它们，这些值将在预测后用作分配标签的方式。</li><li id="2364" class="ow ox jf ll b lm pf lp pg ls ph lw pi ma pj me pb pc pd pe bi translated"><code class="fe op oq or ob b">category_reverse</code>:这是前一个字典的反例，使用id作为键，flairs作为值。</li></ol><p id="e894" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">下一步是创建一个由<code class="fe op oq or ob b">Title</code>、<code class="fe op oq or ob b">Body</code>和<code class="fe op oq or ob b">Comments</code>组合而成的组合特征。我现在不使用URL，让你来分析它。有很多有创意的方法可以做到这一点，你可以在下面的评论中提到它们。我将创建一个新的功能<code class="fe op oq or ob b">Combine</code>，它将纳入上述功能。</p><figure class="ld le lf lg gt iv"><div class="bz fp l di"><div class="nz li l"/></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">创建新功能<code class="fe op oq or ob b">Combine</code></p></figure><figure class="ld le lf lg gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="ok ol di om bf on"><div class="gh gi pk"><img src="../Images/1d9d51a9f1f9aea8a38f1eeb92cfbd52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1d8kn6YRAnF_O3u2zMZhCA.png"/></div></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">添加组合特征后的数据帧</p></figure><p id="506d" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated"><strong class="ll jp">文字清理</strong></p><p id="ec6e" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">这是文本分类项目最重要的方面之一，因为并非所有的单词都同样重要，一些单词如<em class="pl">和</em>和<em class="pl">是</em>是如此常见，以至于它们会出现在所有flair类别的数据中，并混淆分类器。强烈建议删除它们。在情感分析项目中，我们可能会保留标点符号，因为感叹号的数量可能会完全改变那里的含义。然而，我觉得没有必要把它们留在这里，因此，我将在下一步中删除它们。我刚才提到的<em class="pl">常用词</em>在nltk库中都有，所以你不必自己列一个清单。</p><pre class="ld le lf lg gt oa ob oc od aw oe bi"><span id="8687" class="no mn jf ob b gy of og l oh oi"># Collect all the english stopwords and display them<br/>STOPWORDS = nltk.corpus.stopwords.words(‘english’)<br/>print(STOPWORDS)</span></pre><figure class="ld le lf lg gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="ok ol di om bf on"><div class="gh gi pm"><img src="../Images/23f80cf5d433861712f355847ae42c03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AZIrTSAOJThf4rN75n0apg.png"/></div></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">英语中的nltk停用词列表</p></figure><p id="1417" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">让我们定义一个清洗函数。我们将通过这个函数来清理我们的特征。</p><figure class="ld le lf lg gt iv"><div class="bz fp l di"><div class="nz li l"/></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">函数来清理我们的数据</p></figure><figure class="ld le lf lg gt iv gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/67ad631714c353f216be7f4acc3bfb0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*QiXJYuwOI3l2m2VFNKW0dA.png"/></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">清洁后的组合功能</p></figure><h2 id="b50c" class="no mn jf bd mo np nq dn ms nr ns dp mw ls nt nu my lw nv nw na ma nx ny nc jl bi translated">文本表示</h2><p id="3b82" class="pw-post-body-paragraph lj lk jf ll b lm ne kp lo lp nf ks lr ls ng lu lv lw nh ly lz ma ni mc md me im bi translated">分类器和学习算法不能直接处理原始形式的文本文档，因为它们中的大多数期望具有固定大小的数字特征向量，而不是具有可变长度的原始文本文档。因此，在预处理步骤中，文本被转换成更易于管理的表示[1]。矢量化是一种将单词转换成长串数字的方法，这些数字可能具有某种复杂的结构，只有使用某种机器学习或数据挖掘算法的计算机才能理解。[2]</p><p id="fa38" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">对于文章的这一部分，我要感谢<a class="po pp ep" href="https://medium.com/u/731d8566944a?source=post_page-----d681e397f258--------------------------------" rel="noopener" target="_blank">苏珊李</a>。她在<a class="ae jc" rel="noopener" target="_blank" href="/multi-class-text-classification-with-scikit-learn-12f1e60e0a9f">她的文章</a>中介绍的最相关单字和双字测试是一种非常有见地的技术，它让我们找到在特定类型的天赋中出现最多的单词，并让我们深入了解模型的预测方法。如果一个特殊的天赋有很多不相关的词，那么我们可能会考虑添加更多的数据或删除一些数据。</p><p id="2fc2" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">现在，对于我们数据集中出现的每个术语，我们将计算一个称为<a class="ae jc" href="http://www.tfidf.com/" rel="noopener ugc nofollow" target="_blank">术语频率的度量，逆文档频率</a>，缩写为tf-idf。我们将使用<code class="fe op oq or ob b">sklearn.feature_extraction.text.TfidfVectorizer </code>来计算每个消费者投诉叙述的<code class="fe op oq or ob b">tf-idf</code>向量:</p><ul class=""><li id="fc0d" class="ow ox jf ll b lm ln lp lq ls oy lw oz ma pa me pq pc pd pe bi translated"><code class="fe op oq or ob b">sublinear_df</code>设置为<code class="fe op oq or ob b">True</code>以使用对数形式的频率。</li><li id="204a" class="ow ox jf ll b lm pf lp pg ls ph lw pi ma pj me pq pc pd pe bi translated"><code class="fe op oq or ob b">min_df</code>是一个单词必须存在的最小文档数。</li><li id="12e1" class="ow ox jf ll b lm pf lp pg ls ph lw pi ma pj me pq pc pd pe bi translated"><code class="fe op oq or ob b">norm</code>被设置为<code class="fe op oq or ob b">l2</code>，以确保我们所有的特征向量具有1的欧几里德范数。</li><li id="a479" class="ow ox jf ll b lm pf lp pg ls ph lw pi ma pj me pq pc pd pe bi translated"><code class="fe op oq or ob b">ngram_range</code>被设置为<code class="fe op oq or ob b">(1, 2)</code>,表示我们既要考虑单元组，也要考虑二元组。</li><li id="0671" class="ow ox jf ll b lm pf lp pg ls ph lw pi ma pj me pq pc pd pe bi translated"><code class="fe op oq or ob b">stop_words</code>设置为<code class="fe op oq or ob b">"english"</code>删除所有常用代词(<code class="fe op oq or ob b">"a"</code>、<code class="fe op oq or ob b">"the"</code>、...)以减少噪声特征的数量。[1]</li></ul><figure class="ld le lf lg gt iv"><div class="bz fp l di"><div class="nz li l"/></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">组合数据的tfidf矢量化</p></figure><pre class="ld le lf lg gt oa ob oc od aw oe bi"><span id="4866" class="no mn jf ob b gy of og l oh oi"><strong class="ob jp">Output <br/></strong>(1650, 3299)</span></pre><p id="c74d" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">现在，1650个消费者投诉叙述中的每一个都由3299个特征表示，代表不同单字和双字的tf-idf得分。</p><p id="9469" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">我们可以使用<code class="fe op oq or ob b">sklearn.feature_selection.chi2</code>找到与每个产品最相关的术语:</p><figure class="ld le lf lg gt iv"><div class="bz fp l di"><div class="nz li l"/></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">打印每种天赋最相关的单字和双字列表</p></figure><p id="d06f" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">您会发现下面的输出对于每种天赋都非常直观。</p><pre class="ld le lf lg gt oa ob oc od aw oe bi"><span id="4261" class="no mn jf ob b gy of og l oh oi">Flair 'AMA':<br/>Most correlated unigrams:<br/>	. hi<br/>	. anything<br/>	. ask<br/>	. questions<br/>	. ama<br/>Most correlated bigrams:<br/>	. ask us<br/>	. us anything<br/>	. hi reddit<br/>	. answer questions<br/>	. ask anything<br/><br/>Flair 'AskIndia':<br/>Most correlated unigrams:<br/>	. advice<br/>	. dad<br/>	. situation<br/>	. afraid<br/>	. family<br/>Most correlated bigrams:<br/>	. ive seen<br/>	. want know<br/>	. feel like<br/>	. work home<br/>	. dont want<br/><br/>Flair 'Business/Finance':<br/>Most correlated unigrams:<br/>	. firms<br/>	. emi<br/>	. hdfc<br/>	. mukesh<br/>	. bank<br/>Most correlated bigrams:<br/>	. credit card<br/>	. mukesh ambani<br/>	. share market<br/>	. reliance jio<br/>	. yes bank<br/><br/>Flair 'Food':<br/>Most correlated unigrams:<br/>	. restaurant<br/>	. chutney<br/>	. recipe<br/>	. chicken<br/>	. food<br/>Most correlated bigrams:<br/>	. im trying<br/>	. every day<br/>	. couldnt find<br/>	. dont eat<br/>	. indian food<br/><br/>Flair 'Non-Political':<br/>Most correlated unigrams:<br/>	. rural<br/>	. dads<br/>	. found<br/>	. bored<br/>	. comics<br/>Most correlated bigrams:<br/>	. im gonna<br/>	. palghar lynching<br/>	. amazon prime<br/>	. india live<br/>	. amid lockdown<br/><br/>Flair 'Photography':<br/>Most correlated unigrams:<br/>	. mm<br/>	. beach<br/>	. nikon<br/>	. shot<br/>	. oc<br/>Most correlated bigrams:<br/>	. stay home<br/>	. equipment nikon<br/>	. one plus<br/>	. da mm<br/>	. nikon da<br/><br/>Flair 'Policy/Economy':<br/>Most correlated unigrams:<br/>	. gdp<br/>	. govt<br/>	. investments<br/>	. nirmala<br/>	. economy<br/>Most correlated bigrams:<br/>	. health workers<br/>	. https internetfreedomin<br/>	. petrol diesel<br/>	. indian economy<br/>	. raghuram rajan<br/><br/>Flair 'Politics':<br/>Most correlated unigrams:<br/>	. sonia<br/>	. removed<br/>	. modi<br/>	. arnab<br/>	. muslims<br/>Most correlated bigrams:<br/>	. home minister<br/>	. arnab goswami<br/>	. pm modi<br/>	. rahul gandhi<br/>	. john oliver<br/><br/>Flair 'Science/Technology':<br/>Most correlated unigrams:<br/>	. vpn<br/>	. iit<br/>	. develop<br/>	. zoom<br/>	. users<br/>Most correlated bigrams:<br/>	. anyone else<br/>	. covid virus<br/>	. home affairs<br/>	. ministry home<br/>	. cow urine<br/><br/>Flair 'Sports':<br/>Most correlated unigrams:<br/>	. ipl<br/>	. football<br/>	. sports<br/>	. cricket<br/>	. cup<br/>Most correlated bigrams:<br/>	. india pakistan<br/>	. know people<br/>	. one time<br/>	. times india<br/>	. world cup<br/><br/>Flair '[R]eddiquette':<br/>Most correlated unigrams:<br/>	. boop<br/>	. askaway<br/>	. beep<br/>	. creator<br/>	. bot<br/>Most correlated bigrams:<br/>	. bot problem<br/>	. bot bot<br/>	. askaway creator<br/>	. beep boop<br/>	. discussion thread</span></pre><p id="0b7b" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">你会发现，对于大多数flairs来说，最相关的单词是很有解释力的。</p><h2 id="26f7" class="no mn jf bd mo np nq dn ms nr ns dp mw ls nt nu my lw nv nw na ma nx ny nc jl bi translated">对输入要素和标注建模</h2><p id="e9fe" class="pw-post-body-paragraph lj lk jf ll b lm ne kp lo lp nf ks lr ls ng lu lv lw nh ly lz ma ni mc md me im bi translated">我们的下一个任务是以分类器可以理解的方式对输入数据进行建模。我们需要将输入转换成与数字标签相关的数字向量。获得文本的向量表示后，我们可以训练监督分类器来预测用户提交的每个Reddit帖子的“风格”。让我们从按数据划分成训练集和测试集开始。我没有先对数据进行矢量化是有原因的，因为如果你这样做，那么你的矢量化工具会将整个数据视为样本，并基于此进行拟合。这意味着您的<code class="fe op oq or ob b">.fit() </code>或<code class="fe op oq or ob b"> .fit_transform()</code>将使用整个数据进行拟合。当我们稍后拆分数据时，测试数据将基于组合的训练和测试数据进行拆分。然而，这种模式将被部署，我们没有同样的奢侈品与看不见的数据，因此，我们不能转换它的基础上综合数据。这可能会降低测试的准确性，但在我看来，从长远来看，这是一个更好的模型，因为它消除了偏见。</p><figure class="ld le lf lg gt iv"><div class="bz fp l di"><div class="nz li l"/></div></figure><figure class="ld le lf lg gt iv"><div class="bz fp l di"><div class="nz li l"/></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">向量化和转换数据</p></figure><p id="edec" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">在所有上述数据转换之后，现在我们已经有了所有的特征和标签，是时候训练我们的分类器了。对于这个问题，我们可以使用许多不同的分类器。我将使用四种不同类型的模型，由于本文的长度，我将只讨论可能作为良好比较的基线结果。我将会写一篇关于Google当前模型的BERT和超参数调整的文章。我将使用的模型是:-</p><ul class=""><li id="760b" class="ow ox jf ll b lm ln lp lq ls oy lw oz ma pa me pq pc pd pe bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/multinomial-naive-bayes-classifier-for-text-analysis-python-8dd6825ece67">多项式朴素贝叶斯</a></li><li id="6a90" class="ow ox jf ll b lm pf lp pg ls ph lw pi ma pj me pq pc pd pe bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/understanding-random-forest-58381e0602d2">随机森林分类器</a></li><li id="ee42" class="ow ox jf ll b lm pf lp pg ls ph lw pi ma pj me pq pc pd pe bi translated"><a class="ae jc" href="https://monkeylearn.com/blog/introduction-to-support-vector-machines-svm/#tutorial" rel="noopener ugc nofollow" target="_blank">支持向量机分类</a></li><li id="c08f" class="ow ox jf ll b lm pf lp pg ls ph lw pi ma pj me pq pc pd pe bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/logistic-regression-detailed-overview-46c4da4303bc">逻辑回归</a></li></ul><p id="621f" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">这些分类器各有优缺点。由你来决定哪一个最适合你的需要。我将向您介绍实现和流水线化它们的过程。以下是训练数据的方法。</p><pre class="ld le lf lg gt oa ob oc od aw oe bi"><span id="253a" class="no mn jf ob b gy of og l oh oi"># Create an instance <br/>model = MultinomialNB()</span><span id="6af0" class="no mn jf ob b gy os og l oh oi"># Fit to training data<br/>model.fit(X_train_tfidf, y_train)</span><span id="399d" class="no mn jf ob b gy os og l oh oi"># Predictions on X_test_tfidf<br/># Obtain X_test_tfidf in the manner described above<br/>model.predict(X_test_tfidf)<br/></span></pre><p id="38f8" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">这是很基本的，对吧？如果你曾经训练过一个简单的分类器，你一定已经这样做过很多次了。那我们学点新东西吧。</p><h2 id="53d4" class="no mn jf bd mo np nq dn ms nr ns dp mw ls nt nu my lw nv nw na ma nx ny nc jl bi translated">管道铺设</h2><p id="20d8" class="pw-post-body-paragraph lj lk jf ll b lm ne kp lo lp nf ks lr ls ng lu lv lw nh ly lz ma ni mc md me im bi translated">机器学习(ML)模型中有许多活动的部分，它们必须连接在一起，ML模型才能成功地执行并产生结果。流水线的每一级都被馈送从其前一级处理的数据；也就是说，处理单元的输出作为输入提供给下一个步骤。在软件工程中，人们建立管道来开发从源代码到部署的软件。类似地，在ML中，创建管道以允许数据从其原始格式流向一些有用的信息。数据在管道中流动，就像水在管道中流动一样。掌握管道概念是创建无错误ML模型的一种强有力的方法，而管道是AutoML系统的一个至关重要的元素。它提供了一种构造多ML并行流水线系统的机制，以便比较几种ML方法的结果。[3]这是我们的管道的样子。</p><figure class="ld le lf lg gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="ok ol di om bf on"><div class="gh gi pr"><img src="../Images/ece5b77bede803c241a5d77cc741f785.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RlhSxdONC3-eGQcOtHGqzQ.png"/></div></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">我们的管道流程图(用<a class="ae jc" href="https://www.smartdraw.com/" rel="noopener ugc nofollow" target="_blank"> SmartDraw </a>制作)</p></figure><p id="1ca0" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">让我们从多项式朴素贝叶斯分类器开始。</p><pre class="ld le lf lg gt oa ob oc od aw oe bi"><span id="66a1" class="no mn jf ob b gy of og l oh oi">nb_fit = Pipeline([(‘vect’, CountVectorizer()),<br/>                   (‘tfidf’, TfidfTransformer()),<br/>                   (‘clf’, MultinomialNB())])</span></pre><p id="ca13" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">类似地，我们可以为每个分类器创建函数，以实现更简化的方法。</p><figure class="ld le lf lg gt iv"><div class="bz fp l di"><div class="nz li l"/></div><p class="iy iz gj gh gi ja jb bd b be z dk translated">制作我们的预测函数</p></figure><h2 id="e837" class="no mn jf bd mo np nq dn ms nr ns dp mw ls nt nu my lw nv nw na ma nx ny nc jl bi translated">进行预测和评估结果</h2><p id="c9fb" class="pw-post-body-paragraph lj lk jf ll b lm ne kp lo lp nf ks lr ls ng lu lv lw nh ly lz ma ni mc md me im bi translated">使上面创建的功能模块化你的代码，使你的任务更容易。现在你可以方便地进行预测和评估结果。</p><pre class="ld le lf lg gt oa ob oc od aw oe bi"><span id="4505" class="no mn jf ob b gy of og l oh oi">print(“Evaluate Naive Bayes Classifier”)<br/>nb_classifier(X_train, X_test, y_train, y_test)</span><span id="2041" class="no mn jf ob b gy os og l oh oi">print(“Evaluate Random Forest Classifier”)<br/>random_forest(X_train, X_test, y_train, y_test)</span><span id="198b" class="no mn jf ob b gy os og l oh oi">print(“Evaluate Logistic Regression Model”)<br/>log_reg(X_train, X_test, y_train, y_test)</span><span id="2445" class="no mn jf ob b gy os og l oh oi">print(“Evaluate SVC Model”)<br/>svc(X_train, X_test, y_train, y_test)</span></pre><p id="140a" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">以下命令打印结果。根据您所使用的数据和您所做的预处理，结果可能会有所不同。这些是基线结果，后来使用超参数调整进行了临时调整。然而，这篇文章足够长，所以我将在另一篇文章中介绍它。</p><pre class="ld le lf lg gt oa ob oc od aw oe bi"><span id="90ec" class="no mn jf ob b gy of og l oh oi">Evaluate Naive Bayes Classifier<br/>Model Accuracy: 0.53951612903225806<br/>Evaluate Random Forest Classifier<br/>Model Accuracy: 0.6074193548387097<br/>Evaluate Logistic Regression Model<br/>Model Accuracy: 0.6645161290322581<br/>Evaluate SVC Model<br/>Model Accuracy: 0.5248387096774194</span></pre><p id="1592" class="pw-post-body-paragraph lj lk jf ll b lm ln kp lo lp lq ks lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">我们可以看到，逻辑回归模型似乎是最好的。然而，在超参数调优之后，这种情况会很快改变，所以我现在把这个问题留给你。现在性能低的原因有很多，包括数据质量，它们可以在下面的评论中进行很好的讨论。在下一部分中，我将为部署对这个模型进行序列化。我们还将与Flask合作部署我们的机器学习模型。该网络应用程序将以这样一种方式工作，用户将发布一个链接，我们将得到预测的类回来。要学习如何创建网络应用，请继续阅读<a class="ae jc" rel="noopener" target="_blank" href="/predicting-reddit-flairs-using-machine-learning-and-deploying-the-model-using-heroku-part-3-c3cd19374596?source=friends_link&amp;sk=388a869381f067253609f48647a17cd8">第三部分</a>。你可以在这里找到这个系列<a class="ae jc" href="https://towardsdatascience.com/tagged/reddit-flair-prediction" rel="noopener" target="_blank">的所有文章</a>。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="3134" class="mm mn jf bd mo mp mq mr ms mt mu mv mw ku mx kv my kx mz ky na la nb lb nc nd bi translated">参考</h1><ol class=""><li id="5f5f" class="ow ox jf ll b lm ne lp nf ls ps lw pt ma pu me pb pc pd pe bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/multi-class-text-classification-with-scikit-learn-12f1e60e0a9f">https://towards data science . com/multi-class-text-classification-with-scikit-learn-12 f1 e 60 E0 a9 f</a></li><li id="bddb" class="ow ox jf ll b lm pf lp pg ls ph lw pi ma pj me pb pc pd pe bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/effectively-pre-processing-the-text-data-part-1-text-cleaning-9ecae119cb3e">https://towards data science . com/effectively-pre-processing-the-text-data-part-1-text-cleaning-9 ecae 119 cb3e</a></li><li id="4311" class="ow ox jf ll b lm pf lp pg ls ph lw pi ma pj me pb pc pd pe bi translated"><a class="ae jc" href="https://dzone.com/articles/how-to-build-a-simple-machine-learning-pipeline" rel="noopener ugc nofollow" target="_blank">https://dzone . com/articles/how-to-build-a-simple-machine-learning-pipeline</a></li><li id="df52" class="ow ox jf ll b lm pf lp pg ls ph lw pi ma pj me pb pc pd pe bi translated"><a class="ae jc" rel="noopener" target="_blank" href="/text-mining-for-dummies-text-classification-with-python-98e47c3a9deb">https://towards data science . com/text-mining-for-dummies-text-class ification-with-python-98e 47 C3 a9 deb</a></li></ol></div></div>    
</body>
</html>