<html>
<head>
<title>Improving the efficiency of the loss function in Cycle-Consistent Adversarial Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">提高循环一致对抗网络中损失函数的效率</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/improving-the-efficiency-of-the-loss-function-in-cycle-consistent-adversarial-networks-808cca3669f0?source=collection_archive---------17-----------------------#2020-03-06">https://towardsdatascience.com/improving-the-efficiency-of-the-loss-function-in-cycle-consistent-adversarial-networks-808cca3669f0?source=collection_archive---------17-----------------------#2020-03-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="2100" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> CycleGAN </strong>是一种涉及图像到图像翻译模型的自动训练的技术，不需要成对的例子。我们先来看结果。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/954d46d0359ca71a3bef86855192a922.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ly9_34OPb6pMwxXqGlfvrw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">基于循环一致对抗网络的马到斑马翻译</p></figure><p id="31a0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这篇文章中，你会发现一些关于生成对抗网络、CNN、CycleGAN技术的小知识。现在让我们从这个概念背后的一些基本信息开始:生成性对抗网络。生成对抗网络(GANs)是一类用于无监督机器学习的神经网络。发生器和鉴别器分开工作，互为对手</p><h1 id="b90c" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">生成对抗网络</h1><p id="4606" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">生成对抗网络(GAN)是神经网络中的一种模型，它在机器学习领域提供了很多潜力。在GAN中有两个神经网络:第一个是生成网络，第二个是鉴别网络。所以这个项目背后的主要概念是生成性对抗网络。甘是关于创造的东西，这是很难比较的另一个深度学习领域。GAN的主要重点是从零开始生成数据。GAN的一个例子是，从马生成斑马。正如我们所见，早期的GAN由两个网络组成，即发生器和鉴别器。我们来看图像。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/47ec5a07d45320c6fdff3de4f01a901a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*A0a0-7kzP9jSW_nA5OjkfQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">了解GAN(资料来源:Suransh Chopra著《CycleGANs简介》)</p></figure><p id="93d0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">CycleGAN是一种使用生成对抗网络或GAN模型架构来处理准备图像到图像翻译模型的方法。</p><p id="9924" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，在我们跳到CycleGAN之前，我们需要了解CNN。</p><h1 id="0ab2" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">卷积神经网络</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mi"><img src="../Images/0759cce935cea71ccd2ddd22fbc7ecf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wHIiczDZqWWaSydAra5o0g.png"/></div></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mj"><img src="../Images/a28894f3c49503b985e7670fec012fcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x8IybopziYdqCWho2j9yKA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">CNN如何识别图像(来源:Jason Brownlee，“深度学习的Adam优化算法的温和介绍”)</p></figure><p id="c452" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">CNN主要用于图像分类或识别。CNN使功能更加高效，减少了参数。CNN接受像素值作为网络的输入。用于特征提取的隐藏层和最后完全连接的层识别图像属于哪一类？CNN有4层。卷积层、ReLu层(激活函数)、池层和全连接层。<br/>卷积层使用图像上的滤波器矩阵或图像上的移位滤波器矩阵，并获得卷积的特征图。<br/>下一层是ReLu层。它将所有负像素转换为零并运行，但在CycleGAN中，由于负值，我们使用了LeakyReLu。输出被称为校正特征图。下一层是池层。合并层降低了校正后的特征图的维度，这意味着我们必须从图像中选择最大像素。然后将汇集的特征图转换成长的连续LV。这整个过程叫拍马屁。谄媚地连接着一个完全连接的图层来对图像进行分类。</p><h1 id="4691" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">循环GAN</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/4e5faac4180166b45ac60c0a2796c4d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*WrabfQ0hBYsYQ3TIwmk2JQ.jpeg"/></div></figure><p id="774f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">该模型包含两个函数G: X -&gt; Y和F: Y -&gt; X，其中X是源域，Y是目标域。生成器X2Y将马转换为斑马，Y2X将斑马转换为马。CycleGAN背后的关键思想是，它们允许你将模型指向两个不成对的图像集合。例如，一个图像集合，组A是未来的斑马，而另一个集合B是马。所以Cycle-GAN模型可以计算出如何解释不成对的图片。</p><p id="7c51" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这里的主要部分是循环一致性损失，例如，如果我们的输入图像A来自域X，通过生成器G转换为目标图像或域Y的输出图像B，然后域Y的图像B通过生成器f转换回域X，因此这两个图像之间的差异称为循环一致性损失。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ml"><img src="../Images/05332781fbc6df0fe0f6819caef71310.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uKhZmc_SUKtc8d6fTIY3tQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">循环损耗(资料来源:Mohan Nikam“改善循环-GAN”)</p></figure><p id="7597" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">发电机有三个部分:</p><p id="31e7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">I .编码器(提取特征):作为输入，卷积网络拍摄一张图片，我们在输入图片上移动以提取特征的滤波器窗口的大小，以及选择每次前进后我们将移动滤波器窗口的量的步长。</p><p id="09ca" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">二。Transformer(添加先前结果的余数):因此，为此，我们利用了9层resnet块来如下改进结果:Resnet块是包括两个卷积层的神经网络层，其中信息的累积被添加到产出。</p><p id="f73a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">三。解码器(解码结果):解码步骤是步骤1的特定逆步骤，我们将从元素向量再次返回低级特征。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mm"><img src="../Images/349f73b577c48afc9cf0a662bfc749e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MdzQOcNiJDl8HepMTsYq2A.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">CycleGAN实施的步骤</p></figure><p id="5f92" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">周期目标函数、对抗性损失和周期一致性损失。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/171c707e8cbfc32fdfa7bf0838a1e741.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*nq-ttuUpF_O2aySezVqDrg.png"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/3bd611a51f80b406216701661ef0fcc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/1*UQzHBu-_PaTKBJHGsWHGQA.png"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/8b815d039e476fd782a0c37fc0305fe4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*mQmMsm65-7DLrPF40FnDkg.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">对抗性损失</p></figure><p id="4ece" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，我们可以通过将这些损失项放在一起，并用超参数λ对循环一致性损失进行加权，来创建完整的目标函数。我们建议设置λ = 10</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mq"><img src="../Images/585eeb201eac668117643ad50c516563.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/1*_jNwuPO4bb7Vrhvi8Vmysw.png"/></div></div></figure><p id="3b91" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了测量损失，我们像在大多数深度学习中一样使用交叉熵:p log (q)。</p><p id="c8b5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于生成的图像，我们反转标签(即一减一标签)。所以目标变成了:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/cac6e842ff5a38bb5f45d82a14f4f5db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*pKKLRmM1ecEOocPXBKzgDg.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">识别真实图像和生成的图像</p></figure><p id="47c3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">另一方面，基于等式1，优化检查发生器图像的D，目标函数希望模型以最高可能的方式生成图像来欺骗鉴别器。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/b4dd091b1028b20593a9b7bbad65914a.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*T9USCPnT4XfuHRP_nCEGyQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">愚弄鉴别者</p></figure><p id="a3ce" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">g想最小化V，而D想最大化V。</p><p id="4edd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">通过提升其随机梯度来更新鉴别器:</strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/d7f84db9a1c9c82758dfa7f95ca69b84.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*_3GjaUTmLifUFZK1Cj6N8g.png"/></div></figure><p id="db44" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">通过降低其随机梯度来更新生成器:</strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/00bdd84dbba2a76733fdd07f15521d50.png" data-original-src="https://miro.medium.com/v2/resize:fit:496/format:webp/1*uA-KT5HXrplnXNDuPLxg2g.png"/></div></figure><p id="f677" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这些算法实际上是由Ian Goodfellow使用的，但大多数深度学习研究人员使用adam optimizer来获得更好、更高效的结果，因为这种算法的结果与最佳结果相差很远。我使用了亚当优化的最佳效果。</p><p id="bbfd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">发电机损耗:</strong></p><p id="277d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">发电机损耗是这两项之和:</strong></p><p id="9fb6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">G _ loss _ G = G _ loss _ G _ disc+G _ loss _ G _ cycle</strong></p><p id="6ba8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因为循环损耗非常重要，所以我们想增加它的影响。</p><p id="faac" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们为这个乘数使用了一个L1λ常数(在论文中使用了值10)。</p><p id="6452" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在发电机损耗看起来像:</p><p id="0fbf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">G _ loss _ G = G _ loss _ G _ disc+L1 _λ* G _ loss _ G _ cycle</strong></p><p id="980b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">g _ loss _ F = g _ loss _ F _ disc+L1 _λ* g _ loss _ F _ cycle</strong></p><p id="8a46" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">鉴频器损耗:</strong></p><p id="0166" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">鉴别器需要做出两个决定:</p><p id="7f60" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">1.真实图像应标记为真实(推荐值应尽可能接近1)</p><p id="c845" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">2.鉴别器应该能够识别生成的图像，从而预测假图像为0。</p><p id="143f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">减少模型振荡</strong></p><ul class=""><li id="77aa" class="mv mw it js b jt ju jx jy kb mx kf my kj mz kn na nb nc nd bi translated">为了防止模型从一次迭代到另一次迭代发生剧烈变化，鉴别器被输入生成图像的历史，而不仅仅是由最新版本的生成器生成的图像。</li><li id="0055" class="mv mw it js b jt ne jx nf kb ng kf nh kj ni kn na nb nc nd bi translated">此外，我们包含了过去100张图像的历史来训练鉴别器，为什么我们要做这些事情，因为生成器和鉴别器都可能过度拟合，导致模式崩溃</li><li id="4863" class="mv mw it js b jt ne jx nf kb ng kf nh kj ni kn na nb nc nd bi translated">为此，我们保存了100张最近生成的图像。基于这种技术，我们减少了模型振荡以及模型过拟合。</li></ul><p id="e04b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">亚当优化器</strong></p><p id="d7fc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Adam代表<em class="nj">自适应矩估计。</em>在训练的前半部分，学习率被设置为0.0002，然后在剩余的迭代中线性降低到零。</p><p id="abb1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">就像最初的GAN实现一样，我们将创建单独的优化器，这些优化器只能更新网络的某些部分。我们希望两个网络都变得更好。</p><p id="9aea" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">优化器是最重要的，因为在每个时期后，学习率会改变，偏差和权重也会改变，我们会获得最佳结果。大多数研究人员使用随机梯度，但随机是恒定的学习率算法，这就是为什么学习率在每个时期后不会改变。利用亚当优化函数和L1损失函数达到了较好的效果。</strong> <strong class="js iu">批量大小被设置为1，这就是为什么我们称之为实例规范化，而不是批量规范化。</strong></p><p id="e0ac" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将在这里做同样的事情，只是现在我们有3个网络要优化，因此我们需要3个优化器:</p><ul class=""><li id="75ce" class="mv mw it js b jt ju jx jy kb mx kf my kj mz kn na nb nc nd bi translated">G_xy和G_yx变量将作为生成器进行优化，而D_x和D_y应该更新两个不同的鉴别器。</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nk"><img src="../Images/9478b1c19b4d83ecb9e90a3a4ebc8ec3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GgSrMd7D8jK7muG6g7d8KA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">FCN-不同方法的得分，在城市景观标签上进行评估</p></figure><p id="010c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是我在表1和表2中实现的结果，我们考虑的是完全损失的清除。消除GAN损失会极大地破坏结果，消除循环一致性损失也是如此。我们沿着这些思路假设这两个术语是我们结果的基础。<br/>我们同样评估我们的策略，仅在一个方向上的周期损失:GAN +正向周期损失或GAN +反向周期损失。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nl"><img src="../Images/1fffbcf1de67da379fac8dfa368c896e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IVUcpM09kdZmpb_b9IUCAg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">消融研究:FCN——我们方法的不同变体的得分，在城市风景照片→标签上评估</p></figure><p id="c1bc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">此外，我们包含了最近100张图像的历史记录来训练鉴别器，为什么我们要做这些事情，因为生成器和鉴别器都可能过度拟合自己(例如:普京骑在马上),导致模式崩溃。使用这种鉴别器不会有助于击败发生器。它需要击败最后的100个生成器，才能得到最优解。</strong></p><p id="c542" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">结果(Pytorch) </strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/954d46d0359ca71a3bef86855192a922.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ly9_34OPb6pMwxXqGlfvrw.png"/></div></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nm"><img src="../Images/a65d4c5c7f4024cf811757090d9698ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*crGn9--Nca_7KFcGjv26Jg.png"/></div></div></figure><p id="d110" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">故障案例(Pytorch) </strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nn"><img src="../Images/c32a4b722ea5d556b89b501e27c27797.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*00FscQZ2ujTwqphNtZ2Igg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">有时生成器崩溃，这就是为什么产生有限的样本数据</p></figure><h1 id="e847" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">摘要</h1><p id="2a49" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">在本文中，你发现了在循环一致的敌对网络中提高损失函数的效率。具体来说，您学到了:</p><p id="2e5a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">执行CycleGAN的确切方法，GAN、CNN、随机和Adma优化器、发电机损耗、鉴别器损耗的知识，减少模型振荡。</p><p id="ff69" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果您想了解更多的实现细节，可以参考一些非常开放的用法。</p><h1 id="ccbe" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">感谢阅读！</h1><p id="aa4d" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">随时给我发信息。</p><p id="0b5c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">Twitter:aamirjarda<br/>LinkedIn:aamirjarda<br/>insta gram:aamirjarda</p><p id="48e8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你有什么问题吗？在下面的评论中提出你的问题，我会尽力回答。</p></div></div>    
</body>
</html>