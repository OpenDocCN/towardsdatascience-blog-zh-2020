<html>
<head>
<title>Time Series Forecasting with Graph Convolutional Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于图卷积神经网络的时间序列预测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/time-series-forecasting-with-graph-convolutional-neural-network-7ffb3b70afcf?source=collection_archive---------5-----------------------#2020-04-29">https://towardsdatascience.com/time-series-forecasting-with-graph-convolutional-neural-network-7ffb3b70afcf?source=collection_archive---------5-----------------------#2020-04-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7f31" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">结合图和递归结构的商店物品需求预测</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/bc2152052019d631aebac8b688ee9efa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*a3dqtCJx3reErFlj"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">米歇尔·比特托在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="2418" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">时间序列预测任务可以通过以下不同的方法来完成。最经典的是基于统计和自回归方法。更棘手的是基于boosting和ensemble的算法，在这些算法中，我们必须产生大量有用的手工制作的滚动周期特征。另一方面，我们可以找到神经网络模型，使其开发更加自由，提供可定制的顺序建模和更多。</p><p id="cdc6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">递归和卷积结构在时间序列预测中取得了巨大成功。该领域中有趣的方法是通过采用最初在NLP中固有的转换器和注意力架构来给出的。图形结构的使用似乎不常见，其中我们有一个由不同节点组成的网络，这些节点通过某种链接相互关联。我们试图用时间序列的图形表示来预测未来。</p><p id="381f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们执行了一项销售预测任务，其中我们利用图形卷积神经网络，利用我们的数据的嵌套结构，这些数据由不同商店中各种商品的不同销售系列组成。</p><h1 id="a4d0" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">数据</h1><p id="f7c8" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">该数据集是从Kaggle上过去的比赛中收集的。<a class="ae ky" href="https://www.kaggle.com/c/demand-forecasting-kernels-only/data" rel="noopener ugc nofollow" target="_blank">商店商品需求预测挑战赛</a>以每日格式提供了各商店销售的不同商品的4整年的销售数据。我们有10家商店和50种产品，总共500个系列。每个产品在每个商店都有销售。我们的范围是每天为所有项目提供准确的未来预测。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/e2d12cc0adc974d5a447a16d4e886d91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F6tdM-Bsdh5_iRltYJSFqQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">每个商店中商品10的销售额</p></figure><p id="b543" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们掌握的数据很少:只有销售额以及商品和商店的数字编码。这仍然足以让我们强调一个基本的层次结构。我们需要做的就是在项目级别对系列进行分组，这样我们最终得到50个组(项目)，每个组由10个系列组成(每个商店销售的项目)；上图描述了一个组的示例。</p><p id="9be3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在经典图网络中，所有相关信息都存储在一个名为<strong class="lb iu">邻接矩阵</strong>的对象中。这是数据中所有关联的数字表示。我们上下文中的相邻矩阵可以通过根据所有商店中给定商品的销售序列计算的<strong class="lb iu">相关矩阵</strong>来检索。</p><p id="79df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">序列重新划分在我们的方法中是基本的，因为我们决定像递归架构一样处理数据，这也将是我们模型的一部分。</p><h1 id="3d6d" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">模型</h1><p id="8a4d" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我们的模型接收来自所有商店的<strong class="lb iu">销售序列和从相同序列获得的相邻矩阵</strong>作为输入。序列通过LSTM层，而相关矩阵由图卷积层处理。它们在<a class="ae ky" href="https://github.com/danielegrattarola/spektral" rel="noopener ugc nofollow" target="_blank"> Spektral </a>中实现，这是一个基于Tensorflow构建的很酷的图形深度学习库。它提供了各种类型的图层。我们使用最基本的一种，图卷积。它在可学习的权重、外部节点特征(与相邻矩阵一起提供)和我们的相关矩阵之间进行一系列卷积运算。不太可能，目前Spektral不支持Window，所以我必须手动提取我感兴趣的类并创建我的Python可执行文件。</p><p id="ca58" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的网络看起来如下:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="258a" class="my lw it mu b gy mz na l nb nc">def get_model():</span><span id="7e35" class="my lw it mu b gy nd na l nb nc">    opt = Adam(lr=0.001)</span><span id="24e3" class="my lw it mu b gy nd na l nb nc">    inp_seq = Input((sequence_length, 10))<br/>    inp_lap = Input((10, 10))<br/>    inp_feat = Input((10, X_train_feat.shape[-1]))</span><span id="fe08" class="my lw it mu b gy nd na l nb nc">    x = GraphConv(32, activation='relu')([inp_feat, inp_lap])<br/>    x = GraphConv(16, activation='relu')([x, inp_lap])<br/>    x = Flatten()(x)</span><span id="7ecc" class="my lw it mu b gy nd na l nb nc">    xx = LSTM(128, activation='relu',return_sequences=True)(inp_seq)<br/>    xx = LSTM(32, activation='relu')(xx)</span><span id="5724" class="my lw it mu b gy nd na l nb nc">    x = Concatenate()([x,xx])<br/>    x = BatchNormalization()(x)<br/>    x = Dropout(0.5)(x)<br/>    x = Dense(128, activation='relu')(x)<br/>    x = Dense(32, activation='relu')(x)<br/>    x = Dropout(0.3)(x)<br/>    out = Dense(1)(x)</span><span id="14fd" class="my lw it mu b gy nd na l nb nc">    model = Model([inp_seq, inp_lap, inp_feat], out)<br/>    model.compile(optimizer=opt, loss='mse', <br/>                  metrics=[tf.keras.metrics.RootMeanSquaredError()])</span><span id="00ac" class="my lw it mu b gy nd na l nb nc">    return model</span></pre><p id="4754" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如前所述，在开发递归网络时，数据的处理一如既往。这些序列是固定时间段内所有商店中所考虑商品的销售情况的集合。</p><p id="4ab7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的例子中，下一步是在相同的序列上计算商店间销售额的相关矩阵，它代表我们的相邻矩阵。与它们一起提供了一些手工制作的特征(如平均值、标准偏差、偏斜度、峰度、回归系数)，这些特征由我们根据每个序列的存储进行计算，代表我们在网络中的节点特征。</p><p id="65c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">给定样本协方差或相关矩阵，我们可以基于频谱卷积的一阶近似，应用拉普拉斯归一化来估计邻接矩阵，这使得能够使用高效的逐层传播规则(如这里的<a class="ae ky" href="https://arxiv.org/pdf/1609.02907.pdf" rel="noopener ugc nofollow" target="_blank">所述</a>和在<a class="ae ky" href="https://github.com/danielegrattarola/spektral" rel="noopener ugc nofollow" target="_blank">频谱</a>中实现的)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/2b7c22185fa0557143db32be2d8e9af2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-Vk5LPMBdsrtBMSCwXK-Ew.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">给定相关矩阵的拉普拉斯归一化过程</p></figure><p id="ba9c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">训练是用前两年的数据计算的，而剩下的两年分别用于验证和测试。我为每个商店训练了一个模型，所以我们最终得到了总共10个不同的神经网络。</p><p id="c17c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在训练程序结束时，悬挂物的预测由相关模型检索。误差计算为测试数据的RMSE，报告如下。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nf"><img src="../Images/f1d7d7184c4250b69772ac7b3fc05479.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3BL3JgyVMUEVGj2rxvp0aQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">RMSE为每个商店计算了测试集上的所有项目</p></figure><p id="1193" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">同样，很容易提取desired stores中商品的预测，直接操作我们的嵌套数据结构。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/1a8f31a61679758e5126002326da8a1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3xFC9FPzJtfbWaYcCO0BMQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">测试数据预测</p></figure><h1 id="54ba" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">摘要</h1><p id="1804" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在这篇文章中，我在一个不常见的场景中采用了图形神经网络，比如时间序列预测。在我们的深度学习模型中，图依赖将自身与循环部分相结合，试图提供更准确的预测。这种方法似乎很适合我们的问题，因为我们可以强调我们的数据中的基本层次结构，我们用相关矩阵进行数字编码。</p></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><p id="6c98" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://github.com/cerlymarco/MEDIUM_NoteBook" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">查看我的GITHUB回购</strong> </a></p><p id="2329" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">保持联系:<a class="ae ky" href="https://www.linkedin.com/in/marco-cerliani-b0bba714b/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a></p></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><p id="d426" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">参考文献</strong></p><ul class=""><li id="12c8" class="no np it lb b lc ld lf lg li nq lm nr lq ns lu nt nu nv nw bi translated"><a class="ae ky" href="https://github.com/danielegrattarola/spektral" rel="noopener ugc nofollow" target="_blank"> Spektral:带有Keras和Tensorflow的图形神经网络</a></li><li id="906e" class="no np it lb b lc nx lf ny li nz lm oa lq ob lu nt nu nv nw bi translated">图卷积网络的半监督分类</li></ul></div></div>    
</body>
</html>