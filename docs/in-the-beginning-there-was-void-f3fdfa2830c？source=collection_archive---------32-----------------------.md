# 开始时，有一片空白*

> 原文：<https://towardsdatascience.com/in-the-beginning-there-was-void-f3fdfa2830c?source=collection_archive---------32----------------------->

## 一个进化代码和意想不到的后果的故事

![](img/82e3f5284691eccf98ee81d6f374f322.png)

信用: [RawPixel](https://www.rawpixel.com/image/412442/free-illustration-image-pink-star-doodle)

为了纪念即将在谷歌发布的“[软件工程”，我强烈推荐它，我想我会讲述一个软件进化和功能蔓延如何出错的故事，虽然在旅程的每一步都感觉很好，但十年后的最终结果是一场具有惊人大爆炸半径的灾难。这是我与](https://www.oreilly.com/library/view/software-engineering-at/9781492082781/)[东尼·霍尔](https://en.wikipedia.org/wiki/Tony_Hoare)的[十亿美元错误](https://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare/)或者[丹尼斯里奇](https://en.wikipedia.org/wiki/Dennis_Ritchie)的[最昂贵的单字节错误](https://queue.acm.org/detail.cfm?id=2010365)的适度类比，而且，巧合的是，它同时涉及指针和以零结尾的数据结构。

这一切开始时都很天真。今年是 2009 年。我的一个同事有大量的[点积](https://en.wikipedia.org/wiki/Dot_product)需要加速，以提高一个大规模优化问题的可扩展性。当时，浮点计算并不是我们工作负载的常见瓶颈，我们也没有现成的解决方案可用:引入 BLAS 库是多余的，对于像我这样喜欢编写复杂的数学代码和摆弄矢量化英特尔指令的人来说，还有更简单、更有趣的事情可以做。

没问题，我将使用 [SSE 内部函数](https://software.intel.com/sites/landingpage/IntrinsicsGuide/)和一些手动调整的展开来快速实现点积。有一个非常聪明的方法来利用可怕的美丽的[达夫的设备](https://en.wikipedia.org/wiki/Duff%27s_device)，并在不滥用预处理器的情况下快速展开，代价是同样可耻的滥用 C 语法。我喜欢它。一个窍门是:SSE 指令喜欢对 16 字节对齐的数据进行操作。我们的工具链并不总是提供这种保证，编译器提示仍然是特定于编译器的。没问题:我将分配一个更大的缓冲区，并添加一个指向最近的 16 字节边界的数据指针来强制对齐。

但是，等等，如果我要对数据的分配方式加以限制，现在很容易通过正确的输入来确保契约得到执行。因此，让我们将这个裸指针包装成一个新的数据结构: *float ** 变成类似于*aligned _ scoped _ array<float>*的东西。嘿，这打开了新的可能性:当使用 SSE 指令时，处理边缘效应总是大部分实际代码，并且当进行线性代数时，通过将数据填充到 16 字节的倍数，很容易缓解，这与我的数据对齐技巧配合得很好。很好:让我们在数据结构中强制执行，因为我们现在控制它。完成了，现在一切都非常非常快。继续前进。

等等。有人说线性代数吗？我们可以批量处理那些点产品吗？到那时，我们真的进入了 BLAS 的领域，但是让我们不要仅仅为了一个基本的矩阵乘法而重写一切:只需要给数组添加另一个维度，一个执行 2D 乘法的函数，我们就可以开始了。对齐和填充数据也意味着我们可以遍历它，而无需任何进一步的指针间接寻址，这使得代码简短而优雅。当然，任何阅读过 BLAS 相关文献的人，特别是关于该主题的开创性的 [Goto 论文](https://www.cs.utexas.edu/users/pingali/CS378/2008sp/papers/gotoPaper.pdf)，都知道短小精悍可能会带来大量的性能问题，因为关于缓存性能的考虑可能会变得非常复杂。正确的答案可能是不要尝试推出你自己的实现，但是…这很有趣，感觉像是进步，对吗？

坚持住。你能对量子化的表示做同样的事情吗？哦，但是是的！事实上，我写了这篇[漂亮的论文](https://research.google.com/pubs/pub37631.html)关于混合无符号和有符号定点表示对于神经网络来说是如何令人惊讶地工作的。BLAS 在定点数学领域没有提供任何东西，但所有对齐和填充方面的考虑仍然适用。所以我将为 *int8*uint8* 产品添加一个专门化，我们就完成了。魔法。

现在，你可能开始看到一个模式。特性蔓延，每一步都有略微次优的决策，进展的幻觉和越来越难回头的决策。几年后，我的裸指针一次性包装器已经变成了一个成熟的触须矩阵库，学究式地称为 FastMatrix。它支持 x86、ARM 和 CUDA。处理*浮动*、*双*、 *int8* 、 *uint8* 、 *int16* 和 *int32* 。它可以为 Android 和 iOS 编译。它已经移动到我们共享代码库中的一个常规的' *util'* 目录中。它正被[深度学习代码库](https://static.googleusercontent.com/media/research.google.com/en//archive/large_deep_networks_nips2012.pdf)以及越来越多的项目使用，其中大多数我从未听说过。在我们的[谷歌范围分析](https://research.google/pubs/pub36575/)仪表板上，它在 CPU 周期最大消耗者的名单上也占据着一个令人尊敬的位置。有什么不喜欢的？

好吧。它还有一个糟糕的、令人抓狂的不一致的 API，部分原因是不同的硬件供应商针对不同的数据类型和布局进行了优化，而我没能抽象出那些实现细节。它还陷入了一个进化的死胡同:仅仅为了节省几个 CPU 周期和代码行而强制控制数据布局被证明是一个糟糕的想法，因为在它通常强制用户经历的所有数据移动中，大部分好处都消失了。它的存在阻碍了更好支持、更全面、BLAS 感知的解决方案的进展，例如令人敬畏的 Eigen 库，它同时获得了对定点操作的支持。它的 CUDA 端口充满了反模式，当我看到在代码库中的其他地方进行剪切和粘贴时，我很害怕。我们还错误地尝试支持跨指令集的一些算法的动态调度，如果调用者不小心，可能会导致错误平台的编译单元泄漏到一个人的二进制文件中，并导致难以理解的崩溃，这几乎不可能追溯到最初的根本原因，因为二进制文件甚至不必调用被感染的违规代码。哎呀。在广告 [SRE](https://landing.google.com/sre/) 来敲门之前，一切都是娱乐和游戏。

我有没有提到过谷歌在我第一次申请软件工程师时拒绝了我？他们可能说得有道理。那个图书馆需要消亡。

但到那时，所有这些主要的设计缺陷也带来了短期回报:速度相当快。它在那里。由于有点松散，类似 C 的 API，很容易添加功能，或复制粘贴它。消除一些最糟糕的维护噩梦可能会花费数千个 CPU 内核，或者数百个软件工程师小时:对性能敏感的代码极难推理，因为尽管可以安全地假设它具有不错的正确性覆盖率，但性能覆盖率很难实现:10%的速度回归可能只花费一微秒或使数据中心过载，并且您可能无法分辨出差异，直到有人在提交更改几个月后部署了包含您的更改的二进制文件。那时，我看不到的其他库已经开始依赖它，包括它最粗糙的实现细节，我已经达到了疫情级别的感染。

现在是 2020 年。已经十年了。这个怪物还没有完全死去，尽管我已经砍下了它的许多头。最近，该图书馆的死忠粉丝极大地推动了它的消亡，这位死忠粉丝已经决定离开该公司。不要告诉他们:我很高兴地在同一天删除了他们所有的代码。在我在这里的 12 年里，我已经自豪地从我们的库中删除了超过 150 万行代码，然而这些卷须顽固地保留了下来。回想起来，我最近几年做的最好的决定是坚持让 [TensorFlow](http://tensorflow.org/) 不依赖于任何一个。

Donald Knuth 有一句名言:直到最后一个用户死去，代码才会被完全调试。显然，Knuth 不在谷歌工作，否则他可能会说“……它的最后一个用户*和*他们所有的同事……”。即使代码死了，它的一些反模式仍然存在，或者在人们的头脑中，或者通过传统的复制方式。[前述书的合著者 Titus Winters](https://twitter.com/tituswinters?lang=en) 喜欢说“软件工程是随着时间的推移而集成的编程”一个问题是，所涉及的时间常数可以用几十年来衡量，很少有人在任何工作岗位上呆得足够长，以至于看到自己的错误暴露出来。局部地、渐进地做出的决策会很快毒害整个代码库，并且变得难以回头，特别是当人们转向其他更重要的问题时。

## 乐章结尾部

几年后，当我开始研究[dist faith](https://static.googleusercontent.com/media/research.google.com/en//archive/large_deep_networks_nips2012.pdf)代码库时，我立即注意到一些令人惊讶的事情:保存神经网络的最内部结构是一个裸露的“*空洞** ，仅此而已。我查了一下是谁写了那篇异端邪说，当然，结果是[杰夫·迪恩](https://en.wikipedia.org/wiki/Jeff_Dean_(computer_scientist))。哦。我胆怯地问:“杰夫……但是为什么呢？”？？?'他的回答很简单:“嗯，我们还不知道我们在做什么，所以我们不要在数据结构中加入任何我们无法回避的假设。果然，在这种情况下使用正确的数据布局是非常不明显的:您可以使用它来优化 CPU 上的正向推理，但它会影响训练期间反向传递的速度，并且反向传递的成本大约是正向传递的两倍。但在生产中，你大多只是运行推理，所以这可能是正确的权衡？这要看情况，因为在 GPU 上几乎正好相反。这些权衡需要一些时间来解决，最终我们编写了一个类型系统，一个布局，并删除了裸露的指针。教训？有时候，让 Hyrum 定律(即将出版的书的另一位著名合著者)对你有利会更好，推迟 API 合同，直到你理解你的用户将如何(ab)使用它们，而不是过早地承诺一个 API 并成为它的受害者。