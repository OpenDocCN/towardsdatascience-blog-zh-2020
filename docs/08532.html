<html>
<head>
<title>10 Reasons Amazon SageMaker is great for Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">亚马逊SageMaker非常适合机器学习的10个理由</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-makes-aws-sagemaker-great-for-machine-learning-c8a42c208aa3?source=collection_archive---------10-----------------------#2020-06-21">https://towardsdatascience.com/what-makes-aws-sagemaker-great-for-machine-learning-c8a42c208aa3?source=collection_archive---------10-----------------------#2020-06-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="72c1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">学习SageMaker使构建、训练和部署您的ML模型的过程更加容易。</h2></div><p id="3247" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Amazon Web Services是世界上最常用的云提供商，数据科学家越来越需要像DevOps人员一样了解云服务。数据科学家需要建立和使用数据管道，使用数据仓库，在云中训练和托管ML模型等。在这篇博客中，我们将专注于机器学习模型的开发。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/347006c8ed60bf9ad3a98ce846a3b2c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RoFDNSsRxBrvZKsy2vvZpQ.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">亚马逊SageMaker使得在全球范围内扩展ML模型成为可能[ <a class="ae lu" href="https://unsplash.com/photos/Q1p7bh3SHj8" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="e668" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae lu" href="https://aws.amazon.com/sagemaker/" rel="noopener ugc nofollow" target="_blank">亚马逊SageMaker </a>是AWS提供的一项强大服务，用于构建、训练和部署你的机器学习模型。它由AWS于2017年发布，并迅速获得了很大的人气，然而，没有多少数据科学家在使用这项服务，因为它相当新。在这篇博客中，我们将讨论SageMaker以及如何在您的机器学习项目中使用它——不仅用于构建和训练模型，还用于部署您的模型以供成千上万的用户使用。</p><p id="3b99" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">SageMaker的一个伟大之处是它的模块化设计。如果您喜欢在其他地方进行培训，而只是使用SageMaker进行部署，那么您可以这样做。如果您只是喜欢训练您的模型并使用其超参数调整功能，您也可以这样做。这是我真正喜欢SageMaker的地方。考虑到这一点，让我们开始了解亚马逊SageMaker。我们将涵盖SageMaker帮助的3个广泛领域:模型构建、模型培训和模型部署——以及每个领域的3个优势。</p><h1 id="a0cd" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">模型结构</h1><p id="318d" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">在最基本的层面上，SageMaker提供了<strong class="kk iu"> Jupyter笔记本</strong>。您可以使用这些笔记本来构建、培训和部署ML模型。许多数据科学家使用这些<a class="ae lu" href="https://jupyter.org" rel="noopener ugc nofollow" target="_blank">笔记本</a>进行探索性数据分析和模型构建阶段。您可能想开始使用类似熊猫的东西来探索数据集—您有多少丢失的行？数据的分布是什么样的？有没有数据不平衡之类的？您可以构建许多不同的模型，从来自<a class="ae lu" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> Scikit Learn </a>的逻辑回归或决策树到来自<a class="ae lu" href="https://www.tensorflow.org/guide/keras/sequential_model" rel="noopener ugc nofollow" target="_blank"> Keras </a>的深度学习模型，并快速获得基准性能。因此，当您使用SageMaker时，笔记本界面保持不变，没有任何区别！</p><p id="ea1f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">那么你可能会问的一个问题是→使用SageMaker笔记本而不是本地或者某处EC2服务器上托管的笔记本有什么优势？嗯，SageMaker允许您决定您喜欢的机器类型，因此您不需要管理任何复杂的ami或安全组——这使得入门非常容易。SageMaker还提供对GPU和具有大量RAM的大型机器的访问，这在本地设置中是不可能的。</p><p id="29fc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们把SageMaker对于建模的所有优势罗列出来:<br/> <strong class="kk iu"> 1。</strong>从2核和4GB的机器到96核和768GB RAM的机器，您只需点击一下按钮就可以访问这些机器，笔记本电脑就托管在这些机器中，无需您付出任何额外的努力。您不必管理任何安全组或ami，也不必管理机器的IP地址或任何东西。下面列出了不同类型的笔记本电脑，以及全天候运行时每月的价格。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/c6a15a2520bdc8c951656894af154f5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*p07feKxZJFYQRaKQI0fMHA.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">不同AWS实例的CPU/GPU数量、RAM和定价[ <a class="ae lu" href="https://aws.amazon.com/sagemaker/pricing/" rel="noopener ugc nofollow" target="_blank">定价</a>、<a class="ae lu" href="http://Source 2" rel="noopener ugc nofollow" target="_blank">计算</a></p></figure><p id="f213" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> 2。第二个</strong>优势是它附带预配置的环境——您不需要单独安装TensorFlow或其他公共库。</p><p id="4ccc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> 3。</strong>另一个优势是，您可以将您的Github帐户与这些笔记本相关联，这样您就可以在构建模型时继续使用Github repo，而无需担心下载和上传文件以进行版本控制！这可通过SageMaker笔记本电脑的JupyterLab界面获得。我真的很喜欢这个功能。</p><h1 id="b065" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">模特培训</h1><p id="4dde" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">下一步是模特训练。您可以使用相同的笔记本来训练模型，并在S3存储模型工件和文件，然后移动到模型部署的下一步。但是，如果你正在做一个需要几个小时训练的模型，比如说，带有复杂LSTM模型的语言翻译模型，该怎么办呢？在这种情况下，您可以从Sagemaker notebook本身调用一个GPU来训练模型，而不是使用可能在小型实例上运行的notebook本身。这样，您可以在运行笔记本电脑的同时节省成本，因为大多数任务都是围绕构建、检查和探索模型进行的。同样，对于培训模型培训本身，您可以使用另一台机器，该机器不同于用于运行笔记本的机器。</p><p id="70b3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以使用SageMaker进行模型训练的优势有:<br/> <strong class="kk iu"> 1 .</strong>你可以在非GPU t2.medium上运行笔记本电脑，价格约为40美元/月，但你可以使用p2.xlarge GPU实例，价格约为每小时1.2美元——只有用于实际训练模型的秒数才会向你收费。这可以节省大量成本。通常你会用GPU启动EC2服务器——安装所有的东西，运行你的脚本，并且必须记住关闭它。在这里，你是自动按秒计费的实际训练时间。所以重复一遍，你可以使用一个便宜的实例来托管你的笔记本电脑，它可以运行24小时，不会花很多钱，但然后使用GPU来训练笔记本电脑本身的模型。</p><p id="9ba5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> 2。</strong>sage maker用于模型训练的另一个特性是超参数调优。您可以创建超参数调整作业，以便您的模型可以在一夜之间调整，并在早上向您显示最佳超参数。</p><p id="fdd1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> 3。</strong>另一个优势是你可以使用亚马逊自己的预建模型，这些模型已经过高度优化，可以在AWS服务上运行。这些模型是预先构建的，您不需要做太多的工作来构建和检查模型。您可以使用预构建的XGBoost或LDA或PCA或Seq to Seq模型，所有这些都可以通过名为<code class="fe mt mu mv mw b">sagemaker</code>的高级Python SDK获得。这是一个很好的机会来提一下，也有一个低级别的SDK来访问SageMaker，它是使用<code class="fe mt mu mv mw b">boto3</code> — <code class="fe mt mu mv mw b">boto3</code>编写的，是访问Python中其他AWS服务的常用方法。</p><h1 id="1603" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">模型部署</h1><p id="2226" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">最后，我最喜欢使用SageMaker的原因是为了模型部署。即使您的模型可能不太复杂，并且可以在您的本地机器上轻松地进行训练，您仍然需要在某个地方托管该模型。然后是关于扩展模型的问题→你能建立一个服务来服务你的ML输出，可以被成百上千的用户同时使用吗？潜伏期呢？如果需求突然激增怎么办？对于所有这些，SageMaker非常棒，因为它允许您在端点后托管模型。这个端点是一个运行在某个隐藏的EC2服务器上的服务。当然，您仍然需要选择您喜欢的实例类型。但是您不需要担心设置这个服务器——在创建端点的过程中，您可以选择诸如自动扩展组、您想要多少个服务器等等。</p><p id="e81c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以使用SageMaker进行模型部署的优势是:<br/> <strong class="kk iu"> 1。</strong>在一个端点中托管ML模型——然后你可以从任何其他用通用语言编写的代码中调用这个端点。你也可以从Lambda函数中调用这个模型。这样，您的web应用程序就可以调用Lambda函数，该函数可以调用模型端点。如果您在某个地方托管自己的API，那么API代码可以调用这个端点。您还可以配置API Gateway来接收HTTP请求，该请求调用Lambda函数，然后该函数调用SageMaker端点，如下所示:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi mx"><img src="../Images/d4e48ecb9fe607031d844b828674f85c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lrDEhRQLehB6SF50byQqpQ.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">使用API网关、Lambda和SageMaker端点部署ML模型</p></figure><p id="86bc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意:Amazon将SageMaker模型托管在一个一天24小时运行的物理服务器上——服务器不会根据收到请求的时间而打开/关闭。因此，SageMaker在无服务器领域处于EC2和Lambda的中间。服务器像EC2一样一直运行，但是你不能像Lambda一样配置和管理它。</p><p id="462b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> 2。</strong>另一个很大的优势是你可以在同一个端点上托管多个模型。为此，您需要创建一个定制的Docker容器映像。这相当复杂，但是AWS的Github中有启动代码。您将需要创建您自己的映像并在ECR中托管它，然后在托管多个模型时使用该映像。多模型端点允许您托管多个模型，并且实例被预先配置为处理多个模型的负载，而您不必担心这方面的开发。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi my"><img src="../Images/dbd2303cfae0bcbe5cf569613c4d90de.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*-O5TVf-Mqi8_6RxWw6RiAg.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">多型号终端可以为您节省大量成本</p></figure><p id="3a3d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> 3。</strong>您所有的日志都可以轻松存储在CloudWatch日志中。您不需要创建自己的日志管道，这是另一个优势。您可以监控机器上的负载，并根据需求扩展机器。</p></div><div class="ab cl mz na hx nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="im in io ip iq"><p id="370f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但是，有什么问题呢？SageMaker价格昂贵，比AWS的同等EC2服务器选项贵30%到40%。一个t2.medium的价格是33美元/月，但是SageMaker的同等ml.t2.medium的价格是40美元/月。但我觉得所有这些优势在总体上造成了很大的成本差异——你只需为你在昂贵的服务器上使用的模型训练时间按秒收费。这让我想到了第十个优势，即亚马逊不断创新，并带来了新功能，如<a class="ae lu" href="https://aws.amazon.com/blogs/aws/amazon-sagemaker-studio-the-first-fully-integrated-development-environment-for-machine-learning/" rel="noopener ugc nofollow" target="_blank">SageMaker Studio</a>——因此，当您在模型管道中使用sage maker时，您将能够获得所有这些优势。</p><p id="2b0f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我觉得它可能会遇到SageMaker是一个神奇的药丸，可以解决你可能遇到的每个ML问题。我要说，这不是一个神奇的药丸，而是一个非常有用的工具。您仍然需要使用“handler”函数来配置预处理和后处理管道，并弄清楚您想要如何为多模型端点配置Docker容器。所有这一切都不容易，AWS文档也不是那么好——因此，我建议您从小处着手，部署MNIST端点，然后从那里开始构建。SageMaker是一个很好的工具，但我想描绘出完整的画面——很高兴听到你如何使用它，也让我知道我是否在这一集错过了什么。通过LinkedIn或T2的电子邮件或下面的评论联系我。祝你的ML之旅一切顺利！</p></div><div class="ab cl mz na hx nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="im in io ip iq"><p id="3517" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你更喜欢听这个博客的音频版本，我也为这个博客录了一段播客——在这里我会更详细地介绍每一点。你可以在<a class="ae lu" href="https://podcasts.apple.com/us/podcast/the-data-life-podcast/id1453716761" rel="noopener ugc nofollow" target="_blank">苹果播客</a>、<a class="ae lu" href="https://open.spotify.com/show/6xWi36lOBHpHRabi9eO1Bj" rel="noopener ugc nofollow" target="_blank"> Spotify </a>或<a class="ae lu" href="https://anchor.fm/the-data-life-podcast" rel="noopener ugc nofollow" target="_blank"> Anchor.fm </a>上听，或者在我最喜欢的播客应用之一:<a class="ae lu" href="https://overcast.fm/itunes1453716761/the-data-life-podcast" rel="noopener ugc nofollow" target="_blank">阴天</a>上听。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ng"><img src="../Images/f99f77555db0b2cdd1b41238d549cc55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q01K-PY_27qeA6TjFGl3VA.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated"><a class="ae lu" href="https://podcasts.apple.com/us/podcast/the-data-life-podcast/id1453716761" rel="noopener ugc nofollow" target="_blank">我谈论类似话题的播客</a></p></figure><p id="7a2d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于评论/反馈/问题，或者如果你认为我在这一集里错过了什么，请通过<a class="ae lu" href="mailto:sanket@omnilence.com" rel="noopener ugc nofollow" target="_blank">sanket@omnilence.com</a>或LinkedIn:<a class="ae lu" href="https://www.linkedin.com/in/sanketgupta107/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/sanketgupta107/</a>联系我</p><p id="b797" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">资源:<br/> 1。<a class="ae lu" href="https://aws.amazon.com/blogs/machine-learning/build-a-serverless-frontend-for-an-amazon-sagemaker-endpoint/" rel="noopener ugc nofollow" target="_blank">亚马逊SageMaker端点</a>的无服务器前端<br/> 2。<a class="ae lu" href="https://aws.amazon.com/blogs/machine-learning/save-on-inference-costs-by-using-amazon-sagemaker-multi-model-endpoints/" rel="noopener ugc nofollow" target="_blank">多模型端点</a> <br/> 3。<a class="ae lu" href="https://aws.amazon.com/blogs/machine-learning/amazon-sagemaker-automatic-model-tuning-becomes-more-efficient-with-warm-start-of-hyperparameter-tuning-jobs/" rel="noopener ugc nofollow" target="_blank">超参数调整作业</a></p></div></div>    
</body>
</html>