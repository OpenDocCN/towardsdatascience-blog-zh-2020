<html>
<head>
<title>Vision-based moon-tracker</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于视觉的月球跟踪器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/vision-based-moon-tracker-a39ab03b14?source=collection_archive---------67-----------------------#2020-05-22">https://towardsdatascience.com/vision-based-moon-tracker-a39ab03b14?source=collection_archive---------67-----------------------#2020-05-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><blockquote class="jq jr js"><p id="dfbd" class="jt ju jv jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr im bi translated">帮助你基于<em class="it">Mask-RCNN</em>T3】创建<strong class="jw iu">月球追踪器(图片&amp;视频)的完整指南。改变数据集，标记你选择的物体，你就可以创建你自己的物体跟踪器了！没有必要为你的第一个定制的追踪器四处游荡。</strong></p></blockquote><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi ks"><img src="../Images/e6e6d32428300616617e6e3138f67ccb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*QxcURbRg9goh8nZUDqmdtw.gif"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">一帧一帧的月球追踪器(<em class="li">图片作者</em>)</p></figure><h1 id="98b0" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">(追踪器的)为什么部分</h1><blockquote class="jq jr js"><p id="25c5" class="jt ju jv jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr im bi translated">我们都或多或少地被月亮的美丽所吸引。夜空中最大最亮的物体。</p></blockquote><p id="a0da" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mh kg kh ki mi kk kl km mj ko kp kq kr im bi translated">有很多<strong class="jw iu">app</strong>可以追踪月球的运动。关于月亮，没有什么是不可预测的。从这个角度来看，月球是简易追踪器的理想选择。</p><p id="f0ba" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mh kg kh ki mi kk kl km mj ko kp kq kr im bi translated">但是，现在从更广泛的意义上来说，一个智能物体追踪器可以安装在一个固定的位置，或者安装在一个移动的车辆甚至是卫星上。您相机的<strong class="jw iu">视野</strong>可能不同。如果物体移动，那么理想情况下，您的算法应该向摄像设备发出准确的 PTZ 命令(<em class="jv">方向和移动速率</em>)来跟踪感兴趣的物体。很复杂。</p><p id="fd50" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mh kg kh ki mi kk kl km mj ko kp kq kr im bi translated">现在让我们简化一下。</p><p id="e9be" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mh kg kh ki mi kk kl km mj ko kp kq kr im bi translated">从算法的角度来看，有两件事很重要:</p><ol class=""><li id="bd15" class="mk ml it jw b jx jy kb kc mh mm mi mn mj mo kr mp mq mr ms bi translated"><em class="jv">(运动)物体随时间(实时)检测和定位的精度。</em></li><li id="94f8" class="mk ml it jw b jx mt kb mu mh mv mi mw mj mx kr mp mq mr ms bi translated"><em class="jv">速度/帧率处理。否则，当你发现的时候，物体可能已经到达了你(相机)够不到的地方。</em></li></ol><h1 id="fd3d" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">我们要做什么部分</h1><p id="ea9a" class="pw-post-body-paragraph jt ju it jw b jx my jz ka kb mz kd ke mh na kh ki mi nb kl km mj nc kp kq kr im bi translated">由于这更多的是一篇技术文章，我只是分享这个项目的关键，来帮助你一步一步地创建一个<strong class="jw iu">月球追踪器</strong>(或者你选择的任何定制对象)。假设你有 mask-RCNN 的基础知识，即使你没有，你仍然可以遵循这个。</p><p id="72b9" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mh kg kh ki mi kk kl km mj ko kp kq kr im bi translated">基于 Mask-RCNN 的简单<a class="ae nd" href="https://github.com/praveenkottayi/moon-tracker" rel="noopener ugc nofollow" target="_blank"> <strong class="jw iu">月球跟踪器</strong> </a>。</p><h1 id="ed28" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">现在，怎么做的部分</h1><h1 id="9535" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated"><strong class="ak">第一步:设置环境并加载必要的软件包。</strong></h1><p id="ce68" class="pw-post-body-paragraph jt ju it jw b jx my jz ka kb mz kd ke mh na kh ki mi nb kl km mj nc kp kq kr im bi translated">使用 Google <a class="ae nd" href="http://colab.research.google.com" rel="noopener ugc nofollow" target="_blank"> colab </a>是可选的。这是一个很好的选择:</p><ol class=""><li id="717d" class="mk ml it jw b jx jy kb kc mh mm mi mn mj mo kr mp mq mr ms bi translated"><em class="jv">如果数据不敏感</em></li><li id="e791" class="mk ml it jw b jx mt kb mu mh mv mi mw mj mx kr mp mq mr ms bi translated"><em class="jv">如果你有很多数据</em></li><li id="753f" class="mk ml it jw b jx mt kb mu mh mv mi mw mj mx kr mp mq mr ms bi translated"><em class="jv">如果你没有本地 GPU </em></li></ol><pre class="kt ku kv kw gt ne nf ng nh aw ni bi"><span id="969f" class="nj lk it nf b gy nk nl l nm nn"><strong class="nf iu">from</strong> <strong class="nf iu">google.colab</strong> <strong class="nf iu">import</strong> drive<br/>drive.mount('/content/drive/')</span><span id="5d38" class="nj lk it nf b gy no nl l nm nn"><strong class="nf iu">import</strong> <strong class="nf iu">os</strong><br/>os.chdir("drive/My Drive/Colab Notebooks/moon-tracker/")</span><span id="9551" class="nj lk it nf b gy no nl l nm nn">---------------------------------------------------------</span><span id="4ca9" class="nj lk it nf b gy no nl l nm nn"><strong class="nf iu">from</strong> <strong class="nf iu">mrcnn.config</strong> <strong class="nf iu">import</strong> Config<br/><strong class="nf iu">from</strong> <strong class="nf iu">mrcnn</strong> <strong class="nf iu">import</strong> model <strong class="nf iu">as</strong> modellib<br/><strong class="nf iu">from</strong> <strong class="nf iu">mrcnn</strong> <strong class="nf iu">import</strong> visualize<br/><strong class="nf iu">import</strong> <strong class="nf iu">mrcnn</strong><br/><strong class="nf iu">from</strong> <strong class="nf iu">mrcnn.utils</strong> <strong class="nf iu">import</strong> Dataset<br/><strong class="nf iu">from</strong> <strong class="nf iu">mrcnn.model</strong> <strong class="nf iu">import</strong> MaskRCNN<br/><strong class="nf iu">import</strong> <strong class="nf iu">numpy</strong> <strong class="nf iu">as</strong> <strong class="nf iu">np</strong><br/><strong class="nf iu">from</strong> <strong class="nf iu">numpy</strong> <strong class="nf iu">import</strong> zeros<br/><strong class="nf iu">from</strong> <strong class="nf iu">numpy</strong> <strong class="nf iu">import</strong> asarray<br/><strong class="nf iu">import</strong> <strong class="nf iu">colorsys</strong><br/><strong class="nf iu">import</strong> <strong class="nf iu">argparse</strong><br/><strong class="nf iu">import</strong> <strong class="nf iu">imutils</strong><br/><strong class="nf iu">import</strong> <strong class="nf iu">random</strong><br/><strong class="nf iu">import</strong> <strong class="nf iu">cv2</strong><br/><strong class="nf iu">import</strong> <strong class="nf iu">os</strong><br/><strong class="nf iu">import</strong> <strong class="nf iu">time</strong><br/><strong class="nf iu">from</strong> <strong class="nf iu">matplotlib</strong> <strong class="nf iu">import</strong> pyplot<br/><strong class="nf iu">from</strong> <strong class="nf iu">matplotlib.patches</strong> <strong class="nf iu">import</strong> Rectangle<br/><strong class="nf iu">from</strong> <strong class="nf iu">keras.models</strong> <strong class="nf iu">import</strong> load_model<br/>%matplotlib inline<br/><strong class="nf iu">from</strong> <strong class="nf iu">os</strong> <strong class="nf iu">import</strong> listdir<br/><strong class="nf iu">from</strong> <strong class="nf iu">xml.etree</strong> <strong class="nf iu">import</strong> ElementTree</span></pre><p id="4925" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mh kg kh ki mi kk kl km mj ko kp kq kr im bi translated">您可以选择将数据保存在驱动器上，然后像上面一样装载到您的环境中。此外，您可以选择在会议期间直接上传，但只有在会议结束后才能上传。</p><h1 id="fd76" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated"><strong class="ak">第二步:准备好你的训练和测试数据集。</strong></h1><p id="2a40" class="pw-post-body-paragraph jt ju it jw b jx my jz ka kb mz kd ke mh na kh ki mi nb kl km mj nc kp kq kr im bi translated"><em class="jv">即您的图像和相应的对象遮罩。</em></p><p id="484f" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mh kg kh ki mi kk kl km mj ko kp kq kr im bi translated">好吧，如果你没有，为了创建掩码并把它作为一个 XML 文件，你可以使用 Labellmg。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi np"><img src="../Images/b2dcfb6c91e6166e96a0c02e061634bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8CPbmH2J58BuQToZDDV8yg.jpeg"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">(<em class="li">图片作者</em>)</p></figure><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi nq"><img src="../Images/e675343c4eddc9569e4083366990690a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9BUHAVcu5h5r1TnIrEh1zQ.jpeg"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">(<em class="li">图片作者</em>)</p></figure><p id="e7f2" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mh kg kh ki mi kk kl km mj ko kp kq kr im bi translated"><em class="jv">训练和测试集的读取是基于你保存和生成 XML 文件的方式。参考代码，如果你喜欢下面的结构。</em></p><h2 id="0f65" class="nj lk it bd ll nr ns dn lp nt nu dp lt mh nv nw lx mi nx ny mb mj nz oa mf ob bi translated">月球追踪器</h2><h2 id="1135" class="nj lk it bd ll nr ns dn lp nt nu dp lt mh nv nw lx mi nx ny mb mj nz oa mf ob bi translated">— — — —月亮 _ 面具 _ 完整</h2><h2 id="3f38" class="nj lk it bd ll nr ns dn lp nt nu dp lt mh nv nw lx mi nx ny mb mj nz oa mf ob bi translated">— — — — — —图片(所有图片 jpg/png 等)</h2><h2 id="3d63" class="nj lk it bd ll nr ns dn lp nt nu dp lt mh nv nw lx mi nx ny mb mj nz oa mf ob bi translated">— — — — — —注释(图像遮罩的 XML 文件)</h2><pre class="kt ku kv kw gt ne nf ng nh aw ni bi"><span id="2535" class="nj lk it nf b gy nk nl l nm nn"><strong class="nf iu">class</strong> <strong class="nf iu">MoonDataset</strong>(Dataset):<br/>    <em class="jv"># load the dataset definitions</em><br/>    <strong class="nf iu">def</strong> load_dataset(self, dataset_dir, is_train=<strong class="nf iu">True</strong>):<br/>        <br/>        <em class="jv"># Add classes. We have only one class to add.</em><br/>        self.add_class("dataset", 1, "moon")        <br/>        <br/>        <em class="jv">####################################################################</em><br/>        <em class="jv"># define data locations for images and annotations</em><br/>        images_dir = 'moon_mask_full/images/'<br/>        annotations_dir = 'moon_mask_full/annotations/'<br/>        <em class="jv">####################################################################</em><br/>        <br/>        annot_list = []<br/>        <strong class="nf iu">for</strong> annot <strong class="nf iu">in</strong> listdir(annotations_dir):<br/>              annot_list.append(annot.split('.')[0])<br/>                <br/>        <em class="jv"># Iterate through all files in the folder to </em><br/>        <em class="jv">#add class, images and annotaions </em><br/>        <strong class="nf iu">for</strong> filename <strong class="nf iu">in</strong> listdir(images_dir):<br/>            <br/>            <br/>            <em class="jv"># extract image id for all formats like jpg / png / jpeg </em><br/>            image_id =    filename.split('.')[0]    <br/>            <em class="jv">#print(image_id)</em><br/>            <br/>            <em class="jv"># There can be a chance that you don't created xml file for all the images. </em><br/>            <em class="jv"># To filter images which have corresponding mask XML file.</em><br/>                <br/>            <strong class="nf iu">if</strong> image_id != '' <strong class="nf iu">and</strong> image_id <strong class="nf iu">in</strong> annot_list:<br/>              <em class="jv"># setting image file</em><br/>              img_path = images_dir + filename<br/>              <em class="jv">#print(img_path)</em><br/>              <em class="jv"># setting annotations file</em><br/>              ann_path = annotations_dir + image_id + '.xml'<br/>              <em class="jv">#print(ann_path)</em><br/>              <em class="jv"># adding images and annotations to dataset</em><br/>              self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)<br/>    <br/>    <em class="jv"># extract bounding boxes from an annotation file</em><br/>    <strong class="nf iu">def</strong> extract_boxes(self, filename):<br/>        <br/>        <em class="jv"># load and parse the file</em><br/>        tree = ElementTree.parse(filename)<br/>        <em class="jv"># get the root of the document</em><br/>        root = tree.getroot()<br/>        <em class="jv"># extract each bounding box</em><br/>        boxes = list()<br/>        <strong class="nf iu">for</strong> box <strong class="nf iu">in</strong> root.findall('.//bndbox'):<br/>            xmin = int(box.find('xmin').text)<br/>            ymin = int(box.find('ymin').text)<br/>            xmax = int(box.find('xmax').text)<br/>            ymax = int(box.find('ymax').text)<br/>            coors = [xmin, ymin, xmax, ymax]<br/>            boxes.append(coors)<br/>        <br/>        <em class="jv"># extract image dimensions</em><br/>        width = int(root.find('.//size/width').text)<br/>        height = int(root.find('.//size/height').text)<br/><br/>        <em class="jv">#print(boxes, width, height)</em><br/>        <strong class="nf iu">return</strong> boxes, width, height<br/>    <br/>    <em class="jv"># load the masks for an image</em><br/>    <em class="jv">"""Generate instance masks for an image.</em><br/><em class="jv">       Returns:</em><br/><em class="jv">        masks: A bool array of shape [height, width, instance count] with</em><br/><em class="jv">            one mask per instance.</em><br/><em class="jv">        class_ids: a 1D array of class IDs of the instance masks.</em><br/><em class="jv">     """</em><br/>    <strong class="nf iu">def</strong> load_mask(self, image_id):<br/>        <em class="jv"># get details of image</em><br/>        info = self.image_info[image_id]<br/>        <em class="jv">#print(info)</em><br/>        <em class="jv"># define anntation  file location</em><br/>        path = info['annotation']<br/>        <br/>        <em class="jv"># load XML</em><br/>        boxes, w, h = self.extract_boxes(path)<br/>       <br/>        <em class="jv"># create one array for all masks, each on a different channel</em><br/>        masks = zeros([h, w, len(boxes)], dtype='uint8')<br/>        <br/>        <em class="jv"># create masks</em><br/>        class_ids = list()<br/>        <strong class="nf iu">for</strong> i <strong class="nf iu">in</strong> range(len(boxes)):<br/>            box = boxes[i]<br/>            row_s, row_e = box[1], box[3]<br/>            col_s, col_e = box[0], box[2]<br/>            masks[row_s:row_e, col_s:col_e, i] = 1<br/>            class_ids.append(self.class_names.index('moon'))<br/>        <strong class="nf iu">return</strong> masks, asarray(class_ids, dtype='int32')<br/>    <br/>    <em class="jv"># load an image reference</em><br/>    <em class="jv">"""Return the path of the image."""</em><br/>    <strong class="nf iu">def</strong> image_reference(self, image_id):<br/>        info = self.image_info[image_id]<br/>        <em class="jv">#print(info)</em><br/>        <strong class="nf iu">return</strong> info['path']</span></pre><h1 id="4d03" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated"><strong class="ak">第三步:下载 COCO weights '<em class="li">mask _ rcnn _ COCO . H5</em>'并保存在主文件夹中。</strong></h1><p id="2605" class="pw-post-body-paragraph jt ju it jw b jx my jz ka kb mz kd ke mh na kh ki mi nb kl km mj nc kp kq kr im bi translated">链接:<a class="ae nd" href="https://github.com/matterport/Mask_RCNN/releases" rel="noopener ugc nofollow" target="_blank">https://github.com/matterport/Mask_RCNN/releases</a></p><pre class="kt ku kv kw gt ne nf ng nh aw ni bi"><span id="7a5c" class="nj lk it nf b gy nk nl l nm nn"><em class="jv">#load the weights for COCO</em><br/>model.load_weights('mask_rcnn_coco.h5', <br/>                   by_name=<strong class="nf iu">True</strong>, <br/>                   exclude=["mrcnn_class_logits", "mrcnn_bbox_fc",  "mrcnn_bbox", "mrcnn_mask"])</span></pre><h1 id="914d" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated"><strong class="ak">步骤 4:调整训练和学习参数，以微调模型。</strong></h1><p id="e524" class="pw-post-body-paragraph jt ju it jw b jx my jz ka kb mz kd ke mh na kh ki mi nb kl km mj nc kp kq kr im bi translated">使用配置、learning_rate、epoch 和 layers ('all '、' 3+'、' 4+'、' heads ')来获得更好的准确性。</p><pre class="kt ku kv kw gt ne nf ng nh aw ni bi"><span id="aa4c" class="nj lk it nf b gy nk nl l nm nn"><strong class="nf iu">class</strong> <strong class="nf iu">moon_detector_Config</strong>(Config):<br/>    <em class="jv"># give the configuration a recognizable name</em><br/>    NAME = "moon_detector_Config"<br/> <br/>    <em class="jv"># set the number of GPUs to use along with the number of images</em><br/>    <em class="jv"># per GPU</em><br/>    GPU_COUNT = 1<br/>    IMAGES_PER_GPU = 1<br/> <br/>    <em class="jv"># number of classes (we would normally add +1 for the background)</em><br/>     <em class="jv"># moon + BG</em><br/>    NUM_CLASSES = 1+1<br/>   <br/>    <em class="jv"># Number of training steps per epoch</em><br/>    STEPS_PER_EPOCH = 50<br/>    <br/>    <em class="jv"># Learning rate</em><br/>    LEARNING_RATE=0.001<br/>    <br/>    <em class="jv"># Skip detections with &lt; 90% confidence</em><br/>    DETECTION_MIN_CONFIDENCE = 0.95<br/>    <br/>    <em class="jv"># setting Max ground truth instances</em><br/>    MAX_GT_INSTANCES=1   <br/>    <br/>    <em class="jv"># Maximum instances in a frame. Only one moon possible. </em><br/>    <em class="jv"># But can have different number based on the object example cat, dog, bus, car etc.</em><br/>    DETECTION_MAX_INSTANCES = 1</span><span id="6086" class="nj lk it nf b gy no nl l nm nn">config = moon_detector_Config()</span><span id="9a81" class="nj lk it nf b gy no nl l nm nn">config.display()<br/>--------------------------------------------------------------------Configurations:<br/>BACKBONE                       resnet101<br/>BACKBONE_STRIDES               [4, 8, 16, 32, 64]<br/>BATCH_SIZE                     1<br/>BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]<br/>COMPUTE_BACKBONE_SHAPE         None<br/>DETECTION_MAX_INSTANCES        1<br/>DETECTION_MIN_CONFIDENCE       0.95<br/>DETECTION_NMS_THRESHOLD        0.3<br/>FPN_CLASSIF_FC_LAYERS_SIZE     1024<br/>GPU_COUNT                      1<br/>GRADIENT_CLIP_NORM             5.0<br/>IMAGES_PER_GPU                 1<br/>IMAGE_CHANNEL_COUNT            3<br/>IMAGE_MAX_DIM                  1024<br/>IMAGE_META_SIZE                14<br/>IMAGE_MIN_DIM                  800<br/>IMAGE_MIN_SCALE                0<br/>IMAGE_RESIZE_MODE              square<br/>IMAGE_SHAPE                    [1024 1024    3]<br/>LEARNING_MOMENTUM              0.9<br/>LEARNING_RATE                  0.001<br/>LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_mask_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'rpn_bbox_loss': 1.0}<br/>MASK_POOL_SIZE                 14<br/>MASK_SHAPE                     [28, 28]<br/>MAX_GT_INSTANCES               1<br/>MEAN_PIXEL                     [123.7 116.8 103.9]<br/>MINI_MASK_SHAPE                (56, 56)<br/>NAME                           moon_detector_Config<br/>NUM_CLASSES                    2<br/>POOL_SIZE                      7<br/>POST_NMS_ROIS_INFERENCE        1000<br/>POST_NMS_ROIS_TRAINING         2000<br/>PRE_NMS_LIMIT                  6000<br/>ROI_POSITIVE_RATIO             0.33<br/>RPN_ANCHOR_RATIOS              [0.5, 1, 2]<br/>RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)<br/>RPN_ANCHOR_STRIDE              1<br/>RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]<br/>RPN_NMS_THRESHOLD              0.7<br/>RPN_TRAIN_ANCHORS_PER_IMAGE    256<br/>STEPS_PER_EPOCH                50<br/>TOP_DOWN_PYRAMID_SIZE          256<br/>TRAIN_BN                       False<br/>TRAIN_ROIS_PER_IMAGE           200<br/>USE_MINI_MASK                  True<br/>USE_RPN_ROIS                   True<br/>VALIDATION_STEPS               50<br/>WEIGHT_DECAY                   0.0001</span></pre><p id="bf87" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mh kg kh ki mi kk kl km mj ko kp kq kr im bi translated"><strong class="jw iu">加载数据集</strong></p><pre class="kt ku kv kw gt ne nf ng nh aw ni bi"><span id="21db" class="nj lk it nf b gy nk nl l nm nn"><em class="jv"># prepare train set</em><br/>train_set = MoonDataset()<br/>train_set.load_dataset( 'train_data_path/')<br/>train_set.prepare()<br/>print('Train: <strong class="nf iu">%d</strong>' % len(train_set.image_ids))<br/><em class="jv"># prepare test/val set</em><br/>test_set = MoonDataset()<br/>test_set.load_dataset('test_data_path/')<br/>test_set.prepare()<br/>print('Test: <strong class="nf iu">%d</strong>' % len(test_set.image_ids))</span></pre><p id="db7e" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mh kg kh ki mi kk kl km mj ko kp kq kr im bi translated"><strong class="jw iu">加载基础模型</strong></p><pre class="kt ku kv kw gt ne nf ng nh aw ni bi"><span id="411b" class="nj lk it nf b gy nk nl l nm nn">print("Loading Mask R-CNN model...")<br/>model = modellib.MaskRCNN(mode="training", config=config, model_dir='./')</span></pre><p id="f398" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mh kg kh ki mi kk kl km mj ko kp kq kr im bi translated"><strong class="jw iu">调整 learning_rate、epoch 和 layers 并训练</strong></p><p id="edf7" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mh kg kh ki mi kk kl km mj ko kp kq kr im bi translated">层从['全部'，' 3+'，' 4+'，'头']中选择</p><p id="8e95" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mh kg kh ki mi kk kl km mj ko kp kq kr im bi translated">范围[5–50]内的纪元</p><pre class="kt ku kv kw gt ne nf ng nh aw ni bi"><span id="2c85" class="nj lk it nf b gy nk nl l nm nn"><em class="jv">## train heads with higher lr to speedup the learning</em><br/>model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=50, layers='3+' )<br/>history = model.keras_model.history.history</span></pre><p id="1632" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mh kg kh ki mi kk kl km mj ko kp kq kr im bi translated"><strong class="jw iu">为将来保存模型</strong></p><pre class="kt ku kv kw gt ne nf ng nh aw ni bi"><span id="983e" class="nj lk it nf b gy nk nl l nm nn">model_path =  ' path to your model' + 'name' + '.h5' <br/>model.keras_model.save_weights(model_path)</span></pre><h1 id="f16f" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated"><strong class="ak"> 5。测试新的一组图像</strong></h1><pre class="kt ku kv kw gt ne nf ng nh aw ni bi"><span id="1950" class="nj lk it nf b gy nk nl l nm nn"><em class="jv"># Load pretrained moon mask </em><br/><br/>model_path = 'moon_model/moon_mask_rcnn_125.h5' # the model you created</span><span id="5a4b" class="nj lk it nf b gy no nl l nm nn"><strong class="nf iu">from</strong> <strong class="nf iu">keras.preprocessing.image</strong> <strong class="nf iu">import</strong> load_img<br/><strong class="nf iu">from</strong> <strong class="nf iu">keras.preprocessing.image</strong> <strong class="nf iu">import</strong> img_to_array</span><span id="68ce" class="nj lk it nf b gy no nl l nm nn"><em class="jv">#Loading the model in the inference mode</em><br/>model = modellib.MaskRCNN(mode="inference", config=config, model_dir='./')<br/><em class="jv"># loading the trained weights o the custom dataset</em><br/>model.load_weights(model_path, by_name=<strong class="nf iu">True</strong>)</span><span id="0bcc" class="nj lk it nf b gy no nl l nm nn">input_path = "test_images/"<br/><br/><strong class="nf iu">for</strong> i <strong class="nf iu">in</strong> os.listdir(input_path):<br/><br/>    img = load_img(input_path + i)<br/>    img = img_to_array(img)<br/>    <em class="jv"># detecting objects in the image</em><br/>    result= model.detect([img])<br/><br/>    <em class="jv"># Run object detection</em><br/>    results = model.detect([img], verbose=1)<br/>    <em class="jv"># Display results</em><br/><br/>    r = results[0]<br/>    visualize.display_instances(img, r['rois'], r['masks'], r['class_ids'], <br/>                                test_set.class_names, r['scores'], <br/>                                title="Predictions")</span></pre><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi oc"><img src="../Images/5574ff8c8ea33fe1ca7ccd1addef7a9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZuA_pNETsZAqWlWW7IgSFw.jpeg"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">输出。(<em class="li">图片作者</em>)</p></figure><h1 id="855a" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated"><strong class="ak">步骤 6:通过添加更多相关的掩模图像来微调模型，调整<em class="li">步骤 4 </em>中的参数。</strong></h1><h1 id="3c1e" class="lj lk it bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">第七步:视频月亮追踪器</h1><p id="98c0" class="pw-post-body-paragraph jt ju it jw b jx my jz ka kb mz kd ke mh na kh ki mi nb kl km mj nc kp kq kr im bi translated">为了在视频中做同样的事情，在 Opencv 中使用视频的逐帧提取，并在每一帧中应用模型。</p><pre class="kt ku kv kw gt ne nf ng nh aw ni bi"><span id="82aa" class="nj lk it nf b gy nk nl l nm nn"><strong class="nf iu">import</strong> <strong class="nf iu">cv2</strong><br/><strong class="nf iu">import</strong> <strong class="nf iu">numpy</strong> <strong class="nf iu">as</strong> <strong class="nf iu">np</strong><br/><br/><br/><strong class="nf iu">def</strong> random_colors(N):<br/>    np.random.seed(1)<br/>    colors = [tuple(255 * np.random.rand(3)) <strong class="nf iu">for</strong> _ <strong class="nf iu">in</strong> range(N)]<br/>    <strong class="nf iu">return</strong> colors<br/><br/><br/><strong class="nf iu">def</strong> apply_mask(image, mask, color, alpha=0.5):<br/>    <em class="jv">"""apply mask to image"""</em><br/>    <strong class="nf iu">for</strong> n, c <strong class="nf iu">in</strong> enumerate(color):<br/>        image[:, :, n] = np.where(<br/>            mask == 1,<br/>            image[:, :, n] * (1 - alpha) + alpha * c,<br/>            image[:, :, n]<br/>        )<br/>    <strong class="nf iu">return</strong> image<br/><br/><br/><strong class="nf iu">def</strong> display_instances(image, boxes, masks, ids, names, scores):<br/>    <em class="jv">"""</em><br/><em class="jv">        take the image and results and apply the mask, box, and Label</em><br/><em class="jv">    """</em><br/>    n_instances = boxes.shape[0]<br/>    colors = random_colors(n_instances)<br/><br/>    <strong class="nf iu">if</strong> <strong class="nf iu">not</strong> n_instances:<br/>        print('NO INSTANCES TO DISPLAY')<br/>    <strong class="nf iu">else</strong>:<br/>        <strong class="nf iu">assert</strong> boxes.shape[0] == masks.shape[-1] == ids.shape[0]<br/><br/>    <strong class="nf iu">for</strong> i, color <strong class="nf iu">in</strong> enumerate(colors):<br/>        <strong class="nf iu">if</strong> <strong class="nf iu">not</strong> np.any(boxes[i]):<br/>            <strong class="nf iu">continue</strong><br/><br/>        y1, x1, y2, x2 = boxes[i]<br/>        label = names[ids[i]]<br/>        score = scores[i] <strong class="nf iu">if</strong> scores <strong class="nf iu">is</strong> <strong class="nf iu">not</strong> <strong class="nf iu">None</strong> <strong class="nf iu">else</strong> <strong class="nf iu">None</strong><br/>        caption = '<strong class="nf iu">{}</strong> <strong class="nf iu">{:.2f}</strong>'.format(label, score) <strong class="nf iu">if</strong> score <strong class="nf iu">else</strong> label<br/>        mask = masks[:, :, i]<br/><br/>        image = apply_mask(image, mask, color)<br/>        image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)<br/>        image = cv2.putText(<br/>            image, caption, (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.7, color, 2<br/>        )<br/><br/>    <strong class="nf iu">return</strong> image</span></pre><p id="85ef" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mh kg kh ki mi kk kl km mj ko kp kq kr im bi translated"><strong class="jw iu">设置路径和文件夹名称。</strong></p><pre class="kt ku kv kw gt ne nf ng nh aw ni bi"><span id="86e5" class="nj lk it nf b gy nk nl l nm nn"><strong class="nf iu">import</strong> <strong class="nf iu">os</strong><br/><strong class="nf iu">import</strong> <strong class="nf iu">sys</strong><br/><br/>batch_size = 1<br/><br/>ROOT_DIR = os.getcwd()<br/>MODEL_DIR = os.path.join(ROOT_DIR, "logs")<br/>VIDEO_DIR = os.path.join(ROOT_DIR, "video_moon/")<br/>VIDEO_SAVE_DIR = os.path.join(VIDEO_DIR, "frames_object_detection/")<br/>MODEL_PATH = os.path.join(ROOT_DIR, "moon_model/moon_mask_rcnn_125.h5")<br/>model.load_weights(MODEL_PATH, by_name=<strong class="nf iu">True</strong>)<br/>class_names = 'moon'</span></pre><p id="9265" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mh kg kh ki mi kk kl km mj ko kp kq kr im bi translated">获取视频并使用我们的模型逐帧分析。</p><pre class="kt ku kv kw gt ne nf ng nh aw ni bi"><span id="838c" class="nj lk it nf b gy nk nl l nm nn">capture = cv2.VideoCapture(os.path.join(VIDEO_DIR, 'moon_zoom.mp4'))<br/><strong class="nf iu">try</strong>:<br/>    <strong class="nf iu">if</strong> <strong class="nf iu">not</strong> os.path.exists(VIDEO_SAVE_DIR):<br/>        os.makedirs(VIDEO_SAVE_DIR)<br/><strong class="nf iu">except</strong> <strong class="nf iu">OSError</strong>:<br/>    print ('Error: Creating directory of data')<br/>frames = []<br/>frame_count = 0<br/><em class="jv"># these 2 lines can be removed if you dont have a 1080p camera.</em><br/>capture.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)<br/>capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)<br/><br/><strong class="nf iu">while</strong> <strong class="nf iu">True</strong>:<br/>    ret, frame = capture.read()<br/>    <em class="jv"># Bail out when the video file ends</em><br/>    <strong class="nf iu">if</strong> <strong class="nf iu">not</strong> ret:<br/>        <strong class="nf iu">break</strong><br/><br/>    <em class="jv"># Save each frame of the video to a list</em><br/>    frame_count += 1<br/>    frames.append(frame)<br/>    print('frame_count :<strong class="nf iu">{0}</strong>'.format(frame_count))<br/>    <strong class="nf iu">if</strong> len(frames) == batch_size:<br/>        results = model.detect(frames, verbose=0)<br/>        print('Predicted')<br/>        <strong class="nf iu">for</strong> i, item <strong class="nf iu">in</strong> enumerate(zip(frames, results)):<br/>            frame = item[0]<br/>            r = item[1]<br/>            frame = display_instances(<br/>                frame, r['rois'], r['masks'], r['class_ids'], class_names, r['scores']<br/>            )<br/>            name = '<strong class="nf iu">{0}</strong>.jpg'.format(frame_count + i - batch_size)<br/>            name = os.path.join(VIDEO_SAVE_DIR, name)<br/>            cv2.imwrite(name, frame)<br/>            print('writing to file:<strong class="nf iu">{0}</strong>'.format(name))<br/>        <em class="jv"># Clear the frames array to start the next batch</em><br/>        frames = []<br/><br/>capture.release()</span></pre><p id="bd6a" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mh kg kh ki mi kk kl km mj ko kp kq kr im bi translated">这是我们首尾相连的<strong class="jw iu">月球追踪器</strong>整装待发。请试验代码并创建自己版本的<strong class="jw iu"> <em class="jv">对象跟踪器</em> </strong>。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi od"><img src="../Images/d306e13152e9ae8bfd1a9000c53a2994.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*7FxK3IFAT12GBX9WdK6z6Q.gif"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">放大。(<em class="li">图片作者</em>)</p></figure><p id="7a8d" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mh kg kh ki mi kk kl km mj ko kp kq kr im bi translated">干杯！！！</p><p id="032b" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mh kg kh ki mi kk kl km mj ko kp kq kr im bi translated"><a class="ae nd" href="https://github.com/praveenkottayi/moon-tracker" rel="noopener ugc nofollow" target="_blank"> Github 链接。</a></p><p id="3bd7" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mh kg kh ki mi kk kl km mj ko kp kq kr im bi translated">在下面的链接中可以找到<strong class="jw iu">月球追踪器</strong>的整个进化过程。</p><div class="oe of gp gr og oh"><a href="https://medium.com/@praveenkottayi/i-had-a-dream-not-as-big-as-martin-luther-king-jr-but-a-little-one-34dc2cdbb1d9" rel="noopener follow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd iu gy z fp om fr fs on fu fw is bi translated">我有一个梦想，没有马丁·路德·金那么大，但是很小</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">但是这个小家伙帮助我塑造了我的职业生涯。带我探索图像处理领域，让我进入了一个顶级的…</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">medium.com</p></div></div><div class="oq l"><div class="or l os ot ou oq ov lc oh"/></div></div></a></div><p id="2adb" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke mh kg kh ki mi kk kl km mj ko kp kq kr im bi translated">参考:</p><div class="oe of gp gr og oh"><a href="https://github.com/matterport/Mask_RCNN" rel="noopener  ugc nofollow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd iu gy z fp om fr fs on fu fw is bi translated">matterport/Mask_RCNN</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">这是 Mask R-CNN 在 Python 3、Keras 和 TensorFlow 上的实现。该模型生成边界框和…</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">github.com</p></div></div><div class="oq l"><div class="ow l os ot ou oq ov lc oh"/></div></div></a></div><div class="oe of gp gr og oh"><a href="https://github.com/Tony607/colab-mask-rcnn/blob/master/Colab_Mask_R_CNN_Demo.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd iu gy z fp om fr fs on fu fw is bi translated">Tony607/colab-mask-rcnn</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">permalink dissolve GitHub 是超过 5000 万开发人员的家园，他们一起工作来托管和审查代码，管理…</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">github.com</p></div></div><div class="oq l"><div class="ox l os ot ou oq ov lc oh"/></div></div></a></div><div class="oe of gp gr og oh"><a rel="noopener follow" target="_blank" href="/object-detection-using-mask-r-cnn-on-a-custom-dataset-4f79ab692f6d"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd iu gy z fp om fr fs on fu fw is bi translated">在定制数据集上使用掩模 R-CNN 的对象检测</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">在本文中，我们将实现 Mask R-CNN 来检测自定义数据集中的对象</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">towardsdatascience.com</p></div></div><div class="oq l"><div class="oy l os ot ou oq ov lc oh"/></div></div></a></div></div></div>    
</body>
</html>