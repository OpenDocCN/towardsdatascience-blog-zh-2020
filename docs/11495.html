<html>
<head>
<title>Reducing the Artificial Neural Network complexity by transforming your data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过转换数据来降低人工神经网络的复杂性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/reducing-the-artificial-neural-network-complexity-by-transforming-your-data-37ff50d94562?source=collection_archive---------37-----------------------#2020-08-09">https://towardsdatascience.com/reducing-the-artificial-neural-network-complexity-by-transforming-your-data-37ff50d94562?source=collection_archive---------37-----------------------#2020-08-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/200d6402088c01162a13d7b2bc27a634.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kar_M_yNyWnwUkY-"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">艾莉娜·格鲁布尼亚克在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><div class=""><h2 id="12c5" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">难以分类的数据集中的一个实际例子</h2></div><h2 id="9e11" class="ky kz jj bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">介绍</h2><p id="1313" class="pw-post-body-paragraph lu lv jj lw b lx ly kk lz ma mb kn mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">降低模型复杂性的需求可能源于多种因素，通常是为了降低计算要求。然而，复杂性不能任意降低，因为经过多次反复的训练和测试，这是一个提供良好结果的模型。关于这一主题的研究非常活跃，例如，[Koning 等人，2019 年]针对用于系外行星探测的 CNN 提出了一个解决方案:</p><blockquote class="mn mo mp"><p id="4964" class="lu lv mq lw b lx mr kk lz ma ms kn mc mt mu me mf mv mw mh mi mx my mk ml mm im bi translated">卷积神经网络(CNN)的可训练参数太多，影响了计算性能…我们提出并检验了两种降低 AstroNet 复杂性的方法…第一种方法只对 AstroNet 的层数进行了战术性减少，而第二种方法也通过高斯金字塔修改了原始输入数据</p></blockquote><p id="fc8e" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated">第二种方法(修改或转换输入数据)很常见。根据<a class="ae jg" href="https://developers.google.com/machine-learning/crash-course/ml-intro" rel="noopener ugc nofollow" target="_blank">谷歌的机器学习速成班</a>，完成转换<a class="ae jg" href="https://developers.google.com/machine-learning/data-prep/transform/introduction" rel="noopener ugc nofollow" target="_blank">主要有两个原因</a>:</p><ol class=""><li id="187a" class="mz na jj lw b lx mr ma ms lh nb ll nc lp nd mm ne nf ng nh bi translated"><strong class="lw jk">强制转换</strong>:使数据与算法兼容，例如将非数字特征转换为数字特征。</li><li id="39ad" class="mz na jj lw b lx ni ma nj lh nk ll nl lp nm mm ne nf ng nh bi translated"><strong class="lw jk">质量转换</strong>:帮助模型更好的执行，例如归一化数字特征。</li></ol><p id="605c" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated">[Koning et al .，2019]提出的这种转型，以及本文提出的这种转型，就属于第二类。</p><h2 id="61d0" class="ky kz jj bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">目标</h2><p id="5539" class="pw-post-body-paragraph lu lv jj lw b lx ly kk lz ma mb kn mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">我为<a class="ae jg" href="https://archive.ics.uci.edu/ml/datasets/Poker+Hand" rel="noopener ugc nofollow" target="_blank">扑克手数据集</a>【Cattral 等人，2007】提供了一种线性数据转换，并展示了这种转换如何帮助降低<a class="ae jg" href="https://scikit-learn.org/stable/modules/neural_networks_supervised.html" rel="noopener ugc nofollow" target="_blank">多层感知器</a> (MLP)神经网络的模型复杂性，同时保持分类器的准确性并减少高达 50%的训练时间。扑克手数据集是公开可用的，并且在<a class="ae jg" href="http://archive.ics.uci.edu/ml" rel="noopener ugc nofollow" target="_blank"> UCI 机器学习知识库</a>【Dua 等人，2019】中有非常好的记录。</p><p id="3176" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated">在<a class="ae jg" href="https://medium.com/@walintonc/a-good-machine-learning-classifiers-accuracy-metric-for-the-poker-hand-dataset-44cc3456b66d" rel="noopener">之前的</a>故事中，我谈到了扑克手数据集。3 层 MLP 表现相对较好。今天，我向大家展示，通过理解我们正在处理的数据并对其进行转换，使其更适合我们试图解决的问题，用一个不太复杂的模型实现同等的准确性是可能的。</p><h2 id="18bc" class="ky kz jj bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">数据集描述</h2><p id="36b6" class="pw-post-body-paragraph lu lv jj lw b lx ly kk lz ma mb kn mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">这个特殊的数据集对人类非常友好。它使用 11 维描述扑克手牌，明确列出每张牌的花色和等级，以及相关的扑克手牌。每个数据实例包含 5 张卡片。</p><p id="2117" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated"><strong class="lw jk">编码</strong></p><p id="c583" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated">以下是数据集编码描述。详情请点击<a class="ae jg" href="https://archive.ics.uci.edu/ml/datasets/Poker+Hand" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><p id="f02c" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated"><strong class="lw jk">组曲</strong> : <strong class="lw jk"> 1 </strong>:红心、<strong class="lw jk"> 2 </strong>:黑桃、<strong class="lw jk"> 3 </strong>:方块、<strong class="lw jk"> 4 </strong>:梅花<br/> <strong class="lw jk">排位</strong> : <strong class="lw jk"> 1 </strong> : Ace、<strong class="lw jk"> 2 </strong> :2、…、<strong class="lw jk"> 10 </strong>:十、<strong class="lw jk"> 11 </strong>:千斤顶、<strong class="lw jk">12<strong class="lw jk"/></strong></p><p id="a252" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated"><strong class="lw jk">示例</strong></p><p id="d19b" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated">红桃同花顺的一种编码(使用该模型可以有多种表示法)是:<br/> <strong class="lw jk"> <em class="mq">数据</em> </strong> : 1，1，1，10，1，11，1，12，1，13，9 <br/> <strong class="lw jk"> <em class="mq">解释</em> </strong>:红桃-Ace、红桃-10、红桃-Jack、红桃-皇后、红桃-王、红桃-同花顺</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/98460c0bfbad7d23c2768fa9fcf17044.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*gSuYKfPcIwYyaabbJqS2hg.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">皇家同花顺照片:<a class="ae jg" href="https://commons.wikimedia.org/wiki/File:A_studio_image_of_a_hand_of_playing_cards._MOD_45148377.jpg" rel="noopener ugc nofollow" target="_blank">格雷姆 Main/MOD </a></p></figure><h1 id="1442" class="ns kz jj bd la nt nu nv ld nw nx ny lg kp nz kq lk ks oa kt lo kv ob kw ls oc bi translated">转换</h1><p id="c0d0" class="pw-post-body-paragraph lu lv jj lw b lx ly kk lz ma mb kn mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">这种变换是基于这样的事实，即牌(在一手牌中)出现的顺序并不重要(对一手牌进行分类)，并且对一手牌进行分类的一个更重要的属性是出现在一手牌中的具有相同等级或花色的牌的数量(即基数)。原始数据集模型人为地强调了卡片出现的顺序(样本是 5 张卡片的有序列表),并且它没有显式地编码每个套件或等级的基数。前提是，通过使该属性在数据中显式可用，与使用隐藏了该属性的原始模型时的相同神经网络相比，神经网络能够更好地对数据集进行分类。</p><p id="b8fa" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated"><strong class="lw jk">线性变换</strong></p><p id="300d" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated">下面是从原来的 11D 空间到新的 18D 空间的<strong class="lw jk">线性变换</strong>。线性变换是优选的，因为它降低了计算要求。新的维度和描述包括:</p><p id="3b81" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated"><strong class="lw jk">属性 1 到 13:</strong>13 个等级，即 1:王牌，2:二，3:三，…，10:十，11:杰克，12:女王，13:国王。<br/> <strong class="lw jk">属性 14 到 17:</strong>4 组，即 14:红心，15:黑桃，16:方块，17:梅花<br/> <strong class="lw jk">域</strong>:【0–5】。每个维度代表手中的级别或套件基数。<br/> <strong class="lw jk">最后一个维度</strong>:扑克手[0–9](不变)。</p><p id="812f" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated"><strong class="lw jk">编码和示例</strong></p><p id="35a1" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated">以下是皇家同花顺的转换示例。</p><p id="2159" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated"><strong class="lw jk">以原始尺寸表示(11D): </strong></p><p id="5555" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated"><strong class="lw jk"> <em class="mq">数据</em> </strong> : 1，1，1，10，1，11，1，12，1，13，9 <br/> <strong class="lw jk"> <em class="mq">编码</em> </strong>:红心-Ace，红心-10，红心-杰克，红心-皇后，红心-国王，皇家-同花顺</p><p id="5e6e" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated"><strong class="lw jk">新维度中的表示(18D): </strong></p><p id="b14b" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated"><strong class="lw jk"> <em class="mq">数据</em> </strong> <em class="mq"> : </em> 1，0，0，0，0，0，0，0，1，1，1，5，0，0，0，9 <br/> <strong class="lw jk"> <em class="mq">编码</em> </strong> <em class="mq"> : </em>第 1 列= <strong class="lw jk"> 1 Ace </strong>，第 2 至第 9 列=无(无该套牌)，第 10 至第 13 列= <strong class="lw jk"> 1 十张</strong>，.</p><p id="ab31" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated">下图显示了这个特定示例的视觉转换。</p><figure class="no np nq nr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi od"><img src="../Images/5b8c601bfa3d3229ea11fde833fc10cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*h95LZr0pYOoLpPag9sXJ8Q.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">从 11D 到 18D 的线性变换(<em class="oe">作者图片)</em></p></figure><p id="6d56" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated">新模型以相同的方式表示任何给定的 5 张牌的组合，而不管顺序如何，并且<strong class="lw jk">明确地公开了对扑克手有用的信息，例如相同等级的牌的数量。</strong></p><h2 id="7658" class="ky kz jj bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">工具</h2><p id="a214" class="pw-post-body-paragraph lu lv jj lw b lx ly kk lz ma mb kn mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated"><strong class="lw jk"> Scikit-learn </strong>、<strong class="lw jk"> Numpy </strong>和<strong class="lw jk"> Seaborn </strong>分别用于机器学习、数据处理和可视化。</p><h2 id="522d" class="ky kz jj bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">代码在哪里？</h2><p id="321f" class="pw-post-body-paragraph lu lv jj lw b lx ly kk lz ma mb kn mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">一个带有 MLP、可视化和线性变换的 Jupyter 笔记本在这里是<a class="ae jg" href="https://github.com/walintonc/ml/tree/master/pokerhand" rel="noopener ugc nofollow" target="_blank"/>。每个实验的<strong class="lw jk">分类报告</strong>和<strong class="lw jk">混淆矩阵</strong>也包含在 Jupyter 笔记本中。</p><h1 id="aab2" class="ns kz jj bd la nt nu nv ld nw nx ny lg kp nz kq lk ks oa kt lo kv ob kw ls oc bi translated">结果</h1><p id="9c80" class="pw-post-body-paragraph lu lv jj lw b lx ly kk lz ma mb kn mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">在我的<a class="ae jg" href="https://medium.com/@walintonc/a-good-machine-learning-classifiers-accuracy-metric-for-the-poker-hand-dataset-44cc3456b66d" rel="noopener">之前的</a>故事中，我展示了一个 MLP，它有<strong class="lw jk">个 100 个神经元的 3 个隐藏层</strong>个<strong class="lw jk">，</strong>个<strong class="lw jk"> alpha=0.0001 </strong>，<strong class="lw jk">学习率=0.01 </strong>使用原始数据集，<strong class="lw jk"> </strong>达到了<strong class="lw jk"> ~78%的准确率</strong>。这些超参数是在对大范围的值进行广泛的网格搜索后发现的。因此，将基于这些相同的值进行以下测量。</p><h2 id="e7c0" class="ky kz jj bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">韵律学</h2><p id="3765" class="pw-post-body-paragraph lu lv jj lw b lx ly kk lz ma mb kn mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">MLP 精度用<strong class="lw jk">F1</strong>T30】宏平均度量来测量。对于扑克手数据集来说，这是一个合适的指标，因为它很好地处理了这个数据集极度不平衡的事实。<strong class="lw jk">sci kit-了解</strong>的<a class="ae jg" href="https://scikit-learn.org/stable/modules/model_evaluation.html#precision-recall-f-measure-metrics" rel="noopener ugc nofollow" target="_blank">文档</a>:</p><blockquote class="mn mo mp"><p id="7f17" class="lu lv mq lw b lx mr kk lz ma ms kn mc mt mu me mf mv mw mh mi mx my mk ml mm im bi translated">F-measure 可以解释为精度和召回率的加权调和平均值……在不经常出现的类仍然很重要的问题中，宏平均可能是突出其性能的一种方法</p></blockquote><p id="6252" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated"><a class="ae jg" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lw jk">分类报告</strong> </a> <strong class="lw jk"> </strong>显示不同的实验。它包含宏观平均 F1 指标等。</p><p id="e3ec" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated">此外，测量并报告<strong class="lw jk"> MLP 训练时间</strong>。</p><h2 id="8c59" class="ky kz jj bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">原始数据的 3 个隐藏层 MLP</h2><p id="3df3" class="pw-post-body-paragraph lu lv jj lw b lx ly kk lz ma mb kn mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated"><strong class="lw jk">复杂度</strong>:每个隐层有 100 个神经元。</p><p id="e7e9" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated"><strong class="lw jk">精度</strong>:对于 3 层 MLP 和原始数据(还没有应用转换)，在 F1-score 宏观平均中得到一个<strong class="lw jk"> ~80%的精度</strong>。参考<a class="ae jg" href="https://medium.com/@walintonc/a-good-machine-learning-classifiers-accuracy-metric-for-the-poker-hand-dataset-44cc3456b66d" rel="noopener">之前的</a>帖子，了解这个结果是如何实现的。</p><p id="1642" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated"><strong class="lw jk">训练时间</strong> : 20+秒</p><p id="b979" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated"><strong class="lw jk">分类报告</strong></p><pre class="no np nq nr gt of og oh oi aw oj bi"><span id="1480" class="ky kz jj og b gy ok ol l om on">              precision    recall  <strong class="og jk">f1-score</strong>   support<br/>           0       1.00      0.99      0.99    501209<br/>           1       0.99      0.99      0.99    422498<br/>           2       0.96      1.00      0.98     47622<br/>           3       0.99      0.99      0.99     21121<br/>           4       0.85      0.64      0.73      3885<br/>           5       0.97      0.99      0.98      1996<br/>           6       0.77      0.98      0.86      1424<br/>           7       0.70      0.23      0.35       230<br/>           8       1.00      0.83      0.91        12<br/>           9       0.04      0.33      0.07         3<br/>    accuracy                           0.99   1000000<br/>   <strong class="og jk">macro avg       0.83      0.80      0.78   1000000</strong><br/>weighted avg       0.99      0.99      0.99   1000000</span></pre><h2 id="161e" class="ky kz jj bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">具有转换数据的 2 个隐藏层 MLP</h2><p id="0a5f" class="pw-post-body-paragraph lu lv jj lw b lx ly kk lz ma mb kn mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">在这个实验中，通过丢弃一个 100 个神经元的隐藏层来降低模型的复杂性，并且使用转换的(18D)数据。其他一切都保持不变。</p><p id="a36e" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated"><strong class="lw jk">精度:</strong>对于数据转换后的二层 MLP，可以观察到<strong class="lw jk"> ~85%的精度</strong>。</p><p id="7b46" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated"><strong class="lw jk">训练时间</strong>:10-15 秒</p><pre class="no np nq nr gt of og oh oi aw oj bi"><span id="c15e" class="ky kz jj og b gy ok ol l om on">              precision    recall  <strong class="og jk">f1-score</strong>   support</span><span id="35f9" class="ky kz jj og b gy oo ol l om on">           0       1.00      1.00      1.00    501209<br/>           1       1.00      1.00      1.00    422498<br/>           2       1.00      1.00      1.00     47622<br/>           3       0.97      1.00      0.98     21121<br/>           4       1.00      0.99      1.00      3885<br/>           5       1.00      0.98      0.99      1996<br/>           6       0.83      0.48      0.61      1424<br/>           7       1.00      0.41      0.58       230<br/>           8       0.38      0.75      0.50        12<br/>           9       0.50      1.00      0.67         3</span><span id="5eab" class="ky kz jj og b gy oo ol l om on">    accuracy                           1.00   1000000<br/><strong class="og jk">   macro avg       0.87      0.86      0.83   1000000</strong><br/>weighted avg       1.00      1.00      1.00   1000000</span></pre><h2 id="efee" class="ky kz jj bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">1 个隐藏层 MLP，包含转换后的数据和原始数据</h2><p id="b1b9" class="pw-post-body-paragraph lu lv jj lw b lx ly kk lz ma mb kn mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated"><strong class="lw jk">精度:<br/> </strong>单层 100 个神经元，经过<strong class="lw jk">变换</strong>数据的 MLP 达到了<strong class="lw jk"> ~70%的精度</strong>。使用<strong class="lw jk">原始</strong>数据集，它达到了<strong class="lw jk"> ~30%的准确率</strong>。</p><p id="846a" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated"><strong class="lw jk">训练时间</strong> : <br/>对于转换后的数据集约 10 秒，对于原始数据约 12 秒。</p><h2 id="0dba" class="ky kz jj bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">其他实验</h2><p id="5bb1" class="pw-post-body-paragraph lu lv jj lw b lx ly kk lz ma mb kn mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">随意看看<a class="ae jg" href="https://github.com/walintonc/ml/tree/master/pokerhand" rel="noopener ugc nofollow" target="_blank"> Jupyter 笔记本</a>，里面有这些和其他实验的代码和结果。</p><h1 id="8be9" class="ns kz jj bd la nt nu nv ld nw nx ny lg kp nz kq lk ks oa kt lo kv ob kw ls oc bi translated"><strong class="ak">结论</strong></h1><p id="ecea" class="pw-post-body-paragraph lu lv jj lw b lx ly kk lz ma mb kn mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">通过应用一个简单的线性变换，使数据集对人类不太友好，但对 ML 更友好，我证明了一个更简单的 MLP 模型在更少的计算时间内提供了等效的结果。具体来说，100 个神经元的隐藏层被移除，而不损害分类器的性能。结果表明，神经网络的精度与更复杂模型的精度相当或更好，训练时间减少了 25%到 50%。</p><h1 id="7dca" class="ns kz jj bd la nt nu nv ld nw nx ny lg kp nz kq lk ks oa kt lo kv ob kw ls oc bi translated">参考</h1><p id="fa04" class="pw-post-body-paragraph lu lv jj lw b lx ly kk lz ma mb kn mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">卡特拉尔和奥帕彻(2007 年)。<strong class="lw jk">扑克手数据集</strong><a class="ae jg" href="https://archive.ics.uci.edu/ml/datasets/Poker+Hand" rel="noopener ugc nofollow" target="_blank">https://archive.ics.uci.edu/ml/datasets/Poker+Hand</a><br/>卡尔顿大学计算机科学系。<br/>智能系统研究小组</p><p id="9297" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated">Dua d .和 Graff c .(2019 年)。<strong class="lw jk">http://archive.ics.uci.edu/ml</strong>UCI 机器学习资源库<a class="ae jg" href="http://archive.ics.uci.edu/ml" rel="noopener ugc nofollow" target="_blank">。加州欧文:加州大学信息与计算机科学学院。</a></p><p id="2ad0" class="pw-post-body-paragraph lu lv jj lw b lx mr kk lz ma ms kn mc lh mu me mf ll mw mh mi lp my mk ml mm im bi translated"><a class="ae jg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koning%2C+S" rel="noopener ugc nofollow" target="_blank">塞巴斯蒂安·科宁</a>，<a class="ae jg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Greeven%2C+C" rel="noopener ugc nofollow" target="_blank">卡斯帕·格里芬</a>，<a class="ae jg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Postma%2C+E" rel="noopener ugc nofollow" target="_blank">埃里克·波斯特马</a> (2019) <strong class="lw jk">降低人工神经网络复杂性:系外行星探测案例研究</strong>。<a class="ae jg" href="https://arxiv.org/abs/1902.10385v1" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1902.10385</a></p></div></div>    
</body>
</html>