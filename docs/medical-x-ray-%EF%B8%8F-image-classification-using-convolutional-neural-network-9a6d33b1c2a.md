# åŸºäºå·ç§¯ç¥ç»ç½‘ç»œçš„åŒ»å­¦ x å°„çº¿âš•ï¸å›¾åƒåˆ†ç±»

> åŸæ–‡ï¼š<https://towardsdatascience.com/medical-x-ray-%EF%B8%8F-image-classification-using-convolutional-neural-network-9a6d33b1c2a?source=collection_archive---------1----------------------->

## ä»æ— åˆ°æœ‰æ„å»º x çº¿è‚ºç‚æ£€æµ‹çš„ CNN æ¨¡å‹

![](img/a6daf5281e26fbbb5e7baf283f769549.png)

å›¾ç‰‡æ¥è‡ª[ç»´åŸºåª’ä½“](https://commons.wikimedia.org/wiki/File:Projectional_rendering_of_CT_scan_of_thorax_(thumbnail).gif)

## åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ª CNN æ¨¡å‹ï¼Œå®ƒå¯ä»¥å°† X å°„çº¿å›¾åƒåˆ†ç±»ä¸ºè‚ºç‚ç—…ä¾‹æˆ–æ­£å¸¸ç—…ä¾‹ã€‚

**web åº”ç”¨**å·²ç»éƒ¨ç½²åˆ° streamlit share:[https://share . streamlit . io/smarthardk 10/Xray-classifier/main/web app . py](https://share.streamlit.io/smarthardik10/xray-classifier/main/webapp.py)

![](img/6c41245723741d559c71f8be32823227.png)

## ç›®å½•

1.  æ•°æ®é›†
2.  åˆå§‹åŒ–
3.  å‡†å¤‡æ•°æ®

*   3.1 æ•°æ®æ‰©å……
*   3.2 åŠ è½½å›¾åƒ

4.å·ç§¯ç¥ç»ç½‘ç»œ

*   4.1 å¿…è¦çš„è¿›å£
*   4.2 CNN æ¶æ„
*   4.3 æ‹Ÿåˆæ¨¡å‹

5.è¯„ä»·

# 1 æ•°æ®é›†

æˆ‘ä»¬å°†ç”¨äºå›¾åƒåˆ†ç±»çš„æ•°æ®é›†æ˜¯èƒ¸éƒ¨ X å°„çº¿å›¾åƒï¼Œå®ƒåŒ…æ‹¬ä¸¤ä¸ªç±»åˆ«ï¼Œè‚ºç‚å’Œæ­£å¸¸ã€‚è¿™ä¸ª[æ•°æ®é›†](https://www.kaggle.com/pcbreviglieri/pneumonia-xray-images)ç”± Paulo Breviglieri å‘å¸ƒï¼Œæ˜¯ Paul Mooney æœ€å—æ¬¢è¿çš„[æ•°æ®é›†](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia)çš„ä¿®è®¢ç‰ˆã€‚æ•°æ®é›†çš„è¿™ä¸ªæ›´æ–°ç‰ˆæœ¬åœ¨éªŒè¯é›†å’Œæµ‹è¯•é›†ä¸­å…·æœ‰æ›´å¹³è¡¡çš„å›¾åƒåˆ†å¸ƒã€‚æ•°æ®é›†è¢«ç»„ç»‡æˆ 3 ä¸ªæ–‡ä»¶å¤¹(trainã€testã€val ),å¹¶åŒ…å«æ¯ä¸ªå›¾åƒç±»åˆ«ä¸é€æ˜åº¦(å³&æ­£å¸¸è‚ºç‚)ã€‚

*æ€»è§‚å¯Ÿå€¼(å›¾åƒ):5856
è®­ç»ƒè§‚å¯Ÿå€¼:4192(æ­£å¸¸ 1082 ä¾‹ï¼Œè‚ºéƒ¨é˜´å½± 3110 ä¾‹)
éªŒè¯è§‚å¯Ÿå€¼:1040(æ­£å¸¸ 267 ä¾‹ï¼Œè‚ºéƒ¨é˜´å½± 773 ä¾‹)
æµ‹è¯•è§‚å¯Ÿå€¼:624(æ­£å¸¸ 234 ä¾‹ï¼Œè‚ºéƒ¨é˜´å½± 390 ä¾‹)*

é¦–å…ˆï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ Kaggle API ç›´æ¥ä» Kaggle ä¸­æå–æ•°æ®é›†ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ª API ä»¤ç‰Œï¼Œå®ƒä½äº Kaggle API é€‰é¡¹å¡ä¸‹çš„ Account éƒ¨åˆ†ã€‚ç‚¹å‡»â€œåˆ›å»ºä¸€ä¸ªæ–°çš„ API ä»¤ç‰Œâ€,ä¸€ä¸ª json æ–‡ä»¶å°†è¢«ä¸‹è½½ã€‚
è¿è¡Œä¸‹é¢å‡ è¡Œä»£ç æ¥å®‰è£…æ‰€éœ€çš„åº“å¹¶ä¸Šä¼  json æ–‡ä»¶ã€‚

```
! pip install -q kaggle
from google.colab import files
files.upload()
! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json
```

![](img/b9fc73e59b1d8fc6c0842e3714af7c23.png)

å½“æç¤ºâ€œé€‰æ‹©æ–‡ä»¶â€æ—¶ï¼Œä¸Šä¼ ä¸‹è½½çš„ json æ–‡ä»¶ã€‚è¿è¡Œä¸‹ä¸€è¡Œä»£ç å°†ä¸‹è½½æ•°æ®é›†ã€‚è¦è·å¾—æ•°æ®é›† API å‘½ä»¤æ¥ä¸‹è½½æ•°æ®é›†ï¼Œå•å‡» Kaggle æ•°æ®é›†é¡µé¢çš„æ•°æ®éƒ¨åˆ†ä¸­çš„ 3 ä¸ªç‚¹ï¼Œç„¶åå•å‡»â€œå¤åˆ¶ API å‘½ä»¤â€æŒ‰é’®å¹¶ç”¨`!`å°†å…¶ç²˜è´´

```
! kaggle datasets download -d pcbreviglieri/pneumonia-xray-images
```

å› ä¸ºæˆ‘ä½¿ç”¨ Google Colab æ¥è¿è¡Œè¿™ä¸ªé¡¹ç›®ï¼Œæ‰€ä»¥æ•°æ®é›† zip æ–‡ä»¶è¢«ä¸‹è½½åˆ° Sample Data æ–‡ä»¶å¤¹ä¸­ã€‚ç°åœ¨ï¼Œé€šè¿‡è¿è¡Œä¸‹é¢å‡ è¡Œä»£ç ï¼Œæˆ‘ä»¬ä½¿ç”¨ zipfile åº“å°†æ–‡ä»¶å¤¹å’Œæ–‡ä»¶è§£å‹ç¼©åˆ°æ‰€éœ€çš„ç›®æ ‡æ–‡ä»¶å¤¹ã€‚

```
import zipfilezf = "/content/pneumonia-xray-images.zip"
target_dir = "/content/dataset/cnn/pneumonia_revamped"zfile = zipfile.ZipFile(zf)
zfile.extractall(target_dir)
```

**ç°åœ¨æˆ‘ä»¬çš„æ•°æ®é›†å·²ç»å‡†å¤‡å¥½äº†ï¼Œè®©æˆ‘ä»¬å¼€å§‹å§ï¼**

Gif via [GIPHY](https://media.giphy.com/media/yXzMsbJfjrhLy/giphy.gif)

# 2 åˆå§‹åŒ–

è®©æˆ‘ä»¬çœ‹çœ‹æˆ‘ä»¬çš„æ•°æ®é›†ç›®å½•æ ‘ã€‚

```
content
â””â”€â”€â”€dataset
    â””â”€â”€â”€cnn
        â””â”€â”€â”€pneumonia_revamped
            â”œâ”€â”€â”€test
            â”‚   â”œâ”€â”€â”€Normal
            â”‚   â”‚   â”œâ”€â”€â”€image1.jpg
            â”‚   â”‚   â””â”€â”€â”€image2.jpg
            â”‚   â””â”€â”€â”€Opacity
            â”‚       â”œâ”€â”€â”€image1.jpg
            â”‚       â””â”€â”€â”€image2.jpg
            â”œâ”€â”€â”€train
            â”‚   â”œâ”€â”€â”€Normal
            â”‚   â”‚   â”œâ”€â”€â”€image1.jpg
            â”‚   â”‚   â””â”€â”€â”€image2.jpg
            â”‚   â””â”€â”€â”€Opacity
            â”‚       â”œâ”€â”€â”€image1.jpg
            â”‚       â””â”€â”€â”€image2.jpg
            â””â”€â”€â”€val
                â”œâ”€â”€â”€Normal
                â”‚   â”œâ”€â”€â”€image1.jpg
                â”‚   â””â”€â”€â”€image2.jpg
                â””â”€â”€â”€Opacity
                    â”œâ”€â”€â”€image1.jpg
                    â””â”€â”€â”€image2.jpg
```

åœ¨è¿™éƒ¨åˆ†ä»£ç ä¸­ï¼Œæˆ‘ä»¬å°†å®šä¹‰ç›®å½•è·¯å¾„ï¼Œå¯¼å…¥ä¸€äº›éœ€è¦çš„åº“ï¼Œå¹¶å®šä¹‰ä¸€äº›æˆ‘ä»¬å°†åœ¨é¡¹ç›®çš„åé¢éƒ¨åˆ†ç»å¸¸ä½¿ç”¨çš„å…¬å…±å¸¸é‡å‚æ•°ã€‚

```
#Some Basic Importsimport matplotlib.pyplot as plt #For Visualization
import numpy as np              #For handling arrays
import pandas as pd             # For handling data#Define Directories for train, test & Validation Set
train_path = '/content/dataset/cnn/pneumonia_revamped/train'
test_path = '/content/dataset/cnn/pneumonia_revamped/test'
valid_path = '/content/dataset/cnn/pneumonia_revamped/val'#Define some often used standard parameters
#The batch refers to the number of training examples utilized in one #iteration
batch_size = 16 #The dimension of the images we are going to define is 500x500 img_height = 500
img_width = 500The dimension size of 500 or more than 500 with batch size greater than 16 may result in a crash as the RAM gets completely used in such cases. A lower dimension size with greater batch size is one of the options to try.
```

# 3 å‡†å¤‡æ•°æ®

## 3.1 æ•°æ®æ‰©å……

æˆ‘ä»¬å°†é€šè¿‡æ‰§è¡Œä¸€äº›å›¾åƒå¢å¼ºæŠ€æœ¯æ¥äººä¸ºåœ°å¢åŠ å›¾åƒè®­ç»ƒæ•°æ®é›†çš„å¤§å°ã€‚

> å›¾åƒå¢å¼ºé€šè¿‡åˆ›å»ºç°æœ‰è®­ç»ƒé›†å›¾åƒçš„ä¿®æ”¹ç‰ˆæœ¬æ¥æ‰©å±•æ•°æ®é›†çš„å¤§å°ï¼Œè¿™æœ‰åŠ©äºå¢åŠ æ•°æ®é›†å˜åŒ–å¹¶æœ€ç»ˆæé«˜æ¨¡å‹é¢„æµ‹æ–°å›¾åƒçš„èƒ½åŠ›ã€‚

```
from tensorflow.keras.preprocessing.image import ImageDataGenerator# Create Image Data Generator for Train Set
image_gen = ImageDataGenerator(
                                  rescale = 1./255,
                                  shear_range = 0.2,
                                  zoom_range = 0.2,
                                  horizontal_flip = True,          
                               )# Create Image Data Generator for Test/Validation Set
test_data_gen = ImageDataGenerator(rescale = 1./255)
```

Gif via [GIPHY](https://media.giphy.com/media/t1HJXy5Q5NKA8/giphy.gif)

ä½¿ç”¨`tensorflow.keras.preprocessing.image`åº“ï¼Œå¯¹äºè®­ç»ƒé›†ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªå›¾åƒæ•°æ®ç”Ÿæˆå™¨ï¼Œå®ƒå°†å®šä¹‰çš„å‚æ•°éšæœºåº”ç”¨äºè®­ç»ƒé›†ï¼Œå¯¹äºæµ‹è¯•&éªŒè¯é›†ï¼Œæˆ‘ä»¬å°†é‡æ–°è°ƒæ•´å®ƒä»¬ï¼Œä»¥é¿å…äº‹å…ˆæ“çºµæµ‹è¯•æ•°æ®ã€‚

**å®šä¹‰ä¸€äº›å›¾åƒæ•°æ®å‘ç”Ÿå™¨å‚æ•°:-**

1.  `rescale`â€”æ¯ä¸ªæ•°å­—å›¾åƒç”±ä¸€ä¸ªå€¼åœ¨ 0 åˆ° 255 ä¹‹é—´çš„åƒç´ åˆ›å»ºã€‚é»‘è‰²ä¸º 0ï¼Œç™½è‰²ä¸º 255ã€‚å› æ­¤ï¼Œé‡æ–°è°ƒæ•´åŸå§‹å›¾åƒåƒç´ å€¼çš„æ¯”ä¾‹æ•°ç»„ï¼Œä½¿å…¶ä»‹äº[0ï¼Œ1]ä¹‹é—´ï¼Œè¿™ä½¿å¾—å›¾åƒå¯¹æ•´ä½“æŸå¤±çš„è´¡çŒ®æ›´åŠ å‡ç­‰ã€‚å¦åˆ™ï¼Œæ›´é«˜åƒç´ èŒƒå›´çš„å›¾åƒå¯¼è‡´æ›´å¤§çš„æŸå¤±ï¼Œå¹¶ä¸”åº”è¯¥ä½¿ç”¨æ›´ä½çš„å­¦ä¹ ç‡ï¼Œæ›´ä½åƒç´ èŒƒå›´çš„å›¾åƒå°†éœ€è¦æ›´é«˜çš„å­¦ä¹ ç‡ã€‚
2.  `shear_range` â€”å›¾åƒçš„å½¢çŠ¶æ˜¯å‰ªåˆ‡çš„å˜æ¢ã€‚å®ƒå›ºå®šä¸€ä¸ªè½´ï¼Œå¹¶ä»¥æŸä¸ªè§’åº¦æ‹‰ä¼¸å›¾åƒï¼Œè¯¥è§’åº¦ç§°ä¸ºå‰ªåˆ‡è§’ã€‚
3.  `zoom_range` â€”å›¾åƒä»¥å°äº 1.0 çš„å€ç‡æ”¾å¤§ã€‚å›¾ç‰‡ç¼©å°äº† 1.0 å€ä»¥ä¸Šã€‚
4.  `horizontal_flip`â€”ä¸€äº›å›¾åƒè¢«éšæœºæ°´å¹³ç¿»è½¬
5.  `vertical_flip` â€”ä¸€äº›å›¾åƒéšæœºå‚ç›´ç¿»è½¬
6.  `roataion_range` â€”éšæœºåœ°ï¼Œå›¾åƒåœ¨ 0Â°åˆ° 180Â°èŒƒå›´å†…æ—‹è½¬ä¸€å®šè§’åº¦ã€‚
7.  `width_shift_range` â€”æ°´å¹³ç§»åŠ¨å›¾åƒã€‚
8.  `height_shift_range` â€”å‚ç›´ç§»åŠ¨å›¾åƒã€‚
9.  `brightness_range` â€”äº®åº¦ 0.0 å¯¹åº”ç»å¯¹æ— äº®åº¦ï¼Œ1.0 å¯¹åº”æœ€å¤§äº®åº¦
10.  `fill_mode` â€”å°†å›¾åƒä¸­ç¼ºå°‘çš„å€¼å¡«å……åˆ°æœ€æ¥è¿‘çš„å€¼ã€åŒ…è£¹å€¼æˆ–åå°„å€¼ã€‚

é™¤äº†é‡æ–°ç¼©æ”¾ä¹‹å¤–ï¼Œè¿™äº›å˜æ¢æŠ€æœ¯è¢«éšæœºåº”ç”¨äºå›¾åƒã€‚æ‰€æœ‰å›¾åƒå·²è¢«é‡æ–°ç¼©æ”¾ã€‚

## 3.2 åŠ è½½å›¾åƒ

å›¾åƒæ•°æ®ç”Ÿæˆå™¨æœ‰ä¸€ä¸ªåä¸º flow from directory çš„ç±»ï¼Œç”¨äºä»åŒ…å«å›¾åƒçš„æ–‡ä»¶å¤¹ä¸­è¯»å–å›¾åƒã€‚è¿”å›ç›®å½•æ“ä½œç¬¦ç±»å‹`tensorflow.python.keras.preprocessing.image.DirectoryIterator`ã€‚

```
train = image_gen.flow_from_directory(
      train_path,
      target_size=(img_height, img_width),
      color_mode='grayscale',
      class_mode='binary',
      batch_size=batch_size
      )test = test_data_gen.flow_from_directory(
      test_path,
      target_size=(img_height, img_width),
      color_mode='grayscale',
      shuffle=False, 
#setting shuffle as False just so we can later compare it with predicted values without having indexing problem 
      class_mode='binary',
      batch_size=batch_size
      )valid = test_data_gen.flow_from_directory(
      valid_path,
      target_size=(img_height, img_width),
      color_mode='grayscale',
      class_mode='binary', 
      batch_size=batch_size
      )
```

`Found 4192 images belonging to 2 classes. Found 624 images belonging to 2 classes. Found 1040 images belonging to 2 classes.`

**å®ƒæ¥å—çš„ä¸€äº›å‚æ•°å®šä¹‰å¦‚ä¸‹:-**

1.  `directory` â€”ä½¿ç”¨çš„ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯æˆ‘ä»¬ä¹‹å‰å®šä¹‰çš„ trainï¼Œtest &éªŒè¯æ–‡ä»¶å¤¹çš„è·¯å¾„ã€‚
2.  `target_size` â€”ç›®æ ‡å°ºå¯¸æ˜¯æ‚¨çš„è¾“å…¥å›¾åƒçš„å°ºå¯¸ï¼Œæ¯ä¸ªå›¾åƒå°†è¢«è°ƒæ•´åˆ°è¿™ä¸ªå°ºå¯¸ã€‚æˆ‘ä»¬ä¹‹å‰å·²ç»å°†ç›®æ ‡å°ºå¯¸å®šä¹‰ä¸º 500 x 500ã€‚
3.  `color_mode`â€”å¦‚æœå›¾åƒæ˜¯é»‘ç™½æˆ–ç°åº¦è®¾ç½®ä¸ºâ€œç°åº¦â€ï¼Œæˆ–è€…å¦‚æœå›¾åƒæœ‰ä¸‰ä¸ªé¢œè‰²é€šé“è®¾ç½®ä¸ºâ€œrgbâ€æˆ‘ä»¬å°†ä½¿ç”¨ç°åº¦ï¼Œå› ä¸ºè¿™æ˜¯ x å…‰å›¾åƒã€‚
4.  `batch_size` â€”ç”Ÿæˆå™¨æ‰¹é‡ç”Ÿæˆçš„å›¾åƒæ•°é‡ã€‚æˆ‘ä»¬ä¹‹å‰å°†æ‰¹é‡å®šä¹‰ä¸º 16ã€‚æˆ‘ä»¬é€‰æ‹© 16ï¼Œå› ä¸ºå›¾åƒçš„å¤§å°å¤ªå¤§ï¼Œæ— æ³•å¤„ç† RAMã€‚
5.  `class_mode` â€”å¦‚æœæ‚¨åªæœ‰ä¸¤ä¸ªç±»åˆ«è¦é¢„æµ‹ï¼Œåˆ™è®¾ç½®â€œäºŒè¿›åˆ¶â€ï¼Œå¦‚æœæ‚¨æ²¡æœ‰è®¾ç½®ä¸ºâ€œåˆ†ç±»â€ï¼Œå¦‚æœæ‚¨å¼€å‘äº†ä¸€ä¸ªè‡ªåŠ¨ç¼–ç å™¨ç³»ç»Ÿï¼Œåˆ™è¾“å…¥å’Œè¾“å‡ºå¾ˆå¯èƒ½æ˜¯åŒä¸€ä¸ªå›¾åƒï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹è®¾ç½®ä¸ºâ€œè¾“å…¥â€ã€‚è¿™é‡Œæˆ‘ä»¬å°†å®ƒè®¾ç½®ä¸ºäºŒè¿›åˆ¶ï¼Œå› ä¸ºæˆ‘ä»¬åªæœ‰ 2 ä¸ªç±»è¦é¢„æµ‹ã€‚

**è®©æˆ‘ä»¬çœ‹çœ‹æˆ‘ä»¬ä»æ•°æ®æ‰©å……**ä¸­è·å¾—çš„ä¸€äº›åˆ—è½¦ç»„å›¾åƒ

Gif via [GIPHY](https://media.giphy.com/media/YWy93Zf9eW8RMlK0gK/giphy.gif)

```
plt.figure(figsize=(12, 12))
for i in range(0, 10):
    plt.subplot(2,Â 5, i+1)
    for X_batch, Y_batch in train:
        image = X_batch[0]        
        dic = {0:â€™NORMALâ€™, 1:â€™PNEUMONIAâ€™}
        plt.title(dic.get(Y_batch[0]))
        plt.axis(â€™offâ€™)
        plt.imshow(np.squeeze(image),cmap=â€™grayâ€™,interpolation=â€™nearestâ€™)
        break
plt.tight_layout()
plt.show()
```

![](img/4dee568fd86ca62460fce2b2ed2e77a5.png)

æŸ¥çœ‹åˆ—è½¦ç»„çš„ä¸€äº›å›¾åƒ

Gif via [GIPHY](https://media.giphy.com/media/1kkxWqT5nvLXupUTwK/giphy.gif)

å—¯ï¼Œæˆ‘ä¸èƒ½ä»…ä»…é€šè¿‡çœ‹è¿™äº›å›¾ç‰‡æ¥åˆ¤æ–­å“ªä¸€ä¸ªæ˜¯è‚ºç‚ç—…ä¾‹ï¼Œå“ªä¸€ä¸ªæ˜¯æ­£å¸¸ç—…ä¾‹ã€‚ä¸ºæ­¤ï¼Œæˆ‘éœ€è¦ä¸€ä¸ªæ”¾å°„å­¦å­¦å£«å­¦ä½ï¼Œéœ€è¦ 2 åˆ° 4 å¹´æ—¶é—´ï¼Œä»…ç¬¬ä¸€å¹´å°±è¦èŠ±è´¹ 466 ä¸‡å¢æ¯”ã€‚ ***å¥½å§ï¼Œä¸è¦æ‹…å¿ƒï¼Œä½œä¸ºä¸€ä¸ªæ•°æ®ç§‘å­¦ä»ä¸šè€…ï¼Œä½ å¯ä»¥æ•™è®¡ç®—æœºåˆ†è¾¨å®ƒä»¬ä¹‹é—´çš„åŒºåˆ«ã€‚*** *æˆ‘ä»¬æœ‰å¸Œæœ›åœ¨è¿™æ–¹é¢è¾¾åˆ°å¾ˆé«˜çš„ç²¾ç¡®åº¦ï¼Œå¦åˆ™å°±æ˜¯æ”¾å°„ç§‘åŒ»å¸ˆçš„å­¦ä½äº†ã€‚*

# 4 å·ç§¯ç¥ç»ç½‘ç»œ

![](img/c9d5662496f50a9365f8fda3af21c86b.png)

CNN æ¶æ„çš„ä¾‹å­ç”±[ç»´åŸºåª’ä½“](https://commons.wikimedia.org/wiki/File:Typical_cnn.png)

> **ç”¨ä¸€å¥è¯å‘Šè¯‰æˆ‘ä»€ä¹ˆæ˜¯ CNN**â€”å®ƒæ˜¯ä¸€ç§äººå·¥ç¥ç»ç½‘ç»œï¼Œèƒ½å¤Ÿåœ¨å›¾åƒä¸­å®šä½æˆ–æ£€æµ‹æ¨¡å¼ã€‚

![](img/9e8631c40478ebf876d9c47f80115562.png)

æœ€å¤§å…±äº«ç¤ºä¾‹ç”±[ç»´åŸºåª’ä½“](https://commons.wikimedia.org/wiki/File:RoI_pooling_animated.gif)

**è§£é‡Š CNN æ¶æ„å†…éƒ¨çš„æƒ…å†µâ€”** CNN CNN æ¶æ„åŸºäºå¤šå±‚å·ç§¯ã€‚å·ç§¯å±‚æ¥æ”¶è¾“å…¥å¹¶è½¬æ¢å›¾åƒä¸­çš„æ•°æ®ï¼Œç„¶åå°†å…¶ä½œä¸ºè¾“å…¥ä¼ é€’ç»™ä¸‹ä¸€å±‚ã€‚è¿™ç§å˜æ¢ç§°ä¸ºå·ç§¯è¿ç®—ã€‚æˆ‘ä»¬éœ€è¦ä¸ºæ¯ä¸ªå·ç§¯å±‚å®šä¹‰è¿‡æ»¤å™¨çš„æ•°é‡ã€‚è¿™äº›æ»¤é•œæ£€æµ‹è¾¹ç¼˜ã€å½¢çŠ¶ã€æ›²çº¿ã€å¯¹è±¡ã€çº¹ç†ç”šè‡³é¢œè‰²ç­‰å›¾æ¡ˆã€‚å®ƒæ£€æµ‹åˆ°çš„æ›´å¤æ‚çš„å›¾æ¡ˆæˆ–ç‰©ä½“çš„å±‚æ¬¡æ›´æ·±ã€‚æœ¬è´¨ä¸Šï¼Œæ»¤é•œæ˜¯å›¾åƒå†…æ ¸ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸º 3Ã—3 æˆ– 4Ã—4ï¼Œè¿™æ˜¯ä¸€ä¸ªåº”ç”¨äºå›¾åƒæ•´ä½“çš„å°çŸ©é˜µã€‚æˆ‘ä»¬å°†æ± å±‚ä¸å·ç§¯å±‚ä¸€èµ·ä½¿ç”¨ï¼Œç›®æ ‡æ˜¯å¯¹è¾“å…¥è¡¨ç¤º(å›¾åƒ)è¿›è¡Œä¸‹é‡‡æ ·ï¼Œé€šè¿‡ä¿ç•™å­åŒºåŸŸç»‘å®šä¸­çš„æœ€å¤§å€¼(æ¿€æ´»çš„ç‰¹å¾)æ¥é™ä½å…¶ç»´æ•°ã€‚åœ¨è¾“å…¥çŸ©é˜µä¸­ç§»åŠ¨çš„åƒç´ æ•°é‡ç§°ä¸ºæ­¥å¹…ã€‚å½“æ­¥å¹…ä¸º 1 æ—¶ï¼Œæˆ‘ä»¬ä¸€æ¬¡å°†è¿‡æ»¤å™¨ç§»åŠ¨ 1 ä¸ªåƒç´ ã€‚å½“æ­¥å¹…ä¸º 2 æ—¶ï¼Œæˆ‘ä»¬å°†è¿‡æ»¤å™¨ä¸€æ¬¡ç§»åŠ¨ 2 ä¸ªåƒç´ ï¼Œä¾æ­¤ç±»æ¨ã€‚è¾ƒå¤§çš„è¿‡æ»¤å™¨å°ºå¯¸å’Œè·¨åº¦å¯ç”¨äºå°†å¤§å›¾åƒçš„å°ºå¯¸å‡å°åˆ°ä¸­ç­‰å°ºå¯¸ã€‚

[GIPHY](https://media.giphy.com/media/i4NjAwytgIRDW/giphy.gif) çš„å·ç§¯è¿ç®—ç¤ºä¾‹

å¥½å§ï¼Œå¦‚æœä½ è®¨åŒæ•°å­¦ï¼Œæ‰€æœ‰è¿™äº›å¤æ‚çš„æ•°å­¦è¿ç®—éƒ½æ˜¯åœ¨å¹•åè¿›è¡Œçš„ï¼Œæˆ‘ä»¬éœ€è¦åšçš„å°±æ˜¯å®šä¹‰è¶…å‚æ•°å’Œå±‚ã€‚å¦‚æœä½ çƒ­çˆ±æ•°å­¦å¹¶æƒ³äº†è§£è¿™äº›*æ•°å­¦è¿ç®—*æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œä½ å¯ä»¥å‚è€ƒå‚è€ƒèµ„æ–™éƒ¨åˆ†çš„é“¾æ¥ã€‚

YT ä¸Šæœ‰ä¸€ä¸ªå¾ˆæ£’çš„è§†é¢‘ï¼Œä»–ä»¬è¯•å›¾åˆ›å»ºäººç±»ç¥ç»ç½‘ç»œã€‚

**é”å®šå¹¶åŠ è½½æˆ‘ä»¬å¼€å§‹åˆ›å»ºçš„ CNN æ¶æ„ã€‚**

Gif via [GIPHY](https://media.giphy.com/media/3o7buflZ5B9MTxcU7u/giphy.gif)

## **4.1 å¿…è¦è¿›å£**

```
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Conv2D,Flatten,MaxPooling2D
from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau
```

## 4.2 CNN æ¶æ„

å¼€å§‹æ„å»º CNN æ¨¡å‹ä¹‹å‰éœ€è¦æ³¨æ„çš„äº‹é¡¹:-

1.  æ€»æ˜¯ä»ä¸€ä¸ªè¾ƒä½çš„è¿‡æ»¤å€¼å¼€å§‹ï¼Œå¦‚ 32ï¼Œç„¶åé€å±‚å¢åŠ ã€‚
2.  ç”¨ Conv2D å±‚å’Œ MaxPooling å±‚æ„å»ºæ¨¡å‹ã€‚
3.  å†…æ ¸å¤§å°æœ€å¥½æ˜¯å¥‡æ•°ï¼Œå¦‚ 3Ã—3ã€‚
4.  Tanhï¼Œrelu ç­‰ã€‚å¯ç”¨äºæ¿€æ´»åŠŸèƒ½ï¼Œä½† relu æ˜¯æœ€ä¼˜é€‰çš„æ¿€æ´»åŠŸèƒ½ã€‚
5.  `input_shape`å–æœ€åä¸€ä¸ªå°ºå¯¸çš„å›¾åƒå®½åº¦&é«˜åº¦ä½œä¸ºé¢œè‰²é€šé“ã€‚
6.  åœ¨ CNN å±‚å’Œæ·»åŠ  ANN å±‚ä¹‹åå¹³å¦åŒ–è¾“å…¥ã€‚
7.  å¦‚æœé—®é¢˜è¶…è¿‡ 2 ç±»ï¼Œåˆ™ä½¿ç”¨æ¿€æ´»å‡½æ•°ä½œä¸ºæœ€åä¸€å±‚çš„ softmaxï¼Œå°†å•ä½å®šä¹‰ä¸ºç±»çš„æ€»æ•°ï¼Œå¹¶ä½¿ç”¨ sigmoid è¿›è¡ŒäºŒè¿›åˆ¶åˆ†ç±»ï¼Œå¹¶å°†å•ä½è®¾ç½®ä¸º 1ã€‚

æ³¨æ„:-æ‚¨å¯ä»¥éšæ—¶è¯•éªŒè¿™äº›è¶…å‚æ•°ï¼Œå› ä¸ºæ²¡æœ‰æˆ‘ä»¬å¯ä»¥ç¡®å®šçš„å›ºå®šå€¼ã€‚

```
cnn = Sequential()cnn.add(Conv2D(32, (3, 3), activation="relu", input_shape=(img_width, img_height, 1)))
cnn.add(MaxPooling2D(pool_size = (2, 2)))cnn.add(Conv2D(32, (3, 3), activation="relu", input_shape=(img_width, img_height, 1)))
cnn.add(MaxPooling2D(pool_size = (2, 2)))cnn.add(Conv2D(32, (3, 3), activation="relu", input_shape=(img_width, img_height, 1)))
cnn.add(MaxPooling2D(pool_size = (2, 2)))cnn.add(Conv2D(64, (3, 3), activation="relu", input_shape=(img_width, img_height, 1)))
cnn.add(MaxPooling2D(pool_size = (2, 2)))cnn.add(Conv2D(64, (3, 3), activation="relu", input_shape=(img_width, img_height, 1)))
cnn.add(MaxPooling2D(pool_size = (2, 2)))cnn.add(Flatten())cnn.add(Dense(activation = 'relu', units = 128))
cnn.add(Dense(activation = 'relu', units = 64))
cnn.add(Dense(activation = 'sigmoid', units = 1))cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])
```

ç°åœ¨æˆ‘ä»¬å·²ç»å¼€å‘äº† CNN æ¨¡å‹ï¼Œè®©æˆ‘ä»¬æ·±å…¥çœ‹çœ‹è¿™é‡Œå‘ç”Ÿäº†ä»€ä¹ˆã€‚

```
cnn.summary() Model: "sequential_1" _________________________________________________________________ Layer (type)                 Output Shape              Param #    ================================================================= conv2d_3 (Conv2D)            (None, 498, 498, 32)      320        _________________________________________________________________ max_pooling2d_3 (MaxPooling2 (None, 249, 249, 32)      0          _________________________________________________________________ conv2d_4 (Conv2D)            (None, 247, 247, 32)      9248       _________________________________________________________________ max_pooling2d_4 (MaxPooling2 (None, 123, 123, 32)      0          _________________________________________________________________ conv2d_5 (Conv2D)            (None, 121, 121, 32)      9248       _________________________________________________________________ max_pooling2d_5 (MaxPooling2 (None, 60, 60, 32)        0          _________________________________________________________________ conv2d_6 (Conv2D)            (None, 58, 58, 64)        18496      _________________________________________________________________ max_pooling2d_6 (MaxPooling2 (None, 29, 29, 64)        0          _________________________________________________________________ conv2d_7 (Conv2D)            (None, 27, 27, 64)        36928      _________________________________________________________________ max_pooling2d_7 (MaxPooling2 (None, 13, 13, 64)        0          _________________________________________________________________ flatten_1 (Flatten)          (None, 10816)             0          _________________________________________________________________ dense_2 (Dense)              (None, 128)               1384576    _________________________________________________________________ dense_3 (Dense)              (None, 64)                8256       _________________________________________________________________ dense_4 (Dense)              (None, 1)                 65         ================================================================= Total params: 1,467,137 Trainable params: 1,467,137 Non-trainable params: 0 _________________________________________________________________
```

## **å£è¯‘æ¨¡å¼æ€»ç»“**

```
# Hyperparameters of Conv2D
Conv2D(
    filters,
    kernel_size,
    strides=(1, 1),
    padding="valid",
    activation=None,
    input_shape=(height,width,color channel)
    )# Hyperparameters of MaxPooling2D 
MaxPooling2D(
    pool_size=(2, 2), strides=None, padding="valid"
    )
```

å›¾åƒçš„è¾“å…¥å½¢çŠ¶æ˜¯æˆ‘ä»¬ä¹‹å‰å®šä¹‰çš„é«˜åº¦&å®½åº¦`(500,500,1)`ã€‚å¹¶ä¸”`1`ä»£è¡¨é¢œè‰²é€šé“ï¼Œå› ä¸ºå›¾åƒæ˜¯ç°åº¦çš„ï¼Œæ‰€ä»¥å®ƒçš„é¢œè‰²é€šé“æ˜¯ 1ï¼Œå¯¹äº rgb å›¾åƒæ˜¯ 3ã€‚

`(none,500,500,1)`åœ¨è¿™é‡Œï¼ŒKeras å¢åŠ äº†ä¸€ä¸ªé¢å¤–çš„ç»´åº¦`none`ï¼Œå› ä¸ºæ‰¹é‡å¤§å°å¯ä»¥å˜åŒ–ã€‚

åœ¨ç¬¬ä¸€ä¸ª`Conv2d`å±‚å·ç§¯æ“ä½œä¸­ï¼Œå¯¹`(500,500)`çš„å›¾åƒä½¿ç”¨`(3,3)`å†…æ ¸å¤§å°ï¼Œæ­¥é•¿å’Œè†¨èƒ€é»˜è®¤è®¾ç½®ä¸º 1ï¼Œå¡«å……è®¾ç½®ä¸ºâ€œæœ‰æ•ˆâ€ï¼Œå®ƒè¾“å‡º`(500-3+1 , 500-3+1 ) = (498,498)`çš„è¾“å‡ºå¤§å°ï¼Œæˆ‘ä»¬å®šä¹‰çš„è¿‡æ»¤å™¨æ•°é‡ä¸º 32ï¼Œè¾“å‡ºå½¢çŠ¶ç°åœ¨ä¸º`(None,498,498,32)`

ç°åœ¨ï¼Œåœ¨ç¬¬ä¸€ä¸ª Max Pooling å±‚ä¸­ï¼Œæˆ‘ä»¬å·²ç»å°†å†…æ ¸å¤§å°å®šä¹‰ä¸º`(2,2)`ï¼Œé»˜è®¤æƒ…å†µä¸‹,`(2,2)`ä¼šå°†å…¶åº”ç”¨åˆ°å›¾åƒå¤§å°çš„è¾“å…¥ä¸­ï¼Œæˆ‘ä»¬å¾—åˆ°çš„æ˜¯`((498â€“2//2)+1,(498â€“2//2)+1))= (249,249)`

å±•å¹³å±‚é‡‡ç”¨æ‰€æœ‰é€šé“ä¸Šçš„æ‰€æœ‰åƒç´ ï¼Œå¹¶åˆ›å»ºä¸€ä¸ª 1D çŸ¢é‡ï¼Œè€Œä¸è€ƒè™‘æ‰¹æ¬¡å¤§å°ã€‚å› æ­¤ï¼Œ`(13, 13, 64)`çš„è¾“å…¥è¢«æ‹‰å¹³ä¸º`(13*13*64) = 10816`çš„å€¼ã€‚

å‚æ•°å€¼ç”±ç¬¬ä¸€å±‚çš„`(3*3*1*32)+(32) = 320`ç»™å‡ºçš„`(kernel_height * kernel_width * input_channels * output_channels) + (output_channels)`è®¡ç®—ã€‚

æ•´æµçº¿æ€§æ¿€æ´»å‡½æ•°æˆ–çŸ­æœŸ ReLU æ˜¯åˆ†æ®µçº¿æ€§å‡½æ•°ï¼Œå¦‚æœä¸ºæ­£ï¼Œåˆ™ç›´æ¥è¾“å‡ºè¾“å…¥ï¼Œå¦åˆ™è¾“å‡ºé›¶ã€‚æ ¡æ­£çš„çº¿æ€§æ¿€æ´»å‡½æ•°å…‹æœäº†æ¶ˆå¤±æ¢¯åº¦çš„é—®é¢˜ï¼Œå…è®¸æ¨¡å‹æ›´å¿«åœ°å­¦ä¹ å’Œæ›´å¥½åœ°æ‰§è¡Œã€‚

å¡«å……â€” `"SAME"`:è¾“å‡ºå°ºå¯¸ä¸è¾“å…¥å°ºå¯¸**ç›¸åŒ**ã€‚è¿™è¦æ±‚æ»¤æ³¢å™¨çª—å£æ»‘åŠ¨åˆ°è¾“å…¥æ˜ å°„ä¹‹å¤–ï¼Œå› æ­¤éœ€è¦å¡«å……ã€‚`"VALID"`:æ»¤æ³¢çª—å£åœç•™åœ¨è¾“å…¥å›¾å†…çš„**æœ‰æ•ˆ**ä½ç½®ï¼Œè¾“å‡ºå°ºå¯¸ç¼©å°`filter_size - 1`ã€‚ä¸ä¼šå‡ºç°å¡«å……ã€‚

æ¿€æ´»å‡½æ•°-ç®€å•åœ°è¯´ï¼Œæ¿€æ´»æ˜¯ä¸€ç§æ·»åŠ åˆ°äººå·¥ç¥ç»ç½‘ç»œä¸­çš„å‡½æ•°ï¼Œç”¨äºå¸®åŠ©ç½‘ç»œå­¦ä¹ æ•°æ®ä¸­çš„å¤æ‚æ¨¡å¼ã€‚å½“ä¸æˆ‘ä»¬å¤§è„‘ä¸­åŸºäºç¥ç»å…ƒçš„æ¨¡å‹è¿›è¡Œæ¯”è¾ƒæ—¶ï¼Œæ¿€æ´»åŠŸèƒ½åœ¨ä¸€å¤©ç»“æŸæ—¶å†³å®šå¯¹ä¸‹ä¸€ä¸ªç¥ç»å…ƒåšä»€ä¹ˆã€‚ç”±äºåˆ†ç±»åœ¨ä¸¤ä¸ªç±»ä¹‹é—´ï¼Œæˆ‘ä»¬å°†å¯¹æœ€åä¸€å±‚ä½¿ç”¨ sigmoid æ¿€æ´»å‡½æ•°ï¼Œè¯¥å‡½æ•°è¿”å›å€¼åœ¨ 0 åˆ° 1 çš„èŒƒå›´å†…ã€‚å¯¹äº 2 ä¸ªä»¥ä¸Šçš„ç±»ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ softmax æ¿€æ´»åŠŸèƒ½ã€‚

## å®šä¹‰æ¨¡å‹ç¼–è¯‘

*   å­¦ä¹ ç‡â€”â€”è®­ç»ƒæ—¶ï¼Œéšæœºæ¢¯åº¦ä¸‹é™çš„ç›®æ ‡æ˜¯æœ€å°åŒ–è®­ç»ƒé›†çš„å®é™…å€¼å’Œé¢„æµ‹å€¼ä¹‹é—´çš„æŸå¤±ã€‚å‡å°‘æŸå¤±çš„é€”å¾„éœ€è¦å‡ ä¸ªæ­¥éª¤ã€‚Adam æ˜¯ä¸€ç§è‡ªé€‚åº”å­¦ä¹ ç‡æ–¹æ³•ï¼Œè¿™æ„å‘³ç€å®ƒè®¡ç®—ä¸åŒå‚æ•°çš„ä¸ªäººå­¦ä¹ ç‡ã€‚
*   æŸå¤±å‡½æ•°-ç”±äºè¿™æ˜¯ä¸€ä¸ªäºŒå…ƒåˆ†ç±»ï¼Œæˆ‘ä»¬å°†åœ¨è®­ç»ƒæœŸé—´ä½¿ç”¨äºŒå…ƒäº¤å‰ç†µæ¥è¯„ä¼°æŸå¤±ã€‚å¦‚æœæœ‰ 4 ä¸ªä»¥ä¸Šçš„ç±»ï¼Œæˆ‘ä»¬ä¼šé€‰æ‹©åˆ†ç±»äº¤å‰ç†µã€‚
*   åº¦é‡â€”å‡†ç¡®æ€§â€”è®¡ç®—å®é™…æ ‡ç­¾ä¸é¢„æµ‹å€¼ç›¸ç­‰çš„é¢‘ç‡ã€‚å®ƒå°†æµ‹é‡è®­ç»ƒå’ŒéªŒè¯çš„æŸå¤±å’Œå‡†ç¡®æ€§ã€‚

**å¯è§†åŒ– CNN æ¨¡å‹**

```
from tensorflow.keras.utils import plot_modelplot_model(cnn,show_shapes=True, show_layer_names=True, rankdir='TB', expand_nested=True)
```

![](img/31b22a3bf78c41f4526dde7d58d4af4f.png)

ç»˜åˆ¶ CNN æ¶æ„

## 4.3 æ‹Ÿåˆæ¨¡å‹

**å®šä¹‰å›è°ƒåˆ—è¡¨**

æ ¹æ®ä¸€äº›åº¦é‡æ ‡å‡†(`monitor`)å’Œæ¡ä»¶(`mode, patience`)è°ƒç”¨`EarlyStopping`æ¥åœæ­¢å†å…ƒã€‚è¿™æœ‰åŠ©äºé¿å…è¿‡åº¦æ‹Ÿåˆæ¨¡å‹ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å‘Šè¯‰åœæ­¢åŸºäº`val_loss`æŒ‡æ ‡ï¼Œæˆ‘ä»¬éœ€è¦å®ƒæ˜¯æœ€å°çš„ã€‚`patience`è¡¨ç¤ºåœ¨è¾¾åˆ°æœ€å° val_loss ä¹‹åï¼Œåœ¨æ¥ä¸‹æ¥çš„è¿­ä»£ä¸­ï¼Œå¦‚æœ val_loss åœ¨ 3 æ¬¡è¿­ä»£ä¸­çš„ä»»ä½•ä¸€æ¬¡ä¸­å¢åŠ ï¼Œåˆ™è®­ç»ƒå°†åœ¨è¯¥æ—¶æœŸåœæ­¢ã€‚

å½“æŒ‡æ ‡åœæ­¢æ”¹å–„æ—¶ï¼Œé™ä½å­¦ä¹ ç‡ã€‚ä¸€æ—¦å­¦ä¹ åœæ»ï¼Œæ¨¡å‹é€šå¸¸ä¼šå—ç›Šäºå°†å­¦ä¹ é€Ÿåº¦é™ä½ 2-10 å€ã€‚è¿™ç§å›è°ƒç›‘æ§ä¸€ä¸ªæ•°é‡ï¼Œå¦‚æœåœ¨â€œè€å¿ƒâ€æ¬¡æ•°å†…æ²¡æœ‰çœ‹åˆ°æ”¹è¿›ï¼Œåˆ™å­¦ä¹ ç‡é™ä½ã€‚[æ¥æº](https://keras.io/api/callbacks/reduce_lr_on_plateau/)

```
early = EarlyStopping(monitor=â€val_lossâ€, mode=â€minâ€, patience=3)learning_rate_reduction = ReduceLROnPlateau(monitor=â€™val_lossâ€™, patience = 2, verbose=1,factor=0.3, min_lr=0.000001)callbacks_list = [ early, learning_rate_reduction]
```

**åˆ†é…ç±»åˆ«æƒé‡**

ä¸ºæ¯ä¸ªç±»åˆ†é…ç±»æƒé‡æ˜¯ä¸€ç§å¾ˆå¥½çš„åšæ³•ã€‚å®ƒå¼ºè°ƒå°‘æ•°ç±»çš„æƒé‡ï¼Œä»¥ä¾¿æ¨¡å‹èƒ½å¤Ÿå¹³ç­‰åœ°ä»æ‰€æœ‰ç±»ä¸­å­¦ä¹ ã€‚

```
from sklearn.utils.class_weight import compute_class_weight
weights = compute_class_weight('balanced', np.unique(train.classes), train.classes)
cw = dict(zip( np.unique(train.classes), weights))
print(cw)
```

`{0: 1.9371534195933457, 1: 0.6739549839228296}`

## ç°åœ¨ä¸€åˆ‡éƒ½å‡†å¤‡å¥½äº†ï¼Œè¿›å…¥æœ€åä¸€æ­¥**è®­ç»ƒğŸ’ª**

Gif via [GIPHY](https://media.giphy.com/media/3o7qE4gcYTW1zZPkre/giphy.gif)

æˆ‘ä»¬ä¼ é€’ç»™ model.fit çš„å‚æ•°æ˜¯è®­ç»ƒé›†ã€epochs as 25ã€ç”¨äºè®¡ç®— val_loss å’Œ val_accuracy çš„éªŒè¯é›†ã€ç±»æƒé‡å’Œå›è°ƒåˆ—è¡¨ã€‚

```
cnn.fit(train,epochs=25, validation_data=valid, class_weight=cw, callbacks=callbacks_list)
```

![](img/33627b2a551b269c4da3bc9134160f8a.png)

è®­ç»ƒæ¨¡å‹

çœ‹èµ·æ¥æ—©æœŸåœæ­¢åœ¨ val_loss =14.9%å’Œ val_accuracy = 94.6%çš„ç¬¬ 10 ä¸ªå†å…ƒåœæ­¢ã€‚

# 5 è¯„ä¼°

è®©æˆ‘ä»¬ç›´è§‚åœ°çœ‹åˆ°æ‰€æœ‰æŒ‡æ ‡åœ¨æ•´ä¸ªæ—¶æœŸç”Ÿå‘½å‘¨æœŸä¸­çš„è¿›å±•

```
pd.DataFrame(cnn.history.history).plot()
```

![](img/aaf51c5ee34ecbba2f3c50cb7c15f8f4.png)

ç»˜åˆ¶åº¦é‡è¿›åº¦

æˆ‘ä»¬åœ¨æµ‹è¯•æ•°æ®é›†ä¸Šè·å¾—çš„å‡†ç¡®ç‡æ˜¯ 91%

```
test_accu = cnn.evaluate(test)print('The testing accuracy is :',test_accu[1]*100, '%')
```

`39/39 [==============================] â€” 50s 1s/step â€” loss: 0.3132 â€” accuracy: 0.9119 The testing accuracy is : 91.18589758872986 %`

è®©æˆ‘ä»¬é¢„æµ‹æµ‹è¯•æ•°æ®é›†ï¼Œå¹¶è¯¦ç»†æŸ¥çœ‹ä¸€äº›æ€§èƒ½æµ‹é‡æŒ‡æ ‡æ¥è¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹ã€‚

```
preds = cnn.predict(test,verbose=1)
```

`39/39 [==============================] â€” 46s 1s/step`

å› ä¸ºæœ€åä¸€å±‚çš„æ¿€æ´»å‡½æ•°æ˜¯ sigmoidï¼Œæ‰€ä»¥è¯¥æ¨¡å‹ç»™å‡º 0 åˆ° 1 èŒƒå›´å†…çš„é¢„æµ‹ï¼Œè€Œä¸æ˜¯ 0 æˆ– 1 çš„ç²¾ç¡®åˆ†ç±»ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°† 0.5 åˆ° 1 èŒƒå›´å†…çš„æ‰€æœ‰å€¼åˆ†ç±»ä¸º 0ï¼Œå°†å°äº 0.5 çš„å€¼åˆ†ç±»ä¸º 1ã€‚æ³¨(0 è¡¨ç¤ºæ­£å¸¸æƒ…å†µï¼Œ1 è¡¨ç¤ºè‚ºç‚æƒ…å†µ)

```
predictions = preds.copy()
predictions[predictions <= 0.5] = 0
predictions[predictions > 0.5] = 1
```

**æ··æ·†çŸ©é˜µ**

![](img/d79f96a732591b13dc26b08a25f41a94.png)

æ··ä¹±çŸ©é˜µçš„ä¾‹å­ç”±[ç»´åŸºåª’ä½“](https://commons.wikimedia.org/wiki/File:ConfusionMatrixRedBlue.png)

è®©æˆ‘ä»¬æ¥è§£é‡Šæ··æ·†çŸ©é˜µçš„è¾“å‡ºã€‚å·¦ä¸Š(TP)è¡¨ç¤ºè¢«æ­£ç¡®é¢„æµ‹ä¸ºæ­£å¸¸ç—…ä¾‹çš„å›¾åƒæ•°é‡ï¼Œå³ä¸‹(TN)è¡¨ç¤ºè¢«æ­£ç¡®é¢„æµ‹ä¸ºè‚ºç‚ç—…ä¾‹çš„å›¾åƒæ•°é‡ã€‚ä½œä¸ºè‚ºç‚ç—…ä¾‹ï¼Œå³ä¸Šè¡¨ç¤ºä¸æ­£ç¡®é¢„æµ‹ä½†å®é™…ä¸Šæ˜¯æ­£å¸¸ç—…ä¾‹çš„å›¾åƒçš„æ•°é‡ï¼Œå·¦ä¸‹è¡¨ç¤ºä¸æ­£ç¡®é¢„æµ‹ä½†å®é™…ä¸Šæ˜¯è‚ºç‚ç—…ä¾‹çš„æ­£å¸¸ç—…ä¾‹å›¾åƒçš„æ•°é‡ã€‚

Gif via [GIPHY](https://media.giphy.com/media/1oJLpejP9jEvWQlZj4/giphy.gif)

**ï¼Ÿï¼Ÿè¿˜åœ¨å›°æƒ‘å›°æƒ‘çŸ©é˜µï¼Ÿï¼Ÿ**

> è§£é‡ŠäºŒå…ƒæˆ–å¤šç±»åˆ†ç±»çš„æ··æ·†çŸ©é˜µçš„ç®€å•æ–¹æ³•æ˜¯æŸ¥çœ‹æˆ‘ä»¬æ˜¯å¦åœ¨ä»å·¦åˆ°å³çš„å¯¹è§’çº¿åƒå…ƒä¸­è·å¾—æœ€å¤§å€¼ï¼Œåœ¨å…¶ä½™åƒå…ƒä¸­è·å¾—æœ€å°å€¼ã€‚

```
from sklearn.metrics import classification_report,confusion_matrix
cm = pd.DataFrame(data=confusion_matrix(test.classes, predictions, labels=[0, 1]),index=["Actual Normal", "Actual Pneumonia"],
columns=["Predicted Normal", "Predicted Pneumonia"])import seaborn as sns
sns.heatmap(cm,annot=True,fmt="d")
```

![](img/4b0fa93036d9c475e95cb2bfc3f07d6a.png)

æ··æ·†çŸ©é˜µ

**åˆ†ç±»æŠ¥å‘Š**

*   ç²¾åº¦=çœŸé˜³æ€§/(çœŸé˜³æ€§+å‡é˜³æ€§)
*   å›å¿†=çœŸé˜³æ€§/(çœŸé˜³æ€§+å‡é˜´æ€§)
*   F1 = (2 *ç²¾åº¦*å¬å›)/(ç²¾åº¦+å¬å›)

```
print(classification_report(y_true=test.classes,y_pred=predictions,target_names =['NORMAL','PNEUMONIA']))
```

![](img/a3a45282b1d4b27c52c33b7c7b306aca.png)

åˆ†ç±»æŠ¥å‘Š

**è®©æˆ‘ä»¬ç”¨ç™¾åˆ†æ¯”%** å¯è§†åŒ–ä¸€äº›é¢„æµ‹å›¾åƒ

```
test.reset()
x=np.concatenate([test.next()[0] for i in range(test.__len__())])
y=np.concatenate([test.next()[1] for i in range(test.__len__())])
print(x.shape)
print(y.shape)#this little code above extracts the images from test Data iterator without shuffling the sequence# x contains image array and y has labels dic = {0:'NORMAL', 1:'PNEUMONIA'}
plt.figure(figsize=(20,20))
for i in range(0+228, 9+228):
  plt.subplot(3, 3, (i-228)+1)
  if preds[i, 0] >= 0.5: 
      out = ('{:.2%} probability of being Pneumonia case'.format(preds[i][0]))

  else: 
      out = ('{:.2%} probability of being Normal case'.format(1-preds[i][0]))plt.title(out+"\n Actual case : "+ dic.get(y[i]))    
  plt.imshow(np.squeeze(x[i]))
  plt.axis('off')
plt.show()
```

![](img/fe32434c08e2eded56db573381a96b22.png)

æµ‹è¯•æ•°æ®é¢„æµ‹

æ­¤ä»£ç å—ç»™å‡ºäº†å•ä¸ªå›¾åƒçš„ç™¾åˆ†æ¯”é¢„æµ‹ï¼Œå¯ä»¥é€šè¿‡æŒ‡å®šå…¶è·¯å¾„ç›´æ¥ä»æ‚¨çš„é©±åŠ¨å™¨åŠ è½½ã€‚

åœ¨å¯¼å…¥å›¾åƒåï¼Œæˆ‘ä»¬å¿…é¡»åœ¨è¿™é‡Œé‡æ–°åˆ›å»ºæ‰€æœ‰çš„æ•°æ®é¢„å¤„ç†æ­¥éª¤ï¼Œå°±åƒæˆ‘ä»¬ä¹‹å‰å°†æµ‹è¯•é›†è¾“å…¥æ¨¡å‹ä»¥è·å¾—é¢„æµ‹ä¸€æ ·ã€‚å¯¹äºé¢„å¤„ç†ï¼Œæˆ‘ä»¬éœ€è¦å¯¼å…¥`tensorflow.keras.preprocessing.image`ç±»ã€‚

1.  å¯¼å…¥å›¾åƒï¼Œå®šä¹‰å°ºå¯¸ä¸º`(500,500)`ï¼Œé¢œè‰²é€šé“ä¸ºç°åº¦ã€‚
2.  å°†å›¾åƒè½¬æ¢ä¸ºæ•°ç»„ï¼Œå°†å®ƒé™¤ä»¥ 255 è¿›è¡Œç¼©æ”¾ï¼Œå°†ç»´åº¦æ‰©å±•åˆ°è½´= 0ï¼Œå› ä¸ºæˆ‘ä»¬çš„æ¨¡å‹éœ€è¦ 4 ä¸ªç»´åº¦ï¼Œå¦‚å‰æ‰€è¿°ã€‚
3.  æœ€åæˆ‘ä»¬æ¥é¢„æµ‹ä¸€ä¸‹æ¡ˆæƒ…ï¼

**è®©æˆ‘ä»¬ç”¨æˆ‘çš„ X å°„çº¿å¯¹æˆ‘ä»¬çš„æ¨¡å‹åšä¸€äº›å®åœ°æµ‹è¯•**

```
# Testing with my own Chest X-Ray
hardik_path = '/content/drive/My Drive/unsegregated /IMG_20201023_204205928~2.jpg'from tensorflow.keras.preprocessing import imagehardik_img = image.load_img(hardik_path, target_size=(500, 500),color_mode='grayscale')# Preprocessing the image
pp_hardik_img = image.img_to_array(hardik_img)
pp_hardik_img = pp_hardik_img/255
pp_hardik_img = np.expand_dims(pp_hardik_img, axis=0)#predict
hardik_preds= cnn.predict(pp_hardik_img)#print
plt.figure(figsize=(6,6))
plt.axis('off')
if hardik_preds>= 0.5: 
    out = ('I am {:.2%} percent confirmed that this is a Pneumonia case'.format(hardik_preds[0][0]))

else: 
    out = ('I am {:.2%} percent confirmed that this is a Normal case'.format(1-hardik_preds[0][0]))plt.title("Hardik's Chest X-Ray\n"+out)  
plt.imshow(np.squeeze(pp_hardik_img))
plt.show()
```

![](img/10401c711ac87c52ab2c777baf83b797.png)

å“ˆè¿ªå…‹çš„èƒ¸éƒ¨ x å…‰ç‰‡

**Phew** ã€‚æˆ‘çš„èƒ¸éƒ¨ x å…‰æ£€æŸ¥ä¼¼ä¹ä¸€åˆ‡æ­£å¸¸ã€‚ç°åœ¨è½®åˆ°ä½ è¯Šæ–­èƒ¸é€äº†ã€‚

# å¹²å¾—å¥½ï¼æˆ‘ä»¬åˆšåˆšåˆ›å»ºäº†ä¸€ä¸ª CNN æ¨¡å‹ï¼Œå¯ä»¥ä»¥ 91%çš„å‡†ç¡®ç‡å°† X å°„çº¿å›¾åƒåˆ†ç±»ä¸ºè‚ºç‚ç—…ä¾‹æˆ–æ­£å¸¸ç—…ä¾‹ã€‚

Gif via [GIPHY](https://media.giphy.com/media/XreQmk7ETCak0/giphy.gif)

æ„Ÿè°¢ä½ åœ¨è¿™ä¸ªæ¼«é•¿çš„æ—…ç¨‹ä¸­é™ªä¼´æˆ‘ï¼Œæˆ‘ä»¬åˆšåˆšä¸ºâ‚¹çœä¸‹äº† 466 ä¸‡å¢æ¯” x 4 å¹´çš„æ”¾å°„å­¦å®¶å­¦ä½ï¼Œç°åœ¨æˆ‘ä»¬èƒ½å¤Ÿå¯¹ x å…‰è¿›è¡Œåˆ†ç±»ã€‚

## å…³æ³¨æˆ‘çš„ç¤¾äº¤æ´»åŠ¨

é“¾æ¥åˆ°æˆ‘å…³äºè¿™ä¸ªé¡¹ç›®çš„ç¬”è®°æœ¬:[colab.research.google.com](https://colab.research.google.com/drive/1J6nM1LlGE-DW93QO-yFkeBSGv9OQoHSC?usp=sharing)

æˆ‘çš„ LinkedIn ä¸ªäººèµ„æ–™:[https://www.linkedin.com/in/hardik-deshmukh/](https://www.linkedin.com/in/hardik-deshmukh/)

æˆ‘çš„å…¶ä»–åª’ä½“æ–‡ç« :[https://medium.com/@smarthardik10](https://medium.com/@smarthardik10)

æˆ‘çš„ GitHub:[https://github.com/smarthardik10](https://github.com/smarthardik10)

éƒ¨ç½²åœ¨ streamlit ä¸Šçš„åº”ç”¨ç¨‹åº:

https://share . streamlit . io/smarthardk 10/Xray-classifier/main/web app . py

# å‚è€ƒ

[1][https://stack overflow . com/questions/61060736/how-to-interpret-model-summary-output-in-CNN](https://stackoverflow.com/questions/61060736/how-to-interpret-model-summary-output-in-cnn)

[2][https://towards data science . com/a-guide-to-a-efficient-way-to-build-neural-network-architectures-part-ii-hyper-parameter-42 efca 01 e5d 7](/a-guide-to-an-efficient-way-to-build-neural-network-architectures-part-ii-hyper-parameter-42efca01e5d7)

[3][https://medium . com/@ RaghavPrabhu/understanding-of-convolutionary-neural-network-CNN-deep-learning-99760835 f148 #:~:text = Stridesï¼Œwith%20a%20stride%20of%202](https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148#:~:text=Strides,with%20a%20stride%20of%202) ã€‚

[4][https://machine learning mastery . com/rectified-linear-activation-function-for-deep-learning-neural-networks/](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/)

[5][https://stack overflow . com/questions/37674306/what-the-difference-than-same-and-valid-padding-in-TF-nn-max-pool-of-t](https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t)

[6][https://deep lizard . com/learn/playlist/plzbt5o _ S2 Q7 lw i2y 8 _ qtvuxzedl 6 qu](https://deeplizard.com/learn/playlist/PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU)

[7][https://towards data science . com/Adam-latest-trends-in-deep-learning-optimization-6be 9a 291375 c](/adam-latest-trends-in-deep-learning-optimization-6be9a291375c)

[8][https://towardsdatascience . com/everything-you-need-known-to-know-about-activation-functions-in-deep-learning-models-84ba 9f 82 c 253](/everything-you-need-to-know-about-activation-functions-in-deep-learning-models-84ba9f82c253)