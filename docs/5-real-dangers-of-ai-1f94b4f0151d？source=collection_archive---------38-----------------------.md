# 人工智能的 5 个真正危险

> 原文：<https://towardsdatascience.com/5-real-dangers-of-ai-1f94b4f0151d?source=collection_archive---------38----------------------->

![](img/133867982a6107a388b9312c6e645eae.png)

来源:[迅猎兽图片](https://www.pexels.com/@skitterphoto)通过[像素](https://www.pexels.com/photo/brown-wooden-mouse-trap-with-cheese-bait-on-top-633881/)

## 深度造假、算法偏见和其他问题会如何影响我们的日常生活

在过去的几年里，人工智能以令人难以置信的速度推进了我们的技术。从完全自动化劳动密集型工作到诊断肺癌，人工智能已经取得了以前认为不可能的成就。然而，在错误的人手中，算法可能成为毁灭性的武器。为了确保恶意行为者不会对我们的社会造成破坏，我们必须解决几个关键挑战。

人工智能的真正危险不是像天网一样的有感知能力的算法接管世界。尽管这种情况完全是科幻小说，但有几个合理的问题。我们不应该害怕技术，而应该仔细识别这些问题，并负责解决它们。在这篇文章中，我将收集五个特别重要并且已经影响我们日常生活的领域。

# 1.Deepfake

在我们的现代社会中，信息是无限的。打开你的浏览器，在网上冲浪半个小时，你遇到的信息比一个普通的中年人一生中遇到的信息还要多。信息就是力量。地球另一端发生的事件会立即通知你，但有一个问题:你如何知道该相信什么，哪些消息来源是可信的？

看看下面这个视频。

当然，这完全是假的，但是对于一个不经意的观察者来说，可能很难察觉。这些被称为*深度假货*，源于技术术语*深度学习*，这是一个能够产生类似这样的逼真假货图像的算法家族。尽管这个特殊的例子只是一个很好的技术演示，但是如果出现在新闻提要中的深度假货的比例达到一定的阈值，就会变得非常危险。在这种情况下，将无法检测哪些信息是真实的，哪些不是。

毫不奇怪，一个非常有前途的打击深度假货的工具就是 AI 本身。有几个高调的倡议，如 [DARPA 的 MediFor 计划](https://www.darpa.mil/program/media-forensics)或[谷歌的 Deepfake 检测挑战](https://www.kaggle.com/c/deepfake-detection-challenge/)旨在开发过滤错误信息的方法。

尽管深度虚假不像列表中的其他虚假一样出现在我们的生活中，但它无疑是最具破坏性的虚假之一。

# 2.算法偏差

如果你在过去几年里申请过工作，很可能你已经受到了算法偏差的影响，无论是正面的还是负面的。开发一个基于人工智能的算法来筛选求职者可能是一个好主意，但是，这有很大的问题。机器学习需要历史数据来学习哪些候选人值得聘用。问题是，关于过去接受和拒绝的数据受到固有的人类偏见的严重影响，主要是对妇女和代表性不足的少数民族。该算法只是从呈现给它的东西中学习，如果以前的招聘做法是歧视性的(这种情况经常发生)，该算法将以类似的方式行事。

这种现象的一个极好的、发人深省的证明是最适合的教育网络游戏的[生存，这值得一试。](https://www.survivalofthebestfit.com/)

这个问题影响到许多其他应用领域，如信用评分评估、执法等。由于这些在相关人员生活中的纯粹影响，这些决定不应该涉及算法，除非我们能够保证公平。这方面的努力产生了一个新的非常活跃的研究领域。除了确保预测独立于性别、种族和受负面偏见影响的类似变量之外，关键是在这些变量不存在的地方产生数据。要解决这个问题，需要付出更大的努力。为了完全消除数据中的偏见，我们还需要消除我们思维中的偏见，因为最终，数据是我们行动的结果。

# 3.大规模监控

> 那些为了换取一点暂时的安全而放弃基本自由的人，既不配享有自由，也不配享有安全。—本杰明·富兰克林

几十年来，面部识别一直是计算机视觉中的一个关键问题。然而，自从深度学习革命以来，我们不仅可以更准确地识别人脸，而且可以即时完成。如果你把智能手机放在周围，尝试打开相机应用程序并自拍:它会立即在你的脸部周围放置一个边界框，表明它已经成功检测到它。如果你有一部最新的 iPhone，你甚至可以用你的脸作为手机的密码。

如果用于错误的目的，这项技术也有其自身的危险。在中国，这被用于前所未有的大规模监控。结合最近推出的社会信用系统，你的行为会被记分，你可能会因乱穿马路或只是参加某些活动而被扣分，没有什么可以瞒过天空中的眼睛。

# 4.推荐引擎

每次你打开 YouTube、脸书或任何其他社交媒体网站，他们的目标都是尽可能让你参与进来。简单地说，在这种情况下，你就是产品:如果你偶尔看广告，你可以免费使用网站。因此，目标不是为用户提供高质量的内容，而是让他们无限地滚动和自动播放。

鉴于人类大脑是如何进化的，不幸的是，参与是由引发强烈的情绪反应来驱动的。事实证明，例如政治激进的内容特别适合这一点。推荐引擎不仅学会了呈现极端的内容，还学会了慢慢地让每个用户变得激进，一旦用户的偏好发生变化，推荐引擎的工作就会变得简单。这就是所谓的激进化管道。

这是有确凿的科学证据的。例如，最近的一篇论文研究了 YouTube 上数百万特定用户的评论，以展示他们如何慢慢转向极端激进的内容。

这种情况的影响非常严重，可能会对民主选举产生重大影响。在 2016 年美国大选期间，《华尔街日报》对这个话题进行了广泛的调查。他们的发现可以在这里找到:[蓝色饲料，红色饲料](https://graphics.wsj.com/blue-feed-red-feed/)。本质上，用户被有目的地关在一个智力的泡泡里，从不质疑他们自己对外部世界的信念。思考很难，本能反应很容易。

# 5.隐私和定向广告

你有没有发现自己买了并不真正需要的东西，事后后悔？也许你走进超市，一进入收银台，一捆糖果就吸引了你的目光，你毫不犹豫地把它们放进了篮子里。你并不真的需要它，但你还是买了它。这可能会让你感到惊讶，但是这整个场景是被设计的，你被操纵着去做这件事。听起来很奇怪，购物实际上需要你的精神资源，这些资源最终会被耗尽。控制欲望的资源越少，你就越有可能冲动地购买明知对你无益的东西(比如糖果)，但你还是想买。但是这和 AI 有什么关系呢？

超市的设计是基于这些基本的心理学原理，如上所述。这些设计原则在平均水平上起作用。没有一个设计能为每个用户提供个性化和完美的体验。然而，当市场转移到网上时，这种情况发生了变化。虚拟市场不仅可以为你提供量身定制的购物之旅，还可以收集非常具体的数据。基于你的浏览习惯和社交网络，你的行动可以被高度准确地预测。

这有几个潜在的误用。首先是向你展示你可能会在网上市场购买的物品。一件商品呈现给你的内容、地点和方式是由统计算法决定的，目的是从你身上获取最大利润。然而，这影响到个人层面。一个更大的问题是，当个人数据被用于针对你的政治广告时，可能会影响民主选举的结果。这正是剑桥分析公司所做的事情，其影响仍然波及全球。

# 结论

近年来，基于人工智能的技术无疑彻底改变了我们的生活。即使它正在慢慢渗透到我们周围的一切，但它在媒体上的出现大多是有偏见的。无论是通过炒作的粉红色薄雾或天网灭绝人类的可怕愿景。没有一个是真的。然而，为了使他们的应用安全，我们必须清楚地看到人工智能可能带来的真正问题。这些问题并不神秘，它们已经存在于我们的生活中。通过适当的认识、准备和社区努力，这些问题是可以解决的。

[***如果你喜欢把机器学习概念拆开，理解是什么让它们运转，我们有很多共同点。看看我的博客，我经常在那里发表这样的技术文章！***](https://www.tivadardanka.com/blog)