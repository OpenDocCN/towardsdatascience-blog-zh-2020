<html>
<head>
<title>Don’t be Afraid of Nonparametric Topic Models (Part 2: Python)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不要害怕非参数主题模型(第2部分:Python)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/dont-be-afraid-of-nonparametric-topic-models-part-2-python-e5666db347a?source=collection_archive---------10-----------------------#2020-05-27">https://towardsdatascience.com/dont-be-afraid-of-nonparametric-topic-models-part-2-python-e5666db347a?source=collection_archive---------10-----------------------#2020-05-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="7822" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/video-tutorial" rel="noopener" target="_blank">视频教程</a></h2><div class=""/><div class=""><h2 id="b3b3" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">准备好开始你的模特游戏了吗？深入了解如何实现/评估分层Dirichlet过程模型的简单分步教程</h2></div><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="kt ku l"/></div></figure><p id="63c2" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="lr">本文建立在我在上一篇文章</em>  <em class="lr">中介绍的高级基础材料</em> <a class="ae ls" rel="noopener" target="_blank" href="/dont-be-afraid-of-nonparametric-topic-models-d259c237a840"> <em class="lr">的基础上，描述了如何用Python实现主题建模的层次化Dirichlet过程模型。</em></a></p><p id="747d" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们都同意，学习和谈论很酷的新方法是一回事，用数据实际实施/测试它们是另一回事。主要是因为对它们的了解不会带来bug、奇怪的错误等典型的挫折。然而，我个人认为，修补的结果是对概念本身的更深理解。</p><p id="5b19" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">你猜怎么着？贝叶斯非参数(BNP)方法，如分层狄利克雷过程(HDP)也不例外。</p><p id="1858" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在你认为我要把你扔进编码池的最深处之前，不要担心。我写这篇文章的总体目标是，最终你可以<strong class="kx ja">自信地实现一个HDP模型，在你的项目中驱动价值</strong>(或者允许你向你的朋友谦虚地吹嘘)。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lt"><img src="../Images/9faafe6db86a747fedd853b327bc5e78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8xASyiVgFXIz-xmc"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">由<a class="ae ls" href="https://unsplash.com/@markadriane?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> MARK ADRIANE </a>在<a class="ae ls" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="e49b" class="me mf iq bd mg mh mi mj mk ml mm mn mo kf mp kg mq ki mr kj ms kl mt km mu mv bi translated"><strong class="ak">一目了然</strong></h1><p id="8e26" class="pw-post-body-paragraph kv kw iq kx b ky mw ka la lb mx kd ld le my lg lh li mz lk ll lm na lo lp lq ij bi translated">以下是我将介绍的内容</p><ul class=""><li id="be25" class="nb nc iq kx b ky kz lb lc le nd li ne lm nf lq ng nh ni nj bi translated">关于如何使用现有Python库实现HDP模型的分步教程</li><li id="05b3" class="nb nc iq kx b ky nk lb nl le nm li nn lm no lq ng nh ni nj bi translated">其性能与潜在狄利克雷分配(LDA)模型相比如何</li><li id="1b17" class="nb nc iq kx b ky nk lb nl le nm li nn lm no lq ng nh ni nj bi translated">实施HDP时的一些关键注意事项、陷阱和潜在的修复方法</li></ul><p id="872d" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我将使用通过<code class="fe np nq nr ns b">sklearn.datasets</code>获得的<a class="ae ls" href="http://qwone.com/~jason/20Newsgroups/" rel="noopener ugc nofollow" target="_blank"> 20新闻组数据集</a>。考虑到大约20，000个文档的集合几乎平均分布在20个不同的主题(新闻组)中，这是一个很棒的玩具数据集。由此可见，从某种意义上说我们已经知道了<em class="lr">真题</em> <strong class="kx ja"> <em class="lr"> </em> </strong>这个模本应该推断出来。</p><h1 id="017c" class="me mf iq bd mg mh mi mj mk ml mm mn mo kf mp kg mq ki mr kj ms kl mt km mu mv bi translated"><strong class="ak">目录</strong></h1><p id="7287" class="pw-post-body-paragraph kv kw iq kx b ky mw ka la lb mx kd ld le my lg lh li mz lk ll lm na lo lp lq ij bi translated">这篇文章分为以下几个部分</p><ol class=""><li id="ced0" class="nb nc iq kx b ky kz lb lc le nd li ne lm nf lq nt nh ni nj bi translated"><strong class="kx ja">数据预处理</strong></li><li id="7591" class="nb nc iq kx b ky nk lb nl le nm li nn lm no lq nt nh ni nj bi translated"><strong class="kx ja"> HDP模特培训与评估</strong></li><li id="5ccd" class="nb nc iq kx b ky nk lb nl le nm li nn lm no lq nt nh ni nj bi translated"><strong class="kx ja">型号对比</strong></li><li id="c04d" class="nb nc iq kx b ky nk lb nl le nm li nn lm no lq nt nh ni nj bi translated"><strong class="kx ja">反面教材</strong></li></ol></div><div class="ab cl nu nv hu nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="ij ik il im in"><h1 id="4faa" class="me mf iq bd mg mh ob mj mk ml oc mn mo kf od kg mq ki oe kj ms kl of km mu mv bi translated">属国</h1><p id="71a3" class="pw-post-body-paragraph kv kw iq kx b ky mw ka la lb mx kd ld le my lg lh li mz lk ll lm na lo lp lq ij bi translated">在我们开始之前，我建议您安装以下依赖项<code class="fe np nq nr ns b">spaCy</code>、<code class="fe np nq nr ns b">nltk</code>、<code class="fe np nq nr ns b">gensim</code>、<code class="fe np nq nr ns b">tomotopy</code>、<code class="fe np nq nr ns b">plotnine</code>和<code class="fe np nq nr ns b">wordcloud</code>。您可以使用<code class="fe np nq nr ns b">pip</code>单独安装每一个，也可以使用我创建的<a class="ae ls" href="https://github.com/ecoronado92/towards_data_science/blob/master/hdp_example/requirements.txt" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ja">需求文件</strong> </a>来简化您的工作，如下所示</p><pre class="ko kp kq kr gt og ns oh oi aw oj bi"><span id="fa2b" class="ok mf iq ns b gy ol om l on oo">pip3 install -r requirements.txt</span></pre><h1 id="83d0" class="me mf iq bd mg mh mi mj mk ml mm mn mo kf mp kg mq ki mr kj ms kl mt km mu mv bi translated">数据预处理</h1><blockquote class="op oq or"><p id="ec72" class="kv kw lr kx b ky kz ka la lb lc kd ld os lf lg lh ot lj lk ll ou ln lo lp lq ij bi translated">如果你还没有为NLP项目预处理过文本数据，我强烈推荐你提前查看一下这个循序渐进的教程</p></blockquote><p id="cbd5" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们首先加载20个新闻组数据集，指定我们只需要模型的<code class="fe np nq nr ns b">train</code>子集。</p><pre class="ko kp kq kr gt og ns oh oi aw oj bi"><span id="00ba" class="ok mf iq ns b gy ol om l on oo">from sklearn.datasets import fetch_20newsgroups</span><span id="2be0" class="ok mf iq ns b gy ov om l on oo"># Read in train subset (11,314 observations)<br/>news = fetch_20newsgroups(subset='train')</span></pre><p id="35cf" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这个<code class="fe np nq nr ns b">news</code>实例包含文本数据(<code class="fe np nq nr ns b">news.data)</code>和标签(<code class="fe np nq nr ns b">news.target</code>和<code class="fe np nq nr ns b">news.target_names</code>)，在pandas中可能是这样的</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi ow"><img src="../Images/aab6d0effbc227e6d6a220f07c6e6ba8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yt9brlQxvEvKxq7KBElprQ.png"/></div></div></figure><p id="08fc" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">而不是一步一步地告诉你我如何用标准方法预处理<code class="fe np nq nr ns b">content </code>数据(例如，标记化、停用词移除等)。)，我将在下面总结这些步骤。</p><p id="1af7" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">随着我们在这一部分(以及在未来的项目中)向前推进，我希望您记住以下几点:</p><blockquote class="ox"><p id="2144" class="oy oz iq bd pa pb pc pd pe pf pg lq dk translated">基于最终目标和选择的建模方法，这些预处理步骤有意义吗？</p></blockquote><p id="c271" class="pw-post-body-paragraph kv kw iq kx b ky ph ka la lb pi kd ld le pj lg lh li pk lk ll lm pl lo lp lq ij bi translated">这很容易被忽略，因为标准的预处理方法在许多应用程序中工作得很好。例如，<strong class="kx ja">在我们的例子</strong>中，我们想要去除由停止字(<em class="lr"> on、</em>等)产生的噪声。)以便我们的模型可以更好地捕捉与真实主题相似的潜在主题。<br/> <strong class="kx ja">然而，总是这样吗？编号</strong> <br/>【查看<a class="ae ls" href="https://medium.com/@limavallantin/why-is-removing-stop-words-not-always-a-good-idea-c8d35bd77214" rel="noopener">这篇文章</a>关于为什么这不是情绪分析的好主意】</p><h2 id="f233" class="ok mf iq bd mg pm pn dn mk po pp dp mo le pq pr mq li ps pt ms lm pu pv mu iw bi translated">特殊字符删除</h2><p id="9326" class="pw-post-body-paragraph kv kw iq kx b ky mw ka la lb mx kd ld le my lg lh li mz lk ll lm na lo lp lq ij bi translated">首先，我使用正则表达式替换删除了数据集固有的任何特殊字符，如<code class="fe np nq nr ns b">@</code>和<code class="fe np nq nr ns b">\n</code>，以及单引号<code class="fe np nq nr ns b">'</code>。</p><h2 id="44a3" class="ok mf iq bd mg pm pn dn mk po pp dp mo le pq pr mq li ps pt ms lm pu pv mu iw bi translated">标记化</h2><p id="2473" class="pw-post-body-paragraph kv kw iq kx b ky mw ka la lb mx kd ld le my lg lh li mz lk ll lm na lo lp lq ij bi translated">这里我使用了函数<code class="fe np nq nr ns b">gensim.simple_preprocess</code>,它非常有效地标记了每个文档(即，将文本分割成单个单词)。为了删除任何潜在的重音，我用<code class="fe np nq nr ns b">deacc=True</code>参数运行它。</p><h2 id="824e" class="ok mf iq bd mg pm pn dn mk po pp dp mo le pq pr mq li ps pt ms lm pu pv mu iw bi translated">二元模型</h2><p id="6aca" class="pw-post-body-paragraph kv kw iq kx b ky mw ka la lb mx kd ld le my lg lh li mz lk ll lm na lo lp lq ij bi translated">这些有助于构建，因为它们考虑到了词的共现。例如，在我们的数据中，这会生成<code class="fe np nq nr ns b">['oil_leak']</code>而不是<code class="fe np nq nr ns b">['oil', leak']</code>。你可以使用<code class="fe np nq nr ns b">gensim</code>的内置<code class="fe np nq nr ns b">Phrases</code>和<code class="fe np nq nr ns b">Phraser</code>功能来实现这一点。</p><h2 id="bc14" class="ok mf iq bd mg pm pn dn mk po pp dp mo le pq pr mq li ps pt ms lm pu pv mu iw bi translated">停止单词删除</h2><p id="e2e6" class="pw-post-body-paragraph kv kw iq kx b ky mw ka la lb mx kd ld le my lg lh li mz lk ll lm na lo lp lq ij bi translated">如果我们首先删除文档中的非信息词(即停用词)，推断潜在主题将会更容易。我下载了<code class="fe np nq nr ns b">nltk</code>的英文停用词，并添加了几个简单的针对这个数据集<code class="fe np nq nr ns b">['from', ‘subject', ‘re','edu',use']</code>的停用词。</p><h2 id="f3c1" class="ok mf iq bd mg pm pn dn mk po pp dp mo le pq pr mq li ps pt ms lm pu pv mu iw bi translated">词汇化</h2><p id="8d67" class="pw-post-body-paragraph kv kw iq kx b ky mw ka la lb mx kd ld le my lg lh li mz lk ll lm na lo lp lq ij bi translated">考虑到数据集相对较小(即大约10k个观察值)，我使用<code class="fe np nq nr ns b">spaCy</code>和词性(POS)标签为名词、动词、形容词和副词实现了一个词汇化方案。<strong class="kx ja">简单地说，</strong>我删除了任何屈折变化的词尾，并返回了基本/词典单词，如下所示。</p><pre class="ko kp kq kr gt og ns oh oi aw oj bi"><span id="6ed8" class="ok mf iq ns b gy ol om l on oo">"A letter has been written asking him to be released"</span><span id="1cd1" class="ok mf iq ns b gy ov om l on oo">[ex. Original ==&gt; Lemmatized, POS tag]</span><span id="9c10" class="ok mf iq ns b gy ov om l on oo">A        ==&gt; a, DET<br/>letter   ==&gt; letter, NOUN<br/>has      ==&gt; have, AUX<br/>been     ==&gt; be, AUX<br/>written  ==&gt; write, VERB<br/>asking   ==&gt; ask, VERB<br/>him      ==&gt; -PRON-, PRON<br/>to       ==&gt; to, PART<br/>be       ==&gt; be, AUX<br/>released ==&gt; release, VERB</span></pre><p id="f39b" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">虽然lemmatization提供了更好的标记，但它的代价是可能会花费比您希望等待它完成更长的时间。因此，当时间至关重要或者如果你有一个大的数据集，一个<strong class="kx ja">的选择是词干化</strong> <em class="lr"> </em>，它使用粗糙的试探法切断单词的结尾，希望得到基本单词。(例如，在这个数据集<strong class="kx ja">中，词汇化需要大约4分钟，而词干化只需要14秒</strong>)。</p><h2 id="265e" class="ok mf iq bd mg pm pn dn mk po pp dp mo le pq pr mq li ps pt ms lm pu pv mu iw bi translated">把所有的放在一起</h2><p id="d1a6" class="pw-post-body-paragraph kv kw iq kx b ky mw ka la lb mx kd ld le my lg lh li mz lk ll lm na lo lp lq ij bi translated">我构建了一个定制脚本<code class="fe np nq nr ns b">newsgrp_preprocess</code> ( <a class="ae ls" href="https://github.com/ecoronado92/towards_data_science/blob/master/hdp_example/scripts/newsgrp_preprocess.py" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ja">链接此处为</strong> </a>)，它整合了上述所有步骤，并为我们拥有超过1M令牌的HDP模型(即<code class="fe np nq nr ns b">word_list_lemmatized</code>)输出现成的数据。此外，它整理了<code class="fe np nq nr ns b">news</code>实例中的信息，并将信息输出到一个漂亮的<code class="fe np nq nr ns b">pandas</code>数据帧中(如本文前面所示)。</p><pre class="ko kp kq kr gt og ns oh oi aw oj bi"><span id="6b56" class="ok mf iq ns b gy ol om l on oo">&gt; from scripts.newsgrp_preprocess import run_preprocess</span><span id="4a3a" class="ok mf iq ns b gy ov om l on oo">&gt; news_df, word_list_lemmatized = run_preprocess(news)</span><span id="72ad" class="ok mf iq ns b gy ov om l on oo"># Showing first document, first seven tokens<br/>&gt; word_list_lemmatized[0][:7] <br/>&gt; ['where', 'thing', 'car', 'nntp_poste', 'host', 'park', 'line']</span></pre><p id="ce1a" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在已经完成了，让我们继续真正酷的事情——训练模型！</p><h1 id="b509" class="me mf iq bd mg mh mi mj mk ml mm mn mo kf mp kg mq ki mr kj ms kl mt km mu mv bi translated">HDP模型训练与评估</h1><p id="6833" class="pw-post-body-paragraph kv kw iq kx b ky mw ka la lb mx kd ld le my lg lh li mz lk ll lm na lo lp lq ij bi translated">如果你不熟悉贝叶斯模型，你可能会问“训练一个贝叶斯模型意味着什么”？嗯，这基本上意味着我们试图<em class="lr">推断/学习一个分布</em>。在我们的例子中，我们试图从文档中了解<strong class="kx ja">未观察到的(<em class="lr">潜在的</em>)主题的分布。</strong></p><p id="5b9a" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了训练贝叶斯模型，你通常使用两个主要阵营的方法:<strong class="kx ja">蒙特卡罗方法(例如Gibbs/MCMC采样)和近似/优化方法(例如变分推断)。</strong></p><blockquote class="op oq or"><p id="3e51" class="kv kw lr kx b ky kz ka la lb lc kd ld os lf lg lh ot lj lk ll ou ln lo lp lq ij bi translated">MCMC？变分…什么？不要担心，<strong class="kx ja"> </strong> <a class="ae ls" rel="noopener" target="_blank" href="/bayesian-inference-problem-mcmc-and-variational-inference-25a8aa9bce29"> <strong class="kx ja">这里有一本由<a class="pw px ep" href="https://medium.com/u/b17ebd108358?source=post_page-----e5666db347a--------------------------------" rel="noopener" target="_blank">约瑟夫·罗卡</a>撰写的简单读物</strong> </a>，它解释了这些方法，即使你不太了解贝叶斯统计</p></blockquote><p id="3c6d" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">不用深入细节，两个阵营基本上实现了相同的目标:从数据中推断出一组主题。然而，在考虑使用哪种方法时，每种方法都有重要的优点和缺点(其中一些我将在后面的小节中介绍)。</p><p id="fb59" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ja">在本节的剩余部分</strong>，我将使用Python库，这些库使用一种叫做<a class="ae ls" href="https://www.coursera.org/lecture/ml-clustering-and-retrieval/what-is-collapsed-gibbs-sampling-qC5gv" rel="noopener ugc nofollow" target="_blank">折叠吉布斯采样</a>的蒙特卡罗方法。与传统的吉布斯采样器相比，该方法加快了主题推理过程(即模型训练)。</p><h2 id="50b1" class="ok mf iq bd mg pm pn dn mk po pp dp mo le pq pr mq li ps pt ms lm pu pv mu iw bi translated">建立HDP模式</h2><p id="e990" class="pw-post-body-paragraph kv kw iq kx b ky mw ka la lb mx kd ld le my lg lh li mz lk ll lm na lo lp lq ij bi translated">这里我使用了<code class="fe np nq nr ns b">tomotopy</code> Python库。</p><p id="6c51" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果您有任何实现HDPs的经验，此时您可能会问，“但是您为什么不使用<code class="fe np nq nr ns b">gensim.HdpModel</code>函数呢？”嗯，我尽力了(相信我，真的很努力)。还记得我在开头提到的挫折吗？对我来说，这是其中之一，因为即使在广泛的调整之后，我也无法使用<code class="fe np nq nr ns b">gensim</code>的方法来生成高质量的数据集结果。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi py"><img src="../Images/f5200c9ce39286443892e6b12d17583c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R6oir4CuK4PCOHB8Eomf8g.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">对HDP模型和超参数α和γ的直觉</p></figure><p id="70b3" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">训练一个<code class="fe np nq nr ns b">tomotopy</code>模型相当简单。首先，通过设置一些参数来初始化一个模型对象，如模型将如何加权令牌、与令牌频率相关的阈值以及HDP模型的集中参数<code class="fe np nq nr ns b">alpha</code>和<code class="fe np nq nr ns b">gamma</code>(见左图)。</p><p id="dbb1" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于这个数据集，我将模型限制为只使用出现在至少5个带有<code class="fe np nq nr ns b">min_cf</code>参数的文档中的单词，而排除了7个最常用的带有<code class="fe np nq nr ns b">rm_top</code>的单词。类似地，我设置了集中参数<code class="fe np nq nr ns b">gamma=1</code>和<code class="fe np nq nr ns b">alpha=0.1</code>，假设文档共享许多主题，而单个文档只谈论很少的主题。我用<code class="fe np nq nr ns b">initial_k=10</code>初始化了主题的数量，它充当了一种<em class="lr">先于</em>的角色。鉴于数据的20个主题分为6个主要组(例如<code class="fe np nq nr ns b">rec.car</code>、<code class="fe np nq nr ns b">rec.bike</code>下的建议)，我选择了这一点，并且我假设<code class="fe np nq nr ns b">misc</code>组可能有一些应该考虑的其他主题。</p><pre class="ko kp kq kr gt og ns oh oi aw oj bi"><span id="7107" class="ok mf iq ns b gy ol om l on oo">import tomotopy as tp</span><span id="8b20" class="ok mf iq ns b gy ov om l on oo">term_weight = tp.TermWeight.ONE</span><span id="eafe" class="ok mf iq ns b gy ov om l on oo">hdp = tp.HDPModel(tw=term_weight, min_cf=5, rm_top=7, gamma=1,<br/>                  alpha=0.1, initial_k=10, seed=99999)</span></pre><h2 id="a5ad" class="ok mf iq bd mg pm pn dn mk po pp dp mo le pq pr mq li ps pt ms lm pu pv mu iw bi translated">模特培训</h2><p id="58b5" class="pw-post-body-paragraph kv kw iq kx b ky mw ka la lb mx kd ld le my lg lh li mz lk ll lm na lo lp lq ij bi translated">一旦我们实例化了<code class="fe np nq nr ns b">hdp</code>对象，我们就可以添加它将用来训练模型的文档，如下所示。(如果有帮助的话，我已经用一个<a class="ae ls" href="https://github.com/ecoronado92/towards_data_science/blob/master/hdp_example/scripts/model_funcs.py" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ja">自定义函数</strong> </a> <strong class="kx ja"> </strong> <code class="fe np nq nr ns b">train_HDPModel</code>自动化了这些步骤。)</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="pz ku l"/></div></figure><p id="9484" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">上面的示例输出提供了有用的早期诊断信息。例如，看到每个单词的对数似然增加，这告诉我们模型正在充分学习。</p><p id="e468" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">从模型中提取主题不像其他包那样简单，所以我构建了一个<a class="ae ls" href="https://github.com/ecoronado92/towards_data_science/blob/master/hdp_example/scripts/model_funcs.py" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ja">自定义脚本</strong> </a> <strong class="kx ja"> </strong> <code class="fe np nq nr ns b">get_hdp_topics</code>来简化这个过程。</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="pz ku l"/></div></figure><h2 id="6404" class="ok mf iq bd mg pm pn dn mk po pp dp mo le pq pr mq li ps pt ms lm pu pv mu iw bi translated">模型评估</h2><blockquote class="op oq or"><p id="4422" class="kv kw lr kx b ky kz ka la lb lc kd ld os lf lg lh ot lj lk ll ou ln lo lp lq ij bi translated">接下来的部分听起来会很乏味，但是我强烈建议您完成它。它涵盖了如何评估这类模型的最佳实践。</p></blockquote><p id="ee36" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">给定的主题模型是无监督的方法，我们无法使用常见的<em class="lr">性能指标</em>(例如RMSE)来评估它们，相反，我们使用一种称为<strong class="kx ja"> <em class="lr">一致性</em> </strong>的指标，它提供了一种<em class="lr">客观</em>的方法来衡量组合在一起作为主题的单词是否有意义。</p><p id="af78" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有多种方式<a class="ae ls" href="https://palmetto.demos.dice-research.org/" rel="noopener ugc nofollow" target="_blank"/>来计算这个度量，但是基本上，如果定义一个主题的单词在文档中出现在一起(共现)的概率很高，则该主题被认为具有高<strong class="kx ja"><em class="lr"/></strong>。一般来说，<strong class="kx ja"> CV方法</strong>是首选，因为它考虑了通过滑动窗口计算这些概率时单词出现的接近程度。</p><p id="908b" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">假设我们知道数据集中的主题，我们可以评估两件事:</p><ol class=""><li id="b869" class="nb nc iq kx b ky kz lb lc le nd li ne lm nf lq nt nh ni nj bi translated">模型的主题是否代表<em class="lr">真实主题</em>(连贯性)</li><li id="6a13" class="nb nc iq kx b ky nk lb nl le nm li nn lm no lq nt nh ni nj bi translated">模型推断一个看不见的(样本外的)文档的主题有多好</li></ol><p id="717f" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">鉴于<code class="fe np nq nr ns b">tomotopy </code>提供了<a class="ae ls" href="https://bab2min.github.io/tomotopy/v0.7.0/en/index.html#tomotopy.TermWeight" rel="noopener ugc nofollow" target="_blank">三种不同的令牌加权方案</a>，我测试了每种方案，以根据上述标准比较它们的性能。首先，我比较了使用<code class="fe np nq nr ns b">gensim.CoherenceModel</code>的<strong class="kx ja"> <em class="lr"> </em> </strong>和使用<a class="ae ls" href="https://github.com/ecoronado92/towards_data_science/blob/master/hdp_example/scripts/model_funcs.py" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ja">的<code class="fe np nq nr ns b">coherence='c_v'</code>自定义脚本</strong> </a> <strong class="kx ja">。</strong>CV指标得分<strong class="kx ja"> </strong>范围从<strong class="kx ja"> 0到1 </strong>(其中好的话题连贯性得分范围在0.5-0.65之间)。</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="pz ku l"/></div></figure><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi qa"><img src="../Images/ec2ce587e5ec8f4dbfdf7659111d142d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ai66xpOIziUyT1K_tPS0Wg.png"/></div></div></figure><p id="b64d" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于这个数据集，<strong class="kx ja">逆文档频率</strong>模型似乎基于主题一致性表现得最好。如果你的目标只是理解特定数据集中的一些潜在主题，那么很好——你已经完成了！选择一致性最高的模型。然而，<strong class="kx ja">请注意，这并不一定意味着模型将很好地概括</strong>(即<strong class="kx ja"> </strong>准确地将主题分配给看不见的文档)。</p><p id="8591" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在我们的例子中，我们有一个<em class="lr">标记的测试集</em>，我们可以用它来验证模型是如何概括的。(如果没有带标签的数据，可以做一些类似的检查。抓住一个看不见的文件进行预测，选择分配的最主要的主题，看看这个分配基于文本是否有意义。)</p><p id="feff" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">预测到一个，如果你愿意，你也可以使用训练集作为健全性检查，即使它是未标记的数据，只要预测一个文档，看看它是否基于内容有意义。)</p><p id="dfec" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下面的单词clouds提供了一个很好的例子。使用与前面相同的步骤，我们得到一个测试集(<code class="fe np nq nr ns b">subset='test'</code>)，并评估每个模型的泛化能力。我们看到，具有最高一致性的模型(<strong class="kx ja"> IDF </strong>)并不一定分配“正确的”主题(<code class="fe np nq nr ns b">rec.autos</code>)，相反，它似乎认为这份文档讨论的是计算机。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi qb"><img src="../Images/4f96fd4676999c30ad16b3822bb08ddf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LvoxJRtTBk1Gv4z7ZltUYA.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">比较三个HDP模型的概括能力，一些模型给出了正确的主题，而另一些则没有</p></figure><p id="37b6" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">虽然这是一个非常具体的例子，但我选择继续使用<strong class="kx ja"> HDP </strong> <strong class="kx ja"> IDF模型</strong>，因为它倾向于产生类似于<em class="lr">真实标签</em>的主题，并且比其他模型更经常地将正确的主题分配给<em class="lr">测试</em>文档。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi qc"><img src="../Images/9e26bd27d979e25ab8f0ef94be21a3c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p4UCQpNAK-XzuIHQWDS99Q.png"/></div></div></figure><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi qd"><img src="../Images/a54bcfe357fc25c1ae614807ffd92e58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a46bQEsGGzdO4IMZM-Kmiw.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">HDP IDF模型:(上)主题示例[左] sci.med，[中] comp。__，【右】<em class="qe"> rec.sport.hockey </em>。(下)主题分配与真实标签</p></figure><blockquote class="op oq or"><p id="eea9" class="kv kw lr kx b ky kz ka la lb lc kd ld os lf lg lh ot lj lk ll ou ln lo lp lq ij bi translated">顺便提一下，主题标签可能是主观的(例如，一个人可能会将单词理解为硬件主题，而另一个人则理解为软件主题)。为了避免这种情况，<code class="fe np nq nr ns b">tomotopy</code>提供了一种有趣的方法，即<strong class="kx ja">客观地</strong>给主题贴标签。你可以在这里找到一些<strong class="kx ja"> </strong> <a class="ae ls" href="https://github.com/ecoronado92/towards_data_science/blob/master/hdp_example/objective_topic_labels.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ja">的例子</strong> </a>。</p></blockquote><h1 id="f635" class="me mf iq bd mg mh mi mj mk ml mm mn mo kf mp kg mq ki mr kj ms kl mt km mu mv bi translated">模型比较</h1><p id="ee69" class="pw-post-body-paragraph kv kw iq kx b ky mw ka la lb mx kd ld le my lg lh li mz lk ll lm na lo lp lq ij bi translated">恭喜你！如果您已经学了这么多，那么您应该非常了解如何用Python实现HDP模型了！但是，和LDA相比如何？</p><p id="7eed" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们比较我们的HDP模型和MALLET LDA模型(有趣！).我使用这个版本而不是默认的<code class="fe np nq nr ns b">gensim</code> LDA，因为它允许苹果到苹果的比较(即，它也使用折叠吉布斯采样器)。在这种情况下，<code class="fe np nq nr ns b">gensim</code>有一个简单的包装器<code class="fe np nq nr ns b">LdaMallet</code>，一旦你下载了MALLET二进制文件，就可以快速实现这个模型。要了解如何运行它我建议你看看下面的<a class="ae ls" href="https://github.com/ecoronado92/towards_data_science/blob/master/hdp_example/hdp_example.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ja"> Jupyter笔记本</strong> </a> <strong class="kx ja">。</strong></p><p id="b545" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">使用相同的数据集，我将如上所述的几个LDA模型的性能(即相干性+概化)与HDP模型的性能进行了比较。在下图(左)中，我们可以看到，随着LDA模型中主题参数的增加，主题连贯性也在增加。</p><blockquote class="ox"><p id="076d" class="oy oz iq bd pa pb pc pd pe pf pg lq dk translated"><strong class="ak">该比较展示了在不指定主题的情况下，即兴HDP模型如何能够实现与LDA模型相似或更高的主题一致性</strong></p></blockquote><p id="987d" class="pw-post-body-paragraph kv kw iq kx b ky ph ka la lb pi kd ld le pj lg lh li pk lk ll lm pl lo lp lq ij bi translated">类似地，我们可以看到我们的最佳HDP模型(<strong class="kx ja"> IDF </strong>)在将正确的主题分配给看不见的文档(右图)方面具有与最佳LDA模型(主题=26)相似的性能。</p><div class="ko kp kq kr gt ab cb"><figure class="qf ks qg qh qi qj qk paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><img src="../Images/cddb2565ca3bab78d6ec4b2af21791e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*r1czUd_u-CPutXeW9n7NhA.png"/></div></figure><figure class="qf ks ql qh qi qj qk paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><img src="../Images/394a1682dffa17145f4344c9916be0b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/format:webp/1*sVl80sd4BsVfhVTXd76uqw.png"/></div></figure></div><h1 id="bcbf" class="me mf iq bd mg mh mi mj mk ml mm mn mo kf mp kg mq ki mr kj ms kl mt km mu mv bi translated">警示故事</h1><p id="21bc" class="pw-post-body-paragraph kv kw iq kx b ky mw ka la lb mx kd ld le my lg lh li mz lk ll lm na lo lp lq ij bi translated">没有一些好的警示故事的数据科学文章算什么？让我们面对现实吧，每种建模技术都有优点和缺点，也有可能出错的情况。在这里，我只想分享一些在实现HDP模型(或者一般的主题模型)时要记住的事情。</p><h2 id="0e8c" class="ok mf iq bd mg pm pn dn mk po pp dp mo le pq pr mq li ps pt ms lm pu pv mu iw bi translated"><strong class="ak">故事número uno(故事#1):垃圾输入，垃圾输出</strong></h2><p id="ddbe" class="pw-post-body-paragraph kv kw iq kx b ky mw ka la lb mx kd ld le my lg lh li mz lk ll lm na lo lp lq ij bi translated"><em class="lr">认真思考你的预处理步骤。</em>一个简单的开始方式是考虑你的目标是解决什么问题，你拥有的数据，以及你将使用的模型。很多时候我们可以随波逐流，在项目中使用相似的预处理步骤，但是正如我上面提到的，这可能会导致糟糕的输出。</p><p id="f552" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">例如，这个项目的目标是实现一个可以从文本数据中学习20个(<em class="lr"> ish </em>)主题的模型。在给定数据集大小的情况下，删除停用词以减少噪音和词汇化是有意义的。然而，如果目标是做一些情感分析，那么删除停用词就不是一个好的选择。</p><h2 id="5153" class="ok mf iq bd mg pm pn dn mk po pp dp mo le pq pr mq li ps pt ms lm pu pv mu iw bi translated">故事2:不要盲目相信统计数据</h2><p id="f724" class="pw-post-body-paragraph kv kw iq kx b ky mw ka la lb mx kd ld le my lg lh li mz lk ll lm na lo lp lq ij bi translated"><em class="lr">、</em>作为众多可以用来评估主题模型的指标之一，<em class="lr">、</em>提供了一种直观的方式来衡量表现。我不知道你怎么想，但我认为有时我们倾向于专注于<em class="lr">统计</em>(例如RMSE或预测模型的分类)，特别是当它们似乎表明良好的性能时。</p><p id="a9b5" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这里有一个明显的例子。还记得我们把一致性作为一个很好的性能指标吗？当我使用<code class="fe np nq nr ns b">gensim.HdpModel</code>的时候，这肯定不是真的。因为它们的实现是基于变分推理的，所以我测试了(作为数百个调整组合中的一个)改变其中一个学习参数(<strong class="kx ja"> <em class="lr"> kappa </em> </strong>)会如何影响模型的主题一致性和在看不见的文档上的性能。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi qm"><img src="../Images/9d20bd1581fb24dbaef7d105ab366824.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*IFaRh_EmA7Rc_hAiSxAL8Q.png"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">跨kappa ={0.6，0.8，1}值的gensim HDP模型的CV一致性分数</p></figure><p id="a290" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">结果是，当我增加<strong class="kx ja"> <em class="lr"> kappa </em> </strong>时，模型的一致性分数增加。你可能会问，“太好了，这正是我们想要的，对吗？”是的，但是在这种情况下，当您尝试在一个看不见的文档上测试模型时，您会观察到1) <strong class="kx ja">每个文档都被分配了一个相同的主题</strong>和<strong class="kx ja"> 2)这个主题太宽泛了，以至于您无法理解它</strong>。根据给定的度量，该模型已经收敛到一个表现“良好”(例如，局部最优)的解决方案，但是仍然没有用。</p><p id="ee0a" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，如果有一个<strong class="kx ja">我想让你从这篇文章中学到的关键是</strong></p><blockquote class="ox"><p id="63d3" class="oy oz iq bd pa pb pc pd pe pf pg lq dk translated">在完全相信一个统计数据之前，退一步想想这个数字是否有意义，为什么有意义</p></blockquote><h2 id="c6c3" class="ok mf iq bd mg pm qn dn mk po qo dp mo le qp pr mq li qq pt ms lm qr pv mu iw bi translated">故事número tres(故事#3):推理方法可以产生不同的结果</h2><p id="d858" class="pw-post-body-paragraph kv kw iq kx b ky mw ka la lb mx kd ld le my lg lh li mz lk ll lm na lo lp lq ij bi translated">之前我提到过贝叶斯推理中使用的两个主要阵营:蒙特卡罗方法和变分法。根据您的具体项目和目标，选择使用哪个包实现会有很大的不同。然而，我相信这归结为一个<strong class="kx ja">速度/内存与准确性的权衡。</strong></p><p id="496e" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><code class="fe np nq nr ns b">tomotopy</code> <strong class="kx ja">模型:快速准确<br/> </strong>如前所述，这个包使用了折叠吉布斯采样器。<strong class="kx ja">主要优势</strong>是它固有地产生无偏见和准确的结果。<br/> <strong class="kx ja">然而这种方法扩展性不好</strong>(内存开销随着观察次数线性增加)。在我们的例子中，这是有意义的，但是如果您要获取一个包含100万个文档的数据集，您可能需要等待一段时间来完成运行。</p><p id="978d" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><code class="fe np nq nr ns b">gensim</code> <strong class="kx ja">模型:更快和可扩展的<br/> </strong>这个包使用了一个<strong class="kx ja">在线变分推理</strong>方法，简单来说，它允许你大规模使用经典的变分推理近似工具。这种方法的主要优势<strong class="kx ja">是速度和低内存消耗(内存不会随着观察次数的增加而线性增长，因此这对于大型数据集非常有用)。<strong class="kx ja"> <br/>然而，如果你用一个“更简单的分布”来近似一个目标分布，而不是像折叠吉布斯采样那样直接从目标中采样，它会以牺牲准确性为代价获得速度</strong>。这不仅会引入偏差，而且可能需要大量的参数调整才能获得有用的结果。下面是两个参数如何影响学习速度从而影响收敛的例子(你可以在这里访问<a class="ae ls" href="https://vb-learning-rate-demo.herokuapp.com/" rel="noopener ugc nofollow" target="_blank"> Dash应用)。</a></strong></p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi qs"><img src="../Images/1fa3682905a311f8d85cd1da6c700757.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*wzLLCmvYQRydW7kv947Udw.gif"/></div></figure><p id="afc1" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">(考虑到这些限制<a class="ae ls" href="http://www.cs.columbia.edu/~blei/papers/WangBlei2012.pdf" rel="noopener ugc nofollow" target="_blank">，已经开发了新方法</a>来尝试解决变分推理的近似偏差。)</p><h1 id="a483" class="me mf iq bd mg mh mi mj mk ml mm mn mo kf mp kg mq ki mr kj ms kl mt km mu mv bi translated">结论</h1><p id="d2a1" class="pw-post-body-paragraph kv kw iq kx b ky mw ka la lb mx kd ld le my lg lh li mz lk ll lm na lo lp lq ij bi translated">当你不希望预先指定主题时，HDP模型是LDA模型的强大替代品，有几个软件包可以帮助你轻松实现它们。但是，请记住，在实施这些模型之前、期间和之后进行一些尽职调查可以确保您的结果符合您的初始目标。</p><p id="c8e9" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">所以，现在你已经学会了如何实现一个HDP模型(并且可以流利地用西班牙语数数)，继续测试你新学到的技能吧！</p><h1 id="4100" class="me mf iq bd mg mh mi mj mk ml mm mn mo kf mp kg mq ki mr kj ms kl mt km mu mv bi translated">参考</h1><ol class=""><li id="4d44" class="nb nc iq kx b ky mw lb mx le qt li qu lm qv lq nt nh ni nj bi translated">王、钟、、戴维·布雷。"分层狄利克雷过程的在线变分推断."在PMLR举行的第十四届人工智能和统计国际会议记录。2011.</li><li id="0e70" class="nb nc iq kx b ky nk lb nl le nm li nn lm no lq nt nh ni nj bi translated">格里菲斯，托马斯l，和马克斯特弗斯。“寻找科学话题。”<em class="lr">美国国家科学院学报</em>101 . Suppl 1(2004):5228–5235。</li><li id="c5f0" class="nb nc iq kx b ky nk lb nl le nm li nn lm no lq nt nh ni nj bi translated">断层摄影术。【https://github.com/bab2min/tomotopy】T4。<a class="ae ls" href="https://doi.org/10.5281/zenodo.3816629" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.5281/zenodo.3816629</a></li><li id="40f6" class="nb nc iq kx b ky nk lb nl le nm li nn lm no lq nt nh ni nj bi translated">布莱恩特、迈克尔和埃里克·b·索德思。"分层Dirichlet过程的真正非参数在线变分推断."<em class="lr">神经信息处理系统的进展</em>。2012.</li></ol></div><div class="ab cl nu nv hu nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="ij ik il im in"><p id="fcd3" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果你喜欢这篇文章，请随意分享！如果您有任何问题或看到任何不正确/有问题的内容，请发表评论或发推文(<a class="ae ls" href="https://twitter.com/ecoronado92" rel="noopener ugc nofollow" target="_blank"> @ecoronado92 </a>)。</p><p id="aa40" class="pw-post-body-paragraph kv kw iq kx b ky kz ka la lb lc kd ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ja">本文中使用的所有代码和笔记都可以在这里找到</strong></p><div class="qw qx gp gr qy qz"><a href="https://github.com/ecoronado92/towards_data_science/tree/master/hdp_example" rel="noopener  ugc nofollow" target="_blank"><div class="ra ab fo"><div class="rb ab rc cl cj rd"><h2 class="bd ja gy z fp re fr fs rf fu fw iz bi translated">ecoronado 92/走向_数据_科学</h2><div class="rg l"><h3 class="bd b gy z fp re fr fs rf fu fw dk translated">Repo包含了一个在20个新闻组数据集上实现HDP模型的例子，该模型使用tomotopy…</h3></div><div class="rh l"><p class="bd b dl z fp re fr fs rf fu fw dk translated">github.com</p></div></div></div></a></div></div></div>    
</body>
</html>