<html>
<head>
<title>Integration of Dimension Reduction Methods and Neural Network for Image Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">集成降维方法和神经网络的图像分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/integration-of-dimension-reduction-methods-and-neural-network-for-image-classification-96281963fe24?source=collection_archive---------33-----------------------#2020-08-26">https://towardsdatascience.com/integration-of-dimension-reduction-methods-and-neural-network-for-image-classification-96281963fe24?source=collection_archive---------33-----------------------#2020-08-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/2129ab039652cd6115e63d2cdd4772c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nj50VOtinJVoYJN3"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">莫里茨·金德勒在<a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="537a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用原始数字图像构建深度网络需要学习许多参数，这可能会降低准确率。可以通过使用降维方法来压缩图像，并且可以将提取的降维特征馈送到深度网络中用于分类。因此，在网络的训练阶段，参数的数量将会减少。主成分分析是一种众所周知的降维技术，它利用原始数据的正交线性变换。在本文中，我们展示了一个基于神经网络的框架，名为 Fusion-Net，它在图像数据集(CIFAR-10)上实现 PCA，然后神经网络应用于提取主成分。我们还在缩减的数据集上实现了逻辑回归。最后，我们比较了使用原始特征和精简特征的结果。实验结果表明，融合网络优于其他方法。</p><p id="8695" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本文中，我们应用一个名为融合网络的神经网络框架进行图像分类。实施遵循两个步骤:</p><ol class=""><li id="bb3e" class="le lf it ki b kj kk kn ko kr lg kv lh kz li ld lj lk ll lm bi translated">我们对原始数据集实施降维技术(PCA)以提取主成分</li><li id="07fc" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">提取的成分然后被用作 ML 分类器的输入，如神经网络、逻辑回归等。</li></ol><p id="e8ac" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">数据集规范</strong></p><p id="c602" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们在一个名为 CIFAR 的图像数据集上进行了实验。CIFAR 数据集是由 Alex Krizhevsky、Vinod Nair 和 Geoffrey Hinton [1]收集的 10 类图像的多类分类的著名图像数据。数据集中的图像有 10 类不同的对象:<strong class="ki iu">飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船和卡车</strong>。</p><p id="2675" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">图 1 </strong>示出了带有图像类别标签的一些样本图像。在本文中，我们使用由 60，000 张图像组成的 CIFAR-10 数据集，它是 8，000 万个微小图像数据集(CIFAR)的子集。数据集中的每个图像都是具有维度的彩色图像(包含 3 个通道)。CIFAR-10 数据集是一个平衡数据，其中每个类包含 6，000 幅图像。我们将数据集分成 50，000 个训练图像和 10，000 个测试图像，保持类别的比例。</p><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div class="gh gi ls"><img src="../Images/870a486892805c94f84cf4750a157bc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*DIXuO4qhEHXop-MkEzDZig.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图 1: CIFAR-10 数据集</p></figure><p id="fe66" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">方法</strong></p><p id="61c2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">融合网络包括两个主要部分:降维和神经网络。图 2 示出了融合网络的架构，其中神经网络包含四层:输入层、两个隐藏层和输出层。输入层包含由 PCA 提取的特征数量的神经元。第一和第二隐藏层分别包含 128 和 64 个神经元，并且输出层包括 10 个神经元，因为问题是 10 类分类。我们使用类别交叉熵作为损失函数，使用自适应矩估计(Adam)优化器来计算误差和更新参数。</p><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi lx"><img src="../Images/bd4718c98009d23b6468d4b1674b0e74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rFY7Iy5TP2_-8_PDt8TlFw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图 2:融合网络的体系结构</p></figure><p id="cac2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们提出了三种不同版本的融合方法，其中简化的特征分别保留了第一、第二和第三版本的 99%、95%和 90%的数据变化。</p><p id="c343" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">降维</strong></p><p id="449d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将每一幅三维彩色图像转换到一维空间，以便应用主成分分析。转换后，每个观察值由 32×32×3=3072 个特征组成，因此对转换后的数据集实施 PCA。<strong class="ki iu">图 3 </strong>显示了由特征数量解释的变化。原始数据变异的 99%、95%和 90%可以分别由前 658、217 和 99 个主成分解释。仅使用前 21 个分量就可以提取 80%的数据变化。</p><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ly"><img src="../Images/86bc25a9dec71df6452a669ec1920f17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ulAbSh9duK7v1kAqEhwrjA.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图 3:由主成分解释的变化</p></figure><p id="96cf" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们在原始数据集上实现了具有相同架构的逻辑回归和神经网络</p><p id="695d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">在 CIFAR-10 原始数据集上的性能评估:</strong>我们使用早期停止训练神经网络 100 个时期，并且逻辑回归也应用于原始数据集。通过在测试数据上实现训练好的模型来测量模型性能。表 I 展示了这两个模型在这个数据集上的实验结果。</p><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/254810c9375e946d1010407be8e6d882.png" data-original-src="https://miro.medium.com/v2/resize:fit:890/format:webp/1*nLKqxtFJc2Uz_5W5TfkBnQ.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">表 1:不同分类器在 CIFAR-10 原始数据集上的实验结果</p></figure><p id="34e7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">神经网络优于 LR 方法，并获得 0.46 的最高准确度分数，而 LR 获得 0.3954 的准确度分数。</p><p id="7424" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">在 CIFAR-10 缩减数据集上的性能评估:</strong>我们在原始数据集上实施 PCA，并缩减数据集，提取包含 658、217 和 99 个特征的三个不同数据集，它们分别解释了原始数据的 99%、95%和 90%的变化。</p><p id="a2ae" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将具有相同架构的神经网络应用于缩减的数据集。逻辑回归也适用于简化的数据集。表 II 示出了模型在数据集上的实验结果。融合网络优于(PCA+LR)方法，并在三种不同情况下获得了最高的准确率。通过 99 个主成分，融合网络达到了 53.41%的最高准确率。用 217 个特征获得了 0.5307 的几乎相似的精度。Fusion-Net 使用 658 个主成分实现了 0.5194 的精度。对于三个简化的数据集，逻辑回归达到了几乎相似的准确度。</p><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ma"><img src="../Images/d1b847a51d296c1b3c036aec2bae915f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MlAh2ACu-eNkObxBtDC-aQ.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">表二:不同分类器在 CIFAR-10 精简数据集上的实验结果</p></figure><p id="5e86" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">讨论</strong></p><p id="1dc9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">表 III 显示了 Fusion-Net 针对不同数量的特征尺寸学习的参数数量。随着特征数量的减少，参数的总数呈指数减少。由于训练参数的数量随着特征的减少而减少，训练的计算成本也将随着数据集的减少而减少。</p><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mb"><img src="../Images/4900aea4efe1636e6d91076003b0ccd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aS74eHaOOuTy59eGkiurQA.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">表 III:不同数量特征尺寸的神经网络中的总参数</p></figure><p id="df39" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">神经网络使用缩减的数据集比原始数据集产生了更好的结果。通过减少特征，网络学习更少的权重，这可能是产生更好结果的原因，因为我们用 100 个时期训练模型。具有许多时期的微调神经网络模型可能优于融合网络。</p><p id="d253" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">图 4 </strong>显示了用于构建神经网络的代码。</p><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mc"><img src="../Images/cc641707cdd11f340187d5c0d801ec22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UGyBotXjYAizrogaN0ebag.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图 4:神经网络的代码</p></figure><p id="4b38" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">总之，降维技术可应用于图像数据集，以减少特征的数量，同时保留原始数据集的模式和趋势。深度学习网络可以在减少的数据集而不是原始数据上训练，从而减少训练参数的数量。我们在数据集(原始数据集和精简数据集)上进行了所有实验来评估融合网络。我们通过与融合 LR (PCA+LR)方法的性能进行比较来评估融合网络的性能。实验结果表明，融合网络优于其他方法。</p><h1 id="200b" class="md me it bd mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na bi translated">阅读默罕默德·马苏姆博士(以及媒体上成千上万的其他作家)的每一个故事。</h1><p id="4873" class="pw-post-body-paragraph kg kh it ki b kj nb kl km kn nc kp kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">你的会员费将直接支持和激励穆罕默德·马苏曼德和你所阅读的成千上万的其他作家。你还可以在媒体上看到所有的故事—【https://masum-math8065.medium.com/membership】<strong class="ki iu"/></p><p id="9c4f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">快乐阅读！</strong></p></div></div>    
</body>
</html>