# PyTorch 中灵活的声明性数据集采样

> 原文：<https://towardsdatascience.com/flexible-declarative-dataset-sampling-in-pytorch-613c6d5db10c?source=collection_archive---------43----------------------->

## 一个可配置的树形结构 Pytorch 采样器，可以利用任何有用的示例元数据

![](img/25305ebe5820fac9a3ec521e07dcdffb.png)

克里斯蒂娜·温特在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 拍摄的照片

当你正在用 [PyTorch](https://pytorch.org/) 构建你令人敬畏的深度学习应用时， *torchvision* 包提供了许多现有数据集的便捷接口，如[*【MNIST】*](http://yann.lecun.com/exdb/mnist/)和 [*Imagenet*](http://image-net.org/) 。随机梯度下降通过将实例连续采样成小批量来进行。在许多情况下，您不必为此失眠，可以坚持默认行为:一个接一个地检查图像列表，并在每个时期后重新排列列表。如果您在建模过程中没有理由修改它，那么您可以停止阅读这里的内容。

然而，当你在你自己聚集和管理的自定义数据集上工作时，你可能最终会编写你自己的*数据集、数据加载器、*或*采样器*的子类。这就是我们在 [*Atomwise*](https://www.atomwise.com/) 的情况，我们试图根据结构模型预测可能的医学药物的生物活性。在不涉及太多细节的情况下，为了下面的展示，让我简要描述一下我们的数据模式的简化版本。每个例子由一对具有空间坐标的文件组成，用于蛋白质目标和与之结合的配体分子。根据它们的分析(为确定活性而进行的化学或生物实验的类型)，存在对应于不同终点和置信度的多个标记。一些反面的例子可以通过多种不同的方式综合产生。我们不断地问自己这个问题，“使用这些数据的最佳方式是什么？”而且你猜对了，答案从“看情况”到“很复杂”不等。在药物发现领域，为基准构建提供规范、通用的方法可能很棘手。因此，随着时间的推移，我们一直在尝试各种变化，例如:

*   均匀地对目标进行采样，与已知活性分子的数量成比例，或者与其他导出的加权公式成比例
*   蛋白质属于高级家族；我们可以根据层次分组来指定数据集的组成
*   使用实例类型的相对频率(“实验实例 70%的时间，合成实例 30%的时间”)
*   对于匹配目标，在每个正样本之后立即采样负样本
*   替换或不替换的采样

我想你明白了:在构建我们的训练和测试分布时，有一个很大的假设空间。

与其他数据集类似，如 *ImageNet* ，原始数据量太大，无法完全加载到主内存中。通常，它驻留在磁盘上，并使用巧妙的缓存和压缩方案进行访问。我们也可以通过 [*Redis*](https://redis.io/) 等分布式内存服务器来提供。然而，我们可以在内存中保存的是一个目录表，其中包含对原始数据、目标标签和任何其他有用的元数据的引用，以支持上面概述的采样方案。以下是一个假设的元数据文件:

![](img/3cf02738867ab3f6086c96edaa62eac6.png)

改变采样的一个简单方法是获取一个`torch.utils.data.WeightedRandomSampler,`并应用一个脚本来计算元数据表中的权重列。或者，为了只包含一些实例而不包含其他实例，我们可以动态地确定所需的行索引，并应用一个`torch.utils.data.SubsetRandomSampler.`。这些都是非常好的选项，这正是我们开始时所做的。但是我们的实验规范的复杂性随着时间的推移而增长；数据准备错误悄然而至，我们希望无需编写代码就能进行实验。因此，我们开始考虑更通用、更灵活的采样机制。我们提出的是一个由 YAML 规范配置的采样器的子类。由于我们的整个机器学习框架由 YAML 文件管理，采样现在构成了它的一部分。经过几轮的改进，我们最终得到了一个`TreeSampler`，我将在这篇文章的剩余部分描述它的设计。

为了深入研究这个问题，想象一下正面的例子通常是很少的，但是为了平衡这些类，我们想对它们进行 30%的额外采样。所以我们的初始树只包含一个根节点和两个叶节点:

![](img/f51a9497b278d95fe7abd62ddeadaec8.png)

注意到一个节点自然地包含了`WeightedRandomSampler`和`SubsetRandomSampler.`的两个方面*,我们可以将满足选择条件的行子集与子节点相关联。每个节点的任务是一次枚举一个子节点。有不同的方法可以做到这一点。当然，熟悉的随机抽样概念“有替换”或“没有替换”浮现在脑海中。严格地说，只有前者才构成真正意义上的抽样；后者可以通过一个简单的列表迭代器来实现。列表通常会在枚举完所有元素后重新排列，但在某些情况下，不这样做是有用的。因此，总而言之，定义三种可能的采样模式是明智的:`replacement,` `sequential,`或`shuffle.`*

在下文中，我将进一步形式化树及其节点的规范，并基于我们的玩具数据模式演示几个用例。

**案例 1:加权抽样**

采样权重通过对所有兄弟节点进行归一化来归纳概率。在树的图片中，我们可以标记父节点和子节点之间的分支。但是为了保持整洁，相当于给每个子节点赋予一个权重。注意，这些重量属于父母的取样程序；这意味着如果父代应用顺序或无序采样，它们就没有意义。所以让我们把上面的树写成如下:

![](img/784f173bc6253a1f27d8d9d212a9b8a0.png)

节点名称出现在括号中，仅供参考。`column`元数据文件中的表头行；`value`特定内容。如上所述，`mode`可以是`replacement,` `sequential,`或`shuffle.`中的一个，这里权重作为常数给出。为了获得标准意义上的实例权重，我们还允许一个包含任何列名的表达式，比如用`weight: proportional(conf)`或`weight: proportional(count)`表示行数。

隐式地，子集选择使用等式操作符`__eq__();`将列与指定的值进行比较，这是一种简单但可能不太常见的选择机制，它允许使用任何其他比较操作符。

**案例二:多条件**

表达多层次采样条件的能力是建立树的首要原因。在我们的玩具数据集中，我们有两种类型的负面例子，`measured`和`synthetic;`这里是如何以 60%:40%的比例平衡它们，此外还有与之前相同的活跃/不活跃类平衡:

![](img/c0c6096fe116b9b6f6b73a433393af24.png)

敏锐的读者当然会认识到，对于主动、测得的阴性和合成的阴性示例，等效于权重分别设置为 *.3、. 42 和. 28* 的标准`WeightedRandomSampler,`

**情况 3:欠采样多数类**

先前的树正在生成无限序列的替换采样。以这种方式训练是有效的，尽管传统上，在 epochs 中的训练更常见——通过所有可用的数据完成扫描，然后重新洗牌。比方说，我们想对正面的例子这样做，但是我们有大量的合成的反面例子，并且不关心在每个时期列举它们中的每一个。进一步假设我们也想平衡正面和负面。然后，我们可以通过设置如下模式对多数类进行欠采样:

![](img/437fdcf3bf4a1fac500d064083fe5e49.png)

**案例 4:均匀采样**

我们如何描述以相同的频率对每种蛋白质进行采样，而不管我们的元数据包含每种蛋白质的多少数据？简单的解决方案是为每种蛋白质构建一个包含一个节点的树，并分配相等的权重:

![](img/40b9dfcd7593979ff3b0fca336f7427a.png)

然而，这个列表可能会很长，手动编写会非常繁琐！所以让我们发明以下捷径:

![](img/c955bad19687deb4fcb3f20758a41bd5.png)

在构建树时,“magic”`for_each`值就像正则表达式中的通配符:对于文件中遇到的每个惟一值，它克隆一个兄弟节点。

**情况 5:重复**

测试时间增加是一种常见的做法，可以稍微提高预测的准确性。我们对相同实例的多个副本的预测分数进行平均，但是应用了不同的增强。节点属性`repeat`就是为了做这件事而设计的。比方说，我们希望聚合每个示例的 4 个以上的扩展:

![](img/3544d240dcad1366e1016b8d9dad5b27.png)

这将生成四个相同活动实例的序列，后面跟着四个相同的非活动实例。

**案例 6:约束**

现在让我来看最后一个也是最复杂的例子。假设我们正在训练一个连体网络:每个实例由 2 个连续的蛋白质/分子对组成，具有相同的蛋白质但不同的分子；这对中的一个是活动的，另一个不是。

正如我们在上面看到的，我们可以使用`sequential`模式在活动和不活动之间切换。但是我们需要在这方面做更多的工作；也就是说，将蛋白质限制在两者之间。这里`repeat`功能再次派上了用场:

![](img/8f1d395d99340012f858ccac7f9e32c0.png)

为了便于说明，让我们按顺序完成第一个请求的步骤:

1.  `root`有多少种蛋白质，就有多少个孩子。不失一般性，假设它选择`node_prot_1.`

2.`node_prot_1` 是一个顺序节点，所以它选择它的第一个子节点`node_active.`

3.`node_active`是一个叶节点，所以它用`protein=prot1`和`active=1`随机选择元表中的某一行。这是`TreeSampler`返回的例子。

在第二个请求中，

1.  `root`是一个重复的节点，所以它必然会选择和以前一样的节点，`node_prot_1.`
2.  `node_prot_1`是一个有两个子节点的顺序节点，由于它先前列举了第一个子节点，所以现在它前进到`node_inactive.`
3.  `node_active`是一个叶节点，所以它随机选取一个带有`protein=prot_1`和`active=0`的行。这是第二个请求中返回的示例。

第三个请求将再次跟随第一个请求的脚步。

**算法**

我们目前正致力于共享我们的代码；然而，它应该(但愿如此！)不难想象到现在`TreeSampler`的实现。初始化以类似于上面所示的格式读取元数据文件和配置。树是从根到叶递归构造的；子节点被创建并与根据给定条件过滤的示例子集相关联。

我想指出一个乍一看可能并不明显的怪癖:配置和数据集的某些组合可能会导致空的(不可满足的)节点。例如，针对特定于目标的分类度量的训练要求每个蛋白质至少有一个活动的和一个非活动的例子；然而，对于某些蛋白质，元数据可能只包含活性物质或不含活性物质。这就是我们的*修剪*算法的用武之地。使用节点属性`prune_method: individual,`，我们可以忽略(删除)这个单独的空节点。但是在这种情况下，通过指定`prune_method: parent.`更有意义的是完全不考虑蛋白质，注意修剪可以沿着树向上传播多个步骤，直到到达`prune_method: individual`(或者根，此时整个树是空的)。还要注意，修剪会改变聚集的节点权重，因此最终的采样概率是在最终的自底向上过程中计算的。

在我们的第一个实现版本中，我们曾经使用`pandas.DataFrame,`存储示例子集，但是后来的优化导致了相当大的加速:实际的示例可以在构造后被丢弃。我们需要维护的只是索引数组，在内部节点的情况下指向子节点，在叶节点的情况下指向元数据文件中的行号。这些可以使用 *NumPy* 函数直接处理，而不必求助于 *pandas* 。

和其他采样器类一样，在运行时，每次调用`TreeSampler:__next__()`都会返回一个元数据行的索引。它是沿着从根到叶子的路径来完成的。每个节点维护一个本地枚举状态，并根据其指定的属性彼此独立地进行采样。与其为每个实例请求生成一个随机数，不如让所有类型的节点在用完时创建一个完整的子索引缓冲区，这样效率会更高。三种采样模式的区别仅在于补充方式:替换模式的自举采样，洗牌模式的重新洗牌，或者顺序模式的除了倒带什么都不做。根据我们的经验，采样器是非常有效的，每次迭代只需要我们总时间的一小部分，即使对于有数百万行的文件也是如此。

**辅助样本值**

为了使模型训练运行可重复，通常建议将随机种子初始化为已知值(这意味着可以使用的所有随机值 python 库、NumPy、PyTorch 和 cudNN 的随机数生成器)。但是容易被忽略的是 PyTorch `DataLoader`使用多个工作进程(基于`multiprocessing`包)来预取 IO 密集型的例子，同时应用转换和扩充。所有这些过程都依赖于它们自己独立的随机数发生器。即使将它们都初始化为相同的值，也不能保证确定性，因为随着时间的推移，小批量到进程的分配顺序会因竞争条件而变化。

我们发现，在不引入太多代码复杂性的情况下，使数据集转换真正具有确定性的唯一方法是，生成与采样行索引序列并行的所有所需随机种子和参数的序列。例如，对于随机(2D)旋转，我们可以与每个采样的行索引一起生成一个角度。回想一下，采样器是驻留在主进程中的单例对象——因此，所使用的随机数生成器没有歧义。我们允许用户配置一个可变大小的命名迭代器列表。它们的结果被打包成一个数据类结构，传递给转换。我们的转换管道在整个 *YAML* 配置中也有专门的部分，我们的转换类知道如何从生成的数据记录中挑选出它们需要的值。这样，工作进程的所有局部随机性都被绕过了。

当然，这种机制可以控制任何迭代器序列，而不仅仅是随机值。假设对于测试时间增加(案例 5)，我们希望对 4 种不同的作物进行平均，并且`CropTransform`类接受一个字符串`loc`参数。然后，我们可以通过指定参数`loc: itertools.cycle([‘lower_right’, ‘lower_left’, ‘upper_right’, and ‘upper_left’]).`从采样器配置中集中控制这一点。这些值不依赖于所选示例的细节，并将连续出现在一行中。

**总结**

自定义数据集通常带有相关的元数据字段；探索使用它们来确定训练和评估机器学习模型的采样方案的最佳方式是值得的。在采样过程中，对于加权、子集化和约束示例，可能有各种合理的选择。为了避免重复硬编码或者为每个这样的实验改变元数据文件，我们提出并实现了一个 PyTorch `TreeSampler`类。在初始化时，它是根据配置和元数据文件动态构造的。每个节点基于逻辑条件选择一个示例子集；它以顺序、无序或替换模式对其子节点进行采样，彼此独立。在后一种情况下，可以根据元数据列或行计数将频率权重作为常数分配给子代。为了控制跨多个工作线程的数据扩充和转换，有一种生成辅助参数和随机数序列的方法很有帮助，这种方法与采样器生成的行索引并行。

**致谢**

这项工作是我和来自 [Atomwise](http://www.atomwise.com) 的令人敬畏的(前)同事 Misko Dzamba 和 Bastiaan Bergman 合作完成的——谢谢！