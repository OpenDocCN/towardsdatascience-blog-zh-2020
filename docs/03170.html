<html>
<head>
<title>A Simple Approach To Building a Recommendation System</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一种构建推荐系统的简单方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-simple-approach-to-building-a-recommendation-system-d0f4de1a1f50?source=collection_archive---------16-----------------------#2020-03-26">https://towardsdatascience.com/a-simple-approach-to-building-a-recommendation-system-d0f4de1a1f50?source=collection_archive---------16-----------------------#2020-03-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f0c5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">利用惊喜包在Python中构建协同过滤推荐器</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/e1ad8bc9b44be41d2cad35a590992bbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*KQxKzb8hE2_t72TBRFl2Bg.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">具有协同过滤的示例推荐系统。莫莉·里伯斯金图片。</p></figure><p id="8c79" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">要理解推荐系统的力量，最简单的方法就是关注网飞，他最先进的推荐系统让我们在电视机前呆上几个小时。然而，推荐人是极其多样化的，他们在交叉销售产品、确定具有相似技能的员工候选人以及寻找会对促销信息做出回应的客户方面发挥着作用。这些例子仅仅触及了如何使用推荐系统的表面。</p><p id="8448" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">尽管推荐器可能非常复杂，但有两种简单的方法可以作为一个良好的起点。</p><ul class=""><li id="3b0c" class="lq lr it kw b kx ky la lb ld ls lh lt ll lu lp lv lw lx ly bi translated">基于内容的过滤:使用项目特征来推荐与用户以前喜欢或交互过的项目相似的项目。潘多拉的音乐基因组项目识别每首歌曲的音乐属性，并利用这些信息找到相似的歌曲并做出推荐。</li><li id="6a26" class="lq lr it kw b kx ma la mb ld mc lh md ll me lp lv lw lx ly bi translated">协同过滤:根据相似用户对每个项目的评价来确定用户喜欢的项目。网飞通过确定相似用户观看的内容来识别用户喜欢的节目和电影。</li></ul><p id="17b6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这篇文章将重点介绍使用巴西电子商务公司Olist发布的<a class="ae lz" href="https://www.kaggle.com/olistbr/brazilian-ecommerce" rel="noopener ugc nofollow" target="_blank">销售交易数据</a>开发一个协同过滤推荐系统。</p><h1 id="bab1" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">入门指南</h1><p id="bd0a" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">为了构建推荐器，我们将使用<a class="ae lz" href="https://surprise.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank"> Surprise </a>，一个为协同过滤而构建的Python <a class="ae lz" href="https://www.scipy.org/scikits.html" rel="noopener ugc nofollow" target="_blank"> scikit </a>包。</p><p id="af13" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">第一步是加载我们需要的包和数据集。数据集由8个表组成，但是出于演示的目的，我已经连接了表并隔离了我们需要的列。完整代码在这里<a class="ae lz" href="https://github.com/mollyliebeskind/Olist_Ecommerce_Recommendation_Engine" rel="noopener ugc nofollow" target="_blank">。</a></p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="25f3" class="nh mg it nd b gy ni nj l nk nl">#Import packages<strong class="nd iu"><br/>import</strong> pandas <strong class="nd iu">as</strong> pd<br/><strong class="nd iu">import</strong> matplotlib.pyplot <strong class="nd iu">as</strong> plt<br/><strong class="nd iu">import</strong> seaborn <strong class="nd iu">as</strong> sns</span><span id="e4c4" class="nh mg it nd b gy nm nj l nk nl"><strong class="nd iu">from</strong> surprise <strong class="nd iu">import </strong>NormalPredictor, Reader, Dataset, accuracy, SVD, SVDpp, KNNBasic, CoClustering, SlopeOne</span><span id="7454" class="nh mg it nd b gy nm nj l nk nl"><strong class="nd iu">from</strong> surprise.model_selection <strong class="nd iu">import</strong> cross_validate, KFold, GridSearchCV, train_test_split</span><span id="4513" class="nh mg it nd b gy nm nj l nk nl">#import dataset<br/>olist_data = pd.read_csv('olist_data.csv')</span></pre><p id="e320" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">正如现实世界的数据经常发生的那样，这个数据集不是为创建协作推荐系统而完美构建的。这里的一个大挑战是，几乎90%的用户都是第一次购买，这意味着我们没有他们以前的评分来确定喜欢的产品。相反，我们将把数据集分为重复用户和首次用户，并且只把重复用户输入到协作过滤模型中。对于第一次购买的顾客，我们仍然可以提供推荐，但它们会更加通用，侧重于商品的受欢迎程度和用户的位置。</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="ed3e" class="nh mg it nd b gy ni nj l nk nl"><strong class="nd iu">def</strong> repeat_and_first_time(data):</span><span id="d815" class="nh mg it nd b gy nm nj l nk nl">    repeaters = data.groupby('customer_unique_id').filter(<strong class="nd iu">lambda</strong> x: len(x) &gt; 1)<br/>    first_timers = data.groupby('customer_unique_id').filter(<strong class="nd iu">lambda</strong> x: len(x) == 1)<br/><br/>    <strong class="nd iu">return</strong> repeaters, first_timers</span></pre><h1 id="06df" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">利用惊喜</h1><p id="5ac0" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">为了利用surprise内置的用户评级矩阵转换，我们需要提供一个包含用户id列、项目id列和评级列的数据框架。</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="656e" class="nh mg it nd b gy ni nj l nk nl"><strong class="nd iu">def</strong> create_user_ratings_df(data):<br/>    df = data.groupby(['customer_unique_id','product_id'])['review_score'].agg(['mean']).reset_index()<br/>    <br/>    df = df.rename({'mean':'estimator', 'product_id':'productId'}, axis=1)<br/>    <strong class="nd iu">return</strong> df</span><span id="7546" class="nh mg it nd b gy nm nj l nk nl">user_ratings_df = create_user_ratings_df(repeater_data)</span><span id="7fcc" class="nh mg it nd b gy nm nj l nk nl">user_ratings_df.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/06cd682da84dfa19ac52aea5494af5ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*drPO3rW6ZINF5YpiTwgS2w.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">用户评级矩阵示例。莫莉·里伯斯金图片。</p></figure><p id="9fb6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">从这里开始，Surprise将帮助我们生成一个用户评级矩阵，其中每个用户id是一行，公司提供的每个产品是一列。这将产生与创建熊猫数据透视表相同的效果。我们将用80/20分区将数据帧分成训练集和测试集。</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="3415" class="nh mg it nd b gy ni nj l nk nl"><strong class="nd iu">def</strong> surprise_df(data):<br/>    <br/>    scale = (data.estimator.min(), data.estimator.max())<br/>    reader = Reader(rating_scale=scale)<br/><br/>    df = Dataset.load_from_df(data[['customer_unique_id',<br/>                                    'productId',<br/>                                    'estimator']], reader)<br/>    <br/>    <strong class="nd iu">return</strong> df</span><span id="0b10" class="nh mg it nd b gy nm nj l nk nl">user_ratings_matrix = surprise_df(user_ratings_df)</span><span id="2214" class="nh mg it nd b gy nm nj l nk nl">train_set, test_set = train_test_split(user_ratings_matrix, test_size=0.2, random_state=19)</span></pre><p id="6732" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">惊喜提供了<a class="ae lz" href="https://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html" rel="noopener ugc nofollow" target="_blank"> 11种不同的预测算法</a>，包括各种KNN和维数缩减技术，如奇异值分解和NMF。在本次演示中，我们将测试一些最常见的技术。</p><p id="8b92" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">使用5重验证，我们将比较以下模型的结果。</p><ul class=""><li id="0e1d" class="lq lr it kw b kx ky la lb ld ls lh lt ll lu lp lv lw lx ly bi translated">NormalPredictor:根据假定为正态的训练集分布预测随机评级的基线模型。</li><li id="e1c3" class="lq lr it kw b kx ma la mb ld mc lh md ll me lp lv lw lx ly bi translated">奇异值分解:一种矩阵分解技术，作为网飞奖的一部分由<a class="ae lz" href="https://sifter.org/~simon/journal/20061211.html" rel="noopener ugc nofollow" target="_blank">西蒙·芬克</a>推广。</li><li id="ecb7" class="lq lr it kw b kx ma la mb ld mc lh md ll me lp lv lw lx ly bi translated">KNNBasic:利用余弦相似性(或用户确定的距离度量)来执行KNN。</li><li id="31fe" class="lq lr it kw b kx ma la mb ld mc lh md ll me lp lv lw lx ly bi translated">协同聚类:一种<a class="ae lz" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.113.6458&amp;rep=rep1&amp;type=pdf" rel="noopener ugc nofollow" target="_blank">算法</a>，以类似于k-means的方法为聚类分配点数。</li></ul><p id="3101" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有两种方法可以评估模型性能。定性地说，你可以观察一个给定的用户，考虑到他们喜欢的其他产品，确定这个推荐是否有意义。例如，如果有人喜欢恐怖电影，不喜欢浪漫喜剧，<em class="no">《闪灵》</em>相对于<em class="no">真爱</em>会是一个不错的推荐。对于这个数据集，我们没有每个产品的信息，只有一个产品id，所以我们将使用一个定量的测量方法，<a class="ae lz" href="https://www.statisticshowto.datasciencecentral.com/rmse/" rel="noopener ugc nofollow" target="_blank">均方根误差</a>。这两种方法的结合是理想的，尽管定量测量在生产中更现实。</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="5902" class="nh mg it nd b gy ni nj l nk nl">kf = KFold(n_splits=5, shuffle=<strong class="nd iu">True</strong>, random_state=19)</span><span id="6cc1" class="nh mg it nd b gy nm nj l nk nl"><strong class="nd iu">def</strong> model_framework(train_data):</span><span id="f73b" class="nh mg it nd b gy nm nj l nk nl">    #store the rmse values for each fold in the k-fold loop <br/>    normp_rmse, svd_rmse, knn_rmse, co_rmse, slope_rmse = [],[],[], [],[]<br/><br/>    <strong class="nd iu">for</strong> trainset, testset <strong class="nd iu">in</strong> kf.split(train_data):<br/>        <br/>        <em class="no">#baseline</em><br/>        normp = NormalPredictor()<br/>        normp.fit(trainset)<br/>        normp_pred = normp.test(testset)<br/>        normp_rmse.append(accuracy.rmse(normp_pred,verbose=<strong class="nd iu">False</strong>))<br/>        <br/>        <em class="no">#svd</em><br/>        svd = SVD(n_factors=30, n_epochs=50,biased=<strong class="nd iu">True</strong>, lr_all=0.005, reg_all=0.4, verbose=<strong class="nd iu">False</strong>)<br/>        svd.fit(trainset)<br/>        svd_pred = svd.test(testset)<br/>        svd_rmse.append(accuracy.rmse(svd_pred,verbose=<strong class="nd iu">False</strong>))<br/>        <br/>        <em class="no">#knn</em><br/>        knn = KNNBasic(k=40,sim_options={'name': 'cosine', 'user_based': <strong class="nd iu">False</strong>}, verbose=<strong class="nd iu">False</strong>) <br/>        knn.fit(trainset)<br/>        knn_pred = knn.test(testset)<br/>        knn_rmse.append(accuracy.rmse(knn_pred,verbose=<strong class="nd iu">False</strong>))<br/>        <br/>        <em class="no">#co_clustering</em><br/>        co = CoClustering(n_cltr_u=3,n_cltr_i=3,n_epochs=20)         <br/>        co.fit(trainset)<br/>        co_pred = co.test(testset)<br/>        co_rmse.append(accuracy.rmse(co_pred,verbose=<strong class="nd iu">False</strong>))<br/><br/>    <br/>    mean_rmses = [np.mean(normp_rmse),<br/>                  np.mean(svd_rmse),<br/>                  np.mean(knn_rmse),<br/>                  np.mean(co_rmse),<br/>                  np.mean(slope_rmse)]<br/>    <br/>    model_names = ['baseline','svd','knn','coclustering','slopeone']<br/>    compare_df = pd.DataFrame(mean_rmses, columns=['RMSE'], index=model_names)<br/>    <br/>    <strong class="nd iu">return</strong> compare_df</span><span id="ffe1" class="nh mg it nd b gy nm nj l nk nl">comparison_df = model_framework(train_set)<br/>comparison_df.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/1989309aef7a70346e73c05d8f6abf8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*V7gz-62C5FYca_CmqrNkNg.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">莫莉·里伯斯金图片。</p></figure><p id="ba68" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">基于以上所述，我们确定SVD具有最低的rmse，并且是我们将继续调整的模型。</p><h1 id="8b19" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">模型调整:惊奇的网格搜索</h1><p id="089a" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">这个令人惊讶的包提供了一个使用GridSearchCV调整参数的选项。我们将为GridSearchCV提供一个参数字典，并计算和比较每个参数组合的rmse。</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="f52c" class="nh mg it nd b gy ni nj l nk nl"><strong class="nd iu">def</strong> gridsearch(data, model, param_grid):<br/>    param_grid = param_grid<br/>    gs = GridSearchCV(model, param_grid, measures=['rmse'], cv=5)<br/>    gs.fit(data)<br/>    <br/>    new_params = gs.best_params['rmse']<br/>    best_score = gs.best_score['rmse']<br/>    <br/>    print("Best score:", best_score)<br/>    print("Best params:", new_params)<br/>    <br/>    <strong class="nd iu">return</strong> new_params, best_score</span><span id="6cda" class="nh mg it nd b gy nm nj l nk nl">svd_param_grid = {'n_factors': [25, 50,100],<br/>                  'n_epochs': [20,30,50],       <br/>                  'lr_all': [0.002,0.005,0.01],<br/>                  'reg_all':[0.02,0.1, 0.4]}<br/><br/>svd_params, svd_score = gridsearch(train_set, SVD, svd_param_grid)</span></pre><p id="d918" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">从该搜索中，我们得到一个输出，告诉我们获得的最佳分数(最低rmse)是1.27，它是使用参数{'n_factors': 25，' n_epochs': 50，' lr_all': 0.01，' reg_all': 0.1}产生的。</p><h1 id="50c6" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">最终模型和指标</h1><p id="081c" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">利用上面的参数，我们然后在没有交叉验证的完整训练集上运行该模型，并根据测试集获得准确度分数。</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="a26c" class="nh mg it nd b gy ni nj l nk nl"><strong class="nd iu">def</strong> final_model(train_set, test_set):<br/>    params = {'n_factors': 10, 'n_epochs': 50, 'lr_all': 0.01, <br/>              'reg_all': 0.1} <br/>    <br/>    svdpp = SVDpp(n_factors=params['n_factors'], <br/>                    n_epochs=params['n_epochs'],<br/>                    lr_all=params['lr_all'], <br/>                    reg_all=params['reg_all'])<br/>    svdpp.fit(train_set)<br/>    <br/>    predictions = svdpp.test(test_set)<br/>    rmse = accuracy.rmse(predictions,verbose=<strong class="nd iu">False</strong>)<br/>            <br/>    <strong class="nd iu">return</strong> predictions, rmse<br/>    <br/>final_predictions, model_rmse = final_model(train_set, test_set)</span></pre><p id="afad" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">的。测试属性输出预测，其中包含用户id、项目id、用户实际评级、模型估计评级以及可能做出预测的指示器。除了查看来自最终训练模型的model_rmse输出，我们还将查看所有预测的绝对误差分布。为此，我们将把预测输出打包到一个数据帧中，并添加一个列来指示每个预测的错误。然后，我们将通过绘制误差直方图来可视化结果。</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="5560" class="nh mg it nd b gy ni nj l nk nl">results = pd.DataFrame(final_predictions, columns=['userid', 'item_id', 'user_rating', 'model_est', 'details'])     <br/>results['err'] = abs(results.model_est - results.user_rating)</span></pre><p id="fda6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在下面的图中，我们看到，尽管完整数据集的误差为1.0，但当用户给产品的评分高于3时，模型做出了更好的预测，误差仅为0.8。相比之下，当用户给产品打3分或3分以下的分数时，误差明显更高，为1.5分。这是一个很好的结果，因为为了提供好的推荐，我们更关心准确预测用户喜欢并评分高于3的产品。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi nq"><img src="../Images/650b42ea4486e4b4aefbc88155cb8837.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RGnjoaAgsImR6X2IuAtxWw.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">比较整体模型误差与等级&gt; 3和等级≤3的误差的图。莫莉·里伯斯金图片。</p></figure><p id="4bf3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然后，可以使用转储模块对模型进行打包，转储模块是Pickle的包装器。对于这个例子，协同过滤推荐只是整个系统的一部分。它根据每个地理区域的总体畅销产品和最佳表现者进行推荐。</p><h1 id="8592" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">附加注释</h1><p id="cc65" class="pw-post-body-paragraph ku kv it kw b kx mx ju kz la my jx lc ld mz lf lg lh na lj lk ll nb ln lo lp im bi translated">为了熟悉这个过程，Surprise有一些很好的内置数据集，文档详细解释了不同的交叉验证方法、相似性度量和预测算法。</p><p id="f9e3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">目前，Surprise还不能处理隐式评级、执行内容过滤或生成混合推荐。然而，对于初学者来说，Surprise是一个简单直接的协作过滤包。</p><p id="2587" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你可以在<a class="ae lz" href="https://github.com/mollyliebeskind/Olist_Ecommerce_Recommendation_Engine" rel="noopener ugc nofollow" target="_blank"> github </a>上找到这个例子的所有代码。</p></div></div>    
</body>
</html>