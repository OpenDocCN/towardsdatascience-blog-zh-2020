# 用 fastText 和 BM25 建立句子嵌入索引

> 原文：<https://towardsdatascience.com/building-a-sentence-embedding-index-with-fasttext-and-bm25-f07e7148d240?source=collection_archive---------7----------------------->

## 探索如何建立一个文本搜索系统

![](img/d46473139714c74ec6975f4b99b163be.png)

杰西卡·鲁斯切洛在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

*本文涵盖了句子嵌入和*[*code question*](https://github.com/neuml/codequestion)*1.0。最新发布的 codequestion 使用了句子转换器。* [*此处阅读更多*](https://medium.com/neuml/find-answers-with-codequestion-2-0-50b2cfd8c8fe) *。*

自然语言处理是机器学习领域中发展最快的领域之一。许多领域都在发生深度创新，让用户能够更快地找到更好的数据。曾经只有拥有大量 IT 预算和资源的人才能实现的技术和算法现在可以在笔记本电脑上运行。虽然 NLP 不是一个新问题，但是有一些经过时间考验的方法表现得非常好。最简单的方案很多时候可能是最好的方案。

本文将探索各种方法，并对构建文本搜索系统进行评估。

## 全文搜索引擎

允许用户输入搜索查询并找到匹配结果的全文搜索引擎是一种可靠的解决方案，具有很好的性能历史。在这些系统中，每个文档都被标记化，通常去掉一列常用词，称为停用词。这些令牌存储在倒排索引中，每个令牌都根据令牌频率等指标进行加权。

搜索查询也使用相同的方法进行标记化，并且搜索引擎为查询标记找到最佳匹配记录。有一些高度分布式且非常快速的解决方案已经在生产中证明了自己多年，比如 [Elasticsearch](https://www.elastic.co/) 。今天最常见的令牌加权算法是 [BM25](https://en.wikipedia.org/wiki/Okapi_BM25) 。它工作得非常好，仍然很难被击败。

## 嵌入

单词嵌入在过去的 5-7 年里发展迅速，首先从 [Word2vec](https://en.wikipedia.org/wiki/Word2vec) 开始，接着是 [GloVe](https://en.wikipedia.org/wiki/GloVe_(machine_learning)) 和 [fastText](https://en.wikipedia.org/wiki/FastText) 。这些算法通常都构建 300 维向量。现在有了更高级的嵌入，它们的尺寸更大(768+维度)，能够理解句子中单词的上下文，其中 [BERT](https://en.wikipedia.org/wiki/BERT_(language_model)) 嵌入处于领先地位。换句话说，超越简单的单词包方法。

易于使用、健壮的库已经存在，使开发人员能够利用这些进步。 [HuggingFace Transformers](https://github.com/huggingface/transformers) 是一个优秀的库，拥有一组快速增长的前沿功能。通用句子嵌入是另一个重要的发展领域。拥有一个单一的动态模型，可以将文本转换为下游学习任务的嵌入是至关重要的。[句子变形金刚](https://github.com/UKPLab/sentence-transformers)构建在变形金刚之上，是一个可以构建高质量句子嵌入的库的优秀例子。

## 性能考虑因素

随着构建完美嵌入的步伐越来越快，这对试图解决当前业务问题的实践者来说意味着什么。你总是使用最新和最大的进步吗？你总是需要吗？有更复杂的权衡。当处理数百万甚至数十亿个数据点时，处理时间与可接受的功能之间的关系总是一个需要讨论的话题。这些对话考虑了可用的资源、可用的时间以及满足给定问题的要求所必需的内容。

评估文本搜索解决方案时要问的一些问题。

*   我需要多快的查询响应和索引速度？需要多高的精确度？
*   我可以访问哪些计算资源？我可以访问 GPU 吗？
*   我有多少条记录和多少存储空间？假设向量使用 32 位(4 字节)浮点，一个 300 维的向量每条记录需要 300x4 字节。对于 4096 维向量，它是 4096x4，对于相同的数据，需要 13 倍多的空间。
*   一个全文搜索引擎能满足要求吗？

## 我们在建造什么？

[codequestion](https://github.com/neuml/codequestion) 是一个允许用户直接从终端询问编码问题的应用程序。许多开发人员在开发和运行 web 搜索时会打开一个 web 浏览器窗口，因为会出现问题。codequestion 致力于加快这一过程，以便您可以专注于开发。它还允许无法直接访问互联网或互联网访问受限的用户运行代码问题查询。下面是一个实际应用的例子。

![](img/47668b13563564b6a8c3334051cafd61.png)

codequestion 应用程序演示

codequestion 由一个 [SQLite](https://en.wikipedia.org/wiki/SQLite) 数据库提供支持，该数据库存储了问答回复。提供了使用[堆栈交换数据](https://archive.org/details/stackexchange)的预训练模型。该数据库还可以加载自定义的问题列表。

## 精心设计解决方案

最好总是从最简单的解决方案开始，然后一步一步往上走。我们能不能对数据做一个全文索引，然后就到此为止？添加外部文本索引并不是我们所希望的，因为这个应用程序被设计为本地安装在开发人员的机器上。SQLite 确实提供了一个名为 FTS5 的文本索引解决方案。这是很容易添加的，似乎工作得很好。但是一种测量结果的方法对于真正判断它的效果是必要的。

## 评估结果

构建了一个包含 100 个查询的数据集来判断一个索引的工作情况。对于每个查询，手动运行 web 搜索，并为该查询存储顶部堆栈交换结果。选择了流行的查询(即在 python 中解析日期),并注意不总是在查询和答案之间有直接的标记匹配。

[平均倒数排名(MRR)](https://en.wikipedia.org/wiki/Mean_reciprocal_rank) 用于测量人工注释的搜索查询的最高结果得分。标准 FTS5 索引对 100 个查询数据集的评分如下。

*MRR = 45.9*

作为开始还不算太坏。是时候增加复杂性来决定权衡是否值得了。

## **BM25**

SQLite 的 FTS5 默认令牌加权方案是使用 [tf-idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) 。它还支持 BM25，得分为:

*MRR = 49.5*

绝对是个进步。但感觉还是有很大的提升空间。让我们试试句子嵌入。

## **快速文本句子嵌入**

标准文本标记搜索正被同义词和不完全匹配所困扰。单词嵌入是找到不完全匹配的相似结果的好方法。

所需功能的示例如下:

![](img/67f7657dd4a75be2a797e821e0ffa4c9.png)

linux 解码音频文件查询

查询“linux 解码音频文件”返回了类似“通过 linux 命令行播放 mp3 或 wav 文件”的问题。单词 decode 和 audio 没有出现在返回的结果中，但是 decode 类似于 play，audio 类似于 mp3/wav。

上面的示例查询被标记为["linux "，" decode "，" audio "，" file"]。可以使用 fastText 为每个标记检索单词嵌入。为了构建句子嵌入，嵌入可以被平均在一起以创建单个嵌入向量。

## 快速文本+ BM25

平均效果出奇的好。但是如果我们可以两全其美，使用 BM25 来衡量每个标记对句子嵌入的贡献有多大呢？这就是 codequestion 采用的方法。BM25 索引建立在数据集之上。使用[预先训练的快速文本](https://fasttext.cc/docs/en/english-vectors.html)向量加上 BM25，得分为:

*MRR = 66.1*

比直 BM25 (66.1 比 49.5)有相当大的进步！

## 定制训练的快速文本嵌入

这种级别的功能是性能和结果的可接受组合。但还有最后一件事可以尝试，这可能会进一步提高分数，即在问题数据库本身上定制训练的 fastText 嵌入模型。使用根据数据分数训练的 fastText 嵌入，如下所示:

*MRR = 76.3*

又一次，相当大的进步。我们可以继续尝试 BERT 嵌入模型，该模型得分更高，但也需要更多计算/存储。fastText + BM25 不考虑顺序，所以类似“python convert UTC to localtime”的查询可以匹配“python convert localtime to UTC”。BERT 会更好地处理这个用例。但是对于这个项目，嵌入方法工作得很好。

## 构建索引

嵌入本身只是一堆数字。一旦完整的数据存储库被转换为句子嵌入，就需要有一种方法来为查询找到相似的结果。

[余弦相似度](https://en.wikipedia.org/wiki/Cosine_similarity)是比较两个向量相似程度的常用方法。最简单的方法是强力比较查询向量和每个结果，并返回最相似的结果。对于小型数据集，这种方法很有效。但是随着数据的增长，它无法扩展。

Faiss 是一个向量相似性搜索库，可以在这方面提供帮助。它可以量化向量以减少存储量，并支持可扩展的近似最近邻搜索。Faiss 支持高性能搜索，提供结果准确性和速度的良好结合。

## 结论

本文介绍了一种评估如何构建搜索系统的方法，从而产生一个句子嵌入索引。这条路不会总是通向同一个终点，但是像这样的渐进方法应该有助于找到问题的最佳解决方案。