<html>
<head>
<title>Do we need deep graph neural networks?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我们需要深度图神经网络吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/do-we-need-deep-graph-neural-networks-be62d3ec5c59?source=collection_archive---------6-----------------------#2020-07-20">https://towardsdatascience.com/do-we-need-deep-graph-neural-networks-be62d3ec5c59?source=collection_archive---------6-----------------------#2020-07-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="67b8" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">被认为有害的深度？</h2><div class=""/><div class=""><h2 id="a9c9" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">深度学习的标志之一是使用数十层甚至数百层的神经网络。与之形成鲜明对比的是，图形深度学习中使用的大多数架构都很浅，只有少数几层。在这篇文章中，我提出了一个异端的问题:图神经网络架构中的深度带来任何优势吗？</h2></div><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/f4c0447895af69b877fc0f9487726314.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CWUg-DZBQNONJXuxQdLrFQ.png"/></div></div></figure><p id="3964" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi lx translated"><span class="l ly lz ma bm mb mc md me mf di"> T </span>今年，关于图形的深度学习被冠上了机器学习领域<a class="ae mg" href="https://twitter.com/prlz77/status/1178662575900368903" rel="noopener ugc nofollow" target="_blank">最热门话题</a>的桂冠。然而，那些习惯于想象具有数十甚至数百层的卷积神经网络的人<em class="mh">会失望地看到大多数关于图形“深度”学习的工作最多只使用了几层。“深度图神经网络”是一个误称吗？我们是否应该，套用经典的说法，想知道深度是否应该被认为对图形学习有害？</em></p><p id="cbfd" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">训练深度图神经网络是困难的。除了在深度神经架构中观察到的标准困境，如反向传播中的消失梯度和由于大量参数导致的过拟合，还有一些图形特有的问题。其中之一是<em class="mh">过度平滑</em>，由于应用了多个图卷积层，节点特征倾向于收敛到同一个向量并且变得几乎不可区分的现象[1]。这种行为首先在 GCN 模型[2，3]中观察到，其作用类似于低通滤波器。另一个现象是<em class="mh">瓶颈，</em>导致来自指数级邻居的信息“过度压缩”成固定大小的向量[4]。</p><p id="13d8" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">最近，大量的努力致力于解决图形神经网络中的深度问题，希望获得更好的性能，并且在涉及只有两层的图形神经网络时，可能避免使用术语“深度学习”时的尴尬。典型的方法可以分为两类。首先，正则化技术，如逐边丢失(DropEdge) [5]，节点特征之间的成对距离归一化(PairNorm) [6]，或逐节点均值和方差归一化(NodeNorm) [7]。第二，架构变化包括各种类型的剩余连接如跳跃知识[8]或仿射剩余连接[9]。虽然这些技术允许训练具有数十层的深度图神经网络(否则这是一项困难甚至不可能的壮举)，但它们未能展示出显著的收益。更糟糕的是，使用深层架构经常会导致性能下降。从[7]复制的下表显示了在节点分类任务上比较不同深度的图形神经网络的典型实验评估:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mi"><img src="../Images/7437822e50f8bd10bc4df6be0454c976.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mYMS5yplStYiheNbrsrJXg.png"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">深度图神经网络架构的典型结果显示在合著者引文网络的节点分类任务中。随着深度的增加，基线(具有剩余连接的 GCN)表现不佳，性能从 88.18%急剧下降到 39.71%。使用 NodeNorm 技术的架构随着深度的增加表现一致。然而，当深入时，性能下降(尽管不显著，从 89.53%下降到 87.40%)。总体而言，深度 64 层架构实现的最佳结果(87.40%)不如简单基线的结果(88.18%)。此外，观察到 NodeNorm 正则化提高了浅层 2 层架构的性能(从 88.18%提高到 89.53%)。从[7]中复制的表(显示的是每类 5 个标签的情况；论文中研究的其他设置表现出类似的行为)。类似的结果显示在[5]和其他几篇论文中。</p></figure><p id="d7ff" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">从该表中可以明显看出，很难将深度架构带来的优势与训练这种神经网络所需的“技巧”区分开来。实际上，上面例子中的 NodeNorm 也改进了一个只有两层的浅层架构，达到了最佳性能。因此，尚不清楚在其他条件不变的情况下，更深层次的图神经网络是否表现更好。</p><p id="08c1" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi lx translated"><span class="l ly lz ma bm mb mc md me mf di"> T </span>这些结果显然与网格结构数据深度学习的传统设置形成鲜明对比，其中“超深度”架构[10，11]带来了性能上的突破，并在今天得到了广泛应用。在下文中，我将尝试提供一些可能有助于回答这篇文章标题中提出的挑衅性问题的方向。我自己也没有一个明确的答案。</p><p id="c436" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated"><strong class="ld ja">图表的结构。</strong>由于网格是特殊的图形，当然<em class="mh">也有</em>深度有助于图形的例子。除了网格之外，代表分子、点云[12]或网格[9]等结构的“几何”图形似乎也受益于深层架构。为什么这样的图与通常用于评估图神经网络的引用网络(如 Cora、PubMed 或 CoauthorsCS)如此不同？其中一个区别是，后者类似于低直径的“<a class="ae mg" href="https://en.wikipedia.org/wiki/Small-world_network" rel="noopener ugc nofollow" target="_blank">小世界</a>”网络，人们可以通过几跳从任何其他节点到达任何节点。结果，仅仅几个卷积层的感受域就已经覆盖了整个图[13]，所以增加更多的层无助于到达远程节点。另一方面，在计算机视觉中，感受野多项式增长，需要许多层来产生捕捉图像中对象的上下文的感受野[14]。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mn"><img src="../Images/9408f48d6eb41a43c7794ed2424a9377.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wd4fi7WBCrxSi53aRF-mNw.png"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">在小世界图(上图)中，从一个节点到达另一个节点只需要几跳。结果，邻居的数量(以及相应地，图形卷积滤波器的感受域)以指数速度增长。在这个例子中，为了从红色节点到达任何节点，只需要两次跳跃(不同的颜色指示从红色节点开始将到达的相应节点的层)。另一方面，在网格(底部)上，感受野的增长是多项式的，因此需要更多的层来达到相同的感受野大小。</p></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mo"><img src="../Images/f54af546835e38a0fc3fa2f6b5ef038a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5XZJwhfWOEm0tLrE"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">在邻居呈指数增长的图中(如上图所示),会出现瓶颈现象:来自太多邻居的太多信息必须压缩到单个节点特征向量中。结果，消息无法传播，性能受到影响。</p></figure><p id="d32c" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated"><strong class="ld ja">长程 vs 短程问题。</strong>一个稍微不同但相关的区别是问题需要长范围还是短范围的信息。例如，在社交网络中，预测通常仅依赖于来自节点的本地邻居的短程信息，并且不会通过添加远程信息来改进。因此，这样的任务可以由浅 gnn 来执行。另一方面，分子图通常需要长程信息，因为分子的化学性质可能取决于其相对侧的原子组合[15]。可能需要深层 GNNs 来利用这些长程相互作用。然而，如果图的结构导致感受野的指数增长，瓶颈现象可以阻止远程信息的有效传播，这解释了为什么深度模型在性能上没有改善[4]。</p><p id="3076" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated"><strong class="ld ja">理论局限。</strong>除了更大的感受域，深度架构在计算机视觉问题中提供的一个关键优势是它们能够从简单的特征组合出复杂的特征。将 CNN 从面部图像中学习的特征可视化，显示出从简单的几何图元开始，到整个面部结构结束的越来越复杂的特征，这表明传说中的“<a class="ae mg" href="https://en.wikipedia.org/wiki/Grandmother_cell#:~:text=The%20grandmother%20cell%2C%20sometimes%20called,as%20his%20or%20her%20grandmother." rel="noopener ugc nofollow" target="_blank">祖母神经元</a>”比神话更真实。这种复合性对于图形来说似乎是不可能的，例如，无论神经网络有多深，都无法从边组成三角形[16]。另一方面，研究表明，如果没有特定的最小深度，使用消息传递网络计算某些图属性(如图矩)是不可能的[17]。总的来说，我们目前缺乏对哪些图形属性可以由浅 gnn 表示，哪些需要深度模型，以及哪些根本无法计算的理解。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mp"><img src="../Images/e80edabb9dc63e507375cdb831fd7b64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0c5tlL2HovdpbBvkPmyjTQ.png"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">卷积神经网络在人脸图像上学习特征的例子。注意当进入更深的层时，特征如何变得越来越复杂(从简单的几何图元到面部分到整个面)。图改编自马修·斯图尔特的<a class="ae mg" rel="noopener" target="_blank" href="/advanced-topics-in-deep-convolutional-neural-networks-71ef1190522d">博客文章</a>。</p></figure><p id="7329" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">深度与丰富度。与底层网格固定的计算机视觉相反，在对图形的深度学习中，图形的结构确实很重要，并且会被考虑在内。有可能设计更复杂的信息传递机制，考虑复杂的高阶信息，如标准 GNNs 不能发现的基序[18]或<a class="ae mg" rel="noopener" target="_blank" href="/beyond-weisfeiler-lehman-using-substructures-for-provably-expressive-graph-neural-networks-d476ad665fa3">子结构计数</a> [19]。人们可以选择具有更丰富的多跳过滤器的浅层网络，而不是使用具有简单 1 跳卷积的深层架构。我们最近关于<a class="ae mg" href="https://medium.com/@michael.bronstein/simple-scalable-graph-neural-networks-7eb04f366d07" rel="noopener">可扩展类初始图神经网络(SIGN) </a>的论文通过使用具有多个预先计算的过滤器的单层线性图卷积架构，将这一想法发挥到了极致。我们展示了比复杂得多的模型更好的性能，而时间复杂度只是它们的一小部分[20]。有趣的是，计算机视觉社区选择了相反的道路:早期带有大(高达 11×11)滤波器的浅层 CNN 架构，如<a class="ae mg" href="https://en.wikipedia.org/wiki/AlexNet" rel="noopener ugc nofollow" target="_blank"> AlexNet </a>，被带有小(通常为 3×3)滤波器的非常深层架构所取代。</p><p id="3fc1" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated"><strong class="ld ja">评价。</strong>最后但并非最不重要的一点是，图形神经网络的主要评估方法受到了来自 Stephan Günnemann 小组的 Oleksandr Shchur 及其同事的严厉批评[21]，他们提请注意常用基准的缺陷，并表明如果在公平的环境下进行评估，简单模型的性能与更复杂的模型相当。我们在深度架构中观察到的一些现象，比如性能随深度而下降，可能只是源于对小数据集的过度拟合。新的<a class="ae mg" href="https://ogb.stanford.edu/" rel="noopener ugc nofollow" target="_blank"> Open Graph Benchmark </a>解决了其中的一些问题，提供了非常大的图形，具有严格的训练和测试数据分割。我认为，我们需要做精心设计的具体实验，以便更好地了解深度在图形的深度学习中是否或何时有用。</p></div><div class="ab cl mq mr hu ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="ij ik il im in"><p id="a44b" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">[1]更准确地说，过度平滑使节点特征向量塌陷到一个子空间，参见 K. Oono 和 t .铃木，<a class="ae mg" href="https://arxiv.org/pdf/1905.10947.pdf" rel="noopener ugc nofollow" target="_blank">图神经网络对节点分类的指数松散表达能力</a> (2019)。arXiv:1905.10947，使用动态系统形式提供渐近分析。</p><p id="45bc" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">[2] Q. Li，Z. Han，X.-M. Wu，<a class="ae mg" href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/download/16098/16553" rel="noopener ugc nofollow" target="_blank">对半监督学习的图卷积网络的更深入见解</a> (2019)。继续。AAAI。将 GCN 模型与拉普拉斯平滑法进行类比，并指出过度平滑现象。</p><p id="c320" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">[3] H. Nt 和 T. Maehara，<a class="ae mg" href="https://arxiv.org/pdf/1905.09550.pdf" rel="noopener ugc nofollow" target="_blank">重温图形神经网络:我们所拥有的只是低通滤波器</a> (2019)。arXiv:1905.09550。使用图形的频谱分析来回答 gcn 何时表现良好。</p><p id="215b" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">[4] U. Alon 和 E. Yahav，<a class="ae mg" href="https://arxiv.org/pdf/2006.05205.pdf" rel="noopener ugc nofollow" target="_blank">关于图神经网络的瓶颈及其实际意义</a> (2020)。arXiv:2006.05205。确定了图形神经网络中的过度挤压现象，这类似于在顺序递归模型中观察到的现象。</p><p id="c2d8" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">[5] Y. Rong 等<a class="ae mg" href="https://openreview.net/pdf?id=Hkx1qkrKPr" rel="noopener ugc nofollow" target="_blank"> DropEdge:走向节点分类上的深度图卷积网络</a> (2020)。进行中。ICLR。一种类似于丢弃的想法，其中在训练期间使用边的随机子集。</p><p id="d54f" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">[6]赵和阿科格鲁。<a class="ae mg" href="https://arxiv.org/pdf/1909.12223.pdf" rel="noopener ugc nofollow" target="_blank"> PairNorm:在 GNNs </a> (2020)中解决过度投机问题。继续。ICLR。建议对结点要素之间成对距离的总和进行归一化，以防止它们塌陷为一个点。</p><p id="54b5" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">[7] K. Zhou 等<a class="ae mg" href="https://arxiv.org/abs/2006.07107" rel="noopener ugc nofollow" target="_blank">深度图神经网络的有效训练策略</a> (2020)。arXiv:2006.07107。</p><p id="d1bb" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">[8] K. Xu 等，<a class="ae mg" href="https://arxiv.org/pdf/1806.03536.pdf" rel="noopener ugc nofollow" target="_blank">具有跳跃知识网络的图上的表征学习</a> (2018)。继续。ICML 2018。</p><p id="d02a" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">[9] S. Gong 等<a class="ae mg" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Gong_Geometrically_Principled_Connections_in_Graph_Neural_Networks_CVPR_2020_paper.pdf" rel="noopener ugc nofollow" target="_blank">图神经网络中的几何原理连接</a> (2020)。继续。CVPR。</p><p id="f2a7" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">[10] C. Szegedy 等人，深入研究卷积(2015 年)。继续。CVPR。</p><p id="e475" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">[11] K. He 等，用于图像识别的深度残差学习(2016)。继续。CVPR。</p><p id="6429" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">[12] G .李等<a class="ae mg" href="https://arxiv.org/pdf/1904.03751.pdf" rel="noopener ugc nofollow" target="_blank">DeepGCNs:GCNs 能不能做到和 CNN 一样深？</a> (2019)。继续。ICCV。展示了几何点云数据的深度优势。</p><p id="5b9e" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">[13] Alon 和 Yahav 将一个节点不能从比层数更远的节点接收信息的情况称为“欠达”。这一现象最早由 P Barceló等人在<a class="ae mg" href="https://openreview.net/pdf?id=r1lZ7AEKvB" rel="noopener ugc nofollow" target="_blank">图神经网络的逻辑表达能力</a> (2020)中指出。继续。ICLR。Alon 和 Yahav 在分子图(使用层数比图的直径多的 gnn)中的化学性质预测问题上通过实验表明，性能差的原因不是不足，而是过度挤压。</p><p id="f640" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">[14] André Araujo 和合著者有一篇关于卷积神经网络中感受域的<a class="ae mg" href="https://distill.pub/2019/computing-receptive-fields/" rel="noopener ugc nofollow" target="_blank">优秀博客文章</a>。随着 CNN 模型在计算机视觉应用中的发展，从 AlexNet 到 VGG、ResNet 和 Inception，它们的感受域随着层数的增加而增加。在现代架构中，感受域通常覆盖整个输入图像，即，最终输出特征图中每个特征使用的上下文包括所有输入像素。Araujo 等人观察到分类准确性和感受野大小之间的对数关系，这表明大的感受野对于高水平的识别任务是必要的，但回报递减。</p><p id="d012" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">[15] M. K. Matlock 等<a class="ae mg" href="https://arxiv.org/pdf/1810.12153.pdf" rel="noopener ugc nofollow" target="_blank">用波网络在无向图中深度学习长程信息</a> (2019)。继续。IJCNN。观察图形神经网络捕捉分子图形中长距离相互作用的失败。</p><p id="c81c" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">[16]这源于与<a class="ae mg" rel="noopener" target="_blank" href="/expressive-power-of-graph-neural-networks-and-the-weisefeiler-lehman-test-b883db3c7c49"> Weisfeiler-Lehman 图同构测试</a>的消息传递 GNN 等价，参见例如 V. Arvind 等人<a class="ae mg" href="https://arxiv.org/abs/1811.04801" rel="noopener ugc nofollow" target="_blank">关于 Weisfeiler-Leman 不变性:子图计数和相关图属性</a> (2018)。arXiv:1811.04801 和 Z. Chen 等人<a class="ae mg" href="https://arxiv.org/abs/2002.04025" rel="noopener ugc nofollow" target="_blank">图神经网络能统计子结构吗？</a> (2020)。arXiv:2002.04025。</p><p id="a2c1" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">[17] N. Dehmamy，A.-L. Barabási，于荣，<a class="ae mg" href="https://papers.nips.cc/paper/9675-understanding-the-representation-power-of-graph-neural-networks-in-learning-graph-topology.pdf" rel="noopener ugc nofollow" target="_blank">理解图神经网络在学习图拓扑中的表示能力</a> (2019)。继续。神经炎。表明学习某阶图矩需要一定深度的 gnn。</p><p id="7ba3" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">[18] F. Monti，K. Otness，M. M. Bronstein，<a class="ae mg" href="https://arxiv.org/pdf/1802.01572" rel="noopener ugc nofollow" target="_blank"> MotifNet:一种基于 motif 的图卷积网络，用于有向图</a> (2018)。arXiv:1802.01572。</p><p id="5108" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">[19] G. Bouritsas et al. <a class="ae mg" href="https://arxiv.org/abs/2006.09252" rel="noopener ugc nofollow" target="_blank">通过子图同构计数提高图神经网络表达能力</a> (2020)。arXiv:2006.09252。</p><p id="5a8f" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">[20] E. Rossi 等人<a class="ae mg" href="https://arxiv.org/pdf/2004.11198" rel="noopener ugc nofollow" target="_blank">签署:可扩展的初始图神经网络</a> (2020)。arXiv:2004.11198</p><p id="f46f" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">[21] O. Shchur 等人<a class="ae mg" href="https://arxiv.org/pdf/1811.05868.pdf" rel="noopener ugc nofollow" target="_blank">图神经网络评估的陷阱</a> (2018)。关系表征学习工作坊。显示简单的 GNN 模型与更复杂的模型表现相当。</p></div><div class="ab cl mq mr hu ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="ij ik il im in"><p id="3067" class="pw-post-body-paragraph lb lc iq ld b le lf ka lg lh li kd lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated"><em class="mh">我非常感谢尤里·阿龙分享他在图形神经网络瓶颈方面的工作，也非常感谢他、法布里齐奥·弗拉斯卡、费德里科·蒙蒂和伊曼纽·罗西对这篇文章的校对。本帖的</em> <a class="ae mg" href="https://www.infoq.cn/article/4wZrGLeyyUghWLaF6DVi" rel="noopener ugc nofollow" target="_blank"> <em class="mh">中文翻译</em> </a> <em class="mh">由</em> <a class="ae mg" href="https://medium.com/@zhiyongliu" rel="noopener"> <em class="mh">刘止庸</em> </a> <em class="mh">提供。关于图形深度学习的其他文章，请参见我的</em> <a class="ae mg" rel="noopener" target="_blank" href="https://towardsdatascience.com/graph-deep-learning/home"> <em class="mh">博客</em> </a> <em class="mh">关于走向数据科学，</em> <a class="ae mg" href="https://michael-bronstein.medium.com/subscribe" rel="noopener"> <em class="mh">订阅</em> </a> <em class="mh">到我的帖子，获取</em> <a class="ae mg" href="https://michael-bronstein.medium.com/membership" rel="noopener"> <em class="mh">中等会员</em> </a> <em class="mh">，或者关注我的</em><a class="ae mg" href="https://twitter.com/mmbronstein" rel="noopener ugc nofollow" target="_blank"><em class="mh">Twitter</em></a><em class="mh">。</em></p></div></div>    
</body>
</html>