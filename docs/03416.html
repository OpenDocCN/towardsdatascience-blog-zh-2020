<html>
<head>
<title>Predicting Bank Customer Leave with Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用神经网络预测银行客户流失</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ann-classification-banking-customer-leave-or-stay-1cba16441185?source=collection_archive---------9-----------------------#2020-04-01">https://towardsdatascience.com/ann-classification-banking-customer-leave-or-stay-1cba16441185?source=collection_archive---------9-----------------------#2020-04-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="037b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">基于Keras的人工神经网络构建在银行客户去留预测中的直观演示</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/2089662431430428828b129c246921c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*o0qVBYabY9c370P7LolORg.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">来自pixabay的Img通过<a class="ae ku" href="https://pixabay.com/photos/brexit-leave-remain-europe-exit-4131852/" rel="noopener ugc nofollow" target="_blank">链接</a></p></figure><p id="d25f" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">本文旨在解释如何创建一个人工神经网络(ANN ),以使用银行客户的原始数据来预测银行客户是否会离开。本文分为以下六个部分。</p><ol class=""><li id="801f" class="lr ls it kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated">问题陈述</li><li id="175d" class="lr ls it kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">数据处理</li><li id="2f77" class="lr ls it kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">模型结构</li><li id="75fa" class="lr ls it kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">模型编译</li><li id="becb" class="lr ls it kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">模型拟合</li><li id="a1c8" class="lr ls it kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">模型预测法</li></ol><p id="f4b6" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">现在让我们开始旅程🏃‍♂️🏃‍♀️!</p><p id="5d26" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> 1。问题陈述</strong></p><p id="1fff" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">一家银行让我们预测客户是否有可能离开银行。给出了6个月的客户银行数据。该银行计划利用你的调查结果，与即将离开的客户重新建立联系。</p><p id="a482" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> 2。数据处理</strong></p><p id="f6dd" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">首先，使用<em class="mf"> read_csv() </em>导入带有<em class="mf"> Pandas </em>的数据，如下所示。</p><pre class="kj kk kl km gt mg mh mi mj aw mk bi"><span id="bbfb" class="ml mm it mh b gy mn mo l mp mq">dataset = pd.read_csv(‘Churn_Modelling.csv’)</span></pre><p id="d005" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">图1显示了数据片段。前13列是关于客户ID、姓名、信用评分、地理位置、性别、年龄等的<strong class="kx iu">独立</strong>变量。最后一列是因变量<strong class="kx iu">决定客户是离开还是留下。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/2bd77b4c357320b12d1d7c1ed65ad3c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*FS9tLPWVcb9DfD_atp-FPA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图1导入数据片段</p></figure><p id="8106" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">现在，让我们开始数据处理。</p><p id="fd12" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">1)特征选择</p><p id="f29d" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><em class="mf">第一个问题:我们需要所有的自变量来拟合模型吗</em>🤔<em class="mf">？</em>答案是<strong class="kx iu">否</strong>。例如，行号、客户ID或姓氏对客户的去留没有影响。但是客户的年龄可能有变化，因为年轻的客户可能会离开银行。根据这个逻辑，我们可以判断哪些独立变量会影响结果。但是请记住，只有神经网络才能判断哪些特征对结果有很大影响。</p><p id="716b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">所以自变量<em class="mf"> X </em>是:</p><pre class="kj kk kl km gt mg mh mi mj aw mk bi"><span id="8cee" class="ml mm it mh b gy mn mo l mp mq">X = dataset.iloc[:, 3: 13].values</span></pre><p id="32a9" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">因变量<em class="mf"> y </em>为:</p><pre class="kj kk kl km gt mg mh mi mj aw mk bi"><span id="91a6" class="ml mm it mh b gy mn mo l mp mq">y = dataset.iloc[:, 13].values</span></pre><p id="160b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">2)分类编码</p><blockquote class="mr"><p id="6bb1" class="ms mt it bd mu mv mw mx my mz na lq dk translated">神经网络只取数值进行学习。</p></blockquote><p id="7e47" class="pw-post-body-paragraph kv kw it kx b ky nb ju la lb nc jx ld le nd lg lh li ne lk ll lm nf lo lp lq im bi translated">因此，分类变量，如地理和性别需要编码成数字变量。这里我们用<strong class="kx iu"><em class="mf">fit _ transform()</em></strong>的方法<strong class="kx iu"><em class="mf">label encoder</em></strong>from<strong class="kx iu"><em class="mf">sk learn</em></strong>。我们为每一列创建两个标签编码器。</p><pre class="kj kk kl km gt mg mh mi mj aw mk bi"><span id="81ed" class="ml mm it mh b gy mn mo l mp mq">from sklearn.preprocessing import LabelEncoder<br/>labelencoder_X_1 = LabelEncoder()<br/>X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])</span></pre><p id="86de" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">注意上面，我们输入索引1，因为<em class="mf"> X </em>中地理列的索引是1。编码后，国家德语变为1，法国为0，西班牙为2。用同样的方法，对性别列进行如下编码。</p><pre class="kj kk kl km gt mg mh mi mj aw mk bi"><span id="2fd0" class="ml mm it mh b gy mn mo l mp mq">labelencoder_X_2 = LabelEncoder()<br/>X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])</span></pre><p id="e2b1" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">现在，男性是1，女性变成0(希望亲爱的女士不会觉得被冒犯，因为这纯粹是随机的😊).</p><p id="a7c1" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">3)一键编码</p><p id="e6e5" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">注意上面的编码后，德语变成了1，法国是0，西班牙是2。然而，国与国之间没有关系秩序。即西班牙不比德国高，法国不比西班牙低。所以我们需要为分类变量创建<strong class="kx iu"> <em class="mf">虚拟变量</em> </strong>来去除分类编码引入的数值关系。<strong class="kx iu">这里只需要为地理列做这件事，因为性别列只有2个类别。</strong></p><pre class="kj kk kl km gt mg mh mi mj aw mk bi"><span id="8527" class="ml mm it mh b gy mn mo l mp mq">from sklearn.preprocessing import OneHotEncoder<br/>onehotencoder = OneHotEncoder(categorical_features = [1])<br/>X = onehotencoder.fit_transform(X).toarray()</span></pre><p id="dcf9" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">图2是编码数据。<strong class="kx iu">请注意，前3列是针对德国、法国和西班牙国家的一次性编码虚拟变量。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/03d157d2549c7a119cbe1acbd4f88a28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*ND6GC8s9lk-zQBLE3VP9Tg.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图2编码数据片段</p></figure><blockquote class="ng nh ni"><p id="51ea" class="kv kw mf kx b ky kz ju la lb lc jx ld nj lf lg lh nk lj lk ll nl ln lo lp lq im bi translated">为了<strong class="kx iu">避免伪数据陷阱</strong>，我们删除了第1列，因为具有0和1的两列足以编码3个国家。</p></blockquote><pre class="kj kk kl km gt mg mh mi mj aw mk bi"><span id="3093" class="ml mm it mh b gy mn mo l mp mq">X = X[:, 1:]</span></pre><p id="641f" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">4)数据分割</p><p id="ec72" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">接下来，将数据分为训练集和测试集，测试集占20%。我们使用<em class="mf"> random_state </em>来确保每次分割保持不变。</p><pre class="kj kk kl km gt mg mh mi mj aw mk bi"><span id="9e1d" class="ml mm it mh b gy mn mo l mp mq">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.2, random_state = 0)</span></pre><p id="9827" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">5)特征缩放</p><blockquote class="ng nh ni"><p id="2630" class="kv kw mf kx b ky kz ju la lb lc jx ld nj lf lg lh nk lj lk ll nl ln lo lp lq im bi translated">缩放特征是为了避免密集的计算，也是为了避免一个变量支配其他变量。对于二元分类问题，不需要缩放因变量。但是对于回归，我们需要缩放因变量。</p></blockquote><p id="528b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">正常的方法包括标准化和规范化，如图3所示。这里我们拿<strong class="kx iu">标准化</strong>来说。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/805990a386643cac77489b0a881dea7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*Jz55VM8X-aMt8ACE8AWkog.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图3特征缩放方法(作者创建的Img)</p></figure><pre class="kj kk kl km gt mg mh mi mj aw mk bi"><span id="28a2" class="ml mm it mh b gy mn mo l mp mq">from sklearn.preprocessing import StandardScaler<br/>sc = StandardScaler()<br/>X_train = sc.fit_transform(X_train)<br/>X_test = sc.transform(X_test)</span></pre><p id="14ea" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">注意，我们使用来自训练集的标度集来转换测试集。这一步，数据处理就完成了。图4是您应该得到的测试数据。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi ki"><img src="../Images/4fff62d36d76ad94bb8e93043fd9fa42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*yR2IcnRCcRAAWOKU9X6Y5Q.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图4最终测试数据片段</p></figure><p id="f8ae" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> 3。模型构建</strong></p><p id="4b53" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">这里我们使用<strong class="kx iu"> <em class="mf"> Keras </em> </strong>建立一个序列模型。第一步是初始化顺序模型。</p><pre class="kj kk kl km gt mg mh mi mj aw mk bi"><span id="fa21" class="ml mm it mh b gy mn mo l mp mq">classifier = Sequential()</span></pre><p id="b077" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">对于这个问题，模型由两个密集层构成。</p><pre class="kj kk kl km gt mg mh mi mj aw mk bi"><span id="817e" class="ml mm it mh b gy mn mo l mp mq">#add input layer and first hidden layer<br/>classifier.add(Dense(output_dim = 6, init = ‘uniform’, activation = ‘relu’, input_dim = 11))</span><span id="959f" class="ml mm it mh b gy nr mo l mp mq">#add 2nd hidden layer<br/>classifier.add(Dense(output_dim = 6, init = ‘uniform’, activation = ‘relu’))</span></pre><p id="104b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">注意<strong class="kx iu"> <em class="mf"> Output_dim </em> </strong>对于隐藏层来说是一种艺术的选择，看你的经验了。<strong class="kx iu">作为提示，基于实验，选择它作为输入层节点数和输出层节点数的平均值。</strong>一个更明智的方法是使用<strong class="kx iu">参数调整</strong>，使用类似k-fold交叉验证的技术，用不同的参数测试不同的模型。这里，输入维度是11个特征，输出维度是1，因此输出维度是6。这里我们使用<strong class="kx iu"> <em class="mf">均匀</em> </strong>分布来随机化0和1之间的权重。使用<strong class="kx iu"> <em class="mf"> ReLU </em> </strong>函数进行隐藏层激活，根据我的实验，这是最好的。请随意尝试你的。</p><p id="4a9e" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">下面添加输出层。</p><pre class="kj kk kl km gt mg mh mi mj aw mk bi"><span id="780f" class="ml mm it mh b gy mn mo l mp mq">classifier.add(Dense(output_dim = 1, init = ‘uniform’, activation = ‘sigmoid’))</span></pre><p id="d944" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">对于输出层，我们使用<strong class="kx iu"> <em class="mf"> Sigmoid </em> </strong>函数来获得客户离开或留在银行的概率。如果处理多分类，使用<strong class="kx iu"> <em class="mf"> Softmax </em> </strong>功能。</p><p id="0040" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> 4。模型编译</strong></p><blockquote class="mr"><p id="6e39" class="ms mt it bd mu mv mw mx my mz na lq dk translated">模型编译是在网络上应用<strong class="ak">随机梯度下降(SGD) </strong>。</p></blockquote><pre class="ns nt nu nv nw mg mh mi mj aw mk bi"><span id="caf3" class="ml mm it mh b gy mn mo l mp mq">classifier.compile(optimizer = ‘Adam’, loss =’binary_crossentropy’, metrics = [‘accuracy’])</span></pre><p id="782e" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">这里我们使用<strong class="kx iu"> <em class="mf"> Adam </em> </strong>(一种<strong class="kx iu"> SGD </strong>)作为优化器，寻找使神经网络最强大的优化权重。优化器所依据的损失函数是<strong class="kx iu"> <em class="mf">二元交叉熵</em> </strong>。我们用来评估模型性能的指标是<strong class="kx iu"> <em class="mf">准确性</em> </strong>。</p><p id="8f3d" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> 5。模型拟合</strong></p><p id="b0b8" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">由于我们使用<strong class="kx iu"> SGD </strong>，批量被设置为10，表明神经网络在10次观察后更新其权重。Epoch是通过网络的一轮完整数据流。这里我们选100。</p><pre class="kj kk kl km gt mg mh mi mj aw mk bi"><span id="314b" class="ml mm it mh b gy mn mo l mp mq">classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)</span></pre><p id="957d" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">现在是拟合模型的时候了。大约35个历元后，模型精度收敛到<strong class="kx iu"> <em class="mf"> 0.837 </em> </strong>。不错吧，✨✨？</p><p id="a5aa" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> 6。模型预测</strong></p><p id="ec06" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">随着模型的拟合，我们在测试数据上测试模型。使用阈值0.5，将数据转换为真(离开)和假(停留)数据。</p><pre class="kj kk kl km gt mg mh mi mj aw mk bi"><span id="d2e5" class="ml mm it mh b gy mn mo l mp mq">y_pred = classifier.predict(X_test)<br/>y_pred = (y_pred &gt; 0.5)</span></pre><p id="412c" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">然后我们使用<strong class="kx iu"> <em class="mf">混淆_矩阵</em> </strong>在测试集上考察模型性能。</p><pre class="kj kk kl km gt mg mh mi mj aw mk bi"><span id="be8a" class="ml mm it mh b gy mn mo l mp mq">from sklearn.metrics import confusion_matrix<br/>cm = confusion_matrix(y_test, y_pred</span></pre><p id="ee46" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">精度为0.859，高于训练精度，暗示过拟合。</p><p id="8366" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">有了上面的模型，银行可以测试新客户，得到离开或留下的概率。然后，银行可以抽取10%可能性最高的客户，对客户数据进行深度挖掘，了解他们为什么有可能离开。这就是人工神经网络的目的。</p><p id="30a4" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">现在最后一个问题:</strong>如何对新客户数据进行预测🤔？例如，图5中的客户数据:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/49f68b7d3e9e526c3f5e6438d9cedeb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*IK5UCWzo1ZEGz5-I3CdvKA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图5新客户数据</p></figure><p id="a6aa" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">正如你所想象的，我们需要遵循同样的数据处理。首先，对变量进行编码。例如，在虚拟变量中，地理位置法国被编码为(0，0)，性别男性为1。按照这个方法，我们产生了下面的数组。</p><pre class="kj kk kl km gt mg mh mi mj aw mk bi"><span id="2de7" class="ml mm it mh b gy mn mo l mp mq">new_customer = [[0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]]</span></pre><p id="046c" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">好了，一个家庭作业问题:为什么我们使用<strong class="kx iu"> <em class="mf"> [[]] </em> </strong>来创建数组🤔？</p><p id="af0b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">下一步是将变量调整到与训练集相同的范围。</p><pre class="kj kk kl km gt mg mh mi mj aw mk bi"><span id="e658" class="ml mm it mh b gy mn mo l mp mq">new_customer = sc.transform(sc.transform(new_customer))</span></pre><p id="37cd" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">数据准备就绪后，通过以下方式进行预测:</p><pre class="kj kk kl km gt mg mh mi mj aw mk bi"><span id="4161" class="ml mm it mh b gy mn mo l mp mq">new_prediction = classifier.predict(new_customer)<br/>new_prediction = (new_prediction &gt; 0.5)</span></pre><p id="eeee" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">预测结果为假，可能性为<em class="mf"> 0.418% </em>，表明该客户不太可能离开银行👍👍。</p><p id="5d69" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">太好了！仅此而已。如果你需要一些额外的，请访问我的</strong> <a class="ae ku" href="https://github.com/luke4u/Customer_Behaviour_Prediction" rel="noopener ugc nofollow" target="_blank"> <strong class="kx iu"> Github </strong> </a> <strong class="kx iu">回购(仅供参考，回购是积极维护的)💕💕。</strong></p></div></div>    
</body>
</html>